2022-03-28 19:56:14,273: [('name', 'amsoft-36'), ('backbone_model_name', 'SimpleResnet_36'), ('classify_model_name', 'Sphereface2'), ('resume_net_model', '/home/ubuntu/data2/lk/recognition/pytorch_new/snapshot/SR_36_ddp_sphereface2_25continue/backbone_35_checkpoint.pth'), ('resume_net_classifier', '/home/ubuntu/data2/lk/recognition/pytorch_new/snapshot/SR_36_ddp_sphereface2_25continue/classifier_status_35_checkpoint.pth'), ('no_cuda', False), ('gpu_num', 1), ('log_interval', 100), ('log_path', './logs/SR_36_ddp_sphereface2_35continue.log'), ('log_pic_path', './logs/pic/SR_36_ddp_sphereface2_35continue/'), ('save_path', 'snapshot/SR_36_ddp_sphereface2_35continue/'), ('lmdb_path', '/home/ubuntu/data4/lk/data/lmdb_default'), ('batch_size', 512), ('datanum', 3923399), ('num_class', 86876), ('lmdb_workers', 4), ('num_workers', 4), ('start_epoch', 1), ('max_epoch', 45), ('lr', 0.01), ('base', 'epoch'), ('step_size', [10, 20, 30, 40]), ('momentum', 0.9), ('gama', 0.1), ('weight_decay', 0.0005), ('rank', 0), ('dist_url', 'env://'), ('world_size', 2), ('gpu', 0), ('dist_backend', 'nccl'), ('distributed', True), ('master_port', 22000), ('multiprocessing_distributed', False), ('SEED', 1337), ('local_rank', 0)]
2022-03-28 19:56:14,274: SimpleResidualBackbone(
  (conv1): ConvPrelu(
    (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (prelu): PReLU(num_parameters=64)
  )
  (layer1): Sequential(
    (0): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=64)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=64)
      )
    )
    (1): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=64)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=64)
      )
    )
  )
  (conv2): ConvPrelu(
    (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (prelu): PReLU(num_parameters=128)
  )
  (layer2): Sequential(
    (0): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
    )
    (1): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
    )
    (2): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
    )
    (3): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
    )
  )
  (conv3): ConvPrelu(
    (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (prelu): PReLU(num_parameters=256)
  )
  (layer3): Sequential(
    (0): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
    (1): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
    (2): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
    (3): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
    (4): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
    (5): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
    (6): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
    (7): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
  )
  (conv4): ConvPrelu(
    (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (prelu): PReLU(num_parameters=512)
  )
  (layer4): Sequential(
    (0): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=512)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=512)
      )
    )
    (1): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=512)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=512)
      )
    )
  )
  (fc5): Linear(in_features=25088, out_features=512, bias=True)
)
2022-03-28 19:56:14,614: Loading resume (model) network...
2022-03-28 19:56:17,792: resume net (model) loaded
2022-03-28 19:56:17,792: Loading resume (classifier) network...
2022-03-28 19:56:24,303: start epoch: 35
2022-03-28 19:56:25,145: resume net (classifier) loaded
2022-03-28 19:56:25,734: data balance
2022-03-28 19:57:03,993: time cost, forward:0.12693767354945945, backward:0.052015237133912366, data cost:0.2034319940239492 
2022-03-28 19:57:04,019: ============================================================
2022-03-28 19:57:04,020: Epoch 35/45 Batch 100/7662 eta: 8:54:37.308165	Training Loss 0.4285 (0.4311)	Training Prec@1 92.383 (92.274)	Training Prec@5 94.727 (95.200)	
2022-03-28 19:57:04,020: ============================================================
2022-03-28 19:57:37,784: time cost, forward:0.11895940531438319, backward:0.042947525954126715, data cost:0.1979225376742569 
2022-03-28 19:57:37,784: ============================================================
2022-03-28 19:57:37,784: Epoch 35/45 Batch 200/7662 eta: 7:53:10.367234	Training Loss 0.4353 (0.4313)	Training Prec@1 90.234 (92.228)	Training Prec@5 93.945 (95.194)	
2022-03-28 19:57:37,785: ============================================================
2022-03-28 19:58:11,728: time cost, forward:0.11567543103144719, backward:0.0397032224214994, data cost:0.19753519268737588 
2022-03-28 19:58:11,728: ============================================================
2022-03-28 19:58:11,729: Epoch 35/45 Batch 300/7662 eta: 7:55:07.532521	Training Loss 0.4401 (0.4313)	Training Prec@1 93.750 (92.275)	Training Prec@5 95.898 (95.218)	
2022-03-28 19:58:11,729: ============================================================
2022-03-28 19:58:45,846: time cost, forward:0.11387291050196291, backward:0.03801308419172626, data cost:0.19797697700653458 
2022-03-28 19:58:45,847: ============================================================
2022-03-28 19:58:45,847: Epoch 35/45 Batch 400/7662 eta: 7:56:59.284563	Training Loss 0.4287 (0.4316)	Training Prec@1 92.969 (92.237)	Training Prec@5 96.289 (95.181)	
2022-03-28 19:58:45,847: ============================================================
2022-03-28 19:59:21,777: time cost, forward:0.11278469194630104, backward:0.03707397533561997, data cost:0.20163885386052255 
2022-03-28 19:59:21,777: ============================================================
2022-03-28 19:59:21,778: Epoch 35/45 Batch 500/7662 eta: 8:21:43.788871	Training Loss 0.4356 (0.4318)	Training Prec@1 90.625 (92.160)	Training Prec@5 93.750 (95.147)	
2022-03-28 19:59:21,778: ============================================================
2022-03-28 19:59:58,033: time cost, forward:0.11211379700789667, backward:0.03636335729557604, data cost:0.2048838146540876 
2022-03-28 19:59:58,034: ============================================================
2022-03-28 19:59:58,034: Epoch 35/45 Batch 600/7662 eta: 8:25:40.539469	Training Loss 0.4220 (0.4316)	Training Prec@1 94.922 (92.176)	Training Prec@5 96.680 (95.167)	
2022-03-28 19:59:58,034: ============================================================
2022-03-28 20:00:36,126: time cost, forward:0.11180173105777419, backward:0.03592571543692178, data cost:0.20957359530895053 
2022-03-28 20:00:36,159: ============================================================
2022-03-28 20:00:36,160: Epoch 35/45 Batch 700/7662 eta: 8:51:06.402359	Training Loss 0.4185 (0.4316)	Training Prec@1 93.750 (92.178)	Training Prec@5 95.898 (95.163)	
2022-03-28 20:00:36,160: ============================================================
2022-03-28 20:01:16,142: time cost, forward:0.11144349542219141, backward:0.03582685283188229, data cost:0.21528820012776514 
2022-03-28 20:01:16,143: ============================================================
2022-03-28 20:01:16,143: Epoch 35/45 Batch 800/7662 eta: 9:16:19.309467	Training Loss 0.4310 (0.4315)	Training Prec@1 92.578 (92.191)	Training Prec@5 94.727 (95.178)	
2022-03-28 20:01:16,143: ============================================================
2022-03-28 20:01:54,833: time cost, forward:0.11119178590572981, backward:0.035631686084395126, data cost:0.21827442600941896 
2022-03-28 20:01:54,833: ============================================================
2022-03-28 20:01:54,834: Epoch 35/45 Batch 900/7662 eta: 8:57:41.440383	Training Loss 0.4262 (0.4316)	Training Prec@1 93.750 (92.153)	Training Prec@5 96.875 (95.150)	
2022-03-28 20:01:54,834: ============================================================
2022-03-28 20:02:34,043: time cost, forward:0.11101794624710465, backward:0.03537991789129523, data cost:0.2215414035308349 
2022-03-28 20:02:34,044: ============================================================
2022-03-28 20:02:34,044: Epoch 35/45 Batch 1000/7662 eta: 9:04:15.415835	Training Loss 0.4431 (0.4316)	Training Prec@1 89.648 (92.126)	Training Prec@5 92.969 (95.149)	
2022-03-28 20:02:34,044: ============================================================
2022-03-28 20:03:15,314: time cost, forward:0.11095685607417266, backward:0.03513947761091349, data cost:0.22588644752294176 
2022-03-28 20:03:15,314: ============================================================
2022-03-28 20:03:15,314: Epoch 35/45 Batch 1100/7662 eta: 9:32:10.159558	Training Loss 0.4366 (0.4316)	Training Prec@1 92.578 (92.116)	Training Prec@5 94.727 (95.139)	
2022-03-28 20:03:15,315: ============================================================
2022-03-28 20:03:56,608: time cost, forward:0.11082858955790541, backward:0.03496697408343674, data cost:0.22925340502932232 
2022-03-28 20:03:56,609: ============================================================
2022-03-28 20:03:56,609: Epoch 35/45 Batch 1200/7662 eta: 9:31:48.757861	Training Loss 0.4364 (0.4316)	Training Prec@1 91.016 (92.122)	Training Prec@5 95.117 (95.140)	
2022-03-28 20:03:56,609: ============================================================
2022-03-28 20:04:36,925: time cost, forward:0.11066992471913727, backward:0.03482374289661669, data cost:0.23164231085245016 
2022-03-28 20:04:36,926: ============================================================
2022-03-28 20:04:36,926: Epoch 35/45 Batch 1300/7662 eta: 9:17:36.252674	Training Loss 0.4244 (0.4317)	Training Prec@1 91.016 (92.110)	Training Prec@5 94.531 (95.133)	
2022-03-28 20:04:36,926: ============================================================
2022-03-28 20:05:15,715: time cost, forward:0.1106538522064558, backward:0.03478430031537157, data cost:0.2325409510205523 
2022-03-28 20:05:15,716: ============================================================
2022-03-28 20:05:15,717: Epoch 35/45 Batch 1400/7662 eta: 8:55:50.759102	Training Loss 0.4360 (0.4316)	Training Prec@1 91.602 (92.096)	Training Prec@5 94.336 (95.123)	
2022-03-28 20:05:15,717: ============================================================
2022-03-28 20:05:56,230: time cost, forward:0.11051216993910858, backward:0.03466769104563768, data cost:0.23480439456484173 
2022-03-28 20:05:56,231: ============================================================
2022-03-28 20:05:56,232: Epoch 35/45 Batch 1500/7662 eta: 9:18:59.596682	Training Loss 0.4311 (0.4316)	Training Prec@1 91.992 (92.096)	Training Prec@5 95.117 (95.119)	
2022-03-28 20:05:56,232: ============================================================
2022-03-28 20:06:39,266: time cost, forward:0.1105137388731555, backward:0.03465619379464651, data cost:0.23788936649582548 
2022-03-28 20:06:39,267: ============================================================
2022-03-28 20:06:39,268: Epoch 35/45 Batch 1600/7662 eta: 9:53:03.316519	Training Loss 0.4409 (0.4316)	Training Prec@1 93.164 (92.112)	Training Prec@5 95.508 (95.130)	
2022-03-28 20:06:39,268: ============================================================
2022-03-28 20:07:23,943: time cost, forward:0.11045534811418431, backward:0.034702512781503554, data cost:0.24162743539232026 
2022-03-28 20:07:23,944: ============================================================
2022-03-28 20:07:23,944: Epoch 35/45 Batch 1700/7662 eta: 10:14:55.106445	Training Loss 0.4317 (0.4316)	Training Prec@1 91.602 (92.105)	Training Prec@5 95.312 (95.132)	
2022-03-28 20:07:23,944: ============================================================
2022-03-28 20:08:08,560: time cost, forward:0.11040269513472112, backward:0.03474593904695622, data cost:0.24491454098475118 
2022-03-28 20:08:08,561: ============================================================
2022-03-28 20:08:08,561: Epoch 35/45 Batch 1800/7662 eta: 10:13:21.510794	Training Loss 0.4232 (0.4316)	Training Prec@1 93.945 (92.103)	Training Prec@5 96.289 (95.130)	
2022-03-28 20:08:08,561: ============================================================
2022-03-28 20:08:53,237: time cost, forward:0.11032415302632168, backward:0.03472155254096844, data cost:0.2479797387637861 
2022-03-28 20:08:53,238: ============================================================
2022-03-28 20:08:53,238: Epoch 35/45 Batch 1900/7662 eta: 10:13:26.344085	Training Loss 0.4353 (0.4315)	Training Prec@1 92.578 (92.106)	Training Prec@5 94.727 (95.134)	
2022-03-28 20:08:53,238: ============================================================
2022-03-28 20:09:37,851: time cost, forward:0.11027429412757832, backward:0.03468654345368791, data cost:0.25070359421825933 
2022-03-28 20:09:37,851: ============================================================
2022-03-28 20:09:37,851: Epoch 35/45 Batch 2000/7662 eta: 10:11:49.099913	Training Loss 0.4357 (0.4316)	Training Prec@1 92.188 (92.100)	Training Prec@5 95.703 (95.130)	
2022-03-28 20:09:37,852: ============================================================
2022-03-28 20:10:22,418: time cost, forward:0.11022218651519383, backward:0.03464119680839928, data cost:0.25316458102803735 
2022-03-28 20:10:22,419: ============================================================
2022-03-28 20:10:22,419: Epoch 35/45 Batch 2100/7662 eta: 10:10:26.972495	Training Loss 0.4402 (0.4315)	Training Prec@1 92.578 (92.099)	Training Prec@5 95.703 (95.130)	
2022-03-28 20:10:22,419: ============================================================
2022-03-28 20:11:06,941: time cost, forward:0.11014931708262583, backward:0.03459965537601625, data cost:0.2554046484273691 
2022-03-28 20:11:06,941: ============================================================
2022-03-28 20:11:06,942: Epoch 35/45 Batch 2200/7662 eta: 10:09:05.645201	Training Loss 0.4171 (0.4316)	Training Prec@1 91.992 (92.094)	Training Prec@5 94.922 (95.122)	
2022-03-28 20:11:06,942: ============================================================
2022-03-28 20:11:51,531: time cost, forward:0.11009794113272012, backward:0.034573992006983016, data cost:0.2574488576363874 
2022-03-28 20:11:51,532: ============================================================
2022-03-28 20:11:51,532: Epoch 35/45 Batch 2300/7662 eta: 10:09:16.276705	Training Loss 0.4368 (0.4315)	Training Prec@1 92.773 (92.093)	Training Prec@5 95.117 (95.126)	
2022-03-28 20:11:51,532: ============================================================
2022-03-28 20:12:36,127: time cost, forward:0.11003176815164939, backward:0.03460913610836028, data cost:0.2592912990384024 
2022-03-28 20:12:36,127: ============================================================
2022-03-28 20:12:36,128: Epoch 35/45 Batch 2400/7662 eta: 10:08:36.383536	Training Loss 0.4263 (0.4315)	Training Prec@1 91.211 (92.091)	Training Prec@5 95.117 (95.122)	
2022-03-28 20:12:36,128: ============================================================
2022-03-28 20:13:20,841: time cost, forward:0.10997408921835947, backward:0.03461511109341808, data cost:0.2610546036117694 
2022-03-28 20:13:20,841: ============================================================
2022-03-28 20:13:20,841: Epoch 35/45 Batch 2500/7662 eta: 10:09:28.278437	Training Loss 0.4452 (0.4315)	Training Prec@1 89.844 (92.089)	Training Prec@5 92.578 (95.118)	
2022-03-28 20:13:20,842: ============================================================
2022-03-28 20:14:05,712: time cost, forward:0.10988940344997991, backward:0.03461195744657205, data cost:0.2627819764150845 
2022-03-28 20:14:05,713: ============================================================
2022-03-28 20:14:05,713: Epoch 35/45 Batch 2600/7662 eta: 10:10:52.556982	Training Loss 0.4312 (0.4315)	Training Prec@1 91.797 (92.080)	Training Prec@5 95.117 (95.112)	
2022-03-28 20:14:05,713: ============================================================
2022-03-28 20:14:50,439: time cost, forward:0.10985492379102675, backward:0.0345847583691603, data cost:0.26431334111459964 
2022-03-28 20:14:50,440: ============================================================
2022-03-28 20:14:50,440: Epoch 35/45 Batch 2700/7662 eta: 10:08:09.532905	Training Loss 0.4404 (0.4315)	Training Prec@1 91.211 (92.077)	Training Prec@5 94.141 (95.108)	
2022-03-28 20:14:50,440: ============================================================
2022-03-28 20:15:35,197: time cost, forward:0.10981198863158613, backward:0.03454744709351524, data cost:0.26576676884903655 
2022-03-28 20:15:35,197: ============================================================
2022-03-28 20:15:35,197: Epoch 35/45 Batch 2800/7662 eta: 10:07:49.601168	Training Loss 0.4302 (0.4316)	Training Prec@1 92.383 (92.078)	Training Prec@5 94.727 (95.109)	
2022-03-28 20:15:35,197: ============================================================
2022-03-28 20:16:19,863: time cost, forward:0.10980571266205898, backward:0.03453787798386436, data cost:0.26702635047270457 
2022-03-28 20:16:19,864: ============================================================
2022-03-28 20:16:19,864: Epoch 35/45 Batch 2900/7662 eta: 10:05:51.202041	Training Loss 0.4407 (0.4316)	Training Prec@1 90.625 (92.077)	Training Prec@5 93.750 (95.107)	
2022-03-28 20:16:19,864: ============================================================
2022-03-28 20:17:04,558: time cost, forward:0.10974988590760722, backward:0.03451129737477495, data cost:0.26828084289332 
2022-03-28 20:17:04,559: ============================================================
2022-03-28 20:17:04,559: Epoch 35/45 Batch 3000/7662 eta: 10:05:29.479043	Training Loss 0.4360 (0.4316)	Training Prec@1 90.039 (92.077)	Training Prec@5 93.555 (95.105)	
2022-03-28 20:17:04,559: ============================================================
2022-03-28 20:17:49,268: time cost, forward:0.1097121493360157, backward:0.03442568946707899, data cost:0.2695096733109264 
2022-03-28 20:17:49,269: ============================================================
2022-03-28 20:17:49,270: Epoch 35/45 Batch 3100/7662 eta: 10:04:57.093531	Training Loss 0.4348 (0.4316)	Training Prec@1 91.406 (92.083)	Training Prec@5 94.531 (95.109)	
2022-03-28 20:17:49,270: ============================================================
2022-03-28 20:18:33,950: time cost, forward:0.10966806495215752, backward:0.03432853716021219, data cost:0.27067799760461336 
2022-03-28 20:18:33,950: ============================================================
2022-03-28 20:18:33,950: Epoch 35/45 Batch 3200/7662 eta: 10:03:48.627178	Training Loss 0.4393 (0.4316)	Training Prec@1 92.773 (92.081)	Training Prec@5 94.336 (95.107)	
2022-03-28 20:18:33,951: ============================================================
2022-03-28 20:19:18,735: time cost, forward:0.10963348136883354, backward:0.034269540445050824, data cost:0.2717679353438207 
2022-03-28 20:19:18,736: ============================================================
2022-03-28 20:19:18,736: Epoch 35/45 Batch 3300/7662 eta: 10:04:28.692285	Training Loss 0.4315 (0.4316)	Training Prec@1 92.773 (92.079)	Training Prec@5 96.289 (95.104)	
2022-03-28 20:19:18,736: ============================================================
2022-03-28 20:20:03,605: time cost, forward:0.1096120781321917, backward:0.03419807462981253, data cost:0.27282391018150626 
2022-03-28 20:20:03,605: ============================================================
2022-03-28 20:20:03,605: Epoch 35/45 Batch 3400/7662 eta: 10:04:51.628887	Training Loss 0.4290 (0.4316)	Training Prec@1 91.211 (92.083)	Training Prec@5 94.336 (95.108)	
2022-03-28 20:20:03,605: ============================================================
2022-03-28 20:20:48,704: time cost, forward:0.10959410939975683, backward:0.03413001984724081, data cost:0.27388479560400697 
2022-03-28 20:20:48,705: ============================================================
2022-03-28 20:20:48,705: Epoch 35/45 Batch 3500/7662 eta: 10:07:12.853651	Training Loss 0.4310 (0.4316)	Training Prec@1 89.648 (92.083)	Training Prec@5 92.578 (95.103)	
2022-03-28 20:20:48,705: ============================================================
2022-03-28 20:21:33,665: time cost, forward:0.10957511877742003, backward:0.03408972261083825, data cost:0.27482691364971984 
2022-03-28 20:21:33,665: ============================================================
2022-03-28 20:21:33,666: Epoch 35/45 Batch 3600/7662 eta: 10:04:35.631991	Training Loss 0.4388 (0.4317)	Training Prec@1 90.820 (92.076)	Training Prec@5 94.141 (95.093)	
2022-03-28 20:21:33,666: ============================================================
2022-03-28 20:22:18,659: time cost, forward:0.10955248551937205, backward:0.034119691678594015, data cost:0.27566015601125915 
2022-03-28 20:22:18,659: ============================================================
2022-03-28 20:22:18,660: Epoch 35/45 Batch 3700/7662 eta: 10:04:17.766862	Training Loss 0.4419 (0.4317)	Training Prec@1 89.844 (92.079)	Training Prec@5 93.555 (95.096)	
2022-03-28 20:22:18,660: ============================================================
2022-03-28 20:23:03,676: time cost, forward:0.10954044172091684, backward:0.034181337100513735, data cost:0.2764126306836559 
2022-03-28 20:23:03,677: ============================================================
2022-03-28 20:23:03,677: Epoch 35/45 Batch 3800/7662 eta: 10:03:51.119770	Training Loss 0.4411 (0.4317)	Training Prec@1 91.992 (92.075)	Training Prec@5 94.531 (95.092)	
2022-03-28 20:23:03,677: ============================================================
2022-03-28 20:23:48,830: time cost, forward:0.10952889249703308, backward:0.034207683797064854, data cost:0.27719505330359945 
2022-03-28 20:23:48,831: ============================================================
2022-03-28 20:23:48,831: Epoch 35/45 Batch 3900/7662 eta: 10:04:56.037707	Training Loss 0.4323 (0.4317)	Training Prec@1 92.188 (92.075)	Training Prec@5 94.531 (95.090)	
2022-03-28 20:23:48,831: ============================================================
2022-03-28 20:24:33,909: time cost, forward:0.10951164514608877, backward:0.03418607484045313, data cost:0.2779722721107485 
2022-03-28 20:24:33,910: ============================================================
2022-03-28 20:24:33,910: Epoch 35/45 Batch 4000/7662 eta: 10:03:10.685327	Training Loss 0.4415 (0.4317)	Training Prec@1 91.211 (92.072)	Training Prec@5 94.922 (95.088)	
2022-03-28 20:24:33,910: ============================================================
2022-03-28 20:25:19,034: time cost, forward:0.1094988226512491, backward:0.03414878591615184, data cost:0.27873515425498496 
2022-03-28 20:25:19,035: ============================================================
2022-03-28 20:25:19,035: Epoch 35/45 Batch 4100/7662 eta: 10:03:02.582956	Training Loss 0.4408 (0.4317)	Training Prec@1 91.602 (92.078)	Training Prec@5 94.141 (95.092)	
2022-03-28 20:25:19,035: ============================================================
2022-03-28 20:26:04,182: time cost, forward:0.10948558176208263, backward:0.034125141144707306, data cost:0.27945792019211074 
2022-03-28 20:26:04,183: ============================================================
2022-03-28 20:26:04,183: Epoch 35/45 Batch 4200/7662 eta: 10:02:35.946923	Training Loss 0.4304 (0.4317)	Training Prec@1 92.773 (92.073)	Training Prec@5 96.875 (95.090)	
2022-03-28 20:26:04,183: ============================================================
2022-03-28 20:26:49,328: time cost, forward:0.1094701363336599, backward:0.03412646059380989, data cost:0.280126522684907 
2022-03-28 20:26:49,328: ============================================================
2022-03-28 20:26:49,329: Epoch 35/45 Batch 4300/7662 eta: 10:01:48.982849	Training Loss 0.4384 (0.4317)	Training Prec@1 91.797 (92.077)	Training Prec@5 95.117 (95.092)	
2022-03-28 20:26:49,329: ============================================================
2022-03-28 20:27:34,442: time cost, forward:0.10945515991422528, backward:0.03410385781782653, data cost:0.2807788286297992 
2022-03-28 20:27:34,442: ============================================================
2022-03-28 20:27:34,442: Epoch 35/45 Batch 4400/7662 eta: 10:00:37.972161	Training Loss 0.4271 (0.4317)	Training Prec@1 92.383 (92.079)	Training Prec@5 95.898 (95.092)	
2022-03-28 20:27:34,442: ============================================================
2022-03-28 20:28:19,545: time cost, forward:0.10942600922839964, backward:0.034082315529312235, data cost:0.2814171208782073 
2022-03-28 20:28:19,545: ============================================================
2022-03-28 20:28:19,546: Epoch 35/45 Batch 4500/7662 eta: 9:59:44.773904	Training Loss 0.4297 (0.4317)	Training Prec@1 92.578 (92.076)	Training Prec@5 95.312 (95.091)	
2022-03-28 20:28:19,546: ============================================================
2022-03-28 20:29:04,662: time cost, forward:0.10940403703970349, backward:0.034068016519648116, data cost:0.2820169771720752 
2022-03-28 20:29:04,662: ============================================================
2022-03-28 20:29:04,662: Epoch 35/45 Batch 4600/7662 eta: 9:59:10.266676	Training Loss 0.4260 (0.4317)	Training Prec@1 92.383 (92.077)	Training Prec@5 95.703 (95.092)	
2022-03-28 20:29:04,662: ============================================================
2022-03-28 20:29:49,747: time cost, forward:0.10938998470156211, backward:0.03403589019726682, data cost:0.2825940590915489 
2022-03-28 20:29:49,747: ============================================================
2022-03-28 20:29:49,747: Epoch 35/45 Batch 4700/7662 eta: 9:58:00.096902	Training Loss 0.4226 (0.4317)	Training Prec@1 92.773 (92.073)	Training Prec@5 95.898 (95.090)	
2022-03-28 20:29:49,748: ============================================================
2022-03-28 20:30:34,823: time cost, forward:0.10937322554774125, backward:0.03401588941519646, data cost:0.28314006927237456 
2022-03-28 20:30:34,824: ============================================================
2022-03-28 20:30:34,824: Epoch 35/45 Batch 4800/7662 eta: 9:57:08.288425	Training Loss 0.4272 (0.4317)	Training Prec@1 92.188 (92.073)	Training Prec@5 95.898 (95.091)	
2022-03-28 20:30:34,824: ============================================================
2022-03-28 20:31:19,934: time cost, forward:0.10935024452053739, backward:0.03398947741066005, data cost:0.2836843954103045 
2022-03-28 20:31:19,935: ============================================================
2022-03-28 20:31:19,935: Epoch 35/45 Batch 4900/7662 eta: 9:56:50.294652	Training Loss 0.4243 (0.4317)	Training Prec@1 93.945 (92.075)	Training Prec@5 95.898 (95.092)	
2022-03-28 20:31:19,935: ============================================================
2022-03-28 20:32:05,026: time cost, forward:0.10933464502043475, backward:0.03397223815414328, data cost:0.28418967523057836 
2022-03-28 20:32:05,026: ============================================================
2022-03-28 20:32:05,027: Epoch 35/45 Batch 5000/7662 eta: 9:55:50.181298	Training Loss 0.4220 (0.4317)	Training Prec@1 93.750 (92.077)	Training Prec@5 95.703 (95.093)	
2022-03-28 20:32:05,027: ============================================================
2022-03-28 20:32:50,164: time cost, forward:0.10931590683999354, backward:0.03394812344335813, data cost:0.2846956737463697 
2022-03-28 20:32:50,165: ============================================================
2022-03-28 20:32:50,165: Epoch 35/45 Batch 5100/7662 eta: 9:55:41.691834	Training Loss 0.4226 (0.4317)	Training Prec@1 92.773 (92.082)	Training Prec@5 95.703 (95.094)	
2022-03-28 20:32:50,165: ============================================================
2022-03-28 20:33:35,361: time cost, forward:0.10929592606378853, backward:0.033925798265354794, data cost:0.285192822373631 
2022-03-28 20:33:35,362: ============================================================
2022-03-28 20:33:35,362: Epoch 35/45 Batch 5200/7662 eta: 9:55:43.237994	Training Loss 0.4384 (0.4317)	Training Prec@1 93.164 (92.081)	Training Prec@5 94.727 (95.092)	
2022-03-28 20:33:35,362: ============================================================
2022-03-28 20:34:20,534: time cost, forward:0.10928044361446371, backward:0.033899697656338115, data cost:0.2856682465422444 
2022-03-28 20:34:20,534: ============================================================
2022-03-28 20:34:20,534: Epoch 35/45 Batch 5300/7662 eta: 9:54:38.610469	Training Loss 0.4274 (0.4317)	Training Prec@1 93.359 (92.080)	Training Prec@5 94.727 (95.090)	
2022-03-28 20:34:20,535: ============================================================
2022-03-28 20:35:05,746: time cost, forward:0.10927355596369605, backward:0.033877011294010766, data cost:0.28612366188983385 
2022-03-28 20:35:05,746: ============================================================
2022-03-28 20:35:05,747: Epoch 35/45 Batch 5400/7662 eta: 9:54:24.680801	Training Loss 0.4325 (0.4318)	Training Prec@1 92.773 (92.084)	Training Prec@5 94.727 (95.092)	
2022-03-28 20:35:05,747: ============================================================
2022-03-28 20:35:50,996: time cost, forward:0.10926157284875548, backward:0.03384939530347126, data cost:0.2865789332895371 
2022-03-28 20:35:50,996: ============================================================
2022-03-28 20:35:50,996: Epoch 35/45 Batch 5500/7662 eta: 9:54:09.192734	Training Loss 0.4264 (0.4318)	Training Prec@1 92.383 (92.084)	Training Prec@5 95.508 (95.091)	
2022-03-28 20:35:50,997: ============================================================
2022-03-28 20:36:36,393: time cost, forward:0.10925428065514432, backward:0.03381550297138414, data cost:0.2870471149624448 
2022-03-28 20:36:36,393: ============================================================
2022-03-28 20:36:36,394: Epoch 35/45 Batch 5600/7662 eta: 9:55:19.866204	Training Loss 0.4301 (0.4318)	Training Prec@1 91.406 (92.085)	Training Prec@5 95.312 (95.093)	
2022-03-28 20:36:36,394: ============================================================
2022-03-28 20:37:21,706: time cost, forward:0.10925608665237387, backward:0.03382438826004566, data cost:0.28743758233393846 
2022-03-28 20:37:21,707: ============================================================
2022-03-28 20:37:21,707: Epoch 35/45 Batch 5700/7662 eta: 9:53:28.483570	Training Loss 0.4181 (0.4318)	Training Prec@1 93.359 (92.087)	Training Prec@5 96.289 (95.092)	
2022-03-28 20:37:21,707: ============================================================
2022-03-28 20:38:06,982: time cost, forward:0.10925063438961517, backward:0.033862494871439164, data cost:0.2877821664519095 
2022-03-28 20:38:06,983: ============================================================
2022-03-28 20:38:06,983: Epoch 35/45 Batch 5800/7662 eta: 9:52:14.154894	Training Loss 0.4288 (0.4318)	Training Prec@1 92.383 (92.088)	Training Prec@5 94.727 (95.093)	
2022-03-28 20:38:06,983: ============================================================
2022-03-28 20:38:52,238: time cost, forward:0.10924465617076241, backward:0.03390123024090284, data cost:0.2881113729510879 
2022-03-28 20:38:52,238: ============================================================
2022-03-28 20:38:52,238: Epoch 35/45 Batch 5900/7662 eta: 9:51:12.479962	Training Loss 0.4432 (0.4317)	Training Prec@1 89.844 (92.087)	Training Prec@5 94.727 (95.093)	
2022-03-28 20:38:52,239: ============================================================
2022-03-28 20:39:37,503: time cost, forward:0.10923378335215446, backward:0.03389433742185537, data cost:0.28848001360396464 
2022-03-28 20:39:37,504: ============================================================
2022-03-28 20:39:37,504: Epoch 35/45 Batch 6000/7662 eta: 9:50:35.400457	Training Loss 0.4164 (0.4317)	Training Prec@1 94.141 (92.090)	Training Prec@5 95.703 (95.094)	
2022-03-28 20:39:37,504: ============================================================
2022-03-28 20:40:22,765: time cost, forward:0.10922575767049243, backward:0.03389010845315048, data cost:0.2888314565648249 
2022-03-28 20:40:22,765: ============================================================
2022-03-28 20:40:22,765: Epoch 35/45 Batch 6100/7662 eta: 9:49:46.489024	Training Loss 0.4156 (0.4317)	Training Prec@1 92.383 (92.093)	Training Prec@5 95.508 (95.094)	
2022-03-28 20:40:22,765: ============================================================
2022-03-28 20:41:08,110: time cost, forward:0.10921891821374968, backward:0.033890492609574496, data cost:0.28917734791029076 
2022-03-28 20:41:08,111: ============================================================
2022-03-28 20:41:08,111: Epoch 35/45 Batch 6200/7662 eta: 9:50:07.219097	Training Loss 0.4428 (0.4317)	Training Prec@1 92.188 (92.096)	Training Prec@5 95.312 (95.096)	
2022-03-28 20:41:08,111: ============================================================
2022-03-28 20:41:53,463: time cost, forward:0.10921714108678003, backward:0.03387631456290641, data cost:0.2895276738378922 
2022-03-28 20:41:53,464: ============================================================
2022-03-28 20:41:53,464: Epoch 35/45 Batch 6300/7662 eta: 9:49:27.745392	Training Loss 0.4204 (0.4317)	Training Prec@1 92.578 (92.097)	Training Prec@5 95.703 (95.096)	
2022-03-28 20:41:53,464: ============================================================
2022-03-28 20:42:39,996: time cost, forward:0.10990171150073984, backward:0.03387335688457915, data cost:0.2893498874973703 
2022-03-28 20:42:39,996: ============================================================
2022-03-28 20:42:39,997: Epoch 35/45 Batch 6400/7662 eta: 10:04:00.903655	Training Loss 0.4289 (0.4317)	Training Prec@1 91.211 (92.099)	Training Prec@5 94.922 (95.097)	
2022-03-28 20:42:39,997: ============================================================
2022-03-28 20:43:25,253: time cost, forward:0.1098937465147085, backward:0.03384556886250651, data cost:0.2896810346868409 
2022-03-28 20:43:25,253: ============================================================
2022-03-28 20:43:25,253: Epoch 35/45 Batch 6500/7662 eta: 9:46:42.034198	Training Loss 0.4440 (0.4317)	Training Prec@1 91.016 (92.097)	Training Prec@5 94.141 (95.096)	
2022-03-28 20:43:25,253: ============================================================
2022-03-28 20:44:10,481: time cost, forward:0.1099800515091768, backward:0.03382928527870184, data cost:0.289891366869017 
2022-03-28 20:44:10,481: ============================================================
2022-03-28 20:44:10,481: Epoch 35/45 Batch 6600/7662 eta: 9:45:34.298640	Training Loss 0.4336 (0.4317)	Training Prec@1 93.359 (92.097)	Training Prec@5 96.875 (95.096)	
2022-03-28 20:44:10,481: ============================================================
2022-03-28 20:44:55,863: time cost, forward:0.11011009629866422, backward:0.03380958652083492, data cost:0.29007709398253995 
2022-03-28 20:44:55,864: ============================================================
2022-03-28 20:44:55,864: Epoch 35/45 Batch 6700/7662 eta: 9:46:49.379607	Training Loss 0.4435 (0.4317)	Training Prec@1 91.602 (92.098)	Training Prec@5 94.141 (95.097)	
2022-03-28 20:44:55,864: ============================================================
2022-03-28 20:45:41,243: time cost, forward:0.11027110319029568, backward:0.033746182594181495, data cost:0.2902650661653658 
2022-03-28 20:45:41,244: ============================================================
2022-03-28 20:45:41,244: Epoch 35/45 Batch 6800/7662 eta: 9:46:01.954520	Training Loss 0.4362 (0.4317)	Training Prec@1 90.625 (92.095)	Training Prec@5 92.773 (95.094)	
2022-03-28 20:45:41,244: ============================================================
2022-03-28 20:46:26,774: time cost, forward:0.11061249620448957, backward:0.033712574702654215, data cost:0.2902579311011995 
2022-03-28 20:46:26,774: ============================================================
2022-03-28 20:46:26,775: Epoch 35/45 Batch 6900/7662 eta: 9:47:13.007166	Training Loss 0.4369 (0.4317)	Training Prec@1 93.164 (92.094)	Training Prec@5 95.703 (95.094)	
2022-03-28 20:46:26,775: ============================================================
2022-03-28 20:47:13,049: time cost, forward:0.1112850648809423, backward:0.03367502383801542, data cost:0.2900293225611188 
2022-03-28 20:47:13,050: ============================================================
2022-03-28 20:47:13,050: Epoch 35/45 Batch 7000/7662 eta: 9:56:02.806717	Training Loss 0.4293 (0.4318)	Training Prec@1 91.992 (92.095)	Training Prec@5 94.922 (95.093)	
2022-03-28 20:47:13,050: ============================================================
2022-03-28 20:47:58,953: time cost, forward:0.11185786465151677, backward:0.033549469513764835, data cost:0.2899195545407177 
2022-03-28 20:47:58,954: ============================================================
2022-03-28 20:47:58,954: Epoch 35/45 Batch 7100/7662 eta: 9:50:30.183908	Training Loss 0.4307 (0.4317)	Training Prec@1 93.555 (92.097)	Training Prec@5 96.094 (95.094)	
2022-03-28 20:47:58,954: ============================================================
2022-03-28 20:48:45,196: time cost, forward:0.11255042949373945, backward:0.03356970619999679, data cost:0.2895614672641089 
2022-03-28 20:48:45,197: ============================================================
2022-03-28 20:48:45,197: Epoch 35/45 Batch 7200/7662 eta: 9:54:05.233870	Training Loss 0.4226 (0.4318)	Training Prec@1 93.555 (92.097)	Training Prec@5 95.508 (95.094)	
2022-03-28 20:48:45,197: ============================================================
2022-03-28 20:49:31,068: time cost, forward:0.11292035293213258, backward:0.033579761058537175, data cost:0.2894918541334021 
2022-03-28 20:49:31,069: ============================================================
2022-03-28 20:49:31,069: Epoch 35/45 Batch 7300/7662 eta: 9:48:33.774995	Training Loss 0.4210 (0.4318)	Training Prec@1 93.359 (92.100)	Training Prec@5 95.312 (95.095)	
2022-03-28 20:49:31,069: ============================================================
2022-03-28 20:50:18,199: time cost, forward:0.11379980879839183, backward:0.03361594820364148, data cost:0.28905146784807545 
2022-03-28 20:50:18,200: ============================================================
2022-03-28 20:50:18,200: Epoch 35/45 Batch 7400/7662 eta: 10:03:55.780287	Training Loss 0.4328 (0.4318)	Training Prec@1 89.844 (92.099)	Training Prec@5 93.359 (95.095)	
2022-03-28 20:50:18,200: ============================================================
2022-03-28 20:51:03,393: time cost, forward:0.11386026438275469, backward:0.03361708095096273, data cost:0.2891877580760463 
2022-03-28 20:51:03,394: ============================================================
2022-03-28 20:51:03,394: Epoch 35/45 Batch 7500/7662 eta: 9:38:21.376758	Training Loss 0.4456 (0.4318)	Training Prec@1 92.773 (92.092)	Training Prec@5 94.727 (95.089)	
2022-03-28 20:51:03,394: ============================================================
2022-03-28 20:51:48,562: time cost, forward:0.11381716511095491, backward:0.03361371699595611, data cost:0.28942731704064334 
2022-03-28 20:51:48,563: ============================================================
2022-03-28 20:51:48,563: Epoch 35/45 Batch 7600/7662 eta: 9:37:16.634676	Training Loss 0.4203 (0.4318)	Training Prec@1 92.383 (92.095)	Training Prec@5 96.289 (95.091)	
2022-03-28 20:51:48,563: ============================================================
2022-03-28 20:52:18,970: Epoch: 35/45 eta: 9:36:48.178460	Training Loss 0.4295 (0.4318)	Training Prec@1 93.359 (92.097)	Training Prec@5 96.289 (95.093)
2022-03-28 20:52:18,970: ============================================================
2022-03-28 20:52:19,319: Save Checkpoint...
2022-03-28 20:52:19,320: ============================================================
2022-03-28 20:52:21,499: Save done!
2022-03-28 20:52:21,499: ============================================================
2022-03-28 20:53:03,887: time cost, forward:0.10924017790592078, backward:0.03422339998110376, data cost:0.2811764514807499 
2022-03-28 20:53:03,888: ============================================================
2022-03-28 20:53:03,888: Epoch 36/45 Batch 100/7662 eta: 9:00:11.139485	Training Loss 0.4409 (0.4311)	Training Prec@1 90.430 (92.251)	Training Prec@5 93.555 (95.271)	
2022-03-28 20:53:03,888: ============================================================
2022-03-28 20:53:45,849: time cost, forward:0.11067552422758323, backward:0.033262851849273224, data cost:0.2778167197452718 
2022-03-28 20:53:45,849: ============================================================
2022-03-28 20:53:45,850: Epoch 36/45 Batch 200/7662 eta: 8:54:27.505907	Training Loss 0.4282 (0.4314)	Training Prec@1 90.430 (92.178)	Training Prec@5 94.922 (95.176)	
2022-03-28 20:53:45,850: ============================================================
2022-03-28 20:54:31,696: time cost, forward:0.13829085898638568, backward:0.035743456620436445, data cost:0.2602124333780346 
2022-03-28 20:54:31,697: ============================================================
2022-03-28 20:54:31,697: Epoch 36/45 Batch 300/7662 eta: 9:43:10.936638	Training Loss 0.4442 (0.4319)	Training Prec@1 92.969 (92.114)	Training Prec@5 95.898 (95.127)	
2022-03-28 20:54:31,697: ============================================================
2022-03-28 20:55:18,349: time cost, forward:0.16096726336276024, backward:0.03695824630278394, data cost:0.24417278043608318 
2022-03-28 20:55:18,349: ============================================================
2022-03-28 20:55:18,350: Epoch 36/45 Batch 400/7662 eta: 9:52:39.387035	Training Loss 0.4332 (0.4318)	Training Prec@1 92.383 (92.116)	Training Prec@5 95.312 (95.125)	
2022-03-28 20:55:18,350: ============================================================
2022-03-28 20:56:02,633: time cost, forward:0.1663800064690844, backward:0.0371146307201806, data cost:0.238686402479489 
2022-03-28 20:56:02,634: ============================================================
2022-03-28 20:56:02,634: Epoch 36/45 Batch 500/7662 eta: 9:21:49.414505	Training Loss 0.4268 (0.4317)	Training Prec@1 91.602 (92.110)	Training Prec@5 94.531 (95.108)	
2022-03-28 20:56:02,634: ============================================================
2022-03-28 20:56:50,867: time cost, forward:0.17907774866323836, backward:0.039101068881994896, data cost:0.2305825469091858 
2022-03-28 20:56:50,868: ============================================================
2022-03-28 20:56:50,868: Epoch 36/45 Batch 600/7662 eta: 10:11:08.117920	Training Loss 0.4415 (0.4317)	Training Prec@1 90.625 (92.100)	Training Prec@5 93.945 (95.116)	
2022-03-28 20:56:50,868: ============================================================
2022-03-28 20:57:39,737: time cost, forward:0.18964598652972, backward:0.04005289350626977, data cost:0.22456421326840556 
2022-03-28 20:57:39,738: ============================================================
2022-03-28 20:57:39,738: Epoch 36/45 Batch 700/7662 eta: 10:18:22.667189	Training Loss 0.4203 (0.4317)	Training Prec@1 92.383 (92.103)	Training Prec@5 94.336 (95.116)	
2022-03-28 20:57:39,738: ============================================================
2022-03-28 20:58:27,540: time cost, forward:0.19485424367596718, backward:0.04033751929358338, data cost:0.22187531218212447 
2022-03-28 20:58:27,541: ============================================================
2022-03-28 20:58:27,541: Epoch 36/45 Batch 800/7662 eta: 10:04:04.854877	Training Loss 0.4283 (0.4317)	Training Prec@1 92.969 (92.084)	Training Prec@5 95.703 (95.100)	
2022-03-28 20:58:27,542: ============================================================
2022-03-28 20:59:12,702: time cost, forward:0.19762571025080358, backward:0.04060791013503366, data cost:0.21825411269343867 
2022-03-28 20:59:12,702: ============================================================
2022-03-28 20:59:12,703: Epoch 36/45 Batch 900/7662 eta: 9:29:56.623496	Training Loss 0.4457 (0.4317)	Training Prec@1 91.016 (92.080)	Training Prec@5 93.945 (95.092)	
2022-03-28 20:59:12,703: ============================================================
2022-03-28 21:00:00,272: time cost, forward:0.19922013779182932, backward:0.040966518887051113, data cost:0.2181524383174526 
2022-03-28 21:00:00,273: ============================================================
2022-03-28 21:00:00,273: Epoch 36/45 Batch 1000/7662 eta: 9:59:33.056409	Training Loss 0.4284 (0.4318)	Training Prec@1 91.406 (92.095)	Training Prec@5 94.531 (95.097)	
2022-03-28 21:00:00,273: ============================================================
2022-03-28 21:00:47,085: time cost, forward:0.2013180301447583, backward:0.04118487876149283, data cost:0.2166430169175819 
2022-03-28 21:00:47,086: ============================================================
2022-03-28 21:00:47,086: Epoch 36/45 Batch 1100/7662 eta: 9:49:13.593486	Training Loss 0.4188 (0.4317)	Training Prec@1 94.727 (92.109)	Training Prec@5 97.461 (95.100)	
2022-03-28 21:00:47,086: ============================================================
2022-03-28 21:01:33,722: time cost, forward:0.20350224659580107, backward:0.04150403112645344, data cost:0.21467394128851935 
2022-03-28 21:01:33,723: ============================================================
2022-03-28 21:01:33,723: Epoch 36/45 Batch 1200/7662 eta: 9:46:14.052633	Training Loss 0.4294 (0.4318)	Training Prec@1 93.359 (92.105)	Training Prec@5 95.117 (95.100)	
2022-03-28 21:01:33,723: ============================================================
2022-03-28 21:02:23,697: time cost, forward:0.2072792983770921, backward:0.041820293210670524, data cost:0.21361808028011894 
2022-03-28 21:02:23,697: ============================================================
2022-03-28 21:02:23,698: Epoch 36/45 Batch 1300/7662 eta: 10:27:21.547205	Training Loss 0.4399 (0.4317)	Training Prec@1 91.602 (92.102)	Training Prec@5 93.945 (95.094)	
2022-03-28 21:02:23,698: ============================================================
2022-03-28 21:03:12,391: time cost, forward:0.20982797577007914, backward:0.041993329148364116, data cost:0.21257473111919542 
2022-03-28 21:03:12,391: ============================================================
2022-03-28 21:03:12,392: Epoch 36/45 Batch 1400/7662 eta: 10:10:28.004884	Training Loss 0.4192 (0.4316)	Training Prec@1 94.531 (92.105)	Training Prec@5 97.070 (95.097)	
2022-03-28 21:03:12,392: ============================================================
2022-03-28 21:04:01,869: time cost, forward:0.21354307104063638, backward:0.042127389125302284, data cost:0.21070549884106493 
2022-03-28 21:04:01,870: ============================================================
2022-03-28 21:04:01,870: Epoch 36/45 Batch 1500/7662 eta: 10:19:28.625515	Training Loss 0.4233 (0.4316)	Training Prec@1 90.039 (92.106)	Training Prec@5 93.945 (95.101)	
2022-03-28 21:04:01,870: ============================================================
2022-03-28 21:04:50,250: time cost, forward:0.21675014764238254, backward:0.0422554736289477, data cost:0.20839575441872202 
2022-03-28 21:04:50,251: ============================================================
2022-03-28 21:04:50,252: Epoch 36/45 Batch 1600/7662 eta: 10:04:56.271347	Training Loss 0.4251 (0.4315)	Training Prec@1 93.945 (92.116)	Training Prec@5 97.070 (95.104)	
2022-03-28 21:04:50,252: ============================================================
2022-03-28 21:05:38,998: time cost, forward:0.2191654791054549, backward:0.04240323361963157, data cost:0.20696436790524686 
2022-03-28 21:05:38,998: ============================================================
2022-03-28 21:05:38,998: Epoch 36/45 Batch 1700/7662 eta: 10:08:41.663403	Training Loss 0.4295 (0.4314)	Training Prec@1 91.406 (92.108)	Training Prec@5 94.141 (95.099)	
2022-03-28 21:05:38,998: ============================================================
2022-03-28 21:06:28,334: time cost, forward:0.22105155407289057, backward:0.042519902175767614, data cost:0.2062914916182174 
2022-03-28 21:06:28,334: ============================================================
2022-03-28 21:06:28,335: Epoch 36/45 Batch 1800/7662 eta: 10:15:13.994468	Training Loss 0.4291 (0.4315)	Training Prec@1 91.406 (92.106)	Training Prec@5 95.312 (95.094)	
2022-03-28 21:06:28,335: ============================================================
2022-03-28 21:07:15,066: time cost, forward:0.22113864053984325, backward:0.04260427629150423, data cost:0.20594624684571342 
2022-03-28 21:07:15,067: ============================================================
2022-03-28 21:07:15,067: Epoch 36/45 Batch 1900/7662 eta: 9:41:58.807711	Training Loss 0.4209 (0.4314)	Training Prec@1 92.773 (92.106)	Training Prec@5 96.484 (95.094)	
2022-03-28 21:07:15,067: ============================================================
2022-03-28 21:07:59,351: time cost, forward:0.21988300802470326, backward:0.0425168214409634, data cost:0.20590758920014055 
2022-03-28 21:07:59,352: ============================================================
2022-03-28 21:07:59,352: Epoch 36/45 Batch 2000/7662 eta: 9:10:45.789469	Training Loss 0.4362 (0.4316)	Training Prec@1 91.992 (92.091)	Training Prec@5 95.117 (95.091)	
2022-03-28 21:07:59,352: ============================================================
2022-03-28 21:08:43,696: time cost, forward:0.21851545313871037, backward:0.04234805238877324, data cost:0.20621063392352013 
2022-03-28 21:08:43,696: ============================================================
2022-03-28 21:08:43,697: Epoch 36/45 Batch 2100/7662 eta: 9:10:46.233178	Training Loss 0.4374 (0.4316)	Training Prec@1 92.578 (92.092)	Training Prec@5 95.312 (95.090)	
2022-03-28 21:08:43,697: ============================================================
2022-03-28 21:09:30,269: time cost, forward:0.2177050004172401, backward:0.042242311032699854, data cost:0.2070423071359493 
2022-03-28 21:09:30,270: ============================================================
2022-03-28 21:09:30,270: Epoch 36/45 Batch 2200/7662 eta: 9:37:40.337864	Training Loss 0.4270 (0.4316)	Training Prec@1 92.969 (92.093)	Training Prec@5 96.289 (95.093)	
2022-03-28 21:09:30,270: ============================================================
2022-03-28 21:10:17,021: time cost, forward:0.2170945715520526, backward:0.042114476941885665, data cost:0.2078121132620421 
2022-03-28 21:10:17,021: ============================================================
2022-03-28 21:10:17,022: Epoch 36/45 Batch 2300/7662 eta: 9:39:06.330724	Training Loss 0.4388 (0.4316)	Training Prec@1 93.359 (92.101)	Training Prec@5 97.070 (95.096)	
2022-03-28 21:10:17,022: ============================================================
2022-03-28 21:11:03,480: time cost, forward:0.216546273817863, backward:0.04201890687835172, data cost:0.20831396660242243 
2022-03-28 21:11:03,481: ============================================================
2022-03-28 21:11:03,481: Epoch 36/45 Batch 2400/7662 eta: 9:34:42.550359	Training Loss 0.4279 (0.4316)	Training Prec@1 91.602 (92.104)	Training Prec@5 94.922 (95.097)	
2022-03-28 21:11:03,481: ============================================================
2022-03-28 21:11:49,404: time cost, forward:0.2159991994196055, backward:0.04194297195196438, data cost:0.20862884300143397 
2022-03-28 21:11:49,404: ============================================================
2022-03-28 21:11:49,404: Epoch 36/45 Batch 2500/7662 eta: 9:27:18.718027	Training Loss 0.4384 (0.4317)	Training Prec@1 92.969 (92.100)	Training Prec@5 95.508 (95.092)	
2022-03-28 21:11:49,405: ============================================================
2022-03-28 21:12:35,736: time cost, forward:0.21583343708042732, backward:0.04186056136351083, data cost:0.20871462781597167 
2022-03-28 21:12:35,737: ============================================================
2022-03-28 21:12:35,737: Epoch 36/45 Batch 2600/7662 eta: 9:31:35.904406	Training Loss 0.4347 (0.4317)	Training Prec@1 91.406 (92.093)	Training Prec@5 94.727 (95.085)	
2022-03-28 21:12:35,737: ============================================================
2022-03-28 21:13:21,521: time cost, forward:0.2150478401021544, backward:0.04175575541849267, data cost:0.20923111367199146 
2022-03-28 21:13:21,522: ============================================================
2022-03-28 21:13:21,523: Epoch 36/45 Batch 2700/7662 eta: 9:24:05.044328	Training Loss 0.4331 (0.4317)	Training Prec@1 91.797 (92.091)	Training Prec@5 95.508 (95.085)	
2022-03-28 21:13:21,523: ============================================================
2022-03-28 21:14:05,733: time cost, forward:0.21424921029974367, backward:0.0416434158721793, data cost:0.2093166199357393 
2022-03-28 21:14:05,733: ============================================================
2022-03-28 21:14:05,733: Epoch 36/45 Batch 2800/7662 eta: 9:03:56.908475	Training Loss 0.4231 (0.4316)	Training Prec@1 90.625 (92.096)	Training Prec@5 94.141 (95.087)	
2022-03-28 21:14:05,734: ============================================================
2022-03-28 21:14:50,451: time cost, forward:0.21349805311812908, backward:0.041561425410701965, data cost:0.20951288443016322 
2022-03-28 21:14:50,452: ============================================================
2022-03-28 21:14:50,452: Epoch 36/45 Batch 2900/7662 eta: 9:09:27.024969	Training Loss 0.4198 (0.4316)	Training Prec@1 93.359 (92.100)	Training Prec@5 96.094 (95.087)	
2022-03-28 21:14:50,452: ============================================================
2022-03-28 21:15:36,013: time cost, forward:0.21281328873858527, backward:0.04142118215799411, data cost:0.21002992314869423 
2022-03-28 21:15:36,014: ============================================================
2022-03-28 21:15:36,014: Epoch 36/45 Batch 3000/7662 eta: 9:19:03.347313	Training Loss 0.4262 (0.4316)	Training Prec@1 92.188 (92.106)	Training Prec@5 95.703 (95.092)	
2022-03-28 21:15:36,014: ============================================================
2022-03-28 21:16:22,229: time cost, forward:0.21212937878808424, backward:0.04138022101513991, data cost:0.21067918743307107 
2022-03-28 21:16:22,229: ============================================================
2022-03-28 21:16:22,229: Epoch 36/45 Batch 3100/7662 eta: 9:26:17.797748	Training Loss 0.4311 (0.4316)	Training Prec@1 91.406 (92.113)	Training Prec@5 94.531 (95.097)	
2022-03-28 21:16:22,229: ============================================================
2022-03-28 21:17:07,924: time cost, forward:0.21193693883346743, backward:0.041410904893579986, data cost:0.21061673459502897 
2022-03-28 21:17:07,924: ============================================================
2022-03-28 21:17:07,925: Epoch 36/45 Batch 3200/7662 eta: 9:19:09.942262	Training Loss 0.4189 (0.4316)	Training Prec@1 93.750 (92.112)	Training Prec@5 95.898 (95.094)	
2022-03-28 21:17:07,925: ============================================================
2022-03-28 21:17:55,743: time cost, forward:0.21178482047858907, backward:0.04139867541500206, data cost:0.21118043407811363 
2022-03-28 21:17:55,743: ============================================================
2022-03-28 21:17:55,744: Epoch 36/45 Batch 3300/7662 eta: 9:44:21.641699	Training Loss 0.4216 (0.4316)	Training Prec@1 93.359 (92.115)	Training Prec@5 95.508 (95.095)	
2022-03-28 21:17:55,744: ============================================================
2022-03-28 21:18:41,043: time cost, forward:0.21110316128126136, backward:0.041277657119131464, data cost:0.21163511128943258 
2022-03-28 21:18:41,043: ============================================================
2022-03-28 21:18:41,044: Epoch 36/45 Batch 3400/7662 eta: 9:12:48.806416	Training Loss 0.4278 (0.4316)	Training Prec@1 91.602 (92.110)	Training Prec@5 95.312 (95.095)	
2022-03-28 21:18:41,044: ============================================================
2022-03-28 21:19:29,046: time cost, forward:0.21049999359438304, backward:0.041201760749130054, data cost:0.2127721101837725 
2022-03-28 21:19:29,046: ============================================================
2022-03-28 21:19:29,047: Epoch 36/45 Batch 3500/7662 eta: 9:45:00.272251	Training Loss 0.4387 (0.4316)	Training Prec@1 92.969 (92.106)	Training Prec@5 96.875 (95.096)	
2022-03-28 21:19:29,047: ============================================================
2022-03-28 21:20:15,275: time cost, forward:0.20983416969890759, backward:0.04114852205982934, data cost:0.21341020506466385 
2022-03-28 21:20:15,276: ============================================================
2022-03-28 21:20:15,276: Epoch 36/45 Batch 3600/7662 eta: 9:22:37.269524	Training Loss 0.4341 (0.4316)	Training Prec@1 92.578 (92.105)	Training Prec@5 95.508 (95.098)	
2022-03-28 21:20:15,276: ============================================================
2022-03-28 21:21:02,261: time cost, forward:0.209382000598562, backward:0.041149280044832044, data cost:0.2140062933646205 
2022-03-28 21:21:02,262: ============================================================
2022-03-28 21:21:02,262: Epoch 36/45 Batch 3700/7662 eta: 9:31:02.534189	Training Loss 0.4374 (0.4316)	Training Prec@1 91.211 (92.105)	Training Prec@5 95.312 (95.098)	
2022-03-28 21:21:02,262: ============================================================
2022-03-28 21:21:48,048: time cost, forward:0.20886899157868274, backward:0.04111998022842106, data cost:0.214328839233531 
2022-03-28 21:21:48,049: ============================================================
2022-03-28 21:21:48,049: Epoch 36/45 Batch 3800/7662 eta: 9:15:42.504871	Training Loss 0.4293 (0.4315)	Training Prec@1 93.164 (92.110)	Training Prec@5 95.898 (95.102)	
2022-03-28 21:21:48,049: ============================================================
2022-03-28 21:22:36,008: time cost, forward:0.2088584166118566, backward:0.04114011294660155, data cost:0.21471101897103445 
2022-03-28 21:22:36,008: ============================================================
2022-03-28 21:22:36,008: Epoch 36/45 Batch 3900/7662 eta: 9:41:16.538585	Training Loss 0.4351 (0.4315)	Training Prec@1 93.359 (92.108)	Training Prec@5 97.070 (95.104)	
2022-03-28 21:22:36,008: ============================================================
2022-03-28 21:23:23,064: time cost, forward:0.20843355475022932, backward:0.041105605149513544, data cost:0.2153215824469652 
2022-03-28 21:23:23,064: ============================================================
2022-03-28 21:23:23,065: Epoch 36/45 Batch 4000/7662 eta: 9:29:32.820497	Training Loss 0.4190 (0.4315)	Training Prec@1 95.703 (92.107)	Training Prec@5 96.875 (95.102)	
2022-03-28 21:23:23,065: ============================================================
2022-03-28 21:24:09,211: time cost, forward:0.20795258652090765, backward:0.04105195134812723, data cost:0.21577183576175776 
2022-03-28 21:24:09,211: ============================================================
2022-03-28 21:24:09,211: Epoch 36/45 Batch 4100/7662 eta: 9:17:45.997405	Training Loss 0.4392 (0.4315)	Training Prec@1 90.625 (92.105)	Training Prec@5 94.141 (95.103)	
2022-03-28 21:24:09,212: ============================================================
2022-03-28 21:24:56,941: time cost, forward:0.20767117307480815, backward:0.04100987263366307, data cost:0.21637075785995524 
2022-03-28 21:24:56,942: ============================================================
2022-03-28 21:24:56,942: Epoch 36/45 Batch 4200/7662 eta: 9:36:07.190463	Training Loss 0.4336 (0.4315)	Training Prec@1 92.188 (92.104)	Training Prec@5 96.094 (95.101)	
2022-03-28 21:24:56,942: ============================================================
2022-03-28 21:25:42,776: time cost, forward:0.20755252568603644, backward:0.041028096803983276, data cost:0.21629606321485245 
2022-03-28 21:25:42,776: ============================================================
2022-03-28 21:25:42,776: Epoch 36/45 Batch 4300/7662 eta: 9:12:27.552043	Training Loss 0.4241 (0.4315)	Training Prec@1 93.750 (92.105)	Training Prec@5 96.094 (95.102)	
2022-03-28 21:25:42,776: ============================================================
2022-03-28 21:26:26,721: time cost, forward:0.20714134957525346, backward:0.04099692840905698, data cost:0.21615765121314276 
2022-03-28 21:26:26,722: ============================================================
2022-03-28 21:26:26,722: Epoch 36/45 Batch 4400/7662 eta: 8:48:57.966436	Training Loss 0.4279 (0.4315)	Training Prec@1 91.992 (92.110)	Training Prec@5 95.508 (95.106)	
2022-03-28 21:26:26,722: ============================================================
2022-03-28 21:27:12,259: time cost, forward:0.2070675672067751, backward:0.040992194479056054, data cost:0.21602088940305217 
2022-03-28 21:27:12,259: ============================================================
2022-03-28 21:27:12,259: Epoch 36/45 Batch 4500/7662 eta: 9:07:22.129194	Training Loss 0.4237 (0.4316)	Training Prec@1 92.969 (92.113)	Training Prec@5 96.680 (95.106)	
2022-03-28 21:27:12,260: ============================================================
2022-03-28 21:28:00,039: time cost, forward:0.20662272865550885, backward:0.04094029810408401, data cost:0.2168135274931461 
2022-03-28 21:28:00,039: ============================================================
2022-03-28 21:28:00,039: Epoch 36/45 Batch 4600/7662 eta: 9:33:31.598750	Training Loss 0.4335 (0.4316)	Training Prec@1 91.211 (92.110)	Training Prec@5 94.727 (95.103)	
2022-03-28 21:28:00,040: ============================================================
2022-03-28 21:28:44,895: time cost, forward:0.20624238233612963, backward:0.04091230639246429, data cost:0.21685883627974953 
2022-03-28 21:28:44,896: ============================================================
2022-03-28 21:28:44,896: Epoch 36/45 Batch 4700/7662 eta: 8:57:41.452326	Training Loss 0.4295 (0.4316)	Training Prec@1 93.945 (92.110)	Training Prec@5 96.094 (95.102)	
2022-03-28 21:28:44,896: ============================================================
2022-03-28 21:29:31,972: time cost, forward:0.2062051057765871, backward:0.04091284448441229, data cost:0.2170502159788748 
2022-03-28 21:29:31,972: ============================================================
2022-03-28 21:29:31,973: Epoch 36/45 Batch 4800/7662 eta: 9:23:30.873467	Training Loss 0.4365 (0.4316)	Training Prec@1 91.797 (92.107)	Training Prec@5 94.727 (95.101)	
2022-03-28 21:29:31,973: ============================================================
2022-03-28 21:30:17,786: time cost, forward:0.2060701219274891, backward:0.040909746808162825, data cost:0.2170254109610974 
2022-03-28 21:30:17,787: ============================================================
2022-03-28 21:30:17,787: Epoch 36/45 Batch 4900/7662 eta: 9:07:38.618809	Training Loss 0.4184 (0.4316)	Training Prec@1 94.531 (92.107)	Training Prec@5 95.898 (95.099)	
2022-03-28 21:30:17,788: ============================================================
2022-03-28 21:31:03,999: time cost, forward:0.2057145707820458, backward:0.040866641908627696, data cost:0.2174016695829553 
2022-03-28 21:31:03,999: ============================================================
2022-03-28 21:31:04,000: Epoch 36/45 Batch 5000/7662 eta: 9:11:37.869720	Training Loss 0.4195 (0.4316)	Training Prec@1 92.578 (92.108)	Training Prec@5 95.508 (95.100)	
2022-03-28 21:31:04,000: ============================================================
2022-03-28 21:31:48,882: time cost, forward:0.20549041959766687, backward:0.0408733476024208, data cost:0.21732415795723675 
2022-03-28 21:31:48,882: ============================================================
2022-03-28 21:31:48,883: Epoch 36/45 Batch 5100/7662 eta: 8:55:00.751770	Training Loss 0.4397 (0.4316)	Training Prec@1 93.164 (92.107)	Training Prec@5 95.703 (95.098)	
2022-03-28 21:31:48,883: ============================================================
2022-03-28 21:32:35,357: time cost, forward:0.20536321409621314, backward:0.040861773431289654, data cost:0.21747173169732759 
2022-03-28 21:32:35,358: ============================================================
2022-03-28 21:32:35,358: Epoch 36/45 Batch 5200/7662 eta: 9:13:13.137858	Training Loss 0.4370 (0.4316)	Training Prec@1 92.969 (92.105)	Training Prec@5 95.117 (95.096)	
2022-03-28 21:32:35,358: ============================================================
2022-03-28 21:33:22,166: time cost, forward:0.20515134726454343, backward:0.040822484039274964, data cost:0.21778968136858143 
2022-03-28 21:33:22,166: ============================================================
2022-03-28 21:33:22,167: Epoch 36/45 Batch 5300/7662 eta: 9:16:24.374493	Training Loss 0.4386 (0.4316)	Training Prec@1 89.062 (92.106)	Training Prec@5 94.336 (95.096)	
2022-03-28 21:33:22,167: ============================================================
2022-03-28 21:34:08,964: time cost, forward:0.20495081623520403, backward:0.0407853530587742, data cost:0.21809832143174165 
2022-03-28 21:34:08,965: ============================================================
2022-03-28 21:34:08,966: Epoch 36/45 Batch 5400/7662 eta: 9:15:30.789333	Training Loss 0.4399 (0.4316)	Training Prec@1 89.648 (92.102)	Training Prec@5 93.945 (95.096)	
2022-03-28 21:34:08,966: ============================================================
2022-03-28 21:34:55,474: time cost, forward:0.2048188884337613, backward:0.040761628743192675, data cost:0.21826006933046832 
2022-03-28 21:34:55,474: ============================================================
2022-03-28 21:34:55,475: Epoch 36/45 Batch 5500/7662 eta: 9:11:17.468052	Training Loss 0.4237 (0.4316)	Training Prec@1 94.336 (92.100)	Training Prec@5 97.070 (95.095)	
2022-03-28 21:34:55,475: ============================================================
2022-03-28 21:35:41,586: time cost, forward:0.20458361876396264, backward:0.040719094372664334, data cost:0.21849539701928836 
2022-03-28 21:35:41,587: ============================================================
2022-03-28 21:35:41,587: Epoch 36/45 Batch 5600/7662 eta: 9:05:49.545214	Training Loss 0.4304 (0.4316)	Training Prec@1 91.211 (92.099)	Training Prec@5 95.117 (95.093)	
2022-03-28 21:35:41,587: ============================================================
2022-03-28 21:36:26,052: time cost, forward:0.2043764080828084, backward:0.04069470547650818, data cost:0.21838986076666903 
2022-03-28 21:36:26,052: ============================================================
2022-03-28 21:36:26,052: Epoch 36/45 Batch 5700/7662 eta: 8:45:35.255594	Training Loss 0.4335 (0.4316)	Training Prec@1 93.945 (92.100)	Training Prec@5 96.289 (95.095)	
2022-03-28 21:36:26,053: ============================================================
2022-03-28 21:37:13,359: time cost, forward:0.2044502207073061, backward:0.040713082759375, data cost:0.21845543485280666 
2022-03-28 21:37:13,359: ============================================================
2022-03-28 21:37:13,359: Epoch 36/45 Batch 5800/7662 eta: 9:18:23.172050	Training Loss 0.4303 (0.4316)	Training Prec@1 94.141 (92.102)	Training Prec@5 96.680 (95.098)	
2022-03-28 21:37:13,359: ============================================================
2022-03-28 21:37:58,880: time cost, forward:0.2044957050288566, backward:0.040726469379094604, data cost:0.21822785983592458 
2022-03-28 21:37:58,881: ============================================================
2022-03-28 21:37:58,881: Epoch 36/45 Batch 5900/7662 eta: 8:56:33.281507	Training Loss 0.4343 (0.4316)	Training Prec@1 93.750 (92.105)	Training Prec@5 95.898 (95.101)	
2022-03-28 21:37:58,881: ============================================================
2022-03-28 21:38:44,908: time cost, forward:0.20437943237903694, backward:0.04070223186548242, data cost:0.218322383063816 
2022-03-28 21:38:44,908: ============================================================
2022-03-28 21:38:44,908: Epoch 36/45 Batch 6000/7662 eta: 9:01:45.123481	Training Loss 0.4331 (0.4316)	Training Prec@1 93.750 (92.103)	Training Prec@5 95.898 (95.101)	
2022-03-28 21:38:44,909: ============================================================
2022-03-28 21:39:30,568: time cost, forward:0.2041867412217505, backward:0.040677784544304756, data cost:0.2184126716810165 
2022-03-28 21:39:30,569: ============================================================
2022-03-28 21:39:30,569: Epoch 36/45 Batch 6100/7662 eta: 8:56:40.390712	Training Loss 0.4303 (0.4316)	Training Prec@1 94.531 (92.103)	Training Prec@5 96.094 (95.102)	
2022-03-28 21:39:30,569: ============================================================
2022-03-28 21:40:16,876: time cost, forward:0.20404016858128737, backward:0.040644162315421575, data cost:0.2185943303213598 
2022-03-28 21:40:16,876: ============================================================
2022-03-28 21:40:16,877: Epoch 36/45 Batch 6200/7662 eta: 9:03:30.229847	Training Loss 0.4319 (0.4317)	Training Prec@1 90.234 (92.102)	Training Prec@5 92.773 (95.101)	
2022-03-28 21:40:16,877: ============================================================
2022-03-28 21:41:02,131: time cost, forward:0.20383555477697674, backward:0.04064956864282657, data cost:0.2185924035402532 
2022-03-28 21:41:02,132: ============================================================
2022-03-28 21:41:02,132: Epoch 36/45 Batch 6300/7662 eta: 8:50:24.146197	Training Loss 0.4322 (0.4317)	Training Prec@1 91.016 (92.100)	Training Prec@5 93.945 (95.098)	
2022-03-28 21:41:02,133: ============================================================
2022-03-28 21:41:47,769: time cost, forward:0.20365477819184918, backward:0.04063260292593325, data cost:0.2186828982291659 
2022-03-28 21:41:47,769: ============================================================
2022-03-28 21:41:47,770: Epoch 36/45 Batch 6400/7662 eta: 8:54:07.058180	Training Loss 0.4376 (0.4317)	Training Prec@1 91.406 (92.099)	Training Prec@5 94.531 (95.098)	
2022-03-28 21:41:47,770: ============================================================
2022-03-28 21:42:34,238: time cost, forward:0.20369444107675502, backward:0.04063710346095726, data cost:0.21866682203462773 
2022-03-28 21:42:34,239: ============================================================
2022-03-28 21:42:34,239: Epoch 36/45 Batch 6500/7662 eta: 9:03:04.702433	Training Loss 0.4210 (0.4316)	Training Prec@1 94.531 (92.100)	Training Prec@5 96.875 (95.100)	
2022-03-28 21:42:34,239: ============================================================
2022-03-28 21:43:20,761: time cost, forward:0.20350194465104224, backward:0.040619193757911724, data cost:0.21891627699737387 
2022-03-28 21:43:20,762: ============================================================
2022-03-28 21:43:20,762: Epoch 36/45 Batch 6600/7662 eta: 9:02:56.082517	Training Loss 0.4417 (0.4317)	Training Prec@1 91.211 (92.103)	Training Prec@5 94.531 (95.100)	
2022-03-28 21:43:20,762: ============================================================
2022-03-28 21:44:08,581: time cost, forward:0.203351344398855, backward:0.04059470335144234, data cost:0.2192985441706433 
2022-03-28 21:44:08,581: ============================================================
2022-03-28 21:44:08,582: Epoch 36/45 Batch 6700/7662 eta: 9:17:15.746545	Training Loss 0.4264 (0.4317)	Training Prec@1 92.383 (92.106)	Training Prec@5 95.117 (95.103)	
2022-03-28 21:44:08,582: ============================================================
2022-03-28 21:44:54,128: time cost, forward:0.2031885699535717, backward:0.04057975112734375, data cost:0.2193601339735482 
2022-03-28 21:44:54,129: ============================================================
2022-03-28 21:44:54,129: Epoch 36/45 Batch 6800/7662 eta: 8:50:01.837260	Training Loss 0.4269 (0.4317)	Training Prec@1 92.188 (92.108)	Training Prec@5 94.922 (95.104)	
2022-03-28 21:44:54,129: ============================================================
2022-03-28 21:45:40,110: time cost, forward:0.202979782212038, backward:0.040563987327461776, data cost:0.21953622806519768 
2022-03-28 21:45:40,110: ============================================================
2022-03-28 21:45:40,110: Epoch 36/45 Batch 6900/7662 eta: 8:54:18.512543	Training Loss 0.4210 (0.4316)	Training Prec@1 92.578 (92.109)	Training Prec@5 95.898 (95.104)	
2022-03-28 21:45:40,111: ============================================================
2022-03-28 21:46:28,162: time cost, forward:0.20281817756698614, backward:0.0405458816035609, data cost:0.2199160543096493 
2022-03-28 21:46:28,162: ============================================================
2022-03-28 21:46:28,163: Epoch 36/45 Batch 7000/7662 eta: 9:17:34.395161	Training Loss 0.4268 (0.4317)	Training Prec@1 92.773 (92.109)	Training Prec@5 94.922 (95.104)	
2022-03-28 21:46:28,163: ============================================================
2022-03-28 21:47:13,920: time cost, forward:0.20262994546590682, backward:0.04053307842378768, data cost:0.22007164197465806 
2022-03-28 21:47:13,921: ============================================================
2022-03-28 21:47:13,921: Epoch 36/45 Batch 7100/7662 eta: 8:50:11.731549	Training Loss 0.4379 (0.4316)	Training Prec@1 90.625 (92.107)	Training Prec@5 93.750 (95.102)	
2022-03-28 21:47:13,921: ============================================================
2022-03-28 21:48:00,302: time cost, forward:0.20246640379717987, backward:0.040536076745352395, data cost:0.22023487607709796 
2022-03-28 21:48:00,302: ============================================================
2022-03-28 21:48:00,303: Epoch 36/45 Batch 7200/7662 eta: 8:56:38.524622	Training Loss 0.4250 (0.4316)	Training Prec@1 95.117 (92.106)	Training Prec@5 96.289 (95.101)	
2022-03-28 21:48:00,303: ============================================================
2022-03-28 21:48:46,032: time cost, forward:0.2022856449587637, backward:0.04051483440177051, data cost:0.22033634269412275 
2022-03-28 21:48:46,032: ============================================================
2022-03-28 21:48:46,032: Epoch 36/45 Batch 7300/7662 eta: 8:48:20.411503	Training Loss 0.4360 (0.4317)	Training Prec@1 91.797 (92.106)	Training Prec@5 96.484 (95.102)	
2022-03-28 21:48:46,033: ============================================================
2022-03-28 21:49:32,005: time cost, forward:0.20214997038420415, backward:0.04051140141271227, data cost:0.2204374105064494 
2022-03-28 21:49:32,005: ============================================================
2022-03-28 21:49:32,005: Epoch 36/45 Batch 7400/7662 eta: 8:50:22.993964	Training Loss 0.4407 (0.4317)	Training Prec@1 89.258 (92.106)	Training Prec@5 92.773 (95.101)	
2022-03-28 21:49:32,006: ============================================================
2022-03-28 21:50:18,108: time cost, forward:0.20202851769192598, backward:0.04050365093946934, data cost:0.22053368830143538 
2022-03-28 21:50:18,109: ============================================================
2022-03-28 21:50:18,109: Epoch 36/45 Batch 7500/7662 eta: 8:51:07.143798	Training Loss 0.4352 (0.4317)	Training Prec@1 90.820 (92.106)	Training Prec@5 94.922 (95.100)	
2022-03-28 21:50:18,109: ============================================================
2022-03-28 21:51:03,973: time cost, forward:0.2018137565803051, backward:0.040490300518256264, data cost:0.22068683773863548 
2022-03-28 21:51:03,974: ============================================================
2022-03-28 21:51:03,974: Epoch 36/45 Batch 7600/7662 eta: 8:47:36.678140	Training Loss 0.4325 (0.4317)	Training Prec@1 92.773 (92.105)	Training Prec@5 95.703 (95.099)	
2022-03-28 21:51:03,974: ============================================================
2022-03-28 21:51:32,899: Epoch: 36/45 eta: 8:47:07.783011	Training Loss 0.4387 (0.4317)	Training Prec@1 91.602 (92.103)	Training Prec@5 93.359 (95.098)
2022-03-28 21:51:32,900: ============================================================
2022-03-28 21:51:32,990: Save Checkpoint...
2022-03-28 21:51:32,990: ============================================================
2022-03-28 21:51:35,469: Save done!
2022-03-28 21:51:35,469: ============================================================
2022-03-28 21:52:29,028: time cost, forward:0.2647196138748015, backward:0.04227232451390738, data cost:0.2307185476476496 
2022-03-28 21:52:29,028: ============================================================
2022-03-28 21:52:29,029: Epoch 37/45 Batch 100/7662 eta: 10:14:13.484050	Training Loss 0.4405 (0.4310)	Training Prec@1 91.016 (92.134)	Training Prec@5 93.750 (95.131)	
2022-03-28 21:52:29,029: ============================================================
2022-03-28 21:53:15,027: time cost, forward:0.23006014488450247, backward:0.040069987426451105, data cost:0.22839530388913562 
2022-03-28 21:53:15,028: ============================================================
2022-03-28 21:53:15,028: Epoch 37/45 Batch 200/7662 eta: 8:47:08.498525	Training Loss 0.4185 (0.4312)	Training Prec@1 92.188 (92.215)	Training Prec@5 94.531 (95.190)	
2022-03-28 21:53:15,028: ============================================================
2022-03-28 21:54:00,650: time cost, forward:0.21901663330486387, backward:0.039351444180593845, data cost:0.22580555051465498 
2022-03-28 21:54:00,650: ============================================================
2022-03-28 21:54:00,651: Epoch 37/45 Batch 300/7662 eta: 8:42:04.111021	Training Loss 0.4341 (0.4313)	Training Prec@1 90.820 (92.178)	Training Prec@5 93.555 (95.134)	
2022-03-28 21:54:00,651: ============================================================
2022-03-28 21:54:48,240: time cost, forward:0.21376632927055644, backward:0.038915095771464486, data cost:0.22924659126683286 
2022-03-28 21:54:48,241: ============================================================
2022-03-28 21:54:48,241: Epoch 37/45 Batch 400/7662 eta: 9:03:47.515726	Training Loss 0.4304 (0.4314)	Training Prec@1 91.797 (92.155)	Training Prec@5 94.922 (95.124)	
2022-03-28 21:54:48,241: ============================================================
2022-03-28 21:55:34,966: time cost, forward:0.21169087690915278, backward:0.03884048882371677, data cost:0.2283785945189023 
2022-03-28 21:55:34,966: ============================================================
2022-03-28 21:55:34,967: Epoch 37/45 Batch 500/7662 eta: 8:53:07.961585	Training Loss 0.4374 (0.4314)	Training Prec@1 90.625 (92.137)	Training Prec@5 94.336 (95.095)	
2022-03-28 21:55:34,967: ============================================================
2022-03-28 21:56:21,475: time cost, forward:0.20989202418192002, backward:0.03884517688783063, data cost:0.22781066504464126 
2022-03-28 21:56:21,476: ============================================================
2022-03-28 21:56:21,476: Epoch 37/45 Batch 600/7662 eta: 8:49:53.198343	Training Loss 0.4327 (0.4314)	Training Prec@1 93.359 (92.146)	Training Prec@5 95.898 (95.097)	
2022-03-28 21:56:21,476: ============================================================
2022-03-28 21:57:07,192: time cost, forward:0.20864720644698465, backward:0.038972531947625726, data cost:0.22594774502711917 
2022-03-28 21:57:07,192: ============================================================
2022-03-28 21:57:07,193: Epoch 37/45 Batch 700/7662 eta: 8:40:05.790460	Training Loss 0.4366 (0.4315)	Training Prec@1 91.797 (92.131)	Training Prec@5 95.117 (95.099)	
2022-03-28 21:57:07,193: ============================================================
2022-03-28 21:57:51,710: time cost, forward:0.2079836239056832, backward:0.03894590137897057, data cost:0.2231269103564667 
2022-03-28 21:57:51,711: ============================================================
2022-03-28 21:57:51,711: Epoch 37/45 Batch 800/7662 eta: 8:25:43.394539	Training Loss 0.4314 (0.4315)	Training Prec@1 90.234 (92.116)	Training Prec@5 94.141 (95.103)	
2022-03-28 21:57:51,711: ============================================================
2022-03-28 21:58:38,480: time cost, forward:0.2075271643573901, backward:0.039012508211995124, data cost:0.22321407813516686 
2022-03-28 21:58:38,481: ============================================================
2022-03-28 21:58:38,481: Epoch 37/45 Batch 900/7662 eta: 8:50:30.810043	Training Loss 0.4358 (0.4316)	Training Prec@1 92.773 (92.121)	Training Prec@5 94.336 (95.103)	
2022-03-28 21:58:38,481: ============================================================
2022-03-28 21:59:24,088: time cost, forward:0.2075061094056856, backward:0.03892049608049211, data cost:0.22191668606854537 
2022-03-28 21:59:24,089: ============================================================
2022-03-28 21:59:24,089: Epoch 37/45 Batch 1000/7662 eta: 8:36:34.817224	Training Loss 0.4291 (0.4317)	Training Prec@1 92.383 (92.124)	Training Prec@5 95.703 (95.105)	
2022-03-28 21:59:24,089: ============================================================
2022-03-28 22:00:10,249: time cost, forward:0.20787862021886186, backward:0.038983957457260396, data cost:0.22083581828116502 
2022-03-28 22:00:10,250: ============================================================
2022-03-28 22:00:10,250: Epoch 37/45 Batch 1100/7662 eta: 8:42:04.674349	Training Loss 0.4210 (0.4317)	Training Prec@1 94.531 (92.125)	Training Prec@5 96.680 (95.105)	
2022-03-28 22:00:10,250: ============================================================
2022-03-28 22:00:57,261: time cost, forward:0.20870674044216941, backward:0.039082928634465386, data cost:0.22006543583428492 
2022-03-28 22:00:57,261: ============================================================
2022-03-28 22:00:57,261: Epoch 37/45 Batch 1200/7662 eta: 8:50:54.197489	Training Loss 0.4209 (0.4317)	Training Prec@1 93.555 (92.125)	Training Prec@5 96.289 (95.103)	
2022-03-28 22:00:57,261: ============================================================
2022-03-28 22:01:43,983: time cost, forward:0.209408916630499, backward:0.039163783112335794, data cost:0.21921634619010238 
2022-03-28 22:01:43,984: ============================================================
2022-03-28 22:01:43,984: Epoch 37/45 Batch 1300/7662 eta: 8:46:52.023759	Training Loss 0.4417 (0.4318)	Training Prec@1 91.211 (92.121)	Training Prec@5 94.531 (95.101)	
2022-03-28 22:01:43,984: ============================================================
2022-03-28 22:02:31,926: time cost, forward:0.20990826948955282, backward:0.038981294018443434, data cost:0.21970477029201899 
2022-03-28 22:02:31,926: ============================================================
2022-03-28 22:02:31,926: Epoch 37/45 Batch 1400/7662 eta: 8:59:49.449169	Training Loss 0.4255 (0.4317)	Training Prec@1 94.141 (92.119)	Training Prec@5 96.875 (95.104)	
2022-03-28 22:02:31,927: ============================================================
2022-03-28 22:03:17,551: time cost, forward:0.2097337602217091, backward:0.03896864992209161, data cost:0.21905673544274878 
2022-03-28 22:03:17,551: ============================================================
2022-03-28 22:03:17,551: Epoch 37/45 Batch 1500/7662 eta: 8:32:58.143981	Training Loss 0.4320 (0.4317)	Training Prec@1 94.141 (92.131)	Training Prec@5 96.289 (95.104)	
2022-03-28 22:03:17,552: ============================================================
2022-03-28 22:04:05,837: time cost, forward:0.21002566150906238, backward:0.03895431835253288, data cost:0.21968452314647605 
2022-03-28 22:04:05,838: ============================================================
2022-03-28 22:04:05,838: Epoch 37/45 Batch 1600/7662 eta: 9:02:05.347684	Training Loss 0.4245 (0.4317)	Training Prec@1 92.383 (92.128)	Training Prec@5 95.117 (95.101)	
2022-03-28 22:04:05,838: ============================================================
2022-03-28 22:04:54,088: time cost, forward:0.2105698658481214, backward:0.03895776183412944, data cost:0.219920049771763 
2022-03-28 22:04:54,088: ============================================================
2022-03-28 22:04:54,089: Epoch 37/45 Batch 1700/7662 eta: 9:00:52.952904	Training Loss 0.4278 (0.4317)	Training Prec@1 92.969 (92.142)	Training Prec@5 96.875 (95.108)	
2022-03-28 22:04:54,089: ============================================================
2022-03-28 22:05:41,848: time cost, forward:0.21081516701622496, backward:0.03896149109972391, data cost:0.22010567229346742 
2022-03-28 22:05:41,848: ============================================================
2022-03-28 22:05:41,849: Epoch 37/45 Batch 1800/7662 eta: 8:54:35.139034	Training Loss 0.4407 (0.4316)	Training Prec@1 90.430 (92.141)	Training Prec@5 93.750 (95.111)	
2022-03-28 22:05:41,849: ============================================================
2022-03-28 22:06:27,842: time cost, forward:0.21077370530621137, backward:0.038864872466896384, data cost:0.21970074637555148 
2022-03-28 22:06:27,842: ============================================================
2022-03-28 22:06:27,842: Epoch 37/45 Batch 1900/7662 eta: 8:34:02.887962	Training Loss 0.4232 (0.4316)	Training Prec@1 93.555 (92.144)	Training Prec@5 95.703 (95.117)	
2022-03-28 22:06:27,842: ============================================================
2022-03-28 22:07:14,021: time cost, forward:0.21012230716150007, backward:0.0385842712119915, data cost:0.22022632207197806 
2022-03-28 22:07:14,021: ============================================================
2022-03-28 22:07:14,021: Epoch 37/45 Batch 2000/7662 eta: 8:35:21.079079	Training Loss 0.4302 (0.4316)	Training Prec@1 92.773 (92.143)	Training Prec@5 94.727 (95.110)	
2022-03-28 22:07:14,022: ============================================================
2022-03-28 22:08:00,870: time cost, forward:0.20967364004534048, backward:0.038585886721272535, data cost:0.22062969991512216 
2022-03-28 22:08:00,871: ============================================================
2022-03-28 22:08:00,871: Epoch 37/45 Batch 2100/7662 eta: 8:42:03.157697	Training Loss 0.4293 (0.4317)	Training Prec@1 91.602 (92.140)	Training Prec@5 94.922 (95.107)	
2022-03-28 22:08:00,871: ============================================================
2022-03-28 22:08:47,907: time cost, forward:0.20920105964934735, backward:0.03858899484715065, data cost:0.22116100067114386 
2022-03-28 22:08:47,908: ============================================================
2022-03-28 22:08:47,908: Epoch 37/45 Batch 2200/7662 eta: 8:43:21.312053	Training Loss 0.4300 (0.4316)	Training Prec@1 92.383 (92.139)	Training Prec@5 95.508 (95.105)	
2022-03-28 22:08:47,908: ============================================================
2022-03-28 22:09:34,517: time cost, forward:0.20872445415548263, backward:0.03856867072166387, data cost:0.22150536732551274 
2022-03-28 22:09:34,518: ============================================================
2022-03-28 22:09:34,518: Epoch 37/45 Batch 2300/7662 eta: 8:37:49.742189	Training Loss 0.4433 (0.4317)	Training Prec@1 90.820 (92.141)	Training Prec@5 93.945 (95.101)	
2022-03-28 22:09:34,518: ============================================================
2022-03-28 22:10:20,212: time cost, forward:0.2082325715529715, backward:0.0385637204813033, data cost:0.22150639028736033 
2022-03-28 22:10:20,213: ============================================================
2022-03-28 22:10:20,213: Epoch 37/45 Batch 2400/7662 eta: 8:26:54.050266	Training Loss 0.4323 (0.4316)	Training Prec@1 91.992 (92.137)	Training Prec@5 94.922 (95.101)	
2022-03-28 22:10:20,213: ============================================================
2022-03-28 22:11:08,590: time cost, forward:0.2081780871566461, backward:0.03851790025550015, data cost:0.2222030570193165 
2022-03-28 22:11:08,590: ============================================================
2022-03-28 22:11:08,590: Epoch 37/45 Batch 2500/7662 eta: 8:55:51.324770	Training Loss 0.4379 (0.4317)	Training Prec@1 92.188 (92.132)	Training Prec@5 95.117 (95.095)	
2022-03-28 22:11:08,591: ============================================================
2022-03-28 22:11:56,481: time cost, forward:0.20820505731882796, backward:0.03852881189032947, data cost:0.22253408520072182 
2022-03-28 22:11:56,481: ============================================================
2022-03-28 22:11:56,481: Epoch 37/45 Batch 2600/7662 eta: 8:49:39.991085	Training Loss 0.4272 (0.4317)	Training Prec@1 92.383 (92.131)	Training Prec@5 94.141 (95.093)	
2022-03-28 22:11:56,482: ============================================================
2022-03-28 22:12:44,149: time cost, forward:0.2084438890031021, backward:0.03851985816559821, data cost:0.2225757899572338 
2022-03-28 22:12:44,150: ============================================================
2022-03-28 22:12:44,150: Epoch 37/45 Batch 2700/7662 eta: 8:46:24.706766	Training Loss 0.4364 (0.4316)	Training Prec@1 91.602 (92.134)	Training Prec@5 95.117 (95.094)	
2022-03-28 22:12:44,150: ============================================================
2022-03-28 22:13:31,910: time cost, forward:0.2084048540518087, backward:0.038567679658367104, data cost:0.22284306990925692 
2022-03-28 22:13:31,910: ============================================================
2022-03-28 22:13:31,910: Epoch 37/45 Batch 2800/7662 eta: 8:46:37.808121	Training Loss 0.4371 (0.4316)	Training Prec@1 93.164 (92.137)	Training Prec@5 95.898 (95.096)	
2022-03-28 22:13:31,911: ============================================================
2022-03-28 22:14:19,620: time cost, forward:0.20827104314190226, backward:0.038545978032296674, data cost:0.22323547736987365 
2022-03-28 22:14:19,621: ============================================================
2022-03-28 22:14:19,622: Epoch 37/45 Batch 2900/7662 eta: 8:45:17.458449	Training Loss 0.4376 (0.4317)	Training Prec@1 91.602 (92.131)	Training Prec@5 95.312 (95.095)	
2022-03-28 22:14:19,622: ============================================================
2022-03-28 22:15:07,984: time cost, forward:0.2082553408312058, backward:0.03854433446377267, data cost:0.22357934822675266 
2022-03-28 22:15:07,985: ============================================================
2022-03-28 22:15:07,985: Epoch 37/45 Batch 3000/7662 eta: 8:51:40.129950	Training Loss 0.4274 (0.4317)	Training Prec@1 91.406 (92.125)	Training Prec@5 94.141 (95.088)	
2022-03-28 22:15:07,985: ============================================================
2022-03-28 22:15:53,886: time cost, forward:0.2082618548432332, backward:0.03857008446874677, data cost:0.2232651949005767 
2022-03-28 22:15:53,886: ============================================================
2022-03-28 22:15:53,887: Epoch 37/45 Batch 3100/7662 eta: 8:23:50.244538	Training Loss 0.4256 (0.4317)	Training Prec@1 93.164 (92.127)	Training Prec@5 95.898 (95.093)	
2022-03-28 22:15:53,887: ============================================================
2022-03-28 22:16:42,425: time cost, forward:0.20854959982788238, backward:0.03859235861033863, data cost:0.2234355894317102 
2022-03-28 22:16:42,426: ============================================================
2022-03-28 22:16:42,426: Epoch 37/45 Batch 3200/7662 eta: 8:51:58.872975	Training Loss 0.4283 (0.4316)	Training Prec@1 92.383 (92.129)	Training Prec@5 96.094 (95.098)	
2022-03-28 22:16:42,426: ============================================================
2022-03-28 22:17:29,699: time cost, forward:0.2086786050151861, backward:0.03858505584645105, data cost:0.2233567340477339 
2022-03-28 22:17:29,699: ============================================================
2022-03-28 22:17:29,700: Epoch 37/45 Batch 3300/7662 eta: 8:37:19.606184	Training Loss 0.4229 (0.4317)	Training Prec@1 93.945 (92.121)	Training Prec@5 95.898 (95.095)	
2022-03-28 22:17:29,700: ============================================================
2022-03-28 22:18:17,816: time cost, forward:0.20899417022285338, backward:0.03863826496666339, data cost:0.22329931015055052 
2022-03-28 22:18:17,817: ============================================================
2022-03-28 22:18:17,818: Epoch 37/45 Batch 3400/7662 eta: 8:45:45.617274	Training Loss 0.4261 (0.4316)	Training Prec@1 91.992 (92.126)	Training Prec@5 95.898 (95.100)	
2022-03-28 22:18:17,818: ============================================================
2022-03-28 22:19:05,865: time cost, forward:0.20927115555114834, backward:0.03864440995647281, data cost:0.2232798431627612 
2022-03-28 22:19:05,866: ============================================================
2022-03-28 22:19:05,866: Epoch 37/45 Batch 3500/7662 eta: 8:44:11.760048	Training Loss 0.4402 (0.4317)	Training Prec@1 91.992 (92.126)	Training Prec@5 95.898 (95.102)	
2022-03-28 22:19:05,866: ============================================================
2022-03-28 22:19:53,476: time cost, forward:0.20954418811708, backward:0.03865761490588918, data cost:0.22310895130150052 
2022-03-28 22:19:53,476: ============================================================
2022-03-28 22:19:53,476: Epoch 37/45 Batch 3600/7662 eta: 8:38:37.854124	Training Loss 0.4370 (0.4317)	Training Prec@1 91.602 (92.121)	Training Prec@5 95.898 (95.101)	
2022-03-28 22:19:53,477: ============================================================
2022-03-28 22:20:41,000: time cost, forward:0.20973268732182818, backward:0.03868899560677228, data cost:0.22298490108429145 
2022-03-28 22:20:41,001: ============================================================
2022-03-28 22:20:41,001: Epoch 37/45 Batch 3700/7662 eta: 8:36:53.953794	Training Loss 0.4290 (0.4316)	Training Prec@1 91.602 (92.118)	Training Prec@5 93.750 (95.096)	
2022-03-28 22:20:41,001: ============================================================
2022-03-28 22:21:27,678: time cost, forward:0.20956288961775524, backward:0.03869634723939466, data cost:0.22301718692272454 
2022-03-28 22:21:27,678: ============================================================
2022-03-28 22:21:27,678: Epoch 37/45 Batch 3800/7662 eta: 8:26:54.615223	Training Loss 0.4261 (0.4316)	Training Prec@1 90.625 (92.123)	Training Prec@5 94.727 (95.099)	
2022-03-28 22:21:27,679: ============================================================
2022-03-28 22:22:15,424: time cost, forward:0.2094494833583005, backward:0.03867774695792422, data cost:0.22328624562686392 
2022-03-28 22:22:15,424: ============================================================
2022-03-28 22:22:15,424: Epoch 37/45 Batch 3900/7662 eta: 8:37:43.047372	Training Loss 0.4292 (0.4316)	Training Prec@1 91.406 (92.125)	Training Prec@5 94.727 (95.099)	
2022-03-28 22:22:15,425: ============================================================
2022-03-28 22:23:02,243: time cost, forward:0.2093982096164338, backward:0.03869165304631822, data cost:0.22323890780472522 
2022-03-28 22:23:02,243: ============================================================
2022-03-28 22:23:02,243: Epoch 37/45 Batch 4000/7662 eta: 8:26:53.110075	Training Loss 0.4285 (0.4316)	Training Prec@1 91.016 (92.124)	Training Prec@5 95.117 (95.099)	
2022-03-28 22:23:02,243: ============================================================
2022-03-28 22:23:48,703: time cost, forward:0.20935750554380955, backward:0.0386779075077203, data cost:0.2231238224530226 
2022-03-28 22:23:48,703: ============================================================
2022-03-28 22:23:48,703: Epoch 37/45 Batch 4100/7662 eta: 8:22:13.580495	Training Loss 0.4327 (0.4316)	Training Prec@1 93.555 (92.126)	Training Prec@5 96.094 (95.102)	
2022-03-28 22:23:48,704: ============================================================
2022-03-28 22:24:35,330: time cost, forward:0.20919755857085637, backward:0.038665330532080336, data cost:0.22317615132242136 
2022-03-28 22:24:35,330: ============================================================
2022-03-28 22:24:35,331: Epoch 37/45 Batch 4200/7662 eta: 8:23:15.331072	Training Loss 0.4235 (0.4316)	Training Prec@1 91.797 (92.122)	Training Prec@5 95.312 (95.100)	
2022-03-28 22:24:35,331: ============================================================
2022-03-28 22:25:24,232: time cost, forward:0.2090383943055058, backward:0.038561247814308905, data cost:0.22384097687614105 
2022-03-28 22:25:24,233: ============================================================
2022-03-28 22:25:24,233: Epoch 37/45 Batch 4300/7662 eta: 8:46:59.691832	Training Loss 0.4313 (0.4316)	Training Prec@1 92.578 (92.117)	Training Prec@5 96.094 (95.096)	
2022-03-28 22:25:24,233: ============================================================
2022-03-28 22:26:13,291: time cost, forward:0.20903547998720148, backward:0.038527250831900575, data cost:0.22430825444833072 
2022-03-28 22:26:13,291: ============================================================
2022-03-28 22:26:13,291: Epoch 37/45 Batch 4400/7662 eta: 8:47:51.504195	Training Loss 0.4273 (0.4316)	Training Prec@1 93.555 (92.118)	Training Prec@5 95.898 (95.097)	
2022-03-28 22:26:13,291: ============================================================
2022-03-28 22:27:00,307: time cost, forward:0.20889706700662689, backward:0.03852430617287308, data cost:0.22432025280706774 
2022-03-28 22:27:00,308: ============================================================
2022-03-28 22:27:00,308: Epoch 37/45 Batch 4500/7662 eta: 8:25:06.618079	Training Loss 0.4258 (0.4316)	Training Prec@1 90.430 (92.117)	Training Prec@5 93.555 (95.095)	
2022-03-28 22:27:00,308: ============================================================
2022-03-28 22:27:47,615: time cost, forward:0.20873966971851737, backward:0.03852191155929881, data cost:0.2245862011703156 
2022-03-28 22:27:47,615: ============================================================
2022-03-28 22:27:47,616: Epoch 37/45 Batch 4600/7662 eta: 8:27:26.875218	Training Loss 0.4237 (0.4316)	Training Prec@1 92.188 (92.119)	Training Prec@5 95.117 (95.097)	
2022-03-28 22:27:47,616: ============================================================
2022-03-28 22:28:34,653: time cost, forward:0.208646101960732, backward:0.03848568255101196, data cost:0.22466129494565779 
2022-03-28 22:28:34,654: ============================================================
2022-03-28 22:28:34,654: Epoch 37/45 Batch 4700/7662 eta: 8:23:46.245621	Training Loss 0.4299 (0.4316)	Training Prec@1 91.602 (92.118)	Training Prec@5 95.508 (95.097)	
2022-03-28 22:28:34,654: ============================================================
2022-03-28 22:29:21,752: time cost, forward:0.20864840327861234, backward:0.03850004260155975, data cost:0.22463057562320723 
2022-03-28 22:29:21,752: ============================================================
2022-03-28 22:29:21,752: Epoch 37/45 Batch 4800/7662 eta: 8:23:37.701609	Training Loss 0.4408 (0.4316)	Training Prec@1 94.141 (92.115)	Training Prec@5 95.898 (95.098)	
2022-03-28 22:29:21,753: ============================================================
2022-03-28 22:30:08,668: time cost, forward:0.20852548892606543, backward:0.03848649974160351, data cost:0.22469833345407367 
2022-03-28 22:30:08,668: ============================================================
2022-03-28 22:30:08,669: Epoch 37/45 Batch 4900/7662 eta: 8:20:54.238503	Training Loss 0.4320 (0.4316)	Training Prec@1 90.820 (92.115)	Training Prec@5 94.141 (95.095)	
2022-03-28 22:30:08,669: ============================================================
2022-03-28 22:30:55,904: time cost, forward:0.20839190440169333, backward:0.038518111690041254, data cost:0.2248157036020699 
2022-03-28 22:30:55,904: ============================================================
2022-03-28 22:30:55,905: Epoch 37/45 Batch 5000/7662 eta: 8:23:31.543815	Training Loss 0.4334 (0.4316)	Training Prec@1 91.406 (92.113)	Training Prec@5 94.727 (95.096)	
2022-03-28 22:30:55,905: ============================================================
2022-03-28 22:31:42,939: time cost, forward:0.20828585742524755, backward:0.03851804805283547, data cost:0.2248776661318689 
2022-03-28 22:31:42,939: ============================================================
2022-03-28 22:31:42,939: Epoch 37/45 Batch 5100/7662 eta: 8:20:35.831621	Training Loss 0.4343 (0.4315)	Training Prec@1 93.555 (92.118)	Training Prec@5 96.680 (95.101)	
2022-03-28 22:31:42,939: ============================================================
2022-03-28 22:32:30,144: time cost, forward:0.20823543849966347, backward:0.0385015098882148, data cost:0.22494748028958617 
2022-03-28 22:32:30,144: ============================================================
2022-03-28 22:32:30,145: Epoch 37/45 Batch 5200/7662 eta: 8:21:37.715606	Training Loss 0.4175 (0.4315)	Training Prec@1 93.945 (92.119)	Training Prec@5 96.680 (95.101)	
2022-03-28 22:32:30,145: ============================================================
2022-03-28 22:33:17,251: time cost, forward:0.2082245282394343, backward:0.03848267496925724, data cost:0.22493344254033884 
2022-03-28 22:33:17,251: ============================================================
2022-03-28 22:33:17,261: Epoch 37/45 Batch 5300/7662 eta: 8:19:53.422929	Training Loss 0.4193 (0.4315)	Training Prec@1 93.945 (92.117)	Training Prec@5 96.484 (95.099)	
2022-03-28 22:33:17,261: ============================================================
2022-03-28 22:34:06,279: time cost, forward:0.20820575277989475, backward:0.038467282386902724, data cost:0.2253385898602806 
2022-03-28 22:34:06,280: ============================================================
2022-03-28 22:34:06,280: Epoch 37/45 Batch 5400/7662 eta: 8:39:16.459795	Training Loss 0.4240 (0.4315)	Training Prec@1 94.531 (92.117)	Training Prec@5 97.070 (95.099)	
2022-03-28 22:34:06,280: ============================================================
2022-03-28 22:34:53,362: time cost, forward:0.20821754081311236, backward:0.038458839115781726, data cost:0.22529528682547106 
2022-03-28 22:34:53,363: ============================================================
2022-03-28 22:34:53,363: Epoch 37/45 Batch 5500/7662 eta: 8:17:58.415460	Training Loss 0.4402 (0.4315)	Training Prec@1 90.820 (92.113)	Training Prec@5 93.359 (95.097)	
2022-03-28 22:34:53,363: ============================================================
2022-03-28 22:35:40,457: time cost, forward:0.2081697353360312, backward:0.038461268043960925, data cost:0.22531884856512768 
2022-03-28 22:35:40,458: ============================================================
2022-03-28 22:35:40,458: Epoch 37/45 Batch 5600/7662 eta: 8:17:18.822124	Training Loss 0.4368 (0.4316)	Training Prec@1 91.602 (92.111)	Training Prec@5 94.922 (95.095)	
2022-03-28 22:35:40,458: ============================================================
2022-03-28 22:36:28,591: time cost, forward:0.20823143117991347, backward:0.038486120721335414, data cost:0.22538698796829354 
2022-03-28 22:36:28,591: ============================================================
2022-03-28 22:36:28,592: Epoch 37/45 Batch 5700/7662 eta: 8:27:28.862678	Training Loss 0.4503 (0.4316)	Training Prec@1 89.258 (92.111)	Training Prec@5 94.336 (95.095)	
2022-03-28 22:36:28,592: ============================================================
2022-03-28 22:37:15,362: time cost, forward:0.20820613963210516, backward:0.038484806890301836, data cost:0.22533007386759 
2022-03-28 22:37:15,362: ============================================================
2022-03-28 22:37:15,362: Epoch 37/45 Batch 5800/7662 eta: 8:12:19.855502	Training Loss 0.4458 (0.4316)	Training Prec@1 91.211 (92.108)	Training Prec@5 93.750 (95.094)	
2022-03-28 22:37:15,363: ============================================================
2022-03-28 22:38:02,756: time cost, forward:0.2081157646657734, backward:0.03846978437983398, data cost:0.22547314607161428 
2022-03-28 22:38:02,757: ============================================================
2022-03-28 22:38:02,757: Epoch 37/45 Batch 5900/7662 eta: 8:18:06.542719	Training Loss 0.4224 (0.4316)	Training Prec@1 92.578 (92.106)	Training Prec@5 95.703 (95.092)	
2022-03-28 22:38:02,757: ============================================================
2022-03-28 22:38:49,137: time cost, forward:0.20804637991442126, backward:0.03846690320515557, data cost:0.2254003032204866 
2022-03-28 22:38:49,138: ============================================================
2022-03-28 22:38:49,138: Epoch 37/45 Batch 6000/7662 eta: 8:06:41.060950	Training Loss 0.4294 (0.4316)	Training Prec@1 92.578 (92.108)	Training Prec@5 95.703 (95.094)	
2022-03-28 22:38:49,138: ============================================================
2022-03-28 22:39:37,296: time cost, forward:0.20806119375139753, backward:0.03847342030809324, data cost:0.22553231779093194 
2022-03-28 22:39:37,296: ============================================================
2022-03-28 22:39:37,296: Epoch 37/45 Batch 6100/7662 eta: 8:24:31.751414	Training Loss 0.4305 (0.4316)	Training Prec@1 91.406 (92.105)	Training Prec@5 93.750 (95.091)	
2022-03-28 22:39:37,296: ============================================================
2022-03-28 22:40:23,369: time cost, forward:0.20799569080560165, backward:0.038448571851126975, data cost:0.22542772006173156 
2022-03-28 22:40:23,370: ============================================================
2022-03-28 22:40:23,370: Epoch 37/45 Batch 6200/7662 eta: 8:01:55.367018	Training Loss 0.4219 (0.4316)	Training Prec@1 92.969 (92.107)	Training Prec@5 97.266 (95.093)	
2022-03-28 22:40:23,370: ============================================================
2022-03-28 22:41:10,751: time cost, forward:0.20790699100206722, backward:0.03845422085097223, data cost:0.22553499219227943 
2022-03-28 22:41:10,752: ============================================================
2022-03-28 22:41:10,752: Epoch 37/45 Batch 6300/7662 eta: 8:14:49.179386	Training Loss 0.4214 (0.4316)	Training Prec@1 93.164 (92.110)	Training Prec@5 96.484 (95.094)	
2022-03-28 22:41:10,752: ============================================================
2022-03-28 22:41:57,679: time cost, forward:0.20781674748715953, backward:0.03844776986669537, data cost:0.22558276927886595 
2022-03-28 22:41:57,679: ============================================================
2022-03-28 22:41:57,680: Epoch 37/45 Batch 6400/7662 eta: 8:09:17.559232	Training Loss 0.4378 (0.4316)	Training Prec@1 91.992 (92.109)	Training Prec@5 94.727 (95.095)	
2022-03-28 22:41:57,680: ============================================================
2022-03-28 22:42:44,419: time cost, forward:0.2077158356945521, backward:0.038440029994215044, data cost:0.2256257769180676 
2022-03-28 22:42:44,420: ============================================================
2022-03-28 22:42:44,420: Epoch 37/45 Batch 6500/7662 eta: 8:06:33.461843	Training Loss 0.4422 (0.4316)	Training Prec@1 91.211 (92.107)	Training Prec@5 94.141 (95.097)	
2022-03-28 22:42:44,420: ============================================================
2022-03-28 22:43:31,261: time cost, forward:0.20766986812817578, backward:0.03843455058839361, data cost:0.2256125967364218 
2022-03-28 22:43:31,261: ============================================================
2022-03-28 22:43:31,262: Epoch 37/45 Batch 6600/7662 eta: 8:06:50.002073	Training Loss 0.4534 (0.4316)	Training Prec@1 90.625 (92.106)	Training Prec@5 93.555 (95.099)	
2022-03-28 22:43:31,262: ============================================================
2022-03-28 22:44:17,577: time cost, forward:0.20763390899540898, backward:0.038421963413965705, data cost:0.2255204359192086 
2022-03-28 22:44:17,577: ============================================================
2022-03-28 22:44:17,578: Epoch 37/45 Batch 6700/7662 eta: 8:00:35.850524	Training Loss 0.4364 (0.4316)	Training Prec@1 90.430 (92.106)	Training Prec@5 93.164 (95.099)	
2022-03-28 22:44:17,578: ============================================================
2022-03-28 22:45:03,807: time cost, forward:0.20754084946180304, backward:0.03841388297442181, data cost:0.22548265589705493 
2022-03-28 22:45:03,807: ============================================================
2022-03-28 22:45:03,808: Epoch 37/45 Batch 6800/7662 eta: 7:58:56.027611	Training Loss 0.4290 (0.4316)	Training Prec@1 92.578 (92.110)	Training Prec@5 96.484 (95.102)	
2022-03-28 22:45:03,808: ============================================================
2022-03-28 22:45:53,621: time cost, forward:0.20754146268357745, backward:0.03840182355943495, data cost:0.22587583804237685 
2022-03-28 22:45:53,621: ============================================================
2022-03-28 22:45:53,622: Epoch 37/45 Batch 6900/7662 eta: 8:35:14.019294	Training Loss 0.4382 (0.4316)	Training Prec@1 91.406 (92.107)	Training Prec@5 94.922 (95.101)	
2022-03-28 22:45:53,622: ============================================================
2022-03-28 22:46:40,890: time cost, forward:0.2075659107320529, backward:0.038385541392387805, data cost:0.22588052302024111 
2022-03-28 22:46:40,890: ============================================================
2022-03-28 22:46:40,890: Epoch 37/45 Batch 7000/7662 eta: 8:08:07.186433	Training Loss 0.4314 (0.4316)	Training Prec@1 91.992 (92.106)	Training Prec@5 94.727 (95.100)	
2022-03-28 22:46:40,891: ============================================================
2022-03-28 22:47:26,093: time cost, forward:0.20752882386516694, backward:0.03837861553315194, data cost:0.2256381251405941 
2022-03-28 22:47:26,093: ============================================================
2022-03-28 22:47:26,094: Epoch 37/45 Batch 7100/7662 eta: 7:46:02.357279	Training Loss 0.4242 (0.4316)	Training Prec@1 91.797 (92.107)	Training Prec@5 95.508 (95.101)	
2022-03-28 22:47:26,094: ============================================================
2022-03-28 22:48:12,556: time cost, forward:0.2074837751861479, backward:0.038375626141568954, data cost:0.22558819269004637 
2022-03-28 22:48:12,557: ============================================================
2022-03-28 22:48:12,557: Epoch 37/45 Batch 7200/7662 eta: 7:58:15.209512	Training Loss 0.4298 (0.4316)	Training Prec@1 92.188 (92.107)	Training Prec@5 95.898 (95.102)	
2022-03-28 22:48:12,557: ============================================================
2022-03-28 22:49:00,374: time cost, forward:0.20747899633512903, backward:0.0383782164987464, data cost:0.22566430897627127 
2022-03-28 22:49:00,374: ============================================================
2022-03-28 22:49:00,374: Epoch 37/45 Batch 7300/7662 eta: 8:11:23.671409	Training Loss 0.4461 (0.4316)	Training Prec@1 91.797 (92.109)	Training Prec@5 94.727 (95.103)	
2022-03-28 22:49:00,374: ============================================================
2022-03-28 22:49:47,939: time cost, forward:0.2074593876419655, backward:0.038363973036507105, data cost:0.2257554257523451 
2022-03-28 22:49:47,939: ============================================================
2022-03-28 22:49:47,939: Epoch 37/45 Batch 7400/7662 eta: 8:08:00.591222	Training Loss 0.4373 (0.4316)	Training Prec@1 92.578 (92.109)	Training Prec@5 94.727 (95.102)	
2022-03-28 22:49:47,939: ============================================================
2022-03-28 22:50:34,993: time cost, forward:0.20738912204183377, backward:0.03835804361647837, data cost:0.22581588530448266 
2022-03-28 22:50:34,994: ============================================================
2022-03-28 22:50:34,994: Epoch 37/45 Batch 7500/7662 eta: 8:01:59.534836	Training Loss 0.4185 (0.4316)	Training Prec@1 93.164 (92.109)	Training Prec@5 95.898 (95.101)	
2022-03-28 22:50:34,994: ============================================================
2022-03-28 22:51:23,119: time cost, forward:0.2073990275850734, backward:0.03835563145745568, data cost:0.22592564136797794 
2022-03-28 22:51:23,119: ============================================================
2022-03-28 22:51:23,120: Epoch 37/45 Batch 7600/7662 eta: 8:12:09.213171	Training Loss 0.4274 (0.4316)	Training Prec@1 92.969 (92.109)	Training Prec@5 95.703 (95.103)	
2022-03-28 22:51:23,120: ============================================================
2022-03-28 22:51:54,491: Epoch: 37/45 eta: 8:11:38.894221	Training Loss 0.4334 (0.4316)	Training Prec@1 92.188 (92.111)	Training Prec@5 93.945 (95.104)
2022-03-28 22:51:54,492: ============================================================
2022-03-28 22:51:54,644: Save Checkpoint...
2022-03-28 22:51:54,646: ============================================================
2022-03-28 22:51:56,982: Save done!
2022-03-28 22:51:56,982: ============================================================
2022-03-28 22:52:51,743: time cost, forward:0.26349462884845154, backward:0.044314172532823354, data cost:0.2426404110108963 
2022-03-28 22:52:51,744: ============================================================
2022-03-28 22:52:51,744: Epoch 38/45 Batch 100/7662 eta: 9:18:08.142751	Training Loss 0.4374 (0.4313)	Training Prec@1 91.797 (92.168)	Training Prec@5 94.727 (95.240)	
2022-03-28 22:52:51,744: ============================================================
2022-03-28 22:53:37,706: time cost, forward:0.22928674736214644, backward:0.04131945413560723, data cost:0.23356569352461465 
2022-03-28 22:53:37,706: ============================================================
2022-03-28 22:53:37,707: Epoch 38/45 Batch 200/7662 eta: 7:48:01.890330	Training Loss 0.4232 (0.4316)	Training Prec@1 92.578 (92.126)	Training Prec@5 94.727 (95.132)	
2022-03-28 22:53:37,707: ============================================================
2022-03-28 22:54:25,466: time cost, forward:0.21671601840883592, backward:0.04024135946828785, data cost:0.237967837215666 
2022-03-28 22:54:25,467: ============================================================
2022-03-28 22:54:25,467: Epoch 38/45 Batch 300/7662 eta: 8:05:32.215476	Training Loss 0.4420 (0.4318)	Training Prec@1 91.797 (92.112)	Training Prec@5 95.312 (95.154)	
2022-03-28 22:54:25,467: ============================================================
2022-03-28 22:55:11,086: time cost, forward:0.2104987841202203, backward:0.039966810914806854, data cost:0.23501540246165187 
2022-03-28 22:55:11,087: ============================================================
2022-03-28 22:55:11,087: Epoch 38/45 Batch 400/7662 eta: 7:43:01.368280	Training Loss 0.4245 (0.4314)	Training Prec@1 94.141 (92.175)	Training Prec@5 96.094 (95.178)	
2022-03-28 22:55:11,088: ============================================================
2022-03-28 22:56:00,031: time cost, forward:0.20788821333157037, backward:0.03977550437789642, data cost:0.23854400160795222 
2022-03-28 22:56:00,032: ============================================================
2022-03-28 22:56:00,032: Epoch 38/45 Batch 500/7662 eta: 8:15:56.768513	Training Loss 0.4451 (0.4317)	Training Prec@1 90.430 (92.134)	Training Prec@5 94.141 (95.139)	
2022-03-28 22:56:00,032: ============================================================
2022-03-28 22:56:46,223: time cost, forward:0.20700906751947928, backward:0.03977982229700869, data cost:0.23528385241959052 
2022-03-28 22:56:46,223: ============================================================
2022-03-28 22:56:46,223: Epoch 38/45 Batch 600/7662 eta: 7:47:16.871366	Training Loss 0.4393 (0.4316)	Training Prec@1 93.555 (92.118)	Training Prec@5 95.703 (95.130)	
2022-03-28 22:56:46,224: ============================================================
2022-03-28 22:57:33,759: time cost, forward:0.20696500306136278, backward:0.03963217305523131, data cost:0.2344356732648159 
2022-03-28 22:57:33,760: ============================================================
2022-03-28 22:57:33,760: Epoch 38/45 Batch 700/7662 eta: 8:00:05.727998	Training Loss 0.4291 (0.4315)	Training Prec@1 91.992 (92.128)	Training Prec@5 94.727 (95.133)	
2022-03-28 22:57:33,760: ============================================================
2022-03-28 22:58:21,846: time cost, forward:0.20712352127247072, backward:0.03964751891707897, data cost:0.23417878479175783 
2022-03-28 22:58:21,846: ============================================================
2022-03-28 22:58:21,846: Epoch 38/45 Batch 800/7662 eta: 8:04:50.889285	Training Loss 0.4319 (0.4315)	Training Prec@1 92.773 (92.110)	Training Prec@5 95.312 (95.114)	
2022-03-28 22:58:21,847: ============================================================
2022-03-28 22:59:08,163: time cost, forward:0.20647017894783062, backward:0.039770316759391675, data cost:0.2326560200785636 
2022-03-28 22:59:08,163: ============================================================
2022-03-28 22:59:08,163: Epoch 38/45 Batch 900/7662 eta: 7:46:13.942359	Training Loss 0.4348 (0.4315)	Training Prec@1 92.578 (92.113)	Training Prec@5 95.703 (95.121)	
2022-03-28 22:59:08,163: ============================================================
2022-03-28 22:59:55,190: time cost, forward:0.20614990577086792, backward:0.03963276860234258, data cost:0.2322960012071245 
2022-03-28 22:59:55,191: ============================================================
2022-03-28 22:59:55,191: Epoch 38/45 Batch 1000/7662 eta: 7:52:36.239190	Training Loss 0.4158 (0.4315)	Training Prec@1 92.969 (92.108)	Training Prec@5 96.875 (95.116)	
2022-03-28 22:59:55,191: ============================================================
2022-03-28 23:00:41,264: time cost, forward:0.20548380321540868, backward:0.03949640142147491, data cost:0.23130531870743923 
2022-03-28 23:00:41,264: ============================================================
2022-03-28 23:00:41,265: Epoch 38/45 Batch 1100/7662 eta: 7:42:14.925886	Training Loss 0.4222 (0.4315)	Training Prec@1 91.992 (92.113)	Training Prec@5 95.117 (95.105)	
2022-03-28 23:00:41,265: ============================================================
2022-03-28 23:01:29,668: time cost, forward:0.20497927116890366, backward:0.039569102494889645, data cost:0.23249841790282796 
2022-03-28 23:01:29,669: ============================================================
2022-03-28 23:01:29,669: Epoch 38/45 Batch 1200/7662 eta: 8:04:49.499631	Training Loss 0.4458 (0.4315)	Training Prec@1 92.773 (92.106)	Training Prec@5 96.289 (95.107)	
2022-03-28 23:01:29,669: ============================================================
2022-03-28 23:02:17,547: time cost, forward:0.20466957815433118, backward:0.03943446436875411, data cost:0.23300880776450117 
2022-03-28 23:02:17,547: ============================================================
2022-03-28 23:02:17,548: Epoch 38/45 Batch 1300/7662 eta: 7:58:46.037839	Training Loss 0.4327 (0.4315)	Training Prec@1 89.844 (92.118)	Training Prec@5 94.531 (95.110)	
2022-03-28 23:02:17,549: ============================================================
2022-03-28 23:03:05,504: time cost, forward:0.20462553853900028, backward:0.03930301969608637, data cost:0.23340459309619524 
2022-03-28 23:03:05,505: ============================================================
2022-03-28 23:03:05,506: Epoch 38/45 Batch 1400/7662 eta: 7:58:45.158458	Training Loss 0.4226 (0.4316)	Training Prec@1 92.383 (92.109)	Training Prec@5 95.312 (95.101)	
2022-03-28 23:03:05,506: ============================================================
2022-03-28 23:03:52,613: time cost, forward:0.2044217362254361, backward:0.03930656046291603, data cost:0.2329448422564913 
2022-03-28 23:03:52,616: ============================================================
2022-03-28 23:03:52,617: Epoch 38/45 Batch 1500/7662 eta: 7:49:31.056235	Training Loss 0.4270 (0.4316)	Training Prec@1 91.211 (92.111)	Training Prec@5 94.336 (95.103)	
2022-03-28 23:03:52,617: ============================================================
2022-03-28 23:04:39,282: time cost, forward:0.204633487620303, backward:0.039349172024372, data cost:0.23218243132538166 
2022-03-28 23:04:39,283: ============================================================
2022-03-28 23:04:39,283: Epoch 38/45 Batch 1600/7662 eta: 7:44:18.293756	Training Loss 0.4298 (0.4315)	Training Prec@1 92.773 (92.115)	Training Prec@5 95.312 (95.108)	
2022-03-28 23:04:39,283: ============================================================
2022-03-28 23:05:27,690: time cost, forward:0.20490762736953097, backward:0.03937632985645494, data cost:0.2323006366967734 
2022-03-28 23:05:27,690: ============================================================
2022-03-28 23:05:27,691: Epoch 38/45 Batch 1700/7662 eta: 8:00:49.771881	Training Loss 0.4290 (0.4315)	Training Prec@1 92.969 (92.112)	Training Prec@5 95.898 (95.104)	
2022-03-28 23:05:27,691: ============================================================
2022-03-28 23:06:16,265: time cost, forward:0.20526916971466422, backward:0.03934976576168448, data cost:0.2325277972579201 
2022-03-28 23:06:16,265: ============================================================
2022-03-28 23:06:16,265: Epoch 38/45 Batch 1800/7662 eta: 8:01:40.386486	Training Loss 0.4229 (0.4316)	Training Prec@1 91.016 (92.108)	Training Prec@5 94.531 (95.099)	
2022-03-28 23:06:16,266: ============================================================
2022-03-28 23:07:03,151: time cost, forward:0.2054505850403732, backward:0.03937912301178541, data cost:0.23183815827050794 
2022-03-28 23:07:03,151: ============================================================
2022-03-28 23:07:03,151: Epoch 38/45 Batch 1900/7662 eta: 7:44:08.724429	Training Loss 0.4258 (0.4316)	Training Prec@1 90.820 (92.104)	Training Prec@5 93.359 (95.097)	
2022-03-28 23:07:03,151: ============================================================
2022-03-28 23:07:49,575: time cost, forward:0.20502853441262256, backward:0.03936839735824028, data cost:0.23163045818296416 
2022-03-28 23:07:49,575: ============================================================
2022-03-28 23:07:49,576: Epoch 38/45 Batch 2000/7662 eta: 7:38:48.294618	Training Loss 0.4428 (0.4316)	Training Prec@1 91.992 (92.105)	Training Prec@5 94.922 (95.095)	
2022-03-28 23:07:49,576: ============================================================
2022-03-28 23:08:35,283: time cost, forward:0.20443222555675752, backward:0.03933900955349221, data cost:0.23132319209574517 
2022-03-28 23:08:35,284: ============================================================
2022-03-28 23:08:35,284: Epoch 38/45 Batch 2100/7662 eta: 7:30:57.838542	Training Loss 0.4330 (0.4316)	Training Prec@1 93.555 (92.112)	Training Prec@5 95.703 (95.097)	
2022-03-28 23:08:35,284: ============================================================
2022-03-28 23:09:22,078: time cost, forward:0.20403863452357995, backward:0.03929615617069454, data cost:0.23144706729977388 
2022-03-28 23:09:22,079: ============================================================
2022-03-28 23:09:22,079: Epoch 38/45 Batch 2200/7662 eta: 7:40:54.502204	Training Loss 0.4265 (0.4316)	Training Prec@1 91.797 (92.100)	Training Prec@5 96.289 (95.086)	
2022-03-28 23:09:22,079: ============================================================
2022-03-28 23:10:07,665: time cost, forward:0.20356388691457886, backward:0.03928333959044348, data cost:0.2310899948752305 
2022-03-28 23:10:07,666: ============================================================
2022-03-28 23:10:07,666: Epoch 38/45 Batch 2300/7662 eta: 7:28:15.184991	Training Loss 0.4205 (0.4315)	Training Prec@1 92.773 (92.103)	Training Prec@5 95.508 (95.092)	
2022-03-28 23:10:07,667: ============================================================
2022-03-28 23:10:53,966: time cost, forward:0.203395715302455, backward:0.03919919245737003, data cost:0.2308634753622776 
2022-03-28 23:10:53,966: ============================================================
2022-03-28 23:10:53,967: Epoch 38/45 Batch 2400/7662 eta: 7:34:29.446900	Training Loss 0.4326 (0.4315)	Training Prec@1 92.578 (92.100)	Training Prec@5 94.727 (95.091)	
2022-03-28 23:10:53,967: ============================================================
2022-03-28 23:11:42,146: time cost, forward:0.20362234602169116, backward:0.039130257911422626, data cost:0.23101591081226192 
2022-03-28 23:11:42,147: ============================================================
2022-03-28 23:11:42,147: Epoch 38/45 Batch 2500/7662 eta: 7:52:08.748741	Training Loss 0.4348 (0.4315)	Training Prec@1 90.039 (92.101)	Training Prec@5 93.359 (95.092)	
2022-03-28 23:11:42,147: ============================================================
2022-03-28 23:12:30,888: time cost, forward:0.20375897839418874, backward:0.03913575486524053, data cost:0.2313255322534518 
2022-03-28 23:12:30,889: ============================================================
2022-03-28 23:12:30,889: Epoch 38/45 Batch 2600/7662 eta: 7:56:49.938141	Training Loss 0.4177 (0.4315)	Training Prec@1 92.969 (92.112)	Training Prec@5 96.484 (95.100)	
2022-03-28 23:12:30,889: ============================================================
2022-03-28 23:13:18,107: time cost, forward:0.20393368666946735, backward:0.0391200427083273, data cost:0.23113341974567245 
2022-03-28 23:13:18,108: ============================================================
2022-03-28 23:13:18,108: Epoch 38/45 Batch 2700/7662 eta: 7:41:08.793989	Training Loss 0.4354 (0.4315)	Training Prec@1 94.531 (92.107)	Training Prec@5 97.266 (95.097)	
2022-03-28 23:13:18,108: ============================================================
2022-03-28 23:14:06,023: time cost, forward:0.20412529813855748, backward:0.03915653760282429, data cost:0.23109761507607393 
2022-03-28 23:14:06,023: ============================================================
2022-03-28 23:14:06,023: Epoch 38/45 Batch 2800/7662 eta: 7:47:09.167229	Training Loss 0.4274 (0.4315)	Training Prec@1 91.797 (92.114)	Training Prec@5 95.117 (95.101)	
2022-03-28 23:14:06,024: ============================================================
2022-03-28 23:14:53,495: time cost, forward:0.20427866432739974, backward:0.03914809802681382, data cost:0.23091086966286614 
2022-03-28 23:14:53,495: ============================================================
2022-03-28 23:14:53,496: Epoch 38/45 Batch 2900/7662 eta: 7:42:02.487333	Training Loss 0.4378 (0.4314)	Training Prec@1 90.820 (92.110)	Training Prec@5 93.750 (95.100)	
2022-03-28 23:14:53,496: ============================================================
2022-03-28 23:15:41,568: time cost, forward:0.20435657664989385, backward:0.03914091578321721, data cost:0.23104914517035363 
2022-03-28 23:15:41,568: ============================================================
2022-03-28 23:15:41,568: Epoch 38/45 Batch 3000/7662 eta: 7:47:04.944574	Training Loss 0.4282 (0.4315)	Training Prec@1 90.234 (92.117)	Training Prec@5 93.555 (95.103)	
2022-03-28 23:15:41,569: ============================================================
2022-03-28 23:16:29,216: time cost, forward:0.2043539466839446, backward:0.03906493588546354, data cost:0.23116401150442778 
2022-03-28 23:16:29,217: ============================================================
2022-03-28 23:16:29,217: Epoch 38/45 Batch 3100/7662 eta: 7:42:10.158339	Training Loss 0.4242 (0.4315)	Training Prec@1 92.383 (92.119)	Training Prec@5 96.289 (95.102)	
2022-03-28 23:16:29,218: ============================================================
2022-03-28 23:17:16,950: time cost, forward:0.2044493037859102, backward:0.03905980666751748, data cost:0.23117513178139412 
2022-03-28 23:17:16,950: ============================================================
2022-03-28 23:17:16,950: Epoch 38/45 Batch 3200/7662 eta: 7:42:11.501287	Training Loss 0.4380 (0.4315)	Training Prec@1 91.016 (92.120)	Training Prec@5 93.945 (95.105)	
2022-03-28 23:17:16,951: ============================================================
2022-03-28 23:18:04,567: time cost, forward:0.20453719465470235, backward:0.03899005414067199, data cost:0.23116735914831055 
2022-03-28 23:18:04,567: ============================================================
2022-03-28 23:18:04,568: Epoch 38/45 Batch 3300/7662 eta: 7:40:16.589875	Training Loss 0.4293 (0.4315)	Training Prec@1 92.383 (92.119)	Training Prec@5 95.703 (95.104)	
2022-03-28 23:18:04,568: ============================================================
2022-03-28 23:18:52,757: time cost, forward:0.20465682239594196, backward:0.038957703636126786, data cost:0.23129961784533382 
2022-03-28 23:18:52,758: ============================================================
2022-03-28 23:18:52,758: Epoch 38/45 Batch 3400/7662 eta: 7:45:00.717002	Training Loss 0.4445 (0.4315)	Training Prec@1 90.625 (92.119)	Training Prec@5 93.750 (95.105)	
2022-03-28 23:18:52,758: ============================================================
2022-03-28 23:19:40,119: time cost, forward:0.20459149128438814, backward:0.03896405697550287, data cost:0.23130618418649662 
2022-03-28 23:19:40,119: ============================================================
2022-03-28 23:19:40,119: Epoch 38/45 Batch 3500/7662 eta: 7:36:13.536504	Training Loss 0.4349 (0.4315)	Training Prec@1 91.602 (92.121)	Training Prec@5 95.898 (95.106)	
2022-03-28 23:19:40,120: ============================================================
2022-03-28 23:20:26,363: time cost, forward:0.2044898214920523, backward:0.038965204286058604, data cost:0.23105369093816258 
2022-03-28 23:20:26,363: ============================================================
2022-03-28 23:20:26,364: Epoch 38/45 Batch 3600/7662 eta: 7:24:41.410285	Training Loss 0.4205 (0.4315)	Training Prec@1 91.406 (92.116)	Training Prec@5 94.141 (95.102)	
2022-03-28 23:20:26,364: ============================================================
2022-03-28 23:21:13,964: time cost, forward:0.20455079466692658, backward:0.03894710740581594, data cost:0.23103828693151668 
2022-03-28 23:21:13,965: ============================================================
2022-03-28 23:21:13,965: Epoch 38/45 Batch 3700/7662 eta: 7:36:56.912660	Training Loss 0.4384 (0.4315)	Training Prec@1 90.234 (92.112)	Training Prec@5 95.312 (95.100)	
2022-03-28 23:21:13,965: ============================================================
2022-03-28 23:22:02,149: time cost, forward:0.20456854378935474, backward:0.03888206545947005, data cost:0.23126908677852476 
2022-03-28 23:22:02,149: ============================================================
2022-03-28 23:22:02,150: Epoch 38/45 Batch 3800/7662 eta: 7:41:44.769715	Training Loss 0.4435 (0.4315)	Training Prec@1 91.406 (92.114)	Training Prec@5 95.703 (95.099)	
2022-03-28 23:22:02,150: ============================================================
2022-03-28 23:22:49,815: time cost, forward:0.20462211415412396, backward:0.038890413945685536, data cost:0.23124219583040265 
2022-03-28 23:22:49,815: ============================================================
2022-03-28 23:22:49,816: Epoch 38/45 Batch 3900/7662 eta: 7:35:58.921695	Training Loss 0.4407 (0.4315)	Training Prec@1 90.820 (92.113)	Training Prec@5 94.336 (95.100)	
2022-03-28 23:22:49,816: ============================================================
2022-03-28 23:23:36,451: time cost, forward:0.20463989340802913, backward:0.03888649653124493, data cost:0.2310170217525008 
2022-03-28 23:23:36,451: ============================================================
2022-03-28 23:23:36,452: Epoch 38/45 Batch 4000/7662 eta: 7:25:21.001278	Training Loss 0.4274 (0.4315)	Training Prec@1 93.164 (92.116)	Training Prec@5 96.289 (95.102)	
2022-03-28 23:23:36,452: ============================================================
2022-03-28 23:24:23,865: time cost, forward:0.20457010578603155, backward:0.038897031922257796, data cost:0.2310740182271205 
2022-03-28 23:24:23,866: ============================================================
2022-03-28 23:24:23,866: Epoch 38/45 Batch 4100/7662 eta: 7:31:59.581697	Training Loss 0.4340 (0.4315)	Training Prec@1 91.406 (92.124)	Training Prec@5 93.945 (95.105)	
2022-03-28 23:24:23,866: ============================================================
2022-03-28 23:25:10,852: time cost, forward:0.2046166700134677, backward:0.0389099854689378, data cost:0.23087299929030825 
2022-03-28 23:25:10,853: ============================================================
2022-03-28 23:25:10,853: Epoch 38/45 Batch 4200/7662 eta: 7:27:08.011106	Training Loss 0.4316 (0.4315)	Training Prec@1 90.820 (92.126)	Training Prec@5 93.750 (95.105)	
2022-03-28 23:25:10,853: ============================================================
2022-03-28 23:25:59,120: time cost, forward:0.2046655629728805, backward:0.03891394648005114, data cost:0.23101045858530034 
2022-03-28 23:25:59,120: ============================================================
2022-03-28 23:25:59,121: Epoch 38/45 Batch 4300/7662 eta: 7:38:31.366117	Training Loss 0.4332 (0.4315)	Training Prec@1 91.992 (92.121)	Training Prec@5 95.508 (95.101)	
2022-03-28 23:25:59,121: ============================================================
2022-03-28 23:26:45,921: time cost, forward:0.20459257393811175, backward:0.038885866086248326, data cost:0.23095155483106233 
2022-03-28 23:26:45,921: ============================================================
2022-03-28 23:26:45,921: Epoch 38/45 Batch 4400/7662 eta: 7:23:48.063345	Training Loss 0.4267 (0.4315)	Training Prec@1 91.016 (92.122)	Training Prec@5 92.969 (95.098)	
2022-03-28 23:26:45,922: ============================================================
2022-03-28 23:27:33,075: time cost, forward:0.20447978117010757, backward:0.03886678118683492, data cost:0.23100710286116913 
2022-03-28 23:27:33,076: ============================================================
2022-03-28 23:27:33,076: Epoch 38/45 Batch 4500/7662 eta: 7:26:22.531898	Training Loss 0.4230 (0.4315)	Training Prec@1 93.750 (92.125)	Training Prec@5 96.484 (95.101)	
2022-03-28 23:27:33,076: ============================================================
2022-03-28 23:28:19,914: time cost, forward:0.2043021753265122, backward:0.03886826910851286, data cost:0.23104985264701206 
2022-03-28 23:28:19,915: ============================================================
2022-03-28 23:28:19,915: Epoch 38/45 Batch 4600/7662 eta: 7:22:36.295927	Training Loss 0.4221 (0.4315)	Training Prec@1 94.922 (92.127)	Training Prec@5 96.484 (95.101)	
2022-03-28 23:28:19,915: ============================================================
2022-03-28 23:29:06,602: time cost, forward:0.20427478676426788, backward:0.038863432765083125, data cost:0.23091324260067905 
2022-03-28 23:29:06,602: ============================================================
2022-03-28 23:29:06,603: Epoch 38/45 Batch 4700/7662 eta: 7:20:23.706158	Training Loss 0.4257 (0.4315)	Training Prec@1 93.359 (92.129)	Training Prec@5 95.508 (95.099)	
2022-03-28 23:29:06,603: ============================================================
2022-03-28 23:29:54,601: time cost, forward:0.20431567679149057, backward:0.038887261052657274, data cost:0.2309825351323205 
2022-03-28 23:29:54,602: ============================================================
2022-03-28 23:29:54,602: Epoch 38/45 Batch 4800/7662 eta: 7:31:58.049220	Training Loss 0.4313 (0.4314)	Training Prec@1 92.773 (92.130)	Training Prec@5 96.094 (95.098)	
2022-03-28 23:29:54,602: ============================================================
2022-03-28 23:30:41,417: time cost, forward:0.2043336409650352, backward:0.03888875587932138, data cost:0.230814683678248 
2022-03-28 23:30:41,418: ============================================================
2022-03-28 23:30:41,418: Epoch 38/45 Batch 4900/7662 eta: 7:20:02.880288	Training Loss 0.4280 (0.4314)	Training Prec@1 93.555 (92.131)	Training Prec@5 95.508 (95.101)	
2022-03-28 23:30:41,418: ============================================================
2022-03-28 23:31:27,792: time cost, forward:0.20438799688305276, backward:0.03888604921873962, data cost:0.2305642276507517 
2022-03-28 23:31:27,792: ============================================================
2022-03-28 23:31:27,792: Epoch 38/45 Batch 5000/7662 eta: 7:15:07.418864	Training Loss 0.4347 (0.4314)	Training Prec@1 92.773 (92.133)	Training Prec@5 94.727 (95.102)	
2022-03-28 23:31:27,793: ============================================================
2022-03-28 23:32:16,831: time cost, forward:0.2043813977388336, backward:0.038893677903568305, data cost:0.2308687741065825 
2022-03-28 23:32:16,831: ============================================================
2022-03-28 23:32:16,831: Epoch 38/45 Batch 5100/7662 eta: 7:39:18.391112	Training Loss 0.4386 (0.4314)	Training Prec@1 90.820 (92.127)	Training Prec@5 94.727 (95.099)	
2022-03-28 23:32:16,831: ============================================================
2022-03-28 23:33:03,322: time cost, forward:0.20430788780134626, backward:0.03889999762936999, data cost:0.23074963822413416 
2022-03-28 23:33:03,323: ============================================================
2022-03-28 23:33:03,323: Epoch 38/45 Batch 5200/7662 eta: 7:14:40.571557	Training Loss 0.4333 (0.4314)	Training Prec@1 91.992 (92.130)	Training Prec@5 94.727 (95.101)	
2022-03-28 23:33:03,323: ============================================================
2022-03-28 23:33:50,106: time cost, forward:0.2042414927442111, backward:0.038862820818055734, data cost:0.2307407988717273 
2022-03-28 23:33:50,107: ============================================================
2022-03-28 23:33:50,107: Epoch 38/45 Batch 5300/7662 eta: 7:16:37.406269	Training Loss 0.4275 (0.4314)	Training Prec@1 92.773 (92.128)	Training Prec@5 94.727 (95.101)	
2022-03-28 23:33:50,107: ============================================================
2022-03-28 23:34:35,850: time cost, forward:0.20419793443384823, backward:0.038863496264609436, data cost:0.23045452238564404 
2022-03-28 23:34:35,851: ============================================================
2022-03-28 23:34:35,851: Epoch 38/45 Batch 5400/7662 eta: 7:06:09.539782	Training Loss 0.4374 (0.4315)	Training Prec@1 92.383 (92.128)	Training Prec@5 97.070 (95.102)	
2022-03-28 23:34:35,851: ============================================================
2022-03-28 23:35:22,335: time cost, forward:0.20408730338672917, backward:0.038861478929368774, data cost:0.23041636936446497 
2022-03-28 23:35:22,335: ============================================================
2022-03-28 23:35:22,335: Epoch 38/45 Batch 5500/7662 eta: 7:12:17.026135	Training Loss 0.4430 (0.4315)	Training Prec@1 92.578 (92.129)	Training Prec@5 95.117 (95.103)	
2022-03-28 23:35:22,336: ============================================================
2022-03-28 23:36:08,945: time cost, forward:0.20402194623713793, backward:0.03888963711945196, data cost:0.23030777930532062 
2022-03-28 23:36:08,945: ============================================================
2022-03-28 23:36:08,945: Epoch 38/45 Batch 5600/7662 eta: 7:12:40.349996	Training Loss 0.4396 (0.4315)	Training Prec@1 90.234 (92.126)	Training Prec@5 91.992 (95.100)	
2022-03-28 23:36:08,946: ============================================================
2022-03-28 23:36:57,181: time cost, forward:0.2039744541883092, backward:0.03891873543754881, data cost:0.23047088551759762 
2022-03-28 23:36:57,181: ============================================================
2022-03-28 23:36:57,182: Epoch 38/45 Batch 5700/7662 eta: 7:26:57.939948	Training Loss 0.4329 (0.4315)	Training Prec@1 90.820 (92.127)	Training Prec@5 94.141 (95.101)	
2022-03-28 23:36:57,182: ============================================================
2022-03-28 23:37:45,984: time cost, forward:0.2039704710517511, backward:0.03890235745962333, data cost:0.23074121030369057 
2022-03-28 23:37:45,984: ============================================================
2022-03-28 23:37:45,985: Epoch 38/45 Batch 5800/7662 eta: 7:31:24.106554	Training Loss 0.4353 (0.4315)	Training Prec@1 91.797 (92.124)	Training Prec@5 93.945 (95.099)	
2022-03-28 23:37:45,985: ============================================================
2022-03-28 23:38:34,220: time cost, forward:0.20391616337904386, backward:0.0388878153671469, data cost:0.2309377588727026 
2022-03-28 23:38:34,220: ============================================================
2022-03-28 23:38:34,221: Epoch 38/45 Batch 5900/7662 eta: 7:25:21.270406	Training Loss 0.4215 (0.4315)	Training Prec@1 94.141 (92.124)	Training Prec@5 95.898 (95.099)	
2022-03-28 23:38:34,221: ============================================================
2022-03-28 23:39:22,315: time cost, forward:0.20383794833509342, backward:0.038877610704028065, data cost:0.23116076928533144 
2022-03-28 23:39:22,316: ============================================================
2022-03-28 23:39:22,316: Epoch 38/45 Batch 6000/7662 eta: 7:23:15.305480	Training Loss 0.4297 (0.4315)	Training Prec@1 91.211 (92.126)	Training Prec@5 94.336 (95.100)	
2022-03-28 23:39:22,316: ============================================================
2022-03-28 23:40:10,578: time cost, forward:0.20380745791747817, backward:0.03888935600270754, data cost:0.23131919341080304 
2022-03-28 23:40:10,579: ============================================================
2022-03-28 23:40:10,580: Epoch 38/45 Batch 6100/7662 eta: 7:24:00.309261	Training Loss 0.4287 (0.4315)	Training Prec@1 91.992 (92.124)	Training Prec@5 94.336 (95.100)	
2022-03-28 23:40:10,581: ============================================================
2022-03-28 23:40:58,402: time cost, forward:0.20381610157759386, backward:0.0388796860642117, data cost:0.23138138789826004 
2022-03-28 23:40:58,403: ============================================================
2022-03-28 23:40:58,403: Epoch 38/45 Batch 6200/7662 eta: 7:19:08.961832	Training Loss 0.4277 (0.4315)	Training Prec@1 93.164 (92.126)	Training Prec@5 95.898 (95.102)	
2022-03-28 23:40:58,403: ============================================================
2022-03-28 23:41:47,030: time cost, forward:0.20381153600710614, backward:0.03883708778080968, data cost:0.23161420411090092 
2022-03-28 23:41:47,030: ============================================================
2022-03-28 23:41:47,030: Epoch 38/45 Batch 6300/7662 eta: 7:25:43.596318	Training Loss 0.4259 (0.4315)	Training Prec@1 92.188 (92.127)	Training Prec@5 95.703 (95.103)	
2022-03-28 23:41:47,030: ============================================================
2022-03-28 23:42:33,799: time cost, forward:0.20369474081941685, backward:0.038821627524033585, data cost:0.23163235584335934 
2022-03-28 23:42:33,799: ============================================================
2022-03-28 23:42:33,799: Epoch 38/45 Batch 6400/7662 eta: 7:07:54.760552	Training Loss 0.4466 (0.4315)	Training Prec@1 91.016 (92.122)	Training Prec@5 94.336 (95.101)	
2022-03-28 23:42:33,800: ============================================================
2022-03-28 23:43:20,998: time cost, forward:0.2036271807339984, backward:0.038812617922511575, data cost:0.23168068534503589 
2022-03-28 23:43:20,999: ============================================================
2022-03-28 23:43:20,999: Epoch 38/45 Batch 6500/7662 eta: 7:11:03.933839	Training Loss 0.4328 (0.4315)	Training Prec@1 91.602 (92.123)	Training Prec@5 94.336 (95.101)	
2022-03-28 23:43:20,999: ============================================================
2022-03-28 23:44:09,625: time cost, forward:0.20357643754071478, backward:0.038810413124742316, data cost:0.23189969687122958 
2022-03-28 23:44:09,625: ============================================================
2022-03-28 23:44:09,626: Epoch 38/45 Batch 6600/7662 eta: 7:23:17.528498	Training Loss 0.4494 (0.4315)	Training Prec@1 90.625 (92.120)	Training Prec@5 93.945 (95.102)	
2022-03-28 23:44:09,626: ============================================================
2022-03-28 23:44:57,605: time cost, forward:0.20351937746428647, backward:0.03880595000648983, data cost:0.23203906868443344 
2022-03-28 23:44:57,605: ============================================================
2022-03-28 23:44:57,605: Epoch 38/45 Batch 6700/7662 eta: 7:16:35.346428	Training Loss 0.4307 (0.4315)	Training Prec@1 93.555 (92.116)	Training Prec@5 95.312 (95.098)	
2022-03-28 23:44:57,605: ============================================================
2022-03-28 23:45:45,190: time cost, forward:0.20345944856121043, backward:0.03881434511307286, data cost:0.23210499370461055 
2022-03-28 23:45:45,191: ============================================================
2022-03-28 23:45:45,191: Epoch 38/45 Batch 6800/7662 eta: 7:12:12.866652	Training Loss 0.4219 (0.4315)	Training Prec@1 89.453 (92.117)	Training Prec@5 94.336 (95.099)	
2022-03-28 23:45:45,191: ============================================================
2022-03-28 23:46:33,470: time cost, forward:0.20343930808715777, backward:0.0388260632429387, data cost:0.23222508325423344 
2022-03-28 23:46:33,471: ============================================================
2022-03-28 23:46:33,471: Epoch 38/45 Batch 6900/7662 eta: 7:17:42.678732	Training Loss 0.4387 (0.4315)	Training Prec@1 90.625 (92.115)	Training Prec@5 94.727 (95.101)	
2022-03-28 23:46:33,471: ============================================================
2022-03-28 23:47:21,364: time cost, forward:0.20339030159390098, backward:0.038833983132866116, data cost:0.23233107598036729 
2022-03-28 23:47:21,364: ============================================================
2022-03-28 23:47:21,364: Epoch 38/45 Batch 7000/7662 eta: 7:13:24.806885	Training Loss 0.4336 (0.4316)	Training Prec@1 91.992 (92.113)	Training Prec@5 94.531 (95.099)	
2022-03-28 23:47:21,365: ============================================================
2022-03-28 23:48:08,790: time cost, forward:0.2033105587049141, backward:0.03883175743114849, data cost:0.23240239483518557 
2022-03-28 23:48:08,790: ============================================================
2022-03-28 23:48:08,790: Epoch 38/45 Batch 7100/7662 eta: 7:08:23.330636	Training Loss 0.4300 (0.4316)	Training Prec@1 92.773 (92.114)	Training Prec@5 95.508 (95.099)	
2022-03-28 23:48:08,790: ============================================================
2022-03-28 23:48:55,397: time cost, forward:0.20324836500586196, backward:0.03881924611724968, data cost:0.232350276830975 
2022-03-28 23:48:55,398: ============================================================
2022-03-28 23:48:55,398: Epoch 38/45 Batch 7200/7662 eta: 7:00:13.453814	Training Loss 0.4432 (0.4316)	Training Prec@1 91.602 (92.114)	Training Prec@5 93.555 (95.100)	
2022-03-28 23:48:55,398: ============================================================
2022-03-28 23:49:42,960: time cost, forward:0.20317010125618698, backward:0.038818717835814774, data cost:0.2324324055295527 
2022-03-28 23:49:42,960: ============================================================
2022-03-28 23:49:42,960: Epoch 38/45 Batch 7300/7662 eta: 7:08:02.137226	Training Loss 0.4275 (0.4316)	Training Prec@1 93.359 (92.115)	Training Prec@5 95.898 (95.102)	
2022-03-28 23:49:42,960: ============================================================
2022-03-28 23:50:30,604: time cost, forward:0.2031304882029969, backward:0.038810505675599294, data cost:0.23251103188382852 
2022-03-28 23:50:30,605: ============================================================
2022-03-28 23:50:30,605: Epoch 38/45 Batch 7400/7662 eta: 7:07:59.176681	Training Loss 0.4261 (0.4316)	Training Prec@1 92.969 (92.115)	Training Prec@5 96.289 (95.102)	
2022-03-28 23:50:30,605: ============================================================
2022-03-28 23:51:18,790: time cost, forward:0.20311089938029334, backward:0.03881594660695767, data cost:0.23261427411970767 
2022-03-28 23:51:18,791: ============================================================
2022-03-28 23:51:18,791: Epoch 38/45 Batch 7500/7662 eta: 7:12:02.618374	Training Loss 0.4171 (0.4315)	Training Prec@1 92.578 (92.120)	Training Prec@5 96.289 (95.105)	
2022-03-28 23:51:18,791: ============================================================
2022-03-28 23:52:06,079: time cost, forward:0.202990909770439, backward:0.03880986324626061, data cost:0.23271027218748008 
2022-03-28 23:52:06,080: ============================================================
2022-03-28 23:52:06,080: Epoch 38/45 Batch 7600/7662 eta: 7:03:12.703423	Training Loss 0.4194 (0.4315)	Training Prec@1 91.602 (92.121)	Training Prec@5 94.922 (95.108)	
2022-03-28 23:52:06,080: ============================================================
2022-03-28 23:52:37,324: Epoch: 38/45 eta: 7:02:42.911437	Training Loss 0.4351 (0.4315)	Training Prec@1 92.188 (92.121)	Training Prec@5 94.922 (95.107)
2022-03-28 23:52:37,325: ============================================================
2022-03-28 23:52:37,554: Save Checkpoint...
2022-03-28 23:52:37,557: ============================================================
2022-03-28 23:52:40,335: Save done!
2022-03-28 23:52:40,336: ============================================================
2022-03-28 23:53:34,046: time cost, forward:0.2389578337621207, backward:0.037971217222888064, data cost:0.25880347117029057 
2022-03-28 23:53:34,046: ============================================================
2022-03-28 23:53:34,047: Epoch 39/45 Batch 100/7662 eta: 7:57:01.254472	Training Loss 0.4269 (0.4310)	Training Prec@1 94.141 (92.223)	Training Prec@5 96.094 (95.088)	
2022-03-28 23:53:34,047: ============================================================
2022-03-28 23:54:25,758: time cost, forward:0.2504159565547004, backward:0.03975999055795334, data cost:0.23681237230348826 
2022-03-28 23:54:25,759: ============================================================
2022-03-28 23:54:25,759: Epoch 39/45 Batch 200/7662 eta: 7:40:32.707813	Training Loss 0.4396 (0.4313)	Training Prec@1 91.602 (92.222)	Training Prec@5 94.922 (95.159)	
2022-03-28 23:54:25,760: ============================================================
2022-03-28 23:55:14,737: time cost, forward:0.2505293219384541, backward:0.03963156926592058, data cost:0.22411052040431811 
2022-03-28 23:55:14,738: ============================================================
2022-03-28 23:55:14,738: Epoch 39/45 Batch 300/7662 eta: 7:15:22.934694	Training Loss 0.4368 (0.4312)	Training Prec@1 92.578 (92.217)	Training Prec@5 94.727 (95.163)	
2022-03-28 23:55:14,738: ============================================================
2022-03-28 23:56:03,094: time cost, forward:0.24911588475220187, backward:0.040097175684190335, data cost:0.217326857989892 
2022-03-28 23:56:03,094: ============================================================
2022-03-28 23:56:03,095: Epoch 39/45 Batch 400/7662 eta: 7:09:02.500355	Training Loss 0.4389 (0.4310)	Training Prec@1 91.016 (92.213)	Training Prec@5 94.727 (95.131)	
2022-03-28 23:56:03,095: ============================================================
2022-03-28 23:56:51,119: time cost, forward:0.2483181528194634, backward:0.04020307584850487, data cost:0.21263990708009037 
2022-03-28 23:56:51,119: ============================================================
2022-03-28 23:56:51,120: Epoch 39/45 Batch 500/7662 eta: 7:05:18.033634	Training Loss 0.4368 (0.4315)	Training Prec@1 92.969 (92.148)	Training Prec@5 95.703 (95.096)	
2022-03-28 23:56:51,120: ============================================================
2022-03-28 23:57:38,456: time cost, forward:0.24728135155118963, backward:0.04048560537360547, data cost:0.20857290672340456 
2022-03-28 23:57:38,457: ============================================================
2022-03-28 23:57:38,457: Epoch 39/45 Batch 600/7662 eta: 6:58:25.390069	Training Loss 0.4367 (0.4317)	Training Prec@1 93.359 (92.134)	Training Prec@5 95.898 (95.087)	
2022-03-28 23:57:38,457: ============================================================
2022-03-28 23:58:25,864: time cost, forward:0.24631266941840044, backward:0.04039881055447165, data cost:0.20637311717130255 
2022-03-28 23:58:25,864: ============================================================
2022-03-28 23:58:25,865: Epoch 39/45 Batch 700/7662 eta: 6:58:15.259844	Training Loss 0.4298 (0.4316)	Training Prec@1 92.383 (92.127)	Training Prec@5 94.336 (95.074)	
2022-03-28 23:58:25,865: ============================================================
2022-03-28 23:59:14,845: time cost, forward:0.2455542159170024, backward:0.04008436889314234, data cost:0.2069945651688176 
2022-03-28 23:59:14,846: ============================================================
2022-03-28 23:59:14,846: Epoch 39/45 Batch 800/7662 eta: 7:11:19.207814	Training Loss 0.4198 (0.4316)	Training Prec@1 92.578 (92.144)	Training Prec@5 95.898 (95.090)	
2022-03-28 23:59:14,846: ============================================================
2022-03-29 00:00:03,365: time cost, forward:0.24525777039193736, backward:0.039806921834807774, data cost:0.20666983183286877 
2022-03-29 00:00:03,366: ============================================================
2022-03-29 00:00:03,366: Epoch 39/45 Batch 900/7662 eta: 7:06:27.088878	Training Loss 0.4265 (0.4316)	Training Prec@1 92.188 (92.145)	Training Prec@5 94.727 (95.092)	
2022-03-29 00:00:03,366: ============================================================
2022-03-29 00:00:53,533: time cost, forward:0.24514025419920654, backward:0.039605955461840016, data cost:0.20787789728548434 
2022-03-29 00:00:53,534: ============================================================
2022-03-29 00:00:53,534: Epoch 39/45 Batch 1000/7662 eta: 7:20:06.031953	Training Loss 0.4343 (0.4316)	Training Prec@1 92.383 (92.131)	Training Prec@5 94.336 (95.094)	
2022-03-29 00:00:53,534: ============================================================
2022-03-29 00:01:42,026: time cost, forward:0.2451267921458167, backward:0.03960518277266331, data cost:0.20713837630538315 
2022-03-29 00:01:42,026: ============================================================
2022-03-29 00:01:42,026: Epoch 39/45 Batch 1100/7662 eta: 7:04:35.385107	Training Loss 0.4262 (0.4315)	Training Prec@1 93.359 (92.140)	Training Prec@5 96.680 (95.108)	
2022-03-29 00:01:42,027: ============================================================
2022-03-29 00:02:31,123: time cost, forward:0.2452941644778343, backward:0.03959257986468012, data cost:0.20685436846913646 
2022-03-29 00:02:31,124: ============================================================
2022-03-29 00:02:31,124: Epoch 39/45 Batch 1200/7662 eta: 7:09:04.412561	Training Loss 0.4313 (0.4315)	Training Prec@1 91.797 (92.129)	Training Prec@5 95.703 (95.106)	
2022-03-29 00:02:31,124: ============================================================
2022-03-29 00:03:20,096: time cost, forward:0.2452773157682118, backward:0.03938375995010482, data cost:0.20688319573317976 
2022-03-29 00:03:20,097: ============================================================
2022-03-29 00:03:20,097: Epoch 39/45 Batch 1300/7662 eta: 7:07:09.829042	Training Loss 0.4387 (0.4315)	Training Prec@1 91.992 (92.137)	Training Prec@5 94.336 (95.105)	
2022-03-29 00:03:20,097: ============================================================
2022-03-29 00:04:09,060: time cost, forward:0.24524110278715144, backward:0.038705238876724515, data cost:0.20736131998707005 
2022-03-29 00:04:09,061: ============================================================
2022-03-29 00:04:09,061: Epoch 39/45 Batch 1400/7662 eta: 7:06:16.374161	Training Loss 0.4378 (0.4315)	Training Prec@1 93.555 (92.147)	Training Prec@5 96.289 (95.110)	
2022-03-29 00:04:09,061: ============================================================
2022-03-29 00:04:56,652: time cost, forward:0.24524453228676296, backward:0.03854744874930048, data cost:0.20647784787229573 
2022-03-29 00:04:56,652: ============================================================
2022-03-29 00:04:56,653: Epoch 39/45 Batch 1500/7662 eta: 6:53:31.964780	Training Loss 0.4385 (0.4315)	Training Prec@1 92.383 (92.153)	Training Prec@5 95.898 (95.119)	
2022-03-29 00:04:56,653: ============================================================
2022-03-29 00:05:43,958: time cost, forward:0.2445421078713556, backward:0.03834335605676208, data cost:0.20627612110374122 
2022-03-29 00:05:43,958: ============================================================
2022-03-29 00:05:43,959: Epoch 39/45 Batch 1600/7662 eta: 6:50:15.620277	Training Loss 0.4449 (0.4315)	Training Prec@1 90.039 (92.160)	Training Prec@5 93.359 (95.120)	
2022-03-29 00:05:43,959: ============================================================
2022-03-29 00:06:30,932: time cost, forward:0.24347453597294996, backward:0.038203595595334545, data cost:0.20629131857123775 
2022-03-29 00:06:30,932: ============================================================
2022-03-29 00:06:30,932: Epoch 39/45 Batch 1700/7662 eta: 6:46:35.903550	Training Loss 0.4238 (0.4315)	Training Prec@1 93.750 (92.159)	Training Prec@5 96.680 (95.123)	
2022-03-29 00:06:30,933: ============================================================
2022-03-29 00:07:19,829: time cost, forward:0.2432937899054654, backward:0.03816868451782702, data cost:0.2065271716306049 
2022-03-29 00:07:19,830: ============================================================
2022-03-29 00:07:19,830: Epoch 39/45 Batch 1800/7662 eta: 7:02:26.088352	Training Loss 0.4189 (0.4315)	Training Prec@1 93.164 (92.170)	Training Prec@5 97.461 (95.135)	
2022-03-29 00:07:19,830: ============================================================
2022-03-29 00:08:08,616: time cost, forward:0.24337689395701653, backward:0.038073661893590495, data cost:0.20638606044855665 
2022-03-29 00:08:08,618: ============================================================
2022-03-29 00:08:08,619: Epoch 39/45 Batch 1900/7662 eta: 7:00:40.874579	Training Loss 0.4228 (0.4315)	Training Prec@1 92.383 (92.170)	Training Prec@5 95.508 (95.134)	
2022-03-29 00:08:08,619: ============================================================
2022-03-29 00:08:56,497: time cost, forward:0.24332531885602224, backward:0.037983221790682024, data cost:0.20613697435093736 
2022-03-29 00:08:56,498: ============================================================
2022-03-29 00:08:56,498: Epoch 39/45 Batch 2000/7662 eta: 6:52:02.250960	Training Loss 0.4305 (0.4314)	Training Prec@1 92.578 (92.169)	Training Prec@5 96.094 (95.132)	
2022-03-29 00:08:56,498: ============================================================
2022-03-29 00:09:45,314: time cost, forward:0.2433997189902078, backward:0.03792577848484426, data cost:0.20611784684198023 
2022-03-29 00:09:45,314: ============================================================
2022-03-29 00:09:45,315: Epoch 39/45 Batch 2100/7662 eta: 6:59:17.837342	Training Loss 0.4391 (0.4314)	Training Prec@1 92.383 (92.166)	Training Prec@5 96.484 (95.132)	
2022-03-29 00:09:45,315: ============================================================
2022-03-29 00:10:36,278: time cost, forward:0.24416116586106645, backward:0.037898786613322105, data cost:0.20635909956116305 
2022-03-29 00:10:36,279: ============================================================
2022-03-29 00:10:36,279: Epoch 39/45 Batch 2200/7662 eta: 7:16:53.305311	Training Loss 0.4238 (0.4314)	Training Prec@1 91.797 (92.169)	Training Prec@5 94.922 (95.133)	
2022-03-29 00:10:36,279: ============================================================
2022-03-29 00:11:27,695: time cost, forward:0.24503133202594693, backward:0.03801817031153496, data cost:0.2064466653776563 
2022-03-29 00:11:27,695: ============================================================
2022-03-29 00:11:27,696: Epoch 39/45 Batch 2300/7662 eta: 7:19:54.905963	Training Loss 0.4331 (0.4314)	Training Prec@1 90.430 (92.167)	Training Prec@5 94.141 (95.132)	
2022-03-29 00:11:27,696: ============================================================
2022-03-29 00:12:18,797: time cost, forward:0.24532207651603416, backward:0.03823911820714202, data cost:0.20681850778008065 
2022-03-29 00:12:18,798: ============================================================
2022-03-29 00:12:18,798: Epoch 39/45 Batch 2400/7662 eta: 7:16:22.198627	Training Loss 0.4224 (0.4314)	Training Prec@1 92.969 (92.169)	Training Prec@5 96.094 (95.135)	
2022-03-29 00:12:18,798: ============================================================
2022-03-29 00:13:07,957: time cost, forward:0.24516038906101992, backward:0.038357018661193724, data cost:0.2068822746421872 
2022-03-29 00:13:07,957: ============================================================
2022-03-29 00:13:07,958: Epoch 39/45 Batch 2500/7662 eta: 6:58:57.829133	Training Loss 0.4335 (0.4314)	Training Prec@1 90.625 (92.164)	Training Prec@5 94.531 (95.135)	
2022-03-29 00:13:07,958: ============================================================
2022-03-29 00:13:55,362: time cost, forward:0.24463850225380357, backward:0.03837058387292537, data cost:0.2067340346839438 
2022-03-29 00:13:55,363: ============================================================
2022-03-29 00:13:55,364: Epoch 39/45 Batch 2600/7662 eta: 6:43:13.654725	Training Loss 0.4328 (0.4314)	Training Prec@1 91.602 (92.157)	Training Prec@5 93.945 (95.133)	
2022-03-29 00:13:55,364: ============================================================
2022-03-29 00:14:44,590: time cost, forward:0.24455673847431694, backward:0.038313397481380546, data cost:0.2069351939017263 
2022-03-29 00:14:44,591: ============================================================
2022-03-29 00:14:44,591: Epoch 39/45 Batch 2700/7662 eta: 6:57:53.985209	Training Loss 0.4356 (0.4314)	Training Prec@1 91.406 (92.162)	Training Prec@5 95.117 (95.134)	
2022-03-29 00:14:44,591: ============================================================
2022-03-29 00:15:33,190: time cost, forward:0.24371997276856755, backward:0.03821708219909123, data cost:0.20769590426871248 
2022-03-29 00:15:33,190: ============================================================
2022-03-29 00:15:33,191: Epoch 39/45 Batch 2800/7662 eta: 6:51:45.557007	Training Loss 0.4270 (0.4314)	Training Prec@1 92.383 (92.161)	Training Prec@5 95.117 (95.131)	
2022-03-29 00:15:33,191: ============================================================
2022-03-29 00:16:21,911: time cost, forward:0.24358022513164246, backward:0.038120558196900425, data cost:0.20771432802898385 
2022-03-29 00:16:21,911: ============================================================
2022-03-29 00:16:21,911: Epoch 39/45 Batch 2900/7662 eta: 6:51:58.409176	Training Loss 0.4414 (0.4314)	Training Prec@1 91.992 (92.170)	Training Prec@5 94.336 (95.132)	
2022-03-29 00:16:21,912: ============================================================
2022-03-29 00:17:10,178: time cost, forward:0.24217592083879136, backward:0.037982057435944225, data cost:0.20911971836656124 
2022-03-29 00:17:10,178: ============================================================
2022-03-29 00:17:10,179: Epoch 39/45 Batch 3000/7662 eta: 6:47:20.124000	Training Loss 0.4384 (0.4314)	Training Prec@1 91.797 (92.169)	Training Prec@5 94.922 (95.133)	
2022-03-29 00:17:10,179: ============================================================
2022-03-29 00:17:59,211: time cost, forward:0.24191390648700606, backward:0.037915327503589634, data cost:0.20946229215820747 
2022-03-29 00:17:59,212: ============================================================
2022-03-29 00:17:59,212: Epoch 39/45 Batch 3100/7662 eta: 6:52:59.034985	Training Loss 0.4342 (0.4314)	Training Prec@1 91.406 (92.176)	Training Prec@5 95.312 (95.136)	
2022-03-29 00:17:59,212: ============================================================
2022-03-29 00:18:47,332: time cost, forward:0.24130663345589717, backward:0.03782270177523395, data cost:0.20989851036381818 
2022-03-29 00:18:47,332: ============================================================
2022-03-29 00:18:47,333: Epoch 39/45 Batch 3200/7662 eta: 6:44:29.861368	Training Loss 0.4288 (0.4314)	Training Prec@1 92.383 (92.172)	Training Prec@5 95.898 (95.136)	
2022-03-29 00:18:47,333: ============================================================
2022-03-29 00:19:35,707: time cost, forward:0.24148584879250481, backward:0.03774554232967084, data cost:0.20961936794291414 
2022-03-29 00:19:35,707: ============================================================
2022-03-29 00:19:35,708: Epoch 39/45 Batch 3300/7662 eta: 6:45:49.381158	Training Loss 0.4364 (0.4314)	Training Prec@1 90.234 (92.169)	Training Prec@5 94.727 (95.136)	
2022-03-29 00:19:35,708: ============================================================
2022-03-29 00:20:24,675: time cost, forward:0.24169272414092705, backward:0.03768650045392092, data cost:0.20946751702845395 
2022-03-29 00:20:24,676: ============================================================
2022-03-29 00:20:24,676: Epoch 39/45 Batch 3400/7662 eta: 6:49:59.261368	Training Loss 0.4304 (0.4314)	Training Prec@1 90.039 (92.166)	Training Prec@5 92.773 (95.137)	
2022-03-29 00:20:24,676: ============================================================
2022-03-29 00:21:13,035: time cost, forward:0.24189508795976708, backward:0.0375952608212637, data cost:0.20917927786158508 
2022-03-29 00:21:13,035: ============================================================
2022-03-29 00:21:13,036: Epoch 39/45 Batch 3500/7662 eta: 6:44:05.003495	Training Loss 0.4289 (0.4314)	Training Prec@1 92.188 (92.163)	Training Prec@5 96.094 (95.136)	
2022-03-29 00:21:13,036: ============================================================
2022-03-29 00:22:02,238: time cost, forward:0.2420432912736974, backward:0.03749463729773604, data cost:0.20922319052384342 
2022-03-29 00:22:02,238: ============================================================
2022-03-29 00:22:02,238: Epoch 39/45 Batch 3600/7662 eta: 6:50:18.683507	Training Loss 0.4353 (0.4314)	Training Prec@1 92.383 (92.159)	Training Prec@5 94.922 (95.133)	
2022-03-29 00:22:02,239: ============================================================
2022-03-29 00:22:49,999: time cost, forward:0.24216569607629748, backward:0.037441325207019566, data cost:0.20882323459213764 
2022-03-29 00:22:50,000: ============================================================
2022-03-29 00:22:50,000: Epoch 39/45 Batch 3700/7662 eta: 6:37:29.631390	Training Loss 0.4284 (0.4313)	Training Prec@1 91.797 (92.166)	Training Prec@5 94.922 (95.138)	
2022-03-29 00:22:50,000: ============================================================
2022-03-29 00:23:38,322: time cost, forward:0.24222478580399542, backward:0.03742132201951628, data cost:0.20864339570178267 
2022-03-29 00:23:38,323: ============================================================
2022-03-29 00:23:38,323: Epoch 39/45 Batch 3800/7662 eta: 6:41:21.841406	Training Loss 0.4312 (0.4314)	Training Prec@1 91.797 (92.165)	Training Prec@5 94.336 (95.137)	
2022-03-29 00:23:38,323: ============================================================
2022-03-29 00:24:26,379: time cost, forward:0.2422229535581516, backward:0.03738081831294899, data cost:0.20847078328500745 
2022-03-29 00:24:26,380: ============================================================
2022-03-29 00:24:26,380: Epoch 39/45 Batch 3900/7662 eta: 6:38:21.143219	Training Loss 0.4371 (0.4314)	Training Prec@1 92.969 (92.160)	Training Prec@5 95.508 (95.134)	
2022-03-29 00:24:26,380: ============================================================
2022-03-29 00:25:14,919: time cost, forward:0.2424191382861966, backward:0.037401061321562845, data cost:0.20815410820297314 
2022-03-29 00:25:14,919: ============================================================
2022-03-29 00:25:14,920: Epoch 39/45 Batch 4000/7662 eta: 6:41:32.647922	Training Loss 0.4350 (0.4314)	Training Prec@1 91.016 (92.157)	Training Prec@5 94.336 (95.133)	
2022-03-29 00:25:14,920: ============================================================
2022-03-29 00:26:04,356: time cost, forward:0.2416690774998103, backward:0.03732317603195723, data cost:0.2091358632220091 
2022-03-29 00:26:04,356: ============================================================
2022-03-29 00:26:04,356: Epoch 39/45 Batch 4100/7662 eta: 6:48:08.391805	Training Loss 0.4312 (0.4313)	Training Prec@1 94.336 (92.164)	Training Prec@5 96.289 (95.135)	
2022-03-29 00:26:04,356: ============================================================
2022-03-29 00:26:53,075: time cost, forward:0.2411511001714101, backward:0.037257829544855944, data cost:0.20969220132139588 
2022-03-29 00:26:53,075: ============================================================
2022-03-29 00:26:53,075: Epoch 39/45 Batch 4200/7662 eta: 6:41:24.320675	Training Loss 0.4252 (0.4314)	Training Prec@1 91.797 (92.168)	Training Prec@5 94.922 (95.138)	
2022-03-29 00:26:53,075: ============================================================
2022-03-29 00:27:42,340: time cost, forward:0.24127188614008732, backward:0.037224347215942186, data cost:0.2096954097468289 
2022-03-29 00:27:42,341: ============================================================
2022-03-29 00:27:42,341: Epoch 39/45 Batch 4300/7662 eta: 6:45:05.139870	Training Loss 0.4246 (0.4313)	Training Prec@1 91.602 (92.167)	Training Prec@5 94.336 (95.137)	
2022-03-29 00:27:42,341: ============================================================
2022-03-29 00:28:31,060: time cost, forward:0.24129614647910605, backward:0.03718336226317416, data cost:0.2095686269093709 
2022-03-29 00:28:31,061: ============================================================
2022-03-29 00:28:31,061: Epoch 39/45 Batch 4400/7662 eta: 6:39:47.267598	Training Loss 0.4372 (0.4313)	Training Prec@1 93.164 (92.168)	Training Prec@5 96.094 (95.138)	
2022-03-29 00:28:31,061: ============================================================
2022-03-29 00:29:19,745: time cost, forward:0.24131555847656358, backward:0.03711913171994154, data cost:0.20966505177632044 
2022-03-29 00:29:19,745: ============================================================
2022-03-29 00:29:19,746: Epoch 39/45 Batch 4500/7662 eta: 6:38:41.266712	Training Loss 0.4340 (0.4313)	Training Prec@1 93.359 (92.168)	Training Prec@5 95.508 (95.139)	
2022-03-29 00:29:19,746: ============================================================
2022-03-29 00:30:09,229: time cost, forward:0.24152271025438468, backward:0.03704562558379218, data cost:0.20967623388593573 
2022-03-29 00:30:09,230: ============================================================
2022-03-29 00:30:09,230: Epoch 39/45 Batch 4600/7662 eta: 6:44:24.718462	Training Loss 0.4352 (0.4313)	Training Prec@1 93.750 (92.167)	Training Prec@5 96.484 (95.138)	
2022-03-29 00:30:09,230: ============================================================
2022-03-29 00:30:58,113: time cost, forward:0.24172876956336523, backward:0.036927326153278046, data cost:0.20959123268257332 
2022-03-29 00:30:58,114: ============================================================
2022-03-29 00:30:58,114: Epoch 39/45 Batch 4700/7662 eta: 6:38:41.224309	Training Loss 0.4348 (0.4314)	Training Prec@1 91.211 (92.165)	Training Prec@5 93.945 (95.137)	
2022-03-29 00:30:58,114: ============================================================
2022-03-29 00:31:47,113: time cost, forward:0.24128736702445447, backward:0.036945187566081145, data cost:0.21003220572673323 
2022-03-29 00:31:47,114: ============================================================
2022-03-29 00:31:47,114: Epoch 39/45 Batch 4800/7662 eta: 6:38:49.168978	Training Loss 0.4392 (0.4314)	Training Prec@1 92.578 (92.164)	Training Prec@5 94.922 (95.138)	
2022-03-29 00:31:47,114: ============================================================
2022-03-29 00:32:36,868: time cost, forward:0.24142452404678635, backward:0.03700641516058463, data cost:0.210020473232608 
2022-03-29 00:32:36,868: ============================================================
2022-03-29 00:32:36,868: Epoch 39/45 Batch 4900/7662 eta: 6:44:07.813586	Training Loss 0.4371 (0.4314)	Training Prec@1 93.359 (92.162)	Training Prec@5 95.508 (95.135)	
2022-03-29 00:32:36,868: ============================================================
2022-03-29 00:33:26,977: time cost, forward:0.24156477356414888, backward:0.037026560099083415, data cost:0.21008047096060142 
2022-03-29 00:33:26,978: ============================================================
2022-03-29 00:33:26,978: Epoch 39/45 Batch 5000/7662 eta: 6:46:10.829271	Training Loss 0.4339 (0.4314)	Training Prec@1 89.844 (92.158)	Training Prec@5 94.141 (95.133)	
2022-03-29 00:33:26,978: ============================================================
2022-03-29 00:34:16,680: time cost, forward:0.24165755661124458, backward:0.03699314297356075, data cost:0.21018197691237187 
2022-03-29 00:34:16,681: ============================================================
2022-03-29 00:34:16,681: Epoch 39/45 Batch 5100/7662 eta: 6:42:03.419356	Training Loss 0.4349 (0.4314)	Training Prec@1 93.359 (92.158)	Training Prec@5 95.117 (95.135)	
2022-03-29 00:34:16,681: ============================================================
2022-03-29 00:35:08,296: time cost, forward:0.24186689928417643, backward:0.036970912000036486, data cost:0.2105182674578186 
2022-03-29 00:35:08,296: ============================================================
2022-03-29 00:35:08,297: Epoch 39/45 Batch 5200/7662 eta: 6:56:40.203565	Training Loss 0.4191 (0.4314)	Training Prec@1 92.969 (92.154)	Training Prec@5 95.312 (95.132)	
2022-03-29 00:35:08,297: ============================================================
2022-03-29 00:35:57,051: time cost, forward:0.24173378557456082, backward:0.03702281267828796, data cost:0.21055440341195739 
2022-03-29 00:35:57,052: ============================================================
2022-03-29 00:35:57,052: Epoch 39/45 Batch 5300/7662 eta: 6:32:45.612337	Training Loss 0.4198 (0.4314)	Training Prec@1 92.383 (92.154)	Training Prec@5 95.703 (95.132)	
2022-03-29 00:35:57,052: ============================================================
2022-03-29 00:36:45,866: time cost, forward:0.24185984309988345, backward:0.03700251869855931, data cost:0.21041229252992769 
2022-03-29 00:36:45,866: ============================================================
2022-03-29 00:36:45,867: Epoch 39/45 Batch 5400/7662 eta: 6:32:25.843862	Training Loss 0.4213 (0.4314)	Training Prec@1 93.555 (92.154)	Training Prec@5 95.703 (95.131)	
2022-03-29 00:36:45,867: ============================================================
2022-03-29 00:37:33,602: time cost, forward:0.24110902814696888, backward:0.03695797031414381, data cost:0.21098192892717998 
2022-03-29 00:37:33,603: ============================================================
2022-03-29 00:37:33,603: Epoch 39/45 Batch 5500/7662 eta: 6:22:57.942252	Training Loss 0.4236 (0.4314)	Training Prec@1 91.602 (92.153)	Training Prec@5 94.336 (95.131)	
2022-03-29 00:37:33,603: ============================================================
2022-03-29 00:38:23,574: time cost, forward:0.24121181691069754, backward:0.036956339185632625, data cost:0.2110606073630582 
2022-03-29 00:38:23,574: ============================================================
2022-03-29 00:38:23,575: Epoch 39/45 Batch 5600/7662 eta: 6:40:03.784448	Training Loss 0.4121 (0.4314)	Training Prec@1 93.555 (92.148)	Training Prec@5 95.117 (95.127)	
2022-03-29 00:38:23,575: ============================================================
2022-03-29 00:39:10,991: time cost, forward:0.2402588324622954, backward:0.0369101104077006, data cost:0.21175808817864636 
2022-03-29 00:39:10,991: ============================================================
2022-03-29 00:39:10,992: Epoch 39/45 Batch 5700/7662 eta: 6:18:49.370291	Training Loss 0.4303 (0.4314)	Training Prec@1 92.188 (92.144)	Training Prec@5 93.945 (95.124)	
2022-03-29 00:39:10,992: ============================================================
2022-03-29 00:40:00,060: time cost, forward:0.23983909340023193, backward:0.036883213824702867, data cost:0.21224952702029734 
2022-03-29 00:40:00,060: ============================================================
2022-03-29 00:40:00,061: Epoch 39/45 Batch 5800/7662 eta: 6:31:12.138247	Training Loss 0.4448 (0.4314)	Training Prec@1 91.211 (92.141)	Training Prec@5 94.141 (95.123)	
2022-03-29 00:40:00,061: ============================================================
2022-03-29 00:40:48,327: time cost, forward:0.2397529426156959, backward:0.036873414569394955, data cost:0.21222813514596953 
2022-03-29 00:40:48,328: ============================================================
2022-03-29 00:40:48,328: Epoch 39/45 Batch 5900/7662 eta: 6:24:00.281794	Training Loss 0.4429 (0.4314)	Training Prec@1 92.578 (92.141)	Training Prec@5 95.703 (95.122)	
2022-03-29 00:40:48,328: ============================================================
2022-03-29 00:41:38,990: time cost, forward:0.24000787870111734, backward:0.036872939082617996, data cost:0.21224142142307126 
2022-03-29 00:41:38,990: ============================================================
2022-03-29 00:41:38,990: Epoch 39/45 Batch 6000/7662 eta: 6:42:13.173254	Training Loss 0.4278 (0.4314)	Training Prec@1 92.383 (92.140)	Training Prec@5 94.922 (95.121)	
2022-03-29 00:41:38,991: ============================================================
2022-03-29 00:42:28,055: time cost, forward:0.23979869841122006, backward:0.03684673174069854, data cost:0.21250796873152383 
2022-03-29 00:42:28,055: ============================================================
2022-03-29 00:42:28,056: Epoch 39/45 Batch 6100/7662 eta: 6:28:43.292462	Training Loss 0.4340 (0.4314)	Training Prec@1 91.797 (92.135)	Training Prec@5 94.922 (95.118)	
2022-03-29 00:42:28,056: ============================================================
2022-03-29 00:43:16,637: time cost, forward:0.2397561617908333, backward:0.03682269663902267, data cost:0.21247580521028644 
2022-03-29 00:43:16,637: ============================================================
2022-03-29 00:43:16,637: Epoch 39/45 Batch 6200/7662 eta: 6:24:04.598586	Training Loss 0.4359 (0.4314)	Training Prec@1 91.797 (92.133)	Training Prec@5 95.117 (95.116)	
2022-03-29 00:43:16,638: ============================================================
2022-03-29 00:44:04,313: time cost, forward:0.2396179150164856, backward:0.03680673151247879, data cost:0.21245331271411239 
2022-03-29 00:44:04,314: ============================================================
2022-03-29 00:44:04,314: Epoch 39/45 Batch 6300/7662 eta: 6:16:07.737221	Training Loss 0.4341 (0.4315)	Training Prec@1 89.648 (92.132)	Training Prec@5 93.750 (95.115)	
2022-03-29 00:44:04,314: ============================================================
2022-03-29 00:44:54,416: time cost, forward:0.2397429028010439, backward:0.0367991229783261, data cost:0.21252008657340687 
2022-03-29 00:44:54,417: ============================================================
2022-03-29 00:44:54,417: Epoch 39/45 Batch 6400/7662 eta: 6:34:26.075548	Training Loss 0.4441 (0.4314)	Training Prec@1 92.383 (92.136)	Training Prec@5 95.508 (95.117)	
2022-03-29 00:44:54,417: ============================================================
2022-03-29 00:45:43,147: time cost, forward:0.23995201076649028, backward:0.03684180570503513, data cost:0.21221973144342246 
2022-03-29 00:45:43,147: ============================================================
2022-03-29 00:45:43,147: Epoch 39/45 Batch 6500/7662 eta: 6:22:49.037894	Training Loss 0.4258 (0.4314)	Training Prec@1 93.359 (92.137)	Training Prec@5 96.289 (95.117)	
2022-03-29 00:45:43,147: ============================================================
2022-03-29 00:46:32,127: time cost, forward:0.24015986845337597, backward:0.0369030611680157, data cost:0.2119684952427933 
2022-03-29 00:46:32,127: ============================================================
2022-03-29 00:46:32,127: Epoch 39/45 Batch 6600/7662 eta: 6:23:57.820610	Training Loss 0.4282 (0.4315)	Training Prec@1 93.555 (92.135)	Training Prec@5 95.312 (95.116)	
2022-03-29 00:46:32,128: ============================================================
2022-03-29 00:47:21,789: time cost, forward:0.2400980414623893, backward:0.036928230229554417, data cost:0.2121019046650767 
2022-03-29 00:47:21,789: ============================================================
2022-03-29 00:47:21,789: Epoch 39/45 Batch 6700/7662 eta: 6:28:28.843558	Training Loss 0.4237 (0.4314)	Training Prec@1 91.992 (92.137)	Training Prec@5 95.117 (95.116)	
2022-03-29 00:47:21,790: ============================================================
2022-03-29 00:48:11,016: time cost, forward:0.23994338272213672, backward:0.03691377908381527, data cost:0.2123148338218562 
2022-03-29 00:48:11,016: ============================================================
2022-03-29 00:48:11,017: Epoch 39/45 Batch 6800/7662 eta: 6:24:15.549085	Training Loss 0.4439 (0.4315)	Training Prec@1 88.281 (92.131)	Training Prec@5 94.336 (95.114)	
2022-03-29 00:48:11,017: ============================================================
2022-03-29 00:49:00,954: time cost, forward:0.24002169422316091, backward:0.03689424074772631, data cost:0.21237856399358088 
2022-03-29 00:49:00,954: ============================================================
2022-03-29 00:49:00,955: Epoch 39/45 Batch 6900/7662 eta: 6:28:58.482053	Training Loss 0.4332 (0.4315)	Training Prec@1 92.578 (92.132)	Training Prec@5 95.312 (95.114)	
2022-03-29 00:49:00,955: ============================================================
2022-03-29 00:49:48,744: time cost, forward:0.2398051068959602, backward:0.03687658032650164, data cost:0.21246128045485554 
2022-03-29 00:49:48,745: ============================================================
2022-03-29 00:49:48,745: Epoch 39/45 Batch 7000/7662 eta: 6:11:27.108646	Training Loss 0.4325 (0.4314)	Training Prec@1 92.578 (92.132)	Training Prec@5 95.703 (95.115)	
2022-03-29 00:49:48,745: ============================================================
2022-03-29 00:50:37,544: time cost, forward:0.24000433274164454, backward:0.03690144844098164, data cost:0.2122019112723061 
2022-03-29 00:50:37,545: ============================================================
2022-03-29 00:50:37,546: Epoch 39/45 Batch 7100/7662 eta: 6:18:29.355573	Training Loss 0.4453 (0.4314)	Training Prec@1 89.844 (92.131)	Training Prec@5 93.555 (95.115)	
2022-03-29 00:50:37,546: ============================================================
2022-03-29 00:51:24,643: time cost, forward:0.2395884163066039, backward:0.03682492597018005, data cost:0.2124265270574935 
2022-03-29 00:51:24,643: ============================================================
2022-03-29 00:51:24,643: Epoch 39/45 Batch 7200/7662 eta: 6:04:29.818157	Training Loss 0.4325 (0.4314)	Training Prec@1 88.867 (92.132)	Training Prec@5 92.969 (95.117)	
2022-03-29 00:51:24,643: ============================================================
2022-03-29 00:52:13,725: time cost, forward:0.23916713579629673, backward:0.03669741056050025, data cost:0.21296884977975958 
2022-03-29 00:52:13,726: ============================================================
2022-03-29 00:52:13,726: Epoch 39/45 Batch 7300/7662 eta: 6:19:02.451045	Training Loss 0.4219 (0.4315)	Training Prec@1 93.945 (92.132)	Training Prec@5 97.656 (95.117)	
2022-03-29 00:52:13,726: ============================================================
2022-03-29 00:53:03,981: time cost, forward:0.23926383141714716, backward:0.03668993991006789, data cost:0.21309100719606058 
2022-03-29 00:53:03,982: ============================================================
2022-03-29 00:53:03,982: Epoch 39/45 Batch 7400/7662 eta: 6:27:15.835384	Training Loss 0.4105 (0.4315)	Training Prec@1 94.531 (92.132)	Training Prec@5 97.461 (95.116)	
2022-03-29 00:53:03,982: ============================================================
2022-03-29 00:53:50,967: time cost, forward:0.23911569893940368, backward:0.03667590884880028, data cost:0.21298411417395324 
2022-03-29 00:53:50,967: ============================================================
2022-03-29 00:53:50,968: Epoch 39/45 Batch 7500/7662 eta: 6:01:16.871564	Training Loss 0.4249 (0.4315)	Training Prec@1 91.016 (92.130)	Training Prec@5 93.945 (95.116)	
2022-03-29 00:53:50,968: ============================================================
2022-03-29 00:54:39,267: time cost, forward:0.23898000983223033, backward:0.03665789024879123, data cost:0.21307058330585588 
2022-03-29 00:54:39,268: ============================================================
2022-03-29 00:54:39,268: Epoch 39/45 Batch 7600/7662 eta: 6:10:35.175636	Training Loss 0.4435 (0.4315)	Training Prec@1 91.797 (92.128)	Training Prec@5 94.336 (95.115)	
2022-03-29 00:54:39,269: ============================================================
2022-03-29 00:55:11,972: Epoch: 39/45 eta: 6:10:04.746266	Training Loss 0.4150 (0.4315)	Training Prec@1 92.773 (92.129)	Training Prec@5 95.703 (95.114)
2022-03-29 00:55:11,972: ============================================================
2022-03-29 00:55:12,089: Save Checkpoint...
2022-03-29 00:55:12,091: ============================================================
2022-03-29 00:55:14,934: Save done!
2022-03-29 00:55:14,934: ============================================================
2022-03-29 00:56:03,981: time cost, forward:0.1909365678074384, backward:0.03635628536494091, data cost:0.2648569911417335 
2022-03-29 00:56:03,982: ============================================================
2022-03-29 00:56:03,982: Epoch 40/45 Batch 100/7662 eta: 6:14:24.400860	Training Loss 0.4367 (0.4311)	Training Prec@1 92.969 (92.176)	Training Prec@5 95.703 (95.186)	
2022-03-29 00:56:03,982: ============================================================
2022-03-29 00:56:53,290: time cost, forward:0.21052139009063567, backward:0.03390139790635612, data cost:0.24781828789255728 
2022-03-29 00:56:53,291: ============================================================
2022-03-29 00:56:53,291: Epoch 40/45 Batch 200/7662 eta: 6:16:10.241862	Training Loss 0.4381 (0.4313)	Training Prec@1 91.602 (92.199)	Training Prec@5 93.359 (95.145)	
2022-03-29 00:56:53,291: ============================================================
2022-03-29 00:57:38,577: time cost, forward:0.18731786574807055, backward:0.03338556863791169, data cost:0.25795246286934437 
2022-03-29 00:57:38,577: ============================================================
2022-03-29 00:57:38,577: Epoch 40/45 Batch 300/7662 eta: 5:44:43.540775	Training Loss 0.4308 (0.4312)	Training Prec@1 93.945 (92.162)	Training Prec@5 96.289 (95.081)	
2022-03-29 00:57:38,577: ============================================================
2022-03-29 00:58:25,345: time cost, forward:0.1765687202749993, backward:0.03319524762624487, data cost:0.2660464236610814 
2022-03-29 00:58:25,345: ============================================================
2022-03-29 00:58:25,346: Epoch 40/45 Batch 400/7662 eta: 5:55:13.726838	Training Loss 0.4369 (0.4310)	Training Prec@1 92.383 (92.148)	Training Prec@5 94.727 (95.093)	
2022-03-29 00:58:25,346: ============================================================
2022-03-29 00:59:14,672: time cost, forward:0.18012901680741855, backward:0.03372485556440028, data cost:0.26566983272651873 
2022-03-29 00:59:14,672: ============================================================
2022-03-29 00:59:14,672: Epoch 40/45 Batch 500/7662 eta: 6:13:50.200396	Training Loss 0.4244 (0.4311)	Training Prec@1 92.969 (92.166)	Training Prec@5 95.117 (95.100)	
2022-03-29 00:59:14,672: ============================================================
2022-03-29 01:00:01,625: time cost, forward:0.17834317584666665, backward:0.033707051523937805, data cost:0.26563771817839404 
2022-03-29 01:00:01,626: ============================================================
2022-03-29 01:00:01,626: Epoch 40/45 Batch 600/7662 eta: 5:55:04.401097	Training Loss 0.4379 (0.4311)	Training Prec@1 92.188 (92.146)	Training Prec@5 94.531 (95.086)	
2022-03-29 01:00:01,626: ============================================================
2022-03-29 01:00:49,706: time cost, forward:0.18215609517731893, backward:0.033940575153530925, data cost:0.26199919062111 
2022-03-29 01:00:49,706: ============================================================
2022-03-29 01:00:49,706: Epoch 40/45 Batch 700/7662 eta: 6:02:47.416496	Training Loss 0.4439 (0.4312)	Training Prec@1 91.602 (92.149)	Training Prec@5 94.922 (95.083)	
2022-03-29 01:00:49,707: ============================================================
2022-03-29 01:01:35,053: time cost, forward:0.1756462612199843, backward:0.03403816981070928, data cost:0.26529981287310506 
2022-03-29 01:01:35,053: ============================================================
2022-03-29 01:01:35,053: Epoch 40/45 Batch 800/7662 eta: 5:41:24.608981	Training Loss 0.4367 (0.4312)	Training Prec@1 91.406 (92.135)	Training Prec@5 93.555 (95.067)	
2022-03-29 01:01:35,053: ============================================================
2022-03-29 01:02:24,767: time cost, forward:0.1794887758600831, backward:0.03460945674654374, data cost:0.2632898250066399 
2022-03-29 01:02:24,768: ============================================================
2022-03-29 01:02:24,768: Epoch 40/45 Batch 900/7662 eta: 6:13:27.918007	Training Loss 0.4352 (0.4311)	Training Prec@1 93.164 (92.147)	Training Prec@5 95.898 (95.086)	
2022-03-29 01:02:24,768: ============================================================
2022-03-29 01:03:08,799: time cost, forward:0.1722863601134704, backward:0.034552640743083785, data cost:0.26671209731498163 
2022-03-29 01:03:08,799: ============================================================
2022-03-29 01:03:08,799: Epoch 40/45 Batch 1000/7662 eta: 5:30:02.156263	Training Loss 0.4234 (0.4312)	Training Prec@1 92.383 (92.131)	Training Prec@5 95.898 (95.072)	
2022-03-29 01:03:08,799: ============================================================
2022-03-29 01:03:54,901: time cost, forward:0.1696891439731171, backward:0.034921376026143154, data cost:0.26779605238084037 
2022-03-29 01:03:54,901: ============================================================
2022-03-29 01:03:54,902: Epoch 40/45 Batch 1100/7662 eta: 5:44:47.483442	Training Loss 0.4289 (0.4312)	Training Prec@1 91.406 (92.117)	Training Prec@5 93.555 (95.074)	
2022-03-29 01:03:54,902: ============================================================
2022-03-29 01:04:40,194: time cost, forward:0.1648911586694662, backward:0.0349092986605583, data cost:0.27094871387370334 
2022-03-29 01:04:40,194: ============================================================
2022-03-29 01:04:40,195: Epoch 40/45 Batch 1200/7662 eta: 5:37:58.998375	Training Loss 0.4411 (0.4312)	Training Prec@1 91.016 (92.121)	Training Prec@5 94.531 (95.079)	
2022-03-29 01:04:40,195: ============================================================
2022-03-29 01:05:26,973: time cost, forward:0.1646771772353809, backward:0.03497501719080549, data cost:0.270908724812015 
2022-03-29 01:05:26,974: ============================================================
2022-03-29 01:05:26,974: Epoch 40/45 Batch 1300/7662 eta: 5:48:17.680784	Training Loss 0.4364 (0.4312)	Training Prec@1 90.039 (92.113)	Training Prec@5 93.164 (95.077)	
2022-03-29 01:05:26,974: ============================================================
2022-03-29 01:06:12,854: time cost, forward:0.1625837291283979, backward:0.03491095664928946, data cost:0.2721476256634356 
2022-03-29 01:06:12,854: ============================================================
2022-03-29 01:06:12,854: Epoch 40/45 Batch 1400/7662 eta: 5:40:50.391283	Training Loss 0.4261 (0.4312)	Training Prec@1 90.234 (92.117)	Training Prec@5 93.555 (95.084)	
2022-03-29 01:06:12,855: ============================================================
2022-03-29 01:06:57,253: time cost, forward:0.16080602651599887, backward:0.03474062534075248, data cost:0.2723610065554364 
2022-03-29 01:06:57,254: ============================================================
2022-03-29 01:06:57,254: Epoch 40/45 Batch 1500/7662 eta: 5:29:05.705822	Training Loss 0.4385 (0.4313)	Training Prec@1 89.453 (92.112)	Training Prec@5 93.945 (95.077)	
2022-03-29 01:06:57,254: ============================================================
2022-03-29 01:07:46,894: time cost, forward:0.16515894335758097, backward:0.034904094693659245, data cost:0.2696546321365519 
2022-03-29 01:07:46,895: ============================================================
2022-03-29 01:07:46,895: Epoch 40/45 Batch 1600/7662 eta: 6:07:07.299121	Training Loss 0.4240 (0.4313)	Training Prec@1 93.359 (92.127)	Training Prec@5 95.508 (95.088)	
2022-03-29 01:07:46,895: ============================================================
2022-03-29 01:08:32,578: time cost, forward:0.16617305198790677, backward:0.03495459910208089, data cost:0.2676956669031135 
2022-03-29 01:08:32,579: ============================================================
2022-03-29 01:08:32,579: Epoch 40/45 Batch 1700/7662 eta: 5:37:05.588344	Training Loss 0.4354 (0.4313)	Training Prec@1 91.797 (92.139)	Training Prec@5 95.508 (95.097)	
2022-03-29 01:08:32,579: ============================================================
2022-03-29 01:09:17,194: time cost, forward:0.16530949013176197, backward:0.0350563954220274, data cost:0.26713244102609496 
2022-03-29 01:09:17,195: ============================================================
2022-03-29 01:09:17,195: Epoch 40/45 Batch 1800/7662 eta: 5:28:28.349926	Training Loss 0.4318 (0.4312)	Training Prec@1 92.188 (92.144)	Training Prec@5 94.727 (95.098)	
2022-03-29 01:09:17,195: ============================================================
2022-03-29 01:10:02,496: time cost, forward:0.1640674329670308, backward:0.0350402631905281, data cost:0.26767668339878464 
2022-03-29 01:10:02,496: ============================================================
2022-03-29 01:10:02,496: Epoch 40/45 Batch 1900/7662 eta: 5:32:45.639028	Training Loss 0.4273 (0.4313)	Training Prec@1 92.578 (92.135)	Training Prec@5 94.336 (95.096)	
2022-03-29 01:10:02,497: ============================================================
2022-03-29 01:10:55,851: time cost, forward:0.16763210678291415, backward:0.03525175912312235, data cost:0.26727032876122053 
2022-03-29 01:10:55,851: ============================================================
2022-03-29 01:10:55,851: Epoch 40/45 Batch 2000/7662 eta: 6:31:01.744045	Training Loss 0.4388 (0.4313)	Training Prec@1 90.430 (92.130)	Training Prec@5 94.727 (95.092)	
2022-03-29 01:10:55,852: ============================================================
2022-03-29 01:11:49,745: time cost, forward:0.1709270077469577, backward:0.035674418762446924, data cost:0.26679354284194723 
2022-03-29 01:11:49,745: ============================================================
2022-03-29 01:11:49,746: Epoch 40/45 Batch 2100/7662 eta: 6:34:05.029496	Training Loss 0.4297 (0.4313)	Training Prec@1 91.797 (92.128)	Training Prec@5 94.531 (95.095)	
2022-03-29 01:11:49,746: ============================================================
2022-03-29 01:12:42,770: time cost, forward:0.1728169536417102, backward:0.03581934324336518, data cost:0.26729884544466237 
2022-03-29 01:12:42,770: ============================================================
2022-03-29 01:12:42,770: Epoch 40/45 Batch 2200/7662 eta: 6:26:50.602296	Training Loss 0.4276 (0.4313)	Training Prec@1 93.359 (92.128)	Training Prec@5 95.703 (95.095)	
2022-03-29 01:12:42,771: ============================================================
2022-03-29 01:13:31,097: time cost, forward:0.17349998947847092, backward:0.035965003569056644, data cost:0.2668061117443534 
2022-03-29 01:13:31,097: ============================================================
2022-03-29 01:13:31,098: Epoch 40/45 Batch 2300/7662 eta: 5:51:45.879406	Training Loss 0.4345 (0.4314)	Training Prec@1 93.164 (92.130)	Training Prec@5 96.289 (95.100)	
2022-03-29 01:13:31,098: ============================================================
2022-03-29 01:14:22,292: time cost, forward:0.17503653828826435, backward:0.03633982005244546, data cost:0.26638467563296814 
2022-03-29 01:14:22,292: ============================================================
2022-03-29 01:14:22,292: Epoch 40/45 Batch 2400/7662 eta: 6:11:47.007729	Training Loss 0.4154 (0.4314)	Training Prec@1 93.359 (92.132)	Training Prec@5 96.680 (95.103)	
2022-03-29 01:14:22,292: ============================================================
2022-03-29 01:15:13,609: time cost, forward:0.17675561883917995, backward:0.03680431475492418, data cost:0.26559435429216244 
2022-03-29 01:15:13,620: ============================================================
2022-03-29 01:15:13,621: Epoch 40/45 Batch 2500/7662 eta: 6:11:54.068981	Training Loss 0.4216 (0.4314)	Training Prec@1 91.602 (92.129)	Training Prec@5 95.508 (95.103)	
2022-03-29 01:15:13,621: ============================================================
2022-03-29 01:16:01,116: time cost, forward:0.17735665832496048, backward:0.03696703580582587, data cost:0.2646256424271634 
2022-03-29 01:16:01,117: ============================================================
2022-03-29 01:16:01,117: Epoch 40/45 Batch 2600/7662 eta: 5:43:20.439275	Training Loss 0.4409 (0.4314)	Training Prec@1 90.820 (92.127)	Training Prec@5 94.922 (95.101)	
2022-03-29 01:16:01,117: ============================================================
2022-03-29 01:16:48,440: time cost, forward:0.17771016575310486, backward:0.03701719340239246, data cost:0.2639730275229376 
2022-03-29 01:16:48,441: ============================================================
2022-03-29 01:16:48,441: Epoch 40/45 Batch 2700/7662 eta: 5:41:18.649416	Training Loss 0.4216 (0.4314)	Training Prec@1 91.797 (92.132)	Training Prec@5 94.922 (95.108)	
2022-03-29 01:16:48,441: ============================================================
2022-03-29 01:17:35,562: time cost, forward:0.17768973927704, backward:0.03701464956937069, data cost:0.26372469881254673 
2022-03-29 01:17:35,563: ============================================================
2022-03-29 01:17:35,563: Epoch 40/45 Batch 2800/7662 eta: 5:39:03.836534	Training Loss 0.4264 (0.4314)	Training Prec@1 93.359 (92.132)	Training Prec@5 95.508 (95.108)	
2022-03-29 01:17:35,563: ============================================================
2022-03-29 01:18:27,280: time cost, forward:0.18017733463051813, backward:0.03723904222157463, data cost:0.2623032766936277 
2022-03-29 01:18:27,280: ============================================================
2022-03-29 01:18:27,281: Epoch 40/45 Batch 2900/7662 eta: 6:11:16.304333	Training Loss 0.4401 (0.4314)	Training Prec@1 89.453 (92.139)	Training Prec@5 93.555 (95.116)	
2022-03-29 01:18:27,281: ============================================================
2022-03-29 01:19:14,600: time cost, forward:0.1806892245242738, backward:0.037256407713882125, data cost:0.26152970306711937 
2022-03-29 01:19:14,601: ============================================================
2022-03-29 01:19:14,601: Epoch 40/45 Batch 3000/7662 eta: 5:38:55.117824	Training Loss 0.4446 (0.4313)	Training Prec@1 92.188 (92.143)	Training Prec@5 95.898 (95.113)	
2022-03-29 01:19:14,601: ============================================================
2022-03-29 01:20:01,173: time cost, forward:0.18038498789850993, backward:0.03728153221681834, data cost:0.26134574317132014 
2022-03-29 01:20:01,185: ============================================================
2022-03-29 01:20:01,186: Epoch 40/45 Batch 3100/7662 eta: 5:32:52.077246	Training Loss 0.4151 (0.4313)	Training Prec@1 93.359 (92.146)	Training Prec@5 96.289 (95.119)	
2022-03-29 01:20:01,186: ============================================================
2022-03-29 01:20:49,490: time cost, forward:0.1801541081142634, backward:0.037416053138773456, data cost:0.2615378502943844 
2022-03-29 01:20:49,499: ============================================================
2022-03-29 01:20:49,499: Epoch 40/45 Batch 3200/7662 eta: 5:44:25.393982	Training Loss 0.4304 (0.4313)	Training Prec@1 91.602 (92.150)	Training Prec@5 94.336 (95.123)	
2022-03-29 01:20:49,500: ============================================================
2022-03-29 01:21:39,036: time cost, forward:0.18144575824662387, backward:0.03753469336499009, data cost:0.2605834980016768 
2022-03-29 01:21:39,037: ============================================================
2022-03-29 01:21:39,037: Epoch 40/45 Batch 3300/7662 eta: 5:52:19.067846	Training Loss 0.4362 (0.4313)	Training Prec@1 93.164 (92.147)	Training Prec@5 95.898 (95.122)	
2022-03-29 01:21:39,037: ============================================================
2022-03-29 01:22:28,241: time cost, forward:0.18245628820724016, backward:0.03765834917493272, data cost:0.25982827535619735 
2022-03-29 01:22:28,241: ============================================================
2022-03-29 01:22:28,241: Epoch 40/45 Batch 3400/7662 eta: 5:49:07.924033	Training Loss 0.4133 (0.4313)	Training Prec@1 93.945 (92.151)	Training Prec@5 96.289 (95.127)	
2022-03-29 01:22:28,242: ============================================================
2022-03-29 01:23:18,289: time cost, forward:0.1838674322473352, backward:0.03772577376800389, data cost:0.25886769136656146 
2022-03-29 01:23:18,290: ============================================================
2022-03-29 01:23:18,290: Epoch 40/45 Batch 3500/7662 eta: 5:54:16.993003	Training Loss 0.4290 (0.4313)	Training Prec@1 92.578 (92.150)	Training Prec@5 95.117 (95.124)	
2022-03-29 01:23:18,290: ============================================================
2022-03-29 01:24:05,093: time cost, forward:0.18292103717313207, backward:0.037657004324851286, data cost:0.2595227894832042 
2022-03-29 01:24:05,093: ============================================================
2022-03-29 01:24:05,094: Epoch 40/45 Batch 3600/7662 eta: 5:30:32.174017	Training Loss 0.4349 (0.4313)	Training Prec@1 94.531 (92.149)	Training Prec@5 95.703 (95.122)	
2022-03-29 01:24:05,094: ============================================================
2022-03-29 01:24:54,293: time cost, forward:0.1825406608725922, backward:0.037676243886460355, data cost:0.26008956875147515 
2022-03-29 01:24:54,305: ============================================================
2022-03-29 01:24:54,305: Epoch 40/45 Batch 3700/7662 eta: 5:46:43.124251	Training Loss 0.4407 (0.4313)	Training Prec@1 90.820 (92.147)	Training Prec@5 93.750 (95.120)	
2022-03-29 01:24:54,305: ============================================================
2022-03-29 01:25:44,812: time cost, forward:0.1835166445277998, backward:0.03774241335488018, data cost:0.25966861938984653 
2022-03-29 01:25:44,815: ============================================================
2022-03-29 01:25:44,816: Epoch 40/45 Batch 3800/7662 eta: 5:55:01.726382	Training Loss 0.4266 (0.4312)	Training Prec@1 92.188 (92.152)	Training Prec@5 94.922 (95.122)	
2022-03-29 01:25:44,817: ============================================================
2022-03-29 01:26:32,237: time cost, forward:0.18344719167182494, backward:0.03760360852055869, data cost:0.2597758305870774 
2022-03-29 01:26:32,237: ============================================================
2022-03-29 01:26:32,238: Epoch 40/45 Batch 3900/7662 eta: 5:32:32.074801	Training Loss 0.4339 (0.4313)	Training Prec@1 92.578 (92.154)	Training Prec@5 94.727 (95.121)	
2022-03-29 01:26:32,238: ============================================================
2022-03-29 01:27:19,220: time cost, forward:0.18285677050852603, backward:0.03756137018234738, data cost:0.2601210975623125 
2022-03-29 01:27:19,220: ============================================================
2022-03-29 01:27:19,221: Epoch 40/45 Batch 4000/7662 eta: 5:28:40.082641	Training Loss 0.4310 (0.4312)	Training Prec@1 93.164 (92.155)	Training Prec@5 95.898 (95.123)	
2022-03-29 01:27:19,221: ============================================================
2022-03-29 01:28:05,853: time cost, forward:0.18200536564112466, backward:0.03752715769672603, data cost:0.2606762420494227 
2022-03-29 01:28:05,854: ============================================================
2022-03-29 01:28:05,854: Epoch 40/45 Batch 4100/7662 eta: 5:25:26.657611	Training Loss 0.4454 (0.4312)	Training Prec@1 91.211 (92.153)	Training Prec@5 94.531 (95.121)	
2022-03-29 01:28:05,854: ============================================================
2022-03-29 01:28:52,154: time cost, forward:0.180699516234156, backward:0.037434464722878875, data cost:0.26163840986598413 
2022-03-29 01:28:52,155: ============================================================
2022-03-29 01:28:52,155: Epoch 40/45 Batch 4200/7662 eta: 5:22:21.411295	Training Loss 0.4248 (0.4312)	Training Prec@1 92.383 (92.152)	Training Prec@5 94.922 (95.122)	
2022-03-29 01:28:52,155: ============================================================
2022-03-29 01:29:39,808: time cost, forward:0.17987989297881463, backward:0.03737460604710034, data cost:0.2624536898280887 
2022-03-29 01:29:39,809: ============================================================
2022-03-29 01:29:39,809: Epoch 40/45 Batch 4300/7662 eta: 5:30:58.795501	Training Loss 0.4407 (0.4312)	Training Prec@1 93.555 (92.154)	Training Prec@5 96.094 (95.125)	
2022-03-29 01:29:39,820: ============================================================
2022-03-29 01:30:28,326: time cost, forward:0.17981184957026894, backward:0.037286904053840886, data cost:0.26270390803447013 
2022-03-29 01:30:28,327: ============================================================
2022-03-29 01:30:28,327: Epoch 40/45 Batch 4400/7662 eta: 5:36:10.564027	Training Loss 0.4355 (0.4312)	Training Prec@1 91.016 (92.151)	Training Prec@5 92.969 (95.123)	
2022-03-29 01:30:28,327: ============================================================
2022-03-29 01:31:12,717: time cost, forward:0.1785797654164847, backward:0.03723261472409925, data cost:0.26316464819042223 
2022-03-29 01:31:12,728: ============================================================
2022-03-29 01:31:12,728: Epoch 40/45 Batch 4500/7662 eta: 5:06:54.369587	Training Loss 0.4300 (0.4312)	Training Prec@1 91.602 (92.152)	Training Prec@5 94.141 (95.122)	
2022-03-29 01:31:12,728: ============================================================
2022-03-29 01:32:00,207: time cost, forward:0.1784442848007325, backward:0.03716648120054812, data cost:0.263269592560123 
2022-03-29 01:32:00,208: ============================================================
2022-03-29 01:32:00,208: Epoch 40/45 Batch 4600/7662 eta: 5:27:23.782927	Training Loss 0.4402 (0.4312)	Training Prec@1 93.164 (92.153)	Training Prec@5 97.266 (95.123)	
2022-03-29 01:32:00,208: ============================================================
2022-03-29 01:32:46,532: time cost, forward:0.1778161284212712, backward:0.037095511154967134, data cost:0.2636497708730785 
2022-03-29 01:32:46,542: ============================================================
2022-03-29 01:32:46,542: Epoch 40/45 Batch 4700/7662 eta: 5:18:43.659766	Training Loss 0.4270 (0.4312)	Training Prec@1 94.531 (92.159)	Training Prec@5 96.289 (95.127)	
2022-03-29 01:32:46,543: ============================================================
2022-03-29 01:33:34,310: time cost, forward:0.17806571323341516, backward:0.03703965860546865, data cost:0.2634198908558436 
2022-03-29 01:33:34,310: ============================================================
2022-03-29 01:33:34,310: Epoch 40/45 Batch 4800/7662 eta: 5:27:47.507403	Training Loss 0.4261 (0.4312)	Training Prec@1 94.141 (92.162)	Training Prec@5 97.070 (95.131)	
2022-03-29 01:33:34,311: ============================================================
2022-03-29 01:34:20,495: time cost, forward:0.17786504346805096, backward:0.03696614334743396, data cost:0.26334028687859634 
2022-03-29 01:34:20,495: ============================================================
2022-03-29 01:34:20,496: Epoch 40/45 Batch 4900/7662 eta: 5:16:09.611933	Training Loss 0.4229 (0.4312)	Training Prec@1 92.383 (92.159)	Training Prec@5 96.289 (95.128)	
2022-03-29 01:34:20,496: ============================================================
2022-03-29 01:35:06,318: time cost, forward:0.17727115293053727, backward:0.03690985441923285, data cost:0.2635707695452207 
2022-03-29 01:35:06,318: ============================================================
2022-03-29 01:35:06,319: Epoch 40/45 Batch 5000/7662 eta: 5:12:55.087761	Training Loss 0.4275 (0.4312)	Training Prec@1 91.602 (92.160)	Training Prec@5 94.727 (95.128)	
2022-03-29 01:35:06,319: ============================================================
2022-03-29 01:35:52,932: time cost, forward:0.17681749555778914, backward:0.036850500864289655, data cost:0.26386723104096504 
2022-03-29 01:35:52,942: ============================================================
2022-03-29 01:35:52,942: Epoch 40/45 Batch 5100/7662 eta: 5:17:36.581261	Training Loss 0.4441 (0.4312)	Training Prec@1 91.016 (92.160)	Training Prec@5 94.922 (95.130)	
2022-03-29 01:35:52,943: ============================================================
2022-03-29 01:36:38,733: time cost, forward:0.17582496034798656, backward:0.03671806875296019, data cost:0.26458734708420245 
2022-03-29 01:36:38,734: ============================================================
2022-03-29 01:36:38,734: Epoch 40/45 Batch 5200/7662 eta: 5:11:10.602259	Training Loss 0.4339 (0.4312)	Training Prec@1 93.164 (92.159)	Training Prec@5 95.117 (95.128)	
2022-03-29 01:36:38,734: ============================================================
2022-03-29 01:37:27,526: time cost, forward:0.17607865474835546, backward:0.036653586706365586, data cost:0.2646195026001046 
2022-03-29 01:37:27,526: ============================================================
2022-03-29 01:37:27,527: Epoch 40/45 Batch 5300/7662 eta: 5:30:45.350744	Training Loss 0.4422 (0.4312)	Training Prec@1 88.867 (92.156)	Training Prec@5 92.969 (95.128)	
2022-03-29 01:37:27,527: ============================================================
2022-03-29 01:38:14,733: time cost, forward:0.17590512962645127, backward:0.03659894780376086, data cost:0.2647241919454457 
2022-03-29 01:38:14,746: ============================================================
2022-03-29 01:38:14,746: Epoch 40/45 Batch 5400/7662 eta: 5:19:18.295308	Training Loss 0.4239 (0.4312)	Training Prec@1 90.625 (92.153)	Training Prec@5 95.312 (95.126)	
2022-03-29 01:38:14,746: ============================================================
2022-03-29 01:39:03,586: time cost, forward:0.17608539922429467, backward:0.036570360106020584, data cost:0.2647671444586438 
2022-03-29 01:39:03,598: ============================================================
2022-03-29 01:39:03,599: Epoch 40/45 Batch 5500/7662 eta: 5:29:32.060537	Training Loss 0.4352 (0.4312)	Training Prec@1 94.141 (92.158)	Training Prec@5 96.875 (95.128)	
2022-03-29 01:39:03,599: ============================================================
2022-03-29 01:39:55,287: time cost, forward:0.1768400523892086, backward:0.036719862446867584, data cost:0.2645478290752718 
2022-03-29 01:39:55,287: ============================================================
2022-03-29 01:39:55,288: Epoch 40/45 Batch 5600/7662 eta: 5:47:48.485787	Training Loss 0.4317 (0.4313)	Training Prec@1 91.406 (92.156)	Training Prec@5 94.531 (95.127)	
2022-03-29 01:39:55,288: ============================================================
2022-03-29 01:40:45,432: time cost, forward:0.17735874680055402, backward:0.0367826296375768, data cost:0.26438813072314366 
2022-03-29 01:40:45,433: ============================================================
2022-03-29 01:40:45,433: Epoch 40/45 Batch 5700/7662 eta: 5:36:35.115532	Training Loss 0.4330 (0.4313)	Training Prec@1 90.820 (92.157)	Training Prec@5 95.312 (95.129)	
2022-03-29 01:40:45,433: ============================================================
2022-03-29 01:41:33,288: time cost, forward:0.17777229769720376, backward:0.03686757304788067, data cost:0.26387798726548406 
2022-03-29 01:41:33,299: ============================================================
2022-03-29 01:41:33,299: Epoch 40/45 Batch 5800/7662 eta: 5:20:29.047819	Training Loss 0.4456 (0.4313)	Training Prec@1 91.211 (92.153)	Training Prec@5 94.336 (95.126)	
2022-03-29 01:41:33,299: ============================================================
2022-03-29 01:42:21,593: time cost, forward:0.17783162399436847, backward:0.03685528331943479, data cost:0.26389785458787374 
2022-03-29 01:42:21,593: ============================================================
2022-03-29 01:42:21,593: Epoch 40/45 Batch 5900/7662 eta: 5:22:33.134616	Training Loss 0.4201 (0.4312)	Training Prec@1 93.555 (92.155)	Training Prec@5 96.094 (95.127)	
2022-03-29 01:42:21,594: ============================================================
2022-03-29 01:43:11,195: time cost, forward:0.178380759363672, backward:0.03693924806260689, data cost:0.26354532413511284 
2022-03-29 01:43:11,195: ============================================================
2022-03-29 01:43:11,195: Epoch 40/45 Batch 6000/7662 eta: 5:30:27.400216	Training Loss 0.4289 (0.4312)	Training Prec@1 91.211 (92.155)	Training Prec@5 93.359 (95.126)	
2022-03-29 01:43:11,196: ============================================================
2022-03-29 01:44:02,628: time cost, forward:0.17939344529813187, backward:0.0370254378608845, data cost:0.26300452466596635 
2022-03-29 01:44:02,629: ============================================================
2022-03-29 01:44:02,629: Epoch 40/45 Batch 6100/7662 eta: 5:41:48.005705	Training Loss 0.4355 (0.4313)	Training Prec@1 93.164 (92.152)	Training Prec@5 95.508 (95.125)	
2022-03-29 01:44:02,629: ============================================================
2022-03-29 01:44:49,044: time cost, forward:0.17935530299774233, backward:0.03702021060518381, data cost:0.26279886258496526 
2022-03-29 01:44:49,045: ============================================================
2022-03-29 01:44:49,045: Epoch 40/45 Batch 6200/7662 eta: 5:07:41.050619	Training Loss 0.4377 (0.4313)	Training Prec@1 89.648 (92.150)	Training Prec@5 93.359 (95.125)	
2022-03-29 01:44:49,045: ============================================================
2022-03-29 01:45:37,958: time cost, forward:0.1795919709100404, backward:0.03698093509992014, data cost:0.2627263688761046 
2022-03-29 01:45:37,959: ============================================================
2022-03-29 01:45:37,959: Epoch 40/45 Batch 6300/7662 eta: 5:23:25.622574	Training Loss 0.4323 (0.4313)	Training Prec@1 90.820 (92.152)	Training Prec@5 93.555 (95.125)	
2022-03-29 01:45:37,959: ============================================================
2022-03-29 01:46:28,099: time cost, forward:0.18021876187152389, backward:0.03705178754257772, data cost:0.2623854424175126 
2022-03-29 01:46:28,100: ============================================================
2022-03-29 01:46:28,100: Epoch 40/45 Batch 6400/7662 eta: 5:30:42.351250	Training Loss 0.4366 (0.4313)	Training Prec@1 90.430 (92.153)	Training Prec@5 93.750 (95.128)	
2022-03-29 01:46:28,100: ============================================================
2022-03-29 01:47:13,428: time cost, forward:0.1797498356545773, backward:0.03701835130614342, data cost:0.26245959429837024 
2022-03-29 01:47:13,429: ============================================================
2022-03-29 01:47:13,429: Epoch 40/45 Batch 6500/7662 eta: 4:58:12.681347	Training Loss 0.4181 (0.4312)	Training Prec@1 93.750 (92.153)	Training Prec@5 96.875 (95.128)	
2022-03-29 01:47:13,429: ============================================================
2022-03-29 01:48:01,388: time cost, forward:0.17979214863084197, backward:0.03699818277452945, data cost:0.2624302014092059 
2022-03-29 01:48:01,389: ============================================================
2022-03-29 01:48:01,389: Epoch 40/45 Batch 6600/7662 eta: 5:14:43.337939	Training Loss 0.4324 (0.4313)	Training Prec@1 92.188 (92.152)	Training Prec@5 95.703 (95.128)	
2022-03-29 01:48:01,389: ============================================================
2022-03-29 01:48:48,599: time cost, forward:0.1797427584794337, backward:0.03698624865584168, data cost:0.26238034885131456 
2022-03-29 01:48:48,599: ============================================================
2022-03-29 01:48:48,599: Epoch 40/45 Batch 6700/7662 eta: 5:09:00.888092	Training Loss 0.4309 (0.4313)	Training Prec@1 92.188 (92.153)	Training Prec@5 95.703 (95.130)	
2022-03-29 01:48:48,599: ============================================================
2022-03-29 01:49:35,146: time cost, forward:0.1792727664807804, backward:0.03694711774390381, data cost:0.2626811401828946 
2022-03-29 01:49:35,147: ============================================================
2022-03-29 01:49:35,147: Epoch 40/45 Batch 6800/7662 eta: 5:03:54.065396	Training Loss 0.4238 (0.4312)	Training Prec@1 91.992 (92.152)	Training Prec@5 94.531 (95.132)	
2022-03-29 01:49:35,147: ============================================================
2022-03-29 01:50:22,755: time cost, forward:0.17920407832126753, backward:0.03692947651859919, data cost:0.2627339477140949 
2022-03-29 01:50:22,770: ============================================================
2022-03-29 01:50:22,771: Epoch 40/45 Batch 6900/7662 eta: 5:10:08.019070	Training Loss 0.4325 (0.4312)	Training Prec@1 93.750 (92.152)	Training Prec@5 95.703 (95.132)	
2022-03-29 01:50:22,771: ============================================================
2022-03-29 01:51:07,856: time cost, forward:0.17841569981177818, backward:0.036859196583736556, data cost:0.26317890549850625 
2022-03-29 01:51:07,868: ============================================================
2022-03-29 01:51:07,868: Epoch 40/45 Batch 7000/7662 eta: 4:52:55.842483	Training Loss 0.4370 (0.4312)	Training Prec@1 90.625 (92.150)	Training Prec@5 94.336 (95.131)	
2022-03-29 01:51:07,868: ============================================================
2022-03-29 01:51:55,402: time cost, forward:0.17827889512568934, backward:0.03685097268541559, data cost:0.2632637780591591 
2022-03-29 01:51:55,403: ============================================================
2022-03-29 01:51:55,403: Epoch 40/45 Batch 7100/7662 eta: 5:07:58.225902	Training Loss 0.4386 (0.4312)	Training Prec@1 91.406 (92.151)	Training Prec@5 93.945 (95.132)	
2022-03-29 01:51:55,403: ============================================================
2022-03-29 01:52:45,496: time cost, forward:0.1786924028482714, backward:0.03685765916199332, data cost:0.26313294584775304 
2022-03-29 01:52:45,497: ============================================================
2022-03-29 01:52:45,497: Epoch 40/45 Batch 7200/7662 eta: 5:23:42.969307	Training Loss 0.4382 (0.4312)	Training Prec@1 90.430 (92.153)	Training Prec@5 95.117 (95.132)	
2022-03-29 01:52:45,497: ============================================================
2022-03-29 01:53:31,575: time cost, forward:0.178309237112622, backward:0.03683964349354991, data cost:0.2632747478461589 
2022-03-29 01:53:31,576: ============================================================
2022-03-29 01:53:31,576: Epoch 40/45 Batch 7300/7662 eta: 4:57:00.086212	Training Loss 0.4309 (0.4312)	Training Prec@1 90.820 (92.152)	Training Prec@5 94.336 (95.131)	
2022-03-29 01:53:31,576: ============================================================
2022-03-29 01:54:18,762: time cost, forward:0.17811295634621718, backward:0.0368381675022134, data cost:0.26339119182178855 
2022-03-29 01:54:18,763: ============================================================
2022-03-29 01:54:18,763: Epoch 40/45 Batch 7400/7662 eta: 5:03:21.516384	Training Loss 0.4357 (0.4312)	Training Prec@1 91.602 (92.153)	Training Prec@5 94.531 (95.130)	
2022-03-29 01:54:18,763: ============================================================
2022-03-29 01:55:09,421: time cost, forward:0.17860505723654388, backward:0.036890148941652504, data cost:0.26321742257717085 
2022-03-29 01:55:09,421: ============================================================
2022-03-29 01:55:09,421: Epoch 40/45 Batch 7500/7662 eta: 5:24:49.782589	Training Loss 0.4291 (0.4312)	Training Prec@1 91.211 (92.150)	Training Prec@5 94.141 (95.129)	
2022-03-29 01:55:09,421: ============================================================
2022-03-29 01:55:57,041: time cost, forward:0.17881055602369725, backward:0.036931477717497364, data cost:0.26291864362888107 
2022-03-29 01:55:57,041: ============================================================
2022-03-29 01:55:57,042: Epoch 40/45 Batch 7600/7662 eta: 5:04:33.276260	Training Loss 0.4251 (0.4312)	Training Prec@1 93.359 (92.151)	Training Prec@5 96.289 (95.128)	
2022-03-29 01:55:57,042: ============================================================
2022-03-29 01:56:28,806: Epoch: 40/45 eta: 5:04:03.275572	Training Loss 0.4243 (0.4312)	Training Prec@1 92.578 (92.150)	Training Prec@5 95.898 (95.127)
2022-03-29 01:56:28,806: ============================================================
2022-03-29 01:56:28,809: Save Checkpoint...
2022-03-29 01:56:28,810: ============================================================
2022-03-29 01:56:30,799: Save done!
2022-03-29 01:56:30,799: ============================================================
2022-03-29 01:57:17,678: time cost, forward:0.16638827564740422, backward:0.03924057941244106, data cost:0.26480393457894374 
2022-03-29 01:57:17,679: ============================================================
2022-03-29 01:57:17,679: Epoch 41/45 Batch 100/7662 eta: 4:58:22.477422	Training Loss 0.4443 (0.4319)	Training Prec@1 89.453 (92.081)	Training Prec@5 93.555 (95.129)	
2022-03-29 01:57:17,679: ============================================================
2022-03-29 01:58:04,745: time cost, forward:0.16168758018531992, backward:0.03958307438759349, data cost:0.26874557092561197 
2022-03-29 01:58:04,745: ============================================================
2022-03-29 01:58:04,746: Epoch 41/45 Batch 200/7662 eta: 4:58:57.532786	Training Loss 0.4290 (0.4317)	Training Prec@1 93.164 (92.090)	Training Prec@5 95.898 (95.128)	
2022-03-29 01:58:04,746: ============================================================
2022-03-29 01:58:53,214: time cost, forward:0.16865819433461066, backward:0.040809726236655956, data cost:0.2653205059842521 
2022-03-29 01:58:53,215: ============================================================
2022-03-29 01:58:53,216: Epoch 41/45 Batch 300/7662 eta: 5:07:03.963973	Training Loss 0.4376 (0.4316)	Training Prec@1 94.336 (92.037)	Training Prec@5 95.703 (95.049)	
2022-03-29 01:58:53,216: ============================================================
2022-03-29 01:59:43,982: time cost, forward:0.18554888512556417, backward:0.04216353755845761, data cost:0.25524805721483734 
2022-03-29 01:59:43,982: ============================================================
2022-03-29 01:59:43,982: Epoch 41/45 Batch 400/7662 eta: 5:20:46.031503	Training Loss 0.4324 (0.4313)	Training Prec@1 91.797 (92.081)	Training Prec@5 95.117 (95.096)	
2022-03-29 01:59:43,982: ============================================================
2022-03-29 02:00:30,023: time cost, forward:0.17729935330713917, backward:0.041248176762001786, data cost:0.2598519459038316 
2022-03-29 02:00:30,035: ============================================================
2022-03-29 02:00:30,035: Epoch 41/45 Batch 500/7662 eta: 4:50:13.099459	Training Loss 0.4288 (0.4312)	Training Prec@1 90.820 (92.132)	Training Prec@5 93.945 (95.118)	
2022-03-29 02:00:30,035: ============================================================
2022-03-29 02:01:19,045: time cost, forward:0.1830160187958477, backward:0.0415121561696812, data cost:0.2555843732989889 
2022-03-29 02:01:19,046: ============================================================
2022-03-29 02:01:19,046: Epoch 41/45 Batch 600/7662 eta: 5:08:02.502305	Training Loss 0.4255 (0.4314)	Training Prec@1 94.336 (92.137)	Training Prec@5 95.703 (95.127)	
2022-03-29 02:01:19,046: ============================================================
2022-03-29 02:02:07,315: time cost, forward:0.18388978572021397, backward:0.04157223994810353, data cost:0.2549875928608645 
2022-03-29 02:02:07,325: ============================================================
2022-03-29 02:02:07,326: Epoch 41/45 Batch 700/7662 eta: 5:02:38.397278	Training Loss 0.4227 (0.4314)	Training Prec@1 92.773 (92.138)	Training Prec@5 94.922 (95.151)	
2022-03-29 02:02:07,326: ============================================================
2022-03-29 02:02:53,471: time cost, forward:0.18024070152502333, backward:0.04119668406747906, data cost:0.2565772798989383 
2022-03-29 02:02:53,482: ============================================================
2022-03-29 02:02:53,483: Epoch 41/45 Batch 800/7662 eta: 4:48:33.930562	Training Loss 0.4266 (0.4313)	Training Prec@1 91.797 (92.170)	Training Prec@5 95.312 (95.158)	
2022-03-29 02:02:53,483: ============================================================
2022-03-29 02:03:43,945: time cost, forward:0.1837703354234027, backward:0.04158362769444076, data cost:0.25554770277657685 
2022-03-29 02:03:43,946: ============================================================
2022-03-29 02:03:43,946: Epoch 41/45 Batch 900/7662 eta: 5:14:38.892144	Training Loss 0.4463 (0.4312)	Training Prec@1 89.844 (92.162)	Training Prec@5 93.945 (95.147)	
2022-03-29 02:03:43,946: ============================================================
2022-03-29 02:04:31,285: time cost, forward:0.18358748286097376, backward:0.04144914157397754, data cost:0.2549421314720635 
2022-03-29 02:04:31,285: ============================================================
2022-03-29 02:04:31,286: Epoch 41/45 Batch 1000/7662 eta: 4:54:22.885394	Training Loss 0.4276 (0.4310)	Training Prec@1 92.383 (92.175)	Training Prec@5 96.094 (95.150)	
2022-03-29 02:04:31,286: ============================================================
2022-03-29 02:05:18,973: time cost, forward:0.18245600591039962, backward:0.04123070198801889, data cost:0.25595542189204984 
2022-03-29 02:05:18,974: ============================================================
2022-03-29 02:05:18,974: Epoch 41/45 Batch 1100/7662 eta: 4:55:45.327608	Training Loss 0.4271 (0.4312)	Training Prec@1 91.602 (92.173)	Training Prec@5 94.922 (95.144)	
2022-03-29 02:05:18,974: ============================================================
2022-03-29 02:06:05,384: time cost, forward:0.17955664637886157, backward:0.04065112514829914, data cost:0.2581097073511246 
2022-03-29 02:06:05,396: ============================================================
2022-03-29 02:06:05,397: Epoch 41/45 Batch 1200/7662 eta: 4:47:07.794566	Training Loss 0.4280 (0.4312)	Training Prec@1 94.727 (92.165)	Training Prec@5 96.289 (95.142)	
2022-03-29 02:06:05,397: ============================================================
2022-03-29 02:06:53,815: time cost, forward:0.17931426186300958, backward:0.040610844397012597, data cost:0.25887390849588465 
2022-03-29 02:06:53,815: ============================================================
2022-03-29 02:06:53,816: Epoch 41/45 Batch 1300/7662 eta: 4:58:40.418620	Training Loss 0.4370 (0.4312)	Training Prec@1 92.188 (92.163)	Training Prec@5 94.727 (95.149)	
2022-03-29 02:06:53,816: ============================================================
2022-03-29 02:07:44,337: time cost, forward:0.18280560736830018, backward:0.04114208995145589, data cost:0.25659202626128125 
2022-03-29 02:07:44,338: ============================================================
2022-03-29 02:07:44,338: Epoch 41/45 Batch 1400/7662 eta: 5:10:48.246378	Training Loss 0.4377 (0.4312)	Training Prec@1 93.164 (92.163)	Training Prec@5 96.094 (95.151)	
2022-03-29 02:07:44,338: ============================================================
2022-03-29 02:08:31,765: time cost, forward:0.18150102845663385, backward:0.041086879390490064, data cost:0.2575240149507529 
2022-03-29 02:08:31,774: ============================================================
2022-03-29 02:08:31,774: Epoch 41/45 Batch 1500/7662 eta: 4:51:01.843898	Training Loss 0.4203 (0.4312)	Training Prec@1 94.336 (92.146)	Training Prec@5 96.484 (95.141)	
2022-03-29 02:08:31,774: ============================================================
2022-03-29 02:09:19,288: time cost, forward:0.18121610185815215, backward:0.04101158992583637, data cost:0.2575272813001374 
2022-03-29 02:09:19,288: ============================================================
2022-03-29 02:09:19,288: Epoch 41/45 Batch 1600/7662 eta: 4:50:42.776467	Training Loss 0.4282 (0.4312)	Training Prec@1 91.992 (92.151)	Training Prec@5 95.898 (95.146)	
2022-03-29 02:09:19,288: ============================================================
2022-03-29 02:10:08,180: time cost, forward:0.18340689985804026, backward:0.04118405053586101, data cost:0.255575262146041 
2022-03-29 02:10:08,181: ============================================================
2022-03-29 02:10:08,181: Epoch 41/45 Batch 1700/7662 eta: 4:58:20.088313	Training Loss 0.4289 (0.4312)	Training Prec@1 93.555 (92.141)	Training Prec@5 96.289 (95.144)	
2022-03-29 02:10:08,181: ============================================================
2022-03-29 02:10:55,629: time cost, forward:0.18327596453973624, backward:0.04102935798967328, data cost:0.2555839649633012 
2022-03-29 02:10:55,630: ============================================================
2022-03-29 02:10:55,630: Epoch 41/45 Batch 1800/7662 eta: 4:48:44.105304	Training Loss 0.4251 (0.4312)	Training Prec@1 92.383 (92.148)	Training Prec@5 95.312 (95.148)	
2022-03-29 02:10:55,630: ============================================================
2022-03-29 02:11:41,288: time cost, forward:0.18174439169595968, backward:0.040735660947706274, data cost:0.2561423852608165 
2022-03-29 02:11:41,289: ============================================================
2022-03-29 02:11:41,289: Epoch 41/45 Batch 1900/7662 eta: 4:37:04.989872	Training Loss 0.4207 (0.4312)	Training Prec@1 93.359 (92.143)	Training Prec@5 96.094 (95.139)	
2022-03-29 02:11:41,289: ============================================================
2022-03-29 02:12:27,817: time cost, forward:0.18115403283650186, backward:0.040581003196720124, data cost:0.25616777855614054 
2022-03-29 02:12:27,817: ============================================================
2022-03-29 02:12:27,818: Epoch 41/45 Batch 2000/7662 eta: 4:41:35.012145	Training Loss 0.4294 (0.4313)	Training Prec@1 92.383 (92.147)	Training Prec@5 96.094 (95.139)	
2022-03-29 02:12:27,818: ============================================================
2022-03-29 02:13:14,563: time cost, forward:0.18027161188838936, backward:0.040445388641284725, data cost:0.2566485266392432 
2022-03-29 02:13:14,563: ============================================================
2022-03-29 02:13:14,563: Epoch 41/45 Batch 2100/7662 eta: 4:42:07.070103	Training Loss 0.4334 (0.4313)	Training Prec@1 91.797 (92.143)	Training Prec@5 94.922 (95.136)	
2022-03-29 02:13:14,563: ============================================================
2022-03-29 02:14:03,471: time cost, forward:0.1800859733406334, backward:0.040321132929664466, data cost:0.2574700099221681 
2022-03-29 02:14:03,471: ============================================================
2022-03-29 02:14:03,471: Epoch 41/45 Batch 2200/7662 eta: 4:54:21.182427	Training Loss 0.4220 (0.4313)	Training Prec@1 93.750 (92.142)	Training Prec@5 95.508 (95.131)	
2022-03-29 02:14:03,471: ============================================================
2022-03-29 02:14:50,340: time cost, forward:0.17897699749329754, backward:0.040139714029883755, data cost:0.25832064331174154 
2022-03-29 02:14:50,340: ============================================================
2022-03-29 02:14:50,340: Epoch 41/45 Batch 2300/7662 eta: 4:41:18.010857	Training Loss 0.4280 (0.4313)	Training Prec@1 92.773 (92.139)	Training Prec@5 94.727 (95.130)	
2022-03-29 02:14:50,341: ============================================================
2022-03-29 02:15:36,437: time cost, forward:0.17764773156156932, backward:0.03996976826180016, data cost:0.2590978987369005 
2022-03-29 02:15:36,438: ============================================================
2022-03-29 02:15:36,438: Epoch 41/45 Batch 2400/7662 eta: 4:35:54.066834	Training Loss 0.4344 (0.4314)	Training Prec@1 91.406 (92.139)	Training Prec@5 94.336 (95.129)	
2022-03-29 02:15:36,438: ============================================================
2022-03-29 02:16:26,237: time cost, forward:0.17909987032914362, backward:0.04022504110820964, data cost:0.2582579816327471 
2022-03-29 02:16:26,238: ============================================================
2022-03-29 02:16:26,238: Epoch 41/45 Batch 2500/7662 eta: 4:57:13.896254	Training Loss 0.4320 (0.4314)	Training Prec@1 90.820 (92.136)	Training Prec@5 93.945 (95.128)	
2022-03-29 02:16:26,238: ============================================================
2022-03-29 02:17:14,182: time cost, forward:0.17958253463812635, backward:0.04015855616723266, data cost:0.25787994548787335 
2022-03-29 02:17:14,182: ============================================================
2022-03-29 02:17:14,182: Epoch 41/45 Batch 2600/7662 eta: 4:45:21.323051	Training Loss 0.4311 (0.4314)	Training Prec@1 91.797 (92.139)	Training Prec@5 96.289 (95.127)	
2022-03-29 02:17:14,182: ============================================================
2022-03-29 02:17:59,031: time cost, forward:0.17758550004369023, backward:0.0399569870587321, data cost:0.258946617959649 
2022-03-29 02:17:59,032: ============================================================
2022-03-29 02:17:59,032: Epoch 41/45 Batch 2700/7662 eta: 4:26:11.539919	Training Loss 0.4349 (0.4314)	Training Prec@1 90.625 (92.137)	Training Prec@5 95.117 (95.126)	
2022-03-29 02:17:59,032: ============================================================
2022-03-29 02:18:49,438: time cost, forward:0.17921350197350822, backward:0.04003767875229814, data cost:0.25818705558776855 
2022-03-29 02:18:49,450: ============================================================
2022-03-29 02:18:49,450: Epoch 41/45 Batch 2800/7662 eta: 4:58:23.842335	Training Loss 0.4317 (0.4314)	Training Prec@1 93.750 (92.135)	Training Prec@5 96.094 (95.121)	
2022-03-29 02:18:49,450: ============================================================
2022-03-29 02:19:36,637: time cost, forward:0.1794305053321441, backward:0.039975355723349135, data cost:0.2577180050701551 
2022-03-29 02:19:36,638: ============================================================
2022-03-29 02:19:36,638: Epoch 41/45 Batch 2900/7662 eta: 4:38:29.758286	Training Loss 0.4329 (0.4314)	Training Prec@1 91.992 (92.136)	Training Prec@5 94.531 (95.121)	
2022-03-29 02:19:36,638: ============================================================
2022-03-29 02:20:21,162: time cost, forward:0.17738199456606996, backward:0.0397035153399471, data cost:0.25905329754210266 
2022-03-29 02:20:21,163: ============================================================
2022-03-29 02:20:21,163: Epoch 41/45 Batch 3000/7662 eta: 4:22:02.170166	Training Loss 0.4359 (0.4314)	Training Prec@1 92.383 (92.138)	Training Prec@5 95.898 (95.122)	
2022-03-29 02:20:21,163: ============================================================
2022-03-29 02:21:11,316: time cost, forward:0.17855451806355538, backward:0.039724593164075304, data cost:0.2586606793651353 
2022-03-29 02:21:11,316: ============================================================
2022-03-29 02:21:11,316: Epoch 41/45 Batch 3100/7662 eta: 4:54:19.480914	Training Loss 0.4406 (0.4314)	Training Prec@1 93.750 (92.139)	Training Prec@5 95.117 (95.124)	
2022-03-29 02:21:11,316: ============================================================
2022-03-29 02:21:57,942: time cost, forward:0.1776884913109138, backward:0.039660567825904075, data cost:0.25923571433078946 
2022-03-29 02:21:57,942: ============================================================
2022-03-29 02:21:57,942: Epoch 41/45 Batch 3200/7662 eta: 4:32:51.005347	Training Loss 0.4230 (0.4314)	Training Prec@1 93.359 (92.142)	Training Prec@5 96.094 (95.127)	
2022-03-29 02:21:57,943: ============================================================
2022-03-29 02:22:44,558: time cost, forward:0.17722437308751732, backward:0.039598237965893984, data cost:0.2593914210055589 
2022-03-29 02:22:44,558: ============================================================
2022-03-29 02:22:44,558: Epoch 41/45 Batch 3300/7662 eta: 4:32:00.658789	Training Loss 0.4255 (0.4313)	Training Prec@1 92.969 (92.141)	Training Prec@5 94.141 (95.126)	
2022-03-29 02:22:44,558: ============================================================
2022-03-29 02:23:32,968: time cost, forward:0.17734360175821562, backward:0.03950929192803684, data cost:0.2595879144267357 
2022-03-29 02:23:32,969: ============================================================
2022-03-29 02:23:32,969: Epoch 41/45 Batch 3400/7662 eta: 4:41:40.621052	Training Loss 0.4346 (0.4313)	Training Prec@1 92.188 (92.137)	Training Prec@5 95.117 (95.119)	
2022-03-29 02:23:32,969: ============================================================
2022-03-29 02:24:19,742: time cost, forward:0.17763319884957365, backward:0.03944706003745647, data cost:0.25909518500538203 
2022-03-29 02:24:19,742: ============================================================
2022-03-29 02:24:19,742: Epoch 41/45 Batch 3500/7662 eta: 4:31:22.352288	Training Loss 0.4439 (0.4313)	Training Prec@1 89.062 (92.138)	Training Prec@5 92.773 (95.119)	
2022-03-29 02:24:19,743: ============================================================
2022-03-29 02:25:04,043: time cost, forward:0.1763852333552177, backward:0.03929784609960761, data cost:0.2595157621303642 
2022-03-29 02:25:04,044: ============================================================
2022-03-29 02:25:04,044: Epoch 41/45 Batch 3600/7662 eta: 4:16:17.559155	Training Loss 0.4239 (0.4314)	Training Prec@1 91.797 (92.134)	Training Prec@5 94.727 (95.114)	
2022-03-29 02:25:04,045: ============================================================
2022-03-29 02:25:49,630: time cost, forward:0.1748970153686903, backward:0.03916466439147355, data cost:0.260615057093158 
2022-03-29 02:25:49,630: ============================================================
2022-03-29 02:25:49,631: Epoch 41/45 Batch 3700/7662 eta: 4:22:57.927069	Training Loss 0.4298 (0.4314)	Training Prec@1 91.797 (92.135)	Training Prec@5 95.117 (95.115)	
2022-03-29 02:25:49,631: ============================================================
2022-03-29 02:26:35,494: time cost, forward:0.17373914227858442, backward:0.03905607907826664, data cost:0.26146862280309185 
2022-03-29 02:26:35,495: ============================================================
2022-03-29 02:26:35,495: Epoch 41/45 Batch 3800/7662 eta: 4:23:48.177481	Training Loss 0.4363 (0.4313)	Training Prec@1 91.406 (92.135)	Training Prec@5 94.531 (95.116)	
2022-03-29 02:26:35,495: ============================================================
2022-03-29 02:27:22,910: time cost, forward:0.17354721850571067, backward:0.03898299721822766, data cost:0.2616961690883632 
2022-03-29 02:27:22,911: ============================================================
2022-03-29 02:27:22,911: Epoch 41/45 Batch 3900/7662 eta: 4:31:56.317589	Training Loss 0.4263 (0.4313)	Training Prec@1 94.531 (92.138)	Training Prec@5 97.656 (95.119)	
2022-03-29 02:27:22,911: ============================================================
2022-03-29 02:28:10,431: time cost, forward:0.17382196105399947, backward:0.03888049039819235, data cost:0.26150343047883934 
2022-03-29 02:28:10,431: ============================================================
2022-03-29 02:28:10,432: Epoch 41/45 Batch 4000/7662 eta: 4:31:44.865408	Training Loss 0.4300 (0.4313)	Training Prec@1 91.797 (92.140)	Training Prec@5 94.727 (95.117)	
2022-03-29 02:28:10,432: ============================================================
2022-03-29 02:28:55,045: time cost, forward:0.1723303048603126, backward:0.03878272885548019, data cost:0.2623969111450709 
2022-03-29 02:28:55,045: ============================================================
2022-03-29 02:28:55,045: Epoch 41/45 Batch 4100/7662 eta: 4:14:22.787086	Training Loss 0.4296 (0.4313)	Training Prec@1 92.578 (92.135)	Training Prec@5 95.703 (95.118)	
2022-03-29 02:28:55,045: ============================================================
2022-03-29 02:29:40,869: time cost, forward:0.17134773501273307, backward:0.03868259949807923, data cost:0.26310482198892815 
2022-03-29 02:29:40,869: ============================================================
2022-03-29 02:29:40,870: Epoch 41/45 Batch 4200/7662 eta: 4:20:31.130731	Training Loss 0.4335 (0.4313)	Training Prec@1 91.406 (92.136)	Training Prec@5 94.531 (95.118)	
2022-03-29 02:29:40,870: ============================================================
2022-03-29 02:30:29,974: time cost, forward:0.17126675482876608, backward:0.03856163613877759, data cost:0.26373740688926484 
2022-03-29 02:30:29,974: ============================================================
2022-03-29 02:30:29,975: Epoch 41/45 Batch 4300/7662 eta: 4:38:21.114774	Training Loss 0.4386 (0.4313)	Training Prec@1 89.648 (92.136)	Training Prec@5 92.773 (95.118)	
2022-03-29 02:30:29,975: ============================================================
2022-03-29 02:31:15,006: time cost, forward:0.1700020952369983, backward:0.03843842915281108, data cost:0.2645640844213716 
2022-03-29 02:31:15,007: ============================================================
2022-03-29 02:31:15,007: Epoch 41/45 Batch 4400/7662 eta: 4:14:30.835337	Training Loss 0.4427 (0.4313)	Training Prec@1 91.016 (92.139)	Training Prec@5 94.141 (95.124)	
2022-03-29 02:31:15,007: ============================================================
2022-03-29 02:32:00,599: time cost, forward:0.16929312010928507, backward:0.038336664868821355, data cost:0.26498493768819625 
2022-03-29 02:32:00,599: ============================================================
2022-03-29 02:32:00,599: Epoch 41/45 Batch 4500/7662 eta: 4:16:55.293627	Training Loss 0.4391 (0.4313)	Training Prec@1 91.016 (92.139)	Training Prec@5 94.336 (95.123)	
2022-03-29 02:32:00,600: ============================================================
2022-03-29 02:32:46,161: time cost, forward:0.1685808147651057, backward:0.038195830268635905, data cost:0.2654789712382908 
2022-03-29 02:32:46,162: ============================================================
2022-03-29 02:32:46,162: Epoch 41/45 Batch 4600/7662 eta: 4:15:59.690514	Training Loss 0.4243 (0.4313)	Training Prec@1 93.359 (92.142)	Training Prec@5 96.094 (95.125)	
2022-03-29 02:32:46,162: ============================================================
2022-03-29 02:33:35,794: time cost, forward:0.16974388875715732, backward:0.03820885174019232, data cost:0.2648011372682515 
2022-03-29 02:33:35,794: ============================================================
2022-03-29 02:33:35,795: Epoch 41/45 Batch 4700/7662 eta: 4:38:01.947819	Training Loss 0.4372 (0.4313)	Training Prec@1 93.164 (92.143)	Training Prec@5 95.703 (95.128)	
2022-03-29 02:33:35,795: ============================================================
2022-03-29 02:34:23,311: time cost, forward:0.16997270704334194, backward:0.038229063218473074, data cost:0.2645850173630648 
2022-03-29 02:34:23,312: ============================================================
2022-03-29 02:34:23,313: Epoch 41/45 Batch 4800/7662 eta: 4:25:23.751190	Training Loss 0.4116 (0.4312)	Training Prec@1 92.578 (92.146)	Training Prec@5 95.703 (95.131)	
2022-03-29 02:34:23,313: ============================================================
2022-03-29 02:35:14,688: time cost, forward:0.17119741400885907, backward:0.03832187446240723, data cost:0.26408435739189 
2022-03-29 02:35:14,698: ============================================================
2022-03-29 02:35:14,698: Epoch 41/45 Batch 4900/7662 eta: 4:46:08.531744	Training Loss 0.4235 (0.4313)	Training Prec@1 92.188 (92.146)	Training Prec@5 94.531 (95.131)	
2022-03-29 02:35:14,699: ============================================================
2022-03-29 02:36:02,537: time cost, forward:0.17125283038289482, backward:0.03830641907533423, data cost:0.26411765111544344 
2022-03-29 02:36:02,538: ============================================================
2022-03-29 02:36:02,538: Epoch 41/45 Batch 5000/7662 eta: 4:25:35.744271	Training Loss 0.4323 (0.4313)	Training Prec@1 90.625 (92.148)	Training Prec@5 96.094 (95.133)	
2022-03-29 02:36:02,538: ============================================================
2022-03-29 02:36:50,793: time cost, forward:0.1711798766753935, backward:0.038258957287731724, data cost:0.26441236345598246 
2022-03-29 02:36:50,805: ============================================================
2022-03-29 02:36:50,806: Epoch 41/45 Batch 5100/7662 eta: 4:27:10.385448	Training Loss 0.4358 (0.4313)	Training Prec@1 92.578 (92.143)	Training Prec@5 95.703 (95.129)	
2022-03-29 02:36:50,806: ============================================================
2022-03-29 02:37:40,531: time cost, forward:0.17157938590896293, backward:0.03831370813751661, data cost:0.2644007322443841 
2022-03-29 02:37:40,542: ============================================================
2022-03-29 02:37:40,542: Epoch 41/45 Batch 5200/7662 eta: 4:34:28.143977	Training Loss 0.4240 (0.4313)	Training Prec@1 91.602 (92.142)	Training Prec@5 96.289 (95.128)	
2022-03-29 02:37:40,542: ============================================================
2022-03-29 02:38:32,538: time cost, forward:0.17257148770931466, backward:0.03842763924153262, data cost:0.2641115049569871 
2022-03-29 02:38:32,538: ============================================================
2022-03-29 02:38:32,539: Epoch 41/45 Batch 5300/7662 eta: 4:46:04.504254	Training Loss 0.4332 (0.4313)	Training Prec@1 93.164 (92.146)	Training Prec@5 95.312 (95.130)	
2022-03-29 02:38:32,539: ============================================================
2022-03-29 02:39:18,252: time cost, forward:0.17198336409250659, backward:0.038356039784179397, data cost:0.26443743502614586 
2022-03-29 02:39:18,252: ============================================================
2022-03-29 02:39:18,252: Epoch 41/45 Batch 5400/7662 eta: 4:10:44.806793	Training Loss 0.4252 (0.4313)	Training Prec@1 91.992 (92.142)	Training Prec@5 95.312 (95.129)	
2022-03-29 02:39:18,252: ============================================================
2022-03-29 02:40:05,767: time cost, forward:0.1719534505517033, backward:0.03835884812398919, data cost:0.2644459111709165 
2022-03-29 02:40:05,768: ============================================================
2022-03-29 02:40:05,769: Epoch 41/45 Batch 5500/7662 eta: 4:19:50.618318	Training Loss 0.4212 (0.4313)	Training Prec@1 93.359 (92.141)	Training Prec@5 95.508 (95.126)	
2022-03-29 02:40:05,769: ============================================================
2022-03-29 02:40:52,365: time cost, forward:0.1715594610373321, backward:0.03830451840991569, data cost:0.26473801526497 
2022-03-29 02:40:52,365: ============================================================
2022-03-29 02:40:52,365: Epoch 41/45 Batch 5600/7662 eta: 4:14:02.188888	Training Loss 0.4224 (0.4313)	Training Prec@1 93.945 (92.141)	Training Prec@5 95.898 (95.127)	
2022-03-29 02:40:52,365: ============================================================
2022-03-29 02:41:40,943: time cost, forward:0.17177294053243197, backward:0.03828509269335496, data cost:0.2647180854280615 
2022-03-29 02:41:40,943: ============================================================
2022-03-29 02:41:40,944: Epoch 41/45 Batch 5700/7662 eta: 4:24:01.896781	Training Loss 0.4293 (0.4313)	Training Prec@1 89.844 (92.140)	Training Prec@5 93.750 (95.126)	
2022-03-29 02:41:40,944: ============================================================
2022-03-29 02:42:27,076: time cost, forward:0.1717241505627633, backward:0.03827925738969287, data cost:0.2645364749182872 
2022-03-29 02:42:27,076: ============================================================
2022-03-29 02:42:27,076: Epoch 41/45 Batch 5800/7662 eta: 4:09:58.235106	Training Loss 0.4314 (0.4313)	Training Prec@1 92.188 (92.139)	Training Prec@5 94.531 (95.126)	
2022-03-29 02:42:27,077: ============================================================
2022-03-29 02:43:12,152: time cost, forward:0.17113632702346493, backward:0.03820926061139751, data cost:0.2647890022072191 
2022-03-29 02:43:12,152: ============================================================
2022-03-29 02:43:12,152: Epoch 41/45 Batch 5900/7662 eta: 4:03:29.518369	Training Loss 0.4326 (0.4313)	Training Prec@1 92.578 (92.139)	Training Prec@5 95.703 (95.126)	
2022-03-29 02:43:12,152: ============================================================
2022-03-29 02:44:00,687: time cost, forward:0.1715325127245685, backward:0.03817990176338695, data cost:0.26459470516960903 
2022-03-29 02:44:00,687: ============================================================
2022-03-29 02:44:00,687: Epoch 41/45 Batch 6000/7662 eta: 4:21:22.207663	Training Loss 0.4314 (0.4313)	Training Prec@1 91.406 (92.141)	Training Prec@5 95.117 (95.129)	
2022-03-29 02:44:00,688: ============================================================
2022-03-29 02:44:47,158: time cost, forward:0.17149630936076746, backward:0.03815180431684327, data cost:0.2644906973991263 
2022-03-29 02:44:47,158: ============================================================
2022-03-29 02:44:47,158: Epoch 41/45 Batch 6100/7662 eta: 4:09:28.669813	Training Loss 0.4314 (0.4313)	Training Prec@1 90.625 (92.139)	Training Prec@5 94.336 (95.127)	
2022-03-29 02:44:47,158: ============================================================
2022-03-29 02:45:32,371: time cost, forward:0.17082042316406615, backward:0.03810435957554022, data cost:0.26484499690724606 
2022-03-29 02:45:32,372: ============================================================
2022-03-29 02:45:32,372: Epoch 41/45 Batch 6200/7662 eta: 4:01:58.572373	Training Loss 0.4360 (0.4313)	Training Prec@1 91.406 (92.141)	Training Prec@5 93.945 (95.126)	
2022-03-29 02:45:32,372: ============================================================
2022-03-29 02:46:19,402: time cost, forward:0.1707472049124488, backward:0.038046918685217854, data cost:0.264904190574606 
2022-03-29 02:46:19,403: ============================================================
2022-03-29 02:46:19,403: Epoch 41/45 Batch 6300/7662 eta: 4:10:55.214803	Training Loss 0.4486 (0.4313)	Training Prec@1 91.406 (92.142)	Training Prec@5 94.531 (95.126)	
2022-03-29 02:46:19,403: ============================================================
2022-03-29 02:47:09,285: time cost, forward:0.17117863965231955, backward:0.0379984130671591, data cost:0.2649084204974669 
2022-03-29 02:47:09,286: ============================================================
2022-03-29 02:47:09,286: Epoch 41/45 Batch 6400/7662 eta: 4:25:18.051040	Training Loss 0.4359 (0.4313)	Training Prec@1 91.602 (92.142)	Training Prec@5 93.164 (95.127)	
2022-03-29 02:47:09,286: ============================================================
2022-03-29 02:47:55,131: time cost, forward:0.17076023246053734, backward:0.03797837443893956, data cost:0.26509183640662737 
2022-03-29 02:47:55,132: ============================================================
2022-03-29 02:47:55,132: Epoch 41/45 Batch 6500/7662 eta: 4:03:04.168960	Training Loss 0.4273 (0.4313)	Training Prec@1 91.016 (92.144)	Training Prec@5 94.531 (95.127)	
2022-03-29 02:47:55,133: ============================================================
2022-03-29 02:48:41,718: time cost, forward:0.17072137100513388, backward:0.037933673799390194, data cost:0.26504339158742746 
2022-03-29 02:48:41,718: ============================================================
2022-03-29 02:48:41,718: Epoch 41/45 Batch 6600/7662 eta: 4:06:12.899302	Training Loss 0.4237 (0.4313)	Training Prec@1 93.164 (92.146)	Training Prec@5 95.312 (95.128)	
2022-03-29 02:48:41,718: ============================================================
2022-03-29 02:49:32,505: time cost, forward:0.17140299388767624, backward:0.037895369269915845, data cost:0.26483684622506487 
2022-03-29 02:49:32,506: ============================================================
2022-03-29 02:49:32,506: Epoch 41/45 Batch 6700/7662 eta: 4:27:34.446920	Training Loss 0.4432 (0.4313)	Training Prec@1 91.602 (92.145)	Training Prec@5 94.727 (95.127)	
2022-03-29 02:49:32,506: ============================================================
2022-03-29 02:50:16,175: time cost, forward:0.1705600062018371, backward:0.037833770770748884, data cost:0.2652477673141899 
2022-03-29 02:50:16,176: ============================================================
2022-03-29 02:50:16,176: Epoch 41/45 Batch 6800/7662 eta: 3:49:20.903309	Training Loss 0.4303 (0.4313)	Training Prec@1 91.406 (92.146)	Training Prec@5 94.141 (95.128)	
2022-03-29 02:50:16,176: ============================================================
2022-03-29 02:51:05,341: time cost, forward:0.1710116950337965, backward:0.037826630529726325, data cost:0.26506359913432437 
2022-03-29 02:51:05,351: ============================================================
2022-03-29 02:51:05,351: Epoch 41/45 Batch 6900/7662 eta: 4:17:26.365825	Training Loss 0.4275 (0.4313)	Training Prec@1 94.727 (92.145)	Training Prec@5 96.289 (95.128)	
2022-03-29 02:51:05,351: ============================================================
2022-03-29 02:51:55,029: time cost, forward:0.17165821118769706, backward:0.037895578131503356, data cost:0.2646550878420406 
2022-03-29 02:51:55,030: ============================================================
2022-03-29 02:51:55,030: Epoch 41/45 Batch 7000/7662 eta: 4:19:15.008008	Training Loss 0.4272 (0.4313)	Training Prec@1 93.359 (92.145)	Training Prec@5 95.703 (95.129)	
2022-03-29 02:51:55,030: ============================================================
2022-03-29 02:52:43,860: time cost, forward:0.17217113296991335, backward:0.037960723649113765, data cost:0.2642632789520466 
2022-03-29 02:52:43,861: ============================================================
2022-03-29 02:52:43,861: Epoch 41/45 Batch 7100/7662 eta: 4:14:00.590530	Training Loss 0.4298 (0.4313)	Training Prec@1 92.383 (92.146)	Training Prec@5 94.336 (95.129)	
2022-03-29 02:52:43,861: ============================================================
2022-03-29 02:53:31,547: time cost, forward:0.17226577755609707, backward:0.037962377063101044, data cost:0.26419609257671167 
2022-03-29 02:53:31,557: ============================================================
2022-03-29 02:53:31,558: Epoch 41/45 Batch 7200/7662 eta: 4:07:18.920070	Training Loss 0.4384 (0.4313)	Training Prec@1 90.820 (92.148)	Training Prec@5 93.359 (95.129)	
2022-03-29 02:53:31,558: ============================================================
2022-03-29 02:54:18,120: time cost, forward:0.17186036115150646, backward:0.037910412363621256, data cost:0.2645180308666927 
2022-03-29 02:54:18,121: ============================================================
2022-03-29 02:54:18,121: Epoch 41/45 Batch 7300/7662 eta: 4:00:39.708849	Training Loss 0.4315 (0.4312)	Training Prec@1 91.406 (92.147)	Training Prec@5 94.336 (95.127)	
2022-03-29 02:54:18,121: ============================================================
2022-03-29 02:55:08,886: time cost, forward:0.17265910930868128, backward:0.037954481925041486, data cost:0.2641280638332189 
2022-03-29 02:55:08,897: ============================================================
2022-03-29 02:55:08,897: Epoch 41/45 Batch 7400/7662 eta: 4:21:35.342246	Training Loss 0.4260 (0.4312)	Training Prec@1 94.336 (92.149)	Training Prec@5 97.070 (95.128)	
2022-03-29 02:55:08,897: ============================================================
2022-03-29 02:55:55,705: time cost, forward:0.1727521005257366, backward:0.03790185778661479, data cost:0.2639828595277039 
2022-03-29 02:55:55,706: ============================================================
2022-03-29 02:55:55,706: Epoch 41/45 Batch 7500/7662 eta: 4:00:22.381305	Training Loss 0.4357 (0.4312)	Training Prec@1 90.820 (92.146)	Training Prec@5 93.555 (95.125)	
2022-03-29 02:55:55,706: ============================================================
2022-03-29 02:56:43,508: time cost, forward:0.1729598129120355, backward:0.037921619158008256, data cost:0.2637814235210356 
2022-03-29 02:56:43,509: ============================================================
2022-03-29 02:56:43,509: Epoch 41/45 Batch 7600/7662 eta: 4:04:40.755598	Training Loss 0.4369 (0.4312)	Training Prec@1 93.359 (92.148)	Training Prec@5 97.266 (95.126)	
2022-03-29 02:56:43,509: ============================================================
2022-03-29 02:57:15,689: Epoch: 41/45 eta: 4:04:10.639757	Training Loss 0.4251 (0.4312)	Training Prec@1 93.359 (92.150)	Training Prec@5 96.094 (95.127)
2022-03-29 02:57:15,689: ============================================================
2022-03-29 02:57:15,691: Save Checkpoint...
2022-03-29 02:57:15,693: ============================================================
2022-03-29 02:57:17,794: Save done!
2022-03-29 02:57:17,795: ============================================================
2022-03-29 02:58:00,843: time cost, forward:0.10647188533436168, backward:0.035906502694794624, data cost:0.28963112590288875 
2022-03-29 02:58:00,844: ============================================================
2022-03-29 02:58:00,844: Epoch 42/45 Batch 100/7662 eta: 3:39:10.325094	Training Loss 0.4415 (0.4322)	Training Prec@1 89.844 (92.154)	Training Prec@5 92.773 (95.088)	
2022-03-29 02:58:00,844: ============================================================
2022-03-29 02:58:49,745: time cost, forward:0.1593564203636131, backward:0.041038266378431464, data cost:0.25961741131154736 
2022-03-29 02:58:49,745: ============================================================
2022-03-29 02:58:49,746: Epoch 42/45 Batch 200/7662 eta: 4:08:10.059038	Training Loss 0.4341 (0.4326)	Training Prec@1 91.016 (92.107)	Training Prec@5 94.336 (95.061)	
2022-03-29 02:58:49,746: ============================================================
2022-03-29 02:59:38,376: time cost, forward:0.17275491287078348, backward:0.041769953475748016, data cost:0.2543145972350768 
2022-03-29 02:59:38,376: ============================================================
2022-03-29 02:59:38,377: Epoch 42/45 Batch 300/7662 eta: 4:05:59.066269	Training Loss 0.4434 (0.4319)	Training Prec@1 91.211 (92.105)	Training Prec@5 93.750 (95.092)	
2022-03-29 02:59:38,377: ============================================================
2022-03-29 03:00:26,019: time cost, forward:0.17166427860881453, backward:0.041334024945596105, data cost:0.2573756866885307 
2022-03-29 03:00:26,019: ============================================================
2022-03-29 03:00:26,019: Epoch 42/45 Batch 400/7662 eta: 4:00:11.429564	Training Loss 0.4341 (0.4316)	Training Prec@1 91.406 (92.124)	Training Prec@5 93.750 (95.091)	
2022-03-29 03:00:26,019: ============================================================
2022-03-29 03:01:14,305: time cost, forward:0.17335985609906948, backward:0.04035069278342451, data cost:0.2589935190930873 
2022-03-29 03:01:14,306: ============================================================
2022-03-29 03:01:14,307: Epoch 42/45 Batch 500/7662 eta: 4:02:38.126106	Training Loss 0.4290 (0.4314)	Training Prec@1 91.406 (92.163)	Training Prec@5 94.141 (95.109)	
2022-03-29 03:01:14,307: ============================================================
2022-03-29 03:02:04,128: time cost, forward:0.18042071594021755, backward:0.041441711241096406, data cost:0.25505844340698547 
2022-03-29 03:02:04,128: ============================================================
2022-03-29 03:02:04,128: Epoch 42/45 Batch 600/7662 eta: 4:09:30.903820	Training Loss 0.4280 (0.4315)	Training Prec@1 90.234 (92.112)	Training Prec@5 93.555 (95.090)	
2022-03-29 03:02:04,128: ============================================================
2022-03-29 03:02:52,522: time cost, forward:0.17979083586489522, backward:0.041203669382949414, data cost:0.25696978548565647 
2022-03-29 03:02:52,535: ============================================================
2022-03-29 03:02:52,535: Epoch 42/45 Batch 700/7662 eta: 4:01:37.297560	Training Loss 0.4382 (0.4315)	Training Prec@1 92.773 (92.117)	Training Prec@5 95.312 (95.086)	
2022-03-29 03:02:52,535: ============================================================
2022-03-29 03:03:40,619: time cost, forward:0.18186893868953624, backward:0.04103847767444367, data cost:0.2553219404328004 
2022-03-29 03:03:40,620: ============================================================
2022-03-29 03:03:40,620: Epoch 42/45 Batch 800/7662 eta: 3:59:12.912655	Training Loss 0.4329 (0.4315)	Training Prec@1 93.164 (92.132)	Training Prec@5 95.898 (95.105)	
2022-03-29 03:03:40,620: ============================================================
2022-03-29 03:04:28,069: time cost, forward:0.18042568025387434, backward:0.04067715283097892, data cost:0.25665892934109663 
2022-03-29 03:04:28,070: ============================================================
2022-03-29 03:04:28,071: Epoch 42/45 Batch 900/7662 eta: 3:55:15.986691	Training Loss 0.4364 (0.4316)	Training Prec@1 91.016 (92.133)	Training Prec@5 93.750 (95.090)	
2022-03-29 03:04:28,072: ============================================================
2022-03-29 03:05:21,698: time cost, forward:0.18871105421293485, backward:0.042157306327476156, data cost:0.2527421723614942 
2022-03-29 03:05:21,698: ============================================================
2022-03-29 03:05:21,698: Epoch 42/45 Batch 1000/7662 eta: 4:25:00.124797	Training Loss 0.4310 (0.4315)	Training Prec@1 91.602 (92.125)	Training Prec@5 94.727 (95.088)	
2022-03-29 03:05:21,698: ============================================================
2022-03-29 03:06:08,917: time cost, forward:0.1855253069047173, backward:0.04173143241923977, data cost:0.2547482016739572 
2022-03-29 03:06:08,918: ============================================================
2022-03-29 03:06:08,918: Epoch 42/45 Batch 1100/7662 eta: 3:52:32.956297	Training Loss 0.4428 (0.4316)	Training Prec@1 90.430 (92.110)	Training Prec@5 92.773 (95.086)	
2022-03-29 03:06:08,918: ============================================================
2022-03-29 03:06:54,812: time cost, forward:0.1808816473915539, backward:0.04125586900241779, data cost:0.2583201023019086 
2022-03-29 03:06:54,812: ============================================================
2022-03-29 03:06:54,812: Epoch 42/45 Batch 1200/7662 eta: 3:45:15.476295	Training Loss 0.4342 (0.4314)	Training Prec@1 91.406 (92.129)	Training Prec@5 94.336 (95.097)	
2022-03-29 03:06:54,813: ============================================================
2022-03-29 03:07:43,052: time cost, forward:0.18193842210248398, backward:0.04148904647709683, data cost:0.2571992475863509 
2022-03-29 03:07:43,053: ============================================================
2022-03-29 03:07:43,053: Epoch 42/45 Batch 1300/7662 eta: 3:55:58.115253	Training Loss 0.4424 (0.4314)	Training Prec@1 88.477 (92.136)	Training Prec@5 92.773 (95.109)	
2022-03-29 03:07:43,053: ============================================================
2022-03-29 03:08:32,102: time cost, forward:0.18272705994988442, backward:0.04154200363022843, data cost:0.25698398299690994 
2022-03-29 03:08:32,102: ============================================================
2022-03-29 03:08:32,102: Epoch 42/45 Batch 1400/7662 eta: 3:59:06.424305	Training Loss 0.4251 (0.4315)	Training Prec@1 92.188 (92.133)	Training Prec@5 95.117 (95.104)	
2022-03-29 03:08:32,103: ============================================================
2022-03-29 03:09:19,162: time cost, forward:0.18108631675445375, backward:0.04134013336288524, data cost:0.25812861027122735 
2022-03-29 03:09:19,163: ============================================================
2022-03-29 03:09:19,163: Epoch 42/45 Batch 1500/7662 eta: 3:48:37.708484	Training Loss 0.4280 (0.4314)	Training Prec@1 91.211 (92.136)	Training Prec@5 93.945 (95.102)	
2022-03-29 03:09:19,163: ============================================================
2022-03-29 03:10:07,859: time cost, forward:0.1831481039263145, backward:0.041614866912774995, data cost:0.25613424851045974 
2022-03-29 03:10:07,876: ============================================================
2022-03-29 03:10:07,876: Epoch 42/45 Batch 1600/7662 eta: 3:55:50.591460	Training Loss 0.4412 (0.4314)	Training Prec@1 91.797 (92.136)	Training Prec@5 94.336 (95.102)	
2022-03-29 03:10:07,876: ============================================================
2022-03-29 03:10:55,100: time cost, forward:0.18245678259527914, backward:0.04154569377191913, data cost:0.25620629718683974 
2022-03-29 03:10:55,100: ============================================================
2022-03-29 03:10:55,100: Epoch 42/45 Batch 1700/7662 eta: 3:47:51.042643	Training Loss 0.4369 (0.4314)	Training Prec@1 91.016 (92.136)	Training Prec@5 94.336 (95.099)	
2022-03-29 03:10:55,100: ============================================================
2022-03-29 03:11:40,387: time cost, forward:0.180716425793379, backward:0.04130967966114699, data cost:0.2567520625330197 
2022-03-29 03:11:40,387: ============================================================
2022-03-29 03:11:40,387: Epoch 42/45 Batch 1800/7662 eta: 3:37:44.878871	Training Loss 0.4277 (0.4314)	Training Prec@1 92.578 (92.142)	Training Prec@5 95.508 (95.104)	
2022-03-29 03:11:40,388: ============================================================
2022-03-29 03:12:28,998: time cost, forward:0.1800788296342461, backward:0.04114836790236503, data cost:0.25789219458019064 
2022-03-29 03:12:28,998: ============================================================
2022-03-29 03:12:28,998: Epoch 42/45 Batch 1900/7662 eta: 3:52:55.129798	Training Loss 0.4232 (0.4314)	Training Prec@1 93.750 (92.138)	Training Prec@5 95.508 (95.099)	
2022-03-29 03:12:28,998: ============================================================
2022-03-29 03:13:17,127: time cost, forward:0.1810432970076576, backward:0.041172342934925714, data cost:0.25697139085919457 
2022-03-29 03:13:17,127: ============================================================
2022-03-29 03:13:17,128: Epoch 42/45 Batch 2000/7662 eta: 3:49:48.552877	Training Loss 0.4288 (0.4314)	Training Prec@1 93.945 (92.141)	Training Prec@5 95.703 (95.099)	
2022-03-29 03:13:17,128: ============================================================
2022-03-29 03:14:04,189: time cost, forward:0.18035776720778496, backward:0.04113274372549725, data cost:0.25725070552180757 
2022-03-29 03:14:04,189: ============================================================
2022-03-29 03:14:04,189: Epoch 42/45 Batch 2100/7662 eta: 3:43:55.677979	Training Loss 0.4226 (0.4314)	Training Prec@1 94.336 (92.142)	Training Prec@5 96.094 (95.102)	
2022-03-29 03:14:04,190: ============================================================
2022-03-29 03:14:49,608: time cost, forward:0.17916194272615954, backward:0.04103280219667443, data cost:0.2574411367708686 
2022-03-29 03:14:49,609: ============================================================
2022-03-29 03:14:49,609: Epoch 42/45 Batch 2200/7662 eta: 3:35:21.414071	Training Loss 0.4408 (0.4314)	Training Prec@1 90.039 (92.149)	Training Prec@5 93.555 (95.107)	
2022-03-29 03:14:49,609: ============================================================
2022-03-29 03:15:35,206: time cost, forward:0.1767070322464009, backward:0.04082268992420278, data cost:0.25913988335747573 
2022-03-29 03:15:35,206: ============================================================
2022-03-29 03:15:35,207: Epoch 42/45 Batch 2300/7662 eta: 3:35:26.479705	Training Loss 0.4327 (0.4313)	Training Prec@1 92.578 (92.143)	Training Prec@5 96.094 (95.106)	
2022-03-29 03:15:35,207: ============================================================
2022-03-29 03:16:21,302: time cost, forward:0.17552755464360634, backward:0.04069586831761082, data cost:0.2597460016303879 
2022-03-29 03:16:21,303: ============================================================
2022-03-29 03:16:21,304: Epoch 42/45 Batch 2400/7662 eta: 3:37:01.931125	Training Loss 0.4209 (0.4313)	Training Prec@1 94.727 (92.159)	Training Prec@5 96.680 (95.118)	
2022-03-29 03:16:21,305: ============================================================
2022-03-29 03:17:09,396: time cost, forward:0.17470084366296568, backward:0.04066789517549574, data cost:0.2607920465587663 
2022-03-29 03:17:09,396: ============================================================
2022-03-29 03:17:09,396: Epoch 42/45 Batch 2500/7662 eta: 3:45:37.565065	Training Loss 0.4249 (0.4312)	Training Prec@1 93.750 (92.171)	Training Prec@5 96.289 (95.124)	
2022-03-29 03:17:09,396: ============================================================
2022-03-29 03:17:57,586: time cost, forward:0.1757480354206339, backward:0.0406300076708146, data cost:0.259989007613713 
2022-03-29 03:17:57,586: ============================================================
2022-03-29 03:17:57,586: Epoch 42/45 Batch 2600/7662 eta: 3:45:16.846152	Training Loss 0.4351 (0.4312)	Training Prec@1 91.992 (92.172)	Training Prec@5 93.164 (95.126)	
2022-03-29 03:17:57,586: ============================================================
2022-03-29 03:18:42,879: time cost, forward:0.1739040504079609, backward:0.040360818486957474, data cost:0.26123085468952284 
2022-03-29 03:18:42,879: ============================================================
2022-03-29 03:18:42,880: Epoch 42/45 Batch 2700/7662 eta: 3:30:59.003869	Training Loss 0.4270 (0.4312)	Training Prec@1 92.578 (92.169)	Training Prec@5 95.312 (95.126)	
2022-03-29 03:18:42,880: ============================================================
2022-03-29 03:19:31,596: time cost, forward:0.17497006319556418, backward:0.040323292114514034, data cost:0.2605664989870759 
2022-03-29 03:19:31,596: ============================================================
2022-03-29 03:19:31,596: Epoch 42/45 Batch 2800/7662 eta: 3:46:07.096940	Training Loss 0.4266 (0.4312)	Training Prec@1 94.336 (92.171)	Training Prec@5 96.680 (95.124)	
2022-03-29 03:19:31,596: ============================================================
2022-03-29 03:20:17,860: time cost, forward:0.17450135985338594, backward:0.04018170285035759, data cost:0.2607040201314115 
2022-03-29 03:20:17,872: ============================================================
2022-03-29 03:20:17,872: Epoch 42/45 Batch 2900/7662 eta: 3:34:01.101246	Training Loss 0.4373 (0.4312)	Training Prec@1 93.555 (92.172)	Training Prec@5 95.898 (95.126)	
2022-03-29 03:20:17,872: ============================================================
2022-03-29 03:21:05,004: time cost, forward:0.17434447469135728, backward:0.040030708150809585, data cost:0.26083399280384006 
2022-03-29 03:21:05,004: ============================================================
2022-03-29 03:21:05,005: Epoch 42/45 Batch 3000/7662 eta: 3:37:11.659303	Training Loss 0.4175 (0.4312)	Training Prec@1 92.188 (92.174)	Training Prec@5 95.703 (95.128)	
2022-03-29 03:21:05,005: ============================================================
2022-03-29 03:21:50,011: time cost, forward:0.17271024390704096, backward:0.03982249403353774, data cost:0.26177937994467976 
2022-03-29 03:21:50,011: ============================================================
2022-03-29 03:21:50,011: Epoch 42/45 Batch 3100/7662 eta: 3:26:38.850867	Training Loss 0.4298 (0.4312)	Training Prec@1 93.555 (92.175)	Training Prec@5 95.703 (95.132)	
2022-03-29 03:21:50,011: ============================================================
2022-03-29 03:22:34,803: time cost, forward:0.17069126606434723, backward:0.03963963990660152, data cost:0.2631959438920207 
2022-03-29 03:22:34,803: ============================================================
2022-03-29 03:22:34,804: Epoch 42/45 Batch 3200/7662 eta: 3:24:55.099089	Training Loss 0.4450 (0.4313)	Training Prec@1 92.188 (92.167)	Training Prec@5 95.703 (95.128)	
2022-03-29 03:22:34,804: ============================================================
2022-03-29 03:23:21,339: time cost, forward:0.16946478372777943, backward:0.03952900790272065, data cost:0.264292425442985 
2022-03-29 03:23:21,339: ============================================================
2022-03-29 03:23:21,339: Epoch 42/45 Batch 3300/7662 eta: 3:32:07.016274	Training Loss 0.4334 (0.4313)	Training Prec@1 92.383 (92.167)	Training Prec@5 94.336 (95.127)	
2022-03-29 03:23:21,339: ============================================================
2022-03-29 03:24:06,454: time cost, forward:0.16765340120170213, backward:0.039435240758731456, data cost:0.26553184756744463 
2022-03-29 03:24:06,454: ============================================================
2022-03-29 03:24:06,454: Epoch 42/45 Batch 3400/7662 eta: 3:24:53.424683	Training Loss 0.4402 (0.4313)	Training Prec@1 90.430 (92.163)	Training Prec@5 93.164 (95.124)	
2022-03-29 03:24:06,455: ============================================================
2022-03-29 03:24:55,047: time cost, forward:0.16849324634396098, backward:0.03950855853933033, data cost:0.26498999061431844 
2022-03-29 03:24:55,047: ============================================================
2022-03-29 03:24:55,048: Epoch 42/45 Batch 3500/7662 eta: 3:39:52.513293	Training Loss 0.4214 (0.4313)	Training Prec@1 94.141 (92.157)	Training Prec@5 96.875 (95.120)	
2022-03-29 03:24:55,061: ============================================================
2022-03-29 03:25:39,594: time cost, forward:0.1675862659842281, backward:0.03940653184878558, data cost:0.265193926092319 
2022-03-29 03:25:39,595: ============================================================
2022-03-29 03:25:39,595: Epoch 42/45 Batch 3600/7662 eta: 3:20:49.644089	Training Loss 0.4378 (0.4313)	Training Prec@1 92.773 (92.157)	Training Prec@5 95.703 (95.122)	
2022-03-29 03:25:39,595: ============================================================
2022-03-29 03:26:27,254: time cost, forward:0.16702082112661146, backward:0.039300218599169406, data cost:0.26600784815849887 
2022-03-29 03:26:27,254: ============================================================
2022-03-29 03:26:27,254: Epoch 42/45 Batch 3700/7662 eta: 3:34:03.734015	Training Loss 0.4316 (0.4313)	Training Prec@1 92.773 (92.155)	Training Prec@5 94.922 (95.122)	
2022-03-29 03:26:27,254: ============================================================
2022-03-29 03:27:12,030: time cost, forward:0.16604361147527852, backward:0.03922591563368132, data cost:0.2663813354655861 
2022-03-29 03:27:12,043: ============================================================
2022-03-29 03:27:12,044: Epoch 42/45 Batch 3800/7662 eta: 3:20:25.493102	Training Loss 0.4299 (0.4313)	Training Prec@1 92.188 (92.156)	Training Prec@5 95.117 (95.122)	
2022-03-29 03:27:12,044: ============================================================
2022-03-29 03:28:00,371: time cost, forward:0.16647536823706127, backward:0.03919218454216651, data cost:0.2662535824816054 
2022-03-29 03:28:00,372: ============================================================
2022-03-29 03:28:00,372: Epoch 42/45 Batch 3900/7662 eta: 3:35:27.341048	Training Loss 0.4217 (0.4312)	Training Prec@1 94.141 (92.154)	Training Prec@5 95.898 (95.119)	
2022-03-29 03:28:00,372: ============================================================
2022-03-29 03:28:46,291: time cost, forward:0.16613103789548692, backward:0.039089142724733766, data cost:0.2663548295573611 
2022-03-29 03:28:46,291: ============================================================
2022-03-29 03:28:46,291: Epoch 42/45 Batch 4000/7662 eta: 3:23:56.993742	Training Loss 0.4452 (0.4312)	Training Prec@1 90.820 (92.154)	Training Prec@5 94.336 (95.118)	
2022-03-29 03:28:46,291: ============================================================
2022-03-29 03:29:30,674: time cost, forward:0.1646422840787539, backward:0.03893029605449482, data cost:0.2673049697820138 
2022-03-29 03:29:30,674: ============================================================
2022-03-29 03:29:30,674: Epoch 42/45 Batch 4100/7662 eta: 3:16:23.257011	Training Loss 0.4346 (0.4312)	Training Prec@1 90.820 (92.156)	Training Prec@5 93.359 (95.121)	
2022-03-29 03:29:30,674: ============================================================
2022-03-29 03:30:17,124: time cost, forward:0.16456803102441048, backward:0.03889232142876091, data cost:0.26725763308204165 
2022-03-29 03:30:17,125: ============================================================
2022-03-29 03:30:17,125: Epoch 42/45 Batch 4200/7662 eta: 3:24:45.784121	Training Loss 0.4356 (0.4312)	Training Prec@1 90.625 (92.149)	Training Prec@5 93.164 (95.117)	
2022-03-29 03:30:17,125: ============================================================
2022-03-29 03:31:07,604: time cost, forward:0.16586058343335844, backward:0.03901894931655674, data cost:0.2666223746284437 
2022-03-29 03:31:07,616: ============================================================
2022-03-29 03:31:07,616: Epoch 42/45 Batch 4300/7662 eta: 3:41:43.872945	Training Loss 0.4399 (0.4312)	Training Prec@1 91.602 (92.150)	Training Prec@5 94.727 (95.117)	
2022-03-29 03:31:07,616: ============================================================
2022-03-29 03:31:56,312: time cost, forward:0.1666319023400281, backward:0.039052889330274926, data cost:0.2661473949434107 
2022-03-29 03:31:56,329: ============================================================
2022-03-29 03:31:56,329: Epoch 42/45 Batch 4400/7662 eta: 3:33:06.651104	Training Loss 0.4325 (0.4312)	Training Prec@1 91.602 (92.150)	Training Prec@5 93.750 (95.119)	
2022-03-29 03:31:56,329: ============================================================
2022-03-29 03:32:47,419: time cost, forward:0.16824748097962605, backward:0.039146851528801103, data cost:0.2652895001205611 
2022-03-29 03:32:47,430: ============================================================
2022-03-29 03:32:47,430: Epoch 42/45 Batch 4500/7662 eta: 3:42:42.337977	Training Loss 0.4306 (0.4312)	Training Prec@1 92.188 (92.148)	Training Prec@5 94.531 (95.120)	
2022-03-29 03:32:47,430: ============================================================
2022-03-29 03:33:33,201: time cost, forward:0.16746034920798822, backward:0.03906284640420647, data cost:0.2658062527091069 
2022-03-29 03:33:33,202: ============================================================
2022-03-29 03:33:33,202: Epoch 42/45 Batch 4600/7662 eta: 3:18:43.190034	Training Loss 0.4316 (0.4312)	Training Prec@1 92.578 (92.154)	Training Prec@5 95.117 (95.125)	
2022-03-29 03:33:33,203: ============================================================
2022-03-29 03:34:22,780: time cost, forward:0.16825832902535298, backward:0.03909257635914993, data cost:0.26547482541886563 
2022-03-29 03:34:22,780: ============================================================
2022-03-29 03:34:22,780: Epoch 42/45 Batch 4700/7662 eta: 3:34:25.105238	Training Loss 0.4204 (0.4312)	Training Prec@1 93.555 (92.155)	Training Prec@5 96.289 (95.125)	
2022-03-29 03:34:22,781: ============================================================
2022-03-29 03:35:09,327: time cost, forward:0.16810649925282806, backward:0.03911489798491586, data cost:0.2654494005681376 
2022-03-29 03:35:09,342: ============================================================
2022-03-29 03:35:09,343: Epoch 42/45 Batch 4800/7662 eta: 3:20:35.856378	Training Loss 0.4215 (0.4312)	Training Prec@1 93.555 (92.155)	Training Prec@5 97.266 (95.129)	
2022-03-29 03:35:09,343: ============================================================
2022-03-29 03:35:56,744: time cost, forward:0.16862179333152857, backward:0.03912665017114948, data cost:0.2649194839463523 
2022-03-29 03:35:56,744: ============================================================
2022-03-29 03:35:56,744: Epoch 42/45 Batch 4900/7662 eta: 3:23:25.475218	Training Loss 0.4431 (0.4312)	Training Prec@1 92.188 (92.157)	Training Prec@5 95.312 (95.128)	
2022-03-29 03:35:56,744: ============================================================
2022-03-29 03:36:43,988: time cost, forward:0.16859867272793852, backward:0.039075646168662444, data cost:0.26497649488317465 
2022-03-29 03:36:43,989: ============================================================
2022-03-29 03:36:43,989: Epoch 42/45 Batch 5000/7662 eta: 3:21:57.710047	Training Loss 0.4227 (0.4312)	Training Prec@1 93.945 (92.158)	Training Prec@5 95.703 (95.128)	
2022-03-29 03:36:43,989: ============================================================
2022-03-29 03:37:32,286: time cost, forward:0.1686181527396047, backward:0.03904953174063635, data cost:0.26516908892324614 
2022-03-29 03:37:32,287: ============================================================
2022-03-29 03:37:32,287: Epoch 42/45 Batch 5100/7662 eta: 3:25:39.739618	Training Loss 0.4286 (0.4312)	Training Prec@1 93.359 (92.155)	Training Prec@5 96.484 (95.129)	
2022-03-29 03:37:32,287: ============================================================
2022-03-29 03:38:21,814: time cost, forward:0.1693201790087084, backward:0.03905817796964328, data cost:0.2649032246908286 
2022-03-29 03:38:21,814: ============================================================
2022-03-29 03:38:21,814: Epoch 42/45 Batch 5200/7662 eta: 3:30:04.138595	Training Loss 0.4290 (0.4312)	Training Prec@1 91.406 (92.152)	Training Prec@5 95.117 (95.126)	
2022-03-29 03:38:21,814: ============================================================
2022-03-29 03:39:06,790: time cost, forward:0.16914654871409154, backward:0.03904933820559992, data cost:0.2646248257819336 
2022-03-29 03:39:06,807: ============================================================
2022-03-29 03:39:06,808: Epoch 42/45 Batch 5300/7662 eta: 3:10:05.390589	Training Loss 0.4404 (0.4312)	Training Prec@1 91.992 (92.150)	Training Prec@5 94.531 (95.126)	
2022-03-29 03:39:06,808: ============================================================
2022-03-29 03:39:56,291: time cost, forward:0.1701873902767582, backward:0.03900597289350877, data cost:0.2640071312218468 
2022-03-29 03:39:56,304: ============================================================
2022-03-29 03:39:56,304: Epoch 42/45 Batch 5400/7662 eta: 3:28:17.286831	Training Loss 0.4420 (0.4312)	Training Prec@1 89.453 (92.152)	Training Prec@5 93.164 (95.126)	
2022-03-29 03:39:56,304: ============================================================
2022-03-29 03:40:41,819: time cost, forward:0.16985030476885246, backward:0.03894022413331132, data cost:0.26406166141174947 
2022-03-29 03:40:41,819: ============================================================
2022-03-29 03:40:41,819: Epoch 42/45 Batch 5500/7662 eta: 3:10:46.688136	Training Loss 0.4333 (0.4312)	Training Prec@1 91.992 (92.150)	Training Prec@5 95.117 (95.126)	
2022-03-29 03:40:41,819: ============================================================
2022-03-29 03:41:28,862: time cost, forward:0.16944473499612184, backward:0.03889207615131011, data cost:0.2644694024355289 
2022-03-29 03:41:28,875: ============================================================
2022-03-29 03:41:28,876: Epoch 42/45 Batch 5600/7662 eta: 3:16:27.076908	Training Loss 0.4389 (0.4312)	Training Prec@1 92.773 (92.151)	Training Prec@5 95.508 (95.127)	
2022-03-29 03:41:28,876: ============================================================
2022-03-29 03:42:15,192: time cost, forward:0.16906236522886747, backward:0.038856387744976524, data cost:0.2647107453654996 
2022-03-29 03:42:15,193: ============================================================
2022-03-29 03:42:15,193: Epoch 42/45 Batch 5700/7662 eta: 3:12:35.790816	Training Loss 0.4253 (0.4312)	Training Prec@1 93.359 (92.152)	Training Prec@5 96.484 (95.128)	
2022-03-29 03:42:15,193: ============================================================
2022-03-29 03:43:00,441: time cost, forward:0.168642069352333, backward:0.03877186520302331, data cost:0.26484056916148896 
2022-03-29 03:43:00,442: ============================================================
2022-03-29 03:43:00,442: Epoch 42/45 Batch 5800/7662 eta: 3:07:23.839427	Training Loss 0.4447 (0.4312)	Training Prec@1 91.016 (92.153)	Training Prec@5 94.727 (95.130)	
2022-03-29 03:43:00,442: ============================================================
2022-03-29 03:43:45,103: time cost, forward:0.167576493277633, backward:0.03867726819881809, data cost:0.2655660491370411 
2022-03-29 03:43:45,104: ============================================================
2022-03-29 03:43:45,104: Epoch 42/45 Batch 5900/7662 eta: 3:04:13.524580	Training Loss 0.4423 (0.4312)	Training Prec@1 91.602 (92.152)	Training Prec@5 94.141 (95.129)	
2022-03-29 03:43:45,104: ============================================================
2022-03-29 03:44:30,557: time cost, forward:0.1665597034704886, backward:0.03856168633442081, data cost:0.266400837385569 
2022-03-29 03:44:30,557: ============================================================
2022-03-29 03:44:30,557: Epoch 42/45 Batch 6000/7662 eta: 3:06:43.690241	Training Loss 0.4212 (0.4312)	Training Prec@1 90.430 (92.151)	Training Prec@5 93.164 (95.128)	
2022-03-29 03:44:30,557: ============================================================
2022-03-29 03:45:18,105: time cost, forward:0.166405810158963, backward:0.038527384021669595, data cost:0.2666623014605501 
2022-03-29 03:45:18,117: ============================================================
2022-03-29 03:45:18,117: Epoch 42/45 Batch 6100/7662 eta: 3:14:35.392770	Training Loss 0.4270 (0.4312)	Training Prec@1 94.727 (92.154)	Training Prec@5 97.852 (95.128)	
2022-03-29 03:45:18,117: ============================================================
2022-03-29 03:46:05,938: time cost, forward:0.16665108155042707, backward:0.0385014419306438, data cost:0.26653712817710684 
2022-03-29 03:46:05,939: ============================================================
2022-03-29 03:46:05,939: Epoch 42/45 Batch 6200/7662 eta: 3:14:52.013086	Training Loss 0.4331 (0.4312)	Training Prec@1 91.016 (92.153)	Training Prec@5 94.531 (95.126)	
2022-03-29 03:46:05,939: ============================================================
2022-03-29 03:46:52,005: time cost, forward:0.1664162113999995, backward:0.03847068800852779, data cost:0.26661972534771966 
2022-03-29 03:46:52,017: ============================================================
2022-03-29 03:46:52,017: Epoch 42/45 Batch 6300/7662 eta: 3:06:59.597662	Training Loss 0.4335 (0.4312)	Training Prec@1 90.625 (92.154)	Training Prec@5 94.336 (95.126)	
2022-03-29 03:46:52,018: ============================================================
2022-03-29 03:47:38,179: time cost, forward:0.16631918393889336, backward:0.0384388148067407, data cost:0.26657478897659864 
2022-03-29 03:47:38,180: ============================================================
2022-03-29 03:47:38,180: Epoch 42/45 Batch 6400/7662 eta: 3:06:33.962062	Training Loss 0.4300 (0.4312)	Training Prec@1 91.797 (92.154)	Training Prec@5 94.922 (95.126)	
2022-03-29 03:47:38,180: ============================================================
2022-03-29 03:48:28,612: time cost, forward:0.1670388918983916, backward:0.03848017412142527, data cost:0.2663117491074536 
2022-03-29 03:48:28,612: ============================================================
2022-03-29 03:48:28,612: Epoch 42/45 Batch 6500/7662 eta: 3:22:58.984297	Training Loss 0.4334 (0.4312)	Training Prec@1 92.578 (92.154)	Training Prec@5 95.703 (95.127)	
2022-03-29 03:48:28,613: ============================================================
2022-03-29 03:49:12,293: time cost, forward:0.16620681169882456, backward:0.03841087796106756, data cost:0.266665605256586 
2022-03-29 03:49:12,293: ============================================================
2022-03-29 03:49:12,293: Epoch 42/45 Batch 6600/7662 eta: 2:55:04.847358	Training Loss 0.4242 (0.4312)	Training Prec@1 90.430 (92.151)	Training Prec@5 94.141 (95.124)	
2022-03-29 03:49:12,294: ============================================================
2022-03-29 03:49:57,601: time cost, forward:0.16558818611427464, backward:0.038345796667936936, data cost:0.2670773425944297 
2022-03-29 03:49:57,602: ============================================================
2022-03-29 03:49:57,602: Epoch 42/45 Batch 6700/7662 eta: 3:00:50.935475	Training Loss 0.4341 (0.4312)	Training Prec@1 91.406 (92.149)	Training Prec@5 95.703 (95.125)	
2022-03-29 03:49:57,602: ============================================================
2022-03-29 03:50:48,003: time cost, forward:0.1660972362512139, backward:0.03837361050311354, data cost:0.267018369128203 
2022-03-29 03:50:48,003: ============================================================
2022-03-29 03:50:48,004: Epoch 42/45 Batch 6800/7662 eta: 3:20:20.307863	Training Loss 0.4426 (0.4312)	Training Prec@1 91.602 (92.150)	Training Prec@5 95.898 (95.127)	
2022-03-29 03:50:48,004: ============================================================
2022-03-29 03:51:35,527: time cost, forward:0.16623558136220773, backward:0.038396446441183715, data cost:0.26690596517470805 
2022-03-29 03:51:35,527: ============================================================
2022-03-29 03:51:35,527: Epoch 42/45 Batch 6900/7662 eta: 3:08:06.318410	Training Loss 0.4248 (0.4312)	Training Prec@1 92.578 (92.152)	Training Prec@5 96.484 (95.129)	
2022-03-29 03:51:35,527: ============================================================
2022-03-29 03:52:24,077: time cost, forward:0.16665710985941587, backward:0.038379829906535025, data cost:0.2666722016430596 
2022-03-29 03:52:24,077: ============================================================
2022-03-29 03:52:24,077: Epoch 42/45 Batch 7000/7662 eta: 3:11:21.617568	Training Loss 0.4492 (0.4312)	Training Prec@1 91.016 (92.153)	Training Prec@5 94.336 (95.129)	
2022-03-29 03:52:24,077: ============================================================
2022-03-29 03:53:09,762: time cost, forward:0.16623752730751495, backward:0.0383199794743494, data cost:0.2669284937498955 
2022-03-29 03:53:09,762: ============================================================
2022-03-29 03:53:09,763: Epoch 42/45 Batch 7100/7662 eta: 2:59:18.440419	Training Loss 0.4275 (0.4312)	Training Prec@1 92.578 (92.154)	Training Prec@5 95.117 (95.129)	
2022-03-29 03:53:09,763: ============================================================
2022-03-29 03:53:58,390: time cost, forward:0.16667342520468864, backward:0.03834969703646762, data cost:0.26668017303667096 
2022-03-29 03:53:58,391: ============================================================
2022-03-29 03:53:58,391: Epoch 42/45 Batch 7200/7662 eta: 3:10:02.835855	Training Loss 0.4236 (0.4312)	Training Prec@1 93.555 (92.155)	Training Prec@5 96.875 (95.129)	
2022-03-29 03:53:58,391: ============================================================
2022-03-29 03:54:43,543: time cost, forward:0.16655046349601363, backward:0.038358972601440444, data cost:0.2665024154201601 
2022-03-29 03:54:43,543: ============================================================
2022-03-29 03:54:43,543: Epoch 42/45 Batch 7300/7662 eta: 2:55:42.611223	Training Loss 0.4397 (0.4312)	Training Prec@1 93.750 (92.157)	Training Prec@5 95.703 (95.131)	
2022-03-29 03:54:43,543: ============================================================
2022-03-29 03:55:30,556: time cost, forward:0.16650761857453608, backward:0.03833173832259866, data cost:0.2665297115375938 
2022-03-29 03:55:30,556: ============================================================
2022-03-29 03:55:30,556: Epoch 42/45 Batch 7400/7662 eta: 3:02:10.121882	Training Loss 0.4366 (0.4312)	Training Prec@1 92.773 (92.153)	Training Prec@5 95.508 (95.129)	
2022-03-29 03:55:30,556: ============================================================
2022-03-29 03:56:17,056: time cost, forward:0.16639680155977787, backward:0.03830012859924902, data cost:0.2665720631049655 
2022-03-29 03:56:17,057: ============================================================
2022-03-29 03:56:17,057: Epoch 42/45 Batch 7500/7662 eta: 2:59:24.461006	Training Loss 0.4343 (0.4312)	Training Prec@1 92.969 (92.152)	Training Prec@5 95.898 (95.129)	
2022-03-29 03:56:17,057: ============================================================
2022-03-29 03:57:03,882: time cost, forward:0.16607777666678505, backward:0.03825124550342623, data cost:0.26689078685782086 
2022-03-29 03:57:03,883: ============================================================
2022-03-29 03:57:03,883: Epoch 42/45 Batch 7600/7662 eta: 2:59:52.869397	Training Loss 0.4252 (0.4312)	Training Prec@1 93.945 (92.153)	Training Prec@5 96.484 (95.130)	
2022-03-29 03:57:03,883: ============================================================
2022-03-29 03:57:36,925: Epoch: 42/45 eta: 2:59:23.369168	Training Loss 0.4327 (0.4312)	Training Prec@1 91.406 (92.151)	Training Prec@5 94.727 (95.130)
2022-03-29 03:57:36,926: ============================================================
2022-03-29 03:57:36,927: Save Checkpoint...
2022-03-29 03:57:36,927: ============================================================
2022-03-29 03:57:39,090: Save done!
2022-03-29 03:57:39,090: ============================================================
2022-03-29 03:58:23,028: time cost, forward:0.10580887938990738, backward:0.033333123332322245, data cost:0.3007394280096497 
2022-03-29 03:58:23,028: ============================================================
2022-03-29 03:58:23,029: Epoch 43/45 Batch 100/7662 eta: 2:47:15.083229	Training Loss 0.4177 (0.4322)	Training Prec@1 94.727 (92.170)	Training Prec@5 96.875 (95.050)	
2022-03-29 03:58:23,029: ============================================================
2022-03-29 03:59:14,874: time cost, forward:0.1781197468839099, backward:0.04215746668714974, data cost:0.2588238632259656 
2022-03-29 03:59:14,875: ============================================================
2022-03-29 03:59:14,875: Epoch 43/45 Batch 200/7662 eta: 3:16:54.259003	Training Loss 0.4233 (0.4318)	Training Prec@1 93.359 (92.205)	Training Prec@5 96.289 (95.083)	
2022-03-29 03:59:14,875: ============================================================
2022-03-29 04:00:02,193: time cost, forward:0.18013631699475954, backward:0.04316859261248024, data cost:0.2532288653396045 
2022-03-29 04:00:02,193: ============================================================
2022-03-29 04:00:02,194: Epoch 43/45 Batch 300/7662 eta: 2:58:55.106563	Training Loss 0.4330 (0.4317)	Training Prec@1 91.602 (92.146)	Training Prec@5 94.336 (95.041)	
2022-03-29 04:00:02,194: ============================================================
2022-03-29 04:00:46,963: time cost, forward:0.1638700334649337, backward:0.04075828470980613, data cost:0.26459911054835883 
2022-03-29 04:00:46,963: ============================================================
2022-03-29 04:00:46,963: Epoch 43/45 Batch 400/7662 eta: 2:48:32.172378	Training Loss 0.4482 (0.4319)	Training Prec@1 90.234 (92.131)	Training Prec@5 94.531 (95.075)	
2022-03-29 04:00:46,964: ============================================================
2022-03-29 04:01:34,409: time cost, forward:0.15776389681982372, backward:0.03956301704437317, data cost:0.27294481206752497 
2022-03-29 04:01:34,409: ============================================================
2022-03-29 04:01:34,409: Epoch 43/45 Batch 500/7662 eta: 2:57:49.111809	Training Loss 0.4298 (0.4315)	Training Prec@1 90.430 (92.155)	Training Prec@5 93.164 (95.098)	
2022-03-29 04:01:34,409: ============================================================
2022-03-29 04:02:19,656: time cost, forward:0.1562458107586894, backward:0.03887960349578093, data cost:0.2720591110458756 
2022-03-29 04:02:19,657: ============================================================
2022-03-29 04:02:19,657: Epoch 43/45 Batch 600/7662 eta: 2:48:49.670059	Training Loss 0.4355 (0.4314)	Training Prec@1 91.406 (92.157)	Training Prec@5 93.945 (95.093)	
2022-03-29 04:02:19,657: ============================================================
2022-03-29 04:03:07,231: time cost, forward:0.15873010543965133, backward:0.038982358613239336, data cost:0.27064496287289946 
2022-03-29 04:03:07,231: ============================================================
2022-03-29 04:03:07,232: Epoch 43/45 Batch 700/7662 eta: 2:56:42.921288	Training Loss 0.4374 (0.4314)	Training Prec@1 91.797 (92.157)	Training Prec@5 94.922 (95.090)	
2022-03-29 04:03:07,232: ============================================================
2022-03-29 04:03:58,782: time cost, forward:0.1664730350723553, backward:0.0404046611284583, data cost:0.26729929163697663 
2022-03-29 04:03:58,782: ============================================================
2022-03-29 04:03:58,782: Epoch 43/45 Batch 800/7662 eta: 3:10:37.552158	Training Loss 0.4449 (0.4313)	Training Prec@1 90.820 (92.166)	Training Prec@5 93.555 (95.100)	
2022-03-29 04:03:58,783: ============================================================
2022-03-29 04:04:43,828: time cost, forward:0.16538048533099114, backward:0.040218176380280524, data cost:0.265828283000178 
2022-03-29 04:04:43,828: ============================================================
2022-03-29 04:04:43,828: Epoch 43/45 Batch 900/7662 eta: 2:45:49.266945	Training Loss 0.4296 (0.4313)	Training Prec@1 91.211 (92.168)	Training Prec@5 94.531 (95.109)	
2022-03-29 04:04:43,828: ============================================================
2022-03-29 04:05:28,714: time cost, forward:0.16174379101505987, backward:0.03957063442951924, data cost:0.2678389260480115 
2022-03-29 04:05:28,714: ============================================================
2022-03-29 04:05:28,714: Epoch 43/45 Batch 1000/7662 eta: 2:44:29.157562	Training Loss 0.4240 (0.4313)	Training Prec@1 94.531 (92.173)	Training Prec@5 96.094 (95.108)	
2022-03-29 04:05:28,715: ============================================================
2022-03-29 04:06:19,238: time cost, forward:0.1664328421105896, backward:0.040095953208083346, data cost:0.265828143693405 
2022-03-29 04:06:19,238: ============================================================
2022-03-29 04:06:19,238: Epoch 43/45 Batch 1100/7662 eta: 3:04:18.166939	Training Loss 0.4319 (0.4313)	Training Prec@1 91.992 (92.183)	Training Prec@5 94.922 (95.115)	
2022-03-29 04:06:19,239: ============================================================
2022-03-29 04:07:05,827: time cost, forward:0.16658377448552047, backward:0.039985847234527104, data cost:0.2651724493235126 
2022-03-29 04:07:05,827: ============================================================
2022-03-29 04:07:05,828: Epoch 43/45 Batch 1200/7662 eta: 2:49:10.388281	Training Loss 0.4221 (0.4312)	Training Prec@1 91.602 (92.201)	Training Prec@5 94.922 (95.143)	
2022-03-29 04:07:05,828: ============================================================
2022-03-29 04:07:54,873: time cost, forward:0.16847870036030477, backward:0.04023327104305652, data cost:0.2644821255825592 
2022-03-29 04:07:54,874: ============================================================
2022-03-29 04:07:54,875: Epoch 43/45 Batch 1300/7662 eta: 2:57:16.784303	Training Loss 0.4411 (0.4312)	Training Prec@1 89.453 (92.195)	Training Prec@5 93.945 (95.141)	
2022-03-29 04:07:54,875: ============================================================
2022-03-29 04:08:43,090: time cost, forward:0.16893528971695917, backward:0.04024108688349039, data cost:0.2646342576444788 
2022-03-29 04:08:43,090: ============================================================
2022-03-29 04:08:43,090: Epoch 43/45 Batch 1400/7662 eta: 2:53:28.372703	Training Loss 0.4330 (0.4312)	Training Prec@1 91.211 (92.206)	Training Prec@5 94.336 (95.153)	
2022-03-29 04:08:43,090: ============================================================
2022-03-29 04:09:28,608: time cost, forward:0.16839648835892834, backward:0.04015637096203988, data cost:0.2638866880720977 
2022-03-29 04:09:28,609: ============================================================
2022-03-29 04:09:28,610: Epoch 43/45 Batch 1500/7662 eta: 2:43:00.668310	Training Loss 0.4305 (0.4311)	Training Prec@1 92.383 (92.199)	Training Prec@5 95.898 (95.155)	
2022-03-29 04:09:28,610: ============================================================
2022-03-29 04:10:17,536: time cost, forward:0.1703285833982619, backward:0.040337426726560134, data cost:0.26286242379480185 
2022-03-29 04:10:17,537: ============================================================
2022-03-29 04:10:17,537: Epoch 43/45 Batch 1600/7662 eta: 2:54:24.091028	Training Loss 0.4338 (0.4311)	Training Prec@1 89.258 (92.206)	Training Prec@5 93.555 (95.158)	
2022-03-29 04:10:17,537: ============================================================
2022-03-29 04:11:02,297: time cost, forward:0.1680829252756084, backward:0.03987447018480217, data cost:0.26399046424699574 
2022-03-29 04:11:02,298: ============================================================
2022-03-29 04:11:02,299: Epoch 43/45 Batch 1700/7662 eta: 2:38:48.460211	Training Loss 0.4266 (0.4311)	Training Prec@1 93.164 (92.199)	Training Prec@5 95.703 (95.162)	
2022-03-29 04:11:02,299: ============================================================
2022-03-29 04:11:48,901: time cost, forward:0.16667810687096402, backward:0.03940856264590422, data cost:0.2654673690064342 
2022-03-29 04:11:48,902: ============================================================
2022-03-29 04:11:48,902: Epoch 43/45 Batch 1800/7662 eta: 2:44:33.848364	Training Loss 0.4227 (0.4311)	Training Prec@1 91.211 (92.196)	Training Prec@5 94.922 (95.156)	
2022-03-29 04:11:48,902: ============================================================
2022-03-29 04:12:36,730: time cost, forward:0.16751110786008105, backward:0.039588411460743884, data cost:0.26483553858290476 
2022-03-29 04:12:36,730: ============================================================
2022-03-29 04:12:36,731: Epoch 43/45 Batch 1900/7662 eta: 2:48:05.595349	Training Loss 0.4256 (0.4311)	Training Prec@1 92.969 (92.195)	Training Prec@5 96.289 (95.156)	
2022-03-29 04:12:36,731: ============================================================
2022-03-29 04:13:21,032: time cost, forward:0.16482147960557886, backward:0.03934094177120146, data cost:0.26622339199041356 
2022-03-29 04:13:21,033: ============================================================
2022-03-29 04:13:21,033: Epoch 43/45 Batch 2000/7662 eta: 2:34:57.785241	Training Loss 0.4349 (0.4311)	Training Prec@1 90.234 (92.194)	Training Prec@5 94.531 (95.157)	
2022-03-29 04:13:21,034: ============================================================
2022-03-29 04:14:09,056: time cost, forward:0.16469648816916077, backward:0.03933509751238557, data cost:0.26682504726171835 
2022-03-29 04:14:09,057: ============================================================
2022-03-29 04:14:09,057: Epoch 43/45 Batch 2100/7662 eta: 2:47:10.769479	Training Loss 0.4262 (0.4311)	Training Prec@1 93.164 (92.188)	Training Prec@5 96.094 (95.154)	
2022-03-29 04:14:09,057: ============================================================
2022-03-29 04:14:54,982: time cost, forward:0.16405644900368366, backward:0.03925809192353891, data cost:0.2669987279537213 
2022-03-29 04:14:54,983: ============================================================
2022-03-29 04:14:54,983: Epoch 43/45 Batch 2200/7662 eta: 2:39:06.551410	Training Loss 0.4243 (0.4311)	Training Prec@1 93.750 (92.191)	Training Prec@5 96.875 (95.154)	
2022-03-29 04:14:54,983: ============================================================
2022-03-29 04:15:39,354: time cost, forward:0.16278595362294493, backward:0.03911098048395569, data cost:0.26719976664108 
2022-03-29 04:15:39,354: ============================================================
2022-03-29 04:15:39,355: Epoch 43/45 Batch 2300/7662 eta: 2:32:59.222960	Training Loss 0.4355 (0.4312)	Training Prec@1 92.383 (92.189)	Training Prec@5 95.312 (95.152)	
2022-03-29 04:15:39,355: ============================================================
2022-03-29 04:16:25,346: time cost, forward:0.16196605343280013, backward:0.03902686422394931, data cost:0.2677031061260737 
2022-03-29 04:16:25,347: ============================================================
2022-03-29 04:16:25,347: Epoch 43/45 Batch 2400/7662 eta: 2:37:48.475302	Training Loss 0.4273 (0.4311)	Training Prec@1 91.992 (92.204)	Training Prec@5 95.312 (95.162)	
2022-03-29 04:16:25,347: ============================================================
2022-03-29 04:17:11,435: time cost, forward:0.1614039813389345, backward:0.038961908825877765, data cost:0.267995486883413 
2022-03-29 04:17:11,436: ============================================================
2022-03-29 04:17:11,436: Epoch 43/45 Batch 2500/7662 eta: 2:37:22.188610	Training Loss 0.4348 (0.4311)	Training Prec@1 89.844 (92.203)	Training Prec@5 94.336 (95.164)	
2022-03-29 04:17:11,436: ============================================================
2022-03-29 04:17:58,709: time cost, forward:0.16106847186600443, backward:0.038948959458465986, data cost:0.26854424753662437 
2022-03-29 04:17:58,710: ============================================================
2022-03-29 04:17:58,710: Epoch 43/45 Batch 2600/7662 eta: 2:40:37.786091	Training Loss 0.4334 (0.4311)	Training Prec@1 93.359 (92.202)	Training Prec@5 95.703 (95.166)	
2022-03-29 04:17:58,710: ============================================================
2022-03-29 04:18:47,233: time cost, forward:0.16258966291158364, backward:0.039080617956957935, data cost:0.26747810500513497 
2022-03-29 04:18:47,233: ============================================================
2022-03-29 04:18:47,234: Epoch 43/45 Batch 2700/7662 eta: 2:44:03.979754	Training Loss 0.4319 (0.4311)	Training Prec@1 91.211 (92.198)	Training Prec@5 95.312 (95.164)	
2022-03-29 04:18:47,234: ============================================================
2022-03-29 04:19:33,387: time cost, forward:0.16254478550332066, backward:0.03910347911961465, data cost:0.26720047082250226 
2022-03-29 04:19:33,388: ============================================================
2022-03-29 04:19:33,388: Epoch 43/45 Batch 2800/7662 eta: 2:35:17.181771	Training Loss 0.4236 (0.4311)	Training Prec@1 93.359 (92.201)	Training Prec@5 96.680 (95.166)	
2022-03-29 04:19:33,388: ============================================================
2022-03-29 04:20:19,201: time cost, forward:0.16270392785692428, backward:0.03921930664117766, data cost:0.2665289645772344 
2022-03-29 04:20:19,201: ============================================================
2022-03-29 04:20:19,201: Epoch 43/45 Batch 2900/7662 eta: 2:33:22.516688	Training Loss 0.4238 (0.4311)	Training Prec@1 92.383 (92.195)	Training Prec@5 95.508 (95.162)	
2022-03-29 04:20:19,201: ============================================================
2022-03-29 04:21:04,677: time cost, forward:0.16137474987975117, backward:0.03901121432720005, data cost:0.26759965517553497 
2022-03-29 04:21:04,677: ============================================================
2022-03-29 04:21:04,677: Epoch 43/45 Batch 3000/7662 eta: 2:31:29.261592	Training Loss 0.4307 (0.4311)	Training Prec@1 90.820 (92.198)	Training Prec@5 92.773 (95.166)	
2022-03-29 04:21:04,677: ============================================================
2022-03-29 04:21:51,360: time cost, forward:0.16137489306230474, backward:0.038928430131959624, data cost:0.26761718633368 
2022-03-29 04:21:51,361: ============================================================
2022-03-29 04:21:51,361: Epoch 43/45 Batch 3100/7662 eta: 2:34:44.001565	Training Loss 0.4299 (0.4311)	Training Prec@1 91.602 (92.197)	Training Prec@5 94.531 (95.166)	
2022-03-29 04:21:51,361: ============================================================
2022-03-29 04:22:38,266: time cost, forward:0.16146444342739324, backward:0.03891399086322886, data cost:0.26757645517559714 
2022-03-29 04:22:38,276: ============================================================
2022-03-29 04:22:38,277: Epoch 43/45 Batch 3200/7662 eta: 2:34:43.229506	Training Loss 0.4230 (0.4311)	Training Prec@1 92.969 (92.198)	Training Prec@5 94.336 (95.161)	
2022-03-29 04:22:38,277: ============================================================
2022-03-29 04:23:26,303: time cost, forward:0.16241367812155233, backward:0.038969643226570344, data cost:0.2669198549165983 
2022-03-29 04:23:26,304: ============================================================
2022-03-29 04:23:26,304: Epoch 43/45 Batch 3300/7662 eta: 2:37:35.072101	Training Loss 0.4318 (0.4311)	Training Prec@1 92.969 (92.194)	Training Prec@5 95.898 (95.156)	
2022-03-29 04:23:26,304: ============================================================
2022-03-29 04:24:11,300: time cost, forward:0.16166314295931192, backward:0.03884434847314065, data cost:0.26721572763746576 
2022-03-29 04:24:11,301: ============================================================
2022-03-29 04:24:11,301: Epoch 43/45 Batch 3400/7662 eta: 2:26:53.550758	Training Loss 0.4339 (0.4311)	Training Prec@1 90.430 (92.189)	Training Prec@5 94.336 (95.152)	
2022-03-29 04:24:11,301: ============================================================
2022-03-29 04:24:58,652: time cost, forward:0.1618633919628936, backward:0.038878061663051716, data cost:0.2670958260871166 
2022-03-29 04:24:58,652: ============================================================
2022-03-29 04:24:58,652: Epoch 43/45 Batch 3500/7662 eta: 2:33:47.392805	Training Loss 0.4217 (0.4312)	Training Prec@1 92.578 (92.187)	Training Prec@5 94.336 (95.148)	
2022-03-29 04:24:58,653: ============================================================
2022-03-29 04:25:45,799: time cost, forward:0.16225772640644825, backward:0.03887635987809911, data cost:0.2668162292492128 
2022-03-29 04:25:45,809: ============================================================
2022-03-29 04:25:45,809: Epoch 43/45 Batch 3600/7662 eta: 2:32:22.338650	Training Loss 0.4250 (0.4312)	Training Prec@1 91.016 (92.186)	Training Prec@5 95.117 (95.152)	
2022-03-29 04:25:45,810: ============================================================
2022-03-29 04:26:30,832: time cost, forward:0.16179775966119367, backward:0.03875976261109009, data cost:0.2668841743056727 
2022-03-29 04:26:30,832: ============================================================
2022-03-29 04:26:30,832: Epoch 43/45 Batch 3700/7662 eta: 2:24:43.548672	Training Loss 0.4337 (0.4312)	Training Prec@1 93.555 (92.182)	Training Prec@5 95.508 (95.146)	
2022-03-29 04:26:30,832: ============================================================
2022-03-29 04:27:15,868: time cost, forward:0.1604062274557316, backward:0.03862022813855739, data cost:0.2679447588653243 
2022-03-29 04:27:15,869: ============================================================
2022-03-29 04:27:15,869: Epoch 43/45 Batch 3800/7662 eta: 2:24:01.166928	Training Loss 0.4311 (0.4312)	Training Prec@1 92.383 (92.181)	Training Prec@5 95.703 (95.146)	
2022-03-29 04:27:15,869: ============================================================
2022-03-29 04:28:00,962: time cost, forward:0.15904551158962754, backward:0.03848072894874919, data cost:0.26902823638964934 
2022-03-29 04:28:00,963: ============================================================
2022-03-29 04:28:00,963: Epoch 43/45 Batch 3900/7662 eta: 2:23:27.125975	Training Loss 0.4309 (0.4312)	Training Prec@1 93.164 (92.175)	Training Prec@5 96.289 (95.143)	
2022-03-29 04:28:00,963: ============================================================
2022-03-29 04:28:48,976: time cost, forward:0.15936005327158434, backward:0.038446621168670314, data cost:0.26909649398929625 
2022-03-29 04:28:48,987: ============================================================
2022-03-29 04:28:48,988: Epoch 43/45 Batch 4000/7662 eta: 2:31:58.419083	Training Loss 0.4331 (0.4312)	Training Prec@1 92.578 (92.168)	Training Prec@5 94.922 (95.138)	
2022-03-29 04:28:48,989: ============================================================
2022-03-29 04:29:35,878: time cost, forward:0.1596299012308151, backward:0.03836656134429284, data cost:0.26890426904697423 
2022-03-29 04:29:35,878: ============================================================
2022-03-29 04:29:35,878: Epoch 43/45 Batch 4100/7662 eta: 2:27:36.237117	Training Loss 0.4361 (0.4312)	Training Prec@1 92.969 (92.168)	Training Prec@5 95.703 (95.136)	
2022-03-29 04:29:35,878: ============================================================
2022-03-29 04:30:20,408: time cost, forward:0.15873844806964582, backward:0.03824517079040135, data cost:0.26941566530878586 
2022-03-29 04:30:20,408: ============================================================
2022-03-29 04:30:20,408: Epoch 43/45 Batch 4200/7662 eta: 2:19:25.867668	Training Loss 0.4403 (0.4312)	Training Prec@1 90.234 (92.166)	Training Prec@5 94.141 (95.135)	
2022-03-29 04:30:20,408: ============================================================
2022-03-29 04:31:06,406: time cost, forward:0.15858921108480997, backward:0.038186746021846636, data cost:0.2694610449069321 
2022-03-29 04:31:06,406: ============================================================
2022-03-29 04:31:06,407: Epoch 43/45 Batch 4300/7662 eta: 2:23:15.697523	Training Loss 0.4223 (0.4312)	Training Prec@1 93.164 (92.168)	Training Prec@5 96.875 (95.136)	
2022-03-29 04:31:06,407: ============================================================
2022-03-29 04:31:55,035: time cost, forward:0.15938021145400255, backward:0.038208338856073804, data cost:0.26907722184158883 
2022-03-29 04:31:55,035: ============================================================
2022-03-29 04:31:55,036: Epoch 43/45 Batch 4400/7662 eta: 2:30:38.691232	Training Loss 0.4312 (0.4311)	Training Prec@1 91.211 (92.171)	Training Prec@5 93.555 (95.141)	
2022-03-29 04:31:55,036: ============================================================
2022-03-29 04:32:43,412: time cost, forward:0.16026252422048717, backward:0.03824915677130183, data cost:0.268514068742995 
2022-03-29 04:32:43,413: ============================================================
2022-03-29 04:32:43,413: Epoch 43/45 Batch 4500/7662 eta: 2:29:03.502376	Training Loss 0.4288 (0.4311)	Training Prec@1 92.578 (92.171)	Training Prec@5 95.312 (95.141)	
2022-03-29 04:32:43,413: ============================================================
2022-03-29 04:33:33,074: time cost, forward:0.16098002014691012, backward:0.03828395887882094, data cost:0.2683753337412198 
2022-03-29 04:33:33,074: ============================================================
2022-03-29 04:33:33,074: Epoch 43/45 Batch 4600/7662 eta: 2:32:11.249041	Training Loss 0.4255 (0.4311)	Training Prec@1 92.969 (92.171)	Training Prec@5 96.289 (95.141)	
2022-03-29 04:33:33,074: ============================================================
2022-03-29 04:34:22,039: time cost, forward:0.16184739966066777, backward:0.03830272675981215, data cost:0.26794437292561324 
2022-03-29 04:34:22,040: ============================================================
2022-03-29 04:34:22,040: Epoch 43/45 Batch 4700/7662 eta: 2:29:14.334261	Training Loss 0.4417 (0.4311)	Training Prec@1 91.406 (92.170)	Training Prec@5 94.141 (95.140)	
2022-03-29 04:34:22,040: ============================================================
2022-03-29 04:35:07,261: time cost, forward:0.16148709639779577, backward:0.03822648686700921, data cost:0.2680350093698472 
2022-03-29 04:35:07,262: ============================================================
2022-03-29 04:35:07,262: Epoch 43/45 Batch 4800/7662 eta: 2:17:04.478549	Training Loss 0.4263 (0.4311)	Training Prec@1 92.188 (92.168)	Training Prec@5 94.141 (95.138)	
2022-03-29 04:35:07,262: ============================================================
2022-03-29 04:35:58,638: time cost, forward:0.16299210647875786, backward:0.038309795755735586, data cost:0.26738005473823495 
2022-03-29 04:35:58,638: ============================================================
2022-03-29 04:35:58,638: Epoch 43/45 Batch 4900/7662 eta: 2:34:52.467320	Training Loss 0.4402 (0.4312)	Training Prec@1 91.211 (92.169)	Training Prec@5 95.117 (95.138)	
2022-03-29 04:35:58,638: ============================================================
2022-03-29 04:36:45,993: time cost, forward:0.16341936676519875, backward:0.03836909969655674, data cost:0.26693936051500156 
2022-03-29 04:36:45,993: ============================================================
2022-03-29 04:36:45,994: Epoch 43/45 Batch 5000/7662 eta: 2:21:57.816885	Training Loss 0.4301 (0.4312)	Training Prec@1 91.406 (92.171)	Training Prec@5 94.727 (95.137)	
2022-03-29 04:36:45,994: ============================================================
2022-03-29 04:37:36,896: time cost, forward:0.1641048132893992, backward:0.03843712895541688, data cost:0.2669804323465363 
2022-03-29 04:37:36,908: ============================================================
2022-03-29 04:37:36,908: Epoch 43/45 Batch 5100/7662 eta: 2:31:47.067403	Training Loss 0.4231 (0.4312)	Training Prec@1 91.992 (92.167)	Training Prec@5 95.117 (95.135)	
2022-03-29 04:37:36,908: ============================================================
2022-03-29 04:38:23,888: time cost, forward:0.1641218037209985, backward:0.03840271957472302, data cost:0.2669934327612934 
2022-03-29 04:38:23,888: ============================================================
2022-03-29 04:38:23,889: Epoch 43/45 Batch 5200/7662 eta: 2:19:16.420387	Training Loss 0.4317 (0.4312)	Training Prec@1 89.648 (92.166)	Training Prec@5 93.750 (95.136)	
2022-03-29 04:38:23,889: ============================================================
2022-03-29 04:39:13,092: time cost, forward:0.1647895326882539, backward:0.03840739210949099, data cost:0.26665501487459814 
2022-03-29 04:39:13,093: ============================================================
2022-03-29 04:39:13,093: Epoch 43/45 Batch 5300/7662 eta: 2:25:02.750486	Training Loss 0.4276 (0.4312)	Training Prec@1 91.797 (92.166)	Training Prec@5 93.164 (95.135)	
2022-03-29 04:39:13,093: ============================================================
2022-03-29 04:39:59,778: time cost, forward:0.16461589367748697, backward:0.03839289442127028, data cost:0.2668349279211856 
2022-03-29 04:39:59,778: ============================================================
2022-03-29 04:39:59,778: Epoch 43/45 Batch 5400/7662 eta: 2:16:50.566331	Training Loss 0.4425 (0.4312)	Training Prec@1 89.648 (92.163)	Training Prec@5 93.555 (95.134)	
2022-03-29 04:39:59,778: ============================================================
2022-03-29 04:40:43,215: time cost, forward:0.163740916476724, backward:0.038343425056331266, data cost:0.2671037446067298 
2022-03-29 04:40:43,215: ============================================================
2022-03-29 04:40:43,216: Epoch 43/45 Batch 5500/7662 eta: 2:06:35.929592	Training Loss 0.4236 (0.4312)	Training Prec@1 93.164 (92.168)	Training Prec@5 94.727 (95.137)	
2022-03-29 04:40:43,216: ============================================================
2022-03-29 04:41:30,333: time cost, forward:0.1637209207804251, backward:0.03833462425929603, data cost:0.26716811973338767 
2022-03-29 04:41:30,334: ============================================================
2022-03-29 04:41:30,334: Epoch 43/45 Batch 5600/7662 eta: 2:16:32.418728	Training Loss 0.4312 (0.4312)	Training Prec@1 92.188 (92.164)	Training Prec@5 95.312 (95.134)	
2022-03-29 04:41:30,334: ============================================================
2022-03-29 04:42:16,949: time cost, forward:0.1636359496249674, backward:0.038312308054929196, data cost:0.2672007548263103 
2022-03-29 04:42:16,958: ============================================================
2022-03-29 04:42:16,959: Epoch 43/45 Batch 5700/7662 eta: 2:14:19.998465	Training Loss 0.4375 (0.4312)	Training Prec@1 90.820 (92.162)	Training Prec@5 93.164 (95.133)	
2022-03-29 04:42:16,959: ============================================================
2022-03-29 04:43:06,236: time cost, forward:0.1647262252143877, backward:0.038408954136534834, data cost:0.26640967201171073 
2022-03-29 04:43:06,236: ============================================================
2022-03-29 04:43:06,237: Epoch 43/45 Batch 5800/7662 eta: 2:21:09.389760	Training Loss 0.4404 (0.4312)	Training Prec@1 90.820 (92.159)	Training Prec@5 94.531 (95.133)	
2022-03-29 04:43:06,237: ============================================================
2022-03-29 04:43:50,861: time cost, forward:0.16413075363338953, backward:0.038340278835008866, data cost:0.2666501522791711 
2022-03-29 04:43:50,862: ============================================================
2022-03-29 04:43:50,862: Epoch 43/45 Batch 5900/7662 eta: 2:07:05.119214	Training Loss 0.4402 (0.4312)	Training Prec@1 88.477 (92.160)	Training Prec@5 91.797 (95.134)	
2022-03-29 04:43:50,862: ============================================================
2022-03-29 04:44:35,737: time cost, forward:0.16315390817680683, backward:0.03822337883594613, data cost:0.2673963913422343 
2022-03-29 04:44:35,738: ============================================================
2022-03-29 04:44:35,738: Epoch 43/45 Batch 6000/7662 eta: 2:07:03.130617	Training Loss 0.4402 (0.4312)	Training Prec@1 90.820 (92.163)	Training Prec@5 94.727 (95.137)	
2022-03-29 04:44:35,738: ============================================================
2022-03-29 04:45:22,547: time cost, forward:0.16280702587658705, backward:0.03817615987512201, data cost:0.2677718689645347 
2022-03-29 04:45:22,547: ============================================================
2022-03-29 04:45:22,547: Epoch 43/45 Batch 6100/7662 eta: 2:11:44.702506	Training Loss 0.4231 (0.4312)	Training Prec@1 92.383 (92.158)	Training Prec@5 95.508 (95.134)	
2022-03-29 04:45:22,548: ============================================================
2022-03-29 04:46:08,537: time cost, forward:0.16273175222024858, backward:0.03814575933298578, data cost:0.26772154844812973 
2022-03-29 04:46:08,538: ============================================================
2022-03-29 04:46:08,538: Epoch 43/45 Batch 6200/7662 eta: 2:08:40.423389	Training Loss 0.4277 (0.4312)	Training Prec@1 91.992 (92.161)	Training Prec@5 94.727 (95.136)	
2022-03-29 04:46:08,538: ============================================================
2022-03-29 04:46:53,656: time cost, forward:0.1621448311621773, backward:0.03810129326134376, data cost:0.2680824663283655 
2022-03-29 04:46:53,667: ============================================================
2022-03-29 04:46:53,668: Epoch 43/45 Batch 6300/7662 eta: 2:05:30.802419	Training Loss 0.4411 (0.4312)	Training Prec@1 90.820 (92.159)	Training Prec@5 93.945 (95.136)	
2022-03-29 04:46:53,668: ============================================================
2022-03-29 04:47:40,287: time cost, forward:0.16208151586913824, backward:0.038051195415896834, data cost:0.2681461850410887 
2022-03-29 04:47:40,288: ============================================================
2022-03-29 04:47:40,288: Epoch 43/45 Batch 6400/7662 eta: 2:08:52.861002	Training Loss 0.4282 (0.4312)	Training Prec@1 91.602 (92.159)	Training Prec@5 95.312 (95.136)	
2022-03-29 04:47:40,288: ============================================================
2022-03-29 04:48:26,729: time cost, forward:0.1622554192379413, backward:0.038022587786896225, data cost:0.2679364911995222 
2022-03-29 04:48:26,730: ============================================================
2022-03-29 04:48:26,730: Epoch 43/45 Batch 6500/7662 eta: 2:07:36.894098	Training Loss 0.4194 (0.4312)	Training Prec@1 91.797 (92.162)	Training Prec@5 94.141 (95.138)	
2022-03-29 04:48:26,730: ============================================================
2022-03-29 04:49:16,991: time cost, forward:0.1629040125627051, backward:0.03803669147228432, data cost:0.26778952611867435 
2022-03-29 04:49:17,004: ============================================================
2022-03-29 04:49:17,004: Epoch 43/45 Batch 6600/7662 eta: 2:17:18.491479	Training Loss 0.4253 (0.4312)	Training Prec@1 93.555 (92.159)	Training Prec@5 95.703 (95.136)	
2022-03-29 04:49:17,004: ============================================================
2022-03-29 04:50:00,956: time cost, forward:0.16226399508959002, backward:0.03798125014053848, data cost:0.268034161551886 
2022-03-29 04:50:00,956: ============================================================
2022-03-29 04:50:00,956: Epoch 43/45 Batch 6700/7662 eta: 1:59:18.452400	Training Loss 0.4239 (0.4312)	Training Prec@1 92.773 (92.161)	Training Prec@5 95.312 (95.137)	
2022-03-29 04:50:00,956: ============================================================
2022-03-29 04:50:48,496: time cost, forward:0.162675304576954, backward:0.03801745768066083, data cost:0.2676886096563843 
2022-03-29 04:50:48,497: ============================================================
2022-03-29 04:50:48,497: Epoch 43/45 Batch 6800/7662 eta: 2:08:15.436142	Training Loss 0.4441 (0.4312)	Training Prec@1 89.453 (92.162)	Training Prec@5 93.750 (95.134)	
2022-03-29 04:50:48,498: ============================================================
2022-03-29 04:51:33,334: time cost, forward:0.16221732888675838, backward:0.037986228389659815, data cost:0.26787167605256185 
2022-03-29 04:51:33,334: ============================================================
2022-03-29 04:51:33,335: Epoch 43/45 Batch 6900/7662 eta: 2:00:12.998668	Training Loss 0.4304 (0.4312)	Training Prec@1 91.602 (92.163)	Training Prec@5 94.336 (95.135)	
2022-03-29 04:51:33,335: ============================================================
2022-03-29 04:52:22,567: time cost, forward:0.1628783776225627, backward:0.03801346993613267, data cost:0.26751304306393264 
2022-03-29 04:52:22,567: ============================================================
2022-03-29 04:52:22,567: Epoch 43/45 Batch 7000/7662 eta: 2:11:10.831080	Training Loss 0.4316 (0.4312)	Training Prec@1 93.359 (92.160)	Training Prec@5 96.289 (95.135)	
2022-03-29 04:52:22,567: ============================================================
2022-03-29 04:53:08,328: time cost, forward:0.16264617491782693, backward:0.038008380295575746, data cost:0.2675848605683495 
2022-03-29 04:53:08,328: ============================================================
2022-03-29 04:53:08,328: Epoch 43/45 Batch 7100/7662 eta: 2:01:10.071382	Training Loss 0.4313 (0.4312)	Training Prec@1 89.648 (92.159)	Training Prec@5 92.969 (95.133)	
2022-03-29 04:53:08,329: ============================================================
2022-03-29 04:53:58,551: time cost, forward:0.16349511832756405, backward:0.03808311452996749, data cost:0.2671311585534561 
2022-03-29 04:53:58,561: ============================================================
2022-03-29 04:53:58,561: Epoch 43/45 Batch 7200/7662 eta: 2:12:10.267946	Training Loss 0.4343 (0.4312)	Training Prec@1 91.602 (92.160)	Training Prec@5 94.922 (95.133)	
2022-03-29 04:53:58,562: ============================================================
2022-03-29 04:54:45,273: time cost, forward:0.16354994859445876, backward:0.038047229970933835, data cost:0.2670391778257354 
2022-03-29 04:54:45,273: ============================================================
2022-03-29 04:54:45,274: Epoch 43/45 Batch 7300/7662 eta: 2:02:07.781250	Training Loss 0.4385 (0.4312)	Training Prec@1 91.797 (92.158)	Training Prec@5 94.922 (95.131)	
2022-03-29 04:54:45,274: ============================================================
2022-03-29 04:55:33,836: time cost, forward:0.16381361004725906, backward:0.038054943986963075, data cost:0.2670190790598901 
2022-03-29 04:55:33,837: ============================================================
2022-03-29 04:55:33,837: Epoch 43/45 Batch 7400/7662 eta: 2:06:09.564528	Training Loss 0.4215 (0.4312)	Training Prec@1 93.750 (92.158)	Training Prec@5 96.289 (95.132)	
2022-03-29 04:55:33,837: ============================================================
2022-03-29 04:56:20,598: time cost, forward:0.163991274969119, backward:0.03804622037933102, data cost:0.2668186824056908 
2022-03-29 04:56:20,598: ============================================================
2022-03-29 04:56:20,598: Epoch 43/45 Batch 7500/7662 eta: 2:00:41.904489	Training Loss 0.4355 (0.4312)	Training Prec@1 91.992 (92.156)	Training Prec@5 95.117 (95.130)	
2022-03-29 04:56:20,598: ============================================================
2022-03-29 04:57:07,860: time cost, forward:0.16412101345386046, backward:0.03805930097725285, data cost:0.2667236836399902 
2022-03-29 04:57:07,861: ============================================================
2022-03-29 04:57:07,861: Epoch 43/45 Batch 7600/7662 eta: 2:01:12.277177	Training Loss 0.4345 (0.4312)	Training Prec@1 91.406 (92.153)	Training Prec@5 95.312 (95.129)	
2022-03-29 04:57:07,861: ============================================================
2022-03-29 04:57:39,790: Epoch: 43/45 eta: 2:00:42.501817	Training Loss 0.4362 (0.4312)	Training Prec@1 92.578 (92.152)	Training Prec@5 94.531 (95.129)
2022-03-29 04:57:39,790: ============================================================
2022-03-29 04:57:39,792: Save Checkpoint...
2022-03-29 04:57:39,794: ============================================================
2022-03-29 04:57:41,814: Save done!
2022-03-29 04:57:41,815: ============================================================
2022-03-29 04:58:27,703: time cost, forward:0.1577690899974168, backward:0.03882985163216639, data cost:0.2630465440075807 
2022-03-29 04:58:27,704: ============================================================
2022-03-29 04:58:27,704: Epoch 44/45 Batch 100/7662 eta: 1:56:26.430760	Training Loss 0.4331 (0.4303)	Training Prec@1 92.188 (92.225)	Training Prec@5 94.922 (95.208)	
2022-03-29 04:58:27,704: ============================================================
2022-03-29 04:59:12,234: time cost, forward:0.14850015376680462, backward:0.03774666786193848, data cost:0.2659177372803041 
2022-03-29 04:59:12,234: ============================================================
2022-03-29 04:59:12,234: Epoch 44/45 Batch 200/7662 eta: 1:52:15.234185	Training Loss 0.4210 (0.4307)	Training Prec@1 91.992 (92.166)	Training Prec@5 94.141 (95.166)	
2022-03-29 04:59:12,234: ============================================================
2022-03-29 04:59:57,246: time cost, forward:0.14179244408240685, backward:0.03704458495047579, data cost:0.2726623501666015 
2022-03-29 04:59:57,249: ============================================================
2022-03-29 04:59:57,250: Epoch 44/45 Batch 300/7662 eta: 1:52:43.489079	Training Loss 0.4326 (0.4312)	Training Prec@1 91.797 (92.140)	Training Prec@5 94.727 (95.100)	
2022-03-29 04:59:57,250: ============================================================
2022-03-29 05:00:44,636: time cost, forward:0.1479763966753967, backward:0.037024390428586115, data cost:0.2719092213719112 
2022-03-29 05:00:44,637: ============================================================
2022-03-29 05:00:44,637: Epoch 44/45 Batch 400/7662 eta: 1:57:52.592816	Training Loss 0.4376 (0.4313)	Training Prec@1 91.016 (92.088)	Training Prec@5 94.141 (95.074)	
2022-03-29 05:00:44,637: ============================================================
2022-03-29 05:01:32,731: time cost, forward:0.1522782126027262, backward:0.037880508598679294, data cost:0.27143563010649596 
2022-03-29 05:01:32,732: ============================================================
2022-03-29 05:01:32,732: Epoch 44/45 Batch 500/7662 eta: 1:58:50.085380	Training Loss 0.4376 (0.4313)	Training Prec@1 91.406 (92.072)	Training Prec@5 94.922 (95.082)	
2022-03-29 05:01:32,732: ============================================================
2022-03-29 05:02:19,983: time cost, forward:0.15739299220115394, backward:0.038065946161846484, data cost:0.2678234091585188 
2022-03-29 05:02:19,983: ============================================================
2022-03-29 05:02:19,983: Epoch 44/45 Batch 600/7662 eta: 1:55:57.788801	Training Loss 0.4332 (0.4316)	Training Prec@1 91.211 (92.042)	Training Prec@5 94.727 (95.079)	
2022-03-29 05:02:19,984: ============================================================
2022-03-29 05:03:06,439: time cost, forward:0.15913169203227512, backward:0.03826653667444494, data cost:0.2660131014467821 
2022-03-29 05:03:06,439: ============================================================
2022-03-29 05:03:06,439: Epoch 44/45 Batch 700/7662 eta: 1:53:14.160200	Training Loss 0.4231 (0.4315)	Training Prec@1 92.383 (92.069)	Training Prec@5 95.312 (95.087)	
2022-03-29 05:03:06,439: ============================================================
2022-03-29 05:03:51,488: time cost, forward:0.154216138830173, backward:0.037855900572298165, data cost:0.2696450195264757 
2022-03-29 05:03:51,488: ============================================================
2022-03-29 05:03:51,489: Epoch 44/45 Batch 800/7662 eta: 1:49:03.402369	Training Loss 0.4334 (0.4316)	Training Prec@1 92.188 (92.071)	Training Prec@5 95.312 (95.086)	
2022-03-29 05:03:51,489: ============================================================
2022-03-29 05:04:40,333: time cost, forward:0.15727916761022787, backward:0.038042415898952124, data cost:0.26922887981402066 
2022-03-29 05:04:40,334: ============================================================
2022-03-29 05:04:40,334: Epoch 44/45 Batch 900/7662 eta: 1:57:25.983596	Training Loss 0.4366 (0.4314)	Training Prec@1 91.016 (92.097)	Training Prec@5 94.336 (95.106)	
2022-03-29 05:04:40,334: ============================================================
2022-03-29 05:05:27,992: time cost, forward:0.15755953659882416, backward:0.03788826582548735, data cost:0.27037069126889035 
2022-03-29 05:05:27,993: ============================================================
2022-03-29 05:05:27,993: Epoch 44/45 Batch 1000/7662 eta: 1:53:47.136335	Training Loss 0.4219 (0.4313)	Training Prec@1 92.383 (92.116)	Training Prec@5 95.898 (95.108)	
2022-03-29 05:05:27,993: ============================================================
2022-03-29 05:06:16,609: time cost, forward:0.16012544106959864, backward:0.03801958250717427, data cost:0.2694665502699209 
2022-03-29 05:06:16,618: ============================================================
2022-03-29 05:06:16,619: Epoch 44/45 Batch 1100/7662 eta: 1:55:16.967840	Training Loss 0.4266 (0.4313)	Training Prec@1 92.969 (92.109)	Training Prec@5 96.484 (95.112)	
2022-03-29 05:06:16,619: ============================================================
2022-03-29 05:07:04,731: time cost, forward:0.16259120045551367, backward:0.03818860920992764, data cost:0.26794154033549533 
2022-03-29 05:07:04,741: ============================================================
2022-03-29 05:07:04,741: Epoch 44/45 Batch 1200/7662 eta: 1:53:17.307832	Training Loss 0.4469 (0.4314)	Training Prec@1 91.016 (92.112)	Training Prec@5 93.359 (95.119)	
2022-03-29 05:07:04,741: ============================================================
2022-03-29 05:07:52,632: time cost, forward:0.1643007100775574, backward:0.03840554338679853, data cost:0.26672683301753863 
2022-03-29 05:07:52,644: ============================================================
2022-03-29 05:07:52,644: Epoch 44/45 Batch 1300/7662 eta: 1:51:58.373396	Training Loss 0.4218 (0.4314)	Training Prec@1 92.188 (92.108)	Training Prec@5 95.117 (95.111)	
2022-03-29 05:07:52,644: ============================================================
2022-03-29 05:08:37,403: time cost, forward:0.16271895677213416, backward:0.0381596969484516, data cost:0.2669004339077713 
2022-03-29 05:08:37,405: ============================================================
2022-03-29 05:08:37,406: Epoch 44/45 Batch 1400/7662 eta: 1:43:53.072025	Training Loss 0.4181 (0.4313)	Training Prec@1 93.164 (92.122)	Training Prec@5 95.508 (95.116)	
2022-03-29 05:08:37,406: ============================================================
2022-03-29 05:09:27,213: time cost, forward:0.16612926302471503, backward:0.0384105912361883, data cost:0.2651864082674888 
2022-03-29 05:09:27,214: ============================================================
2022-03-29 05:09:27,215: Epoch 44/45 Batch 1500/7662 eta: 1:54:46.072893	Training Loss 0.4381 (0.4312)	Training Prec@1 93.359 (92.130)	Training Prec@5 95.312 (95.120)	
2022-03-29 05:09:27,215: ============================================================
2022-03-29 05:10:13,124: time cost, forward:0.16521285294442717, backward:0.03832285817225625, data cost:0.265526359568841 
2022-03-29 05:10:13,124: ============================================================
2022-03-29 05:10:13,125: Epoch 44/45 Batch 1600/7662 eta: 1:45:01.163153	Training Loss 0.4247 (0.4312)	Training Prec@1 92.578 (92.139)	Training Prec@5 95.312 (95.121)	
2022-03-29 05:10:13,125: ============================================================
2022-03-29 05:11:00,212: time cost, forward:0.16427113000893326, backward:0.03820805622592542, data cost:0.2665952495296539 
2022-03-29 05:11:00,212: ============================================================
2022-03-29 05:11:00,212: Epoch 44/45 Batch 1700/7662 eta: 1:46:55.675851	Training Loss 0.4331 (0.4313)	Training Prec@1 91.797 (92.131)	Training Prec@5 94.727 (95.117)	
2022-03-29 05:11:00,212: ============================================================
2022-03-29 05:11:46,322: time cost, forward:0.16357815338546133, backward:0.038091277466541264, data cost:0.26694610981625805 
2022-03-29 05:11:46,323: ============================================================
2022-03-29 05:11:46,324: Epoch 44/45 Batch 1800/7662 eta: 1:43:56.548809	Training Loss 0.4362 (0.4312)	Training Prec@1 95.117 (92.144)	Training Prec@5 96.875 (95.126)	
2022-03-29 05:11:46,324: ============================================================
2022-03-29 05:12:31,153: time cost, forward:0.16213395094607866, backward:0.03803187021774766, data cost:0.26738354028558153 
2022-03-29 05:12:31,153: ============================================================
2022-03-29 05:12:31,154: Epoch 44/45 Batch 1900/7662 eta: 1:40:18.428962	Training Loss 0.4349 (0.4312)	Training Prec@1 91.602 (92.139)	Training Prec@5 94.141 (95.116)	
2022-03-29 05:12:31,154: ============================================================
2022-03-29 05:13:18,074: time cost, forward:0.16152894634076986, backward:0.037902075627733914, data cost:0.2681698585641927 
2022-03-29 05:13:18,075: ============================================================
2022-03-29 05:13:18,075: Epoch 44/45 Batch 2000/7662 eta: 1:44:12.276782	Training Loss 0.4396 (0.4312)	Training Prec@1 92.188 (92.146)	Training Prec@5 94.531 (95.124)	
2022-03-29 05:13:18,075: ============================================================
2022-03-29 05:14:05,894: time cost, forward:0.1632009437392018, backward:0.038033363420432835, data cost:0.2668131057735623 
2022-03-29 05:14:05,894: ============================================================
2022-03-29 05:14:05,895: Epoch 44/45 Batch 2100/7662 eta: 1:45:24.145645	Training Loss 0.4327 (0.4312)	Training Prec@1 91.602 (92.142)	Training Prec@5 93.945 (95.121)	
2022-03-29 05:14:05,895: ============================================================
2022-03-29 05:14:52,280: time cost, forward:0.16303238797155278, backward:0.03805750887629226, data cost:0.26678596035140706 
2022-03-29 05:14:52,280: ============================================================
2022-03-29 05:14:52,280: Epoch 44/45 Batch 2200/7662 eta: 1:41:28.147907	Training Loss 0.4319 (0.4313)	Training Prec@1 89.453 (92.138)	Training Prec@5 93.164 (95.116)	
2022-03-29 05:14:52,281: ============================================================
2022-03-29 05:15:37,403: time cost, forward:0.16256754104859833, backward:0.03801122246850517, data cost:0.266563078692396 
2022-03-29 05:15:37,404: ============================================================
2022-03-29 05:15:37,404: Epoch 44/45 Batch 2300/7662 eta: 1:37:57.328188	Training Loss 0.4314 (0.4313)	Training Prec@1 91.992 (92.137)	Training Prec@5 95.312 (95.117)	
2022-03-29 05:15:37,404: ============================================================
2022-03-29 05:16:25,610: time cost, forward:0.16316469742288783, backward:0.03801868467740389, data cost:0.2665591885915345 
2022-03-29 05:16:25,611: ============================================================
2022-03-29 05:16:25,611: Epoch 44/45 Batch 2400/7662 eta: 1:43:50.742611	Training Loss 0.4344 (0.4314)	Training Prec@1 91.602 (92.123)	Training Prec@5 95.117 (95.105)	
2022-03-29 05:16:25,611: ============================================================
2022-03-29 05:17:09,796: time cost, forward:0.16168037382494502, backward:0.03783380388975048, data cost:0.26717882558983674 
2022-03-29 05:17:09,797: ============================================================
2022-03-29 05:17:09,797: Epoch 44/45 Batch 2500/7662 eta: 1:34:26.869344	Training Loss 0.4380 (0.4314)	Training Prec@1 90.430 (92.119)	Training Prec@5 93.945 (95.101)	
2022-03-29 05:17:09,797: ============================================================
2022-03-29 05:17:57,847: time cost, forward:0.16249601801526964, backward:0.03784878009005022, data cost:0.26684762157353586 
2022-03-29 05:17:57,847: ============================================================
2022-03-29 05:17:57,847: Epoch 44/45 Batch 2600/7662 eta: 1:41:54.423566	Training Loss 0.4323 (0.4314)	Training Prec@1 91.602 (92.117)	Training Prec@5 93.359 (95.100)	
2022-03-29 05:17:57,848: ============================================================
2022-03-29 05:18:44,354: time cost, forward:0.16286009450716724, backward:0.037933307384817455, data cost:0.2663096426680778 
2022-03-29 05:18:44,355: ============================================================
2022-03-29 05:18:44,355: Epoch 44/45 Batch 2700/7662 eta: 1:37:51.578338	Training Loss 0.4360 (0.4314)	Training Prec@1 91.602 (92.111)	Training Prec@5 95.312 (95.098)	
2022-03-29 05:18:44,355: ============================================================
2022-03-29 05:19:29,471: time cost, forward:0.1621395948743258, backward:0.03783427634039876, data cost:0.26654442679503 
2022-03-29 05:19:29,472: ============================================================
2022-03-29 05:19:29,472: Epoch 44/45 Batch 2800/7662 eta: 1:34:10.860455	Training Loss 0.4300 (0.4314)	Training Prec@1 92.383 (92.113)	Training Prec@5 96.680 (95.102)	
2022-03-29 05:19:29,472: ============================================================
2022-03-29 05:20:15,331: time cost, forward:0.16106772365221364, backward:0.03776049178071826, data cost:0.2673862549550536 
2022-03-29 05:20:15,332: ============================================================
2022-03-29 05:20:15,332: Epoch 44/45 Batch 2900/7662 eta: 1:34:58.110734	Training Loss 0.4278 (0.4314)	Training Prec@1 92.578 (92.109)	Training Prec@5 95.312 (95.098)	
2022-03-29 05:20:15,332: ============================================================
2022-03-29 05:21:01,631: time cost, forward:0.16016869451173665, backward:0.03772191343088077, data cost:0.26821866413878376 
2022-03-29 05:21:01,631: ============================================================
2022-03-29 05:21:01,631: Epoch 44/45 Batch 3000/7662 eta: 1:35:06.401355	Training Loss 0.4293 (0.4314)	Training Prec@1 89.648 (92.119)	Training Prec@5 93.750 (95.104)	
2022-03-29 05:21:01,631: ============================================================
2022-03-29 05:21:47,739: time cost, forward:0.1603493314283284, backward:0.03766246202031271, data cost:0.2678940877794412 
2022-03-29 05:21:47,739: ============================================================
2022-03-29 05:21:47,739: Epoch 44/45 Batch 3100/7662 eta: 1:33:56.728916	Training Loss 0.4278 (0.4314)	Training Prec@1 93.359 (92.123)	Training Prec@5 96.680 (95.109)	
2022-03-29 05:21:47,739: ============================================================
2022-03-29 05:22:34,029: time cost, forward:0.15979907325596762, backward:0.037529550518382894, data cost:0.268458988562939 
2022-03-29 05:22:34,029: ============================================================
2022-03-29 05:22:34,029: Epoch 44/45 Batch 3200/7662 eta: 1:33:32.665646	Training Loss 0.4336 (0.4314)	Training Prec@1 91.016 (92.123)	Training Prec@5 94.922 (95.108)	
2022-03-29 05:22:34,030: ============================================================
2022-03-29 05:23:18,781: time cost, forward:0.15883125742842624, backward:0.03745678136767167, data cost:0.2689341318610944 
2022-03-29 05:23:18,781: ============================================================
2022-03-29 05:23:18,782: Epoch 44/45 Batch 3300/7662 eta: 1:29:41.456079	Training Loss 0.4155 (0.4314)	Training Prec@1 93.750 (92.117)	Training Prec@5 96.484 (95.107)	
2022-03-29 05:23:18,782: ============================================================
2022-03-29 05:24:03,421: time cost, forward:0.15726193241176623, backward:0.03735226496207991, data cost:0.2700353067880099 
2022-03-29 05:24:03,421: ============================================================
2022-03-29 05:24:03,422: Epoch 44/45 Batch 3400/7662 eta: 1:28:43.308356	Training Loss 0.4224 (0.4314)	Training Prec@1 93.555 (92.119)	Training Prec@5 95.703 (95.109)	
2022-03-29 05:24:03,422: ============================================================
2022-03-29 05:24:51,156: time cost, forward:0.15788596389838103, backward:0.03737247177586279, data cost:0.26974774790205386 
2022-03-29 05:24:51,157: ============================================================
2022-03-29 05:24:51,157: Epoch 44/45 Batch 3500/7662 eta: 1:34:04.710059	Training Loss 0.4441 (0.4314)	Training Prec@1 91.211 (92.125)	Training Prec@5 95.117 (95.114)	
2022-03-29 05:24:51,157: ============================================================
2022-03-29 05:25:36,488: time cost, forward:0.15757880213526296, backward:0.03734443889256483, data cost:0.269740944936826 
2022-03-29 05:25:36,488: ============================================================
2022-03-29 05:25:36,488: Epoch 44/45 Batch 3600/7662 eta: 1:28:35.075527	Training Loss 0.4224 (0.4314)	Training Prec@1 91.797 (92.120)	Training Prec@5 94.336 (95.111)	
2022-03-29 05:25:36,488: ============================================================
2022-03-29 05:26:21,209: time cost, forward:0.156818085987847, backward:0.03712669879431723, data cost:0.27022398062801645 
2022-03-29 05:26:21,209: ============================================================
2022-03-29 05:26:21,209: Epoch 44/45 Batch 3700/7662 eta: 1:26:38.861727	Training Loss 0.4249 (0.4314)	Training Prec@1 94.336 (92.118)	Training Prec@5 96.680 (95.112)	
2022-03-29 05:26:21,210: ============================================================
2022-03-29 05:27:06,060: time cost, forward:0.15548249331547354, backward:0.037031911617519044, data cost:0.2712324532310283 
2022-03-29 05:27:06,060: ============================================================
2022-03-29 05:27:06,060: Epoch 44/45 Batch 3800/7662 eta: 1:26:09.073856	Training Loss 0.4330 (0.4314)	Training Prec@1 93.164 (92.123)	Training Prec@5 95.703 (95.117)	
2022-03-29 05:27:06,061: ============================================================
2022-03-29 05:27:50,705: time cost, forward:0.15421667860911178, backward:0.03692397902518794, data cost:0.27214107534218274 
2022-03-29 05:27:50,705: ============================================================
2022-03-29 05:27:50,705: Epoch 44/45 Batch 3900/7662 eta: 1:25:00.690540	Training Loss 0.4189 (0.4314)	Training Prec@1 93.750 (92.127)	Training Prec@5 95.898 (95.117)	
2022-03-29 05:27:50,706: ============================================================
2022-03-29 05:28:39,394: time cost, forward:0.1547974715622761, backward:0.036881427760123014, data cost:0.2721726230216879 
2022-03-29 05:28:39,395: ============================================================
2022-03-29 05:28:39,395: Epoch 44/45 Batch 4000/7662 eta: 1:31:54.090773	Training Loss 0.4352 (0.4314)	Training Prec@1 91.797 (92.130)	Training Prec@5 93.555 (95.119)	
2022-03-29 05:28:39,396: ============================================================
2022-03-29 05:29:25,607: time cost, forward:0.15521732252613746, backward:0.03681989116301098, data cost:0.2717521146437865 
2022-03-29 05:29:25,607: ============================================================
2022-03-29 05:29:25,608: Epoch 44/45 Batch 4100/7662 eta: 1:26:27.368042	Training Loss 0.4363 (0.4314)	Training Prec@1 90.234 (92.131)	Training Prec@5 93.945 (95.118)	
2022-03-29 05:29:25,608: ============================================================
2022-03-29 05:30:10,126: time cost, forward:0.15414172713317653, backward:0.03669388693382298, data cost:0.2725156346057875 
2022-03-29 05:30:10,135: ============================================================
2022-03-29 05:30:10,136: Epoch 44/45 Batch 4200/7662 eta: 1:22:33.724311	Training Loss 0.4349 (0.4313)	Training Prec@1 92.188 (92.133)	Training Prec@5 95.703 (95.121)	
2022-03-29 05:30:10,136: ============================================================
2022-03-29 05:30:55,815: time cost, forward:0.15411319558524508, backward:0.036677929822110274, data cost:0.2723809546386122 
2022-03-29 05:30:55,815: ============================================================
2022-03-29 05:30:55,816: Epoch 44/45 Batch 4300/7662 eta: 1:23:56.232099	Training Loss 0.4284 (0.4313)	Training Prec@1 91.016 (92.136)	Training Prec@5 94.922 (95.122)	
2022-03-29 05:30:55,816: ============================================================
2022-03-29 05:31:41,294: time cost, forward:0.15355918504455246, backward:0.03662469636908876, data cost:0.27281635044433494 
2022-03-29 05:31:41,295: ============================================================
2022-03-29 05:31:41,295: Epoch 44/45 Batch 4400/7662 eta: 1:22:48.610298	Training Loss 0.4361 (0.4313)	Training Prec@1 91.797 (92.137)	Training Prec@5 94.531 (95.120)	
2022-03-29 05:31:41,295: ============================================================
2022-03-29 05:32:29,902: time cost, forward:0.15428188563082107, backward:0.03680929419039938, data cost:0.2723919076637629 
2022-03-29 05:32:29,902: ============================================================
2022-03-29 05:32:29,902: Epoch 44/45 Batch 4500/7662 eta: 1:27:41.727790	Training Loss 0.4269 (0.4313)	Training Prec@1 90.820 (92.142)	Training Prec@5 93.164 (95.123)	
2022-03-29 05:32:29,902: ============================================================
2022-03-29 05:33:17,653: time cost, forward:0.1550396402184407, backward:0.03687919360395358, data cost:0.27183830870263187 
2022-03-29 05:33:17,653: ============================================================
2022-03-29 05:33:17,654: Epoch 44/45 Batch 4600/7662 eta: 1:25:21.378511	Training Loss 0.4220 (0.4313)	Training Prec@1 95.312 (92.145)	Training Prec@5 97.266 (95.124)	
2022-03-29 05:33:17,654: ============================================================
2022-03-29 05:34:03,628: time cost, forward:0.15487425001054705, backward:0.036889879773033, data cost:0.2719074376315912 
2022-03-29 05:34:03,628: ============================================================
2022-03-29 05:34:03,629: Epoch 44/45 Batch 4700/7662 eta: 1:21:24.806097	Training Loss 0.4271 (0.4313)	Training Prec@1 91.406 (92.144)	Training Prec@5 94.922 (95.122)	
2022-03-29 05:34:03,629: ============================================================
2022-03-29 05:34:48,956: time cost, forward:0.1541251920118608, backward:0.03683144555883771, data cost:0.27249353829709955 
2022-03-29 05:34:48,956: ============================================================
2022-03-29 05:34:48,956: Epoch 44/45 Batch 4800/7662 eta: 1:19:30.740013	Training Loss 0.4408 (0.4312)	Training Prec@1 90.430 (92.146)	Training Prec@5 93.945 (95.124)	
2022-03-29 05:34:48,957: ============================================================
2022-03-29 05:35:37,530: time cost, forward:0.15515231273446334, backward:0.03689482042219571, data cost:0.2718468964112051 
2022-03-29 05:35:37,530: ============================================================
2022-03-29 05:35:37,531: Epoch 44/45 Batch 4900/7662 eta: 1:24:23.884202	Training Loss 0.4273 (0.4312)	Training Prec@1 92.578 (92.150)	Training Prec@5 95.508 (95.127)	
2022-03-29 05:35:37,531: ============================================================
2022-03-29 05:36:21,694: time cost, forward:0.15425325126785305, backward:0.036769312366196384, data cost:0.27241274742489696 
2022-03-29 05:36:21,695: ============================================================
2022-03-29 05:36:21,695: Epoch 44/45 Batch 5000/7662 eta: 1:15:59.957473	Training Loss 0.4252 (0.4312)	Training Prec@1 92.578 (92.147)	Training Prec@5 95.117 (95.125)	
2022-03-29 05:36:21,695: ============================================================
2022-03-29 05:37:08,306: time cost, forward:0.1540365671265193, backward:0.036709970388956736, data cost:0.2727130186934171 
2022-03-29 05:37:08,306: ============================================================
2022-03-29 05:37:08,306: Epoch 44/45 Batch 5100/7662 eta: 1:19:26.008350	Training Loss 0.4183 (0.4312)	Training Prec@1 94.336 (92.148)	Training Prec@5 96.875 (95.127)	
2022-03-29 05:37:08,306: ============================================================
2022-03-29 05:37:56,608: time cost, forward:0.1544841795523457, backward:0.036728393529373585, data cost:0.2726179567477547 
2022-03-29 05:37:56,608: ============================================================
2022-03-29 05:37:56,608: Epoch 44/45 Batch 5200/7662 eta: 1:21:30.555224	Training Loss 0.4269 (0.4312)	Training Prec@1 92.383 (92.147)	Training Prec@5 94.141 (95.126)	
2022-03-29 05:37:56,608: ============================================================
2022-03-29 05:38:43,510: time cost, forward:0.15495956648203715, backward:0.036820714530865634, data cost:0.27214023756022543 
2022-03-29 05:38:43,510: ============================================================
2022-03-29 05:38:43,510: Epoch 44/45 Batch 5300/7662 eta: 1:18:21.943087	Training Loss 0.4352 (0.4312)	Training Prec@1 89.648 (92.147)	Training Prec@5 94.727 (95.127)	
2022-03-29 05:38:43,510: ============================================================
2022-03-29 05:39:28,698: time cost, forward:0.15472969087677368, backward:0.03686518094168259, data cost:0.272087372239154 
2022-03-29 05:39:28,698: ============================================================
2022-03-29 05:39:28,698: Epoch 44/45 Batch 5400/7662 eta: 1:14:44.902915	Training Loss 0.4206 (0.4312)	Training Prec@1 92.383 (92.144)	Training Prec@5 95.312 (95.125)	
2022-03-29 05:39:28,698: ============================================================
2022-03-29 05:40:12,385: time cost, forward:0.1539464538846152, backward:0.03681908110788376, data cost:0.27241794333325275 
2022-03-29 05:40:12,386: ============================================================
2022-03-29 05:40:12,386: Epoch 44/45 Batch 5500/7662 eta: 1:11:32.332035	Training Loss 0.4274 (0.4312)	Training Prec@1 93.750 (92.145)	Training Prec@5 95.508 (95.124)	
2022-03-29 05:40:12,386: ============================================================
2022-03-29 05:40:57,411: time cost, forward:0.15347112027805476, backward:0.0368090604198556, data cost:0.27265909399852556 
2022-03-29 05:40:57,411: ============================================================
2022-03-29 05:40:57,412: Epoch 44/45 Batch 5600/7662 eta: 1:12:58.721279	Training Loss 0.4276 (0.4312)	Training Prec@1 91.797 (92.146)	Training Prec@5 94.727 (95.126)	
2022-03-29 05:40:57,412: ============================================================
2022-03-29 05:41:43,072: time cost, forward:0.15290038755931945, backward:0.03674905428574323, data cost:0.27316737639358074 
2022-03-29 05:41:43,072: ============================================================
2022-03-29 05:41:43,073: Epoch 44/45 Batch 5700/7662 eta: 1:13:14.876231	Training Loss 0.4329 (0.4312)	Training Prec@1 90.234 (92.149)	Training Prec@5 94.922 (95.127)	
2022-03-29 05:41:43,073: ============================================================
2022-03-29 05:42:27,494: time cost, forward:0.15208693219990868, backward:0.036683227218704234, data cost:0.27371371312477727 
2022-03-29 05:42:27,494: ============================================================
2022-03-29 05:42:27,495: Epoch 44/45 Batch 5800/7662 eta: 1:10:31.202079	Training Loss 0.4225 (0.4312)	Training Prec@1 93.555 (92.149)	Training Prec@5 95.508 (95.129)	
2022-03-29 05:42:27,495: ============================================================
2022-03-29 05:43:14,599: time cost, forward:0.1525470044859831, backward:0.03674235374649858, data cost:0.27332685284340535 
2022-03-29 05:43:14,600: ============================================================
2022-03-29 05:43:14,600: Epoch 44/45 Batch 5900/7662 eta: 1:13:59.686947	Training Loss 0.4339 (0.4312)	Training Prec@1 92.578 (92.149)	Training Prec@5 94.922 (95.130)	
2022-03-29 05:43:14,600: ============================================================
2022-03-29 05:43:59,948: time cost, forward:0.15178475238458577, backward:0.03668558126609511, data cost:0.2739880075055692 
2022-03-29 05:43:59,949: ============================================================
2022-03-29 05:43:59,949: Epoch 44/45 Batch 6000/7662 eta: 1:10:28.785911	Training Loss 0.4262 (0.4312)	Training Prec@1 92.969 (92.148)	Training Prec@5 96.094 (95.131)	
2022-03-29 05:43:59,949: ============================================================
2022-03-29 05:44:46,358: time cost, forward:0.1516223100780131, backward:0.0366981425897511, data cost:0.2741577962633625 
2022-03-29 05:44:46,358: ============================================================
2022-03-29 05:44:46,358: Epoch 44/45 Batch 6100/7662 eta: 1:11:21.264971	Training Loss 0.4378 (0.4312)	Training Prec@1 91.602 (92.149)	Training Prec@5 94.727 (95.132)	
2022-03-29 05:44:46,359: ============================================================
2022-03-29 05:45:31,127: time cost, forward:0.15109873325675893, backward:0.03663447384373529, data cost:0.27449440490739885 
2022-03-29 05:45:31,128: ============================================================
2022-03-29 05:45:31,128: Epoch 44/45 Batch 6200/7662 eta: 1:08:05.215049	Training Loss 0.4319 (0.4312)	Training Prec@1 92.773 (92.145)	Training Prec@5 94.727 (95.129)	
2022-03-29 05:45:31,128: ============================================================
2022-03-29 05:46:15,757: time cost, forward:0.1503891455103318, backward:0.03656933859882515, data cost:0.2750129105079967 
2022-03-29 05:46:15,758: ============================================================
2022-03-29 05:46:15,758: Epoch 44/45 Batch 6300/7662 eta: 1:07:07.841480	Training Loss 0.4381 (0.4312)	Training Prec@1 90.234 (92.148)	Training Prec@5 94.141 (95.130)	
2022-03-29 05:46:15,758: ============================================================
2022-03-29 05:47:04,210: time cost, forward:0.150937585499831, backward:0.03660848346012126, data cost:0.27477089914237546 
2022-03-29 05:47:04,210: ============================================================
2022-03-29 05:47:04,210: Epoch 44/45 Batch 6400/7662 eta: 1:12:04.394316	Training Loss 0.4298 (0.4312)	Training Prec@1 90.039 (92.150)	Training Prec@5 94.141 (95.130)	
2022-03-29 05:47:04,211: ============================================================
2022-03-29 05:47:49,492: time cost, forward:0.15064651519633346, backward:0.036568007921875395, data cost:0.27495754064092415 
2022-03-29 05:47:49,493: ============================================================
2022-03-29 05:47:49,493: Epoch 44/45 Batch 6500/7662 eta: 1:06:36.171791	Training Loss 0.4208 (0.4312)	Training Prec@1 94.141 (92.150)	Training Prec@5 94.922 (95.130)	
2022-03-29 05:47:49,493: ============================================================
2022-03-29 05:48:36,840: time cost, forward:0.1513596705404768, backward:0.036577767468813895, data cost:0.2743922026704019 
2022-03-29 05:48:36,840: ============================================================
2022-03-29 05:48:36,840: Epoch 44/45 Batch 6600/7662 eta: 1:08:51.088229	Training Loss 0.4309 (0.4312)	Training Prec@1 91.992 (92.147)	Training Prec@5 95.312 (95.127)	
2022-03-29 05:48:36,841: ============================================================
2022-03-29 05:49:25,126: time cost, forward:0.15208748294837726, backward:0.036687217874124094, data cost:0.2738428615174875 
2022-03-29 05:49:25,126: ============================================================
2022-03-29 05:49:25,127: Epoch 44/45 Batch 6700/7662 eta: 1:09:24.683788	Training Loss 0.4389 (0.4312)	Training Prec@1 91.992 (92.148)	Training Prec@5 94.727 (95.128)	
2022-03-29 05:49:25,127: ============================================================
2022-03-29 05:50:11,768: time cost, forward:0.1522829699190176, backward:0.03664710136314826, data cost:0.2737384585882569 
2022-03-29 05:50:11,768: ============================================================
2022-03-29 05:50:11,768: Epoch 44/45 Batch 6800/7662 eta: 1:06:16.214196	Training Loss 0.4347 (0.4312)	Training Prec@1 92.383 (92.146)	Training Prec@5 95.508 (95.127)	
2022-03-29 05:50:11,769: ============================================================
2022-03-29 05:50:59,746: time cost, forward:0.1526914128083598, backward:0.03669103226258731, data cost:0.2735119006965174 
2022-03-29 05:50:59,747: ============================================================
2022-03-29 05:50:59,747: Epoch 44/45 Batch 6900/7662 eta: 1:07:22.199141	Training Loss 0.4336 (0.4312)	Training Prec@1 92.383 (92.143)	Training Prec@5 95.312 (95.126)	
2022-03-29 05:50:59,747: ============================================================
2022-03-29 05:51:47,316: time cost, forward:0.15316313684863828, backward:0.036711474285242914, data cost:0.27319142685258097 
2022-03-29 05:51:47,317: ============================================================
2022-03-29 05:51:47,317: Epoch 44/45 Batch 7000/7662 eta: 1:06:00.178657	Training Loss 0.4362 (0.4312)	Training Prec@1 92.188 (92.147)	Training Prec@5 95.117 (95.128)	
2022-03-29 05:51:47,317: ============================================================
2022-03-29 05:52:32,714: time cost, forward:0.15323602150722127, backward:0.036706645315105535, data cost:0.27297879961413857 
2022-03-29 05:52:32,714: ============================================================
2022-03-29 05:52:32,715: Epoch 44/45 Batch 7100/7662 eta: 1:02:13.961498	Training Loss 0.4461 (0.4312)	Training Prec@1 91.797 (92.145)	Training Prec@5 94.531 (95.126)	
2022-03-29 05:52:32,715: ============================================================
2022-03-29 05:53:18,065: time cost, forward:0.1528335262427878, backward:0.03667828400510271, data cost:0.2732723097053397 
2022-03-29 05:53:18,066: ============================================================
2022-03-29 05:53:18,066: Epoch 44/45 Batch 7200/7662 eta: 1:01:24.803624	Training Loss 0.4290 (0.4312)	Training Prec@1 91.406 (92.145)	Training Prec@5 95.312 (95.126)	
2022-03-29 05:53:18,066: ============================================================
2022-03-29 05:54:06,696: time cost, forward:0.15320320951888, backward:0.036707059767723475, data cost:0.2731948648189613 
2022-03-29 05:54:06,697: ============================================================
2022-03-29 05:54:06,697: Epoch 44/45 Batch 7300/7662 eta: 1:05:02.641657	Training Loss 0.4284 (0.4312)	Training Prec@1 91.992 (92.145)	Training Prec@5 94.336 (95.127)	
2022-03-29 05:54:06,697: ============================================================
2022-03-29 05:54:52,860: time cost, forward:0.15316853579322556, backward:0.03672077298438264, data cost:0.2731947085876403 
2022-03-29 05:54:52,872: ============================================================
2022-03-29 05:54:52,872: Epoch 44/45 Batch 7400/7662 eta: 1:00:59.399658	Training Loss 0.4431 (0.4312)	Training Prec@1 91.211 (92.147)	Training Prec@5 95.312 (95.127)	
2022-03-29 05:54:52,873: ============================================================
2022-03-29 05:55:41,026: time cost, forward:0.15371410664534121, backward:0.03679229005334663, data cost:0.272813132960473 
2022-03-29 05:55:41,027: ============================================================
2022-03-29 05:55:41,027: Epoch 44/45 Batch 7500/7662 eta: 1:02:48.074887	Training Loss 0.4182 (0.4312)	Training Prec@1 91.797 (92.148)	Training Prec@5 94.727 (95.127)	
2022-03-29 05:55:41,027: ============================================================
2022-03-29 05:56:26,448: time cost, forward:0.1538343667387884, backward:0.03677478519328755, data cost:0.27256926842027 
2022-03-29 05:56:26,448: ============================================================
2022-03-29 05:56:26,448: Epoch 44/45 Batch 7600/7662 eta: 0:58:28.823765	Training Loss 0.4378 (0.4312)	Training Prec@1 91.016 (92.149)	Training Prec@5 94.141 (95.127)	
2022-03-29 05:56:26,449: ============================================================
2022-03-29 05:56:56,322: Epoch: 44/45 eta: 0:58:00.208115	Training Loss 0.4403 (0.4312)	Training Prec@1 94.336 (92.152)	Training Prec@5 96.484 (95.129)
2022-03-29 05:56:56,323: ============================================================
2022-03-29 05:56:56,325: Save Checkpoint...
2022-03-29 05:56:56,326: ============================================================
2022-03-29 05:56:58,675: Save done!
2022-03-29 05:56:58,675: ============================================================
2022-03-29 05:57:42,461: time cost, forward:0.12341499328613281, backward:0.03631489204637932, data cost:0.28004687723487315 
2022-03-29 05:57:42,472: ============================================================
2022-03-29 05:57:42,472: Epoch 45/45 Batch 100/7662 eta: 0:55:12.277307	Training Loss 0.4296 (0.4313)	Training Prec@1 92.969 (92.026)	Training Prec@5 95.508 (95.135)	
2022-03-29 05:57:42,473: ============================================================
2022-03-29 05:58:26,666: time cost, forward:0.13172358723741082, backward:0.03602528811699182, data cost:0.2724971040409414 
2022-03-29 05:58:26,667: ============================================================
2022-03-29 05:58:26,667: Epoch 45/45 Batch 200/7662 eta: 0:54:58.228380	Training Loss 0.4272 (0.4310)	Training Prec@1 92.969 (92.119)	Training Prec@5 94.922 (95.151)	
2022-03-29 05:58:26,667: ============================================================
2022-03-29 05:59:14,892: time cost, forward:0.15319290448191972, backward:0.03603840591915475, data cost:0.26475124454817245 
2022-03-29 05:59:14,893: ============================================================
2022-03-29 05:59:14,893: Epoch 45/45 Batch 300/7662 eta: 0:59:10.865376	Training Loss 0.4157 (0.4306)	Training Prec@1 94.727 (92.155)	Training Prec@5 97.461 (95.145)	
2022-03-29 05:59:14,893: ============================================================
2022-03-29 06:00:01,398: time cost, forward:0.15150021729911478, backward:0.03598944047339877, data cost:0.2691908097804937 
2022-03-29 06:00:01,398: ============================================================
2022-03-29 06:00:01,399: Epoch 45/45 Batch 400/7662 eta: 0:56:17.726506	Training Loss 0.4202 (0.4306)	Training Prec@1 92.578 (92.194)	Training Prec@5 94.727 (95.178)	
2022-03-29 06:00:01,399: ============================================================
2022-03-29 06:00:47,578: time cost, forward:0.15260954658110779, backward:0.03648403077899574, data cost:0.2685201082057609 
2022-03-29 06:00:47,578: ============================================================
2022-03-29 06:00:47,578: Epoch 45/45 Batch 500/7662 eta: 0:55:07.861245	Training Loss 0.4304 (0.4306)	Training Prec@1 93.945 (92.187)	Training Prec@5 95.703 (95.179)	
2022-03-29 06:00:47,579: ============================================================
2022-03-29 06:01:33,046: time cost, forward:0.1547704897261223, backward:0.03707710968234105, data cost:0.2650138663131128 
2022-03-29 06:01:33,046: ============================================================
2022-03-29 06:01:33,047: Epoch 45/45 Batch 600/7662 eta: 0:53:31.418661	Training Loss 0.4320 (0.4308)	Training Prec@1 91.211 (92.193)	Training Prec@5 94.336 (95.178)	
2022-03-29 06:01:33,047: ============================================================
2022-03-29 06:02:19,652: time cost, forward:0.15588825727907543, backward:0.03722799591752081, data cost:0.2650831977014719 
2022-03-29 06:02:19,652: ============================================================
2022-03-29 06:02:19,652: Epoch 45/45 Batch 700/7662 eta: 0:54:05.149862	Training Loss 0.4331 (0.4308)	Training Prec@1 93.359 (92.195)	Training Prec@5 96.094 (95.178)	
2022-03-29 06:02:19,652: ============================================================
2022-03-29 06:03:07,725: time cost, forward:0.15694123334968194, backward:0.03741761948796775, data cost:0.266537211863359 
2022-03-29 06:03:07,725: ============================================================
2022-03-29 06:03:07,725: Epoch 45/45 Batch 800/7662 eta: 0:54:59.260541	Training Loss 0.4290 (0.4307)	Training Prec@1 91.406 (92.194)	Training Prec@5 94.336 (95.177)	
2022-03-29 06:03:07,726: ============================================================
2022-03-29 06:03:51,021: time cost, forward:0.15534107544530884, backward:0.03760024066496479, data cost:0.26471510347190236 
2022-03-29 06:03:51,021: ============================================================
2022-03-29 06:03:51,022: Epoch 45/45 Batch 900/7662 eta: 0:48:48.118768	Training Loss 0.4181 (0.4308)	Training Prec@1 94.141 (92.192)	Training Prec@5 97.070 (95.174)	
2022-03-29 06:03:51,022: ============================================================
2022-03-29 06:04:38,644: time cost, forward:0.1566388103458378, backward:0.03753816234218227, data cost:0.26533624455258176 
2022-03-29 06:04:38,644: ============================================================
2022-03-29 06:04:38,645: Epoch 45/45 Batch 1000/7662 eta: 0:52:53.117974	Training Loss 0.4308 (0.4307)	Training Prec@1 91.016 (92.206)	Training Prec@5 94.727 (95.186)	
2022-03-29 06:04:38,645: ============================================================
2022-03-29 06:05:22,316: time cost, forward:0.15283639372425584, backward:0.03713239530089554, data cost:0.26730745135924294 
2022-03-29 06:05:22,317: ============================================================
2022-03-29 06:05:22,317: Epoch 45/45 Batch 1100/7662 eta: 0:47:46.224682	Training Loss 0.4349 (0.4308)	Training Prec@1 89.648 (92.197)	Training Prec@5 93.164 (95.175)	
2022-03-29 06:05:22,317: ============================================================
2022-03-29 06:06:10,238: time cost, forward:0.1546427392283512, backward:0.0372304488858946, data cost:0.26720184957712667 
2022-03-29 06:06:10,249: ============================================================
2022-03-29 06:06:10,249: Epoch 45/45 Batch 1200/7662 eta: 0:51:37.838067	Training Loss 0.4246 (0.4308)	Training Prec@1 94.141 (92.193)	Training Prec@5 96.680 (95.166)	
2022-03-29 06:06:10,249: ============================================================
2022-03-29 06:06:57,299: time cost, forward:0.15535497812237348, backward:0.03730787471040017, data cost:0.26735462511017105 
2022-03-29 06:06:57,300: ============================================================
2022-03-29 06:06:57,300: Epoch 45/45 Batch 1300/7662 eta: 0:49:53.843487	Training Loss 0.4206 (0.4309)	Training Prec@1 93.164 (92.194)	Training Prec@5 94.727 (95.166)	
2022-03-29 06:06:57,300: ============================================================
2022-03-29 06:07:45,942: time cost, forward:0.15729639647772178, backward:0.03769056570368038, data cost:0.26687447525417063 
2022-03-29 06:07:45,942: ============================================================
2022-03-29 06:07:45,943: Epoch 45/45 Batch 1400/7662 eta: 0:50:46.494284	Training Loss 0.4296 (0.4310)	Training Prec@1 93.750 (92.181)	Training Prec@5 96.289 (95.158)	
2022-03-29 06:07:45,943: ============================================================
2022-03-29 06:08:33,789: time cost, forward:0.16050411320432495, backward:0.03795818554074706, data cost:0.26445501259440496 
2022-03-29 06:08:33,802: ============================================================
2022-03-29 06:08:33,803: Epoch 45/45 Batch 1500/7662 eta: 0:49:09.605578	Training Loss 0.4397 (0.4310)	Training Prec@1 89.844 (92.170)	Training Prec@5 93.945 (95.148)	
2022-03-29 06:08:33,803: ============================================================
2022-03-29 06:09:20,049: time cost, forward:0.1612342592326457, backward:0.03798451790442833, data cost:0.26356275593063994 
2022-03-29 06:09:20,049: ============================================================
2022-03-29 06:09:20,049: Epoch 45/45 Batch 1600/7662 eta: 0:46:43.937641	Training Loss 0.4142 (0.4310)	Training Prec@1 94.141 (92.176)	Training Prec@5 96.680 (95.152)	
2022-03-29 06:09:20,049: ============================================================
2022-03-29 06:10:07,715: time cost, forward:0.16219653039205909, backward:0.03800793856014007, data cost:0.26334676004424384 
2022-03-29 06:10:07,716: ============================================================
2022-03-29 06:10:07,716: Epoch 45/45 Batch 1700/7662 eta: 0:47:22.376460	Training Loss 0.4249 (0.4311)	Training Prec@1 91.992 (92.168)	Training Prec@5 94.922 (95.145)	
2022-03-29 06:10:07,716: ============================================================
2022-03-29 06:10:51,694: time cost, forward:0.16011157746179824, backward:0.03777643797992666, data cost:0.2642883560006787 
2022-03-29 06:10:51,694: ============================================================
2022-03-29 06:10:51,695: Epoch 45/45 Batch 1800/7662 eta: 0:42:58.460106	Training Loss 0.4196 (0.4311)	Training Prec@1 93.555 (92.172)	Training Prec@5 96.680 (95.157)	
2022-03-29 06:10:51,695: ============================================================
2022-03-29 06:11:39,008: time cost, forward:0.16092705186760506, backward:0.03771003639779636, data cost:0.26410402179454867 
2022-03-29 06:11:39,009: ============================================================
2022-03-29 06:11:39,009: Epoch 45/45 Batch 1900/7662 eta: 0:45:26.724541	Training Loss 0.4204 (0.4310)	Training Prec@1 94.531 (92.180)	Training Prec@5 97.266 (95.167)	
2022-03-29 06:11:39,009: ============================================================
2022-03-29 06:12:26,799: time cost, forward:0.16202222507795494, backward:0.037812978640504334, data cost:0.2636090672690013 
2022-03-29 06:12:26,799: ============================================================
2022-03-29 06:12:26,799: Epoch 45/45 Batch 2000/7662 eta: 0:45:06.362658	Training Loss 0.4274 (0.4311)	Training Prec@1 91.211 (92.181)	Training Prec@5 94.531 (95.167)	
2022-03-29 06:12:26,799: ============================================================
2022-03-29 06:13:12,793: time cost, forward:0.16133003850503444, backward:0.037920216709843926, data cost:0.26401001751678455 
2022-03-29 06:13:12,793: ============================================================
2022-03-29 06:13:12,793: Epoch 45/45 Batch 2100/7662 eta: 0:42:38.643525	Training Loss 0.4354 (0.4311)	Training Prec@1 93.359 (92.177)	Training Prec@5 96.484 (95.163)	
2022-03-29 06:13:12,793: ============================================================
2022-03-29 06:13:57,898: time cost, forward:0.1601175585352545, backward:0.037854399774333684, data cost:0.26474968885063527 
2022-03-29 06:13:57,909: ============================================================
2022-03-29 06:13:57,909: Epoch 45/45 Batch 2200/7662 eta: 0:41:04.677516	Training Loss 0.4287 (0.4311)	Training Prec@1 93.164 (92.179)	Training Prec@5 96.094 (95.167)	
2022-03-29 06:13:57,909: ============================================================
2022-03-29 06:14:43,213: time cost, forward:0.15898274276089597, backward:0.037787600567466335, data cost:0.26549384292181083 
2022-03-29 06:14:43,214: ============================================================
2022-03-29 06:14:43,214: Epoch 45/45 Batch 2300/7662 eta: 0:40:29.701336	Training Loss 0.4397 (0.4311)	Training Prec@1 91.602 (92.175)	Training Prec@5 95.117 (95.168)	
2022-03-29 06:14:43,214: ============================================================
2022-03-29 06:15:30,122: time cost, forward:0.15942304479226116, backward:0.03779789356948834, data cost:0.26526904165769627 
2022-03-29 06:15:30,123: ============================================================
2022-03-29 06:15:30,123: Epoch 45/45 Batch 2400/7662 eta: 0:41:08.828822	Training Loss 0.4388 (0.4311)	Training Prec@1 91.016 (92.175)	Training Prec@5 94.727 (95.165)	
2022-03-29 06:15:30,123: ============================================================
2022-03-29 06:16:18,310: time cost, forward:0.1606929694332567, backward:0.03792932664169794, data cost:0.26462373813661205 
2022-03-29 06:16:18,311: ============================================================
2022-03-29 06:16:18,311: Epoch 45/45 Batch 2500/7662 eta: 0:41:27.932775	Training Loss 0.4324 (0.4312)	Training Prec@1 92.578 (92.177)	Training Prec@5 95.898 (95.166)	
2022-03-29 06:16:18,311: ============================================================
2022-03-29 06:17:02,454: time cost, forward:0.15929664341749344, backward:0.037767164979636, data cost:0.26532305869380984 
2022-03-29 06:17:02,454: ============================================================
2022-03-29 06:17:02,455: Epoch 45/45 Batch 2600/7662 eta: 0:37:15.004253	Training Loss 0.4266 (0.4311)	Training Prec@1 90.820 (92.179)	Training Prec@5 94.141 (95.169)	
2022-03-29 06:17:02,455: ============================================================
2022-03-29 06:17:47,119: time cost, forward:0.1574749332659772, backward:0.03758973031187111, data cost:0.26672315191189067 
2022-03-29 06:17:47,119: ============================================================
2022-03-29 06:17:47,120: Epoch 45/45 Batch 2700/7662 eta: 0:36:56.716186	Training Loss 0.4251 (0.4311)	Training Prec@1 92.578 (92.180)	Training Prec@5 94.922 (95.168)	
2022-03-29 06:17:47,120: ============================================================
2022-03-29 06:18:35,797: time cost, forward:0.15866810119590746, backward:0.03767783192917039, data cost:0.2663451793066899 
2022-03-29 06:18:35,798: ============================================================
2022-03-29 06:18:35,798: Epoch 45/45 Batch 2800/7662 eta: 0:39:27.223846	Training Loss 0.4447 (0.4312)	Training Prec@1 89.453 (92.173)	Training Prec@5 93.555 (95.162)	
2022-03-29 06:18:35,798: ============================================================
2022-03-29 06:19:20,547: time cost, forward:0.1585606773708063, backward:0.03761661566714247, data cost:0.2659356188634298 
2022-03-29 06:19:20,547: ============================================================
2022-03-29 06:19:20,547: Epoch 45/45 Batch 2900/7662 eta: 0:35:31.413895	Training Loss 0.4307 (0.4312)	Training Prec@1 93.359 (92.170)	Training Prec@5 96.484 (95.157)	
2022-03-29 06:19:20,547: ============================================================
2022-03-29 06:20:07,621: time cost, forward:0.1588179241541665, backward:0.03761171372424129, data cost:0.26596472834936574 
2022-03-29 06:20:07,621: ============================================================
2022-03-29 06:20:07,622: Epoch 45/45 Batch 3000/7662 eta: 0:36:35.078636	Training Loss 0.4336 (0.4312)	Training Prec@1 91.797 (92.165)	Training Prec@5 95.312 (95.155)	
2022-03-29 06:20:07,622: ============================================================
2022-03-29 06:20:55,905: time cost, forward:0.16074553925439442, backward:0.037735003815731256, data cost:0.2645584718378639 
2022-03-29 06:20:55,905: ============================================================
2022-03-29 06:20:55,905: Epoch 45/45 Batch 3100/7662 eta: 0:36:43.183707	Training Loss 0.4349 (0.4311)	Training Prec@1 91.016 (92.169)	Training Prec@5 94.531 (95.154)	
2022-03-29 06:20:55,905: ============================================================
2022-03-29 06:21:43,502: time cost, forward:0.16166143113279685, backward:0.037733870619868964, data cost:0.2640290454090592 
2022-03-29 06:21:43,513: ============================================================
2022-03-29 06:21:43,513: Epoch 45/45 Batch 3200/7662 eta: 0:35:24.738519	Training Loss 0.4343 (0.4312)	Training Prec@1 90.039 (92.167)	Training Prec@5 94.141 (95.151)	
2022-03-29 06:21:43,514: ============================================================
2022-03-29 06:22:28,344: time cost, forward:0.16133662750230265, backward:0.037669865208417946, data cost:0.26393655337287136 
2022-03-29 06:22:28,344: ============================================================
2022-03-29 06:22:28,344: Epoch 45/45 Batch 3300/7662 eta: 0:32:35.971354	Training Loss 0.4356 (0.4312)	Training Prec@1 92.969 (92.165)	Training Prec@5 94.531 (95.149)	
2022-03-29 06:22:28,344: ============================================================
2022-03-29 06:23:13,340: time cost, forward:0.16107632013305773, backward:0.037683380530419926, data cost:0.2637902055988946 
2022-03-29 06:23:13,340: ============================================================
2022-03-29 06:23:13,340: Epoch 45/45 Batch 3400/7662 eta: 0:31:58.180946	Training Loss 0.4295 (0.4312)	Training Prec@1 92.578 (92.159)	Training Prec@5 95.508 (95.143)	
2022-03-29 06:23:13,340: ============================================================
2022-03-29 06:23:57,694: time cost, forward:0.16030806628388314, backward:0.03756414450519798, data cost:0.26409547613088863 
2022-03-29 06:23:57,695: ============================================================
2022-03-29 06:23:57,695: Epoch 45/45 Batch 3500/7662 eta: 0:30:46.498561	Training Loss 0.4290 (0.4311)	Training Prec@1 92.578 (92.159)	Training Prec@5 95.508 (95.142)	
2022-03-29 06:23:57,695: ============================================================
2022-03-29 06:24:42,767: time cost, forward:0.15938752159273403, backward:0.03750453759776648, data cost:0.2647720836009804 
2022-03-29 06:24:42,768: ============================================================
2022-03-29 06:24:42,768: Epoch 45/45 Batch 3600/7662 eta: 0:30:31.294803	Training Loss 0.4314 (0.4311)	Training Prec@1 90.039 (92.160)	Training Prec@5 94.141 (95.143)	
2022-03-29 06:24:42,768: ============================================================
2022-03-29 06:25:29,415: time cost, forward:0.16026569966143225, backward:0.03752020282595826, data cost:0.2639794282637341 
2022-03-29 06:25:29,415: ============================================================
2022-03-29 06:25:29,415: Epoch 45/45 Batch 3700/7662 eta: 0:30:48.649119	Training Loss 0.4208 (0.4311)	Training Prec@1 94.141 (92.156)	Training Prec@5 96.094 (95.138)	
2022-03-29 06:25:29,415: ============================================================
2022-03-29 06:26:12,959: time cost, forward:0.15906870556555475, backward:0.037424118338713175, data cost:0.26453725499019837 
2022-03-29 06:26:12,960: ============================================================
2022-03-29 06:26:12,960: Epoch 45/45 Batch 3800/7662 eta: 0:28:02.132393	Training Loss 0.4305 (0.4311)	Training Prec@1 93.359 (92.159)	Training Prec@5 96.094 (95.140)	
2022-03-29 06:26:12,960: ============================================================
2022-03-29 06:26:57,917: time cost, forward:0.15813641708366197, backward:0.03731336511688741, data cost:0.2652871394713862 
2022-03-29 06:26:57,918: ============================================================
2022-03-29 06:26:57,918: Epoch 45/45 Batch 3900/7662 eta: 0:28:11.775038	Training Loss 0.4335 (0.4311)	Training Prec@1 92.383 (92.159)	Training Prec@5 95.703 (95.142)	
2022-03-29 06:26:57,918: ============================================================
2022-03-29 06:27:42,819: time cost, forward:0.15682296783931854, backward:0.0372023680830753, data cost:0.2663984033399059 
2022-03-29 06:27:42,819: ============================================================
2022-03-29 06:27:42,819: Epoch 45/45 Batch 4000/7662 eta: 0:27:24.729386	Training Loss 0.4392 (0.4311)	Training Prec@1 93.164 (92.156)	Training Prec@5 95.508 (95.138)	
2022-03-29 06:27:42,820: ============================================================
2022-03-29 06:28:28,421: time cost, forward:0.15633000766803473, backward:0.03711073164184898, data cost:0.2668868279742101 
2022-03-29 06:28:28,432: ============================================================
2022-03-29 06:28:28,433: Epoch 45/45 Batch 4100/7662 eta: 0:27:05.197023	Training Loss 0.4443 (0.4311)	Training Prec@1 92.188 (92.159)	Training Prec@5 94.727 (95.139)	
2022-03-29 06:28:28,433: ============================================================
2022-03-29 06:29:12,701: time cost, forward:0.15549647992609456, backward:0.03703954606488876, data cost:0.26734961620765973 
2022-03-29 06:29:12,702: ============================================================
2022-03-29 06:29:12,702: Epoch 45/45 Batch 4200/7662 eta: 0:25:33.037511	Training Loss 0.4468 (0.4311)	Training Prec@1 90.430 (92.160)	Training Prec@5 93.945 (95.142)	
2022-03-29 06:29:12,702: ============================================================
2022-03-29 06:29:57,364: time cost, forward:0.15505414586977836, backward:0.0370331433906919, data cost:0.26748318227398366 
2022-03-29 06:29:57,364: ============================================================
2022-03-29 06:29:57,364: Epoch 45/45 Batch 4300/7662 eta: 0:25:02.001796	Training Loss 0.4202 (0.4311)	Training Prec@1 94.727 (92.163)	Training Prec@5 96.484 (95.142)	
2022-03-29 06:29:57,364: ============================================================
2022-03-29 06:30:43,566: time cost, forward:0.15489858891590533, backward:0.037010405545452554, data cost:0.26770544431512533 
2022-03-29 06:30:43,566: ============================================================
2022-03-29 06:30:43,566: Epoch 45/45 Batch 4400/7662 eta: 0:25:07.575411	Training Loss 0.4368 (0.4311)	Training Prec@1 91.016 (92.162)	Training Prec@5 94.531 (95.142)	
2022-03-29 06:30:43,567: ============================================================
2022-03-29 06:31:28,475: time cost, forward:0.15465451394433205, backward:0.036976911513427545, data cost:0.26772394262967997 
2022-03-29 06:31:28,475: ============================================================
2022-03-29 06:31:28,475: Epoch 45/45 Batch 4500/7662 eta: 0:23:40.472655	Training Loss 0.4412 (0.4311)	Training Prec@1 92.188 (92.166)	Training Prec@5 95.703 (95.144)	
2022-03-29 06:31:28,476: ============================================================
2022-03-29 06:32:12,069: time cost, forward:0.15358427276453732, backward:0.03690149737949293, data cost:0.26834512824829726 
2022-03-29 06:32:12,070: ============================================================
2022-03-29 06:32:12,070: Epoch 45/45 Batch 4600/7662 eta: 0:22:15.292307	Training Loss 0.4331 (0.4311)	Training Prec@1 90.820 (92.158)	Training Prec@5 93.555 (95.140)	
2022-03-29 06:32:12,070: ============================================================
2022-03-29 06:32:56,176: time cost, forward:0.15271061632221722, backward:0.036816548682142, data cost:0.2689135229366844 
2022-03-29 06:32:56,177: ============================================================
2022-03-29 06:32:56,177: Epoch 45/45 Batch 4700/7662 eta: 0:21:46.891819	Training Loss 0.4282 (0.4311)	Training Prec@1 93.750 (92.159)	Training Prec@5 95.117 (95.141)	
2022-03-29 06:32:56,177: ============================================================
2022-03-29 06:33:40,390: time cost, forward:0.15171848279432745, backward:0.036769560958773276, data cost:0.2696116370045908 
2022-03-29 06:33:40,390: ============================================================
2022-03-29 06:33:40,390: Epoch 45/45 Batch 4800/7662 eta: 0:21:05.831318	Training Loss 0.4272 (0.4311)	Training Prec@1 92.383 (92.151)	Training Prec@5 95.898 (95.136)	
2022-03-29 06:33:40,390: ============================================================
2022-03-29 06:34:25,330: time cost, forward:0.15077285173840121, backward:0.03673224216530483, data cost:0.27040945352109313 
2022-03-29 06:34:25,330: ============================================================
2022-03-29 06:34:25,330: Epoch 45/45 Batch 4900/7662 eta: 0:20:41.696543	Training Loss 0.4226 (0.4311)	Training Prec@1 92.578 (92.152)	Training Prec@5 95.508 (95.137)	
2022-03-29 06:34:25,331: ============================================================
2022-03-29 06:35:10,013: time cost, forward:0.1502285767708046, backward:0.0366878697432907, data cost:0.27079242280684224 
2022-03-29 06:35:10,025: ============================================================
2022-03-29 06:35:10,026: Epoch 45/45 Batch 5000/7662 eta: 0:19:50.233213	Training Loss 0.4250 (0.4311)	Training Prec@1 90.820 (92.154)	Training Prec@5 95.703 (95.141)	
2022-03-29 06:35:10,026: ============================================================
2022-03-29 06:35:55,035: time cost, forward:0.14979183063667928, backward:0.03665591408444704, data cost:0.2710864883844795 
2022-03-29 06:35:55,035: ============================================================
2022-03-29 06:35:55,036: Epoch 45/45 Batch 5100/7662 eta: 0:19:13.603794	Training Loss 0.4421 (0.4311)	Training Prec@1 89.844 (92.154)	Training Prec@5 93.555 (95.140)	
2022-03-29 06:35:55,036: ============================================================
2022-03-29 06:36:41,389: time cost, forward:0.1499404907685148, backward:0.03665109477746622, data cost:0.27104946108225747 
2022-03-29 06:36:41,390: ============================================================
2022-03-29 06:36:41,390: Epoch 45/45 Batch 5200/7662 eta: 0:19:01.702493	Training Loss 0.4405 (0.4312)	Training Prec@1 92.383 (92.152)	Training Prec@5 95.117 (95.137)	
2022-03-29 06:36:41,390: ============================================================
2022-03-29 06:37:30,353: time cost, forward:0.15075739920645487, backward:0.03673581070080189, data cost:0.2707367908911877 
2022-03-29 06:37:30,353: ============================================================
2022-03-29 06:37:30,353: Epoch 45/45 Batch 5300/7662 eta: 0:19:17.005145	Training Loss 0.4360 (0.4312)	Training Prec@1 90.039 (92.148)	Training Prec@5 95.703 (95.135)	
2022-03-29 06:37:30,353: ============================================================
2022-03-29 06:38:19,712: time cost, forward:0.1519891801951748, backward:0.03680971269807146, data cost:0.2700850852309918 
2022-03-29 06:38:19,712: ============================================================
2022-03-29 06:38:19,712: Epoch 45/45 Batch 5400/7662 eta: 0:18:36.992578	Training Loss 0.4249 (0.4312)	Training Prec@1 91.797 (92.144)	Training Prec@5 94.531 (95.132)	
2022-03-29 06:38:19,712: ============================================================
2022-03-29 06:39:04,053: time cost, forward:0.15164320042706073, backward:0.03678178149887726, data cost:0.2701598174096368 
2022-03-29 06:39:04,054: ============================================================
2022-03-29 06:39:04,054: Epoch 45/45 Batch 5500/7662 eta: 0:15:59.112463	Training Loss 0.4213 (0.4312)	Training Prec@1 92.969 (92.144)	Training Prec@5 96.875 (95.131)	
2022-03-29 06:39:04,054: ============================================================
2022-03-29 06:39:51,115: time cost, forward:0.1518342878205752, backward:0.036743301007338434, data cost:0.2702213124859267 
2022-03-29 06:39:51,115: ============================================================
2022-03-29 06:39:51,116: Epoch 45/45 Batch 5600/7662 eta: 0:16:10.885898	Training Loss 0.4259 (0.4312)	Training Prec@1 94.531 (92.145)	Training Prec@5 96.680 (95.132)	
2022-03-29 06:39:51,116: ============================================================
2022-03-29 06:40:38,015: time cost, forward:0.1522492968339547, backward:0.036730749269476434, data cost:0.26997737822605444 
2022-03-29 06:40:38,015: ============================================================
2022-03-29 06:40:38,015: Epoch 45/45 Batch 5700/7662 eta: 0:15:20.637305	Training Loss 0.4279 (0.4312)	Training Prec@1 91.602 (92.143)	Training Prec@5 93.945 (95.129)	
2022-03-29 06:40:38,015: ============================================================
2022-03-29 06:41:22,144: time cost, forward:0.15144656962167602, backward:0.03665208240935958, data cost:0.2705404037318367 
2022-03-29 06:41:22,144: ============================================================
2022-03-29 06:41:22,144: Epoch 45/45 Batch 5800/7662 eta: 0:13:42.125739	Training Loss 0.4329 (0.4312)	Training Prec@1 92.773 (92.143)	Training Prec@5 95.508 (95.130)	
2022-03-29 06:41:22,144: ============================================================
2022-03-29 06:42:06,133: time cost, forward:0.15077114173933134, backward:0.03660243526315826, data cost:0.2709429201422596 
2022-03-29 06:42:06,133: ============================================================
2022-03-29 06:42:06,133: Epoch 45/45 Batch 5900/7662 eta: 0:12:55.523776	Training Loss 0.4303 (0.4312)	Training Prec@1 91.211 (92.141)	Training Prec@5 94.727 (95.127)	
2022-03-29 06:42:06,133: ============================================================
2022-03-29 06:42:49,358: time cost, forward:0.15008889680942866, backward:0.036548819019707426, data cost:0.27123905913315927 
2022-03-29 06:42:49,358: ============================================================
2022-03-29 06:42:49,358: Epoch 45/45 Batch 6000/7662 eta: 0:11:58.834797	Training Loss 0.4330 (0.4312)	Training Prec@1 92.969 (92.141)	Training Prec@5 95.703 (95.128)	
2022-03-29 06:42:49,359: ============================================================
2022-03-29 06:43:36,748: time cost, forward:0.15069909302166865, backward:0.036566746979585375, data cost:0.2708656471231801 
2022-03-29 06:43:36,749: ============================================================
2022-03-29 06:43:36,749: Epoch 45/45 Batch 6100/7662 eta: 0:12:20.716617	Training Loss 0.4188 (0.4312)	Training Prec@1 93.359 (92.144)	Training Prec@5 95.508 (95.130)	
2022-03-29 06:43:36,749: ============================================================
2022-03-29 06:44:20,771: time cost, forward:0.15020030635963583, backward:0.03654323218041494, data cost:0.27108316753040995 
2022-03-29 06:44:20,771: ============================================================
2022-03-29 06:44:20,772: Epoch 45/45 Batch 6200/7662 eta: 0:10:44.049472	Training Loss 0.4295 (0.4312)	Training Prec@1 91.406 (92.143)	Training Prec@5 94.531 (95.130)	
2022-03-29 06:44:20,772: ============================================================
2022-03-29 06:45:07,178: time cost, forward:0.1501085325202633, backward:0.036504784885484615, data cost:0.2713085661087363 
2022-03-29 06:45:07,178: ============================================================
2022-03-29 06:45:07,179: Epoch 45/45 Batch 6300/7662 eta: 0:10:32.527424	Training Loss 0.4232 (0.4312)	Training Prec@1 91.992 (92.143)	Training Prec@5 94.922 (95.129)	
2022-03-29 06:45:07,179: ============================================================
2022-03-29 06:45:51,652: time cost, forward:0.15025687150646697, backward:0.0364636900946952, data cost:0.2709911273110377 
2022-03-29 06:45:51,653: ============================================================
2022-03-29 06:45:51,653: Epoch 45/45 Batch 6400/7662 eta: 0:09:21.707716	Training Loss 0.4282 (0.4312)	Training Prec@1 93.945 (92.144)	Training Prec@5 96.484 (95.130)	
2022-03-29 06:45:51,653: ============================================================
2022-03-29 06:46:36,706: time cost, forward:0.1502263909542555, backward:0.03645893870399335, data cost:0.27090282931036536 
2022-03-29 06:46:36,707: ============================================================
2022-03-29 06:46:36,707: Epoch 45/45 Batch 6500/7662 eta: 0:08:43.980584	Training Loss 0.4303 (0.4312)	Training Prec@1 93.945 (92.146)	Training Prec@5 96.680 (95.130)	
2022-03-29 06:46:36,707: ============================================================
2022-03-29 06:47:22,076: time cost, forward:0.15033655077024813, backward:0.03643372619236973, data cost:0.270766200504803 
2022-03-29 06:47:22,076: ============================================================
2022-03-29 06:47:22,077: Epoch 45/45 Batch 6600/7662 eta: 0:08:02.279221	Training Loss 0.4237 (0.4312)	Training Prec@1 92.578 (92.145)	Training Prec@5 95.117 (95.129)	
2022-03-29 06:47:22,077: ============================================================
2022-03-29 06:48:05,844: time cost, forward:0.14977750971808793, backward:0.03638226325021856, data cost:0.27105674613392305 
2022-03-29 06:48:05,845: ============================================================
2022-03-29 06:48:05,845: Epoch 45/45 Batch 6700/7662 eta: 0:07:01.487618	Training Loss 0.4292 (0.4312)	Training Prec@1 90.820 (92.148)	Training Prec@5 95.898 (95.131)	
2022-03-29 06:48:05,845: ============================================================
2022-03-29 06:48:51,626: time cost, forward:0.14941967573388917, backward:0.03634711166816102, data cost:0.2714540903700469 
2022-03-29 06:48:51,626: ============================================================
2022-03-29 06:48:51,626: Epoch 45/45 Batch 6800/7662 eta: 0:06:35.094296	Training Loss 0.4316 (0.4312)	Training Prec@1 92.188 (92.146)	Training Prec@5 95.508 (95.128)	
2022-03-29 06:48:51,627: ============================================================
2022-03-29 06:49:37,447: time cost, forward:0.1490581342492834, backward:0.036320057446100625, data cost:0.2718671402873846 
2022-03-29 06:49:37,458: ============================================================
2022-03-29 06:49:37,458: Epoch 45/45 Batch 6900/7662 eta: 0:05:49.698437	Training Loss 0.4320 (0.4312)	Training Prec@1 92.383 (92.147)	Training Prec@5 95.117 (95.128)	
2022-03-29 06:49:37,459: ============================================================
2022-03-29 06:50:24,081: time cost, forward:0.14917694812060117, backward:0.03630801431961376, data cost:0.2718632202145712 
2022-03-29 06:50:24,081: ============================================================
2022-03-29 06:50:24,081: Epoch 45/45 Batch 7000/7662 eta: 0:05:09.110949	Training Loss 0.4338 (0.4312)	Training Prec@1 93.164 (92.149)	Training Prec@5 95.898 (95.130)	
2022-03-29 06:50:24,082: ============================================================
2022-03-29 06:51:10,868: time cost, forward:0.14915601746064372, backward:0.0363054589866534, data cost:0.27203973976218004 
2022-03-29 06:51:10,868: ============================================================
2022-03-29 06:51:10,868: Epoch 45/45 Batch 7100/7662 eta: 0:04:23.410522	Training Loss 0.4287 (0.4312)	Training Prec@1 90.234 (92.153)	Training Prec@5 93.945 (95.131)	
2022-03-29 06:51:10,868: ============================================================
2022-03-29 06:51:55,027: time cost, forward:0.1489390385682458, backward:0.03628199619458009, data cost:0.2720355655372366 
2022-03-29 06:51:55,027: ============================================================
2022-03-29 06:51:55,027: Epoch 45/45 Batch 7200/7662 eta: 0:03:24.454397	Training Loss 0.4261 (0.4312)	Training Prec@1 93.164 (92.154)	Training Prec@5 96.289 (95.130)	
2022-03-29 06:51:55,027: ============================================================
2022-03-29 06:52:40,685: time cost, forward:0.14907258646931448, backward:0.03633005277051193, data cost:0.2718532417290569 
2022-03-29 06:52:40,685: ============================================================
2022-03-29 06:52:40,685: Epoch 45/45 Batch 7300/7662 eta: 0:02:45.739006	Training Loss 0.4302 (0.4312)	Training Prec@1 93.164 (92.153)	Training Prec@5 94.727 (95.131)	
2022-03-29 06:52:40,685: ============================================================
2022-03-29 06:53:25,548: time cost, forward:0.14878412987319403, backward:0.03628775332002708, data cost:0.2720518131838697 
2022-03-29 06:53:25,548: ============================================================
2022-03-29 06:53:25,548: Epoch 45/45 Batch 7400/7662 eta: 0:01:57.990410	Training Loss 0.4326 (0.4312)	Training Prec@1 90.820 (92.155)	Training Prec@5 93.750 (95.133)	
2022-03-29 06:53:25,549: ============================================================
2022-03-29 06:54:12,544: time cost, forward:0.14866079166899174, backward:0.03626199047761625, data cost:0.27236623881037736 
2022-03-29 06:54:12,544: ============================================================
2022-03-29 06:54:12,544: Epoch 45/45 Batch 7500/7662 eta: 0:01:16.603212	Training Loss 0.4301 (0.4312)	Training Prec@1 92.188 (92.154)	Training Prec@5 95.312 (95.132)	
2022-03-29 06:54:12,544: ============================================================
2022-03-29 06:54:56,765: time cost, forward:0.1484633004732831, backward:0.03623640912193141, data cost:0.2723876443532348 
2022-03-29 06:54:56,766: ============================================================
2022-03-29 06:54:56,766: Epoch 45/45 Batch 7600/7662 eta: 0:00:27.859541	Training Loss 0.4311 (0.4312)	Training Prec@1 91.602 (92.154)	Training Prec@5 95.508 (95.131)	
2022-03-29 06:54:56,766: ============================================================
2022-03-29 06:55:27,435: Epoch: 45/45 eta: 0:00:00	Training Loss 0.4219 (0.4312)	Training Prec@1 92.969 (92.153)	Training Prec@5 95.312 (95.131)
2022-03-29 06:55:27,437: ============================================================
2022-03-29 06:55:27,439: Save Checkpoint...
2022-03-29 06:55:27,440: ============================================================
2022-03-29 06:55:29,425: Save done!
2022-03-29 06:55:29,425: ============================================================
