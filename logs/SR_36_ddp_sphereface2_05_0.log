2022-03-31 08:58:33,968: [('name', 'amsoft-36'), ('backbone_model_name', 'SimpleResnet_36'), ('classify_model_name', 'Sphereface2'), ('resume_net_model', None), ('resume_net_classifier', None), ('no_cuda', False), ('gpu_num', 1), ('log_interval', 100), ('log_path', './logs/SR_36_ddp_sphereface2_05.log'), ('log_pic_path', './logs/pic/SR_36_ddp_sphereface2_05/'), ('save_path', 'snapshot/SR_36_ddp_sphereface2_05/'), ('lmdb_path', '/home/ubuntu/data4/lk/data/lmdb_default'), ('batch_size', 512), ('datanum', 3923399), ('num_class', 86876), ('lmdb_workers', 4), ('num_workers', 4), ('start_epoch', 1), ('max_epoch', 31), ('lr', 0.05), ('base', 'epoch'), ('step_size', [10, 20, 30, 40]), ('momentum', 0.9), ('gama', 0.1), ('weight_decay', 0.0005), ('rank', 0), ('dist_url', 'env://'), ('world_size', 2), ('gpu', 0), ('dist_backend', 'nccl'), ('distributed', True), ('master_port', 22000), ('multiprocessing_distributed', False), ('SEED', 1337), ('local_rank', 0)]
2022-03-31 08:58:33,968: SimpleResidualBackbone(
  (conv1): ConvPrelu(
    (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (prelu): PReLU(num_parameters=64)
  )
  (layer1): Sequential(
    (0): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=64)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=64)
      )
    )
    (1): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=64)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=64)
      )
    )
  )
  (conv2): ConvPrelu(
    (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (prelu): PReLU(num_parameters=128)
  )
  (layer2): Sequential(
    (0): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
    )
    (1): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
    )
    (2): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
    )
    (3): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
    )
  )
  (conv3): ConvPrelu(
    (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (prelu): PReLU(num_parameters=256)
  )
  (layer3): Sequential(
    (0): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
    (1): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
    (2): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
    (3): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
    (4): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
    (5): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
    (6): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
    (7): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
  )
  (conv4): ConvPrelu(
    (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (prelu): PReLU(num_parameters=512)
  )
  (layer4): Sequential(
    (0): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=512)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=512)
      )
    )
    (1): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=512)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=512)
      )
    )
  )
  (fc5): Linear(in_features=25088, out_features=512, bias=True)
)
2022-03-31 08:58:34,504: data balance
2022-03-31 08:59:09,006: time cost, forward:0.11497361491424869, backward:0.038057820965545344, data cost:0.19132131277912795 
2022-03-31 08:59:09,007: ============================================================
2022-03-31 08:59:09,007: Epoch 1/31 Batch 100/7662 eta: 22:37:42.964875	Training Loss 0.8325 (0.8412)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.010)	
2022-03-31 08:59:09,007: ============================================================
2022-03-31 08:59:41,338: time cost, forward:0.11145208109563319, backward:0.034933269922457745, data cost:0.18721405944632524 
2022-03-31 08:59:41,338: ============================================================
2022-03-31 08:59:41,339: Epoch 1/31 Batch 200/7662 eta: 21:18:50.412917	Training Loss 0.8310 (0.8363)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.008)	
2022-03-31 08:59:41,339: ============================================================
2022-03-31 09:00:13,841: time cost, forward:0.110423753094115, backward:0.034852670586627464, data cost:0.18529958390073234 
2022-03-31 09:00:13,842: ============================================================
2022-03-31 09:00:13,842: Epoch 1/31 Batch 300/7662 eta: 21:25:05.276662	Training Loss 0.8293 (0.8344)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.006)	
2022-03-31 09:00:13,842: ============================================================
2022-03-31 09:00:46,414: time cost, forward:0.1096140388259314, backward:0.03468553344707441, data cost:0.1849632627683176 
2022-03-31 09:00:46,414: ============================================================
2022-03-31 09:00:46,414: Epoch 1/31 Batch 400/7662 eta: 21:27:17.322772	Training Loss 0.8306 (0.8334)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.006)	
2022-03-31 09:00:46,415: ============================================================
2022-03-31 09:01:19,120: time cost, forward:0.10928001480255432, backward:0.034539868215281884, data cost:0.18491080289852166 
2022-03-31 09:01:19,120: ============================================================
2022-03-31 09:01:19,120: Epoch 1/31 Batch 500/7662 eta: 21:32:00.521636	Training Loss 0.8300 (0.8329)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.007)	
2022-03-31 09:01:19,120: ============================================================
2022-03-31 09:01:52,016: time cost, forward:0.10895314121087127, backward:0.03445043428513363, data cost:0.18529749235048118 
2022-03-31 09:01:52,016: ============================================================
2022-03-31 09:01:52,017: Epoch 1/31 Batch 600/7662 eta: 21:38:58.446313	Training Loss 0.8299 (0.8325)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.009)	
2022-03-31 09:01:52,017: ============================================================
2022-03-31 09:02:25,071: time cost, forward:0.10873705975828593, backward:0.03420192898598863, data cost:0.18597409824103928 
2022-03-31 09:02:25,071: ============================================================
2022-03-31 09:02:25,071: Epoch 1/31 Batch 700/7662 eta: 21:44:41.104272	Training Loss 0.8306 (0.8323)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.009)	
2022-03-31 09:02:25,071: ============================================================
2022-03-31 09:02:58,322: time cost, forward:0.1085180382853903, backward:0.03402711393239352, data cost:0.18675295223431831 
2022-03-31 09:02:58,322: ============================================================
2022-03-31 09:02:58,322: Epoch 1/31 Batch 800/7662 eta: 21:51:52.682157	Training Loss 0.8318 (0.8322)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.009)	
2022-03-31 09:02:58,322: ============================================================
2022-03-31 09:03:31,714: time cost, forward:0.1083755896274452, backward:0.034008886180279384, data cost:0.18738280122351725 
2022-03-31 09:03:31,715: ============================================================
2022-03-31 09:03:31,715: Epoch 1/31 Batch 900/7662 eta: 21:56:55.255228	Training Loss 0.8318 (0.8321)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.009)	
2022-03-31 09:03:31,715: ============================================================
2022-03-31 09:04:06,141: time cost, forward:0.10820835011380094, backward:0.03393458222245072, data cost:0.1890419572442621 
2022-03-31 09:04:06,142: ============================================================
2022-03-31 09:04:06,142: Epoch 1/31 Batch 1000/7662 eta: 22:37:07.195870	Training Loss 0.8320 (0.8320)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.009)	
2022-03-31 09:04:06,142: ============================================================
2022-03-31 09:04:42,546: time cost, forward:0.10808147941533819, backward:0.033789045057912866, data cost:0.19227046116142515 
2022-03-31 09:04:42,546: ============================================================
2022-03-31 09:04:42,546: Epoch 1/31 Batch 1100/7662 eta: 23:54:28.681513	Training Loss 0.8331 (0.8320)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.010)	
2022-03-31 09:04:42,546: ============================================================
2022-03-31 09:05:17,494: time cost, forward:0.10795823408227051, backward:0.03371136301850358, data cost:0.19370883419873616 
2022-03-31 09:05:17,494: ============================================================
2022-03-31 09:05:17,494: Epoch 1/31 Batch 1200/7662 eta: 22:56:29.786119	Training Loss 0.8309 (0.8319)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.011)	
2022-03-31 09:05:17,494: ============================================================
2022-03-31 09:05:52,397: time cost, forward:0.10788876722187515, backward:0.03366306233718085, data cost:0.19485877934926468 
2022-03-31 09:05:52,398: ============================================================
2022-03-31 09:05:52,398: Epoch 1/31 Batch 1300/7662 eta: 22:54:10.989355	Training Loss 0.8304 (0.8318)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.012)	
2022-03-31 09:05:52,398: ============================================================
2022-03-31 09:06:27,116: time cost, forward:0.10780582417753273, backward:0.033598536504346015, data cost:0.1957443239349736 
2022-03-31 09:06:27,116: ============================================================
2022-03-31 09:06:27,116: Epoch 1/31 Batch 1400/7662 eta: 22:46:17.906955	Training Loss 0.8298 (0.8317)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.015)	
2022-03-31 09:06:27,117: ============================================================
2022-03-31 09:07:03,841: time cost, forward:0.10773683500894314, backward:0.033478502117052646, data cost:0.19792147570248045 
2022-03-31 09:07:03,842: ============================================================
2022-03-31 09:07:03,843: Epoch 1/31 Batch 1500/7662 eta: 1 day, 0:04:42.291651	Training Loss 0.8272 (0.8315)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.018)	
2022-03-31 09:07:03,843: ============================================================
2022-03-31 09:07:38,741: time cost, forward:0.10770636860320836, backward:0.03342347684839951, data cost:0.19859462711794665 
2022-03-31 09:07:38,741: ============================================================
2022-03-31 09:07:38,741: Epoch 1/31 Batch 1600/7662 eta: 22:52:13.726445	Training Loss 0.8262 (0.8312)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.022)	
2022-03-31 09:07:38,741: ============================================================
2022-03-31 09:08:14,964: time cost, forward:0.10766705433855063, backward:0.0333980876884438, data cost:0.1999641543910951 
2022-03-31 09:08:14,965: ============================================================
2022-03-31 09:08:14,965: Epoch 1/31 Batch 1700/7662 eta: 23:43:44.273829	Training Loss 0.8236 (0.8309)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.195 (0.026)	
2022-03-31 09:08:14,965: ============================================================
2022-03-31 09:08:51,099: time cost, forward:0.10761706188958907, backward:0.03338304501629459, data cost:0.20112868784002758 
2022-03-31 09:08:51,099: ============================================================
2022-03-31 09:08:51,100: Epoch 1/31 Batch 1800/7662 eta: 23:39:38.220528	Training Loss 0.8236 (0.8305)	Training Prec@1 0.195 (0.009)	Training Prec@5 0.195 (0.031)	
2022-03-31 09:08:51,100: ============================================================
2022-03-31 09:09:26,233: time cost, forward:0.10762738716985251, backward:0.0333060733640489, data cost:0.20165902479753298 
2022-03-31 09:09:26,234: ============================================================
2022-03-31 09:09:26,234: Epoch 1/31 Batch 1900/7662 eta: 22:59:44.124839	Training Loss 0.8217 (0.8301)	Training Prec@1 0.000 (0.011)	Training Prec@5 0.195 (0.039)	
2022-03-31 09:09:26,234: ============================================================
2022-03-31 09:10:03,555: time cost, forward:0.10755974951835201, backward:0.0332381823111797, data cost:0.203312487766825 
2022-03-31 09:10:03,555: ============================================================
2022-03-31 09:10:03,556: Epoch 1/31 Batch 2000/7662 eta: 1 day, 0:25:00.967597	Training Loss 0.8185 (0.8295)	Training Prec@1 0.000 (0.015)	Training Prec@5 0.195 (0.052)	
2022-03-31 09:10:03,556: ============================================================
2022-03-31 09:10:40,208: time cost, forward:0.10749545660741333, backward:0.03319806970829848, data cost:0.20445420788605478 
2022-03-31 09:10:40,208: ============================================================
2022-03-31 09:10:40,209: Epoch 1/31 Batch 2100/7662 eta: 23:58:09.841678	Training Loss 0.8159 (0.8289)	Training Prec@1 0.391 (0.020)	Training Prec@5 0.586 (0.066)	
2022-03-31 09:10:40,209: ============================================================
2022-03-31 09:11:18,029: time cost, forward:0.10745496444129683, backward:0.033199146586474965, data cost:0.205976095347038 
2022-03-31 09:11:18,030: ============================================================
2022-03-31 09:11:18,030: Epoch 1/31 Batch 2200/7662 eta: 1 day, 0:43:22.391235	Training Loss 0.8120 (0.8282)	Training Prec@1 0.000 (0.027)	Training Prec@5 0.586 (0.086)	
2022-03-31 09:11:18,031: ============================================================
2022-03-31 09:11:54,715: time cost, forward:0.10742724652184565, backward:0.03318897440621209, data cost:0.20688968733529933 
2022-03-31 09:11:54,715: ============================================================
2022-03-31 09:11:54,716: Epoch 1/31 Batch 2300/7662 eta: 23:58:12.637546	Training Loss 0.8100 (0.8275)	Training Prec@1 0.000 (0.036)	Training Prec@5 0.195 (0.114)	
2022-03-31 09:11:54,716: ============================================================
2022-03-31 09:12:32,041: time cost, forward:0.10739773211254583, backward:0.03323518459674665, data cost:0.20789445067704246 
2022-03-31 09:12:32,042: ============================================================
2022-03-31 09:12:32,042: Epoch 1/31 Batch 2400/7662 eta: 1 day, 0:22:42.526652	Training Loss 0.8052 (0.8266)	Training Prec@1 0.000 (0.046)	Training Prec@5 1.172 (0.146)	
2022-03-31 09:12:32,042: ============================================================
2022-03-31 09:13:09,117: time cost, forward:0.10735662377515093, backward:0.03327174699988638, data cost:0.2087981306872114 
2022-03-31 09:13:09,117: ============================================================
2022-03-31 09:13:09,118: Epoch 1/31 Batch 2500/7662 eta: 1 day, 0:12:17.097724	Training Loss 0.8012 (0.8257)	Training Prec@1 0.977 (0.061)	Training Prec@5 1.367 (0.192)	
2022-03-31 09:13:09,118: ============================================================
2022-03-31 09:13:47,837: time cost, forward:0.1073212253905205, backward:0.03331085212783843, data cost:0.21023336462260853 
2022-03-31 09:13:47,838: ============================================================
2022-03-31 09:13:47,838: Epoch 1/31 Batch 2600/7662 eta: 1 day, 1:16:01.805359	Training Loss 0.7976 (0.8248)	Training Prec@1 0.977 (0.081)	Training Prec@5 2.539 (0.249)	
2022-03-31 09:13:47,838: ============================================================
2022-03-31 09:14:24,564: time cost, forward:0.1073038089535951, backward:0.03331616102390353, data cost:0.2108324782501198 
2022-03-31 09:14:24,564: ============================================================
2022-03-31 09:14:24,565: Epoch 1/31 Batch 2700/7662 eta: 23:57:23.130803	Training Loss 0.7937 (0.8237)	Training Prec@1 0.781 (0.108)	Training Prec@5 2.539 (0.318)	
2022-03-31 09:14:24,565: ============================================================
2022-03-31 09:15:02,203: time cost, forward:0.10725813339590473, backward:0.03335409592031879, data cost:0.2117274664435569 
2022-03-31 09:15:02,203: ============================================================
2022-03-31 09:15:02,203: Epoch 1/31 Batch 2800/7662 eta: 1 day, 0:32:26.904633	Training Loss 0.7935 (0.8227)	Training Prec@1 1.172 (0.142)	Training Prec@5 2.734 (0.402)	
2022-03-31 09:15:02,204: ============================================================
2022-03-31 09:15:39,586: time cost, forward:0.10722810550162035, backward:0.03341260068208524, data cost:0.21240991944072574 
2022-03-31 09:15:39,587: ============================================================
2022-03-31 09:15:39,587: Epoch 1/31 Batch 2900/7662 eta: 1 day, 0:21:50.094772	Training Loss 0.7919 (0.8215)	Training Prec@1 0.781 (0.188)	Training Prec@5 2.148 (0.504)	
2022-03-31 09:15:39,587: ============================================================
2022-03-31 09:16:18,201: time cost, forward:0.10719559438310491, backward:0.03344476918611339, data cost:0.21351295838796444 
2022-03-31 09:16:18,201: ============================================================
2022-03-31 09:16:18,202: Epoch 1/31 Batch 3000/7662 eta: 1 day, 1:09:20.380464	Training Loss 0.7829 (0.8204)	Training Prec@1 2.344 (0.243)	Training Prec@5 5.664 (0.635)	
2022-03-31 09:16:18,202: ============================================================
2022-03-31 09:16:55,660: time cost, forward:0.10718418960226625, backward:0.033449575800247905, data cost:0.2141002303133014 
2022-03-31 09:16:55,660: ============================================================
2022-03-31 09:16:55,660: Epoch 1/31 Batch 3100/7662 eta: 1 day, 0:23:31.940625	Training Loss 0.7809 (0.8191)	Training Prec@1 1.953 (0.310)	Training Prec@5 5.469 (0.783)	
2022-03-31 09:16:55,661: ============================================================
2022-03-31 09:17:33,900: time cost, forward:0.10714580789883832, backward:0.03344865782851911, data cost:0.21505267823551102 
2022-03-31 09:17:33,901: ============================================================
2022-03-31 09:17:33,901: Epoch 1/31 Batch 3200/7662 eta: 1 day, 0:53:26.796259	Training Loss 0.7746 (0.8178)	Training Prec@1 2.539 (0.396)	Training Prec@5 5.078 (0.965)	
2022-03-31 09:17:33,901: ============================================================
2022-03-31 09:18:11,380: time cost, forward:0.10712989072577091, backward:0.03350309004527795, data cost:0.2155157552772885 
2022-03-31 09:18:11,381: ============================================================
2022-03-31 09:18:11,381: Epoch 1/31 Batch 3300/7662 eta: 1 day, 0:23:07.210437	Training Loss 0.7715 (0.8165)	Training Prec@1 4.492 (0.497)	Training Prec@5 9.570 (1.169)	
2022-03-31 09:18:11,382: ============================================================
2022-03-31 09:18:50,896: time cost, forward:0.1070963406990682, backward:0.03348850649782895, data cost:0.21676164832175496 
2022-03-31 09:18:50,897: ============================================================
2022-03-31 09:18:50,897: Epoch 1/31 Batch 3400/7662 eta: 1 day, 1:41:55.213049	Training Loss 0.7645 (0.8151)	Training Prec@1 5.078 (0.614)	Training Prec@5 9.766 (1.404)	
2022-03-31 09:18:50,897: ============================================================
2022-03-31 09:19:28,430: time cost, forward:0.10707478456478113, backward:0.03346724004601029, data cost:0.21731403160858373 
2022-03-31 09:19:28,430: ============================================================
2022-03-31 09:19:28,431: Epoch 1/31 Batch 3500/7662 eta: 1 day, 0:23:57.432141	Training Loss 0.7614 (0.8136)	Training Prec@1 4.492 (0.750)	Training Prec@5 10.742 (1.668)	
2022-03-31 09:19:28,431: ============================================================
2022-03-31 09:20:07,575: time cost, forward:0.1070608613755379, backward:0.03346591321717835, data cost:0.21825677774190305 
2022-03-31 09:20:07,576: ============================================================
2022-03-31 09:20:07,576: Epoch 1/31 Batch 3600/7662 eta: 1 day, 1:26:10.037266	Training Loss 0.7583 (0.8121)	Training Prec@1 7.031 (0.907)	Training Prec@5 12.500 (1.962)	
2022-03-31 09:20:07,576: ============================================================
2022-03-31 09:20:46,243: time cost, forward:0.10704599931195607, backward:0.03350373234868726, data cost:0.21896910622301022 
2022-03-31 09:20:46,243: ============================================================
2022-03-31 09:20:46,243: Epoch 1/31 Batch 3700/7662 eta: 1 day, 1:06:53.247113	Training Loss 0.7497 (0.8106)	Training Prec@1 9.375 (1.093)	Training Prec@5 16.211 (2.294)	
2022-03-31 09:20:46,243: ============================================================
2022-03-31 09:21:26,301: time cost, forward:0.10703250426121466, backward:0.03352846688865266, data cost:0.22003164665420985 
2022-03-31 09:21:26,302: ============================================================
2022-03-31 09:21:26,302: Epoch 1/31 Batch 3800/7662 eta: 1 day, 2:00:26.342661	Training Loss 0.7418 (0.8090)	Training Prec@1 12.109 (1.299)	Training Prec@5 19.336 (2.652)	
2022-03-31 09:21:26,302: ============================================================
2022-03-31 09:22:05,478: time cost, forward:0.10699359023531267, backward:0.033557796331514726, data cost:0.2208184344122183 
2022-03-31 09:22:05,478: ============================================================
2022-03-31 09:22:05,478: Epoch 1/31 Batch 3900/7662 eta: 1 day, 1:25:24.904834	Training Loss 0.7397 (0.8073)	Training Prec@1 13.672 (1.534)	Training Prec@5 20.117 (3.047)	
2022-03-31 09:22:05,478: ============================================================
2022-03-31 09:22:45,653: time cost, forward:0.10692977827768023, backward:0.03359211048623209, data cost:0.22185341517130533 
2022-03-31 09:22:45,653: ============================================================
2022-03-31 09:22:45,654: Epoch 1/31 Batch 4000/7662 eta: 1 day, 2:03:38.475907	Training Loss 0.7361 (0.8056)	Training Prec@1 13.477 (1.790)	Training Prec@5 23.438 (3.470)	
2022-03-31 09:22:45,654: ============================================================
2022-03-31 09:23:25,338: time cost, forward:0.10692818416680147, backward:0.033593948133458854, data cost:0.2226778289462683 
2022-03-31 09:23:25,338: ============================================================
2022-03-31 09:23:25,339: Epoch 1/31 Batch 4100/7662 eta: 1 day, 1:43:54.033173	Training Loss 0.7267 (0.8039)	Training Prec@1 15.430 (2.072)	Training Prec@5 26.562 (3.917)	
2022-03-31 09:23:25,339: ============================================================
2022-03-31 09:24:04,233: time cost, forward:0.10690083155094882, backward:0.03363159594861744, data cost:0.22327614034973856 
2022-03-31 09:24:04,234: ============================================================
2022-03-31 09:24:04,234: Epoch 1/31 Batch 4200/7662 eta: 1 day, 1:12:31.247266	Training Loss 0.7233 (0.8021)	Training Prec@1 16.406 (2.387)	Training Prec@5 26.758 (4.401)	
2022-03-31 09:24:04,234: ============================================================
2022-03-31 09:24:44,186: time cost, forward:0.10688148561980343, backward:0.03363621021376346, data cost:0.22411401955630508 
2022-03-31 09:24:44,187: ============================================================
2022-03-31 09:24:44,187: Epoch 1/31 Batch 4300/7662 eta: 1 day, 1:52:59.848360	Training Loss 0.7200 (0.8003)	Training Prec@1 18.164 (2.724)	Training Prec@5 29.102 (4.911)	
2022-03-31 09:24:44,187: ============================================================
2022-03-31 09:25:24,448: time cost, forward:0.10685297840696813, backward:0.03368231669749203, data cost:0.22494851407421587 
2022-03-31 09:25:24,448: ============================================================
2022-03-31 09:25:24,449: Epoch 1/31 Batch 4400/7662 eta: 1 day, 2:04:19.420533	Training Loss 0.7193 (0.7984)	Training Prec@1 20.312 (3.077)	Training Prec@5 29.297 (5.440)	
2022-03-31 09:25:24,449: ============================================================
2022-03-31 09:26:04,038: time cost, forward:0.1068407686373, backward:0.03370329013637077, data cost:0.22560738679911727 
2022-03-31 09:26:04,038: ============================================================
2022-03-31 09:26:04,039: Epoch 1/31 Batch 4500/7662 eta: 1 day, 1:37:33.779944	Training Loss 0.7179 (0.7965)	Training Prec@1 18.555 (3.452)	Training Prec@5 27.734 (5.989)	
2022-03-31 09:26:04,039: ============================================================
2022-03-31 09:26:45,163: time cost, forward:0.10681204257723714, backward:0.03370244825993136, data cost:0.226606350718542 
2022-03-31 09:26:45,163: ============================================================
2022-03-31 09:26:45,164: Epoch 1/31 Batch 4600/7662 eta: 1 day, 2:36:29.675380	Training Loss 0.7050 (0.7946)	Training Prec@1 22.461 (3.853)	Training Prec@5 33.203 (6.562)	
2022-03-31 09:26:45,164: ============================================================
2022-03-31 09:27:25,362: time cost, forward:0.10679455421457495, backward:0.033732920409415876, data cost:0.2273229543998866 
2022-03-31 09:27:25,363: ============================================================
2022-03-31 09:27:25,364: Epoch 1/31 Batch 4700/7662 eta: 1 day, 1:59:54.705672	Training Loss 0.6913 (0.7926)	Training Prec@1 27.539 (4.268)	Training Prec@5 37.305 (7.145)	
2022-03-31 09:27:25,364: ============================================================
2022-03-31 09:28:04,536: time cost, forward:0.10679197226943858, backward:0.03375982194921577, data cost:0.22779820948547314 
2022-03-31 09:28:04,537: ============================================================
2022-03-31 09:28:04,537: Epoch 1/31 Batch 4800/7662 eta: 1 day, 1:19:24.834030	Training Loss 0.6916 (0.7906)	Training Prec@1 28.320 (4.705)	Training Prec@5 38.867 (7.752)	
2022-03-31 09:28:04,537: ============================================================
2022-03-31 09:28:44,027: time cost, forward:0.10680058358226122, backward:0.033778802256945274, data cost:0.22829575255394566 
2022-03-31 09:28:44,027: ============================================================
2022-03-31 09:28:44,028: Epoch 1/31 Batch 4900/7662 eta: 1 day, 1:31:04.706754	Training Loss 0.6843 (0.7886)	Training Prec@1 30.078 (5.160)	Training Prec@5 42.773 (8.371)	
2022-03-31 09:28:44,028: ============================================================
2022-03-31 09:29:22,772: time cost, forward:0.10679883440868167, backward:0.03379334848292901, data cost:0.22864903958231528 
2022-03-31 09:29:22,772: ============================================================
2022-03-31 09:29:22,772: Epoch 1/31 Batch 5000/7662 eta: 1 day, 1:01:30.714545	Training Loss 0.6815 (0.7866)	Training Prec@1 32.812 (5.632)	Training Prec@5 44.336 (9.001)	
2022-03-31 09:29:22,773: ============================================================
2022-03-31 09:30:01,303: time cost, forward:0.10681983372070528, backward:0.0337949875500371, data cost:0.2289236251642527 
2022-03-31 09:30:01,303: ============================================================
2022-03-31 09:30:01,303: Epoch 1/31 Batch 5100/7662 eta: 1 day, 0:52:34.897029	Training Loss 0.6792 (0.7845)	Training Prec@1 32.227 (6.122)	Training Prec@5 47.461 (9.653)	
2022-03-31 09:30:01,304: ============================================================
2022-03-31 09:30:40,136: time cost, forward:0.10690569781321566, backward:0.03379812454301409, data cost:0.22919255890601367 
2022-03-31 09:30:40,137: ============================================================
2022-03-31 09:30:40,137: Epoch 1/31 Batch 5200/7662 eta: 1 day, 1:03:39.731373	Training Loss 0.6722 (0.7824)	Training Prec@1 32.617 (6.622)	Training Prec@5 42.969 (10.309)	
2022-03-31 09:30:40,137: ============================================================
2022-03-31 09:31:19,662: time cost, forward:0.10696647517702268, backward:0.03382027943329128, data cost:0.229584503632758 
2022-03-31 09:31:19,663: ============================================================
2022-03-31 09:31:19,663: Epoch 1/31 Batch 5300/7662 eta: 1 day, 1:29:47.872275	Training Loss 0.6614 (0.7803)	Training Prec@1 36.328 (7.143)	Training Prec@5 48.438 (10.981)	
2022-03-31 09:31:19,663: ============================================================
2022-03-31 09:31:57,985: time cost, forward:0.10716152195578087, backward:0.03379395101264265, data cost:0.22964300749853467 
2022-03-31 09:31:57,985: ============================================================
2022-03-31 09:31:57,986: Epoch 1/31 Batch 5400/7662 eta: 1 day, 0:42:35.570751	Training Loss 0.6698 (0.7782)	Training Prec@1 33.984 (7.672)	Training Prec@5 46.094 (11.658)	
2022-03-31 09:31:57,986: ============================================================
2022-03-31 09:32:39,392: time cost, forward:0.10769285013684794, backward:0.033818266482369685, data cost:0.22987603781374613 
2022-03-31 09:32:39,393: ============================================================
2022-03-31 09:32:39,393: Epoch 1/31 Batch 5500/7662 eta: 1 day, 2:41:14.773878	Training Loss 0.6565 (0.7761)	Training Prec@1 40.039 (8.211)	Training Prec@5 52.148 (12.342)	
2022-03-31 09:32:39,393: ============================================================
2022-03-31 09:33:20,138: time cost, forward:0.10780317184222045, backward:0.033821684438259524, data cost:0.2303993882058156 
2022-03-31 09:33:20,138: ============================================================
2022-03-31 09:33:20,139: Epoch 1/31 Batch 5600/7662 eta: 1 day, 2:14:58.323299	Training Loss 0.6502 (0.7739)	Training Prec@1 40.430 (8.754)	Training Prec@5 51.367 (13.022)	
2022-03-31 09:33:20,139: ============================================================
2022-03-31 09:33:59,132: time cost, forward:0.10789362851685234, backward:0.03383271287127239, data cost:0.23060238769251457 
2022-03-31 09:33:59,132: ============================================================
2022-03-31 09:33:59,133: Epoch 1/31 Batch 5700/7662 eta: 1 day, 1:06:37.220808	Training Loss 0.6531 (0.7718)	Training Prec@1 41.016 (9.315)	Training Prec@5 52.734 (13.713)	
2022-03-31 09:33:59,133: ============================================================
2022-03-31 09:34:39,786: time cost, forward:0.10794708818829374, backward:0.03381658706362442, data cost:0.2311462892666215 
2022-03-31 09:34:39,801: ============================================================
2022-03-31 09:34:39,801: Epoch 1/31 Batch 5800/7662 eta: 1 day, 2:10:38.574752	Training Loss 0.8803 (0.7710)	Training Prec@1 0.000 (9.627)	Training Prec@5 0.000 (14.085)	
2022-03-31 09:34:39,801: ============================================================
2022-03-31 09:35:19,992: time cost, forward:0.10795795984198672, backward:0.03381992881834396, data cost:0.23161696555109665 
2022-03-31 09:35:19,992: ============================================================
2022-03-31 09:35:19,992: Epoch 1/31 Batch 5900/7662 eta: 1 day, 1:51:31.871593	Training Loss 0.8379 (0.7723)	Training Prec@1 0.000 (9.463)	Training Prec@5 0.000 (13.847)	
2022-03-31 09:35:19,992: ============================================================
2022-03-31 09:35:59,869: time cost, forward:0.10798793769832611, backward:0.033824139186632116, data cost:0.23199479717833935 
2022-03-31 09:35:59,869: ============================================================
2022-03-31 09:35:59,869: Epoch 1/31 Batch 6000/7662 eta: 1 day, 1:38:44.336399	Training Loss 0.8521 (0.7734)	Training Prec@1 0.195 (9.307)	Training Prec@5 0.391 (13.620)	
2022-03-31 09:35:59,870: ============================================================
2022-03-31 09:36:39,049: time cost, forward:0.10802019942215299, backward:0.033821501210393, data cost:0.23225654569057622 
2022-03-31 09:36:39,050: ============================================================
2022-03-31 09:36:39,050: Epoch 1/31 Batch 6100/7662 eta: 1 day, 1:11:12.457952	Training Loss 0.7600 (0.7741)	Training Prec@1 5.078 (9.167)	Training Prec@5 12.891 (13.426)	
2022-03-31 09:36:39,050: ============================================================
2022-03-31 09:37:18,953: time cost, forward:0.10810997490345191, backward:0.03385143819249894, data cost:0.23251956338785526 
2022-03-31 09:37:18,953: ============================================================
2022-03-31 09:37:18,953: Epoch 1/31 Batch 6200/7662 eta: 1 day, 1:38:26.537692	Training Loss 0.8264 (0.7753)	Training Prec@1 0.391 (9.038)	Training Prec@5 0.781 (13.246)	
2022-03-31 09:37:18,954: ============================================================
2022-03-31 09:38:02,843: time cost, forward:0.1089081448171797, backward:0.03388585940601902, data cost:0.2327195615839591 
2022-03-31 09:38:02,843: ============================================================
2022-03-31 09:38:02,844: Epoch 1/31 Batch 6300/7662 eta: 1 day, 4:11:23.866455	Training Loss 0.7621 (0.7758)	Training Prec@1 8.203 (8.916)	Training Prec@5 13.672 (13.086)	
2022-03-31 09:38:02,844: ============================================================
2022-03-31 09:38:48,465: time cost, forward:0.10997767399243777, backward:0.03390364945726593, data cost:0.23288843370560725 
2022-03-31 09:38:48,466: ============================================================
2022-03-31 09:38:48,466: Epoch 1/31 Batch 6400/7662 eta: 1 day, 5:17:24.146749	Training Loss 0.8542 (0.7764)	Training Prec@1 0.000 (8.873)	Training Prec@5 0.000 (13.033)	
2022-03-31 09:38:48,466: ============================================================
2022-03-31 09:39:35,294: time cost, forward:0.11104172757083149, backward:0.033970452910442504, data cost:0.23315997930063911 
2022-03-31 09:39:35,314: ============================================================
2022-03-31 09:39:35,314: Epoch 1/31 Batch 6500/7662 eta: 1 day, 6:03:50.495127	Training Loss 0.8277 (0.7774)	Training Prec@1 0.000 (8.737)	Training Prec@5 0.000 (12.834)	
2022-03-31 09:39:35,315: ============================================================
2022-03-31 09:40:19,655: time cost, forward:0.11193387991443766, backward:0.03401660109888624, data cost:0.23320448888144832 
2022-03-31 09:40:19,655: ============================================================
2022-03-31 09:40:19,656: Epoch 1/31 Batch 6600/7662 eta: 1 day, 4:26:33.791694	Training Loss 0.8592 (0.7785)	Training Prec@1 0.000 (8.606)	Training Prec@5 0.000 (12.645)	
2022-03-31 09:40:19,656: ============================================================
2022-03-31 09:41:04,661: time cost, forward:0.11272148734367611, backward:0.034070104712033415, data cost:0.23339191261094477 
2022-03-31 09:41:04,662: ============================================================
2022-03-31 09:41:04,662: Epoch 1/31 Batch 6700/7662 eta: 1 day, 4:51:25.650684	Training Loss 0.8473 (0.7796)	Training Prec@1 0.000 (8.478)	Training Prec@5 0.000 (12.456)	
2022-03-31 09:41:04,662: ============================================================
2022-03-31 09:41:47,633: time cost, forward:0.11332611677172885, backward:0.034152460336720245, data cost:0.2334560393094841 
2022-03-31 09:41:47,648: ============================================================
2022-03-31 09:41:47,649: Epoch 1/31 Batch 6800/7662 eta: 1 day, 3:32:59.693495	Training Loss 0.8327 (0.7804)	Training Prec@1 0.000 (8.354)	Training Prec@5 0.000 (12.275)	
2022-03-31 09:41:47,649: ============================================================
2022-03-31 09:42:31,310: time cost, forward:0.11383171163792022, backward:0.03422271595396569, data cost:0.2336788461560494 
2022-03-31 09:42:31,311: ============================================================
2022-03-31 09:42:31,311: Epoch 1/31 Batch 6900/7662 eta: 1 day, 3:58:14.904993	Training Loss 0.7742 (0.7808)	Training Prec@1 4.297 (8.247)	Training Prec@5 8.789 (12.130)	
2022-03-31 09:42:31,311: ============================================================
2022-03-31 09:43:14,651: time cost, forward:0.11418999268474161, backward:0.03429251392324714, data cost:0.23398231993336085 
2022-03-31 09:43:14,676: ============================================================
2022-03-31 09:43:14,676: Epoch 1/31 Batch 7000/7662 eta: 1 day, 3:46:06.209935	Training Loss 0.7383 (0.7806)	Training Prec@1 12.305 (8.235)	Training Prec@5 21.289 (12.149)	
2022-03-31 09:43:14,676: ============================================================
2022-03-31 09:43:58,813: time cost, forward:0.11483431087444997, backward:0.03440276987704782, data cost:0.23404678628048034 
2022-03-31 09:43:58,813: ============================================================
2022-03-31 09:43:58,813: Epoch 1/31 Batch 7100/7662 eta: 1 day, 4:15:03.156101	Training Loss 0.7227 (0.7797)	Training Prec@1 18.750 (8.396)	Training Prec@5 26.172 (12.401)	
2022-03-31 09:43:58,813: ============================================================
2022-03-31 09:44:41,861: time cost, forward:0.11533678583112553, backward:0.03445106010368126, data cost:0.2341462434505585 
2022-03-31 09:44:41,861: ============================================================
2022-03-31 09:44:41,862: Epoch 1/31 Batch 7200/7662 eta: 1 day, 3:32:30.104773	Training Loss 0.6881 (0.7787)	Training Prec@1 31.641 (8.616)	Training Prec@5 42.969 (12.713)	
2022-03-31 09:44:41,862: ============================================================
2022-03-31 09:45:24,664: time cost, forward:0.11573134113426224, backward:0.03447498908057933, data cost:0.2343215627169867 
2022-03-31 09:45:24,665: ============================================================
2022-03-31 09:45:24,665: Epoch 1/31 Batch 7300/7662 eta: 1 day, 3:22:22.501026	Training Loss 0.8393 (0.7793)	Training Prec@1 0.000 (8.581)	Training Prec@5 0.000 (12.654)	
2022-03-31 09:45:24,665: ============================================================
2022-03-31 09:46:07,359: time cost, forward:0.11608072357703615, backward:0.03451613665174868, data cost:0.2345102578663378 
2022-03-31 09:46:07,360: ============================================================
2022-03-31 09:46:07,360: Epoch 1/31 Batch 7400/7662 eta: 1 day, 3:17:31.707649	Training Loss 0.7736 (0.7799)	Training Prec@1 5.273 (8.472)	Training Prec@5 10.742 (12.499)	
2022-03-31 09:46:07,360: ============================================================
2022-03-31 09:46:51,456: time cost, forward:0.11666394205216742, backward:0.03456871572184966, data cost:0.23461595149433825 
2022-03-31 09:46:51,457: ============================================================
2022-03-31 09:46:51,457: Epoch 1/31 Batch 7500/7662 eta: 1 day, 4:10:33.629774	Training Loss 0.8287 (0.7807)	Training Prec@1 0.586 (8.365)	Training Prec@5 0.586 (12.344)	
2022-03-31 09:46:51,457: ============================================================
2022-03-31 09:47:35,972: time cost, forward:0.11715894395512239, backward:0.034618198628456345, data cost:0.23484162456629418 
2022-03-31 09:47:35,972: ============================================================
2022-03-31 09:47:35,972: Epoch 1/31 Batch 7600/7662 eta: 1 day, 4:25:50.683614	Training Loss 0.7383 (0.7808)	Training Prec@1 12.305 (8.308)	Training Prec@5 21.289 (12.279)	
2022-03-31 09:47:35,972: ============================================================
2022-03-31 09:48:03,681: Epoch: 1/31 eta: 1 day, 4:25:22.639037	Training Loss 0.7134 (0.7806)	Training Prec@1 20.117 (8.339)	Training Prec@5 31.641 (12.334)
2022-03-31 09:48:03,682: ============================================================
2022-03-31 09:48:47,255: time cost, forward:0.15738268091221047, backward:0.041801286466193924, data cost:0.23720544757265033 
2022-03-31 09:48:47,256: ============================================================
2022-03-31 09:48:47,256: Epoch 2/31 Batch 100/7662 eta: 1 day, 3:44:56.625175	Training Loss 0.7312 (0.7175)	Training Prec@1 15.039 (23.023)	Training Prec@5 23.828 (32.546)	
2022-03-31 09:48:47,256: ============================================================
2022-03-31 09:49:30,961: time cost, forward:0.15559428181480522, backward:0.04264435816050774, data cost:0.2381835642771505 
2022-03-31 09:49:30,961: ============================================================
2022-03-31 09:49:30,961: Epoch 2/31 Batch 200/7662 eta: 1 day, 3:52:53.676073	Training Loss 0.6688 (0.7011)	Training Prec@1 36.133 (27.047)	Training Prec@5 47.070 (37.605)	
2022-03-31 09:49:30,961: ============================================================
2022-03-31 09:50:13,368: time cost, forward:0.1495953307901338, backward:0.04056431457749179, data cost:0.24202749322489353 
2022-03-31 09:50:13,369: ============================================================
2022-03-31 09:50:13,369: Epoch 2/31 Batch 300/7662 eta: 1 day, 3:02:31.616963	Training Loss 0.6494 (0.6882)	Training Prec@1 41.406 (30.543)	Training Prec@5 54.883 (41.636)	
2022-03-31 09:50:13,369: ============================================================
2022-03-31 09:50:55,934: time cost, forward:0.14480928789105332, backward:0.03933616509114889, data cost:0.2463121563569645 
2022-03-31 09:50:55,935: ============================================================
2022-03-31 09:50:55,935: Epoch 2/31 Batch 400/7662 eta: 1 day, 3:07:51.923357	Training Loss 0.6453 (0.6805)	Training Prec@1 43.359 (32.616)	Training Prec@5 54.688 (44.019)	
2022-03-31 09:50:55,935: ============================================================
2022-03-31 09:51:38,058: time cost, forward:0.14486380808339092, backward:0.03870256534798112, data cost:0.2448562056363704 
2022-03-31 09:51:38,058: ============================================================
2022-03-31 09:51:38,059: Epoch 2/31 Batch 500/7662 eta: 1 day, 2:50:15.589241	Training Loss 0.6708 (0.6816)	Training Prec@1 37.109 (32.334)	Training Prec@5 49.805 (43.714)	
2022-03-31 09:51:38,059: ============================================================
2022-03-31 09:52:18,923: time cost, forward:0.14293964398723213, backward:0.03821369682210116, data cost:0.24393711862261586 
2022-03-31 09:52:18,924: ============================================================
2022-03-31 09:52:18,924: Epoch 2/31 Batch 600/7662 eta: 1 day, 2:01:28.800383	Training Loss 0.6520 (0.6768)	Training Prec@1 39.648 (33.686)	Training Prec@5 52.734 (45.132)	
2022-03-31 09:52:18,924: ============================================================
2022-03-31 09:52:59,656: time cost, forward:0.1397628780768835, backward:0.037690723743902595, data cost:0.2449746428641127 
2022-03-31 09:52:59,656: ============================================================
2022-03-31 09:52:59,656: Epoch 2/31 Batch 700/7662 eta: 1 day, 1:55:41.903580	Training Loss 0.6439 (0.6720)	Training Prec@1 44.141 (35.050)	Training Prec@5 53.516 (46.565)	
2022-03-31 09:52:59,656: ============================================================
2022-03-31 09:53:44,329: time cost, forward:0.1406174926495224, backward:0.03776033261839827, data cost:0.24701984802981342 
2022-03-31 09:53:44,329: ============================================================
2022-03-31 09:53:44,330: Epoch 2/31 Batch 800/7662 eta: 1 day, 4:25:29.267791	Training Loss 0.8724 (0.6710)	Training Prec@1 0.000 (35.597)	Training Prec@5 0.000 (47.030)	
2022-03-31 09:53:44,330: ============================================================
2022-03-31 09:54:26,905: time cost, forward:0.13696032503953368, backward:0.037182837890438296, data cost:0.2511568292229539 
2022-03-31 09:54:26,905: ============================================================
2022-03-31 09:54:26,906: Epoch 2/31 Batch 900/7662 eta: 1 day, 3:04:42.402004	Training Loss 0.7438 (0.6877)	Training Prec@1 9.180 (31.890)	Training Prec@5 18.359 (42.251)	
2022-03-31 09:54:26,906: ============================================================
2022-03-31 09:55:08,266: time cost, forward:0.13621742088157493, backward:0.03690263267990586, data cost:0.25106006293922095 
2022-03-31 09:55:08,266: ============================================================
2022-03-31 09:55:08,266: Epoch 2/31 Batch 1000/7662 eta: 1 day, 2:17:38.257108	Training Loss 0.8401 (0.7042)	Training Prec@1 0.000 (28.721)	Training Prec@5 0.000 (38.061)	
2022-03-31 09:55:08,266: ============================================================
2022-03-31 09:55:50,749: time cost, forward:0.13539211179474683, backward:0.036614919164378174, data cost:0.25214148760926625 
2022-03-31 09:55:50,749: ============================================================
2022-03-31 09:55:50,750: Epoch 2/31 Batch 1100/7662 eta: 1 day, 2:59:45.494550	Training Loss 0.8210 (0.7156)	Training Prec@1 0.781 (26.134)	Training Prec@5 1.562 (34.662)	
2022-03-31 09:55:50,750: ============================================================
2022-03-31 09:56:32,891: time cost, forward:0.13398184748467454, backward:0.03593130883224017, data cost:0.2539688848872499 
2022-03-31 09:56:32,892: ============================================================
2022-03-31 09:56:32,892: Epoch 2/31 Batch 1200/7662 eta: 1 day, 2:46:02.986362	Training Loss 0.8691 (0.7239)	Training Prec@1 0.000 (24.377)	Training Prec@5 0.000 (32.470)	
2022-03-31 09:56:32,892: ============================================================
2022-03-31 09:57:14,677: time cost, forward:0.13193505025075158, backward:0.0358350155810561, data cost:0.25564136901573553 
2022-03-31 09:57:14,678: ============================================================
2022-03-31 09:57:14,678: Epoch 2/31 Batch 1300/7662 eta: 1 day, 2:31:46.458076	Training Loss 0.8456 (0.7341)	Training Prec@1 0.000 (22.501)	Training Prec@5 0.195 (29.973)	
2022-03-31 09:57:14,678: ============================================================
2022-03-31 09:57:55,922: time cost, forward:0.13112122557519418, backward:0.03573398678706662, data cost:0.25574781521462475 
2022-03-31 09:57:55,923: ============================================================
2022-03-31 09:57:55,923: Epoch 2/31 Batch 1400/7662 eta: 1 day, 2:10:28.220640	Training Loss 0.8261 (0.7398)	Training Prec@1 0.000 (20.972)	Training Prec@5 0.000 (28.012)	
2022-03-31 09:57:55,923: ============================================================
2022-03-31 09:58:40,441: time cost, forward:0.1328068589114443, backward:0.0358592767251023, data cost:0.2554259810788064 
2022-03-31 09:58:40,441: ============================================================
2022-03-31 09:58:40,441: Epoch 2/31 Batch 1500/7662 eta: 1 day, 4:14:22.902879	Training Loss 0.8235 (0.7433)	Training Prec@1 0.391 (19.866)	Training Prec@5 0.781 (26.681)	
2022-03-31 09:58:40,441: ============================================================
2022-03-31 09:59:21,302: time cost, forward:0.13243407708097055, backward:0.035746998903228015, data cost:0.25491639418181516 
2022-03-31 09:59:21,303: ============================================================
2022-03-31 09:59:21,303: Epoch 2/31 Batch 1600/7662 eta: 1 day, 1:54:31.778502	Training Loss 0.6869 (0.7430)	Training Prec@1 33.789 (19.612)	Training Prec@5 44.531 (26.522)	
2022-03-31 09:59:21,303: ============================================================
2022-03-31 10:00:04,120: time cost, forward:0.13339114357542473, backward:0.03591681691462184, data cost:0.2540482451734717 
2022-03-31 10:00:04,121: ============================================================
2022-03-31 10:00:04,121: Epoch 2/31 Batch 1700/7662 eta: 1 day, 3:08:14.415605	Training Loss 0.7094 (0.7426)	Training Prec@1 22.656 (19.530)	Training Prec@5 33.984 (26.498)	
2022-03-31 10:00:04,122: ============================================================
2022-03-31 10:00:44,837: time cost, forward:0.13302494871278417, backward:0.03581283342977442, data cost:0.25359191319358027 
2022-03-31 10:00:44,838: ============================================================
2022-03-31 10:00:44,839: Epoch 2/31 Batch 1800/7662 eta: 1 day, 1:47:39.919825	Training Loss 0.6650 (0.7391)	Training Prec@1 37.695 (20.295)	Training Prec@5 49.609 (27.512)	
2022-03-31 10:00:44,839: ============================================================
2022-03-31 10:01:28,919: time cost, forward:0.1338208336902958, backward:0.035901919109310336, data cost:0.253637669022426 
2022-03-31 10:01:28,920: ============================================================
2022-03-31 10:01:28,920: Epoch 2/31 Batch 1900/7662 eta: 1 day, 3:54:49.112596	Training Loss 0.6621 (0.7362)	Training Prec@1 39.258 (20.928)	Training Prec@5 49.219 (28.337)	
2022-03-31 10:01:28,920: ============================================================
2022-03-31 10:02:10,213: time cost, forward:0.13389676877890544, backward:0.03576524428214473, data cost:0.2531361869718505 
2022-03-31 10:02:10,215: ============================================================
2022-03-31 10:02:10,216: Epoch 2/31 Batch 2000/7662 eta: 1 day, 2:08:15.197951	Training Loss 0.6504 (0.7319)	Training Prec@1 39.062 (21.943)	Training Prec@5 53.711 (29.557)	
2022-03-31 10:02:10,216: ============================================================
2022-03-31 10:02:54,740: time cost, forward:0.13454738090355206, backward:0.03580447354164505, data cost:0.2535112819653457 
2022-03-31 10:02:54,740: ============================================================
2022-03-31 10:02:54,741: Epoch 2/31 Batch 2100/7662 eta: 1 day, 4:10:11.748083	Training Loss 0.6400 (0.7278)	Training Prec@1 45.898 (22.944)	Training Prec@5 58.594 (30.742)	
2022-03-31 10:02:54,741: ============================================================
2022-03-31 10:03:37,042: time cost, forward:0.13463501737246789, backward:0.03589832658060793, data cost:0.25313043984677264 
2022-03-31 10:03:37,043: ============================================================
2022-03-31 10:03:37,043: Epoch 2/31 Batch 2200/7662 eta: 1 day, 2:45:05.990044	Training Loss 0.6361 (0.7238)	Training Prec@1 45.508 (23.926)	Training Prec@5 56.055 (31.897)	
2022-03-31 10:03:37,043: ============================================================
2022-03-31 10:04:18,422: time cost, forward:0.13463560380641146, backward:0.03586813863229109, data cost:0.2528401647976763 
2022-03-31 10:04:18,423: ============================================================
2022-03-31 10:04:18,423: Epoch 2/31 Batch 2300/7662 eta: 1 day, 2:09:24.614562	Training Loss 0.6235 (0.7200)	Training Prec@1 51.953 (24.867)	Training Prec@5 62.500 (32.996)	
2022-03-31 10:04:18,423: ============================================================
2022-03-31 10:05:01,466: time cost, forward:0.1347939936306736, backward:0.03586895349573324, data cost:0.25295457366905194 
2022-03-31 10:05:01,467: ============================================================
2022-03-31 10:05:01,468: Epoch 2/31 Batch 2400/7662 eta: 1 day, 3:11:49.133150	Training Loss 0.6285 (0.7163)	Training Prec@1 52.539 (25.796)	Training Prec@5 62.500 (34.059)	
2022-03-31 10:05:01,469: ============================================================
2022-03-31 10:05:43,982: time cost, forward:0.13511631774062774, backward:0.035963006761847806, data cost:0.2525769231223068 
2022-03-31 10:05:43,983: ============================================================
2022-03-31 10:05:43,983: Epoch 2/31 Batch 2500/7662 eta: 1 day, 2:51:03.631419	Training Loss 0.6341 (0.7128)	Training Prec@1 46.680 (26.679)	Training Prec@5 58.203 (35.060)	
2022-03-31 10:05:43,983: ============================================================
2022-03-31 10:06:24,116: time cost, forward:0.13403433036143708, backward:0.03600581236278245, data cost:0.2527211146338163 
2022-03-31 10:06:24,117: ============================================================
2022-03-31 10:06:24,117: Epoch 2/31 Batch 2600/7662 eta: 1 day, 1:20:08.596114	Training Loss 0.6262 (0.7094)	Training Prec@1 47.266 (27.555)	Training Prec@5 60.742 (36.040)	
2022-03-31 10:06:24,117: ============================================================
2022-03-31 10:07:06,666: time cost, forward:0.13444048928172114, backward:0.03609044351326885, data cost:0.25232791891801176 
2022-03-31 10:07:06,667: ============================================================
2022-03-31 10:07:06,667: Epoch 2/31 Batch 2700/7662 eta: 1 day, 2:50:58.114576	Training Loss 0.6156 (0.7062)	Training Prec@1 53.516 (28.401)	Training Prec@5 63.086 (36.980)	
2022-03-31 10:07:06,667: ============================================================
2022-03-31 10:07:48,709: time cost, forward:0.13386343725667166, backward:0.03610313862892252, data cost:0.25277384403306447 
2022-03-31 10:07:48,709: ============================================================
2022-03-31 10:07:48,710: Epoch 2/31 Batch 2800/7662 eta: 1 day, 2:31:01.632666	Training Loss 0.8576 (0.7059)	Training Prec@1 0.000 (28.696)	Training Prec@5 0.000 (37.259)	
2022-03-31 10:07:48,710: ============================================================
2022-03-31 10:08:30,356: time cost, forward:0.13379377749674318, backward:0.03604628769189335, data cost:0.2526833371237748 
2022-03-31 10:08:30,357: ============================================================
2022-03-31 10:08:30,357: Epoch 2/31 Batch 2900/7662 eta: 1 day, 2:15:22.914282	Training Loss 0.8440 (0.7106)	Training Prec@1 0.000 (27.706)	Training Prec@5 0.000 (35.974)	
2022-03-31 10:08:30,357: ============================================================
2022-03-31 10:09:12,864: time cost, forward:0.13292836578498884, backward:0.03595805255601151, data cost:0.253696104493607 
2022-03-31 10:09:12,864: ============================================================
2022-03-31 10:09:12,865: Epoch 2/31 Batch 3000/7662 eta: 1 day, 2:47:13.775622	Training Loss 0.8439 (0.7150)	Training Prec@1 0.000 (26.783)	Training Prec@5 0.000 (34.774)	
2022-03-31 10:09:12,865: ============================================================
2022-03-31 10:09:55,295: time cost, forward:0.13281711458044307, backward:0.035951748552842465, data cost:0.2538300239874417 
2022-03-31 10:09:55,308: ============================================================
2022-03-31 10:09:55,309: Epoch 2/31 Batch 3100/7662 eta: 1 day, 2:44:06.528599	Training Loss 0.8422 (0.7191)	Training Prec@1 0.000 (25.918)	Training Prec@5 0.000 (33.653)	
2022-03-31 10:09:55,309: ============================================================
2022-03-31 10:10:35,350: time cost, forward:0.13202118404062885, backward:0.035790352643970846, data cost:0.2541126734616422 
2022-03-31 10:10:35,350: ============================================================
2022-03-31 10:10:35,351: Epoch 2/31 Batch 3200/7662 eta: 1 day, 1:12:39.612877	Training Loss 0.8409 (0.7229)	Training Prec@1 0.000 (25.108)	Training Prec@5 0.000 (32.601)	
2022-03-31 10:10:35,351: ============================================================
2022-03-31 10:11:19,067: time cost, forward:0.1324504161827779, backward:0.03567156317596112, data cost:0.25424775603179606 
2022-03-31 10:11:19,067: ============================================================
2022-03-31 10:11:19,067: Epoch 2/31 Batch 3300/7662 eta: 1 day, 3:30:44.996643	Training Loss 0.8231 (0.7262)	Training Prec@1 0.000 (24.347)	Training Prec@5 0.000 (31.615)	
2022-03-31 10:11:19,067: ============================================================
2022-03-31 10:12:01,428: time cost, forward:0.13289283394427748, backward:0.03565140526657352, data cost:0.25384782917115856 
2022-03-31 10:12:01,428: ============================================================
2022-03-31 10:12:01,428: Epoch 2/31 Batch 3400/7662 eta: 1 day, 2:38:51.492600	Training Loss 0.8761 (0.7291)	Training Prec@1 0.000 (23.632)	Training Prec@5 0.000 (30.690)	
2022-03-31 10:12:01,429: ============================================================
2022-03-31 10:12:44,625: time cost, forward:0.13271239622213665, backward:0.03567644888143875, data cost:0.2542701366459448 
2022-03-31 10:12:44,626: ============================================================
2022-03-31 10:12:44,626: Epoch 2/31 Batch 3500/7662 eta: 1 day, 3:09:42.423558	Training Loss 0.8297 (0.7323)	Training Prec@1 0.000 (22.957)	Training Prec@5 0.000 (29.814)	
2022-03-31 10:12:44,626: ============================================================
2022-03-31 10:13:26,929: time cost, forward:0.13255428870408592, backward:0.03567897806435236, data cost:0.25440856435955417 
2022-03-31 10:13:26,930: ============================================================
2022-03-31 10:13:26,930: Epoch 2/31 Batch 3600/7662 eta: 1 day, 2:35:16.799404	Training Loss 0.8018 (0.7346)	Training Prec@1 0.781 (22.323)	Training Prec@5 1.562 (28.997)	
2022-03-31 10:13:26,930: ============================================================
2022-03-31 10:14:11,195: time cost, forward:0.13344090047415028, backward:0.035729326084195746, data cost:0.25398512046444766 
2022-03-31 10:14:11,196: ============================================================
2022-03-31 10:14:11,197: Epoch 2/31 Batch 3700/7662 eta: 1 day, 3:48:34.676838	Training Loss 0.7937 (0.7364)	Training Prec@1 1.172 (21.731)	Training Prec@5 3.516 (28.248)	
2022-03-31 10:14:11,197: ============================================================
2022-03-31 10:14:57,258: time cost, forward:0.13404641091180305, backward:0.03571715120203591, data cost:0.25436188397077425 
2022-03-31 10:14:57,258: ============================================================
2022-03-31 10:14:57,259: Epoch 2/31 Batch 3800/7662 eta: 1 day, 4:55:28.028184	Training Loss 0.7648 (0.7375)	Training Prec@1 5.469 (21.223)	Training Prec@5 14.453 (27.656)	
2022-03-31 10:14:57,259: ============================================================
2022-03-31 10:15:41,342: time cost, forward:0.1341545760983166, backward:0.0357336827992598, data cost:0.25462874151798787 
2022-03-31 10:15:41,343: ============================================================
2022-03-31 10:15:41,343: Epoch 2/31 Batch 3900/7662 eta: 1 day, 3:40:12.700825	Training Loss 0.8505 (0.7410)	Training Prec@1 0.000 (20.683)	Training Prec@5 0.000 (26.955)	
2022-03-31 10:15:41,343: ============================================================
2022-03-31 10:16:24,426: time cost, forward:0.13428739173080242, backward:0.035741603502663234, data cost:0.254666421078956 
2022-03-31 10:16:24,426: ============================================================
2022-03-31 10:16:24,426: Epoch 2/31 Batch 4000/7662 eta: 1 day, 3:01:49.093514	Training Loss 0.8375 (0.7436)	Training Prec@1 0.000 (20.166)	Training Prec@5 0.000 (26.282)	
2022-03-31 10:16:24,426: ============================================================
2022-03-31 10:17:08,411: time cost, forward:0.13487647480719203, backward:0.035820201130197175, data cost:0.25434475039295756 
2022-03-31 10:17:08,411: ============================================================
2022-03-31 10:17:08,411: Epoch 2/31 Batch 4100/7662 eta: 1 day, 3:35:00.553082	Training Loss 0.8139 (0.7455)	Training Prec@1 0.000 (19.676)	Training Prec@5 0.391 (25.646)	
2022-03-31 10:17:08,411: ============================================================
2022-03-31 10:17:53,363: time cost, forward:0.1355539324965526, backward:0.035908373573559416, data cost:0.254150740672759 
2022-03-31 10:17:53,364: ============================================================
2022-03-31 10:17:53,364: Epoch 2/31 Batch 4200/7662 eta: 1 day, 4:10:40.767536	Training Loss 0.8433 (0.7476)	Training Prec@1 0.000 (19.211)	Training Prec@5 0.000 (25.045)	
2022-03-31 10:17:53,364: ============================================================
2022-03-31 10:18:35,619: time cost, forward:0.13543212311188546, backward:0.03590851613160315, data cost:0.2541671518559621 
2022-03-31 10:18:35,619: ============================================================
2022-03-31 10:18:35,619: Epoch 2/31 Batch 4300/7662 eta: 1 day, 2:28:31.939287	Training Loss 0.7869 (0.7491)	Training Prec@1 1.367 (18.774)	Training Prec@5 2.734 (24.491)	
2022-03-31 10:18:35,620: ============================================================
2022-03-31 10:19:18,893: time cost, forward:0.13589394474658242, backward:0.03590333133861406, data cost:0.2538730045642926 
2022-03-31 10:19:18,894: ============================================================
2022-03-31 10:19:18,894: Epoch 2/31 Batch 4400/7662 eta: 1 day, 3:06:07.369086	Training Loss 0.7720 (0.7499)	Training Prec@1 3.125 (18.387)	Training Prec@5 7.031 (24.033)	
2022-03-31 10:19:18,894: ============================================================
2022-03-31 10:20:01,878: time cost, forward:0.1362382412274749, backward:0.03593451490824051, data cost:0.25355245850302954 
2022-03-31 10:20:01,879: ============================================================
2022-03-31 10:20:01,879: Epoch 2/31 Batch 4500/7662 eta: 1 day, 2:54:30.830282	Training Loss 0.7528 (0.7504)	Training Prec@1 8.008 (18.078)	Training Prec@5 13.672 (23.702)	
2022-03-31 10:20:01,879: ============================================================
2022-03-31 10:20:44,653: time cost, forward:0.1361971984974429, backward:0.03588016366512782, data cost:0.25368373096961255 
2022-03-31 10:20:44,653: ============================================================
2022-03-31 10:20:44,654: Epoch 2/31 Batch 4600/7662 eta: 1 day, 2:45:54.833344	Training Loss 0.8379 (0.7513)	Training Prec@1 0.000 (17.774)	Training Prec@5 0.195 (23.355)	
2022-03-31 10:20:44,654: ============================================================
2022-03-31 10:21:30,322: time cost, forward:0.1368769347147628, backward:0.03596637314445137, data cost:0.2535725531869301 
2022-03-31 10:21:30,323: ============================================================
2022-03-31 10:21:30,323: Epoch 2/31 Batch 4700/7662 eta: 1 day, 4:33:49.527370	Training Loss 0.7257 (0.7517)	Training Prec@1 16.211 (17.544)	Training Prec@5 26.172 (23.126)	
2022-03-31 10:21:30,323: ============================================================
2022-03-31 10:22:13,052: time cost, forward:0.13695202129139059, backward:0.036011506130507055, data cost:0.25345723195283654 
2022-03-31 10:22:13,053: ============================================================
2022-03-31 10:22:13,053: Epoch 2/31 Batch 4800/7662 eta: 1 day, 2:42:48.805197	Training Loss 0.7152 (0.7513)	Training Prec@1 19.336 (17.512)	Training Prec@5 31.055 (23.174)	
2022-03-31 10:22:13,053: ============================================================
2022-03-31 10:22:55,758: time cost, forward:0.13690991498032598, backward:0.036032986168862365, data cost:0.2534767801748487 
2022-03-31 10:22:55,758: ============================================================
2022-03-31 10:22:55,759: Epoch 2/31 Batch 4900/7662 eta: 1 day, 2:41:11.473708	Training Loss 0.7817 (0.7514)	Training Prec@1 6.445 (17.439)	Training Prec@5 10.938 (23.129)	
2022-03-31 10:22:55,759: ============================================================
2022-03-31 10:23:41,738: time cost, forward:0.13739674180525496, backward:0.03605947844575324, data cost:0.2536240106679173 
2022-03-31 10:23:41,738: ============================================================
2022-03-31 10:23:41,738: Epoch 2/31 Batch 5000/7662 eta: 1 day, 4:43:09.807611	Training Loss 0.7224 (0.7506)	Training Prec@1 19.141 (17.562)	Training Prec@5 30.469 (23.349)	
2022-03-31 10:23:41,738: ============================================================
2022-03-31 10:24:26,430: time cost, forward:0.1377506648869953, backward:0.036079062833858956, data cost:0.2536148584503874 
2022-03-31 10:24:26,430: ============================================================
2022-03-31 10:24:26,431: Epoch 2/31 Batch 5100/7662 eta: 1 day, 3:54:10.947397	Training Loss 0.8594 (0.7520)	Training Prec@1 0.000 (17.269)	Training Prec@5 0.000 (22.976)	
2022-03-31 10:24:26,431: ============================================================
2022-03-31 10:25:10,313: time cost, forward:0.13790047629610075, backward:0.036092617943278185, data cost:0.25367397261390456 
2022-03-31 10:25:10,314: ============================================================
2022-03-31 10:25:10,314: Epoch 2/31 Batch 5200/7662 eta: 1 day, 3:23:08.323848	Training Loss 0.6961 (0.7524)	Training Prec@1 27.539 (17.152)	Training Prec@5 39.648 (22.856)	
2022-03-31 10:25:10,314: ============================================================
2022-03-31 10:25:53,005: time cost, forward:0.13805896917768953, backward:0.036103902481303705, data cost:0.25343304909632147 
2022-03-31 10:25:53,006: ============================================================
2022-03-31 10:25:53,006: Epoch 2/31 Batch 5300/7662 eta: 1 day, 2:37:50.783350	Training Loss 0.6864 (0.7518)	Training Prec@1 30.859 (17.262)	Training Prec@5 39.648 (23.032)	
2022-03-31 10:25:53,007: ============================================================
2022-03-31 10:26:35,733: time cost, forward:0.13802164526951932, backward:0.03610016271171139, data cost:0.2535054730494655 
2022-03-31 10:26:35,733: ============================================================
2022-03-31 10:26:35,733: Epoch 2/31 Batch 5400/7662 eta: 1 day, 2:38:25.525853	Training Loss 0.6704 (0.7504)	Training Prec@1 34.766 (17.576)	Training Prec@5 44.531 (23.453)	
2022-03-31 10:26:35,733: ============================================================
2022-03-31 10:27:20,866: time cost, forward:0.1381295165228267, backward:0.03608124892177051, data cost:0.25381676438375483 
2022-03-31 10:27:20,866: ============================================================
2022-03-31 10:27:20,866: Epoch 2/31 Batch 5500/7662 eta: 1 day, 4:07:41.040865	Training Loss 0.8667 (0.7497)	Training Prec@1 0.000 (17.780)	Training Prec@5 0.000 (23.721)	
2022-03-31 10:27:20,867: ============================================================
2022-03-31 10:28:02,031: time cost, forward:0.13798677889358404, backward:0.03607202359748155, data cost:0.25368165795260994 
2022-03-31 10:28:02,032: ============================================================
2022-03-31 10:28:02,032: Epoch 2/31 Batch 5600/7662 eta: 1 day, 1:38:38.539272	Training Loss 0.8424 (0.7514)	Training Prec@1 0.000 (17.463)	Training Prec@5 0.000 (23.298)	
2022-03-31 10:28:02,032: ============================================================
2022-03-31 10:28:45,548: time cost, forward:0.1379765464373065, backward:0.036070367498844624, data cost:0.2538130331047796 
2022-03-31 10:28:45,549: ============================================================
2022-03-31 10:28:45,549: Epoch 2/31 Batch 5700/7662 eta: 1 day, 3:05:47.870784	Training Loss 0.7914 (0.7528)	Training Prec@1 2.148 (17.160)	Training Prec@5 3.320 (22.899)	
2022-03-31 10:28:45,549: ============================================================
2022-03-31 10:29:29,413: time cost, forward:0.13813033830011523, backward:0.036047112142079694, data cost:0.2538588168313121 
2022-03-31 10:29:29,413: ============================================================
2022-03-31 10:29:29,413: Epoch 2/31 Batch 5800/7662 eta: 1 day, 3:18:02.656235	Training Loss 0.8118 (0.7543)	Training Prec@1 0.000 (16.873)	Training Prec@5 0.391 (22.527)	
2022-03-31 10:29:29,413: ============================================================
2022-03-31 10:30:12,761: time cost, forward:0.13791922141503712, backward:0.036050280346104926, data cost:0.2541507439484817 
2022-03-31 10:30:12,762: ============================================================
2022-03-31 10:30:12,762: Epoch 2/31 Batch 5900/7662 eta: 1 day, 2:58:04.127647	Training Loss 0.8578 (0.7548)	Training Prec@1 0.000 (16.694)	Training Prec@5 0.000 (22.336)	
2022-03-31 10:30:12,762: ============================================================
2022-03-31 10:30:53,212: time cost, forward:0.13757730567628174, backward:0.036083731259439644, data cost:0.25404936104024284 
2022-03-31 10:30:53,214: ============================================================
2022-03-31 10:30:53,214: Epoch 2/31 Batch 6000/7662 eta: 1 day, 1:09:16.018264	Training Loss 0.7632 (0.7561)	Training Prec@1 6.445 (16.425)	Training Prec@5 12.109 (21.984)	
2022-03-31 10:30:53,214: ============================================================
2022-03-31 10:31:39,259: time cost, forward:0.13789084599162343, backward:0.03613665006574714, data cost:0.2541997383062635 
2022-03-31 10:31:39,259: ============================================================
2022-03-31 10:31:39,259: Epoch 2/31 Batch 6100/7662 eta: 1 day, 4:37:12.260791	Training Loss 0.7216 (0.7559)	Training Prec@1 20.703 (16.388)	Training Prec@5 32.617 (21.987)	
2022-03-31 10:31:39,260: ============================================================
2022-03-31 10:32:22,060: time cost, forward:0.1380210411627459, backward:0.036153613338356615, data cost:0.2540538297158746 
2022-03-31 10:32:22,060: ============================================================
2022-03-31 10:32:22,061: Epoch 2/31 Batch 6200/7662 eta: 1 day, 2:35:29.457892	Training Loss 0.7302 (0.7557)	Training Prec@1 15.039 (16.407)	Training Prec@5 24.805 (22.038)	
2022-03-31 10:32:22,061: ============================================================
2022-03-31 10:33:06,377: time cost, forward:0.1382186457096045, backward:0.036167258098969896, data cost:0.25406514793979795 
2022-03-31 10:33:06,378: ============================================================
2022-03-31 10:33:06,378: Epoch 2/31 Batch 6300/7662 eta: 1 day, 3:31:17.005680	Training Loss 0.6738 (0.7546)	Training Prec@1 33.594 (16.641)	Training Prec@5 47.070 (22.364)	
2022-03-31 10:33:06,378: ============================================================
2022-03-31 10:33:50,416: time cost, forward:0.13838572665329443, backward:0.03620184378840808, data cost:0.25404079598660656 
2022-03-31 10:33:50,417: ============================================================
2022-03-31 10:33:50,417: Epoch 2/31 Batch 6400/7662 eta: 1 day, 3:20:09.298328	Training Loss 0.8580 (0.7550)	Training Prec@1 0.000 (16.637)	Training Prec@5 0.000 (22.356)	
2022-03-31 10:33:50,417: ============================================================
2022-03-31 10:34:36,018: time cost, forward:0.13877683706440583, backward:0.03615901869688608, data cost:0.25410291704329585 
2022-03-31 10:34:36,019: ============================================================
2022-03-31 10:34:36,019: Epoch 2/31 Batch 6500/7662 eta: 1 day, 4:17:36.976709	Training Loss 0.8443 (0.7564)	Training Prec@1 0.000 (16.381)	Training Prec@5 0.000 (22.012)	
2022-03-31 10:34:36,019: ============================================================
2022-03-31 10:35:18,714: time cost, forward:0.138702697366598, backward:0.03615601844255771, data cost:0.25414229299213187 
2022-03-31 10:35:18,715: ============================================================
2022-03-31 10:35:18,715: Epoch 2/31 Batch 6600/7662 eta: 1 day, 2:28:43.159611	Training Loss 0.8238 (0.7577)	Training Prec@1 0.195 (16.134)	Training Prec@5 0.781 (21.681)	
2022-03-31 10:35:18,715: ============================================================
2022-03-31 10:36:03,460: time cost, forward:0.13901200460344842, backward:0.036168254654982995, data cost:0.2540848073647581 
2022-03-31 10:36:03,460: ============================================================
2022-03-31 10:36:03,460: Epoch 2/31 Batch 6700/7662 eta: 1 day, 3:44:14.824685	Training Loss 0.8588 (0.7593)	Training Prec@1 0.000 (15.893)	Training Prec@5 0.000 (21.358)	
2022-03-31 10:36:03,460: ============================================================
2022-03-31 10:36:45,763: time cost, forward:0.13890090460706447, backward:0.03614818178427397, data cost:0.2541061463575536 
2022-03-31 10:36:45,778: ============================================================
2022-03-31 10:36:45,779: Epoch 2/31 Batch 6800/7662 eta: 1 day, 2:13:15.592869	Training Loss 0.8506 (0.7607)	Training Prec@1 0.000 (15.659)	Training Prec@5 0.000 (21.044)	
2022-03-31 10:36:45,779: ============================================================
2022-03-31 10:37:31,119: time cost, forward:0.13938808423882895, backward:0.03610595234374513, data cost:0.254020352521864 
2022-03-31 10:37:31,120: ============================================================
2022-03-31 10:37:31,120: Epoch 2/31 Batch 6900/7662 eta: 1 day, 4:04:52.898689	Training Loss 0.8514 (0.7620)	Training Prec@1 0.000 (15.432)	Training Prec@5 0.000 (20.739)	
2022-03-31 10:37:31,120: ============================================================
2022-03-31 10:38:16,658: time cost, forward:0.13977567429780313, backward:0.036121576543296466, data cost:0.25397773275444857 
2022-03-31 10:38:16,658: ============================================================
2022-03-31 10:38:16,658: Epoch 2/31 Batch 7000/7662 eta: 1 day, 4:11:27.956211	Training Loss 0.8512 (0.7633)	Training Prec@1 0.000 (15.212)	Training Prec@5 0.000 (20.443)	
2022-03-31 10:38:16,659: ============================================================
2022-03-31 10:39:01,843: time cost, forward:0.1401184319207191, backward:0.03613990742583596, data cost:0.2539117360790106 
2022-03-31 10:39:01,844: ============================================================
2022-03-31 10:39:01,844: Epoch 2/31 Batch 7100/7662 eta: 1 day, 3:57:35.964085	Training Loss 0.8485 (0.7645)	Training Prec@1 0.000 (14.998)	Training Prec@5 0.000 (20.155)	
2022-03-31 10:39:01,844: ============================================================
2022-03-31 10:39:46,619: time cost, forward:0.14018093117211722, backward:0.03614916197375003, data cost:0.2540697740140698 
2022-03-31 10:39:46,619: ============================================================
2022-03-31 10:39:46,620: Epoch 2/31 Batch 7200/7662 eta: 1 day, 3:41:37.556014	Training Loss 0.8471 (0.7656)	Training Prec@1 0.000 (14.789)	Training Prec@5 0.000 (19.875)	
2022-03-31 10:39:46,620: ============================================================
2022-03-31 10:40:30,144: time cost, forward:0.14027937197786502, backward:0.036214212143742916, data cost:0.25397255888114584 
2022-03-31 10:40:30,145: ============================================================
2022-03-31 10:40:30,145: Epoch 2/31 Batch 7300/7662 eta: 1 day, 2:54:30.570099	Training Loss 0.8447 (0.7667)	Training Prec@1 0.000 (14.587)	Training Prec@5 0.000 (19.603)	
2022-03-31 10:40:30,145: ============================================================
2022-03-31 10:41:14,437: time cost, forward:0.14041396366098247, backward:0.03622429112128783, data cost:0.2539856553738271 
2022-03-31 10:41:14,437: ============================================================
2022-03-31 10:41:14,437: Epoch 2/31 Batch 7400/7662 eta: 1 day, 3:22:13.168787	Training Loss 0.8455 (0.7678)	Training Prec@1 0.000 (14.390)	Training Prec@5 0.000 (19.339)	
2022-03-31 10:41:14,437: ============================================================
2022-03-31 10:42:00,224: time cost, forward:0.14088432978655374, backward:0.036273446937039114, data cost:0.25382617896899395 
2022-03-31 10:42:00,225: ============================================================
2022-03-31 10:42:00,225: Epoch 2/31 Batch 7500/7662 eta: 1 day, 4:16:54.226556	Training Loss 0.8362 (0.7688)	Training Prec@1 0.000 (14.198)	Training Prec@5 0.195 (19.081)	
2022-03-31 10:42:00,225: ============================================================
2022-03-31 10:42:45,229: time cost, forward:0.14111880114681236, backward:0.03629356946642735, data cost:0.2538162498885761 
2022-03-31 10:42:45,229: ============================================================
2022-03-31 10:42:45,230: Epoch 2/31 Batch 7600/7662 eta: 1 day, 3:47:07.159569	Training Loss 0.8374 (0.7697)	Training Prec@1 0.000 (14.011)	Training Prec@5 0.000 (18.831)	
2022-03-31 10:42:45,230: ============================================================
2022-03-31 10:43:16,136: Epoch: 2/31 eta: 1 day, 3:46:38.806817	Training Loss 0.8231 (0.7702)	Training Prec@1 0.000 (13.897)	Training Prec@5 0.391 (18.678)
2022-03-31 10:43:16,137: ============================================================
2022-03-31 10:43:58,724: time cost, forward:0.10740941461890635, backward:0.03449749946594238, data cost:0.281609499093258 
2022-03-31 10:43:58,724: ============================================================
2022-03-31 10:43:58,725: Epoch 3/31 Batch 100/7662 eta: 1 day, 2:01:39.581961	Training Loss 0.8490 (0.8244)	Training Prec@1 0.000 (0.083)	Training Prec@5 0.000 (0.264)	
2022-03-31 10:43:58,725: ============================================================
2022-03-31 10:44:41,112: time cost, forward:0.1147919995101852, backward:0.034691260687669916, data cost:0.2731085398688388 
2022-03-31 10:44:41,113: ============================================================
2022-03-31 10:44:41,113: Epoch 3/31 Batch 200/7662 eta: 1 day, 2:08:21.282299	Training Loss 0.8441 (0.8353)	Training Prec@1 0.000 (0.043)	Training Prec@5 0.000 (0.142)	
2022-03-31 10:44:41,113: ============================================================
2022-03-31 10:45:24,094: time cost, forward:0.12530670756081674, backward:0.03473733898787993, data cost:0.265195202269283 
2022-03-31 10:45:24,105: ============================================================
2022-03-31 10:45:24,105: Epoch 3/31 Batch 300/7662 eta: 1 day, 2:29:59.605004	Training Loss 0.8422 (0.8377)	Training Prec@1 0.000 (0.032)	Training Prec@5 0.000 (0.111)	
2022-03-31 10:45:24,105: ============================================================
2022-03-31 10:46:07,340: time cost, forward:0.13092950890237526, backward:0.03513448758232862, data cost:0.26077340121257275 
2022-03-31 10:46:07,341: ============================================================
2022-03-31 10:46:07,341: Epoch 3/31 Batch 400/7662 eta: 1 day, 2:38:16.480620	Training Loss 0.8424 (0.8382)	Training Prec@1 0.000 (0.026)	Training Prec@5 0.000 (0.099)	
2022-03-31 10:46:07,341: ============================================================
2022-03-31 10:46:51,028: time cost, forward:0.1332599490821242, backward:0.03551460076907355, data cost:0.25993606848324946 
2022-03-31 10:46:51,028: ============================================================
2022-03-31 10:46:51,028: Epoch 3/31 Batch 500/7662 eta: 1 day, 2:54:14.155982	Training Loss 0.8215 (0.8367)	Training Prec@1 0.195 (0.036)	Training Prec@5 0.195 (0.122)	
2022-03-31 10:46:51,028: ============================================================
2022-03-31 10:47:35,517: time cost, forward:0.13776065590783632, backward:0.03603700763594129, data cost:0.25693176863388545 
2022-03-31 10:47:35,517: ============================================================
2022-03-31 10:47:35,518: Epoch 3/31 Batch 600/7662 eta: 1 day, 3:23:08.994645	Training Loss 0.8242 (0.8362)	Training Prec@1 0.000 (0.038)	Training Prec@5 0.195 (0.131)	
2022-03-31 10:47:35,519: ============================================================
2022-03-31 10:48:20,616: time cost, forward:0.13882475554175644, backward:0.036009392172140796, data cost:0.2590776049186914 
2022-03-31 10:48:20,617: ============================================================
2022-03-31 10:48:20,617: Epoch 3/31 Batch 700/7662 eta: 1 day, 3:44:53.513406	Training Loss 0.8146 (0.8363)	Training Prec@1 0.000 (0.039)	Training Prec@5 0.000 (0.134)	
2022-03-31 10:48:20,617: ============================================================
2022-03-31 10:49:02,730: time cost, forward:0.1386081035504204, backward:0.036213577912656475, data cost:0.257389666887935 
2022-03-31 10:49:02,730: ============================================================
2022-03-31 10:49:02,730: Epoch 3/31 Batch 800/7662 eta: 1 day, 1:53:58.601032	Training Loss 0.8490 (0.8380)	Training Prec@1 0.000 (0.036)	Training Prec@5 0.000 (0.122)	
2022-03-31 10:49:02,730: ============================================================
2022-03-31 10:49:46,808: time cost, forward:0.13955047318879701, backward:0.0364087346663597, data cost:0.25719317472286035 
2022-03-31 10:49:46,809: ============================================================
2022-03-31 10:49:46,809: Epoch 3/31 Batch 900/7662 eta: 1 day, 3:05:45.479754	Training Loss 0.8480 (0.8393)	Training Prec@1 0.000 (0.032)	Training Prec@5 0.000 (0.109)	
2022-03-31 10:49:46,809: ============================================================
2022-03-31 10:50:31,179: time cost, forward:0.14106994467573958, backward:0.036582150855460564, data cost:0.25637492952165425 
2022-03-31 10:50:31,179: ============================================================
2022-03-31 10:50:31,179: Epoch 3/31 Batch 1000/7662 eta: 1 day, 3:15:46.971172	Training Loss 0.8398 (0.8401)	Training Prec@1 0.000 (0.029)	Training Prec@5 0.000 (0.101)	
2022-03-31 10:50:31,180: ============================================================
2022-03-31 10:51:13,802: time cost, forward:0.14161405094761106, backward:0.0365713030994752, data cost:0.25508117979499184 
2022-03-31 10:51:13,802: ============================================================
2022-03-31 10:51:13,802: Epoch 3/31 Batch 1100/7662 eta: 1 day, 2:10:39.278537	Training Loss 0.8398 (0.8402)	Training Prec@1 0.195 (0.028)	Training Prec@5 0.195 (0.099)	
2022-03-31 10:51:13,803: ============================================================
2022-03-31 10:51:59,655: time cost, forward:0.14435989962109333, backward:0.036729581560861875, data cost:0.25421565865555634 
2022-03-31 10:51:59,656: ============================================================
2022-03-31 10:51:59,656: Epoch 3/31 Batch 1200/7662 eta: 1 day, 4:08:56.069178	Training Loss 0.8380 (0.8396)	Training Prec@1 0.000 (0.029)	Training Prec@5 0.000 (0.102)	
2022-03-31 10:51:59,656: ============================================================
2022-03-31 10:52:44,258: time cost, forward:0.1457102016084831, backward:0.03688753871756209, data cost:0.25338777218349534 
2022-03-31 10:52:44,258: ============================================================
2022-03-31 10:52:44,259: Epoch 3/31 Batch 1300/7662 eta: 1 day, 3:22:06.547490	Training Loss 0.8203 (0.8389)	Training Prec@1 0.195 (0.031)	Training Prec@5 0.391 (0.108)	
2022-03-31 10:52:44,259: ============================================================
2022-03-31 10:53:28,263: time cost, forward:0.14627412849873453, backward:0.03697617195434789, data cost:0.2530182174821681 
2022-03-31 10:53:28,264: ============================================================
2022-03-31 10:53:28,264: Epoch 3/31 Batch 1400/7662 eta: 1 day, 2:59:22.850255	Training Loss 0.8128 (0.8374)	Training Prec@1 0.195 (0.039)	Training Prec@5 0.391 (0.126)	
2022-03-31 10:53:28,264: ============================================================
2022-03-31 10:54:12,809: time cost, forward:0.14621604021745493, backward:0.03701816470405116, data cost:0.25361622978322423 
2022-03-31 10:54:12,809: ============================================================
2022-03-31 10:54:12,809: Epoch 3/31 Batch 1500/7662 eta: 1 day, 3:18:31.894610	Training Loss 0.8033 (0.8354)	Training Prec@1 0.195 (0.057)	Training Prec@5 1.172 (0.180)	
2022-03-31 10:54:12,810: ============================================================
2022-03-31 10:54:57,673: time cost, forward:0.14730525523740995, backward:0.037050556286638274, data cost:0.25313050781211827 
2022-03-31 10:54:57,674: ============================================================
2022-03-31 10:54:57,674: Epoch 3/31 Batch 1600/7662 eta: 1 day, 3:29:31.072364	Training Loss 0.7953 (0.8334)	Training Prec@1 0.586 (0.082)	Training Prec@5 1.562 (0.248)	
2022-03-31 10:54:57,674: ============================================================
2022-03-31 10:55:39,826: time cost, forward:0.14619919620870914, backward:0.036997063430777154, data cost:0.2533255854096393 
2022-03-31 10:55:39,837: ============================================================
2022-03-31 10:55:39,837: Epoch 3/31 Batch 1700/7662 eta: 1 day, 1:49:29.687018	Training Loss 0.7919 (0.8312)	Training Prec@1 0.781 (0.125)	Training Prec@5 1.562 (0.364)	
2022-03-31 10:55:39,838: ============================================================
2022-03-31 10:56:23,315: time cost, forward:0.1459562211251378, backward:0.036987266121737625, data cost:0.25347300355072616 
2022-03-31 10:56:23,337: ============================================================
2022-03-31 10:56:23,339: Epoch 3/31 Batch 1800/7662 eta: 1 day, 2:37:55.809817	Training Loss 0.8137 (0.8285)	Training Prec@1 0.586 (0.235)	Training Prec@5 1.562 (0.620)	
2022-03-31 10:56:23,339: ============================================================
2022-03-31 10:57:07,032: time cost, forward:0.1463342685960606, backward:0.03694056196549241, data cost:0.25313873188065 
2022-03-31 10:57:07,033: ============================================================
2022-03-31 10:57:07,033: Epoch 3/31 Batch 1900/7662 eta: 1 day, 2:44:18.564871	Training Loss 0.8591 (0.8275)	Training Prec@1 0.000 (0.302)	Training Prec@5 0.000 (0.755)	
2022-03-31 10:57:07,033: ============================================================
2022-03-31 10:57:52,025: time cost, forward:0.14688810042705222, backward:0.036928969064076105, data cost:0.25322177482879776 
2022-03-31 10:57:52,025: ============================================================
2022-03-31 10:57:52,025: Epoch 3/31 Batch 2000/7662 eta: 1 day, 3:31:12.212554	Training Loss 0.8508 (0.8288)	Training Prec@1 0.000 (0.287)	Training Prec@5 0.000 (0.717)	
2022-03-31 10:57:52,025: ============================================================
2022-03-31 10:58:36,142: time cost, forward:0.14717651015522937, backward:0.037031996869200355, data cost:0.2530169776645713 
2022-03-31 10:58:36,142: ============================================================
2022-03-31 10:58:36,142: Epoch 3/31 Batch 2100/7662 eta: 1 day, 2:58:21.507932	Training Loss 0.8492 (0.8299)	Training Prec@1 0.000 (0.274)	Training Prec@5 0.000 (0.684)	
2022-03-31 10:58:36,142: ============================================================
2022-03-31 10:59:19,427: time cost, forward:0.14717533936442, backward:0.036981001936776794, data cost:0.2527949774249026 
2022-03-31 10:59:19,427: ============================================================
2022-03-31 10:59:19,427: Epoch 3/31 Batch 2200/7662 eta: 1 day, 2:27:06.577305	Training Loss 0.8487 (0.8306)	Training Prec@1 0.000 (0.262)	Training Prec@5 0.000 (0.656)	
2022-03-31 10:59:19,428: ============================================================
2022-03-31 11:00:01,255: time cost, forward:0.14625320189825708, backward:0.036841460340382895, data cost:0.25301784367704455 
2022-03-31 11:00:01,255: ============================================================
2022-03-31 11:00:01,256: Epoch 3/31 Batch 2300/7662 eta: 1 day, 1:33:00.152350	Training Loss 0.8477 (0.8313)	Training Prec@1 0.000 (0.251)	Training Prec@5 0.000 (0.628)	
2022-03-31 11:00:01,256: ============================================================
2022-03-31 11:00:44,190: time cost, forward:0.14589904248093308, backward:0.036789425416209394, data cost:0.25313206134412924 
2022-03-31 11:00:44,191: ============================================================
2022-03-31 11:00:44,191: Epoch 3/31 Batch 2400/7662 eta: 1 day, 2:12:51.727646	Training Loss 0.8440 (0.8320)	Training Prec@1 0.195 (0.241)	Training Prec@5 0.195 (0.603)	
2022-03-31 11:00:44,191: ============================================================
2022-03-31 11:01:28,940: time cost, forward:0.1460991104205354, backward:0.03675663857614579, data cost:0.253404980327855 
2022-03-31 11:01:28,940: ============================================================
2022-03-31 11:01:28,941: Epoch 3/31 Batch 2500/7662 eta: 1 day, 3:18:33.816470	Training Loss 0.8410 (0.8325)	Training Prec@1 0.000 (0.232)	Training Prec@5 0.000 (0.581)	
2022-03-31 11:01:28,941: ============================================================
2022-03-31 11:02:14,629: time cost, forward:0.14637810416109703, backward:0.036770071695290334, data cost:0.2538849750634751 
2022-03-31 11:02:14,629: ============================================================
2022-03-31 11:02:14,629: Epoch 3/31 Batch 2600/7662 eta: 1 day, 3:52:12.385822	Training Loss 0.8395 (0.8328)	Training Prec@1 0.000 (0.223)	Training Prec@5 0.195 (0.563)	
2022-03-31 11:02:14,630: ============================================================
2022-03-31 11:02:57,714: time cost, forward:0.14639127038063143, backward:0.036776744334421234, data cost:0.2536131546823304 
2022-03-31 11:02:57,714: ============================================================
2022-03-31 11:02:57,714: Epoch 3/31 Batch 2700/7662 eta: 1 day, 2:16:10.944846	Training Loss 0.8269 (0.8328)	Training Prec@1 0.195 (0.217)	Training Prec@5 0.195 (0.548)	
2022-03-31 11:02:57,715: ============================================================
2022-03-31 11:03:39,438: time cost, forward:0.14582610121792067, backward:0.0366615651973276, data cost:0.253563714819578 
2022-03-31 11:03:39,438: ============================================================
2022-03-31 11:03:39,439: Epoch 3/31 Batch 2800/7662 eta: 1 day, 1:25:42.514197	Training Loss 0.8191 (0.8326)	Training Prec@1 0.000 (0.213)	Training Prec@5 0.195 (0.542)	
2022-03-31 11:03:39,439: ============================================================
2022-03-31 11:04:23,522: time cost, forward:0.14556499002883663, backward:0.03665439101407017, data cost:0.2539773742344183 
2022-03-31 11:04:23,522: ============================================================
2022-03-31 11:04:23,522: Epoch 3/31 Batch 2900/7662 eta: 1 day, 2:51:15.313386	Training Loss 0.8385 (0.8320)	Training Prec@1 0.000 (0.213)	Training Prec@5 0.000 (0.544)	
2022-03-31 11:04:23,522: ============================================================
2022-03-31 11:05:07,369: time cost, forward:0.14538939399057804, backward:0.03655367845215373, data cost:0.25430799572020224 
2022-03-31 11:05:07,369: ============================================================
2022-03-31 11:05:07,370: Epoch 3/31 Batch 3000/7662 eta: 1 day, 2:41:52.918498	Training Loss 0.8031 (0.8314)	Training Prec@1 0.586 (0.214)	Training Prec@5 2.344 (0.548)	
2022-03-31 11:05:07,370: ============================================================
2022-03-31 11:05:52,009: time cost, forward:0.14554705570574228, backward:0.036552717086383316, data cost:0.2544748280732314 
2022-03-31 11:05:52,010: ============================================================
2022-03-31 11:05:52,010: Epoch 3/31 Batch 3100/7662 eta: 1 day, 3:10:06.252473	Training Loss 0.8518 (0.8311)	Training Prec@1 0.000 (0.215)	Training Prec@5 0.000 (0.554)	
2022-03-31 11:05:52,010: ============================================================
2022-03-31 11:06:32,874: time cost, forward:0.14432742641135357, backward:0.036428383120375524, data cost:0.2549106403230391 
2022-03-31 11:06:32,874: ============================================================
2022-03-31 11:06:32,874: Epoch 3/31 Batch 3200/7662 eta: 1 day, 0:51:32.480961	Training Loss 0.8495 (0.8317)	Training Prec@1 0.000 (0.208)	Training Prec@5 0.000 (0.538)	
2022-03-31 11:06:32,874: ============================================================
2022-03-31 11:07:17,712: time cost, forward:0.14448913692452395, backward:0.03641083732667422, data cost:0.2551455535322075 
2022-03-31 11:07:17,712: ============================================================
2022-03-31 11:07:17,712: Epoch 3/31 Batch 3300/7662 eta: 1 day, 3:15:49.811104	Training Loss 0.8194 (0.8318)	Training Prec@1 0.391 (0.203)	Training Prec@5 0.586 (0.526)	
2022-03-31 11:07:17,712: ============================================================
2022-03-31 11:07:58,426: time cost, forward:0.14384939229358606, backward:0.03639107032466124, data cost:0.2549332276131343 
2022-03-31 11:07:58,427: ============================================================
2022-03-31 11:07:58,427: Epoch 3/31 Batch 3400/7662 eta: 1 day, 0:44:43.233828	Training Loss 0.8002 (0.8311)	Training Prec@1 0.977 (0.206)	Training Prec@5 1.953 (0.539)	
2022-03-31 11:07:58,427: ============================================================
2022-03-31 11:08:42,075: time cost, forward:0.14399445421459267, backward:0.0364691064370704, data cost:0.2547393832488822 
2022-03-31 11:08:42,075: ============================================================
2022-03-31 11:08:42,075: Epoch 3/31 Batch 3500/7662 eta: 1 day, 2:30:58.657222	Training Loss 0.8155 (0.8305)	Training Prec@1 0.195 (0.210)	Training Prec@5 0.781 (0.551)	
2022-03-31 11:08:42,075: ============================================================
2022-03-31 11:09:25,094: time cost, forward:0.14376343273725667, backward:0.036496784462469026, data cost:0.2547883813862802 
2022-03-31 11:09:25,095: ============================================================
2022-03-31 11:09:25,095: Epoch 3/31 Batch 3600/7662 eta: 1 day, 2:07:20.420429	Training Loss 0.7985 (0.8300)	Training Prec@1 0.977 (0.214)	Training Prec@5 1.562 (0.562)	
2022-03-31 11:09:25,095: ============================================================
2022-03-31 11:10:06,504: time cost, forward:0.14338597164633596, backward:0.036438329247533714, data cost:0.2546482358181209 
2022-03-31 11:10:06,504: ============================================================
2022-03-31 11:10:06,504: Epoch 3/31 Batch 3700/7662 eta: 1 day, 1:07:59.286889	Training Loss 0.7913 (0.8290)	Training Prec@1 0.977 (0.227)	Training Prec@5 2.148 (0.601)	
2022-03-31 11:10:06,505: ============================================================
2022-03-31 11:10:48,553: time cost, forward:0.1428690406014085, backward:0.036421914199805006, data cost:0.2547970271229775 
2022-03-31 11:10:48,554: ============================================================
2022-03-31 11:10:48,554: Epoch 3/31 Batch 3800/7662 eta: 1 day, 1:30:35.811928	Training Loss 0.8534 (0.8288)	Training Prec@1 0.000 (0.238)	Training Prec@5 0.000 (0.628)	
2022-03-31 11:10:48,567: ============================================================
2022-03-31 11:11:31,873: time cost, forward:0.14269128901189826, backward:0.03647361855899471, data cost:0.25487983431624095 
2022-03-31 11:11:31,874: ============================================================
2022-03-31 11:11:31,874: Epoch 3/31 Batch 3900/7662 eta: 1 day, 2:16:07.146432	Training Loss 0.8377 (0.8292)	Training Prec@1 0.195 (0.232)	Training Prec@5 0.195 (0.614)	
2022-03-31 11:11:31,874: ============================================================
2022-03-31 11:12:17,156: time cost, forward:0.14274682578935596, backward:0.036471268152349974, data cost:0.25527124125887735 
2022-03-31 11:12:17,156: ============================================================
2022-03-31 11:12:17,157: Epoch 3/31 Batch 4000/7662 eta: 1 day, 3:26:46.501193	Training Loss 0.8154 (0.8291)	Training Prec@1 0.000 (0.229)	Training Prec@5 0.977 (0.608)	
2022-03-31 11:12:17,157: ============================================================
2022-03-31 11:13:01,044: time cost, forward:0.143092308837805, backward:0.03645007073457545, data cost:0.25505401541995376 
2022-03-31 11:13:01,044: ============================================================
2022-03-31 11:13:01,044: Epoch 3/31 Batch 4100/7662 eta: 1 day, 2:35:18.691678	Training Loss 0.7851 (0.8285)	Training Prec@1 2.539 (0.238)	Training Prec@5 5.273 (0.633)	
2022-03-31 11:13:01,044: ============================================================
2022-03-31 11:13:45,583: time cost, forward:0.14339585331514582, backward:0.03646924649570408, data cost:0.2549228119719565 
2022-03-31 11:13:45,584: ============================================================
2022-03-31 11:13:45,584: Epoch 3/31 Batch 4200/7662 eta: 1 day, 2:58:15.238406	Training Loss 0.7869 (0.8276)	Training Prec@1 0.977 (0.256)	Training Prec@5 3.516 (0.678)	
2022-03-31 11:13:45,584: ============================================================
2022-03-31 11:14:31,163: time cost, forward:0.14366035412621792, backward:0.03653780985333305, data cost:0.25511245207332905 
2022-03-31 11:14:31,163: ============================================================
2022-03-31 11:14:31,163: Epoch 3/31 Batch 4300/7662 eta: 1 day, 3:35:17.886603	Training Loss 0.7803 (0.8266)	Training Prec@1 1.367 (0.284)	Training Prec@5 4.688 (0.750)	
2022-03-31 11:14:31,164: ============================================================
2022-03-31 11:15:17,383: time cost, forward:0.14383580869478269, backward:0.036606137116786217, data cost:0.2554530320207648 
2022-03-31 11:15:17,383: ============================================================
2022-03-31 11:15:17,383: Epoch 3/31 Batch 4400/7662 eta: 1 day, 3:57:46.426282	Training Loss 0.7765 (0.8255)	Training Prec@1 2.930 (0.328)	Training Prec@5 7.422 (0.857)	
2022-03-31 11:15:17,383: ============================================================
2022-03-31 11:16:01,485: time cost, forward:0.14404037502718703, backward:0.03662944364664315, data cost:0.25530707499641236 
2022-03-31 11:16:01,485: ============================================================
2022-03-31 11:16:01,485: Epoch 3/31 Batch 4500/7662 eta: 1 day, 2:40:09.134426	Training Loss 0.7677 (0.8244)	Training Prec@1 1.562 (0.390)	Training Prec@5 6.641 (0.992)	
2022-03-31 11:16:01,485: ============================================================
2022-03-31 11:16:47,797: time cost, forward:0.1443613172743885, backward:0.036634266078407335, data cost:0.25554577110383425 
2022-03-31 11:16:47,797: ============================================================
2022-03-31 11:16:47,798: Epoch 3/31 Batch 4600/7662 eta: 1 day, 3:59:35.275920	Training Loss 0.7597 (0.8231)	Training Prec@1 5.469 (0.479)	Training Prec@5 9.570 (1.173)	
2022-03-31 11:16:47,798: ============================================================
2022-03-31 11:17:32,391: time cost, forward:0.1445073596871541, backward:0.03662467266707046, data cost:0.25561782323849863 
2022-03-31 11:17:32,391: ============================================================
2022-03-31 11:17:32,391: Epoch 3/31 Batch 4700/7662 eta: 1 day, 2:56:31.131955	Training Loss 0.7986 (0.8221)	Training Prec@1 0.000 (0.551)	Training Prec@5 1.172 (1.319)	
2022-03-31 11:17:32,391: ============================================================
2022-03-31 11:18:17,046: time cost, forward:0.14483170753768346, backward:0.036598339853845155, data cost:0.2555159561135764 
2022-03-31 11:18:17,047: ============================================================
2022-03-31 11:18:17,047: Epoch 3/31 Batch 4800/7662 eta: 1 day, 2:58:00.967426	Training Loss 0.7685 (0.8213)	Training Prec@1 3.711 (0.586)	Training Prec@5 8.594 (1.396)	
2022-03-31 11:18:17,047: ============================================================
2022-03-31 11:19:02,688: time cost, forward:0.14524123317783136, backward:0.03664692987542076, data cost:0.2554355707186099 
2022-03-31 11:19:02,688: ============================================================
2022-03-31 11:19:02,688: Epoch 3/31 Batch 4900/7662 eta: 1 day, 3:32:58.343821	Training Loss 0.7583 (0.8202)	Training Prec@1 7.422 (0.670)	Training Prec@5 12.891 (1.567)	
2022-03-31 11:19:02,689: ============================================================
2022-03-31 11:19:46,822: time cost, forward:0.14550736485111354, backward:0.036646471473783894, data cost:0.25523203538641687 
2022-03-31 11:19:46,823: ============================================================
2022-03-31 11:19:46,823: Epoch 3/31 Batch 5000/7662 eta: 1 day, 2:37:39.271707	Training Loss 0.8513 (0.8195)	Training Prec@1 0.000 (0.754)	Training Prec@5 0.000 (1.721)	
2022-03-31 11:19:46,823: ============================================================
2022-03-31 11:20:30,160: time cost, forward:0.14548541536796886, backward:0.03661482842395436, data cost:0.25519716176221735 
2022-03-31 11:20:30,160: ============================================================
2022-03-31 11:20:30,161: Epoch 3/31 Batch 5100/7662 eta: 1 day, 2:08:06.008637	Training Loss 0.7861 (0.8197)	Training Prec@1 1.953 (0.745)	Training Prec@5 3.906 (1.701)	
2022-03-31 11:20:30,161: ============================================================
2022-03-31 11:21:15,077: time cost, forward:0.14567948992744412, backward:0.03660107131278568, data cost:0.2552361922622713 
2022-03-31 11:21:15,078: ============================================================
2022-03-31 11:21:15,078: Epoch 3/31 Batch 5200/7662 eta: 1 day, 3:04:30.598815	Training Loss 0.8501 (0.8201)	Training Prec@1 0.000 (0.735)	Training Prec@5 0.000 (1.679)	
2022-03-31 11:21:15,078: ============================================================
2022-03-31 11:22:01,460: time cost, forward:0.14625067592994473, backward:0.036679289165049776, data cost:0.25506222830738384 
2022-03-31 11:22:01,460: ============================================================
2022-03-31 11:22:01,460: Epoch 3/31 Batch 5300/7662 eta: 1 day, 3:56:42.745694	Training Loss 0.8406 (0.8206)	Training Prec@1 0.000 (0.721)	Training Prec@5 0.000 (1.648)	
2022-03-31 11:22:01,461: ============================================================
2022-03-31 11:22:49,018: time cost, forward:0.14710811717264252, backward:0.03681555653660579, data cost:0.2547464524845124 
2022-03-31 11:22:49,019: ============================================================
2022-03-31 11:22:49,019: Epoch 3/31 Batch 5400/7662 eta: 1 day, 4:38:25.899732	Training Loss 0.8301 (0.8209)	Training Prec@1 0.195 (0.708)	Training Prec@5 0.195 (1.620)	
2022-03-31 11:22:49,019: ============================================================
2022-03-31 11:23:33,647: time cost, forward:0.147224653155224, backward:0.03681245334019637, data cost:0.2547410721994786 
2022-03-31 11:23:33,647: ============================================================
2022-03-31 11:23:33,648: Epoch 3/31 Batch 5500/7662 eta: 1 day, 2:51:50.411637	Training Loss 0.7956 (0.8208)	Training Prec@1 0.977 (0.701)	Training Prec@5 2.734 (1.606)	
2022-03-31 11:23:33,648: ============================================================
2022-03-31 11:24:19,611: time cost, forward:0.1477227193965595, backward:0.0368344466118626, data cost:0.25458620462828097 
2022-03-31 11:24:19,611: ============================================================
2022-03-31 11:24:19,611: Epoch 3/31 Batch 5600/7662 eta: 1 day, 3:39:16.627043	Training Loss 0.7582 (0.8199)	Training Prec@1 6.641 (0.752)	Training Prec@5 11.914 (1.713)	
2022-03-31 11:24:19,611: ============================================================
2022-03-31 11:25:04,295: time cost, forward:0.14793501972922068, backward:0.03686696948827746, data cost:0.254472927035606 
2022-03-31 11:25:04,295: ============================================================
2022-03-31 11:25:04,295: Epoch 3/31 Batch 5700/7662 eta: 1 day, 2:52:20.373964	Training Loss 0.7510 (0.8188)	Training Prec@1 7.617 (0.867)	Training Prec@5 13.672 (1.925)	
2022-03-31 11:25:04,295: ============================================================
2022-03-31 11:25:50,344: time cost, forward:0.14827510746908015, backward:0.03688260916492655, data cost:0.2544665736234441 
2022-03-31 11:25:50,345: ============================================================
2022-03-31 11:25:50,345: Epoch 3/31 Batch 5800/7662 eta: 1 day, 3:40:51.067649	Training Loss 0.7457 (0.8175)	Training Prec@1 10.156 (1.004)	Training Prec@5 17.188 (2.167)	
2022-03-31 11:25:50,345: ============================================================
2022-03-31 11:26:35,601: time cost, forward:0.14830775247991923, backward:0.03686700972243272, data cost:0.25465610577385595 
2022-03-31 11:26:35,601: ============================================================
2022-03-31 11:26:35,601: Epoch 3/31 Batch 5900/7662 eta: 1 day, 3:11:29.144996	Training Loss 0.7426 (0.8164)	Training Prec@1 11.328 (1.137)	Training Prec@5 16.992 (2.401)	
2022-03-31 11:26:35,602: ============================================================
2022-03-31 11:27:20,061: time cost, forward:0.1483243362648047, backward:0.03695813396172159, data cost:0.2546205553219187 
2022-03-31 11:27:20,062: ============================================================
2022-03-31 11:27:20,062: Epoch 3/31 Batch 6000/7662 eta: 1 day, 2:42:03.437324	Training Loss 0.7328 (0.8151)	Training Prec@1 13.477 (1.321)	Training Prec@5 21.875 (2.704)	
2022-03-31 11:27:20,063: ============================================================
2022-03-31 11:28:05,239: time cost, forward:0.1486854602086933, backward:0.037059346932547074, data cost:0.2543333404708014 
2022-03-31 11:28:05,240: ============================================================
2022-03-31 11:28:05,240: Epoch 3/31 Batch 6100/7662 eta: 1 day, 3:07:09.571969	Training Loss 0.7314 (0.8143)	Training Prec@1 14.453 (1.414)	Training Prec@5 22.852 (2.862)	
2022-03-31 11:28:05,241: ============================================================
2022-03-31 11:28:50,444: time cost, forward:0.14885498473943867, backward:0.03714523428504477, data cost:0.25426525738108907 
2022-03-31 11:28:50,444: ============================================================
2022-03-31 11:28:50,444: Epoch 3/31 Batch 6200/7662 eta: 1 day, 3:07:20.298158	Training Loss 0.7359 (0.8130)	Training Prec@1 12.891 (1.612)	Training Prec@5 19.141 (3.180)	
2022-03-31 11:28:50,444: ============================================================
2022-03-31 11:29:33,853: time cost, forward:0.14908419220877897, backward:0.037141727443573344, data cost:0.2539226447122213 
2022-03-31 11:29:33,854: ============================================================
2022-03-31 11:29:33,854: Epoch 3/31 Batch 6300/7662 eta: 1 day, 2:02:01.670123	Training Loss 0.7204 (0.8116)	Training Prec@1 17.188 (1.841)	Training Prec@5 29.688 (3.533)	
2022-03-31 11:29:33,854: ============================================================
2022-03-31 11:30:14,755: time cost, forward:0.14883316060605878, backward:0.037112506372255355, data cost:0.2536990582933648 
2022-03-31 11:30:14,756: ============================================================
2022-03-31 11:30:14,756: Epoch 3/31 Batch 6400/7662 eta: 1 day, 0:31:06.057481	Training Loss 0.7219 (0.8101)	Training Prec@1 16.992 (2.089)	Training Prec@5 25.586 (3.903)	
2022-03-31 11:30:14,756: ============================================================
2022-03-31 11:30:58,931: time cost, forward:0.14856405118040386, backward:0.037073045349942844, data cost:0.2540401048817292 
2022-03-31 11:30:58,931: ============================================================
2022-03-31 11:30:58,931: Epoch 3/31 Batch 6500/7662 eta: 1 day, 2:28:05.770605	Training Loss 0.7078 (0.8086)	Training Prec@1 22.852 (2.350)	Training Prec@5 31.055 (4.293)	
2022-03-31 11:30:58,932: ============================================================
2022-03-31 11:31:41,576: time cost, forward:0.14834522135168482, backward:0.037035749109970255, data cost:0.2540898624379123 
2022-03-31 11:31:41,576: ============================================================
2022-03-31 11:31:41,576: Epoch 3/31 Batch 6600/7662 eta: 1 day, 1:32:21.666630	Training Loss 0.7070 (0.8071)	Training Prec@1 20.508 (2.623)	Training Prec@5 33.008 (4.694)	
2022-03-31 11:31:41,576: ============================================================
2022-03-31 11:32:25,641: time cost, forward:0.1485116982890663, backward:0.03703488732722468, data cost:0.2539333619543253 
2022-03-31 11:32:25,642: ============================================================
2022-03-31 11:32:25,643: Epoch 3/31 Batch 6700/7662 eta: 1 day, 2:22:42.842062	Training Loss 0.7078 (0.8056)	Training Prec@1 21.289 (2.906)	Training Prec@5 32.031 (5.104)	
2022-03-31 11:32:25,643: ============================================================
2022-03-31 11:33:09,035: time cost, forward:0.1482480790513739, backward:0.036994239445520966, data cost:0.2541417540092822 
2022-03-31 11:33:09,035: ============================================================
2022-03-31 11:33:09,035: Epoch 3/31 Batch 6800/7662 eta: 1 day, 1:57:47.015533	Training Loss 0.7232 (0.8041)	Training Prec@1 24.805 (3.194)	Training Prec@5 35.742 (5.516)	
2022-03-31 11:33:09,035: ============================================================
2022-03-31 11:33:50,651: time cost, forward:0.1479312956099891, backward:0.03699737788110665, data cost:0.25409616278745 
2022-03-31 11:33:50,651: ============================================================
2022-03-31 11:33:50,651: Epoch 3/31 Batch 6900/7662 eta: 1 day, 0:53:18.652045	Training Loss 0.8449 (0.8048)	Training Prec@1 0.000 (3.153)	Training Prec@5 0.000 (5.444)	
2022-03-31 11:33:50,652: ============================================================
2022-03-31 11:34:33,546: time cost, forward:0.14784718850865194, backward:0.036965372358361115, data cost:0.25408067126191675 
2022-03-31 11:34:33,547: ============================================================
2022-03-31 11:34:33,547: Epoch 3/31 Batch 7000/7662 eta: 1 day, 1:38:31.155363	Training Loss 0.8396 (0.8054)	Training Prec@1 0.000 (3.108)	Training Prec@5 0.195 (5.366)	
2022-03-31 11:34:33,547: ============================================================
2022-03-31 11:35:16,147: time cost, forward:0.14774890919271733, backward:0.036912862340032694, data cost:0.2540288843694145 
2022-03-31 11:35:16,147: ============================================================
2022-03-31 11:35:16,148: Epoch 3/31 Batch 7100/7662 eta: 1 day, 1:27:13.858974	Training Loss 0.8387 (0.8058)	Training Prec@1 0.000 (3.066)	Training Prec@5 0.000 (5.297)	
2022-03-31 11:35:16,148: ============================================================
2022-03-31 11:36:00,131: time cost, forward:0.1478531968678049, backward:0.03691609416807471, data cost:0.253932226133075 
2022-03-31 11:36:00,141: ============================================================
2022-03-31 11:36:00,142: Epoch 3/31 Batch 7200/7662 eta: 1 day, 2:16:26.215035	Training Loss 0.8346 (0.8066)	Training Prec@1 0.000 (3.031)	Training Prec@5 0.000 (5.241)	
2022-03-31 11:36:00,142: ============================================================
2022-03-31 11:36:39,801: time cost, forward:0.14778248204451944, backward:0.036937194191310356, data cost:0.25340557562225335 
2022-03-31 11:36:39,801: ============================================================
2022-03-31 11:36:39,801: Epoch 3/31 Batch 7300/7662 eta: 23:40:28.328753	Training Loss 0.8346 (0.8070)	Training Prec@1 0.000 (2.989)	Training Prec@5 0.000 (5.169)	
2022-03-31 11:36:39,801: ============================================================
2022-03-31 11:37:21,017: time cost, forward:0.1478418987141153, backward:0.036913275122561956, data cost:0.2530001285092575 
2022-03-31 11:37:21,025: ============================================================
2022-03-31 11:37:21,025: Epoch 3/31 Batch 7400/7662 eta: 1 day, 0:35:48.656747	Training Loss 0.8346 (0.8073)	Training Prec@1 0.000 (2.949)	Training Prec@5 0.000 (5.099)	
2022-03-31 11:37:21,025: ============================================================
2022-03-31 11:38:02,986: time cost, forward:0.14805674587890202, backward:0.036897466602063465, data cost:0.2525509922547982 
2022-03-31 11:38:02,987: ============================================================
2022-03-31 11:38:02,987: Epoch 3/31 Batch 7500/7662 eta: 1 day, 1:01:32.556709	Training Loss 0.8346 (0.8077)	Training Prec@1 0.000 (2.909)	Training Prec@5 0.000 (5.031)	
2022-03-31 11:38:02,988: ============================================================
2022-03-31 11:38:46,197: time cost, forward:0.14830315738998756, backward:0.03689619176779033, data cost:0.2522307294719328 
2022-03-31 11:38:46,198: ============================================================
2022-03-31 11:38:46,198: Epoch 3/31 Batch 7600/7662 eta: 1 day, 1:45:29.461044	Training Loss 0.8346 (0.8081)	Training Prec@1 0.000 (2.871)	Training Prec@5 0.000 (4.965)	
2022-03-31 11:38:46,198: ============================================================
2022-03-31 11:39:13,992: Epoch: 3/31 eta: 1 day, 1:45:02.238382	Training Loss 0.8346 (0.8083)	Training Prec@1 0.000 (2.848)	Training Prec@5 0.000 (4.924)
2022-03-31 11:39:13,992: ============================================================
2022-03-31 11:39:55,976: time cost, forward:0.12265759044223362, backward:0.03352870363177675, data cost:0.2626676414952134 
2022-03-31 11:39:55,977: ============================================================
2022-03-31 11:39:55,978: Epoch 4/31 Batch 100/7662 eta: 1 day, 0:51:43.161228	Training Loss 0.8346 (0.8346)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.004)	
2022-03-31 11:39:55,978: ============================================================
2022-03-31 11:40:35,301: time cost, forward:0.12603209485959768, backward:0.03591430366937839, data cost:0.24387666448276846 
2022-03-31 11:40:35,302: ============================================================
2022-03-31 11:40:35,302: Epoch 4/31 Batch 200/7662 eta: 23:24:46.596542	Training Loss 0.8346 (0.8346)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 11:40:35,302: ============================================================
2022-03-31 11:41:17,435: time cost, forward:0.13409332048932845, backward:0.03666381453191955, data cost:0.23996210018527947 
2022-03-31 11:41:17,436: ============================================================
2022-03-31 11:41:17,436: Epoch 4/31 Batch 300/7662 eta: 1 day, 1:04:26.085992	Training Loss 0.8346 (0.8346)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 11:41:17,436: ============================================================
2022-03-31 11:42:01,211: time cost, forward:0.14186430037171022, backward:0.037041882823284404, data cost:0.23848749461926913 
2022-03-31 11:42:01,211: ============================================================
2022-03-31 11:42:01,212: Epoch 4/31 Batch 400/7662 eta: 1 day, 2:02:20.489107	Training Loss 0.8346 (0.8346)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 11:42:01,212: ============================================================
2022-03-31 11:42:46,144: time cost, forward:0.14985848142054373, backward:0.03752533849590049, data cost:0.23612072424802608 
2022-03-31 11:42:46,145: ============================================================
2022-03-31 11:42:46,146: Epoch 4/31 Batch 500/7662 eta: 1 day, 2:42:54.777330	Training Loss 0.8346 (0.8346)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.002)	
2022-03-31 11:42:46,146: ============================================================
2022-03-31 11:43:28,824: time cost, forward:0.1523208733592089, backward:0.03779394877374869, data cost:0.23376551693389333 
2022-03-31 11:43:28,825: ============================================================
2022-03-31 11:43:28,825: Epoch 4/31 Batch 600/7662 eta: 1 day, 1:21:47.142162	Training Loss 0.8346 (0.8346)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 11:43:28,825: ============================================================
2022-03-31 11:44:09,299: time cost, forward:0.1524669083743989, backward:0.03796001565302902, data cost:0.2306786006441785 
2022-03-31 11:44:09,299: ============================================================
2022-03-31 11:44:09,299: Epoch 4/31 Batch 700/7662 eta: 1 day, 0:02:29.148503	Training Loss 0.8346 (0.8346)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 11:44:09,299: ============================================================
2022-03-31 11:44:51,423: time cost, forward:0.152016994204181, backward:0.03789454885060259, data cost:0.23114365898772085 
2022-03-31 11:44:51,424: ============================================================
2022-03-31 11:44:51,424: Epoch 4/31 Batch 800/7662 eta: 1 day, 1:00:36.094138	Training Loss 0.8346 (0.8346)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 11:44:51,424: ============================================================
2022-03-31 11:45:33,689: time cost, forward:0.15336259904507138, backward:0.03819642873176345, data cost:0.22961918636742104 
2022-03-31 11:45:33,689: ============================================================
2022-03-31 11:45:33,689: Epoch 4/31 Batch 900/7662 eta: 1 day, 1:04:54.093904	Training Loss 0.8346 (0.8346)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 11:45:33,689: ============================================================
2022-03-31 11:46:15,905: time cost, forward:0.1539056246225779, backward:0.037815752926770155, data cost:0.22940251156613156 
2022-03-31 11:46:15,906: ============================================================
2022-03-31 11:46:15,906: Epoch 4/31 Batch 1000/7662 eta: 1 day, 1:02:28.418922	Training Loss 0.8346 (0.8346)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 11:46:15,906: ============================================================
2022-03-31 11:46:57,333: time cost, forward:0.15446399145499481, backward:0.037769920073171655, data cost:0.2282435627174551 
2022-03-31 11:46:57,334: ============================================================
2022-03-31 11:46:57,334: Epoch 4/31 Batch 1100/7662 eta: 1 day, 0:33:43.190194	Training Loss 0.8346 (0.8346)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 11:46:57,334: ============================================================
2022-03-31 11:47:38,670: time cost, forward:0.1545925726982034, backward:0.037645396637459215, data cost:0.22759553091639376 
2022-03-31 11:47:38,671: ============================================================
2022-03-31 11:47:38,671: Epoch 4/31 Batch 1200/7662 eta: 1 day, 0:29:46.395235	Training Loss 0.8346 (0.8346)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 11:47:38,671: ============================================================
2022-03-31 11:48:19,910: time cost, forward:0.1534244239651487, backward:0.037589488715919925, data cost:0.2282043114545439 
2022-03-31 11:48:19,910: ============================================================
2022-03-31 11:48:19,910: Epoch 4/31 Batch 1300/7662 eta: 1 day, 0:25:37.948972	Training Loss 0.8346 (0.8346)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 11:48:19,910: ============================================================
2022-03-31 11:48:58,833: time cost, forward:0.1523233463799979, backward:0.037435395620481045, data cost:0.22731854661692033 
2022-03-31 11:48:58,834: ============================================================
2022-03-31 11:48:58,834: Epoch 4/31 Batch 1400/7662 eta: 23:02:40.888991	Training Loss 0.8346 (0.8346)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 11:48:58,834: ============================================================
2022-03-31 11:49:42,693: time cost, forward:0.15335572155576455, backward:0.037680437439198966, data cost:0.22739654417591465 
2022-03-31 11:49:42,703: ============================================================
2022-03-31 11:49:42,703: Epoch 4/31 Batch 1500/7662 eta: 1 day, 1:57:37.197885	Training Loss 0.8346 (0.8346)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 11:49:42,703: ============================================================
2022-03-31 11:50:24,309: time cost, forward:0.1535120645562435, backward:0.0377926595364607, data cost:0.22697484217411731 
2022-03-31 11:50:24,310: ============================================================
2022-03-31 11:50:24,310: Epoch 4/31 Batch 1600/7662 eta: 1 day, 0:36:36.511003	Training Loss 0.8346 (0.8346)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 11:50:24,310: ============================================================
2022-03-31 11:51:08,323: time cost, forward:0.154333949580201, backward:0.037696921172880156, data cost:0.22745966335967963 
2022-03-31 11:51:08,334: ============================================================
2022-03-31 11:51:08,335: Epoch 4/31 Batch 1700/7662 eta: 1 day, 2:01:40.860224	Training Loss 0.8346 (0.8346)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 11:51:08,335: ============================================================
2022-03-31 11:51:48,266: time cost, forward:0.15385096161944659, backward:0.03759582802081784, data cost:0.22692418456276367 
2022-03-31 11:51:48,266: ============================================================
2022-03-31 11:51:48,267: Epoch 4/31 Batch 1800/7662 eta: 23:35:49.745590	Training Loss 0.8346 (0.8346)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 11:51:48,267: ============================================================
2022-03-31 11:52:31,435: time cost, forward:0.15432162207010358, backward:0.03762974344849147, data cost:0.2270338453701636 
2022-03-31 11:52:31,435: ============================================================
2022-03-31 11:52:31,436: Epoch 4/31 Batch 1900/7662 eta: 1 day, 1:29:53.696754	Training Loss 0.8346 (0.8346)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 11:52:31,438: ============================================================
2022-03-31 11:53:12,280: time cost, forward:0.15400947744456334, backward:0.037437532948755875, data cost:0.22701090416233202 
2022-03-31 11:53:12,280: ============================================================
2022-03-31 11:53:12,280: Epoch 4/31 Batch 2000/7662 eta: 1 day, 0:06:49.892996	Training Loss 0.8346 (0.8346)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 11:53:12,280: ============================================================
2022-03-31 11:53:51,122: time cost, forward:0.15342824330722904, backward:0.037238309586712606, data cost:0.22635009721553342 
2022-03-31 11:53:51,122: ============================================================
2022-03-31 11:53:51,122: Epoch 4/31 Batch 2100/7662 eta: 22:55:14.449325	Training Loss 0.8346 (0.8346)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 11:53:51,122: ============================================================
2022-03-31 11:54:31,209: time cost, forward:0.153188792181427, backward:0.03717135266316593, data cost:0.22591140639950005 
2022-03-31 11:54:31,210: ============================================================
2022-03-31 11:54:31,219: Epoch 4/31 Batch 2200/7662 eta: 23:39:00.129779	Training Loss 0.8346 (0.8346)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 11:54:31,219: ============================================================
2022-03-31 11:55:11,877: time cost, forward:0.15297502463358598, backward:0.037120770350286575, data cost:0.22568665591982875 
2022-03-31 11:55:11,877: ============================================================
2022-03-31 11:55:11,877: Epoch 4/31 Batch 2300/7662 eta: 23:58:11.780421	Training Loss 0.8346 (0.8346)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 11:55:11,877: ============================================================
2022-03-31 11:55:50,115: time cost, forward:0.15196761363444103, backward:0.037069656492124355, data cost:0.22536106862938368 
2022-03-31 11:55:50,116: ============================================================
2022-03-31 11:55:50,116: Epoch 4/31 Batch 2400/7662 eta: 22:31:59.041304	Training Loss 0.8346 (0.8346)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 11:55:50,116: ============================================================
2022-03-31 11:56:32,923: time cost, forward:0.15198128697584992, backward:0.03705114543604918, data cost:0.22588596595864907 
2022-03-31 11:56:32,924: ============================================================
2022-03-31 11:56:32,924: Epoch 4/31 Batch 2500/7662 eta: 1 day, 1:12:48.487231	Training Loss 0.8346 (0.8346)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 11:56:32,924: ============================================================
2022-03-31 11:57:11,997: time cost, forward:0.15107804933572191, backward:0.036994200020673045, data cost:0.2258635275452905 
2022-03-31 11:57:12,011: ============================================================
2022-03-31 11:57:12,012: Epoch 4/31 Batch 2600/7662 eta: 23:00:41.211605	Training Loss 0.8346 (0.8346)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 11:57:12,012: ============================================================
2022-03-31 11:57:50,837: time cost, forward:0.1504391291796079, backward:0.03690052050137882, data cost:0.22563034704589277 
2022-03-31 11:57:50,838: ============================================================
2022-03-31 11:57:50,839: Epoch 4/31 Batch 2700/7662 eta: 22:50:49.641678	Training Loss 0.8346 (0.8346)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 11:57:50,839: ============================================================
2022-03-31 11:58:31,947: time cost, forward:0.14996727588731248, backward:0.036884574133739086, data cost:0.22605763209125918 
2022-03-31 11:58:31,947: ============================================================
2022-03-31 11:58:31,947: Epoch 4/31 Batch 2800/7662 eta: 1 day, 0:10:42.294879	Training Loss 0.8391 (0.8346)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 11:58:31,947: ============================================================
2022-03-31 11:59:13,165: time cost, forward:0.14944079663269105, backward:0.03681913019254644, data cost:0.22660523745552266 
2022-03-31 11:59:13,166: ============================================================
2022-03-31 11:59:13,166: Epoch 4/31 Batch 2900/7662 eta: 1 day, 0:13:53.927637	Training Loss 0.8630 (0.8352)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.195 (0.003)	
2022-03-31 11:59:13,166: ============================================================
2022-03-31 11:59:55,162: time cost, forward:0.14901298751589376, backward:0.03678384118177128, data cost:0.22727902685256351 
2022-03-31 11:59:55,163: ============================================================
2022-03-31 11:59:55,163: Epoch 4/31 Batch 3000/7662 eta: 1 day, 0:40:39.001186	Training Loss 0.8878 (0.8366)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.004)	
2022-03-31 11:59:55,163: ============================================================
2022-03-31 12:00:38,019: time cost, forward:0.14840172775024826, backward:0.03680650393168131, data cost:0.22833760310157955 
2022-03-31 12:00:38,019: ============================================================
2022-03-31 12:00:38,020: Epoch 4/31 Batch 3100/7662 eta: 1 day, 1:10:15.128351	Training Loss 0.8888 (0.8383)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.004)	
2022-03-31 12:00:38,020: ============================================================
2022-03-31 12:01:22,497: time cost, forward:0.14854063917674584, backward:0.03680938405892222, data cost:0.22916146038695773 
2022-03-31 12:01:22,497: ============================================================
2022-03-31 12:01:22,497: Epoch 4/31 Batch 3200/7662 eta: 1 day, 2:06:37.924007	Training Loss 0.9076 (0.8399)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.004)	
2022-03-31 12:01:22,497: ============================================================
2022-03-31 12:02:06,521: time cost, forward:0.14819874276389278, backward:0.036783901479396724, data cost:0.2303058760713252 
2022-03-31 12:02:06,521: ============================================================
2022-03-31 12:02:06,521: Epoch 4/31 Batch 3300/7662 eta: 1 day, 1:49:54.719881	Training Loss 0.8849 (0.8413)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.004)	
2022-03-31 12:02:06,521: ============================================================
2022-03-31 12:02:49,553: time cost, forward:0.1480621070362393, backward:0.0367493650498689, data cost:0.23087319587040872 
2022-03-31 12:02:49,553: ============================================================
2022-03-31 12:02:49,553: Epoch 4/31 Batch 3400/7662 eta: 1 day, 1:14:16.479011	Training Loss 0.8844 (0.8426)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.004)	
2022-03-31 12:02:49,553: ============================================================
2022-03-31 12:03:33,894: time cost, forward:0.14766290161261458, backward:0.0366503966130608, data cost:0.2321344296160205 
2022-03-31 12:03:33,895: ============================================================
2022-03-31 12:03:33,895: Epoch 4/31 Batch 3500/7662 eta: 1 day, 1:59:37.275351	Training Loss 0.8776 (0.8437)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.004)	
2022-03-31 12:03:33,895: ============================================================
2022-03-31 12:04:15,700: time cost, forward:0.14723866288613596, backward:0.03655744208399207, data cost:0.2327019793353302 
2022-03-31 12:04:15,711: ============================================================
2022-03-31 12:04:15,712: Epoch 4/31 Batch 3600/7662 eta: 1 day, 0:30:08.354911	Training Loss 0.8743 (0.8447)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.004)	
2022-03-31 12:04:15,713: ============================================================
2022-03-31 12:05:00,319: time cost, forward:0.14766015333560842, backward:0.03655549087019088, data cost:0.23307450348121084 
2022-03-31 12:05:00,319: ============================================================
2022-03-31 12:05:00,319: Epoch 4/31 Batch 3700/7662 eta: 1 day, 2:07:28.614272	Training Loss 0.8770 (0.8456)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.004)	
2022-03-31 12:05:00,320: ============================================================
2022-03-31 12:05:43,324: time cost, forward:0.147354879703105, backward:0.03646433237321316, data cost:0.23378903020460626 
2022-03-31 12:05:43,324: ============================================================
2022-03-31 12:05:43,325: Epoch 4/31 Batch 3800/7662 eta: 1 day, 1:10:27.698309	Training Loss 0.8724 (0.8464)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.004)	
2022-03-31 12:05:43,325: ============================================================
2022-03-31 12:06:29,342: time cost, forward:0.14759313861478074, backward:0.036383225631029005, data cost:0.2347117493965284 
2022-03-31 12:06:29,343: ============================================================
2022-03-31 12:06:29,343: Epoch 4/31 Batch 3900/7662 eta: 1 day, 2:55:31.359282	Training Loss 0.8708 (0.8471)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.004)	
2022-03-31 12:06:29,343: ============================================================
2022-03-31 12:07:13,522: time cost, forward:0.1475960653881694, backward:0.03637731185583032, data cost:0.23527801749288335 
2022-03-31 12:07:13,522: ============================================================
2022-03-31 12:07:13,522: Epoch 4/31 Batch 4000/7662 eta: 1 day, 1:50:14.427041	Training Loss 0.8690 (0.8478)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.004)	
2022-03-31 12:07:13,523: ============================================================
2022-03-31 12:07:55,233: time cost, forward:0.14688319809758452, backward:0.03630898091292259, data cost:0.23599358644971732 
2022-03-31 12:07:55,234: ============================================================
2022-03-31 12:07:55,234: Epoch 4/31 Batch 4100/7662 eta: 1 day, 0:22:56.608723	Training Loss 0.8661 (0.8484)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.004)	
2022-03-31 12:07:55,234: ============================================================
2022-03-31 12:08:39,175: time cost, forward:0.14711901868459978, backward:0.03631703340885156, data cost:0.23622970922869369 
2022-03-31 12:08:39,176: ============================================================
2022-03-31 12:08:39,176: Epoch 4/31 Batch 4200/7662 eta: 1 day, 1:40:25.674553	Training Loss 0.8664 (0.8489)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.004)	
2022-03-31 12:08:39,176: ============================================================
2022-03-31 12:09:24,613: time cost, forward:0.14669343099174845, backward:0.03629434671643779, data cost:0.237437099821486 
2022-03-31 12:09:24,614: ============================================================
2022-03-31 12:09:24,614: Epoch 4/31 Batch 4300/7662 eta: 1 day, 2:32:08.327066	Training Loss 0.8676 (0.8493)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.005)	
2022-03-31 12:09:24,614: ============================================================
2022-03-31 12:10:08,994: time cost, forward:0.14670521894837812, backward:0.03626505812072407, data cost:0.23800523857225964 
2022-03-31 12:10:08,995: ============================================================
2022-03-31 12:10:08,995: Epoch 4/31 Batch 4400/7662 eta: 1 day, 1:54:20.284819	Training Loss 0.8675 (0.8498)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.005)	
2022-03-31 12:10:08,995: ============================================================
2022-03-31 12:10:52,974: time cost, forward:0.14672695766371815, backward:0.03627016560770083, data cost:0.2383802049979816 
2022-03-31 12:10:52,974: ============================================================
2022-03-31 12:10:52,975: Epoch 4/31 Batch 4500/7662 eta: 1 day, 1:39:33.831965	Training Loss 0.8662 (0.8501)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.005)	
2022-03-31 12:10:52,975: ============================================================
2022-03-31 12:11:34,890: time cost, forward:0.14640486325925267, backward:0.036297697480747716, data cost:0.23861162204746578 
2022-03-31 12:11:34,891: ============================================================
2022-03-31 12:11:34,891: Epoch 4/31 Batch 4600/7662 eta: 1 day, 0:26:38.070615	Training Loss 0.8640 (0.8505)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.005)	
2022-03-31 12:11:34,891: ============================================================
2022-03-31 12:12:19,028: time cost, forward:0.14635849815907695, backward:0.03630253623764321, data cost:0.2390722735787128 
2022-03-31 12:12:19,028: ============================================================
2022-03-31 12:12:19,028: Epoch 4/31 Batch 4700/7662 eta: 1 day, 1:43:36.223137	Training Loss 0.8622 (0.8508)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.005)	
2022-03-31 12:12:19,028: ============================================================
2022-03-31 12:13:02,520: time cost, forward:0.14648539340851283, backward:0.03630351334667425, data cost:0.23921595997898795 
2022-03-31 12:13:02,520: ============================================================
2022-03-31 12:13:02,520: Epoch 4/31 Batch 4800/7662 eta: 1 day, 1:20:18.817256	Training Loss 0.8641 (0.8511)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.005)	
2022-03-31 12:13:02,520: ============================================================
2022-03-31 12:13:45,888: time cost, forward:0.14690172684438424, backward:0.03633868278204409, data cost:0.23898683272714297 
2022-03-31 12:13:45,888: ============================================================
2022-03-31 12:13:45,888: Epoch 4/31 Batch 4900/7662 eta: 1 day, 1:15:15.327741	Training Loss 0.8626 (0.8514)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.005)	
2022-03-31 12:13:45,888: ============================================================
2022-03-31 12:14:28,042: time cost, forward:0.14646258891213057, backward:0.036314251471052265, data cost:0.23941978899854066 
2022-03-31 12:14:28,042: ============================================================
2022-03-31 12:14:28,043: Epoch 4/31 Batch 5000/7662 eta: 1 day, 0:32:09.037882	Training Loss 0.8622 (0.8517)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.005)	
2022-03-31 12:14:28,043: ============================================================
2022-03-31 12:15:11,490: time cost, forward:0.14642886204634445, backward:0.03630587474391329, data cost:0.23970237192534352 
2022-03-31 12:15:11,491: ============================================================
2022-03-31 12:15:11,491: Epoch 4/31 Batch 5100/7662 eta: 1 day, 1:16:36.745923	Training Loss 0.8645 (0.8520)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.005)	
2022-03-31 12:15:11,491: ============================================================
2022-03-31 12:15:55,332: time cost, forward:0.1464228372340891, backward:0.036289851466929327, data cost:0.24002309289430743 
2022-03-31 12:15:55,333: ============================================================
2022-03-31 12:15:55,333: Epoch 4/31 Batch 5200/7662 eta: 1 day, 1:29:37.507093	Training Loss 0.8624 (0.8522)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.005)	
2022-03-31 12:15:55,333: ============================================================
2022-03-31 12:16:36,504: time cost, forward:0.14631919812247265, backward:0.03628210828852757, data cost:0.2399101893077101 
2022-03-31 12:16:36,504: ============================================================
2022-03-31 12:16:36,504: Epoch 4/31 Batch 5300/7662 eta: 23:55:45.760959	Training Loss 0.8614 (0.8524)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.005)	
2022-03-31 12:16:36,504: ============================================================
2022-03-31 12:17:18,545: time cost, forward:0.14606773016474428, backward:0.03624397446698978, data cost:0.24015098193063186 
2022-03-31 12:17:18,545: ============================================================
2022-03-31 12:17:18,545: Epoch 4/31 Batch 5400/7662 eta: 1 day, 0:25:23.612037	Training Loss 0.8605 (0.8525)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.005)	
2022-03-31 12:17:18,546: ============================================================
2022-03-31 12:17:59,316: time cost, forward:0.14556023267685966, backward:0.03620373086292845, data cost:0.24042524439916976 
2022-03-31 12:17:59,316: ============================================================
2022-03-31 12:17:59,316: Epoch 4/31 Batch 5500/7662 eta: 23:40:26.110761	Training Loss 0.8613 (0.8527)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.005)	
2022-03-31 12:17:59,317: ============================================================
2022-03-31 12:18:41,073: time cost, forward:0.1454621342425475, backward:0.03618579282145731, data cost:0.2404341608695759 
2022-03-31 12:18:41,074: ============================================================
2022-03-31 12:18:41,074: Epoch 4/31 Batch 5600/7662 eta: 1 day, 0:14:07.780735	Training Loss 0.8577 (0.8529)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.005)	
2022-03-31 12:18:41,075: ============================================================
2022-03-31 12:19:22,534: time cost, forward:0.14515267361421547, backward:0.03621506000698858, data cost:0.24059541519534527 
2022-03-31 12:19:22,534: ============================================================
2022-03-31 12:19:22,534: Epoch 4/31 Batch 5700/7662 eta: 1 day, 0:03:04.087157	Training Loss 0.8593 (0.8530)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.005)	
2022-03-31 12:19:22,534: ============================================================
2022-03-31 12:20:04,506: time cost, forward:0.14487261808335852, backward:0.03620427915774084, data cost:0.2408386004507634 
2022-03-31 12:20:04,507: ============================================================
2022-03-31 12:20:04,507: Epoch 4/31 Batch 5800/7662 eta: 1 day, 0:20:12.331595	Training Loss 0.8616 (0.8532)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.005)	
2022-03-31 12:20:04,507: ============================================================
2022-03-31 12:20:48,166: time cost, forward:0.14481231878926984, backward:0.03620233392691204, data cost:0.24111458644520975 
2022-03-31 12:20:48,167: ============================================================
2022-03-31 12:20:48,167: Epoch 4/31 Batch 5900/7662 eta: 1 day, 1:18:10.767637	Training Loss 0.8616 (0.8533)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.005)	
2022-03-31 12:20:48,167: ============================================================
2022-03-31 12:21:29,662: time cost, forward:0.1446600348616783, backward:0.03618408139695086, data cost:0.24116866356890526 
2022-03-31 12:21:29,664: ============================================================
2022-03-31 12:21:29,665: Epoch 4/31 Batch 6000/7662 eta: 1 day, 0:02:18.914265	Training Loss 0.8625 (0.8534)	Training Prec@1 0.195 (0.001)	Training Prec@5 0.195 (0.006)	
2022-03-31 12:21:29,666: ============================================================
2022-03-31 12:22:11,860: time cost, forward:0.14460513857197108, backward:0.036182798426900656, data cost:0.24122136431573785 
2022-03-31 12:22:11,860: ============================================================
2022-03-31 12:22:11,861: Epoch 4/31 Batch 6100/7662 eta: 1 day, 0:25:51.029151	Training Loss 0.8587 (0.8535)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.006)	
2022-03-31 12:22:11,861: ============================================================
2022-03-31 12:22:53,877: time cost, forward:0.14472579006072608, backward:0.03615926761630274, data cost:0.2410804003856897 
2022-03-31 12:22:53,878: ============================================================
2022-03-31 12:22:53,878: Epoch 4/31 Batch 6200/7662 eta: 1 day, 0:18:58.132929	Training Loss 0.8607 (0.8537)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.006)	
2022-03-31 12:22:53,878: ============================================================
2022-03-31 12:23:35,139: time cost, forward:0.1444972539103245, backward:0.03621592872160581, data cost:0.24109777622250153 
2022-03-31 12:23:35,139: ============================================================
2022-03-31 12:23:35,139: Epoch 4/31 Batch 6300/7662 eta: 23:52:01.297930	Training Loss 0.8607 (0.8538)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.195 (0.006)	
2022-03-31 12:23:35,139: ============================================================
2022-03-31 12:24:16,645: time cost, forward:0.14423227783366468, backward:0.0362355268305215, data cost:0.24123281310323366 
2022-03-31 12:24:16,645: ============================================================
2022-03-31 12:24:16,645: Epoch 4/31 Batch 6400/7662 eta: 23:59:49.549742	Training Loss 0.8608 (0.8539)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.006)	
2022-03-31 12:24:16,646: ============================================================
2022-03-31 12:24:57,663: time cost, forward:0.14398579884353171, backward:0.03624247077575627, data cost:0.24128983926545622 
2022-03-31 12:24:57,663: ============================================================
2022-03-31 12:24:57,664: Epoch 4/31 Batch 6500/7662 eta: 23:42:12.757786	Training Loss 0.8561 (0.8539)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.006)	
2022-03-31 12:24:57,664: ============================================================
2022-03-31 12:25:39,624: time cost, forward:0.1437222485398502, backward:0.03620424681061018, data cost:0.24155070615873353 
2022-03-31 12:25:39,624: ============================================================
2022-03-31 12:25:39,624: Epoch 4/31 Batch 6600/7662 eta: 1 day, 0:14:11.496109	Training Loss 0.8580 (0.8540)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.006)	
2022-03-31 12:25:39,624: ============================================================
2022-03-31 12:26:24,284: time cost, forward:0.1439286804071094, backward:0.036209112246510945, data cost:0.24169368390841953 
2022-03-31 12:26:24,284: ============================================================
2022-03-31 12:26:24,284: Epoch 4/31 Batch 6700/7662 eta: 1 day, 1:47:00.579184	Training Loss 0.8574 (0.8541)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.006)	
2022-03-31 12:26:24,285: ============================================================
2022-03-31 12:27:05,194: time cost, forward:0.14382554156093988, backward:0.03618963130485803, data cost:0.24163219647857087 
2022-03-31 12:27:05,195: ============================================================
2022-03-31 12:27:05,195: Epoch 4/31 Batch 6800/7662 eta: 23:36:25.907209	Training Loss 0.8585 (0.8541)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.006)	
2022-03-31 12:27:05,195: ============================================================
2022-03-31 12:27:46,539: time cost, forward:0.14347633114239844, backward:0.03616825575966095, data cost:0.24186870059615928 
2022-03-31 12:27:46,539: ============================================================
2022-03-31 12:27:46,540: Epoch 4/31 Batch 6900/7662 eta: 23:50:47.070684	Training Loss 0.8565 (0.8542)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.006)	
2022-03-31 12:27:46,540: ============================================================
2022-03-31 12:28:29,936: time cost, forward:0.14348784115062746, backward:0.03614634662921948, data cost:0.24206334758714398 
2022-03-31 12:28:29,936: ============================================================
2022-03-31 12:28:29,937: Epoch 4/31 Batch 7000/7662 eta: 1 day, 1:01:05.127444	Training Loss 0.8549 (0.8542)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.007)	
2022-03-31 12:28:29,937: ============================================================
2022-03-31 12:29:14,750: time cost, forward:0.14335689233682378, backward:0.03611604746571224, data cost:0.24259206566580216 
2022-03-31 12:29:14,750: ============================================================
2022-03-31 12:29:14,751: Epoch 4/31 Batch 7100/7662 eta: 1 day, 1:49:20.575111	Training Loss 0.8543 (0.8543)	Training Prec@1 0.195 (0.001)	Training Prec@5 0.195 (0.007)	
2022-03-31 12:29:14,751: ============================================================
2022-03-31 12:29:56,868: time cost, forward:0.14338276713800888, backward:0.03611478475683811, data cost:0.24254439774280223 
2022-03-31 12:29:56,868: ============================================================
2022-03-31 12:29:56,869: Epoch 4/31 Batch 7200/7662 eta: 1 day, 0:15:26.213048	Training Loss 0.8618 (0.8543)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.007)	
2022-03-31 12:29:56,869: ============================================================
2022-03-31 12:30:39,043: time cost, forward:0.14323377504726356, backward:0.03607842017075904, data cost:0.24271240504184216 
2022-03-31 12:30:39,044: ============================================================
2022-03-31 12:30:39,044: Epoch 4/31 Batch 7300/7662 eta: 1 day, 0:16:43.083640	Training Loss 0.8563 (0.8543)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.007)	
2022-03-31 12:30:39,044: ============================================================
2022-03-31 12:31:23,077: time cost, forward:0.14322274058940426, backward:0.03606986612834742, data cost:0.24297324108552218 
2022-03-31 12:31:23,077: ============================================================
2022-03-31 12:31:23,078: Epoch 4/31 Batch 7400/7662 eta: 1 day, 1:20:09.815503	Training Loss 0.8532 (0.8543)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.195 (0.007)	
2022-03-31 12:31:23,078: ============================================================
2022-03-31 12:32:06,789: time cost, forward:0.1432391154096832, backward:0.036061819242881064, data cost:0.24316681936782653 
2022-03-31 12:32:06,789: ============================================================
2022-03-31 12:32:06,789: Epoch 4/31 Batch 7500/7662 eta: 1 day, 1:08:19.217512	Training Loss 0.8533 (0.8542)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 12:32:06,789: ============================================================
2022-03-31 12:32:51,056: time cost, forward:0.143412893799547, backward:0.03607159213716066, data cost:0.2432234017437015 
2022-03-31 12:32:51,057: ============================================================
2022-03-31 12:32:51,057: Epoch 4/31 Batch 7600/7662 eta: 1 day, 1:26:46.094353	Training Loss 0.8484 (0.8542)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.391 (0.008)	
2022-03-31 12:32:51,057: ============================================================
2022-03-31 12:33:19,449: Epoch: 4/31 eta: 1 day, 1:26:18.205749	Training Loss 0.8470 (0.8541)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)
2022-03-31 12:33:19,450: ============================================================
2022-03-31 12:34:03,203: time cost, forward:0.10987103828276047, backward:0.034769209948453034, data cost:0.2932495107554426 
2022-03-31 12:34:03,203: ============================================================
2022-03-31 12:34:03,204: Epoch 5/31 Batch 100/7662 eta: 1 day, 1:03:26.836085	Training Loss 0.8503 (0.8523)	Training Prec@1 0.000 (0.012)	Training Prec@5 0.000 (0.030)	
2022-03-31 12:34:03,204: ============================================================
2022-03-31 12:34:44,153: time cost, forward:0.1089639759542954, backward:0.03499407983904508, data cost:0.27926914296557553 
2022-03-31 12:34:44,153: ============================================================
2022-03-31 12:34:44,154: Epoch 5/31 Batch 200/7662 eta: 23:30:33.726481	Training Loss 0.8605 (0.8532)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.024)	
2022-03-31 12:34:44,154: ============================================================
2022-03-31 12:35:22,733: time cost, forward:0.10887283545274001, backward:0.03505459836494165, data cost:0.2668962749749123 
2022-03-31 12:35:22,734: ============================================================
2022-03-31 12:35:22,734: Epoch 5/31 Batch 300/7662 eta: 22:08:17.669613	Training Loss 0.8576 (0.8546)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.016)	
2022-03-31 12:35:22,735: ============================================================
2022-03-31 12:36:02,494: time cost, forward:0.10943272478299632, backward:0.034716449584578514, data cost:0.2632062913182385 
2022-03-31 12:36:02,495: ============================================================
2022-03-31 12:36:02,495: Epoch 5/31 Batch 400/7662 eta: 22:48:16.313887	Training Loss 0.8535 (0.8552)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.013)	
2022-03-31 12:36:02,495: ============================================================
2022-03-31 12:36:44,940: time cost, forward:0.10965226981826201, backward:0.034704617364612035, data cost:0.26637331660620434 
2022-03-31 12:36:44,941: ============================================================
2022-03-31 12:36:44,941: Epoch 5/31 Batch 500/7662 eta: 1 day, 0:19:57.537107	Training Loss 0.8559 (0.8553)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.013)	
2022-03-31 12:36:44,941: ============================================================
2022-03-31 12:37:24,024: time cost, forward:0.10970832748285717, backward:0.034521759650942084, data cost:0.2630588467013657 
2022-03-31 12:37:24,024: ============================================================
2022-03-31 12:37:24,025: Epoch 5/31 Batch 600/7662 eta: 22:23:40.435655	Training Loss 0.8552 (0.8553)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.013)	
2022-03-31 12:37:24,025: ============================================================
2022-03-31 12:38:03,591: time cost, forward:0.11110056043523917, backward:0.034659757122973006, data cost:0.25989321066074617 
2022-03-31 12:38:03,592: ============================================================
2022-03-31 12:38:03,592: Epoch 5/31 Batch 700/7662 eta: 22:39:37.826871	Training Loss 0.8575 (0.8551)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.013)	
2022-03-31 12:38:03,592: ============================================================
2022-03-31 12:38:44,490: time cost, forward:0.11095964505764958, backward:0.03460676499988618, data cost:0.2603887198714351 
2022-03-31 12:38:44,491: ============================================================
2022-03-31 12:38:44,491: Epoch 5/31 Batch 800/7662 eta: 23:24:42.116888	Training Loss 0.8568 (0.8548)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.195 (0.014)	
2022-03-31 12:38:44,491: ============================================================
2022-03-31 12:39:24,549: time cost, forward:0.11162319994874473, backward:0.03454956859847463, data cost:0.25913475591428287 
2022-03-31 12:39:24,550: ============================================================
2022-03-31 12:39:24,550: Epoch 5/31 Batch 900/7662 eta: 22:55:11.976586	Training Loss 0.8532 (0.8546)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.013)	
2022-03-31 12:39:24,550: ============================================================
2022-03-31 12:40:06,362: time cost, forward:0.1131154741491522, backward:0.03481488399677449, data cost:0.25853869220515985 
2022-03-31 12:40:06,363: ============================================================
2022-03-31 12:40:06,364: Epoch 5/31 Batch 1000/7662 eta: 23:54:43.981791	Training Loss 0.8508 (0.8544)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.014)	
2022-03-31 12:40:06,365: ============================================================
2022-03-31 12:40:49,519: time cost, forward:0.11553258262405187, backward:0.035089980265137495, data cost:0.2582081516186035 
2022-03-31 12:40:49,520: ============================================================
2022-03-31 12:40:49,520: Epoch 5/31 Batch 1100/7662 eta: 1 day, 0:40:04.747435	Training Loss 0.8526 (0.8541)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.195 (0.015)	
2022-03-31 12:40:49,520: ============================================================
2022-03-31 12:41:29,349: time cost, forward:0.11527486320731041, backward:0.03517191801794973, data cost:0.2574622537614506 
2022-03-31 12:41:29,350: ============================================================
2022-03-31 12:41:29,350: Epoch 5/31 Batch 1200/7662 eta: 22:45:19.737913	Training Loss 0.8533 (0.8539)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.016)	
2022-03-31 12:41:29,350: ============================================================
2022-03-31 12:42:17,570: time cost, forward:0.12006865215815427, backward:0.03568217385448429, data cost:0.2577860575625307 
2022-03-31 12:42:17,570: ============================================================
2022-03-31 12:42:17,571: Epoch 5/31 Batch 1300/7662 eta: 1 day, 3:32:09.873172	Training Loss 0.8507 (0.8536)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.017)	
2022-03-31 12:42:17,571: ============================================================
2022-03-31 12:42:58,405: time cost, forward:0.11975850609049275, backward:0.03562743498479749, data cost:0.2578152381496143 
2022-03-31 12:42:58,405: ============================================================
2022-03-31 12:42:58,405: Epoch 5/31 Batch 1400/7662 eta: 23:18:25.624229	Training Loss 0.8445 (0.8532)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.018)	
2022-03-31 12:42:58,406: ============================================================
2022-03-31 12:43:42,645: time cost, forward:0.1214197586980798, backward:0.03575723834479945, data cost:0.2578798504651905 
2022-03-31 12:43:42,646: ============================================================
2022-03-31 12:43:42,646: Epoch 5/31 Batch 1500/7662 eta: 1 day, 1:14:19.047764	Training Loss 0.8430 (0.8527)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.019)	
2022-03-31 12:43:42,647: ============================================================
2022-03-31 12:44:26,487: time cost, forward:0.12207526978736673, backward:0.035832413440200966, data cost:0.2586067811334931 
2022-03-31 12:44:26,487: ============================================================
2022-03-31 12:44:26,488: Epoch 5/31 Batch 1600/7662 eta: 1 day, 0:59:56.008722	Training Loss 0.8535 (0.8525)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.020)	
2022-03-31 12:44:26,488: ============================================================
2022-03-31 12:45:13,031: time cost, forward:0.12493311916820578, backward:0.03604440298972935, data cost:0.25801809273304976 
2022-03-31 12:45:13,032: ============================================================
2022-03-31 12:45:13,032: Epoch 5/31 Batch 1700/7662 eta: 1 day, 2:31:37.435964	Training Loss 0.8513 (0.8523)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.021)	
2022-03-31 12:45:13,032: ============================================================
2022-03-31 12:45:52,401: time cost, forward:0.12427991559069444, backward:0.03595863851724299, data cost:0.2577024525307893 
2022-03-31 12:45:52,401: ============================================================
2022-03-31 12:45:52,401: Epoch 5/31 Batch 1800/7662 eta: 22:25:36.100365	Training Loss 0.8486 (0.8520)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.023)	
2022-03-31 12:45:52,401: ============================================================
2022-03-31 12:46:36,857: time cost, forward:0.12596443064781537, backward:0.03607786109787719, data cost:0.2572622644455575 
2022-03-31 12:46:36,857: ============================================================
2022-03-31 12:46:36,858: Epoch 5/31 Batch 1900/7662 eta: 1 day, 1:18:44.102066	Training Loss 0.8516 (0.8516)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.024)	
2022-03-31 12:46:36,858: ============================================================
2022-03-31 12:47:20,398: time cost, forward:0.1261250124745753, backward:0.03603643032835387, data cost:0.25793583229698497 
2022-03-31 12:47:20,398: ============================================================
2022-03-31 12:47:20,398: Epoch 5/31 Batch 2000/7662 eta: 1 day, 0:46:44.638666	Training Loss 0.8414 (0.8514)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.026)	
2022-03-31 12:47:20,399: ============================================================
2022-03-31 12:48:06,162: time cost, forward:0.12757782677118412, backward:0.03614706718223103, data cost:0.2581117381477083 
2022-03-31 12:48:06,163: ============================================================
2022-03-31 12:48:06,163: Epoch 5/31 Batch 2100/7662 eta: 1 day, 2:01:54.235147	Training Loss 0.8418 (0.8511)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.391 (0.028)	
2022-03-31 12:48:06,163: ============================================================
2022-03-31 12:48:51,698: time cost, forward:0.12904143734594103, backward:0.03615597011068291, data cost:0.2581418293505812 
2022-03-31 12:48:51,699: ============================================================
2022-03-31 12:48:51,699: Epoch 5/31 Batch 2200/7662 eta: 1 day, 1:53:20.676272	Training Loss 0.8447 (0.8509)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.030)	
2022-03-31 12:48:51,699: ============================================================
2022-03-31 12:49:34,481: time cost, forward:0.12993220289461818, backward:0.03620035630716039, data cost:0.25738772261189397 
2022-03-31 12:49:34,481: ============================================================
2022-03-31 12:49:34,482: Epoch 5/31 Batch 2300/7662 eta: 1 day, 0:18:42.951061	Training Loss 0.8344 (0.8504)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.033)	
2022-03-31 12:49:34,482: ============================================================
2022-03-31 12:50:21,974: time cost, forward:0.13100341699082635, backward:0.03622772873516329, data cost:0.2583924849463682 
2022-03-31 12:50:21,974: ============================================================
2022-03-31 12:50:21,974: Epoch 5/31 Batch 2400/7662 eta: 1 day, 2:58:30.478176	Training Loss 0.8361 (0.8499)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.036)	
2022-03-31 12:50:21,974: ============================================================
2022-03-31 12:51:09,216: time cost, forward:0.13247982727713278, backward:0.036235524731285336, data cost:0.25879620608924725 
2022-03-31 12:51:09,217: ============================================================
2022-03-31 12:51:09,217: Epoch 5/31 Batch 2500/7662 eta: 1 day, 2:49:12.563126	Training Loss 0.8494 (0.8498)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.036)	
2022-03-31 12:51:09,217: ============================================================
2022-03-31 12:51:54,895: time cost, forward:0.13414660340412252, backward:0.03627127727759531, data cost:0.2581673250055258 
2022-03-31 12:51:54,895: ============================================================
2022-03-31 12:51:54,896: Epoch 5/31 Batch 2600/7662 eta: 1 day, 1:55:10.134655	Training Loss 0.8360 (0.8495)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.195 (0.037)	
2022-03-31 12:51:54,896: ============================================================
2022-03-31 12:52:42,168: time cost, forward:0.13630351096270216, backward:0.03634003296124577, data cost:0.25759084174349467 
2022-03-31 12:52:42,168: ============================================================
2022-03-31 12:52:42,168: Epoch 5/31 Batch 2700/7662 eta: 1 day, 2:48:38.544685	Training Loss 0.8353 (0.8491)	Training Prec@1 0.000 (0.009)	Training Prec@5 0.195 (0.041)	
2022-03-31 12:52:42,168: ============================================================
2022-03-31 12:53:29,659: time cost, forward:0.1384099080077918, backward:0.036338509641063346, data cost:0.25706336539998653 
2022-03-31 12:53:29,660: ============================================================
2022-03-31 12:53:29,660: Epoch 5/31 Batch 2800/7662 eta: 1 day, 2:55:18.389357	Training Loss 0.8352 (0.8487)	Training Prec@1 0.000 (0.010)	Training Prec@5 0.000 (0.043)	
2022-03-31 12:53:29,660: ============================================================
2022-03-31 12:54:12,100: time cost, forward:0.13857678612086968, backward:0.03628885889925106, data cost:0.2566537634180759 
2022-03-31 12:54:12,100: ============================================================
2022-03-31 12:54:12,100: Epoch 5/31 Batch 2900/7662 eta: 1 day, 0:02:48.094050	Training Loss 0.8292 (0.8482)	Training Prec@1 0.000 (0.011)	Training Prec@5 0.000 (0.047)	
2022-03-31 12:54:12,101: ============================================================
2022-03-31 12:54:56,518: time cost, forward:0.13860358838917375, backward:0.03627806824419887, data cost:0.25705803660958476 
2022-03-31 12:54:56,518: ============================================================
2022-03-31 12:54:56,518: Epoch 5/31 Batch 3000/7662 eta: 1 day, 1:09:17.048726	Training Loss 0.8275 (0.8476)	Training Prec@1 0.000 (0.012)	Training Prec@5 0.195 (0.051)	
2022-03-31 12:54:56,518: ============================================================
2022-03-31 12:55:42,228: time cost, forward:0.13943707085148138, backward:0.036306479855020724, data cost:0.25699469965478994 
2022-03-31 12:55:42,229: ============================================================
2022-03-31 12:55:42,229: Epoch 5/31 Batch 3100/7662 eta: 1 day, 1:52:26.562148	Training Loss 0.8572 (0.8471)	Training Prec@1 0.000 (0.013)	Training Prec@5 0.000 (0.056)	
2022-03-31 12:55:42,229: ============================================================
2022-03-31 12:56:30,748: time cost, forward:0.14103251809289807, backward:0.03632912884730404, data cost:0.2570134411382839 
2022-03-31 12:56:30,749: ============================================================
2022-03-31 12:56:30,749: Epoch 5/31 Batch 3200/7662 eta: 1 day, 3:27:03.696565	Training Loss 0.8564 (0.8473)	Training Prec@1 0.000 (0.013)	Training Prec@5 0.000 (0.055)	
2022-03-31 12:56:30,749: ============================================================
2022-03-31 12:57:17,268: time cost, forward:0.14206054471557378, backward:0.03635313395985548, data cost:0.25685868735890127 
2022-03-31 12:57:17,269: ============================================================
2022-03-31 12:57:17,269: Epoch 5/31 Batch 3300/7662 eta: 1 day, 2:18:22.587128	Training Loss 0.8479 (0.8474)	Training Prec@1 0.000 (0.013)	Training Prec@5 0.000 (0.055)	
2022-03-31 12:57:17,269: ============================================================
2022-03-31 12:58:02,872: time cost, forward:0.1426340033286247, backward:0.03637208788491025, data cost:0.2568666087630638 
2022-03-31 12:58:02,873: ============================================================
2022-03-31 12:58:02,873: Epoch 5/31 Batch 3400/7662 eta: 1 day, 1:46:32.752285	Training Loss 0.8398 (0.8474)	Training Prec@1 0.000 (0.013)	Training Prec@5 0.195 (0.055)	
2022-03-31 12:58:02,873: ============================================================
2022-03-31 12:58:49,562: time cost, forward:0.14364363589127357, backward:0.0364148813031271, data cost:0.25669806935031536 
2022-03-31 12:58:49,562: ============================================================
2022-03-31 12:58:49,563: Epoch 5/31 Batch 3500/7662 eta: 1 day, 2:22:35.212059	Training Loss 0.8446 (0.8472)	Training Prec@1 0.195 (0.014)	Training Prec@5 0.195 (0.057)	
2022-03-31 12:58:49,563: ============================================================
2022-03-31 12:59:32,880: time cost, forward:0.14387979690284655, backward:0.036396311004481804, data cost:0.2563792811926619 
2022-03-31 12:59:32,880: ============================================================
2022-03-31 12:59:32,881: Epoch 5/31 Batch 3600/7662 eta: 1 day, 0:27:34.691314	Training Loss 0.8346 (0.8468)	Training Prec@1 0.000 (0.014)	Training Prec@5 0.000 (0.059)	
2022-03-31 12:59:32,881: ============================================================
2022-03-31 13:00:19,165: time cost, forward:0.1444492319462331, backward:0.0363753291199935, data cost:0.25650295762636754 
2022-03-31 13:00:19,166: ============================================================
2022-03-31 13:00:19,166: Epoch 5/31 Batch 3700/7662 eta: 1 day, 2:07:20.230969	Training Loss 0.8264 (0.8463)	Training Prec@1 0.000 (0.016)	Training Prec@5 0.000 (0.065)	
2022-03-31 13:00:19,166: ============================================================
2022-03-31 13:01:05,682: time cost, forward:0.1453874082934326, backward:0.0364367046240726, data cost:0.256241085278922 
2022-03-31 13:01:05,682: ============================================================
2022-03-31 13:01:05,683: Epoch 5/31 Batch 3800/7662 eta: 1 day, 2:14:23.832160	Training Loss 0.8212 (0.8457)	Training Prec@1 0.195 (0.018)	Training Prec@5 0.195 (0.071)	
2022-03-31 13:01:05,683: ============================================================
2022-03-31 13:01:50,447: time cost, forward:0.14568295659820799, backward:0.03642022093004617, data cost:0.25618737090639837 
2022-03-31 13:01:50,447: ============================================================
2022-03-31 13:01:50,448: Epoch 5/31 Batch 3900/7662 eta: 1 day, 1:14:21.572166	Training Loss 0.8203 (0.8451)	Training Prec@1 0.195 (0.020)	Training Prec@5 0.586 (0.079)	
2022-03-31 13:01:50,448: ============================================================
2022-03-31 13:02:36,114: time cost, forward:0.14631477496897646, backward:0.0363910271543716, data cost:0.25604461341775875 
2022-03-31 13:02:36,114: ============================================================
2022-03-31 13:02:36,114: Epoch 5/31 Batch 4000/7662 eta: 1 day, 1:44:06.557789	Training Loss 0.8203 (0.8445)	Training Prec@1 0.000 (0.022)	Training Prec@5 0.391 (0.088)	
2022-03-31 13:02:36,115: ============================================================
2022-03-31 13:03:21,328: time cost, forward:0.14665073271232804, backward:0.036396211227227145, data cost:0.2560052778058356 
2022-03-31 13:03:21,329: ============================================================
2022-03-31 13:03:21,329: Epoch 5/31 Batch 4100/7662 eta: 1 day, 1:28:04.177026	Training Loss 0.8228 (0.8438)	Training Prec@1 0.000 (0.026)	Training Prec@5 0.586 (0.101)	
2022-03-31 13:03:21,329: ============================================================
2022-03-31 13:04:05,550: time cost, forward:0.14698993623128928, backward:0.03639747245336152, data cost:0.25574896306644085 
2022-03-31 13:04:05,551: ============================================================
2022-03-31 13:04:05,551: Epoch 5/31 Batch 4200/7662 eta: 1 day, 0:53:46.422674	Training Loss 0.8022 (0.8430)	Training Prec@1 0.586 (0.031)	Training Prec@5 2.148 (0.116)	
2022-03-31 13:04:05,551: ============================================================
2022-03-31 13:04:49,821: time cost, forward:0.14720807987247742, backward:0.0363906894514355, data cost:0.25560581287580136 
2022-03-31 13:04:49,821: ============================================================
2022-03-31 13:04:49,821: Epoch 5/31 Batch 4300/7662 eta: 1 day, 0:54:40.836791	Training Loss 0.8022 (0.8422)	Training Prec@1 0.000 (0.038)	Training Prec@5 0.586 (0.138)	
2022-03-31 13:04:49,821: ============================================================
2022-03-31 13:05:34,873: time cost, forward:0.14773627388718508, backward:0.03633046703030776, data cost:0.25538227828585797 
2022-03-31 13:05:34,874: ============================================================
2022-03-31 13:05:34,874: Epoch 5/31 Batch 4400/7662 eta: 1 day, 1:20:20.521995	Training Loss 0.7988 (0.8412)	Training Prec@1 0.000 (0.048)	Training Prec@5 0.781 (0.166)	
2022-03-31 13:05:34,874: ============================================================
2022-03-31 13:06:21,611: time cost, forward:0.14829858665228896, backward:0.03627251974607367, data cost:0.2554924891349553 
2022-03-31 13:06:21,611: ============================================================
2022-03-31 13:06:21,611: Epoch 5/31 Batch 4500/7662 eta: 1 day, 2:16:24.709141	Training Loss 0.7957 (0.8403)	Training Prec@1 1.172 (0.060)	Training Prec@5 2.734 (0.202)	
2022-03-31 13:06:21,612: ============================================================
2022-03-31 13:07:04,075: time cost, forward:0.14815039478143574, backward:0.03622723320407125, data cost:0.2553266981783886 
2022-03-31 13:07:04,076: ============================================================
2022-03-31 13:07:04,076: Epoch 5/31 Batch 4600/7662 eta: 23:51:35.357114	Training Loss 0.7951 (0.8394)	Training Prec@1 0.586 (0.073)	Training Prec@5 1.172 (0.237)	
2022-03-31 13:07:04,076: ============================================================
2022-03-31 13:07:48,056: time cost, forward:0.1479329341369681, backward:0.03617995960911834, data cost:0.2555920140087211 
2022-03-31 13:07:48,057: ============================================================
2022-03-31 13:07:48,057: Epoch 5/31 Batch 4700/7662 eta: 1 day, 0:41:57.853485	Training Loss 0.7873 (0.8384)	Training Prec@1 1.172 (0.093)	Training Prec@5 3.516 (0.287)	
2022-03-31 13:07:48,057: ============================================================
2022-03-31 13:08:35,767: time cost, forward:0.1484923964367481, backward:0.036200645044958325, data cost:0.25573601874740803 
2022-03-31 13:08:35,768: ============================================================
2022-03-31 13:08:35,768: Epoch 5/31 Batch 4800/7662 eta: 1 day, 2:46:53.277500	Training Loss 0.7908 (0.8375)	Training Prec@1 0.586 (0.110)	Training Prec@5 1.758 (0.332)	
2022-03-31 13:08:35,769: ============================================================
2022-03-31 13:09:17,308: time cost, forward:0.14817796913695155, backward:0.03608549685107369, data cost:0.2557067452072732 
2022-03-31 13:09:17,309: ============================================================
2022-03-31 13:09:17,309: Epoch 5/31 Batch 4900/7662 eta: 23:18:21.505143	Training Loss 0.7837 (0.8365)	Training Prec@1 1.953 (0.132)	Training Prec@5 4.883 (0.392)	
2022-03-31 13:09:17,309: ============================================================
2022-03-31 13:10:03,984: time cost, forward:0.14853158782162315, backward:0.03608527043314547, data cost:0.2558756012944227 
2022-03-31 13:10:03,985: ============================================================
2022-03-31 13:10:03,985: Epoch 5/31 Batch 5000/7662 eta: 1 day, 2:10:27.354766	Training Loss 0.7766 (0.8354)	Training Prec@1 1.953 (0.169)	Training Prec@5 4.492 (0.483)	
2022-03-31 13:10:03,985: ============================================================
2022-03-31 13:10:49,119: time cost, forward:0.14848711210551227, backward:0.03603974696023017, data cost:0.2561563857281107 
2022-03-31 13:10:49,119: ============================================================
2022-03-31 13:10:49,119: Epoch 5/31 Batch 5100/7662 eta: 1 day, 1:17:49.558222	Training Loss 0.7653 (0.8341)	Training Prec@1 4.492 (0.225)	Training Prec@5 8.203 (0.615)	
2022-03-31 13:10:49,119: ============================================================
2022-03-31 13:11:35,623: time cost, forward:0.14900929988817793, backward:0.036045161960995824, data cost:0.2560934785192438 
2022-03-31 13:11:35,623: ============================================================
2022-03-31 13:11:35,624: Epoch 5/31 Batch 5200/7662 eta: 1 day, 2:03:07.839607	Training Loss 0.7598 (0.8328)	Training Prec@1 6.055 (0.306)	Training Prec@5 12.305 (0.786)	
2022-03-31 13:11:35,624: ============================================================
2022-03-31 13:12:20,063: time cost, forward:0.1491032386865452, backward:0.03599249652971252, data cost:0.2560992123023769 
2022-03-31 13:12:20,063: ============================================================
2022-03-31 13:12:20,063: Epoch 5/31 Batch 5300/7662 eta: 1 day, 0:52:59.291408	Training Loss 0.7459 (0.8314)	Training Prec@1 10.156 (0.420)	Training Prec@5 17.578 (1.010)	
2022-03-31 13:12:20,063: ============================================================
2022-03-31 13:13:06,382: time cost, forward:0.14924044307900217, backward:0.03598661408598367, data cost:0.25637315061053073 
2022-03-31 13:13:06,383: ============================================================
2022-03-31 13:13:06,383: Epoch 5/31 Batch 5400/7662 eta: 1 day, 1:55:22.290381	Training Loss 0.7396 (0.8298)	Training Prec@1 11.133 (0.571)	Training Prec@5 19.922 (1.285)	
2022-03-31 13:13:06,383: ============================================================
2022-03-31 13:13:53,191: time cost, forward:0.14956052360978642, backward:0.036031168056501216, data cost:0.25647976728412625 
2022-03-31 13:13:53,192: ============================================================
2022-03-31 13:13:53,192: Epoch 5/31 Batch 5500/7662 eta: 1 day, 2:11:01.854236	Training Loss 0.7310 (0.8282)	Training Prec@1 10.547 (0.750)	Training Prec@5 20.898 (1.600)	
2022-03-31 13:13:53,192: ============================================================
2022-03-31 13:14:36,299: time cost, forward:0.1494653568584635, backward:0.036025576643442164, data cost:0.25637966501944875 
2022-03-31 13:14:36,300: ============================================================
2022-03-31 13:14:36,300: Epoch 5/31 Batch 5600/7662 eta: 1 day, 0:06:05.944279	Training Loss 0.7308 (0.8265)	Training Prec@1 13.477 (0.966)	Training Prec@5 22.852 (1.958)	
2022-03-31 13:14:36,300: ============================================================
2022-03-31 13:15:21,259: time cost, forward:0.14961961504241253, backward:0.03603055511028814, data cost:0.25632669035019134 
2022-03-31 13:15:21,259: ============================================================
2022-03-31 13:15:21,260: Epoch 5/31 Batch 5700/7662 eta: 1 day, 1:07:26.911188	Training Loss 0.7398 (0.8252)	Training Prec@1 12.695 (1.126)	Training Prec@5 19.727 (2.231)	
2022-03-31 13:15:21,260: ============================================================
2022-03-31 13:16:08,099: time cost, forward:0.1501609379925755, backward:0.03604534873265113, data cost:0.2562480998627172 
2022-03-31 13:16:08,100: ============================================================
2022-03-31 13:16:08,100: Epoch 5/31 Batch 5800/7662 eta: 1 day, 2:09:45.135818	Training Loss 0.7259 (0.8235)	Training Prec@1 16.406 (1.355)	Training Prec@5 26.172 (2.598)	
2022-03-31 13:16:08,101: ============================================================
2022-03-31 13:16:53,039: time cost, forward:0.150431938991039, backward:0.03602012849941276, data cost:0.25610423407366284 
2022-03-31 13:16:53,039: ============================================================
2022-03-31 13:16:53,040: Epoch 5/31 Batch 5900/7662 eta: 1 day, 1:05:16.956190	Training Loss 0.7170 (0.8218)	Training Prec@1 16.992 (1.624)	Training Prec@5 30.078 (3.017)	
2022-03-31 13:16:53,040: ============================================================
2022-03-31 13:17:35,644: time cost, forward:0.15031471123673912, backward:0.03598608122525324, data cost:0.25597231947276805 
2022-03-31 13:17:35,645: ============================================================
2022-03-31 13:17:35,645: Epoch 5/31 Batch 6000/7662 eta: 23:46:23.081621	Training Loss 0.7165 (0.8200)	Training Prec@1 18.164 (1.909)	Training Prec@5 27.344 (3.450)	
2022-03-31 13:17:35,645: ============================================================
2022-03-31 13:18:20,997: time cost, forward:0.1505036811825486, backward:0.0359818149656717, data cost:0.2559750223574159 
2022-03-31 13:18:20,998: ============================================================
2022-03-31 13:18:20,998: Epoch 5/31 Batch 6100/7662 eta: 1 day, 1:17:37.558839	Training Loss 0.7993 (0.8187)	Training Prec@1 0.586 (2.116)	Training Prec@5 1.758 (3.763)	
2022-03-31 13:18:20,998: ============================================================
2022-03-31 13:19:07,957: time cost, forward:0.15096242436671914, backward:0.03599463764516206, data cost:0.2559266232698074 
2022-03-31 13:19:07,958: ============================================================
2022-03-31 13:19:07,958: Epoch 5/31 Batch 6200/7662 eta: 1 day, 2:10:37.224563	Training Loss 0.7266 (0.8176)	Training Prec@1 14.453 (2.252)	Training Prec@5 25.000 (3.987)	
2022-03-31 13:19:07,958: ============================================================
2022-03-31 13:19:55,715: time cost, forward:0.15138378819315598, backward:0.036006205837808725, data cost:0.2560337603442308 
2022-03-31 13:19:55,716: ============================================================
2022-03-31 13:19:55,716: Epoch 5/31 Batch 6300/7662 eta: 1 day, 2:36:30.578645	Training Loss 0.7060 (0.8159)	Training Prec@1 21.875 (2.538)	Training Prec@5 31.836 (4.411)	
2022-03-31 13:19:55,716: ============================================================
2022-03-31 13:20:43,213: time cost, forward:0.15184025958955874, backward:0.036009786762023537, data cost:0.25602140112172106 
2022-03-31 13:20:43,214: ============================================================
2022-03-31 13:20:43,214: Epoch 5/31 Batch 6400/7662 eta: 1 day, 2:27:01.518763	Training Loss 0.7006 (0.8141)	Training Prec@1 23.047 (2.844)	Training Prec@5 33.789 (4.856)	
2022-03-31 13:20:43,214: ============================================================
2022-03-31 13:21:26,277: time cost, forward:0.1518485739444252, backward:0.035995596866457986, data cost:0.2558552467157188 
2022-03-31 13:21:26,277: ============================================================
2022-03-31 13:21:26,278: Epoch 5/31 Batch 6500/7662 eta: 23:58:08.732100	Training Loss 0.7107 (0.8127)	Training Prec@1 23.633 (3.083)	Training Prec@5 33.594 (5.209)	
2022-03-31 13:21:26,278: ============================================================
2022-03-31 13:22:12,845: time cost, forward:0.15239707562648486, backward:0.03601828169183201, data cost:0.2556108236854809 
2022-03-31 13:22:12,846: ============================================================
2022-03-31 13:22:12,846: Epoch 5/31 Batch 6600/7662 eta: 1 day, 1:54:25.044359	Training Loss 0.6920 (0.8110)	Training Prec@1 29.102 (3.397)	Training Prec@5 40.039 (5.655)	
2022-03-31 13:22:12,846: ============================================================
2022-03-31 13:22:59,271: time cost, forward:0.15272554512752812, backward:0.03600164900468097, data cost:0.25559578171095254 
2022-03-31 13:22:59,271: ============================================================
2022-03-31 13:22:59,272: Epoch 5/31 Batch 6700/7662 eta: 1 day, 1:48:52.394792	Training Loss 0.6972 (0.8093)	Training Prec@1 22.852 (3.732)	Training Prec@5 33.008 (6.117)	
2022-03-31 13:22:59,272: ============================================================
2022-03-31 13:23:41,986: time cost, forward:0.15245866698365929, backward:0.035970530311471134, data cost:0.25563449662544213 
2022-03-31 13:23:41,986: ============================================================
2022-03-31 13:23:41,986: Epoch 5/31 Batch 6800/7662 eta: 23:44:21.154553	Training Loss 0.7272 (0.8078)	Training Prec@1 15.430 (4.017)	Training Prec@5 25.195 (6.517)	
2022-03-31 13:23:41,986: ============================================================
2022-03-31 13:24:29,016: time cost, forward:0.15283483348906707, backward:0.03597551951427048, data cost:0.2556207388756085 
2022-03-31 13:24:29,017: ============================================================
2022-03-31 13:24:29,017: Epoch 5/31 Batch 6900/7662 eta: 1 day, 2:07:29.939294	Training Loss 0.6896 (0.8061)	Training Prec@1 30.859 (4.347)	Training Prec@5 39.844 (6.970)	
2022-03-31 13:24:29,017: ============================================================
2022-03-31 13:25:15,541: time cost, forward:0.15321991695371895, backward:0.03598015300545254, data cost:0.25553467900842614 
2022-03-31 13:25:15,541: ============================================================
2022-03-31 13:25:15,541: Epoch 5/31 Batch 7000/7662 eta: 1 day, 1:49:50.106955	Training Loss 0.7484 (0.8044)	Training Prec@1 26.367 (4.692)	Training Prec@5 39.258 (7.439)	
2022-03-31 13:25:15,541: ============================================================
2022-03-31 13:25:58,750: time cost, forward:0.15333670591834497, backward:0.03598327437896664, data cost:0.2552231363317197 
2022-03-31 13:25:58,751: ============================================================
2022-03-31 13:25:58,751: Epoch 5/31 Batch 7100/7662 eta: 23:58:42.653738	Training Loss 0.8346 (0.8054)	Training Prec@1 0.000 (4.635)	Training Prec@5 0.000 (7.348)	
2022-03-31 13:25:58,751: ============================================================
2022-03-31 13:26:45,082: time cost, forward:0.15378786156717017, backward:0.03599211579810448, data cost:0.2550257536284972 
2022-03-31 13:26:45,082: ============================================================
2022-03-31 13:26:45,082: Epoch 5/31 Batch 7200/7662 eta: 1 day, 1:41:51.287323	Training Loss 0.8346 (0.8058)	Training Prec@1 0.000 (4.571)	Training Prec@5 0.000 (7.246)	
2022-03-31 13:26:45,082: ============================================================
2022-03-31 13:27:28,605: time cost, forward:0.15403988959446624, backward:0.0359918591028567, data cost:0.2546395336312617 
2022-03-31 13:27:28,606: ============================================================
2022-03-31 13:27:28,606: Epoch 5/31 Batch 7300/7662 eta: 1 day, 0:07:42.583674	Training Loss 0.8346 (0.8062)	Training Prec@1 0.000 (4.508)	Training Prec@5 0.000 (7.147)	
2022-03-31 13:27:28,606: ============================================================
2022-03-31 13:28:11,544: time cost, forward:0.15417251971657653, backward:0.03598050988031442, data cost:0.2543006426966791 
2022-03-31 13:28:11,545: ============================================================
2022-03-31 13:28:11,545: Epoch 5/31 Batch 7400/7662 eta: 23:47:33.067971	Training Loss 0.8346 (0.8066)	Training Prec@1 0.000 (4.447)	Training Prec@5 0.000 (7.050)	
2022-03-31 13:28:11,546: ============================================================
2022-03-31 13:28:56,810: time cost, forward:0.1543462246890894, backward:0.035973589521103626, data cost:0.2542367559192117 
2022-03-31 13:28:56,810: ============================================================
2022-03-31 13:28:56,811: Epoch 5/31 Batch 7500/7662 eta: 1 day, 1:04:08.326534	Training Loss 0.8346 (0.8070)	Training Prec@1 0.000 (4.388)	Training Prec@5 0.000 (6.956)	
2022-03-31 13:28:56,811: ============================================================
2022-03-31 13:29:40,988: time cost, forward:0.15454247970771814, backward:0.035966357803294526, data cost:0.25399798157184056 
2022-03-31 13:29:40,988: ============================================================
2022-03-31 13:29:40,988: Epoch 5/31 Batch 7600/7662 eta: 1 day, 0:27:14.821944	Training Loss 0.8350 (0.8073)	Training Prec@1 0.000 (4.330)	Training Prec@5 0.000 (6.865)	
2022-03-31 13:29:40,989: ============================================================
2022-03-31 13:30:09,395: Epoch: 5/31 eta: 1 day, 0:26:46.990084	Training Loss 0.8422 (0.8076)	Training Prec@1 0.000 (4.295)	Training Prec@5 0.000 (6.808)
2022-03-31 13:30:09,396: ============================================================
2022-03-31 13:30:09,470: Save Checkpoint...
2022-03-31 13:30:09,470: ============================================================
2022-03-31 13:30:17,603: Save done!
2022-03-31 13:30:17,603: ============================================================
2022-03-31 13:30:56,408: time cost, forward:0.12019968996144305, backward:0.03246889210710622, data cost:0.23515938990043872 
2022-03-31 13:30:56,409: ============================================================
2022-03-31 13:30:56,409: Epoch 6/31 Batch 100/7662 eta: 21:21:26.078841	Training Loss 0.8346 (0.9084)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.002)	
2022-03-31 13:30:56,409: ============================================================
2022-03-31 13:31:34,023: time cost, forward:0.12515741976062258, backward:0.03313785821349177, data cost:0.22319057718593271 
2022-03-31 13:31:34,024: ============================================================
2022-03-31 13:31:34,024: Epoch 6/31 Batch 200/7662 eta: 20:47:38.810193	Training Loss 0.8346 (0.8713)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.002)	
2022-03-31 13:31:34,024: ============================================================
2022-03-31 13:32:13,866: time cost, forward:0.13497111948836207, backward:0.03362926033428282, data cost:0.21829187431463032 
2022-03-31 13:32:13,881: ============================================================
2022-03-31 13:32:13,881: Epoch 6/31 Batch 300/7662 eta: 22:01:20.799213	Training Loss 0.8346 (0.8590)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.001)	
2022-03-31 13:32:13,881: ============================================================
2022-03-31 13:32:52,172: time cost, forward:0.13381979877787425, backward:0.034155765571689846, data cost:0.21804464371282056 
2022-03-31 13:32:52,172: ============================================================
2022-03-31 13:32:52,172: Epoch 6/31 Batch 400/7662 eta: 21:08:48.521316	Training Loss 0.8346 (0.8529)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.195 (0.002)	
2022-03-31 13:32:52,173: ============================================================
2022-03-31 13:33:32,973: time cost, forward:0.13805655343738013, backward:0.03489701064650664, data cost:0.217413568305587 
2022-03-31 13:33:32,974: ============================================================
2022-03-31 13:33:32,974: Epoch 6/31 Batch 500/7662 eta: 22:31:18.226919	Training Loss 0.8346 (0.8492)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 13:33:32,974: ============================================================
2022-03-31 13:34:17,758: time cost, forward:0.14756346306140117, backward:0.03547774650815731, data cost:0.21671483592318375 
2022-03-31 13:34:17,773: ============================================================
2022-03-31 13:34:17,773: Epoch 6/31 Batch 600/7662 eta: 1 day, 0:42:57.376153	Training Loss 0.8346 (0.8468)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 13:34:17,774: ============================================================
2022-03-31 13:34:57,688: time cost, forward:0.14851765298365865, backward:0.035514801868553325, data cost:0.21566046972643152 
2022-03-31 13:34:57,688: ============================================================
2022-03-31 13:34:57,689: Epoch 6/31 Batch 700/7662 eta: 22:00:37.162926	Training Loss 0.8346 (0.8450)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.002)	
2022-03-31 13:34:57,689: ============================================================
2022-03-31 13:35:43,068: time cost, forward:0.1523881489702399, backward:0.03578857307290852, data cost:0.21814023478607064 
2022-03-31 13:35:43,069: ============================================================
2022-03-31 13:35:43,069: Epoch 6/31 Batch 800/7662 eta: 1 day, 1:00:40.311603	Training Loss 0.8346 (0.8437)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 13:35:43,069: ============================================================
2022-03-31 13:36:21,936: time cost, forward:0.15147489223119548, backward:0.03581973708113521, data cost:0.21705690957813029 
2022-03-31 13:36:21,937: ============================================================
2022-03-31 13:36:21,937: Epoch 6/31 Batch 900/7662 eta: 21:24:40.430707	Training Loss 0.8346 (0.8427)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.002)	
2022-03-31 13:36:21,937: ============================================================
2022-03-31 13:37:01,287: time cost, forward:0.15104994998202548, backward:0.03587344864586572, data cost:0.21620421700768763 
2022-03-31 13:37:01,287: ============================================================
2022-03-31 13:37:01,288: Epoch 6/31 Batch 1000/7662 eta: 21:39:57.620582	Training Loss 0.8346 (0.8419)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.002)	
2022-03-31 13:37:01,288: ============================================================
2022-03-31 13:37:42,057: time cost, forward:0.15067785040045784, backward:0.03592138316438239, data cost:0.21691828060410476 
2022-03-31 13:37:42,071: ============================================================
2022-03-31 13:37:42,071: Epoch 6/31 Batch 1100/7662 eta: 22:26:37.189490	Training Loss 0.8346 (0.8412)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.002)	
2022-03-31 13:37:42,071: ============================================================
2022-03-31 13:38:22,052: time cost, forward:0.15084895936522114, backward:0.03587641191045079, data cost:0.2165052139132693 
2022-03-31 13:38:22,053: ============================================================
2022-03-31 13:38:22,053: Epoch 6/31 Batch 1200/7662 eta: 21:59:29.855306	Training Loss 0.8346 (0.8407)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.002)	
2022-03-31 13:38:22,053: ============================================================
2022-03-31 13:39:01,281: time cost, forward:0.15014381900578852, backward:0.035788083461911244, data cost:0.21643674089139567 
2022-03-31 13:39:01,282: ============================================================
2022-03-31 13:39:01,282: Epoch 6/31 Batch 1300/7662 eta: 21:33:58.805878	Training Loss 0.8346 (0.8402)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.002)	
2022-03-31 13:39:01,282: ============================================================
2022-03-31 13:39:42,393: time cost, forward:0.15057875072214755, backward:0.035780793517891894, data cost:0.2165984505836754 
2022-03-31 13:39:42,393: ============================================================
2022-03-31 13:39:42,394: Epoch 6/31 Batch 1400/7662 eta: 22:35:24.532008	Training Loss 0.8346 (0.8398)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.002)	
2022-03-31 13:39:42,394: ============================================================
2022-03-31 13:40:21,239: time cost, forward:0.1499184237232679, backward:0.03561140045155836, data cost:0.2162954328535715 
2022-03-31 13:40:21,239: ============================================================
2022-03-31 13:40:21,239: Epoch 6/31 Batch 1500/7662 eta: 21:20:03.143135	Training Loss 0.8346 (0.8395)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.002)	
2022-03-31 13:40:21,240: ============================================================
2022-03-31 13:41:03,147: time cost, forward:0.15048080179525808, backward:0.03563649494846289, data cost:0.2168680972945623 
2022-03-31 13:41:03,147: ============================================================
2022-03-31 13:41:03,148: Epoch 6/31 Batch 1600/7662 eta: 23:00:15.866156	Training Loss 0.8346 (0.8392)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 13:41:03,148: ============================================================
2022-03-31 13:41:45,382: time cost, forward:0.15092521698914113, backward:0.03576157288105085, data cost:0.2174096880694429 
2022-03-31 13:41:45,382: ============================================================
2022-03-31 13:41:45,383: Epoch 6/31 Batch 1700/7662 eta: 23:10:19.896946	Training Loss 0.8346 (0.8389)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 13:41:45,383: ============================================================
2022-03-31 13:42:24,741: time cost, forward:0.1505770856900769, backward:0.035730303493455226, data cost:0.21719195194679078 
2022-03-31 13:42:24,741: ============================================================
2022-03-31 13:42:24,741: Epoch 6/31 Batch 1800/7662 eta: 21:34:59.128376	Training Loss 0.8346 (0.8387)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 13:42:24,742: ============================================================
2022-03-31 13:43:05,127: time cost, forward:0.15028603871663412, backward:0.03564606383325176, data cost:0.21754790959451123 
2022-03-31 13:43:05,127: ============================================================
2022-03-31 13:43:05,128: Epoch 6/31 Batch 1900/7662 eta: 22:08:07.072642	Training Loss 0.8346 (0.8384)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 13:43:05,128: ============================================================
2022-03-31 13:43:46,086: time cost, forward:0.15023838191583433, backward:0.03580275495509137, data cost:0.21773311935585102 
2022-03-31 13:43:46,086: ============================================================
2022-03-31 13:43:46,086: Epoch 6/31 Batch 2000/7662 eta: 22:26:16.126827	Training Loss 0.8346 (0.8383)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 13:43:46,086: ============================================================
2022-03-31 13:44:25,943: time cost, forward:0.14940062859559297, backward:0.03576535892350268, data cost:0.21829894873685868 
2022-03-31 13:44:25,943: ============================================================
2022-03-31 13:44:25,943: Epoch 6/31 Batch 2100/7662 eta: 21:49:23.496405	Training Loss 0.8346 (0.8381)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 13:44:25,944: ============================================================
2022-03-31 13:45:05,654: time cost, forward:0.14901509237267743, backward:0.035672578664192454, data cost:0.21848183309234995 
2022-03-31 13:45:05,654: ============================================================
2022-03-31 13:45:05,655: Epoch 6/31 Batch 2200/7662 eta: 21:43:55.995354	Training Loss 0.8346 (0.8379)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 13:45:05,655: ============================================================
2022-03-31 13:45:43,347: time cost, forward:0.1477742817361441, backward:0.035533820924265276, data cost:0.2186822809308132 
2022-03-31 13:45:43,360: ============================================================
2022-03-31 13:45:43,361: Epoch 6/31 Batch 2300/7662 eta: 20:37:28.161494	Training Loss 0.8346 (0.8378)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 13:45:43,361: ============================================================
2022-03-31 13:46:21,551: time cost, forward:0.14706509925266661, backward:0.035540195741768726, data cost:0.2185666921885126 
2022-03-31 13:46:21,551: ============================================================
2022-03-31 13:46:21,551: Epoch 6/31 Batch 2400/7662 eta: 20:52:44.512133	Training Loss 0.8346 (0.8376)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 13:46:21,552: ============================================================
2022-03-31 13:47:03,981: time cost, forward:0.14779434265161143, backward:0.035630104588527306, data cost:0.2186677961551747 
2022-03-31 13:47:03,981: ============================================================
2022-03-31 13:47:03,982: Epoch 6/31 Batch 2500/7662 eta: 23:11:05.676844	Training Loss 0.8346 (0.8375)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 13:47:03,982: ============================================================
2022-03-31 13:47:41,967: time cost, forward:0.14707666702020988, backward:0.035525666791322186, data cost:0.21861200224394614 
2022-03-31 13:47:41,968: ============================================================
2022-03-31 13:47:41,968: Epoch 6/31 Batch 2600/7662 eta: 20:44:46.283853	Training Loss 0.8346 (0.8374)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 13:47:41,968: ============================================================
2022-03-31 13:48:24,125: time cost, forward:0.14760593459887963, backward:0.03552719459307552, data cost:0.21880806998528124 
2022-03-31 13:48:24,126: ============================================================
2022-03-31 13:48:24,126: Epoch 6/31 Batch 2700/7662 eta: 23:00:45.437492	Training Loss 0.8346 (0.8373)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 13:48:24,126: ============================================================
2022-03-31 13:49:05,761: time cost, forward:0.1477865955581747, backward:0.03554372380315597, data cost:0.21912104549387515 
2022-03-31 13:49:05,761: ============================================================
2022-03-31 13:49:05,761: Epoch 6/31 Batch 2800/7662 eta: 22:42:57.491443	Training Loss 0.8346 (0.8372)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 13:49:05,761: ============================================================
2022-03-31 13:49:49,335: time cost, forward:0.1486518839467349, backward:0.03565526082623453, data cost:0.2192480010631044 
2022-03-31 13:49:49,336: ============================================================
2022-03-31 13:49:49,336: Epoch 6/31 Batch 2900/7662 eta: 23:45:42.411158	Training Loss 0.8346 (0.8371)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 13:49:49,336: ============================================================
2022-03-31 13:50:30,456: time cost, forward:0.14887705410508642, backward:0.035702529371718875, data cost:0.2192317137284134 
2022-03-31 13:50:30,457: ============================================================
2022-03-31 13:50:30,457: Epoch 6/31 Batch 3000/7662 eta: 22:24:45.387325	Training Loss 0.8346 (0.8370)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 13:50:30,457: ============================================================
2022-03-31 13:51:10,641: time cost, forward:0.14895658694609168, backward:0.03570929724541584, data cost:0.21909089248462738 
2022-03-31 13:51:10,641: ============================================================
2022-03-31 13:51:10,641: Epoch 6/31 Batch 3100/7662 eta: 21:53:26.426681	Training Loss 0.8346 (0.8370)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 13:51:10,641: ============================================================
2022-03-31 13:51:52,245: time cost, forward:0.14903789432617454, backward:0.035727036301140935, data cost:0.2193608507583871 
2022-03-31 13:51:52,245: ============================================================
2022-03-31 13:51:52,245: Epoch 6/31 Batch 3200/7662 eta: 22:39:08.845392	Training Loss 0.8346 (0.8369)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 13:51:52,245: ============================================================
2022-03-31 13:52:33,844: time cost, forward:0.14924076464220262, backward:0.03578938083527268, data cost:0.21943099898401627 
2022-03-31 13:52:33,845: ============================================================
2022-03-31 13:52:33,845: Epoch 6/31 Batch 3300/7662 eta: 22:38:19.335115	Training Loss 0.8346 (0.8368)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 13:52:33,845: ============================================================
2022-03-31 13:53:12,821: time cost, forward:0.14898768366347626, backward:0.035763465014932154, data cost:0.21927475059477852 
2022-03-31 13:53:12,821: ============================================================
2022-03-31 13:53:12,821: Epoch 6/31 Batch 3400/7662 eta: 21:12:00.899950	Training Loss 0.8346 (0.8367)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 13:53:12,821: ============================================================
2022-03-31 13:53:55,737: time cost, forward:0.1494164081872208, backward:0.0358788669364866, data cost:0.21944360993323445 
2022-03-31 13:53:55,737: ============================================================
2022-03-31 13:53:55,737: Epoch 6/31 Batch 3500/7662 eta: 23:19:52.398041	Training Loss 0.8346 (0.8367)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 13:53:55,738: ============================================================
2022-03-31 13:54:35,867: time cost, forward:0.14938327894504946, backward:0.035920496747440085, data cost:0.2193020555369554 
2022-03-31 13:54:35,868: ============================================================
2022-03-31 13:54:35,868: Epoch 6/31 Batch 3600/7662 eta: 21:48:20.235866	Training Loss 0.8346 (0.8366)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 13:54:35,868: ============================================================
2022-03-31 13:55:16,638: time cost, forward:0.1492443181399108, backward:0.03593361664540254, data cost:0.21952157054085383 
2022-03-31 13:55:16,639: ============================================================
2022-03-31 13:55:16,639: Epoch 6/31 Batch 3700/7662 eta: 22:08:33.672044	Training Loss 0.8346 (0.8366)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 13:55:16,640: ============================================================
2022-03-31 13:55:56,893: time cost, forward:0.14911237306486905, backward:0.03589369033819501, data cost:0.2196304618010053 
2022-03-31 13:55:56,894: ============================================================
2022-03-31 13:55:56,894: Epoch 6/31 Batch 3800/7662 eta: 21:51:03.098972	Training Loss 0.8346 (0.8365)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 13:55:56,894: ============================================================
2022-03-31 13:56:36,776: time cost, forward:0.1489740422702074, backward:0.035855414898586936, data cost:0.21965238307494023 
2022-03-31 13:56:36,776: ============================================================
2022-03-31 13:56:36,777: Epoch 6/31 Batch 3900/7662 eta: 21:38:15.701507	Training Loss 0.8346 (0.8365)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 13:56:36,777: ============================================================
2022-03-31 13:57:16,948: time cost, forward:0.14887297072986508, backward:0.03581913902509746, data cost:0.21970598093716315 
2022-03-31 13:57:16,949: ============================================================
2022-03-31 13:57:16,949: Epoch 6/31 Batch 4000/7662 eta: 21:47:02.066023	Training Loss 0.8346 (0.8364)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 13:57:16,949: ============================================================
2022-03-31 13:58:01,434: time cost, forward:0.14979542113129876, backward:0.03587993885662882, data cost:0.21968678673118114 
2022-03-31 13:58:01,434: ============================================================
2022-03-31 13:58:01,434: Epoch 6/31 Batch 4100/7662 eta: 1 day, 0:06:36.324403	Training Loss 0.8349 (0.8364)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 13:58:01,435: ============================================================
2022-03-31 13:58:41,301: time cost, forward:0.14965922158512227, backward:0.035900601093812795, data cost:0.21965177185792645 
2022-03-31 13:58:41,302: ============================================================
2022-03-31 13:58:41,302: Epoch 6/31 Batch 4200/7662 eta: 21:35:46.498250	Training Loss 0.8382 (0.8364)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 13:58:41,302: ============================================================
2022-03-31 13:59:22,165: time cost, forward:0.1496592716550683, backward:0.03593234357015286, data cost:0.21968629538222617 
2022-03-31 13:59:22,166: ============================================================
2022-03-31 13:59:22,166: Epoch 6/31 Batch 4300/7662 eta: 22:07:29.548682	Training Loss 0.8659 (0.8368)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 13:59:22,166: ============================================================
2022-03-31 14:00:03,126: time cost, forward:0.14926411276867402, backward:0.0359385772899325, data cost:0.22017319843589678 
2022-03-31 14:00:03,126: ============================================================
2022-03-31 14:00:03,127: Epoch 6/31 Batch 4400/7662 eta: 22:09:57.056067	Training Loss 0.9522 (0.8385)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 14:00:03,127: ============================================================
2022-03-31 14:00:48,082: time cost, forward:0.14937665759788457, backward:0.035939706063424254, data cost:0.22102629112969455 
2022-03-31 14:00:48,082: ============================================================
2022-03-31 14:00:48,082: Epoch 6/31 Batch 4500/7662 eta: 1 day, 0:18:54.085509	Training Loss 0.9092 (0.8409)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 14:00:48,082: ============================================================
2022-03-31 14:01:29,842: time cost, forward:0.14891393595764132, backward:0.03589452243571853, data cost:0.22177036297427594 
2022-03-31 14:01:29,842: ============================================================
2022-03-31 14:01:29,842: Epoch 6/31 Batch 4600/7662 eta: 22:34:30.778536	Training Loss 0.9607 (0.8430)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.003)	
2022-03-31 14:01:29,843: ============================================================
2022-03-31 14:02:12,862: time cost, forward:0.14874910055056204, backward:0.03584501027401317, data cost:0.22248765848423221 
2022-03-31 14:02:12,863: ============================================================
2022-03-31 14:02:12,863: Epoch 6/31 Batch 4700/7662 eta: 23:14:40.858786	Training Loss 0.8970 (0.8446)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.004)	
2022-03-31 14:02:12,863: ============================================================
2022-03-31 14:02:53,858: time cost, forward:0.14849509450638634, backward:0.035849622200617916, data cost:0.22278600003377028 
2022-03-31 14:02:53,858: ============================================================
2022-03-31 14:02:53,859: Epoch 6/31 Batch 4800/7662 eta: 22:08:20.679851	Training Loss 0.9220 (0.8460)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.004)	
2022-03-31 14:02:53,859: ============================================================
2022-03-31 14:03:37,937: time cost, forward:0.14848741080522976, backward:0.035852255833881394, data cost:0.22347845479307624 
2022-03-31 14:03:37,937: ============================================================
2022-03-31 14:03:37,937: Epoch 6/31 Batch 4900/7662 eta: 23:47:30.840888	Training Loss 0.8927 (0.8471)	Training Prec@1 0.195 (0.000)	Training Prec@5 0.195 (0.004)	
2022-03-31 14:03:37,938: ============================================================
2022-03-31 14:04:20,425: time cost, forward:0.14857952683943465, backward:0.03585355690561025, data cost:0.2237005858546282 
2022-03-31 14:04:20,426: ============================================================
2022-03-31 14:04:20,426: Epoch 6/31 Batch 5000/7662 eta: 22:55:18.071270	Training Loss 0.9014 (0.8481)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.004)	
2022-03-31 14:04:20,426: ============================================================
2022-03-31 14:05:04,130: time cost, forward:0.1486061703670163, backward:0.0358957983414597, data cost:0.22418940130414436 
2022-03-31 14:05:04,130: ============================================================
2022-03-31 14:05:04,131: Epoch 6/31 Batch 5100/7662 eta: 23:33:56.496430	Training Loss 0.8881 (0.8490)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.004)	
2022-03-31 14:05:04,131: ============================================================
2022-03-31 14:05:49,119: time cost, forward:0.14899301129961318, backward:0.03595729290602138, data cost:0.2244627740342334 
2022-03-31 14:05:49,119: ============================================================
2022-03-31 14:05:49,119: Epoch 6/31 Batch 5200/7662 eta: 1 day, 0:14:43.934226	Training Loss 0.8818 (0.8499)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.004)	
2022-03-31 14:05:49,119: ============================================================
2022-03-31 14:06:31,464: time cost, forward:0.14863918142108157, backward:0.035928063717489536, data cost:0.2251756979083313 
2022-03-31 14:06:31,465: ============================================================
2022-03-31 14:06:31,465: Epoch 6/31 Batch 5300/7662 eta: 22:48:33.399811	Training Loss 0.8816 (0.8506)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.004)	
2022-03-31 14:06:31,465: ============================================================
2022-03-31 14:07:13,348: time cost, forward:0.148590650044452, backward:0.03592420079174208, data cost:0.2253895111493787 
2022-03-31 14:07:13,349: ============================================================
2022-03-31 14:07:13,349: Epoch 6/31 Batch 5400/7662 eta: 22:32:57.014104	Training Loss 0.8814 (0.8512)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.004)	
2022-03-31 14:07:13,349: ============================================================
2022-03-31 14:07:56,396: time cost, forward:0.14845378612643872, backward:0.03590971046110612, data cost:0.22591950369219407 
2022-03-31 14:07:56,397: ============================================================
2022-03-31 14:07:56,397: Epoch 6/31 Batch 5500/7662 eta: 23:09:49.940521	Training Loss 0.8737 (0.8518)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.004)	
2022-03-31 14:07:56,397: ============================================================
2022-03-31 14:08:41,516: time cost, forward:0.1487782776494136, backward:0.035942024153286824, data cost:0.22628605580794042 
2022-03-31 14:08:41,516: ============================================================
2022-03-31 14:08:41,517: Epoch 6/31 Batch 5600/7662 eta: 1 day, 0:15:57.045665	Training Loss 0.8772 (0.8523)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.004)	
2022-03-31 14:08:41,517: ============================================================
2022-03-31 14:09:23,867: time cost, forward:0.14851811066450288, backward:0.03596077414641654, data cost:0.22672637639746035 
2022-03-31 14:09:23,867: ============================================================
2022-03-31 14:09:23,867: Epoch 6/31 Batch 5700/7662 eta: 22:45:54.218784	Training Loss 0.8766 (0.8528)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.004)	
2022-03-31 14:09:23,868: ============================================================
2022-03-31 14:10:10,147: time cost, forward:0.14920506988810883, backward:0.036014951535557276, data cost:0.22687422186984216 
2022-03-31 14:10:10,147: ============================================================
2022-03-31 14:10:10,147: Epoch 6/31 Batch 5800/7662 eta: 1 day, 0:51:51.493459	Training Loss 0.8711 (0.8532)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.004)	
2022-03-31 14:10:10,148: ============================================================
2022-03-31 14:10:55,862: time cost, forward:0.14939315380898952, backward:0.0360352056554706, data cost:0.2274317712293962 
2022-03-31 14:10:55,862: ============================================================
2022-03-31 14:10:55,862: Epoch 6/31 Batch 5900/7662 eta: 1 day, 0:32:53.206471	Training Loss 0.8771 (0.8536)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.004)	
2022-03-31 14:10:55,863: ============================================================
2022-03-31 14:11:39,232: time cost, forward:0.1494480657426491, backward:0.03602893003961964, data cost:0.22771803282324246 
2022-03-31 14:11:39,233: ============================================================
2022-03-31 14:11:39,233: Epoch 6/31 Batch 6000/7662 eta: 23:16:37.540612	Training Loss 0.8733 (0.8540)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.004)	
2022-03-31 14:11:39,233: ============================================================
2022-03-31 14:12:24,401: time cost, forward:0.14980552489297433, backward:0.03599393846637246, data cost:0.22802072103775256 
2022-03-31 14:12:24,402: ============================================================
2022-03-31 14:12:24,402: Epoch 6/31 Batch 6100/7662 eta: 1 day, 0:13:47.359051	Training Loss 0.8722 (0.8543)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.004)	
2022-03-31 14:12:24,402: ============================================================
2022-03-31 14:13:06,964: time cost, forward:0.14989744945771658, backward:0.03600057972537104, data cost:0.2281099078077946 
2022-03-31 14:13:06,964: ============================================================
2022-03-31 14:13:06,964: Epoch 6/31 Batch 6200/7662 eta: 22:49:10.467857	Training Loss 0.8714 (0.8547)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.004)	
2022-03-31 14:13:06,964: ============================================================
2022-03-31 14:13:50,518: time cost, forward:0.14985411218999586, backward:0.03600133398370641, data cost:0.22848755788341327 
2022-03-31 14:13:50,518: ============================================================
2022-03-31 14:13:50,519: Epoch 6/31 Batch 6300/7662 eta: 23:20:21.914253	Training Loss 0.8697 (0.8549)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.004)	
2022-03-31 14:13:50,519: ============================================================
2022-03-31 14:14:33,648: time cost, forward:0.14989115566290026, backward:0.035973622326106465, data cost:0.22873371208919402 
2022-03-31 14:14:33,648: ============================================================
2022-03-31 14:14:33,648: Epoch 6/31 Batch 6400/7662 eta: 23:05:59.981413	Training Loss 0.8672 (0.8552)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.004)	
2022-03-31 14:14:33,649: ============================================================
2022-03-31 14:15:17,459: time cost, forward:0.14995418843681546, backward:0.0359873721775302, data cost:0.2290208759739282 
2022-03-31 14:15:17,459: ============================================================
2022-03-31 14:15:17,459: Epoch 6/31 Batch 6500/7662 eta: 23:27:09.080960	Training Loss 0.8706 (0.8555)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.004)	
2022-03-31 14:15:17,459: ============================================================
2022-03-31 14:15:58,779: time cost, forward:0.1493873531880894, backward:0.03595303455832005, data cost:0.2295837231089914 
2022-03-31 14:15:58,780: ============================================================
2022-03-31 14:15:58,780: Epoch 6/31 Batch 6600/7662 eta: 22:06:28.774324	Training Loss 0.8712 (0.8557)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.005)	
2022-03-31 14:15:58,780: ============================================================
2022-03-31 14:16:43,592: time cost, forward:0.14942933897737923, backward:0.035950173404896896, data cost:0.23003171233743638 
2022-03-31 14:16:43,593: ============================================================
2022-03-31 14:16:43,593: Epoch 6/31 Batch 6700/7662 eta: 23:57:51.344031	Training Loss 0.8690 (0.8559)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.004)	
2022-03-31 14:16:43,593: ============================================================
2022-03-31 14:17:25,210: time cost, forward:0.14924480932953604, backward:0.035956775253179196, data cost:0.2302157627096736 
2022-03-31 14:17:25,211: ============================================================
2022-03-31 14:17:25,211: Epoch 6/31 Batch 6800/7662 eta: 22:14:38.127697	Training Loss 0.8672 (0.8561)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.004)	
2022-03-31 14:17:25,211: ============================================================
2022-03-31 14:18:08,942: time cost, forward:0.14909543201774422, backward:0.035945843641162524, data cost:0.23069146789144926 
2022-03-31 14:18:08,942: ============================================================
2022-03-31 14:18:08,942: Epoch 6/31 Batch 6900/7662 eta: 23:21:41.479094	Training Loss 0.8643 (0.8563)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.004)	
2022-03-31 14:18:08,943: ============================================================
2022-03-31 14:18:54,752: time cost, forward:0.1494076570828892, backward:0.03598154870284116, data cost:0.23093983380687902 
2022-03-31 14:18:54,753: ============================================================
2022-03-31 14:18:54,753: Epoch 6/31 Batch 7000/7662 eta: 1 day, 0:27:33.622534	Training Loss 0.8685 (0.8565)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.004)	
2022-03-31 14:18:54,753: ============================================================
2022-03-31 14:19:38,541: time cost, forward:0.14943937547342226, backward:0.03599050008405983, data cost:0.23119841708081057 
2022-03-31 14:19:38,541: ============================================================
2022-03-31 14:19:38,542: Epoch 6/31 Batch 7100/7662 eta: 23:22:03.683747	Training Loss 0.8703 (0.8567)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.004)	
2022-03-31 14:19:38,542: ============================================================
2022-03-31 14:20:21,935: time cost, forward:0.1496309374650165, backward:0.036007364883507635, data cost:0.23122544642338605 
2022-03-31 14:20:21,935: ============================================================
2022-03-31 14:20:21,935: Epoch 6/31 Batch 7200/7662 eta: 23:08:41.932253	Training Loss 0.8672 (0.8568)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.005)	
2022-03-31 14:20:21,936: ============================================================
2022-03-31 14:21:07,074: time cost, forward:0.14984102163564378, backward:0.036036585729274706, data cost:0.2314341628464922 
2022-03-31 14:21:07,074: ============================================================
2022-03-31 14:21:07,075: Epoch 6/31 Batch 7300/7662 eta: 1 day, 0:03:47.925124	Training Loss 0.8673 (0.8570)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.005)	
2022-03-31 14:21:07,075: ============================================================
2022-03-31 14:21:50,117: time cost, forward:0.14970517239066003, backward:0.0360260651649406, data cost:0.2317741428586112 
2022-03-31 14:21:50,118: ============================================================
2022-03-31 14:21:50,118: Epoch 6/31 Batch 7400/7662 eta: 22:56:02.439985	Training Loss 0.8664 (0.8571)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.005)	
2022-03-31 14:21:50,118: ============================================================
2022-03-31 14:22:34,432: time cost, forward:0.14976928106608875, backward:0.03603272295614961, data cost:0.23204466863892398 
2022-03-31 14:22:34,433: ============================================================
2022-03-31 14:22:34,433: Epoch 6/31 Batch 7500/7662 eta: 23:35:57.935101	Training Loss 0.8651 (0.8573)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.005)	
2022-03-31 14:22:34,433: ============================================================
2022-03-31 14:23:17,176: time cost, forward:0.14996408236498956, backward:0.03604842568874547, data cost:0.23195652146608614 
2022-03-31 14:23:17,177: ============================================================
2022-03-31 14:23:17,177: Epoch 6/31 Batch 7600/7662 eta: 22:45:03.192667	Training Loss 0.8654 (0.8574)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.005)	
2022-03-31 14:23:17,177: ============================================================
2022-03-31 14:23:45,739: Epoch: 6/31 eta: 22:44:36.263903	Training Loss 0.8602 (0.8575)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.005)
2022-03-31 14:23:45,739: ============================================================
2022-03-31 14:24:28,881: time cost, forward:0.10615921742988355, backward:0.032420553342260496, data cost:0.2927023810569686 
2022-03-31 14:24:28,882: ============================================================
2022-03-31 14:24:28,882: Epoch 7/31 Batch 100/7662 eta: 22:51:08.101019	Training Loss 0.8652 (0.8656)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.002)	
2022-03-31 14:24:28,883: ============================================================
2022-03-31 14:25:09,842: time cost, forward:0.10570899445806915, backward:0.03230370708446407, data cost:0.28199001053469863 
2022-03-31 14:25:09,843: ============================================================
2022-03-31 14:25:09,843: Epoch 7/31 Batch 200/7662 eta: 21:46:19.007033	Training Loss 0.8682 (0.8657)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.005)	
2022-03-31 14:25:09,843: ============================================================
2022-03-31 14:25:53,626: time cost, forward:0.11658127411552098, backward:0.03312144311375442, data cost:0.2762529228044593 
2022-03-31 14:25:53,626: ============================================================
2022-03-31 14:25:53,626: Epoch 7/31 Batch 300/7662 eta: 23:15:35.809249	Training Loss 0.8639 (0.8655)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.005)	
2022-03-31 14:25:53,627: ============================================================
2022-03-31 14:26:36,712: time cost, forward:0.1202408896950552, backward:0.03372802650719358, data cost:0.2730896640242192 
2022-03-31 14:26:36,712: ============================================================
2022-03-31 14:26:36,712: Epoch 7/31 Batch 400/7662 eta: 22:52:39.355798	Training Loss 0.8637 (0.8653)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.005)	
2022-03-31 14:26:36,713: ============================================================
2022-03-31 14:27:20,324: time cost, forward:0.12341001659691453, backward:0.03368497468187718, data cost:0.27166088931785076 
2022-03-31 14:27:20,325: ============================================================
2022-03-31 14:27:20,325: Epoch 7/31 Batch 500/7662 eta: 23:08:42.300395	Training Loss 0.8651 (0.8652)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.007)	
2022-03-31 14:27:20,325: ============================================================
2022-03-31 14:28:05,591: time cost, forward:0.12719002072520566, backward:0.034000603702908166, data cost:0.27145735170685986 
2022-03-31 14:28:05,592: ============================================================
2022-03-31 14:28:05,592: Epoch 7/31 Batch 600/7662 eta: 1 day, 0:00:37.296499	Training Loss 0.8653 (0.8651)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.007)	
2022-03-31 14:28:05,592: ============================================================
2022-03-31 14:28:49,328: time cost, forward:0.1294587616927293, backward:0.034063055109397875, data cost:0.26984922261708794 
2022-03-31 14:28:49,329: ============================================================
2022-03-31 14:28:49,329: Epoch 7/31 Batch 700/7662 eta: 23:11:12.753932	Training Loss 0.8622 (0.8650)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.008)	
2022-03-31 14:28:49,329: ============================================================
2022-03-31 14:29:32,281: time cost, forward:0.1315141362750038, backward:0.03396598627331558, data cost:0.26736470516095023 
2022-03-31 14:29:32,282: ============================================================
2022-03-31 14:29:32,282: Epoch 7/31 Batch 800/7662 eta: 22:45:33.109345	Training Loss 0.8615 (0.8650)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.007)	
2022-03-31 14:29:32,282: ============================================================
2022-03-31 14:30:15,178: time cost, forward:0.13286728376276102, backward:0.033942893031441726, data cost:0.265494639138889 
2022-03-31 14:30:15,178: ============================================================
2022-03-31 14:30:15,178: Epoch 7/31 Batch 900/7662 eta: 22:43:02.675517	Training Loss 0.8680 (0.8649)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.007)	
2022-03-31 14:30:15,178: ============================================================
2022-03-31 14:30:59,581: time cost, forward:0.13488390925410274, backward:0.03393119758552498, data cost:0.26467926724179014 
2022-03-31 14:30:59,581: ============================================================
2022-03-31 14:30:59,581: Epoch 7/31 Batch 1000/7662 eta: 23:30:10.279430	Training Loss 0.8644 (0.8648)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.007)	
2022-03-31 14:30:59,581: ============================================================
2022-03-31 14:31:41,291: time cost, forward:0.13359200401236732, backward:0.03375750720446711, data cost:0.2646059807698438 
2022-03-31 14:31:41,292: ============================================================
2022-03-31 14:31:41,292: Epoch 7/31 Batch 1100/7662 eta: 22:03:58.056639	Training Loss 0.8633 (0.8647)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.007)	
2022-03-31 14:31:41,292: ============================================================
2022-03-31 14:32:27,082: time cost, forward:0.13543863193107905, backward:0.03395926644147884, data cost:0.26466543541240933 
2022-03-31 14:32:27,082: ============================================================
2022-03-31 14:32:27,082: Epoch 7/31 Batch 1200/7662 eta: 1 day, 0:12:42.836531	Training Loss 0.8613 (0.8646)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.007)	
2022-03-31 14:32:27,083: ============================================================
2022-03-31 14:33:10,766: time cost, forward:0.1362746334516424, backward:0.034142743449104666, data cost:0.2638429580421242 
2022-03-31 14:33:10,767: ============================================================
2022-03-31 14:33:10,767: Epoch 7/31 Batch 1300/7662 eta: 23:05:10.441635	Training Loss 0.8653 (0.8646)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 14:33:10,767: ============================================================
2022-03-31 14:33:54,325: time cost, forward:0.13602768599433163, backward:0.034101985027485016, data cost:0.2642067199608869 
2022-03-31 14:33:54,325: ============================================================
2022-03-31 14:33:54,325: Epoch 7/31 Batch 1400/7662 eta: 23:00:26.701742	Training Loss 0.8603 (0.8645)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 14:33:54,326: ============================================================
2022-03-31 14:34:37,163: time cost, forward:0.1354401243615739, backward:0.03409195534780552, data cost:0.2643418003512351 
2022-03-31 14:34:37,164: ============================================================
2022-03-31 14:34:37,164: Epoch 7/31 Batch 1500/7662 eta: 22:36:54.947383	Training Loss 0.8621 (0.8644)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 14:34:37,164: ============================================================
2022-03-31 14:35:23,209: time cost, forward:0.13771344766980637, backward:0.03432413635587901, data cost:0.263490639007263 
2022-03-31 14:35:23,209: ============================================================
2022-03-31 14:35:23,210: Epoch 7/31 Batch 1600/7662 eta: 1 day, 0:17:44.250990	Training Loss 0.8632 (0.8644)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.007)	
2022-03-31 14:35:23,210: ============================================================
2022-03-31 14:36:07,644: time cost, forward:0.13917157241637176, backward:0.03450314994416846, data cost:0.26234379819451253 
2022-03-31 14:36:07,644: ============================================================
2022-03-31 14:36:07,644: Epoch 7/31 Batch 1700/7662 eta: 23:25:59.744952	Training Loss 0.8606 (0.8643)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 14:36:07,644: ============================================================
2022-03-31 14:36:52,526: time cost, forward:0.13912830662899642, backward:0.03449215366815182, data cost:0.26312331718627185 
2022-03-31 14:36:52,526: ============================================================
2022-03-31 14:36:52,526: Epoch 7/31 Batch 1800/7662 eta: 23:39:24.058691	Training Loss 0.8630 (0.8643)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 14:36:52,526: ============================================================
2022-03-31 14:37:34,782: time cost, forward:0.13874339266410937, backward:0.03442352981928966, data cost:0.26279098125053996 
2022-03-31 14:37:34,782: ============================================================
2022-03-31 14:37:34,782: Epoch 7/31 Batch 1900/7662 eta: 22:15:38.899510	Training Loss 0.8647 (0.8643)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 14:37:34,783: ============================================================
2022-03-31 14:38:19,870: time cost, forward:0.13978483260661856, backward:0.03447897163494162, data cost:0.2624130677198875 
2022-03-31 14:38:19,870: ============================================================
2022-03-31 14:38:19,871: Epoch 7/31 Batch 2000/7662 eta: 23:44:25.235840	Training Loss 0.8616 (0.8642)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 14:38:19,871: ============================================================
2022-03-31 14:39:04,362: time cost, forward:0.14074618422229726, backward:0.03457894547886369, data cost:0.26169273681786015 
2022-03-31 14:39:04,362: ============================================================
2022-03-31 14:39:04,363: Epoch 7/31 Batch 2100/7662 eta: 23:24:50.647972	Training Loss 0.8632 (0.8641)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 14:39:04,363: ============================================================
2022-03-31 14:39:48,441: time cost, forward:0.1405775288984742, backward:0.03456275015324015, data cost:0.2620459860593094 
2022-03-31 14:39:48,441: ============================================================
2022-03-31 14:39:48,441: Epoch 7/31 Batch 2200/7662 eta: 23:11:03.120775	Training Loss 0.8666 (0.8641)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 14:39:48,441: ============================================================
2022-03-31 14:40:30,530: time cost, forward:0.1407034568239057, backward:0.03460462801660751, data cost:0.26117227957942474 
2022-03-31 14:40:30,530: ============================================================
2022-03-31 14:40:30,530: Epoch 7/31 Batch 2300/7662 eta: 22:07:33.790647	Training Loss 0.8621 (0.8641)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 14:40:30,530: ============================================================
2022-03-31 14:41:14,486: time cost, forward:0.14066388627895468, backward:0.034653669598202944, data cost:0.2612739830724693 
2022-03-31 14:41:14,486: ============================================================
2022-03-31 14:41:14,487: Epoch 7/31 Batch 2400/7662 eta: 23:05:44.133711	Training Loss 0.8642 (0.8640)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 14:41:14,487: ============================================================
2022-03-31 14:41:57,867: time cost, forward:0.14114605459798665, backward:0.034750424274781935, data cost:0.2605546541622325 
2022-03-31 14:41:57,867: ============================================================
2022-03-31 14:41:57,867: Epoch 7/31 Batch 2500/7662 eta: 22:46:51.561728	Training Loss 0.8633 (0.8640)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.195 (0.008)	
2022-03-31 14:41:57,868: ============================================================
2022-03-31 14:42:41,568: time cost, forward:0.14072412231785833, backward:0.03475440011752849, data cost:0.26100825300213004 
2022-03-31 14:42:41,569: ============================================================
2022-03-31 14:42:41,569: Epoch 7/31 Batch 2600/7662 eta: 22:56:14.449080	Training Loss 0.8594 (0.8639)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 14:42:41,569: ============================================================
2022-03-31 14:43:26,405: time cost, forward:0.14051800685796353, backward:0.03473404753247911, data cost:0.26162452307309253 
2022-03-31 14:43:26,406: ============================================================
2022-03-31 14:43:26,406: Epoch 7/31 Batch 2700/7662 eta: 23:31:15.248290	Training Loss 0.8595 (0.8639)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 14:43:26,406: ============================================================
2022-03-31 14:44:09,363: time cost, forward:0.14011142857801323, backward:0.03470670235672351, data cost:0.2618175871502548 
2022-03-31 14:44:09,364: ============================================================
2022-03-31 14:44:09,364: Epoch 7/31 Batch 2800/7662 eta: 22:31:23.663476	Training Loss 0.8654 (0.8639)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.007)	
2022-03-31 14:44:09,364: ============================================================
2022-03-31 14:44:53,597: time cost, forward:0.1404996103317666, backward:0.03472509759177254, data cost:0.2615776803831513 
2022-03-31 14:44:53,598: ============================================================
2022-03-31 14:44:53,598: Epoch 7/31 Batch 2900/7662 eta: 23:10:48.189129	Training Loss 0.8602 (0.8638)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.007)	
2022-03-31 14:44:53,598: ============================================================
2022-03-31 14:45:37,040: time cost, forward:0.14049540817359957, backward:0.03474512311688023, data cost:0.2614744784395549 
2022-03-31 14:45:37,040: ============================================================
2022-03-31 14:45:37,041: Epoch 7/31 Batch 3000/7662 eta: 22:45:11.172639	Training Loss 0.8623 (0.8638)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.007)	
2022-03-31 14:45:37,041: ============================================================
2022-03-31 14:46:21,977: time cost, forward:0.1407513778492034, backward:0.03474320600632123, data cost:0.2616143692074456 
2022-03-31 14:46:21,978: ============================================================
2022-03-31 14:46:21,978: Epoch 7/31 Batch 3100/7662 eta: 23:31:24.900790	Training Loss 0.8623 (0.8637)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.007)	
2022-03-31 14:46:21,978: ============================================================
2022-03-31 14:47:07,394: time cost, forward:0.14145025732965164, backward:0.03481436662653082, data cost:0.26135553528122996 
2022-03-31 14:47:07,394: ============================================================
2022-03-31 14:47:07,395: Epoch 7/31 Batch 3200/7662 eta: 23:45:42.652578	Training Loss 0.8611 (0.8637)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.007)	
2022-03-31 14:47:07,395: ============================================================
2022-03-31 14:47:50,523: time cost, forward:0.14115264842856395, backward:0.03475943389319044, data cost:0.26151106132814905 
2022-03-31 14:47:50,524: ============================================================
2022-03-31 14:47:50,524: Epoch 7/31 Batch 3300/7662 eta: 22:33:11.369733	Training Loss 0.8603 (0.8636)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.007)	
2022-03-31 14:47:50,524: ============================================================
2022-03-31 14:48:35,389: time cost, forward:0.1416013546640924, backward:0.034883576934917705, data cost:0.26124597570762176 
2022-03-31 14:48:35,390: ============================================================
2022-03-31 14:48:35,390: Epoch 7/31 Batch 3400/7662 eta: 23:26:56.290035	Training Loss 0.8622 (0.8636)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.007)	
2022-03-31 14:48:35,390: ============================================================
2022-03-31 14:49:19,490: time cost, forward:0.14178203943628145, backward:0.03492117984256052, data cost:0.26110568800187856 
2022-03-31 14:49:19,491: ============================================================
2022-03-31 14:49:19,491: Epoch 7/31 Batch 3500/7662 eta: 23:02:12.449655	Training Loss 0.8635 (0.8635)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.007)	
2022-03-31 14:49:19,491: ============================================================
2022-03-31 14:50:03,283: time cost, forward:0.14208675106554172, backward:0.03498087607678124, data cost:0.2607624016724947 
2022-03-31 14:50:03,283: ============================================================
2022-03-31 14:50:03,283: Epoch 7/31 Batch 3600/7662 eta: 22:51:48.170156	Training Loss 0.8614 (0.8635)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.007)	
2022-03-31 14:50:03,284: ============================================================
2022-03-31 14:50:47,894: time cost, forward:0.14231548988680545, backward:0.03498554687365934, data cost:0.2607331657512796 
2022-03-31 14:50:47,895: ============================================================
2022-03-31 14:50:47,895: Epoch 7/31 Batch 3700/7662 eta: 23:16:43.622760	Training Loss 0.8608 (0.8634)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.007)	
2022-03-31 14:50:47,895: ============================================================
2022-03-31 14:51:32,536: time cost, forward:0.14252367481554015, backward:0.035030392666621155, data cost:0.26068802845104644 
2022-03-31 14:51:32,537: ============================================================
2022-03-31 14:51:32,537: Epoch 7/31 Batch 3800/7662 eta: 23:16:55.431600	Training Loss 0.8625 (0.8634)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 14:51:32,537: ============================================================
2022-03-31 14:52:15,675: time cost, forward:0.14253812687431858, backward:0.035014547119081925, data cost:0.2605118160829938 
2022-03-31 14:52:15,675: ============================================================
2022-03-31 14:52:15,675: Epoch 7/31 Batch 3900/7662 eta: 22:29:09.176076	Training Loss 0.8596 (0.8633)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 14:52:15,675: ============================================================
2022-03-31 14:52:59,968: time cost, forward:0.1425942739685585, backward:0.03501553271943016, data cost:0.2605533983803415 
2022-03-31 14:52:59,968: ============================================================
2022-03-31 14:52:59,968: Epoch 7/31 Batch 4000/7662 eta: 23:04:32.056512	Training Loss 0.8619 (0.8633)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 14:52:59,968: ============================================================
2022-03-31 14:53:41,693: time cost, forward:0.14220793283866887, backward:0.035006226199695206, data cost:0.26041286338914105 
2022-03-31 14:53:41,693: ============================================================
2022-03-31 14:53:41,693: Epoch 7/31 Batch 4100/7662 eta: 21:43:34.221856	Training Loss 0.8612 (0.8633)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 14:53:41,694: ============================================================
2022-03-31 14:54:28,550: time cost, forward:0.14266407146258533, backward:0.03501783481351703, data cost:0.2606976956065197 
2022-03-31 14:54:28,550: ============================================================
2022-03-31 14:54:28,550: Epoch 7/31 Batch 4200/7662 eta: 1 day, 0:23:06.919810	Training Loss 0.8632 (0.8632)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 14:54:28,551: ============================================================
2022-03-31 14:55:12,955: time cost, forward:0.14249561642125252, backward:0.03501505589978754, data cost:0.26098897563049644 
2022-03-31 14:55:12,956: ============================================================
2022-03-31 14:55:12,956: Epoch 7/31 Batch 4300/7662 eta: 23:05:49.840008	Training Loss 0.8604 (0.8632)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 14:55:12,956: ============================================================
2022-03-31 14:55:55,565: time cost, forward:0.1426460858392943, backward:0.0350491176222801, data cost:0.26051323504360135 
2022-03-31 14:55:55,566: ============================================================
2022-03-31 14:55:55,566: Epoch 7/31 Batch 4400/7662 eta: 22:09:05.250619	Training Loss 0.8621 (0.8631)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.195 (0.008)	
2022-03-31 14:55:55,566: ============================================================
2022-03-31 14:56:39,259: time cost, forward:0.142578025583851, backward:0.035029036650580284, data cost:0.2605740257198743 
2022-03-31 14:56:39,260: ============================================================
2022-03-31 14:56:39,260: Epoch 7/31 Batch 4500/7662 eta: 22:42:09.539943	Training Loss 0.8638 (0.8631)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 14:56:39,260: ============================================================
2022-03-31 14:57:23,840: time cost, forward:0.14276584518243499, backward:0.03501949291639832, data cost:0.2605448147088814 
2022-03-31 14:57:23,840: ============================================================
2022-03-31 14:57:23,841: Epoch 7/31 Batch 4600/7662 eta: 23:09:04.644198	Training Loss 0.8596 (0.8630)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 14:57:23,841: ============================================================
2022-03-31 14:58:06,384: time cost, forward:0.14254267942806487, backward:0.03499222456279981, data cost:0.26051022956208436 
2022-03-31 14:58:06,384: ============================================================
2022-03-31 14:58:06,384: Epoch 7/31 Batch 4700/7662 eta: 22:04:52.818766	Training Loss 0.8609 (0.8629)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 14:58:06,384: ============================================================
2022-03-31 14:58:52,273: time cost, forward:0.14284014647194285, backward:0.03502025557548013, data cost:0.2606141859850652 
2022-03-31 14:58:52,274: ============================================================
2022-03-31 14:58:52,274: Epoch 7/31 Batch 4800/7662 eta: 23:48:19.385368	Training Loss 0.8607 (0.8629)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.195 (0.008)	
2022-03-31 14:58:52,274: ============================================================
2022-03-31 14:59:35,908: time cost, forward:0.14311967710739107, backward:0.035047688613645545, data cost:0.2602578780436472 
2022-03-31 14:59:35,909: ============================================================
2022-03-31 14:59:35,909: Epoch 7/31 Batch 4900/7662 eta: 22:37:25.311131	Training Loss 0.8556 (0.8627)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 14:59:35,909: ============================================================
2022-03-31 15:00:21,488: time cost, forward:0.14340490802666453, backward:0.03508018059452955, data cost:0.2602685618624732 
2022-03-31 15:00:21,488: ============================================================
2022-03-31 15:00:21,488: Epoch 7/31 Batch 5000/7662 eta: 23:37:08.785692	Training Loss 0.8568 (0.8626)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 15:00:21,488: ============================================================
2022-03-31 15:01:06,445: time cost, forward:0.14353208192120956, backward:0.035112899246111086, data cost:0.260317072210931 
2022-03-31 15:01:06,445: ============================================================
2022-03-31 15:01:06,445: Epoch 7/31 Batch 5100/7662 eta: 23:17:02.859230	Training Loss 0.8610 (0.8625)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.009)	
2022-03-31 15:01:06,446: ============================================================
2022-03-31 15:01:47,855: time cost, forward:0.1430669653573892, backward:0.03507751266551398, data cost:0.2603310226224711 
2022-03-31 15:01:47,855: ============================================================
2022-03-31 15:01:47,855: Epoch 7/31 Batch 5200/7662 eta: 21:26:08.198510	Training Loss 0.8528 (0.8624)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.009)	
2022-03-31 15:01:47,856: ============================================================
2022-03-31 15:02:34,225: time cost, forward:0.1433253824587115, backward:0.03511674279513326, data cost:0.2605031535049096 
2022-03-31 15:02:34,225: ============================================================
2022-03-31 15:02:34,225: Epoch 7/31 Batch 5300/7662 eta: 23:59:24.284752	Training Loss 0.8562 (0.8622)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.009)	
2022-03-31 15:02:34,225: ============================================================
2022-03-31 15:03:18,011: time cost, forward:0.14325708238079185, backward:0.03507351928296896, data cost:0.26058556428991614 
2022-03-31 15:03:18,011: ============================================================
2022-03-31 15:03:18,011: Epoch 7/31 Batch 5400/7662 eta: 22:38:28.325423	Training Loss 0.8438 (0.8620)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.010)	
2022-03-31 15:03:18,012: ============================================================
2022-03-31 15:04:03,177: time cost, forward:0.14365681524080762, backward:0.03513883568846458, data cost:0.2603541333624657 
2022-03-31 15:04:03,178: ============================================================
2022-03-31 15:04:03,178: Epoch 7/31 Batch 5500/7662 eta: 23:20:32.440307	Training Loss 0.8561 (0.8618)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.195 (0.011)	
2022-03-31 15:04:03,178: ============================================================
2022-03-31 15:04:48,570: time cost, forward:0.14410763865050344, backward:0.03520332116871183, data cost:0.26008926112431674 
2022-03-31 15:04:48,570: ============================================================
2022-03-31 15:04:48,571: Epoch 7/31 Batch 5600/7662 eta: 23:26:48.115656	Training Loss 0.8478 (0.8617)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.012)	
2022-03-31 15:04:48,571: ============================================================
2022-03-31 15:05:32,006: time cost, forward:0.1439925852857738, backward:0.03521662570861667, data cost:0.26009503764674463 
2022-03-31 15:05:32,006: ============================================================
2022-03-31 15:05:32,007: Epoch 7/31 Batch 5700/7662 eta: 22:25:26.344248	Training Loss 0.8573 (0.8615)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.012)	
2022-03-31 15:05:32,007: ============================================================
2022-03-31 15:06:17,324: time cost, forward:0.14420767767015336, backward:0.03522832345543164, data cost:0.26008971688418087 
2022-03-31 15:06:17,325: ============================================================
2022-03-31 15:06:17,325: Epoch 7/31 Batch 5800/7662 eta: 23:22:59.770288	Training Loss 0.8436 (0.8613)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.013)	
2022-03-31 15:06:17,325: ============================================================
2022-03-31 15:07:05,083: time cost, forward:0.14471005839722745, backward:0.03523249766810059, data cost:0.260230335346176 
2022-03-31 15:07:05,084: ============================================================
2022-03-31 15:07:05,084: Epoch 7/31 Batch 5900/7662 eta: 1 day, 0:37:45.081125	Training Loss 0.8392 (0.8609)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.195 (0.015)	
2022-03-31 15:07:05,084: ============================================================
2022-03-31 15:07:48,275: time cost, forward:0.14459913681896355, backward:0.035215304243224804, data cost:0.26021973847110863 
2022-03-31 15:07:48,275: ============================================================
2022-03-31 15:07:48,275: Epoch 7/31 Batch 6000/7662 eta: 22:15:41.646477	Training Loss 0.8539 (0.8608)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.015)	
2022-03-31 15:07:48,276: ============================================================
2022-03-31 15:08:36,386: time cost, forward:0.14528596758901105, backward:0.03526549109436876, data cost:0.2601511072655118 
2022-03-31 15:08:36,387: ============================================================
2022-03-31 15:08:36,387: Epoch 7/31 Batch 6100/7662 eta: 1 day, 0:47:03.304337	Training Loss 0.8518 (0.8607)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.015)	
2022-03-31 15:08:36,387: ============================================================
2022-03-31 15:09:20,622: time cost, forward:0.14536432632228447, backward:0.035252652258272225, data cost:0.26010392373330093 
2022-03-31 15:09:20,622: ============================================================
2022-03-31 15:09:20,623: Epoch 7/31 Batch 6200/7662 eta: 22:46:31.433632	Training Loss 0.8495 (0.8605)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.015)	
2022-03-31 15:09:20,623: ============================================================
2022-03-31 15:10:07,019: time cost, forward:0.14570978763160639, backward:0.03527796486101939, data cost:0.260098582166474 
2022-03-31 15:10:07,020: ============================================================
2022-03-31 15:10:07,020: Epoch 7/31 Batch 6300/7662 eta: 23:52:31.516116	Training Loss 0.8425 (0.8602)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.015)	
2022-03-31 15:10:07,020: ============================================================
2022-03-31 15:10:51,791: time cost, forward:0.14582039438424435, backward:0.035282918486227784, data cost:0.2600828181357845 
2022-03-31 15:10:51,792: ============================================================
2022-03-31 15:10:51,792: Epoch 7/31 Batch 6400/7662 eta: 23:01:35.473899	Training Loss 0.8422 (0.8599)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.195 (0.016)	
2022-03-31 15:10:51,792: ============================================================
2022-03-31 15:11:36,947: time cost, forward:0.14591961465334596, backward:0.035294197030866455, data cost:0.2601248233350245 
2022-03-31 15:11:36,948: ============================================================
2022-03-31 15:11:36,948: Epoch 7/31 Batch 6500/7662 eta: 23:12:41.736142	Training Loss 0.8354 (0.8596)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.017)	
2022-03-31 15:11:36,948: ============================================================
2022-03-31 15:12:20,959: time cost, forward:0.14601924856931336, backward:0.03531147729521322, data cost:0.2599784843053469 
2022-03-31 15:12:20,960: ============================================================
2022-03-31 15:12:20,960: Epoch 7/31 Batch 6600/7662 eta: 22:36:41.006443	Training Loss 0.8366 (0.8593)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.195 (0.018)	
2022-03-31 15:12:20,960: ============================================================
2022-03-31 15:13:06,842: time cost, forward:0.14641698785176258, backward:0.03533946707953729, data cost:0.25979319001724693 
2022-03-31 15:13:06,843: ============================================================
2022-03-31 15:13:06,843: Epoch 7/31 Batch 6700/7662 eta: 23:33:35.066908	Training Loss 0.8372 (0.8589)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.195 (0.020)	
2022-03-31 15:13:06,843: ============================================================
2022-03-31 15:13:55,017: time cost, forward:0.1468188729000751, backward:0.03536931776548067, data cost:0.2599596893073776 
2022-03-31 15:13:55,017: ============================================================
2022-03-31 15:13:55,018: Epoch 7/31 Batch 6800/7662 eta: 1 day, 0:43:22.950641	Training Loss 0.8248 (0.8585)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.022)	
2022-03-31 15:13:55,018: ============================================================
2022-03-31 15:14:37,583: time cost, forward:0.1465825291194161, backward:0.03534153655467301, data cost:0.25998624440016377 
2022-03-31 15:14:37,583: ============================================================
2022-03-31 15:14:37,583: Epoch 7/31 Batch 6900/7662 eta: 21:49:58.273002	Training Loss 0.8206 (0.8580)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.195 (0.026)	
2022-03-31 15:14:37,584: ============================================================
2022-03-31 15:15:24,607: time cost, forward:0.14688760213365484, backward:0.035345122139357484, data cost:0.260076148831209 
2022-03-31 15:15:24,607: ============================================================
2022-03-31 15:15:24,607: Epoch 7/31 Batch 7000/7662 eta: 1 day, 0:06:22.782066	Training Loss 0.8407 (0.8576)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.195 (0.028)	
2022-03-31 15:15:24,607: ============================================================
2022-03-31 15:16:09,376: time cost, forward:0.14694516546945535, backward:0.03536071601359336, data cost:0.26007713376846026 
2022-03-31 15:16:09,376: ============================================================
2022-03-31 15:16:09,376: Epoch 7/31 Batch 7100/7662 eta: 22:56:17.024405	Training Loss 0.8345 (0.8573)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.195 (0.030)	
2022-03-31 15:16:09,376: ============================================================
2022-03-31 15:16:54,531: time cost, forward:0.14727135167583555, backward:0.03540183464873746, data cost:0.2598265878259018 
2022-03-31 15:16:54,532: ============================================================
2022-03-31 15:16:54,532: Epoch 7/31 Batch 7200/7662 eta: 23:07:24.489981	Training Loss 0.8144 (0.8568)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.391 (0.035)	
2022-03-31 15:16:54,532: ============================================================
2022-03-31 15:17:38,612: time cost, forward:0.14725234485975863, backward:0.03539527091347595, data cost:0.2598203807877325 
2022-03-31 15:17:38,613: ============================================================
2022-03-31 15:17:38,613: Epoch 7/31 Batch 7300/7662 eta: 22:33:39.737508	Training Loss 0.8082 (0.8561)	Training Prec@1 0.586 (0.012)	Training Prec@5 1.172 (0.047)	
2022-03-31 15:17:38,613: ============================================================
2022-03-31 15:18:24,541: time cost, forward:0.1474355511575764, backward:0.035395143772882616, data cost:0.2598577703490646 
2022-03-31 15:18:24,542: ============================================================
2022-03-31 15:18:24,542: Epoch 7/31 Batch 7400/7662 eta: 23:29:38.957597	Training Loss 0.7817 (0.8553)	Training Prec@1 1.172 (0.023)	Training Prec@5 3.516 (0.078)	
2022-03-31 15:18:24,542: ============================================================
2022-03-31 15:19:07,761: time cost, forward:0.14734569999882025, backward:0.035366883006377574, data cost:0.2598036080459735 
2022-03-31 15:19:07,761: ============================================================
2022-03-31 15:19:07,762: Epoch 7/31 Batch 7500/7662 eta: 22:05:46.460486	Training Loss 0.7736 (0.8543)	Training Prec@1 2.930 (0.049)	Training Prec@5 6.055 (0.144)	
2022-03-31 15:19:07,762: ============================================================
2022-03-31 15:19:54,491: time cost, forward:0.1475225175143951, backward:0.03536229040108475, data cost:0.259980172636572 
2022-03-31 15:19:54,492: ============================================================
2022-03-31 15:19:54,492: Epoch 7/31 Batch 7600/7662 eta: 23:52:40.760206	Training Loss 0.7561 (0.8531)	Training Prec@1 6.250 (0.101)	Training Prec@5 14.453 (0.259)	
2022-03-31 15:19:54,492: ============================================================
2022-03-31 15:20:24,696: Epoch: 7/31 eta: 23:52:11.320149	Training Loss 0.7503 (0.8523)	Training Prec@1 7.617 (0.155)	Training Prec@5 15.820 (0.366)
2022-03-31 15:20:24,697: ============================================================
2022-03-31 15:21:11,255: time cost, forward:0.16805302253877274, backward:0.03725531366136339, data cost:0.2605438521414092 
2022-03-31 15:21:11,256: ============================================================
2022-03-31 15:21:11,257: Epoch 8/31 Batch 100/7662 eta: 23:43:08.861992	Training Loss 0.7413 (0.7465)	Training Prec@1 10.938 (9.659)	Training Prec@5 20.117 (17.541)	
2022-03-31 15:21:11,258: ============================================================
2022-03-31 15:21:55,641: time cost, forward:0.15129138476884546, backward:0.03518171885504794, data cost:0.26840966310932407 
2022-03-31 15:21:55,642: ============================================================
2022-03-31 15:21:55,642: Epoch 8/31 Batch 200/7662 eta: 22:38:50.737079	Training Loss 0.7319 (0.7409)	Training Prec@1 12.500 (11.402)	Training Prec@5 20.312 (19.842)	
2022-03-31 15:21:55,642: ============================================================
2022-03-31 15:22:41,472: time cost, forward:0.15059712658757748, backward:0.03447656089246871, data cost:0.27051062488236954 
2022-03-31 15:22:41,472: ============================================================
2022-03-31 15:22:41,473: Epoch 8/31 Batch 300/7662 eta: 23:22:19.839166	Training Loss 0.7214 (0.7367)	Training Prec@1 16.992 (12.754)	Training Prec@5 26.562 (21.536)	
2022-03-31 15:22:41,473: ============================================================
2022-03-31 15:23:27,782: time cost, forward:0.15382736727109828, backward:0.03450129324929756, data cost:0.26923020202713205 
2022-03-31 15:23:27,782: ============================================================
2022-03-31 15:23:27,783: Epoch 8/31 Batch 400/7662 eta: 23:36:13.472751	Training Loss 0.7201 (0.7328)	Training Prec@1 14.453 (13.934)	Training Prec@5 27.344 (23.075)	
2022-03-31 15:23:27,783: ============================================================
2022-03-31 15:24:14,678: time cost, forward:0.15616524768974593, backward:0.03473531507060141, data cost:0.26881824227755435 
2022-03-31 15:24:14,679: ============================================================
2022-03-31 15:24:14,679: Epoch 8/31 Batch 500/7662 eta: 23:53:22.589727	Training Loss 0.8654 (0.7425)	Training Prec@1 0.000 (13.210)	Training Prec@5 0.000 (21.626)	
2022-03-31 15:24:14,679: ============================================================
2022-03-31 15:25:02,828: time cost, forward:0.15740173686923886, backward:0.0353831663752637, data cost:0.27039474835976934 
2022-03-31 15:25:02,828: ============================================================
2022-03-31 15:25:02,829: Epoch 8/31 Batch 600/7662 eta: 1 day, 0:30:53.428185	Training Loss 0.9638 (0.7613)	Training Prec@1 0.000 (11.005)	Training Prec@5 0.000 (18.016)	
2022-03-31 15:25:02,829: ============================================================
2022-03-31 15:25:50,374: time cost, forward:0.15922771775841885, backward:0.035950611248207365, data cost:0.26974883713947345 
2022-03-31 15:25:50,375: ============================================================
2022-03-31 15:25:50,375: Epoch 8/31 Batch 700/7662 eta: 1 day, 0:11:39.623270	Training Loss 0.8464 (0.7737)	Training Prec@1 0.000 (9.431)	Training Prec@5 0.000 (15.442)	
2022-03-31 15:25:50,375: ============================================================
2022-03-31 15:26:37,720: time cost, forward:0.1611270600176872, backward:0.03648388400692516, data cost:0.2683431039912829 
2022-03-31 15:26:37,721: ============================================================
2022-03-31 15:26:37,721: Epoch 8/31 Batch 800/7662 eta: 1 day, 0:04:44.951621	Training Loss 0.8477 (0.7827)	Training Prec@1 0.000 (8.252)	Training Prec@5 0.000 (13.512)	
2022-03-31 15:26:37,721: ============================================================
2022-03-31 15:27:24,956: time cost, forward:0.16151576471806103, backward:0.03663415399621406, data cost:0.26840509853851013 
2022-03-31 15:27:24,957: ============================================================
2022-03-31 15:27:24,957: Epoch 8/31 Batch 900/7662 eta: 1 day, 0:00:37.257860	Training Loss 0.8427 (0.7895)	Training Prec@1 0.000 (7.335)	Training Prec@5 0.000 (12.013)	
2022-03-31 15:27:24,957: ============================================================
2022-03-31 15:28:12,597: time cost, forward:0.16250999864037927, backward:0.03674711145318903, data cost:0.2683135038381582 
2022-03-31 15:28:12,598: ============================================================
2022-03-31 15:28:12,598: Epoch 8/31 Batch 1000/7662 eta: 1 day, 0:12:09.541144	Training Loss 0.8385 (0.7947)	Training Prec@1 0.000 (6.602)	Training Prec@5 0.000 (10.816)	
2022-03-31 15:28:12,598: ============================================================
2022-03-31 15:28:59,031: time cost, forward:0.16280515981436428, backward:0.036830584280484364, data cost:0.2675511121099054 
2022-03-31 15:28:59,031: ============================================================
2022-03-31 15:28:59,031: Epoch 8/31 Batch 1100/7662 eta: 23:34:35.236276	Training Loss 0.8380 (0.7988)	Training Prec@1 0.000 (6.001)	Training Prec@5 0.000 (9.835)	
2022-03-31 15:28:59,031: ============================================================
2022-03-31 15:29:50,076: time cost, forward:0.16479808276051577, backward:0.03694367806448153, data cost:0.2689779500746548 
2022-03-31 15:29:50,077: ============================================================
2022-03-31 15:29:50,077: Epoch 8/31 Batch 1200/7662 eta: 1 day, 1:54:14.503550	Training Loss 0.8274 (0.8019)	Training Prec@1 0.195 (5.503)	Training Prec@5 0.586 (9.024)	
2022-03-31 15:29:50,077: ============================================================
2022-03-31 15:30:38,222: time cost, forward:0.1657079745476938, backward:0.03704422193825291, data cost:0.26877202301230957 
2022-03-31 15:30:38,222: ============================================================
2022-03-31 15:30:38,223: Epoch 8/31 Batch 1300/7662 eta: 1 day, 0:25:09.378567	Training Loss 0.8287 (0.8043)	Training Prec@1 0.000 (5.081)	Training Prec@5 0.000 (8.335)	
2022-03-31 15:30:38,223: ============================================================
2022-03-31 15:31:24,754: time cost, forward:0.1650705928884292, backward:0.03705077055439598, data cost:0.26891919184446844 
2022-03-31 15:31:24,755: ============================================================
2022-03-31 15:31:24,755: Epoch 8/31 Batch 1400/7662 eta: 23:35:15.669781	Training Loss 0.8247 (0.8060)	Training Prec@1 0.000 (4.720)	Training Prec@5 0.000 (7.747)	
2022-03-31 15:31:24,755: ============================================================
2022-03-31 15:32:12,512: time cost, forward:0.16506612706454776, backward:0.037063234086192554, data cost:0.26932374328832137 
2022-03-31 15:32:12,512: ============================================================
2022-03-31 15:32:12,512: Epoch 8/31 Batch 1500/7662 eta: 1 day, 0:11:44.635281	Training Loss 0.8296 (0.8077)	Training Prec@1 0.000 (4.408)	Training Prec@5 0.195 (7.238)	
2022-03-31 15:32:12,513: ============================================================
2022-03-31 15:32:58,133: time cost, forward:0.16423564109301253, backward:0.0369434897939886, data cost:0.2693175330170995 
2022-03-31 15:32:58,133: ============================================================
2022-03-31 15:32:58,133: Epoch 8/31 Batch 1600/7662 eta: 23:06:01.890940	Training Loss 0.8245 (0.8089)	Training Prec@1 0.195 (4.135)	Training Prec@5 0.391 (6.795)	
2022-03-31 15:32:58,133: ============================================================
2022-03-31 15:33:46,814: time cost, forward:0.16490939436694185, backward:0.0370108717816798, data cost:0.26952827152187087 
2022-03-31 15:33:46,814: ============================================================
2022-03-31 15:33:46,814: Epoch 8/31 Batch 1700/7662 eta: 1 day, 0:38:11.791518	Training Loss 0.8262 (0.8104)	Training Prec@1 0.000 (3.893)	Training Prec@5 0.195 (6.401)	
2022-03-31 15:33:46,815: ============================================================
2022-03-31 15:34:32,622: time cost, forward:0.16459459553432837, backward:0.036971425267972834, data cost:0.2690963229581739 
2022-03-31 15:34:32,622: ============================================================
2022-03-31 15:34:32,623: Epoch 8/31 Batch 1800/7662 eta: 23:10:11.433472	Training Loss 0.8243 (0.8114)	Training Prec@1 0.586 (3.679)	Training Prec@5 0.586 (6.055)	
2022-03-31 15:34:32,623: ============================================================
2022-03-31 15:35:21,951: time cost, forward:0.16545176556262298, backward:0.0368846305236495, data cost:0.2695019885450366 
2022-03-31 15:35:21,951: ============================================================
2022-03-31 15:35:21,951: Epoch 8/31 Batch 1900/7662 eta: 1 day, 0:56:12.916870	Training Loss 0.8243 (0.8121)	Training Prec@1 0.000 (3.489)	Training Prec@5 0.391 (5.747)	
2022-03-31 15:35:21,951: ============================================================
2022-03-31 15:36:07,796: time cost, forward:0.16499070264864946, backward:0.036862006719378365, data cost:0.2692748821634481 
2022-03-31 15:36:07,797: ============================================================
2022-03-31 15:36:07,797: Epoch 8/31 Batch 2000/7662 eta: 23:09:47.744983	Training Loss 0.8584 (0.8126)	Training Prec@1 0.000 (3.317)	Training Prec@5 0.000 (5.472)	
2022-03-31 15:36:07,797: ============================================================
2022-03-31 15:36:56,221: time cost, forward:0.16482181751256672, backward:0.0368254051826408, data cost:0.2700946151557112 
2022-03-31 15:36:56,221: ============================================================
2022-03-31 15:36:56,222: Epoch 8/31 Batch 2100/7662 eta: 1 day, 0:27:11.248615	Training Loss 0.8357 (0.8140)	Training Prec@1 0.000 (3.159)	Training Prec@5 0.000 (5.214)	
2022-03-31 15:36:56,222: ============================================================
2022-03-31 15:37:45,416: time cost, forward:0.16535559574437717, backward:0.036875804373761534, data cost:0.2703844717059584 
2022-03-31 15:37:45,416: ============================================================
2022-03-31 15:37:45,416: Epoch 8/31 Batch 2200/7662 eta: 1 day, 0:49:41.129769	Training Loss 0.8321 (0.8150)	Training Prec@1 0.000 (3.016)	Training Prec@5 0.000 (4.980)	
2022-03-31 15:37:45,416: ============================================================
2022-03-31 15:38:30,777: time cost, forward:0.16441980990807664, backward:0.03675704294829433, data cost:0.2705912927069214 
2022-03-31 15:38:30,778: ============================================================
2022-03-31 15:38:30,778: Epoch 8/31 Batch 2300/7662 eta: 22:52:51.592991	Training Loss 0.8320 (0.8159)	Training Prec@1 0.000 (2.886)	Training Prec@5 0.000 (4.766)	
2022-03-31 15:38:30,778: ============================================================
2022-03-31 15:39:17,357: time cost, forward:0.16404374195367608, backward:0.03673781509844647, data cost:0.2707630232405096 
2022-03-31 15:39:17,358: ============================================================
2022-03-31 15:39:17,358: Epoch 8/31 Batch 2400/7662 eta: 23:28:57.952514	Training Loss 0.8308 (0.8166)	Training Prec@1 0.195 (2.766)	Training Prec@5 0.195 (4.571)	
2022-03-31 15:39:17,358: ============================================================
2022-03-31 15:40:06,640: time cost, forward:0.1646984986850575, backward:0.036828883794270885, data cost:0.270812539588742 
2022-03-31 15:40:06,640: ============================================================
2022-03-31 15:40:06,640: Epoch 8/31 Batch 2500/7662 eta: 1 day, 0:49:52.655137	Training Loss 0.8277 (0.8172)	Training Prec@1 0.000 (2.657)	Training Prec@5 0.000 (4.394)	
2022-03-31 15:40:06,640: ============================================================
2022-03-31 15:40:55,222: time cost, forward:0.1657523801575353, backward:0.036930141654460416, data cost:0.27019459350882424 
2022-03-31 15:40:55,223: ============================================================
2022-03-31 15:40:55,223: Epoch 8/31 Batch 2600/7662 eta: 1 day, 0:27:55.138574	Training Loss 0.8206 (0.8175)	Training Prec@1 0.000 (2.557)	Training Prec@5 0.000 (4.232)	
2022-03-31 15:40:55,223: ============================================================
2022-03-31 15:41:43,791: time cost, forward:0.16589370176676424, backward:0.036895562560967314, data cost:0.2705133155612161 
2022-03-31 15:41:43,792: ============================================================
2022-03-31 15:41:43,792: Epoch 8/31 Batch 2700/7662 eta: 1 day, 0:26:41.670301	Training Loss 0.8326 (0.8177)	Training Prec@1 0.000 (2.464)	Training Prec@5 0.000 (4.084)	
2022-03-31 15:41:43,792: ============================================================
2022-03-31 15:42:32,856: time cost, forward:0.16679964443750575, backward:0.03692816691383288, data cost:0.27020136174579823 
2022-03-31 15:42:32,857: ============================================================
2022-03-31 15:42:32,857: Epoch 8/31 Batch 2800/7662 eta: 1 day, 0:40:51.611975	Training Loss 0.8247 (0.8181)	Training Prec@1 0.000 (2.378)	Training Prec@5 0.195 (3.944)	
2022-03-31 15:42:32,857: ============================================================
2022-03-31 15:43:19,916: time cost, forward:0.16663994744713037, backward:0.036803446625298, data cost:0.27033507754038677 
2022-03-31 15:43:19,916: ============================================================
2022-03-31 15:43:19,917: Epoch 8/31 Batch 2900/7662 eta: 23:39:32.136961	Training Loss 0.8256 (0.8183)	Training Prec@1 0.000 (2.298)	Training Prec@5 0.000 (3.817)	
2022-03-31 15:43:19,917: ============================================================
2022-03-31 15:44:09,709: time cost, forward:0.16676974940514636, backward:0.03675700339049886, data cost:0.2710802322151105 
2022-03-31 15:44:09,710: ============================================================
2022-03-31 15:44:09,710: Epoch 8/31 Batch 3000/7662 eta: 1 day, 1:01:11.284985	Training Loss 0.8131 (0.8183)	Training Prec@1 0.000 (2.226)	Training Prec@5 0.000 (3.704)	
2022-03-31 15:44:09,710: ============================================================
2022-03-31 15:44:58,876: time cost, forward:0.16771276684182812, backward:0.03665899868817743, data cost:0.27076240499852816 
2022-03-31 15:44:58,877: ============================================================
2022-03-31 15:44:58,877: Epoch 8/31 Batch 3100/7662 eta: 1 day, 0:41:28.343678	Training Loss 0.8111 (0.8185)	Training Prec@1 0.000 (2.156)	Training Prec@5 1.172 (3.593)	
2022-03-31 15:44:58,877: ============================================================
2022-03-31 15:45:47,457: time cost, forward:0.16849133989966708, backward:0.03670917156525946, data cost:0.2702557064287735 
2022-03-31 15:45:47,458: ============================================================
2022-03-31 15:45:47,458: Epoch 8/31 Batch 3200/7662 eta: 1 day, 0:23:00.322932	Training Loss 0.8264 (0.8182)	Training Prec@1 0.195 (2.097)	Training Prec@5 0.391 (3.508)	
2022-03-31 15:45:47,458: ============================================================
2022-03-31 15:46:35,212: time cost, forward:0.16912964670251232, backward:0.03666605932057066, data cost:0.2697125698949901 
2022-03-31 15:46:35,212: ============================================================
2022-03-31 15:46:35,212: Epoch 8/31 Batch 3300/7662 eta: 23:57:19.030261	Training Loss 0.7901 (0.8179)	Training Prec@1 0.586 (2.045)	Training Prec@5 1.758 (3.436)	
2022-03-31 15:46:35,212: ============================================================
2022-03-31 15:47:26,242: time cost, forward:0.16968394602421769, backward:0.03667907260312302, data cost:0.27014858465259234 
2022-03-31 15:47:26,242: ============================================================
2022-03-31 15:47:26,242: Epoch 8/31 Batch 3400/7662 eta: 1 day, 1:35:03.695436	Training Loss 0.7754 (0.8170)	Training Prec@1 1.953 (2.020)	Training Prec@5 6.250 (3.428)	
2022-03-31 15:47:26,243: ============================================================
2022-03-31 15:48:13,221: time cost, forward:0.16999662539113347, backward:0.03669524560760995, data cost:0.2695852265626439 
2022-03-31 15:48:13,222: ============================================================
2022-03-31 15:48:13,222: Epoch 8/31 Batch 3500/7662 eta: 23:32:25.734663	Training Loss 0.7613 (0.8156)	Training Prec@1 5.273 (2.069)	Training Prec@5 12.109 (3.568)	
2022-03-31 15:48:13,222: ============================================================
2022-03-31 15:48:59,785: time cost, forward:0.1697001821566171, backward:0.03670366872314216, data cost:0.2695996415519025 
2022-03-31 15:48:59,785: ============================================================
2022-03-31 15:48:59,785: Epoch 8/31 Batch 3600/7662 eta: 23:19:09.016680	Training Loss 0.7397 (0.8138)	Training Prec@1 11.523 (2.251)	Training Prec@5 19.727 (3.914)	
2022-03-31 15:48:59,786: ============================================================
2022-03-31 15:49:49,020: time cost, forward:0.17024106127276684, backward:0.03676947454208617, data cost:0.26941812731311526 
2022-03-31 15:49:49,020: ============================================================
2022-03-31 15:49:49,021: Epoch 8/31 Batch 3700/7662 eta: 1 day, 0:38:36.236543	Training Loss 0.7346 (0.8117)	Training Prec@1 14.453 (2.523)	Training Prec@5 19.922 (4.377)	
2022-03-31 15:49:49,021: ============================================================
2022-03-31 15:50:38,098: time cost, forward:0.17046578735638745, backward:0.036815869491267875, data cost:0.26951569643545287 
2022-03-31 15:50:38,098: ============================================================
2022-03-31 15:50:38,098: Epoch 8/31 Batch 3800/7662 eta: 1 day, 0:33:03.740345	Training Loss 0.8844 (0.8110)	Training Prec@1 0.000 (2.622)	Training Prec@5 0.000 (4.545)	
2022-03-31 15:50:38,099: ============================================================
2022-03-31 15:51:27,144: time cost, forward:0.17099465654886328, backward:0.03682496352634787, data cost:0.2692916055128005 
2022-03-31 15:51:27,144: ============================================================
2022-03-31 15:51:27,145: Epoch 8/31 Batch 3900/7662 eta: 1 day, 0:31:17.966674	Training Loss 0.8502 (0.8122)	Training Prec@1 0.000 (2.555)	Training Prec@5 0.000 (4.428)	
2022-03-31 15:51:27,145: ============================================================
2022-03-31 15:52:14,951: time cost, forward:0.17096677181809566, backward:0.03677966046792384, data cost:0.26938053899241793 
2022-03-31 15:52:14,951: ============================================================
2022-03-31 15:52:14,951: Epoch 8/31 Batch 4000/7662 eta: 23:53:19.075607	Training Loss 0.8448 (0.8131)	Training Prec@1 0.000 (2.492)	Training Prec@5 0.195 (4.319)	
2022-03-31 15:52:14,952: ============================================================
2022-03-31 15:53:05,435: time cost, forward:0.17152437247075986, backward:0.03681928455960492, data cost:0.2694445915063959 
2022-03-31 15:53:05,435: ============================================================
2022-03-31 15:53:05,436: Epoch 8/31 Batch 4100/7662 eta: 1 day, 1:12:44.977042	Training Loss 0.8396 (0.8138)	Training Prec@1 0.000 (2.431)	Training Prec@5 0.000 (4.215)	
2022-03-31 15:53:05,436: ============================================================
2022-03-31 15:53:54,251: time cost, forward:0.1719637806854466, backward:0.03682775433843095, data cost:0.26924936866215166 
2022-03-31 15:53:54,252: ============================================================
2022-03-31 15:53:54,252: Epoch 8/31 Batch 4200/7662 eta: 1 day, 0:21:57.547288	Training Loss 0.8318 (0.8143)	Training Prec@1 0.195 (2.374)	Training Prec@5 0.391 (4.116)	
2022-03-31 15:53:54,252: ============================================================
2022-03-31 15:54:43,100: time cost, forward:0.1725334381330676, backward:0.03679454545692999, data cost:0.26892821925771765 
2022-03-31 15:54:43,100: ============================================================
2022-03-31 15:54:43,101: Epoch 8/31 Batch 4300/7662 eta: 1 day, 0:22:07.374478	Training Loss 0.8258 (0.8147)	Training Prec@1 0.000 (2.320)	Training Prec@5 0.000 (4.024)	
2022-03-31 15:54:43,101: ============================================================
2022-03-31 15:55:31,222: time cost, forward:0.1724826987696442, backward:0.0367650753748799, data cost:0.26908259631341414 
2022-03-31 15:55:31,222: ============================================================
2022-03-31 15:55:31,222: Epoch 8/31 Batch 4400/7662 eta: 23:59:32.629700	Training Loss 0.8255 (0.8150)	Training Prec@1 0.000 (2.268)	Training Prec@5 0.000 (3.936)	
2022-03-31 15:55:31,223: ============================================================
2022-03-31 15:56:18,580: time cost, forward:0.17225230601290167, backward:0.03671622451185306, data cost:0.2692359802218961 
2022-03-31 15:56:18,580: ============================================================
2022-03-31 15:56:18,580: Epoch 8/31 Batch 4500/7662 eta: 23:35:54.934912	Training Loss 0.8231 (0.8152)	Training Prec@1 0.000 (2.218)	Training Prec@5 0.195 (3.852)	
2022-03-31 15:56:18,581: ============================================================
2022-03-31 15:57:08,039: time cost, forward:0.17286840037797735, backward:0.03676032999282973, data cost:0.26893624354248646 
2022-03-31 15:57:08,040: ============================================================
2022-03-31 15:57:08,040: Epoch 8/31 Batch 4600/7662 eta: 1 day, 0:37:56.289028	Training Loss 0.8217 (0.8154)	Training Prec@1 0.195 (2.171)	Training Prec@5 0.195 (3.774)	
2022-03-31 15:57:08,040: ============================================================
2022-03-31 15:57:57,826: time cost, forward:0.1730211004852665, backward:0.03676329427233248, data cost:0.2691487408516432 
2022-03-31 15:57:57,826: ============================================================
2022-03-31 15:57:57,827: Epoch 8/31 Batch 4700/7662 eta: 1 day, 0:46:51.793452	Training Loss 0.8195 (0.8155)	Training Prec@1 0.000 (2.128)	Training Prec@5 0.195 (3.701)	
2022-03-31 15:57:57,827: ============================================================
2022-03-31 15:58:44,433: time cost, forward:0.17269985102991134, backward:0.036726481866329805, data cost:0.26926776542592035 
2022-03-31 15:58:44,434: ============================================================
2022-03-31 15:58:44,434: Epoch 8/31 Batch 4800/7662 eta: 23:11:08.942105	Training Loss 0.8104 (0.8155)	Training Prec@1 0.000 (2.086)	Training Prec@5 0.586 (3.635)	
2022-03-31 15:58:44,434: ============================================================
2022-03-31 15:59:32,739: time cost, forward:0.1731803007431482, backward:0.036715204410588016, data cost:0.26887037662078617 
2022-03-31 15:59:32,740: ============================================================
2022-03-31 15:59:32,740: Epoch 8/31 Batch 4900/7662 eta: 1 day, 0:01:01.858762	Training Loss 0.8359 (0.8155)	Training Prec@1 0.000 (2.047)	Training Prec@5 0.000 (3.570)	
2022-03-31 15:59:32,740: ============================================================
2022-03-31 16:00:21,230: time cost, forward:0.17329749128155097, backward:0.03663933732600707, data cost:0.2689271160163124 
2022-03-31 16:00:21,231: ============================================================
2022-03-31 16:00:21,231: Epoch 8/31 Batch 5000/7662 eta: 1 day, 0:05:44.919866	Training Loss 0.8067 (0.8155)	Training Prec@1 0.781 (2.012)	Training Prec@5 0.781 (3.516)	
2022-03-31 16:00:21,231: ============================================================
2022-03-31 16:01:10,493: time cost, forward:0.17375551197757486, backward:0.03661897603753362, data cost:0.2687181125180023 
2022-03-31 16:01:10,493: ============================================================
2022-03-31 16:01:10,493: Epoch 8/31 Batch 5100/7662 eta: 1 day, 0:27:55.922259	Training Loss 0.7703 (0.8148)	Training Prec@1 3.320 (2.013)	Training Prec@5 8.789 (3.542)	
2022-03-31 16:01:10,493: ============================================================
2022-03-31 16:01:58,875: time cost, forward:0.17403155071136012, backward:0.03661500102947666, data cost:0.2685773446482405 
2022-03-31 16:01:58,876: ============================================================
2022-03-31 16:01:58,876: Epoch 8/31 Batch 5200/7662 eta: 1 day, 0:00:54.349303	Training Loss 0.7499 (0.8137)	Training Prec@1 8.594 (2.107)	Training Prec@5 16.602 (3.735)	
2022-03-31 16:01:58,876: ============================================================
2022-03-31 16:02:49,687: time cost, forward:0.17429957634594154, backward:0.036647156828595776, data cost:0.2688058669397484 
2022-03-31 16:02:49,688: ============================================================
2022-03-31 16:02:49,688: Epoch 8/31 Batch 5300/7662 eta: 1 day, 1:12:24.606553	Training Loss 0.7369 (0.8123)	Training Prec@1 11.133 (2.279)	Training Prec@5 19.922 (4.030)	
2022-03-31 16:02:49,688: ============================================================
2022-03-31 16:03:40,050: time cost, forward:0.17470927674762848, backward:0.036690942533238326, data cost:0.2687626732435684 
2022-03-31 16:03:40,050: ============================================================
2022-03-31 16:03:40,050: Epoch 8/31 Batch 5400/7662 eta: 1 day, 0:58:11.417854	Training Loss 0.7410 (0.8109)	Training Prec@1 12.500 (2.473)	Training Prec@5 20.117 (4.346)	
2022-03-31 16:03:40,050: ============================================================
2022-03-31 16:04:32,076: time cost, forward:0.17549341634135396, backward:0.03675595069499553, data cost:0.2686629037376663 
2022-03-31 16:04:32,077: ============================================================
2022-03-31 16:04:32,077: Epoch 8/31 Batch 5500/7662 eta: 1 day, 1:46:49.737222	Training Loss 0.7296 (0.8094)	Training Prec@1 14.844 (2.707)	Training Prec@5 23.047 (4.714)	
2022-03-31 16:04:32,077: ============================================================
2022-03-31 16:05:21,768: time cost, forward:0.17588807272259563, backward:0.03676571048015057, data cost:0.2685319868064944 
2022-03-31 16:05:21,768: ============================================================
2022-03-31 16:05:21,769: Epoch 8/31 Batch 5600/7662 eta: 1 day, 0:36:34.755491	Training Loss 0.7165 (0.8079)	Training Prec@1 19.141 (2.966)	Training Prec@5 28.125 (5.109)	
2022-03-31 16:05:21,769: ============================================================
2022-03-31 16:06:09,684: time cost, forward:0.17608246051924212, backward:0.03678012517569964, data cost:0.2682774455573689 
2022-03-31 16:06:09,684: ============================================================
2022-03-31 16:06:09,684: Epoch 8/31 Batch 5700/7662 eta: 23:43:00.347286	Training Loss 0.8405 (0.8083)	Training Prec@1 0.000 (2.966)	Training Prec@5 0.000 (5.104)	
2022-03-31 16:06:09,684: ============================================================
2022-03-31 16:07:00,808: time cost, forward:0.17667612504868657, backward:0.03680614858562524, data cost:0.26817182208530077 
2022-03-31 16:07:00,808: ============================================================
2022-03-31 16:07:00,808: Epoch 8/31 Batch 5800/7662 eta: 1 day, 1:17:26.323666	Training Loss 0.7571 (0.8083)	Training Prec@1 8.203 (2.940)	Training Prec@5 13.477 (5.066)	
2022-03-31 16:07:00,808: ============================================================
2022-03-31 16:07:51,326: time cost, forward:0.1769728710700302, backward:0.03680899143623162, data cost:0.2682714899185654 
2022-03-31 16:07:51,327: ============================================================
2022-03-31 16:07:51,327: Epoch 8/31 Batch 5900/7662 eta: 1 day, 0:58:37.232237	Training Loss 0.7309 (0.8071)	Training Prec@1 15.430 (3.112)	Training Prec@5 25.195 (5.344)	
2022-03-31 16:07:51,327: ============================================================
2022-03-31 16:08:40,791: time cost, forward:0.1771816515409861, backward:0.03681093912399656, data cost:0.2682465344076257 
2022-03-31 16:08:40,791: ============================================================
2022-03-31 16:08:40,791: Epoch 8/31 Batch 6000/7662 eta: 1 day, 0:26:31.928068	Training Loss 0.7126 (0.8057)	Training Prec@1 19.922 (3.346)	Training Prec@5 29.492 (5.699)	
2022-03-31 16:08:40,791: ============================================================
2022-03-31 16:09:31,660: time cost, forward:0.1776358197802187, backward:0.03682262292747166, data cost:0.2682068641507483 
2022-03-31 16:09:31,661: ============================================================
2022-03-31 16:09:31,661: Epoch 8/31 Batch 6100/7662 eta: 1 day, 1:07:20.501957	Training Loss 0.7061 (0.8042)	Training Prec@1 23.828 (3.609)	Training Prec@5 35.156 (6.087)	
2022-03-31 16:09:31,661: ============================================================
2022-03-31 16:10:20,769: time cost, forward:0.17794718394684858, backward:0.03683572427786864, data cost:0.26801558143959103 
2022-03-31 16:10:20,770: ============================================================
2022-03-31 16:10:20,770: Epoch 8/31 Batch 6200/7662 eta: 1 day, 0:14:21.594705	Training Loss 0.7044 (0.8027)	Training Prec@1 20.898 (3.884)	Training Prec@5 31.055 (6.486)	
2022-03-31 16:10:20,770: ============================================================
2022-03-31 16:11:10,907: time cost, forward:0.17824301622768945, backward:0.03685006419331862, data cost:0.267924292349857 
2022-03-31 16:11:10,908: ============================================================
2022-03-31 16:11:10,908: Epoch 8/31 Batch 6300/7662 eta: 1 day, 0:43:59.647783	Training Loss 0.6999 (0.8012)	Training Prec@1 23.438 (4.174)	Training Prec@5 34.180 (6.894)	
2022-03-31 16:11:10,908: ============================================================
2022-03-31 16:11:59,918: time cost, forward:0.17850079169812139, backward:0.03688231168789572, data cost:0.26780877241512296 
2022-03-31 16:11:59,918: ============================================================
2022-03-31 16:11:59,919: Epoch 8/31 Batch 6400/7662 eta: 1 day, 0:09:48.573372	Training Loss 0.7032 (0.7997)	Training Prec@1 21.680 (4.468)	Training Prec@5 32.031 (7.309)	
2022-03-31 16:11:59,919: ============================================================
2022-03-31 16:12:52,437: time cost, forward:0.17912081388862963, backward:0.03693508922109092, data cost:0.26776750994968607 
2022-03-31 16:12:52,437: ============================================================
2022-03-31 16:12:52,438: Epoch 8/31 Batch 6500/7662 eta: 1 day, 1:52:42.528915	Training Loss 0.7071 (0.7981)	Training Prec@1 19.336 (4.770)	Training Prec@5 32.031 (7.725)	
2022-03-31 16:12:52,438: ============================================================
2022-03-31 16:13:42,598: time cost, forward:0.1794265981406258, backward:0.036947087060865046, data cost:0.26771904031586186 
2022-03-31 16:13:42,599: ============================================================
2022-03-31 16:13:42,599: Epoch 8/31 Batch 6600/7662 eta: 1 day, 0:42:10.964141	Training Loss 0.8169 (0.7981)	Training Prec@1 0.586 (4.807)	Training Prec@5 1.172 (7.766)	
2022-03-31 16:13:42,599: ============================================================
2022-03-31 16:14:32,486: time cost, forward:0.17977239064519698, backward:0.03693106765621793, data cost:0.26761002511404436 
2022-03-31 16:14:32,486: ============================================================
2022-03-31 16:14:32,486: Epoch 8/31 Batch 6700/7662 eta: 1 day, 0:33:14.783098	Training Loss 0.8806 (0.7996)	Training Prec@1 0.000 (4.736)	Training Prec@5 0.000 (7.653)	
2022-03-31 16:14:32,487: ============================================================
2022-03-31 16:15:23,504: time cost, forward:0.18023677415086128, backward:0.03696525403727046, data cost:0.26747125284621637 
2022-03-31 16:15:23,504: ============================================================
2022-03-31 16:15:23,504: Epoch 8/31 Batch 6800/7662 eta: 1 day, 1:05:47.260754	Training Loss 0.8678 (0.8007)	Training Prec@1 0.000 (4.666)	Training Prec@5 0.000 (7.541)	
2022-03-31 16:15:23,505: ============================================================
2022-03-31 16:16:12,638: time cost, forward:0.1803989652654955, backward:0.03697910362749035, data cost:0.2673871950198471 
2022-03-31 16:16:12,639: ============================================================
2022-03-31 16:16:12,639: Epoch 8/31 Batch 6900/7662 eta: 1 day, 0:09:22.392298	Training Loss 0.8605 (0.8016)	Training Prec@1 0.000 (4.598)	Training Prec@5 0.000 (7.431)	
2022-03-31 16:16:12,639: ============================================================
2022-03-31 16:17:03,624: time cost, forward:0.180807053932106, backward:0.03700156742580483, data cost:0.2673169809982664 
2022-03-31 16:17:03,624: ============================================================
2022-03-31 16:17:03,624: Epoch 8/31 Batch 7000/7662 eta: 1 day, 1:03:07.886344	Training Loss 0.8577 (0.8024)	Training Prec@1 0.000 (4.533)	Training Prec@5 0.000 (7.325)	
2022-03-31 16:17:03,625: ============================================================
2022-03-31 16:17:54,413: time cost, forward:0.18111712473482292, backward:0.036940282525302896, data cost:0.26738008879862935 
2022-03-31 16:17:54,414: ============================================================
2022-03-31 16:17:54,414: Epoch 8/31 Batch 7100/7662 eta: 1 day, 0:56:30.601102	Training Loss 0.8534 (0.8031)	Training Prec@1 0.000 (4.469)	Training Prec@5 0.000 (7.222)	
2022-03-31 16:17:54,414: ============================================================
2022-03-31 16:18:44,898: time cost, forward:0.18127932027241045, backward:0.036957406984433346, data cost:0.26746170115745765 
2022-03-31 16:18:44,898: ============================================================
2022-03-31 16:18:44,898: Epoch 8/31 Batch 7200/7662 eta: 1 day, 0:46:40.227816	Training Loss 0.8533 (0.8038)	Training Prec@1 0.000 (4.407)	Training Prec@5 0.000 (7.122)	
2022-03-31 16:18:44,899: ============================================================
2022-03-31 16:19:37,717: time cost, forward:0.18177225978787034, backward:0.036976674498393286, data cost:0.267519976802355 
2022-03-31 16:19:37,717: ============================================================
2022-03-31 16:19:37,718: Epoch 8/31 Batch 7300/7662 eta: 1 day, 1:54:32.953153	Training Loss 0.8513 (0.8044)	Training Prec@1 0.000 (4.346)	Training Prec@5 0.000 (7.025)	
2022-03-31 16:19:37,718: ============================================================
2022-03-31 16:20:28,875: time cost, forward:0.1822403282519208, backward:0.03700216800268477, data cost:0.2673617145921398 
2022-03-31 16:20:28,875: ============================================================
2022-03-31 16:20:28,875: Epoch 8/31 Batch 7400/7662 eta: 1 day, 1:04:47.564726	Training Loss 0.8477 (0.8051)	Training Prec@1 0.000 (4.288)	Training Prec@5 0.000 (6.930)	
2022-03-31 16:20:28,876: ============================================================
2022-03-31 16:21:16,994: time cost, forward:0.1822591984585168, backward:0.0369979330564693, data cost:0.2672769177006092 
2022-03-31 16:21:16,995: ============================================================
2022-03-31 16:21:16,995: Epoch 8/31 Batch 7500/7662 eta: 23:34:37.655272	Training Loss 0.8508 (0.8057)	Training Prec@1 0.000 (4.231)	Training Prec@5 0.000 (6.837)	
2022-03-31 16:21:16,995: ============================================================
2022-03-31 16:22:05,179: time cost, forward:0.1820503163767545, backward:0.03698964535617439, data cost:0.2674276526624677 
2022-03-31 16:22:05,179: ============================================================
2022-03-31 16:22:05,180: Epoch 8/31 Batch 7600/7662 eta: 23:35:44.643556	Training Loss 0.8515 (0.8063)	Training Prec@1 0.000 (4.175)	Training Prec@5 0.000 (6.747)	
2022-03-31 16:22:05,180: ============================================================
2022-03-31 16:22:36,469: Epoch: 8/31 eta: 23:35:14.287081	Training Loss 0.8515 (0.8066)	Training Prec@1 0.000 (4.141)	Training Prec@5 0.000 (6.692)
2022-03-31 16:22:36,469: ============================================================
2022-03-31 16:23:25,153: time cost, forward:0.17549815804067284, backward:0.03539266489972972, data cost:0.2764241406411836 
2022-03-31 16:23:25,154: ============================================================
2022-03-31 16:23:25,154: Epoch 9/31 Batch 100/7662 eta: 23:45:45.349053	Training Loss 0.8503 (0.8498)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.008)	
2022-03-31 16:23:25,154: ============================================================
2022-03-31 16:24:13,891: time cost, forward:0.18223056002477905, backward:0.03636229697184347, data cost:0.26842755648358985 
2022-03-31 16:24:13,891: ============================================================
2022-03-31 16:24:13,891: Epoch 9/31 Batch 200/7662 eta: 23:49:50.661719	Training Loss 0.8513 (0.8500)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.009)	
2022-03-31 16:24:13,892: ============================================================
2022-03-31 16:25:03,409: time cost, forward:0.18596785921715575, backward:0.03700777120813478, data cost:0.2669021166287936 
2022-03-31 16:25:03,409: ============================================================
2022-03-31 16:25:03,409: Epoch 9/31 Batch 300/7662 eta: 1 day, 0:11:55.206175	Training Loss 0.8518 (0.8501)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.008)	
2022-03-31 16:25:03,409: ============================================================
2022-03-31 16:25:51,671: time cost, forward:0.1804035164061047, backward:0.03666643869309198, data cost:0.2707369793626599 
2022-03-31 16:25:51,671: ============================================================
2022-03-31 16:25:51,671: Epoch 9/31 Batch 400/7662 eta: 23:34:17.543466	Training Loss 0.8500 (0.8502)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.007)	
2022-03-31 16:25:51,671: ============================================================
2022-03-31 16:26:41,223: time cost, forward:0.18348981622225774, backward:0.036978504700746706, data cost:0.26865229577960853 
2022-03-31 16:26:41,223: ============================================================
2022-03-31 16:26:41,223: Epoch 9/31 Batch 500/7662 eta: 1 day, 0:11:16.543938	Training Loss 0.8510 (0.8503)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.007)	
2022-03-31 16:26:41,224: ============================================================
2022-03-31 16:27:33,063: time cost, forward:0.18773779964606233, backward:0.037312753212471836, data cost:0.26889378359799393 
2022-03-31 16:27:33,064: ============================================================
2022-03-31 16:27:33,064: Epoch 9/31 Batch 600/7662 eta: 1 day, 1:17:25.619518	Training Loss 0.8510 (0.8505)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.006)	
2022-03-31 16:27:33,064: ============================================================
2022-03-31 16:28:22,500: time cost, forward:0.1872836967053502, backward:0.03722598931308468, data cost:0.26962500785041776 
2022-03-31 16:28:22,501: ============================================================
2022-03-31 16:28:22,501: Epoch 9/31 Batch 700/7662 eta: 1 day, 0:06:15.800724	Training Loss 0.8519 (0.8506)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.006)	
2022-03-31 16:28:22,501: ============================================================
2022-03-31 16:29:12,553: time cost, forward:0.1856248841267802, backward:0.0373290280376716, data cost:0.27177178098800336 
2022-03-31 16:29:12,554: ============================================================
2022-03-31 16:29:12,554: Epoch 9/31 Batch 800/7662 eta: 1 day, 0:23:26.179305	Training Loss 0.8523 (0.8507)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.007)	
2022-03-31 16:29:12,554: ============================================================
2022-03-31 16:30:01,517: time cost, forward:0.18585794070140937, backward:0.03740858739952622, data cost:0.27085762930924157 
2022-03-31 16:30:01,517: ============================================================
2022-03-31 16:30:01,517: Epoch 9/31 Batch 900/7662 eta: 23:50:46.223981	Training Loss 0.8552 (0.8508)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.007)	
2022-03-31 16:30:01,517: ============================================================
2022-03-31 16:30:52,630: time cost, forward:0.18723694197050444, backward:0.037525839514441196, data cost:0.2709790741478478 
2022-03-31 16:30:52,630: ============================================================
2022-03-31 16:30:52,631: Epoch 9/31 Batch 1000/7662 eta: 1 day, 0:52:44.010316	Training Loss 0.8531 (0.8509)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.007)	
2022-03-31 16:30:52,631: ============================================================
2022-03-31 16:31:42,308: time cost, forward:0.1876841240085397, backward:0.03768416683276856, data cost:0.2704492949484911 
2022-03-31 16:31:42,308: ============================================================
2022-03-31 16:31:42,308: Epoch 9/31 Batch 1100/7662 eta: 1 day, 0:09:59.307089	Training Loss 0.8527 (0.8510)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.007)	
2022-03-31 16:31:42,308: ============================================================
2022-03-31 16:32:33,222: time cost, forward:0.1884717161800585, backward:0.03783463477292987, data cost:0.2706087075043361 
2022-03-31 16:32:33,223: ============================================================
2022-03-31 16:32:33,223: Epoch 9/31 Batch 1200/7662 eta: 1 day, 0:45:13.949568	Training Loss 0.8533 (0.8511)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.008)	
2022-03-31 16:32:33,223: ============================================================
2022-03-31 16:33:22,412: time cost, forward:0.18867340924833442, backward:0.037840553023798636, data cost:0.2700108250257508 
2022-03-31 16:33:22,412: ============================================================
2022-03-31 16:33:22,412: Epoch 9/31 Batch 1300/7662 eta: 23:54:05.690137	Training Loss 0.8528 (0.8512)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.008)	
2022-03-31 16:33:22,412: ============================================================
2022-03-31 16:34:12,240: time cost, forward:0.18792020277605473, backward:0.03768054292063955, data cost:0.2709077508897761 
2022-03-31 16:34:12,241: ============================================================
2022-03-31 16:34:12,241: Epoch 9/31 Batch 1400/7662 eta: 1 day, 0:11:53.883079	Training Loss 0.8536 (0.8513)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.008)	
2022-03-31 16:34:12,241: ============================================================
2022-03-31 16:35:04,711: time cost, forward:0.18925481179780052, backward:0.037699713875565075, data cost:0.27146488877437047 
2022-03-31 16:35:04,711: ============================================================
2022-03-31 16:35:04,712: Epoch 9/31 Batch 1500/7662 eta: 1 day, 1:28:00.595010	Training Loss 0.8518 (0.8514)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 16:35:04,712: ============================================================
2022-03-31 16:35:55,110: time cost, forward:0.18999879132068626, backward:0.037766743630748605, data cost:0.27097560197879106 
2022-03-31 16:35:55,111: ============================================================
2022-03-31 16:35:55,111: Epoch 9/31 Batch 1600/7662 eta: 1 day, 0:26:50.500171	Training Loss 0.8551 (0.8515)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 16:35:55,111: ============================================================
2022-03-31 16:36:47,002: time cost, forward:0.1915764341359983, backward:0.037897095952474626, data cost:0.27048833556846 
2022-03-31 16:36:47,003: ============================================================
2022-03-31 16:36:47,003: Epoch 9/31 Batch 1700/7662 eta: 1 day, 1:09:25.952727	Training Loss 0.8532 (0.8516)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 16:36:47,004: ============================================================
2022-03-31 16:37:35,546: time cost, forward:0.1907819291497019, backward:0.037889817080410275, data cost:0.270453804131678 
2022-03-31 16:37:35,547: ============================================================
2022-03-31 16:37:35,547: Epoch 9/31 Batch 1800/7662 eta: 23:31:13.394004	Training Loss 0.8530 (0.8517)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 16:37:35,547: ============================================================
2022-03-31 16:38:23,868: time cost, forward:0.1905084562778724, backward:0.03793906801433674, data cost:0.2696921947191991 
2022-03-31 16:38:23,868: ============================================================
2022-03-31 16:38:23,868: Epoch 9/31 Batch 1900/7662 eta: 23:23:57.672870	Training Loss 0.8511 (0.8517)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 16:38:23,869: ============================================================
2022-03-31 16:39:13,247: time cost, forward:0.19018142207853195, backward:0.03760437013627053, data cost:0.27021346526363005 
2022-03-31 16:39:13,248: ============================================================
2022-03-31 16:39:13,248: Epoch 9/31 Batch 2000/7662 eta: 23:53:52.432528	Training Loss 0.8549 (0.8518)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 16:39:13,248: ============================================================
2022-03-31 16:40:05,282: time cost, forward:0.19091460692308926, backward:0.037688079704949834, data cost:0.2704153875330052 
2022-03-31 16:40:05,283: ============================================================
2022-03-31 16:40:05,283: Epoch 9/31 Batch 2100/7662 eta: 1 day, 1:10:07.151490	Training Loss 0.8519 (0.8519)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 16:40:05,283: ============================================================
2022-03-31 16:40:55,593: time cost, forward:0.19094016954214696, backward:0.037508792907555245, data cost:0.2707719863572409 
2022-03-31 16:40:55,593: ============================================================
2022-03-31 16:40:55,593: Epoch 9/31 Batch 2200/7662 eta: 1 day, 0:19:13.798904	Training Loss 0.8533 (0.8520)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 16:40:55,594: ============================================================
2022-03-31 16:41:47,208: time cost, forward:0.1913240148794034, backward:0.0374934309303579, data cost:0.27109304185844907 
2022-03-31 16:41:47,209: ============================================================
2022-03-31 16:41:47,209: Epoch 9/31 Batch 2300/7662 eta: 1 day, 0:56:13.532394	Training Loss 0.8538 (0.8521)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 16:41:47,210: ============================================================
2022-03-31 16:42:36,982: time cost, forward:0.1913046019929009, backward:0.0374307521137907, data cost:0.2710488424941171 
2022-03-31 16:42:36,982: ============================================================
2022-03-31 16:42:36,982: Epoch 9/31 Batch 2400/7662 eta: 1 day, 0:01:58.873756	Training Loss 0.8528 (0.8521)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 16:42:36,983: ============================================================
2022-03-31 16:43:30,420: time cost, forward:0.1926612529624887, backward:0.03752820460306926, data cost:0.2709866839916814 
2022-03-31 16:43:30,421: ============================================================
2022-03-31 16:43:30,421: Epoch 9/31 Batch 2500/7662 eta: 1 day, 1:47:18.099742	Training Loss 0.8548 (0.8522)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 16:43:30,421: ============================================================
2022-03-31 16:44:20,172: time cost, forward:0.19281586631989195, backward:0.037494426968006866, data cost:0.27069627830458404 
2022-03-31 16:44:20,172: ============================================================
2022-03-31 16:44:20,172: Epoch 9/31 Batch 2600/7662 eta: 23:59:41.436890	Training Loss 0.8523 (0.8523)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 16:44:20,172: ============================================================
2022-03-31 16:45:12,188: time cost, forward:0.1934176710368351, backward:0.037560581145086924, data cost:0.2707115433400717 
2022-03-31 16:45:12,189: ============================================================
2022-03-31 16:45:12,189: Epoch 9/31 Batch 2700/7662 eta: 1 day, 1:04:22.582171	Training Loss 0.8582 (0.8523)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 16:45:12,189: ============================================================
2022-03-31 16:46:02,616: time cost, forward:0.19358189202240852, backward:0.037550225092624505, data cost:0.27055600576206545 
2022-03-31 16:46:02,616: ============================================================
2022-03-31 16:46:02,616: Epoch 9/31 Batch 2800/7662 eta: 1 day, 0:17:35.077825	Training Loss 0.8543 (0.8524)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 16:46:02,617: ============================================================
2022-03-31 16:46:53,701: time cost, forward:0.19372133593511565, backward:0.037565557740399984, data cost:0.2707739652704066 
2022-03-31 16:46:53,702: ============================================================
2022-03-31 16:46:53,702: Epoch 9/31 Batch 2900/7662 eta: 1 day, 0:35:45.622472	Training Loss 0.8571 (0.8525)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 16:46:53,703: ============================================================
2022-03-31 16:47:42,169: time cost, forward:0.19306145448929551, backward:0.03749954744194618, data cost:0.27089775987925946 
2022-03-31 16:47:42,169: ============================================================
2022-03-31 16:47:42,169: Epoch 9/31 Batch 3000/7662 eta: 23:19:17.715340	Training Loss 0.8571 (0.8525)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 16:47:42,169: ============================================================
2022-03-31 16:48:34,216: time cost, forward:0.1936738633386317, backward:0.0375609877187231, data cost:0.2708158692301147 
2022-03-31 16:48:34,217: ============================================================
2022-03-31 16:48:34,217: Epoch 9/31 Batch 3100/7662 eta: 1 day, 1:01:48.749000	Training Loss 0.8537 (0.8526)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 16:48:34,217: ============================================================
2022-03-31 16:49:23,955: time cost, forward:0.19367718696594238, backward:0.03754314924635414, data cost:0.2707063405727662 
2022-03-31 16:49:23,956: ============================================================
2022-03-31 16:49:23,956: Epoch 9/31 Batch 3200/7662 eta: 23:54:21.521796	Training Loss 0.8572 (0.8527)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 16:49:23,956: ============================================================
2022-03-31 16:50:14,980: time cost, forward:0.19355227673331982, backward:0.0375734403228066, data cost:0.27098854182885973 
2022-03-31 16:50:14,980: ============================================================
2022-03-31 16:50:14,981: Epoch 9/31 Batch 3300/7662 eta: 1 day, 0:30:35.721145	Training Loss 0.8521 (0.8527)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 16:50:14,981: ============================================================
2022-03-31 16:51:07,080: time cost, forward:0.19401927547056416, backward:0.03763804733139447, data cost:0.2710333181921613 
2022-03-31 16:51:07,081: ============================================================
2022-03-31 16:51:07,081: Epoch 9/31 Batch 3400/7662 eta: 1 day, 1:00:43.397146	Training Loss 0.8549 (0.8528)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 16:51:07,081: ============================================================
2022-03-31 16:51:58,200: time cost, forward:0.19451410963249807, backward:0.03775560784319463, data cost:0.2706711061956815 
2022-03-31 16:51:58,200: ============================================================
2022-03-31 16:51:58,200: Epoch 9/31 Batch 3500/7662 eta: 1 day, 0:31:36.872241	Training Loss 0.8509 (0.8528)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 16:51:58,201: ============================================================
2022-03-31 16:52:48,772: time cost, forward:0.1945663887648226, backward:0.03779886675795173, data cost:0.27062775181809806 
2022-03-31 16:52:48,773: ============================================================
2022-03-31 16:52:48,773: Epoch 9/31 Batch 3600/7662 eta: 1 day, 0:15:02.780631	Training Loss 0.8558 (0.8529)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 16:52:48,774: ============================================================
2022-03-31 16:53:36,747: time cost, forward:0.19397851189074242, backward:0.037722354903353905, data cost:0.2705812367209553 
2022-03-31 16:53:36,748: ============================================================
2022-03-31 16:53:36,751: Epoch 9/31 Batch 3700/7662 eta: 22:59:34.684323	Training Loss 0.8542 (0.8529)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 16:53:36,751: ============================================================
2022-03-31 16:54:26,434: time cost, forward:0.19363836025871645, backward:0.03771975078718322, data cost:0.27082922704033424 
2022-03-31 16:54:26,435: ============================================================
2022-03-31 16:54:26,435: Epoch 9/31 Batch 3800/7662 eta: 23:47:48.248385	Training Loss 0.8548 (0.8530)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 16:54:26,435: ============================================================
2022-03-31 16:55:16,500: time cost, forward:0.19373676140328558, backward:0.03774952264772558, data cost:0.2706484496822783 
2022-03-31 16:55:16,500: ============================================================
2022-03-31 16:55:16,501: Epoch 9/31 Batch 3900/7662 eta: 23:57:56.545550	Training Loss 0.8550 (0.8530)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 16:55:16,501: ============================================================
2022-03-31 16:56:06,046: time cost, forward:0.19343583748977938, backward:0.03771489231131559, data cost:0.2708139139939976 
2022-03-31 16:56:06,046: ============================================================
2022-03-31 16:56:06,046: Epoch 9/31 Batch 4000/7662 eta: 23:42:11.342233	Training Loss 0.8564 (0.8530)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 16:56:06,047: ============================================================
2022-03-31 16:56:57,776: time cost, forward:0.19378989520495216, backward:0.03778480372506835, data cost:0.27074616261882645 
2022-03-31 16:56:57,776: ============================================================
2022-03-31 16:56:57,776: Epoch 9/31 Batch 4100/7662 eta: 1 day, 0:44:01.361153	Training Loss 0.8565 (0.8530)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 16:56:57,777: ============================================================
2022-03-31 16:57:47,342: time cost, forward:0.1936754043058544, backward:0.0378193393097687, data cost:0.2706549700228025 
2022-03-31 16:57:47,343: ============================================================
2022-03-31 16:57:47,343: Epoch 9/31 Batch 4200/7662 eta: 23:41:08.141840	Training Loss 0.8568 (0.8531)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 16:57:47,343: ============================================================
2022-03-31 16:58:39,123: time cost, forward:0.19401469317168019, backward:0.03784187762341851, data cost:0.27065341787078706 
2022-03-31 16:58:39,124: ============================================================
2022-03-31 16:58:39,124: Epoch 9/31 Batch 4300/7662 eta: 1 day, 0:43:45.555358	Training Loss 0.8524 (0.8531)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 16:58:39,124: ============================================================
2022-03-31 16:59:29,565: time cost, forward:0.19426538007154767, backward:0.03789601257698838, data cost:0.27038132762280237 
2022-03-31 16:59:29,565: ============================================================
2022-03-31 16:59:29,565: Epoch 9/31 Batch 4400/7662 eta: 1 day, 0:04:31.284901	Training Loss 0.8546 (0.8532)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 16:59:29,566: ============================================================
2022-03-31 17:00:18,956: time cost, forward:0.19429797923784833, backward:0.03790043586888666, data cost:0.2701319383764087 
2022-03-31 17:00:18,957: ============================================================
2022-03-31 17:00:18,957: Epoch 9/31 Batch 4500/7662 eta: 23:33:39.267526	Training Loss 0.8560 (0.8532)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 17:00:18,957: ============================================================
2022-03-31 17:01:08,131: time cost, forward:0.19435319617458674, backward:0.03795158274667785, data cost:0.26979851157646073 
2022-03-31 17:01:08,131: ============================================================
2022-03-31 17:01:08,131: Epoch 9/31 Batch 4600/7662 eta: 23:26:36.374557	Training Loss 0.8607 (0.8532)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 17:01:08,132: ============================================================
2022-03-31 17:01:56,171: time cost, forward:0.19378694865926324, backward:0.037968509018129426, data cost:0.26986851893122793 
2022-03-31 17:01:56,172: ============================================================
2022-03-31 17:01:56,172: Epoch 9/31 Batch 4700/7662 eta: 22:53:22.644643	Training Loss 0.8514 (0.8533)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 17:01:56,172: ============================================================
2022-03-31 17:02:46,383: time cost, forward:0.19381346362758414, backward:0.037950822228465284, data cost:0.26986088234078115 
2022-03-31 17:02:46,384: ============================================================
2022-03-31 17:02:46,384: Epoch 9/31 Batch 4800/7662 eta: 23:54:37.017835	Training Loss 0.8545 (0.8533)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 17:02:46,384: ============================================================
2022-03-31 17:03:37,606: time cost, forward:0.19419201288108412, backward:0.037949963427728765, data cost:0.26969035359445115 
2022-03-31 17:03:37,606: ============================================================
2022-03-31 17:03:37,606: Epoch 9/31 Batch 4900/7662 eta: 1 day, 0:22:37.690466	Training Loss 0.8564 (0.8533)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 17:03:37,607: ============================================================
2022-03-31 17:04:28,007: time cost, forward:0.19388429420808478, backward:0.03794525227181362, data cost:0.27002065604771347 
2022-03-31 17:04:28,007: ============================================================
2022-03-31 17:04:28,007: Epoch 9/31 Batch 5000/7662 eta: 23:58:19.792903	Training Loss 0.8566 (0.8534)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 17:04:28,007: ============================================================
2022-03-31 17:05:16,035: time cost, forward:0.19372211612657275, backward:0.037925356344794214, data cost:0.26978922624357965 
2022-03-31 17:05:16,036: ============================================================
2022-03-31 17:05:16,036: Epoch 9/31 Batch 5100/7662 eta: 22:49:50.266218	Training Loss 0.8542 (0.8534)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 17:05:16,036: ============================================================
2022-03-31 17:06:08,901: time cost, forward:0.1939021302406823, backward:0.0379440823892695, data cost:0.2700813407736527 
2022-03-31 17:06:08,902: ============================================================
2022-03-31 17:06:08,902: Epoch 9/31 Batch 5200/7662 eta: 1 day, 1:06:54.923308	Training Loss 0.8564 (0.8534)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 17:06:08,902: ============================================================
2022-03-31 17:06:57,506: time cost, forward:0.193603708600521, backward:0.03793387445419954, data cost:0.2701076311218354 
2022-03-31 17:06:57,506: ============================================================
2022-03-31 17:06:57,507: Epoch 9/31 Batch 5300/7662 eta: 23:04:38.517821	Training Loss 0.8565 (0.8535)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.195 (0.008)	
2022-03-31 17:06:57,507: ============================================================
2022-03-31 17:07:49,427: time cost, forward:0.19398035210886583, backward:0.037940374854141354, data cost:0.27003358165121316 
2022-03-31 17:07:49,428: ============================================================
2022-03-31 17:07:49,428: Epoch 9/31 Batch 5400/7662 eta: 1 day, 0:38:15.261808	Training Loss 0.8517 (0.8535)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 17:07:49,428: ============================================================
2022-03-31 17:08:38,207: time cost, forward:0.19374169560210622, backward:0.037915325485634616, data cost:0.2700541383202541 
2022-03-31 17:08:38,207: ============================================================
2022-03-31 17:08:38,207: Epoch 9/31 Batch 5500/7662 eta: 23:08:00.188907	Training Loss 0.8557 (0.8535)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 17:08:38,208: ============================================================
2022-03-31 17:09:28,327: time cost, forward:0.19385147205440673, backward:0.03791468921442674, data cost:0.26991142875744967 
2022-03-31 17:09:28,327: ============================================================
2022-03-31 17:09:28,328: Epoch 9/31 Batch 5600/7662 eta: 23:45:18.525172	Training Loss 0.8548 (0.8535)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 17:09:28,328: ============================================================
2022-03-31 17:10:21,712: time cost, forward:0.19418002476000246, backward:0.03793494951141406, data cost:0.2701138704152332 
2022-03-31 17:10:21,713: ============================================================
2022-03-31 17:10:21,713: Epoch 9/31 Batch 5700/7662 eta: 1 day, 1:17:16.350396	Training Loss 0.8566 (0.8536)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 17:10:21,713: ============================================================
2022-03-31 17:11:10,065: time cost, forward:0.19412554303291113, backward:0.03793634828112622, data cost:0.26984301787611736 
2022-03-31 17:11:10,065: ============================================================
2022-03-31 17:11:10,065: Epoch 9/31 Batch 5800/7662 eta: 22:53:25.428241	Training Loss 0.8542 (0.8536)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 17:11:10,066: ============================================================
2022-03-31 17:12:00,626: time cost, forward:0.19412279909072155, backward:0.0378057076013943, data cost:0.27003215324840296 
2022-03-31 17:12:00,626: ============================================================
2022-03-31 17:12:00,626: Epoch 9/31 Batch 5900/7662 eta: 23:55:19.262878	Training Loss 0.8553 (0.8536)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 17:12:00,627: ============================================================
2022-03-31 17:12:51,420: time cost, forward:0.19416908197232854, backward:0.03783842173590821, data cost:0.2700388019811036 
2022-03-31 17:12:51,420: ============================================================
2022-03-31 17:12:51,421: Epoch 9/31 Batch 6000/7662 eta: 1 day, 0:01:05.264163	Training Loss 0.8564 (0.8536)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 17:12:51,421: ============================================================
2022-03-31 17:13:43,487: time cost, forward:0.19430494421836803, backward:0.037828314634674315, data cost:0.27022196168019197 
2022-03-31 17:13:43,487: ============================================================
2022-03-31 17:13:43,487: Epoch 9/31 Batch 6100/7662 eta: 1 day, 0:36:19.461542	Training Loss 0.8568 (0.8537)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 17:13:43,487: ============================================================
2022-03-31 17:14:35,087: time cost, forward:0.19455324286202266, backward:0.037836630472465375, data cost:0.2701773328884203 
2022-03-31 17:14:35,088: ============================================================
2022-03-31 17:14:35,088: Epoch 9/31 Batch 6200/7662 eta: 1 day, 0:22:15.481185	Training Loss 0.8577 (0.8537)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 17:14:35,088: ============================================================
2022-03-31 17:15:25,497: time cost, forward:0.1946510868917327, backward:0.0378462601737534, data cost:0.27009429282887737 
2022-03-31 17:15:25,497: ============================================================
2022-03-31 17:15:25,498: Epoch 9/31 Batch 6300/7662 eta: 23:47:39.437567	Training Loss 0.8543 (0.8537)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 17:15:25,498: ============================================================
2022-03-31 17:16:16,036: time cost, forward:0.19485150163742615, backward:0.03785305795194134, data cost:0.2699255281210803 
2022-03-31 17:16:16,036: ============================================================
2022-03-31 17:16:16,036: Epoch 9/31 Batch 6400/7662 eta: 23:50:28.401954	Training Loss 0.8550 (0.8537)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 17:16:16,037: ============================================================
2022-03-31 17:17:05,365: time cost, forward:0.19476386997805759, backward:0.037845407711357165, data cost:0.26986369600221183 
2022-03-31 17:17:05,366: ============================================================
2022-03-31 17:17:05,366: Epoch 9/31 Batch 6500/7662 eta: 23:15:25.262690	Training Loss 0.8543 (0.8538)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 17:17:05,366: ============================================================
2022-03-31 17:17:53,844: time cost, forward:0.19447927175823315, backward:0.03783965320329916, data cost:0.2698718133632442 
2022-03-31 17:17:53,844: ============================================================
2022-03-31 17:17:53,845: Epoch 9/31 Batch 6600/7662 eta: 22:50:33.173000	Training Loss 0.8532 (0.8538)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 17:17:53,845: ============================================================
2022-03-31 17:18:42,822: time cost, forward:0.19440036407957006, backward:0.03784411009398302, data cost:0.2697660953255799 
2022-03-31 17:18:42,823: ============================================================
2022-03-31 17:18:42,823: Epoch 9/31 Batch 6700/7662 eta: 23:03:51.806163	Training Loss 0.8556 (0.8538)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 17:18:42,824: ============================================================
2022-03-31 17:19:36,126: time cost, forward:0.1947960547794926, backward:0.03789046298477435, data cost:0.2697672303204397 
2022-03-31 17:19:36,126: ============================================================
2022-03-31 17:19:36,126: Epoch 9/31 Batch 6800/7662 eta: 1 day, 1:05:09.939965	Training Loss 0.8566 (0.8538)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 17:19:36,126: ============================================================
2022-03-31 17:20:22,857: time cost, forward:0.19418985727196553, backward:0.03786090478152015, data cost:0.2698905171821352 
2022-03-31 17:20:22,857: ============================================================
2022-03-31 17:20:22,858: Epoch 9/31 Batch 6900/7662 eta: 21:58:48.530916	Training Loss 0.8554 (0.8538)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 17:20:22,858: ============================================================
2022-03-31 17:21:15,164: time cost, forward:0.1942375664166645, backward:0.03786432891253796, data cost:0.2701313705474313 
2022-03-31 17:21:15,165: ============================================================
2022-03-31 17:21:15,165: Epoch 9/31 Batch 7000/7662 eta: 1 day, 0:35:18.623845	Training Loss 0.8557 (0.8539)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 17:21:15,165: ============================================================
2022-03-31 17:22:05,901: time cost, forward:0.19426590013645084, backward:0.03787148524412119, data cost:0.27017144190289466 
2022-03-31 17:22:05,902: ============================================================
2022-03-31 17:22:05,902: Epoch 9/31 Batch 7100/7662 eta: 23:50:09.484111	Training Loss 0.8554 (0.8539)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 17:22:05,902: ============================================================
2022-03-31 17:22:55,817: time cost, forward:0.19413852191564193, backward:0.03785387852702278, data cost:0.27020644522289516 
2022-03-31 17:22:55,818: ============================================================
2022-03-31 17:22:55,818: Epoch 9/31 Batch 7200/7662 eta: 23:26:12.115576	Training Loss 0.8552 (0.8539)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 17:22:55,819: ============================================================
2022-03-31 17:23:43,604: time cost, forward:0.19403371387580468, backward:0.03784897883047158, data cost:0.27003276062299164 
2022-03-31 17:23:43,604: ============================================================
2022-03-31 17:23:43,604: Epoch 9/31 Batch 7300/7662 eta: 22:25:23.764349	Training Loss 0.8533 (0.8539)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 17:23:43,605: ============================================================
2022-03-31 17:24:34,117: time cost, forward:0.19405750977636946, backward:0.037837586703856646, data cost:0.27004917551817353 
2022-03-31 17:24:34,117: ============================================================
2022-03-31 17:24:34,118: Epoch 9/31 Batch 7400/7662 eta: 23:41:20.016843	Training Loss 0.8551 (0.8539)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 17:24:34,118: ============================================================
2022-03-31 17:25:25,187: time cost, forward:0.19412142627317758, backward:0.03784340539762601, data cost:0.27008413553142535 
2022-03-31 17:25:25,188: ============================================================
2022-03-31 17:25:25,188: Epoch 9/31 Batch 7500/7662 eta: 23:56:09.638688	Training Loss 0.8548 (0.8539)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 17:25:25,188: ============================================================
2022-03-31 17:26:16,746: time cost, forward:0.19426773676575446, backward:0.03785154709362296, data cost:0.27010347852896416 
2022-03-31 17:26:16,747: ============================================================
2022-03-31 17:26:16,747: Epoch 9/31 Batch 7600/7662 eta: 1 day, 0:09:01.987289	Training Loss 0.8519 (0.8539)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-31 17:26:16,747: ============================================================
2022-03-31 17:26:46,566: Epoch: 9/31 eta: 1 day, 0:08:29.505271	Training Loss 0.8543 (0.8539)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)
2022-03-31 17:26:46,566: ============================================================
2022-03-31 17:27:34,137: time cost, forward:0.16112309272843178, backward:0.03448867557024715, data cost:0.28121768826186055 
2022-03-31 17:27:34,138: ============================================================
2022-03-31 17:27:34,138: Epoch 10/31 Batch 100/7662 eta: 22:14:51.062859	Training Loss 0.8463 (0.8479)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.010)	
2022-03-31 17:27:34,139: ============================================================
2022-03-31 17:28:26,781: time cost, forward:0.19576752844767356, backward:0.037268099473349414, data cost:0.2684995313385623 
2022-03-31 17:28:26,782: ============================================================
2022-03-31 17:28:26,782: Epoch 10/31 Batch 200/7662 eta: 1 day, 0:37:13.108502	Training Loss 0.8409 (0.8456)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.010)	
2022-03-31 17:28:26,782: ============================================================
2022-03-31 17:29:19,584: time cost, forward:0.20556369433833604, backward:0.03750801086425781, data cost:0.2672551977993254 
2022-03-31 17:29:19,584: ============================================================
2022-03-31 17:29:19,584: Epoch 10/31 Batch 300/7662 eta: 1 day, 0:40:48.530223	Training Loss 0.8372 (0.8438)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.012)	
2022-03-31 17:29:19,585: ============================================================
2022-03-31 17:30:07,232: time cost, forward:0.19966519267337962, backward:0.037125775688572935, data cost:0.2650577143618935 
2022-03-31 17:30:07,232: ============================================================
2022-03-31 17:30:07,232: Epoch 10/31 Batch 400/7662 eta: 22:15:26.823385	Training Loss 0.8378 (0.8424)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.014)	
2022-03-31 17:30:07,232: ============================================================
2022-03-31 17:31:00,616: time cost, forward:0.204678406457385, backward:0.03756702017927457, data cost:0.2658268870237117 
2022-03-31 17:31:00,616: ============================================================
2022-03-31 17:31:00,616: Epoch 10/31 Batch 500/7662 eta: 1 day, 0:55:19.929898	Training Loss 0.8372 (0.8412)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.195 (0.013)	
2022-03-31 17:31:00,616: ============================================================
2022-03-31 17:31:48,841: time cost, forward:0.2016281898511272, backward:0.03730365549383657, data cost:0.26474797904789943 
2022-03-31 17:31:48,841: ============================================================
2022-03-31 17:31:48,841: Epoch 10/31 Batch 600/7662 eta: 22:30:00.976524	Training Loss 0.8367 (0.8402)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.013)	
2022-03-31 17:31:48,841: ============================================================
2022-03-31 17:32:40,181: time cost, forward:0.20374189698815517, backward:0.03730837981588339, data cost:0.26393523066170055 
2022-03-31 17:32:40,181: ============================================================
2022-03-31 17:32:40,182: Epoch 10/31 Batch 700/7662 eta: 23:56:22.832977	Training Loss 0.8333 (0.8393)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.012)	
2022-03-31 17:32:40,182: ============================================================
2022-03-31 17:33:29,555: time cost, forward:0.20245526371073813, backward:0.037293539476931765, data cost:0.26370227769558063 
2022-03-31 17:33:29,556: ============================================================
2022-03-31 17:33:29,556: Epoch 10/31 Batch 800/7662 eta: 23:00:32.742002	Training Loss 0.8335 (0.8385)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.012)	
2022-03-31 17:33:29,556: ============================================================
2022-03-31 17:34:22,007: time cost, forward:0.20345497635235643, backward:0.03745085007621926, data cost:0.2649524424046908 
2022-03-31 17:34:22,008: ============================================================
2022-03-31 17:34:22,008: Epoch 10/31 Batch 900/7662 eta: 1 day, 0:25:44.094150	Training Loss 0.8293 (0.8378)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.012)	
2022-03-31 17:34:22,009: ============================================================
2022-03-31 17:35:14,273: time cost, forward:0.20438322887287005, backward:0.03762541709838806, data cost:0.2654447789426084 
2022-03-31 17:35:14,274: ============================================================
2022-03-31 17:35:14,274: Epoch 10/31 Batch 1000/7662 eta: 1 day, 0:19:38.590907	Training Loss 0.8317 (0.8372)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.011)	
2022-03-31 17:35:14,274: ============================================================
2022-03-31 17:36:02,219: time cost, forward:0.20165041167699174, backward:0.03762426779853745, data cost:0.26561000479471697 
2022-03-31 17:36:02,219: ============================================================
2022-03-31 17:36:02,220: Epoch 10/31 Batch 1100/7662 eta: 22:18:12.392157	Training Loss 0.8319 (0.8366)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.011)	
2022-03-31 17:36:02,220: ============================================================
2022-03-31 17:36:49,914: time cost, forward:0.1986355739797126, backward:0.03757436917760752, data cost:0.2662395486441923 
2022-03-31 17:36:49,915: ============================================================
2022-03-31 17:36:49,915: Epoch 10/31 Batch 1200/7662 eta: 22:10:25.646026	Training Loss 0.8316 (0.8361)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.011)	
2022-03-31 17:36:49,915: ============================================================
2022-03-31 17:37:39,032: time cost, forward:0.19871866069820132, backward:0.03766350125789275, data cost:0.26522040789268675 
2022-03-31 17:37:39,033: ============================================================
2022-03-31 17:37:39,033: Epoch 10/31 Batch 1300/7662 eta: 22:49:16.815984	Training Loss 0.8321 (0.8357)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.011)	
2022-03-31 17:37:39,033: ============================================================
2022-03-31 17:38:28,090: time cost, forward:0.1977503386627699, backward:0.0376535729905211, data cost:0.2653635746244876 
2022-03-31 17:38:28,091: ============================================================
2022-03-31 17:38:28,091: Epoch 10/31 Batch 1400/7662 eta: 22:46:47.946137	Training Loss 0.8305 (0.8353)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.012)	
2022-03-31 17:38:28,091: ============================================================
2022-03-31 17:39:17,477: time cost, forward:0.19776357786905138, backward:0.03742496501294035, data cost:0.2650261023905056 
2022-03-31 17:39:17,478: ============================================================
2022-03-31 17:39:17,479: Epoch 10/31 Batch 1500/7662 eta: 22:55:09.798535	Training Loss 0.8281 (0.8350)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.011)	
2022-03-31 17:39:17,479: ============================================================
2022-03-31 17:40:08,885: time cost, forward:0.19912074102767935, backward:0.03750077346625218, data cost:0.26446639097355695 
2022-03-31 17:40:08,885: ============================================================
2022-03-31 17:40:08,885: Epoch 10/31 Batch 1600/7662 eta: 23:50:31.002220	Training Loss 0.8303 (0.8346)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.012)	
2022-03-31 17:40:08,886: ============================================================
2022-03-31 17:40:59,977: time cost, forward:0.19961995893257237, backward:0.03759770873295973, data cost:0.26440117919073164 
2022-03-31 17:40:59,977: ============================================================
2022-03-31 17:40:59,977: Epoch 10/31 Batch 1700/7662 eta: 23:40:54.344758	Training Loss 0.8306 (0.8344)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.011)	
2022-03-31 17:40:59,977: ============================================================
2022-03-31 17:41:48,208: time cost, forward:0.19863124779027458, backward:0.037602610691445874, data cost:0.2642774062397879 
2022-03-31 17:41:48,209: ============================================================
2022-03-31 17:41:48,209: Epoch 10/31 Batch 1800/7662 eta: 22:20:33.349888	Training Loss 0.8294 (0.8341)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.011)	
2022-03-31 17:41:48,209: ============================================================
2022-03-31 17:42:39,386: time cost, forward:0.19929606805292163, backward:0.0377393720525387, data cost:0.26404566260122386 
2022-03-31 17:42:39,386: ============================================================
2022-03-31 17:42:39,386: Epoch 10/31 Batch 1900/7662 eta: 23:41:35.176687	Training Loss 0.8293 (0.8339)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.011)	
2022-03-31 17:42:39,386: ============================================================
2022-03-31 17:43:30,181: time cost, forward:0.19868185103923575, backward:0.037698405572567775, data cost:0.2647656957884918 
2022-03-31 17:43:30,181: ============================================================
2022-03-31 17:43:30,181: Epoch 10/31 Batch 2000/7662 eta: 23:30:06.604113	Training Loss 0.8303 (0.8336)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.011)	
2022-03-31 17:43:30,182: ============================================================
2022-03-31 17:44:18,992: time cost, forward:0.19744042296134728, backward:0.03753946348847293, data cost:0.2658132560597311 
2022-03-31 17:44:18,992: ============================================================
2022-03-31 17:44:18,992: Epoch 10/31 Batch 2100/7662 eta: 22:34:13.176561	Training Loss 0.8289 (0.8334)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.011)	
2022-03-31 17:44:18,992: ============================================================
2022-03-31 17:45:07,978: time cost, forward:0.19687446023508223, backward:0.03753004837383081, data cost:0.2658669568018894 
2022-03-31 17:45:07,978: ============================================================
2022-03-31 17:45:07,979: Epoch 10/31 Batch 2200/7662 eta: 22:38:16.673971	Training Loss 0.8291 (0.8332)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.011)	
2022-03-31 17:45:07,979: ============================================================
2022-03-31 17:45:54,774: time cost, forward:0.1952687552204439, backward:0.037399460202250705, data cost:0.266174002905004 
2022-03-31 17:45:54,775: ============================================================
2022-03-31 17:45:54,775: Epoch 10/31 Batch 2300/7662 eta: 21:36:45.386848	Training Loss 0.8275 (0.8331)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.011)	
2022-03-31 17:45:54,775: ============================================================
2022-03-31 17:46:45,247: time cost, forward:0.19555168223410857, backward:0.03754946598165877, data cost:0.26598837108301987 
2022-03-31 17:46:45,248: ============================================================
2022-03-31 17:46:45,248: Epoch 10/31 Batch 2400/7662 eta: 23:17:48.200250	Training Loss 0.8290 (0.8329)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.011)	
2022-03-31 17:46:45,248: ============================================================
2022-03-31 17:47:36,043: time cost, forward:0.19583561583584239, backward:0.03754881316540288, data cost:0.2660015737022959 
2022-03-31 17:47:36,043: ============================================================
2022-03-31 17:47:36,043: Epoch 10/31 Batch 2500/7662 eta: 23:25:53.736792	Training Loss 0.8300 (0.8327)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.011)	
2022-03-31 17:47:36,044: ============================================================
2022-03-31 17:48:23,847: time cost, forward:0.19579105342338066, backward:0.03755215169283554, data cost:0.2652415928358112 
2022-03-31 17:48:23,848: ============================================================
2022-03-31 17:48:23,848: Epoch 10/31 Batch 2600/7662 eta: 22:02:18.860865	Training Loss 0.8293 (0.8326)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.011)	
2022-03-31 17:48:23,848: ============================================================
2022-03-31 17:49:13,982: time cost, forward:0.19589876015568805, backward:0.03757458105931771, data cost:0.2651811170772342 
2022-03-31 17:49:13,982: ============================================================
2022-03-31 17:49:13,982: Epoch 10/31 Batch 2700/7662 eta: 23:05:55.345661	Training Loss 0.8272 (0.8325)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.195 (0.011)	
2022-03-31 17:49:13,982: ============================================================
2022-03-31 17:50:04,136: time cost, forward:0.1961351316628519, backward:0.037651468064368476, data cost:0.2648751554254039 
2022-03-31 17:50:04,136: ============================================================
2022-03-31 17:50:04,136: Epoch 10/31 Batch 2800/7662 eta: 23:05:37.515750	Training Loss 0.8275 (0.8323)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.011)	
2022-03-31 17:50:04,136: ============================================================
2022-03-31 17:50:53,797: time cost, forward:0.1962536153566348, backward:0.03770976997564973, data cost:0.2646816824583729 
2022-03-31 17:50:53,797: ============================================================
2022-03-31 17:50:53,797: Epoch 10/31 Batch 2900/7662 eta: 22:51:10.868024	Training Loss 0.8292 (0.8322)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.012)	
2022-03-31 17:50:53,797: ============================================================
2022-03-31 17:51:43,833: time cost, forward:0.19616400364757816, backward:0.03766173591372091, data cost:0.26485012347954995 
2022-03-31 17:51:43,833: ============================================================
2022-03-31 17:51:43,834: Epoch 10/31 Batch 3000/7662 eta: 23:00:42.588160	Training Loss 0.8288 (0.8321)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.012)	
2022-03-31 17:51:43,834: ============================================================
2022-03-31 17:52:36,788: time cost, forward:0.19679042469035737, backward:0.03770697943892699, data cost:0.26517751933144307 
2022-03-31 17:52:36,789: ============================================================
2022-03-31 17:52:36,789: Epoch 10/31 Batch 3100/7662 eta: 1 day, 0:20:22.625373	Training Loss 0.8287 (0.8320)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.012)	
2022-03-31 17:52:36,789: ============================================================
2022-03-31 17:53:23,592: time cost, forward:0.19629607926535958, backward:0.037679492849676116, data cost:0.26466729962181096 
2022-03-31 17:53:23,592: ============================================================
2022-03-31 17:53:23,592: Epoch 10/31 Batch 3200/7662 eta: 21:29:56.479142	Training Loss 0.8281 (0.8318)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.012)	
2022-03-31 17:53:23,592: ============================================================
2022-03-31 17:54:14,380: time cost, forward:0.19587388050198445, backward:0.03769975078579295, data cost:0.26533023615106016 
2022-03-31 17:54:14,380: ============================================================
2022-03-31 17:54:14,381: Epoch 10/31 Batch 3300/7662 eta: 23:18:55.267902	Training Loss 0.8283 (0.8317)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.012)	
2022-03-31 17:54:14,381: ============================================================
2022-03-31 17:55:03,429: time cost, forward:0.19575977914646886, backward:0.037625591626550284, data cost:0.26528521122810383 
2022-03-31 17:55:03,429: ============================================================
2022-03-31 17:55:03,430: Epoch 10/31 Batch 3400/7662 eta: 22:30:11.628497	Training Loss 0.8296 (0.8316)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.012)	
2022-03-31 17:55:03,430: ============================================================
2022-03-31 17:55:54,926: time cost, forward:0.19610061690479594, backward:0.03762474677398499, data cost:0.2653686913738049 
2022-03-31 17:55:54,926: ============================================================
2022-03-31 17:55:54,926: Epoch 10/31 Batch 3500/7662 eta: 23:36:43.419513	Training Loss 0.8283 (0.8315)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.012)	
2022-03-31 17:55:54,927: ============================================================
2022-03-31 17:56:44,356: time cost, forward:0.19628063378383068, backward:0.03766344023532555, data cost:0.2650296364137947 
2022-03-31 17:56:44,357: ============================================================
2022-03-31 17:56:44,357: Epoch 10/31 Batch 3600/7662 eta: 22:39:02.609436	Training Loss 0.8266 (0.8314)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.012)	
2022-03-31 17:56:44,357: ============================================================
2022-03-31 17:57:33,442: time cost, forward:0.19534968614384882, backward:0.03763467790501025, data cost:0.2657556804523948 
2022-03-31 17:57:33,442: ============================================================
2022-03-31 17:57:33,442: Epoch 10/31 Batch 3700/7662 eta: 22:28:44.888585	Training Loss 0.8249 (0.8313)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.012)	
2022-03-31 17:57:33,442: ============================================================
2022-03-31 17:58:20,242: time cost, forward:0.19497081586391432, backward:0.03760293522267694, data cost:0.2653546879937317 
2022-03-31 17:58:20,242: ============================================================
2022-03-31 17:58:20,243: Epoch 10/31 Batch 3800/7662 eta: 21:25:10.532958	Training Loss 0.8289 (0.8312)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.195 (0.012)	
2022-03-31 17:58:20,243: ============================================================
2022-03-31 17:59:08,982: time cost, forward:0.19462200891485457, backward:0.03758968515682294, data cost:0.26542659568982296 
2022-03-31 17:59:08,983: ============================================================
2022-03-31 17:59:08,984: Epoch 10/31 Batch 3900/7662 eta: 22:17:39.847294	Training Loss 0.8289 (0.8312)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.012)	
2022-03-31 17:59:08,984: ============================================================
2022-03-31 17:59:59,599: time cost, forward:0.19471256069375087, backward:0.03764983820122282, data cost:0.2654543018961108 
2022-03-31 17:59:59,600: ============================================================
2022-03-31 17:59:59,600: Epoch 10/31 Batch 4000/7662 eta: 23:08:15.913084	Training Loss 0.8280 (0.8311)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.013)	
2022-03-31 17:59:59,600: ============================================================
2022-03-31 18:00:45,549: time cost, forward:0.1935901030530927, backward:0.03758536358814933, data cost:0.26571962780474334 
2022-03-31 18:00:45,549: ============================================================
2022-03-31 18:00:45,549: Epoch 10/31 Batch 4100/7662 eta: 20:59:31.091169	Training Loss 0.8283 (0.8310)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.013)	
2022-03-31 18:00:45,549: ============================================================
2022-03-31 18:01:37,524: time cost, forward:0.19386817995040978, backward:0.037626725942017096, data cost:0.26592762659322255 
2022-03-31 18:01:37,525: ============================================================
2022-03-31 18:01:37,525: Epoch 10/31 Batch 4200/7662 eta: 23:43:49.642044	Training Loss 0.8283 (0.8309)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.013)	
2022-03-31 18:01:37,525: ============================================================
2022-03-31 18:02:24,268: time cost, forward:0.1933473834716378, backward:0.037590851088295595, data cost:0.2657646216134965 
2022-03-31 18:02:24,268: ============================================================
2022-03-31 18:02:24,269: Epoch 10/31 Batch 4300/7662 eta: 21:19:44.290404	Training Loss 0.8260 (0.8308)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.013)	
2022-03-31 18:02:24,270: ============================================================
2022-03-31 18:03:15,230: time cost, forward:0.19368299312769324, backward:0.037632831797650736, data cost:0.2656917264174808 
2022-03-31 18:03:15,231: ============================================================
2022-03-31 18:03:15,231: Epoch 10/31 Batch 4400/7662 eta: 23:14:21.122098	Training Loss 0.8270 (0.8308)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.013)	
2022-03-31 18:03:15,231: ============================================================
2022-03-31 18:04:03,395: time cost, forward:0.19330290259984262, backward:0.037584900670540176, data cost:0.2657540072915712 
2022-03-31 18:04:03,395: ============================================================
2022-03-31 18:04:03,395: Epoch 10/31 Batch 4500/7662 eta: 21:57:01.254339	Training Loss 0.8281 (0.8307)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.013)	
2022-03-31 18:04:03,395: ============================================================
2022-03-31 18:04:50,375: time cost, forward:0.1927729369402191, backward:0.03755806305792622, data cost:0.2657141069091644 
2022-03-31 18:04:50,375: ============================================================
2022-03-31 18:04:50,375: Epoch 10/31 Batch 4600/7662 eta: 21:23:50.617472	Training Loss 0.8269 (0.8306)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.013)	
2022-03-31 18:04:50,375: ============================================================
2022-03-31 18:05:42,882: time cost, forward:0.19310778459352898, backward:0.037569083363788135, data cost:0.26596935811664835 
2022-03-31 18:05:42,883: ============================================================
2022-03-31 18:05:42,883: Epoch 10/31 Batch 4700/7662 eta: 23:54:01.908982	Training Loss 0.8265 (0.8306)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.013)	
2022-03-31 18:05:42,883: ============================================================
2022-03-31 18:06:32,000: time cost, forward:0.1930161025231519, backward:0.037603037832776416, data cost:0.26590829378467074 
2022-03-31 18:06:32,000: ============================================================
2022-03-31 18:06:32,000: Epoch 10/31 Batch 4800/7662 eta: 22:20:36.989740	Training Loss 0.8266 (0.8305)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.195 (0.013)	
2022-03-31 18:06:32,001: ============================================================
2022-03-31 18:07:21,686: time cost, forward:0.1928769317688468, backward:0.03760805994326982, data cost:0.2660303191764911 
2022-03-31 18:07:21,687: ============================================================
2022-03-31 18:07:21,688: Epoch 10/31 Batch 4900/7662 eta: 22:35:20.660569	Training Loss 0.8257 (0.8304)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.195 (0.014)	
2022-03-31 18:07:21,688: ============================================================
2022-03-31 18:08:11,571: time cost, forward:0.1930972849709865, backward:0.03761576967111562, data cost:0.26586564079860037 
2022-03-31 18:08:11,572: ============================================================
2022-03-31 18:08:11,572: Epoch 10/31 Batch 5000/7662 eta: 22:39:52.876234	Training Loss 0.8279 (0.8303)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.014)	
2022-03-31 18:08:11,572: ============================================================
2022-03-31 18:08:59,028: time cost, forward:0.19305737192992206, backward:0.03756761139433719, data cost:0.26550702638171614 
2022-03-31 18:08:59,029: ============================================================
2022-03-31 18:08:59,029: Epoch 10/31 Batch 5100/7662 eta: 21:32:56.042622	Training Loss 0.8273 (0.8303)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.014)	
2022-03-31 18:08:59,029: ============================================================
2022-03-31 18:09:49,767: time cost, forward:0.19336004893718764, backward:0.03759122761562939, data cost:0.2653889443741828 
2022-03-31 18:09:49,767: ============================================================
2022-03-31 18:09:49,768: Epoch 10/31 Batch 5200/7662 eta: 23:01:29.192593	Training Loss 0.8275 (0.8302)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.014)	
2022-03-31 18:09:49,768: ============================================================
2022-03-31 18:10:35,653: time cost, forward:0.1929005066118818, backward:0.03755915999570013, data cost:0.26515451488145725 
2022-03-31 18:10:35,653: ============================================================
2022-03-31 18:10:35,654: Epoch 10/31 Batch 5300/7662 eta: 20:48:35.591703	Training Loss 0.8280 (0.8301)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.014)	
2022-03-31 18:10:35,654: ============================================================
2022-03-31 18:11:26,415: time cost, forward:0.19312093314870152, backward:0.03759820056328135, data cost:0.2651265267200615 
2022-03-31 18:11:26,415: ============================================================
2022-03-31 18:11:26,416: Epoch 10/31 Batch 5400/7662 eta: 23:00:25.751693	Training Loss 0.8268 (0.8301)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.015)	
2022-03-31 18:11:26,416: ============================================================
2022-03-31 18:12:17,814: time cost, forward:0.193524502173058, backward:0.03763033229885458, data cost:0.2649929082963787 
2022-03-31 18:12:17,814: ============================================================
2022-03-31 18:12:17,814: Epoch 10/31 Batch 5500/7662 eta: 23:16:53.133476	Training Loss 0.8253 (0.8300)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.015)	
2022-03-31 18:12:17,814: ============================================================
2022-03-31 18:13:03,333: time cost, forward:0.19302539958296386, backward:0.03756797268978718, data cost:0.26481467827151217 
2022-03-31 18:13:03,333: ============================================================
2022-03-31 18:13:03,334: Epoch 10/31 Batch 5600/7662 eta: 20:36:20.805801	Training Loss 0.8261 (0.8299)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.015)	
2022-03-31 18:13:03,334: ============================================================
2022-03-31 18:13:54,774: time cost, forward:0.19337339082461194, backward:0.037562104312343164, data cost:0.2647937275397399 
2022-03-31 18:13:54,775: ============================================================
2022-03-31 18:13:54,775: Epoch 10/31 Batch 5700/7662 eta: 23:16:19.745745	Training Loss 0.8275 (0.8299)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.016)	
2022-03-31 18:13:54,775: ============================================================
2022-03-31 18:14:46,156: time cost, forward:0.19372631496634024, backward:0.03756957202969923, data cost:0.26475346102799235 
2022-03-31 18:14:46,156: ============================================================
2022-03-31 18:14:46,156: Epoch 10/31 Batch 5800/7662 eta: 23:13:51.256814	Training Loss 0.8260 (0.8298)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.016)	
2022-03-31 18:14:46,157: ============================================================
2022-03-31 18:15:35,606: time cost, forward:0.19368623066481988, backward:0.03756558994132193, data cost:0.26475145324122445 
2022-03-31 18:15:35,607: ============================================================
2022-03-31 18:15:35,607: Epoch 10/31 Batch 5900/7662 eta: 22:20:38.983167	Training Loss 0.8265 (0.8297)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.016)	
2022-03-31 18:15:35,607: ============================================================
2022-03-31 18:16:23,975: time cost, forward:0.1935977030046822, backward:0.03754687197984587, data cost:0.2646633840676327 
2022-03-31 18:16:23,976: ============================================================
2022-03-31 18:16:23,976: Epoch 10/31 Batch 6000/7662 eta: 21:50:30.569060	Training Loss 0.8256 (0.8297)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.016)	
2022-03-31 18:16:23,976: ============================================================
2022-03-31 18:17:14,355: time cost, forward:0.1938626742359067, backward:0.037540739609542725, data cost:0.2645049550568868 
2022-03-31 18:17:14,355: ============================================================
2022-03-31 18:17:14,355: Epoch 10/31 Batch 6100/7662 eta: 22:44:08.844591	Training Loss 0.8240 (0.8296)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-31 18:17:14,355: ============================================================
2022-03-31 18:18:03,059: time cost, forward:0.1937258554324159, backward:0.0375080552864967, data cost:0.26452720574860344 
2022-03-31 18:18:03,060: ============================================================
2022-03-31 18:18:03,060: Epoch 10/31 Batch 6200/7662 eta: 21:57:59.662539	Training Loss 0.8257 (0.8295)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-31 18:18:03,060: ============================================================
2022-03-31 18:18:49,972: time cost, forward:0.19348720286191126, backward:0.03746353870233783, data cost:0.26439641585216045 
2022-03-31 18:18:49,973: ============================================================
2022-03-31 18:18:49,973: Epoch 10/31 Batch 6300/7662 eta: 21:08:42.922343	Training Loss 0.8214 (0.8294)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.195 (0.017)	
2022-03-31 18:18:49,973: ============================================================
2022-03-31 18:19:41,587: time cost, forward:0.19380454965672803, backward:0.03745559182534424, data cost:0.26440708077238917 
2022-03-31 18:19:41,587: ============================================================
2022-03-31 18:19:41,588: Epoch 10/31 Batch 6400/7662 eta: 23:15:00.920775	Training Loss 0.8232 (0.8293)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.195 (0.018)	
2022-03-31 18:19:41,588: ============================================================
2022-03-31 18:20:29,608: time cost, forward:0.1936773284616278, backward:0.03744853949763258, data cost:0.2642931391925404 
2022-03-31 18:20:29,608: ============================================================
2022-03-31 18:20:29,609: Epoch 10/31 Batch 6500/7662 eta: 21:37:05.298029	Training Loss 0.8197 (0.8292)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.019)	
2022-03-31 18:20:29,609: ============================================================
2022-03-31 18:21:18,401: time cost, forward:0.19354786412573924, backward:0.03746297009371685, data cost:0.2642704536922413 
2022-03-31 18:21:18,401: ============================================================
2022-03-31 18:21:18,401: Epoch 10/31 Batch 6600/7662 eta: 21:57:07.137958	Training Loss 0.8215 (0.8290)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.195 (0.020)	
2022-03-31 18:21:18,401: ============================================================
2022-03-31 18:22:04,710: time cost, forward:0.1932338415143881, backward:0.03744558651672582, data cost:0.2641205917206927 
2022-03-31 18:22:04,710: ============================================================
2022-03-31 18:22:04,711: Epoch 10/31 Batch 6700/7662 eta: 20:49:18.553374	Training Loss 0.8215 (0.8289)	Training Prec@1 0.195 (0.005)	Training Prec@5 0.195 (0.021)	
2022-03-31 18:22:04,711: ============================================================
2022-03-31 18:22:51,956: time cost, forward:0.19296848579336043, backward:0.03743519160936538, data cost:0.2640746750363814 
2022-03-31 18:22:51,956: ============================================================
2022-03-31 18:22:51,957: Epoch 10/31 Batch 6800/7662 eta: 21:13:47.630442	Training Loss 0.8212 (0.8288)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.022)	
2022-03-31 18:22:51,957: ============================================================
2022-03-31 18:23:42,148: time cost, forward:0.19292046070306226, backward:0.03744791141194284, data cost:0.2642103965290389 
2022-03-31 18:23:42,149: ============================================================
2022-03-31 18:23:42,149: Epoch 10/31 Batch 6900/7662 eta: 22:32:23.180727	Training Loss 0.8165 (0.8286)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.023)	
2022-03-31 18:23:42,149: ============================================================
2022-03-31 18:24:27,378: time cost, forward:0.19242310421792827, backward:0.03742458735522006, data cost:0.2641217818957156 
2022-03-31 18:24:27,379: ============================================================
2022-03-31 18:24:27,379: Epoch 10/31 Batch 7000/7662 eta: 20:17:56.195826	Training Loss 0.8171 (0.8285)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.195 (0.024)	
2022-03-31 18:24:27,379: ============================================================
2022-03-31 18:25:16,884: time cost, forward:0.19230233271166647, backward:0.03743698657742855, data cost:0.264210549386929 
2022-03-31 18:25:16,885: ============================================================
2022-03-31 18:25:16,885: Epoch 10/31 Batch 7100/7662 eta: 22:12:14.957669	Training Loss 0.8172 (0.8283)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.026)	
2022-03-31 18:25:16,885: ============================================================
2022-03-31 18:26:07,227: time cost, forward:0.19236465701958855, backward:0.0373993521681228, data cost:0.2643338084667983 
2022-03-31 18:26:07,227: ============================================================
2022-03-31 18:26:07,227: Epoch 10/31 Batch 7200/7662 eta: 22:33:54.771118	Training Loss 0.8180 (0.8281)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.027)	
2022-03-31 18:26:07,228: ============================================================
2022-03-31 18:26:59,715: time cost, forward:0.19272248368342293, backward:0.037414197089460095, data cost:0.26436401334653603 
2022-03-31 18:26:59,716: ============================================================
2022-03-31 18:26:59,716: Epoch 10/31 Batch 7300/7662 eta: 23:30:45.640080	Training Loss 0.8158 (0.8280)	Training Prec@1 0.195 (0.007)	Training Prec@5 0.195 (0.028)	
2022-03-31 18:26:59,716: ============================================================
2022-03-31 18:27:47,588: time cost, forward:0.19267267651744172, backward:0.03740696414674773, data cost:0.264205062851775 
2022-03-31 18:27:47,588: ============================================================
2022-03-31 18:27:47,588: Epoch 10/31 Batch 7400/7662 eta: 21:25:53.415588	Training Loss 0.8143 (0.8278)	Training Prec@1 0.195 (0.007)	Training Prec@5 0.586 (0.030)	
2022-03-31 18:27:47,588: ============================================================
2022-03-31 18:28:37,448: time cost, forward:0.1927162922132904, backward:0.03741103847085007, data cost:0.26421846575952557 
2022-03-31 18:28:37,448: ============================================================
2022-03-31 18:28:37,449: Epoch 10/31 Batch 7500/7662 eta: 22:18:27.596365	Training Loss 0.8263 (0.8277)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.032)	
2022-03-31 18:28:37,449: ============================================================
2022-03-31 18:29:22,274: time cost, forward:0.1922670596680338, backward:0.03737523819619314, data cost:0.26408996979238675 
2022-03-31 18:29:22,275: ============================================================
2022-03-31 18:29:22,275: Epoch 10/31 Batch 7600/7662 eta: 20:02:34.677821	Training Loss 0.8144 (0.8276)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.033)	
2022-03-31 18:29:22,275: ============================================================
2022-03-31 18:29:54,925: Epoch: 10/31 eta: 20:02:06.437242	Training Loss 0.8117 (0.8275)	Training Prec@1 0.195 (0.008)	Training Prec@5 0.391 (0.036)
2022-03-31 18:29:54,925: ============================================================
2022-03-31 18:29:55,015: Save Checkpoint...
2022-03-31 18:29:55,015: ============================================================
2022-03-31 18:29:57,564: Save done!
2022-03-31 18:29:57,565: ============================================================
2022-03-31 18:30:41,805: time cost, forward:0.14500061670939127, backward:0.03494217660692003, data cost:0.264176505984682 
2022-03-31 18:30:41,806: ============================================================
2022-03-31 18:30:41,806: Epoch 11/31 Batch 100/7662 eta: 19:44:57.873923	Training Loss 0.8124 (0.8123)	Training Prec@1 0.000 (0.087)	Training Prec@5 0.000 (0.268)	
2022-03-31 18:30:41,806: ============================================================
2022-03-31 18:31:28,014: time cost, forward:0.14665585187212307, backward:0.03519997285239061, data cost:0.2708988836662254 
2022-03-31 18:31:28,014: ============================================================
2022-03-31 18:31:28,015: Epoch 11/31 Batch 200/7662 eta: 20:37:38.883544	Training Loss 0.8250 (0.8195)	Training Prec@1 0.000 (0.050)	Training Prec@5 0.000 (0.169)	
2022-03-31 18:31:28,015: ============================================================
2022-03-31 18:32:12,193: time cost, forward:0.14802451356996263, backward:0.03534202591631325, data cost:0.26549297112684983 
2022-03-31 18:32:12,194: ============================================================
2022-03-31 18:32:12,194: Epoch 11/31 Batch 300/7662 eta: 19:42:33.594509	Training Loss 0.8311 (0.8223)	Training Prec@1 0.000 (0.035)	Training Prec@5 0.000 (0.123)	
2022-03-31 18:32:12,194: ============================================================
2022-03-31 18:32:58,898: time cost, forward:0.15630588794411873, backward:0.03591815750102949, data cost:0.2611011520663001 
2022-03-31 18:32:58,898: ============================================================
2022-03-31 18:32:58,898: Epoch 11/31 Batch 400/7662 eta: 20:49:21.572527	Training Loss 0.8297 (0.8244)	Training Prec@1 0.000 (0.027)	Training Prec@5 0.000 (0.094)	
2022-03-31 18:32:58,899: ============================================================
2022-03-31 18:33:45,192: time cost, forward:0.15551932971319837, backward:0.03602557287426415, data cost:0.26354432631590086 
2022-03-31 18:33:45,192: ============================================================
2022-03-31 18:33:45,192: Epoch 11/31 Batch 500/7662 eta: 20:37:37.143271	Training Loss 0.8304 (0.8256)	Training Prec@1 0.000 (0.022)	Training Prec@5 0.000 (0.078)	
2022-03-31 18:33:45,193: ============================================================
2022-03-31 18:34:30,446: time cost, forward:0.1547973370910288, backward:0.03570591388441286, data cost:0.2641420881815864 
2022-03-31 18:34:30,446: ============================================================
2022-03-31 18:34:30,446: Epoch 11/31 Batch 600/7662 eta: 20:09:03.143460	Training Loss 0.8299 (0.8263)	Training Prec@1 0.000 (0.019)	Training Prec@5 0.000 (0.068)	
2022-03-31 18:34:30,446: ============================================================
2022-03-31 18:35:16,785: time cost, forward:0.15577366594251815, backward:0.03562191934544641, data cost:0.26447885844840513 
2022-03-31 18:35:16,785: ============================================================
2022-03-31 18:35:16,785: Epoch 11/31 Batch 700/7662 eta: 20:37:16.761107	Training Loss 0.8296 (0.8268)	Training Prec@1 0.000 (0.016)	Training Prec@5 0.000 (0.059)	
2022-03-31 18:35:16,786: ============================================================
2022-03-31 18:36:04,553: time cost, forward:0.1591126333936135, backward:0.03590852328027145, data cost:0.2634793834781766 
2022-03-31 18:36:04,553: ============================================================
2022-03-31 18:36:04,554: Epoch 11/31 Batch 800/7662 eta: 21:14:38.537552	Training Loss 0.8297 (0.8271)	Training Prec@1 0.000 (0.014)	Training Prec@5 0.000 (0.054)	
2022-03-31 18:36:04,554: ============================================================
2022-03-31 18:36:50,866: time cost, forward:0.16059617868917803, backward:0.03605282982941862, data cost:0.2623510639182187 
2022-03-31 18:36:50,867: ============================================================
2022-03-31 18:36:50,867: Epoch 11/31 Batch 900/7662 eta: 20:35:02.849668	Training Loss 0.8302 (0.8274)	Training Prec@1 0.000 (0.012)	Training Prec@5 0.000 (0.048)	
2022-03-31 18:36:50,867: ============================================================
2022-03-31 18:37:36,080: time cost, forward:0.16097978643468908, backward:0.03618319900902184, data cost:0.26103505763682994 
2022-03-31 18:37:36,080: ============================================================
2022-03-31 18:37:36,080: Epoch 11/31 Batch 1000/7662 eta: 20:04:57.121523	Training Loss 0.8287 (0.8275)	Training Prec@1 0.000 (0.011)	Training Prec@5 0.000 (0.045)	
2022-03-31 18:37:36,080: ============================================================
2022-03-31 18:38:21,100: time cost, forward:0.1593479535273794, backward:0.03613044935752306, data cost:0.261951726821469 
2022-03-31 18:38:21,101: ============================================================
2022-03-31 18:38:21,101: Epoch 11/31 Batch 1100/7662 eta: 19:59:04.657405	Training Loss 0.8281 (0.8276)	Training Prec@1 0.000 (0.011)	Training Prec@5 0.000 (0.042)	
2022-03-31 18:38:21,101: ============================================================
2022-03-31 18:39:08,234: time cost, forward:0.15985097499366996, backward:0.036314601198248905, data cost:0.26237058202061087 
2022-03-31 18:39:08,235: ============================================================
2022-03-31 18:39:08,236: Epoch 11/31 Batch 1200/7662 eta: 20:54:35.242181	Training Loss 0.8279 (0.8276)	Training Prec@1 0.000 (0.011)	Training Prec@5 0.000 (0.041)	
2022-03-31 18:39:08,236: ============================================================
2022-03-31 18:39:54,775: time cost, forward:0.16020580343873433, backward:0.03634538441276991, data cost:0.2625213587073017 
2022-03-31 18:39:54,775: ============================================================
2022-03-31 18:39:54,776: Epoch 11/31 Batch 1300/7662 eta: 20:37:59.372366	Training Loss 0.8280 (0.8276)	Training Prec@1 0.000 (0.011)	Training Prec@5 0.000 (0.040)	
2022-03-31 18:39:54,776: ============================================================
2022-03-31 18:40:41,582: time cost, forward:0.1615352073339499, backward:0.03645276205296002, data cost:0.26170922433418237 
2022-03-31 18:40:41,583: ============================================================
2022-03-31 18:40:41,583: Epoch 11/31 Batch 1400/7662 eta: 20:44:19.121259	Training Loss 0.8282 (0.8276)	Training Prec@1 0.000 (0.011)	Training Prec@5 0.195 (0.039)	
2022-03-31 18:40:41,583: ============================================================
2022-03-31 18:41:27,945: time cost, forward:0.16114503403676997, backward:0.03646845003220938, data cost:0.26233499920153475 
2022-03-31 18:41:27,946: ============================================================
2022-03-31 18:41:27,946: Epoch 11/31 Batch 1500/7662 eta: 20:31:44.099407	Training Loss 0.8255 (0.8275)	Training Prec@1 0.000 (0.011)	Training Prec@5 0.000 (0.039)	
2022-03-31 18:41:27,946: ============================================================
2022-03-31 18:42:14,289: time cost, forward:0.16202545136194665, backward:0.03652975617385492, data cost:0.26152677398834323 
2022-03-31 18:42:14,289: ============================================================
2022-03-31 18:42:14,289: Epoch 11/31 Batch 1600/7662 eta: 20:30:26.321677	Training Loss 0.8256 (0.8275)	Training Prec@1 0.000 (0.010)	Training Prec@5 0.000 (0.038)	
2022-03-31 18:42:14,290: ============================================================
2022-03-31 18:43:01,629: time cost, forward:0.16351815614369142, backward:0.036657909423621564, data cost:0.2606564631807306 
2022-03-31 18:43:01,629: ============================================================
2022-03-31 18:43:01,630: Epoch 11/31 Batch 1700/7662 eta: 20:56:06.982843	Training Loss 0.8274 (0.8274)	Training Prec@1 0.000 (0.010)	Training Prec@5 0.000 (0.037)	
2022-03-31 18:43:01,630: ============================================================
2022-03-31 18:43:48,267: time cost, forward:0.16281036220039508, backward:0.03659190264856106, data cost:0.2617416919901213 
2022-03-31 18:43:48,268: ============================================================
2022-03-31 18:43:48,268: Epoch 11/31 Batch 1800/7662 eta: 20:36:42.553508	Training Loss 0.8253 (0.8274)	Training Prec@1 0.000 (0.009)	Training Prec@5 0.000 (0.036)	
2022-03-31 18:43:48,268: ============================================================
2022-03-31 18:44:30,831: time cost, forward:0.16122394790769942, backward:0.036395042805121784, data cost:0.26163538045918333 
2022-03-31 18:44:30,831: ============================================================
2022-03-31 18:44:30,832: Epoch 11/31 Batch 1900/7662 eta: 18:47:57.753186	Training Loss 0.8275 (0.8274)	Training Prec@1 0.000 (0.009)	Training Prec@5 0.000 (0.035)	
2022-03-31 18:44:30,832: ============================================================
2022-03-31 18:45:18,957: time cost, forward:0.16220928144908178, backward:0.03644500761523493, data cost:0.2616818236255121 
2022-03-31 18:45:18,957: ============================================================
2022-03-31 18:45:18,957: Epoch 11/31 Batch 2000/7662 eta: 21:14:33.306467	Training Loss 0.8271 (0.8273)	Training Prec@1 0.000 (0.009)	Training Prec@5 0.000 (0.035)	
2022-03-31 18:45:18,957: ============================================================
2022-03-31 18:46:02,733: time cost, forward:0.16136676041837986, backward:0.036359845484478695, data cost:0.26148472518339333 
2022-03-31 18:46:02,734: ============================================================
2022-03-31 18:46:02,734: Epoch 11/31 Batch 2100/7662 eta: 19:18:38.598212	Training Loss 0.8269 (0.8273)	Training Prec@1 0.000 (0.009)	Training Prec@5 0.000 (0.035)	
2022-03-31 18:46:02,734: ============================================================
2022-03-31 18:46:48,884: time cost, forward:0.16093782925399774, backward:0.036259436835045705, data cost:0.2620950303548246 
2022-03-31 18:46:48,884: ============================================================
2022-03-31 18:46:48,884: Epoch 11/31 Batch 2200/7662 eta: 20:20:41.855029	Training Loss 0.8255 (0.8273)	Training Prec@1 0.000 (0.009)	Training Prec@5 0.000 (0.035)	
2022-03-31 18:46:48,884: ============================================================
2022-03-31 18:47:32,673: time cost, forward:0.1606834359975834, backward:0.03616543612619129, data cost:0.26150629363821193 
2022-03-31 18:47:32,674: ============================================================
2022-03-31 18:47:32,674: Epoch 11/31 Batch 2300/7662 eta: 19:17:31.659205	Training Loss 0.8266 (0.8272)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.034)	
2022-03-31 18:47:32,674: ============================================================
2022-03-31 18:48:16,342: time cost, forward:0.1593398870950741, backward:0.03605527408722293, data cost:0.26204508610097704 
2022-03-31 18:48:16,342: ============================================================
2022-03-31 18:48:16,343: Epoch 11/31 Batch 2400/7662 eta: 19:13:36.519611	Training Loss 0.8265 (0.8272)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.035)	
2022-03-31 18:48:16,343: ============================================================
2022-03-31 18:49:04,379: time cost, forward:0.16026470078235153, backward:0.036090671181344854, data cost:0.2619943826758609 
2022-03-31 18:49:04,379: ============================================================
2022-03-31 18:49:04,380: Epoch 11/31 Batch 2500/7662 eta: 21:08:11.403214	Training Loss 0.8277 (0.8271)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.035)	
2022-03-31 18:49:04,380: ============================================================
2022-03-31 18:49:48,505: time cost, forward:0.15956420410408703, backward:0.03601234121568481, data cost:0.2620754805194639 
2022-03-31 18:49:48,506: ============================================================
2022-03-31 18:49:48,506: Epoch 11/31 Batch 2600/7662 eta: 19:24:13.618414	Training Loss 0.8281 (0.8271)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.034)	
2022-03-31 18:49:48,506: ============================================================
2022-03-31 18:50:34,127: time cost, forward:0.15896039196366335, backward:0.03595582597032217, data cost:0.26267179951662484 
2022-03-31 18:50:34,127: ============================================================
2022-03-31 18:50:34,127: Epoch 11/31 Batch 2700/7662 eta: 20:02:54.666159	Training Loss 0.8247 (0.8271)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.035)	
2022-03-31 18:50:34,128: ============================================================
2022-03-31 18:51:20,824: time cost, forward:0.15923905670749328, backward:0.03602667347198301, data cost:0.2626621975307594 
2022-03-31 18:51:20,825: ============================================================
2022-03-31 18:51:20,825: Epoch 11/31 Batch 2800/7662 eta: 20:30:30.319167	Training Loss 0.8272 (0.8270)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.034)	
2022-03-31 18:51:20,825: ============================================================
2022-03-31 18:52:08,089: time cost, forward:0.16020786412710483, backward:0.03614666125576181, data cost:0.26204657052952324 
2022-03-31 18:52:08,089: ============================================================
2022-03-31 18:52:08,090: Epoch 11/31 Batch 2900/7662 eta: 20:44:39.240008	Training Loss 0.8262 (0.8270)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.034)	
2022-03-31 18:52:08,090: ============================================================
2022-03-31 18:52:55,445: time cost, forward:0.16088638014696408, backward:0.03623065919866559, data cost:0.2617906657565868 
2022-03-31 18:52:55,445: ============================================================
2022-03-31 18:52:55,445: Epoch 11/31 Batch 3000/7662 eta: 20:46:16.116549	Training Loss 0.8268 (0.8270)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.034)	
2022-03-31 18:52:55,445: ============================================================
2022-03-31 18:53:42,158: time cost, forward:0.16148995176058656, backward:0.03623426033628106, data cost:0.2614398713495009 
2022-03-31 18:53:42,159: ============================================================
2022-03-31 18:53:42,159: Epoch 11/31 Batch 3100/7662 eta: 20:28:35.956451	Training Loss 0.8248 (0.8269)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.034)	
2022-03-31 18:53:42,159: ============================================================
2022-03-31 18:54:28,942: time cost, forward:0.1621360410634858, backward:0.036230319512937544, data cost:0.26106101671357795 
2022-03-31 18:54:28,942: ============================================================
2022-03-31 18:54:28,942: Epoch 11/31 Batch 3200/7662 eta: 20:29:38.448273	Training Loss 0.8248 (0.8269)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.034)	
2022-03-31 18:54:28,943: ============================================================
2022-03-31 18:55:13,327: time cost, forward:0.16140116760679432, backward:0.03620915204765364, data cost:0.26131086676147497 
2022-03-31 18:55:13,327: ============================================================
2022-03-31 18:55:13,328: Epoch 11/31 Batch 3300/7662 eta: 19:25:52.498102	Training Loss 0.8253 (0.8268)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.034)	
2022-03-31 18:55:13,328: ============================================================
2022-03-31 18:55:59,487: time cost, forward:0.16165028224450134, backward:0.036193018066213216, data cost:0.26116139701479635 
2022-03-31 18:55:59,487: ============================================================
2022-03-31 18:55:59,487: Epoch 11/31 Batch 3400/7662 eta: 20:11:43.047346	Training Loss 0.8254 (0.8268)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.034)	
2022-03-31 18:55:59,488: ============================================================
2022-03-31 18:56:45,403: time cost, forward:0.16181283257422566, backward:0.03622534214411166, data cost:0.2609448011822958 
2022-03-31 18:56:45,404: ============================================================
2022-03-31 18:56:45,404: Epoch 11/31 Batch 3500/7662 eta: 20:04:33.750117	Training Loss 0.8245 (0.8268)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.034)	
2022-03-31 18:56:45,404: ============================================================
2022-03-31 18:57:32,268: time cost, forward:0.16238142192678406, backward:0.03629210784257071, data cost:0.26057439606929694 
2022-03-31 18:57:32,268: ============================================================
2022-03-31 18:57:32,269: Epoch 11/31 Batch 3600/7662 eta: 20:28:39.622670	Training Loss 0.8252 (0.8267)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.035)	
2022-03-31 18:57:32,269: ============================================================
2022-03-31 18:58:16,063: time cost, forward:0.16144749305479653, backward:0.036187379545184466, data cost:0.2610110983264611 
2022-03-31 18:58:16,064: ============================================================
2022-03-31 18:58:16,064: Epoch 11/31 Batch 3700/7662 eta: 19:07:28.040072	Training Loss 0.8254 (0.8267)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.035)	
2022-03-31 18:58:16,064: ============================================================
2022-03-31 18:59:02,078: time cost, forward:0.16152354710100197, backward:0.03613502209234878, data cost:0.26098078487734633 
2022-03-31 18:59:02,079: ============================================================
2022-03-31 18:59:02,079: Epoch 11/31 Batch 3800/7662 eta: 20:04:50.996181	Training Loss 0.8279 (0.8266)	Training Prec@1 0.000 (0.009)	Training Prec@5 0.000 (0.036)	
2022-03-31 18:59:02,080: ============================================================
2022-03-31 18:59:46,431: time cost, forward:0.16103930435415476, backward:0.03610252098842718, data cost:0.2611357259518001 
2022-03-31 18:59:46,432: ============================================================
2022-03-31 18:59:46,432: Epoch 11/31 Batch 3900/7662 eta: 19:20:34.973746	Training Loss 0.8234 (0.8266)	Training Prec@1 0.000 (0.009)	Training Prec@5 0.000 (0.036)	
2022-03-31 18:59:46,432: ============================================================
2022-03-31 19:00:33,138: time cost, forward:0.1611909546176026, backward:0.03610217180750495, data cost:0.2611933110445313 
2022-03-31 19:00:33,139: ============================================================
2022-03-31 19:00:33,139: Epoch 11/31 Batch 4000/7662 eta: 20:21:25.114062	Training Loss 0.8265 (0.8266)	Training Prec@1 0.000 (0.009)	Training Prec@5 0.000 (0.036)	
2022-03-31 19:00:33,140: ============================================================
2022-03-31 19:01:17,841: time cost, forward:0.16103596511658413, backward:0.03608724180446307, data cost:0.26108972442880085 
2022-03-31 19:01:17,842: ============================================================
2022-03-31 19:01:17,842: Epoch 11/31 Batch 4100/7662 eta: 19:28:15.414160	Training Loss 0.8251 (0.8265)	Training Prec@1 0.195 (0.009)	Training Prec@5 0.195 (0.036)	
2022-03-31 19:01:17,842: ============================================================
2022-03-31 19:02:05,192: time cost, forward:0.16108308584527137, backward:0.036076481497324654, data cost:0.2613854031813772 
2022-03-31 19:02:05,192: ============================================================
2022-03-31 19:02:05,193: Epoch 11/31 Batch 4200/7662 eta: 20:36:39.848833	Training Loss 0.8259 (0.8265)	Training Prec@1 0.000 (0.009)	Training Prec@5 0.195 (0.037)	
2022-03-31 19:02:05,193: ============================================================
2022-03-31 19:02:51,306: time cost, forward:0.1610596575385389, backward:0.03604428666667845, data cost:0.2615143345466573 
2022-03-31 19:02:51,306: ============================================================
2022-03-31 19:02:51,306: Epoch 11/31 Batch 4300/7662 eta: 20:03:35.614826	Training Loss 0.8235 (0.8264)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.037)	
2022-03-31 19:02:51,307: ============================================================
2022-03-31 19:03:36,686: time cost, forward:0.16071533219167713, backward:0.036083724721504035, data cost:0.2616863801929728 
2022-03-31 19:03:36,686: ============================================================
2022-03-31 19:03:36,687: Epoch 11/31 Batch 4400/7662 eta: 19:43:41.140683	Training Loss 0.8264 (0.8264)	Training Prec@1 0.000 (0.009)	Training Prec@5 0.000 (0.037)	
2022-03-31 19:03:36,687: ============================================================
2022-03-31 19:04:21,272: time cost, forward:0.1603871655215102, backward:0.036061794764732195, data cost:0.2617395787960849 
2022-03-31 19:04:21,273: ============================================================
2022-03-31 19:04:21,273: Epoch 11/31 Batch 4500/7662 eta: 19:22:14.554499	Training Loss 0.8261 (0.8264)	Training Prec@1 0.000 (0.009)	Training Prec@5 0.000 (0.037)	
2022-03-31 19:04:21,273: ============================================================
2022-03-31 19:05:07,673: time cost, forward:0.16045361924466944, backward:0.03608999062579828, data cost:0.2617733268070076 
2022-03-31 19:05:07,674: ============================================================
2022-03-31 19:05:07,674: Epoch 11/31 Batch 4600/7662 eta: 20:08:45.951596	Training Loss 0.8250 (0.8263)	Training Prec@1 0.000 (0.009)	Training Prec@5 0.000 (0.037)	
2022-03-31 19:05:07,674: ============================================================
2022-03-31 19:05:55,479: time cost, forward:0.1606575761812498, backward:0.03609707274825605, data cost:0.26197244258960983 
2022-03-31 19:05:55,479: ============================================================
2022-03-31 19:05:55,479: Epoch 11/31 Batch 4700/7662 eta: 20:44:33.606219	Training Loss 0.8246 (0.8263)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.037)	
2022-03-31 19:05:55,480: ============================================================
2022-03-31 19:06:41,643: time cost, forward:0.1608790541519893, backward:0.03608866263538829, data cost:0.26179163355110935 
2022-03-31 19:06:41,643: ============================================================
2022-03-31 19:06:41,644: Epoch 11/31 Batch 4800/7662 eta: 20:01:03.792415	Training Loss 0.8250 (0.8262)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.037)	
2022-03-31 19:06:41,644: ============================================================
2022-03-31 19:07:28,646: time cost, forward:0.16113494206117254, backward:0.036099318753312765, data cost:0.26174948910932977 
2022-03-31 19:07:28,647: ============================================================
2022-03-31 19:07:28,647: Epoch 11/31 Batch 4900/7662 eta: 20:22:07.013650	Training Loss 0.8268 (0.8262)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.037)	
2022-03-31 19:07:28,647: ============================================================
2022-03-31 19:08:15,072: time cost, forward:0.16116519798443638, backward:0.03608538928473561, data cost:0.2618464009478989 
2022-03-31 19:08:15,072: ============================================================
2022-03-31 19:08:15,072: Epoch 11/31 Batch 5000/7662 eta: 20:06:18.343466	Training Loss 0.8233 (0.8262)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.195 (0.037)	
2022-03-31 19:08:15,073: ============================================================
2022-03-31 19:09:00,771: time cost, forward:0.16087889951873138, backward:0.03606999600768253, data cost:0.2620839205740199 
2022-03-31 19:09:00,772: ============================================================
2022-03-31 19:09:00,772: Epoch 11/31 Batch 5100/7662 eta: 19:46:41.605554	Training Loss 0.8227 (0.8261)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.037)	
2022-03-31 19:09:00,772: ============================================================
2022-03-31 19:09:45,840: time cost, forward:0.16082131190812687, backward:0.03605264644252266, data cost:0.26198744948127217 
2022-03-31 19:09:45,841: ============================================================
2022-03-31 19:09:45,841: Epoch 11/31 Batch 5200/7662 eta: 19:29:33.757979	Training Loss 0.8260 (0.8261)	Training Prec@1 0.000 (0.009)	Training Prec@5 0.000 (0.038)	
2022-03-31 19:09:45,841: ============================================================
2022-03-31 19:10:29,603: time cost, forward:0.1605898305410978, backward:0.03602393849162836, data cost:0.26184957673986536 
2022-03-31 19:10:29,603: ============================================================
2022-03-31 19:10:29,603: Epoch 11/31 Batch 5300/7662 eta: 18:54:55.361171	Training Loss 0.8253 (0.8261)	Training Prec@1 0.000 (0.009)	Training Prec@5 0.000 (0.038)	
2022-03-31 19:10:29,604: ============================================================
2022-03-31 19:11:16,668: time cost, forward:0.16080021081003443, backward:0.03605062366746315, data cost:0.2618113472011712 
2022-03-31 19:11:16,668: ============================================================
2022-03-31 19:11:16,668: Epoch 11/31 Batch 5400/7662 eta: 20:19:47.532270	Training Loss 0.8243 (0.8260)	Training Prec@1 0.000 (0.009)	Training Prec@5 0.000 (0.038)	
2022-03-31 19:11:16,669: ============================================================
2022-03-31 19:12:02,387: time cost, forward:0.16066238589233908, backward:0.036031260969942754, data cost:0.26194783283767104 
2022-03-31 19:12:02,388: ============================================================
2022-03-31 19:12:02,388: Epoch 11/31 Batch 5500/7662 eta: 19:44:09.763313	Training Loss 0.8233 (0.8260)	Training Prec@1 0.000 (0.009)	Training Prec@5 0.000 (0.038)	
2022-03-31 19:12:02,388: ============================================================
2022-03-31 19:12:48,486: time cost, forward:0.1607623719853958, backward:0.03603886663754043, data cost:0.26187396858564166 
2022-03-31 19:12:48,486: ============================================================
2022-03-31 19:12:48,486: Epoch 11/31 Batch 5600/7662 eta: 19:53:12.006902	Training Loss 0.8263 (0.8259)	Training Prec@1 0.000 (0.009)	Training Prec@5 0.000 (0.039)	
2022-03-31 19:12:48,487: ============================================================
2022-03-31 19:13:34,318: time cost, forward:0.16063410400361172, backward:0.03604030855958306, data cost:0.26194838984720875 
2022-03-31 19:13:34,318: ============================================================
2022-03-31 19:13:34,319: Epoch 11/31 Batch 5700/7662 eta: 19:45:32.685611	Training Loss 0.8256 (0.8259)	Training Prec@1 0.000 (0.009)	Training Prec@5 0.000 (0.039)	
2022-03-31 19:13:34,319: ============================================================
2022-03-31 19:14:18,616: time cost, forward:0.1604205481162008, backward:0.035997592286624504, data cost:0.2619574392719667 
2022-03-31 19:14:18,617: ============================================================
2022-03-31 19:14:18,617: Epoch 11/31 Batch 5800/7662 eta: 19:05:08.965591	Training Loss 0.8246 (0.8259)	Training Prec@1 0.000 (0.009)	Training Prec@5 0.000 (0.040)	
2022-03-31 19:14:18,618: ============================================================
2022-03-31 19:15:05,373: time cost, forward:0.16044023849738212, backward:0.035975194054147834, data cost:0.2621186368444003 
2022-03-31 19:15:05,374: ============================================================
2022-03-31 19:15:05,374: Epoch 11/31 Batch 5900/7662 eta: 20:07:54.033137	Training Loss 0.8239 (0.8258)	Training Prec@1 0.000 (0.009)	Training Prec@5 0.195 (0.040)	
2022-03-31 19:15:05,374: ============================================================
2022-03-31 19:15:47,469: time cost, forward:0.16003268328204237, backward:0.03594814866637166, data cost:0.2619273882743656 
2022-03-31 19:15:47,469: ============================================================
2022-03-31 19:15:47,469: Epoch 11/31 Batch 6000/7662 eta: 18:06:46.951558	Training Loss 0.8213 (0.8258)	Training Prec@1 0.000 (0.009)	Training Prec@5 0.391 (0.040)	
2022-03-31 19:15:47,469: ============================================================
2022-03-31 19:16:32,880: time cost, forward:0.15995009783194247, backward:0.035953781686467914, data cost:0.2619186433969433 
2022-03-31 19:16:32,880: ============================================================
2022-03-31 19:16:32,880: Epoch 11/31 Batch 6100/7662 eta: 19:31:37.484794	Training Loss 0.8235 (0.8258)	Training Prec@1 0.000 (0.009)	Training Prec@5 0.000 (0.041)	
2022-03-31 19:16:32,880: ============================================================
2022-03-31 19:17:17,698: time cost, forward:0.15987324933887279, backward:0.03595506796857622, data cost:0.2618479989078434 
2022-03-31 19:17:17,698: ============================================================
2022-03-31 19:17:17,698: Epoch 11/31 Batch 6200/7662 eta: 19:15:34.703983	Training Loss 0.8229 (0.8257)	Training Prec@1 0.000 (0.009)	Training Prec@5 0.000 (0.041)	
2022-03-31 19:17:17,698: ============================================================
2022-03-31 19:18:05,350: time cost, forward:0.15986411297845546, backward:0.03596650957966593, data cost:0.262120345146396 
2022-03-31 19:18:05,350: ============================================================
2022-03-31 19:18:05,351: Epoch 11/31 Batch 6300/7662 eta: 20:27:51.962591	Training Loss 0.8229 (0.8257)	Training Prec@1 0.000 (0.009)	Training Prec@5 0.000 (0.041)	
2022-03-31 19:18:05,351: ============================================================
2022-03-31 19:18:50,595: time cost, forward:0.15985170023984174, backward:0.03595510209458082, data cost:0.26205800316970523 
2022-03-31 19:18:50,596: ============================================================
2022-03-31 19:18:50,596: Epoch 11/31 Batch 6400/7662 eta: 19:25:06.064621	Training Loss 0.8222 (0.8256)	Training Prec@1 0.000 (0.010)	Training Prec@5 0.000 (0.042)	
2022-03-31 19:18:50,597: ============================================================
2022-03-31 19:19:37,243: time cost, forward:0.1600546410201531, backward:0.035965610676718635, data cost:0.261987261303316 
2022-03-31 19:19:37,244: ============================================================
2022-03-31 19:19:37,244: Epoch 11/31 Batch 6500/7662 eta: 20:00:25.884938	Training Loss 0.8230 (0.8256)	Training Prec@1 0.195 (0.010)	Training Prec@5 0.195 (0.042)	
2022-03-31 19:19:37,244: ============================================================
2022-03-31 19:20:22,554: time cost, forward:0.1602891968098314, backward:0.03597454393175555, data cost:0.2616556212836675 
2022-03-31 19:20:22,555: ============================================================
2022-03-31 19:20:22,555: Epoch 11/31 Batch 6600/7662 eta: 19:25:15.655651	Training Loss 0.8251 (0.8256)	Training Prec@1 0.000 (0.010)	Training Prec@5 0.000 (0.043)	
2022-03-31 19:20:22,555: ============================================================
2022-03-31 19:21:06,929: time cost, forward:0.15986140124173925, backward:0.03593877173658805, data cost:0.2619041731365048 
2022-03-31 19:21:06,929: ============================================================
2022-03-31 19:21:06,929: Epoch 11/31 Batch 6700/7662 eta: 19:00:26.601099	Training Loss 0.8221 (0.8255)	Training Prec@1 0.000 (0.010)	Training Prec@5 0.000 (0.043)	
2022-03-31 19:21:06,929: ============================================================
2022-03-31 19:21:50,557: time cost, forward:0.159695587573393, backward:0.035921690270802185, data cost:0.26176501866876595 
2022-03-31 19:21:50,558: ============================================================
2022-03-31 19:21:50,558: Epoch 11/31 Batch 6800/7662 eta: 18:40:32.992666	Training Loss 0.8239 (0.8255)	Training Prec@1 0.000 (0.010)	Training Prec@5 0.000 (0.044)	
2022-03-31 19:21:50,558: ============================================================
2022-03-31 19:22:38,011: time cost, forward:0.1598250755349317, backward:0.03591813742552897, data cost:0.2618810699580113 
2022-03-31 19:22:38,012: ============================================================
2022-03-31 19:22:38,012: Epoch 11/31 Batch 6900/7662 eta: 20:18:00.639424	Training Loss 0.8242 (0.8254)	Training Prec@1 0.000 (0.010)	Training Prec@5 0.000 (0.044)	
2022-03-31 19:22:38,012: ============================================================
2022-03-31 19:23:22,995: time cost, forward:0.1597814760577391, backward:0.035894872495354474, data cost:0.2618255868675471 
2022-03-31 19:23:22,995: ============================================================
2022-03-31 19:23:22,996: Epoch 11/31 Batch 7000/7662 eta: 19:13:51.158558	Training Loss 0.8231 (0.8254)	Training Prec@1 0.000 (0.010)	Training Prec@5 0.000 (0.044)	
2022-03-31 19:23:22,996: ============================================================
2022-03-31 19:24:08,746: time cost, forward:0.1598727533827031, backward:0.035889175915855775, data cost:0.2617308218590994 
2022-03-31 19:24:08,747: ============================================================
2022-03-31 19:24:08,747: Epoch 11/31 Batch 7100/7662 eta: 19:32:47.222648	Training Loss 0.8217 (0.8253)	Training Prec@1 0.000 (0.010)	Training Prec@5 0.000 (0.045)	
2022-03-31 19:24:08,747: ============================================================
2022-03-31 19:24:55,551: time cost, forward:0.15996411310697467, backward:0.03590095929096666, data cost:0.26176868486543514 
2022-03-31 19:24:55,551: ============================================================
2022-03-31 19:24:55,552: Epoch 11/31 Batch 7200/7662 eta: 19:58:59.913098	Training Loss 0.8227 (0.8253)	Training Prec@1 0.000 (0.010)	Training Prec@5 0.195 (0.045)	
2022-03-31 19:24:55,552: ============================================================
2022-03-31 19:25:40,014: time cost, forward:0.15993993108216042, backward:0.03589992060009985, data cost:0.26162311631958035 
2022-03-31 19:25:40,014: ============================================================
2022-03-31 19:25:40,015: Epoch 11/31 Batch 7300/7662 eta: 18:58:16.413356	Training Loss 0.8230 (0.8253)	Training Prec@1 0.000 (0.011)	Training Prec@5 0.000 (0.046)	
2022-03-31 19:25:40,015: ============================================================
2022-03-31 19:26:25,611: time cost, forward:0.15996408024290507, backward:0.03588615418898285, data cost:0.2615865032195014 
2022-03-31 19:26:25,611: ============================================================
2022-03-31 19:26:25,611: Epoch 11/31 Batch 7400/7662 eta: 19:26:32.644154	Training Loss 0.8215 (0.8252)	Training Prec@1 0.000 (0.011)	Training Prec@5 0.195 (0.047)	
2022-03-31 19:26:25,612: ============================================================
2022-03-31 19:27:12,316: time cost, forward:0.15992313837238845, backward:0.03589720852550848, data cost:0.2617385926318496 
2022-03-31 19:27:12,317: ============================================================
2022-03-31 19:27:12,317: Epoch 11/31 Batch 7500/7662 eta: 19:54:07.672006	Training Loss 0.8206 (0.8251)	Training Prec@1 0.000 (0.011)	Training Prec@5 0.000 (0.047)	
2022-03-31 19:27:12,317: ============================================================
2022-03-31 19:27:57,966: time cost, forward:0.15996554309183836, backward:0.035892308676049874, data cost:0.26168008069644433 
2022-03-31 19:27:57,966: ============================================================
2022-03-31 19:27:57,967: Epoch 11/31 Batch 7600/7662 eta: 19:26:22.135059	Training Loss 0.8236 (0.8251)	Training Prec@1 0.000 (0.011)	Training Prec@5 0.000 (0.048)	
2022-03-31 19:27:57,967: ============================================================
2022-03-31 19:28:25,013: Epoch: 11/31 eta: 19:25:53.375841	Training Loss 0.8231 (0.8251)	Training Prec@1 0.000 (0.011)	Training Prec@5 0.000 (0.049)
2022-03-31 19:28:25,013: ============================================================
2022-03-31 19:29:52,489: time cost, forward:0.11256066476455842, backward:0.033785085485439105, data cost:0.7345782048774488 
2022-03-31 19:29:52,489: ============================================================
2022-03-31 19:29:52,490: Epoch 12/31 Batch 100/7662 eta: 1 day, 13:11:52.348053	Training Loss 0.8186 (0.8190)	Training Prec@1 0.195 (0.039)	Training Prec@5 0.195 (0.116)	
2022-03-31 19:29:52,490: ============================================================
2022-03-31 19:30:28,035: time cost, forward:0.11223434802874847, backward:0.0335013015785409, data cost:0.4709341118683168 
2022-03-31 19:30:28,036: ============================================================
2022-03-31 19:30:28,036: Epoch 12/31 Batch 200/7662 eta: 15:06:40.192131	Training Loss 0.8198 (0.8188)	Training Prec@1 0.000 (0.033)	Training Prec@5 0.000 (0.123)	
2022-03-31 19:30:28,036: ============================================================
2022-03-31 19:31:06,207: time cost, forward:0.11235009148766763, backward:0.03334825174465626, data cost:0.3922268275831854 
2022-03-31 19:31:06,208: ============================================================
2022-03-31 19:31:06,208: Epoch 12/31 Batch 300/7662 eta: 16:13:01.143806	Training Loss 0.8170 (0.8185)	Training Prec@1 0.000 (0.038)	Training Prec@5 0.391 (0.144)	
2022-03-31 19:31:06,208: ============================================================
2022-03-31 19:31:44,724: time cost, forward:0.11201482966430205, backward:0.03306096657774502, data cost:0.3543473096718465 
2022-03-31 19:31:44,724: ============================================================
2022-03-31 19:31:44,725: Epoch 12/31 Batch 400/7662 eta: 16:21:09.195799	Training Loss 0.8193 (0.8182)	Training Prec@1 0.195 (0.037)	Training Prec@5 0.195 (0.143)	
2022-03-31 19:31:44,725: ============================================================
2022-03-31 19:32:26,770: time cost, forward:0.1116945972901308, backward:0.03261408251607585, data cost:0.33927288179646037 
2022-03-31 19:32:26,771: ============================================================
2022-03-31 19:32:26,771: Epoch 12/31 Batch 500/7662 eta: 17:50:21.632722	Training Loss 0.8184 (0.8178)	Training Prec@1 0.000 (0.037)	Training Prec@5 0.195 (0.153)	
2022-03-31 19:32:26,771: ============================================================
2022-03-31 19:33:05,855: time cost, forward:0.11149757891545113, backward:0.03245271466212201, data cost:0.32408075539615994 
2022-03-31 19:33:05,855: ============================================================
2022-03-31 19:33:05,855: Epoch 12/31 Batch 600/7662 eta: 16:34:19.155540	Training Loss 0.8151 (0.8173)	Training Prec@1 0.000 (0.039)	Training Prec@5 0.000 (0.160)	
2022-03-31 19:33:05,855: ============================================================
2022-03-31 19:33:46,590: time cost, forward:0.11132321541913077, backward:0.03256694714569398, data cost:0.3154232573611542 
2022-03-31 19:33:46,591: ============================================================
2022-03-31 19:33:46,591: Epoch 12/31 Batch 700/7662 eta: 17:15:38.880005	Training Loss 0.8133 (0.8168)	Training Prec@1 0.195 (0.044)	Training Prec@5 0.391 (0.178)	
2022-03-31 19:33:46,591: ============================================================
2022-03-31 19:34:26,934: time cost, forward:0.11117067504138016, backward:0.03249403233820566, data cost:0.3085310903747329 
2022-03-31 19:34:26,935: ============================================================
2022-03-31 19:34:26,935: Epoch 12/31 Batch 800/7662 eta: 17:05:00.290912	Training Loss 0.8096 (0.8162)	Training Prec@1 0.000 (0.050)	Training Prec@5 0.391 (0.197)	
2022-03-31 19:34:26,935: ============================================================
2022-03-31 19:35:10,498: time cost, forward:0.11406912925643836, backward:0.03267185282256367, data cost:0.30363289002449284 
2022-03-31 19:35:10,499: ============================================================
2022-03-31 19:35:10,499: Epoch 12/31 Batch 900/7662 eta: 18:26:06.158873	Training Loss 0.8098 (0.8157)	Training Prec@1 0.195 (0.057)	Training Prec@5 0.781 (0.218)	
2022-03-31 19:35:10,499: ============================================================
2022-03-31 19:35:55,600: time cost, forward:0.1169754196335007, backward:0.032924215595524116, data cost:0.3005536814948341 
2022-03-31 19:35:55,600: ============================================================
2022-03-31 19:35:55,600: Epoch 12/31 Batch 1000/7662 eta: 19:04:22.618956	Training Loss 0.8088 (0.8150)	Training Prec@1 0.195 (0.064)	Training Prec@5 0.195 (0.236)	
2022-03-31 19:35:55,601: ============================================================
2022-03-31 19:36:39,478: time cost, forward:0.11936102117377048, backward:0.03265803938458679, data cost:0.2972296449246463 
2022-03-31 19:36:39,478: ============================================================
2022-03-31 19:36:39,479: Epoch 12/31 Batch 1100/7662 eta: 18:32:36.825567	Training Loss 0.8083 (0.8144)	Training Prec@1 0.000 (0.070)	Training Prec@5 0.000 (0.258)	
2022-03-31 19:36:39,479: ============================================================
2022-03-31 19:37:25,207: time cost, forward:0.12242693201117559, backward:0.03207758807261056, data cost:0.2954722419194722 
2022-03-31 19:37:25,207: ============================================================
2022-03-31 19:37:25,207: Epoch 12/31 Batch 1200/7662 eta: 19:18:46.290726	Training Loss 0.8080 (0.8138)	Training Prec@1 0.000 (0.078)	Training Prec@5 0.000 (0.283)	
2022-03-31 19:37:25,207: ============================================================
2022-03-31 19:38:11,568: time cost, forward:0.12599735795946834, backward:0.03192353707446421, data cost:0.2930613913106588 
2022-03-31 19:38:11,568: ============================================================
2022-03-31 19:38:11,569: Epoch 12/31 Batch 1300/7662 eta: 19:34:01.893098	Training Loss 0.8074 (0.8133)	Training Prec@1 0.000 (0.087)	Training Prec@5 0.781 (0.311)	
2022-03-31 19:38:11,569: ============================================================
2022-03-31 19:38:59,590: time cost, forward:0.1293253977014134, backward:0.032164826062511254, data cost:0.2915719666593496 
2022-03-31 19:38:59,590: ============================================================
2022-03-31 19:38:59,590: Epoch 12/31 Batch 1400/7662 eta: 20:15:16.701757	Training Loss 0.8339 (0.8141)	Training Prec@1 0.000 (0.085)	Training Prec@5 0.000 (0.305)	
2022-03-31 19:38:59,591: ============================================================
2022-03-31 19:39:46,616: time cost, forward:0.13209507861401415, backward:0.03239492498452541, data cost:0.2896729040495788 
2022-03-31 19:39:46,616: ============================================================
2022-03-31 19:39:46,616: Epoch 12/31 Batch 1500/7662 eta: 19:49:17.840996	Training Loss 0.8266 (0.8151)	Training Prec@1 0.000 (0.080)	Training Prec@5 0.000 (0.287)	
2022-03-31 19:39:46,617: ============================================================
2022-03-31 19:40:35,070: time cost, forward:0.13505547176382554, backward:0.0325763107762626, data cost:0.2884394503743146 
2022-03-31 19:40:35,071: ============================================================
2022-03-31 19:40:35,071: Epoch 12/31 Batch 1600/7662 eta: 20:24:36.630506	Training Loss 0.8235 (0.8157)	Training Prec@1 0.000 (0.076)	Training Prec@5 0.195 (0.274)	
2022-03-31 19:40:35,071: ============================================================
2022-03-31 19:41:20,910: time cost, forward:0.13723324550608454, backward:0.032775554466135295, data cost:0.2861385978341734 
2022-03-31 19:41:20,911: ============================================================
2022-03-31 19:41:20,911: Epoch 12/31 Batch 1700/7662 eta: 19:17:46.965488	Training Loss 0.8130 (0.8159)	Training Prec@1 0.195 (0.074)	Training Prec@5 0.391 (0.265)	
2022-03-31 19:41:20,911: ============================================================
2022-03-31 19:42:09,299: time cost, forward:0.13891516863604, backward:0.03295500534252699, data cost:0.2858295917776043 
2022-03-31 19:42:09,300: ============================================================
2022-03-31 19:42:09,300: Epoch 12/31 Batch 1800/7662 eta: 20:21:20.473078	Training Loss 0.8076 (0.8157)	Training Prec@1 0.195 (0.076)	Training Prec@5 0.391 (0.273)	
2022-03-31 19:42:09,300: ============================================================
2022-03-31 19:42:56,131: time cost, forward:0.14072881879901936, backward:0.03308001262630646, data cost:0.284353731179501 
2022-03-31 19:42:56,131: ============================================================
2022-03-31 19:42:56,131: Epoch 12/31 Batch 1900/7662 eta: 19:41:14.658640	Training Loss 0.8058 (0.8152)	Training Prec@1 0.391 (0.082)	Training Prec@5 0.977 (0.296)	
2022-03-31 19:42:56,131: ============================================================
2022-03-31 19:43:39,753: time cost, forward:0.14113357473815186, backward:0.033081380649469326, data cost:0.2828711333902196 
2022-03-31 19:43:39,754: ============================================================
2022-03-31 19:43:39,754: Epoch 12/31 Batch 2000/7662 eta: 18:19:35.718857	Training Loss 0.8012 (0.8147)	Training Prec@1 0.195 (0.085)	Training Prec@5 0.391 (0.315)	
2022-03-31 19:43:39,754: ============================================================
2022-03-31 19:44:27,084: time cost, forward:0.14278465171494104, backward:0.03308259662757208, data cost:0.28194657367090203 
2022-03-31 19:44:27,084: ============================================================
2022-03-31 19:44:27,085: Epoch 12/31 Batch 2100/7662 eta: 19:52:15.751197	Training Loss 0.8017 (0.8142)	Training Prec@1 0.000 (0.091)	Training Prec@5 0.391 (0.335)	
2022-03-31 19:44:27,085: ============================================================
2022-03-31 19:45:14,099: time cost, forward:0.14410570568797695, backward:0.03321295979349328, data cost:0.28106348272777243 
2022-03-31 19:45:14,099: ============================================================
2022-03-31 19:45:14,100: Epoch 12/31 Batch 2200/7662 eta: 19:43:32.128690	Training Loss 0.7985 (0.8136)	Training Prec@1 0.391 (0.098)	Training Prec@5 1.367 (0.361)	
2022-03-31 19:45:14,100: ============================================================
2022-03-31 19:46:01,344: time cost, forward:0.14594182806359315, backward:0.03332182561485287, data cost:0.27968080855805544 
2022-03-31 19:46:01,345: ============================================================
2022-03-31 19:46:01,345: Epoch 12/31 Batch 2300/7662 eta: 19:48:32.361015	Training Loss 0.8022 (0.8131)	Training Prec@1 0.195 (0.106)	Training Prec@5 0.977 (0.386)	
2022-03-31 19:46:01,345: ============================================================
2022-03-31 19:46:46,422: time cost, forward:0.14716990712584432, backward:0.0333771999799594, data cost:0.27803816592608854 
2022-03-31 19:46:46,422: ============================================================
2022-03-31 19:46:46,423: Epoch 12/31 Batch 2400/7662 eta: 18:53:15.789966	Training Loss 0.8366 (0.8131)	Training Prec@1 0.000 (0.111)	Training Prec@5 0.000 (0.401)	
2022-03-31 19:46:46,423: ============================================================
2022-03-31 19:47:32,267: time cost, forward:0.14794657658748314, backward:0.03343629951522845, data cost:0.27720682351004367 
2022-03-31 19:47:32,267: ============================================================
2022-03-31 19:47:32,267: Epoch 12/31 Batch 2500/7662 eta: 19:11:46.889476	Training Loss 0.8343 (0.8140)	Training Prec@1 0.000 (0.106)	Training Prec@5 0.000 (0.386)	
2022-03-31 19:47:32,268: ============================================================
2022-03-31 19:48:14,939: time cost, forward:0.14747998796090936, backward:0.03345334424381762, data cost:0.27640929218437543 
2022-03-31 19:48:14,939: ============================================================
2022-03-31 19:48:14,939: Epoch 12/31 Batch 2600/7662 eta: 17:51:21.115464	Training Loss 0.8328 (0.8147)	Training Prec@1 0.000 (0.102)	Training Prec@5 0.000 (0.371)	
2022-03-31 19:48:14,939: ============================================================
2022-03-31 19:49:02,730: time cost, forward:0.14806736200197665, backward:0.033546867791084324, data cost:0.2764741765785853 
2022-03-31 19:49:02,730: ============================================================
2022-03-31 19:49:02,730: Epoch 12/31 Batch 2700/7662 eta: 19:59:05.345609	Training Loss 0.8289 (0.8153)	Training Prec@1 0.000 (0.099)	Training Prec@5 0.000 (0.358)	
2022-03-31 19:49:02,730: ============================================================
2022-03-31 19:49:48,619: time cost, forward:0.14884327164118782, backward:0.03364960344061761, data cost:0.2756006681054522 
2022-03-31 19:49:48,620: ============================================================
2022-03-31 19:49:48,620: Epoch 12/31 Batch 2800/7662 eta: 19:10:36.659134	Training Loss 0.8286 (0.8158)	Training Prec@1 0.000 (0.096)	Training Prec@5 0.000 (0.346)	
2022-03-31 19:49:48,620: ============================================================
2022-03-31 19:50:36,303: time cost, forward:0.15013150125998964, backward:0.03372746634047456, data cost:0.27483133646322555 
2022-03-31 19:50:36,304: ============================================================
2022-03-31 19:50:36,304: Epoch 12/31 Batch 2900/7662 eta: 19:54:48.545471	Training Loss 0.8307 (0.8163)	Training Prec@1 0.000 (0.092)	Training Prec@5 0.000 (0.335)	
2022-03-31 19:50:36,304: ============================================================
2022-03-31 19:51:21,838: time cost, forward:0.15061467828334033, backward:0.033738378049056106, data cost:0.27426529415610157 
2022-03-31 19:51:21,838: ============================================================
2022-03-31 19:51:21,838: Epoch 12/31 Batch 3000/7662 eta: 19:00:11.282362	Training Loss 0.8279 (0.8166)	Training Prec@1 0.000 (0.089)	Training Prec@5 0.195 (0.325)	
2022-03-31 19:51:21,838: ============================================================
2022-03-31 19:52:09,123: time cost, forward:0.1515737710825356, backward:0.03382314978664481, data cost:0.27364553502006816 
2022-03-31 19:52:09,124: ============================================================
2022-03-31 19:52:09,124: Epoch 12/31 Batch 3100/7662 eta: 19:43:15.129533	Training Loss 0.8274 (0.8170)	Training Prec@1 0.000 (0.087)	Training Prec@5 0.000 (0.316)	
2022-03-31 19:52:09,124: ============================================================
2022-03-31 19:52:54,182: time cost, forward:0.1518401691935218, backward:0.033831484953512736, data cost:0.2730818937330851 
2022-03-31 19:52:54,182: ============================================================
2022-03-31 19:52:54,182: Epoch 12/31 Batch 3200/7662 eta: 18:46:46.055216	Training Loss 0.8270 (0.8173)	Training Prec@1 0.000 (0.084)	Training Prec@5 0.000 (0.307)	
2022-03-31 19:52:54,182: ============================================================
2022-03-31 19:53:41,823: time cost, forward:0.15290975628494674, backward:0.03389632112873652, data cost:0.2724413458380998 
2022-03-31 19:53:41,823: ============================================================
2022-03-31 19:53:41,823: Epoch 12/31 Batch 3300/7662 eta: 19:50:33.251366	Training Loss 0.8233 (0.8175)	Training Prec@1 0.000 (0.082)	Training Prec@5 0.000 (0.299)	
2022-03-31 19:53:41,823: ============================================================
2022-03-31 19:54:29,690: time cost, forward:0.15350711763027872, backward:0.03395985624095067, data cost:0.2723215516436342 
2022-03-31 19:54:29,690: ============================================================
2022-03-31 19:54:29,690: Epoch 12/31 Batch 3400/7662 eta: 19:55:24.643485	Training Loss 0.8195 (0.8177)	Training Prec@1 0.000 (0.080)	Training Prec@5 0.000 (0.293)	
2022-03-31 19:54:29,691: ============================================================
2022-03-31 19:55:16,330: time cost, forward:0.15384185072284795, backward:0.033942806615118094, data cost:0.27223486551457593 
2022-03-31 19:55:16,331: ============================================================
2022-03-31 19:55:16,331: Epoch 12/31 Batch 3500/7662 eta: 19:23:59.810189	Training Loss 0.8185 (0.8177)	Training Prec@1 0.000 (0.079)	Training Prec@5 0.391 (0.288)	
2022-03-31 19:55:16,331: ============================================================
2022-03-31 19:56:03,309: time cost, forward:0.15443130101254, backward:0.033918404585787175, data cost:0.2719153558323535 
2022-03-31 19:56:03,309: ============================================================
2022-03-31 19:56:03,310: Epoch 12/31 Batch 3600/7662 eta: 19:31:39.839105	Training Loss 0.8106 (0.8176)	Training Prec@1 0.000 (0.079)	Training Prec@5 0.000 (0.289)	
2022-03-31 19:56:03,310: ============================================================
2022-03-31 19:56:50,640: time cost, forward:0.1553180398861116, backward:0.0339614559296306, data cost:0.27132687371432634 
2022-03-31 19:56:50,641: ============================================================
2022-03-31 19:56:50,641: Epoch 12/31 Batch 3700/7662 eta: 19:39:39.260827	Training Loss 0.8054 (0.8173)	Training Prec@1 0.195 (0.081)	Training Prec@5 1.172 (0.297)	
2022-03-31 19:56:50,641: ============================================================
2022-03-31 19:57:36,063: time cost, forward:0.1556457944153547, backward:0.033955233948705824, data cost:0.2708226844303606 
2022-03-31 19:57:36,063: ============================================================
2022-03-31 19:57:36,063: Epoch 12/31 Batch 3800/7662 eta: 18:51:20.012653	Training Loss 0.7998 (0.8169)	Training Prec@1 0.391 (0.087)	Training Prec@5 1.367 (0.315)	
2022-03-31 19:57:36,063: ============================================================
2022-03-31 19:58:23,097: time cost, forward:0.1560461267381792, backward:0.033939135505713446, data cost:0.2706967840197148 
2022-03-31 19:58:23,097: ============================================================
2022-03-31 19:58:23,098: Epoch 12/31 Batch 3900/7662 eta: 19:30:41.378021	Training Loss 0.7972 (0.8165)	Training Prec@1 1.172 (0.094)	Training Prec@5 2.344 (0.336)	
2022-03-31 19:58:23,098: ============================================================
2022-03-31 19:59:09,759: time cost, forward:0.15648611338921384, backward:0.033934799245847226, data cost:0.27038693803642716 
2022-03-31 19:59:09,760: ============================================================
2022-03-31 19:59:09,760: Epoch 12/31 Batch 4000/7662 eta: 19:20:39.565471	Training Loss 0.8023 (0.8161)	Training Prec@1 0.391 (0.102)	Training Prec@5 1.172 (0.360)	
2022-03-31 19:59:09,760: ============================================================
2022-03-31 19:59:56,026: time cost, forward:0.15676863765274499, backward:0.033925744433843906, data cost:0.2701436651424828 
2022-03-31 19:59:56,027: ============================================================
2022-03-31 19:59:56,027: Epoch 12/31 Batch 4100/7662 eta: 19:10:02.703719	Training Loss 0.7979 (0.8156)	Training Prec@1 0.391 (0.110)	Training Prec@5 1.758 (0.385)	
2022-03-31 19:59:56,027: ============================================================
2022-03-31 20:00:44,002: time cost, forward:0.15727693599074988, backward:0.03393663630993146, data cost:0.27008905346037576 
2022-03-31 20:00:44,003: ============================================================
2022-03-31 20:00:44,003: Epoch 12/31 Batch 4200/7662 eta: 19:51:43.935494	Training Loss 0.7969 (0.8152)	Training Prec@1 0.195 (0.118)	Training Prec@5 0.781 (0.408)	
2022-03-31 20:00:44,003: ============================================================
2022-03-31 20:01:28,262: time cost, forward:0.15735330429707164, backward:0.03392784249979442, data cost:0.26956681429882273 
2022-03-31 20:01:28,263: ============================================================
2022-03-31 20:01:28,263: Epoch 12/31 Batch 4300/7662 eta: 18:18:41.390631	Training Loss 0.7959 (0.8148)	Training Prec@1 0.977 (0.127)	Training Prec@5 2.148 (0.437)	
2022-03-31 20:01:28,263: ============================================================
2022-03-31 20:02:15,287: time cost, forward:0.1581604476949523, backward:0.03397344442681037, data cost:0.26891621418177036 
2022-03-31 20:02:15,287: ============================================================
2022-03-31 20:02:15,287: Epoch 12/31 Batch 4400/7662 eta: 19:26:31.744048	Training Loss 0.7960 (0.8143)	Training Prec@1 0.195 (0.136)	Training Prec@5 1.367 (0.464)	
2022-03-31 20:02:15,288: ============================================================
2022-03-31 20:02:59,634: time cost, forward:0.1579374351827906, backward:0.033956239901269426, data cost:0.26876444306790126 
2022-03-31 20:02:59,635: ============================================================
2022-03-31 20:02:59,635: Epoch 12/31 Batch 4500/7662 eta: 18:19:22.734953	Training Loss 0.7943 (0.8139)	Training Prec@1 0.391 (0.147)	Training Prec@5 1.953 (0.494)	
2022-03-31 20:02:59,635: ============================================================
2022-03-31 20:03:46,891: time cost, forward:0.15835063813639402, backward:0.03397626803216273, data cost:0.2685673994249716 
2022-03-31 20:03:46,891: ============================================================
2022-03-31 20:03:46,891: Epoch 12/31 Batch 4600/7662 eta: 19:30:42.773385	Training Loss 0.7910 (0.8134)	Training Prec@1 0.000 (0.159)	Training Prec@5 0.586 (0.529)	
2022-03-31 20:03:46,892: ============================================================
2022-03-31 20:04:34,582: time cost, forward:0.15910684029887043, backward:0.03402972388810415, data cost:0.2680996630287698 
2022-03-31 20:04:34,583: ============================================================
2022-03-31 20:04:34,583: Epoch 12/31 Batch 4700/7662 eta: 19:40:41.205700	Training Loss 0.7998 (0.8131)	Training Prec@1 0.195 (0.168)	Training Prec@5 1.367 (0.551)	
2022-03-31 20:04:34,583: ============================================================
2022-03-31 20:05:21,687: time cost, forward:0.15943855354005432, backward:0.03405953839710042, data cost:0.26794145916570944 
2022-03-31 20:05:21,687: ============================================================
2022-03-31 20:05:21,687: Epoch 12/31 Batch 4800/7662 eta: 19:25:22.509133	Training Loss 0.7930 (0.8127)	Training Prec@1 0.781 (0.181)	Training Prec@5 1.562 (0.587)	
2022-03-31 20:05:21,688: ============================================================
2022-03-31 20:06:09,479: time cost, forward:0.15979011702668938, backward:0.03402400454785732, data cost:0.2679382850014694 
2022-03-31 20:06:09,480: ============================================================
2022-03-31 20:06:09,480: Epoch 12/31 Batch 4900/7662 eta: 19:41:36.158928	Training Loss 0.8358 (0.8125)	Training Prec@1 0.000 (0.191)	Training Prec@5 0.000 (0.613)	
2022-03-31 20:06:09,480: ============================================================
2022-03-31 20:06:56,959: time cost, forward:0.1603887185117535, backward:0.03406392972358205, data cost:0.2675518027113113 
2022-03-31 20:06:56,959: ============================================================
2022-03-31 20:06:56,959: Epoch 12/31 Batch 5000/7662 eta: 19:33:03.739312	Training Loss 0.8329 (0.8129)	Training Prec@1 0.000 (0.187)	Training Prec@5 0.000 (0.601)	
2022-03-31 20:06:56,960: ============================================================
2022-03-31 20:07:43,297: time cost, forward:0.16087568037695546, backward:0.03410281132520192, data cost:0.267046507444305 
2022-03-31 20:07:43,298: ============================================================
2022-03-31 20:07:43,298: Epoch 12/31 Batch 5100/7662 eta: 19:04:06.288357	Training Loss 0.8295 (0.8133)	Training Prec@1 0.000 (0.184)	Training Prec@5 0.000 (0.589)	
2022-03-31 20:07:43,298: ============================================================
2022-03-31 20:08:28,784: time cost, forward:0.16094244290003526, backward:0.034100218263124586, data cost:0.26684312413210687 
2022-03-31 20:08:28,785: ============================================================
2022-03-31 20:08:28,785: Epoch 12/31 Batch 5200/7662 eta: 18:42:19.410006	Training Loss 0.8291 (0.8136)	Training Prec@1 0.000 (0.180)	Training Prec@5 0.000 (0.578)	
2022-03-31 20:08:28,785: ============================================================
2022-03-31 20:09:15,519: time cost, forward:0.16121933203324842, backward:0.034074968426919115, data cost:0.2666791724942724 
2022-03-31 20:09:15,520: ============================================================
2022-03-31 20:09:15,520: Epoch 12/31 Batch 5300/7662 eta: 19:12:20.333774	Training Loss 0.8261 (0.8138)	Training Prec@1 0.000 (0.177)	Training Prec@5 0.000 (0.568)	
2022-03-31 20:09:15,520: ============================================================
2022-03-31 20:10:02,906: time cost, forward:0.16144526960850203, backward:0.03406632633248089, data cost:0.26666701332377735 
2022-03-31 20:10:02,907: ============================================================
2022-03-31 20:10:02,907: Epoch 12/31 Batch 5400/7662 eta: 19:27:37.598436	Training Loss 0.8224 (0.8140)	Training Prec@1 0.000 (0.174)	Training Prec@5 0.000 (0.558)	
2022-03-31 20:10:02,907: ============================================================
2022-03-31 20:10:48,466: time cost, forward:0.1615110528016008, backward:0.034071199762580565, data cost:0.26647981020900896 
2022-03-31 20:10:48,467: ============================================================
2022-03-31 20:10:48,467: Epoch 12/31 Batch 5500/7662 eta: 18:41:50.899200	Training Loss 0.8237 (0.8142)	Training Prec@1 0.000 (0.171)	Training Prec@5 0.000 (0.550)	
2022-03-31 20:10:48,467: ============================================================
2022-03-31 20:11:37,331: time cost, forward:0.16206717235655801, backward:0.034110086393007145, data cost:0.2663500024114555 
2022-03-31 20:11:37,331: ============================================================
2022-03-31 20:11:37,332: Epoch 12/31 Batch 5600/7662 eta: 20:02:24.023488	Training Loss 0.8211 (0.8144)	Training Prec@1 0.000 (0.168)	Training Prec@5 0.195 (0.541)	
2022-03-31 20:11:37,332: ============================================================
2022-03-31 20:12:22,221: time cost, forward:0.1617075076206125, backward:0.03408675190439808, data cost:0.2664920547423101 
2022-03-31 20:12:22,221: ============================================================
2022-03-31 20:12:22,222: Epoch 12/31 Batch 5700/7662 eta: 18:23:51.168422	Training Loss 0.8216 (0.8145)	Training Prec@1 0.000 (0.166)	Training Prec@5 0.195 (0.534)	
2022-03-31 20:12:22,222: ============================================================
2022-03-31 20:13:10,548: time cost, forward:0.162208492456993, backward:0.03411896472594762, data cost:0.26630168130509213 
2022-03-31 20:13:10,548: ============================================================
2022-03-31 20:13:10,549: Epoch 12/31 Batch 5800/7662 eta: 19:47:33.781344	Training Loss 0.8149 (0.8146)	Training Prec@1 0.195 (0.164)	Training Prec@5 0.195 (0.528)	
2022-03-31 20:13:10,549: ============================================================
2022-03-31 20:13:57,365: time cost, forward:0.1622666890670898, backward:0.03415926991327069, data cost:0.2662911569896361 
2022-03-31 20:13:57,366: ============================================================
2022-03-31 20:13:57,366: Epoch 12/31 Batch 5900/7662 eta: 19:09:40.772141	Training Loss 0.8279 (0.8147)	Training Prec@1 0.000 (0.162)	Training Prec@5 0.000 (0.523)	
2022-03-31 20:13:57,366: ============================================================
2022-03-31 20:14:42,431: time cost, forward:0.1624461555703518, backward:0.034182375879123976, data cost:0.26588127739847967 
2022-03-31 20:14:42,431: ============================================================
2022-03-31 20:14:42,432: Epoch 12/31 Batch 6000/7662 eta: 18:25:55.468608	Training Loss 0.8288 (0.8149)	Training Prec@1 0.000 (0.160)	Training Prec@5 0.195 (0.515)	
2022-03-31 20:14:42,432: ============================================================
2022-03-31 20:15:29,579: time cost, forward:0.1629304667343212, backward:0.0342370311360532, data cost:0.26549247124680225 
2022-03-31 20:15:29,579: ============================================================
2022-03-31 20:15:29,580: Epoch 12/31 Batch 6100/7662 eta: 19:16:14.300037	Training Loss 0.8302 (0.8152)	Training Prec@1 0.000 (0.157)	Training Prec@5 0.000 (0.507)	
2022-03-31 20:15:29,580: ============================================================
2022-03-31 20:16:16,416: time cost, forward:0.16329531481927934, backward:0.034271797570014584, data cost:0.2651754777880326 
2022-03-31 20:16:16,416: ============================================================
2022-03-31 20:16:16,417: Epoch 12/31 Batch 6200/7662 eta: 19:07:49.113780	Training Loss 0.8250 (0.8154)	Training Prec@1 0.000 (0.155)	Training Prec@5 0.195 (0.499)	
2022-03-31 20:16:16,417: ============================================================
2022-03-31 20:17:03,263: time cost, forward:0.16349398561802567, backward:0.03426901520878801, data cost:0.2650625246974244 
2022-03-31 20:17:03,263: ============================================================
2022-03-31 20:17:03,263: Epoch 12/31 Batch 6300/7662 eta: 19:07:17.043361	Training Loss 0.8264 (0.8156)	Training Prec@1 0.000 (0.152)	Training Prec@5 0.195 (0.491)	
2022-03-31 20:17:03,263: ============================================================
2022-03-31 20:17:49,072: time cost, forward:0.1635775323919364, backward:0.03422282945180167, data cost:0.2649449022286831 
2022-03-31 20:17:49,073: ============================================================
2022-03-31 20:17:49,073: Epoch 12/31 Batch 6400/7662 eta: 18:41:07.292760	Training Loss 0.8274 (0.8157)	Training Prec@1 0.000 (0.150)	Training Prec@5 0.000 (0.484)	
2022-03-31 20:17:49,073: ============================================================
2022-03-31 20:18:36,542: time cost, forward:0.1636162150876488, backward:0.03424664478445809, data cost:0.2650467738644456 
2022-03-31 20:18:36,543: ============================================================
2022-03-31 20:18:36,543: Epoch 12/31 Batch 6500/7662 eta: 19:20:57.998923	Training Loss 0.8267 (0.8159)	Training Prec@1 0.000 (0.148)	Training Prec@5 0.000 (0.477)	
2022-03-31 20:18:36,543: ============================================================
2022-03-31 20:19:20,815: time cost, forward:0.16320714991749155, backward:0.03425400209058359, data cost:0.2651473606946089 
2022-03-31 20:19:20,816: ============================================================
2022-03-31 20:19:20,816: Epoch 12/31 Batch 6600/7662 eta: 18:02:02.397203	Training Loss 0.8265 (0.8161)	Training Prec@1 0.000 (0.146)	Training Prec@5 0.000 (0.470)	
2022-03-31 20:19:20,816: ============================================================
2022-03-31 20:20:07,304: time cost, forward:0.16329135750991086, backward:0.034271901926899655, data cost:0.2650663644845031 
2022-03-31 20:20:07,304: ============================================================
2022-03-31 20:20:07,304: Epoch 12/31 Batch 6700/7662 eta: 18:55:24.610240	Training Loss 0.8262 (0.8162)	Training Prec@1 0.000 (0.144)	Training Prec@5 0.000 (0.464)	
2022-03-31 20:20:07,305: ============================================================
2022-03-31 20:20:53,799: time cost, forward:0.1634902121617805, backward:0.03430609226858007, data cost:0.26485337031415357 
2022-03-31 20:20:53,800: ============================================================
2022-03-31 20:20:53,800: Epoch 12/31 Batch 6800/7662 eta: 18:54:48.372286	Training Loss 0.8261 (0.8164)	Training Prec@1 0.000 (0.142)	Training Prec@5 0.000 (0.458)	
2022-03-31 20:20:53,800: ============================================================
2022-03-31 20:21:41,226: time cost, forward:0.16398134133421455, backward:0.034347197995322015, data cost:0.2644947543491884 
2022-03-31 20:21:41,226: ============================================================
2022-03-31 20:21:41,226: Epoch 12/31 Batch 6900/7662 eta: 19:16:44.418323	Training Loss 0.8288 (0.8165)	Training Prec@1 0.000 (0.140)	Training Prec@5 0.000 (0.452)	
2022-03-31 20:21:41,226: ============================================================
2022-03-31 20:22:28,232: time cost, forward:0.1638958291302989, backward:0.03434924855200218, data cost:0.2646754054380053 
2022-03-31 20:22:28,232: ============================================================
2022-03-31 20:22:28,232: Epoch 12/31 Batch 7000/7662 eta: 19:05:41.796969	Training Loss 0.8255 (0.8166)	Training Prec@1 0.000 (0.138)	Training Prec@5 0.000 (0.446)	
2022-03-31 20:22:28,232: ============================================================
2022-03-31 20:23:16,094: time cost, forward:0.1641452839751028, backward:0.034362912463510455, data cost:0.26462400643015127 
2022-03-31 20:23:16,094: ============================================================
2022-03-31 20:23:16,094: Epoch 12/31 Batch 7100/7662 eta: 19:25:46.464630	Training Loss 0.8232 (0.8167)	Training Prec@1 0.000 (0.136)	Training Prec@5 0.195 (0.440)	
2022-03-31 20:23:16,095: ============================================================
2022-03-31 20:24:04,636: time cost, forward:0.164428095765239, backward:0.034374124292764985, data cost:0.2646283755651496 
2022-03-31 20:24:04,637: ============================================================
2022-03-31 20:24:04,637: Epoch 12/31 Batch 7200/7662 eta: 19:41:31.899528	Training Loss 0.8243 (0.8168)	Training Prec@1 0.000 (0.134)	Training Prec@5 0.000 (0.435)	
2022-03-31 20:24:04,637: ============================================================
2022-03-31 20:24:48,551: time cost, forward:0.16410046202595194, backward:0.03435062996278578, data cost:0.2646410796785701 
2022-03-31 20:24:48,551: ============================================================
2022-03-31 20:24:48,551: Epoch 12/31 Batch 7300/7662 eta: 17:48:09.327597	Training Loss 0.8234 (0.8169)	Training Prec@1 0.000 (0.133)	Training Prec@5 0.000 (0.430)	
2022-03-31 20:24:48,552: ============================================================
2022-03-31 20:25:35,176: time cost, forward:0.1643923359443117, backward:0.03433054881347871, data cost:0.26440407047563025 
2022-03-31 20:25:35,176: ============================================================
2022-03-31 20:25:35,176: Epoch 12/31 Batch 7400/7662 eta: 18:53:18.049137	Training Loss 0.8197 (0.8170)	Training Prec@1 0.000 (0.131)	Training Prec@5 0.000 (0.425)	
2022-03-31 20:25:35,176: ============================================================
2022-03-31 20:26:22,112: time cost, forward:0.16465849618241538, backward:0.03433868519098445, data cost:0.2642131494289876 
2022-03-31 20:26:22,112: ============================================================
2022-03-31 20:26:22,113: Epoch 12/31 Batch 7500/7662 eta: 19:00:05.479949	Training Loss 0.8283 (0.8170)	Training Prec@1 0.000 (0.130)	Training Prec@5 0.000 (0.421)	
2022-03-31 20:26:22,113: ============================================================
2022-03-31 20:27:10,154: time cost, forward:0.1646701186436511, backward:0.03433819340473571, data cost:0.26442917555096057 
2022-03-31 20:27:10,154: ============================================================
2022-03-31 20:27:10,155: Epoch 12/31 Batch 7600/7662 eta: 19:26:08.920484	Training Loss 0.8154 (0.8171)	Training Prec@1 0.000 (0.128)	Training Prec@5 0.391 (0.417)	
2022-03-31 20:27:10,155: ============================================================
2022-03-31 20:27:43,364: Epoch: 12/31 eta: 19:25:38.653993	Training Loss 0.8069 (0.8170)	Training Prec@1 0.000 (0.129)	Training Prec@5 0.195 (0.417)
2022-03-31 20:27:43,365: ============================================================
2022-03-31 20:28:25,024: time cost, forward:0.10824981361928612, backward:0.03183860971470072, data cost:0.2764389563088465 
2022-03-31 20:28:25,024: ============================================================
2022-03-31 20:28:25,025: Epoch 13/31 Batch 100/7662 eta: 16:46:20.244715	Training Loss 0.8091 (0.8128)	Training Prec@1 0.000 (0.136)	Training Prec@5 0.195 (0.430)	
2022-03-31 20:28:25,025: ============================================================
2022-03-31 20:29:11,919: time cost, forward:0.14189930776854856, backward:0.0338517577204872, data cost:0.26700708135288564 
2022-03-31 20:29:11,920: ============================================================
2022-03-31 20:29:11,920: Epoch 13/31 Batch 200/7662 eta: 18:56:16.195693	Training Loss 0.7919 (0.8053)	Training Prec@1 0.977 (0.275)	Training Prec@5 1.172 (0.874)	
2022-03-31 20:29:11,920: ============================================================
2022-03-31 20:30:02,753: time cost, forward:0.17058073397862872, backward:0.03534419480773517, data cost:0.25829834363931 
2022-03-31 20:30:02,753: ============================================================
2022-03-31 20:30:02,753: Epoch 13/31 Batch 300/7662 eta: 20:30:50.178307	Training Loss 0.8227 (0.8035)	Training Prec@1 0.000 (0.349)	Training Prec@5 0.000 (1.077)	
2022-03-31 20:30:02,754: ============================================================
2022-03-31 20:30:47,425: time cost, forward:0.1714388236664889, backward:0.03546949317282005, data cost:0.25279548771698074 
2022-03-31 20:30:47,425: ============================================================
2022-03-31 20:30:47,425: Epoch 13/31 Batch 400/7662 eta: 18:00:54.270709	Training Loss 0.7898 (0.8038)	Training Prec@1 0.586 (0.366)	Training Prec@5 1.758 (1.114)	
2022-03-31 20:30:47,426: ============================================================
2022-03-31 20:31:34,152: time cost, forward:0.17487685474938525, backward:0.035635462743724755, data cost:0.25066324369701926 
2022-03-31 20:31:34,152: ============================================================
2022-03-31 20:31:34,153: Epoch 13/31 Batch 500/7662 eta: 18:49:51.348653	Training Loss 0.7864 (0.8001)	Training Prec@1 0.195 (0.537)	Training Prec@5 2.539 (1.558)	
2022-03-31 20:31:34,153: ============================================================
2022-03-31 20:32:19,905: time cost, forward:0.17230531210095337, backward:0.03584363782943191, data cost:0.2521616333912131 
2022-03-31 20:32:19,905: ============================================================
2022-03-31 20:32:19,906: Epoch 13/31 Batch 600/7662 eta: 18:25:32.543313	Training Loss 0.7789 (0.7967)	Training Prec@1 1.953 (0.784)	Training Prec@5 6.836 (2.126)	
2022-03-31 20:32:19,906: ============================================================
2022-03-31 20:33:04,032: time cost, forward:0.16881876578487892, backward:0.03592732126620706, data cost:0.25286988809555555 
2022-03-31 20:33:04,033: ============================================================
2022-03-31 20:33:04,033: Epoch 13/31 Batch 700/7662 eta: 17:45:30.824858	Training Loss 0.8271 (0.7992)	Training Prec@1 0.000 (0.781)	Training Prec@5 0.000 (2.078)	
2022-03-31 20:33:04,033: ============================================================
2022-03-31 20:33:47,303: time cost, forward:0.16546986667026717, backward:0.03574699633410935, data cost:0.253199313250889 
2022-03-31 20:33:47,303: ============================================================
2022-03-31 20:33:47,304: Epoch 13/31 Batch 800/7662 eta: 17:24:07.095555	Training Loss 0.8259 (0.8026)	Training Prec@1 0.000 (0.686)	Training Prec@5 0.000 (1.825)	
2022-03-31 20:33:47,304: ============================================================
2022-03-31 20:34:35,288: time cost, forward:0.16622877306614622, backward:0.03591659177795003, data cost:0.2549760991394586 
2022-03-31 20:34:35,288: ============================================================
2022-03-31 20:34:35,289: Epoch 13/31 Batch 900/7662 eta: 19:17:04.171431	Training Loss 0.8263 (0.8052)	Training Prec@1 0.000 (0.611)	Training Prec@5 0.000 (1.628)	
2022-03-31 20:34:35,289: ============================================================
2022-03-31 20:35:15,782: time cost, forward:0.16187688585993526, backward:0.03567675713662271, data cost:0.25445350727161486 
2022-03-31 20:35:15,783: ============================================================
2022-03-31 20:35:15,783: Epoch 13/31 Batch 1000/7662 eta: 16:15:46.342769	Training Loss 0.8234 (0.8070)	Training Prec@1 0.000 (0.552)	Training Prec@5 0.000 (1.473)	
2022-03-31 20:35:15,783: ============================================================
2022-03-31 20:36:02,011: time cost, forward:0.16225972861132912, backward:0.03572587450598456, data cost:0.2549001033789901 
2022-03-31 20:36:02,011: ============================================================
2022-03-31 20:36:02,011: Epoch 13/31 Batch 1100/7662 eta: 18:33:10.320379	Training Loss 0.8225 (0.8084)	Training Prec@1 0.000 (0.503)	Training Prec@5 0.000 (1.345)	
2022-03-31 20:36:02,012: ============================================================
2022-03-31 20:36:45,718: time cost, forward:0.16030627036711093, backward:0.035639693082820584, data cost:0.2555506338766955 
2022-03-31 20:36:45,719: ============================================================
2022-03-31 20:36:45,719: Epoch 13/31 Batch 1200/7662 eta: 17:31:44.527127	Training Loss 0.8179 (0.8094)	Training Prec@1 0.000 (0.464)	Training Prec@5 0.195 (1.244)	
2022-03-31 20:36:45,719: ============================================================
2022-03-31 20:37:31,690: time cost, forward:0.16140630210336124, backward:0.0356481853496854, data cost:0.255081273850521 
2022-03-31 20:37:31,690: ============================================================
2022-03-31 20:37:31,691: Epoch 13/31 Batch 1300/7662 eta: 18:25:27.592564	Training Loss 0.8201 (0.8098)	Training Prec@1 0.000 (0.437)	Training Prec@5 0.000 (1.179)	
2022-03-31 20:37:31,691: ============================================================
2022-03-31 20:38:16,524: time cost, forward:0.16163533785413042, backward:0.03570554016146002, data cost:0.2544203424896829 
2022-03-31 20:38:16,524: ============================================================
2022-03-31 20:38:16,525: Epoch 13/31 Batch 1400/7662 eta: 17:57:20.932864	Training Loss 0.7876 (0.8101)	Training Prec@1 0.781 (0.415)	Training Prec@5 2.734 (1.123)	
2022-03-31 20:38:16,525: ============================================================
2022-03-31 20:38:58,623: time cost, forward:0.1603067889859312, backward:0.03562418200955381, data cost:0.2538458798391331 
2022-03-31 20:38:58,623: ============================================================
2022-03-31 20:38:58,624: Epoch 13/31 Batch 1500/7662 eta: 16:50:56.142452	Training Loss 0.7791 (0.8080)	Training Prec@1 2.539 (0.522)	Training Prec@5 5.664 (1.380)	
2022-03-31 20:38:58,624: ============================================================
2022-03-31 20:39:45,165: time cost, forward:0.16110101634819407, backward:0.03576464366733916, data cost:0.25382778180845833 
2022-03-31 20:39:45,166: ============================================================
2022-03-31 20:39:45,166: Epoch 13/31 Batch 1600/7662 eta: 18:36:50.841509	Training Loss 0.7695 (0.8056)	Training Prec@1 3.320 (0.708)	Training Prec@5 6.250 (1.780)	
2022-03-31 20:39:45,166: ============================================================
2022-03-31 20:40:29,813: time cost, forward:0.1610738591210431, backward:0.035849038820676485, data cost:0.2534942851479156 
2022-03-31 20:40:29,813: ============================================================
2022-03-31 20:40:29,814: Epoch 13/31 Batch 1700/7662 eta: 17:50:38.954593	Training Loss 0.7639 (0.8033)	Training Prec@1 4.102 (0.919)	Training Prec@5 9.570 (2.230)	
2022-03-31 20:40:29,814: ============================================================
2022-03-31 20:41:15,054: time cost, forward:0.1605516374608157, backward:0.035961696874969466, data cost:0.25399171981366225 
2022-03-31 20:41:15,054: ============================================================
2022-03-31 20:41:15,054: Epoch 13/31 Batch 1800/7662 eta: 18:04:06.338457	Training Loss 0.7605 (0.8009)	Training Prec@1 5.469 (1.181)	Training Prec@5 11.719 (2.749)	
2022-03-31 20:41:15,055: ============================================================
2022-03-31 20:41:57,504: time cost, forward:0.15958974912582163, backward:0.03587465112996516, data cost:0.2536765323807655 
2022-03-31 20:41:57,504: ============================================================
2022-03-31 20:41:57,505: Epoch 13/31 Batch 1900/7662 eta: 16:56:32.480288	Training Loss 0.7427 (0.7984)	Training Prec@1 8.203 (1.489)	Training Prec@5 18.164 (3.331)	
2022-03-31 20:41:57,505: ============================================================
2022-03-31 20:42:43,670: time cost, forward:0.1598781066396464, backward:0.035911985133038934, data cost:0.253933601703806 
2022-03-31 20:42:43,671: ============================================================
2022-03-31 20:42:43,671: Epoch 13/31 Batch 2000/7662 eta: 18:24:45.377258	Training Loss 0.7480 (0.7960)	Training Prec@1 7.617 (1.819)	Training Prec@5 16.406 (3.927)	
2022-03-31 20:42:43,672: ============================================================
2022-03-31 20:43:27,739: time cost, forward:0.15977265779150845, backward:0.03591410303865517, data cost:0.25362177676618414 
2022-03-31 20:43:27,740: ============================================================
2022-03-31 20:43:27,740: Epoch 13/31 Batch 2100/7662 eta: 17:33:49.754019	Training Loss 0.7483 (0.7937)	Training Prec@1 8.398 (2.165)	Training Prec@5 16.406 (4.543)	
2022-03-31 20:43:27,740: ============================================================
2022-03-31 20:44:12,085: time cost, forward:0.15917069047838517, backward:0.035921109812321474, data cost:0.2539073149146357 
2022-03-31 20:44:12,085: ============================================================
2022-03-31 20:44:12,085: Epoch 13/31 Batch 2200/7662 eta: 17:39:41.426137	Training Loss 0.7370 (0.7914)	Training Prec@1 11.719 (2.549)	Training Prec@5 20.312 (5.187)	
2022-03-31 20:44:12,086: ============================================================
2022-03-31 20:44:57,859: time cost, forward:0.1596190985413726, backward:0.03597574236082896, data cost:0.2537765045589133 
2022-03-31 20:44:57,860: ============================================================
2022-03-31 20:44:57,860: Epoch 13/31 Batch 2300/7662 eta: 18:13:05.755375	Training Loss 0.7333 (0.7891)	Training Prec@1 14.062 (2.957)	Training Prec@5 22.461 (5.860)	
2022-03-31 20:44:57,860: ============================================================
2022-03-31 20:45:40,809: time cost, forward:0.15872515783353666, backward:0.03593446722424194, data cost:0.25384610451574674 
2022-03-31 20:45:40,809: ============================================================
2022-03-31 20:45:40,810: Epoch 13/31 Batch 2400/7662 eta: 17:04:54.453761	Training Loss 0.7405 (0.7869)	Training Prec@1 13.867 (3.368)	Training Prec@5 20.312 (6.519)	
2022-03-31 20:45:40,810: ============================================================
2022-03-31 20:46:27,612: time cost, forward:0.15944358662349217, backward:0.03600273737195684, data cost:0.2538433170356766 
2022-03-31 20:46:27,612: ============================================================
2022-03-31 20:46:27,612: Epoch 13/31 Batch 2500/7662 eta: 18:36:05.006440	Training Loss 0.7410 (0.7848)	Training Prec@1 14.453 (3.791)	Training Prec@5 23.047 (7.181)	
2022-03-31 20:46:27,613: ============================================================
2022-03-31 20:47:09,831: time cost, forward:0.15827440362382092, backward:0.035993926293027084, data cost:0.25395871713189905 
2022-03-31 20:47:09,832: ============================================================
2022-03-31 20:47:09,832: Epoch 13/31 Batch 2600/7662 eta: 16:46:05.389544	Training Loss 0.8177 (0.7858)	Training Prec@1 0.195 (3.707)	Training Prec@5 0.195 (7.022)	
2022-03-31 20:47:09,832: ============================================================
2022-03-31 20:47:54,138: time cost, forward:0.1572912236680451, backward:0.03592471468665062, data cost:0.2548157510690311 
2022-03-31 20:47:54,138: ============================================================
2022-03-31 20:47:54,139: Epoch 13/31 Batch 2700/7662 eta: 17:35:04.658867	Training Loss 0.8103 (0.7869)	Training Prec@1 0.195 (3.573)	Training Prec@5 0.586 (6.773)	
2022-03-31 20:47:54,139: ============================================================
2022-03-31 20:48:39,845: time cost, forward:0.15773399551666903, backward:0.03601754227038919, data cost:0.2545974863644539 
2022-03-31 20:48:39,846: ============================================================
2022-03-31 20:48:39,846: Epoch 13/31 Batch 2800/7662 eta: 18:07:40.266480	Training Loss 0.8409 (0.7882)	Training Prec@1 0.000 (3.454)	Training Prec@5 0.000 (6.559)	
2022-03-31 20:48:39,846: ============================================================
2022-03-31 20:49:26,745: time cost, forward:0.15786076504923469, backward:0.036067634091043355, data cost:0.25510591250035053 
2022-03-31 20:49:26,745: ============================================================
2022-03-31 20:49:26,746: Epoch 13/31 Batch 2900/7662 eta: 18:35:16.184780	Training Loss 0.8355 (0.7899)	Training Prec@1 0.000 (3.335)	Training Prec@5 0.000 (6.333)	
2022-03-31 20:49:26,746: ============================================================
2022-03-31 20:50:09,631: time cost, forward:0.1574863528124131, backward:0.03607273666252093, data cost:0.2548172083565616 
2022-03-31 20:50:09,631: ============================================================
2022-03-31 20:50:09,632: Epoch 13/31 Batch 3000/7662 eta: 16:59:06.467216	Training Loss 0.8328 (0.7914)	Training Prec@1 0.000 (3.224)	Training Prec@5 0.000 (6.122)	
2022-03-31 20:50:09,632: ============================================================
2022-03-31 20:50:57,699: time cost, forward:0.15827870399731134, backward:0.036157244903574304, data cost:0.25497259544379947 
2022-03-31 20:50:57,700: ============================================================
2022-03-31 20:50:57,700: Epoch 13/31 Batch 3100/7662 eta: 19:01:27.471636	Training Loss 0.8341 (0.7928)	Training Prec@1 0.000 (3.120)	Training Prec@5 0.000 (5.925)	
2022-03-31 20:50:57,700: ============================================================
2022-03-31 20:51:40,612: time cost, forward:0.15800239533772875, backward:0.036091294799904854, data cost:0.2546517254971608 
2022-03-31 20:51:40,613: ============================================================
2022-03-31 20:51:40,613: Epoch 13/31 Batch 3200/7662 eta: 16:58:18.788800	Training Loss 0.8315 (0.7940)	Training Prec@1 0.000 (3.022)	Training Prec@5 0.000 (5.740)	
2022-03-31 20:51:40,613: ============================================================
2022-03-31 20:52:27,922: time cost, forward:0.15802417707717864, backward:0.03608495858843741, data cost:0.25537390938741794 
2022-03-31 20:52:27,923: ============================================================
2022-03-31 20:52:27,923: Epoch 13/31 Batch 3300/7662 eta: 18:41:52.448894	Training Loss 0.8301 (0.7951)	Training Prec@1 0.000 (2.931)	Training Prec@5 0.000 (5.566)	
2022-03-31 20:52:27,923: ============================================================
2022-03-31 20:53:13,174: time cost, forward:0.15810386304751534, backward:0.03609930658803403, data cost:0.2553428251205314 
2022-03-31 20:53:13,175: ============================================================
2022-03-31 20:53:13,175: Epoch 13/31 Batch 3400/7662 eta: 17:52:18.449351	Training Loss 0.8286 (0.7961)	Training Prec@1 0.000 (2.845)	Training Prec@5 0.000 (5.403)	
2022-03-31 20:53:13,175: ============================================================
2022-03-31 20:53:56,490: time cost, forward:0.1576141072328038, backward:0.03602171502954178, data cost:0.25544972391120363 
2022-03-31 20:53:56,491: ============================================================
2022-03-31 20:53:56,491: Epoch 13/31 Batch 3500/7662 eta: 17:05:43.066986	Training Loss 0.8288 (0.7971)	Training Prec@1 0.000 (2.763)	Training Prec@5 0.000 (5.249)	
2022-03-31 20:53:56,491: ============================================================
2022-03-31 20:54:41,876: time cost, forward:0.15741868474875004, backward:0.03602481451455869, data cost:0.25574998644929225 
2022-03-31 20:54:41,876: ============================================================
2022-03-31 20:54:41,876: Epoch 13/31 Batch 3600/7662 eta: 17:53:57.793677	Training Loss 0.8279 (0.7980)	Training Prec@1 0.000 (2.687)	Training Prec@5 0.195 (5.104)	
2022-03-31 20:54:41,877: ============================================================
2022-03-31 20:55:27,939: time cost, forward:0.15775227024607416, backward:0.036030093667699895, data cost:0.2557028985468237 
2022-03-31 20:55:27,940: ============================================================
2022-03-31 20:55:27,940: Epoch 13/31 Batch 3700/7662 eta: 18:09:14.382322	Training Loss 0.8270 (0.7988)	Training Prec@1 0.000 (2.614)	Training Prec@5 0.000 (4.966)	
2022-03-31 20:55:27,940: ============================================================
2022-03-31 20:56:13,006: time cost, forward:0.15758264626475127, backward:0.035985995920497074, data cost:0.2559445935445385 
2022-03-31 20:56:13,007: ============================================================
2022-03-31 20:56:13,007: Epoch 13/31 Batch 3800/7662 eta: 17:44:55.550594	Training Loss 0.8282 (0.7996)	Training Prec@1 0.000 (2.546)	Training Prec@5 0.000 (4.837)	
2022-03-31 20:56:13,007: ============================================================
2022-03-31 20:56:57,099: time cost, forward:0.15741941176123667, backward:0.03596402474261761, data cost:0.25589627637469364 
2022-03-31 20:56:57,099: ============================================================
2022-03-31 20:56:57,100: Epoch 13/31 Batch 3900/7662 eta: 17:21:09.943083	Training Loss 0.8261 (0.8002)	Training Prec@1 0.000 (2.481)	Training Prec@5 0.000 (4.714)	
2022-03-31 20:56:57,100: ============================================================
2022-03-31 20:57:44,964: time cost, forward:0.15773850335094683, backward:0.03591077474988559, data cost:0.2563677050525411 
2022-03-31 20:57:44,964: ============================================================
2022-03-31 20:57:44,965: Epoch 13/31 Batch 4000/7662 eta: 18:49:27.032075	Training Loss 0.8245 (0.8008)	Training Prec@1 0.000 (2.419)	Training Prec@5 0.195 (4.597)	
2022-03-31 20:57:44,965: ============================================================
2022-03-31 20:58:31,537: time cost, forward:0.15791721319564817, backward:0.03587738389822296, data cost:0.2565056832716738 
2022-03-31 20:58:31,537: ============================================================
2022-03-31 20:58:31,537: Epoch 13/31 Batch 4100/7662 eta: 18:18:10.577111	Training Loss 0.8156 (0.8013)	Training Prec@1 0.000 (2.361)	Training Prec@5 0.195 (4.488)	
2022-03-31 20:58:31,537: ============================================================
2022-03-31 20:59:17,407: time cost, forward:0.15797909432066198, backward:0.035877141932073905, data cost:0.25659268934064094 
2022-03-31 20:59:17,407: ============================================================
2022-03-31 20:59:17,408: Epoch 13/31 Batch 4200/7662 eta: 18:00:51.037244	Training Loss 0.8138 (0.8016)	Training Prec@1 0.195 (2.307)	Training Prec@5 0.391 (4.390)	
2022-03-31 20:59:17,408: ============================================================
2022-03-31 21:00:00,249: time cost, forward:0.15743309305168413, backward:0.03587863755298232, data cost:0.256728345001817 
2022-03-31 21:00:00,250: ============================================================
2022-03-31 21:00:00,250: Epoch 13/31 Batch 4300/7662 eta: 16:48:47.119710	Training Loss 0.8103 (0.8018)	Training Prec@1 0.000 (2.257)	Training Prec@5 0.391 (4.300)	
2022-03-31 21:00:00,250: ============================================================
2022-03-31 21:00:45,637: time cost, forward:0.15750229513138417, backward:0.035848686277229536, data cost:0.2567653895562604 
2022-03-31 21:00:45,638: ============================================================
2022-03-31 21:00:45,638: Epoch 13/31 Batch 4400/7662 eta: 17:47:58.590784	Training Loss 0.8048 (0.8019)	Training Prec@1 0.586 (2.211)	Training Prec@5 0.781 (4.220)	
2022-03-31 21:00:45,638: ============================================================
2022-03-31 21:01:31,246: time cost, forward:0.15737892638632764, backward:0.03582792452744151, data cost:0.2570480578580044 
2022-03-31 21:01:31,247: ============================================================
2022-03-31 21:01:31,247: Epoch 13/31 Batch 4500/7662 eta: 17:52:24.193318	Training Loss 0.8010 (0.8019)	Training Prec@1 0.000 (2.169)	Training Prec@5 0.781 (4.151)	
2022-03-31 21:01:31,247: ============================================================
2022-03-31 21:02:15,781: time cost, forward:0.15693442581477024, backward:0.035832812252654334, data cost:0.2573538914170569 
2022-03-31 21:02:15,781: ============================================================
2022-03-31 21:02:15,781: Epoch 13/31 Batch 4600/7662 eta: 17:26:24.497624	Training Loss 0.8017 (0.8019)	Training Prec@1 0.586 (2.133)	Training Prec@5 1.172 (4.093)	
2022-03-31 21:02:15,782: ============================================================
2022-03-31 21:03:00,530: time cost, forward:0.15717535131559598, backward:0.03586485137785209, data cost:0.25703604780985817 
2022-03-31 21:03:00,531: ============================================================
2022-03-31 21:03:00,531: Epoch 13/31 Batch 4700/7662 eta: 17:30:42.796616	Training Loss 0.7955 (0.8018)	Training Prec@1 0.391 (2.099)	Training Prec@5 1.953 (4.044)	
2022-03-31 21:03:00,531: ============================================================
2022-03-31 21:03:47,089: time cost, forward:0.15727048800572377, backward:0.03588612597792018, data cost:0.2572347856010092 
2022-03-31 21:03:47,089: ============================================================
2022-03-31 21:03:47,089: Epoch 13/31 Batch 4800/7662 eta: 18:12:24.127600	Training Loss 0.7946 (0.8017)	Training Prec@1 0.781 (2.070)	Training Prec@5 1.953 (4.001)	
2022-03-31 21:03:47,089: ============================================================
2022-03-31 21:04:31,216: time cost, forward:0.15735409926044427, backward:0.035855732004991425, data cost:0.2569725390331286 
2022-03-31 21:04:31,217: ============================================================
2022-03-31 21:04:31,217: Epoch 13/31 Batch 4900/7662 eta: 17:14:38.553111	Training Loss 0.7931 (0.8015)	Training Prec@1 0.781 (2.044)	Training Prec@5 2.148 (3.965)	
2022-03-31 21:04:31,217: ============================================================
2022-03-31 21:05:13,835: time cost, forward:0.1569447037123947, backward:0.035799299819299184, data cost:0.25695709086198953 
2022-03-31 21:05:13,836: ============================================================
2022-03-31 21:05:13,836: Epoch 13/31 Batch 5000/7662 eta: 16:38:33.439363	Training Loss 0.7914 (0.8014)	Training Prec@1 1.172 (2.020)	Training Prec@5 2.734 (3.933)	
2022-03-31 21:05:13,836: ============================================================
2022-03-31 21:06:00,414: time cost, forward:0.1571549621603727, backward:0.03578212500132867, data cost:0.2570757462852584 
2022-03-31 21:06:00,414: ============================================================
2022-03-31 21:06:00,414: Epoch 13/31 Batch 5100/7662 eta: 18:10:32.411874	Training Loss 0.8080 (0.8012)	Training Prec@1 0.195 (1.996)	Training Prec@5 0.781 (3.901)	
2022-03-31 21:06:00,414: ============================================================
2022-03-31 21:06:45,099: time cost, forward:0.1571779306587473, backward:0.03578952767111104, data cost:0.2569298210408188 
2022-03-31 21:06:45,100: ============================================================
2022-03-31 21:06:45,100: Epoch 13/31 Batch 5200/7662 eta: 17:25:29.353779	Training Loss 0.7981 (0.8011)	Training Prec@1 0.586 (1.971)	Training Prec@5 1.758 (3.865)	
2022-03-31 21:06:45,100: ============================================================
2022-03-31 21:07:29,600: time cost, forward:0.15714486015587623, backward:0.03583615729214448, data cost:0.2568542919961613 
2022-03-31 21:07:29,601: ============================================================
2022-03-31 21:07:29,601: Epoch 13/31 Batch 5300/7662 eta: 17:20:25.513875	Training Loss 0.7954 (0.8010)	Training Prec@1 0.391 (1.947)	Training Prec@5 1.953 (3.832)	
2022-03-31 21:07:29,601: ============================================================
2022-03-31 21:08:15,316: time cost, forward:0.157061004046931, backward:0.03586025762655135, data cost:0.2570552563177124 
2022-03-31 21:08:15,316: ============================================================
2022-03-31 21:08:15,316: Epoch 13/31 Batch 5400/7662 eta: 17:48:03.719404	Training Loss 0.8333 (0.8010)	Training Prec@1 0.000 (1.925)	Training Prec@5 0.391 (3.799)	
2022-03-31 21:08:15,317: ============================================================
2022-03-31 21:09:00,046: time cost, forward:0.15700270609761136, backward:0.03584017131865772, data cost:0.25707456466826034 
2022-03-31 21:09:00,046: ============================================================
2022-03-31 21:09:00,046: Epoch 13/31 Batch 5500/7662 eta: 17:24:17.129329	Training Loss 0.8320 (0.8016)	Training Prec@1 0.000 (1.890)	Training Prec@5 0.000 (3.730)	
2022-03-31 21:09:00,046: ============================================================
2022-03-31 21:09:43,161: time cost, forward:0.15667675937748654, backward:0.035832541694511666, data cost:0.2570544127631047 
2022-03-31 21:09:43,162: ============================================================
2022-03-31 21:09:43,162: Epoch 13/31 Batch 5600/7662 eta: 16:45:52.683754	Training Loss 0.8277 (0.8021)	Training Prec@1 0.000 (1.857)	Training Prec@5 0.000 (3.665)	
2022-03-31 21:09:43,162: ============================================================
2022-03-31 21:10:31,562: time cost, forward:0.15698286423998603, backward:0.035880820586778, data cost:0.25731015811993124 
2022-03-31 21:10:31,562: ============================================================
2022-03-31 21:10:31,563: Epoch 13/31 Batch 5700/7662 eta: 18:48:22.464640	Training Loss 0.8277 (0.8025)	Training Prec@1 0.000 (1.825)	Training Prec@5 0.000 (3.601)	
2022-03-31 21:10:31,563: ============================================================
2022-03-31 21:11:15,275: time cost, forward:0.1569915856754272, backward:0.03588790547376995, data cost:0.25706537108233024 
2022-03-31 21:11:15,276: ============================================================
2022-03-31 21:11:15,276: Epoch 13/31 Batch 5800/7662 eta: 16:58:22.209882	Training Loss 0.8256 (0.8029)	Training Prec@1 0.000 (1.793)	Training Prec@5 0.195 (3.540)	
2022-03-31 21:11:15,276: ============================================================
2022-03-31 21:11:57,960: time cost, forward:0.15654788010806264, backward:0.035866377494722775, data cost:0.25712097295362435 
2022-03-31 21:11:57,960: ============================================================
2022-03-31 21:11:57,960: Epoch 13/31 Batch 5900/7662 eta: 16:33:40.884766	Training Loss 0.8257 (0.8033)	Training Prec@1 0.000 (1.763)	Training Prec@5 0.000 (3.481)	
2022-03-31 21:11:57,960: ============================================================
2022-03-31 21:12:43,160: time cost, forward:0.15658976960567697, backward:0.03586653439794745, data cost:0.25712134778887097 
2022-03-31 21:12:43,161: ============================================================
2022-03-31 21:12:43,161: Epoch 13/31 Batch 6000/7662 eta: 17:31:30.637860	Training Loss 0.8245 (0.8037)	Training Prec@1 0.000 (1.734)	Training Prec@5 0.000 (3.424)	
2022-03-31 21:12:43,161: ============================================================
2022-03-31 21:13:27,996: time cost, forward:0.1564917374798696, backward:0.035818870232953146, data cost:0.2572377151027041 
2022-03-31 21:13:27,997: ============================================================
2022-03-31 21:13:27,997: Epoch 13/31 Batch 6100/7662 eta: 17:22:16.708287	Training Loss 0.8231 (0.8040)	Training Prec@1 0.000 (1.706)	Training Prec@5 0.000 (3.369)	
2022-03-31 21:13:27,997: ============================================================
2022-03-31 21:14:15,853: time cost, forward:0.15678009646114638, backward:0.03584494612297333, data cost:0.2573951012973998 
2022-03-31 21:14:15,854: ============================================================
2022-03-31 21:14:15,854: Epoch 13/31 Batch 6200/7662 eta: 18:31:43.402729	Training Loss 0.8257 (0.8043)	Training Prec@1 0.000 (1.679)	Training Prec@5 0.000 (3.316)	
2022-03-31 21:14:15,855: ============================================================
2022-03-31 21:15:00,558: time cost, forward:0.1567764829540843, backward:0.035839767186561074, data cost:0.2573450189636783 
2022-03-31 21:15:00,559: ============================================================
2022-03-31 21:15:00,559: Epoch 13/31 Batch 6300/7662 eta: 17:17:44.297291	Training Loss 0.8221 (0.8046)	Training Prec@1 0.000 (1.652)	Training Prec@5 0.000 (3.264)	
2022-03-31 21:15:00,559: ============================================================
2022-03-31 21:15:43,228: time cost, forward:0.15626407418517066, backward:0.035797350442787694, data cost:0.2575268738715793 
2022-03-31 21:15:43,229: ============================================================
2022-03-31 21:15:43,229: Epoch 13/31 Batch 6400/7662 eta: 16:29:47.334636	Training Loss 0.8204 (0.8049)	Training Prec@1 0.195 (1.627)	Training Prec@5 0.195 (3.215)	
2022-03-31 21:15:43,229: ============================================================
2022-03-31 21:16:28,680: time cost, forward:0.15644923172137942, backward:0.03581323251667014, data cost:0.2573932175050058 
2022-03-31 21:16:28,681: ============================================================
2022-03-31 21:16:28,681: Epoch 13/31 Batch 6500/7662 eta: 17:33:34.025792	Training Loss 0.8208 (0.8051)	Training Prec@1 0.000 (1.602)	Training Prec@5 0.391 (3.168)	
2022-03-31 21:16:28,681: ============================================================
2022-03-31 21:17:14,015: time cost, forward:0.15650086584263162, backward:0.03582424488116763, data cost:0.2573826630597115 
2022-03-31 21:17:14,016: ============================================================
2022-03-31 21:17:14,016: Epoch 13/31 Batch 6600/7662 eta: 17:30:06.521029	Training Loss 0.8171 (0.8053)	Training Prec@1 0.000 (1.579)	Training Prec@5 0.195 (3.122)	
2022-03-31 21:17:14,016: ============================================================
2022-03-31 21:18:00,680: time cost, forward:0.15681148977631293, backward:0.03584964909932919, data cost:0.2572954922829978 
2022-03-31 21:18:00,681: ============================================================
2022-03-31 21:18:00,681: Epoch 13/31 Batch 6700/7662 eta: 18:00:07.550541	Training Loss 0.8136 (0.8055)	Training Prec@1 0.000 (1.556)	Training Prec@5 0.195 (3.079)	
2022-03-31 21:18:00,681: ============================================================
2022-03-31 21:18:45,330: time cost, forward:0.15676846748275747, backward:0.03585053373915533, data cost:0.25727728707489855 
2022-03-31 21:18:45,331: ============================================================
2022-03-31 21:18:45,331: Epoch 13/31 Batch 6800/7662 eta: 17:12:44.802125	Training Loss 0.7979 (0.8056)	Training Prec@1 1.172 (1.537)	Training Prec@5 2.148 (3.045)	
2022-03-31 21:18:45,331: ============================================================
2022-03-31 21:19:31,964: time cost, forward:0.15686136450451654, backward:0.03585709273115347, data cost:0.2574039023585001 
2022-03-31 21:19:31,965: ============================================================
2022-03-31 21:19:31,965: Epoch 13/31 Batch 6900/7662 eta: 17:57:52.214317	Training Loss 0.7913 (0.8054)	Training Prec@1 1.172 (1.527)	Training Prec@5 3.125 (3.036)	
2022-03-31 21:19:31,965: ============================================================
2022-03-31 21:20:16,847: time cost, forward:0.15665886238279095, backward:0.03583800937468911, data cost:0.2576046664811216 
2022-03-31 21:20:16,848: ============================================================
2022-03-31 21:20:16,848: Epoch 13/31 Batch 7000/7662 eta: 17:16:37.988196	Training Loss 0.7878 (0.8052)	Training Prec@1 1.758 (1.524)	Training Prec@5 3.906 (3.043)	
2022-03-31 21:20:16,848: ============================================================
2022-03-31 21:21:03,372: time cost, forward:0.15665383244219053, backward:0.03584267771030786, data cost:0.25780667498306853 
2022-03-31 21:21:03,372: ============================================================
2022-03-31 21:21:03,372: Epoch 13/31 Batch 7100/7662 eta: 17:53:46.241254	Training Loss 0.7820 (0.8049)	Training Prec@1 2.344 (1.525)	Training Prec@5 7.227 (3.061)	
2022-03-31 21:21:03,372: ============================================================
2022-03-31 21:21:48,781: time cost, forward:0.1566253716555846, backward:0.0358188138734733, data cost:0.2579089399675045 
2022-03-31 21:21:48,781: ============================================================
2022-03-31 21:21:48,782: Epoch 13/31 Batch 7200/7662 eta: 17:27:16.937679	Training Loss 0.7808 (0.8046)	Training Prec@1 2.539 (1.530)	Training Prec@5 5.273 (3.081)	
2022-03-31 21:21:48,782: ============================================================
2022-03-31 21:22:38,862: time cost, forward:0.1572439149563109, backward:0.03582980829095952, data cost:0.2579760483183719 
2022-03-31 21:22:38,863: ============================================================
2022-03-31 21:22:38,863: Epoch 13/31 Batch 7300/7662 eta: 19:14:11.981187	Training Loss 0.7805 (0.8043)	Training Prec@1 2.344 (1.536)	Training Prec@5 5.078 (3.105)	
2022-03-31 21:22:38,863: ============================================================
2022-03-31 21:23:30,994: time cost, forward:0.15792353859880934, backward:0.03586419461014819, data cost:0.25820103421825413 
2022-03-31 21:23:30,995: ============================================================
2022-03-31 21:23:30,995: Epoch 13/31 Batch 7400/7662 eta: 20:00:35.684447	Training Loss 0.7931 (0.8041)	Training Prec@1 0.977 (1.534)	Training Prec@5 1.562 (3.112)	
2022-03-31 21:23:30,995: ============================================================
2022-03-31 21:24:18,691: time cost, forward:0.15797725736753102, backward:0.0358614265672333, data cost:0.2584683722473014 
2022-03-31 21:24:18,692: ============================================================
2022-03-31 21:24:18,692: Epoch 13/31 Batch 7500/7662 eta: 18:17:39.373430	Training Loss 0.7809 (0.8038)	Training Prec@1 2.148 (1.541)	Training Prec@5 3.906 (3.137)	
2022-03-31 21:24:18,692: ============================================================
2022-03-31 21:25:07,307: time cost, forward:0.15820273005157603, backward:0.0358342939904684, data cost:0.25871770945736133 
2022-03-31 21:25:07,307: ============================================================
2022-03-31 21:25:07,308: Epoch 13/31 Batch 7600/7662 eta: 18:37:59.601129	Training Loss 0.7791 (0.8037)	Training Prec@1 2.148 (1.539)	Training Prec@5 5.469 (3.141)	
2022-03-31 21:25:07,308: ============================================================
2022-03-31 21:25:36,155: Epoch: 13/31 eta: 18:37:28.973172	Training Loss 0.7769 (0.8034)	Training Prec@1 2.734 (1.549)	Training Prec@5 6.055 (3.169)
2022-03-31 21:25:36,156: ============================================================
2022-03-31 21:26:23,128: time cost, forward:0.1550931954624677, backward:0.03481019626964222, data cost:0.28025480231853445 
2022-03-31 21:26:23,128: ============================================================
2022-03-31 21:26:23,129: Epoch 14/31 Batch 100/7662 eta: 17:55:46.152689	Training Loss 0.8350 (0.7865)	Training Prec@1 0.195 (2.139)	Training Prec@5 0.195 (4.974)	
2022-03-31 21:26:23,129: ============================================================
2022-03-31 21:27:10,233: time cost, forward:0.15794647039480544, backward:0.03496044964047532, data cost:0.27708573557024624 
2022-03-31 21:27:10,234: ============================================================
2022-03-31 21:27:10,234: Epoch 14/31 Batch 200/7662 eta: 18:01:12.542772	Training Loss 0.8297 (0.8092)	Training Prec@1 0.000 (1.068)	Training Prec@5 0.000 (2.495)	
2022-03-31 21:27:10,235: ============================================================
2022-03-31 21:28:02,860: time cost, forward:0.18013016037319018, backward:0.037381136297780934, data cost:0.2710970596326235 
2022-03-31 21:28:02,861: ============================================================
2022-03-31 21:28:02,861: Epoch 14/31 Batch 300/7662 eta: 20:07:03.202625	Training Loss 0.8257 (0.8149)	Training Prec@1 0.000 (0.717)	Training Prec@5 0.000 (1.682)	
2022-03-31 21:28:02,861: ============================================================
2022-03-31 21:28:51,474: time cost, forward:0.18062653756679448, backward:0.037538144821511174, data cost:0.27009541169742596 
2022-03-31 21:28:51,474: ============================================================
2022-03-31 21:28:51,474: Epoch 14/31 Batch 400/7662 eta: 18:34:11.371880	Training Loss 0.8235 (0.8171)	Training Prec@1 0.000 (0.545)	Training Prec@5 0.000 (1.282)	
2022-03-31 21:28:51,474: ============================================================
2022-03-31 21:29:39,204: time cost, forward:0.1797846945110925, backward:0.03713547108407489, data cost:0.2687904141947836 
2022-03-31 21:29:39,205: ============================================================
2022-03-31 21:29:39,206: Epoch 14/31 Batch 500/7662 eta: 18:13:11.135276	Training Loss 0.8222 (0.8180)	Training Prec@1 0.000 (0.443)	Training Prec@5 0.195 (1.051)	
2022-03-31 21:29:39,206: ============================================================
2022-03-31 21:30:29,271: time cost, forward:0.18138023330293634, backward:0.037787560429517336, data cost:0.2690343809048202 
2022-03-31 21:30:29,272: ============================================================
2022-03-31 21:30:29,272: Epoch 14/31 Batch 600/7662 eta: 19:05:49.486708	Training Loss 0.8202 (0.8185)	Training Prec@1 0.000 (0.376)	Training Prec@5 0.000 (0.900)	
2022-03-31 21:30:29,272: ============================================================
2022-03-31 21:31:17,822: time cost, forward:0.18173819720659815, backward:0.03758211026716983, data cost:0.26838430587484774 
2022-03-31 21:31:17,823: ============================================================
2022-03-31 21:31:17,823: Epoch 14/31 Batch 700/7662 eta: 18:30:20.276213	Training Loss 0.8196 (0.8186)	Training Prec@1 0.000 (0.329)	Training Prec@5 0.000 (0.793)	
2022-03-31 21:31:17,823: ============================================================
2022-03-31 21:32:02,886: time cost, forward:0.17905896566388604, backward:0.03735145490071055, data cost:0.2667751010875678 
2022-03-31 21:32:02,886: ============================================================
2022-03-31 21:32:02,887: Epoch 14/31 Batch 800/7662 eta: 17:09:49.894421	Training Loss 0.8179 (0.8186)	Training Prec@1 0.000 (0.293)	Training Prec@5 0.195 (0.715)	
2022-03-31 21:32:02,887: ============================================================
2022-03-31 21:32:51,806: time cost, forward:0.18051459685846483, backward:0.03732145774086007, data cost:0.265934363355626 
2022-03-31 21:32:51,806: ============================================================
2022-03-31 21:32:51,807: Epoch 14/31 Batch 900/7662 eta: 18:37:08.809933	Training Loss 0.8181 (0.8184)	Training Prec@1 0.000 (0.269)	Training Prec@5 0.391 (0.663)	
2022-03-31 21:32:51,807: ============================================================
2022-03-31 21:33:36,002: time cost, forward:0.17729974962450243, backward:0.03723142049214742, data cost:0.2650022103383138 
2022-03-31 21:33:36,003: ============================================================
2022-03-31 21:33:36,004: Epoch 14/31 Batch 1000/7662 eta: 16:48:32.778896	Training Loss 0.8151 (0.8180)	Training Prec@1 0.391 (0.249)	Training Prec@5 0.977 (0.628)	
2022-03-31 21:33:36,004: ============================================================
2022-03-31 21:34:23,954: time cost, forward:0.17738945295422373, backward:0.03739354760132669, data cost:0.26470810874577977 
2022-03-31 21:34:23,955: ============================================================
2022-03-31 21:34:23,955: Epoch 14/31 Batch 1100/7662 eta: 18:13:26.045057	Training Loss 0.8099 (0.8175)	Training Prec@1 0.195 (0.239)	Training Prec@5 0.586 (0.607)	
2022-03-31 21:34:23,955: ============================================================
2022-03-31 21:35:12,750: time cost, forward:0.17754724783336648, backward:0.03745609347873971, data cost:0.2651774958832449 
2022-03-31 21:35:12,750: ============================================================
2022-03-31 21:35:12,750: Epoch 14/31 Batch 1200/7662 eta: 18:31:51.488890	Training Loss 0.8045 (0.8166)	Training Prec@1 0.586 (0.237)	Training Prec@5 1.367 (0.617)	
2022-03-31 21:35:12,750: ============================================================
2022-03-31 21:35:57,922: time cost, forward:0.17517328060435, backward:0.037228786734271914, data cost:0.2655425196523571 
2022-03-31 21:35:57,922: ============================================================
2022-03-31 21:35:57,922: Epoch 14/31 Batch 1300/7662 eta: 17:08:32.773812	Training Loss 0.7819 (0.8149)	Training Prec@1 2.930 (0.306)	Training Prec@5 5.273 (0.796)	
2022-03-31 21:35:57,923: ============================================================
2022-03-31 21:36:46,346: time cost, forward:0.17526237925433363, backward:0.03750777602451371, data cost:0.2656599546518387 
2022-03-31 21:36:46,346: ============================================================
2022-03-31 21:36:46,346: Epoch 14/31 Batch 1400/7662 eta: 18:21:46.768833	Training Loss 0.7773 (0.8125)	Training Prec@1 1.953 (0.442)	Training Prec@5 6.055 (1.136)	
2022-03-31 21:36:46,346: ============================================================
2022-03-31 21:37:34,885: time cost, forward:0.17623563366305278, backward:0.037590502420212925, data cost:0.2649797901779592 
2022-03-31 21:37:34,885: ============================================================
2022-03-31 21:37:34,885: Epoch 14/31 Batch 1500/7662 eta: 18:23:35.795362	Training Loss 0.7706 (0.8099)	Training Prec@1 1.953 (0.620)	Training Prec@5 6.445 (1.537)	
2022-03-31 21:37:34,886: ============================================================
2022-03-31 21:38:20,363: time cost, forward:0.1751368613896182, backward:0.03739871629854528, data cost:0.26475853275850164 
2022-03-31 21:38:20,364: ============================================================
2022-03-31 21:38:20,364: Epoch 14/31 Batch 1600/7662 eta: 17:13:14.791167	Training Loss 0.7719 (0.8074)	Training Prec@1 4.492 (0.810)	Training Prec@5 9.570 (1.963)	
2022-03-31 21:38:20,364: ============================================================
2022-03-31 21:39:05,576: time cost, forward:0.17342559908192742, backward:0.037188517619330015, data cost:0.26520117035046825 
2022-03-31 21:39:05,576: ============================================================
2022-03-31 21:39:05,576: Epoch 14/31 Batch 1700/7662 eta: 17:06:27.197643	Training Loss 0.7644 (0.8050)	Training Prec@1 5.078 (1.026)	Training Prec@5 11.719 (2.403)	
2022-03-31 21:39:05,577: ============================================================
2022-03-31 21:39:53,796: time cost, forward:0.17255333054390398, backward:0.03707919563433407, data cost:0.26651680502645037 
2022-03-31 21:39:53,796: ============================================================
2022-03-31 21:39:53,797: Epoch 14/31 Batch 1800/7662 eta: 18:13:55.730375	Training Loss 0.7665 (0.8030)	Training Prec@1 5.273 (1.206)	Training Prec@5 8.984 (2.776)	
2022-03-31 21:39:53,797: ============================================================
2022-03-31 21:40:38,945: time cost, forward:0.17126725246053798, backward:0.03700162009730849, data cost:0.2665716424121425 
2022-03-31 21:40:38,945: ============================================================
2022-03-31 21:40:38,945: Epoch 14/31 Batch 1900/7662 eta: 17:03:29.999376	Training Loss 0.7614 (0.8008)	Training Prec@1 4.297 (1.423)	Training Prec@5 10.156 (3.213)	
2022-03-31 21:40:38,945: ============================================================
2022-03-31 21:41:25,928: time cost, forward:0.17014518208716023, backward:0.03685467013005557, data cost:0.26753425311899115 
2022-03-31 21:41:25,929: ============================================================
2022-03-31 21:41:25,929: Epoch 14/31 Batch 2000/7662 eta: 17:44:18.885159	Training Loss 0.7597 (0.7991)	Training Prec@1 5.664 (1.590)	Training Prec@5 11.719 (3.550)	
2022-03-31 21:41:25,929: ============================================================
2022-03-31 21:42:13,755: time cost, forward:0.17066282360482182, backward:0.0369110744643518, data cost:0.26714948247079906 
2022-03-31 21:42:13,756: ============================================================
2022-03-31 21:42:13,756: Epoch 14/31 Batch 2100/7662 eta: 18:02:37.271582	Training Loss 0.8320 (0.7981)	Training Prec@1 0.000 (1.717)	Training Prec@5 0.000 (3.808)	
2022-03-31 21:42:13,756: ============================================================
2022-03-31 21:42:58,269: time cost, forward:0.16874202038277925, backward:0.03671401454514403, data cost:0.26786253299426904 
2022-03-31 21:42:58,270: ============================================================
2022-03-31 21:42:58,270: Epoch 14/31 Batch 2200/7662 eta: 16:46:52.879889	Training Loss 0.8232 (0.7995)	Training Prec@1 0.000 (1.640)	Training Prec@5 0.000 (3.638)	
2022-03-31 21:42:58,270: ============================================================
2022-03-31 21:43:44,163: time cost, forward:0.16775832398137927, backward:0.03663336986974822, data cost:0.26833174818751604 
2022-03-31 21:43:44,163: ============================================================
2022-03-31 21:43:44,164: Epoch 14/31 Batch 2300/7662 eta: 17:17:19.487281	Training Loss 0.8197 (0.8005)	Training Prec@1 0.000 (1.570)	Training Prec@5 0.195 (3.484)	
2022-03-31 21:43:44,164: ============================================================
2022-03-31 21:44:32,154: time cost, forward:0.16763754316348242, backward:0.036637737135829504, data cost:0.26863931734992247 
2022-03-31 21:44:32,154: ============================================================
2022-03-31 21:44:32,154: Epoch 14/31 Batch 2400/7662 eta: 18:03:55.642549	Training Loss 0.8171 (0.8013)	Training Prec@1 0.000 (1.507)	Training Prec@5 0.195 (3.346)	
2022-03-31 21:44:32,155: ============================================================
2022-03-31 21:45:17,436: time cost, forward:0.16694666271736355, backward:0.03658466302857202, data cost:0.2686630352443101 
2022-03-31 21:45:17,436: ============================================================
2022-03-31 21:45:17,436: Epoch 14/31 Batch 2500/7662 eta: 17:01:59.404310	Training Loss 0.8164 (0.8020)	Training Prec@1 0.195 (1.450)	Training Prec@5 0.391 (3.220)	
2022-03-31 21:45:17,436: ============================================================
2022-03-31 21:46:01,758: time cost, forward:0.1662561185270972, backward:0.036578503697135896, data cost:0.26823702120881854 
2022-03-31 21:46:01,758: ============================================================
2022-03-31 21:46:01,758: Epoch 14/31 Batch 2600/7662 eta: 16:39:35.357247	Training Loss 0.8136 (0.8025)	Training Prec@1 0.000 (1.397)	Training Prec@5 0.586 (3.106)	
2022-03-31 21:46:01,758: ============================================================
2022-03-31 21:46:50,256: time cost, forward:0.1662250355730767, backward:0.03654705563842389, data cost:0.2687509930014566 
2022-03-31 21:46:50,257: ============================================================
2022-03-31 21:46:50,257: Epoch 14/31 Batch 2700/7662 eta: 18:12:58.463192	Training Loss 0.8094 (0.8028)	Training Prec@1 0.195 (1.350)	Training Prec@5 0.391 (3.007)	
2022-03-31 21:46:50,257: ============================================================
2022-03-31 21:47:36,079: time cost, forward:0.16644307152208748, backward:0.03651254361933919, data cost:0.268110867780036 
2022-03-31 21:47:36,079: ============================================================
2022-03-31 21:47:36,079: Epoch 14/31 Batch 2800/7662 eta: 17:11:53.738617	Training Loss 0.8061 (0.8031)	Training Prec@1 0.195 (1.310)	Training Prec@5 0.781 (2.922)	
2022-03-31 21:47:36,080: ============================================================
2022-03-31 21:48:23,172: time cost, forward:0.16682052094182215, backward:0.03649768898428699, data cost:0.26774698555490073 
2022-03-31 21:48:23,173: ============================================================
2022-03-31 21:48:23,173: Epoch 14/31 Batch 2900/7662 eta: 17:39:44.194705	Training Loss 0.7990 (0.8031)	Training Prec@1 0.977 (1.279)	Training Prec@5 1.758 (2.860)	
2022-03-31 21:48:23,173: ============================================================
2022-03-31 21:49:07,781: time cost, forward:0.1661104252037107, backward:0.03644990555323454, data cost:0.2676539474346114 
2022-03-31 21:49:07,782: ============================================================
2022-03-31 21:49:07,782: Epoch 14/31 Batch 3000/7662 eta: 16:43:05.340325	Training Loss 0.7730 (0.8026)	Training Prec@1 4.688 (1.299)	Training Prec@5 8.594 (2.911)	
2022-03-31 21:49:07,782: ============================================================
2022-03-31 21:49:54,971: time cost, forward:0.16602014125874442, backward:0.03643157706025263, data cost:0.26774482505480757 
2022-03-31 21:49:54,971: ============================================================
2022-03-31 21:49:54,972: Epoch 14/31 Batch 3100/7662 eta: 17:40:19.621341	Training Loss 0.7599 (0.8014)	Training Prec@1 6.836 (1.414)	Training Prec@5 13.672 (3.142)	
2022-03-31 21:49:54,972: ============================================================
2022-03-31 21:50:43,529: time cost, forward:0.16652356083969208, backward:0.036517974323464694, data cost:0.2676672723077915 
2022-03-31 21:50:43,530: ============================================================
2022-03-31 21:50:43,530: Epoch 14/31 Batch 3200/7662 eta: 18:10:16.036434	Training Loss 0.7548 (0.8001)	Training Prec@1 7.031 (1.565)	Training Prec@5 14.844 (3.438)	
2022-03-31 21:50:43,530: ============================================================
2022-03-31 21:51:30,206: time cost, forward:0.16626348246874756, backward:0.03649137929989808, data cost:0.2678267426763964 
2022-03-31 21:51:30,206: ============================================================
2022-03-31 21:51:30,206: Epoch 14/31 Batch 3300/7662 eta: 17:27:14.546481	Training Loss 0.7520 (0.7988)	Training Prec@1 8.789 (1.735)	Training Prec@5 15.820 (3.756)	
2022-03-31 21:51:30,207: ============================================================
2022-03-31 21:52:16,065: time cost, forward:0.16570096059419295, backward:0.03643108010467413, data cost:0.2680505631635665 
2022-03-31 21:52:16,066: ============================================================
2022-03-31 21:52:16,066: Epoch 14/31 Batch 3400/7662 eta: 17:08:08.720253	Training Loss 0.7515 (0.7974)	Training Prec@1 8.203 (1.919)	Training Prec@5 14.844 (4.093)	
2022-03-31 21:52:16,066: ============================================================
2022-03-31 21:53:04,780: time cost, forward:0.16620306397683624, backward:0.03647470651404726, data cost:0.267995029832677 
2022-03-31 21:53:04,781: ============================================================
2022-03-31 21:53:04,781: Epoch 14/31 Batch 3500/7662 eta: 18:11:21.369304	Training Loss 0.7486 (0.7960)	Training Prec@1 8.398 (2.109)	Training Prec@5 16.016 (4.431)	
2022-03-31 21:53:04,781: ============================================================
2022-03-31 21:53:50,939: time cost, forward:0.16598476764724532, backward:0.03645273101564976, data cost:0.268003787488267 
2022-03-31 21:53:50,939: ============================================================
2022-03-31 21:53:50,940: Epoch 14/31 Batch 3600/7662 eta: 17:13:19.117165	Training Loss 0.7464 (0.7948)	Training Prec@1 9.375 (2.271)	Training Prec@5 16.992 (4.723)	
2022-03-31 21:53:50,940: ============================================================
2022-03-31 21:54:38,322: time cost, forward:0.1661823662785976, backward:0.036467428044971176, data cost:0.2678394999559521 
2022-03-31 21:54:38,323: ============================================================
2022-03-31 21:54:38,323: Epoch 14/31 Batch 3700/7662 eta: 17:39:56.345290	Training Loss 0.7428 (0.7935)	Training Prec@1 10.547 (2.478)	Training Prec@5 18.555 (5.072)	
2022-03-31 21:54:38,323: ============================================================
2022-03-31 21:55:25,155: time cost, forward:0.16584645374475826, backward:0.03644128145748579, data cost:0.26816146340486907 
2022-03-31 21:55:25,156: ============================================================
2022-03-31 21:55:25,156: Epoch 14/31 Batch 3800/7662 eta: 17:26:51.087441	Training Loss 0.7446 (0.7922)	Training Prec@1 10.742 (2.682)	Training Prec@5 19.727 (5.426)	
2022-03-31 21:55:25,156: ============================================================
2022-03-31 21:56:11,646: time cost, forward:0.16571024748935978, backward:0.03643517801167874, data cost:0.2681530477695509 
2022-03-31 21:56:11,647: ============================================================
2022-03-31 21:56:11,647: Epoch 14/31 Batch 3900/7662 eta: 17:18:25.767340	Training Loss 0.7418 (0.7910)	Training Prec@1 10.742 (2.883)	Training Prec@5 18.945 (5.757)	
2022-03-31 21:56:11,647: ============================================================
2022-03-31 21:56:58,649: time cost, forward:0.1659169842166047, backward:0.03648285062112162, data cost:0.26786240406947365 
2022-03-31 21:56:58,650: ============================================================
2022-03-31 21:56:58,650: Epoch 14/31 Batch 4000/7662 eta: 17:29:05.085762	Training Loss 0.7400 (0.7898)	Training Prec@1 11.719 (3.096)	Training Prec@5 20.312 (6.115)	
2022-03-31 21:56:58,650: ============================================================
2022-03-31 21:57:45,033: time cost, forward:0.16581359151573583, backward:0.03647016472687341, data cost:0.2677372074848444 
2022-03-31 21:57:45,033: ============================================================
2022-03-31 21:57:45,034: Epoch 14/31 Batch 4100/7662 eta: 17:14:29.250483	Training Loss 0.7498 (0.7894)	Training Prec@1 6.836 (3.156)	Training Prec@5 14.453 (6.211)	
2022-03-31 21:57:45,034: ============================================================
2022-03-31 21:58:29,190: time cost, forward:0.16527342501070477, backward:0.03642963903181381, data cost:0.2677182599345001 
2022-03-31 21:58:29,190: ============================================================
2022-03-31 21:58:29,190: Epoch 14/31 Batch 4200/7662 eta: 16:24:04.833637	Training Loss 0.7367 (0.7882)	Training Prec@1 11.328 (3.374)	Training Prec@5 20.898 (6.571)	
2022-03-31 21:58:29,190: ============================================================
2022-03-31 21:59:16,150: time cost, forward:0.16540730102141532, backward:0.0364605285700434, data cost:0.26756625148855717 
2022-03-31 21:59:16,151: ============================================================
2022-03-31 21:59:16,151: Epoch 14/31 Batch 4300/7662 eta: 17:25:47.844282	Training Loss 0.7290 (0.7869)	Training Prec@1 16.797 (3.605)	Training Prec@5 26.367 (6.939)	
2022-03-31 21:59:16,151: ============================================================
2022-03-31 22:00:02,906: time cost, forward:0.16538962203552843, backward:0.03649968720479672, data cost:0.26744430410398573 
2022-03-31 22:00:02,906: ============================================================
2022-03-31 22:00:02,907: Epoch 14/31 Batch 4400/7662 eta: 17:20:26.482785	Training Loss 0.7322 (0.7857)	Training Prec@1 14.062 (3.829)	Training Prec@5 23.047 (7.300)	
2022-03-31 22:00:02,907: ============================================================
2022-03-31 22:00:51,630: time cost, forward:0.16588608374408045, backward:0.036544931388001994, data cost:0.2673430964267898 
2022-03-31 22:00:51,631: ============================================================
2022-03-31 22:00:51,631: Epoch 14/31 Batch 4500/7662 eta: 18:03:26.790261	Training Loss 0.7275 (0.7846)	Training Prec@1 13.281 (4.042)	Training Prec@5 23.047 (7.636)	
2022-03-31 22:00:51,631: ============================================================
2022-03-31 22:01:37,545: time cost, forward:0.16567101632027192, backward:0.036539359309409436, data cost:0.2673193350852274 
2022-03-31 22:01:37,546: ============================================================
2022-03-31 22:01:37,546: Epoch 14/31 Batch 4600/7662 eta: 17:00:12.269738	Training Loss 0.7291 (0.7834)	Training Prec@1 15.234 (4.283)	Training Prec@5 24.805 (8.010)	
2022-03-31 22:01:37,546: ============================================================
2022-03-31 22:02:24,326: time cost, forward:0.16563789508118987, backward:0.03651665093721697, data cost:0.26733568354499265 
2022-03-31 22:02:24,326: ============================================================
2022-03-31 22:02:24,327: Epoch 14/31 Batch 4700/7662 eta: 17:18:39.747252	Training Loss 0.7307 (0.7822)	Training Prec@1 15.820 (4.528)	Training Prec@5 24.023 (8.379)	
2022-03-31 22:02:24,327: ============================================================
2022-03-31 22:03:09,555: time cost, forward:0.165421836051774, backward:0.03649835647158534, data cost:0.2671978351448347 
2022-03-31 22:03:09,556: ============================================================
2022-03-31 22:03:09,556: Epoch 14/31 Batch 4800/7662 eta: 16:43:27.965702	Training Loss 0.7210 (0.7810)	Training Prec@1 16.797 (4.774)	Training Prec@5 26.758 (8.749)	
2022-03-31 22:03:09,556: ============================================================
2022-03-31 22:03:57,625: time cost, forward:0.1659109245930236, backward:0.03655019685379654, data cost:0.26687262709906306 
2022-03-31 22:03:57,625: ============================================================
2022-03-31 22:03:57,625: Epoch 14/31 Batch 4900/7662 eta: 17:45:40.261412	Training Loss 0.7214 (0.7798)	Training Prec@1 15.625 (5.024)	Training Prec@5 28.906 (9.125)	
2022-03-31 22:03:57,625: ============================================================
2022-03-31 22:04:44,674: time cost, forward:0.16593357581428395, backward:0.03654137576286925, data cost:0.26688950122368527 
2022-03-31 22:04:44,675: ============================================================
2022-03-31 22:04:44,675: Epoch 14/31 Batch 5000/7662 eta: 17:22:17.057700	Training Loss 0.7254 (0.7786)	Training Prec@1 17.188 (5.279)	Training Prec@5 25.977 (9.503)	
2022-03-31 22:04:44,675: ============================================================
2022-03-31 22:05:29,572: time cost, forward:0.16529550746881067, backward:0.03651783297543059, data cost:0.2671363997585658 
2022-03-31 22:05:29,573: ============================================================
2022-03-31 22:05:29,573: Epoch 14/31 Batch 5100/7662 eta: 16:33:52.279577	Training Loss 0.7227 (0.7775)	Training Prec@1 18.359 (5.528)	Training Prec@5 26.562 (9.868)	
2022-03-31 22:05:29,573: ============================================================
2022-03-31 22:06:17,646: time cost, forward:0.1656089346324923, backward:0.03654333503687925, data cost:0.2670237569997897 
2022-03-31 22:06:17,647: ============================================================
2022-03-31 22:06:17,647: Epoch 14/31 Batch 5200/7662 eta: 17:43:22.092605	Training Loss 0.7098 (0.7763)	Training Prec@1 20.898 (5.789)	Training Prec@5 31.641 (10.247)	
2022-03-31 22:06:17,647: ============================================================
2022-03-31 22:07:04,347: time cost, forward:0.16569508267114874, backward:0.036536821398471385, data cost:0.26689359389919 
2022-03-31 22:07:04,347: ============================================================
2022-03-31 22:07:04,347: Epoch 14/31 Batch 5300/7662 eta: 17:12:12.665193	Training Loss 0.7126 (0.7752)	Training Prec@1 21.094 (6.046)	Training Prec@5 32.422 (10.613)	
2022-03-31 22:07:04,347: ============================================================
2022-03-31 22:07:51,477: time cost, forward:0.16592387831593072, backward:0.036564676777966314, data cost:0.26664858426092114 
2022-03-31 22:07:51,477: ============================================================
2022-03-31 22:07:51,478: Epoch 14/31 Batch 5400/7662 eta: 17:20:55.890982	Training Loss 0.7103 (0.7740)	Training Prec@1 22.852 (6.309)	Training Prec@5 32.617 (10.989)	
2022-03-31 22:07:51,478: ============================================================
2022-03-31 22:08:38,556: time cost, forward:0.16579237572169994, backward:0.0365537247845944, data cost:0.266824503381982 
2022-03-31 22:08:38,557: ============================================================
2022-03-31 22:08:38,557: Epoch 14/31 Batch 5500/7662 eta: 17:19:01.474880	Training Loss 0.7069 (0.7730)	Training Prec@1 21.289 (6.553)	Training Prec@5 31.250 (11.338)	
2022-03-31 22:08:38,558: ============================================================
2022-03-31 22:09:27,413: time cost, forward:0.16611639740935905, backward:0.036586825859122964, data cost:0.26682761422777457 
2022-03-31 22:09:27,413: ============================================================
2022-03-31 22:09:27,414: Epoch 14/31 Batch 5600/7662 eta: 17:57:24.961594	Training Loss 0.7076 (0.7718)	Training Prec@1 20.508 (6.825)	Training Prec@5 35.352 (11.715)	
2022-03-31 22:09:27,414: ============================================================
2022-03-31 22:10:13,633: time cost, forward:0.16622840004817377, backward:0.03661111736113533, data cost:0.2665356199120948 
2022-03-31 22:10:13,633: ============================================================
2022-03-31 22:10:13,634: Epoch 14/31 Batch 5700/7662 eta: 16:58:30.794844	Training Loss 0.6999 (0.7707)	Training Prec@1 24.609 (7.102)	Training Prec@5 37.305 (12.097)	
2022-03-31 22:10:13,634: ============================================================
2022-03-31 22:11:00,131: time cost, forward:0.1665000940195588, backward:0.03659943260598088, data cost:0.26621390470329453 
2022-03-31 22:11:00,132: ============================================================
2022-03-31 22:11:00,133: Epoch 14/31 Batch 5800/7662 eta: 17:03:52.838547	Training Loss 0.7003 (0.7695)	Training Prec@1 26.172 (7.375)	Training Prec@5 35.156 (12.473)	
2022-03-31 22:11:00,133: ============================================================
2022-03-31 22:11:46,471: time cost, forward:0.1666390448025595, backward:0.036584846365955, data cost:0.2659843660326484 
2022-03-31 22:11:46,472: ============================================================
2022-03-31 22:11:46,472: Epoch 14/31 Batch 5900/7662 eta: 16:59:35.978620	Training Loss 0.7050 (0.7684)	Training Prec@1 23.633 (7.651)	Training Prec@5 33.398 (12.850)	
2022-03-31 22:11:46,472: ============================================================
2022-03-31 22:12:33,159: time cost, forward:0.1666142024841283, backward:0.03658428647594067, data cost:0.2659591550647388 
2022-03-31 22:12:33,160: ============================================================
2022-03-31 22:12:33,160: Epoch 14/31 Batch 6000/7662 eta: 17:06:29.639451	Training Loss 0.6948 (0.7673)	Training Prec@1 28.320 (7.930)	Training Prec@5 35.547 (13.223)	
2022-03-31 22:12:33,160: ============================================================
2022-03-31 22:13:19,631: time cost, forward:0.16680014119771372, backward:0.03658287348092863, data cost:0.26568365695144647 
2022-03-31 22:13:19,632: ============================================================
2022-03-31 22:13:19,632: Epoch 14/31 Batch 6100/7662 eta: 17:00:57.519330	Training Loss 0.6999 (0.7662)	Training Prec@1 24.023 (8.209)	Training Prec@5 35.547 (13.595)	
2022-03-31 22:13:19,632: ============================================================
2022-03-31 22:14:06,485: time cost, forward:0.16674317300540822, backward:0.03656278992683815, data cost:0.2657621270284516 
2022-03-31 22:14:06,486: ============================================================
2022-03-31 22:14:06,486: Epoch 14/31 Batch 6200/7662 eta: 17:08:35.115417	Training Loss 0.6999 (0.7651)	Training Prec@1 24.219 (8.489)	Training Prec@5 35.156 (13.964)	
2022-03-31 22:14:06,486: ============================================================
2022-03-31 22:14:54,254: time cost, forward:0.16693109484925536, backward:0.03656944662337266, data cost:0.26567079275633576 
2022-03-31 22:14:54,255: ============================================================
2022-03-31 22:14:54,255: Epoch 14/31 Batch 6300/7662 eta: 17:27:51.980766	Training Loss 0.6952 (0.7640)	Training Prec@1 26.172 (8.769)	Training Prec@5 36.914 (14.338)	
2022-03-31 22:14:54,255: ============================================================
2022-03-31 22:15:38,465: time cost, forward:0.1668099897655589, backward:0.036580450889896206, data cost:0.2653689472763627 
2022-03-31 22:15:38,466: ============================================================
2022-03-31 22:15:38,466: Epoch 14/31 Batch 6400/7662 eta: 16:09:04.680433	Training Loss 0.6984 (0.7629)	Training Prec@1 23.242 (9.048)	Training Prec@5 36.719 (14.700)	
2022-03-31 22:15:38,466: ============================================================
2022-03-31 22:16:24,433: time cost, forward:0.16678934743687232, backward:0.03659546256047026, data cost:0.2652376284322696 
2022-03-31 22:16:24,433: ============================================================
2022-03-31 22:16:24,433: Epoch 14/31 Batch 6500/7662 eta: 16:46:49.195914	Training Loss 0.6912 (0.7619)	Training Prec@1 27.734 (9.321)	Training Prec@5 38.281 (15.057)	
2022-03-31 22:16:24,434: ============================================================
2022-03-31 22:17:10,838: time cost, forward:0.1666373909197173, backward:0.0365875908634413, data cost:0.26531936273662987 
2022-03-31 22:17:10,839: ============================================================
2022-03-31 22:17:10,839: Epoch 14/31 Batch 6600/7662 eta: 16:55:38.687303	Training Loss 0.6850 (0.7608)	Training Prec@1 28.906 (9.595)	Training Prec@5 39.648 (15.414)	
2022-03-31 22:17:10,839: ============================================================
2022-03-31 22:17:57,240: time cost, forward:0.16665341124852784, backward:0.03656707448485289, data cost:0.2652446461677694 
2022-03-31 22:17:57,240: ============================================================
2022-03-31 22:17:57,240: Epoch 14/31 Batch 6700/7662 eta: 16:54:46.149427	Training Loss 0.6935 (0.7598)	Training Prec@1 28.125 (9.870)	Training Prec@5 39.648 (15.771)	
2022-03-31 22:17:57,241: ============================================================
2022-03-31 22:18:46,420: time cost, forward:0.16675465621392785, backward:0.03657672839719489, data cost:0.265485068843161 
2022-03-31 22:18:46,420: ============================================================
2022-03-31 22:18:46,421: Epoch 14/31 Batch 6800/7662 eta: 17:54:43.886812	Training Loss 0.6816 (0.7588)	Training Prec@1 30.664 (10.137)	Training Prec@5 39.648 (16.117)	
2022-03-31 22:18:46,421: ============================================================
2022-03-31 22:19:33,513: time cost, forward:0.16680306800121258, backward:0.036566829176843466, data cost:0.2654532200876466 
2022-03-31 22:19:33,513: ============================================================
2022-03-31 22:19:33,513: Epoch 14/31 Batch 6900/7662 eta: 17:08:19.326564	Training Loss 0.6926 (0.7578)	Training Prec@1 28.711 (10.408)	Training Prec@5 40.234 (16.465)	
2022-03-31 22:19:33,514: ============================================================
2022-03-31 22:20:18,091: time cost, forward:0.16658758694724637, backward:0.036522041611849264, data cost:0.26538959457663436 
2022-03-31 22:20:18,092: ============================================================
2022-03-31 22:20:18,092: Epoch 14/31 Batch 7000/7662 eta: 16:12:41.339602	Training Loss 0.6842 (0.7568)	Training Prec@1 30.664 (10.677)	Training Prec@5 41.797 (16.809)	
2022-03-31 22:20:18,093: ============================================================
2022-03-31 22:21:05,474: time cost, forward:0.16668132060446325, backward:0.03652969234878706, data cost:0.2653628197299341 
2022-03-31 22:21:05,475: ============================================================
2022-03-31 22:21:05,475: Epoch 14/31 Batch 7100/7662 eta: 17:13:04.654062	Training Loss 0.6747 (0.7558)	Training Prec@1 33.398 (10.939)	Training Prec@5 45.312 (17.147)	
2022-03-31 22:21:05,475: ============================================================
2022-03-31 22:21:52,532: time cost, forward:0.16670385588041725, backward:0.03653078483929153, data cost:0.2653496811200818 
2022-03-31 22:21:52,533: ============================================================
2022-03-31 22:21:52,533: Epoch 14/31 Batch 7200/7662 eta: 17:05:13.373808	Training Loss 0.6860 (0.7548)	Training Prec@1 27.930 (11.197)	Training Prec@5 38.281 (17.475)	
2022-03-31 22:21:52,534: ============================================================
2022-03-31 22:22:39,913: time cost, forward:0.16649325237909168, backward:0.036524095475175544, data cost:0.26564414711223266 
2022-03-31 22:22:39,913: ============================================================
2022-03-31 22:22:39,914: Epoch 14/31 Batch 7300/7662 eta: 17:11:26.491080	Training Loss 0.6873 (0.7539)	Training Prec@1 27.539 (11.452)	Training Prec@5 40.625 (17.799)	
2022-03-31 22:22:39,914: ============================================================
2022-03-31 22:23:30,043: time cost, forward:0.16688142162446218, backward:0.03657255032236857, data cost:0.2656453955671339 
2022-03-31 22:23:30,044: ============================================================
2022-03-31 22:23:30,045: Epoch 14/31 Batch 7400/7662 eta: 18:10:29.396108	Training Loss 0.8328 (0.7547)	Training Prec@1 0.000 (11.367)	Training Prec@5 0.000 (17.656)	
2022-03-31 22:23:30,045: ============================================================
2022-03-31 22:24:16,207: time cost, forward:0.16687739761785947, backward:0.036570046485018805, data cost:0.2655311877734821 
2022-03-31 22:24:16,207: ============================================================
2022-03-31 22:24:16,208: Epoch 14/31 Batch 7500/7662 eta: 16:43:24.515829	Training Loss 0.8274 (0.7557)	Training Prec@1 0.000 (11.216)	Training Prec@5 0.195 (17.421)	
2022-03-31 22:24:16,208: ============================================================
2022-03-31 22:25:04,386: time cost, forward:0.16719660992402122, backward:0.03657855907856344, data cost:0.2653800276552851 
2022-03-31 22:25:04,414: ============================================================
2022-03-31 22:25:04,415: Epoch 14/31 Batch 7600/7662 eta: 17:27:01.380876	Training Loss 0.8290 (0.7566)	Training Prec@1 0.000 (11.068)	Training Prec@5 0.195 (17.193)	
2022-03-31 22:25:04,415: ============================================================
2022-03-31 22:25:39,045: Epoch: 14/31 eta: 17:26:31.010725	Training Loss 0.8268 (0.7572)	Training Prec@1 0.000 (10.977)	Training Prec@5 0.000 (17.052)
2022-03-31 22:25:39,046: ============================================================
2022-03-31 22:26:33,138: time cost, forward:0.2116477826629022, backward:0.03706024150655727, data cost:0.293303547483502 
2022-03-31 22:26:33,139: ============================================================
2022-03-31 22:26:33,139: Epoch 15/31 Batch 100/7662 eta: 19:30:15.974655	Training Loss 0.8246 (0.8248)	Training Prec@1 0.000 (0.010)	Training Prec@5 0.000 (0.037)	
2022-03-31 22:26:33,139: ============================================================
2022-03-31 22:27:28,963: time cost, forward:0.21916549888687517, backward:0.03910150839455763, data cost:0.291361837530855 
2022-03-31 22:27:28,980: ============================================================
2022-03-31 22:27:28,980: Epoch 15/31 Batch 200/7662 eta: 20:10:24.159940	Training Loss 0.8256 (0.8245)	Training Prec@1 0.000 (0.016)	Training Prec@5 0.000 (0.046)	
2022-03-31 22:27:28,980: ============================================================
2022-03-31 22:28:15,329: time cost, forward:0.2005922164406665, backward:0.03882887849839635, data cost:0.2804123781197845 
2022-03-31 22:28:15,330: ============================================================
2022-03-31 22:28:15,330: Epoch 15/31 Batch 300/7662 eta: 16:43:54.142066	Training Loss 0.8224 (0.8242)	Training Prec@1 0.000 (0.013)	Training Prec@5 0.000 (0.049)	
2022-03-31 22:28:15,330: ============================================================
2022-03-31 22:29:01,908: time cost, forward:0.19050707733421995, backward:0.03839839849256931, data cost:0.2779312313051152 
2022-03-31 22:29:01,908: ============================================================
2022-03-31 22:29:01,909: Epoch 15/31 Batch 400/7662 eta: 16:48:04.848060	Training Loss 0.8234 (0.8238)	Training Prec@1 0.000 (0.014)	Training Prec@5 0.000 (0.054)	
2022-03-31 22:29:01,909: ============================================================
2022-03-31 22:29:47,247: time cost, forward:0.18442917156792835, backward:0.037715237221880284, data cost:0.2737980170813734 
2022-03-31 22:29:47,288: ============================================================
2022-03-31 22:29:47,289: Epoch 15/31 Batch 500/7662 eta: 16:21:22.908554	Training Loss 0.8226 (0.8235)	Training Prec@1 0.000 (0.014)	Training Prec@5 0.000 (0.054)	
2022-03-31 22:29:47,289: ============================================================
2022-03-31 22:30:39,421: time cost, forward:0.18807456409791873, backward:0.038274147673719915, data cost:0.2738809975638413 
2022-03-31 22:30:39,421: ============================================================
2022-03-31 22:30:39,421: Epoch 15/31 Batch 600/7662 eta: 18:46:32.607937	Training Loss 0.8197 (0.8232)	Training Prec@1 0.000 (0.012)	Training Prec@5 0.195 (0.056)	
2022-03-31 22:30:39,422: ============================================================
2022-03-31 22:31:28,062: time cost, forward:0.19011424778186542, backward:0.03826206538810239, data cost:0.26974672172884745 
2022-03-31 22:31:28,063: ============================================================
2022-03-31 22:31:28,063: Epoch 15/31 Batch 700/7662 eta: 17:30:17.516324	Training Loss 0.8212 (0.8229)	Training Prec@1 0.000 (0.015)	Training Prec@5 0.000 (0.061)	
2022-03-31 22:31:28,063: ============================================================
2022-03-31 22:32:17,294: time cost, forward:0.19071726238026337, backward:0.03840711000416246, data cost:0.268238081054783 
2022-03-31 22:32:17,294: ============================================================
2022-03-31 22:32:17,295: Epoch 15/31 Batch 800/7662 eta: 17:42:12.907964	Training Loss 0.8209 (0.8227)	Training Prec@1 0.000 (0.016)	Training Prec@5 0.195 (0.067)	
2022-03-31 22:32:17,295: ============================================================
2022-03-31 22:33:00,703: time cost, forward:0.18368482748844203, backward:0.037961252804460194, data cost:0.26869448061381884 
2022-03-31 22:33:00,703: ============================================================
2022-03-31 22:33:00,704: Epoch 15/31 Batch 900/7662 eta: 15:35:51.856489	Training Loss 0.8194 (0.8224)	Training Prec@1 0.000 (0.020)	Training Prec@5 0.000 (0.074)	
2022-03-31 22:33:00,704: ============================================================
2022-03-31 22:33:48,317: time cost, forward:0.18136315135745792, backward:0.03795896301995049, data cost:0.26951992285024895 
2022-03-31 22:33:48,317: ============================================================
2022-03-31 22:33:48,318: Epoch 15/31 Batch 1000/7662 eta: 17:05:43.462247	Training Loss 0.8177 (0.8221)	Training Prec@1 0.000 (0.022)	Training Prec@5 0.195 (0.078)	
2022-03-31 22:33:48,318: ============================================================
2022-03-31 22:34:36,179: time cost, forward:0.18156484021611166, backward:0.037971690961509756, data cost:0.26833889720871623 
2022-03-31 22:34:36,180: ============================================================
2022-03-31 22:34:36,180: Epoch 15/31 Batch 1100/7662 eta: 17:10:16.767779	Training Loss 0.8199 (0.8219)	Training Prec@1 0.000 (0.022)	Training Prec@5 0.000 (0.082)	
2022-03-31 22:34:36,180: ============================================================
2022-03-31 22:35:20,248: time cost, forward:0.17856611382275248, backward:0.03759674433373331, data cost:0.26773537984980056 
2022-03-31 22:35:20,249: ============================================================
2022-03-31 22:35:20,249: Epoch 15/31 Batch 1200/7662 eta: 15:47:53.354419	Training Loss 0.8180 (0.8216)	Training Prec@1 0.000 (0.024)	Training Prec@5 0.195 (0.087)	
2022-03-31 22:35:20,250: ============================================================
2022-03-31 22:36:06,792: time cost, forward:0.17745621576962606, backward:0.03743004688765105, data cost:0.2675381727270019 
2022-03-31 22:36:06,792: ============================================================
2022-03-31 22:36:06,792: Epoch 15/31 Batch 1300/7662 eta: 16:40:19.299958	Training Loss 0.8196 (0.8213)	Training Prec@1 0.000 (0.024)	Training Prec@5 0.000 (0.091)	
2022-03-31 22:36:06,792: ============================================================
2022-03-31 22:36:54,423: time cost, forward:0.17761144423331424, backward:0.037447376537527506, data cost:0.266838451553192 
2022-03-31 22:36:54,423: ============================================================
2022-03-31 22:36:54,423: Epoch 15/31 Batch 1400/7662 eta: 17:02:55.140154	Training Loss 0.8188 (0.8210)	Training Prec@1 0.195 (0.027)	Training Prec@5 0.195 (0.097)	
2022-03-31 22:36:54,423: ============================================================
2022-03-31 22:37:40,827: time cost, forward:0.17686703652044072, backward:0.037414082850990016, data cost:0.26638348648117094 
2022-03-31 22:37:40,828: ============================================================
2022-03-31 22:37:40,828: Epoch 15/31 Batch 1500/7662 eta: 16:35:48.137929	Training Loss 0.8127 (0.8207)	Training Prec@1 0.000 (0.027)	Training Prec@5 0.391 (0.102)	
2022-03-31 22:37:40,828: ============================================================
2022-03-31 22:38:26,628: time cost, forward:0.17609361322914682, backward:0.03728382717154039, data cost:0.26572659628476253 
2022-03-31 22:38:26,628: ============================================================
2022-03-31 22:38:26,628: Epoch 15/31 Batch 1600/7662 eta: 16:22:04.527649	Training Loss 0.8161 (0.8204)	Training Prec@1 0.000 (0.029)	Training Prec@5 0.000 (0.111)	
2022-03-31 22:38:26,628: ============================================================
2022-03-31 22:39:12,071: time cost, forward:0.17436026053403392, backward:0.03714564437372254, data cost:0.266175906050549 
2022-03-31 22:39:12,072: ============================================================
2022-03-31 22:39:12,072: Epoch 15/31 Batch 1700/7662 eta: 16:13:40.396896	Training Loss 0.8131 (0.8201)	Training Prec@1 0.000 (0.031)	Training Prec@5 0.000 (0.120)	
2022-03-31 22:39:12,072: ============================================================
2022-03-31 22:39:57,925: time cost, forward:0.17346613310389283, backward:0.037154373292991885, data cost:0.26598830127663053 
2022-03-31 22:39:57,925: ============================================================
2022-03-31 22:39:57,926: Epoch 15/31 Batch 1800/7662 eta: 16:21:41.038862	Training Loss 0.8119 (0.8197)	Training Prec@1 0.195 (0.034)	Training Prec@5 0.195 (0.128)	
2022-03-31 22:39:57,926: ============================================================
2022-03-31 22:40:41,579: time cost, forward:0.1719432355479983, backward:0.03709468582920679, data cost:0.2654311535168849 
2022-03-31 22:40:41,580: ============================================================
2022-03-31 22:40:41,580: Epoch 15/31 Batch 1900/7662 eta: 15:33:52.234975	Training Loss 0.8095 (0.8193)	Training Prec@1 0.195 (0.037)	Training Prec@5 0.391 (0.138)	
2022-03-31 22:40:41,580: ============================================================
2022-03-31 22:41:29,101: time cost, forward:0.17197355799462688, backward:0.0371753090080349, data cost:0.2653298281382894 
2022-03-31 22:41:29,101: ============================================================
2022-03-31 22:41:29,101: Epoch 15/31 Batch 2000/7662 eta: 16:55:48.770297	Training Loss 0.8083 (0.8189)	Training Prec@1 0.195 (0.042)	Training Prec@5 0.586 (0.154)	
2022-03-31 22:41:29,101: ============================================================
2022-03-31 22:42:15,589: time cost, forward:0.17181969506789413, backward:0.037190302943774435, data cost:0.2649891568456961 
2022-03-31 22:42:15,590: ============================================================
2022-03-31 22:42:15,590: Epoch 15/31 Batch 2100/7662 eta: 16:32:57.403324	Training Loss 0.8066 (0.8183)	Training Prec@1 0.391 (0.050)	Training Prec@5 1.562 (0.175)	
2022-03-31 22:42:15,590: ============================================================
2022-03-31 22:43:01,476: time cost, forward:0.17182897003524247, backward:0.03721506349495076, data cost:0.2642884034360198 
2022-03-31 22:43:01,476: ============================================================
2022-03-31 22:43:01,477: Epoch 15/31 Batch 2200/7662 eta: 16:19:20.303947	Training Loss 0.7992 (0.8177)	Training Prec@1 0.781 (0.064)	Training Prec@5 1.758 (0.216)	
2022-03-31 22:43:01,477: ============================================================
2022-03-31 22:43:47,191: time cost, forward:0.17170030036766978, backward:0.03716696309441844, data cost:0.2637482996140422 
2022-03-31 22:43:47,205: ============================================================
2022-03-31 22:43:47,205: Epoch 15/31 Batch 2300/7662 eta: 16:15:12.055788	Training Loss 0.7948 (0.8167)	Training Prec@1 1.367 (0.093)	Training Prec@5 3.125 (0.291)	
2022-03-31 22:43:47,205: ============================================================
2022-03-31 22:44:32,878: time cost, forward:0.17128358676364988, backward:0.03710694589332622, data cost:0.26351799791979263 
2022-03-31 22:44:32,879: ============================================================
2022-03-31 22:44:32,879: Epoch 15/31 Batch 2400/7662 eta: 16:13:15.920566	Training Loss 0.7843 (0.8156)	Training Prec@1 1.367 (0.140)	Training Prec@5 3.516 (0.419)	
2022-03-31 22:44:32,879: ============================================================
2022-03-31 22:45:17,574: time cost, forward:0.1707806760857419, backward:0.03702836868618908, data cost:0.2630793500681217 
2022-03-31 22:45:17,575: ============================================================
2022-03-31 22:45:17,575: Epoch 15/31 Batch 2500/7662 eta: 15:51:41.506206	Training Loss 0.7814 (0.8143)	Training Prec@1 1.953 (0.203)	Training Prec@5 4.688 (0.576)	
2022-03-31 22:45:17,575: ============================================================
2022-03-31 22:46:03,888: time cost, forward:0.17019402223992872, backward:0.036981750791372815, data cost:0.2633991912035999 
2022-03-31 22:46:03,889: ============================================================
2022-03-31 22:46:03,889: Epoch 15/31 Batch 2600/7662 eta: 16:25:22.276868	Training Loss 0.7726 (0.8130)	Training Prec@1 3.906 (0.274)	Training Prec@5 7.617 (0.750)	
2022-03-31 22:46:03,889: ============================================================
2022-03-31 22:46:48,873: time cost, forward:0.16928897649546648, backward:0.0369580254902792, data cost:0.2634772369268869 
2022-03-31 22:46:48,873: ============================================================
2022-03-31 22:46:48,873: Epoch 15/31 Batch 2700/7662 eta: 15:56:19.722519	Training Loss 0.7758 (0.8117)	Training Prec@1 1.367 (0.352)	Training Prec@5 5.078 (0.941)	
2022-03-31 22:46:48,874: ============================================================
2022-03-31 22:47:34,246: time cost, forward:0.16860078376887228, backward:0.036773059912433195, data cost:0.2637047252300681 
2022-03-31 22:47:34,247: ============================================================
2022-03-31 22:47:34,247: Epoch 15/31 Batch 2800/7662 eta: 16:03:50.945894	Training Loss 0.7776 (0.8106)	Training Prec@1 2.148 (0.412)	Training Prec@5 5.469 (1.091)	
2022-03-31 22:47:34,247: ============================================================
2022-03-31 22:48:19,046: time cost, forward:0.16851010294608634, backward:0.0367044842461135, data cost:0.26322670589853625 
2022-03-31 22:48:19,046: ============================================================
2022-03-31 22:48:19,046: Epoch 15/31 Batch 2900/7662 eta: 15:50:54.259893	Training Loss 0.7734 (0.8094)	Training Prec@1 2.539 (0.501)	Training Prec@5 7.227 (1.293)	
2022-03-31 22:48:19,047: ============================================================
2022-03-31 22:49:06,057: time cost, forward:0.167914387940486, backward:0.036702076647034405, data cost:0.2639105209472697 
2022-03-31 22:49:06,058: ============================================================
2022-03-31 22:49:06,058: Epoch 15/31 Batch 3000/7662 eta: 16:37:04.682901	Training Loss 0.7727 (0.8082)	Training Prec@1 3.906 (0.585)	Training Prec@5 8.008 (1.474)	
2022-03-31 22:49:06,058: ============================================================
2022-03-31 22:49:50,060: time cost, forward:0.16705932360227818, backward:0.036449009697450366, data cost:0.2640672185491 
2022-03-31 22:49:50,061: ============================================================
2022-03-31 22:49:50,061: Epoch 15/31 Batch 3100/7662 eta: 15:32:32.043477	Training Loss 0.7665 (0.8070)	Training Prec@1 4.492 (0.682)	Training Prec@5 8.203 (1.685)	
2022-03-31 22:49:50,061: ============================================================
2022-03-31 22:50:38,652: time cost, forward:0.16749889047938088, backward:0.0361358619325047, data cost:0.2645230820194637 
2022-03-31 22:50:38,652: ============================================================
2022-03-31 22:50:38,653: Epoch 15/31 Batch 3200/7662 eta: 17:08:58.072754	Training Loss 0.7677 (0.8063)	Training Prec@1 3.516 (0.732)	Training Prec@5 8.203 (1.799)	
2022-03-31 22:50:38,653: ============================================================
2022-03-31 22:51:23,252: time cost, forward:0.1673299201729443, backward:0.0359920458057932, data cost:0.2641389436452958 
2022-03-31 22:51:23,252: ============================================================
2022-03-31 22:51:23,252: Epoch 15/31 Batch 3300/7662 eta: 15:43:41.501581	Training Loss 0.7718 (0.8051)	Training Prec@1 4.297 (0.832)	Training Prec@5 8.203 (2.013)	
2022-03-31 22:51:23,253: ============================================================
2022-03-31 22:52:10,468: time cost, forward:0.16715270780612174, backward:0.03597278004360396, data cost:0.2644716390058131 
2022-03-31 22:52:10,468: ============================================================
2022-03-31 22:52:10,468: Epoch 15/31 Batch 3400/7662 eta: 16:38:15.686020	Training Loss 0.7713 (0.8039)	Training Prec@1 3.320 (0.939)	Training Prec@5 8.398 (2.237)	
2022-03-31 22:52:10,468: ============================================================
2022-03-31 22:52:58,213: time cost, forward:0.1676807606618859, backward:0.03601636822545961, data cost:0.2641676726699659 
2022-03-31 22:52:58,213: ============================================================
2022-03-31 22:52:58,214: Epoch 15/31 Batch 3500/7662 eta: 16:48:39.657532	Training Loss 0.7600 (0.8031)	Training Prec@1 5.273 (1.008)	Training Prec@5 10.547 (2.386)	
2022-03-31 22:52:58,214: ============================================================
2022-03-31 22:53:43,962: time cost, forward:0.16725599206000707, backward:0.03604940779840459, data cost:0.264273965116937 
2022-03-31 22:53:43,963: ============================================================
2022-03-31 22:53:43,963: Epoch 15/31 Batch 3600/7662 eta: 16:05:44.035612	Training Loss 0.8472 (0.8021)	Training Prec@1 0.391 (1.110)	Training Prec@5 0.781 (2.596)	
2022-03-31 22:53:43,963: ============================================================
2022-03-31 22:54:29,830: time cost, forward:0.16729830142194177, backward:0.03601681693046922, data cost:0.2639943085093213 
2022-03-31 22:54:29,831: ============================================================
2022-03-31 22:54:29,831: Epoch 15/31 Batch 3700/7662 eta: 16:07:28.268861	Training Loss 0.7788 (0.8023)	Training Prec@1 0.977 (1.095)	Training Prec@5 3.711 (2.568)	
2022-03-31 22:54:29,831: ============================================================
2022-03-31 22:55:16,290: time cost, forward:0.1676051531945068, backward:0.03603429196853015, data cost:0.26359632593231724 
2022-03-31 22:55:16,290: ============================================================
2022-03-31 22:55:16,291: Epoch 15/31 Batch 3800/7662 eta: 16:19:10.374688	Training Loss 0.7614 (0.8013)	Training Prec@1 5.469 (1.190)	Training Prec@5 10.742 (2.757)	
2022-03-31 22:55:16,291: ============================================================
2022-03-31 22:56:01,094: time cost, forward:0.1670688948713226, backward:0.03597309975233956, data cost:0.26368913487857293 
2022-03-31 22:56:01,095: ============================================================
2022-03-31 22:56:01,095: Epoch 15/31 Batch 3900/7662 eta: 15:43:32.674289	Training Loss 0.7560 (0.8004)	Training Prec@1 6.055 (1.301)	Training Prec@5 10.938 (2.976)	
2022-03-31 22:56:01,095: ============================================================
2022-03-31 22:56:48,191: time cost, forward:0.16736637863346146, backward:0.03601964231311276, data cost:0.26343501207380776 
2022-03-31 22:56:48,191: ============================================================
2022-03-31 22:56:48,192: Epoch 15/31 Batch 4000/7662 eta: 16:31:01.502354	Training Loss 0.7619 (0.7993)	Training Prec@1 5.664 (1.424)	Training Prec@5 11.523 (3.209)	
2022-03-31 22:56:48,192: ============================================================
2022-03-31 22:57:36,237: time cost, forward:0.16770534336232476, backward:0.03602460792338624, data cost:0.2634228851539852 
2022-03-31 22:57:36,238: ============================================================
2022-03-31 22:57:36,238: Epoch 15/31 Batch 4100/7662 eta: 16:50:13.362811	Training Loss 0.8382 (0.7984)	Training Prec@1 0.195 (1.542)	Training Prec@5 1.758 (3.432)	
2022-03-31 22:57:36,238: ============================================================
2022-03-31 22:58:23,005: time cost, forward:0.16764939844849622, backward:0.03602860876139245, data cost:0.2634925842285156 
2022-03-31 22:58:23,005: ============================================================
2022-03-31 22:58:23,006: Epoch 15/31 Batch 4200/7662 eta: 16:22:32.499741	Training Loss 0.7513 (0.7979)	Training Prec@1 8.398 (1.592)	Training Prec@5 15.039 (3.531)	
2022-03-31 22:58:23,006: ============================================================
2022-03-31 22:59:09,948: time cost, forward:0.16810353325255722, backward:0.03606549416289382, data cost:0.2630409081887855 
2022-03-31 22:59:09,948: ============================================================
2022-03-31 22:59:09,948: Epoch 15/31 Batch 4300/7662 eta: 16:25:26.923016	Training Loss 0.7512 (0.7969)	Training Prec@1 7.812 (1.725)	Training Prec@5 16.016 (3.784)	
2022-03-31 22:59:09,949: ============================================================
2022-03-31 22:59:55,748: time cost, forward:0.16810738457742402, backward:0.036061430389324516, data cost:0.2628142433725831 
2022-03-31 22:59:55,749: ============================================================
2022-03-31 22:59:55,749: Epoch 15/31 Batch 4400/7662 eta: 16:00:42.034331	Training Loss 0.7472 (0.7959)	Training Prec@1 10.156 (1.862)	Training Prec@5 17.578 (4.033)	
2022-03-31 22:59:55,749: ============================================================
2022-03-31 23:00:42,757: time cost, forward:0.16826189208173783, backward:0.03605853332151543, data cost:0.26273164322016423 
2022-03-31 23:00:42,758: ============================================================
2022-03-31 23:00:42,758: Epoch 15/31 Batch 4500/7662 eta: 16:25:16.316142	Training Loss 0.7490 (0.7948)	Training Prec@1 8.984 (2.011)	Training Prec@5 14.453 (4.297)	
2022-03-31 23:00:42,758: ============================================================
2022-03-31 23:01:31,302: time cost, forward:0.16871762555639339, backward:0.03606846426382975, data cost:0.2626693742278867 
2022-03-31 23:01:31,302: ============================================================
2022-03-31 23:01:31,302: Epoch 15/31 Batch 4600/7662 eta: 16:56:38.422950	Training Loss 0.7455 (0.7938)	Training Prec@1 10.352 (2.167)	Training Prec@5 19.531 (4.572)	
2022-03-31 23:01:31,302: ============================================================
2022-03-31 23:02:18,007: time cost, forward:0.16895693965505149, backward:0.03606743811546272, data cost:0.2624003673568891 
2022-03-31 23:02:18,007: ============================================================
2022-03-31 23:02:18,007: Epoch 15/31 Batch 4700/7662 eta: 16:17:20.606041	Training Loss 0.7505 (0.7927)	Training Prec@1 10.547 (2.333)	Training Prec@5 17.188 (4.858)	
2022-03-31 23:02:18,008: ============================================================
2022-03-31 23:03:04,852: time cost, forward:0.16877485374829054, backward:0.036033004292549506, data cost:0.262637963814645 
2022-03-31 23:03:04,852: ============================================================
2022-03-31 23:03:04,853: Epoch 15/31 Batch 4800/7662 eta: 16:19:29.724702	Training Loss 0.7388 (0.7919)	Training Prec@1 11.914 (2.477)	Training Prec@5 19.922 (5.105)	
2022-03-31 23:03:04,853: ============================================================
2022-03-31 23:03:51,750: time cost, forward:0.1691098772863827, backward:0.03609673260036452, data cost:0.26227013265193544 
2022-03-31 23:03:51,751: ============================================================
2022-03-31 23:03:51,751: Epoch 15/31 Batch 4900/7662 eta: 16:19:49.140625	Training Loss 0.7359 (0.7908)	Training Prec@1 12.500 (2.661)	Training Prec@5 20.312 (5.406)	
2022-03-31 23:03:51,751: ============================================================
2022-03-31 23:04:38,108: time cost, forward:0.1693985343432517, backward:0.0361510547882892, data cost:0.26183884638408395 
2022-03-31 23:04:38,108: ============================================================
2022-03-31 23:04:38,108: Epoch 15/31 Batch 5000/7662 eta: 16:07:45.008479	Training Loss 0.7455 (0.7904)	Training Prec@1 9.961 (2.737)	Training Prec@5 16.602 (5.541)	
2022-03-31 23:04:38,108: ============================================================
2022-03-31 23:05:25,242: time cost, forward:0.16971101992783488, backward:0.03617198763232204, data cost:0.26157375811875905 
2022-03-31 23:05:25,242: ============================================================
2022-03-31 23:05:25,242: Epoch 15/31 Batch 5100/7662 eta: 16:23:10.515705	Training Loss 0.7379 (0.7893)	Training Prec@1 11.719 (2.937)	Training Prec@5 20.898 (5.863)	
2022-03-31 23:05:25,242: ============================================================
2022-03-31 23:06:10,384: time cost, forward:0.16963925653293652, backward:0.03618091485848402, data cost:0.26130762827536264 
2022-03-31 23:06:10,385: ============================================================
2022-03-31 23:06:10,385: Epoch 15/31 Batch 5200/7662 eta: 15:40:53.520071	Training Loss 0.7301 (0.7882)	Training Prec@1 15.820 (3.146)	Training Prec@5 25.195 (6.194)	
2022-03-31 23:06:10,385: ============================================================
2022-03-31 23:06:56,901: time cost, forward:0.16941082488817863, backward:0.036192183765426496, data cost:0.2614914041394264 
2022-03-31 23:06:56,901: ============================================================
2022-03-31 23:06:56,901: Epoch 15/31 Batch 5300/7662 eta: 16:08:44.196838	Training Loss 0.7274 (0.7871)	Training Prec@1 16.016 (3.360)	Training Prec@5 24.805 (6.530)	
2022-03-31 23:06:56,901: ============================================================
2022-03-31 23:07:42,705: time cost, forward:0.16908640887123896, backward:0.03614973253531685, data cost:0.26166682478277126 
2022-03-31 23:07:42,705: ============================================================
2022-03-31 23:07:42,705: Epoch 15/31 Batch 5400/7662 eta: 15:53:08.679631	Training Loss 0.7242 (0.7860)	Training Prec@1 16.406 (3.584)	Training Prec@5 25.781 (6.880)	
2022-03-31 23:07:42,706: ============================================================
2022-03-31 23:08:30,345: time cost, forward:0.16924875561682434, backward:0.036180560080262394, data cost:0.26165229733542195 
2022-03-31 23:08:30,346: ============================================================
2022-03-31 23:08:30,346: Epoch 15/31 Batch 5500/7662 eta: 16:30:33.971000	Training Loss 0.7265 (0.7854)	Training Prec@1 14.258 (3.725)	Training Prec@5 23.633 (7.101)	
2022-03-31 23:08:30,346: ============================================================
2022-03-31 23:09:14,810: time cost, forward:0.16884120900112723, backward:0.03617979633231145, data cost:0.2616543112790761 
2022-03-31 23:09:14,810: ============================================================
2022-03-31 23:09:14,810: Epoch 15/31 Batch 5600/7662 eta: 15:23:47.040824	Training Loss 0.7240 (0.7842)	Training Prec@1 17.188 (3.968)	Training Prec@5 26.562 (7.465)	
2022-03-31 23:09:14,810: ============================================================
2022-03-31 23:10:00,481: time cost, forward:0.16882359833022045, backward:0.036187212139624295, data cost:0.2614820213103675 
2022-03-31 23:10:00,481: ============================================================
2022-03-31 23:10:00,482: Epoch 15/31 Batch 5700/7662 eta: 15:48:05.821708	Training Loss 0.8535 (0.7833)	Training Prec@1 0.000 (4.180)	Training Prec@5 0.000 (7.782)	
2022-03-31 23:10:00,482: ============================================================
2022-03-31 23:10:49,116: time cost, forward:0.16891282680713426, backward:0.036198075628831566, data cost:0.26172336723747325 
2022-03-31 23:10:49,117: ============================================================
2022-03-31 23:10:49,117: Epoch 15/31 Batch 5800/7662 eta: 16:48:49.048867	Training Loss 0.7308 (0.7835)	Training Prec@1 16.016 (4.181)	Training Prec@5 25.195 (7.777)	
2022-03-31 23:10:49,117: ============================================================
2022-03-31 23:11:31,872: time cost, forward:0.1685871172201878, backward:0.03619364512777062, data cost:0.26138702306247885 
2022-03-31 23:11:31,872: ============================================================
2022-03-31 23:11:31,872: Epoch 15/31 Batch 5900/7662 eta: 14:46:08.785647	Training Loss 0.7163 (0.7824)	Training Prec@1 19.727 (4.413)	Training Prec@5 32.422 (8.120)	
2022-03-31 23:11:31,873: ============================================================
2022-03-31 23:12:20,930: time cost, forward:0.169004880581166, backward:0.03620598069388264, data cost:0.2612765153699526 
2022-03-31 23:12:20,931: ============================================================
2022-03-31 23:12:20,931: Epoch 15/31 Batch 6000/7662 eta: 16:55:57.839502	Training Loss 0.7126 (0.7813)	Training Prec@1 18.945 (4.670)	Training Prec@5 30.273 (8.493)	
2022-03-31 23:12:20,931: ============================================================
2022-03-31 23:13:03,952: time cost, forward:0.1685593647729336, backward:0.03616893578795336, data cost:0.2612409304743772 
2022-03-31 23:13:03,953: ============================================================
2022-03-31 23:13:03,953: Epoch 15/31 Batch 6100/7662 eta: 14:50:13.959456	Training Loss 0.7323 (0.7806)	Training Prec@1 13.867 (4.836)	Training Prec@5 24.219 (8.739)	
2022-03-31 23:13:03,953: ============================================================
2022-03-31 23:13:52,135: time cost, forward:0.16873789648987397, backward:0.036191851386217784, data cost:0.26128290333773246 
2022-03-31 23:13:52,135: ============================================================
2022-03-31 23:13:52,135: Epoch 15/31 Batch 6200/7662 eta: 16:36:12.548533	Training Loss 0.7143 (0.7803)	Training Prec@1 21.484 (4.900)	Training Prec@5 29.883 (8.838)	
2022-03-31 23:13:52,136: ============================================================
2022-03-31 23:14:37,801: time cost, forward:0.16854490698623475, backward:0.036178640570597415, data cost:0.26131462248417475 
2022-03-31 23:14:37,801: ============================================================
2022-03-31 23:14:37,801: Epoch 15/31 Batch 6300/7662 eta: 15:43:25.122892	Training Loss 0.7143 (0.7792)	Training Prec@1 18.945 (5.146)	Training Prec@5 30.469 (9.191)	
2022-03-31 23:14:37,802: ============================================================
2022-03-31 23:15:22,183: time cost, forward:0.1683099403998352, backward:0.03614344863635262, data cost:0.26125370835788475 
2022-03-31 23:15:22,183: ============================================================
2022-03-31 23:15:22,183: Epoch 15/31 Batch 6400/7662 eta: 15:16:09.228615	Training Loss 0.7236 (0.7783)	Training Prec@1 16.211 (5.356)	Training Prec@5 26.758 (9.496)	
2022-03-31 23:15:22,183: ============================================================
2022-03-31 23:16:08,913: time cost, forward:0.16827409915657002, backward:0.036141129122603616, data cost:0.2613016548001192 
2022-03-31 23:16:08,913: ============================================================
2022-03-31 23:16:08,913: Epoch 15/31 Batch 6500/7662 eta: 16:03:51.012775	Training Loss 0.7034 (0.7773)	Training Prec@1 25.586 (5.618)	Training Prec@5 37.891 (9.861)	
2022-03-31 23:16:08,914: ============================================================
2022-03-31 23:16:52,870: time cost, forward:0.16788337671100995, backward:0.03609798095103086, data cost:0.2613373883367759 
2022-03-31 23:16:52,871: ============================================================
2022-03-31 23:16:52,871: Epoch 15/31 Batch 6600/7662 eta: 15:05:55.491233	Training Loss 0.6964 (0.7762)	Training Prec@1 26.758 (5.879)	Training Prec@5 38.867 (10.225)	
2022-03-31 23:16:52,871: ============================================================
2022-03-31 23:17:40,832: time cost, forward:0.16808234533101235, backward:0.036113415143083756, data cost:0.26133687977720366 
2022-03-31 23:17:40,833: ============================================================
2022-03-31 23:17:40,833: Epoch 15/31 Batch 6700/7662 eta: 16:27:39.605684	Training Loss 0.7023 (0.7752)	Training Prec@1 24.219 (6.116)	Training Prec@5 35.156 (10.560)	
2022-03-31 23:17:40,833: ============================================================
2022-03-31 23:18:27,998: time cost, forward:0.16803210776489366, backward:0.03609500963699469, data cost:0.26148477353178623 
2022-03-31 23:18:27,999: ============================================================
2022-03-31 23:18:27,999: Epoch 15/31 Batch 6800/7662 eta: 16:10:29.110409	Training Loss 0.7035 (0.7741)	Training Prec@1 22.656 (6.395)	Training Prec@5 33.789 (10.937)	
2022-03-31 23:18:27,999: ============================================================
2022-03-31 23:19:14,016: time cost, forward:0.1678220898815818, backward:0.03609747612954983, data cost:0.2616076825718756 
2022-03-31 23:19:14,017: ============================================================
2022-03-31 23:19:14,017: Epoch 15/31 Batch 6900/7662 eta: 15:46:05.047316	Training Loss 0.6963 (0.7730)	Training Prec@1 25.000 (6.675)	Training Prec@5 35.742 (11.316)	
2022-03-31 23:19:14,017: ============================================================
2022-03-31 23:19:58,393: time cost, forward:0.16761548516749994, backward:0.036076234159920624, data cost:0.26151707142076247 
2022-03-31 23:19:58,394: ============================================================
2022-03-31 23:19:58,394: Epoch 15/31 Batch 7000/7662 eta: 15:11:37.159157	Training Loss 0.7015 (0.7720)	Training Prec@1 25.781 (6.935)	Training Prec@5 35.742 (11.670)	
2022-03-31 23:19:58,394: ============================================================
2022-03-31 23:20:46,428: time cost, forward:0.1676764079493055, backward:0.036061181234866735, data cost:0.26165985080419685 
2022-03-31 23:20:46,429: ============================================================
2022-03-31 23:20:46,429: Epoch 15/31 Batch 7100/7662 eta: 16:25:57.357837	Training Loss 0.6967 (0.7709)	Training Prec@1 27.539 (7.215)	Training Prec@5 38.672 (12.046)	
2022-03-31 23:20:46,429: ============================================================
2022-03-31 23:21:31,321: time cost, forward:0.16756418490181335, backward:0.03604059680366967, data cost:0.26157754920459253 
2022-03-31 23:21:31,321: ============================================================
2022-03-31 23:21:31,322: Epoch 15/31 Batch 7200/7662 eta: 15:20:42.514190	Training Loss 0.7548 (0.7704)	Training Prec@1 9.766 (7.386)	Training Prec@5 17.383 (12.274)	
2022-03-31 23:21:31,322: ============================================================
2022-03-31 23:22:17,175: time cost, forward:0.1674020198260714, backward:0.036039676449367126, data cost:0.2616536090073152 
2022-03-31 23:22:17,176: ============================================================
2022-03-31 23:22:17,176: Epoch 15/31 Batch 7300/7662 eta: 15:39:40.368590	Training Loss 0.6904 (0.7694)	Training Prec@1 27.930 (7.630)	Training Prec@5 42.773 (12.602)	
2022-03-31 23:22:17,176: ============================================================
2022-03-31 23:23:02,379: time cost, forward:0.1673142825256958, backward:0.036037769168111855, data cost:0.26155475620192953 
2022-03-31 23:23:02,379: ============================================================
2022-03-31 23:23:02,380: Epoch 15/31 Batch 7400/7662 eta: 15:25:34.884158	Training Loss 0.6819 (0.7683)	Training Prec@1 31.055 (7.907)	Training Prec@5 41.016 (12.965)	
2022-03-31 23:23:02,380: ============================================================
2022-03-31 23:23:50,729: time cost, forward:0.1676564234735998, backward:0.03605722811940925, data cost:0.26144451636571153 
2022-03-31 23:23:50,730: ============================================================
2022-03-31 23:23:50,730: Epoch 15/31 Batch 7500/7662 eta: 16:29:12.259252	Training Loss 0.6910 (0.7672)	Training Prec@1 27.539 (8.187)	Training Prec@5 40.234 (13.330)	
2022-03-31 23:23:50,730: ============================================================
2022-03-31 23:24:36,913: time cost, forward:0.1676272762372378, backward:0.036028194120015296, data cost:0.26145411598194523 
2022-03-31 23:24:36,913: ============================================================
2022-03-31 23:24:36,913: Epoch 15/31 Batch 7600/7662 eta: 15:44:06.461765	Training Loss 0.6841 (0.7662)	Training Prec@1 28.711 (8.470)	Training Prec@5 42.969 (13.696)	
2022-03-31 23:24:36,914: ============================================================
2022-03-31 23:25:08,546: Epoch: 15/31 eta: 15:43:37.366114	Training Loss 0.6918 (0.7655)	Training Prec@1 24.805 (8.647)	Training Prec@5 39.258 (13.925)
2022-03-31 23:25:08,546: ============================================================
2022-03-31 23:25:08,665: Save Checkpoint...
2022-03-31 23:25:08,666: ============================================================
2022-03-31 23:25:11,240: Save done!
2022-03-31 23:25:11,240: ============================================================
2022-03-31 23:25:54,635: time cost, forward:0.1471003113370953, backward:0.03532786802812056, data cost:0.25271723487160425 
2022-03-31 23:25:54,635: ============================================================
2022-03-31 23:25:54,635: Epoch 16/31 Batch 100/7662 eta: 14:45:00.706622	Training Loss 0.6759 (0.6735)	Training Prec@1 33.203 (33.925)	Training Prec@5 45.703 (46.021)	
2022-03-31 23:25:54,636: ============================================================
2022-03-31 23:26:39,785: time cost, forward:0.14767132092959917, backward:0.03511556069455554, data cost:0.25976739696521856 
2022-03-31 23:26:39,786: ============================================================
2022-03-31 23:26:39,786: Epoch 16/31 Batch 200/7662 eta: 15:21:00.936273	Training Loss 0.6744 (0.6737)	Training Prec@1 33.789 (34.018)	Training Prec@5 43.555 (46.095)	
2022-03-31 23:26:39,786: ============================================================
2022-03-31 23:27:20,391: time cost, forward:0.1343647277474802, backward:0.03416517586213689, data cost:0.26166611610846374 
2022-03-31 23:27:20,392: ============================================================
2022-03-31 23:27:20,392: Epoch 16/31 Batch 300/7662 eta: 13:47:38.414475	Training Loss 0.6733 (0.6737)	Training Prec@1 36.133 (34.044)	Training Prec@5 48.438 (46.121)	
2022-03-31 23:27:20,392: ============================================================
2022-03-31 23:28:03,526: time cost, forward:0.13379390018625667, backward:0.03409148756423989, data cost:0.26268784563642994 
2022-03-31 23:28:03,527: ============================================================
2022-03-31 23:28:03,527: Epoch 16/31 Batch 400/7662 eta: 14:38:28.012592	Training Loss 0.6739 (0.6734)	Training Prec@1 35.352 (34.165)	Training Prec@5 46.094 (46.227)	
2022-03-31 23:28:03,527: ============================================================
2022-03-31 23:28:50,146: time cost, forward:0.139783532442693, backward:0.03435192509500202, data cost:0.26335392686312564 
2022-03-31 23:28:50,146: ============================================================
2022-03-31 23:28:50,147: Epoch 16/31 Batch 500/7662 eta: 15:48:39.239771	Training Loss 0.6688 (0.6730)	Training Prec@1 32.422 (34.256)	Training Prec@5 48.633 (46.295)	
2022-03-31 23:28:50,147: ============================================================
2022-03-31 23:29:33,203: time cost, forward:0.13906496514462072, backward:0.034321038273220666, data cost:0.26302977515779474 
2022-03-31 23:29:33,204: ============================================================
2022-03-31 23:29:33,204: Epoch 16/31 Batch 600/7662 eta: 14:35:27.170738	Training Loss 0.6749 (0.6745)	Training Prec@1 32.812 (33.859)	Training Prec@5 44.922 (45.841)	
2022-03-31 23:29:33,204: ============================================================
2022-03-31 23:30:19,205: time cost, forward:0.14081943359156707, backward:0.033877840710641316, data cost:0.26481608362156944 
2022-03-31 23:30:19,205: ============================================================
2022-03-31 23:30:19,206: Epoch 16/31 Batch 700/7662 eta: 15:34:32.799197	Training Loss 0.6728 (0.6740)	Training Prec@1 34.375 (33.970)	Training Prec@5 46.289 (45.939)	
2022-03-31 23:30:19,206: ============================================================
2022-03-31 23:31:02,453: time cost, forward:0.140387768142662, backward:0.03382818928648145, data cost:0.2644339124013545 
2022-03-31 23:31:02,453: ============================================================
2022-03-31 23:31:02,453: Epoch 16/31 Batch 800/7662 eta: 14:37:52.569019	Training Loss 0.6720 (0.6738)	Training Prec@1 32.812 (34.011)	Training Prec@5 43.750 (46.009)	
2022-03-31 23:31:02,454: ============================================================
2022-03-31 23:31:45,858: time cost, forward:0.14152854966109535, backward:0.03408116758599032, data cost:0.26250844590523353 
2022-03-31 23:31:45,859: ============================================================
2022-03-31 23:31:45,859: Epoch 16/31 Batch 900/7662 eta: 14:40:21.549911	Training Loss 0.6804 (0.6734)	Training Prec@1 31.641 (34.115)	Training Prec@5 43.555 (46.091)	
2022-03-31 23:31:45,859: ============================================================
2022-03-31 23:32:31,555: time cost, forward:0.14217130486313645, backward:0.0341620748346155, data cost:0.2636125710633424 
2022-03-31 23:32:31,566: ============================================================
2022-03-31 23:32:31,566: Epoch 16/31 Batch 1000/7662 eta: 15:26:16.329314	Training Loss 0.8428 (0.6804)	Training Prec@1 0.000 (32.830)	Training Prec@5 0.000 (44.357)	
2022-03-31 23:32:31,566: ============================================================
2022-03-31 23:33:15,434: time cost, forward:0.14103264956174924, backward:0.0340872507294923, data cost:0.2647318668643163 
2022-03-31 23:33:15,435: ============================================================
2022-03-31 23:33:15,435: Epoch 16/31 Batch 1100/7662 eta: 14:48:18.143866	Training Loss 0.8209 (0.6940)	Training Prec@1 0.000 (29.845)	Training Prec@5 0.000 (40.330)	
2022-03-31 23:33:15,435: ============================================================
2022-03-31 23:34:00,302: time cost, forward:0.14281823935361582, backward:0.03428393587457627, data cost:0.2633951444045219 
2022-03-31 23:34:00,315: ============================================================
2022-03-31 23:34:00,315: Epoch 16/31 Batch 1200/7662 eta: 15:08:00.787238	Training Loss 0.7860 (0.7037)	Training Prec@1 3.711 (27.393)	Training Prec@5 6.641 (37.061)	
2022-03-31 23:34:00,315: ============================================================
2022-03-31 23:34:43,593: time cost, forward:0.1420135077740065, backward:0.034389362415962715, data cost:0.2634988207372911 
2022-03-31 23:34:43,594: ============================================================
2022-03-31 23:34:43,594: Epoch 16/31 Batch 1300/7662 eta: 14:34:54.343735	Training Loss 0.8259 (0.7122)	Training Prec@1 0.000 (25.421)	Training Prec@5 0.195 (34.456)	
2022-03-31 23:34:43,594: ============================================================
2022-03-31 23:35:31,509: time cost, forward:0.1452817023865575, backward:0.03478655481099912, data cost:0.26257803714471345 
2022-03-31 23:35:31,510: ============================================================
2022-03-31 23:35:31,510: Epoch 16/31 Batch 1400/7662 eta: 16:07:50.690383	Training Loss 0.8219 (0.7202)	Training Prec@1 0.000 (23.605)	Training Prec@5 0.000 (31.999)	
2022-03-31 23:35:31,510: ============================================================
2022-03-31 23:36:15,186: time cost, forward:0.1449378211153118, backward:0.03483456401048778, data cost:0.2624759977861116 
2022-03-31 23:36:15,186: ============================================================
2022-03-31 23:36:15,187: Epoch 16/31 Batch 1500/7662 eta: 14:41:29.634052	Training Loss 0.8186 (0.7269)	Training Prec@1 0.000 (22.033)	Training Prec@5 0.000 (29.874)	
2022-03-31 23:36:15,187: ============================================================
2022-03-31 23:36:59,625: time cost, forward:0.1454788342798554, backward:0.035021709456452735, data cost:0.2618401940723298 
2022-03-31 23:36:59,625: ============================================================
2022-03-31 23:36:59,625: Epoch 16/31 Batch 1600/7662 eta: 14:56:07.909518	Training Loss 0.8144 (0.7324)	Training Prec@1 0.000 (20.658)	Training Prec@5 0.391 (28.022)	
2022-03-31 23:36:59,626: ============================================================
2022-03-31 23:37:43,982: time cost, forward:0.14604046304061738, backward:0.03504067789182164, data cost:0.2613361886559408 
2022-03-31 23:37:43,983: ============================================================
2022-03-31 23:37:43,983: Epoch 16/31 Batch 1700/7662 eta: 14:53:45.307412	Training Loss 0.8012 (0.7368)	Training Prec@1 0.195 (19.457)	Training Prec@5 0.781 (26.418)	
2022-03-31 23:37:43,983: ============================================================
2022-03-31 23:38:26,289: time cost, forward:0.14432440975628144, backward:0.035004265246091786, data cost:0.26196777323605686 
2022-03-31 23:38:26,290: ============================================================
2022-03-31 23:38:26,291: Epoch 16/31 Batch 1800/7662 eta: 14:11:44.203144	Training Loss 0.8404 (0.7396)	Training Prec@1 0.000 (18.569)	Training Prec@5 0.000 (25.326)	
2022-03-31 23:38:26,291: ============================================================
2022-03-31 23:39:12,028: time cost, forward:0.1451499782279016, backward:0.035038465321095384, data cost:0.26189081125224245 
2022-03-31 23:39:12,029: ============================================================
2022-03-31 23:39:12,029: Epoch 16/31 Batch 1900/7662 eta: 15:20:03.626053	Training Loss 0.8312 (0.7446)	Training Prec@1 0.000 (17.591)	Training Prec@5 0.000 (23.994)	
2022-03-31 23:39:12,029: ============================================================
2022-03-31 23:39:58,311: time cost, forward:0.14578197549855249, backward:0.03511852989082279, data cost:0.2622511592013887 
2022-03-31 23:39:58,311: ============================================================
2022-03-31 23:39:58,312: Epoch 16/31 Batch 2000/7662 eta: 15:30:13.269524	Training Loss 0.8299 (0.7489)	Training Prec@1 0.000 (16.712)	Training Prec@5 0.000 (22.794)	
2022-03-31 23:39:58,312: ============================================================
2022-03-31 23:40:39,471: time cost, forward:0.14462530516396824, backward:0.03499886000252951, data cost:0.26196328976882416 
2022-03-31 23:40:39,471: ============================================================
2022-03-31 23:40:39,471: Epoch 16/31 Batch 2100/7662 eta: 13:46:34.647713	Training Loss 0.8290 (0.7528)	Training Prec@1 0.000 (15.916)	Training Prec@5 0.000 (21.710)	
2022-03-31 23:40:39,472: ============================================================
2022-03-31 23:41:22,722: time cost, forward:0.14371177140774105, backward:0.034944032852950016, data cost:0.2625004803933789 
2022-03-31 23:41:22,723: ============================================================
2022-03-31 23:41:22,723: Epoch 16/31 Batch 2200/7662 eta: 14:27:51.738940	Training Loss 0.8292 (0.7562)	Training Prec@1 0.000 (15.193)	Training Prec@5 0.000 (20.724)	
2022-03-31 23:41:22,723: ============================================================
2022-03-31 23:42:08,358: time cost, forward:0.14391870403248314, backward:0.03501527990761815, data cost:0.26291603272559594 
2022-03-31 23:42:08,359: ============================================================
2022-03-31 23:42:08,359: Epoch 16/31 Batch 2300/7662 eta: 15:14:57.026954	Training Loss 0.8266 (0.7593)	Training Prec@1 0.000 (14.532)	Training Prec@5 0.000 (19.824)	
2022-03-31 23:42:08,359: ============================================================
2022-03-31 23:42:53,244: time cost, forward:0.1448344226279026, backward:0.035132357556405494, data cost:0.26214936834019686 
2022-03-31 23:42:53,245: ============================================================
2022-03-31 23:42:53,245: Epoch 16/31 Batch 2400/7662 eta: 14:59:09.927026	Training Loss 0.8229 (0.7620)	Training Prec@1 0.000 (13.927)	Training Prec@5 0.000 (19.001)	
2022-03-31 23:42:53,245: ============================================================
2022-03-31 23:43:37,030: time cost, forward:0.14503312521144932, backward:0.03520199097171217, data cost:0.261680253652059 
2022-03-31 23:43:37,030: ============================================================
2022-03-31 23:43:37,030: Epoch 16/31 Batch 2500/7662 eta: 14:36:23.080349	Training Loss 0.8119 (0.7642)	Training Prec@1 0.000 (13.374)	Training Prec@5 0.781 (18.252)	
2022-03-31 23:43:37,030: ============================================================
2022-03-31 23:44:22,187: time cost, forward:0.14487514261008685, backward:0.03520854494579942, data cost:0.2621946634811454 
2022-03-31 23:44:22,188: ============================================================
2022-03-31 23:44:22,188: Epoch 16/31 Batch 2600/7662 eta: 15:03:06.144263	Training Loss 0.7606 (0.7651)	Training Prec@1 9.375 (12.970)	Training Prec@5 16.016 (17.779)	
2022-03-31 23:44:22,189: ============================================================
2022-03-31 23:45:05,462: time cost, forward:0.14455540942545067, backward:0.035241907726795245, data cost:0.2621176864713066 
2022-03-31 23:45:05,463: ============================================================
2022-03-31 23:45:05,463: Epoch 16/31 Batch 2700/7662 eta: 14:24:43.308256	Training Loss 0.8060 (0.7657)	Training Prec@1 0.195 (12.718)	Training Prec@5 0.391 (17.529)	
2022-03-31 23:45:05,463: ============================================================
2022-03-31 23:45:48,024: time cost, forward:0.14425013992947397, backward:0.03524183230384753, data cost:0.2617389334657866 
2022-03-31 23:45:48,025: ============================================================
2022-03-31 23:45:48,025: Epoch 16/31 Batch 2800/7662 eta: 14:09:46.605161	Training Loss 0.7134 (0.7654)	Training Prec@1 19.531 (12.589)	Training Prec@5 29.883 (17.442)	
2022-03-31 23:45:48,025: ============================================================
2022-03-31 23:46:31,199: time cost, forward:0.14423863432990472, backward:0.03525793490717435, data cost:0.2614340718017031 
2022-03-31 23:46:31,199: ============================================================
2022-03-31 23:46:31,200: Epoch 16/31 Batch 2900/7662 eta: 14:21:16.842571	Training Loss 0.7009 (0.7633)	Training Prec@1 26.562 (12.993)	Training Prec@5 37.695 (18.058)	
2022-03-31 23:46:31,200: ============================================================
2022-03-31 23:47:13,797: time cost, forward:0.1440919232630817, backward:0.03526117897860485, data cost:0.26111177978375705 
2022-03-31 23:47:13,797: ============================================================
2022-03-31 23:47:13,798: Epoch 16/31 Batch 3000/7662 eta: 14:09:04.402696	Training Loss 0.6907 (0.7609)	Training Prec@1 31.250 (13.499)	Training Prec@5 42.383 (18.773)	
2022-03-31 23:47:13,798: ============================================================
2022-03-31 23:47:54,008: time cost, forward:0.14337240322515557, backward:0.03519343960550609, data cost:0.2606228042625927 
2022-03-31 23:47:54,008: ============================================================
2022-03-31 23:47:54,009: Epoch 16/31 Batch 3100/7662 eta: 13:20:49.429332	Training Loss 0.6827 (0.7585)	Training Prec@1 30.664 (14.018)	Training Prec@5 42.969 (19.490)	
2022-03-31 23:47:54,009: ============================================================
2022-03-31 23:48:35,769: time cost, forward:0.1428575719211503, backward:0.0351651495193906, data cost:0.26048775880401603 
2022-03-31 23:48:35,769: ============================================================
2022-03-31 23:48:35,770: Epoch 16/31 Batch 3200/7662 eta: 13:50:59.404343	Training Loss 0.6826 (0.7562)	Training Prec@1 30.664 (14.536)	Training Prec@5 42.578 (20.200)	
2022-03-31 23:48:35,770: ============================================================
2022-03-31 23:49:18,225: time cost, forward:0.1424008249044057, backward:0.03513622291162542, data cost:0.2605470607193285 
2022-03-31 23:49:18,225: ============================================================
2022-03-31 23:49:18,225: Epoch 16/31 Batch 3300/7662 eta: 14:04:06.630609	Training Loss 0.6846 (0.7539)	Training Prec@1 30.664 (15.042)	Training Prec@5 41.211 (20.890)	
2022-03-31 23:49:18,225: ============================================================
2022-03-31 23:50:02,556: time cost, forward:0.14194836718925977, backward:0.03507531576557838, data cost:0.2611955134578928 
2022-03-31 23:50:02,556: ============================================================
2022-03-31 23:50:02,556: Epoch 16/31 Batch 3400/7662 eta: 14:40:39.668607	Training Loss 0.7273 (0.7524)	Training Prec@1 16.211 (15.405)	Training Prec@5 26.172 (21.400)	
2022-03-31 23:50:02,557: ============================================================
2022-03-31 23:50:45,233: time cost, forward:0.14173700278675463, backward:0.03502298559792282, data cost:0.26106677323826794 
2022-03-31 23:50:45,233: ============================================================
2022-03-31 23:50:45,234: Epoch 16/31 Batch 3500/7662 eta: 14:07:05.562149	Training Loss 0.6808 (0.7505)	Training Prec@1 31.055 (15.844)	Training Prec@5 42.773 (21.999)	
2022-03-31 23:50:45,234: ============================================================
2022-03-31 23:51:29,049: time cost, forward:0.14142820277986476, backward:0.035038986282899795, data cost:0.26142246976896405 
2022-03-31 23:51:29,050: ============================================================
2022-03-31 23:51:29,050: Epoch 16/31 Batch 3600/7662 eta: 14:28:58.419408	Training Loss 0.6827 (0.7484)	Training Prec@1 31.250 (16.316)	Training Prec@5 39.844 (22.618)	
2022-03-31 23:51:29,050: ============================================================
2022-03-31 23:52:12,362: time cost, forward:0.14199949657958919, backward:0.0350911800330895, data cost:0.2606648645970782 
2022-03-31 23:52:12,362: ============================================================
2022-03-31 23:52:12,362: Epoch 16/31 Batch 3700/7662 eta: 14:18:15.441618	Training Loss 0.6656 (0.7464)	Training Prec@1 34.961 (16.777)	Training Prec@5 48.047 (23.217)	
2022-03-31 23:52:12,363: ============================================================
2022-03-31 23:52:55,523: time cost, forward:0.1420860746779797, backward:0.034968923223304194, data cost:0.26053333113023436 
2022-03-31 23:52:55,524: ============================================================
2022-03-31 23:52:55,524: Epoch 16/31 Batch 3800/7662 eta: 14:14:32.983696	Training Loss 0.6789 (0.7446)	Training Prec@1 31.445 (17.208)	Training Prec@5 44.531 (23.778)	
2022-03-31 23:52:55,524: ============================================================
2022-03-31 23:53:36,874: time cost, forward:0.141609356690138, backward:0.03494411451628832, data cost:0.26037218137165313 
2022-03-31 23:53:36,874: ============================================================
2022-03-31 23:53:36,874: Epoch 16/31 Batch 3900/7662 eta: 13:37:59.904309	Training Loss 0.6684 (0.7427)	Training Prec@1 34.375 (17.636)	Training Prec@5 46.484 (24.331)	
2022-03-31 23:53:36,875: ============================================================
2022-03-31 23:54:18,778: time cost, forward:0.14114931965804334, backward:0.03503452452697525, data cost:0.2603098937170778 
2022-03-31 23:54:18,778: ============================================================
2022-03-31 23:54:18,778: Epoch 16/31 Batch 4000/7662 eta: 13:48:15.066571	Training Loss 0.6751 (0.7410)	Training Prec@1 30.469 (18.044)	Training Prec@5 43.555 (24.860)	
2022-03-31 23:54:18,778: ============================================================
2022-03-31 23:55:01,483: time cost, forward:0.14072677710487308, backward:0.035035059259530536, data cost:0.2604932649509591 
2022-03-31 23:55:01,484: ============================================================
2022-03-31 23:55:01,484: Epoch 16/31 Batch 4100/7662 eta: 14:03:23.302863	Training Loss 0.6695 (0.7393)	Training Prec@1 34.961 (18.436)	Training Prec@5 49.023 (25.369)	
2022-03-31 23:55:01,484: ============================================================
2022-03-31 23:55:42,284: time cost, forward:0.14032466424649942, backward:0.03498101183334173, data cost:0.2602721973100314 
2022-03-31 23:55:42,285: ============================================================
2022-03-31 23:55:42,285: Epoch 16/31 Batch 4200/7662 eta: 13:25:05.482060	Training Loss 0.6755 (0.7377)	Training Prec@1 33.203 (18.809)	Training Prec@5 45.703 (25.854)	
2022-03-31 23:55:42,285: ============================================================
2022-03-31 23:56:25,995: time cost, forward:0.14048148471550986, backward:0.034949561112646334, data cost:0.2601674799310188 
2022-03-31 23:56:25,995: ============================================================
2022-03-31 23:56:25,996: Epoch 16/31 Batch 4300/7662 eta: 14:21:46.775951	Training Loss 0.6669 (0.7361)	Training Prec@1 35.352 (19.179)	Training Prec@5 45.117 (26.323)	
2022-03-31 23:56:25,996: ============================================================
2022-03-31 23:57:07,072: time cost, forward:0.14009332754417397, backward:0.03492332133522736, data cost:0.26001441405561465 
2022-03-31 23:57:07,073: ============================================================
2022-03-31 23:57:07,073: Epoch 16/31 Batch 4400/7662 eta: 13:29:10.363367	Training Loss 0.6641 (0.7346)	Training Prec@1 36.133 (19.547)	Training Prec@5 48.633 (26.790)	
2022-03-31 23:57:07,073: ============================================================
2022-03-31 23:57:49,149: time cost, forward:0.13950702348638308, backward:0.03485816604536251, data cost:0.26032834292571 
2022-03-31 23:57:49,150: ============================================================
2022-03-31 23:57:49,150: Epoch 16/31 Batch 4500/7662 eta: 13:48:10.199002	Training Loss 0.6598 (0.7331)	Training Prec@1 39.453 (19.899)	Training Prec@5 49.219 (27.241)	
2022-03-31 23:57:49,150: ============================================================
2022-03-31 23:58:34,021: time cost, forward:0.13986844476292148, backward:0.034878456429259415, data cost:0.2602486357945 
2022-03-31 23:58:34,021: ============================================================
2022-03-31 23:58:34,022: Epoch 16/31 Batch 4600/7662 eta: 14:42:25.443377	Training Loss 0.6620 (0.7317)	Training Prec@1 36.719 (20.241)	Training Prec@5 48.438 (27.671)	
2022-03-31 23:58:34,022: ============================================================
2022-03-31 23:59:16,249: time cost, forward:0.13979261929645365, backward:0.03489610793159779, data cost:0.26002472602298704 
2022-03-31 23:59:16,249: ============================================================
2022-03-31 23:59:16,249: Epoch 16/31 Batch 4700/7662 eta: 13:49:43.507415	Training Loss 0.6559 (0.7304)	Training Prec@1 37.109 (20.571)	Training Prec@5 53.125 (28.090)	
2022-03-31 23:59:16,250: ============================================================
2022-03-31 23:59:58,662: time cost, forward:0.13950516860120915, backward:0.0348689751367714, data cost:0.2601125873260434 
2022-03-31 23:59:58,662: ============================================================
2022-03-31 23:59:58,663: Epoch 16/31 Batch 4800/7662 eta: 13:52:39.722145	Training Loss 0.6624 (0.7291)	Training Prec@1 37.500 (20.883)	Training Prec@5 50.977 (28.486)	
2022-03-31 23:59:58,663: ============================================================
2022-04-01 00:00:44,239: time cost, forward:0.13989167934681693, backward:0.03491091655210272, data cost:0.2601153418881038 
2022-04-01 00:00:44,239: ============================================================
2022-04-01 00:00:44,240: Epoch 16/31 Batch 4900/7662 eta: 14:54:01.020431	Training Loss 0.6677 (0.7278)	Training Prec@1 34.961 (21.196)	Training Prec@5 46.680 (28.878)	
2022-04-01 00:00:44,240: ============================================================
2022-04-01 00:01:28,988: time cost, forward:0.13983322592062053, backward:0.03490781731595037, data cost:0.2604283626424382 
2022-04-01 00:01:28,988: ============================================================
2022-04-01 00:01:28,988: Epoch 16/31 Batch 5000/7662 eta: 14:37:01.215598	Training Loss 0.6686 (0.7265)	Training Prec@1 34.766 (21.506)	Training Prec@5 44.727 (29.261)	
2022-04-01 00:01:28,989: ============================================================
2022-04-01 00:02:12,179: time cost, forward:0.1400291123421058, backward:0.034929803877069475, data cost:0.260136400865419 
2022-04-01 00:02:12,179: ============================================================
2022-04-01 00:02:12,179: Epoch 16/31 Batch 5100/7662 eta: 14:05:46.579211	Training Loss 0.6721 (0.7253)	Training Prec@1 33.008 (21.800)	Training Prec@5 47.266 (29.629)	
2022-04-01 00:02:12,180: ============================================================
2022-04-01 00:02:54,639: time cost, forward:0.14008715845663103, backward:0.034921688904187204, data cost:0.25987767833864533 
2022-04-01 00:02:54,639: ============================================================
2022-04-01 00:02:54,640: Epoch 16/31 Batch 5200/7662 eta: 13:50:45.411546	Training Loss 0.6646 (0.7242)	Training Prec@1 37.305 (22.085)	Training Prec@5 49.609 (29.985)	
2022-04-01 00:02:54,640: ============================================================
2022-04-01 00:03:38,831: time cost, forward:0.14017201522809872, backward:0.034903020673392966, data cost:0.25993744164823385 
2022-04-01 00:03:38,832: ============================================================
2022-04-01 00:03:38,832: Epoch 16/31 Batch 5300/7662 eta: 14:23:54.643442	Training Loss 0.6665 (0.7230)	Training Prec@1 36.914 (22.370)	Training Prec@5 47.852 (30.339)	
2022-04-01 00:03:38,832: ============================================================
2022-04-01 00:04:22,720: time cost, forward:0.14055204197176518, backward:0.034846770584550164, data cost:0.25967441450381507 
2022-04-01 00:04:22,720: ============================================================
2022-04-01 00:04:22,720: Epoch 16/31 Batch 5400/7662 eta: 14:17:13.921749	Training Loss 0.6704 (0.7219)	Training Prec@1 34.766 (22.640)	Training Prec@5 44.336 (30.673)	
2022-04-01 00:04:22,721: ============================================================
2022-04-01 00:05:05,160: time cost, forward:0.14032347043181878, backward:0.034783286600898536, data cost:0.25976551890611693 
2022-04-01 00:05:05,161: ============================================================
2022-04-01 00:05:05,161: Epoch 16/31 Batch 5500/7662 eta: 13:48:15.176295	Training Loss 0.6646 (0.7208)	Training Prec@1 39.062 (22.906)	Training Prec@5 50.000 (31.001)	
2022-04-01 00:05:05,161: ============================================================
2022-04-01 00:05:49,028: time cost, forward:0.14061334278354007, backward:0.0347884544454998, data cost:0.25949008278728364 
2022-04-01 00:05:49,029: ============================================================
2022-04-01 00:05:49,029: Epoch 16/31 Batch 5600/7662 eta: 14:15:22.048561	Training Loss 0.6577 (0.7198)	Training Prec@1 37.109 (23.173)	Training Prec@5 52.734 (31.328)	
2022-04-01 00:05:49,029: ============================================================
2022-04-01 00:06:33,606: time cost, forward:0.14074204047116548, backward:0.034791291774542925, data cost:0.2595905383274542 
2022-04-01 00:06:33,607: ============================================================
2022-04-01 00:06:33,607: Epoch 16/31 Batch 5700/7662 eta: 14:28:28.646901	Training Loss 0.6547 (0.7187)	Training Prec@1 40.430 (23.431)	Training Prec@5 50.781 (31.643)	
2022-04-01 00:06:33,607: ============================================================
2022-04-01 00:07:17,227: time cost, forward:0.14066551023155352, backward:0.03475782562482149, data cost:0.25970375206906704 
2022-04-01 00:07:17,227: ============================================================
2022-04-01 00:07:17,228: Epoch 16/31 Batch 5800/7662 eta: 14:09:06.320257	Training Loss 0.6644 (0.7178)	Training Prec@1 36.914 (23.674)	Training Prec@5 48.242 (31.945)	
2022-04-01 00:07:17,229: ============================================================
2022-04-01 00:08:02,275: time cost, forward:0.14117765099259832, backward:0.03475885392043687, data cost:0.25945072069796976 
2022-04-01 00:08:02,275: ============================================================
2022-04-01 00:08:02,275: Epoch 16/31 Batch 5900/7662 eta: 14:36:07.307153	Training Loss 0.6617 (0.7168)	Training Prec@1 36.914 (23.921)	Training Prec@5 47.461 (32.246)	
2022-04-01 00:08:02,276: ============================================================
2022-04-01 00:08:47,924: time cost, forward:0.1414230555807636, backward:0.03479961948328007, data cost:0.25951828231690705 
2022-04-01 00:08:47,924: ============================================================
2022-04-01 00:08:47,924: Epoch 16/31 Batch 6000/7662 eta: 14:47:03.309989	Training Loss 0.6582 (0.7158)	Training Prec@1 38.672 (24.160)	Training Prec@5 50.391 (32.536)	
2022-04-01 00:08:47,924: ============================================================
2022-04-01 00:09:30,748: time cost, forward:0.14156979516913293, backward:0.03480413312266197, data cost:0.2592325398210112 
2022-04-01 00:09:30,749: ============================================================
2022-04-01 00:09:30,750: Epoch 16/31 Batch 6100/7662 eta: 13:51:28.590022	Training Loss 0.6600 (0.7149)	Training Prec@1 36.523 (24.397)	Training Prec@5 50.391 (32.823)	
2022-04-01 00:09:30,750: ============================================================
2022-04-01 00:10:15,064: time cost, forward:0.14197750744617338, backward:0.034881099229244324, data cost:0.25885232588344476 
2022-04-01 00:10:15,065: ============================================================
2022-04-01 00:10:15,065: Epoch 16/31 Batch 6200/7662 eta: 14:19:40.260098	Training Loss 0.6534 (0.7140)	Training Prec@1 40.039 (24.630)	Training Prec@5 51.953 (33.107)	
2022-04-01 00:10:15,066: ============================================================
2022-04-01 00:10:59,352: time cost, forward:0.1421225093285003, backward:0.034908522573950405, data cost:0.25880377749485295 
2022-04-01 00:10:59,352: ============================================================
2022-04-01 00:10:59,353: Epoch 16/31 Batch 6300/7662 eta: 14:18:22.970028	Training Loss 0.6533 (0.7131)	Training Prec@1 42.188 (24.859)	Training Prec@5 51.172 (33.377)	
2022-04-01 00:10:59,353: ============================================================
2022-04-01 00:11:43,050: time cost, forward:0.14223811480752713, backward:0.034942546213468664, data cost:0.2586635428120297 
2022-04-01 00:11:43,051: ============================================================
2022-04-01 00:11:43,051: Epoch 16/31 Batch 6400/7662 eta: 14:06:14.300484	Training Loss 0.6617 (0.7122)	Training Prec@1 36.719 (25.076)	Training Prec@5 49.414 (33.642)	
2022-04-01 00:11:43,051: ============================================================
2022-04-01 00:12:27,739: time cost, forward:0.1424376289190412, backward:0.03493624214833288, data cost:0.25862387353263466 
2022-04-01 00:12:27,740: ============================================================
2022-04-01 00:12:27,740: Epoch 16/31 Batch 6500/7662 eta: 14:24:40.766045	Training Loss 0.6704 (0.7114)	Training Prec@1 36.719 (25.296)	Training Prec@5 48.242 (33.904)	
2022-04-01 00:12:27,740: ============================================================
2022-04-01 00:13:12,326: time cost, forward:0.14226325549290278, backward:0.034926711691023814, data cost:0.25895407435062673 
2022-04-01 00:13:12,326: ============================================================
2022-04-01 00:13:12,327: Epoch 16/31 Batch 6600/7662 eta: 14:21:57.468587	Training Loss 0.6517 (0.7105)	Training Prec@1 39.453 (25.509)	Training Prec@5 52.148 (34.159)	
2022-04-01 00:13:12,327: ============================================================
2022-04-01 00:13:54,918: time cost, forward:0.14207705815775498, backward:0.0349088791751705, data cost:0.25900194797609827 
2022-04-01 00:13:54,919: ============================================================
2022-04-01 00:13:54,919: Epoch 16/31 Batch 6700/7662 eta: 13:42:41.560206	Training Loss 0.6587 (0.7097)	Training Prec@1 40.039 (25.716)	Training Prec@5 49.609 (34.407)	
2022-04-01 00:13:54,919: ============================================================
2022-04-01 00:14:39,513: time cost, forward:0.14237517566431232, backward:0.034919822228307286, data cost:0.2588314155845681 
2022-04-01 00:14:39,513: ============================================================
2022-04-01 00:14:39,513: Epoch 16/31 Batch 6800/7662 eta: 14:20:37.139124	Training Loss 0.6416 (0.7089)	Training Prec@1 44.922 (25.930)	Training Prec@5 55.664 (34.660)	
2022-04-01 00:14:39,513: ============================================================
2022-04-01 00:15:22,325: time cost, forward:0.1423497089770829, backward:0.034897159227237684, data cost:0.2587594142390742 
2022-04-01 00:15:22,325: ============================================================
2022-04-01 00:15:22,326: Epoch 16/31 Batch 6900/7662 eta: 13:45:30.799446	Training Loss 0.6556 (0.7081)	Training Prec@1 39.258 (26.130)	Training Prec@5 53.320 (34.898)	
2022-04-01 00:15:22,326: ============================================================
2022-04-01 00:16:08,868: time cost, forward:0.14274557043201738, backward:0.03492790022004007, data cost:0.25874093812369403 
2022-04-01 00:16:08,869: ============================================================
2022-04-01 00:16:08,869: Epoch 16/31 Batch 7000/7662 eta: 14:56:41.136202	Training Loss 0.6501 (0.7073)	Training Prec@1 40.820 (26.330)	Training Prec@5 54.688 (35.137)	
2022-04-01 00:16:08,869: ============================================================
2022-04-01 00:16:54,469: time cost, forward:0.14311361326300134, backward:0.03500707822209396, data cost:0.25854850191518547 
2022-04-01 00:16:54,470: ============================================================
2022-04-01 00:16:54,470: Epoch 16/31 Batch 7100/7662 eta: 14:37:45.904085	Training Loss 0.6447 (0.7066)	Training Prec@1 46.680 (26.531)	Training Prec@5 56.250 (35.371)	
2022-04-01 00:16:54,470: ============================================================
2022-04-01 00:17:37,634: time cost, forward:0.14313091548188955, backward:0.03505568339404405, data cost:0.25840936884116356 
2022-04-01 00:17:37,635: ============================================================
2022-04-01 00:17:37,635: Epoch 16/31 Batch 7200/7662 eta: 13:50:09.371899	Training Loss 0.6588 (0.7058)	Training Prec@1 38.477 (26.724)	Training Prec@5 48.438 (35.599)	
2022-04-01 00:17:37,636: ============================================================
2022-04-01 00:18:22,996: time cost, forward:0.14314961106765106, backward:0.03509250959805845, data cost:0.25857714026378337 
2022-04-01 00:18:22,997: ============================================================
2022-04-01 00:18:22,997: Epoch 16/31 Batch 7300/7662 eta: 14:31:39.088325	Training Loss 0.6517 (0.7051)	Training Prec@1 42.578 (26.912)	Training Prec@5 51.953 (35.818)	
2022-04-01 00:18:22,997: ============================================================
2022-04-01 00:19:11,149: time cost, forward:0.14361780887520753, backward:0.03516719215285828, data cost:0.2586258083183164 
2022-04-01 00:19:11,149: ============================================================
2022-04-01 00:19:11,149: Epoch 16/31 Batch 7400/7662 eta: 15:24:28.191680	Training Loss 0.6439 (0.7044)	Training Prec@1 42.383 (27.098)	Training Prec@5 56.055 (36.037)	
2022-04-01 00:19:11,150: ============================================================
2022-04-01 00:19:57,402: time cost, forward:0.1438798641169734, backward:0.03520408228629906, data cost:0.2586489578043084 
2022-04-01 00:19:57,402: ============================================================
2022-04-01 00:19:57,403: Epoch 16/31 Batch 7500/7662 eta: 14:47:14.305848	Training Loss 0.6560 (0.7037)	Training Prec@1 39.258 (27.284)	Training Prec@5 51.367 (36.260)	
2022-04-01 00:19:57,403: ============================================================
2022-04-01 00:20:44,472: time cost, forward:0.14440857531099136, backward:0.035265418444358765, data cost:0.2584720454509046 
2022-04-01 00:20:44,472: ============================================================
2022-04-01 00:20:44,472: Epoch 16/31 Batch 7600/7662 eta: 15:02:06.817903	Training Loss 0.6551 (0.7030)	Training Prec@1 39.062 (27.465)	Training Prec@5 51.172 (36.471)	
2022-04-01 00:20:44,472: ============================================================
2022-04-01 00:21:14,298: Epoch: 16/31 eta: 15:01:37.164015	Training Loss 0.6542 (0.7026)	Training Prec@1 38.672 (27.581)	Training Prec@5 51.367 (36.605)
2022-04-01 00:21:14,298: ============================================================
2022-04-01 00:21:57,279: time cost, forward:0.10747378763526377, backward:0.03372263185905688, data cost:0.2879957839696094 
2022-04-01 00:21:57,280: ============================================================
2022-04-01 00:21:57,280: Epoch 17/31 Batch 100/7662 eta: 13:39:37.968648	Training Loss 0.6268 (0.6316)	Training Prec@1 50.391 (48.465)	Training Prec@5 58.594 (59.631)	
2022-04-01 00:21:57,280: ============================================================
2022-04-01 00:22:38,322: time cost, forward:0.11128923042335702, backward:0.033518834329729706, data cost:0.2749881061477278 
2022-04-01 00:22:38,323: ============================================================
2022-04-01 00:22:38,323: Epoch 17/31 Batch 200/7662 eta: 13:04:48.448540	Training Loss 0.6451 (0.6312)	Training Prec@1 50.000 (48.379)	Training Prec@5 60.742 (59.491)	
2022-04-01 00:22:38,323: ============================================================
2022-04-01 00:23:23,285: time cost, forward:0.11978458800044746, backward:0.033877692493706646, data cost:0.2760376491674213 
2022-04-01 00:23:23,285: ============================================================
2022-04-01 00:23:23,286: Epoch 17/31 Batch 300/7662 eta: 14:19:01.507901	Training Loss 0.8872 (0.7103)	Training Prec@1 0.000 (34.648)	Training Prec@5 0.000 (42.715)	
2022-04-01 00:23:23,286: ============================================================
2022-04-01 00:24:05,882: time cost, forward:0.1249859757291942, backward:0.03416223514050171, data cost:0.26936630139076023 
2022-04-01 00:24:05,883: ============================================================
2022-04-01 00:24:05,883: Epoch 17/31 Batch 400/7662 eta: 13:33:07.284388	Training Loss 0.8300 (0.7426)	Training Prec@1 0.000 (25.964)	Training Prec@5 0.000 (32.015)	
2022-04-01 00:24:05,883: ============================================================
2022-04-01 00:24:48,950: time cost, forward:0.1290107781519154, backward:0.034429860258389094, data cost:0.2653969758020374 
2022-04-01 00:24:48,951: ============================================================
2022-04-01 00:24:48,951: Epoch 17/31 Batch 500/7662 eta: 13:41:22.705831	Training Loss 0.8274 (0.7600)	Training Prec@1 0.000 (20.761)	Training Prec@5 0.000 (25.604)	
2022-04-01 00:24:48,951: ============================================================
2022-04-01 00:25:31,166: time cost, forward:0.12833206920273516, backward:0.034342585899595025, data cost:0.2650447504747292 
2022-04-01 00:25:31,166: ============================================================
2022-04-01 00:25:31,166: Epoch 17/31 Batch 600/7662 eta: 13:24:25.557722	Training Loss 0.8262 (0.7713)	Training Prec@1 0.000 (17.296)	Training Prec@5 0.000 (21.332)	
2022-04-01 00:25:31,167: ============================================================
2022-04-01 00:26:14,918: time cost, forward:0.13222990083762676, backward:0.03453448913639707, data cost:0.26218264399679947 
2022-04-01 00:26:14,919: ============================================================
2022-04-01 00:26:14,919: Epoch 17/31 Batch 700/7662 eta: 13:52:58.930324	Training Loss 0.8238 (0.7791)	Training Prec@1 0.000 (14.823)	Training Prec@5 0.000 (18.286)	
2022-04-01 00:26:14,919: ============================================================
2022-04-01 00:27:00,603: time cost, forward:0.13543201656604142, backward:0.03484050651664877, data cost:0.2621476292162574 
2022-04-01 00:27:00,603: ============================================================
2022-04-01 00:27:00,604: Epoch 17/31 Batch 800/7662 eta: 14:29:00.438440	Training Loss 0.8236 (0.7847)	Training Prec@1 0.000 (12.970)	Training Prec@5 0.000 (16.004)	
2022-04-01 00:27:00,604: ============================================================
2022-04-01 00:27:42,568: time cost, forward:0.13526586828560666, backward:0.03465789549873191, data cost:0.2609649006861601 
2022-04-01 00:27:42,568: ============================================================
2022-04-01 00:27:42,568: Epoch 17/31 Batch 900/7662 eta: 13:17:32.862465	Training Loss 0.8150 (0.7885)	Training Prec@1 0.000 (11.532)	Training Prec@5 0.195 (14.246)	
2022-04-01 00:27:42,569: ============================================================
2022-04-01 00:28:26,335: time cost, forward:0.13748174410563213, backward:0.034869945801056186, data cost:0.25921187505827054 
2022-04-01 00:28:26,335: ============================================================
2022-04-01 00:28:26,335: Epoch 17/31 Batch 1000/7662 eta: 13:51:03.975098	Training Loss 0.7947 (0.7904)	Training Prec@1 1.172 (10.424)	Training Prec@5 3.516 (12.955)	
2022-04-01 00:28:26,335: ============================================================
2022-04-01 00:29:07,853: time cost, forward:0.1371504640015176, backward:0.03490324948894858, data cost:0.257970937931939 
2022-04-01 00:29:07,854: ============================================================
2022-04-01 00:29:07,854: Epoch 17/31 Batch 1100/7662 eta: 13:07:41.490237	Training Loss 0.8965 (0.7968)	Training Prec@1 0.000 (9.521)	Training Prec@5 0.000 (11.905)	
2022-04-01 00:29:07,854: ============================================================
2022-04-01 00:29:51,017: time cost, forward:0.1380849691904814, backward:0.035143513993684004, data cost:0.2569263955769288 
2022-04-01 00:29:51,018: ============================================================
2022-04-01 00:29:51,018: Epoch 17/31 Batch 1200/7662 eta: 13:38:10.488242	Training Loss 0.8742 (0.8044)	Training Prec@1 0.000 (8.727)	Training Prec@5 0.195 (10.913)	
2022-04-01 00:29:51,018: ============================================================
2022-04-01 00:30:33,597: time cost, forward:0.1367894426687944, backward:0.03489953522685861, data cost:0.2580543333425074 
2022-04-01 00:30:33,598: ============================================================
2022-04-01 00:30:33,598: Epoch 17/31 Batch 1300/7662 eta: 13:26:23.857561	Training Loss 0.8333 (0.8081)	Training Prec@1 0.391 (8.057)	Training Prec@5 0.391 (10.078)	
2022-04-01 00:30:33,598: ============================================================
2022-04-01 00:31:16,944: time cost, forward:0.1374737643786547, backward:0.03497931103437095, data cost:0.25753468713903527 
2022-04-01 00:31:16,944: ============================================================
2022-04-01 00:31:16,944: Epoch 17/31 Batch 1400/7662 eta: 13:40:11.761922	Training Loss 0.8154 (0.8092)	Training Prec@1 0.000 (7.487)	Training Prec@5 0.391 (9.375)	
2022-04-01 00:31:16,944: ============================================================
2022-04-01 00:32:00,165: time cost, forward:0.13768608097715168, backward:0.03487910883994481, data cost:0.25755885444218674 
2022-04-01 00:32:00,165: ============================================================
2022-04-01 00:32:00,166: Epoch 17/31 Batch 1500/7662 eta: 13:37:06.315895	Training Loss 0.8073 (0.8093)	Training Prec@1 0.000 (6.995)	Training Prec@5 0.781 (8.780)	
2022-04-01 00:32:00,166: ============================================================
2022-04-01 00:32:44,255: time cost, forward:0.1382171120622741, backward:0.03493543995254259, data cost:0.25765414145531096 
2022-04-01 00:32:44,256: ============================================================
2022-04-01 00:32:44,256: Epoch 17/31 Batch 1600/7662 eta: 13:52:48.131732	Training Loss 0.7866 (0.8087)	Training Prec@1 0.977 (6.592)	Training Prec@5 4.688 (8.336)	
2022-04-01 00:32:44,256: ============================================================
2022-04-01 00:33:27,239: time cost, forward:0.13882153549216789, backward:0.03514931018104127, data cost:0.25675027646900556 
2022-04-01 00:33:27,239: ============================================================
2022-04-01 00:33:27,239: Epoch 17/31 Batch 1700/7662 eta: 13:31:10.467903	Training Loss 0.7586 (0.8066)	Training Prec@1 8.203 (6.490)	Training Prec@5 15.234 (8.423)	
2022-04-01 00:33:27,240: ============================================================
2022-04-01 00:34:09,234: time cost, forward:0.13833783519738513, backward:0.035127142789033866, data cost:0.2565271981627892 
2022-04-01 00:34:09,234: ============================================================
2022-04-01 00:34:09,234: Epoch 17/31 Batch 1800/7662 eta: 13:11:49.316658	Training Loss 0.7452 (0.8045)	Training Prec@1 13.477 (6.516)	Training Prec@5 20.898 (8.673)	
2022-04-01 00:34:09,235: ============================================================
2022-04-01 00:34:51,161: time cost, forward:0.1374898097463631, backward:0.03507355516241876, data cost:0.2569440585051542 
2022-04-01 00:34:51,162: ============================================================
2022-04-01 00:34:51,162: Epoch 17/31 Batch 1900/7662 eta: 13:09:51.011901	Training Loss 0.7415 (0.8041)	Training Prec@1 12.891 (6.409)	Training Prec@5 22.461 (8.650)	
2022-04-01 00:34:51,162: ============================================================
2022-04-01 00:35:32,411: time cost, forward:0.13675876388912384, backward:0.035075250060752725, data cost:0.2567905212056941 
2022-04-01 00:35:32,412: ============================================================
2022-04-01 00:35:32,412: Epoch 17/31 Batch 2000/7662 eta: 12:56:24.298402	Training Loss 0.8535 (0.8022)	Training Prec@1 0.195 (6.721)	Training Prec@5 0.195 (9.219)	
2022-04-01 00:35:32,412: ============================================================
2022-04-01 00:36:15,694: time cost, forward:0.13696672031571605, backward:0.035259181854553366, data cost:0.2565610356533056 
2022-04-01 00:36:15,695: ============================================================
2022-04-01 00:36:15,696: Epoch 17/31 Batch 2100/7662 eta: 13:33:57.091506	Training Loss 0.7448 (0.8017)	Training Prec@1 11.914 (6.554)	Training Prec@5 20.117 (9.073)	
2022-04-01 00:36:15,696: ============================================================
2022-04-01 00:36:58,695: time cost, forward:0.13690834589685402, backward:0.03523109760431877, data cost:0.2566941944562939 
2022-04-01 00:36:58,695: ============================================================
2022-04-01 00:36:58,696: Epoch 17/31 Batch 2200/7662 eta: 13:27:54.422726	Training Loss 0.6991 (0.7983)	Training Prec@1 27.734 (7.080)	Training Prec@5 39.258 (9.938)	
2022-04-01 00:36:58,696: ============================================================
2022-04-01 00:37:42,180: time cost, forward:0.13629787359200338, backward:0.035252547668549954, data cost:0.25755686052678306 
2022-04-01 00:37:42,181: ============================================================
2022-04-01 00:37:42,181: Epoch 17/31 Batch 2300/7662 eta: 13:36:17.958122	Training Loss 0.6945 (0.7958)	Training Prec@1 25.391 (7.515)	Training Prec@5 36.328 (10.640)	
2022-04-01 00:37:42,181: ============================================================
2022-04-01 00:38:25,328: time cost, forward:0.1366747009997668, backward:0.03532955277805877, data cost:0.25717644703393183 
2022-04-01 00:38:25,328: ============================================================
2022-04-01 00:38:25,328: Epoch 17/31 Batch 2400/7662 eta: 13:29:14.413342	Training Loss 0.6735 (0.7911)	Training Prec@1 36.133 (8.563)	Training Prec@5 47.266 (12.039)	
2022-04-01 00:38:25,329: ============================================================
2022-04-01 00:39:08,671: time cost, forward:0.1366907196457074, backward:0.03528045882888678, data cost:0.25731407436860854 
2022-04-01 00:39:08,672: ============================================================
2022-04-01 00:39:08,672: Epoch 17/31 Batch 2500/7662 eta: 13:32:11.582642	Training Loss 0.6676 (0.7862)	Training Prec@1 35.938 (9.725)	Training Prec@5 48.047 (13.520)	
2022-04-01 00:39:08,672: ============================================================
2022-04-01 00:39:52,633: time cost, forward:0.13685655905770172, backward:0.035218165901451215, data cost:0.25762976853376907 
2022-04-01 00:39:52,633: ============================================================
2022-04-01 00:39:52,633: Epoch 17/31 Batch 2600/7662 eta: 13:43:01.925679	Training Loss 0.8340 (0.7888)	Training Prec@1 0.195 (9.430)	Training Prec@5 0.391 (13.109)	
2022-04-01 00:39:52,633: ============================================================
2022-04-01 00:40:36,868: time cost, forward:0.13729692662632345, backward:0.03532241617763162, data cost:0.2575647605706604 
2022-04-01 00:40:36,869: ============================================================
2022-04-01 00:40:36,869: Epoch 17/31 Batch 2700/7662 eta: 13:47:26.621893	Training Loss 0.7313 (0.7884)	Training Prec@1 16.016 (9.286)	Training Prec@5 28.516 (12.990)	
2022-04-01 00:40:36,869: ============================================================
2022-04-01 00:41:21,369: time cost, forward:0.13753547290258214, backward:0.03533567791114581, data cost:0.2578110334574218 
2022-04-01 00:41:21,370: ============================================================
2022-04-01 00:41:21,370: Epoch 17/31 Batch 2800/7662 eta: 13:51:39.243794	Training Loss 0.6779 (0.7852)	Training Prec@1 36.719 (9.943)	Training Prec@5 46.289 (13.908)	
2022-04-01 00:41:21,371: ============================================================
2022-04-01 00:42:06,132: time cost, forward:0.1377554330467232, backward:0.03528297362799643, data cost:0.25824038025920826 
2022-04-01 00:42:06,133: ============================================================
2022-04-01 00:42:06,133: Epoch 17/31 Batch 2900/7662 eta: 13:55:48.552198	Training Loss 0.6617 (0.7813)	Training Prec@1 41.602 (10.864)	Training Prec@5 52.148 (15.092)	
2022-04-01 00:42:06,133: ============================================================
2022-04-01 00:42:48,896: time cost, forward:0.13828867401588596, backward:0.03539929337484036, data cost:0.2574225740060682 
2022-04-01 00:42:48,897: ============================================================
2022-04-01 00:42:48,897: Epoch 17/31 Batch 3000/7662 eta: 13:17:45.972357	Training Loss 0.6668 (0.7773)	Training Prec@1 34.766 (11.816)	Training Prec@5 46.484 (16.285)	
2022-04-01 00:42:48,897: ============================================================
2022-04-01 00:43:32,757: time cost, forward:0.13787022149343572, backward:0.03535935716422845, data cost:0.25811751206562034 
2022-04-01 00:43:32,757: ============================================================
2022-04-01 00:43:32,757: Epoch 17/31 Batch 3100/7662 eta: 13:37:29.550544	Training Loss 0.6600 (0.7750)	Training Prec@1 41.797 (12.390)	Training Prec@5 55.469 (17.058)	
2022-04-01 00:43:32,758: ============================================================
2022-04-01 00:44:16,090: time cost, forward:0.1376274588257866, backward:0.035315836321826874, data cost:0.2584577750772117 
2022-04-01 00:44:16,090: ============================================================
2022-04-01 00:44:16,090: Epoch 17/31 Batch 3200/7662 eta: 13:26:56.454105	Training Loss 0.6552 (0.7713)	Training Prec@1 42.383 (13.263)	Training Prec@5 53.711 (18.136)	
2022-04-01 00:44:16,091: ============================================================
2022-04-01 00:45:00,675: time cost, forward:0.1377548312157998, backward:0.035312348186843284, data cost:0.2587621063852209 
2022-04-01 00:45:00,675: ============================================================
2022-04-01 00:45:00,676: Epoch 17/31 Batch 3300/7662 eta: 13:49:30.903095	Training Loss 0.6575 (0.7678)	Training Prec@1 39.844 (14.121)	Training Prec@5 53.711 (19.194)	
2022-04-01 00:45:00,676: ============================================================
2022-04-01 00:45:43,065: time cost, forward:0.13752678605730864, backward:0.035273900765747, data cost:0.2587855803542153 
2022-04-01 00:45:43,066: ============================================================
2022-04-01 00:45:43,067: Epoch 17/31 Batch 3400/7662 eta: 13:07:58.840601	Training Loss 0.6484 (0.7644)	Training Prec@1 44.727 (14.949)	Training Prec@5 56.836 (20.212)	
2022-04-01 00:45:43,067: ============================================================
2022-04-01 00:46:27,484: time cost, forward:0.13863311600228587, backward:0.035335766584336945, data cost:0.25797162903619175 
2022-04-01 00:46:27,485: ============================================================
2022-04-01 00:46:27,485: Epoch 17/31 Batch 3500/7662 eta: 13:44:55.935371	Training Loss 0.6539 (0.7611)	Training Prec@1 39.648 (15.757)	Training Prec@5 52.148 (21.190)	
2022-04-01 00:46:27,485: ============================================================
2022-04-01 00:47:09,718: time cost, forward:0.13857427886142504, backward:0.03531741459987733, data cost:0.2577627634598037 
2022-04-01 00:47:09,718: ============================================================
2022-04-01 00:47:09,718: Epoch 17/31 Batch 3600/7662 eta: 13:03:39.009741	Training Loss 0.6587 (0.7580)	Training Prec@1 37.500 (16.521)	Training Prec@5 49.219 (22.115)	
2022-04-01 00:47:09,719: ============================================================
2022-04-01 00:47:53,359: time cost, forward:0.13874647900296985, backward:0.03531504160779719, data cost:0.257705924639221 
2022-04-01 00:47:53,360: ============================================================
2022-04-01 00:47:53,360: Epoch 17/31 Batch 3700/7662 eta: 13:29:02.951381	Training Loss 0.6433 (0.7550)	Training Prec@1 46.289 (17.243)	Training Prec@5 58.008 (22.988)	
2022-04-01 00:47:53,360: ============================================================
2022-04-01 00:48:38,731: time cost, forward:0.13887996703707942, backward:0.035301507727413875, data cost:0.2581542007042628 
2022-04-01 00:48:38,732: ============================================================
2022-04-01 00:48:38,733: Epoch 17/31 Batch 3800/7662 eta: 14:00:22.794741	Training Loss 0.6586 (0.7521)	Training Prec@1 36.328 (17.936)	Training Prec@5 50.000 (23.828)	
2022-04-01 00:48:38,733: ============================================================
2022-04-01 00:49:22,622: time cost, forward:0.13870114227171645, backward:0.03526015592312379, data cost:0.2585395851267335 
2022-04-01 00:49:22,623: ============================================================
2022-04-01 00:49:22,623: Epoch 17/31 Batch 3900/7662 eta: 13:32:12.140547	Training Loss 0.6402 (0.7494)	Training Prec@1 48.047 (18.599)	Training Prec@5 58.203 (24.626)	
2022-04-01 00:49:22,623: ============================================================
2022-04-01 00:50:06,187: time cost, forward:0.13868864347529905, backward:0.03522812977347502, data cost:0.2586351717433562 
2022-04-01 00:50:06,187: ============================================================
2022-04-01 00:50:06,187: Epoch 17/31 Batch 4000/7662 eta: 13:25:26.309997	Training Loss 0.6462 (0.7468)	Training Prec@1 40.039 (19.224)	Training Prec@5 54.688 (25.387)	
2022-04-01 00:50:06,187: ============================================================
2022-04-01 00:50:48,140: time cost, forward:0.1387698416536568, backward:0.03520357233630532, data cost:0.2582577230523755 
2022-04-01 00:50:48,151: ============================================================
2022-04-01 00:50:48,151: Epoch 17/31 Batch 4100/7662 eta: 12:55:08.551384	Training Loss 0.6367 (0.7443)	Training Prec@1 50.391 (19.834)	Training Prec@5 57.617 (26.121)	
2022-04-01 00:50:48,151: ============================================================
2022-04-01 00:51:28,706: time cost, forward:0.1383775842561697, backward:0.035174014086267955, data cost:0.25805010634338493 
2022-04-01 00:51:28,707: ============================================================
2022-04-01 00:51:28,707: Epoch 17/31 Batch 4200/7662 eta: 12:28:28.184211	Training Loss 0.6424 (0.7420)	Training Prec@1 46.094 (20.404)	Training Prec@5 58.594 (26.812)	
2022-04-01 00:51:28,707: ============================================================
2022-04-01 00:52:10,349: time cost, forward:0.13810189692578667, backward:0.03516303769209463, data cost:0.2579686657776248 
2022-04-01 00:52:10,350: ============================================================
2022-04-01 00:52:10,350: Epoch 17/31 Batch 4300/7662 eta: 12:47:49.886790	Training Loss 0.6445 (0.7397)	Training Prec@1 44.727 (20.958)	Training Prec@5 54.883 (27.482)	
2022-04-01 00:52:10,350: ============================================================
2022-04-01 00:52:53,978: time cost, forward:0.13793619000442897, backward:0.03514786611011988, data cost:0.2582555157565399 
2022-04-01 00:52:53,979: ============================================================
2022-04-01 00:52:53,979: Epoch 17/31 Batch 4400/7662 eta: 13:23:43.834777	Training Loss 0.6465 (0.7375)	Training Prec@1 41.992 (21.503)	Training Prec@5 55.469 (28.131)	
2022-04-01 00:52:53,979: ============================================================
2022-04-01 00:53:36,064: time cost, forward:0.1375335691027653, backward:0.03508654979367499, data cost:0.2584803094861772 
2022-04-01 00:53:36,065: ============================================================
2022-04-01 00:53:36,065: Epoch 17/31 Batch 4500/7662 eta: 12:54:35.921641	Training Loss 0.6377 (0.7354)	Training Prec@1 45.117 (22.018)	Training Prec@5 55.078 (28.743)	
2022-04-01 00:53:36,065: ============================================================
2022-04-01 00:54:19,601: time cost, forward:0.13755110176419869, backward:0.035067760055286515, data cost:0.25855403061560067 
2022-04-01 00:54:19,602: ============================================================
2022-04-01 00:54:19,602: Epoch 17/31 Batch 4600/7662 eta: 13:20:34.937088	Training Loss 0.6433 (0.7333)	Training Prec@1 42.578 (22.511)	Training Prec@5 53.516 (29.338)	
2022-04-01 00:54:19,602: ============================================================
2022-04-01 00:55:01,807: time cost, forward:0.13741691565610015, backward:0.035152385579344816, data cost:0.2584110762520429 
2022-04-01 00:55:01,808: ============================================================
2022-04-01 00:55:01,808: Epoch 17/31 Batch 4700/7662 eta: 12:55:24.269677	Training Loss 0.6493 (0.7314)	Training Prec@1 42.773 (22.984)	Training Prec@5 52.539 (29.907)	
2022-04-01 00:55:01,808: ============================================================
2022-04-01 00:55:47,211: time cost, forward:0.13807183440761484, backward:0.03519222199308249, data cost:0.2582003273897356 
2022-04-01 00:55:47,211: ============================================================
2022-04-01 00:55:47,211: Epoch 17/31 Batch 4800/7662 eta: 13:53:22.942429	Training Loss 0.6433 (0.7296)	Training Prec@1 45.312 (23.432)	Training Prec@5 57.812 (30.442)	
2022-04-01 00:55:47,212: ============================================================
2022-04-01 00:56:30,234: time cost, forward:0.13758054332456726, backward:0.03506856535035363, data cost:0.25877756876808256 
2022-04-01 00:56:30,235: ============================================================
2022-04-01 00:56:30,235: Epoch 17/31 Batch 4900/7662 eta: 13:08:59.147110	Training Loss 0.6436 (0.7277)	Training Prec@1 45.117 (23.874)	Training Prec@5 57.227 (30.969)	
2022-04-01 00:56:30,235: ============================================================
2022-04-01 00:57:12,101: time cost, forward:0.1374984521058875, backward:0.03502355267653873, data cost:0.2586409690785966 
2022-04-01 00:57:12,101: ============================================================
2022-04-01 00:57:12,102: Epoch 17/31 Batch 5000/7662 eta: 12:47:04.704424	Training Loss 0.6396 (0.7260)	Training Prec@1 46.289 (24.307)	Training Prec@5 57.031 (31.475)	
2022-04-01 00:57:12,102: ============================================================
2022-04-01 00:57:55,259: time cost, forward:0.1374927314736605, backward:0.035045031543618724, data cost:0.25862470657878306 
2022-04-01 00:57:55,259: ============================================================
2022-04-01 00:57:55,259: Epoch 17/31 Batch 5100/7662 eta: 13:10:00.475423	Training Loss 0.6293 (0.7243)	Training Prec@1 50.391 (24.726)	Training Prec@5 60.547 (31.976)	
2022-04-01 00:57:55,260: ============================================================
2022-04-01 00:58:36,621: time cost, forward:0.1376386811398937, backward:0.03509472759670192, data cost:0.25808190382267565 
2022-04-01 00:58:36,622: ============================================================
2022-04-01 00:58:36,622: Epoch 17/31 Batch 5200/7662 eta: 12:36:27.448196	Training Loss 0.6303 (0.7226)	Training Prec@1 49.023 (25.129)	Training Prec@5 60.352 (32.455)	
2022-04-01 00:58:36,622: ============================================================
2022-04-01 00:59:20,155: time cost, forward:0.13747557191764168, backward:0.035104446263555356, data cost:0.2583030027856375 
2022-04-01 00:59:20,156: ============================================================
2022-04-01 00:59:20,156: Epoch 17/31 Batch 5300/7662 eta: 13:15:26.738803	Training Loss 0.6390 (0.7210)	Training Prec@1 44.141 (25.516)	Training Prec@5 56.250 (32.913)	
2022-04-01 00:59:20,156: ============================================================
2022-04-01 01:00:00,358: time cost, forward:0.1371007281379537, backward:0.03505677964029808, data cost:0.25819029859269765 
2022-04-01 01:00:00,359: ============================================================
2022-04-01 01:00:00,359: Epoch 17/31 Batch 5400/7662 eta: 12:13:54.898423	Training Loss 0.6316 (0.7195)	Training Prec@1 46.680 (25.886)	Training Prec@5 56.836 (33.356)	
2022-04-01 01:00:00,359: ============================================================
2022-04-01 01:00:43,862: time cost, forward:0.13723038517143277, backward:0.035053808356571424, data cost:0.2581554411280955 
2022-04-01 01:00:43,863: ============================================================
2022-04-01 01:00:43,863: Epoch 17/31 Batch 5500/7662 eta: 13:13:26.742690	Training Loss 0.6383 (0.7180)	Training Prec@1 44.922 (26.253)	Training Prec@5 56.641 (33.790)	
2022-04-01 01:00:43,863: ============================================================
2022-04-01 01:01:27,035: time cost, forward:0.1375341162466113, backward:0.0350465477311328, data cost:0.2578680398613667 
2022-04-01 01:01:27,035: ============================================================
2022-04-01 01:01:27,035: Epoch 17/31 Batch 5600/7662 eta: 13:06:40.858609	Training Loss 0.6288 (0.7165)	Training Prec@1 49.023 (26.605)	Training Prec@5 59.961 (34.207)	
2022-04-01 01:01:27,036: ============================================================
2022-04-01 01:02:08,134: time cost, forward:0.13713171779534172, backward:0.035007273613266575, data cost:0.25796270307730657 
2022-04-01 01:02:08,134: ============================================================
2022-04-01 01:02:08,135: Epoch 17/31 Batch 5700/7662 eta: 12:28:13.396603	Training Loss 0.6287 (0.7152)	Training Prec@1 46.289 (26.941)	Training Prec@5 58.789 (34.604)	
2022-04-01 01:02:08,135: ============================================================
2022-04-01 01:02:52,358: time cost, forward:0.1375344986133605, backward:0.03503586876328638, data cost:0.25774165629764983 
2022-04-01 01:02:52,358: ============================================================
2022-04-01 01:02:52,359: Epoch 17/31 Batch 5800/7662 eta: 13:24:21.859766	Training Loss 0.6430 (0.7138)	Training Prec@1 43.555 (27.269)	Training Prec@5 53.906 (34.993)	
2022-04-01 01:02:52,359: ============================================================
2022-04-01 01:03:35,056: time cost, forward:0.13750392850283183, backward:0.035011010041457555, data cost:0.2577335322422584 
2022-04-01 01:03:35,056: ============================================================
2022-04-01 01:03:35,057: Epoch 17/31 Batch 5900/7662 eta: 12:55:53.903219	Training Loss 0.6326 (0.7125)	Training Prec@1 47.656 (27.591)	Training Prec@5 57.227 (35.367)	
2022-04-01 01:03:35,057: ============================================================
2022-04-01 01:04:18,189: time cost, forward:0.13782121300955658, backward:0.03500195979515619, data cost:0.2574057197507212 
2022-04-01 01:04:18,190: ============================================================
2022-04-01 01:04:18,190: Epoch 17/31 Batch 6000/7662 eta: 13:03:05.729879	Training Loss 0.6422 (0.7112)	Training Prec@1 44.531 (27.902)	Training Prec@5 54.492 (35.732)	
2022-04-01 01:04:18,190: ============================================================
2022-04-01 01:05:00,434: time cost, forward:0.13760955823525228, backward:0.03496921639067948, data cost:0.2575410879094164 
2022-04-01 01:05:00,434: ============================================================
2022-04-01 01:05:00,434: Epoch 17/31 Batch 6100/7662 eta: 12:46:14.846788	Training Loss 0.6373 (0.7100)	Training Prec@1 46.289 (28.205)	Training Prec@5 58.008 (36.092)	
2022-04-01 01:05:00,435: ============================================================
2022-04-01 01:05:42,020: time cost, forward:0.13752129170601937, backward:0.03496800001291791, data cost:0.2573920673546358 
2022-04-01 01:05:42,020: ============================================================
2022-04-01 01:05:42,021: Epoch 17/31 Batch 6200/7662 eta: 12:33:37.079455	Training Loss 0.6350 (0.7088)	Training Prec@1 45.312 (28.502)	Training Prec@5 58.984 (36.439)	
2022-04-01 01:05:42,021: ============================================================
2022-04-01 01:06:25,892: time cost, forward:0.1376727219327402, backward:0.03496873834848896, data cost:0.25738144658977863 
2022-04-01 01:06:25,893: ============================================================
2022-04-01 01:06:25,893: Epoch 17/31 Batch 6300/7662 eta: 13:14:18.877970	Training Loss 0.6265 (0.7076)	Training Prec@1 48.047 (28.789)	Training Prec@5 59.375 (36.774)	
2022-04-01 01:06:25,893: ============================================================
2022-04-01 01:07:08,771: time cost, forward:0.1376615793076432, backward:0.034985313417017695, data cost:0.25734854843639215 
2022-04-01 01:07:08,771: ============================================================
2022-04-01 01:07:08,772: Epoch 17/31 Batch 6400/7662 eta: 12:55:37.018043	Training Loss 0.6302 (0.7064)	Training Prec@1 47.656 (29.073)	Training Prec@5 57.617 (37.101)	
2022-04-01 01:07:08,772: ============================================================
2022-04-01 01:07:51,752: time cost, forward:0.13731325584331794, backward:0.0349663204551752, data cost:0.257708724709103 
2022-04-01 01:07:51,753: ============================================================
2022-04-01 01:07:51,753: Epoch 17/31 Batch 6500/7662 eta: 12:56:44.827582	Training Loss 0.6231 (0.7053)	Training Prec@1 50.000 (29.349)	Training Prec@5 59.180 (37.424)	
2022-04-01 01:07:51,753: ============================================================
2022-04-01 01:08:33,755: time cost, forward:0.13745757582910603, backward:0.034967532535812536, data cost:0.25740300761802504 
2022-04-01 01:08:33,755: ============================================================
2022-04-01 01:08:33,756: Epoch 17/31 Batch 6600/7662 eta: 12:38:21.992300	Training Loss 0.6233 (0.7042)	Training Prec@1 49.805 (29.620)	Training Prec@5 59.766 (37.740)	
2022-04-01 01:08:33,756: ============================================================
2022-04-01 01:09:14,923: time cost, forward:0.13736597316125237, backward:0.03494003605960038, data cost:0.2572395818983375 
2022-04-01 01:09:14,923: ============================================================
2022-04-01 01:09:14,923: Epoch 17/31 Batch 6700/7662 eta: 12:22:36.290340	Training Loss 0.6322 (0.7031)	Training Prec@1 48.828 (29.886)	Training Prec@5 58.398 (38.048)	
2022-04-01 01:09:14,924: ============================================================
2022-04-01 01:09:57,462: time cost, forward:0.13738623691457286, backward:0.034907960246496124, data cost:0.2571907929242192 
2022-04-01 01:09:57,463: ============================================================
2022-04-01 01:09:57,463: Epoch 17/31 Batch 6800/7662 eta: 12:46:38.720342	Training Loss 0.6353 (0.7021)	Training Prec@1 43.359 (30.146)	Training Prec@5 56.836 (38.350)	
2022-04-01 01:09:57,463: ============================================================
2022-04-01 01:10:37,944: time cost, forward:0.13705341320726247, backward:0.03486978660408769, data cost:0.2572060199142591 
2022-04-01 01:10:37,945: ============================================================
2022-04-01 01:10:37,945: Epoch 17/31 Batch 6900/7662 eta: 12:08:52.770327	Training Loss 0.6252 (0.7011)	Training Prec@1 46.094 (30.401)	Training Prec@5 57.422 (38.646)	
2022-04-01 01:10:37,945: ============================================================
2022-04-01 01:11:19,442: time cost, forward:0.13690167489196933, backward:0.03485523933920797, data cost:0.25715816707368544 
2022-04-01 01:11:19,442: ============================================================
2022-04-01 01:11:19,442: Epoch 17/31 Batch 7000/7662 eta: 12:26:28.724305	Training Loss 0.6277 (0.7001)	Training Prec@1 49.414 (30.649)	Training Prec@5 58.594 (38.934)	
2022-04-01 01:11:19,443: ============================================================
2022-04-01 01:12:03,617: time cost, forward:0.137175211017779, backward:0.034855980993341536, data cost:0.257063110574297 
2022-04-01 01:12:03,618: ============================================================
2022-04-01 01:12:03,618: Epoch 17/31 Batch 7100/7662 eta: 13:13:55.184366	Training Loss 0.6355 (0.6991)	Training Prec@1 45.898 (30.890)	Training Prec@5 59.180 (39.213)	
2022-04-01 01:12:03,618: ============================================================
2022-04-01 01:12:45,219: time cost, forward:0.13696685399027528, backward:0.034843331526544195, data cost:0.25709414422503774 
2022-04-01 01:12:45,220: ============================================================
2022-04-01 01:12:45,220: Epoch 17/31 Batch 7200/7662 eta: 12:26:57.781865	Training Loss 0.6209 (0.6981)	Training Prec@1 48.438 (31.128)	Training Prec@5 59.961 (39.487)	
2022-04-01 01:12:45,220: ============================================================
2022-04-01 01:13:26,618: time cost, forward:0.1366657982755808, backward:0.03482147794436847, data cost:0.2572129228406123 
2022-04-01 01:13:26,619: ============================================================
2022-04-01 01:13:26,619: Epoch 17/31 Batch 7300/7662 eta: 12:22:38.213299	Training Loss 0.6231 (0.6972)	Training Prec@1 48.828 (31.370)	Training Prec@5 59.570 (39.760)	
2022-04-01 01:13:26,619: ============================================================
2022-04-01 01:14:07,341: time cost, forward:0.1364726336489885, backward:0.034807744034562084, data cost:0.25711755382642504 
2022-04-01 01:14:07,342: ============================================================
2022-04-01 01:14:07,342: Epoch 17/31 Batch 7400/7662 eta: 12:09:49.808420	Training Loss 0.6260 (0.6963)	Training Prec@1 47.852 (31.604)	Training Prec@5 59.375 (40.025)	
2022-04-01 01:14:07,342: ============================================================
2022-04-01 01:14:49,029: time cost, forward:0.13624336290620204, backward:0.03482805854369043, data cost:0.25717169066272844 
2022-04-01 01:14:49,029: ============================================================
2022-04-01 01:14:49,029: Epoch 17/31 Batch 7500/7662 eta: 12:26:25.206429	Training Loss 0.6289 (0.6954)	Training Prec@1 48.438 (31.828)	Training Prec@5 58.984 (40.285)	
2022-04-01 01:14:49,029: ============================================================
2022-04-01 01:15:33,298: time cost, forward:0.13661925474865402, backward:0.03486575818654816, data cost:0.25694151341342536 
2022-04-01 01:15:33,299: ============================================================
2022-04-01 01:15:33,299: Epoch 17/31 Batch 7600/7662 eta: 13:11:55.239965	Training Loss 0.6249 (0.6945)	Training Prec@1 50.586 (32.048)	Training Prec@5 61.719 (40.540)	
2022-04-01 01:15:33,299: ============================================================
2022-04-01 01:16:01,711: Epoch: 17/31 eta: 13:11:27.349979	Training Loss 0.6226 (0.6939)	Training Prec@1 49.023 (32.185)	Training Prec@5 59.570 (40.699)
2022-04-01 01:16:01,711: ============================================================
2022-04-01 01:16:46,787: time cost, forward:0.10796897339098381, backward:0.032803824453642876, data cost:0.31193646276840054 
2022-04-01 01:16:46,788: ============================================================
2022-04-01 01:16:46,788: Epoch 18/31 Batch 100/7662 eta: 13:24:51.046839	Training Loss 0.6004 (0.6074)	Training Prec@1 57.227 (55.459)	Training Prec@5 70.312 (66.081)	
2022-04-01 01:16:46,788: ============================================================
2022-04-01 01:17:26,977: time cost, forward:0.10805415268519417, backward:0.033075128967438513, data cost:0.28566769139850556 
2022-04-01 01:17:26,978: ============================================================
2022-04-01 01:17:26,978: Epoch 18/31 Batch 200/7662 eta: 11:57:10.597964	Training Loss 0.6072 (0.6085)	Training Prec@1 54.297 (55.324)	Training Prec@5 64.844 (65.859)	
2022-04-01 01:17:26,978: ============================================================
2022-04-01 01:18:07,043: time cost, forward:0.10813408870760813, backward:0.032690033067428945, data cost:0.27727585412985506 
2022-04-01 01:18:07,044: ============================================================
2022-04-01 01:18:07,044: Epoch 18/31 Batch 300/7662 eta: 11:54:18.483376	Training Loss 0.6136 (0.6090)	Training Prec@1 52.539 (55.081)	Training Prec@5 63.281 (65.692)	
2022-04-01 01:18:07,044: ============================================================
2022-04-01 01:18:47,740: time cost, forward:0.10850773658370015, backward:0.03080848643654271, data cost:0.2758538603483884 
2022-04-01 01:18:47,741: ============================================================
2022-04-01 01:18:47,741: Epoch 18/31 Batch 400/7662 eta: 12:04:52.404597	Training Loss 0.6042 (0.6096)	Training Prec@1 55.664 (54.988)	Training Prec@5 68.750 (65.576)	
2022-04-01 01:18:47,741: ============================================================
2022-04-01 01:19:29,001: time cost, forward:0.11268031621027089, backward:0.03136997041339148, data cost:0.27047505789624904 
2022-04-01 01:19:29,001: ============================================================
2022-04-01 01:19:29,001: Epoch 18/31 Batch 500/7662 eta: 12:14:13.395959	Training Loss 0.6089 (0.6095)	Training Prec@1 54.297 (55.029)	Training Prec@5 63.867 (65.609)	
2022-04-01 01:19:29,002: ============================================================
2022-04-01 01:20:10,008: time cost, forward:0.1126683371293923, backward:0.031417027538726244, data cost:0.26973834937323315 
2022-04-01 01:20:10,008: ============================================================
2022-04-01 01:20:10,008: Epoch 18/31 Batch 600/7662 eta: 12:09:01.840977	Training Loss 0.6049 (0.6099)	Training Prec@1 56.641 (54.945)	Training Prec@5 68.945 (65.558)	
2022-04-01 01:20:10,009: ============================================================
2022-04-01 01:20:50,826: time cost, forward:0.11553448702985467, backward:0.03177560825375187, data cost:0.2656007583901947 
2022-04-01 01:20:50,826: ============================================================
2022-04-01 01:20:50,826: Epoch 18/31 Batch 700/7662 eta: 12:04:59.052220	Training Loss 0.6083 (0.6099)	Training Prec@1 52.734 (54.971)	Training Prec@5 65.039 (65.571)	
2022-04-01 01:20:50,826: ============================================================
2022-04-01 01:21:33,916: time cost, forward:0.11838897656141145, backward:0.032056214663203575, data cost:0.2647611641316897 
2022-04-01 01:21:33,917: ============================================================
2022-04-01 01:21:33,917: Epoch 18/31 Batch 800/7662 eta: 12:44:38.677958	Training Loss 0.6131 (0.6100)	Training Prec@1 53.125 (54.930)	Training Prec@5 62.891 (65.520)	
2022-04-01 01:21:33,918: ============================================================
2022-04-01 01:22:14,508: time cost, forward:0.12019913745536422, backward:0.03230940539791799, data cost:0.26158661147511175 
2022-04-01 01:22:14,509: ============================================================
2022-04-01 01:22:14,509: Epoch 18/31 Batch 900/7662 eta: 11:59:37.200511	Training Loss 0.6141 (0.6103)	Training Prec@1 50.000 (54.825)	Training Prec@5 63.086 (65.403)	
2022-04-01 01:22:14,510: ============================================================
2022-04-01 01:22:56,302: time cost, forward:0.12033203772238425, backward:0.032595517518403415, data cost:0.2614694655955852 
2022-04-01 01:22:56,303: ============================================================
2022-04-01 01:22:56,303: Epoch 18/31 Batch 1000/7662 eta: 12:20:13.922613	Training Loss 0.6112 (0.6105)	Training Prec@1 54.883 (54.760)	Training Prec@5 65.430 (65.310)	
2022-04-01 01:22:56,303: ============================================================
2022-04-01 01:23:37,542: time cost, forward:0.12081243711997423, backward:0.032726248358465305, data cost:0.2606744831317766 
2022-04-01 01:23:37,542: ============================================================
2022-04-01 01:23:37,543: Epoch 18/31 Batch 1100/7662 eta: 12:09:43.433178	Training Loss 0.6119 (0.6107)	Training Prec@1 55.664 (54.674)	Training Prec@5 65.625 (65.234)	
2022-04-01 01:23:37,543: ============================================================
2022-04-01 01:24:18,288: time cost, forward:0.12010128166001473, backward:0.03281498074630979, data cost:0.2606915862884394 
2022-04-01 01:24:18,289: ============================================================
2022-04-01 01:24:18,289: Epoch 18/31 Batch 1200/7662 eta: 12:00:19.500693	Training Loss 0.6172 (0.6109)	Training Prec@1 51.758 (54.634)	Training Prec@5 62.891 (65.181)	
2022-04-01 01:24:18,289: ============================================================
2022-04-01 01:25:01,761: time cost, forward:0.12227930703284283, backward:0.03295206399584294, data cost:0.26000164819736493 
2022-04-01 01:25:01,761: ============================================================
2022-04-01 01:25:01,761: Epoch 18/31 Batch 1300/7662 eta: 12:47:47.171749	Training Loss 0.6167 (0.6111)	Training Prec@1 55.078 (54.554)	Training Prec@5 65.625 (65.130)	
2022-04-01 01:25:01,762: ============================================================
2022-04-01 01:25:43,923: time cost, forward:0.12270824000867799, backward:0.03300616364550642, data cost:0.2599660375443759 
2022-04-01 01:25:43,923: ============================================================
2022-04-01 01:25:43,924: Epoch 18/31 Batch 1400/7662 eta: 12:23:56.558897	Training Loss 0.6141 (0.6112)	Training Prec@1 54.688 (54.509)	Training Prec@5 65.039 (65.083)	
2022-04-01 01:25:43,924: ============================================================
2022-04-01 01:26:24,458: time cost, forward:0.12294658141743747, backward:0.03298656713016197, data cost:0.2590176785604567 
2022-04-01 01:26:24,458: ============================================================
2022-04-01 01:26:24,458: Epoch 18/31 Batch 1500/7662 eta: 11:54:33.346728	Training Loss 0.6165 (0.6114)	Training Prec@1 51.953 (54.435)	Training Prec@5 63.867 (65.012)	
2022-04-01 01:26:24,459: ============================================================
2022-04-01 01:27:06,659: time cost, forward:0.12436488660295879, backward:0.03302123413897068, data cost:0.25796817107972986 
2022-04-01 01:27:06,660: ============================================================
2022-04-01 01:27:06,660: Epoch 18/31 Batch 1600/7662 eta: 12:23:13.748787	Training Loss 0.6113 (0.6115)	Training Prec@1 54.297 (54.391)	Training Prec@5 64.648 (64.974)	
2022-04-01 01:27:06,660: ============================================================
2022-04-01 01:27:46,339: time cost, forward:0.12473378060774779, backward:0.033031870716806716, data cost:0.25648224038050554 
2022-04-01 01:27:46,339: ============================================================
2022-04-01 01:27:46,340: Epoch 18/31 Batch 1700/7662 eta: 11:38:09.529336	Training Loss 0.6154 (0.6116)	Training Prec@1 52.734 (54.353)	Training Prec@5 62.891 (64.947)	
2022-04-01 01:27:46,340: ============================================================
2022-04-01 01:28:28,472: time cost, forward:0.1252106243269254, backward:0.03301417304119049, data cost:0.2563823682192367 
2022-04-01 01:28:28,473: ============================================================
2022-04-01 01:28:28,473: Epoch 18/31 Batch 1800/7662 eta: 12:20:37.770910	Training Loss 0.6125 (0.6116)	Training Prec@1 52.344 (54.338)	Training Prec@5 65.039 (64.942)	
2022-04-01 01:28:28,473: ============================================================
2022-04-01 01:29:10,812: time cost, forward:0.1249699577524387, backward:0.033081230582407486, data cost:0.2570373883932876 
2022-04-01 01:29:10,813: ============================================================
2022-04-01 01:29:10,813: Epoch 18/31 Batch 1900/7662 eta: 12:23:33.089305	Training Loss 0.6145 (0.6116)	Training Prec@1 52.344 (54.314)	Training Prec@5 62.109 (64.923)	
2022-04-01 01:29:10,813: ============================================================
2022-04-01 01:29:52,285: time cost, forward:0.12566458576616493, backward:0.03313000551636902, data cost:0.25624961135028423 
2022-04-01 01:29:52,285: ============================================================
2022-04-01 01:29:52,285: Epoch 18/31 Batch 2000/7662 eta: 12:07:37.584468	Training Loss 0.6109 (0.6117)	Training Prec@1 55.469 (54.283)	Training Prec@5 66.992 (64.889)	
2022-04-01 01:29:52,285: ============================================================
2022-04-01 01:30:32,594: time cost, forward:0.1250623116440975, backward:0.03313716608549993, data cost:0.25625479999413203 
2022-04-01 01:30:32,595: ============================================================
2022-04-01 01:30:32,595: Epoch 18/31 Batch 2100/7662 eta: 11:46:33.278818	Training Loss 0.6149 (0.6117)	Training Prec@1 52.148 (54.271)	Training Prec@5 66.016 (64.880)	
2022-04-01 01:30:32,595: ============================================================
2022-04-01 01:31:14,607: time cost, forward:0.1253569079507964, backward:0.03324187490386061, data cost:0.25608589617758243 
2022-04-01 01:31:14,608: ============================================================
2022-04-01 01:31:14,608: Epoch 18/31 Batch 2200/7662 eta: 12:15:42.925308	Training Loss 0.6121 (0.6116)	Training Prec@1 56.445 (54.276)	Training Prec@5 65.039 (64.890)	
2022-04-01 01:31:14,609: ============================================================
2022-04-01 01:31:57,325: time cost, forward:0.1258801159105803, backward:0.03332321194785219, data cost:0.25602990422574473 
2022-04-01 01:31:57,326: ============================================================
2022-04-01 01:31:57,326: Epoch 18/31 Batch 2300/7662 eta: 12:27:20.210127	Training Loss 0.7312 (0.6148)	Training Prec@1 23.438 (53.532)	Training Prec@5 33.203 (64.109)	
2022-04-01 01:31:57,326: ============================================================
2022-04-01 01:32:37,580: time cost, forward:0.12604352820659986, backward:0.033365887669336305, data cost:0.2552710357632623 
2022-04-01 01:32:37,581: ============================================================
2022-04-01 01:32:37,581: Epoch 18/31 Batch 2400/7662 eta: 11:43:35.377859	Training Loss 0.6206 (0.6158)	Training Prec@1 51.367 (53.255)	Training Prec@5 61.523 (63.854)	
2022-04-01 01:32:37,581: ============================================================
2022-04-01 01:33:19,935: time cost, forward:0.12633109684227084, backward:0.03342174834945575, data cost:0.25527127383469866 
2022-04-01 01:33:19,935: ============================================================
2022-04-01 01:33:19,935: Epoch 18/31 Batch 2500/7662 eta: 12:19:33.922805	Training Loss 0.6085 (0.6158)	Training Prec@1 55.078 (53.238)	Training Prec@5 66.211 (63.835)	
2022-04-01 01:33:19,935: ============================================================
2022-04-01 01:34:03,378: time cost, forward:0.1267226794537511, backward:0.033445313142877034, data cost:0.2556039170606084 
2022-04-01 01:34:03,378: ============================================================
2022-04-01 01:34:03,379: Epoch 18/31 Batch 2600/7662 eta: 12:37:51.667936	Training Loss 0.6183 (0.6157)	Training Prec@1 51.367 (53.244)	Training Prec@5 62.695 (63.837)	
2022-04-01 01:34:03,379: ============================================================
2022-04-01 01:34:45,190: time cost, forward:0.1271034748124034, backward:0.0335007802165407, data cost:0.25521351364463646 
2022-04-01 01:34:45,191: ============================================================
2022-04-01 01:34:45,191: Epoch 18/31 Batch 2700/7662 eta: 12:08:42.582039	Training Loss 0.6072 (0.6156)	Training Prec@1 52.539 (53.258)	Training Prec@5 64.062 (63.851)	
2022-04-01 01:34:45,191: ============================================================
2022-04-01 01:35:25,718: time cost, forward:0.12662801260435397, backward:0.033489424145702974, data cost:0.2553286825004924 
2022-04-01 01:35:25,718: ============================================================
2022-04-01 01:35:25,718: Epoch 18/31 Batch 2800/7662 eta: 11:45:38.810876	Training Loss 0.6056 (0.6155)	Training Prec@1 54.688 (53.287)	Training Prec@5 66.797 (63.871)	
2022-04-01 01:35:25,719: ============================================================
2022-04-01 01:36:09,014: time cost, forward:0.12705026177876405, backward:0.033556698930390996, data cost:0.2554050361999112 
2022-04-01 01:36:09,015: ============================================================
2022-04-01 01:36:09,015: Epoch 18/31 Batch 2900/7662 eta: 12:33:08.184269	Training Loss 0.6188 (0.6154)	Training Prec@1 52.344 (53.311)	Training Prec@5 62.305 (63.894)	
2022-04-01 01:36:09,015: ============================================================
2022-04-01 01:36:49,596: time cost, forward:0.12659772462390112, backward:0.03351264263876838, data cost:0.25555882035751826 
2022-04-01 01:36:49,597: ============================================================
2022-04-01 01:36:49,597: Epoch 18/31 Batch 3000/7662 eta: 11:45:14.339696	Training Loss 0.6141 (0.6152)	Training Prec@1 53.906 (53.337)	Training Prec@5 65.234 (63.921)	
2022-04-01 01:36:49,597: ============================================================
2022-04-01 01:37:30,943: time cost, forward:0.12626579116336298, backward:0.03349366538868523, data cost:0.2558221036136131 
2022-04-01 01:37:30,945: ============================================================
2022-04-01 01:37:30,945: Epoch 18/31 Batch 3100/7662 eta: 11:57:52.049759	Training Loss 0.5981 (0.6151)	Training Prec@1 56.836 (53.357)	Training Prec@5 66.602 (63.944)	
2022-04-01 01:37:30,946: ============================================================
2022-04-01 01:38:14,335: time cost, forward:0.12681128599376149, backward:0.03352529192462717, data cost:0.2558355304590424 
2022-04-01 01:38:14,335: ============================================================
2022-04-01 01:38:14,335: Epoch 18/31 Batch 3200/7662 eta: 12:32:35.714878	Training Loss 0.6188 (0.6150)	Training Prec@1 53.125 (53.380)	Training Prec@5 63.867 (63.972)	
2022-04-01 01:38:14,335: ============================================================
2022-04-01 01:38:56,304: time cost, forward:0.12733908225710228, backward:0.0335994954902716, data cost:0.25532511126890295 
2022-04-01 01:38:56,305: ============================================================
2022-04-01 01:38:56,305: Epoch 18/31 Batch 3300/7662 eta: 12:07:15.684476	Training Loss 0.6077 (0.6149)	Training Prec@1 56.836 (53.422)	Training Prec@5 65.430 (64.001)	
2022-04-01 01:38:56,305: ============================================================
2022-04-01 01:39:36,686: time cost, forward:0.12755176522304607, backward:0.03355511422366316, data cost:0.2547965003448783 
2022-04-01 01:39:36,686: ============================================================
2022-04-01 01:39:36,686: Epoch 18/31 Batch 3400/7662 eta: 11:39:03.474661	Training Loss 0.6037 (0.6147)	Training Prec@1 55.664 (53.450)	Training Prec@5 66.992 (64.031)	
2022-04-01 01:39:36,686: ============================================================
2022-04-01 01:40:17,603: time cost, forward:0.12790170864705938, backward:0.03354005501521727, data cost:0.25424316740949077 
2022-04-01 01:40:17,603: ============================================================
2022-04-01 01:40:17,603: Epoch 18/31 Batch 3500/7662 eta: 11:47:39.282521	Training Loss 0.6123 (0.6146)	Training Prec@1 54.102 (53.484)	Training Prec@5 65.430 (64.060)	
2022-04-01 01:40:17,604: ============================================================
2022-04-01 01:40:58,800: time cost, forward:0.12747272367972937, backward:0.03349959873497304, data cost:0.25458926219150535 
2022-04-01 01:40:58,800: ============================================================
2022-04-01 01:40:58,800: Epoch 18/31 Batch 3600/7662 eta: 11:51:48.550336	Training Loss 0.6172 (0.6144)	Training Prec@1 53.711 (53.520)	Training Prec@5 62.109 (64.093)	
2022-04-01 01:40:58,801: ============================================================
2022-04-01 01:41:41,520: time cost, forward:0.12740045258985336, backward:0.03349901135143766, data cost:0.25496840657463393 
2022-04-01 01:41:41,520: ============================================================
2022-04-01 01:41:41,520: Epoch 18/31 Batch 3700/7662 eta: 12:17:24.540772	Training Loss 0.6098 (0.6143)	Training Prec@1 54.102 (53.563)	Training Prec@5 65.039 (64.129)	
2022-04-01 01:41:41,520: ============================================================
2022-04-01 01:42:22,884: time cost, forward:0.12755843155256663, backward:0.03349296649401676, data cost:0.2547624291291705 
2022-04-01 01:42:22,884: ============================================================
2022-04-01 01:42:22,885: Epoch 18/31 Batch 3800/7662 eta: 11:53:19.180462	Training Loss 0.6061 (0.6141)	Training Prec@1 52.344 (53.601)	Training Prec@5 62.891 (64.164)	
2022-04-01 01:42:22,885: ============================================================
2022-04-01 01:43:05,051: time cost, forward:0.12776677331486613, backward:0.033487228467911447, data cost:0.25469031955193605 
2022-04-01 01:43:05,052: ============================================================
2022-04-01 01:43:05,052: Epoch 18/31 Batch 3900/7662 eta: 12:06:27.895867	Training Loss 0.5970 (0.6139)	Training Prec@1 59.766 (53.642)	Training Prec@5 68.359 (64.203)	
2022-04-01 01:43:05,052: ============================================================
2022-04-01 01:43:47,918: time cost, forward:0.12798214513202047, backward:0.03352009799963953, data cost:0.25476977603976264 
2022-04-01 01:43:47,919: ============================================================
2022-04-01 01:43:47,919: Epoch 18/31 Batch 4000/7662 eta: 12:17:48.582829	Training Loss 0.6069 (0.6138)	Training Prec@1 54.297 (53.673)	Training Prec@5 66.406 (64.231)	
2022-04-01 01:43:47,919: ============================================================
2022-04-01 01:44:32,290: time cost, forward:0.12826190980128122, backward:0.03350346586883984, data cost:0.2551683877613173 
2022-04-01 01:44:32,290: ============================================================
2022-04-01 01:44:32,291: Epoch 18/31 Batch 4100/7662 eta: 12:42:57.527082	Training Loss 0.6066 (0.6137)	Training Prec@1 56.641 (53.714)	Training Prec@5 64.844 (64.270)	
2022-04-01 01:44:32,291: ============================================================
2022-04-01 01:45:13,721: time cost, forward:0.12837502836584902, backward:0.03351878466904802, data cost:0.25495748299591653 
2022-04-01 01:45:13,722: ============================================================
2022-04-01 01:45:13,722: Epoch 18/31 Batch 4200/7662 eta: 11:51:42.939558	Training Loss 0.5969 (0.6135)	Training Prec@1 54.297 (53.746)	Training Prec@5 67.578 (64.296)	
2022-04-01 01:45:13,722: ============================================================
2022-04-01 01:45:54,484: time cost, forward:0.12826496829928896, backward:0.03349158530402777, data cost:0.2548728680771488 
2022-04-01 01:45:54,484: ============================================================
2022-04-01 01:45:54,484: Epoch 18/31 Batch 4300/7662 eta: 11:39:32.584747	Training Loss 0.6102 (0.6134)	Training Prec@1 52.344 (53.770)	Training Prec@5 63.086 (64.323)	
2022-04-01 01:45:54,485: ============================================================
2022-04-01 01:46:34,616: time cost, forward:0.12789296166250233, backward:0.033465040627054854, data cost:0.25491901711188386 
2022-04-01 01:46:34,616: ============================================================
2022-04-01 01:46:34,617: Epoch 18/31 Batch 4400/7662 eta: 11:28:03.620780	Training Loss 0.6127 (0.6133)	Training Prec@1 54.883 (53.811)	Training Prec@5 66.211 (64.362)	
2022-04-01 01:46:34,617: ============================================================
2022-04-01 01:47:15,871: time cost, forward:0.12802686116832657, backward:0.033443868941904625, data cost:0.2547118026803774 
2022-04-01 01:47:15,871: ============================================================
2022-04-01 01:47:15,871: Epoch 18/31 Batch 4500/7662 eta: 11:46:36.994563	Training Loss 0.6032 (0.6131)	Training Prec@1 53.906 (53.846)	Training Prec@5 64.844 (64.398)	
2022-04-01 01:47:15,871: ============================================================
2022-04-01 01:47:57,643: time cost, forward:0.12812888744111214, backward:0.03339544532868779, data cost:0.25469359156099913 
2022-04-01 01:47:57,644: ============================================================
2022-04-01 01:47:57,644: Epoch 18/31 Batch 4600/7662 eta: 11:54:47.405861	Training Loss 0.6100 (0.6130)	Training Prec@1 53.516 (53.877)	Training Prec@5 65.820 (64.427)	
2022-04-01 01:47:57,644: ============================================================
2022-04-01 01:48:39,712: time cost, forward:0.12819592169838576, backward:0.033378480114462934, data cost:0.2547344953918944 
2022-04-01 01:48:39,712: ============================================================
2022-04-01 01:48:39,712: Epoch 18/31 Batch 4700/7662 eta: 11:59:09.385556	Training Loss 0.6105 (0.6129)	Training Prec@1 54.688 (53.911)	Training Prec@5 63.477 (64.457)	
2022-04-01 01:48:39,713: ============================================================
2022-04-01 01:49:19,951: time cost, forward:0.12811361692626916, backward:0.033386630250851694, data cost:0.2544894248750166 
2022-04-01 01:49:19,952: ============================================================
2022-04-01 01:49:19,952: Epoch 18/31 Batch 4800/7662 eta: 11:27:13.249301	Training Loss 0.5990 (0.6127)	Training Prec@1 56.836 (53.950)	Training Prec@5 66.797 (64.492)	
2022-04-01 01:49:19,952: ============================================================
2022-04-01 01:50:01,246: time cost, forward:0.12777805435436068, backward:0.03335184709323526, data cost:0.25472235669893106 
2022-04-01 01:50:01,247: ============================================================
2022-04-01 01:50:01,247: Epoch 18/31 Batch 4900/7662 eta: 11:44:33.185151	Training Loss 0.6065 (0.6126)	Training Prec@1 56.250 (53.989)	Training Prec@5 66.016 (64.525)	
2022-04-01 01:50:01,247: ============================================================
2022-04-01 01:50:43,677: time cost, forward:0.12788416300088937, backward:0.03341776062236068, data cost:0.2547920040665543 
2022-04-01 01:50:43,677: ============================================================
2022-04-01 01:50:43,677: Epoch 18/31 Batch 5000/7662 eta: 12:03:13.100560	Training Loss 0.5968 (0.6125)	Training Prec@1 56.445 (54.035)	Training Prec@5 66.406 (64.569)	
2022-04-01 01:50:43,678: ============================================================
2022-04-01 01:51:23,958: time cost, forward:0.12762603995425487, backward:0.03339767862848498, data cost:0.25479783500309294 
2022-04-01 01:51:23,959: ============================================================
2022-04-01 01:51:23,959: Epoch 18/31 Batch 5100/7662 eta: 11:25:55.136659	Training Loss 0.5933 (0.6123)	Training Prec@1 59.180 (54.067)	Training Prec@5 71.484 (64.598)	
2022-04-01 01:51:23,959: ============================================================
2022-04-01 01:52:07,763: time cost, forward:0.1279228975461478, backward:0.033411773907998404, data cost:0.2549135598752975 
2022-04-01 01:52:07,763: ============================================================
2022-04-01 01:52:07,763: Epoch 18/31 Batch 5200/7662 eta: 12:25:10.951974	Training Loss 0.5940 (0.6122)	Training Prec@1 59.180 (54.109)	Training Prec@5 67.383 (64.636)	
2022-04-01 01:52:07,764: ============================================================
2022-04-01 01:52:48,832: time cost, forward:0.12788118972353585, backward:0.03340984821589539, data cost:0.2548484507991044 
2022-04-01 01:52:48,832: ============================================================
2022-04-01 01:52:48,833: Epoch 18/31 Batch 5300/7662 eta: 11:37:57.823171	Training Loss 0.6107 (0.6121)	Training Prec@1 50.977 (54.147)	Training Prec@5 66.406 (64.675)	
2022-04-01 01:52:48,833: ============================================================
2022-04-01 01:53:32,264: time cost, forward:0.12833322390602084, backward:0.033377203859208046, data cost:0.25475321281483976 
2022-04-01 01:53:32,264: ============================================================
2022-04-01 01:53:32,265: Epoch 18/31 Batch 5400/7662 eta: 12:17:23.748858	Training Loss 0.6176 (0.6119)	Training Prec@1 54.492 (54.187)	Training Prec@5 66.602 (64.713)	
2022-04-01 01:53:32,265: ============================================================
2022-04-01 01:54:14,343: time cost, forward:0.12862277759337645, backward:0.03335666838592346, data cost:0.25456500391588144 
2022-04-01 01:54:14,343: ============================================================
2022-04-01 01:54:14,344: Epoch 18/31 Batch 5500/7662 eta: 11:53:43.391094	Training Loss 0.6125 (0.6117)	Training Prec@1 52.930 (54.231)	Training Prec@5 63.867 (64.754)	
2022-04-01 01:54:14,344: ============================================================
2022-04-01 01:54:58,400: time cost, forward:0.12907671149148753, backward:0.03336513287298465, data cost:0.2545179859572893 
2022-04-01 01:54:58,400: ============================================================
2022-04-01 01:54:58,400: Epoch 18/31 Batch 5600/7662 eta: 12:26:32.094304	Training Loss 0.6105 (0.6116)	Training Prec@1 53.906 (54.274)	Training Prec@5 66.406 (64.792)	
2022-04-01 01:54:58,401: ============================================================
2022-04-01 01:55:37,223: time cost, forward:0.12883172844309287, backward:0.03333128613533733, data cost:0.254283239180884 
2022-04-01 01:55:37,224: ============================================================
2022-04-01 01:55:37,224: Epoch 18/31 Batch 5700/7662 eta: 10:57:12.662668	Training Loss 0.5999 (0.6114)	Training Prec@1 55.273 (54.315)	Training Prec@5 64.453 (64.828)	
2022-04-01 01:55:37,224: ============================================================
2022-04-01 01:56:20,551: time cost, forward:0.12921274129759341, backward:0.03337883328462309, data cost:0.2541439885167258 
2022-04-01 01:56:20,551: ============================================================
2022-04-01 01:56:20,551: Epoch 18/31 Batch 5800/7662 eta: 12:12:44.003822	Training Loss 0.9061 (0.6124)	Training Prec@1 0.000 (54.188)	Training Prec@5 0.000 (64.689)	
2022-04-01 01:56:20,552: ============================================================
2022-04-01 01:57:03,820: time cost, forward:0.12944756493485163, backward:0.033379371377609005, data cost:0.254186437420571 
2022-04-01 01:57:03,821: ============================================================
2022-04-01 01:57:03,821: Epoch 18/31 Batch 5900/7662 eta: 12:11:01.905875	Training Loss 0.9004 (0.6173)	Training Prec@1 0.000 (53.269)	Training Prec@5 0.000 (63.593)	
2022-04-01 01:57:03,821: ============================================================
2022-04-01 01:57:45,137: time cost, forward:0.12920436403675464, backward:0.0333626458676264, data cost:0.2543658621610453 
2022-04-01 01:57:45,137: ============================================================
2022-04-01 01:57:45,137: Epoch 18/31 Batch 6000/7662 eta: 11:37:20.595794	Training Loss 0.8932 (0.6220)	Training Prec@1 0.000 (52.381)	Training Prec@5 0.000 (62.533)	
2022-04-01 01:57:45,138: ============================================================
2022-04-01 01:58:26,090: time cost, forward:0.12926728499875847, backward:0.03335921243285132, data cost:0.25417758199226115 
2022-04-01 01:58:26,091: ============================================================
2022-04-01 01:58:26,091: Epoch 18/31 Batch 6100/7662 eta: 11:30:32.424216	Training Loss 0.8847 (0.6264)	Training Prec@1 0.000 (51.523)	Training Prec@5 0.000 (61.508)	
2022-04-01 01:58:26,091: ============================================================
2022-04-01 01:59:06,850: time cost, forward:0.1294664030479681, backward:0.033359370129322656, data cost:0.2538293186436355 
2022-04-01 01:59:06,850: ============================================================
2022-04-01 01:59:06,851: Epoch 18/31 Batch 6200/7662 eta: 11:26:35.473784	Training Loss 0.8755 (0.6304)	Training Prec@1 0.000 (50.691)	Training Prec@5 0.000 (60.515)	
2022-04-01 01:59:06,851: ============================================================
2022-04-01 01:59:49,933: time cost, forward:0.12961486919207466, backward:0.03337822090653999, data cost:0.25387823284571276 
2022-04-01 01:59:49,933: ============================================================
2022-04-01 01:59:49,934: Epoch 18/31 Batch 6300/7662 eta: 12:05:00.317981	Training Loss 0.8610 (0.6342)	Training Prec@1 0.000 (49.887)	Training Prec@5 0.000 (59.555)	
2022-04-01 01:59:49,934: ============================================================
2022-04-01 02:00:29,945: time cost, forward:0.12951775308064437, backward:0.03332274238436199, data cost:0.25376765361743564 
2022-04-01 02:00:29,945: ============================================================
2022-04-01 02:00:29,946: Epoch 18/31 Batch 6400/7662 eta: 11:12:39.735869	Training Loss 0.8480 (0.6376)	Training Prec@1 0.000 (49.107)	Training Prec@5 0.000 (58.624)	
2022-04-01 02:00:29,946: ============================================================
2022-04-01 02:01:10,879: time cost, forward:0.12931236029955254, backward:0.033307742184722475, data cost:0.25387228028666775 
2022-04-01 02:01:10,879: ============================================================
2022-04-01 02:01:10,879: Epoch 18/31 Batch 6500/7662 eta: 11:27:28.319990	Training Loss 0.8405 (0.6408)	Training Prec@1 0.000 (48.352)	Training Prec@5 0.000 (57.723)	
2022-04-01 02:01:10,879: ============================================================
2022-04-01 02:01:54,965: time cost, forward:0.12945014018870823, backward:0.03332313520833568, data cost:0.254084353519942 
2022-04-01 02:01:54,966: ============================================================
2022-04-01 02:01:54,966: Epoch 18/31 Batch 6600/7662 eta: 12:19:41.583822	Training Loss 0.8383 (0.6438)	Training Prec@1 0.000 (47.619)	Training Prec@5 0.000 (56.848)	
2022-04-01 02:01:54,966: ============================================================
2022-04-01 02:02:37,359: time cost, forward:0.1295608574462517, backward:0.03333427030873985, data cost:0.25406695291308756 
2022-04-01 02:02:37,359: ============================================================
2022-04-01 02:02:37,359: Epoch 18/31 Batch 6700/7662 eta: 11:50:34.623435	Training Loss 0.8336 (0.6467)	Training Prec@1 0.000 (46.908)	Training Prec@5 0.000 (56.000)	
2022-04-01 02:02:37,359: ============================================================
2022-04-01 02:03:18,683: time cost, forward:0.12958155770322158, backward:0.03331533939211767, data cost:0.25396864549923265 
2022-04-01 02:03:18,683: ============================================================
2022-04-01 02:03:18,684: Epoch 18/31 Batch 6800/7662 eta: 11:31:58.222403	Training Loss 0.8324 (0.6494)	Training Prec@1 0.000 (46.218)	Training Prec@5 0.000 (55.176)	
2022-04-01 02:03:18,684: ============================================================
2022-04-01 02:03:59,430: time cost, forward:0.12966388366346446, backward:0.03332405778735872, data cost:0.25375850142940504 
2022-04-01 02:03:59,430: ============================================================
2022-04-01 02:03:59,430: Epoch 18/31 Batch 6900/7662 eta: 11:21:37.043407	Training Loss 0.8294 (0.6521)	Training Prec@1 0.000 (45.548)	Training Prec@5 0.000 (54.377)	
2022-04-01 02:03:59,431: ============================================================
2022-04-01 02:04:41,831: time cost, forward:0.12999969803447262, backward:0.03336644911871653, data cost:0.2534880386725343 
2022-04-01 02:04:41,832: ============================================================
2022-04-01 02:04:41,832: Epoch 18/31 Batch 7000/7662 eta: 11:48:35.842351	Training Loss 0.8330 (0.6547)	Training Prec@1 0.000 (44.898)	Training Prec@5 0.000 (53.600)	
2022-04-01 02:04:41,832: ============================================================
2022-04-01 02:05:23,857: time cost, forward:0.13027143112319106, backward:0.03340845703155092, data cost:0.2532235766350509 
2022-04-01 02:05:23,857: ============================================================
2022-04-01 02:05:23,858: Epoch 18/31 Batch 7100/7662 eta: 11:41:36.571157	Training Loss 0.8305 (0.6572)	Training Prec@1 0.000 (44.265)	Training Prec@5 0.000 (52.845)	
2022-04-01 02:05:23,858: ============================================================
2022-04-01 02:06:04,345: time cost, forward:0.1302074747526707, backward:0.03339326138263909, data cost:0.2531234211583223 
2022-04-01 02:06:04,346: ============================================================
2022-04-01 02:06:04,346: Epoch 18/31 Batch 7200/7662 eta: 11:15:16.029206	Training Loss 0.8309 (0.6596)	Training Prec@1 0.000 (43.650)	Training Prec@5 0.000 (52.111)	
2022-04-01 02:06:04,346: ============================================================
2022-04-01 02:06:46,472: time cost, forward:0.13030133202951694, backward:0.03341063337303838, data cost:0.25307352406666006 
2022-04-01 02:06:46,472: ============================================================
2022-04-01 02:06:46,473: Epoch 18/31 Batch 7300/7662 eta: 11:41:53.806535	Training Loss 0.8325 (0.6619)	Training Prec@1 0.000 (43.052)	Training Prec@5 0.000 (51.397)	
2022-04-01 02:06:46,473: ============================================================
2022-04-01 02:07:29,335: time cost, forward:0.13069291687733517, backward:0.033451744021072725, data cost:0.2528034611189103 
2022-04-01 02:07:29,335: ============================================================
2022-04-01 02:07:29,335: Epoch 18/31 Batch 7400/7662 eta: 11:53:26.626043	Training Loss 0.8296 (0.6642)	Training Prec@1 0.000 (42.470)	Training Prec@5 0.000 (50.702)	
2022-04-01 02:07:29,336: ============================================================
2022-04-01 02:08:09,448: time cost, forward:0.1306442468225805, backward:0.033466184881627205, data cost:0.2526178406085757 
2022-04-01 02:08:09,448: ============================================================
2022-04-01 02:08:09,448: Epoch 18/31 Batch 7500/7662 eta: 11:07:00.051304	Training Loss 0.8293 (0.6664)	Training Prec@1 0.000 (41.904)	Training Prec@5 0.000 (50.026)	
2022-04-01 02:08:09,448: ============================================================
2022-04-01 02:08:52,021: time cost, forward:0.1307683360311511, backward:0.03347477907882833, data cost:0.25259608107972326 
2022-04-01 02:08:52,021: ============================================================
2022-04-01 02:08:52,022: Epoch 18/31 Batch 7600/7662 eta: 11:47:12.433115	Training Loss 0.8312 (0.6686)	Training Prec@1 0.000 (41.353)	Training Prec@5 0.000 (49.368)	
2022-04-01 02:08:52,022: ============================================================
2022-04-01 02:09:20,898: Epoch: 18/31 eta: 11:46:45.611904	Training Loss 0.8310 (0.6699)	Training Prec@1 0.000 (41.013)	Training Prec@5 0.000 (48.962)
2022-04-01 02:09:20,899: ============================================================
2022-04-01 02:10:02,072: time cost, forward:0.11832855205343228, backward:0.030989220648100883, data cost:0.2626037404994772 
2022-04-01 02:10:02,073: ============================================================
2022-04-01 02:10:02,073: Epoch 19/31 Batch 100/7662 eta: 11:20:39.028844	Training Loss 0.8306 (0.8305)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.008)	
2022-04-01 02:10:02,073: ============================================================
2022-04-01 02:10:43,458: time cost, forward:0.11729746248254824, backward:0.03183121777060044, data cost:0.2635466561245559 
2022-04-01 02:10:43,458: ============================================================
2022-04-01 02:10:43,459: Epoch 19/31 Batch 200/7662 eta: 11:25:40.294400	Training Loss 0.8307 (0.8306)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.010)	
2022-04-01 02:10:43,459: ============================================================
2022-04-01 02:11:23,624: time cost, forward:0.11488066548886507, backward:0.03203625344113761, data cost:0.26191073994971437 
2022-04-01 02:11:23,624: ============================================================
2022-04-01 02:11:23,624: Epoch 19/31 Batch 300/7662 eta: 11:04:47.362313	Training Loss 0.8294 (0.8307)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.010)	
2022-04-01 02:11:23,624: ============================================================
2022-04-01 02:12:05,911: time cost, forward:0.11928080078354455, backward:0.03226223685090106, data cost:0.260772190595928 
2022-04-01 02:12:05,912: ============================================================
2022-04-01 02:12:05,912: Epoch 19/31 Batch 400/7662 eta: 11:39:12.185339	Training Loss 0.8303 (0.8307)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.011)	
2022-04-01 02:12:05,912: ============================================================
2022-04-01 02:12:47,335: time cost, forward:0.12049873319560875, backward:0.03224163256092874, data cost:0.25983607362888617 
2022-04-01 02:12:47,335: ============================================================
2022-04-01 02:12:47,335: Epoch 19/31 Batch 500/7662 eta: 11:24:13.490382	Training Loss 0.8304 (0.8306)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.011)	
2022-04-01 02:12:47,335: ============================================================
2022-04-01 02:13:29,921: time cost, forward:0.12471839661192217, backward:0.032594637799143594, data cost:0.2575145408585792 
2022-04-01 02:13:29,922: ============================================================
2022-04-01 02:13:29,922: Epoch 19/31 Batch 600/7662 eta: 11:42:43.747702	Training Loss 0.8318 (0.8306)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.010)	
2022-04-01 02:13:29,922: ============================================================
2022-04-01 02:14:11,661: time cost, forward:0.12453113877892664, backward:0.032600559731239244, data cost:0.257963553689239 
2022-04-01 02:14:11,661: ============================================================
2022-04-01 02:14:11,661: Epoch 19/31 Batch 700/7662 eta: 11:28:03.074136	Training Loss 0.8298 (0.8306)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.195 (0.011)	
2022-04-01 02:14:11,661: ============================================================
2022-04-01 02:14:53,473: time cost, forward:0.12531247186720446, backward:0.03267890252219571, data cost:0.25733586366245237 
2022-04-01 02:14:53,474: ============================================================
2022-04-01 02:14:53,474: Epoch 19/31 Batch 800/7662 eta: 11:28:33.738124	Training Loss 0.8322 (0.8306)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.011)	
2022-04-01 02:14:53,474: ============================================================
2022-04-01 02:15:34,688: time cost, forward:0.1258731317997509, backward:0.032769474755139714, data cost:0.25642758826657847 
2022-04-01 02:15:34,689: ============================================================
2022-04-01 02:15:34,689: Epoch 19/31 Batch 900/7662 eta: 11:18:02.234226	Training Loss 0.8315 (0.8306)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.013)	
2022-04-01 02:15:34,689: ============================================================
2022-04-01 02:16:16,665: time cost, forward:0.1267574955154587, backward:0.032779068560213655, data cost:0.25593546370008924 
2022-04-01 02:16:16,666: ============================================================
2022-04-01 02:16:16,666: Epoch 19/31 Batch 1000/7662 eta: 11:29:52.400271	Training Loss 0.8312 (0.8306)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.012)	
2022-04-01 02:16:16,666: ============================================================
2022-04-01 02:16:59,902: time cost, forward:0.12738940778702795, backward:0.03292660652452214, data cost:0.25668931159244224 
2022-04-01 02:16:59,902: ============================================================
2022-04-01 02:16:59,902: Epoch 19/31 Batch 1100/7662 eta: 11:49:50.866582	Training Loss 0.8320 (0.8306)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.011)	
2022-04-01 02:16:59,903: ============================================================
2022-04-01 02:17:39,339: time cost, forward:0.12617153361800115, backward:0.03279623973359656, data cost:0.25608348130583264 
2022-04-01 02:17:39,339: ============================================================
2022-04-01 02:17:39,339: Epoch 19/31 Batch 1200/7662 eta: 10:46:48.451888	Training Loss 0.8293 (0.8305)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.012)	
2022-04-01 02:17:39,339: ============================================================
2022-04-01 02:18:22,762: time cost, forward:0.1273339962023235, backward:0.032866572672995906, data cost:0.2562812710836174 
2022-04-01 02:18:22,762: ============================================================
2022-04-01 02:18:22,762: Epoch 19/31 Batch 1300/7662 eta: 11:51:27.966131	Training Loss 0.8280 (0.8305)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.012)	
2022-04-01 02:18:22,762: ============================================================
2022-04-01 02:19:06,415: time cost, forward:0.12873025141587166, backward:0.0329113345729018, data cost:0.25631090229626124 
2022-04-01 02:19:06,415: ============================================================
2022-04-01 02:19:06,416: Epoch 19/31 Batch 1400/7662 eta: 11:54:30.605743	Training Loss 0.8293 (0.8305)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.012)	
2022-04-01 02:19:06,416: ============================================================
2022-04-01 02:19:47,366: time cost, forward:0.12795838298123227, backward:0.03293619146340684, data cost:0.25637260813010065 
2022-04-01 02:19:47,367: ============================================================
2022-04-01 02:19:47,367: Epoch 19/31 Batch 1500/7662 eta: 11:09:36.092734	Training Loss 0.8321 (0.8305)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.012)	
2022-04-01 02:19:47,367: ============================================================
2022-04-01 02:20:29,079: time cost, forward:0.12792537195970297, backward:0.03296286065254903, data cost:0.25625737910720986 
2022-04-01 02:20:29,079: ============================================================
2022-04-01 02:20:29,079: Epoch 19/31 Batch 1600/7662 eta: 11:21:21.062949	Training Loss 0.8287 (0.8305)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.012)	
2022-04-01 02:20:29,079: ============================================================
2022-04-01 02:21:10,601: time cost, forward:0.12884706423660108, backward:0.033007017649784726, data cost:0.25526690202435726 
2022-04-01 02:21:10,601: ============================================================
2022-04-01 02:21:10,602: Epoch 19/31 Batch 1700/7662 eta: 11:17:33.242234	Training Loss 0.8300 (0.8305)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.012)	
2022-04-01 02:21:10,602: ============================================================
2022-04-01 02:21:52,319: time cost, forward:0.1284454554037759, backward:0.03297620286141057, data cost:0.25571457924877294 
2022-04-01 02:21:52,319: ============================================================
2022-04-01 02:21:52,320: Epoch 19/31 Batch 1800/7662 eta: 11:20:03.114869	Training Loss 0.8307 (0.8304)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.012)	
2022-04-01 02:21:52,320: ============================================================
2022-04-01 02:22:33,808: time cost, forward:0.1281188552539056, backward:0.03298836045669467, data cost:0.25585829590169173 
2022-04-01 02:22:33,809: ============================================================
2022-04-01 02:22:33,809: Epoch 19/31 Batch 1900/7662 eta: 11:15:38.061248	Training Loss 0.8304 (0.8304)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.012)	
2022-04-01 02:22:33,809: ============================================================
2022-04-01 02:23:15,249: time cost, forward:0.12805362079309307, backward:0.03301785229563176, data cost:0.2558157865019546 
2022-04-01 02:23:15,250: ============================================================
2022-04-01 02:23:15,250: Epoch 19/31 Batch 2000/7662 eta: 11:14:09.148138	Training Loss 0.8299 (0.8304)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.012)	
2022-04-01 02:23:15,250: ============================================================
2022-04-01 02:23:56,871: time cost, forward:0.12786667275394695, backward:0.03303894455970157, data cost:0.25591323385924714 
2022-04-01 02:23:56,872: ============================================================
2022-04-01 02:23:56,872: Epoch 19/31 Batch 2100/7662 eta: 11:16:24.316327	Training Loss 0.8294 (0.8304)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.013)	
2022-04-01 02:23:56,872: ============================================================
2022-04-01 02:24:38,738: time cost, forward:0.12803467244872074, backward:0.03310269201381904, data cost:0.2557428888214236 
2022-04-01 02:24:38,738: ============================================================
2022-04-01 02:24:38,739: Epoch 19/31 Batch 2200/7662 eta: 11:19:41.258041	Training Loss 0.8311 (0.8303)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.013)	
2022-04-01 02:24:38,739: ============================================================
2022-04-01 02:25:21,061: time cost, forward:0.12757246076360687, backward:0.03312749725779848, data cost:0.25637829765230224 
2022-04-01 02:25:21,062: ============================================================
2022-04-01 02:25:21,062: Epoch 19/31 Batch 2300/7662 eta: 11:26:23.612298	Training Loss 0.8290 (0.8303)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.013)	
2022-04-01 02:25:21,062: ============================================================
2022-04-01 02:26:02,255: time cost, forward:0.12682753078338255, backward:0.03308949037212389, data cost:0.25702901798866845 
2022-04-01 02:26:02,255: ============================================================
2022-04-01 02:26:02,256: Epoch 19/31 Batch 2400/7662 eta: 11:07:22.999191	Training Loss 0.8278 (0.8303)	Training Prec@1 0.195 (0.002)	Training Prec@5 0.195 (0.012)	
2022-04-01 02:26:02,256: ============================================================
2022-04-01 02:26:43,396: time cost, forward:0.12655796065908664, backward:0.03306680681611023, data cost:0.2570726853363416 
2022-04-01 02:26:43,396: ============================================================
2022-04-01 02:26:43,397: Epoch 19/31 Batch 2500/7662 eta: 11:05:50.854570	Training Loss 0.8303 (0.8303)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.012)	
2022-04-01 02:26:43,397: ============================================================
2022-04-01 02:27:25,017: time cost, forward:0.12684149327485458, backward:0.03309603579551635, data cost:0.2567192074334268 
2022-04-01 02:27:25,017: ============================================================
2022-04-01 02:27:25,017: Epoch 19/31 Batch 2600/7662 eta: 11:12:55.079297	Training Loss 0.8278 (0.8302)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.013)	
2022-04-01 02:27:25,018: ============================================================
2022-04-01 02:28:05,635: time cost, forward:0.12654040079728104, backward:0.033122994008440584, data cost:0.2565832875666242 
2022-04-01 02:28:05,636: ============================================================
2022-04-01 02:28:05,636: Epoch 19/31 Batch 2700/7662 eta: 10:56:02.101862	Training Loss 0.8323 (0.8302)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.013)	
2022-04-01 02:28:05,636: ============================================================
2022-04-01 02:28:47,079: time cost, forward:0.125892270245949, backward:0.03312864376843593, data cost:0.257149178371041 
2022-04-01 02:28:47,080: ============================================================
2022-04-01 02:28:47,080: Epoch 19/31 Batch 2800/7662 eta: 11:08:40.834800	Training Loss 0.8297 (0.8302)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.013)	
2022-04-01 02:28:47,080: ============================================================
2022-04-01 02:29:29,765: time cost, forward:0.1262518259195181, backward:0.03318386482509838, data cost:0.2571162414287608 
2022-04-01 02:29:29,766: ============================================================
2022-04-01 02:29:29,766: Epoch 19/31 Batch 2900/7662 eta: 11:28:00.434974	Training Loss 0.8297 (0.8302)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.014)	
2022-04-01 02:29:29,766: ============================================================
2022-04-01 02:30:10,900: time cost, forward:0.1267298256090857, backward:0.03322579130088142, data cost:0.2563930839329968 
2022-04-01 02:30:10,901: ============================================================
2022-04-01 02:30:10,901: Epoch 19/31 Batch 3000/7662 eta: 11:02:19.176119	Training Loss 0.8286 (0.8301)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.014)	
2022-04-01 02:30:10,901: ============================================================
2022-04-01 02:30:54,095: time cost, forward:0.12752078109573803, backward:0.03326147831267178, data cost:0.25608479942033735 
2022-04-01 02:30:54,095: ============================================================
2022-04-01 02:30:54,095: Epoch 19/31 Batch 3100/7662 eta: 11:34:45.617377	Training Loss 0.8282 (0.8301)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.013)	
2022-04-01 02:30:54,095: ============================================================
2022-04-01 02:31:35,719: time cost, forward:0.1272410796410816, backward:0.0332318623016014, data cost:0.256342052928952 
2022-04-01 02:31:35,719: ============================================================
2022-04-01 02:31:35,719: Epoch 19/31 Batch 3200/7662 eta: 11:08:48.348385	Training Loss 0.8302 (0.8301)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.014)	
2022-04-01 02:31:35,719: ============================================================
2022-04-01 02:32:15,141: time cost, forward:0.12668727072270286, backward:0.033187781293741246, data cost:0.25625740126719365 
2022-04-01 02:32:15,142: ============================================================
2022-04-01 02:32:15,142: Epoch 19/31 Batch 3300/7662 eta: 10:32:46.640980	Training Loss 0.8288 (0.8300)	Training Prec@1 0.195 (0.003)	Training Prec@5 0.195 (0.014)	
2022-04-01 02:32:15,142: ============================================================
2022-04-01 02:32:56,428: time cost, forward:0.12665547409910566, backward:0.033172523600103296, data cost:0.2561883603028951 
2022-04-01 02:32:56,428: ============================================================
2022-04-01 02:32:56,429: Epoch 19/31 Batch 3400/7662 eta: 11:02:00.729426	Training Loss 0.8277 (0.8300)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.014)	
2022-04-01 02:32:56,429: ============================================================
2022-04-01 02:33:37,738: time cost, forward:0.12651112782134094, backward:0.03314091832885132, data cost:0.2562667064988364 
2022-04-01 02:33:37,739: ============================================================
2022-04-01 02:33:37,739: Epoch 19/31 Batch 3500/7662 eta: 11:01:41.994120	Training Loss 0.8290 (0.8300)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.014)	
2022-04-01 02:33:37,739: ============================================================
2022-04-01 02:34:18,833: time cost, forward:0.12631674732357703, backward:0.0331175830768989, data cost:0.25634554599052867 
2022-04-01 02:34:18,834: ============================================================
2022-04-01 02:34:18,834: Epoch 19/31 Batch 3600/7662 eta: 10:57:34.137564	Training Loss 0.8278 (0.8300)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.014)	
2022-04-01 02:34:18,834: ============================================================
2022-04-01 02:35:00,777: time cost, forward:0.12652973375890217, backward:0.03315378434273255, data cost:0.25619058713425685 
2022-04-01 02:35:00,777: ============================================================
2022-04-01 02:35:00,777: Epoch 19/31 Batch 3700/7662 eta: 11:10:26.643743	Training Loss 0.8274 (0.8299)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.015)	
2022-04-01 02:35:00,777: ============================================================
2022-04-01 02:35:41,554: time cost, forward:0.12605233969390942, backward:0.03311276975572972, data cost:0.25648704256688837 
2022-04-01 02:35:41,554: ============================================================
2022-04-01 02:35:41,554: Epoch 19/31 Batch 3800/7662 eta: 10:51:07.451962	Training Loss 0.8293 (0.8299)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.195 (0.015)	
2022-04-01 02:35:41,555: ============================================================
2022-04-01 02:36:21,315: time cost, forward:0.12561397969524016, backward:0.03311121497407391, data cost:0.2564528019008162 
2022-04-01 02:36:21,315: ============================================================
2022-04-01 02:36:21,315: Epoch 19/31 Batch 3900/7662 eta: 10:34:13.905483	Training Loss 0.8287 (0.8298)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.015)	
2022-04-01 02:36:21,315: ============================================================
2022-04-01 02:37:02,565: time cost, forward:0.12528975649635982, backward:0.03311213632618436, data cost:0.256710600632374 
2022-04-01 02:37:02,565: ============================================================
2022-04-01 02:37:02,566: Epoch 19/31 Batch 4000/7662 eta: 10:57:18.239903	Training Loss 0.8287 (0.8298)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.015)	
2022-04-01 02:37:02,566: ============================================================
2022-04-01 02:37:43,420: time cost, forward:0.12484192249105452, backward:0.033110966883685186, data cost:0.2569914120643655 
2022-04-01 02:37:43,421: ============================================================
2022-04-01 02:37:43,421: Epoch 19/31 Batch 4100/7662 eta: 10:50:19.595269	Training Loss 0.8271 (0.8298)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.015)	
2022-04-01 02:37:43,421: ============================================================
2022-04-01 02:38:24,210: time cost, forward:0.12440997806439147, backward:0.03308388947815973, data cost:0.2572500346870359 
2022-04-01 02:38:24,210: ============================================================
2022-04-01 02:38:24,210: Epoch 19/31 Batch 4200/7662 eta: 10:48:36.126976	Training Loss 0.8253 (0.8297)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.016)	
2022-04-01 02:38:24,211: ============================================================
2022-04-01 02:39:06,222: time cost, forward:0.12399261728168283, backward:0.033059654859199886, data cost:0.2578331049333259 
2022-04-01 02:39:06,222: ============================================================
2022-04-01 02:39:06,223: Epoch 19/31 Batch 4300/7662 eta: 11:07:20.603922	Training Loss 0.8282 (0.8297)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.016)	
2022-04-01 02:39:06,223: ============================================================
2022-04-01 02:39:46,134: time cost, forward:0.12360325063404969, backward:0.03301735790406175, data cost:0.25788653371116743 
2022-04-01 02:39:46,134: ============================================================
2022-04-01 02:39:46,135: Epoch 19/31 Batch 4400/7662 eta: 10:33:18.931073	Training Loss 0.8276 (0.8296)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.016)	
2022-04-01 02:39:46,135: ============================================================
2022-04-01 02:40:27,531: time cost, forward:0.12322405545704627, backward:0.03298005455731021, data cost:0.25829469789317194 
2022-04-01 02:40:27,531: ============================================================
2022-04-01 02:40:27,532: Epoch 19/31 Batch 4500/7662 eta: 10:56:11.411528	Training Loss 0.8278 (0.8296)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.016)	
2022-04-01 02:40:27,532: ============================================================
2022-04-01 02:41:09,426: time cost, forward:0.12287659509256109, backward:0.032958080105533756, data cost:0.2587500966924977 
2022-04-01 02:41:09,426: ============================================================
2022-04-01 02:41:09,426: Epoch 19/31 Batch 4600/7662 eta: 11:03:23.093838	Training Loss 0.8272 (0.8295)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.016)	
2022-04-01 02:41:09,427: ============================================================
2022-04-01 02:41:48,961: time cost, forward:0.12256025192356536, backward:0.03295915551478874, data cost:0.25864174797778994 
2022-04-01 02:41:48,961: ============================================================
2022-04-01 02:41:48,962: Epoch 19/31 Batch 4700/7662 eta: 10:25:21.619428	Training Loss 0.8268 (0.8295)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.016)	
2022-04-01 02:41:48,962: ============================================================
2022-04-01 02:42:28,952: time cost, forward:0.12231957303854196, backward:0.03296008545250961, data cost:0.25857815565628717 
2022-04-01 02:42:28,952: ============================================================
2022-04-01 02:42:28,952: Epoch 19/31 Batch 4800/7662 eta: 10:31:53.780652	Training Loss 0.8269 (0.8294)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-04-01 02:42:28,952: ============================================================
2022-04-01 02:43:10,597: time cost, forward:0.1224365816429747, backward:0.03297413809247395, data cost:0.25850515415240705 
2022-04-01 02:43:10,598: ============================================================
2022-04-01 02:43:10,598: Epoch 19/31 Batch 4900/7662 eta: 10:57:21.594717	Training Loss 0.8251 (0.8293)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-04-01 02:43:10,598: ============================================================
2022-04-01 02:43:51,963: time cost, forward:0.12244536738844962, backward:0.032893054221577345, data cost:0.25856356011268783 
2022-04-01 02:43:51,963: ============================================================
2022-04-01 02:43:51,963: Epoch 19/31 Batch 5000/7662 eta: 10:52:14.383601	Training Loss 0.8254 (0.8293)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-04-01 02:43:51,963: ============================================================
2022-04-01 02:44:34,808: time cost, forward:0.12290034852417854, backward:0.032756776617049795, data cost:0.2585086570952214 
2022-04-01 02:44:34,808: ============================================================
2022-04-01 02:44:34,808: Epoch 19/31 Batch 5100/7662 eta: 11:14:51.295926	Training Loss 0.8263 (0.8292)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-04-01 02:44:34,808: ============================================================
2022-04-01 02:45:17,056: time cost, forward:0.12345228004418879, backward:0.032597074464642786, data cost:0.2582841640849553 
2022-04-01 02:45:17,056: ============================================================
2022-04-01 02:45:17,057: Epoch 19/31 Batch 5200/7662 eta: 11:04:45.696580	Training Loss 0.8251 (0.8291)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.391 (0.018)	
2022-04-01 02:45:17,057: ============================================================
2022-04-01 02:46:01,223: time cost, forward:0.12392119687331085, backward:0.032448109781366405, data cost:0.2584615457415648 
2022-04-01 02:46:01,223: ============================================================
2022-04-01 02:46:01,224: Epoch 19/31 Batch 5300/7662 eta: 11:34:12.406357	Training Loss 0.8255 (0.8290)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.019)	
2022-04-01 02:46:01,224: ============================================================
2022-04-01 02:46:45,917: time cost, forward:0.1248989540198309, backward:0.03235267175305969, data cost:0.2581875938070021 
2022-04-01 02:46:45,918: ============================================================
2022-04-01 02:46:45,918: Epoch 19/31 Batch 5400/7662 eta: 11:41:45.383973	Training Loss 0.8244 (0.8289)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.019)	
2022-04-01 02:46:45,918: ============================================================
2022-04-01 02:47:26,635: time cost, forward:0.12514190553296456, backward:0.03237848863707475, data cost:0.2577483746372021 
2022-04-01 02:47:26,635: ============================================================
2022-04-01 02:47:26,635: Epoch 19/31 Batch 5500/7662 eta: 10:38:37.611591	Training Loss 0.8238 (0.8288)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.020)	
2022-04-01 02:47:26,635: ============================================================
2022-04-01 02:48:10,508: time cost, forward:0.12544573454116792, backward:0.03241153520480887, data cost:0.2578343958870857 
2022-04-01 02:48:10,508: ============================================================
2022-04-01 02:48:10,508: Epoch 19/31 Batch 5600/7662 eta: 11:27:23.699315	Training Loss 0.8222 (0.8287)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.021)	
2022-04-01 02:48:10,508: ============================================================
2022-04-01 02:48:51,114: time cost, forward:0.12525779578869417, backward:0.032388495528754446, data cost:0.25786816000750157 
2022-04-01 02:48:51,115: ============================================================
2022-04-01 02:48:51,115: Epoch 19/31 Batch 5700/7662 eta: 10:35:32.622825	Training Loss 0.8225 (0.8286)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.022)	
2022-04-01 02:48:51,115: ============================================================
2022-04-01 02:49:35,692: time cost, forward:0.12595534168413783, backward:0.03245405707611752, data cost:0.2576225051429276 
2022-04-01 02:49:35,692: ============================================================
2022-04-01 02:49:35,692: Epoch 19/31 Batch 5800/7662 eta: 11:36:56.861149	Training Loss 0.8192 (0.8284)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.023)	
2022-04-01 02:49:35,693: ============================================================
2022-04-01 02:50:16,411: time cost, forward:0.1258439547653056, backward:0.03246582821478862, data cost:0.2575619571955452 
2022-04-01 02:50:16,411: ============================================================
2022-04-01 02:50:16,411: Epoch 19/31 Batch 5900/7662 eta: 10:35:56.377597	Training Loss 0.8208 (0.8283)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.025)	
2022-04-01 02:50:16,411: ============================================================
2022-04-01 02:50:58,221: time cost, forward:0.12581596010465346, backward:0.03247269170843456, data cost:0.2576181888580322 
2022-04-01 02:50:58,221: ============================================================
2022-04-01 02:50:58,221: Epoch 19/31 Batch 6000/7662 eta: 10:52:16.943813	Training Loss 0.8182 (0.8281)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.195 (0.026)	
2022-04-01 02:50:58,221: ============================================================
2022-04-01 02:51:38,292: time cost, forward:0.12554091167246675, backward:0.032473387220175974, data cost:0.25763949739637876 
2022-04-01 02:51:38,292: ============================================================
2022-04-01 02:51:38,292: Epoch 19/31 Batch 6100/7662 eta: 10:24:29.277900	Training Loss 0.8180 (0.8280)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.195 (0.028)	
2022-04-01 02:51:38,292: ============================================================
2022-04-01 02:52:18,634: time cost, forward:0.12563812942307964, backward:0.032506526372263096, data cost:0.257311498413049 
2022-04-01 02:52:18,635: ============================================================
2022-04-01 02:52:18,635: Epoch 19/31 Batch 6200/7662 eta: 10:28:02.679753	Training Loss 0.8159 (0.8278)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.031)	
2022-04-01 02:52:18,635: ============================================================
2022-04-01 02:52:59,059: time cost, forward:0.12562055534021233, backward:0.03251927454219127, data cost:0.25712980105964356 
2022-04-01 02:52:59,059: ============================================================
2022-04-01 02:52:59,060: Epoch 19/31 Batch 6300/7662 eta: 10:28:39.376952	Training Loss 0.8131 (0.8276)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.034)	
2022-04-01 02:52:59,060: ============================================================
2022-04-01 02:53:38,911: time cost, forward:0.1254162687047382, backward:0.032529198093178835, data cost:0.2570538597938548 
2022-04-01 02:53:38,911: ============================================================
2022-04-01 02:53:38,911: Epoch 19/31 Batch 6400/7662 eta: 10:19:04.267859	Training Loss 0.8098 (0.8273)	Training Prec@1 0.391 (0.010)	Training Prec@5 0.391 (0.039)	
2022-04-01 02:53:38,911: ============================================================
2022-04-01 02:54:19,485: time cost, forward:0.125270455410745, backward:0.032524264029382396, data cost:0.25705852375009974 
2022-04-01 02:54:19,485: ============================================================
2022-04-01 02:54:19,485: Epoch 19/31 Batch 6500/7662 eta: 10:29:37.274249	Training Loss 0.8061 (0.8271)	Training Prec@1 0.391 (0.012)	Training Prec@5 0.977 (0.046)	
2022-04-01 02:54:19,485: ============================================================
2022-04-01 02:55:00,961: time cost, forward:0.12517457597995277, backward:0.03252019906047619, data cost:0.2571510783757815 
2022-04-01 02:55:00,962: ============================================================
2022-04-01 02:55:00,962: Epoch 19/31 Batch 6600/7662 eta: 10:42:56.387880	Training Loss 0.8042 (0.8267)	Training Prec@1 0.195 (0.016)	Training Prec@5 1.367 (0.061)	
2022-04-01 02:55:00,962: ============================================================
2022-04-01 02:55:41,066: time cost, forward:0.12524136405753492, backward:0.03252998087402244, data cost:0.256863949138347 
2022-04-01 02:55:41,066: ============================================================
2022-04-01 02:55:41,066: Epoch 19/31 Batch 6700/7662 eta: 10:20:59.505101	Training Loss 0.7997 (0.8263)	Training Prec@1 0.391 (0.024)	Training Prec@5 1.758 (0.085)	
2022-04-01 02:55:41,066: ============================================================
2022-04-01 02:56:22,994: time cost, forward:0.12538866292625547, backward:0.03254991065826394, data cost:0.2567623913822884 
2022-04-01 02:56:22,994: ============================================================
2022-04-01 02:56:22,995: Epoch 19/31 Batch 6800/7662 eta: 10:48:32.592894	Training Loss 0.8320 (0.8258)	Training Prec@1 0.195 (0.038)	Training Prec@5 0.586 (0.126)	
2022-04-01 02:56:22,995: ============================================================
2022-04-01 02:57:03,800: time cost, forward:0.12568993585008453, backward:0.03258791324418081, data cost:0.25632272227672 
2022-04-01 02:57:03,801: ============================================================
2022-04-01 02:57:03,801: Epoch 19/31 Batch 6900/7662 eta: 10:30:30.277905	Training Loss 0.7851 (0.8255)	Training Prec@1 1.367 (0.046)	Training Prec@5 3.711 (0.148)	
2022-04-01 02:57:03,801: ============================================================
2022-04-01 02:57:43,914: time cost, forward:0.12567964259650574, backward:0.03258889023619629, data cost:0.2561203004428533 
2022-04-01 02:57:43,914: ============================================================
2022-04-01 02:57:43,915: Epoch 19/31 Batch 7000/7662 eta: 10:19:08.018126	Training Loss 0.7853 (0.8252)	Training Prec@1 1.562 (0.056)	Training Prec@5 3.125 (0.173)	
2022-04-01 02:57:43,915: ============================================================
2022-04-01 02:58:25,388: time cost, forward:0.12572617469698397, backward:0.03260790050693055, data cost:0.25606615043959324 
2022-04-01 02:58:25,388: ============================================================
2022-04-01 02:58:25,389: Epoch 19/31 Batch 7100/7662 eta: 10:39:26.437852	Training Loss 0.8038 (0.8248)	Training Prec@1 0.781 (0.073)	Training Prec@5 1.562 (0.212)	
2022-04-01 02:58:25,389: ============================================================
2022-04-01 02:59:05,120: time cost, forward:0.12551472236388492, backward:0.03262150431692741, data cost:0.25602097937855095 
2022-04-01 02:59:05,121: ============================================================
2022-04-01 02:59:05,121: Epoch 19/31 Batch 7200/7662 eta: 10:11:55.409757	Training Loss 0.8217 (0.8248)	Training Prec@1 0.000 (0.075)	Training Prec@5 0.000 (0.218)	
2022-04-01 02:59:05,121: ============================================================
2022-04-01 02:59:46,074: time cost, forward:0.1252873972484977, backward:0.03261814693634372, data cost:0.25619063199031905 
2022-04-01 02:59:46,075: ============================================================
2022-04-01 02:59:46,075: Epoch 19/31 Batch 7300/7662 eta: 10:30:03.399753	Training Loss 0.8234 (0.8247)	Training Prec@1 0.000 (0.074)	Training Prec@5 0.000 (0.216)	
2022-04-01 02:59:46,075: ============================================================
2022-04-01 03:00:27,176: time cost, forward:0.12513942173291323, backward:0.03260932504881039, data cost:0.2563014874056813 
2022-04-01 03:00:27,176: ============================================================
2022-04-01 03:00:27,176: Epoch 19/31 Batch 7400/7662 eta: 10:31:38.349118	Training Loss 0.8191 (0.8247)	Training Prec@1 0.000 (0.074)	Training Prec@5 0.195 (0.214)	
2022-04-01 03:00:27,176: ============================================================
2022-04-01 03:01:08,877: time cost, forward:0.1251285873519403, backward:0.03262754401646863, data cost:0.25631422512625707 
2022-04-01 03:01:08,877: ============================================================
2022-04-01 03:01:08,877: Epoch 19/31 Batch 7500/7662 eta: 10:40:09.611637	Training Loss 0.8150 (0.8246)	Training Prec@1 0.195 (0.073)	Training Prec@5 0.195 (0.213)	
2022-04-01 03:01:08,878: ============================================================
2022-04-01 03:01:48,644: time cost, forward:0.12492322510740508, backward:0.0326106429711849, data cost:0.25632669069466113 
2022-04-01 03:01:48,644: ============================================================
2022-04-01 03:01:48,645: Epoch 19/31 Batch 7600/7662 eta: 10:09:48.627002	Training Loss 0.8176 (0.8245)	Training Prec@1 0.000 (0.073)	Training Prec@5 0.000 (0.213)	
2022-04-01 03:01:48,645: ============================================================
2022-04-01 03:02:16,922: Epoch: 19/31 eta: 10:09:23.573652	Training Loss 0.8124 (0.8244)	Training Prec@1 0.000 (0.073)	Training Prec@5 0.391 (0.212)
2022-04-01 03:02:16,923: ============================================================
2022-04-01 03:02:59,325: time cost, forward:0.132289575807976, backward:0.03333149052629567, data cost:0.2600344889091723 
2022-04-01 03:02:59,326: ============================================================
2022-04-01 03:02:59,326: Epoch 20/31 Batch 100/7662 eta: 10:48:58.313784	Training Loss 0.8068 (0.8110)	Training Prec@1 0.000 (0.079)	Training Prec@5 0.391 (0.329)	
2022-04-01 03:02:59,326: ============================================================
2022-04-01 03:03:41,461: time cost, forward:0.13208163084097244, backward:0.03284313331297294, data cost:0.2579605399663724 
2022-04-01 03:03:41,461: ============================================================
2022-04-01 03:03:41,461: Epoch 20/31 Batch 200/7662 eta: 10:44:17.117532	Training Loss 0.8098 (0.8102)	Training Prec@1 0.195 (0.128)	Training Prec@5 0.586 (0.446)	
2022-04-01 03:03:41,462: ============================================================
2022-04-01 03:04:21,751: time cost, forward:0.12562904469544273, backward:0.032846230726975664, data cost:0.25786518093734284 
2022-04-01 03:04:21,752: ============================================================
2022-04-01 03:04:21,752: Epoch 20/31 Batch 300/7662 eta: 10:15:24.405422	Training Loss 0.8079 (0.8097)	Training Prec@1 0.195 (0.163)	Training Prec@5 1.172 (0.533)	
2022-04-01 03:04:21,752: ============================================================
2022-04-01 03:05:01,609: time cost, forward:0.12111270397826843, backward:0.03301617137172766, data cost:0.25768730216157765 
2022-04-01 03:05:01,609: ============================================================
2022-04-01 03:05:01,609: Epoch 20/31 Batch 400/7662 eta: 10:08:07.464196	Training Loss 0.8079 (0.8094)	Training Prec@1 0.391 (0.184)	Training Prec@5 1.367 (0.592)	
2022-04-01 03:05:01,610: ============================================================
2022-04-01 03:05:43,007: time cost, forward:0.11851049616246041, backward:0.03320895263809479, data cost:0.2603891579087129 
2022-04-01 03:05:43,008: ============================================================
2022-04-01 03:05:43,008: Epoch 20/31 Batch 500/7662 eta: 10:30:56.804878	Training Loss 0.8087 (0.8090)	Training Prec@1 0.195 (0.199)	Training Prec@5 0.195 (0.627)	
2022-04-01 03:05:43,008: ============================================================
2022-04-01 03:06:23,611: time cost, forward:0.11675684758538196, backward:0.033168523259871394, data cost:0.26117050946256354 
2022-04-01 03:06:23,611: ============================================================
2022-04-01 03:06:23,612: Epoch 20/31 Batch 600/7662 eta: 10:18:09.405920	Training Loss 0.8048 (0.8088)	Training Prec@1 0.586 (0.214)	Training Prec@5 1.758 (0.672)	
2022-04-01 03:06:23,612: ============================================================
2022-04-01 03:07:03,643: time cost, forward:0.11617794193764443, backward:0.03312286082255482, data cost:0.25992159099879014 
2022-04-01 03:07:03,643: ============================================================
2022-04-01 03:07:03,643: Epoch 20/31 Batch 700/7662 eta: 10:08:46.919784	Training Loss 0.8042 (0.8085)	Training Prec@1 0.195 (0.235)	Training Prec@5 1.367 (0.726)	
2022-04-01 03:07:03,643: ============================================================
2022-04-01 03:07:43,366: time cost, forward:0.11516241197741225, backward:0.03305910078246841, data cost:0.259688422139804 
2022-04-01 03:07:43,366: ============================================================
2022-04-01 03:07:43,367: Epoch 20/31 Batch 800/7662 eta: 10:03:25.929326	Training Loss 0.8092 (0.8083)	Training Prec@1 0.000 (0.248)	Training Prec@5 0.781 (0.766)	
2022-04-01 03:07:43,367: ============================================================
2022-04-01 03:08:23,434: time cost, forward:0.11442233829264911, backward:0.03306339341355643, data cost:0.2595612461760524 
2022-04-01 03:08:23,434: ============================================================
2022-04-01 03:08:23,435: Epoch 20/31 Batch 900/7662 eta: 10:07:59.983389	Training Loss 0.8077 (0.8080)	Training Prec@1 0.195 (0.263)	Training Prec@5 0.391 (0.799)	
2022-04-01 03:08:23,435: ============================================================
2022-04-01 03:09:03,381: time cost, forward:0.11375314432818133, backward:0.03299682515042203, data cost:0.2594029378365945 
2022-04-01 03:09:03,381: ============================================================
2022-04-01 03:09:03,381: Epoch 20/31 Batch 1000/7662 eta: 10:05:29.323233	Training Loss 0.8072 (0.8078)	Training Prec@1 0.000 (0.271)	Training Prec@5 1.562 (0.826)	
2022-04-01 03:09:03,381: ============================================================
2022-04-01 03:09:44,548: time cost, forward:0.11392838245527218, backward:0.03308891490766197, data cost:0.25974665586247675 
2022-04-01 03:09:44,548: ============================================================
2022-04-01 03:09:44,549: Epoch 20/31 Batch 1100/7662 eta: 10:23:18.501465	Training Loss 0.8015 (0.8076)	Training Prec@1 0.781 (0.283)	Training Prec@5 1.562 (0.854)	
2022-04-01 03:09:44,549: ============================================================
2022-04-01 03:10:25,917: time cost, forward:0.11567099219665018, backward:0.03320400231673978, data cost:0.25844077908863516 
2022-04-01 03:10:25,917: ============================================================
2022-04-01 03:10:25,917: Epoch 20/31 Batch 1200/7662 eta: 10:25:40.203817	Training Loss 0.8045 (0.8074)	Training Prec@1 0.195 (0.286)	Training Prec@5 1.172 (0.876)	
2022-04-01 03:10:25,918: ============================================================
2022-04-01 03:11:06,387: time cost, forward:0.11551176758341096, backward:0.03309856459578704, data cost:0.25849574469345366 
2022-04-01 03:11:06,387: ============================================================
2022-04-01 03:11:06,387: Epoch 20/31 Batch 1300/7662 eta: 10:11:23.709731	Training Loss 0.8025 (0.8072)	Training Prec@1 0.195 (0.292)	Training Prec@5 1.172 (0.900)	
2022-04-01 03:11:06,387: ============================================================
2022-04-01 03:11:47,915: time cost, forward:0.11535854728158838, backward:0.0330562381935256, data cost:0.25899771727179527 
2022-04-01 03:11:47,915: ============================================================
2022-04-01 03:11:47,915: Epoch 20/31 Batch 1400/7662 eta: 10:26:41.858859	Training Loss 0.8025 (0.8070)	Training Prec@1 0.391 (0.301)	Training Prec@5 2.148 (0.928)	
2022-04-01 03:11:47,916: ============================================================
2022-04-01 03:12:29,684: time cost, forward:0.1158534033128307, backward:0.0330991310783829, data cost:0.2593363412942307 
2022-04-01 03:12:29,685: ============================================================
2022-04-01 03:12:29,685: Epoch 20/31 Batch 1500/7662 eta: 10:29:38.432269	Training Loss 0.8047 (0.8068)	Training Prec@1 0.195 (0.309)	Training Prec@5 0.586 (0.955)	
2022-04-01 03:12:29,685: ============================================================
2022-04-01 03:13:10,474: time cost, forward:0.11563492954485562, backward:0.0331253213685628, data cost:0.2594073834159808 
2022-04-01 03:13:10,474: ============================================================
2022-04-01 03:13:10,475: Epoch 20/31 Batch 1600/7662 eta: 10:14:11.295744	Training Loss 0.8034 (0.8065)	Training Prec@1 0.195 (0.322)	Training Prec@5 1.367 (0.984)	
2022-04-01 03:13:10,475: ============================================================
2022-04-01 03:13:54,463: time cost, forward:0.11709846714933596, backward:0.03317997931311452, data cost:0.2598323474006136 
2022-04-01 03:13:54,463: ============================================================
2022-04-01 03:13:54,464: Epoch 20/31 Batch 1700/7662 eta: 11:01:37.896577	Training Loss 0.8016 (0.8063)	Training Prec@1 0.195 (0.329)	Training Prec@5 1.172 (1.006)	
2022-04-01 03:13:54,464: ============================================================
2022-04-01 03:14:36,569: time cost, forward:0.1177999518724731, backward:0.033222304774099355, data cost:0.2596607035965042 
2022-04-01 03:14:36,570: ============================================================
2022-04-01 03:14:36,570: Epoch 20/31 Batch 1800/7662 eta: 10:32:36.912296	Training Loss 0.8017 (0.8061)	Training Prec@1 0.781 (0.341)	Training Prec@5 1.758 (1.035)	
2022-04-01 03:14:36,570: ============================================================
2022-04-01 03:15:17,809: time cost, forward:0.11790154443532935, backward:0.033234229773330085, data cost:0.25960376703343685 
2022-04-01 03:15:17,809: ============================================================
2022-04-01 03:15:17,810: Epoch 20/31 Batch 1900/7662 eta: 10:18:54.086133	Training Loss 0.8034 (0.8060)	Training Prec@1 0.586 (0.348)	Training Prec@5 1.953 (1.056)	
2022-04-01 03:15:17,810: ============================================================
2022-04-01 03:16:00,587: time cost, forward:0.11855298438747267, backward:0.033292690117756325, data cost:0.25973073478458286 
2022-04-01 03:16:00,587: ============================================================
2022-04-01 03:16:00,588: Epoch 20/31 Batch 2000/7662 eta: 10:41:16.764416	Training Loss 0.8033 (0.8058)	Training Prec@1 0.781 (0.356)	Training Prec@5 0.977 (1.077)	
2022-04-01 03:16:00,588: ============================================================
2022-04-01 03:16:41,690: time cost, forward:0.11895314212524646, backward:0.03334764516484232, data cost:0.2592281207066027 
2022-04-01 03:16:41,691: ============================================================
2022-04-01 03:16:41,691: Epoch 20/31 Batch 2100/7662 eta: 10:15:29.039337	Training Loss 0.7993 (0.8056)	Training Prec@1 0.586 (0.362)	Training Prec@5 1.758 (1.093)	
2022-04-01 03:16:41,691: ============================================================
2022-04-01 03:17:26,285: time cost, forward:0.12041567249046559, backward:0.033467678115171644, data cost:0.25921090281296993 
2022-04-01 03:17:26,285: ============================================================
2022-04-01 03:17:26,285: Epoch 20/31 Batch 2200/7662 eta: 11:07:01.417959	Training Loss 0.7984 (0.8054)	Training Prec@1 0.391 (0.373)	Training Prec@5 0.781 (1.119)	
2022-04-01 03:17:26,285: ============================================================
2022-04-01 03:18:07,675: time cost, forward:0.12080143803666601, backward:0.03350088076780235, data cost:0.25882543486686 
2022-04-01 03:18:07,676: ============================================================
2022-04-01 03:18:07,676: Epoch 20/31 Batch 2300/7662 eta: 10:18:24.585600	Training Loss 0.8018 (0.8052)	Training Prec@1 0.781 (0.381)	Training Prec@5 1.562 (1.140)	
2022-04-01 03:18:07,676: ============================================================
2022-04-01 03:18:50,201: time cost, forward:0.1210723703431308, backward:0.03356170614543882, data cost:0.25895847982046455 
2022-04-01 03:18:50,201: ============================================================
2022-04-01 03:18:50,202: Epoch 20/31 Batch 2400/7662 eta: 10:34:39.669317	Training Loss 0.8022 (0.8050)	Training Prec@1 0.391 (0.387)	Training Prec@5 0.977 (1.165)	
2022-04-01 03:18:50,202: ============================================================
2022-04-01 03:19:34,982: time cost, forward:0.12264663880231047, backward:0.0336289358119957, data cost:0.25869582242229167 
2022-04-01 03:19:34,983: ============================================================
2022-04-01 03:19:34,983: Epoch 20/31 Batch 2500/7662 eta: 11:07:34.693557	Training Loss 0.8027 (0.8048)	Training Prec@1 0.586 (0.393)	Training Prec@5 1.367 (1.183)	
2022-04-01 03:19:34,983: ============================================================
2022-04-01 03:20:17,566: time cost, forward:0.12288518518886, backward:0.03363204332625421, data cost:0.2588449327154038 
2022-04-01 03:20:17,566: ============================================================
2022-04-01 03:20:17,566: Epoch 20/31 Batch 2600/7662 eta: 10:34:05.791951	Training Loss 0.7999 (0.8046)	Training Prec@1 0.391 (0.401)	Training Prec@5 2.148 (1.202)	
2022-04-01 03:20:17,566: ============================================================
2022-04-01 03:20:59,831: time cost, forward:0.12326846294113335, backward:0.03340605428016552, data cost:0.2589552517333001 
2022-04-01 03:20:59,831: ============================================================
2022-04-01 03:20:59,832: Epoch 20/31 Batch 2700/7662 eta: 10:28:39.902560	Training Loss 0.7977 (0.8044)	Training Prec@1 1.172 (0.410)	Training Prec@5 1.953 (1.226)	
2022-04-01 03:20:59,832: ============================================================
2022-04-01 03:21:42,804: time cost, forward:0.12408034534870023, backward:0.03344750276588039, data cost:0.25855507157282476 
2022-04-01 03:21:42,805: ============================================================
2022-04-01 03:21:42,805: Epoch 20/31 Batch 2800/7662 eta: 10:38:28.614792	Training Loss 0.7997 (0.8043)	Training Prec@1 0.000 (0.418)	Training Prec@5 1.758 (1.247)	
2022-04-01 03:21:42,805: ============================================================
2022-04-01 03:22:25,234: time cost, forward:0.1245481101921321, backward:0.033432538528284476, data cost:0.2583767227897894 
2022-04-01 03:22:25,234: ============================================================
2022-04-01 03:22:25,234: Epoch 20/31 Batch 2900/7662 eta: 10:29:41.329897	Training Loss 0.7989 (0.8041)	Training Prec@1 0.195 (0.425)	Training Prec@5 1.562 (1.266)	
2022-04-01 03:22:25,235: ============================================================
2022-04-01 03:23:07,572: time cost, forward:0.12499973733411625, backward:0.033436428113316013, data cost:0.2581972094844603 
2022-04-01 03:23:07,572: ============================================================
2022-04-01 03:23:07,573: Epoch 20/31 Batch 3000/7662 eta: 10:27:37.594378	Training Loss 0.7954 (0.8039)	Training Prec@1 0.977 (0.432)	Training Prec@5 1.953 (1.285)	
2022-04-01 03:23:07,573: ============================================================
2022-04-01 03:23:52,231: time cost, forward:0.12589688407255395, backward:0.03346920590433008, data cost:0.2582176082478142 
2022-04-01 03:23:52,231: ============================================================
2022-04-01 03:23:52,231: Epoch 20/31 Batch 3100/7662 eta: 11:01:16.937700	Training Loss 0.7977 (0.8037)	Training Prec@1 0.977 (0.439)	Training Prec@5 2.539 (1.303)	
2022-04-01 03:23:52,231: ============================================================
2022-04-01 03:24:33,967: time cost, forward:0.12663158985852227, backward:0.03351392579026504, data cost:0.25740283569271544 
2022-04-01 03:24:33,968: ============================================================
2022-04-01 03:24:33,968: Epoch 20/31 Batch 3200/7662 eta: 10:17:19.197228	Training Loss 0.8003 (0.8036)	Training Prec@1 1.172 (0.446)	Training Prec@5 1.953 (1.318)	
2022-04-01 03:24:33,968: ============================================================
2022-04-01 03:25:16,931: time cost, forward:0.12730304694023953, backward:0.0335591792626683, data cost:0.2570188333136127 
2022-04-01 03:25:16,931: ============================================================
2022-04-01 03:25:16,932: Epoch 20/31 Batch 3300/7662 eta: 10:34:45.428700	Training Loss 0.7939 (0.8034)	Training Prec@1 0.977 (0.453)	Training Prec@5 3.125 (1.335)	
2022-04-01 03:25:16,932: ============================================================
2022-04-01 03:26:01,881: time cost, forward:0.12860000824430262, backward:0.03360670333260752, data cost:0.25661186528016483 
2022-04-01 03:26:01,881: ============================================================
2022-04-01 03:26:01,882: Epoch 20/31 Batch 3400/7662 eta: 11:03:20.880644	Training Loss 0.7954 (0.8032)	Training Prec@1 1.172 (0.460)	Training Prec@5 2.148 (1.354)	
2022-04-01 03:26:01,882: ============================================================
2022-04-01 03:26:42,776: time cost, forward:0.12868348405374122, backward:0.03355208489853302, data cost:0.2563034609134758 
2022-04-01 03:26:42,777: ============================================================
2022-04-01 03:26:42,777: Epoch 20/31 Batch 3500/7662 eta: 10:02:49.963985	Training Loss 0.7981 (0.8031)	Training Prec@1 0.391 (0.466)	Training Prec@5 1.367 (1.369)	
2022-04-01 03:26:42,777: ============================================================
2022-04-01 03:27:25,365: time cost, forward:0.1291396649687381, backward:0.03353164725318224, data cost:0.25606982858355226 
2022-04-01 03:27:25,365: ============================================================
2022-04-01 03:27:25,366: Epoch 20/31 Batch 3600/7662 eta: 10:27:04.841940	Training Loss 0.7965 (0.8029)	Training Prec@1 0.195 (0.471)	Training Prec@5 1.172 (1.385)	
2022-04-01 03:27:25,366: ============================================================
2022-04-01 03:28:07,502: time cost, forward:0.12931274259112982, backward:0.03355807257716995, data cost:0.25592338880934434 
2022-04-01 03:28:07,502: ============================================================
2022-04-01 03:28:07,502: Epoch 20/31 Batch 3700/7662 eta: 10:19:43.464777	Training Loss 0.7985 (0.8028)	Training Prec@1 0.586 (0.480)	Training Prec@5 1.758 (1.401)	
2022-04-01 03:28:07,502: ============================================================
2022-04-01 03:28:49,670: time cost, forward:0.1287925186267681, backward:0.03353392051753009, data cost:0.2565422774804646 
2022-04-01 03:28:49,671: ============================================================
2022-04-01 03:28:49,671: Epoch 20/31 Batch 3800/7662 eta: 10:19:29.490266	Training Loss 0.7958 (0.8026)	Training Prec@1 0.781 (0.487)	Training Prec@5 1.562 (1.418)	
2022-04-01 03:28:49,671: ============================================================
2022-04-01 03:29:32,945: time cost, forward:0.12935703447091942, backward:0.033528115694936834, data cost:0.2563316428254708 
2022-04-01 03:29:32,946: ============================================================
2022-04-01 03:29:32,946: Epoch 20/31 Batch 3900/7662 eta: 10:35:01.434370	Training Loss 0.7955 (0.8025)	Training Prec@1 1.562 (0.496)	Training Prec@5 3.125 (1.438)	
2022-04-01 03:29:32,946: ============================================================
2022-04-01 03:30:14,908: time cost, forward:0.12976667349801776, backward:0.03351635091094322, data cost:0.25593624904353074 
2022-04-01 03:30:14,909: ============================================================
2022-04-01 03:30:14,909: Epoch 20/31 Batch 4000/7662 eta: 10:15:04.591676	Training Loss 0.7993 (0.8023)	Training Prec@1 0.977 (0.504)	Training Prec@5 2.148 (1.455)	
2022-04-01 03:30:14,909: ============================================================
2022-04-01 03:30:57,932: time cost, forward:0.1296981456483914, backward:0.033517150769555935, data cost:0.2562421215659498 
2022-04-01 03:30:57,933: ============================================================
2022-04-01 03:30:57,933: Epoch 20/31 Batch 4100/7662 eta: 10:29:54.516095	Training Loss 0.7977 (0.8022)	Training Prec@1 0.781 (0.511)	Training Prec@5 1.953 (1.473)	
2022-04-01 03:30:57,933: ============================================================
2022-04-01 03:31:39,727: time cost, forward:0.12955216130463104, backward:0.03349581023686612, data cost:0.25637332976900645 
2022-04-01 03:31:39,727: ============================================================
2022-04-01 03:31:39,727: Epoch 20/31 Batch 4200/7662 eta: 10:11:12.414462	Training Loss 0.7977 (0.8020)	Training Prec@1 0.391 (0.519)	Training Prec@5 1.367 (1.493)	
2022-04-01 03:31:39,728: ============================================================
2022-04-01 03:32:21,869: time cost, forward:0.1295069166326778, backward:0.03348924870212623, data cost:0.25646729623475556 
2022-04-01 03:32:21,869: ============================================================
2022-04-01 03:32:21,870: Epoch 20/31 Batch 4300/7662 eta: 10:15:35.490018	Training Loss 0.7966 (0.8019)	Training Prec@1 0.977 (0.524)	Training Prec@5 2.539 (1.510)	
2022-04-01 03:32:21,870: ============================================================
2022-04-01 03:33:05,924: time cost, forward:0.1298573115761374, backward:0.03349843494565304, data cost:0.2565754030639135 
2022-04-01 03:33:05,925: ============================================================
2022-04-01 03:33:05,925: Epoch 20/31 Batch 4400/7662 eta: 10:42:48.150600	Training Loss 0.7935 (0.8018)	Training Prec@1 1.172 (0.531)	Training Prec@5 2.148 (1.525)	
2022-04-01 03:33:05,925: ============================================================
2022-04-01 03:33:47,227: time cost, forward:0.12975018584587808, backward:0.03345678419133085, data cost:0.2565768098375431 
2022-04-01 03:33:47,227: ============================================================
2022-04-01 03:33:47,227: Epoch 20/31 Batch 4500/7662 eta: 10:01:56.872311	Training Loss 0.7953 (0.8016)	Training Prec@1 0.781 (0.536)	Training Prec@5 1.758 (1.538)	
2022-04-01 03:33:47,227: ============================================================
2022-04-01 03:34:30,380: time cost, forward:0.1297629320717397, backward:0.033441720565626686, data cost:0.25682512286643044 
2022-04-01 03:34:30,381: ============================================================
2022-04-01 03:34:30,381: Epoch 20/31 Batch 4600/7662 eta: 10:28:12.598739	Training Loss 0.7953 (0.8015)	Training Prec@1 0.391 (0.543)	Training Prec@5 1.367 (1.555)	
2022-04-01 03:34:30,381: ============================================================
2022-04-01 03:35:11,397: time cost, forward:0.1294465908270538, backward:0.03341756670696732, data cost:0.25694659527983404 
2022-04-01 03:35:11,397: ============================================================
2022-04-01 03:35:11,397: Epoch 20/31 Batch 4700/7662 eta: 9:56:24.846878	Training Loss 0.7962 (0.8014)	Training Prec@1 0.586 (0.548)	Training Prec@5 1.953 (1.570)	
2022-04-01 03:35:11,398: ============================================================
2022-04-01 03:35:55,997: time cost, forward:0.13006520017928744, backward:0.033450034142136695, data cost:0.25684188241435973 
2022-04-01 03:35:55,997: ============================================================
2022-04-01 03:35:55,998: Epoch 20/31 Batch 4800/7662 eta: 10:47:46.758219	Training Loss 0.7963 (0.8012)	Training Prec@1 1.562 (0.556)	Training Prec@5 2.344 (1.586)	
2022-04-01 03:35:55,998: ============================================================
2022-04-01 03:36:38,121: time cost, forward:0.1297739857823344, backward:0.03341273026311609, data cost:0.2571779684427685 
2022-04-01 03:36:38,121: ============================================================
2022-04-01 03:36:38,122: Epoch 20/31 Batch 4900/7662 eta: 10:11:06.824656	Training Loss 0.7936 (0.8011)	Training Prec@1 1.172 (0.562)	Training Prec@5 3.906 (1.605)	
2022-04-01 03:36:38,122: ============================================================
2022-04-01 03:37:20,246: time cost, forward:0.12970811978748595, backward:0.03339474423929891, data cost:0.2572763442611618 
2022-04-01 03:37:20,247: ============================================================
2022-04-01 03:37:20,247: Epoch 20/31 Batch 5000/7662 eta: 10:10:25.985886	Training Loss 0.7939 (0.8010)	Training Prec@1 1.562 (0.568)	Training Prec@5 2.930 (1.619)	
2022-04-01 03:37:20,247: ============================================================
2022-04-01 03:38:02,845: time cost, forward:0.12991406777765874, backward:0.033385609009378585, data cost:0.25717900972502866 
2022-04-01 03:38:02,846: ============================================================
2022-04-01 03:38:02,846: Epoch 20/31 Batch 5100/7662 eta: 10:16:35.053286	Training Loss 0.7918 (0.8008)	Training Prec@1 0.781 (0.574)	Training Prec@5 2.930 (1.636)	
2022-04-01 03:38:02,846: ============================================================
2022-04-01 03:38:45,200: time cost, forward:0.1300563250030089, backward:0.03339540396637356, data cost:0.25708899586951417 
2022-04-01 03:38:45,200: ============================================================
2022-04-01 03:38:45,200: Epoch 20/31 Batch 5200/7662 eta: 10:12:20.071274	Training Loss 0.7936 (0.8007)	Training Prec@1 1.172 (0.581)	Training Prec@5 2.344 (1.652)	
2022-04-01 03:38:45,200: ============================================================
2022-04-01 03:39:26,351: time cost, forward:0.12976612116080632, backward:0.033367920245825515, data cost:0.25721519356472217 
2022-04-01 03:39:26,352: ============================================================
2022-04-01 03:39:26,352: Epoch 20/31 Batch 5300/7662 eta: 9:54:15.955967	Training Loss 0.7948 (0.8006)	Training Prec@1 0.586 (0.586)	Training Prec@5 3.516 (1.668)	
2022-04-01 03:39:26,352: ============================================================
2022-04-01 03:40:09,171: time cost, forward:0.12998176199525655, backward:0.033403547279568464, data cost:0.2571070482166062 
2022-04-01 03:40:09,171: ============================================================
2022-04-01 03:40:09,171: Epoch 20/31 Batch 5400/7662 eta: 10:17:38.051237	Training Loss 0.7988 (0.8004)	Training Prec@1 0.586 (0.593)	Training Prec@5 2.148 (1.684)	
2022-04-01 03:40:09,171: ============================================================
2022-04-01 03:40:51,657: time cost, forward:0.12995924258539948, backward:0.0334104725958586, data cost:0.2571999063750227 
2022-04-01 03:40:51,657: ============================================================
2022-04-01 03:40:51,657: Epoch 20/31 Batch 5500/7662 eta: 10:12:07.110140	Training Loss 0.7929 (0.8003)	Training Prec@1 1.172 (0.599)	Training Prec@5 2.734 (1.702)	
2022-04-01 03:40:51,658: ============================================================
2022-04-01 03:41:32,522: time cost, forward:0.12994194724854027, backward:0.033411331571922026, data cost:0.25698761655552343 
2022-04-01 03:41:32,523: ============================================================
2022-04-01 03:41:32,523: Epoch 20/31 Batch 5600/7662 eta: 9:48:05.220020	Training Loss 0.7927 (0.8002)	Training Prec@1 1.172 (0.606)	Training Prec@5 2.148 (1.718)	
2022-04-01 03:41:32,523: ============================================================
2022-04-01 03:42:14,838: time cost, forward:0.13005158281635873, backward:0.03340811983788928, data cost:0.25693445524472397 
2022-04-01 03:42:14,838: ============================================================
2022-04-01 03:42:14,838: Epoch 20/31 Batch 5700/7662 eta: 10:08:14.825745	Training Loss 0.7944 (0.8001)	Training Prec@1 1.367 (0.614)	Training Prec@5 3.516 (1.737)	
2022-04-01 03:42:14,838: ============================================================
2022-04-01 03:42:56,871: time cost, forward:0.1299029517778139, backward:0.03338403964087889, data cost:0.25709758941254385 
2022-04-01 03:42:56,871: ============================================================
2022-04-01 03:42:56,871: Epoch 20/31 Batch 5800/7662 eta: 10:03:29.630377	Training Loss 0.7905 (0.7999)	Training Prec@1 0.781 (0.620)	Training Prec@5 2.734 (1.753)	
2022-04-01 03:42:56,872: ============================================================
2022-04-01 03:43:40,396: time cost, forward:0.1302121074386806, backward:0.0333788741703942, data cost:0.25703316370215046 
2022-04-01 03:43:40,396: ============================================================
2022-04-01 03:43:40,397: Epoch 20/31 Batch 5900/7662 eta: 10:24:11.288812	Training Loss 0.7907 (0.7998)	Training Prec@1 1.367 (0.626)	Training Prec@5 3.125 (1.769)	
2022-04-01 03:43:40,397: ============================================================
2022-04-01 03:44:22,808: time cost, forward:0.13037248090180303, backward:0.03336836823146926, data cost:0.2569450398925384 
2022-04-01 03:44:22,808: ============================================================
2022-04-01 03:44:22,809: Epoch 20/31 Batch 6000/7662 eta: 10:07:31.052773	Training Loss 0.7887 (0.7997)	Training Prec@1 1.172 (0.633)	Training Prec@5 3.516 (1.786)	
2022-04-01 03:44:22,809: ============================================================
2022-04-01 03:45:04,365: time cost, forward:0.1302618584020702, backward:0.03334735045375971, data cost:0.2569867018930911 
2022-04-01 03:45:04,365: ============================================================
2022-04-01 03:45:04,366: Epoch 20/31 Batch 6100/7662 eta: 9:54:34.529627	Training Loss 0.7958 (0.7998)	Training Prec@1 1.172 (0.632)	Training Prec@5 2.930 (1.784)	
2022-04-01 03:45:04,366: ============================================================
2022-04-01 03:45:46,877: time cost, forward:0.13054160518710856, backward:0.03336124809389442, data cost:0.2567570386422913 
2022-04-01 03:45:46,878: ============================================================
2022-04-01 03:45:46,878: Epoch 20/31 Batch 6200/7662 eta: 10:07:32.234204	Training Loss 0.7925 (0.7997)	Training Prec@1 0.586 (0.638)	Training Prec@5 3.320 (1.799)	
2022-04-01 03:45:46,878: ============================================================
2022-04-01 03:46:28,350: time cost, forward:0.1304993455723025, backward:0.03336585909814224, data cost:0.25670104080541756 
2022-04-01 03:46:28,351: ============================================================
2022-04-01 03:46:28,351: Epoch 20/31 Batch 6300/7662 eta: 9:51:59.428376	Training Loss 0.8010 (0.7996)	Training Prec@1 0.977 (0.646)	Training Prec@5 2.539 (1.816)	
2022-04-01 03:46:28,351: ============================================================
2022-04-01 03:47:12,350: time cost, forward:0.13066750925990786, backward:0.033361756963680676, data cost:0.2568231547394848 
2022-04-01 03:47:12,350: ============================================================
2022-04-01 03:47:12,350: Epoch 20/31 Batch 6400/7662 eta: 10:27:19.313771	Training Loss 0.7925 (0.7995)	Training Prec@1 0.586 (0.649)	Training Prec@5 3.125 (1.825)	
2022-04-01 03:47:12,350: ============================================================
2022-04-01 03:47:54,562: time cost, forward:0.13075989065656002, backward:0.033354133583065326, data cost:0.2567511417073715 
2022-04-01 03:47:54,562: ============================================================
2022-04-01 03:47:54,562: Epoch 20/31 Batch 6500/7662 eta: 10:01:08.226246	Training Loss 0.7975 (0.7994)	Training Prec@1 0.781 (0.656)	Training Prec@5 2.930 (1.843)	
2022-04-01 03:47:54,563: ============================================================
2022-04-01 03:48:35,225: time cost, forward:0.1306341495057239, backward:0.03335095897084349, data cost:0.25667372785349435 
2022-04-01 03:48:35,225: ============================================================
2022-04-01 03:48:35,225: Epoch 20/31 Batch 6600/7662 eta: 9:38:23.571698	Training Loss 0.7891 (0.7993)	Training Prec@1 1.172 (0.664)	Training Prec@5 3.320 (1.861)	
2022-04-01 03:48:35,225: ============================================================
2022-04-01 03:49:18,958: time cost, forward:0.13092704437832137, backward:0.0333738563345126, data cost:0.25659667472195885 
2022-04-01 03:49:18,958: ============================================================
2022-04-01 03:49:18,959: Epoch 20/31 Batch 6700/7662 eta: 10:21:20.546473	Training Loss 0.7911 (0.7991)	Training Prec@1 1.172 (0.672)	Training Prec@5 3.711 (1.881)	
2022-04-01 03:49:18,959: ============================================================
2022-04-01 03:50:01,326: time cost, forward:0.1311737994513699, backward:0.0333994241089729, data cost:0.2563617844181142 
2022-04-01 03:50:01,326: ============================================================
2022-04-01 03:50:01,326: Epoch 20/31 Batch 6800/7662 eta: 10:01:13.762866	Training Loss 0.7889 (0.7990)	Training Prec@1 1.172 (0.681)	Training Prec@5 3.125 (1.901)	
2022-04-01 03:50:01,326: ============================================================
2022-04-01 03:50:43,188: time cost, forward:0.1310684753856999, backward:0.033392762840614924, data cost:0.2564230985720273 
2022-04-01 03:50:43,188: ============================================================
2022-04-01 03:50:43,188: Epoch 20/31 Batch 6900/7662 eta: 9:53:21.686110	Training Loss 0.7888 (0.7989)	Training Prec@1 1.953 (0.690)	Training Prec@5 4.492 (1.920)	
2022-04-01 03:50:43,188: ============================================================
2022-04-01 03:51:23,784: time cost, forward:0.13078191652010468, backward:0.03338253363521972, data cost:0.2565111944310613 
2022-04-01 03:51:23,785: ============================================================
2022-04-01 03:51:23,785: Epoch 20/31 Batch 7000/7662 eta: 9:34:44.930570	Training Loss 0.8015 (0.7991)	Training Prec@1 0.391 (0.687)	Training Prec@5 0.781 (1.911)	
2022-04-01 03:51:23,785: ============================================================
2022-04-01 03:52:08,847: time cost, forward:0.13119111965871022, backward:0.03339387215532238, data cost:0.25650794292137746 
2022-04-01 03:52:08,847: ============================================================
2022-04-01 03:52:08,847: Epoch 20/31 Batch 7100/7662 eta: 10:37:13.187905	Training Loss 0.7905 (0.7990)	Training Prec@1 1.758 (0.694)	Training Prec@5 3.516 (1.929)	
2022-04-01 03:52:08,848: ============================================================
2022-04-01 03:52:49,848: time cost, forward:0.13116776020862375, backward:0.03338597383511068, data cost:0.2563771206995798 
2022-04-01 03:52:49,848: ============================================================
2022-04-01 03:52:49,849: Epoch 20/31 Batch 7200/7662 eta: 9:39:06.419830	Training Loss 0.7945 (0.7989)	Training Prec@1 1.172 (0.704)	Training Prec@5 2.148 (1.950)	
2022-04-01 03:52:49,849: ============================================================
2022-04-01 03:53:33,254: time cost, forward:0.13149751070542343, backward:0.03338199217754907, data cost:0.25623578054478013 
2022-04-01 03:53:33,254: ============================================================
2022-04-01 03:53:33,255: Epoch 20/31 Batch 7300/7662 eta: 10:12:21.047765	Training Loss 0.7911 (0.7989)	Training Prec@1 1.367 (0.707)	Training Prec@5 3.320 (1.955)	
2022-04-01 03:53:33,255: ============================================================
2022-04-01 03:54:15,346: time cost, forward:0.1315780367814523, backward:0.033360437245477874, data cost:0.2561663349088196 
2022-04-01 03:54:15,346: ============================================================
2022-04-01 03:54:15,346: Epoch 20/31 Batch 7400/7662 eta: 9:53:06.301647	Training Loss 0.7895 (0.7987)	Training Prec@1 1.367 (0.718)	Training Prec@5 2.734 (1.981)	
2022-04-01 03:54:15,346: ============================================================
2022-04-01 03:54:56,883: time cost, forward:0.13172190833813446, backward:0.03335787089828937, data cost:0.25593637533069596 
2022-04-01 03:54:56,883: ============================================================
2022-04-01 03:54:56,883: Epoch 20/31 Batch 7500/7662 eta: 9:44:36.054292	Training Loss 0.7862 (0.7986)	Training Prec@1 2.344 (0.730)	Training Prec@5 4.688 (2.009)	
2022-04-01 03:54:56,883: ============================================================
2022-04-01 03:55:39,272: time cost, forward:0.13186561501266172, backward:0.03336640197456722, data cost:0.2558263765697276 
2022-04-01 03:55:39,272: ============================================================
2022-04-01 03:55:39,272: Epoch 20/31 Batch 7600/7662 eta: 9:55:52.942676	Training Loss 0.7862 (0.7985)	Training Prec@1 2.930 (0.741)	Training Prec@5 5.078 (2.037)	
2022-04-01 03:55:39,273: ============================================================
2022-04-01 03:56:06,328: Epoch: 20/31 eta: 9:55:26.237650	Training Loss 0.8270 (0.7985)	Training Prec@1 0.000 (0.747)	Training Prec@5 0.586 (2.048)
2022-04-01 03:56:06,328: ============================================================
2022-04-01 03:56:06,330: Save Checkpoint...
2022-04-01 03:56:06,331: ============================================================
2022-04-01 03:56:08,832: Save done!
2022-04-01 03:56:08,832: ============================================================
2022-04-01 03:56:48,104: time cost, forward:0.11167730947937628, backward:0.032359775870737406, data cost:0.24944764917547052 
2022-04-01 03:56:48,104: ============================================================
2022-04-01 03:56:48,105: Epoch 21/31 Batch 100/7662 eta: 9:10:30.301647	Training Loss 0.7857 (0.7889)	Training Prec@1 0.977 (1.602)	Training Prec@5 4.297 (3.956)	
2022-04-01 03:56:48,105: ============================================================
2022-04-01 03:57:28,484: time cost, forward:0.11103528109028112, backward:0.032497754648103186, data cost:0.2550071951132923 
2022-04-01 03:57:28,485: ============================================================
2022-04-01 03:57:28,485: Epoch 21/31 Batch 200/7662 eta: 9:25:53.121046	Training Loss 0.7857 (0.7857)	Training Prec@1 2.344 (1.969)	Training Prec@5 3.906 (4.702)	
2022-04-01 03:57:28,485: ============================================================
2022-04-01 03:58:08,962: time cost, forward:0.11100384303957324, backward:0.03296641601766631, data cost:0.2563911417256231 
2022-04-01 03:58:08,962: ============================================================
2022-04-01 03:58:08,962: Epoch 21/31 Batch 300/7662 eta: 9:26:33.840156	Training Loss 0.7806 (0.7847)	Training Prec@1 4.102 (2.129)	Training Prec@5 8.203 (5.047)	
2022-04-01 03:58:08,962: ============================================================
2022-04-01 03:58:51,221: time cost, forward:0.11889154152165081, backward:0.033865694414105335, data cost:0.2531018717247143 
2022-04-01 03:58:51,221: ============================================================
2022-04-01 03:58:51,222: Epoch 21/31 Batch 400/7662 eta: 9:50:48.476810	Training Loss 0.7789 (0.7839)	Training Prec@1 3.711 (2.210)	Training Prec@5 7.227 (5.211)	
2022-04-01 03:58:51,222: ============================================================
2022-04-01 03:59:31,725: time cost, forward:0.11721786946237446, backward:0.03367317415669351, data cost:0.2547781171206243 
2022-04-01 03:59:31,726: ============================================================
2022-04-01 03:59:31,726: Epoch 21/31 Batch 500/7662 eta: 9:25:35.621086	Training Loss 0.7811 (0.7833)	Training Prec@1 1.758 (2.303)	Training Prec@5 5.273 (5.380)	
2022-04-01 03:59:31,726: ============================================================
2022-04-01 04:00:13,018: time cost, forward:0.11668378164453777, backward:0.033675395188626146, data cost:0.2564098214068277 
2022-04-01 04:00:13,018: ============================================================
2022-04-01 04:00:13,018: Epoch 21/31 Batch 600/7662 eta: 9:35:54.914121	Training Loss 0.7803 (0.7829)	Training Prec@1 2.344 (2.351)	Training Prec@5 4.492 (5.500)	
2022-04-01 04:00:13,019: ============================================================
2022-04-01 04:00:53,712: time cost, forward:0.11706808537713789, backward:0.033623551435566085, data cost:0.2560758328062611 
2022-04-01 04:00:53,712: ============================================================
2022-04-01 04:00:53,713: Epoch 21/31 Batch 700/7662 eta: 9:26:53.431425	Training Loss 0.7782 (0.7827)	Training Prec@1 3.125 (2.401)	Training Prec@5 7.031 (5.606)	
2022-04-01 04:00:53,713: ============================================================
2022-04-01 04:01:35,254: time cost, forward:0.11866487012488373, backward:0.033827092381979854, data cost:0.2552373358543883 
2022-04-01 04:01:35,254: ============================================================
2022-04-01 04:01:35,254: Epoch 21/31 Batch 800/7662 eta: 9:38:00.379327	Training Loss 0.7830 (0.7825)	Training Prec@1 2.539 (2.442)	Training Prec@5 5.859 (5.682)	
2022-04-01 04:01:35,255: ============================================================
2022-04-01 04:02:15,859: time cost, forward:0.11962925525873204, backward:0.03386041505450799, data cost:0.25399467942446835 
2022-04-01 04:02:15,859: ============================================================
2022-04-01 04:02:15,859: Epoch 21/31 Batch 900/7662 eta: 9:24:17.423834	Training Loss 0.7804 (0.7822)	Training Prec@1 1.953 (2.483)	Training Prec@5 4.883 (5.730)	
2022-04-01 04:02:15,859: ============================================================
2022-04-01 04:02:58,001: time cost, forward:0.12088159016064098, backward:0.033934777444070044, data cost:0.25401298706237974 
2022-04-01 04:02:58,001: ============================================================
2022-04-01 04:02:58,001: Epoch 21/31 Batch 1000/7662 eta: 9:44:57.311851	Training Loss 0.7816 (0.7820)	Training Prec@1 4.492 (2.521)	Training Prec@5 7.812 (5.802)	
2022-04-01 04:02:58,002: ============================================================
2022-04-01 04:03:40,197: time cost, forward:0.12303092026298322, backward:0.03407486099021016, data cost:0.252944927849045 
2022-04-01 04:03:40,198: ============================================================
2022-04-01 04:03:40,198: Epoch 21/31 Batch 1100/7662 eta: 9:45:00.272008	Training Loss 0.7804 (0.7818)	Training Prec@1 2.734 (2.564)	Training Prec@5 7.422 (5.876)	
2022-04-01 04:03:40,198: ============================================================
2022-04-01 04:04:21,340: time cost, forward:0.1219118890213509, backward:0.033743378119830594, data cost:0.254462978261227 
2022-04-01 04:04:21,341: ============================================================
2022-04-01 04:04:21,341: Epoch 21/31 Batch 1200/7662 eta: 9:29:42.769465	Training Loss 0.7790 (0.7816)	Training Prec@1 2.734 (2.595)	Training Prec@5 5.469 (5.924)	
2022-04-01 04:04:21,341: ============================================================
2022-04-01 04:05:01,504: time cost, forward:0.12205666023736003, backward:0.0330560943362711, data cost:0.2543302949710109 
2022-04-01 04:05:01,504: ============================================================
2022-04-01 04:05:01,505: Epoch 21/31 Batch 1300/7662 eta: 9:15:29.055128	Training Loss 0.8567 (0.7827)	Training Prec@1 0.000 (2.568)	Training Prec@5 0.000 (5.858)	
2022-04-01 04:05:01,505: ============================================================
2022-04-01 04:05:41,512: time cost, forward:0.12118565346020473, backward:0.03291728805013006, data cost:0.2545979040021808 
2022-04-01 04:05:41,513: ============================================================
2022-04-01 04:05:41,513: Epoch 21/31 Batch 1400/7662 eta: 9:12:40.353031	Training Loss 0.7829 (0.7845)	Training Prec@1 3.320 (2.452)	Training Prec@5 5.273 (5.607)	
2022-04-01 04:05:41,513: ============================================================
2022-04-01 04:06:22,962: time cost, forward:0.12260659811415618, backward:0.03299522002272959, data cost:0.2534579511798963 
2022-04-01 04:06:22,963: ============================================================
2022-04-01 04:06:22,963: Epoch 21/31 Batch 1500/7662 eta: 9:31:53.264984	Training Loss 0.7804 (0.7841)	Training Prec@1 1.758 (2.480)	Training Prec@5 6.250 (5.668)	
2022-04-01 04:06:22,963: ============================================================
2022-04-01 04:07:04,314: time cost, forward:0.12315501042497837, backward:0.0330088975058264, data cost:0.2531779510218923 
2022-04-01 04:07:04,315: ============================================================
2022-04-01 04:07:04,315: Epoch 21/31 Batch 1600/7662 eta: 9:29:51.024481	Training Loss 0.7819 (0.7839)	Training Prec@1 3.516 (2.504)	Training Prec@5 5.664 (5.713)	
2022-04-01 04:07:04,315: ============================================================
2022-04-01 04:07:44,718: time cost, forward:0.12270789808775132, backward:0.03297896312221911, data cost:0.2533083326890933 
2022-04-01 04:07:44,719: ============================================================
2022-04-01 04:07:44,719: Epoch 21/31 Batch 1700/7662 eta: 9:16:07.120261	Training Loss 0.7796 (0.7835)	Training Prec@1 1.953 (2.534)	Training Prec@5 4.883 (5.781)	
2022-04-01 04:07:44,719: ============================================================
2022-04-01 04:08:26,700: time cost, forward:0.12230643886801533, backward:0.032999400763858884, data cost:0.25427515417950364 
2022-04-01 04:08:26,701: ============================================================
2022-04-01 04:08:26,702: Epoch 21/31 Batch 1800/7662 eta: 9:37:08.504593	Training Loss 0.7758 (0.7832)	Training Prec@1 3.320 (2.559)	Training Prec@5 7.812 (5.833)	
2022-04-01 04:08:26,702: ============================================================
2022-04-01 04:09:08,412: time cost, forward:0.12336950580844006, backward:0.03300386482066013, data cost:0.2534934638235806 
2022-04-01 04:09:08,412: ============================================================
2022-04-01 04:09:08,413: Epoch 21/31 Batch 1900/7662 eta: 9:32:42.597309	Training Loss 0.7772 (0.7830)	Training Prec@1 2.930 (2.590)	Training Prec@5 6.250 (5.887)	
2022-04-01 04:09:08,413: ============================================================
2022-04-01 04:09:49,896: time cost, forward:0.12393906678242228, backward:0.03306067854598381, data cost:0.2531623351329443 
2022-04-01 04:09:49,896: ============================================================
2022-04-01 04:09:49,897: Epoch 21/31 Batch 2000/7662 eta: 9:28:54.287344	Training Loss 0.7778 (0.7827)	Training Prec@1 3.516 (2.616)	Training Prec@5 8.398 (5.932)	
2022-04-01 04:09:49,897: ============================================================
2022-04-01 04:10:32,295: time cost, forward:0.12494366290513648, backward:0.03316736471204317, data cost:0.252706754997039 
2022-04-01 04:10:32,295: ============================================================
2022-04-01 04:10:32,295: Epoch 21/31 Batch 2100/7662 eta: 9:40:44.721127	Training Loss 0.7782 (0.7825)	Training Prec@1 2.734 (2.647)	Training Prec@5 7.422 (5.995)	
2022-04-01 04:10:32,296: ============================================================
2022-04-01 04:11:13,288: time cost, forward:0.1243567895000227, backward:0.033211432244898025, data cost:0.25321438758142323 
2022-04-01 04:11:13,288: ============================================================
2022-04-01 04:11:13,289: Epoch 21/31 Batch 2200/7662 eta: 9:20:48.380109	Training Loss 0.7781 (0.7823)	Training Prec@1 3.516 (2.670)	Training Prec@5 8.789 (6.047)	
2022-04-01 04:11:13,289: ============================================================
2022-04-01 04:11:55,699: time cost, forward:0.12530792096533325, backward:0.03320174115592887, data cost:0.2528271221917523 
2022-04-01 04:11:55,700: ============================================================
2022-04-01 04:11:55,700: Epoch 21/31 Batch 2300/7662 eta: 9:39:30.066393	Training Loss 0.8334 (0.7822)	Training Prec@1 0.195 (2.682)	Training Prec@5 0.586 (6.074)	
2022-04-01 04:11:55,700: ============================================================
2022-04-01 04:12:37,862: time cost, forward:0.12598263944074878, backward:0.03319580220043187, data cost:0.25256158292865 
2022-04-01 04:12:37,862: ============================================================
2022-04-01 04:12:37,862: Epoch 21/31 Batch 2400/7662 eta: 9:35:23.917064	Training Loss 0.7749 (0.7826)	Training Prec@1 3.320 (2.659)	Training Prec@5 8.984 (6.022)	
2022-04-01 04:12:37,863: ============================================================
2022-04-01 04:13:18,132: time cost, forward:0.12557738759413678, backward:0.03312383302930547, data cost:0.252658623321002 
2022-04-01 04:13:18,133: ============================================================
2022-04-01 04:13:18,133: Epoch 21/31 Batch 2500/7662 eta: 9:08:54.336006	Training Loss 0.8451 (0.7834)	Training Prec@1 0.195 (2.635)	Training Prec@5 0.195 (5.964)	
2022-04-01 04:13:18,133: ============================================================
2022-04-01 04:14:01,285: time cost, forward:0.12618328581043461, backward:0.03317083969351052, data cost:0.25277802264428956 
2022-04-01 04:14:01,285: ============================================================
2022-04-01 04:14:01,285: Epoch 21/31 Batch 2600/7662 eta: 9:47:28.307334	Training Loss 0.7805 (0.7841)	Training Prec@1 2.539 (2.575)	Training Prec@5 6.055 (5.837)	
2022-04-01 04:14:01,286: ============================================================
2022-04-01 04:14:43,995: time cost, forward:0.12575054875388328, backward:0.03311558642534028, data cost:0.2537998117840524 
2022-04-01 04:14:43,995: ============================================================
2022-04-01 04:14:43,995: Epoch 21/31 Batch 2700/7662 eta: 9:40:43.868643	Training Loss 0.8622 (0.7841)	Training Prec@1 0.000 (2.588)	Training Prec@5 0.000 (5.863)	
2022-04-01 04:14:43,995: ============================================================
2022-04-01 04:15:23,073: time cost, forward:0.1256823993742828, backward:0.033077833438694755, data cost:0.25308055237132593 
2022-04-01 04:15:23,074: ============================================================
2022-04-01 04:15:23,074: Epoch 21/31 Batch 2800/7662 eta: 8:50:42.700382	Training Loss 0.8111 (0.7864)	Training Prec@1 0.000 (2.497)	Training Prec@5 0.195 (5.658)	
2022-04-01 04:15:23,074: ============================================================
2022-04-01 04:16:03,741: time cost, forward:0.1253594838162462, backward:0.033032805231284504, data cost:0.25327636776977097 
2022-04-01 04:16:03,741: ============================================================
2022-04-01 04:16:03,741: Epoch 21/31 Batch 2900/7662 eta: 9:11:36.391764	Training Loss 0.7759 (0.7864)	Training Prec@1 3.711 (2.480)	Training Prec@5 7.227 (5.622)	
2022-04-01 04:16:03,742: ============================================================
2022-04-01 04:16:46,151: time cost, forward:0.1257539453725888, backward:0.03303552540432179, data cost:0.25326811523984455 
2022-04-01 04:16:46,152: ============================================================
2022-04-01 04:16:46,152: Epoch 21/31 Batch 3000/7662 eta: 9:34:32.295366	Training Loss 0.7780 (0.7861)	Training Prec@1 3.125 (2.507)	Training Prec@5 8.008 (5.678)	
2022-04-01 04:16:46,152: ============================================================
2022-04-01 04:17:26,919: time cost, forward:0.12605585625726357, backward:0.03303637909250669, data cost:0.2528302878016385 
2022-04-01 04:17:26,920: ============================================================
2022-04-01 04:17:26,920: Epoch 21/31 Batch 3100/7662 eta: 9:11:36.872323	Training Loss 0.7761 (0.7858)	Training Prec@1 4.883 (2.537)	Training Prec@5 8.594 (5.728)	
2022-04-01 04:17:26,920: ============================================================
2022-04-01 04:18:08,297: time cost, forward:0.12603063104897225, backward:0.03301667645410584, data cost:0.25290428030748 
2022-04-01 04:18:08,298: ============================================================
2022-04-01 04:18:08,298: Epoch 21/31 Batch 3200/7662 eta: 9:19:10.499012	Training Loss 0.7728 (0.7855)	Training Prec@1 5.078 (2.568)	Training Prec@5 9.570 (5.787)	
2022-04-01 04:18:08,298: ============================================================
2022-04-01 04:18:49,398: time cost, forward:0.12634410689042605, backward:0.03302930528086292, data cost:0.2525719783276491 
2022-04-01 04:18:49,399: ============================================================
2022-04-01 04:18:49,399: Epoch 21/31 Batch 3300/7662 eta: 9:14:44.676727	Training Loss 0.7754 (0.7852)	Training Prec@1 3.516 (2.598)	Training Prec@5 7.617 (5.847)	
2022-04-01 04:18:49,399: ============================================================
2022-04-01 04:19:30,568: time cost, forward:0.12610182245888055, backward:0.033057189962729945, data cost:0.25275474318548946 
2022-04-01 04:19:30,568: ============================================================
2022-04-01 04:19:30,569: Epoch 21/31 Batch 3400/7662 eta: 9:14:59.436863	Training Loss 0.7737 (0.7850)	Training Prec@1 2.344 (2.627)	Training Prec@5 7.227 (5.901)	
2022-04-01 04:19:30,569: ============================================================
2022-04-01 04:20:12,289: time cost, forward:0.12644531747960266, backward:0.033069883833343076, data cost:0.25255100159482907 
2022-04-01 04:20:12,289: ============================================================
2022-04-01 04:20:12,289: Epoch 21/31 Batch 3500/7662 eta: 9:21:43.155098	Training Loss 0.8247 (0.7847)	Training Prec@1 0.977 (2.656)	Training Prec@5 1.562 (5.955)	
2022-04-01 04:20:12,289: ============================================================
2022-04-01 04:20:52,538: time cost, forward:0.12647917364066957, backward:0.03306336196206218, data cost:0.2522522255790734 
2022-04-01 04:20:52,539: ============================================================
2022-04-01 04:20:52,539: Epoch 21/31 Batch 3600/7662 eta: 9:01:14.493919	Training Loss 0.7850 (0.7849)	Training Prec@1 2.344 (2.641)	Training Prec@5 4.688 (5.926)	
2022-04-01 04:20:52,539: ============================================================
2022-04-01 04:21:34,922: time cost, forward:0.12667689809415042, backward:0.03306396570228892, data cost:0.25236864952372035 
2022-04-01 04:21:34,923: ============================================================
2022-04-01 04:21:34,923: Epoch 21/31 Batch 3700/7662 eta: 9:29:14.273026	Training Loss 0.7760 (0.7848)	Training Prec@1 4.297 (2.664)	Training Prec@5 8.789 (5.963)	
2022-04-01 04:21:34,923: ============================================================
2022-04-01 04:22:16,685: time cost, forward:0.126947554954575, backward:0.03305183815058673, data cost:0.25223915769602634 
2022-04-01 04:22:16,685: ============================================================
2022-04-01 04:22:16,685: Epoch 21/31 Batch 3800/7662 eta: 9:20:11.695452	Training Loss 0.8127 (0.7856)	Training Prec@1 0.000 (2.633)	Training Prec@5 0.195 (5.893)	
2022-04-01 04:22:16,685: ============================================================
2022-04-01 04:22:59,102: time cost, forward:0.12774882270116383, backward:0.033065420629183856, data cost:0.2517051469304373 
2022-04-01 04:22:59,103: ============================================================
2022-04-01 04:22:59,103: Epoch 21/31 Batch 3900/7662 eta: 9:28:16.533400	Training Loss 0.7803 (0.7856)	Training Prec@1 2.930 (2.624)	Training Prec@5 6.836 (5.876)	
2022-04-01 04:22:59,103: ============================================================
2022-04-01 04:23:39,748: time cost, forward:0.12752296042817926, backward:0.03306017705397953, data cost:0.25179466422601593 
2022-04-01 04:23:39,749: ============================================================
2022-04-01 04:23:39,749: Epoch 21/31 Batch 4000/7662 eta: 9:03:51.727234	Training Loss 0.7760 (0.7854)	Training Prec@1 3.906 (2.650)	Training Prec@5 8.008 (5.925)	
2022-04-01 04:23:39,749: ============================================================
2022-04-01 04:24:20,926: time cost, forward:0.12779851359953442, backward:0.03307999212819211, data cost:0.25147074680556375 
2022-04-01 04:24:20,927: ============================================================
2022-04-01 04:24:20,927: Epoch 21/31 Batch 4100/7662 eta: 9:10:18.020299	Training Loss 0.7755 (0.7851)	Training Prec@1 3.906 (2.675)	Training Prec@5 9.766 (5.974)	
2022-04-01 04:24:20,927: ============================================================
2022-04-01 04:25:00,828: time cost, forward:0.12741247294317629, backward:0.03307028616232712, data cost:0.2515457542375827 
2022-04-01 04:25:00,829: ============================================================
2022-04-01 04:25:00,829: Epoch 21/31 Batch 4200/7662 eta: 8:52:34.458188	Training Loss 0.8669 (0.7858)	Training Prec@1 0.000 (2.662)	Training Prec@5 0.000 (5.941)	
2022-04-01 04:25:00,829: ============================================================
2022-04-01 04:25:41,970: time cost, forward:0.12764196430258654, backward:0.03307907013982971, data cost:0.25127476457940556 
2022-04-01 04:25:41,970: ============================================================
2022-04-01 04:25:41,971: Epoch 21/31 Batch 4300/7662 eta: 9:08:26.464523	Training Loss 0.8614 (0.7876)	Training Prec@1 0.000 (2.600)	Training Prec@5 0.000 (5.804)	
2022-04-01 04:25:41,971: ============================================================
2022-04-01 04:26:22,144: time cost, forward:0.12742070941443767, backward:0.0330597325654755, data cost:0.25126574542961977 
2022-04-01 04:26:22,144: ============================================================
2022-04-01 04:26:22,144: Epoch 21/31 Batch 4400/7662 eta: 8:54:51.890949	Training Loss 0.8558 (0.7893)	Training Prec@1 0.000 (2.541)	Training Prec@5 0.391 (5.673)	
2022-04-01 04:26:22,144: ============================================================
2022-04-01 04:27:04,413: time cost, forward:0.12776968955569704, backward:0.0330717388749997, data cost:0.25114984463574913 
2022-04-01 04:27:04,413: ============================================================
2022-04-01 04:27:04,413: Epoch 21/31 Batch 4500/7662 eta: 9:22:03.501802	Training Loss 0.8507 (0.7907)	Training Prec@1 0.000 (2.485)	Training Prec@5 0.000 (5.547)	
2022-04-01 04:27:04,413: ============================================================
2022-04-01 04:27:44,400: time cost, forward:0.12759139631644206, backward:0.03308355313172727, data cost:0.25104523954455765 
2022-04-01 04:27:44,400: ============================================================
2022-04-01 04:27:44,401: Epoch 21/31 Batch 4600/7662 eta: 8:51:03.125980	Training Loss 0.8312 (0.7918)	Training Prec@1 0.000 (2.431)	Training Prec@5 0.000 (5.427)	
2022-04-01 04:27:44,401: ============================================================
2022-04-01 04:28:25,354: time cost, forward:0.1273551924377331, backward:0.033097426113511026, data cost:0.2512186813110949 
2022-04-01 04:28:25,354: ============================================================
2022-04-01 04:28:25,354: Epoch 21/31 Batch 4700/7662 eta: 9:03:12.202667	Training Loss 0.8159 (0.7925)	Training Prec@1 0.195 (2.380)	Training Prec@5 0.586 (5.316)	
2022-04-01 04:28:25,354: ============================================================
2022-04-01 04:29:06,672: time cost, forward:0.12718256420581434, backward:0.033125555249496556, data cost:0.25138043562405604 
2022-04-01 04:29:06,672: ============================================================
2022-04-01 04:29:06,673: Epoch 21/31 Batch 4800/7662 eta: 9:07:20.974178	Training Loss 0.8101 (0.7929)	Training Prec@1 0.195 (2.334)	Training Prec@5 0.586 (5.218)	
2022-04-01 04:29:06,673: ============================================================
2022-04-01 04:29:48,203: time cost, forward:0.12728622373840617, backward:0.03314335415815426, data cost:0.2513345932809643 
2022-04-01 04:29:48,203: ============================================================
2022-04-01 04:29:48,203: Epoch 21/31 Batch 4900/7662 eta: 9:09:28.366468	Training Loss 0.7804 (0.7930)	Training Prec@1 2.344 (2.309)	Training Prec@5 6.641 (5.168)	
2022-04-01 04:29:48,203: ============================================================
2022-04-01 04:30:29,102: time cost, forward:0.12743156427000732, backward:0.0331653796045464, data cost:0.25110445959278527 
2022-04-01 04:30:29,102: ============================================================
2022-04-01 04:30:29,103: Epoch 21/31 Batch 5000/7662 eta: 9:00:26.186615	Training Loss 0.7748 (0.7927)	Training Prec@1 3.906 (2.330)	Training Prec@5 8.398 (5.211)	
2022-04-01 04:30:29,103: ============================================================
2022-04-01 04:31:10,799: time cost, forward:0.12752812253327714, backward:0.03319287678848928, data cost:0.2510747492932927 
2022-04-01 04:31:10,800: ============================================================
2022-04-01 04:31:10,800: Epoch 21/31 Batch 5100/7662 eta: 9:10:17.295548	Training Loss 0.7756 (0.7924)	Training Prec@1 2.930 (2.352)	Training Prec@5 5.664 (5.258)	
2022-04-01 04:31:10,800: ============================================================
2022-04-01 04:31:51,667: time cost, forward:0.1273526169057304, backward:0.03319163206885195, data cost:0.2511741910033053 
2022-04-01 04:31:51,668: ============================================================
2022-04-01 04:31:51,668: Epoch 21/31 Batch 5200/7662 eta: 8:58:39.550715	Training Loss 0.7769 (0.7921)	Training Prec@1 3.125 (2.379)	Training Prec@5 5.664 (5.309)	
2022-04-01 04:31:51,668: ============================================================
2022-04-01 04:32:34,156: time cost, forward:0.12706407022197239, backward:0.03320776626599872, data cost:0.25169981477575093 
2022-04-01 04:32:34,156: ============================================================
2022-04-01 04:32:34,156: Epoch 21/31 Batch 5300/7662 eta: 9:19:18.528972	Training Loss 0.7732 (0.7917)	Training Prec@1 3.516 (2.404)	Training Prec@5 8.789 (5.358)	
2022-04-01 04:32:34,156: ============================================================
2022-04-01 04:33:13,208: time cost, forward:0.12677806416006523, backward:0.03321992549482905, data cost:0.2515652123635114 
2022-04-01 04:33:13,208: ============================================================
2022-04-01 04:33:13,208: Epoch 21/31 Batch 5400/7662 eta: 8:33:25.523855	Training Loss 0.7736 (0.7914)	Training Prec@1 3.711 (2.433)	Training Prec@5 8.008 (5.411)	
2022-04-01 04:33:13,209: ============================================================
2022-04-01 04:33:54,136: time cost, forward:0.12659061468824687, backward:0.033227773552960665, data cost:0.25170499776835703 
2022-04-01 04:33:54,136: ============================================================
2022-04-01 04:33:54,137: Epoch 21/31 Batch 5500/7662 eta: 8:57:24.383794	Training Loss 0.7745 (0.7911)	Training Prec@1 2.539 (2.457)	Training Prec@5 5.859 (5.459)	
2022-04-01 04:33:54,137: ============================================================
2022-04-01 04:34:36,076: time cost, forward:0.12699175966831378, backward:0.03326220583928485, data cost:0.2513950884948992 
2022-04-01 04:34:36,077: ============================================================
2022-04-01 04:34:36,077: Epoch 21/31 Batch 5600/7662 eta: 9:09:59.993919	Training Loss 0.7749 (0.7908)	Training Prec@1 2.930 (2.481)	Training Prec@5 8.008 (5.506)	
2022-04-01 04:34:36,077: ============================================================
2022-04-01 04:35:17,087: time cost, forward:0.12710000080149475, backward:0.03327877870001779, data cost:0.2512366727352728 
2022-04-01 04:35:17,087: ============================================================
2022-04-01 04:35:17,087: Epoch 21/31 Batch 5700/7662 eta: 8:57:07.103940	Training Loss 0.7782 (0.7906)	Training Prec@1 2.734 (2.508)	Training Prec@5 7.227 (5.558)	
2022-04-01 04:35:17,087: ============================================================
2022-04-01 04:35:57,892: time cost, forward:0.12701926064462493, backward:0.03325194181049871, data cost:0.25127518166754037 
2022-04-01 04:35:57,892: ============================================================
2022-04-01 04:35:57,892: Epoch 21/31 Batch 5800/7662 eta: 8:53:45.050138	Training Loss 0.7733 (0.7903)	Training Prec@1 3.516 (2.533)	Training Prec@5 9.180 (5.608)	
2022-04-01 04:35:57,892: ============================================================
2022-04-01 04:36:38,191: time cost, forward:0.12673783936850558, backward:0.033216064189284265, data cost:0.251436600100693 
2022-04-01 04:36:38,191: ============================================================
2022-04-01 04:36:38,192: Epoch 21/31 Batch 5900/7662 eta: 8:46:27.735063	Training Loss 0.8598 (0.7913)	Training Prec@1 0.000 (2.499)	Training Prec@5 0.000 (5.531)	
2022-04-01 04:36:38,192: ============================================================
2022-04-01 04:37:18,595: time cost, forward:0.12648595072941335, backward:0.03318960461184907, data cost:0.2515971599409711 
2022-04-01 04:37:18,595: ============================================================
2022-04-01 04:37:18,595: Epoch 21/31 Batch 6000/7662 eta: 8:47:09.386272	Training Loss 0.8563 (0.7924)	Training Prec@1 0.000 (2.457)	Training Prec@5 0.000 (5.439)	
2022-04-01 04:37:18,596: ============================================================
2022-04-01 04:37:59,091: time cost, forward:0.126294260514449, backward:0.033165100031669933, data cost:0.2516847277571088 
2022-04-01 04:37:59,091: ============================================================
2022-04-01 04:37:59,091: Epoch 21/31 Batch 6100/7662 eta: 8:47:40.924343	Training Loss 0.8500 (0.7934)	Training Prec@1 0.000 (2.417)	Training Prec@5 0.195 (5.351)	
2022-04-01 04:37:59,092: ============================================================
2022-04-01 04:38:42,405: time cost, forward:0.12634622156475797, backward:0.03316414915836517, data cost:0.25199440368280657 
2022-04-01 04:38:42,406: ============================================================
2022-04-01 04:38:42,406: Epoch 21/31 Batch 6200/7662 eta: 9:23:41.396263	Training Loss 0.8368 (0.7943)	Training Prec@1 0.195 (2.378)	Training Prec@5 0.391 (5.265)	
2022-04-01 04:38:42,406: ============================================================
2022-04-01 04:39:22,006: time cost, forward:0.1263459562252279, backward:0.03316341231485873, data cost:0.25173088145040295 
2022-04-01 04:39:22,006: ============================================================
2022-04-01 04:39:22,006: Epoch 21/31 Batch 6300/7662 eta: 8:34:41.501449	Training Loss 0.8179 (0.7948)	Training Prec@1 0.000 (2.341)	Training Prec@5 0.195 (5.184)	
2022-04-01 04:39:22,006: ============================================================
2022-04-01 04:40:03,680: time cost, forward:0.1265344526604165, backward:0.03316986898012991, data cost:0.2516300265426505 
2022-04-01 04:40:03,681: ============================================================
2022-04-01 04:40:03,681: Epoch 21/31 Batch 6400/7662 eta: 9:00:57.541527	Training Loss 0.8103 (0.7951)	Training Prec@1 0.391 (2.308)	Training Prec@5 0.781 (5.114)	
2022-04-01 04:40:03,681: ============================================================
2022-04-01 04:40:45,154: time cost, forward:0.12679106243795057, backward:0.0331783755079822, data cost:0.2513786233889358 
2022-04-01 04:40:45,154: ============================================================
2022-04-01 04:40:45,155: Epoch 21/31 Batch 6500/7662 eta: 8:57:39.385183	Training Loss 0.7779 (0.7951)	Training Prec@1 3.711 (2.290)	Training Prec@5 6.641 (5.079)	
2022-04-01 04:40:45,155: ============================================================
2022-04-01 04:41:24,905: time cost, forward:0.12654127780551855, backward:0.03315035912787884, data cost:0.2514740956843053 
2022-04-01 04:41:24,905: ============================================================
2022-04-01 04:41:24,905: Epoch 21/31 Batch 6600/7662 eta: 8:34:39.402557	Training Loss 0.7754 (0.7948)	Training Prec@1 2.344 (2.312)	Training Prec@5 7.422 (5.125)	
2022-04-01 04:41:24,905: ============================================================
2022-04-01 04:42:06,164: time cost, forward:0.12629215598800392, backward:0.03312461154463398, data cost:0.25175478537058826 
2022-04-01 04:42:06,165: ============================================================
2022-04-01 04:42:06,165: Epoch 21/31 Batch 6700/7662 eta: 8:53:30.505699	Training Loss 0.7723 (0.7945)	Training Prec@1 4.297 (2.338)	Training Prec@5 9.375 (5.173)	
2022-04-01 04:42:06,165: ============================================================
2022-04-01 04:42:46,976: time cost, forward:0.1260472059004411, backward:0.03310518195338417, data cost:0.25197237076908724 
2022-04-01 04:42:46,976: ============================================================
2022-04-01 04:42:46,977: Epoch 21/31 Batch 6800/7662 eta: 8:47:02.087658	Training Loss 0.7696 (0.7942)	Training Prec@1 5.273 (2.361)	Training Prec@5 10.742 (5.221)	
2022-04-01 04:42:46,977: ============================================================
2022-04-01 04:43:30,528: time cost, forward:0.12612021043691485, backward:0.033101979399577555, data cost:0.25225663713863544 
2022-04-01 04:43:30,528: ============================================================
2022-04-01 04:43:30,529: Epoch 21/31 Batch 6900/7662 eta: 9:21:41.821318	Training Loss 0.7717 (0.7939)	Training Prec@1 3.125 (2.389)	Training Prec@5 8.203 (5.274)	
2022-04-01 04:43:30,529: ============================================================
2022-04-01 04:44:10,516: time cost, forward:0.1260071211941737, backward:0.033077502662853815, data cost:0.25222560415473694 
2022-04-01 04:44:10,517: ============================================================
2022-04-01 04:44:10,517: Epoch 21/31 Batch 7000/7662 eta: 8:35:04.095860	Training Loss 0.7705 (0.7936)	Training Prec@1 5.078 (2.415)	Training Prec@5 10.352 (5.325)	
2022-04-01 04:44:10,517: ============================================================
2022-04-01 04:44:51,209: time cost, forward:0.12582164661097417, backward:0.0330470683020863, data cost:0.2523715360716441 
2022-04-01 04:44:51,209: ============================================================
2022-04-01 04:44:51,209: Epoch 21/31 Batch 7100/7662 eta: 8:43:27.755298	Training Loss 0.7748 (0.7933)	Training Prec@1 5.078 (2.441)	Training Prec@5 10.352 (5.376)	
2022-04-01 04:44:51,209: ============================================================
2022-04-01 04:45:32,559: time cost, forward:0.12579548079067676, backward:0.033024828373384, data cost:0.2524405470621687 
2022-04-01 04:45:32,560: ============================================================
2022-04-01 04:45:32,560: Epoch 21/31 Batch 7200/7662 eta: 8:51:14.242570	Training Loss 0.7733 (0.7931)	Training Prec@1 2.930 (2.466)	Training Prec@5 8.789 (5.426)	
2022-04-01 04:45:32,560: ============================================================
2022-04-01 04:46:13,386: time cost, forward:0.12585366561096292, backward:0.03301687733182059, data cost:0.25234572180886355 
2022-04-01 04:46:13,386: ============================================================
2022-04-01 04:46:13,387: Epoch 21/31 Batch 7300/7662 eta: 8:43:49.696628	Training Loss 0.7711 (0.7928)	Training Prec@1 5.469 (2.490)	Training Prec@5 9.766 (5.474)	
2022-04-01 04:46:13,387: ============================================================
2022-04-01 04:46:55,923: time cost, forward:0.1259385683936418, backward:0.03301912227954908, data cost:0.25236688641087884 
2022-04-01 04:46:55,923: ============================================================
2022-04-01 04:46:55,924: Epoch 21/31 Batch 7400/7662 eta: 9:05:03.641194	Training Loss 0.7730 (0.7925)	Training Prec@1 4.883 (2.516)	Training Prec@5 10.156 (5.522)	
2022-04-01 04:46:55,924: ============================================================
2022-04-01 04:47:36,364: time cost, forward:0.12573297587469873, backward:0.033008147214377524, data cost:0.2525622325828034 
2022-04-01 04:47:36,364: ============================================================
2022-04-01 04:47:36,364: Epoch 21/31 Batch 7500/7662 eta: 8:37:31.577780	Training Loss 0.8473 (0.7924)	Training Prec@1 0.000 (2.530)	Training Prec@5 0.000 (5.549)	
2022-04-01 04:47:36,364: ============================================================
2022-04-01 04:48:16,273: time cost, forward:0.12554833556118883, backward:0.03300264672646947, data cost:0.252592233187714 
2022-04-01 04:48:16,274: ============================================================
2022-04-01 04:48:16,274: Epoch 21/31 Batch 7600/7662 eta: 8:30:04.121011	Training Loss 0.7797 (0.7927)	Training Prec@1 2.148 (2.508)	Training Prec@5 4.297 (5.501)	
2022-04-01 04:48:16,274: ============================================================
2022-04-01 04:48:45,293: Epoch: 21/31 eta: 8:29:38.977764	Training Loss 0.7720 (0.7925)	Training Prec@1 4.688 (2.524)	Training Prec@5 8.398 (5.532)
2022-04-01 04:48:45,293: ============================================================
2022-04-01 04:49:25,654: time cost, forward:0.10916081823483863, backward:0.03209916750590006, data cost:0.2639481443347353 
2022-04-01 04:49:25,655: ============================================================
2022-04-01 04:49:25,655: Epoch 22/31 Batch 100/7662 eta: 8:34:42.028494	Training Loss 0.7668 (0.7697)	Training Prec@1 4.688 (4.713)	Training Prec@5 8.984 (10.115)	
2022-04-01 04:49:25,656: ============================================================
2022-04-01 04:50:06,651: time cost, forward:0.10794344020249257, backward:0.03260299668240188, data cost:0.2668008205279633 
2022-04-01 04:50:06,652: ============================================================
2022-04-01 04:50:06,652: Epoch 22/31 Batch 200/7662 eta: 8:42:10.045144	Training Loss 0.7683 (0.7696)	Training Prec@1 5.859 (4.792)	Training Prec@5 12.305 (10.081)	
2022-04-01 04:50:06,652: ============================================================
2022-04-01 04:50:45,749: time cost, forward:0.10758806869736483, backward:0.03280906852671135, data cost:0.2612201944242752 
2022-04-01 04:50:45,750: ============================================================
2022-04-01 04:50:45,750: Epoch 22/31 Batch 300/7662 eta: 8:17:20.164580	Training Loss 0.7746 (0.7702)	Training Prec@1 5.273 (4.816)	Training Prec@5 11.523 (10.020)	
2022-04-01 04:50:45,750: ============================================================
2022-04-01 04:51:26,730: time cost, forward:0.10802144872813595, backward:0.03309659611312369, data cost:0.26258943612712965 
2022-04-01 04:51:26,731: ============================================================
2022-04-01 04:51:26,731: Epoch 22/31 Batch 400/7662 eta: 8:40:35.920984	Training Loss 0.8410 (0.7867)	Training Prec@1 0.000 (3.811)	Training Prec@5 0.391 (7.961)	
2022-04-01 04:51:26,731: ============================================================
2022-04-01 04:52:06,958: time cost, forward:0.10805089631395971, backward:0.03240417956350323, data cost:0.2627748444467365 
2022-04-01 04:52:06,959: ============================================================
2022-04-01 04:52:06,959: Epoch 22/31 Batch 500/7662 eta: 8:30:21.990124	Training Loss 0.7679 (0.7899)	Training Prec@1 5.469 (3.339)	Training Prec@5 12.109 (7.007)	
2022-04-01 04:52:06,959: ============================================================
2022-04-01 04:52:47,007: time cost, forward:0.10813434334947589, backward:0.03243000758112174, data cost:0.26217635207263773 
2022-04-01 04:52:47,007: ============================================================
2022-04-01 04:52:47,008: Epoch 22/31 Batch 600/7662 eta: 8:27:25.341099	Training Loss 0.7710 (0.7866)	Training Prec@1 5.859 (3.596)	Training Prec@5 9.570 (7.471)	
2022-04-01 04:52:47,008: ============================================================
2022-04-01 04:53:26,547: time cost, forward:0.10836893328610749, backward:0.032659814422563764, data cost:0.2607021000934432 
2022-04-01 04:53:26,547: ============================================================
2022-04-01 04:53:26,547: Epoch 22/31 Batch 700/7662 eta: 8:20:19.015667	Training Loss 0.7684 (0.7842)	Training Prec@1 2.930 (3.786)	Training Prec@5 8.398 (7.830)	
2022-04-01 04:53:26,548: ============================================================
2022-04-01 04:54:07,984: time cost, forward:0.10859993372452871, backward:0.032778831835234716, data cost:0.2612039711657394 
2022-04-01 04:54:07,984: ============================================================
2022-04-01 04:54:07,984: Epoch 22/31 Batch 800/7662 eta: 8:43:37.955390	Training Loss 0.7674 (0.7824)	Training Prec@1 5.273 (3.908)	Training Prec@5 10.156 (8.068)	
2022-04-01 04:54:07,985: ============================================================
2022-04-01 04:54:47,048: time cost, forward:0.10880470647164792, backward:0.03277617275250767, data cost:0.2601853026961856 
2022-04-01 04:54:47,049: ============================================================
2022-04-01 04:54:47,049: Epoch 22/31 Batch 900/7662 eta: 8:12:59.960250	Training Loss 0.8530 (0.7838)	Training Prec@1 0.000 (3.870)	Training Prec@5 0.195 (7.976)	
2022-04-01 04:54:47,049: ============================================================
2022-04-01 04:55:26,804: time cost, forward:0.1089627814364505, backward:0.03254029676840231, data cost:0.2598413738521847 
2022-04-01 04:55:26,804: ============================================================
2022-04-01 04:55:26,804: Epoch 22/31 Batch 1000/7662 eta: 8:21:03.376181	Training Loss 0.8420 (0.7904)	Training Prec@1 0.000 (3.484)	Training Prec@5 0.195 (7.184)	
2022-04-01 04:55:26,804: ============================================================
2022-04-01 04:56:06,073: time cost, forward:0.10907174631939681, backward:0.03268749807182499, data cost:0.25874242465858355 
2022-04-01 04:56:06,074: ============================================================
2022-04-01 04:56:06,074: Epoch 22/31 Batch 1100/7662 eta: 8:14:17.017101	Training Loss 0.8059 (0.7934)	Training Prec@1 1.172 (3.177)	Training Prec@5 2.344 (6.562)	
2022-04-01 04:56:06,074: ============================================================
2022-04-01 04:56:46,696: time cost, forward:0.10925455805259113, backward:0.032877567313530726, data cost:0.25857666256628603 
2022-04-01 04:56:46,697: ============================================================
2022-04-01 04:56:46,697: Epoch 22/31 Batch 1200/7662 eta: 8:30:38.340910	Training Loss 0.7746 (0.7925)	Training Prec@1 3.125 (3.187)	Training Prec@5 8.398 (6.608)	
2022-04-01 04:56:46,697: ============================================================
2022-04-01 04:57:25,996: time cost, forward:0.10942862068716612, backward:0.03290879496984798, data cost:0.25769783791622075 
2022-04-01 04:57:25,996: ============================================================
2022-04-01 04:57:25,996: Epoch 22/31 Batch 1300/7662 eta: 8:13:20.495884	Training Loss 0.7729 (0.7907)	Training Prec@1 3.516 (3.312)	Training Prec@5 8.984 (6.878)	
2022-04-01 04:57:25,996: ============================================================
2022-04-01 04:58:05,672: time cost, forward:0.1094582413161457, backward:0.033011277289455326, data cost:0.2575667971283134 
2022-04-01 04:58:05,672: ============================================================
2022-04-01 04:58:05,673: Epoch 22/31 Batch 1400/7662 eta: 8:17:24.990184	Training Loss 0.7696 (0.7892)	Training Prec@1 6.641 (3.433)	Training Prec@5 11.133 (7.113)	
2022-04-01 04:58:05,673: ============================================================
2022-04-01 04:58:45,451: time cost, forward:0.10942329924610791, backward:0.03300187156707784, data cost:0.2574459113145845 
2022-04-01 04:58:45,451: ============================================================
2022-04-01 04:58:45,451: Epoch 22/31 Batch 1500/7662 eta: 8:18:02.267102	Training Loss 0.7700 (0.7879)	Training Prec@1 3.906 (3.545)	Training Prec@5 9.570 (7.329)	
2022-04-01 04:58:45,452: ============================================================
2022-04-01 04:59:25,246: time cost, forward:0.10951756208370893, backward:0.03300102164105671, data cost:0.2572170839673508 
2022-04-01 04:59:25,247: ============================================================
2022-04-01 04:59:25,247: Epoch 22/31 Batch 1600/7662 eta: 8:17:34.929857	Training Loss 0.7686 (0.7867)	Training Prec@1 4.883 (3.656)	Training Prec@5 10.156 (7.536)	
2022-04-01 04:59:25,247: ============================================================
2022-04-01 05:00:04,568: time cost, forward:0.10958754546225527, backward:0.03299429137402243, data cost:0.25674614813694047 
2022-04-01 05:00:04,568: ============================================================
2022-04-01 05:00:04,568: Epoch 22/31 Batch 1700/7662 eta: 8:11:00.101253	Training Loss 0.8419 (0.7867)	Training Prec@1 0.000 (3.661)	Training Prec@5 0.391 (7.558)	
2022-04-01 05:00:04,569: ============================================================
2022-04-01 05:00:43,539: time cost, forward:0.1096562985382589, backward:0.03305547180409031, data cost:0.2560495137505693 
2022-04-01 05:00:43,539: ============================================================
2022-04-01 05:00:43,539: Epoch 22/31 Batch 1800/7662 eta: 8:05:58.238746	Training Loss 0.7701 (0.7868)	Training Prec@1 5.078 (3.629)	Training Prec@5 9.570 (7.484)	
2022-04-01 05:00:43,539: ============================================================
2022-04-01 05:01:23,521: time cost, forward:0.10972212301297461, backward:0.03315666689880275, data cost:0.2559446073193623 
2022-04-01 05:01:23,522: ============================================================
2022-04-01 05:01:23,522: Epoch 22/31 Batch 1900/7662 eta: 8:17:55.569371	Training Loss 0.8398 (0.7861)	Training Prec@1 0.391 (3.700)	Training Prec@5 0.586 (7.616)	
2022-04-01 05:01:23,522: ============================================================
2022-04-01 05:02:02,323: time cost, forward:0.10982902530672074, backward:0.033121172340587715, data cost:0.25530170356708504 
2022-04-01 05:02:02,323: ============================================================
2022-04-01 05:02:02,324: Epoch 22/31 Batch 2000/7662 eta: 8:02:34.141743	Training Loss 0.7680 (0.7869)	Training Prec@1 4.688 (3.617)	Training Prec@5 11.133 (7.462)	
2022-04-01 05:02:02,324: ============================================================
2022-04-01 05:02:41,614: time cost, forward:0.10988894776539214, backward:0.03314364859466044, data cost:0.2549609022517611 
2022-04-01 05:02:41,614: ============================================================
2022-04-01 05:02:41,614: Epoch 22/31 Batch 2100/7662 eta: 8:07:59.746650	Training Loss 0.7675 (0.7860)	Training Prec@1 6.055 (3.701)	Training Prec@5 10.938 (7.611)	
2022-04-01 05:02:41,614: ============================================================
2022-04-01 05:03:21,033: time cost, forward:0.11000354976315778, backward:0.033110435250782326, data cost:0.25468552215579643 
2022-04-01 05:03:21,033: ============================================================
2022-04-01 05:03:21,034: Epoch 22/31 Batch 2200/7662 eta: 8:08:56.400019	Training Loss 0.7716 (0.7852)	Training Prec@1 3.711 (3.779)	Training Prec@5 8.984 (7.754)	
2022-04-01 05:03:21,034: ============================================================
2022-04-01 05:04:00,862: time cost, forward:0.1099938284370784, backward:0.03307413608937639, data cost:0.25473085710825016 
2022-04-01 05:04:00,862: ============================================================
2022-04-01 05:04:00,862: Epoch 22/31 Batch 2300/7662 eta: 8:13:21.165787	Training Loss 0.7725 (0.7845)	Training Prec@1 3.320 (3.849)	Training Prec@5 8.008 (7.882)	
2022-04-01 05:04:00,863: ============================================================
2022-04-01 05:04:41,179: time cost, forward:0.10999564828351917, backward:0.0328866338272699, data cost:0.2551240572187989 
2022-04-01 05:04:41,180: ============================================================
2022-04-01 05:04:41,180: Epoch 22/31 Batch 2400/7662 eta: 8:18:44.000089	Training Loss 0.8390 (0.7850)	Training Prec@1 0.000 (3.827)	Training Prec@5 0.000 (7.834)	
2022-04-01 05:04:41,180: ============================================================
2022-04-01 05:05:20,311: time cost, forward:0.11004953128712422, backward:0.03285148640831455, data cost:0.2548356527517013 
2022-04-01 05:05:20,311: ============================================================
2022-04-01 05:05:20,312: Epoch 22/31 Batch 2500/7662 eta: 8:03:24.750659	Training Loss 0.7700 (0.7849)	Training Prec@1 5.078 (3.808)	Training Prec@5 9.570 (7.799)	
2022-04-01 05:05:20,312: ============================================================
2022-04-01 05:06:00,246: time cost, forward:0.11005858184283125, backward:0.0327966169193645, data cost:0.2549003300734693 
2022-04-01 05:06:00,247: ============================================================
2022-04-01 05:06:00,247: Epoch 22/31 Batch 2600/7662 eta: 8:12:40.717095	Training Loss 0.7711 (0.7843)	Training Prec@1 5.078 (3.868)	Training Prec@5 9.961 (7.911)	
2022-04-01 05:06:00,247: ============================================================
2022-04-01 05:06:41,100: time cost, forward:0.11005795130070689, backward:0.032804578354995576, data cost:0.2552833039480565 
2022-04-01 05:06:41,100: ============================================================
2022-04-01 05:06:41,100: Epoch 22/31 Batch 2700/7662 eta: 8:23:19.112271	Training Loss 0.7709 (0.7846)	Training Prec@1 5.078 (3.836)	Training Prec@5 10.742 (7.844)	
2022-04-01 05:06:41,101: ============================================================
2022-04-01 05:07:19,963: time cost, forward:0.11006383377980147, backward:0.03283009822132674, data cost:0.2549188795495178 
2022-04-01 05:07:19,964: ============================================================
2022-04-01 05:07:19,964: Epoch 22/31 Batch 2800/7662 eta: 7:58:09.339941	Training Loss 0.7714 (0.7841)	Training Prec@1 3.516 (3.884)	Training Prec@5 8.008 (7.933)	
2022-04-01 05:07:19,964: ============================================================
2022-04-01 05:08:00,456: time cost, forward:0.11009342319268775, backward:0.03275220227183947, data cost:0.25518387562244177 
2022-04-01 05:08:00,456: ============================================================
2022-04-01 05:08:00,456: Epoch 22/31 Batch 2900/7662 eta: 8:17:31.341866	Training Loss 0.7682 (0.7835)	Training Prec@1 5.273 (3.937)	Training Prec@5 10.547 (8.039)	
2022-04-01 05:08:00,456: ============================================================
2022-04-01 05:08:40,357: time cost, forward:0.11005520502620238, backward:0.03277127708582609, data cost:0.25522454129174854 
2022-04-01 05:08:40,358: ============================================================
2022-04-01 05:08:40,358: Epoch 22/31 Batch 3000/7662 eta: 8:09:36.126409	Training Loss 0.8578 (0.7836)	Training Prec@1 0.000 (3.947)	Training Prec@5 0.000 (8.051)	
2022-04-01 05:08:40,358: ============================================================
2022-04-01 05:09:19,942: time cost, forward:0.1100809438723293, backward:0.03275618225422625, data cost:0.25513660788497605 
2022-04-01 05:09:19,942: ============================================================
2022-04-01 05:09:19,943: Epoch 22/31 Batch 3100/7662 eta: 8:05:03.172539	Training Loss 0.8550 (0.7860)	Training Prec@1 0.000 (3.819)	Training Prec@5 0.000 (7.792)	
2022-04-01 05:09:19,943: ============================================================
2022-04-01 05:09:59,426: time cost, forward:0.11015011161966375, backward:0.032733660334533135, data cost:0.254998870922946 
2022-04-01 05:09:59,427: ============================================================
2022-04-01 05:09:59,427: Epoch 22/31 Batch 3200/7662 eta: 8:03:09.659648	Training Loss 0.8524 (0.7881)	Training Prec@1 0.000 (3.700)	Training Prec@5 0.000 (7.550)	
2022-04-01 05:09:59,427: ============================================================
2022-04-01 05:10:41,221: time cost, forward:0.1110631510430157, backward:0.03275698211996004, data cost:0.2546569111492461 
2022-04-01 05:10:41,221: ============================================================
2022-04-01 05:10:41,221: Epoch 22/31 Batch 3300/7662 eta: 8:30:44.116759	Training Loss 0.8503 (0.7900)	Training Prec@1 0.000 (3.588)	Training Prec@5 0.000 (7.322)	
2022-04-01 05:10:41,221: ============================================================
2022-04-01 05:11:22,223: time cost, forward:0.1118118878707145, backward:0.03279993168639239, data cost:0.2541699571516907 
2022-04-01 05:11:22,224: ============================================================
2022-04-01 05:11:22,224: Epoch 22/31 Batch 3400/7662 eta: 8:20:22.368294	Training Loss 0.8497 (0.7918)	Training Prec@1 0.000 (3.483)	Training Prec@5 0.000 (7.108)	
2022-04-01 05:11:22,224: ============================================================
2022-04-01 05:12:02,773: time cost, forward:0.11216517127081475, backward:0.032817031356667616, data cost:0.25398893654772337 
2022-04-01 05:12:02,773: ============================================================
2022-04-01 05:12:02,774: Epoch 22/31 Batch 3500/7662 eta: 8:14:10.476903	Training Loss 0.8474 (0.7934)	Training Prec@1 0.000 (3.384)	Training Prec@5 0.000 (6.906)	
2022-04-01 05:12:02,774: ============================================================
2022-04-01 05:12:43,443: time cost, forward:0.11272985069378776, backward:0.03282831569087608, data cost:0.2536152417410013 
2022-04-01 05:12:43,444: ============================================================
2022-04-01 05:12:43,444: Epoch 22/31 Batch 3600/7662 eta: 8:14:57.836787	Training Loss 0.8445 (0.7948)	Training Prec@1 0.000 (3.290)	Training Prec@5 0.000 (6.715)	
2022-04-01 05:12:43,444: ============================================================
2022-04-01 05:13:24,054: time cost, forward:0.11320966022921498, backward:0.03284361221301101, data cost:0.25330599806507914 
2022-04-01 05:13:24,055: ============================================================
2022-04-01 05:13:24,055: Epoch 22/31 Batch 3700/7662 eta: 8:13:33.923014	Training Loss 0.8427 (0.7961)	Training Prec@1 0.000 (3.201)	Training Prec@5 0.000 (6.534)	
2022-04-01 05:13:24,055: ============================================================
2022-04-01 05:14:03,824: time cost, forward:0.1132527755793536, backward:0.032840203975306966, data cost:0.25322371289804757 
2022-04-01 05:14:03,824: ============================================================
2022-04-01 05:14:03,825: Epoch 22/31 Batch 3800/7662 eta: 8:02:40.744838	Training Loss 0.8395 (0.7973)	Training Prec@1 0.000 (3.117)	Training Prec@5 0.000 (6.364)	
2022-04-01 05:14:03,825: ============================================================
2022-04-01 05:14:44,982: time cost, forward:0.11389708139860315, backward:0.032829726894992105, data cost:0.2528902559165436 
2022-04-01 05:14:44,982: ============================================================
2022-04-01 05:14:44,982: Epoch 22/31 Batch 3900/7662 eta: 8:18:50.369256	Training Loss 0.8370 (0.7983)	Training Prec@1 0.195 (3.038)	Training Prec@5 0.195 (6.202)	
2022-04-01 05:14:44,983: ============================================================
2022-04-01 05:15:26,164: time cost, forward:0.11425524701115845, backward:0.03280641097192557, data cost:0.25284381543555595 
2022-04-01 05:15:26,164: ============================================================
2022-04-01 05:15:26,164: Epoch 22/31 Batch 4000/7662 eta: 8:18:26.598710	Training Loss 0.8317 (0.7992)	Training Prec@1 0.000 (2.962)	Training Prec@5 0.000 (6.049)	
2022-04-01 05:15:26,164: ============================================================
2022-04-01 05:16:08,093: time cost, forward:0.11469059218485549, backward:0.03278455143295925, data cost:0.252903034815587 
2022-04-01 05:16:08,093: ============================================================
2022-04-01 05:16:08,093: Epoch 22/31 Batch 4100/7662 eta: 8:26:47.417853	Training Loss 0.8282 (0.8000)	Training Prec@1 0.195 (2.891)	Training Prec@5 0.195 (5.903)	
2022-04-01 05:16:08,093: ============================================================
2022-04-01 05:16:49,711: time cost, forward:0.11521742349012774, backward:0.03278551756924009, data cost:0.25271283015945917 
2022-04-01 05:16:49,711: ============================================================
2022-04-01 05:16:49,711: Epoch 22/31 Batch 4200/7662 eta: 8:22:20.170248	Training Loss 0.8263 (0.8007)	Training Prec@1 0.000 (2.822)	Training Prec@5 0.195 (5.764)	
2022-04-01 05:16:49,712: ============================================================
2022-04-01 05:17:30,442: time cost, forward:0.11584207029446915, backward:0.03278345101155301, data cost:0.25224256526594746 
2022-04-01 05:17:30,442: ============================================================
2022-04-01 05:17:30,443: Epoch 22/31 Batch 4300/7662 eta: 8:10:57.241657	Training Loss 0.8224 (0.8012)	Training Prec@1 0.000 (2.757)	Training Prec@5 0.391 (5.633)	
2022-04-01 05:17:30,443: ============================================================
2022-04-01 05:18:11,148: time cost, forward:0.11612210503543716, backward:0.03279954158438691, data cost:0.25211105901670877 
2022-04-01 05:18:11,148: ============================================================
2022-04-01 05:18:11,148: Epoch 22/31 Batch 4400/7662 eta: 8:09:58.059752	Training Loss 0.8187 (0.8016)	Training Prec@1 0.000 (2.696)	Training Prec@5 0.586 (5.511)	
2022-04-01 05:18:11,148: ============================================================
2022-04-01 05:18:52,189: time cost, forward:0.11643165846776103, backward:0.03282270248160412, data cost:0.25195888997078153 
2022-04-01 05:18:52,190: ============================================================
2022-04-01 05:18:52,190: Epoch 22/31 Batch 4500/7662 eta: 8:13:19.678185	Training Loss 0.8164 (0.8020)	Training Prec@1 0.000 (2.639)	Training Prec@5 0.195 (5.401)	
2022-04-01 05:18:52,190: ============================================================
2022-04-01 05:19:33,307: time cost, forward:0.11665579675980095, backward:0.032835669246905, data cost:0.2519435841613657 
2022-04-01 05:19:33,308: ============================================================
2022-04-01 05:19:33,308: Epoch 22/31 Batch 4600/7662 eta: 8:13:33.658507	Training Loss 0.8133 (0.8022)	Training Prec@1 0.586 (2.588)	Training Prec@5 0.781 (5.303)	
2022-04-01 05:19:33,308: ============================================================
2022-04-01 05:20:14,030: time cost, forward:0.1168517112528981, backward:0.03284731376016361, data cost:0.25183081165174903 
2022-04-01 05:20:14,030: ============================================================
2022-04-01 05:20:14,030: Epoch 22/31 Batch 4700/7662 eta: 8:08:07.906512	Training Loss 0.8078 (0.8024)	Training Prec@1 1.367 (2.544)	Training Prec@5 2.148 (5.219)	
2022-04-01 05:20:14,031: ============================================================
2022-04-01 05:20:54,904: time cost, forward:0.11693619434772419, backward:0.032850796641297926, data cost:0.25189721621580735 
2022-04-01 05:20:54,904: ============================================================
2022-04-01 05:20:54,905: Epoch 22/31 Batch 4800/7662 eta: 8:09:16.263881	Training Loss 0.7794 (0.8023)	Training Prec@1 3.516 (2.521)	Training Prec@5 7.227 (5.185)	
2022-04-01 05:20:54,905: ============================================================
2022-04-01 05:21:35,873: time cost, forward:0.116877768715685, backward:0.03284655032923913, data cost:0.2521252113839854 
2022-04-01 05:21:35,874: ============================================================
2022-04-01 05:21:35,874: Epoch 22/31 Batch 4900/7662 eta: 8:09:43.688631	Training Loss 0.7699 (0.8017)	Training Prec@1 4.102 (2.561)	Training Prec@5 9.961 (5.264)	
2022-04-01 05:21:35,874: ============================================================
2022-04-01 05:22:15,079: time cost, forward:0.11681239999373165, backward:0.03282941291513002, data cost:0.25199847808955406 
2022-04-01 05:22:15,079: ============================================================
2022-04-01 05:22:15,080: Epoch 22/31 Batch 5000/7662 eta: 7:47:59.376368	Training Loss 0.7760 (0.8011)	Training Prec@1 4.297 (2.609)	Training Prec@5 8.594 (5.357)	
2022-04-01 05:22:15,080: ============================================================
2022-04-01 05:22:58,198: time cost, forward:0.11673189083906593, backward:0.03282101497062867, data cost:0.2526476832552736 
2022-04-01 05:22:58,198: ============================================================
2022-04-01 05:22:58,198: Epoch 22/31 Batch 5100/7662 eta: 8:33:58.990244	Training Loss 0.7688 (0.8005)	Training Prec@1 3.906 (2.663)	Training Prec@5 8.984 (5.461)	
2022-04-01 05:22:58,199: ============================================================
2022-04-01 05:23:36,745: time cost, forward:0.11667920011904497, backward:0.03276247170182874, data cost:0.25244025987807456 
2022-04-01 05:23:36,745: ============================================================
2022-04-01 05:23:36,746: Epoch 22/31 Batch 5200/7662 eta: 7:38:50.841663	Training Loss 0.7719 (0.7999)	Training Prec@1 3.906 (2.715)	Training Prec@5 9.180 (5.561)	
2022-04-01 05:23:36,746: ============================================================
2022-04-01 05:24:15,567: time cost, forward:0.11661408824456325, backward:0.03264112606613698, data cost:0.2523600288912314 
2022-04-01 05:24:15,567: ============================================================
2022-04-01 05:24:15,567: Epoch 22/31 Batch 5300/7662 eta: 7:41:27.798909	Training Loss 0.7642 (0.7994)	Training Prec@1 6.836 (2.770)	Training Prec@5 13.281 (5.660)	
2022-04-01 05:24:15,567: ============================================================
2022-04-01 05:24:56,161: time cost, forward:0.11653605976200121, backward:0.032612427757236336, data cost:0.2525392295828924 
2022-04-01 05:24:56,161: ============================================================
2022-04-01 05:24:56,162: Epoch 22/31 Batch 5400/7662 eta: 8:01:51.958489	Training Loss 0.7702 (0.7988)	Training Prec@1 6.250 (2.819)	Training Prec@5 10.547 (5.755)	
2022-04-01 05:24:56,162: ============================================================
2022-04-01 05:25:37,019: time cost, forward:0.11647822679574109, backward:0.03258041529942478, data cost:0.25275302939164374 
2022-04-01 05:25:37,019: ============================================================
2022-04-01 05:25:37,019: Epoch 22/31 Batch 5500/7662 eta: 8:04:18.172251	Training Loss 0.7647 (0.7982)	Training Prec@1 7.031 (2.871)	Training Prec@5 14.062 (5.851)	
2022-04-01 05:25:37,019: ============================================================
2022-04-01 05:26:15,650: time cost, forward:0.11642641841481681, backward:0.03257938588723729, data cost:0.2525159909397731 
2022-04-01 05:26:15,651: ============================================================
2022-04-01 05:26:15,651: Epoch 22/31 Batch 5600/7662 eta: 7:37:16.748373	Training Loss 0.7708 (0.7977)	Training Prec@1 4.688 (2.923)	Training Prec@5 8.594 (5.947)	
2022-04-01 05:26:15,651: ============================================================
2022-04-01 05:26:54,113: time cost, forward:0.11637715499303616, backward:0.0326061645794969, data cost:0.25224310319702714 
2022-04-01 05:26:54,113: ============================================================
2022-04-01 05:26:54,114: Epoch 22/31 Batch 5700/7662 eta: 7:34:38.121920	Training Loss 0.7704 (0.7972)	Training Prec@1 5.469 (2.973)	Training Prec@5 10.742 (6.041)	
2022-04-01 05:26:54,114: ============================================================
2022-04-01 05:27:34,338: time cost, forward:0.11659482685239753, backward:0.03261430186636593, data cost:0.2520272206347407 
2022-04-01 05:27:34,338: ============================================================
2022-04-01 05:27:34,339: Epoch 22/31 Batch 5800/7662 eta: 7:54:47.741104	Training Loss 0.7656 (0.7967)	Training Prec@1 8.398 (3.021)	Training Prec@5 14.453 (6.135)	
2022-04-01 05:27:34,339: ============================================================
2022-04-01 05:28:12,897: time cost, forward:0.11653590040664427, backward:0.032620079094200824, data cost:0.25181385730763456 
2022-04-01 05:28:12,898: ============================================================
2022-04-01 05:28:12,898: Epoch 22/31 Batch 5900/7662 eta: 7:34:29.601762	Training Loss 0.7718 (0.7962)	Training Prec@1 4.102 (3.070)	Training Prec@5 7.617 (6.228)	
2022-04-01 05:28:12,898: ============================================================
2022-04-01 05:28:51,127: time cost, forward:0.11643712161719591, backward:0.03263279695792245, data cost:0.2515763490075647 
2022-04-01 05:28:51,127: ============================================================
2022-04-01 05:28:51,128: Epoch 22/31 Batch 6000/7662 eta: 7:29:58.072240	Training Loss 0.7702 (0.7957)	Training Prec@1 4.297 (3.120)	Training Prec@5 8.398 (6.322)	
2022-04-01 05:28:51,128: ============================================================
2022-04-01 05:29:29,626: time cost, forward:0.1163608713958435, backward:0.03263196075015389, data cost:0.2513865545003565 
2022-04-01 05:29:29,626: ============================================================
2022-04-01 05:29:29,626: Epoch 22/31 Batch 6100/7662 eta: 7:32:29.734236	Training Loss 0.7655 (0.7952)	Training Prec@1 6.445 (3.167)	Training Prec@5 11.133 (6.408)	
2022-04-01 05:29:29,627: ============================================================
2022-04-01 05:30:09,343: time cost, forward:0.11626099109418893, backward:0.032650006396248564, data cost:0.2514186609289419 
2022-04-01 05:30:09,343: ============================================================
2022-04-01 05:30:09,343: Epoch 22/31 Batch 6200/7662 eta: 7:46:09.167171	Training Loss 0.7702 (0.7947)	Training Prec@1 5.078 (3.214)	Training Prec@5 9.180 (6.497)	
2022-04-01 05:30:09,344: ============================================================
2022-04-01 05:30:49,480: time cost, forward:0.11618121424673625, backward:0.03267446493871592, data cost:0.25147544908076924 
2022-04-01 05:30:49,480: ============================================================
2022-04-01 05:30:49,480: Epoch 22/31 Batch 6300/7662 eta: 7:50:24.608385	Training Loss 0.7697 (0.7943)	Training Prec@1 6.641 (3.256)	Training Prec@5 12.695 (6.580)	
2022-04-01 05:30:49,481: ============================================================
2022-04-01 05:31:27,562: time cost, forward:0.1161263423480919, backward:0.03270367622971628, data cost:0.2511973613164335 
2022-04-01 05:31:27,563: ============================================================
2022-04-01 05:31:27,563: Epoch 22/31 Batch 6400/7662 eta: 7:25:42.115392	Training Loss 0.7636 (0.7938)	Training Prec@1 6.836 (3.300)	Training Prec@5 14.453 (6.661)	
2022-04-01 05:31:27,563: ============================================================
2022-04-01 05:32:06,389: time cost, forward:0.1160517884577434, backward:0.032704211029754744, data cost:0.25108815622542485 
2022-04-01 05:32:06,389: ============================================================
2022-04-01 05:32:06,389: Epoch 22/31 Batch 6500/7662 eta: 7:33:45.441082	Training Loss 0.7706 (0.7934)	Training Prec@1 7.227 (3.342)	Training Prec@5 13.477 (6.739)	
2022-04-01 05:32:06,390: ============================================================
2022-04-01 05:32:45,799: time cost, forward:0.11597517779928786, backward:0.03271215755770759, data cost:0.25105288426502853 
2022-04-01 05:32:45,800: ============================================================
2022-04-01 05:32:45,800: Epoch 22/31 Batch 6600/7662 eta: 7:39:55.748776	Training Loss 0.7633 (0.7930)	Training Prec@1 5.469 (3.384)	Training Prec@5 13.672 (6.822)	
2022-04-01 05:32:45,800: ============================================================
2022-04-01 05:33:25,716: time cost, forward:0.11587339063992623, backward:0.03271034344361244, data cost:0.25115367312416387 
2022-04-01 05:33:25,716: ============================================================
2022-04-01 05:33:25,716: Epoch 22/31 Batch 6700/7662 eta: 7:45:09.892334	Training Loss 0.7647 (0.7926)	Training Prec@1 5.664 (3.423)	Training Prec@5 11.523 (6.899)	
2022-04-01 05:33:25,717: ============================================================
2022-04-01 05:34:05,691: time cost, forward:0.11578819477868477, backward:0.03270625356260968, data cost:0.2512296966497189 
2022-04-01 05:34:05,692: ============================================================
2022-04-01 05:34:05,693: Epoch 22/31 Batch 6800/7662 eta: 7:45:11.609050	Training Loss 0.7644 (0.7922)	Training Prec@1 7.031 (3.462)	Training Prec@5 13.281 (6.972)	
2022-04-01 05:34:05,693: ============================================================
2022-04-01 05:34:45,257: time cost, forward:0.1156885241370112, backward:0.03270557172437702, data cost:0.25126488168337396 
2022-04-01 05:34:45,258: ============================================================
2022-04-01 05:34:45,258: Epoch 22/31 Batch 6900/7662 eta: 7:39:45.335770	Training Loss 0.7677 (0.7918)	Training Prec@1 6.055 (3.502)	Training Prec@5 11.719 (7.047)	
2022-04-01 05:34:45,258: ============================================================
2022-04-01 05:35:25,650: time cost, forward:0.11558396980785986, backward:0.032715447546158676, data cost:0.25142221100620926 
2022-04-01 05:35:25,651: ============================================================
2022-04-01 05:35:25,651: Epoch 22/31 Batch 7000/7662 eta: 7:48:42.279188	Training Loss 0.7619 (0.7914)	Training Prec@1 8.398 (3.540)	Training Prec@5 15.234 (7.117)	
2022-04-01 05:35:25,651: ============================================================
2022-04-01 05:36:05,717: time cost, forward:0.11552485453778547, backward:0.032668645020219066, data cost:0.25154279194880347 
2022-04-01 05:36:05,717: ============================================================
2022-04-01 05:36:05,718: Epoch 22/31 Batch 7100/7662 eta: 7:44:14.564963	Training Loss 0.7635 (0.7911)	Training Prec@1 5.664 (3.578)	Training Prec@5 12.695 (7.189)	
2022-04-01 05:36:05,718: ============================================================
2022-04-01 05:36:43,727: time cost, forward:0.1154761016658651, backward:0.03256284334474445, data cost:0.2514172427636714 
2022-04-01 05:36:43,727: ============================================================
2022-04-01 05:36:43,727: Epoch 22/31 Batch 7200/7662 eta: 7:19:46.769987	Training Loss 0.7628 (0.7907)	Training Prec@1 8.008 (3.618)	Training Prec@5 14.453 (7.261)	
2022-04-01 05:36:43,727: ============================================================
2022-04-01 05:37:24,145: time cost, forward:0.11568448618350413, backward:0.032493401560199996, data cost:0.25132816584898454 
2022-04-01 05:37:24,145: ============================================================
2022-04-01 05:37:24,145: Epoch 22/31 Batch 7300/7662 eta: 7:46:58.129870	Training Loss 0.7737 (0.7903)	Training Prec@1 6.250 (3.659)	Training Prec@5 12.109 (7.334)	
2022-04-01 05:37:24,145: ============================================================
2022-04-01 05:38:03,307: time cost, forward:0.11560792223088305, backward:0.032505534407028816, data cost:0.25128657058342546 
2022-04-01 05:38:03,307: ============================================================
2022-04-01 05:38:03,307: Epoch 22/31 Batch 7400/7662 eta: 7:31:48.298768	Training Loss 0.7644 (0.7904)	Training Prec@1 7.812 (3.650)	Training Prec@5 13.477 (7.319)	
2022-04-01 05:38:03,307: ============================================================
2022-04-01 05:38:45,191: time cost, forward:0.11552936033433811, backward:0.032512461889551585, data cost:0.25160898264447346 
2022-04-01 05:38:45,191: ============================================================
2022-04-01 05:38:45,191: Epoch 22/31 Batch 7500/7662 eta: 8:02:30.608537	Training Loss 0.7635 (0.7900)	Training Prec@1 6.641 (3.690)	Training Prec@5 13.477 (7.391)	
2022-04-01 05:38:45,191: ============================================================
2022-04-01 05:39:23,577: time cost, forward:0.11547931578147096, backward:0.03252951103317877, data cost:0.2514331776274711 
2022-04-01 05:39:23,577: ============================================================
2022-04-01 05:39:23,577: Epoch 22/31 Batch 7600/7662 eta: 7:21:34.457776	Training Loss 0.7636 (0.7897)	Training Prec@1 6.445 (3.727)	Training Prec@5 12.305 (7.460)	
2022-04-01 05:39:23,577: ============================================================
2022-04-01 05:39:49,705: Epoch: 22/31 eta: 7:21:10.274544	Training Loss 0.7630 (0.7895)	Training Prec@1 8.203 (3.751)	Training Prec@5 13.477 (7.504)
2022-04-01 05:39:49,705: ============================================================
2022-04-01 05:40:30,376: time cost, forward:0.1310029270673039, backward:0.033332942712186564, data cost:0.24393847735241206 
2022-04-01 05:40:30,377: ============================================================
2022-04-01 05:40:30,377: Epoch 23/31 Batch 100/7662 eta: 7:46:42.568939	Training Loss 0.7639 (0.7617)	Training Prec@1 5.078 (7.232)	Training Prec@5 11.719 (13.747)	
2022-04-01 05:40:30,377: ============================================================
2022-04-01 05:41:11,127: time cost, forward:0.13764084044413352, backward:0.03376833038713465, data cost:0.23566444435311323 
2022-04-01 05:41:11,127: ============================================================
2022-04-01 05:41:11,127: Epoch 23/31 Batch 200/7662 eta: 7:46:59.812991	Training Loss 0.7624 (0.7616)	Training Prec@1 6.641 (7.217)	Training Prec@5 12.695 (13.731)	
2022-04-01 05:41:11,128: ============================================================
2022-04-01 05:41:53,207: time cost, forward:0.1319599366905697, backward:0.03282717398576513, data cost:0.24707507688464928 
2022-04-01 05:41:53,208: ============================================================
2022-04-01 05:41:53,208: Epoch 23/31 Batch 300/7662 eta: 8:01:32.093306	Training Loss 0.7870 (0.7625)	Training Prec@1 4.492 (7.112)	Training Prec@5 8.789 (13.540)	
2022-04-01 05:41:53,208: ============================================================
2022-04-01 05:42:33,294: time cost, forward:0.12626630560796065, backward:0.032705252033128476, data cost:0.2500815260081662 
2022-04-01 05:42:33,295: ============================================================
2022-04-01 05:42:33,295: Epoch 23/31 Batch 400/7662 eta: 7:38:03.187085	Training Loss 0.7612 (0.7652)	Training Prec@1 8.008 (6.653)	Training Prec@5 12.500 (12.739)	
2022-04-01 05:42:33,295: ============================================================
2022-04-01 05:43:13,245: time cost, forward:0.12342959654355097, backward:0.03247985763396911, data cost:0.2511347305320786 
2022-04-01 05:43:13,245: ============================================================
2022-04-01 05:43:13,245: Epoch 23/31 Batch 500/7662 eta: 7:35:49.669223	Training Loss 0.7625 (0.7646)	Training Prec@1 8.008 (6.747)	Training Prec@5 14.648 (12.884)	
2022-04-01 05:43:13,246: ============================================================
2022-04-01 05:43:53,063: time cost, forward:0.12140636611263422, backward:0.032393036780253875, data cost:0.2516705981877093 
2022-04-01 05:43:53,063: ============================================================
2022-04-01 05:43:53,064: Epoch 23/31 Batch 600/7662 eta: 7:33:39.417128	Training Loss 0.7608 (0.7643)	Training Prec@1 8.398 (6.804)	Training Prec@5 15.039 (12.945)	
2022-04-01 05:43:53,064: ============================================================
2022-04-01 05:44:32,573: time cost, forward:0.11992753046606061, backward:0.03253989806332131, data cost:0.25146997708278324 
2022-04-01 05:44:32,573: ============================================================
2022-04-01 05:44:32,573: Epoch 23/31 Batch 700/7662 eta: 7:29:28.805246	Training Loss 0.7624 (0.7670)	Training Prec@1 6.055 (6.441)	Training Prec@5 11.914 (12.313)	
2022-04-01 05:44:32,573: ============================================================
2022-04-01 05:45:13,061: time cost, forward:0.11884962453114076, backward:0.0326664450768386, data cost:0.25244478021604994 
2022-04-01 05:45:13,062: ============================================================
2022-04-01 05:45:13,062: Epoch 23/31 Batch 800/7662 eta: 7:39:56.681923	Training Loss 0.7619 (0.7664)	Training Prec@1 8.789 (6.529)	Training Prec@5 14.648 (12.474)	
2022-04-01 05:45:13,062: ============================================================
2022-04-01 05:45:51,621: time cost, forward:0.1179526992581445, backward:0.03283138720689546, data cost:0.2511178511003233 
2022-04-01 05:45:51,621: ============================================================
2022-04-01 05:45:51,621: Epoch 23/31 Batch 900/7662 eta: 7:17:23.071841	Training Loss 0.7651 (0.7658)	Training Prec@1 7.031 (6.618)	Training Prec@5 12.891 (12.621)	
2022-04-01 05:45:51,621: ============================================================
2022-04-01 05:46:31,533: time cost, forward:0.11725645332603722, backward:0.032919693995524454, data cost:0.25112974655640136 
2022-04-01 05:46:31,534: ============================================================
2022-04-01 05:46:31,534: Epoch 23/31 Batch 1000/7662 eta: 7:32:04.282120	Training Loss 0.7617 (0.7653)	Training Prec@1 5.273 (6.687)	Training Prec@5 11.914 (12.722)	
2022-04-01 05:46:31,534: ============================================================
2022-04-01 05:47:12,178: time cost, forward:0.1165186577867225, backward:0.03270551678915258, data cost:0.25273952362643687 
2022-04-01 05:47:12,178: ============================================================
2022-04-01 05:47:12,178: Epoch 23/31 Batch 1100/7662 eta: 7:39:40.921983	Training Loss 0.7831 (0.7675)	Training Prec@1 2.344 (6.454)	Training Prec@5 5.664 (12.299)	
2022-04-01 05:47:12,179: ============================================================
2022-04-01 05:47:49,898: time cost, forward:0.11619545580249115, backward:0.03261877140271057, data cost:0.25104221530115733 
2022-04-01 05:47:49,898: ============================================================
2022-04-01 05:47:49,898: Epoch 23/31 Batch 1200/7662 eta: 7:05:58.520345	Training Loss 0.7593 (0.7672)	Training Prec@1 5.273 (6.488)	Training Prec@5 12.109 (12.361)	
2022-04-01 05:47:49,898: ============================================================
2022-04-01 05:48:30,201: time cost, forward:0.11576336268923483, backward:0.032572294034069554, data cost:0.25180213023737086 
2022-04-01 05:48:30,201: ============================================================
2022-04-01 05:48:30,201: Epoch 23/31 Batch 1300/7662 eta: 7:34:28.766934	Training Loss 0.7576 (0.7668)	Training Prec@1 8.398 (6.537)	Training Prec@5 15.625 (12.454)	
2022-04-01 05:48:30,202: ============================================================
2022-04-01 05:49:08,263: time cost, forward:0.11554307030983871, backward:0.0325866520958683, data cost:0.2505495524389391 
2022-04-01 05:49:08,263: ============================================================
2022-04-01 05:49:08,263: Epoch 23/31 Batch 1400/7662 eta: 7:08:34.238148	Training Loss 0.7602 (0.7664)	Training Prec@1 8.203 (6.604)	Training Prec@5 14.062 (12.546)	
2022-04-01 05:49:08,264: ============================================================
2022-04-01 05:49:46,261: time cost, forward:0.11523068929370679, backward:0.03255727881189185, data cost:0.2496554942191482 
2022-04-01 05:49:46,261: ============================================================
2022-04-01 05:49:46,262: Epoch 23/31 Batch 1500/7662 eta: 7:07:13.222907	Training Loss 0.8324 (0.7669)	Training Prec@1 0.195 (6.558)	Training Prec@5 0.781 (12.483)	
2022-04-01 05:49:46,262: ============================================================
2022-04-01 05:50:24,966: time cost, forward:0.11507366119585162, backward:0.032499989544771256, data cost:0.2492017459690459 
2022-04-01 05:50:24,966: ============================================================
2022-04-01 05:50:24,966: Epoch 23/31 Batch 1600/7662 eta: 7:14:31.184466	Training Loss 0.7598 (0.7676)	Training Prec@1 7.422 (6.459)	Training Prec@5 14.844 (12.296)	
2022-04-01 05:50:24,966: ============================================================
2022-04-01 05:51:02,996: time cost, forward:0.11500649328720156, backward:0.03243494805621708, data cost:0.24832955734248438 
2022-04-01 05:51:02,996: ============================================================
2022-04-01 05:51:02,996: Epoch 23/31 Batch 1700/7662 eta: 7:06:18.554224	Training Loss 0.7575 (0.7673)	Training Prec@1 8.398 (6.515)	Training Prec@5 13.867 (12.395)	
2022-04-01 05:51:02,996: ============================================================
2022-04-01 05:51:43,736: time cost, forward:0.11475353959270687, backward:0.032378840141656866, data cost:0.24927704065226394 
2022-04-01 05:51:43,736: ============================================================
2022-04-01 05:51:43,736: Epoch 23/31 Batch 1800/7662 eta: 7:36:00.454595	Training Loss 0.7585 (0.7669)	Training Prec@1 8.008 (6.577)	Training Prec@5 15.234 (12.496)	
2022-04-01 05:51:43,736: ============================================================
2022-04-01 05:52:21,856: time cost, forward:0.11454762578826631, backward:0.03239093145739097, data cost:0.24863257729548915 
2022-04-01 05:52:21,856: ============================================================
2022-04-01 05:52:21,856: Epoch 23/31 Batch 1900/7662 eta: 7:06:02.910229	Training Loss 0.7588 (0.7667)	Training Prec@1 8.398 (6.612)	Training Prec@5 15.430 (12.558)	
2022-04-01 05:52:21,856: ============================================================
2022-04-01 05:53:01,913: time cost, forward:0.1144134962540856, backward:0.032572691293881496, data cost:0.24881081738550703 
2022-04-01 05:53:01,914: ============================================================
2022-04-01 05:53:01,915: Epoch 23/31 Batch 2000/7662 eta: 7:27:02.703042	Training Loss 0.7621 (0.7664)	Training Prec@1 8.594 (6.665)	Training Prec@5 14.258 (12.635)	
2022-04-01 05:53:01,915: ============================================================
2022-04-01 05:53:41,457: time cost, forward:0.11423865200622471, backward:0.03258725244014135, data cost:0.2489483406453998 
2022-04-01 05:53:41,457: ============================================================
2022-04-01 05:53:41,457: Epoch 23/31 Batch 2100/7662 eta: 7:20:37.831193	Training Loss 0.7584 (0.7662)	Training Prec@1 7.617 (6.715)	Training Prec@5 14.648 (12.712)	
2022-04-01 05:53:41,457: ============================================================
2022-04-01 05:54:22,059: time cost, forward:0.11408985100208818, backward:0.032545692544462684, data cost:0.24958999322836592 
2022-04-01 05:54:22,060: ============================================================
2022-04-01 05:54:22,060: Epoch 23/31 Batch 2200/7662 eta: 7:31:45.926726	Training Loss 0.8428 (0.7689)	Training Prec@1 0.000 (6.480)	Training Prec@5 0.195 (12.275)	
2022-04-01 05:54:22,060: ============================================================
2022-04-01 05:55:02,890: time cost, forward:0.11402334136100062, backward:0.03251446999379374, data cost:0.2502087062729499 
2022-04-01 05:55:02,890: ============================================================
2022-04-01 05:55:02,890: Epoch 23/31 Batch 2300/7662 eta: 7:33:36.978991	Training Loss 0.8162 (0.7717)	Training Prec@1 0.000 (6.200)	Training Prec@5 0.391 (11.747)	
2022-04-01 05:55:02,890: ============================================================
2022-04-01 05:55:42,017: time cost, forward:0.113941981922641, backward:0.03245719356703828, data cost:0.250085359317355 
2022-04-01 05:55:42,017: ============================================================
2022-04-01 05:55:42,018: Epoch 23/31 Batch 2400/7662 eta: 7:14:02.920370	Training Loss 0.7632 (0.7723)	Training Prec@1 8.203 (6.080)	Training Prec@5 15.430 (11.535)	
2022-04-01 05:55:42,018: ============================================================
2022-04-01 05:56:21,385: time cost, forward:0.11386008690051339, backward:0.032343301452508494, data cost:0.25015713415798446 
2022-04-01 05:56:21,386: ============================================================
2022-04-01 05:56:21,386: Epoch 23/31 Batch 2500/7662 eta: 7:16:03.828383	Training Loss 0.7573 (0.7719)	Training Prec@1 8.984 (6.138)	Training Prec@5 15.430 (11.638)	
2022-04-01 05:56:21,386: ============================================================
2022-04-01 05:56:59,676: time cost, forward:0.11383170400871227, backward:0.03225090330313976, data cost:0.249732504445069 
2022-04-01 05:56:59,676: ============================================================
2022-04-01 05:56:59,677: Epoch 23/31 Batch 2600/7662 eta: 7:03:29.190789	Training Loss 0.7635 (0.7714)	Training Prec@1 6.641 (6.204)	Training Prec@5 13.086 (11.750)	
2022-04-01 05:56:59,677: ============================================================
2022-04-01 05:57:41,157: time cost, forward:0.11372919637391019, backward:0.03192821508339044, data cost:0.250630382521588 
2022-04-01 05:57:41,157: ============================================================
2022-04-01 05:57:41,157: Epoch 23/31 Batch 2700/7662 eta: 7:38:04.705080	Training Loss 0.7586 (0.7710)	Training Prec@1 11.914 (6.272)	Training Prec@5 17.578 (11.863)	
2022-04-01 05:57:41,157: ============================================================
2022-04-01 05:58:19,882: time cost, forward:0.11370037086693974, backward:0.031902176007580524, data cost:0.2505823109310923 
2022-04-01 05:58:19,882: ============================================================
2022-04-01 05:58:19,882: Epoch 23/31 Batch 2800/7662 eta: 7:07:00.116222	Training Loss 0.7527 (0.7706)	Training Prec@1 9.375 (6.332)	Training Prec@5 16.602 (11.964)	
2022-04-01 05:58:19,882: ============================================================
2022-04-01 05:58:58,731: time cost, forward:0.1137024058519293, backward:0.03190550396219539, data cost:0.25030912708191677 
2022-04-01 05:58:58,732: ============================================================
2022-04-01 05:58:58,732: Epoch 23/31 Batch 2900/7662 eta: 7:07:43.640935	Training Loss 0.7621 (0.7702)	Training Prec@1 7.617 (6.392)	Training Prec@5 13.867 (12.057)	
2022-04-01 05:58:58,732: ============================================================
2022-04-01 05:59:39,802: time cost, forward:0.11425395042111612, backward:0.031951596554854425, data cost:0.2501704981423251 
2022-04-01 05:59:39,803: ============================================================
2022-04-01 05:59:39,803: Epoch 23/31 Batch 3000/7662 eta: 7:31:30.044387	Training Loss 0.7704 (0.7700)	Training Prec@1 6.250 (6.431)	Training Prec@5 13.477 (12.121)	
2022-04-01 05:59:39,803: ============================================================
2022-04-01 06:00:20,922: time cost, forward:0.11478036686311656, backward:0.03201973626751329, data cost:0.25003509476862634 
2022-04-01 06:00:20,922: ============================================================
2022-04-01 06:00:20,923: Epoch 23/31 Batch 3100/7662 eta: 7:31:20.956460	Training Loss 0.7606 (0.7703)	Training Prec@1 5.859 (6.375)	Training Prec@5 15.234 (12.036)	
2022-04-01 06:00:20,923: ============================================================
2022-04-01 06:01:01,170: time cost, forward:0.11467609102929448, backward:0.032047055146961746, data cost:0.25030327871763247 
2022-04-01 06:01:01,170: ============================================================
2022-04-01 06:01:01,170: Epoch 23/31 Batch 3200/7662 eta: 7:21:06.582232	Training Loss 0.7547 (0.7700)	Training Prec@1 8.789 (6.424)	Training Prec@5 15.234 (12.119)	
2022-04-01 06:01:01,171: ============================================================
2022-04-01 06:01:40,549: time cost, forward:0.11463984289686764, backward:0.03206147898974365, data cost:0.2501972719697238 
2022-04-01 06:01:40,550: ============================================================
2022-04-01 06:01:40,550: Epoch 23/31 Batch 3300/7662 eta: 7:10:56.304038	Training Loss 0.7586 (0.7696)	Training Prec@1 7.031 (6.472)	Training Prec@5 14.258 (12.204)	
2022-04-01 06:01:40,550: ============================================================
2022-04-01 06:02:18,742: time cost, forward:0.11459812328162422, backward:0.032059734728308975, data cost:0.24979680655598113 
2022-04-01 06:02:18,743: ============================================================
2022-04-01 06:02:18,743: Epoch 23/31 Batch 3400/7662 eta: 6:57:18.959863	Training Loss 0.7593 (0.7693)	Training Prec@1 8.008 (6.522)	Training Prec@5 14.648 (12.283)	
2022-04-01 06:02:18,743: ============================================================
2022-04-01 06:02:59,780: time cost, forward:0.11453787562982734, backward:0.03207823711655827, data cost:0.25023095605713397 
2022-04-01 06:02:59,781: ============================================================
2022-04-01 06:02:59,781: Epoch 23/31 Batch 3500/7662 eta: 7:27:43.034369	Training Loss 0.7599 (0.7690)	Training Prec@1 7.031 (6.569)	Training Prec@5 14.062 (12.364)	
2022-04-01 06:02:59,781: ============================================================
2022-04-01 06:03:39,629: time cost, forward:0.11455000967209655, backward:0.03208533516523738, data cost:0.25025488641998045 
2022-04-01 06:03:39,629: ============================================================
2022-04-01 06:03:39,629: Epoch 23/31 Batch 3600/7662 eta: 7:14:04.311385	Training Loss 0.7637 (0.7687)	Training Prec@1 7.422 (6.619)	Training Prec@5 13.477 (12.450)	
2022-04-01 06:03:39,629: ============================================================
2022-04-01 06:04:19,254: time cost, forward:0.11457541808143568, backward:0.03207272805211092, data cost:0.25020712747803314 
2022-04-01 06:04:19,254: ============================================================
2022-04-01 06:04:19,254: Epoch 23/31 Batch 3700/7662 eta: 7:10:59.011312	Training Loss 0.7561 (0.7691)	Training Prec@1 8.789 (6.571)	Training Prec@5 16.211 (12.372)	
2022-04-01 06:04:19,254: ============================================================
2022-04-01 06:04:59,329: time cost, forward:0.11468385972296385, backward:0.0320598477908077, data cost:0.25021219573607095 
2022-04-01 06:04:59,329: ============================================================
2022-04-01 06:04:59,330: Epoch 23/31 Batch 3800/7662 eta: 7:15:12.606145	Training Loss 0.7554 (0.7688)	Training Prec@1 8.398 (6.617)	Training Prec@5 15.430 (12.447)	
2022-04-01 06:04:59,330: ============================================================
2022-04-01 06:05:38,248: time cost, forward:0.11498661847198949, backward:0.03206086678515951, data cost:0.24967437225844683 
2022-04-01 06:05:38,248: ============================================================
2022-04-01 06:05:38,249: Epoch 23/31 Batch 3900/7662 eta: 7:02:00.317891	Training Loss 0.7593 (0.7685)	Training Prec@1 7.812 (6.656)	Training Prec@5 13.672 (12.516)	
2022-04-01 06:05:38,249: ============================================================
2022-04-01 06:06:18,222: time cost, forward:0.11522011507687255, backward:0.032066589893475564, data cost:0.24948706529116027 
2022-04-01 06:06:18,222: ============================================================
2022-04-01 06:06:18,222: Epoch 23/31 Batch 4000/7662 eta: 7:12:46.672701	Training Loss 0.7568 (0.7683)	Training Prec@1 7.812 (6.697)	Training Prec@5 14.062 (12.587)	
2022-04-01 06:06:18,223: ============================================================
2022-04-01 06:06:57,256: time cost, forward:0.11534749609460247, backward:0.03206088142180972, data cost:0.24922100350053522 
2022-04-01 06:06:57,256: ============================================================
2022-04-01 06:06:57,256: Epoch 23/31 Batch 4100/7662 eta: 7:01:56.826652	Training Loss 0.7575 (0.7680)	Training Prec@1 8.398 (6.745)	Training Prec@5 15.430 (12.663)	
2022-04-01 06:06:57,256: ============================================================
2022-04-01 06:07:37,556: time cost, forward:0.11553160858653959, backward:0.032062536763361335, data cost:0.24919367489516095 
2022-04-01 06:07:37,557: ============================================================
2022-04-01 06:07:37,557: Epoch 23/31 Batch 4200/7662 eta: 7:14:58.453489	Training Loss 0.7599 (0.7678)	Training Prec@1 7.812 (6.792)	Training Prec@5 15.039 (12.741)	
2022-04-01 06:07:37,557: ============================================================
2022-04-01 06:08:18,200: time cost, forward:0.11546170497999882, backward:0.03205275008722249, data cost:0.24949625953182727 
2022-04-01 06:08:18,201: ============================================================
2022-04-01 06:08:18,201: Epoch 23/31 Batch 4300/7662 eta: 7:17:59.908416	Training Loss 0.8181 (0.7679)	Training Prec@1 1.172 (6.789)	Training Prec@5 3.320 (12.735)	
2022-04-01 06:08:18,201: ============================================================
2022-04-01 06:08:56,654: time cost, forward:0.11542480478072117, backward:0.03203828656204616, data cost:0.24925601539299633 
2022-04-01 06:08:56,655: ============================================================
2022-04-01 06:08:56,655: Epoch 23/31 Batch 4400/7662 eta: 6:53:45.526631	Training Loss 0.7591 (0.7679)	Training Prec@1 7.617 (6.773)	Training Prec@5 14.258 (12.706)	
2022-04-01 06:08:56,655: ============================================================
2022-04-01 06:09:37,333: time cost, forward:0.11534701482167004, backward:0.03204368214841471, data cost:0.2495463423846589 
2022-04-01 06:09:37,334: ============================================================
2022-04-01 06:09:37,334: Epoch 23/31 Batch 4500/7662 eta: 7:17:01.196324	Training Loss 0.7578 (0.7677)	Training Prec@1 8.398 (6.810)	Training Prec@5 16.211 (12.769)	
2022-04-01 06:09:37,334: ============================================================
2022-04-01 06:10:16,991: time cost, forward:0.11527705814662667, backward:0.03206635019161774, data cost:0.24956673211340127 
2022-04-01 06:10:16,991: ============================================================
2022-04-01 06:10:16,992: Epoch 23/31 Batch 4600/7662 eta: 7:05:23.441425	Training Loss 0.7547 (0.7675)	Training Prec@1 8.594 (6.850)	Training Prec@5 16.992 (12.830)	
2022-04-01 06:10:16,992: ============================================================
2022-04-01 06:10:57,401: time cost, forward:0.11523089563118495, backward:0.03207384888023284, data cost:0.24971977790179825 
2022-04-01 06:10:57,402: ============================================================
2022-04-01 06:10:57,402: Epoch 23/31 Batch 4700/7662 eta: 7:12:47.343700	Training Loss 0.7607 (0.7673)	Training Prec@1 8.984 (6.887)	Training Prec@5 13.672 (12.886)	
2022-04-01 06:10:57,402: ============================================================
2022-04-01 06:11:36,955: time cost, forward:0.11515287608746613, backward:0.0320788559552952, data cost:0.24974551387666835 
2022-04-01 06:11:36,956: ============================================================
2022-04-01 06:11:36,956: Epoch 23/31 Batch 4800/7662 eta: 7:02:57.224099	Training Loss 0.7598 (0.7671)	Training Prec@1 7.031 (6.928)	Training Prec@5 14.648 (12.954)	
2022-04-01 06:11:36,956: ============================================================
2022-04-01 06:12:16,874: time cost, forward:0.11507752837636417, backward:0.032039368680653026, data cost:0.24994334762839546 
2022-04-01 06:12:16,874: ============================================================
2022-04-01 06:12:16,874: Epoch 23/31 Batch 4900/7662 eta: 7:06:11.236709	Training Loss 0.7591 (0.7673)	Training Prec@1 8.984 (6.899)	Training Prec@5 14.258 (12.906)	
2022-04-01 06:12:16,874: ============================================================
2022-04-01 06:12:57,104: time cost, forward:0.11502235578188635, backward:0.03196127931221315, data cost:0.25015499687690834 
2022-04-01 06:12:57,104: ============================================================
2022-04-01 06:12:57,104: Epoch 23/31 Batch 5000/7662 eta: 7:08:50.991631	Training Loss 0.7513 (0.7671)	Training Prec@1 10.742 (6.938)	Training Prec@5 19.727 (12.966)	
2022-04-01 06:12:57,105: ============================================================
2022-04-01 06:13:34,503: time cost, forward:0.11497273382473797, backward:0.03191417342285288, data cost:0.24981094655113423 
2022-04-01 06:13:34,503: ============================================================
2022-04-01 06:13:34,503: Epoch 23/31 Batch 5100/7662 eta: 6:38:02.604832	Training Loss 0.7557 (0.7669)	Training Prec@1 8.594 (6.975)	Training Prec@5 17.188 (13.025)	
2022-04-01 06:13:34,504: ============================================================
2022-04-01 06:14:13,830: time cost, forward:0.11492255995607899, backward:0.03190865294707237, data cost:0.24979589750822243 
2022-04-01 06:14:13,831: ============================================================
2022-04-01 06:14:13,831: Epoch 23/31 Batch 5200/7662 eta: 6:57:54.820336	Training Loss 0.7577 (0.7668)	Training Prec@1 7.422 (7.013)	Training Prec@5 13.086 (13.082)	
2022-04-01 06:14:13,831: ============================================================
2022-04-01 06:14:51,578: time cost, forward:0.11486558078212274, backward:0.03190805678503494, data cost:0.24948301673452908 
2022-04-01 06:14:51,578: ============================================================
2022-04-01 06:14:51,579: Epoch 23/31 Batch 5300/7662 eta: 6:40:29.764465	Training Loss 0.7595 (0.7666)	Training Prec@1 8.398 (7.052)	Training Prec@5 16.211 (13.142)	
2022-04-01 06:14:51,579: ============================================================
2022-04-01 06:15:30,818: time cost, forward:0.1148090174428223, backward:0.031891882033188226, data cost:0.24947642105379508 
2022-04-01 06:15:30,819: ============================================================
2022-04-01 06:15:30,819: Epoch 23/31 Batch 5400/7662 eta: 6:55:40.728146	Training Loss 0.8065 (0.7669)	Training Prec@1 0.391 (7.024)	Training Prec@5 0.586 (13.092)	
2022-04-01 06:15:30,819: ============================================================
2022-04-01 06:16:10,380: time cost, forward:0.1147636816618247, backward:0.031849991995587225, data cost:0.24954566528069191 
2022-04-01 06:16:10,380: ============================================================
2022-04-01 06:16:10,380: Epoch 23/31 Batch 5500/7662 eta: 6:58:25.246999	Training Loss 0.7588 (0.7668)	Training Prec@1 8.203 (7.031)	Training Prec@5 13.867 (13.101)	
2022-04-01 06:16:10,380: ============================================================
2022-04-01 06:16:49,742: time cost, forward:0.11468884088584708, backward:0.03186027402004018, data cost:0.24956292121575163 
2022-04-01 06:16:49,742: ============================================================
2022-04-01 06:16:49,743: Epoch 23/31 Batch 5600/7662 eta: 6:55:39.547823	Training Loss 0.7588 (0.7666)	Training Prec@1 9.375 (7.065)	Training Prec@5 16.992 (13.157)	
2022-04-01 06:16:49,743: ============================================================
2022-04-01 06:17:30,151: time cost, forward:0.11462075899809908, backward:0.03189695703500111, data cost:0.24972165218673897 
2022-04-01 06:17:30,151: ============================================================
2022-04-01 06:17:30,151: Epoch 23/31 Batch 5700/7662 eta: 7:06:02.206642	Training Loss 0.7560 (0.7664)	Training Prec@1 10.352 (7.100)	Training Prec@5 17.969 (13.207)	
2022-04-01 06:17:30,152: ============================================================
2022-04-01 06:18:10,815: time cost, forward:0.11455103380348296, backward:0.03192882370097737, data cost:0.24992563560474 
2022-04-01 06:18:10,815: ============================================================
2022-04-01 06:18:10,815: Epoch 23/31 Batch 5800/7662 eta: 7:08:02.811044	Training Loss 0.7601 (0.7663)	Training Prec@1 8.203 (7.137)	Training Prec@5 14.648 (13.262)	
2022-04-01 06:18:10,815: ============================================================
2022-04-01 06:18:50,675: time cost, forward:0.1144741327202023, backward:0.03195850888355887, data cost:0.2500147586718396 
2022-04-01 06:18:50,675: ============================================================
2022-04-01 06:18:50,675: Epoch 23/31 Batch 5900/7662 eta: 6:58:55.390552	Training Loss 0.7577 (0.7661)	Training Prec@1 8.398 (7.173)	Training Prec@5 14.844 (13.315)	
2022-04-01 06:18:50,675: ============================================================
2022-04-01 06:19:30,211: time cost, forward:0.11440769607453649, backward:0.03198450747122862, data cost:0.2500303668724654 
2022-04-01 06:19:30,211: ============================================================
2022-04-01 06:19:30,212: Epoch 23/31 Batch 6000/7662 eta: 6:54:51.741040	Training Loss 0.7615 (0.7660)	Training Prec@1 8.203 (7.207)	Training Prec@5 14.453 (13.369)	
2022-04-01 06:19:30,212: ============================================================
2022-04-01 06:20:09,734: time cost, forward:0.11438389840058019, backward:0.032002376208326466, data cost:0.2500128737432602 
2022-04-01 06:20:09,735: ============================================================
2022-04-01 06:20:09,735: Epoch 23/31 Batch 6100/7662 eta: 6:54:03.993967	Training Loss 0.7536 (0.7658)	Training Prec@1 12.500 (7.242)	Training Prec@5 19.531 (13.419)	
2022-04-01 06:20:09,735: ============================================================
2022-04-01 06:20:46,693: time cost, forward:0.11438928340438644, backward:0.03202589986247004, data cost:0.24953742280354863 
2022-04-01 06:20:46,693: ============================================================
2022-04-01 06:20:46,694: Epoch 23/31 Batch 6200/7662 eta: 6:26:34.893888	Training Loss 0.7770 (0.7657)	Training Prec@1 9.570 (7.268)	Training Prec@5 16.211 (13.462)	
2022-04-01 06:20:46,694: ============================================================
2022-04-01 06:21:26,542: time cost, forward:0.11463905274063695, backward:0.032084103632889244, data cost:0.24926453371770155 
2022-04-01 06:21:26,542: ============================================================
2022-04-01 06:21:26,543: Epoch 23/31 Batch 6300/7662 eta: 6:56:09.193893	Training Loss 0.8099 (0.7667)	Training Prec@1 0.000 (7.163)	Training Prec@5 0.586 (13.271)	
2022-04-01 06:21:26,543: ============================================================
2022-04-01 06:22:07,345: time cost, forward:0.11459248023846128, backward:0.032076167322579986, data cost:0.24949569910052122 
2022-04-01 06:22:07,345: ============================================================
2022-04-01 06:22:07,346: Epoch 23/31 Batch 6400/7662 eta: 7:05:25.732035	Training Loss 0.7548 (0.7667)	Training Prec@1 11.133 (7.158)	Training Prec@5 21.289 (13.263)	
2022-04-01 06:22:07,346: ============================================================
2022-04-01 06:22:46,615: time cost, forward:0.11453892840185721, backward:0.03207848676994665, data cost:0.24950094504766526 
2022-04-01 06:22:46,616: ============================================================
2022-04-01 06:22:46,616: Epoch 23/31 Batch 6500/7662 eta: 6:48:47.676688	Training Loss 0.7556 (0.7665)	Training Prec@1 9.570 (7.191)	Training Prec@5 17.969 (13.314)	
2022-04-01 06:22:46,616: ============================================================
2022-04-01 06:23:26,025: time cost, forward:0.11449985649390985, backward:0.03208077826415396, data cost:0.24948886329973444 
2022-04-01 06:23:26,026: ============================================================
2022-04-01 06:23:26,026: Epoch 23/31 Batch 6600/7662 eta: 6:49:35.756143	Training Loss 0.7565 (0.7663)	Training Prec@1 9.570 (7.224)	Training Prec@5 16.406 (13.366)	
2022-04-01 06:23:26,026: ============================================================
2022-04-01 06:24:05,019: time cost, forward:0.114464482650381, backward:0.032070498908521664, data cost:0.24945015148505076 
2022-04-01 06:24:05,020: ============================================================
2022-04-01 06:24:05,020: Epoch 23/31 Batch 6700/7662 eta: 6:44:37.338410	Training Loss 0.7550 (0.7662)	Training Prec@1 9.961 (7.261)	Training Prec@5 17.773 (13.420)	
2022-04-01 06:24:05,020: ============================================================
2022-04-01 06:24:44,200: time cost, forward:0.11443294818163935, backward:0.03205907234357971, data cost:0.24942090644926196 
2022-04-01 06:24:44,200: ============================================================
2022-04-01 06:24:44,200: Epoch 23/31 Batch 6800/7662 eta: 6:45:54.110833	Training Loss 0.7514 (0.7660)	Training Prec@1 11.719 (7.295)	Training Prec@5 19.336 (13.472)	
2022-04-01 06:24:44,200: ============================================================
2022-04-01 06:25:25,702: time cost, forward:0.11439793084666149, backward:0.032049391369557687, data cost:0.24970342463592737 
2022-04-01 06:25:25,703: ============================================================
2022-04-01 06:25:25,703: Epoch 23/31 Batch 6900/7662 eta: 7:09:16.147629	Training Loss 0.7525 (0.7659)	Training Prec@1 10.938 (7.325)	Training Prec@5 18.555 (13.519)	
2022-04-01 06:25:25,703: ============================================================
2022-04-01 06:26:05,512: time cost, forward:0.11436757024210988, backward:0.032041105445341854, data cost:0.24980134803204046 
2022-04-01 06:26:05,512: ============================================================
2022-04-01 06:26:05,512: Epoch 23/31 Batch 7000/7662 eta: 6:51:05.543866	Training Loss 0.7559 (0.7657)	Training Prec@1 9.180 (7.357)	Training Prec@5 17.773 (13.571)	
2022-04-01 06:26:05,513: ============================================================
2022-04-01 06:26:44,403: time cost, forward:0.11433742912508497, backward:0.032045630002159486, data cost:0.2497086277779164 
2022-04-01 06:26:44,403: ============================================================
2022-04-01 06:26:44,404: Epoch 23/31 Batch 7100/7662 eta: 6:40:57.727211	Training Loss 0.7560 (0.7656)	Training Prec@1 9.961 (7.392)	Training Prec@5 15.820 (13.625)	
2022-04-01 06:26:44,404: ============================================================
2022-04-01 06:27:25,559: time cost, forward:0.11429859724520379, backward:0.03205641201261448, data cost:0.24995428430552216 
2022-04-01 06:27:25,559: ============================================================
2022-04-01 06:27:25,560: Epoch 23/31 Batch 7200/7662 eta: 7:03:37.435176	Training Loss 0.7510 (0.7654)	Training Prec@1 10.742 (7.425)	Training Prec@5 19.727 (13.675)	
2022-04-01 06:27:25,560: ============================================================
2022-04-01 06:28:04,424: time cost, forward:0.11427271361219701, backward:0.032113520343559444, data cost:0.24981112443579273 
2022-04-01 06:28:04,424: ============================================================
2022-04-01 06:28:04,425: Epoch 23/31 Batch 7300/7662 eta: 6:39:23.884727	Training Loss 0.7538 (0.7652)	Training Prec@1 10.352 (7.460)	Training Prec@5 17.578 (13.729)	
2022-04-01 06:28:04,425: ============================================================
2022-04-01 06:28:42,485: time cost, forward:0.11425991002925909, backward:0.03214311026160597, data cost:0.2495842330889825 
2022-04-01 06:28:42,485: ============================================================
2022-04-01 06:28:42,485: Epoch 23/31 Batch 7400/7662 eta: 6:30:29.825023	Training Loss 0.7537 (0.7651)	Training Prec@1 9.961 (7.495)	Training Prec@5 16.406 (13.779)	
2022-04-01 06:28:42,486: ============================================================
2022-04-01 06:29:20,161: time cost, forward:0.11423700401696829, backward:0.03217404456850147, data cost:0.24931057536899287 
2022-04-01 06:29:20,161: ============================================================
2022-04-01 06:29:20,161: Epoch 23/31 Batch 7500/7662 eta: 6:25:55.097735	Training Loss 0.7567 (0.7649)	Training Prec@1 10.156 (7.529)	Training Prec@5 16.992 (13.827)	
2022-04-01 06:29:20,161: ============================================================
2022-04-01 06:29:59,171: time cost, forward:0.11420062024713519, backward:0.03219413879686695, data cost:0.24924355677074939 
2022-04-01 06:29:59,172: ============================================================
2022-04-01 06:29:59,172: Epoch 23/31 Batch 7600/7662 eta: 6:38:56.628802	Training Loss 0.8043 (0.7658)	Training Prec@1 0.391 (7.442)	Training Prec@5 1.562 (13.670)	
2022-04-01 06:29:59,172: ============================================================
2022-04-01 06:30:25,647: Epoch: 23/31 eta: 6:38:32.052006	Training Loss 0.7513 (0.7658)	Training Prec@1 9.961 (7.435)	Training Prec@5 16.992 (13.655)
2022-04-01 06:30:25,647: ============================================================
2022-04-01 06:31:06,453: time cost, forward:0.11841757369763924, backward:0.0322141069354433, data cost:0.2583729859554406 
2022-04-01 06:31:06,454: ============================================================
2022-04-01 06:31:06,454: Epoch 24/31 Batch 100/7662 eta: 6:55:55.882124	Training Loss 0.7558 (0.7512)	Training Prec@1 7.617 (10.598)	Training Prec@5 14.648 (18.628)	
2022-04-01 06:31:06,454: ============================================================
2022-04-01 06:31:46,263: time cost, forward:0.12013506889343262, backward:0.032680535436275616, data cost:0.25087263116884473 
2022-04-01 06:31:46,264: ============================================================
2022-04-01 06:31:46,264: Epoch 24/31 Batch 200/7662 eta: 6:45:22.780195	Training Loss 0.7489 (0.7510)	Training Prec@1 11.133 (10.789)	Training Prec@5 19.531 (18.835)	
2022-04-01 06:31:46,264: ============================================================
2022-04-01 06:32:26,066: time cost, forward:0.11857528351621086, backward:0.03299276804844273, data cost:0.24997260658238643 
2022-04-01 06:32:26,066: ============================================================
2022-04-01 06:32:26,066: Epoch 24/31 Batch 300/7662 eta: 6:44:38.360453	Training Loss 0.7541 (0.7515)	Training Prec@1 13.086 (10.774)	Training Prec@5 18.750 (18.743)	
2022-04-01 06:32:26,067: ============================================================
2022-04-01 06:33:05,311: time cost, forward:0.11741776872697032, backward:0.033425005456259975, data cost:0.248294280585191 
2022-04-01 06:33:05,311: ============================================================
2022-04-01 06:33:05,311: Epoch 24/31 Batch 400/7662 eta: 6:38:18.857708	Training Loss 0.7451 (0.7513)	Training Prec@1 12.109 (10.836)	Training Prec@5 20.312 (18.782)	
2022-04-01 06:33:05,311: ============================================================
2022-04-01 06:33:44,763: time cost, forward:0.11649191546774579, backward:0.03371769536234334, data cost:0.24789699619423172 
2022-04-01 06:33:44,763: ============================================================
2022-04-01 06:33:44,764: Epoch 24/31 Batch 500/7662 eta: 6:39:45.845169	Training Loss 0.8176 (0.7517)	Training Prec@1 1.172 (10.805)	Training Prec@5 4.102 (18.737)	
2022-04-01 06:33:44,764: ============================================================
2022-04-01 06:34:24,852: time cost, forward:0.11565008306742112, backward:0.03395783284271699, data cost:0.24894899080114094 
2022-04-01 06:34:24,853: ============================================================
2022-04-01 06:34:24,853: Epoch 24/31 Batch 600/7662 eta: 6:45:33.108445	Training Loss 0.7799 (0.7628)	Training Prec@1 2.930 (9.126)	Training Prec@5 8.008 (15.916)	
2022-04-01 06:34:24,853: ============================================================
2022-04-01 06:35:03,582: time cost, forward:0.11516669482120628, backward:0.034003400325092976, data cost:0.24774000675381508 
2022-04-01 06:35:03,582: ============================================================
2022-04-01 06:35:03,582: Epoch 24/31 Batch 700/7662 eta: 6:31:08.833376	Training Loss 0.7517 (0.7616)	Training Prec@1 9.375 (9.203)	Training Prec@5 16.602 (16.078)	
2022-04-01 06:35:03,583: ============================================================
2022-04-01 06:35:42,685: time cost, forward:0.11483271220449512, backward:0.03363713901839656, data cost:0.24761025717619511 
2022-04-01 06:35:42,685: ============================================================
2022-04-01 06:35:42,685: Epoch 24/31 Batch 800/7662 eta: 6:34:16.114749	Training Loss 0.7528 (0.7603)	Training Prec@1 9.180 (9.430)	Training Prec@5 18.164 (16.430)	
2022-04-01 06:35:42,685: ============================================================
2022-04-01 06:36:21,386: time cost, forward:0.11445280389075019, backward:0.033454113197538826, data cost:0.247185596236928 
2022-04-01 06:36:21,386: ============================================================
2022-04-01 06:36:21,386: Epoch 24/31 Batch 900/7662 eta: 6:29:34.224667	Training Loss 0.7485 (0.7592)	Training Prec@1 12.891 (9.622)	Training Prec@5 19.727 (16.741)	
2022-04-01 06:36:21,386: ============================================================
2022-04-01 06:37:01,784: time cost, forward:0.11413955044102024, backward:0.033384698527949945, data cost:0.2484226269764943 
2022-04-01 06:37:01,785: ============================================================
2022-04-01 06:37:01,785: Epoch 24/31 Batch 1000/7662 eta: 6:45:59.089275	Training Loss 0.7529 (0.7583)	Training Prec@1 9.570 (9.780)	Training Prec@5 17.188 (16.982)	
2022-04-01 06:37:01,785: ============================================================
2022-04-01 06:37:41,435: time cost, forward:0.11394653741178781, backward:0.03318298112489181, data cost:0.2487585711631046 
2022-04-01 06:37:41,436: ============================================================
2022-04-01 06:37:41,436: Epoch 24/31 Batch 1100/7662 eta: 6:37:48.700428	Training Loss 0.7461 (0.7576)	Training Prec@1 14.844 (9.905)	Training Prec@5 21.680 (17.190)	
2022-04-01 06:37:41,436: ============================================================
2022-04-01 06:38:19,552: time cost, forward:0.11387467205375308, backward:0.03315764093916052, data cost:0.24766661824535788 
2022-04-01 06:38:19,552: ============================================================
2022-04-01 06:38:19,552: Epoch 24/31 Batch 1200/7662 eta: 6:21:46.734248	Training Loss 0.7520 (0.7570)	Training Prec@1 9.961 (10.021)	Training Prec@5 18.555 (17.370)	
2022-04-01 06:38:19,552: ============================================================
2022-04-01 06:38:57,081: time cost, forward:0.11384640536554232, backward:0.033190605179725746, data cost:0.24611610665148823 
2022-04-01 06:38:57,082: ============================================================
2022-04-01 06:38:57,082: Epoch 24/31 Batch 1300/7662 eta: 6:15:16.844759	Training Loss 0.7583 (0.7564)	Training Prec@1 10.742 (10.103)	Training Prec@5 18.359 (17.510)	
2022-04-01 06:38:57,082: ============================================================
2022-04-01 06:39:36,467: time cost, forward:0.11381404974189632, backward:0.03316725825649913, data cost:0.24620563954945715 
2022-04-01 06:39:36,468: ============================================================
2022-04-01 06:39:36,468: Epoch 24/31 Batch 1400/7662 eta: 6:33:11.066930	Training Loss 0.7529 (0.7562)	Training Prec@1 10.547 (10.163)	Training Prec@5 18.555 (17.602)	
2022-04-01 06:39:36,468: ============================================================
2022-04-01 06:40:15,103: time cost, forward:0.11463080890342504, backward:0.03315272372591249, data cost:0.24492885240958165 
2022-04-01 06:40:15,104: ============================================================
2022-04-01 06:40:15,104: Epoch 24/31 Batch 1500/7662 eta: 6:25:03.186264	Training Loss 0.7450 (0.7558)	Training Prec@1 12.891 (10.239)	Training Prec@5 21.875 (17.722)	
2022-04-01 06:40:15,104: ============================================================
2022-04-01 06:40:55,050: time cost, forward:0.11511356835070068, backward:0.03320772965450895, data cost:0.2447980847337829 
2022-04-01 06:40:55,051: ============================================================
2022-04-01 06:40:55,051: Epoch 24/31 Batch 1600/7662 eta: 6:37:26.979421	Training Loss 0.7504 (0.7554)	Training Prec@1 10.156 (10.307)	Training Prec@5 20.703 (17.823)	
2022-04-01 06:40:55,051: ============================================================
2022-04-01 06:41:34,509: time cost, forward:0.11491270553651735, backward:0.03323377729374356, data cost:0.245058736077051 
2022-04-01 06:41:34,509: ============================================================
2022-04-01 06:41:34,509: Epoch 24/31 Batch 1700/7662 eta: 6:31:56.139595	Training Loss 0.7437 (0.7550)	Training Prec@1 12.109 (10.370)	Training Prec@5 23.828 (17.926)	
2022-04-01 06:41:34,510: ============================================================
2022-04-01 06:42:14,512: time cost, forward:0.11467160947989463, backward:0.03328517902685974, data cost:0.24559597998211422 
2022-04-01 06:42:14,512: ============================================================
2022-04-01 06:42:14,512: Epoch 24/31 Batch 1800/7662 eta: 6:36:40.593859	Training Loss 0.8409 (0.7556)	Training Prec@1 0.195 (10.324)	Training Prec@5 0.781 (17.844)	
2022-04-01 06:42:14,513: ============================================================
2022-04-01 06:42:51,831: time cost, forward:0.1145701910584396, backward:0.03328185510861365, data cost:0.2446262679519372 
2022-04-01 06:42:51,831: ============================================================
2022-04-01 06:42:51,831: Epoch 24/31 Batch 1900/7662 eta: 6:09:26.255833	Training Loss 0.7525 (0.7576)	Training Prec@1 8.594 (10.003)	Training Prec@5 16.211 (17.314)	
2022-04-01 06:42:51,831: ============================================================
2022-04-01 06:43:31,761: time cost, forward:0.11443245202198572, backward:0.03324854081723021, data cost:0.2448706245231533 
2022-04-01 06:43:31,762: ============================================================
2022-04-01 06:43:31,762: Epoch 24/31 Batch 2000/7662 eta: 6:34:37.673004	Training Loss 0.7533 (0.7572)	Training Prec@1 9.375 (10.086)	Training Prec@5 17.578 (17.441)	
2022-04-01 06:43:31,762: ============================================================
2022-04-01 06:44:11,817: time cost, forward:0.11432619501489182, backward:0.0330965688195667, data cost:0.24571913602864418 
2022-04-01 06:44:11,818: ============================================================
2022-04-01 06:44:11,818: Epoch 24/31 Batch 2100/7662 eta: 6:35:11.872409	Training Loss 0.7489 (0.7568)	Training Prec@1 12.305 (10.166)	Training Prec@5 19.336 (17.568)	
2022-04-01 06:44:11,818: ============================================================
2022-04-01 06:44:50,425: time cost, forward:0.11428188009118968, backward:0.033161652093586354, data cost:0.24535016018241684 
2022-04-01 06:44:50,425: ============================================================
2022-04-01 06:44:50,426: Epoch 24/31 Batch 2200/7662 eta: 6:20:16.041284	Training Loss 0.7444 (0.7565)	Training Prec@1 11.719 (10.225)	Training Prec@5 21.484 (17.655)	
2022-04-01 06:44:50,426: ============================================================
2022-04-01 06:45:30,525: time cost, forward:0.11422727304004804, backward:0.033191890185581385, data cost:0.24572785048963922 
2022-04-01 06:45:30,525: ============================================================
2022-04-01 06:45:30,525: Epoch 24/31 Batch 2300/7662 eta: 6:34:17.593128	Training Loss 0.7495 (0.7561)	Training Prec@1 10.156 (10.287)	Training Prec@5 16.602 (17.749)	
2022-04-01 06:45:30,525: ============================================================
2022-04-01 06:46:10,546: time cost, forward:0.11417859502015584, backward:0.03322534950736564, data cost:0.24592842534960882 
2022-04-01 06:46:10,546: ============================================================
2022-04-01 06:46:10,546: Epoch 24/31 Batch 2400/7662 eta: 6:32:51.183060	Training Loss 0.7964 (0.7561)	Training Prec@1 5.078 (10.314)	Training Prec@5 9.766 (17.791)	
2022-04-01 06:46:10,546: ============================================================
2022-04-01 06:46:49,975: time cost, forward:0.1141574341757577, backward:0.03328989257140844, data cost:0.24600003623351807 
2022-04-01 06:46:49,975: ============================================================
2022-04-01 06:46:49,975: Epoch 24/31 Batch 2500/7662 eta: 6:26:23.141686	Training Loss 0.7526 (0.7562)	Training Prec@1 11.719 (10.296)	Training Prec@5 18.359 (17.786)	
2022-04-01 06:46:49,976: ============================================================
2022-04-01 06:47:29,273: time cost, forward:0.11417437397823649, backward:0.03335095727017129, data cost:0.24589004944085432 
2022-04-01 06:47:29,273: ============================================================
2022-04-01 06:47:29,273: Epoch 24/31 Batch 2600/7662 eta: 6:24:26.614170	Training Loss 0.7512 (0.7559)	Training Prec@1 10.742 (10.340)	Training Prec@5 18.164 (17.853)	
2022-04-01 06:47:29,273: ============================================================
2022-04-01 06:48:09,033: time cost, forward:0.11497869585213197, backward:0.033429475747554026, data cost:0.24516076297837747 
2022-04-01 06:48:09,033: ============================================================
2022-04-01 06:48:09,034: Epoch 24/31 Batch 2700/7662 eta: 6:28:18.478460	Training Loss 0.7505 (0.7556)	Training Prec@1 10.352 (10.399)	Training Prec@5 19.531 (17.939)	
2022-04-01 06:48:09,034: ============================================================
2022-04-01 06:48:48,674: time cost, forward:0.11557826155975658, backward:0.0334656671269871, data cost:0.2446133101484783 
2022-04-01 06:48:48,674: ============================================================
2022-04-01 06:48:48,674: Epoch 24/31 Batch 2800/7662 eta: 6:26:28.633867	Training Loss 0.7585 (0.7554)	Training Prec@1 9.766 (10.452)	Training Prec@5 18.164 (18.024)	
2022-04-01 06:48:48,675: ============================================================
2022-04-01 06:49:27,661: time cost, forward:0.11549920063670152, backward:0.0334567162611436, data cost:0.2445435226271999 
2022-04-01 06:49:27,662: ============================================================
2022-04-01 06:49:27,662: Epoch 24/31 Batch 2900/7662 eta: 6:19:27.572255	Training Loss 0.7433 (0.7557)	Training Prec@1 15.820 (10.421)	Training Prec@5 24.219 (17.969)	
2022-04-01 06:49:27,662: ============================================================
2022-04-01 06:50:06,957: time cost, forward:0.11566971063057396, backward:0.03346204733840622, data cost:0.24434773068938426 
2022-04-01 06:50:06,957: ============================================================
2022-04-01 06:50:06,957: Epoch 24/31 Batch 3000/7662 eta: 6:21:47.938514	Training Loss 0.7518 (0.7554)	Training Prec@1 10.156 (10.470)	Training Prec@5 17.383 (18.046)	
2022-04-01 06:50:06,957: ============================================================
2022-04-01 06:50:47,088: time cost, forward:0.11560310198822957, backward:0.033467636603853636, data cost:0.24465216548645177 
2022-04-01 06:50:47,089: ============================================================
2022-04-01 06:50:47,089: Epoch 24/31 Batch 3100/7662 eta: 6:29:15.451993	Training Loss 0.7495 (0.7552)	Training Prec@1 12.109 (10.517)	Training Prec@5 20.117 (18.126)	
2022-04-01 06:50:47,089: ============================================================
2022-04-01 06:51:25,653: time cost, forward:0.11554417404468151, backward:0.033430501422721096, data cost:0.24448440610784858 
2022-04-01 06:51:25,653: ============================================================
2022-04-01 06:51:25,654: Epoch 24/31 Batch 3200/7662 eta: 6:13:24.896849	Training Loss 0.7493 (0.7549)	Training Prec@1 11.719 (10.569)	Training Prec@5 19.141 (18.202)	
2022-04-01 06:51:25,654: ============================================================
2022-04-01 06:52:06,869: time cost, forward:0.11576362847197812, backward:0.033343495943937276, data cost:0.24489533904828098 
2022-04-01 06:52:06,869: ============================================================
2022-04-01 06:52:06,870: Epoch 24/31 Batch 3300/7662 eta: 6:38:24.095696	Training Loss 0.7462 (0.7547)	Training Prec@1 11.523 (10.617)	Training Prec@5 19.727 (18.271)	
2022-04-01 06:52:06,870: ============================================================
2022-04-01 06:52:45,467: time cost, forward:0.11593616454171307, backward:0.03332881059110708, data cost:0.24450940852938205 
2022-04-01 06:52:45,468: ============================================================
2022-04-01 06:52:45,468: Epoch 24/31 Batch 3400/7662 eta: 6:12:27.198660	Training Loss 0.7521 (0.7545)	Training Prec@1 11.719 (10.667)	Training Prec@5 18.750 (18.340)	
2022-04-01 06:52:45,468: ============================================================
2022-04-01 06:53:25,280: time cost, forward:0.11583216682983555, backward:0.03330106911028273, data cost:0.24473723325432284 
2022-04-01 06:53:25,281: ============================================================
2022-04-01 06:53:25,281: Epoch 24/31 Batch 3500/7662 eta: 6:23:30.755279	Training Loss 0.7434 (0.7543)	Training Prec@1 15.039 (10.712)	Training Prec@5 23.828 (18.405)	
2022-04-01 06:53:25,281: ============================================================
2022-04-01 06:54:06,682: time cost, forward:0.11574485117145697, backward:0.03324984907938328, data cost:0.24542303362234527 
2022-04-01 06:54:06,682: ============================================================
2022-04-01 06:54:06,683: Epoch 24/31 Batch 3600/7662 eta: 6:38:07.537347	Training Loss 0.7510 (0.7541)	Training Prec@1 11.133 (10.766)	Training Prec@5 19.922 (18.475)	
2022-04-01 06:54:06,683: ============================================================
2022-04-01 06:54:47,437: time cost, forward:0.11569303601263149, backward:0.03326292352503653, data cost:0.24582230023159535 
2022-04-01 06:54:47,437: ============================================================
2022-04-01 06:54:47,438: Epoch 24/31 Batch 3700/7662 eta: 6:31:13.650962	Training Loss 0.7460 (0.7539)	Training Prec@1 12.305 (10.814)	Training Prec@5 20.312 (18.545)	
2022-04-01 06:54:47,438: ============================================================
2022-04-01 06:55:27,851: time cost, forward:0.116064748816755, backward:0.03329201075992449, data cost:0.2456652319221065 
2022-04-01 06:55:27,852: ============================================================
2022-04-01 06:55:27,852: Epoch 24/31 Batch 3800/7662 eta: 6:27:16.999495	Training Loss 0.7486 (0.7537)	Training Prec@1 13.086 (10.853)	Training Prec@5 19.336 (18.603)	
2022-04-01 06:55:27,852: ============================================================
2022-04-01 06:56:07,235: time cost, forward:0.1163520308511934, backward:0.03331388745989118, data cost:0.24530674885957476 
2022-04-01 06:56:07,235: ============================================================
2022-04-01 06:56:07,235: Epoch 24/31 Batch 3900/7662 eta: 6:16:44.974921	Training Loss 0.7499 (0.7535)	Training Prec@1 8.984 (10.895)	Training Prec@5 16.602 (18.656)	
2022-04-01 06:56:07,236: ============================================================
2022-04-01 06:56:47,128: time cost, forward:0.11690844163563169, backward:0.033316339305353986, data cost:0.2448396286865448 
2022-04-01 06:56:47,128: ============================================================
2022-04-01 06:56:47,128: Epoch 24/31 Batch 4000/7662 eta: 6:20:57.373571	Training Loss 0.7465 (0.7533)	Training Prec@1 12.305 (10.941)	Training Prec@5 22.461 (18.717)	
2022-04-01 06:56:47,128: ============================================================
2022-04-01 06:57:26,515: time cost, forward:0.11679811150773498, backward:0.033202870295204225, data cost:0.2450304349534946 
2022-04-01 06:57:26,515: ============================================================
2022-04-01 06:57:26,516: Epoch 24/31 Batch 4100/7662 eta: 6:15:28.326988	Training Loss 0.7477 (0.7531)	Training Prec@1 12.500 (10.989)	Training Prec@5 22.266 (18.777)	
2022-04-01 06:57:26,516: ============================================================
2022-04-01 06:58:06,559: time cost, forward:0.11667573829581834, backward:0.03314768532736865, data cost:0.24532806427599732 
2022-04-01 06:58:06,560: ============================================================
2022-04-01 06:58:06,560: Epoch 24/31 Batch 4200/7662 eta: 6:21:04.179778	Training Loss 0.7443 (0.7529)	Training Prec@1 12.695 (11.027)	Training Prec@5 21.289 (18.837)	
2022-04-01 06:58:06,560: ============================================================
2022-04-01 06:58:45,421: time cost, forward:0.11658894602546417, backward:0.03318159711668729, data cost:0.2452240798273151 
2022-04-01 06:58:45,422: ============================================================
2022-04-01 06:58:45,422: Epoch 24/31 Batch 4300/7662 eta: 6:09:10.116923	Training Loss 0.7464 (0.7528)	Training Prec@1 12.695 (11.067)	Training Prec@5 20.312 (18.893)	
2022-04-01 06:58:45,422: ============================================================
2022-04-01 06:59:25,204: time cost, forward:0.1164629373747697, backward:0.03314296287090894, data cost:0.24544122262986365 
2022-04-01 06:59:25,205: ============================================================
2022-04-01 06:59:25,205: Epoch 24/31 Batch 4400/7662 eta: 6:17:15.452609	Training Loss 0.7442 (0.7526)	Training Prec@1 12.891 (11.108)	Training Prec@5 20.703 (18.949)	
2022-04-01 06:59:25,205: ============================================================
2022-04-01 07:00:03,630: time cost, forward:0.11636877791249346, backward:0.033075803331492556, data cost:0.24535604036233244 
2022-04-01 07:00:03,630: ============================================================
2022-04-01 07:00:03,630: Epoch 24/31 Batch 4500/7662 eta: 6:03:44.366794	Training Loss 0.7951 (0.7525)	Training Prec@1 6.055 (11.136)	Training Prec@5 10.156 (18.992)	
2022-04-01 07:00:03,630: ============================================================
2022-04-01 07:00:43,186: time cost, forward:0.11628711355797854, backward:0.03299509563972754, data cost:0.24552873959617008 
2022-04-01 07:00:43,187: ============================================================
2022-04-01 07:00:43,187: Epoch 24/31 Batch 4600/7662 eta: 6:13:47.355810	Training Loss 0.7496 (0.7528)	Training Prec@1 11.914 (11.091)	Training Prec@5 19.922 (18.924)	
2022-04-01 07:00:43,187: ============================================================
2022-04-01 07:01:23,143: time cost, forward:0.11620698190288459, backward:0.03297679103113383, data cost:0.24571327621263503 
2022-04-01 07:01:23,143: ============================================================
2022-04-01 07:01:23,143: Epoch 24/31 Batch 4700/7662 eta: 6:16:54.162254	Training Loss 0.7468 (0.7526)	Training Prec@1 13.867 (11.138)	Training Prec@5 22.266 (18.991)	
2022-04-01 07:01:23,143: ============================================================
2022-04-01 07:02:02,711: time cost, forward:0.11607658726445186, backward:0.0329826861824883, data cost:0.2458495986936092 
2022-04-01 07:02:02,711: ============================================================
2022-04-01 07:02:02,711: Epoch 24/31 Batch 4800/7662 eta: 6:12:34.728694	Training Loss 0.7451 (0.7525)	Training Prec@1 13.086 (11.181)	Training Prec@5 22.461 (19.051)	
2022-04-01 07:02:02,711: ============================================================
2022-04-01 07:02:42,369: time cost, forward:0.11599152271639063, backward:0.03298576079137132, data cost:0.24591919776735852 
2022-04-01 07:02:42,370: ============================================================
2022-04-01 07:02:42,370: Epoch 24/31 Batch 4900/7662 eta: 6:12:46.429442	Training Loss 0.7489 (0.7523)	Training Prec@1 13.086 (11.221)	Training Prec@5 22.070 (19.110)	
2022-04-01 07:02:42,370: ============================================================
2022-04-01 07:03:23,945: time cost, forward:0.11590369536080677, backward:0.032979194534661936, data cost:0.24646719237951595 
2022-04-01 07:03:23,945: ============================================================
2022-04-01 07:03:23,945: Epoch 24/31 Batch 5000/7662 eta: 6:30:05.495494	Training Loss 0.7415 (0.7521)	Training Prec@1 14.453 (11.260)	Training Prec@5 25.391 (19.163)	
2022-04-01 07:03:23,945: ============================================================
2022-04-01 07:04:02,926: time cost, forward:0.11584135513021376, backward:0.03299184896637819, data cost:0.24639278370905307 
2022-04-01 07:04:02,926: ============================================================
2022-04-01 07:04:02,926: Epoch 24/31 Batch 5100/7662 eta: 6:05:06.129629	Training Loss 0.7424 (0.7520)	Training Prec@1 14.453 (11.299)	Training Prec@5 22.656 (19.222)	
2022-04-01 07:04:02,926: ============================================================
2022-04-01 07:04:42,950: time cost, forward:0.11577433131020398, backward:0.032993174030313495, data cost:0.24655138114067793 
2022-04-01 07:04:42,950: ============================================================
2022-04-01 07:04:42,950: Epoch 24/31 Batch 5200/7662 eta: 6:14:12.232880	Training Loss 0.7453 (0.7523)	Training Prec@1 13.477 (11.259)	Training Prec@5 23.438 (19.160)	
2022-04-01 07:04:42,950: ============================================================
2022-04-01 07:05:22,146: time cost, forward:0.11569757852088193, backward:0.032992648907395256, data cost:0.2465611356770144 
2022-04-01 07:05:22,147: ============================================================
2022-04-01 07:05:22,147: Epoch 24/31 Batch 5300/7662 eta: 6:05:49.112197	Training Loss 0.7453 (0.7521)	Training Prec@1 11.719 (11.295)	Training Prec@5 20.898 (19.212)	
2022-04-01 07:05:22,147: ============================================================
2022-04-01 07:06:02,954: time cost, forward:0.1156464954022236, backward:0.03294173614429884, data cost:0.2468864609519957 
2022-04-01 07:06:02,954: ============================================================
2022-04-01 07:06:02,954: Epoch 24/31 Batch 5400/7662 eta: 6:20:10.064261	Training Loss 0.7446 (0.7520)	Training Prec@1 12.305 (11.331)	Training Prec@5 20.312 (19.260)	
2022-04-01 07:06:02,955: ============================================================
2022-04-01 07:06:42,206: time cost, forward:0.1155885393174264, backward:0.03297497675969051, data cost:0.24684924068267095 
2022-04-01 07:06:42,207: ============================================================
2022-04-01 07:06:42,207: Epoch 24/31 Batch 5500/7662 eta: 6:05:01.795014	Training Loss 0.7442 (0.7518)	Training Prec@1 13.086 (11.370)	Training Prec@5 19.922 (19.311)	
2022-04-01 07:06:42,207: ============================================================
2022-04-01 07:07:21,695: time cost, forward:0.11550970029822416, backward:0.032972805371006, data cost:0.24692293583739972 
2022-04-01 07:07:21,696: ============================================================
2022-04-01 07:07:21,696: Epoch 24/31 Batch 5600/7662 eta: 6:06:34.077494	Training Loss 0.7415 (0.7517)	Training Prec@1 14.258 (11.407)	Training Prec@5 24.414 (19.362)	
2022-04-01 07:07:21,696: ============================================================
2022-04-01 07:08:01,693: time cost, forward:0.11543810352941922, backward:0.03300551013541569, data cost:0.24703975229184655 
2022-04-01 07:08:01,693: ============================================================
2022-04-01 07:08:01,694: Epoch 24/31 Batch 5700/7662 eta: 6:10:37.584351	Training Loss 0.7430 (0.7521)	Training Prec@1 12.500 (11.339)	Training Prec@5 22.656 (19.253)	
2022-04-01 07:08:01,694: ============================================================
2022-04-01 07:08:41,107: time cost, forward:0.1153705084317716, backward:0.03302418159850611, data cost:0.24706209188988545 
2022-04-01 07:08:41,107: ============================================================
2022-04-01 07:08:41,107: Epoch 24/31 Batch 5800/7662 eta: 6:04:33.457798	Training Loss 0.7401 (0.7520)	Training Prec@1 15.820 (11.378)	Training Prec@5 24.414 (19.309)	
2022-04-01 07:08:41,108: ============================================================
2022-04-01 07:09:19,932: time cost, forward:0.11530615390610101, backward:0.033022349073555855, data cost:0.2469926133441165 
2022-04-01 07:09:19,932: ============================================================
2022-04-01 07:09:19,932: Epoch 24/31 Batch 5900/7662 eta: 5:58:27.814483	Training Loss 0.7392 (0.7518)	Training Prec@1 14.648 (11.421)	Training Prec@5 25.195 (19.367)	
2022-04-01 07:09:19,933: ============================================================
2022-04-01 07:09:59,602: time cost, forward:0.11554875479556855, backward:0.033020173416353896, data cost:0.24676619034684644 
2022-04-01 07:09:59,602: ============================================================
2022-04-01 07:09:59,603: Epoch 24/31 Batch 6000/7662 eta: 6:05:36.504120	Training Loss 0.7404 (0.7517)	Training Prec@1 16.992 (11.460)	Training Prec@5 25.000 (19.423)	
2022-04-01 07:09:59,603: ============================================================
2022-04-01 07:10:40,520: time cost, forward:0.11555167498559635, backward:0.03300406600944643, data cost:0.24700321160607464 
2022-04-01 07:10:40,520: ============================================================
2022-04-01 07:10:40,520: Epoch 24/31 Batch 6100/7662 eta: 6:16:25.237223	Training Loss 0.7452 (0.7515)	Training Prec@1 13.086 (11.501)	Training Prec@5 22.461 (19.477)	
2022-04-01 07:10:40,520: ============================================================
2022-04-01 07:11:18,437: time cost, forward:0.11549391010381037, backward:0.03298621170750393, data cost:0.24680689193102828 
2022-04-01 07:11:18,437: ============================================================
2022-04-01 07:11:18,437: Epoch 24/31 Batch 6200/7662 eta: 5:48:11.255102	Training Loss 0.7418 (0.7514)	Training Prec@1 12.695 (11.538)	Training Prec@5 21.875 (19.530)	
2022-04-01 07:11:18,437: ============================================================
2022-04-01 07:11:58,352: time cost, forward:0.11541735632000584, backward:0.03298122210244486, data cost:0.2469434027331919 
2022-04-01 07:11:58,352: ============================================================
2022-04-01 07:11:58,353: Epoch 24/31 Batch 6300/7662 eta: 6:05:52.231250	Training Loss 0.7406 (0.7512)	Training Prec@1 14.062 (11.580)	Training Prec@5 22.070 (19.588)	
2022-04-01 07:11:58,353: ============================================================
2022-04-01 07:12:38,496: time cost, forward:0.11540985498638484, backward:0.03299283292036836, data cost:0.24702188927301263 
2022-04-01 07:12:38,497: ============================================================
2022-04-01 07:12:38,497: Epoch 24/31 Batch 6400/7662 eta: 6:07:18.103793	Training Loss 0.7532 (0.7511)	Training Prec@1 12.305 (11.618)	Training Prec@5 21.875 (19.637)	
2022-04-01 07:12:38,497: ============================================================
2022-04-01 07:13:17,629: time cost, forward:0.11551317949995002, backward:0.03300195577456816, data cost:0.2468437286024186 
2022-04-01 07:13:17,629: ============================================================
2022-04-01 07:13:17,630: Epoch 24/31 Batch 6500/7662 eta: 5:57:23.507844	Training Loss 0.7350 (0.7511)	Training Prec@1 15.234 (11.640)	Training Prec@5 25.586 (19.664)	
2022-04-01 07:13:17,630: ============================================================
2022-04-01 07:13:57,742: time cost, forward:0.11560885883457897, backward:0.03300923744030551, data cost:0.24682843903733628 
2022-04-01 07:13:57,742: ============================================================
2022-04-01 07:13:57,742: Epoch 24/31 Batch 6600/7662 eta: 6:05:40.335664	Training Loss 0.7412 (0.7510)	Training Prec@1 13.281 (11.681)	Training Prec@5 22.852 (19.715)	
2022-04-01 07:13:57,742: ============================================================
2022-04-01 07:14:38,267: time cost, forward:0.11586793932848537, backward:0.03303906034579792, data cost:0.2466843896240312 
2022-04-01 07:14:38,267: ============================================================
2022-04-01 07:14:38,267: Epoch 24/31 Batch 6700/7662 eta: 6:08:45.490015	Training Loss 0.7400 (0.7508)	Training Prec@1 12.109 (11.724)	Training Prec@5 18.945 (19.771)	
2022-04-01 07:14:38,268: ============================================================
2022-04-01 07:15:17,949: time cost, forward:0.11602236155394789, backward:0.03305328030816981, data cost:0.24653004576027576 
2022-04-01 07:15:17,950: ============================================================
2022-04-01 07:15:17,950: Epoch 24/31 Batch 6800/7662 eta: 6:00:25.720770	Training Loss 0.7436 (0.7507)	Training Prec@1 12.695 (11.763)	Training Prec@5 19.336 (19.827)	
2022-04-01 07:15:17,950: ============================================================
2022-04-01 07:15:58,349: time cost, forward:0.11594525605530856, backward:0.03304701170069115, data cost:0.24672466935515663 
2022-04-01 07:15:58,349: ============================================================
2022-04-01 07:15:58,349: Epoch 24/31 Batch 6900/7662 eta: 6:06:16.222564	Training Loss 0.7411 (0.7506)	Training Prec@1 15.430 (11.803)	Training Prec@5 24.414 (19.880)	
2022-04-01 07:15:58,350: ============================================================
2022-04-01 07:16:38,352: time cost, forward:0.1158622399213093, backward:0.033046310434070275, data cost:0.24687148564405859 
2022-04-01 07:16:38,352: ============================================================
2022-04-01 07:16:38,352: Epoch 24/31 Batch 7000/7662 eta: 6:02:00.167036	Training Loss 0.7413 (0.7504)	Training Prec@1 14.258 (11.848)	Training Prec@5 22.656 (19.940)	
2022-04-01 07:16:38,352: ============================================================
2022-04-01 07:17:18,831: time cost, forward:0.11598233744063366, backward:0.0330377698767469, data cost:0.2468742897752675 
2022-04-01 07:17:18,831: ============================================================
2022-04-01 07:17:18,831: Epoch 24/31 Batch 7100/7662 eta: 6:05:38.462990	Training Loss 0.7401 (0.7502)	Training Prec@1 14.844 (11.887)	Training Prec@5 26.172 (19.994)	
2022-04-01 07:17:18,831: ============================================================
2022-04-01 07:18:00,474: time cost, forward:0.11631521520920637, backward:0.03305370222447498, data cost:0.2468124083767899 
2022-04-01 07:18:00,474: ============================================================
2022-04-01 07:18:00,474: Epoch 24/31 Batch 7200/7662 eta: 6:15:27.699290	Training Loss 0.7629 (0.7505)	Training Prec@1 7.227 (11.856)	Training Prec@5 16.211 (19.940)	
2022-04-01 07:18:00,474: ============================================================
2022-04-01 07:18:41,769: time cost, forward:0.11659066578119907, backward:0.03306421450938831, data cost:0.246747483748543 
2022-04-01 07:18:41,769: ============================================================
2022-04-01 07:18:41,769: Epoch 24/31 Batch 7300/7662 eta: 6:11:37.953308	Training Loss 0.7385 (0.7504)	Training Prec@1 14.453 (11.890)	Training Prec@5 25.000 (19.986)	
2022-04-01 07:18:41,769: ============================================================
2022-04-01 07:19:22,328: time cost, forward:0.11671749407060245, backward:0.03306235086436142, data cost:0.24674479470637734 
2022-04-01 07:19:22,329: ============================================================
2022-04-01 07:19:22,329: Epoch 24/31 Batch 7400/7662 eta: 6:04:20.468840	Training Loss 0.7328 (0.7503)	Training Prec@1 17.969 (11.930)	Training Prec@5 28.320 (20.041)	
2022-04-01 07:19:22,329: ============================================================
2022-04-01 07:20:04,495: time cost, forward:0.1169589648709041, backward:0.03309417836013389, data cost:0.24679854886184327 
2022-04-01 07:20:04,495: ============================================================
2022-04-01 07:20:04,495: Epoch 24/31 Batch 7500/7662 eta: 6:18:04.381444	Training Loss 0.7424 (0.7501)	Training Prec@1 15.234 (11.965)	Training Prec@5 23.438 (20.092)	
2022-04-01 07:20:04,496: ============================================================
2022-04-01 07:20:45,940: time cost, forward:0.11722014815983983, backward:0.03312703031727414, data cost:0.24672863417227717 
2022-04-01 07:20:45,941: ============================================================
2022-04-01 07:20:45,941: Epoch 24/31 Batch 7600/7662 eta: 6:10:55.001474	Training Loss 0.7347 (0.7500)	Training Prec@1 14.648 (12.009)	Training Prec@5 24.414 (20.151)	
2022-04-01 07:20:45,941: ============================================================
2022-04-01 07:21:12,079: Epoch: 24/31 eta: 6:10:28.890795	Training Loss 0.7406 (0.7499)	Training Prec@1 15.430 (12.036)	Training Prec@5 25.391 (20.187)
2022-04-01 07:21:12,079: ============================================================
2022-04-01 07:21:54,971: time cost, forward:0.13934940280336322, backward:0.03327760070261329, data cost:0.2524547673235036 
2022-04-01 07:21:54,971: ============================================================
2022-04-01 07:21:54,971: Epoch 25/31 Batch 100/7662 eta: 6:20:25.467187	Training Loss 0.7362 (0.7350)	Training Prec@1 17.188 (16.546)	Training Prec@5 26.758 (25.998)	
2022-04-01 07:21:54,971: ============================================================
2022-04-01 07:22:38,117: time cost, forward:0.15105678448125945, backward:0.03386527090216402, data cost:0.24473076968935867 
2022-04-01 07:22:38,117: ============================================================
2022-04-01 07:22:38,117: Epoch 25/31 Batch 200/7662 eta: 6:24:15.012435	Training Loss 0.7369 (0.7349)	Training Prec@1 16.602 (16.671)	Training Prec@5 23.633 (26.242)	
2022-04-01 07:22:38,117: ============================================================
2022-04-01 07:23:23,041: time cost, forward:0.1586178234189649, backward:0.03351241130892648, data cost:0.2435043081392014 
2022-04-01 07:23:23,042: ============================================================
2022-04-01 07:23:23,042: Epoch 25/31 Batch 300/7662 eta: 6:39:20.873596	Training Loss 0.7304 (0.7348)	Training Prec@1 18.945 (16.688)	Training Prec@5 27.148 (26.251)	
2022-04-01 07:23:23,043: ============================================================
2022-04-01 07:24:07,970: time cost, forward:0.1641721432669121, backward:0.03391062227406896, data cost:0.2410313724575186 
2022-04-01 07:24:07,971: ============================================================
2022-04-01 07:24:07,971: Epoch 25/31 Batch 400/7662 eta: 6:38:37.636173	Training Loss 0.7358 (0.7348)	Training Prec@1 15.625 (16.638)	Training Prec@5 27.539 (26.143)	
2022-04-01 07:24:07,971: ============================================================
2022-04-01 07:24:49,863: time cost, forward:0.16315015762267945, backward:0.03394233105416766, data cost:0.23800762669595785 
2022-04-01 07:24:49,864: ============================================================
2022-04-01 07:24:49,864: Epoch 25/31 Batch 500/7662 eta: 6:10:59.832062	Training Loss 0.7358 (0.7348)	Training Prec@1 16.602 (16.691)	Training Prec@5 26.562 (26.217)	
2022-04-01 07:24:49,864: ============================================================
2022-04-01 07:25:33,392: time cost, forward:0.16214318705321554, backward:0.03389759652801667, data cost:0.23900831561653763 
2022-04-01 07:25:33,392: ============================================================
2022-04-01 07:25:33,392: Epoch 25/31 Batch 600/7662 eta: 6:24:45.392113	Training Loss 0.7414 (0.7348)	Training Prec@1 17.578 (16.661)	Training Prec@5 26.758 (26.237)	
2022-04-01 07:25:33,393: ============================================================
2022-04-01 07:26:14,216: time cost, forward:0.16004829891079314, backward:0.03383572725778997, data cost:0.23725232204824728 
2022-04-01 07:26:14,217: ============================================================
2022-04-01 07:26:14,217: Epoch 25/31 Batch 700/7662 eta: 6:00:10.380968	Training Loss 0.7368 (0.7363)	Training Prec@1 15.234 (16.432)	Training Prec@5 23.438 (26.010)	
2022-04-01 07:26:14,217: ============================================================
2022-04-01 07:26:58,452: time cost, forward:0.15484808473026052, backward:0.03356007550923487, data cost:0.2439642301638225 
2022-04-01 07:26:58,452: ============================================================
2022-04-01 07:26:58,452: Epoch 25/31 Batch 800/7662 eta: 6:29:31.696225	Training Loss 0.7301 (0.7359)	Training Prec@1 19.727 (16.524)	Training Prec@5 29.297 (26.109)	
2022-04-01 07:26:58,452: ============================================================
2022-04-01 07:27:39,780: time cost, forward:0.15189052768490868, backward:0.03355236286846496, data cost:0.24481872191551132 
2022-04-01 07:27:39,780: ============================================================
2022-04-01 07:27:39,780: Epoch 25/31 Batch 900/7662 eta: 6:03:14.419283	Training Loss 0.7339 (0.7356)	Training Prec@1 17.188 (16.592)	Training Prec@5 25.195 (26.208)	
2022-04-01 07:27:39,780: ============================================================
2022-04-01 07:28:22,625: time cost, forward:0.15113135071488115, backward:0.0336277341699457, data cost:0.24532622594136494 
2022-04-01 07:28:22,626: ============================================================
2022-04-01 07:28:22,626: Epoch 25/31 Batch 1000/7662 eta: 6:15:51.921174	Training Loss 0.7349 (0.7354)	Training Prec@1 15.234 (16.632)	Training Prec@5 25.586 (26.268)	
2022-04-01 07:28:22,626: ============================================================
2022-04-01 07:29:04,153: time cost, forward:0.14808580634591795, backward:0.03362122267566018, data cost:0.24695490185405256 
2022-04-01 07:29:04,153: ============================================================
2022-04-01 07:29:04,153: Epoch 25/31 Batch 1100/7662 eta: 6:03:36.366992	Training Loss 0.7334 (0.7351)	Training Prec@1 17.578 (16.712)	Training Prec@5 27.930 (26.352)	
2022-04-01 07:29:04,154: ============================================================
2022-04-01 07:29:45,604: time cost, forward:0.1459687714580698, backward:0.033536957143444734, data cost:0.2479598730976528 
2022-04-01 07:29:45,604: ============================================================
2022-04-01 07:29:45,604: Epoch 25/31 Batch 1200/7662 eta: 6:02:14.779081	Training Loss 0.7371 (0.7350)	Training Prec@1 15.430 (16.750)	Training Prec@5 23.828 (26.399)	
2022-04-01 07:29:45,604: ============================================================
2022-04-01 07:30:28,988: time cost, forward:0.14608996129201135, backward:0.033550338987390106, data cost:0.2483177069428336 
2022-04-01 07:30:28,988: ============================================================
2022-04-01 07:30:28,989: Epoch 25/31 Batch 1300/7662 eta: 6:18:25.192243	Training Loss 0.7356 (0.7347)	Training Prec@1 14.453 (16.827)	Training Prec@5 25.000 (26.500)	
2022-04-01 07:30:28,989: ============================================================
2022-04-01 07:31:10,554: time cost, forward:0.14570069994732174, backward:0.03343968514121371, data cost:0.2478782288767424 
2022-04-01 07:31:10,554: ============================================================
2022-04-01 07:31:10,554: Epoch 25/31 Batch 1400/7662 eta: 6:01:51.801205	Training Loss 0.7308 (0.7346)	Training Prec@1 18.164 (16.887)	Training Prec@5 29.883 (26.565)	
2022-04-01 07:31:10,554: ============================================================
2022-04-01 07:31:53,466: time cost, forward:0.14490843725808863, backward:0.03328393076641548, data cost:0.24897969604095194 
2022-04-01 07:31:53,466: ============================================================
2022-04-01 07:31:53,466: Epoch 25/31 Batch 1500/7662 eta: 6:12:52.217160	Training Loss 0.7360 (0.7344)	Training Prec@1 17.383 (16.945)	Training Prec@5 24.414 (26.643)	
2022-04-01 07:31:53,466: ============================================================
2022-04-01 07:32:33,912: time cost, forward:0.1435703260589943, backward:0.033219777769860515, data cost:0.24891947894785238 
2022-04-01 07:32:33,912: ============================================================
2022-04-01 07:32:33,912: Epoch 25/31 Batch 1600/7662 eta: 5:50:46.139051	Training Loss 0.7289 (0.7342)	Training Prec@1 17.383 (16.992)	Training Prec@5 27.148 (26.695)	
2022-04-01 07:32:33,913: ============================================================
2022-04-01 07:33:15,066: time cost, forward:0.14194656232302857, backward:0.03323310764485629, data cost:0.24969147555332735 
2022-04-01 07:33:15,067: ============================================================
2022-04-01 07:33:15,067: Epoch 25/31 Batch 1700/7662 eta: 5:56:13.513676	Training Loss 0.7310 (0.7340)	Training Prec@1 21.289 (17.044)	Training Prec@5 30.469 (26.753)	
2022-04-01 07:33:15,067: ============================================================
2022-04-01 07:33:56,267: time cost, forward:0.14116323796028957, backward:0.03319244877771247, data cost:0.24972870828311533 
2022-04-01 07:33:56,267: ============================================================
2022-04-01 07:33:56,267: Epoch 25/31 Batch 1800/7662 eta: 5:55:56.348759	Training Loss 0.7502 (0.7339)	Training Prec@1 19.141 (17.098)	Training Prec@5 25.977 (26.802)	
2022-04-01 07:33:56,268: ============================================================
2022-04-01 07:34:38,317: time cost, forward:0.13989658302982083, backward:0.03310386076169368, data cost:0.2509309277526952 
2022-04-01 07:34:38,318: ============================================================
2022-04-01 07:34:38,318: Epoch 25/31 Batch 1900/7662 eta: 6:02:34.838219	Training Loss 0.7340 (0.7342)	Training Prec@1 16.602 (17.096)	Training Prec@5 26.367 (26.796)	
2022-04-01 07:34:38,318: ============================================================
2022-04-01 07:35:17,761: time cost, forward:0.1384525782111408, backward:0.033003301248364356, data cost:0.25098237101586834 
2022-04-01 07:35:17,761: ============================================================
2022-04-01 07:35:17,762: Epoch 25/31 Batch 2000/7662 eta: 5:39:26.723018	Training Loss 0.7276 (0.7341)	Training Prec@1 18.164 (17.143)	Training Prec@5 28.516 (26.845)	
2022-04-01 07:35:17,762: ============================================================
2022-04-01 07:36:02,227: time cost, forward:0.13925154155751193, backward:0.033040442768876584, data cost:0.25118157714818307 
2022-04-01 07:36:02,250: ============================================================
2022-04-01 07:36:02,250: Epoch 25/31 Batch 2100/7662 eta: 6:22:07.204073	Training Loss 0.7250 (0.7339)	Training Prec@1 20.508 (17.188)	Training Prec@5 32.617 (26.911)	
2022-04-01 07:36:02,250: ============================================================
2022-04-01 07:36:43,447: time cost, forward:0.13894122868789874, backward:0.03302710540948428, data cost:0.2509534577989426 
2022-04-01 07:36:43,448: ============================================================
2022-04-01 07:36:43,448: Epoch 25/31 Batch 2200/7662 eta: 5:53:09.968579	Training Loss 0.7296 (0.7338)	Training Prec@1 19.141 (17.245)	Training Prec@5 28.516 (26.964)	
2022-04-01 07:36:43,448: ============================================================
2022-04-01 07:37:27,889: time cost, forward:0.13924846404425317, backward:0.03306143944447017, data cost:0.25152316576711714 
2022-04-01 07:37:27,889: ============================================================
2022-04-01 07:37:27,889: Epoch 25/31 Batch 2300/7662 eta: 6:20:13.841684	Training Loss 0.7277 (0.7336)	Training Prec@1 18.750 (17.300)	Training Prec@5 28.125 (27.028)	
2022-04-01 07:37:27,889: ============================================================
2022-04-01 07:38:11,592: time cost, forward:0.13945459703347643, backward:0.03310526008653661, data cost:0.25180230959597705 
2022-04-01 07:38:11,592: ============================================================
2022-04-01 07:38:11,593: Epoch 25/31 Batch 2400/7662 eta: 6:13:11.588896	Training Loss 0.7691 (0.7339)	Training Prec@1 12.500 (17.270)	Training Prec@5 21.094 (26.989)	
2022-04-01 07:38:11,593: ============================================================
2022-04-01 07:38:54,955: time cost, forward:0.13988642866204098, backward:0.03315919778403305, data cost:0.2516876314582229 
2022-04-01 07:38:54,955: ============================================================
2022-04-01 07:38:54,955: Epoch 25/31 Batch 2500/7662 eta: 6:09:33.593322	Training Loss 0.7322 (0.7340)	Training Prec@1 19.336 (17.278)	Training Prec@5 27.930 (26.997)	
2022-04-01 07:38:54,956: ============================================================
2022-04-01 07:39:38,947: time cost, forward:0.14051631415243468, backward:0.0331953089252808, data cost:0.25159188837856455 
2022-04-01 07:39:38,947: ============================================================
2022-04-01 07:39:38,947: Epoch 25/31 Batch 2600/7662 eta: 6:14:11.258848	Training Loss 0.7306 (0.7339)	Training Prec@1 20.312 (17.322)	Training Prec@5 29.102 (27.051)	
2022-04-01 07:39:38,948: ============================================================
2022-04-01 07:40:19,632: time cost, forward:0.1395933335690465, backward:0.033154198221473086, data cost:0.25184723278821597 
2022-04-01 07:40:19,632: ============================================================
2022-04-01 07:40:19,632: Epoch 25/31 Batch 2700/7662 eta: 5:45:22.888327	Training Loss 0.7309 (0.7337)	Training Prec@1 19.141 (17.366)	Training Prec@5 27.930 (27.103)	
2022-04-01 07:40:19,633: ============================================================
2022-04-01 07:41:03,551: time cost, forward:0.1397093643925794, backward:0.03317160459874825, data cost:0.2522069872085773 
2022-04-01 07:41:03,552: ============================================================
2022-04-01 07:41:03,552: Epoch 25/31 Batch 2800/7662 eta: 6:12:06.569025	Training Loss 0.7277 (0.7335)	Training Prec@1 20.703 (17.418)	Training Prec@5 28.906 (27.170)	
2022-04-01 07:41:03,552: ============================================================
2022-04-01 07:41:47,616: time cost, forward:0.14034935744641855, backward:0.03319608585387931, data cost:0.2520933037751623 
2022-04-01 07:41:47,616: ============================================================
2022-04-01 07:41:47,616: Epoch 25/31 Batch 2900/7662 eta: 6:12:35.992637	Training Loss 0.7282 (0.7334)	Training Prec@1 18.945 (17.462)	Training Prec@5 28.125 (27.227)	
2022-04-01 07:41:47,616: ============================================================
2022-04-01 07:42:32,022: time cost, forward:0.14106531554995158, backward:0.03322657436957237, data cost:0.25193136292483337 
2022-04-01 07:42:32,022: ============================================================
2022-04-01 07:42:32,022: Epoch 25/31 Batch 3000/7662 eta: 6:14:45.003159	Training Loss 0.7277 (0.7332)	Training Prec@1 17.969 (17.512)	Training Prec@5 28.320 (27.288)	
2022-04-01 07:42:32,022: ============================================================
2022-04-01 07:43:14,313: time cost, forward:0.14083709521384422, backward:0.033259819999515106, data cost:0.2520053842907069 
2022-04-01 07:43:14,337: ============================================================
2022-04-01 07:43:14,337: Epoch 25/31 Batch 3100/7662 eta: 5:56:23.846603	Training Loss 0.7312 (0.7331)	Training Prec@1 17.773 (17.557)	Training Prec@5 26.758 (27.335)	
2022-04-01 07:43:14,338: ============================================================
2022-04-01 07:43:59,184: time cost, forward:0.14073316474823924, backward:0.03326007789952862, data cost:0.25272778594221834 
2022-04-01 07:43:59,185: ============================================================
2022-04-01 07:43:59,185: Epoch 25/31 Batch 3200/7662 eta: 6:16:58.840396	Training Loss 0.7317 (0.7329)	Training Prec@1 18.359 (17.596)	Training Prec@5 25.781 (27.375)	
2022-04-01 07:43:59,185: ============================================================
2022-04-01 07:44:43,517: time cost, forward:0.14073573332477535, backward:0.03324542633870689, data cost:0.25330394071027995 
2022-04-01 07:44:43,518: ============================================================
2022-04-01 07:44:43,518: Epoch 25/31 Batch 3300/7662 eta: 6:11:55.016362	Training Loss 0.7306 (0.7328)	Training Prec@1 18.164 (17.629)	Training Prec@5 28.125 (27.420)	
2022-04-01 07:44:43,518: ============================================================
2022-04-01 07:45:26,344: time cost, forward:0.14092018710195614, backward:0.03327493584832923, data cost:0.2531124655377623 
2022-04-01 07:45:26,345: ============================================================
2022-04-01 07:45:26,345: Epoch 25/31 Batch 3400/7662 eta: 5:58:34.211670	Training Loss 0.7253 (0.7326)	Training Prec@1 18.555 (17.674)	Training Prec@5 29.883 (27.473)	
2022-04-01 07:45:26,345: ============================================================
2022-04-01 07:46:09,672: time cost, forward:0.14120970156643178, backward:0.03331971195773691, data cost:0.2529306289092852 
2022-04-01 07:46:09,672: ============================================================
2022-04-01 07:46:09,672: Epoch 25/31 Batch 3500/7662 eta: 6:02:02.074236	Training Loss 0.7298 (0.7325)	Training Prec@1 18.359 (17.722)	Training Prec@5 28.711 (27.532)	
2022-04-01 07:46:09,672: ============================================================
2022-04-01 07:46:53,172: time cost, forward:0.14159631185910543, backward:0.03333284954920051, data cost:0.25274348384839157 
2022-04-01 07:46:53,172: ============================================================
2022-04-01 07:46:53,172: Epoch 25/31 Batch 3600/7662 eta: 6:02:45.235378	Training Loss 0.8025 (0.7324)	Training Prec@1 7.422 (17.755)	Training Prec@5 14.062 (27.571)	
2022-04-01 07:46:53,172: ============================================================
2022-04-01 07:47:34,586: time cost, forward:0.14150452530039231, backward:0.033321484774310836, data cost:0.2524263541677186 
2022-04-01 07:47:34,586: ============================================================
2022-04-01 07:47:34,586: Epoch 25/31 Batch 3700/7662 eta: 5:44:40.202233	Training Loss 0.7271 (0.7333)	Training Prec@1 17.383 (17.592)	Training Prec@5 27.539 (27.333)	
2022-04-01 07:47:34,586: ============================================================
2022-04-01 07:48:19,255: time cost, forward:0.14169199311692454, backward:0.033317732980421386, data cost:0.25277251129120265 
2022-04-01 07:48:19,255: ============================================================
2022-04-01 07:48:19,255: Epoch 25/31 Batch 3800/7662 eta: 6:11:00.695231	Training Loss 0.7250 (0.7331)	Training Prec@1 18.164 (17.642)	Training Prec@5 29.688 (27.395)	
2022-04-01 07:48:19,255: ============================================================
2022-04-01 07:49:02,961: time cost, forward:0.14182892369135552, backward:0.03332541477499818, data cost:0.2528288113700943 
2022-04-01 07:49:02,961: ============================================================
2022-04-01 07:49:02,961: Epoch 25/31 Batch 3900/7662 eta: 6:02:17.336853	Training Loss 0.7254 (0.7330)	Training Prec@1 21.289 (17.690)	Training Prec@5 30.859 (27.448)	
2022-04-01 07:49:02,962: ============================================================
2022-04-01 07:49:46,380: time cost, forward:0.1418821405666892, backward:0.033327389967742635, data cost:0.25294791766779817 
2022-04-01 07:49:46,380: ============================================================
2022-04-01 07:49:46,380: Epoch 25/31 Batch 4000/7662 eta: 5:59:10.825346	Training Loss 0.7280 (0.7328)	Training Prec@1 17.383 (17.750)	Training Prec@5 27.344 (27.515)	
2022-04-01 07:49:46,380: ============================================================
2022-04-01 07:50:28,980: time cost, forward:0.14175975389613207, backward:0.03328776900493159, data cost:0.2530498304550867 
2022-04-01 07:50:28,990: ============================================================
2022-04-01 07:50:28,991: Epoch 25/31 Batch 4100/7662 eta: 5:51:47.100948	Training Loss 0.7219 (0.7327)	Training Prec@1 23.438 (17.798)	Training Prec@5 32.812 (27.568)	
2022-04-01 07:50:28,991: ============================================================
2022-04-01 07:51:12,733: time cost, forward:0.14156286181027222, backward:0.033234858518556405, data cost:0.25350961091263463 
2022-04-01 07:51:12,733: ============================================================
2022-04-01 07:51:12,733: Epoch 25/31 Batch 4200/7662 eta: 6:00:24.252472	Training Loss 0.7222 (0.7325)	Training Prec@1 21.094 (17.841)	Training Prec@5 30.664 (27.626)	
2022-04-01 07:51:12,734: ============================================================
2022-04-01 07:51:54,641: time cost, forward:0.14160454913776235, backward:0.033209148743286274, data cost:0.253267743915257 
2022-04-01 07:51:54,642: ============================================================
2022-04-01 07:51:54,642: Epoch 25/31 Batch 4300/7662 eta: 5:44:35.554925	Training Loss 0.7253 (0.7324)	Training Prec@1 18.164 (17.891)	Training Prec@5 29.102 (27.681)	
2022-04-01 07:51:54,642: ============================================================
2022-04-01 07:52:36,336: time cost, forward:0.1408275411085097, backward:0.033131007146607695, data cost:0.25385887261330203 
2022-04-01 07:52:36,336: ============================================================
2022-04-01 07:52:36,337: Epoch 25/31 Batch 4400/7662 eta: 5:42:08.437665	Training Loss 0.7265 (0.7322)	Training Prec@1 20.312 (17.938)	Training Prec@5 29.688 (27.736)	
2022-04-01 07:52:36,337: ============================================================
2022-04-01 07:53:16,754: time cost, forward:0.14006137402753455, backward:0.033093172487986836, data cost:0.2541290230421417 
2022-04-01 07:53:16,755: ============================================================
2022-04-01 07:53:16,755: Epoch 25/31 Batch 4500/7662 eta: 5:30:59.447902	Training Loss 0.7262 (0.7321)	Training Prec@1 21.875 (17.993)	Training Prec@5 30.273 (27.799)	
2022-04-01 07:53:16,755: ============================================================
2022-04-01 07:53:57,438: time cost, forward:0.1393277339246849, backward:0.03303722828257263, data cost:0.2544689299257249 
2022-04-01 07:53:57,439: ============================================================
2022-04-01 07:53:57,439: Epoch 25/31 Batch 4600/7662 eta: 5:32:29.374623	Training Loss 0.7525 (0.7322)	Training Prec@1 15.234 (17.995)	Training Prec@5 25.000 (27.803)	
2022-04-01 07:53:57,439: ============================================================
2022-04-01 07:54:38,301: time cost, forward:0.1386260694076366, backward:0.032980811268655666, data cost:0.25483994109500185 
2022-04-01 07:54:38,302: ============================================================
2022-04-01 07:54:38,302: Epoch 25/31 Batch 4700/7662 eta: 5:33:16.362211	Training Loss 0.7267 (0.7321)	Training Prec@1 19.531 (18.038)	Training Prec@5 29.688 (27.849)	
2022-04-01 07:54:38,302: ============================================================
2022-04-01 07:55:18,761: time cost, forward:0.13794996878037133, backward:0.03294225130560101, data cost:0.255083321382364 
2022-04-01 07:55:18,761: ============================================================
2022-04-01 07:55:18,762: Epoch 25/31 Batch 4800/7662 eta: 5:29:18.543100	Training Loss 0.7239 (0.7320)	Training Prec@1 19.141 (18.081)	Training Prec@5 30.859 (27.903)	
2022-04-01 07:55:18,762: ============================================================
2022-04-01 07:55:59,362: time cost, forward:0.13731902091934817, backward:0.03291178635369274, data cost:0.2553278926344009 
2022-04-01 07:55:59,363: ============================================================
2022-04-01 07:55:59,363: Epoch 25/31 Batch 4900/7662 eta: 5:29:46.980811	Training Loss 0.7234 (0.7319)	Training Prec@1 20.898 (18.122)	Training Prec@5 31.250 (27.952)	
2022-04-01 07:55:59,363: ============================================================
2022-04-01 07:56:41,370: time cost, forward:0.13671667334031382, backward:0.03290130410534927, data cost:0.2558371571927911 
2022-04-01 07:56:41,370: ============================================================
2022-04-01 07:56:41,371: Epoch 25/31 Batch 5000/7662 eta: 5:40:30.443139	Training Loss 0.7226 (0.7317)	Training Prec@1 19.336 (18.177)	Training Prec@5 30.078 (28.012)	
2022-04-01 07:56:41,371: ============================================================
2022-04-01 07:57:21,372: time cost, forward:0.13614855370911505, backward:0.032898862681264476, data cost:0.2559009162228022 
2022-04-01 07:57:21,372: ============================================================
2022-04-01 07:57:21,373: Epoch 25/31 Batch 5100/7662 eta: 5:23:34.990417	Training Loss 0.7235 (0.7316)	Training Prec@1 19.336 (18.223)	Training Prec@5 30.859 (28.067)	
2022-04-01 07:57:21,373: ============================================================
2022-04-01 07:58:01,234: time cost, forward:0.13560018009303923, backward:0.03290658695098413, data cost:0.25592724303370096 
2022-04-01 07:58:01,235: ============================================================
2022-04-01 07:58:01,235: Epoch 25/31 Batch 5200/7662 eta: 5:21:47.302887	Training Loss 0.7222 (0.7314)	Training Prec@1 23.047 (18.270)	Training Prec@5 31.250 (28.121)	
2022-04-01 07:58:01,235: ============================================================
2022-04-01 07:58:41,847: time cost, forward:0.13506711129985635, backward:0.03290490209662615, data cost:0.25609898432220324 
2022-04-01 07:58:41,847: ============================================================
2022-04-01 07:58:41,847: Epoch 25/31 Batch 5300/7662 eta: 5:27:10.066257	Training Loss 0.7236 (0.7319)	Training Prec@1 20.117 (18.194)	Training Prec@5 32.617 (28.016)	
2022-04-01 07:58:41,848: ============================================================
2022-04-01 07:59:22,205: time cost, forward:0.1345643079110838, backward:0.03292148814066226, data cost:0.25619424548628683 
2022-04-01 07:59:22,205: ============================================================
2022-04-01 07:59:22,205: Epoch 25/31 Batch 5400/7662 eta: 5:24:26.590123	Training Loss 0.7223 (0.7317)	Training Prec@1 20.312 (18.241)	Training Prec@5 30.664 (28.073)	
2022-04-01 07:59:22,206: ============================================================
2022-04-01 08:00:02,282: time cost, forward:0.13408009362970835, backward:0.032927198526230175, data cost:0.2562592855083398 
2022-04-01 08:00:02,283: ============================================================
2022-04-01 08:00:02,283: Epoch 25/31 Batch 5500/7662 eta: 5:21:31.472114	Training Loss 0.7193 (0.7316)	Training Prec@1 23.633 (18.287)	Training Prec@5 31.836 (28.128)	
2022-04-01 08:00:02,283: ============================================================
2022-04-01 08:00:42,853: time cost, forward:0.13362302514437502, backward:0.032915907217830734, data cost:0.25641153786603543 
2022-04-01 08:00:42,853: ============================================================
2022-04-01 08:00:42,853: Epoch 25/31 Batch 5600/7662 eta: 5:24:48.005612	Training Loss 0.7241 (0.7314)	Training Prec@1 18.945 (18.330)	Training Prec@5 29.883 (28.177)	
2022-04-01 08:00:42,854: ============================================================
2022-04-01 08:01:24,648: time cost, forward:0.13319251867402412, backward:0.03288323834478322, data cost:0.2567824643418378 
2022-04-01 08:01:24,648: ============================================================
2022-04-01 08:01:24,648: Epoch 25/31 Batch 5700/7662 eta: 5:33:54.277058	Training Loss 0.7240 (0.7313)	Training Prec@1 21.875 (18.371)	Training Prec@5 33.008 (28.228)	
2022-04-01 08:01:24,648: ============================================================
2022-04-01 08:02:04,490: time cost, forward:0.13279380784361172, backward:0.03289655862871707, data cost:0.2567329834732316 
2022-04-01 08:02:04,491: ============================================================
2022-04-01 08:02:04,491: Epoch 25/31 Batch 5800/7662 eta: 5:17:38.739923	Training Loss 0.7205 (0.7311)	Training Prec@1 23.828 (18.422)	Training Prec@5 33.594 (28.286)	
2022-04-01 08:02:04,491: ============================================================
2022-04-01 08:02:45,222: time cost, forward:0.13251635951093746, backward:0.03293629657779635, data cost:0.25671457039903717 
2022-04-01 08:02:45,222: ============================================================
2022-04-01 08:02:45,223: Epoch 25/31 Batch 5900/7662 eta: 5:24:03.326020	Training Loss 0.7301 (0.7312)	Training Prec@1 20.703 (18.444)	Training Prec@5 30.273 (28.313)	
2022-04-01 08:02:45,223: ============================================================
2022-04-01 08:03:28,025: time cost, forward:0.13242857455014984, backward:0.0329554406061314, data cost:0.2568590521395137 
2022-04-01 08:03:28,026: ============================================================
2022-04-01 08:03:28,026: Epoch 25/31 Batch 6000/7662 eta: 5:39:49.223801	Training Loss 0.7255 (0.7311)	Training Prec@1 19.727 (18.483)	Training Prec@5 30.273 (28.358)	
2022-04-01 08:03:28,026: ============================================================
2022-04-01 08:04:07,879: time cost, forward:0.13206758560128126, backward:0.032994387168965585, data cost:0.256793100104056 
2022-04-01 08:04:07,879: ============================================================
2022-04-01 08:04:07,879: Epoch 25/31 Batch 6100/7662 eta: 5:15:44.367179	Training Loss 0.7216 (0.7310)	Training Prec@1 22.656 (18.526)	Training Prec@5 33.203 (28.407)	
2022-04-01 08:04:07,879: ============================================================
2022-04-01 08:04:49,013: time cost, forward:0.13169152799354944, backward:0.03302898793898199, data cost:0.25696295229614424 
2022-04-01 08:04:49,014: ============================================================
2022-04-01 08:04:49,014: Epoch 25/31 Batch 6200/7662 eta: 5:25:12.294848	Training Loss 0.7217 (0.7309)	Training Prec@1 21.289 (18.568)	Training Prec@5 32.617 (28.457)	
2022-04-01 08:04:49,014: ============================================================
2022-04-01 08:05:29,797: time cost, forward:0.13134083052933604, backward:0.033053968610943715, data cost:0.2570546583668318 
2022-04-01 08:05:29,797: ============================================================
2022-04-01 08:05:29,797: Epoch 25/31 Batch 6300/7662 eta: 5:21:44.745902	Training Loss 0.7227 (0.7307)	Training Prec@1 24.023 (18.621)	Training Prec@5 32.617 (28.513)	
2022-04-01 08:05:29,797: ============================================================
2022-04-01 08:06:10,239: time cost, forward:0.13112698750377427, backward:0.03306614490091139, data cost:0.25697293529698284 
2022-04-01 08:06:10,239: ============================================================
2022-04-01 08:06:10,240: Epoch 25/31 Batch 6400/7662 eta: 5:18:22.949724	Training Loss 0.7211 (0.7306)	Training Prec@1 22.070 (18.668)	Training Prec@5 31.250 (28.567)	
2022-04-01 08:06:10,240: ============================================================
2022-04-01 08:06:51,714: time cost, forward:0.13091652227156086, backward:0.033082525076031925, data cost:0.25706432287207676 
2022-04-01 08:06:51,715: ============================================================
2022-04-01 08:06:51,715: Epoch 25/31 Batch 6500/7662 eta: 5:25:49.402805	Training Loss 0.7157 (0.7304)	Training Prec@1 23.828 (18.715)	Training Prec@5 34.180 (28.623)	
2022-04-01 08:06:51,715: ============================================================
2022-04-01 08:07:31,782: time cost, forward:0.13061883088620727, backward:0.03309154629725401, data cost:0.25704811793201743 
2022-04-01 08:07:31,783: ============================================================
2022-04-01 08:07:31,783: Epoch 25/31 Batch 6600/7662 eta: 5:14:05.942233	Training Loss 0.7210 (0.7303)	Training Prec@1 20.117 (18.764)	Training Prec@5 32.031 (28.680)	
2022-04-01 08:07:31,783: ============================================================
2022-04-01 08:08:11,362: time cost, forward:0.13032040380331844, backward:0.03311669241049198, data cost:0.25694404842070917 
2022-04-01 08:08:11,362: ============================================================
2022-04-01 08:08:11,362: Epoch 25/31 Batch 6700/7662 eta: 5:09:36.709140	Training Loss 0.7209 (0.7301)	Training Prec@1 22.461 (18.807)	Training Prec@5 33.789 (28.731)	
2022-04-01 08:08:11,363: ============================================================
2022-04-01 08:08:53,486: time cost, forward:0.13000768439737131, backward:0.03313803781497336, data cost:0.25719287322187867 
2022-04-01 08:08:53,487: ============================================================
2022-04-01 08:08:53,487: Epoch 25/31 Batch 6800/7662 eta: 5:28:48.993066	Training Loss 0.7164 (0.7300)	Training Prec@1 23.828 (18.854)	Training Prec@5 34.570 (28.787)	
2022-04-01 08:08:53,487: ============================================================
2022-04-01 08:09:33,025: time cost, forward:0.1297372745973405, backward:0.03314139884802755, data cost:0.25714178575365626 
2022-04-01 08:09:33,026: ============================================================
2022-04-01 08:09:33,026: Epoch 25/31 Batch 6900/7662 eta: 5:07:58.464532	Training Loss 0.7201 (0.7299)	Training Prec@1 23.438 (18.901)	Training Prec@5 34.766 (28.843)	
2022-04-01 08:09:33,026: ============================================================
2022-04-01 08:10:13,684: time cost, forward:0.12945780251294925, backward:0.033156778492541256, data cost:0.2572150669501226 
2022-04-01 08:10:13,684: ============================================================
2022-04-01 08:10:13,685: Epoch 25/31 Batch 7000/7662 eta: 5:16:01.217206	Training Loss 0.7256 (0.7303)	Training Prec@1 22.266 (18.831)	Training Prec@5 33.203 (28.738)	
2022-04-01 08:10:13,685: ============================================================
2022-04-01 08:10:54,341: time cost, forward:0.12920006010998872, backward:0.03316797748688729, data cost:0.2572629417159353 
2022-04-01 08:10:54,341: ============================================================
2022-04-01 08:10:54,342: Epoch 25/31 Batch 7100/7662 eta: 5:15:19.714455	Training Loss 0.7189 (0.7301)	Training Prec@1 24.414 (18.876)	Training Prec@5 33.594 (28.792)	
2022-04-01 08:10:54,342: ============================================================
2022-04-01 08:11:34,168: time cost, forward:0.12893803147147606, backward:0.033190362402789705, data cost:0.2572034517416177 
2022-04-01 08:11:34,168: ============================================================
2022-04-01 08:11:34,168: Epoch 25/31 Batch 7200/7662 eta: 5:08:13.586919	Training Loss 0.7153 (0.7300)	Training Prec@1 25.195 (18.922)	Training Prec@5 35.352 (28.846)	
2022-04-01 08:11:34,168: ============================================================
2022-04-01 08:12:15,958: time cost, forward:0.12869097249346867, backward:0.03321639066331108, data cost:0.25740808143176713 
2022-04-01 08:12:15,959: ============================================================
2022-04-01 08:12:15,959: Epoch 25/31 Batch 7300/7662 eta: 5:22:43.575888	Training Loss 0.7233 (0.7299)	Training Prec@1 21.680 (18.972)	Training Prec@5 30.078 (28.905)	
2022-04-01 08:12:15,959: ============================================================
2022-04-01 08:12:56,583: time cost, forward:0.12843177492255406, backward:0.033252790274209534, data cost:0.25744437243361973 
2022-04-01 08:12:56,584: ============================================================
2022-04-01 08:12:56,584: Epoch 25/31 Batch 7400/7662 eta: 5:13:02.969301	Training Loss 0.7179 (0.7297)	Training Prec@1 20.898 (19.015)	Training Prec@5 31.445 (28.954)	
2022-04-01 08:12:56,584: ============================================================
2022-04-01 08:13:36,848: time cost, forward:0.12817938783388486, backward:0.0332936537330954, data cost:0.2574297809206592 
2022-04-01 08:13:36,849: ============================================================
2022-04-01 08:13:36,849: Epoch 25/31 Batch 7500/7662 eta: 5:09:36.241409	Training Loss 0.7132 (0.7297)	Training Prec@1 22.266 (19.042)	Training Prec@5 34.766 (28.987)	
2022-04-01 08:13:36,849: ============================================================
2022-04-01 08:14:16,488: time cost, forward:0.12793470834615842, backward:0.033321971029870716, data cost:0.2573379181391127 
2022-04-01 08:14:16,488: ============================================================
2022-04-01 08:14:16,488: Epoch 25/31 Batch 7600/7662 eta: 5:04:08.132902	Training Loss 0.7193 (0.7295)	Training Prec@1 22.461 (19.090)	Training Prec@5 32.812 (29.041)	
2022-04-01 08:14:16,489: ============================================================
2022-04-01 08:14:43,677: Epoch: 25/31 eta: 5:03:43.159895	Training Loss 0.7160 (0.7295)	Training Prec@1 22.461 (19.122)	Training Prec@5 34.180 (29.076)
2022-04-01 08:14:43,678: ============================================================
2022-04-01 08:14:43,798: Save Checkpoint...
2022-04-01 08:14:43,818: ============================================================
2022-04-01 08:14:46,363: Save done!
2022-04-01 08:14:46,363: ============================================================
2022-04-01 08:15:26,692: time cost, forward:0.11851091577549173, backward:0.033051839982620394, data cost:0.2524151320409293 
2022-04-01 08:15:26,692: ============================================================
2022-04-01 08:15:26,693: Epoch 26/31 Batch 100/7662 eta: 5:08:00.858436	Training Loss 0.7073 (0.7143)	Training Prec@1 25.586 (24.392)	Training Prec@5 36.914 (35.233)	
2022-04-01 08:15:26,693: ============================================================
2022-04-01 08:16:08,253: time cost, forward:0.11642940200153906, backward:0.03363103243573826, data cost:0.2597282424044968 
2022-04-01 08:16:08,254: ============================================================
2022-04-01 08:16:08,254: Epoch 26/31 Batch 200/7662 eta: 5:17:03.948375	Training Loss 0.7210 (0.7153)	Training Prec@1 21.680 (24.400)	Training Prec@5 32.617 (35.212)	
2022-04-01 08:16:08,254: ============================================================
2022-04-01 08:16:49,153: time cost, forward:0.11488156254873627, backward:0.034042175796917054, data cost:0.26043507008249545 
2022-04-01 08:16:49,153: ============================================================
2022-04-01 08:16:49,153: Epoch 26/31 Batch 300/7662 eta: 5:11:19.823214	Training Loss 0.7137 (0.7150)	Training Prec@1 25.391 (24.397)	Training Prec@5 34.180 (35.182)	
2022-04-01 08:16:49,153: ============================================================
2022-04-01 08:17:28,473: time cost, forward:0.11379639905198176, backward:0.03397165862539956, data cost:0.2574339540381181 
2022-04-01 08:17:28,474: ============================================================
2022-04-01 08:17:28,474: Epoch 26/31 Batch 400/7662 eta: 4:58:39.648874	Training Loss 0.7125 (0.7148)	Training Prec@1 23.242 (24.410)	Training Prec@5 38.086 (35.197)	
2022-04-01 08:17:28,474: ============================================================
2022-04-01 08:18:07,786: time cost, forward:0.1135861338498836, backward:0.033998153013791256, data cost:0.2551017667583091 
2022-04-01 08:18:07,787: ============================================================
2022-04-01 08:18:07,787: Epoch 26/31 Batch 500/7662 eta: 4:57:56.670483	Training Loss 0.7191 (0.7147)	Training Prec@1 22.852 (24.355)	Training Prec@5 33.789 (35.175)	
2022-04-01 08:18:07,787: ============================================================
2022-04-01 08:18:49,283: time cost, forward:0.11522835085109398, backward:0.0341098423991259, data cost:0.2553079331259497 
2022-04-01 08:18:49,283: ============================================================
2022-04-01 08:18:49,284: Epoch 26/31 Batch 600/7662 eta: 5:13:48.398967	Training Loss 0.7542 (0.7175)	Training Prec@1 16.992 (23.891)	Training Prec@5 26.953 (34.564)	
2022-04-01 08:18:49,284: ============================================================
2022-04-01 08:19:29,503: time cost, forward:0.11466761549484406, backward:0.03372854497470228, data cost:0.2550382228709427 
2022-04-01 08:19:29,504: ============================================================
2022-04-01 08:19:29,504: Epoch 26/31 Batch 700/7662 eta: 5:03:29.053946	Training Loss 0.7160 (0.7174)	Training Prec@1 23.242 (23.896)	Training Prec@5 33.203 (34.586)	
2022-04-01 08:19:29,504: ============================================================
2022-04-01 08:20:09,228: time cost, forward:0.1144501810825811, backward:0.03320940803079044, data cost:0.25569669803480927 
2022-04-01 08:20:09,229: ============================================================
2022-04-01 08:20:09,229: Epoch 26/31 Batch 800/7662 eta: 4:59:04.831073	Training Loss 0.7095 (0.7168)	Training Prec@1 26.172 (24.004)	Training Prec@5 38.086 (34.706)	
2022-04-01 08:20:09,229: ============================================================
2022-04-01 08:20:51,238: time cost, forward:0.11415979992163194, backward:0.03331779531960493, data cost:0.2576481221912965 
2022-04-01 08:20:51,239: ============================================================
2022-04-01 08:20:51,239: Epoch 26/31 Batch 900/7662 eta: 5:15:35.179331	Training Loss 0.7158 (0.7167)	Training Prec@1 23.242 (24.056)	Training Prec@5 33.203 (34.775)	
2022-04-01 08:20:51,239: ============================================================
2022-04-01 08:21:30,811: time cost, forward:0.11398397623239695, backward:0.03348173656024494, data cost:0.25676655888676764 
2022-04-01 08:21:30,811: ============================================================
2022-04-01 08:21:30,811: Epoch 26/31 Batch 1000/7662 eta: 4:56:36.822903	Training Loss 0.7103 (0.7162)	Training Prec@1 24.805 (24.143)	Training Prec@5 35.938 (34.881)	
2022-04-01 08:21:30,811: ============================================================
2022-04-01 08:22:10,612: time cost, forward:0.11365671826016371, backward:0.033510526165949205, data cost:0.2564047113996511 
2022-04-01 08:22:10,612: ============================================================
2022-04-01 08:22:10,612: Epoch 26/31 Batch 1100/7662 eta: 4:57:39.987623	Training Loss 0.7212 (0.7159)	Training Prec@1 21.289 (24.235)	Training Prec@5 33.398 (34.969)	
2022-04-01 08:22:10,613: ============================================================
2022-04-01 08:22:51,502: time cost, forward:0.11340156866173828, backward:0.0336297210601094, data cost:0.2569605759325576 
2022-04-01 08:22:51,502: ============================================================
2022-04-01 08:22:51,502: Epoch 26/31 Batch 1200/7662 eta: 5:05:07.654128	Training Loss 0.7059 (0.7156)	Training Prec@1 27.148 (24.302)	Training Prec@5 39.062 (35.049)	
2022-04-01 08:22:51,502: ============================================================
2022-04-01 08:23:32,364: time cost, forward:0.11341014286478819, backward:0.03355302417893149, data cost:0.2573773851754392 
2022-04-01 08:23:32,364: ============================================================
2022-04-01 08:23:32,364: Epoch 26/31 Batch 1300/7662 eta: 5:04:14.360923	Training Loss 0.7756 (0.7156)	Training Prec@1 14.258 (24.350)	Training Prec@5 23.242 (35.088)	
2022-04-01 08:23:32,365: ============================================================
2022-04-01 08:24:12,352: time cost, forward:0.1151063917704017, backward:0.03373190110883515, data cost:0.2551659232297056 
2022-04-01 08:24:12,352: ============================================================
2022-04-01 08:24:12,352: Epoch 26/31 Batch 1400/7662 eta: 4:57:03.733136	Training Loss 0.7070 (0.7157)	Training Prec@1 28.125 (24.340)	Training Prec@5 36.914 (35.062)	
2022-04-01 08:24:12,352: ============================================================
2022-04-01 08:24:53,662: time cost, forward:0.11501789920086698, backward:0.033794775575379514, data cost:0.25574114069770065 
2022-04-01 08:24:53,662: ============================================================
2022-04-01 08:24:53,663: Epoch 26/31 Batch 1500/7662 eta: 5:06:12.054780	Training Loss 0.7149 (0.7155)	Training Prec@1 23.438 (24.406)	Training Prec@5 33.594 (35.114)	
2022-04-01 08:24:53,663: ============================================================
2022-04-01 08:25:33,637: time cost, forward:0.11481732096502079, backward:0.03384141358380917, data cost:0.25556883847735834 
2022-04-01 08:25:33,638: ============================================================
2022-04-01 08:25:33,638: Epoch 26/31 Batch 1600/7662 eta: 4:55:38.201181	Training Loss 0.7126 (0.7152)	Training Prec@1 28.516 (24.495)	Training Prec@5 36.914 (35.197)	
2022-04-01 08:25:33,638: ============================================================
2022-04-01 08:26:12,254: time cost, forward:0.11467297474309372, backward:0.03391770196704741, data cost:0.2545270442681989 
2022-04-01 08:26:12,254: ============================================================
2022-04-01 08:26:12,255: Epoch 26/31 Batch 1700/7662 eta: 4:44:56.803017	Training Loss 0.7071 (0.7156)	Training Prec@1 26.562 (24.482)	Training Prec@5 38.281 (35.178)	
2022-04-01 08:26:12,255: ============================================================
2022-04-01 08:26:52,837: time cost, forward:0.11457660239295472, backward:0.03390112037192192, data cost:0.2547545577500382 
2022-04-01 08:26:52,838: ============================================================
2022-04-01 08:26:52,838: Epoch 26/31 Batch 1800/7662 eta: 4:58:46.711715	Training Loss 0.7080 (0.7153)	Training Prec@1 27.148 (24.532)	Training Prec@5 39.844 (35.246)	
2022-04-01 08:26:52,838: ============================================================
2022-04-01 08:27:32,858: time cost, forward:0.11446240740490311, backward:0.03396923947547724, data cost:0.25463109973105963 
2022-04-01 08:27:32,858: ============================================================
2022-04-01 08:27:32,859: Epoch 26/31 Batch 1900/7662 eta: 4:53:58.357357	Training Loss 0.7096 (0.7151)	Training Prec@1 26.172 (24.585)	Training Prec@5 35.938 (35.301)	
2022-04-01 08:27:32,859: ============================================================
2022-04-01 08:28:12,564: time cost, forward:0.11440271326993452, backward:0.034023524404108794, data cost:0.25433152267013326 
2022-04-01 08:28:12,565: ============================================================
2022-04-01 08:28:12,565: Epoch 26/31 Batch 2000/7662 eta: 4:51:00.166946	Training Loss 0.7145 (0.7149)	Training Prec@1 23.047 (24.627)	Training Prec@5 34.570 (35.356)	
2022-04-01 08:28:12,565: ============================================================
2022-04-01 08:28:53,773: time cost, forward:0.11432469283018071, backward:0.03403987402913683, data cost:0.2548399093095435 
2022-04-01 08:28:53,773: ============================================================
2022-04-01 08:28:53,773: Epoch 26/31 Batch 2100/7662 eta: 5:01:19.305898	Training Loss 0.7399 (0.7148)	Training Prec@1 21.484 (24.689)	Training Prec@5 32.031 (35.415)	
2022-04-01 08:28:53,774: ============================================================
2022-04-01 08:29:35,492: time cost, forward:0.11499356280244877, backward:0.03405306652601658, data cost:0.2547565505091523 
2022-04-01 08:29:35,493: ============================================================
2022-04-01 08:29:35,493: Epoch 26/31 Batch 2200/7662 eta: 5:04:21.934789	Training Loss 0.7057 (0.7150)	Training Prec@1 29.492 (24.684)	Training Prec@5 39.453 (35.416)	
2022-04-01 08:29:35,493: ============================================================
2022-04-01 08:30:16,415: time cost, forward:0.11552260926932342, backward:0.034170371338096375, data cost:0.2543194192344596 
2022-04-01 08:30:16,415: ============================================================
2022-04-01 08:30:16,416: Epoch 26/31 Batch 2300/7662 eta: 4:57:52.090251	Training Loss 0.7093 (0.7148)	Training Prec@1 25.000 (24.733)	Training Prec@5 37.891 (35.475)	
2022-04-01 08:30:16,416: ============================================================
2022-04-01 08:30:58,172: time cost, forward:0.11550224875847266, backward:0.03421127045835341, data cost:0.2548377327046428 
2022-04-01 08:30:58,172: ============================================================
2022-04-01 08:30:58,172: Epoch 26/31 Batch 2400/7662 eta: 5:03:14.701864	Training Loss 0.7122 (0.7146)	Training Prec@1 24.219 (24.789)	Training Prec@5 34.375 (35.542)	
2022-04-01 08:30:58,173: ============================================================
2022-04-01 08:31:37,362: time cost, forward:0.11534634920633903, backward:0.034254071616134245, data cost:0.25445551135722233 
2022-04-01 08:31:37,363: ============================================================
2022-04-01 08:31:37,363: Epoch 26/31 Batch 2500/7662 eta: 4:43:57.356762	Training Loss 0.7208 (0.7144)	Training Prec@1 22.070 (24.854)	Training Prec@5 32.812 (35.610)	
2022-04-01 08:31:37,363: ============================================================
2022-04-01 08:32:18,513: time cost, forward:0.11518538709143668, backward:0.03436471527014479, data cost:0.2547829300681184 
2022-04-01 08:32:18,514: ============================================================
2022-04-01 08:32:18,514: Epoch 26/31 Batch 2600/7662 eta: 4:57:28.360884	Training Loss 0.7337 (0.7148)	Training Prec@1 22.461 (24.800)	Training Prec@5 31.836 (35.549)	
2022-04-01 08:32:18,514: ============================================================
2022-04-01 08:32:57,745: time cost, forward:0.11524484209680434, backward:0.03440728926049113, data cost:0.25420967946895273 
2022-04-01 08:32:57,745: ============================================================
2022-04-01 08:32:57,746: Epoch 26/31 Batch 2700/7662 eta: 4:42:56.704526	Training Loss 0.7029 (0.7147)	Training Prec@1 27.734 (24.822)	Training Prec@5 39.258 (35.575)	
2022-04-01 08:32:57,746: ============================================================
2022-04-01 08:33:38,803: time cost, forward:0.11545298703443412, backward:0.03439430587416932, data cost:0.25424711096921365 
2022-04-01 08:33:38,804: ============================================================
2022-04-01 08:33:38,804: Epoch 26/31 Batch 2800/7662 eta: 4:55:26.250251	Training Loss 0.7110 (0.7145)	Training Prec@1 27.344 (24.881)	Training Prec@5 36.914 (35.642)	
2022-04-01 08:33:38,804: ============================================================
2022-04-01 08:34:20,041: time cost, forward:0.11562368507095763, backward:0.03441383452940168, data cost:0.2543253104166147 
2022-04-01 08:34:20,042: ============================================================
2022-04-01 08:34:20,043: Epoch 26/31 Batch 2900/7662 eta: 4:56:02.548452	Training Loss 0.7088 (0.7142)	Training Prec@1 26.758 (24.946)	Training Prec@5 35.938 (35.712)	
2022-04-01 08:34:20,043: ============================================================
2022-04-01 08:34:59,317: time cost, forward:0.11568378050671534, backward:0.03440307656619182, data cost:0.25386766792734927 
2022-04-01 08:34:59,318: ============================================================
2022-04-01 08:34:59,318: Epoch 26/31 Batch 3000/7662 eta: 4:41:17.839022	Training Loss 0.7156 (0.7143)	Training Prec@1 24.609 (24.963)	Training Prec@5 35.156 (35.730)	
2022-04-01 08:34:59,318: ============================================================
2022-04-01 08:35:40,362: time cost, forward:0.11607774906521576, backward:0.0344157295867142, data cost:0.25364058738602635 
2022-04-01 08:35:40,363: ============================================================
2022-04-01 08:35:40,363: Epoch 26/31 Batch 3100/7662 eta: 4:53:17.206017	Training Loss 0.7105 (0.7141)	Training Prec@1 25.781 (25.019)	Training Prec@5 34.570 (35.787)	
2022-04-01 08:35:40,363: ============================================================
2022-04-01 08:36:20,454: time cost, forward:0.11595855820510641, backward:0.03440682490790922, data cost:0.25365886072622085 
2022-04-01 08:36:20,454: ============================================================
2022-04-01 08:36:20,455: Epoch 26/31 Batch 3200/7662 eta: 4:45:48.463258	Training Loss 0.7071 (0.7139)	Training Prec@1 26.953 (25.078)	Training Prec@5 38.086 (35.845)	
2022-04-01 08:36:20,455: ============================================================
2022-04-01 08:36:59,972: time cost, forward:0.11597559798229966, backward:0.03441998220711413, data cost:0.25334289826274314 
2022-04-01 08:36:59,972: ============================================================
2022-04-01 08:36:59,973: Epoch 26/31 Batch 3300/7662 eta: 4:41:03.484959	Training Loss 0.7062 (0.7137)	Training Prec@1 27.344 (25.130)	Training Prec@5 37.695 (35.898)	
2022-04-01 08:36:59,973: ============================================================
2022-04-01 08:37:39,735: time cost, forward:0.11587677025801997, backward:0.034433630432371326, data cost:0.2532229486652317 
2022-04-01 08:37:39,736: ============================================================
2022-04-01 08:37:39,736: Epoch 26/31 Batch 3400/7662 eta: 4:42:08.484191	Training Loss 0.7172 (0.7139)	Training Prec@1 24.805 (25.134)	Training Prec@5 34.180 (35.894)	
2022-04-01 08:37:39,736: ============================================================
2022-04-01 08:38:20,488: time cost, forward:0.1158235931641785, backward:0.034426484321927846, data cost:0.2533529609501379 
2022-04-01 08:38:20,488: ============================================================
2022-04-01 08:38:20,489: Epoch 26/31 Batch 3500/7662 eta: 4:48:28.853298	Training Loss 0.7042 (0.7138)	Training Prec@1 26.953 (25.177)	Training Prec@5 39.453 (35.941)	
2022-04-01 08:38:20,489: ============================================================
2022-04-01 08:38:59,935: time cost, forward:0.11575344629703743, backward:0.03444807520837511, data cost:0.25319457769592657 
2022-04-01 08:38:59,935: ============================================================
2022-04-01 08:38:59,935: Epoch 26/31 Batch 3600/7662 eta: 4:38:34.776700	Training Loss 0.7050 (0.7136)	Training Prec@1 26.953 (25.230)	Training Prec@5 38.867 (35.997)	
2022-04-01 08:38:59,936: ============================================================
2022-04-01 08:39:40,253: time cost, forward:0.11564826552820838, backward:0.03445730501975714, data cost:0.2532588830346125 
2022-04-01 08:39:40,254: ============================================================
2022-04-01 08:39:40,254: Epoch 26/31 Batch 3700/7662 eta: 4:44:03.894754	Training Loss 0.7128 (0.7135)	Training Prec@1 26.758 (25.281)	Training Prec@5 37.695 (36.051)	
2022-04-01 08:39:40,254: ============================================================
2022-04-01 08:40:19,597: time cost, forward:0.11559782043260221, backward:0.03447713416386479, data cost:0.25302760856469764 
2022-04-01 08:40:19,598: ============================================================
2022-04-01 08:40:19,598: Epoch 26/31 Batch 3800/7662 eta: 4:36:32.459898	Training Loss 0.7052 (0.7134)	Training Prec@1 27.539 (25.322)	Training Prec@5 38.281 (36.093)	
2022-04-01 08:40:19,598: ============================================================
2022-04-01 08:41:00,003: time cost, forward:0.1155164406280635, backward:0.034516599062743264, data cost:0.25307671514404956 
2022-04-01 08:41:00,003: ============================================================
2022-04-01 08:41:00,003: Epoch 26/31 Batch 3900/7662 eta: 4:43:19.755030	Training Loss 0.7121 (0.7132)	Training Prec@1 25.000 (25.364)	Training Prec@5 33.398 (36.139)	
2022-04-01 08:41:00,003: ============================================================
2022-04-01 08:41:47,292: time cost, forward:0.11687867097122487, backward:0.03460971275905753, data cost:0.25336666135795116 
2022-04-01 08:41:47,293: ============================================================
2022-04-01 08:41:47,293: Epoch 26/31 Batch 4000/7662 eta: 5:30:48.884279	Training Loss 0.7072 (0.7131)	Training Prec@1 26.562 (25.403)	Training Prec@5 38.867 (36.182)	
2022-04-01 08:41:47,293: ============================================================
2022-04-01 08:42:30,160: time cost, forward:0.1178606281224679, backward:0.03462246471162132, data cost:0.2529388616421828 
2022-04-01 08:42:30,163: ============================================================
2022-04-01 08:42:30,164: Epoch 26/31 Batch 4100/7662 eta: 4:59:11.095417	Training Loss 0.6990 (0.7129)	Training Prec@1 28.906 (25.460)	Training Prec@5 39.844 (36.241)	
2022-04-01 08:42:30,164: ============================================================
2022-04-01 08:43:19,076: time cost, forward:0.1194409582551873, backward:0.034744515763092225, data cost:0.2532110402174693 
2022-04-01 08:43:19,112: ============================================================
2022-04-01 08:43:19,113: Epoch 26/31 Batch 4200/7662 eta: 5:40:47.642302	Training Loss 0.7077 (0.7128)	Training Prec@1 24.805 (25.505)	Training Prec@5 34.961 (36.290)	
2022-04-01 08:43:19,113: ============================================================
2022-04-01 08:44:09,836: time cost, forward:0.12103419460288645, backward:0.034845274252846066, data cost:0.25384898633839337 
2022-04-01 08:44:09,836: ============================================================
2022-04-01 08:44:09,837: Epoch 26/31 Batch 4300/7662 eta: 5:52:18.167502	Training Loss 0.7043 (0.7126)	Training Prec@1 28.125 (25.561)	Training Prec@5 39.648 (36.343)	
2022-04-01 08:44:09,837: ============================================================
2022-04-01 08:44:57,846: time cost, forward:0.122510001669691, backward:0.03497180355546366, data cost:0.25381967137417594 
2022-04-01 08:44:57,846: ============================================================
2022-04-01 08:44:57,847: Epoch 26/31 Batch 4400/7662 eta: 5:32:39.257461	Training Loss 0.6998 (0.7124)	Training Prec@1 30.664 (25.614)	Training Prec@5 39.844 (36.399)	
2022-04-01 08:44:57,847: ============================================================
2022-04-01 08:45:37,121: time cost, forward:0.12226648478010915, backward:0.034954286093286845, data cost:0.2536568789514973 
2022-04-01 08:45:37,122: ============================================================
2022-04-01 08:45:37,122: Epoch 26/31 Batch 4500/7662 eta: 4:31:28.670691	Training Loss 0.7095 (0.7122)	Training Prec@1 25.586 (25.665)	Training Prec@5 37.109 (36.450)	
2022-04-01 08:45:37,122: ============================================================
2022-04-01 08:46:16,818: time cost, forward:0.12201819681141475, backward:0.03495846750633072, data cost:0.253592806138223 
2022-04-01 08:46:16,819: ============================================================
2022-04-01 08:46:16,819: Epoch 26/31 Batch 4600/7662 eta: 4:33:43.923962	Training Loss 0.7015 (0.7121)	Training Prec@1 27.930 (25.719)	Training Prec@5 38.867 (36.506)	
2022-04-01 08:46:16,820: ============================================================
2022-04-01 08:46:56,486: time cost, forward:0.12179097420967851, backward:0.034958089709560984, data cost:0.253517899520348 
2022-04-01 08:46:56,487: ============================================================
2022-04-01 08:46:56,487: Epoch 26/31 Batch 4700/7662 eta: 4:32:51.951046	Training Loss 0.7019 (0.7119)	Training Prec@1 27.148 (25.775)	Training Prec@5 39.062 (36.564)	
2022-04-01 08:46:56,487: ============================================================
2022-04-01 08:47:37,603: time cost, forward:0.1218873353569824, backward:0.03497331632775897, data cost:0.25340981129731555 
2022-04-01 08:47:37,604: ============================================================
2022-04-01 08:47:37,605: Epoch 26/31 Batch 4800/7662 eta: 4:42:09.486961	Training Loss 0.7056 (0.7117)	Training Prec@1 27.930 (25.830)	Training Prec@5 40.234 (36.621)	
2022-04-01 08:47:37,605: ============================================================
2022-04-01 08:48:19,137: time cost, forward:0.12213952304344076, backward:0.035021814138798305, data cost:0.2532107751207416 
2022-04-01 08:48:19,138: ============================================================
2022-04-01 08:48:19,138: Epoch 26/31 Batch 4900/7662 eta: 4:44:18.995290	Training Loss 0.7221 (0.7116)	Training Prec@1 24.414 (25.875)	Training Prec@5 35.938 (36.664)	
2022-04-01 08:48:19,138: ============================================================
2022-04-01 08:49:00,464: time cost, forward:0.12197083410059698, backward:0.03506278743694295, data cost:0.25338226906131045 
2022-04-01 08:49:00,464: ============================================================
2022-04-01 08:49:00,464: Epoch 26/31 Batch 5000/7662 eta: 4:42:12.623981	Training Loss 0.7071 (0.7116)	Training Prec@1 26.172 (25.904)	Training Prec@5 38.281 (36.693)	
2022-04-01 08:49:00,465: ============================================================
2022-04-01 08:49:42,860: time cost, forward:0.12222534989721519, backward:0.03508654868609767, data cost:0.2533577620503855 
2022-04-01 08:49:42,860: ============================================================
2022-04-01 08:49:42,860: Epoch 26/31 Batch 5100/7662 eta: 4:48:48.516360	Training Loss 0.6995 (0.7114)	Training Prec@1 28.320 (25.957)	Training Prec@5 41.211 (36.748)	
2022-04-01 08:49:42,861: ============================================================
2022-04-01 08:50:23,356: time cost, forward:0.12208273562588906, backward:0.03509056419105478, data cost:0.2533808856497455 
2022-04-01 08:50:23,356: ============================================================
2022-04-01 08:50:23,357: Epoch 26/31 Batch 5200/7662 eta: 4:35:11.482803	Training Loss 0.7040 (0.7113)	Training Prec@1 27.734 (26.008)	Training Prec@5 39.648 (36.800)	
2022-04-01 08:50:23,357: ============================================================
2022-04-01 08:51:05,115: time cost, forward:0.12194536253739627, backward:0.03507251734102778, data cost:0.2536561283486635 
2022-04-01 08:51:05,115: ============================================================
2022-04-01 08:51:05,116: Epoch 26/31 Batch 5300/7662 eta: 4:43:04.721395	Training Loss 0.7134 (0.7111)	Training Prec@1 24.805 (26.060)	Training Prec@5 34.961 (36.850)	
2022-04-01 08:51:05,116: ============================================================
2022-04-01 08:51:49,100: time cost, forward:0.12203845030114616, backward:0.03507763144042143, data cost:0.2541023648917885 
2022-04-01 08:51:49,101: ============================================================
2022-04-01 08:51:49,101: Epoch 26/31 Batch 5400/7662 eta: 4:57:26.189555	Training Loss 0.7116 (0.7110)	Training Prec@1 30.078 (26.106)	Training Prec@5 39.648 (36.901)	
2022-04-01 08:51:49,101: ============================================================
2022-04-01 08:52:29,162: time cost, forward:0.1219891607815579, backward:0.03506596766074889, data cost:0.2539530472877698 
2022-04-01 08:52:29,162: ============================================================
2022-04-01 08:52:29,162: Epoch 26/31 Batch 5500/7662 eta: 4:30:14.029650	Training Loss 0.7001 (0.7109)	Training Prec@1 30.273 (26.146)	Training Prec@5 40.430 (36.949)	
2022-04-01 08:52:29,163: ============================================================
2022-04-01 08:53:11,988: time cost, forward:0.1225156922024432, backward:0.03509777306360653, data cost:0.2536963730928067 
2022-04-01 08:53:11,988: ============================================================
2022-04-01 08:53:11,989: Epoch 26/31 Batch 5600/7662 eta: 4:48:10.252339	Training Loss 0.7065 (0.7107)	Training Prec@1 27.734 (26.196)	Training Prec@5 35.938 (36.997)	
2022-04-01 08:53:11,989: ============================================================
2022-04-01 08:53:52,242: time cost, forward:0.12240129609885268, backward:0.03509498320246688, data cost:0.2536539535268103 
2022-04-01 08:53:52,243: ============================================================
2022-04-01 08:53:52,244: Epoch 26/31 Batch 5700/7662 eta: 4:30:11.901861	Training Loss 0.7015 (0.7106)	Training Prec@1 28.125 (26.253)	Training Prec@5 40.430 (37.057)	
2022-04-01 08:53:52,244: ============================================================
2022-04-01 08:54:32,996: time cost, forward:0.12224230541815366, backward:0.03510302682440124, data cost:0.25373411610283136 
2022-04-01 08:54:32,997: ============================================================
2022-04-01 08:54:32,997: Epoch 26/31 Batch 5800/7662 eta: 4:32:51.865237	Training Loss 0.7043 (0.7104)	Training Prec@1 28.516 (26.299)	Training Prec@5 40.820 (37.105)	
2022-04-01 08:54:32,997: ============================================================
2022-04-01 08:55:14,276: time cost, forward:0.12239275364213767, backward:0.035135990847044225, data cost:0.253569382007778 
2022-04-01 08:55:14,276: ============================================================
2022-04-01 08:55:14,276: Epoch 26/31 Batch 5900/7662 eta: 4:35:41.850726	Training Loss 0.7059 (0.7102)	Training Prec@1 26.758 (26.351)	Training Prec@5 36.133 (37.156)	
2022-04-01 08:55:14,277: ============================================================
2022-04-01 08:55:55,497: time cost, forward:0.12250259018357663, backward:0.0351508350884205, data cost:0.2534695751052198 
2022-04-01 08:55:55,498: ============================================================
2022-04-01 08:55:55,498: Epoch 26/31 Batch 6000/7662 eta: 4:34:37.481885	Training Loss 0.7073 (0.7102)	Training Prec@1 25.977 (26.387)	Training Prec@5 38.281 (37.193)	
2022-04-01 08:55:55,498: ============================================================
2022-04-01 08:56:36,519: time cost, forward:0.12267853338457675, backward:0.035167644445691704, data cost:0.2532529445100288 
2022-04-01 08:56:36,520: ============================================================
2022-04-01 08:56:36,520: Epoch 26/31 Batch 6100/7662 eta: 4:32:36.752189	Training Loss 0.6983 (0.7100)	Training Prec@1 29.688 (26.435)	Training Prec@5 41.602 (37.245)	
2022-04-01 08:56:36,520: ============================================================
2022-04-01 08:57:17,308: time cost, forward:0.12254175591380351, backward:0.035155778355051535, data cost:0.2533411111999354 
2022-04-01 08:57:17,309: ============================================================
2022-04-01 08:57:17,309: Epoch 26/31 Batch 6200/7662 eta: 4:30:22.970010	Training Loss 0.7019 (0.7098)	Training Prec@1 24.609 (26.484)	Training Prec@5 35.156 (37.300)	
2022-04-01 08:57:17,309: ============================================================
2022-04-01 08:57:57,292: time cost, forward:0.12240647315827603, backward:0.035150666372381255, data cost:0.2532990015126501 
2022-04-01 08:57:57,293: ============================================================
2022-04-01 08:57:57,293: Epoch 26/31 Batch 6300/7662 eta: 4:24:22.823931	Training Loss 0.6939 (0.7097)	Training Prec@1 31.445 (26.533)	Training Prec@5 42.383 (37.347)	
2022-04-01 08:57:57,293: ============================================================
2022-04-01 08:58:37,448: time cost, forward:0.1222308234211653, backward:0.03514896487608461, data cost:0.25331581296501987 
2022-04-01 08:58:37,449: ============================================================
2022-04-01 08:58:37,449: Epoch 26/31 Batch 6400/7662 eta: 4:24:51.017056	Training Loss 0.6997 (0.7095)	Training Prec@1 30.078 (26.584)	Training Prec@5 39.648 (37.398)	
2022-04-01 08:58:37,449: ============================================================
2022-04-01 08:59:18,315: time cost, forward:0.12206984542116493, backward:0.035143863349570585, data cost:0.2534545248225022 
2022-04-01 08:59:18,315: ============================================================
2022-04-01 08:59:18,316: Epoch 26/31 Batch 6500/7662 eta: 4:28:51.234165	Training Loss 0.6994 (0.7093)	Training Prec@1 28.516 (26.638)	Training Prec@5 41.211 (37.452)	
2022-04-01 08:59:18,316: ============================================================
2022-04-01 08:59:58,160: time cost, forward:0.12193193260802158, backward:0.035133329155337074, data cost:0.2534068377203319 
2022-04-01 08:59:58,161: ============================================================
2022-04-01 08:59:58,161: Epoch 26/31 Batch 6600/7662 eta: 4:21:28.281598	Training Loss 0.7050 (0.7092)	Training Prec@1 28.711 (26.681)	Training Prec@5 39.648 (37.497)	
2022-04-01 08:59:58,161: ============================================================
2022-04-01 09:00:39,042: time cost, forward:0.12179276928614816, backward:0.035125022753795095, data cost:0.25352653490463145 
2022-04-01 09:00:39,042: ============================================================
2022-04-01 09:00:39,043: Epoch 26/31 Batch 6700/7662 eta: 4:27:35.445431	Training Loss 0.7060 (0.7091)	Training Prec@1 29.297 (26.728)	Training Prec@5 39.453 (37.544)	
2022-04-01 09:00:39,043: ============================================================
2022-04-01 09:01:18,524: time cost, forward:0.12171608185939954, backward:0.03511187496878221, data cost:0.2533809943380803 
2022-04-01 09:01:18,524: ============================================================
2022-04-01 09:01:18,524: Epoch 26/31 Batch 6800/7662 eta: 4:17:46.232163	Training Loss 0.6941 (0.7090)	Training Prec@1 29.688 (26.770)	Training Prec@5 40.625 (37.587)	
2022-04-01 09:01:18,525: ============================================================
2022-04-01 09:01:58,238: time cost, forward:0.1216236421173423, backward:0.035095390262319, data cost:0.25325703005770667 
2022-04-01 09:01:58,239: ============================================================
2022-04-01 09:01:58,239: Epoch 26/31 Batch 6900/7662 eta: 4:18:37.611818	Training Loss 0.7002 (0.7088)	Training Prec@1 27.344 (26.818)	Training Prec@5 37.305 (37.635)	
2022-04-01 09:01:58,239: ============================================================
2022-04-01 09:02:39,450: time cost, forward:0.12171673107051836, backward:0.035118773113337394, data cost:0.25319436206564183 
2022-04-01 09:02:39,451: ============================================================
2022-04-01 09:02:39,451: Epoch 26/31 Batch 7000/7662 eta: 4:27:41.636345	Training Loss 0.7043 (0.7087)	Training Prec@1 26.953 (26.865)	Training Prec@5 37.695 (37.683)	
2022-04-01 09:02:39,451: ============================================================
2022-04-01 09:03:19,614: time cost, forward:0.12158167424345037, backward:0.03512120525641145, data cost:0.25320889987077727 
2022-04-01 09:03:19,614: ============================================================
2022-04-01 09:03:19,614: Epoch 26/31 Batch 7100/7662 eta: 4:20:12.675175	Training Loss 0.7114 (0.7085)	Training Prec@1 27.148 (26.914)	Training Prec@5 35.352 (37.731)	
2022-04-01 09:03:19,615: ============================================================
2022-04-01 09:03:59,314: time cost, forward:0.12144900464501575, backward:0.03510720946090323, data cost:0.25316390465954836 
2022-04-01 09:03:59,315: ============================================================
2022-04-01 09:03:59,316: Epoch 26/31 Batch 7200/7662 eta: 4:16:33.356910	Training Loss 0.6928 (0.7084)	Training Prec@1 30.859 (26.961)	Training Prec@5 45.117 (37.777)	
2022-04-01 09:03:59,316: ============================================================
2022-04-01 09:04:41,153: time cost, forward:0.12131282907264627, backward:0.03509305405084328, data cost:0.25343358851504794 
2022-04-01 09:04:41,153: ============================================================
2022-04-01 09:04:41,153: Epoch 26/31 Batch 7300/7662 eta: 4:29:39.925581	Training Loss 0.7016 (0.7082)	Training Prec@1 28.320 (27.008)	Training Prec@5 41.797 (37.825)	
2022-04-01 09:04:41,154: ============================================================
2022-04-01 09:05:21,016: time cost, forward:0.1211656035724758, backward:0.035100126124697935, data cost:0.2534200737227909 
2022-04-01 09:05:21,016: ============================================================
2022-04-01 09:05:21,017: Epoch 26/31 Batch 7400/7662 eta: 4:16:16.450142	Training Loss 0.7063 (0.7081)	Training Prec@1 30.469 (27.058)	Training Prec@5 41.211 (37.876)	
2022-04-01 09:05:21,017: ============================================================
2022-04-01 09:06:03,188: time cost, forward:0.1213988085272535, backward:0.03509918164055989, data cost:0.2533346172777362 
2022-04-01 09:06:03,188: ============================================================
2022-04-01 09:06:03,189: Epoch 26/31 Batch 7500/7662 eta: 4:30:24.811336	Training Loss 0.7011 (0.7080)	Training Prec@1 27.344 (27.106)	Training Prec@5 38.672 (37.925)	
2022-04-01 09:06:03,189: ============================================================
2022-04-01 09:06:46,684: time cost, forward:0.12165179715719422, backward:0.035111183523425835, data cost:0.2533339481163 
2022-04-01 09:06:46,685: ============================================================
2022-04-01 09:06:46,685: Epoch 26/31 Batch 7600/7662 eta: 4:38:11.002616	Training Loss 0.6935 (0.7078)	Training Prec@1 31.641 (27.152)	Training Prec@5 43.750 (37.975)	
2022-04-01 09:06:46,686: ============================================================
2022-04-01 09:07:14,262: Epoch: 26/31 eta: 4:37:43.599672	Training Loss 0.7040 (0.7077)	Training Prec@1 26.172 (27.184)	Training Prec@5 35.938 (38.007)
2022-04-01 09:07:14,262: ============================================================
2022-04-01 09:08:00,920: time cost, forward:0.11207628009295223, backward:0.034879104055539525, data cost:0.3198730536181517 
2022-04-01 09:08:00,920: ============================================================
2022-04-01 09:08:00,921: Epoch 27/31 Batch 100/7662 eta: 4:55:52.980022	Training Loss 0.6894 (0.6916)	Training Prec@1 35.742 (32.637)	Training Prec@5 45.312 (43.981)	
2022-04-01 09:08:00,921: ============================================================
2022-04-01 09:08:42,168: time cost, forward:0.11120807106171421, backward:0.03405994506337535, data cost:0.2937725968097323 
2022-04-01 09:08:42,169: ============================================================
2022-04-01 09:08:42,169: Epoch 27/31 Batch 200/7662 eta: 4:22:00.092665	Training Loss 0.6860 (0.6916)	Training Prec@1 34.570 (32.823)	Training Prec@5 46.875 (43.983)	
2022-04-01 09:08:42,169: ============================================================
2022-04-01 09:09:23,048: time cost, forward:0.11115622520446777, backward:0.03369422182191575, data cost:0.28406346203092747 
2022-04-01 09:09:23,049: ============================================================
2022-04-01 09:09:23,049: Epoch 27/31 Batch 300/7662 eta: 4:18:58.892856	Training Loss 0.6873 (0.6913)	Training Prec@1 32.812 (32.928)	Training Prec@5 43.164 (44.026)	
2022-04-01 09:09:23,049: ============================================================
2022-04-01 09:10:02,505: time cost, forward:0.11199839252577092, backward:0.033625545358299314, data cost:0.2745951046620993 
2022-04-01 09:10:02,505: ============================================================
2022-04-01 09:10:02,506: Epoch 27/31 Batch 400/7662 eta: 4:09:18.468527	Training Loss 0.6905 (0.6912)	Training Prec@1 32.617 (32.903)	Training Prec@5 42.578 (43.968)	
2022-04-01 09:10:02,506: ============================================================
2022-04-01 09:10:45,843: time cost, forward:0.11260455118152565, backward:0.03350958078801035, data cost:0.27589491230691365 
2022-04-01 09:10:45,843: ============================================================
2022-04-01 09:10:45,844: Epoch 27/31 Batch 500/7662 eta: 4:33:06.478826	Training Loss 0.6879 (0.6911)	Training Prec@1 35.547 (32.963)	Training Prec@5 44.531 (44.036)	
2022-04-01 09:10:45,844: ============================================================
2022-04-01 09:11:27,016: time cost, forward:0.1120871932359291, backward:0.033396515901976315, data cost:0.2753353337811707 
2022-04-01 09:11:27,016: ============================================================
2022-04-01 09:11:27,017: Epoch 27/31 Batch 600/7662 eta: 4:18:46.777399	Training Loss 0.7297 (0.6917)	Training Prec@1 29.883 (32.946)	Training Prec@5 43.164 (44.044)	
2022-04-01 09:11:27,017: ============================================================
2022-04-01 09:12:08,365: time cost, forward:0.11312885550470311, backward:0.033363453137857546, data cost:0.27332043579549065 
2022-04-01 09:12:08,365: ============================================================
2022-04-01 09:12:08,366: Epoch 27/31 Batch 700/7662 eta: 4:19:11.707011	Training Loss 0.6879 (0.6922)	Training Prec@1 33.984 (32.766)	Training Prec@5 45.117 (43.901)	
2022-04-01 09:12:08,366: ============================================================
2022-04-01 09:12:49,029: time cost, forward:0.11553119121117049, backward:0.03348341811732745, data cost:0.26905061992745527 
2022-04-01 09:12:49,029: ============================================================
2022-04-01 09:12:49,029: Epoch 27/31 Batch 800/7662 eta: 4:14:13.393368	Training Loss 0.6893 (0.6919)	Training Prec@1 32.617 (32.814)	Training Prec@5 42.773 (43.946)	
2022-04-01 09:12:49,029: ============================================================
2022-04-01 09:13:30,618: time cost, forward:0.11511950153397506, backward:0.03377514447730959, data cost:0.26882949421747904 
2022-04-01 09:13:30,619: ============================================================
2022-04-01 09:13:30,619: Epoch 27/31 Batch 900/7662 eta: 4:19:19.006172	Training Loss 0.6905 (0.6917)	Training Prec@1 34.766 (32.849)	Training Prec@5 45.898 (43.977)	
2022-04-01 09:13:30,619: ============================================================
2022-04-01 09:14:12,826: time cost, forward:0.11590909098719691, backward:0.033891452802671446, data cost:0.2683704195318518 
2022-04-01 09:14:12,827: ============================================================
2022-04-01 09:14:12,827: Epoch 27/31 Batch 1000/7662 eta: 4:22:28.386358	Training Loss 0.6857 (0.6915)	Training Prec@1 35.352 (32.903)	Training Prec@5 45.898 (44.049)	
2022-04-01 09:14:12,827: ============================================================
2022-04-01 09:14:54,472: time cost, forward:0.11670232990636296, backward:0.034089999159864125, data cost:0.2671867555873409 
2022-04-01 09:14:54,472: ============================================================
2022-04-01 09:14:54,473: Epoch 27/31 Batch 1100/7662 eta: 4:18:16.696604	Training Loss 0.6881 (0.6914)	Training Prec@1 33.203 (32.906)	Training Prec@5 45.508 (44.056)	
2022-04-01 09:14:54,473: ============================================================
2022-04-01 09:15:36,280: time cost, forward:0.11770409062268637, backward:0.03450801633018767, data cost:0.2657664601657667 
2022-04-01 09:15:36,280: ============================================================
2022-04-01 09:15:36,280: Epoch 27/31 Batch 1200/7662 eta: 4:18:35.233751	Training Loss 0.6907 (0.6912)	Training Prec@1 33.398 (32.979)	Training Prec@5 43.555 (44.115)	
2022-04-01 09:15:36,280: ============================================================
2022-04-01 09:16:17,562: time cost, forward:0.11869759170526353, backward:0.03453614970553004, data cost:0.26425778452849 
2022-04-01 09:16:17,562: ============================================================
2022-04-01 09:16:17,563: Epoch 27/31 Batch 1300/7662 eta: 4:14:39.007846	Training Loss 0.6928 (0.6910)	Training Prec@1 31.836 (33.015)	Training Prec@5 41.797 (44.159)	
2022-04-01 09:16:17,563: ============================================================
2022-04-01 09:16:59,168: time cost, forward:0.1186253058220166, backward:0.03461338895998144, data cost:0.2641337516053904 
2022-04-01 09:16:59,168: ============================================================
2022-04-01 09:16:59,168: Epoch 27/31 Batch 1400/7662 eta: 4:15:57.154559	Training Loss 0.6876 (0.6909)	Training Prec@1 33.984 (33.060)	Training Prec@5 44.727 (44.195)	
2022-04-01 09:16:59,169: ============================================================
2022-04-01 09:17:40,750: time cost, forward:0.11905117492981161, backward:0.034761441079992864, data cost:0.26344132232538775 
2022-04-01 09:17:40,751: ============================================================
2022-04-01 09:17:40,751: Epoch 27/31 Batch 1500/7662 eta: 4:15:06.862014	Training Loss 0.6860 (0.6907)	Training Prec@1 35.742 (33.102)	Training Prec@5 47.461 (44.226)	
2022-04-01 09:17:40,751: ============================================================
2022-04-01 09:18:23,566: time cost, forward:0.12027127970897682, backward:0.03488850578656414, data cost:0.26273853127251123 
2022-04-01 09:18:23,567: ============================================================
2022-04-01 09:18:23,567: Epoch 27/31 Batch 1600/7662 eta: 4:21:58.187093	Training Loss 0.7152 (0.6907)	Training Prec@1 32.812 (33.146)	Training Prec@5 41.211 (44.252)	
2022-04-01 09:18:23,567: ============================================================
2022-04-01 09:19:06,330: time cost, forward:0.12086991663186812, backward:0.03488523627534342, data cost:0.2626654498362415 
2022-04-01 09:19:06,331: ============================================================
2022-04-01 09:19:06,331: Epoch 27/31 Batch 1700/7662 eta: 4:20:56.408759	Training Loss 0.6859 (0.6907)	Training Prec@1 33.203 (33.171)	Training Prec@5 46.875 (44.269)	
2022-04-01 09:19:06,331: ============================================================
2022-04-01 09:19:47,773: time cost, forward:0.1204139010782968, backward:0.034773618662072396, data cost:0.26302370434008815 
2022-04-01 09:19:47,773: ============================================================
2022-04-01 09:19:47,774: Epoch 27/31 Batch 1800/7662 eta: 4:12:11.069476	Training Loss 0.6847 (0.6905)	Training Prec@1 34.961 (33.216)	Training Prec@5 45.117 (44.302)	
2022-04-01 09:19:47,774: ============================================================
2022-04-01 09:20:30,875: time cost, forward:0.12069481721107679, backward:0.034764757151350086, data cost:0.2633943797538882 
2022-04-01 09:20:30,876: ============================================================
2022-04-01 09:20:30,876: Epoch 27/31 Batch 1900/7662 eta: 4:21:33.964537	Training Loss 0.6897 (0.6903)	Training Prec@1 33.008 (33.263)	Training Prec@5 44.922 (44.345)	
2022-04-01 09:20:30,876: ============================================================
2022-04-01 09:21:14,805: time cost, forward:0.12174077174733912, backward:0.034871072039239226, data cost:0.2632380078112024 
2022-04-01 09:21:14,805: ============================================================
2022-04-01 09:21:14,805: Epoch 27/31 Batch 2000/7662 eta: 4:25:51.212300	Training Loss 0.6887 (0.6901)	Training Prec@1 34.766 (33.309)	Training Prec@5 43.359 (44.389)	
2022-04-01 09:21:14,805: ============================================================
2022-04-01 09:21:56,327: time cost, forward:0.12285670182317594, backward:0.03501841589176638, data cost:0.26172273473662383 
2022-04-01 09:21:56,327: ============================================================
2022-04-01 09:21:56,327: Epoch 27/31 Batch 2100/7662 eta: 4:10:35.551390	Training Loss 0.6839 (0.6900)	Training Prec@1 36.719 (33.355)	Training Prec@5 47.461 (44.437)	
2022-04-01 09:21:56,327: ============================================================
2022-04-01 09:22:38,539: time cost, forward:0.12373702869788253, backward:0.0349719086361235, data cost:0.2609668597680647 
2022-04-01 09:22:38,539: ============================================================
2022-04-01 09:22:38,539: Epoch 27/31 Batch 2200/7662 eta: 4:14:03.096590	Training Loss 0.6874 (0.6898)	Training Prec@1 33.594 (33.401)	Training Prec@5 44.336 (44.477)	
2022-04-01 09:22:38,539: ============================================================
2022-04-01 09:23:20,284: time cost, forward:0.12437648138516672, backward:0.03471827621094918, data cost:0.2604725201164136 
2022-04-01 09:23:20,284: ============================================================
2022-04-01 09:23:20,284: Epoch 27/31 Batch 2300/7662 eta: 4:10:32.827711	Training Loss 0.6827 (0.6897)	Training Prec@1 36.914 (33.442)	Training Prec@5 46.875 (44.518)	
2022-04-01 09:23:20,284: ============================================================
2022-04-01 09:24:02,767: time cost, forward:0.12512085685237043, backward:0.03474274472725197, data cost:0.2599068123283561 
2022-04-01 09:24:02,777: ============================================================
2022-04-01 09:24:02,778: Epoch 27/31 Batch 2400/7662 eta: 4:14:19.765182	Training Loss 0.6828 (0.6895)	Training Prec@1 34.766 (33.495)	Training Prec@5 46.289 (44.559)	
2022-04-01 09:24:02,778: ============================================================
2022-04-01 09:24:45,747: time cost, forward:0.12612202445141266, backward:0.03449217096811869, data cost:0.2595410069354585 
2022-04-01 09:24:45,748: ============================================================
2022-04-01 09:24:45,748: Epoch 27/31 Batch 2500/7662 eta: 4:16:28.104876	Training Loss 0.6885 (0.6895)	Training Prec@1 34.180 (33.520)	Training Prec@5 44.727 (44.582)	
2022-04-01 09:24:45,749: ============================================================
2022-04-01 09:25:28,199: time cost, forward:0.12714131972843887, backward:0.03455279055995728, data cost:0.25857510251143934 
2022-04-01 09:25:28,200: ============================================================
2022-04-01 09:25:28,200: Epoch 27/31 Batch 2600/7662 eta: 4:12:39.986176	Training Loss 0.6895 (0.6894)	Training Prec@1 34.375 (33.567)	Training Prec@5 45.898 (44.628)	
2022-04-01 09:25:28,200: ============================================================
2022-04-01 09:26:08,946: time cost, forward:0.12685675610432406, backward:0.03462089163676683, data cost:0.2583130639144428 
2022-04-01 09:26:08,946: ============================================================
2022-04-01 09:26:08,947: Epoch 27/31 Batch 2700/7662 eta: 4:01:50.405672	Training Loss 0.6866 (0.6894)	Training Prec@1 33.789 (33.590)	Training Prec@5 45.508 (44.639)	
2022-04-01 09:26:08,947: ============================================================
2022-04-01 09:26:52,800: time cost, forward:0.12677886742445008, backward:0.03476291028207096, data cost:0.2588665275839492 
2022-04-01 09:26:52,800: ============================================================
2022-04-01 09:26:52,801: Epoch 27/31 Batch 2800/7662 eta: 4:19:32.962393	Training Loss 0.6843 (0.6892)	Training Prec@1 33.984 (33.639)	Training Prec@5 47.070 (44.680)	
2022-04-01 09:26:52,801: ============================================================
2022-04-01 09:27:34,869: time cost, forward:0.12671358875670735, backward:0.03483346512746136, data cost:0.2588804283813182 
2022-04-01 09:27:34,869: ============================================================
2022-04-01 09:27:34,869: Epoch 27/31 Batch 2900/7662 eta: 4:08:16.890143	Training Loss 0.6839 (0.6890)	Training Prec@1 34.961 (33.685)	Training Prec@5 45.703 (44.720)	
2022-04-01 09:27:34,869: ============================================================
2022-04-01 09:28:16,533: time cost, forward:0.1272837024165933, backward:0.03495198911569563, data cost:0.2580254207495333 
2022-04-01 09:28:16,533: ============================================================
2022-04-01 09:28:16,533: Epoch 27/31 Batch 3000/7662 eta: 4:05:12.087275	Training Loss 0.6875 (0.6888)	Training Prec@1 33.984 (33.731)	Training Prec@5 46.094 (44.768)	
2022-04-01 09:28:16,534: ============================================================
2022-04-01 09:28:57,501: time cost, forward:0.12669795672714268, backward:0.03489924754277857, data cost:0.2583222236122459 
2022-04-01 09:28:57,502: ============================================================
2022-04-01 09:28:57,502: Epoch 27/31 Batch 3100/7662 eta: 4:00:25.436297	Training Loss 0.6866 (0.6889)	Training Prec@1 33.594 (33.757)	Training Prec@5 43.164 (44.784)	
2022-04-01 09:28:57,502: ============================================================
2022-04-01 09:29:40,275: time cost, forward:0.12642924902624694, backward:0.034893553418716666, data cost:0.2588287009489316 
2022-04-01 09:29:40,275: ============================================================
2022-04-01 09:29:40,275: Epoch 27/31 Batch 3200/7662 eta: 4:10:18.049628	Training Loss 0.6877 (0.6887)	Training Prec@1 32.617 (33.793)	Training Prec@5 44.531 (44.815)	
2022-04-01 09:29:40,275: ============================================================
2022-04-01 09:30:22,472: time cost, forward:0.12617880779889615, backward:0.03488819582529522, data cost:0.2591213607614638 
2022-04-01 09:30:22,472: ============================================================
2022-04-01 09:30:22,472: Epoch 27/31 Batch 3300/7662 eta: 4:06:13.616721	Training Loss 0.6782 (0.6886)	Training Prec@1 37.305 (33.836)	Training Prec@5 47.852 (44.849)	
2022-04-01 09:30:22,472: ============================================================
2022-04-01 09:31:03,574: time cost, forward:0.12628812451824156, backward:0.034858133625233656, data cost:0.2587781441355495 
2022-04-01 09:31:03,575: ============================================================
2022-04-01 09:31:03,575: Epoch 27/31 Batch 3400/7662 eta: 3:59:09.387983	Training Loss 0.6817 (0.6884)	Training Prec@1 34.570 (33.869)	Training Prec@5 48.047 (44.878)	
2022-04-01 09:31:03,575: ============================================================
2022-04-01 09:31:45,432: time cost, forward:0.12635377762351047, backward:0.034994638930323736, data cost:0.2585143702954829 
2022-04-01 09:31:45,433: ============================================================
2022-04-01 09:31:45,433: Epoch 27/31 Batch 3500/7662 eta: 4:02:51.230971	Training Loss 0.6834 (0.6883)	Training Prec@1 37.305 (33.907)	Training Prec@5 47.852 (44.916)	
2022-04-01 09:31:45,433: ============================================================
2022-04-01 09:32:28,431: time cost, forward:0.1265202752415688, backward:0.03511375564772343, data cost:0.25849448942283554 
2022-04-01 09:32:28,433: ============================================================
2022-04-01 09:32:28,434: Epoch 27/31 Batch 3600/7662 eta: 4:08:45.854136	Training Loss 0.6794 (0.6881)	Training Prec@1 34.961 (33.958)	Training Prec@5 45.117 (44.958)	
2022-04-01 09:32:28,434: ============================================================
2022-04-01 09:33:12,340: time cost, forward:0.1267728487779463, backward:0.03489984470820163, data cost:0.25888881995311197 
2022-04-01 09:33:12,341: ============================================================
2022-04-01 09:33:12,342: Epoch 27/31 Batch 3700/7662 eta: 4:13:17.015949	Training Loss 0.6814 (0.6882)	Training Prec@1 34.180 (33.965)	Training Prec@5 47.266 (44.963)	
2022-04-01 09:33:12,342: ============================================================
2022-04-01 09:33:54,844: time cost, forward:0.12698701244493824, backward:0.03489243755154812, data cost:0.2588498154324147 
2022-04-01 09:33:54,844: ============================================================
2022-04-01 09:33:54,845: Epoch 27/31 Batch 3800/7662 eta: 4:04:28.282004	Training Loss 0.6815 (0.6881)	Training Prec@1 35.156 (33.999)	Training Prec@5 49.609 (44.997)	
2022-04-01 09:33:54,845: ============================================================
2022-04-01 09:34:35,816: time cost, forward:0.12717780965387776, backward:0.0348795032036491, data cost:0.2583649014166974 
2022-04-01 09:34:35,817: ============================================================
2022-04-01 09:34:35,818: Epoch 27/31 Batch 3900/7662 eta: 3:54:59.275738	Training Loss 0.6836 (0.6879)	Training Prec@1 33.203 (34.037)	Training Prec@5 46.094 (45.024)	
2022-04-01 09:34:35,819: ============================================================
2022-04-01 09:35:18,993: time cost, forward:0.1276626851624863, backward:0.03483024285000007, data cost:0.2582136393487677 
2022-04-01 09:35:18,994: ============================================================
2022-04-01 09:35:18,995: Epoch 27/31 Batch 4000/7662 eta: 4:06:54.371810	Training Loss 0.6818 (0.6878)	Training Prec@1 36.328 (34.078)	Training Prec@5 45.898 (45.069)	
2022-04-01 09:35:18,995: ============================================================
2022-04-01 09:36:01,308: time cost, forward:0.12819781301079158, backward:0.034831229463732225, data cost:0.25771085394100607 
2022-04-01 09:36:01,309: ============================================================
2022-04-01 09:36:01,309: Epoch 27/31 Batch 4100/7662 eta: 4:01:16.184019	Training Loss 0.6870 (0.6876)	Training Prec@1 33.203 (34.120)	Training Prec@5 44.922 (45.108)	
2022-04-01 09:36:01,309: ============================================================
2022-04-01 09:36:41,872: time cost, forward:0.12795624814734172, backward:0.034799451173899085, data cost:0.2576120702048999 
2022-04-01 09:36:41,872: ============================================================
2022-04-01 09:36:41,873: Epoch 27/31 Batch 4200/7662 eta: 3:50:36.618388	Training Loss 0.6887 (0.6875)	Training Prec@1 31.641 (34.162)	Training Prec@5 43.750 (45.150)	
2022-04-01 09:36:41,873: ============================================================
2022-04-01 09:37:23,888: time cost, forward:0.12816715467860737, backward:0.034792640315124836, data cost:0.25738624046780006 
2022-04-01 09:37:23,889: ============================================================
2022-04-01 09:37:23,889: Epoch 27/31 Batch 4300/7662 eta: 3:58:10.151374	Training Loss 0.6794 (0.6873)	Training Prec@1 35.938 (34.206)	Training Prec@5 48.438 (45.189)	
2022-04-01 09:37:23,889: ============================================================
2022-04-01 09:38:07,280: time cost, forward:0.1283593799992566, backward:0.03472898824292439, data cost:0.2575588558554297 
2022-04-01 09:38:07,281: ============================================================
2022-04-01 09:38:07,281: Epoch 27/31 Batch 4400/7662 eta: 4:05:14.672991	Training Loss 0.6817 (0.6871)	Training Prec@1 35.938 (34.254)	Training Prec@5 46.094 (45.235)	
2022-04-01 09:38:07,281: ============================================================
2022-04-01 09:38:49,822: time cost, forward:0.12835106369547644, backward:0.034756097138577184, data cost:0.2576276693748988 
2022-04-01 09:38:49,823: ============================================================
2022-04-01 09:38:49,823: Epoch 27/31 Batch 4500/7662 eta: 3:59:43.942627	Training Loss 0.6814 (0.6870)	Training Prec@1 36.914 (34.288)	Training Prec@5 49.609 (45.268)	
2022-04-01 09:38:49,823: ============================================================
2022-04-01 09:39:33,475: time cost, forward:0.12886058835782133, backward:0.03477011459966047, data cost:0.2574237318862182 
2022-04-01 09:39:33,486: ============================================================
2022-04-01 09:39:33,487: Epoch 27/31 Batch 4600/7662 eta: 4:05:19.422039	Training Loss 0.6831 (0.6870)	Training Prec@1 33.008 (34.310)	Training Prec@5 44.336 (45.290)	
2022-04-01 09:39:33,487: ============================================================
2022-04-01 09:40:16,007: time cost, forward:0.12886551157619933, backward:0.03477249142463523, data cost:0.2573716064086998 
2022-04-01 09:40:16,007: ============================================================
2022-04-01 09:40:16,007: Epoch 27/31 Batch 4700/7662 eta: 3:58:11.586071	Training Loss 0.6796 (0.6869)	Training Prec@1 36.133 (34.354)	Training Prec@5 45.312 (45.330)	
2022-04-01 09:40:16,007: ============================================================
2022-04-01 09:40:58,271: time cost, forward:0.12882837501012379, backward:0.03477489722224667, data cost:0.25755257744619214 
2022-04-01 09:40:58,271: ============================================================
2022-04-01 09:40:58,271: Epoch 27/31 Batch 4800/7662 eta: 3:56:03.069045	Training Loss 0.6849 (0.6867)	Training Prec@1 36.328 (34.399)	Training Prec@5 47.461 (45.372)	
2022-04-01 09:40:58,271: ============================================================
2022-04-01 09:41:39,771: time cost, forward:0.12853389862825199, backward:0.03476294256468456, data cost:0.25771765301095684 
2022-04-01 09:41:39,771: ============================================================
2022-04-01 09:41:39,772: Epoch 27/31 Batch 4900/7662 eta: 3:51:05.696834	Training Loss 0.6774 (0.6865)	Training Prec@1 37.695 (34.449)	Training Prec@5 49.219 (45.413)	
2022-04-01 09:41:39,772: ============================================================
2022-04-01 09:42:23,323: time cost, forward:0.12879212237901988, backward:0.034790156006359964, data cost:0.25771523881230407 
2022-04-01 09:42:23,323: ============================================================
2022-04-01 09:42:23,324: Epoch 27/31 Batch 5000/7662 eta: 4:01:47.640806	Training Loss 0.6799 (0.6864)	Training Prec@1 33.789 (34.487)	Training Prec@5 48.438 (45.449)	
2022-04-01 09:42:23,324: ============================================================
2022-04-01 09:43:04,340: time cost, forward:0.12859330469076483, backward:0.034779717534587626, data cost:0.2577040370339668 
2022-04-01 09:43:04,340: ============================================================
2022-04-01 09:43:04,340: Epoch 27/31 Batch 5100/7662 eta: 3:47:02.074934	Training Loss 0.6745 (0.6862)	Training Prec@1 40.430 (34.531)	Training Prec@5 50.195 (45.493)	
2022-04-01 09:43:04,341: ============================================================
2022-04-01 09:43:47,487: time cost, forward:0.12841286689507364, backward:0.0347417674401238, data cost:0.258115060330813 
2022-04-01 09:43:47,487: ============================================================
2022-04-01 09:43:47,488: Epoch 27/31 Batch 5200/7662 eta: 3:58:06.467533	Training Loss 0.6752 (0.6861)	Training Prec@1 36.719 (34.577)	Training Prec@5 50.391 (45.536)	
2022-04-01 09:43:47,488: ============================================================
2022-04-01 09:44:32,257: time cost, forward:0.12876356541154338, backward:0.03473319668076042, data cost:0.2582578070547518 
2022-04-01 09:44:32,257: ============================================================
2022-04-01 09:44:32,258: Epoch 27/31 Batch 5300/7662 eta: 4:06:18.994865	Training Loss 0.6836 (0.6860)	Training Prec@1 35.938 (34.617)	Training Prec@5 46.484 (45.577)	
2022-04-01 09:44:32,258: ============================================================
2022-04-01 09:45:12,806: time cost, forward:0.12867121458892625, backward:0.03476494134499157, data cost:0.25798867825866517 
2022-04-01 09:45:12,807: ============================================================
2022-04-01 09:45:12,807: Epoch 27/31 Batch 5400/7662 eta: 3:42:25.303614	Training Loss 0.6781 (0.6858)	Training Prec@1 37.695 (34.659)	Training Prec@5 47.656 (45.621)	
2022-04-01 09:45:12,808: ============================================================
2022-04-01 09:45:56,395: time cost, forward:0.1291290511866443, backward:0.0347679118326218, data cost:0.2578017670450524 
2022-04-01 09:45:56,395: ============================================================
2022-04-01 09:45:56,395: Epoch 27/31 Batch 5500/7662 eta: 3:58:21.668321	Training Loss 0.6790 (0.6856)	Training Prec@1 37.109 (34.700)	Training Prec@5 47.266 (45.661)	
2022-04-01 09:45:56,395: ============================================================
2022-04-01 09:46:39,944: time cost, forward:0.129357147182731, backward:0.03479757899151335, data cost:0.25778125264555624 
2022-04-01 09:46:39,945: ============================================================
2022-04-01 09:46:39,945: Epoch 27/31 Batch 5600/7662 eta: 3:57:25.628942	Training Loss 0.6892 (0.6855)	Training Prec@1 31.641 (34.739)	Training Prec@5 44.531 (45.699)	
2022-04-01 09:46:39,945: ============================================================
2022-04-01 09:47:22,246: time cost, forward:0.12930960549787798, backward:0.034794377535973794, data cost:0.25783982099535424 
2022-04-01 09:47:22,246: ============================================================
2022-04-01 09:47:22,246: Epoch 27/31 Batch 5700/7662 eta: 3:49:54.793066	Training Loss 0.6794 (0.6853)	Training Prec@1 35.547 (34.783)	Training Prec@5 48.438 (45.741)	
2022-04-01 09:47:22,246: ============================================================
2022-04-01 09:48:05,650: time cost, forward:0.1296717207027645, backward:0.03479224987164883, data cost:0.2576757277018203 
2022-04-01 09:48:05,650: ============================================================
2022-04-01 09:48:05,651: Epoch 27/31 Batch 5800/7662 eta: 3:55:11.343577	Training Loss 0.6771 (0.6852)	Training Prec@1 36.523 (34.824)	Training Prec@5 47.461 (45.780)	
2022-04-01 09:48:05,652: ============================================================
2022-04-01 09:48:48,292: time cost, forward:0.12997675334059358, backward:0.03481918178305502, data cost:0.2574013660956003 
2022-04-01 09:48:48,292: ============================================================
2022-04-01 09:48:48,293: Epoch 27/31 Batch 5900/7662 eta: 3:50:20.519795	Training Loss 0.6796 (0.6851)	Training Prec@1 36.719 (34.862)	Training Prec@5 48.242 (45.817)	
2022-04-01 09:48:48,293: ============================================================
2022-04-01 09:49:29,888: time cost, forward:0.13021420713145845, backward:0.03482581524277433, data cost:0.25704876449350955 
2022-04-01 09:49:29,889: ============================================================
2022-04-01 09:49:29,889: Epoch 27/31 Batch 6000/7662 eta: 3:44:00.257030	Training Loss 0.6810 (0.6849)	Training Prec@1 36.523 (34.909)	Training Prec@5 47.070 (45.866)	
2022-04-01 09:49:29,889: ============================================================
2022-04-01 09:50:13,566: time cost, forward:0.130379046039672, backward:0.034866236921098706, data cost:0.2570683179399697 
2022-04-01 09:50:13,566: ============================================================
2022-04-01 09:50:13,567: Epoch 27/31 Batch 6100/7662 eta: 3:54:28.981262	Training Loss 0.6689 (0.6847)	Training Prec@1 36.523 (34.953)	Training Prec@5 49.805 (45.912)	
2022-04-01 09:50:13,567: ============================================================
2022-04-01 09:50:55,886: time cost, forward:0.13050188755177553, backward:0.03487245366157572, data cost:0.2569458570801879 
2022-04-01 09:50:55,886: ============================================================
2022-04-01 09:50:55,886: Epoch 27/31 Batch 6200/7662 eta: 3:46:29.200166	Training Loss 0.6729 (0.6846)	Training Prec@1 39.453 (35.003)	Training Prec@5 49.023 (45.960)	
2022-04-01 09:50:55,886: ============================================================
2022-04-01 09:51:37,713: time cost, forward:0.13054379169326638, backward:0.03487347878999494, data cost:0.25683141723665515 
2022-04-01 09:51:37,713: ============================================================
2022-04-01 09:51:37,714: Epoch 27/31 Batch 6300/7662 eta: 3:43:09.402280	Training Loss 0.6816 (0.6844)	Training Prec@1 35.352 (35.050)	Training Prec@5 44.727 (46.002)	
2022-04-01 09:51:37,714: ============================================================
2022-04-01 09:52:22,381: time cost, forward:0.13059539816531934, backward:0.0348822390554398, data cost:0.25714944608324414 
2022-04-01 09:52:22,381: ============================================================
2022-04-01 09:52:22,381: Epoch 27/31 Batch 6400/7662 eta: 3:57:33.917068	Training Loss 0.6751 (0.6843)	Training Prec@1 36.914 (35.093)	Training Prec@5 47.070 (46.043)	
2022-04-01 09:52:22,382: ============================================================
2022-04-01 09:53:06,227: time cost, forward:0.13078770294136627, backward:0.0349128796955607, data cost:0.2571529558501366 
2022-04-01 09:53:06,228: ============================================================
2022-04-01 09:53:06,228: Epoch 27/31 Batch 6500/7662 eta: 3:52:27.975657	Training Loss 0.6731 (0.6841)	Training Prec@1 37.305 (35.138)	Training Prec@5 47.852 (46.082)	
2022-04-01 09:53:06,228: ============================================================
2022-04-01 09:53:49,642: time cost, forward:0.13083058368944728, backward:0.03489436241944173, data cost:0.2572897671749961 
2022-04-01 09:53:49,653: ============================================================
2022-04-01 09:53:49,653: Epoch 27/31 Batch 6600/7662 eta: 3:49:30.570687	Training Loss 0.6806 (0.6840)	Training Prec@1 36.328 (35.177)	Training Prec@5 47.461 (46.121)	
2022-04-01 09:53:49,653: ============================================================
2022-04-01 09:54:34,821: time cost, forward:0.13129161496467778, backward:0.03490968361988515, data cost:0.2572336878451256 
2022-04-01 09:54:34,821: ============================================================
2022-04-01 09:54:34,821: Epoch 27/31 Batch 6700/7662 eta: 3:57:58.128977	Training Loss 0.6729 (0.6838)	Training Prec@1 38.672 (35.225)	Training Prec@5 49.414 (46.167)	
2022-04-01 09:54:34,821: ============================================================
2022-04-01 09:55:18,213: time cost, forward:0.13129259751358177, backward:0.034938946280835007, data cost:0.25734759488689984 
2022-04-01 09:55:18,214: ============================================================
2022-04-01 09:55:18,214: Epoch 27/31 Batch 6800/7662 eta: 3:47:53.470528	Training Loss 0.6742 (0.6837)	Training Prec@1 36.328 (35.278)	Training Prec@5 48.242 (46.217)	
2022-04-01 09:55:18,214: ============================================================
2022-04-01 09:56:00,223: time cost, forward:0.13145750020617833, backward:0.0349560168225241, data cost:0.2571091347111189 
2022-04-01 09:56:00,231: ============================================================
2022-04-01 09:56:00,231: Epoch 27/31 Batch 6900/7662 eta: 3:39:57.970042	Training Loss 0.6716 (0.6835)	Training Prec@1 39.062 (35.322)	Training Prec@5 50.391 (46.257)	
2022-04-01 09:56:00,231: ============================================================
2022-04-01 09:56:44,783: time cost, forward:0.13180716495238673, backward:0.03496701520823601, data cost:0.2570548776661197 
2022-04-01 09:56:44,783: ============================================================
2022-04-01 09:56:44,784: Epoch 27/31 Batch 7000/7662 eta: 3:52:29.891879	Training Loss 0.6665 (0.6834)	Training Prec@1 40.430 (35.364)	Training Prec@5 51.172 (46.298)	
2022-04-01 09:56:44,784: ============================================================
2022-04-01 09:57:28,723: time cost, forward:0.13187142160009677, backward:0.0349668997377556, data cost:0.2571997100794075 
2022-04-01 09:57:28,723: ============================================================
2022-04-01 09:57:28,724: Epoch 27/31 Batch 7100/7662 eta: 3:48:34.109102	Training Loss 0.6745 (0.6832)	Training Prec@1 35.547 (35.403)	Training Prec@5 50.977 (46.334)	
2022-04-01 09:57:28,724: ============================================================
2022-04-01 09:58:11,305: time cost, forward:0.1318010673835586, backward:0.034920828824971245, data cost:0.2573312670841103 
2022-04-01 09:58:11,305: ============================================================
2022-04-01 09:58:11,305: Epoch 27/31 Batch 7200/7662 eta: 3:40:47.535748	Training Loss 0.6739 (0.6831)	Training Prec@1 39.453 (35.445)	Training Prec@5 51.562 (46.375)	
2022-04-01 09:58:11,305: ============================================================
2022-04-01 09:58:57,799: time cost, forward:0.13253902951272029, backward:0.0349569903414353, data cost:0.25710400520473137 
2022-04-01 09:58:57,799: ============================================================
2022-04-01 09:58:57,799: Epoch 27/31 Batch 7300/7662 eta: 4:00:18.279835	Training Loss 0.6737 (0.6829)	Training Prec@1 36.328 (35.490)	Training Prec@5 47.266 (46.418)	
2022-04-01 09:58:57,800: ============================================================
2022-04-01 09:59:39,404: time cost, forward:0.1323572613610047, backward:0.03494788379439761, data cost:0.2571686320505298 
2022-04-01 09:59:39,405: ============================================================
2022-04-01 09:59:39,405: Epoch 27/31 Batch 7400/7662 eta: 3:34:20.700788	Training Loss 0.6646 (0.6828)	Training Prec@1 41.211 (35.532)	Training Prec@5 53.906 (46.457)	
2022-04-01 09:59:39,405: ============================================================
2022-04-01 10:00:25,750: time cost, forward:0.1327900058953885, backward:0.034979282275631136, data cost:0.257226651470603 
2022-04-01 10:00:25,750: ============================================================
2022-04-01 10:00:25,750: Epoch 27/31 Batch 7500/7662 eta: 3:57:59.549687	Training Loss 0.6798 (0.6827)	Training Prec@1 34.766 (35.573)	Training Prec@5 43.750 (46.500)	
2022-04-01 10:00:25,751: ============================================================
2022-04-01 10:01:09,683: time cost, forward:0.1330582462403159, backward:0.03499202148461596, data cost:0.2571268642649931 
2022-04-01 10:01:09,684: ============================================================
2022-04-01 10:01:09,684: Epoch 27/31 Batch 7600/7662 eta: 3:44:52.400287	Training Loss 0.6649 (0.6825)	Training Prec@1 41.211 (35.617)	Training Prec@5 51.758 (46.542)	
2022-04-01 10:01:09,684: ============================================================
2022-04-01 10:01:37,725: Epoch: 27/31 eta: 3:44:24.722216	Training Loss 0.6749 (0.6824)	Training Prec@1 34.961 (35.644)	Training Prec@5 46.094 (46.569)
2022-04-01 10:01:37,725: ============================================================
2022-04-01 10:02:20,086: time cost, forward:0.11830991205542979, backward:0.03537630794024227, data cost:0.26970879718510793 
2022-04-01 10:02:20,087: ============================================================
2022-04-01 10:02:20,087: Epoch 28/31 Batch 100/7662 eta: 3:35:03.883182	Training Loss 0.6638 (0.6635)	Training Prec@1 41.797 (41.724)	Training Prec@5 53.125 (52.636)	
2022-04-01 10:02:20,087: ============================================================
2022-04-01 10:03:02,225: time cost, forward:0.12105447443286378, backward:0.03474213729551689, data cost:0.2664974538525145 
2022-04-01 10:03:02,226: ============================================================
2022-04-01 10:03:02,226: Epoch 28/31 Batch 200/7662 eta: 3:33:50.884200	Training Loss 0.6602 (0.6668)	Training Prec@1 42.383 (41.387)	Training Prec@5 52.539 (52.198)	
2022-04-01 10:03:02,226: ============================================================
2022-04-01 10:03:46,821: time cost, forward:0.1311016146554596, backward:0.03556735698993389, data cost:0.2634066060235269 
2022-04-01 10:03:46,821: ============================================================
2022-04-01 10:03:46,822: Epoch 28/31 Batch 300/7662 eta: 3:45:34.352691	Training Loss 0.6647 (0.6666)	Training Prec@1 39.258 (41.266)	Training Prec@5 51.172 (52.168)	
2022-04-01 10:03:46,822: ============================================================
2022-04-01 10:04:29,552: time cost, forward:0.13652119959207407, backward:0.03575229047235092, data cost:0.25700608769753824 
2022-04-01 10:04:29,553: ============================================================
2022-04-01 10:04:29,553: Epoch 28/31 Batch 400/7662 eta: 3:35:25.832873	Training Loss 0.6699 (0.6660)	Training Prec@1 39.453 (41.340)	Training Prec@5 49.609 (52.190)	
2022-04-01 10:04:29,553: ============================================================
2022-04-01 10:05:12,872: time cost, forward:0.13992505990909432, backward:0.03644958431113937, data cost:0.25348160500994665 
2022-04-01 10:05:12,873: ============================================================
2022-04-01 10:05:12,876: Epoch 28/31 Batch 500/7662 eta: 3:37:41.191838	Training Loss 0.6593 (0.6654)	Training Prec@1 43.555 (41.440)	Training Prec@5 52.930 (52.281)	
2022-04-01 10:05:12,876: ============================================================
2022-04-01 10:05:56,476: time cost, forward:0.14039406394321652, backward:0.03638786346168072, data cost:0.25378520699693685 
2022-04-01 10:05:56,476: ============================================================
2022-04-01 10:05:56,477: Epoch 28/31 Batch 600/7662 eta: 3:38:21.819330	Training Loss 0.6585 (0.6653)	Training Prec@1 41.992 (41.369)	Training Prec@5 52.344 (52.234)	
2022-04-01 10:05:56,477: ============================================================
2022-04-01 10:06:41,690: time cost, forward:0.1439311732891121, backward:0.03661112348750255, data cost:0.25309262903292634 
2022-04-01 10:06:41,691: ============================================================
2022-04-01 10:06:41,691: Epoch 28/31 Batch 700/7662 eta: 3:45:41.227398	Training Loss 0.6600 (0.6651)	Training Prec@1 43.555 (41.415)	Training Prec@5 54.102 (52.260)	
2022-04-01 10:06:41,691: ============================================================
2022-04-01 10:07:24,814: time cost, forward:0.1445035791218057, backward:0.03671973249939118, data cost:0.2520175609779597 
2022-04-01 10:07:24,814: ============================================================
2022-04-01 10:07:24,814: Epoch 28/31 Batch 800/7662 eta: 3:34:31.909920	Training Loss 0.6642 (0.6648)	Training Prec@1 41.406 (41.438)	Training Prec@5 52.539 (52.273)	
2022-04-01 10:07:24,815: ============================================================
2022-04-01 10:08:09,614: time cost, forward:0.14355798398825165, backward:0.036381422876648695, data cost:0.25491903700738383 
2022-04-01 10:08:09,614: ============================================================
2022-04-01 10:08:09,614: Epoch 28/31 Batch 900/7662 eta: 3:42:07.522125	Training Loss 0.6503 (0.6647)	Training Prec@1 45.312 (41.451)	Training Prec@5 56.055 (52.274)	
2022-04-01 10:08:09,615: ============================================================
2022-04-01 10:08:51,581: time cost, forward:0.14242127015664652, backward:0.036363510756163266, data cost:0.2545011117532327 
2022-04-01 10:08:51,581: ============================================================
2022-04-01 10:08:51,581: Epoch 28/31 Batch 1000/7662 eta: 3:27:22.750026	Training Loss 0.6633 (0.6646)	Training Prec@1 41.211 (41.473)	Training Prec@5 51.953 (52.276)	
2022-04-01 10:08:51,581: ============================================================
2022-04-01 10:09:35,705: time cost, forward:0.14304746357932538, backward:0.036418262235244046, data cost:0.2543983058131099 
2022-04-01 10:09:35,706: ============================================================
2022-04-01 10:09:35,707: Epoch 28/31 Batch 1100/7662 eta: 3:37:18.580015	Training Loss 0.6564 (0.6644)	Training Prec@1 45.117 (41.525)	Training Prec@5 53.320 (52.338)	
2022-04-01 10:09:35,708: ============================================================
2022-04-01 10:10:20,935: time cost, forward:0.14320376299141446, backward:0.0362310892746188, data cost:0.25595599238926214 
2022-04-01 10:10:20,936: ============================================================
2022-04-01 10:10:20,936: Epoch 28/31 Batch 1200/7662 eta: 3:41:59.692764	Training Loss 0.6655 (0.6642)	Training Prec@1 40.234 (41.568)	Training Prec@5 52.734 (52.377)	
2022-04-01 10:10:20,936: ============================================================
2022-04-01 10:11:02,919: time cost, forward:0.14182053720886842, backward:0.035921969351353694, data cost:0.2563428990743636 
2022-04-01 10:11:02,919: ============================================================
2022-04-01 10:11:02,919: Epoch 28/31 Batch 1300/7662 eta: 3:25:21.607265	Training Loss 0.6654 (0.6641)	Training Prec@1 41.797 (41.615)	Training Prec@5 51.953 (52.415)	
2022-04-01 10:11:02,919: ============================================================
2022-04-01 10:11:46,670: time cost, forward:0.14140177318417574, backward:0.03585512643204662, data cost:0.2570374397144222 
2022-04-01 10:11:46,671: ============================================================
2022-04-01 10:11:46,671: Epoch 28/31 Batch 1400/7662 eta: 3:33:16.977947	Training Loss 0.6614 (0.6639)	Training Prec@1 42.969 (41.630)	Training Prec@5 53.516 (52.443)	
2022-04-01 10:11:46,671: ============================================================
2022-04-01 10:12:29,417: time cost, forward:0.14092594118735408, backward:0.03579807058821685, data cost:0.25704259408005403 
2022-04-01 10:12:29,418: ============================================================
2022-04-01 10:12:29,418: Epoch 28/31 Batch 1500/7662 eta: 3:27:40.227536	Training Loss 0.6594 (0.6638)	Training Prec@1 42.383 (41.661)	Training Prec@5 54.688 (52.476)	
2022-04-01 10:12:29,418: ============================================================
2022-04-01 10:13:13,736: time cost, forward:0.14186573252221657, backward:0.03585728531408638, data cost:0.25651323474743276 
2022-04-01 10:13:13,737: ============================================================
2022-04-01 10:13:13,737: Epoch 28/31 Batch 1600/7662 eta: 3:34:34.382627	Training Loss 0.6690 (0.6636)	Training Prec@1 37.109 (41.710)	Training Prec@5 47.852 (52.517)	
2022-04-01 10:13:13,738: ============================================================
2022-04-01 10:13:59,019: time cost, forward:0.1427518741883833, backward:0.03606071171864402, data cost:0.25654697123522474 
2022-04-01 10:13:59,020: ============================================================
2022-04-01 10:13:59,020: Epoch 28/31 Batch 1700/7662 eta: 3:38:28.946127	Training Loss 0.6637 (0.6635)	Training Prec@1 41.211 (41.743)	Training Prec@5 52.148 (52.546)	
2022-04-01 10:13:59,022: ============================================================
2022-04-01 10:14:43,064: time cost, forward:0.14314514878990253, backward:0.03632829718088825, data cost:0.2560566250916121 
2022-04-01 10:14:43,065: ============================================================
2022-04-01 10:14:43,065: Epoch 28/31 Batch 1800/7662 eta: 3:31:46.486359	Training Loss 0.6667 (0.6633)	Training Prec@1 43.164 (41.795)	Training Prec@5 52.344 (52.592)	
2022-04-01 10:14:43,065: ============================================================
2022-04-01 10:15:29,247: time cost, forward:0.14388302842713205, backward:0.0366681104211069, data cost:0.25634209365201915 
2022-04-01 10:15:29,247: ============================================================
2022-04-01 10:15:29,248: Epoch 28/31 Batch 1900/7662 eta: 3:41:17.065565	Training Loss 0.6534 (0.6631)	Training Prec@1 44.727 (41.840)	Training Prec@5 55.078 (52.637)	
2022-04-01 10:15:29,248: ============================================================
2022-04-01 10:16:10,900: time cost, forward:0.14297088364948923, backward:0.03658821405083493, data cost:0.25627987631682814 
2022-04-01 10:16:10,900: ============================================================
2022-04-01 10:16:10,901: Epoch 28/31 Batch 2000/7662 eta: 3:18:53.117048	Training Loss 0.6597 (0.6630)	Training Prec@1 44.531 (41.879)	Training Prec@5 54.492 (52.676)	
2022-04-01 10:16:10,901: ============================================================
2022-04-01 10:16:54,994: time cost, forward:0.14280265441901802, backward:0.036639627131352596, data cost:0.2565902188143428 
2022-04-01 10:16:55,005: ============================================================
2022-04-01 10:16:55,005: Epoch 28/31 Batch 2100/7662 eta: 3:29:51.325723	Training Loss 0.6634 (0.6628)	Training Prec@1 43.359 (41.919)	Training Prec@5 53.125 (52.714)	
2022-04-01 10:16:55,005: ============================================================
2022-04-01 10:17:39,854: time cost, forward:0.14389030041072304, backward:0.036809136944502364, data cost:0.25590819844119705 
2022-04-01 10:17:39,855: ============================================================
2022-04-01 10:17:39,855: Epoch 28/31 Batch 2200/7662 eta: 3:32:39.365892	Training Loss 0.6622 (0.6626)	Training Prec@1 39.844 (41.956)	Training Prec@5 53.125 (52.738)	
2022-04-01 10:17:39,855: ============================================================
2022-04-01 10:18:23,069: time cost, forward:0.14343475590274873, backward:0.0368744133347374, data cost:0.25607345352073296 
2022-04-01 10:18:23,070: ============================================================
2022-04-01 10:18:23,070: Epoch 28/31 Batch 2300/7662 eta: 3:24:11.018906	Training Loss 0.6576 (0.6624)	Training Prec@1 44.336 (42.014)	Training Prec@5 53.125 (52.787)	
2022-04-01 10:18:23,070: ============================================================
2022-04-01 10:19:06,878: time cost, forward:0.14310255553534548, backward:0.036721946200314735, data cost:0.2566020655701587 
2022-04-01 10:19:06,879: ============================================================
2022-04-01 10:19:06,879: Epoch 28/31 Batch 2400/7662 eta: 3:26:15.610274	Training Loss 0.6525 (0.6623)	Training Prec@1 46.094 (42.053)	Training Prec@5 58.594 (52.824)	
2022-04-01 10:19:06,879: ============================================================
2022-04-01 10:19:51,120: time cost, forward:0.1431418509901214, backward:0.03676588614495481, data cost:0.2567232650201194 
2022-04-01 10:19:51,121: ============================================================
2022-04-01 10:19:51,122: Epoch 28/31 Batch 2500/7662 eta: 3:27:34.004963	Training Loss 0.6536 (0.6622)	Training Prec@1 44.531 (42.088)	Training Prec@5 53.516 (52.853)	
2022-04-01 10:19:51,122: ============================================================
2022-04-01 10:20:35,694: time cost, forward:0.14265585431872813, backward:0.03666828081395911, data cost:0.2575486669544075 
2022-04-01 10:20:35,694: ============================================================
2022-04-01 10:20:35,694: Epoch 28/31 Batch 2600/7662 eta: 3:28:22.141726	Training Loss 0.6571 (0.6621)	Training Prec@1 42.188 (42.123)	Training Prec@5 53.125 (52.875)	
2022-04-01 10:20:35,695: ============================================================
2022-04-01 10:21:19,517: time cost, forward:0.1424245703613462, backward:0.03662111565730182, data cost:0.2579378838802365 
2022-04-01 10:21:19,517: ============================================================
2022-04-01 10:21:19,517: Epoch 28/31 Batch 2700/7662 eta: 3:24:08.086459	Training Loss 0.6577 (0.6619)	Training Prec@1 42.969 (42.167)	Training Prec@5 52.539 (52.918)	
2022-04-01 10:21:19,518: ============================================================
2022-04-01 10:22:02,870: time cost, forward:0.1419256074209646, backward:0.03656007844066995, data cost:0.2583618299498563 
2022-04-01 10:22:02,871: ============================================================
2022-04-01 10:22:02,872: Epoch 28/31 Batch 2800/7662 eta: 3:21:13.738150	Training Loss 0.6603 (0.6618)	Training Prec@1 40.625 (42.213)	Training Prec@5 50.781 (52.953)	
2022-04-01 10:22:02,873: ============================================================
2022-04-01 10:22:49,385: time cost, forward:0.1423340219594397, backward:0.03655694681597233, data cost:0.2587206712382627 
2022-04-01 10:22:49,385: ============================================================
2022-04-01 10:22:49,386: Epoch 28/31 Batch 2900/7662 eta: 3:35:07.188235	Training Loss 0.6551 (0.6617)	Training Prec@1 41.992 (42.239)	Training Prec@5 53.906 (52.974)	
2022-04-01 10:22:49,386: ============================================================
2022-04-01 10:23:33,646: time cost, forward:0.14237912077234363, backward:0.03652070092534812, data cost:0.25903198773879216 
2022-04-01 10:23:33,661: ============================================================
2022-04-01 10:23:33,662: Epoch 28/31 Batch 3000/7662 eta: 3:24:01.682516	Training Loss 0.6481 (0.6615)	Training Prec@1 45.703 (42.278)	Training Prec@5 57.422 (53.010)	
2022-04-01 10:23:33,662: ============================================================
2022-04-01 10:24:17,612: time cost, forward:0.14245814044616345, backward:0.03652072837561244, data cost:0.2589952619508914 
2022-04-01 10:24:17,613: ============================================================
2022-04-01 10:24:17,613: Epoch 28/31 Batch 3100/7662 eta: 3:21:48.313070	Training Loss 0.6503 (0.6614)	Training Prec@1 44.727 (42.315)	Training Prec@5 55.469 (53.039)	
2022-04-01 10:24:17,613: ============================================================
2022-04-01 10:25:01,963: time cost, forward:0.14278784928078875, backward:0.03651684423877732, data cost:0.25881957739507755 
2022-04-01 10:25:01,963: ============================================================
2022-04-01 10:25:01,964: Epoch 28/31 Batch 3200/7662 eta: 3:22:53.774730	Training Loss 0.6584 (0.6612)	Training Prec@1 44.336 (42.343)	Training Prec@5 55.664 (53.066)	
2022-04-01 10:25:01,964: ============================================================
2022-04-01 10:25:46,301: time cost, forward:0.14250291467038168, backward:0.03645672918124862, data cost:0.2592986521846636 
2022-04-01 10:25:46,302: ============================================================
2022-04-01 10:25:46,302: Epoch 28/31 Batch 3300/7662 eta: 3:22:06.049192	Training Loss 0.6493 (0.6611)	Training Prec@1 46.094 (42.381)	Training Prec@5 56.641 (53.104)	
2022-04-01 10:25:46,302: ============================================================
2022-04-01 10:26:30,554: time cost, forward:0.1425792252747372, backward:0.036486788264580704, data cost:0.25931191661842573 
2022-04-01 10:26:30,568: ============================================================
2022-04-01 10:26:30,569: Epoch 28/31 Batch 3400/7662 eta: 3:21:02.246669	Training Loss 0.6550 (0.6609)	Training Prec@1 42.188 (42.426)	Training Prec@5 53.711 (53.153)	
2022-04-01 10:26:30,569: ============================================================
2022-04-01 10:27:15,249: time cost, forward:0.14284252064266897, backward:0.03658585835947722, data cost:0.2591540168850515 
2022-04-01 10:27:15,249: ============================================================
2022-04-01 10:27:15,250: Epoch 28/31 Batch 3500/7662 eta: 3:22:10.436662	Training Loss 0.6492 (0.6608)	Training Prec@1 44.922 (42.475)	Training Prec@5 56.055 (53.200)	
2022-04-01 10:27:15,250: ============================================================
2022-04-01 10:27:58,450: time cost, forward:0.14252060762740865, backward:0.03654166439169809, data cost:0.2593142002547705 
2022-04-01 10:27:58,451: ============================================================
2022-04-01 10:27:58,451: Epoch 28/31 Batch 3600/7662 eta: 3:14:45.549599	Training Loss 0.6597 (0.6606)	Training Prec@1 41.797 (42.509)	Training Prec@5 53.125 (53.237)	
2022-04-01 10:27:58,451: ============================================================
2022-04-01 10:28:44,893: time cost, forward:0.1434995870262779, backward:0.03663421405525135, data cost:0.25890918292365034 
2022-04-01 10:28:44,893: ============================================================
2022-04-01 10:28:44,893: Epoch 28/31 Batch 3700/7662 eta: 3:28:35.750612	Training Loss 0.6554 (0.6605)	Training Prec@1 44.141 (42.538)	Training Prec@5 52.930 (53.263)	
2022-04-01 10:28:44,894: ============================================================
2022-04-01 10:29:28,077: time cost, forward:0.14346793658735252, backward:0.036663304570161155, data cost:0.25873371631605246 
2022-04-01 10:29:28,077: ============================================================
2022-04-01 10:29:28,077: Epoch 28/31 Batch 3800/7662 eta: 3:13:14.492648	Training Loss 0.6503 (0.6603)	Training Prec@1 46.680 (42.587)	Training Prec@5 56.055 (53.300)	
2022-04-01 10:29:28,077: ============================================================
2022-04-01 10:30:14,526: time cost, forward:0.14385462944615832, backward:0.03672600440656139, data cost:0.2589044017527586 
2022-04-01 10:30:14,526: ============================================================
2022-04-01 10:30:14,526: Epoch 28/31 Batch 3900/7662 eta: 3:27:04.579905	Training Loss 0.6448 (0.6602)	Training Prec@1 47.852 (42.628)	Training Prec@5 60.547 (53.336)	
2022-04-01 10:30:14,526: ============================================================
2022-04-01 10:30:56,995: time cost, forward:0.14297876759867992, backward:0.0367008711463602, data cost:0.2594211353126482 
2022-04-01 10:30:56,995: ============================================================
2022-04-01 10:30:56,995: Epoch 28/31 Batch 4000/7662 eta: 3:08:37.608566	Training Loss 0.6546 (0.6601)	Training Prec@1 41.211 (42.660)	Training Prec@5 52.734 (53.366)	
2022-04-01 10:30:56,995: ============================================================
2022-04-01 10:31:41,809: time cost, forward:0.1429166886305687, backward:0.036686214594528074, data cost:0.2596949721929881 
2022-04-01 10:31:41,809: ============================================================
2022-04-01 10:31:41,810: Epoch 28/31 Batch 4100/7662 eta: 3:18:17.741180	Training Loss 0.6480 (0.6599)	Training Prec@1 47.852 (42.710)	Training Prec@5 56.641 (53.415)	
2022-04-01 10:31:41,810: ============================================================
2022-04-01 10:32:27,102: time cost, forward:0.143032555865174, backward:0.03667516343847403, data cost:0.2598949047632801 
2022-04-01 10:32:27,103: ============================================================
2022-04-01 10:32:27,103: Epoch 28/31 Batch 4200/7662 eta: 3:19:39.684927	Training Loss 0.6574 (0.6597)	Training Prec@1 42.773 (42.751)	Training Prec@5 54.102 (53.450)	
2022-04-01 10:32:27,103: ============================================================
2022-04-01 10:33:16,078: time cost, forward:0.14384925950541277, backward:0.036702453826687784, data cost:0.26019358374291063 
2022-04-01 10:33:16,092: ============================================================
2022-04-01 10:33:16,092: Epoch 28/31 Batch 4300/7662 eta: 3:35:08.016395	Training Loss 0.6510 (0.6596)	Training Prec@1 46.484 (42.793)	Training Prec@5 56.250 (53.492)	
2022-04-01 10:33:16,092: ============================================================
2022-04-01 10:34:02,104: time cost, forward:0.14440629487147139, backward:0.03668574876041677, data cost:0.2600447076319239 
2022-04-01 10:34:02,104: ============================================================
2022-04-01 10:34:02,104: Epoch 28/31 Batch 4400/7662 eta: 3:21:17.846796	Training Loss 0.6502 (0.6594)	Training Prec@1 46.875 (42.833)	Training Prec@5 56.641 (53.527)	
2022-04-01 10:34:02,104: ============================================================
2022-04-01 10:34:47,668: time cost, forward:0.14482625655848122, backward:0.036662539526419416, data cost:0.2599986306453551 
2022-04-01 10:34:47,668: ============================================================
2022-04-01 10:34:47,669: Epoch 28/31 Batch 4500/7662 eta: 3:18:34.567613	Training Loss 0.6633 (0.6593)	Training Prec@1 40.820 (42.879)	Training Prec@5 51.172 (53.566)	
2022-04-01 10:34:47,669: ============================================================
2022-04-01 10:35:32,118: time cost, forward:0.14409269304684022, backward:0.036605128621920266, data cost:0.2608405325458889 
2022-04-01 10:35:32,118: ============================================================
2022-04-01 10:35:32,118: Epoch 28/31 Batch 4600/7662 eta: 3:12:58.774116	Training Loss 0.6537 (0.6591)	Training Prec@1 42.969 (42.919)	Training Prec@5 55.078 (53.603)	
2022-04-01 10:35:32,119: ============================================================
2022-04-01 10:36:18,394: time cost, forward:0.14404401842090114, backward:0.03660801451975905, data cost:0.26132441997832506 
2022-04-01 10:36:18,395: ============================================================
2022-04-01 10:36:18,395: Epoch 28/31 Batch 4700/7662 eta: 3:20:08.274814	Training Loss 0.6593 (0.6590)	Training Prec@1 42.383 (42.966)	Training Prec@5 51.172 (53.641)	
2022-04-01 10:36:18,395: ============================================================
2022-04-01 10:37:02,003: time cost, forward:0.1440336928314953, backward:0.03662478315206735, data cost:0.26117507292097075 
2022-04-01 10:37:02,003: ============================================================
2022-04-01 10:37:02,004: Epoch 28/31 Batch 4800/7662 eta: 3:07:52.442393	Training Loss 0.6529 (0.6588)	Training Prec@1 43.750 (43.011)	Training Prec@5 54.492 (53.682)	
2022-04-01 10:37:02,004: ============================================================
2022-04-01 10:37:48,141: time cost, forward:0.14410021558638178, backward:0.03666659159717766, data cost:0.261456459097581 
2022-04-01 10:37:48,142: ============================================================
2022-04-01 10:37:48,143: Epoch 28/31 Batch 4900/7662 eta: 3:18:00.311265	Training Loss 0.6523 (0.6586)	Training Prec@1 45.508 (43.059)	Training Prec@5 54.883 (53.726)	
2022-04-01 10:37:48,143: ============================================================
2022-04-01 10:38:34,507: time cost, forward:0.14449856848353312, backward:0.03668297403071923, data cost:0.2614524826619071 
2022-04-01 10:38:34,507: ============================================================
2022-04-01 10:38:34,508: Epoch 28/31 Batch 5000/7662 eta: 3:18:12.148151	Training Loss 0.6556 (0.6586)	Training Prec@1 45.312 (43.095)	Training Prec@5 55.664 (53.761)	
2022-04-01 10:38:34,508: ============================================================
2022-04-01 10:39:22,742: time cost, forward:0.14521686052149196, backward:0.036759592827966946, data cost:0.2614205748129181 
2022-04-01 10:39:22,742: ============================================================
2022-04-01 10:39:22,742: Epoch 28/31 Batch 5100/7662 eta: 3:25:23.509260	Training Loss 0.6432 (0.6584)	Training Prec@1 45.703 (43.130)	Training Prec@5 55.859 (53.794)	
2022-04-01 10:39:22,743: ============================================================
2022-04-01 10:40:07,895: time cost, forward:0.14549358185953212, backward:0.036835488687916244, data cost:0.26120341326278274 
2022-04-01 10:40:07,896: ============================================================
2022-04-01 10:40:07,897: Epoch 28/31 Batch 5200/7662 eta: 3:11:31.198028	Training Loss 0.6500 (0.6583)	Training Prec@1 45.703 (43.167)	Training Prec@5 58.203 (53.831)	
2022-04-01 10:40:07,897: ============================================================
2022-04-01 10:40:56,720: time cost, forward:0.1463103522937643, backward:0.036905147327884545, data cost:0.2611286038609131 
2022-04-01 10:40:56,720: ============================================================
2022-04-01 10:40:56,720: Epoch 28/31 Batch 5300/7662 eta: 3:26:16.372220	Training Loss 0.6544 (0.6581)	Training Prec@1 43.164 (43.214)	Training Prec@5 54.297 (53.877)	
2022-04-01 10:40:56,720: ============================================================
2022-04-01 10:41:41,617: time cost, forward:0.14654445551041873, backward:0.03689562795250079, data cost:0.2609719962935952 
2022-04-01 10:41:41,617: ============================================================
2022-04-01 10:41:41,617: Epoch 28/31 Batch 5400/7662 eta: 3:08:56.034278	Training Loss 0.6486 (0.6580)	Training Prec@1 46.289 (43.250)	Training Prec@5 58.398 (53.910)	
2022-04-01 10:41:41,617: ============================================================
2022-04-01 10:42:29,990: time cost, forward:0.1469258509412378, backward:0.0369109109783849, data cost:0.2612629628740759 
2022-04-01 10:42:29,999: ============================================================
2022-04-01 10:42:29,999: Epoch 28/31 Batch 5500/7662 eta: 3:22:47.600085	Training Loss 0.6506 (0.6578)	Training Prec@1 45.312 (43.287)	Training Prec@5 56.641 (53.946)	
2022-04-01 10:42:29,999: ============================================================
2022-04-01 10:43:19,107: time cost, forward:0.1474601171936046, backward:0.03692007431027548, data cost:0.26154279998422286 
2022-04-01 10:43:19,108: ============================================================
2022-04-01 10:43:19,108: Epoch 28/31 Batch 5600/7662 eta: 3:25:01.211696	Training Loss 0.6488 (0.6577)	Training Prec@1 47.656 (43.331)	Training Prec@5 60.352 (53.989)	
2022-04-01 10:43:19,108: ============================================================
2022-04-01 10:44:06,572: time cost, forward:0.14819886316686665, backward:0.03695586284517635, data cost:0.2612385173746736 
2022-04-01 10:44:06,572: ============================================================
2022-04-01 10:44:06,572: Epoch 28/31 Batch 5700/7662 eta: 3:17:21.912620	Training Loss 0.6432 (0.6575)	Training Prec@1 48.633 (43.371)	Training Prec@5 56.055 (54.027)	
2022-04-01 10:44:06,572: ============================================================
2022-04-01 10:44:52,486: time cost, forward:0.14860987157570038, backward:0.0370318284423665, data cost:0.2609768503389393 
2022-04-01 10:44:52,486: ============================================================
2022-04-01 10:44:52,487: Epoch 28/31 Batch 5800/7662 eta: 3:10:09.221885	Training Loss 0.6505 (0.6574)	Training Prec@1 45.312 (43.411)	Training Prec@5 55.859 (54.065)	
2022-04-01 10:44:52,487: ============================================================
2022-04-01 10:45:35,975: time cost, forward:0.1482645154181204, backward:0.03703268460650266, data cost:0.2611042473917998 
2022-04-01 10:45:35,976: ============================================================
2022-04-01 10:45:35,977: Epoch 28/31 Batch 5900/7662 eta: 2:59:23.392913	Training Loss 0.6465 (0.6572)	Training Prec@1 45.898 (43.454)	Training Prec@5 55.273 (54.107)	
2022-04-01 10:45:35,978: ============================================================
2022-04-01 10:46:23,077: time cost, forward:0.14867171225378484, backward:0.03704004944274974, data cost:0.2610848307271742 
2022-04-01 10:46:23,077: ============================================================
2022-04-01 10:46:23,077: Epoch 28/31 Batch 6000/7662 eta: 3:13:29.744855	Training Loss 0.6440 (0.6571)	Training Prec@1 46.875 (43.497)	Training Prec@5 58.203 (54.146)	
2022-04-01 10:46:23,077: ============================================================
2022-04-01 10:47:06,804: time cost, forward:0.14872018179554963, backward:0.037030154319058914, data cost:0.2608805579579371 
2022-04-01 10:47:06,805: ============================================================
2022-04-01 10:47:06,805: Epoch 28/31 Batch 6100/7662 eta: 2:58:54.811167	Training Loss 0.6486 (0.6569)	Training Prec@1 45.312 (43.537)	Training Prec@5 56.641 (54.184)	
2022-04-01 10:47:06,806: ============================================================
2022-04-01 10:47:52,908: time cost, forward:0.14898557073744215, backward:0.037039842965584026, data cost:0.2608167227092607 
2022-04-01 10:47:52,920: ============================================================
2022-04-01 10:47:52,920: Epoch 28/31 Batch 6200/7662 eta: 3:07:54.631112	Training Loss 0.6436 (0.6568)	Training Prec@1 48.633 (43.576)	Training Prec@5 59.961 (54.223)	
2022-04-01 10:47:52,920: ============================================================
2022-04-01 10:48:42,387: time cost, forward:0.14963259744651736, backward:0.03707793137822422, data cost:0.2608696269050328 
2022-04-01 10:48:42,396: ============================================================
2022-04-01 10:48:42,397: Epoch 28/31 Batch 6300/7662 eta: 3:20:47.050990	Training Loss 0.6358 (0.6566)	Training Prec@1 50.391 (43.616)	Training Prec@5 61.133 (54.262)	
2022-04-01 10:48:42,397: ============================================================
2022-04-01 10:49:28,408: time cost, forward:0.14974240564446764, backward:0.03710234491205491, data cost:0.26093316953766066 
2022-04-01 10:49:28,408: ============================================================
2022-04-01 10:49:28,408: Epoch 28/31 Batch 6400/7662 eta: 3:05:57.410529	Training Loss 0.6471 (0.6565)	Training Prec@1 45.508 (43.649)	Training Prec@5 57.812 (54.296)	
2022-04-01 10:49:28,409: ============================================================
2022-04-01 10:50:14,946: time cost, forward:0.15005810489322904, backward:0.0371139133172799, data cost:0.26084970778585453 
2022-04-01 10:50:14,946: ============================================================
2022-04-01 10:50:14,947: Epoch 28/31 Batch 6500/7662 eta: 3:07:18.489570	Training Loss 0.6378 (0.6563)	Training Prec@1 50.000 (43.686)	Training Prec@5 58.789 (54.330)	
2022-04-01 10:50:14,947: ============================================================
2022-04-01 10:51:02,063: time cost, forward:0.15041620537338338, backward:0.037130866633850367, data cost:0.2608182929577042 
2022-04-01 10:51:02,063: ============================================================
2022-04-01 10:51:02,063: Epoch 28/31 Batch 6600/7662 eta: 3:08:51.086624	Training Loss 0.6433 (0.6562)	Training Prec@1 47.852 (43.727)	Training Prec@5 59.180 (54.370)	
2022-04-01 10:51:02,063: ============================================================
2022-04-01 10:51:53,128: time cost, forward:0.1513579671534874, backward:0.03719936838646863, data cost:0.2607236735979858 
2022-04-01 10:51:53,141: ============================================================
2022-04-01 10:51:53,142: Epoch 28/31 Batch 6700/7662 eta: 3:23:52.766848	Training Loss 0.6411 (0.6560)	Training Prec@1 48.633 (43.770)	Training Prec@5 58.789 (54.412)	
2022-04-01 10:51:53,142: ============================================================
2022-04-01 10:52:39,961: time cost, forward:0.1514503812768877, backward:0.03717521047360723, data cost:0.2609330213215443 
2022-04-01 10:52:39,961: ============================================================
2022-04-01 10:52:39,961: Epoch 28/31 Batch 6800/7662 eta: 3:06:06.065848	Training Loss 0.6476 (0.6559)	Training Prec@1 47.070 (43.813)	Training Prec@5 57.031 (54.450)	
2022-04-01 10:52:39,962: ============================================================
2022-04-01 10:53:25,869: time cost, forward:0.15167452041818397, backward:0.037152563701385796, data cost:0.26085790911866785 
2022-04-01 10:53:25,869: ============================================================
2022-04-01 10:53:25,870: Epoch 28/31 Batch 6900/7662 eta: 3:01:42.777323	Training Loss 0.6464 (0.6557)	Training Prec@1 46.875 (43.851)	Training Prec@5 57.031 (54.485)	
2022-04-01 10:53:25,870: ============================================================
2022-04-01 10:54:09,926: time cost, forward:0.1515336152161338, backward:0.037120028723476785, data cost:0.26088597389915563 
2022-04-01 10:54:09,926: ============================================================
2022-04-01 10:54:09,926: Epoch 28/31 Batch 7000/7662 eta: 2:53:38.924269	Training Loss 0.6440 (0.6556)	Training Prec@1 47.461 (43.892)	Training Prec@5 59.180 (54.524)	
2022-04-01 10:54:09,927: ============================================================
2022-04-01 10:54:55,909: time cost, forward:0.15147250073781263, backward:0.037135459685228224, data cost:0.26107072981331847 
2022-04-01 10:54:55,910: ============================================================
2022-04-01 10:54:55,910: Epoch 28/31 Batch 7100/7662 eta: 3:00:28.685408	Training Loss 0.6504 (0.6554)	Training Prec@1 44.141 (43.930)	Training Prec@5 52.930 (54.560)	
2022-04-01 10:54:55,910: ============================================================
2022-04-01 10:55:42,127: time cost, forward:0.15171348818442376, backward:0.037144978686593805, data cost:0.26098154418782105 
2022-04-01 10:55:42,127: ============================================================
2022-04-01 10:55:42,128: Epoch 28/31 Batch 7200/7662 eta: 3:00:37.584337	Training Loss 0.6529 (0.6553)	Training Prec@1 43.555 (43.969)	Training Prec@5 53.125 (54.595)	
2022-04-01 10:55:42,128: ============================================================
2022-04-01 10:56:28,532: time cost, forward:0.1519453151860716, backward:0.037159677727089495, data cost:0.2609174551743647 
2022-04-01 10:56:28,533: ============================================================
2022-04-01 10:56:28,534: Epoch 28/31 Batch 7300/7662 eta: 3:00:35.372266	Training Loss 0.6530 (0.6551)	Training Prec@1 43.945 (44.011)	Training Prec@5 53.516 (54.635)	
2022-04-01 10:56:28,535: ============================================================
2022-04-01 10:57:17,383: time cost, forward:0.1524066155239414, backward:0.037179030893879784, data cost:0.26095347273009806 
2022-04-01 10:57:17,384: ============================================================
2022-04-01 10:57:17,384: Epoch 28/31 Batch 7400/7662 eta: 3:09:17.139249	Training Loss 0.6488 (0.6550)	Training Prec@1 46.289 (44.054)	Training Prec@5 55.664 (54.673)	
2022-04-01 10:57:17,384: ============================================================
2022-04-01 10:58:04,259: time cost, forward:0.15251414030929425, backward:0.03719657859034118, data cost:0.2610572757904077 
2022-04-01 10:58:04,259: ============================================================
2022-04-01 10:58:04,259: Epoch 28/31 Batch 7500/7662 eta: 3:00:51.204906	Training Loss 0.6522 (0.6548)	Training Prec@1 44.727 (44.098)	Training Prec@5 53.320 (54.709)	
2022-04-01 10:58:04,260: ============================================================
2022-04-01 10:58:50,121: time cost, forward:0.15250257062730013, backward:0.0372044127118291, data cost:0.26114413097887107 
2022-04-01 10:58:50,122: ============================================================
2022-04-01 10:58:50,122: Epoch 28/31 Batch 7600/7662 eta: 2:56:10.822226	Training Loss 0.6383 (0.6547)	Training Prec@1 50.195 (44.138)	Training Prec@5 59.570 (54.747)	
2022-04-01 10:58:50,122: ============================================================
2022-04-01 10:59:19,876: Epoch: 28/31 eta: 2:55:41.928920	Training Loss 0.6389 (0.6546)	Training Prec@1 48.047 (44.162)	Training Prec@5 59.570 (54.769)
2022-04-01 10:59:19,877: ============================================================
2022-04-01 11:00:04,233: time cost, forward:0.12029060691294044, backward:0.03701417133061573, data cost:0.2882227006584707 
2022-04-01 11:00:04,233: ============================================================
2022-04-01 11:00:04,234: Epoch 29/31 Batch 100/7662 eta: 2:49:10.892932	Training Loss 0.6381 (0.6365)	Training Prec@1 49.805 (49.594)	Training Prec@5 58.789 (59.939)	
2022-04-01 11:00:04,234: ============================================================
2022-04-01 11:00:49,274: time cost, forward:0.1331978730819932, backward:0.03679357461593858, data cost:0.2773904009680053 
2022-04-01 11:00:49,275: ============================================================
2022-04-01 11:00:49,275: Epoch 29/31 Batch 200/7662 eta: 2:51:03.582993	Training Loss 0.6348 (0.6365)	Training Prec@1 52.539 (49.753)	Training Prec@5 59.961 (60.021)	
2022-04-01 11:00:49,275: ============================================================
2022-04-01 11:01:39,385: time cost, forward:0.13929409486394265, backward:0.03687706599666123, data cost:0.28916415641937765 
2022-04-01 11:01:39,386: ============================================================
2022-04-01 11:01:39,386: Epoch 29/31 Batch 300/7662 eta: 3:09:28.673984	Training Loss 0.6393 (0.6361)	Training Prec@1 45.117 (49.777)	Training Prec@5 56.055 (60.122)	
2022-04-01 11:01:39,386: ============================================================
2022-04-01 11:02:23,498: time cost, forward:0.14018051964896067, backward:0.036634299390596856, data cost:0.2820805051272973 
2022-04-01 11:02:23,499: ============================================================
2022-04-01 11:02:23,499: Epoch 29/31 Batch 400/7662 eta: 2:46:03.794136	Training Loss 0.6342 (0.6362)	Training Prec@1 48.438 (49.649)	Training Prec@5 59.180 (60.043)	
2022-04-01 11:02:23,500: ============================================================
2022-04-01 11:03:10,208: time cost, forward:0.14300389328079377, backward:0.03755954128945758, data cost:0.27969241428948594 
2022-04-01 11:03:10,209: ============================================================
2022-04-01 11:03:10,209: Epoch 29/31 Batch 500/7662 eta: 2:55:03.714648	Training Loss 0.6244 (0.6361)	Training Prec@1 54.883 (49.619)	Training Prec@5 66.016 (60.034)	
2022-04-01 11:03:10,209: ============================================================
2022-04-01 11:03:56,290: time cost, forward:0.14698680573592401, backward:0.03768950830118883, data cost:0.275729864387958 
2022-04-01 11:03:56,290: ============================================================
2022-04-01 11:03:56,291: Epoch 29/31 Batch 600/7662 eta: 2:51:56.309878	Training Loss 0.6434 (0.6363)	Training Prec@1 46.680 (49.648)	Training Prec@5 57.422 (60.070)	
2022-04-01 11:03:56,291: ============================================================
2022-04-01 11:04:41,151: time cost, forward:0.14663239439499054, backward:0.03685605099613916, data cost:0.2750751416229554 
2022-04-01 11:04:41,151: ============================================================
2022-04-01 11:04:41,152: Epoch 29/31 Batch 700/7662 eta: 2:46:38.143240	Training Loss 0.6331 (0.6361)	Training Prec@1 51.953 (49.708)	Training Prec@5 62.109 (60.118)	
2022-04-01 11:04:41,152: ============================================================
2022-04-01 11:05:28,191: time cost, forward:0.1511496659065218, backward:0.03726525449931845, data cost:0.27164904226797243 
2022-04-01 11:05:28,192: ============================================================
2022-04-01 11:05:28,192: Epoch 29/31 Batch 800/7662 eta: 2:53:56.779497	Training Loss 0.6424 (0.6359)	Training Prec@1 44.727 (49.732)	Training Prec@5 56.836 (60.130)	
2022-04-01 11:05:28,192: ============================================================
2022-04-01 11:06:15,550: time cost, forward:0.15216633395703139, backward:0.03742067514192541, data cost:0.2719007320743514 
2022-04-01 11:06:15,550: ============================================================
2022-04-01 11:06:15,551: Epoch 29/31 Batch 900/7662 eta: 2:54:20.167420	Training Loss 0.6392 (0.6358)	Training Prec@1 50.977 (49.761)	Training Prec@5 59.961 (60.139)	
2022-04-01 11:06:15,551: ============================================================
2022-04-01 11:07:02,411: time cost, forward:0.15321373199676727, backward:0.037508371236684684, data cost:0.27129313179680536 
2022-04-01 11:07:02,411: ============================================================
2022-04-01 11:07:02,412: Epoch 29/31 Batch 1000/7662 eta: 2:51:43.313720	Training Loss 0.6380 (0.6358)	Training Prec@1 49.414 (49.740)	Training Prec@5 59.180 (60.120)	
2022-04-01 11:07:02,412: ============================================================
2022-04-01 11:07:49,855: time cost, forward:0.15511670234097039, backward:0.0376396029509665, data cost:0.27033245639436565 
2022-04-01 11:07:49,866: ============================================================
2022-04-01 11:07:49,866: Epoch 29/31 Batch 1100/7662 eta: 2:53:06.425738	Training Loss 0.6258 (0.6357)	Training Prec@1 53.125 (49.735)	Training Prec@5 62.695 (60.117)	
2022-04-01 11:07:49,866: ============================================================
2022-04-01 11:08:37,784: time cost, forward:0.15779683906103392, backward:0.03756743058052731, data cost:0.26908408352690405 
2022-04-01 11:08:37,785: ============================================================
2022-04-01 11:08:37,785: Epoch 29/31 Batch 1200/7662 eta: 2:53:59.990130	Training Loss 0.6321 (0.6357)	Training Prec@1 49.219 (49.761)	Training Prec@5 58.398 (60.135)	
2022-04-01 11:08:37,785: ============================================================
2022-04-01 11:09:25,563: time cost, forward:0.15957376955104297, backward:0.03768473115675811, data cost:0.26814554488319353 
2022-04-01 11:09:25,564: ============================================================
2022-04-01 11:09:25,564: Epoch 29/31 Batch 1300/7662 eta: 2:52:41.838254	Training Loss 0.6337 (0.6356)	Training Prec@1 50.000 (49.793)	Training Prec@5 59.961 (60.140)	
2022-04-01 11:09:25,564: ============================================================
2022-04-01 11:10:11,328: time cost, forward:0.1594577195220031, backward:0.03767164542557428, data cost:0.2676778686651594 
2022-04-01 11:10:11,329: ============================================================
2022-04-01 11:10:11,329: Epoch 29/31 Batch 1400/7662 eta: 2:44:39.324953	Training Loss 0.6311 (0.6355)	Training Prec@1 51.172 (49.809)	Training Prec@5 61.133 (60.160)	
2022-04-01 11:10:11,329: ============================================================
2022-04-01 11:10:59,342: time cost, forward:0.1610608953408514, backward:0.03769930113626369, data cost:0.26703140225070093 
2022-04-01 11:10:59,343: ============================================================
2022-04-01 11:10:59,343: Epoch 29/31 Batch 1500/7662 eta: 2:51:56.709100	Training Loss 0.6451 (0.6354)	Training Prec@1 48.047 (49.839)	Training Prec@5 60.156 (60.182)	
2022-04-01 11:10:59,343: ============================================================
2022-04-01 11:11:46,409: time cost, forward:0.16156558322489, backward:0.03777631466801723, data cost:0.2666795425224185 
2022-04-01 11:11:46,409: ============================================================
2022-04-01 11:11:46,410: Epoch 29/31 Batch 1600/7662 eta: 2:47:46.182813	Training Loss 0.6231 (0.6353)	Training Prec@1 54.297 (49.882)	Training Prec@5 61.914 (60.210)	
2022-04-01 11:11:46,410: ============================================================
2022-04-01 11:12:32,483: time cost, forward:0.16158576036916894, backward:0.037722501984899924, data cost:0.26635566425716406 
2022-04-01 11:12:32,483: ============================================================
2022-04-01 11:12:32,483: Epoch 29/31 Batch 1700/7662 eta: 2:43:27.690441	Training Loss 0.6366 (0.6352)	Training Prec@1 49.609 (49.906)	Training Prec@5 60.547 (60.236)	
2022-04-01 11:12:32,483: ============================================================
2022-04-01 11:13:18,505: time cost, forward:0.1612112048998881, backward:0.037758229373891596, data cost:0.26634835998106826 
2022-04-01 11:13:18,505: ============================================================
2022-04-01 11:13:18,505: Epoch 29/31 Batch 1800/7662 eta: 2:42:30.726972	Training Loss 0.6355 (0.6350)	Training Prec@1 49.414 (49.945)	Training Prec@5 58.594 (60.269)	
2022-04-01 11:13:18,506: ============================================================
2022-04-01 11:14:05,610: time cost, forward:0.16142988669489358, backward:0.03770222395203376, data cost:0.2664535006703421 
2022-04-01 11:14:05,611: ============================================================
2022-04-01 11:14:05,611: Epoch 29/31 Batch 1900/7662 eta: 2:45:33.185900	Training Loss 0.6409 (0.6350)	Training Prec@1 48.438 (49.943)	Training Prec@5 58.594 (60.256)	
2022-04-01 11:14:05,611: ============================================================
2022-04-01 11:14:50,547: time cost, forward:0.16063065788875883, backward:0.0375951673460937, data cost:0.2665254107232449 
2022-04-01 11:14:50,548: ============================================================
2022-04-01 11:14:50,548: Epoch 29/31 Batch 2000/7662 eta: 2:37:10.853042	Training Loss 0.6404 (0.6350)	Training Prec@1 47.852 (49.943)	Training Prec@5 59.375 (60.267)	
2022-04-01 11:14:50,548: ============================================================
2022-04-01 11:15:35,099: time cost, forward:0.15984618192402847, backward:0.03758163495311401, data cost:0.26633330297901725 
2022-04-01 11:15:35,099: ============================================================
2022-04-01 11:15:35,099: Epoch 29/31 Batch 2100/7662 eta: 2:35:05.514051	Training Loss 0.6286 (0.6349)	Training Prec@1 51.367 (49.969)	Training Prec@5 61.719 (60.290)	
2022-04-01 11:15:35,100: ============================================================
2022-04-01 11:16:19,758: time cost, forward:0.15901451015429044, backward:0.03748490193476727, data cost:0.26651219239610063 
2022-04-01 11:16:19,758: ============================================================
2022-04-01 11:16:19,758: Epoch 29/31 Batch 2200/7662 eta: 2:34:43.253477	Training Loss 0.6300 (0.6348)	Training Prec@1 50.781 (49.979)	Training Prec@5 61.328 (60.291)	
2022-04-01 11:16:19,759: ============================================================
2022-04-01 11:17:08,173: time cost, forward:0.1599151163113641, backward:0.03755945503945037, data cost:0.26637201300907676 
2022-04-01 11:17:08,184: ============================================================
2022-04-01 11:17:08,184: Epoch 29/31 Batch 2300/7662 eta: 2:46:57.808667	Training Loss 0.6375 (0.6348)	Training Prec@1 48.828 (49.998)	Training Prec@5 59.570 (60.304)	
2022-04-01 11:17:08,184: ============================================================
2022-04-01 11:17:53,185: time cost, forward:0.16015012247356686, backward:0.037568029635844005, data cost:0.2655603225750941 
2022-04-01 11:17:53,186: ============================================================
2022-04-01 11:17:53,187: Epoch 29/31 Batch 2400/7662 eta: 2:34:24.757209	Training Loss 0.6289 (0.6347)	Training Prec@1 50.000 (50.026)	Training Prec@5 60.547 (60.330)	
2022-04-01 11:17:53,188: ============================================================
2022-04-01 11:18:39,324: time cost, forward:0.15991809178276414, backward:0.03750314174436865, data cost:0.2657585695487301 
2022-04-01 11:18:39,324: ============================================================
2022-04-01 11:18:39,325: Epoch 29/31 Batch 2500/7662 eta: 2:37:32.187290	Training Loss 0.6365 (0.6346)	Training Prec@1 49.219 (50.049)	Training Prec@5 58.594 (60.351)	
2022-04-01 11:18:39,325: ============================================================
2022-04-01 11:19:23,319: time cost, forward:0.1594230587457684, backward:0.037452395854889776, data cost:0.2653763333665907 
2022-04-01 11:19:23,320: ============================================================
2022-04-01 11:19:23,320: Epoch 29/31 Batch 2600/7662 eta: 2:29:29.309087	Training Loss 0.6286 (0.6345)	Training Prec@1 51.953 (50.074)	Training Prec@5 63.086 (60.371)	
2022-04-01 11:19:23,320: ============================================================
2022-04-01 11:20:09,824: time cost, forward:0.15907342321742857, backward:0.03743269082218155, data cost:0.2658373333428161 
2022-04-01 11:20:09,825: ============================================================
2022-04-01 11:20:09,836: Epoch 29/31 Batch 2700/7662 eta: 2:37:16.664844	Training Loss 0.6305 (0.6344)	Training Prec@1 51.758 (50.114)	Training Prec@5 62.109 (60.402)	
2022-04-01 11:20:09,836: ============================================================
2022-04-01 11:20:54,174: time cost, forward:0.15883126153227003, backward:0.03740785870649168, data cost:0.2653932486231219 
2022-04-01 11:20:54,184: ============================================================
2022-04-01 11:20:54,186: Epoch 29/31 Batch 2800/7662 eta: 2:29:12.883560	Training Loss 0.6264 (0.6343)	Training Prec@1 51.172 (50.138)	Training Prec@5 60.742 (60.415)	
2022-04-01 11:20:54,186: ============================================================
2022-04-01 11:21:37,597: time cost, forward:0.15800589205849455, backward:0.03734042415046494, data cost:0.2653172902708919 
2022-04-01 11:21:37,598: ============================================================
2022-04-01 11:21:37,598: Epoch 29/31 Batch 2900/7662 eta: 2:25:20.282888	Training Loss 0.6251 (0.6342)	Training Prec@1 53.711 (50.152)	Training Prec@5 62.109 (60.439)	
2022-04-01 11:21:37,598: ============================================================
2022-04-01 11:22:23,520: time cost, forward:0.15784483609417352, backward:0.03734051167627063, data cost:0.2654100226020368 
2022-04-01 11:22:23,520: ============================================================
2022-04-01 11:22:23,521: Epoch 29/31 Batch 3000/7662 eta: 2:32:58.558693	Training Loss 0.6230 (0.6341)	Training Prec@1 54.492 (50.179)	Training Prec@5 65.430 (60.460)	
2022-04-01 11:22:23,521: ============================================================
2022-04-01 11:23:09,383: time cost, forward:0.15731470205584586, backward:0.03727398275675101, data cost:0.265908130333092 
2022-04-01 11:23:09,383: ============================================================
2022-04-01 11:23:09,384: Epoch 29/31 Batch 3100/7662 eta: 2:32:00.779440	Training Loss 0.6346 (0.6340)	Training Prec@1 51.953 (50.201)	Training Prec@5 61.914 (60.475)	
2022-04-01 11:23:09,384: ============================================================
2022-04-01 11:23:53,122: time cost, forward:0.1565530157789807, backward:0.03721924817871399, data cost:0.2659797201904888 
2022-04-01 11:23:53,123: ============================================================
2022-04-01 11:23:53,123: Epoch 29/31 Batch 3200/7662 eta: 2:24:14.682792	Training Loss 0.6355 (0.6339)	Training Prec@1 49.219 (50.229)	Training Prec@5 61.328 (60.508)	
2022-04-01 11:23:53,123: ============================================================
2022-04-01 11:24:37,818: time cost, forward:0.15610824898901618, backward:0.037199555038863796, data cost:0.2660019828464523 
2022-04-01 11:24:37,819: ============================================================
2022-04-01 11:24:37,819: Epoch 29/31 Batch 3300/7662 eta: 2:26:39.326182	Training Loss 0.6337 (0.6338)	Training Prec@1 49.609 (50.254)	Training Prec@5 60.156 (60.528)	
2022-04-01 11:24:37,819: ============================================================
2022-04-01 11:25:20,331: time cost, forward:0.1549450198002653, backward:0.037174893323377006, data cost:0.2661964635212094 
2022-04-01 11:25:20,331: ============================================================
2022-04-01 11:25:20,331: Epoch 29/31 Batch 3400/7662 eta: 2:18:46.904751	Training Loss 0.6294 (0.6337)	Training Prec@1 53.711 (50.279)	Training Prec@5 62.500 (60.548)	
2022-04-01 11:25:20,332: ============================================================
2022-04-01 11:26:04,964: time cost, forward:0.1541347119357798, backward:0.037115735849607805, data cost:0.2667249804668748 
2022-04-01 11:26:04,964: ============================================================
2022-04-01 11:26:04,965: Epoch 29/31 Batch 3500/7662 eta: 2:24:57.671206	Training Loss 0.6408 (0.6336)	Training Prec@1 48.047 (50.302)	Training Prec@5 60.742 (60.569)	
2022-04-01 11:26:04,965: ============================================================
2022-04-01 11:26:49,590: time cost, forward:0.15376435494747517, backward:0.03711323779170531, data cost:0.2667461499534537 
2022-04-01 11:26:49,590: ============================================================
2022-04-01 11:26:49,590: Epoch 29/31 Batch 3600/7662 eta: 2:24:11.632668	Training Loss 0.6253 (0.6335)	Training Prec@1 52.734 (50.323)	Training Prec@5 62.695 (60.588)	
2022-04-01 11:26:49,591: ============================================================
2022-04-01 11:27:35,036: time cost, forward:0.1536127204797048, backward:0.03709172113227277, data cost:0.26682009114288385 
2022-04-01 11:27:35,036: ============================================================
2022-04-01 11:27:35,037: Epoch 29/31 Batch 3700/7662 eta: 2:26:05.189858	Training Loss 0.6342 (0.6334)	Training Prec@1 51.562 (50.362)	Training Prec@5 60.352 (60.621)	
2022-04-01 11:27:35,037: ============================================================
2022-04-01 11:28:18,590: time cost, forward:0.15336302344062888, backward:0.03706239587101506, data cost:0.2664937779099479 
2022-04-01 11:28:18,590: ============================================================
2022-04-01 11:28:18,591: Epoch 29/31 Batch 3800/7662 eta: 2:19:16.689721	Training Loss 0.6240 (0.6333)	Training Prec@1 53.125 (50.387)	Training Prec@5 64.844 (60.642)	
2022-04-01 11:28:18,591: ============================================================
2022-04-01 11:29:01,703: time cost, forward:0.15264258857995128, backward:0.03701348205687725, data cost:0.266584254497441 
2022-04-01 11:29:01,703: ============================================================
2022-04-01 11:29:01,704: Epoch 29/31 Batch 3900/7662 eta: 2:17:09.002276	Training Loss 0.6321 (0.6332)	Training Prec@1 49.805 (50.405)	Training Prec@5 62.109 (60.663)	
2022-04-01 11:29:01,704: ============================================================
2022-04-01 11:29:45,782: time cost, forward:0.15184865161221336, backward:0.036971894405161805, data cost:0.26703499656642904 
2022-04-01 11:29:45,792: ============================================================
2022-04-01 11:29:45,792: Epoch 29/31 Batch 4000/7662 eta: 2:19:31.144567	Training Loss 0.6328 (0.6331)	Training Prec@1 51.758 (50.431)	Training Prec@5 59.766 (60.686)	
2022-04-01 11:29:45,793: ============================================================
2022-04-01 11:30:28,202: time cost, forward:0.15080095111058672, backward:0.03697081535843763, data cost:0.267285403346806 
2022-04-01 11:30:28,202: ============================================================
2022-04-01 11:30:28,202: Epoch 29/31 Batch 4100/7662 eta: 2:13:29.967485	Training Loss 0.6372 (0.6330)	Training Prec@1 49.609 (50.445)	Training Prec@5 61.328 (60.698)	
2022-04-01 11:30:28,203: ============================================================
2022-04-01 11:31:13,196: time cost, forward:0.15088851391119343, backward:0.03698691807351927, data cost:0.26705887062715955 
2022-04-01 11:31:13,196: ============================================================
2022-04-01 11:31:13,196: Epoch 29/31 Batch 4200/7662 eta: 2:20:52.979279	Training Loss 0.6411 (0.6329)	Training Prec@1 46.875 (50.471)	Training Prec@5 59.180 (60.720)	
2022-04-01 11:31:13,196: ============================================================
2022-04-01 11:31:59,545: time cost, forward:0.15099456604759925, backward:0.03697770444369089, data cost:0.2670567804337879 
2022-04-01 11:31:59,545: ============================================================
2022-04-01 11:31:59,546: Epoch 29/31 Batch 4300/7662 eta: 2:24:21.305436	Training Loss 0.6281 (0.6329)	Training Prec@1 50.195 (50.493)	Training Prec@5 59.766 (60.736)	
2022-04-01 11:31:59,546: ============================================================
2022-04-01 11:32:41,443: time cost, forward:0.1499770659429156, backward:0.0368683190745748, data cost:0.2674268194967358 
2022-04-01 11:32:41,443: ============================================================
2022-04-01 11:32:41,444: Epoch 29/31 Batch 4400/7662 eta: 2:09:47.581305	Training Loss 0.6278 (0.6328)	Training Prec@1 52.539 (50.512)	Training Prec@5 62.109 (60.754)	
2022-04-01 11:32:41,444: ============================================================
2022-04-01 11:33:26,096: time cost, forward:0.149442967003413, backward:0.03680074932999705, data cost:0.26784267237939474 
2022-04-01 11:33:26,097: ============================================================
2022-04-01 11:33:26,097: Epoch 29/31 Batch 4500/7662 eta: 2:17:35.061794	Training Loss 0.6265 (0.6326)	Training Prec@1 51.562 (50.548)	Training Prec@5 63.086 (60.783)	
2022-04-01 11:33:26,097: ============================================================
2022-04-01 11:34:11,039: time cost, forward:0.1493323211126624, backward:0.03678889532767319, data cost:0.2678604971509727 
2022-04-01 11:34:11,039: ============================================================
2022-04-01 11:34:11,040: Epoch 29/31 Batch 4600/7662 eta: 2:17:43.623745	Training Loss 0.6277 (0.6326)	Training Prec@1 51.367 (50.569)	Training Prec@5 60.352 (60.803)	
2022-04-01 11:34:11,040: ============================================================
2022-04-01 11:34:55,373: time cost, forward:0.1490386738425038, backward:0.03676879530283816, data cost:0.26794046197807214 
2022-04-01 11:34:55,374: ============================================================
2022-04-01 11:34:55,374: Epoch 29/31 Batch 4700/7662 eta: 2:15:07.410135	Training Loss 0.6375 (0.6325)	Training Prec@1 49.023 (50.590)	Training Prec@5 59.375 (60.825)	
2022-04-01 11:34:55,374: ============================================================
2022-04-01 11:35:41,589: time cost, forward:0.14945647045333427, backward:0.036754503128900703, data cost:0.26767597304803425 
2022-04-01 11:35:41,589: ============================================================
2022-04-01 11:35:41,590: Epoch 29/31 Batch 4800/7662 eta: 2:20:05.216822	Training Loss 0.6198 (0.6324)	Training Prec@1 56.250 (50.606)	Training Prec@5 66.602 (60.842)	
2022-04-01 11:35:41,590: ============================================================
2022-04-01 11:36:27,085: time cost, forward:0.1497114233689348, backward:0.0367458250162966, data cost:0.267444152057256 
2022-04-01 11:36:27,097: ============================================================
2022-04-01 11:36:27,097: Epoch 29/31 Batch 4900/7662 eta: 2:17:10.970405	Training Loss 0.6285 (0.6323)	Training Prec@1 49.609 (50.623)	Training Prec@5 58.789 (60.863)	
2022-04-01 11:36:27,097: ============================================================
2022-04-01 11:37:13,130: time cost, forward:0.15005447769622896, backward:0.03671862044604356, data cost:0.26726732050855057 
2022-04-01 11:37:13,131: ============================================================
2022-04-01 11:37:13,131: Epoch 29/31 Batch 5000/7662 eta: 2:18:00.055329	Training Loss 0.6258 (0.6322)	Training Prec@1 50.391 (50.650)	Training Prec@5 59.570 (60.888)	
2022-04-01 11:37:13,131: ============================================================
2022-04-01 11:37:58,230: time cost, forward:0.1500017488206174, backward:0.036719395708023135, data cost:0.2671979473347429 
2022-04-01 11:37:58,230: ============================================================
2022-04-01 11:37:58,230: Epoch 29/31 Batch 5100/7662 eta: 2:14:26.991394	Training Loss 0.6355 (0.6321)	Training Prec@1 50.391 (50.677)	Training Prec@5 60.352 (60.909)	
2022-04-01 11:37:58,231: ============================================================
2022-04-01 11:38:45,414: time cost, forward:0.15028087032095794, backward:0.03674784447739138, data cost:0.2672471474583137 
2022-04-01 11:38:45,425: ============================================================
2022-04-01 11:38:45,425: Epoch 29/31 Batch 5200/7662 eta: 2:19:54.534690	Training Loss 0.6280 (0.6320)	Training Prec@1 50.586 (50.705)	Training Prec@5 61.523 (60.934)	
2022-04-01 11:38:45,425: ============================================================
2022-04-01 11:39:29,054: time cost, forward:0.15019688095140285, backward:0.03674606054003317, data cost:0.2669940216628127 
2022-04-01 11:39:29,065: ============================================================
2022-04-01 11:39:29,066: Epoch 29/31 Batch 5300/7662 eta: 2:08:38.665096	Training Loss 0.6220 (0.6319)	Training Prec@1 54.883 (50.726)	Training Prec@5 64.062 (60.952)	
2022-04-01 11:39:29,066: ============================================================
2022-04-01 11:40:13,877: time cost, forward:0.1500875454828637, backward:0.03672022619916899, data cost:0.2669983138020645 
2022-04-01 11:40:13,878: ============================================================
2022-04-01 11:40:13,878: Epoch 29/31 Batch 5400/7662 eta: 2:11:21.221253	Training Loss 0.6245 (0.6318)	Training Prec@1 51.562 (50.744)	Training Prec@5 63.867 (60.972)	
2022-04-01 11:40:13,879: ============================================================
2022-04-01 11:41:00,970: time cost, forward:0.1507622766850276, backward:0.03677095875217169, data cost:0.2665723242484823 
2022-04-01 11:41:00,986: ============================================================
2022-04-01 11:41:00,986: Epoch 29/31 Batch 5500/7662 eta: 2:17:17.753036	Training Loss 0.6280 (0.6317)	Training Prec@1 52.148 (50.771)	Training Prec@5 60.742 (60.996)	
2022-04-01 11:41:00,987: ============================================================
2022-04-01 11:41:44,937: time cost, forward:0.15032524669951766, backward:0.03670543580209385, data cost:0.26678454694971054 
2022-04-01 11:41:44,937: ============================================================
2022-04-01 11:41:44,937: Epoch 29/31 Batch 5600/7662 eta: 2:07:21.756220	Training Loss 0.6299 (0.6316)	Training Prec@1 50.586 (50.795)	Training Prec@5 60.547 (61.019)	
2022-04-01 11:41:44,937: ============================================================
2022-04-01 11:42:31,658: time cost, forward:0.15056850588474385, backward:0.03676327234152054, data cost:0.26670733492172355 
2022-04-01 11:42:31,658: ============================================================
2022-04-01 11:42:31,659: Epoch 29/31 Batch 5700/7662 eta: 2:14:36.732502	Training Loss 0.6255 (0.6315)	Training Prec@1 53.906 (50.819)	Training Prec@5 61.719 (61.041)	
2022-04-01 11:42:31,659: ============================================================
2022-04-01 11:43:17,361: time cost, forward:0.15065634832400293, backward:0.036779780781748046, data cost:0.2666431890929397 
2022-04-01 11:43:17,372: ============================================================
2022-04-01 11:43:17,372: Epoch 29/31 Batch 5800/7662 eta: 2:10:56.801049	Training Loss 0.6219 (0.6314)	Training Prec@1 53.906 (50.840)	Training Prec@5 66.211 (61.064)	
2022-04-01 11:43:17,372: ============================================================
2022-04-01 11:44:02,256: time cost, forward:0.15080075192035183, backward:0.03679163121716373, data cost:0.26638106803486644 
2022-04-01 11:44:02,256: ============================================================
2022-04-01 11:44:02,256: Epoch 29/31 Batch 5900/7662 eta: 2:07:49.316625	Training Loss 0.6351 (0.6313)	Training Prec@1 52.344 (50.866)	Training Prec@5 61.133 (61.086)	
2022-04-01 11:44:02,256: ============================================================
2022-04-01 11:44:48,708: time cost, forward:0.15108415158038577, backward:0.03683036147485, data cost:0.2662192486707201 
2022-04-01 11:44:48,709: ============================================================
2022-04-01 11:44:48,709: Epoch 29/31 Batch 6000/7662 eta: 2:11:30.960794	Training Loss 0.6271 (0.6312)	Training Prec@1 51.367 (50.893)	Training Prec@5 62.109 (61.112)	
2022-04-01 11:44:48,709: ============================================================
2022-04-01 11:45:32,455: time cost, forward:0.15107028901449948, backward:0.036825015791558224, data cost:0.2659556405195195 
2022-04-01 11:45:32,467: ============================================================
2022-04-01 11:45:32,467: Epoch 29/31 Batch 6100/7662 eta: 2:03:09.424635	Training Loss 0.6118 (0.6311)	Training Prec@1 54.883 (50.915)	Training Prec@5 65.234 (61.133)	
2022-04-01 11:45:32,468: ============================================================
2022-04-01 11:46:20,397: time cost, forward:0.15104644243554505, backward:0.03686021654658557, data cost:0.2663548387314239 
2022-04-01 11:46:20,398: ============================================================
2022-04-01 11:46:20,398: Epoch 29/31 Batch 6200/7662 eta: 2:14:06.143470	Training Loss 0.6203 (0.6310)	Training Prec@1 53.516 (50.944)	Training Prec@5 62.695 (61.156)	
2022-04-01 11:46:20,398: ============================================================
2022-04-01 11:47:04,356: time cost, forward:0.1509938087136353, backward:0.03686125960912491, data cost:0.26616934780696777 
2022-04-01 11:47:04,356: ============================================================
2022-04-01 11:47:04,356: Epoch 29/31 Batch 6300/7662 eta: 2:02:15.279448	Training Loss 0.6295 (0.6309)	Training Prec@1 51.562 (50.971)	Training Prec@5 62.891 (61.183)	
2022-04-01 11:47:04,356: ============================================================
2022-04-01 11:47:50,406: time cost, forward:0.15123258849422827, backward:0.03689063059238554, data cost:0.26598441733068034 
2022-04-01 11:47:50,406: ============================================================
2022-04-01 11:47:50,407: Epoch 29/31 Batch 6400/7662 eta: 2:07:18.398517	Training Loss 0.6175 (0.6308)	Training Prec@1 55.078 (50.998)	Training Prec@5 65.234 (61.207)	
2022-04-01 11:47:50,407: ============================================================
2022-04-01 11:48:36,294: time cost, forward:0.15141987587822678, backward:0.03691681756810383, data cost:0.26582705580210536 
2022-04-01 11:48:36,294: ============================================================
2022-04-01 11:48:36,294: Epoch 29/31 Batch 6500/7662 eta: 2:06:05.524020	Training Loss 0.6197 (0.6307)	Training Prec@1 50.977 (51.023)	Training Prec@5 61.914 (61.229)	
2022-04-01 11:48:36,295: ============================================================
2022-04-01 11:49:19,568: time cost, forward:0.15127868243357795, backward:0.03690826056454828, data cost:0.26564476753404814 
2022-04-01 11:49:19,568: ============================================================
2022-04-01 11:49:19,568: Epoch 29/31 Batch 6600/7662 eta: 1:58:11.301812	Training Loss 0.6233 (0.6307)	Training Prec@1 52.734 (51.041)	Training Prec@5 61.914 (61.247)	
2022-04-01 11:49:19,568: ============================================================
2022-04-01 11:50:03,435: time cost, forward:0.15102764499207044, backward:0.03691904365811744, data cost:0.2656444812785478 
2022-04-01 11:50:03,435: ============================================================
2022-04-01 11:50:03,435: Epoch 29/31 Batch 6700/7662 eta: 1:59:04.617258	Training Loss 0.6260 (0.6306)	Training Prec@1 53.125 (51.065)	Training Prec@5 63.867 (61.271)	
2022-04-01 11:50:03,435: ============================================================
2022-04-01 11:50:49,871: time cost, forward:0.15125986533509334, backward:0.03693514512661433, data cost:0.2655554689156832 
2022-04-01 11:50:49,871: ============================================================
2022-04-01 11:50:49,872: Epoch 29/31 Batch 6800/7662 eta: 2:05:16.642151	Training Loss 0.6265 (0.6305)	Training Prec@1 52.344 (51.085)	Training Prec@5 62.500 (61.289)	
2022-04-01 11:50:49,872: ============================================================
2022-04-01 11:51:35,398: time cost, forward:0.15116636527415755, backward:0.03692272165958942, data cost:0.2656769272485908 
2022-04-01 11:51:35,399: ============================================================
2022-04-01 11:51:35,399: Epoch 29/31 Batch 6900/7662 eta: 2:02:03.998019	Training Loss 0.6305 (0.6304)	Training Prec@1 49.805 (51.109)	Training Prec@5 60.156 (61.308)	
2022-04-01 11:51:35,399: ============================================================
2022-04-01 11:52:22,082: time cost, forward:0.15137903266914368, backward:0.03694264220074085, data cost:0.2656100536860948 
2022-04-01 11:52:22,083: ============================================================
2022-04-01 11:52:22,083: Epoch 29/31 Batch 7000/7662 eta: 2:04:23.385414	Training Loss 0.6180 (0.6303)	Training Prec@1 53.906 (51.132)	Training Prec@5 62.500 (61.328)	
2022-04-01 11:52:22,084: ============================================================
2022-04-01 11:53:07,534: time cost, forward:0.15134566950955883, backward:0.03692964080824518, data cost:0.26565053684977785 
2022-04-01 11:53:07,535: ============================================================
2022-04-01 11:53:07,535: Epoch 29/31 Batch 7100/7662 eta: 2:00:20.894833	Training Loss 0.6273 (0.6302)	Training Prec@1 52.930 (51.154)	Training Prec@5 61.719 (61.349)	
2022-04-01 11:53:07,535: ============================================================
2022-04-01 11:53:55,126: time cost, forward:0.15176711391783337, backward:0.03696979441763974, data cost:0.2654609396683208 
2022-04-01 11:53:55,126: ============================================================
2022-04-01 11:53:55,126: Epoch 29/31 Batch 7200/7662 eta: 2:05:13.270112	Training Loss 0.6151 (0.6301)	Training Prec@1 55.078 (51.177)	Training Prec@5 64.844 (61.368)	
2022-04-01 11:53:55,126: ============================================================
2022-04-01 11:54:37,944: time cost, forward:0.15145348084921836, backward:0.03692851005833285, data cost:0.2654716056215386 
2022-04-01 11:54:37,944: ============================================================
2022-04-01 11:54:37,945: Epoch 29/31 Batch 7300/7662 eta: 1:51:56.899915	Training Loss 0.6236 (0.6300)	Training Prec@1 52.734 (51.206)	Training Prec@5 65.234 (61.393)	
2022-04-01 11:54:37,945: ============================================================
2022-04-01 11:55:24,225: time cost, forward:0.15174534559604333, backward:0.036966963931827516, data cost:0.2652529575870172 
2022-04-01 11:55:24,225: ============================================================
2022-04-01 11:55:24,225: Epoch 29/31 Batch 7400/7662 eta: 2:00:13.786714	Training Loss 0.6230 (0.6299)	Training Prec@1 53.125 (51.225)	Training Prec@5 63.672 (61.416)	
2022-04-01 11:55:24,225: ============================================================
2022-04-01 11:56:08,917: time cost, forward:0.15171151963022966, backward:0.03696370566744918, data cost:0.26517936372330925 
2022-04-01 11:56:08,917: ============================================================
2022-04-01 11:56:08,917: Epoch 29/31 Batch 7500/7662 eta: 1:55:21.413841	Training Loss 0.6187 (0.6298)	Training Prec@1 53.906 (51.249)	Training Prec@5 64.648 (61.437)	
2022-04-01 11:56:08,917: ============================================================
2022-04-01 11:56:55,015: time cost, forward:0.15184450253073614, backward:0.03694581154036293, data cost:0.2651478165873635 
2022-04-01 11:56:55,015: ============================================================
2022-04-01 11:56:55,016: Epoch 29/31 Batch 7600/7662 eta: 1:58:13.194870	Training Loss 0.6192 (0.6297)	Training Prec@1 54.297 (51.276)	Training Prec@5 66.211 (61.463)	
2022-04-01 11:56:55,016: ============================================================
2022-04-01 11:57:25,386: Epoch: 29/31 eta: 1:57:44.152738	Training Loss 0.6230 (0.6297)	Training Prec@1 54.102 (51.291)	Training Prec@5 64.844 (61.477)
2022-04-01 11:57:25,386: ============================================================
2022-04-01 11:58:11,796: time cost, forward:0.11805529064602321, backward:0.03339876791443488, data cost:0.3141722390145967 
2022-04-01 11:58:11,797: ============================================================
2022-04-01 11:58:11,797: Epoch 30/31 Batch 100/7662 eta: 1:57:40.416319	Training Loss 0.6169 (0.6144)	Training Prec@1 57.617 (55.666)	Training Prec@5 67.383 (65.623)	
2022-04-01 11:58:11,797: ============================================================
2022-04-01 11:58:50,697: time cost, forward:0.11200941507540756, backward:0.03364064106390105, data cost:0.28135176519652705 
2022-04-01 11:58:50,697: ============================================================
2022-04-01 11:58:50,697: Epoch 30/31 Batch 200/7662 eta: 1:38:03.655846	Training Loss 0.6163 (0.6142)	Training Prec@1 55.273 (55.861)	Training Prec@5 64.062 (65.563)	
2022-04-01 11:58:50,697: ============================================================
2022-04-01 11:59:33,351: time cost, forward:0.11973727905630667, backward:0.03382925046327521, data cost:0.2730959219278699 
2022-04-01 11:59:33,352: ============================================================
2022-04-01 11:59:33,352: Epoch 30/31 Batch 300/7662 eta: 1:46:48.857433	Training Loss 0.6131 (0.6139)	Training Prec@1 54.102 (55.920)	Training Prec@5 65.039 (65.647)	
2022-04-01 11:59:33,352: ============================================================
2022-04-01 12:00:16,949: time cost, forward:0.12819583852189526, backward:0.035072721634293556, data cost:0.2655211827509983 
2022-04-01 12:00:16,949: ============================================================
2022-04-01 12:00:16,949: Epoch 30/31 Batch 400/7662 eta: 1:48:26.878849	Training Loss 0.6126 (0.6139)	Training Prec@1 55.469 (55.897)	Training Prec@5 66.797 (65.629)	
2022-04-01 12:00:16,949: ============================================================
2022-04-01 12:01:01,741: time cost, forward:0.13036276200013552, backward:0.035656063255661716, data cost:0.2664129390028531 
2022-04-01 12:01:01,741: ============================================================
2022-04-01 12:01:01,742: Epoch 30/31 Batch 500/7662 eta: 1:50:40.496611	Training Loss 0.6075 (0.6139)	Training Prec@1 58.984 (55.926)	Training Prec@5 68.164 (65.633)	
2022-04-01 12:01:01,742: ============================================================
2022-04-01 12:01:44,163: time cost, forward:0.1281375932773087, backward:0.035020804763437316, data cost:0.26795760618028336 
2022-04-01 12:01:44,163: ============================================================
2022-04-01 12:01:44,163: Epoch 30/31 Batch 600/7662 eta: 1:44:06.604944	Training Loss 0.6135 (0.6136)	Training Prec@1 56.641 (56.013)	Training Prec@5 67.188 (65.718)	
2022-04-01 12:01:44,164: ============================================================
2022-04-01 12:02:30,102: time cost, forward:0.13259504963570568, backward:0.03532938486516732, data cost:0.2671156212666175 
2022-04-01 12:02:30,103: ============================================================
2022-04-01 12:02:30,103: Epoch 30/31 Batch 700/7662 eta: 1:51:58.667789	Training Loss 0.6214 (0.6137)	Training Prec@1 52.734 (55.968)	Training Prec@5 63.086 (65.679)	
2022-04-01 12:02:30,103: ============================================================
2022-04-01 12:03:14,553: time cost, forward:0.13561434620462162, backward:0.03557119858876635, data cost:0.2649187059963451 
2022-04-01 12:03:14,553: ============================================================
2022-04-01 12:03:14,553: Epoch 30/31 Batch 800/7662 eta: 1:47:36.403440	Training Loss 0.6107 (0.6136)	Training Prec@1 58.203 (55.998)	Training Prec@5 69.336 (65.733)	
2022-04-01 12:03:14,554: ============================================================
2022-04-01 12:03:58,542: time cost, forward:0.13628116916363708, backward:0.03587676977554338, data cost:0.2642636479472159 
2022-04-01 12:03:58,543: ============================================================
2022-04-01 12:03:58,543: Epoch 30/31 Batch 900/7662 eta: 1:45:45.505019	Training Loss 0.6202 (0.6135)	Training Prec@1 53.906 (55.993)	Training Prec@5 63.477 (65.719)	
2022-04-01 12:03:58,543: ============================================================
2022-04-01 12:04:45,249: time cost, forward:0.14022796027533882, backward:0.036043776406182185, data cost:0.26314761808087994 
2022-04-01 12:04:45,259: ============================================================
2022-04-01 12:04:45,259: Epoch 30/31 Batch 1000/7662 eta: 1:51:32.028350	Training Loss 0.6089 (0.6134)	Training Prec@1 56.250 (56.018)	Training Prec@5 66.016 (65.738)	
2022-04-01 12:04:45,259: ============================================================
2022-04-01 12:05:28,829: time cost, forward:0.13813497371517386, backward:0.035528379532290766, data cost:0.26536341099656635 
2022-04-01 12:05:28,829: ============================================================
2022-04-01 12:05:28,830: Epoch 30/31 Batch 1100/7662 eta: 1:43:17.987550	Training Loss 0.6089 (0.6134)	Training Prec@1 53.906 (56.035)	Training Prec@5 63.867 (65.764)	
2022-04-01 12:05:28,830: ============================================================
2022-04-01 12:06:15,696: time cost, forward:0.1397768512579478, backward:0.03539951529673878, data cost:0.26628902417804123 
2022-04-01 12:06:15,696: ============================================================
2022-04-01 12:06:15,697: Epoch 30/31 Batch 1200/7662 eta: 1:50:19.935712	Training Loss 0.6109 (0.6135)	Training Prec@1 56.836 (56.033)	Training Prec@5 67.578 (65.758)	
2022-04-01 12:06:15,697: ============================================================
2022-04-01 12:06:59,398: time cost, forward:0.14074918230833505, backward:0.03545146340861331, data cost:0.2648424522247197 
2022-04-01 12:06:59,398: ============================================================
2022-04-01 12:06:59,399: Epoch 30/31 Batch 1300/7662 eta: 1:42:09.202544	Training Loss 0.6090 (0.6134)	Training Prec@1 55.664 (56.074)	Training Prec@5 65.234 (65.783)	
2022-04-01 12:06:59,399: ============================================================
2022-04-01 12:07:44,666: time cost, forward:0.14188912359623504, backward:0.03546379002781746, data cost:0.26447839290436204 
2022-04-01 12:07:44,666: ============================================================
2022-04-01 12:07:44,667: Epoch 30/31 Batch 1400/7662 eta: 1:45:03.596640	Training Loss 0.6058 (0.6133)	Training Prec@1 58.984 (56.103)	Training Prec@5 69.727 (65.815)	
2022-04-01 12:07:44,667: ============================================================
2022-04-01 12:08:28,520: time cost, forward:0.14165353981791695, backward:0.035515449459032664, data cost:0.2644063392585719 
2022-04-01 12:08:28,521: ============================================================
2022-04-01 12:08:28,521: Epoch 30/31 Batch 1500/7662 eta: 1:41:02.861560	Training Loss 0.6168 (0.6132)	Training Prec@1 53.125 (56.120)	Training Prec@5 64.258 (65.842)	
2022-04-01 12:08:28,521: ============================================================
2022-04-01 12:09:13,508: time cost, forward:0.141505989303732, backward:0.03556817885560495, data cost:0.26500587690018207 
2022-04-01 12:09:13,508: ============================================================
2022-04-01 12:09:13,508: Epoch 30/31 Batch 1600/7662 eta: 1:42:54.477136	Training Loss 0.6115 (0.6132)	Training Prec@1 55.078 (56.147)	Training Prec@5 65.039 (65.865)	
2022-04-01 12:09:13,508: ============================================================
2022-04-01 12:09:58,189: time cost, forward:0.14185835039566516, backward:0.03574500468424168, data cost:0.264713142955212 
2022-04-01 12:09:58,190: ============================================================
2022-04-01 12:09:58,191: Epoch 30/31 Batch 1700/7662 eta: 1:41:28.053012	Training Loss 0.6083 (0.6132)	Training Prec@1 56.836 (56.142)	Training Prec@5 66.016 (65.856)	
2022-04-01 12:09:58,192: ============================================================
2022-04-01 12:10:43,945: time cost, forward:0.1439417920687783, backward:0.03586050919389115, data cost:0.26333622868820455 
2022-04-01 12:10:43,945: ============================================================
2022-04-01 12:10:43,945: Epoch 30/31 Batch 1800/7662 eta: 1:43:08.240908	Training Loss 0.6175 (0.6132)	Training Prec@1 56.250 (56.163)	Training Prec@5 65.234 (65.872)	
2022-04-01 12:10:43,945: ============================================================
2022-04-01 12:11:28,782: time cost, forward:0.14418652435551824, backward:0.03597475542025293, data cost:0.26320477370653356 
2022-04-01 12:11:28,783: ============================================================
2022-04-01 12:11:28,783: Epoch 30/31 Batch 1900/7662 eta: 1:40:19.426098	Training Loss 0.6223 (0.6132)	Training Prec@1 52.344 (56.147)	Training Prec@5 63.867 (65.852)	
2022-04-01 12:11:28,783: ============================================================
2022-04-01 12:12:13,278: time cost, forward:0.1442187296384093, backward:0.03595557267693295, data cost:0.26321077990853947 
2022-04-01 12:12:13,289: ============================================================
2022-04-01 12:12:13,290: Epoch 30/31 Batch 2000/7662 eta: 1:38:50.546436	Training Loss 0.6034 (0.6132)	Training Prec@1 59.180 (56.146)	Training Prec@5 67.578 (65.858)	
2022-04-01 12:12:13,290: ============================================================
2022-04-01 12:12:59,237: time cost, forward:0.14502328597346392, backward:0.03606717401370939, data cost:0.2630478285107515 
2022-04-01 12:12:59,237: ============================================================
2022-04-01 12:12:59,237: Epoch 30/31 Batch 2100/7662 eta: 1:41:16.595562	Training Loss 0.6127 (0.6132)	Training Prec@1 58.008 (56.158)	Training Prec@5 66.797 (65.875)	
2022-04-01 12:12:59,238: ============================================================
2022-04-01 12:13:45,309: time cost, forward:0.14511474168750577, backward:0.035974879002451846, data cost:0.26378289294709073 
2022-04-01 12:13:45,310: ============================================================
2022-04-01 12:13:45,310: Epoch 30/31 Batch 2200/7662 eta: 1:40:47.000228	Training Loss 0.6075 (0.6132)	Training Prec@1 58.008 (56.151)	Training Prec@5 66.602 (65.877)	
2022-04-01 12:13:45,310: ============================================================
2022-04-01 12:14:29,712: time cost, forward:0.14536647798704966, backward:0.035920576408356365, data cost:0.2635351624266901 
2022-04-01 12:14:29,712: ============================================================
2022-04-01 12:14:29,713: Epoch 30/31 Batch 2300/7662 eta: 1:36:23.461357	Training Loss 0.6014 (0.6132)	Training Prec@1 62.305 (56.158)	Training Prec@5 71.289 (65.871)	
2022-04-01 12:14:29,713: ============================================================
2022-04-01 12:15:15,632: time cost, forward:0.14628101975384133, backward:0.03598177169650334, data cost:0.2631377465231014 
2022-04-01 12:15:15,633: ============================================================
2022-04-01 12:15:15,634: Epoch 30/31 Batch 2400/7662 eta: 1:38:55.275692	Training Loss 0.6108 (0.6132)	Training Prec@1 57.227 (56.157)	Training Prec@5 65.625 (65.861)	
2022-04-01 12:15:15,634: ============================================================
2022-04-01 12:16:01,196: time cost, forward:0.14693088500964352, backward:0.035954098646141804, data cost:0.2628897933685193 
2022-04-01 12:16:01,196: ============================================================
2022-04-01 12:16:01,196: Epoch 30/31 Batch 2500/7662 eta: 1:37:23.427990	Training Loss 0.6078 (0.6132)	Training Prec@1 59.375 (56.143)	Training Prec@5 66.992 (65.854)	
2022-04-01 12:16:01,196: ============================================================
2022-04-01 12:16:44,873: time cost, forward:0.14641521425603124, backward:0.03582404998230356, data cost:0.26316860539493947 
2022-04-01 12:16:44,887: ============================================================
2022-04-01 12:16:44,887: Epoch 30/31 Batch 2600/7662 eta: 1:32:39.636333	Training Loss 0.5969 (0.6131)	Training Prec@1 63.477 (56.157)	Training Prec@5 72.852 (65.867)	
2022-04-01 12:16:44,887: ============================================================
2022-04-01 12:17:30,412: time cost, forward:0.1461831285760066, backward:0.03583570319928695, data cost:0.2637390904004329 
2022-04-01 12:17:30,413: ============================================================
2022-04-01 12:17:30,413: Epoch 30/31 Batch 2700/7662 eta: 1:35:47.647028	Training Loss 0.6119 (0.6131)	Training Prec@1 56.445 (56.159)	Training Prec@5 65.625 (65.876)	
2022-04-01 12:17:30,413: ============================================================
2022-04-01 12:18:14,610: time cost, forward:0.1456167373371022, backward:0.03581281618034469, data cost:0.2641761917095177 
2022-04-01 12:18:14,611: ============================================================
2022-04-01 12:18:14,611: Epoch 30/31 Batch 2800/7662 eta: 1:32:15.810155	Training Loss 0.6024 (0.6131)	Training Prec@1 59.766 (56.168)	Training Prec@5 69.531 (65.882)	
2022-04-01 12:18:14,611: ============================================================
2022-04-01 12:18:57,673: time cost, forward:0.14488462342521824, backward:0.03572895980037546, data cost:0.2644280423456819 
2022-04-01 12:18:57,673: ============================================================
2022-04-01 12:18:57,673: Epoch 30/31 Batch 2900/7662 eta: 1:29:10.515240	Training Loss 0.6114 (0.6131)	Training Prec@1 55.273 (56.182)	Training Prec@5 64.453 (65.894)	
2022-04-01 12:18:57,674: ============================================================
2022-04-01 12:19:41,760: time cost, forward:0.14421944277967838, backward:0.03568803560499272, data cost:0.2649964978592362 
2022-04-01 12:19:41,761: ============================================================
2022-04-01 12:19:41,761: Epoch 30/31 Batch 3000/7662 eta: 1:30:33.756148	Training Loss 0.6064 (0.6131)	Training Prec@1 57.422 (56.166)	Training Prec@5 68.750 (65.883)	
2022-04-01 12:19:41,761: ============================================================
2022-04-01 12:20:24,795: time cost, forward:0.14321137528605676, backward:0.03563754502401386, data cost:0.26557058894122637 
2022-04-01 12:20:24,795: ============================================================
2022-04-01 12:20:24,795: Epoch 30/31 Batch 3100/7662 eta: 1:27:40.959712	Training Loss 0.6183 (0.6131)	Training Prec@1 54.688 (56.159)	Training Prec@5 63.086 (65.875)	
2022-04-01 12:20:24,795: ============================================================
2022-04-01 12:21:08,752: time cost, forward:0.14296430489092032, backward:0.03565251689361162, data cost:0.265627160523973 
2022-04-01 12:21:08,752: ============================================================
2022-04-01 12:21:08,753: Epoch 30/31 Batch 3200/7662 eta: 1:28:49.833459	Training Loss 0.6063 (0.6131)	Training Prec@1 58.203 (56.167)	Training Prec@5 66.602 (65.878)	
2022-04-01 12:21:08,753: ============================================================
2022-04-01 12:21:51,446: time cost, forward:0.14243681671475597, backward:0.03564778896272815, data cost:0.2656297954728149 
2022-04-01 12:21:51,446: ============================================================
2022-04-01 12:21:51,447: Epoch 30/31 Batch 3300/7662 eta: 1:25:33.947996	Training Loss 0.6136 (0.6131)	Training Prec@1 57.227 (56.155)	Training Prec@5 66.992 (65.873)	
2022-04-01 12:21:51,447: ============================================================
2022-04-01 12:22:34,871: time cost, forward:0.14213784339323435, backward:0.03562091188803951, data cost:0.2656581843730526 
2022-04-01 12:22:34,871: ============================================================
2022-04-01 12:22:34,872: Epoch 30/31 Batch 3400/7662 eta: 1:26:18.449725	Training Loss 0.6112 (0.6131)	Training Prec@1 57.617 (56.163)	Training Prec@5 66.797 (65.870)	
2022-04-01 12:22:34,872: ============================================================
2022-04-01 12:23:17,877: time cost, forward:0.14146023363547858, backward:0.03558177898937922, data cost:0.26597666406536075 
2022-04-01 12:23:17,878: ============================================================
2022-04-01 12:23:17,878: Epoch 30/31 Batch 3500/7662 eta: 1:24:45.506615	Training Loss 0.6199 (0.6131)	Training Prec@1 54.883 (56.154)	Training Prec@5 62.305 (65.859)	
2022-04-01 12:23:17,878: ============================================================
2022-04-01 12:24:02,541: time cost, forward:0.1416993351173454, backward:0.03560455105774401, data cost:0.26579876169955674 
2022-04-01 12:24:02,542: ============================================================
2022-04-01 12:24:02,542: Epoch 30/31 Batch 3600/7662 eta: 1:27:16.834044	Training Loss 0.6055 (0.6131)	Training Prec@1 56.836 (56.157)	Training Prec@5 65.430 (65.859)	
2022-04-01 12:24:02,542: ============================================================
2022-04-01 12:24:43,869: time cost, forward:0.14100187402958805, backward:0.03564949298620417, data cost:0.26563958936074067 
2022-04-01 12:24:43,870: ============================================================
2022-04-01 12:24:43,870: Epoch 30/31 Batch 3700/7662 eta: 1:20:04.377375	Training Loss 0.6171 (0.6131)	Training Prec@1 54.688 (56.164)	Training Prec@5 64.062 (65.868)	
2022-04-01 12:24:43,870: ============================================================
2022-04-01 12:25:26,354: time cost, forward:0.14011620464811955, backward:0.035688785415914505, data cost:0.26600796845625124 
2022-04-01 12:25:26,354: ============================================================
2022-04-01 12:25:26,355: Epoch 30/31 Batch 3800/7662 eta: 1:21:36.352988	Training Loss 0.6068 (0.6131)	Training Prec@1 60.156 (56.169)	Training Prec@5 70.898 (65.874)	
2022-04-01 12:25:26,355: ============================================================
2022-04-01 12:26:10,716: time cost, forward:0.1399887835988634, backward:0.03575923333384496, data cost:0.2660996372744376 
2022-04-01 12:26:10,716: ============================================================
2022-04-01 12:26:10,717: Epoch 30/31 Batch 3900/7662 eta: 1:24:28.365172	Training Loss 0.6164 (0.6131)	Training Prec@1 54.492 (56.173)	Training Prec@5 64.648 (65.874)	
2022-04-01 12:26:10,717: ============================================================
2022-04-01 12:26:52,492: time cost, forward:0.13910762862462822, backward:0.03579168952861766, data cost:0.266311847200749 
2022-04-01 12:26:52,492: ============================================================
2022-04-01 12:26:52,493: Epoch 30/31 Batch 4000/7662 eta: 1:18:51.127034	Training Loss 0.6110 (0.6131)	Training Prec@1 56.641 (56.174)	Training Prec@5 68.555 (65.878)	
2022-04-01 12:26:52,493: ============================================================
2022-04-01 12:27:35,770: time cost, forward:0.1390760138023769, backward:0.03577603599332431, data cost:0.26617063665192253 
2022-04-01 12:27:35,771: ============================================================
2022-04-01 12:27:35,771: Epoch 30/31 Batch 4100/7662 eta: 1:20:57.985514	Training Loss 0.6162 (0.6131)	Training Prec@1 57.617 (56.174)	Training Prec@5 65.430 (65.879)	
2022-04-01 12:27:35,771: ============================================================
2022-04-01 12:28:19,031: time cost, forward:0.13915748646157672, backward:0.03579601340987734, data cost:0.2658559430579567 
2022-04-01 12:28:19,032: ============================================================
2022-04-01 12:28:19,032: Epoch 30/31 Batch 4200/7662 eta: 1:20:12.788098	Training Loss 0.6208 (0.6130)	Training Prec@1 54.102 (56.194)	Training Prec@5 64.258 (65.895)	
2022-04-01 12:28:19,032: ============================================================
2022-04-01 12:29:01,978: time cost, forward:0.1384934260418704, backward:0.03575439435378095, data cost:0.266275902298002 
2022-04-01 12:29:01,978: ============================================================
2022-04-01 12:29:01,978: Epoch 30/31 Batch 4300/7662 eta: 1:18:54.844403	Training Loss 0.6118 (0.6130)	Training Prec@1 57.422 (56.195)	Training Prec@5 68.164 (65.896)	
2022-04-01 12:29:01,978: ============================================================
2022-04-01 12:29:44,186: time cost, forward:0.13772032796916542, backward:0.035694038903179376, data cost:0.26669418462218686 
2022-04-01 12:29:44,187: ============================================================
2022-04-01 12:29:44,187: Epoch 30/31 Batch 4400/7662 eta: 1:16:51.283512	Training Loss 0.6057 (0.6130)	Training Prec@1 56.445 (56.203)	Training Prec@5 65.820 (65.907)	
2022-04-01 12:29:44,187: ============================================================
2022-04-01 12:30:29,382: time cost, forward:0.1377794774910375, backward:0.035710208228917406, data cost:0.2668805888134205 
2022-04-01 12:30:29,382: ============================================================
2022-04-01 12:30:29,383: Epoch 30/31 Batch 4500/7662 eta: 1:21:32.445538	Training Loss 0.6078 (0.6130)	Training Prec@1 59.766 (56.210)	Training Prec@5 69.922 (65.912)	
2022-04-01 12:30:29,383: ============================================================
2022-04-01 12:31:14,232: time cost, forward:0.137884798193009, backward:0.035736729617117796, data cost:0.26689904092264893 
2022-04-01 12:31:14,233: ============================================================
2022-04-01 12:31:14,233: Epoch 30/31 Batch 4600/7662 eta: 1:20:10.204067	Training Loss 0.6071 (0.6130)	Training Prec@1 57.617 (56.211)	Training Prec@5 68.359 (65.914)	
2022-04-01 12:31:14,234: ============================================================
2022-04-01 12:31:57,087: time cost, forward:0.13773948767256752, backward:0.03576676904914176, data cost:0.2667534274734267 
2022-04-01 12:31:57,088: ============================================================
2022-04-01 12:31:57,088: Epoch 30/31 Batch 4700/7662 eta: 1:15:53.314164	Training Loss 0.6081 (0.6130)	Training Prec@1 56.445 (56.206)	Training Prec@5 67.383 (65.912)	
2022-04-01 12:31:57,088: ============================================================
2022-04-01 12:32:42,149: time cost, forward:0.13764354074267104, backward:0.03577843028372788, data cost:0.26704056030960227 
2022-04-01 12:32:42,149: ============================================================
2022-04-01 12:32:42,150: Epoch 30/31 Batch 4800/7662 eta: 1:19:02.779820	Training Loss 0.6074 (0.6130)	Training Prec@1 59.375 (56.216)	Training Prec@5 67.969 (65.918)	
2022-04-01 12:32:42,150: ============================================================
2022-04-01 12:33:26,053: time cost, forward:0.13734021491482687, backward:0.035784368004986744, data cost:0.2673038716558584 
2022-04-01 12:33:26,054: ============================================================
2022-04-01 12:33:26,054: Epoch 30/31 Batch 4900/7662 eta: 1:16:16.990464	Training Loss 0.6070 (0.6130)	Training Prec@1 56.445 (56.215)	Training Prec@5 65.039 (65.915)	
2022-04-01 12:33:26,054: ============================================================
2022-04-01 12:34:10,106: time cost, forward:0.13754272894946115, backward:0.0357751935976795, data cost:0.26711377159884797 
2022-04-01 12:34:10,107: ============================================================
2022-04-01 12:34:10,107: Epoch 30/31 Batch 5000/7662 eta: 1:15:48.484605	Training Loss 0.6096 (0.6130)	Training Prec@1 58.398 (56.216)	Training Prec@5 67.188 (65.919)	
2022-04-01 12:34:10,107: ============================================================
2022-04-01 12:34:58,044: time cost, forward:0.13802405623132796, backward:0.035756902803180494, data cost:0.26737806132597697 
2022-04-01 12:34:58,044: ============================================================
2022-04-01 12:34:58,044: Epoch 30/31 Batch 5100/7662 eta: 1:21:41.614104	Training Loss 0.5993 (0.6129)	Training Prec@1 59.961 (56.220)	Training Prec@5 71.875 (65.922)	
2022-04-01 12:34:58,045: ============================================================
2022-04-01 12:35:41,677: time cost, forward:0.1380199278104899, backward:0.035799225698780336, data cost:0.26724757843692615 
2022-04-01 12:35:41,677: ============================================================
2022-04-01 12:35:41,678: Epoch 30/31 Batch 5200/7662 eta: 1:13:37.845536	Training Loss 0.6157 (0.6129)	Training Prec@1 56.055 (56.225)	Training Prec@5 66.602 (65.925)	
2022-04-01 12:35:41,678: ============================================================
2022-04-01 12:36:26,084: time cost, forward:0.1379625281650495, backward:0.035775659083870134, data cost:0.26737370840174496 
2022-04-01 12:36:26,085: ============================================================
2022-04-01 12:36:26,085: Epoch 30/31 Batch 5300/7662 eta: 1:14:11.850324	Training Loss 0.6162 (0.6129)	Training Prec@1 57.227 (56.236)	Training Prec@5 65.430 (65.933)	
2022-04-01 12:36:26,085: ============================================================
2022-04-01 12:37:11,185: time cost, forward:0.13813589771360485, backward:0.03578972246806298, data cost:0.26736284004447414 
2022-04-01 12:37:11,185: ============================================================
2022-04-01 12:37:11,185: Epoch 30/31 Batch 5400/7662 eta: 1:14:36.194442	Training Loss 0.6209 (0.6129)	Training Prec@1 55.273 (56.238)	Training Prec@5 63.867 (65.936)	
2022-04-01 12:37:11,186: ============================================================
2022-04-01 12:37:54,482: time cost, forward:0.13794928933299874, backward:0.035764600736788346, data cost:0.26741640249974813 
2022-04-01 12:37:54,483: ============================================================
2022-04-01 12:37:54,483: Epoch 30/31 Batch 5500/7662 eta: 1:10:54.001899	Training Loss 0.6184 (0.6129)	Training Prec@1 55.664 (56.239)	Training Prec@5 64.844 (65.938)	
2022-04-01 12:37:54,484: ============================================================
2022-04-01 12:38:41,817: time cost, forward:0.13872169779760324, backward:0.03581714391665792, data cost:0.26713010378662316 
2022-04-01 12:38:41,817: ============================================================
2022-04-01 12:38:41,817: Epoch 30/31 Batch 5600/7662 eta: 1:16:43.257294	Training Loss 0.6181 (0.6129)	Training Prec@1 54.297 (56.242)	Training Prec@5 62.695 (65.936)	
2022-04-01 12:38:41,817: ============================================================
2022-04-01 12:39:24,881: time cost, forward:0.1385691963720581, backward:0.035838610876190134, data cost:0.2670625967610445 
2022-04-01 12:39:24,881: ============================================================
2022-04-01 12:39:24,881: Epoch 30/31 Batch 5700/7662 eta: 1:09:04.900007	Training Loss 0.6098 (0.6129)	Training Prec@1 55.078 (56.244)	Training Prec@5 66.211 (65.939)	
2022-04-01 12:39:24,881: ============================================================
2022-04-01 12:40:08,653: time cost, forward:0.13874651687189224, backward:0.0358529758979625, data cost:0.2668224564707059 
2022-04-01 12:40:08,653: ============================================================
2022-04-01 12:40:08,653: Epoch 30/31 Batch 5800/7662 eta: 1:09:29.303559	Training Loss 0.6091 (0.6129)	Training Prec@1 58.594 (56.248)	Training Prec@5 68.164 (65.941)	
2022-04-01 12:40:08,653: ============================================================
2022-04-01 12:40:54,649: time cost, forward:0.13893610385539754, backward:0.03587530030701439, data cost:0.2669014002755853 
2022-04-01 12:40:54,650: ============================================================
2022-04-01 12:40:54,650: Epoch 30/31 Batch 5900/7662 eta: 1:12:15.202237	Training Loss 0.6094 (0.6129)	Training Prec@1 57.812 (56.245)	Training Prec@5 67.578 (65.939)	
2022-04-01 12:40:54,650: ============================================================
2022-04-01 12:41:39,689: time cost, forward:0.1390744817914675, backward:0.03582261434931182, data cost:0.2669602407378184 
2022-04-01 12:41:39,689: ============================================================
2022-04-01 12:41:39,690: Epoch 30/31 Batch 6000/7662 eta: 1:09:59.925505	Training Loss 0.6118 (0.6129)	Training Prec@1 58.203 (56.242)	Training Prec@5 68.359 (65.940)	
2022-04-01 12:41:39,690: ============================================================
2022-04-01 12:42:23,773: time cost, forward:0.13917410528098859, backward:0.03586695166489476, data cost:0.26679471325221504 
2022-04-01 12:42:23,773: ============================================================
2022-04-01 12:42:23,774: Epoch 30/31 Batch 6100/7662 eta: 1:07:46.748482	Training Loss 0.6092 (0.6129)	Training Prec@1 56.055 (56.245)	Training Prec@5 65.430 (65.940)	
2022-04-01 12:42:23,774: ============================================================
2022-04-01 12:43:08,534: time cost, forward:0.1392271753318234, backward:0.035843703261804805, data cost:0.26685003850475053 
2022-04-01 12:43:08,534: ============================================================
2022-04-01 12:43:08,535: Epoch 30/31 Batch 6200/7662 eta: 1:08:04.452512	Training Loss 0.6226 (0.6129)	Training Prec@1 52.148 (56.244)	Training Prec@5 62.109 (65.939)	
2022-04-01 12:43:08,535: ============================================================
2022-04-01 12:43:53,429: time cost, forward:0.13922736879037778, backward:0.035831505466139606, data cost:0.2669580567922076 
2022-04-01 12:43:53,429: ============================================================
2022-04-01 12:43:53,429: Epoch 30/31 Batch 6300/7662 eta: 1:07:31.738460	Training Loss 0.6072 (0.6129)	Training Prec@1 58.984 (56.253)	Training Prec@5 67.969 (65.945)	
2022-04-01 12:43:53,429: ============================================================
2022-04-01 12:44:40,397: time cost, forward:0.13968337191363986, backward:0.035851651941506, data cost:0.2669095664420041 
2022-04-01 12:44:40,398: ============================================================
2022-04-01 12:44:40,398: Epoch 30/31 Batch 6400/7662 eta: 1:09:51.952788	Training Loss 0.6153 (0.6129)	Training Prec@1 54.688 (56.255)	Training Prec@5 66.016 (65.947)	
2022-04-01 12:44:40,398: ============================================================
2022-04-01 12:45:25,965: time cost, forward:0.1399655140699066, backward:0.03589006137216911, data cost:0.2667891982886072 
2022-04-01 12:45:25,966: ============================================================
2022-04-01 12:45:25,966: Epoch 30/31 Batch 6500/7662 eta: 1:07:01.385517	Training Loss 0.6087 (0.6128)	Training Prec@1 56.836 (56.265)	Training Prec@5 65.820 (65.957)	
2022-04-01 12:45:25,966: ============================================================
2022-04-01 12:46:10,186: time cost, forward:0.14004242259420252, backward:0.03591754422402414, data cost:0.2666576396409156 
2022-04-01 12:46:10,186: ============================================================
2022-04-01 12:46:10,187: Epoch 30/31 Batch 6600/7662 eta: 1:04:18.231156	Training Loss 0.6004 (0.6128)	Training Prec@1 62.305 (56.273)	Training Prec@5 71.094 (65.960)	
2022-04-01 12:46:10,187: ============================================================
2022-04-01 12:46:54,709: time cost, forward:0.14006780606452202, backward:0.035969186672649735, data cost:0.26661909674687034 
2022-04-01 12:46:54,709: ============================================================
2022-04-01 12:46:54,710: Epoch 30/31 Batch 6700/7662 eta: 1:04:00.115104	Training Loss 0.6003 (0.6128)	Training Prec@1 61.133 (56.271)	Training Prec@5 71.094 (65.958)	
2022-04-01 12:46:54,710: ============================================================
2022-04-01 12:47:39,597: time cost, forward:0.14015188033413511, backward:0.03597880588031583, data cost:0.26660453282589247 
2022-04-01 12:47:39,597: ============================================================
2022-04-01 12:47:39,597: Epoch 30/31 Batch 6800/7662 eta: 1:03:46.670334	Training Loss 0.6160 (0.6128)	Training Prec@1 55.859 (56.271)	Training Prec@5 67.383 (65.957)	
2022-04-01 12:47:39,597: ============================================================
2022-04-01 12:48:24,625: time cost, forward:0.14033348962247744, backward:0.0360354325929955, data cost:0.26646838956750774 
2022-04-01 12:48:24,626: ============================================================
2022-04-01 12:48:24,626: Epoch 30/31 Batch 6900/7662 eta: 1:03:13.656475	Training Loss 0.6060 (0.6128)	Training Prec@1 56.836 (56.266)	Training Prec@5 67.969 (65.953)	
2022-04-01 12:48:24,626: ============================================================
2022-04-01 12:49:11,634: time cost, forward:0.14067368739706257, backward:0.03614302971888004, data cost:0.26639877903340525 
2022-04-01 12:49:11,634: ============================================================
2022-04-01 12:49:11,634: Epoch 30/31 Batch 7000/7662 eta: 1:05:13.455212	Training Loss 0.6096 (0.6128)	Training Prec@1 56.836 (56.266)	Training Prec@5 64.648 (65.953)	
2022-04-01 12:49:11,634: ============================================================
2022-04-01 12:49:55,877: time cost, forward:0.14066472827993592, backward:0.03614272885229205, data cost:0.2663938632094032 
2022-04-01 12:49:55,878: ============================================================
2022-04-01 12:49:55,878: Epoch 30/31 Batch 7100/7662 eta: 1:00:39.036640	Training Loss 0.6104 (0.6128)	Training Prec@1 57.617 (56.273)	Training Prec@5 67.188 (65.959)	
2022-04-01 12:49:55,878: ============================================================
2022-04-01 12:50:40,129: time cost, forward:0.14058835209368137, backward:0.03614338624310139, data cost:0.26643733498718625 
2022-04-01 12:50:40,129: ============================================================
2022-04-01 12:50:40,129: Epoch 30/31 Batch 7200/7662 eta: 0:59:55.418540	Training Loss 0.6157 (0.6128)	Training Prec@1 54.883 (56.274)	Training Prec@5 66.211 (65.960)	
2022-04-01 12:50:40,129: ============================================================
2022-04-01 12:51:25,237: time cost, forward:0.14080195267537896, backward:0.036164543696961544, data cost:0.2663155757722699 
2022-04-01 12:51:25,238: ============================================================
2022-04-01 12:51:25,238: Epoch 30/31 Batch 7300/7662 eta: 1:00:19.965429	Training Loss 0.6191 (0.6128)	Training Prec@1 54.883 (56.282)	Training Prec@5 63.086 (65.965)	
2022-04-01 12:51:25,238: ============================================================
2022-04-01 12:52:10,172: time cost, forward:0.1409049479441637, backward:0.036162748097052264, data cost:0.2662910528320898 
2022-04-01 12:52:10,172: ============================================================
2022-04-01 12:52:10,172: Epoch 30/31 Batch 7400/7662 eta: 0:59:21.063488	Training Loss 0.6152 (0.6128)	Training Prec@1 56.836 (56.280)	Training Prec@5 66.992 (65.964)	
2022-04-01 12:52:10,172: ============================================================
2022-04-01 12:52:57,300: time cost, forward:0.1412739103548462, backward:0.0361911459181496, data cost:0.2662304379905378 
2022-04-01 12:52:57,300: ============================================================
2022-04-01 12:52:57,301: Epoch 30/31 Batch 7500/7662 eta: 1:01:27.788800	Training Loss 0.6072 (0.6128)	Training Prec@1 57.227 (56.281)	Training Prec@5 69.922 (65.966)	
2022-04-01 12:52:57,301: ============================================================
2022-04-01 12:53:40,456: time cost, forward:0.14120562369297296, backward:0.03618136367165332, data cost:0.2661603257944434 
2022-04-01 12:53:40,457: ============================================================
2022-04-01 12:53:40,457: Epoch 30/31 Batch 7600/7662 eta: 0:55:33.818231	Training Loss 0.6158 (0.6128)	Training Prec@1 53.711 (56.278)	Training Prec@5 62.500 (65.962)	
2022-04-01 12:53:40,457: ============================================================
2022-04-01 12:54:10,134: Epoch: 30/31 eta: 0:55:06.629811	Training Loss 0.6022 (0.6128)	Training Prec@1 58.594 (56.279)	Training Prec@5 68.945 (65.965)
2022-04-01 12:54:10,135: ============================================================
2022-04-01 12:54:10,136: Save Checkpoint...
2022-04-01 12:54:10,161: ============================================================
2022-04-01 12:54:13,033: Save done!
2022-04-01 12:54:13,033: ============================================================
2022-04-01 12:55:08,879: time cost, forward:0.10755138927035862, backward:0.03349319371310147, data cost:0.42044315434465507 
2022-04-01 12:55:08,879: ============================================================
2022-04-01 12:55:08,880: Epoch 31/31 Batch 100/7662 eta: 1:10:23.559714	Training Loss 0.6114 (0.6107)	Training Prec@1 54.102 (56.986)	Training Prec@5 65.234 (66.529)	
2022-04-01 12:55:08,880: ============================================================
2022-04-01 12:55:49,774: time cost, forward:0.10798823294328086, backward:0.033187201274699304, data cost:0.34338647396720234 
2022-04-01 12:55:49,774: ============================================================
2022-04-01 12:55:49,775: Epoch 31/31 Batch 200/7662 eta: 0:50:51.992105	Training Loss 0.6021 (0.6105)	Training Prec@1 60.156 (57.007)	Training Prec@5 69.141 (66.647)	
2022-04-01 12:55:49,775: ============================================================
2022-04-01 12:56:31,266: time cost, forward:0.11017957419456048, backward:0.03287756004461078, data cost:0.31815086718785723 
2022-04-01 12:56:31,267: ============================================================
2022-04-01 12:56:31,267: Epoch 31/31 Batch 300/7662 eta: 0:50:55.064868	Training Loss 0.6123 (0.6110)	Training Prec@1 57.031 (56.820)	Training Prec@5 68.750 (66.447)	
2022-04-01 12:56:31,267: ============================================================
2022-04-01 12:57:13,523: time cost, forward:0.1157463624662624, backward:0.03416768052524194, data cost:0.30154026002812206 
2022-04-01 12:57:13,523: ============================================================
2022-04-01 12:57:13,524: Epoch 31/31 Batch 400/7662 eta: 0:51:09.116592	Training Loss 0.6096 (0.6112)	Training Prec@1 59.180 (56.800)	Training Prec@5 67.773 (66.411)	
2022-04-01 12:57:13,524: ============================================================
2022-04-01 12:57:54,936: time cost, forward:0.11583907236317116, backward:0.03402661751649662, data cost:0.29397343872544285 
2022-04-01 12:57:54,936: ============================================================
2022-04-01 12:57:54,936: Epoch 31/31 Batch 500/7662 eta: 0:49:26.399347	Training Loss 0.6212 (0.6111)	Training Prec@1 54.297 (56.839)	Training Prec@5 64.062 (66.474)	
2022-04-01 12:57:54,937: ============================================================
2022-04-01 12:58:39,599: time cost, forward:0.12118985258876183, backward:0.03460592300147564, data cost:0.2882374929068284 
2022-04-01 12:58:39,600: ============================================================
2022-04-01 12:58:39,600: Epoch 31/31 Batch 600/7662 eta: 0:52:34.578531	Training Loss 0.6074 (0.6111)	Training Prec@1 55.859 (56.855)	Training Prec@5 67.188 (66.471)	
2022-04-01 12:58:39,600: ============================================================
2022-04-01 12:59:23,932: time cost, forward:0.12348358791444093, backward:0.03490297443024249, data cost:0.28537536963543325 
2022-04-01 12:59:23,933: ============================================================
2022-04-01 12:59:23,933: Epoch 31/31 Batch 700/7662 eta: 0:51:26.906454	Training Loss 0.6115 (0.6110)	Training Prec@1 58.594 (56.878)	Training Prec@5 65.820 (66.511)	
2022-04-01 12:59:23,933: ============================================================
2022-04-01 13:00:08,414: time cost, forward:0.12737033155295666, backward:0.035016975653484855, data cost:0.28136335594931594 
2022-04-01 13:00:08,415: ============================================================
2022-04-01 13:00:08,415: Epoch 31/31 Batch 800/7662 eta: 0:50:52.815818	Training Loss 0.6063 (0.6109)	Training Prec@1 59.375 (56.869)	Training Prec@5 68.945 (66.503)	
2022-04-01 13:00:08,416: ============================================================
2022-04-01 13:00:52,194: time cost, forward:0.1283634035155028, backward:0.0350770605551918, data cost:0.2796853018284374 
2022-04-01 13:00:52,200: ============================================================
2022-04-01 13:00:52,200: Epoch 31/31 Batch 900/7662 eta: 0:49:21.162529	Training Loss 0.6128 (0.6109)	Training Prec@1 53.711 (56.899)	Training Prec@5 64.648 (66.524)	
2022-04-01 13:00:52,200: ============================================================
2022-04-01 13:01:35,996: time cost, forward:0.1272366989601601, backward:0.0349076531670831, data cost:0.280400464961956 
2022-04-01 13:01:35,996: ============================================================
2022-04-01 13:01:35,997: Epoch 31/31 Batch 1000/7662 eta: 0:48:38.171325	Training Loss 0.6148 (0.6109)	Training Prec@1 57.227 (56.889)	Training Prec@5 66.797 (66.487)	
2022-04-01 13:01:35,997: ============================================================
2022-04-01 13:02:22,926: time cost, forward:0.13209385346889063, backward:0.03520954316914136, data cost:0.2775575843477813 
2022-04-01 13:02:22,926: ============================================================
2022-04-01 13:02:22,926: Epoch 31/31 Batch 1100/7662 eta: 0:51:19.992965	Training Loss 0.6055 (0.6109)	Training Prec@1 58.398 (56.899)	Training Prec@5 66.992 (66.475)	
2022-04-01 13:02:22,927: ============================================================
2022-04-01 13:03:06,516: time cost, forward:0.13327229808428767, backward:0.03518451383652739, data cost:0.27561700851147725 
2022-04-01 13:03:06,517: ============================================================
2022-04-01 13:03:06,517: Epoch 31/31 Batch 1200/7662 eta: 0:46:57.264840	Training Loss 0.6138 (0.6109)	Training Prec@1 55.469 (56.893)	Training Prec@5 66.016 (66.469)	
2022-04-01 13:03:06,517: ============================================================
2022-04-01 13:03:51,472: time cost, forward:0.1344717068338137, backward:0.035057071908975765, data cost:0.2748768700371347 
2022-04-01 13:03:51,472: ============================================================
2022-04-01 13:03:51,472: Epoch 31/31 Batch 1300/7662 eta: 0:47:40.518731	Training Loss 0.6155 (0.6108)	Training Prec@1 55.859 (56.931)	Training Prec@5 63.672 (66.506)	
2022-04-01 13:03:51,473: ============================================================
2022-04-01 13:04:36,011: time cost, forward:0.1346227696659396, backward:0.03506884530580751, data cost:0.27476162685506084 
2022-04-01 13:04:36,011: ============================================================
2022-04-01 13:04:36,012: Epoch 31/31 Batch 1400/7662 eta: 0:46:29.504599	Training Loss 0.6123 (0.6109)	Training Prec@1 58.789 (56.910)	Training Prec@5 69.141 (66.493)	
2022-04-01 13:04:36,012: ============================================================
2022-04-01 13:05:22,310: time cost, forward:0.1361091965592011, backward:0.03503794921406752, data cost:0.2744734568783567 
2022-04-01 13:05:22,310: ============================================================
2022-04-01 13:05:22,311: Epoch 31/31 Batch 1500/7662 eta: 0:47:33.400833	Training Loss 0.6107 (0.6109)	Training Prec@1 59.180 (56.915)	Training Prec@5 66.406 (66.495)	
2022-04-01 13:05:22,311: ============================================================
2022-04-01 13:06:05,677: time cost, forward:0.1365004474480052, backward:0.035005667568967815, data cost:0.2732986956555222 
2022-04-01 13:06:05,677: ============================================================
2022-04-01 13:06:05,677: Epoch 31/31 Batch 1600/7662 eta: 0:43:49.319996	Training Loss 0.6103 (0.6108)	Training Prec@1 57.031 (56.911)	Training Prec@5 65.430 (66.500)	
2022-04-01 13:06:05,677: ============================================================
2022-04-01 13:06:51,389: time cost, forward:0.13670507889063377, backward:0.03503149435616999, data cost:0.2737745558113965 
2022-04-01 13:06:51,390: ============================================================
2022-04-01 13:06:51,390: Epoch 31/31 Batch 1700/7662 eta: 0:45:25.852872	Training Loss 0.5992 (0.6109)	Training Prec@1 62.305 (56.901)	Training Prec@5 70.312 (66.496)	
2022-04-01 13:06:51,390: ============================================================
2022-04-01 13:07:33,360: time cost, forward:0.1358635577975279, backward:0.034972271036611394, data cost:0.2731854139002513 
2022-04-01 13:07:33,361: ============================================================
2022-04-01 13:07:33,361: Epoch 31/31 Batch 1800/7662 eta: 0:41:00.749146	Training Loss 0.6124 (0.6109)	Training Prec@1 56.836 (56.880)	Training Prec@5 67.773 (66.488)	
2022-04-01 13:07:33,361: ============================================================
2022-04-01 13:08:18,827: time cost, forward:0.1371827770873959, backward:0.03504025666195195, data cost:0.2723298253606281 
2022-04-01 13:08:18,829: ============================================================
2022-04-01 13:08:18,829: Epoch 31/31 Batch 1900/7662 eta: 0:43:40.325865	Training Loss 0.6053 (0.6109)	Training Prec@1 59.766 (56.866)	Training Prec@5 67.969 (66.474)	
2022-04-01 13:08:18,830: ============================================================
2022-04-01 13:09:03,301: time cost, forward:0.13745441265020328, backward:0.03507484764740311, data cost:0.271946812940276 
2022-04-01 13:09:03,302: ============================================================
2022-04-01 13:09:03,304: Epoch 31/31 Batch 2000/7662 eta: 0:41:58.584397	Training Loss 0.6236 (0.6109)	Training Prec@1 54.883 (56.859)	Training Prec@5 63.672 (66.463)	
2022-04-01 13:09:03,304: ============================================================
2022-04-01 13:09:47,281: time cost, forward:0.13806706431253915, backward:0.03482569564575806, data cost:0.2713381095748109 
2022-04-01 13:09:47,281: ============================================================
2022-04-01 13:09:47,281: Epoch 31/31 Batch 2100/7662 eta: 0:40:46.498722	Training Loss 0.6035 (0.6109)	Training Prec@1 59.766 (56.879)	Training Prec@5 68.945 (66.489)	
2022-04-01 13:09:47,282: ============================================================
2022-04-01 13:10:32,133: time cost, forward:0.1384795219478633, backward:0.03471106515791591, data cost:0.27119852695317637 
2022-04-01 13:10:32,134: ============================================================
2022-04-01 13:10:32,134: Epoch 31/31 Batch 2200/7662 eta: 0:40:50.282005	Training Loss 0.6146 (0.6109)	Training Prec@1 54.297 (56.871)	Training Prec@5 65.234 (66.477)	
2022-04-01 13:10:32,134: ============================================================
2022-04-01 13:11:17,849: time cost, forward:0.13924280111039913, backward:0.03468278129497991, data cost:0.2709718819751383 
2022-04-01 13:11:17,849: ============================================================
2022-04-01 13:11:17,849: Epoch 31/31 Batch 2300/7662 eta: 0:40:51.717029	Training Loss 0.6113 (0.6109)	Training Prec@1 56.250 (56.879)	Training Prec@5 68.359 (66.486)	
2022-04-01 13:11:17,849: ============================================================
2022-04-01 13:12:02,807: time cost, forward:0.13979003736504717, backward:0.03472909424492795, data cost:0.27056452531325614 
2022-04-01 13:12:02,807: ============================================================
2022-04-01 13:12:02,807: Epoch 31/31 Batch 2400/7662 eta: 0:39:26.151018	Training Loss 0.6256 (0.6109)	Training Prec@1 53.125 (56.866)	Training Prec@5 62.305 (66.476)	
2022-04-01 13:12:02,808: ============================================================
2022-04-01 13:12:47,532: time cost, forward:0.1396463147255362, backward:0.03468885112638805, data cost:0.27081998017560294 
2022-04-01 13:12:47,532: ============================================================
2022-04-01 13:12:47,532: Epoch 31/31 Batch 2500/7662 eta: 0:38:29.146390	Training Loss 0.6095 (0.6109)	Training Prec@1 58.203 (56.868)	Training Prec@5 67.188 (66.479)	
2022-04-01 13:12:47,532: ============================================================
2022-04-01 13:13:33,187: time cost, forward:0.14007374670653217, backward:0.03472925397514059, data cost:0.27078961564651494 
2022-04-01 13:13:33,188: ============================================================
2022-04-01 13:13:33,188: Epoch 31/31 Batch 2600/7662 eta: 0:38:31.551904	Training Loss 0.6090 (0.6109)	Training Prec@1 59.570 (56.876)	Training Prec@5 67.578 (66.490)	
2022-04-01 13:13:33,188: ============================================================
2022-04-01 13:14:15,510: time cost, forward:0.13953839774130009, backward:0.03476062983484258, data cost:0.27043564260425546 
2022-04-01 13:14:15,510: ============================================================
2022-04-01 13:14:15,511: Epoch 31/31 Batch 2700/7662 eta: 0:35:00.472845	Training Loss 0.6165 (0.6109)	Training Prec@1 55.664 (56.871)	Training Prec@5 64.258 (66.492)	
2022-04-01 13:14:15,511: ============================================================
2022-04-01 13:14:58,270: time cost, forward:0.13883588279132633, backward:0.03481139017454681, data cost:0.2704438008168375 
2022-04-01 13:14:58,271: ============================================================
2022-04-01 13:14:58,271: Epoch 31/31 Batch 2800/7662 eta: 0:34:39.434266	Training Loss 0.6091 (0.6109)	Training Prec@1 58.789 (56.876)	Training Prec@5 67.188 (66.489)	
2022-04-01 13:14:58,271: ============================================================
2022-04-01 13:15:43,690: time cost, forward:0.13953781983242977, backward:0.03490146426095268, data cost:0.2700023938968865 
2022-04-01 13:15:43,690: ============================================================
2022-04-01 13:15:43,690: Epoch 31/31 Batch 2900/7662 eta: 0:36:03.324090	Training Loss 0.6273 (0.6109)	Training Prec@1 51.758 (56.884)	Training Prec@5 60.938 (66.488)	
2022-04-01 13:15:43,691: ============================================================
2022-04-01 13:16:28,754: time cost, forward:0.13998597357502854, backward:0.035100042839851645, data cost:0.2695421616845864 
2022-04-01 13:16:28,755: ============================================================
2022-04-01 13:16:28,755: Epoch 31/31 Batch 3000/7662 eta: 0:35:01.350357	Training Loss 0.6172 (0.6109)	Training Prec@1 54.492 (56.874)	Training Prec@5 64.258 (66.478)	
2022-04-01 13:16:28,755: ============================================================
2022-04-01 13:17:12,676: time cost, forward:0.14037775170152977, backward:0.03514404379963759, data cost:0.2688969317156486 
2022-04-01 13:17:12,676: ============================================================
2022-04-01 13:17:12,676: Epoch 31/31 Batch 3100/7662 eta: 0:33:24.137173	Training Loss 0.6028 (0.6109)	Training Prec@1 59.570 (56.870)	Training Prec@5 69.336 (66.480)	
2022-04-01 13:17:12,678: ============================================================
2022-04-01 13:17:57,267: time cost, forward:0.1410667531823471, backward:0.03517345578717455, data cost:0.26820099253176005 
2022-04-01 13:17:57,267: ============================================================
2022-04-01 13:17:57,267: Epoch 31/31 Batch 3200/7662 eta: 0:33:10.100962	Training Loss 0.6112 (0.6109)	Training Prec@1 58.203 (56.869)	Training Prec@5 68.555 (66.478)	
2022-04-01 13:17:57,268: ============================================================
2022-04-01 13:18:42,055: time cost, forward:0.14110125581869107, backward:0.03517462051648305, data cost:0.2682539481544321 
2022-04-01 13:18:42,056: ============================================================
2022-04-01 13:18:42,056: Epoch 31/31 Batch 3300/7662 eta: 0:32:34.130486	Training Loss 0.6082 (0.6109)	Training Prec@1 56.445 (56.877)	Training Prec@5 67.188 (66.487)	
2022-04-01 13:18:42,056: ============================================================
2022-04-01 13:19:27,669: time cost, forward:0.14154139207580155, backward:0.03515808874805312, data cost:0.2681605822901825 
2022-04-01 13:19:27,670: ============================================================
2022-04-01 13:19:27,671: Epoch 31/31 Batch 3400/7662 eta: 0:32:24.542082	Training Loss 0.5941 (0.6109)	Training Prec@1 65.430 (56.891)	Training Prec@5 73.047 (66.495)	
2022-04-01 13:19:27,671: ============================================================
2022-04-01 13:20:12,211: time cost, forward:0.1418433712018698, backward:0.03523431855905189, data cost:0.2677709351747027 
2022-04-01 13:20:12,212: ============================================================
2022-04-01 13:20:12,213: Epoch 31/31 Batch 3500/7662 eta: 0:30:54.277189	Training Loss 0.6029 (0.6109)	Training Prec@1 58.008 (56.889)	Training Prec@5 68.555 (66.496)	
2022-04-01 13:20:12,213: ============================================================
2022-04-01 13:20:56,631: time cost, forward:0.14226388070079213, backward:0.035241241950596594, data cost:0.26729218414605543 
2022-04-01 13:20:56,632: ============================================================
2022-04-01 13:20:56,632: Epoch 31/31 Batch 3600/7662 eta: 0:30:04.770790	Training Loss 0.6093 (0.6109)	Training Prec@1 57.812 (56.892)	Training Prec@5 66.992 (66.495)	
2022-04-01 13:20:56,632: ============================================================
2022-04-01 13:21:43,800: time cost, forward:0.14276794170360044, backward:0.03526933955707947, data cost:0.26748061231678644 
2022-04-01 13:21:43,801: ============================================================
2022-04-01 13:21:43,801: Epoch 31/31 Batch 3700/7662 eta: 0:31:09.309970	Training Loss 0.6107 (0.6109)	Training Prec@1 58.203 (56.883)	Training Prec@5 68.164 (66.484)	
2022-04-01 13:21:43,801: ============================================================
2022-04-01 13:22:29,303: time cost, forward:0.14336800437188205, backward:0.035432013940673086, data cost:0.26695898853813105 
2022-04-01 13:22:29,304: ============================================================
2022-04-01 13:22:29,304: Epoch 31/31 Batch 3800/7662 eta: 0:29:17.768420	Training Loss 0.6204 (0.6109)	Training Prec@1 55.273 (56.883)	Training Prec@5 65.234 (66.480)	
2022-04-01 13:22:29,304: ============================================================
2022-04-01 13:23:13,079: time cost, forward:0.14365810527346567, backward:0.03553608130968421, data cost:0.26633515759106324 
2022-04-01 13:23:13,079: ============================================================
2022-04-01 13:23:13,080: Epoch 31/31 Batch 3900/7662 eta: 0:27:27.284780	Training Loss 0.6093 (0.6109)	Training Prec@1 58.984 (56.896)	Training Prec@5 70.898 (66.491)	
2022-04-01 13:23:13,080: ============================================================
2022-04-01 13:23:56,702: time cost, forward:0.14375540899556707, backward:0.03558041841335731, data cost:0.26592671194503414 
2022-04-01 13:23:56,702: ============================================================
2022-04-01 13:23:56,702: Epoch 31/31 Batch 4000/7662 eta: 0:26:37.905177	Training Loss 0.6119 (0.6108)	Training Prec@1 55.664 (56.905)	Training Prec@5 66.992 (66.506)	
2022-04-01 13:23:56,703: ============================================================
2022-04-01 13:24:40,782: time cost, forward:0.14351272327081552, backward:0.03557487329816667, data cost:0.2660561296002811 
2022-04-01 13:24:40,782: ============================================================
2022-04-01 13:24:40,783: Epoch 31/31 Batch 4100/7662 eta: 0:26:10.576106	Training Loss 0.6097 (0.6108)	Training Prec@1 56.055 (56.911)	Training Prec@5 64.844 (66.508)	
2022-04-01 13:24:40,783: ============================================================
2022-04-01 13:25:23,154: time cost, forward:0.14303595981702374, backward:0.035597229719332324, data cost:0.26599256235464724 
2022-04-01 13:25:23,154: ============================================================
2022-04-01 13:25:23,154: Epoch 31/31 Batch 4200/7662 eta: 0:24:27.324154	Training Loss 0.6061 (0.6108)	Training Prec@1 59.180 (56.910)	Training Prec@5 68.359 (66.511)	
2022-04-01 13:25:23,154: ============================================================
2022-04-01 13:26:05,699: time cost, forward:0.14280395985869757, backward:0.03559034872842572, data cost:0.2657792544359383 
2022-04-01 13:26:05,700: ============================================================
2022-04-01 13:26:05,700: Epoch 31/31 Batch 4300/7662 eta: 0:23:50.809248	Training Loss 0.6091 (0.6108)	Training Prec@1 56.055 (56.911)	Training Prec@5 63.672 (66.513)	
2022-04-01 13:26:05,700: ============================================================
2022-04-01 13:26:49,482: time cost, forward:0.14292961262821963, backward:0.03560332711053507, data cost:0.26547132933456863 
2022-04-01 13:26:49,482: ============================================================
2022-04-01 13:26:49,482: Epoch 31/31 Batch 4400/7662 eta: 0:23:48.630001	Training Loss 0.6120 (0.6108)	Training Prec@1 55.273 (56.909)	Training Prec@5 64.648 (66.513)	
2022-04-01 13:26:49,483: ============================================================
2022-04-01 13:27:31,144: time cost, forward:0.14246613546381212, backward:0.035586027919941414, data cost:0.265342148602552 
2022-04-01 13:27:31,144: ============================================================
2022-04-01 13:27:31,144: Epoch 31/31 Batch 4500/7662 eta: 0:21:57.765959	Training Loss 0.6212 (0.6108)	Training Prec@1 52.344 (56.914)	Training Prec@5 60.742 (66.517)	
2022-04-01 13:27:31,145: ============================================================
2022-04-01 13:28:13,525: time cost, forward:0.1420170322504477, backward:0.03556725045187781, data cost:0.26535164913319326 
2022-04-01 13:28:13,525: ============================================================
2022-04-01 13:28:13,525: Epoch 31/31 Batch 4600/7662 eta: 0:21:38.132806	Training Loss 0.6091 (0.6108)	Training Prec@1 56.250 (56.915)	Training Prec@5 67.188 (66.515)	
2022-04-01 13:28:13,526: ============================================================
2022-04-01 13:28:56,840: time cost, forward:0.14171086836175784, backward:0.03557397355726867, data cost:0.2654402918652236 
2022-04-01 13:28:56,841: ============================================================
2022-04-01 13:28:56,841: Epoch 31/31 Batch 4700/7662 eta: 0:21:23.438061	Training Loss 0.6115 (0.6108)	Training Prec@1 58.594 (56.913)	Training Prec@5 68.750 (66.516)	
2022-04-01 13:28:56,841: ============================================================
2022-04-01 13:29:38,568: time cost, forward:0.14095258280544834, backward:0.03555033271028042, data cost:0.26567863195879954 
2022-04-01 13:29:38,569: ============================================================
2022-04-01 13:29:38,569: Epoch 31/31 Batch 4800/7662 eta: 0:19:54.667334	Training Loss 0.6109 (0.6108)	Training Prec@1 57.812 (56.915)	Training Prec@5 67.383 (66.516)	
2022-04-01 13:29:38,569: ============================================================
2022-04-01 13:30:19,457: time cost, forward:0.14023017849234032, backward:0.03550466174226704, data cost:0.2657548275546751 
2022-04-01 13:30:19,457: ============================================================
2022-04-01 13:30:19,457: Epoch 31/31 Batch 4900/7662 eta: 0:18:49.751659	Training Loss 0.6085 (0.6108)	Training Prec@1 55.859 (56.909)	Training Prec@5 66.797 (66.514)	
2022-04-01 13:30:19,458: ============================================================
2022-04-01 13:31:01,146: time cost, forward:0.13953057926496187, backward:0.035452237151150326, data cost:0.2660146931405782 
2022-04-01 13:31:01,146: ============================================================
2022-04-01 13:31:01,147: Epoch 31/31 Batch 5000/7662 eta: 0:18:30.183102	Training Loss 0.6087 (0.6108)	Training Prec@1 56.250 (56.917)	Training Prec@5 65.430 (66.520)	
2022-04-01 13:31:01,147: ============================================================
2022-04-01 13:31:43,877: time cost, forward:0.13951517521434964, backward:0.03545591110667894, data cost:0.2657475507500172 
2022-04-01 13:31:43,877: ============================================================
2022-04-01 13:31:43,877: Epoch 31/31 Batch 5100/7662 eta: 0:18:15.187530	Training Loss 0.6172 (0.6108)	Training Prec@1 54.883 (56.918)	Training Prec@5 64.258 (66.516)	
2022-04-01 13:31:43,877: ============================================================
2022-04-01 13:32:24,554: time cost, forward:0.13886823212098423, backward:0.03540153231935378, data cost:0.2657871854880792 
2022-04-01 13:32:24,555: ============================================================
2022-04-01 13:32:24,555: Epoch 31/31 Batch 5200/7662 eta: 0:16:41.891511	Training Loss 0.6079 (0.6108)	Training Prec@1 58.398 (56.920)	Training Prec@5 65.234 (66.517)	
2022-04-01 13:32:24,555: ============================================================
2022-04-01 13:33:06,193: time cost, forward:0.13835569713943116, backward:0.035369709361879574, data cost:0.2658950811873114 
2022-04-01 13:33:06,193: ============================================================
2022-04-01 13:33:06,193: Epoch 31/31 Batch 5300/7662 eta: 0:16:23.918081	Training Loss 0.6200 (0.6108)	Training Prec@1 53.516 (56.918)	Training Prec@5 63.477 (66.519)	
2022-04-01 13:33:06,194: ============================================================
2022-04-01 13:33:48,927: time cost, forward:0.13837778548395926, backward:0.035348631095215, data cost:0.2656511866531895 
2022-04-01 13:33:48,927: ============================================================
2022-04-01 13:33:48,927: Epoch 31/31 Batch 5400/7662 eta: 0:16:07.067538	Training Loss 0.6062 (0.6108)	Training Prec@1 58.398 (56.922)	Training Prec@5 67.773 (66.522)	
2022-04-01 13:33:48,928: ============================================================
2022-04-01 13:34:31,408: time cost, forward:0.13803146396643207, backward:0.03531876350017131, data cost:0.2657442660001348 
2022-04-01 13:34:31,408: ============================================================
2022-04-01 13:34:31,409: Epoch 31/31 Batch 5500/7662 eta: 0:15:18.873538	Training Loss 0.6088 (0.6108)	Training Prec@1 56.836 (56.931)	Training Prec@5 68.359 (66.530)	
2022-04-01 13:34:31,409: ============================================================
2022-04-01 13:35:13,219: time cost, forward:0.13772629524771923, backward:0.035309111056401915, data cost:0.26568738765685895 
2022-04-01 13:35:13,219: ============================================================
2022-04-01 13:35:13,219: Epoch 31/31 Batch 5600/7662 eta: 0:14:22.549359	Training Loss 0.6097 (0.6108)	Training Prec@1 55.859 (56.936)	Training Prec@5 64.453 (66.534)	
2022-04-01 13:35:13,219: ============================================================
2022-04-01 13:35:54,311: time cost, forward:0.13740084744018513, backward:0.035299028967907396, data cost:0.2654668856428514 
2022-04-01 13:35:54,311: ============================================================
2022-04-01 13:35:54,312: Epoch 31/31 Batch 5700/7662 eta: 0:13:26.644352	Training Loss 0.6113 (0.6108)	Training Prec@1 58.203 (56.933)	Training Prec@5 65.820 (66.534)	
2022-04-01 13:35:54,312: ============================================================
2022-04-01 13:36:36,506: time cost, forward:0.13726133505914473, backward:0.03530198410680159, data cost:0.2653759744048509 
2022-04-01 13:36:36,507: ============================================================
2022-04-01 13:36:36,507: Epoch 31/31 Batch 5800/7662 eta: 0:13:06.099871	Training Loss 0.6122 (0.6108)	Training Prec@1 54.297 (56.932)	Training Prec@5 64.062 (66.532)	
2022-04-01 13:36:36,507: ============================================================
2022-04-01 13:37:18,339: time cost, forward:0.13738011715674445, backward:0.03530632521989366, data cost:0.2649082076975927 
2022-04-01 13:37:18,340: ============================================================
2022-04-01 13:37:18,340: Epoch 31/31 Batch 5900/7662 eta: 0:12:17.511140	Training Loss 0.6042 (0.6108)	Training Prec@1 57.422 (56.931)	Training Prec@5 69.922 (66.529)	
2022-04-01 13:37:18,340: ============================================================
2022-04-01 13:37:58,943: time cost, forward:0.1370343380638869, backward:0.03528989209872839, data cost:0.2647380890459155 
2022-04-01 13:37:58,953: ============================================================
2022-04-01 13:37:58,954: Epoch 31/31 Batch 6000/7662 eta: 0:11:15.409109	Training Loss 0.6061 (0.6108)	Training Prec@1 57.617 (56.929)	Training Prec@5 67.188 (66.529)	
2022-04-01 13:37:58,954: ============================================================
2022-04-01 13:38:40,073: time cost, forward:0.1367607069398599, backward:0.035275771317276376, data cost:0.2645852073213471 
2022-04-01 13:38:40,073: ============================================================
2022-04-01 13:38:40,073: Epoch 31/31 Batch 6100/7662 eta: 0:10:42.702565	Training Loss 0.6230 (0.6107)	Training Prec@1 54.492 (56.935)	Training Prec@5 64.648 (66.538)	
2022-04-01 13:38:40,074: ============================================================
2022-04-01 13:39:22,411: time cost, forward:0.1366142868168759, backward:0.03526730148191124, data cost:0.26452818130712236 
2022-04-01 13:39:22,412: ============================================================
2022-04-01 13:39:22,412: Epoch 31/31 Batch 6200/7662 eta: 0:10:19.411387	Training Loss 0.6100 (0.6107)	Training Prec@1 55.078 (56.939)	Training Prec@5 66.211 (66.540)	
2022-04-01 13:39:22,412: ============================================================
2022-04-01 13:40:03,402: time cost, forward:0.1361552429759402, backward:0.03524615999667829, data cost:0.2645798689752443 
2022-04-01 13:40:03,402: ============================================================
2022-04-01 13:40:03,402: Epoch 31/31 Batch 6300/7662 eta: 0:09:18.698529	Training Loss 0.6202 (0.6107)	Training Prec@1 55.078 (56.943)	Training Prec@5 63.867 (66.542)	
2022-04-01 13:40:03,403: ============================================================
2022-04-01 13:40:46,339: time cost, forward:0.13604545120075914, backward:0.03526063244088327, data cost:0.2645540955402382 
2022-04-01 13:40:46,339: ============================================================
2022-04-01 13:40:46,340: Epoch 31/31 Batch 6400/7662 eta: 0:09:02.298222	Training Loss 0.6021 (0.6107)	Training Prec@1 60.742 (56.942)	Training Prec@5 69.922 (66.542)	
2022-04-01 13:40:46,340: ============================================================
2022-04-01 13:41:28,071: time cost, forward:0.13581835972307132, backward:0.03526052490970431, data cost:0.26449841692880915 
2022-04-01 13:41:28,072: ============================================================
2022-04-01 13:41:28,072: Epoch 31/31 Batch 6500/7662 eta: 0:08:05.345940	Training Loss 0.6215 (0.6107)	Training Prec@1 53.711 (56.948)	Training Prec@5 64.844 (66.547)	
2022-04-01 13:41:28,072: ============================================================
2022-04-01 13:42:09,667: time cost, forward:0.13539598258738628, backward:0.03523536276900419, data cost:0.2646408966227469 
2022-04-01 13:42:09,667: ============================================================
2022-04-01 13:42:09,667: Epoch 31/31 Batch 6600/7662 eta: 0:07:22.158072	Training Loss 0.6135 (0.6107)	Training Prec@1 56.055 (56.950)	Training Prec@5 66.602 (66.550)	
2022-04-01 13:42:09,667: ============================================================
2022-04-01 13:42:51,818: time cost, forward:0.13520125951993323, backward:0.035212431297068775, data cost:0.26464677501176787 
2022-04-01 13:42:51,819: ============================================================
2022-04-01 13:42:51,819: Epoch 31/31 Batch 6700/7662 eta: 0:06:45.922299	Training Loss 0.6036 (0.6107)	Training Prec@1 58.594 (56.953)	Training Prec@5 70.117 (66.551)	
2022-04-01 13:42:51,819: ============================================================
2022-04-01 13:43:32,716: time cost, forward:0.13500137163586678, backward:0.035185600943662854, data cost:0.2644829706928979 
2022-04-01 13:43:32,717: ============================================================
2022-04-01 13:43:32,717: Epoch 31/31 Batch 6800/7662 eta: 0:05:52.948102	Training Loss 0.6062 (0.6107)	Training Prec@1 57.227 (56.957)	Training Prec@5 67.969 (66.556)	
2022-04-01 13:43:32,717: ============================================================
2022-04-01 13:44:14,186: time cost, forward:0.13472354054399152, backward:0.035196051699196984, data cost:0.2644542361155923 
2022-04-01 13:44:14,187: ============================================================
2022-04-01 13:44:14,187: Epoch 31/31 Batch 6900/7662 eta: 0:05:16.419929	Training Loss 0.6172 (0.6107)	Training Prec@1 56.055 (56.961)	Training Prec@5 65.430 (66.562)	
2022-04-01 13:44:14,187: ============================================================
2022-04-01 13:44:54,790: time cost, forward:0.13433163004920284, backward:0.03519620185478157, data cost:0.2644287904921149 
2022-04-01 13:44:54,790: ============================================================
2022-04-01 13:44:54,790: Epoch 31/31 Batch 7000/7662 eta: 0:04:29.198866	Training Loss 0.6154 (0.6107)	Training Prec@1 54.688 (56.962)	Training Prec@5 66.211 (66.562)	
2022-04-01 13:44:54,791: ============================================================
2022-04-01 13:45:35,248: time cost, forward:0.13395225361948837, backward:0.035191774200362076, data cost:0.26439765742638194 
2022-04-01 13:45:35,248: ============================================================
2022-04-01 13:45:35,248: Epoch 31/31 Batch 7100/7662 eta: 0:03:47.778702	Training Loss 0.6125 (0.6107)	Training Prec@1 58.008 (56.965)	Training Prec@5 67.383 (66.563)	
2022-04-01 13:45:35,249: ============================================================
2022-04-01 13:46:16,318: time cost, forward:0.13364843286264438, backward:0.03516458620510427, data cost:0.2643961595121167 
2022-04-01 13:46:16,319: ============================================================
2022-04-01 13:46:16,319: Epoch 31/31 Batch 7200/7662 eta: 0:03:10.156600	Training Loss 0.6164 (0.6107)	Training Prec@1 54.102 (56.966)	Training Prec@5 64.453 (66.562)	
2022-04-01 13:46:16,319: ============================================================
2022-04-01 13:46:58,395: time cost, forward:0.13352049336170135, backward:0.03513757704643211, data cost:0.2643808021433044 
2022-04-01 13:46:58,395: ============================================================
2022-04-01 13:46:58,395: Epoch 31/31 Batch 7300/7662 eta: 0:02:32.737070	Training Loss 0.6074 (0.6107)	Training Prec@1 53.711 (56.971)	Training Prec@5 64.648 (66.564)	
2022-04-01 13:46:58,396: ============================================================
2022-04-01 13:47:38,647: time cost, forward:0.1331792855717102, backward:0.035099722272819045, data cost:0.264341621177231 
2022-04-01 13:47:38,647: ============================================================
2022-04-01 13:47:38,647: Epoch 31/31 Batch 7400/7662 eta: 0:01:45.862519	Training Loss 0.6082 (0.6106)	Training Prec@1 59.375 (56.972)	Training Prec@5 67.773 (66.567)	
2022-04-01 13:47:38,647: ============================================================
2022-04-01 13:48:22,380: time cost, forward:0.13329642148697626, backward:0.03511748518653195, data cost:0.26425269642326416 
2022-04-01 13:48:22,380: ============================================================
2022-04-01 13:48:22,380: Epoch 31/31 Batch 7500/7662 eta: 0:01:11.284975	Training Loss 0.6058 (0.6106)	Training Prec@1 55.859 (56.971)	Training Prec@5 66.211 (66.567)	
2022-04-01 13:48:22,381: ============================================================
2022-04-01 13:49:03,836: time cost, forward:0.13315539765411308, backward:0.03509569108478332, data cost:0.2641810997487181 
2022-04-01 13:49:03,836: ============================================================
2022-04-01 13:49:03,837: Epoch 31/31 Batch 7600/7662 eta: 0:00:26.117625	Training Loss 0.6082 (0.6106)	Training Prec@1 57.617 (56.973)	Training Prec@5 69.141 (66.569)	
2022-04-01 13:49:03,837: ============================================================
2022-04-01 13:49:31,088: Epoch: 31/31 eta: 0:00:00	Training Loss 0.6126 (0.6106)	Training Prec@1 55.859 (56.976)	Training Prec@5 66.211 (66.572)
2022-04-01 13:49:31,089: ============================================================
2022-04-01 13:49:31,092: Save Checkpoint...
2022-04-01 13:49:31,092: ============================================================
2022-04-01 13:49:33,331: Save done!
2022-04-01 13:49:33,331: ============================================================
