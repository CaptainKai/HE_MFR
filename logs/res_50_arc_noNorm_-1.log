2022-07-24 14:13:26,137: ('name', 'resnet-50-arc')
2022-07-24 14:13:26,138: ('description', '去掉norm初始化来一次实验')
2022-07-24 14:13:26,138: ('data_settings', {'training': {'batch_size': 512, 'num_workers': 4, 'num_class': 86876, 'loader_settings': {'lmdb_path': '/home/ubuntu/data4/lk/data/lmdb_mask_augu_full', 'num': 3923399, 'max_reader': 4, 'augu_paral': False, 'ldm68': False, 'augu_rate': 0, 'preproc': None, 'shuffle': True}}})
2022-07-24 14:13:26,138: ('common_settings', {'backbone': {'num': 1, 'settings': [{'backbone_model_name': 'resnet50', 'args': {'input_size': [112, 112]}, 'resume_net_model': None}]}, 'classifier': {'num': 1, 'settings': [{'classifier_model_name': 'ArcFace', 'args': {'in_features': 512, 'out_features': 86876}, 'resume_net_classifier': None, 'alpha': 1}]}})
2022-07-24 14:13:26,138: ('gpu_settings', {'no_cuda': False, 'gpu_num': 2})
2022-07-24 14:13:26,138: ('log_settings', {'training': {'log_path': './logs/res_50_arc_noNorm.log', 'log_pic_path': './logs/pic/res_50_arc_noNorm/', 'save_path': 'snapshot/res_50_arc_noNorm/', 'log_interval': 100}, 'testing': {'result_path': './result/result.txt'}})
2022-07-24 14:13:26,138: ('other_settings', {'resume': False, 'resume_net_optimizer': None, 'start_epoch': 1, 'max_epoch': 25, 'lr': 0.05, 'base': 'epoch', 'step_size': [10, 20, 30], 'momentum': 0.9, 'gama': 0.1, 'weight_decay': 0.0005})
2022-07-24 14:13:26,138: ('environ_settings', {'rank': -1, 'dist_url': 'env://', 'world_size': -1, 'gpu': None, 'dist_backend': 'nccl', 'distributed': False, 'master_port': 22345, 'multiprocessing_distributed': False, 'SEED': 1337})
2022-07-24 14:13:26,138: ('local_rank', -1)
2022-07-24 14:13:26,879: ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer2): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer3): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (4): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (5): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer4): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (bn_o1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (dropout): Dropout(p=0, inplace=False)
  (fc): Linear(in_features=32768, out_features=512, bias=True)
)
2022-07-24 14:13:31,379: Use DP
2022-07-24 14:13:35,353: CrossEntropyLoss()
2022-07-24 14:13:35,353: LogSoftmax(dim=1)
2022-07-24 14:13:35,353: NLLLoss()
2022-07-24 14:13:35,353: <bound method Trainer.loss_func of <trainner.Trainer object at 0x7faecd420ef0>>
2022-07-24 14:14:19,074: time cost, forward:0.13186368797764633, backward:0.11261759141478876, data cost:0.19456357185286705 
2022-07-24 14:14:19,075: ============================================================
2022-07-24 14:14:19,075: Epoch 1/25 Batch 100/7662 eta: 23:15:02.910394	Training Loss1 45.0729 (45.3424)	Training Total_Loss 45.0729 (45.3424)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.006)	
2022-07-24 14:14:19,075: ============================================================
2022-07-24 14:14:59,627: time cost, forward:0.12773819185381557, backward:0.10460999742824229, data cost:0.18950464497858555 
2022-07-24 14:14:59,627: ============================================================
2022-07-24 14:14:59,627: Epoch 1/25 Batch 200/7662 eta: 21:33:17.869774	Training Loss1 45.1021 (45.1455)	Training Total_Loss 45.1021 (45.1455)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.005)	
2022-07-24 14:14:59,627: ============================================================
2022-07-24 14:15:40,326: time cost, forward:0.12644485167436376, backward:0.10209479459552064, data cost:0.1880820602876287 
2022-07-24 14:15:40,326: ============================================================
2022-07-24 14:15:40,326: Epoch 1/25 Batch 300/7662 eta: 21:37:17.162188	Training Loss1 44.8521 (45.0461)	Training Total_Loss 44.8521 (45.0461)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.005)	
2022-07-24 14:15:40,326: ============================================================
2022-07-24 14:16:21,092: time cost, forward:0.1258876449183414, backward:0.1008777708039248, data cost:0.18744381388327233 
2022-07-24 14:16:21,092: ============================================================
2022-07-24 14:16:21,092: Epoch 1/25 Batch 400/7662 eta: 21:38:44.028362	Training Loss1 44.7936 (44.9818)	Training Total_Loss 44.7936 (44.9818)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.005)	
2022-07-24 14:16:21,092: ============================================================
2022-07-24 14:17:01,872: time cost, forward:0.12554098035625083, backward:0.10017686807559822, data cost:0.18708110715678794 
2022-07-24 14:17:01,873: ============================================================
2022-07-24 14:17:01,873: Epoch 1/25 Batch 500/7662 eta: 21:38:31.961060	Training Loss1 44.7125 (44.9288)	Training Total_Loss 44.7125 (44.9288)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.004)	
2022-07-24 14:17:01,873: ============================================================
2022-07-24 14:17:42,680: time cost, forward:0.1253641193020523, backward:0.09968690919955704, data cost:0.1868531481053475 
2022-07-24 14:17:42,681: ============================================================
2022-07-24 14:17:42,681: Epoch 1/25 Batch 600/7662 eta: 21:38:43.610216	Training Loss1 44.7116 (44.8846)	Training Total_Loss 44.7116 (44.8846)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.004)	
2022-07-24 14:17:42,681: ============================================================
2022-07-24 14:18:23,508: time cost, forward:0.12523680354051495, backward:0.09933310789782261, data cost:0.18670366318611287 
2022-07-24 14:18:23,509: ============================================================
2022-07-24 14:18:23,509: Epoch 1/25 Batch 700/7662 eta: 21:38:40.322434	Training Loss1 44.6901 (44.8438)	Training Total_Loss 44.6901 (44.8438)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.005)	
2022-07-24 14:18:23,509: ============================================================
2022-07-24 14:19:04,307: time cost, forward:0.12509849641439463, backward:0.0990965205229567, data cost:0.18657186810155685 
2022-07-24 14:19:04,307: ============================================================
2022-07-24 14:19:04,307: Epoch 1/25 Batch 800/7662 eta: 21:37:03.328554	Training Loss1 44.6716 (44.8078)	Training Total_Loss 44.6716 (44.8078)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.005)	
2022-07-24 14:19:04,307: ============================================================
2022-07-24 14:19:45,089: time cost, forward:0.1249920995667726, backward:0.09890024521459595, data cost:0.18647606115585175 
2022-07-24 14:19:45,089: ============================================================
2022-07-24 14:19:45,090: Epoch 1/25 Batch 900/7662 eta: 21:35:52.074129	Training Loss1 44.5462 (44.7742)	Training Total_Loss 44.5462 (44.7742)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.005)	
2022-07-24 14:19:45,090: ============================================================
2022-07-24 14:20:25,930: time cost, forward:0.12495030965413656, backward:0.09875053543228286, data cost:0.18640438524691072 
2022-07-24 14:20:25,930: ============================================================
2022-07-24 14:20:25,931: Epoch 1/25 Batch 1000/7662 eta: 21:37:02.903624	Training Loss1 44.2990 (44.7411)	Training Total_Loss 44.2990 (44.7411)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.005)	
2022-07-24 14:20:25,931: ============================================================
2022-07-24 14:21:06,769: time cost, forward:0.12491779570366926, backward:0.09862052754340549, data cost:0.18635225079079126 
2022-07-24 14:21:06,770: ============================================================
2022-07-24 14:21:06,770: Epoch 1/25 Batch 1100/7662 eta: 21:36:18.801959	Training Loss1 44.4973 (44.7109)	Training Total_Loss 44.4973 (44.7109)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.006)	
2022-07-24 14:21:06,770: ============================================================
2022-07-24 14:21:47,573: time cost, forward:0.12486349134469052, backward:0.09850801797187557, data cost:0.186311059638398 
2022-07-24 14:21:47,573: ============================================================
2022-07-24 14:21:47,573: Epoch 1/25 Batch 1200/7662 eta: 21:34:29.418602	Training Loss1 44.4282 (44.6814)	Training Total_Loss 44.4282 (44.6814)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.006)	
2022-07-24 14:21:47,573: ============================================================
2022-07-24 14:22:28,423: time cost, forward:0.12481790693839574, backward:0.09844950917503116, data cost:0.18627703400920959 
2022-07-24 14:22:28,423: ============================================================
2022-07-24 14:22:28,424: Epoch 1/25 Batch 1300/7662 eta: 21:35:18.622397	Training Loss1 44.3912 (44.6534)	Training Total_Loss 44.3912 (44.6534)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.006)	
2022-07-24 14:22:28,424: ============================================================
2022-07-24 14:23:09,254: time cost, forward:0.12478423663937593, backward:0.09838349398244185, data cost:0.18624513536116497 
2022-07-24 14:23:09,254: ============================================================
2022-07-24 14:23:09,254: Epoch 1/25 Batch 1400/7662 eta: 21:33:59.824172	Training Loss1 44.2122 (44.6260)	Training Total_Loss 44.2122 (44.6260)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.006)	
2022-07-24 14:23:09,254: ============================================================
2022-07-24 14:23:50,238: time cost, forward:0.12476695021285146, backward:0.09841020811868557, data cost:0.18621926756204168 
2022-07-24 14:23:50,238: ============================================================
2022-07-24 14:23:50,238: Epoch 1/25 Batch 1500/7662 eta: 21:38:11.001566	Training Loss1 44.3841 (44.5989)	Training Total_Loss 44.3841 (44.5989)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.007)	
2022-07-24 14:23:50,239: ============================================================
2022-07-24 14:24:31,239: time cost, forward:0.12475030566842352, backward:0.09843834449978006, data cost:0.18620383642553315 
2022-07-24 14:24:31,239: ============================================================
2022-07-24 14:24:31,239: Epoch 1/25 Batch 1600/7662 eta: 21:38:01.154057	Training Loss1 44.1649 (44.5724)	Training Total_Loss 44.1649 (44.5724)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.195 (0.007)	
2022-07-24 14:24:31,239: ============================================================
2022-07-24 14:25:12,292: time cost, forward:0.12475198307340464, backward:0.09846853269697148, data cost:0.18619645322470751 
2022-07-24 14:25:12,292: ============================================================
2022-07-24 14:25:12,292: Epoch 1/25 Batch 1700/7662 eta: 21:38:59.276596	Training Loss1 44.1630 (44.5455)	Training Total_Loss 44.1630 (44.5455)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.007)	
2022-07-24 14:25:12,292: ============================================================
2022-07-24 14:25:53,304: time cost, forward:0.12474833918386463, backward:0.09847909692527852, data cost:0.18619042293703378 
2022-07-24 14:25:53,305: ============================================================
2022-07-24 14:25:53,305: Epoch 1/25 Batch 1800/7662 eta: 21:37:02.014864	Training Loss1 44.0801 (44.5199)	Training Total_Loss 44.0801 (44.5199)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.007)	
2022-07-24 14:25:53,305: ============================================================
2022-07-24 14:26:34,198: time cost, forward:0.12475091021207836, backward:0.09843208401877357, data cost:0.18617599584228933 
2022-07-24 14:26:34,199: ============================================================
2022-07-24 14:26:34,199: Epoch 1/25 Batch 1900/7662 eta: 21:32:36.224137	Training Loss1 43.8569 (44.4945)	Training Total_Loss 43.8569 (44.4945)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.007)	
2022-07-24 14:26:34,199: ============================================================
2022-07-24 14:27:15,125: time cost, forward:0.12476089145017302, backward:0.09839356142380883, data cost:0.18616681948132727 
2022-07-24 14:27:15,125: ============================================================
2022-07-24 14:27:15,126: Epoch 1/25 Batch 2000/7662 eta: 21:32:56.768681	Training Loss1 43.9856 (44.4690)	Training Total_Loss 43.9856 (44.4690)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.007)	
2022-07-24 14:27:15,126: ============================================================
2022-07-24 14:27:56,111: time cost, forward:0.12478965767909936, backward:0.09835644220385795, data cost:0.18617023610682532 
2022-07-24 14:27:56,112: ============================================================
2022-07-24 14:27:56,112: Epoch 1/25 Batch 2100/7662 eta: 21:34:09.119611	Training Loss1 44.0390 (44.4441)	Training Total_Loss 44.0390 (44.4441)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.007)	
2022-07-24 14:27:56,112: ============================================================
2022-07-24 14:28:37,080: time cost, forward:0.12481262077792984, backward:0.09831966579692263, data cost:0.1861715079329674 
2022-07-24 14:28:37,080: ============================================================
2022-07-24 14:28:37,080: Epoch 1/25 Batch 2200/7662 eta: 21:32:54.179371	Training Loss1 43.9906 (44.4196)	Training Total_Loss 43.9906 (44.4196)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.007)	
2022-07-24 14:28:37,081: ============================================================
2022-07-24 14:29:18,090: time cost, forward:0.12485024419853406, backward:0.09828712816806709, data cost:0.18617300698942804 
2022-07-24 14:29:18,090: ============================================================
2022-07-24 14:29:18,090: Epoch 1/25 Batch 2300/7662 eta: 21:33:31.222791	Training Loss1 43.8239 (44.3957)	Training Total_Loss 43.8239 (44.3957)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.008)	
2022-07-24 14:29:18,090: ============================================================
2022-07-24 14:29:59,130: time cost, forward:0.12487304762235628, backward:0.09828039982657773, data cost:0.18617606043765922 
2022-07-24 14:29:59,130: ============================================================
2022-07-24 14:29:59,130: Epoch 1/25 Batch 2400/7662 eta: 21:33:48.022652	Training Loss1 43.8468 (44.3709)	Training Total_Loss 43.8468 (44.3709)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.008)	
2022-07-24 14:29:59,130: ============================================================
2022-07-24 14:30:40,158: time cost, forward:0.12488729117058811, backward:0.09827234116302772, data cost:0.18617715202078144 
2022-07-24 14:30:40,158: ============================================================
2022-07-24 14:30:40,158: Epoch 1/25 Batch 2500/7662 eta: 21:32:43.905800	Training Loss1 43.7338 (44.3475)	Training Total_Loss 43.7338 (44.3475)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.195 (0.008)	
2022-07-24 14:30:40,158: ============================================================
2022-07-24 14:31:21,132: time cost, forward:0.12490250322166523, backward:0.09825024452517701, data cost:0.18617415464855516 
2022-07-24 14:31:21,132: ============================================================
2022-07-24 14:31:21,132: Epoch 1/25 Batch 2600/7662 eta: 21:30:20.584930	Training Loss1 43.6746 (44.3235)	Training Total_Loss 43.6746 (44.3235)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.008)	
2022-07-24 14:31:21,132: ============================================================
2022-07-24 14:32:02,140: time cost, forward:0.12490108809059484, backward:0.09825343368405896, data cost:0.18617574671278533 
2022-07-24 14:32:02,140: ============================================================
2022-07-24 14:32:02,140: Epoch 1/25 Batch 2700/7662 eta: 21:30:43.710361	Training Loss1 43.7202 (44.3003)	Training Total_Loss 43.7202 (44.3003)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.008)	
2022-07-24 14:32:02,140: ============================================================
2022-07-24 14:32:43,154: time cost, forward:0.12490693566287232, backward:0.09825604538612598, data cost:0.18617232810944137 
2022-07-24 14:32:43,154: ============================================================
2022-07-24 14:32:43,154: Epoch 1/25 Batch 2800/7662 eta: 21:30:14.959199	Training Loss1 43.6471 (44.2767)	Training Total_Loss 43.6471 (44.2767)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.008)	
2022-07-24 14:32:43,155: ============================================================
2022-07-24 14:33:24,196: time cost, forward:0.12491890634903212, backward:0.09825848373473615, data cost:0.18617285420541807 
2022-07-24 14:33:24,197: ============================================================
2022-07-24 14:33:24,197: Epoch 1/25 Batch 2900/7662 eta: 21:30:26.978764	Training Loss1 43.3775 (44.2533)	Training Total_Loss 43.3775 (44.2533)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.009)	
2022-07-24 14:33:24,197: ============================================================
2022-07-24 14:34:05,160: time cost, forward:0.12492765574186554, backward:0.09823680520256427, data cost:0.18617348330702213 
2022-07-24 14:34:05,160: ============================================================
2022-07-24 14:34:05,161: Epoch 1/25 Batch 3000/7662 eta: 21:27:17.390570	Training Loss1 43.5625 (44.2295)	Training Total_Loss 43.5625 (44.2295)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.009)	
2022-07-24 14:34:05,161: ============================================================
2022-07-24 14:34:46,169: time cost, forward:0.12493581131759403, backward:0.09823151187152007, data cost:0.1861720095914808 
2022-07-24 14:34:46,169: ============================================================
2022-07-24 14:34:46,169: Epoch 1/25 Batch 3100/7662 eta: 21:28:01.339184	Training Loss1 43.3914 (44.2060)	Training Total_Loss 43.3914 (44.2060)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.010)	
2022-07-24 14:34:46,169: ============================================================
2022-07-24 14:35:27,173: time cost, forward:0.12494645911702963, backward:0.09822513305160842, data cost:0.18616894417608035 
2022-07-24 14:35:27,173: ============================================================
2022-07-24 14:35:27,173: Epoch 1/25 Batch 3200/7662 eta: 21:27:11.600666	Training Loss1 43.3968 (44.1831)	Training Total_Loss 43.3968 (44.1831)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.010)	
2022-07-24 14:35:27,173: ============================================================
2022-07-24 14:36:08,179: time cost, forward:0.12496638334169645, backward:0.09820262646451074, data cost:0.18616614677068427 
2022-07-24 14:36:08,179: ============================================================
2022-07-24 14:36:08,179: Epoch 1/25 Batch 3300/7662 eta: 21:26:34.232069	Training Loss1 43.2981 (44.1600)	Training Total_Loss 43.2981 (44.1600)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.010)	
2022-07-24 14:36:08,179: ============================================================
2022-07-24 14:36:49,118: time cost, forward:0.12496777063399492, backward:0.09818931564438796, data cost:0.18616059507542268 
2022-07-24 14:36:49,118: ============================================================
2022-07-24 14:36:49,119: Epoch 1/25 Batch 3400/7662 eta: 21:23:47.706494	Training Loss1 43.3173 (44.1368)	Training Total_Loss 43.3173 (44.1368)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.010)	
2022-07-24 14:36:49,119: ============================================================
2022-07-24 14:37:30,172: time cost, forward:0.12498582871037232, backward:0.09818746887571167, data cost:0.1861566847888154 
2022-07-24 14:37:30,172: ============================================================
2022-07-24 14:37:30,173: Epoch 1/25 Batch 3500/7662 eta: 21:26:42.260080	Training Loss1 43.2326 (44.1137)	Training Total_Loss 43.2326 (44.1137)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.011)	
2022-07-24 14:37:30,173: ============================================================
2022-07-24 14:38:11,126: time cost, forward:0.12498547408805354, backward:0.0981819774085, data cost:0.18614975542914838 
2022-07-24 14:38:11,126: ============================================================
2022-07-24 14:38:11,126: Epoch 1/25 Batch 3600/7662 eta: 21:22:53.016970	Training Loss1 43.2808 (44.0908)	Training Total_Loss 43.2808 (44.0908)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.011)	
2022-07-24 14:38:11,126: ============================================================
2022-07-24 14:38:52,151: time cost, forward:0.1249970105184868, backward:0.09818277355141497, data cost:0.18614479792250205 
2022-07-24 14:38:52,151: ============================================================
2022-07-24 14:38:52,151: Epoch 1/25 Batch 3700/7662 eta: 21:24:25.719757	Training Loss1 43.2427 (44.0680)	Training Total_Loss 43.2427 (44.0680)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.011)	
2022-07-24 14:38:52,151: ============================================================
2022-07-24 14:39:33,176: time cost, forward:0.12502517070102515, backward:0.09816807368831529, data cost:0.18613895274175096 
2022-07-24 14:39:33,176: ============================================================
2022-07-24 14:39:33,177: Epoch 1/25 Batch 3800/7662 eta: 21:23:45.561904	Training Loss1 43.2340 (44.0455)	Training Total_Loss 43.2340 (44.0455)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.011)	
2022-07-24 14:39:33,177: ============================================================
2022-07-24 14:40:14,188: time cost, forward:0.1250434985188956, backward:0.09816284154005067, data cost:0.18612944605901444 
2022-07-24 14:40:14,188: ============================================================
2022-07-24 14:40:14,189: Epoch 1/25 Batch 3900/7662 eta: 21:22:39.388459	Training Loss1 43.1960 (44.0229)	Training Total_Loss 43.1960 (44.0229)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.012)	
2022-07-24 14:40:14,189: ============================================================
2022-07-24 14:40:55,276: time cost, forward:0.12504387998855182, backward:0.0981902539595928, data cost:0.18612270076205117 
2022-07-24 14:40:55,277: ============================================================
2022-07-24 14:40:55,277: Epoch 1/25 Batch 4000/7662 eta: 21:24:21.461619	Training Loss1 43.0062 (44.0004)	Training Total_Loss 43.0062 (44.0004)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.012)	
2022-07-24 14:40:55,277: ============================================================
2022-07-24 14:41:36,373: time cost, forward:0.125048156132434, backward:0.09821155967582113, data cost:0.18611896756393906 
2022-07-24 14:41:36,373: ============================================================
2022-07-24 14:41:36,373: Epoch 1/25 Batch 4100/7662 eta: 21:23:55.579287	Training Loss1 43.1896 (43.9776)	Training Total_Loss 43.1896 (43.9776)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.012)	
2022-07-24 14:41:36,373: ============================================================
2022-07-24 14:42:17,426: time cost, forward:0.12506913945742465, backward:0.09820676395001085, data cost:0.1861138650422211 
2022-07-24 14:42:17,427: ============================================================
2022-07-24 14:42:17,427: Epoch 1/25 Batch 4200/7662 eta: 21:21:54.342780	Training Loss1 42.9999 (43.9553)	Training Total_Loss 42.9999 (43.9553)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.013)	
2022-07-24 14:42:17,427: ============================================================
2022-07-24 14:42:58,463: time cost, forward:0.12508269625226962, backward:0.09820315759662807, data cost:0.18610766372671791 
2022-07-24 14:42:58,463: ============================================================
2022-07-24 14:42:58,464: Epoch 1/25 Batch 4300/7662 eta: 21:20:41.420416	Training Loss1 42.9602 (43.9329)	Training Total_Loss 42.9602 (43.9329)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.013)	
2022-07-24 14:42:58,464: ============================================================
2022-07-24 14:43:39,565: time cost, forward:0.12509256239559574, backward:0.09822027838807346, data cost:0.1861018987643933 
2022-07-24 14:43:39,566: ============================================================
2022-07-24 14:43:39,566: Epoch 1/25 Batch 4400/7662 eta: 21:22:03.648678	Training Loss1 42.9788 (43.9103)	Training Total_Loss 42.9788 (43.9103)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.014)	
2022-07-24 14:43:39,566: ============================================================
2022-07-24 14:44:20,608: time cost, forward:0.12510866222182335, backward:0.09821680223287331, data cost:0.1860971766118077 
2022-07-24 14:44:20,609: ============================================================
2022-07-24 14:44:20,609: Epoch 1/25 Batch 4500/7662 eta: 21:19:31.201419	Training Loss1 42.9618 (43.8877)	Training Total_Loss 42.9618 (43.8877)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.015)	
2022-07-24 14:44:20,609: ============================================================
2022-07-24 14:45:01,595: time cost, forward:0.12511239053892503, backward:0.09821609726001916, data cost:0.1860898573726746 
2022-07-24 14:45:01,595: ============================================================
2022-07-24 14:45:01,595: Epoch 1/25 Batch 4600/7662 eta: 21:17:04.007084	Training Loss1 42.7919 (43.8649)	Training Total_Loss 42.7919 (43.8649)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.195 (0.015)	
2022-07-24 14:45:01,595: ============================================================
2022-07-24 14:45:42,584: time cost, forward:0.12511862585153394, backward:0.09821137120607534, data cost:0.18608227073448622 
2022-07-24 14:45:42,584: ============================================================
2022-07-24 14:45:42,585: Epoch 1/25 Batch 4700/7662 eta: 21:16:29.412349	Training Loss1 42.8297 (43.8426)	Training Total_Loss 42.8297 (43.8426)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.195 (0.016)	
2022-07-24 14:45:42,585: ============================================================
2022-07-24 14:46:23,566: time cost, forward:0.12512856375353862, backward:0.09820467582666072, data cost:0.18607369858315895 
2022-07-24 14:46:23,566: ============================================================
2022-07-24 14:46:23,566: Epoch 1/25 Batch 4800/7662 eta: 21:15:33.692608	Training Loss1 42.6527 (43.8199)	Training Total_Loss 42.6527 (43.8199)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-07-24 14:46:23,566: ============================================================
2022-07-24 14:47:04,557: time cost, forward:0.12513993311522079, backward:0.0981966417452393, data cost:0.1860676008381389 
2022-07-24 14:47:04,558: ============================================================
2022-07-24 14:47:04,558: Epoch 1/25 Batch 4900/7662 eta: 21:15:11.097436	Training Loss1 42.6961 (43.7976)	Training Total_Loss 42.6961 (43.7976)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-07-24 14:47:04,558: ============================================================
2022-07-24 14:47:45,597: time cost, forward:0.12515668235652136, backward:0.09819003109169808, data cost:0.1860617761445966 
2022-07-24 14:47:45,597: ============================================================
2022-07-24 14:47:45,598: Epoch 1/25 Batch 5000/7662 eta: 21:16:00.173621	Training Loss1 42.6110 (43.7754)	Training Total_Loss 42.6110 (43.7754)	Training Prec@1 0.195 (0.004)	Training Prec@5 0.195 (0.018)	
2022-07-24 14:47:45,598: ============================================================
2022-07-24 14:48:26,555: time cost, forward:0.1251481945174749, backward:0.0981959949687173, data cost:0.18605446333884257 
2022-07-24 14:48:26,555: ============================================================
2022-07-24 14:48:26,556: Epoch 1/25 Batch 5100/7662 eta: 21:12:46.525351	Training Loss1 42.5358 (43.7532)	Training Total_Loss 42.5358 (43.7532)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.195 (0.019)	
2022-07-24 14:48:26,556: ============================================================
2022-07-24 14:49:07,535: time cost, forward:0.12514966573823436, backward:0.09819593872558981, data cost:0.1860483377386593 
2022-07-24 14:49:07,535: ============================================================
2022-07-24 14:49:07,535: Epoch 1/25 Batch 5200/7662 eta: 21:12:46.172437	Training Loss1 42.5925 (43.7310)	Training Total_Loss 42.5925 (43.7310)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.019)	
2022-07-24 14:49:07,535: ============================================================
2022-07-24 14:49:48,569: time cost, forward:0.1251618943139728, backward:0.09819435042960618, data cost:0.18604287518085366 
2022-07-24 14:49:48,570: ============================================================
2022-07-24 14:49:48,570: Epoch 1/25 Batch 5300/7662 eta: 21:13:46.979430	Training Loss1 42.5276 (43.7092)	Training Total_Loss 42.5276 (43.7092)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.020)	
2022-07-24 14:49:48,570: ============================================================
2022-07-24 14:50:29,641: time cost, forward:0.12515930428198474, backward:0.09821384009177386, data cost:0.18603834939855274 
2022-07-24 14:50:29,641: ============================================================
2022-07-24 14:50:29,641: Epoch 1/25 Batch 5400/7662 eta: 21:14:15.025835	Training Loss1 42.4299 (43.6873)	Training Total_Loss 42.4299 (43.6873)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.021)	
2022-07-24 14:50:29,641: ============================================================
2022-07-24 14:51:10,770: time cost, forward:0.12516226649696252, backward:0.09823257794356775, data cost:0.18603381557364013 
2022-07-24 14:51:10,771: ============================================================
2022-07-24 14:51:10,771: Epoch 1/25 Batch 5500/7662 eta: 21:15:22.427415	Training Loss1 42.4347 (43.6657)	Training Total_Loss 42.4347 (43.6657)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.022)	
2022-07-24 14:51:10,771: ============================================================
2022-07-24 14:51:51,916: time cost, forward:0.1251665929275488, backward:0.09825336062326924, data cost:0.18603037212294837 
2022-07-24 14:51:51,916: ============================================================
2022-07-24 14:51:51,916: Epoch 1/25 Batch 5600/7662 eta: 21:15:10.225208	Training Loss1 42.3752 (43.6440)	Training Total_Loss 42.3752 (43.6440)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.023)	
2022-07-24 14:51:51,917: ============================================================
2022-07-24 14:52:33,062: time cost, forward:0.12516376369353824, backward:0.0982842851174591, data cost:0.18602487852247498 
2022-07-24 14:52:33,063: ============================================================
2022-07-24 14:52:33,063: Epoch 1/25 Batch 5700/7662 eta: 21:14:31.242626	Training Loss1 42.3914 (43.6223)	Training Total_Loss 42.3914 (43.6223)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.024)	
2022-07-24 14:52:33,063: ============================================================
2022-07-24 14:53:14,028: time cost, forward:0.12516780227684815, backward:0.09827550182385288, data cost:0.18602151351872137 
2022-07-24 14:53:14,028: ============================================================
2022-07-24 14:53:14,028: Epoch 1/25 Batch 5800/7662 eta: 21:08:13.060851	Training Loss1 42.3892 (43.6009)	Training Total_Loss 42.3892 (43.6009)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.025)	
2022-07-24 14:53:14,028: ============================================================
2022-07-24 14:53:54,947: time cost, forward:0.12516094135175138, backward:0.09827209994194366, data cost:0.18601614448009335 
2022-07-24 14:53:54,947: ============================================================
2022-07-24 14:53:54,947: Epoch 1/25 Batch 5900/7662 eta: 21:06:07.202217	Training Loss1 42.2819 (43.5795)	Training Total_Loss 42.2819 (43.5795)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.195 (0.027)	
2022-07-24 14:53:54,948: ============================================================
2022-07-24 14:54:35,944: time cost, forward:0.12515442330433063, backward:0.09827975257870991, data cost:0.18601241877206584 
2022-07-24 14:54:35,944: ============================================================
2022-07-24 14:54:35,944: Epoch 1/25 Batch 6000/7662 eta: 21:07:49.870961	Training Loss1 42.3298 (43.5582)	Training Total_Loss 42.3298 (43.5582)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.195 (0.028)	
2022-07-24 14:54:35,944: ============================================================
2022-07-24 14:55:16,954: time cost, forward:0.12515248773840337, backward:0.09828489888865628, data cost:0.1860099325885263 
2022-07-24 14:55:16,954: ============================================================
2022-07-24 14:55:16,954: Epoch 1/25 Batch 6100/7662 eta: 21:07:33.992736	Training Loss1 42.2690 (43.5373)	Training Total_Loss 42.2690 (43.5373)	Training Prec@1 0.000 (0.009)	Training Prec@5 0.195 (0.030)	
2022-07-24 14:55:16,955: ============================================================
2022-07-24 14:55:58,093: time cost, forward:0.12515668273645172, backward:0.09830099268293435, data cost:0.1860081674899184 
2022-07-24 14:55:58,094: ============================================================
2022-07-24 14:55:58,094: Epoch 1/25 Batch 6200/7662 eta: 21:10:52.227878	Training Loss1 42.3147 (43.5163)	Training Total_Loss 42.3147 (43.5163)	Training Prec@1 0.000 (0.009)	Training Prec@5 0.195 (0.031)	
2022-07-24 14:55:58,094: ============================================================
2022-07-24 14:56:39,182: time cost, forward:0.12516905557808375, backward:0.09830036491113042, data cost:0.18600883785174524 
2022-07-24 14:56:39,182: ============================================================
2022-07-24 14:56:39,182: Epoch 1/25 Batch 6300/7662 eta: 21:08:37.059464	Training Loss1 42.2442 (43.4957)	Training Total_Loss 42.2442 (43.4957)	Training Prec@1 0.000 (0.010)	Training Prec@5 0.195 (0.033)	
2022-07-24 14:56:39,183: ============================================================
2022-07-24 14:57:20,203: time cost, forward:0.12517618618825205, backward:0.09829335444456787, data cost:0.18600849021801932 
2022-07-24 14:57:20,203: ============================================================
2022-07-24 14:57:20,204: Epoch 1/25 Batch 6400/7662 eta: 21:05:51.088626	Training Loss1 42.1260 (43.4752)	Training Total_Loss 42.1260 (43.4752)	Training Prec@1 0.195 (0.011)	Training Prec@5 0.195 (0.035)	
2022-07-24 14:57:20,204: ============================================================
2022-07-24 14:58:01,212: time cost, forward:0.1251797879323682, backward:0.09829176886482667, data cost:0.18600607054071033 
2022-07-24 14:58:01,212: ============================================================
2022-07-24 14:58:01,212: Epoch 1/25 Batch 6500/7662 eta: 21:04:47.109392	Training Loss1 42.1073 (43.4548)	Training Total_Loss 42.1073 (43.4548)	Training Prec@1 0.195 (0.012)	Training Prec@5 0.391 (0.036)	
2022-07-24 14:58:01,212: ============================================================
2022-07-24 14:58:42,276: time cost, forward:0.1251861207285403, backward:0.09829246945445475, data cost:0.18600513978805808 
2022-07-24 14:58:42,276: ============================================================
2022-07-24 14:58:42,276: Epoch 1/25 Batch 6600/7662 eta: 21:05:48.116608	Training Loss1 42.2067 (43.4348)	Training Total_Loss 42.2067 (43.4348)	Training Prec@1 0.195 (0.013)	Training Prec@5 0.195 (0.039)	
2022-07-24 14:58:42,276: ============================================================
2022-07-24 14:59:23,289: time cost, forward:0.12518861383124064, backward:0.09829074842820579, data cost:0.1860044756688757 
2022-07-24 14:59:23,289: ============================================================
2022-07-24 14:59:23,289: Epoch 1/25 Batch 6700/7662 eta: 21:03:33.158807	Training Loss1 42.0955 (43.4148)	Training Total_Loss 42.0955 (43.4148)	Training Prec@1 0.000 (0.014)	Training Prec@5 0.195 (0.041)	
2022-07-24 14:59:23,290: ============================================================
2022-07-24 15:00:04,411: time cost, forward:0.1252022450558314, backward:0.09829326376597274, data cost:0.1860044905500809 
2022-07-24 15:00:04,412: ============================================================
2022-07-24 15:00:04,412: Epoch 1/25 Batch 6800/7662 eta: 21:06:14.114023	Training Loss1 42.0787 (43.3951)	Training Total_Loss 42.0787 (43.3951)	Training Prec@1 0.000 (0.015)	Training Prec@5 0.000 (0.044)	
2022-07-24 15:00:04,412: ============================================================
2022-07-24 15:00:45,444: time cost, forward:0.12520127086332525, backward:0.09829721072045318, data cost:0.18600390548031473 
2022-07-24 15:00:45,444: ============================================================
2022-07-24 15:00:45,444: Epoch 1/25 Batch 6900/7662 eta: 21:02:46.714714	Training Loss1 41.9600 (43.3755)	Training Total_Loss 41.9600 (43.3755)	Training Prec@1 0.000 (0.016)	Training Prec@5 0.195 (0.047)	
2022-07-24 15:00:45,444: ============================================================
2022-07-24 15:01:26,462: time cost, forward:0.12520309805376117, backward:0.09829753343506122, data cost:0.18600229165063176 
2022-07-24 15:01:26,462: ============================================================
2022-07-24 15:01:26,463: Epoch 1/25 Batch 7000/7662 eta: 21:01:39.705377	Training Loss1 41.9774 (43.3563)	Training Total_Loss 41.9774 (43.3563)	Training Prec@1 0.195 (0.017)	Training Prec@5 0.195 (0.050)	
2022-07-24 15:01:26,463: ============================================================
2022-07-24 15:02:07,521: time cost, forward:0.12520726121031142, backward:0.09829920757856314, data cost:0.18600276531107174 
2022-07-24 15:02:07,522: ============================================================
2022-07-24 15:02:07,522: Epoch 1/25 Batch 7100/7662 eta: 21:02:13.988104	Training Loss1 41.9668 (43.3374)	Training Total_Loss 41.9668 (43.3374)	Training Prec@1 0.000 (0.018)	Training Prec@5 0.391 (0.052)	
2022-07-24 15:02:07,522: ============================================================
2022-07-24 15:02:48,568: time cost, forward:0.1252116974500637, backward:0.09829972892821638, data cost:0.18600229535405546 
2022-07-24 15:02:48,568: ============================================================
2022-07-24 15:02:48,569: Epoch 1/25 Batch 7200/7662 eta: 21:01:10.347826	Training Loss1 41.9657 (43.3187)	Training Total_Loss 41.9657 (43.3187)	Training Prec@1 0.195 (0.020)	Training Prec@5 0.195 (0.056)	
2022-07-24 15:02:48,569: ============================================================
2022-07-24 15:03:29,665: time cost, forward:0.1252124934086066, backward:0.0983083138712172, data cost:0.18600166479289196 
2022-07-24 15:03:29,665: ============================================================
2022-07-24 15:03:29,665: Epoch 1/25 Batch 7300/7662 eta: 21:02:01.351232	Training Loss1 41.9793 (43.3002)	Training Total_Loss 41.9793 (43.3002)	Training Prec@1 0.195 (0.022)	Training Prec@5 0.391 (0.060)	
2022-07-24 15:03:29,666: ============================================================
2022-07-24 15:04:10,820: time cost, forward:0.12521130214721582, backward:0.09832593804679218, data cost:0.18600305406962525 
2022-07-24 15:04:10,821: ============================================================
2022-07-24 15:04:10,821: Epoch 1/25 Batch 7400/7662 eta: 21:03:07.937154	Training Loss1 41.8712 (43.2820)	Training Total_Loss 41.8712 (43.2820)	Training Prec@1 0.195 (0.023)	Training Prec@5 0.586 (0.063)	
2022-07-24 15:04:10,821: ============================================================
2022-07-24 15:04:51,886: time cost, forward:0.12521525509660444, backward:0.09832691742525305, data cost:0.18600213437068303 
2022-07-24 15:04:51,887: ============================================================
2022-07-24 15:04:51,887: Epoch 1/25 Batch 7500/7662 eta: 20:59:42.412155	Training Loss1 41.9015 (43.2641)	Training Total_Loss 41.9015 (43.2641)	Training Prec@1 0.586 (0.025)	Training Prec@5 1.172 (0.067)	
2022-07-24 15:04:51,887: ============================================================
2022-07-24 15:05:32,945: time cost, forward:0.1252212241097867, backward:0.09832608833142309, data cost:0.18600058028503128 
2022-07-24 15:05:32,945: ============================================================
2022-07-24 15:05:32,946: Epoch 1/25 Batch 7600/7662 eta: 20:58:47.837641	Training Loss1 41.9070 (43.2465)	Training Total_Loss 41.9070 (43.2465)	Training Prec@1 0.391 (0.027)	Training Prec@5 0.586 (0.071)	
2022-07-24 15:05:32,946: ============================================================
2022-07-24 15:05:59,693: Epoch 1/25 Batch 7663/7662 eta: 20:58:21.970678	Training Loss1 41.9293 (43.2356)	Training Total_Loss 41.9293 (43.2356)	Training Prec@1 0.195 (0.028)	Training Prec@5 0.195 (0.074)	
2022-07-24 15:05:59,693: ============================================================
2022-07-24 15:06:42,469: time cost, forward:0.12525019742021656, backward:0.09751625253696634, data cost:0.20560209438054247 
2022-07-24 15:06:42,469: ============================================================
2022-07-24 15:06:42,470: Epoch 2/25 Batch 100/7662 eta: 21:46:47.124475	Training Loss1 41.8030 (41.8670)	Training Total_Loss 41.8030 (41.8670)	Training Prec@1 0.195 (0.241)	Training Prec@5 0.195 (0.501)	
2022-07-24 15:06:42,470: ============================================================
2022-07-24 15:07:23,362: time cost, forward:0.12501019808515232, backward:0.09763510742379193, data cost:0.1956291917580456 
2022-07-24 15:07:23,363: ============================================================
2022-07-24 15:07:23,363: Epoch 2/25 Batch 200/7662 eta: 20:51:56.208398	Training Loss1 41.9094 (41.8669)	Training Total_Loss 41.9094 (41.8669)	Training Prec@1 0.195 (0.231)	Training Prec@5 0.586 (0.494)	
2022-07-24 15:07:23,363: ============================================================
2022-07-24 15:08:04,191: time cost, forward:0.12483073237747652, backward:0.09757354506680797, data cost:0.19232673469594488 
2022-07-24 15:08:04,192: ============================================================
2022-07-24 15:08:04,192: Epoch 2/25 Batch 300/7662 eta: 20:49:17.989638	Training Loss1 41.8172 (41.8607)	Training Total_Loss 41.8172 (41.8607)	Training Prec@1 0.781 (0.251)	Training Prec@5 0.977 (0.512)	
2022-07-24 15:08:04,192: ============================================================
2022-07-24 15:08:45,089: time cost, forward:0.1247592432457104, backward:0.09772472632558722, data cost:0.1906538296462898 
2022-07-24 15:08:45,089: ============================================================
2022-07-24 15:08:45,089: Epoch 2/25 Batch 400/7662 eta: 20:50:41.443532	Training Loss1 41.7600 (41.8556)	Training Total_Loss 41.7600 (41.8556)	Training Prec@1 0.586 (0.268)	Training Prec@5 0.781 (0.536)	
2022-07-24 15:08:45,089: ============================================================
2022-07-24 15:09:25,976: time cost, forward:0.12477145644132503, backward:0.097728947121538, data cost:0.1896609485985521 
2022-07-24 15:09:25,976: ============================================================
2022-07-24 15:09:25,976: Epoch 2/25 Batch 500/7662 eta: 20:49:42.675081	Training Loss1 41.8195 (41.8501)	Training Total_Loss 41.8195 (41.8501)	Training Prec@1 0.391 (0.284)	Training Prec@5 0.781 (0.561)	
2022-07-24 15:09:25,976: ============================================================
2022-07-24 15:10:06,898: time cost, forward:0.12475053376466881, backward:0.0977966339639909, data cost:0.18899285176361544 
2022-07-24 15:10:06,899: ============================================================
2022-07-24 15:10:06,899: Epoch 2/25 Batch 600/7662 eta: 20:50:06.606454	Training Loss1 41.8106 (41.8443)	Training Total_Loss 41.8106 (41.8443)	Training Prec@1 0.586 (0.299)	Training Prec@5 0.977 (0.589)	
2022-07-24 15:10:06,899: ============================================================
2022-07-24 15:10:47,874: time cost, forward:0.1248773911139143, backward:0.09777560390969033, data cost:0.18853027148649246 
2022-07-24 15:10:47,875: ============================================================
2022-07-24 15:10:47,875: Epoch 2/25 Batch 700/7662 eta: 20:51:03.841855	Training Loss1 41.7341 (41.8390)	Training Total_Loss 41.7341 (41.8390)	Training Prec@1 0.977 (0.315)	Training Prec@5 1.562 (0.614)	
2022-07-24 15:10:47,875: ============================================================
2022-07-24 15:11:28,727: time cost, forward:0.12482614421725124, backward:0.09777860170013467, data cost:0.18816264042717046 
2022-07-24 15:11:28,727: ============================================================
2022-07-24 15:11:28,727: Epoch 2/25 Batch 800/7662 eta: 20:46:36.058250	Training Loss1 41.8193 (41.8335)	Training Total_Loss 41.8193 (41.8335)	Training Prec@1 0.391 (0.330)	Training Prec@5 0.781 (0.645)	
2022-07-24 15:11:28,727: ============================================================
2022-07-24 15:12:09,616: time cost, forward:0.12482398529604359, backward:0.0977744782992014, data cost:0.18788697695705597 
2022-07-24 15:12:09,616: ============================================================
2022-07-24 15:12:09,616: Epoch 2/25 Batch 900/7662 eta: 20:47:02.439722	Training Loss1 41.7038 (41.8282)	Training Total_Loss 41.7038 (41.8282)	Training Prec@1 0.391 (0.351)	Training Prec@5 0.781 (0.677)	
2022-07-24 15:12:09,616: ============================================================
2022-07-24 15:12:50,475: time cost, forward:0.12482944002619258, backward:0.09774546675734573, data cost:0.1876568746519041 
2022-07-24 15:12:50,475: ============================================================
2022-07-24 15:12:50,476: Epoch 2/25 Batch 1000/7662 eta: 20:45:27.305396	Training Loss1 41.7745 (41.8227)	Training Total_Loss 41.7745 (41.8227)	Training Prec@1 0.586 (0.370)	Training Prec@5 0.586 (0.705)	
2022-07-24 15:12:50,476: ============================================================
2022-07-24 15:13:31,307: time cost, forward:0.1247843641709804, backward:0.09775273381199373, data cost:0.18746251968821143 
2022-07-24 15:13:31,308: ============================================================
2022-07-24 15:13:31,308: Epoch 2/25 Batch 1100/7662 eta: 20:43:56.765792	Training Loss1 41.8460 (41.8177)	Training Total_Loss 41.8460 (41.8177)	Training Prec@1 0.781 (0.391)	Training Prec@5 1.367 (0.734)	
2022-07-24 15:13:31,308: ============================================================
2022-07-24 15:14:12,173: time cost, forward:0.12479400535341698, backward:0.09773331467960157, data cost:0.18730478668531048 
2022-07-24 15:14:12,174: ============================================================
2022-07-24 15:14:12,174: Epoch 2/25 Batch 1200/7662 eta: 20:44:17.741942	Training Loss1 41.7062 (41.8114)	Training Total_Loss 41.7062 (41.8114)	Training Prec@1 0.781 (0.413)	Training Prec@5 0.977 (0.769)	
2022-07-24 15:14:12,174: ============================================================
2022-07-24 15:14:52,989: time cost, forward:0.12475365414079838, backward:0.09773550664947252, data cost:0.1871646799611715 
2022-07-24 15:14:52,990: ============================================================
2022-07-24 15:14:52,990: Epoch 2/25 Batch 1300/7662 eta: 20:42:05.620678	Training Loss1 41.7677 (41.8057)	Training Total_Loss 41.7677 (41.8057)	Training Prec@1 0.781 (0.431)	Training Prec@5 1.172 (0.799)	
2022-07-24 15:14:52,990: ============================================================
2022-07-24 15:15:33,848: time cost, forward:0.12475558925816807, backward:0.0977320611434293, data cost:0.18704213134896508 
2022-07-24 15:15:33,849: ============================================================
2022-07-24 15:15:33,849: Epoch 2/25 Batch 1400/7662 eta: 20:42:43.137812	Training Loss1 41.7485 (41.8005)	Training Total_Loss 41.7485 (41.8005)	Training Prec@1 0.781 (0.448)	Training Prec@5 0.977 (0.828)	
2022-07-24 15:15:33,849: ============================================================
2022-07-24 15:16:15,004: time cost, forward:0.12476839790191549, backward:0.0978907998042396, data cost:0.18695743629501374 
2022-07-24 15:16:15,005: ============================================================
2022-07-24 15:16:15,005: Epoch 2/25 Batch 1500/7662 eta: 20:51:03.790969	Training Loss1 41.7289 (41.7940)	Training Total_Loss 41.7289 (41.7940)	Training Prec@1 1.758 (0.468)	Training Prec@5 1.953 (0.860)	
2022-07-24 15:16:15,005: ============================================================
2022-07-24 15:16:56,106: time cost, forward:0.12477064296705713, backward:0.09800818266161834, data cost:0.18688133912506963 
2022-07-24 15:16:56,106: ============================================================
2022-07-24 15:16:56,106: Epoch 2/25 Batch 1600/7662 eta: 20:48:43.254804	Training Loss1 41.7532 (41.7877)	Training Total_Loss 41.7532 (41.7877)	Training Prec@1 0.391 (0.493)	Training Prec@5 1.562 (0.896)	
2022-07-24 15:16:56,106: ============================================================
2022-07-24 15:17:37,264: time cost, forward:0.12476987765774157, backward:0.09814573499018336, data cost:0.1868163674911939 
2022-07-24 15:17:37,264: ============================================================
2022-07-24 15:17:37,264: Epoch 2/25 Batch 1700/7662 eta: 20:49:45.115348	Training Loss1 41.6649 (41.7808)	Training Total_Loss 41.6649 (41.7808)	Training Prec@1 1.172 (0.519)	Training Prec@5 1.758 (0.936)	
2022-07-24 15:17:37,264: ============================================================
2022-07-24 15:18:18,168: time cost, forward:0.12477154755605599, backward:0.09813301996630784, data cost:0.1867538110755297 
2022-07-24 15:18:18,168: ============================================================
2022-07-24 15:18:18,168: Epoch 2/25 Batch 1800/7662 eta: 20:41:21.538771	Training Loss1 41.7732 (41.7741)	Training Total_Loss 41.7732 (41.7741)	Training Prec@1 0.586 (0.545)	Training Prec@5 0.781 (0.977)	
2022-07-24 15:18:18,168: ============================================================
2022-07-24 15:18:59,012: time cost, forward:0.12475721844878555, backward:0.09811958782041368, data cost:0.18668424135261363 
2022-07-24 15:18:59,012: ============================================================
2022-07-24 15:18:59,013: Epoch 2/25 Batch 1900/7662 eta: 20:38:52.850848	Training Loss1 41.6154 (41.7671)	Training Total_Loss 41.6154 (41.7671)	Training Prec@1 0.781 (0.571)	Training Prec@5 1.758 (1.016)	
2022-07-24 15:18:59,013: ============================================================
2022-07-24 15:19:39,928: time cost, forward:0.12477742772868063, backward:0.09809282208872533, data cost:0.18662358880818278 
2022-07-24 15:19:39,928: ============================================================
2022-07-24 15:19:39,928: Epoch 2/25 Batch 2000/7662 eta: 20:40:21.121938	Training Loss1 41.6253 (41.7592)	Training Total_Loss 41.6253 (41.7592)	Training Prec@1 1.367 (0.602)	Training Prec@5 1.953 (1.064)	
2022-07-24 15:19:39,928: ============================================================
2022-07-24 15:20:20,810: time cost, forward:0.12478218730601201, backward:0.09806858749262432, data cost:0.18657514638932562 
2022-07-24 15:20:20,811: ============================================================
2022-07-24 15:20:20,811: Epoch 2/25 Batch 2100/7662 eta: 20:38:39.809788	Training Loss1 41.5906 (41.7511)	Training Total_Loss 41.5906 (41.7511)	Training Prec@1 1.562 (0.636)	Training Prec@5 2.539 (1.111)	
2022-07-24 15:20:20,811: ============================================================
2022-07-24 15:21:01,645: time cost, forward:0.12475534122930217, backward:0.0980689783647094, data cost:0.18652406135652758 
2022-07-24 15:21:01,645: ============================================================
2022-07-24 15:21:01,645: Epoch 2/25 Batch 2200/7662 eta: 20:36:31.137706	Training Loss1 41.5475 (41.7430)	Training Total_Loss 41.5475 (41.7430)	Training Prec@1 1.562 (0.669)	Training Prec@5 2.344 (1.159)	
2022-07-24 15:21:01,645: ============================================================
2022-07-24 15:21:42,512: time cost, forward:0.12474417551645459, backward:0.09806740921753912, data cost:0.18647983604122526 
2022-07-24 15:21:42,513: ============================================================
2022-07-24 15:21:42,513: Epoch 2/25 Batch 2300/7662 eta: 20:36:51.756641	Training Loss1 41.5556 (41.7344)	Training Total_Loss 41.5556 (41.7344)	Training Prec@1 0.977 (0.700)	Training Prec@5 1.562 (1.207)	
2022-07-24 15:21:42,513: ============================================================
2022-07-24 15:22:23,517: time cost, forward:0.12474466890730228, backward:0.09810662458419005, data cost:0.18644314837883094 
2022-07-24 15:22:23,517: ============================================================
2022-07-24 15:22:23,517: Epoch 2/25 Batch 2400/7662 eta: 20:40:18.659442	Training Loss1 41.5035 (41.7242)	Training Total_Loss 41.5035 (41.7242)	Training Prec@1 1.562 (0.737)	Training Prec@5 2.734 (1.262)	
2022-07-24 15:22:23,517: ============================================================
2022-07-24 15:23:04,505: time cost, forward:0.12475571092389592, backward:0.09812600834935414, data cost:0.18640939346930177 
2022-07-24 15:23:04,505: ============================================================
2022-07-24 15:23:04,505: Epoch 2/25 Batch 2500/7662 eta: 20:39:07.611592	Training Loss1 41.4576 (41.7135)	Training Total_Loss 41.4576 (41.7135)	Training Prec@1 2.148 (0.778)	Training Prec@5 3.125 (1.324)	
2022-07-24 15:23:04,505: ============================================================
2022-07-24 15:23:45,542: time cost, forward:0.12474383845518258, backward:0.09818898131637309, data cost:0.18637233773026388 
2022-07-24 15:23:45,542: ============================================================
2022-07-24 15:23:45,543: Epoch 2/25 Batch 2600/7662 eta: 20:39:55.747494	Training Loss1 41.3287 (41.7023)	Training Total_Loss 41.3287 (41.7023)	Training Prec@1 2.344 (0.821)	Training Prec@5 3.516 (1.385)	
2022-07-24 15:23:45,543: ============================================================
2022-07-24 15:24:26,499: time cost, forward:0.12473517508363671, backward:0.09821507470525605, data cost:0.18633960644021305 
2022-07-24 15:24:26,499: ============================================================
2022-07-24 15:24:26,499: Epoch 2/25 Batch 2700/7662 eta: 20:36:48.839629	Training Loss1 41.3498 (41.6901)	Training Total_Loss 41.3498 (41.6901)	Training Prec@1 2.539 (0.867)	Training Prec@5 2.930 (1.453)	
2022-07-24 15:24:26,499: ============================================================
2022-07-24 15:25:07,316: time cost, forward:0.12472415311117604, backward:0.09819774305705473, data cost:0.18630511993252835 
2022-07-24 15:25:07,317: ============================================================
2022-07-24 15:25:07,317: Epoch 2/25 Batch 2800/7662 eta: 20:31:56.649112	Training Loss1 41.1113 (41.6770)	Training Total_Loss 41.1113 (41.6770)	Training Prec@1 2.539 (0.914)	Training Prec@5 4.688 (1.520)	
2022-07-24 15:25:07,317: ============================================================
2022-07-24 15:25:48,232: time cost, forward:0.12474782099268197, backward:0.09817726145780839, data cost:0.18627662064906605 
2022-07-24 15:25:48,233: ============================================================
2022-07-24 15:25:48,233: Epoch 2/25 Batch 2900/7662 eta: 20:34:13.051693	Training Loss1 41.0347 (41.6628)	Training Total_Loss 41.0347 (41.6628)	Training Prec@1 3.906 (0.963)	Training Prec@5 4.883 (1.593)	
2022-07-24 15:25:48,233: ============================================================
2022-07-24 15:26:29,358: time cost, forward:0.12475450868088231, backward:0.09823344285665413, data cost:0.1862586505733438 
2022-07-24 15:26:29,358: ============================================================
2022-07-24 15:26:29,358: Epoch 2/25 Batch 3000/7662 eta: 20:39:51.274467	Training Loss1 41.0857 (41.6476)	Training Total_Loss 41.0857 (41.6476)	Training Prec@1 3.516 (1.016)	Training Prec@5 5.273 (1.673)	
2022-07-24 15:26:29,358: ============================================================
2022-07-24 15:27:10,358: time cost, forward:0.12476684809423486, backward:0.09823656428356485, data cost:0.18624397322761507 
2022-07-24 15:27:10,358: ============================================================
2022-07-24 15:27:10,359: Epoch 2/25 Batch 3100/7662 eta: 20:35:24.289569	Training Loss1 40.9456 (41.6314)	Training Total_Loss 40.9456 (41.6314)	Training Prec@1 4.492 (1.070)	Training Prec@5 5.273 (1.753)	
2022-07-24 15:27:10,359: ============================================================
2022-07-24 15:27:51,284: time cost, forward:0.12477424577758922, backward:0.09822136746901726, data cost:0.18623188287997924 
2022-07-24 15:27:51,284: ============================================================
2022-07-24 15:27:51,285: Epoch 2/25 Batch 3200/7662 eta: 20:32:28.825587	Training Loss1 41.1206 (41.6137)	Training Total_Loss 41.1206 (41.6137)	Training Prec@1 1.758 (1.129)	Training Prec@5 3.516 (1.839)	
2022-07-24 15:27:51,285: ============================================================
2022-07-24 15:28:32,222: time cost, forward:0.1247804426503709, backward:0.09821372857488404, data cost:0.18621808993306874 
2022-07-24 15:28:32,222: ============================================================
2022-07-24 15:28:32,222: Epoch 2/25 Batch 3300/7662 eta: 20:32:08.956418	Training Loss1 40.7372 (41.5941)	Training Total_Loss 40.7372 (41.5941)	Training Prec@1 4.492 (1.194)	Training Prec@5 7.227 (1.937)	
2022-07-24 15:28:32,222: ============================================================
2022-07-24 15:29:13,262: time cost, forward:0.124801003466497, backward:0.0982136573466037, data cost:0.1862079590760669 
2022-07-24 15:29:13,262: ============================================================
2022-07-24 15:29:13,262: Epoch 2/25 Batch 3400/7662 eta: 20:34:32.796984	Training Loss1 40.7980 (41.5732)	Training Total_Loss 40.7980 (41.5732)	Training Prec@1 3.906 (1.264)	Training Prec@5 5.469 (2.039)	
2022-07-24 15:29:13,262: ============================================================
2022-07-24 15:29:54,274: time cost, forward:0.12483081718143922, backward:0.09819748048000113, data cost:0.18620146986892408 
2022-07-24 15:29:54,274: ============================================================
2022-07-24 15:29:54,274: Epoch 2/25 Batch 3500/7662 eta: 20:33:00.639228	Training Loss1 40.6843 (41.5506)	Training Total_Loss 40.6843 (41.5506)	Training Prec@1 3.711 (1.340)	Training Prec@5 7.422 (2.149)	
2022-07-24 15:29:54,274: ============================================================
2022-07-24 15:30:35,414: time cost, forward:0.12485095288032093, backward:0.09822323720433308, data cost:0.1861961132355881 
2022-07-24 15:30:35,415: ============================================================
2022-07-24 15:30:35,415: Epoch 2/25 Batch 3600/7662 eta: 20:36:12.288338	Training Loss1 40.5093 (41.5265)	Training Total_Loss 40.5093 (41.5265)	Training Prec@1 4.688 (1.422)	Training Prec@5 7.227 (2.270)	
2022-07-24 15:30:35,415: ============================================================
2022-07-24 15:31:16,424: time cost, forward:0.12486748006995481, backward:0.09821683795234905, data cost:0.18619130501459663 
2022-07-24 15:31:16,425: ============================================================
2022-07-24 15:31:16,425: Epoch 2/25 Batch 3700/7662 eta: 20:31:35.580627	Training Loss1 40.3936 (41.5007)	Training Total_Loss 40.3936 (41.5007)	Training Prec@1 5.469 (1.512)	Training Prec@5 8.203 (2.400)	
2022-07-24 15:31:16,425: ============================================================
2022-07-24 15:31:57,392: time cost, forward:0.12487884746409932, backward:0.09820531713049423, data cost:0.18618496131445114 
2022-07-24 15:31:57,393: ============================================================
2022-07-24 15:31:57,393: Epoch 2/25 Batch 3800/7662 eta: 20:29:39.026280	Training Loss1 40.2962 (41.4733)	Training Total_Loss 40.2962 (41.4733)	Training Prec@1 6.250 (1.604)	Training Prec@5 9.375 (2.537)	
2022-07-24 15:31:57,393: ============================================================
2022-07-24 15:32:38,456: time cost, forward:0.12490887347170254, backward:0.09819942433028749, data cost:0.18617899951704894 
2022-07-24 15:32:38,456: ============================================================
2022-07-24 15:32:38,456: Epoch 2/25 Batch 3900/7662 eta: 20:31:49.431429	Training Loss1 40.3152 (41.4435)	Training Total_Loss 40.3152 (41.4435)	Training Prec@1 5.859 (1.705)	Training Prec@5 8.398 (2.684)	
2022-07-24 15:32:38,456: ============================================================
2022-07-24 15:33:19,403: time cost, forward:0.12491090043123497, backward:0.09819696759784123, data cost:0.18616813199166568 
2022-07-24 15:33:19,403: ============================================================
2022-07-24 15:33:19,403: Epoch 2/25 Batch 4000/7662 eta: 20:27:39.260389	Training Loss1 40.2409 (41.4131)	Training Total_Loss 40.2409 (41.4131)	Training Prec@1 5.469 (1.808)	Training Prec@5 8.398 (2.834)	
2022-07-24 15:33:19,403: ============================================================
2022-07-24 15:34:00,314: time cost, forward:0.12490537196259639, backward:0.09818851113115819, data cost:0.1861580873472163 
2022-07-24 15:34:00,314: ============================================================
2022-07-24 15:34:00,314: Epoch 2/25 Batch 4100/7662 eta: 20:25:53.705856	Training Loss1 39.7897 (41.3806)	Training Total_Loss 39.7897 (41.3806)	Training Prec@1 7.617 (1.918)	Training Prec@5 11.914 (2.992)	
2022-07-24 15:34:00,315: ============================================================
2022-07-24 15:34:41,273: time cost, forward:0.12490259366082021, backward:0.09819463197036311, data cost:0.18614772519318085 
2022-07-24 15:34:41,274: ============================================================
2022-07-24 15:34:41,274: Epoch 2/25 Batch 4200/7662 eta: 20:26:39.211848	Training Loss1 39.3769 (41.3460)	Training Total_Loss 39.3769 (41.3460)	Training Prec@1 10.938 (2.035)	Training Prec@5 14.844 (3.164)	
2022-07-24 15:34:41,274: ============================================================
2022-07-24 15:35:22,229: time cost, forward:0.12491014830648525, backward:0.0981855838347047, data cost:0.18613898468505619 
2022-07-24 15:35:22,229: ============================================================
2022-07-24 15:35:22,229: Epoch 2/25 Batch 4300/7662 eta: 20:25:52.088214	Training Loss1 39.5145 (41.3083)	Training Total_Loss 39.5145 (41.3083)	Training Prec@1 8.398 (2.165)	Training Prec@5 13.086 (3.355)	
2022-07-24 15:35:22,230: ============================================================
2022-07-24 15:36:03,179: time cost, forward:0.12490773737552519, backward:0.0981890149321386, data cost:0.186129756070289 
2022-07-24 15:36:03,180: ============================================================
2022-07-24 15:36:03,180: Epoch 2/25 Batch 4400/7662 eta: 20:25:01.552243	Training Loss1 39.6376 (41.2693)	Training Total_Loss 39.6376 (41.2693)	Training Prec@1 7.812 (2.301)	Training Prec@5 12.305 (3.553)	
2022-07-24 15:36:03,180: ============================================================
2022-07-24 15:36:44,101: time cost, forward:0.12490781155340563, backward:0.09817696529167126, data cost:0.1861224238621868 
2022-07-24 15:36:44,101: ============================================================
2022-07-24 15:36:44,101: Epoch 2/25 Batch 4500/7662 eta: 20:23:28.560942	Training Loss1 39.5881 (41.2285)	Training Total_Loss 39.5881 (41.2285)	Training Prec@1 6.641 (2.444)	Training Prec@5 10.938 (3.761)	
2022-07-24 15:36:44,101: ============================================================
2022-07-24 15:37:25,019: time cost, forward:0.12489848495644314, backward:0.09818028387595167, data cost:0.1861120323741869 
2022-07-24 15:37:25,019: ============================================================
2022-07-24 15:37:25,019: Epoch 2/25 Batch 4600/7662 eta: 20:22:40.903187	Training Loss1 39.0309 (41.1845)	Training Total_Loss 39.0309 (41.1845)	Training Prec@1 10.156 (2.602)	Training Prec@5 15.039 (3.991)	
2022-07-24 15:37:25,019: ============================================================
2022-07-24 15:38:05,954: time cost, forward:0.12489336509607173, backward:0.09818650849653472, data cost:0.18610119499990752 
2022-07-24 15:38:05,954: ============================================================
2022-07-24 15:38:05,954: Epoch 2/25 Batch 4700/7662 eta: 20:22:30.846160	Training Loss1 39.2015 (41.1385)	Training Total_Loss 39.2015 (41.1385)	Training Prec@1 10.352 (2.773)	Training Prec@5 14.844 (4.236)	
2022-07-24 15:38:05,954: ============================================================
2022-07-24 15:38:46,897: time cost, forward:0.12489159968178032, backward:0.09818629886637531, data cost:0.18609531111060443 
2022-07-24 15:38:46,898: ============================================================
2022-07-24 15:38:46,898: Epoch 2/25 Batch 4800/7662 eta: 20:22:05.794965	Training Loss1 39.0455 (41.0907)	Training Total_Loss 39.0455 (41.0907)	Training Prec@1 9.375 (2.952)	Training Prec@5 14.844 (4.494)	
2022-07-24 15:38:46,898: ============================================================
2022-07-24 15:39:27,843: time cost, forward:0.1248951247819323, backward:0.09818634701690082, data cost:0.18608448811515688 
2022-07-24 15:39:27,843: ============================================================
2022-07-24 15:39:27,843: Epoch 2/25 Batch 4900/7662 eta: 20:21:28.211792	Training Loss1 38.4858 (41.0409)	Training Total_Loss 38.4858 (41.0409)	Training Prec@1 11.719 (3.142)	Training Prec@5 18.555 (4.769)	
2022-07-24 15:39:27,843: ============================================================
2022-07-24 15:40:08,729: time cost, forward:0.12489097150332167, backward:0.09818188627616575, data cost:0.1860740055535216 
2022-07-24 15:40:08,729: ============================================================
2022-07-24 15:40:08,730: Epoch 2/25 Batch 5000/7662 eta: 20:19:01.020004	Training Loss1 38.3829 (40.9886)	Training Total_Loss 38.3829 (40.9886)	Training Prec@1 14.648 (3.344)	Training Prec@5 21.875 (5.059)	
2022-07-24 15:40:08,730: ============================================================
2022-07-24 15:40:49,568: time cost, forward:0.12487616873788095, backward:0.09818303372304003, data cost:0.1860605267642362 
2022-07-24 15:40:49,568: ============================================================
2022-07-24 15:40:49,569: Epoch 2/25 Batch 5100/7662 eta: 20:16:55.618373	Training Loss1 38.3424 (40.9337)	Training Total_Loss 38.3424 (40.9337)	Training Prec@1 13.086 (3.566)	Training Prec@5 18.555 (5.374)	
2022-07-24 15:40:49,569: ============================================================
2022-07-24 15:41:30,503: time cost, forward:0.1248742191808502, backward:0.09818354637078493, data cost:0.18605165161474735 
2022-07-24 15:41:30,503: ============================================================
2022-07-24 15:41:30,503: Epoch 2/25 Batch 5200/7662 eta: 20:19:05.357498	Training Loss1 38.0007 (40.8768)	Training Total_Loss 38.0007 (40.8768)	Training Prec@1 15.820 (3.800)	Training Prec@5 22.852 (5.707)	
2022-07-24 15:41:30,503: ============================================================
2022-07-24 15:42:11,245: time cost, forward:0.12486972775542977, backward:0.09815664627930425, data cost:0.1860418364245344 
2022-07-24 15:42:11,245: ============================================================
2022-07-24 15:42:11,245: Epoch 2/25 Batch 5300/7662 eta: 20:12:40.944310	Training Loss1 37.5432 (40.8160)	Training Total_Loss 37.5432 (40.8160)	Training Prec@1 15.039 (4.061)	Training Prec@5 26.172 (6.071)	
2022-07-24 15:42:11,245: ============================================================
2022-07-24 15:42:52,096: time cost, forward:0.12486594009010808, backward:0.09814651835117104, data cost:0.18603261114602002 
2022-07-24 15:42:52,096: ============================================================
2022-07-24 15:42:52,096: Epoch 2/25 Batch 5400/7662 eta: 20:15:14.581518	Training Loss1 38.0667 (40.7529)	Training Total_Loss 38.0667 (40.7529)	Training Prec@1 14.648 (4.336)	Training Prec@5 22.266 (6.457)	
2022-07-24 15:42:52,096: ============================================================
2022-07-24 15:43:32,994: time cost, forward:0.1248598093552077, backward:0.0981441236101599, data cost:0.18602668270021597 
2022-07-24 15:43:32,994: ============================================================
2022-07-24 15:43:32,994: Epoch 2/25 Batch 5500/7662 eta: 20:15:57.483462	Training Loss1 37.0755 (40.6879)	Training Total_Loss 37.0755 (40.6879)	Training Prec@1 20.312 (4.625)	Training Prec@5 29.883 (6.861)	
2022-07-24 15:43:32,994: ============================================================
2022-07-24 15:44:13,849: time cost, forward:0.1248523544724402, backward:0.09813731677788967, data cost:0.1860185166004833 
2022-07-24 15:44:13,850: ============================================================
2022-07-24 15:44:13,850: Epoch 2/25 Batch 5600/7662 eta: 20:14:01.289139	Training Loss1 36.4959 (40.6194)	Training Total_Loss 36.4959 (40.6194)	Training Prec@1 24.609 (4.935)	Training Prec@5 33.008 (7.294)	
2022-07-24 15:44:13,850: ============================================================
2022-07-24 15:44:54,759: time cost, forward:0.12484892553813752, backward:0.09813606598896402, data cost:0.18601144311887838 
2022-07-24 15:44:54,760: ============================================================
2022-07-24 15:44:54,760: Epoch 2/25 Batch 5700/7662 eta: 20:14:57.627307	Training Loss1 36.5615 (40.5478)	Training Total_Loss 36.5615 (40.5478)	Training Prec@1 25.000 (5.271)	Training Prec@5 33.594 (7.754)	
2022-07-24 15:44:54,761: ============================================================
2022-07-24 15:45:35,633: time cost, forward:0.12485079774364848, backward:0.09812372469618354, data cost:0.1860045227311278 
2022-07-24 15:45:35,633: ============================================================
2022-07-24 15:45:35,633: Epoch 2/25 Batch 5800/7662 eta: 20:13:10.356291	Training Loss1 35.5937 (40.4736)	Training Total_Loss 35.5937 (40.4736)	Training Prec@1 29.883 (5.624)	Training Prec@5 39.648 (8.235)	
2022-07-24 15:45:35,633: ============================================================
2022-07-24 15:46:16,471: time cost, forward:0.12484257935386409, backward:0.09811866386479534, data cost:0.1859953514214875 
2022-07-24 15:46:16,472: ============================================================
2022-07-24 15:46:16,472: Epoch 2/25 Batch 5900/7662 eta: 20:11:27.965240	Training Loss1 35.7240 (40.3961)	Training Total_Loss 35.7240 (40.3961)	Training Prec@1 31.836 (5.998)	Training Prec@5 40.039 (8.736)	
2022-07-24 15:46:16,472: ============================================================
2022-07-24 15:46:57,391: time cost, forward:0.12484023296389904, backward:0.09811845360686132, data cost:0.18598729158405622 
2022-07-24 15:46:57,391: ============================================================
2022-07-24 15:46:57,391: Epoch 2/25 Batch 6000/7662 eta: 20:13:10.988854	Training Loss1 35.3030 (40.3163)	Training Total_Loss 35.3030 (40.3163)	Training Prec@1 32.422 (6.394)	Training Prec@5 41.797 (9.264)	
2022-07-24 15:46:57,391: ============================================================
2022-07-24 15:47:38,280: time cost, forward:0.12483750133949101, backward:0.09811485671746885, data cost:0.18597945007540628 
2022-07-24 15:47:38,280: ============================================================
2022-07-24 15:47:38,280: Epoch 2/25 Batch 6100/7662 eta: 20:11:36.602742	Training Loss1 34.9693 (40.2342)	Training Total_Loss 34.9693 (40.2342)	Training Prec@1 33.203 (6.809)	Training Prec@5 45.898 (9.811)	
2022-07-24 15:47:38,280: ============================================================
2022-07-24 15:48:19,260: time cost, forward:0.12484698415590997, backward:0.0981127398497521, data cost:0.18597400321135849 
2022-07-24 15:48:19,260: ============================================================
2022-07-24 15:48:19,260: Epoch 2/25 Batch 6200/7662 eta: 20:13:36.568836	Training Loss1 34.4953 (40.1476)	Training Total_Loss 34.4953 (40.1476)	Training Prec@1 36.133 (7.247)	Training Prec@5 48.242 (10.383)	
2022-07-24 15:48:19,260: ============================================================
2022-07-24 15:49:00,206: time cost, forward:0.12484794477561785, backward:0.09811344667547638, data cost:0.185968909458161 
2022-07-24 15:49:00,206: ============================================================
2022-07-24 15:49:00,206: Epoch 2/25 Batch 6300/7662 eta: 20:11:55.460861	Training Loss1 33.9362 (40.0578)	Training Total_Loss 33.9362 (40.0578)	Training Prec@1 39.844 (7.711)	Training Prec@5 53.711 (10.978)	
2022-07-24 15:49:00,206: ============================================================
2022-07-24 15:49:41,139: time cost, forward:0.12484935559897073, backward:0.09811200747584567, data cost:0.18596415296907182 
2022-07-24 15:49:41,140: ============================================================
2022-07-24 15:49:41,140: Epoch 2/25 Batch 6400/7662 eta: 20:10:52.793362	Training Loss1 32.9344 (39.9645)	Training Total_Loss 32.9344 (39.9645)	Training Prec@1 45.703 (8.195)	Training Prec@5 57.422 (11.594)	
2022-07-24 15:49:41,140: ============================================================
2022-07-24 15:50:22,225: time cost, forward:0.12487166858596203, backward:0.09811108591813714, data cost:0.18596058582265407 
2022-07-24 15:50:22,226: ============================================================
2022-07-24 15:50:22,226: Epoch 2/25 Batch 6500/7662 eta: 20:14:42.083811	Training Loss1 33.4668 (39.8671)	Training Total_Loss 33.4668 (39.8671)	Training Prec@1 39.062 (8.701)	Training Prec@5 51.562 (12.230)	
2022-07-24 15:50:22,226: ============================================================
2022-07-24 15:51:03,145: time cost, forward:0.12487751781118514, backward:0.09810581198604311, data cost:0.18595357012759556 
2022-07-24 15:51:03,145: ============================================================
2022-07-24 15:51:03,145: Epoch 2/25 Batch 6600/7662 eta: 20:09:05.252646	Training Loss1 33.2756 (39.7667)	Training Total_Loss 33.2756 (39.7667)	Training Prec@1 42.578 (9.222)	Training Prec@5 53.906 (12.875)	
2022-07-24 15:51:03,145: ============================================================
2022-07-24 15:51:44,052: time cost, forward:0.12488380171039386, backward:0.09809719916510393, data cost:0.18594778806598422 
2022-07-24 15:51:44,053: ============================================================
2022-07-24 15:51:44,053: Epoch 2/25 Batch 6700/7662 eta: 20:08:03.920160	Training Loss1 31.7727 (39.6630)	Training Total_Loss 31.7727 (39.6630)	Training Prec@1 46.289 (9.761)	Training Prec@5 60.938 (13.541)	
2022-07-24 15:51:44,053: ============================================================
2022-07-24 15:52:25,099: time cost, forward:0.12489817920616925, backward:0.09809957004361405, data cost:0.18594331418017918 
2022-07-24 15:52:25,099: ============================================================
2022-07-24 15:52:25,099: Epoch 2/25 Batch 6800/7662 eta: 20:11:29.085011	Training Loss1 31.4763 (39.5554)	Training Total_Loss 31.4763 (39.5554)	Training Prec@1 50.391 (10.320)	Training Prec@5 62.109 (14.220)	
2022-07-24 15:52:25,099: ============================================================
2022-07-24 15:53:06,164: time cost, forward:0.1249074582725975, backward:0.09810929019168799, data cost:0.18593868132449004 
2022-07-24 15:53:06,174: ============================================================
2022-07-24 15:53:06,175: Epoch 2/25 Batch 6900/7662 eta: 20:11:38.637774	Training Loss1 31.5128 (39.4436)	Training Total_Loss 31.5128 (39.4436)	Training Prec@1 50.000 (10.902)	Training Prec@5 64.453 (14.913)	
2022-07-24 15:53:06,175: ============================================================
2022-07-24 15:53:47,254: time cost, forward:0.12492392073019622, backward:0.09810704128250665, data cost:0.18593747630462015 
2022-07-24 15:53:47,254: ============================================================
2022-07-24 15:53:47,254: Epoch 2/25 Batch 7000/7662 eta: 20:11:04.919312	Training Loss1 30.5934 (39.3293)	Training Total_Loss 30.5934 (39.3293)	Training Prec@1 54.102 (11.491)	Training Prec@5 66.211 (15.613)	
2022-07-24 15:53:47,254: ============================================================
2022-07-24 15:54:28,188: time cost, forward:0.12492966934028923, backward:0.09810115330856373, data cost:0.18593346496621796 
2022-07-24 15:54:28,188: ============================================================
2022-07-24 15:54:28,189: Epoch 2/25 Batch 7100/7662 eta: 20:06:08.093169	Training Loss1 30.8683 (39.2103)	Training Total_Loss 30.8683 (39.2103)	Training Prec@1 54.883 (12.101)	Training Prec@5 64.844 (16.328)	
2022-07-24 15:54:28,189: ============================================================
2022-07-24 15:55:09,108: time cost, forward:0.12492860607147746, backward:0.09809927570106156, data cost:0.1859302711844494 
2022-07-24 15:55:09,109: ============================================================
2022-07-24 15:55:09,109: Epoch 2/25 Batch 7200/7662 eta: 20:05:01.261100	Training Loss1 30.0056 (39.0883)	Training Total_Loss 30.0056 (39.0883)	Training Prec@1 57.031 (12.717)	Training Prec@5 68.945 (17.046)	
2022-07-24 15:55:09,109: ============================================================
2022-07-24 15:55:50,114: time cost, forward:0.12493097133743615, backward:0.09810584459358379, data cost:0.18592700959558536 
2022-07-24 15:55:50,115: ============================================================
2022-07-24 15:55:50,115: Epoch 2/25 Batch 7300/7662 eta: 20:06:52.491699	Training Loss1 29.5282 (38.9622)	Training Total_Loss 29.5282 (38.9622)	Training Prec@1 60.156 (13.348)	Training Prec@5 71.875 (17.770)	
2022-07-24 15:55:50,115: ============================================================
2022-07-24 15:56:31,079: time cost, forward:0.12493197736522284, backward:0.09810704098374219, data cost:0.18592459905113717 
2022-07-24 15:56:31,079: ============================================================
2022-07-24 15:56:31,079: Epoch 2/25 Batch 7400/7662 eta: 20:04:57.615827	Training Loss1 29.3013 (38.8323)	Training Total_Loss 29.3013 (38.8323)	Training Prec@1 65.430 (13.993)	Training Prec@5 74.219 (18.503)	
2022-07-24 15:56:31,079: ============================================================
2022-07-24 15:57:12,073: time cost, forward:0.12493443889671332, backward:0.09810948696179714, data cost:0.1859231463812688 
2022-07-24 15:57:12,073: ============================================================
2022-07-24 15:57:12,073: Epoch 2/25 Batch 7500/7662 eta: 20:05:08.176101	Training Loss1 28.9893 (38.6979)	Training Total_Loss 28.9893 (38.6979)	Training Prec@1 61.328 (14.648)	Training Prec@5 74.219 (19.240)	
2022-07-24 15:57:12,073: ============================================================
2022-07-24 15:57:53,161: time cost, forward:0.12493800705930938, backward:0.09812203431258093, data cost:0.18592291707223238 
2022-07-24 15:57:53,161: ============================================================
2022-07-24 15:57:53,161: Epoch 2/25 Batch 7600/7662 eta: 20:07:13.996395	Training Loss1 27.4678 (38.5602)	Training Total_Loss 27.4678 (38.5602)	Training Prec@1 67.969 (15.314)	Training Prec@5 79.102 (19.979)	
2022-07-24 15:57:53,161: ============================================================
2022-07-24 15:58:19,666: Epoch 2/25 Batch 7663/7662 eta: 20:06:48.110822	Training Loss1 27.0349 (38.4722)	Training Total_Loss 27.0349 (38.4722)	Training Prec@1 70.508 (15.736)	Training Prec@5 80.078 (20.444)	
2022-07-24 15:58:19,666: ============================================================
2022-07-24 15:59:01,334: time cost, forward:0.12526451698457353, backward:0.09746403405160615, data cost:0.19551785546119768 
2022-07-24 15:59:01,335: ============================================================
2022-07-24 15:59:01,335: Epoch 3/25 Batch 100/7662 eta: 20:23:04.884562	Training Loss1 26.9874 (26.2764)	Training Total_Loss 26.9874 (26.2764)	Training Prec@1 66.016 (72.072)	Training Prec@5 78.516 (81.027)	
2022-07-24 15:59:01,335: ============================================================
2022-07-24 15:59:42,231: time cost, forward:0.12521124485150054, backward:0.0972862567134838, data cost:0.1907191971438614 
2022-07-24 15:59:42,231: ============================================================
2022-07-24 15:59:42,231: Epoch 3/25 Batch 200/7662 eta: 19:59:48.689196	Training Loss1 26.0671 (26.1372)	Training Total_Loss 26.0671 (26.1372)	Training Prec@1 74.219 (72.431)	Training Prec@5 83.203 (81.341)	
2022-07-24 15:59:42,231: ============================================================
2022-07-24 16:00:23,046: time cost, forward:0.12497991861706992, backward:0.0972535370983009, data cost:0.18902536459192384 
2022-07-24 16:00:23,046: ============================================================
2022-07-24 16:00:23,046: Epoch 3/25 Batch 300/7662 eta: 19:56:44.929799	Training Loss1 25.4466 (25.9012)	Training Total_Loss 25.4466 (25.9012)	Training Prec@1 71.875 (73.080)	Training Prec@5 81.445 (81.817)	
2022-07-24 16:00:23,046: ============================================================
2022-07-24 16:01:03,880: time cost, forward:0.12488870393662226, backward:0.097257651780781, data cost:0.188211150635454 
2022-07-24 16:01:03,880: ============================================================
2022-07-24 16:01:03,880: Epoch 3/25 Batch 400/7662 eta: 19:56:36.965555	Training Loss1 25.3390 (25.6831)	Training Total_Loss 25.3390 (25.6831)	Training Prec@1 74.805 (73.647)	Training Prec@5 82.617 (82.279)	
2022-07-24 16:01:03,880: ============================================================
2022-07-24 16:01:44,712: time cost, forward:0.12480865308421409, backward:0.09727768573111188, data cost:0.1877269505976675 
2022-07-24 16:01:44,713: ============================================================
2022-07-24 16:01:44,713: Epoch 3/25 Batch 500/7662 eta: 19:55:53.933792	Training Loss1 24.7247 (25.4898)	Training Total_Loss 24.7247 (25.4898)	Training Prec@1 75.586 (74.144)	Training Prec@5 83.789 (82.715)	
2022-07-24 16:01:44,713: ============================================================
2022-07-24 16:02:25,507: time cost, forward:0.12474571922187615, backward:0.09725442832220775, data cost:0.18739083374481966 
2022-07-24 16:02:25,507: ============================================================
2022-07-24 16:02:25,507: Epoch 3/25 Batch 600/7662 eta: 19:54:05.619485	Training Loss1 24.6318 (25.2943)	Training Total_Loss 24.6318 (25.2943)	Training Prec@1 75.977 (74.652)	Training Prec@5 85.742 (83.141)	
2022-07-24 16:02:25,507: ============================================================
2022-07-24 16:03:06,323: time cost, forward:0.12470802319407975, backward:0.09726191283295595, data cost:0.18715410102931557 
2022-07-24 16:03:06,324: ============================================================
2022-07-24 16:03:06,324: Epoch 3/25 Batch 700/7662 eta: 19:54:04.370407	Training Loss1 23.5700 (25.0938)	Training Total_Loss 23.5700 (25.0938)	Training Prec@1 77.344 (75.088)	Training Prec@5 84.180 (83.478)	
2022-07-24 16:03:06,324: ============================================================
2022-07-24 16:03:47,158: time cost, forward:0.124680747973904, backward:0.09728266748230209, data cost:0.18697990255152924 
2022-07-24 16:03:47,158: ============================================================
2022-07-24 16:03:47,158: Epoch 3/25 Batch 800/7662 eta: 19:53:54.588712	Training Loss1 22.7744 (24.8919)	Training Total_Loss 22.7744 (24.8919)	Training Prec@1 80.664 (75.570)	Training Prec@5 87.305 (83.843)	
2022-07-24 16:03:47,158: ============================================================
2022-07-24 16:04:28,000: time cost, forward:0.12467714491092058, backward:0.0972828687364453, data cost:0.1868516284976573 
2022-07-24 16:04:28,000: ============================================================
2022-07-24 16:04:28,001: Epoch 3/25 Batch 900/7662 eta: 19:53:27.860535	Training Loss1 23.7796 (24.6859)	Training Total_Loss 23.7796 (24.6859)	Training Prec@1 76.367 (76.065)	Training Prec@5 83.984 (84.228)	
2022-07-24 16:04:28,001: ============================================================
2022-07-24 16:05:08,792: time cost, forward:0.12464537563266696, backward:0.09726748046454964, data cost:0.18674383650312912 
2022-07-24 16:05:08,792: ============================================================
2022-07-24 16:05:08,792: Epoch 3/25 Batch 1000/7662 eta: 19:51:17.461175	Training Loss1 22.3853 (24.4893)	Training Total_Loss 22.3853 (24.4893)	Training Prec@1 81.055 (76.540)	Training Prec@5 88.477 (84.604)	
2022-07-24 16:05:08,792: ============================================================
2022-07-24 16:05:49,637: time cost, forward:0.1246366980294947, backward:0.09729242997347387, data cost:0.1866514504877842 
2022-07-24 16:05:49,637: ============================================================
2022-07-24 16:05:49,637: Epoch 3/25 Batch 1100/7662 eta: 19:52:11.229461	Training Loss1 22.1110 (24.2912)	Training Total_Loss 22.1110 (24.2912)	Training Prec@1 82.227 (77.007)	Training Prec@5 88.281 (84.962)	
2022-07-24 16:05:49,637: ============================================================
2022-07-24 16:06:30,440: time cost, forward:0.124610619906886, backward:0.097299036729127, data cost:0.1865702112880322 
2022-07-24 16:06:30,440: ============================================================
2022-07-24 16:06:30,441: Epoch 3/25 Batch 1200/7662 eta: 19:50:16.618962	Training Loss1 21.3094 (24.0875)	Training Total_Loss 21.3094 (24.0875)	Training Prec@1 86.523 (77.475)	Training Prec@5 91.016 (85.317)	
2022-07-24 16:06:30,441: ============================================================
2022-07-24 16:07:11,267: time cost, forward:0.12459931068919639, backward:0.09730968225727273, data cost:0.1865045448006622 
2022-07-24 16:07:11,267: ============================================================
2022-07-24 16:07:11,267: Epoch 3/25 Batch 1300/7662 eta: 19:50:16.866826	Training Loss1 21.4719 (23.9072)	Training Total_Loss 21.4719 (23.9072)	Training Prec@1 84.766 (77.907)	Training Prec@5 90.820 (85.634)	
2022-07-24 16:07:11,267: ============================================================
2022-07-24 16:07:52,045: time cost, forward:0.12457591180208327, backward:0.09731276739146387, data cost:0.18643139412438894 
2022-07-24 16:07:52,045: ============================================================
2022-07-24 16:07:52,045: Epoch 3/25 Batch 1400/7662 eta: 19:48:11.261043	Training Loss1 20.6524 (23.7270)	Training Total_Loss 20.6524 (23.7270)	Training Prec@1 86.133 (78.322)	Training Prec@5 90.625 (85.943)	
2022-07-24 16:07:52,045: ============================================================
2022-07-24 16:08:32,811: time cost, forward:0.12453698396205584, backward:0.09733001974282701, data cost:0.18636542880749846 
2022-07-24 16:08:32,812: ============================================================
2022-07-24 16:08:32,812: Epoch 3/25 Batch 1500/7662 eta: 19:47:09.914566	Training Loss1 20.2214 (23.5431)	Training Total_Loss 20.2214 (23.5431)	Training Prec@1 85.547 (78.725)	Training Prec@5 91.211 (86.239)	
2022-07-24 16:08:32,812: ============================================================
2022-07-24 16:09:13,604: time cost, forward:0.12452315583387116, backward:0.0973311041652448, data cost:0.18631763440359378 
2022-07-24 16:09:13,604: ============================================================
2022-07-24 16:09:13,604: Epoch 3/25 Batch 1600/7662 eta: 19:47:14.545393	Training Loss1 20.7129 (23.3639)	Training Total_Loss 20.7129 (23.3639)	Training Prec@1 86.523 (79.134)	Training Prec@5 91.406 (86.543)	
2022-07-24 16:09:13,604: ============================================================
2022-07-24 16:09:54,331: time cost, forward:0.12447711395613932, backward:0.09733584012755091, data cost:0.1862667060165001 
2022-07-24 16:09:54,332: ============================================================
2022-07-24 16:09:54,332: Epoch 3/25 Batch 1700/7662 eta: 19:44:40.892889	Training Loss1 20.1034 (23.1936)	Training Total_Loss 20.1034 (23.1936)	Training Prec@1 87.695 (79.506)	Training Prec@5 93.359 (86.822)	
2022-07-24 16:09:54,332: ============================================================
2022-07-24 16:10:35,069: time cost, forward:0.12445222463390442, backward:0.09733775259720875, data cost:0.18621421112094474 
2022-07-24 16:10:35,069: ============================================================
2022-07-24 16:10:35,070: Epoch 3/25 Batch 1800/7662 eta: 19:44:17.411134	Training Loss1 20.1497 (23.0234)	Training Total_Loss 20.1497 (23.0234)	Training Prec@1 85.742 (79.871)	Training Prec@5 92.773 (87.094)	
2022-07-24 16:10:35,070: ============================================================
2022-07-24 16:11:15,802: time cost, forward:0.12444352940423291, backward:0.0973203749704386, data cost:0.1861699061873337 
2022-07-24 16:11:15,802: ============================================================
2022-07-24 16:11:15,802: Epoch 3/25 Batch 1900/7662 eta: 19:43:28.471510	Training Loss1 19.6298 (22.8660)	Training Total_Loss 19.6298 (22.8660)	Training Prec@1 86.914 (80.212)	Training Prec@5 93.750 (87.340)	
2022-07-24 16:11:15,803: ============================================================
2022-07-24 16:11:56,575: time cost, forward:0.12442458934220986, backward:0.09732994417836512, data cost:0.18612926026592855 
2022-07-24 16:11:56,576: ============================================================
2022-07-24 16:11:56,576: Epoch 3/25 Batch 2000/7662 eta: 19:43:57.987611	Training Loss1 20.1414 (22.7088)	Training Total_Loss 20.1414 (22.7088)	Training Prec@1 86.719 (80.536)	Training Prec@5 91.406 (87.587)	
2022-07-24 16:11:56,576: ============================================================
2022-07-24 16:12:37,348: time cost, forward:0.12441665220964858, backward:0.0973300895218397, data cost:0.18609689155495013 
2022-07-24 16:12:37,348: ============================================================
2022-07-24 16:12:37,348: Epoch 3/25 Batch 2100/7662 eta: 19:43:16.321383	Training Loss1 18.8021 (22.5604)	Training Total_Loss 18.8021 (22.5604)	Training Prec@1 89.062 (80.842)	Training Prec@5 93.164 (87.808)	
2022-07-24 16:12:37,349: ============================================================
2022-07-24 16:13:18,052: time cost, forward:0.1243931830823828, backward:0.0973238508069228, data cost:0.1860590882060635 
2022-07-24 16:13:18,052: ============================================================
2022-07-24 16:13:18,052: Epoch 3/25 Batch 2200/7662 eta: 19:40:35.099502	Training Loss1 18.9643 (22.4166)	Training Total_Loss 18.9643 (22.4166)	Training Prec@1 89.648 (81.142)	Training Prec@5 94.336 (88.034)	
2022-07-24 16:13:18,052: ============================================================
2022-07-24 16:13:58,778: time cost, forward:0.12436882201979191, backward:0.0973281035894101, data cost:0.18602823900004584 
2022-07-24 16:13:58,779: ============================================================
2022-07-24 16:13:58,779: Epoch 3/25 Batch 2300/7662 eta: 19:40:35.025777	Training Loss1 18.1552 (22.2686)	Training Total_Loss 18.1552 (22.2686)	Training Prec@1 87.695 (81.442)	Training Prec@5 92.578 (88.246)	
2022-07-24 16:13:58,779: ============================================================
2022-07-24 16:14:39,557: time cost, forward:0.1243845837073507, backward:0.09731342584801594, data cost:0.18600134036599622 
2022-07-24 16:14:39,557: ============================================================
2022-07-24 16:14:39,557: Epoch 3/25 Batch 2400/7662 eta: 19:41:23.890822	Training Loss1 18.8691 (22.1295)	Training Total_Loss 18.8691 (22.1295)	Training Prec@1 87.109 (81.719)	Training Prec@5 93.945 (88.450)	
2022-07-24 16:14:39,557: ============================================================
2022-07-24 16:15:20,294: time cost, forward:0.12438037386890792, backward:0.09730478705001287, data cost:0.18597407091040763 
2022-07-24 16:15:20,294: ============================================================
2022-07-24 16:15:20,295: Epoch 3/25 Batch 2500/7662 eta: 19:39:31.577611	Training Loss1 17.9503 (21.9936)	Training Total_Loss 17.9503 (21.9936)	Training Prec@1 89.648 (82.001)	Training Prec@5 93.164 (88.647)	
2022-07-24 16:15:20,295: ============================================================
2022-07-24 16:16:01,070: time cost, forward:0.12436715031000412, backward:0.09731597935249825, data cost:0.1859500165075557 
2022-07-24 16:16:01,071: ============================================================
2022-07-24 16:16:01,071: Epoch 3/25 Batch 2600/7662 eta: 19:39:58.463066	Training Loss1 17.6504 (21.8624)	Training Total_Loss 17.6504 (21.8624)	Training Prec@1 90.234 (82.259)	Training Prec@5 94.336 (88.831)	
2022-07-24 16:16:01,071: ============================================================
2022-07-24 16:16:41,796: time cost, forward:0.12435332807446904, backward:0.0973125783193107, data cost:0.1859284034699323 
2022-07-24 16:16:41,796: ============================================================
2022-07-24 16:16:41,797: Epoch 3/25 Batch 2700/7662 eta: 19:37:50.435276	Training Loss1 18.8521 (21.7352)	Training Total_Loss 18.8521 (21.7352)	Training Prec@1 88.477 (82.511)	Training Prec@5 93.164 (89.010)	
2022-07-24 16:16:41,797: ============================================================
2022-07-24 16:17:22,569: time cost, forward:0.1243507877423449, backward:0.09731519022086724, data cost:0.18591035251406185 
2022-07-24 16:17:22,569: ============================================================
2022-07-24 16:17:22,570: Epoch 3/25 Batch 2800/7662 eta: 19:38:31.390713	Training Loss1 18.5944 (21.6142)	Training Total_Loss 18.5944 (21.6142)	Training Prec@1 89.062 (82.744)	Training Prec@5 93.164 (89.178)	
2022-07-24 16:17:22,570: ============================================================
2022-07-24 16:18:03,327: time cost, forward:0.12434248884779373, backward:0.09731874033351239, data cost:0.1858922665429222 
2022-07-24 16:18:03,327: ============================================================
2022-07-24 16:18:03,327: Epoch 3/25 Batch 2900/7662 eta: 19:37:24.016799	Training Loss1 17.5709 (21.4939)	Training Total_Loss 17.5709 (21.4939)	Training Prec@1 91.406 (82.979)	Training Prec@5 95.117 (89.349)	
2022-07-24 16:18:03,327: ============================================================
2022-07-24 16:18:44,043: time cost, forward:0.1243317914271442, backward:0.0973128121310212, data cost:0.1858744985383922 
2022-07-24 16:18:44,043: ============================================================
2022-07-24 16:18:44,043: Epoch 3/25 Batch 3000/7662 eta: 19:35:31.145520	Training Loss1 18.0144 (21.3787)	Training Total_Loss 18.0144 (21.3787)	Training Prec@1 90.820 (83.206)	Training Prec@5 93.750 (89.511)	
2022-07-24 16:18:44,043: ============================================================
2022-07-24 16:19:24,811: time cost, forward:0.12433921179105174, backward:0.09730484417154928, data cost:0.18585802347823935 
2022-07-24 16:19:24,812: ============================================================
2022-07-24 16:19:24,812: Epoch 3/25 Batch 3100/7662 eta: 19:36:21.457402	Training Loss1 18.0169 (21.2680)	Training Total_Loss 18.0169 (21.2680)	Training Prec@1 89.453 (83.423)	Training Prec@5 94.727 (89.669)	
2022-07-24 16:19:24,812: ============================================================
2022-07-24 16:20:05,582: time cost, forward:0.12433063428675468, backward:0.09731208424748537, data cost:0.18584209183075534 
2022-07-24 16:20:05,583: ============================================================
2022-07-24 16:20:05,583: Epoch 3/25 Batch 3200/7662 eta: 19:35:44.644536	Training Loss1 17.3050 (21.1555)	Training Total_Loss 17.3050 (21.1555)	Training Prec@1 91.797 (83.637)	Training Prec@5 95.508 (89.822)	
2022-07-24 16:20:05,583: ============================================================
2022-07-24 16:20:46,362: time cost, forward:0.12432803591658542, backward:0.09731381045720475, data cost:0.18582830525918886 
2022-07-24 16:20:46,362: ============================================================
2022-07-24 16:20:46,363: Epoch 3/25 Batch 3300/7662 eta: 19:35:19.242998	Training Loss1 18.3549 (21.0498)	Training Total_Loss 18.3549 (21.0498)	Training Prec@1 88.672 (83.842)	Training Prec@5 93.750 (89.967)	
2022-07-24 16:20:46,363: ============================================================
2022-07-24 16:21:27,149: time cost, forward:0.1243268067993182, backward:0.09731951732079959, data cost:0.18581482262147037 
2022-07-24 16:21:27,149: ============================================================
2022-07-24 16:21:27,149: Epoch 3/25 Batch 3400/7662 eta: 19:34:50.156837	Training Loss1 17.8687 (20.9460)	Training Total_Loss 17.8687 (20.9460)	Training Prec@1 91.797 (84.045)	Training Prec@5 95.508 (90.111)	
2022-07-24 16:21:27,149: ============================================================
2022-07-24 16:22:07,964: time cost, forward:0.12433486797019869, backward:0.09732463578559154, data cost:0.1858017203398315 
2022-07-24 16:22:07,965: ============================================================
2022-07-24 16:22:07,965: Epoch 3/25 Batch 3500/7662 eta: 19:34:59.697993	Training Loss1 17.5164 (20.8467)	Training Total_Loss 17.5164 (20.8467)	Training Prec@1 90.820 (84.234)	Training Prec@5 94.727 (90.246)	
2022-07-24 16:22:07,965: ============================================================
2022-07-24 16:22:48,760: time cost, forward:0.12433884792375578, backward:0.09732558482817459, data cost:0.18579235200121455 
2022-07-24 16:22:48,760: ============================================================
2022-07-24 16:22:48,760: Epoch 3/25 Batch 3600/7662 eta: 19:33:43.509926	Training Loss1 17.4097 (20.7490)	Training Total_Loss 17.4097 (20.7490)	Training Prec@1 88.477 (84.421)	Training Prec@5 94.141 (90.378)	
2022-07-24 16:22:48,760: ============================================================
2022-07-24 16:23:29,562: time cost, forward:0.12434792886008504, backward:0.09732174074111613, data cost:0.18578376348484654 
2022-07-24 16:23:29,563: ============================================================
2022-07-24 16:23:29,563: Epoch 3/25 Batch 3700/7662 eta: 19:33:15.911232	Training Loss1 17.3091 (20.6542)	Training Total_Loss 17.3091 (20.6542)	Training Prec@1 89.453 (84.601)	Training Prec@5 93.359 (90.505)	
2022-07-24 16:23:29,563: ============================================================
2022-07-24 16:24:10,362: time cost, forward:0.12434805133023304, backward:0.09732332747997376, data cost:0.18577823522185677 
2022-07-24 16:24:10,362: ============================================================
2022-07-24 16:24:10,362: Epoch 3/25 Batch 3800/7662 eta: 19:32:29.335346	Training Loss1 17.1528 (20.5634)	Training Total_Loss 17.1528 (20.5634)	Training Prec@1 90.430 (84.768)	Training Prec@5 95.312 (90.624)	
2022-07-24 16:24:10,362: ============================================================
2022-07-24 16:24:51,107: time cost, forward:0.12434297006660378, backward:0.09732255754668946, data cost:0.1857669266654027 
2022-07-24 16:24:51,108: ============================================================
2022-07-24 16:24:51,108: Epoch 3/25 Batch 3900/7662 eta: 19:30:15.499580	Training Loss1 17.4772 (20.4726)	Training Total_Loss 17.4772 (20.4726)	Training Prec@1 89.258 (84.936)	Training Prec@5 93.945 (90.743)	
2022-07-24 16:24:51,108: ============================================================
2022-07-24 16:25:31,849: time cost, forward:0.12433543101523215, backward:0.09732161912061954, data cost:0.1857582893810382 
2022-07-24 16:25:31,849: ============================================================
2022-07-24 16:25:31,849: Epoch 3/25 Batch 4000/7662 eta: 19:29:28.009215	Training Loss1 17.2278 (20.3896)	Training Total_Loss 17.2278 (20.3896)	Training Prec@1 89.453 (85.093)	Training Prec@5 93.945 (90.855)	
2022-07-24 16:25:31,850: ============================================================
2022-07-24 16:26:12,618: time cost, forward:0.12433469036667194, backward:0.09731865400336201, data cost:0.18575231050043228 
2022-07-24 16:26:12,618: ============================================================
2022-07-24 16:26:12,618: Epoch 3/25 Batch 4100/7662 eta: 19:29:33.837044	Training Loss1 16.4870 (20.3056)	Training Total_Loss 16.4870 (20.3056)	Training Prec@1 92.578 (85.249)	Training Prec@5 96.484 (90.966)	
2022-07-24 16:26:12,618: ============================================================
2022-07-24 16:26:53,431: time cost, forward:0.12433062272004838, backward:0.09732384146835497, data cost:0.18574844652427097 
2022-07-24 16:26:53,432: ============================================================
2022-07-24 16:26:53,432: Epoch 3/25 Batch 4200/7662 eta: 19:30:10.542207	Training Loss1 16.6074 (20.2231)	Training Total_Loss 16.6074 (20.2231)	Training Prec@1 93.359 (85.405)	Training Prec@5 98.047 (91.075)	
2022-07-24 16:26:53,432: ============================================================
2022-07-24 16:27:34,250: time cost, forward:0.12433384928378317, backward:0.09732771906971405, data cost:0.18574408443341783 
2022-07-24 16:27:34,250: ============================================================
2022-07-24 16:27:34,250: Epoch 3/25 Batch 4300/7662 eta: 19:29:37.919271	Training Loss1 16.6954 (20.1417)	Training Total_Loss 16.6954 (20.1417)	Training Prec@1 91.602 (85.553)	Training Prec@5 95.117 (91.181)	
2022-07-24 16:27:34,250: ============================================================
2022-07-24 16:28:15,108: time cost, forward:0.12434394279917035, backward:0.09732797509514492, data cost:0.18574515048090126 
2022-07-24 16:28:15,108: ============================================================
2022-07-24 16:28:15,108: Epoch 3/25 Batch 4400/7662 eta: 19:30:04.912271	Training Loss1 17.0526 (20.0599)	Training Total_Loss 17.0526 (20.0599)	Training Prec@1 91.211 (85.697)	Training Prec@5 94.727 (91.282)	
2022-07-24 16:28:15,108: ============================================================
2022-07-24 16:28:55,933: time cost, forward:0.12434471096031187, backward:0.09733076984815053, data cost:0.18574554291161519 
2022-07-24 16:28:55,933: ============================================================
2022-07-24 16:28:55,933: Epoch 3/25 Batch 4500/7662 eta: 19:28:27.987968	Training Loss1 17.0665 (19.9844)	Training Total_Loss 17.0665 (19.9844)	Training Prec@1 91.406 (85.837)	Training Prec@5 96.484 (91.378)	
2022-07-24 16:28:55,933: ============================================================
2022-07-24 16:29:36,739: time cost, forward:0.12434650991605298, backward:0.09732989286127026, data cost:0.18574376644375895 
2022-07-24 16:29:36,739: ============================================================
2022-07-24 16:29:36,739: Epoch 3/25 Batch 4600/7662 eta: 19:27:13.816538	Training Loss1 17.1801 (19.9103)	Training Total_Loss 17.1801 (19.9103)	Training Prec@1 90.039 (85.970)	Training Prec@5 94.141 (91.473)	
2022-07-24 16:29:36,739: ============================================================
2022-07-24 16:30:17,551: time cost, forward:0.12434587394412362, backward:0.09733354581064507, data cost:0.1857408186962666 
2022-07-24 16:30:17,551: ============================================================
2022-07-24 16:30:17,551: Epoch 3/25 Batch 4700/7662 eta: 19:26:44.002529	Training Loss1 16.8490 (19.8356)	Training Total_Loss 16.8490 (19.8356)	Training Prec@1 91.797 (86.101)	Training Prec@5 95.898 (91.564)	
2022-07-24 16:30:17,552: ============================================================
2022-07-24 16:30:58,395: time cost, forward:0.12435605148892523, backward:0.09733083179081994, data cost:0.1857403710773275 
2022-07-24 16:30:58,396: ============================================================
2022-07-24 16:30:58,396: Epoch 3/25 Batch 4800/7662 eta: 19:26:58.396087	Training Loss1 15.7427 (19.7649)	Training Total_Loss 15.7427 (19.7649)	Training Prec@1 93.359 (86.227)	Training Prec@5 96.094 (91.651)	
2022-07-24 16:30:58,396: ============================================================
2022-07-24 16:31:39,247: time cost, forward:0.12436804685769798, backward:0.09732860082216374, data cost:0.18573870486594093 
2022-07-24 16:31:39,247: ============================================================
2022-07-24 16:31:39,248: Epoch 3/25 Batch 4900/7662 eta: 19:26:29.890464	Training Loss1 15.8409 (19.6941)	Training Total_Loss 15.8409 (19.6941)	Training Prec@1 94.531 (86.357)	Training Prec@5 97.070 (91.739)	
2022-07-24 16:31:39,248: ============================================================
2022-07-24 16:32:20,066: time cost, forward:0.12436628432291988, backward:0.097333623447712, data cost:0.18573651835545943 
2022-07-24 16:32:20,066: ============================================================
2022-07-24 16:32:20,066: Epoch 3/25 Batch 5000/7662 eta: 19:24:52.378797	Training Loss1 17.1572 (19.6252)	Training Total_Loss 17.1572 (19.6252)	Training Prec@1 92.188 (86.481)	Training Prec@5 96.289 (91.824)	
2022-07-24 16:32:20,066: ============================================================
2022-07-24 16:33:00,861: time cost, forward:0.12435839867727456, backward:0.0973388990202846, data cost:0.18573574660735684 
2022-07-24 16:33:00,861: ============================================================
2022-07-24 16:33:00,861: Epoch 3/25 Batch 5100/7662 eta: 19:23:31.400132	Training Loss1 16.6925 (19.5587)	Training Total_Loss 16.6925 (19.5587)	Training Prec@1 92.969 (86.597)	Training Prec@5 96.680 (91.905)	
2022-07-24 16:33:00,861: ============================================================
2022-07-24 16:33:41,718: time cost, forward:0.12435986124843239, backward:0.0973452839811941, data cost:0.18573640350837803 
2022-07-24 16:33:41,718: ============================================================
2022-07-24 16:33:41,718: Epoch 3/25 Batch 5200/7662 eta: 19:24:36.725035	Training Loss1 16.4966 (19.4935)	Training Total_Loss 16.4966 (19.4935)	Training Prec@1 92.773 (86.715)	Training Prec@5 96.484 (91.987)	
2022-07-24 16:33:41,718: ============================================================
2022-07-24 16:34:22,533: time cost, forward:0.12435700128968874, backward:0.0973492292755841, data cost:0.18573578800158944 
2022-07-24 16:34:22,533: ============================================================
2022-07-24 16:34:22,533: Epoch 3/25 Batch 5300/7662 eta: 19:22:43.560917	Training Loss1 15.7650 (19.4313)	Training Total_Loss 15.7650 (19.4313)	Training Prec@1 91.992 (86.827)	Training Prec@5 96.680 (92.067)	
2022-07-24 16:34:22,533: ============================================================
2022-07-24 16:35:03,339: time cost, forward:0.12435749085396831, backward:0.09734802366208314, data cost:0.1857357593041081 
2022-07-24 16:35:03,340: ============================================================
2022-07-24 16:35:03,340: Epoch 3/25 Batch 5400/7662 eta: 19:21:48.712328	Training Loss1 16.0890 (19.3684)	Training Total_Loss 16.0890 (19.3684)	Training Prec@1 91.797 (86.937)	Training Prec@5 96.289 (92.144)	
2022-07-24 16:35:03,340: ============================================================
2022-07-24 16:35:44,180: time cost, forward:0.12436488572630715, backward:0.09734862079228417, data cost:0.18573354981036203 
2022-07-24 16:35:44,180: ============================================================
2022-07-24 16:35:44,180: Epoch 3/25 Batch 5500/7662 eta: 19:22:05.934849	Training Loss1 15.6597 (19.3066)	Training Total_Loss 15.6597 (19.3066)	Training Prec@1 92.969 (87.044)	Training Prec@5 96.484 (92.217)	
2022-07-24 16:35:44,180: ============================================================
2022-07-24 16:36:24,982: time cost, forward:0.12436390008260403, backward:0.09735045230352446, data cost:0.18573083816244892 
2022-07-24 16:36:24,982: ============================================================
2022-07-24 16:36:24,982: Epoch 3/25 Batch 5600/7662 eta: 19:20:18.890562	Training Loss1 15.8565 (19.2461)	Training Total_Loss 15.8565 (19.2461)	Training Prec@1 93.359 (87.148)	Training Prec@5 96.289 (92.288)	
2022-07-24 16:36:24,982: ============================================================
2022-07-24 16:37:05,764: time cost, forward:0.12436114965687511, backward:0.09735117604553041, data cost:0.18572734150683218 
2022-07-24 16:37:05,764: ============================================================
2022-07-24 16:37:05,764: Epoch 3/25 Batch 5700/7662 eta: 19:19:04.459890	Training Loss1 15.5266 (19.1867)	Training Total_Loss 15.5266 (19.1867)	Training Prec@1 93.359 (87.250)	Training Prec@5 96.484 (92.359)	
2022-07-24 16:37:05,764: ============================================================
2022-07-24 16:37:46,546: time cost, forward:0.12436416749811148, backward:0.09734696835397667, data cost:0.1857235399191288 
2022-07-24 16:37:46,547: ============================================================
2022-07-24 16:37:46,547: Epoch 3/25 Batch 5800/7662 eta: 19:18:24.465276	Training Loss1 16.6231 (19.1294)	Training Total_Loss 16.6231 (19.1294)	Training Prec@1 90.820 (87.347)	Training Prec@5 95.898 (92.426)	
2022-07-24 16:37:46,547: ============================================================
2022-07-24 16:38:27,340: time cost, forward:0.12436041320293793, backward:0.09735207598903337, data cost:0.18571906737259514 
2022-07-24 16:38:27,340: ============================================================
2022-07-24 16:38:27,340: Epoch 3/25 Batch 5900/7662 eta: 19:18:02.515618	Training Loss1 15.6385 (19.0737)	Training Total_Loss 15.6385 (19.0737)	Training Prec@1 93.750 (87.446)	Training Prec@5 95.703 (92.494)	
2022-07-24 16:38:27,340: ============================================================
2022-07-24 16:39:08,052: time cost, forward:0.12435459065266422, backward:0.09734830110743554, data cost:0.18571252643237374 
2022-07-24 16:39:08,052: ============================================================
2022-07-24 16:39:08,053: Epoch 3/25 Batch 6000/7662 eta: 19:15:03.240174	Training Loss1 16.0595 (19.0169)	Training Total_Loss 16.0595 (19.0169)	Training Prec@1 93.164 (87.540)	Training Prec@5 95.898 (92.557)	
2022-07-24 16:39:08,053: ============================================================
2022-07-24 16:39:48,822: time cost, forward:0.12435212712304321, backward:0.0973501733569439, data cost:0.18570666454682333 
2022-07-24 16:39:48,822: ============================================================
2022-07-24 16:39:48,823: Epoch 3/25 Batch 6100/7662 eta: 19:16:00.680114	Training Loss1 15.8630 (18.9620)	Training Total_Loss 15.8630 (18.9620)	Training Prec@1 93.555 (87.632)	Training Prec@5 95.508 (92.619)	
2022-07-24 16:39:48,823: ============================================================
2022-07-24 16:40:29,605: time cost, forward:0.12435212249158947, backward:0.09735055688235582, data cost:0.1857023764125838 
2022-07-24 16:40:29,605: ============================================================
2022-07-24 16:40:29,606: Epoch 3/25 Batch 6200/7662 eta: 19:15:41.989379	Training Loss1 16.5303 (18.9083)	Training Total_Loss 16.5303 (18.9083)	Training Prec@1 90.039 (87.725)	Training Prec@5 94.141 (92.684)	
2022-07-24 16:40:29,606: ============================================================
2022-07-24 16:41:10,356: time cost, forward:0.12434606783767412, backward:0.0973509722502388, data cost:0.1856988811704881 
2022-07-24 16:41:10,356: ============================================================
2022-07-24 16:41:10,356: Epoch 3/25 Batch 6300/7662 eta: 19:14:06.622270	Training Loss1 15.1625 (18.8568)	Training Total_Loss 15.1625 (18.8568)	Training Prec@1 94.531 (87.812)	Training Prec@5 97.070 (92.744)	
2022-07-24 16:41:10,356: ============================================================
2022-07-24 16:41:51,067: time cost, forward:0.12433798798622052, backward:0.097349052821161, data cost:0.18569399249015292 
2022-07-24 16:41:51,067: ============================================================
2022-07-24 16:41:51,067: Epoch 3/25 Batch 6400/7662 eta: 19:12:18.450497	Training Loss1 15.4885 (18.8060)	Training Total_Loss 15.4885 (18.8060)	Training Prec@1 93.555 (87.900)	Training Prec@5 97.070 (92.803)	
2022-07-24 16:41:51,067: ============================================================
2022-07-24 16:42:31,829: time cost, forward:0.1243363250712465, backward:0.09734809565569809, data cost:0.18569018433948428 
2022-07-24 16:42:31,830: ============================================================
2022-07-24 16:42:31,830: Epoch 3/25 Batch 6500/7662 eta: 19:13:04.872956	Training Loss1 15.3244 (18.7575)	Training Total_Loss 15.3244 (18.7575)	Training Prec@1 92.578 (87.983)	Training Prec@5 96.680 (92.858)	
2022-07-24 16:42:31,830: ============================================================
2022-07-24 16:43:12,575: time cost, forward:0.12433604128994098, backward:0.0973447381519769, data cost:0.18568505961202386 
2022-07-24 16:43:12,575: ============================================================
2022-07-24 16:43:12,575: Epoch 3/25 Batch 6600/7662 eta: 19:11:55.260240	Training Loss1 16.0043 (18.7078)	Training Total_Loss 16.0043 (18.7078)	Training Prec@1 94.141 (88.068)	Training Prec@5 97.461 (92.917)	
2022-07-24 16:43:12,575: ============================================================
2022-07-24 16:43:53,325: time cost, forward:0.12433425400359967, backward:0.09734185636354963, data cost:0.1856800709078251 
2022-07-24 16:43:53,326: ============================================================
2022-07-24 16:43:53,326: Epoch 3/25 Batch 6700/7662 eta: 19:11:22.973968	Training Loss1 15.7771 (18.6597)	Training Total_Loss 15.7771 (18.6597)	Training Prec@1 91.797 (88.148)	Training Prec@5 95.312 (92.973)	
2022-07-24 16:43:53,326: ============================================================
2022-07-24 16:44:34,057: time cost, forward:0.12432840803578103, backward:0.09734254329410401, data cost:0.18567490037670378 
2022-07-24 16:44:34,057: ============================================================
2022-07-24 16:44:34,057: Epoch 3/25 Batch 6800/7662 eta: 19:10:10.065850	Training Loss1 15.5297 (18.6113)	Training Total_Loss 15.5297 (18.6113)	Training Prec@1 91.797 (88.231)	Training Prec@5 96.094 (93.027)	
2022-07-24 16:44:34,057: ============================================================
2022-07-24 16:45:14,837: time cost, forward:0.12432832686101757, backward:0.09734412393184275, data cost:0.18567020852663565 
2022-07-24 16:45:14,837: ============================================================
2022-07-24 16:45:14,837: Epoch 3/25 Batch 6900/7662 eta: 19:10:52.070526	Training Loss1 15.3640 (18.5648)	Training Total_Loss 15.3640 (18.5648)	Training Prec@1 91.797 (88.309)	Training Prec@5 95.898 (93.082)	
2022-07-24 16:45:14,838: ============================================================
2022-07-24 16:45:55,651: time cost, forward:0.12433148738502996, backward:0.09734458493443791, data cost:0.18566847607176173 
2022-07-24 16:45:55,651: ============================================================
2022-07-24 16:45:55,651: Epoch 3/25 Batch 7000/7662 eta: 19:11:07.697955	Training Loss1 14.8113 (18.5186)	Training Total_Loss 14.8113 (18.5186)	Training Prec@1 93.359 (88.387)	Training Prec@5 96.094 (93.135)	
2022-07-24 16:45:55,651: ============================================================
2022-07-24 16:46:36,414: time cost, forward:0.12433247731460419, backward:0.09734124256735335, data cost:0.18566564657869836 
2022-07-24 16:46:36,414: ============================================================
2022-07-24 16:46:36,414: Epoch 3/25 Batch 7100/7662 eta: 19:09:01.132173	Training Loss1 15.3246 (18.4726)	Training Total_Loss 15.3246 (18.4726)	Training Prec@1 92.578 (88.465)	Training Prec@5 97.461 (93.187)	
2022-07-24 16:46:36,414: ============================================================
2022-07-24 16:47:17,137: time cost, forward:0.12432959961020164, backward:0.09733706822841097, data cost:0.18566062692503646 
2022-07-24 16:47:17,137: ============================================================
2022-07-24 16:47:17,138: Epoch 3/25 Batch 7200/7662 eta: 19:07:13.730920	Training Loss1 14.1419 (18.4273)	Training Total_Loss 14.1419 (18.4273)	Training Prec@1 95.508 (88.542)	Training Prec@5 98.242 (93.238)	
2022-07-24 16:47:17,138: ============================================================
2022-07-24 16:47:57,840: time cost, forward:0.12432662378126406, backward:0.0973317737791012, data cost:0.18565569068980814 
2022-07-24 16:47:57,840: ============================================================
2022-07-24 16:47:57,841: Epoch 3/25 Batch 7300/7662 eta: 19:05:58.208310	Training Loss1 15.3696 (18.3831)	Training Total_Loss 15.3696 (18.3831)	Training Prec@1 93.359 (88.616)	Training Prec@5 95.508 (93.287)	
2022-07-24 16:47:57,841: ============================================================
2022-07-24 16:48:38,546: time cost, forward:0.12431961759584532, backward:0.0973314363129285, data cost:0.1856504733344319 
2022-07-24 16:48:38,547: ============================================================
2022-07-24 16:48:38,547: Epoch 3/25 Batch 7400/7662 eta: 19:05:23.289135	Training Loss1 14.9586 (18.3386)	Training Total_Loss 14.9586 (18.3386)	Training Prec@1 93.164 (88.688)	Training Prec@5 96.484 (93.336)	
2022-07-24 16:48:38,547: ============================================================
2022-07-24 16:49:19,260: time cost, forward:0.12431681453426578, backward:0.09732714149535124, data cost:0.18564670317044876 
2022-07-24 16:49:19,260: ============================================================
2022-07-24 16:49:19,261: Epoch 3/25 Batch 7500/7662 eta: 19:04:54.965271	Training Loss1 13.6622 (18.2961)	Training Total_Loss 13.6622 (18.2961)	Training Prec@1 95.703 (88.757)	Training Prec@5 97.656 (93.382)	
2022-07-24 16:49:19,261: ============================================================
2022-07-24 16:49:59,975: time cost, forward:0.12431304162074773, backward:0.0973247439473189, data cost:0.18564272202979828 
2022-07-24 16:49:59,976: ============================================================
2022-07-24 16:49:59,976: Epoch 3/25 Batch 7600/7662 eta: 19:04:16.933590	Training Loss1 15.5014 (18.2541)	Training Total_Loss 15.5014 (18.2541)	Training Prec@1 92.383 (88.825)	Training Prec@5 97.266 (93.428)	
2022-07-24 16:49:59,976: ============================================================
2022-07-24 16:50:26,774: Epoch 3/25 Batch 7663/7662 eta: 19:03:51.282972	Training Loss1 15.4484 (18.2274)	Training Total_Loss 15.4484 (18.2274)	Training Prec@1 94.531 (88.868)	Training Prec@5 98.242 (93.457)	
2022-07-24 16:50:26,774: ============================================================
2022-07-24 16:51:10,439: time cost, forward:0.12407125367058648, backward:0.09690155645813604, data cost:0.21649964891298853 
2022-07-24 16:51:10,439: ============================================================
2022-07-24 16:51:10,439: Epoch 4/25 Batch 100/7662 eta: 20:23:07.149112	Training Loss1 13.4427 (13.6408)	Training Total_Loss 13.4427 (13.6408)	Training Prec@1 96.680 (95.460)	Training Prec@5 98.828 (97.777)	
2022-07-24 16:51:10,439: ============================================================
2022-07-24 16:51:51,169: time cost, forward:0.12419416796621965, backward:0.09693814042824597, data cost:0.20083364529825334 
2022-07-24 16:51:51,170: ============================================================
2022-07-24 16:51:51,170: Epoch 4/25 Batch 200/7662 eta: 19:02:56.309717	Training Loss1 14.0201 (13.7025)	Training Total_Loss 14.0201 (13.7025)	Training Prec@1 95.117 (95.546)	Training Prec@5 98.047 (97.785)	
2022-07-24 16:51:51,170: ============================================================
2022-07-24 16:52:31,917: time cost, forward:0.12427945280553505, backward:0.09695616374446397, data cost:0.1956631172460856 
2022-07-24 16:52:31,918: ============================================================
2022-07-24 16:52:31,918: Epoch 4/25 Batch 300/7662 eta: 19:02:44.677806	Training Loss1 14.3869 (13.7743)	Training Total_Loss 14.3869 (13.7743)	Training Prec@1 94.727 (95.493)	Training Prec@5 97.656 (97.763)	
2022-07-24 16:52:31,918: ============================================================
2022-07-24 16:53:12,639: time cost, forward:0.12423465126439144, backward:0.09699935662119012, data cost:0.19307125720165128 
2022-07-24 16:53:12,639: ============================================================
2022-07-24 16:53:12,640: Epoch 4/25 Batch 400/7662 eta: 19:01:19.732126	Training Loss1 14.2750 (13.8552)	Training Total_Loss 14.2750 (13.8552)	Training Prec@1 94.141 (95.450)	Training Prec@5 97.461 (97.727)	
2022-07-24 16:53:12,640: ============================================================
2022-07-24 16:53:53,372: time cost, forward:0.12424138122665619, backward:0.09700435149167964, data cost:0.1915290900366101 
2022-07-24 16:53:53,372: ============================================================
2022-07-24 16:53:53,372: Epoch 4/25 Batch 500/7662 eta: 19:00:57.016950	Training Loss1 14.1928 (13.9159)	Training Total_Loss 14.1928 (13.9159)	Training Prec@1 94.531 (95.421)	Training Prec@5 96.484 (97.736)	
2022-07-24 16:53:53,372: ============================================================
2022-07-24 16:54:34,148: time cost, forward:0.12429358565150597, backward:0.09700691680080306, data cost:0.19052519901766005 
2022-07-24 16:54:34,149: ============================================================
2022-07-24 16:54:34,149: Epoch 4/25 Batch 600/7662 eta: 19:01:30.875723	Training Loss1 14.5443 (13.9767)	Training Total_Loss 14.5443 (13.9767)	Training Prec@1 93.945 (95.391)	Training Prec@5 97.852 (97.722)	
2022-07-24 16:54:34,149: ============================================================
2022-07-24 16:55:14,938: time cost, forward:0.12433530946657893, backward:0.09702081946344335, data cost:0.18981485578294136 
2022-07-24 16:55:14,939: ============================================================
2022-07-24 16:55:14,939: Epoch 4/25 Batch 700/7662 eta: 19:01:11.915716	Training Loss1 14.9280 (14.0214)	Training Total_Loss 14.9280 (14.0214)	Training Prec@1 93.945 (95.368)	Training Prec@5 97.070 (97.716)	
2022-07-24 16:55:14,939: ============================================================
2022-07-24 16:55:55,721: time cost, forward:0.12434018836898708, backward:0.0970424003386229, data cost:0.18928392210949646 
2022-07-24 16:55:55,721: ============================================================
2022-07-24 16:55:55,722: Epoch 4/25 Batch 800/7662 eta: 19:00:19.263952	Training Loss1 14.7807 (14.0557)	Training Total_Loss 14.7807 (14.0557)	Training Prec@1 95.312 (95.335)	Training Prec@5 98.438 (97.695)	
2022-07-24 16:55:55,722: ============================================================
2022-07-24 16:56:36,544: time cost, forward:0.12438825558502231, backward:0.09704598171161995, data cost:0.18888739086231746 
2022-07-24 16:56:36,544: ============================================================
2022-07-24 16:56:36,544: Epoch 4/25 Batch 900/7662 eta: 19:00:45.154139	Training Loss1 14.9788 (14.0929)	Training Total_Loss 14.9788 (14.0929)	Training Prec@1 94.141 (95.300)	Training Prec@5 96.484 (97.674)	
2022-07-24 16:56:36,544: ============================================================
2022-07-24 16:57:17,319: time cost, forward:0.12437474214517558, backward:0.09706490295188683, data cost:0.188558293773128 
2022-07-24 16:57:17,320: ============================================================
2022-07-24 16:57:17,320: Epoch 4/25 Batch 1000/7662 eta: 18:58:45.742733	Training Loss1 15.4685 (14.1300)	Training Total_Loss 15.4685 (14.1300)	Training Prec@1 93.750 (95.262)	Training Prec@5 95.898 (97.644)	
2022-07-24 16:57:17,320: ============================================================
2022-07-24 16:57:58,134: time cost, forward:0.12440923932902481, backward:0.09706572991701773, data cost:0.1882929435309982 
2022-07-24 16:57:58,135: ============================================================
2022-07-24 16:57:58,135: Epoch 4/25 Batch 1100/7662 eta: 18:59:10.788340	Training Loss1 14.7741 (14.1533)	Training Total_Loss 14.7741 (14.1533)	Training Prec@1 95.508 (95.254)	Training Prec@5 97.656 (97.642)	
2022-07-24 16:57:58,135: ============================================================
2022-07-24 16:58:38,954: time cost, forward:0.12444172251512847, backward:0.09706616978331145, data cost:0.18807279119101836 
2022-07-24 16:58:38,954: ============================================================
2022-07-24 16:58:38,954: Epoch 4/25 Batch 1200/7662 eta: 18:58:37.671044	Training Loss1 14.4270 (14.1789)	Training Total_Loss 14.4270 (14.1789)	Training Prec@1 93.555 (95.233)	Training Prec@5 96.484 (97.629)	
2022-07-24 16:58:38,955: ============================================================
2022-07-24 16:59:19,797: time cost, forward:0.12447065532528684, backward:0.09706996623326303, data cost:0.1878998040969414 
2022-07-24 16:59:19,797: ============================================================
2022-07-24 16:59:19,797: Epoch 4/25 Batch 1300/7662 eta: 18:58:35.453232	Training Loss1 13.8113 (14.1958)	Training Total_Loss 13.8113 (14.1958)	Training Prec@1 96.094 (95.205)	Training Prec@5 98.828 (97.611)	
2022-07-24 16:59:19,797: ============================================================
2022-07-24 17:00:00,619: time cost, forward:0.12447970164001115, backward:0.09708472862679929, data cost:0.1877416565726705 
2022-07-24 17:00:00,619: ============================================================
2022-07-24 17:00:00,619: Epoch 4/25 Batch 1400/7662 eta: 18:57:20.809355	Training Loss1 14.5038 (14.2125)	Training Total_Loss 14.5038 (14.2125)	Training Prec@1 95.898 (95.179)	Training Prec@5 97.656 (97.594)	
2022-07-24 17:00:00,620: ============================================================
2022-07-24 17:00:41,419: time cost, forward:0.12446675179718812, backward:0.09709877789696508, data cost:0.18760780146155379 
2022-07-24 17:00:41,419: ============================================================
2022-07-24 17:00:41,419: Epoch 4/25 Batch 1500/7662 eta: 18:56:01.822871	Training Loss1 13.8583 (14.2303)	Training Total_Loss 13.8583 (14.2303)	Training Prec@1 95.312 (95.161)	Training Prec@5 96.680 (97.588)	
2022-07-24 17:00:41,419: ============================================================
2022-07-24 17:01:22,248: time cost, forward:0.12447303932409423, backward:0.09711290732855496, data cost:0.18749047458880091 
2022-07-24 17:01:22,248: ============================================================
2022-07-24 17:01:22,249: Epoch 4/25 Batch 1600/7662 eta: 18:56:10.860759	Training Loss1 13.7317 (14.2487)	Training Total_Loss 13.7317 (14.2487)	Training Prec@1 95.312 (95.132)	Training Prec@5 97.266 (97.571)	
2022-07-24 17:01:22,249: ============================================================
2022-07-24 17:02:03,088: time cost, forward:0.12447791523341223, backward:0.0971270355496286, data cost:0.187391998207941 
2022-07-24 17:02:03,088: ============================================================
2022-07-24 17:02:03,089: Epoch 4/25 Batch 1700/7662 eta: 18:55:47.694501	Training Loss1 14.3042 (14.2586)	Training Total_Loss 14.3042 (14.2586)	Training Prec@1 94.141 (95.127)	Training Prec@5 97.070 (97.569)	
2022-07-24 17:02:03,089: ============================================================
2022-07-24 17:02:43,946: time cost, forward:0.12448797973412286, backward:0.09714071958710446, data cost:0.18730657918377674 
2022-07-24 17:02:43,946: ============================================================
2022-07-24 17:02:43,946: Epoch 4/25 Batch 1800/7662 eta: 18:55:35.986942	Training Loss1 14.9035 (14.2691)	Training Total_Loss 14.9035 (14.2691)	Training Prec@1 95.117 (95.115)	Training Prec@5 97.461 (97.560)	
2022-07-24 17:02:43,946: ============================================================
2022-07-24 17:03:24,810: time cost, forward:0.12450994272618748, backward:0.09714891786258932, data cost:0.1872264276748585 
2022-07-24 17:03:24,811: ============================================================
2022-07-24 17:03:24,811: Epoch 4/25 Batch 1900/7662 eta: 18:55:07.228680	Training Loss1 14.3623 (14.2770)	Training Total_Loss 14.3623 (14.2770)	Training Prec@1 94.141 (95.104)	Training Prec@5 96.875 (97.555)	
2022-07-24 17:03:24,811: ============================================================
2022-07-24 17:04:05,594: time cost, forward:0.1245063669148417, backward:0.09714900057813178, data cost:0.18714396878443343 
2022-07-24 17:04:05,595: ============================================================
2022-07-24 17:04:05,595: Epoch 4/25 Batch 2000/7662 eta: 18:52:12.006077	Training Loss1 14.4051 (14.2832)	Training Total_Loss 14.4051 (14.2832)	Training Prec@1 94.922 (95.098)	Training Prec@5 96.875 (97.552)	
2022-07-24 17:04:05,595: ============================================================
2022-07-24 17:04:46,374: time cost, forward:0.12449987494644521, backward:0.09714694668305039, data cost:0.18707319575869055 
2022-07-24 17:04:46,375: ============================================================
2022-07-24 17:04:46,375: Epoch 4/25 Batch 2100/7662 eta: 18:51:24.285265	Training Loss1 14.8668 (14.2891)	Training Total_Loss 14.8668 (14.2891)	Training Prec@1 95.508 (95.087)	Training Prec@5 97.461 (97.544)	
2022-07-24 17:04:46,375: ============================================================
2022-07-24 17:05:27,225: time cost, forward:0.12452141639046801, backward:0.09714096348195685, data cost:0.1870173560103919 
2022-07-24 17:05:27,226: ============================================================
2022-07-24 17:05:27,226: Epoch 4/25 Batch 2200/7662 eta: 18:52:41.774200	Training Loss1 15.3479 (14.2985)	Training Total_Loss 15.3479 (14.2985)	Training Prec@1 94.336 (95.072)	Training Prec@5 97.266 (97.536)	
2022-07-24 17:05:27,226: ============================================================
2022-07-24 17:06:08,043: time cost, forward:0.12452293603821597, backward:0.09714409463972877, data cost:0.18696075794540212 
2022-07-24 17:06:08,043: ============================================================
2022-07-24 17:06:08,044: Epoch 4/25 Batch 2300/7662 eta: 18:51:05.484140	Training Loss1 14.4394 (14.3053)	Training Total_Loss 14.4394 (14.3053)	Training Prec@1 92.969 (95.059)	Training Prec@5 95.703 (97.532)	
2022-07-24 17:06:08,044: ============================================================
2022-07-24 17:06:48,810: time cost, forward:0.12451856292352521, backward:0.09714051274867692, data cost:0.18690131763062312 
2022-07-24 17:06:48,810: ============================================================
2022-07-24 17:06:48,811: Epoch 4/25 Batch 2400/7662 eta: 18:49:00.736258	Training Loss1 14.5969 (14.3078)	Training Total_Loss 14.5969 (14.3078)	Training Prec@1 94.922 (95.056)	Training Prec@5 96.484 (97.532)	
2022-07-24 17:06:48,811: ============================================================
2022-07-24 17:07:29,571: time cost, forward:0.1245106809279498, backward:0.09714067397283621, data cost:0.18684409264804555 
2022-07-24 17:07:29,571: ============================================================
2022-07-24 17:07:29,571: Epoch 4/25 Batch 2500/7662 eta: 18:48:09.194669	Training Loss1 14.5049 (14.3071)	Training Total_Loss 14.5049 (14.3071)	Training Prec@1 95.117 (95.054)	Training Prec@5 97.266 (97.530)	
2022-07-24 17:07:29,571: ============================================================
2022-07-24 17:08:10,324: time cost, forward:0.12449827951942788, backward:0.09714071023184412, data cost:0.1867932552280404 
2022-07-24 17:08:10,325: ============================================================
2022-07-24 17:08:10,325: Epoch 4/25 Batch 2600/7662 eta: 18:47:16.361857	Training Loss1 14.1245 (14.3059)	Training Total_Loss 14.1245 (14.3059)	Training Prec@1 94.531 (95.054)	Training Prec@5 97.852 (97.533)	
2022-07-24 17:08:10,325: ============================================================
2022-07-24 17:08:51,071: time cost, forward:0.12448768476151943, backward:0.09713966619442815, data cost:0.18674468084280912 
2022-07-24 17:08:51,072: ============================================================
2022-07-24 17:08:51,072: Epoch 4/25 Batch 2700/7662 eta: 18:46:24.983438	Training Loss1 14.3530 (14.3049)	Training Total_Loss 14.3530 (14.3049)	Training Prec@1 93.359 (95.053)	Training Prec@5 97.070 (97.534)	
2022-07-24 17:08:51,072: ============================================================
2022-07-24 17:09:31,851: time cost, forward:0.12449265795547905, backward:0.09713355257239414, data cost:0.1867013084926789 
2022-07-24 17:09:31,851: ============================================================
2022-07-24 17:09:31,852: Epoch 4/25 Batch 2800/7662 eta: 18:46:38.689512	Training Loss1 14.3663 (14.3037)	Training Total_Loss 14.3663 (14.3037)	Training Prec@1 94.141 (95.049)	Training Prec@5 97.852 (97.530)	
2022-07-24 17:09:31,852: ============================================================
2022-07-24 17:10:12,601: time cost, forward:0.1244875634691147, backward:0.09713070636866379, data cost:0.18665717502592677 
2022-07-24 17:10:12,601: ============================================================
2022-07-24 17:10:12,601: Epoch 4/25 Batch 2900/7662 eta: 18:45:07.683329	Training Loss1 14.6584 (14.3038)	Training Total_Loss 14.6584 (14.3038)	Training Prec@1 96.289 (95.046)	Training Prec@5 98.828 (97.529)	
2022-07-24 17:10:12,601: ============================================================
2022-07-24 17:10:53,347: time cost, forward:0.12448083221534761, backward:0.09712913991133743, data cost:0.18661655589476073 
2022-07-24 17:10:53,348: ============================================================
2022-07-24 17:10:53,348: Epoch 4/25 Batch 3000/7662 eta: 18:44:22.611041	Training Loss1 14.6934 (14.3030)	Training Total_Loss 14.6934 (14.3030)	Training Prec@1 94.531 (95.042)	Training Prec@5 97.070 (97.526)	
2022-07-24 17:10:53,348: ============================================================
2022-07-24 17:11:34,118: time cost, forward:0.12448485600021278, backward:0.09712539399274128, data cost:0.18657858327882218 
2022-07-24 17:11:34,118: ============================================================
2022-07-24 17:11:34,119: Epoch 4/25 Batch 3100/7662 eta: 18:44:21.111295	Training Loss1 14.8173 (14.3039)	Training Total_Loss 14.8173 (14.3039)	Training Prec@1 95.508 (95.041)	Training Prec@5 97.461 (97.526)	
2022-07-24 17:11:34,119: ============================================================
2022-07-24 17:12:14,873: time cost, forward:0.12448389614399763, backward:0.09712320508417319, data cost:0.18654035403975178 
2022-07-24 17:12:14,873: ============================================================
2022-07-24 17:12:14,873: Epoch 4/25 Batch 3200/7662 eta: 18:43:14.141642	Training Loss1 13.9849 (14.3040)	Training Total_Loss 13.9849 (14.3040)	Training Prec@1 95.117 (95.040)	Training Prec@5 98.242 (97.525)	
2022-07-24 17:12:14,873: ============================================================
2022-07-24 17:12:55,632: time cost, forward:0.12448489221524889, backward:0.09712219845348866, data cost:0.18650368641058074 
2022-07-24 17:12:55,632: ============================================================
2022-07-24 17:12:55,632: Epoch 4/25 Batch 3300/7662 eta: 18:42:39.851589	Training Loss1 13.9918 (14.2999)	Training Total_Loss 13.9918 (14.2999)	Training Prec@1 94.727 (95.039)	Training Prec@5 97.461 (97.523)	
2022-07-24 17:12:55,632: ============================================================
2022-07-24 17:13:36,394: time cost, forward:0.12448477766099275, backward:0.0971192864678684, data cost:0.18647235125154213 
2022-07-24 17:13:36,394: ============================================================
2022-07-24 17:13:36,394: Epoch 4/25 Batch 3400/7662 eta: 18:42:05.021316	Training Loss1 13.8633 (14.2987)	Training Total_Loss 13.8633 (14.2987)	Training Prec@1 96.680 (95.040)	Training Prec@5 98.242 (97.524)	
2022-07-24 17:13:36,395: ============================================================
2022-07-24 17:14:17,129: time cost, forward:0.1244766376944534, backward:0.0971163371250472, data cost:0.18644391192337825 
2022-07-24 17:14:17,129: ============================================================
2022-07-24 17:14:17,129: Epoch 4/25 Batch 3500/7662 eta: 18:40:39.040643	Training Loss1 13.9054 (14.2950)	Training Total_Loss 13.9054 (14.2950)	Training Prec@1 97.070 (95.043)	Training Prec@5 98.242 (97.526)	
2022-07-24 17:14:17,129: ============================================================
2022-07-24 17:14:57,892: time cost, forward:0.12447547634365361, backward:0.09711288412135984, data cost:0.18641873206254939 
2022-07-24 17:14:57,892: ============================================================
2022-07-24 17:14:57,893: Epoch 4/25 Batch 3600/7662 eta: 18:40:45.237139	Training Loss1 14.1418 (14.2915)	Training Total_Loss 14.1418 (14.2915)	Training Prec@1 93.945 (95.044)	Training Prec@5 97.070 (97.525)	
2022-07-24 17:14:57,893: ============================================================
2022-07-24 17:15:38,639: time cost, forward:0.12446886483125669, backward:0.09711212517603503, data cost:0.18639359334959602 
2022-07-24 17:15:38,639: ============================================================
2022-07-24 17:15:38,639: Epoch 4/25 Batch 3700/7662 eta: 18:39:36.940513	Training Loss1 14.6359 (14.2886)	Training Total_Loss 14.6359 (14.2886)	Training Prec@1 92.969 (95.042)	Training Prec@5 95.117 (97.523)	
2022-07-24 17:15:38,639: ============================================================
2022-07-24 17:16:19,386: time cost, forward:0.12446501607109164, backward:0.09711314967256623, data cost:0.1863657245199189 
2022-07-24 17:16:19,387: ============================================================
2022-07-24 17:16:19,387: Epoch 4/25 Batch 3800/7662 eta: 18:38:57.888155	Training Loss1 13.8695 (14.2855)	Training Total_Loss 13.8695 (14.2855)	Training Prec@1 94.336 (95.046)	Training Prec@5 97.266 (97.524)	
2022-07-24 17:16:19,387: ============================================================
2022-07-24 17:17:00,111: time cost, forward:0.12446077617812566, backward:0.09710871558765412, data cost:0.18633975393193047 
2022-07-24 17:17:00,112: ============================================================
2022-07-24 17:17:00,112: Epoch 4/25 Batch 3900/7662 eta: 18:37:39.983626	Training Loss1 14.2205 (14.2811)	Training Total_Loss 14.2205 (14.2811)	Training Prec@1 95.508 (95.048)	Training Prec@5 97.461 (97.523)	
2022-07-24 17:17:00,112: ============================================================
2022-07-24 17:17:40,871: time cost, forward:0.12446308964698069, backward:0.09710361439456162, data cost:0.18631779315859773 
2022-07-24 17:17:40,872: ============================================================
2022-07-24 17:17:40,872: Epoch 4/25 Batch 4000/7662 eta: 18:37:56.645332	Training Loss1 14.8844 (14.2787)	Training Total_Loss 14.8844 (14.2787)	Training Prec@1 94.531 (95.044)	Training Prec@5 96.680 (97.521)	
2022-07-24 17:17:40,872: ============================================================
2022-07-24 17:18:21,659: time cost, forward:0.12446883638535049, backward:0.09710185520240056, data cost:0.18629675726973158 
2022-07-24 17:18:21,660: ============================================================
2022-07-24 17:18:21,660: Epoch 4/25 Batch 4100/7662 eta: 18:38:01.604808	Training Loss1 14.3508 (14.2748)	Training Total_Loss 14.3508 (14.2748)	Training Prec@1 96.484 (95.046)	Training Prec@5 97.461 (97.521)	
2022-07-24 17:18:21,660: ============================================================
2022-07-24 17:19:02,418: time cost, forward:0.12446968854680235, backward:0.09709818728284116, data cost:0.18627664497222865 
2022-07-24 17:19:02,418: ============================================================
2022-07-24 17:19:02,418: Epoch 4/25 Batch 4200/7662 eta: 18:36:32.577409	Training Loss1 14.3769 (14.2720)	Training Total_Loss 14.3769 (14.2720)	Training Prec@1 94.336 (95.047)	Training Prec@5 96.094 (97.521)	
2022-07-24 17:19:02,418: ============================================================
2022-07-24 17:19:43,194: time cost, forward:0.12447601158859065, backward:0.09709145258015936, data cost:0.18625932949924226 
2022-07-24 17:19:43,194: ============================================================
2022-07-24 17:19:43,195: Epoch 4/25 Batch 4300/7662 eta: 18:36:21.307002	Training Loss1 13.6419 (14.2660)	Training Total_Loss 13.6419 (14.2660)	Training Prec@1 94.922 (95.052)	Training Prec@5 97.852 (97.526)	
2022-07-24 17:19:43,195: ============================================================
2022-07-24 17:20:23,964: time cost, forward:0.12447873075649558, backward:0.09708613963472922, data cost:0.18624358308345088 
2022-07-24 17:20:23,965: ============================================================
2022-07-24 17:20:23,965: Epoch 4/25 Batch 4400/7662 eta: 18:35:30.707276	Training Loss1 14.5236 (14.2614)	Training Total_Loss 14.5236 (14.2614)	Training Prec@1 94.922 (95.052)	Training Prec@5 97.656 (97.528)	
2022-07-24 17:20:23,965: ============================================================
2022-07-24 17:21:04,741: time cost, forward:0.12448307810213387, backward:0.09708134522303445, data cost:0.186227823368945 
2022-07-24 17:21:04,741: ============================================================
2022-07-24 17:21:04,741: Epoch 4/25 Batch 4500/7662 eta: 18:34:59.524646	Training Loss1 13.6381 (14.2553)	Training Total_Loss 13.6381 (14.2553)	Training Prec@1 95.508 (95.056)	Training Prec@5 97.656 (97.531)	
2022-07-24 17:21:04,741: ============================================================
2022-07-24 17:21:45,483: time cost, forward:0.12447643679208044, backward:0.09708189549563268, data cost:0.1862109078093958 
2022-07-24 17:21:45,483: ============================================================
2022-07-24 17:21:45,483: Epoch 4/25 Batch 4600/7662 eta: 18:33:23.110686	Training Loss1 13.5555 (14.2524)	Training Total_Loss 13.5555 (14.2524)	Training Prec@1 96.680 (95.055)	Training Prec@5 98.633 (97.532)	
2022-07-24 17:21:45,484: ============================================================
2022-07-24 17:22:26,280: time cost, forward:0.12448677709189393, backward:0.09707820986301043, data cost:0.18619485712223902 
2022-07-24 17:22:26,280: ============================================================
2022-07-24 17:22:26,281: Epoch 4/25 Batch 4700/7662 eta: 18:34:12.207093	Training Loss1 14.1587 (14.2454)	Training Total_Loss 14.1587 (14.2454)	Training Prec@1 93.750 (95.063)	Training Prec@5 97.461 (97.535)	
2022-07-24 17:22:26,281: ============================================================
2022-07-24 17:23:07,061: time cost, forward:0.12448304234556566, backward:0.09708316754887417, data cost:0.18618076119380186 
2022-07-24 17:23:07,062: ============================================================
2022-07-24 17:23:07,062: Epoch 4/25 Batch 4800/7662 eta: 18:33:05.297710	Training Loss1 13.4084 (14.2413)	Training Total_Loss 13.4084 (14.2413)	Training Prec@1 95.703 (95.064)	Training Prec@5 98.047 (97.537)	
2022-07-24 17:23:07,062: ============================================================
2022-07-24 17:23:47,868: time cost, forward:0.12448762771815128, backward:0.09708160029355058, data cost:0.18617073509931126 
2022-07-24 17:23:47,868: ============================================================
2022-07-24 17:23:47,868: Epoch 4/25 Batch 4900/7662 eta: 18:33:06.186818	Training Loss1 14.4915 (14.2349)	Training Total_Loss 14.4915 (14.2349)	Training Prec@1 94.922 (95.069)	Training Prec@5 96.680 (97.540)	
2022-07-24 17:23:47,869: ============================================================
2022-07-24 17:24:28,697: time cost, forward:0.12449488703740504, backward:0.09708021325715949, data cost:0.18616284320630605 
2022-07-24 17:24:28,697: ============================================================
2022-07-24 17:24:28,697: Epoch 4/25 Batch 5000/7662 eta: 18:33:01.910557	Training Loss1 13.5129 (14.2293)	Training Total_Loss 13.5129 (14.2293)	Training Prec@1 96.484 (95.070)	Training Prec@5 98.242 (97.541)	
2022-07-24 17:24:28,698: ============================================================
2022-07-24 17:25:09,514: time cost, forward:0.12450106397846863, backward:0.0970784795356746, data cost:0.18615385845002533 
2022-07-24 17:25:09,514: ============================================================
2022-07-24 17:25:09,514: Epoch 4/25 Batch 5100/7662 eta: 18:32:01.052142	Training Loss1 14.0395 (14.2228)	Training Total_Loss 14.0395 (14.2228)	Training Prec@1 95.508 (95.075)	Training Prec@5 98.242 (97.542)	
2022-07-24 17:25:09,514: ============================================================
2022-07-24 17:25:50,339: time cost, forward:0.12450739034530543, backward:0.0970772374338956, data cost:0.18614604918400493 
2022-07-24 17:25:50,339: ============================================================
2022-07-24 17:25:50,339: Epoch 4/25 Batch 5200/7662 eta: 18:31:33.847795	Training Loss1 12.5812 (14.2169)	Training Total_Loss 12.5812 (14.2169)	Training Prec@1 96.289 (95.080)	Training Prec@5 98.633 (97.545)	
2022-07-24 17:25:50,339: ============================================================
2022-07-24 17:26:31,170: time cost, forward:0.12451375270929173, backward:0.09707580815848145, data cost:0.1861397384989822 
2022-07-24 17:26:31,170: ============================================================
2022-07-24 17:26:31,170: Epoch 4/25 Batch 5300/7662 eta: 18:31:02.834670	Training Loss1 14.1122 (14.2110)	Training Total_Loss 14.1122 (14.2110)	Training Prec@1 95.117 (95.084)	Training Prec@5 97.852 (97.547)	
2022-07-24 17:26:31,170: ============================================================
2022-07-24 17:27:11,948: time cost, forward:0.12451007379869948, backward:0.09707626693225344, data cost:0.18613162171423359 
2022-07-24 17:27:11,948: ============================================================
2022-07-24 17:27:11,948: Epoch 4/25 Batch 5400/7662 eta: 18:28:55.616842	Training Loss1 14.3414 (14.2047)	Training Total_Loss 14.3414 (14.2047)	Training Prec@1 95.117 (95.091)	Training Prec@5 97.461 (97.551)	
2022-07-24 17:27:11,948: ============================================================
2022-07-24 17:27:52,732: time cost, forward:0.12450639489217766, backward:0.09707813255135245, data cost:0.18612362961700601 
2022-07-24 17:27:52,733: ============================================================
2022-07-24 17:27:52,733: Epoch 4/25 Batch 5500/7662 eta: 18:28:24.953930	Training Loss1 13.9826 (14.2005)	Training Total_Loss 13.9826 (14.2005)	Training Prec@1 94.531 (95.096)	Training Prec@5 97.070 (97.552)	
2022-07-24 17:27:52,733: ============================================================
2022-07-24 17:28:33,519: time cost, forward:0.12450335898299711, backward:0.09707944166194032, data cost:0.18611659154570045 
2022-07-24 17:28:33,519: ============================================================
2022-07-24 17:28:33,519: Epoch 4/25 Batch 5600/7662 eta: 18:27:48.235667	Training Loss1 13.7369 (14.1962)	Training Total_Loss 13.7369 (14.1962)	Training Prec@1 95.508 (95.099)	Training Prec@5 97.656 (97.554)	
2022-07-24 17:28:33,520: ============================================================
2022-07-24 17:29:14,325: time cost, forward:0.12450542109412967, backward:0.09707980094028787, data cost:0.18610892573622867 
2022-07-24 17:29:14,325: ============================================================
2022-07-24 17:29:14,325: Epoch 4/25 Batch 5700/7662 eta: 18:27:38.316792	Training Loss1 13.6539 (14.1906)	Training Total_Loss 13.6539 (14.1906)	Training Prec@1 94.727 (95.104)	Training Prec@5 98.047 (97.557)	
2022-07-24 17:29:14,325: ============================================================
2022-07-24 17:29:55,140: time cost, forward:0.12450661324574878, backward:0.09708040006038628, data cost:0.1861033877497563 
2022-07-24 17:29:55,141: ============================================================
2022-07-24 17:29:55,141: Epoch 4/25 Batch 5800/7662 eta: 18:27:13.551178	Training Loss1 13.6541 (14.1827)	Training Total_Loss 13.6541 (14.1827)	Training Prec@1 93.555 (95.110)	Training Prec@5 96.094 (97.560)	
2022-07-24 17:29:55,141: ============================================================
2022-07-24 17:30:35,981: time cost, forward:0.12451255646857756, backward:0.09708183780527252, data cost:0.18609708663790403 
2022-07-24 17:30:35,981: ============================================================
2022-07-24 17:30:35,982: Epoch 4/25 Batch 5900/7662 eta: 18:27:13.442292	Training Loss1 13.5500 (14.1768)	Training Total_Loss 13.5500 (14.1768)	Training Prec@1 97.070 (95.116)	Training Prec@5 98.438 (97.564)	
2022-07-24 17:30:35,982: ============================================================
2022-07-24 17:31:16,799: time cost, forward:0.12451695318837268, backward:0.09708112584568894, data cost:0.18609061871474733 
2022-07-24 17:31:16,799: ============================================================
2022-07-24 17:31:16,800: Epoch 4/25 Batch 6000/7662 eta: 18:25:55.934923	Training Loss1 13.9439 (14.1710)	Training Total_Loss 13.9439 (14.1710)	Training Prec@1 95.312 (95.120)	Training Prec@5 98.047 (97.567)	
2022-07-24 17:31:16,800: ============================================================
2022-07-24 17:31:57,607: time cost, forward:0.12451791732032527, backward:0.09708212981323353, data cost:0.1860842086737577 
2022-07-24 17:31:57,608: ============================================================
2022-07-24 17:31:57,608: Epoch 4/25 Batch 6100/7662 eta: 18:24:59.001268	Training Loss1 13.9418 (14.1660)	Training Total_Loss 13.9418 (14.1660)	Training Prec@1 95.898 (95.126)	Training Prec@5 97.852 (97.571)	
2022-07-24 17:31:57,608: ============================================================
2022-07-24 17:32:38,467: time cost, forward:0.12452386367472934, backward:0.09708563761088825, data cost:0.1860785607003958 
2022-07-24 17:32:38,467: ============================================================
2022-07-24 17:32:38,467: Epoch 4/25 Batch 6200/7662 eta: 18:25:41.236345	Training Loss1 13.9686 (14.1598)	Training Total_Loss 13.9686 (14.1598)	Training Prec@1 94.336 (95.130)	Training Prec@5 98.633 (97.575)	
2022-07-24 17:32:38,467: ============================================================
2022-07-24 17:33:19,290: time cost, forward:0.12452296870798323, backward:0.09709058967653315, data cost:0.1860724183600523 
2022-07-24 17:33:19,290: ============================================================
2022-07-24 17:33:19,290: Epoch 4/25 Batch 6300/7662 eta: 18:24:01.640887	Training Loss1 14.0938 (14.1535)	Training Total_Loss 14.0938 (14.1535)	Training Prec@1 94.922 (95.136)	Training Prec@5 98.242 (97.580)	
2022-07-24 17:33:19,290: ============================================================
2022-07-24 17:34:00,146: time cost, forward:0.12452496903299223, backward:0.09709401025606666, data cost:0.1860682714691496 
2022-07-24 17:34:00,146: ============================================================
2022-07-24 17:34:00,146: Epoch 4/25 Batch 6400/7662 eta: 18:24:13.927785	Training Loss1 14.2738 (14.1472)	Training Total_Loss 14.2738 (14.1472)	Training Prec@1 95.117 (95.141)	Training Prec@5 97.070 (97.583)	
2022-07-24 17:34:00,146: ============================================================
2022-07-24 17:34:40,955: time cost, forward:0.12452782310143051, backward:0.09709357918180087, data cost:0.18606178289854558 
2022-07-24 17:34:40,956: ============================================================
2022-07-24 17:34:40,956: Epoch 4/25 Batch 6500/7662 eta: 18:22:17.955939	Training Loss1 13.7659 (14.1405)	Training Total_Loss 13.7659 (14.1405)	Training Prec@1 95.508 (95.146)	Training Prec@5 98.242 (97.586)	
2022-07-24 17:34:40,956: ============================================================
2022-07-24 17:35:21,754: time cost, forward:0.12453042414896885, backward:0.09709313505074169, data cost:0.1860541852247825 
2022-07-24 17:35:21,754: ============================================================
2022-07-24 17:35:21,755: Epoch 4/25 Batch 6600/7662 eta: 18:21:19.968711	Training Loss1 14.4398 (14.1342)	Training Total_Loss 14.4398 (14.1342)	Training Prec@1 96.094 (95.154)	Training Prec@5 98.047 (97.590)	
2022-07-24 17:35:21,755: ============================================================
2022-07-24 17:36:02,534: time cost, forward:0.12453059357197396, backward:0.09709344669711609, data cost:0.18604607211242666 
2022-07-24 17:36:02,534: ============================================================
2022-07-24 17:36:02,534: Epoch 4/25 Batch 6700/7662 eta: 18:20:08.190753	Training Loss1 13.3717 (14.1283)	Training Total_Loss 13.3717 (14.1283)	Training Prec@1 95.703 (95.158)	Training Prec@5 97.656 (97.593)	
2022-07-24 17:36:02,534: ============================================================
2022-07-24 17:36:43,382: time cost, forward:0.12453939697640418, backward:0.09709514861843975, data cost:0.18603795425806663 
2022-07-24 17:36:43,383: ============================================================
2022-07-24 17:36:43,383: Epoch 4/25 Batch 6800/7662 eta: 18:21:18.255548	Training Loss1 13.6851 (14.1214)	Training Total_Loss 13.6851 (14.1214)	Training Prec@1 97.070 (95.165)	Training Prec@5 98.828 (97.597)	
2022-07-24 17:36:43,383: ============================================================
2022-07-24 17:37:24,170: time cost, forward:0.12453866758317529, backward:0.0970943613075868, data cost:0.18603330284706976 
2022-07-24 17:37:24,170: ============================================================
2022-07-24 17:37:24,171: Epoch 4/25 Batch 6900/7662 eta: 18:18:59.797032	Training Loss1 14.6055 (14.1159)	Training Total_Loss 14.6055 (14.1159)	Training Prec@1 94.727 (95.170)	Training Prec@5 96.875 (97.600)	
2022-07-24 17:37:24,171: ============================================================
2022-07-24 17:38:04,993: time cost, forward:0.1245464701910737, backward:0.0970912653474335, data cost:0.1860273331637927 
2022-07-24 17:38:04,993: ============================================================
2022-07-24 17:38:04,993: Epoch 4/25 Batch 7000/7662 eta: 18:19:14.828967	Training Loss1 14.1903 (14.1089)	Training Total_Loss 14.1903 (14.1089)	Training Prec@1 94.531 (95.175)	Training Prec@5 97.852 (97.602)	
2022-07-24 17:38:04,993: ============================================================
2022-07-24 17:38:45,777: time cost, forward:0.12454957806874302, backward:0.09708716889840983, data cost:0.18602130597436037 
2022-07-24 17:38:45,778: ============================================================
2022-07-24 17:38:45,778: Epoch 4/25 Batch 7100/7662 eta: 18:17:32.949892	Training Loss1 14.3857 (14.1035)	Training Total_Loss 14.3857 (14.1035)	Training Prec@1 94.922 (95.180)	Training Prec@5 97.656 (97.604)	
2022-07-24 17:38:45,778: ============================================================
2022-07-24 17:39:26,586: time cost, forward:0.12455486386894335, backward:0.0970850678711637, data cost:0.18601494024885845 
2022-07-24 17:39:26,586: ============================================================
2022-07-24 17:39:26,586: Epoch 4/25 Batch 7200/7662 eta: 18:17:30.235995	Training Loss1 14.4464 (14.0976)	Training Total_Loss 14.4464 (14.0976)	Training Prec@1 93.945 (95.184)	Training Prec@5 97.461 (97.606)	
2022-07-24 17:39:26,586: ============================================================
2022-07-24 17:40:07,369: time cost, forward:0.12455670006194496, backward:0.09708209167785686, data cost:0.18600953492518565 
2022-07-24 17:40:07,370: ============================================================
2022-07-24 17:40:07,370: Epoch 4/25 Batch 7300/7662 eta: 18:16:09.787649	Training Loss1 13.3914 (14.0917)	Training Total_Loss 13.3914 (14.0917)	Training Prec@1 94.922 (95.190)	Training Prec@5 97.852 (97.608)	
2022-07-24 17:40:07,370: ============================================================
2022-07-24 17:40:48,142: time cost, forward:0.12455550837088218, backward:0.09708164772289414, data cost:0.1860032294276341 
2022-07-24 17:40:48,143: ============================================================
2022-07-24 17:40:48,143: Epoch 4/25 Batch 7400/7662 eta: 18:15:11.819670	Training Loss1 13.8987 (14.0861)	Training Total_Loss 13.8987 (14.0861)	Training Prec@1 97.070 (95.195)	Training Prec@5 98.047 (97.611)	
2022-07-24 17:40:48,143: ============================================================
2022-07-24 17:41:28,895: time cost, forward:0.12455582230834106, backward:0.09707921211648614, data cost:0.1859950795461693 
2022-07-24 17:41:28,895: ============================================================
2022-07-24 17:41:28,895: Epoch 4/25 Batch 7500/7662 eta: 18:13:58.444307	Training Loss1 13.5512 (14.0798)	Training Total_Loss 13.5512 (14.0798)	Training Prec@1 95.508 (95.201)	Training Prec@5 97.852 (97.614)	
2022-07-24 17:41:28,896: ============================================================
2022-07-24 17:42:09,646: time cost, forward:0.12455224052732407, backward:0.09708061665669132, data cost:0.185987257835096 
2022-07-24 17:42:09,646: ============================================================
2022-07-24 17:42:09,647: Epoch 4/25 Batch 7600/7662 eta: 18:13:15.007833	Training Loss1 13.4368 (14.0733)	Training Total_Loss 13.4368 (14.0733)	Training Prec@1 96.289 (95.207)	Training Prec@5 98.828 (97.617)	
2022-07-24 17:42:09,647: ============================================================
2022-07-24 17:42:36,124: Epoch 4/25 Batch 7663/7662 eta: 18:12:49.334640	Training Loss1 13.7847 (14.0701)	Training Total_Loss 13.7847 (14.0701)	Training Prec@1 94.922 (95.209)	Training Prec@5 98.438 (97.618)	
2022-07-24 17:42:36,124: ============================================================
2022-07-24 17:43:17,724: time cost, forward:0.12410724042641996, backward:0.09705654298416291, data cost:0.1964332286757652 
2022-07-24 17:43:17,724: ============================================================
2022-07-24 17:43:17,724: Epoch 5/25 Batch 100/7662 eta: 18:34:49.527363	Training Loss1 11.8099 (12.3118)	Training Total_Loss 11.8099 (12.3118)	Training Prec@1 97.266 (96.871)	Training Prec@5 98.438 (98.552)	
2022-07-24 17:43:17,724: ============================================================
2022-07-24 17:43:58,464: time cost, forward:0.12419694512333702, backward:0.09702300426348968, data cost:0.19090937489840254 
2022-07-24 17:43:58,464: ============================================================
2022-07-24 17:43:58,464: Epoch 5/25 Batch 200/7662 eta: 18:11:10.814863	Training Loss1 13.5723 (12.3679)	Training Total_Loss 13.5723 (12.3679)	Training Prec@1 96.289 (96.771)	Training Prec@5 97.852 (98.479)	
2022-07-24 17:43:58,465: ============================================================
2022-07-24 17:44:39,211: time cost, forward:0.12427599693221791, backward:0.0970257006361333, data cost:0.1890432786782051 
2022-07-24 17:44:39,212: ============================================================
2022-07-24 17:44:39,212: Epoch 5/25 Batch 300/7662 eta: 18:10:41.481035	Training Loss1 12.1855 (12.4238)	Training Total_Loss 12.1855 (12.4238)	Training Prec@1 96.484 (96.769)	Training Prec@5 97.656 (98.485)	
2022-07-24 17:44:39,212: ============================================================
2022-07-24 17:45:19,944: time cost, forward:0.12428670479241469, backward:0.09702352593118385, data cost:0.18811028404044627 
2022-07-24 17:45:19,945: ============================================================
2022-07-24 17:45:19,945: Epoch 5/25 Batch 400/7662 eta: 18:09:37.753256	Training Loss1 13.2104 (12.4701)	Training Total_Loss 13.2104 (12.4701)	Training Prec@1 95.508 (96.749)	Training Prec@5 97.656 (98.490)	
2022-07-24 17:45:19,945: ============================================================
2022-07-24 17:46:00,671: time cost, forward:0.12427448700807377, backward:0.09701053269640478, data cost:0.18756637783470995 
2022-07-24 17:46:00,671: ============================================================
2022-07-24 17:46:00,671: Epoch 5/25 Batch 500/7662 eta: 18:08:46.239880	Training Loss1 11.8102 (12.5419)	Training Total_Loss 11.8102 (12.5419)	Training Prec@1 98.828 (96.685)	Training Prec@5 99.414 (98.448)	
2022-07-24 17:46:00,671: ============================================================
2022-07-24 17:46:41,377: time cost, forward:0.12423182091052226, backward:0.09700622423264339, data cost:0.18719860070535854 
2022-07-24 17:46:41,377: ============================================================
2022-07-24 17:46:41,378: Epoch 5/25 Batch 600/7662 eta: 18:07:33.734283	Training Loss1 11.8099 (12.5870)	Training Total_Loss 11.8099 (12.5870)	Training Prec@1 96.094 (96.670)	Training Prec@5 97.852 (98.448)	
2022-07-24 17:46:41,378: ============================================================
2022-07-24 17:47:22,074: time cost, forward:0.12420034203918195, backward:0.09700147345001264, data cost:0.18692950527043814 
2022-07-24 17:47:22,074: ============================================================
2022-07-24 17:47:22,074: Epoch 5/25 Batch 700/7662 eta: 18:06:36.818436	Training Loss1 12.8805 (12.6526)	Training Total_Loss 12.8805 (12.6526)	Training Prec@1 97.461 (96.627)	Training Prec@5 98.633 (98.431)	
2022-07-24 17:47:22,074: ============================================================
2022-07-24 17:48:02,789: time cost, forward:0.1241982756031022, backward:0.09699460412742796, data cost:0.18673140832569185 
2022-07-24 17:48:02,790: ============================================================
2022-07-24 17:48:02,790: Epoch 5/25 Batch 800/7662 eta: 18:06:27.075733	Training Loss1 12.6063 (12.6951)	Training Total_Loss 12.6063 (12.6951)	Training Prec@1 98.047 (96.603)	Training Prec@5 99.219 (98.413)	
2022-07-24 17:48:02,790: ============================================================
2022-07-24 17:48:43,525: time cost, forward:0.12421111349799609, backward:0.09699709237748974, data cost:0.18657706868529186 
2022-07-24 17:48:43,525: ============================================================
2022-07-24 17:48:43,525: Epoch 5/25 Batch 900/7662 eta: 18:06:17.688047	Training Loss1 12.3792 (12.7338)	Training Total_Loss 12.3792 (12.7338)	Training Prec@1 97.461 (96.576)	Training Prec@5 99.219 (98.402)	
2022-07-24 17:48:43,525: ============================================================
2022-07-24 17:49:24,259: time cost, forward:0.12421498164996968, backward:0.09699818536683961, data cost:0.18646076706436662 
2022-07-24 17:49:24,259: ============================================================
2022-07-24 17:49:24,260: Epoch 5/25 Batch 1000/7662 eta: 18:05:35.694287	Training Loss1 12.6741 (12.7704)	Training Total_Loss 12.6741 (12.7704)	Training Prec@1 95.508 (96.549)	Training Prec@5 97.656 (98.378)	
2022-07-24 17:49:24,260: ============================================================
2022-07-24 17:50:05,006: time cost, forward:0.12422409092327809, backward:0.09700015678093366, data cost:0.18637088323528925 
2022-07-24 17:50:05,006: ============================================================
2022-07-24 17:50:05,007: Epoch 5/25 Batch 1100/7662 eta: 18:05:14.974858	Training Loss1 12.9164 (12.7981)	Training Total_Loss 12.9164 (12.7981)	Training Prec@1 94.531 (96.524)	Training Prec@5 97.266 (98.360)	
2022-07-24 17:50:05,007: ============================================================
2022-07-24 17:50:45,726: time cost, forward:0.12422816170763233, backward:0.09699600234043608, data cost:0.18628227959283697 
2022-07-24 17:50:45,726: ============================================================
2022-07-24 17:50:45,726: Epoch 5/25 Batch 1200/7662 eta: 18:03:50.439862	Training Loss1 12.7478 (12.8239)	Training Total_Loss 12.7478 (12.8239)	Training Prec@1 95.508 (96.496)	Training Prec@5 97.266 (98.345)	
2022-07-24 17:50:45,726: ============================================================
2022-07-24 17:51:26,468: time cost, forward:0.124247866286233, backward:0.09699412526489681, data cost:0.18620497323257176 
2022-07-24 17:51:26,468: ============================================================
2022-07-24 17:51:26,468: Epoch 5/25 Batch 1300/7662 eta: 18:03:45.662190	Training Loss1 13.5302 (12.8540)	Training Total_Loss 13.5302 (12.8540)	Training Prec@1 96.875 (96.468)	Training Prec@5 98.633 (98.329)	
2022-07-24 17:51:26,468: ============================================================
2022-07-24 17:52:07,201: time cost, forward:0.12425097778407568, backward:0.09699534994947476, data cost:0.18614574429646316 
2022-07-24 17:52:07,201: ============================================================
2022-07-24 17:52:07,201: Epoch 5/25 Batch 1400/7662 eta: 18:02:49.628809	Training Loss1 13.5830 (12.8790)	Training Total_Loss 13.5830 (12.8790)	Training Prec@1 96.094 (96.450)	Training Prec@5 98.633 (98.319)	
2022-07-24 17:52:07,201: ============================================================
2022-07-24 17:52:47,934: time cost, forward:0.12424714872246985, backward:0.09700273560873264, data cost:0.1860931636970627 
2022-07-24 17:52:47,934: ============================================================
2022-07-24 17:52:47,935: Epoch 5/25 Batch 1500/7662 eta: 18:02:10.646759	Training Loss1 13.9324 (12.8987)	Training Total_Loss 13.9324 (12.8987)	Training Prec@1 95.703 (96.430)	Training Prec@5 97.852 (98.309)	
2022-07-24 17:52:47,935: ============================================================
2022-07-24 17:53:28,686: time cost, forward:0.1242531437363902, backward:0.09699744414806068, data cost:0.1860622512764898 
2022-07-24 17:53:28,687: ============================================================
2022-07-24 17:53:28,687: Epoch 5/25 Batch 1600/7662 eta: 18:01:59.656257	Training Loss1 13.0433 (12.9178)	Training Total_Loss 13.0433 (12.9178)	Training Prec@1 96.875 (96.409)	Training Prec@5 98.828 (98.297)	
2022-07-24 17:53:28,687: ============================================================
2022-07-24 17:54:09,460: time cost, forward:0.12426669138750657, backward:0.0969982677659545, data cost:0.18603234083390083 
2022-07-24 17:54:09,460: ============================================================
2022-07-24 17:54:09,460: Epoch 5/25 Batch 1700/7662 eta: 18:01:52.540258	Training Loss1 13.3920 (12.9382)	Training Total_Loss 13.3920 (12.9382)	Training Prec@1 97.070 (96.393)	Training Prec@5 98.438 (98.284)	
2022-07-24 17:54:09,460: ============================================================
2022-07-24 17:54:50,210: time cost, forward:0.12426449312906653, backward:0.09700305359836682, data cost:0.18600283920135413 
2022-07-24 17:54:50,210: ============================================================
2022-07-24 17:54:50,210: Epoch 5/25 Batch 1800/7662 eta: 18:00:34.555953	Training Loss1 12.7451 (12.9540)	Training Total_Loss 12.7451 (12.9540)	Training Prec@1 97.461 (96.373)	Training Prec@5 98.633 (98.278)	
2022-07-24 17:54:50,210: ============================================================
2022-07-24 17:55:30,958: time cost, forward:0.12426396242375748, backward:0.09700437782311704, data cost:0.1859778371090761 
2022-07-24 17:55:30,958: ============================================================
2022-07-24 17:55:30,958: Epoch 5/25 Batch 1900/7662 eta: 17:59:49.939913	Training Loss1 13.0373 (12.9673)	Training Total_Loss 13.0373 (12.9673)	Training Prec@1 97.266 (96.361)	Training Prec@5 99.023 (98.271)	
2022-07-24 17:55:30,958: ============================================================
2022-07-24 17:56:11,729: time cost, forward:0.12426672308608375, backward:0.09700920964670873, data cost:0.18596101117289143 
2022-07-24 17:56:11,729: ============================================================
2022-07-24 17:56:11,729: Epoch 5/25 Batch 2000/7662 eta: 17:59:46.427984	Training Loss1 13.1401 (12.9790)	Training Total_Loss 13.1401 (12.9790)	Training Prec@1 95.898 (96.347)	Training Prec@5 97.852 (98.271)	
2022-07-24 17:56:11,729: ============================================================
2022-07-24 17:56:52,505: time cost, forward:0.1242708865661403, backward:0.09701361060994418, data cost:0.1859461411571094 
2022-07-24 17:56:52,505: ============================================================
2022-07-24 17:56:52,506: Epoch 5/25 Batch 2100/7662 eta: 17:59:14.423023	Training Loss1 13.0602 (12.9896)	Training Total_Loss 13.0602 (12.9896)	Training Prec@1 96.289 (96.329)	Training Prec@5 98.047 (98.262)	
2022-07-24 17:56:52,506: ============================================================
2022-07-24 17:57:33,316: time cost, forward:0.12429043952851689, backward:0.09701824003916103, data cost:0.18593160517381613 
2022-07-24 17:57:33,316: ============================================================
2022-07-24 17:57:33,317: Epoch 5/25 Batch 2200/7662 eta: 17:59:28.214151	Training Loss1 13.2848 (13.0001)	Training Total_Loss 13.2848 (13.0001)	Training Prec@1 96.484 (96.314)	Training Prec@5 97.852 (98.250)	
2022-07-24 17:57:33,317: ============================================================
2022-07-24 17:58:14,112: time cost, forward:0.12430026096694104, backward:0.09701964937121312, data cost:0.18592325092762021 
2022-07-24 17:58:14,113: ============================================================
2022-07-24 17:58:14,113: Epoch 5/25 Batch 2300/7662 eta: 17:58:24.019833	Training Loss1 13.5646 (13.0129)	Training Total_Loss 13.5646 (13.0129)	Training Prec@1 94.141 (96.300)	Training Prec@5 96.094 (98.242)	
2022-07-24 17:58:14,113: ============================================================
2022-07-24 17:58:54,914: time cost, forward:0.12431151551870367, backward:0.09702395160479464, data cost:0.18591283112081103 
2022-07-24 17:58:54,915: ============================================================
2022-07-24 17:58:54,915: Epoch 5/25 Batch 2400/7662 eta: 17:57:52.414917	Training Loss1 13.4490 (13.0214)	Training Total_Loss 13.4490 (13.0214)	Training Prec@1 97.070 (96.290)	Training Prec@5 98.633 (98.234)	
2022-07-24 17:58:54,915: ============================================================
2022-07-24 17:59:35,717: time cost, forward:0.12432475364794966, backward:0.09702607401374246, data cost:0.18590202976484782 
2022-07-24 17:59:35,717: ============================================================
2022-07-24 17:59:35,717: Epoch 5/25 Batch 2500/7662 eta: 17:57:12.229626	Training Loss1 13.5514 (13.0346)	Training Total_Loss 13.5514 (13.0346)	Training Prec@1 95.117 (96.275)	Training Prec@5 98.438 (98.225)	
2022-07-24 17:59:35,717: ============================================================
2022-07-24 18:00:16,528: time cost, forward:0.12433751531177505, backward:0.09702678834901217, data cost:0.18589640792033543 
2022-07-24 18:00:16,529: ============================================================
2022-07-24 18:00:16,529: Epoch 5/25 Batch 2600/7662 eta: 17:56:46.068246	Training Loss1 13.2976 (13.0415)	Training Total_Loss 13.2976 (13.0415)	Training Prec@1 95.898 (96.266)	Training Prec@5 98.438 (98.218)	
2022-07-24 18:00:16,529: ============================================================
2022-07-24 18:00:57,323: time cost, forward:0.12434134319032639, backward:0.09703127089673919, data cost:0.18588909920872296 
2022-07-24 18:00:57,323: ============================================================
2022-07-24 18:00:57,324: Epoch 5/25 Batch 2700/7662 eta: 17:55:38.445884	Training Loss1 12.8079 (13.0463)	Training Total_Loss 12.8079 (13.0463)	Training Prec@1 96.680 (96.256)	Training Prec@5 98.047 (98.214)	
2022-07-24 18:00:57,324: ============================================================
2022-07-24 18:01:38,135: time cost, forward:0.12435584180735826, backward:0.09702980599261983, data cost:0.18588340014123456 
2022-07-24 18:01:38,135: ============================================================
2022-07-24 18:01:38,135: Epoch 5/25 Batch 2800/7662 eta: 17:55:24.087221	Training Loss1 13.2668 (13.0542)	Training Total_Loss 13.2668 (13.0542)	Training Prec@1 95.898 (96.246)	Training Prec@5 97.070 (98.208)	
2022-07-24 18:01:38,135: ============================================================
2022-07-24 18:02:18,933: time cost, forward:0.12436314910475489, backward:0.09703256443230272, data cost:0.18587507063374514 
2022-07-24 18:02:18,934: ============================================================
2022-07-24 18:02:18,934: Epoch 5/25 Batch 2900/7662 eta: 17:54:23.286136	Training Loss1 13.5688 (13.0616)	Training Total_Loss 13.5688 (13.0616)	Training Prec@1 95.117 (96.242)	Training Prec@5 97.656 (98.205)	
2022-07-24 18:02:18,934: ============================================================
2022-07-24 18:02:59,727: time cost, forward:0.12436890872409638, backward:0.09703483952009984, data cost:0.18586775794670002 
2022-07-24 18:02:59,727: ============================================================
2022-07-24 18:02:59,727: Epoch 5/25 Batch 3000/7662 eta: 17:53:34.393632	Training Loss1 12.4840 (13.0671)	Training Total_Loss 12.4840 (13.0671)	Training Prec@1 97.070 (96.230)	Training Prec@5 98.438 (98.197)	
2022-07-24 18:02:59,728: ============================================================
2022-07-24 18:03:40,499: time cost, forward:0.12437139483719882, backward:0.09703668397101482, data cost:0.18585639740044396 
2022-07-24 18:03:40,499: ============================================================
2022-07-24 18:03:40,500: Epoch 5/25 Batch 3100/7662 eta: 17:52:19.738758	Training Loss1 12.6780 (13.0739)	Training Total_Loss 12.6780 (13.0739)	Training Prec@1 97.070 (96.221)	Training Prec@5 98.633 (98.191)	
2022-07-24 18:03:40,500: ============================================================
2022-07-24 18:04:21,282: time cost, forward:0.12437329049332509, backward:0.09703753105585707, data cost:0.18585001829826447 
2022-07-24 18:04:21,283: ============================================================
2022-07-24 18:04:21,283: Epoch 5/25 Batch 3200/7662 eta: 17:51:56.572452	Training Loss1 13.3732 (13.0792)	Training Total_Loss 13.3732 (13.0792)	Training Prec@1 95.312 (96.219)	Training Prec@5 97.070 (98.190)	
2022-07-24 18:04:21,283: ============================================================
2022-07-24 18:05:02,090: time cost, forward:0.12439002850518945, backward:0.09703167347013318, data cost:0.18584398639386407 
2022-07-24 18:05:02,091: ============================================================
2022-07-24 18:05:02,091: Epoch 5/25 Batch 3300/7662 eta: 17:51:54.611712	Training Loss1 13.0563 (13.0837)	Training Total_Loss 13.0563 (13.0837)	Training Prec@1 96.680 (96.213)	Training Prec@5 98.047 (98.188)	
2022-07-24 18:05:02,091: ============================================================
2022-07-24 18:05:42,900: time cost, forward:0.12440844780208433, backward:0.09702667743888242, data cost:0.1858352188784854 
2022-07-24 18:05:42,900: ============================================================
2022-07-24 18:05:42,901: Epoch 5/25 Batch 3400/7662 eta: 17:51:16.225430	Training Loss1 13.1572 (13.0873)	Training Total_Loss 13.1572 (13.0873)	Training Prec@1 96.680 (96.204)	Training Prec@5 98.633 (98.184)	
2022-07-24 18:05:42,901: ============================================================
2022-07-24 18:06:23,709: time cost, forward:0.12442363483901023, backward:0.09702251740406839, data cost:0.185828550163764 
2022-07-24 18:06:23,709: ============================================================
2022-07-24 18:06:23,709: Epoch 5/25 Batch 3500/7662 eta: 17:50:33.881769	Training Loss1 13.8054 (13.0893)	Training Total_Loss 13.8054 (13.0893)	Training Prec@1 96.484 (96.197)	Training Prec@5 97.852 (98.181)	
2022-07-24 18:06:23,709: ============================================================
2022-07-24 18:07:04,471: time cost, forward:0.12443017634990382, backward:0.09702019215822551, data cost:0.1858156867476429 
2022-07-24 18:07:04,471: ============================================================
2022-07-24 18:07:04,471: Epoch 5/25 Batch 3600/7662 eta: 17:48:40.312166	Training Loss1 13.6327 (13.0915)	Training Total_Loss 13.6327 (13.0915)	Training Prec@1 93.750 (96.193)	Training Prec@5 97.266 (98.179)	
2022-07-24 18:07:04,471: ============================================================
2022-07-24 18:07:45,200: time cost, forward:0.12442498459755391, backward:0.09701880534683315, data cost:0.185804296293978 
2022-07-24 18:07:45,200: ============================================================
2022-07-24 18:07:45,200: Epoch 5/25 Batch 3700/7662 eta: 17:47:07.172159	Training Loss1 12.5166 (13.0949)	Training Total_Loss 12.5166 (13.0949)	Training Prec@1 97.070 (96.190)	Training Prec@5 97.852 (98.178)	
2022-07-24 18:07:45,200: ============================================================
2022-07-24 18:08:25,940: time cost, forward:0.1244230443598503, backward:0.09701783018822606, data cost:0.18579271405142964 
2022-07-24 18:08:25,940: ============================================================
2022-07-24 18:08:25,940: Epoch 5/25 Batch 3800/7662 eta: 17:46:43.507138	Training Loss1 13.2019 (13.0967)	Training Total_Loss 13.2019 (13.0967)	Training Prec@1 95.508 (96.185)	Training Prec@5 98.633 (98.176)	
2022-07-24 18:08:25,940: ============================================================
2022-07-24 18:09:06,693: time cost, forward:0.12442595819902286, backward:0.09701587457356009, data cost:0.18578219603318133 
2022-07-24 18:09:06,693: ============================================================
2022-07-24 18:09:06,693: Epoch 5/25 Batch 3900/7662 eta: 17:46:23.260059	Training Loss1 12.5068 (13.0993)	Training Total_Loss 12.5068 (13.0993)	Training Prec@1 97.461 (96.183)	Training Prec@5 99.023 (98.174)	
2022-07-24 18:09:06,693: ============================================================
2022-07-24 18:09:47,454: time cost, forward:0.12443137455058116, backward:0.09701449533020386, data cost:0.1857710084369046 
2022-07-24 18:09:47,454: ============================================================
2022-07-24 18:09:47,454: Epoch 5/25 Batch 4000/7662 eta: 17:45:55.878122	Training Loss1 12.8238 (13.1003)	Training Total_Loss 12.8238 (13.1003)	Training Prec@1 96.094 (96.182)	Training Prec@5 98.828 (98.174)	
2022-07-24 18:09:47,455: ============================================================
2022-07-24 18:10:28,198: time cost, forward:0.12443252690509053, backward:0.0970136420149197, data cost:0.18575993471827323 
2022-07-24 18:10:28,198: ============================================================
2022-07-24 18:10:28,198: Epoch 5/25 Batch 4100/7662 eta: 17:44:47.551439	Training Loss1 13.3117 (13.1001)	Training Total_Loss 13.3117 (13.1001)	Training Prec@1 96.289 (96.179)	Training Prec@5 98.242 (98.172)	
2022-07-24 18:10:28,198: ============================================================
2022-07-24 18:11:08,926: time cost, forward:0.12442987962801362, backward:0.09701233019173557, data cost:0.18574927426088592 
2022-07-24 18:11:08,926: ============================================================
2022-07-24 18:11:08,927: Epoch 5/25 Batch 4200/7662 eta: 17:43:42.312676	Training Loss1 13.2457 (13.1011)	Training Total_Loss 13.2457 (13.1011)	Training Prec@1 96.875 (96.178)	Training Prec@5 98.633 (98.171)	
2022-07-24 18:11:08,927: ============================================================
2022-07-24 18:11:49,655: time cost, forward:0.12442793721902035, backward:0.09701332948351495, data cost:0.1857370996397577 
2022-07-24 18:11:49,655: ============================================================
2022-07-24 18:11:49,655: Epoch 5/25 Batch 4300/7662 eta: 17:43:02.668370	Training Loss1 13.0409 (13.0999)	Training Total_Loss 13.0409 (13.0999)	Training Prec@1 97.266 (96.179)	Training Prec@5 98.633 (98.172)	
2022-07-24 18:11:49,656: ============================================================
2022-07-24 18:12:30,371: time cost, forward:0.12442325938693717, backward:0.09701235789173054, data cost:0.18572669057418986 
2022-07-24 18:12:30,371: ============================================================
2022-07-24 18:12:30,372: Epoch 5/25 Batch 4400/7662 eta: 17:42:01.982500	Training Loss1 13.5375 (13.1011)	Training Total_Loss 13.5375 (13.1011)	Training Prec@1 95.703 (96.179)	Training Prec@5 98.047 (98.169)	
2022-07-24 18:12:30,372: ============================================================
2022-07-24 18:13:11,035: time cost, forward:0.12441703477788697, backward:0.09700775962587091, data cost:0.1857115347985825 
2022-07-24 18:13:11,036: ============================================================
2022-07-24 18:13:11,036: Epoch 5/25 Batch 4500/7662 eta: 17:40:00.120191	Training Loss1 12.9139 (13.1009)	Training Total_Loss 12.9139 (13.1009)	Training Prec@1 96.094 (96.175)	Training Prec@5 98.828 (98.167)	
2022-07-24 18:13:11,036: ============================================================
2022-07-24 18:13:51,718: time cost, forward:0.12441223474864624, backward:0.09700364293054696, data cost:0.1857000988290268 
2022-07-24 18:13:51,719: ============================================================
2022-07-24 18:13:51,719: Epoch 5/25 Batch 4600/7662 eta: 17:39:48.805525	Training Loss1 12.0379 (13.1006)	Training Total_Loss 12.0379 (13.1006)	Training Prec@1 96.680 (96.173)	Training Prec@5 97.852 (98.165)	
2022-07-24 18:13:51,719: ============================================================
2022-07-24 18:14:32,436: time cost, forward:0.12440546976046046, backward:0.09700640786782455, data cost:0.18569169543758052 
2022-07-24 18:14:32,437: ============================================================
2022-07-24 18:14:32,437: Epoch 5/25 Batch 4700/7662 eta: 17:40:02.482333	Training Loss1 13.5717 (13.1007)	Training Total_Loss 13.5717 (13.1007)	Training Prec@1 95.312 (96.172)	Training Prec@5 97.852 (98.163)	
2022-07-24 18:14:32,437: ============================================================
2022-07-24 18:15:13,190: time cost, forward:0.12440979761440422, backward:0.09700465505384957, data cost:0.18568450029901376 
2022-07-24 18:15:13,191: ============================================================
2022-07-24 18:15:13,191: Epoch 5/25 Batch 4800/7662 eta: 17:40:18.251897	Training Loss1 14.0111 (13.0998)	Training Total_Loss 14.0111 (13.0998)	Training Prec@1 95.508 (96.169)	Training Prec@5 98.438 (98.163)	
2022-07-24 18:15:13,191: ============================================================
2022-07-24 18:15:53,940: time cost, forward:0.12441165327028149, backward:0.09700447876956128, data cost:0.18567763189559908 
2022-07-24 18:15:53,940: ============================================================
2022-07-24 18:15:53,940: Epoch 5/25 Batch 4900/7662 eta: 17:39:30.246529	Training Loss1 12.5324 (13.0974)	Training Total_Loss 12.5324 (13.0974)	Training Prec@1 96.094 (96.170)	Training Prec@5 97.461 (98.163)	
2022-07-24 18:15:53,940: ============================================================
2022-07-24 18:16:34,681: time cost, forward:0.12440998298116959, backward:0.09700391149015325, data cost:0.18567268446365054 
2022-07-24 18:16:34,681: ============================================================
2022-07-24 18:16:34,682: Epoch 5/25 Batch 5000/7662 eta: 17:38:37.229140	Training Loss1 12.7004 (13.0978)	Training Total_Loss 12.7004 (13.0978)	Training Prec@1 96.289 (96.169)	Training Prec@5 97.656 (98.162)	
2022-07-24 18:16:34,682: ============================================================
2022-07-24 18:17:15,404: time cost, forward:0.12440439172061338, backward:0.09700563688515729, data cost:0.18566616733159755 
2022-07-24 18:17:15,405: ============================================================
2022-07-24 18:17:15,405: Epoch 5/25 Batch 5100/7662 eta: 17:37:27.725602	Training Loss1 12.9805 (13.0970)	Training Total_Loss 12.9805 (13.0970)	Training Prec@1 95.703 (96.168)	Training Prec@5 98.242 (98.162)	
2022-07-24 18:17:15,405: ============================================================
2022-07-24 18:17:56,101: time cost, forward:0.12439918054895095, backward:0.09700329153784011, data cost:0.18565884492195073 
2022-07-24 18:17:56,101: ============================================================
2022-07-24 18:17:56,101: Epoch 5/25 Batch 5200/7662 eta: 17:36:05.882349	Training Loss1 13.1524 (13.0952)	Training Total_Loss 13.1524 (13.0952)	Training Prec@1 97.656 (96.168)	Training Prec@5 99.219 (98.164)	
2022-07-24 18:17:56,101: ============================================================
2022-07-24 18:18:36,824: time cost, forward:0.12439702267600897, backward:0.09700180260859294, data cost:0.1856528961741715 
2022-07-24 18:18:36,824: ============================================================
2022-07-24 18:18:36,824: Epoch 5/25 Batch 5300/7662 eta: 17:36:06.062857	Training Loss1 13.4004 (13.0938)	Training Total_Loss 13.4004 (13.0938)	Training Prec@1 96.680 (96.166)	Training Prec@5 98.242 (98.164)	
2022-07-24 18:18:36,824: ============================================================
2022-07-24 18:19:17,524: time cost, forward:0.12439224900614665, backward:0.09699978998886874, data cost:0.1856467482292513 
2022-07-24 18:19:17,524: ============================================================
2022-07-24 18:19:17,525: Epoch 5/25 Batch 5400/7662 eta: 17:34:50.148547	Training Loss1 12.6885 (13.0947)	Training Total_Loss 12.6885 (13.0947)	Training Prec@1 96.289 (96.166)	Training Prec@5 98.828 (98.164)	
2022-07-24 18:19:17,525: ============================================================
2022-07-24 18:19:58,267: time cost, forward:0.12439329005475694, backward:0.09699969426959965, data cost:0.18564074029487185 
2022-07-24 18:19:58,268: ============================================================
2022-07-24 18:19:58,268: Epoch 5/25 Batch 5500/7662 eta: 17:35:16.603141	Training Loss1 12.8548 (13.0935)	Training Total_Loss 12.8548 (13.0935)	Training Prec@1 95.898 (96.164)	Training Prec@5 97.266 (98.163)	
2022-07-24 18:19:58,268: ============================================================
2022-07-24 18:20:38,990: time cost, forward:0.12439219737440417, backward:0.09699999645237924, data cost:0.18563312772215 
2022-07-24 18:20:38,990: ============================================================
2022-07-24 18:20:38,990: Epoch 5/25 Batch 5600/7662 eta: 17:34:03.035851	Training Loss1 13.5970 (13.0927)	Training Total_Loss 13.5970 (13.0927)	Training Prec@1 94.727 (96.162)	Training Prec@5 99.219 (98.162)	
2022-07-24 18:20:38,990: ============================================================
2022-07-24 18:21:19,689: time cost, forward:0.1243873150395937, backward:0.09699780624317357, data cost:0.18562821288509607 
2022-07-24 18:21:19,689: ============================================================
2022-07-24 18:21:19,689: Epoch 5/25 Batch 5700/7662 eta: 17:32:46.130212	Training Loss1 12.6214 (13.0913)	Training Total_Loss 12.6214 (13.0913)	Training Prec@1 97.266 (96.160)	Training Prec@5 98.633 (98.162)	
2022-07-24 18:21:19,689: ============================================================
2022-07-24 18:22:00,443: time cost, forward:0.12439288639121887, backward:0.0969957474039061, data cost:0.18562288012128797 
2022-07-24 18:22:00,444: ============================================================
2022-07-24 18:22:00,444: Epoch 5/25 Batch 5800/7662 eta: 17:33:31.140632	Training Loss1 12.6546 (13.0910)	Training Total_Loss 12.6546 (13.0910)	Training Prec@1 96.875 (96.159)	Training Prec@5 98.047 (98.163)	
2022-07-24 18:22:00,444: ============================================================
2022-07-24 18:22:41,224: time cost, forward:0.12439742632327716, backward:0.09699430011413647, data cost:0.18562207187226434 
2022-07-24 18:22:41,225: ============================================================
2022-07-24 18:22:41,225: Epoch 5/25 Batch 5900/7662 eta: 17:33:31.969877	Training Loss1 12.6559 (13.0902)	Training Total_Loss 12.6559 (13.0902)	Training Prec@1 95.508 (96.159)	Training Prec@5 97.656 (98.163)	
2022-07-24 18:22:41,225: ============================================================
2022-07-24 18:23:22,022: time cost, forward:0.12440243012151195, backward:0.09699490396633488, data cost:0.18562173883126842 
2022-07-24 18:23:22,022: ============================================================
2022-07-24 18:23:22,022: Epoch 5/25 Batch 6000/7662 eta: 17:33:16.407229	Training Loss1 14.3166 (13.0895)	Training Total_Loss 14.3166 (13.0895)	Training Prec@1 95.117 (96.161)	Training Prec@5 97.656 (98.164)	
2022-07-24 18:23:22,022: ============================================================
2022-07-24 18:24:02,803: time cost, forward:0.12440445970797034, backward:0.09699525722110246, data cost:0.18562164250348978 
2022-07-24 18:24:02,803: ============================================================
2022-07-24 18:24:02,803: Epoch 5/25 Batch 6100/7662 eta: 17:32:10.427923	Training Loss1 13.3323 (13.0880)	Training Total_Loss 13.3323 (13.0880)	Training Prec@1 96.094 (96.161)	Training Prec@5 98.438 (98.165)	
2022-07-24 18:24:02,803: ============================================================
2022-07-24 18:24:43,574: time cost, forward:0.1244032634114196, backward:0.09699699259088931, data cost:0.18562192119962073 
2022-07-24 18:24:43,574: ============================================================
2022-07-24 18:24:43,574: Epoch 5/25 Batch 6200/7662 eta: 17:31:13.892859	Training Loss1 13.0104 (13.0866)	Training Total_Loss 13.0104 (13.0866)	Training Prec@1 96.094 (96.161)	Training Prec@5 97.852 (98.165)	
2022-07-24 18:24:43,574: ============================================================
2022-07-24 18:25:24,370: time cost, forward:0.12440588391381685, backward:0.09699926589818053, data cost:0.18562121988572966 
2022-07-24 18:25:24,370: ============================================================
2022-07-24 18:25:24,370: Epoch 5/25 Batch 6300/7662 eta: 17:31:11.735203	Training Loss1 12.1363 (13.0863)	Training Total_Loss 12.1363 (13.0863)	Training Prec@1 97.656 (96.162)	Training Prec@5 99.023 (98.164)	
2022-07-24 18:25:24,370: ============================================================
2022-07-24 18:26:05,163: time cost, forward:0.12440837526865388, backward:0.09700009554210054, data cost:0.1856218556870444 
2022-07-24 18:26:05,163: ============================================================
2022-07-24 18:26:05,164: Epoch 5/25 Batch 6400/7662 eta: 17:30:26.918947	Training Loss1 12.6045 (13.0846)	Training Total_Loss 12.6045 (13.0846)	Training Prec@1 95.508 (96.162)	Training Prec@5 97.852 (98.164)	
2022-07-24 18:26:05,164: ============================================================
2022-07-24 18:26:45,994: time cost, forward:0.12441440600031137, backward:0.09700133679811543, data cost:0.18562408432004487 
2022-07-24 18:26:45,994: ============================================================
2022-07-24 18:26:45,994: Epoch 5/25 Batch 6500/7662 eta: 17:30:43.947816	Training Loss1 13.2159 (13.0833)	Training Total_Loss 13.2159 (13.0833)	Training Prec@1 96.094 (96.163)	Training Prec@5 98.438 (98.165)	
2022-07-24 18:26:45,995: ============================================================
2022-07-24 18:27:26,775: time cost, forward:0.12441515637123327, backward:0.09700165573151333, data cost:0.18562457076996308 
2022-07-24 18:27:26,775: ============================================================
2022-07-24 18:27:26,775: Epoch 5/25 Batch 6600/7662 eta: 17:28:46.386105	Training Loss1 13.1044 (13.0814)	Training Total_Loss 13.1044 (13.0814)	Training Prec@1 96.094 (96.164)	Training Prec@5 97.852 (98.165)	
2022-07-24 18:27:26,776: ============================================================
2022-07-24 18:28:07,585: time cost, forward:0.12441833376226043, backward:0.0970024582449581, data cost:0.18562642199403404 
2022-07-24 18:28:07,586: ============================================================
2022-07-24 18:28:07,586: Epoch 5/25 Batch 6700/7662 eta: 17:28:50.848626	Training Loss1 12.9962 (13.0790)	Training Total_Loss 12.9962 (13.0790)	Training Prec@1 95.898 (96.165)	Training Prec@5 98.633 (98.165)	
2022-07-24 18:28:07,586: ============================================================
2022-07-24 18:28:48,436: time cost, forward:0.12442802856872846, backward:0.09700326222429417, data cost:0.18562778361949311 
2022-07-24 18:28:48,436: ============================================================
2022-07-24 18:28:48,437: Epoch 5/25 Batch 6800/7662 eta: 17:29:12.081322	Training Loss1 12.7457 (13.0778)	Training Total_Loss 12.7457 (13.0778)	Training Prec@1 96.484 (96.164)	Training Prec@5 98.633 (98.165)	
2022-07-24 18:28:48,437: ============================================================
2022-07-24 18:29:29,270: time cost, forward:0.12443266434675715, backward:0.09700494500964876, data cost:0.18562998922342216 
2022-07-24 18:29:29,270: ============================================================
2022-07-24 18:29:29,270: Epoch 5/25 Batch 6900/7662 eta: 17:28:04.994044	Training Loss1 13.1202 (13.0759)	Training Total_Loss 13.1202 (13.0759)	Training Prec@1 95.898 (96.166)	Training Prec@5 98.438 (98.166)	
2022-07-24 18:29:29,270: ============================================================
2022-07-24 18:30:10,112: time cost, forward:0.12444082064736926, backward:0.09700513420862579, data cost:0.18563102967297287 
2022-07-24 18:30:10,113: ============================================================
2022-07-24 18:30:10,113: Epoch 5/25 Batch 7000/7662 eta: 17:27:38.027573	Training Loss1 12.1232 (13.0742)	Training Total_Loss 12.1232 (13.0742)	Training Prec@1 96.289 (96.166)	Training Prec@5 98.242 (98.166)	
2022-07-24 18:30:10,113: ============================================================
2022-07-24 18:30:50,943: time cost, forward:0.12444682956866973, backward:0.09700565859371045, data cost:0.1856324736845965 
2022-07-24 18:30:50,943: ============================================================
2022-07-24 18:30:50,943: Epoch 5/25 Batch 7100/7662 eta: 17:26:38.362862	Training Loss1 12.9827 (13.0721)	Training Total_Loss 12.9827 (13.0721)	Training Prec@1 96.875 (96.167)	Training Prec@5 99.414 (98.167)	
2022-07-24 18:30:50,943: ============================================================
2022-07-24 18:31:31,730: time cost, forward:0.12444692006424445, backward:0.09700677692600382, data cost:0.1856327851392574 
2022-07-24 18:31:31,730: ============================================================
2022-07-24 18:31:31,731: Epoch 5/25 Batch 7200/7662 eta: 17:24:51.373515	Training Loss1 13.0196 (13.0702)	Training Total_Loss 13.0196 (13.0702)	Training Prec@1 96.094 (96.169)	Training Prec@5 97.852 (98.168)	
2022-07-24 18:31:31,731: ============================================================
2022-07-24 18:32:12,505: time cost, forward:0.12444688382418552, backward:0.09700706175278762, data cost:0.18563259694817655 
2022-07-24 18:32:12,506: ============================================================
2022-07-24 18:32:12,506: Epoch 5/25 Batch 7300/7662 eta: 17:23:52.358762	Training Loss1 12.7881 (13.0687)	Training Total_Loss 12.7881 (13.0687)	Training Prec@1 96.484 (96.169)	Training Prec@5 98.047 (98.168)	
2022-07-24 18:32:12,506: ============================================================
2022-07-24 18:32:53,276: time cost, forward:0.12444599097863228, backward:0.09700803351347503, data cost:0.1856318192315079 
2022-07-24 18:32:53,276: ============================================================
2022-07-24 18:32:53,277: Epoch 5/25 Batch 7400/7662 eta: 17:23:03.901736	Training Loss1 12.3109 (13.0666)	Training Total_Loss 12.3109 (13.0666)	Training Prec@1 96.484 (96.168)	Training Prec@5 98.242 (98.168)	
2022-07-24 18:32:53,277: ============================================================
2022-07-24 18:33:34,037: time cost, forward:0.12444585370197186, backward:0.09700771261332973, data cost:0.18563041964885887 
2022-07-24 18:33:34,038: ============================================================
2022-07-24 18:33:34,038: Epoch 5/25 Batch 7500/7662 eta: 17:22:09.047663	Training Loss1 12.3957 (13.0643)	Training Total_Loss 12.3957 (13.0643)	Training Prec@1 95.117 (96.171)	Training Prec@5 96.680 (98.169)	
2022-07-24 18:33:34,038: ============================================================
2022-07-24 18:34:14,805: time cost, forward:0.12444773610131743, backward:0.09700695475962212, data cost:0.18562878484960638 
2022-07-24 18:34:14,805: ============================================================
2022-07-24 18:34:14,806: Epoch 5/25 Batch 7600/7662 eta: 17:21:38.249977	Training Loss1 12.9617 (13.0627)	Training Total_Loss 12.9617 (13.0627)	Training Prec@1 96.875 (96.171)	Training Prec@5 99.023 (98.168)	
2022-07-24 18:34:14,806: ============================================================
2022-07-24 18:34:41,587: Epoch 5/25 Batch 7663/7662 eta: 17:21:12.566267	Training Loss1 12.4325 (13.0621)	Training Total_Loss 12.4325 (13.0621)	Training Prec@1 97.656 (96.173)	Training Prec@5 98.828 (98.168)	
2022-07-24 18:34:41,587: ============================================================
2022-07-24 18:34:41,661: Save Checkpoint...
2022-07-24 18:34:41,662: ============================================================
2022-07-24 18:34:45,289: Save done!
2022-07-24 18:34:45,289: ============================================================
2022-07-24 18:35:27,554: time cost, forward:0.1240031695125079, backward:0.09677805081762449, data cost:0.20337017858871306 
2022-07-24 18:35:27,555: ============================================================
2022-07-24 18:35:27,555: Epoch 6/25 Batch 100/7662 eta: 17:58:06.877808	Training Loss1 12.0426 (11.6410)	Training Total_Loss 12.0426 (11.6410)	Training Prec@1 97.070 (97.467)	Training Prec@5 98.438 (98.868)	
2022-07-24 18:35:27,555: ============================================================
2022-07-24 18:36:08,281: time cost, forward:0.12413296507830596, backward:0.09686800223499087, data cost:0.194359487025582 
2022-07-24 18:36:08,281: ============================================================
2022-07-24 18:36:08,281: Epoch 6/25 Batch 200/7662 eta: 17:18:48.023261	Training Loss1 11.9805 (11.7124)	Training Total_Loss 11.9805 (11.7124)	Training Prec@1 96.680 (97.411)	Training Prec@5 97.852 (98.840)	
2022-07-24 18:36:08,281: ============================================================
2022-07-24 18:36:49,020: time cost, forward:0.12422262785028056, backward:0.0968853550212439, data cost:0.1913673502944385 
2022-07-24 18:36:49,021: ============================================================
2022-07-24 18:36:49,021: Epoch 6/25 Batch 300/7662 eta: 17:18:27.933692	Training Loss1 11.5167 (11.7743)	Training Total_Loss 11.5167 (11.7743)	Training Prec@1 97.266 (97.322)	Training Prec@5 99.023 (98.799)	
2022-07-24 18:36:49,021: ============================================================
2022-07-24 18:37:29,753: time cost, forward:0.12428647772710126, backward:0.09688703816636164, data cost:0.18984916156395934 
2022-07-24 18:37:29,754: ============================================================
2022-07-24 18:37:29,754: Epoch 6/25 Batch 400/7662 eta: 17:17:36.886021	Training Loss1 12.1480 (11.8440)	Training Total_Loss 12.1480 (11.8440)	Training Prec@1 96.289 (97.246)	Training Prec@5 98.438 (98.763)	
2022-07-24 18:37:29,754: ============================================================
2022-07-24 18:38:10,481: time cost, forward:0.12430600412861857, backward:0.09690350807740358, data cost:0.18893636491351232 
2022-07-24 18:38:10,482: ============================================================
2022-07-24 18:38:10,482: Epoch 6/25 Batch 500/7662 eta: 17:16:48.048105	Training Loss1 12.0531 (11.9065)	Training Total_Loss 12.0531 (11.9065)	Training Prec@1 96.875 (97.202)	Training Prec@5 98.242 (98.730)	
2022-07-24 18:38:10,482: ============================================================
2022-07-24 18:38:51,216: time cost, forward:0.12431747726287587, backward:0.0969069561297587, data cost:0.18834572522986512 
2022-07-24 18:38:51,216: ============================================================
2022-07-24 18:38:51,217: Epoch 6/25 Batch 600/7662 eta: 17:16:17.808974	Training Loss1 12.0631 (11.9614)	Training Total_Loss 12.0631 (11.9614)	Training Prec@1 97.461 (97.150)	Training Prec@5 98.438 (98.695)	
2022-07-24 18:38:51,217: ============================================================
2022-07-24 18:39:31,937: time cost, forward:0.12431853625907406, backward:0.09691278276184256, data cost:0.1879083308709708 
2022-07-24 18:39:31,937: ============================================================
2022-07-24 18:39:31,938: Epoch 6/25 Batch 700/7662 eta: 17:15:16.211815	Training Loss1 12.1227 (12.0127)	Training Total_Loss 12.1227 (12.0127)	Training Prec@1 96.875 (97.139)	Training Prec@5 98.438 (98.697)	
2022-07-24 18:39:31,938: ============================================================
2022-07-24 18:40:12,662: time cost, forward:0.12431475844639861, backward:0.09691619335933681, data cost:0.18758648865213978 
2022-07-24 18:40:12,663: ============================================================
2022-07-24 18:40:12,663: Epoch 6/25 Batch 800/7662 eta: 17:14:42.118652	Training Loss1 11.3949 (12.0615)	Training Total_Loss 11.3949 (12.0615)	Training Prec@1 97.461 (97.119)	Training Prec@5 99.414 (98.686)	
2022-07-24 18:40:12,663: ============================================================
2022-07-24 18:40:53,381: time cost, forward:0.12431142407078896, backward:0.09691232197541946, data cost:0.1873377565547277 
2022-07-24 18:40:53,382: ============================================================
2022-07-24 18:40:53,382: Epoch 6/25 Batch 900/7662 eta: 17:13:51.503122	Training Loss1 11.7788 (12.1037)	Training Total_Loss 11.7788 (12.1037)	Training Prec@1 97.461 (97.092)	Training Prec@5 99.414 (98.663)	
2022-07-24 18:40:53,382: ============================================================
2022-07-24 18:41:34,115: time cost, forward:0.1243190657985103, backward:0.0969133599026425, data cost:0.18713960776457916 
2022-07-24 18:41:34,115: ============================================================
2022-07-24 18:41:34,115: Epoch 6/25 Batch 1000/7662 eta: 17:13:32.752356	Training Loss1 11.6179 (12.1328)	Training Total_Loss 11.6179 (12.1328)	Training Prec@1 96.875 (97.077)	Training Prec@5 99.609 (98.660)	
2022-07-24 18:41:34,115: ============================================================
2022-07-24 18:42:14,862: time cost, forward:0.12432020550103921, backward:0.09691458425270198, data cost:0.18699181437817783 
2022-07-24 18:42:14,862: ============================================================
2022-07-24 18:42:14,862: Epoch 6/25 Batch 1100/7662 eta: 17:13:13.394897	Training Loss1 12.5484 (12.1718)	Training Total_Loss 12.5484 (12.1718)	Training Prec@1 96.875 (97.048)	Training Prec@5 98.633 (98.652)	
2022-07-24 18:42:14,862: ============================================================
2022-07-24 18:42:55,584: time cost, forward:0.12430913036718678, backward:0.09691772687624056, data cost:0.18685750269313173 
2022-07-24 18:42:55,584: ============================================================
2022-07-24 18:42:55,584: Epoch 6/25 Batch 1200/7662 eta: 17:11:54.395389	Training Loss1 12.2651 (12.2094)	Training Total_Loss 12.2651 (12.2094)	Training Prec@1 97.070 (97.016)	Training Prec@5 98.633 (98.633)	
2022-07-24 18:42:55,585: ============================================================
2022-07-24 18:43:36,337: time cost, forward:0.1243193885562418, backward:0.09692587900198452, data cost:0.18674395963538143 
2022-07-24 18:43:36,337: ============================================================
2022-07-24 18:43:36,337: Epoch 6/25 Batch 1300/7662 eta: 17:12:00.271602	Training Loss1 13.3222 (12.2381)	Training Total_Loss 13.3222 (12.2381)	Training Prec@1 95.703 (96.995)	Training Prec@5 98.047 (98.626)	
2022-07-24 18:43:36,337: ============================================================
2022-07-24 18:44:17,073: time cost, forward:0.12431545765422088, backward:0.09693028826301144, data cost:0.18664891213668594 
2022-07-24 18:44:17,073: ============================================================
2022-07-24 18:44:17,073: Epoch 6/25 Batch 1400/7662 eta: 17:10:53.843420	Training Loss1 11.7419 (12.2622)	Training Total_Loss 11.7419 (12.2622)	Training Prec@1 97.461 (96.970)	Training Prec@5 98.828 (98.614)	
2022-07-24 18:44:17,073: ============================================================
2022-07-24 18:44:57,797: time cost, forward:0.12431125405472544, backward:0.09693513845427185, data cost:0.18655910565107167 
2022-07-24 18:44:57,797: ============================================================
2022-07-24 18:44:57,797: Epoch 6/25 Batch 1500/7662 eta: 17:09:55.346686	Training Loss1 12.1061 (12.2828)	Training Total_Loss 12.1061 (12.2828)	Training Prec@1 96.680 (96.950)	Training Prec@5 98.438 (98.603)	
2022-07-24 18:44:57,798: ============================================================
2022-07-24 18:45:38,520: time cost, forward:0.12430987468430815, backward:0.09693941852314313, data cost:0.18647836669673765 
2022-07-24 18:45:38,521: ============================================================
2022-07-24 18:45:38,521: Epoch 6/25 Batch 1600/7662 eta: 17:09:13.022645	Training Loss1 12.2878 (12.3061)	Training Total_Loss 12.2878 (12.3061)	Training Prec@1 96.680 (96.926)	Training Prec@5 98.242 (98.588)	
2022-07-24 18:45:38,521: ============================================================
2022-07-24 18:46:19,241: time cost, forward:0.1243050544664676, backward:0.09694260032546036, data cost:0.186410796298498 
2022-07-24 18:46:19,242: ============================================================
2022-07-24 18:46:19,242: Epoch 6/25 Batch 1700/7662 eta: 17:08:29.061848	Training Loss1 11.5707 (12.3252)	Training Total_Loss 11.5707 (12.3252)	Training Prec@1 96.875 (96.913)	Training Prec@5 99.023 (98.583)	
2022-07-24 18:46:19,242: ============================================================
2022-07-24 18:46:59,980: time cost, forward:0.12431115637626033, backward:0.09694404148803677, data cost:0.18635134540576945 
2022-07-24 18:46:59,980: ============================================================
2022-07-24 18:46:59,981: Epoch 6/25 Batch 1800/7662 eta: 17:08:15.454516	Training Loss1 12.1397 (12.3448)	Training Total_Loss 12.1397 (12.3448)	Training Prec@1 98.633 (96.896)	Training Prec@5 99.219 (98.577)	
2022-07-24 18:46:59,981: ============================================================
2022-07-24 18:47:40,713: time cost, forward:0.12430526822287513, backward:0.0969520743863717, data cost:0.1862991173810994 
2022-07-24 18:47:40,714: ============================================================
2022-07-24 18:47:40,714: Epoch 6/25 Batch 1900/7662 eta: 17:07:25.957993	Training Loss1 12.3446 (12.3592)	Training Total_Loss 12.3446 (12.3592)	Training Prec@1 97.461 (96.882)	Training Prec@5 99.023 (98.568)	
2022-07-24 18:47:40,714: ============================================================
2022-07-24 18:48:21,409: time cost, forward:0.12429186688356843, backward:0.09695232266363589, data cost:0.1862485989622619 
2022-07-24 18:48:21,409: ============================================================
2022-07-24 18:48:21,409: Epoch 6/25 Batch 2000/7662 eta: 17:05:48.257201	Training Loss1 12.6052 (12.3730)	Training Total_Loss 12.6052 (12.3730)	Training Prec@1 95.508 (96.870)	Training Prec@5 97.461 (98.560)	
2022-07-24 18:48:21,409: ============================================================
2022-07-24 18:49:02,127: time cost, forward:0.12428941426815562, backward:0.09695818209545905, data cost:0.18619844208108977 
2022-07-24 18:49:02,128: ============================================================
2022-07-24 18:49:02,128: Epoch 6/25 Batch 2100/7662 eta: 17:05:42.309735	Training Loss1 12.3151 (12.3839)	Training Total_Loss 12.3151 (12.3839)	Training Prec@1 96.875 (96.859)	Training Prec@5 97.656 (98.553)	
2022-07-24 18:49:02,128: ============================================================
2022-07-24 18:49:42,836: time cost, forward:0.12428475217745487, backward:0.0969592707435778, data cost:0.1861551730618687 
2022-07-24 18:49:42,837: ============================================================
2022-07-24 18:49:42,837: Epoch 6/25 Batch 2200/7662 eta: 17:04:47.427422	Training Loss1 12.8285 (12.3916)	Training Total_Loss 12.8285 (12.3916)	Training Prec@1 95.508 (96.852)	Training Prec@5 98.242 (98.550)	
2022-07-24 18:49:42,837: ============================================================
2022-07-24 18:50:23,608: time cost, forward:0.12430466056233025, backward:0.09695632014911348, data cost:0.18612390676235416 
2022-07-24 18:50:23,608: ============================================================
2022-07-24 18:50:23,609: Epoch 6/25 Batch 2300/7662 eta: 17:05:41.136341	Training Loss1 12.3540 (12.3999)	Training Total_Loss 12.3540 (12.3999)	Training Prec@1 97.656 (96.849)	Training Prec@5 99.219 (98.548)	
2022-07-24 18:50:23,609: ============================================================
2022-07-24 18:51:04,394: time cost, forward:0.12431929150239882, backward:0.0969579122423281, data cost:0.1861007518696755 
2022-07-24 18:51:04,395: ============================================================
2022-07-24 18:51:04,395: Epoch 6/25 Batch 2400/7662 eta: 17:05:22.478882	Training Loss1 11.9779 (12.4142)	Training Total_Loss 11.9779 (12.4142)	Training Prec@1 96.289 (96.834)	Training Prec@5 98.242 (98.540)	
2022-07-24 18:51:04,395: ============================================================
2022-07-24 18:51:45,173: time cost, forward:0.12433033649708662, backward:0.0969565524345114, data cost:0.1860818817120354 
2022-07-24 18:51:45,173: ============================================================
2022-07-24 18:51:45,174: Epoch 6/25 Batch 2500/7662 eta: 17:04:30.342891	Training Loss1 12.6615 (12.4241)	Training Total_Loss 12.6615 (12.4241)	Training Prec@1 95.703 (96.825)	Training Prec@5 97.266 (98.532)	
2022-07-24 18:51:45,174: ============================================================
2022-07-24 18:52:25,947: time cost, forward:0.12433715818844744, backward:0.09695792583467044, data cost:0.18606130936458598 
2022-07-24 18:52:25,948: ============================================================
2022-07-24 18:52:25,948: Epoch 6/25 Batch 2600/7662 eta: 17:03:42.584988	Training Loss1 12.5461 (12.4325)	Training Total_Loss 12.5461 (12.4325)	Training Prec@1 96.875 (96.815)	Training Prec@5 98.438 (98.527)	
2022-07-24 18:52:25,948: ============================================================
2022-07-24 18:53:06,718: time cost, forward:0.12433918938454808, backward:0.09696118387304972, data cost:0.18604363605418706 
2022-07-24 18:53:06,718: ============================================================
2022-07-24 18:53:06,718: Epoch 6/25 Batch 2700/7662 eta: 17:02:56.188035	Training Loss1 12.1364 (12.4433)	Training Total_Loss 12.1364 (12.4433)	Training Prec@1 97.070 (96.802)	Training Prec@5 98.633 (98.520)	
2022-07-24 18:53:06,718: ============================================================
2022-07-24 18:53:47,491: time cost, forward:0.1243346431673574, backward:0.09696883514720485, data cost:0.1860295554151191 
2022-07-24 18:53:47,492: ============================================================
2022-07-24 18:53:47,492: Epoch 6/25 Batch 2800/7662 eta: 17:02:20.378873	Training Loss1 12.5863 (12.4501)	Training Total_Loss 12.5863 (12.4501)	Training Prec@1 96.484 (96.790)	Training Prec@5 99.023 (98.511)	
2022-07-24 18:53:47,492: ============================================================
2022-07-24 18:54:28,268: time cost, forward:0.12433416253741587, backward:0.09697277959604517, data cost:0.18601771838585235 
2022-07-24 18:54:28,269: ============================================================
2022-07-24 18:54:28,269: Epoch 6/25 Batch 2900/7662 eta: 17:01:44.601469	Training Loss1 12.6572 (12.4601)	Training Total_Loss 12.6572 (12.4601)	Training Prec@1 97.266 (96.784)	Training Prec@5 99.219 (98.506)	
2022-07-24 18:54:28,269: ============================================================
2022-07-24 18:55:09,057: time cost, forward:0.12433693956716652, backward:0.09697736370917279, data cost:0.18600649211994208 
2022-07-24 18:55:09,058: ============================================================
2022-07-24 18:55:09,058: Epoch 6/25 Batch 3000/7662 eta: 17:01:21.590560	Training Loss1 12.9403 (12.4668)	Training Total_Loss 12.9403 (12.4668)	Training Prec@1 95.508 (96.774)	Training Prec@5 97.852 (98.503)	
2022-07-24 18:55:09,058: ============================================================
2022-07-24 18:55:49,859: time cost, forward:0.12434341277411462, backward:0.09698267735447104, data cost:0.18599638618858216 
2022-07-24 18:55:49,859: ============================================================
2022-07-24 18:55:49,859: Epoch 6/25 Batch 3100/7662 eta: 17:01:00.079138	Training Loss1 12.8567 (12.4726)	Training Total_Loss 12.8567 (12.4726)	Training Prec@1 97.266 (96.766)	Training Prec@5 99.023 (98.496)	
2022-07-24 18:55:49,860: ============================================================
2022-07-24 18:56:30,660: time cost, forward:0.12435089047531218, backward:0.09698772199379724, data cost:0.18598384609741134 
2022-07-24 18:56:30,660: ============================================================
2022-07-24 18:56:30,660: Epoch 6/25 Batch 3200/7662 eta: 17:00:17.562502	Training Loss1 12.9788 (12.4761)	Training Total_Loss 12.9788 (12.4761)	Training Prec@1 96.289 (96.758)	Training Prec@5 98.438 (98.494)	
2022-07-24 18:56:30,660: ============================================================
2022-07-24 18:57:11,457: time cost, forward:0.12435315305010844, backward:0.09699310841579153, data cost:0.18597589929597455 
2022-07-24 18:57:11,457: ============================================================
2022-07-24 18:57:11,457: Epoch 6/25 Batch 3300/7662 eta: 16:59:31.800024	Training Loss1 12.6904 (12.4801)	Training Total_Loss 12.6904 (12.4801)	Training Prec@1 95.703 (96.752)	Training Prec@5 97.852 (98.492)	
2022-07-24 18:57:11,457: ============================================================
2022-07-24 18:57:52,243: time cost, forward:0.12435638676604371, backward:0.09699535250628685, data cost:0.1859666991844076 
2022-07-24 18:57:52,244: ============================================================
2022-07-24 18:57:52,244: Epoch 6/25 Batch 3400/7662 eta: 16:58:35.071982	Training Loss1 12.5067 (12.4841)	Training Total_Loss 12.5067 (12.4841)	Training Prec@1 97.852 (96.744)	Training Prec@5 99.219 (98.488)	
2022-07-24 18:57:52,244: ============================================================
2022-07-24 18:58:33,029: time cost, forward:0.12435604831633414, backward:0.09699910775223061, data cost:0.18595909057054633 
2022-07-24 18:58:33,030: ============================================================
2022-07-24 18:58:33,030: Epoch 6/25 Batch 3500/7662 eta: 16:57:53.227902	Training Loss1 12.5726 (12.4882)	Training Total_Loss 12.5726 (12.4882)	Training Prec@1 97.070 (96.742)	Training Prec@5 98.828 (98.486)	
2022-07-24 18:58:33,030: ============================================================
2022-07-24 18:59:13,809: time cost, forward:0.1243601083821739, backward:0.09700035677912766, data cost:0.1859483019979042 
2022-07-24 18:59:13,810: ============================================================
2022-07-24 18:59:13,810: Epoch 6/25 Batch 3600/7662 eta: 16:57:03.647921	Training Loss1 12.8598 (12.4929)	Training Total_Loss 12.8598 (12.4929)	Training Prec@1 95.117 (96.737)	Training Prec@5 97.461 (98.482)	
2022-07-24 18:59:13,810: ============================================================
2022-07-24 18:59:54,618: time cost, forward:0.12436338939290331, backward:0.09700399509923914, data cost:0.18594354138112643 
2022-07-24 18:59:54,618: ============================================================
2022-07-24 18:59:54,618: Epoch 6/25 Batch 3700/7662 eta: 16:57:05.433714	Training Loss1 12.4940 (12.4980)	Training Total_Loss 12.4940 (12.4980)	Training Prec@1 94.727 (96.730)	Training Prec@5 98.438 (98.479)	
2022-07-24 18:59:54,618: ============================================================
2022-07-24 19:00:35,441: time cost, forward:0.12437014223306109, backward:0.09700653125625373, data cost:0.1859402900057173 
2022-07-24 19:00:35,441: ============================================================
2022-07-24 19:00:35,441: Epoch 6/25 Batch 3800/7662 eta: 16:56:45.978696	Training Loss1 13.0299 (12.5030)	Training Total_Loss 13.0299 (12.5030)	Training Prec@1 95.898 (96.723)	Training Prec@5 98.047 (98.476)	
2022-07-24 19:00:35,441: ============================================================
2022-07-24 19:01:16,278: time cost, forward:0.12438383057166992, backward:0.09700616832634339, data cost:0.1859370087562203 
2022-07-24 19:01:16,279: ============================================================
2022-07-24 19:01:16,279: Epoch 6/25 Batch 3900/7662 eta: 16:56:27.115351	Training Loss1 12.2211 (12.5051)	Training Total_Loss 12.2211 (12.5051)	Training Prec@1 96.875 (96.718)	Training Prec@5 98.828 (98.474)	
2022-07-24 19:01:16,279: ============================================================
2022-07-24 19:01:57,101: time cost, forward:0.12439587385125624, backward:0.09700472118199303, data cost:0.18593238848213792 
2022-07-24 19:01:57,101: ============================================================
2022-07-24 19:01:57,101: Epoch 6/25 Batch 4000/7662 eta: 16:55:23.832133	Training Loss1 12.6280 (12.5067)	Training Total_Loss 12.6280 (12.5067)	Training Prec@1 95.898 (96.717)	Training Prec@5 98.047 (98.473)	
2022-07-24 19:01:57,101: ============================================================
2022-07-24 19:02:37,900: time cost, forward:0.12440239059893088, backward:0.09700555300008788, data cost:0.18592520503481297 
2022-07-24 19:02:37,900: ============================================================
2022-07-24 19:02:37,900: Epoch 6/25 Batch 4100/7662 eta: 16:54:08.244997	Training Loss1 12.8787 (12.5099)	Training Total_Loss 12.8787 (12.5099)	Training Prec@1 96.094 (96.712)	Training Prec@5 97.461 (98.468)	
2022-07-24 19:02:37,900: ============================================================
2022-07-24 19:03:18,662: time cost, forward:0.12440332846290642, backward:0.0970061998419547, data cost:0.18591507033638568 
2022-07-24 19:03:18,662: ============================================================
2022-07-24 19:03:18,663: Epoch 6/25 Batch 4200/7662 eta: 16:52:32.560174	Training Loss1 12.2588 (12.5131)	Training Total_Loss 12.2588 (12.5131)	Training Prec@1 97.656 (96.707)	Training Prec@5 99.023 (98.467)	
2022-07-24 19:03:18,663: ============================================================
2022-07-24 19:03:59,420: time cost, forward:0.1244035455398045, backward:0.09700657223845449, data cost:0.18590512561864647 
2022-07-24 19:03:59,420: ============================================================
2022-07-24 19:03:59,420: Epoch 6/25 Batch 4300/7662 eta: 16:51:44.736282	Training Loss1 11.5473 (12.5146)	Training Total_Loss 11.5473 (12.5146)	Training Prec@1 97.266 (96.702)	Training Prec@5 98.633 (98.462)	
2022-07-24 19:03:59,420: ============================================================
2022-07-24 19:04:40,127: time cost, forward:0.1243952734683367, backward:0.0970044862847351, data cost:0.18589542551077504 
2022-07-24 19:04:40,128: ============================================================
2022-07-24 19:04:40,128: Epoch 6/25 Batch 4400/7662 eta: 16:49:49.928759	Training Loss1 12.3388 (12.5154)	Training Total_Loss 12.3388 (12.5154)	Training Prec@1 95.703 (96.698)	Training Prec@5 97.461 (98.460)	
2022-07-24 19:04:40,128: ============================================================
2022-07-24 19:05:20,859: time cost, forward:0.12438844616981738, backward:0.0970068146425185, data cost:0.18588456791701596 
2022-07-24 19:05:20,860: ============================================================
2022-07-24 19:05:20,860: Epoch 6/25 Batch 4500/7662 eta: 16:49:44.825760	Training Loss1 12.7805 (12.5170)	Training Total_Loss 12.7805 (12.5170)	Training Prec@1 96.680 (96.695)	Training Prec@5 98.438 (98.458)	
2022-07-24 19:05:20,860: ============================================================
2022-07-24 19:06:01,601: time cost, forward:0.1243883242008867, backward:0.09700500677398662, data cost:0.1858749468447359 
2022-07-24 19:06:01,602: ============================================================
2022-07-24 19:06:01,602: Epoch 6/25 Batch 4600/7662 eta: 16:49:19.272783	Training Loss1 12.0953 (12.5184)	Training Total_Loss 12.0953 (12.5184)	Training Prec@1 96.484 (96.690)	Training Prec@5 98.828 (98.456)	
2022-07-24 19:06:01,602: ============================================================
2022-07-24 19:06:42,355: time cost, forward:0.12439108239916899, backward:0.09700419659765763, data cost:0.18586511377528211 
2022-07-24 19:06:42,356: ============================================================
2022-07-24 19:06:42,356: Epoch 6/25 Batch 4700/7662 eta: 16:48:56.810585	Training Loss1 13.4982 (12.5197)	Training Total_Loss 13.4982 (12.5197)	Training Prec@1 97.852 (96.688)	Training Prec@5 99.023 (98.455)	
2022-07-24 19:06:42,356: ============================================================
2022-07-24 19:07:23,089: time cost, forward:0.12438754971808855, backward:0.09700471005059202, data cost:0.18585580372517246 
2022-07-24 19:07:23,090: ============================================================
2022-07-24 19:07:23,090: Epoch 6/25 Batch 4800/7662 eta: 16:47:45.627401	Training Loss1 12.0263 (12.5220)	Training Total_Loss 12.0263 (12.5220)	Training Prec@1 97.852 (96.684)	Training Prec@5 98.828 (98.453)	
2022-07-24 19:07:23,090: ============================================================
2022-07-24 19:08:03,805: time cost, forward:0.12438210114383483, backward:0.09700278891279007, data cost:0.18584729394369598 
2022-07-24 19:08:03,805: ============================================================
2022-07-24 19:08:03,806: Epoch 6/25 Batch 4900/7662 eta: 16:46:38.224594	Training Loss1 12.6394 (12.5232)	Training Total_Loss 12.6394 (12.5232)	Training Prec@1 97.266 (96.683)	Training Prec@5 99.023 (98.451)	
2022-07-24 19:08:03,806: ============================================================
2022-07-24 19:08:44,515: time cost, forward:0.1243777197822377, backward:0.09700092369853365, data cost:0.18583759481274 
2022-07-24 19:08:44,515: ============================================================
2022-07-24 19:08:44,515: Epoch 6/25 Batch 5000/7662 eta: 16:45:48.087302	Training Loss1 13.2607 (12.5239)	Training Total_Loss 13.2607 (12.5239)	Training Prec@1 97.266 (96.684)	Training Prec@5 98.828 (98.450)	
2022-07-24 19:08:44,515: ============================================================
2022-07-24 19:09:25,233: time cost, forward:0.12437449303017478, backward:0.09699896121170035, data cost:0.18582905299711705 
2022-07-24 19:09:25,233: ============================================================
2022-07-24 19:09:25,234: Epoch 6/25 Batch 5100/7662 eta: 16:45:20.880881	Training Loss1 12.0773 (12.5254)	Training Total_Loss 12.0773 (12.5254)	Training Prec@1 97.656 (96.680)	Training Prec@5 99.023 (98.449)	
2022-07-24 19:09:25,234: ============================================================
2022-07-24 19:10:05,945: time cost, forward:0.12437036028731945, backward:0.09699715442624453, data cost:0.18581993654613932 
2022-07-24 19:10:05,946: ============================================================
2022-07-24 19:10:05,946: Epoch 6/25 Batch 5200/7662 eta: 16:44:30.854839	Training Loss1 12.4526 (12.5269)	Training Total_Loss 12.4526 (12.5269)	Training Prec@1 96.289 (96.677)	Training Prec@5 98.242 (98.449)	
2022-07-24 19:10:05,946: ============================================================
2022-07-24 19:10:46,662: time cost, forward:0.1243658832928711, backward:0.09699629693464144, data cost:0.1858121057032729 
2022-07-24 19:10:46,662: ============================================================
2022-07-24 19:10:46,662: Epoch 6/25 Batch 5300/7662 eta: 16:43:56.378283	Training Loss1 12.5519 (12.5285)	Training Total_Loss 12.5519 (12.5285)	Training Prec@1 97.266 (96.673)	Training Prec@5 97.852 (98.448)	
2022-07-24 19:10:46,662: ============================================================
2022-07-24 19:11:27,370: time cost, forward:0.12436058327409377, backward:0.09699589483250863, data cost:0.1858040110493925 
2022-07-24 19:11:27,371: ============================================================
2022-07-24 19:11:27,371: Epoch 6/25 Batch 5400/7662 eta: 16:43:03.805765	Training Loss1 12.9298 (12.5288)	Training Total_Loss 12.9298 (12.5288)	Training Prec@1 95.703 (96.671)	Training Prec@5 98.047 (98.446)	
2022-07-24 19:11:27,371: ============================================================
2022-07-24 19:12:08,129: time cost, forward:0.12436512527216086, backward:0.09699294107093402, data cost:0.18579795404355468 
2022-07-24 19:12:08,129: ============================================================
2022-07-24 19:12:08,130: Epoch 6/25 Batch 5500/7662 eta: 16:43:37.409086	Training Loss1 12.0043 (12.5296)	Training Total_Loss 12.0043 (12.5296)	Training Prec@1 98.047 (96.669)	Training Prec@5 99.023 (98.444)	
2022-07-24 19:12:08,130: ============================================================
2022-07-24 19:12:48,891: time cost, forward:0.12436821938072024, backward:0.09699113566144318, data cost:0.18579315227958895 
2022-07-24 19:12:48,892: ============================================================
2022-07-24 19:12:48,892: Epoch 6/25 Batch 5600/7662 eta: 16:43:01.632578	Training Loss1 12.3295 (12.5311)	Training Total_Loss 12.3295 (12.5311)	Training Prec@1 96.680 (96.667)	Training Prec@5 98.242 (98.443)	
2022-07-24 19:12:48,892: ============================================================
2022-07-24 19:13:29,665: time cost, forward:0.12437347609403991, backward:0.0969900409262062, data cost:0.18578787752778347 
2022-07-24 19:13:29,665: ============================================================
2022-07-24 19:13:29,665: Epoch 6/25 Batch 5700/7662 eta: 16:42:37.975018	Training Loss1 12.7346 (12.5327)	Training Total_Loss 12.7346 (12.5327)	Training Prec@1 95.312 (96.662)	Training Prec@5 97.656 (98.441)	
2022-07-24 19:13:29,666: ============================================================
2022-07-24 19:14:10,413: time cost, forward:0.1243738798380597, backward:0.09699115228562503, data cost:0.18578050066261667 
2022-07-24 19:14:10,413: ============================================================
2022-07-24 19:14:10,493: Epoch 6/25 Batch 5800/7662 eta: 16:43:16.151728	Training Loss1 11.7699 (12.5322)	Training Total_Loss 11.7699 (12.5322)	Training Prec@1 96.484 (96.659)	Training Prec@5 98.438 (98.442)	
2022-07-24 19:14:10,493: ============================================================
2022-07-24 19:14:51,258: time cost, forward:0.12438054362845272, backward:0.09698816771668121, data cost:0.18578720557566394 
2022-07-24 19:14:51,258: ============================================================
2022-07-24 19:14:51,259: Epoch 6/25 Batch 5900/7662 eta: 16:41:04.758454	Training Loss1 12.4933 (12.5322)	Training Total_Loss 12.4933 (12.5322)	Training Prec@1 96.875 (96.659)	Training Prec@5 98.438 (98.441)	
2022-07-24 19:14:51,259: ============================================================
2022-07-24 19:15:31,987: time cost, forward:0.12438101334499506, backward:0.09698703031099563, data cost:0.18577924905806548 
2022-07-24 19:15:31,987: ============================================================
2022-07-24 19:15:31,987: Epoch 6/25 Batch 6000/7662 eta: 16:39:28.815319	Training Loss1 12.6806 (12.5323)	Training Total_Loss 12.6806 (12.5323)	Training Prec@1 96.484 (96.656)	Training Prec@5 98.242 (98.438)	
2022-07-24 19:15:31,987: ============================================================
2022-07-24 19:16:12,745: time cost, forward:0.12438250944485017, backward:0.0969865097337364, data cost:0.18577406550649933 
2022-07-24 19:16:12,745: ============================================================
2022-07-24 19:16:12,745: Epoch 6/25 Batch 6100/7662 eta: 16:39:32.273789	Training Loss1 12.3444 (12.5325)	Training Total_Loss 12.3444 (12.5325)	Training Prec@1 95.508 (96.656)	Training Prec@5 98.828 (98.439)	
2022-07-24 19:16:12,745: ============================================================
2022-07-24 19:16:53,480: time cost, forward:0.12437884302596197, backward:0.0969877997258533, data cost:0.1857690516932008 
2022-07-24 19:16:53,480: ============================================================
2022-07-24 19:16:53,480: Epoch 6/25 Batch 6200/7662 eta: 16:38:16.773979	Training Loss1 12.7317 (12.5322)	Training Total_Loss 12.7317 (12.5322)	Training Prec@1 96.484 (96.656)	Training Prec@5 97.852 (98.439)	
2022-07-24 19:16:53,480: ============================================================
2022-07-24 19:17:34,188: time cost, forward:0.1243743320403922, backward:0.0969879098838616, data cost:0.18576199778641456 
2022-07-24 19:17:34,188: ============================================================
2022-07-24 19:17:34,188: Epoch 6/25 Batch 6300/7662 eta: 16:36:56.943291	Training Loss1 12.9081 (12.5323)	Training Total_Loss 12.9081 (12.5323)	Training Prec@1 96.875 (96.656)	Training Prec@5 97.852 (98.438)	
2022-07-24 19:17:34,188: ============================================================
2022-07-24 19:18:14,923: time cost, forward:0.12437289903864002, backward:0.0969886918387612, data cost:0.1857555633896048 
2022-07-24 19:18:14,923: ============================================================
2022-07-24 19:18:14,923: Epoch 6/25 Batch 6400/7662 eta: 16:36:55.749465	Training Loss1 13.4015 (12.5325)	Training Total_Loss 13.4015 (12.5325)	Training Prec@1 95.703 (96.655)	Training Prec@5 97.852 (98.437)	
2022-07-24 19:18:14,923: ============================================================
2022-07-24 19:18:55,661: time cost, forward:0.124372547966716, backward:0.09698863333235302, data cost:0.18574955570164012 
2022-07-24 19:18:55,662: ============================================================
2022-07-24 19:18:55,662: Epoch 6/25 Batch 6500/7662 eta: 16:36:20.406777	Training Loss1 12.6975 (12.5334)	Training Total_Loss 12.6975 (12.5334)	Training Prec@1 97.070 (96.653)	Training Prec@5 99.219 (98.435)	
2022-07-24 19:18:55,662: ============================================================
2022-07-24 19:19:36,448: time cost, forward:0.12437930195995273, backward:0.0969875715486677, data cost:0.1857452365119704 
2022-07-24 19:19:36,448: ============================================================
2022-07-24 19:19:36,449: Epoch 6/25 Batch 6600/7662 eta: 16:36:49.762548	Training Loss1 13.0024 (12.5346)	Training Total_Loss 13.0024 (12.5346)	Training Prec@1 96.875 (96.652)	Training Prec@5 98.438 (98.435)	
2022-07-24 19:19:36,449: ============================================================
2022-07-24 19:20:17,242: time cost, forward:0.12438534811230306, backward:0.09698609356240277, data cost:0.18574278552882048 
2022-07-24 19:20:17,242: ============================================================
2022-07-24 19:20:17,243: Epoch 6/25 Batch 6700/7662 eta: 16:36:20.040922	Training Loss1 12.9077 (12.5337)	Training Total_Loss 12.9077 (12.5337)	Training Prec@1 96.680 (96.653)	Training Prec@5 98.633 (98.436)	
2022-07-24 19:20:17,243: ============================================================
2022-07-24 19:20:58,013: time cost, forward:0.12438784572793765, backward:0.09698559252860564, data cost:0.18573996785423794 
2022-07-24 19:20:58,014: ============================================================
2022-07-24 19:20:58,014: Epoch 6/25 Batch 6800/7662 eta: 16:35:05.721484	Training Loss1 12.6285 (12.5334)	Training Total_Loss 12.6285 (12.5334)	Training Prec@1 97.461 (96.652)	Training Prec@5 98.828 (98.435)	
2022-07-24 19:20:58,014: ============================================================
2022-07-24 19:21:38,796: time cost, forward:0.12439047092803233, backward:0.09698553886391457, data cost:0.18573829923475768 
2022-07-24 19:21:38,797: ============================================================
2022-07-24 19:21:38,797: Epoch 6/25 Batch 6900/7662 eta: 16:34:42.151977	Training Loss1 12.9721 (12.5325)	Training Total_Loss 12.9721 (12.5325)	Training Prec@1 96.680 (96.651)	Training Prec@5 99.023 (98.434)	
2022-07-24 19:21:38,797: ============================================================
2022-07-24 19:22:19,584: time cost, forward:0.12439317869482627, backward:0.09698604069227558, data cost:0.18573700834945503 
2022-07-24 19:22:19,584: ============================================================
2022-07-24 19:22:19,584: Epoch 6/25 Batch 7000/7662 eta: 16:34:07.724522	Training Loss1 12.4034 (12.5304)	Training Total_Loss 12.4034 (12.5304)	Training Prec@1 96.680 (96.654)	Training Prec@5 98.438 (98.435)	
2022-07-24 19:22:19,584: ============================================================
2022-07-24 19:23:00,393: time cost, forward:0.1243968849904874, backward:0.09698664764230193, data cost:0.1857369617771676 
2022-07-24 19:23:00,393: ============================================================
2022-07-24 19:23:00,393: Epoch 6/25 Batch 7100/7662 eta: 16:33:59.195688	Training Loss1 12.5667 (12.5296)	Training Total_Loss 12.5667 (12.5296)	Training Prec@1 97.656 (96.654)	Training Prec@5 98.633 (98.435)	
2022-07-24 19:23:00,393: ============================================================
2022-07-24 19:23:41,190: time cost, forward:0.12439864627982795, backward:0.09698827744590059, data cost:0.18573590764934478 
2022-07-24 19:23:41,190: ============================================================
2022-07-24 19:23:41,190: Epoch 6/25 Batch 7200/7662 eta: 16:33:00.433717	Training Loss1 12.4671 (12.5294)	Training Total_Loss 12.4671 (12.5294)	Training Prec@1 96.875 (96.652)	Training Prec@5 98.242 (98.434)	
2022-07-24 19:23:41,191: ============================================================
2022-07-24 19:24:21,973: time cost, forward:0.12439791015246614, backward:0.09698979373434861, data cost:0.18573533023672734 
2022-07-24 19:24:21,973: ============================================================
2022-07-24 19:24:21,973: Epoch 6/25 Batch 7300/7662 eta: 16:31:58.763457	Training Loss1 12.0316 (12.5295)	Training Total_Loss 12.0316 (12.5295)	Training Prec@1 99.219 (96.651)	Training Prec@5 100.000 (98.434)	
2022-07-24 19:24:21,973: ============================================================
2022-07-24 19:25:02,747: time cost, forward:0.1243984079277182, backward:0.09699053741142644, data cost:0.18573355884193682 
2022-07-24 19:25:02,747: ============================================================
2022-07-24 19:25:02,747: Epoch 6/25 Batch 7400/7662 eta: 16:31:04.865350	Training Loss1 12.4853 (12.5292)	Training Total_Loss 12.4853 (12.5292)	Training Prec@1 97.656 (96.650)	Training Prec@5 98.242 (98.434)	
2022-07-24 19:25:02,747: ============================================================
2022-07-24 19:25:43,546: time cost, forward:0.1243997835003387, backward:0.09699225517921026, data cost:0.18573317217467578 
2022-07-24 19:25:43,547: ============================================================
2022-07-24 19:25:43,547: Epoch 6/25 Batch 7500/7662 eta: 16:31:02.278937	Training Loss1 12.3885 (12.5290)	Training Total_Loss 12.3885 (12.5290)	Training Prec@1 97.656 (96.650)	Training Prec@5 99.414 (98.433)	
2022-07-24 19:25:43,547: ============================================================
2022-07-24 19:26:24,339: time cost, forward:0.12440047601066556, backward:0.09699367949767777, data cost:0.18573282517670237 
2022-07-24 19:26:24,339: ============================================================
2022-07-24 19:26:24,339: Epoch 6/25 Batch 7600/7662 eta: 16:30:10.479254	Training Loss1 12.3034 (12.5286)	Training Total_Loss 12.3034 (12.5286)	Training Prec@1 95.898 (96.649)	Training Prec@5 98.047 (98.433)	
2022-07-24 19:26:24,339: ============================================================
2022-07-24 19:26:51,173: Epoch 6/25 Batch 7663/7662 eta: 16:29:44.780033	Training Loss1 12.7194 (12.5289)	Training Total_Loss 12.7194 (12.5289)	Training Prec@1 96.875 (96.647)	Training Prec@5 98.633 (98.432)	
2022-07-24 19:26:51,173: ============================================================
2022-07-24 19:27:33,003: time cost, forward:0.12451291084289551, backward:0.09709401323337748, data cost:0.19827567928969259 
2022-07-24 19:27:33,004: ============================================================
2022-07-24 19:27:33,004: Epoch 7/25 Batch 100/7662 eta: 16:54:01.378679	Training Loss1 11.4343 (11.2876)	Training Total_Loss 11.4343 (11.2876)	Training Prec@1 98.242 (97.528)	Training Prec@5 99.219 (98.941)	
2022-07-24 19:27:33,004: ============================================================
2022-07-24 19:28:13,777: time cost, forward:0.12436912646844758, backward:0.09709971154754485, data cost:0.19196040426666414 
2022-07-24 19:28:13,777: ============================================================
2022-07-24 19:28:13,778: Epoch 7/25 Batch 200/7662 eta: 16:27:56.287099	Training Loss1 11.1665 (11.3179)	Training Total_Loss 11.1665 (11.3179)	Training Prec@1 97.070 (97.551)	Training Prec@5 98.438 (98.922)	
2022-07-24 19:28:13,778: ============================================================
2022-07-24 19:28:54,578: time cost, forward:0.12439603151685019, backward:0.09713341958546719, data cost:0.18986323764890334 
2022-07-24 19:28:54,579: ============================================================
2022-07-24 19:28:54,579: Epoch 7/25 Batch 300/7662 eta: 16:27:55.467154	Training Loss1 11.5499 (11.3585)	Training Total_Loss 11.5499 (11.3585)	Training Prec@1 96.680 (97.548)	Training Prec@5 98.828 (98.922)	
2022-07-24 19:28:54,579: ============================================================
2022-07-24 19:29:35,384: time cost, forward:0.1243992885551357, backward:0.09715344553304496, data cost:0.18882714477099272 
2022-07-24 19:29:35,385: ============================================================
2022-07-24 19:29:35,385: Epoch 7/25 Batch 400/7662 eta: 16:27:22.152208	Training Loss1 11.1147 (11.4316)	Training Total_Loss 11.1147 (11.4316)	Training Prec@1 97.266 (97.499)	Training Prec@5 98.633 (98.899)	
2022-07-24 19:29:35,385: ============================================================
2022-07-24 19:30:16,182: time cost, forward:0.12440753699782377, backward:0.09715306304977508, data cost:0.18820176908152852 
2022-07-24 19:30:16,182: ============================================================
2022-07-24 19:30:16,183: Epoch 7/25 Batch 500/7662 eta: 16:26:28.658832	Training Loss1 12.2311 (11.4782)	Training Total_Loss 12.2311 (11.4782)	Training Prec@1 96.875 (97.481)	Training Prec@5 98.438 (98.889)	
2022-07-24 19:30:16,183: ============================================================
2022-07-24 19:30:56,954: time cost, forward:0.12438632331427828, backward:0.09714564496965361, data cost:0.18777738270258068 
2022-07-24 19:30:56,955: ============================================================
2022-07-24 19:30:56,955: Epoch 7/25 Batch 600/7662 eta: 16:25:11.285959	Training Loss1 11.5780 (11.5259)	Training Total_Loss 11.5780 (11.5259)	Training Prec@1 98.047 (97.466)	Training Prec@5 99.023 (98.880)	
2022-07-24 19:30:56,955: ============================================================
2022-07-24 19:31:37,741: time cost, forward:0.12439325609602812, backward:0.09713423098617358, data cost:0.18747619532038043 
2022-07-24 19:31:37,741: ============================================================
2022-07-24 19:31:37,741: Epoch 7/25 Batch 700/7662 eta: 16:24:51.012508	Training Loss1 11.6316 (11.5762)	Training Total_Loss 11.6316 (11.5762)	Training Prec@1 97.070 (97.434)	Training Prec@5 98.438 (98.859)	
2022-07-24 19:31:37,741: ============================================================
2022-07-24 19:32:18,496: time cost, forward:0.12437883605049907, backward:0.09712629861318424, data cost:0.18723544191210081 
2022-07-24 19:32:18,496: ============================================================
2022-07-24 19:32:18,497: Epoch 7/25 Batch 800/7662 eta: 16:23:24.931181	Training Loss1 12.2268 (11.6177)	Training Total_Loss 12.2268 (11.6177)	Training Prec@1 95.703 (97.397)	Training Prec@5 97.656 (98.836)	
2022-07-24 19:32:18,497: ============================================================
2022-07-24 19:32:59,252: time cost, forward:0.12437245524897592, backward:0.09712220272577644, data cost:0.18703915677691196 
2022-07-24 19:32:59,252: ============================================================
2022-07-24 19:32:59,252: Epoch 7/25 Batch 900/7662 eta: 16:22:45.098727	Training Loss1 13.2035 (11.6579)	Training Total_Loss 13.2035 (11.6579)	Training Prec@1 96.875 (97.386)	Training Prec@5 98.242 (98.825)	
2022-07-24 19:32:59,252: ============================================================
2022-07-24 19:33:40,003: time cost, forward:0.12436238065496222, backward:0.09711292842486957, data cost:0.18688644231618703 
2022-07-24 19:33:40,003: ============================================================
2022-07-24 19:33:40,003: Epoch 7/25 Batch 1000/7662 eta: 16:21:57.007633	Training Loss1 12.5886 (11.6982)	Training Total_Loss 12.5886 (11.6982)	Training Prec@1 96.289 (97.349)	Training Prec@5 98.438 (98.804)	
2022-07-24 19:33:40,003: ============================================================
2022-07-24 19:34:20,745: time cost, forward:0.12435662800664789, backward:0.09710405282913499, data cost:0.18675769752974505 
2022-07-24 19:34:20,745: ============================================================
2022-07-24 19:34:20,745: Epoch 7/25 Batch 1100/7662 eta: 16:21:04.220263	Training Loss1 12.7298 (11.7230)	Training Total_Loss 12.7298 (11.7230)	Training Prec@1 96.680 (97.344)	Training Prec@5 97.656 (98.800)	
2022-07-24 19:34:20,746: ============================================================
2022-07-24 19:35:01,470: time cost, forward:0.12434700114017133, backward:0.0970945624732494, data cost:0.18664090528002972 
2022-07-24 19:35:01,471: ============================================================
2022-07-24 19:35:01,471: Epoch 7/25 Batch 1200/7662 eta: 16:19:58.814383	Training Loss1 11.9257 (11.7473)	Training Total_Loss 11.9257 (11.7473)	Training Prec@1 96.875 (97.325)	Training Prec@5 98.242 (98.791)	
2022-07-24 19:35:01,471: ============================================================
2022-07-24 19:35:42,242: time cost, forward:0.12436341927361727, backward:0.09708452977245821, data cost:0.18655378181627844 
2022-07-24 19:35:42,242: ============================================================
2022-07-24 19:35:42,242: Epoch 7/25 Batch 1300/7662 eta: 16:20:24.882919	Training Loss1 11.8801 (11.7750)	Training Total_Loss 11.8801 (11.7750)	Training Prec@1 97.070 (97.305)	Training Prec@5 98.438 (98.782)	
2022-07-24 19:35:42,243: ============================================================
2022-07-24 19:36:22,973: time cost, forward:0.12435566876256696, backward:0.09707746035376133, data cost:0.1864710101236012 
2022-07-24 19:36:22,973: ============================================================
2022-07-24 19:36:22,973: Epoch 7/25 Batch 1400/7662 eta: 16:18:45.141070	Training Loss1 11.9194 (11.8037)	Training Total_Loss 11.9194 (11.8037)	Training Prec@1 98.242 (97.283)	Training Prec@5 99.023 (98.769)	
2022-07-24 19:36:22,973: ============================================================
2022-07-24 19:37:03,680: time cost, forward:0.12434269969983448, backward:0.09706836672446345, data cost:0.1863939498089567 
2022-07-24 19:37:03,680: ============================================================
2022-07-24 19:37:03,681: Epoch 7/25 Batch 1500/7662 eta: 16:17:30.884356	Training Loss1 12.8808 (11.8273)	Training Total_Loss 12.8808 (11.8273)	Training Prec@1 95.898 (97.262)	Training Prec@5 98.438 (98.761)	
2022-07-24 19:37:03,681: ============================================================
2022-07-24 19:37:44,411: time cost, forward:0.1243383789002858, backward:0.0970604419708252, data cost:0.18633187689432285 
2022-07-24 19:37:44,412: ============================================================
2022-07-24 19:37:44,412: Epoch 7/25 Batch 1600/7662 eta: 16:17:24.571801	Training Loss1 12.5611 (11.8538)	Training Total_Loss 12.5611 (11.8538)	Training Prec@1 96.289 (97.242)	Training Prec@5 98.047 (98.746)	
2022-07-24 19:37:44,412: ============================================================
2022-07-24 19:38:25,126: time cost, forward:0.1243266486784793, backward:0.09705607325557823, data cost:0.18627310542936815 
2022-07-24 19:38:25,126: ============================================================
2022-07-24 19:38:25,126: Epoch 7/25 Batch 1700/7662 eta: 16:16:18.920396	Training Loss1 11.6505 (11.8775)	Training Total_Loss 11.6505 (11.8775)	Training Prec@1 97.656 (97.230)	Training Prec@5 98.828 (98.741)	
2022-07-24 19:38:25,126: ============================================================
2022-07-24 19:39:05,880: time cost, forward:0.12433171285530671, backward:0.09705408193324261, data cost:0.1862256081651621 
2022-07-24 19:39:05,881: ============================================================
2022-07-24 19:39:05,881: Epoch 7/25 Batch 1800/7662 eta: 16:16:36.968101	Training Loss1 11.6966 (11.8923)	Training Total_Loss 11.6966 (11.8923)	Training Prec@1 97.461 (97.218)	Training Prec@5 99.219 (98.731)	
2022-07-24 19:39:05,881: ============================================================
2022-07-24 19:39:46,639: time cost, forward:0.12433285660464993, backward:0.09705526681872906, data cost:0.18618676661189573 
2022-07-24 19:39:46,639: ============================================================
2022-07-24 19:39:46,639: Epoch 7/25 Batch 1900/7662 eta: 16:16:01.300192	Training Loss1 12.1146 (11.9106)	Training Total_Loss 12.1146 (11.9106)	Training Prec@1 97.461 (97.204)	Training Prec@5 98.438 (98.725)	
2022-07-24 19:39:46,639: ============================================================
2022-07-24 19:40:27,401: time cost, forward:0.12434541004308765, backward:0.09705114304989561, data cost:0.18614473707858414 
2022-07-24 19:40:27,401: ============================================================
2022-07-24 19:40:27,401: Epoch 7/25 Batch 2000/7662 eta: 16:15:25.673470	Training Loss1 12.4226 (11.9306)	Training Total_Loss 12.4226 (11.9306)	Training Prec@1 96.289 (97.190)	Training Prec@5 97.656 (98.720)	
2022-07-24 19:40:27,401: ============================================================
2022-07-24 19:41:08,145: time cost, forward:0.12434535437734312, backward:0.0970469630860669, data cost:0.1861117527904029 
2022-07-24 19:41:08,145: ============================================================
2022-07-24 19:41:08,146: Epoch 7/25 Batch 2100/7662 eta: 16:14:19.595452	Training Loss1 11.8775 (11.9495)	Training Total_Loss 11.8775 (11.9495)	Training Prec@1 96.875 (97.172)	Training Prec@5 98.047 (98.713)	
2022-07-24 19:41:08,146: ============================================================
2022-07-24 19:41:48,861: time cost, forward:0.12433482962014622, backward:0.09704519369863499, data cost:0.186076856624435 
2022-07-24 19:41:48,861: ============================================================
2022-07-24 19:41:48,861: Epoch 7/25 Batch 2200/7662 eta: 16:12:57.929511	Training Loss1 12.3668 (11.9645)	Training Total_Loss 12.3668 (11.9645)	Training Prec@1 97.266 (97.159)	Training Prec@5 99.023 (98.706)	
2022-07-24 19:41:48,862: ============================================================
2022-07-24 19:42:29,609: time cost, forward:0.12433825383346046, backward:0.09704330103352776, data cost:0.1860479374147592 
2022-07-24 19:42:29,610: ============================================================
2022-07-24 19:42:29,610: Epoch 7/25 Batch 2300/7662 eta: 16:13:03.909562	Training Loss1 12.5517 (11.9816)	Training Total_Loss 12.5517 (11.9816)	Training Prec@1 96.289 (97.138)	Training Prec@5 98.828 (98.695)	
2022-07-24 19:42:29,610: ============================================================
2022-07-24 19:43:10,332: time cost, forward:0.12433151793310969, backward:0.09704131670622292, data cost:0.1860196746454084 
2022-07-24 19:43:10,332: ============================================================
2022-07-24 19:43:10,332: Epoch 7/25 Batch 2400/7662 eta: 16:11:45.486370	Training Loss1 11.9542 (11.9946)	Training Total_Loss 11.9542 (11.9946)	Training Prec@1 96.680 (97.130)	Training Prec@5 98.438 (98.689)	
2022-07-24 19:43:10,332: ============================================================
2022-07-24 19:43:51,081: time cost, forward:0.12433533918480723, backward:0.09703934893888586, data cost:0.18599525782145132 
2022-07-24 19:43:51,081: ============================================================
2022-07-24 19:43:51,081: Epoch 7/25 Batch 2500/7662 eta: 16:11:43.356647	Training Loss1 13.0832 (12.0077)	Training Total_Loss 13.0832 (12.0077)	Training Prec@1 96.680 (97.118)	Training Prec@5 98.633 (98.685)	
2022-07-24 19:43:51,081: ============================================================
2022-07-24 19:44:31,804: time cost, forward:0.12432976345137112, backward:0.09703835215463964, data cost:0.18596949729611204 
2022-07-24 19:44:31,804: ============================================================
2022-07-24 19:44:31,804: Epoch 7/25 Batch 2600/7662 eta: 16:10:25.858096	Training Loss1 11.8708 (12.0163)	Training Total_Loss 11.8708 (12.0163)	Training Prec@1 96.289 (97.111)	Training Prec@5 98.633 (98.682)	
2022-07-24 19:44:31,805: ============================================================
2022-07-24 19:45:12,616: time cost, forward:0.12435250398890978, backward:0.09703351913358865, data cost:0.18595474532199108 
2022-07-24 19:45:12,616: ============================================================
2022-07-24 19:45:12,616: Epoch 7/25 Batch 2700/7662 eta: 16:11:51.384762	Training Loss1 11.5630 (12.0275)	Training Total_Loss 11.5630 (12.0275)	Training Prec@1 98.047 (97.102)	Training Prec@5 99.414 (98.677)	
2022-07-24 19:45:12,616: ============================================================
2022-07-24 19:45:53,398: time cost, forward:0.12436425587925667, backward:0.0970299910033929, data cost:0.18593954077445 
2022-07-24 19:45:53,399: ============================================================
2022-07-24 19:45:53,399: Epoch 7/25 Batch 2800/7662 eta: 16:10:29.107833	Training Loss1 12.2549 (12.0367)	Training Total_Loss 12.2549 (12.0367)	Training Prec@1 97.070 (97.091)	Training Prec@5 98.633 (98.673)	
2022-07-24 19:45:53,399: ============================================================
2022-07-24 19:46:34,131: time cost, forward:0.12436010945291509, backward:0.09702770469023385, data cost:0.1859221184570323 
2022-07-24 19:46:34,132: ============================================================
2022-07-24 19:46:34,132: Epoch 7/25 Batch 2900/7662 eta: 16:08:37.392905	Training Loss1 12.2986 (12.0466)	Training Total_Loss 12.2986 (12.0466)	Training Prec@1 97.266 (97.082)	Training Prec@5 99.023 (98.668)	
2022-07-24 19:46:34,132: ============================================================
2022-07-24 19:47:14,855: time cost, forward:0.12435757251293034, backward:0.09702311574955629, data cost:0.1859038326095525 
2022-07-24 19:47:14,855: ============================================================
2022-07-24 19:47:14,855: Epoch 7/25 Batch 3000/7662 eta: 16:07:42.869460	Training Loss1 12.7735 (12.0550)	Training Total_Loss 12.7735 (12.0550)	Training Prec@1 97.461 (97.074)	Training Prec@5 98.828 (98.665)	
2022-07-24 19:47:14,855: ============================================================
2022-07-24 19:47:55,579: time cost, forward:0.12435416669067009, backward:0.0970200104419552, data cost:0.1858875089093307 
2022-07-24 19:47:55,580: ============================================================
2022-07-24 19:47:55,580: Epoch 7/25 Batch 3100/7662 eta: 16:07:04.247864	Training Loss1 12.1416 (12.0628)	Training Total_Loss 12.1416 (12.0628)	Training Prec@1 95.312 (97.064)	Training Prec@5 97.852 (98.658)	
2022-07-24 19:47:55,580: ============================================================
2022-07-24 19:48:36,339: time cost, forward:0.12436204181681874, backward:0.09701532116156886, data cost:0.1858744566870615 
2022-07-24 19:48:36,340: ============================================================
2022-07-24 19:48:36,340: Epoch 7/25 Batch 3200/7662 eta: 16:07:13.711617	Training Loss1 12.1702 (12.0744)	Training Total_Loss 12.1702 (12.0744)	Training Prec@1 96.094 (97.055)	Training Prec@5 98.438 (98.652)	
2022-07-24 19:48:36,340: ============================================================
2022-07-24 19:49:17,065: time cost, forward:0.12436397858336681, backward:0.09701116181171529, data cost:0.18585757863778135 
2022-07-24 19:49:17,066: ============================================================
2022-07-24 19:49:17,066: Epoch 7/25 Batch 3300/7662 eta: 16:05:44.541231	Training Loss1 12.2079 (12.0849)	Training Total_Loss 12.2079 (12.0849)	Training Prec@1 97.461 (97.048)	Training Prec@5 99.023 (98.647)	
2022-07-24 19:49:17,066: ============================================================
2022-07-24 19:49:57,779: time cost, forward:0.12435588397570096, backward:0.09701086493512047, data cost:0.18584313579221515 
2022-07-24 19:49:57,779: ============================================================
2022-07-24 19:49:57,779: Epoch 7/25 Batch 3400/7662 eta: 16:04:45.822114	Training Loss1 11.9401 (12.0912)	Training Total_Loss 11.9401 (12.0912)	Training Prec@1 97.461 (97.041)	Training Prec@5 98.633 (98.640)	
2022-07-24 19:49:57,779: ============================================================
2022-07-24 19:50:38,526: time cost, forward:0.12435644597590191, backward:0.09700981021847306, data cost:0.18583260246193997 
2022-07-24 19:50:38,527: ============================================================
2022-07-24 19:50:38,527: Epoch 7/25 Batch 3500/7662 eta: 16:04:53.860626	Training Loss1 11.9503 (12.0967)	Training Total_Loss 11.9503 (12.0967)	Training Prec@1 96.875 (97.036)	Training Prec@5 98.633 (98.638)	
2022-07-24 19:50:38,527: ============================================================
2022-07-24 19:51:19,266: time cost, forward:0.12434895113462473, backward:0.09701045767139414, data cost:0.18582619776756243 
2022-07-24 19:51:19,266: ============================================================
2022-07-24 19:51:19,266: Epoch 7/25 Batch 3600/7662 eta: 16:04:01.221315	Training Loss1 12.3868 (12.1044)	Training Total_Loss 12.3868 (12.1044)	Training Prec@1 96.094 (97.028)	Training Prec@5 97.656 (98.634)	
2022-07-24 19:51:19,266: ============================================================
2022-07-24 19:52:00,051: time cost, forward:0.12435359502360768, backward:0.09700987409275588, data cost:0.18582201068483195 
2022-07-24 19:52:00,051: ============================================================
2022-07-24 19:52:00,051: Epoch 7/25 Batch 3700/7662 eta: 16:04:25.369553	Training Loss1 11.2877 (12.1081)	Training Total_Loss 11.2877 (12.1081)	Training Prec@1 98.047 (97.024)	Training Prec@5 99.609 (98.631)	
2022-07-24 19:52:00,051: ============================================================
2022-07-24 19:52:40,816: time cost, forward:0.12435231870273189, backward:0.09701106949334522, data cost:0.1858170205086399 
2022-07-24 19:52:40,816: ============================================================
2022-07-24 19:52:40,816: Epoch 7/25 Batch 3800/7662 eta: 16:03:16.478569	Training Loss1 12.4932 (12.1157)	Training Total_Loss 12.4932 (12.1157)	Training Prec@1 96.094 (97.014)	Training Prec@5 98.242 (98.625)	
2022-07-24 19:52:40,816: ============================================================
2022-07-24 19:53:21,590: time cost, forward:0.12435033902904259, backward:0.09701336374891878, data cost:0.18581376512345976 
2022-07-24 19:53:21,590: ============================================================
2022-07-24 19:53:21,590: Epoch 7/25 Batch 3900/7662 eta: 16:02:48.180497	Training Loss1 12.3827 (12.1182)	Training Total_Loss 12.3827 (12.1182)	Training Prec@1 95.312 (97.011)	Training Prec@5 97.266 (98.622)	
2022-07-24 19:53:21,591: ============================================================
2022-07-24 19:54:02,374: time cost, forward:0.1243512376483365, backward:0.09701561635659617, data cost:0.1858107097508401 
2022-07-24 19:54:02,374: ============================================================
2022-07-24 19:54:02,374: Epoch 7/25 Batch 4000/7662 eta: 16:02:21.070220	Training Loss1 12.0888 (12.1207)	Training Total_Loss 12.0888 (12.1207)	Training Prec@1 96.875 (97.006)	Training Prec@5 98.242 (98.620)	
2022-07-24 19:54:02,374: ============================================================
2022-07-24 19:54:43,177: time cost, forward:0.12435722170762534, backward:0.09701757275147914, data cost:0.18580734092859444 
2022-07-24 19:54:43,177: ============================================================
2022-07-24 19:54:43,177: Epoch 7/25 Batch 4100/7662 eta: 16:02:07.698258	Training Loss1 12.1404 (12.1257)	Training Total_Loss 12.1404 (12.1257)	Training Prec@1 96.289 (97.003)	Training Prec@5 98.047 (98.618)	
2022-07-24 19:54:43,177: ============================================================
2022-07-24 19:55:23,983: time cost, forward:0.12436390882675123, backward:0.09701806348004378, data cost:0.1858049673987559 
2022-07-24 19:55:23,984: ============================================================
2022-07-24 19:55:23,984: Epoch 7/25 Batch 4200/7662 eta: 16:01:32.235839	Training Loss1 12.5699 (12.1285)	Training Total_Loss 12.5699 (12.1285)	Training Prec@1 96.289 (96.999)	Training Prec@5 98.047 (98.616)	
2022-07-24 19:55:23,984: ============================================================
2022-07-24 19:56:04,804: time cost, forward:0.12437162312775829, backward:0.09702024744898531, data cost:0.1858027842633251 
2022-07-24 19:56:04,805: ============================================================
2022-07-24 19:56:04,805: Epoch 7/25 Batch 4300/7662 eta: 16:01:11.380143	Training Loss1 12.5912 (12.1326)	Training Total_Loss 12.5912 (12.1326)	Training Prec@1 96.289 (96.991)	Training Prec@5 98.438 (98.612)	
2022-07-24 19:56:04,805: ============================================================
2022-07-24 19:56:45,599: time cost, forward:0.12437348643279288, backward:0.09702186748151699, data cost:0.18580086932016465 
2022-07-24 19:56:45,599: ============================================================
2022-07-24 19:56:45,599: Epoch 7/25 Batch 4400/7662 eta: 15:59:53.037418	Training Loss1 11.2854 (12.1365)	Training Total_Loss 11.2854 (12.1365)	Training Prec@1 96.875 (96.984)	Training Prec@5 98.828 (98.609)	
2022-07-24 19:56:45,599: ============================================================
2022-07-24 19:57:26,409: time cost, forward:0.12437402960935628, backward:0.09702569411897373, data cost:0.18580146868193406 
2022-07-24 19:57:26,409: ============================================================
2022-07-24 19:57:26,409: Epoch 7/25 Batch 4500/7662 eta: 15:59:34.427945	Training Loss1 12.0436 (12.1412)	Training Total_Loss 12.0436 (12.1412)	Training Prec@1 97.070 (96.978)	Training Prec@5 98.828 (98.606)	
2022-07-24 19:57:26,409: ============================================================
2022-07-24 19:58:07,213: time cost, forward:0.12437998825997264, backward:0.09702655179885761, data cost:0.18579831738191005 
2022-07-24 19:58:07,214: ============================================================
2022-07-24 19:58:07,214: Epoch 7/25 Batch 4600/7662 eta: 15:58:45.901573	Training Loss1 12.4446 (12.1442)	Training Total_Loss 12.4446 (12.1442)	Training Prec@1 96.484 (96.975)	Training Prec@5 98.242 (98.604)	
2022-07-24 19:58:07,214: ============================================================
2022-07-24 19:58:48,016: time cost, forward:0.12438414730551801, backward:0.09702705682452929, data cost:0.18579737377511768 
2022-07-24 19:58:48,016: ============================================================
2022-07-24 19:58:48,016: Epoch 7/25 Batch 4700/7662 eta: 15:58:02.014933	Training Loss1 11.7548 (12.1465)	Training Total_Loss 11.7548 (12.1465)	Training Prec@1 97.852 (96.972)	Training Prec@5 98.633 (98.602)	
2022-07-24 19:58:48,016: ============================================================
2022-07-24 19:59:28,821: time cost, forward:0.12438902782385337, backward:0.09702807114655387, data cost:0.18579524103416256 
2022-07-24 19:59:28,821: ============================================================
2022-07-24 19:59:28,822: Epoch 7/25 Batch 4800/7662 eta: 15:57:25.527562	Training Loss1 12.6682 (12.1486)	Training Total_Loss 12.6682 (12.1486)	Training Prec@1 97.852 (96.967)	Training Prec@5 98.633 (98.599)	
2022-07-24 19:59:28,822: ============================================================
2022-07-24 20:00:09,611: time cost, forward:0.12438987892339316, backward:0.09703021089406276, data cost:0.18579328953185648 
2022-07-24 20:00:09,611: ============================================================
2022-07-24 20:00:09,611: Epoch 7/25 Batch 4900/7662 eta: 15:56:22.226156	Training Loss1 12.2099 (12.1525)	Training Total_Loss 12.2099 (12.1525)	Training Prec@1 97.656 (96.964)	Training Prec@5 98.633 (98.597)	
2022-07-24 20:00:09,611: ============================================================
2022-07-24 20:00:50,387: time cost, forward:0.1243922446675004, backward:0.09702946873134698, data cost:0.185789687558636 
2022-07-24 20:00:50,388: ============================================================
2022-07-24 20:00:50,388: Epoch 7/25 Batch 5000/7662 eta: 15:55:23.717435	Training Loss1 12.4167 (12.1560)	Training Total_Loss 12.4167 (12.1560)	Training Prec@1 96.289 (96.960)	Training Prec@5 98.828 (98.595)	
2022-07-24 20:00:50,388: ============================================================
2022-07-24 20:01:31,207: time cost, forward:0.12439797849930088, backward:0.09703032543528756, data cost:0.18578925663921314 
2022-07-24 20:01:31,207: ============================================================
2022-07-24 20:01:31,208: Epoch 7/25 Batch 5100/7662 eta: 15:55:42.892348	Training Loss1 12.8596 (12.1590)	Training Total_Loss 12.8596 (12.1590)	Training Prec@1 96.680 (96.956)	Training Prec@5 98.438 (98.593)	
2022-07-24 20:01:31,208: ============================================================
2022-07-24 20:02:11,937: time cost, forward:0.12439409965137996, backward:0.0970293471253269, data cost:0.18578307054024015 
2022-07-24 20:02:11,937: ============================================================
2022-07-24 20:02:11,937: Epoch 7/25 Batch 5200/7662 eta: 15:52:55.941002	Training Loss1 12.8215 (12.1608)	Training Total_Loss 12.8215 (12.1608)	Training Prec@1 96.094 (96.953)	Training Prec@5 97.852 (98.592)	
2022-07-24 20:02:11,937: ============================================================
2022-07-24 20:02:52,706: time cost, forward:0.12439625158380126, backward:0.09702911312163022, data cost:0.18577744128861998 
2022-07-24 20:02:52,706: ============================================================
2022-07-24 20:02:52,706: Epoch 7/25 Batch 5300/7662 eta: 15:53:10.244915	Training Loss1 13.0825 (12.1631)	Training Total_Loss 13.0825 (12.1631)	Training Prec@1 95.117 (96.949)	Training Prec@5 97.656 (98.590)	
2022-07-24 20:02:52,706: ============================================================
2022-07-24 20:03:33,449: time cost, forward:0.12439574447246056, backward:0.09702708990977062, data cost:0.1857715974275349 
2022-07-24 20:03:33,449: ============================================================
2022-07-24 20:03:33,450: Epoch 7/25 Batch 5400/7662 eta: 15:51:53.585545	Training Loss1 12.4742 (12.1654)	Training Total_Loss 12.4742 (12.1654)	Training Prec@1 95.508 (96.944)	Training Prec@5 97.852 (98.588)	
2022-07-24 20:03:33,450: ============================================================
2022-07-24 20:04:14,180: time cost, forward:0.12439516779075299, backward:0.09702448165076367, data cost:0.18576478515891384 
2022-07-24 20:04:14,180: ============================================================
2022-07-24 20:04:14,181: Epoch 7/25 Batch 5500/7662 eta: 15:50:55.722694	Training Loss1 12.5786 (12.1663)	Training Total_Loss 12.5786 (12.1663)	Training Prec@1 96.875 (96.944)	Training Prec@5 98.828 (98.587)	
2022-07-24 20:04:14,181: ============================================================
2022-07-24 20:04:54,911: time cost, forward:0.1243955612523276, backward:0.09702240967243819, data cost:0.18575666474112232 
2022-07-24 20:04:54,911: ============================================================
2022-07-24 20:04:54,912: Epoch 7/25 Batch 5600/7662 eta: 15:50:14.761646	Training Loss1 11.5051 (12.1670)	Training Total_Loss 11.5051 (12.1670)	Training Prec@1 96.875 (96.942)	Training Prec@5 98.633 (98.585)	
2022-07-24 20:04:54,912: ============================================================
2022-07-24 20:05:35,625: time cost, forward:0.12439200911193088, backward:0.09702090979417305, data cost:0.18574923731858614 
2022-07-24 20:05:35,625: ============================================================
2022-07-24 20:05:35,625: Epoch 7/25 Batch 5700/7662 eta: 15:49:10.223653	Training Loss1 11.8688 (12.1686)	Training Total_Loss 11.8688 (12.1686)	Training Prec@1 97.461 (96.940)	Training Prec@5 98.633 (98.585)	
2022-07-24 20:05:35,626: ============================================================
2022-07-24 20:06:16,362: time cost, forward:0.12439257244669912, backward:0.097019532977106, data cost:0.1857424448391223 
2022-07-24 20:06:16,363: ============================================================
2022-07-24 20:06:16,363: Epoch 7/25 Batch 5800/7662 eta: 15:49:02.221447	Training Loss1 12.0130 (12.1693)	Training Total_Loss 12.0130 (12.1693)	Training Prec@1 97.266 (96.940)	Training Prec@5 99.219 (98.584)	
2022-07-24 20:06:16,363: ============================================================
2022-07-24 20:06:57,107: time cost, forward:0.12439192871175231, backward:0.09701885160985166, data cost:0.1857373911680903 
2022-07-24 20:06:57,108: ============================================================
2022-07-24 20:06:57,108: Epoch 7/25 Batch 5900/7662 eta: 15:48:32.007912	Training Loss1 12.4250 (12.1694)	Training Total_Loss 12.4250 (12.1694)	Training Prec@1 96.289 (96.939)	Training Prec@5 98.438 (98.584)	
2022-07-24 20:06:57,108: ============================================================
2022-07-24 20:07:37,844: time cost, forward:0.12438999829560166, backward:0.09701922929849321, data cost:0.18573128900879282 
2022-07-24 20:07:37,844: ============================================================
2022-07-24 20:07:37,845: Epoch 7/25 Batch 6000/7662 eta: 15:47:40.127162	Training Loss1 12.8752 (12.1699)	Training Total_Loss 12.8752 (12.1699)	Training Prec@1 96.484 (96.936)	Training Prec@5 97.852 (98.582)	
2022-07-24 20:07:37,845: ============================================================
2022-07-24 20:08:18,616: time cost, forward:0.12439297316288983, backward:0.09702041896176467, data cost:0.1857253506762568 
2022-07-24 20:08:18,617: ============================================================
2022-07-24 20:08:18,617: Epoch 7/25 Batch 6100/7662 eta: 15:47:48.940980	Training Loss1 12.7542 (12.1711)	Training Total_Loss 12.7542 (12.1711)	Training Prec@1 96.484 (96.936)	Training Prec@5 98.438 (98.583)	
2022-07-24 20:08:18,617: ============================================================
2022-07-24 20:08:59,376: time cost, forward:0.12439136728968885, backward:0.09702203600305495, data cost:0.18572128670968285 
2022-07-24 20:08:59,376: ============================================================
2022-07-24 20:08:59,376: Epoch 7/25 Batch 6200/7662 eta: 15:46:50.031014	Training Loss1 11.3635 (12.1718)	Training Total_Loss 11.3635 (12.1718)	Training Prec@1 97.852 (96.933)	Training Prec@5 99.219 (98.581)	
2022-07-24 20:08:59,377: ============================================================
2022-07-24 20:09:40,114: time cost, forward:0.12439076547339561, backward:0.09702172349759332, data cost:0.18571560022130357 
2022-07-24 20:09:40,115: ============================================================
2022-07-24 20:09:40,115: Epoch 7/25 Batch 6300/7662 eta: 15:45:40.153995	Training Loss1 12.5193 (12.1727)	Training Total_Loss 12.5193 (12.1727)	Training Prec@1 96.875 (96.931)	Training Prec@5 97.656 (98.580)	
2022-07-24 20:09:40,115: ============================================================
2022-07-24 20:10:20,836: time cost, forward:0.12438782190304097, backward:0.09702191164315091, data cost:0.1857089891268287 
2022-07-24 20:10:20,836: ============================================================
2022-07-24 20:10:20,836: Epoch 7/25 Batch 6400/7662 eta: 15:44:35.741532	Training Loss1 12.2358 (12.1731)	Training Total_Loss 12.2358 (12.1731)	Training Prec@1 96.094 (96.931)	Training Prec@5 98.438 (98.580)	
2022-07-24 20:10:20,836: ============================================================
2022-07-24 20:11:01,575: time cost, forward:0.12438638783689829, backward:0.09702250979133414, data cost:0.18570356600870444 
2022-07-24 20:11:01,575: ============================================================
2022-07-24 20:11:01,575: Epoch 7/25 Batch 6500/7662 eta: 15:44:19.008948	Training Loss1 12.3102 (12.1744)	Training Total_Loss 12.3102 (12.1744)	Training Prec@1 97.852 (96.930)	Training Prec@5 99.219 (98.580)	
2022-07-24 20:11:01,575: ============================================================
2022-07-24 20:11:42,325: time cost, forward:0.12438681617363381, backward:0.09702324748021181, data cost:0.18569814474189944 
2022-07-24 20:11:42,325: ============================================================
2022-07-24 20:11:42,325: Epoch 7/25 Batch 6600/7662 eta: 15:43:54.280479	Training Loss1 12.8850 (12.1762)	Training Total_Loss 12.8850 (12.1762)	Training Prec@1 97.461 (96.929)	Training Prec@5 98.242 (98.579)	
2022-07-24 20:11:42,325: ============================================================
2022-07-24 20:12:23,066: time cost, forward:0.12438810720499247, backward:0.09702224485161305, data cost:0.18569259071264682 
2022-07-24 20:12:23,067: ============================================================
2022-07-24 20:12:23,067: Epoch 7/25 Batch 6700/7662 eta: 15:43:01.401554	Training Loss1 11.9009 (12.1772)	Training Total_Loss 11.9009 (12.1772)	Training Prec@1 96.875 (96.928)	Training Prec@5 98.828 (98.578)	
2022-07-24 20:12:23,067: ============================================================
2022-07-24 20:13:03,807: time cost, forward:0.12438791933296743, backward:0.09702170258112595, data cost:0.18568801504668989 
2022-07-24 20:13:03,808: ============================================================
2022-07-24 20:13:03,808: Epoch 7/25 Batch 6800/7662 eta: 15:42:19.923517	Training Loss1 12.3316 (12.1778)	Training Total_Loss 12.3316 (12.1778)	Training Prec@1 96.484 (96.927)	Training Prec@5 98.242 (98.576)	
2022-07-24 20:13:03,808: ============================================================
2022-07-24 20:13:44,538: time cost, forward:0.12438681291866897, backward:0.09702144233813094, data cost:0.185682385015149 
2022-07-24 20:13:44,538: ============================================================
2022-07-24 20:13:44,538: Epoch 7/25 Batch 6900/7662 eta: 15:41:24.586589	Training Loss1 12.3600 (12.1796)	Training Total_Loss 12.3600 (12.1796)	Training Prec@1 96.484 (96.925)	Training Prec@5 97.656 (98.575)	
2022-07-24 20:13:44,538: ============================================================
2022-07-24 20:14:25,237: time cost, forward:0.12438180290267951, backward:0.09702178014484639, data cost:0.18567625647494582 
2022-07-24 20:14:25,238: ============================================================
2022-07-24 20:14:25,238: Epoch 7/25 Batch 7000/7662 eta: 15:40:00.976080	Training Loss1 12.2158 (12.1809)	Training Total_Loss 12.2158 (12.1809)	Training Prec@1 96.875 (96.925)	Training Prec@5 98.047 (98.574)	
2022-07-24 20:14:25,238: ============================================================
2022-07-24 20:15:05,941: time cost, forward:0.1243772744830183, backward:0.09702184593565012, data cost:0.18567041374122714 
2022-07-24 20:15:05,942: ============================================================
2022-07-24 20:15:05,942: Epoch 7/25 Batch 7100/7662 eta: 15:39:26.482580	Training Loss1 11.6372 (12.1806)	Training Total_Loss 11.6372 (12.1806)	Training Prec@1 97.070 (96.925)	Training Prec@5 98.828 (98.574)	
2022-07-24 20:15:05,942: ============================================================
2022-07-24 20:15:46,658: time cost, forward:0.12437587752079265, backward:0.09702103537707747, data cost:0.185664512329854 
2022-07-24 20:15:46,659: ============================================================
2022-07-24 20:15:46,659: Epoch 7/25 Batch 7200/7662 eta: 15:39:03.984961	Training Loss1 12.2518 (12.1808)	Training Total_Loss 12.2518 (12.1808)	Training Prec@1 96.289 (96.925)	Training Prec@5 98.633 (98.574)	
2022-07-24 20:15:46,659: ============================================================
2022-07-24 20:16:27,403: time cost, forward:0.12437809939449136, backward:0.09702061009514837, data cost:0.1856592388769783 
2022-07-24 20:16:27,403: ============================================================
2022-07-24 20:16:27,404: Epoch 7/25 Batch 7300/7662 eta: 15:39:01.308923	Training Loss1 12.4450 (12.1810)	Training Total_Loss 12.4450 (12.1810)	Training Prec@1 97.852 (96.923)	Training Prec@5 98.828 (98.574)	
2022-07-24 20:16:27,404: ============================================================
2022-07-24 20:17:08,124: time cost, forward:0.12437793508963514, backward:0.09702054931273539, data cost:0.18565302727141564 
2022-07-24 20:17:08,125: ============================================================
2022-07-24 20:17:08,125: Epoch 7/25 Batch 7400/7662 eta: 15:37:48.262568	Training Loss1 11.9855 (12.1810)	Training Total_Loss 11.9855 (12.1810)	Training Prec@1 97.070 (96.924)	Training Prec@5 98.047 (98.574)	
2022-07-24 20:17:08,125: ============================================================
2022-07-24 20:17:48,858: time cost, forward:0.12437855757018823, backward:0.0970197936219682, data cost:0.1856484711368905 
2022-07-24 20:17:48,858: ============================================================
2022-07-24 20:17:48,858: Epoch 7/25 Batch 7500/7662 eta: 15:37:24.523376	Training Loss1 11.8476 (12.1811)	Training Total_Loss 11.8476 (12.1811)	Training Prec@1 96.289 (96.923)	Training Prec@5 98.828 (98.573)	
2022-07-24 20:17:48,859: ============================================================
2022-07-24 20:18:29,583: time cost, forward:0.12437725534626082, backward:0.09701979585440006, data cost:0.18564328320294027 
2022-07-24 20:18:29,583: ============================================================
2022-07-24 20:18:29,583: Epoch 7/25 Batch 7600/7662 eta: 15:36:31.554173	Training Loss1 11.5728 (12.1813)	Training Total_Loss 11.5728 (12.1813)	Training Prec@1 96.875 (96.921)	Training Prec@5 98.242 (98.572)	
2022-07-24 20:18:29,583: ============================================================
2022-07-24 20:18:56,872: Epoch 7/25 Batch 7663/7662 eta: 15:36:05.897603	Training Loss1 12.1748 (12.1811)	Training Total_Loss 12.1748 (12.1811)	Training Prec@1 97.461 (96.920)	Training Prec@5 98.438 (98.571)	
2022-07-24 20:18:56,872: ============================================================
2022-07-24 20:19:39,369: time cost, forward:0.12434819972876346, backward:0.09685899272109523, data cost:0.2043808518034039 
2022-07-24 20:19:39,369: ============================================================
2022-07-24 20:19:39,369: Epoch 8/25 Batch 100/7662 eta: 16:13:36.926619	Training Loss1 11.8721 (10.9214)	Training Total_Loss 11.8721 (10.9214)	Training Prec@1 97.070 (97.733)	Training Prec@5 98.438 (99.008)	
2022-07-24 20:19:39,369: ============================================================
2022-07-24 20:20:20,102: time cost, forward:0.12426945791771664, backward:0.09695039921669504, data cost:0.19486277307098235 
2022-07-24 20:20:20,103: ============================================================
2022-07-24 20:20:20,103: Epoch 8/25 Batch 200/7662 eta: 15:34:57.218845	Training Loss1 11.3532 (10.9876)	Training Total_Loss 11.3532 (10.9876)	Training Prec@1 97.461 (97.745)	Training Prec@5 99.023 (98.992)	
2022-07-24 20:20:20,103: ============================================================
2022-07-24 20:21:00,850: time cost, forward:0.1242513505112766, backward:0.09697779444946493, data cost:0.19175121855974994 
2022-07-24 20:21:00,850: ============================================================
2022-07-24 20:21:00,850: Epoch 8/25 Batch 300/7662 eta: 15:34:35.248464	Training Loss1 11.4599 (11.0527)	Training Total_Loss 11.4599 (11.0527)	Training Prec@1 97.852 (97.735)	Training Prec@5 99.414 (98.998)	
2022-07-24 20:21:00,850: ============================================================
2022-07-24 20:21:41,641: time cost, forward:0.12431385702357854, backward:0.09698570880077238, data cost:0.19024284919700526 
2022-07-24 20:21:41,642: ============================================================
2022-07-24 20:21:41,642: Epoch 8/25 Batch 400/7662 eta: 15:34:55.571440	Training Loss1 11.0376 (11.1162)	Training Total_Loss 11.0376 (11.1162)	Training Prec@1 98.242 (97.706)	Training Prec@5 99.414 (98.987)	
2022-07-24 20:21:41,642: ============================================================
2022-07-24 20:22:22,471: time cost, forward:0.12441787308824803, backward:0.09698658715746923, data cost:0.18935711350374088 
2022-07-24 20:22:22,472: ============================================================
2022-07-24 20:22:22,472: Epoch 8/25 Batch 500/7662 eta: 15:35:07.254189	Training Loss1 10.8862 (11.1738)	Training Total_Loss 10.8862 (11.1738)	Training Prec@1 97.852 (97.690)	Training Prec@5 98.438 (98.976)	
2022-07-24 20:22:22,472: ============================================================
2022-07-24 20:23:03,310: time cost, forward:0.12449095683026194, backward:0.09700235858783499, data cost:0.18876323118830762 
2022-07-24 20:23:03,311: ============================================================
2022-07-24 20:23:03,311: Epoch 8/25 Batch 600/7662 eta: 15:34:39.113546	Training Loss1 11.5817 (11.2268)	Training Total_Loss 11.5817 (11.2268)	Training Prec@1 96.680 (97.668)	Training Prec@5 98.633 (98.959)	
2022-07-24 20:23:03,311: ============================================================
2022-07-24 20:23:44,113: time cost, forward:0.12450015527837095, backward:0.0970092058522848, data cost:0.18833667832894388 
2022-07-24 20:23:44,114: ============================================================
2022-07-24 20:23:44,114: Epoch 8/25 Batch 700/7662 eta: 15:33:08.312564	Training Loss1 11.2146 (11.2802)	Training Total_Loss 11.2146 (11.2802)	Training Prec@1 98.047 (97.638)	Training Prec@5 99.414 (98.947)	
2022-07-24 20:23:44,114: ============================================================
2022-07-24 20:24:24,892: time cost, forward:0.12447761176375484, backward:0.0970202157733139, data cost:0.18800895980959093 
2022-07-24 20:24:24,892: ============================================================
2022-07-24 20:24:24,892: Epoch 8/25 Batch 800/7662 eta: 15:31:54.308915	Training Loss1 12.0927 (11.3290)	Training Total_Loss 12.0927 (11.3290)	Training Prec@1 97.266 (97.602)	Training Prec@5 98.633 (98.927)	
2022-07-24 20:24:24,892: ============================================================
2022-07-24 20:25:05,668: time cost, forward:0.12445781732162459, backward:0.09702951863026858, data cost:0.18775294275251989 
2022-07-24 20:25:05,668: ============================================================
2022-07-24 20:25:05,668: Epoch 8/25 Batch 900/7662 eta: 15:31:09.993477	Training Loss1 11.3470 (11.3764)	Training Total_Loss 11.3470 (11.3764)	Training Prec@1 97.266 (97.565)	Training Prec@5 99.219 (98.911)	
2022-07-24 20:25:05,668: ============================================================
2022-07-24 20:25:46,443: time cost, forward:0.12444425297451688, backward:0.09704085847398301, data cost:0.18754136574280275 
2022-07-24 20:25:46,443: ============================================================
2022-07-24 20:25:46,443: Epoch 8/25 Batch 1000/7662 eta: 15:30:27.797851	Training Loss1 11.6371 (11.4153)	Training Total_Loss 11.6371 (11.4153)	Training Prec@1 97.461 (97.531)	Training Prec@5 99.023 (98.894)	
2022-07-24 20:25:46,443: ============================================================
2022-07-24 20:26:27,242: time cost, forward:0.12444993688151226, backward:0.09704558257084743, data cost:0.18737837051238876 
2022-07-24 20:26:27,242: ============================================================
2022-07-24 20:26:27,242: Epoch 8/25 Batch 1100/7662 eta: 15:30:19.993960	Training Loss1 12.0367 (11.4465)	Training Total_Loss 12.0367 (11.4465)	Training Prec@1 97.656 (97.517)	Training Prec@5 98.828 (98.887)	
2022-07-24 20:26:27,242: ============================================================
2022-07-24 20:27:08,036: time cost, forward:0.12444846266204859, backward:0.09704861867616732, data cost:0.18724228025377543 
2022-07-24 20:27:08,036: ============================================================
2022-07-24 20:27:08,036: Epoch 8/25 Batch 1200/7662 eta: 15:29:32.297980	Training Loss1 11.2524 (11.4836)	Training Total_Loss 11.2524 (11.4836)	Training Prec@1 98.047 (97.485)	Training Prec@5 98.828 (98.872)	
2022-07-24 20:27:08,036: ============================================================
2022-07-24 20:27:48,831: time cost, forward:0.12443486812758942, backward:0.09706332648690615, data cost:0.1871282114626537 
2022-07-24 20:27:48,831: ============================================================
2022-07-24 20:27:48,832: Epoch 8/25 Batch 1300/7662 eta: 15:28:53.573632	Training Loss1 12.0964 (11.5165)	Training Total_Loss 12.0964 (11.5165)	Training Prec@1 97.070 (97.469)	Training Prec@5 98.633 (98.864)	
2022-07-24 20:27:48,832: ============================================================
2022-07-24 20:28:29,616: time cost, forward:0.12441527937206734, backward:0.09707603836332243, data cost:0.18702952958925695 
2022-07-24 20:28:29,616: ============================================================
2022-07-24 20:28:29,616: Epoch 8/25 Batch 1400/7662 eta: 15:27:58.069942	Training Loss1 11.8114 (11.5425)	Training Total_Loss 11.8114 (11.5425)	Training Prec@1 97.656 (97.453)	Training Prec@5 99.414 (98.855)	
2022-07-24 20:28:29,617: ============================================================
2022-07-24 20:29:10,419: time cost, forward:0.12441664254212077, backward:0.09708401980282387, data cost:0.18694207189558665 
2022-07-24 20:29:10,419: ============================================================
2022-07-24 20:29:10,419: Epoch 8/25 Batch 1500/7662 eta: 15:27:41.645312	Training Loss1 11.4903 (11.5676)	Training Total_Loss 11.4903 (11.5676)	Training Prec@1 97.656 (97.435)	Training Prec@5 99.414 (98.847)	
2022-07-24 20:29:10,419: ============================================================
2022-07-24 20:29:51,200: time cost, forward:0.12441520664079105, backward:0.09708547756178369, data cost:0.18686050769312074 
2022-07-24 20:29:51,200: ============================================================
2022-07-24 20:29:51,200: Epoch 8/25 Batch 1600/7662 eta: 15:26:31.679386	Training Loss1 12.4151 (11.5899)	Training Total_Loss 12.4151 (11.5899)	Training Prec@1 96.875 (97.418)	Training Prec@5 98.242 (98.839)	
2022-07-24 20:29:51,200: ============================================================
2022-07-24 20:30:31,972: time cost, forward:0.12440705930856903, backward:0.09708973896931451, data cost:0.18678669174535614 
2022-07-24 20:30:31,973: ============================================================
2022-07-24 20:30:31,973: Epoch 8/25 Batch 1700/7662 eta: 15:25:39.358274	Training Loss1 12.1904 (11.6162)	Training Total_Loss 12.1904 (11.6162)	Training Prec@1 96.680 (97.403)	Training Prec@5 98.242 (98.830)	
2022-07-24 20:30:31,973: ============================================================
2022-07-24 20:31:12,724: time cost, forward:0.12440108987872901, backward:0.09708716287554603, data cost:0.18671520515704831 
2022-07-24 20:31:12,724: ============================================================
2022-07-24 20:31:12,724: Epoch 8/25 Batch 1800/7662 eta: 15:24:29.406911	Training Loss1 12.7166 (11.6367)	Training Total_Loss 12.7166 (11.6367)	Training Prec@1 95.312 (97.394)	Training Prec@5 98.047 (98.825)	
2022-07-24 20:31:12,724: ============================================================
2022-07-24 20:31:53,466: time cost, forward:0.12439571725123176, backward:0.09708739821065909, data cost:0.18664282996633166 
2022-07-24 20:31:53,466: ============================================================
2022-07-24 20:31:53,466: Epoch 8/25 Batch 1900/7662 eta: 15:23:35.843599	Training Loss1 12.3832 (11.6517)	Training Total_Loss 12.3832 (11.6517)	Training Prec@1 96.484 (97.381)	Training Prec@5 98.438 (98.817)	
2022-07-24 20:31:53,466: ============================================================
2022-07-24 20:32:34,202: time cost, forward:0.12438765342620804, backward:0.09708418817505829, data cost:0.18658235193551212 
2022-07-24 20:32:34,202: ============================================================
2022-07-24 20:32:34,202: Epoch 8/25 Batch 2000/7662 eta: 15:22:47.296646	Training Loss1 12.3563 (11.6755)	Training Total_Loss 12.3563 (11.6755)	Training Prec@1 96.875 (97.363)	Training Prec@5 98.242 (98.809)	
2022-07-24 20:32:34,202: ============================================================
2022-07-24 20:33:14,950: time cost, forward:0.12437848070225527, backward:0.09708608281561282, data cost:0.18652963388414823 
2022-07-24 20:33:14,951: ============================================================
2022-07-24 20:33:14,951: Epoch 8/25 Batch 2100/7662 eta: 15:22:23.747558	Training Loss1 12.3265 (11.6943)	Training Total_Loss 12.3265 (11.6943)	Training Prec@1 97.266 (97.351)	Training Prec@5 99.219 (98.803)	
2022-07-24 20:33:14,951: ============================================================
2022-07-24 20:33:55,692: time cost, forward:0.12437352368700445, backward:0.09708452755996128, data cost:0.18647977751783482 
2022-07-24 20:33:55,692: ============================================================
2022-07-24 20:33:55,692: Epoch 8/25 Batch 2200/7662 eta: 15:21:33.088031	Training Loss1 11.7694 (11.7130)	Training Total_Loss 11.7694 (11.7130)	Training Prec@1 97.852 (97.336)	Training Prec@5 99.023 (98.795)	
2022-07-24 20:33:55,693: ============================================================
2022-07-24 20:34:36,425: time cost, forward:0.1243703136137124, backward:0.09708102281428566, data cost:0.1864305452037345 
2022-07-24 20:34:36,425: ============================================================
2022-07-24 20:34:36,425: Epoch 8/25 Batch 2300/7662 eta: 15:20:40.564848	Training Loss1 11.9640 (11.7334)	Training Total_Loss 11.9640 (11.7334)	Training Prec@1 96.680 (97.321)	Training Prec@5 98.438 (98.786)	
2022-07-24 20:34:36,425: ============================================================
2022-07-24 20:35:17,142: time cost, forward:0.12435639605218045, backward:0.09708103352459632, data cost:0.1863866356225151 
2022-07-24 20:35:17,142: ============================================================
2022-07-24 20:35:17,142: Epoch 8/25 Batch 2400/7662 eta: 15:19:38.727979	Training Loss1 12.2872 (11.7461)	Training Total_Loss 12.2872 (11.7461)	Training Prec@1 96.484 (97.312)	Training Prec@5 98.242 (98.780)	
2022-07-24 20:35:17,142: ============================================================
2022-07-24 20:35:57,885: time cost, forward:0.12435574157565248, backward:0.09707757051871652, data cost:0.1863479266027395 
2022-07-24 20:35:57,885: ============================================================
2022-07-24 20:35:57,885: Epoch 8/25 Batch 2500/7662 eta: 15:19:32.910254	Training Loss1 12.4952 (11.7585)	Training Total_Loss 12.4952 (11.7585)	Training Prec@1 97.266 (97.300)	Training Prec@5 98.438 (98.776)	
2022-07-24 20:35:57,885: ============================================================
2022-07-24 20:36:38,630: time cost, forward:0.12435332359190673, backward:0.09707702192355688, data cost:0.1863121637797163 
2022-07-24 20:36:38,631: ============================================================
2022-07-24 20:36:38,631: Epoch 8/25 Batch 2600/7662 eta: 15:18:55.825480	Training Loss1 12.0393 (11.7685)	Training Total_Loss 12.0393 (11.7685)	Training Prec@1 97.070 (97.291)	Training Prec@5 98.242 (98.771)	
2022-07-24 20:36:38,631: ============================================================
2022-07-24 20:37:19,355: time cost, forward:0.12434706249781209, backward:0.09707379906475212, data cost:0.18627882613301852 
2022-07-24 20:37:19,356: ============================================================
2022-07-24 20:37:19,356: Epoch 8/25 Batch 2700/7662 eta: 15:17:46.716597	Training Loss1 12.1747 (11.7778)	Training Total_Loss 12.1747 (11.7778)	Training Prec@1 97.266 (97.284)	Training Prec@5 98.828 (98.767)	
2022-07-24 20:37:19,356: ============================================================
2022-07-24 20:38:00,081: time cost, forward:0.12434596672957605, backward:0.09706915502422152, data cost:0.186244591852306 
2022-07-24 20:38:00,082: ============================================================
2022-07-24 20:38:00,082: Epoch 8/25 Batch 2800/7662 eta: 15:17:07.748549	Training Loss1 12.1071 (11.7889)	Training Total_Loss 12.1071 (11.7889)	Training Prec@1 97.656 (97.270)	Training Prec@5 98.828 (98.761)	
2022-07-24 20:38:00,082: ============================================================
2022-07-24 20:38:40,762: time cost, forward:0.12433410809343541, backward:0.09706409193804116, data cost:0.18620910065549948 
2022-07-24 20:38:40,762: ============================================================
2022-07-24 20:38:40,762: Epoch 8/25 Batch 2900/7662 eta: 15:15:25.671203	Training Loss1 12.0170 (11.7978)	Training Total_Loss 12.0170 (11.7978)	Training Prec@1 97.266 (97.259)	Training Prec@5 98.828 (98.755)	
2022-07-24 20:38:40,762: ============================================================
2022-07-24 20:39:21,445: time cost, forward:0.12432197484623475, backward:0.0970594712041465, data cost:0.18617742114879562 
2022-07-24 20:39:21,445: ============================================================
2022-07-24 20:39:21,445: Epoch 8/25 Batch 3000/7662 eta: 15:14:48.337590	Training Loss1 11.5735 (11.8048)	Training Total_Loss 11.5735 (11.8048)	Training Prec@1 97.656 (97.251)	Training Prec@5 99.219 (98.750)	
2022-07-24 20:39:21,445: ============================================================
2022-07-24 20:40:02,188: time cost, forward:0.12432057929062082, backward:0.09705931788761794, data cost:0.1861528003935123 
2022-07-24 20:40:02,188: ============================================================
2022-07-24 20:40:02,188: Epoch 8/25 Batch 3100/7662 eta: 15:15:28.394887	Training Loss1 12.7605 (11.8154)	Training Total_Loss 12.7605 (11.8154)	Training Prec@1 95.508 (97.238)	Training Prec@5 97.461 (98.740)	
2022-07-24 20:40:02,188: ============================================================
2022-07-24 20:40:42,920: time cost, forward:0.12432206522937714, backward:0.09705614126932252, data cost:0.18612632881145472 
2022-07-24 20:40:42,921: ============================================================
2022-07-24 20:40:42,921: Epoch 8/25 Batch 3200/7662 eta: 15:14:33.552986	Training Loss1 11.9770 (11.8217)	Training Total_Loss 11.9770 (11.8217)	Training Prec@1 96.680 (97.234)	Training Prec@5 98.438 (98.738)	
2022-07-24 20:40:42,921: ============================================================
2022-07-24 20:41:23,660: time cost, forward:0.12432488877688729, backward:0.09705297576185067, data cost:0.1861030230127562 
2022-07-24 20:41:23,660: ============================================================
2022-07-24 20:41:23,660: Epoch 8/25 Batch 3300/7662 eta: 15:14:02.078702	Training Loss1 11.4044 (11.8288)	Training Total_Loss 11.4044 (11.8288)	Training Prec@1 97.852 (97.230)	Training Prec@5 99.805 (98.737)	
2022-07-24 20:41:23,660: ============================================================
2022-07-24 20:42:04,402: time cost, forward:0.12432945654931647, backward:0.09704991150126804, data cost:0.18608002832406548 
2022-07-24 20:42:04,402: ============================================================
2022-07-24 20:42:04,403: Epoch 8/25 Batch 3400/7662 eta: 15:13:25.601323	Training Loss1 12.2436 (11.8338)	Training Total_Loss 12.2436 (11.8338)	Training Prec@1 96.875 (97.223)	Training Prec@5 98.438 (98.736)	
2022-07-24 20:42:04,403: ============================================================
2022-07-24 20:42:45,147: time cost, forward:0.12433314902607323, backward:0.09704858870395901, data cost:0.18605834778869926 
2022-07-24 20:42:45,147: ============================================================
2022-07-24 20:42:45,147: Epoch 8/25 Batch 3500/7662 eta: 15:12:47.615220	Training Loss1 12.6247 (11.8410)	Training Total_Loss 12.6247 (11.8410)	Training Prec@1 96.484 (97.210)	Training Prec@5 98.438 (98.729)	
2022-07-24 20:42:45,147: ============================================================
2022-07-24 20:43:25,833: time cost, forward:0.12432214093559416, backward:0.09704624695657325, data cost:0.18603716674331958 
2022-07-24 20:43:25,833: ============================================================
2022-07-24 20:43:25,833: Epoch 8/25 Batch 3600/7662 eta: 15:10:48.168332	Training Loss1 11.5040 (11.8471)	Training Total_Loss 11.5040 (11.8471)	Training Prec@1 97.656 (97.202)	Training Prec@5 98.828 (98.727)	
2022-07-24 20:43:25,833: ============================================================
2022-07-24 20:44:06,559: time cost, forward:0.12431792666313293, backward:0.09704454378941214, data cost:0.186020684261585 
2022-07-24 20:44:06,559: ============================================================
2022-07-24 20:44:06,559: Epoch 8/25 Batch 3700/7662 eta: 15:11:01.595993	Training Loss1 12.0143 (11.8503)	Training Total_Loss 12.0143 (11.8503)	Training Prec@1 97.266 (97.199)	Training Prec@5 98.438 (98.726)	
2022-07-24 20:44:06,559: ============================================================
2022-07-24 20:44:47,286: time cost, forward:0.1243153177584181, backward:0.09704398587993271, data cost:0.18600439134162486 
2022-07-24 20:44:47,287: ============================================================
2022-07-24 20:44:47,287: Epoch 8/25 Batch 3800/7662 eta: 15:10:22.343162	Training Loss1 12.1572 (11.8546)	Training Total_Loss 12.1572 (11.8546)	Training Prec@1 96.094 (97.195)	Training Prec@5 97.852 (98.723)	
2022-07-24 20:44:47,287: ============================================================
2022-07-24 20:45:27,997: time cost, forward:0.12431204242564434, backward:0.0970429543746866, data cost:0.18598509544163186 
2022-07-24 20:45:27,997: ============================================================
2022-07-24 20:45:27,997: Epoch 8/25 Batch 3900/7662 eta: 15:09:19.014432	Training Loss1 12.4682 (11.8595)	Training Total_Loss 12.4682 (11.8595)	Training Prec@1 97.266 (97.191)	Training Prec@5 98.242 (98.721)	
2022-07-24 20:45:27,997: ============================================================
2022-07-24 20:46:08,707: time cost, forward:0.12430878846935703, backward:0.09704044223517351, data cost:0.18596809856532126 
2022-07-24 20:46:08,707: ============================================================
2022-07-24 20:46:08,708: Epoch 8/25 Batch 4000/7662 eta: 15:08:38.071476	Training Loss1 11.6750 (11.8613)	Training Total_Loss 11.6750 (11.8613)	Training Prec@1 96.680 (97.191)	Training Prec@5 98.633 (98.721)	
2022-07-24 20:46:08,708: ============================================================
2022-07-24 20:46:49,443: time cost, forward:0.12430507661540731, backward:0.09704112459840238, data cost:0.18595603629710414 
2022-07-24 20:46:49,443: ============================================================
2022-07-24 20:46:49,444: Epoch 8/25 Batch 4100/7662 eta: 15:08:31.516132	Training Loss1 11.6928 (11.8656)	Training Total_Loss 11.6928 (11.8656)	Training Prec@1 97.852 (97.186)	Training Prec@5 99.023 (98.719)	
2022-07-24 20:46:49,444: ============================================================
2022-07-24 20:47:30,193: time cost, forward:0.12430671749582856, backward:0.097040419522908, data cost:0.18594402391361492 
2022-07-24 20:47:30,193: ============================================================
2022-07-24 20:47:30,193: Epoch 8/25 Batch 4200/7662 eta: 15:08:09.529255	Training Loss1 11.6697 (11.8712)	Training Total_Loss 11.6697 (11.8712)	Training Prec@1 97.266 (97.180)	Training Prec@5 98.047 (98.716)	
2022-07-24 20:47:30,194: ============================================================
2022-07-24 20:48:10,903: time cost, forward:0.1242994109151751, backward:0.09703979904803045, data cost:0.18593209170829308 
2022-07-24 20:48:10,903: ============================================================
2022-07-24 20:48:10,904: Epoch 8/25 Batch 4300/7662 eta: 15:06:35.814291	Training Loss1 12.4390 (11.8764)	Training Total_Loss 12.4390 (11.8764)	Training Prec@1 96.484 (97.175)	Training Prec@5 97.461 (98.714)	
2022-07-24 20:48:10,904: ============================================================
2022-07-24 20:48:51,636: time cost, forward:0.12429631241453483, backward:0.0970384211777611, data cost:0.18592252143813037 
2022-07-24 20:48:51,637: ============================================================
2022-07-24 20:48:51,637: Epoch 8/25 Batch 4400/7662 eta: 15:06:25.789716	Training Loss1 12.7151 (11.8810)	Training Total_Loss 12.7151 (11.8810)	Training Prec@1 96.680 (97.172)	Training Prec@5 98.242 (98.712)	
2022-07-24 20:48:51,637: ============================================================
2022-07-24 20:49:32,396: time cost, forward:0.12429955085666212, backward:0.09703658299595548, data cost:0.1859137243523972 
2022-07-24 20:49:32,396: ============================================================
2022-07-24 20:49:32,396: Epoch 8/25 Batch 4500/7662 eta: 15:06:19.711853	Training Loss1 12.2086 (11.8849)	Training Total_Loss 12.2086 (11.8849)	Training Prec@1 97.461 (97.169)	Training Prec@5 98.438 (98.710)	
2022-07-24 20:49:32,396: ============================================================
2022-07-24 20:50:13,137: time cost, forward:0.1242979722169203, backward:0.09703523803208283, data cost:0.1859053935038315 
2022-07-24 20:50:13,137: ============================================================
2022-07-24 20:50:13,138: Epoch 8/25 Batch 4600/7662 eta: 15:05:15.369580	Training Loss1 12.7490 (11.8881)	Training Total_Loss 12.7490 (11.8881)	Training Prec@1 96.094 (97.168)	Training Prec@5 97.852 (98.709)	
2022-07-24 20:50:13,138: ============================================================
2022-07-24 20:50:53,921: time cost, forward:0.12430283774160583, backward:0.09703470341929428, data cost:0.18589979994928718 
2022-07-24 20:50:53,922: ============================================================
2022-07-24 20:50:53,922: Epoch 8/25 Batch 4700/7662 eta: 15:05:31.425082	Training Loss1 11.5333 (11.8908)	Training Total_Loss 11.5333 (11.8908)	Training Prec@1 97.266 (97.165)	Training Prec@5 99.023 (98.708)	
2022-07-24 20:50:53,922: ============================================================
2022-07-24 20:51:34,706: time cost, forward:0.124306277201359, backward:0.09703397795567291, data cost:0.18589596411515633 
2022-07-24 20:51:34,707: ============================================================
2022-07-24 20:51:34,707: Epoch 8/25 Batch 4800/7662 eta: 15:04:51.813949	Training Loss1 12.5791 (11.8948)	Training Total_Loss 12.5791 (11.8948)	Training Prec@1 96.094 (97.159)	Training Prec@5 98.242 (98.704)	
2022-07-24 20:51:34,707: ============================================================
2022-07-24 20:52:15,484: time cost, forward:0.12430819639699218, backward:0.09703353872881249, data cost:0.18589159069462294 
2022-07-24 20:52:15,484: ============================================================
2022-07-24 20:52:15,484: Epoch 8/25 Batch 4900/7662 eta: 15:04:01.164995	Training Loss1 12.2574 (11.8968)	Training Total_Loss 12.2574 (11.8968)	Training Prec@1 96.289 (97.155)	Training Prec@5 98.242 (98.702)	
2022-07-24 20:52:15,485: ============================================================
2022-07-24 20:52:56,274: time cost, forward:0.12431163448265825, backward:0.09703354869849397, data cost:0.18588812276348396 
2022-07-24 20:52:56,275: ============================================================
2022-07-24 20:52:56,275: Epoch 8/25 Batch 5000/7662 eta: 15:03:37.223260	Training Loss1 11.3452 (11.9007)	Training Total_Loss 11.3452 (11.9007)	Training Prec@1 98.633 (97.152)	Training Prec@5 99.609 (98.700)	
2022-07-24 20:52:56,275: ============================================================
2022-07-24 20:53:37,064: time cost, forward:0.1243154454123719, backward:0.09703390896145, data cost:0.18588412118954012 
2022-07-24 20:53:37,064: ============================================================
2022-07-24 20:53:37,064: Epoch 8/25 Batch 5100/7662 eta: 15:02:55.248349	Training Loss1 11.7918 (11.9039)	Training Total_Loss 11.7918 (11.9039)	Training Prec@1 96.875 (97.149)	Training Prec@5 98.828 (98.698)	
2022-07-24 20:53:37,064: ============================================================
2022-07-24 20:54:17,847: time cost, forward:0.12431695209509777, backward:0.09703520592140863, data cost:0.18588007608499177 
2022-07-24 20:54:17,848: ============================================================
2022-07-24 20:54:17,848: Epoch 8/25 Batch 5200/7662 eta: 15:02:06.851538	Training Loss1 11.8164 (11.9078)	Training Total_Loss 11.8164 (11.9078)	Training Prec@1 97.656 (97.144)	Training Prec@5 99.023 (98.695)	
2022-07-24 20:54:17,848: ============================================================
2022-07-24 20:54:58,633: time cost, forward:0.12431965622953209, backward:0.09703637631710216, data cost:0.18587534804235295 
2022-07-24 20:54:58,634: ============================================================
2022-07-24 20:54:58,634: Epoch 8/25 Batch 5300/7662 eta: 15:01:29.057709	Training Loss1 12.6132 (11.9095)	Training Total_Loss 12.6132 (11.9095)	Training Prec@1 96.875 (97.143)	Training Prec@5 99.023 (98.694)	
2022-07-24 20:54:58,634: ============================================================
2022-07-24 20:55:39,408: time cost, forward:0.12431935249246653, backward:0.0970379287919682, data cost:0.18587181519128412 
2022-07-24 20:55:39,409: ============================================================
2022-07-24 20:55:39,409: Epoch 8/25 Batch 5400/7662 eta: 15:00:34.063424	Training Loss1 11.5028 (11.9113)	Training Total_Loss 11.5028 (11.9113)	Training Prec@1 97.656 (97.145)	Training Prec@5 98.828 (98.695)	
2022-07-24 20:55:39,409: ============================================================
2022-07-24 20:56:20,241: time cost, forward:0.1243285527119183, backward:0.09703777447291387, data cost:0.18587095426589625 
2022-07-24 20:56:20,242: ============================================================
2022-07-24 20:56:20,242: Epoch 8/25 Batch 5500/7662 eta: 15:01:09.610648	Training Loss1 12.4801 (11.9128)	Training Total_Loss 12.4801 (11.9128)	Training Prec@1 97.070 (97.143)	Training Prec@5 98.438 (98.693)	
2022-07-24 20:56:20,242: ============================================================
2022-07-24 20:57:01,069: time cost, forward:0.12433745218485802, backward:0.09703730979036446, data cost:0.18586979267490317 
2022-07-24 20:57:01,070: ============================================================
2022-07-24 20:57:01,070: Epoch 8/25 Batch 5600/7662 eta: 15:00:22.266866	Training Loss1 12.1739 (11.9153)	Training Total_Loss 12.1739 (11.9153)	Training Prec@1 96.289 (97.141)	Training Prec@5 98.828 (98.692)	
2022-07-24 20:57:01,070: ============================================================
2022-07-24 20:57:41,925: time cost, forward:0.12435129396244818, backward:0.09703608524759604, data cost:0.18586906773476333 
2022-07-24 20:57:41,926: ============================================================
2022-07-24 20:57:41,926: Epoch 8/25 Batch 5700/7662 eta: 15:00:18.834047	Training Loss1 12.0540 (11.9164)	Training Total_Loss 12.0540 (11.9164)	Training Prec@1 97.266 (97.138)	Training Prec@5 98.438 (98.691)	
2022-07-24 20:57:41,926: ============================================================
2022-07-24 20:58:22,793: time cost, forward:0.12436270504126078, backward:0.09703709244995327, data cost:0.18587017281340368 
2022-07-24 20:58:22,793: ============================================================
2022-07-24 20:58:22,793: Epoch 8/25 Batch 5800/7662 eta: 14:59:53.051140	Training Loss1 12.2219 (11.9165)	Training Total_Loss 12.2219 (11.9165)	Training Prec@1 96.875 (97.137)	Training Prec@5 98.633 (98.690)	
2022-07-24 20:58:22,794: ============================================================
2022-07-24 20:59:03,670: time cost, forward:0.1243769746247864, backward:0.09703599778165815, data cost:0.18587103874567384 
2022-07-24 20:59:03,670: ============================================================
2022-07-24 20:59:03,670: Epoch 8/25 Batch 5900/7662 eta: 14:59:24.295549	Training Loss1 11.6143 (11.9177)	Training Total_Loss 11.6143 (11.9177)	Training Prec@1 98.047 (97.135)	Training Prec@5 99.414 (98.688)	
2022-07-24 20:59:03,670: ============================================================
2022-07-24 20:59:44,478: time cost, forward:0.1243821784523571, backward:0.09703545932830185, data cost:0.18586815860116854 
2022-07-24 20:59:44,479: ============================================================
2022-07-24 20:59:44,479: Epoch 8/25 Batch 6000/7662 eta: 14:57:13.412230	Training Loss1 12.2855 (11.9198)	Training Total_Loss 12.2855 (11.9198)	Training Prec@1 96.680 (97.132)	Training Prec@5 98.242 (98.688)	
2022-07-24 20:59:44,479: ============================================================
2022-07-24 21:00:25,289: time cost, forward:0.12438848753955876, backward:0.09703432980043455, data cost:0.18586535734472792 
2022-07-24 21:00:25,289: ============================================================
2022-07-24 21:00:25,289: Epoch 8/25 Batch 6100/7662 eta: 14:56:35.244545	Training Loss1 12.4631 (11.9216)	Training Total_Loss 12.4631 (11.9216)	Training Prec@1 96.289 (97.128)	Training Prec@5 98.047 (98.687)	
2022-07-24 21:00:25,289: ============================================================
2022-07-24 21:01:06,115: time cost, forward:0.12439745236720014, backward:0.0970331103325967, data cost:0.18586234251017109 
2022-07-24 21:01:06,115: ============================================================
2022-07-24 21:01:06,115: Epoch 8/25 Batch 6200/7662 eta: 14:56:14.454218	Training Loss1 12.7684 (11.9214)	Training Total_Loss 12.7684 (11.9214)	Training Prec@1 97.852 (97.129)	Training Prec@5 98.242 (98.687)	
2022-07-24 21:01:06,115: ============================================================
2022-07-24 21:01:46,885: time cost, forward:0.12439961114711734, backward:0.09703198529970344, data cost:0.1858569366777865 
2022-07-24 21:01:46,885: ============================================================
2022-07-24 21:01:46,885: Epoch 8/25 Batch 6300/7662 eta: 14:54:20.255268	Training Loss1 12.2821 (11.9232)	Training Total_Loss 12.2821 (11.9232)	Training Prec@1 97.461 (97.125)	Training Prec@5 98.828 (98.686)	
2022-07-24 21:01:46,885: ============================================================
2022-07-24 21:02:27,616: time cost, forward:0.12439527454218244, backward:0.09703079915303778, data cost:0.18585205111657851 
2022-07-24 21:02:27,617: ============================================================
2022-07-24 21:02:27,617: Epoch 8/25 Batch 6400/7662 eta: 14:52:48.969653	Training Loss1 11.4256 (11.9255)	Training Total_Loss 11.4256 (11.9255)	Training Prec@1 98.438 (97.122)	Training Prec@5 99.805 (98.685)	
2022-07-24 21:02:27,617: ============================================================
2022-07-24 21:03:08,389: time cost, forward:0.12439670550271097, backward:0.0970310079334222, data cost:0.185846758064884 
2022-07-24 21:03:08,389: ============================================================
2022-07-24 21:03:08,389: Epoch 8/25 Batch 6500/7662 eta: 14:53:01.984469	Training Loss1 11.4671 (11.9269)	Training Total_Loss 11.4671 (11.9269)	Training Prec@1 97.266 (97.119)	Training Prec@5 97.852 (98.683)	
2022-07-24 21:03:08,389: ============================================================
2022-07-24 21:03:49,129: time cost, forward:0.12439807358429746, backward:0.09702975339177053, data cost:0.1858384662332779 
2022-07-24 21:03:49,130: ============================================================
2022-07-24 21:03:49,130: Epoch 8/25 Batch 6600/7662 eta: 14:51:39.242425	Training Loss1 12.1526 (11.9279)	Training Total_Loss 12.1526 (11.9279)	Training Prec@1 96.094 (97.117)	Training Prec@5 97.852 (98.682)	
2022-07-24 21:03:49,130: ============================================================
2022-07-24 21:04:29,855: time cost, forward:0.1243958188840072, backward:0.09702889580106643, data cost:0.18583119205617785 
2022-07-24 21:04:29,855: ============================================================
2022-07-24 21:04:29,855: Epoch 8/25 Batch 6700/7662 eta: 14:50:38.615857	Training Loss1 11.8823 (11.9288)	Training Total_Loss 11.8823 (11.9288)	Training Prec@1 96.484 (97.116)	Training Prec@5 98.242 (98.681)	
2022-07-24 21:04:29,855: ============================================================
2022-07-24 21:05:10,591: time cost, forward:0.12439518834689309, backward:0.09702815731091786, data cost:0.18582412852559269 
2022-07-24 21:05:10,591: ============================================================
2022-07-24 21:05:10,591: Epoch 8/25 Batch 6800/7662 eta: 14:50:12.088479	Training Loss1 11.2959 (11.9301)	Training Total_Loss 11.2959 (11.9301)	Training Prec@1 97.070 (97.114)	Training Prec@5 98.828 (98.679)	
2022-07-24 21:05:10,591: ============================================================
2022-07-24 21:05:51,312: time cost, forward:0.12439183367043409, backward:0.09702818907591065, data cost:0.1858171204377437 
2022-07-24 21:05:51,313: ============================================================
2022-07-24 21:05:51,313: Epoch 8/25 Batch 6900/7662 eta: 14:49:11.862020	Training Loss1 11.4980 (11.9313)	Training Total_Loss 11.4980 (11.9313)	Training Prec@1 96.680 (97.113)	Training Prec@5 98.438 (98.679)	
2022-07-24 21:05:51,313: ============================================================
2022-07-24 21:06:32,021: time cost, forward:0.1243884634981838, backward:0.0970272611832513, data cost:0.18580949461482255 
2022-07-24 21:06:32,021: ============================================================
2022-07-24 21:06:32,022: Epoch 8/25 Batch 7000/7662 eta: 14:48:14.895863	Training Loss1 11.2916 (11.9324)	Training Total_Loss 11.2916 (11.9324)	Training Prec@1 97.461 (97.112)	Training Prec@5 98.633 (98.677)	
2022-07-24 21:06:32,022: ============================================================
2022-07-24 21:07:12,760: time cost, forward:0.12438801524168606, backward:0.09702728143593412, data cost:0.18580249605556326 
2022-07-24 21:07:12,760: ============================================================
2022-07-24 21:07:12,760: Epoch 8/25 Batch 7100/7662 eta: 14:48:12.711847	Training Loss1 11.6438 (11.9337)	Training Total_Loss 11.6438 (11.9337)	Training Prec@1 97.656 (97.108)	Training Prec@5 98.828 (98.676)	
2022-07-24 21:07:12,760: ============================================================
2022-07-24 21:07:53,458: time cost, forward:0.12438277202043985, backward:0.09702696994305121, data cost:0.18579552574014643 
2022-07-24 21:07:53,458: ============================================================
2022-07-24 21:07:53,458: Epoch 8/25 Batch 7200/7662 eta: 14:46:39.420576	Training Loss1 12.4447 (11.9344)	Training Total_Loss 12.4447 (11.9344)	Training Prec@1 97.070 (97.108)	Training Prec@5 98.242 (98.676)	
2022-07-24 21:07:53,458: ============================================================
2022-07-24 21:08:34,187: time cost, forward:0.12438275360345742, backward:0.0970258387102952, data cost:0.18578832292249717 
2022-07-24 21:08:34,187: ============================================================
2022-07-24 21:08:34,187: Epoch 8/25 Batch 7300/7662 eta: 14:46:39.311022	Training Loss1 11.6314 (11.9349)	Training Total_Loss 11.6314 (11.9349)	Training Prec@1 97.852 (97.107)	Training Prec@5 99.023 (98.676)	
2022-07-24 21:08:34,188: ============================================================
2022-07-24 21:09:14,897: time cost, forward:0.12437871524265834, backward:0.09702552581320004, data cost:0.1857820234519112 
2022-07-24 21:09:14,898: ============================================================
2022-07-24 21:09:14,898: Epoch 8/25 Batch 7400/7662 eta: 14:45:33.948095	Training Loss1 12.5392 (11.9349)	Training Total_Loss 12.5392 (11.9349)	Training Prec@1 96.680 (97.105)	Training Prec@5 98.633 (98.674)	
2022-07-24 21:09:14,898: ============================================================
2022-07-24 21:09:55,644: time cost, forward:0.1243794484843666, backward:0.09702583334734956, data cost:0.18577568097692568 
2022-07-24 21:09:55,644: ============================================================
2022-07-24 21:09:55,645: Epoch 8/25 Batch 7500/7662 eta: 14:45:40.804146	Training Loss1 11.2356 (11.9363)	Training Total_Loss 11.2356 (11.9363)	Training Prec@1 97.656 (97.103)	Training Prec@5 99.414 (98.674)	
2022-07-24 21:09:55,645: ============================================================
2022-07-24 21:10:36,369: time cost, forward:0.1243785535493859, backward:0.09702499848727349, data cost:0.18576964329286444 
2022-07-24 21:10:36,369: ============================================================
2022-07-24 21:10:36,370: Epoch 8/25 Batch 7600/7662 eta: 14:44:31.512062	Training Loss1 11.8287 (11.9366)	Training Total_Loss 11.8287 (11.9366)	Training Prec@1 97.852 (97.104)	Training Prec@5 99.219 (98.675)	
2022-07-24 21:10:36,370: ============================================================
2022-07-24 21:11:03,353: Epoch 8/25 Batch 7663/7662 eta: 14:44:05.855354	Training Loss1 12.6544 (11.9365)	Training Total_Loss 12.6544 (11.9365)	Training Prec@1 96.680 (97.103)	Training Prec@5 98.242 (98.674)	
2022-07-24 21:11:03,353: ============================================================
2022-07-24 21:11:45,696: time cost, forward:0.12453044785393609, backward:0.09700565145473287, data cost:0.20215595852244983 
2022-07-24 21:11:45,697: ============================================================
2022-07-24 21:11:45,697: Epoch 9/25 Batch 100/7662 eta: 15:15:23.285344	Training Loss1 10.8714 (10.7013)	Training Total_Loss 10.8714 (10.7013)	Training Prec@1 97.656 (97.986)	Training Prec@5 99.414 (99.136)	
2022-07-24 21:11:45,697: ============================================================
2022-07-24 21:12:26,426: time cost, forward:0.12444674669198655, backward:0.09698673468738345, data cost:0.19367032674089749 
2022-07-24 21:12:26,426: ============================================================
2022-07-24 21:12:26,426: Epoch 9/25 Batch 200/7662 eta: 14:42:50.564322	Training Loss1 11.1800 (10.7675)	Training Total_Loss 11.1800 (10.7675)	Training Prec@1 97.656 (97.947)	Training Prec@5 99.219 (99.127)	
2022-07-24 21:12:26,426: ============================================================
2022-07-24 21:13:07,166: time cost, forward:0.12442357803268178, backward:0.09698669168861415, data cost:0.19089450644808867 
2022-07-24 21:13:07,166: ============================================================
2022-07-24 21:13:07,167: Epoch 9/25 Batch 300/7662 eta: 14:42:23.997298	Training Loss1 11.1400 (10.8303)	Training Total_Loss 11.1400 (10.8303)	Training Prec@1 97.461 (97.893)	Training Prec@5 98.828 (99.087)	
2022-07-24 21:13:07,167: ============================================================
2022-07-24 21:13:47,889: time cost, forward:0.12436537157025254, backward:0.09699955918735131, data cost:0.18949667194433378 
2022-07-24 21:13:47,889: ============================================================
2022-07-24 21:13:47,890: Epoch 9/25 Batch 400/7662 eta: 14:41:20.946761	Training Loss1 11.2370 (10.9007)	Training Total_Loss 11.2370 (10.9007)	Training Prec@1 98.242 (97.835)	Training Prec@5 99.219 (99.068)	
2022-07-24 21:13:47,890: ============================================================
2022-07-24 21:14:28,624: time cost, forward:0.12435488280409085, backward:0.09699763707025257, data cost:0.18867452493411505 
2022-07-24 21:14:28,624: ============================================================
2022-07-24 21:14:28,625: Epoch 9/25 Batch 500/7662 eta: 14:40:55.798728	Training Loss1 11.1727 (10.9686)	Training Total_Loss 11.1727 (10.9686)	Training Prec@1 97.656 (97.801)	Training Prec@5 98.242 (99.047)	
2022-07-24 21:14:28,625: ============================================================
2022-07-24 21:15:09,321: time cost, forward:0.12428215628673318, backward:0.09700409478456627, data cost:0.18812078346991182 
2022-07-24 21:15:09,321: ============================================================
2022-07-24 21:15:09,321: Epoch 9/25 Batch 600/7662 eta: 14:39:25.057976	Training Loss1 11.1135 (11.0150)	Training Total_Loss 11.1135 (11.0150)	Training Prec@1 97.070 (97.774)	Training Prec@5 98.633 (99.028)	
2022-07-24 21:15:09,321: ============================================================
2022-07-24 21:15:50,002: time cost, forward:0.12423005295072673, backward:0.09700507428683607, data cost:0.18770820559009121 
2022-07-24 21:15:50,002: ============================================================
2022-07-24 21:15:50,003: Epoch 9/25 Batch 700/7662 eta: 14:38:24.868776	Training Loss1 10.8695 (11.0692)	Training Total_Loss 10.8695 (11.0692)	Training Prec@1 98.242 (97.748)	Training Prec@5 99.219 (99.018)	
2022-07-24 21:15:50,003: ============================================================
2022-07-24 21:16:30,710: time cost, forward:0.12420526404255472, backward:0.0970012019662296, data cost:0.1874192918794176 
2022-07-24 21:16:30,711: ============================================================
2022-07-24 21:16:30,711: Epoch 9/25 Batch 800/7662 eta: 14:38:18.641947	Training Loss1 11.5606 (11.1268)	Training Total_Loss 11.5606 (11.1268)	Training Prec@1 96.484 (97.719)	Training Prec@5 98.633 (98.999)	
2022-07-24 21:16:30,711: ============================================================
2022-07-24 21:17:11,427: time cost, forward:0.12419702001620453, backward:0.09699919597723328, data cost:0.1871922164658153 
2022-07-24 21:17:11,427: ============================================================
2022-07-24 21:17:11,427: Epoch 9/25 Batch 900/7662 eta: 14:37:48.608738	Training Loss1 10.8254 (11.1723)	Training Total_Loss 10.8254 (11.1723)	Training Prec@1 98.242 (97.693)	Training Prec@5 99.609 (98.992)	
2022-07-24 21:17:11,427: ============================================================
2022-07-24 21:17:52,144: time cost, forward:0.12419261015929259, backward:0.096995405726008, data cost:0.18701073595950077 
2022-07-24 21:17:52,144: ============================================================
2022-07-24 21:17:52,144: Epoch 9/25 Batch 1000/7662 eta: 14:37:08.914909	Training Loss1 11.0324 (11.2110)	Training Total_Loss 11.0324 (11.2110)	Training Prec@1 97.852 (97.677)	Training Prec@5 99.023 (98.981)	
2022-07-24 21:17:52,144: ============================================================
2022-07-24 21:18:32,873: time cost, forward:0.12419316289205785, backward:0.09699704106880166, data cost:0.1868667977847654 
2022-07-24 21:18:32,873: ============================================================
2022-07-24 21:18:32,873: Epoch 9/25 Batch 1100/7662 eta: 14:36:43.238913	Training Loss1 11.7840 (11.2406)	Training Total_Loss 11.7840 (11.2406)	Training Prec@1 97.852 (97.667)	Training Prec@5 99.805 (98.980)	
2022-07-24 21:18:32,873: ============================================================
2022-07-24 21:19:13,615: time cost, forward:0.12419730549160891, backward:0.09699779833426965, data cost:0.18675218093782986 
2022-07-24 21:19:13,616: ============================================================
2022-07-24 21:19:13,616: Epoch 9/25 Batch 1200/7662 eta: 14:36:20.652229	Training Loss1 11.6971 (11.2785)	Training Total_Loss 11.6971 (11.2785)	Training Prec@1 97.656 (97.642)	Training Prec@5 98.828 (98.968)	
2022-07-24 21:19:13,616: ============================================================
2022-07-24 21:19:54,377: time cost, forward:0.12421224188859689, backward:0.0970060214159395, data cost:0.1866545645983243 
2022-07-24 21:19:54,377: ============================================================
2022-07-24 21:19:54,377: Epoch 9/25 Batch 1300/7662 eta: 14:36:03.988483	Training Loss1 11.5029 (11.3130)	Training Total_Loss 11.5029 (11.3130)	Training Prec@1 97.070 (97.620)	Training Prec@5 98.633 (98.952)	
2022-07-24 21:19:54,377: ============================================================
2022-07-24 21:20:35,131: time cost, forward:0.12422645134615677, backward:0.09700778248141373, data cost:0.1865666624986759 
2022-07-24 21:20:35,131: ============================================================
2022-07-24 21:20:35,131: Epoch 9/25 Batch 1400/7662 eta: 14:35:13.842512	Training Loss1 11.9753 (11.3403)	Training Total_Loss 11.9753 (11.3403)	Training Prec@1 96.484 (97.604)	Training Prec@5 98.438 (98.947)	
2022-07-24 21:20:35,132: ============================================================
2022-07-24 21:21:15,868: time cost, forward:0.12421987118762362, backward:0.09701110952452392, data cost:0.1864978056736514 
2022-07-24 21:21:15,868: ============================================================
2022-07-24 21:21:15,868: Epoch 9/25 Batch 1500/7662 eta: 14:34:10.690727	Training Loss1 11.4913 (11.3673)	Training Total_Loss 11.4913 (11.3673)	Training Prec@1 97.852 (97.584)	Training Prec@5 99.219 (98.935)	
2022-07-24 21:21:15,868: ============================================================
2022-07-24 21:21:56,627: time cost, forward:0.12422792772862075, backward:0.09701506684466106, data cost:0.18643676675506649 
2022-07-24 21:21:56,628: ============================================================
2022-07-24 21:21:56,628: Epoch 9/25 Batch 1600/7662 eta: 14:33:59.224633	Training Loss1 11.2563 (11.3888)	Training Total_Loss 11.2563 (11.3888)	Training Prec@1 98.438 (97.576)	Training Prec@5 99.219 (98.930)	
2022-07-24 21:21:56,628: ============================================================
2022-07-24 21:22:37,380: time cost, forward:0.12422568858406556, backward:0.09701632639462278, data cost:0.1863884243844466 
2022-07-24 21:22:37,380: ============================================================
2022-07-24 21:22:37,380: Epoch 9/25 Batch 1700/7662 eta: 14:33:08.871032	Training Loss1 12.5475 (11.4105)	Training Total_Loss 12.5475 (11.4105)	Training Prec@1 97.266 (97.561)	Training Prec@5 98.828 (98.919)	
2022-07-24 21:22:37,380: ============================================================
2022-07-24 21:23:18,137: time cost, forward:0.12422771451206854, backward:0.09702235225043475, data cost:0.18634083524155842 
2022-07-24 21:23:18,137: ============================================================
2022-07-24 21:23:18,137: Epoch 9/25 Batch 1800/7662 eta: 14:32:34.508439	Training Loss1 11.8113 (11.4362)	Training Total_Loss 11.8113 (11.4362)	Training Prec@1 96.289 (97.544)	Training Prec@5 98.438 (98.908)	
2022-07-24 21:23:18,137: ============================================================
2022-07-24 21:23:58,905: time cost, forward:0.12423119135691406, backward:0.09703084655408171, data cost:0.18630056961264468 
2022-07-24 21:23:58,905: ============================================================
2022-07-24 21:23:58,906: Epoch 9/25 Batch 1900/7662 eta: 14:32:08.368813	Training Loss1 11.4004 (11.4536)	Training Total_Loss 11.4004 (11.4536)	Training Prec@1 97.461 (97.526)	Training Prec@5 98.633 (98.898)	
2022-07-24 21:23:58,906: ============================================================
2022-07-24 21:24:39,679: time cost, forward:0.1242404480228548, backward:0.09703174944577544, data cost:0.18626818625911468 
2022-07-24 21:24:39,680: ============================================================
2022-07-24 21:24:39,680: Epoch 9/25 Batch 2000/7662 eta: 14:31:35.173996	Training Loss1 11.3663 (11.4723)	Training Total_Loss 11.3663 (11.4723)	Training Prec@1 98.438 (97.513)	Training Prec@5 99.609 (98.890)	
2022-07-24 21:24:39,680: ============================================================
2022-07-24 21:25:20,516: time cost, forward:0.12427388525622524, backward:0.09702681768162015, data cost:0.18624713047167527 
2022-07-24 21:25:20,516: ============================================================
2022-07-24 21:25:20,517: Epoch 9/25 Batch 2100/7662 eta: 14:32:14.276809	Training Loss1 12.6740 (11.4919)	Training Total_Loss 12.6740 (11.4919)	Training Prec@1 96.484 (97.495)	Training Prec@5 98.047 (98.883)	
2022-07-24 21:25:20,517: ============================================================
2022-07-24 21:26:01,320: time cost, forward:0.12429189291689927, backward:0.0970253112805112, data cost:0.18622363399732866 
2022-07-24 21:26:01,320: ============================================================
2022-07-24 21:26:01,320: Epoch 9/25 Batch 2200/7662 eta: 14:30:51.193568	Training Loss1 12.5066 (11.5051)	Training Total_Loss 12.5066 (11.5051)	Training Prec@1 96.680 (97.482)	Training Prec@5 98.242 (98.878)	
2022-07-24 21:26:01,320: ============================================================
2022-07-24 21:26:42,098: time cost, forward:0.12430106312775414, backward:0.09702548642633478, data cost:0.18619500838865036 
2022-07-24 21:26:42,098: ============================================================
2022-07-24 21:26:42,099: Epoch 9/25 Batch 2300/7662 eta: 14:29:37.612381	Training Loss1 12.2958 (11.5175)	Training Total_Loss 12.2958 (11.5175)	Training Prec@1 97.070 (97.468)	Training Prec@5 98.828 (98.874)	
2022-07-24 21:26:42,099: ============================================================
2022-07-24 21:27:22,883: time cost, forward:0.12430956861584223, backward:0.09702787174687579, data cost:0.18616916428709487 
2022-07-24 21:27:22,883: ============================================================
2022-07-24 21:27:22,883: Epoch 9/25 Batch 2400/7662 eta: 14:29:05.261008	Training Loss1 11.7152 (11.5361)	Training Total_Loss 11.7152 (11.5361)	Training Prec@1 97.852 (97.455)	Training Prec@5 98.438 (98.869)	
2022-07-24 21:27:22,883: ============================================================
2022-07-24 21:28:03,665: time cost, forward:0.12431388485188387, backward:0.09703263620130059, data cost:0.18614608748238676 
2022-07-24 21:28:03,665: ============================================================
2022-07-24 21:28:03,665: Epoch 9/25 Batch 2500/7662 eta: 14:28:20.813607	Training Loss1 11.5496 (11.5502)	Training Total_Loss 11.5496 (11.5502)	Training Prec@1 96.289 (97.443)	Training Prec@5 98.242 (98.862)	
2022-07-24 21:28:03,665: ============================================================
2022-07-24 21:28:44,457: time cost, forward:0.12432198076809585, backward:0.09703471597317045, data cost:0.1861272241666529 
2022-07-24 21:28:44,458: ============================================================
2022-07-24 21:28:44,458: Epoch 9/25 Batch 2600/7662 eta: 14:27:53.968731	Training Loss1 11.8635 (11.5616)	Training Total_Loss 11.8635 (11.5616)	Training Prec@1 96.680 (97.433)	Training Prec@5 99.023 (98.858)	
2022-07-24 21:28:44,458: ============================================================
2022-07-24 21:29:25,240: time cost, forward:0.12432391451835278, backward:0.09703797232269931, data cost:0.18610990882229037 
2022-07-24 21:29:25,241: ============================================================
2022-07-24 21:29:25,241: Epoch 9/25 Batch 2700/7662 eta: 14:27:01.006535	Training Loss1 11.1940 (11.5734)	Training Total_Loss 11.1940 (11.5734)	Training Prec@1 97.656 (97.422)	Training Prec@5 98.438 (98.852)	
2022-07-24 21:29:25,241: ============================================================
2022-07-24 21:30:06,019: time cost, forward:0.1243309839234347, backward:0.0970411296400184, data cost:0.1860876375541128 
2022-07-24 21:30:06,020: ============================================================
2022-07-24 21:30:06,020: Epoch 9/25 Batch 2800/7662 eta: 14:26:14.632924	Training Loss1 10.5669 (11.5804)	Training Total_Loss 10.5669 (11.5804)	Training Prec@1 97.852 (97.414)	Training Prec@5 98.633 (98.845)	
2022-07-24 21:30:06,020: ============================================================
2022-07-24 21:30:46,790: time cost, forward:0.12433827947279058, backward:0.09704100908843268, data cost:0.18606643250746002 
2022-07-24 21:30:46,790: ============================================================
2022-07-24 21:30:46,790: Epoch 9/25 Batch 2900/7662 eta: 14:25:23.496415	Training Loss1 12.0297 (11.5853)	Training Total_Loss 12.0297 (11.5853)	Training Prec@1 97.266 (97.409)	Training Prec@5 99.023 (98.845)	
2022-07-24 21:30:46,791: ============================================================
2022-07-24 21:31:27,535: time cost, forward:0.12433615578298134, backward:0.09704132913231413, data cost:0.18604587832861402 
2022-07-24 21:31:27,535: ============================================================
2022-07-24 21:31:27,535: Epoch 9/25 Batch 3000/7662 eta: 14:24:09.551726	Training Loss1 11.2604 (11.5926)	Training Total_Loss 11.2604 (11.5926)	Training Prec@1 98.242 (97.404)	Training Prec@5 99.414 (98.843)	
2022-07-24 21:31:27,535: ============================================================
2022-07-24 21:32:08,268: time cost, forward:0.12433481785742534, backward:0.09703985196076965, data cost:0.186024175685773 
2022-07-24 21:32:08,268: ============================================================
2022-07-24 21:32:08,269: Epoch 9/25 Batch 3100/7662 eta: 14:23:14.558846	Training Loss1 12.4051 (11.6001)	Training Total_Loss 12.4051 (11.6001)	Training Prec@1 97.266 (97.397)	Training Prec@5 98.438 (98.838)	
2022-07-24 21:32:08,269: ============================================================
2022-07-24 21:32:49,014: time cost, forward:0.1243406186516712, backward:0.09703854979407456, data cost:0.18600123015818426 
2022-07-24 21:32:49,014: ============================================================
2022-07-24 21:32:49,014: Epoch 9/25 Batch 3200/7662 eta: 14:22:49.203315	Training Loss1 11.3772 (11.6062)	Training Total_Loss 11.3772 (11.6062)	Training Prec@1 97.070 (97.389)	Training Prec@5 98.633 (98.833)	
2022-07-24 21:32:49,014: ============================================================
2022-07-24 21:33:29,779: time cost, forward:0.12434265012992589, backward:0.09703984192625326, data cost:0.18598515599306586 
2022-07-24 21:33:29,779: ============================================================
2022-07-24 21:33:29,779: Epoch 9/25 Batch 3300/7662 eta: 14:22:33.391126	Training Loss1 11.8382 (11.6146)	Training Total_Loss 11.8382 (11.6146)	Training Prec@1 97.070 (97.383)	Training Prec@5 98.047 (98.830)	
2022-07-24 21:33:29,779: ============================================================
2022-07-24 21:34:10,498: time cost, forward:0.12433708236651689, backward:0.09704056449692612, data cost:0.18596507633879242 
2022-07-24 21:34:10,498: ============================================================
2022-07-24 21:34:10,499: Epoch 9/25 Batch 3400/7662 eta: 14:20:54.706987	Training Loss1 11.7332 (11.6210)	Training Total_Loss 11.7332 (11.6210)	Training Prec@1 97.070 (97.376)	Training Prec@5 98.438 (98.825)	
2022-07-24 21:34:10,499: ============================================================
2022-07-24 21:34:51,232: time cost, forward:0.12433634951783099, backward:0.09704038625991354, data cost:0.18594779413609752 
2022-07-24 21:34:51,232: ============================================================
2022-07-24 21:34:51,232: Epoch 9/25 Batch 3500/7662 eta: 14:20:31.821971	Training Loss1 12.1316 (11.6274)	Training Total_Loss 12.1316 (11.6274)	Training Prec@1 97.070 (97.369)	Training Prec@5 98.828 (98.819)	
2022-07-24 21:34:51,232: ============================================================
2022-07-24 21:35:31,943: time cost, forward:0.12433376057872046, backward:0.09703950181077606, data cost:0.18592769637906773 
2022-07-24 21:35:31,943: ============================================================
2022-07-24 21:35:31,943: Epoch 9/25 Batch 3600/7662 eta: 14:19:22.870612	Training Loss1 12.1746 (11.6321)	Training Total_Loss 12.1746 (11.6321)	Training Prec@1 97.266 (97.360)	Training Prec@5 98.633 (98.815)	
2022-07-24 21:35:31,944: ============================================================
2022-07-24 21:36:12,639: time cost, forward:0.1243291072634047, backward:0.09703782037259051, data cost:0.18590813019559913 
2022-07-24 21:36:12,639: ============================================================
2022-07-24 21:36:12,639: Epoch 9/25 Batch 3700/7662 eta: 14:18:22.759260	Training Loss1 12.2900 (11.6394)	Training Total_Loss 12.2900 (11.6394)	Training Prec@1 96.484 (97.354)	Training Prec@5 98.828 (98.811)	
2022-07-24 21:36:12,639: ============================================================
2022-07-24 21:36:53,350: time cost, forward:0.1243250807450614, backward:0.09703647384332274, data cost:0.1858920319891817 
2022-07-24 21:36:53,351: ============================================================
2022-07-24 21:36:53,351: Epoch 9/25 Batch 3800/7662 eta: 14:18:01.721206	Training Loss1 11.5854 (11.6441)	Training Total_Loss 11.5854 (11.6441)	Training Prec@1 97.070 (97.347)	Training Prec@5 98.242 (98.808)	
2022-07-24 21:36:53,351: ============================================================
2022-07-24 21:37:34,079: time cost, forward:0.12432350241608973, backward:0.09703608108318962, data cost:0.18587703813678577 
2022-07-24 21:37:34,079: ============================================================
2022-07-24 21:37:34,079: Epoch 9/25 Batch 3900/7662 eta: 14:17:42.050782	Training Loss1 11.8579 (11.6503)	Training Total_Loss 11.8579 (11.6503)	Training Prec@1 97.266 (97.340)	Training Prec@5 98.242 (98.803)	
2022-07-24 21:37:34,079: ============================================================
2022-07-24 21:38:14,810: time cost, forward:0.12432517281589761, backward:0.09703490107498874, data cost:0.18586145499015516 
2022-07-24 21:38:14,810: ============================================================
2022-07-24 21:38:14,810: Epoch 9/25 Batch 4000/7662 eta: 14:17:04.882442	Training Loss1 11.7776 (11.6551)	Training Total_Loss 11.7776 (11.6551)	Training Prec@1 97.070 (97.334)	Training Prec@5 99.023 (98.800)	
2022-07-24 21:38:14,810: ============================================================
2022-07-24 21:38:55,536: time cost, forward:0.1243228693071241, backward:0.09703467688522097, data cost:0.1858491585236638 
2022-07-24 21:38:55,536: ============================================================
2022-07-24 21:38:55,537: Epoch 9/25 Batch 4100/7662 eta: 14:16:18.510704	Training Loss1 11.7177 (11.6600)	Training Total_Loss 11.7177 (11.6600)	Training Prec@1 96.875 (97.326)	Training Prec@5 98.438 (98.796)	
2022-07-24 21:38:55,537: ============================================================
2022-07-24 21:39:36,270: time cost, forward:0.1243240817951912, backward:0.09703272625104846, data cost:0.18583801803943173 
2022-07-24 21:39:36,270: ============================================================
2022-07-24 21:39:36,270: Epoch 9/25 Batch 4200/7662 eta: 14:15:47.103308	Training Loss1 12.0668 (11.6644)	Training Total_Loss 12.0668 (11.6644)	Training Prec@1 97.852 (97.321)	Training Prec@5 99.609 (98.793)	
2022-07-24 21:39:36,271: ============================================================
2022-07-24 21:40:16,964: time cost, forward:0.12431817344244926, backward:0.09703057442856101, data cost:0.1858252863962724 
2022-07-24 21:40:16,964: ============================================================
2022-07-24 21:40:16,965: Epoch 9/25 Batch 4300/7662 eta: 14:14:16.372752	Training Loss1 12.4583 (11.6674)	Training Total_Loss 12.4583 (11.6674)	Training Prec@1 96.289 (97.316)	Training Prec@5 98.828 (98.792)	
2022-07-24 21:40:16,965: ============================================================
2022-07-24 21:40:57,676: time cost, forward:0.1243160069056548, backward:0.09702940902050909, data cost:0.1858122012213594 
2022-07-24 21:40:57,676: ============================================================
2022-07-24 21:40:57,676: Epoch 9/25 Batch 4400/7662 eta: 14:13:57.499645	Training Loss1 12.0348 (11.6724)	Training Total_Loss 12.0348 (11.6724)	Training Prec@1 97.266 (97.309)	Training Prec@5 98.047 (98.786)	
2022-07-24 21:40:57,676: ============================================================
2022-07-24 21:41:38,381: time cost, forward:0.12431156388863798, backward:0.09702824073040266, data cost:0.18580083169786632 
2022-07-24 21:41:38,381: ============================================================
2022-07-24 21:41:38,381: Epoch 9/25 Batch 4500/7662 eta: 14:13:08.795723	Training Loss1 12.4010 (11.6765)	Training Total_Loss 12.4010 (11.6765)	Training Prec@1 96.875 (97.307)	Training Prec@5 98.828 (98.784)	
2022-07-24 21:41:38,381: ============================================================
2022-07-24 21:42:19,095: time cost, forward:0.12430837554085589, backward:0.09702712252078353, data cost:0.18579055625839216 
2022-07-24 21:42:19,095: ============================================================
2022-07-24 21:42:19,095: Epoch 9/25 Batch 4600/7662 eta: 14:12:39.091601	Training Loss1 11.2856 (11.6809)	Training Total_Loss 11.2856 (11.6809)	Training Prec@1 97.266 (97.302)	Training Prec@5 98.633 (98.780)	
2022-07-24 21:42:19,095: ============================================================
2022-07-24 21:42:59,812: time cost, forward:0.12430514150742496, backward:0.09702582190863299, data cost:0.18578205689087043 
2022-07-24 21:42:59,812: ============================================================
2022-07-24 21:42:59,812: Epoch 9/25 Batch 4700/7662 eta: 14:12:02.408668	Training Loss1 11.8161 (11.6847)	Training Total_Loss 11.8161 (11.6847)	Training Prec@1 97.852 (97.298)	Training Prec@5 99.023 (98.776)	
2022-07-24 21:42:59,813: ============================================================
2022-07-24 21:43:40,545: time cost, forward:0.12430561773725837, backward:0.09702386093974287, data cost:0.18577435861703975 
2022-07-24 21:43:40,546: ============================================================
2022-07-24 21:43:40,546: Epoch 9/25 Batch 4800/7662 eta: 14:11:42.021599	Training Loss1 11.4322 (11.6879)	Training Total_Loss 11.4322 (11.6879)	Training Prec@1 98.828 (97.294)	Training Prec@5 99.219 (98.774)	
2022-07-24 21:43:40,546: ============================================================
2022-07-24 21:44:21,300: time cost, forward:0.12431029140474747, backward:0.09702227947346458, data cost:0.1857664255152724 
2022-07-24 21:44:21,300: ============================================================
2022-07-24 21:44:21,301: Epoch 9/25 Batch 4900/7662 eta: 14:11:28.108810	Training Loss1 12.3949 (11.6923)	Training Total_Loss 12.3949 (11.6923)	Training Prec@1 95.898 (97.291)	Training Prec@5 98.438 (98.772)	
2022-07-24 21:44:21,301: ============================================================
2022-07-24 21:45:02,064: time cost, forward:0.12431535937352571, backward:0.09702165810244874, data cost:0.18575954213097565 
2022-07-24 21:45:02,065: ============================================================
2022-07-24 21:45:02,065: Epoch 9/25 Batch 5000/7662 eta: 14:10:59.264673	Training Loss1 11.9160 (11.6965)	Training Total_Loss 11.9160 (11.6965)	Training Prec@1 97.070 (97.288)	Training Prec@5 98.633 (98.770)	
2022-07-24 21:45:02,065: ============================================================
2022-07-24 21:45:42,807: time cost, forward:0.12431554879410918, backward:0.09702152134180303, data cost:0.18575279009905626 
2022-07-24 21:45:42,807: ============================================================
2022-07-24 21:45:42,807: Epoch 9/25 Batch 5100/7662 eta: 14:09:51.380396	Training Loss1 11.5644 (11.6991)	Training Total_Loss 11.5644 (11.6991)	Training Prec@1 97.852 (97.288)	Training Prec@5 99.219 (98.770)	
2022-07-24 21:45:42,807: ============================================================
2022-07-24 21:46:23,538: time cost, forward:0.12431360708105722, backward:0.09702247737760519, data cost:0.18574480062082285 
2022-07-24 21:46:23,539: ============================================================
2022-07-24 21:46:23,539: Epoch 9/25 Batch 5200/7662 eta: 14:08:56.601004	Training Loss1 11.5063 (11.7024)	Training Total_Loss 11.5063 (11.7024)	Training Prec@1 98.242 (97.286)	Training Prec@5 98.828 (98.768)	
2022-07-24 21:46:23,539: ============================================================
2022-07-24 21:47:04,272: time cost, forward:0.12431256477282528, backward:0.09702277143038901, data cost:0.18573741004880498 
2022-07-24 21:47:04,273: ============================================================
2022-07-24 21:47:04,273: Epoch 9/25 Batch 5300/7662 eta: 14:08:19.222986	Training Loss1 13.0710 (11.7065)	Training Total_Loss 13.0710 (11.7065)	Training Prec@1 95.898 (97.282)	Training Prec@5 98.242 (98.767)	
2022-07-24 21:47:04,273: ============================================================
2022-07-24 21:47:45,003: time cost, forward:0.12430922237452058, backward:0.09702385538351671, data cost:0.18573070455644058 
2022-07-24 21:47:45,003: ============================================================
2022-07-24 21:47:45,003: Epoch 9/25 Batch 5400/7662 eta: 14:07:34.101475	Training Loss1 11.5072 (11.7099)	Training Total_Loss 11.5072 (11.7099)	Training Prec@1 96.875 (97.279)	Training Prec@5 98.633 (98.765)	
2022-07-24 21:47:45,003: ============================================================
2022-07-24 21:48:25,752: time cost, forward:0.1243065060388177, backward:0.09702575260952487, data cost:0.18572694211683397 
2022-07-24 21:48:25,753: ============================================================
2022-07-24 21:48:25,753: Epoch 9/25 Batch 5500/7662 eta: 14:07:17.194331	Training Loss1 12.3058 (11.7141)	Training Total_Loss 12.3058 (11.7141)	Training Prec@1 96.875 (97.278)	Training Prec@5 98.633 (98.764)	
2022-07-24 21:48:25,753: ============================================================
2022-07-24 21:49:06,538: time cost, forward:0.12430835655915522, backward:0.09702682997588921, data cost:0.18572610002433557 
2022-07-24 21:49:06,538: ============================================================
2022-07-24 21:49:06,538: Epoch 9/25 Batch 5600/7662 eta: 14:07:20.612888	Training Loss1 12.4302 (11.7178)	Training Total_Loss 12.4302 (11.7178)	Training Prec@1 96.875 (97.277)	Training Prec@5 97.852 (98.764)	
2022-07-24 21:49:06,538: ============================================================
2022-07-24 21:49:47,325: time cost, forward:0.12431001520968463, backward:0.09702834306547235, data cost:0.18572530944758622 
2022-07-24 21:49:47,325: ============================================================
2022-07-24 21:49:47,325: Epoch 9/25 Batch 5700/7662 eta: 14:06:42.636203	Training Loss1 11.6329 (11.7202)	Training Total_Loss 11.6329 (11.7202)	Training Prec@1 97.852 (97.273)	Training Prec@5 98.242 (98.762)	
2022-07-24 21:49:47,325: ============================================================
2022-07-24 21:50:28,125: time cost, forward:0.12431238322119031, backward:0.0970315013513172, data cost:0.18572452644332357 
2022-07-24 21:50:28,126: ============================================================
2022-07-24 21:50:28,126: Epoch 9/25 Batch 5800/7662 eta: 14:06:18.141107	Training Loss1 11.9392 (11.7234)	Training Total_Loss 11.9392 (11.7234)	Training Prec@1 98.047 (97.268)	Training Prec@5 98.828 (98.760)	
2022-07-24 21:50:28,126: ============================================================
2022-07-24 21:51:08,935: time cost, forward:0.12431714724314215, backward:0.09703366496559321, data cost:0.18572373203472234 
2022-07-24 21:51:08,935: ============================================================
2022-07-24 21:51:08,935: Epoch 9/25 Batch 5900/7662 eta: 14:05:48.457426	Training Loss1 12.9188 (11.7258)	Training Total_Loss 12.9188 (11.7258)	Training Prec@1 95.508 (97.265)	Training Prec@5 97.266 (98.759)	
2022-07-24 21:51:08,935: ============================================================
2022-07-24 21:51:49,706: time cost, forward:0.12431561841549804, backward:0.09703618861333711, data cost:0.18572247876865025 
2022-07-24 21:51:49,706: ============================================================
2022-07-24 21:51:49,706: Epoch 9/25 Batch 6000/7662 eta: 14:04:19.833224	Training Loss1 12.0007 (11.7275)	Training Total_Loss 12.0007 (11.7275)	Training Prec@1 97.461 (97.263)	Training Prec@5 98.633 (98.759)	
2022-07-24 21:51:49,706: ============================================================
2022-07-24 21:52:30,498: time cost, forward:0.12431728329731219, backward:0.09703798574743788, data cost:0.18572242311970838 
2022-07-24 21:52:30,499: ============================================================
2022-07-24 21:52:30,499: Epoch 9/25 Batch 6100/7662 eta: 14:04:06.257560	Training Loss1 11.9713 (11.7298)	Training Total_Loss 11.9713 (11.7298)	Training Prec@1 98.438 (97.262)	Training Prec@5 99.219 (98.758)	
2022-07-24 21:52:30,499: ============================================================
2022-07-24 21:53:11,302: time cost, forward:0.1243210806925848, backward:0.09703929571590802, data cost:0.18572231861329266 
2022-07-24 21:53:11,303: ============================================================
2022-07-24 21:53:11,303: Epoch 9/25 Batch 6200/7662 eta: 14:03:39.500864	Training Loss1 11.6378 (11.7316)	Training Total_Loss 11.6378 (11.7316)	Training Prec@1 97.656 (97.259)	Training Prec@5 99.414 (98.755)	
2022-07-24 21:53:11,303: ============================================================
2022-07-24 21:53:52,110: time cost, forward:0.12432652674964315, backward:0.0970408135244706, data cost:0.18572060962313033 
2022-07-24 21:53:52,111: ============================================================
2022-07-24 21:53:52,111: Epoch 9/25 Batch 6300/7662 eta: 14:03:03.727622	Training Loss1 11.9624 (11.7325)	Training Total_Loss 11.9624 (11.7325)	Training Prec@1 95.508 (97.256)	Training Prec@5 98.242 (98.753)	
2022-07-24 21:53:52,111: ============================================================
2022-07-24 21:54:32,923: time cost, forward:0.12433057707685068, backward:0.09704270227232246, data cost:0.18572020169291054 
2022-07-24 21:54:32,924: ============================================================
2022-07-24 21:54:32,924: Epoch 9/25 Batch 6400/7662 eta: 14:02:28.877026	Training Loss1 11.9286 (11.7347)	Training Total_Loss 11.9286 (11.7347)	Training Prec@1 97.461 (97.254)	Training Prec@5 99.023 (98.753)	
2022-07-24 21:54:32,924: ============================================================
2022-07-24 21:55:13,720: time cost, forward:0.12433438866775684, backward:0.09704348897545094, data cost:0.18571892817729546 
2022-07-24 21:55:13,720: ============================================================
2022-07-24 21:55:13,720: Epoch 9/25 Batch 6500/7662 eta: 14:01:27.463639	Training Loss1 11.9587 (11.7382)	Training Total_Loss 11.9587 (11.7382)	Training Prec@1 97.461 (97.252)	Training Prec@5 98.828 (98.751)	
2022-07-24 21:55:13,720: ============================================================
2022-07-24 21:55:54,504: time cost, forward:0.1243359059126996, backward:0.09704424493474334, data cost:0.18571785793717766 
2022-07-24 21:55:54,505: ============================================================
2022-07-24 21:55:54,505: Epoch 9/25 Batch 6600/7662 eta: 14:00:32.187720	Training Loss1 12.6709 (11.7407)	Training Total_Loss 12.6709 (11.7407)	Training Prec@1 95.898 (97.247)	Training Prec@5 98.047 (98.749)	
2022-07-24 21:55:54,505: ============================================================
2022-07-24 21:56:35,316: time cost, forward:0.12433953967836832, backward:0.09704600591982705, data cost:0.18571744315356242 
2022-07-24 21:56:35,316: ============================================================
2022-07-24 21:56:35,317: Epoch 9/25 Batch 6700/7662 eta: 14:00:25.011540	Training Loss1 11.8080 (11.7420)	Training Total_Loss 11.8080 (11.7420)	Training Prec@1 97.852 (97.247)	Training Prec@5 98.633 (98.749)	
2022-07-24 21:56:35,317: ============================================================
2022-07-24 21:57:16,167: time cost, forward:0.12434623486540881, backward:0.09704807902595755, data cost:0.18571999701073388 
2022-07-24 21:57:16,168: ============================================================
2022-07-24 21:57:16,168: Epoch 9/25 Batch 6800/7662 eta: 14:00:32.708688	Training Loss1 12.6025 (11.7438)	Training Total_Loss 12.6025 (11.7438)	Training Prec@1 96.094 (97.246)	Training Prec@5 97.461 (98.748)	
2022-07-24 21:57:16,168: ============================================================
2022-07-24 21:57:56,977: time cost, forward:0.12434925143486142, backward:0.0970490773634075, data cost:0.18572091524074658 
2022-07-24 21:57:56,978: ============================================================
2022-07-24 21:57:56,978: Epoch 9/25 Batch 6900/7662 eta: 13:59:01.210133	Training Loss1 11.1634 (11.7452)	Training Total_Loss 11.1634 (11.7452)	Training Prec@1 98.242 (97.245)	Training Prec@5 99.023 (98.748)	
2022-07-24 21:57:56,978: ============================================================
2022-07-24 21:58:37,826: time cost, forward:0.12435980987031045, backward:0.09704761376362525, data cost:0.1857221147335841 
2022-07-24 21:58:37,826: ============================================================
2022-07-24 21:58:37,826: Epoch 9/25 Batch 7000/7662 eta: 13:59:07.789305	Training Loss1 11.2605 (11.7459)	Training Total_Loss 11.2605 (11.7459)	Training Prec@1 97.070 (97.245)	Training Prec@5 99.219 (98.747)	
2022-07-24 21:58:37,826: ============================================================
2022-07-24 21:59:18,646: time cost, forward:0.12436546559299545, backward:0.09704637544258227, data cost:0.18572368835425576 
2022-07-24 21:59:18,647: ============================================================
2022-07-24 21:59:18,647: Epoch 9/25 Batch 7100/7662 eta: 13:57:52.851330	Training Loss1 11.7746 (11.7481)	Training Total_Loss 11.7746 (11.7481)	Training Prec@1 97.266 (97.243)	Training Prec@5 98.633 (98.747)	
2022-07-24 21:59:18,647: ============================================================
2022-07-24 21:59:59,454: time cost, forward:0.12437193329788973, backward:0.0970444267599893, data cost:0.18572329901907075 
2022-07-24 21:59:59,455: ============================================================
2022-07-24 21:59:59,455: Epoch 9/25 Batch 7200/7662 eta: 13:56:55.930978	Training Loss1 11.9976 (11.7491)	Training Total_Loss 11.9976 (11.7491)	Training Prec@1 96.875 (97.241)	Training Prec@5 98.438 (98.746)	
2022-07-24 21:59:59,455: ============================================================
2022-07-24 22:00:40,249: time cost, forward:0.12437711628941187, backward:0.09704298570656192, data cost:0.18572152394238425 
2022-07-24 22:00:40,249: ============================================================
2022-07-24 22:00:40,249: Epoch 9/25 Batch 7300/7662 eta: 13:55:58.789669	Training Loss1 11.4764 (11.7492)	Training Total_Loss 11.4764 (11.7492)	Training Prec@1 97.852 (97.240)	Training Prec@5 99.023 (98.745)	
2022-07-24 22:00:40,249: ============================================================
2022-07-24 22:01:20,970: time cost, forward:0.12437282318778256, backward:0.09704276767513659, data cost:0.18571769384004438 
2022-07-24 22:01:20,970: ============================================================
2022-07-24 22:01:20,970: Epoch 9/25 Batch 7400/7662 eta: 13:53:47.660888	Training Loss1 11.5419 (11.7505)	Training Total_Loss 11.5419 (11.7505)	Training Prec@1 95.898 (97.239)	Training Prec@5 98.828 (98.745)	
2022-07-24 22:01:20,970: ============================================================
2022-07-24 22:02:01,692: time cost, forward:0.12436984195472686, backward:0.09704182904344318, data cost:0.1857138302250216 
2022-07-24 22:02:01,692: ============================================================
2022-07-24 22:02:01,692: Epoch 9/25 Batch 7500/7662 eta: 13:53:08.586555	Training Loss1 11.4965 (11.7521)	Training Total_Loss 11.4965 (11.7521)	Training Prec@1 98.633 (97.238)	Training Prec@5 99.023 (98.744)	
2022-07-24 22:02:01,692: ============================================================
2022-07-24 22:02:42,444: time cost, forward:0.12436953185812269, backward:0.09704289977245228, data cost:0.1857094176742086 
2022-07-24 22:02:42,444: ============================================================
2022-07-24 22:02:42,444: Epoch 9/25 Batch 7600/7662 eta: 13:53:04.638554	Training Loss1 12.0249 (11.7522)	Training Total_Loss 12.0249 (11.7522)	Training Prec@1 96.875 (97.236)	Training Prec@5 98.633 (98.744)	
2022-07-24 22:02:42,445: ============================================================
2022-07-24 22:03:09,806: Epoch 9/25 Batch 7663/7662 eta: 13:52:38.964654	Training Loss1 11.1871 (11.7527)	Training Total_Loss 11.1871 (11.7527)	Training Prec@1 97.461 (97.235)	Training Prec@5 98.633 (98.743)	
2022-07-24 22:03:09,807: ============================================================
2022-07-24 22:03:52,423: time cost, forward:0.12418710342561355, backward:0.09675468338860406, data cost:0.20577556677538938 
2022-07-24 22:03:52,424: ============================================================
2022-07-24 22:03:52,424: Epoch 10/25 Batch 100/7662 eta: 14:27:38.947333	Training Loss1 9.4326 (9.3493)	Training Total_Loss 9.4326 (9.3493)	Training Prec@1 97.461 (98.398)	Training Prec@5 98.828 (99.388)	
2022-07-24 22:03:52,424: ============================================================
2022-07-24 22:04:33,129: time cost, forward:0.12417590438421049, backward:0.09683386884143005, data cost:0.1954862843805821 
2022-07-24 22:04:33,129: ============================================================
2022-07-24 22:04:33,129: Epoch 10/25 Batch 200/7662 eta: 13:50:20.729166	Training Loss1 8.6728 (8.9872)	Training Total_Loss 8.6728 (8.9872)	Training Prec@1 98.828 (98.574)	Training Prec@5 99.805 (99.485)	
2022-07-24 22:04:33,129: ============================================================
2022-07-24 22:05:13,843: time cost, forward:0.12419588749225323, backward:0.09685973578870895, data cost:0.19208487938080343 
2022-07-24 22:05:13,843: ============================================================
2022-07-24 22:05:13,843: Epoch 10/25 Batch 300/7662 eta: 13:49:50.548111	Training Loss1 8.7665 (8.7684)	Training Total_Loss 8.7665 (8.7684)	Training Prec@1 99.414 (98.661)	Training Prec@5 99.805 (99.511)	
2022-07-24 22:05:13,843: ============================================================
2022-07-24 22:05:54,581: time cost, forward:0.12423002032707807, backward:0.09688748572404522, data cost:0.1904012021564302 
2022-07-24 22:05:54,581: ============================================================
2022-07-24 22:05:54,581: Epoch 10/25 Batch 400/7662 eta: 13:49:38.996182	Training Loss1 7.5658 (8.6113)	Training Total_Loss 7.5658 (8.6113)	Training Prec@1 99.609 (98.728)	Training Prec@5 99.805 (99.528)	
2022-07-24 22:05:54,582: ============================================================
2022-07-24 22:06:35,317: time cost, forward:0.1242372454526668, backward:0.09691958054750859, data cost:0.1894033647969156 
2022-07-24 22:06:35,317: ============================================================
2022-07-24 22:06:35,318: Epoch 10/25 Batch 500/7662 eta: 13:48:55.867722	Training Loss1 7.2962 (8.4923)	Training Total_Loss 7.2962 (8.4923)	Training Prec@1 99.219 (98.763)	Training Prec@5 99.414 (99.540)	
2022-07-24 22:06:35,318: ============================================================
2022-07-24 22:07:16,070: time cost, forward:0.1242793163592509, backward:0.09692231840601748, data cost:0.18874817658744392 
2022-07-24 22:07:16,070: ============================================================
2022-07-24 22:07:16,070: Epoch 10/25 Batch 600/7662 eta: 13:48:35.616806	Training Loss1 7.4528 (8.3782)	Training Total_Loss 7.4528 (8.3782)	Training Prec@1 99.219 (98.807)	Training Prec@5 99.805 (99.546)	
2022-07-24 22:07:16,070: ============================================================
2022-07-24 22:07:56,793: time cost, forward:0.12427200643460297, backward:0.0969270165897746, data cost:0.18827235340560455 
2022-07-24 22:07:56,793: ============================================================
2022-07-24 22:07:56,793: Epoch 10/25 Batch 700/7662 eta: 13:47:18.629143	Training Loss1 7.3641 (8.2928)	Training Total_Loss 7.3641 (8.2928)	Training Prec@1 99.023 (98.833)	Training Prec@5 99.805 (99.554)	
2022-07-24 22:07:56,794: ============================================================
2022-07-24 22:08:37,513: time cost, forward:0.12425444511060273, backward:0.09693492607718265, data cost:0.18791529502677679 
2022-07-24 22:08:37,513: ============================================================
2022-07-24 22:08:37,513: Epoch 10/25 Batch 800/7662 eta: 13:46:33.665648	Training Loss1 8.1662 (8.2053)	Training Total_Loss 8.1662 (8.2053)	Training Prec@1 99.219 (98.860)	Training Prec@5 99.609 (99.565)	
2022-07-24 22:08:37,513: ============================================================
2022-07-24 22:09:18,228: time cost, forward:0.1242591358795845, backward:0.09693493381623298, data cost:0.18762518327944272 
2022-07-24 22:09:18,228: ============================================================
2022-07-24 22:09:18,228: Epoch 10/25 Batch 900/7662 eta: 13:45:47.301364	Training Loss1 6.9510 (8.1233)	Training Total_Loss 6.9510 (8.1233)	Training Prec@1 98.242 (98.880)	Training Prec@5 98.828 (99.573)	
2022-07-24 22:09:18,228: ============================================================
2022-07-24 22:09:58,946: time cost, forward:0.12425307874326352, backward:0.09693728027878343, data cost:0.18739783035980928 
2022-07-24 22:09:58,947: ============================================================
2022-07-24 22:09:58,947: Epoch 10/25 Batch 1000/7662 eta: 13:45:11.056340	Training Loss1 7.3820 (8.0568)	Training Total_Loss 7.3820 (8.0568)	Training Prec@1 99.219 (98.899)	Training Prec@5 99.609 (99.582)	
2022-07-24 22:09:58,947: ============================================================
2022-07-24 22:10:39,676: time cost, forward:0.12424568418376114, backward:0.09694226163425046, data cost:0.18722103659514408 
2022-07-24 22:10:39,676: ============================================================
2022-07-24 22:10:39,676: Epoch 10/25 Batch 1100/7662 eta: 13:44:43.403735	Training Loss1 7.8806 (7.9895)	Training Total_Loss 7.8806 (7.9895)	Training Prec@1 98.438 (98.921)	Training Prec@5 99.609 (99.589)	
2022-07-24 22:10:39,676: ============================================================
2022-07-24 22:11:20,410: time cost, forward:0.12424785778659697, backward:0.09694625816313399, data cost:0.1870717717966902 
2022-07-24 22:11:20,411: ============================================================
2022-07-24 22:11:20,411: Epoch 10/25 Batch 1200/7662 eta: 13:44:09.061304	Training Loss1 7.4607 (7.9251)	Training Total_Loss 7.4607 (7.9251)	Training Prec@1 99.023 (98.935)	Training Prec@5 99.609 (99.593)	
2022-07-24 22:11:20,411: ============================================================
2022-07-24 22:12:01,159: time cost, forward:0.12426764566775374, backward:0.09694591552317372, data cost:0.18694142105948292 
2022-07-24 22:12:01,159: ============================================================
2022-07-24 22:12:01,159: Epoch 10/25 Batch 1300/7662 eta: 13:43:45.137231	Training Loss1 6.5546 (7.8654)	Training Total_Loss 6.5546 (7.8654)	Training Prec@1 99.023 (98.947)	Training Prec@5 99.609 (99.599)	
2022-07-24 22:12:01,160: ============================================================
2022-07-24 22:12:41,933: time cost, forward:0.1243009204264621, backward:0.09694776746355865, data cost:0.1868301363311724 
2022-07-24 22:12:41,933: ============================================================
2022-07-24 22:12:41,934: Epoch 10/25 Batch 1400/7662 eta: 13:43:35.369828	Training Loss1 7.1251 (7.8062)	Training Total_Loss 7.1251 (7.8062)	Training Prec@1 99.219 (98.965)	Training Prec@5 99.609 (99.607)	
2022-07-24 22:12:41,934: ============================================================
2022-07-24 22:13:22,691: time cost, forward:0.12431356682627896, backward:0.09694743076907228, data cost:0.1867387627187453 
2022-07-24 22:13:22,691: ============================================================
2022-07-24 22:13:22,691: Epoch 10/25 Batch 1500/7662 eta: 13:42:34.425694	Training Loss1 7.8919 (7.7508)	Training Total_Loss 7.8919 (7.7508)	Training Prec@1 99.219 (98.980)	Training Prec@5 99.219 (99.613)	
2022-07-24 22:13:22,691: ============================================================
2022-07-24 22:14:03,454: time cost, forward:0.12432057459403605, backward:0.09695397607231974, data cost:0.18665922247222844 
2022-07-24 22:14:03,454: ============================================================
2022-07-24 22:14:03,455: Epoch 10/25 Batch 1600/7662 eta: 13:42:01.062873	Training Loss1 7.4467 (7.7012)	Training Total_Loss 7.4467 (7.7012)	Training Prec@1 99.609 (98.995)	Training Prec@5 99.805 (99.617)	
2022-07-24 22:14:03,455: ============================================================
2022-07-24 22:14:44,234: time cost, forward:0.1243278357195391, backward:0.09695934168797089, data cost:0.18659690171567883 
2022-07-24 22:14:44,234: ============================================================
2022-07-24 22:14:44,234: Epoch 10/25 Batch 1700/7662 eta: 13:41:39.787206	Training Loss1 6.7330 (7.6526)	Training Total_Loss 6.7330 (7.6526)	Training Prec@1 98.438 (99.011)	Training Prec@5 99.414 (99.625)	
2022-07-24 22:14:44,234: ============================================================
2022-07-24 22:15:24,977: time cost, forward:0.12433740362450439, backward:0.09695905828025356, data cost:0.18652517852549952 
2022-07-24 22:15:24,978: ============================================================
2022-07-24 22:15:24,978: Epoch 10/25 Batch 1800/7662 eta: 13:40:15.502439	Training Loss1 6.8912 (7.6045)	Training Total_Loss 6.8912 (7.6045)	Training Prec@1 98.438 (99.024)	Training Prec@5 99.805 (99.632)	
2022-07-24 22:15:24,978: ============================================================
2022-07-24 22:16:05,709: time cost, forward:0.1243324051284991, backward:0.096959204972575, data cost:0.18647032175772185 
2022-07-24 22:16:05,710: ============================================================
2022-07-24 22:16:05,710: Epoch 10/25 Batch 1900/7662 eta: 13:39:20.480388	Training Loss1 8.0462 (7.5574)	Training Total_Loss 8.0462 (7.5574)	Training Prec@1 98.047 (99.035)	Training Prec@5 99.023 (99.636)	
2022-07-24 22:16:05,710: ============================================================
2022-07-24 22:16:46,456: time cost, forward:0.12433663566688587, backward:0.09695877713999669, data cost:0.1864197929243018 
2022-07-24 22:16:46,456: ============================================================
2022-07-24 22:16:46,456: Epoch 10/25 Batch 2000/7662 eta: 13:38:57.492605	Training Loss1 7.3349 (7.5138)	Training Total_Loss 7.3349 (7.5138)	Training Prec@1 99.414 (99.049)	Training Prec@5 99.609 (99.642)	
2022-07-24 22:16:46,456: ============================================================
2022-07-24 22:17:27,203: time cost, forward:0.12432934148587631, backward:0.09696304304023877, data cost:0.18637904989088985 
2022-07-24 22:17:27,203: ============================================================
2022-07-24 22:17:27,203: Epoch 10/25 Batch 2100/7662 eta: 13:38:17.090496	Training Loss1 7.1822 (7.4728)	Training Total_Loss 7.1822 (7.4728)	Training Prec@1 99.023 (99.063)	Training Prec@5 99.609 (99.648)	
2022-07-24 22:17:27,203: ============================================================
2022-07-24 22:18:07,965: time cost, forward:0.1243316147098654, backward:0.09696696313092144, data cost:0.1863419527137968 
2022-07-24 22:18:07,966: ============================================================
2022-07-24 22:18:07,966: Epoch 10/25 Batch 2200/7662 eta: 13:37:55.398758	Training Loss1 6.6040 (7.4319)	Training Total_Loss 6.6040 (7.4319)	Training Prec@1 99.219 (99.075)	Training Prec@5 99.805 (99.653)	
2022-07-24 22:18:07,966: ============================================================
2022-07-24 22:18:48,754: time cost, forward:0.12433803501519082, backward:0.09697061873042309, data cost:0.18631262196411824 
2022-07-24 22:18:48,754: ============================================================
2022-07-24 22:18:48,754: Epoch 10/25 Batch 2300/7662 eta: 13:37:45.405234	Training Loss1 6.1401 (7.3931)	Training Total_Loss 6.1401 (7.3931)	Training Prec@1 99.609 (99.085)	Training Prec@5 99.805 (99.656)	
2022-07-24 22:18:48,754: ============================================================
2022-07-24 22:19:29,575: time cost, forward:0.12435436199088055, backward:0.09697590762746985, data cost:0.18628699842121463 
2022-07-24 22:19:29,575: ============================================================
2022-07-24 22:19:29,575: Epoch 10/25 Batch 2400/7662 eta: 13:37:44.227081	Training Loss1 6.3993 (7.3584)	Training Total_Loss 6.3993 (7.3584)	Training Prec@1 99.609 (99.095)	Training Prec@5 99.805 (99.659)	
2022-07-24 22:19:29,575: ============================================================
2022-07-24 22:20:10,363: time cost, forward:0.12435301889081438, backward:0.09698418351639362, data cost:0.18626429606266334 
2022-07-24 22:20:10,364: ============================================================
2022-07-24 22:20:10,364: Epoch 10/25 Batch 2500/7662 eta: 13:36:24.294304	Training Loss1 7.1094 (7.3212)	Training Total_Loss 7.1094 (7.3212)	Training Prec@1 99.414 (99.103)	Training Prec@5 99.414 (99.662)	
2022-07-24 22:20:10,364: ============================================================
2022-07-24 22:20:51,124: time cost, forward:0.12434576309016229, backward:0.09698824104596762, data cost:0.18624165673676066 
2022-07-24 22:20:51,124: ============================================================
2022-07-24 22:20:51,124: Epoch 10/25 Batch 2600/7662 eta: 13:35:09.576203	Training Loss1 6.2992 (7.2831)	Training Total_Loss 6.2992 (7.2831)	Training Prec@1 99.609 (99.112)	Training Prec@5 99.805 (99.666)	
2022-07-24 22:20:51,124: ============================================================
2022-07-24 22:21:31,909: time cost, forward:0.1243444364483421, backward:0.09699631700165937, data cost:0.18622020519676363 
2022-07-24 22:21:31,909: ============================================================
2022-07-24 22:21:31,910: Epoch 10/25 Batch 2700/7662 eta: 13:34:58.750906	Training Loss1 7.2085 (7.2484)	Training Total_Loss 7.2085 (7.2484)	Training Prec@1 98.438 (99.122)	Training Prec@5 99.414 (99.671)	
2022-07-24 22:21:31,910: ============================================================
2022-07-24 22:22:12,701: time cost, forward:0.12434912656366336, backward:0.09699858993920056, data cost:0.18620226867882939 
2022-07-24 22:22:12,701: ============================================================
2022-07-24 22:22:12,701: Epoch 10/25 Batch 2800/7662 eta: 13:34:25.541067	Training Loss1 6.9961 (7.2106)	Training Total_Loss 6.9961 (7.2106)	Training Prec@1 98.828 (99.132)	Training Prec@5 99.805 (99.675)	
2022-07-24 22:22:12,701: ============================================================
2022-07-24 22:22:53,481: time cost, forward:0.12434591051215507, backward:0.09700339750899821, data cost:0.18618622003813864 
2022-07-24 22:22:53,481: ============================================================
2022-07-24 22:22:53,482: Epoch 10/25 Batch 2900/7662 eta: 13:33:31.202316	Training Loss1 5.8039 (7.1775)	Training Total_Loss 5.8039 (7.1775)	Training Prec@1 99.219 (99.142)	Training Prec@5 99.805 (99.678)	
2022-07-24 22:22:53,482: ============================================================
2022-07-24 22:23:34,269: time cost, forward:0.12434563536610592, backward:0.09700869408874918, data cost:0.186170096634308 
2022-07-24 22:23:34,269: ============================================================
2022-07-24 22:23:34,269: Epoch 10/25 Batch 3000/7662 eta: 13:32:59.340056	Training Loss1 6.1573 (7.1432)	Training Total_Loss 6.1573 (7.1432)	Training Prec@1 98.633 (99.149)	Training Prec@5 99.219 (99.682)	
2022-07-24 22:23:34,270: ============================================================
2022-07-24 22:24:15,065: time cost, forward:0.12435070796719133, backward:0.0970107168872805, data cost:0.186156374902716 
2022-07-24 22:24:15,066: ============================================================
2022-07-24 22:24:15,066: Epoch 10/25 Batch 3100/7662 eta: 13:32:28.843475	Training Loss1 6.2876 (7.1112)	Training Total_Loss 6.2876 (7.1112)	Training Prec@1 99.219 (99.159)	Training Prec@5 99.414 (99.685)	
2022-07-24 22:24:15,066: ============================================================
2022-07-24 22:24:55,852: time cost, forward:0.12435345420169622, backward:0.097013325570486, data cost:0.18614146134822807 
2022-07-24 22:24:55,852: ============================================================
2022-07-24 22:24:55,852: Epoch 10/25 Batch 3200/7662 eta: 13:31:36.195460	Training Loss1 5.9778 (7.0783)	Training Total_Loss 5.9778 (7.0783)	Training Prec@1 99.414 (99.168)	Training Prec@5 99.609 (99.688)	
2022-07-24 22:24:55,852: ============================================================
2022-07-24 22:25:36,651: time cost, forward:0.12435924280553415, backward:0.09701522367222448, data cost:0.1861286849171944 
2022-07-24 22:25:36,651: ============================================================
2022-07-24 22:25:36,651: Epoch 10/25 Batch 3300/7662 eta: 13:31:09.991597	Training Loss1 6.0428 (7.0490)	Training Total_Loss 6.0428 (7.0490)	Training Prec@1 99.609 (99.177)	Training Prec@5 99.609 (99.692)	
2022-07-24 22:25:36,651: ============================================================
2022-07-24 22:26:17,422: time cost, forward:0.12435512656357471, backward:0.09701872131480088, data cost:0.18611657966687842 
2022-07-24 22:26:17,423: ============================================================
2022-07-24 22:26:17,423: Epoch 10/25 Batch 3400/7662 eta: 13:29:57.317476	Training Loss1 6.1010 (7.0193)	Training Total_Loss 6.1010 (7.0193)	Training Prec@1 99.805 (99.184)	Training Prec@5 99.805 (99.696)	
2022-07-24 22:26:17,423: ============================================================
2022-07-24 22:26:58,218: time cost, forward:0.12435443921237715, backward:0.09702351155298783, data cost:0.18610556965795508 
2022-07-24 22:26:58,218: ============================================================
2022-07-24 22:26:58,218: Epoch 10/25 Batch 3500/7662 eta: 13:29:44.296096	Training Loss1 6.1462 (6.9920)	Training Total_Loss 6.1462 (6.9920)	Training Prec@1 99.805 (99.191)	Training Prec@5 99.805 (99.699)	
2022-07-24 22:26:58,218: ============================================================
2022-07-24 22:27:39,033: time cost, forward:0.12435801653903072, backward:0.0970275955221394, data cost:0.18609632051928438 
2022-07-24 22:27:39,033: ============================================================
2022-07-24 22:27:39,034: Epoch 10/25 Batch 3600/7662 eta: 13:29:27.385661	Training Loss1 5.7737 (6.9644)	Training Total_Loss 5.7737 (6.9644)	Training Prec@1 99.805 (99.199)	Training Prec@5 100.000 (99.702)	
2022-07-24 22:27:39,034: ============================================================
2022-07-24 22:28:19,866: time cost, forward:0.12436690534182773, backward:0.09702916653229114, data cost:0.18609124062737442 
2022-07-24 22:28:19,866: ============================================================
2022-07-24 22:28:19,866: Epoch 10/25 Batch 3700/7662 eta: 13:29:07.365460	Training Loss1 5.9604 (6.9381)	Training Total_Loss 5.9604 (6.9381)	Training Prec@1 99.609 (99.205)	Training Prec@5 99.805 (99.705)	
2022-07-24 22:28:19,867: ============================================================
2022-07-24 22:29:00,639: time cost, forward:0.12436336572310208, backward:0.0970314975536695, data cost:0.1860818379048957 
2022-07-24 22:29:00,639: ============================================================
2022-07-24 22:29:00,640: Epoch 10/25 Batch 3800/7662 eta: 13:27:15.561374	Training Loss1 6.2066 (6.9102)	Training Total_Loss 6.2066 (6.9102)	Training Prec@1 99.219 (99.214)	Training Prec@5 99.805 (99.708)	
2022-07-24 22:29:00,640: ============================================================
2022-07-24 22:29:41,408: time cost, forward:0.12436586271404884, backward:0.09703111825890649, data cost:0.18606909796897494 
2022-07-24 22:29:41,408: ============================================================
2022-07-24 22:29:41,409: Epoch 10/25 Batch 3900/7662 eta: 13:26:30.099782	Training Loss1 5.9103 (6.8860)	Training Total_Loss 5.9103 (6.8860)	Training Prec@1 99.609 (99.219)	Training Prec@5 99.805 (99.711)	
2022-07-24 22:29:41,409: ============================================================
2022-07-24 22:30:22,157: time cost, forward:0.12436364996161989, backward:0.09703043843245739, data cost:0.18605643315564457 
2022-07-24 22:30:22,157: ============================================================
2022-07-24 22:30:22,158: Epoch 10/25 Batch 4000/7662 eta: 13:25:25.306993	Training Loss1 5.7712 (6.8598)	Training Total_Loss 5.7712 (6.8598)	Training Prec@1 99.609 (99.227)	Training Prec@5 100.000 (99.714)	
2022-07-24 22:30:22,158: ============================================================
2022-07-24 22:31:02,875: time cost, forward:0.12435532395622735, backward:0.09703070898118848, data cost:0.18604260038881656 
2022-07-24 22:31:02,876: ============================================================
2022-07-24 22:31:02,876: Epoch 10/25 Batch 4100/7662 eta: 13:24:08.459929	Training Loss1 6.7350 (6.8343)	Training Total_Loss 6.7350 (6.8343)	Training Prec@1 99.414 (99.232)	Training Prec@5 99.805 (99.716)	
2022-07-24 22:31:02,876: ============================================================
2022-07-24 22:31:43,600: time cost, forward:0.12435043917067932, backward:0.09702955884404284, data cost:0.18602817017113943 
2022-07-24 22:31:43,600: ============================================================
2022-07-24 22:31:43,601: Epoch 10/25 Batch 4200/7662 eta: 13:23:35.125448	Training Loss1 5.6555 (6.8103)	Training Total_Loss 5.6555 (6.8103)	Training Prec@1 99.609 (99.238)	Training Prec@5 100.000 (99.719)	
2022-07-24 22:31:43,601: ============================================================
2022-07-24 22:32:24,333: time cost, forward:0.12434824895625836, backward:0.09702838983999404, data cost:0.1860144474972789 
2022-07-24 22:32:24,334: ============================================================
2022-07-24 22:32:24,334: Epoch 10/25 Batch 4300/7662 eta: 13:23:04.465418	Training Loss1 4.9253 (6.7848)	Training Total_Loss 4.9253 (6.7848)	Training Prec@1 99.805 (99.246)	Training Prec@5 100.000 (99.722)	
2022-07-24 22:32:24,334: ============================================================
2022-07-24 22:33:05,064: time cost, forward:0.12434328098301455, backward:0.09702863907862805, data cost:0.1860018385136824 
2022-07-24 22:33:05,064: ============================================================
2022-07-24 22:33:05,065: Epoch 10/25 Batch 4400/7662 eta: 13:22:21.018872	Training Loss1 5.0918 (6.7618)	Training Total_Loss 5.0918 (6.7618)	Training Prec@1 99.609 (99.252)	Training Prec@5 100.000 (99.725)	
2022-07-24 22:33:05,065: ============================================================
2022-07-24 22:33:45,842: time cost, forward:0.12435158434696371, backward:0.09702802176050515, data cost:0.18598836796843865 
2022-07-24 22:33:45,842: ============================================================
2022-07-24 22:33:45,843: Epoch 10/25 Batch 4500/7662 eta: 13:22:36.004785	Training Loss1 6.0203 (6.7382)	Training Total_Loss 6.0203 (6.7382)	Training Prec@1 99.805 (99.257)	Training Prec@5 100.000 (99.727)	
2022-07-24 22:33:45,843: ============================================================
2022-07-24 22:34:26,604: time cost, forward:0.12435454865024514, backward:0.09702670830803141, data cost:0.18597761530750703 
2022-07-24 22:34:26,605: ============================================================
2022-07-24 22:34:26,605: Epoch 10/25 Batch 4600/7662 eta: 13:21:36.514934	Training Loss1 5.9726 (6.7148)	Training Total_Loss 5.9726 (6.7148)	Training Prec@1 99.609 (99.263)	Training Prec@5 100.000 (99.730)	
2022-07-24 22:34:26,605: ============================================================
2022-07-24 22:35:07,344: time cost, forward:0.12435192451956019, backward:0.0970259447964386, data cost:0.18596709725907012 
2022-07-24 22:35:07,344: ============================================================
2022-07-24 22:35:07,345: Epoch 10/25 Batch 4700/7662 eta: 13:20:29.376040	Training Loss1 5.4670 (6.6926)	Training Total_Loss 5.4670 (6.6926)	Training Prec@1 99.414 (99.268)	Training Prec@5 100.000 (99.732)	
2022-07-24 22:35:07,345: ============================================================
2022-07-24 22:35:48,078: time cost, forward:0.12435018864739163, backward:0.09702456332813032, data cost:0.18595563145721175 
2022-07-24 22:35:48,078: ============================================================
2022-07-24 22:35:48,079: Epoch 10/25 Batch 4800/7662 eta: 13:19:41.643030	Training Loss1 5.8568 (6.6717)	Training Total_Loss 5.8568 (6.6717)	Training Prec@1 99.414 (99.274)	Training Prec@5 100.000 (99.735)	
2022-07-24 22:35:48,079: ============================================================
2022-07-24 22:36:28,841: time cost, forward:0.12435090661073223, backward:0.09702436221719007, data cost:0.18594714149355182 
2022-07-24 22:36:28,841: ============================================================
2022-07-24 22:36:28,841: Epoch 10/25 Batch 4900/7662 eta: 13:19:34.952077	Training Loss1 5.5271 (6.6500)	Training Total_Loss 5.5271 (6.6500)	Training Prec@1 99.609 (99.279)	Training Prec@5 100.000 (99.737)	
2022-07-24 22:36:28,841: ============================================================
2022-07-24 22:37:09,602: time cost, forward:0.1243527991029114, backward:0.09702507775648758, data cost:0.18593700520156217 
2022-07-24 22:37:09,603: ============================================================
2022-07-24 22:37:09,603: Epoch 10/25 Batch 5000/7662 eta: 13:18:52.639436	Training Loss1 5.8010 (6.6296)	Training Total_Loss 5.8010 (6.6296)	Training Prec@1 99.609 (99.285)	Training Prec@5 99.805 (99.739)	
2022-07-24 22:37:09,603: ============================================================
2022-07-24 22:37:50,348: time cost, forward:0.12435144975059616, backward:0.09702558343516632, data cost:0.18592694053979078 
2022-07-24 22:37:50,348: ============================================================
2022-07-24 22:37:50,348: Epoch 10/25 Batch 5100/7662 eta: 13:17:52.963913	Training Loss1 6.0993 (6.6087)	Training Total_Loss 6.0993 (6.6087)	Training Prec@1 99.219 (99.291)	Training Prec@5 99.805 (99.741)	
2022-07-24 22:37:50,348: ============================================================
2022-07-24 22:38:31,086: time cost, forward:0.12435097253237763, backward:0.09702545135015248, data cost:0.18591617290550388 
2022-07-24 22:38:31,086: ============================================================
2022-07-24 22:38:31,086: Epoch 10/25 Batch 5200/7662 eta: 13:17:03.416660	Training Loss1 5.4855 (6.5885)	Training Total_Loss 5.4855 (6.5885)	Training Prec@1 99.609 (99.296)	Training Prec@5 100.000 (99.743)	
2022-07-24 22:38:31,086: ============================================================
2022-07-24 22:39:11,833: time cost, forward:0.12435219683361899, backward:0.09702468116365755, data cost:0.18590675054529654 
2022-07-24 22:39:11,834: ============================================================
2022-07-24 22:39:11,834: Epoch 10/25 Batch 5300/7662 eta: 13:16:34.391572	Training Loss1 5.4846 (6.5686)	Training Total_Loss 5.4846 (6.5686)	Training Prec@1 99.609 (99.301)	Training Prec@5 100.000 (99.745)	
2022-07-24 22:39:11,834: ============================================================
2022-07-24 22:39:52,576: time cost, forward:0.12435289258580667, backward:0.09702395968888508, data cost:0.18589714920770284 
2022-07-24 22:39:52,576: ============================================================
2022-07-24 22:39:52,576: Epoch 10/25 Batch 5400/7662 eta: 13:15:47.352515	Training Loss1 5.4028 (6.5496)	Training Total_Loss 5.4028 (6.5496)	Training Prec@1 99.609 (99.305)	Training Prec@5 99.609 (99.747)	
2022-07-24 22:39:52,576: ============================================================
2022-07-24 22:40:33,350: time cost, forward:0.12435772709899391, backward:0.09702295020485514, data cost:0.18588985324144408 
2022-07-24 22:40:33,351: ============================================================
2022-07-24 22:40:33,351: Epoch 10/25 Batch 5500/7662 eta: 13:15:44.095768	Training Loss1 5.5802 (6.5305)	Training Total_Loss 5.5802 (6.5305)	Training Prec@1 99.414 (99.309)	Training Prec@5 99.805 (99.748)	
2022-07-24 22:40:33,351: ============================================================
2022-07-24 22:41:14,101: time cost, forward:0.12435956383671244, backward:0.09702073094844392, data cost:0.1858828535333747 
2022-07-24 22:41:14,101: ============================================================
2022-07-24 22:41:14,101: Epoch 10/25 Batch 5600/7662 eta: 13:14:34.730343	Training Loss1 5.6837 (6.5109)	Training Total_Loss 5.6837 (6.5109)	Training Prec@1 99.023 (99.313)	Training Prec@5 99.805 (99.750)	
2022-07-24 22:41:14,101: ============================================================
2022-07-24 22:41:54,830: time cost, forward:0.12435671985724617, backward:0.09702013818647469, data cost:0.18587515617299652 
2022-07-24 22:41:54,830: ============================================================
2022-07-24 22:41:54,831: Epoch 10/25 Batch 5700/7662 eta: 13:13:30.081929	Training Loss1 4.6349 (6.4920)	Training Total_Loss 4.6349 (6.4920)	Training Prec@1 99.609 (99.318)	Training Prec@5 99.805 (99.752)	
2022-07-24 22:41:54,831: ============================================================
2022-07-24 22:42:35,571: time cost, forward:0.12435932232606285, backward:0.09701801065864964, data cost:0.18586631634457806 
2022-07-24 22:42:35,571: ============================================================
2022-07-24 22:42:35,571: Epoch 10/25 Batch 5800/7662 eta: 13:13:02.516042	Training Loss1 4.9561 (6.4733)	Training Total_Loss 4.9561 (6.4733)	Training Prec@1 99.609 (99.323)	Training Prec@5 99.609 (99.754)	
2022-07-24 22:42:35,572: ============================================================
2022-07-24 22:43:16,302: time cost, forward:0.12435969374385561, backward:0.09701572452324653, data cost:0.1858584412398389 
2022-07-24 22:43:16,302: ============================================================
2022-07-24 22:43:16,302: Epoch 10/25 Batch 5900/7662 eta: 13:12:09.695206	Training Loss1 5.4713 (6.4549)	Training Total_Loss 5.4713 (6.4549)	Training Prec@1 99.805 (99.328)	Training Prec@5 100.000 (99.757)	
2022-07-24 22:43:16,302: ============================================================
2022-07-24 22:43:57,037: time cost, forward:0.124360262622315, backward:0.09701450225968702, data cost:0.18585019331014957 
2022-07-24 22:43:57,038: ============================================================
2022-07-24 22:43:57,038: Epoch 10/25 Batch 6000/7662 eta: 13:11:35.311208	Training Loss1 5.0352 (6.4375)	Training Total_Loss 5.0352 (6.4375)	Training Prec@1 99.609 (99.332)	Training Prec@5 100.000 (99.758)	
2022-07-24 22:43:57,038: ============================================================
2022-07-24 22:44:37,772: time cost, forward:0.12435868193349167, backward:0.09701549969729605, data cost:0.18584168041352464 
2022-07-24 22:44:37,772: ============================================================
2022-07-24 22:44:37,772: Epoch 10/25 Batch 6100/7662 eta: 13:10:52.801288	Training Loss1 5.1800 (6.4202)	Training Total_Loss 5.1800 (6.4202)	Training Prec@1 99.805 (99.336)	Training Prec@5 100.000 (99.760)	
2022-07-24 22:44:37,773: ============================================================
2022-07-24 22:45:18,503: time cost, forward:0.12435542569850448, backward:0.0970173380147605, data cost:0.18583370947341685 
2022-07-24 22:45:18,503: ============================================================
2022-07-24 22:45:18,503: Epoch 10/25 Batch 6200/7662 eta: 13:10:07.867931	Training Loss1 5.0346 (6.4034)	Training Total_Loss 5.0346 (6.4034)	Training Prec@1 99.805 (99.339)	Training Prec@5 99.805 (99.761)	
2022-07-24 22:45:18,503: ============================================================
2022-07-24 22:45:59,219: time cost, forward:0.12435235899958388, backward:0.09701683385388438, data cost:0.18582614559392208 
2022-07-24 22:45:59,219: ============================================================
2022-07-24 22:45:59,219: Epoch 10/25 Batch 6300/7662 eta: 13:09:09.673315	Training Loss1 4.9821 (6.3867)	Training Total_Loss 4.9821 (6.3867)	Training Prec@1 99.609 (99.343)	Training Prec@5 99.805 (99.762)	
2022-07-24 22:45:59,219: ============================================================
2022-07-24 22:46:40,010: time cost, forward:0.12435532461983988, backward:0.09701798416372574, data cost:0.18582292708927328 
2022-07-24 22:46:40,011: ============================================================
2022-07-24 22:46:40,011: Epoch 10/25 Batch 6400/7662 eta: 13:09:56.881553	Training Loss1 5.8825 (6.3706)	Training Total_Loss 5.8825 (6.3706)	Training Prec@1 99.609 (99.346)	Training Prec@5 99.609 (99.763)	
2022-07-24 22:46:40,011: ============================================================
2022-07-24 22:47:20,850: time cost, forward:0.12436355090284369, backward:0.09701938019438622, data cost:0.18582141874459804 
2022-07-24 22:47:20,850: ============================================================
2022-07-24 22:47:20,850: Epoch 10/25 Batch 6500/7662 eta: 13:10:11.695775	Training Loss1 5.4606 (6.3548)	Training Total_Loss 5.4606 (6.3548)	Training Prec@1 99.609 (99.349)	Training Prec@5 99.609 (99.764)	
2022-07-24 22:47:20,850: ============================================================
2022-07-24 22:48:01,677: time cost, forward:0.12437013814550112, backward:0.09702014467863987, data cost:0.18581989032244173 
2022-07-24 22:48:01,677: ============================================================
2022-07-24 22:48:01,677: Epoch 10/25 Batch 6600/7662 eta: 13:09:16.505415	Training Loss1 5.4957 (6.3388)	Training Total_Loss 5.4957 (6.3388)	Training Prec@1 99.023 (99.353)	Training Prec@5 99.219 (99.766)	
2022-07-24 22:48:01,677: ============================================================
2022-07-24 22:48:42,457: time cost, forward:0.1243715947876227, backward:0.09702116461863605, data cost:0.18581639120589086 
2022-07-24 22:48:42,458: ============================================================
2022-07-24 22:48:42,458: Epoch 10/25 Batch 6700/7662 eta: 13:07:41.884879	Training Loss1 5.2061 (6.3234)	Training Total_Loss 5.2061 (6.3234)	Training Prec@1 99.609 (99.355)	Training Prec@5 100.000 (99.767)	
2022-07-24 22:48:42,458: ============================================================
2022-07-24 22:49:23,257: time cost, forward:0.12437506952186177, backward:0.09702276885465658, data cost:0.1858133518234704 
2022-07-24 22:49:23,257: ============================================================
2022-07-24 22:49:23,257: Epoch 10/25 Batch 6800/7662 eta: 13:07:22.726772	Training Loss1 5.4191 (6.3079)	Training Total_Loss 5.4191 (6.3079)	Training Prec@1 99.023 (99.359)	Training Prec@5 99.805 (99.768)	
2022-07-24 22:49:23,257: ============================================================
2022-07-24 22:50:04,041: time cost, forward:0.12437513863319831, backward:0.09702426199464456, data cost:0.1858115410835851 
2022-07-24 22:50:04,041: ============================================================
2022-07-24 22:50:04,042: Epoch 10/25 Batch 6900/7662 eta: 13:06:24.822760	Training Loss1 5.2792 (6.2922)	Training Total_Loss 5.2792 (6.2922)	Training Prec@1 99.609 (99.363)	Training Prec@5 99.805 (99.769)	
2022-07-24 22:50:04,042: ============================================================
2022-07-24 22:50:44,826: time cost, forward:0.12437522941051951, backward:0.09702596590849039, data cost:0.1858096527770547 
2022-07-24 22:50:44,826: ============================================================
2022-07-24 22:50:44,826: Epoch 10/25 Batch 7000/7662 eta: 13:05:44.304199	Training Loss1 5.0391 (6.2769)	Training Total_Loss 5.0391 (6.2769)	Training Prec@1 99.414 (99.366)	Training Prec@5 100.000 (99.771)	
2022-07-24 22:50:44,826: ============================================================
2022-07-24 22:51:25,616: time cost, forward:0.12437591093965845, backward:0.09702660275405688, data cost:0.18580899145892346 
2022-07-24 22:51:25,616: ============================================================
2022-07-24 22:51:25,617: Epoch 10/25 Batch 7100/7662 eta: 13:05:09.843303	Training Loss1 5.4356 (6.2629)	Training Total_Loss 5.4356 (6.2629)	Training Prec@1 99.023 (99.370)	Training Prec@5 99.609 (99.773)	
2022-07-24 22:51:25,617: ============================================================
2022-07-24 22:52:06,415: time cost, forward:0.12437821477796489, backward:0.09702756617164957, data cost:0.1858070914754273 
2022-07-24 22:52:06,415: ============================================================
2022-07-24 22:52:06,415: Epoch 10/25 Batch 7200/7662 eta: 13:04:38.836296	Training Loss1 5.3021 (6.2483)	Training Total_Loss 5.3021 (6.2483)	Training Prec@1 99.805 (99.373)	Training Prec@5 100.000 (99.774)	
2022-07-24 22:52:06,415: ============================================================
2022-07-24 22:52:47,214: time cost, forward:0.12437876362819543, backward:0.09702909219785984, data cost:0.1858066022355257 
2022-07-24 22:52:47,214: ============================================================
2022-07-24 22:52:47,214: Epoch 10/25 Batch 7300/7662 eta: 13:03:58.463117	Training Loss1 5.6043 (6.2342)	Training Total_Loss 5.6043 (6.2342)	Training Prec@1 100.000 (99.376)	Training Prec@5 100.000 (99.776)	
2022-07-24 22:52:47,214: ============================================================
2022-07-24 22:53:28,023: time cost, forward:0.12438134206825212, backward:0.09703067354711911, data cost:0.18580548037289124 
2022-07-24 22:53:28,023: ============================================================
2022-07-24 22:53:28,023: Epoch 10/25 Batch 7400/7662 eta: 13:03:29.116880	Training Loss1 5.4850 (6.2201)	Training Total_Loss 5.4850 (6.2201)	Training Prec@1 99.414 (99.379)	Training Prec@5 99.805 (99.777)	
2022-07-24 22:53:28,023: ============================================================
2022-07-24 22:54:08,818: time cost, forward:0.12438196938170451, backward:0.09703193837633958, data cost:0.1858043608975134 
2022-07-24 22:54:08,819: ============================================================
2022-07-24 22:54:08,819: Epoch 10/25 Batch 7500/7662 eta: 13:02:32.808766	Training Loss1 4.9308 (6.2060)	Training Total_Loss 4.9308 (6.2060)	Training Prec@1 99.609 (99.382)	Training Prec@5 100.000 (99.778)	
2022-07-24 22:54:08,819: ============================================================
2022-07-24 22:54:49,632: time cost, forward:0.12438232965540895, backward:0.09703604144977258, data cost:0.18580341800323738 
2022-07-24 22:54:49,633: ============================================================
2022-07-24 22:54:49,633: Epoch 10/25 Batch 7600/7662 eta: 13:02:13.042481	Training Loss1 5.2086 (6.1928)	Training Total_Loss 5.2086 (6.1928)	Training Prec@1 100.000 (99.385)	Training Prec@5 100.000 (99.779)	
2022-07-24 22:54:49,633: ============================================================
2022-07-24 22:55:16,478: Epoch 10/25 Batch 7663/7662 eta: 13:01:47.329770	Training Loss1 4.9413 (6.1843)	Training Total_Loss 4.9413 (6.1843)	Training Prec@1 99.805 (99.387)	Training Prec@5 100.000 (99.780)	
2022-07-24 22:55:16,478: ============================================================
2022-07-24 22:55:16,618: Save Checkpoint...
2022-07-24 22:55:16,619: ============================================================
2022-07-24 22:55:19,077: Save done!
2022-07-24 22:55:19,077: ============================================================
2022-07-24 22:56:03,219: time cost, forward:0.12425765365061134, backward:0.0973063117325908, data cost:0.22129893784571175 
2022-07-24 22:56:03,219: ============================================================
2022-07-24 22:56:03,219: Epoch 11/25 Batch 100/7662 eta: 14:03:58.083543	Training Loss1 4.2919 (4.1041)	Training Total_Loss 4.2919 (4.1041)	Training Prec@1 99.805 (99.872)	Training Prec@5 100.000 (99.961)	
2022-07-24 22:56:03,220: ============================================================
2022-07-24 22:56:43,982: time cost, forward:0.1242572135062673, backward:0.09717618640343748, data cost:0.20338622050069685 
2022-07-24 22:56:43,983: ============================================================
2022-07-24 22:56:43,983: Epoch 11/25 Batch 200/7662 eta: 12:59:28.339699	Training Loss1 3.9056 (4.0951)	Training Total_Loss 3.9056 (4.0951)	Training Prec@1 99.805 (99.844)	Training Prec@5 99.805 (99.947)	
2022-07-24 22:56:43,983: ============================================================
2022-07-24 22:57:24,745: time cost, forward:0.12425293491835578, backward:0.09712950122794978, data cost:0.1974564842555834 
2022-07-24 22:57:24,745: ============================================================
2022-07-24 22:57:24,745: Epoch 11/25 Batch 300/7662 eta: 12:58:46.155878	Training Loss1 4.1412 (4.1206)	Training Total_Loss 4.1412 (4.1206)	Training Prec@1 99.805 (99.829)	Training Prec@5 100.000 (99.941)	
2022-07-24 22:57:24,745: ============================================================
2022-07-24 22:58:05,529: time cost, forward:0.12428838029541169, backward:0.09710964881686639, data cost:0.19451316735499485 
2022-07-24 22:58:05,529: ============================================================
2022-07-24 22:58:05,530: Epoch 11/25 Batch 400/7662 eta: 12:58:30.807635	Training Loss1 4.2230 (4.1115)	Training Total_Loss 4.2230 (4.1115)	Training Prec@1 100.000 (99.825)	Training Prec@5 100.000 (99.939)	
2022-07-24 22:58:05,530: ============================================================
2022-07-24 22:58:46,275: time cost, forward:0.12426663066198926, backward:0.09709320995277297, data cost:0.1927219889684765 
2022-07-24 22:58:46,275: ============================================================
2022-07-24 22:58:46,275: Epoch 11/25 Batch 500/7662 eta: 12:57:05.535588	Training Loss1 4.0860 (4.1178)	Training Total_Loss 4.0860 (4.1178)	Training Prec@1 99.609 (99.820)	Training Prec@5 99.805 (99.935)	
2022-07-24 22:58:46,275: ============================================================
2022-07-24 22:59:27,085: time cost, forward:0.12435343110302653, backward:0.09706982945361002, data cost:0.19155037542416375 
2022-07-24 22:59:27,086: ============================================================
2022-07-24 22:59:27,086: Epoch 11/25 Batch 600/7662 eta: 12:57:39.479246	Training Loss1 4.0291 (4.1233)	Training Total_Loss 4.0291 (4.1233)	Training Prec@1 99.805 (99.819)	Training Prec@5 100.000 (99.936)	
2022-07-24 22:59:27,086: ============================================================
2022-07-24 23:00:07,926: time cost, forward:0.1244361291456973, backward:0.09705989043600058, data cost:0.19072293928252781 
2022-07-24 23:00:07,926: ============================================================
2022-07-24 23:00:07,926: Epoch 11/25 Batch 700/7662 eta: 12:57:32.172070	Training Loss1 4.1549 (4.1270)	Training Total_Loss 4.1549 (4.1270)	Training Prec@1 99.805 (99.818)	Training Prec@5 100.000 (99.937)	
2022-07-24 23:00:07,926: ============================================================
2022-07-24 23:00:48,732: time cost, forward:0.12448343019163206, backward:0.09703791007231712, data cost:0.19009220137614033 
2022-07-24 23:00:48,732: ============================================================
2022-07-24 23:00:48,732: Epoch 11/25 Batch 800/7662 eta: 12:56:12.399799	Training Loss1 4.1655 (4.1287)	Training Total_Loss 4.1655 (4.1287)	Training Prec@1 99.805 (99.818)	Training Prec@5 100.000 (99.935)	
2022-07-24 23:00:48,732: ============================================================
2022-07-24 23:01:29,535: time cost, forward:0.12451244700074328, backward:0.09702119440072371, data cost:0.18960700045703383 
2022-07-24 23:01:29,535: ============================================================
2022-07-24 23:01:29,535: Epoch 11/25 Batch 900/7662 eta: 12:55:27.825303	Training Loss1 4.3301 (4.1369)	Training Total_Loss 4.3301 (4.1369)	Training Prec@1 99.609 (99.818)	Training Prec@5 99.609 (99.935)	
2022-07-24 23:01:29,535: ============================================================
2022-07-24 23:02:10,323: time cost, forward:0.12453257930171382, backward:0.09701115877420695, data cost:0.18920247929470912 
2022-07-24 23:02:10,323: ============================================================
2022-07-24 23:02:10,323: Epoch 11/25 Batch 1000/7662 eta: 12:54:30.514041	Training Loss1 4.6271 (4.1435)	Training Total_Loss 4.6271 (4.1435)	Training Prec@1 99.805 (99.818)	Training Prec@5 100.000 (99.936)	
2022-07-24 23:02:10,324: ============================================================
2022-07-24 23:02:51,066: time cost, forward:0.12451270887046863, backward:0.09700657499172777, data cost:0.18886629422216442 
2022-07-24 23:02:51,067: ============================================================
2022-07-24 23:02:51,067: Epoch 11/25 Batch 1100/7662 eta: 12:52:58.747048	Training Loss1 3.8933 (4.1514)	Training Total_Loss 3.8933 (4.1514)	Training Prec@1 99.219 (99.816)	Training Prec@5 99.414 (99.935)	
2022-07-24 23:02:51,067: ============================================================
2022-07-24 23:03:31,793: time cost, forward:0.12448797015173421, backward:0.09700185821094147, data cost:0.1885789379266225 
2022-07-24 23:03:31,793: ============================================================
2022-07-24 23:03:31,794: Epoch 11/25 Batch 1200/7662 eta: 12:51:58.919046	Training Loss1 4.2118 (4.1587)	Training Total_Loss 4.2118 (4.1587)	Training Prec@1 99.609 (99.814)	Training Prec@5 100.000 (99.934)	
2022-07-24 23:03:31,794: ============================================================
2022-07-24 23:04:12,495: time cost, forward:0.12445562908152051, backward:0.09699707787435177, data cost:0.1883281850190783 
2022-07-24 23:04:12,495: ============================================================
2022-07-24 23:04:12,496: Epoch 11/25 Batch 1300/7662 eta: 12:50:49.944298	Training Loss1 4.3809 (4.1644)	Training Total_Loss 4.3809 (4.1644)	Training Prec@1 99.609 (99.816)	Training Prec@5 100.000 (99.935)	
2022-07-24 23:04:12,496: ============================================================
2022-07-24 23:04:53,200: time cost, forward:0.12443275737966956, backward:0.0969907257538169, data cost:0.188114622135176 
2022-07-24 23:04:53,200: ============================================================
2022-07-24 23:04:53,201: Epoch 11/25 Batch 1400/7662 eta: 12:50:12.940171	Training Loss1 3.6953 (4.1689)	Training Total_Loss 3.6953 (4.1689)	Training Prec@1 100.000 (99.816)	Training Prec@5 100.000 (99.935)	
2022-07-24 23:04:53,201: ============================================================
2022-07-24 23:05:33,943: time cost, forward:0.12443482247569547, backward:0.09698617482201269, data cost:0.18793541101553665 
2022-07-24 23:05:33,944: ============================================================
2022-07-24 23:05:33,944: Epoch 11/25 Batch 1500/7662 eta: 12:50:15.486063	Training Loss1 3.9639 (4.1710)	Training Total_Loss 3.9639 (4.1710)	Training Prec@1 99.805 (99.819)	Training Prec@5 99.805 (99.935)	
2022-07-24 23:05:33,944: ============================================================
2022-07-24 23:06:14,658: time cost, forward:0.12441324069397088, backward:0.09698515433382436, data cost:0.1877788134557594 
2022-07-24 23:06:14,659: ============================================================
2022-07-24 23:06:14,659: Epoch 11/25 Batch 1600/7662 eta: 12:49:02.912449	Training Loss1 4.2693 (4.1762)	Training Total_Loss 4.2693 (4.1762)	Training Prec@1 99.805 (99.818)	Training Prec@5 99.805 (99.936)	
2022-07-24 23:06:14,659: ============================================================
2022-07-24 23:06:55,377: time cost, forward:0.1243997547751388, backward:0.09698289278467098, data cost:0.1876396282481193 
2022-07-24 23:06:55,377: ============================================================
2022-07-24 23:06:55,377: Epoch 11/25 Batch 1700/7662 eta: 12:48:25.698436	Training Loss1 4.3220 (4.1817)	Training Total_Loss 4.3220 (4.1817)	Training Prec@1 99.609 (99.816)	Training Prec@5 99.805 (99.934)	
2022-07-24 23:06:55,377: ============================================================
2022-07-24 23:07:36,113: time cost, forward:0.12439613742520904, backward:0.09698151256588845, data cost:0.18751603805601366 
2022-07-24 23:07:36,114: ============================================================
2022-07-24 23:07:36,114: Epoch 11/25 Batch 1800/7662 eta: 12:48:05.657045	Training Loss1 3.4847 (4.1891)	Training Total_Loss 3.4847 (4.1891)	Training Prec@1 100.000 (99.814)	Training Prec@5 100.000 (99.933)	
2022-07-24 23:07:36,114: ============================================================
2022-07-24 23:08:16,836: time cost, forward:0.1243855766147736, backward:0.09698152190575542, data cost:0.18740441536765276 
2022-07-24 23:08:16,836: ============================================================
2022-07-24 23:08:16,836: Epoch 11/25 Batch 1900/7662 eta: 12:47:08.889266	Training Loss1 4.0601 (4.1948)	Training Total_Loss 4.0601 (4.1948)	Training Prec@1 99.609 (99.814)	Training Prec@5 100.000 (99.933)	
2022-07-24 23:08:16,836: ============================================================
2022-07-24 23:08:57,569: time cost, forward:0.12437576601182061, backward:0.09698561729938761, data cost:0.18730537637345132 
2022-07-24 23:08:57,569: ============================================================
2022-07-24 23:08:57,569: Epoch 11/25 Batch 2000/7662 eta: 12:46:40.340978	Training Loss1 4.2171 (4.2008)	Training Total_Loss 4.2171 (4.2008)	Training Prec@1 99.805 (99.814)	Training Prec@5 100.000 (99.934)	
2022-07-24 23:08:57,569: ============================================================
2022-07-24 23:09:38,309: time cost, forward:0.12436554408062067, backward:0.09699041403833601, data cost:0.18721844753576153 
2022-07-24 23:09:38,310: ============================================================
2022-07-24 23:09:38,310: Epoch 11/25 Batch 2100/7662 eta: 12:46:07.722528	Training Loss1 4.5932 (4.2055)	Training Total_Loss 4.5932 (4.2055)	Training Prec@1 99.805 (99.815)	Training Prec@5 99.805 (99.934)	
2022-07-24 23:09:38,310: ============================================================
2022-07-24 23:10:19,040: time cost, forward:0.12435465761074536, backward:0.09699189614143736, data cost:0.1871389180435382 
2022-07-24 23:10:19,041: ============================================================
2022-07-24 23:10:19,041: Epoch 11/25 Batch 2200/7662 eta: 12:45:16.423234	Training Loss1 4.9168 (4.2127)	Training Total_Loss 4.9168 (4.2127)	Training Prec@1 99.805 (99.815)	Training Prec@5 100.000 (99.936)	
2022-07-24 23:10:19,041: ============================================================
2022-07-24 23:10:59,749: time cost, forward:0.12434229046015596, backward:0.09699023936613066, data cost:0.18706380973540476 
2022-07-24 23:10:59,749: ============================================================
2022-07-24 23:10:59,749: Epoch 11/25 Batch 2300/7662 eta: 12:44:10.145361	Training Loss1 4.6711 (4.2156)	Training Total_Loss 4.6711 (4.2156)	Training Prec@1 99.219 (99.815)	Training Prec@5 99.609 (99.935)	
2022-07-24 23:10:59,749: ============================================================
2022-07-24 23:11:40,484: time cost, forward:0.12433857289688345, backward:0.09698897622535009, data cost:0.18699769697471577 
2022-07-24 23:11:40,484: ============================================================
2022-07-24 23:11:40,484: Epoch 11/25 Batch 2400/7662 eta: 12:43:59.607099	Training Loss1 4.2937 (4.2204)	Training Total_Loss 4.2937 (4.2204)	Training Prec@1 99.609 (99.815)	Training Prec@5 99.805 (99.935)	
2022-07-24 23:11:40,484: ============================================================
2022-07-24 23:12:21,221: time cost, forward:0.12434026182723455, backward:0.09698832831701407, data cost:0.18693326062419596 
2022-07-24 23:12:21,222: ============================================================
2022-07-24 23:12:21,222: Epoch 11/25 Batch 2500/7662 eta: 12:43:21.964036	Training Loss1 4.5682 (4.2241)	Training Total_Loss 4.5682 (4.2241)	Training Prec@1 99.805 (99.815)	Training Prec@5 100.000 (99.935)	
2022-07-24 23:12:21,222: ============================================================
2022-07-24 23:13:01,960: time cost, forward:0.12434117029886514, backward:0.09698769384826683, data cost:0.18687516728379536 
2022-07-24 23:13:01,961: ============================================================
2022-07-24 23:13:01,961: Epoch 11/25 Batch 2600/7662 eta: 12:42:42.291574	Training Loss1 4.1308 (4.2286)	Training Total_Loss 4.1308 (4.2286)	Training Prec@1 99.805 (99.815)	Training Prec@5 99.805 (99.936)	
2022-07-24 23:13:01,961: ============================================================
2022-07-24 23:13:42,691: time cost, forward:0.12433633507512684, backward:0.096986526116127, data cost:0.18682403624521532 
2022-07-24 23:13:42,692: ============================================================
2022-07-24 23:13:42,692: Epoch 11/25 Batch 2700/7662 eta: 12:41:53.008700	Training Loss1 4.3476 (4.2332)	Training Total_Loss 4.3476 (4.2332)	Training Prec@1 100.000 (99.816)	Training Prec@5 100.000 (99.936)	
2022-07-24 23:13:42,692: ============================================================
2022-07-24 23:14:23,410: time cost, forward:0.1243293345847612, backward:0.09698617862948097, data cost:0.18677326405461492 
2022-07-24 23:14:23,410: ============================================================
2022-07-24 23:14:23,410: Epoch 11/25 Batch 2800/7662 eta: 12:40:57.946967	Training Loss1 4.5558 (4.2363)	Training Total_Loss 4.5558 (4.2363)	Training Prec@1 100.000 (99.816)	Training Prec@5 100.000 (99.936)	
2022-07-24 23:14:23,410: ============================================================
2022-07-24 23:15:04,128: time cost, forward:0.12432647976804577, backward:0.0969837489067254, data cost:0.18672398790568062 
2022-07-24 23:15:04,128: ============================================================
2022-07-24 23:15:04,128: Epoch 11/25 Batch 2900/7662 eta: 12:40:16.952118	Training Loss1 4.3123 (4.2408)	Training Total_Loss 4.3123 (4.2408)	Training Prec@1 99.805 (99.816)	Training Prec@5 100.000 (99.935)	
2022-07-24 23:15:04,129: ============================================================
2022-07-24 23:15:44,865: time cost, forward:0.12432642832085386, backward:0.09698503364837738, data cost:0.18667839137106268 
2022-07-24 23:15:44,866: ============================================================
2022-07-24 23:15:44,866: Epoch 11/25 Batch 3000/7662 eta: 12:39:57.790197	Training Loss1 4.4884 (4.2436)	Training Total_Loss 4.4884 (4.2436)	Training Prec@1 99.805 (99.815)	Training Prec@5 99.805 (99.935)	
2022-07-24 23:15:44,866: ============================================================
2022-07-24 23:16:25,649: time cost, forward:0.12433024574457041, backward:0.09698945655096497, data cost:0.18664457760306472 
2022-07-24 23:16:25,649: ============================================================
2022-07-24 23:16:25,650: Epoch 11/25 Batch 3100/7662 eta: 12:40:08.772876	Training Loss1 4.4658 (4.2469)	Training Total_Loss 4.4658 (4.2469)	Training Prec@1 100.000 (99.816)	Training Prec@5 100.000 (99.935)	
2022-07-24 23:16:25,650: ============================================================
2022-07-24 23:17:06,429: time cost, forward:0.12433476155905024, backward:0.096991252809735, data cost:0.18661212734819838 
2022-07-24 23:17:06,430: ============================================================
2022-07-24 23:17:06,430: Epoch 11/25 Batch 3200/7662 eta: 12:39:24.270715	Training Loss1 4.2021 (4.2505)	Training Total_Loss 4.2021 (4.2505)	Training Prec@1 100.000 (99.816)	Training Prec@5 100.000 (99.936)	
2022-07-24 23:17:06,430: ============================================================
2022-07-24 23:17:47,214: time cost, forward:0.12433862100770597, backward:0.09699334712345045, data cost:0.18658381261475776 
2022-07-24 23:17:47,215: ============================================================
2022-07-24 23:17:47,215: Epoch 11/25 Batch 3300/7662 eta: 12:38:48.651281	Training Loss1 4.4888 (4.2548)	Training Total_Loss 4.4888 (4.2548)	Training Prec@1 100.000 (99.816)	Training Prec@5 100.000 (99.935)	
2022-07-24 23:17:47,215: ============================================================
2022-07-24 23:18:27,994: time cost, forward:0.1243396022804487, backward:0.09699651647154181, data cost:0.18655595978627174 
2022-07-24 23:18:27,995: ============================================================
2022-07-24 23:18:27,995: Epoch 11/25 Batch 3400/7662 eta: 12:38:02.436166	Training Loss1 4.3333 (4.2596)	Training Total_Loss 4.3333 (4.2596)	Training Prec@1 100.000 (99.816)	Training Prec@5 100.000 (99.935)	
2022-07-24 23:18:27,995: ============================================================
2022-07-24 23:19:08,779: time cost, forward:0.12434221554156813, backward:0.0969982984645873, data cost:0.18653062024297767 
2022-07-24 23:19:08,779: ============================================================
2022-07-24 23:19:08,779: Epoch 11/25 Batch 3500/7662 eta: 12:37:26.283560	Training Loss1 4.7175 (4.2644)	Training Total_Loss 4.7175 (4.2644)	Training Prec@1 100.000 (99.815)	Training Prec@5 100.000 (99.935)	
2022-07-24 23:19:08,779: ============================================================
2022-07-24 23:19:49,626: time cost, forward:0.12435748478411701, backward:0.0969991000303463, data cost:0.18651198413379327 
2022-07-24 23:19:49,627: ============================================================
2022-07-24 23:19:49,627: Epoch 11/25 Batch 3600/7662 eta: 12:37:56.388459	Training Loss1 4.2761 (4.2677)	Training Total_Loss 4.2761 (4.2677)	Training Prec@1 100.000 (99.814)	Training Prec@5 100.000 (99.934)	
2022-07-24 23:19:49,627: ============================================================
2022-07-24 23:20:30,471: time cost, forward:0.12437257846647677, backward:0.09699968654872856, data cost:0.18649433373953722 
2022-07-24 23:20:30,472: ============================================================
2022-07-24 23:20:30,472: Epoch 11/25 Batch 3700/7662 eta: 12:37:11.875282	Training Loss1 4.2844 (4.2712)	Training Total_Loss 4.2844 (4.2712)	Training Prec@1 99.805 (99.814)	Training Prec@5 99.805 (99.934)	
2022-07-24 23:20:30,472: ============================================================
2022-07-24 23:21:11,351: time cost, forward:0.12439350091523012, backward:0.09700084630047907, data cost:0.1864787710751631 
2022-07-24 23:21:11,352: ============================================================
2022-07-24 23:21:11,352: Epoch 11/25 Batch 3800/7662 eta: 12:37:10.469243	Training Loss1 4.4092 (4.2745)	Training Total_Loss 4.4092 (4.2745)	Training Prec@1 99.805 (99.813)	Training Prec@5 99.805 (99.934)	
2022-07-24 23:21:11,352: ============================================================
2022-07-24 23:21:52,205: time cost, forward:0.1244067276829663, backward:0.09700066549834853, data cost:0.18646552520521056 
2022-07-24 23:21:52,206: ============================================================
2022-07-24 23:21:52,206: Epoch 11/25 Batch 3900/7662 eta: 12:36:00.710729	Training Loss1 3.8880 (4.2787)	Training Total_Loss 3.8880 (4.2787)	Training Prec@1 100.000 (99.812)	Training Prec@5 100.000 (99.933)	
2022-07-24 23:21:52,206: ============================================================
2022-07-24 23:22:33,060: time cost, forward:0.12442175106097234, backward:0.09699946369162557, data cost:0.18645211069784812 
2022-07-24 23:22:33,060: ============================================================
2022-07-24 23:22:33,060: Epoch 11/25 Batch 4000/7662 eta: 12:35:20.322383	Training Loss1 4.4615 (4.2823)	Training Total_Loss 4.4615 (4.2823)	Training Prec@1 99.805 (99.811)	Training Prec@5 100.000 (99.933)	
2022-07-24 23:22:33,061: ============================================================
2022-07-24 23:23:13,866: time cost, forward:0.12442249785286241, backward:0.09700364745457192, data cost:0.18643556271683562 
2022-07-24 23:23:13,867: ============================================================
2022-07-24 23:23:13,867: Epoch 11/25 Batch 4100/7662 eta: 12:33:46.132267	Training Loss1 4.7993 (4.2872)	Training Total_Loss 4.7993 (4.2872)	Training Prec@1 99.414 (99.810)	Training Prec@5 99.609 (99.933)	
2022-07-24 23:23:13,867: ============================================================
2022-07-24 23:23:54,681: time cost, forward:0.12443034056681455, backward:0.09700444642348811, data cost:0.18641737342647327 
2022-07-24 23:23:54,681: ============================================================
2022-07-24 23:23:54,681: Epoch 11/25 Batch 4200/7662 eta: 12:33:14.279282	Training Loss1 3.7900 (4.2905)	Training Total_Loss 3.7900 (4.2905)	Training Prec@1 99.805 (99.809)	Training Prec@5 100.000 (99.933)	
2022-07-24 23:23:54,681: ============================================================
2022-07-24 23:24:35,491: time cost, forward:0.12443623916579835, backward:0.09700440428761112, data cost:0.1864015749372086 
2022-07-24 23:24:35,491: ============================================================
2022-07-24 23:24:35,491: Epoch 11/25 Batch 4300/7662 eta: 12:32:28.233820	Training Loss1 4.4069 (4.2946)	Training Total_Loss 4.4069 (4.2946)	Training Prec@1 99.805 (99.809)	Training Prec@5 100.000 (99.932)	
2022-07-24 23:24:35,491: ============================================================
2022-07-24 23:25:16,299: time cost, forward:0.12444175018671291, backward:0.09700535904090224, data cost:0.1863856802856036 
2022-07-24 23:25:16,299: ============================================================
2022-07-24 23:25:16,299: Epoch 11/25 Batch 4400/7662 eta: 12:31:45.882177	Training Loss1 4.3027 (4.2977)	Training Total_Loss 4.3027 (4.2977)	Training Prec@1 99.805 (99.808)	Training Prec@5 100.000 (99.932)	
2022-07-24 23:25:16,300: ============================================================
2022-07-24 23:25:57,102: time cost, forward:0.12444389971342848, backward:0.09700776153364349, data cost:0.18637086805117664 
2022-07-24 23:25:57,102: ============================================================
2022-07-24 23:25:57,103: Epoch 11/25 Batch 4500/7662 eta: 12:30:59.313081	Training Loss1 4.3172 (4.3015)	Training Total_Loss 4.3172 (4.3015)	Training Prec@1 100.000 (99.807)	Training Prec@5 100.000 (99.932)	
2022-07-24 23:25:57,103: ============================================================
2022-07-24 23:26:37,900: time cost, forward:0.1244439583650022, backward:0.09701051103418147, data cost:0.18635747909131167 
2022-07-24 23:26:37,900: ============================================================
2022-07-24 23:26:37,900: Epoch 11/25 Batch 4600/7662 eta: 12:30:12.486370	Training Loss1 4.6225 (4.3052)	Training Total_Loss 4.6225 (4.3052)	Training Prec@1 99.609 (99.806)	Training Prec@5 99.805 (99.932)	
2022-07-24 23:26:37,900: ============================================================
2022-07-24 23:27:18,688: time cost, forward:0.12444207885971117, backward:0.09701323559954461, data cost:0.18634416879961202 
2022-07-24 23:27:18,688: ============================================================
2022-07-24 23:27:18,688: Epoch 11/25 Batch 4700/7662 eta: 12:29:21.003578	Training Loss1 4.6155 (4.3088)	Training Total_Loss 4.6155 (4.3088)	Training Prec@1 99.805 (99.805)	Training Prec@5 100.000 (99.931)	
2022-07-24 23:27:18,688: ============================================================
2022-07-24 23:27:59,481: time cost, forward:0.12444276555326239, backward:0.09701606903902862, data cost:0.18632914002027628 
2022-07-24 23:27:59,481: ============================================================
2022-07-24 23:27:59,481: Epoch 11/25 Batch 4800/7662 eta: 12:28:45.543982	Training Loss1 4.4035 (4.3126)	Training Total_Loss 4.4035 (4.3126)	Training Prec@1 99.609 (99.805)	Training Prec@5 100.000 (99.931)	
2022-07-24 23:27:59,481: ============================================================
2022-07-24 23:28:40,243: time cost, forward:0.1244393785916243, backward:0.09701731327140202, data cost:0.1863139795512417 
2022-07-24 23:28:40,243: ============================================================
2022-07-24 23:28:40,243: Epoch 11/25 Batch 4900/7662 eta: 12:27:30.891403	Training Loss1 4.1817 (4.3166)	Training Total_Loss 4.1817 (4.3166)	Training Prec@1 100.000 (99.804)	Training Prec@5 100.000 (99.931)	
2022-07-24 23:28:40,243: ============================================================
2022-07-24 23:29:21,043: time cost, forward:0.12444538110541115, backward:0.09701745160509763, data cost:0.1862991724664818 
2022-07-24 23:29:21,043: ============================================================
2022-07-24 23:29:21,044: Epoch 11/25 Batch 5000/7662 eta: 12:27:32.260749	Training Loss1 4.4410 (4.3201)	Training Total_Loss 4.4410 (4.3201)	Training Prec@1 99.805 (99.803)	Training Prec@5 100.000 (99.931)	
2022-07-24 23:29:21,044: ============================================================
2022-07-24 23:30:01,849: time cost, forward:0.12445176332738966, backward:0.09701610462505178, data cost:0.18628682793764817 
2022-07-24 23:30:01,849: ============================================================
2022-07-24 23:30:01,850: Epoch 11/25 Batch 5100/7662 eta: 12:26:57.700438	Training Loss1 4.9229 (4.3223)	Training Total_Loss 4.9229 (4.3223)	Training Prec@1 99.609 (99.803)	Training Prec@5 100.000 (99.931)	
2022-07-24 23:30:01,850: ============================================================
2022-07-24 23:30:42,662: time cost, forward:0.12445932788375617, backward:0.09701515078705121, data cost:0.18627488629179154 
2022-07-24 23:30:42,662: ============================================================
2022-07-24 23:30:42,662: Epoch 11/25 Batch 5200/7662 eta: 12:26:24.319915	Training Loss1 4.6208 (4.3255)	Training Total_Loss 4.6208 (4.3255)	Training Prec@1 100.000 (99.803)	Training Prec@5 100.000 (99.931)	
2022-07-24 23:30:42,663: ============================================================
2022-07-24 23:31:23,464: time cost, forward:0.1244651285471343, backward:0.09701382688676036, data cost:0.1862626575618268 
2022-07-24 23:31:23,464: ============================================================
2022-07-24 23:31:23,464: Epoch 11/25 Batch 5300/7662 eta: 12:25:31.681184	Training Loss1 4.4817 (4.3285)	Training Total_Loss 4.4817 (4.3285)	Training Prec@1 99.805 (99.802)	Training Prec@5 100.000 (99.931)	
2022-07-24 23:31:23,465: ============================================================
2022-07-24 23:32:04,234: time cost, forward:0.12446371253540525, backward:0.09701421791192535, data cost:0.18625059903253116 
2022-07-24 23:32:04,234: ============================================================
2022-07-24 23:32:04,234: Epoch 11/25 Batch 5400/7662 eta: 12:24:15.555740	Training Loss1 4.2009 (4.3310)	Training Total_Loss 4.2009 (4.3310)	Training Prec@1 100.000 (99.802)	Training Prec@5 100.000 (99.931)	
2022-07-24 23:32:04,234: ============================================================
2022-07-24 23:32:44,961: time cost, forward:0.12445915905122953, backward:0.09701435256815104, data cost:0.18623492747659054 
2022-07-24 23:32:44,962: ============================================================
2022-07-24 23:32:44,962: Epoch 11/25 Batch 5500/7662 eta: 12:22:48.827742	Training Loss1 4.6178 (4.3349)	Training Total_Loss 4.6178 (4.3349)	Training Prec@1 99.805 (99.802)	Training Prec@5 100.000 (99.931)	
2022-07-24 23:32:44,962: ============================================================
2022-07-24 23:33:25,701: time cost, forward:0.12445680467885271, backward:0.09701383933571327, data cost:0.18622036430745875 
2022-07-24 23:33:25,702: ============================================================
2022-07-24 23:33:25,702: Epoch 11/25 Batch 5600/7662 eta: 12:22:21.157986	Training Loss1 3.9882 (4.3381)	Training Total_Loss 3.9882 (4.3381)	Training Prec@1 100.000 (99.802)	Training Prec@5 100.000 (99.931)	
2022-07-24 23:33:25,702: ============================================================
2022-07-24 23:34:06,427: time cost, forward:0.1244524195018955, backward:0.09701313866211837, data cost:0.18620635484640882 
2022-07-24 23:34:06,427: ============================================================
2022-07-24 23:34:06,427: Epoch 11/25 Batch 5700/7662 eta: 12:21:24.651221	Training Loss1 4.7190 (4.3418)	Training Total_Loss 4.7190 (4.3418)	Training Prec@1 99.805 (99.801)	Training Prec@5 99.805 (99.931)	
2022-07-24 23:34:06,427: ============================================================
2022-07-24 23:34:47,155: time cost, forward:0.12444932371568096, backward:0.09701212584345396, data cost:0.186192775475689 
2022-07-24 23:34:47,155: ============================================================
2022-07-24 23:34:47,155: Epoch 11/25 Batch 5800/7662 eta: 12:20:47.276371	Training Loss1 4.0721 (4.3447)	Training Total_Loss 4.0721 (4.3447)	Training Prec@1 100.000 (99.801)	Training Prec@5 100.000 (99.931)	
2022-07-24 23:34:47,156: ============================================================
2022-07-24 23:35:27,886: time cost, forward:0.12444639711142354, backward:0.09701270700652916, data cost:0.1861779788809927 
2022-07-24 23:35:27,886: ============================================================
2022-07-24 23:35:27,886: Epoch 11/25 Batch 5900/7662 eta: 12:20:09.209891	Training Loss1 4.6607 (4.3471)	Training Total_Loss 4.6607 (4.3471)	Training Prec@1 99.219 (99.800)	Training Prec@5 100.000 (99.931)	
2022-07-24 23:35:27,886: ============================================================
2022-07-24 23:36:08,618: time cost, forward:0.12444456872750886, backward:0.09701202515463647, data cost:0.18616400863512653 
2022-07-24 23:36:08,618: ============================================================
2022-07-24 23:36:08,619: Epoch 11/25 Batch 6000/7662 eta: 12:19:30.186686	Training Loss1 5.0897 (4.3500)	Training Total_Loss 5.0897 (4.3500)	Training Prec@1 100.000 (99.800)	Training Prec@5 100.000 (99.931)	
2022-07-24 23:36:08,619: ============================================================
2022-07-24 23:36:49,338: time cost, forward:0.12444011706527207, backward:0.09701176924204354, data cost:0.18615079332637208 
2022-07-24 23:36:49,338: ============================================================
2022-07-24 23:36:49,339: Epoch 11/25 Batch 6100/7662 eta: 12:18:35.997243	Training Loss1 4.5588 (4.3531)	Training Total_Loss 4.5588 (4.3531)	Training Prec@1 99.805 (99.799)	Training Prec@5 99.805 (99.931)	
2022-07-24 23:36:49,339: ============================================================
2022-07-24 23:37:30,099: time cost, forward:0.12443605867734472, backward:0.09701374354410948, data cost:0.18614224688355663 
2022-07-24 23:37:30,099: ============================================================
2022-07-24 23:37:30,099: Epoch 11/25 Batch 6200/7662 eta: 12:18:39.365829	Training Loss1 4.5610 (4.3558)	Training Total_Loss 4.5610 (4.3558)	Training Prec@1 99.805 (99.799)	Training Prec@5 100.000 (99.930)	
2022-07-24 23:37:30,099: ============================================================
2022-07-24 23:38:10,858: time cost, forward:0.1244368465727597, backward:0.09701391041591104, data cost:0.18613091690764766 
2022-07-24 23:38:10,859: ============================================================
2022-07-24 23:38:10,859: Epoch 11/25 Batch 6300/7662 eta: 12:17:57.756277	Training Loss1 4.2547 (4.3589)	Training Total_Loss 4.2547 (4.3589)	Training Prec@1 100.000 (99.798)	Training Prec@5 100.000 (99.930)	
2022-07-24 23:38:10,859: ============================================================
2022-07-24 23:38:51,596: time cost, forward:0.12443297742809946, backward:0.09701483680747751, data cost:0.18612038502377967 
2022-07-24 23:38:51,596: ============================================================
2022-07-24 23:38:51,597: Epoch 11/25 Batch 6400/7662 eta: 12:16:52.920612	Training Loss1 5.0173 (4.3621)	Training Total_Loss 5.0173 (4.3621)	Training Prec@1 99.609 (99.798)	Training Prec@5 100.000 (99.930)	
2022-07-24 23:38:51,597: ============================================================
2022-07-24 23:39:32,346: time cost, forward:0.1244326717836304, backward:0.09701435029240714, data cost:0.18610998303509801 
2022-07-24 23:39:32,346: ============================================================
2022-07-24 23:39:32,346: Epoch 11/25 Batch 6500/7662 eta: 12:16:25.269538	Training Loss1 4.7603 (4.3656)	Training Total_Loss 4.7603 (4.3656)	Training Prec@1 100.000 (99.797)	Training Prec@5 100.000 (99.930)	
2022-07-24 23:39:32,346: ============================================================
2022-07-24 23:40:13,112: time cost, forward:0.12443281625469339, backward:0.09701452661344619, data cost:0.18610106130173068 
2022-07-24 23:40:13,112: ============================================================
2022-07-24 23:40:13,112: Epoch 11/25 Batch 6600/7662 eta: 12:16:02.067758	Training Loss1 4.3943 (4.3676)	Training Total_Loss 4.3943 (4.3676)	Training Prec@1 99.609 (99.797)	Training Prec@5 100.000 (99.930)	
2022-07-24 23:40:13,112: ============================================================
2022-07-24 23:40:53,852: time cost, forward:0.12442932625033283, backward:0.0970144790043527, data cost:0.18609219455847117 
2022-07-24 23:40:53,853: ============================================================
2022-07-24 23:40:53,853: Epoch 11/25 Batch 6700/7662 eta: 12:14:53.895168	Training Loss1 4.4065 (4.3703)	Training Total_Loss 4.4065 (4.3703)	Training Prec@1 99.609 (99.796)	Training Prec@5 99.609 (99.930)	
2022-07-24 23:40:53,853: ============================================================
2022-07-24 23:41:34,571: time cost, forward:0.12442407896981938, backward:0.09701421050784131, data cost:0.18608239633683896 
2022-07-24 23:41:34,571: ============================================================
2022-07-24 23:41:34,571: Epoch 11/25 Batch 6800/7662 eta: 12:13:49.182169	Training Loss1 4.3995 (4.3732)	Training Total_Loss 4.3995 (4.3732)	Training Prec@1 100.000 (99.795)	Training Prec@5 100.000 (99.930)	
2022-07-24 23:41:34,571: ============================================================
2022-07-24 23:42:15,299: time cost, forward:0.12442139774703481, backward:0.09701409079334256, data cost:0.18607207691691927 
2022-07-24 23:42:15,299: ============================================================
2022-07-24 23:42:15,300: Epoch 11/25 Batch 6900/7662 eta: 12:13:19.520075	Training Loss1 4.2523 (4.3754)	Training Total_Loss 4.2523 (4.3754)	Training Prec@1 100.000 (99.794)	Training Prec@5 100.000 (99.930)	
2022-07-24 23:42:15,300: ============================================================
2022-07-24 23:42:56,043: time cost, forward:0.12442069187183383, backward:0.09701448219948998, data cost:0.1860620935298082 
2022-07-24 23:42:56,043: ============================================================
2022-07-24 23:42:56,043: Epoch 11/25 Batch 7000/7662 eta: 12:12:55.161619	Training Loss1 4.3061 (4.3781)	Training Total_Loss 4.3061 (4.3781)	Training Prec@1 99.609 (99.794)	Training Prec@5 100.000 (99.930)	
2022-07-24 23:42:56,044: ============================================================
2022-07-24 23:43:36,780: time cost, forward:0.12441795966141256, backward:0.09701488541623104, data cost:0.18605303012043478 
2022-07-24 23:43:36,781: ============================================================
2022-07-24 23:43:36,781: Epoch 11/25 Batch 7100/7662 eta: 12:12:07.389029	Training Loss1 4.7566 (4.3806)	Training Total_Loss 4.7566 (4.3806)	Training Prec@1 99.609 (99.794)	Training Prec@5 99.805 (99.930)	
2022-07-24 23:43:36,781: ============================================================
2022-07-24 23:44:17,517: time cost, forward:0.12441618536260164, backward:0.09701463301523905, data cost:0.18604420357105517 
2022-07-24 23:44:17,517: ============================================================
2022-07-24 23:44:17,518: Epoch 11/25 Batch 7200/7662 eta: 12:11:26.230025	Training Loss1 4.4882 (4.3834)	Training Total_Loss 4.4882 (4.3834)	Training Prec@1 99.219 (99.793)	Training Prec@5 99.805 (99.929)	
2022-07-24 23:44:17,518: ============================================================
2022-07-24 23:44:58,287: time cost, forward:0.12441859550387227, backward:0.09701454801124357, data cost:0.18603603773565222 
2022-07-24 23:44:58,288: ============================================================
2022-07-24 23:44:58,288: Epoch 11/25 Batch 7300/7662 eta: 12:11:21.600309	Training Loss1 4.8724 (4.3863)	Training Total_Loss 4.8724 (4.3863)	Training Prec@1 99.609 (99.793)	Training Prec@5 100.000 (99.929)	
2022-07-24 23:44:58,288: ============================================================
2022-07-24 23:45:39,079: time cost, forward:0.12442211415867883, backward:0.09701429333037856, data cost:0.18602997835527676 
2022-07-24 23:45:39,080: ============================================================
2022-07-24 23:45:39,080: Epoch 11/25 Batch 7400/7662 eta: 12:11:03.745109	Training Loss1 4.9305 (4.3894)	Training Total_Loss 4.9305 (4.3894)	Training Prec@1 99.414 (99.792)	Training Prec@5 99.609 (99.929)	
2022-07-24 23:45:39,080: ============================================================
2022-07-24 23:46:19,868: time cost, forward:0.12442297988898723, backward:0.09701551963749179, data cost:0.18602463966656532 
2022-07-24 23:46:19,868: ============================================================
2022-07-24 23:46:19,868: Epoch 11/25 Batch 7500/7662 eta: 12:10:19.504012	Training Loss1 4.5494 (4.3923)	Training Total_Loss 4.5494 (4.3923)	Training Prec@1 100.000 (99.792)	Training Prec@5 100.000 (99.929)	
2022-07-24 23:46:19,868: ============================================================
2022-07-24 23:47:00,664: time cost, forward:0.12442434061544634, backward:0.09701724578901598, data cost:0.18601989303706334 
2022-07-24 23:47:00,664: ============================================================
2022-07-24 23:47:00,665: Epoch 11/25 Batch 7600/7662 eta: 12:09:47.127350	Training Loss1 4.7203 (4.3948)	Training Total_Loss 4.7203 (4.3948)	Training Prec@1 99.805 (99.791)	Training Prec@5 100.000 (99.929)	
2022-07-24 23:47:00,665: ============================================================
2022-07-24 23:47:28,119: Epoch 11/25 Batch 7663/7662 eta: 12:09:21.425651	Training Loss1 4.6215 (4.3965)	Training Total_Loss 4.6215 (4.3965)	Training Prec@1 99.609 (99.790)	Training Prec@5 99.805 (99.929)	
2022-07-24 23:47:28,119: ============================================================
2022-07-24 23:48:11,747: time cost, forward:0.12422585487365723, backward:0.0975140899118751, data cost:0.21539186949681755 
2022-07-24 23:48:11,747: ============================================================
2022-07-24 23:48:11,747: Epoch 12/25 Batch 100/7662 eta: 12:57:26.874400	Training Loss1 3.7371 (3.4842)	Training Total_Loss 3.7371 (3.4842)	Training Prec@1 100.000 (99.891)	Training Prec@5 100.000 (99.951)	
2022-07-24 23:48:11,747: ============================================================
2022-07-24 23:48:52,511: time cost, forward:0.12425201981510949, backward:0.09727263690239221, data cost:0.20045740400726472 
2022-07-24 23:48:52,511: ============================================================
2022-07-24 23:48:52,511: Epoch 12/25 Batch 200/7662 eta: 12:07:25.937162	Training Loss1 3.4825 (3.4751)	Training Total_Loss 3.4825 (3.4751)	Training Prec@1 100.000 (99.903)	Training Prec@5 100.000 (99.956)	
2022-07-24 23:48:52,511: ============================================================
2022-07-24 23:49:33,309: time cost, forward:0.12431874163573402, backward:0.09720784046976862, data cost:0.19556237463169673 
2022-07-24 23:49:33,309: ============================================================
2022-07-24 23:49:33,309: Epoch 12/25 Batch 300/7662 eta: 12:07:21.055878	Training Loss1 3.3425 (3.4681)	Training Total_Loss 3.3425 (3.4681)	Training Prec@1 100.000 (99.901)	Training Prec@5 100.000 (99.954)	
2022-07-24 23:49:33,309: ============================================================
2022-07-24 23:50:14,087: time cost, forward:0.12432690610861719, backward:0.09717727962293123, data cost:0.1930931612363734 
2022-07-24 23:50:14,088: ============================================================
2022-07-24 23:50:14,088: Epoch 12/25 Batch 400/7662 eta: 12:06:19.757939	Training Loss1 3.4603 (3.4836)	Training Total_Loss 3.4603 (3.4836)	Training Prec@1 100.000 (99.896)	Training Prec@5 100.000 (99.952)	
2022-07-24 23:50:14,088: ============================================================
2022-07-24 23:50:54,878: time cost, forward:0.12433387425715077, backward:0.09716886174463796, data cost:0.1916191372460497 
2022-07-24 23:50:54,878: ============================================================
2022-07-24 23:50:54,878: Epoch 12/25 Batch 500/7662 eta: 12:05:51.652649	Training Loss1 3.4355 (3.5014)	Training Total_Loss 3.4355 (3.5014)	Training Prec@1 99.805 (99.892)	Training Prec@5 100.000 (99.953)	
2022-07-24 23:50:54,879: ============================================================
2022-07-24 23:51:35,669: time cost, forward:0.12434660771454316, backward:0.09715884595562102, data cost:0.19063608355832617 
2022-07-24 23:51:35,669: ============================================================
2022-07-24 23:51:35,669: Epoch 12/25 Batch 600/7662 eta: 12:05:11.068615	Training Loss1 3.9526 (3.5161)	Training Total_Loss 3.9526 (3.5161)	Training Prec@1 99.609 (99.891)	Training Prec@5 99.805 (99.953)	
2022-07-24 23:51:35,669: ============================================================
2022-07-24 23:52:16,455: time cost, forward:0.12435780608432317, backward:0.09715234943384435, data cost:0.18992441065492208 
2022-07-24 23:52:16,455: ============================================================
2022-07-24 23:52:16,455: Epoch 12/25 Batch 700/7662 eta: 12:04:25.464075	Training Loss1 3.1870 (3.5303)	Training Total_Loss 3.1870 (3.5303)	Training Prec@1 99.805 (99.890)	Training Prec@5 99.805 (99.956)	
2022-07-24 23:52:16,455: ============================================================
2022-07-24 23:52:57,247: time cost, forward:0.12435561843747937, backward:0.09714394964473567, data cost:0.18941005240095424 
2022-07-24 23:52:57,247: ============================================================
2022-07-24 23:52:57,247: Epoch 12/25 Batch 800/7662 eta: 12:03:50.863985	Training Loss1 3.4255 (3.5470)	Training Total_Loss 3.4255 (3.5470)	Training Prec@1 100.000 (99.891)	Training Prec@5 100.000 (99.956)	
2022-07-24 23:52:57,248: ============================================================
2022-07-24 23:53:38,085: time cost, forward:0.12437921238688128, backward:0.09715178758071713, data cost:0.1890205358371586 
2022-07-24 23:53:38,085: ============================================================
2022-07-24 23:53:38,086: Epoch 12/25 Batch 900/7662 eta: 12:03:59.056226	Training Loss1 3.2001 (3.5624)	Training Total_Loss 3.2001 (3.5624)	Training Prec@1 99.805 (99.890)	Training Prec@5 100.000 (99.956)	
2022-07-24 23:53:38,086: ============================================================
2022-07-24 23:54:18,892: time cost, forward:0.124386434201841, backward:0.09714829146086394, data cost:0.18870150505959452 
2022-07-24 23:54:18,892: ============================================================
2022-07-24 23:54:18,892: Epoch 12/25 Batch 1000/7662 eta: 12:02:44.844144	Training Loss1 3.8410 (3.5731)	Training Total_Loss 3.8410 (3.5731)	Training Prec@1 99.805 (99.892)	Training Prec@5 100.000 (99.958)	
2022-07-24 23:54:18,892: ============================================================
2022-07-24 23:54:59,720: time cost, forward:0.1244116653845026, backward:0.09714892520158262, data cost:0.18843705986064602 
2022-07-24 23:54:59,720: ============================================================
2022-07-24 23:54:59,720: Epoch 12/25 Batch 1100/7662 eta: 12:02:26.606492	Training Loss1 3.6083 (3.5849)	Training Total_Loss 3.6083 (3.5849)	Training Prec@1 100.000 (99.889)	Training Prec@5 100.000 (99.958)	
2022-07-24 23:54:59,720: ============================================================
2022-07-24 23:55:40,541: time cost, forward:0.12444155786910387, backward:0.09714015808773598, data cost:0.1882151107772178 
2022-07-24 23:55:40,542: ============================================================
2022-07-24 23:55:40,542: Epoch 12/25 Batch 1200/7662 eta: 12:01:39.177926	Training Loss1 3.8325 (3.5983)	Training Total_Loss 3.8325 (3.5983)	Training Prec@1 99.609 (99.887)	Training Prec@5 100.000 (99.957)	
2022-07-24 23:55:40,542: ============================================================
2022-07-24 23:56:21,343: time cost, forward:0.12444219559866984, backward:0.09714077875373729, data cost:0.1880279752820891 
2022-07-24 23:56:21,344: ============================================================
2022-07-24 23:56:21,344: Epoch 12/25 Batch 1300/7662 eta: 12:00:37.425194	Training Loss1 3.8364 (3.6095)	Training Total_Loss 3.8364 (3.6095)	Training Prec@1 100.000 (99.888)	Training Prec@5 100.000 (99.958)	
2022-07-24 23:56:21,344: ============================================================
2022-07-24 23:57:02,112: time cost, forward:0.12442686235674626, backward:0.09713933023066926, data cost:0.18786088358597555 
2022-07-24 23:57:02,112: ============================================================
2022-07-24 23:57:02,112: Epoch 12/25 Batch 1400/7662 eta: 11:59:21.152878	Training Loss1 3.7208 (3.6183)	Training Total_Loss 3.7208 (3.6183)	Training Prec@1 99.805 (99.888)	Training Prec@5 100.000 (99.959)	
2022-07-24 23:57:02,112: ============================================================
2022-07-24 23:57:42,897: time cost, forward:0.1244210703838977, backward:0.09714214812921952, data cost:0.18771335138647932 
2022-07-24 23:57:42,897: ============================================================
2022-07-24 23:57:42,897: Epoch 12/25 Batch 1500/7662 eta: 11:58:57.883715	Training Loss1 3.8434 (3.6336)	Training Total_Loss 3.8434 (3.6336)	Training Prec@1 99.805 (99.889)	Training Prec@5 100.000 (99.959)	
2022-07-24 23:57:42,897: ============================================================
2022-07-24 23:58:23,655: time cost, forward:0.12441567572449952, backward:0.09713199796193536, data cost:0.18757963135810551 
2022-07-24 23:58:23,655: ============================================================
2022-07-24 23:58:23,655: Epoch 12/25 Batch 1600/7662 eta: 11:57:48.295547	Training Loss1 3.3553 (3.6452)	Training Total_Loss 3.3553 (3.6452)	Training Prec@1 100.000 (99.890)	Training Prec@5 100.000 (99.960)	
2022-07-24 23:58:23,655: ============================================================
2022-07-24 23:59:04,437: time cost, forward:0.12442892309214663, backward:0.09712506687732357, data cost:0.18745847489287953 
2022-07-24 23:59:04,438: ============================================================
2022-07-24 23:59:04,438: Epoch 12/25 Batch 1700/7662 eta: 11:57:33.969423	Training Loss1 3.7133 (3.6572)	Training Total_Loss 3.7133 (3.6572)	Training Prec@1 99.609 (99.888)	Training Prec@5 99.805 (99.960)	
2022-07-24 23:59:04,438: ============================================================
2022-07-24 23:59:45,190: time cost, forward:0.12442789202335479, backward:0.09711815000176761, data cost:0.18734642304997765 
2022-07-24 23:59:45,191: ============================================================
2022-07-24 23:59:45,191: Epoch 12/25 Batch 1800/7662 eta: 11:56:21.920900	Training Loss1 4.1121 (3.6693)	Training Total_Loss 4.1121 (3.6693)	Training Prec@1 100.000 (99.887)	Training Prec@5 100.000 (99.960)	
2022-07-24 23:59:45,191: ============================================================
2022-07-25 00:00:25,946: time cost, forward:0.12442238008178744, backward:0.09711284471725777, data cost:0.18725165597635424 
2022-07-25 00:00:25,946: ============================================================
2022-07-25 00:00:25,946: Epoch 12/25 Batch 1900/7662 eta: 11:55:43.455873	Training Loss1 3.5877 (3.6794)	Training Total_Loss 3.5877 (3.6794)	Training Prec@1 99.805 (99.887)	Training Prec@5 100.000 (99.959)	
2022-07-25 00:00:25,946: ============================================================
2022-07-25 00:01:06,685: time cost, forward:0.12441778242617861, backward:0.09710544929199066, data cost:0.18715997908698612 
2022-07-25 00:01:06,685: ============================================================
2022-07-25 00:01:06,685: Epoch 12/25 Batch 2000/7662 eta: 11:54:45.309855	Training Loss1 3.5053 (3.6929)	Training Total_Loss 3.5053 (3.6929)	Training Prec@1 100.000 (99.886)	Training Prec@5 100.000 (99.959)	
2022-07-25 00:01:06,685: ============================================================
2022-07-25 00:01:47,435: time cost, forward:0.12441539753045622, backward:0.09710132377155625, data cost:0.18707875299022106 
2022-07-25 00:01:47,436: ============================================================
2022-07-25 00:01:47,436: Epoch 12/25 Batch 2100/7662 eta: 11:54:17.299259	Training Loss1 4.1415 (3.7031)	Training Total_Loss 4.1415 (3.7031)	Training Prec@1 99.805 (99.885)	Training Prec@5 100.000 (99.960)	
2022-07-25 00:01:47,436: ============================================================
2022-07-25 00:02:28,167: time cost, forward:0.12440267277067496, backward:0.09709937217941388, data cost:0.18700557418604666 
2022-07-25 00:02:28,167: ============================================================
2022-07-25 00:02:28,167: Epoch 12/25 Batch 2200/7662 eta: 11:53:15.673372	Training Loss1 4.0738 (3.7140)	Training Total_Loss 4.0738 (3.7140)	Training Prec@1 100.000 (99.886)	Training Prec@5 100.000 (99.960)	
2022-07-25 00:02:28,167: ============================================================
2022-07-25 00:03:08,892: time cost, forward:0.1243900573476598, backward:0.09709548639079289, data cost:0.1869391608933046 
2022-07-25 00:03:08,893: ============================================================
2022-07-25 00:03:08,893: Epoch 12/25 Batch 2300/7662 eta: 11:52:29.430254	Training Loss1 4.1236 (3.7253)	Training Total_Loss 4.1236 (3.7253)	Training Prec@1 100.000 (99.885)	Training Prec@5 100.000 (99.959)	
2022-07-25 00:03:08,893: ============================================================
2022-07-25 00:03:49,637: time cost, forward:0.12438691233833316, backward:0.09709196778425032, data cost:0.18687682004708359 
2022-07-25 00:03:49,637: ============================================================
2022-07-25 00:03:49,637: Epoch 12/25 Batch 2400/7662 eta: 11:52:08.576148	Training Loss1 3.8767 (3.7352)	Training Total_Loss 3.8767 (3.7352)	Training Prec@1 99.805 (99.884)	Training Prec@5 100.000 (99.959)	
2022-07-25 00:03:49,638: ============================================================
2022-07-25 00:04:30,379: time cost, forward:0.12437781699899197, backward:0.09709015823736722, data cost:0.18682266083084234 
2022-07-25 00:04:30,380: ============================================================
2022-07-25 00:04:30,380: Epoch 12/25 Batch 2500/7662 eta: 11:51:25.530877	Training Loss1 3.7515 (3.7466)	Training Total_Loss 3.7515 (3.7466)	Training Prec@1 99.609 (99.883)	Training Prec@5 99.805 (99.958)	
2022-07-25 00:04:30,380: ============================================================
2022-07-25 00:05:11,112: time cost, forward:0.12437232910279541, backward:0.09708746197866724, data cost:0.18676810761789672 
2022-07-25 00:05:11,113: ============================================================
2022-07-25 00:05:11,113: Epoch 12/25 Batch 2600/7662 eta: 11:50:34.777645	Training Loss1 4.2521 (3.7574)	Training Total_Loss 4.2521 (3.7574)	Training Prec@1 100.000 (99.881)	Training Prec@5 100.000 (99.957)	
2022-07-25 00:05:11,113: ============================================================
2022-07-25 00:05:51,875: time cost, forward:0.12437732858364561, backward:0.09708349119075452, data cost:0.186719876565329 
2022-07-25 00:05:51,875: ============================================================
2022-07-25 00:05:51,876: Epoch 12/25 Batch 2700/7662 eta: 11:50:25.094495	Training Loss1 4.1810 (3.7678)	Training Total_Loss 4.1810 (3.7678)	Training Prec@1 100.000 (99.881)	Training Prec@5 100.000 (99.958)	
2022-07-25 00:05:51,876: ============================================================
2022-07-25 00:06:32,611: time cost, forward:0.12437148876128856, backward:0.09707855701276173, data cost:0.18667730019321693 
2022-07-25 00:06:32,611: ============================================================
2022-07-25 00:06:32,611: Epoch 12/25 Batch 2800/7662 eta: 11:49:16.087907	Training Loss1 4.3811 (3.7771)	Training Total_Loss 4.3811 (3.7771)	Training Prec@1 100.000 (99.880)	Training Prec@5 100.000 (99.957)	
2022-07-25 00:06:32,611: ============================================================
2022-07-25 00:07:13,388: time cost, forward:0.12437305642884942, backward:0.09707757660996383, data cost:0.18664101059167867 
2022-07-25 00:07:13,388: ============================================================
2022-07-25 00:07:13,389: Epoch 12/25 Batch 2900/7662 eta: 11:49:19.023597	Training Loss1 4.4281 (3.7885)	Training Total_Loss 4.4281 (3.7885)	Training Prec@1 100.000 (99.879)	Training Prec@5 100.000 (99.957)	
2022-07-25 00:07:13,389: ============================================================
2022-07-25 00:07:54,116: time cost, forward:0.1243638512133439, backward:0.09707601247687625, data cost:0.18660273628260304 
2022-07-25 00:07:54,116: ============================================================
2022-07-25 00:07:54,116: Epoch 12/25 Batch 3000/7662 eta: 11:47:46.413736	Training Loss1 4.0980 (3.7993)	Training Total_Loss 4.0980 (3.7993)	Training Prec@1 100.000 (99.878)	Training Prec@5 100.000 (99.956)	
2022-07-25 00:07:54,116: ============================================================
2022-07-25 00:08:35,649: time cost, forward:0.12435894360193017, backward:0.09707288628203056, data cost:0.18682370758241282 
2022-07-25 00:08:35,650: ============================================================
2022-07-25 00:08:35,650: Epoch 12/25 Batch 3100/7662 eta: 12:01:05.112286	Training Loss1 3.6896 (3.8108)	Training Total_Loss 3.6896 (3.8108)	Training Prec@1 99.805 (99.879)	Training Prec@5 100.000 (99.957)	
2022-07-25 00:08:35,650: ============================================================
2022-07-25 00:09:16,346: time cost, forward:0.12433900725807984, backward:0.09707118064472547, data cost:0.1867831497872088 
2022-07-25 00:09:16,346: ============================================================
2022-07-25 00:09:16,347: Epoch 12/25 Batch 3200/7662 eta: 11:45:52.620041	Training Loss1 3.7383 (3.8200)	Training Total_Loss 3.7383 (3.8200)	Training Prec@1 100.000 (99.878)	Training Prec@5 100.000 (99.957)	
2022-07-25 00:09:16,347: ============================================================
2022-07-25 00:09:57,043: time cost, forward:0.12431973231565088, backward:0.09707004903265475, data cost:0.18674590067994995 
2022-07-25 00:09:57,043: ============================================================
2022-07-25 00:09:57,044: Epoch 12/25 Batch 3300/7662 eta: 11:45:12.248093	Training Loss1 4.2291 (3.8293)	Training Total_Loss 4.2291 (3.8293)	Training Prec@1 99.805 (99.878)	Training Prec@5 99.805 (99.957)	
2022-07-25 00:09:57,044: ============================================================
2022-07-25 00:10:37,766: time cost, forward:0.12430362260913316, backward:0.09707151240690837, data cost:0.18671329970498687 
2022-07-25 00:10:37,766: ============================================================
2022-07-25 00:10:37,766: Epoch 12/25 Batch 3400/7662 eta: 11:44:58.173721	Training Loss1 4.1454 (3.8382)	Training Total_Loss 4.1454 (3.8382)	Training Prec@1 100.000 (99.877)	Training Prec@5 100.000 (99.957)	
2022-07-25 00:10:37,766: ============================================================
2022-07-25 00:11:18,520: time cost, forward:0.12429015477680076, backward:0.09707353019005709, data cost:0.18668935196029693 
2022-07-25 00:11:18,521: ============================================================
2022-07-25 00:11:18,521: Epoch 12/25 Batch 3500/7662 eta: 11:44:50.488523	Training Loss1 4.5538 (3.8482)	Training Total_Loss 4.5538 (3.8482)	Training Prec@1 100.000 (99.876)	Training Prec@5 100.000 (99.957)	
2022-07-25 00:11:18,521: ============================================================
2022-07-25 00:11:59,267: time cost, forward:0.1242794426787923, backward:0.09707227095063112, data cost:0.1866658501043423 
2022-07-25 00:11:59,267: ============================================================
2022-07-25 00:11:59,267: Epoch 12/25 Batch 3600/7662 eta: 11:44:01.387763	Training Loss1 3.5861 (3.8588)	Training Total_Loss 3.5861 (3.8588)	Training Prec@1 99.609 (99.874)	Training Prec@5 100.000 (99.956)	
2022-07-25 00:11:59,267: ============================================================
2022-07-25 00:12:40,045: time cost, forward:0.12426602431135134, backward:0.09707911564356961, data cost:0.18664643454467905 
2022-07-25 00:12:40,045: ============================================================
2022-07-25 00:12:40,046: Epoch 12/25 Batch 3700/7662 eta: 11:43:53.629919	Training Loss1 4.4415 (3.8677)	Training Total_Loss 4.4415 (3.8677)	Training Prec@1 99.414 (99.873)	Training Prec@5 100.000 (99.956)	
2022-07-25 00:12:40,046: ============================================================
2022-07-25 00:13:20,789: time cost, forward:0.12425837789155458, backward:0.09707697337161368, data cost:0.18662392506319525 
2022-07-25 00:13:20,789: ============================================================
2022-07-25 00:13:20,789: Epoch 12/25 Batch 3800/7662 eta: 11:42:37.200864	Training Loss1 4.1145 (3.8767)	Training Total_Loss 4.1145 (3.8767)	Training Prec@1 99.805 (99.872)	Training Prec@5 100.000 (99.956)	
2022-07-25 00:13:20,789: ============================================================
2022-07-25 00:14:01,582: time cost, forward:0.1242600735348596, backward:0.09707374540956609, data cost:0.1866073739868031 
2022-07-25 00:14:01,582: ============================================================
2022-07-25 00:14:01,583: Epoch 12/25 Batch 3900/7662 eta: 11:42:47.754588	Training Loss1 4.4784 (3.8855)	Training Total_Loss 4.4784 (3.8855)	Training Prec@1 99.609 (99.871)	Training Prec@5 100.000 (99.955)	
2022-07-25 00:14:01,583: ============================================================
2022-07-25 00:14:42,356: time cost, forward:0.1242537253437772, backward:0.09707677665428091, data cost:0.1865895036519483 
2022-07-25 00:14:42,357: ============================================================
2022-07-25 00:14:42,357: Epoch 12/25 Batch 4000/7662 eta: 11:41:47.218370	Training Loss1 4.0349 (3.8941)	Training Total_Loss 4.0349 (3.8941)	Training Prec@1 100.000 (99.870)	Training Prec@5 100.000 (99.955)	
2022-07-25 00:14:42,357: ============================================================
2022-07-25 00:15:23,122: time cost, forward:0.1242463238560941, backward:0.09708114099607261, data cost:0.1865707704805112 
2022-07-25 00:15:23,122: ============================================================
2022-07-25 00:15:23,123: Epoch 12/25 Batch 4100/7662 eta: 11:40:57.438215	Training Loss1 4.6175 (3.9023)	Training Total_Loss 4.6175 (3.9023)	Training Prec@1 100.000 (99.870)	Training Prec@5 100.000 (99.955)	
2022-07-25 00:15:23,123: ============================================================
2022-07-25 00:16:03,942: time cost, forward:0.12423774184826358, backward:0.0970999827183948, data cost:0.18655326628179658 
2022-07-25 00:16:03,942: ============================================================
2022-07-25 00:16:03,942: Epoch 12/25 Batch 4200/7662 eta: 11:41:12.454876	Training Loss1 4.4528 (3.9125)	Training Total_Loss 4.4528 (3.9125)	Training Prec@1 99.609 (99.868)	Training Prec@5 99.805 (99.955)	
2022-07-25 00:16:03,942: ============================================================
2022-07-25 00:16:44,709: time cost, forward:0.12423105161116273, backward:0.09710515285819374, data cost:0.18653754839705267 
2022-07-25 00:16:44,710: ============================================================
2022-07-25 00:16:44,710: Epoch 12/25 Batch 4300/7662 eta: 11:39:38.084867	Training Loss1 4.3023 (3.9219)	Training Total_Loss 4.3023 (3.9219)	Training Prec@1 100.000 (99.868)	Training Prec@5 100.000 (99.954)	
2022-07-25 00:16:44,710: ============================================================
2022-07-25 00:17:25,452: time cost, forward:0.1242347245434247, backward:0.09709257671957153, data cost:0.18652513380022476 
2022-07-25 00:17:25,452: ============================================================
2022-07-25 00:17:25,453: Epoch 12/25 Batch 4400/7662 eta: 11:38:31.590998	Training Loss1 3.3341 (3.9305)	Training Total_Loss 3.3341 (3.9305)	Training Prec@1 100.000 (99.867)	Training Prec@5 100.000 (99.955)	
2022-07-25 00:17:25,453: ============================================================
2022-07-25 00:18:06,148: time cost, forward:0.12423175985374883, backward:0.09708108179143705, data cost:0.1865097367782067 
2022-07-25 00:18:06,148: ============================================================
2022-07-25 00:18:06,148: Epoch 12/25 Batch 4500/7662 eta: 11:37:02.345793	Training Loss1 4.5369 (3.9395)	Training Total_Loss 4.5369 (3.9395)	Training Prec@1 99.609 (99.867)	Training Prec@5 99.805 (99.954)	
2022-07-25 00:18:06,148: ============================================================
2022-07-25 00:18:46,813: time cost, forward:0.12422409050359393, backward:0.09707161078481058, data cost:0.18649111221240483 
2022-07-25 00:18:46,814: ============================================================
2022-07-25 00:18:46,814: Epoch 12/25 Batch 4600/7662 eta: 11:35:51.034445	Training Loss1 4.3474 (3.9486)	Training Total_Loss 4.3474 (3.9486)	Training Prec@1 99.805 (99.865)	Training Prec@5 100.000 (99.954)	
2022-07-25 00:18:46,814: ============================================================
2022-07-25 00:19:27,468: time cost, forward:0.12421522842718961, backward:0.09706257241511503, data cost:0.18647325579271237 
2022-07-25 00:19:27,469: ============================================================
2022-07-25 00:19:27,469: Epoch 12/25 Batch 4700/7662 eta: 11:34:59.424720	Training Loss1 4.4091 (3.9565)	Training Total_Loss 4.4091 (3.9565)	Training Prec@1 100.000 (99.864)	Training Prec@5 100.000 (99.954)	
2022-07-25 00:19:27,469: ============================================================
2022-07-25 00:20:08,112: time cost, forward:0.12420783566544269, backward:0.09705268171683627, data cost:0.18645339018107704 
2022-07-25 00:20:08,113: ============================================================
2022-07-25 00:20:08,113: Epoch 12/25 Batch 4800/7662 eta: 11:34:07.440316	Training Loss1 4.3394 (3.9643)	Training Total_Loss 4.3394 (3.9643)	Training Prec@1 99.805 (99.864)	Training Prec@5 100.000 (99.954)	
2022-07-25 00:20:08,113: ============================================================
2022-07-25 00:20:48,757: time cost, forward:0.12419939659205863, backward:0.09704471121128298, data cost:0.18643449306196036 
2022-07-25 00:20:48,757: ============================================================
2022-07-25 00:20:48,757: Epoch 12/25 Batch 4900/7662 eta: 11:33:27.435829	Training Loss1 3.9180 (3.9727)	Training Total_Loss 3.9180 (3.9727)	Training Prec@1 100.000 (99.863)	Training Prec@5 100.000 (99.953)	
2022-07-25 00:20:48,757: ============================================================
2022-07-25 00:21:29,404: time cost, forward:0.12419231368627852, backward:0.09703505561456224, data cost:0.1864179076373899 
2022-07-25 00:21:29,404: ============================================================
2022-07-25 00:21:29,404: Epoch 12/25 Batch 5000/7662 eta: 11:32:49.427291	Training Loss1 3.8862 (3.9802)	Training Total_Loss 3.8862 (3.9802)	Training Prec@1 99.609 (99.862)	Training Prec@5 99.805 (99.954)	
2022-07-25 00:21:29,404: ============================================================
2022-07-25 00:22:10,054: time cost, forward:0.12418568211458411, backward:0.09702593519491737, data cost:0.1864023315693776 
2022-07-25 00:22:10,054: ============================================================
2022-07-25 00:22:10,055: Epoch 12/25 Batch 5100/7662 eta: 11:32:11.904187	Training Loss1 4.7260 (3.9881)	Training Total_Loss 4.7260 (3.9881)	Training Prec@1 100.000 (99.862)	Training Prec@5 100.000 (99.954)	
2022-07-25 00:22:10,055: ============================================================
2022-07-25 00:22:50,729: time cost, forward:0.12418001260773956, backward:0.09701919697825555, data cost:0.18638970242438122 
2022-07-25 00:22:50,729: ============================================================
2022-07-25 00:22:50,729: Epoch 12/25 Batch 5200/7662 eta: 11:31:56.117205	Training Loss1 4.3728 (3.9960)	Training Total_Loss 4.3728 (3.9960)	Training Prec@1 99.805 (99.860)	Training Prec@5 100.000 (99.953)	
2022-07-25 00:22:50,729: ============================================================
2022-07-25 00:23:31,367: time cost, forward:0.12417226544999474, backward:0.09701130812652697, data cost:0.18637406382836988 
2022-07-25 00:23:31,368: ============================================================
2022-07-25 00:23:31,368: Epoch 12/25 Batch 5300/7662 eta: 11:30:38.833224	Training Loss1 4.1006 (4.0047)	Training Total_Loss 4.1006 (4.0047)	Training Prec@1 99.609 (99.859)	Training Prec@5 99.805 (99.953)	
2022-07-25 00:23:31,368: ============================================================
2022-07-25 00:24:12,005: time cost, forward:0.12416541384290514, backward:0.09700161162339486, data cost:0.18636052518845664 
2022-07-25 00:24:12,005: ============================================================
2022-07-25 00:24:12,006: Epoch 12/25 Batch 5400/7662 eta: 11:29:57.278685	Training Loss1 4.6170 (4.0131)	Training Total_Loss 4.6170 (4.0131)	Training Prec@1 100.000 (99.858)	Training Prec@5 100.000 (99.953)	
2022-07-25 00:24:12,006: ============================================================
2022-07-25 00:24:52,672: time cost, forward:0.1241629309688054, backward:0.09699167141287429, data cost:0.1863489994289095 
2022-07-25 00:24:52,672: ============================================================
2022-07-25 00:24:52,672: Epoch 12/25 Batch 5500/7662 eta: 11:29:46.155680	Training Loss1 4.7234 (4.0222)	Training Total_Loss 4.7234 (4.0222)	Training Prec@1 100.000 (99.857)	Training Prec@5 100.000 (99.953)	
2022-07-25 00:24:52,672: ============================================================
2022-07-25 00:25:33,316: time cost, forward:0.12415627335454549, backward:0.09698427134399905, data cost:0.18633606136217779 
2022-07-25 00:25:33,316: ============================================================
2022-07-25 00:25:33,316: Epoch 12/25 Batch 5600/7662 eta: 11:28:42.140679	Training Loss1 5.0438 (4.0301)	Training Total_Loss 5.0438 (4.0301)	Training Prec@1 99.414 (99.856)	Training Prec@5 100.000 (99.952)	
2022-07-25 00:25:33,316: ============================================================
2022-07-25 00:26:13,954: time cost, forward:0.1241506042135747, backward:0.09697618696182982, data cost:0.18632301675120788 
2022-07-25 00:26:13,954: ============================================================
2022-07-25 00:26:13,954: Epoch 12/25 Batch 5700/7662 eta: 11:27:55.621855	Training Loss1 4.5889 (4.0375)	Training Total_Loss 4.5889 (4.0375)	Training Prec@1 100.000 (99.855)	Training Prec@5 100.000 (99.952)	
2022-07-25 00:26:13,954: ============================================================
2022-07-25 00:26:54,591: time cost, forward:0.12414733881291737, backward:0.09696550220430956, data cost:0.18631064416951487 
2022-07-25 00:26:54,592: ============================================================
2022-07-25 00:26:54,592: Epoch 12/25 Batch 5800/7662 eta: 11:27:14.479922	Training Loss1 4.3643 (4.0460)	Training Total_Loss 4.3643 (4.0460)	Training Prec@1 99.805 (99.854)	Training Prec@5 99.805 (99.951)	
2022-07-25 00:26:54,592: ============================================================
2022-07-25 00:27:35,218: time cost, forward:0.12414326221584404, backward:0.09695559171200364, data cost:0.18629785201613794 
2022-07-25 00:27:35,219: ============================================================
2022-07-25 00:27:35,219: Epoch 12/25 Batch 5900/7662 eta: 11:26:23.222877	Training Loss1 5.0667 (4.0534)	Training Total_Loss 5.0667 (4.0534)	Training Prec@1 99.805 (99.853)	Training Prec@5 99.805 (99.950)	
2022-07-25 00:27:35,219: ============================================================
2022-07-25 00:28:15,849: time cost, forward:0.12413912261400765, backward:0.09694594986380328, data cost:0.18628586099672007 
2022-07-25 00:28:15,849: ============================================================
2022-07-25 00:28:15,849: Epoch 12/25 Batch 6000/7662 eta: 11:25:46.356572	Training Loss1 4.2440 (4.0604)	Training Total_Loss 4.2440 (4.0604)	Training Prec@1 99.805 (99.852)	Training Prec@5 99.805 (99.951)	
2022-07-25 00:28:15,850: ============================================================
2022-07-25 00:28:56,470: time cost, forward:0.12413374027828249, backward:0.09693715544602269, data cost:0.1862737639924897 
2022-07-25 00:28:56,470: ============================================================
2022-07-25 00:28:56,470: Epoch 12/25 Batch 6100/7662 eta: 11:24:55.408729	Training Loss1 5.0205 (4.0676)	Training Total_Loss 5.0205 (4.0676)	Training Prec@1 100.000 (99.851)	Training Prec@5 100.000 (99.950)	
2022-07-25 00:28:56,470: ============================================================
2022-07-25 00:29:37,076: time cost, forward:0.1241270293918689, backward:0.0969290896411249, data cost:0.18626089641443663 
2022-07-25 00:29:37,077: ============================================================
2022-07-25 00:29:37,077: Epoch 12/25 Batch 6200/7662 eta: 11:24:00.876652	Training Loss1 4.4942 (4.0741)	Training Total_Loss 4.4942 (4.0741)	Training Prec@1 100.000 (99.851)	Training Prec@5 100.000 (99.951)	
2022-07-25 00:29:37,077: ============================================================
2022-07-25 00:30:17,702: time cost, forward:0.12412180505417361, backward:0.09692165502992428, data cost:0.1862497264609524 
2022-07-25 00:30:17,703: ============================================================
2022-07-25 00:30:17,703: Epoch 12/25 Batch 6300/7662 eta: 11:23:39.630480	Training Loss1 4.8705 (4.0807)	Training Total_Loss 4.8705 (4.0807)	Training Prec@1 99.805 (99.850)	Training Prec@5 99.805 (99.950)	
2022-07-25 00:30:17,703: ============================================================
2022-07-25 00:30:58,307: time cost, forward:0.12411417303876703, backward:0.0969140461076515, data cost:0.18623880983088273 
2022-07-25 00:30:58,307: ============================================================
2022-07-25 00:30:58,308: Epoch 12/25 Batch 6400/7662 eta: 11:22:37.635497	Training Loss1 4.0947 (4.0873)	Training Total_Loss 4.0947 (4.0873)	Training Prec@1 99.805 (99.849)	Training Prec@5 99.805 (99.950)	
2022-07-25 00:30:58,308: ============================================================
2022-07-25 00:31:38,929: time cost, forward:0.12410983794981709, backward:0.0969064788169761, data cost:0.18622795254070038 
2022-07-25 00:31:38,930: ============================================================
2022-07-25 00:31:38,930: Epoch 12/25 Batch 6500/7662 eta: 11:22:14.643832	Training Loss1 4.3565 (4.0945)	Training Total_Loss 4.3565 (4.0945)	Training Prec@1 100.000 (99.848)	Training Prec@5 100.000 (99.950)	
2022-07-25 00:31:38,930: ============================================================
2022-07-25 00:32:19,564: time cost, forward:0.12410721512956499, backward:0.09689849769550664, data cost:0.18621809848566312 
2022-07-25 00:32:19,564: ============================================================
2022-07-25 00:32:19,564: Epoch 12/25 Batch 6600/7662 eta: 11:21:45.887846	Training Loss1 5.1495 (4.1028)	Training Total_Loss 5.1495 (4.1028)	Training Prec@1 99.414 (99.847)	Training Prec@5 99.805 (99.949)	
2022-07-25 00:32:19,564: ============================================================
2022-07-25 00:33:00,196: time cost, forward:0.12410305001554534, backward:0.09689169329375469, data cost:0.186209146114121 
2022-07-25 00:33:00,196: ============================================================
2022-07-25 00:33:00,196: Epoch 12/25 Batch 6700/7662 eta: 11:21:03.567701	Training Loss1 5.1168 (4.1100)	Training Total_Loss 5.1168 (4.1100)	Training Prec@1 99.805 (99.846)	Training Prec@5 100.000 (99.949)	
2022-07-25 00:33:00,196: ============================================================
2022-07-25 00:33:40,816: time cost, forward:0.12409808537875541, backward:0.0968836322744588, data cost:0.1862009936070544 
2022-07-25 00:33:40,817: ============================================================
2022-07-25 00:33:40,817: Epoch 12/25 Batch 6800/7662 eta: 11:20:10.948672	Training Loss1 3.9061 (4.1164)	Training Total_Loss 3.9061 (4.1164)	Training Prec@1 99.805 (99.845)	Training Prec@5 100.000 (99.949)	
2022-07-25 00:33:40,817: ============================================================
2022-07-25 00:34:21,419: time cost, forward:0.1240923050815324, backward:0.09687729786575523, data cost:0.1861899327602848 
2022-07-25 00:34:21,419: ============================================================
2022-07-25 00:34:21,419: Epoch 12/25 Batch 6900/7662 eta: 11:19:12.221006	Training Loss1 4.5594 (4.1225)	Training Total_Loss 4.5594 (4.1225)	Training Prec@1 99.414 (99.844)	Training Prec@5 99.805 (99.949)	
2022-07-25 00:34:21,419: ============================================================
2022-07-25 00:35:02,035: time cost, forward:0.12408740882584667, backward:0.09687161776044911, data cost:0.18618009352380846 
2022-07-25 00:35:02,035: ============================================================
2022-07-25 00:35:02,036: Epoch 12/25 Batch 7000/7662 eta: 11:18:45.729359	Training Loss1 4.9138 (4.1299)	Training Total_Loss 4.9138 (4.1299)	Training Prec@1 99.805 (99.844)	Training Prec@5 100.000 (99.949)	
2022-07-25 00:35:02,036: ============================================================
2022-07-25 00:35:42,642: time cost, forward:0.12408375320241122, backward:0.09686504835678769, data cost:0.1861689073936354 
2022-07-25 00:35:42,642: ============================================================
2022-07-25 00:35:42,643: Epoch 12/25 Batch 7100/7662 eta: 11:17:55.638600	Training Loss1 4.5507 (4.1361)	Training Total_Loss 4.5507 (4.1361)	Training Prec@1 99.609 (99.843)	Training Prec@5 99.805 (99.948)	
2022-07-25 00:35:42,643: ============================================================
2022-07-25 00:36:23,240: time cost, forward:0.12407822161188456, backward:0.0968580964969784, data cost:0.18615942031811603 
2022-07-25 00:36:23,241: ============================================================
2022-07-25 00:36:23,241: Epoch 12/25 Batch 7200/7662 eta: 11:17:06.374600	Training Loss1 4.5650 (4.1427)	Training Total_Loss 4.5650 (4.1427)	Training Prec@1 99.023 (99.842)	Training Prec@5 99.805 (99.948)	
2022-07-25 00:36:23,241: ============================================================
2022-07-25 00:37:03,858: time cost, forward:0.12407507833054106, backward:0.09685224297112317, data cost:0.18614998100914193 
2022-07-25 00:37:03,859: ============================================================
2022-07-25 00:37:03,859: Epoch 12/25 Batch 7300/7662 eta: 11:16:45.310491	Training Loss1 4.5959 (4.1490)	Training Total_Loss 4.5959 (4.1490)	Training Prec@1 99.609 (99.840)	Training Prec@5 100.000 (99.947)	
2022-07-25 00:37:03,859: ============================================================
2022-07-25 00:37:44,478: time cost, forward:0.12407257518569817, backward:0.09684648837958144, data cost:0.18614042470673964 
2022-07-25 00:37:44,478: ============================================================
2022-07-25 00:37:44,478: Epoch 12/25 Batch 7400/7662 eta: 11:16:06.312188	Training Loss1 5.4295 (4.1554)	Training Total_Loss 5.4295 (4.1554)	Training Prec@1 99.805 (99.839)	Training Prec@5 100.000 (99.947)	
2022-07-25 00:37:44,478: ============================================================
2022-07-25 00:38:25,097: time cost, forward:0.1240700287951805, backward:0.09684021359428531, data cost:0.18613189241857206 
2022-07-25 00:38:25,097: ============================================================
2022-07-25 00:38:25,097: Epoch 12/25 Batch 7500/7662 eta: 11:15:25.176728	Training Loss1 4.1631 (4.1617)	Training Total_Loss 4.1631 (4.1617)	Training Prec@1 100.000 (99.838)	Training Prec@5 100.000 (99.946)	
2022-07-25 00:38:25,097: ============================================================
2022-07-25 00:39:05,724: time cost, forward:0.12406671249579404, backward:0.09683586293293435, data cost:0.18612349427111888 
2022-07-25 00:39:05,724: ============================================================
2022-07-25 00:39:05,725: Epoch 12/25 Batch 7600/7662 eta: 11:14:52.802274	Training Loss1 4.8403 (4.1677)	Training Total_Loss 4.8403 (4.1677)	Training Prec@1 99.805 (99.837)	Training Prec@5 99.805 (99.946)	
2022-07-25 00:39:05,725: ============================================================
2022-07-25 00:39:32,808: Epoch 12/25 Batch 7663/7662 eta: 11:14:27.207089	Training Loss1 4.7990 (4.1718)	Training Total_Loss 4.7990 (4.1718)	Training Prec@1 99.805 (99.837)	Training Prec@5 100.000 (99.946)	
2022-07-25 00:39:32,809: ============================================================
2022-07-25 00:40:16,434: time cost, forward:0.1237246532632847, backward:0.09728151620036424, data cost:0.21693154296489678 
2022-07-25 00:40:16,435: ============================================================
2022-07-25 00:40:16,435: Epoch 13/25 Batch 100/7662 eta: 12:03:03.239367	Training Loss1 3.4813 (3.4035)	Training Total_Loss 3.4813 (3.4035)	Training Prec@1 100.000 (99.925)	Training Prec@5 100.000 (99.980)	
2022-07-25 00:40:16,435: ============================================================
2022-07-25 00:40:57,133: time cost, forward:0.12369195899771686, backward:0.09682619871206619, data cost:0.20159196494212703 
2022-07-25 00:40:57,133: ============================================================
2022-07-25 00:40:57,133: Epoch 13/25 Batch 200/7662 eta: 11:14:16.975557	Training Loss1 3.8969 (3.3921)	Training Total_Loss 3.8969 (3.3921)	Training Prec@1 99.805 (99.920)	Training Prec@5 100.000 (99.977)	
2022-07-25 00:40:57,133: ============================================================
2022-07-25 00:41:37,866: time cost, forward:0.12377272640981005, backward:0.09671005516945319, data cost:0.19647134028150884 
2022-07-25 00:41:37,866: ============================================================
2022-07-25 00:41:37,867: Epoch 13/25 Batch 300/7662 eta: 11:14:11.241236	Training Loss1 3.1613 (3.4135)	Training Total_Loss 3.1613 (3.4135)	Training Prec@1 99.805 (99.921)	Training Prec@5 100.000 (99.975)	
2022-07-25 00:41:37,867: ============================================================
2022-07-25 00:42:18,649: time cost, forward:0.12394222400540995, backward:0.09664748187053174, data cost:0.19394254923464363 
2022-07-25 00:42:18,649: ============================================================
2022-07-25 00:42:18,649: Epoch 13/25 Batch 400/7662 eta: 11:14:18.889497	Training Loss1 3.6574 (3.4414)	Training Total_Loss 3.6574 (3.4414)	Training Prec@1 100.000 (99.917)	Training Prec@5 100.000 (99.973)	
2022-07-25 00:42:18,649: ============================================================
2022-07-25 00:42:59,492: time cost, forward:0.12410062348436497, backward:0.09659577706056033, data cost:0.1924791441173974 
2022-07-25 00:42:59,492: ============================================================
2022-07-25 00:42:59,493: Epoch 13/25 Batch 500/7662 eta: 11:14:38.941354	Training Loss1 3.3233 (3.4617)	Training Total_Loss 3.3233 (3.4617)	Training Prec@1 99.805 (99.915)	Training Prec@5 100.000 (99.970)	
2022-07-25 00:42:59,493: ============================================================
2022-07-25 00:43:40,364: time cost, forward:0.12412705325921111, backward:0.09665449234798476, data cost:0.191538593804896 
2022-07-25 00:43:40,364: ============================================================
2022-07-25 00:43:40,364: Epoch 13/25 Batch 600/7662 eta: 11:14:25.796857	Training Loss1 3.5989 (3.4815)	Training Total_Loss 3.5989 (3.4815)	Training Prec@1 100.000 (99.914)	Training Prec@5 100.000 (99.969)	
2022-07-25 00:43:40,364: ============================================================
2022-07-25 00:44:21,215: time cost, forward:0.12415529764090825, backward:0.09680914947062262, data cost:0.19072209714308316 
2022-07-25 00:44:21,215: ============================================================
2022-07-25 00:44:21,216: Epoch 13/25 Batch 700/7662 eta: 11:13:24.833494	Training Loss1 3.6929 (3.4950)	Training Total_Loss 3.6929 (3.4950)	Training Prec@1 99.414 (99.912)	Training Prec@5 99.805 (99.968)	
2022-07-25 00:44:21,216: ============================================================
2022-07-25 00:45:01,912: time cost, forward:0.12413351079250903, backward:0.09677637593170281, data cost:0.19011594297292086 
2022-07-25 00:45:01,912: ============================================================
2022-07-25 00:45:01,912: Epoch 13/25 Batch 800/7662 eta: 11:10:10.983043	Training Loss1 3.5327 (3.5163)	Training Total_Loss 3.5327 (3.5163)	Training Prec@1 100.000 (99.910)	Training Prec@5 100.000 (99.967)	
2022-07-25 00:45:01,912: ============================================================
2022-07-25 00:45:42,585: time cost, forward:0.12411677903672877, backward:0.09675578068573032, data cost:0.18961636110460667 
2022-07-25 00:45:42,586: ============================================================
2022-07-25 00:45:42,586: Epoch 13/25 Batch 900/7662 eta: 11:09:07.818569	Training Loss1 3.6710 (3.5326)	Training Total_Loss 3.6710 (3.5326)	Training Prec@1 99.414 (99.907)	Training Prec@5 99.609 (99.966)	
2022-07-25 00:45:42,586: ============================================================
2022-07-25 00:46:23,264: time cost, forward:0.12409759355378938, backward:0.09673804516071552, data cost:0.18921774094765847 
2022-07-25 00:46:23,264: ============================================================
2022-07-25 00:46:23,265: Epoch 13/25 Batch 1000/7662 eta: 11:08:32.150768	Training Loss1 3.9215 (3.5494)	Training Total_Loss 3.9215 (3.5494)	Training Prec@1 100.000 (99.905)	Training Prec@5 100.000 (99.967)	
2022-07-25 00:46:23,265: ============================================================
2022-07-25 00:47:04,075: time cost, forward:0.12411043511617173, backward:0.09671374469371792, data cost:0.18900032863495456 
2022-07-25 00:47:04,075: ============================================================
2022-07-25 00:47:04,075: Epoch 13/25 Batch 1100/7662 eta: 11:10:01.102146	Training Loss1 3.7441 (3.5701)	Training Total_Loss 3.7441 (3.5701)	Training Prec@1 100.000 (99.904)	Training Prec@5 100.000 (99.967)	
2022-07-25 00:47:04,075: ============================================================
2022-07-25 00:47:44,909: time cost, forward:0.12414910198749354, backward:0.09668964261905266, data cost:0.18881662772833258 
2022-07-25 00:47:44,909: ============================================================
2022-07-25 00:47:44,909: Epoch 13/25 Batch 1200/7662 eta: 11:09:43.599891	Training Loss1 4.0557 (3.5877)	Training Total_Loss 4.0557 (3.5877)	Training Prec@1 99.805 (99.904)	Training Prec@5 100.000 (99.967)	
2022-07-25 00:47:44,909: ============================================================
2022-07-25 00:48:25,786: time cost, forward:0.12417811132376702, backward:0.09668058152378661, data cost:0.18868561576567217 
2022-07-25 00:48:25,786: ============================================================
2022-07-25 00:48:25,786: Epoch 13/25 Batch 1300/7662 eta: 11:09:44.669348	Training Loss1 4.0455 (3.6055)	Training Total_Loss 4.0455 (3.6055)	Training Prec@1 100.000 (99.904)	Training Prec@5 100.000 (99.967)	
2022-07-25 00:48:25,786: ============================================================
2022-07-25 00:49:06,700: time cost, forward:0.12418638816299057, backward:0.09666923423423522, data cost:0.18861199533027612 
2022-07-25 00:49:06,700: ============================================================
2022-07-25 00:49:06,700: Epoch 13/25 Batch 1400/7662 eta: 11:09:40.638665	Training Loss1 3.7155 (3.6231)	Training Total_Loss 3.7155 (3.6231)	Training Prec@1 99.805 (99.902)	Training Prec@5 99.805 (99.965)	
2022-07-25 00:49:06,700: ============================================================
2022-07-25 00:49:47,577: time cost, forward:0.12419912161391286, backward:0.0966583562740252, data cost:0.18851963117012904 
2022-07-25 00:49:47,577: ============================================================
2022-07-25 00:49:47,577: Epoch 13/25 Batch 1500/7662 eta: 11:08:23.391220	Training Loss1 4.0390 (3.6377)	Training Total_Loss 4.0390 (3.6377)	Training Prec@1 100.000 (99.899)	Training Prec@5 100.000 (99.964)	
2022-07-25 00:49:47,577: ============================================================
2022-07-25 00:50:28,444: time cost, forward:0.12421727091018075, backward:0.0966516079344997, data cost:0.18843017659238012 
2022-07-25 00:50:28,444: ============================================================
2022-07-25 00:50:28,444: Epoch 13/25 Batch 1600/7662 eta: 11:07:32.644401	Training Loss1 3.8252 (3.6527)	Training Total_Loss 3.8252 (3.6527)	Training Prec@1 100.000 (99.899)	Training Prec@5 100.000 (99.963)	
2022-07-25 00:50:28,444: ============================================================
2022-07-25 00:51:09,324: time cost, forward:0.12422915259973662, backward:0.09664852960170052, data cost:0.1883550958818657 
2022-07-25 00:51:09,324: ============================================================
2022-07-25 00:51:09,324: Epoch 13/25 Batch 1700/7662 eta: 11:07:04.017330	Training Loss1 3.7217 (3.6686)	Training Total_Loss 3.7217 (3.6686)	Training Prec@1 100.000 (99.897)	Training Prec@5 100.000 (99.963)	
2022-07-25 00:51:09,324: ============================================================
2022-07-25 00:51:50,132: time cost, forward:0.12424133843087434, backward:0.09664189119747177, data cost:0.18825015788478544 
2022-07-25 00:51:50,132: ============================================================
2022-07-25 00:51:50,132: Epoch 13/25 Batch 1800/7662 eta: 11:05:13.453750	Training Loss1 4.0899 (3.6852)	Training Total_Loss 4.0899 (3.6852)	Training Prec@1 100.000 (99.895)	Training Prec@5 100.000 (99.963)	
2022-07-25 00:51:50,133: ============================================================
2022-07-25 00:52:30,928: time cost, forward:0.12424283808567073, backward:0.09663845414296773, data cost:0.18816158782814352 
2022-07-25 00:52:30,928: ============================================================
2022-07-25 00:52:30,929: Epoch 13/25 Batch 1900/7662 eta: 11:04:20.721273	Training Loss1 3.8640 (3.7035)	Training Total_Loss 3.8640 (3.7035)	Training Prec@1 100.000 (99.894)	Training Prec@5 100.000 (99.962)	
2022-07-25 00:52:30,929: ============================================================
2022-07-25 00:53:11,689: time cost, forward:0.12423105798046728, backward:0.09663604962462005, data cost:0.18807711298314259 
2022-07-25 00:53:11,689: ============================================================
2022-07-25 00:53:11,689: Epoch 13/25 Batch 2000/7662 eta: 11:03:04.910133	Training Loss1 4.0066 (3.7207)	Training Total_Loss 4.0066 (3.7207)	Training Prec@1 100.000 (99.893)	Training Prec@5 100.000 (99.961)	
2022-07-25 00:53:11,689: ============================================================
2022-07-25 00:53:52,442: time cost, forward:0.12421695114942663, backward:0.09663295586828166, data cost:0.18799237378044548 
2022-07-25 00:53:52,442: ============================================================
2022-07-25 00:53:52,442: Epoch 13/25 Batch 2100/7662 eta: 11:02:17.557308	Training Loss1 3.9777 (3.7364)	Training Total_Loss 3.9777 (3.7364)	Training Prec@1 99.805 (99.891)	Training Prec@5 99.805 (99.961)	
2022-07-25 00:53:52,443: ============================================================
2022-07-25 00:54:33,207: time cost, forward:0.12422191820235727, backward:0.09663186424588442, data cost:0.18790613818895063 
2022-07-25 00:54:33,208: ============================================================
2022-07-25 00:54:33,208: Epoch 13/25 Batch 2200/7662 eta: 11:01:48.276475	Training Loss1 3.7919 (3.7525)	Training Total_Loss 3.7919 (3.7525)	Training Prec@1 99.805 (99.889)	Training Prec@5 100.000 (99.960)	
2022-07-25 00:54:33,208: ============================================================
2022-07-25 00:55:13,988: time cost, forward:0.12421894446825556, backward:0.09662824529520891, data cost:0.187848118711109 
2022-07-25 00:55:13,988: ============================================================
2022-07-25 00:55:13,988: Epoch 13/25 Batch 2300/7662 eta: 11:01:22.208457	Training Loss1 4.1216 (3.7684)	Training Total_Loss 4.1216 (3.7684)	Training Prec@1 99.414 (99.887)	Training Prec@5 99.609 (99.960)	
2022-07-25 00:55:13,988: ============================================================
2022-07-25 00:55:54,762: time cost, forward:0.12421507068155407, backward:0.09662423078195907, data cost:0.18779498808281578 
2022-07-25 00:55:54,763: ============================================================
2022-07-25 00:55:54,763: Epoch 13/25 Batch 2400/7662 eta: 11:00:35.662781	Training Loss1 4.2633 (3.7829)	Training Total_Loss 4.2633 (3.7829)	Training Prec@1 100.000 (99.886)	Training Prec@5 100.000 (99.959)	
2022-07-25 00:55:54,763: ============================================================
2022-07-25 00:56:35,479: time cost, forward:0.12420663618001522, backward:0.09661635077920329, data cost:0.18773245906867997 
2022-07-25 00:56:35,480: ============================================================
2022-07-25 00:56:35,480: Epoch 13/25 Batch 2500/7662 eta: 10:58:59.294044	Training Loss1 4.6267 (3.7973)	Training Total_Loss 4.6267 (3.7973)	Training Prec@1 99.805 (99.886)	Training Prec@5 100.000 (99.960)	
2022-07-25 00:56:35,480: ============================================================
2022-07-25 00:57:16,268: time cost, forward:0.12420251893281661, backward:0.09660831072001147, data cost:0.18769889998867129 
2022-07-25 00:57:16,269: ============================================================
2022-07-25 00:57:16,269: Epoch 13/25 Batch 2600/7662 eta: 10:59:27.968783	Training Loss1 4.2340 (3.8122)	Training Total_Loss 4.2340 (3.8122)	Training Prec@1 100.000 (99.885)	Training Prec@5 100.000 (99.960)	
2022-07-25 00:57:16,269: ============================================================
2022-07-25 00:57:56,949: time cost, forward:0.12418785418524217, backward:0.0966009742112105, data cost:0.18763298527228917 
2022-07-25 00:57:56,950: ============================================================
2022-07-25 00:57:56,950: Epoch 13/25 Batch 2700/7662 eta: 10:57:02.708939	Training Loss1 4.5420 (3.8255)	Training Total_Loss 4.5420 (3.8255)	Training Prec@1 99.805 (99.885)	Training Prec@5 100.000 (99.960)	
2022-07-25 00:57:56,950: ============================================================
2022-07-25 00:58:37,734: time cost, forward:0.12420241566120023, backward:0.09659456704164582, data cost:0.18758488110279603 
2022-07-25 00:58:37,734: ============================================================
2022-07-25 00:58:37,735: Epoch 13/25 Batch 2800/7662 eta: 10:58:02.606936	Training Loss1 4.3734 (3.8394)	Training Total_Loss 4.3734 (3.8394)	Training Prec@1 99.805 (99.884)	Training Prec@5 100.000 (99.959)	
2022-07-25 00:58:37,735: ============================================================
2022-07-25 00:59:18,455: time cost, forward:0.12419813565033475, backward:0.09659095499670971, data cost:0.1875303632105248 
2022-07-25 00:59:18,456: ============================================================
2022-07-25 00:59:18,456: Epoch 13/25 Batch 2900/7662 eta: 10:56:20.252027	Training Loss1 4.1103 (3.8519)	Training Total_Loss 4.1103 (3.8519)	Training Prec@1 100.000 (99.883)	Training Prec@5 100.000 (99.959)	
2022-07-25 00:59:18,456: ============================================================
2022-07-25 00:59:59,225: time cost, forward:0.12420704548420132, backward:0.09658843622719618, data cost:0.1874845539899459 
2022-07-25 00:59:59,225: ============================================================
2022-07-25 00:59:59,225: Epoch 13/25 Batch 3000/7662 eta: 10:56:26.234414	Training Loss1 4.3164 (3.8660)	Training Total_Loss 4.3164 (3.8660)	Training Prec@1 100.000 (99.882)	Training Prec@5 100.000 (99.959)	
2022-07-25 00:59:59,225: ============================================================
2022-07-25 01:00:39,951: time cost, forward:0.12420659412988427, backward:0.09658791196465531, data cost:0.18742849127482353 
2022-07-25 01:00:39,951: ============================================================
2022-07-25 01:00:39,951: Epoch 13/25 Batch 3100/7662 eta: 10:55:03.231506	Training Loss1 3.9251 (3.8808)	Training Total_Loss 3.9251 (3.8808)	Training Prec@1 99.805 (99.881)	Training Prec@5 100.000 (99.959)	
2022-07-25 01:00:39,951: ============================================================
2022-07-25 01:01:20,713: time cost, forward:0.12421429794480854, backward:0.09658416296102434, data cost:0.18738805401805939 
2022-07-25 01:01:20,713: ============================================================
2022-07-25 01:01:20,713: Epoch 13/25 Batch 3200/7662 eta: 10:54:57.527153	Training Loss1 4.3631 (3.8938)	Training Total_Loss 4.3631 (3.8938)	Training Prec@1 99.805 (99.880)	Training Prec@5 100.000 (99.959)	
2022-07-25 01:01:20,713: ============================================================
2022-07-25 01:02:01,447: time cost, forward:0.12420896314497824, backward:0.09658215081341233, data cost:0.18734557797020585 
2022-07-25 01:02:01,447: ============================================================
2022-07-25 01:02:01,447: Epoch 13/25 Batch 3300/7662 eta: 10:53:49.618495	Training Loss1 4.1176 (3.9058)	Training Total_Loss 4.1176 (3.9058)	Training Prec@1 99.805 (99.880)	Training Prec@5 100.000 (99.959)	
2022-07-25 01:02:01,447: ============================================================
2022-07-25 01:02:42,100: time cost, forward:0.12420176267273182, backward:0.09657855783009676, data cost:0.18729360779091414 
2022-07-25 01:02:42,100: ============================================================
2022-07-25 01:02:42,100: Epoch 13/25 Batch 3400/7662 eta: 10:51:51.147427	Training Loss1 4.3188 (3.9179)	Training Total_Loss 4.3188 (3.9179)	Training Prec@1 99.805 (99.878)	Training Prec@5 100.000 (99.958)	
2022-07-25 01:02:42,100: ============================================================
2022-07-25 01:03:22,852: time cost, forward:0.12420343494169983, backward:0.09657594407412215, data cost:0.18726270428450661 
2022-07-25 01:03:22,852: ============================================================
2022-07-25 01:03:22,852: Epoch 13/25 Batch 3500/7662 eta: 10:52:45.363876	Training Loss1 4.4856 (3.9304)	Training Total_Loss 4.4856 (3.9304)	Training Prec@1 99.805 (99.877)	Training Prec@5 100.000 (99.957)	
2022-07-25 01:03:22,852: ============================================================
2022-07-25 01:04:03,630: time cost, forward:0.12421111876383593, backward:0.09657067436415409, data cost:0.18723724563441763 
2022-07-25 01:04:03,631: ============================================================
2022-07-25 01:04:03,631: Epoch 13/25 Batch 3600/7662 eta: 10:52:30.294229	Training Loss1 4.1585 (3.9421)	Training Total_Loss 4.1585 (3.9421)	Training Prec@1 99.609 (99.876)	Training Prec@5 100.000 (99.957)	
2022-07-25 01:04:03,631: ============================================================
2022-07-25 01:04:44,572: time cost, forward:0.12422723504587521, backward:0.09659669888473969, data cost:0.18721650032843729 
2022-07-25 01:04:44,572: ============================================================
2022-07-25 01:04:44,572: Epoch 13/25 Batch 3700/7662 eta: 10:54:25.462982	Training Loss1 4.5476 (3.9538)	Training Total_Loss 4.5476 (3.9538)	Training Prec@1 99.609 (99.875)	Training Prec@5 100.000 (99.957)	
2022-07-25 01:04:44,572: ============================================================
2022-07-25 01:05:25,510: time cost, forward:0.12423188562737103, backward:0.09662465937484657, data cost:0.18720362851041716 
2022-07-25 01:05:25,510: ============================================================
2022-07-25 01:05:25,510: Epoch 13/25 Batch 3800/7662 eta: 10:53:41.623125	Training Loss1 3.9811 (3.9645)	Training Total_Loss 3.9811 (3.9645)	Training Prec@1 100.000 (99.874)	Training Prec@5 100.000 (99.956)	
2022-07-25 01:05:25,510: ============================================================
2022-07-25 01:06:06,317: time cost, forward:0.12422597350203463, backward:0.09665278166677745, data cost:0.1871672507034384 
2022-07-25 01:06:06,317: ============================================================
2022-07-25 01:06:06,318: Epoch 13/25 Batch 3900/7662 eta: 10:50:55.667002	Training Loss1 4.3278 (3.9758)	Training Total_Loss 4.3278 (3.9758)	Training Prec@1 100.000 (99.873)	Training Prec@5 100.000 (99.956)	
2022-07-25 01:06:06,318: ============================================================
2022-07-25 01:06:47,136: time cost, forward:0.12422236534141547, backward:0.09668124196051836, data cost:0.18713226882360315 
2022-07-25 01:06:47,136: ============================================================
2022-07-25 01:06:47,136: Epoch 13/25 Batch 4000/7662 eta: 10:50:25.615273	Training Loss1 4.4418 (3.9874)	Training Total_Loss 4.4418 (3.9874)	Training Prec@1 99.805 (99.872)	Training Prec@5 99.805 (99.956)	
2022-07-25 01:06:47,137: ============================================================
2022-07-25 01:07:27,852: time cost, forward:0.12421901687292623, backward:0.09668641079923355, data cost:0.1870960859474132 
2022-07-25 01:07:27,852: ============================================================
2022-07-25 01:07:27,852: Epoch 13/25 Batch 4100/7662 eta: 10:48:06.249244	Training Loss1 4.2268 (3.9989)	Training Total_Loss 4.2268 (3.9989)	Training Prec@1 100.000 (99.871)	Training Prec@5 100.000 (99.956)	
2022-07-25 01:07:27,852: ============================================================
2022-07-25 01:08:08,474: time cost, forward:0.12420720411329277, backward:0.09668005202662011, data cost:0.18705998474315508 
2022-07-25 01:08:08,474: ============================================================
2022-07-25 01:08:08,474: Epoch 13/25 Batch 4200/7662 eta: 10:45:56.516310	Training Loss1 4.3316 (4.0108)	Training Total_Loss 4.3316 (4.0108)	Training Prec@1 99.805 (99.869)	Training Prec@5 99.805 (99.955)	
2022-07-25 01:08:08,474: ============================================================
2022-07-25 01:08:49,157: time cost, forward:0.12419969604635937, backward:0.09667443264138008, data cost:0.18703562632691836 
2022-07-25 01:08:49,158: ============================================================
2022-07-25 01:08:49,158: Epoch 13/25 Batch 4300/7662 eta: 10:46:14.184311	Training Loss1 4.5564 (4.0213)	Training Total_Loss 4.5564 (4.0213)	Training Prec@1 99.805 (99.868)	Training Prec@5 100.000 (99.954)	
2022-07-25 01:08:49,158: ============================================================
2022-07-25 01:09:29,784: time cost, forward:0.12419543837547085, backward:0.09666751259753693, data cost:0.18699804813543702 
2022-07-25 01:09:29,785: ============================================================
2022-07-25 01:09:29,785: Epoch 13/25 Batch 4400/7662 eta: 10:44:39.713703	Training Loss1 4.4011 (4.0315)	Training Total_Loss 4.4011 (4.0315)	Training Prec@1 100.000 (99.866)	Training Prec@5 100.000 (99.954)	
2022-07-25 01:09:29,785: ============================================================
2022-07-25 01:10:10,371: time cost, forward:0.1241816215765267, backward:0.09666278850345988, data cost:0.1869615398266231 
2022-07-25 01:10:10,371: ============================================================
2022-07-25 01:10:10,372: Epoch 13/25 Batch 4500/7662 eta: 10:43:20.870963	Training Loss1 4.3332 (4.0422)	Training Total_Loss 4.3332 (4.0422)	Training Prec@1 99.805 (99.865)	Training Prec@5 99.805 (99.954)	
2022-07-25 01:10:10,372: ============================================================
2022-07-25 01:10:50,963: time cost, forward:0.12417085986211004, backward:0.09665720456059691, data cost:0.1869264278341361 
2022-07-25 01:10:50,963: ============================================================
2022-07-25 01:10:50,963: Epoch 13/25 Batch 4600/7662 eta: 10:42:44.847765	Training Loss1 4.6335 (4.0522)	Training Total_Loss 4.6335 (4.0522)	Training Prec@1 100.000 (99.865)	Training Prec@5 100.000 (99.953)	
2022-07-25 01:10:50,963: ============================================================
2022-07-25 01:11:31,571: time cost, forward:0.12416051149013119, backward:0.09665233060435352, data cost:0.18689544892458237 
2022-07-25 01:11:31,571: ============================================================
2022-07-25 01:11:31,571: Epoch 13/25 Batch 4700/7662 eta: 10:42:19.592935	Training Loss1 4.1531 (4.0622)	Training Total_Loss 4.1531 (4.0622)	Training Prec@1 100.000 (99.864)	Training Prec@5 100.000 (99.953)	
2022-07-25 01:11:31,571: ============================================================
2022-07-25 01:12:12,175: time cost, forward:0.12415157678003583, backward:0.0966469207687362, data cost:0.18686440031238832 
2022-07-25 01:12:12,175: ============================================================
2022-07-25 01:12:12,175: Epoch 13/25 Batch 4800/7662 eta: 10:41:35.715783	Training Loss1 4.4649 (4.0720)	Training Total_Loss 4.4649 (4.0720)	Training Prec@1 100.000 (99.863)	Training Prec@5 100.000 (99.953)	
2022-07-25 01:12:12,175: ============================================================
2022-07-25 01:12:52,766: time cost, forward:0.12413978542593407, backward:0.09664224103704523, data cost:0.1868348950438413 
2022-07-25 01:12:52,767: ============================================================
2022-07-25 01:12:52,767: Epoch 13/25 Batch 4900/7662 eta: 10:40:43.038010	Training Loss1 4.8985 (4.0812)	Training Total_Loss 4.8985 (4.0812)	Training Prec@1 99.805 (99.862)	Training Prec@5 100.000 (99.952)	
2022-07-25 01:12:52,767: ============================================================
2022-07-25 01:13:33,358: time cost, forward:0.12412879485610867, backward:0.09663753820481503, data cost:0.18680718064808946 
2022-07-25 01:13:33,358: ============================================================
2022-07-25 01:13:33,358: Epoch 13/25 Batch 5000/7662 eta: 10:40:02.175563	Training Loss1 4.7495 (4.0908)	Training Total_Loss 4.7495 (4.0908)	Training Prec@1 99.805 (99.861)	Training Prec@5 100.000 (99.952)	
2022-07-25 01:13:33,358: ============================================================
2022-07-25 01:14:13,988: time cost, forward:0.12412081028485115, backward:0.0966351387149611, data cost:0.18678367673286997 
2022-07-25 01:14:13,988: ============================================================
2022-07-25 01:14:13,988: Epoch 13/25 Batch 5100/7662 eta: 10:39:58.620968	Training Loss1 5.0649 (4.1000)	Training Total_Loss 5.0649 (4.1000)	Training Prec@1 100.000 (99.860)	Training Prec@5 100.000 (99.952)	
2022-07-25 01:14:13,989: ============================================================
2022-07-25 01:14:54,625: time cost, forward:0.12411372884921694, backward:0.09663424406585429, data cost:0.18675988530810003 
2022-07-25 01:14:54,625: ============================================================
2022-07-25 01:14:54,626: Epoch 13/25 Batch 5200/7662 eta: 10:39:24.305019	Training Loss1 4.5489 (4.1087)	Training Total_Loss 4.5489 (4.1087)	Training Prec@1 100.000 (99.859)	Training Prec@5 100.000 (99.952)	
2022-07-25 01:14:54,626: ============================================================
2022-07-25 01:15:35,264: time cost, forward:0.12410730662312591, backward:0.09663235846499853, data cost:0.186738408540955 
2022-07-25 01:15:35,264: ============================================================
2022-07-25 01:15:35,264: Epoch 13/25 Batch 5300/7662 eta: 10:38:44.906102	Training Loss1 3.9503 (4.1184)	Training Total_Loss 3.9503 (4.1184)	Training Prec@1 99.805 (99.858)	Training Prec@5 99.805 (99.952)	
2022-07-25 01:15:35,264: ============================================================
2022-07-25 01:16:15,907: time cost, forward:0.12410133276676376, backward:0.09663073644304214, data cost:0.18671795416152087 
2022-07-25 01:16:15,907: ============================================================
2022-07-25 01:16:15,907: Epoch 13/25 Batch 5400/7662 eta: 10:38:08.520582	Training Loss1 5.0122 (4.1270)	Training Total_Loss 5.0122 (4.1270)	Training Prec@1 100.000 (99.857)	Training Prec@5 100.000 (99.951)	
2022-07-25 01:16:15,907: ============================================================
2022-07-25 01:16:56,545: time cost, forward:0.12409515510062387, backward:0.096629094808703, data cost:0.1866978956018931 
2022-07-25 01:16:56,545: ============================================================
2022-07-25 01:16:56,545: Epoch 13/25 Batch 5500/7662 eta: 10:37:23.305207	Training Loss1 4.5462 (4.1364)	Training Total_Loss 4.5462 (4.1364)	Training Prec@1 100.000 (99.857)	Training Prec@5 100.000 (99.951)	
2022-07-25 01:16:56,545: ============================================================
2022-07-25 01:17:37,188: time cost, forward:0.12408984101314718, backward:0.09662677015783873, data cost:0.1866794505871328 
2022-07-25 01:17:37,188: ============================================================
2022-07-25 01:17:37,188: Epoch 13/25 Batch 5600/7662 eta: 10:36:47.413054	Training Loss1 4.9879 (4.1450)	Training Total_Loss 4.9879 (4.1450)	Training Prec@1 99.805 (99.855)	Training Prec@5 100.000 (99.951)	
2022-07-25 01:17:37,188: ============================================================
2022-07-25 01:18:17,817: time cost, forward:0.12408452110136574, backward:0.09662388843242527, data cost:0.1866603777437466 
2022-07-25 01:18:17,818: ============================================================
2022-07-25 01:18:17,818: Epoch 13/25 Batch 5700/7662 eta: 10:35:54.008068	Training Loss1 4.8711 (4.1549)	Training Total_Loss 4.8711 (4.1549)	Training Prec@1 100.000 (99.853)	Training Prec@5 100.000 (99.950)	
2022-07-25 01:18:17,818: ============================================================
2022-07-25 01:18:58,448: time cost, forward:0.1240786161684213, backward:0.09662170590234431, data cost:0.18664221920665328 
2022-07-25 01:18:58,448: ============================================================
2022-07-25 01:18:58,448: Epoch 13/25 Batch 5800/7662 eta: 10:35:14.064445	Training Loss1 5.2627 (4.1635)	Training Total_Loss 5.2627 (4.1635)	Training Prec@1 99.609 (99.852)	Training Prec@5 100.000 (99.950)	
2022-07-25 01:18:58,448: ============================================================
2022-07-25 01:19:39,090: time cost, forward:0.12407413994504105, backward:0.09662112431478492, data cost:0.1866238506027431 
2022-07-25 01:19:39,091: ============================================================
2022-07-25 01:19:39,091: Epoch 13/25 Batch 5900/7662 eta: 10:34:45.113830	Training Loss1 4.2280 (4.1719)	Training Total_Loss 4.2280 (4.1719)	Training Prec@1 100.000 (99.851)	Training Prec@5 100.000 (99.950)	
2022-07-25 01:19:39,091: ============================================================
2022-07-25 01:20:19,753: time cost, forward:0.12407212119079428, backward:0.09662154663163516, data cost:0.18660625542654835 
2022-07-25 01:20:19,753: ============================================================
2022-07-25 01:20:19,753: Epoch 13/25 Batch 6000/7662 eta: 10:34:22.767075	Training Loss1 4.6815 (4.1795)	Training Total_Loss 4.6815 (4.1795)	Training Prec@1 99.609 (99.850)	Training Prec@5 100.000 (99.949)	
2022-07-25 01:20:19,753: ============================================================
2022-07-25 01:21:00,390: time cost, forward:0.12406686646642402, backward:0.09661878943736484, data cost:0.18659131842414792 
2022-07-25 01:21:00,390: ============================================================
2022-07-25 01:21:00,390: Epoch 13/25 Batch 6100/7662 eta: 10:33:18.494511	Training Loss1 4.3676 (4.1874)	Training Total_Loss 4.3676 (4.1874)	Training Prec@1 100.000 (99.850)	Training Prec@5 100.000 (99.949)	
2022-07-25 01:21:00,390: ============================================================
2022-07-25 01:21:41,027: time cost, forward:0.1240621996148976, backward:0.09661686299289113, data cost:0.18657558228550736 
2022-07-25 01:21:41,027: ============================================================
2022-07-25 01:21:41,027: Epoch 13/25 Batch 6200/7662 eta: 10:32:37.728955	Training Loss1 4.4827 (4.1966)	Training Total_Loss 4.4827 (4.1966)	Training Prec@1 100.000 (99.848)	Training Prec@5 100.000 (99.949)	
2022-07-25 01:21:41,027: ============================================================
2022-07-25 01:22:21,669: time cost, forward:0.12405797692968233, backward:0.09661595884590495, data cost:0.18656014245471267 
2022-07-25 01:22:21,669: ============================================================
2022-07-25 01:22:21,669: Epoch 13/25 Batch 6300/7662 eta: 10:32:01.778179	Training Loss1 4.6846 (4.2042)	Training Total_Loss 4.6846 (4.2042)	Training Prec@1 99.805 (99.848)	Training Prec@5 100.000 (99.948)	
2022-07-25 01:22:21,669: ============================================================
2022-07-25 01:23:02,299: time cost, forward:0.12405249498322302, backward:0.09661545740811038, data cost:0.18654417302351778 
2022-07-25 01:23:02,300: ============================================================
2022-07-25 01:23:02,300: Epoch 13/25 Batch 6400/7662 eta: 10:31:10.625764	Training Loss1 4.8153 (4.2109)	Training Total_Loss 4.8153 (4.2109)	Training Prec@1 99.219 (99.847)	Training Prec@5 99.805 (99.948)	
2022-07-25 01:23:02,300: ============================================================
2022-07-25 01:23:42,938: time cost, forward:0.12404723691287307, backward:0.09661601660599763, data cost:0.18652883058768965 
2022-07-25 01:23:42,938: ============================================================
2022-07-25 01:23:42,938: Epoch 13/25 Batch 6500/7662 eta: 10:30:37.002478	Training Loss1 4.8667 (4.2186)	Training Total_Loss 4.8667 (4.2186)	Training Prec@1 100.000 (99.846)	Training Prec@5 100.000 (99.948)	
2022-07-25 01:23:42,938: ============================================================
2022-07-25 01:24:23,584: time cost, forward:0.12404250520560792, backward:0.09661739341127708, data cost:0.18651402648750048 
2022-07-25 01:24:23,584: ============================================================
2022-07-25 01:24:23,584: Epoch 13/25 Batch 6600/7662 eta: 10:30:03.821602	Training Loss1 5.2781 (4.2263)	Training Total_Loss 5.2781 (4.2263)	Training Prec@1 99.805 (99.844)	Training Prec@5 99.805 (99.948)	
2022-07-25 01:24:23,584: ============================================================
2022-07-25 01:25:04,226: time cost, forward:0.12403805381523209, backward:0.09661701886151011, data cost:0.18650079663252897 
2022-07-25 01:25:04,226: ============================================================
2022-07-25 01:25:04,226: Epoch 13/25 Batch 6700/7662 eta: 10:29:19.216386	Training Loss1 5.0577 (4.2340)	Training Total_Loss 5.0577 (4.2340)	Training Prec@1 99.805 (99.844)	Training Prec@5 100.000 (99.947)	
2022-07-25 01:25:04,226: ============================================================
2022-07-25 01:25:44,854: time cost, forward:0.12403406460752626, backward:0.09661391020206901, data cost:0.18648842833185567 
2022-07-25 01:25:44,855: ============================================================
2022-07-25 01:25:44,855: Epoch 13/25 Batch 6800/7662 eta: 10:28:26.287361	Training Loss1 4.7228 (4.2410)	Training Total_Loss 4.7228 (4.2410)	Training Prec@1 99.609 (99.843)	Training Prec@5 99.805 (99.947)	
2022-07-25 01:25:44,855: ============================================================
2022-07-25 01:26:25,472: time cost, forward:0.12402999914285151, backward:0.09661059853719238, data cost:0.18647542447694093 
2022-07-25 01:26:25,472: ============================================================
2022-07-25 01:26:25,472: Epoch 13/25 Batch 6900/7662 eta: 10:27:35.133168	Training Loss1 4.7068 (4.2471)	Training Total_Loss 4.7068 (4.2471)	Training Prec@1 99.805 (99.842)	Training Prec@5 99.805 (99.947)	
2022-07-25 01:26:25,472: ============================================================
2022-07-25 01:27:06,076: time cost, forward:0.12402607056222179, backward:0.09660803251461329, data cost:0.1864600958594562 
2022-07-25 01:27:06,076: ============================================================
2022-07-25 01:27:06,076: Epoch 13/25 Batch 7000/7662 eta: 10:26:42.007486	Training Loss1 4.9912 (4.2544)	Training Total_Loss 4.9912 (4.2544)	Training Prec@1 99.805 (99.841)	Training Prec@5 100.000 (99.946)	
2022-07-25 01:27:06,076: ============================================================
2022-07-25 01:27:46,723: time cost, forward:0.1240264300746571, backward:0.09660610438635826, data cost:0.1864464695410991 
2022-07-25 01:27:46,723: ============================================================
2022-07-25 01:27:46,723: Epoch 13/25 Batch 7100/7662 eta: 10:26:41.266103	Training Loss1 4.9179 (4.2614)	Training Total_Loss 4.9179 (4.2614)	Training Prec@1 99.414 (99.839)	Training Prec@5 99.609 (99.946)	
2022-07-25 01:27:46,723: ============================================================
2022-07-25 01:28:27,332: time cost, forward:0.12402174853338005, backward:0.09660447185313409, data cost:0.18643264357191536 
2022-07-25 01:28:27,332: ============================================================
2022-07-25 01:28:27,332: Epoch 13/25 Batch 7200/7662 eta: 10:25:25.976098	Training Loss1 4.7969 (4.2690)	Training Total_Loss 4.7969 (4.2690)	Training Prec@1 99.414 (99.838)	Training Prec@5 99.609 (99.945)	
2022-07-25 01:28:27,333: ============================================================
2022-07-25 01:29:07,927: time cost, forward:0.1240167105617646, backward:0.0966019539624669, data cost:0.18641848684353507 
2022-07-25 01:29:07,927: ============================================================
2022-07-25 01:29:07,927: Epoch 13/25 Batch 7300/7662 eta: 10:24:31.575078	Training Loss1 5.1451 (4.2757)	Training Total_Loss 5.1451 (4.2757)	Training Prec@1 99.414 (99.837)	Training Prec@5 100.000 (99.945)	
2022-07-25 01:29:07,927: ============================================================
2022-07-25 01:29:48,528: time cost, forward:0.12401242990206345, backward:0.09660006990495897, data cost:0.18640453610199176 
2022-07-25 01:29:48,528: ============================================================
2022-07-25 01:29:48,528: Epoch 13/25 Batch 7400/7662 eta: 10:23:57.159352	Training Loss1 4.8997 (4.2829)	Training Total_Loss 4.8997 (4.2829)	Training Prec@1 99.609 (99.836)	Training Prec@5 99.805 (99.945)	
2022-07-25 01:29:48,528: ============================================================
2022-07-25 01:30:29,143: time cost, forward:0.12400971897317022, backward:0.09659758286883727, data cost:0.1863920152592713 
2022-07-25 01:30:29,144: ============================================================
2022-07-25 01:30:29,144: Epoch 13/25 Batch 7500/7662 eta: 10:23:29.760724	Training Loss1 5.2467 (4.2892)	Training Total_Loss 5.2467 (4.2892)	Training Prec@1 100.000 (99.835)	Training Prec@5 100.000 (99.944)	
2022-07-25 01:30:29,144: ============================================================
2022-07-25 01:31:09,826: time cost, forward:0.12400758722955137, backward:0.09660274264906281, data cost:0.18638017011608068 
2022-07-25 01:31:09,826: ============================================================
2022-07-25 01:31:09,826: Epoch 13/25 Batch 7600/7662 eta: 10:23:50.623292	Training Loss1 4.5234 (4.2961)	Training Total_Loss 4.5234 (4.2961)	Training Prec@1 100.000 (99.834)	Training Prec@5 100.000 (99.944)	
2022-07-25 01:31:09,826: ============================================================
2022-07-25 01:31:37,038: Epoch 13/25 Batch 7663/7662 eta: 10:23:24.993402	Training Loss1 4.3801 (4.3001)	Training Total_Loss 4.3801 (4.3001)	Training Prec@1 100.000 (99.834)	Training Prec@5 100.000 (99.944)	
2022-07-25 01:31:37,038: ============================================================
2022-07-25 01:32:19,602: time cost, forward:0.12419694601887404, backward:0.09708678601968168, data cost:0.20481194871844668 
2022-07-25 01:32:19,603: ============================================================
2022-07-25 01:32:19,604: Epoch 14/25 Batch 100/7662 eta: 10:49:45.301775	Training Loss1 3.0268 (3.5101)	Training Total_Loss 3.0268 (3.5101)	Training Prec@1 100.000 (99.917)	Training Prec@5 100.000 (99.980)	
2022-07-25 01:32:19,604: ============================================================
2022-07-25 01:33:00,525: time cost, forward:0.12417558449596616, backward:0.09714248671603562, data cost:0.19584105002820193 
2022-07-25 01:33:00,525: ============================================================
2022-07-25 01:33:00,526: Epoch 14/25 Batch 200/7662 eta: 10:25:43.809217	Training Loss1 3.2709 (3.5182)	Training Total_Loss 3.2709 (3.5182)	Training Prec@1 100.000 (99.907)	Training Prec@5 100.000 (99.974)	
2022-07-25 01:33:00,526: ============================================================
2022-07-25 01:33:41,445: time cost, forward:0.12417272739984518, backward:0.09719681819545783, data cost:0.1928657831555625 
2022-07-25 01:33:41,445: ============================================================
2022-07-25 01:33:41,445: Epoch 14/25 Batch 300/7662 eta: 10:25:00.915571	Training Loss1 3.7259 (3.5403)	Training Total_Loss 3.7259 (3.5403)	Training Prec@1 100.000 (99.909)	Training Prec@5 100.000 (99.973)	
2022-07-25 01:33:41,445: ============================================================
2022-07-25 01:34:22,324: time cost, forward:0.12414726458097759, backward:0.09723575790424395, data cost:0.1913085635144609 
2022-07-25 01:34:22,325: ============================================================
2022-07-25 01:34:22,325: Epoch 14/25 Batch 400/7662 eta: 10:23:43.255837	Training Loss1 3.0103 (3.5629)	Training Total_Loss 3.0103 (3.5629)	Training Prec@1 100.000 (99.907)	Training Prec@5 100.000 (99.970)	
2022-07-25 01:34:22,325: ============================================================
2022-07-25 01:35:03,211: time cost, forward:0.12416984036355792, backward:0.09726066388682517, data cost:0.19037162039227382 
2022-07-25 01:35:03,211: ============================================================
2022-07-25 01:35:03,211: Epoch 14/25 Batch 500/7662 eta: 10:23:08.651532	Training Loss1 3.7233 (3.5817)	Training Total_Loss 3.7233 (3.5817)	Training Prec@1 99.805 (99.905)	Training Prec@5 99.805 (99.972)	
2022-07-25 01:35:03,212: ============================================================
2022-07-25 01:35:44,127: time cost, forward:0.12417894372955984, backward:0.09726650010365277, data cost:0.18980802160272614 
2022-07-25 01:35:44,128: ============================================================
2022-07-25 01:35:44,128: Epoch 14/25 Batch 600/7662 eta: 10:22:55.438784	Training Loss1 4.1561 (3.6043)	Training Total_Loss 4.1561 (3.6043)	Training Prec@1 99.805 (99.901)	Training Prec@5 99.805 (99.970)	
2022-07-25 01:35:44,128: ============================================================
2022-07-25 01:36:25,083: time cost, forward:0.12414164468113104, backward:0.09731231670352351, data cost:0.18947602921459977 
2022-07-25 01:36:25,084: ============================================================
2022-07-25 01:36:25,084: Epoch 14/25 Batch 700/7662 eta: 10:22:49.975312	Training Loss1 3.9828 (3.6266)	Training Total_Loss 3.9828 (3.6266)	Training Prec@1 100.000 (99.900)	Training Prec@5 100.000 (99.969)	
2022-07-25 01:36:25,084: ============================================================
2022-07-25 01:37:05,973: time cost, forward:0.12411474913022992, backward:0.09736608175819597, data cost:0.1891217213846715 
2022-07-25 01:37:05,973: ============================================================
2022-07-25 01:37:05,974: Epoch 14/25 Batch 800/7662 eta: 10:21:08.983285	Training Loss1 3.8186 (3.6518)	Training Total_Loss 3.8186 (3.6518)	Training Prec@1 100.000 (99.898)	Training Prec@5 100.000 (99.969)	
2022-07-25 01:37:05,974: ============================================================
2022-07-25 01:37:46,824: time cost, forward:0.12407387270943342, backward:0.09741151637840059, data cost:0.1888088763622076 
2022-07-25 01:37:46,824: ============================================================
2022-07-25 01:37:46,824: Epoch 14/25 Batch 900/7662 eta: 10:19:52.492158	Training Loss1 4.0521 (3.6677)	Training Total_Loss 4.0521 (3.6677)	Training Prec@1 100.000 (99.897)	Training Prec@5 100.000 (99.969)	
2022-07-25 01:37:46,824: ============================================================
2022-07-25 01:38:27,716: time cost, forward:0.12405472713428456, backward:0.0974549526447529, data cost:0.1885907771709087 
2022-07-25 01:38:27,717: ============================================================
2022-07-25 01:38:27,717: Epoch 14/25 Batch 1000/7662 eta: 10:19:49.651748	Training Loss1 4.0068 (3.6902)	Training Total_Loss 4.0068 (3.6902)	Training Prec@1 99.805 (99.894)	Training Prec@5 100.000 (99.968)	
2022-07-25 01:38:27,717: ============================================================
2022-07-25 01:39:08,573: time cost, forward:0.12402182237140909, backward:0.09749113721561171, data cost:0.18838748788703452 
2022-07-25 01:39:08,573: ============================================================
2022-07-25 01:39:08,574: Epoch 14/25 Batch 1100/7662 eta: 10:18:36.408332	Training Loss1 4.1560 (3.7094)	Training Total_Loss 4.1560 (3.7094)	Training Prec@1 99.805 (99.893)	Training Prec@5 100.000 (99.968)	
2022-07-25 01:39:08,574: ============================================================
2022-07-25 01:39:49,446: time cost, forward:0.12401923783328556, backward:0.09752542421756137, data cost:0.18819774479742743 
2022-07-25 01:39:49,446: ============================================================
2022-07-25 01:39:49,446: Epoch 14/25 Batch 1200/7662 eta: 10:18:09.741852	Training Loss1 3.7366 (3.7265)	Training Total_Loss 3.7366 (3.7265)	Training Prec@1 100.000 (99.894)	Training Prec@5 100.000 (99.968)	
2022-07-25 01:39:49,446: ============================================================
2022-07-25 01:40:30,323: time cost, forward:0.12403500841800023, backward:0.09754583228084103, data cost:0.18804571681797183 
2022-07-25 01:40:30,324: ============================================================
2022-07-25 01:40:30,324: Epoch 14/25 Batch 1300/7662 eta: 10:17:33.533544	Training Loss1 4.0412 (3.7441)	Training Total_Loss 4.0412 (3.7441)	Training Prec@1 100.000 (99.894)	Training Prec@5 100.000 (99.968)	
2022-07-25 01:40:30,324: ============================================================
2022-07-25 01:41:11,184: time cost, forward:0.12401718033305911, backward:0.09756737201873365, data cost:0.18792918139137993 
2022-07-25 01:41:11,184: ============================================================
2022-07-25 01:41:11,185: Epoch 14/25 Batch 1400/7662 eta: 10:16:37.421531	Training Loss1 4.3810 (3.7636)	Training Total_Loss 4.3810 (3.7636)	Training Prec@1 100.000 (99.894)	Training Prec@5 100.000 (99.967)	
2022-07-25 01:41:11,185: ============================================================
2022-07-25 01:41:52,142: time cost, forward:0.12402237455712867, backward:0.0975861574825722, data cost:0.18787439160541028 
2022-07-25 01:41:52,142: ============================================================
2022-07-25 01:41:52,143: Epoch 14/25 Batch 1500/7662 eta: 10:17:24.409356	Training Loss1 4.2890 (3.7835)	Training Total_Loss 4.2890 (3.7835)	Training Prec@1 100.000 (99.893)	Training Prec@5 100.000 (99.967)	
2022-07-25 01:41:52,143: ============================================================
2022-07-25 01:42:33,110: time cost, forward:0.12401373718886766, backward:0.09760007715135757, data cost:0.1878489890346086 
2022-07-25 01:42:33,111: ============================================================
2022-07-25 01:42:33,111: Epoch 14/25 Batch 1600/7662 eta: 10:16:52.712938	Training Loss1 3.6423 (3.8015)	Training Total_Loss 3.6423 (3.8015)	Training Prec@1 100.000 (99.892)	Training Prec@5 100.000 (99.967)	
2022-07-25 01:42:33,111: ============================================================
2022-07-25 01:43:14,005: time cost, forward:0.12401933695303123, backward:0.09754800586015636, data cost:0.1878357656286912 
2022-07-25 01:43:14,005: ============================================================
2022-07-25 01:43:14,006: Epoch 14/25 Batch 1700/7662 eta: 10:15:05.588595	Training Loss1 3.7525 (3.8179)	Training Total_Loss 3.7525 (3.8179)	Training Prec@1 99.805 (99.890)	Training Prec@5 99.805 (99.966)	
2022-07-25 01:43:14,006: ============================================================
2022-07-25 01:43:54,842: time cost, forward:0.12403237614252621, backward:0.0974923367630183, data cost:0.18779215937259794 
2022-07-25 01:43:54,842: ============================================================
2022-07-25 01:43:54,842: Epoch 14/25 Batch 1800/7662 eta: 10:13:32.310882	Training Loss1 4.0069 (3.8370)	Training Total_Loss 4.0069 (3.8370)	Training Prec@1 99.805 (99.887)	Training Prec@5 100.000 (99.964)	
2022-07-25 01:43:54,842: ============================================================
2022-07-25 01:44:35,796: time cost, forward:0.12403672202252412, backward:0.09744479393820941, data cost:0.1878067567010752 
2022-07-25 01:44:35,796: ============================================================
2022-07-25 01:44:35,796: Epoch 14/25 Batch 1900/7662 eta: 10:14:36.740547	Training Loss1 4.3414 (3.8529)	Training Total_Loss 4.3414 (3.8529)	Training Prec@1 100.000 (99.885)	Training Prec@5 100.000 (99.963)	
2022-07-25 01:44:35,796: ============================================================
2022-07-25 01:45:16,653: time cost, forward:0.12402883775834145, backward:0.0974025441265631, data cost:0.18779515552186798 
2022-07-25 01:45:16,653: ============================================================
2022-07-25 01:45:16,653: Epoch 14/25 Batch 2000/7662 eta: 10:12:28.612161	Training Loss1 4.1449 (3.8718)	Training Total_Loss 4.1449 (3.8718)	Training Prec@1 99.609 (99.885)	Training Prec@5 99.805 (99.963)	
2022-07-25 01:45:16,653: ============================================================
2022-07-25 01:45:57,518: time cost, forward:0.12404165908573582, backward:0.09735795246413233, data cost:0.18776929577286328 
2022-07-25 01:45:57,518: ============================================================
2022-07-25 01:45:57,518: Epoch 14/25 Batch 2100/7662 eta: 10:11:55.632228	Training Loss1 4.2916 (3.8872)	Training Total_Loss 4.2916 (3.8872)	Training Prec@1 99.219 (99.885)	Training Prec@5 99.414 (99.963)	
2022-07-25 01:45:57,518: ============================================================
2022-07-25 01:46:38,384: time cost, forward:0.12405374343962276, backward:0.09731944477953874, data cost:0.18774424004739065 
2022-07-25 01:46:38,384: ============================================================
2022-07-25 01:46:38,384: Epoch 14/25 Batch 2200/7662 eta: 10:11:15.057699	Training Loss1 4.1773 (3.9040)	Training Total_Loss 4.1773 (3.9040)	Training Prec@1 100.000 (99.884)	Training Prec@5 100.000 (99.963)	
2022-07-25 01:46:38,384: ============================================================
2022-07-25 01:47:19,195: time cost, forward:0.12404794410914637, backward:0.09728377826735475, data cost:0.18771989390143834 
2022-07-25 01:47:19,196: ============================================================
2022-07-25 01:47:19,196: Epoch 14/25 Batch 2300/7662 eta: 10:09:45.487407	Training Loss1 4.4785 (3.9208)	Training Total_Loss 4.4785 (3.9208)	Training Prec@1 99.609 (99.882)	Training Prec@5 100.000 (99.962)	
2022-07-25 01:47:19,196: ============================================================
2022-07-25 01:47:59,958: time cost, forward:0.12404670761047974, backward:0.09725298658913997, data cost:0.18767091739967795 
2022-07-25 01:47:59,958: ============================================================
2022-07-25 01:47:59,958: Epoch 14/25 Batch 2400/7662 eta: 10:08:20.754835	Training Loss1 4.4343 (3.9364)	Training Total_Loss 4.4343 (3.9364)	Training Prec@1 100.000 (99.882)	Training Prec@5 100.000 (99.961)	
2022-07-25 01:47:59,958: ============================================================
2022-07-25 01:48:40,707: time cost, forward:0.1240535918690291, backward:0.09722437740278607, data cost:0.1876117814870394 
2022-07-25 01:48:40,707: ============================================================
2022-07-25 01:48:40,707: Epoch 14/25 Batch 2500/7662 eta: 10:07:28.135896	Training Loss1 4.0178 (3.9535)	Training Total_Loss 4.0178 (3.9535)	Training Prec@1 99.609 (99.881)	Training Prec@5 100.000 (99.961)	
2022-07-25 01:48:40,708: ============================================================
2022-07-25 01:49:21,516: time cost, forward:0.12406206314450917, backward:0.0971972238746869, data cost:0.18757515900315758 
2022-07-25 01:49:21,517: ============================================================
2022-07-25 01:49:21,517: Epoch 14/25 Batch 2600/7662 eta: 10:07:41.022599	Training Loss1 4.1464 (3.9695)	Training Total_Loss 4.1464 (3.9695)	Training Prec@1 100.000 (99.879)	Training Prec@5 100.000 (99.961)	
2022-07-25 01:49:21,517: ============================================================
2022-07-25 01:50:02,319: time cost, forward:0.12407299164004924, backward:0.0971760026345919, data cost:0.18753069142316525 
2022-07-25 01:50:02,320: ============================================================
2022-07-25 01:50:02,320: Epoch 14/25 Batch 2700/7662 eta: 10:06:54.793717	Training Loss1 4.3266 (3.9826)	Training Total_Loss 4.3266 (3.9826)	Training Prec@1 100.000 (99.878)	Training Prec@5 100.000 (99.960)	
2022-07-25 01:50:02,320: ============================================================
2022-07-25 01:50:43,153: time cost, forward:0.12408272484959598, backward:0.09715117527442815, data cost:0.18750567272672827 
2022-07-25 01:50:43,154: ============================================================
2022-07-25 01:50:43,154: Epoch 14/25 Batch 2800/7662 eta: 10:06:41.544212	Training Loss1 4.1861 (3.9960)	Training Total_Loss 4.1861 (3.9960)	Training Prec@1 100.000 (99.877)	Training Prec@5 100.000 (99.960)	
2022-07-25 01:50:43,154: ============================================================
2022-07-25 01:51:23,997: time cost, forward:0.12409944080327781, backward:0.09712865197193873, data cost:0.18747456799954865 
2022-07-25 01:51:23,997: ============================================================
2022-07-25 01:51:23,997: Epoch 14/25 Batch 2900/7662 eta: 10:06:08.823378	Training Loss1 4.2147 (4.0087)	Training Total_Loss 4.2147 (4.0087)	Training Prec@1 100.000 (99.876)	Training Prec@5 100.000 (99.960)	
2022-07-25 01:51:23,997: ============================================================
2022-07-25 01:52:04,873: time cost, forward:0.12411533224061952, backward:0.09710740701243574, data cost:0.1874638281889302 
2022-07-25 01:52:04,874: ============================================================
2022-07-25 01:52:04,874: Epoch 14/25 Batch 3000/7662 eta: 10:05:57.698680	Training Loss1 4.1643 (4.0212)	Training Total_Loss 4.1643 (4.0212)	Training Prec@1 100.000 (99.876)	Training Prec@5 100.000 (99.959)	
2022-07-25 01:52:04,874: ============================================================
2022-07-25 01:52:45,621: time cost, forward:0.12412060795771995, backward:0.09708892879812284, data cost:0.18741988766458811 
2022-07-25 01:52:45,621: ============================================================
2022-07-25 01:52:45,621: Epoch 14/25 Batch 3100/7662 eta: 10:03:22.110817	Training Loss1 4.9086 (4.0354)	Training Total_Loss 4.9086 (4.0354)	Training Prec@1 99.219 (99.876)	Training Prec@5 100.000 (99.959)	
2022-07-25 01:52:45,621: ============================================================
2022-07-25 01:53:26,431: time cost, forward:0.12413411999017084, backward:0.09707135668245097, data cost:0.18738623207977095 
2022-07-25 01:53:26,431: ============================================================
2022-07-25 01:53:26,431: Epoch 14/25 Batch 3200/7662 eta: 10:03:36.576316	Training Loss1 4.2465 (4.0464)	Training Total_Loss 4.2465 (4.0464)	Training Prec@1 99.414 (99.873)	Training Prec@5 99.805 (99.959)	
2022-07-25 01:53:26,431: ============================================================
2022-07-25 01:54:07,220: time cost, forward:0.12412932086041495, backward:0.0970543397126974, data cost:0.18736679267073877 
2022-07-25 01:54:07,221: ============================================================
2022-07-25 01:54:07,221: Epoch 14/25 Batch 3300/7662 eta: 10:02:38.115611	Training Loss1 4.5525 (4.0590)	Training Total_Loss 4.5525 (4.0590)	Training Prec@1 99.805 (99.872)	Training Prec@5 100.000 (99.958)	
2022-07-25 01:54:07,221: ============================================================
2022-07-25 01:54:47,957: time cost, forward:0.12412895297751633, backward:0.09703817715466671, data cost:0.18733215773936826 
2022-07-25 01:54:47,957: ============================================================
2022-07-25 01:54:47,958: Epoch 14/25 Batch 3400/7662 eta: 10:01:10.535263	Training Loss1 3.7912 (4.0707)	Training Total_Loss 3.7912 (4.0707)	Training Prec@1 100.000 (99.870)	Training Prec@5 100.000 (99.958)	
2022-07-25 01:54:47,958: ============================================================
2022-07-25 01:55:28,673: time cost, forward:0.12412967910832015, backward:0.09702146908459441, data cost:0.18729468085623427 
2022-07-25 01:55:28,673: ============================================================
2022-07-25 01:55:28,674: Epoch 14/25 Batch 3500/7662 eta: 10:00:11.082815	Training Loss1 4.7990 (4.0832)	Training Total_Loss 4.7990 (4.0832)	Training Prec@1 99.805 (99.869)	Training Prec@5 99.805 (99.957)	
2022-07-25 01:55:28,674: ============================================================
2022-07-25 01:56:09,371: time cost, forward:0.12413622002099481, backward:0.0970025717069388, data cost:0.18725144674328176 
2022-07-25 01:56:09,371: ============================================================
2022-07-25 01:56:09,371: Epoch 14/25 Batch 3600/7662 eta: 9:59:14.213739	Training Loss1 4.4780 (4.0968)	Training Total_Loss 4.4780 (4.0968)	Training Prec@1 99.609 (99.867)	Training Prec@5 99.805 (99.956)	
2022-07-25 01:56:09,371: ============================================================
2022-07-25 01:56:50,065: time cost, forward:0.12412430273903226, backward:0.09698635856987303, data cost:0.18722259234531274 
2022-07-25 01:56:50,065: ============================================================
2022-07-25 01:56:50,065: Epoch 14/25 Batch 3700/7662 eta: 9:58:30.685189	Training Loss1 4.3355 (4.1085)	Training Total_Loss 4.3355 (4.1085)	Training Prec@1 99.805 (99.865)	Training Prec@5 100.000 (99.955)	
2022-07-25 01:56:50,065: ============================================================
2022-07-25 01:57:30,739: time cost, forward:0.12411912424559969, backward:0.09697279869866829, data cost:0.18718482193491215 
2022-07-25 01:57:30,740: ============================================================
2022-07-25 01:57:30,740: Epoch 14/25 Batch 3800/7662 eta: 9:57:32.654861	Training Loss1 4.4214 (4.1213)	Training Total_Loss 4.4214 (4.1213)	Training Prec@1 99.805 (99.864)	Training Prec@5 100.000 (99.955)	
2022-07-25 01:57:30,740: ============================================================
2022-07-25 01:58:11,404: time cost, forward:0.12411626695699954, backward:0.09695967554159426, data cost:0.1871450257380824 
2022-07-25 01:58:11,404: ============================================================
2022-07-25 01:58:11,405: Epoch 14/25 Batch 3900/7662 eta: 9:56:43.190640	Training Loss1 4.7625 (4.1340)	Training Total_Loss 4.7625 (4.1340)	Training Prec@1 100.000 (99.863)	Training Prec@5 100.000 (99.954)	
2022-07-25 01:58:11,405: ============================================================
2022-07-25 01:58:52,076: time cost, forward:0.12411914291486767, backward:0.09694647860544925, data cost:0.1871042100153258 
2022-07-25 01:58:52,076: ============================================================
2022-07-25 01:58:52,077: Epoch 14/25 Batch 4000/7662 eta: 9:56:08.926598	Training Loss1 4.6390 (4.1460)	Training Total_Loss 4.6390 (4.1460)	Training Prec@1 99.805 (99.862)	Training Prec@5 99.805 (99.954)	
2022-07-25 01:58:52,077: ============================================================
2022-07-25 01:59:32,812: time cost, forward:0.12412001150763596, backward:0.09693506369505839, data cost:0.18708150710789684 
2022-07-25 01:59:32,813: ============================================================
2022-07-25 01:59:32,813: Epoch 14/25 Batch 4100/7662 eta: 9:56:24.834772	Training Loss1 4.5390 (4.1563)	Training Total_Loss 4.5390 (4.1563)	Training Prec@1 100.000 (99.860)	Training Prec@5 100.000 (99.954)	
2022-07-25 01:59:32,813: ============================================================
2022-07-25 02:00:13,515: time cost, forward:0.1241222938829219, backward:0.09692545810407842, data cost:0.18704926096050192 
2022-07-25 02:00:13,516: ============================================================
2022-07-25 02:00:13,516: Epoch 14/25 Batch 4200/7662 eta: 9:55:14.662896	Training Loss1 4.5560 (4.1659)	Training Total_Loss 4.5560 (4.1659)	Training Prec@1 100.000 (99.859)	Training Prec@5 100.000 (99.953)	
2022-07-25 02:00:13,516: ============================================================
2022-07-25 02:00:54,257: time cost, forward:0.12411814812977222, backward:0.09691380251005767, data cost:0.18703378120337177 
2022-07-25 02:00:54,257: ============================================================
2022-07-25 02:00:54,257: Epoch 14/25 Batch 4300/7662 eta: 9:55:07.832840	Training Loss1 4.3604 (4.1766)	Training Total_Loss 4.3604 (4.1766)	Training Prec@1 100.000 (99.858)	Training Prec@5 100.000 (99.953)	
2022-07-25 02:00:54,257: ============================================================
2022-07-25 02:01:35,003: time cost, forward:0.12412178340243274, backward:0.09690312988028035, data cost:0.18701214485749462 
2022-07-25 02:01:35,003: ============================================================
2022-07-25 02:01:35,004: Epoch 14/25 Batch 4400/7662 eta: 9:54:31.487955	Training Loss1 4.4909 (4.1870)	Training Total_Loss 4.4909 (4.1870)	Training Prec@1 100.000 (99.858)	Training Prec@5 100.000 (99.953)	
2022-07-25 02:01:35,004: ============================================================
2022-07-25 02:02:15,659: time cost, forward:0.12412035706361735, backward:0.0968926789681629, data cost:0.18697918243052086 
2022-07-25 02:02:15,659: ============================================================
2022-07-25 02:02:15,659: Epoch 14/25 Batch 4500/7662 eta: 9:52:31.126238	Training Loss1 4.6196 (4.1965)	Training Total_Loss 4.6196 (4.1965)	Training Prec@1 99.805 (99.857)	Training Prec@5 100.000 (99.953)	
2022-07-25 02:02:15,659: ============================================================
2022-07-25 02:02:56,293: time cost, forward:0.12411364966772204, backward:0.09688271644660301, data cost:0.18694873539409732 
2022-07-25 02:02:56,294: ============================================================
2022-07-25 02:02:56,294: Epoch 14/25 Batch 4600/7662 eta: 9:51:32.451237	Training Loss1 4.9890 (4.2075)	Training Total_Loss 4.9890 (4.2075)	Training Prec@1 99.609 (99.856)	Training Prec@5 100.000 (99.952)	
2022-07-25 02:02:56,294: ============================================================
2022-07-25 02:03:36,930: time cost, forward:0.12410574249572819, backward:0.09687258781689638, data cost:0.18692179882011406 
2022-07-25 02:03:36,930: ============================================================
2022-07-25 02:03:36,931: Epoch 14/25 Batch 4700/7662 eta: 9:50:53.519418	Training Loss1 5.0909 (4.2180)	Training Total_Loss 5.0909 (4.2180)	Training Prec@1 99.414 (99.854)	Training Prec@5 99.805 (99.952)	
2022-07-25 02:03:36,931: ============================================================
2022-07-25 02:04:17,561: time cost, forward:0.12409831181395226, backward:0.0968637478354077, data cost:0.1868938479629202 
2022-07-25 02:04:17,561: ============================================================
2022-07-25 02:04:17,562: Epoch 14/25 Batch 4800/7662 eta: 9:50:07.984301	Training Loss1 4.6026 (4.2279)	Training Total_Loss 4.6026 (4.2279)	Training Prec@1 99.805 (99.853)	Training Prec@5 99.805 (99.951)	
2022-07-25 02:04:17,562: ============================================================
2022-07-25 02:04:58,193: time cost, forward:0.12409000791902809, backward:0.09685553037577635, data cost:0.1868681375239182 
2022-07-25 02:04:58,193: ============================================================
2022-07-25 02:04:58,194: Epoch 14/25 Batch 4900/7662 eta: 9:49:28.090338	Training Loss1 4.5424 (4.2372)	Training Total_Loss 4.5424 (4.2372)	Training Prec@1 99.805 (99.853)	Training Prec@5 100.000 (99.951)	
2022-07-25 02:04:58,194: ============================================================
2022-07-25 02:05:38,827: time cost, forward:0.12408337671295551, backward:0.09684687086190431, data cost:0.18684321600190398 
2022-07-25 02:05:38,827: ============================================================
2022-07-25 02:05:38,828: Epoch 14/25 Batch 5000/7662 eta: 9:48:49.222027	Training Loss1 4.8471 (4.2470)	Training Total_Loss 4.8471 (4.2470)	Training Prec@1 99.609 (99.851)	Training Prec@5 99.609 (99.950)	
2022-07-25 02:05:38,828: ============================================================
2022-07-25 02:06:19,463: time cost, forward:0.12407742871750006, backward:0.09683811559376003, data cost:0.18681961626463203 
2022-07-25 02:06:19,463: ============================================================
2022-07-25 02:06:19,464: Epoch 14/25 Batch 5100/7662 eta: 9:48:10.282365	Training Loss1 4.3151 (4.2569)	Training Total_Loss 4.3151 (4.2569)	Training Prec@1 99.805 (99.850)	Training Prec@5 100.000 (99.949)	
2022-07-25 02:06:19,464: ============================================================
2022-07-25 02:07:00,116: time cost, forward:0.12407298862165982, backward:0.09683093742169561, data cost:0.18679780055752487 
2022-07-25 02:07:00,116: ============================================================
2022-07-25 02:07:00,116: Epoch 14/25 Batch 5200/7662 eta: 9:47:44.188499	Training Loss1 4.7643 (4.2667)	Training Total_Loss 4.7643 (4.2667)	Training Prec@1 100.000 (99.849)	Training Prec@5 100.000 (99.949)	
2022-07-25 02:07:00,116: ============================================================
2022-07-25 02:07:40,756: time cost, forward:0.12406829501755126, backward:0.09682322997240599, data cost:0.18677567666286476 
2022-07-25 02:07:40,757: ============================================================
2022-07-25 02:07:40,757: Epoch 14/25 Batch 5300/7662 eta: 9:46:52.928439	Training Loss1 4.5631 (4.2762)	Training Total_Loss 4.5631 (4.2762)	Training Prec@1 99.805 (99.847)	Training Prec@5 100.000 (99.949)	
2022-07-25 02:07:40,757: ============================================================
2022-07-25 02:08:21,391: time cost, forward:0.12406484284518404, backward:0.09681641558714102, data cost:0.18675181357413226 
2022-07-25 02:08:21,391: ============================================================
2022-07-25 02:08:21,391: Epoch 14/25 Batch 5400/7662 eta: 9:46:07.130112	Training Loss1 4.9656 (4.2851)	Training Total_Loss 4.9656 (4.2851)	Training Prec@1 99.609 (99.845)	Training Prec@5 100.000 (99.949)	
2022-07-25 02:08:21,391: ============================================================
2022-07-25 02:09:02,022: time cost, forward:0.12406012313455685, backward:0.0968099297296136, data cost:0.18672934318156778 
2022-07-25 02:09:02,023: ============================================================
2022-07-25 02:09:02,023: Epoch 14/25 Batch 5500/7662 eta: 9:45:23.913989	Training Loss1 4.4607 (4.2933)	Training Total_Loss 4.4607 (4.2933)	Training Prec@1 99.805 (99.844)	Training Prec@5 100.000 (99.948)	
2022-07-25 02:09:02,023: ============================================================
2022-07-25 02:09:42,648: time cost, forward:0.12405565581719435, backward:0.09680394995189134, data cost:0.18670616773307952 
2022-07-25 02:09:42,648: ============================================================
2022-07-25 02:09:42,648: Epoch 14/25 Batch 5600/7662 eta: 9:44:37.923048	Training Loss1 4.9152 (4.3022)	Training Total_Loss 4.9152 (4.3022)	Training Prec@1 99.805 (99.843)	Training Prec@5 100.000 (99.948)	
2022-07-25 02:09:42,648: ============================================================
2022-07-25 02:10:23,288: time cost, forward:0.12405505914984304, backward:0.09679892745472335, data cost:0.1866820115837262 
2022-07-25 02:10:23,288: ============================================================
2022-07-25 02:10:23,288: Epoch 14/25 Batch 5700/7662 eta: 9:44:10.237252	Training Loss1 4.9732 (4.3099)	Training Total_Loss 4.9732 (4.3099)	Training Prec@1 100.000 (99.842)	Training Prec@5 100.000 (99.947)	
2022-07-25 02:10:23,288: ============================================================
2022-07-25 02:11:03,950: time cost, forward:0.1240551396883198, backward:0.09679437403145237, data cost:0.18666090203022254 
2022-07-25 02:11:03,950: ============================================================
2022-07-25 02:11:03,950: Epoch 14/25 Batch 5800/7662 eta: 9:43:48.092127	Training Loss1 4.9315 (4.3185)	Training Total_Loss 4.9315 (4.3185)	Training Prec@1 99.609 (99.841)	Training Prec@5 99.805 (99.947)	
2022-07-25 02:11:03,950: ============================================================
2022-07-25 02:11:44,599: time cost, forward:0.1240536847707073, backward:0.09679008286006169, data cost:0.1866398719351743 
2022-07-25 02:11:44,599: ============================================================
2022-07-25 02:11:44,599: Epoch 14/25 Batch 5900/7662 eta: 9:42:56.449632	Training Loss1 4.9132 (4.3265)	Training Total_Loss 4.9132 (4.3265)	Training Prec@1 100.000 (99.840)	Training Prec@5 100.000 (99.947)	
2022-07-25 02:11:44,599: ============================================================
2022-07-25 02:12:25,287: time cost, forward:0.12405899103968754, backward:0.09678518511808243, data cost:0.18662042092394682 
2022-07-25 02:12:25,287: ============================================================
2022-07-25 02:12:25,288: Epoch 14/25 Batch 6000/7662 eta: 9:42:49.657291	Training Loss1 4.9286 (4.3348)	Training Total_Loss 4.9286 (4.3348)	Training Prec@1 99.805 (99.839)	Training Prec@5 100.000 (99.946)	
2022-07-25 02:12:25,288: ============================================================
2022-07-25 02:13:05,969: time cost, forward:0.12406182257850398, backward:0.09678075966003938, data cost:0.18660236601165756 
2022-07-25 02:13:05,969: ============================================================
2022-07-25 02:13:05,969: Epoch 14/25 Batch 6100/7662 eta: 9:42:02.999254	Training Loss1 4.2938 (4.3426)	Training Total_Loss 4.2938 (4.3426)	Training Prec@1 100.000 (99.838)	Training Prec@5 100.000 (99.946)	
2022-07-25 02:13:05,969: ============================================================
2022-07-25 02:13:46,659: time cost, forward:0.12405965204757344, backward:0.09677989457110894, data cost:0.1865878516309664 
2022-07-25 02:13:46,659: ============================================================
2022-07-25 02:13:46,660: Epoch 14/25 Batch 6200/7662 eta: 9:41:30.026721	Training Loss1 4.4792 (4.3506)	Training Total_Loss 4.4792 (4.3506)	Training Prec@1 99.609 (99.837)	Training Prec@5 100.000 (99.946)	
2022-07-25 02:13:46,660: ============================================================
2022-07-25 02:14:27,329: time cost, forward:0.12405640372285238, backward:0.09677831107310822, data cost:0.18657317197896275 
2022-07-25 02:14:27,329: ============================================================
2022-07-25 02:14:27,330: Epoch 14/25 Batch 6300/7662 eta: 9:40:31.946328	Training Loss1 4.5924 (4.3586)	Training Total_Loss 4.5924 (4.3586)	Training Prec@1 99.609 (99.836)	Training Prec@5 99.609 (99.945)	
2022-07-25 02:14:27,330: ============================================================
2022-07-25 02:15:07,981: time cost, forward:0.12404983202765409, backward:0.09677822207227166, data cost:0.1865586218451649 
2022-07-25 02:15:07,982: ============================================================
2022-07-25 02:15:07,982: Epoch 14/25 Batch 6400/7662 eta: 9:39:35.770082	Training Loss1 5.2173 (4.3662)	Training Total_Loss 5.2173 (4.3662)	Training Prec@1 100.000 (99.835)	Training Prec@5 100.000 (99.945)	
2022-07-25 02:15:07,982: ============================================================
2022-07-25 02:15:48,643: time cost, forward:0.12404690087437721, backward:0.09677613208909863, data cost:0.1865445591703087 
2022-07-25 02:15:48,643: ============================================================
2022-07-25 02:15:48,643: Epoch 14/25 Batch 6500/7662 eta: 9:39:03.247991	Training Loss1 4.9531 (4.3741)	Training Total_Loss 4.9531 (4.3741)	Training Prec@1 99.609 (99.834)	Training Prec@5 99.805 (99.945)	
2022-07-25 02:15:48,643: ============================================================
2022-07-25 02:16:29,297: time cost, forward:0.1240440153465034, backward:0.0967737877616414, data cost:0.18653030127426912 
2022-07-25 02:16:29,297: ============================================================
2022-07-25 02:16:29,297: Epoch 14/25 Batch 6600/7662 eta: 9:38:15.894868	Training Loss1 4.8473 (4.3816)	Training Total_Loss 4.8473 (4.3816)	Training Prec@1 99.805 (99.833)	Training Prec@5 100.000 (99.944)	
2022-07-25 02:16:29,297: ============================================================
2022-07-25 02:17:09,940: time cost, forward:0.12404070930492346, backward:0.0967716621914841, data cost:0.1865150703923313 
2022-07-25 02:17:09,940: ============================================================
2022-07-25 02:17:09,941: Epoch 14/25 Batch 6700/7662 eta: 9:37:26.647784	Training Loss1 5.0551 (4.3894)	Training Total_Loss 5.0551 (4.3894)	Training Prec@1 100.000 (99.832)	Training Prec@5 100.000 (99.944)	
2022-07-25 02:17:09,941: ============================================================
2022-07-25 02:17:50,576: time cost, forward:0.1240367300634192, backward:0.09676873072015309, data cost:0.18650108674884386 
2022-07-25 02:17:50,576: ============================================================
2022-07-25 02:17:50,576: Epoch 14/25 Batch 6800/7662 eta: 9:36:39.443163	Training Loss1 5.3234 (4.3963)	Training Total_Loss 5.3234 (4.3963)	Training Prec@1 99.414 (99.832)	Training Prec@5 99.805 (99.944)	
2022-07-25 02:17:50,577: ============================================================
2022-07-25 02:18:31,229: time cost, forward:0.12403335162117302, backward:0.0967667190592122, data cost:0.18648877059537305 
2022-07-25 02:18:31,230: ============================================================
2022-07-25 02:18:31,230: Epoch 14/25 Batch 6900/7662 eta: 9:36:13.558270	Training Loss1 5.2952 (4.4037)	Training Total_Loss 5.2952 (4.4037)	Training Prec@1 99.805 (99.831)	Training Prec@5 99.805 (99.943)	
2022-07-25 02:18:31,230: ============================================================
2022-07-25 02:19:11,873: time cost, forward:0.12402985845059732, backward:0.09676401992238647, data cost:0.1864760438447885 
2022-07-25 02:19:11,874: ============================================================
2022-07-25 02:19:11,874: Epoch 14/25 Batch 7000/7662 eta: 9:35:25.155614	Training Loss1 5.2926 (4.4101)	Training Total_Loss 5.2926 (4.4101)	Training Prec@1 99.414 (99.830)	Training Prec@5 99.805 (99.943)	
2022-07-25 02:19:11,874: ============================================================
2022-07-25 02:19:52,520: time cost, forward:0.12402526286810717, backward:0.09676334884472675, data cost:0.18646377566029007 
2022-07-25 02:19:52,521: ============================================================
2022-07-25 02:19:52,521: Epoch 14/25 Batch 7100/7662 eta: 9:34:46.962182	Training Loss1 4.6031 (4.4170)	Training Total_Loss 4.6031 (4.4170)	Training Prec@1 100.000 (99.828)	Training Prec@5 100.000 (99.942)	
2022-07-25 02:19:52,521: ============================================================
2022-07-25 02:20:33,170: time cost, forward:0.12402240318264426, backward:0.09676159870493725, data cost:0.18645168781479227 
2022-07-25 02:20:33,170: ============================================================
2022-07-25 02:20:33,170: Epoch 14/25 Batch 7200/7662 eta: 9:34:08.482936	Training Loss1 4.6063 (4.4246)	Training Total_Loss 4.6063 (4.4246)	Training Prec@1 100.000 (99.827)	Training Prec@5 100.000 (99.942)	
2022-07-25 02:20:33,170: ============================================================
2022-07-25 02:21:13,813: time cost, forward:0.12401919045469861, backward:0.09675937346325034, data cost:0.18643998443173912 
2022-07-25 02:21:13,813: ============================================================
2022-07-25 02:21:13,813: Epoch 14/25 Batch 7300/7662 eta: 9:33:22.230324	Training Loss1 5.1419 (4.4314)	Training Total_Loss 5.1419 (4.4314)	Training Prec@1 99.414 (99.825)	Training Prec@5 99.609 (99.942)	
2022-07-25 02:21:13,813: ============================================================
2022-07-25 02:21:54,461: time cost, forward:0.12401756494008845, backward:0.09675684927734012, data cost:0.18642801870476766 
2022-07-25 02:21:54,462: ============================================================
2022-07-25 02:21:54,462: Epoch 14/25 Batch 7400/7662 eta: 9:32:46.211607	Training Loss1 4.9240 (4.4384)	Training Total_Loss 4.9240 (4.4384)	Training Prec@1 100.000 (99.824)	Training Prec@5 100.000 (99.941)	
2022-07-25 02:21:54,462: ============================================================
2022-07-25 02:22:35,107: time cost, forward:0.12401516177778578, backward:0.09675530154381709, data cost:0.18641612020742576 
2022-07-25 02:22:35,107: ============================================================
2022-07-25 02:22:35,107: Epoch 14/25 Batch 7500/7662 eta: 9:32:03.220274	Training Loss1 5.8679 (4.4445)	Training Total_Loss 5.8679 (4.4445)	Training Prec@1 99.609 (99.823)	Training Prec@5 100.000 (99.941)	
2022-07-25 02:22:35,108: ============================================================
2022-07-25 02:23:15,763: time cost, forward:0.12401376684836171, backward:0.09675289502440668, data cost:0.18640570440391505 
2022-07-25 02:23:15,763: ============================================================
2022-07-25 02:23:15,763: Epoch 14/25 Batch 7600/7662 eta: 9:31:31.160539	Training Loss1 4.8449 (4.4515)	Training Total_Loss 4.8449 (4.4515)	Training Prec@1 99.609 (99.822)	Training Prec@5 100.000 (99.940)	
2022-07-25 02:23:15,763: ============================================================
2022-07-25 02:23:42,785: Epoch 14/25 Batch 7663/7662 eta: 9:31:05.547366	Training Loss1 4.6972 (4.4554)	Training Total_Loss 4.6972 (4.4554)	Training Prec@1 99.609 (99.821)	Training Prec@5 99.805 (99.940)	
2022-07-25 02:23:42,785: ============================================================
2022-07-25 02:24:25,623: time cost, forward:0.12389850616455078, backward:0.09650229203580606, data cost:0.20947141840000344 
2022-07-25 02:24:25,623: ============================================================
2022-07-25 02:24:25,624: Epoch 15/25 Batch 100/7662 eta: 10:00:29.853099	Training Loss1 3.4312 (3.5934)	Training Total_Loss 3.4312 (3.5934)	Training Prec@1 100.000 (99.888)	Training Prec@5 100.000 (99.966)	
2022-07-25 02:24:25,624: ============================================================
2022-07-25 02:25:06,279: time cost, forward:0.12376114591282217, backward:0.0965541822826443, data cost:0.19759191819770852 
2022-07-25 02:25:06,279: ============================================================
2022-07-25 02:25:06,279: Epoch 15/25 Batch 200/7662 eta: 9:29:44.336346	Training Loss1 3.6081 (3.5956)	Training Total_Loss 3.6081 (3.5956)	Training Prec@1 100.000 (99.888)	Training Prec@5 100.000 (99.967)	
2022-07-25 02:25:06,279: ============================================================
2022-07-25 02:25:46,961: time cost, forward:0.1238214698523582, backward:0.09656065044594449, data cost:0.19364801378154436 
2022-07-25 02:25:46,962: ============================================================
2022-07-25 02:25:46,962: Epoch 15/25 Batch 300/7662 eta: 9:29:26.637772	Training Loss1 3.8134 (3.6249)	Training Total_Loss 3.8134 (3.6249)	Training Prec@1 99.805 (99.892)	Training Prec@5 100.000 (99.969)	
2022-07-25 02:25:46,962: ============================================================
2022-07-25 02:26:27,660: time cost, forward:0.12385271724901702, backward:0.09656581066007304, data cost:0.19171829450698125 
2022-07-25 02:26:27,661: ============================================================
2022-07-25 02:26:27,662: Epoch 15/25 Batch 400/7662 eta: 9:29:00.228646	Training Loss1 3.9213 (3.6507)	Training Total_Loss 3.9213 (3.6507)	Training Prec@1 100.000 (99.897)	Training Prec@5 100.000 (99.972)	
2022-07-25 02:26:27,662: ============================================================
2022-07-25 02:27:08,387: time cost, forward:0.12389103778617415, backward:0.09654465419257094, data cost:0.19060504890396027 
2022-07-25 02:27:08,387: ============================================================
2022-07-25 02:27:08,387: Epoch 15/25 Batch 500/7662 eta: 9:28:41.008800	Training Loss1 3.5734 (3.6767)	Training Total_Loss 3.5734 (3.6767)	Training Prec@1 100.000 (99.901)	Training Prec@5 100.000 (99.973)	
2022-07-25 02:27:08,387: ============================================================
2022-07-25 02:27:49,017: time cost, forward:0.12387639930928888, backward:0.09653687357703512, data cost:0.18976586529726974 
2022-07-25 02:27:49,017: ============================================================
2022-07-25 02:27:49,018: Epoch 15/25 Batch 600/7662 eta: 9:26:40.882432	Training Loss1 4.1946 (3.6998)	Training Total_Loss 4.1946 (3.6998)	Training Prec@1 99.805 (99.899)	Training Prec@5 100.000 (99.971)	
2022-07-25 02:27:49,018: ============================================================
2022-07-25 02:28:29,702: time cost, forward:0.12390315004002213, backward:0.09651561868037277, data cost:0.1892015378021546 
2022-07-25 02:28:29,702: ============================================================
2022-07-25 02:28:29,703: Epoch 15/25 Batch 700/7662 eta: 9:26:45.573917	Training Loss1 4.1088 (3.7238)	Training Total_Loss 4.1088 (3.7238)	Training Prec@1 100.000 (99.900)	Training Prec@5 100.000 (99.970)	
2022-07-25 02:28:29,703: ============================================================
2022-07-25 02:29:10,415: time cost, forward:0.12393780972095246, backward:0.09649704036784261, data cost:0.18881126846628582 
2022-07-25 02:29:10,415: ============================================================
2022-07-25 02:29:10,415: Epoch 15/25 Batch 800/7662 eta: 9:26:28.122940	Training Loss1 4.0210 (3.7441)	Training Total_Loss 4.0210 (3.7441)	Training Prec@1 100.000 (99.900)	Training Prec@5 100.000 (99.970)	
2022-07-25 02:29:10,415: ============================================================
2022-07-25 02:29:51,099: time cost, forward:0.12393610416450543, backward:0.09649088517975091, data cost:0.18849293010783805 
2022-07-25 02:29:51,100: ============================================================
2022-07-25 02:29:51,100: Epoch 15/25 Batch 900/7662 eta: 9:25:24.164960	Training Loss1 3.2953 (3.7629)	Training Total_Loss 3.2953 (3.7629)	Training Prec@1 100.000 (99.899)	Training Prec@5 100.000 (99.969)	
2022-07-25 02:29:51,100: ============================================================
2022-07-25 02:30:31,764: time cost, forward:0.12392035499588028, backward:0.09648636177376106, data cost:0.18823463804609664 
2022-07-25 02:30:31,765: ============================================================
2022-07-25 02:30:31,765: Epoch 15/25 Batch 1000/7662 eta: 9:24:26.938197	Training Loss1 3.6186 (3.7834)	Training Total_Loss 3.6186 (3.7834)	Training Prec@1 100.000 (99.898)	Training Prec@5 100.000 (99.969)	
2022-07-25 02:30:31,765: ============================================================
2022-07-25 02:31:12,444: time cost, forward:0.12393371141206361, backward:0.09648752819960284, data cost:0.18800598518538192 
2022-07-25 02:31:12,444: ============================================================
2022-07-25 02:31:12,445: Epoch 15/25 Batch 1100/7662 eta: 9:23:58.777422	Training Loss1 4.0527 (3.8012)	Training Total_Loss 4.0527 (3.8012)	Training Prec@1 100.000 (99.899)	Training Prec@5 100.000 (99.969)	
2022-07-25 02:31:12,445: ============================================================
2022-07-25 02:31:53,069: time cost, forward:0.12392032275704963, backward:0.09648321766570969, data cost:0.18779951796320898 
2022-07-25 02:31:53,070: ============================================================
2022-07-25 02:31:53,070: Epoch 15/25 Batch 1200/7662 eta: 9:22:32.678324	Training Loss1 3.8345 (3.8201)	Training Total_Loss 3.8345 (3.8201)	Training Prec@1 100.000 (99.897)	Training Prec@5 100.000 (99.967)	
2022-07-25 02:31:53,070: ============================================================
2022-07-25 02:32:33,710: time cost, forward:0.12390268665721914, backward:0.09648218569707834, data cost:0.1876316215553313 
2022-07-25 02:32:33,710: ============================================================
2022-07-25 02:32:33,710: Epoch 15/25 Batch 1300/7662 eta: 9:22:04.489134	Training Loss1 4.0084 (3.8419)	Training Total_Loss 4.0084 (3.8419)	Training Prec@1 99.805 (99.895)	Training Prec@5 100.000 (99.967)	
2022-07-25 02:32:33,710: ============================================================
2022-07-25 02:33:14,433: time cost, forward:0.12390717410291409, backward:0.09647972742262016, data cost:0.1875363405130862 
2022-07-25 02:33:14,434: ============================================================
2022-07-25 02:33:14,434: Epoch 15/25 Batch 1400/7662 eta: 9:22:32.981824	Training Loss1 3.8906 (3.8602)	Training Total_Loss 3.8906 (3.8602)	Training Prec@1 100.000 (99.893)	Training Prec@5 100.000 (99.966)	
2022-07-25 02:33:14,434: ============================================================
2022-07-25 02:33:55,120: time cost, forward:0.12391143245964228, backward:0.09647509159446956, data cost:0.18743607694105438 
2022-07-25 02:33:55,121: ============================================================
2022-07-25 02:33:55,121: Epoch 15/25 Batch 1500/7662 eta: 9:21:22.019701	Training Loss1 4.0001 (3.8779)	Training Total_Loss 4.0001 (3.8779)	Training Prec@1 99.805 (99.889)	Training Prec@5 99.805 (99.965)	
2022-07-25 02:33:55,121: ============================================================
2022-07-25 02:34:35,774: time cost, forward:0.12390548874244904, backward:0.09647523335474144, data cost:0.18732368714962996 
2022-07-25 02:34:35,774: ============================================================
2022-07-25 02:34:35,774: Epoch 15/25 Batch 1600/7662 eta: 9:20:13.362361	Training Loss1 4.0537 (3.8944)	Training Total_Loss 4.0537 (3.8944)	Training Prec@1 99.609 (99.889)	Training Prec@5 100.000 (99.965)	
2022-07-25 02:34:35,774: ============================================================
2022-07-25 02:35:16,393: time cost, forward:0.1238984594350706, backward:0.0964724753729521, data cost:0.18721515070065953 
2022-07-25 02:35:16,393: ============================================================
2022-07-25 02:35:16,393: Epoch 15/25 Batch 1700/7662 eta: 9:19:04.640168	Training Loss1 4.1537 (3.9139)	Training Total_Loss 4.1537 (3.9139)	Training Prec@1 100.000 (99.886)	Training Prec@5 100.000 (99.964)	
2022-07-25 02:35:16,394: ============================================================
2022-07-25 02:35:57,015: time cost, forward:0.12389051271452381, backward:0.0964696335752783, data cost:0.1871220536732952 
2022-07-25 02:35:57,015: ============================================================
2022-07-25 02:35:57,015: Epoch 15/25 Batch 1800/7662 eta: 9:18:25.837954	Training Loss1 4.0936 (3.9310)	Training Total_Loss 4.0936 (3.9310)	Training Prec@1 100.000 (99.885)	Training Prec@5 100.000 (99.963)	
2022-07-25 02:35:57,015: ============================================================
2022-07-25 02:36:37,600: time cost, forward:0.12387405300592359, backward:0.09646850576395735, data cost:0.18702862236360426 
2022-07-25 02:36:37,601: ============================================================
2022-07-25 02:36:37,601: Epoch 15/25 Batch 1900/7662 eta: 9:17:15.746133	Training Loss1 3.8669 (3.9484)	Training Total_Loss 3.8669 (3.9484)	Training Prec@1 100.000 (99.883)	Training Prec@5 100.000 (99.962)	
2022-07-25 02:36:37,601: ============================================================
2022-07-25 02:37:18,218: time cost, forward:0.1238716477570145, backward:0.09646865533196133, data cost:0.18694645718015868 
2022-07-25 02:37:18,218: ============================================================
2022-07-25 02:37:18,218: Epoch 15/25 Batch 2000/7662 eta: 9:17:01.395277	Training Loss1 4.2150 (3.9638)	Training Total_Loss 4.2150 (3.9638)	Training Prec@1 99.805 (99.880)	Training Prec@5 100.000 (99.962)	
2022-07-25 02:37:18,218: ============================================================
2022-07-25 02:37:58,932: time cost, forward:0.12387486376496597, backward:0.09646451058644462, data cost:0.1869117324269346 
2022-07-25 02:37:58,932: ============================================================
2022-07-25 02:37:58,932: Epoch 15/25 Batch 2100/7662 eta: 9:17:40.000717	Training Loss1 4.5148 (3.9815)	Training Total_Loss 4.5148 (3.9815)	Training Prec@1 100.000 (99.878)	Training Prec@5 100.000 (99.961)	
2022-07-25 02:37:58,932: ============================================================
2022-07-25 02:38:39,684: time cost, forward:0.12389218942747164, backward:0.0964578110936448, data cost:0.18689640330531046 
2022-07-25 02:38:39,684: ============================================================
2022-07-25 02:38:39,685: Epoch 15/25 Batch 2200/7662 eta: 9:17:30.639389	Training Loss1 4.1935 (3.9977)	Training Total_Loss 4.1935 (3.9977)	Training Prec@1 99.805 (99.876)	Training Prec@5 100.000 (99.961)	
2022-07-25 02:38:39,685: ============================================================
2022-07-25 02:39:20,396: time cost, forward:0.12389657548221623, backward:0.09645570895629325, data cost:0.18686775852151932 
2022-07-25 02:39:20,397: ============================================================
2022-07-25 02:39:20,397: Epoch 15/25 Batch 2300/7662 eta: 9:16:17.179815	Training Loss1 4.3498 (4.0136)	Training Total_Loss 4.3498 (4.0136)	Training Prec@1 100.000 (99.874)	Training Prec@5 100.000 (99.961)	
2022-07-25 02:39:20,397: ============================================================
2022-07-25 02:40:01,069: time cost, forward:0.12388769822003395, backward:0.09645178487967729, data cost:0.18683351552103797 
2022-07-25 02:40:01,069: ============================================================
2022-07-25 02:40:01,069: Epoch 15/25 Batch 2400/7662 eta: 9:15:03.800813	Training Loss1 4.4652 (4.0288)	Training Total_Loss 4.4652 (4.0288)	Training Prec@1 99.609 (99.872)	Training Prec@5 99.805 (99.960)	
2022-07-25 02:40:01,069: ============================================================
2022-07-25 02:40:41,724: time cost, forward:0.12387437742201983, backward:0.0964484259623344, data cost:0.1868072543539205 
2022-07-25 02:40:41,725: ============================================================
2022-07-25 02:40:41,725: Epoch 15/25 Batch 2500/7662 eta: 9:14:09.257874	Training Loss1 4.2714 (4.0427)	Training Total_Loss 4.2714 (4.0427)	Training Prec@1 99.609 (99.871)	Training Prec@5 100.000 (99.960)	
2022-07-25 02:40:41,725: ============================================================
2022-07-25 02:41:22,396: time cost, forward:0.12387776127133107, backward:0.0964456832881339, data cost:0.1867667190291965 
2022-07-25 02:41:22,397: ============================================================
2022-07-25 02:41:22,397: Epoch 15/25 Batch 2600/7662 eta: 9:13:42.134632	Training Loss1 4.3730 (4.0571)	Training Total_Loss 4.3730 (4.0571)	Training Prec@1 99.805 (99.870)	Training Prec@5 100.000 (99.960)	
2022-07-25 02:41:22,397: ============================================================
2022-07-25 02:42:03,001: time cost, forward:0.12386752385128512, backward:0.09644199327523287, data cost:0.1867246979384477 
2022-07-25 02:42:03,001: ============================================================
2022-07-25 02:42:03,001: Epoch 15/25 Batch 2700/7662 eta: 9:12:06.357999	Training Loss1 4.9505 (4.0730)	Training Total_Loss 4.9505 (4.0730)	Training Prec@1 100.000 (99.868)	Training Prec@5 100.000 (99.959)	
2022-07-25 02:42:03,001: ============================================================
2022-07-25 02:42:43,621: time cost, forward:0.12386003721181986, backward:0.09644123851166916, data cost:0.18668589884998885 
2022-07-25 02:42:43,621: ============================================================
2022-07-25 02:42:43,621: Epoch 15/25 Batch 2800/7662 eta: 9:11:38.358761	Training Loss1 5.0111 (4.0875)	Training Total_Loss 5.0111 (4.0875)	Training Prec@1 99.609 (99.866)	Training Prec@5 100.000 (99.958)	
2022-07-25 02:42:43,621: ============================================================
2022-07-25 02:43:24,256: time cost, forward:0.12385317776769801, backward:0.09644455184357542, data cost:0.18665107376372334 
2022-07-25 02:43:24,256: ============================================================
2022-07-25 02:43:24,257: Epoch 15/25 Batch 2900/7662 eta: 9:11:10.180343	Training Loss1 4.6566 (4.1031)	Training Total_Loss 4.6566 (4.1031)	Training Prec@1 99.805 (99.865)	Training Prec@5 99.805 (99.958)	
2022-07-25 02:43:24,257: ============================================================
2022-07-25 02:44:04,920: time cost, forward:0.12385355913468145, backward:0.09644873025378373, data cost:0.1866204233001017 
2022-07-25 02:44:04,920: ============================================================
2022-07-25 02:44:04,921: Epoch 15/25 Batch 3000/7662 eta: 9:10:52.900350	Training Loss1 4.6315 (4.1168)	Training Total_Loss 4.6315 (4.1168)	Training Prec@1 99.805 (99.864)	Training Prec@5 100.000 (99.957)	
2022-07-25 02:44:04,921: ============================================================
2022-07-25 02:44:45,553: time cost, forward:0.12384860651767728, backward:0.09645119733524231, data cost:0.1865888031192963 
2022-07-25 02:44:45,554: ============================================================
2022-07-25 02:44:45,554: Epoch 15/25 Batch 3100/7662 eta: 9:09:47.256506	Training Loss1 4.7224 (4.1310)	Training Total_Loss 4.7224 (4.1310)	Training Prec@1 100.000 (99.862)	Training Prec@5 100.000 (99.957)	
2022-07-25 02:44:45,554: ============================================================
2022-07-25 02:45:26,186: time cost, forward:0.12384511143313828, backward:0.09645233231807135, data cost:0.18655900651121482 
2022-07-25 02:45:26,187: ============================================================
2022-07-25 02:45:26,187: Epoch 15/25 Batch 3200/7662 eta: 9:09:06.523161	Training Loss1 4.7729 (4.1435)	Training Total_Loss 4.7729 (4.1435)	Training Prec@1 100.000 (99.862)	Training Prec@5 100.000 (99.956)	
2022-07-25 02:45:26,187: ============================================================
2022-07-25 02:46:06,827: time cost, forward:0.12384181508298135, backward:0.09645467116710597, data cost:0.18653175634989488 
2022-07-25 02:46:06,828: ============================================================
2022-07-25 02:46:06,828: Epoch 15/25 Batch 3300/7662 eta: 9:08:32.337934	Training Loss1 4.8773 (4.1555)	Training Total_Loss 4.8773 (4.1555)	Training Prec@1 99.805 (99.860)	Training Prec@5 100.000 (99.956)	
2022-07-25 02:46:06,828: ============================================================
2022-07-25 02:46:47,470: time cost, forward:0.12383834962881324, backward:0.09645594467517733, data cost:0.18650712669509478 
2022-07-25 02:46:47,470: ============================================================
2022-07-25 02:46:47,470: Epoch 15/25 Batch 3400/7662 eta: 9:07:52.820954	Training Loss1 4.4309 (4.1687)	Training Total_Loss 4.4309 (4.1687)	Training Prec@1 99.805 (99.859)	Training Prec@5 100.000 (99.955)	
2022-07-25 02:46:47,470: ============================================================
2022-07-25 02:47:28,111: time cost, forward:0.12383574797583158, backward:0.09645901648921264, data cost:0.18648223217367002 
2022-07-25 02:47:28,111: ============================================================
2022-07-25 02:47:28,111: Epoch 15/25 Batch 3500/7662 eta: 9:07:11.030997	Training Loss1 3.9955 (4.1822)	Training Total_Loss 3.9955 (4.1822)	Training Prec@1 99.805 (99.858)	Training Prec@5 99.805 (99.954)	
2022-07-25 02:47:28,111: ============================================================
2022-07-25 02:48:08,766: time cost, forward:0.12383579777227106, backward:0.09646304702387813, data cost:0.18645787152955187 
2022-07-25 02:48:08,766: ============================================================
2022-07-25 02:48:08,766: Epoch 15/25 Batch 3600/7662 eta: 9:06:41.585717	Training Loss1 4.4080 (4.1952)	Training Total_Loss 4.4080 (4.1952)	Training Prec@1 100.000 (99.855)	Training Prec@5 100.000 (99.953)	
2022-07-25 02:48:08,766: ============================================================
2022-07-25 02:48:49,448: time cost, forward:0.12383676542079458, backward:0.096468204548308, data cost:0.18644031636551864 
2022-07-25 02:48:49,448: ============================================================
2022-07-25 02:48:49,448: Epoch 15/25 Batch 3700/7662 eta: 9:06:22.829600	Training Loss1 4.4310 (4.2065)	Training Total_Loss 4.4310 (4.2065)	Training Prec@1 99.805 (99.854)	Training Prec@5 99.805 (99.953)	
2022-07-25 02:48:49,448: ============================================================
2022-07-25 02:49:30,101: time cost, forward:0.12383645884329848, backward:0.09647025933984896, data cost:0.1864199089232041 
2022-07-25 02:49:30,101: ============================================================
2022-07-25 02:49:30,101: Epoch 15/25 Batch 3800/7662 eta: 9:05:18.448984	Training Loss1 4.2811 (4.2182)	Training Total_Loss 4.2811 (4.2182)	Training Prec@1 99.805 (99.854)	Training Prec@5 99.805 (99.953)	
2022-07-25 02:49:30,101: ============================================================
2022-07-25 02:50:10,744: time cost, forward:0.12383464435089182, backward:0.09647117158821773, data cost:0.18640122153142014 
2022-07-25 02:50:10,744: ============================================================
2022-07-25 02:50:10,744: Epoch 15/25 Batch 3900/7662 eta: 9:04:30.396259	Training Loss1 4.5893 (4.2290)	Training Total_Loss 4.5893 (4.2290)	Training Prec@1 99.414 (99.853)	Training Prec@5 99.414 (99.952)	
2022-07-25 02:50:10,744: ============================================================
2022-07-25 02:50:51,384: time cost, forward:0.12383255954979956, backward:0.09647216836223903, data cost:0.18638251769181996 
2022-07-25 02:50:51,384: ============================================================
2022-07-25 02:50:51,384: Epoch 15/25 Batch 4000/7662 eta: 9:03:46.977596	Training Loss1 4.6268 (4.2406)	Training Total_Loss 4.6268 (4.2406)	Training Prec@1 99.805 (99.852)	Training Prec@5 99.805 (99.951)	
2022-07-25 02:50:51,384: ============================================================
2022-07-25 02:51:32,036: time cost, forward:0.12383205264217827, backward:0.09647394104915935, data cost:0.1863654135029093 
2022-07-25 02:51:32,036: ============================================================
2022-07-25 02:51:32,036: Epoch 15/25 Batch 4100/7662 eta: 9:03:15.847257	Training Loss1 4.6503 (4.2514)	Training Total_Loss 4.6503 (4.2514)	Training Prec@1 100.000 (99.850)	Training Prec@5 100.000 (99.951)	
2022-07-25 02:51:32,036: ============================================================
2022-07-25 02:52:12,676: time cost, forward:0.12383045494968081, backward:0.09647476494269701, data cost:0.1863482895565192 
2022-07-25 02:52:12,676: ============================================================
2022-07-25 02:52:12,676: Epoch 15/25 Batch 4200/7662 eta: 9:02:26.003363	Training Loss1 4.5352 (4.2611)	Training Total_Loss 4.5352 (4.2611)	Training Prec@1 99.805 (99.849)	Training Prec@5 100.000 (99.950)	
2022-07-25 02:52:12,677: ============================================================
2022-07-25 02:52:53,329: time cost, forward:0.12383124971977637, backward:0.09647687780882043, data cost:0.1863313010194241 
2022-07-25 02:52:53,329: ============================================================
2022-07-25 02:52:53,329: Epoch 15/25 Batch 4300/7662 eta: 9:01:55.504529	Training Loss1 4.2186 (4.2710)	Training Total_Loss 4.2186 (4.2710)	Training Prec@1 99.805 (99.848)	Training Prec@5 100.000 (99.950)	
2022-07-25 02:52:53,330: ============================================================
2022-07-25 02:53:33,964: time cost, forward:0.12382836698483109, backward:0.09647743478095594, data cost:0.18631656133578456 
2022-07-25 02:53:33,964: ============================================================
2022-07-25 02:53:33,965: Epoch 15/25 Batch 4400/7662 eta: 9:01:00.537034	Training Loss1 5.0419 (4.2821)	Training Total_Loss 5.0419 (4.2821)	Training Prec@1 99.805 (99.847)	Training Prec@5 100.000 (99.949)	
2022-07-25 02:53:33,965: ============================================================
2022-07-25 02:54:14,669: time cost, forward:0.12382795164706469, backward:0.09649403192223802, data cost:0.18629891158581097 
2022-07-25 02:54:14,669: ============================================================
2022-07-25 02:54:14,669: Epoch 15/25 Batch 4500/7662 eta: 9:01:15.441638	Training Loss1 4.4221 (4.2928)	Training Total_Loss 4.4221 (4.2928)	Training Prec@1 100.000 (99.846)	Training Prec@5 100.000 (99.949)	
2022-07-25 02:54:14,669: ============================================================
2022-07-25 02:54:55,411: time cost, forward:0.12382589834984242, backward:0.09652050227335054, data cost:0.18628093718860325 
2022-07-25 02:54:55,412: ============================================================
2022-07-25 02:54:55,412: Epoch 15/25 Batch 4600/7662 eta: 9:01:04.776796	Training Loss1 4.7132 (4.3032)	Training Total_Loss 4.7132 (4.3032)	Training Prec@1 99.609 (99.845)	Training Prec@5 99.805 (99.949)	
2022-07-25 02:54:55,412: ============================================================
2022-07-25 02:55:36,145: time cost, forward:0.12382147783521745, backward:0.09654578423850155, data cost:0.18626390626821704 
2022-07-25 02:55:36,145: ============================================================
2022-07-25 02:55:36,145: Epoch 15/25 Batch 4700/7662 eta: 9:00:17.113972	Training Loss1 4.7294 (4.3125)	Training Total_Loss 4.7294 (4.3125)	Training Prec@1 99.805 (99.844)	Training Prec@5 100.000 (99.949)	
2022-07-25 02:55:36,146: ============================================================
2022-07-25 02:56:16,877: time cost, forward:0.12381735794940177, backward:0.09657092307055586, data cost:0.1862465285539478 
2022-07-25 02:56:16,878: ============================================================
2022-07-25 02:56:16,878: Epoch 15/25 Batch 4800/7662 eta: 8:59:35.431796	Training Loss1 5.0896 (4.3212)	Training Total_Loss 5.0896 (4.3212)	Training Prec@1 99.609 (99.843)	Training Prec@5 100.000 (99.949)	
2022-07-25 02:56:16,878: ============================================================
2022-07-25 02:56:57,482: time cost, forward:0.12381571763679675, backward:0.0965678510336906, data cost:0.18622957037088456 
2022-07-25 02:56:57,482: ============================================================
2022-07-25 02:56:57,482: Epoch 15/25 Batch 4900/7662 eta: 8:57:12.804931	Training Loss1 5.1298 (4.3312)	Training Total_Loss 5.1298 (4.3312)	Training Prec@1 99.609 (99.842)	Training Prec@5 99.805 (99.948)	
2022-07-25 02:56:57,482: ============================================================
2022-07-25 02:57:38,084: time cost, forward:0.1238126230134943, backward:0.09656463090980928, data cost:0.186214837724625 
2022-07-25 02:57:38,084: ============================================================
2022-07-25 02:57:38,084: Epoch 15/25 Batch 5000/7662 eta: 8:56:30.404835	Training Loss1 5.0737 (4.3413)	Training Total_Loss 5.0737 (4.3413)	Training Prec@1 99.805 (99.841)	Training Prec@5 100.000 (99.948)	
2022-07-25 02:57:38,084: ============================================================
2022-07-25 02:58:18,696: time cost, forward:0.12381082283419519, backward:0.0965612826802773, data cost:0.18620181387605608 
2022-07-25 02:58:18,696: ============================================================
2022-07-25 02:58:18,697: Epoch 15/25 Batch 5100/7662 eta: 8:55:58.269275	Training Loss1 5.0008 (4.3500)	Training Total_Loss 5.0008 (4.3500)	Training Prec@1 100.000 (99.840)	Training Prec@5 100.000 (99.948)	
2022-07-25 02:58:18,697: ============================================================
2022-07-25 02:58:59,316: time cost, forward:0.12380699025458798, backward:0.0965603920881004, data cost:0.18619027044204914 
2022-07-25 02:58:59,317: ============================================================
2022-07-25 02:58:59,317: Epoch 15/25 Batch 5200/7662 eta: 8:55:23.593134	Training Loss1 5.3225 (4.3596)	Training Total_Loss 5.3225 (4.3596)	Training Prec@1 99.414 (99.838)	Training Prec@5 99.609 (99.947)	
2022-07-25 02:58:59,317: ============================================================
2022-07-25 02:59:39,930: time cost, forward:0.12380503897262893, backward:0.09655850031259353, data cost:0.18617693121241138 
2022-07-25 02:59:39,930: ============================================================
2022-07-25 02:59:39,931: Epoch 15/25 Batch 5300/7662 eta: 8:54:38.043264	Training Loss1 4.7109 (4.3683)	Training Total_Loss 4.7109 (4.3683)	Training Prec@1 99.609 (99.838)	Training Prec@5 99.805 (99.947)	
2022-07-25 02:59:39,931: ============================================================
2022-07-25 03:00:20,547: time cost, forward:0.12380555793739598, backward:0.09655551482933851, data cost:0.18616371690001526 
2022-07-25 03:00:20,547: ============================================================
2022-07-25 03:00:20,547: Epoch 15/25 Batch 5400/7662 eta: 8:53:59.405664	Training Loss1 4.7563 (4.3767)	Training Total_Loss 4.7563 (4.3767)	Training Prec@1 100.000 (99.836)	Training Prec@5 100.000 (99.947)	
2022-07-25 03:00:20,547: ============================================================
2022-07-25 03:01:01,134: time cost, forward:0.12380214564733927, backward:0.0965525618811741, data cost:0.18614996864830805 
2022-07-25 03:01:01,134: ============================================================
2022-07-25 03:01:01,135: Epoch 15/25 Batch 5500/7662 eta: 8:52:56.138106	Training Loss1 4.6390 (4.3851)	Training Total_Loss 4.6390 (4.3851)	Training Prec@1 99.805 (99.835)	Training Prec@5 99.805 (99.947)	
2022-07-25 03:01:01,135: ============================================================
2022-07-25 03:01:41,736: time cost, forward:0.12379946085273591, backward:0.09655106695747137, data cost:0.18613744514459882 
2022-07-25 03:01:41,736: ============================================================
2022-07-25 03:01:41,736: Epoch 15/25 Batch 5600/7662 eta: 8:52:26.724021	Training Loss1 5.2289 (4.3944)	Training Total_Loss 5.2289 (4.3944)	Training Prec@1 100.000 (99.834)	Training Prec@5 100.000 (99.946)	
2022-07-25 03:01:41,736: ============================================================
2022-07-25 03:02:22,346: time cost, forward:0.12379885870315543, backward:0.09654837303944776, data cost:0.18612592181399698 
2022-07-25 03:02:22,346: ============================================================
2022-07-25 03:02:22,346: Epoch 15/25 Batch 5700/7662 eta: 8:51:52.271061	Training Loss1 4.4585 (4.4017)	Training Total_Loss 4.4585 (4.4017)	Training Prec@1 99.609 (99.833)	Training Prec@5 100.000 (99.946)	
2022-07-25 03:02:22,346: ============================================================
2022-07-25 03:03:02,954: time cost, forward:0.12379772787691087, backward:0.09654644300740718, data cost:0.1861142664453987 
2022-07-25 03:03:02,955: ============================================================
2022-07-25 03:03:02,955: Epoch 15/25 Batch 5800/7662 eta: 8:51:11.086784	Training Loss1 4.9245 (4.4085)	Training Total_Loss 4.9245 (4.4085)	Training Prec@1 99.414 (99.831)	Training Prec@5 99.805 (99.945)	
2022-07-25 03:03:02,955: ============================================================
2022-07-25 03:03:43,576: time cost, forward:0.1237976119000541, backward:0.0965444423279776, data cost:0.18610380952449992 
2022-07-25 03:03:43,576: ============================================================
2022-07-25 03:03:43,576: Epoch 15/25 Batch 5900/7662 eta: 8:50:40.386051	Training Loss1 4.5674 (4.4160)	Training Total_Loss 4.5674 (4.4160)	Training Prec@1 99.805 (99.830)	Training Prec@5 100.000 (99.945)	
2022-07-25 03:03:43,577: ============================================================
2022-07-25 03:04:24,185: time cost, forward:0.12379457931117945, backward:0.09654275153672463, data cost:0.1860944606757478 
2022-07-25 03:04:24,186: ============================================================
2022-07-25 03:04:24,186: Epoch 15/25 Batch 6000/7662 eta: 8:49:50.108249	Training Loss1 5.1462 (4.4243)	Training Total_Loss 5.1462 (4.4243)	Training Prec@1 100.000 (99.829)	Training Prec@5 100.000 (99.944)	
2022-07-25 03:04:24,186: ============================================================
2022-07-25 03:05:04,799: time cost, forward:0.12379394669789998, backward:0.09654019097457814, data cost:0.1860844820009761 
2022-07-25 03:05:04,799: ============================================================
2022-07-25 03:05:04,799: Epoch 15/25 Batch 6100/7662 eta: 8:49:12.914310	Training Loss1 4.9305 (4.4318)	Training Total_Loss 4.9305 (4.4318)	Training Prec@1 99.609 (99.827)	Training Prec@5 99.805 (99.944)	
2022-07-25 03:05:04,799: ============================================================
2022-07-25 03:05:45,375: time cost, forward:0.12379008251768021, backward:0.09653729595548012, data cost:0.18607260719732538 
2022-07-25 03:05:45,375: ============================================================
2022-07-25 03:05:45,376: Epoch 15/25 Batch 6200/7662 eta: 8:48:03.224276	Training Loss1 4.9796 (4.4395)	Training Total_Loss 4.9796 (4.4395)	Training Prec@1 99.805 (99.826)	Training Prec@5 100.000 (99.944)	
2022-07-25 03:05:45,376: ============================================================
2022-07-25 03:06:25,954: time cost, forward:0.12378710655016187, backward:0.09653486473481983, data cost:0.18606109868195117 
2022-07-25 03:06:25,954: ============================================================
2022-07-25 03:06:25,955: Epoch 15/25 Batch 6300/7662 eta: 8:47:24.728074	Training Loss1 5.4403 (4.4465)	Training Total_Loss 5.4403 (4.4465)	Training Prec@1 99.414 (99.825)	Training Prec@5 99.805 (99.943)	
2022-07-25 03:06:25,955: ============================================================
2022-07-25 03:07:06,558: time cost, forward:0.12378557847242538, backward:0.0965333933158859, data cost:0.18605157423250412 
2022-07-25 03:07:06,558: ============================================================
2022-07-25 03:07:06,558: Epoch 15/25 Batch 6400/7662 eta: 8:47:03.137660	Training Loss1 5.0304 (4.4535)	Training Total_Loss 5.0304 (4.4535)	Training Prec@1 99.609 (99.824)	Training Prec@5 100.000 (99.943)	
2022-07-25 03:07:06,558: ============================================================
2022-07-25 03:07:47,181: time cost, forward:0.12378711864790158, backward:0.09653132507334784, data cost:0.18604322264131756 
2022-07-25 03:07:47,181: ============================================================
2022-07-25 03:07:47,181: Epoch 15/25 Batch 6500/7662 eta: 8:46:37.984408	Training Loss1 5.0080 (4.4609)	Training Total_Loss 5.0080 (4.4609)	Training Prec@1 99.805 (99.822)	Training Prec@5 99.805 (99.942)	
2022-07-25 03:07:47,181: ============================================================
2022-07-25 03:08:27,792: time cost, forward:0.12378632218426945, backward:0.09652960399801686, data cost:0.1860353529751346 
2022-07-25 03:08:27,792: ============================================================
2022-07-25 03:08:27,792: Epoch 15/25 Batch 6600/7662 eta: 8:45:47.753165	Training Loss1 5.1443 (4.4683)	Training Total_Loss 5.1443 (4.4683)	Training Prec@1 100.000 (99.822)	Training Prec@5 100.000 (99.942)	
2022-07-25 03:08:27,792: ============================================================
2022-07-25 03:09:08,402: time cost, forward:0.12378452514281717, backward:0.09652783732251242, data cost:0.18602836486171798 
2022-07-25 03:09:08,402: ============================================================
2022-07-25 03:09:08,403: Epoch 15/25 Batch 6700/7662 eta: 8:45:06.826163	Training Loss1 5.5462 (4.4747)	Training Total_Loss 5.5462 (4.4747)	Training Prec@1 99.219 (99.820)	Training Prec@5 99.609 (99.941)	
2022-07-25 03:09:08,403: ============================================================
2022-07-25 03:09:49,000: time cost, forward:0.1237822589952817, backward:0.0965259814721764, data cost:0.18602060759693476 
2022-07-25 03:09:49,000: ============================================================
2022-07-25 03:09:49,000: Epoch 15/25 Batch 6800/7662 eta: 8:44:16.130695	Training Loss1 4.9884 (4.4816)	Training Total_Loss 4.9884 (4.4816)	Training Prec@1 99.609 (99.819)	Training Prec@5 100.000 (99.941)	
2022-07-25 03:09:49,000: ============================================================
2022-07-25 03:10:29,605: time cost, forward:0.12378210474709045, backward:0.09652437094519632, data cost:0.18601198368512092 
2022-07-25 03:10:29,606: ============================================================
2022-07-25 03:10:29,606: Epoch 15/25 Batch 6900/7662 eta: 8:43:41.848698	Training Loss1 5.3393 (4.4885)	Training Total_Loss 5.3393 (4.4885)	Training Prec@1 99.805 (99.818)	Training Prec@5 100.000 (99.941)	
2022-07-25 03:10:29,606: ============================================================
2022-07-25 03:11:10,217: time cost, forward:0.12378089920863677, backward:0.09652278743176515, data cost:0.18600547591317193 
2022-07-25 03:11:10,218: ============================================================
2022-07-25 03:11:10,218: Epoch 15/25 Batch 7000/7662 eta: 8:43:06.207881	Training Loss1 4.6161 (4.4945)	Training Total_Loss 4.6161 (4.4945)	Training Prec@1 100.000 (99.817)	Training Prec@5 100.000 (99.941)	
2022-07-25 03:11:10,218: ============================================================
2022-07-25 03:11:50,832: time cost, forward:0.12378008128186484, backward:0.09652152624343849, data cost:0.18599893516479268 
2022-07-25 03:11:50,833: ============================================================
2022-07-25 03:11:50,833: Epoch 15/25 Batch 7100/7662 eta: 8:42:27.909869	Training Loss1 4.7744 (4.5004)	Training Total_Loss 4.7744 (4.5004)	Training Prec@1 99.414 (99.816)	Training Prec@5 99.805 (99.940)	
2022-07-25 03:11:50,833: ============================================================
2022-07-25 03:12:31,479: time cost, forward:0.12378099123990144, backward:0.096522602277889, data cost:0.18599295212106748 
2022-07-25 03:12:31,479: ============================================================
2022-07-25 03:12:31,480: Epoch 15/25 Batch 7200/7662 eta: 8:42:11.808713	Training Loss1 4.2865 (4.5070)	Training Total_Loss 4.2865 (4.5070)	Training Prec@1 99.609 (99.815)	Training Prec@5 100.000 (99.939)	
2022-07-25 03:12:31,480: ============================================================
2022-07-25 03:13:12,152: time cost, forward:0.12378380027172059, backward:0.09652345760960598, data cost:0.18598879512196811 
2022-07-25 03:13:12,152: ============================================================
2022-07-25 03:13:12,152: Epoch 15/25 Batch 7300/7662 eta: 8:41:50.770001	Training Loss1 5.3050 (4.5124)	Training Total_Loss 5.3050 (4.5124)	Training Prec@1 99.609 (99.814)	Training Prec@5 100.000 (99.939)	
2022-07-25 03:13:12,152: ============================================================
2022-07-25 03:13:52,808: time cost, forward:0.12378416523480354, backward:0.09652463802374252, data cost:0.18598491121811034 
2022-07-25 03:13:52,809: ============================================================
2022-07-25 03:13:52,809: Epoch 15/25 Batch 7400/7662 eta: 8:40:58.223842	Training Loss1 5.2299 (4.5184)	Training Total_Loss 5.2299 (4.5184)	Training Prec@1 99.414 (99.813)	Training Prec@5 99.805 (99.939)	
2022-07-25 03:13:52,809: ============================================================
2022-07-25 03:14:33,447: time cost, forward:0.12378291944485217, backward:0.09652672695913288, data cost:0.1859791890861734 
2022-07-25 03:14:33,447: ============================================================
2022-07-25 03:14:33,448: Epoch 15/25 Batch 7500/7662 eta: 8:40:03.612844	Training Loss1 4.9934 (4.5244)	Training Total_Loss 4.9934 (4.5244)	Training Prec@1 100.000 (99.813)	Training Prec@5 100.000 (99.939)	
2022-07-25 03:14:33,448: ============================================================
2022-07-25 03:15:14,165: time cost, forward:0.12379103200124085, backward:0.09652629747627942, data cost:0.18597731171101076 
2022-07-25 03:15:14,165: ============================================================
2022-07-25 03:15:14,165: Epoch 15/25 Batch 7600/7662 eta: 8:40:23.708566	Training Loss1 5.3673 (4.5296)	Training Total_Loss 5.3673 (4.5296)	Training Prec@1 99.805 (99.811)	Training Prec@5 99.805 (99.938)	
2022-07-25 03:15:14,166: ============================================================
2022-07-25 03:15:41,352: Epoch 15/25 Batch 7663/7662 eta: 8:39:58.056288	Training Loss1 5.2715 (4.5331)	Training Total_Loss 5.2715 (4.5331)	Training Prec@1 99.609 (99.811)	Training Prec@5 99.805 (99.938)	
2022-07-25 03:15:41,353: ============================================================
2022-07-25 03:15:41,358: Save Checkpoint...
2022-07-25 03:15:41,358: ============================================================
2022-07-25 03:15:44,485: Save done!
2022-07-25 03:15:44,485: ============================================================
2022-07-25 03:16:26,498: time cost, forward:0.12414004826786543, backward:0.09644631424335519, data cost:0.20098217569216334 
2022-07-25 03:16:26,498: ============================================================
2022-07-25 03:16:26,499: Epoch 16/25 Batch 100/7662 eta: 8:55:43.029627	Training Loss1 3.7695 (3.6109)	Training Total_Loss 3.7695 (3.6109)	Training Prec@1 99.805 (99.917)	Training Prec@5 100.000 (99.974)	
2022-07-25 03:16:26,499: ============================================================
2022-07-25 03:17:07,461: time cost, forward:0.1246645642285371, backward:0.09645580286955714, data cost:0.19414832484183 
2022-07-25 03:17:07,462: ============================================================
2022-07-25 03:17:07,462: Epoch 16/25 Batch 200/7662 eta: 8:41:44.477850	Training Loss1 3.8753 (3.6444)	Training Total_Loss 3.8753 (3.6444)	Training Prec@1 100.000 (99.911)	Training Prec@5 100.000 (99.975)	
2022-07-25 03:17:07,462: ============================================================
2022-07-25 03:17:48,490: time cost, forward:0.12488384470094406, backward:0.09643611461422515, data cost:0.19208532671465922 
2022-07-25 03:17:48,490: ============================================================
2022-07-25 03:17:48,490: Epoch 16/25 Batch 300/7662 eta: 8:41:53.401942	Training Loss1 3.6992 (3.6531)	Training Total_Loss 3.6992 (3.6531)	Training Prec@1 99.805 (99.907)	Training Prec@5 100.000 (99.967)	
2022-07-25 03:17:48,490: ============================================================
2022-07-25 03:18:29,514: time cost, forward:0.12499634902877617, backward:0.09642089996720317, data cost:0.1910141882741063 
2022-07-25 03:18:29,514: ============================================================
2022-07-25 03:18:29,514: Epoch 16/25 Batch 400/7662 eta: 8:41:08.873002	Training Loss1 4.3190 (3.6815)	Training Total_Loss 4.3190 (3.6815)	Training Prec@1 99.805 (99.906)	Training Prec@5 100.000 (99.967)	
2022-07-25 03:18:29,514: ============================================================
2022-07-25 03:19:10,508: time cost, forward:0.1249947705584203, backward:0.09641308583811911, data cost:0.1903806764759377 
2022-07-25 03:19:10,508: ============================================================
2022-07-25 03:19:10,508: Epoch 16/25 Batch 500/7662 eta: 8:40:05.173197	Training Loss1 4.0435 (3.7038)	Training Total_Loss 4.0435 (3.7038)	Training Prec@1 100.000 (99.904)	Training Prec@5 100.000 (99.968)	
2022-07-25 03:19:10,509: ============================================================
2022-07-25 03:19:51,400: time cost, forward:0.12498038678814055, backward:0.09642363629476455, data cost:0.18980488713476215 
2022-07-25 03:19:51,400: ============================================================
2022-07-25 03:19:51,400: Epoch 16/25 Batch 600/7662 eta: 8:38:06.391834	Training Loss1 3.9913 (3.7232)	Training Total_Loss 3.9913 (3.7232)	Training Prec@1 100.000 (99.906)	Training Prec@5 100.000 (99.968)	
2022-07-25 03:19:51,400: ============================================================
2022-07-25 03:20:32,219: time cost, forward:0.12488291226060946, backward:0.09644673788155268, data cost:0.18936188879272287 
2022-07-25 03:20:32,219: ============================================================
2022-07-25 03:20:32,219: Epoch 16/25 Batch 700/7662 eta: 8:36:30.231730	Training Loss1 3.8215 (3.7496)	Training Total_Loss 3.8215 (3.7496)	Training Prec@1 99.805 (99.901)	Training Prec@5 100.000 (99.966)	
2022-07-25 03:20:32,220: ============================================================
2022-07-25 03:21:13,041: time cost, forward:0.12481476398224527, backward:0.09646166310889252, data cost:0.18901526614631967 
2022-07-25 03:21:13,041: ============================================================
2022-07-25 03:21:13,042: Epoch 16/25 Batch 800/7662 eta: 8:35:51.797777	Training Loss1 3.7994 (3.7726)	Training Total_Loss 3.7994 (3.7726)	Training Prec@1 99.805 (99.900)	Training Prec@5 100.000 (99.965)	
2022-07-25 03:21:13,042: ============================================================
2022-07-25 03:21:53,927: time cost, forward:0.1248216101271955, backward:0.09646717751516781, data cost:0.1887660026550293 
2022-07-25 03:21:53,927: ============================================================
2022-07-25 03:21:53,928: Epoch 16/25 Batch 900/7662 eta: 8:35:59.256224	Training Loss1 3.6641 (3.7941)	Training Total_Loss 3.6641 (3.7941)	Training Prec@1 100.000 (99.897)	Training Prec@5 100.000 (99.962)	
2022-07-25 03:21:53,928: ============================================================
2022-07-25 03:22:34,816: time cost, forward:0.12481889352426156, backward:0.09647185928948052, data cost:0.18856639785690232 
2022-07-25 03:22:34,817: ============================================================
2022-07-25 03:22:34,817: Epoch 16/25 Batch 1000/7662 eta: 8:35:20.880867	Training Loss1 4.1445 (3.8135)	Training Total_Loss 4.1445 (3.8135)	Training Prec@1 99.805 (99.896)	Training Prec@5 99.805 (99.962)	
2022-07-25 03:22:34,817: ============================================================
2022-07-25 03:23:15,617: time cost, forward:0.12475936601550282, backward:0.09647992418721332, data cost:0.18837936820497939 
2022-07-25 03:23:15,617: ============================================================
2022-07-25 03:23:15,617: Epoch 16/25 Batch 1100/7662 eta: 8:33:32.808699	Training Loss1 4.3599 (3.8306)	Training Total_Loss 4.3599 (3.8306)	Training Prec@1 100.000 (99.895)	Training Prec@5 100.000 (99.962)	
2022-07-25 03:23:15,617: ============================================================
2022-07-25 03:23:56,318: time cost, forward:0.12470585391161539, backward:0.09648154257137244, data cost:0.18816481320633305 
2022-07-25 03:23:56,318: ============================================================
2022-07-25 03:23:56,318: Epoch 16/25 Batch 1200/7662 eta: 8:31:37.146146	Training Loss1 3.9269 (3.8534)	Training Total_Loss 3.9269 (3.8534)	Training Prec@1 100.000 (99.893)	Training Prec@5 100.000 (99.961)	
2022-07-25 03:23:56,318: ============================================================
2022-07-25 03:24:36,989: time cost, forward:0.12463360717426913, backward:0.09648998560035477, data cost:0.18797830199167487 
2022-07-25 03:24:36,989: ============================================================
2022-07-25 03:24:36,989: Epoch 16/25 Batch 1300/7662 eta: 8:30:33.786314	Training Loss1 4.4346 (3.8763)	Training Total_Loss 4.4346 (3.8763)	Training Prec@1 100.000 (99.892)	Training Prec@5 100.000 (99.962)	
2022-07-25 03:24:36,989: ============================================================
2022-07-25 03:25:17,666: time cost, forward:0.12458493182964202, backward:0.09648903460908226, data cost:0.18781837418387837 
2022-07-25 03:25:17,666: ============================================================
2022-07-25 03:25:17,667: Epoch 16/25 Batch 1400/7662 eta: 8:29:57.947138	Training Loss1 4.2604 (3.8955)	Training Total_Loss 4.2604 (3.8955)	Training Prec@1 99.805 (99.891)	Training Prec@5 99.805 (99.961)	
2022-07-25 03:25:17,667: ============================================================
2022-07-25 03:25:58,321: time cost, forward:0.12453491485778931, backward:0.09649494427534006, data cost:0.18766606752676834 
2022-07-25 03:25:58,321: ============================================================
2022-07-25 03:25:58,322: Epoch 16/25 Batch 1500/7662 eta: 8:29:00.364798	Training Loss1 4.0901 (3.9154)	Training Total_Loss 4.0901 (3.9154)	Training Prec@1 99.805 (99.887)	Training Prec@5 100.000 (99.960)	
2022-07-25 03:25:58,322: ============================================================
2022-07-25 03:26:39,017: time cost, forward:0.124508039439895, backward:0.09649989171054976, data cost:0.1875414870693357 
2022-07-25 03:26:39,018: ============================================================
2022-07-25 03:26:39,018: Epoch 16/25 Batch 1600/7662 eta: 8:28:50.685927	Training Loss1 4.0795 (3.9320)	Training Total_Loss 4.0795 (3.9320)	Training Prec@1 100.000 (99.886)	Training Prec@5 100.000 (99.962)	
2022-07-25 03:26:39,018: ============================================================
2022-07-25 03:27:19,733: time cost, forward:0.12449591506432617, backward:0.0965021060732549, data cost:0.18743269088480177 
2022-07-25 03:27:19,733: ============================================================
2022-07-25 03:27:19,733: Epoch 16/25 Batch 1700/7662 eta: 8:28:24.403932	Training Loss1 4.0867 (3.9503)	Training Total_Loss 4.0867 (3.9503)	Training Prec@1 100.000 (99.883)	Training Prec@5 100.000 (99.960)	
2022-07-25 03:27:19,733: ============================================================
2022-07-25 03:28:00,408: time cost, forward:0.12446839866404934, backward:0.09650001133594863, data cost:0.18733543207275663 
2022-07-25 03:28:00,408: ============================================================
2022-07-25 03:28:00,408: Epoch 16/25 Batch 1800/7662 eta: 8:27:13.449385	Training Loss1 4.3611 (3.9684)	Training Total_Loss 4.3611 (3.9684)	Training Prec@1 100.000 (99.882)	Training Prec@5 100.000 (99.959)	
2022-07-25 03:28:00,408: ============================================================
2022-07-25 03:28:41,173: time cost, forward:0.12445788373439923, backward:0.09649935906155603, data cost:0.1872816365790907 
2022-07-25 03:28:41,173: ============================================================
2022-07-25 03:28:41,174: Epoch 16/25 Batch 1900/7662 eta: 8:27:40.382537	Training Loss1 4.7217 (3.9866)	Training Total_Loss 4.7217 (3.9866)	Training Prec@1 100.000 (99.881)	Training Prec@5 100.000 (99.959)	
2022-07-25 03:28:41,174: ============================================================
2022-07-25 03:29:21,904: time cost, forward:0.12444924580687103, backward:0.09650002687558226, data cost:0.18721328156181669 
2022-07-25 03:29:21,905: ============================================================
2022-07-25 03:29:21,905: Epoch 16/25 Batch 2000/7662 eta: 8:26:34.109686	Training Loss1 4.5332 (4.0025)	Training Total_Loss 4.5332 (4.0025)	Training Prec@1 99.609 (99.878)	Training Prec@5 100.000 (99.959)	
2022-07-25 03:29:21,905: ============================================================
2022-07-25 03:30:02,677: time cost, forward:0.12443965420716147, backward:0.09650039843231681, data cost:0.18716843574600256 
2022-07-25 03:30:02,677: ============================================================
2022-07-25 03:30:02,678: Epoch 16/25 Batch 2100/7662 eta: 8:26:24.125745	Training Loss1 3.8202 (4.0211)	Training Total_Loss 3.8202 (4.0211)	Training Prec@1 100.000 (99.877)	Training Prec@5 100.000 (99.958)	
2022-07-25 03:30:02,678: ============================================================
2022-07-25 03:30:43,370: time cost, forward:0.12442035033194354, backward:0.09650094284692533, data cost:0.18710115162986904 
2022-07-25 03:30:43,370: ============================================================
2022-07-25 03:30:43,371: Epoch 16/25 Batch 2200/7662 eta: 8:24:44.153912	Training Loss1 4.6031 (4.0364)	Training Total_Loss 4.6031 (4.0364)	Training Prec@1 99.609 (99.876)	Training Prec@5 100.000 (99.958)	
2022-07-25 03:30:43,371: ============================================================
2022-07-25 03:31:24,105: time cost, forward:0.12440653892639877, backward:0.09650338043488332, data cost:0.1870571448005454 
2022-07-25 03:31:24,105: ============================================================
2022-07-25 03:31:24,105: Epoch 16/25 Batch 2300/7662 eta: 8:24:34.556499	Training Loss1 4.6120 (4.0526)	Training Total_Loss 4.6120 (4.0526)	Training Prec@1 99.609 (99.874)	Training Prec@5 100.000 (99.958)	
2022-07-25 03:31:24,105: ============================================================
2022-07-25 03:32:04,837: time cost, forward:0.12439681848619023, backward:0.09650296407622465, data cost:0.1870161252699578 
2022-07-25 03:32:04,837: ============================================================
2022-07-25 03:32:04,837: Epoch 16/25 Batch 2400/7662 eta: 8:23:51.746113	Training Loss1 4.3309 (4.0681)	Training Total_Loss 4.3309 (4.0681)	Training Prec@1 99.609 (99.874)	Training Prec@5 100.000 (99.958)	
2022-07-25 03:32:04,838: ============================================================
2022-07-25 03:32:45,578: time cost, forward:0.12439038191570574, backward:0.0965040423670689, data cost:0.18697763500618142 
2022-07-25 03:32:45,578: ============================================================
2022-07-25 03:32:45,578: Epoch 16/25 Batch 2500/7662 eta: 8:23:17.446238	Training Loss1 3.6166 (4.0824)	Training Total_Loss 3.6166 (4.0824)	Training Prec@1 100.000 (99.873)	Training Prec@5 100.000 (99.957)	
2022-07-25 03:32:45,578: ============================================================
2022-07-25 03:33:26,333: time cost, forward:0.12439106986723573, backward:0.0965027195437682, data cost:0.18694334187935113 
2022-07-25 03:33:26,333: ============================================================
2022-07-25 03:33:26,333: Epoch 16/25 Batch 2600/7662 eta: 8:22:47.445703	Training Loss1 4.0836 (4.0978)	Training Total_Loss 4.0836 (4.0978)	Training Prec@1 99.805 (99.871)	Training Prec@5 100.000 (99.957)	
2022-07-25 03:33:26,334: ============================================================
2022-07-25 03:34:07,071: time cost, forward:0.12438980991551504, backward:0.09650383811829133, data cost:0.18690535482453965 
2022-07-25 03:34:07,072: ============================================================
2022-07-25 03:34:07,072: Epoch 16/25 Batch 2700/7662 eta: 8:21:54.113864	Training Loss1 4.4104 (4.1107)	Training Total_Loss 4.4104 (4.1107)	Training Prec@1 100.000 (99.869)	Training Prec@5 100.000 (99.956)	
2022-07-25 03:34:07,072: ============================================================
2022-07-25 03:34:47,839: time cost, forward:0.12438562683822343, backward:0.09650326678053572, data cost:0.18688475842900087 
2022-07-25 03:34:47,839: ============================================================
2022-07-25 03:34:47,839: Epoch 16/25 Batch 2800/7662 eta: 8:21:34.883365	Training Loss1 4.1966 (4.1255)	Training Total_Loss 4.1966 (4.1255)	Training Prec@1 99.805 (99.868)	Training Prec@5 100.000 (99.955)	
2022-07-25 03:34:47,839: ============================================================
2022-07-25 03:35:28,524: time cost, forward:0.12437269366087689, backward:0.09650499551778993, data cost:0.1868406092968428 
2022-07-25 03:35:28,524: ============================================================
2022-07-25 03:35:28,524: Epoch 16/25 Batch 2900/7662 eta: 8:19:53.492157	Training Loss1 4.5025 (4.1382)	Training Total_Loss 4.5025 (4.1382)	Training Prec@1 99.414 (99.866)	Training Prec@5 100.000 (99.955)	
2022-07-25 03:35:28,524: ============================================================
2022-07-25 03:36:09,253: time cost, forward:0.12436491181429882, backward:0.09650556037091303, data cost:0.18681411204158405 
2022-07-25 03:36:09,254: ============================================================
2022-07-25 03:36:09,254: Epoch 16/25 Batch 3000/7662 eta: 8:19:45.556509	Training Loss1 4.9040 (4.1501)	Training Total_Loss 4.9040 (4.1501)	Training Prec@1 99.609 (99.865)	Training Prec@5 100.000 (99.954)	
2022-07-25 03:36:09,254: ============================================================
2022-07-25 03:36:49,905: time cost, forward:0.12434947702260739, backward:0.09650488129043702, data cost:0.18677344072938312 
2022-07-25 03:36:49,906: ============================================================
2022-07-25 03:36:49,906: Epoch 16/25 Batch 3100/7662 eta: 8:18:07.607538	Training Loss1 4.5225 (4.1623)	Training Total_Loss 4.5225 (4.1623)	Training Prec@1 100.000 (99.865)	Training Prec@5 100.000 (99.955)	
2022-07-25 03:36:49,906: ============================================================
2022-07-25 03:37:30,546: time cost, forward:0.12433127948514146, backward:0.09650730035870698, data cost:0.1867330854629941 
2022-07-25 03:37:30,547: ============================================================
2022-07-25 03:37:30,547: Epoch 16/25 Batch 3200/7662 eta: 8:17:19.147317	Training Loss1 4.5241 (4.1739)	Training Total_Loss 4.5241 (4.1739)	Training Prec@1 99.805 (99.864)	Training Prec@5 99.805 (99.954)	
2022-07-25 03:37:30,547: ============================================================
2022-07-25 03:38:11,220: time cost, forward:0.12432059471301507, backward:0.0965097937738581, data cost:0.18669696510398195 
2022-07-25 03:38:11,220: ============================================================
2022-07-25 03:38:11,220: Epoch 16/25 Batch 3300/7662 eta: 8:17:02.057902	Training Loss1 4.8843 (4.1877)	Training Total_Loss 4.8843 (4.1877)	Training Prec@1 100.000 (99.862)	Training Prec@5 100.000 (99.953)	
2022-07-25 03:38:11,220: ============================================================
2022-07-25 03:38:51,908: time cost, forward:0.12431046955022225, backward:0.09651183268363843, data cost:0.1866684458682943 
2022-07-25 03:38:51,909: ============================================================
2022-07-25 03:38:51,909: Epoch 16/25 Batch 3400/7662 eta: 8:16:32.642623	Training Loss1 4.8931 (4.2000)	Training Total_Loss 4.8931 (4.2000)	Training Prec@1 100.000 (99.860)	Training Prec@5 100.000 (99.952)	
2022-07-25 03:38:51,909: ============================================================
2022-07-25 03:39:32,655: time cost, forward:0.12431313692416147, backward:0.09651131335583098, data cost:0.18664895067490248 
2022-07-25 03:39:32,655: ============================================================
2022-07-25 03:39:32,655: Epoch 16/25 Batch 3500/7662 eta: 8:16:34.341196	Training Loss1 4.5974 (4.2104)	Training Total_Loss 4.5974 (4.2104)	Training Prec@1 100.000 (99.858)	Training Prec@5 100.000 (99.952)	
2022-07-25 03:39:32,655: ============================================================
2022-07-25 03:40:13,372: time cost, forward:0.12430843693509834, backward:0.09651242126587796, data cost:0.1866275108201731 
2022-07-25 03:40:13,373: ============================================================
2022-07-25 03:40:13,373: Epoch 16/25 Batch 3600/7662 eta: 8:15:32.292402	Training Loss1 4.4218 (4.2221)	Training Total_Loss 4.4218 (4.2221)	Training Prec@1 99.805 (99.857)	Training Prec@5 100.000 (99.951)	
2022-07-25 03:40:13,373: ============================================================
2022-07-25 03:40:54,089: time cost, forward:0.12429804665296584, backward:0.09651555761062444, data cost:0.1866076597170947 
2022-07-25 03:40:54,089: ============================================================
2022-07-25 03:40:54,089: Epoch 16/25 Batch 3700/7662 eta: 8:14:50.682191	Training Loss1 4.4505 (4.2331)	Training Total_Loss 4.4505 (4.2331)	Training Prec@1 99.805 (99.857)	Training Prec@5 100.000 (99.951)	
2022-07-25 03:40:54,089: ============================================================
2022-07-25 03:41:34,769: time cost, forward:0.12428971358618318, backward:0.09651712129918737, data cost:0.18658329876324603 
2022-07-25 03:41:34,769: ============================================================
2022-07-25 03:41:34,770: Epoch 16/25 Batch 3800/7662 eta: 8:13:43.958212	Training Loss1 5.2078 (4.2433)	Training Total_Loss 5.2078 (4.2433)	Training Prec@1 99.609 (99.855)	Training Prec@5 99.805 (99.951)	
2022-07-25 03:41:34,770: ============================================================
2022-07-25 03:42:15,447: time cost, forward:0.12427662390566814, backward:0.09652244717562984, data cost:0.18656008284530384 
2022-07-25 03:42:15,447: ============================================================
2022-07-25 03:42:15,447: Epoch 16/25 Batch 3900/7662 eta: 8:13:00.938622	Training Loss1 4.6511 (4.2545)	Training Total_Loss 4.6511 (4.2545)	Training Prec@1 99.805 (99.853)	Training Prec@5 100.000 (99.950)	
2022-07-25 03:42:15,447: ============================================================
2022-07-25 03:42:56,215: time cost, forward:0.12428536126541477, backward:0.09652436545682747, data cost:0.1865419923558656 
2022-07-25 03:42:56,216: ============================================================
2022-07-25 03:42:56,216: Epoch 16/25 Batch 4000/7662 eta: 8:13:26.879769	Training Loss1 4.7516 (4.2652)	Training Total_Loss 4.7516 (4.2652)	Training Prec@1 100.000 (99.852)	Training Prec@5 100.000 (99.950)	
2022-07-25 03:42:56,216: ============================================================
2022-07-25 03:43:36,940: time cost, forward:0.12428204854484534, backward:0.09652709315305338, data cost:0.1865264406201897 
2022-07-25 03:43:36,940: ============================================================
2022-07-25 03:43:36,940: Epoch 16/25 Batch 4100/7662 eta: 8:12:13.664695	Training Loss1 4.9891 (4.2757)	Training Total_Loss 4.9891 (4.2757)	Training Prec@1 100.000 (99.851)	Training Prec@5 100.000 (99.950)	
2022-07-25 03:43:36,940: ============================================================
2022-07-25 03:44:17,657: time cost, forward:0.12427731348407016, backward:0.09653075935443715, data cost:0.18651103280674533 
2022-07-25 03:44:17,657: ============================================================
2022-07-25 03:44:17,658: Epoch 16/25 Batch 4200/7662 eta: 8:11:27.880278	Training Loss1 4.9217 (4.2865)	Training Total_Loss 4.9217 (4.2865)	Training Prec@1 99.609 (99.849)	Training Prec@5 100.000 (99.949)	
2022-07-25 03:44:17,658: ============================================================
2022-07-25 03:44:58,368: time cost, forward:0.12427354901578433, backward:0.09653319384115024, data cost:0.18649494406732745 
2022-07-25 03:44:58,368: ============================================================
2022-07-25 03:44:58,369: Epoch 16/25 Batch 4300/7662 eta: 8:10:42.582284	Training Loss1 4.6274 (4.2953)	Training Total_Loss 4.6274 (4.2953)	Training Prec@1 99.805 (99.848)	Training Prec@5 99.805 (99.949)	
2022-07-25 03:44:58,369: ============================================================
2022-07-25 03:45:39,057: time cost, forward:0.12426786152821667, backward:0.09653562685391338, data cost:0.1864765387932044 
2022-07-25 03:45:39,057: ============================================================
2022-07-25 03:45:39,057: Epoch 16/25 Batch 4400/7662 eta: 8:09:45.642394	Training Loss1 4.2075 (4.3044)	Training Total_Loss 4.2075 (4.3044)	Training Prec@1 99.805 (99.847)	Training Prec@5 99.805 (99.949)	
2022-07-25 03:45:39,057: ============================================================
2022-07-25 03:46:19,774: time cost, forward:0.12426576219047009, backward:0.0965396634576903, data cost:0.18645945721982612 
2022-07-25 03:46:19,774: ============================================================
2022-07-25 03:46:19,774: Epoch 16/25 Batch 4500/7662 eta: 8:09:25.706006	Training Loss1 5.3926 (4.3147)	Training Total_Loss 5.3926 (4.3147)	Training Prec@1 99.609 (99.845)	Training Prec@5 99.805 (99.948)	
2022-07-25 03:46:19,774: ============================================================
2022-07-25 03:47:00,529: time cost, forward:0.12426943622430683, backward:0.09654199447183927, data cost:0.18644560469469576 
2022-07-25 03:47:00,529: ============================================================
2022-07-25 03:47:00,529: Epoch 16/25 Batch 4600/7662 eta: 8:09:12.011304	Training Loss1 4.6927 (4.3238)	Training Total_Loss 4.6927 (4.3238)	Training Prec@1 100.000 (99.844)	Training Prec@5 100.000 (99.947)	
2022-07-25 03:47:00,529: ============================================================
2022-07-25 03:47:41,286: time cost, forward:0.12427010422540385, backward:0.09654429497224622, data cost:0.18643705929611865 
2022-07-25 03:47:41,286: ============================================================
2022-07-25 03:47:41,297: Epoch 16/25 Batch 4700/7662 eta: 8:08:40.692841	Training Loss1 4.3637 (4.3331)	Training Total_Loss 4.3637 (4.3331)	Training Prec@1 100.000 (99.842)	Training Prec@5 100.000 (99.947)	
2022-07-25 03:47:41,297: ============================================================
2022-07-25 03:48:22,132: time cost, forward:0.12426716731374128, backward:0.0965702052314124, data cost:0.18642677906081687 
2022-07-25 03:48:22,132: ============================================================
2022-07-25 03:48:22,132: Epoch 16/25 Batch 4800/7662 eta: 8:08:48.324386	Training Loss1 4.4804 (4.3406)	Training Total_Loss 4.4804 (4.3406)	Training Prec@1 100.000 (99.841)	Training Prec@5 100.000 (99.946)	
2022-07-25 03:48:22,132: ============================================================
2022-07-25 03:49:02,977: time cost, forward:0.1242640452084188, backward:0.09659756317652593, data cost:0.18641434024367728 
2022-07-25 03:49:02,977: ============================================================
2022-07-25 03:49:02,977: Epoch 16/25 Batch 4900/7662 eta: 8:08:14.399208	Training Loss1 4.5985 (4.3490)	Training Total_Loss 4.5985 (4.3490)	Training Prec@1 99.805 (99.840)	Training Prec@5 99.805 (99.946)	
2022-07-25 03:49:02,977: ============================================================
2022-07-25 03:49:43,836: time cost, forward:0.12426423120317423, backward:0.09662425177029119, data cost:0.18640146839258598 
2022-07-25 03:49:43,837: ============================================================
2022-07-25 03:49:43,837: Epoch 16/25 Batch 5000/7662 eta: 8:07:43.968614	Training Loss1 5.1821 (4.3572)	Training Total_Loss 5.1821 (4.3572)	Training Prec@1 99.414 (99.839)	Training Prec@5 99.805 (99.945)	
2022-07-25 03:49:43,837: ============================================================
2022-07-25 03:50:24,687: time cost, forward:0.12426372742414428, backward:0.09664934166367556, data cost:0.1863886897623317 
2022-07-25 03:50:24,688: ============================================================
2022-07-25 03:50:24,688: Epoch 16/25 Batch 5100/7662 eta: 8:06:57.050240	Training Loss1 4.8765 (4.3645)	Training Total_Loss 4.8765 (4.3645)	Training Prec@1 99.609 (99.838)	Training Prec@5 100.000 (99.945)	
2022-07-25 03:50:24,688: ============================================================
2022-07-25 03:51:05,555: time cost, forward:0.12426527038540466, backward:0.09667324024705984, data cost:0.18637791847490215 
2022-07-25 03:51:05,555: ============================================================
2022-07-25 03:51:05,555: Epoch 16/25 Batch 5200/7662 eta: 8:06:28.116002	Training Loss1 4.3563 (4.3729)	Training Total_Loss 4.3563 (4.3729)	Training Prec@1 99.805 (99.837)	Training Prec@5 100.000 (99.945)	
2022-07-25 03:51:05,556: ============================================================
2022-07-25 03:51:46,427: time cost, forward:0.12426675133130127, backward:0.0966972957401596, data cost:0.18636739571199346 
2022-07-25 03:51:46,427: ============================================================
2022-07-25 03:51:46,427: Epoch 16/25 Batch 5300/7662 eta: 8:05:49.960315	Training Loss1 4.2488 (4.3820)	Training Total_Loss 4.2488 (4.3820)	Training Prec@1 100.000 (99.836)	Training Prec@5 100.000 (99.945)	
2022-07-25 03:51:46,427: ============================================================
2022-07-25 03:52:27,268: time cost, forward:0.12426912190627556, backward:0.09671380957490229, data cost:0.18635689984826959 
2022-07-25 03:52:27,268: ============================================================
2022-07-25 03:52:27,268: Epoch 16/25 Batch 5400/7662 eta: 8:04:47.562583	Training Loss1 4.9290 (4.3906)	Training Total_Loss 4.9290 (4.3906)	Training Prec@1 99.609 (99.834)	Training Prec@5 100.000 (99.944)	
2022-07-25 03:52:27,268: ============================================================
2022-07-25 03:53:07,997: time cost, forward:0.12427255916127207, backward:0.09671229599909167, data cost:0.18634373449286368 
2022-07-25 03:53:07,997: ============================================================
2022-07-25 03:53:07,997: Epoch 16/25 Batch 5500/7662 eta: 8:02:47.002212	Training Loss1 4.5076 (4.3980)	Training Total_Loss 4.5076 (4.3980)	Training Prec@1 99.609 (99.834)	Training Prec@5 100.000 (99.944)	
2022-07-25 03:53:07,998: ============================================================
2022-07-25 03:53:48,642: time cost, forward:0.12426644649904187, backward:0.0967090145181941, data cost:0.18632830771234848 
2022-07-25 03:53:48,642: ============================================================
2022-07-25 03:53:48,643: Epoch 16/25 Batch 5600/7662 eta: 8:01:06.632074	Training Loss1 5.1005 (4.4053)	Training Total_Loss 5.1005 (4.4053)	Training Prec@1 99.805 (99.833)	Training Prec@5 100.000 (99.944)	
2022-07-25 03:53:48,643: ============================================================
2022-07-25 03:54:29,256: time cost, forward:0.12425801172070722, backward:0.09670499517826014, data cost:0.18631188349465275 
2022-07-25 03:54:29,256: ============================================================
2022-07-25 03:54:29,256: Epoch 16/25 Batch 5700/7662 eta: 8:00:03.608974	Training Loss1 4.4327 (4.4134)	Training Total_Loss 4.4327 (4.4134)	Training Prec@1 99.805 (99.833)	Training Prec@5 99.805 (99.944)	
2022-07-25 03:54:29,256: ============================================================
2022-07-25 03:55:09,864: time cost, forward:0.1242473988024032, backward:0.09670177289670367, data cost:0.18629688241395853 
2022-07-25 03:55:09,865: ============================================================
2022-07-25 03:55:09,865: Epoch 16/25 Batch 5800/7662 eta: 7:59:19.330253	Training Loss1 4.7045 (4.4213)	Training Total_Loss 4.7045 (4.4213)	Training Prec@1 100.000 (99.832)	Training Prec@5 100.000 (99.944)	
2022-07-25 03:55:09,865: ============================================================
2022-07-25 03:55:50,475: time cost, forward:0.12423756325077175, backward:0.09669883167527453, data cost:0.18628230218585012 
2022-07-25 03:55:50,475: ============================================================
2022-07-25 03:55:50,476: Epoch 16/25 Batch 5900/7662 eta: 7:58:40.323589	Training Loss1 4.9632 (4.4279)	Training Total_Loss 4.9632 (4.4279)	Training Prec@1 100.000 (99.832)	Training Prec@5 100.000 (99.944)	
2022-07-25 03:55:50,476: ============================================================
2022-07-25 03:56:31,101: time cost, forward:0.1242278479083138, backward:0.0966972592553013, data cost:0.1862694342785387 
2022-07-25 03:56:31,102: ============================================================
2022-07-25 03:56:31,102: Epoch 16/25 Batch 6000/7662 eta: 7:58:10.594494	Training Loss1 5.2084 (4.4350)	Training Total_Loss 5.2084 (4.4350)	Training Prec@1 99.609 (99.830)	Training Prec@5 100.000 (99.943)	
2022-07-25 03:56:31,102: ============================================================
2022-07-25 03:57:11,734: time cost, forward:0.12421873476216394, backward:0.09669582420420424, data cost:0.18625732186701008 
2022-07-25 03:57:11,734: ============================================================
2022-07-25 03:57:11,734: Epoch 16/25 Batch 6100/7662 eta: 7:57:34.300682	Training Loss1 5.0900 (4.4418)	Training Total_Loss 5.0900 (4.4418)	Training Prec@1 99.609 (99.829)	Training Prec@5 100.000 (99.943)	
2022-07-25 03:57:11,734: ============================================================
2022-07-25 03:57:52,362: time cost, forward:0.12421022897613569, backward:0.09669279798343694, data cost:0.18624638845736335 
2022-07-25 03:57:52,363: ============================================================
2022-07-25 03:57:52,363: Epoch 16/25 Batch 6200/7662 eta: 7:56:51.261587	Training Loss1 4.6501 (4.4492)	Training Total_Loss 4.6501 (4.4492)	Training Prec@1 99.805 (99.828)	Training Prec@5 99.805 (99.943)	
2022-07-25 03:57:52,363: ============================================================
2022-07-25 03:58:32,997: time cost, forward:0.12420296369989556, backward:0.09668974335902569, data cost:0.18623578364857796 
2022-07-25 03:58:32,997: ============================================================
2022-07-25 03:58:32,997: Epoch 16/25 Batch 6300/7662 eta: 7:56:14.486839	Training Loss1 5.0177 (4.4561)	Training Total_Loss 5.0177 (4.4561)	Training Prec@1 99.609 (99.827)	Training Prec@5 99.805 (99.943)	
2022-07-25 03:58:32,997: ============================================================
2022-07-25 03:59:13,622: time cost, forward:0.12419578827513551, backward:0.09668641500984212, data cost:0.18622471701634977 
2022-07-25 03:59:13,623: ============================================================
2022-07-25 03:59:13,623: Epoch 16/25 Batch 6400/7662 eta: 7:55:27.774302	Training Loss1 4.7643 (4.4623)	Training Total_Loss 4.7643 (4.4623)	Training Prec@1 99.805 (99.826)	Training Prec@5 99.805 (99.942)	
2022-07-25 03:59:13,623: ============================================================
2022-07-25 03:59:54,250: time cost, forward:0.1241906977631639, backward:0.09668274442312039, data cost:0.18621285978987284 
2022-07-25 03:59:54,250: ============================================================
2022-07-25 03:59:54,250: Epoch 16/25 Batch 6500/7662 eta: 7:54:48.196827	Training Loss1 4.9249 (4.4682)	Training Total_Loss 4.9249 (4.4682)	Training Prec@1 100.000 (99.825)	Training Prec@5 100.000 (99.942)	
2022-07-25 03:59:54,250: ============================================================
2022-07-25 04:00:34,878: time cost, forward:0.12418445321100556, backward:0.09667950284211883, data cost:0.1862023598245643 
2022-07-25 04:00:34,878: ============================================================
2022-07-25 04:00:34,878: Epoch 16/25 Batch 6600/7662 eta: 7:54:08.233396	Training Loss1 5.0851 (4.4747)	Training Total_Loss 5.0851 (4.4747)	Training Prec@1 100.000 (99.824)	Training Prec@5 100.000 (99.941)	
2022-07-25 04:00:34,878: ============================================================
2022-07-25 04:01:15,500: time cost, forward:0.12417729261437892, backward:0.09667674042000879, data cost:0.18619234171495952 
2022-07-25 04:01:15,500: ============================================================
2022-07-25 04:01:15,500: Epoch 16/25 Batch 6700/7662 eta: 7:53:23.090889	Training Loss1 5.1313 (4.4809)	Training Total_Loss 5.1313 (4.4809)	Training Prec@1 99.609 (99.823)	Training Prec@5 99.805 (99.941)	
2022-07-25 04:01:15,500: ============================================================
2022-07-25 04:01:56,151: time cost, forward:0.12417118481668168, backward:0.09667546581846771, data cost:0.1861843952695698 
2022-07-25 04:01:56,151: ============================================================
2022-07-25 04:01:56,152: Epoch 16/25 Batch 6800/7662 eta: 7:53:03.344899	Training Loss1 4.4788 (4.4874)	Training Total_Loss 4.4788 (4.4874)	Training Prec@1 99.609 (99.822)	Training Prec@5 99.805 (99.940)	
2022-07-25 04:01:56,152: ============================================================
2022-07-25 04:02:36,801: time cost, forward:0.12416734956696268, backward:0.09667386008546151, data cost:0.1861748270650483 
2022-07-25 04:02:36,801: ============================================================
2022-07-25 04:02:36,801: Epoch 16/25 Batch 6900/7662 eta: 7:52:21.239483	Training Loss1 5.2258 (4.4940)	Training Total_Loss 5.2258 (4.4940)	Training Prec@1 99.805 (99.821)	Training Prec@5 99.805 (99.940)	
2022-07-25 04:02:36,801: ============================================================
2022-07-25 04:03:17,426: time cost, forward:0.12416102852475934, backward:0.09667066387286066, data cost:0.18616609073294998 
2022-07-25 04:03:17,427: ============================================================
2022-07-25 04:03:17,427: Epoch 16/25 Batch 7000/7662 eta: 7:51:23.970956	Training Loss1 4.7184 (4.4993)	Training Total_Loss 4.7184 (4.4993)	Training Prec@1 99.414 (99.819)	Training Prec@5 99.805 (99.940)	
2022-07-25 04:03:17,427: ============================================================
2022-07-25 04:03:58,057: time cost, forward:0.12415497610981757, backward:0.09666853341305318, data cost:0.18615762202365915 
2022-07-25 04:03:58,057: ============================================================
2022-07-25 04:03:58,057: Epoch 16/25 Batch 7100/7662 eta: 7:50:46.701616	Training Loss1 4.8512 (4.5054)	Training Total_Loss 4.8512 (4.5054)	Training Prec@1 99.805 (99.818)	Training Prec@5 99.805 (99.939)	
2022-07-25 04:03:58,057: ============================================================
2022-07-25 04:04:38,688: time cost, forward:0.12414951204574676, backward:0.09666507931977018, data cost:0.18615031345037308 
2022-07-25 04:04:38,689: ============================================================
2022-07-25 04:04:38,689: Epoch 16/25 Batch 7200/7662 eta: 7:50:06.915105	Training Loss1 5.2226 (4.5118)	Training Total_Loss 5.2226 (4.5118)	Training Prec@1 99.805 (99.818)	Training Prec@5 100.000 (99.939)	
2022-07-25 04:04:38,689: ============================================================
2022-07-25 04:05:19,308: time cost, forward:0.1241434462545081, backward:0.09666203482377397, data cost:0.18614200027466865 
2022-07-25 04:05:19,308: ============================================================
2022-07-25 04:05:19,308: Epoch 16/25 Batch 7300/7662 eta: 7:49:17.749996	Training Loss1 4.6216 (4.5175)	Training Total_Loss 4.6216 (4.5175)	Training Prec@1 99.805 (99.817)	Training Prec@5 100.000 (99.939)	
2022-07-25 04:05:19,308: ============================================================
2022-07-25 04:05:59,946: time cost, forward:0.12413772358606273, backward:0.09666094687810249, data cost:0.18613428369633717 
2022-07-25 04:05:59,946: ============================================================
2022-07-25 04:05:59,947: Epoch 16/25 Batch 7400/7662 eta: 7:48:50.221099	Training Loss1 4.9468 (4.5239)	Training Total_Loss 4.9468 (4.5239)	Training Prec@1 100.000 (99.816)	Training Prec@5 100.000 (99.939)	
2022-07-25 04:05:59,947: ============================================================
2022-07-25 04:06:40,560: time cost, forward:0.12413158049852407, backward:0.09665770593651582, data cost:0.1861263639943761 
2022-07-25 04:06:40,560: ============================================================
2022-07-25 04:06:40,560: Epoch 16/25 Batch 7500/7662 eta: 7:47:52.571951	Training Loss1 5.3444 (4.5294)	Training Total_Loss 5.3444 (4.5294)	Training Prec@1 99.414 (99.815)	Training Prec@5 99.805 (99.938)	
2022-07-25 04:06:40,560: ============================================================
2022-07-25 04:07:21,178: time cost, forward:0.12412723903201696, backward:0.09665551385152872, data cost:0.18611656494682785 
2022-07-25 04:07:21,179: ============================================================
2022-07-25 04:07:21,179: Epoch 16/25 Batch 7600/7662 eta: 7:47:15.420933	Training Loss1 4.1405 (4.5348)	Training Total_Loss 4.1405 (4.5348)	Training Prec@1 100.000 (99.814)	Training Prec@5 100.000 (99.938)	
2022-07-25 04:07:21,179: ============================================================
2022-07-25 04:07:48,548: Epoch 16/25 Batch 7663/7662 eta: 7:46:49.831163	Training Loss1 4.8151 (4.5381)	Training Total_Loss 4.8151 (4.5381)	Training Prec@1 100.000 (99.813)	Training Prec@5 100.000 (99.938)	
2022-07-25 04:07:48,548: ============================================================
2022-07-25 04:08:30,263: time cost, forward:0.12402802525144635, backward:0.09666266826668171, data cost:0.19807974497477213 
2022-07-25 04:08:30,264: ============================================================
2022-07-25 04:08:30,264: Epoch 17/25 Batch 100/7662 eta: 7:58:33.703620	Training Loss1 4.0386 (3.6206)	Training Total_Loss 4.0386 (3.6206)	Training Prec@1 100.000 (99.901)	Training Prec@5 100.000 (99.972)	
2022-07-25 04:08:30,264: ============================================================
2022-07-25 04:09:11,009: time cost, forward:0.12398122303449928, backward:0.09654892149882101, data cost:0.19230796344316187 
2022-07-25 04:09:11,009: ============================================================
2022-07-25 04:09:11,009: Epoch 17/25 Batch 200/7662 eta: 7:46:55.935619	Training Loss1 3.7500 (3.6242)	Training Total_Loss 3.7500 (3.6242)	Training Prec@1 99.805 (99.911)	Training Prec@5 100.000 (99.971)	
2022-07-25 04:09:11,009: ============================================================
2022-07-25 04:09:51,763: time cost, forward:0.12399232108457431, backward:0.09652286947371569, data cost:0.1903843632509876 
2022-07-25 04:09:51,764: ============================================================
2022-07-25 04:09:51,764: Epoch 17/25 Batch 300/7662 eta: 7:46:21.810032	Training Loss1 3.8163 (3.6374)	Training Total_Loss 3.8163 (3.6374)	Training Prec@1 99.609 (99.905)	Training Prec@5 100.000 (99.971)	
2022-07-25 04:09:51,764: ============================================================
2022-07-25 04:10:32,476: time cost, forward:0.12402579121123579, backward:0.09650564731511854, data cost:0.1892932859578527 
2022-07-25 04:10:32,476: ============================================================
2022-07-25 04:10:32,476: Epoch 17/25 Batch 400/7662 eta: 7:45:12.130180	Training Loss1 3.7739 (3.6722)	Training Total_Loss 3.7739 (3.6722)	Training Prec@1 100.000 (99.898)	Training Prec@5 100.000 (99.968)	
2022-07-25 04:10:32,477: ============================================================
2022-07-25 04:11:13,243: time cost, forward:0.12409186745454409, backward:0.0965162326912125, data cost:0.18867666066767935 
2022-07-25 04:11:13,243: ============================================================
2022-07-25 04:11:13,243: Epoch 17/25 Batch 500/7662 eta: 7:45:08.454444	Training Loss1 4.0964 (3.6911)	Training Total_Loss 4.0964 (3.6911)	Training Prec@1 100.000 (99.897)	Training Prec@5 100.000 (99.968)	
2022-07-25 04:11:13,243: ============================================================
2022-07-25 04:11:53,995: time cost, forward:0.12411792330033393, backward:0.09653038612391196, data cost:0.1882591967988691 
2022-07-25 04:11:53,996: ============================================================
2022-07-25 04:11:53,996: Epoch 17/25 Batch 600/7662 eta: 7:44:18.166776	Training Loss1 3.9242 (3.7079)	Training Total_Loss 3.9242 (3.7079)	Training Prec@1 100.000 (99.898)	Training Prec@5 100.000 (99.969)	
2022-07-25 04:11:53,996: ============================================================
2022-07-25 04:12:34,747: time cost, forward:0.12409213718256043, backward:0.09654242252246163, data cost:0.1879802814369038 
2022-07-25 04:12:34,748: ============================================================
2022-07-25 04:12:34,748: Epoch 17/25 Batch 700/7662 eta: 7:43:36.845739	Training Loss1 3.4131 (3.7206)	Training Total_Loss 3.4131 (3.7206)	Training Prec@1 99.609 (99.899)	Training Prec@5 100.000 (99.969)	
2022-07-25 04:12:34,748: ============================================================
2022-07-25 04:13:15,471: time cost, forward:0.12408100917133431, backward:0.09655641315875572, data cost:0.1877414607285558 
2022-07-25 04:13:15,471: ============================================================
2022-07-25 04:13:15,472: Epoch 17/25 Batch 800/7662 eta: 7:42:36.888165	Training Loss1 3.7294 (3.7466)	Training Total_Loss 3.7294 (3.7466)	Training Prec@1 100.000 (99.896)	Training Prec@5 100.000 (99.968)	
2022-07-25 04:13:15,472: ============================================================
2022-07-25 04:13:56,210: time cost, forward:0.1241117043542915, backward:0.09655792482437627, data cost:0.1875423175739632 
2022-07-25 04:13:56,211: ============================================================
2022-07-25 04:13:56,211: Epoch 17/25 Batch 900/7662 eta: 7:42:06.681659	Training Loss1 4.0936 (3.7674)	Training Total_Loss 4.0936 (3.7674)	Training Prec@1 99.805 (99.895)	Training Prec@5 100.000 (99.969)	
2022-07-25 04:13:56,211: ============================================================
2022-07-25 04:14:36,977: time cost, forward:0.12412046145151805, backward:0.09656331703827546, data cost:0.1874213278353274 
2022-07-25 04:14:36,977: ============================================================
2022-07-25 04:14:36,978: Epoch 17/25 Batch 1000/7662 eta: 7:41:44.704215	Training Loss1 3.9644 (3.7860)	Training Total_Loss 3.9644 (3.7860)	Training Prec@1 99.414 (99.893)	Training Prec@5 100.000 (99.968)	
2022-07-25 04:14:36,978: ============================================================
2022-07-25 04:15:17,734: time cost, forward:0.12414101191929408, backward:0.09655942886498324, data cost:0.1873089844145701 
2022-07-25 04:15:17,734: ============================================================
2022-07-25 04:15:17,735: Epoch 17/25 Batch 1100/7662 eta: 7:40:57.358134	Training Loss1 4.1952 (3.8066)	Training Total_Loss 4.1952 (3.8066)	Training Prec@1 99.805 (99.892)	Training Prec@5 100.000 (99.967)	
2022-07-25 04:15:17,735: ============================================================
2022-07-25 04:15:58,535: time cost, forward:0.12416450414586007, backward:0.09656235712383865, data cost:0.18723828619574387 
2022-07-25 04:15:58,535: ============================================================
2022-07-25 04:15:58,535: Epoch 17/25 Batch 1200/7662 eta: 7:40:46.021724	Training Loss1 3.9358 (3.8254)	Training Total_Loss 3.9358 (3.8254)	Training Prec@1 100.000 (99.889)	Training Prec@5 100.000 (99.966)	
2022-07-25 04:15:58,535: ============================================================
2022-07-25 04:16:39,389: time cost, forward:0.12418911987492633, backward:0.09660762415380089, data cost:0.1871643398613816 
2022-07-25 04:16:39,389: ============================================================
2022-07-25 04:16:39,389: Epoch 17/25 Batch 1300/7662 eta: 7:40:41.640211	Training Loss1 4.3115 (3.8492)	Training Total_Loss 4.3115 (3.8492)	Training Prec@1 99.805 (99.886)	Training Prec@5 99.805 (99.965)	
2022-07-25 04:16:39,390: ============================================================
2022-07-25 04:17:20,337: time cost, forward:0.1242014029095904, backward:0.09669931434238699, data cost:0.18712988131552444 
2022-07-25 04:17:20,337: ============================================================
2022-07-25 04:17:20,338: Epoch 17/25 Batch 1400/7662 eta: 7:41:04.192174	Training Loss1 4.4023 (3.8659)	Training Total_Loss 4.4023 (3.8659)	Training Prec@1 100.000 (99.886)	Training Prec@5 100.000 (99.964)	
2022-07-25 04:17:20,338: ============================================================
2022-07-25 04:18:01,201: time cost, forward:0.12420703936927394, backward:0.0967766532427156, data cost:0.18705031774774084 
2022-07-25 04:18:01,202: ============================================================
2022-07-25 04:18:01,202: Epoch 17/25 Batch 1500/7662 eta: 7:39:26.462220	Training Loss1 3.5599 (3.8818)	Training Total_Loss 3.5599 (3.8818)	Training Prec@1 100.000 (99.884)	Training Prec@5 100.000 (99.964)	
2022-07-25 04:18:01,202: ============================================================
2022-07-25 04:18:41,912: time cost, forward:0.12420568367777354, backward:0.09676372102829275, data cost:0.1869753231623532 
2022-07-25 04:18:41,912: ============================================================
2022-07-25 04:18:41,912: Epoch 17/25 Batch 1600/7662 eta: 7:37:02.371667	Training Loss1 3.8897 (3.9027)	Training Total_Loss 3.8897 (3.9027)	Training Prec@1 100.000 (99.883)	Training Prec@5 100.000 (99.965)	
2022-07-25 04:18:41,913: ============================================================
2022-07-25 04:19:22,703: time cost, forward:0.12420976140907472, backward:0.09674886214585779, data cost:0.18695515348603967 
2022-07-25 04:19:22,703: ============================================================
2022-07-25 04:19:22,703: Epoch 17/25 Batch 1700/7662 eta: 7:37:15.475256	Training Loss1 4.2548 (3.9200)	Training Total_Loss 4.2548 (3.9200)	Training Prec@1 99.805 (99.882)	Training Prec@5 100.000 (99.965)	
2022-07-25 04:19:22,703: ============================================================
2022-07-25 04:20:03,499: time cost, forward:0.12422454986657083, backward:0.09673606918678475, data cost:0.1869278765175328 
2022-07-25 04:20:03,499: ============================================================
2022-07-25 04:20:03,499: Epoch 17/25 Batch 1800/7662 eta: 7:36:38.205497	Training Loss1 3.9228 (3.9380)	Training Total_Loss 3.9228 (3.9380)	Training Prec@1 99.805 (99.880)	Training Prec@5 100.000 (99.964)	
2022-07-25 04:20:03,499: ============================================================
2022-07-25 04:20:44,205: time cost, forward:0.12421376030968641, backward:0.09673199859526736, data cost:0.18687226007711644 
2022-07-25 04:20:44,205: ============================================================
2022-07-25 04:20:44,205: Epoch 17/25 Batch 1900/7662 eta: 7:34:56.879757	Training Loss1 4.4180 (3.9564)	Training Total_Loss 4.4180 (3.9564)	Training Prec@1 99.805 (99.877)	Training Prec@5 99.805 (99.964)	
2022-07-25 04:20:44,205: ============================================================
2022-07-25 04:21:24,862: time cost, forward:0.1241916382891229, backward:0.09672474348288647, data cost:0.18681417422750224 
2022-07-25 04:21:24,862: ============================================================
2022-07-25 04:21:24,862: Epoch 17/25 Batch 2000/7662 eta: 7:33:43.702347	Training Loss1 4.4278 (3.9757)	Training Total_Loss 4.4278 (3.9757)	Training Prec@1 99.805 (99.876)	Training Prec@5 99.805 (99.963)	
2022-07-25 04:21:24,862: ============================================================
2022-07-25 04:22:05,532: time cost, forward:0.12417817979042958, backward:0.0967162097278466, data cost:0.18676231269781904 
2022-07-25 04:22:05,532: ============================================================
2022-07-25 04:22:05,532: Epoch 17/25 Batch 2100/7662 eta: 7:33:11.575117	Training Loss1 4.2476 (3.9905)	Training Total_Loss 4.2476 (3.9905)	Training Prec@1 99.805 (99.876)	Training Prec@5 99.805 (99.963)	
2022-07-25 04:22:05,532: ============================================================
2022-07-25 04:22:46,163: time cost, forward:0.12415887638350517, backward:0.09670498968525983, data cost:0.18670868060435963 
2022-07-25 04:22:46,164: ============================================================
2022-07-25 04:22:46,164: Epoch 17/25 Batch 2200/7662 eta: 7:32:05.226859	Training Loss1 4.1501 (4.0049)	Training Total_Loss 4.1501 (4.0049)	Training Prec@1 100.000 (99.874)	Training Prec@5 100.000 (99.962)	
2022-07-25 04:22:46,164: ============================================================
2022-07-25 04:23:26,832: time cost, forward:0.12414971420483882, backward:0.09669369383965849, data cost:0.1866684388263996 
2022-07-25 04:23:26,832: ============================================================
2022-07-25 04:23:26,832: Epoch 17/25 Batch 2300/7662 eta: 7:31:48.983504	Training Loss1 4.0398 (4.0212)	Training Total_Loss 4.0398 (4.0212)	Training Prec@1 100.000 (99.871)	Training Prec@5 100.000 (99.962)	
2022-07-25 04:23:26,832: ============================================================
2022-07-25 04:24:07,515: time cost, forward:0.12413795792395595, backward:0.09668274748668218, data cost:0.18664134348765568 
2022-07-25 04:24:07,516: ============================================================
2022-07-25 04:24:07,516: Epoch 17/25 Batch 2400/7662 eta: 7:31:18.705833	Training Loss1 4.5803 (4.0353)	Training Total_Loss 4.5803 (4.0353)	Training Prec@1 99.805 (99.870)	Training Prec@5 100.000 (99.961)	
2022-07-25 04:24:07,516: ============================================================
2022-07-25 04:24:48,160: time cost, forward:0.12412513919523498, backward:0.09667455429742698, data cost:0.18660145742791134 
2022-07-25 04:24:48,160: ============================================================
2022-07-25 04:24:48,160: Epoch 17/25 Batch 2500/7662 eta: 7:30:11.682510	Training Loss1 4.5602 (4.0502)	Training Total_Loss 4.5602 (4.0502)	Training Prec@1 99.609 (99.868)	Training Prec@5 99.805 (99.960)	
2022-07-25 04:24:48,160: ============================================================
2022-07-25 04:25:28,816: time cost, forward:0.1241136143968031, backward:0.09666397902726118, data cost:0.18657202140878557 
2022-07-25 04:25:28,816: ============================================================
2022-07-25 04:25:28,816: Epoch 17/25 Batch 2600/7662 eta: 7:29:39.231714	Training Loss1 4.5798 (4.0653)	Training Total_Loss 4.5798 (4.0653)	Training Prec@1 99.805 (99.867)	Training Prec@5 99.805 (99.960)	
2022-07-25 04:25:28,817: ============================================================
2022-07-25 04:26:09,543: time cost, forward:0.12411682108412322, backward:0.09665387089316957, data cost:0.18655658156927446 
2022-07-25 04:26:09,543: ============================================================
2022-07-25 04:26:09,543: Epoch 17/25 Batch 2700/7662 eta: 7:29:45.240213	Training Loss1 4.2300 (4.0791)	Training Total_Loss 4.2300 (4.0791)	Training Prec@1 99.805 (99.865)	Training Prec@5 100.000 (99.960)	
2022-07-25 04:26:09,543: ============================================================
2022-07-25 04:26:50,213: time cost, forward:0.12411057518907596, backward:0.09664926302352093, data cost:0.18652669000983366 
2022-07-25 04:26:50,213: ============================================================
2022-07-25 04:26:50,213: Epoch 17/25 Batch 2800/7662 eta: 7:28:26.853520	Training Loss1 4.3965 (4.0913)	Training Total_Loss 4.3965 (4.0913)	Training Prec@1 100.000 (99.864)	Training Prec@5 100.000 (99.960)	
2022-07-25 04:26:50,213: ============================================================
2022-07-25 04:27:30,922: time cost, forward:0.12410481504918625, backward:0.0966405411266631, data cost:0.18651632672139143 
2022-07-25 04:27:30,922: ============================================================
2022-07-25 04:27:30,922: Epoch 17/25 Batch 2900/7662 eta: 7:28:11.964683	Training Loss1 4.0816 (4.1044)	Training Total_Loss 4.0816 (4.1044)	Training Prec@1 99.805 (99.862)	Training Prec@5 100.000 (99.959)	
2022-07-25 04:27:30,923: ============================================================
2022-07-25 04:28:11,522: time cost, forward:0.12408950576069912, backward:0.09663417475268855, data cost:0.1864792213872418 
2022-07-25 04:28:11,522: ============================================================
2022-07-25 04:28:11,522: Epoch 17/25 Batch 3000/7662 eta: 7:26:19.141638	Training Loss1 4.8406 (4.1178)	Training Total_Loss 4.8406 (4.1178)	Training Prec@1 99.609 (99.861)	Training Prec@5 99.805 (99.959)	
2022-07-25 04:28:11,522: ============================================================
2022-07-25 04:28:52,121: time cost, forward:0.12407655222025868, backward:0.0966271941759541, data cost:0.18644340548372224 
2022-07-25 04:28:52,121: ============================================================
2022-07-25 04:28:52,121: Epoch 17/25 Batch 3100/7662 eta: 7:25:38.354478	Training Loss1 4.6347 (4.1282)	Training Total_Loss 4.6347 (4.1282)	Training Prec@1 99.023 (99.861)	Training Prec@5 99.805 (99.958)	
2022-07-25 04:28:52,122: ============================================================
2022-07-25 04:29:32,748: time cost, forward:0.12406660110065809, backward:0.09662292927047095, data cost:0.18641441268598932 
2022-07-25 04:29:32,748: ============================================================
2022-07-25 04:29:32,748: Epoch 17/25 Batch 3200/7662 eta: 7:25:15.911030	Training Loss1 4.5234 (4.1398)	Training Total_Loss 4.5234 (4.1398)	Training Prec@1 99.805 (99.860)	Training Prec@5 99.805 (99.958)	
2022-07-25 04:29:32,749: ============================================================
2022-07-25 04:30:13,415: time cost, forward:0.12405892645600855, backward:0.09661852616040986, data cost:0.18639781634783736 
2022-07-25 04:30:13,415: ============================================================
2022-07-25 04:30:13,416: Epoch 17/25 Batch 3300/7662 eta: 7:25:01.629317	Training Loss1 4.3752 (4.1517)	Training Total_Loss 4.3752 (4.1517)	Training Prec@1 99.805 (99.860)	Training Prec@5 99.805 (99.958)	
2022-07-25 04:30:13,416: ============================================================
2022-07-25 04:30:54,050: time cost, forward:0.1240493225048275, backward:0.0966120187799241, data cost:0.18637718071338533 
2022-07-25 04:30:54,050: ============================================================
2022-07-25 04:30:54,050: Epoch 17/25 Batch 3400/7662 eta: 7:23:59.650025	Training Loss1 4.6517 (4.1629)	Training Total_Loss 4.6517 (4.1629)	Training Prec@1 99.609 (99.859)	Training Prec@5 99.805 (99.957)	
2022-07-25 04:30:54,050: ============================================================
2022-07-25 04:31:34,694: time cost, forward:0.12404059287172346, backward:0.09660669543737001, data cost:0.18636015531982003 
2022-07-25 04:31:34,695: ============================================================
2022-07-25 04:31:34,695: Epoch 17/25 Batch 3500/7662 eta: 7:23:25.607651	Training Loss1 4.6593 (4.1745)	Training Total_Loss 4.6593 (4.1745)	Training Prec@1 99.609 (99.858)	Training Prec@5 100.000 (99.957)	
2022-07-25 04:31:34,695: ============================================================
2022-07-25 04:32:15,346: time cost, forward:0.12402993097806116, backward:0.09660131628561695, data cost:0.18634798255818658 
2022-07-25 04:32:15,346: ============================================================
2022-07-25 04:32:15,346: Epoch 17/25 Batch 3600/7662 eta: 7:22:49.249478	Training Loss1 4.1847 (4.1860)	Training Total_Loss 4.1847 (4.1860)	Training Prec@1 100.000 (99.857)	Training Prec@5 100.000 (99.956)	
2022-07-25 04:32:15,346: ============================================================
2022-07-25 04:32:55,981: time cost, forward:0.12402204604817907, backward:0.09659768891160506, data cost:0.186329319916019 
2022-07-25 04:32:55,981: ============================================================
2022-07-25 04:32:55,982: Epoch 17/25 Batch 3700/7662 eta: 7:21:58.249811	Training Loss1 4.8385 (4.1967)	Training Total_Loss 4.8385 (4.1967)	Training Prec@1 99.805 (99.855)	Training Prec@5 99.805 (99.956)	
2022-07-25 04:32:55,982: ============================================================
2022-07-25 04:33:36,582: time cost, forward:0.12401161265392058, backward:0.09659336616755097, data cost:0.18630687730442258 
2022-07-25 04:33:36,583: ============================================================
2022-07-25 04:33:36,583: Epoch 17/25 Batch 3800/7662 eta: 7:20:55.295274	Training Loss1 4.2583 (4.2091)	Training Total_Loss 4.2583 (4.2091)	Training Prec@1 100.000 (99.855)	Training Prec@5 100.000 (99.955)	
2022-07-25 04:33:36,583: ============================================================
2022-07-25 04:34:17,180: time cost, forward:0.12399862851507085, backward:0.09658956185277531, data cost:0.1862869587394634 
2022-07-25 04:34:17,180: ============================================================
2022-07-25 04:34:17,180: Epoch 17/25 Batch 3900/7662 eta: 7:20:12.283994	Training Loss1 4.2756 (4.2200)	Training Total_Loss 4.2756 (4.2200)	Training Prec@1 99.609 (99.853)	Training Prec@5 100.000 (99.954)	
2022-07-25 04:34:17,180: ============================================================
2022-07-25 04:34:57,778: time cost, forward:0.12398901138343821, backward:0.09658590886973834, data cost:0.18626637958413095 
2022-07-25 04:34:57,778: ============================================================
2022-07-25 04:34:57,779: Epoch 17/25 Batch 4000/7662 eta: 7:19:32.314886	Training Loss1 4.5378 (4.2306)	Training Total_Loss 4.5378 (4.2306)	Training Prec@1 100.000 (99.852)	Training Prec@5 100.000 (99.954)	
2022-07-25 04:34:57,779: ============================================================
2022-07-25 04:35:38,379: time cost, forward:0.12397931127555198, backward:0.09658187981145096, data cost:0.18624769614713604 
2022-07-25 04:35:38,379: ============================================================
2022-07-25 04:35:38,380: Epoch 17/25 Batch 4100/7662 eta: 7:18:53.461552	Training Loss1 3.7507 (4.2409)	Training Total_Loss 3.7507 (4.2409)	Training Prec@1 100.000 (99.850)	Training Prec@5 100.000 (99.954)	
2022-07-25 04:35:38,380: ============================================================
2022-07-25 04:36:19,013: time cost, forward:0.12397489606780533, backward:0.09657940599968899, data cost:0.18623273098403484 
2022-07-25 04:36:19,013: ============================================================
2022-07-25 04:36:19,013: Epoch 17/25 Batch 4200/7662 eta: 7:18:33.952239	Training Loss1 4.8399 (4.2509)	Training Total_Loss 4.8399 (4.2509)	Training Prec@1 99.805 (99.848)	Training Prec@5 100.000 (99.953)	
2022-07-25 04:36:19,013: ============================================================
2022-07-25 04:36:59,623: time cost, forward:0.1239676413965325, backward:0.09657602200371689, data cost:0.18621673692684168 
2022-07-25 04:36:59,623: ============================================================
2022-07-25 04:36:59,623: Epoch 17/25 Batch 4300/7662 eta: 7:17:37.949536	Training Loss1 4.3477 (4.2610)	Training Total_Loss 4.3477 (4.2610)	Training Prec@1 99.805 (99.847)	Training Prec@5 99.805 (99.952)	
2022-07-25 04:36:59,623: ============================================================
2022-07-25 04:37:40,235: time cost, forward:0.12396292346096711, backward:0.09657370667480344, data cost:0.18619972425418757 
2022-07-25 04:37:40,236: ============================================================
2022-07-25 04:37:40,236: Epoch 17/25 Batch 4400/7662 eta: 7:16:59.057091	Training Loss1 5.3131 (4.2704)	Training Total_Loss 5.3131 (4.2704)	Training Prec@1 100.000 (99.845)	Training Prec@5 100.000 (99.952)	
2022-07-25 04:37:40,236: ============================================================
2022-07-25 04:38:20,835: time cost, forward:0.12395626064087714, backward:0.09657106163184308, data cost:0.18618265462732494 
2022-07-25 04:38:20,835: ============================================================
2022-07-25 04:38:20,835: Epoch 17/25 Batch 4500/7662 eta: 7:16:10.101131	Training Loss1 4.2846 (4.2794)	Training Total_Loss 4.2846 (4.2794)	Training Prec@1 100.000 (99.844)	Training Prec@5 100.000 (99.951)	
2022-07-25 04:38:20,835: ============================================================
2022-07-25 04:39:01,417: time cost, forward:0.12394969078166818, backward:0.09656717497827075, data cost:0.18616449042334973 
2022-07-25 04:39:01,418: ============================================================
2022-07-25 04:39:01,418: Epoch 17/25 Batch 4600/7662 eta: 7:15:18.490856	Training Loss1 4.5043 (4.2892)	Training Total_Loss 4.5043 (4.2892)	Training Prec@1 99.609 (99.843)	Training Prec@5 100.000 (99.951)	
2022-07-25 04:39:01,418: ============================================================
2022-07-25 04:39:41,995: time cost, forward:0.12394153348789187, backward:0.09656407995968835, data cost:0.18614679063779543 
2022-07-25 04:39:41,995: ============================================================
2022-07-25 04:39:41,995: Epoch 17/25 Batch 4700/7662 eta: 7:14:34.602337	Training Loss1 4.5486 (4.2989)	Training Total_Loss 4.5486 (4.2989)	Training Prec@1 99.609 (99.843)	Training Prec@5 99.805 (99.950)	
2022-07-25 04:39:41,995: ============================================================
2022-07-25 04:40:22,612: time cost, forward:0.12393812786467151, backward:0.09656247697191503, data cost:0.18613200819623996 
2022-07-25 04:40:22,612: ============================================================
2022-07-25 04:40:22,613: Epoch 17/25 Batch 4800/7662 eta: 7:14:19.737966	Training Loss1 4.6753 (4.3086)	Training Total_Loss 4.6753 (4.3086)	Training Prec@1 99.805 (99.842)	Training Prec@5 100.000 (99.950)	
2022-07-25 04:40:22,613: ============================================================
2022-07-25 04:41:03,255: time cost, forward:0.12393527596452865, backward:0.09656340118621558, data cost:0.18611979192557396 
2022-07-25 04:41:03,256: ============================================================
2022-07-25 04:41:03,256: Epoch 17/25 Batch 4900/7662 eta: 7:13:55.611553	Training Loss1 4.6948 (4.3165)	Training Total_Loss 4.6948 (4.3165)	Training Prec@1 99.414 (99.841)	Training Prec@5 99.805 (99.950)	
2022-07-25 04:41:03,256: ============================================================
2022-07-25 04:41:43,917: time cost, forward:0.12393207348783294, backward:0.09656529594454963, data cost:0.18611109397439485 
2022-07-25 04:41:43,917: ============================================================
2022-07-25 04:41:43,917: Epoch 17/25 Batch 5000/7662 eta: 7:13:26.679926	Training Loss1 4.7334 (4.3263)	Training Total_Loss 4.7334 (4.3263)	Training Prec@1 99.609 (99.840)	Training Prec@5 99.609 (99.949)	
2022-07-25 04:41:43,917: ============================================================
2022-07-25 04:42:24,593: time cost, forward:0.12393096957306789, backward:0.09656658661695153, data cost:0.18610362095747726 
2022-07-25 04:42:24,593: ============================================================
2022-07-25 04:42:24,593: Epoch 17/25 Batch 5100/7662 eta: 7:12:55.178208	Training Loss1 4.5354 (4.3349)	Training Total_Loss 4.5354 (4.3349)	Training Prec@1 100.000 (99.838)	Training Prec@5 100.000 (99.949)	
2022-07-25 04:42:24,593: ============================================================
2022-07-25 04:43:05,295: time cost, forward:0.12393514012620871, backward:0.09656693147085886, data cost:0.18609753689598088 
2022-07-25 04:43:05,295: ============================================================
2022-07-25 04:43:05,295: Epoch 17/25 Batch 5200/7662 eta: 7:12:31.232050	Training Loss1 4.3164 (4.3422)	Training Total_Loss 4.3164 (4.3422)	Training Prec@1 99.414 (99.837)	Training Prec@5 99.609 (99.948)	
2022-07-25 04:43:05,295: ============================================================
2022-07-25 04:43:45,948: time cost, forward:0.12393193151348378, backward:0.09656809851636884, data cost:0.18608958119602784 
2022-07-25 04:43:45,948: ============================================================
2022-07-25 04:43:45,948: Epoch 17/25 Batch 5300/7662 eta: 7:11:19.458779	Training Loss1 4.8673 (4.3498)	Training Total_Loss 4.8673 (4.3498)	Training Prec@1 100.000 (99.836)	Training Prec@5 100.000 (99.948)	
2022-07-25 04:43:45,949: ============================================================
2022-07-25 04:44:26,589: time cost, forward:0.12392880091249424, backward:0.09656918205625814, data cost:0.18607979899182278 
2022-07-25 04:44:26,589: ============================================================
2022-07-25 04:44:26,589: Epoch 17/25 Batch 5400/7662 eta: 7:10:30.823638	Training Loss1 4.5116 (4.3578)	Training Total_Loss 4.5116 (4.3578)	Training Prec@1 100.000 (99.836)	Training Prec@5 100.000 (99.948)	
2022-07-25 04:44:26,589: ============================================================
2022-07-25 04:45:07,230: time cost, forward:0.12392600438100118, backward:0.09656929536220442, data cost:0.1860711378582089 
2022-07-25 04:45:07,230: ============================================================
2022-07-25 04:45:07,230: Epoch 17/25 Batch 5500/7662 eta: 7:09:50.441354	Training Loss1 5.0135 (4.3654)	Training Total_Loss 5.0135 (4.3654)	Training Prec@1 99.805 (99.835)	Training Prec@5 100.000 (99.948)	
2022-07-25 04:45:07,230: ============================================================
2022-07-25 04:45:47,904: time cost, forward:0.12392862065814823, backward:0.09656961497759729, data cost:0.18606294940935542 
2022-07-25 04:45:47,905: ============================================================
2022-07-25 04:45:47,905: Epoch 17/25 Batch 5600/7662 eta: 7:09:30.914604	Training Loss1 5.0911 (4.3722)	Training Total_Loss 5.0911 (4.3722)	Training Prec@1 99.609 (99.834)	Training Prec@5 100.000 (99.948)	
2022-07-25 04:45:47,905: ============================================================
2022-07-25 04:46:28,582: time cost, forward:0.12393080951833248, backward:0.09657043619184331, data cost:0.1860551422448467 
2022-07-25 04:46:28,582: ============================================================
2022-07-25 04:46:28,582: Epoch 17/25 Batch 5700/7662 eta: 7:08:52.290886	Training Loss1 4.9170 (4.3802)	Training Total_Loss 4.9170 (4.3802)	Training Prec@1 99.219 (99.832)	Training Prec@5 99.805 (99.947)	
2022-07-25 04:46:28,583: ============================================================
2022-07-25 04:47:09,299: time cost, forward:0.12393641702099738, backward:0.09657103054522234, data cost:0.18605111212252667 
2022-07-25 04:47:09,299: ============================================================
2022-07-25 04:47:09,299: Epoch 17/25 Batch 5800/7662 eta: 7:08:36.345530	Training Loss1 4.5878 (4.3879)	Training Total_Loss 4.5878 (4.3879)	Training Prec@1 99.805 (99.831)	Training Prec@5 100.000 (99.946)	
2022-07-25 04:47:09,299: ============================================================
2022-07-25 04:47:50,036: time cost, forward:0.12394466026695447, backward:0.09657016081776856, data cost:0.1860492473174847 
2022-07-25 04:47:50,036: ============================================================
2022-07-25 04:47:50,036: Epoch 17/25 Batch 5900/7662 eta: 7:08:08.344221	Training Loss1 4.5794 (4.3956)	Training Total_Loss 4.5794 (4.3956)	Training Prec@1 99.805 (99.829)	Training Prec@5 100.000 (99.946)	
2022-07-25 04:47:50,036: ============================================================
2022-07-25 04:48:30,710: time cost, forward:0.12394227614341567, backward:0.0965730308949858, data cost:0.1860438471814954 
2022-07-25 04:48:30,710: ============================================================
2022-07-25 04:48:30,710: Epoch 17/25 Batch 6000/7662 eta: 7:06:48.051001	Training Loss1 5.2262 (4.4032)	Training Total_Loss 5.2262 (4.4032)	Training Prec@1 99.609 (99.828)	Training Prec@5 100.000 (99.946)	
2022-07-25 04:48:30,710: ============================================================
2022-07-25 04:49:11,383: time cost, forward:0.1239392074879554, backward:0.09657653837365036, data cost:0.18603893646863195 
2022-07-25 04:49:11,383: ============================================================
2022-07-25 04:49:11,383: Epoch 17/25 Batch 6100/7662 eta: 7:06:06.670355	Training Loss1 5.1024 (4.4101)	Training Total_Loss 5.1024 (4.4101)	Training Prec@1 100.000 (99.826)	Training Prec@5 100.000 (99.945)	
2022-07-25 04:49:11,384: ============================================================
2022-07-25 04:49:52,059: time cost, forward:0.1239391556669193, backward:0.09657839675702709, data cost:0.1860333193231156 
2022-07-25 04:49:52,060: ============================================================
2022-07-25 04:49:52,060: Epoch 17/25 Batch 6200/7662 eta: 7:05:28.062041	Training Loss1 5.1324 (4.4160)	Training Total_Loss 5.1324 (4.4160)	Training Prec@1 100.000 (99.826)	Training Prec@5 100.000 (99.945)	
2022-07-25 04:49:52,060: ============================================================
2022-07-25 04:50:32,720: time cost, forward:0.12393754102782913, backward:0.09657960128057455, data cost:0.18602744014059897 
2022-07-25 04:50:32,720: ============================================================
2022-07-25 04:50:32,720: Epoch 17/25 Batch 6300/7662 eta: 7:04:37.494696	Training Loss1 4.7991 (4.4227)	Training Total_Loss 4.7991 (4.4227)	Training Prec@1 99.805 (99.825)	Training Prec@5 99.805 (99.945)	
2022-07-25 04:50:32,720: ============================================================
2022-07-25 04:51:13,391: time cost, forward:0.12393564022151841, backward:0.09658206926880264, data cost:0.18602226193686316 
2022-07-25 04:51:13,391: ============================================================
2022-07-25 04:51:13,391: Epoch 17/25 Batch 6400/7662 eta: 7:04:03.152832	Training Loss1 4.6110 (4.4294)	Training Total_Loss 4.6110 (4.4294)	Training Prec@1 99.805 (99.824)	Training Prec@5 100.000 (99.945)	
2022-07-25 04:51:13,391: ============================================================
2022-07-25 04:51:54,057: time cost, forward:0.12393417929223656, backward:0.09658357605124862, data cost:0.18601712382267138 
2022-07-25 04:51:54,057: ============================================================
2022-07-25 04:51:54,057: Epoch 17/25 Batch 6500/7662 eta: 7:03:19.870976	Training Loss1 4.5183 (4.4349)	Training Total_Loss 4.5183 (4.4349)	Training Prec@1 100.000 (99.823)	Training Prec@5 100.000 (99.944)	
2022-07-25 04:51:54,058: ============================================================
2022-07-25 04:52:34,694: time cost, forward:0.12393116488531153, backward:0.09658237951671486, data cost:0.18601182934587193 
2022-07-25 04:52:34,694: ============================================================
2022-07-25 04:52:34,695: Epoch 17/25 Batch 6600/7662 eta: 7:02:20.936753	Training Loss1 4.8033 (4.4408)	Training Total_Loss 4.8033 (4.4408)	Training Prec@1 99.805 (99.822)	Training Prec@5 99.805 (99.944)	
2022-07-25 04:52:34,695: ============================================================
2022-07-25 04:53:15,328: time cost, forward:0.12392903267580958, backward:0.09658002547318054, data cost:0.18600662374944896 
2022-07-25 04:53:15,328: ============================================================
2022-07-25 04:53:15,328: Epoch 17/25 Batch 6700/7662 eta: 7:01:38.087420	Training Loss1 4.6037 (4.4469)	Training Total_Loss 4.6037 (4.4469)	Training Prec@1 99.805 (99.822)	Training Prec@5 99.805 (99.944)	
2022-07-25 04:53:15,328: ============================================================
2022-07-25 04:53:55,966: time cost, forward:0.12392828846384557, backward:0.09657828242204736, data cost:0.1860004825300286 
2022-07-25 04:53:55,967: ============================================================
2022-07-25 04:53:55,967: Epoch 17/25 Batch 6800/7662 eta: 7:01:00.472455	Training Loss1 4.8829 (4.4530)	Training Total_Loss 4.8829 (4.4530)	Training Prec@1 99.414 (99.821)	Training Prec@5 99.805 (99.943)	
2022-07-25 04:53:55,967: ============================================================
2022-07-25 04:54:36,605: time cost, forward:0.12392722497661661, backward:0.09657638790746031, data cost:0.18599511388592624 
2022-07-25 04:54:36,606: ============================================================
2022-07-25 04:54:36,606: Epoch 17/25 Batch 6900/7662 eta: 7:00:20.145135	Training Loss1 4.8256 (4.4590)	Training Total_Loss 4.8256 (4.4590)	Training Prec@1 99.805 (99.820)	Training Prec@5 99.805 (99.943)	
2022-07-25 04:54:36,606: ============================================================
2022-07-25 04:55:17,250: time cost, forward:0.12392705977857241, backward:0.0965758916871482, data cost:0.18598832977143404 
2022-07-25 04:55:17,251: ============================================================
2022-07-25 04:55:17,251: Epoch 17/25 Batch 7000/7662 eta: 6:59:43.196835	Training Loss1 4.5578 (4.4648)	Training Total_Loss 4.5578 (4.4648)	Training Prec@1 99.805 (99.819)	Training Prec@5 100.000 (99.943)	
2022-07-25 04:55:17,251: ============================================================
2022-07-25 04:55:57,886: time cost, forward:0.12392675065544226, backward:0.09657459343666928, data cost:0.18598173514002225 
2022-07-25 04:55:57,886: ============================================================
2022-07-25 04:55:57,887: Epoch 17/25 Batch 7100/7662 eta: 6:58:56.987646	Training Loss1 4.4346 (4.4706)	Training Total_Loss 4.4346 (4.4706)	Training Prec@1 99.414 (99.818)	Training Prec@5 99.609 (99.942)	
2022-07-25 04:55:57,887: ============================================================
2022-07-25 04:56:38,515: time cost, forward:0.12392521795423052, backward:0.09657372483148692, data cost:0.18597511884851214 
2022-07-25 04:56:38,516: ============================================================
2022-07-25 04:56:38,516: Epoch 17/25 Batch 7200/7662 eta: 6:58:12.187028	Training Loss1 5.3036 (4.4763)	Training Total_Loss 5.3036 (4.4763)	Training Prec@1 99.805 (99.817)	Training Prec@5 99.805 (99.942)	
2022-07-25 04:56:38,516: ============================================================
2022-07-25 04:57:19,147: time cost, forward:0.1239241692673296, backward:0.09657230036179322, data cost:0.185969126814113 
2022-07-25 04:57:19,147: ============================================================
2022-07-25 04:57:19,147: Epoch 17/25 Batch 7300/7662 eta: 6:57:33.019514	Training Loss1 4.8950 (4.4812)	Training Total_Loss 4.8950 (4.4812)	Training Prec@1 99.609 (99.816)	Training Prec@5 99.805 (99.942)	
2022-07-25 04:57:19,148: ============================================================
2022-07-25 04:57:59,771: time cost, forward:0.12392271526891938, backward:0.09657055085567964, data cost:0.18596297300317866 
2022-07-25 04:57:59,771: ============================================================
2022-07-25 04:57:59,772: Epoch 17/25 Batch 7400/7662 eta: 6:56:47.883192	Training Loss1 4.7551 (4.4865)	Training Total_Loss 4.7551 (4.4865)	Training Prec@1 99.414 (99.815)	Training Prec@5 100.000 (99.941)	
2022-07-25 04:57:59,772: ============================================================
2022-07-25 04:58:40,406: time cost, forward:0.12392158631659107, backward:0.09656820934380607, data cost:0.18595886220930735 
2022-07-25 04:58:40,406: ============================================================
2022-07-25 04:58:40,406: Epoch 17/25 Batch 7500/7662 eta: 6:56:13.748153	Training Loss1 4.3593 (4.4916)	Training Total_Loss 4.3593 (4.4916)	Training Prec@1 100.000 (99.814)	Training Prec@5 100.000 (99.941)	
2022-07-25 04:58:40,407: ============================================================
2022-07-25 04:59:21,025: time cost, forward:0.12391833638435823, backward:0.09656757510858298, data cost:0.18595342944210838 
2022-07-25 04:59:21,026: ============================================================
2022-07-25 04:59:21,026: Epoch 17/25 Batch 7600/7662 eta: 6:55:23.559353	Training Loss1 4.6689 (4.4968)	Training Total_Loss 4.6689 (4.4968)	Training Prec@1 100.000 (99.813)	Training Prec@5 100.000 (99.940)	
2022-07-25 04:59:21,026: ============================================================
2022-07-25 04:59:48,161: Epoch 17/25 Batch 7663/7662 eta: 6:54:57.969232	Training Loss1 5.1957 (4.4998)	Training Total_Loss 5.1957 (4.4998)	Training Prec@1 99.609 (99.813)	Training Prec@5 99.805 (99.940)	
2022-07-25 04:59:48,162: ============================================================
2022-07-25 05:00:31,069: time cost, forward:0.12402322075583717, backward:0.09645189420141355, data cost:0.210131368251762 
2022-07-25 05:00:31,070: ============================================================
2022-07-25 05:00:31,070: Epoch 18/25 Batch 100/7662 eta: 7:17:24.613874	Training Loss1 3.7376 (3.5960)	Training Total_Loss 3.7376 (3.5960)	Training Prec@1 100.000 (99.891)	Training Prec@5 100.000 (99.963)	
2022-07-25 05:00:31,070: ============================================================
2022-07-25 05:01:11,889: time cost, forward:0.1241517821748053, backward:0.09646358202450239, data cost:0.1984238337032759 
2022-07-25 05:01:11,890: ============================================================
2022-07-25 05:01:11,890: Epoch 18/25 Batch 200/7662 eta: 6:55:39.600894	Training Loss1 3.8029 (3.5939)	Training Total_Loss 3.8029 (3.5939)	Training Prec@1 100.000 (99.901)	Training Prec@5 100.000 (99.971)	
2022-07-25 05:01:11,890: ============================================================
2022-07-25 05:01:52,690: time cost, forward:0.12413231903892696, backward:0.09650366282383335, data cost:0.19453583672692545 
2022-07-25 05:01:52,690: ============================================================
2022-07-25 05:01:52,690: Epoch 18/25 Batch 300/7662 eta: 6:54:47.001675	Training Loss1 3.9148 (3.6010)	Training Total_Loss 3.9148 (3.6010)	Training Prec@1 99.805 (99.913)	Training Prec@5 100.000 (99.977)	
2022-07-25 05:01:52,690: ============================================================
2022-07-25 05:02:33,558: time cost, forward:0.12434541850460502, backward:0.09649365647394854, data cost:0.1925767089490006 
2022-07-25 05:02:33,558: ============================================================
2022-07-25 05:02:33,559: Epoch 18/25 Batch 400/7662 eta: 6:54:47.692039	Training Loss1 3.7802 (3.6135)	Training Total_Loss 3.7802 (3.6135)	Training Prec@1 100.000 (99.909)	Training Prec@5 100.000 (99.974)	
2022-07-25 05:02:33,559: ============================================================
2022-07-25 05:03:14,417: time cost, forward:0.1243814237132101, backward:0.096514718088215, data cost:0.19144258470477943 
2022-07-25 05:03:14,417: ============================================================
2022-07-25 05:03:14,417: Epoch 18/25 Batch 500/7662 eta: 6:54:00.813418	Training Loss1 4.3577 (3.6383)	Training Total_Loss 4.3577 (3.6383)	Training Prec@1 100.000 (99.908)	Training Prec@5 100.000 (99.974)	
2022-07-25 05:03:14,417: ============================================================
2022-07-25 05:03:55,240: time cost, forward:0.12434855486594378, backward:0.0965290921359309, data cost:0.1906882522500218 
2022-07-25 05:03:55,240: ============================================================
2022-07-25 05:03:55,240: Epoch 18/25 Batch 600/7662 eta: 6:52:58.373763	Training Loss1 3.9621 (3.6581)	Training Total_Loss 3.9621 (3.6581)	Training Prec@1 100.000 (99.906)	Training Prec@5 100.000 (99.974)	
2022-07-25 05:03:55,240: ============================================================
2022-07-25 05:04:36,057: time cost, forward:0.12432940187031279, backward:0.09651860283509174, data cost:0.1901426264144832 
2022-07-25 05:04:36,058: ============================================================
2022-07-25 05:04:36,058: Epoch 18/25 Batch 700/7662 eta: 6:52:14.252204	Training Loss1 3.7647 (3.6818)	Training Total_Loss 3.7647 (3.6818)	Training Prec@1 100.000 (99.907)	Training Prec@5 100.000 (99.973)	
2022-07-25 05:04:36,058: ============================================================
2022-07-25 05:05:16,839: time cost, forward:0.12427168823452259, backward:0.09651280523689279, data cost:0.18971277506688658 
2022-07-25 05:05:16,840: ============================================================
2022-07-25 05:05:16,840: Epoch 18/25 Batch 800/7662 eta: 6:51:11.896964	Training Loss1 3.7155 (3.7007)	Training Total_Loss 3.7155 (3.7007)	Training Prec@1 100.000 (99.903)	Training Prec@5 100.000 (99.971)	
2022-07-25 05:05:16,840: ============================================================
2022-07-25 05:05:57,521: time cost, forward:0.12423156206812026, backward:0.09651149605484773, data cost:0.1892835826046342 
2022-07-25 05:05:57,521: ============================================================
2022-07-25 05:05:57,521: Epoch 18/25 Batch 900/7662 eta: 6:49:30.369242	Training Loss1 3.7331 (3.7204)	Training Total_Loss 3.7331 (3.7204)	Training Prec@1 99.805 (99.900)	Training Prec@5 100.000 (99.970)	
2022-07-25 05:05:57,521: ============================================================
2022-07-25 05:06:38,247: time cost, forward:0.12421814672223798, backward:0.09651087783836387, data cost:0.18896585708862548 
2022-07-25 05:06:38,247: ============================================================
2022-07-25 05:06:38,247: Epoch 18/25 Batch 1000/7662 eta: 6:49:16.563738	Training Loss1 4.1656 (3.7414)	Training Total_Loss 4.1656 (3.7414)	Training Prec@1 99.609 (99.897)	Training Prec@5 99.805 (99.970)	
2022-07-25 05:06:38,247: ============================================================
2022-07-25 05:07:19,019: time cost, forward:0.12423222904535074, backward:0.09651135443773348, data cost:0.18872226271659706 
2022-07-25 05:07:19,019: ============================================================
2022-07-25 05:07:19,020: Epoch 18/25 Batch 1100/7662 eta: 6:49:03.723967	Training Loss1 3.7600 (3.7588)	Training Total_Loss 3.7600 (3.7588)	Training Prec@1 100.000 (99.897)	Training Prec@5 100.000 (99.969)	
2022-07-25 05:07:19,020: ============================================================
2022-07-25 05:07:59,799: time cost, forward:0.12423892136510956, backward:0.0965044275734005, data cost:0.18853725146213304 
2022-07-25 05:07:59,799: ============================================================
2022-07-25 05:07:59,799: Epoch 18/25 Batch 1200/7662 eta: 6:48:27.333349	Training Loss1 3.9853 (3.7799)	Training Total_Loss 3.9853 (3.7799)	Training Prec@1 99.805 (99.896)	Training Prec@5 100.000 (99.968)	
2022-07-25 05:07:59,799: ============================================================
2022-07-25 05:08:40,566: time cost, forward:0.12422636786821349, backward:0.0965036980641448, data cost:0.1883852483677442 
2022-07-25 05:08:40,566: ============================================================
2022-07-25 05:08:40,566: Epoch 18/25 Batch 1300/7662 eta: 6:47:39.101271	Training Loss1 4.4716 (3.8000)	Training Total_Loss 4.4716 (3.8000)	Training Prec@1 99.805 (99.895)	Training Prec@5 100.000 (99.967)	
2022-07-25 05:08:40,567: ============================================================
2022-07-25 05:09:21,321: time cost, forward:0.12421606658951907, backward:0.09649632878606877, data cost:0.18823924143029758 
2022-07-25 05:09:21,321: ============================================================
2022-07-25 05:09:21,321: Epoch 18/25 Batch 1400/7662 eta: 6:46:50.953301	Training Loss1 4.6367 (3.8167)	Training Total_Loss 4.6367 (3.8167)	Training Prec@1 99.414 (99.892)	Training Prec@5 99.805 (99.966)	
2022-07-25 05:09:21,322: ============================================================
2022-07-25 05:10:01,954: time cost, forward:0.12418768245272035, backward:0.09649059754995762, data cost:0.18806195052326957 
2022-07-25 05:10:01,954: ============================================================
2022-07-25 05:10:01,954: Epoch 18/25 Batch 1500/7662 eta: 6:44:57.202605	Training Loss1 4.1877 (3.8356)	Training Total_Loss 4.1877 (3.8356)	Training Prec@1 99.805 (99.891)	Training Prec@5 99.805 (99.964)	
2022-07-25 05:10:01,954: ============================================================
2022-07-25 05:10:42,604: time cost, forward:0.12415849812109818, backward:0.0964958426205347, data cost:0.18791475961027926 
2022-07-25 05:10:42,604: ============================================================
2022-07-25 05:10:42,604: Epoch 18/25 Batch 1600/7662 eta: 6:44:26.818601	Training Loss1 4.1714 (3.8552)	Training Total_Loss 4.1714 (3.8552)	Training Prec@1 99.805 (99.890)	Training Prec@5 100.000 (99.964)	
2022-07-25 05:10:42,604: ============================================================
2022-07-25 05:11:23,319: time cost, forward:0.12415907044772753, backward:0.09649884132443631, data cost:0.18779753768633506 
2022-07-25 05:11:23,319: ============================================================
2022-07-25 05:11:23,319: Epoch 18/25 Batch 1700/7662 eta: 6:44:25.011000	Training Loss1 3.8914 (3.8721)	Training Total_Loss 3.8914 (3.8721)	Training Prec@1 99.805 (99.890)	Training Prec@5 100.000 (99.964)	
2022-07-25 05:11:23,319: ============================================================
2022-07-25 05:12:04,015: time cost, forward:0.1241487908058527, backward:0.09650451915670992, data cost:0.18769169622424445 
2022-07-25 05:12:04,015: ============================================================
2022-07-25 05:12:04,016: Epoch 18/25 Batch 1800/7662 eta: 6:43:33.022874	Training Loss1 4.1284 (3.8895)	Training Total_Loss 4.1284 (3.8895)	Training Prec@1 99.805 (99.888)	Training Prec@5 100.000 (99.963)	
2022-07-25 05:12:04,016: ============================================================
2022-07-25 05:12:44,708: time cost, forward:0.1241452788101365, backward:0.09650712706278097, data cost:0.18759185894970645 
2022-07-25 05:12:44,708: ============================================================
2022-07-25 05:12:44,709: Epoch 18/25 Batch 1900/7662 eta: 6:42:50.409927	Training Loss1 3.7999 (3.9073)	Training Total_Loss 3.7999 (3.9073)	Training Prec@1 99.805 (99.886)	Training Prec@5 100.000 (99.963)	
2022-07-25 05:12:44,709: ============================================================
2022-07-25 05:13:25,556: time cost, forward:0.12415745199889526, backward:0.09650678882722917, data cost:0.18755990901906947 
2022-07-25 05:13:25,557: ============================================================
2022-07-25 05:13:25,557: Epoch 18/25 Batch 2000/7662 eta: 6:43:41.729635	Training Loss1 4.3518 (3.9229)	Training Total_Loss 4.3518 (3.9229)	Training Prec@1 100.000 (99.886)	Training Prec@5 100.000 (99.963)	
2022-07-25 05:13:25,557: ============================================================
2022-07-25 05:14:06,439: time cost, forward:0.1241566202309996, backward:0.09650838267184145, data cost:0.18755786926647547 
2022-07-25 05:14:06,440: ============================================================
2022-07-25 05:14:06,440: Epoch 18/25 Batch 2100/7662 eta: 6:43:21.544028	Training Loss1 4.1486 (3.9410)	Training Total_Loss 4.1486 (3.9410)	Training Prec@1 100.000 (99.884)	Training Prec@5 100.000 (99.963)	
2022-07-25 05:14:06,440: ============================================================
2022-07-25 05:14:47,265: time cost, forward:0.12415968499003675, backward:0.09651032888439363, data cost:0.18752992570589974 
2022-07-25 05:14:47,265: ============================================================
2022-07-25 05:14:47,265: Epoch 18/25 Batch 2200/7662 eta: 6:42:06.734508	Training Loss1 4.4120 (3.9570)	Training Total_Loss 4.4120 (3.9570)	Training Prec@1 99.805 (99.883)	Training Prec@5 100.000 (99.963)	
2022-07-25 05:14:47,265: ============================================================
2022-07-25 05:15:28,078: time cost, forward:0.12415762308526423, backward:0.09650978029889094, data cost:0.18750713793491997 
2022-07-25 05:15:28,078: ============================================================
2022-07-25 05:15:28,079: Epoch 18/25 Batch 2300/7662 eta: 6:41:18.529563	Training Loss1 4.0685 (3.9715)	Training Total_Loss 4.0685 (3.9715)	Training Prec@1 99.414 (99.881)	Training Prec@5 99.609 (99.962)	
2022-07-25 05:15:28,079: ============================================================
2022-07-25 05:16:08,784: time cost, forward:0.12414904612707764, backward:0.09651208142530625, data cost:0.1874456625274938 
2022-07-25 05:16:08,784: ============================================================
2022-07-25 05:16:08,785: Epoch 18/25 Batch 2400/7662 eta: 6:39:34.561057	Training Loss1 4.5115 (3.9850)	Training Total_Loss 4.5115 (3.9850)	Training Prec@1 99.805 (99.880)	Training Prec@5 99.805 (99.961)	
2022-07-25 05:16:08,785: ============================================================
2022-07-25 05:16:49,587: time cost, forward:0.12415990661553929, backward:0.09651039342204777, data cost:0.18741346054336652 
2022-07-25 05:16:49,588: ============================================================
2022-07-25 05:16:49,588: Epoch 18/25 Batch 2500/7662 eta: 6:39:51.147085	Training Loss1 4.4333 (3.9985)	Training Total_Loss 4.4333 (3.9985)	Training Prec@1 100.000 (99.879)	Training Prec@5 100.000 (99.962)	
2022-07-25 05:16:49,588: ============================================================
2022-07-25 05:17:30,368: time cost, forward:0.1241559957531426, backward:0.09651302511575544, data cost:0.18738384722012105 
2022-07-25 05:17:30,368: ============================================================
2022-07-25 05:17:30,368: Epoch 18/25 Batch 2600/7662 eta: 6:38:57.002258	Training Loss1 4.1495 (4.0130)	Training Total_Loss 4.1495 (4.0130)	Training Prec@1 100.000 (99.877)	Training Prec@5 100.000 (99.962)	
2022-07-25 05:17:30,369: ============================================================
2022-07-25 05:18:11,159: time cost, forward:0.12414879549781938, backward:0.09651318264254909, data cost:0.18736065631002882 
2022-07-25 05:18:11,159: ============================================================
2022-07-25 05:18:11,159: Epoch 18/25 Batch 2700/7662 eta: 6:38:22.021675	Training Loss1 4.2239 (4.0270)	Training Total_Loss 4.2239 (4.0270)	Training Prec@1 99.805 (99.876)	Training Prec@5 100.000 (99.962)	
2022-07-25 05:18:11,159: ============================================================
2022-07-25 05:18:51,829: time cost, forward:0.12413367325597766, backward:0.09651964636690577, data cost:0.18730499694159133 
2022-07-25 05:18:51,829: ============================================================
2022-07-25 05:18:51,829: Epoch 18/25 Batch 2800/7662 eta: 6:36:30.853234	Training Loss1 4.5702 (4.0401)	Training Total_Loss 4.5702 (4.0401)	Training Prec@1 100.000 (99.875)	Training Prec@5 100.000 (99.961)	
2022-07-25 05:18:51,829: ============================================================
2022-07-25 05:19:32,524: time cost, forward:0.12412384289139178, backward:0.09652547739258549, data cost:0.1872563615425902 
2022-07-25 05:19:32,524: ============================================================
2022-07-25 05:19:32,524: Epoch 18/25 Batch 2900/7662 eta: 6:36:04.552740	Training Loss1 4.0697 (4.0544)	Training Total_Loss 4.0697 (4.0544)	Training Prec@1 99.805 (99.873)	Training Prec@5 100.000 (99.960)	
2022-07-25 05:19:32,524: ============================================================
2022-07-25 05:20:13,259: time cost, forward:0.12411527905554802, backward:0.09652980123610845, data cost:0.18722541978574667 
2022-07-25 05:20:13,259: ============================================================
2022-07-25 05:20:13,260: Epoch 18/25 Batch 3000/7662 eta: 6:35:47.646489	Training Loss1 4.6705 (4.0676)	Training Total_Loss 4.6705 (4.0676)	Training Prec@1 100.000 (99.873)	Training Prec@5 100.000 (99.960)	
2022-07-25 05:20:13,260: ============================================================
2022-07-25 05:20:54,003: time cost, forward:0.12411806274899055, backward:0.0965342744006846, data cost:0.18718426394516438 
2022-07-25 05:20:54,004: ============================================================
2022-07-25 05:20:54,004: Epoch 18/25 Batch 3100/7662 eta: 6:35:11.906925	Training Loss1 4.1060 (4.0807)	Training Total_Loss 4.1060 (4.0807)	Training Prec@1 99.805 (99.871)	Training Prec@5 100.000 (99.959)	
2022-07-25 05:20:54,004: ============================================================
2022-07-25 05:21:34,683: time cost, forward:0.12411218913281921, backward:0.09654022202189172, data cost:0.18713629465618892 
2022-07-25 05:21:34,683: ============================================================
2022-07-25 05:21:34,683: Epoch 18/25 Batch 3200/7662 eta: 6:33:53.513215	Training Loss1 4.7295 (4.0917)	Training Total_Loss 4.7295 (4.0917)	Training Prec@1 100.000 (99.870)	Training Prec@5 100.000 (99.958)	
2022-07-25 05:21:34,683: ============================================================
2022-07-25 05:22:15,332: time cost, forward:0.12410049049664208, backward:0.0965419249955218, data cost:0.1870919598634043 
2022-07-25 05:22:15,332: ============================================================
2022-07-25 05:22:15,332: Epoch 18/25 Batch 3300/7662 eta: 6:32:55.154443	Training Loss1 4.4017 (4.1048)	Training Total_Loss 4.4017 (4.1048)	Training Prec@1 100.000 (99.868)	Training Prec@5 100.000 (99.958)	
2022-07-25 05:22:15,332: ============================================================
2022-07-25 05:22:55,992: time cost, forward:0.12409455792347661, backward:0.0965412851991847, data cost:0.1870502471643253 
2022-07-25 05:22:55,992: ============================================================
2022-07-25 05:22:55,993: Epoch 18/25 Batch 3400/7662 eta: 6:32:21.205297	Training Loss1 4.2690 (4.1169)	Training Total_Loss 4.2690 (4.1169)	Training Prec@1 99.805 (99.867)	Training Prec@5 100.000 (99.957)	
2022-07-25 05:22:55,993: ============================================================
2022-07-25 05:23:36,632: time cost, forward:0.12408840816407314, backward:0.09654027927122855, data cost:0.18700581961067855 
2022-07-25 05:23:36,632: ============================================================
2022-07-25 05:23:36,633: Epoch 18/25 Batch 3500/7662 eta: 6:31:28.624934	Training Loss1 4.5019 (4.1277)	Training Total_Loss 4.5019 (4.1277)	Training Prec@1 99.609 (99.865)	Training Prec@5 99.805 (99.957)	
2022-07-25 05:23:36,633: ============================================================
2022-07-25 05:24:17,273: time cost, forward:0.12407852510970048, backward:0.09654077300431828, data cost:0.1869646260128249 
2022-07-25 05:24:17,273: ============================================================
2022-07-25 05:24:17,273: Epoch 18/25 Batch 3600/7662 eta: 6:30:48.565982	Training Loss1 4.3966 (4.1392)	Training Total_Loss 4.3966 (4.1392)	Training Prec@1 99.805 (99.864)	Training Prec@5 100.000 (99.956)	
2022-07-25 05:24:17,273: ============================================================
2022-07-25 05:24:57,966: time cost, forward:0.12407176982521785, backward:0.09654095547364898, data cost:0.18694049037769375 
2022-07-25 05:24:57,966: ============================================================
2022-07-25 05:24:57,966: Epoch 18/25 Batch 3700/7662 eta: 6:30:37.833415	Training Loss1 4.4123 (4.1511)	Training Total_Loss 4.4123 (4.1511)	Training Prec@1 99.609 (99.862)	Training Prec@5 100.000 (99.955)	
2022-07-25 05:24:57,966: ============================================================
2022-07-25 05:25:38,717: time cost, forward:0.12406461638631115, backward:0.0965418749716634, data cost:0.18692858955300962 
2022-07-25 05:25:38,717: ============================================================
2022-07-25 05:25:38,717: Epoch 18/25 Batch 3800/7662 eta: 6:30:30.466990	Training Loss1 4.6200 (4.1610)	Training Total_Loss 4.6200 (4.1610)	Training Prec@1 100.000 (99.862)	Training Prec@5 100.000 (99.956)	
2022-07-25 05:25:38,717: ============================================================
2022-07-25 05:26:19,514: time cost, forward:0.12406670016855972, backward:0.09654202409877811, data cost:0.1869192569186731 
2022-07-25 05:26:19,514: ============================================================
2022-07-25 05:26:19,514: Epoch 18/25 Batch 3900/7662 eta: 6:30:16.399106	Training Loss1 4.8312 (4.1717)	Training Total_Loss 4.8312 (4.1717)	Training Prec@1 99.805 (99.861)	Training Prec@5 99.805 (99.956)	
2022-07-25 05:26:19,514: ============================================================
2022-07-25 05:27:00,259: time cost, forward:0.12406275903740416, backward:0.09654165047590481, data cost:0.18690863142135172 
2022-07-25 05:27:00,260: ============================================================
2022-07-25 05:27:00,260: Epoch 18/25 Batch 4000/7662 eta: 6:29:06.058197	Training Loss1 4.7093 (4.1816)	Training Total_Loss 4.7093 (4.1816)	Training Prec@1 99.805 (99.860)	Training Prec@5 100.000 (99.955)	
2022-07-25 05:27:00,260: ============================================================
2022-07-25 05:27:41,099: time cost, forward:0.12406347815250007, backward:0.09654071511917506, data cost:0.18691478952834537 
2022-07-25 05:27:41,099: ============================================================
2022-07-25 05:27:41,100: Epoch 18/25 Batch 4100/7662 eta: 6:29:19.096973	Training Loss1 4.8288 (4.1916)	Training Total_Loss 4.8288 (4.1916)	Training Prec@1 99.805 (99.859)	Training Prec@5 100.000 (99.955)	
2022-07-25 05:27:41,100: ============================================================
2022-07-25 05:28:21,918: time cost, forward:0.12406710858400676, backward:0.09654071541677403, data cost:0.18691802439334193 
2022-07-25 05:28:21,918: ============================================================
2022-07-25 05:28:21,918: Epoch 18/25 Batch 4200/7662 eta: 6:28:26.322200	Training Loss1 5.0651 (4.2019)	Training Total_Loss 5.0651 (4.2019)	Training Prec@1 99.609 (99.857)	Training Prec@5 100.000 (99.954)	
2022-07-25 05:28:21,919: ============================================================
2022-07-25 05:29:02,694: time cost, forward:0.12406642150257764, backward:0.09654047572909469, data cost:0.18691288407222148 
2022-07-25 05:29:02,694: ============================================================
2022-07-25 05:29:02,695: Epoch 18/25 Batch 4300/7662 eta: 6:27:21.177860	Training Loss1 4.7025 (4.2108)	Training Total_Loss 4.7025 (4.2108)	Training Prec@1 99.609 (99.856)	Training Prec@5 99.805 (99.954)	
2022-07-25 05:29:02,695: ============================================================
2022-07-25 05:29:43,323: time cost, forward:0.12405970931784839, backward:0.09653944230995604, data cost:0.18688180615181652 
2022-07-25 05:29:43,323: ============================================================
2022-07-25 05:29:43,323: Epoch 18/25 Batch 4400/7662 eta: 6:25:16.580225	Training Loss1 4.5122 (4.2198)	Training Total_Loss 4.5122 (4.2198)	Training Prec@1 100.000 (99.855)	Training Prec@5 100.000 (99.954)	
2022-07-25 05:29:43,324: ============================================================
2022-07-25 05:30:23,964: time cost, forward:0.12405564435775292, backward:0.0965375707901486, data cost:0.1868527555603482 
2022-07-25 05:30:23,964: ============================================================
2022-07-25 05:30:23,964: Epoch 18/25 Batch 4500/7662 eta: 6:24:42.678937	Training Loss1 4.2908 (4.2285)	Training Total_Loss 4.2908 (4.2285)	Training Prec@1 99.805 (99.855)	Training Prec@5 100.000 (99.953)	
2022-07-25 05:30:23,964: ============================================================
2022-07-25 05:31:04,643: time cost, forward:0.12405912169530926, backward:0.09653587345455905, data cost:0.1868239006391684 
2022-07-25 05:31:04,644: ============================================================
2022-07-25 05:31:04,644: Epoch 18/25 Batch 4600/7662 eta: 6:24:24.189187	Training Loss1 4.7840 (4.2386)	Training Total_Loss 4.7840 (4.2386)	Training Prec@1 100.000 (99.853)	Training Prec@5 100.000 (99.953)	
2022-07-25 05:31:04,644: ============================================================
2022-07-25 05:31:45,278: time cost, forward:0.12405290474762788, backward:0.09653615758733106, data cost:0.18679647685162792 
2022-07-25 05:31:45,278: ============================================================
2022-07-25 05:31:45,278: Epoch 18/25 Batch 4700/7662 eta: 6:23:17.843480	Training Loss1 4.3964 (4.2471)	Training Total_Loss 4.3964 (4.2471)	Training Prec@1 99.414 (99.853)	Training Prec@5 100.000 (99.952)	
2022-07-25 05:31:45,278: ============================================================
2022-07-25 05:32:25,885: time cost, forward:0.12404343420626049, backward:0.09653613636408728, data cost:0.18676802858160693 
2022-07-25 05:32:25,885: ============================================================
2022-07-25 05:32:25,886: Epoch 18/25 Batch 4800/7662 eta: 6:22:21.960185	Training Loss1 5.1485 (4.2548)	Training Total_Loss 5.1485 (4.2548)	Training Prec@1 100.000 (99.851)	Training Prec@5 100.000 (99.952)	
2022-07-25 05:32:25,886: ============================================================
2022-07-25 05:33:06,519: time cost, forward:0.12403688009331776, backward:0.09653491267235237, data cost:0.1867445823391449 
2022-07-25 05:33:06,519: ============================================================
2022-07-25 05:33:06,519: Epoch 18/25 Batch 4900/7662 eta: 6:21:55.991954	Training Loss1 4.8979 (4.2624)	Training Total_Loss 4.8979 (4.2624)	Training Prec@1 99.805 (99.850)	Training Prec@5 99.805 (99.951)	
2022-07-25 05:33:06,519: ============================================================
2022-07-25 05:33:47,147: time cost, forward:0.12402869868598049, backward:0.09653539442019263, data cost:0.1867218364308085 
2022-07-25 05:33:47,147: ============================================================
2022-07-25 05:33:47,147: Epoch 18/25 Batch 5000/7662 eta: 6:21:12.371614	Training Loss1 4.7688 (4.2711)	Training Total_Loss 4.7688 (4.2711)	Training Prec@1 99.805 (99.848)	Training Prec@5 99.805 (99.950)	
2022-07-25 05:33:47,147: ============================================================
2022-07-25 05:34:27,778: time cost, forward:0.12402245376034797, backward:0.09653586849415388, data cost:0.1866987129360303 
2022-07-25 05:34:27,778: ============================================================
2022-07-25 05:34:27,778: Epoch 18/25 Batch 5100/7662 eta: 6:20:33.515640	Training Loss1 4.7126 (4.2795)	Training Total_Loss 4.7126 (4.2795)	Training Prec@1 100.000 (99.846)	Training Prec@5 100.000 (99.950)	
2022-07-25 05:34:27,778: ============================================================
2022-07-25 05:35:08,425: time cost, forward:0.12401906369534518, backward:0.09653450672753523, data cost:0.18667832964497086 
2022-07-25 05:35:08,426: ============================================================
2022-07-25 05:35:08,426: Epoch 18/25 Batch 5200/7662 eta: 6:20:02.032243	Training Loss1 4.6342 (4.2891)	Training Total_Loss 4.6342 (4.2891)	Training Prec@1 100.000 (99.846)	Training Prec@5 100.000 (99.949)	
2022-07-25 05:35:08,426: ============================================================
2022-07-25 05:35:49,059: time cost, forward:0.1240149732130072, backward:0.09653459231478692, data cost:0.18665593834412866 
2022-07-25 05:35:49,059: ============================================================
2022-07-25 05:35:49,059: Epoch 18/25 Batch 5300/7662 eta: 6:19:13.653864	Training Loss1 4.5119 (4.2964)	Training Total_Loss 4.5119 (4.2964)	Training Prec@1 99.414 (99.845)	Training Prec@5 100.000 (99.949)	
2022-07-25 05:35:49,060: ============================================================
2022-07-25 05:36:29,840: time cost, forward:0.12401102140758363, backward:0.0965549467581028, data cost:0.18664132870884156 
2022-07-25 05:36:29,840: ============================================================
2022-07-25 05:36:29,841: Epoch 18/25 Batch 5400/7662 eta: 6:19:55.406555	Training Loss1 4.7165 (4.3034)	Training Total_Loss 4.7165 (4.3034)	Training Prec@1 99.609 (99.844)	Training Prec@5 100.000 (99.949)	
2022-07-25 05:36:29,841: ============================================================
2022-07-25 05:37:10,611: time cost, forward:0.12400580571117911, backward:0.09657875393321025, data cost:0.18662169136162518 
2022-07-25 05:37:10,612: ============================================================
2022-07-25 05:37:10,612: Epoch 18/25 Batch 5500/7662 eta: 6:19:09.138093	Training Loss1 4.7573 (4.3110)	Training Total_Loss 4.7573 (4.3110)	Training Prec@1 99.609 (99.843)	Training Prec@5 100.000 (99.949)	
2022-07-25 05:37:10,612: ============================================================
2022-07-25 05:37:51,210: time cost, forward:0.12399722793566838, backward:0.0965767178413676, data cost:0.18660157500558464 
2022-07-25 05:37:51,210: ============================================================
2022-07-25 05:37:51,210: Epoch 18/25 Batch 5600/7662 eta: 6:16:52.249997	Training Loss1 4.3635 (4.3188)	Training Total_Loss 4.3635 (4.3188)	Training Prec@1 99.609 (99.841)	Training Prec@5 100.000 (99.948)	
2022-07-25 05:37:51,211: ============================================================
2022-07-25 05:38:31,875: time cost, forward:0.12399772904090325, backward:0.09657407869558875, data cost:0.18658544306463057 
2022-07-25 05:38:31,875: ============================================================
2022-07-25 05:38:31,875: Epoch 18/25 Batch 5700/7662 eta: 6:16:48.250680	Training Loss1 4.4123 (4.3259)	Training Total_Loss 4.4123 (4.3259)	Training Prec@1 100.000 (99.840)	Training Prec@5 100.000 (99.948)	
2022-07-25 05:38:31,875: ============================================================
2022-07-25 05:39:12,570: time cost, forward:0.12400185023737192, backward:0.09657106298396333, data cost:0.18657225566725213 
2022-07-25 05:39:12,570: ============================================================
2022-07-25 05:39:12,571: Epoch 18/25 Batch 5800/7662 eta: 6:16:24.786870	Training Loss1 5.0322 (4.3337)	Training Total_Loss 5.0322 (4.3337)	Training Prec@1 100.000 (99.840)	Training Prec@5 100.000 (99.948)	
2022-07-25 05:39:12,571: ============================================================
2022-07-25 05:39:53,252: time cost, forward:0.12400211425408769, backward:0.09656982685392398, data cost:0.1865590489664448 
2022-07-25 05:39:53,252: ============================================================
2022-07-25 05:39:53,252: Epoch 18/25 Batch 5900/7662 eta: 6:15:36.425627	Training Loss1 5.1029 (4.3409)	Training Total_Loss 5.1029 (4.3409)	Training Prec@1 99.805 (99.838)	Training Prec@5 100.000 (99.947)	
2022-07-25 05:39:53,252: ============================================================
2022-07-25 05:40:33,980: time cost, forward:0.12400817890965277, backward:0.096568444785048, data cost:0.18654813148872437 
2022-07-25 05:40:33,980: ============================================================
2022-07-25 05:40:33,980: Epoch 18/25 Batch 6000/7662 eta: 6:15:21.353286	Training Loss1 4.8817 (4.3481)	Training Total_Loss 4.8817 (4.3481)	Training Prec@1 99.805 (99.837)	Training Prec@5 100.000 (99.947)	
2022-07-25 05:40:33,980: ============================================================
2022-07-25 05:41:14,665: time cost, forward:0.12400718829068498, backward:0.09656964682969799, data cost:0.18653529990909726 
2022-07-25 05:41:14,666: ============================================================
2022-07-25 05:41:14,666: Epoch 18/25 Batch 6100/7662 eta: 6:14:17.282243	Training Loss1 4.6337 (4.3550)	Training Total_Loss 4.6337 (4.3550)	Training Prec@1 100.000 (99.836)	Training Prec@5 100.000 (99.946)	
2022-07-25 05:41:14,666: ============================================================
2022-07-25 05:41:55,424: time cost, forward:0.12401689189271516, backward:0.09656887078289063, data cost:0.18652558469026198 
2022-07-25 05:41:55,425: ============================================================
2022-07-25 05:41:55,425: Epoch 18/25 Batch 6200/7662 eta: 6:14:16.907448	Training Loss1 4.9634 (4.3609)	Training Total_Loss 4.9634 (4.3609)	Training Prec@1 99.805 (99.835)	Training Prec@5 100.000 (99.946)	
2022-07-25 05:41:55,425: ============================================================
2022-07-25 05:42:36,161: time cost, forward:0.12402159854672716, backward:0.09656811888434808, data cost:0.1865179919500089 
2022-07-25 05:42:36,162: ============================================================
2022-07-25 05:42:36,162: Epoch 18/25 Batch 6300/7662 eta: 6:13:24.096021	Training Loss1 5.2549 (4.3676)	Training Total_Loss 5.2549 (4.3676)	Training Prec@1 99.609 (99.835)	Training Prec@5 100.000 (99.946)	
2022-07-25 05:42:36,162: ============================================================
2022-07-25 05:43:16,854: time cost, forward:0.1240229182251544, backward:0.09656813662952698, data cost:0.1865067238695157 
2022-07-25 05:43:16,854: ============================================================
2022-07-25 05:43:16,854: Epoch 18/25 Batch 6400/7662 eta: 6:12:18.841897	Training Loss1 4.7758 (4.3738)	Training Total_Loss 4.7758 (4.3738)	Training Prec@1 99.805 (99.834)	Training Prec@5 100.000 (99.946)	
2022-07-25 05:43:16,854: ============================================================
2022-07-25 05:43:57,488: time cost, forward:0.12401859898588477, backward:0.09656820423439073, data cost:0.1864926392050005 
2022-07-25 05:43:57,488: ============================================================
2022-07-25 05:43:57,488: Epoch 18/25 Batch 6500/7662 eta: 6:11:06.478488	Training Loss1 4.2858 (4.3798)	Training Total_Loss 4.2858 (4.3798)	Training Prec@1 100.000 (99.833)	Training Prec@5 100.000 (99.945)	
2022-07-25 05:43:57,489: ============================================================
2022-07-25 05:44:38,129: time cost, forward:0.1240146009104417, backward:0.09656721928893192, data cost:0.18648074803740386 
2022-07-25 05:44:38,130: ============================================================
2022-07-25 05:44:38,130: Epoch 18/25 Batch 6600/7662 eta: 6:10:29.604834	Training Loss1 4.3302 (4.3862)	Training Total_Loss 4.3302 (4.3862)	Training Prec@1 100.000 (99.832)	Training Prec@5 100.000 (99.945)	
2022-07-25 05:44:38,130: ============================================================
2022-07-25 05:45:18,776: time cost, forward:0.1240106220120084, backward:0.09656649590392738, data cost:0.18646973068099498 
2022-07-25 05:45:18,777: ============================================================
2022-07-25 05:45:18,777: Epoch 18/25 Batch 6700/7662 eta: 6:09:51.977025	Training Loss1 4.3749 (4.3919)	Training Total_Loss 4.3749 (4.3919)	Training Prec@1 99.805 (99.831)	Training Prec@5 100.000 (99.945)	
2022-07-25 05:45:18,777: ============================================================
2022-07-25 05:45:59,426: time cost, forward:0.12400589116900647, backward:0.09656797806854406, data cost:0.18645835241897613 
2022-07-25 05:45:59,427: ============================================================
2022-07-25 05:45:59,427: Epoch 18/25 Batch 6800/7662 eta: 6:09:13.042636	Training Loss1 5.0336 (4.3984)	Training Total_Loss 5.0336 (4.3984)	Training Prec@1 99.805 (99.830)	Training Prec@5 100.000 (99.944)	
2022-07-25 05:45:59,427: ============================================================
2022-07-25 05:46:40,078: time cost, forward:0.12400101678823108, backward:0.09657073770852898, data cost:0.18644645819198846 
2022-07-25 05:46:40,078: ============================================================
2022-07-25 05:46:40,079: Epoch 18/25 Batch 6900/7662 eta: 6:08:33.365567	Training Loss1 4.5157 (4.4043)	Training Total_Loss 4.5157 (4.4043)	Training Prec@1 99.805 (99.829)	Training Prec@5 100.000 (99.944)	
2022-07-25 05:46:40,079: ============================================================
2022-07-25 05:47:20,722: time cost, forward:0.12399769718433418, backward:0.09657159115965323, data cost:0.18643400907209898 
2022-07-25 05:47:20,722: ============================================================
2022-07-25 05:47:20,722: Epoch 18/25 Batch 7000/7662 eta: 6:07:48.264806	Training Loss1 5.2629 (4.4101)	Training Total_Loss 5.2629 (4.4101)	Training Prec@1 100.000 (99.828)	Training Prec@5 100.000 (99.944)	
2022-07-25 05:47:20,722: ============================================================
2022-07-25 05:48:01,398: time cost, forward:0.12399636307036747, backward:0.09657321441071119, data cost:0.18642395780966103 
2022-07-25 05:48:01,398: ============================================================
2022-07-25 05:48:01,398: Epoch 18/25 Batch 7100/7662 eta: 6:07:25.166874	Training Loss1 4.8690 (4.4156)	Training Total_Loss 4.8690 (4.4156)	Training Prec@1 99.805 (99.827)	Training Prec@5 100.000 (99.944)	
2022-07-25 05:48:01,398: ============================================================
2022-07-25 05:48:42,069: time cost, forward:0.12399517613858842, backward:0.09657379590334007, data cost:0.1864144150987899 
2022-07-25 05:48:42,070: ============================================================
2022-07-25 05:48:42,070: Epoch 18/25 Batch 7200/7662 eta: 6:06:42.223720	Training Loss1 4.3740 (4.4211)	Training Total_Loss 4.3740 (4.4211)	Training Prec@1 99.805 (99.826)	Training Prec@5 100.000 (99.943)	
2022-07-25 05:48:42,070: ============================================================
2022-07-25 05:49:22,761: time cost, forward:0.1239970942232148, backward:0.09657384742039624, data cost:0.186405419258079 
2022-07-25 05:49:22,761: ============================================================
2022-07-25 05:49:22,761: Epoch 18/25 Batch 7300/7662 eta: 6:06:11.942435	Training Loss1 5.0044 (4.4271)	Training Total_Loss 5.0044 (4.4271)	Training Prec@1 100.000 (99.825)	Training Prec@5 100.000 (99.943)	
2022-07-25 05:49:22,761: ============================================================
2022-07-25 05:50:03,421: time cost, forward:0.12399465832489216, backward:0.09657405025009401, data cost:0.18639659404690193 
2022-07-25 05:50:03,421: ============================================================
2022-07-25 05:50:03,421: Epoch 18/25 Batch 7400/7662 eta: 6:05:14.714410	Training Loss1 5.3942 (4.4325)	Training Total_Loss 5.3942 (4.4325)	Training Prec@1 99.609 (99.824)	Training Prec@5 99.805 (99.943)	
2022-07-25 05:50:03,421: ============================================================
2022-07-25 05:50:44,053: time cost, forward:0.12399153525645867, backward:0.09657312348804914, data cost:0.18638640305951112 
2022-07-25 05:50:44,054: ============================================================
2022-07-25 05:50:44,054: Epoch 18/25 Batch 7500/7662 eta: 6:04:19.021610	Training Loss1 4.7486 (4.4371)	Training Total_Loss 4.7486 (4.4371)	Training Prec@1 99.609 (99.823)	Training Prec@5 100.000 (99.942)	
2022-07-25 05:50:44,054: ============================================================
2022-07-25 05:51:24,677: time cost, forward:0.123988598173332, backward:0.09657099162580025, data cost:0.1863763084818241 
2022-07-25 05:51:24,677: ============================================================
2022-07-25 05:51:24,677: Epoch 18/25 Batch 7600/7662 eta: 6:03:33.688806	Training Loss1 4.7712 (4.4420)	Training Total_Loss 4.7712 (4.4420)	Training Prec@1 99.414 (99.823)	Training Prec@5 99.609 (99.942)	
2022-07-25 05:51:24,678: ============================================================
2022-07-25 05:51:51,958: Epoch 18/25 Batch 7663/7662 eta: 6:03:08.095897	Training Loss1 4.3960 (4.4452)	Training Total_Loss 4.3960 (4.4452)	Training Prec@1 100.000 (99.822)	Training Prec@5 100.000 (99.942)	
2022-07-25 05:51:51,958: ============================================================
2022-07-25 05:52:34,286: time cost, forward:0.1241704984144731, backward:0.09642206538807262, data cost:0.2041619329741507 
2022-07-25 05:52:34,287: ============================================================
2022-07-25 05:52:34,287: Epoch 19/25 Batch 100/7662 eta: 6:17:25.789103	Training Loss1 3.8430 (3.5333)	Training Total_Loss 3.8430 (3.5333)	Training Prec@1 99.805 (99.895)	Training Prec@5 99.805 (99.963)	
2022-07-25 05:52:34,287: ============================================================
2022-07-25 05:53:15,230: time cost, forward:0.12430255976154576, backward:0.09636183479922501, data cost:0.1961847441879349 
2022-07-25 05:53:15,230: ============================================================
2022-07-25 05:53:15,230: Epoch 19/25 Batch 200/7662 eta: 6:04:38.193390	Training Loss1 3.2942 (3.5281)	Training Total_Loss 3.2942 (3.5281)	Training Prec@1 99.805 (99.897)	Training Prec@5 99.805 (99.971)	
2022-07-25 05:53:15,231: ============================================================
2022-07-25 05:53:56,113: time cost, forward:0.12428695780776416, backward:0.09636682331761388, data cost:0.19330342158824704 
2022-07-25 05:53:56,114: ============================================================
2022-07-25 05:53:56,114: Epoch 19/25 Batch 300/7662 eta: 6:03:25.095374	Training Loss1 3.5844 (3.5292)	Training Total_Loss 3.5844 (3.5292)	Training Prec@1 99.414 (99.891)	Training Prec@5 100.000 (99.969)	
2022-07-25 05:53:56,114: ============================================================
2022-07-25 05:54:37,044: time cost, forward:0.12427800938599091, backward:0.09636822081448738, data cost:0.19198661639278097 
2022-07-25 05:54:37,044: ============================================================
2022-07-25 05:54:37,044: Epoch 19/25 Batch 400/7662 eta: 6:03:09.330114	Training Loss1 4.2000 (3.5466)	Training Total_Loss 4.2000 (3.5466)	Training Prec@1 99.805 (99.898)	Training Prec@5 100.000 (99.972)	
2022-07-25 05:54:37,044: ============================================================
2022-07-25 05:55:17,974: time cost, forward:0.12431910377227233, backward:0.09636763484779007, data cost:0.19114677031675656 
2022-07-25 05:55:17,974: ============================================================
2022-07-25 05:55:17,974: Epoch 19/25 Batch 500/7662 eta: 6:02:28.114110	Training Loss1 3.5096 (3.5614)	Training Total_Loss 3.5096 (3.5614)	Training Prec@1 100.000 (99.905)	Training Prec@5 100.000 (99.973)	
2022-07-25 05:55:17,974: ============================================================
2022-07-25 05:55:58,848: time cost, forward:0.12430970855865733, backward:0.09635730776842528, data cost:0.19058159317118498 
2022-07-25 05:55:58,848: ============================================================
2022-07-25 05:55:58,848: Epoch 19/25 Batch 600/7662 eta: 6:01:17.427438	Training Loss1 3.9197 (3.5854)	Training Total_Loss 3.9197 (3.5854)	Training Prec@1 99.805 (99.906)	Training Prec@5 100.000 (99.974)	
2022-07-25 05:55:58,848: ============================================================
2022-07-25 05:56:39,581: time cost, forward:0.12429823418373032, backward:0.09637551587368115, data cost:0.18993818231236098 
2022-07-25 05:56:39,581: ============================================================
2022-07-25 05:56:39,581: Epoch 19/25 Batch 700/7662 eta: 5:59:22.155554	Training Loss1 3.7708 (3.6091)	Training Total_Loss 3.7708 (3.6091)	Training Prec@1 99.805 (99.904)	Training Prec@5 100.000 (99.971)	
2022-07-25 05:56:39,581: ============================================================
2022-07-25 05:57:20,349: time cost, forward:0.12426487137289609, backward:0.09638401295276398, data cost:0.1895326866823084 
2022-07-25 05:57:20,350: ============================================================
2022-07-25 05:57:20,350: Epoch 19/25 Batch 800/7662 eta: 5:59:00.067759	Training Loss1 3.8659 (3.6331)	Training Total_Loss 3.8659 (3.6331)	Training Prec@1 100.000 (99.901)	Training Prec@5 100.000 (99.970)	
2022-07-25 05:57:20,350: ============================================================
2022-07-25 05:58:01,058: time cost, forward:0.12425131819006864, backward:0.09637953654279698, data cost:0.18913464445426015 
2022-07-25 05:58:01,058: ============================================================
2022-07-25 05:58:01,058: Epoch 19/25 Batch 900/7662 eta: 5:57:47.491513	Training Loss1 3.8334 (3.6524)	Training Total_Loss 3.8334 (3.6524)	Training Prec@1 100.000 (99.900)	Training Prec@5 100.000 (99.970)	
2022-07-25 05:58:01,058: ============================================================
2022-07-25 05:58:41,788: time cost, forward:0.12423086142516113, backward:0.09637926052043864, data cost:0.1888642215633297 
2022-07-25 05:58:41,788: ============================================================
2022-07-25 05:58:41,788: Epoch 19/25 Batch 1000/7662 eta: 5:57:18.313566	Training Loss1 3.7650 (3.6741)	Training Total_Loss 3.7650 (3.6741)	Training Prec@1 99.805 (99.900)	Training Prec@5 99.805 (99.969)	
2022-07-25 05:58:41,788: ============================================================
2022-07-25 05:59:22,511: time cost, forward:0.12421100588686582, backward:0.09638454504073805, data cost:0.1886140054957882 
2022-07-25 05:59:22,511: ============================================================
2022-07-25 05:59:22,511: Epoch 19/25 Batch 1100/7662 eta: 5:56:33.900723	Training Loss1 3.6574 (3.6958)	Training Total_Loss 3.6574 (3.6958)	Training Prec@1 99.805 (99.899)	Training Prec@5 100.000 (99.969)	
2022-07-25 05:59:22,511: ============================================================
2022-07-25 06:00:03,204: time cost, forward:0.1241994621954529, backward:0.09639350069473941, data cost:0.18838326467684252 
2022-07-25 06:00:03,204: ============================================================
2022-07-25 06:00:03,205: Epoch 19/25 Batch 1200/7662 eta: 5:55:37.559613	Training Loss1 3.8254 (3.7150)	Training Total_Loss 3.8254 (3.7150)	Training Prec@1 100.000 (99.898)	Training Prec@5 100.000 (99.969)	
2022-07-25 06:00:03,205: ============================================================
2022-07-25 06:00:43,893: time cost, forward:0.1241937103961595, backward:0.09640249001970651, data cost:0.18817360443367787 
2022-07-25 06:00:43,893: ============================================================
2022-07-25 06:00:43,893: Epoch 19/25 Batch 1300/7662 eta: 5:54:54.444850	Training Loss1 3.8014 (3.7349)	Training Total_Loss 3.8014 (3.7349)	Training Prec@1 100.000 (99.898)	Training Prec@5 100.000 (99.969)	
2022-07-25 06:00:43,893: ============================================================
2022-07-25 06:01:24,555: time cost, forward:0.12417555434777108, backward:0.09640622292355694, data cost:0.1880004204878899 
2022-07-25 06:01:24,555: ============================================================
2022-07-25 06:01:24,555: Epoch 19/25 Batch 1400/7662 eta: 5:53:59.774747	Training Loss1 4.1729 (3.7572)	Training Total_Loss 4.1729 (3.7572)	Training Prec@1 100.000 (99.896)	Training Prec@5 100.000 (99.967)	
2022-07-25 06:01:24,555: ============================================================
2022-07-25 06:02:05,215: time cost, forward:0.12416176194743843, backward:0.09641220952925322, data cost:0.18784201980193826 
2022-07-25 06:02:05,215: ============================================================
2022-07-25 06:02:05,215: Epoch 19/25 Batch 1500/7662 eta: 5:53:18.105961	Training Loss1 3.8229 (3.7746)	Training Total_Loss 3.8229 (3.7746)	Training Prec@1 100.000 (99.897)	Training Prec@5 100.000 (99.968)	
2022-07-25 06:02:05,215: ============================================================
2022-07-25 06:02:45,839: time cost, forward:0.12412994544605974, backward:0.09641286505245282, data cost:0.18770449216698318 
2022-07-25 06:02:45,840: ============================================================
2022-07-25 06:02:45,840: Epoch 19/25 Batch 1600/7662 eta: 5:52:18.967030	Training Loss1 3.9520 (3.7936)	Training Total_Loss 3.9520 (3.7936)	Training Prec@1 99.805 (99.895)	Training Prec@5 99.805 (99.968)	
2022-07-25 06:02:45,840: ============================================================
2022-07-25 06:03:26,471: time cost, forward:0.1241080259982104, backward:0.09641232751551061, data cost:0.1875753854568598 
2022-07-25 06:03:26,471: ============================================================
2022-07-25 06:03:26,471: Epoch 19/25 Batch 1700/7662 eta: 5:51:41.765344	Training Loss1 4.1070 (3.8120)	Training Total_Loss 4.1070 (3.8120)	Training Prec@1 99.805 (99.894)	Training Prec@5 100.000 (99.968)	
2022-07-25 06:03:26,471: ============================================================
2022-07-25 06:04:07,153: time cost, forward:0.12410906754048948, backward:0.09641287444763014, data cost:0.18747309845907945 
2022-07-25 06:04:07,154: ============================================================
2022-07-25 06:04:07,154: Epoch 19/25 Batch 1800/7662 eta: 5:51:28.003065	Training Loss1 4.3142 (3.8299)	Training Total_Loss 4.3142 (3.8299)	Training Prec@1 99.609 (99.892)	Training Prec@5 99.609 (99.967)	
2022-07-25 06:04:07,154: ============================================================
2022-07-25 06:04:47,886: time cost, forward:0.12409899547390087, backward:0.09641648732467097, data cost:0.1874138322110048 
2022-07-25 06:04:47,886: ============================================================
2022-07-25 06:04:47,886: Epoch 19/25 Batch 1900/7662 eta: 5:51:12.858264	Training Loss1 4.2239 (3.8472)	Training Total_Loss 4.2239 (3.8472)	Training Prec@1 99.805 (99.891)	Training Prec@5 100.000 (99.967)	
2022-07-25 06:04:47,886: ============================================================
2022-07-25 06:05:28,616: time cost, forward:0.12409180197016843, backward:0.09641886067545491, data cost:0.18736165198401966 
2022-07-25 06:05:28,616: ============================================================
2022-07-25 06:05:28,616: Epoch 19/25 Batch 2000/7662 eta: 5:50:30.953607	Training Loss1 3.9053 (3.8642)	Training Total_Loss 3.9053 (3.8642)	Training Prec@1 100.000 (99.890)	Training Prec@5 100.000 (99.966)	
2022-07-25 06:05:28,616: ============================================================
2022-07-25 06:06:09,299: time cost, forward:0.12407768391722325, backward:0.09642426952854573, data cost:0.18730017944652164 
2022-07-25 06:06:09,299: ============================================================
2022-07-25 06:06:09,300: Epoch 19/25 Batch 2100/7662 eta: 5:49:26.131907	Training Loss1 4.6387 (3.8805)	Training Total_Loss 4.6387 (3.8805)	Training Prec@1 100.000 (99.889)	Training Prec@5 100.000 (99.965)	
2022-07-25 06:06:09,300: ============================================================
2022-07-25 06:06:49,911: time cost, forward:0.12405862055783273, backward:0.09642633160117975, data cost:0.1872171103385103 
2022-07-25 06:06:49,911: ============================================================
2022-07-25 06:06:49,911: Epoch 19/25 Batch 2200/7662 eta: 5:48:08.628783	Training Loss1 4.2666 (3.8967)	Training Total_Loss 4.2666 (3.8967)	Training Prec@1 100.000 (99.887)	Training Prec@5 100.000 (99.964)	
2022-07-25 06:06:49,911: ============================================================
2022-07-25 06:07:30,502: time cost, forward:0.12403448357069788, backward:0.09642690676821476, data cost:0.1871425527860518 
2022-07-25 06:07:30,502: ============================================================
2022-07-25 06:07:30,502: Epoch 19/25 Batch 2300/7662 eta: 5:47:17.269824	Training Loss1 4.1234 (3.9118)	Training Total_Loss 4.1234 (3.9118)	Training Prec@1 99.414 (99.886)	Training Prec@5 100.000 (99.964)	
2022-07-25 06:07:30,502: ============================================================
2022-07-25 06:08:11,175: time cost, forward:0.12402646290157775, backward:0.0964277749659867, data cost:0.18709373086529407 
2022-07-25 06:08:11,175: ============================================================
2022-07-25 06:08:11,175: Epoch 19/25 Batch 2400/7662 eta: 5:47:19.020361	Training Loss1 3.9746 (3.9267)	Training Total_Loss 3.9746 (3.9267)	Training Prec@1 100.000 (99.883)	Training Prec@5 100.000 (99.963)	
2022-07-25 06:08:11,176: ============================================================
2022-07-25 06:08:51,839: time cost, forward:0.12401320191086078, backward:0.09644400896955461, data cost:0.18703380447714363 
2022-07-25 06:08:51,839: ============================================================
2022-07-25 06:08:51,839: Epoch 19/25 Batch 2500/7662 eta: 5:46:33.426206	Training Loss1 4.6126 (3.9426)	Training Total_Loss 4.6126 (3.9426)	Training Prec@1 99.805 (99.882)	Training Prec@5 100.000 (99.963)	
2022-07-25 06:08:51,839: ============================================================
2022-07-25 06:09:32,705: time cost, forward:0.12401992974716133, backward:0.09649467816853716, data cost:0.18699680525048415 
2022-07-25 06:09:32,705: ============================================================
2022-07-25 06:09:32,705: Epoch 19/25 Batch 2600/7662 eta: 5:47:35.832752	Training Loss1 4.5280 (3.9561)	Training Total_Loss 4.5280 (3.9561)	Training Prec@1 99.805 (99.880)	Training Prec@5 100.000 (99.961)	
2022-07-25 06:09:32,705: ============================================================
2022-07-25 06:10:13,632: time cost, forward:0.12401825880818829, backward:0.09654472164862153, data cost:0.18698903824409407 
2022-07-25 06:10:13,633: ============================================================
2022-07-25 06:10:13,633: Epoch 19/25 Batch 2700/7662 eta: 5:47:26.566520	Training Loss1 4.0358 (3.9698)	Training Total_Loss 4.0358 (3.9698)	Training Prec@1 100.000 (99.879)	Training Prec@5 100.000 (99.962)	
2022-07-25 06:10:13,633: ============================================================
2022-07-25 06:10:54,632: time cost, forward:0.12402866507649805, backward:0.09658104558210792, data cost:0.18700514405316307 
2022-07-25 06:10:54,632: ============================================================
2022-07-25 06:10:54,633: Epoch 19/25 Batch 2800/7662 eta: 5:47:22.287946	Training Loss1 4.4217 (3.9839)	Training Total_Loss 4.4217 (3.9839)	Training Prec@1 100.000 (99.876)	Training Prec@5 100.000 (99.961)	
2022-07-25 06:10:54,633: ============================================================
2022-07-25 06:11:35,456: time cost, forward:0.124046909188188, backward:0.09658183266928214, data cost:0.1869863187415553 
2022-07-25 06:11:35,456: ============================================================
2022-07-25 06:11:35,456: Epoch 19/25 Batch 2900/7662 eta: 5:45:11.772080	Training Loss1 3.8373 (3.9951)	Training Total_Loss 3.8373 (3.9951)	Training Prec@1 100.000 (99.875)	Training Prec@5 100.000 (99.960)	
2022-07-25 06:11:35,456: ============================================================
2022-07-25 06:12:16,283: time cost, forward:0.12405644062559937, backward:0.09658239197039374, data cost:0.1869828190633399 
2022-07-25 06:12:16,283: ============================================================
2022-07-25 06:12:16,283: Epoch 19/25 Batch 3000/7662 eta: 5:44:32.823352	Training Loss1 4.6292 (4.0091)	Training Total_Loss 4.6292 (4.0091)	Training Prec@1 99.609 (99.875)	Training Prec@5 100.000 (99.960)	
2022-07-25 06:12:16,283: ============================================================
2022-07-25 06:12:57,005: time cost, forward:0.1240595189476444, backward:0.09658330592389028, data cost:0.18694890695604519 
2022-07-25 06:12:57,005: ============================================================
2022-07-25 06:12:57,006: Epoch 19/25 Batch 3100/7662 eta: 5:42:59.058068	Training Loss1 3.9813 (4.0216)	Training Total_Loss 3.9813 (4.0216)	Training Prec@1 99.609 (99.873)	Training Prec@5 99.609 (99.960)	
2022-07-25 06:12:57,006: ============================================================
2022-07-25 06:13:37,770: time cost, forward:0.12406444333426167, backward:0.09658300135052923, data cost:0.18692870518683494 
2022-07-25 06:13:37,770: ============================================================
2022-07-25 06:13:37,770: Epoch 19/25 Batch 3200/7662 eta: 5:42:39.546547	Training Loss1 4.8308 (4.0346)	Training Total_Loss 4.8308 (4.0346)	Training Prec@1 99.609 (99.871)	Training Prec@5 100.000 (99.959)	
2022-07-25 06:13:37,770: ============================================================
2022-07-25 06:14:18,531: time cost, forward:0.12406427761250173, backward:0.0965832143380592, data cost:0.18691397486545347 
2022-07-25 06:14:18,532: ============================================================
2022-07-25 06:14:18,532: Epoch 19/25 Batch 3300/7662 eta: 5:41:57.485898	Training Loss1 4.4707 (4.0470)	Training Total_Loss 4.4707 (4.0470)	Training Prec@1 100.000 (99.869)	Training Prec@5 100.000 (99.958)	
2022-07-25 06:14:18,532: ============================================================
2022-07-25 06:14:59,344: time cost, forward:0.12406629806197576, backward:0.09658155002184354, data cost:0.186913717911853 
2022-07-25 06:14:59,344: ============================================================
2022-07-25 06:14:59,344: Epoch 19/25 Batch 3400/7662 eta: 5:41:42.110749	Training Loss1 4.9120 (4.0606)	Training Total_Loss 4.9120 (4.0606)	Training Prec@1 99.805 (99.867)	Training Prec@5 100.000 (99.957)	
2022-07-25 06:14:59,344: ============================================================
2022-07-25 06:15:40,079: time cost, forward:0.12407349034287855, backward:0.09658076600300718, data cost:0.1868860457208573 
2022-07-25 06:15:40,079: ============================================================
2022-07-25 06:15:40,080: Epoch 19/25 Batch 3500/7662 eta: 5:40:22.616749	Training Loss1 4.2700 (4.0729)	Training Total_Loss 4.2700 (4.0729)	Training Prec@1 99.609 (99.866)	Training Prec@5 99.609 (99.957)	
2022-07-25 06:15:40,080: ============================================================
2022-07-25 06:16:20,721: time cost, forward:0.1240614890787263, backward:0.0965802792742306, data cost:0.18685325611694284 
2022-07-25 06:16:20,721: ============================================================
2022-07-25 06:16:20,721: Epoch 19/25 Batch 3600/7662 eta: 5:38:54.889109	Training Loss1 4.6675 (4.0839)	Training Total_Loss 4.6675 (4.0839)	Training Prec@1 99.609 (99.865)	Training Prec@5 100.000 (99.956)	
2022-07-25 06:16:20,721: ============================================================
2022-07-25 06:17:01,409: time cost, forward:0.1240544420991533, backward:0.09658114063833236, data cost:0.18682654415088332 
2022-07-25 06:17:01,409: ============================================================
2022-07-25 06:17:01,409: Epoch 19/25 Batch 3700/7662 eta: 5:38:37.692433	Training Loss1 4.4711 (4.0953)	Training Total_Loss 4.4711 (4.0953)	Training Prec@1 99.609 (99.864)	Training Prec@5 100.000 (99.956)	
2022-07-25 06:17:01,409: ============================================================
2022-07-25 06:17:42,181: time cost, forward:0.12405976034145852, backward:0.09658526363859807, data cost:0.18681021319090865 
2022-07-25 06:17:42,181: ============================================================
2022-07-25 06:17:42,181: Epoch 19/25 Batch 3800/7662 eta: 5:38:38.741327	Training Loss1 3.9833 (4.1078)	Training Total_Loss 3.9833 (4.1078)	Training Prec@1 100.000 (99.863)	Training Prec@5 100.000 (99.956)	
2022-07-25 06:17:42,181: ============================================================
2022-07-25 06:18:22,863: time cost, forward:0.12405085838828585, backward:0.09658748909704928, data cost:0.1867840385461471 
2022-07-25 06:18:22,863: ============================================================
2022-07-25 06:18:22,863: Epoch 19/25 Batch 3900/7662 eta: 5:37:13.259895	Training Loss1 4.7507 (4.1175)	Training Total_Loss 4.7507 (4.1175)	Training Prec@1 99.805 (99.863)	Training Prec@5 100.000 (99.955)	
2022-07-25 06:18:22,864: ============================================================
2022-07-25 06:19:03,639: time cost, forward:0.12405572649418459, backward:0.096585774010317, data cost:0.18677574725531434 
2022-07-25 06:19:03,639: ============================================================
2022-07-25 06:19:03,639: Epoch 19/25 Batch 4000/7662 eta: 5:37:19.135423	Training Loss1 4.4795 (4.1292)	Training Total_Loss 4.4795 (4.1292)	Training Prec@1 99.805 (99.861)	Training Prec@5 99.805 (99.955)	
2022-07-25 06:19:03,639: ============================================================
2022-07-25 06:19:44,355: time cost, forward:0.12405632832888482, backward:0.09658440091779215, data cost:0.1867571949057243 
2022-07-25 06:19:44,356: ============================================================
2022-07-25 06:19:44,356: Epoch 19/25 Batch 4100/7662 eta: 5:36:08.914045	Training Loss1 4.5288 (4.1385)	Training Total_Loss 4.5288 (4.1385)	Training Prec@1 100.000 (99.860)	Training Prec@5 100.000 (99.955)	
2022-07-25 06:19:44,356: ============================================================
2022-07-25 06:20:25,097: time cost, forward:0.12406061177709098, backward:0.09658242032822612, data cost:0.18674244827303213 
2022-07-25 06:20:25,097: ============================================================
2022-07-25 06:20:25,097: Epoch 19/25 Batch 4200/7662 eta: 5:35:40.482687	Training Loss1 4.2510 (4.1483)	Training Total_Loss 4.2510 (4.1483)	Training Prec@1 100.000 (99.859)	Training Prec@5 100.000 (99.955)	
2022-07-25 06:20:25,097: ============================================================
2022-07-25 06:21:05,786: time cost, forward:0.12405972348781319, backward:0.09658187227100515, data cost:0.18671982985481214 
2022-07-25 06:21:05,786: ============================================================
2022-07-25 06:21:05,786: Epoch 19/25 Batch 4300/7662 eta: 5:34:33.988671	Training Loss1 4.4831 (4.1567)	Training Total_Loss 4.4831 (4.1567)	Training Prec@1 99.609 (99.859)	Training Prec@5 100.000 (99.955)	
2022-07-25 06:21:05,786: ============================================================
2022-07-25 06:21:46,457: time cost, forward:0.12405395047126452, backward:0.09658085841920111, data cost:0.1866995954437672 
2022-07-25 06:21:46,457: ============================================================
2022-07-25 06:21:46,457: Epoch 19/25 Batch 4400/7662 eta: 5:33:44.208969	Training Loss1 4.5379 (4.1663)	Training Total_Loss 4.5379 (4.1663)	Training Prec@1 100.000 (99.858)	Training Prec@5 100.000 (99.954)	
2022-07-25 06:21:46,457: ============================================================
2022-07-25 06:22:27,112: time cost, forward:0.12405088308732438, backward:0.09657757365457162, data cost:0.18667673020660677 
2022-07-25 06:22:27,112: ============================================================
2022-07-25 06:22:27,112: Epoch 19/25 Batch 4500/7662 eta: 5:32:56.053769	Training Loss1 4.6384 (4.1750)	Training Total_Loss 4.6384 (4.1750)	Training Prec@1 99.805 (99.857)	Training Prec@5 100.000 (99.954)	
2022-07-25 06:22:27,113: ============================================================
2022-07-25 06:23:07,736: time cost, forward:0.12404410526477194, backward:0.09657426796988006, data cost:0.1866530851582699 
2022-07-25 06:23:07,736: ============================================================
2022-07-25 06:23:07,736: Epoch 19/25 Batch 4600/7662 eta: 5:31:59.928749	Training Loss1 5.1073 (4.1834)	Training Total_Loss 5.1073 (4.1834)	Training Prec@1 100.000 (99.856)	Training Prec@5 100.000 (99.954)	
2022-07-25 06:23:07,736: ============================================================
2022-07-25 06:23:48,348: time cost, forward:0.12403679568860398, backward:0.09657088130756905, data cost:0.1866295144872022 
2022-07-25 06:23:48,349: ============================================================
2022-07-25 06:23:48,349: Epoch 19/25 Batch 4700/7662 eta: 5:31:13.676100	Training Loss1 4.6106 (4.1915)	Training Total_Loss 4.6106 (4.1915)	Training Prec@1 99.805 (99.854)	Training Prec@5 100.000 (99.953)	
2022-07-25 06:23:48,349: ============================================================
2022-07-25 06:24:28,986: time cost, forward:0.12403297478965382, backward:0.09657066920122073, data cost:0.1866046561626475 
2022-07-25 06:24:28,987: ============================================================
2022-07-25 06:24:28,987: Epoch 19/25 Batch 4800/7662 eta: 5:30:45.656259	Training Loss1 4.4477 (4.2001)	Training Total_Loss 4.4477 (4.2001)	Training Prec@1 99.609 (99.854)	Training Prec@5 99.609 (99.953)	
2022-07-25 06:24:28,987: ============================================================
2022-07-25 06:25:09,705: time cost, forward:0.12403856070339984, backward:0.0965684530904863, data cost:0.1865893984162143 
2022-07-25 06:25:09,705: ============================================================
2022-07-25 06:25:09,705: Epoch 19/25 Batch 4900/7662 eta: 5:30:44.163366	Training Loss1 4.3234 (4.2090)	Training Total_Loss 4.3234 (4.2090)	Training Prec@1 99.609 (99.853)	Training Prec@5 99.805 (99.953)	
2022-07-25 06:25:09,706: ============================================================
2022-07-25 06:25:50,472: time cost, forward:0.1240544360169031, backward:0.09656506716000793, data cost:0.1865748676640388 
2022-07-25 06:25:50,472: ============================================================
2022-07-25 06:25:50,472: Epoch 19/25 Batch 5000/7662 eta: 5:30:26.952625	Training Loss1 4.5259 (4.2177)	Training Total_Loss 4.5259 (4.2177)	Training Prec@1 99.805 (99.852)	Training Prec@5 99.805 (99.952)	
2022-07-25 06:25:50,472: ============================================================
2022-07-25 06:26:31,228: time cost, forward:0.12406719878833185, backward:0.09656265862527186, data cost:0.18655799556933425 
2022-07-25 06:26:31,228: ============================================================
2022-07-25 06:26:31,229: Epoch 19/25 Batch 5100/7662 eta: 5:29:41.034551	Training Loss1 4.5382 (4.2253)	Training Total_Loss 4.5382 (4.2253)	Training Prec@1 99.609 (99.851)	Training Prec@5 99.609 (99.952)	
2022-07-25 06:26:31,229: ============================================================
2022-07-25 06:27:11,898: time cost, forward:0.12406943930779817, backward:0.096560506092445, data cost:0.18653787675099226 
2022-07-25 06:27:11,899: ============================================================
2022-07-25 06:27:11,899: Epoch 19/25 Batch 5200/7662 eta: 5:28:18.599644	Training Loss1 4.7064 (4.2329)	Training Total_Loss 4.7064 (4.2329)	Training Prec@1 99.805 (99.850)	Training Prec@5 100.000 (99.951)	
2022-07-25 06:27:11,899: ============================================================
2022-07-25 06:27:52,760: time cost, forward:0.12407647418309932, backward:0.09658412911752909, data cost:0.1865209384917493 
2022-07-25 06:27:52,760: ============================================================
2022-07-25 06:27:52,761: Epoch 19/25 Batch 5300/7662 eta: 5:29:10.629256	Training Loss1 4.4181 (4.2405)	Training Total_Loss 4.4181 (4.2405)	Training Prec@1 99.805 (99.849)	Training Prec@5 100.000 (99.951)	
2022-07-25 06:27:52,761: ============================================================
2022-07-25 06:28:33,430: time cost, forward:0.12407792014178357, backward:0.09658315425052491, data cost:0.18650088987652516 
2022-07-25 06:28:33,431: ============================================================
2022-07-25 06:28:33,431: Epoch 19/25 Batch 5400/7662 eta: 5:26:57.275163	Training Loss1 4.5133 (4.2490)	Training Total_Loss 4.5133 (4.2490)	Training Prec@1 100.000 (99.847)	Training Prec@5 100.000 (99.950)	
2022-07-25 06:28:33,431: ============================================================
2022-07-25 06:29:14,052: time cost, forward:0.1240724083032797, backward:0.09658044796680229, data cost:0.18648277323643583 
2022-07-25 06:29:14,052: ============================================================
2022-07-25 06:29:14,052: Epoch 19/25 Batch 5500/7662 eta: 5:25:53.000315	Training Loss1 4.8041 (4.2565)	Training Total_Loss 4.8041 (4.2565)	Training Prec@1 99.805 (99.846)	Training Prec@5 99.805 (99.950)	
2022-07-25 06:29:14,052: ============================================================
2022-07-25 06:29:54,704: time cost, forward:0.12406853297540685, backward:0.09657748470691341, data cost:0.1864692096008448 
2022-07-25 06:29:54,704: ============================================================
2022-07-25 06:29:54,704: Epoch 19/25 Batch 5600/7662 eta: 5:25:27.130570	Training Loss1 4.5669 (4.2643)	Training Total_Loss 4.5669 (4.2643)	Training Prec@1 100.000 (99.845)	Training Prec@5 100.000 (99.949)	
2022-07-25 06:29:54,704: ============================================================
2022-07-25 06:30:35,333: time cost, forward:0.12406415980329512, backward:0.09657588953050653, data cost:0.186451575069558 
2022-07-25 06:30:35,334: ============================================================
2022-07-25 06:30:35,334: Epoch 19/25 Batch 5700/7662 eta: 5:24:35.891469	Training Loss1 4.8258 (4.2715)	Training Total_Loss 4.8258 (4.2715)	Training Prec@1 99.805 (99.843)	Training Prec@5 100.000 (99.949)	
2022-07-25 06:30:35,334: ============================================================
2022-07-25 06:31:15,951: time cost, forward:0.12405761983358031, backward:0.0965739195666286, data cost:0.1864361162739882 
2022-07-25 06:31:15,951: ============================================================
2022-07-25 06:31:15,951: Epoch 19/25 Batch 5800/7662 eta: 5:23:49.287296	Training Loss1 4.4402 (4.2783)	Training Total_Loss 4.4402 (4.2783)	Training Prec@1 100.000 (99.842)	Training Prec@5 100.000 (99.949)	
2022-07-25 06:31:15,951: ============================================================
2022-07-25 06:31:56,541: time cost, forward:0.12404882024760812, backward:0.09657179955648838, data cost:0.18641945850568256 
2022-07-25 06:31:56,541: ============================================================
2022-07-25 06:31:56,541: Epoch 19/25 Batch 5900/7662 eta: 5:22:55.659448	Training Loss1 4.9213 (4.2857)	Training Total_Loss 4.9213 (4.2857)	Training Prec@1 99.414 (99.842)	Training Prec@5 99.805 (99.948)	
2022-07-25 06:31:56,541: ============================================================
2022-07-25 06:32:37,128: time cost, forward:0.12404002903262502, backward:0.09656985518653743, data cost:0.18640331527276285 
2022-07-25 06:32:37,128: ============================================================
2022-07-25 06:32:37,128: Epoch 19/25 Batch 6000/7662 eta: 5:22:13.768789	Training Loss1 4.1380 (4.2921)	Training Total_Loss 4.1380 (4.2921)	Training Prec@1 100.000 (99.841)	Training Prec@5 100.000 (99.948)	
2022-07-25 06:32:37,128: ============================================================
2022-07-25 06:33:17,734: time cost, forward:0.124033869710354, backward:0.0965678590226318, data cost:0.18638834872779778 
2022-07-25 06:33:17,734: ============================================================
2022-07-25 06:33:17,734: Epoch 19/25 Batch 6100/7662 eta: 5:21:41.940356	Training Loss1 4.8538 (4.2993)	Training Total_Loss 4.8538 (4.2993)	Training Prec@1 99.805 (99.840)	Training Prec@5 100.000 (99.948)	
2022-07-25 06:33:17,734: ============================================================
2022-07-25 06:33:58,353: time cost, forward:0.12402835879177408, backward:0.09656642344444485, data cost:0.18637475988176067 
2022-07-25 06:33:58,353: ============================================================
2022-07-25 06:33:58,353: Epoch 19/25 Batch 6200/7662 eta: 5:21:07.730635	Training Loss1 5.7526 (4.3064)	Training Total_Loss 5.7526 (4.3064)	Training Prec@1 100.000 (99.839)	Training Prec@5 100.000 (99.948)	
2022-07-25 06:33:58,353: ============================================================
2022-07-25 06:34:38,973: time cost, forward:0.12402194862347554, backward:0.09656567508444973, data cost:0.18636233637419594 
2022-07-25 06:34:38,973: ============================================================
2022-07-25 06:34:38,973: Epoch 19/25 Batch 6300/7662 eta: 5:20:27.386436	Training Loss1 4.5372 (4.3136)	Training Total_Loss 4.5372 (4.3136)	Training Prec@1 100.000 (99.838)	Training Prec@5 100.000 (99.948)	
2022-07-25 06:34:38,973: ============================================================
2022-07-25 06:35:19,587: time cost, forward:0.12401594082104599, backward:0.0965635797012074, data cost:0.18635054408879853 
2022-07-25 06:35:19,587: ============================================================
2022-07-25 06:35:19,587: Epoch 19/25 Batch 6400/7662 eta: 5:19:43.942755	Training Loss1 4.4974 (4.3201)	Training Total_Loss 4.4974 (4.3201)	Training Prec@1 100.000 (99.837)	Training Prec@5 100.000 (99.947)	
2022-07-25 06:35:19,587: ============================================================
2022-07-25 06:36:00,207: time cost, forward:0.12401016471312218, backward:0.09656200773588675, data cost:0.18633962458950828 
2022-07-25 06:36:00,207: ============================================================
2022-07-25 06:36:00,207: Epoch 19/25 Batch 6500/7662 eta: 5:19:06.401019	Training Loss1 5.0262 (4.3262)	Training Total_Loss 5.0262 (4.3262)	Training Prec@1 99.609 (99.836)	Training Prec@5 100.000 (99.947)	
2022-07-25 06:36:00,207: ============================================================
2022-07-25 06:36:40,835: time cost, forward:0.12400565271685386, backward:0.09656030449980695, data cost:0.18632947612773434 
2022-07-25 06:36:40,835: ============================================================
2022-07-25 06:36:40,835: Epoch 19/25 Batch 6600/7662 eta: 5:18:29.276641	Training Loss1 5.3550 (4.3320)	Training Total_Loss 5.3550 (4.3320)	Training Prec@1 99.805 (99.835)	Training Prec@5 100.000 (99.947)	
2022-07-25 06:36:40,835: ============================================================
2022-07-25 06:37:21,460: time cost, forward:0.1240014828110937, backward:0.09655913948603469, data cost:0.18631831039722543 
2022-07-25 06:37:21,460: ============================================================
2022-07-25 06:37:21,460: Epoch 19/25 Batch 6700/7662 eta: 5:17:47.428572	Training Loss1 4.4689 (4.3382)	Training Total_Loss 4.4689 (4.3382)	Training Prec@1 100.000 (99.834)	Training Prec@5 100.000 (99.946)	
2022-07-25 06:37:21,460: ============================================================
2022-07-25 06:38:02,078: time cost, forward:0.12399765301634413, backward:0.09655727854825623, data cost:0.1863071468581626 
2022-07-25 06:38:02,078: ============================================================
2022-07-25 06:38:02,078: Epoch 19/25 Batch 6800/7662 eta: 5:17:03.330103	Training Loss1 4.8034 (4.3440)	Training Total_Loss 4.8034 (4.3440)	Training Prec@1 100.000 (99.833)	Training Prec@5 100.000 (99.946)	
2022-07-25 06:38:02,078: ============================================================
2022-07-25 06:38:42,696: time cost, forward:0.12399230657893517, backward:0.09655633099201123, data cost:0.18629731321908508 
2022-07-25 06:38:42,697: ============================================================
2022-07-25 06:38:42,697: Epoch 19/25 Batch 6900/7662 eta: 5:16:23.155920	Training Loss1 4.9957 (4.3501)	Training Total_Loss 4.9957 (4.3501)	Training Prec@1 99.414 (99.832)	Training Prec@5 100.000 (99.946)	
2022-07-25 06:38:42,697: ============================================================
2022-07-25 06:39:23,327: time cost, forward:0.12398833577199261, backward:0.09655532984754701, data cost:0.1862882002879422 
2022-07-25 06:39:23,327: ============================================================
2022-07-25 06:39:23,327: Epoch 19/25 Batch 7000/7662 eta: 5:15:48.019924	Training Loss1 4.7818 (4.3568)	Training Total_Loss 4.7818 (4.3568)	Training Prec@1 99.805 (99.831)	Training Prec@5 100.000 (99.946)	
2022-07-25 06:39:23,327: ============================================================
2022-07-25 06:40:03,985: time cost, forward:0.12398662632964903, backward:0.09655583766266097, data cost:0.18627948253183974 
2022-07-25 06:40:03,985: ============================================================
2022-07-25 06:40:03,986: Epoch 19/25 Batch 7100/7662 eta: 5:15:20.366497	Training Loss1 4.9514 (4.3628)	Training Total_Loss 4.9514 (4.3628)	Training Prec@1 99.609 (99.831)	Training Prec@5 99.609 (99.945)	
2022-07-25 06:40:03,986: ============================================================
2022-07-25 06:40:44,676: time cost, forward:0.12398701844107428, backward:0.09655758867265118, data cost:0.1862720493012492 
2022-07-25 06:40:44,676: ============================================================
2022-07-25 06:40:44,676: Epoch 19/25 Batch 7200/7662 eta: 5:14:54.618185	Training Loss1 5.2983 (4.3690)	Training Total_Loss 5.2983 (4.3690)	Training Prec@1 99.414 (99.830)	Training Prec@5 99.805 (99.945)	
2022-07-25 06:40:44,676: ============================================================
2022-07-25 06:41:25,383: time cost, forward:0.12398895712352188, backward:0.09655795667020894, data cost:0.18626708144242674 
2022-07-25 06:41:25,383: ============================================================
2022-07-25 06:41:25,384: Epoch 19/25 Batch 7300/7662 eta: 5:14:21.785097	Training Loss1 4.9347 (4.3741)	Training Total_Loss 4.9347 (4.3741)	Training Prec@1 99.414 (99.829)	Training Prec@5 99.805 (99.945)	
2022-07-25 06:41:25,384: ============================================================
2022-07-25 06:42:06,062: time cost, forward:0.12398907519269753, backward:0.09655847454702618, data cost:0.18626000875072682 
2022-07-25 06:42:06,062: ============================================================
2022-07-25 06:42:06,062: Epoch 19/25 Batch 7400/7662 eta: 5:13:27.700808	Training Loss1 4.6223 (4.3801)	Training Total_Loss 4.6223 (4.3801)	Training Prec@1 100.000 (99.828)	Training Prec@5 100.000 (99.945)	
2022-07-25 06:42:06,062: ============================================================
2022-07-25 06:42:46,742: time cost, forward:0.12398755399365952, backward:0.09655959422722835, data cost:0.18625471260980345 
2022-07-25 06:42:46,742: ============================================================
2022-07-25 06:42:46,743: Epoch 19/25 Batch 7500/7662 eta: 5:12:47.947479	Training Loss1 4.8054 (4.3853)	Training Total_Loss 4.8054 (4.3853)	Training Prec@1 99.805 (99.827)	Training Prec@5 100.000 (99.944)	
2022-07-25 06:42:46,743: ============================================================
2022-07-25 06:43:27,388: time cost, forward:0.12398455148936102, backward:0.09656121116168312, data cost:0.18624595695929333 
2022-07-25 06:43:27,388: ============================================================
2022-07-25 06:43:27,388: Epoch 19/25 Batch 7600/7662 eta: 5:11:51.203424	Training Loss1 4.9354 (4.3904)	Training Total_Loss 4.9354 (4.3904)	Training Prec@1 100.000 (99.826)	Training Prec@5 100.000 (99.944)	
2022-07-25 06:43:27,388: ============================================================
2022-07-25 06:43:54,498: Epoch 19/25 Batch 7663/7662 eta: 5:11:25.596694	Training Loss1 4.5033 (4.3942)	Training Total_Loss 4.5033 (4.3942)	Training Prec@1 99.805 (99.825)	Training Prec@5 100.000 (99.943)	
2022-07-25 06:43:54,499: ============================================================
2022-07-25 06:44:37,161: time cost, forward:0.12449845159896697, backward:0.09642710589399242, data cost:0.20723136266072592 
2022-07-25 06:44:37,162: ============================================================
2022-07-25 06:44:37,162: Epoch 20/25 Batch 100/7662 eta: 5:26:00.739084	Training Loss1 3.4591 (3.1468)	Training Total_Loss 3.4591 (3.1468)	Training Prec@1 100.000 (99.913)	Training Prec@5 100.000 (99.982)	
2022-07-25 06:44:37,162: ============================================================
2022-07-25 06:45:18,080: time cost, forward:0.12451089566676461, backward:0.09647711916784545, data cost:0.19727859425185315 
2022-07-25 06:45:18,081: ============================================================
2022-07-25 06:45:18,081: Epoch 20/25 Batch 200/7662 eta: 5:12:09.905121	Training Loss1 3.0842 (3.0502)	Training Total_Loss 3.0842 (3.0502)	Training Prec@1 100.000 (99.921)	Training Prec@5 100.000 (99.983)	
2022-07-25 06:45:18,081: ============================================================
2022-07-25 06:45:59,068: time cost, forward:0.12453436054114912, backward:0.09650331675806971, data cost:0.1942189010888039 
2022-07-25 06:45:59,068: ============================================================
2022-07-25 06:45:59,069: Epoch 20/25 Batch 300/7662 eta: 5:12:00.240563	Training Loss1 3.0515 (2.9891)	Training Total_Loss 3.0515 (2.9891)	Training Prec@1 100.000 (99.924)	Training Prec@5 100.000 (99.980)	
2022-07-25 06:45:59,069: ============================================================
2022-07-25 06:46:39,922: time cost, forward:0.12444567441342767, backward:0.09654800097147624, data cost:0.19241643011719362 
2022-07-25 06:46:39,922: ============================================================
2022-07-25 06:46:39,922: Epoch 20/25 Batch 400/7662 eta: 5:10:18.228307	Training Loss1 2.3212 (2.9508)	Training Total_Loss 2.3212 (2.9508)	Training Prec@1 99.805 (99.925)	Training Prec@5 100.000 (99.979)	
2022-07-25 06:46:39,922: ============================================================
2022-07-25 06:47:20,886: time cost, forward:0.12453964716924694, backward:0.0965340065812778, data cost:0.1914775997460008 
2022-07-25 06:47:20,886: ============================================================
2022-07-25 06:47:20,887: Epoch 20/25 Batch 500/7662 eta: 5:10:27.714966	Training Loss1 3.1614 (2.9158)	Training Total_Loss 3.1614 (2.9158)	Training Prec@1 99.805 (99.924)	Training Prec@5 99.805 (99.980)	
2022-07-25 06:47:20,887: ============================================================
2022-07-25 06:48:01,761: time cost, forward:0.12444487159359634, backward:0.09654593467712402, data cost:0.190827590197275 
2022-07-25 06:48:01,761: ============================================================
2022-07-25 06:48:01,761: Epoch 20/25 Batch 600/7662 eta: 5:09:06.128614	Training Loss1 2.6486 (2.8793)	Training Total_Loss 2.6486 (2.8793)	Training Prec@1 100.000 (99.930)	Training Prec@5 100.000 (99.980)	
2022-07-25 06:48:01,761: ============================================================
2022-07-25 06:48:42,604: time cost, forward:0.1243991159403614, backward:0.0965437721967356, data cost:0.19028878075541003 
2022-07-25 06:48:42,604: ============================================================
2022-07-25 06:48:42,604: Epoch 20/25 Batch 700/7662 eta: 5:08:10.835170	Training Loss1 2.6753 (2.8529)	Training Total_Loss 2.6753 (2.8529)	Training Prec@1 99.805 (99.931)	Training Prec@5 100.000 (99.980)	
2022-07-25 06:48:42,604: ============================================================
2022-07-25 06:49:23,448: time cost, forward:0.12436603723986725, backward:0.09655836705719872, data cost:0.18985763568902045 
2022-07-25 06:49:23,448: ============================================================
2022-07-25 06:49:23,448: Epoch 20/25 Batch 800/7662 eta: 5:07:30.520370	Training Loss1 2.3937 (2.8334)	Training Total_Loss 2.3937 (2.8334)	Training Prec@1 100.000 (99.933)	Training Prec@5 100.000 (99.979)	
2022-07-25 06:49:23,449: ============================================================
2022-07-25 06:50:04,296: time cost, forward:0.12436208337777449, backward:0.09656508109460815, data cost:0.18952032350194334 
2022-07-25 06:50:04,296: ============================================================
2022-07-25 06:50:04,296: Epoch 20/25 Batch 900/7662 eta: 5:06:51.435182	Training Loss1 2.8666 (2.8153)	Training Total_Loss 2.8666 (2.8153)	Training Prec@1 99.805 (99.932)	Training Prec@5 100.000 (99.979)	
2022-07-25 06:50:04,297: ============================================================
2022-07-25 06:50:45,112: time cost, forward:0.12434303509938466, backward:0.09656375234907454, data cost:0.18925700698409592 
2022-07-25 06:50:45,113: ============================================================
2022-07-25 06:50:45,113: Epoch 20/25 Batch 1000/7662 eta: 5:05:56.345120	Training Loss1 2.7402 (2.7968)	Training Total_Loss 2.7402 (2.7968)	Training Prec@1 100.000 (99.933)	Training Prec@5 100.000 (99.978)	
2022-07-25 06:50:45,113: ============================================================
2022-07-25 06:51:25,921: time cost, forward:0.12431284229358398, backward:0.09656199745094918, data cost:0.18904854884681319 
2022-07-25 06:51:25,922: ============================================================
2022-07-25 06:51:25,922: Epoch 20/25 Batch 1100/7662 eta: 5:05:12.188234	Training Loss1 2.8147 (2.7833)	Training Total_Loss 2.8147 (2.7833)	Training Prec@1 100.000 (99.935)	Training Prec@5 100.000 (99.979)	
2022-07-25 06:51:25,922: ============================================================
2022-07-25 06:52:06,661: time cost, forward:0.12428164899697196, backward:0.09655668001755563, data cost:0.18882887516546687 
2022-07-25 06:52:06,661: ============================================================
2022-07-25 06:52:06,661: Epoch 20/25 Batch 1200/7662 eta: 5:04:00.362218	Training Loss1 2.7260 (2.7704)	Training Total_Loss 2.7260 (2.7704)	Training Prec@1 100.000 (99.936)	Training Prec@5 100.000 (99.980)	
2022-07-25 06:52:06,661: ============================================================
2022-07-25 06:52:47,432: time cost, forward:0.12428766713865542, backward:0.09655460529459542, data cost:0.18863140187692973 
2022-07-25 06:52:47,432: ============================================================
2022-07-25 06:52:47,433: Epoch 20/25 Batch 1300/7662 eta: 5:03:33.653180	Training Loss1 2.7196 (2.7579)	Training Total_Loss 2.7196 (2.7579)	Training Prec@1 100.000 (99.937)	Training Prec@5 100.000 (99.980)	
2022-07-25 06:52:47,433: ============================================================
2022-07-25 06:53:28,184: time cost, forward:0.12428636019190692, backward:0.09654972449296538, data cost:0.18845056567215937 
2022-07-25 06:53:28,184: ============================================================
2022-07-25 06:53:28,184: Epoch 20/25 Batch 1400/7662 eta: 5:02:44.348088	Training Loss1 2.8265 (2.7485)	Training Total_Loss 2.8265 (2.7485)	Training Prec@1 100.000 (99.937)	Training Prec@5 100.000 (99.980)	
2022-07-25 06:53:28,184: ============================================================
2022-07-25 06:54:08,943: time cost, forward:0.12425468014112069, backward:0.09654689630402813, data cost:0.18832910068835157 
2022-07-25 06:54:08,944: ============================================================
2022-07-25 06:54:08,944: Epoch 20/25 Batch 1500/7662 eta: 5:02:06.911797	Training Loss1 2.2578 (2.7361)	Training Total_Loss 2.2578 (2.7361)	Training Prec@1 100.000 (99.937)	Training Prec@5 100.000 (99.981)	
2022-07-25 06:54:08,944: ============================================================
2022-07-25 06:54:49,770: time cost, forward:0.12423691069654855, backward:0.096544625238749, data cost:0.18826064845783552 
2022-07-25 06:54:49,770: ============================================================
2022-07-25 06:54:49,771: Epoch 20/25 Batch 1600/7662 eta: 5:01:56.081196	Training Loss1 2.7683 (2.7229)	Training Total_Loss 2.7683 (2.7229)	Training Prec@1 99.805 (99.939)	Training Prec@5 100.000 (99.981)	
2022-07-25 06:54:49,771: ============================================================
2022-07-25 06:55:30,637: time cost, forward:0.12421307274704474, backward:0.09653452721113595, data cost:0.1882462716228896 
2022-07-25 06:55:30,638: ============================================================
2022-07-25 06:55:30,638: Epoch 20/25 Batch 1700/7662 eta: 5:01:33.204866	Training Loss1 2.3880 (2.7112)	Training Total_Loss 2.3880 (2.7112)	Training Prec@1 99.609 (99.940)	Training Prec@5 100.000 (99.982)	
2022-07-25 06:55:30,638: ============================================================
2022-07-25 06:56:11,490: time cost, forward:0.12418660990326454, backward:0.09653054176932775, data cost:0.18821600425766866 
2022-07-25 06:56:11,490: ============================================================
2022-07-25 06:56:11,490: Epoch 20/25 Batch 1800/7662 eta: 5:00:45.744582	Training Loss1 2.5526 (2.7026)	Training Total_Loss 2.5526 (2.7026)	Training Prec@1 100.000 (99.941)	Training Prec@5 100.000 (99.982)	
2022-07-25 06:56:11,490: ============================================================
2022-07-25 06:56:52,250: time cost, forward:0.12416437238439125, backward:0.09653071455732028, data cost:0.18813916781878962 
2022-07-25 06:56:52,250: ============================================================
2022-07-25 06:56:52,250: Epoch 20/25 Batch 1900/7662 eta: 4:59:24.149962	Training Loss1 2.5167 (2.6927)	Training Total_Loss 2.5167 (2.6927)	Training Prec@1 99.805 (99.941)	Training Prec@5 100.000 (99.982)	
2022-07-25 06:56:52,250: ============================================================
2022-07-25 06:57:32,980: time cost, forward:0.12416380032591369, backward:0.0965291862192006, data cost:0.1880383455735436 
2022-07-25 06:57:32,981: ============================================================
2022-07-25 06:57:32,981: Epoch 20/25 Batch 2000/7662 eta: 4:58:30.362055	Training Loss1 2.7285 (2.6829)	Training Total_Loss 2.7285 (2.6829)	Training Prec@1 100.000 (99.942)	Training Prec@5 100.000 (99.982)	
2022-07-25 06:57:32,981: ============================================================
2022-07-25 06:58:13,824: time cost, forward:0.12418450623140158, backward:0.09652269971319583, data cost:0.1879761846023494 
2022-07-25 06:58:13,824: ============================================================
2022-07-25 06:58:13,824: Epoch 20/25 Batch 2100/7662 eta: 4:58:39.191201	Training Loss1 2.0503 (2.6740)	Training Total_Loss 2.0503 (2.6740)	Training Prec@1 100.000 (99.943)	Training Prec@5 100.000 (99.982)	
2022-07-25 06:58:13,824: ============================================================
2022-07-25 06:58:54,709: time cost, forward:0.12419784757536939, backward:0.0965147462960209, data cost:0.1879574148803475 
2022-07-25 06:58:54,709: ============================================================
2022-07-25 06:58:54,722: Epoch 20/25 Batch 2200/7662 eta: 4:58:22.291768	Training Loss1 2.0836 (2.6664)	Training Total_Loss 2.0836 (2.6664)	Training Prec@1 99.805 (99.944)	Training Prec@5 99.805 (99.982)	
2022-07-25 06:58:54,722: ============================================================
2022-07-25 06:59:35,457: time cost, forward:0.12419176796510356, backward:0.09651094698397789, data cost:0.18789270391874907 
2022-07-25 06:59:35,457: ============================================================
2022-07-25 06:59:35,458: Epoch 20/25 Batch 2300/7662 eta: 4:56:30.370080	Training Loss1 2.4925 (2.6577)	Training Total_Loss 2.4925 (2.6577)	Training Prec@1 100.000 (99.945)	Training Prec@5 100.000 (99.982)	
2022-07-25 06:59:35,458: ============================================================
2022-07-25 07:00:16,148: time cost, forward:0.12418848914670766, backward:0.09650875797565901, data cost:0.18780306092199062 
2022-07-25 07:00:16,148: ============================================================
2022-07-25 07:00:16,149: Epoch 20/25 Batch 2400/7662 eta: 4:55:30.351339	Training Loss1 2.7223 (2.6487)	Training Total_Loss 2.7223 (2.6487)	Training Prec@1 100.000 (99.945)	Training Prec@5 100.000 (99.982)	
2022-07-25 07:00:16,149: ============================================================
2022-07-25 07:00:56,860: time cost, forward:0.12418591723340948, backward:0.0965058905642335, data cost:0.18773442413769706 
2022-07-25 07:00:56,860: ============================================================
2022-07-25 07:00:56,860: Epoch 20/25 Batch 2500/7662 eta: 4:54:58.462272	Training Loss1 2.4359 (2.6418)	Training Total_Loss 2.4359 (2.6418)	Training Prec@1 100.000 (99.945)	Training Prec@5 100.000 (99.982)	
2022-07-25 07:00:56,860: ============================================================
2022-07-25 07:01:37,615: time cost, forward:0.12418438802090183, backward:0.09650536471488338, data cost:0.18768318711266513 
2022-07-25 07:01:37,615: ============================================================
2022-07-25 07:01:37,615: Epoch 20/25 Batch 2600/7662 eta: 4:54:36.676024	Training Loss1 2.4508 (2.6358)	Training Total_Loss 2.4508 (2.6358)	Training Prec@1 100.000 (99.946)	Training Prec@5 100.000 (99.982)	
2022-07-25 07:01:37,615: ============================================================
2022-07-25 07:02:18,252: time cost, forward:0.12416920153111517, backward:0.09650567691827006, data cost:0.187603693001356 
2022-07-25 07:02:18,252: ============================================================
2022-07-25 07:02:18,252: Epoch 20/25 Batch 2700/7662 eta: 4:53:04.978113	Training Loss1 2.6002 (2.6279)	Training Total_Loss 2.6002 (2.6279)	Training Prec@1 100.000 (99.947)	Training Prec@5 100.000 (99.983)	
2022-07-25 07:02:18,252: ============================================================
2022-07-25 07:02:58,897: time cost, forward:0.12416061387397681, backward:0.09650461909684933, data cost:0.18752931892637612 
2022-07-25 07:02:58,898: ============================================================
2022-07-25 07:02:58,898: Epoch 20/25 Batch 2800/7662 eta: 4:52:27.825799	Training Loss1 2.5721 (2.6215)	Training Total_Loss 2.5721 (2.6215)	Training Prec@1 100.000 (99.947)	Training Prec@5 100.000 (99.983)	
2022-07-25 07:02:58,898: ============================================================
2022-07-25 07:03:39,590: time cost, forward:0.124153432948049, backward:0.09650339599969922, data cost:0.18747549987982454 
2022-07-25 07:03:39,602: ============================================================
2022-07-25 07:03:39,602: Epoch 20/25 Batch 2900/7662 eta: 4:52:12.709857	Training Loss1 2.7177 (2.6156)	Training Total_Loss 2.7177 (2.6156)	Training Prec@1 100.000 (99.947)	Training Prec@5 100.000 (99.983)	
2022-07-25 07:03:39,602: ============================================================
2022-07-25 07:04:20,284: time cost, forward:0.12413922283163703, backward:0.09650389231535227, data cost:0.18743288314274925 
2022-07-25 07:04:20,284: ============================================================
2022-07-25 07:04:20,285: Epoch 20/25 Batch 3000/7662 eta: 4:51:22.339964	Training Loss1 2.6310 (2.6090)	Training Total_Loss 2.6310 (2.6090)	Training Prec@1 99.609 (99.948)	Training Prec@5 100.000 (99.983)	
2022-07-25 07:04:20,285: ============================================================
2022-07-25 07:05:01,030: time cost, forward:0.12412766419367931, backward:0.09650259688809135, data cost:0.18740928238459117 
2022-07-25 07:05:01,030: ============================================================
2022-07-25 07:05:01,030: Epoch 20/25 Batch 3100/7662 eta: 4:51:08.863944	Training Loss1 2.4025 (2.6037)	Training Total_Loss 2.4025 (2.6037)	Training Prec@1 100.000 (99.948)	Training Prec@5 100.000 (99.983)	
2022-07-25 07:05:01,030: ============================================================
2022-07-25 07:05:41,716: time cost, forward:0.12412415969815244, backward:0.0965007145205823, data cost:0.18736160744276223 
2022-07-25 07:05:41,716: ============================================================
2022-07-25 07:05:41,717: Epoch 20/25 Batch 3200/7662 eta: 4:50:02.838104	Training Loss1 2.4829 (2.5984)	Training Total_Loss 2.4829 (2.5984)	Training Prec@1 100.000 (99.948)	Training Prec@5 100.000 (99.983)	
2022-07-25 07:05:41,717: ============================================================
2022-07-25 07:06:22,347: time cost, forward:0.1241113168971399, backward:0.09649975916297915, data cost:0.1873087752909688 
2022-07-25 07:06:22,347: ============================================================
2022-07-25 07:06:22,347: Epoch 20/25 Batch 3300/7662 eta: 4:48:58.265812	Training Loss1 2.2210 (2.5925)	Training Total_Loss 2.2210 (2.5925)	Training Prec@1 100.000 (99.948)	Training Prec@5 100.000 (99.984)	
2022-07-25 07:06:22,347: ============================================================
2022-07-25 07:07:02,972: time cost, forward:0.12410389146022005, backward:0.0964976288564558, data cost:0.18725493516105524 
2022-07-25 07:07:02,973: ============================================================
2022-07-25 07:07:02,973: Epoch 20/25 Batch 3400/7662 eta: 4:48:15.531148	Training Loss1 2.4270 (2.5870)	Training Total_Loss 2.4270 (2.5870)	Training Prec@1 100.000 (99.949)	Training Prec@5 100.000 (99.984)	
2022-07-25 07:07:02,973: ============================================================
2022-07-25 07:07:43,627: time cost, forward:0.12410260105378357, backward:0.09649603392063259, data cost:0.18720495711057042 
2022-07-25 07:07:43,628: ============================================================
2022-07-25 07:07:43,628: Epoch 20/25 Batch 3500/7662 eta: 4:47:47.499401	Training Loss1 2.7199 (2.5817)	Training Total_Loss 2.7199 (2.5817)	Training Prec@1 100.000 (99.949)	Training Prec@5 100.000 (99.984)	
2022-07-25 07:07:43,628: ============================================================
2022-07-25 07:08:24,298: time cost, forward:0.12409641968604425, backward:0.09650056969625945, data cost:0.1871621638544734 
2022-07-25 07:08:24,299: ============================================================
2022-07-25 07:08:24,299: Epoch 20/25 Batch 3600/7662 eta: 4:47:13.425544	Training Loss1 2.6273 (2.5765)	Training Total_Loss 2.6273 (2.5765)	Training Prec@1 100.000 (99.949)	Training Prec@5 100.000 (99.984)	
2022-07-25 07:08:24,299: ============================================================
2022-07-25 07:09:05,001: time cost, forward:0.12409277167246772, backward:0.09650482858120026, data cost:0.1871277013641011 
2022-07-25 07:09:05,001: ============================================================
2022-07-25 07:09:05,002: Epoch 20/25 Batch 3700/7662 eta: 4:46:46.330741	Training Loss1 2.4914 (2.5715)	Training Total_Loss 2.4914 (2.5715)	Training Prec@1 100.000 (99.950)	Training Prec@5 100.000 (99.984)	
2022-07-25 07:09:05,002: ============================================================
2022-07-25 07:09:45,690: time cost, forward:0.12408685301378797, backward:0.09650926848529796, data cost:0.18709419664190644 
2022-07-25 07:09:45,690: ============================================================
2022-07-25 07:09:45,691: Epoch 20/25 Batch 3800/7662 eta: 4:45:59.774941	Training Loss1 1.9797 (2.5660)	Training Total_Loss 1.9797 (2.5660)	Training Prec@1 99.805 (99.950)	Training Prec@5 99.805 (99.984)	
2022-07-25 07:09:45,691: ============================================================
2022-07-25 07:10:26,401: time cost, forward:0.12408708798393099, backward:0.09651298393314085, data cost:0.18706226666849923 
2022-07-25 07:10:26,401: ============================================================
2022-07-25 07:10:26,401: Epoch 20/25 Batch 3900/7662 eta: 4:45:28.130772	Training Loss1 2.4245 (2.5619)	Training Total_Loss 2.4245 (2.5619)	Training Prec@1 100.000 (99.950)	Training Prec@5 100.000 (99.984)	
2022-07-25 07:10:26,401: ============================================================
2022-07-25 07:11:07,084: time cost, forward:0.12407825368140513, backward:0.09651553425141411, data cost:0.1870351029086274 
2022-07-25 07:11:07,084: ============================================================
2022-07-25 07:11:07,084: Epoch 20/25 Batch 4000/7662 eta: 4:44:35.992610	Training Loss1 2.8515 (2.5570)	Training Total_Loss 2.8515 (2.5570)	Training Prec@1 99.805 (99.950)	Training Prec@5 100.000 (99.984)	
2022-07-25 07:11:07,085: ============================================================
2022-07-25 07:11:47,794: time cost, forward:0.12407147637167393, backward:0.09651756699593017, data cost:0.18701518288645172 
2022-07-25 07:11:47,794: ============================================================
2022-07-25 07:11:47,795: Epoch 20/25 Batch 4100/7662 eta: 4:44:06.484040	Training Loss1 2.3915 (2.5524)	Training Total_Loss 2.3915 (2.5524)	Training Prec@1 100.000 (99.950)	Training Prec@5 100.000 (99.984)	
2022-07-25 07:11:47,795: ============================================================
2022-07-25 07:12:28,462: time cost, forward:0.12406275788498197, backward:0.09651737219948348, data cost:0.1869899372624113 
2022-07-25 07:12:28,462: ============================================================
2022-07-25 07:12:28,462: Epoch 20/25 Batch 4200/7662 eta: 4:43:08.059781	Training Loss1 2.7281 (2.5479)	Training Total_Loss 2.7281 (2.5479)	Training Prec@1 99.805 (99.950)	Training Prec@5 99.805 (99.984)	
2022-07-25 07:12:28,462: ============================================================
2022-07-25 07:13:09,151: time cost, forward:0.12405915425582996, backward:0.09652011919698207, data cost:0.18696347306733577 
2022-07-25 07:13:09,151: ============================================================
2022-07-25 07:13:09,151: Epoch 20/25 Batch 4300/7662 eta: 4:42:36.361501	Training Loss1 2.0877 (2.5441)	Training Total_Loss 2.0877 (2.5441)	Training Prec@1 100.000 (99.950)	Training Prec@5 100.000 (99.984)	
2022-07-25 07:13:09,151: ============================================================
2022-07-25 07:13:49,831: time cost, forward:0.12405487227694613, backward:0.09652304774009252, data cost:0.1869364151712926 
2022-07-25 07:13:49,831: ============================================================
2022-07-25 07:13:49,831: Epoch 20/25 Batch 4400/7662 eta: 4:41:51.910701	Training Loss1 2.1597 (2.5396)	Training Total_Loss 2.1597 (2.5396)	Training Prec@1 100.000 (99.951)	Training Prec@5 100.000 (99.984)	
2022-07-25 07:13:49,831: ============================================================
2022-07-25 07:14:30,578: time cost, forward:0.12406150392225833, backward:0.09652554387382783, data cost:0.18691218696877437 
2022-07-25 07:14:30,578: ============================================================
2022-07-25 07:14:30,578: Epoch 20/25 Batch 4500/7662 eta: 4:41:39.022781	Training Loss1 2.6400 (2.5358)	Training Total_Loss 2.6400 (2.5358)	Training Prec@1 99.805 (99.951)	Training Prec@5 99.805 (99.984)	
2022-07-25 07:14:30,578: ============================================================
2022-07-25 07:15:11,339: time cost, forward:0.12407262103924105, backward:0.09652555572076786, data cost:0.18689127439103662 
2022-07-25 07:15:11,339: ============================================================
2022-07-25 07:15:11,339: Epoch 20/25 Batch 4600/7662 eta: 4:41:04.019002	Training Loss1 2.6324 (2.5327)	Training Total_Loss 2.6324 (2.5327)	Training Prec@1 100.000 (99.951)	Training Prec@5 100.000 (99.984)	
2022-07-25 07:15:11,339: ============================================================
2022-07-25 07:15:52,091: time cost, forward:0.1240826179738196, backward:0.09652606602246824, data cost:0.1868698527950458 
2022-07-25 07:15:52,091: ============================================================
2022-07-25 07:15:52,091: Epoch 20/25 Batch 4700/7662 eta: 4:40:19.672582	Training Loss1 2.7077 (2.5290)	Training Total_Loss 2.7077 (2.5290)	Training Prec@1 100.000 (99.951)	Training Prec@5 100.000 (99.984)	
2022-07-25 07:15:52,091: ============================================================
2022-07-25 07:16:32,798: time cost, forward:0.12408080710100865, backward:0.09652742715546628, data cost:0.1868506202749422 
2022-07-25 07:16:32,798: ============================================================
2022-07-25 07:16:32,798: Epoch 20/25 Batch 4800/7662 eta: 4:39:20.142141	Training Loss1 2.4505 (2.5251)	Training Total_Loss 2.4505 (2.5251)	Training Prec@1 100.000 (99.952)	Training Prec@5 100.000 (99.985)	
2022-07-25 07:16:32,798: ============================================================
2022-07-25 07:17:13,506: time cost, forward:0.12408067528435979, backward:0.09652951713191366, data cost:0.1868302467818843 
2022-07-25 07:17:13,506: ============================================================
2022-07-25 07:17:13,506: Epoch 20/25 Batch 4900/7662 eta: 4:38:40.018948	Training Loss1 2.3236 (2.5205)	Training Total_Loss 2.3236 (2.5205)	Training Prec@1 100.000 (99.951)	Training Prec@5 100.000 (99.985)	
2022-07-25 07:17:13,506: ============================================================
2022-07-25 07:17:54,225: time cost, forward:0.12408343718800217, backward:0.09653018164286543, data cost:0.18681161750385966 
2022-07-25 07:17:54,225: ============================================================
2022-07-25 07:17:54,226: Epoch 20/25 Batch 5000/7662 eta: 4:38:04.052145	Training Loss1 2.2210 (2.5170)	Training Total_Loss 2.2210 (2.5170)	Training Prec@1 100.000 (99.951)	Training Prec@5 100.000 (99.985)	
2022-07-25 07:17:54,226: ============================================================
2022-07-25 07:18:34,929: time cost, forward:0.12408645809059121, backward:0.09653265982614964, data cost:0.18678846946532268 
2022-07-25 07:18:34,929: ============================================================
2022-07-25 07:18:34,929: Epoch 20/25 Batch 5100/7662 eta: 4:37:16.715257	Training Loss1 2.1536 (2.5137)	Training Total_Loss 2.1536 (2.5137)	Training Prec@1 99.805 (99.951)	Training Prec@5 100.000 (99.985)	
2022-07-25 07:18:34,929: ============================================================
2022-07-25 07:19:15,576: time cost, forward:0.12408059618752332, backward:0.09653301637065849, data cost:0.18676631004449426 
2022-07-25 07:19:15,577: ============================================================
2022-07-25 07:19:15,577: Epoch 20/25 Batch 5200/7662 eta: 4:36:13.331759	Training Loss1 2.7151 (2.5103)	Training Total_Loss 2.7151 (2.5103)	Training Prec@1 99.805 (99.951)	Training Prec@5 100.000 (99.985)	
2022-07-25 07:19:15,577: ============================================================
2022-07-25 07:19:56,224: time cost, forward:0.12407580369552322, backward:0.09653444883170545, data cost:0.18674225549829257 
2022-07-25 07:19:56,225: ============================================================
2022-07-25 07:19:56,225: Epoch 20/25 Batch 5300/7662 eta: 4:35:32.694809	Training Loss1 2.3239 (2.5067)	Training Total_Loss 2.3239 (2.5067)	Training Prec@1 100.000 (99.951)	Training Prec@5 100.000 (99.985)	
2022-07-25 07:19:56,225: ============================================================
2022-07-25 07:20:36,812: time cost, forward:0.12406649274237842, backward:0.09653280134178087, data cost:0.18671714639107284 
2022-07-25 07:20:36,813: ============================================================
2022-07-25 07:20:36,813: Epoch 20/25 Batch 5400/7662 eta: 4:34:27.786869	Training Loss1 2.0901 (2.5038)	Training Total_Loss 2.0901 (2.5038)	Training Prec@1 100.000 (99.951)	Training Prec@5 100.000 (99.985)	
2022-07-25 07:20:36,813: ============================================================
2022-07-25 07:21:17,415: time cost, forward:0.12405942960053407, backward:0.0965305991033182, data cost:0.18669400047792004 
2022-07-25 07:21:17,415: ============================================================
2022-07-25 07:21:17,415: Epoch 20/25 Batch 5500/7662 eta: 4:33:53.003588	Training Loss1 2.3403 (2.5005)	Training Total_Loss 2.3403 (2.5005)	Training Prec@1 100.000 (99.951)	Training Prec@5 100.000 (99.985)	
2022-07-25 07:21:17,415: ============================================================
2022-07-25 07:21:58,025: time cost, forward:0.12405230203128793, backward:0.09653063807493449, data cost:0.1866708719894319 
2022-07-25 07:21:58,025: ============================================================
2022-07-25 07:21:58,025: Epoch 20/25 Batch 5600/7662 eta: 4:33:15.404894	Training Loss1 2.1821 (2.4970)	Training Total_Loss 2.1821 (2.4970)	Training Prec@1 99.805 (99.952)	Training Prec@5 100.000 (99.985)	
2022-07-25 07:21:58,025: ============================================================
2022-07-25 07:22:38,640: time cost, forward:0.12404596502267597, backward:0.09652832617444268, data cost:0.18665184655049785 
2022-07-25 07:22:38,640: ============================================================
2022-07-25 07:22:38,640: Epoch 20/25 Batch 5700/7662 eta: 4:32:36.860902	Training Loss1 2.0095 (2.4942)	Training Total_Loss 2.0095 (2.4942)	Training Prec@1 100.000 (99.951)	Training Prec@5 100.000 (99.985)	
2022-07-25 07:22:38,640: ============================================================
2022-07-25 07:23:19,242: time cost, forward:0.12403846091290018, backward:0.09652791699164283, data cost:0.18663144740673526 
2022-07-25 07:23:19,242: ============================================================
2022-07-25 07:23:19,243: Epoch 20/25 Batch 5800/7662 eta: 4:31:51.255240	Training Loss1 2.4419 (2.4908)	Training Total_Loss 2.4419 (2.4908)	Training Prec@1 100.000 (99.952)	Training Prec@5 100.000 (99.984)	
2022-07-25 07:23:19,243: ============================================================
2022-07-25 07:23:59,853: time cost, forward:0.12403093982417819, backward:0.0965274012397964, data cost:0.1866132617299891 
2022-07-25 07:23:59,854: ============================================================
2022-07-25 07:23:59,854: Epoch 20/25 Batch 5900/7662 eta: 4:31:14.214876	Training Loss1 2.5808 (2.4875)	Training Total_Loss 2.5808 (2.4875)	Training Prec@1 100.000 (99.952)	Training Prec@5 100.000 (99.985)	
2022-07-25 07:23:59,854: ============================================================
2022-07-25 07:24:40,553: time cost, forward:0.1240223289072603, backward:0.09654296161850645, data cost:0.1865955360890786 
2022-07-25 07:24:40,553: ============================================================
2022-07-25 07:24:40,554: Epoch 20/25 Batch 6000/7662 eta: 4:31:08.868064	Training Loss1 2.1086 (2.4841)	Training Total_Loss 2.1086 (2.4841)	Training Prec@1 100.000 (99.952)	Training Prec@5 100.000 (99.985)	
2022-07-25 07:24:40,554: ============================================================
2022-07-25 07:25:21,297: time cost, forward:0.12401615160178857, backward:0.0965635437988066, data cost:0.1865780364882655 
2022-07-25 07:25:21,298: ============================================================
2022-07-25 07:25:21,298: Epoch 20/25 Batch 6100/7662 eta: 4:30:45.913948	Training Loss1 1.8924 (2.4805)	Training Total_Loss 1.8924 (2.4805)	Training Prec@1 100.000 (99.952)	Training Prec@5 100.000 (99.985)	
2022-07-25 07:25:21,298: ============================================================
2022-07-25 07:26:02,025: time cost, forward:0.12401175995106889, backward:0.09657991042077917, data cost:0.1865602973430921 
2022-07-25 07:26:02,025: ============================================================
2022-07-25 07:26:02,025: Epoch 20/25 Batch 6200/7662 eta: 4:29:58.566672	Training Loss1 2.0170 (2.4777)	Training Total_Loss 2.0170 (2.4777)	Training Prec@1 100.000 (99.952)	Training Prec@5 100.000 (99.985)	
2022-07-25 07:26:02,025: ============================================================
2022-07-25 07:26:42,631: time cost, forward:0.12400668525453559, backward:0.09657752894280278, data cost:0.18654310054146198 
2022-07-25 07:26:42,631: ============================================================
2022-07-25 07:26:42,632: Epoch 20/25 Batch 6300/7662 eta: 4:28:29.746998	Training Loss1 2.1411 (2.4752)	Training Total_Loss 2.1411 (2.4752)	Training Prec@1 100.000 (99.953)	Training Prec@5 100.000 (99.985)	
2022-07-25 07:26:42,632: ============================================================
2022-07-25 07:27:23,234: time cost, forward:0.12400116259501416, backward:0.09657468697413334, data cost:0.18652710446642234 
2022-07-25 07:27:23,234: ============================================================
2022-07-25 07:27:23,234: Epoch 20/25 Batch 6400/7662 eta: 4:27:47.542584	Training Loss1 2.1421 (2.4725)	Training Total_Loss 2.1421 (2.4725)	Training Prec@1 100.000 (99.953)	Training Prec@5 100.000 (99.985)	
2022-07-25 07:27:23,234: ============================================================
2022-07-25 07:28:03,928: time cost, forward:0.12399494198583276, backward:0.09658565384036744, data cost:0.186512428644089 
2022-07-25 07:28:03,928: ============================================================
2022-07-25 07:28:03,928: Epoch 20/25 Batch 6500/7662 eta: 4:27:43.240404	Training Loss1 2.4139 (2.4702)	Training Total_Loss 2.4139 (2.4702)	Training Prec@1 100.000 (99.953)	Training Prec@5 100.000 (99.985)	
2022-07-25 07:28:03,928: ============================================================
2022-07-25 07:28:44,646: time cost, forward:0.1239929256664657, backward:0.09659682470553752, data cost:0.18649710032195282 
2022-07-25 07:28:44,646: ============================================================
2022-07-25 07:28:44,646: Epoch 20/25 Batch 6600/7662 eta: 4:27:11.886850	Training Loss1 2.0490 (2.4672)	Training Total_Loss 2.0490 (2.4672)	Training Prec@1 100.000 (99.953)	Training Prec@5 100.000 (99.985)	
2022-07-25 07:28:44,646: ============================================================
2022-07-25 07:29:25,280: time cost, forward:0.12399200247835625, backward:0.09659514471316875, data cost:0.18648164370893133 
2022-07-25 07:29:25,280: ============================================================
2022-07-25 07:29:25,280: Epoch 20/25 Batch 6700/7662 eta: 4:25:58.280265	Training Loss1 2.1687 (2.4647)	Training Total_Loss 2.1687 (2.4647)	Training Prec@1 100.000 (99.953)	Training Prec@5 100.000 (99.985)	
2022-07-25 07:29:25,280: ============================================================
2022-07-25 07:30:05,884: time cost, forward:0.12398761222425288, backward:0.09659271759923056, data cost:0.18646654414331093 
2022-07-25 07:30:05,884: ============================================================
2022-07-25 07:30:05,884: Epoch 20/25 Batch 6800/7662 eta: 4:25:05.746584	Training Loss1 2.2084 (2.4627)	Training Total_Loss 2.2084 (2.4627)	Training Prec@1 100.000 (99.953)	Training Prec@5 100.000 (99.985)	
2022-07-25 07:30:05,884: ============================================================
2022-07-25 07:30:46,473: time cost, forward:0.12398160718665432, backward:0.0965903151603795, data cost:0.1864515970298943 
2022-07-25 07:30:46,473: ============================================================
2022-07-25 07:30:46,474: Epoch 20/25 Batch 6900/7662 eta: 4:24:19.491159	Training Loss1 2.3945 (2.4605)	Training Total_Loss 2.3945 (2.4605)	Training Prec@1 100.000 (99.954)	Training Prec@5 100.000 (99.985)	
2022-07-25 07:30:46,474: ============================================================
2022-07-25 07:31:27,057: time cost, forward:0.12397539583269673, backward:0.09658755144232903, data cost:0.1864370710084329 
2022-07-25 07:31:27,058: ============================================================
2022-07-25 07:31:27,058: Epoch 20/25 Batch 7000/7662 eta: 4:23:36.845849	Training Loss1 2.5675 (2.4582)	Training Total_Loss 2.5675 (2.4582)	Training Prec@1 99.805 (99.954)	Training Prec@5 100.000 (99.985)	
2022-07-25 07:31:27,058: ============================================================
2022-07-25 07:32:07,635: time cost, forward:0.12396878302139301, backward:0.09658439415645424, data cost:0.18642307029742392 
2022-07-25 07:32:07,636: ============================================================
2022-07-25 07:32:07,636: Epoch 20/25 Batch 7100/7662 eta: 4:22:53.882816	Training Loss1 2.3158 (2.4562)	Training Total_Loss 2.3158 (2.4562)	Training Prec@1 99.805 (99.953)	Training Prec@5 99.805 (99.985)	
2022-07-25 07:32:07,636: ============================================================
2022-07-25 07:32:48,294: time cost, forward:0.12396470124994091, backward:0.0965902741410067, data cost:0.18640896001943766 
2022-07-25 07:32:48,294: ============================================================
2022-07-25 07:32:48,294: Epoch 20/25 Batch 7200/7662 eta: 4:22:44.476093	Training Loss1 2.2528 (2.4544)	Training Total_Loss 2.2528 (2.4544)	Training Prec@1 100.000 (99.953)	Training Prec@5 100.000 (99.985)	
2022-07-25 07:32:48,294: ============================================================
2022-07-25 07:33:29,044: time cost, forward:0.12396189548786674, backward:0.0966061862433899, data cost:0.1863962885026557 
2022-07-25 07:33:29,044: ============================================================
2022-07-25 07:33:29,044: Epoch 20/25 Batch 7300/7662 eta: 4:22:39.349016	Training Loss1 2.2114 (2.4518)	Training Total_Loss 2.2114 (2.4518)	Training Prec@1 100.000 (99.954)	Training Prec@5 100.000 (99.985)	
2022-07-25 07:33:29,044: ============================================================
2022-07-25 07:34:09,787: time cost, forward:0.12395839305129594, backward:0.09662142069311717, data cost:0.18638403168528897 
2022-07-25 07:34:09,787: ============================================================
2022-07-25 07:34:09,788: Epoch 20/25 Batch 7400/7662 eta: 4:21:55.904817	Training Loss1 2.2157 (2.4494)	Training Total_Loss 2.2157 (2.4494)	Training Prec@1 100.000 (99.954)	Training Prec@5 100.000 (99.985)	
2022-07-25 07:34:09,788: ============================================================
2022-07-25 07:34:50,531: time cost, forward:0.12395475352346173, backward:0.09663687398996747, data cost:0.18637168784191774 
2022-07-25 07:34:50,531: ============================================================
2022-07-25 07:34:50,531: Epoch 20/25 Batch 7500/7662 eta: 4:21:15.206760	Training Loss1 2.5767 (2.4472)	Training Total_Loss 2.5767 (2.4472)	Training Prec@1 100.000 (99.954)	Training Prec@5 100.000 (99.985)	
2022-07-25 07:34:50,531: ============================================================
2022-07-25 07:35:31,280: time cost, forward:0.12395354769295462, backward:0.0966485314721229, data cost:0.18636093526815864 
2022-07-25 07:35:31,280: ============================================================
2022-07-25 07:35:31,280: Epoch 20/25 Batch 7600/7662 eta: 4:20:36.628161	Training Loss1 2.3186 (2.4448)	Training Total_Loss 2.3186 (2.4448)	Training Prec@1 100.000 (99.954)	Training Prec@5 100.000 (99.985)	
2022-07-25 07:35:31,280: ============================================================
2022-07-25 07:35:58,334: Epoch 20/25 Batch 7663/7662 eta: 4:20:10.956268	Training Loss1 2.1090 (2.4434)	Training Total_Loss 2.1090 (2.4434)	Training Prec@1 100.000 (99.954)	Training Prec@5 100.000 (99.985)	
2022-07-25 07:35:58,335: ============================================================
2022-07-25 07:35:58,380: Save Checkpoint...
2022-07-25 07:35:58,380: ============================================================
2022-07-25 07:36:05,477: Save done!
2022-07-25 07:36:05,477: ============================================================
2022-07-25 07:36:46,973: time cost, forward:0.12405100735751065, backward:0.09767747166180851, data cost:0.1947702325955786 
2022-07-25 07:36:46,974: ============================================================
2022-07-25 07:36:46,974: Epoch 21/25 Batch 100/7662 eta: 4:24:12.919885	Training Loss1 1.9073 (1.8657)	Training Total_Loss 1.9073 (1.8657)	Training Prec@1 99.805 (99.974)	Training Prec@5 99.805 (99.988)	
2022-07-25 07:36:46,974: ============================================================
2022-07-25 07:37:27,781: time cost, forward:0.12405551138834738, backward:0.09772127836792913, data cost:0.1901741279429527 
2022-07-25 07:37:27,781: ============================================================
2022-07-25 07:37:27,781: Epoch 21/25 Batch 200/7662 eta: 4:19:12.109572	Training Loss1 1.6155 (1.8804)	Training Total_Loss 1.6155 (1.8804)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.991)	
2022-07-25 07:37:27,782: ============================================================
2022-07-25 07:38:08,613: time cost, forward:0.12407740382446493, backward:0.09775629649592882, data cost:0.18868854851228337 
2022-07-25 07:38:08,614: ============================================================
2022-07-25 07:38:08,614: Epoch 21/25 Batch 300/7662 eta: 4:18:40.749764	Training Loss1 1.7649 (1.8765)	Training Total_Loss 1.7649 (1.8765)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.992)	
2022-07-25 07:38:08,614: ============================================================
2022-07-25 07:38:49,513: time cost, forward:0.12418381612103685, backward:0.0977809919151746, data cost:0.1880131735837549 
2022-07-25 07:38:49,514: ============================================================
2022-07-25 07:38:49,514: Epoch 21/25 Batch 400/7662 eta: 4:18:25.691683	Training Loss1 1.7482 (1.8812)	Training Total_Loss 1.7482 (1.8812)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.992)	
2022-07-25 07:38:49,514: ============================================================
2022-07-25 07:39:30,399: time cost, forward:0.12422498146852176, backward:0.09779929350277704, data cost:0.1876019351706954 
2022-07-25 07:39:30,399: ============================================================
2022-07-25 07:39:30,399: Epoch 21/25 Batch 500/7662 eta: 4:17:39.131107	Training Loss1 1.8038 (1.8798)	Training Total_Loss 1.8038 (1.8798)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.992)	
2022-07-25 07:39:30,399: ============================================================
2022-07-25 07:40:11,296: time cost, forward:0.12425637205375455, backward:0.09781605572453723, data cost:0.18734272135319016 
2022-07-25 07:40:11,297: ============================================================
2022-07-25 07:40:11,297: Epoch 21/25 Batch 600/7662 eta: 4:17:02.879616	Training Loss1 2.0462 (1.8787)	Training Total_Loss 2.0462 (1.8787)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.992)	
2022-07-25 07:40:11,297: ============================================================
2022-07-25 07:40:52,186: time cost, forward:0.124287415642254, backward:0.09783021336120257, data cost:0.1871390533720134 
2022-07-25 07:40:52,187: ============================================================
2022-07-25 07:40:52,187: Epoch 21/25 Batch 700/7662 eta: 4:16:19.108437	Training Loss1 1.9529 (1.8810)	Training Total_Loss 1.9529 (1.8810)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.992)	
2022-07-25 07:40:52,187: ============================================================
2022-07-25 07:41:33,047: time cost, forward:0.124279550676501, backward:0.09784200522717607, data cost:0.1869778931513895 
2022-07-25 07:41:33,047: ============================================================
2022-07-25 07:41:33,048: Epoch 21/25 Batch 800/7662 eta: 4:15:27.351846	Training Loss1 1.8332 (1.8807)	Training Total_Loss 1.8332 (1.8807)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.992)	
2022-07-25 07:41:33,048: ============================================================
2022-07-25 07:42:13,887: time cost, forward:0.12425244318630062, backward:0.09784575935465607, data cost:0.18685274341612954 
2022-07-25 07:42:13,887: ============================================================
2022-07-25 07:42:13,887: Epoch 21/25 Batch 900/7662 eta: 4:14:38.484682	Training Loss1 1.8037 (1.8801)	Training Total_Loss 1.8037 (1.8801)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.993)	
2022-07-25 07:42:13,887: ============================================================
2022-07-25 07:42:54,719: time cost, forward:0.12422809395584855, backward:0.09785368969967893, data cost:0.18674412002792587 
2022-07-25 07:42:54,719: ============================================================
2022-07-25 07:42:54,719: Epoch 21/25 Batch 1000/7662 eta: 4:13:54.920041	Training Loss1 2.0493 (1.8801)	Training Total_Loss 2.0493 (1.8801)	Training Prec@1 100.000 (99.979)	Training Prec@5 100.000 (99.993)	
2022-07-25 07:42:54,720: ============================================================
2022-07-25 07:43:35,540: time cost, forward:0.1242105743904565, backward:0.09785440187219926, data cost:0.18664895045529506 
2022-07-25 07:43:35,540: ============================================================
2022-07-25 07:43:35,541: Epoch 21/25 Batch 1100/7662 eta: 4:13:09.944044	Training Loss1 1.7769 (1.8808)	Training Total_Loss 1.7769 (1.8808)	Training Prec@1 100.000 (99.979)	Training Prec@5 100.000 (99.993)	
2022-07-25 07:43:35,541: ============================================================
2022-07-25 07:44:16,235: time cost, forward:0.12417983809941206, backward:0.0977848657873693, data cost:0.1865553460188763 
2022-07-25 07:44:16,235: ============================================================
2022-07-25 07:44:16,236: Epoch 21/25 Batch 1200/7662 eta: 4:11:42.357348	Training Loss1 1.6256 (1.8808)	Training Total_Loss 1.6256 (1.8808)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.992)	
2022-07-25 07:44:16,236: ============================================================
2022-07-25 07:44:56,926: time cost, forward:0.12416175184477468, backward:0.09769883644039398, data cost:0.18649399656805285 
2022-07-25 07:44:56,926: ============================================================
2022-07-25 07:44:56,926: Epoch 21/25 Batch 1300/7662 eta: 4:11:00.028114	Training Loss1 2.0309 (1.8818)	Training Total_Loss 2.0309 (1.8818)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.991)	
2022-07-25 07:44:56,926: ============================================================
2022-07-25 07:45:37,631: time cost, forward:0.12415738971511153, backward:0.09762212120694208, data cost:0.18644374741069583 
2022-07-25 07:45:37,632: ============================================================
2022-07-25 07:45:37,632: Epoch 21/25 Batch 1400/7662 eta: 4:10:24.787791	Training Loss1 1.7739 (1.8830)	Training Total_Loss 1.7739 (1.8830)	Training Prec@1 100.000 (99.979)	Training Prec@5 100.000 (99.991)	
2022-07-25 07:45:37,632: ============================================================
2022-07-25 07:46:18,307: time cost, forward:0.12413518042306729, backward:0.09755872439511065, data cost:0.18639607808047567 
2022-07-25 07:46:18,307: ============================================================
2022-07-25 07:46:18,307: Epoch 21/25 Batch 1500/7662 eta: 4:09:32.979111	Training Loss1 1.8419 (1.8815)	Training Total_Loss 1.8419 (1.8815)	Training Prec@1 100.000 (99.979)	Training Prec@5 100.000 (99.991)	
2022-07-25 07:46:18,307: ============================================================
2022-07-25 07:46:58,986: time cost, forward:0.12412259413198504, backward:0.0974992924440347, data cost:0.1863538679143203 
2022-07-25 07:46:58,987: ============================================================
2022-07-25 07:46:58,987: Epoch 21/25 Batch 1600/7662 eta: 4:08:53.912463	Training Loss1 1.7973 (1.8833)	Training Total_Loss 1.7973 (1.8833)	Training Prec@1 100.000 (99.979)	Training Prec@5 100.000 (99.991)	
2022-07-25 07:46:58,987: ============================================================
2022-07-25 07:47:39,665: time cost, forward:0.12410958771708434, backward:0.09744852104209464, data cost:0.1863161650315813 
2022-07-25 07:47:39,665: ============================================================
2022-07-25 07:47:39,666: Epoch 21/25 Batch 1700/7662 eta: 4:08:12.903636	Training Loss1 1.6992 (1.8813)	Training Total_Loss 1.6992 (1.8813)	Training Prec@1 100.000 (99.979)	Training Prec@5 100.000 (99.991)	
2022-07-25 07:47:39,666: ============================================================
2022-07-25 07:48:20,395: time cost, forward:0.12412301111777933, backward:0.0973981057623481, data cost:0.18629194657758846 
2022-07-25 07:48:20,395: ============================================================
2022-07-25 07:48:20,396: Epoch 21/25 Batch 1800/7662 eta: 4:07:50.980360	Training Loss1 1.6826 (1.8816)	Training Total_Loss 1.6826 (1.8816)	Training Prec@1 100.000 (99.980)	Training Prec@5 100.000 (99.992)	
2022-07-25 07:48:20,396: ============================================================
2022-07-25 07:49:01,059: time cost, forward:0.12411058432431897, backward:0.09735853223815726, data cost:0.18625386769423805 
2022-07-25 07:49:01,059: ============================================================
2022-07-25 07:49:01,059: Epoch 21/25 Batch 1900/7662 eta: 4:06:46.036059	Training Loss1 1.8750 (1.8805)	Training Total_Loss 1.8750 (1.8805)	Training Prec@1 99.805 (99.979)	Training Prec@5 99.805 (99.991)	
2022-07-25 07:49:01,059: ============================================================
2022-07-25 07:49:41,710: time cost, forward:0.1241040024654814, backward:0.09731603610986707, data cost:0.1862141799783635 
2022-07-25 07:49:41,710: ============================================================
2022-07-25 07:49:41,710: Epoch 21/25 Batch 2000/7662 eta: 4:06:00.745055	Training Loss1 1.9645 (1.8813)	Training Total_Loss 1.9645 (1.8813)	Training Prec@1 100.000 (99.979)	Training Prec@5 100.000 (99.991)	
2022-07-25 07:49:41,710: ============================================================
2022-07-25 07:50:22,347: time cost, forward:0.12409804218323132, backward:0.09727214210768323, data cost:0.18617803747168946 
2022-07-25 07:50:22,348: ============================================================
2022-07-25 07:50:22,348: Epoch 21/25 Batch 2100/7662 eta: 4:05:15.295734	Training Loss1 1.7250 (1.8810)	Training Total_Loss 1.7250 (1.8810)	Training Prec@1 100.000 (99.979)	Training Prec@5 100.000 (99.992)	
2022-07-25 07:50:22,348: ============================================================
2022-07-25 07:51:03,026: time cost, forward:0.12409257596056263, backward:0.09725022803875141, data cost:0.18614549829830848 
2022-07-25 07:51:03,026: ============================================================
2022-07-25 07:51:03,026: Epoch 21/25 Batch 2200/7662 eta: 4:04:49.386423	Training Loss1 1.7595 (1.8810)	Training Total_Loss 1.7595 (1.8810)	Training Prec@1 100.000 (99.979)	Training Prec@5 100.000 (99.991)	
2022-07-25 07:51:03,026: ============================================================
2022-07-25 07:51:43,799: time cost, forward:0.12408328948201382, backward:0.09727460760404463, data cost:0.1861155471785165 
2022-07-25 07:51:43,799: ============================================================
2022-07-25 07:51:43,799: Epoch 21/25 Batch 2300/7662 eta: 4:04:42.718840	Training Loss1 2.0384 (1.8824)	Training Total_Loss 2.0384 (1.8824)	Training Prec@1 100.000 (99.979)	Training Prec@5 100.000 (99.991)	
2022-07-25 07:51:43,799: ============================================================
2022-07-25 07:52:24,587: time cost, forward:0.12407759151244074, backward:0.09729757155910936, data cost:0.1860915290757784 
2022-07-25 07:52:24,588: ============================================================
2022-07-25 07:52:24,588: Epoch 21/25 Batch 2400/7662 eta: 4:04:07.586086	Training Loss1 1.5238 (1.8831)	Training Total_Loss 1.5238 (1.8831)	Training Prec@1 100.000 (99.979)	Training Prec@5 100.000 (99.991)	
2022-07-25 07:52:24,588: ============================================================
2022-07-25 07:53:05,375: time cost, forward:0.12407244391897385, backward:0.09731844741375555, data cost:0.186069186566686 
2022-07-25 07:53:05,375: ============================================================
2022-07-25 07:53:05,375: Epoch 21/25 Batch 2500/7662 eta: 4:03:26.409371	Training Loss1 1.8028 (1.8839)	Training Total_Loss 1.8028 (1.8839)	Training Prec@1 100.000 (99.979)	Training Prec@5 100.000 (99.991)	
2022-07-25 07:53:05,375: ============================================================
2022-07-25 07:53:46,165: time cost, forward:0.12406836036720291, backward:0.09733832263175961, data cost:0.18604826028184646 
2022-07-25 07:53:46,165: ============================================================
2022-07-25 07:53:46,165: Epoch 21/25 Batch 2600/7662 eta: 4:02:46.529658	Training Loss1 2.0157 (1.8834)	Training Total_Loss 2.0157 (1.8834)	Training Prec@1 100.000 (99.979)	Training Prec@5 100.000 (99.991)	
2022-07-25 07:53:46,165: ============================================================
2022-07-25 07:54:26,957: time cost, forward:0.12406593033365516, backward:0.09735553376804505, data cost:0.18602919463715584 
2022-07-25 07:54:26,957: ============================================================
2022-07-25 07:54:26,957: Epoch 21/25 Batch 2700/7662 eta: 4:02:06.370793	Training Loss1 1.9676 (1.8828)	Training Total_Loss 1.9676 (1.8828)	Training Prec@1 100.000 (99.979)	Training Prec@5 100.000 (99.991)	
2022-07-25 07:54:26,957: ============================================================
2022-07-25 07:55:07,733: time cost, forward:0.1240552131002739, backward:0.09737262235193773, data cost:0.1860126535055168 
2022-07-25 07:55:07,733: ============================================================
2022-07-25 07:55:07,734: Epoch 21/25 Batch 2800/7662 eta: 4:01:20.151969	Training Loss1 1.5903 (1.8836)	Training Total_Loss 1.5903 (1.8836)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.991)	
2022-07-25 07:55:07,734: ============================================================
2022-07-25 07:55:48,506: time cost, forward:0.12404539618832607, backward:0.09738850001426926, data cost:0.18599550951838945 
2022-07-25 07:55:48,506: ============================================================
2022-07-25 07:55:48,506: Epoch 21/25 Batch 2900/7662 eta: 4:00:37.962315	Training Loss1 2.0043 (1.8835)	Training Total_Loss 2.0043 (1.8835)	Training Prec@1 100.000 (99.979)	Training Prec@5 100.000 (99.991)	
2022-07-25 07:55:48,506: ============================================================
2022-07-25 07:56:29,291: time cost, forward:0.12403787657116683, backward:0.09740425253280126, data cost:0.18598167750786923 
2022-07-25 07:56:29,291: ============================================================
2022-07-25 07:56:29,292: Epoch 21/25 Batch 3000/7662 eta: 4:00:01.788380	Training Loss1 2.1504 (1.8846)	Training Total_Loss 2.1504 (1.8846)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.991)	
2022-07-25 07:56:29,292: ============================================================
2022-07-25 07:57:09,972: time cost, forward:0.1240280363089656, backward:0.09739168523472715, data cost:0.1859655482571292 
2022-07-25 07:57:09,972: ============================================================
2022-07-25 07:57:09,972: Epoch 21/25 Batch 3100/7662 eta: 3:58:43.983498	Training Loss1 1.7546 (1.8849)	Training Total_Loss 1.7546 (1.8849)	Training Prec@1 100.000 (99.979)	Training Prec@5 100.000 (99.991)	
2022-07-25 07:57:09,972: ============================================================
2022-07-25 07:57:50,610: time cost, forward:0.12402148595561308, backward:0.09736307854576386, data cost:0.1859529008713317 
2022-07-25 07:57:50,611: ============================================================
2022-07-25 07:57:50,611: Epoch 21/25 Batch 3200/7662 eta: 3:57:48.644752	Training Loss1 1.9099 (1.8853)	Training Total_Loss 1.9099 (1.8853)	Training Prec@1 100.000 (99.979)	Training Prec@5 100.000 (99.991)	
2022-07-25 07:57:50,611: ============================================================
2022-07-25 07:58:31,247: time cost, forward:0.12401683462789904, backward:0.0973342035206277, data cost:0.18594037456633863 
2022-07-25 07:58:31,247: ============================================================
2022-07-25 07:58:31,247: Epoch 21/25 Batch 3300/7662 eta: 3:57:07.302653	Training Loss1 2.0329 (1.8858)	Training Total_Loss 2.0329 (1.8858)	Training Prec@1 100.000 (99.979)	Training Prec@5 100.000 (99.991)	
2022-07-25 07:58:31,248: ============================================================
2022-07-25 07:59:11,874: time cost, forward:0.12400886787320278, backward:0.0973074419353246, data cost:0.18592878684256842 
2022-07-25 07:59:11,874: ============================================================
2022-07-25 07:59:11,874: Epoch 21/25 Batch 3400/7662 eta: 3:56:23.292336	Training Loss1 1.9966 (1.8872)	Training Total_Loss 1.9966 (1.8872)	Training Prec@1 100.000 (99.979)	Training Prec@5 100.000 (99.991)	
2022-07-25 07:59:11,875: ============================================================
2022-07-25 07:59:52,510: time cost, forward:0.12400369407041102, backward:0.0972803871643206, data cost:0.18592003693952666 
2022-07-25 07:59:52,510: ============================================================
2022-07-25 07:59:52,510: Epoch 21/25 Batch 3500/7662 eta: 3:55:45.633268	Training Loss1 1.7667 (1.8879)	Training Total_Loss 1.7667 (1.8879)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.991)	
2022-07-25 07:59:52,510: ============================================================
2022-07-25 08:00:33,132: time cost, forward:0.12399709526119249, backward:0.09725595050535125, data cost:0.18590880321376554 
2022-07-25 08:00:33,132: ============================================================
2022-07-25 08:00:33,132: Epoch 21/25 Batch 3600/7662 eta: 3:55:00.433087	Training Loss1 1.8123 (1.8882)	Training Total_Loss 1.8123 (1.8882)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.991)	
2022-07-25 08:00:33,132: ============================================================
2022-07-25 08:01:13,772: time cost, forward:0.12399087702464207, backward:0.0972359747653331, data cost:0.1858998102315473 
2022-07-25 08:01:13,773: ============================================================
2022-07-25 08:01:13,773: Epoch 21/25 Batch 3700/7662 eta: 3:54:26.137941	Training Loss1 2.3744 (1.8880)	Training Total_Loss 2.3744 (1.8880)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.991)	
2022-07-25 08:01:13,773: ============================================================
2022-07-25 08:01:54,410: time cost, forward:0.12398664340686723, backward:0.0972159845824617, data cost:0.1858898235892396 
2022-07-25 08:01:54,411: ============================================================
2022-07-25 08:01:54,411: Epoch 21/25 Batch 3800/7662 eta: 3:53:44.529335	Training Loss1 1.8567 (1.8872)	Training Total_Loss 1.8567 (1.8872)	Training Prec@1 99.805 (99.978)	Training Prec@5 99.805 (99.991)	
2022-07-25 08:01:54,411: ============================================================
2022-07-25 08:02:35,044: time cost, forward:0.12398073544224643, backward:0.09719674695482863, data cost:0.1858811891516162 
2022-07-25 08:02:35,044: ============================================================
2022-07-25 08:02:35,044: Epoch 21/25 Batch 3900/7662 eta: 3:53:02.328085	Training Loss1 1.7274 (1.8865)	Training Total_Loss 1.7274 (1.8865)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.991)	
2022-07-25 08:02:35,044: ============================================================
2022-07-25 08:03:15,694: time cost, forward:0.12397584100758084, backward:0.09717797028717323, data cost:0.1858743797334679 
2022-07-25 08:03:15,695: ============================================================
2022-07-25 08:03:15,695: Epoch 21/25 Batch 4000/7662 eta: 3:52:27.651483	Training Loss1 1.6286 (1.8866)	Training Total_Loss 1.6286 (1.8866)	Training Prec@1 100.000 (99.979)	Training Prec@5 100.000 (99.991)	
2022-07-25 08:03:15,695: ============================================================
2022-07-25 08:03:56,339: time cost, forward:0.12397129467621928, backward:0.09716190661299837, data cost:0.18586715048887462 
2022-07-25 08:03:56,339: ============================================================
2022-07-25 08:03:56,339: Epoch 21/25 Batch 4100/7662 eta: 3:51:44.858335	Training Loss1 1.6614 (1.8880)	Training Total_Loss 1.6614 (1.8880)	Training Prec@1 100.000 (99.979)	Training Prec@5 100.000 (99.991)	
2022-07-25 08:03:56,339: ============================================================
2022-07-25 08:04:36,997: time cost, forward:0.12396895661187132, backward:0.09714775097940785, data cost:0.1858607343504275 
2022-07-25 08:04:36,997: ============================================================
2022-07-25 08:04:36,997: Epoch 21/25 Batch 4200/7662 eta: 3:51:08.896002	Training Loss1 1.7316 (1.8885)	Training Total_Loss 1.7316 (1.8885)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.991)	
2022-07-25 08:04:36,998: ============================================================
2022-07-25 08:05:17,630: time cost, forward:0.12396346233312017, backward:0.09713051030180515, data cost:0.18585600146417647 
2022-07-25 08:05:17,630: ============================================================
2022-07-25 08:05:17,631: Epoch 21/25 Batch 4300/7662 eta: 3:50:19.731356	Training Loss1 1.9313 (1.8893)	Training Total_Loss 1.9313 (1.8893)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.991)	
2022-07-25 08:05:17,631: ============================================================
2022-07-25 08:05:58,268: time cost, forward:0.12395891700990906, backward:0.09711392680794902, data cost:0.18585273145843456 
2022-07-25 08:05:58,268: ============================================================
2022-07-25 08:05:58,268: Epoch 21/25 Batch 4400/7662 eta: 3:49:40.564612	Training Loss1 1.7116 (1.8896)	Training Total_Loss 1.7116 (1.8896)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.991)	
2022-07-25 08:05:58,268: ============================================================
2022-07-25 08:06:38,901: time cost, forward:0.1239549577911845, backward:0.09709802493171497, data cost:0.18584831175896346 
2022-07-25 08:06:38,901: ============================================================
2022-07-25 08:06:38,901: Epoch 21/25 Batch 4500/7662 eta: 3:48:58.568051	Training Loss1 1.4974 (1.8898)	Training Total_Loss 1.4974 (1.8898)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.991)	
2022-07-25 08:06:38,902: ============================================================
2022-07-25 08:07:19,587: time cost, forward:0.12395112684017214, backward:0.09709522246692356, data cost:0.18584265587614474 
2022-07-25 08:07:19,587: ============================================================
2022-07-25 08:07:19,588: Epoch 21/25 Batch 4600/7662 eta: 3:48:35.738915	Training Loss1 2.0999 (1.8894)	Training Total_Loss 2.0999 (1.8894)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.991)	
2022-07-25 08:07:19,588: ============================================================
2022-07-25 08:08:00,398: time cost, forward:0.12394913822368095, backward:0.09711297544222432, data cost:0.1858409578482073 
2022-07-25 08:08:00,398: ============================================================
2022-07-25 08:08:00,398: Epoch 21/25 Batch 4700/7662 eta: 3:48:36.814960	Training Loss1 1.6962 (1.8893)	Training Total_Loss 1.6962 (1.8893)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.991)	
2022-07-25 08:08:00,398: ============================================================
2022-07-25 08:08:41,227: time cost, forward:0.12395027911422103, backward:0.09713122267900941, data cost:0.1858388193201636 
2022-07-25 08:08:41,227: ============================================================
2022-07-25 08:08:41,227: Epoch 21/25 Batch 4800/7662 eta: 3:48:02.189570	Training Loss1 2.0026 (1.8899)	Training Total_Loss 2.0026 (1.8899)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.991)	
2022-07-25 08:08:41,227: ============================================================
2022-07-25 08:09:22,068: time cost, forward:0.12395445403577747, backward:0.09714741170540175, data cost:0.1858378035799779 
2022-07-25 08:09:22,068: ============================================================
2022-07-25 08:09:22,069: Epoch 21/25 Batch 4900/7662 eta: 3:47:25.545932	Training Loss1 1.8450 (1.8893)	Training Total_Loss 1.8450 (1.8893)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.991)	
2022-07-25 08:09:22,069: ============================================================
2022-07-25 08:10:02,898: time cost, forward:0.12395626322034121, backward:0.09716267398796836, data cost:0.18583688599559206 
2022-07-25 08:10:02,898: ============================================================
2022-07-25 08:10:02,898: Epoch 21/25 Batch 5000/7662 eta: 3:46:40.732363	Training Loss1 2.0205 (1.8896)	Training Total_Loss 2.0205 (1.8896)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.991)	
2022-07-25 08:10:02,898: ============================================================
2022-07-25 08:10:43,733: time cost, forward:0.12395819834013223, backward:0.09717868131430717, data cost:0.18583545569789997 
2022-07-25 08:10:43,733: ============================================================
2022-07-25 08:10:43,733: Epoch 21/25 Batch 5100/7662 eta: 3:46:01.762459	Training Loss1 2.1054 (1.8903)	Training Total_Loss 2.1054 (1.8903)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.991)	
2022-07-25 08:10:43,733: ============================================================
2022-07-25 08:11:24,525: time cost, forward:0.1239533765106436, backward:0.09719322612364033, data cost:0.18583358336146186 
2022-07-25 08:11:24,525: ============================================================
2022-07-25 08:11:24,525: Epoch 21/25 Batch 5200/7662 eta: 3:45:06.615061	Training Loss1 2.1000 (1.8901)	Training Total_Loss 2.1000 (1.8901)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.991)	
2022-07-25 08:11:24,525: ============================================================
2022-07-25 08:12:05,398: time cost, forward:0.12396400580880416, backward:0.09720972097691645, data cost:0.18583015771064249 
2022-07-25 08:12:05,398: ============================================================
2022-07-25 08:12:05,398: Epoch 21/25 Batch 5300/7662 eta: 3:44:52.580569	Training Loss1 1.5203 (1.8910)	Training Total_Loss 1.5203 (1.8910)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.991)	
2022-07-25 08:12:05,398: ============================================================
2022-07-25 08:12:46,176: time cost, forward:0.1239609212693428, backward:0.0972210133289889, data cost:0.18582697390715133 
2022-07-25 08:12:46,177: ============================================================
2022-07-25 08:12:46,177: Epoch 21/25 Batch 5400/7662 eta: 3:43:40.696826	Training Loss1 1.8882 (1.8909)	Training Total_Loss 1.8882 (1.8909)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.991)	
2022-07-25 08:12:46,177: ============================================================
2022-07-25 08:13:26,986: time cost, forward:0.12396214801325627, backward:0.09723182278647165, data cost:0.18582560565606487 
2022-07-25 08:13:26,987: ============================================================
2022-07-25 08:13:26,987: Epoch 21/25 Batch 5500/7662 eta: 3:43:10.094765	Training Loss1 1.7378 (1.8912)	Training Total_Loss 1.7378 (1.8912)	Training Prec@1 99.805 (99.978)	Training Prec@5 100.000 (99.991)	
2022-07-25 08:13:26,987: ============================================================
2022-07-25 08:14:07,797: time cost, forward:0.12396118423303848, backward:0.09724484471087584, data cost:0.18582402814560903 
2022-07-25 08:14:07,798: ============================================================
2022-07-25 08:14:07,798: Epoch 21/25 Batch 5600/7662 eta: 3:42:29.688039	Training Loss1 1.8123 (1.8910)	Training Total_Loss 1.8123 (1.8910)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.992)	
2022-07-25 08:14:07,798: ============================================================
2022-07-25 08:14:48,584: time cost, forward:0.12395895880802742, backward:0.09725523346410464, data cost:0.18582174865420104 
2022-07-25 08:14:48,584: ============================================================
2022-07-25 08:14:48,584: Epoch 21/25 Batch 5700/7662 eta: 3:41:40.908677	Training Loss1 1.7640 (1.8910)	Training Total_Loss 1.7640 (1.8910)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.991)	
2022-07-25 08:14:48,584: ============================================================
2022-07-25 08:15:29,397: time cost, forward:0.12395909494892403, backward:0.09726715770378712, data cost:0.18582005911108584 
2022-07-25 08:15:29,398: ============================================================
2022-07-25 08:15:29,398: Epoch 21/25 Batch 5800/7662 eta: 3:41:08.896805	Training Loss1 2.0024 (1.8916)	Training Total_Loss 2.0024 (1.8916)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.991)	
2022-07-25 08:15:29,398: ============================================================
2022-07-25 08:16:10,217: time cost, forward:0.12396272256588972, backward:0.09727603897318474, data cost:0.18581823418354215 
2022-07-25 08:16:10,217: ============================================================
2022-07-25 08:16:10,217: Epoch 21/25 Batch 5900/7662 eta: 3:40:29.867960	Training Loss1 1.9454 (1.8916)	Training Total_Loss 1.9454 (1.8916)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.991)	
2022-07-25 08:16:10,217: ============================================================
2022-07-25 08:16:51,026: time cost, forward:0.1239638801494585, backward:0.09728578516474802, data cost:0.18581613096957963 
2022-07-25 08:16:51,026: ============================================================
2022-07-25 08:16:51,026: Epoch 21/25 Batch 6000/7662 eta: 3:39:45.807473	Training Loss1 1.7203 (1.8917)	Training Total_Loss 1.7203 (1.8917)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.991)	
2022-07-25 08:16:51,026: ============================================================
2022-07-25 08:17:31,839: time cost, forward:0.12396683206634847, backward:0.09729385270429725, data cost:0.18581421712633625 
2022-07-25 08:17:31,839: ============================================================
2022-07-25 08:17:31,839: Epoch 21/25 Batch 6100/7662 eta: 3:39:06.246389	Training Loss1 1.7074 (1.8919)	Training Total_Loss 1.7074 (1.8919)	Training Prec@1 99.609 (99.977)	Training Prec@5 100.000 (99.991)	
2022-07-25 08:17:31,839: ============================================================
2022-07-25 08:18:12,607: time cost, forward:0.12396344205490484, backward:0.0973022763316411, data cost:0.185810837135678 
2022-07-25 08:18:12,607: ============================================================
2022-07-25 08:18:12,607: Epoch 21/25 Batch 6200/7662 eta: 3:38:11.189600	Training Loss1 1.7765 (1.8920)	Training Total_Loss 1.7765 (1.8920)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.991)	
2022-07-25 08:18:12,608: ============================================================
2022-07-25 08:18:53,394: time cost, forward:0.12396451730087724, backward:0.09731023900943023, data cost:0.18580636120463273 
2022-07-25 08:18:53,395: ============================================================
2022-07-25 08:18:53,395: Epoch 21/25 Batch 6300/7662 eta: 3:37:36.434086	Training Loss1 2.1702 (1.8921)	Training Total_Loss 2.1702 (1.8921)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.991)	
2022-07-25 08:18:53,395: ============================================================
2022-07-25 08:19:34,152: time cost, forward:0.12396314975376668, backward:0.09731685945737695, data cost:0.18580058318112935 
2022-07-25 08:19:34,152: ============================================================
2022-07-25 08:19:34,152: Epoch 21/25 Batch 6400/7662 eta: 3:36:46.049950	Training Loss1 2.4317 (1.8924)	Training Total_Loss 2.4317 (1.8924)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.991)	
2022-07-25 08:19:34,152: ============================================================
2022-07-25 08:20:14,970: time cost, forward:0.12397178214666457, backward:0.09732226585127571, data cost:0.18579576198532685 
2022-07-25 08:20:14,970: ============================================================
2022-07-25 08:20:14,970: Epoch 21/25 Batch 6500/7662 eta: 3:36:24.638123	Training Loss1 1.9656 (1.8930)	Training Total_Loss 1.9656 (1.8930)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.991)	
2022-07-25 08:20:14,970: ============================================================
2022-07-25 08:20:55,783: time cost, forward:0.12397851353613676, backward:0.09732894591082766, data cost:0.1857904176094944 
2022-07-25 08:20:55,783: ============================================================
2022-07-25 08:20:55,783: Epoch 21/25 Batch 6600/7662 eta: 3:35:42.326321	Training Loss1 1.8211 (1.8933)	Training Total_Loss 1.8211 (1.8933)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.991)	
2022-07-25 08:20:55,784: ============================================================
2022-07-25 08:21:36,571: time cost, forward:0.12397952563087519, backward:0.09733779047083224, data cost:0.18578454095368102 
2022-07-25 08:21:36,571: ============================================================
2022-07-25 08:21:36,571: Epoch 21/25 Batch 6700/7662 eta: 3:34:53.485067	Training Loss1 1.7555 (1.8935)	Training Total_Loss 1.7555 (1.8935)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.991)	
2022-07-25 08:21:36,572: ============================================================
2022-07-25 08:22:17,394: time cost, forward:0.12398723210108809, backward:0.09734396851050502, data cost:0.18578012337805963 
2022-07-25 08:22:17,395: ============================================================
2022-07-25 08:22:17,395: Epoch 21/25 Batch 6800/7662 eta: 3:34:23.890956	Training Loss1 1.7558 (1.8935)	Training Total_Loss 1.7558 (1.8935)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.991)	
2022-07-25 08:22:17,395: ============================================================
2022-07-25 08:22:58,228: time cost, forward:0.12399613596353173, backward:0.09734977451091677, data cost:0.1857759237876922 
2022-07-25 08:22:58,228: ============================================================
2022-07-25 08:22:58,228: Epoch 21/25 Batch 6900/7662 eta: 3:33:46.179577	Training Loss1 1.5784 (1.8939)	Training Total_Loss 1.5784 (1.8939)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.991)	
2022-07-25 08:22:58,228: ============================================================
2022-07-25 08:23:39,083: time cost, forward:0.12400952443546492, backward:0.09735308801945593, data cost:0.185772676436556 
2022-07-25 08:23:39,083: ============================================================
2022-07-25 08:23:39,084: Epoch 21/25 Batch 7000/7662 eta: 3:33:12.188858	Training Loss1 1.9398 (1.8941)	Training Total_Loss 1.9398 (1.8941)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.991)	
2022-07-25 08:23:39,084: ============================================================
2022-07-25 08:24:19,929: time cost, forward:0.12401801587024328, backward:0.09736037056183107, data cost:0.18576879003615862 
2022-07-25 08:24:19,930: ============================================================
2022-07-25 08:24:19,930: Epoch 21/25 Batch 7100/7662 eta: 3:32:28.484634	Training Loss1 1.6287 (1.8943)	Training Total_Loss 1.6287 (1.8943)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.991)	
2022-07-25 08:24:19,930: ============================================================
2022-07-25 08:25:00,739: time cost, forward:0.12402104086173145, backward:0.09736762571407699, data cost:0.18576477808925174 
2022-07-25 08:25:00,740: ============================================================
2022-07-25 08:25:00,740: Epoch 21/25 Batch 7200/7662 eta: 3:31:36.397895	Training Loss1 1.5411 (1.8945)	Training Total_Loss 1.5411 (1.8945)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.991)	
2022-07-25 08:25:00,740: ============================================================
2022-07-25 08:25:41,642: time cost, forward:0.12404196467166373, backward:0.09736955321019668, data cost:0.18576074273704846 
2022-07-25 08:25:41,642: ============================================================
2022-07-25 08:25:41,643: Epoch 21/25 Batch 7300/7662 eta: 3:31:24.399274	Training Loss1 1.7354 (1.8946)	Training Total_Loss 1.7354 (1.8946)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.991)	
2022-07-25 08:25:41,643: ============================================================
2022-07-25 08:26:22,536: time cost, forward:0.12405731794334357, backward:0.09737506591398855, data cost:0.1857569691361181 
2022-07-25 08:26:22,536: ============================================================
2022-07-25 08:26:22,536: Epoch 21/25 Batch 7400/7662 eta: 3:30:40.543973	Training Loss1 2.0013 (1.8949)	Training Total_Loss 2.0013 (1.8949)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.991)	
2022-07-25 08:26:22,536: ============================================================
2022-07-25 08:27:03,441: time cost, forward:0.1240684567077714, backward:0.0973860686867217, data cost:0.18575292778803612 
2022-07-25 08:27:03,441: ============================================================
2022-07-25 08:27:03,441: Epoch 21/25 Batch 7500/7662 eta: 3:30:03.364642	Training Loss1 1.6128 (1.8952)	Training Total_Loss 1.6128 (1.8952)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.991)	
2022-07-25 08:27:03,442: ============================================================
2022-07-25 08:27:44,314: time cost, forward:0.1240891050799832, backward:0.09738108954597169, data cost:0.18574922049354606 
2022-07-25 08:27:44,315: ============================================================
2022-07-25 08:27:44,315: Epoch 21/25 Batch 7600/7662 eta: 3:29:12.593768	Training Loss1 2.0381 (1.8951)	Training Total_Loss 2.0381 (1.8951)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.991)	
2022-07-25 08:27:44,315: ============================================================
2022-07-25 08:28:11,810: Epoch 21/25 Batch 7663/7662 eta: 3:28:46.843600	Training Loss1 2.0268 (1.8953)	Training Total_Loss 2.0268 (1.8953)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.991)	
2022-07-25 08:28:11,811: ============================================================
2022-07-25 08:28:55,602: time cost, forward:0.12363729091605755, backward:0.09633355429678252, data cost:0.21933422184953785 
2022-07-25 08:28:55,615: ============================================================
2022-07-25 08:28:55,616: Epoch 22/25 Batch 100/7662 eta: 3:42:42.663202	Training Loss1 1.7462 (1.5621)	Training Total_Loss 1.7462 (1.5621)	Training Prec@1 100.000 (99.986)	Training Prec@5 100.000 (99.998)	
2022-07-25 08:28:55,616: ============================================================
2022-07-25 08:29:36,210: time cost, forward:0.12374364311371616, backward:0.0963029621833533, data cost:0.20229415677899693 
2022-07-25 08:29:36,211: ============================================================
2022-07-25 08:29:36,211: Epoch 22/25 Batch 200/7662 eta: 3:26:00.905353	Training Loss1 1.1844 (1.5403)	Training Total_Loss 1.1844 (1.5403)	Training Prec@1 100.000 (99.984)	Training Prec@5 100.000 (99.996)	
2022-07-25 08:29:36,211: ============================================================
2022-07-25 08:30:16,854: time cost, forward:0.12391476567373627, backward:0.09630473082679569, data cost:0.19661776038715273 
2022-07-25 08:30:16,854: ============================================================
2022-07-25 08:30:16,855: Epoch 22/25 Batch 300/7662 eta: 3:25:34.966246	Training Loss1 2.0276 (1.5471)	Training Total_Loss 2.0276 (1.5471)	Training Prec@1 100.000 (99.983)	Training Prec@5 100.000 (99.995)	
2022-07-25 08:30:16,855: ============================================================
2022-07-25 08:30:57,489: time cost, forward:0.12392839752044295, backward:0.09631671343829698, data cost:0.1938249078908361 
2022-07-25 08:30:57,489: ============================================================
2022-07-25 08:30:57,490: Epoch 22/25 Batch 400/7662 eta: 3:24:51.628789	Training Loss1 1.4011 (1.5463)	Training Total_Loss 1.4011 (1.5463)	Training Prec@1 99.805 (99.986)	Training Prec@5 100.000 (99.996)	
2022-07-25 08:30:57,490: ============================================================
2022-07-25 08:31:38,146: time cost, forward:0.12394857024382017, backward:0.0963269670406181, data cost:0.19218203634441736 
2022-07-25 08:31:38,146: ============================================================
2022-07-25 08:31:38,146: Epoch 22/25 Batch 500/7662 eta: 3:24:17.560562	Training Loss1 1.4387 (1.5508)	Training Total_Loss 1.4387 (1.5508)	Training Prec@1 100.000 (99.986)	Training Prec@5 100.000 (99.995)	
2022-07-25 08:31:38,146: ============================================================
2022-07-25 08:32:18,786: time cost, forward:0.1239487782543609, backward:0.09632941836705788, data cost:0.19107731873284597 
2022-07-25 08:32:18,786: ============================================================
2022-07-25 08:32:18,786: Epoch 22/25 Batch 600/7662 eta: 3:23:31.984772	Training Loss1 1.5403 (1.5505)	Training Total_Loss 1.5403 (1.5505)	Training Prec@1 100.000 (99.987)	Training Prec@5 100.000 (99.995)	
2022-07-25 08:32:18,786: ============================================================
2022-07-25 08:32:59,369: time cost, forward:0.12388613432091534, backward:0.09634442049716846, data cost:0.1902607370684928 
2022-07-25 08:32:59,370: ============================================================
2022-07-25 08:32:59,370: Epoch 22/25 Batch 700/7662 eta: 3:22:34.344747	Training Loss1 2.0208 (1.5568)	Training Total_Loss 2.0208 (1.5568)	Training Prec@1 100.000 (99.987)	Training Prec@5 100.000 (99.996)	
2022-07-25 08:32:59,370: ============================================================
2022-07-25 08:33:39,957: time cost, forward:0.12384861759906717, backward:0.09635003457528928, data cost:0.18965514341791223 
2022-07-25 08:33:39,957: ============================================================
2022-07-25 08:33:39,957: Epoch 22/25 Batch 800/7662 eta: 3:21:54.918069	Training Loss1 1.6435 (1.5561)	Training Total_Loss 1.6435 (1.5561)	Training Prec@1 100.000 (99.988)	Training Prec@5 100.000 (99.996)	
2022-07-25 08:33:39,957: ============================================================
2022-07-25 08:34:20,542: time cost, forward:0.12381272268242247, backward:0.09635785742516778, data cost:0.18918635635673006 
2022-07-25 08:34:20,543: ============================================================
2022-07-25 08:34:20,543: Epoch 22/25 Batch 900/7662 eta: 3:21:13.840896	Training Loss1 1.2895 (1.5586)	Training Total_Loss 1.2895 (1.5586)	Training Prec@1 100.000 (99.988)	Training Prec@5 100.000 (99.996)	
2022-07-25 08:34:20,543: ============================================================
2022-07-25 08:35:01,128: time cost, forward:0.12378404329011629, backward:0.09636748421776879, data cost:0.18880331217944324 
2022-07-25 08:35:01,128: ============================================================
2022-07-25 08:35:01,128: Epoch 22/25 Batch 1000/7662 eta: 3:20:33.197228	Training Loss1 1.6158 (1.5581)	Training Total_Loss 1.6158 (1.5581)	Training Prec@1 100.000 (99.988)	Training Prec@5 100.000 (99.996)	
2022-07-25 08:35:01,128: ============================================================
2022-07-25 08:35:41,712: time cost, forward:0.12376411531706959, backward:0.09637161772071068, data cost:0.18849180436763469 
2022-07-25 08:35:41,712: ============================================================
2022-07-25 08:35:41,712: Epoch 22/25 Batch 1100/7662 eta: 3:19:52.145269	Training Loss1 1.6586 (1.5604)	Training Total_Loss 1.6586 (1.5604)	Training Prec@1 99.805 (99.988)	Training Prec@5 100.000 (99.996)	
2022-07-25 08:35:41,712: ============================================================
2022-07-25 08:36:22,290: time cost, forward:0.12374270429603253, backward:0.0963761289483612, data cost:0.188229590878077 
2022-07-25 08:36:22,291: ============================================================
2022-07-25 08:36:22,291: Epoch 22/25 Batch 1200/7662 eta: 3:19:09.997300	Training Loss1 1.4176 (1.5596)	Training Total_Loss 1.4176 (1.5596)	Training Prec@1 100.000 (99.989)	Training Prec@5 100.000 (99.996)	
2022-07-25 08:36:22,291: ============================================================
2022-07-25 08:37:02,916: time cost, forward:0.1237567034567935, backward:0.09638116798371513, data cost:0.18800870155352092 
2022-07-25 08:37:02,916: ============================================================
2022-07-25 08:37:02,916: Epoch 22/25 Batch 1300/7662 eta: 3:18:43.127743	Training Loss1 1.4973 (1.5596)	Training Total_Loss 1.4973 (1.5596)	Training Prec@1 100.000 (99.989)	Training Prec@5 100.000 (99.996)	
2022-07-25 08:37:02,916: ============================================================
2022-07-25 08:37:43,632: time cost, forward:0.12381111902369185, backward:0.09638189894544644, data cost:0.1878446479453795 
2022-07-25 08:37:43,633: ============================================================
2022-07-25 08:37:43,633: Epoch 22/25 Batch 1400/7662 eta: 3:18:29.234997	Training Loss1 1.5596 (1.5606)	Training Total_Loss 1.5596 (1.5606)	Training Prec@1 100.000 (99.989)	Training Prec@5 100.000 (99.996)	
2022-07-25 08:37:43,633: ============================================================
2022-07-25 08:38:24,310: time cost, forward:0.12382353950612461, backward:0.09639082390757861, data cost:0.18770556612122927 
2022-07-25 08:38:24,311: ============================================================
2022-07-25 08:38:24,311: Epoch 22/25 Batch 1500/7662 eta: 3:17:37.204707	Training Loss1 1.7011 (1.5617)	Training Total_Loss 1.7011 (1.5617)	Training Prec@1 100.000 (99.989)	Training Prec@5 100.000 (99.996)	
2022-07-25 08:38:24,311: ============================================================
2022-07-25 08:39:05,001: time cost, forward:0.1238307195428463, backward:0.09640142439006641, data cost:0.187591404822411 
2022-07-25 08:39:05,001: ============================================================
2022-07-25 08:39:05,001: Epoch 22/25 Batch 1600/7662 eta: 3:17:00.085351	Training Loss1 1.5342 (1.5629)	Training Total_Loss 1.5342 (1.5629)	Training Prec@1 100.000 (99.988)	Training Prec@5 100.000 (99.995)	
2022-07-25 08:39:05,001: ============================================================
2022-07-25 08:39:45,686: time cost, forward:0.12384232077056903, backward:0.09640736029806243, data cost:0.1874868788390808 
2022-07-25 08:39:45,686: ============================================================
2022-07-25 08:39:45,686: Epoch 22/25 Batch 1700/7662 eta: 3:16:18.006579	Training Loss1 1.4508 (1.5647)	Training Total_Loss 1.4508 (1.5647)	Training Prec@1 100.000 (99.988)	Training Prec@5 100.000 (99.995)	
2022-07-25 08:39:45,686: ============================================================
2022-07-25 08:40:26,331: time cost, forward:0.1238351147860007, backward:0.09640926742235643, data cost:0.18739161125615678 
2022-07-25 08:40:26,331: ============================================================
2022-07-25 08:40:26,331: Epoch 22/25 Batch 1800/7662 eta: 3:15:25.556984	Training Loss1 1.7315 (1.5655)	Training Total_Loss 1.7315 (1.5655)	Training Prec@1 100.000 (99.988)	Training Prec@5 100.000 (99.995)	
2022-07-25 08:40:26,331: ============================================================
2022-07-25 08:41:06,961: time cost, forward:0.12382619502733982, backward:0.09640858147004958, data cost:0.18730374836432048 
2022-07-25 08:41:06,961: ============================================================
2022-07-25 08:41:06,961: Epoch 22/25 Batch 1900/7662 eta: 3:14:40.795432	Training Loss1 1.5505 (1.5671)	Training Total_Loss 1.5505 (1.5671)	Training Prec@1 100.000 (99.987)	Training Prec@5 100.000 (99.995)	
2022-07-25 08:41:06,961: ============================================================
2022-07-25 08:41:47,595: time cost, forward:0.1238158894157696, backward:0.09641428396903377, data cost:0.1872235339185248 
2022-07-25 08:41:47,596: ============================================================
2022-07-25 08:41:47,596: Epoch 22/25 Batch 2000/7662 eta: 3:14:01.373473	Training Loss1 1.5992 (1.5703)	Training Total_Loss 1.5992 (1.5703)	Training Prec@1 100.000 (99.987)	Training Prec@5 100.000 (99.995)	
2022-07-25 08:41:47,596: ============================================================
2022-07-25 08:42:28,232: time cost, forward:0.12381632808505381, backward:0.09641765378213259, data cost:0.18714290224068955 
2022-07-25 08:42:28,232: ============================================================
2022-07-25 08:42:28,233: Epoch 22/25 Batch 2100/7662 eta: 3:13:21.353013	Training Loss1 1.8953 (1.5717)	Training Total_Loss 1.8953 (1.5717)	Training Prec@1 100.000 (99.987)	Training Prec@5 100.000 (99.995)	
2022-07-25 08:42:28,233: ============================================================
2022-07-25 08:43:08,856: time cost, forward:0.12381296160005341, backward:0.09641731213634261, data cost:0.18707108692778085 
2022-07-25 08:43:08,856: ============================================================
2022-07-25 08:43:08,857: Epoch 22/25 Batch 2200/7662 eta: 3:12:37.167293	Training Loss1 1.5217 (1.5734)	Training Total_Loss 1.5217 (1.5734)	Training Prec@1 100.000 (99.987)	Training Prec@5 100.000 (99.995)	
2022-07-25 08:43:08,857: ============================================================
2022-07-25 08:43:49,488: time cost, forward:0.1238086640497766, backward:0.09641663133190631, data cost:0.18701027289013492 
2022-07-25 08:43:49,489: ============================================================
2022-07-25 08:43:49,489: Epoch 22/25 Batch 2300/7662 eta: 3:11:58.829881	Training Loss1 1.2739 (1.5737)	Training Total_Loss 1.2739 (1.5737)	Training Prec@1 100.000 (99.987)	Training Prec@5 100.000 (99.995)	
2022-07-25 08:43:49,489: ============================================================
2022-07-25 08:44:30,121: time cost, forward:0.12380134537598649, backward:0.09641977209208061, data cost:0.18695654139612158 
2022-07-25 08:44:30,122: ============================================================
2022-07-25 08:44:30,122: Epoch 22/25 Batch 2400/7662 eta: 3:11:18.404624	Training Loss1 1.4167 (1.5749)	Training Total_Loss 1.4167 (1.5749)	Training Prec@1 100.000 (99.988)	Training Prec@5 100.000 (99.995)	
2022-07-25 08:44:30,122: ============================================================
2022-07-25 08:45:10,748: time cost, forward:0.12379322704576215, backward:0.09642134136369392, data cost:0.18690714849477388 
2022-07-25 08:45:10,748: ============================================================
2022-07-25 08:45:10,748: Epoch 22/25 Batch 2500/7662 eta: 3:10:35.886678	Training Loss1 1.5151 (1.5752)	Training Total_Loss 1.5151 (1.5752)	Training Prec@1 100.000 (99.988)	Training Prec@5 100.000 (99.995)	
2022-07-25 08:45:10,748: ============================================================
2022-07-25 08:45:51,382: time cost, forward:0.12378836311070265, backward:0.09642138266480854, data cost:0.18686353431017685 
2022-07-25 08:45:51,383: ============================================================
2022-07-25 08:45:51,383: Epoch 22/25 Batch 2600/7662 eta: 3:09:57.608295	Training Loss1 1.6223 (1.5777)	Training Total_Loss 1.6223 (1.5777)	Training Prec@1 100.000 (99.987)	Training Prec@5 100.000 (99.995)	
2022-07-25 08:45:51,383: ============================================================
2022-07-25 08:46:32,010: time cost, forward:0.12378359644799022, backward:0.09642261017159472, data cost:0.18681921628547093 
2022-07-25 08:46:32,010: ============================================================
2022-07-25 08:46:32,010: Epoch 22/25 Batch 2700/7662 eta: 3:09:15.022771	Training Loss1 1.4697 (1.5796)	Training Total_Loss 1.4697 (1.5796)	Training Prec@1 100.000 (99.987)	Training Prec@5 100.000 (99.995)	
2022-07-25 08:46:32,010: ============================================================
2022-07-25 08:47:12,655: time cost, forward:0.12378807773160781, backward:0.0964245256162959, data cost:0.186773597533978 
2022-07-25 08:47:12,655: ============================================================
2022-07-25 08:47:12,655: Epoch 22/25 Batch 2800/7662 eta: 3:08:39.163366	Training Loss1 1.4841 (1.5801)	Training Total_Loss 1.4841 (1.5801)	Training Prec@1 100.000 (99.987)	Training Prec@5 100.000 (99.995)	
2022-07-25 08:47:12,655: ============================================================
2022-07-25 08:47:53,280: time cost, forward:0.12378694748788013, backward:0.0964246334064085, data cost:0.1867308613348517 
2022-07-25 08:47:53,280: ============================================================
2022-07-25 08:47:53,281: Epoch 22/25 Batch 2900/7662 eta: 3:07:53.178916	Training Loss1 1.6445 (1.5806)	Training Total_Loss 1.6445 (1.5806)	Training Prec@1 100.000 (99.987)	Training Prec@5 100.000 (99.995)	
2022-07-25 08:47:53,281: ============================================================
2022-07-25 08:48:33,975: time cost, forward:0.12377838358635822, backward:0.09645383896212373, data cost:0.18669276016479575 
2022-07-25 08:48:33,975: ============================================================
2022-07-25 08:48:33,975: Epoch 22/25 Batch 3000/7662 eta: 3:07:31.564748	Training Loss1 1.6589 (1.5812)	Training Total_Loss 1.6589 (1.5812)	Training Prec@1 100.000 (99.987)	Training Prec@5 100.000 (99.995)	
2022-07-25 08:48:33,975: ============================================================
2022-07-25 08:49:14,714: time cost, forward:0.1237713338944865, backward:0.0964974431539205, data cost:0.1866535570360684 
2022-07-25 08:49:14,714: ============================================================
2022-07-25 08:49:14,714: Epoch 22/25 Batch 3100/7662 eta: 3:07:03.312782	Training Loss1 1.8884 (1.5827)	Training Total_Loss 1.8884 (1.5827)	Training Prec@1 100.000 (99.987)	Training Prec@5 100.000 (99.995)	
2022-07-25 08:49:14,715: ============================================================
2022-07-25 08:49:55,458: time cost, forward:0.12376947967884652, backward:0.09653638384796076, data cost:0.18661572039593158 
2022-07-25 08:49:55,458: ============================================================
2022-07-25 08:49:55,459: Epoch 22/25 Batch 3200/7662 eta: 3:06:23.846791	Training Loss1 1.2937 (1.5830)	Training Total_Loss 1.2937 (1.5830)	Training Prec@1 100.000 (99.987)	Training Prec@5 100.000 (99.995)	
2022-07-25 08:49:55,459: ============================================================
2022-07-25 08:50:36,181: time cost, forward:0.12376418811836254, backward:0.09657232831484912, data cost:0.18657849636465249 
2022-07-25 08:50:36,182: ============================================================
2022-07-25 08:50:36,182: Epoch 22/25 Batch 3300/7662 eta: 3:05:37.432591	Training Loss1 1.7901 (1.5839)	Training Total_Loss 1.7901 (1.5839)	Training Prec@1 100.000 (99.987)	Training Prec@5 100.000 (99.995)	
2022-07-25 08:50:36,182: ============================================================
2022-07-25 08:51:16,918: time cost, forward:0.1237606298015131, backward:0.096607885559926, data cost:0.18654347083329384 
2022-07-25 08:51:16,918: ============================================================
2022-07-25 08:51:16,918: Epoch 22/25 Batch 3400/7662 eta: 3:05:00.304939	Training Loss1 1.7132 (1.5861)	Training Total_Loss 1.7132 (1.5861)	Training Prec@1 100.000 (99.987)	Training Prec@5 100.000 (99.995)	
2022-07-25 08:51:16,918: ============================================================
2022-07-25 08:51:57,667: time cost, forward:0.12375903729201385, backward:0.09664111976863385, data cost:0.18651324682625472 
2022-07-25 08:51:57,667: ============================================================
2022-07-25 08:51:57,668: Epoch 22/25 Batch 3500/7662 eta: 3:04:22.976776	Training Loss1 1.7575 (1.5875)	Training Total_Loss 1.7575 (1.5875)	Training Prec@1 100.000 (99.987)	Training Prec@5 100.000 (99.995)	
2022-07-25 08:51:57,668: ============================================================
2022-07-25 08:52:38,411: time cost, forward:0.12375662591133425, backward:0.09667256879422292, data cost:0.1864840924723276 
2022-07-25 08:52:38,411: ============================================================
2022-07-25 08:52:38,411: Epoch 22/25 Batch 3600/7662 eta: 3:03:40.813723	Training Loss1 1.5246 (1.5887)	Training Total_Loss 1.5246 (1.5887)	Training Prec@1 100.000 (99.987)	Training Prec@5 100.000 (99.995)	
2022-07-25 08:52:38,411: ============================================================
2022-07-25 08:53:19,050: time cost, forward:0.12375695578437716, backward:0.09667094342287698, data cost:0.18645779446480434 
2022-07-25 08:53:19,051: ============================================================
2022-07-25 08:53:19,051: Epoch 22/25 Batch 3700/7662 eta: 3:02:31.920967	Training Loss1 1.4543 (1.5908)	Training Total_Loss 1.4543 (1.5908)	Training Prec@1 100.000 (99.987)	Training Prec@5 100.000 (99.995)	
2022-07-25 08:53:19,051: ============================================================
2022-07-25 08:53:59,671: time cost, forward:0.12375940125564049, backward:0.09666454173853975, data cost:0.18643110844611369 
2022-07-25 08:53:59,671: ============================================================
2022-07-25 08:53:59,671: Epoch 22/25 Batch 3800/7662 eta: 3:01:46.186226	Training Loss1 1.4550 (1.5919)	Training Total_Loss 1.4550 (1.5919)	Training Prec@1 100.000 (99.987)	Training Prec@5 100.000 (99.995)	
2022-07-25 08:53:59,671: ============================================================
2022-07-25 08:54:40,305: time cost, forward:0.12376095992413873, backward:0.09665885611233511, data cost:0.18640956336885087 
2022-07-25 08:54:40,305: ============================================================
2022-07-25 08:54:40,305: Epoch 22/25 Batch 3900/7662 eta: 3:01:09.166292	Training Loss1 1.4785 (1.5922)	Training Total_Loss 1.4785 (1.5922)	Training Prec@1 100.000 (99.987)	Training Prec@5 100.000 (99.995)	
2022-07-25 08:54:40,305: ============================================================
2022-07-25 08:55:20,923: time cost, forward:0.12375804673853323, backward:0.09665385172587092, data cost:0.18638909307233273 
2022-07-25 08:55:20,924: ============================================================
2022-07-25 08:55:20,924: Epoch 22/25 Batch 4000/7662 eta: 3:00:24.415613	Training Loss1 1.8475 (1.5937)	Training Total_Loss 1.8475 (1.5937)	Training Prec@1 100.000 (99.987)	Training Prec@5 100.000 (99.995)	
2022-07-25 08:55:20,924: ============================================================
2022-07-25 08:56:01,543: time cost, forward:0.12375617318108012, backward:0.09664882418876103, data cost:0.18636942410009552 
2022-07-25 08:56:01,543: ============================================================
2022-07-25 08:56:01,543: Epoch 22/25 Batch 4100/7662 eta: 2:59:44.108823	Training Loss1 1.3878 (1.5941)	Training Total_Loss 1.3878 (1.5941)	Training Prec@1 100.000 (99.987)	Training Prec@5 100.000 (99.995)	
2022-07-25 08:56:01,543: ============================================================
2022-07-25 08:56:42,128: time cost, forward:0.12375412097457592, backward:0.09664228616029939, data cost:0.18634505475183474 
2022-07-25 08:56:42,129: ============================================================
2022-07-25 08:56:42,129: Epoch 22/25 Batch 4200/7662 eta: 2:58:54.425789	Training Loss1 1.5227 (1.5952)	Training Total_Loss 1.5227 (1.5952)	Training Prec@1 100.000 (99.987)	Training Prec@5 100.000 (99.995)	
2022-07-25 08:56:42,129: ============================================================
2022-07-25 08:57:22,701: time cost, forward:0.12375019672000705, backward:0.09663480962534565, data cost:0.18632174874771804 
2022-07-25 08:57:22,701: ============================================================
2022-07-25 08:57:22,701: Epoch 22/25 Batch 4300/7662 eta: 2:58:10.437594	Training Loss1 1.5827 (1.5965)	Training Total_Loss 1.5827 (1.5965)	Training Prec@1 100.000 (99.987)	Training Prec@5 100.000 (99.995)	
2022-07-25 08:57:22,701: ============================================================
2022-07-25 08:58:03,269: time cost, forward:0.1237461545787689, backward:0.09662735529936668, data cost:0.18629923574651852 
2022-07-25 08:58:03,269: ============================================================
2022-07-25 08:58:03,269: Epoch 22/25 Batch 4400/7662 eta: 2:57:28.719624	Training Loss1 1.6594 (1.5973)	Training Total_Loss 1.6594 (1.5973)	Training Prec@1 100.000 (99.987)	Training Prec@5 100.000 (99.995)	
2022-07-25 08:58:03,269: ============================================================
2022-07-25 08:58:43,870: time cost, forward:0.1237461779429717, backward:0.09662096345125237, data cost:0.18628049930166365 
2022-07-25 08:58:43,870: ============================================================
2022-07-25 08:58:43,870: Epoch 22/25 Batch 4500/7662 eta: 2:56:56.699025	Training Loss1 1.4529 (1.5983)	Training Total_Loss 1.4529 (1.5983)	Training Prec@1 100.000 (99.987)	Training Prec@5 100.000 (99.995)	
2022-07-25 08:58:43,870: ============================================================
2022-07-25 08:59:24,497: time cost, forward:0.12374458009197702, backward:0.09661937122838501, data cost:0.18626519202356573 
2022-07-25 08:59:24,497: ============================================================
2022-07-25 08:59:24,497: Epoch 22/25 Batch 4600/7662 eta: 2:56:22.923528	Training Loss1 1.6098 (1.5994)	Training Total_Loss 1.6098 (1.5994)	Training Prec@1 100.000 (99.987)	Training Prec@5 100.000 (99.995)	
2022-07-25 08:59:24,497: ============================================================
2022-07-25 09:00:05,076: time cost, forward:0.12374305567809384, backward:0.0966139039630001, data cost:0.18624484079851703 
2022-07-25 09:00:05,076: ============================================================
2022-07-25 09:00:05,077: Epoch 22/25 Batch 4700/7662 eta: 2:55:29.973084	Training Loss1 1.5437 (1.5999)	Training Total_Loss 1.5437 (1.5999)	Training Prec@1 100.000 (99.987)	Training Prec@5 100.000 (99.995)	
2022-07-25 09:00:05,077: ============================================================
2022-07-25 09:00:45,650: time cost, forward:0.12374102560076324, backward:0.09660818010947436, data cost:0.18622515886668042 
2022-07-25 09:00:45,650: ============================================================
2022-07-25 09:00:45,651: Epoch 22/25 Batch 4800/7662 eta: 2:54:48.002441	Training Loss1 1.6718 (1.6012)	Training Total_Loss 1.6718 (1.6012)	Training Prec@1 99.805 (99.987)	Training Prec@5 99.805 (99.995)	
2022-07-25 09:00:45,651: ============================================================
2022-07-25 09:01:26,209: time cost, forward:0.12373707259910693, backward:0.09660268263029405, data cost:0.1862054392862719 
2022-07-25 09:01:26,209: ============================================================
2022-07-25 09:01:26,209: Epoch 22/25 Batch 4900/7662 eta: 2:54:03.380061	Training Loss1 1.8759 (1.6025)	Training Total_Loss 1.8759 (1.6025)	Training Prec@1 100.000 (99.986)	Training Prec@5 100.000 (99.994)	
2022-07-25 09:01:26,209: ============================================================
2022-07-25 09:02:06,793: time cost, forward:0.12373679822672604, backward:0.09659859637637977, data cost:0.18618720239294745 
2022-07-25 09:02:06,793: ============================================================
2022-07-25 09:02:06,793: Epoch 22/25 Batch 5000/7662 eta: 2:53:29.426574	Training Loss1 1.5863 (1.6032)	Training Total_Loss 1.5863 (1.6032)	Training Prec@1 100.000 (99.986)	Training Prec@5 100.000 (99.994)	
2022-07-25 09:02:06,793: ============================================================
2022-07-25 09:02:47,350: time cost, forward:0.12373322312750988, backward:0.09659342107456743, data cost:0.18616914491977007 
2022-07-25 09:02:47,351: ============================================================
2022-07-25 09:02:47,351: Epoch 22/25 Batch 5100/7662 eta: 2:52:42.037960	Training Loss1 1.6958 (1.6044)	Training Total_Loss 1.6958 (1.6044)	Training Prec@1 100.000 (99.986)	Training Prec@5 100.000 (99.994)	
2022-07-25 09:02:47,351: ============================================================
2022-07-25 09:03:27,914: time cost, forward:0.12372957410480362, backward:0.0965880184683531, data cost:0.1861531757854411 
2022-07-25 09:03:27,914: ============================================================
2022-07-25 09:03:27,915: Epoch 22/25 Batch 5200/7662 eta: 2:52:03.083125	Training Loss1 1.8009 (1.6057)	Training Total_Loss 1.8009 (1.6057)	Training Prec@1 100.000 (99.986)	Training Prec@5 100.000 (99.994)	
2022-07-25 09:03:27,915: ============================================================
2022-07-25 09:04:08,516: time cost, forward:0.12373194489350385, backward:0.09658263962006519, data cost:0.18613974011873474 
2022-07-25 09:04:08,516: ============================================================
2022-07-25 09:04:08,516: Epoch 22/25 Batch 5300/7662 eta: 2:51:32.086573	Training Loss1 1.5447 (1.6068)	Training Total_Loss 1.5447 (1.6068)	Training Prec@1 100.000 (99.986)	Training Prec@5 100.000 (99.994)	
2022-07-25 09:04:08,516: ============================================================
2022-07-25 09:04:49,105: time cost, forward:0.12373418290430936, backward:0.09657652255759722, data cost:0.18612487785549908 
2022-07-25 09:04:49,106: ============================================================
2022-07-25 09:04:49,106: Epoch 22/25 Batch 5400/7662 eta: 2:50:48.471557	Training Loss1 2.0078 (1.6083)	Training Total_Loss 2.0078 (1.6083)	Training Prec@1 99.805 (99.986)	Training Prec@5 99.805 (99.994)	
2022-07-25 09:04:49,106: ============================================================
2022-07-25 09:05:29,703: time cost, forward:0.12373618139616249, backward:0.09657213609421074, data cost:0.18611124026209555 
2022-07-25 09:05:29,703: ============================================================
2022-07-25 09:05:29,704: Epoch 22/25 Batch 5500/7662 eta: 2:50:09.945703	Training Loss1 1.6350 (1.6092)	Training Total_Loss 1.6350 (1.6092)	Training Prec@1 100.000 (99.986)	Training Prec@5 100.000 (99.994)	
2022-07-25 09:05:29,704: ============================================================
2022-07-25 09:06:10,289: time cost, forward:0.12373624577822909, backward:0.09656632604461032, data cost:0.18609944980769183 
2022-07-25 09:06:10,290: ============================================================
2022-07-25 09:06:10,290: Epoch 22/25 Batch 5600/7662 eta: 2:49:26.428817	Training Loss1 1.5722 (1.6104)	Training Total_Loss 1.5722 (1.6104)	Training Prec@1 100.000 (99.986)	Training Prec@5 100.000 (99.994)	
2022-07-25 09:06:10,290: ============================================================
2022-07-25 09:06:51,009: time cost, forward:0.12373670692463928, backward:0.096583774328692, data cost:0.18608747852289964 
2022-07-25 09:06:51,009: ============================================================
2022-07-25 09:06:51,010: Epoch 22/25 Batch 5700/7662 eta: 2:49:19.202649	Training Loss1 1.7606 (1.6111)	Training Total_Loss 1.7606 (1.6111)	Training Prec@1 99.805 (99.986)	Training Prec@5 99.805 (99.994)	
2022-07-25 09:06:51,010: ============================================================
2022-07-25 09:07:31,758: time cost, forward:0.12373682790263847, backward:0.09660439779890428, data cost:0.18607732389976 
2022-07-25 09:07:31,759: ============================================================
2022-07-25 09:07:31,759: Epoch 22/25 Batch 5800/7662 eta: 2:48:45.767194	Training Loss1 1.7180 (1.6122)	Training Total_Loss 1.7180 (1.6122)	Training Prec@1 100.000 (99.986)	Training Prec@5 100.000 (99.994)	
2022-07-25 09:07:31,759: ============================================================
2022-07-25 09:08:12,486: time cost, forward:0.12373513883605895, backward:0.09662429505151134, data cost:0.1860658119726755 
2022-07-25 09:08:12,486: ============================================================
2022-07-25 09:08:12,486: Epoch 22/25 Batch 5900/7662 eta: 2:47:59.673571	Training Loss1 1.7200 (1.6130)	Training Total_Loss 1.7200 (1.6130)	Training Prec@1 100.000 (99.986)	Training Prec@5 100.000 (99.994)	
2022-07-25 09:08:12,486: ============================================================
2022-07-25 09:08:53,250: time cost, forward:0.1237353954261135, backward:0.09664473066252059, data cost:0.1860576134599195 
2022-07-25 09:08:53,250: ============================================================
2022-07-25 09:08:53,251: Epoch 22/25 Batch 6000/7662 eta: 2:47:27.953782	Training Loss1 1.6005 (1.6138)	Training Total_Loss 1.6005 (1.6138)	Training Prec@1 100.000 (99.986)	Training Prec@5 100.000 (99.994)	
2022-07-25 09:08:53,251: ============================================================
2022-07-25 09:09:34,022: time cost, forward:0.12373733543962666, backward:0.09666413806621942, data cost:0.18604975779499455 
2022-07-25 09:09:34,022: ============================================================
2022-07-25 09:09:34,023: Epoch 22/25 Batch 6100/7662 eta: 2:46:49.150080	Training Loss1 1.4724 (1.6145)	Training Total_Loss 1.4724 (1.6145)	Training Prec@1 100.000 (99.986)	Training Prec@5 100.000 (99.994)	
2022-07-25 09:09:34,023: ============================================================
2022-07-25 09:10:14,796: time cost, forward:0.12374059383591099, backward:0.0966818618435959, data cost:0.18604191643015994 
2022-07-25 09:10:14,796: ============================================================
2022-07-25 09:10:14,796: Epoch 22/25 Batch 6200/7662 eta: 2:46:08.730086	Training Loss1 1.5245 (1.6154)	Training Total_Loss 1.5245 (1.6154)	Training Prec@1 99.805 (99.986)	Training Prec@5 99.805 (99.994)	
2022-07-25 09:10:14,796: ============================================================
2022-07-25 09:10:55,574: time cost, forward:0.12374366240040388, backward:0.09669916401554392, data cost:0.18603460753526097 
2022-07-25 09:10:55,574: ============================================================
2022-07-25 09:10:55,574: Epoch 22/25 Batch 6300/7662 eta: 2:45:28.992812	Training Loss1 1.2784 (1.6164)	Training Total_Loss 1.2784 (1.6164)	Training Prec@1 100.000 (99.985)	Training Prec@5 100.000 (99.994)	
2022-07-25 09:10:55,574: ============================================================
2022-07-25 09:11:36,324: time cost, forward:0.12374587699125886, backward:0.09671479986130883, data cost:0.18602527277714426 
2022-07-25 09:11:36,324: ============================================================
2022-07-25 09:11:36,324: Epoch 22/25 Batch 6400/7662 eta: 2:44:41.557054	Training Loss1 1.5435 (1.6174)	Training Total_Loss 1.5435 (1.6174)	Training Prec@1 100.000 (99.985)	Training Prec@5 100.000 (99.994)	
2022-07-25 09:11:36,325: ============================================================
2022-07-25 09:12:17,075: time cost, forward:0.12374789400419138, backward:0.09673005574518835, data cost:0.18601638200668613 
2022-07-25 09:12:17,075: ============================================================
2022-07-25 09:12:17,075: Epoch 22/25 Batch 6500/7662 eta: 2:44:00.930876	Training Loss1 1.6602 (1.6179)	Training Total_Loss 1.6602 (1.6179)	Training Prec@1 100.000 (99.985)	Training Prec@5 100.000 (99.994)	
2022-07-25 09:12:17,075: ============================================================
2022-07-25 09:12:57,860: time cost, forward:0.12375327012162801, backward:0.09674506643393271, data cost:0.18600914113032743 
2022-07-25 09:12:57,860: ============================================================
2022-07-25 09:12:57,861: Epoch 22/25 Batch 6600/7662 eta: 2:43:28.417697	Training Loss1 1.5654 (1.6184)	Training Total_Loss 1.5654 (1.6184)	Training Prec@1 100.000 (99.985)	Training Prec@5 100.000 (99.994)	
2022-07-25 09:12:57,861: ============================================================
2022-07-25 09:13:38,647: time cost, forward:0.12375762946998242, backward:0.09675997743892713, data cost:0.18600301198735844 
2022-07-25 09:13:38,647: ============================================================
2022-07-25 09:13:38,648: Epoch 22/25 Batch 6700/7662 eta: 2:42:48.092948	Training Loss1 1.7300 (1.6189)	Training Total_Loss 1.7300 (1.6189)	Training Prec@1 100.000 (99.985)	Training Prec@5 100.000 (99.994)	
2022-07-25 09:13:38,648: ============================================================
2022-07-25 09:14:19,431: time cost, forward:0.12376286727853655, backward:0.09677384618205662, data cost:0.18599623030538961 
2022-07-25 09:14:19,431: ============================================================
2022-07-25 09:14:19,431: Epoch 22/25 Batch 6800/7662 eta: 2:42:06.511206	Training Loss1 1.5969 (1.6201)	Training Total_Loss 1.5969 (1.6201)	Training Prec@1 100.000 (99.985)	Training Prec@5 100.000 (99.994)	
2022-07-25 09:14:19,431: ============================================================
2022-07-25 09:15:00,228: time cost, forward:0.12376761101245673, backward:0.09678770155297758, data cost:0.18599130997088945 
2022-07-25 09:15:00,228: ============================================================
2022-07-25 09:15:00,228: Epoch 22/25 Batch 6900/7662 eta: 2:41:28.832121	Training Loss1 1.7867 (1.6210)	Training Total_Loss 1.7867 (1.6210)	Training Prec@1 100.000 (99.985)	Training Prec@5 100.000 (99.994)	
2022-07-25 09:15:00,228: ============================================================
2022-07-25 09:15:41,004: time cost, forward:0.12377066172128201, backward:0.0968010688887475, data cost:0.1859851499373001 
2022-07-25 09:15:41,004: ============================================================
2022-07-25 09:15:41,004: Epoch 22/25 Batch 7000/7662 eta: 2:40:43.118726	Training Loss1 2.0110 (1.6224)	Training Total_Loss 2.0110 (1.6224)	Training Prec@1 99.805 (99.985)	Training Prec@5 99.805 (99.994)	
2022-07-25 09:15:41,004: ============================================================
2022-07-25 09:16:21,759: time cost, forward:0.12377191103752407, backward:0.09681446153624895, data cost:0.18597771439993613 
2022-07-25 09:16:21,760: ============================================================
2022-07-25 09:16:21,760: Epoch 22/25 Batch 7100/7662 eta: 2:39:57.575484	Training Loss1 1.7691 (1.6233)	Training Total_Loss 1.7691 (1.6233)	Training Prec@1 100.000 (99.985)	Training Prec@5 100.000 (99.994)	
2022-07-25 09:16:21,760: ============================================================
2022-07-25 09:17:02,497: time cost, forward:0.12377224092368269, backward:0.09682716378107188, data cost:0.1859691182777838 
2022-07-25 09:17:02,497: ============================================================
2022-07-25 09:17:02,497: Epoch 22/25 Batch 7200/7662 eta: 2:39:12.463741	Training Loss1 1.4878 (1.6243)	Training Total_Loss 1.4878 (1.6243)	Training Prec@1 100.000 (99.985)	Training Prec@5 100.000 (99.994)	
2022-07-25 09:17:02,497: ============================================================
2022-07-25 09:17:43,227: time cost, forward:0.12377219138724915, backward:0.09683910577750268, data cost:0.185960613484088 
2022-07-25 09:17:43,227: ============================================================
2022-07-25 09:17:43,227: Epoch 22/25 Batch 7300/7662 eta: 2:38:30.057168	Training Loss1 1.6334 (1.6252)	Training Total_Loss 1.6334 (1.6252)	Training Prec@1 100.000 (99.985)	Training Prec@5 100.000 (99.994)	
2022-07-25 09:17:43,227: ============================================================
2022-07-25 09:18:23,948: time cost, forward:0.12377122705539251, backward:0.09685111261732048, data cost:0.18595183148611588 
2022-07-25 09:18:23,948: ============================================================
2022-07-25 09:18:23,948: Epoch 22/25 Batch 7400/7662 eta: 2:37:47.230767	Training Loss1 1.4390 (1.6260)	Training Total_Loss 1.4390 (1.6260)	Training Prec@1 100.000 (99.985)	Training Prec@5 100.000 (99.994)	
2022-07-25 09:18:23,948: ============================================================
2022-07-25 09:19:04,658: time cost, forward:0.12376942770022331, backward:0.0968625674582844, data cost:0.18594281503972665 
2022-07-25 09:19:04,658: ============================================================
2022-07-25 09:19:04,659: Epoch 22/25 Batch 7500/7662 eta: 2:37:04.080820	Training Loss1 1.5232 (1.6269)	Training Total_Loss 1.5232 (1.6269)	Training Prec@1 100.000 (99.985)	Training Prec@5 100.000 (99.994)	
2022-07-25 09:19:04,659: ============================================================
2022-07-25 09:19:45,353: time cost, forward:0.12376659408119545, backward:0.0968737715497615, data cost:0.1859330909160238 
2022-07-25 09:19:45,353: ============================================================
2022-07-25 09:19:45,353: Epoch 22/25 Batch 7600/7662 eta: 2:36:19.679529	Training Loss1 1.6938 (1.6280)	Training Total_Loss 1.6938 (1.6280)	Training Prec@1 100.000 (99.985)	Training Prec@5 100.000 (99.994)	
2022-07-25 09:19:45,353: ============================================================
2022-07-25 09:20:12,530: Epoch 22/25 Batch 7663/7662 eta: 2:35:54.041983	Training Loss1 1.7788 (1.6285)	Training Total_Loss 1.7788 (1.6285)	Training Prec@1 100.000 (99.985)	Training Prec@5 100.000 (99.994)	
2022-07-25 09:20:12,530: ============================================================
2022-07-25 09:20:55,388: time cost, forward:0.12406810606368865, backward:0.0962730971249667, data cost:0.20913634155735825 
2022-07-25 09:20:55,389: ============================================================
2022-07-25 09:20:55,389: Epoch 23/25 Batch 100/7662 eta: 2:43:06.677366	Training Loss1 1.4681 (1.3462)	Training Total_Loss 1.4681 (1.3462)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.998)	
2022-07-25 09:20:55,389: ============================================================
2022-07-25 09:21:36,115: time cost, forward:0.12420154815942198, backward:0.09621896815659413, data cost:0.19756080876642734 
2022-07-25 09:21:36,116: ============================================================
2022-07-25 09:21:36,116: Epoch 23/25 Batch 200/7662 eta: 2:34:40.457904	Training Loss1 1.1963 (1.3435)	Training Total_Loss 1.1963 (1.3435)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.996)	
2022-07-25 09:21:36,116: ============================================================
2022-07-25 09:22:16,958: time cost, forward:0.12424899662617457, backward:0.09620965444124661, data cost:0.19409985287133666 
2022-07-25 09:22:16,959: ============================================================
2022-07-25 09:22:16,959: Epoch 23/25 Batch 300/7662 eta: 2:34:26.015155	Training Loss1 1.5057 (1.3381)	Training Total_Loss 1.5057 (1.3381)	Training Prec@1 100.000 (99.991)	Training Prec@5 100.000 (99.997)	
2022-07-25 09:22:16,959: ============================================================
2022-07-25 09:22:57,775: time cost, forward:0.1243044302278294, backward:0.09620134573532525, data cost:0.19225271841637173 
2022-07-25 09:22:57,775: ============================================================
2022-07-25 09:22:57,775: Epoch 23/25 Batch 400/7662 eta: 2:33:39.260324	Training Loss1 1.4135 (1.3448)	Training Total_Loss 1.4135 (1.3448)	Training Prec@1 100.000 (99.991)	Training Prec@5 100.000 (99.996)	
2022-07-25 09:22:57,776: ============================================================
2022-07-25 09:23:38,508: time cost, forward:0.12428962826012131, backward:0.09621219740124169, data cost:0.1910329132615206 
2022-07-25 09:23:38,508: ============================================================
2022-07-25 09:23:38,508: Epoch 23/25 Batch 500/7662 eta: 2:32:39.587579	Training Loss1 1.4524 (1.3467)	Training Total_Loss 1.4524 (1.3467)	Training Prec@1 100.000 (99.991)	Training Prec@5 100.000 (99.995)	
2022-07-25 09:23:38,508: ============================================================
2022-07-25 09:24:19,248: time cost, forward:0.12432226075950967, backward:0.09624260693838282, data cost:0.1901659651073271 
2022-07-25 09:24:19,248: ============================================================
2022-07-25 09:24:19,248: Epoch 23/25 Batch 600/7662 eta: 2:32:00.491130	Training Loss1 1.3559 (1.3491)	Training Total_Loss 1.3559 (1.3491)	Training Prec@1 100.000 (99.991)	Training Prec@5 100.000 (99.995)	
2022-07-25 09:24:19,248: ============================================================
2022-07-25 09:24:59,941: time cost, forward:0.12431386032159066, backward:0.096253773685177, data cost:0.1895270044029356 
2022-07-25 09:24:59,942: ============================================================
2022-07-25 09:24:59,942: Epoch 23/25 Batch 700/7662 eta: 2:31:09.364765	Training Loss1 1.1821 (1.3496)	Training Total_Loss 1.1821 (1.3496)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.994)	
2022-07-25 09:24:59,942: ============================================================
2022-07-25 09:25:40,583: time cost, forward:0.12427158439263832, backward:0.09625448810591715, data cost:0.18900904339156552 
2022-07-25 09:25:40,583: ============================================================
2022-07-25 09:25:40,584: Epoch 23/25 Batch 800/7662 eta: 2:30:17.158222	Training Loss1 1.4045 (1.3534)	Training Total_Loss 1.4045 (1.3534)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.994)	
2022-07-25 09:25:40,584: ============================================================
2022-07-25 09:26:21,262: time cost, forward:0.12423792511257897, backward:0.09625653403752107, data cost:0.1886702769325095 
2022-07-25 09:26:21,262: ============================================================
2022-07-25 09:26:21,263: Epoch 23/25 Batch 900/7662 eta: 2:29:44.756174	Training Loss1 1.3224 (1.3552)	Training Total_Loss 1.3224 (1.3552)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.994)	
2022-07-25 09:26:21,263: ============================================================
2022-07-25 09:27:01,935: time cost, forward:0.12422980441226138, backward:0.09625382967539378, data cost:0.18837916433393537 
2022-07-25 09:27:01,935: ============================================================
2022-07-25 09:27:01,935: Epoch 23/25 Batch 1000/7662 eta: 2:29:02.697412	Training Loss1 1.2221 (1.3566)	Training Total_Loss 1.2221 (1.3566)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.994)	
2022-07-25 09:27:01,935: ============================================================
2022-07-25 09:27:42,544: time cost, forward:0.12419365209487485, backward:0.09625855785158138, data cost:0.18810747470282987 
2022-07-25 09:27:42,545: ============================================================
2022-07-25 09:27:42,545: Epoch 23/25 Batch 1100/7662 eta: 2:28:08.254789	Training Loss1 1.3676 (1.3569)	Training Total_Loss 1.3676 (1.3569)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.994)	
2022-07-25 09:27:42,545: ============================================================
2022-07-25 09:28:23,175: time cost, forward:0.12418768026114901, backward:0.09626115810085675, data cost:0.18787826032216992 
2022-07-25 09:28:23,176: ============================================================
2022-07-25 09:28:23,176: Epoch 23/25 Batch 1200/7662 eta: 2:27:32.275512	Training Loss1 1.2532 (1.3563)	Training Total_Loss 1.2532 (1.3563)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.994)	
2022-07-25 09:28:23,176: ============================================================
2022-07-25 09:29:03,819: time cost, forward:0.12418039199294632, backward:0.09626470078313415, data cost:0.18768509302440287 
2022-07-25 09:29:03,820: ============================================================
2022-07-25 09:29:03,820: Epoch 23/25 Batch 1300/7662 eta: 2:26:54.449969	Training Loss1 1.2467 (1.3579)	Training Total_Loss 1.2467 (1.3579)	Training Prec@1 100.000 (99.991)	Training Prec@5 100.000 (99.995)	
2022-07-25 09:29:03,820: ============================================================
2022-07-25 09:29:44,471: time cost, forward:0.12417022580330163, backward:0.09626628740759216, data cost:0.18753262738656623 
2022-07-25 09:29:44,471: ============================================================
2022-07-25 09:29:44,471: Epoch 23/25 Batch 1400/7662 eta: 2:26:15.433744	Training Loss1 1.4715 (1.3608)	Training Total_Loss 1.4715 (1.3608)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.994)	
2022-07-25 09:29:44,471: ============================================================
2022-07-25 09:30:25,110: time cost, forward:0.1241629728084409, backward:0.09626840431742703, data cost:0.1873976050256649 
2022-07-25 09:30:25,111: ============================================================
2022-07-25 09:30:25,111: Epoch 23/25 Batch 1500/7662 eta: 2:25:32.234190	Training Loss1 1.3027 (1.3610)	Training Total_Loss 1.3027 (1.3610)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.994)	
2022-07-25 09:30:25,111: ============================================================
2022-07-25 09:31:05,828: time cost, forward:0.12415099874595466, backward:0.09626857544050282, data cost:0.1873341881535514 
2022-07-25 09:31:05,828: ============================================================
2022-07-25 09:31:05,829: Epoch 23/25 Batch 1600/7662 eta: 2:25:08.261203	Training Loss1 1.4743 (1.3628)	Training Total_Loss 1.4743 (1.3628)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.994)	
2022-07-25 09:31:05,829: ============================================================
2022-07-25 09:31:46,550: time cost, forward:0.12416271815375765, backward:0.09629588101877053, data cost:0.18723034437717306 
2022-07-25 09:31:46,550: ============================================================
2022-07-25 09:31:46,551: Epoch 23/25 Batch 1700/7662 eta: 2:24:28.496277	Training Loss1 1.5665 (1.3646)	Training Total_Loss 1.5665 (1.3646)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.994)	
2022-07-25 09:31:46,551: ============================================================
2022-07-25 09:32:27,345: time cost, forward:0.12416008898388882, backward:0.0963643233334773, data cost:0.18714584609811474 
2022-07-25 09:32:27,345: ============================================================
2022-07-25 09:32:27,345: Epoch 23/25 Batch 1800/7662 eta: 2:24:03.188880	Training Loss1 1.1998 (1.3659)	Training Total_Loss 1.1998 (1.3659)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.994)	
2022-07-25 09:32:27,345: ============================================================
2022-07-25 09:33:08,027: time cost, forward:0.12415888888262146, backward:0.09639479977134154, data cost:0.18704272509248965 
2022-07-25 09:33:08,028: ============================================================
2022-07-25 09:33:08,028: Epoch 23/25 Batch 1900/7662 eta: 2:22:58.702612	Training Loss1 1.1868 (1.3676)	Training Total_Loss 1.1868 (1.3676)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.994)	
2022-07-25 09:33:08,028: ============================================================
2022-07-25 09:33:48,713: time cost, forward:0.12417851870748149, backward:0.09638389782526303, data cost:0.18696913306506768 
2022-07-25 09:33:48,714: ============================================================
2022-07-25 09:33:48,714: Epoch 23/25 Batch 2000/7662 eta: 2:22:18.799164	Training Loss1 1.1133 (1.3704)	Training Total_Loss 1.1133 (1.3704)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.995)	
2022-07-25 09:33:48,714: ============================================================
2022-07-25 09:34:29,409: time cost, forward:0.12419533172978169, backward:0.0963747879617154, data cost:0.18690218000879966 
2022-07-25 09:34:29,409: ============================================================
2022-07-25 09:34:29,409: Epoch 23/25 Batch 2100/7662 eta: 2:21:40.045260	Training Loss1 1.4984 (1.3713)	Training Total_Loss 1.4984 (1.3713)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.995)	
2022-07-25 09:34:29,409: ============================================================
2022-07-25 09:35:10,041: time cost, forward:0.1242043362687316, backward:0.09636887543415036, data cost:0.18682111420919809 
2022-07-25 09:35:10,041: ============================================================
2022-07-25 09:35:10,042: Epoch 23/25 Batch 2200/7662 eta: 2:20:46.242127	Training Loss1 1.4346 (1.3738)	Training Total_Loss 1.4346 (1.3738)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.995)	
2022-07-25 09:35:10,042: ============================================================
2022-07-25 09:35:50,647: time cost, forward:0.12420133768656608, backward:0.09636232395595237, data cost:0.18674807602449728 
2022-07-25 09:35:50,648: ============================================================
2022-07-25 09:35:50,648: Epoch 23/25 Batch 2300/7662 eta: 2:20:00.182543	Training Loss1 1.3714 (1.3748)	Training Total_Loss 1.3714 (1.3748)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.995)	
2022-07-25 09:35:50,648: ============================================================
2022-07-25 09:36:31,297: time cost, forward:0.12419877394182874, backward:0.09635910157016438, data cost:0.1866902030970266 
2022-07-25 09:36:31,297: ============================================================
2022-07-25 09:36:31,297: Epoch 23/25 Batch 2400/7662 eta: 2:19:28.551466	Training Loss1 1.3550 (1.3762)	Training Total_Loss 1.3550 (1.3762)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.995)	
2022-07-25 09:36:31,297: ============================================================
2022-07-25 09:37:11,943: time cost, forward:0.12419449381467675, backward:0.09635829000102848, data cost:0.18664071062842863 
2022-07-25 09:37:11,944: ============================================================
2022-07-25 09:37:11,944: Epoch 23/25 Batch 2500/7662 eta: 2:18:47.262692	Training Loss1 1.5992 (1.3779)	Training Total_Loss 1.5992 (1.3779)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.995)	
2022-07-25 09:37:11,944: ============================================================
2022-07-25 09:37:52,617: time cost, forward:0.1241876256149427, backward:0.09635997130440584, data cost:0.18660649064413717 
2022-07-25 09:37:52,618: ============================================================
2022-07-25 09:37:52,618: Epoch 23/25 Batch 2600/7662 eta: 2:18:12.199296	Training Loss1 1.8609 (1.3802)	Training Total_Loss 1.8609 (1.3802)	Training Prec@1 99.609 (99.990)	Training Prec@5 99.805 (99.995)	
2022-07-25 09:37:52,618: ============================================================
2022-07-25 09:38:33,334: time cost, forward:0.1242014609164068, backward:0.09636399471216531, data cost:0.18656795304896612 
2022-07-25 09:38:33,335: ============================================================
2022-07-25 09:38:33,335: Epoch 23/25 Batch 2700/7662 eta: 2:17:40.259049	Training Loss1 1.6539 (1.3814)	Training Total_Loss 1.6539 (1.3814)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.995)	
2022-07-25 09:38:33,335: ============================================================
2022-07-25 09:39:14,022: time cost, forward:0.12420364540361771, backward:0.09636526893146892, data cost:0.1865310365704819 
2022-07-25 09:39:14,022: ============================================================
2022-07-25 09:39:14,022: Epoch 23/25 Batch 2800/7662 eta: 2:16:53.578887	Training Loss1 1.4313 (1.3833)	Training Total_Loss 1.4313 (1.3833)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.995)	
2022-07-25 09:39:14,022: ============================================================
2022-07-25 09:39:54,693: time cost, forward:0.12420208070063517, backward:0.09636664152063144, data cost:0.18649398741865209 
2022-07-25 09:39:54,693: ============================================================
2022-07-25 09:39:54,693: Epoch 23/25 Batch 2900/7662 eta: 2:16:09.510880	Training Loss1 1.5760 (1.3850)	Training Total_Loss 1.5760 (1.3850)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.995)	
2022-07-25 09:39:54,693: ============================================================
2022-07-25 09:40:35,328: time cost, forward:0.12419208298925162, backward:0.09636557145928017, data cost:0.1864627769447319 
2022-07-25 09:40:35,329: ============================================================
2022-07-25 09:40:35,329: Epoch 23/25 Batch 3000/7662 eta: 2:15:21.918781	Training Loss1 1.2002 (1.3862)	Training Total_Loss 1.2002 (1.3862)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.995)	
2022-07-25 09:40:35,329: ============================================================
2022-07-25 09:41:15,971: time cost, forward:0.12418551443468644, backward:0.09636600073709455, data cost:0.18643129421996085 
2022-07-25 09:41:15,972: ============================================================
2022-07-25 09:41:15,972: Epoch 23/25 Batch 3100/7662 eta: 2:14:42.635930	Training Loss1 1.2916 (1.3874)	Training Total_Loss 1.2916 (1.3874)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.995)	
2022-07-25 09:41:15,972: ============================================================
2022-07-25 09:41:56,614: time cost, forward:0.12418319136323538, backward:0.09636626872616881, data cost:0.18639804684173022 
2022-07-25 09:41:56,614: ============================================================
2022-07-25 09:41:56,614: Epoch 23/25 Batch 3200/7662 eta: 2:14:01.959105	Training Loss1 1.1965 (1.3875)	Training Total_Loss 1.1965 (1.3875)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.995)	
2022-07-25 09:41:56,615: ============================================================
2022-07-25 09:42:37,281: time cost, forward:0.12417620671594023, backward:0.09636712934292241, data cost:0.1863778987484435 
2022-07-25 09:42:37,281: ============================================================
2022-07-25 09:42:37,281: Epoch 23/25 Batch 3300/7662 eta: 2:13:26.068743	Training Loss1 1.6846 (1.3890)	Training Total_Loss 1.6846 (1.3890)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.995)	
2022-07-25 09:42:37,281: ============================================================
2022-07-25 09:43:18,025: time cost, forward:0.12417386285905875, backward:0.09637056241564346, data cost:0.18637237102713924 
2022-07-25 09:43:18,026: ============================================================
2022-07-25 09:43:18,026: Epoch 23/25 Batch 3400/7662 eta: 2:13:00.612778	Training Loss1 1.2459 (1.3908)	Training Total_Loss 1.2459 (1.3908)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.995)	
2022-07-25 09:43:18,026: ============================================================
2022-07-25 09:43:58,859: time cost, forward:0.12418052243246082, backward:0.09640625300629543, data cost:0.18635050825951405 
2022-07-25 09:43:58,859: ============================================================
2022-07-25 09:43:58,859: Epoch 23/25 Batch 3500/7662 eta: 2:12:37.263944	Training Loss1 1.4344 (1.3930)	Training Total_Loss 1.4344 (1.3930)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.995)	
2022-07-25 09:43:58,859: ============================================================
2022-07-25 09:44:39,687: time cost, forward:0.1241802452471098, backward:0.09644436107539044, data cost:0.186333901884159 
2022-07-25 09:44:39,687: ============================================================
2022-07-25 09:44:39,687: Epoch 23/25 Batch 3600/7662 eta: 2:11:55.292249	Training Loss1 1.3274 (1.3942)	Training Total_Loss 1.3274 (1.3942)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.995)	
2022-07-25 09:44:39,687: ============================================================
2022-07-25 09:45:20,444: time cost, forward:0.12417076020087381, backward:0.09647728082585187, data cost:0.18630822808976494 
2022-07-25 09:45:20,444: ============================================================
2022-07-25 09:45:20,445: Epoch 23/25 Batch 3700/7662 eta: 2:11:00.885355	Training Loss1 1.2510 (1.3953)	Training Total_Loss 1.2510 (1.3953)	Training Prec@1 100.000 (99.991)	Training Prec@5 100.000 (99.995)	
2022-07-25 09:45:20,445: ============================================================
2022-07-25 09:46:01,151: time cost, forward:0.12416592652184551, backward:0.09649282074125229, data cost:0.1862857771660347 
2022-07-25 09:46:01,151: ============================================================
2022-07-25 09:46:01,151: Epoch 23/25 Batch 3800/7662 eta: 2:10:10.348251	Training Loss1 1.4996 (1.3968)	Training Total_Loss 1.4996 (1.3968)	Training Prec@1 100.000 (99.991)	Training Prec@5 100.000 (99.995)	
2022-07-25 09:46:01,151: ============================================================
2022-07-25 09:46:41,753: time cost, forward:0.12415708001071472, backward:0.09648997834414266, data cost:0.18626044743731868 
2022-07-25 09:46:41,754: ============================================================
2022-07-25 09:46:41,754: Epoch 23/25 Batch 3900/7662 eta: 2:09:09.821375	Training Loss1 1.1217 (1.3976)	Training Total_Loss 1.1217 (1.3976)	Training Prec@1 100.000 (99.991)	Training Prec@5 100.000 (99.995)	
2022-07-25 09:46:41,754: ============================================================
2022-07-25 09:47:22,382: time cost, forward:0.12414776262386824, backward:0.09648753858023985, data cost:0.18624370853493707 
2022-07-25 09:47:22,382: ============================================================
2022-07-25 09:47:22,382: Epoch 23/25 Batch 4000/7662 eta: 2:08:34.176478	Training Loss1 1.2989 (1.3991)	Training Total_Loss 1.2989 (1.3991)	Training Prec@1 100.000 (99.991)	Training Prec@5 100.000 (99.995)	
2022-07-25 09:47:22,383: ============================================================
2022-07-25 09:48:02,958: time cost, forward:0.12413554024073983, backward:0.09648334418718162, data cost:0.18621986864485024 
2022-07-25 09:48:02,958: ============================================================
2022-07-25 09:48:02,958: Epoch 23/25 Batch 4100/7662 eta: 2:07:43.555703	Training Loss1 1.2503 (1.4008)	Training Total_Loss 1.2503 (1.4008)	Training Prec@1 100.000 (99.991)	Training Prec@5 100.000 (99.995)	
2022-07-25 09:48:02,958: ============================================================
2022-07-25 09:48:43,531: time cost, forward:0.12412691712521405, backward:0.09647831941792215, data cost:0.18619441361505662 
2022-07-25 09:48:43,532: ============================================================
2022-07-25 09:48:43,532: Epoch 23/25 Batch 4200/7662 eta: 2:07:02.559017	Training Loss1 1.3936 (1.4026)	Training Total_Loss 1.3936 (1.4026)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.995)	
2022-07-25 09:48:43,532: ============================================================
2022-07-25 09:49:24,105: time cost, forward:0.12411903963446146, backward:0.09647487861995338, data cost:0.18616879077866122 
2022-07-25 09:49:24,106: ============================================================
2022-07-25 09:49:24,106: Epoch 23/25 Batch 4300/7662 eta: 2:06:22.047319	Training Loss1 1.6269 (1.4032)	Training Total_Loss 1.6269 (1.4032)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.995)	
2022-07-25 09:49:24,106: ============================================================
2022-07-25 09:50:04,679: time cost, forward:0.12410857688841372, backward:0.09647137025563006, data cost:0.18614736311163083 
2022-07-25 09:50:04,679: ============================================================
2022-07-25 09:50:04,679: Epoch 23/25 Batch 4400/7662 eta: 2:05:41.331774	Training Loss1 1.2626 (1.4046)	Training Total_Loss 1.2626 (1.4046)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.995)	
2022-07-25 09:50:04,679: ============================================================
2022-07-25 09:50:45,216: time cost, forward:0.1240953045650227, backward:0.09646626068873256, data cost:0.18612374441176952 
2022-07-25 09:50:45,217: ============================================================
2022-07-25 09:50:45,217: Epoch 23/25 Batch 4500/7662 eta: 2:04:54.239408	Training Loss1 1.4126 (1.4056)	Training Total_Loss 1.4126 (1.4056)	Training Prec@1 99.805 (99.990)	Training Prec@5 100.000 (99.995)	
2022-07-25 09:50:45,217: ============================================================
2022-07-25 09:51:25,747: time cost, forward:0.12408074173467992, backward:0.09646243591831155, data cost:0.18610063659857087 
2022-07-25 09:51:25,747: ============================================================
2022-07-25 09:51:25,747: Epoch 23/25 Batch 4600/7662 eta: 2:04:12.319701	Training Loss1 1.5867 (1.4065)	Training Total_Loss 1.5867 (1.4065)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.995)	
2022-07-25 09:51:25,747: ============================================================
2022-07-25 09:52:06,280: time cost, forward:0.12406675337121496, backward:0.09645852704686443, data cost:0.18607959312995867 
2022-07-25 09:52:06,281: ============================================================
2022-07-25 09:52:06,281: Epoch 23/25 Batch 4700/7662 eta: 2:03:32.362881	Training Loss1 1.5176 (1.4075)	Training Total_Loss 1.5176 (1.4075)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.995)	
2022-07-25 09:52:06,281: ============================================================
2022-07-25 09:52:46,781: time cost, forward:0.12405060107172915, backward:0.0964532443497871, data cost:0.18605741045578839 
2022-07-25 09:52:46,781: ============================================================
2022-07-25 09:52:46,782: Epoch 23/25 Batch 4800/7662 eta: 2:02:45.894396	Training Loss1 1.6580 (1.4097)	Training Total_Loss 1.6580 (1.4097)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.995)	
2022-07-25 09:52:46,782: ============================================================
2022-07-25 09:53:27,279: time cost, forward:0.12403368395088789, backward:0.09644873401636395, data cost:0.186036316563485 
2022-07-25 09:53:27,280: ============================================================
2022-07-25 09:53:27,280: Epoch 23/25 Batch 4900/7662 eta: 2:02:04.892691	Training Loss1 1.3990 (1.4110)	Training Total_Loss 1.3990 (1.4110)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.995)	
2022-07-25 09:53:27,280: ============================================================
2022-07-25 09:54:07,789: time cost, forward:0.12401892967666714, backward:0.09644509873692574, data cost:0.1860160778989599 
2022-07-25 09:54:07,789: ============================================================
2022-07-25 09:54:07,789: Epoch 23/25 Batch 5000/7662 eta: 2:01:26.423871	Training Loss1 1.6133 (1.4125)	Training Total_Loss 1.6133 (1.4125)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.995)	
2022-07-25 09:54:07,789: ============================================================
2022-07-25 09:54:48,309: time cost, forward:0.12400588598361692, backward:0.09644173865085444, data cost:0.18599752090238642 
2022-07-25 09:54:48,309: ============================================================
2022-07-25 09:54:48,309: Epoch 23/25 Batch 5100/7662 eta: 2:00:47.822418	Training Loss1 1.6557 (1.4137)	Training Total_Loss 1.6557 (1.4137)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.995)	
2022-07-25 09:54:48,309: ============================================================
2022-07-25 09:55:28,819: time cost, forward:0.1239931280279554, backward:0.0964380438269549, data cost:0.18597829353353065 
2022-07-25 09:55:28,819: ============================================================
2022-07-25 09:55:28,819: Epoch 23/25 Batch 5200/7662 eta: 2:00:05.536556	Training Loss1 1.4558 (1.4155)	Training Total_Loss 1.4558 (1.4155)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.995)	
2022-07-25 09:55:28,819: ============================================================
2022-07-25 09:56:09,339: time cost, forward:0.12398267732653714, backward:0.09643439005671593, data cost:0.18596013363047936 
2022-07-25 09:56:09,339: ============================================================
2022-07-25 09:56:09,340: Epoch 23/25 Batch 5300/7662 eta: 1:59:26.827891	Training Loss1 1.5260 (1.4170)	Training Total_Loss 1.5260 (1.4170)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.995)	
2022-07-25 09:56:09,340: ============================================================
2022-07-25 09:56:49,873: time cost, forward:0.12397355211070343, backward:0.09643107516872902, data cost:0.1859433579873235 
2022-07-25 09:56:49,873: ============================================================
2022-07-25 09:56:49,873: Epoch 23/25 Batch 5400/7662 eta: 1:58:48.680770	Training Loss1 1.7641 (1.4182)	Training Total_Loss 1.7641 (1.4182)	Training Prec@1 99.805 (99.989)	Training Prec@5 100.000 (99.995)	
2022-07-25 09:56:49,874: ============================================================
2022-07-25 09:57:30,391: time cost, forward:0.12396237715349824, backward:0.09642690575151015, data cost:0.18592791428108998 
2022-07-25 09:57:30,392: ============================================================
2022-07-25 09:57:30,392: Epoch 23/25 Batch 5500/7662 eta: 1:58:05.427710	Training Loss1 1.5441 (1.4200)	Training Total_Loss 1.5441 (1.4200)	Training Prec@1 100.000 (99.989)	Training Prec@5 100.000 (99.995)	
2022-07-25 09:57:30,392: ============================================================
2022-07-25 09:58:10,916: time cost, forward:0.12395111389044332, backward:0.0964241639314581, data cost:0.185913340878031 
2022-07-25 09:58:10,916: ============================================================
2022-07-25 09:58:10,917: Epoch 23/25 Batch 5600/7662 eta: 1:57:26.043090	Training Loss1 1.5122 (1.4209)	Training Total_Loss 1.5122 (1.4209)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.995)	
2022-07-25 09:58:10,917: ============================================================
2022-07-25 09:58:51,431: time cost, forward:0.12394010156764339, backward:0.09642167977438326, data cost:0.18589804820542505 
2022-07-25 09:58:51,431: ============================================================
2022-07-25 09:58:51,431: Epoch 23/25 Batch 5700/7662 eta: 1:56:43.833673	Training Loss1 1.2908 (1.4222)	Training Total_Loss 1.2908 (1.4222)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.995)	
2022-07-25 09:58:51,432: ============================================================
2022-07-25 09:59:31,952: time cost, forward:0.1239286636685396, backward:0.09641976511916285, data cost:0.18588458227482227 
2022-07-25 09:59:31,952: ============================================================
2022-07-25 09:59:31,952: Epoch 23/25 Batch 5800/7662 eta: 1:56:04.265292	Training Loss1 1.6688 (1.4233)	Training Total_Loss 1.6688 (1.4233)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.995)	
2022-07-25 09:59:31,952: ============================================================
2022-07-25 10:00:12,485: time cost, forward:0.12392217168405432, backward:0.09641692225741903, data cost:0.18586965879558973 
2022-07-25 10:00:12,486: ============================================================
2022-07-25 10:00:12,486: Epoch 23/25 Batch 5900/7662 eta: 1:55:25.993236	Training Loss1 1.4313 (1.4250)	Training Total_Loss 1.4313 (1.4250)	Training Prec@1 100.000 (99.989)	Training Prec@5 100.000 (99.995)	
2022-07-25 10:00:12,486: ============================================================
2022-07-25 10:00:52,996: time cost, forward:0.12391233917156207, backward:0.09641415616992634, data cost:0.18585538562088535 
2022-07-25 10:00:52,997: ============================================================
2022-07-25 10:00:52,997: Epoch 23/25 Batch 6000/7662 eta: 1:54:41.636078	Training Loss1 1.4270 (1.4260)	Training Total_Loss 1.4270 (1.4260)	Training Prec@1 100.000 (99.989)	Training Prec@5 100.000 (99.995)	
2022-07-25 10:00:52,997: ============================================================
2022-07-25 10:01:33,549: time cost, forward:0.12390788032649325, backward:0.09641221480831628, data cost:0.18584319243061287 
2022-07-25 10:01:33,549: ============================================================
2022-07-25 10:01:33,549: Epoch 23/25 Batch 6100/7662 eta: 1:54:08.071889	Training Loss1 1.5004 (1.4270)	Training Total_Loss 1.5004 (1.4270)	Training Prec@1 100.000 (99.989)	Training Prec@5 100.000 (99.995)	
2022-07-25 10:01:33,549: ============================================================
2022-07-25 10:02:14,058: time cost, forward:0.12389758095123592, backward:0.09640985359047897, data cost:0.18583044780417976 
2022-07-25 10:02:14,058: ============================================================
2022-07-25 10:02:14,058: Epoch 23/25 Batch 6200/7662 eta: 1:53:20.246001	Training Loss1 1.5880 (1.4281)	Training Total_Loss 1.5880 (1.4281)	Training Prec@1 100.000 (99.989)	Training Prec@5 100.000 (99.995)	
2022-07-25 10:02:14,058: ============================================================
2022-07-25 10:02:54,572: time cost, forward:0.12388937434311385, backward:0.09640708168757721, data cost:0.18581731971586898 
2022-07-25 10:02:54,572: ============================================================
2022-07-25 10:02:54,572: Epoch 23/25 Batch 6300/7662 eta: 1:52:40.506718	Training Loss1 1.6700 (1.4292)	Training Total_Loss 1.6700 (1.4292)	Training Prec@1 100.000 (99.989)	Training Prec@5 100.000 (99.995)	
2022-07-25 10:02:54,572: ============================================================
2022-07-25 10:03:35,085: time cost, forward:0.1238810078280664, backward:0.09640487884614482, data cost:0.1858044962786868 
2022-07-25 10:03:35,085: ============================================================
2022-07-25 10:03:35,085: Epoch 23/25 Batch 6400/7662 eta: 1:51:59.903413	Training Loss1 1.6204 (1.4305)	Training Total_Loss 1.6204 (1.4305)	Training Prec@1 100.000 (99.989)	Training Prec@5 100.000 (99.995)	
2022-07-25 10:03:35,085: ============================================================
2022-07-25 10:04:15,596: time cost, forward:0.1238733104310195, backward:0.09640229098667345, data cost:0.18579199890445464 
2022-07-25 10:04:15,596: ============================================================
2022-07-25 10:04:15,596: Epoch 23/25 Batch 6500/7662 eta: 1:51:19.105396	Training Loss1 1.1828 (1.4320)	Training Total_Loss 1.1828 (1.4320)	Training Prec@1 100.000 (99.989)	Training Prec@5 100.000 (99.995)	
2022-07-25 10:04:15,596: ============================================================
2022-07-25 10:04:56,119: time cost, forward:0.12386614085147012, backward:0.09640107510360484, data cost:0.18578011943709039 
2022-07-25 10:04:56,119: ============================================================
2022-07-25 10:04:56,119: Epoch 23/25 Batch 6600/7662 eta: 1:50:40.460877	Training Loss1 1.4975 (1.4334)	Training Total_Loss 1.4975 (1.4334)	Training Prec@1 100.000 (99.989)	Training Prec@5 100.000 (99.995)	
2022-07-25 10:04:56,119: ============================================================
2022-07-25 10:05:36,648: time cost, forward:0.12385955542339319, backward:0.09639981391270101, data cost:0.18576929031476846 
2022-07-25 10:05:36,648: ============================================================
2022-07-25 10:05:36,648: Epoch 23/25 Batch 6700/7662 eta: 1:50:01.020095	Training Loss1 1.5432 (1.4345)	Training Total_Loss 1.5432 (1.4345)	Training Prec@1 100.000 (99.989)	Training Prec@5 100.000 (99.995)	
2022-07-25 10:05:36,649: ============================================================
2022-07-25 10:06:17,204: time cost, forward:0.12385315014204745, backward:0.09639990657616195, data cost:0.1857615550627935 
2022-07-25 10:06:17,205: ============================================================
2022-07-25 10:06:17,205: Epoch 23/25 Batch 6800/7662 eta: 1:49:24.847922	Training Loss1 1.5529 (1.4357)	Training Total_Loss 1.5529 (1.4357)	Training Prec@1 100.000 (99.989)	Training Prec@5 100.000 (99.995)	
2022-07-25 10:06:17,205: ============================================================
2022-07-25 10:06:57,780: time cost, forward:0.12384877005838488, backward:0.09639975540464141, data cost:0.18575530864999232 
2022-07-25 10:06:57,780: ============================================================
2022-07-25 10:06:57,780: Epoch 23/25 Batch 6900/7662 eta: 1:48:47.380687	Training Loss1 1.5798 (1.4369)	Training Total_Loss 1.5798 (1.4369)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.995)	
2022-07-25 10:06:57,780: ============================================================
2022-07-25 10:07:38,345: time cost, forward:0.12384338936885436, backward:0.09639962425673411, data cost:0.1857484274037243 
2022-07-25 10:07:38,345: ============================================================
2022-07-25 10:07:38,345: Epoch 23/25 Batch 7000/7662 eta: 1:48:05.124691	Training Loss1 1.6227 (1.4383)	Training Total_Loss 1.6227 (1.4383)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.995)	
2022-07-25 10:07:38,345: ============================================================
2022-07-25 10:08:18,913: time cost, forward:0.12383764857120087, backward:0.09640019106888438, data cost:0.1857424652531107 
2022-07-25 10:08:18,913: ============================================================
2022-07-25 10:08:18,913: Epoch 23/25 Batch 7100/7662 eta: 1:47:25.073626	Training Loss1 1.5297 (1.4393)	Training Total_Loss 1.5297 (1.4393)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.995)	
2022-07-25 10:08:18,914: ============================================================
2022-07-25 10:08:59,488: time cost, forward:0.12383318861452536, backward:0.09640058634562333, data cost:0.1857363534877823 
2022-07-25 10:08:59,488: ============================================================
2022-07-25 10:08:59,489: Epoch 23/25 Batch 7200/7662 eta: 1:46:45.604654	Training Loss1 1.5950 (1.4408)	Training Total_Loss 1.5950 (1.4408)	Training Prec@1 100.000 (99.989)	Training Prec@5 100.000 (99.995)	
2022-07-25 10:08:59,489: ============================================================
2022-07-25 10:09:40,105: time cost, forward:0.12383040981368507, backward:0.09640059554098337, data cost:0.18573477111755782 
2022-07-25 10:09:40,105: ============================================================
2022-07-25 10:09:40,105: Epoch 23/25 Batch 7300/7662 eta: 1:46:11.549835	Training Loss1 1.5538 (1.4419)	Training Total_Loss 1.5538 (1.4419)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.995)	
2022-07-25 10:09:40,106: ============================================================
2022-07-25 10:10:20,733: time cost, forward:0.12382893827190623, backward:0.09640106618009656, data cost:0.18573336514899466 
2022-07-25 10:10:20,734: ============================================================
2022-07-25 10:10:20,734: Epoch 23/25 Batch 7400/7662 eta: 1:45:32.760465	Training Loss1 1.5888 (1.4430)	Training Total_Loss 1.5888 (1.4430)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.995)	
2022-07-25 10:10:20,734: ============================================================
2022-07-25 10:11:01,343: time cost, forward:0.12382746423176248, backward:0.09640118363285434, data cost:0.18573036911106378 
2022-07-25 10:11:01,343: ============================================================
2022-07-25 10:11:01,343: Epoch 23/25 Batch 7500/7662 eta: 1:44:49.204627	Training Loss1 1.6531 (1.4440)	Training Total_Loss 1.6531 (1.4440)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.995)	
2022-07-25 10:11:01,344: ============================================================
2022-07-25 10:11:41,910: time cost, forward:0.12382406983850566, backward:0.09640113101662547, data cost:0.1857239231810411 
2022-07-25 10:11:41,911: ============================================================
2022-07-25 10:11:41,911: Epoch 23/25 Batch 7600/7662 eta: 1:44:02.094426	Training Loss1 1.5643 (1.4455)	Training Total_Loss 1.5643 (1.4455)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.995)	
2022-07-25 10:11:41,911: ============================================================
2022-07-25 10:12:08,961: Epoch 23/25 Batch 7663/7662 eta: 1:43:36.537010	Training Loss1 1.8219 (1.4467)	Training Total_Loss 1.8219 (1.4467)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.995)	
2022-07-25 10:12:08,962: ============================================================
2022-07-25 10:12:50,803: time cost, forward:0.12394253894536182, backward:0.09646339849992232, data cost:0.19885418150160047 
2022-07-25 10:12:50,812: ============================================================
2022-07-25 10:12:50,813: Epoch 24/25 Batch 100/7662 eta: 1:46:02.497221	Training Loss1 1.0804 (1.1731)	Training Total_Loss 1.0804 (1.1731)	Training Prec@1 100.000 (99.992)	Training Prec@5 100.000 (99.996)	
2022-07-25 10:12:50,813: ============================================================
2022-07-25 10:13:31,656: time cost, forward:0.12414897506560513, backward:0.09640064311386952, data cost:0.19288314287386946 
2022-07-25 10:13:31,656: ============================================================
2022-07-25 10:13:31,656: Epoch 24/25 Batch 200/7662 eta: 1:42:57.596525	Training Loss1 1.2042 (1.1797)	Training Total_Loss 1.2042 (1.1797)	Training Prec@1 100.000 (99.993)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:13:31,656: ============================================================
2022-07-25 10:14:12,516: time cost, forward:0.12413828189556415, backward:0.0963898454621484, data cost:0.19109350303343706 
2022-07-25 10:14:12,517: ============================================================
2022-07-25 10:14:12,517: Epoch 24/25 Batch 300/7662 eta: 1:42:19.311991	Training Loss1 1.1369 (1.1803)	Training Total_Loss 1.1369 (1.1803)	Training Prec@1 100.000 (99.992)	Training Prec@5 100.000 (99.996)	
2022-07-25 10:14:12,517: ============================================================
2022-07-25 10:14:53,384: time cost, forward:0.12410382399881693, backward:0.09640925091908391, data cost:0.19022222927638463 
2022-07-25 10:14:53,384: ============================================================
2022-07-25 10:14:53,384: Epoch 24/25 Batch 400/7662 eta: 1:41:39.450508	Training Loss1 1.4039 (1.1812)	Training Total_Loss 1.4039 (1.1812)	Training Prec@1 100.000 (99.991)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:14:53,384: ============================================================
2022-07-25 10:15:34,218: time cost, forward:0.12404196104688013, backward:0.09641253350970741, data cost:0.18966960620306775 
2022-07-25 10:15:34,218: ============================================================
2022-07-25 10:15:34,218: Epoch 24/25 Batch 500/7662 eta: 1:40:53.638855	Training Loss1 1.3305 (1.1877)	Training Total_Loss 1.3305 (1.1877)	Training Prec@1 100.000 (99.991)	Training Prec@5 100.000 (99.996)	
2022-07-25 10:15:34,218: ============================================================
2022-07-25 10:16:15,034: time cost, forward:0.12398268344605308, backward:0.0964120922980205, data cost:0.1892794149745884 
2022-07-25 10:16:15,034: ============================================================
2022-07-25 10:16:15,035: Epoch 24/25 Batch 600/7662 eta: 1:40:10.194932	Training Loss1 1.1924 (1.1914)	Training Total_Loss 1.1924 (1.1914)	Training Prec@1 100.000 (99.992)	Training Prec@5 100.000 (99.995)	
2022-07-25 10:16:15,035: ============================================================
2022-07-25 10:16:55,857: time cost, forward:0.1239651641108959, backward:0.09640036188652246, data cost:0.1889787525237033 
2022-07-25 10:16:55,858: ============================================================
2022-07-25 10:16:55,858: Epoch 24/25 Batch 700/7662 eta: 1:39:30.400774	Training Loss1 1.3628 (1.1944)	Training Total_Loss 1.3628 (1.1944)	Training Prec@1 100.000 (99.992)	Training Prec@5 100.000 (99.996)	
2022-07-25 10:16:55,858: ============================================================
2022-07-25 10:17:36,685: time cost, forward:0.12395964844504345, backward:0.09639158684559847, data cost:0.18876111492495962 
2022-07-25 10:17:36,686: ============================================================
2022-07-25 10:17:36,686: Epoch 24/25 Batch 800/7662 eta: 1:38:50.259461	Training Loss1 1.4977 (1.1971)	Training Total_Loss 1.4977 (1.1971)	Training Prec@1 100.000 (99.993)	Training Prec@5 100.000 (99.996)	
2022-07-25 10:17:36,686: ============================================================
2022-07-25 10:18:17,436: time cost, forward:0.12393674171541105, backward:0.09639110687179481, data cost:0.18854170116089342 
2022-07-25 10:18:17,436: ============================================================
2022-07-25 10:18:17,437: Epoch 24/25 Batch 900/7662 eta: 1:37:58.310176	Training Loss1 1.2352 (1.2021)	Training Total_Loss 1.2352 (1.2021)	Training Prec@1 100.000 (99.993)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:18:17,437: ============================================================
2022-07-25 10:18:58,184: time cost, forward:0.12394837478736977, backward:0.09638446921462172, data cost:0.188328481412626 
2022-07-25 10:18:58,185: ============================================================
2022-07-25 10:18:58,185: Epoch 24/25 Batch 1000/7662 eta: 1:37:17.181554	Training Loss1 0.9560 (1.2033)	Training Total_Loss 0.9560 (1.2033)	Training Prec@1 100.000 (99.993)	Training Prec@5 100.000 (99.996)	
2022-07-25 10:18:58,185: ============================================================
2022-07-25 10:19:38,955: time cost, forward:0.12397429984303579, backward:0.0963770171747737, data cost:0.1881506108933953 
2022-07-25 10:19:38,955: ============================================================
2022-07-25 10:19:38,955: Epoch 24/25 Batch 1100/7662 eta: 1:36:39.562953	Training Loss1 1.0858 (1.2040)	Training Total_Loss 1.0858 (1.2040)	Training Prec@1 100.000 (99.993)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:19:38,955: ============================================================
2022-07-25 10:20:19,609: time cost, forward:0.12397596535829826, backward:0.09637179167893054, data cost:0.18793386196076026 
2022-07-25 10:20:19,610: ============================================================
2022-07-25 10:20:19,610: Epoch 24/25 Batch 1200/7662 eta: 1:35:42.498035	Training Loss1 1.1851 (1.2054)	Training Total_Loss 1.1851 (1.2054)	Training Prec@1 100.000 (99.992)	Training Prec@5 100.000 (99.996)	
2022-07-25 10:20:19,610: ============================================================
2022-07-25 10:21:00,246: time cost, forward:0.1239874001371576, backward:0.09636817463000431, data cost:0.1877310417357365 
2022-07-25 10:21:00,246: ============================================================
2022-07-25 10:21:00,246: Epoch 24/25 Batch 1300/7662 eta: 1:34:59.283855	Training Loss1 1.1973 (1.2044)	Training Total_Loss 1.1973 (1.2044)	Training Prec@1 100.000 (99.992)	Training Prec@5 100.000 (99.996)	
2022-07-25 10:21:00,247: ============================================================
2022-07-25 10:21:40,886: time cost, forward:0.12398103103201419, backward:0.09636345482281568, data cost:0.18758006416277173 
2022-07-25 10:21:40,887: ============================================================
2022-07-25 10:21:40,887: Epoch 24/25 Batch 1400/7662 eta: 1:34:19.163075	Training Loss1 1.4392 (1.2086)	Training Total_Loss 1.4392 (1.2086)	Training Prec@1 100.000 (99.992)	Training Prec@5 100.000 (99.996)	
2022-07-25 10:21:40,887: ============================================================
2022-07-25 10:22:21,543: time cost, forward:0.12394987097416343, backward:0.09635240479737142, data cost:0.1874945822201068 
2022-07-25 10:22:21,544: ============================================================
2022-07-25 10:22:21,544: Epoch 24/25 Batch 1500/7662 eta: 1:33:40.843938	Training Loss1 1.0557 (1.2115)	Training Total_Loss 1.0557 (1.2115)	Training Prec@1 100.000 (99.993)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:22:21,544: ============================================================
2022-07-25 10:23:02,155: time cost, forward:0.1239362908125371, backward:0.09634883676639865, data cost:0.18737099303388088 
2022-07-25 10:23:02,156: ============================================================
2022-07-25 10:23:02,156: Epoch 24/25 Batch 1600/7662 eta: 1:32:53.997489	Training Loss1 1.1655 (1.2126)	Training Total_Loss 1.1655 (1.2126)	Training Prec@1 100.000 (99.993)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:23:02,156: ============================================================
2022-07-25 10:23:42,791: time cost, forward:0.12391372790681818, backward:0.09638409477040795, data cost:0.1872464454195091 
2022-07-25 10:23:42,792: ============================================================
2022-07-25 10:23:42,792: Epoch 24/25 Batch 1700/7662 eta: 1:32:16.631048	Training Loss1 0.9774 (1.2138)	Training Total_Loss 0.9774 (1.2138)	Training Prec@1 100.000 (99.993)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:23:42,792: ============================================================
2022-07-25 10:24:23,354: time cost, forward:0.1238968748725607, backward:0.09638149503736512, data cost:0.1871250008396999 
2022-07-25 10:24:23,354: ============================================================
2022-07-25 10:24:23,354: Epoch 24/25 Batch 1800/7662 eta: 1:31:26.078351	Training Loss1 1.2816 (1.2156)	Training Total_Loss 1.2816 (1.2156)	Training Prec@1 100.000 (99.993)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:24:23,354: ============================================================
2022-07-25 10:25:03,991: time cost, forward:0.12388289031259256, backward:0.09637513331452943, data cost:0.18704859478464875 
2022-07-25 10:25:03,991: ============================================================
2022-07-25 10:25:03,991: Epoch 24/25 Batch 1900/7662 eta: 1:30:55.530000	Training Loss1 1.1401 (1.2177)	Training Total_Loss 1.1401 (1.2177)	Training Prec@1 100.000 (99.992)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:25:03,991: ============================================================
2022-07-25 10:25:44,635: time cost, forward:0.12386720582447748, backward:0.09636587855695426, data cost:0.18700165662722565 
2022-07-25 10:25:44,636: ============================================================
2022-07-25 10:25:44,636: Epoch 24/25 Batch 2000/7662 eta: 1:30:15.905329	Training Loss1 1.1072 (1.2200)	Training Total_Loss 1.1072 (1.2200)	Training Prec@1 100.000 (99.992)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:25:44,636: ============================================================
2022-07-25 10:26:25,302: time cost, forward:0.1238499071667341, backward:0.09635719076232038, data cost:0.1869670404258826 
2022-07-25 10:26:25,302: ============================================================
2022-07-25 10:26:25,302: Epoch 24/25 Batch 2100/7662 eta: 1:29:38.133444	Training Loss1 1.2582 (1.2217)	Training Total_Loss 1.2582 (1.2217)	Training Prec@1 100.000 (99.992)	Training Prec@5 100.000 (99.996)	
2022-07-25 10:26:25,303: ============================================================
2022-07-25 10:27:05,931: time cost, forward:0.12383354799809267, backward:0.09635502005122151, data cost:0.18691902943446778 
2022-07-25 10:27:05,932: ============================================================
2022-07-25 10:27:05,932: Epoch 24/25 Batch 2200/7662 eta: 1:28:52.620268	Training Loss1 1.1863 (1.2239)	Training Total_Loss 1.1863 (1.2239)	Training Prec@1 100.000 (99.992)	Training Prec@5 100.000 (99.996)	
2022-07-25 10:27:05,932: ============================================================
2022-07-25 10:27:46,484: time cost, forward:0.12382496632198087, backward:0.0963521462100752, data cost:0.18683594182658683 
2022-07-25 10:27:46,484: ============================================================
2022-07-25 10:27:46,484: Epoch 24/25 Batch 2300/7662 eta: 1:28:01.905521	Training Loss1 1.2930 (1.2262)	Training Total_Loss 1.2930 (1.2262)	Training Prec@1 100.000 (99.992)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:27:46,484: ============================================================
2022-07-25 10:28:27,007: time cost, forward:0.12380597918368519, backward:0.09634911989161947, data cost:0.1867596720496333 
2022-07-25 10:28:27,008: ============================================================
2022-07-25 10:28:27,008: Epoch 24/25 Batch 2400/7662 eta: 1:27:17.711306	Training Loss1 1.2688 (1.2285)	Training Total_Loss 1.2688 (1.2285)	Training Prec@1 100.000 (99.992)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:28:27,008: ============================================================
2022-07-25 10:29:07,536: time cost, forward:0.12379142760085601, backward:0.09634514625857667, data cost:0.1866893796932225 
2022-07-25 10:29:07,536: ============================================================
2022-07-25 10:29:07,536: Epoch 24/25 Batch 2500/7662 eta: 1:26:37.766498	Training Loss1 1.2276 (1.2308)	Training Total_Loss 1.2276 (1.2308)	Training Prec@1 100.000 (99.992)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:29:07,536: ============================================================
2022-07-25 10:29:48,140: time cost, forward:0.12377820972664258, backward:0.09633877425067193, data cost:0.1866565801034115 
2022-07-25 10:29:48,140: ============================================================
2022-07-25 10:29:48,140: Epoch 24/25 Batch 2600/7662 eta: 1:26:06.862349	Training Loss1 1.2503 (1.2326)	Training Total_Loss 1.2503 (1.2326)	Training Prec@1 100.000 (99.993)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:29:48,140: ============================================================
2022-07-25 10:30:28,759: time cost, forward:0.12377483370393327, backward:0.09633369161359201, data cost:0.18661861359609327 
2022-07-25 10:30:28,759: ============================================================
2022-07-25 10:30:28,759: Epoch 24/25 Batch 2700/7662 eta: 1:25:28.144561	Training Loss1 1.4549 (1.2347)	Training Total_Loss 1.4549 (1.2347)	Training Prec@1 100.000 (99.993)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:30:28,759: ============================================================
2022-07-25 10:31:09,393: time cost, forward:0.12377355140462523, backward:0.09632974967397763, data cost:0.18659129403411767 
2022-07-25 10:31:09,394: ============================================================
2022-07-25 10:31:09,394: Epoch 24/25 Batch 2800/7662 eta: 1:24:49.461871	Training Loss1 1.3739 (1.2366)	Training Total_Loss 1.3739 (1.2366)	Training Prec@1 100.000 (99.993)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:31:09,394: ============================================================
2022-07-25 10:31:50,160: time cost, forward:0.1237727221475465, backward:0.09632750485181069, data cost:0.18660504779309064 
2022-07-25 10:31:50,160: ============================================================
2022-07-25 10:31:50,160: Epoch 24/25 Batch 2900/7662 eta: 1:24:25.232352	Training Loss1 1.2180 (1.2385)	Training Total_Loss 1.2180 (1.2385)	Training Prec@1 100.000 (99.993)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:31:50,160: ============================================================
2022-07-25 10:32:30,988: time cost, forward:0.12378324497219084, backward:0.09632125287184758, data cost:0.1866370203813818 
2022-07-25 10:32:30,989: ============================================================
2022-07-25 10:32:30,989: Epoch 24/25 Batch 3000/7662 eta: 1:23:52.122914	Training Loss1 1.4089 (1.2398)	Training Total_Loss 1.4089 (1.2398)	Training Prec@1 100.000 (99.993)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:32:30,989: ============================================================
2022-07-25 10:33:11,704: time cost, forward:0.12378666846357494, backward:0.09631739496684683, data cost:0.18663159298412105 
2022-07-25 10:33:11,704: ============================================================
2022-07-25 10:33:11,704: Epoch 24/25 Batch 3100/7662 eta: 1:22:57.432640	Training Loss1 1.4657 (1.2416)	Training Total_Loss 1.4657 (1.2416)	Training Prec@1 100.000 (99.993)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:33:11,704: ============================================================
2022-07-25 10:33:52,375: time cost, forward:0.12378708769955386, backward:0.09631454076346624, data cost:0.1866092836159995 
2022-07-25 10:33:52,375: ============================================================
2022-07-25 10:33:52,375: Epoch 24/25 Batch 3200/7662 eta: 1:22:11.428217	Training Loss1 1.4130 (1.2430)	Training Total_Loss 1.4130 (1.2430)	Training Prec@1 100.000 (99.993)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:33:52,376: ============================================================
2022-07-25 10:34:32,997: time cost, forward:0.12378531334869208, backward:0.09631070428705461, data cost:0.1865833535560083 
2022-07-25 10:34:32,997: ============================================================
2022-07-25 10:34:32,998: Epoch 24/25 Batch 3300/7662 eta: 1:21:24.800515	Training Loss1 1.0489 (1.2444)	Training Total_Loss 1.0489 (1.2444)	Training Prec@1 100.000 (99.993)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:34:32,998: ============================================================
2022-07-25 10:35:13,677: time cost, forward:0.12379066633385537, backward:0.09630918159103281, data cost:0.18656336458054104 
2022-07-25 10:35:13,677: ============================================================
2022-07-25 10:35:13,677: Epoch 24/25 Batch 3400/7662 eta: 1:20:51.071783	Training Loss1 1.4561 (1.2465)	Training Total_Loss 1.4561 (1.2465)	Training Prec@1 100.000 (99.992)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:35:13,677: ============================================================
2022-07-25 10:35:54,357: time cost, forward:0.12380022537916106, backward:0.09630852203499968, data cost:0.1865430417896237 
2022-07-25 10:35:54,357: ============================================================
2022-07-25 10:35:54,358: Epoch 24/25 Batch 3500/7662 eta: 1:20:10.444347	Training Loss1 1.1133 (1.2478)	Training Total_Loss 1.1133 (1.2478)	Training Prec@1 100.000 (99.993)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:35:54,358: ============================================================
2022-07-25 10:36:35,042: time cost, forward:0.12380303260716308, backward:0.0963088210074893, data cost:0.1865307555393432 
2022-07-25 10:36:35,042: ============================================================
2022-07-25 10:36:35,043: Epoch 24/25 Batch 3600/7662 eta: 1:19:30.293963	Training Loss1 1.4267 (1.2497)	Training Total_Loss 1.4267 (1.2497)	Training Prec@1 100.000 (99.993)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:36:35,043: ============================================================
2022-07-25 10:37:15,632: time cost, forward:0.12379939616064858, backward:0.09631033625658153, data cost:0.18649808262837644 
2022-07-25 10:37:15,632: ============================================================
2022-07-25 10:37:15,632: Epoch 24/25 Batch 3700/7662 eta: 1:18:38.530118	Training Loss1 1.4609 (1.2519)	Training Total_Loss 1.4609 (1.2519)	Training Prec@1 100.000 (99.993)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:37:15,632: ============================================================
2022-07-25 10:37:56,251: time cost, forward:0.12379592253867498, backward:0.09631376845110526, data cost:0.18647020601793227 
2022-07-25 10:37:56,251: ============================================================
2022-07-25 10:37:56,251: Epoch 24/25 Batch 3800/7662 eta: 1:18:01.363101	Training Loss1 1.3049 (1.2539)	Training Total_Loss 1.3049 (1.2539)	Training Prec@1 100.000 (99.993)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:37:56,251: ============================================================
2022-07-25 10:38:36,932: time cost, forward:0.12379621095796768, backward:0.0963156900212654, data cost:0.1864597810235015 
2022-07-25 10:38:36,932: ============================================================
2022-07-25 10:38:36,932: Epoch 24/25 Batch 3900/7662 eta: 1:17:27.822118	Training Loss1 1.3335 (1.2562)	Training Total_Loss 1.3335 (1.2562)	Training Prec@1 100.000 (99.993)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:38:36,932: ============================================================
2022-07-25 10:39:17,619: time cost, forward:0.12380172718045233, backward:0.09631872314248988, data cost:0.18644474971052943 
2022-07-25 10:39:17,619: ============================================================
2022-07-25 10:39:17,619: Epoch 24/25 Batch 4000/7662 eta: 1:16:47.764953	Training Loss1 1.5734 (1.2571)	Training Total_Loss 1.5734 (1.2571)	Training Prec@1 100.000 (99.992)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:39:17,619: ============================================================
2022-07-25 10:39:58,267: time cost, forward:0.12380314164116313, backward:0.09632042362271766, data cost:0.18642599502985988 
2022-07-25 10:39:58,267: ============================================================
2022-07-25 10:39:58,267: Epoch 24/25 Batch 4100/7662 eta: 1:16:02.786387	Training Loss1 1.2770 (1.2587)	Training Total_Loss 1.2770 (1.2587)	Training Prec@1 100.000 (99.993)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:39:58,268: ============================================================
2022-07-25 10:40:38,863: time cost, forward:0.12379560495564187, backward:0.09632316519175578, data cost:0.1864046503686144 
2022-07-25 10:40:38,863: ============================================================
2022-07-25 10:40:38,863: Epoch 24/25 Batch 4200/7662 eta: 1:15:16.256005	Training Loss1 1.2030 (1.2605)	Training Total_Loss 1.2030 (1.2605)	Training Prec@1 100.000 (99.993)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:40:38,863: ============================================================
2022-07-25 10:41:19,429: time cost, forward:0.12378616415087249, backward:0.09632586368047018, data cost:0.1863803559055049 
2022-07-25 10:41:19,430: ============================================================
2022-07-25 10:41:19,430: Epoch 24/25 Batch 4300/7662 eta: 1:14:32.490843	Training Loss1 1.5510 (1.2626)	Training Total_Loss 1.5510 (1.2626)	Training Prec@1 100.000 (99.993)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:41:19,430: ============================================================
2022-07-25 10:42:00,111: time cost, forward:0.12377712189487285, backward:0.09635364090645684, data cost:0.1863569538006324 
2022-07-25 10:42:00,111: ============================================================
2022-07-25 10:42:00,112: Epoch 24/25 Batch 4400/7662 eta: 1:14:04.484919	Training Loss1 1.4501 (1.2644)	Training Total_Loss 1.4501 (1.2644)	Training Prec@1 100.000 (99.993)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:42:00,112: ============================================================
2022-07-25 10:42:40,820: time cost, forward:0.12376977486407977, backward:0.09638415450227343, data cost:0.1863351558732785 
2022-07-25 10:42:40,820: ============================================================
2022-07-25 10:42:40,820: Epoch 24/25 Batch 4500/7662 eta: 1:13:26.667706	Training Loss1 1.4010 (1.2657)	Training Total_Loss 1.4010 (1.2657)	Training Prec@1 100.000 (99.993)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:42:40,820: ============================================================
2022-07-25 10:43:21,505: time cost, forward:0.12376164000665242, backward:0.09641199392918842, data cost:0.18631250014847375 
2022-07-25 10:43:21,505: ============================================================
2022-07-25 10:43:21,505: Epoch 24/25 Batch 4600/7662 eta: 1:12:43.528636	Training Loss1 1.1946 (1.2671)	Training Total_Loss 1.1946 (1.2671)	Training Prec@1 100.000 (99.993)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:43:21,506: ============================================================
2022-07-25 10:44:02,211: time cost, forward:0.1237555855663565, backward:0.09643976326621982, data cost:0.18629209344299277 
2022-07-25 10:44:02,211: ============================================================
2022-07-25 10:44:02,211: Epoch 24/25 Batch 4700/7662 eta: 1:12:05.002225	Training Loss1 1.4038 (1.2685)	Training Total_Loss 1.4038 (1.2685)	Training Prec@1 100.000 (99.992)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:44:02,211: ============================================================
2022-07-25 10:44:42,911: time cost, forward:0.12374971776883983, backward:0.09646627246700096, data cost:0.18627132135372557 
2022-07-25 10:44:42,911: ============================================================
2022-07-25 10:44:42,911: Epoch 24/25 Batch 4800/7662 eta: 1:11:23.678066	Training Loss1 1.4983 (1.2702)	Training Total_Loss 1.4983 (1.2702)	Training Prec@1 100.000 (99.992)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:44:42,911: ============================================================
2022-07-25 10:45:23,602: time cost, forward:0.12374463395747294, backward:0.09649053382055933, data cost:0.18625024406976617 
2022-07-25 10:45:23,602: ============================================================
2022-07-25 10:45:23,603: Epoch 24/25 Batch 4900/7662 eta: 1:10:42.057428	Training Loss1 1.1555 (1.2716)	Training Total_Loss 1.1555 (1.2716)	Training Prec@1 100.000 (99.993)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:45:23,603: ============================================================
2022-07-25 10:46:04,321: time cost, forward:0.1237420100978814, backward:0.09651421603977167, data cost:0.1862324047718174 
2022-07-25 10:46:04,321: ============================================================
2022-07-25 10:46:04,321: Epoch 24/25 Batch 5000/7662 eta: 1:10:04.167366	Training Loss1 1.1202 (1.2727)	Training Total_Loss 1.1202 (1.2727)	Training Prec@1 100.000 (99.993)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:46:04,321: ============================================================
2022-07-25 10:46:45,026: time cost, forward:0.12373724201656505, backward:0.09653772997327775, data cost:0.18621406991894654 
2022-07-25 10:46:45,027: ============================================================
2022-07-25 10:46:45,027: Epoch 24/25 Batch 5100/7662 eta: 1:09:22.165082	Training Loss1 1.3756 (1.2742)	Training Total_Loss 1.3756 (1.2742)	Training Prec@1 100.000 (99.993)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:46:45,027: ============================================================
2022-07-25 10:47:25,697: time cost, forward:0.12372948500164932, backward:0.09655900266588273, data cost:0.186194885095786 
2022-07-25 10:47:25,697: ============================================================
2022-07-25 10:47:25,698: Epoch 24/25 Batch 5200/7662 eta: 1:08:37.922842	Training Loss1 1.1024 (1.2755)	Training Total_Loss 1.1024 (1.2755)	Training Prec@1 100.000 (99.993)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:47:25,698: ============================================================
2022-07-25 10:48:06,350: time cost, forward:0.12372169077992552, backward:0.09657757645351614, data cost:0.1861761271402417 
2022-07-25 10:48:06,350: ============================================================
2022-07-25 10:48:06,351: Epoch 24/25 Batch 5300/7662 eta: 1:07:55.475260	Training Loss1 1.1873 (1.2766)	Training Total_Loss 1.1873 (1.2766)	Training Prec@1 100.000 (99.992)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:48:06,351: ============================================================
2022-07-25 10:48:47,002: time cost, forward:0.12371375821744718, backward:0.09659613121613504, data cost:0.1861571428355828 
2022-07-25 10:48:47,002: ============================================================
2022-07-25 10:48:47,002: Epoch 24/25 Batch 5400/7662 eta: 1:07:14.688468	Training Loss1 1.2703 (1.2781)	Training Total_Loss 1.2703 (1.2781)	Training Prec@1 100.000 (99.992)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:48:47,003: ============================================================
2022-07-25 10:49:27,666: time cost, forward:0.1237072560500613, backward:0.09661433124004613, data cost:0.1861385561202001 
2022-07-25 10:49:27,666: ============================================================
2022-07-25 10:49:27,666: Epoch 24/25 Batch 5500/7662 eta: 1:06:35.221630	Training Loss1 1.3695 (1.2796)	Training Total_Loss 1.3695 (1.2796)	Training Prec@1 100.000 (99.992)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:49:27,666: ============================================================
2022-07-25 10:50:08,228: time cost, forward:0.12369880022204631, backward:0.09661572144316401, data cost:0.1861211212432093 
2022-07-25 10:50:08,228: ============================================================
2022-07-25 10:50:08,228: Epoch 24/25 Batch 5600/7662 eta: 1:05:44.619237	Training Loss1 1.4482 (1.2810)	Training Total_Loss 1.4482 (1.2810)	Training Prec@1 100.000 (99.992)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:50:08,228: ============================================================
2022-07-25 10:50:48,766: time cost, forward:0.12369548912570442, backward:0.0966100161860838, data cost:0.1861024350110931 
2022-07-25 10:50:48,766: ============================================================
2022-07-25 10:50:48,766: Epoch 24/25 Batch 5700/7662 eta: 1:05:01.798069	Training Loss1 1.3284 (1.2823)	Training Total_Loss 1.3284 (1.2823)	Training Prec@1 100.000 (99.992)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:50:48,766: ============================================================
2022-07-25 10:51:29,332: time cost, forward:0.12369642053766279, backward:0.09660444302401844, data cost:0.18608499444914514 
2022-07-25 10:51:29,333: ============================================================
2022-07-25 10:51:29,333: Epoch 24/25 Batch 5800/7662 eta: 1:04:23.976970	Training Loss1 1.4439 (1.2839)	Training Total_Loss 1.4439 (1.2839)	Training Prec@1 100.000 (99.992)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:51:29,333: ============================================================
2022-07-25 10:52:09,897: time cost, forward:0.12369649562619059, backward:0.09659927609533066, data cost:0.186068997138192 
2022-07-25 10:52:09,897: ============================================================
2022-07-25 10:52:09,897: Epoch 24/25 Batch 5900/7662 eta: 1:03:43.216650	Training Loss1 1.3728 (1.2859)	Training Total_Loss 1.3728 (1.2859)	Training Prec@1 100.000 (99.992)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:52:09,898: ============================================================
2022-07-25 10:52:50,417: time cost, forward:0.12369120587983078, backward:0.09659447127887658, data cost:0.1860518864063963 
2022-07-25 10:52:50,417: ============================================================
2022-07-25 10:52:50,417: Epoch 24/25 Batch 6000/7662 eta: 1:02:58.468988	Training Loss1 1.4274 (1.2867)	Training Total_Loss 1.4274 (1.2867)	Training Prec@1 100.000 (99.992)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:52:50,417: ============================================================
2022-07-25 10:53:30,930: time cost, forward:0.12368625839297195, backward:0.09659032798982249, data cost:0.18603344490575408 
2022-07-25 10:53:30,930: ============================================================
2022-07-25 10:53:30,930: Epoch 24/25 Batch 6100/7662 eta: 1:02:17.349566	Training Loss1 1.3663 (1.2883)	Training Total_Loss 1.3663 (1.2883)	Training Prec@1 100.000 (99.992)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:53:30,931: ============================================================
2022-07-25 10:54:11,446: time cost, forward:0.12368151529659512, backward:0.09658557235242705, data cost:0.1860168454800523 
2022-07-25 10:54:11,446: ============================================================
2022-07-25 10:54:11,447: Epoch 24/25 Batch 6200/7662 eta: 1:01:37.090007	Training Loss1 1.1747 (1.2898)	Training Total_Loss 1.1747 (1.2898)	Training Prec@1 100.000 (99.992)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:54:11,447: ============================================================
2022-07-25 10:54:51,952: time cost, forward:0.12367457343502865, backward:0.09658086441834592, data cost:0.1860015099342711 
2022-07-25 10:54:51,952: ============================================================
2022-07-25 10:54:51,952: Epoch 24/25 Batch 6300/7662 eta: 1:00:55.632894	Training Loss1 1.7634 (1.2917)	Training Total_Loss 1.7634 (1.2917)	Training Prec@1 100.000 (99.992)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:54:51,952: ============================================================
2022-07-25 10:55:32,458: time cost, forward:0.12366779507426735, backward:0.09657599885382863, data cost:0.1859873285664676 
2022-07-25 10:55:32,459: ============================================================
2022-07-25 10:55:32,459: Epoch 24/25 Batch 6400/7662 eta: 1:00:15.216105	Training Loss1 1.6882 (1.2930)	Training Total_Loss 1.6882 (1.2930)	Training Prec@1 100.000 (99.992)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:55:32,459: ============================================================
2022-07-25 10:56:12,946: time cost, forward:0.12366069403221505, backward:0.09657113888498856, data cost:0.18597105826427615 
2022-07-25 10:56:12,946: ============================================================
2022-07-25 10:56:12,946: Epoch 24/25 Batch 6500/7662 eta: 0:59:33.003713	Training Loss1 1.3883 (1.2944)	Training Total_Loss 1.3883 (1.2944)	Training Prec@1 99.805 (99.992)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:56:12,946: ============================================================
2022-07-25 10:56:53,461: time cost, forward:0.12365574687877412, backward:0.09656658088064389, data cost:0.18595751583043293 
2022-07-25 10:56:53,461: ============================================================
2022-07-25 10:56:53,461: Epoch 24/25 Batch 6600/7662 eta: 0:58:54.961488	Training Loss1 1.3143 (1.2956)	Training Total_Loss 1.3143 (1.2956)	Training Prec@1 100.000 (99.992)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:56:53,462: ============================================================
2022-07-25 10:57:33,996: time cost, forward:0.123654230581609, backward:0.09656225537022364, data cost:0.18594403611419627 
2022-07-25 10:57:33,996: ============================================================
2022-07-25 10:57:33,996: Epoch 24/25 Batch 6700/7662 eta: 0:58:16.121405	Training Loss1 1.3144 (1.2971)	Training Total_Loss 1.3144 (1.2971)	Training Prec@1 100.000 (99.992)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:57:33,996: ============================================================
2022-07-25 10:58:14,531: time cost, forward:0.12365234450463565, backward:0.09655779238079625, data cost:0.18593164404835275 
2022-07-25 10:58:14,531: ============================================================
2022-07-25 10:58:14,531: Epoch 24/25 Batch 6800/7662 eta: 0:57:35.593026	Training Loss1 1.3703 (1.2984)	Training Total_Loss 1.3703 (1.2984)	Training Prec@1 100.000 (99.992)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:58:14,531: ============================================================
2022-07-25 10:58:55,057: time cost, forward:0.12365024531124329, backward:0.09655390647653739, data cost:0.1859182245680553 
2022-07-25 10:58:55,057: ============================================================
2022-07-25 10:58:55,057: Epoch 24/25 Batch 6900/7662 eta: 0:56:54.350674	Training Loss1 1.1882 (1.2995)	Training Total_Loss 1.1882 (1.2995)	Training Prec@1 100.000 (99.992)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:58:55,057: ============================================================
2022-07-25 10:59:35,548: time cost, forward:0.12364405876467068, backward:0.09654937445870432, data cost:0.18590486937036582 
2022-07-25 10:59:35,549: ============================================================
2022-07-25 10:59:35,549: Epoch 24/25 Batch 7000/7662 eta: 0:56:10.903354	Training Loss1 1.2047 (1.3008)	Training Total_Loss 1.2047 (1.3008)	Training Prec@1 100.000 (99.992)	Training Prec@5 100.000 (99.997)	
2022-07-25 10:59:35,549: ============================================================
2022-07-25 11:00:16,054: time cost, forward:0.12364041474456938, backward:0.09654547715123261, data cost:0.18589159095265492 
2022-07-25 11:00:16,055: ============================================================
2022-07-25 11:00:16,055: Epoch 24/25 Batch 7100/7662 eta: 0:55:31.622229	Training Loss1 1.3377 (1.3022)	Training Total_Loss 1.3377 (1.3022)	Training Prec@1 100.000 (99.992)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:00:16,055: ============================================================
2022-07-25 11:00:56,549: time cost, forward:0.12363484634725828, backward:0.09654173345628059, data cost:0.18587906176157337 
2022-07-25 11:00:56,549: ============================================================
2022-07-25 11:00:56,549: Epoch 24/25 Batch 7200/7662 eta: 0:54:50.193926	Training Loss1 1.2582 (1.3036)	Training Total_Loss 1.2582 (1.3036)	Training Prec@1 100.000 (99.992)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:00:56,550: ============================================================
2022-07-25 11:01:37,036: time cost, forward:0.123629941795277, backward:0.0965375599428013, data cost:0.18586566605328175 
2022-07-25 11:01:37,037: ============================================================
2022-07-25 11:01:37,037: Epoch 24/25 Batch 7300/7662 eta: 0:54:09.105245	Training Loss1 1.3129 (1.3048)	Training Total_Loss 1.3129 (1.3048)	Training Prec@1 100.000 (99.992)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:01:37,037: ============================================================
2022-07-25 11:02:17,525: time cost, forward:0.12362421530455348, backward:0.0965337113989964, data cost:0.18585361566297395 
2022-07-25 11:02:17,525: ============================================================
2022-07-25 11:02:17,525: Epoch 24/25 Batch 7400/7662 eta: 0:53:28.707399	Training Loss1 1.5351 (1.3062)	Training Total_Loss 1.5351 (1.3062)	Training Prec@1 100.000 (99.992)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:02:17,525: ============================================================
2022-07-25 11:02:58,028: time cost, forward:0.12361905857441759, backward:0.09653078862739764, data cost:0.18584249098788327 
2022-07-25 11:02:58,028: ============================================================
2022-07-25 11:02:58,029: Epoch 24/25 Batch 7500/7662 eta: 0:52:49.390572	Training Loss1 1.1164 (1.3076)	Training Total_Loss 1.1164 (1.3076)	Training Prec@1 100.000 (99.992)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:02:58,029: ============================================================
2022-07-25 11:03:38,608: time cost, forward:0.12361530844106974, backward:0.09653748410487586, data cost:0.18583075054885054 
2022-07-25 11:03:38,608: ============================================================
2022-07-25 11:03:38,609: Epoch 24/25 Batch 7600/7662 eta: 0:52:14.808862	Training Loss1 1.5567 (1.3089)	Training Total_Loss 1.5567 (1.3089)	Training Prec@1 100.000 (99.992)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:03:38,609: ============================================================
2022-07-25 11:04:05,559: Epoch 24/25 Batch 7663/7662 eta: 0:51:49.243430	Training Loss1 1.4625 (1.3100)	Training Total_Loss 1.4625 (1.3100)	Training Prec@1 100.000 (99.992)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:04:05,559: ============================================================
2022-07-25 11:04:47,763: time cost, forward:0.12373916548911972, backward:0.09627834955851237, data cost:0.20360468613980998 
2022-07-25 11:04:47,763: ============================================================
2022-07-25 11:04:47,764: Epoch 25/25 Batch 100/7662 eta: 0:53:09.911049	Training Loss1 1.0008 (1.0664)	Training Total_Loss 1.0008 (1.0664)	Training Prec@1 100.000 (99.990)	Training Prec@5 100.000 (99.994)	
2022-07-25 11:04:47,764: ============================================================
2022-07-25 11:05:28,459: time cost, forward:0.12383323817995924, backward:0.09629835435493507, data cost:0.19483950749114531 
2022-07-25 11:05:28,459: ============================================================
2022-07-25 11:05:28,459: Epoch 25/25 Batch 200/7662 eta: 0:50:37.113146	Training Loss1 1.0939 (1.0738)	Training Total_Loss 1.0939 (1.0738)	Training Prec@1 100.000 (99.993)	Training Prec@5 100.000 (99.996)	
2022-07-25 11:05:28,459: ============================================================
2022-07-25 11:06:09,249: time cost, forward:0.1238698425101596, backward:0.09634266888417528, data cost:0.19217612990567517 
2022-07-25 11:06:09,249: ============================================================
2022-07-25 11:06:09,249: Epoch 25/25 Batch 300/7662 eta: 0:50:03.349844	Training Loss1 0.9035 (1.0758)	Training Total_Loss 0.9035 (1.0758)	Training Prec@1 100.000 (99.993)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:06:09,249: ============================================================
2022-07-25 11:06:49,990: time cost, forward:0.1238784981251958, backward:0.0963537955941413, data cost:0.19077021615547046 
2022-07-25 11:06:49,990: ============================================================
2022-07-25 11:06:49,990: Epoch 25/25 Batch 400/7662 eta: 0:49:19.037389	Training Loss1 0.9243 (1.0750)	Training Total_Loss 0.9243 (1.0750)	Training Prec@1 100.000 (99.992)	Training Prec@5 100.000 (99.996)	
2022-07-25 11:06:49,990: ============================================================
2022-07-25 11:07:30,689: time cost, forward:0.12394210953033998, backward:0.09635749035225602, data cost:0.18979026463801016 
2022-07-25 11:07:30,690: ============================================================
2022-07-25 11:07:30,690: Epoch 25/25 Batch 500/7662 eta: 0:48:35.302510	Training Loss1 0.8958 (1.0748)	Training Total_Loss 0.8958 (1.0748)	Training Prec@1 100.000 (99.993)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:07:30,690: ============================================================
2022-07-25 11:08:11,455: time cost, forward:0.12394263907545595, backward:0.09635710716247559, data cost:0.1892570346743117 
2022-07-25 11:08:11,455: ============================================================
2022-07-25 11:08:11,455: Epoch 25/25 Batch 600/7662 eta: 0:47:59.273770	Training Loss1 0.8524 (1.0778)	Training Total_Loss 0.8524 (1.0778)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:08:11,455: ============================================================
2022-07-25 11:08:52,268: time cost, forward:0.12394752932208802, backward:0.09637255866469573, data cost:0.18894322235696817 
2022-07-25 11:08:52,268: ============================================================
2022-07-25 11:08:52,268: Epoch 25/25 Batch 700/7662 eta: 0:47:21.804689	Training Loss1 1.2351 (1.0836)	Training Total_Loss 1.2351 (1.0836)	Training Prec@1 100.000 (99.995)	Training Prec@5 100.000 (99.998)	
2022-07-25 11:08:52,268: ============================================================
2022-07-25 11:09:33,077: time cost, forward:0.12393737883681201, backward:0.09637178407891074, data cost:0.18873774930741521 
2022-07-25 11:09:33,077: ============================================================
2022-07-25 11:09:33,077: Epoch 25/25 Batch 800/7662 eta: 0:46:40.709006	Training Loss1 1.2627 (1.0863)	Training Total_Loss 1.2627 (1.0863)	Training Prec@1 100.000 (99.995)	Training Prec@5 100.000 (99.998)	
2022-07-25 11:09:33,077: ============================================================
2022-07-25 11:10:13,827: time cost, forward:0.12393004159640948, backward:0.0963692471501029, data cost:0.18851858861454338 
2022-07-25 11:10:13,827: ============================================================
2022-07-25 11:10:13,827: Epoch 25/25 Batch 900/7662 eta: 0:45:55.949524	Training Loss1 1.1927 (1.0882)	Training Total_Loss 1.1927 (1.0882)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:10:13,828: ============================================================
2022-07-25 11:10:54,614: time cost, forward:0.12391872974010082, backward:0.09637622169784836, data cost:0.188374253245326 
2022-07-25 11:10:54,614: ============================================================
2022-07-25 11:10:54,614: Epoch 25/25 Batch 1000/7662 eta: 0:45:17.618251	Training Loss1 1.1521 (1.0900)	Training Total_Loss 1.1521 (1.0900)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:10:54,614: ============================================================
2022-07-25 11:11:35,351: time cost, forward:0.12391756511580629, backward:0.09637752438372542, data cost:0.1882047533880482 
2022-07-25 11:11:35,351: ============================================================
2022-07-25 11:11:35,351: Epoch 25/25 Batch 1100/7662 eta: 0:44:33.578729	Training Loss1 1.0435 (1.0906)	Training Total_Loss 1.0435 (1.0906)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.998)	
2022-07-25 11:11:35,351: ============================================================
2022-07-25 11:12:16,107: time cost, forward:0.1239214376969771, backward:0.09638281043516386, data cost:0.18807082697189878 
2022-07-25 11:12:16,107: ============================================================
2022-07-25 11:12:16,107: Epoch 25/25 Batch 1200/7662 eta: 0:43:54.041438	Training Loss1 1.0541 (1.0908)	Training Total_Loss 1.0541 (1.0908)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:12:16,107: ============================================================
2022-07-25 11:12:56,868: time cost, forward:0.12391968485573056, backward:0.09638871478520511, data cost:0.18795721305159993 
2022-07-25 11:12:56,868: ============================================================
2022-07-25 11:12:56,869: Epoch 25/25 Batch 1300/7662 eta: 0:43:13.658682	Training Loss1 1.1463 (1.0928)	Training Total_Loss 1.1463 (1.0928)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:12:56,869: ============================================================
2022-07-25 11:13:37,597: time cost, forward:0.12392255729909792, backward:0.09639251070247538, data cost:0.18784191371544162 
2022-07-25 11:13:37,598: ============================================================
2022-07-25 11:13:37,598: Epoch 25/25 Batch 1400/7662 eta: 0:42:30.868385	Training Loss1 1.0921 (1.0956)	Training Total_Loss 1.0921 (1.0956)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:13:37,598: ============================================================
2022-07-25 11:14:18,356: time cost, forward:0.12392758273378542, backward:0.09639321859078538, data cost:0.18775848327596 
2022-07-25 11:14:18,356: ============================================================
2022-07-25 11:14:18,356: Epoch 25/25 Batch 1500/7662 eta: 0:41:51.941248	Training Loss1 1.1839 (1.0983)	Training Total_Loss 1.1839 (1.0983)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:14:18,356: ============================================================
2022-07-25 11:14:59,146: time cost, forward:0.12392363927005007, backward:0.09639228918613532, data cost:0.18772086804922555 
2022-07-25 11:14:59,146: ============================================================
2022-07-25 11:14:59,146: Epoch 25/25 Batch 1600/7662 eta: 0:41:13.104333	Training Loss1 1.2404 (1.0995)	Training Total_Loss 1.2404 (1.0995)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:14:59,146: ============================================================
2022-07-25 11:15:39,979: time cost, forward:0.12392859181072377, backward:0.09638611578534392, data cost:0.18769936255667755 
2022-07-25 11:15:39,979: ============================================================
2022-07-25 11:15:39,979: Epoch 25/25 Batch 1700/7662 eta: 0:40:34.874900	Training Loss1 1.2284 (1.1011)	Training Total_Loss 1.2284 (1.1011)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:15:39,979: ============================================================
2022-07-25 11:16:20,810: time cost, forward:0.12395126797080769, backward:0.09637895022716172, data cost:0.1876594722105305 
2022-07-25 11:16:20,811: ============================================================
2022-07-25 11:16:20,811: Epoch 25/25 Batch 1800/7662 eta: 0:39:53.944670	Training Loss1 0.9245 (1.1024)	Training Total_Loss 0.9245 (1.1024)	Training Prec@1 100.000 (99.995)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:16:20,811: ============================================================
2022-07-25 11:17:01,613: time cost, forward:0.1239563355388109, backward:0.09637328057994712, data cost:0.18762465562865632 
2022-07-25 11:17:01,613: ============================================================
2022-07-25 11:17:01,613: Epoch 25/25 Batch 1900/7662 eta: 0:39:11.440656	Training Loss1 1.1127 (1.1051)	Training Total_Loss 1.1127 (1.1051)	Training Prec@1 99.805 (99.995)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:17:01,613: ============================================================
2022-07-25 11:17:42,372: time cost, forward:0.12396213935577255, backward:0.09636804793941313, data cost:0.18757849207158206 
2022-07-25 11:17:42,373: ============================================================
2022-07-25 11:17:42,373: Epoch 25/25 Batch 2000/7662 eta: 0:38:28.214267	Training Loss1 1.1601 (1.1070)	Training Total_Loss 1.1601 (1.1070)	Training Prec@1 100.000 (99.995)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:17:42,373: ============================================================
2022-07-25 11:18:23,188: time cost, forward:0.12396998437260831, backward:0.09637489427890931, data cost:0.18754440639744832 
2022-07-25 11:18:23,188: ============================================================
2022-07-25 11:18:23,188: Epoch 25/25 Batch 2100/7662 eta: 0:37:50.574343	Training Loss1 1.1876 (1.1094)	Training Total_Loss 1.1876 (1.1094)	Training Prec@1 100.000 (99.995)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:18:23,188: ============================================================
2022-07-25 11:19:03,946: time cost, forward:0.123973305629784, backward:0.09636884312458394, data cost:0.18750542562188968 
2022-07-25 11:19:03,946: ============================================================
2022-07-25 11:19:03,947: Epoch 25/25 Batch 2200/7662 eta: 0:37:06.615526	Training Loss1 1.1874 (1.1116)	Training Total_Loss 1.1874 (1.1116)	Training Prec@1 100.000 (99.995)	Training Prec@5 100.000 (99.998)	
2022-07-25 11:19:03,947: ============================================================
2022-07-25 11:19:44,792: time cost, forward:0.12397155641420554, backward:0.09635999297100131, data cost:0.18750973150179456 
2022-07-25 11:19:44,793: ============================================================
2022-07-25 11:19:44,793: Epoch 25/25 Batch 2300/7662 eta: 0:36:30.584570	Training Loss1 1.3002 (1.1135)	Training Total_Loss 1.3002 (1.1135)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:19:44,793: ============================================================
2022-07-25 11:20:25,561: time cost, forward:0.12398597030353427, backward:0.09635061967268543, data cost:0.1874741553862724 
2022-07-25 11:20:25,561: ============================================================
2022-07-25 11:20:25,561: Epoch 25/25 Batch 2400/7662 eta: 0:35:45.631479	Training Loss1 1.1689 (1.1146)	Training Total_Loss 1.1689 (1.1146)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:20:25,561: ============================================================
2022-07-25 11:21:06,295: time cost, forward:0.12398742875751374, backward:0.09634183969150405, data cost:0.18744098543882273 
2022-07-25 11:21:06,295: ============================================================
2022-07-25 11:21:06,295: Epoch 25/25 Batch 2500/7662 eta: 0:35:03.104210	Training Loss1 1.0774 (1.1155)	Training Total_Loss 1.0774 (1.1155)	Training Prec@1 100.000 (99.995)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:21:06,295: ============================================================
2022-07-25 11:21:46,960: time cost, forward:0.12398676635577799, backward:0.09633779314766942, data cost:0.1873814746846415 
2022-07-25 11:21:46,960: ============================================================
2022-07-25 11:21:46,960: Epoch 25/25 Batch 2600/7662 eta: 0:34:18.887803	Training Loss1 0.8413 (1.1171)	Training Total_Loss 0.8413 (1.1171)	Training Prec@1 100.000 (99.995)	Training Prec@5 100.000 (99.998)	
2022-07-25 11:21:46,961: ============================================================
2022-07-25 11:22:27,723: time cost, forward:0.12399199221831156, backward:0.09633225765701751, data cost:0.18735809554078484 
2022-07-25 11:22:27,724: ============================================================
2022-07-25 11:22:27,724: Epoch 25/25 Batch 2700/7662 eta: 0:33:43.091486	Training Loss1 1.2267 (1.1192)	Training Total_Loss 1.2267 (1.1192)	Training Prec@1 100.000 (99.995)	Training Prec@5 100.000 (99.998)	
2022-07-25 11:22:27,724: ============================================================
2022-07-25 11:23:08,447: time cost, forward:0.12400343529707025, backward:0.09633055939423948, data cost:0.18731046864372272 
2022-07-25 11:23:08,448: ============================================================
2022-07-25 11:23:08,448: Epoch 25/25 Batch 2800/7662 eta: 0:33:00.395470	Training Loss1 1.0065 (1.1211)	Training Total_Loss 1.0065 (1.1211)	Training Prec@1 100.000 (99.995)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:23:08,448: ============================================================
2022-07-25 11:23:49,134: time cost, forward:0.1240016889391212, backward:0.0963281781643002, data cost:0.18726528723020314 
2022-07-25 11:23:49,134: ============================================================
2022-07-25 11:23:49,135: Epoch 25/25 Batch 2900/7662 eta: 0:32:17.913613	Training Loss1 1.1380 (1.1233)	Training Total_Loss 1.1380 (1.1233)	Training Prec@1 100.000 (99.995)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:23:49,135: ============================================================
2022-07-25 11:24:29,849: time cost, forward:0.12400970645012876, backward:0.0963250071496, data cost:0.18722792218708523 
2022-07-25 11:24:29,849: ============================================================
2022-07-25 11:24:29,849: Epoch 25/25 Batch 3000/7662 eta: 0:31:38.517066	Training Loss1 1.3665 (1.1256)	Training Total_Loss 1.3665 (1.1256)	Training Prec@1 100.000 (99.995)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:24:29,849: ============================================================
2022-07-25 11:25:10,511: time cost, forward:0.12400770910557873, backward:0.09632327511219026, data cost:0.18718450013265645 
2022-07-25 11:25:10,512: ============================================================
2022-07-25 11:25:10,512: Epoch 25/25 Batch 3100/7662 eta: 0:30:55.444666	Training Loss1 1.1216 (1.1280)	Training Total_Loss 1.1216 (1.1280)	Training Prec@1 100.000 (99.995)	Training Prec@5 100.000 (99.998)	
2022-07-25 11:25:10,512: ============================================================
2022-07-25 11:25:51,182: time cost, forward:0.12399784487908838, backward:0.0963182153460308, data cost:0.1871581513570897 
2022-07-25 11:25:51,183: ============================================================
2022-07-25 11:25:51,183: Epoch 25/25 Batch 3200/7662 eta: 0:30:15.148911	Training Loss1 1.1508 (1.1295)	Training Total_Loss 1.1508 (1.1295)	Training Prec@1 100.000 (99.995)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:25:51,183: ============================================================
2022-07-25 11:26:31,854: time cost, forward:0.1239921597864961, backward:0.09631465029882713, data cost:0.18712866302691433 
2022-07-25 11:26:31,854: ============================================================
2022-07-25 11:26:31,854: Epoch 25/25 Batch 3300/7662 eta: 0:29:34.473483	Training Loss1 1.0965 (1.1313)	Training Total_Loss 1.0965 (1.1313)	Training Prec@1 100.000 (99.995)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:26:31,854: ============================================================
2022-07-25 11:27:12,548: time cost, forward:0.12398877744290294, backward:0.09631106908898664, data cost:0.18710611188506407 
2022-07-25 11:27:12,548: ============================================================
2022-07-25 11:27:12,549: Epoch 25/25 Batch 3400/7662 eta: 0:28:54.812856	Training Loss1 1.0860 (1.1328)	Training Total_Loss 1.0860 (1.1328)	Training Prec@1 100.000 (99.995)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:27:12,549: ============================================================
2022-07-25 11:27:53,198: time cost, forward:0.12398019760940783, backward:0.09630675709700715, data cost:0.1870716283852184 
2022-07-25 11:27:53,198: ============================================================
2022-07-25 11:27:53,198: Epoch 25/25 Batch 3500/7662 eta: 0:28:12.240824	Training Loss1 1.2345 (1.1342)	Training Total_Loss 1.2345 (1.1342)	Training Prec@1 100.000 (99.995)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:27:53,198: ============================================================
2022-07-25 11:28:33,887: time cost, forward:0.12397578226986711, backward:0.0963019707296318, data cost:0.18704374938184734 
2022-07-25 11:28:33,887: ============================================================
2022-07-25 11:28:33,887: Epoch 25/25 Batch 3600/7662 eta: 0:27:33.192884	Training Loss1 1.1804 (1.1355)	Training Total_Loss 1.1804 (1.1355)	Training Prec@1 100.000 (99.995)	Training Prec@5 100.000 (99.998)	
2022-07-25 11:28:33,887: ============================================================
2022-07-25 11:29:14,531: time cost, forward:0.12396645707096658, backward:0.09629744895569986, data cost:0.18701963451753664 
2022-07-25 11:29:14,531: ============================================================
2022-07-25 11:29:14,531: Epoch 25/25 Batch 3700/7662 eta: 0:26:50.720513	Training Loss1 1.0627 (1.1370)	Training Total_Loss 1.0627 (1.1370)	Training Prec@1 100.000 (99.995)	Training Prec@5 100.000 (99.998)	
2022-07-25 11:29:14,531: ============================================================
2022-07-25 11:29:55,270: time cost, forward:0.1239731041937635, backward:0.09629190084211887, data cost:0.18699721412678774 
2022-07-25 11:29:55,270: ============================================================
2022-07-25 11:29:55,270: Epoch 25/25 Batch 3800/7662 eta: 0:26:13.760329	Training Loss1 1.2288 (1.1389)	Training Total_Loss 1.2288 (1.1389)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:29:55,270: ============================================================
2022-07-25 11:30:35,964: time cost, forward:0.12398228305338223, backward:0.0962896887599948, data cost:0.18696549073889734 
2022-07-25 11:30:35,964: ============================================================
2022-07-25 11:30:35,964: Epoch 25/25 Batch 3900/7662 eta: 0:25:31.306742	Training Loss1 1.2668 (1.1408)	Training Total_Loss 1.2668 (1.1408)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:30:35,964: ============================================================
2022-07-25 11:31:16,598: time cost, forward:0.12398003023485744, backward:0.09628712645051599, data cost:0.18693306166459753 
2022-07-25 11:31:16,598: ============================================================
2022-07-25 11:31:16,598: Epoch 25/25 Batch 4000/7662 eta: 0:24:48.420174	Training Loss1 1.1710 (1.1432)	Training Total_Loss 1.1710 (1.1432)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:31:16,598: ============================================================
2022-07-25 11:31:57,245: time cost, forward:0.1239768210548574, backward:0.09628389817559158, data cost:0.18690938337688534 
2022-07-25 11:31:57,245: ============================================================
2022-07-25 11:31:57,246: Epoch 25/25 Batch 4100/7662 eta: 0:24:08.268940	Training Loss1 1.3860 (1.1454)	Training Total_Loss 1.3860 (1.1454)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:31:57,246: ============================================================
2022-07-25 11:32:37,769: time cost, forward:0.12396171150334706, backward:0.09628036051144001, data cost:0.1868671026363859 
2022-07-25 11:32:37,770: ============================================================
2022-07-25 11:32:37,770: Epoch 25/25 Batch 4200/7662 eta: 0:23:23.353103	Training Loss1 1.1287 (1.1472)	Training Total_Loss 1.1287 (1.1472)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:32:37,770: ============================================================
2022-07-25 11:33:18,295: time cost, forward:0.1239478058470047, backward:0.09627814441538046, data cost:0.18682844435289644 
2022-07-25 11:33:18,295: ============================================================
2022-07-25 11:33:18,296: Epoch 25/25 Batch 4300/7662 eta: 0:22:42.883087	Training Loss1 1.1542 (1.1490)	Training Total_Loss 1.1542 (1.1490)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:33:18,296: ============================================================
2022-07-25 11:33:58,868: time cost, forward:0.12394318848367332, backward:0.0962774332449311, data cost:0.18678958704862358 
2022-07-25 11:33:58,868: ============================================================
2022-07-25 11:33:58,869: Epoch 25/25 Batch 4400/7662 eta: 0:22:03.899081	Training Loss1 1.2685 (1.1507)	Training Total_Loss 1.2685 (1.1507)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:33:58,869: ============================================================
2022-07-25 11:34:39,442: time cost, forward:0.12393085811900732, backward:0.09627609439467451, data cost:0.18676352257144585 
2022-07-25 11:34:39,443: ============================================================
2022-07-25 11:34:39,443: Epoch 25/25 Batch 4500/7662 eta: 0:21:23.362192	Training Loss1 1.2417 (1.1524)	Training Total_Loss 1.2417 (1.1524)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:34:39,443: ============================================================
2022-07-25 11:35:20,057: time cost, forward:0.12392482515987455, backward:0.0962751038724066, data cost:0.1867397848640636 
2022-07-25 11:35:20,057: ============================================================
2022-07-25 11:35:20,057: Epoch 25/25 Batch 4600/7662 eta: 0:20:44.022962	Training Loss1 1.4171 (1.1537)	Training Total_Loss 1.4171 (1.1537)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:35:20,057: ============================================================
2022-07-25 11:36:00,676: time cost, forward:0.12392233132960873, backward:0.09627635252173847, data cost:0.18671433599382342 
2022-07-25 11:36:00,677: ============================================================
2022-07-25 11:36:00,677: Epoch 25/25 Batch 4700/7662 eta: 0:20:03.552434	Training Loss1 1.2931 (1.1558)	Training Total_Loss 1.2931 (1.1558)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.998)	
2022-07-25 11:36:00,677: ============================================================
2022-07-25 11:36:41,263: time cost, forward:0.12391792960305044, backward:0.09627629404491274, data cost:0.18668651516225393 
2022-07-25 11:36:41,263: ============================================================
2022-07-25 11:36:41,263: Epoch 25/25 Batch 4800/7662 eta: 0:19:21.985718	Training Loss1 1.2975 (1.1570)	Training Total_Loss 1.2975 (1.1570)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.998)	
2022-07-25 11:36:41,263: ============================================================
2022-07-25 11:37:21,864: time cost, forward:0.12391410737311166, backward:0.09627830016172573, data cost:0.1866602118488817 
2022-07-25 11:37:21,865: ============================================================
2022-07-25 11:37:21,865: Epoch 25/25 Batch 4900/7662 eta: 0:18:41.825823	Training Loss1 1.2708 (1.1584)	Training Total_Loss 1.2708 (1.1584)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.998)	
2022-07-25 11:37:21,865: ============================================================
2022-07-25 11:38:02,489: time cost, forward:0.12391124689285697, backward:0.0962802181961203, data cost:0.18663856782396213 
2022-07-25 11:38:02,489: ============================================================
2022-07-25 11:38:02,490: Epoch 25/25 Batch 5000/7662 eta: 0:18:01.837331	Training Loss1 1.4505 (1.1603)	Training Total_Loss 1.4505 (1.1603)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.998)	
2022-07-25 11:38:02,490: ============================================================
2022-07-25 11:38:43,161: time cost, forward:0.12391292027198327, backward:0.09628827475080025, data cost:0.18661665238453187 
2022-07-25 11:38:43,162: ============================================================
2022-07-25 11:38:43,162: Epoch 25/25 Batch 5100/7662 eta: 0:17:22.429133	Training Loss1 1.2338 (1.1621)	Training Total_Loss 1.2338 (1.1621)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.998)	
2022-07-25 11:38:43,162: ============================================================
2022-07-25 11:39:23,810: time cost, forward:0.12391420349888582, backward:0.0962926686601149, data cost:0.18659453888218272 
2022-07-25 11:39:23,810: ============================================================
2022-07-25 11:39:23,810: Epoch 25/25 Batch 5200/7662 eta: 0:16:41.176048	Training Loss1 1.2452 (1.1633)	Training Total_Loss 1.2452 (1.1633)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.998)	
2022-07-25 11:39:23,811: ============================================================
2022-07-25 11:40:04,451: time cost, forward:0.1239129454488011, backward:0.09629675734153355, data cost:0.18657467337819086 
2022-07-25 11:40:04,451: ============================================================
2022-07-25 11:40:04,451: Epoch 25/25 Batch 5300/7662 eta: 0:16:00.343208	Training Loss1 1.3126 (1.1652)	Training Total_Loss 1.3126 (1.1652)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.998)	
2022-07-25 11:40:04,451: ============================================================
2022-07-25 11:40:45,075: time cost, forward:0.12390873767332052, backward:0.0963001136846908, data cost:0.1865568843279134 
2022-07-25 11:40:45,075: ============================================================
2022-07-25 11:40:45,075: Epoch 25/25 Batch 5400/7662 eta: 0:15:19.321149	Training Loss1 1.3558 (1.1671)	Training Total_Loss 1.3558 (1.1671)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.998)	
2022-07-25 11:40:45,075: ============================================================
2022-07-25 11:41:25,657: time cost, forward:0.12390316493035577, backward:0.0963015072040936, data cost:0.18653538648075008 
2022-07-25 11:41:25,658: ============================================================
2022-07-25 11:41:25,658: Epoch 25/25 Batch 5500/7662 eta: 0:14:37.798211	Training Loss1 1.2743 (1.1686)	Training Total_Loss 1.2743 (1.1686)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.998)	
2022-07-25 11:41:25,658: ============================================================
2022-07-25 11:42:06,245: time cost, forward:0.12389791550477033, backward:0.09630331598790463, data cost:0.18651555908388442 
2022-07-25 11:42:06,245: ============================================================
2022-07-25 11:42:06,246: Epoch 25/25 Batch 5600/7662 eta: 0:13:57.329069	Training Loss1 1.2351 (1.1703)	Training Total_Loss 1.2351 (1.1703)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.998)	
2022-07-25 11:42:06,246: ============================================================
2022-07-25 11:42:46,860: time cost, forward:0.12389689969439155, backward:0.09630485705522764, data cost:0.18649675390514958 
2022-07-25 11:42:46,860: ============================================================
2022-07-25 11:42:46,860: Epoch 25/25 Batch 5700/7662 eta: 0:13:17.269085	Training Loss1 1.0729 (1.1717)	Training Total_Loss 1.0729 (1.1717)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.998)	
2022-07-25 11:42:46,861: ============================================================
2022-07-25 11:43:27,454: time cost, forward:0.12389369178669353, backward:0.09630656530166787, data cost:0.18647720863498846 
2022-07-25 11:43:27,454: ============================================================
2022-07-25 11:43:27,454: Epoch 25/25 Batch 5800/7662 eta: 0:12:36.260981	Training Loss1 1.4393 (1.1735)	Training Total_Loss 1.4393 (1.1735)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.998)	
2022-07-25 11:43:27,454: ============================================================
2022-07-25 11:44:08,032: time cost, forward:0.12388927772057665, backward:0.09630863624905142, data cost:0.18645674945096036 
2022-07-25 11:44:08,032: ============================================================
2022-07-25 11:44:08,032: Epoch 25/25 Batch 5900/7662 eta: 0:11:55.385698	Training Loss1 1.3647 (1.1749)	Training Total_Loss 1.3647 (1.1749)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.998)	
2022-07-25 11:44:08,032: ============================================================
2022-07-25 11:44:48,616: time cost, forward:0.12388529382480902, backward:0.09631050672306977, data cost:0.18643776232609255 
2022-07-25 11:44:48,616: ============================================================
2022-07-25 11:44:48,616: Epoch 25/25 Batch 6000/7662 eta: 0:11:14.920771	Training Loss1 1.3466 (1.1767)	Training Total_Loss 1.3466 (1.1767)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.998)	
2022-07-25 11:44:48,617: ============================================================
2022-07-25 11:45:29,190: time cost, forward:0.1238787483828911, backward:0.0963123367348349, data cost:0.18642042863367034 
2022-07-25 11:45:29,190: ============================================================
2022-07-25 11:45:29,191: Epoch 25/25 Batch 6100/7662 eta: 0:10:34.172621	Training Loss1 1.1587 (1.1781)	Training Total_Loss 1.1587 (1.1781)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.998)	
2022-07-25 11:45:29,191: ============================================================
2022-07-25 11:46:09,755: time cost, forward:0.1238731925651746, backward:0.09631341379445336, data cost:0.1864019385997971 
2022-07-25 11:46:09,755: ============================================================
2022-07-25 11:46:09,755: Epoch 25/25 Batch 6200/7662 eta: 0:09:53.460223	Training Loss1 1.4307 (1.1799)	Training Total_Loss 1.4307 (1.1799)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.998)	
2022-07-25 11:46:09,755: ============================================================
2022-07-25 11:46:50,327: time cost, forward:0.12386910058824122, backward:0.0963139670635901, data cost:0.1863845155094896 
2022-07-25 11:46:50,327: ============================================================
2022-07-25 11:46:50,328: Epoch 25/25 Batch 6300/7662 eta: 0:09:13.002541	Training Loss1 1.2766 (1.1814)	Training Total_Loss 1.2766 (1.1814)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:46:50,328: ============================================================
2022-07-25 11:47:30,845: time cost, forward:0.12386146417389178, backward:0.09631245980916274, data cost:0.18636493504764623 
2022-07-25 11:47:30,845: ============================================================
2022-07-25 11:47:30,845: Epoch 25/25 Batch 6400/7662 eta: 0:08:31.739222	Training Loss1 1.2806 (1.1827)	Training Total_Loss 1.2806 (1.1827)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:47:30,845: ============================================================
2022-07-25 11:48:11,369: time cost, forward:0.12385484416185114, backward:0.0963117214216968, data cost:0.18634534010540102 
2022-07-25 11:48:11,370: ============================================================
2022-07-25 11:48:11,370: Epoch 25/25 Batch 6500/7662 eta: 0:07:51.299013	Training Loss1 1.3492 (1.1840)	Training Total_Loss 1.3492 (1.1840)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:48:11,370: ============================================================
2022-07-25 11:48:51,884: time cost, forward:0.12384748552799008, backward:0.09631078679338696, data cost:0.18632612049191227 
2022-07-25 11:48:51,884: ============================================================
2022-07-25 11:48:51,884: Epoch 25/25 Batch 6600/7662 eta: 0:07:10.665677	Training Loss1 0.9775 (1.1852)	Training Total_Loss 0.9775 (1.1852)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:48:51,884: ============================================================
2022-07-25 11:49:32,381: time cost, forward:0.12384006086971035, backward:0.09630946458889701, data cost:0.18630570631487048 
2022-07-25 11:49:32,381: ============================================================
2022-07-25 11:49:32,381: Epoch 25/25 Batch 6700/7662 eta: 0:06:29.987159	Training Loss1 1.3735 (1.1868)	Training Total_Loss 1.3735 (1.1868)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:49:32,381: ============================================================
2022-07-25 11:50:12,886: time cost, forward:0.12383308738868962, backward:0.09630815020938677, data cost:0.18628667575293628 
2022-07-25 11:50:12,886: ============================================================
2022-07-25 11:50:12,886: Epoch 25/25 Batch 6800/7662 eta: 0:05:49.559776	Training Loss1 1.5103 (1.1881)	Training Total_Loss 1.5103 (1.1881)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:50:12,886: ============================================================
2022-07-25 11:50:53,382: time cost, forward:0.12382566996252456, backward:0.09630655986638255, data cost:0.18626786881831267 
2022-07-25 11:50:53,383: ============================================================
2022-07-25 11:50:53,383: Epoch 25/25 Batch 6900/7662 eta: 0:05:08.989110	Training Loss1 1.1228 (1.1889)	Training Total_Loss 1.1228 (1.1889)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:50:53,383: ============================================================
2022-07-25 11:51:33,895: time cost, forward:0.12381916568013221, backward:0.09630565732559965, data cost:0.18625060529909163 
2022-07-25 11:51:33,895: ============================================================
2022-07-25 11:51:33,895: Epoch 25/25 Batch 7000/7662 eta: 0:04:28.595678	Training Loss1 1.2910 (1.1902)	Training Total_Loss 1.2910 (1.1902)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:51:33,895: ============================================================
2022-07-25 11:52:14,445: time cost, forward:0.12381592077644027, backward:0.09630566483602539, data cost:0.18623519665860075 
2022-07-25 11:52:14,445: ============================================================
2022-07-25 11:52:14,445: Epoch 25/25 Batch 7100/7662 eta: 0:03:48.298345	Training Loss1 1.2099 (1.1916)	Training Total_Loss 1.2099 (1.1916)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:52:14,445: ============================================================
2022-07-25 11:52:54,977: time cost, forward:0.12381120903125355, backward:0.09630546504912368, data cost:0.18621940145162696 
2022-07-25 11:52:54,977: ============================================================
2022-07-25 11:52:54,978: Epoch 25/25 Batch 7200/7662 eta: 0:03:07.664383	Training Loss1 1.3530 (1.1931)	Training Total_Loss 1.3530 (1.1931)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:52:54,978: ============================================================
2022-07-25 11:53:35,493: time cost, forward:0.12380515064078008, backward:0.09630485161769421, data cost:0.18620356152622417 
2022-07-25 11:53:35,493: ============================================================
2022-07-25 11:53:35,493: Epoch 25/25 Batch 7300/7662 eta: 0:02:27.071773	Training Loss1 1.2579 (1.1945)	Training Total_Loss 1.2579 (1.1945)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:53:35,493: ============================================================
2022-07-25 11:54:16,023: time cost, forward:0.12380149322903661, backward:0.09630446979235532, data cost:0.18618799377283643 
2022-07-25 11:54:16,024: ============================================================
2022-07-25 11:54:16,024: Epoch 25/25 Batch 7400/7662 eta: 0:01:46.595323	Training Loss1 1.3038 (1.1964)	Training Total_Loss 1.3038 (1.1964)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:54:16,024: ============================================================
2022-07-25 11:54:56,527: time cost, forward:0.12379492459447881, backward:0.09630346819629254, data cost:0.18617286521890256 
2022-07-25 11:54:56,528: ============================================================
2022-07-25 11:54:56,528: Epoch 25/25 Batch 7500/7662 eta: 0:01:06.021487	Training Loss1 1.2903 (1.1981)	Training Total_Loss 1.2903 (1.1981)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:54:56,528: ============================================================
2022-07-25 11:55:37,050: time cost, forward:0.12379136774505121, backward:0.09630311384124494, data cost:0.18615713522989258 
2022-07-25 11:55:37,050: ============================================================
2022-07-25 11:55:37,050: Epoch 25/25 Batch 7600/7662 eta: 0:00:25.529211	Training Loss1 1.1717 (1.1995)	Training Total_Loss 1.1717 (1.1995)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:55:37,050: ============================================================
2022-07-25 11:56:04,085: Epoch 25/25 Batch 7663/7662 eta: 0:00:00	Training Loss1 1.3387 (1.2002)	Training Total_Loss 1.3387 (1.2002)	Training Prec@1 100.000 (99.994)	Training Prec@5 100.000 (99.997)	
2022-07-25 11:56:04,085: ============================================================
2022-07-25 11:56:04,121: Save Checkpoint...
2022-07-25 11:56:04,121: ============================================================
2022-07-25 11:56:06,995: Save done!
2022-07-25 11:56:06,995: ============================================================
