2022-04-03 09:40:34,293: [('name', 'amsoft-36'), ('backbone_model_name', 'SimpleResnet_36'), ('classify_model_name', 'MarginCosineProduct'), ('resume_net_model', None), ('resume_net_classifier', None), ('no_cuda', False), ('gpu_num', 1), ('log_interval', 100), ('log_path', './logs/SR_36_ddp_sphereNorm.log'), ('log_pic_path', './logs/pic/SR_36_ddp_sphereNorm/'), ('save_path', 'snapshot/SR_36_ddp_sphereNorm/'), ('lmdb_path', '/home/ubuntu/data4/lk/data/lmdb_default'), ('batch_size', 512), ('datanum', 3923399), ('num_class', 86876), ('lmdb_workers', 4), ('num_workers', 4), ('start_epoch', 1), ('max_epoch', 26), ('lr', 0.1), ('base', 'epoch'), ('step_size', [10, 20, 30]), ('momentum', 0.9), ('gama', 0.1), ('weight_decay', 0.0005), ('rank', 0), ('dist_url', 'env://'), ('world_size', 2), ('gpu', 0), ('dist_backend', 'nccl'), ('distributed', True), ('master_port', 22345), ('multiprocessing_distributed', False), ('SEED', 1337), ('local_rank', 0)]
2022-04-03 09:40:34,294: SimpleResidualBackbone(
  (conv1): ConvPrelu(
    (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (prelu): PReLU(num_parameters=64)
  )
  (layer1): Sequential(
    (0): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=64)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=64)
      )
    )
    (1): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=64)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=64)
      )
    )
  )
  (conv2): ConvPrelu(
    (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (prelu): PReLU(num_parameters=128)
  )
  (layer2): Sequential(
    (0): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
    )
    (1): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
    )
    (2): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
    )
    (3): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
    )
  )
  (conv3): ConvPrelu(
    (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (prelu): PReLU(num_parameters=256)
  )
  (layer3): Sequential(
    (0): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
    (1): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
    (2): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
    (3): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
    (4): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
    (5): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
    (6): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
    (7): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
  )
  (conv4): ConvPrelu(
    (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (prelu): PReLU(num_parameters=512)
  )
  (layer4): Sequential(
    (0): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=512)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=512)
      )
    )
    (1): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=512)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=512)
      )
    )
  )
  (fc5): Linear(in_features=25088, out_features=512, bias=True)
)
2022-04-03 09:40:35,287: data balance
2022-04-03 09:41:06,402: time cost, forward:0.0255199417923436, backward:0.05653428549718375, data cost:0.2264740996890598 
2022-04-03 09:41:06,402: ============================================================
2022-04-03 09:41:06,403: Epoch 1/26 Batch 100/7662 eta: 17:05:48.848180	Training Loss 22.2967 (22.4485)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.012)	
2022-04-03 09:41:06,403: ============================================================
2022-04-03 09:41:35,196: time cost, forward:0.020449507775618204, backward:0.05408046473210781, data cost:0.22336260637446265 
2022-04-03 09:41:35,197: ============================================================
2022-04-03 09:41:35,197: Epoch 1/26 Batch 200/7662 eta: 15:55:04.376218	Training Loss 22.2712 (22.3555)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.013)	
2022-04-03 09:41:35,197: ============================================================
2022-04-03 09:42:04,285: time cost, forward:0.01852704928471492, backward:0.053553109982340634, data cost:0.22318654634482088 
2022-04-03 09:42:04,286: ============================================================
2022-04-03 09:42:04,286: Epoch 1/26 Batch 300/7662 eta: 16:04:22.437558	Training Loss 22.1974 (22.3217)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.011)	
2022-04-03 09:42:04,287: ============================================================
2022-04-03 09:42:33,541: time cost, forward:0.017047889848102005, backward:0.053877602842517365, data cost:0.22351737249465214 
2022-04-03 09:42:33,541: ============================================================
2022-04-03 09:42:33,542: Epoch 1/26 Batch 400/7662 eta: 16:09:23.430214	Training Loss 22.3136 (22.3114)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.012)	
2022-04-03 09:42:33,542: ============================================================
2022-04-03 09:43:03,117: time cost, forward:0.016190589071514612, backward:0.05408406544305041, data cost:0.22430643385541224 
2022-04-03 09:43:03,118: ============================================================
2022-04-03 09:43:03,119: Epoch 1/26 Batch 500/7662 eta: 16:19:32.934954	Training Loss 22.3118 (22.3169)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.013)	
2022-04-03 09:43:03,119: ============================================================
2022-04-03 09:43:33,383: time cost, forward:0.015734806283686516, backward:0.054092048205596974, data cost:0.22601276168441137 
2022-04-03 09:43:33,384: ============================================================
2022-04-03 09:43:33,384: Epoch 1/26 Batch 600/7662 eta: 16:41:51.947835	Training Loss 22.3524 (22.3290)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.014)	
2022-04-03 09:43:33,385: ============================================================
2022-04-03 09:44:04,114: time cost, forward:0.015429505292267588, backward:0.054115494603933355, data cost:0.2276185449100871 
2022-04-03 09:44:04,115: ============================================================
2022-04-03 09:44:04,115: Epoch 1/26 Batch 700/7662 eta: 16:56:44.844867	Training Loss 22.4565 (22.3480)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.013)	
2022-04-03 09:44:04,116: ============================================================
2022-04-03 09:44:35,632: time cost, forward:0.015081188108804676, backward:0.05422469552079488, data cost:0.23013035854201144 
2022-04-03 09:44:35,633: ============================================================
2022-04-03 09:44:35,633: Epoch 1/26 Batch 800/7662 eta: 17:22:15.148734	Training Loss 22.4565 (22.3667)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.013)	
2022-04-03 09:44:35,633: ============================================================
2022-04-03 09:45:08,315: time cost, forward:0.014825129270288385, backward:0.05431819916832301, data cost:0.23335216069248016 
2022-04-03 09:45:08,315: ============================================================
2022-04-03 09:45:08,316: Epoch 1/26 Batch 900/7662 eta: 18:00:13.925905	Training Loss 22.4503 (22.3802)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.013)	
2022-04-03 09:45:08,316: ============================================================
2022-04-03 09:45:40,563: time cost, forward:0.014632669893709628, backward:0.054367302654980416, data cost:0.23541530307468111 
2022-04-03 09:45:40,588: ============================================================
2022-04-03 09:45:40,589: Epoch 1/26 Batch 1000/7662 eta: 17:46:08.997003	Training Loss 22.2266 (22.3757)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-04-03 09:45:40,589: ============================================================
2022-04-03 09:46:13,043: time cost, forward:0.014539066068251855, backward:0.054379505065487554, data cost:0.23730408548766424 
2022-04-03 09:46:13,044: ============================================================
2022-04-03 09:46:13,044: Epoch 1/26 Batch 1100/7662 eta: 17:51:38.432237	Training Loss 21.9964 (22.3483)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.195 (0.031)	
2022-04-03 09:46:13,044: ============================================================
2022-04-03 09:46:45,782: time cost, forward:0.014438702326401558, backward:0.05439516442134243, data cost:0.23910351889246798 
2022-04-03 09:46:45,783: ============================================================
2022-04-03 09:46:45,783: Epoch 1/26 Batch 1200/7662 eta: 18:00:27.507863	Training Loss 21.6491 (22.3010)	Training Prec@1 0.195 (0.011)	Training Prec@5 0.391 (0.048)	
2022-04-03 09:46:45,783: ============================================================
2022-04-03 09:47:18,367: time cost, forward:0.01437668069864439, backward:0.05440667466625422, data cost:0.24047477801457287 
2022-04-03 09:47:18,368: ============================================================
2022-04-03 09:47:18,368: Epoch 1/26 Batch 1300/7662 eta: 17:54:50.243208	Training Loss 21.3881 (22.2368)	Training Prec@1 0.000 (0.023)	Training Prec@5 0.391 (0.082)	
2022-04-03 09:47:18,368: ============================================================
2022-04-03 09:47:52,843: time cost, forward:0.01433853527066365, backward:0.05438162021077983, data cost:0.24302138116548877 
2022-04-03 09:47:52,843: ============================================================
2022-04-03 09:47:52,843: Epoch 1/26 Batch 1400/7662 eta: 18:56:36.414048	Training Loss 21.0171 (22.1587)	Training Prec@1 0.000 (0.042)	Training Prec@5 0.781 (0.145)	
2022-04-03 09:47:52,843: ============================================================
2022-04-03 09:48:28,076: time cost, forward:0.014341461093844057, backward:0.05435434256178924, data cost:0.24570713526730223 
2022-04-03 09:48:28,077: ============================================================
2022-04-03 09:48:28,077: Epoch 1/26 Batch 1500/7662 eta: 19:21:01.873572	Training Loss 20.4808 (22.0698)	Training Prec@1 0.586 (0.073)	Training Prec@5 1.562 (0.232)	
2022-04-03 09:48:28,077: ============================================================
2022-04-03 09:49:02,603: time cost, forward:0.014296407622050464, backward:0.05436819415304197, data cost:0.24764065536728047 
2022-04-03 09:49:02,603: ============================================================
2022-04-03 09:49:02,604: Epoch 1/26 Batch 1600/7662 eta: 18:57:08.659720	Training Loss 20.3884 (21.9690)	Training Prec@1 0.391 (0.132)	Training Prec@5 3.125 (0.378)	
2022-04-03 09:49:02,604: ============================================================
2022-04-03 09:49:37,217: time cost, forward:0.014262533945641566, backward:0.05437886623721603, data cost:0.24938673900112537 
2022-04-03 09:49:37,218: ============================================================
2022-04-03 09:49:37,218: Epoch 1/26 Batch 1700/7662 eta: 18:59:28.213292	Training Loss 19.8779 (21.8594)	Training Prec@1 2.734 (0.221)	Training Prec@5 5.664 (0.598)	
2022-04-03 09:49:37,219: ============================================================
2022-04-03 09:50:12,380: time cost, forward:0.01415591971485929, backward:0.05447530812724157, data cost:0.25120670481348384 
2022-04-03 09:50:12,380: ============================================================
2022-04-03 09:50:12,380: Epoch 1/26 Batch 1800/7662 eta: 19:16:55.047532	Training Loss 19.4918 (21.7400)	Training Prec@1 2.734 (0.355)	Training Prec@5 8.203 (0.901)	
2022-04-03 09:50:12,381: ============================================================
2022-04-03 09:50:47,909: time cost, forward:0.014031399922222762, backward:0.0545714877039712, data cost:0.25305935029546606 
2022-04-03 09:50:47,909: ============================================================
2022-04-03 09:50:47,909: Epoch 1/26 Batch 1900/7662 eta: 19:28:23.393720	Training Loss 19.0746 (21.6101)	Training Prec@1 4.102 (0.555)	Training Prec@5 9.375 (1.311)	
2022-04-03 09:50:47,910: ============================================================
2022-04-03 09:51:24,277: time cost, forward:0.013943257482126988, backward:0.054647025613560565, data cost:0.25515484750241024 
2022-04-03 09:51:24,277: ============================================================
2022-04-03 09:51:24,278: Epoch 1/26 Batch 2000/7662 eta: 19:55:22.698963	Training Loss 18.7823 (21.4714)	Training Prec@1 7.227 (0.829)	Training Prec@5 14.258 (1.837)	
2022-04-03 09:51:24,278: ============================================================
2022-04-03 09:52:01,534: time cost, forward:0.0139152976431808, backward:0.0546643563598153, data cost:0.2574599501403983 
2022-04-03 09:52:01,535: ============================================================
2022-04-03 09:52:01,535: Epoch 1/26 Batch 2100/7662 eta: 20:23:59.041706	Training Loss 18.2775 (21.3227)	Training Prec@1 8.594 (1.201)	Training Prec@5 14.062 (2.498)	
2022-04-03 09:52:01,535: ============================================================
2022-04-03 09:52:38,095: time cost, forward:0.01389814854318741, backward:0.054663129045834265, data cost:0.2592400168765399 
2022-04-03 09:52:38,096: ============================================================
2022-04-03 09:52:38,096: Epoch 1/26 Batch 2200/7662 eta: 20:00:30.271203	Training Loss 17.5306 (21.1642)	Training Prec@1 11.719 (1.688)	Training Prec@5 22.266 (3.313)	
2022-04-03 09:52:38,096: ============================================================
2022-04-03 09:53:15,521: time cost, forward:0.013899123269405091, backward:0.05466244375254601, data cost:0.2612355250076088 
2022-04-03 09:53:15,521: ============================================================
2022-04-03 09:53:15,522: Epoch 1/26 Batch 2300/7662 eta: 20:28:15.696246	Training Loss 16.9029 (20.9952)	Training Prec@1 19.141 (2.293)	Training Prec@5 29.297 (4.271)	
2022-04-03 09:53:15,522: ============================================================
2022-04-03 09:53:52,464: time cost, forward:0.013942927805370667, backward:0.05461702301085815, data cost:0.262882894752124 
2022-04-03 09:53:52,465: ============================================================
2022-04-03 09:53:52,465: Epoch 1/26 Batch 2400/7662 eta: 20:11:49.603230	Training Loss 16.2266 (20.8163)	Training Prec@1 23.047 (3.038)	Training Prec@5 36.328 (5.394)	
2022-04-03 09:53:52,465: ============================================================
2022-04-03 09:54:29,396: time cost, forward:0.013873293572494916, backward:0.054682112636924886, data cost:0.2643698116644424 
2022-04-03 09:54:29,396: ============================================================
2022-04-03 09:54:29,397: Epoch 1/26 Batch 2500/7662 eta: 20:10:49.390282	Training Loss 15.6029 (20.6292)	Training Prec@1 31.445 (3.917)	Training Prec@5 42.188 (6.643)	
2022-04-03 09:54:29,397: ============================================================
2022-04-03 09:55:06,744: time cost, forward:0.013799884953192447, backward:0.054748667346004705, data cost:0.2659042543886074 
2022-04-03 09:55:06,745: ============================================================
2022-04-03 09:55:06,745: Epoch 1/26 Batch 2600/7662 eta: 20:23:51.741950	Training Loss 15.0764 (20.4358)	Training Prec@1 34.570 (4.919)	Training Prec@5 46.680 (8.001)	
2022-04-03 09:55:06,746: ============================================================
2022-04-03 09:55:44,847: time cost, forward:0.013761856592156438, backward:0.05477948646361672, data cost:0.2676123864300033 
2022-04-03 09:55:44,847: ============================================================
2022-04-03 09:55:44,848: Epoch 1/26 Batch 2700/7662 eta: 20:47:56.124929	Training Loss 14.5216 (20.2357)	Training Prec@1 38.672 (6.028)	Training Prec@5 51.758 (9.451)	
2022-04-03 09:55:44,848: ============================================================
2022-04-03 09:56:22,708: time cost, forward:0.013661998303799426, backward:0.05486939182533627, data cost:0.26911932232125224 
2022-04-03 09:56:22,709: ============================================================
2022-04-03 09:56:22,709: Epoch 1/26 Batch 2800/7662 eta: 20:39:25.250360	Training Loss 14.4211 (20.0303)	Training Prec@1 39.844 (7.237)	Training Prec@5 51.172 (10.982)	
2022-04-03 09:56:22,709: ============================================================
2022-04-03 09:57:01,443: time cost, forward:0.013609328653204642, backward:0.054910207789862886, data cost:0.2708284728236756 
2022-04-03 09:57:01,443: ============================================================
2022-04-03 09:57:01,443: Epoch 1/26 Batch 2900/7662 eta: 21:07:20.268643	Training Loss 13.8682 (19.8203)	Training Prec@1 45.898 (8.525)	Training Prec@5 57.031 (12.565)	
2022-04-03 09:57:01,444: ============================================================
2022-04-03 09:57:39,446: time cost, forward:0.013582991456619776, backward:0.054927628928321565, data cost:0.2721725397405723 
2022-04-03 09:57:39,446: ============================================================
2022-04-03 09:57:39,447: Epoch 1/26 Batch 3000/7662 eta: 20:42:47.627787	Training Loss 12.8921 (19.6074)	Training Prec@1 54.688 (9.883)	Training Prec@5 67.188 (14.197)	
2022-04-03 09:57:39,447: ============================================================
2022-04-03 09:58:19,204: time cost, forward:0.013555003120346045, backward:0.05495650616719978, data cost:0.2739799468122632 
2022-04-03 09:58:19,205: ============================================================
2022-04-03 09:58:19,205: Epoch 1/26 Batch 3100/7662 eta: 21:39:30.889685	Training Loss 12.6800 (19.3916)	Training Prec@1 57.031 (11.308)	Training Prec@5 67.969 (15.858)	
2022-04-03 09:58:19,205: ============================================================
2022-04-03 09:58:59,615: time cost, forward:0.013557019104022986, backward:0.05495194264895173, data cost:0.27589775853397025 
2022-04-03 09:58:59,616: ============================================================
2022-04-03 09:58:59,616: Epoch 1/26 Batch 3200/7662 eta: 22:00:11.083106	Training Loss 12.1703 (19.1750)	Training Prec@1 59.375 (12.764)	Training Prec@5 70.508 (17.523)	
2022-04-03 09:58:59,616: ============================================================
2022-04-03 09:59:38,852: time cost, forward:0.013530984724171417, backward:0.05497486188795466, data cost:0.2773277749434208 
2022-04-03 09:59:38,852: ============================================================
2022-04-03 09:59:38,853: Epoch 1/26 Batch 3300/7662 eta: 21:21:09.226331	Training Loss 11.8923 (18.9587)	Training Prec@1 64.844 (14.247)	Training Prec@5 74.219 (19.183)	
2022-04-03 09:59:38,853: ============================================================
2022-04-03 10:00:18,504: time cost, forward:0.013471208694718382, backward:0.05503527028801231, data cost:0.2787952193725667 
2022-04-03 10:00:18,505: ============================================================
2022-04-03 10:00:18,505: Epoch 1/26 Batch 3400/7662 eta: 21:34:04.557780	Training Loss 11.2868 (18.7457)	Training Prec@1 67.773 (15.713)	Training Prec@5 77.539 (20.810)	
2022-04-03 10:00:18,505: ============================================================
2022-04-03 10:00:57,873: time cost, forward:0.013432091050367419, backward:0.05506974821534965, data cost:0.2801170996442186 
2022-04-03 10:00:57,874: ============================================================
2022-04-03 10:00:57,875: Epoch 1/26 Batch 3500/7662 eta: 21:24:12.027296	Training Loss 11.1216 (18.5332)	Training Prec@1 69.336 (17.192)	Training Prec@5 77.734 (22.417)	
2022-04-03 10:00:57,875: ============================================================
2022-04-03 10:01:37,364: time cost, forward:0.013411378621988808, backward:0.055090876743839196, data cost:0.28136721681508464 
2022-04-03 10:01:37,365: ============================================================
2022-04-03 10:01:37,365: Epoch 1/26 Batch 3600/7662 eta: 21:27:27.672124	Training Loss 10.9300 (18.3240)	Training Prec@1 70.508 (18.658)	Training Prec@5 81.055 (23.997)	
2022-04-03 10:01:37,365: ============================================================
2022-04-03 10:02:18,263: time cost, forward:0.013382187982803101, backward:0.05511977827913151, data cost:0.28288212006850705 
2022-04-03 10:02:18,263: ============================================================
2022-04-03 10:02:18,263: Epoch 1/26 Batch 3700/7662 eta: 22:12:41.621335	Training Loss 10.3069 (18.1176)	Training Prec@1 72.461 (20.104)	Training Prec@5 82.031 (25.545)	
2022-04-03 10:02:18,263: ============================================================
2022-04-03 10:02:58,796: time cost, forward:0.013339711729241975, backward:0.05515791887231612, data cost:0.2843452760124558 
2022-04-03 10:02:58,797: ============================================================
2022-04-03 10:02:58,797: Epoch 1/26 Batch 3800/7662 eta: 22:00:07.695190	Training Loss 10.0671 (17.9151)	Training Prec@1 74.414 (21.528)	Training Prec@5 83.398 (27.056)	
2022-04-03 10:02:58,797: ============================================================
2022-04-03 10:03:37,785: time cost, forward:0.01331766485158955, backward:0.05518202287596169, data cost:0.28529931747415 
2022-04-03 10:03:37,786: ============================================================
2022-04-03 10:03:37,786: Epoch 1/26 Batch 3900/7662 eta: 21:09:11.040682	Training Loss 9.9741 (17.7175)	Training Prec@1 79.883 (22.921)	Training Prec@5 87.891 (28.510)	
2022-04-03 10:03:37,786: ============================================================
2022-04-03 10:04:17,932: time cost, forward:0.013279565068059159, backward:0.05521719209490254, data cost:0.2864408404208863 
2022-04-03 10:04:17,933: ============================================================
2022-04-03 10:04:17,933: Epoch 1/26 Batch 4000/7662 eta: 21:46:12.404810	Training Loss 9.8513 (17.5252)	Training Prec@1 77.344 (24.276)	Training Prec@5 84.180 (29.921)	
2022-04-03 10:04:17,933: ============================================================
2022-04-03 10:04:58,862: time cost, forward:0.013262907043553818, backward:0.05522846454351406, data cost:0.2877855744121074 
2022-04-03 10:04:58,862: ============================================================
2022-04-03 10:04:58,863: Epoch 1/26 Batch 4100/7662 eta: 22:10:58.806238	Training Loss 9.7003 (17.3363)	Training Prec@1 77.539 (25.605)	Training Prec@5 85.352 (31.295)	
2022-04-03 10:04:58,863: ============================================================
2022-04-03 10:05:39,999: time cost, forward:0.013262104437333624, backward:0.055231243237111365, data cost:0.2890796712478816 
2022-04-03 10:05:39,999: ============================================================
2022-04-03 10:05:40,000: Epoch 1/26 Batch 4200/7662 eta: 22:17:02.860632	Training Loss 9.5989 (17.1518)	Training Prec@1 80.859 (26.907)	Training Prec@5 87.305 (32.627)	
2022-04-03 10:05:40,000: ============================================================
2022-04-03 10:06:21,337: time cost, forward:0.013271556285459736, backward:0.055231038956731995, data cost:0.2903538944278104 
2022-04-03 10:06:21,338: ============================================================
2022-04-03 10:06:21,338: Epoch 1/26 Batch 4300/7662 eta: 22:22:53.893995	Training Loss 9.2639 (16.9723)	Training Prec@1 82.617 (28.165)	Training Prec@5 89.648 (33.909)	
2022-04-03 10:06:21,339: ============================================================
2022-04-03 10:07:02,423: time cost, forward:0.013269728708061259, backward:0.055250916326010764, data cost:0.29150767487866086 
2022-04-03 10:07:02,423: ============================================================
2022-04-03 10:07:02,423: Epoch 1/26 Batch 4400/7662 eta: 22:13:58.903939	Training Loss 9.2575 (16.7978)	Training Prec@1 83.203 (29.391)	Training Prec@5 89.062 (35.152)	
2022-04-03 10:07:02,423: ============================================================
2022-04-03 10:07:41,782: time cost, forward:0.01326736785963287, backward:0.05526531216938725, data cost:0.2922153748997478 
2022-04-03 10:07:41,783: ============================================================
2022-04-03 10:07:41,783: Epoch 1/26 Batch 4500/7662 eta: 21:17:18.233939	Training Loss 9.3706 (16.6283)	Training Prec@1 80.664 (30.577)	Training Prec@5 87.109 (36.353)	
2022-04-03 10:07:41,783: ============================================================
2022-04-03 10:08:21,516: time cost, forward:0.01327529309184221, backward:0.055264294886231344, data cost:0.2929675230178451 
2022-04-03 10:08:21,517: ============================================================
2022-04-03 10:08:21,517: Epoch 1/26 Batch 4600/7662 eta: 21:28:47.483422	Training Loss 9.0764 (16.4626)	Training Prec@1 83.984 (31.731)	Training Prec@5 90.820 (37.517)	
2022-04-03 10:08:21,517: ============================================================
2022-04-03 10:09:02,251: time cost, forward:0.013273864077567851, backward:0.05527713903089005, data cost:0.2938604047892575 
2022-04-03 10:09:02,251: ============================================================
2022-04-03 10:09:02,252: Epoch 1/26 Batch 4700/7662 eta: 22:00:34.557775	Training Loss 8.7989 (16.3023)	Training Prec@1 84.180 (32.853)	Training Prec@5 91.016 (38.640)	
2022-04-03 10:09:02,252: ============================================================
2022-04-03 10:09:41,294: time cost, forward:0.013278781287146995, backward:0.055282074104972025, data cost:0.2944894241377522 
2022-04-03 10:09:41,294: ============================================================
2022-04-03 10:09:41,295: Epoch 1/26 Batch 4800/7662 eta: 21:05:04.978113	Training Loss 8.8785 (16.1464)	Training Prec@1 85.352 (33.945)	Training Prec@5 90.234 (39.728)	
2022-04-03 10:09:41,295: ============================================================
2022-04-03 10:10:21,603: time cost, forward:0.013278342529471297, backward:0.05529029653081604, data cost:0.2952983284463783 
2022-04-03 10:10:21,604: ============================================================
2022-04-03 10:10:21,604: Epoch 1/26 Batch 4900/7662 eta: 21:45:25.927404	Training Loss 8.6954 (15.9945)	Training Prec@1 82.422 (34.995)	Training Prec@5 90.430 (40.776)	
2022-04-03 10:10:21,604: ============================================================
2022-04-03 10:11:01,778: time cost, forward:0.013268007090340187, backward:0.05531311869788203, data cost:0.29603874819305903 
2022-04-03 10:11:01,779: ============================================================
2022-04-03 10:11:01,779: Epoch 1/26 Batch 5000/7662 eta: 21:40:25.559312	Training Loss 8.5641 (15.8468)	Training Prec@1 84.766 (36.017)	Training Prec@5 90.234 (41.794)	
2022-04-03 10:11:01,779: ============================================================
2022-04-03 10:11:42,420: time cost, forward:0.013253264577745526, backward:0.055334444582801304, data cost:0.29683433431904793 
2022-04-03 10:11:42,421: ============================================================
2022-04-03 10:11:42,421: Epoch 1/26 Batch 5100/7662 eta: 21:54:50.582521	Training Loss 8.4688 (15.7023)	Training Prec@1 87.695 (37.017)	Training Prec@5 91.602 (42.785)	
2022-04-03 10:11:42,421: ============================================================
2022-04-03 10:12:23,611: time cost, forward:0.013231494147448751, backward:0.05536447421567535, data cost:0.29770808596866916 
2022-04-03 10:12:23,611: ============================================================
2022-04-03 10:12:23,611: Epoch 1/26 Batch 5200/7662 eta: 22:11:54.546429	Training Loss 8.3902 (15.5623)	Training Prec@1 87.305 (37.983)	Training Prec@5 93.945 (43.737)	
2022-04-03 10:12:23,611: ============================================================
2022-04-03 10:13:06,156: time cost, forward:0.013230257651607458, backward:0.05537058875614302, data cost:0.29880675110508303 
2022-04-03 10:13:06,157: ============================================================
2022-04-03 10:13:06,157: Epoch 1/26 Batch 5300/7662 eta: 22:55:02.146392	Training Loss 8.5140 (15.4260)	Training Prec@1 87.109 (38.918)	Training Prec@5 91.797 (44.657)	
2022-04-03 10:13:06,157: ============================================================
2022-04-03 10:13:47,450: time cost, forward:0.013210137346581765, backward:0.05539302411709125, data cost:0.299642226280471 
2022-04-03 10:13:47,451: ============================================================
2022-04-03 10:13:47,451: Epoch 1/26 Batch 5400/7662 eta: 22:13:52.733410	Training Loss 8.3364 (15.2931)	Training Prec@1 86.523 (39.826)	Training Prec@5 92.773 (45.551)	
2022-04-03 10:13:47,451: ============================================================
2022-04-03 10:14:29,149: time cost, forward:0.013193387164920432, backward:0.05541272279587111, data cost:0.30051258013972065 
2022-04-03 10:14:29,149: ============================================================
2022-04-03 10:14:29,149: Epoch 1/26 Batch 5500/7662 eta: 22:26:15.054443	Training Loss 8.0929 (15.1636)	Training Prec@1 89.258 (40.710)	Training Prec@5 95.508 (46.418)	
2022-04-03 10:14:29,149: ============================================================
2022-04-03 10:15:10,211: time cost, forward:0.013173542910121258, backward:0.05543942970130077, data cost:0.30123408753268527 
2022-04-03 10:15:10,211: ============================================================
2022-04-03 10:15:10,212: Epoch 1/26 Batch 5600/7662 eta: 22:05:02.250419	Training Loss 7.9840 (15.0377)	Training Prec@1 89.844 (41.568)	Training Prec@5 95.117 (47.258)	
2022-04-03 10:15:10,212: ============================================================
2022-04-03 10:15:51,162: time cost, forward:0.013169620848262618, backward:0.05544454780748631, data cost:0.3019176255738365 
2022-04-03 10:15:51,163: ============================================================
2022-04-03 10:15:51,163: Epoch 1/26 Batch 5700/7662 eta: 22:00:45.497509	Training Loss 8.1438 (14.9149)	Training Prec@1 89.648 (42.401)	Training Prec@5 94.141 (48.072)	
2022-04-03 10:15:51,163: ============================================================
2022-04-03 10:16:32,082: time cost, forward:0.013171899563321822, backward:0.055451403858127586, data cost:0.30256599499287534 
2022-04-03 10:16:32,082: ============================================================
2022-04-03 10:16:32,082: Epoch 1/26 Batch 5800/7662 eta: 21:59:03.652120	Training Loss 8.2385 (14.7962)	Training Prec@1 89.062 (43.207)	Training Prec@5 93.750 (48.861)	
2022-04-03 10:16:32,083: ============================================================
2022-04-03 10:17:13,479: time cost, forward:0.013168367981445913, backward:0.05546529662065495, data cost:0.30324292878090964 
2022-04-03 10:17:13,480: ============================================================
2022-04-03 10:17:13,480: Epoch 1/26 Batch 5900/7662 eta: 22:13:46.952503	Training Loss 7.8658 (14.6795)	Training Prec@1 90.625 (43.995)	Training Prec@5 94.336 (49.627)	
2022-04-03 10:17:13,480: ============================================================
2022-04-03 10:17:55,867: time cost, forward:0.013160638440388563, backward:0.05547726800152015, data cost:0.30411950853153513 
2022-04-03 10:17:55,867: ============================================================
2022-04-03 10:17:55,867: Epoch 1/26 Batch 6000/7662 eta: 22:44:58.325382	Training Loss 7.8711 (14.5662)	Training Prec@1 89.648 (44.759)	Training Prec@5 94.531 (50.369)	
2022-04-03 10:17:55,868: ============================================================
2022-04-03 10:18:36,981: time cost, forward:0.013136713245615135, backward:0.05550266703849426, data cost:0.30472975125917157 
2022-04-03 10:18:36,981: ============================================================
2022-04-03 10:18:36,982: Epoch 1/26 Batch 6100/7662 eta: 22:03:16.752006	Training Loss 7.4806 (14.4554)	Training Prec@1 91.406 (45.503)	Training Prec@5 95.312 (51.091)	
2022-04-03 10:18:36,982: ============================================================
2022-04-03 10:19:17,992: time cost, forward:0.01313533916033397, backward:0.05550250524012268, data cost:0.305321925108347 
2022-04-03 10:19:17,993: ============================================================
2022-04-03 10:19:17,993: Epoch 1/26 Batch 6200/7662 eta: 21:59:17.063327	Training Loss 7.7428 (14.3485)	Training Prec@1 91.406 (46.219)	Training Prec@5 95.117 (51.788)	
2022-04-03 10:19:17,993: ============================================================
2022-04-03 10:19:57,636: time cost, forward:0.013113306181490241, backward:0.055519445337252234, data cost:0.3056776995960919 
2022-04-03 10:19:57,637: ============================================================
2022-04-03 10:19:57,637: Epoch 1/26 Batch 6300/7662 eta: 21:14:38.827672	Training Loss 7.6498 (14.2434)	Training Prec@1 91.406 (46.919)	Training Prec@5 95.508 (52.466)	
2022-04-03 10:19:57,637: ============================================================
2022-04-03 10:20:37,786: time cost, forward:0.013116347974195091, backward:0.055515020783012, data cost:0.3060881971549123 
2022-04-03 10:20:37,787: ============================================================
2022-04-03 10:20:37,788: Epoch 1/26 Batch 6400/7662 eta: 21:30:15.113374	Training Loss 7.6450 (14.1409)	Training Prec@1 92.188 (47.601)	Training Prec@5 96.094 (53.126)	
2022-04-03 10:20:37,788: ============================================================
2022-04-03 10:21:19,125: time cost, forward:0.013114324439982485, backward:0.05551804053011188, data cost:0.3066711240152998 
2022-04-03 10:21:19,126: ============================================================
2022-04-03 10:21:19,126: Epoch 1/26 Batch 6500/7662 eta: 22:07:44.620360	Training Loss 7.1955 (14.0404)	Training Prec@1 93.750 (48.268)	Training Prec@5 96.680 (53.771)	
2022-04-03 10:21:19,126: ============================================================
2022-04-03 10:21:59,946: time cost, forward:0.013111061933528729, backward:0.05551514605316796, data cost:0.3071665648601871 
2022-04-03 10:21:59,947: ============================================================
2022-04-03 10:21:59,947: Epoch 1/26 Batch 6600/7662 eta: 21:50:26.289326	Training Loss 7.6784 (13.9428)	Training Prec@1 89.453 (48.912)	Training Prec@5 94.336 (54.393)	
2022-04-03 10:21:59,947: ============================================================
2022-04-03 10:22:42,522: time cost, forward:0.013101531135660443, backward:0.055523343932577025, data cost:0.30790400942825064 
2022-04-03 10:22:42,522: ============================================================
2022-04-03 10:22:42,522: Epoch 1/26 Batch 6700/7662 eta: 22:46:03.592651	Training Loss 7.4446 (13.8473)	Training Prec@1 94.141 (49.543)	Training Prec@5 95.508 (55.000)	
2022-04-03 10:22:42,523: ============================================================
2022-04-03 10:23:25,940: time cost, forward:0.013098543681613065, backward:0.055524634515420355, data cost:0.30873067885010463 
2022-04-03 10:23:25,941: ============================================================
2022-04-03 10:23:25,942: Epoch 1/26 Batch 6800/7662 eta: 23:12:24.043893	Training Loss 7.2873 (13.7539)	Training Prec@1 93.359 (50.158)	Training Prec@5 96.484 (55.593)	
2022-04-03 10:23:25,942: ============================================================
2022-04-03 10:24:08,136: time cost, forward:0.013102914858838927, backward:0.055522023568828655, data cost:0.30938456604179737 
2022-04-03 10:24:08,136: ============================================================
2022-04-03 10:24:08,137: Epoch 1/26 Batch 6900/7662 eta: 22:32:26.718734	Training Loss 7.4919 (13.6625)	Training Prec@1 90.234 (50.758)	Training Prec@5 94.141 (56.171)	
2022-04-03 10:24:08,137: ============================================================
2022-04-03 10:24:49,853: time cost, forward:0.013122153564902234, backward:0.05550255426629507, data cost:0.3099327570779917 
2022-04-03 10:24:49,854: ============================================================
2022-04-03 10:24:49,854: Epoch 1/26 Batch 7000/7662 eta: 22:16:26.070522	Training Loss 7.4613 (13.5735)	Training Prec@1 91.602 (51.341)	Training Prec@5 94.531 (56.728)	
2022-04-03 10:24:49,854: ============================================================
2022-04-03 10:25:31,449: time cost, forward:0.01312600886222258, backward:0.055499106330726494, data cost:0.3104506936404449 
2022-04-03 10:25:31,450: ============================================================
2022-04-03 10:25:31,450: Epoch 1/26 Batch 7100/7662 eta: 22:11:51.402177	Training Loss 7.6660 (13.4871)	Training Prec@1 89.648 (51.906)	Training Prec@5 94.727 (57.270)	
2022-04-03 10:25:31,450: ============================================================
2022-04-03 10:26:12,612: time cost, forward:0.013121765377554963, backward:0.05550530665880244, data cost:0.3108913222192509 
2022-04-03 10:26:12,613: ============================================================
2022-04-03 10:26:12,613: Epoch 1/26 Batch 7200/7662 eta: 21:57:18.467045	Training Loss 7.3621 (13.4021)	Training Prec@1 90.234 (52.459)	Training Prec@5 94.922 (57.801)	
2022-04-03 10:26:12,613: ============================================================
2022-04-03 10:26:53,734: time cost, forward:0.01312583119007868, backward:0.05549838138224409, data cost:0.31133028327120316 
2022-04-03 10:26:53,734: ============================================================
2022-04-03 10:26:53,734: Epoch 1/26 Batch 7300/7662 eta: 21:55:17.201880	Training Loss 7.3711 (13.3190)	Training Prec@1 91.797 (53.002)	Training Prec@5 95.508 (58.319)	
2022-04-03 10:26:53,735: ============================================================
2022-04-03 10:27:35,306: time cost, forward:0.013127948774133345, backward:0.05549891115217728, data cost:0.311784373890598 
2022-04-03 10:27:35,306: ============================================================
2022-04-03 10:27:35,307: Epoch 1/26 Batch 7400/7662 eta: 22:09:00.595533	Training Loss 7.1962 (13.2386)	Training Prec@1 91.406 (53.526)	Training Prec@5 95.898 (58.823)	
2022-04-03 10:27:35,307: ============================================================
2022-04-03 10:28:16,683: time cost, forward:0.013123292194269295, backward:0.05550566977350724, data cost:0.31221707971402207 
2022-04-03 10:28:16,683: ============================================================
2022-04-03 10:28:16,684: Epoch 1/26 Batch 7500/7662 eta: 22:02:05.203830	Training Loss 7.0088 (13.1588)	Training Prec@1 92.773 (54.044)	Training Prec@5 95.898 (59.316)	
2022-04-03 10:28:16,684: ============================================================
2022-04-03 10:28:57,867: time cost, forward:0.013116632453515853, backward:0.055508615186550474, data cost:0.3126316410975325 
2022-04-03 10:28:57,868: ============================================================
2022-04-03 10:28:57,868: Epoch 1/26 Batch 7600/7662 eta: 21:55:14.747217	Training Loss 7.4227 (13.0807)	Training Prec@1 91.016 (54.548)	Training Prec@5 94.922 (59.797)	
2022-04-03 10:28:57,868: ============================================================
2022-04-03 10:29:24,232: Epoch: 1/26 eta: 21:54:48.801017	Training Loss 7.1044 (13.0325)	Training Prec@1 93.359 (54.859)	Training Prec@5 95.508 (60.093)
2022-04-03 10:29:24,233: ============================================================
2022-04-03 10:30:05,026: time cost, forward:0.012783823591290098, backward:0.05689357988762133, data cost:0.33646874235133933 
2022-04-03 10:30:05,026: ============================================================
2022-04-03 10:30:05,026: Epoch 2/26 Batch 100/7662 eta: 21:34:56.992400	Training Loss 6.9392 (6.7430)	Training Prec@1 92.188 (93.809)	Training Prec@5 94.727 (96.719)	
2022-04-03 10:30:05,027: ============================================================
2022-04-03 10:30:46,813: time cost, forward:0.012245341161986691, backward:0.05752004211272427, data cost:0.34146655863852954 
2022-04-03 10:30:46,814: ============================================================
2022-04-03 10:30:46,814: Epoch 2/26 Batch 200/7662 eta: 22:12:41.728255	Training Loss 6.8637 (6.7772)	Training Prec@1 91.992 (93.751)	Training Prec@5 95.508 (96.738)	
2022-04-03 10:30:46,815: ============================================================
2022-04-03 10:31:28,549: time cost, forward:0.01217619551464068, backward:0.057603454111411816, data cost:0.34365082584495926 
2022-04-03 10:31:28,549: ============================================================
2022-04-03 10:31:28,549: Epoch 2/26 Batch 300/7662 eta: 22:10:19.003174	Training Loss 6.7244 (6.7907)	Training Prec@1 91.992 (93.811)	Training Prec@5 95.703 (96.740)	
2022-04-03 10:31:28,550: ============================================================
2022-04-03 10:32:08,894: time cost, forward:0.011833667755126953, backward:0.05779237077947248, data cost:0.341153615698181 
2022-04-03 10:32:08,894: ============================================================
2022-04-03 10:32:08,894: Epoch 2/26 Batch 400/7662 eta: 21:25:19.858244	Training Loss 6.8265 (6.8190)	Training Prec@1 92.383 (93.750)	Training Prec@5 94.727 (96.721)	
2022-04-03 10:32:08,895: ============================================================
2022-04-03 10:32:50,277: time cost, forward:0.011576764808150236, backward:0.05800736452152352, data cost:0.3416943660002194 
2022-04-03 10:32:50,278: ============================================================
2022-04-03 10:32:50,278: Epoch 2/26 Batch 500/7662 eta: 21:57:43.426339	Training Loss 7.1892 (6.8421)	Training Prec@1 94.141 (93.698)	Training Prec@5 97.070 (96.688)	
2022-04-03 10:32:50,278: ============================================================
2022-04-03 10:33:32,045: time cost, forward:0.011419512791705251, backward:0.05825538627293353, data cost:0.3424730320804704 
2022-04-03 10:33:32,045: ============================================================
2022-04-03 10:33:32,046: Epoch 2/26 Batch 600/7662 eta: 22:09:15.812518	Training Loss 7.0180 (6.8537)	Training Prec@1 94.141 (93.683)	Training Prec@5 96.875 (96.682)	
2022-04-03 10:33:32,046: ============================================================
2022-04-03 10:34:14,249: time cost, forward:0.011283246573801545, backward:0.05849727097157927, data cost:0.3437057257721864 
2022-04-03 10:34:14,250: ============================================================
2022-04-03 10:34:14,250: Epoch 2/26 Batch 700/7662 eta: 22:22:27.189671	Training Loss 7.0112 (6.8604)	Training Prec@1 91.797 (93.677)	Training Prec@5 95.117 (96.672)	
2022-04-03 10:34:14,250: ============================================================
2022-04-03 10:34:57,371: time cost, forward:0.011112725182677688, backward:0.05871275250097091, data cost:0.3458507156491429 
2022-04-03 10:34:57,371: ============================================================
2022-04-03 10:34:57,371: Epoch 2/26 Batch 800/7662 eta: 22:50:55.028581	Training Loss 6.8958 (6.8740)	Training Prec@1 93.945 (93.631)	Training Prec@5 97.070 (96.639)	
2022-04-03 10:34:57,372: ============================================================
2022-04-03 10:35:40,761: time cost, forward:0.010999380415087944, backward:0.058857111564865366, data cost:0.3478119063032615 
2022-04-03 10:35:40,761: ============================================================
2022-04-03 10:35:40,761: Epoch 2/26 Batch 900/7662 eta: 22:58:42.733188	Training Loss 6.9538 (6.8812)	Training Prec@1 93.359 (93.604)	Training Prec@5 95.508 (96.626)	
2022-04-03 10:35:40,761: ============================================================
2022-04-03 10:36:23,924: time cost, forward:0.01089822088514601, backward:0.05899219326786809, data cost:0.3491161652394124 
2022-04-03 10:36:23,924: ============================================================
2022-04-03 10:36:23,924: Epoch 2/26 Batch 1000/7662 eta: 22:50:48.291118	Training Loss 7.1113 (6.8852)	Training Prec@1 92.969 (93.609)	Training Prec@5 95.898 (96.633)	
2022-04-03 10:36:23,925: ============================================================
2022-04-03 10:37:06,825: time cost, forward:0.010823828182619632, backward:0.059105124443199986, data cost:0.34996884448404636 
2022-04-03 10:37:06,826: ============================================================
2022-04-03 10:37:06,826: Epoch 2/26 Batch 1100/7662 eta: 22:41:46.078736	Training Loss 6.9012 (6.8899)	Training Prec@1 94.336 (93.590)	Training Prec@5 96.875 (96.624)	
2022-04-03 10:37:06,826: ============================================================
2022-04-03 10:37:50,331: time cost, forward:0.010802070134077796, backward:0.059143643462727526, data cost:0.35113008982743493 
2022-04-03 10:37:50,331: ============================================================
2022-04-03 10:37:50,331: Epoch 2/26 Batch 1200/7662 eta: 23:00:12.805003	Training Loss 6.7306 (6.8885)	Training Prec@1 93.750 (93.584)	Training Prec@5 97.070 (96.623)	
2022-04-03 10:37:50,331: ============================================================
2022-04-03 10:38:31,076: time cost, forward:0.010778542937821291, backward:0.059202893685156605, data cost:0.350034531122726 
2022-04-03 10:38:31,077: ============================================================
2022-04-03 10:38:31,077: Epoch 2/26 Batch 1300/7662 eta: 21:31:58.919592	Training Loss 6.9104 (6.8886)	Training Prec@1 92.188 (93.565)	Training Prec@5 96.289 (96.607)	
2022-04-03 10:38:31,077: ============================================================
2022-04-03 10:39:12,465: time cost, forward:0.010763546839367073, backward:0.05923686664900327, data cost:0.3494969453872997 
2022-04-03 10:39:12,466: ============================================================
2022-04-03 10:39:12,466: Epoch 2/26 Batch 1400/7662 eta: 21:51:41.860673	Training Loss 6.9471 (6.8887)	Training Prec@1 94.141 (93.544)	Training Prec@5 97.266 (96.592)	
2022-04-03 10:39:12,466: ============================================================
2022-04-03 10:39:54,932: time cost, forward:0.010729090701428311, backward:0.059285205550954054, data cost:0.34982288114383586 
2022-04-03 10:39:54,932: ============================================================
2022-04-03 10:39:54,932: Epoch 2/26 Batch 1500/7662 eta: 22:25:07.986702	Training Loss 7.1289 (6.8854)	Training Prec@1 90.430 (93.550)	Training Prec@5 94.727 (96.584)	
2022-04-03 10:39:54,933: ============================================================
2022-04-03 10:40:38,043: time cost, forward:0.010703783619769145, backward:0.05932896923019858, data cost:0.35047579199317996 
2022-04-03 10:40:38,044: ============================================================
2022-04-03 10:40:38,044: Epoch 2/26 Batch 1600/7662 eta: 22:44:50.844066	Training Loss 6.8057 (6.8838)	Training Prec@1 93.164 (93.542)	Training Prec@5 96.094 (96.577)	
2022-04-03 10:40:38,044: ============================================================
2022-04-03 10:41:20,083: time cost, forward:0.010699583825958413, backward:0.05934779892394373, data cost:0.3504048172623498 
2022-04-03 10:41:20,084: ============================================================
2022-04-03 10:41:20,084: Epoch 2/26 Batch 1700/7662 eta: 22:10:13.499288	Training Loss 6.3847 (6.8786)	Training Prec@1 94.336 (93.544)	Training Prec@5 97.461 (96.584)	
2022-04-03 10:41:20,084: ============================================================
2022-04-03 10:42:01,335: time cost, forward:0.010700567355747021, backward:0.059366422603367566, data cost:0.34994513806930977 
2022-04-03 10:42:01,336: ============================================================
2022-04-03 10:42:01,336: Epoch 2/26 Batch 1800/7662 eta: 21:44:35.911690	Training Loss 6.8848 (6.8752)	Training Prec@1 91.016 (93.548)	Training Prec@5 94.922 (96.585)	
2022-04-03 10:42:01,336: ============================================================
2022-04-03 10:42:43,827: time cost, forward:0.010740617502984905, backward:0.05932153457713918, data cost:0.35013730178198227 
2022-04-03 10:42:43,827: ============================================================
2022-04-03 10:42:43,827: Epoch 2/26 Batch 1900/7662 eta: 22:23:05.529156	Training Loss 6.9440 (6.8711)	Training Prec@1 92.969 (93.557)	Training Prec@5 97.070 (96.593)	
2022-04-03 10:42:43,828: ============================================================
2022-04-03 10:43:26,428: time cost, forward:0.010739068856174913, backward:0.05934372766427006, data cost:0.35039666976375305 
2022-04-03 10:43:26,429: ============================================================
2022-04-03 10:43:26,429: Epoch 2/26 Batch 2000/7662 eta: 22:25:51.050520	Training Loss 6.9031 (6.8666)	Training Prec@1 93.555 (93.563)	Training Prec@5 97.266 (96.598)	
2022-04-03 10:43:26,429: ============================================================
2022-04-03 10:44:07,257: time cost, forward:0.010726213568786941, backward:0.05937185453312235, data cost:0.34981037833226075 
2022-04-03 10:44:07,258: ============================================================
2022-04-03 10:44:07,258: Epoch 2/26 Batch 2100/7662 eta: 21:29:11.526490	Training Loss 6.7299 (6.8618)	Training Prec@1 93.164 (93.568)	Training Prec@5 96.094 (96.597)	
2022-04-03 10:44:07,258: ============================================================
2022-04-03 10:44:48,463: time cost, forward:0.010745969996120562, backward:0.05935332871610981, data cost:0.34938981848556705 
2022-04-03 10:44:48,463: ============================================================
2022-04-03 10:44:48,464: Epoch 2/26 Batch 2200/7662 eta: 21:40:23.117284	Training Loss 6.7177 (6.8547)	Training Prec@1 94.141 (93.580)	Training Prec@5 97.461 (96.605)	
2022-04-03 10:44:48,464: ============================================================
2022-04-03 10:45:30,143: time cost, forward:0.010741124209138092, backward:0.05936778250234238, data cost:0.34925660023019334 
2022-04-03 10:45:30,143: ============================================================
2022-04-03 10:45:30,143: Epoch 2/26 Batch 2300/7662 eta: 21:54:39.597187	Training Loss 6.5977 (6.8490)	Training Prec@1 92.969 (93.585)	Training Prec@5 96.289 (96.610)	
2022-04-03 10:45:30,144: ============================================================
2022-04-03 10:46:10,493: time cost, forward:0.010747334717611016, backward:0.059362183614987636, data cost:0.3485598552222051 
2022-04-03 10:46:10,494: ============================================================
2022-04-03 10:46:10,494: Epoch 2/26 Batch 2400/7662 eta: 21:12:03.141756	Training Loss 6.6030 (6.8440)	Training Prec@1 93.750 (93.592)	Training Prec@5 95.508 (96.613)	
2022-04-03 10:46:10,494: ============================================================
2022-04-03 10:46:53,379: time cost, forward:0.010745841629651129, backward:0.05936224129544396, data cost:0.34891131612099185 
2022-04-03 10:46:53,379: ============================================================
2022-04-03 10:46:53,380: Epoch 2/26 Batch 2500/7662 eta: 22:31:15.829809	Training Loss 6.8784 (6.8387)	Training Prec@1 95.508 (93.604)	Training Prec@5 97.461 (96.617)	
2022-04-03 10:46:53,380: ============================================================
2022-04-03 10:47:34,950: time cost, forward:0.010750160349383177, backward:0.05936582549896181, data cost:0.3487881242701438 
2022-04-03 10:47:34,951: ============================================================
2022-04-03 10:47:34,951: Epoch 2/26 Batch 2600/7662 eta: 21:49:09.534881	Training Loss 6.6986 (6.8322)	Training Prec@1 94.727 (93.621)	Training Prec@5 96.875 (96.626)	
2022-04-03 10:47:34,951: ============================================================
2022-04-03 10:48:16,152: time cost, forward:0.010730958594441987, backward:0.05939265276247062, data cost:0.34849110167306546 
2022-04-03 10:48:16,153: ============================================================
2022-04-03 10:48:16,153: Epoch 2/26 Batch 2700/7662 eta: 21:36:50.415852	Training Loss 6.4682 (6.8266)	Training Prec@1 94.922 (93.625)	Training Prec@5 98.633 (96.633)	
2022-04-03 10:48:16,153: ============================================================
2022-04-03 10:48:56,839: time cost, forward:0.01072979995547639, backward:0.0593856506238626, data cost:0.34810228993442066 
2022-04-03 10:48:56,839: ============================================================
2022-04-03 10:48:56,840: Epoch 2/26 Batch 2800/7662 eta: 21:19:56.325608	Training Loss 6.6564 (6.8201)	Training Prec@1 94.141 (93.638)	Training Prec@5 96.875 (96.642)	
2022-04-03 10:48:56,840: ============================================================
2022-04-03 10:49:38,847: time cost, forward:0.010725679871294982, backward:0.05938849263291558, data cost:0.34813898454332565 
2022-04-03 10:49:38,848: ============================================================
2022-04-03 10:49:38,848: Epoch 2/26 Batch 2900/7662 eta: 22:00:49.397051	Training Loss 6.3536 (6.8145)	Training Prec@1 94.141 (93.646)	Training Prec@5 96.680 (96.649)	
2022-04-03 10:49:38,848: ============================================================
2022-04-03 10:50:20,539: time cost, forward:0.010731683647127777, backward:0.05938026920164693, data cost:0.3480469511126868 
2022-04-03 10:50:20,539: ============================================================
2022-04-03 10:50:20,539: Epoch 2/26 Batch 3000/7662 eta: 21:50:09.555756	Training Loss 6.6879 (6.8077)	Training Prec@1 92.773 (93.662)	Training Prec@5 96.094 (96.659)	
2022-04-03 10:50:20,540: ============================================================
2022-04-03 10:51:03,785: time cost, forward:0.010747108739512548, backward:0.059358147891654854, data cost:0.3485100204693036 
2022-04-03 10:51:03,786: ============================================================
2022-04-03 10:51:03,786: Epoch 2/26 Batch 3100/7662 eta: 22:38:18.848144	Training Loss 6.5175 (6.8016)	Training Prec@1 95.117 (93.677)	Training Prec@5 98.047 (96.666)	
2022-04-03 10:51:03,786: ============================================================
2022-04-03 10:51:46,992: time cost, forward:0.010753938353557294, backward:0.059345261683200215, data cost:0.34892031154471587 
2022-04-03 10:51:46,993: ============================================================
2022-04-03 10:51:46,993: Epoch 2/26 Batch 3200/7662 eta: 22:36:20.599705	Training Loss 6.7014 (6.7948)	Training Prec@1 93.164 (93.688)	Training Prec@5 95.898 (96.670)	
2022-04-03 10:51:46,993: ============================================================
2022-04-03 10:52:28,571: time cost, forward:0.010798563195489037, backward:0.05930651683234995, data cost:0.34880416745234705 
2022-04-03 10:52:28,571: ============================================================
2022-04-03 10:52:28,572: Epoch 2/26 Batch 3300/7662 eta: 21:44:32.232037	Training Loss 6.4685 (6.7885)	Training Prec@1 94.336 (93.696)	Training Prec@5 97.461 (96.679)	
2022-04-03 10:52:28,572: ============================================================
2022-04-03 10:53:09,201: time cost, forward:0.010806207482903871, backward:0.05930073445739028, data cost:0.34842254183298704 
2022-04-03 10:53:09,202: ============================================================
2022-04-03 10:53:09,202: Epoch 2/26 Batch 3400/7662 eta: 21:14:06.339613	Training Loss 6.5935 (6.7824)	Training Prec@1 94.141 (93.711)	Training Prec@5 96.680 (96.688)	
2022-04-03 10:53:09,202: ============================================================
2022-04-03 10:53:50,603: time cost, forward:0.010791925744827763, backward:0.059309620487925055, data cost:0.3482719524549259 
2022-04-03 10:53:50,604: ============================================================
2022-04-03 10:53:50,605: Epoch 2/26 Batch 3500/7662 eta: 21:37:37.714235	Training Loss 6.3375 (6.7754)	Training Prec@1 93.359 (93.726)	Training Prec@5 97.070 (96.698)	
2022-04-03 10:53:50,605: ============================================================
2022-04-03 10:54:32,388: time cost, forward:0.010803415961449727, backward:0.059302472048052224, data cost:0.3482444709657 
2022-04-03 10:54:32,388: ============================================================
2022-04-03 10:54:32,388: Epoch 2/26 Batch 3600/7662 eta: 21:48:53.238663	Training Loss 6.5545 (6.7687)	Training Prec@1 94.141 (93.740)	Training Prec@5 96.875 (96.707)	
2022-04-03 10:54:32,389: ============================================================
2022-04-03 10:55:14,594: time cost, forward:0.010801980546372231, backward:0.05930083395500833, data cost:0.3483255157666646 
2022-04-03 10:55:14,595: ============================================================
2022-04-03 10:55:14,595: Epoch 2/26 Batch 3700/7662 eta: 22:01:25.631594	Training Loss 6.8862 (6.7622)	Training Prec@1 93.555 (93.754)	Training Prec@5 97.461 (96.715)	
2022-04-03 10:55:14,595: ============================================================
2022-04-03 10:55:57,176: time cost, forward:0.010816840693711544, backward:0.05928406479422059, data cost:0.3485131379208084 
2022-04-03 10:55:57,176: ============================================================
2022-04-03 10:55:57,176: Epoch 2/26 Batch 3800/7662 eta: 22:12:26.613823	Training Loss 6.4546 (6.7557)	Training Prec@1 93.945 (93.769)	Training Prec@5 97.461 (96.726)	
2022-04-03 10:55:57,176: ============================================================
2022-04-03 10:56:40,010: time cost, forward:0.010814153221699787, backward:0.05929531339316162, data cost:0.34873740732379377 
2022-04-03 10:56:40,011: ============================================================
2022-04-03 10:56:40,011: Epoch 2/26 Batch 3900/7662 eta: 22:19:40.462062	Training Loss 6.3431 (6.7492)	Training Prec@1 95.898 (93.786)	Training Prec@5 97.461 (96.738)	
2022-04-03 10:56:40,011: ============================================================
2022-04-03 10:57:22,598: time cost, forward:0.010924467536084918, backward:0.05917882466202946, data cost:0.3488987334581219 
2022-04-03 10:57:22,599: ============================================================
2022-04-03 10:57:22,599: Epoch 2/26 Batch 4000/7662 eta: 22:11:13.571614	Training Loss 6.8620 (6.7432)	Training Prec@1 92.773 (93.797)	Training Prec@5 95.117 (96.744)	
2022-04-03 10:57:22,599: ============================================================
2022-04-03 10:58:04,753: time cost, forward:0.010918694317239063, backward:0.05918534274914405, data cost:0.3489432538477611 
2022-04-03 10:58:04,753: ============================================================
2022-04-03 10:58:04,753: Epoch 2/26 Batch 4100/7662 eta: 21:56:58.824439	Training Loss 6.4185 (6.7365)	Training Prec@1 93.945 (93.809)	Training Prec@5 96.094 (96.752)	
2022-04-03 10:58:04,754: ============================================================
2022-04-03 10:58:46,915: time cost, forward:0.010914213801032165, backward:0.059182127648008585, data cost:0.3489805182606642 
2022-04-03 10:58:46,915: ============================================================
2022-04-03 10:58:46,915: Epoch 2/26 Batch 4200/7662 eta: 21:56:30.787358	Training Loss 6.1726 (6.7303)	Training Prec@1 94.531 (93.820)	Training Prec@5 97.070 (96.759)	
2022-04-03 10:58:46,915: ============================================================
2022-04-03 10:59:30,852: time cost, forward:0.0109129386270953, backward:0.05918378651377822, data cost:0.3494670387200628 
2022-04-03 10:59:30,852: ============================================================
2022-04-03 10:59:30,853: Epoch 2/26 Batch 4300/7662 eta: 22:51:13.365713	Training Loss 6.3587 (6.7238)	Training Prec@1 95.898 (93.833)	Training Prec@5 97.852 (96.765)	
2022-04-03 10:59:30,853: ============================================================
2022-04-03 11:00:12,838: time cost, forward:0.010905046846737074, backward:0.05919509092280203, data cost:0.3494637002184001 
2022-04-03 11:00:12,838: ============================================================
2022-04-03 11:00:12,839: Epoch 2/26 Batch 4400/7662 eta: 21:49:36.882091	Training Loss 6.3495 (6.7179)	Training Prec@1 94.922 (93.844)	Training Prec@5 97.070 (96.773)	
2022-04-03 11:00:12,839: ============================================================
2022-04-03 11:00:56,010: time cost, forward:0.010913828103429451, backward:0.05918777707047557, data cost:0.3497043508613181 
2022-04-03 11:00:56,010: ============================================================
2022-04-03 11:00:56,011: Epoch 2/26 Batch 4500/7662 eta: 22:25:53.685241	Training Loss 6.5362 (6.7116)	Training Prec@1 95.312 (93.859)	Training Prec@5 98.242 (96.786)	
2022-04-03 11:00:56,011: ============================================================
2022-04-03 11:01:38,992: time cost, forward:0.010915792151673199, backward:0.05918486856019712, data cost:0.3499119016859267 
2022-04-03 11:01:38,993: ============================================================
2022-04-03 11:01:38,993: Epoch 2/26 Batch 4600/7662 eta: 22:19:15.642743	Training Loss 6.5973 (6.7057)	Training Prec@1 93.164 (93.869)	Training Prec@5 96.094 (96.793)	
2022-04-03 11:01:38,993: ============================================================
2022-04-03 11:02:21,140: time cost, forward:0.010915497663960251, backward:0.059185183943776684, data cost:0.3499340529542295 
2022-04-03 11:02:21,140: ============================================================
2022-04-03 11:02:21,140: Epoch 2/26 Batch 4700/7662 eta: 21:52:32.963374	Training Loss 6.0065 (6.7002)	Training Prec@1 95.898 (93.880)	Training Prec@5 98.047 (96.800)	
2022-04-03 11:02:21,140: ============================================================
2022-04-03 11:03:02,980: time cost, forward:0.0109233696725523, backward:0.059172573673846846, data cost:0.34990534853950145 
2022-04-03 11:03:02,981: ============================================================
2022-04-03 11:03:02,981: Epoch 2/26 Batch 4800/7662 eta: 21:42:17.732253	Training Loss 6.2748 (6.6944)	Training Prec@1 95.703 (93.889)	Training Prec@5 97.266 (96.806)	
2022-04-03 11:03:02,981: ============================================================
2022-04-03 11:03:44,497: time cost, forward:0.010921721800075888, backward:0.05916717194080061, data cost:0.3497866021538053 
2022-04-03 11:03:44,497: ============================================================
2022-04-03 11:03:44,498: Epoch 2/26 Batch 4900/7662 eta: 21:31:31.305066	Training Loss 6.2270 (6.6881)	Training Prec@1 94.531 (93.904)	Training Prec@5 97.461 (96.817)	
2022-04-03 11:03:44,498: ============================================================
2022-04-03 11:04:26,746: time cost, forward:0.010948322181297222, backward:0.059134658323952996, data cost:0.34983327613398657 
2022-04-03 11:04:26,747: ============================================================
2022-04-03 11:04:26,747: Epoch 2/26 Batch 5000/7662 eta: 21:53:36.447171	Training Loss 6.3823 (6.6821)	Training Prec@1 95.703 (93.917)	Training Prec@5 97.266 (96.825)	
2022-04-03 11:04:26,747: ============================================================
2022-04-03 11:05:07,186: time cost, forward:0.010941944395380643, backward:0.05914360697443847, data cost:0.3495097709744789 
2022-04-03 11:05:07,187: ============================================================
2022-04-03 11:05:07,187: Epoch 2/26 Batch 5100/7662 eta: 20:56:40.968988	Training Loss 6.4274 (6.6760)	Training Prec@1 95.117 (93.932)	Training Prec@5 97.070 (96.836)	
2022-04-03 11:05:07,187: ============================================================
2022-04-03 11:05:50,485: time cost, forward:0.01093585570515704, backward:0.059145587617375574, data cost:0.3497679846221196 
2022-04-03 11:05:50,486: ============================================================
2022-04-03 11:05:50,486: Epoch 2/26 Batch 5200/7662 eta: 22:24:47.994245	Training Loss 6.1837 (6.6703)	Training Prec@1 95.898 (93.943)	Training Prec@5 97.852 (96.842)	
2022-04-03 11:05:50,486: ============================================================
2022-04-03 11:06:33,694: time cost, forward:0.010923394033831905, backward:0.05915728193968056, data cost:0.34998249287739364 
2022-04-03 11:06:33,694: ============================================================
2022-04-03 11:06:33,694: Epoch 2/26 Batch 5300/7662 eta: 22:21:15.879499	Training Loss 6.3617 (6.6646)	Training Prec@1 94.727 (93.953)	Training Prec@5 96.680 (96.848)	
2022-04-03 11:06:33,694: ============================================================
2022-04-03 11:07:16,984: time cost, forward:0.010918527118451817, backward:0.059165660927396814, data cost:0.3502187044405456 
2022-04-03 11:07:16,984: ============================================================
2022-04-03 11:07:16,984: Epoch 2/26 Batch 5400/7662 eta: 22:23:05.316389	Training Loss 6.2446 (6.6585)	Training Prec@1 94.922 (93.966)	Training Prec@5 97.266 (96.856)	
2022-04-03 11:07:16,985: ============================================================
2022-04-03 11:08:00,632: time cost, forward:0.01091479409670999, backward:0.05916918613928451, data cost:0.35049470161650265 
2022-04-03 11:08:00,633: ============================================================
2022-04-03 11:08:00,633: Epoch 2/26 Batch 5500/7662 eta: 22:33:28.447161	Training Loss 6.1684 (6.6527)	Training Prec@1 95.508 (93.980)	Training Prec@5 98.047 (96.863)	
2022-04-03 11:08:00,633: ============================================================
2022-04-03 11:08:42,655: time cost, forward:0.010916303962357323, backward:0.05916820319343154, data cost:0.3504732104364645 
2022-04-03 11:08:42,655: ============================================================
2022-04-03 11:08:42,656: Epoch 2/26 Batch 5600/7662 eta: 21:42:21.566282	Training Loss 6.0918 (6.6469)	Training Prec@1 94.922 (93.992)	Training Prec@5 97.070 (96.871)	
2022-04-03 11:08:42,656: ============================================================
2022-04-03 11:09:24,889: time cost, forward:0.010914160967249686, backward:0.05917057612001279, data cost:0.35046958973542036 
2022-04-03 11:09:24,889: ============================================================
2022-04-03 11:09:24,889: Epoch 2/26 Batch 5700/7662 eta: 21:48:11.712204	Training Loss 6.1838 (6.6410)	Training Prec@1 94.922 (94.007)	Training Prec@5 97.852 (96.880)	
2022-04-03 11:09:24,890: ============================================================
2022-04-03 11:10:05,819: time cost, forward:0.010940603684466303, backward:0.059140895929680255, data cost:0.35031208327606356 
2022-04-03 11:10:05,820: ============================================================
2022-04-03 11:10:05,820: Epoch 2/26 Batch 5800/7662 eta: 21:07:09.450394	Training Loss 6.1823 (6.6353)	Training Prec@1 95.117 (94.015)	Training Prec@5 97.656 (96.886)	
2022-04-03 11:10:05,820: ============================================================
2022-04-03 11:10:47,019: time cost, forward:0.010929198967519302, backward:0.05914272233821069, data cost:0.35015440569184236 
2022-04-03 11:10:47,019: ============================================================
2022-04-03 11:10:47,020: Epoch 2/26 Batch 5900/7662 eta: 21:14:47.546821	Training Loss 6.5081 (6.6296)	Training Prec@1 94.141 (94.026)	Training Prec@5 97.266 (96.892)	
2022-04-03 11:10:47,020: ============================================================
2022-04-03 11:11:30,641: time cost, forward:0.010950526071997717, backward:0.05911729112826381, data cost:0.3504142456401247 
2022-04-03 11:11:30,642: ============================================================
2022-04-03 11:11:30,642: Epoch 2/26 Batch 6000/7662 eta: 22:29:01.517707	Training Loss 6.1414 (6.6236)	Training Prec@1 95.703 (94.040)	Training Prec@5 97.461 (96.900)	
2022-04-03 11:11:30,642: ============================================================
2022-04-03 11:12:14,262: time cost, forward:0.010946712253093328, backward:0.0591155514011111, data cost:0.3506752531496027 
2022-04-03 11:12:14,263: ============================================================
2022-04-03 11:12:14,263: Epoch 2/26 Batch 6100/7662 eta: 22:28:15.004685	Training Loss 6.3968 (6.6180)	Training Prec@1 93.945 (94.051)	Training Prec@5 97.852 (96.907)	
2022-04-03 11:12:14,263: ============================================================
2022-04-03 11:12:56,602: time cost, forward:0.01093538993211461, backward:0.059117142472234076, data cost:0.35071960932440405 
2022-04-03 11:12:56,603: ============================================================
2022-04-03 11:12:56,603: Epoch 2/26 Batch 6200/7662 eta: 21:47:57.782051	Training Loss 6.4141 (6.6123)	Training Prec@1 94.922 (94.063)	Training Prec@5 98.242 (96.914)	
2022-04-03 11:12:56,603: ============================================================
2022-04-03 11:13:39,201: time cost, forward:0.01092750327059874, backward:0.059121574593226214, data cost:0.3507970548618557 
2022-04-03 11:13:39,202: ============================================================
2022-04-03 11:13:39,202: Epoch 2/26 Batch 6300/7662 eta: 21:55:15.256742	Training Loss 6.3241 (6.6068)	Training Prec@1 93.359 (94.077)	Training Prec@5 96.875 (96.923)	
2022-04-03 11:13:39,202: ============================================================
2022-04-03 11:14:22,837: time cost, forward:0.010914524861994637, backward:0.05913073324676528, data cost:0.3510247244464548 
2022-04-03 11:14:22,837: ============================================================
2022-04-03 11:14:22,837: Epoch 2/26 Batch 6400/7662 eta: 22:26:31.467846	Training Loss 6.3604 (6.6013)	Training Prec@1 94.531 (94.086)	Training Prec@5 97.266 (96.929)	
2022-04-03 11:14:22,838: ============================================================
2022-04-03 11:15:04,450: time cost, forward:0.010911156019993536, backward:0.05912968359978167, data cost:0.35095167644281794 
2022-04-03 11:15:04,450: ============================================================
2022-04-03 11:15:04,450: Epoch 2/26 Batch 6500/7662 eta: 21:23:25.354096	Training Loss 6.2820 (6.5958)	Training Prec@1 94.336 (94.096)	Training Prec@5 96.680 (96.935)	
2022-04-03 11:15:04,451: ============================================================
2022-04-03 11:15:48,394: time cost, forward:0.010908827454343965, backward:0.05912342998616207, data cost:0.3512303298089446 
2022-04-03 11:15:48,395: ============================================================
2022-04-03 11:15:48,395: Epoch 2/26 Batch 6600/7662 eta: 22:34:35.584448	Training Loss 6.0491 (6.5903)	Training Prec@1 95.508 (94.109)	Training Prec@5 97.266 (96.943)	
2022-04-03 11:15:48,395: ============================================================
2022-04-03 11:16:32,123: time cost, forward:0.010902437492526633, backward:0.059125241423244, data cost:0.35147027037609585 
2022-04-03 11:16:32,123: ============================================================
2022-04-03 11:16:32,123: Epoch 2/26 Batch 6700/7662 eta: 22:27:12.773824	Training Loss 6.5075 (6.5853)	Training Prec@1 93.555 (94.121)	Training Prec@5 97.070 (96.951)	
2022-04-03 11:16:32,124: ============================================================
2022-04-03 11:17:15,923: time cost, forward:0.010894794992917355, backward:0.05912879264114499, data cost:0.3517076431574024 
2022-04-03 11:17:15,924: ============================================================
2022-04-03 11:17:15,924: Epoch 2/26 Batch 6800/7662 eta: 22:28:41.919743	Training Loss 6.1439 (6.5800)	Training Prec@1 95.508 (94.134)	Training Prec@5 97.461 (96.959)	
2022-04-03 11:17:15,924: ============================================================
2022-04-03 11:17:59,827: time cost, forward:0.010889390634961674, backward:0.059126999641193966, data cost:0.3519542189607898 
2022-04-03 11:17:59,828: ============================================================
2022-04-03 11:17:59,828: Epoch 2/26 Batch 6900/7662 eta: 22:31:09.254805	Training Loss 6.3312 (6.5745)	Training Prec@1 93.555 (94.145)	Training Prec@5 97.461 (96.965)	
2022-04-03 11:17:59,828: ============================================================
2022-04-03 11:18:43,100: time cost, forward:0.010878894172032947, backward:0.059133410096117424, data cost:0.35210608165423213 
2022-04-03 11:18:43,100: ============================================================
2022-04-03 11:18:43,100: Epoch 2/26 Batch 7000/7662 eta: 22:10:59.625184	Training Loss 6.2427 (6.5689)	Training Prec@1 94.531 (94.159)	Training Prec@5 96.680 (96.973)	
2022-04-03 11:18:43,101: ============================================================
2022-04-03 11:19:26,761: time cost, forward:0.010870291559036927, backward:0.05913640939277534, data cost:0.3523104410135237 
2022-04-03 11:19:26,761: ============================================================
2022-04-03 11:19:26,762: Epoch 2/26 Batch 7100/7662 eta: 22:22:13.527134	Training Loss 6.4141 (6.5634)	Training Prec@1 93.555 (94.172)	Training Prec@5 96.289 (96.982)	
2022-04-03 11:19:26,762: ============================================================
2022-04-03 11:20:10,067: time cost, forward:0.010861115880203935, backward:0.05914426674560004, data cost:0.3524541798557303 
2022-04-03 11:20:10,068: ============================================================
2022-04-03 11:20:10,068: Epoch 2/26 Batch 7200/7662 eta: 22:10:35.418526	Training Loss 6.1382 (6.5580)	Training Prec@1 95.898 (94.183)	Training Prec@5 97.852 (96.988)	
2022-04-03 11:20:10,068: ============================================================
2022-04-03 11:20:53,225: time cost, forward:0.010868721260471137, backward:0.05913043949829093, data cost:0.35256091129748784 
2022-04-03 11:20:53,226: ============================================================
2022-04-03 11:20:53,226: Epoch 2/26 Batch 7300/7662 eta: 22:05:19.609295	Training Loss 6.1251 (6.5528)	Training Prec@1 93.945 (94.193)	Training Prec@5 96.484 (96.994)	
2022-04-03 11:20:53,226: ============================================================
2022-04-03 11:21:36,682: time cost, forward:0.010867818881892114, backward:0.05913027036285091, data cost:0.3527335457132223 
2022-04-03 11:21:36,682: ============================================================
2022-04-03 11:21:36,682: Epoch 2/26 Batch 7400/7662 eta: 22:13:44.997233	Training Loss 5.9710 (6.5473)	Training Prec@1 96.484 (94.206)	Training Prec@5 98.438 (97.001)	
2022-04-03 11:21:36,683: ============================================================
2022-04-03 11:22:20,450: time cost, forward:0.010866670199021735, backward:0.0591281066339546, data cost:0.35292823938770856 
2022-04-03 11:22:20,451: ============================================================
2022-04-03 11:22:20,451: Epoch 2/26 Batch 7500/7662 eta: 22:22:36.455128	Training Loss 6.1440 (6.5430)	Training Prec@1 95.508 (94.214)	Training Prec@5 97.852 (97.006)	
2022-04-03 11:22:20,451: ============================================================
2022-04-03 11:23:04,734: time cost, forward:0.010866460933200872, backward:0.05912881186799417, data cost:0.3531826784585962 
2022-04-03 11:23:04,735: ============================================================
2022-04-03 11:23:04,735: Epoch 2/26 Batch 7600/7662 eta: 22:37:41.257163	Training Loss 6.0455 (6.5382)	Training Prec@1 95.703 (94.225)	Training Prec@5 97.266 (97.013)	
2022-04-03 11:23:04,736: ============================================================
2022-04-03 11:23:33,279: Epoch: 2/26 eta: 22:37:13.358107	Training Loss 6.2170 (6.5354)	Training Prec@1 94.922 (94.229)	Training Prec@5 96.484 (97.015)
2022-04-03 11:23:33,280: ============================================================
2022-04-03 11:24:19,011: time cost, forward:0.010781483216719194, backward:0.0576688689414901, data cost:0.38425924320413607 
2022-04-03 11:24:19,011: ============================================================
2022-04-03 11:24:19,012: Epoch 3/26 Batch 100/7662 eta: 23:05:33.559322	Training Loss 5.7461 (5.7393)	Training Prec@1 96.484 (95.883)	Training Prec@5 98.438 (98.027)	
2022-04-03 11:24:19,012: ============================================================
2022-04-03 11:25:02,676: time cost, forward:0.010999726290678857, backward:0.05764073942174863, data cost:0.37570488153390547 
2022-04-03 11:25:02,676: ============================================================
2022-04-03 11:25:02,676: Epoch 3/26 Batch 200/7662 eta: 22:16:47.778131	Training Loss 6.1825 (5.7736)	Training Prec@1 95.703 (95.895)	Training Prec@5 97.852 (98.012)	
2022-04-03 11:25:02,677: ============================================================
2022-04-03 11:25:45,889: time cost, forward:0.011242194319249794, backward:0.05751682683376963, data cost:0.37120032390224494 
2022-04-03 11:25:45,890: ============================================================
2022-04-03 11:25:45,890: Epoch 3/26 Batch 300/7662 eta: 22:02:14.760705	Training Loss 5.7644 (5.8080)	Training Prec@1 95.898 (95.847)	Training Prec@5 98.047 (97.993)	
2022-04-03 11:25:45,890: ============================================================
2022-04-03 11:26:28,323: time cost, forward:0.01113451752148774, backward:0.05779322765226053, data cost:0.36714766796370196 
2022-04-03 11:26:28,324: ============================================================
2022-04-03 11:26:28,324: Epoch 3/26 Batch 400/7662 eta: 21:37:42.434930	Training Loss 5.8976 (5.8378)	Training Prec@1 95.703 (95.806)	Training Prec@5 97.656 (97.966)	
2022-04-03 11:26:28,324: ============================================================
2022-04-03 11:27:09,567: time cost, forward:0.011129462886191084, backward:0.05805785526971301, data cost:0.36195871968546467 
2022-04-03 11:27:09,568: ============================================================
2022-04-03 11:27:09,568: Epoch 3/26 Batch 500/7662 eta: 21:00:36.553330	Training Loss 5.8944 (5.8641)	Training Prec@1 94.922 (95.761)	Training Prec@5 96.680 (97.936)	
2022-04-03 11:27:09,568: ============================================================
2022-04-03 11:27:54,124: time cost, forward:0.011044352201866187, backward:0.058280729889272645, data cost:0.36395438804053304 
2022-04-03 11:27:54,124: ============================================================
2022-04-03 11:27:54,124: Epoch 3/26 Batch 600/7662 eta: 22:41:06.700430	Training Loss 5.9830 (5.8860)	Training Prec@1 96.680 (95.715)	Training Prec@5 98.438 (97.899)	
2022-04-03 11:27:54,124: ============================================================
2022-04-03 11:28:38,111: time cost, forward:0.011252121522873427, backward:0.05817429804494964, data cost:0.36486386809396815 
2022-04-03 11:28:38,111: ============================================================
2022-04-03 11:28:38,112: Epoch 3/26 Batch 700/7662 eta: 22:23:00.491458	Training Loss 6.0590 (5.9031)	Training Prec@1 95.898 (95.707)	Training Prec@5 98.438 (97.893)	
2022-04-03 11:28:38,112: ============================================================
2022-04-03 11:29:22,159: time cost, forward:0.011217466731542938, backward:0.05827130423917042, data cost:0.3655392395539934 
2022-04-03 11:29:22,159: ============================================================
2022-04-03 11:29:22,159: Epoch 3/26 Batch 800/7662 eta: 22:24:05.978667	Training Loss 5.6163 (5.9172)	Training Prec@1 96.875 (95.685)	Training Prec@5 98.633 (97.889)	
2022-04-03 11:29:22,159: ============================================================
2022-04-03 11:30:06,351: time cost, forward:0.011195332110259637, backward:0.05834606014714225, data cost:0.366115294786396 
2022-04-03 11:30:06,351: ============================================================
2022-04-03 11:30:06,352: Epoch 3/26 Batch 900/7662 eta: 22:27:47.239086	Training Loss 6.0583 (5.9307)	Training Prec@1 94.336 (95.644)	Training Prec@5 96.875 (97.872)	
2022-04-03 11:30:06,352: ============================================================
2022-04-03 11:30:50,885: time cost, forward:0.011160486333959692, backward:0.05837401088412937, data cost:0.367112603154149 
2022-04-03 11:30:50,885: ============================================================
2022-04-03 11:30:50,885: Epoch 3/26 Batch 1000/7662 eta: 22:37:27.535082	Training Loss 5.9203 (5.9428)	Training Prec@1 96.875 (95.610)	Training Prec@5 99.023 (97.860)	
2022-04-03 11:30:50,886: ============================================================
2022-04-03 11:31:34,017: time cost, forward:0.011106781139495266, backward:0.0583984315991944, data cost:0.36662305345092716 
2022-04-03 11:31:34,017: ============================================================
2022-04-03 11:31:34,018: Epoch 3/26 Batch 1100/7662 eta: 21:54:00.610258	Training Loss 6.1483 (5.9539)	Training Prec@1 95.312 (95.577)	Training Prec@5 98.633 (97.834)	
2022-04-03 11:31:34,018: ============================================================
2022-04-03 11:32:17,386: time cost, forward:0.011018382995898173, backward:0.0584757918611579, data cost:0.36635872639647316 
2022-04-03 11:32:17,387: ============================================================
2022-04-03 11:32:17,387: Epoch 3/26 Batch 1200/7662 eta: 22:00:30.871454	Training Loss 6.1424 (5.9614)	Training Prec@1 95.117 (95.554)	Training Prec@5 97.656 (97.823)	
2022-04-03 11:32:17,387: ============================================================
2022-04-03 11:33:01,113: time cost, forward:0.010994014784039857, backward:0.05847443187117485, data cost:0.3665112092735402 
2022-04-03 11:33:01,114: ============================================================
2022-04-03 11:33:01,114: Epoch 3/26 Batch 1300/7662 eta: 22:10:40.719452	Training Loss 6.1807 (5.9677)	Training Prec@1 94.727 (95.534)	Training Prec@5 96.875 (97.813)	
2022-04-03 11:33:01,114: ============================================================
2022-04-03 11:33:45,120: time cost, forward:0.011009392523612185, backward:0.058420307726583964, data cost:0.36674687434640246 
2022-04-03 11:33:45,121: ============================================================
2022-04-03 11:33:45,121: Epoch 3/26 Batch 1400/7662 eta: 22:18:28.645108	Training Loss 5.9122 (5.9730)	Training Prec@1 95.508 (95.511)	Training Prec@5 97.461 (97.801)	
2022-04-03 11:33:45,121: ============================================================
2022-04-03 11:34:28,119: time cost, forward:0.010999312473981677, backward:0.05841211766859466, data cost:0.3663275750817419 
2022-04-03 11:34:28,119: ============================================================
2022-04-03 11:34:28,119: Epoch 3/26 Batch 1500/7662 eta: 21:47:04.079076	Training Loss 6.0590 (5.9779)	Training Prec@1 94.727 (95.485)	Training Prec@5 96.680 (97.791)	
2022-04-03 11:34:28,120: ============================================================
2022-04-03 11:35:11,563: time cost, forward:0.010989007389195045, backward:0.05840427969454824, data cost:0.3662186226597274 
2022-04-03 11:35:11,563: ============================================================
2022-04-03 11:35:11,563: Epoch 3/26 Batch 1600/7662 eta: 21:59:53.335462	Training Loss 6.4530 (5.9808)	Training Prec@1 94.336 (95.478)	Training Prec@5 97.070 (97.787)	
2022-04-03 11:35:11,563: ============================================================
2022-04-03 11:35:54,760: time cost, forward:0.010949656849682085, backward:0.05842539799641412, data cost:0.36599381156638483 
2022-04-03 11:35:54,760: ============================================================
2022-04-03 11:35:54,761: Epoch 3/26 Batch 1700/7662 eta: 21:51:40.686251	Training Loss 6.0931 (5.9861)	Training Prec@1 93.945 (95.461)	Training Prec@5 97.070 (97.773)	
2022-04-03 11:35:54,761: ============================================================
2022-04-03 11:36:36,863: time cost, forward:0.01093764819324911, backward:0.058430103145088334, data cost:0.36518613188183263 
2022-04-03 11:36:36,864: ============================================================
2022-04-03 11:36:36,864: Epoch 3/26 Batch 1800/7662 eta: 21:17:46.177933	Training Loss 5.9286 (5.9886)	Training Prec@1 95.898 (95.449)	Training Prec@5 98.047 (97.765)	
2022-04-03 11:36:36,864: ============================================================
2022-04-03 11:37:18,817: time cost, forward:0.010906776043538862, backward:0.05846837786011096, data cost:0.3643314426606928 
2022-04-03 11:37:18,817: ============================================================
2022-04-03 11:37:18,817: Epoch 3/26 Batch 1900/7662 eta: 21:12:29.741594	Training Loss 5.7360 (5.9915)	Training Prec@1 97.266 (95.444)	Training Prec@5 98.633 (97.763)	
2022-04-03 11:37:18,817: ============================================================
2022-04-03 11:38:02,780: time cost, forward:0.010949456375679295, backward:0.058425824364284805, data cost:0.3646178238388298 
2022-04-03 11:38:02,780: ============================================================
2022-04-03 11:38:02,780: Epoch 3/26 Batch 2000/7662 eta: 22:12:44.297003	Training Loss 5.9891 (5.9958)	Training Prec@1 95.117 (95.426)	Training Prec@5 98.438 (97.749)	
2022-04-03 11:38:02,781: ============================================================
2022-04-03 11:38:45,943: time cost, forward:0.010931711528572712, backward:0.05843013385865392, data cost:0.36450226435268307 
2022-04-03 11:38:45,944: ============================================================
2022-04-03 11:38:45,944: Epoch 3/26 Batch 2100/7662 eta: 21:47:46.597864	Training Loss 6.0667 (5.9966)	Training Prec@1 94.727 (95.417)	Training Prec@5 97.461 (97.742)	
2022-04-03 11:38:45,944: ============================================================
2022-04-03 11:39:29,973: time cost, forward:0.010931832620153214, backward:0.05844327784386913, data cost:0.3647505598428196 
2022-04-03 11:39:29,974: ============================================================
2022-04-03 11:39:29,974: Epoch 3/26 Batch 2200/7662 eta: 22:13:18.009727	Training Loss 5.8486 (5.9981)	Training Prec@1 96.289 (95.405)	Training Prec@5 98.633 (97.734)	
2022-04-03 11:39:29,974: ============================================================
2022-04-03 11:40:13,815: time cost, forward:0.01094205849271279, backward:0.05845790616633219, data cost:0.3648789598922099 
2022-04-03 11:40:13,816: ============================================================
2022-04-03 11:40:13,816: Epoch 3/26 Batch 2300/7662 eta: 22:06:51.764066	Training Loss 6.1084 (5.9973)	Training Prec@1 94.922 (95.408)	Training Prec@5 97.852 (97.735)	
2022-04-03 11:40:13,816: ============================================================
2022-04-03 11:40:57,329: time cost, forward:0.010933071138859789, backward:0.058481077990863856, data cost:0.3648554588069812 
2022-04-03 11:40:57,329: ============================================================
2022-04-03 11:40:57,330: Epoch 3/26 Batch 2400/7662 eta: 21:56:12.833005	Training Loss 5.8989 (5.9969)	Training Prec@1 96.094 (95.401)	Training Prec@5 98.047 (97.730)	
2022-04-03 11:40:57,330: ============================================================
2022-04-03 11:41:40,912: time cost, forward:0.010926930319552138, backward:0.05850533076695034, data cost:0.36490009745963814 
2022-04-03 11:41:40,912: ============================================================
2022-04-03 11:41:40,913: Epoch 3/26 Batch 2500/7662 eta: 21:57:34.640625	Training Loss 6.0849 (5.9979)	Training Prec@1 94.336 (95.389)	Training Prec@5 96.875 (97.722)	
2022-04-03 11:41:40,913: ============================================================
2022-04-03 11:42:23,570: time cost, forward:0.01092311821336148, backward:0.05852713085862938, data cost:0.3645617859140641 
2022-04-03 11:42:23,570: ============================================================
2022-04-03 11:42:23,570: Epoch 3/26 Batch 2600/7662 eta: 21:28:53.629691	Training Loss 6.2268 (5.9972)	Training Prec@1 94.141 (95.386)	Training Prec@5 97.461 (97.719)	
2022-04-03 11:42:23,571: ============================================================
2022-04-03 11:43:06,024: time cost, forward:0.010917752263456771, backward:0.05855179283520874, data cost:0.364181466259838 
2022-04-03 11:43:06,025: ============================================================
2022-04-03 11:43:06,025: Epoch 3/26 Batch 2700/7662 eta: 21:22:02.660163	Training Loss 6.0941 (5.9985)	Training Prec@1 95.117 (95.379)	Training Prec@5 97.461 (97.713)	
2022-04-03 11:43:06,025: ============================================================
2022-04-03 11:43:49,826: time cost, forward:0.010925634029125391, backward:0.058551236023516175, data cost:0.364292582855688 
2022-04-03 11:43:49,826: ============================================================
2022-04-03 11:43:49,826: Epoch 3/26 Batch 2800/7662 eta: 22:01:59.720503	Training Loss 6.0183 (5.9984)	Training Prec@1 94.531 (95.371)	Training Prec@5 96.680 (97.711)	
2022-04-03 11:43:49,826: ============================================================
2022-04-03 11:44:32,024: time cost, forward:0.010922947601023605, backward:0.05856568001598767, data cost:0.3638714049017894 
2022-04-03 11:44:32,025: ============================================================
2022-04-03 11:44:32,025: Epoch 3/26 Batch 2900/7662 eta: 21:12:55.118111	Training Loss 5.8932 (5.9996)	Training Prec@1 96.484 (95.362)	Training Prec@5 97.461 (97.706)	
2022-04-03 11:44:32,025: ============================================================
2022-04-03 11:45:14,600: time cost, forward:0.010917698633436284, backward:0.05858268345066133, data cost:0.3635806492782903 
2022-04-03 11:45:14,600: ============================================================
2022-04-03 11:45:14,600: Epoch 3/26 Batch 3000/7662 eta: 21:23:34.184461	Training Loss 5.6700 (5.9989)	Training Prec@1 96.484 (95.358)	Training Prec@5 97.852 (97.707)	
2022-04-03 11:45:14,601: ============================================================
2022-04-03 11:45:56,999: time cost, forward:0.01092404032876777, backward:0.05857340402470823, data cost:0.3632802174682962 
2022-04-03 11:45:56,999: ============================================================
2022-04-03 11:45:56,999: Epoch 3/26 Batch 3100/7662 eta: 21:17:32.526689	Training Loss 6.0044 (5.9971)	Training Prec@1 94.922 (95.362)	Training Prec@5 97.656 (97.711)	
2022-04-03 11:45:56,999: ============================================================
2022-04-03 11:46:39,544: time cost, forward:0.010942118135829687, backward:0.05854895600083099, data cost:0.36301521101233436 
2022-04-03 11:46:39,544: ============================================================
2022-04-03 11:46:39,544: Epoch 3/26 Batch 3200/7662 eta: 21:21:14.162759	Training Loss 5.8544 (5.9958)	Training Prec@1 95.898 (95.358)	Training Prec@5 97.852 (97.707)	
2022-04-03 11:46:39,545: ============================================================
2022-04-03 11:47:19,973: time cost, forward:0.01093196030565015, backward:0.05855226516723633, data cost:0.3621456997435756 
2022-04-03 11:47:19,973: ============================================================
2022-04-03 11:47:19,973: Epoch 3/26 Batch 3300/7662 eta: 20:16:50.363659	Training Loss 5.6760 (5.9951)	Training Prec@1 96.484 (95.353)	Training Prec@5 98.438 (97.705)	
2022-04-03 11:47:19,974: ============================================================
2022-04-03 11:48:01,663: time cost, forward:0.01092478905610738, backward:0.058556937441891804, data cost:0.3617162867201255 
2022-04-03 11:48:01,663: ============================================================
2022-04-03 11:48:01,663: Epoch 3/26 Batch 3400/7662 eta: 20:54:05.613327	Training Loss 6.1569 (5.9947)	Training Prec@1 95.703 (95.347)	Training Prec@5 97.461 (97.699)	
2022-04-03 11:48:01,663: ============================================================
2022-04-03 11:48:44,993: time cost, forward:0.01091667944174148, backward:0.05854858143324851, data cost:0.36178061143777546 
2022-04-03 11:48:44,993: ============================================================
2022-04-03 11:48:44,993: Epoch 3/26 Batch 3500/7662 eta: 21:42:42.813761	Training Loss 5.9189 (5.9945)	Training Prec@1 94.141 (95.342)	Training Prec@5 96.680 (97.699)	
2022-04-03 11:48:44,994: ============================================================
2022-04-03 11:49:28,392: time cost, forward:0.010916760047961355, backward:0.058540828428721554, data cost:0.3618455915591491 
2022-04-03 11:49:28,393: ============================================================
2022-04-03 11:49:28,393: Epoch 3/26 Batch 3600/7662 eta: 21:44:04.661912	Training Loss 6.3641 (5.9938)	Training Prec@1 95.312 (95.340)	Training Prec@5 98.047 (97.700)	
2022-04-03 11:49:28,393: ============================================================
2022-04-03 11:50:11,779: time cost, forward:0.010916816830538389, backward:0.05853420168878452, data cost:0.3619088287384454 
2022-04-03 11:50:11,779: ============================================================
2022-04-03 11:50:11,780: Epoch 3/26 Batch 3700/7662 eta: 21:42:58.217515	Training Loss 5.9109 (5.9924)	Training Prec@1 95.703 (95.333)	Training Prec@5 97.656 (97.697)	
2022-04-03 11:50:11,780: ============================================================
2022-04-03 11:50:54,240: time cost, forward:0.01091538105678734, backward:0.0585244284958926, data cost:0.36172867323355035 
2022-04-03 11:50:54,240: ============================================================
2022-04-03 11:50:54,240: Epoch 3/26 Batch 3800/7662 eta: 21:14:26.556316	Training Loss 6.3945 (5.9917)	Training Prec@1 92.578 (95.328)	Training Prec@5 96.094 (97.693)	
2022-04-03 11:50:54,240: ============================================================
2022-04-03 11:51:35,438: time cost, forward:0.010904478580409303, backward:0.05853248376300867, data cost:0.36122423509782203 
2022-04-03 11:51:35,438: ============================================================
2022-04-03 11:51:35,438: Epoch 3/26 Batch 3900/7662 eta: 20:35:52.041076	Training Loss 6.1120 (5.9913)	Training Prec@1 94.727 (95.326)	Training Prec@5 97.070 (97.691)	
2022-04-03 11:51:35,438: ============================================================
2022-04-03 11:52:17,819: time cost, forward:0.010900126602924535, backward:0.0585440132253675, data cost:0.3610328002165603 
2022-04-03 11:52:17,820: ============================================================
2022-04-03 11:52:17,820: Epoch 3/26 Batch 4000/7662 eta: 21:10:39.739750	Training Loss 6.0004 (5.9908)	Training Prec@1 95.898 (95.326)	Training Prec@5 97.656 (97.691)	
2022-04-03 11:52:17,820: ============================================================
2022-04-03 11:52:59,891: time cost, forward:0.010903050882637749, backward:0.05854947975886453, data cost:0.36077411478977434 
2022-04-03 11:52:59,891: ============================================================
2022-04-03 11:52:59,892: Epoch 3/26 Batch 4100/7662 eta: 21:00:40.687959	Training Loss 5.6320 (5.9898)	Training Prec@1 94.727 (95.326)	Training Prec@5 97.852 (97.692)	
2022-04-03 11:52:59,892: ============================================================
2022-04-03 11:53:42,681: time cost, forward:0.011047762557136697, backward:0.05841483357804933, data cost:0.36069712845533625 
2022-04-03 11:53:42,681: ============================================================
2022-04-03 11:53:42,681: Epoch 3/26 Batch 4200/7662 eta: 21:21:28.134325	Training Loss 6.0300 (5.9885)	Training Prec@1 94.336 (95.330)	Training Prec@5 97.070 (97.695)	
2022-04-03 11:53:42,681: ============================================================
2022-04-03 11:54:24,659: time cost, forward:0.011041602524914667, backward:0.05843037576225087, data cost:0.36043429130674876 
2022-04-03 11:54:24,659: ============================================================
2022-04-03 11:54:24,660: Epoch 3/26 Batch 4300/7662 eta: 20:56:28.336139	Training Loss 5.6663 (5.9866)	Training Prec@1 96.680 (95.332)	Training Prec@5 99.219 (97.695)	
2022-04-03 11:54:24,660: ============================================================
2022-04-03 11:55:06,078: time cost, forward:0.011046099863314689, backward:0.05843494994772053, data cost:0.36005048872151413 
2022-04-03 11:55:06,079: ============================================================
2022-04-03 11:55:06,079: Epoch 3/26 Batch 4400/7662 eta: 20:39:03.065267	Training Loss 6.0070 (5.9844)	Training Prec@1 95.312 (95.335)	Training Prec@5 97.461 (97.696)	
2022-04-03 11:55:06,079: ============================================================
2022-04-03 11:55:47,873: time cost, forward:0.011041153057545232, backward:0.05844271127370549, data cost:0.35978077284148813 
2022-04-03 11:55:47,873: ============================================================
2022-04-03 11:55:47,874: Epoch 3/26 Batch 4500/7662 eta: 20:49:35.249043	Training Loss 5.7128 (5.9824)	Training Prec@1 96.875 (95.337)	Training Prec@5 99.023 (97.698)	
2022-04-03 11:55:47,874: ============================================================
2022-04-03 11:56:29,793: time cost, forward:0.011036520031229987, backward:0.05844384624948189, data cost:0.35954843621897836 
2022-04-03 11:56:29,794: ============================================================
2022-04-03 11:56:29,794: Epoch 3/26 Batch 4600/7662 eta: 20:52:38.100257	Training Loss 5.6773 (5.9807)	Training Prec@1 97.070 (95.338)	Training Prec@5 98.438 (97.700)	
2022-04-03 11:56:29,794: ============================================================
2022-04-03 11:57:12,834: time cost, forward:0.01102385548333661, backward:0.058452193598514876, data cost:0.35956437705957933 
2022-04-03 11:57:12,834: ============================================================
2022-04-03 11:57:12,834: Epoch 3/26 Batch 4700/7662 eta: 21:25:24.128076	Training Loss 5.7719 (5.9790)	Training Prec@1 96.484 (95.338)	Training Prec@5 98.438 (97.700)	
2022-04-03 11:57:12,835: ============================================================
2022-04-03 11:57:55,140: time cost, forward:0.01103964351718439, backward:0.058431310836512186, data cost:0.3594444547252969 
2022-04-03 11:57:55,140: ============================================================
2022-04-03 11:57:55,141: Epoch 3/26 Batch 4800/7662 eta: 21:02:45.716409	Training Loss 5.9277 (5.9779)	Training Prec@1 96.289 (95.337)	Training Prec@5 97.266 (97.700)	
2022-04-03 11:57:55,141: ============================================================
2022-04-03 11:58:38,024: time cost, forward:0.011032051056057708, backward:0.05843234290928713, data cost:0.35942997959687484 
2022-04-03 11:58:38,024: ============================================================
2022-04-03 11:58:38,025: Epoch 3/26 Batch 4900/7662 eta: 21:19:17.738036	Training Loss 5.8805 (5.9762)	Training Prec@1 95.117 (95.340)	Training Prec@5 97.852 (97.701)	
2022-04-03 11:58:38,025: ============================================================
2022-04-03 11:59:19,451: time cost, forward:0.01102376394353883, backward:0.05843735962158252, data cost:0.3591493539606054 
2022-04-03 11:59:19,451: ============================================================
2022-04-03 11:59:19,452: Epoch 3/26 Batch 5000/7662 eta: 20:35:08.256119	Training Loss 5.6302 (5.9749)	Training Prec@1 95.508 (95.338)	Training Prec@5 97.070 (97.700)	
2022-04-03 11:59:19,452: ============================================================
2022-04-03 12:00:01,485: time cost, forward:0.011016464065069965, backward:0.0584389814140049, data cost:0.35895919187276076 
2022-04-03 12:00:01,485: ============================================================
2022-04-03 12:00:01,485: Epoch 3/26 Batch 5100/7662 eta: 20:52:31.901700	Training Loss 5.7847 (5.9739)	Training Prec@1 96.484 (95.337)	Training Prec@5 98.242 (97.699)	
2022-04-03 12:00:01,486: ============================================================
2022-04-03 12:00:43,579: time cost, forward:0.01100657985494283, backward:0.05844027355419349, data cost:0.35882270251312814 
2022-04-03 12:00:43,580: ============================================================
2022-04-03 12:00:43,580: Epoch 3/26 Batch 5200/7662 eta: 20:53:38.246759	Training Loss 5.9677 (5.9719)	Training Prec@1 95.508 (95.338)	Training Prec@5 97.852 (97.699)	
2022-04-03 12:00:43,580: ============================================================
2022-04-03 12:01:27,361: time cost, forward:0.01099996189730058, backward:0.058446666973450204, data cost:0.3589958237530848 
2022-04-03 12:01:27,362: ============================================================
2022-04-03 12:01:27,362: Epoch 3/26 Batch 5300/7662 eta: 21:43:10.272956	Training Loss 5.8522 (5.9707)	Training Prec@1 95.117 (95.337)	Training Prec@5 97.266 (97.700)	
2022-04-03 12:01:27,362: ============================================================
2022-04-03 12:02:10,463: time cost, forward:0.011002175696228671, backward:0.05845641529014716, data cost:0.3590183253640664 
2022-04-03 12:02:10,464: ============================================================
2022-04-03 12:02:10,464: Epoch 3/26 Batch 5400/7662 eta: 21:22:12.041104	Training Loss 5.7473 (5.9689)	Training Prec@1 97.070 (95.339)	Training Prec@5 99.023 (97.702)	
2022-04-03 12:02:10,464: ============================================================
2022-04-03 12:02:54,125: time cost, forward:0.01099712334019116, backward:0.058463401199579455, data cost:0.3591496045642776 
2022-04-03 12:02:54,126: ============================================================
2022-04-03 12:02:54,126: Epoch 3/26 Batch 5500/7662 eta: 21:38:08.031972	Training Loss 6.0075 (5.9676)	Training Prec@1 95.508 (95.342)	Training Prec@5 97.461 (97.704)	
2022-04-03 12:02:54,126: ============================================================
2022-04-03 12:03:37,626: time cost, forward:0.010995006195071084, backward:0.05847212003158403, data cost:0.3592548649701546 
2022-04-03 12:03:37,627: ============================================================
2022-04-03 12:03:37,627: Epoch 3/26 Batch 5600/7662 eta: 21:32:37.223588	Training Loss 5.9179 (5.9660)	Training Prec@1 95.703 (95.344)	Training Prec@5 98.242 (97.705)	
2022-04-03 12:03:37,627: ============================================================
2022-04-03 12:04:19,976: time cost, forward:0.010986742544098892, backward:0.05849039008647104, data cost:0.3591337096881482 
2022-04-03 12:04:19,977: ============================================================
2022-04-03 12:04:19,977: Epoch 3/26 Batch 5700/7662 eta: 20:57:43.408388	Training Loss 5.8944 (5.9644)	Training Prec@1 94.727 (95.345)	Training Prec@5 98.242 (97.705)	
2022-04-03 12:04:19,977: ============================================================
2022-04-03 12:05:00,138: time cost, forward:0.01098153183718841, backward:0.058500417205131675, data cost:0.35864081533227754 
2022-04-03 12:05:00,139: ============================================================
2022-04-03 12:05:00,139: Epoch 3/26 Batch 5800/7662 eta: 19:52:03.919799	Training Loss 5.7470 (5.9629)	Training Prec@1 97.070 (95.345)	Training Prec@5 98.828 (97.705)	
2022-04-03 12:05:00,139: ============================================================
2022-04-03 12:05:43,159: time cost, forward:0.010984168333165786, backward:0.05850772818057572, data cost:0.3586734740041761 
2022-04-03 12:05:43,160: ============================================================
2022-04-03 12:05:43,160: Epoch 3/26 Batch 5900/7662 eta: 21:16:12.378059	Training Loss 5.7179 (5.9612)	Training Prec@1 96.094 (95.347)	Training Prec@5 98.242 (97.705)	
2022-04-03 12:05:43,160: ============================================================
2022-04-03 12:06:26,563: time cost, forward:0.010973473949658114, backward:0.05852814180927687, data cost:0.35875584825235 
2022-04-03 12:06:26,563: ============================================================
2022-04-03 12:06:26,564: Epoch 3/26 Batch 6000/7662 eta: 21:26:50.645178	Training Loss 5.8164 (5.9588)	Training Prec@1 94.531 (95.347)	Training Prec@5 97.266 (97.706)	
2022-04-03 12:06:26,564: ============================================================
2022-04-03 12:07:09,751: time cost, forward:0.01096581896712964, backward:0.05854327574306325, data cost:0.3587980262176544 
2022-04-03 12:07:09,751: ============================================================
2022-04-03 12:07:09,751: Epoch 3/26 Batch 6100/7662 eta: 21:19:42.808764	Training Loss 5.8005 (5.9574)	Training Prec@1 94.141 (95.347)	Training Prec@5 96.484 (97.708)	
2022-04-03 12:07:09,751: ============================================================
2022-04-03 12:07:52,347: time cost, forward:0.010959913738698108, backward:0.05855367802519782, data cost:0.3587461187101445 
2022-04-03 12:07:52,348: ============================================================
2022-04-03 12:07:52,348: Epoch 3/26 Batch 6200/7662 eta: 21:01:29.584091	Training Loss 6.2062 (5.9560)	Training Prec@1 94.531 (95.347)	Training Prec@5 97.266 (97.707)	
2022-04-03 12:07:52,348: ============================================================
2022-04-03 12:08:33,730: time cost, forward:0.010961267754735975, backward:0.0585632365096995, data cost:0.3585020248275614 
2022-04-03 12:08:33,731: ============================================================
2022-04-03 12:08:33,731: Epoch 3/26 Batch 6300/7662 eta: 20:24:51.943603	Training Loss 5.7980 (5.9544)	Training Prec@1 95.117 (95.348)	Training Prec@5 97.656 (97.709)	
2022-04-03 12:08:33,731: ============================================================
2022-04-03 12:09:15,850: time cost, forward:0.010958667322329608, backward:0.058578197947515696, data cost:0.35835821286908054 
2022-04-03 12:09:15,850: ============================================================
2022-04-03 12:09:15,851: Epoch 3/26 Batch 6400/7662 eta: 20:45:57.843140	Training Loss 6.1697 (5.9527)	Training Prec@1 95.508 (95.349)	Training Prec@5 97.852 (97.712)	
2022-04-03 12:09:15,851: ============================================================
2022-04-03 12:09:59,303: time cost, forward:0.010955170789742986, backward:0.058587612234861926, data cost:0.3584658826639293 
2022-04-03 12:09:59,303: ============================================================
2022-04-03 12:09:59,303: Epoch 3/26 Batch 6500/7662 eta: 21:24:40.223125	Training Loss 5.8419 (5.9508)	Training Prec@1 96.094 (95.352)	Training Prec@5 97.852 (97.713)	
2022-04-03 12:09:59,304: ============================================================
2022-04-03 12:10:42,375: time cost, forward:0.010952319100257537, backward:0.058598706786931326, data cost:0.3584851257583195 
2022-04-03 12:10:42,376: ============================================================
2022-04-03 12:10:42,376: Epoch 3/26 Batch 6600/7662 eta: 21:12:42.693341	Training Loss 5.7805 (5.9492)	Training Prec@1 95.508 (95.353)	Training Prec@5 97.852 (97.714)	
2022-04-03 12:10:42,376: ============================================================
2022-04-03 12:11:25,972: time cost, forward:0.010952690213914236, backward:0.05860398213958399, data cost:0.35859165630833145 
2022-04-03 12:11:25,973: ============================================================
2022-04-03 12:11:25,973: Epoch 3/26 Batch 6700/7662 eta: 21:27:29.756442	Training Loss 6.1406 (5.9476)	Training Prec@1 94.727 (95.353)	Training Prec@5 96.875 (97.715)	
2022-04-03 12:11:25,973: ============================================================
2022-04-03 12:12:10,115: time cost, forward:0.010952223187107289, backward:0.058611967297472804, data cost:0.3587652816371298 
2022-04-03 12:12:10,115: ============================================================
2022-04-03 12:12:10,115: Epoch 3/26 Batch 6800/7662 eta: 21:42:50.675708	Training Loss 5.7598 (5.9465)	Training Prec@1 96.484 (95.352)	Training Prec@5 97.461 (97.715)	
2022-04-03 12:12:10,116: ============================================================
2022-04-03 12:12:54,555: time cost, forward:0.010947696228513926, backward:0.058620251094211547, data cost:0.3589813042281417 
2022-04-03 12:12:54,555: ============================================================
2022-04-03 12:12:54,556: Epoch 3/26 Batch 6900/7662 eta: 21:50:54.875913	Training Loss 6.0015 (5.9454)	Training Prec@1 94.922 (95.353)	Training Prec@5 97.070 (97.716)	
2022-04-03 12:12:54,556: ============================================================
2022-04-03 12:13:39,172: time cost, forward:0.010947880088848665, backward:0.05862544154861958, data cost:0.3592258333597784 
2022-04-03 12:13:39,173: ============================================================
2022-04-03 12:13:39,173: Epoch 3/26 Batch 7000/7662 eta: 21:55:22.561938	Training Loss 6.0283 (5.9437)	Training Prec@1 95.508 (95.355)	Training Prec@5 97.656 (97.717)	
2022-04-03 12:13:39,173: ============================================================
2022-04-03 12:14:22,804: time cost, forward:0.010948454465542332, backward:0.05863275006046126, data cost:0.3593250290913252 
2022-04-03 12:14:22,804: ============================================================
2022-04-03 12:14:22,804: Epoch 3/26 Batch 7100/7662 eta: 21:25:35.570311	Training Loss 6.1204 (5.9424)	Training Prec@1 93.750 (95.355)	Training Prec@5 96.484 (97.718)	
2022-04-03 12:14:22,804: ============================================================
2022-04-03 12:15:08,207: time cost, forward:0.010940486547896922, backward:0.058647779412262305, data cost:0.35965075296136234 
2022-04-03 12:15:08,207: ============================================================
2022-04-03 12:15:08,207: Epoch 3/26 Batch 7200/7662 eta: 22:17:02.390383	Training Loss 5.6611 (5.9402)	Training Prec@1 96.484 (95.358)	Training Prec@5 98.242 (97.719)	
2022-04-03 12:15:08,208: ============================================================
2022-04-03 12:15:52,698: time cost, forward:0.010934119813163602, backward:0.05865562675848189, data cost:0.3598528161475488 
2022-04-03 12:15:52,698: ============================================================
2022-04-03 12:15:52,699: Epoch 3/26 Batch 7300/7662 eta: 21:49:26.381550	Training Loss 5.9475 (5.9386)	Training Prec@1 95.508 (95.359)	Training Prec@5 98.242 (97.720)	
2022-04-03 12:15:52,699: ============================================================
2022-04-03 12:16:36,988: time cost, forward:0.010936065241523265, backward:0.058658008173295396, data cost:0.3600186827311984 
2022-04-03 12:16:36,989: ============================================================
2022-04-03 12:16:36,989: Epoch 3/26 Batch 7400/7662 eta: 21:42:47.433319	Training Loss 5.7993 (5.9371)	Training Prec@1 95.898 (95.359)	Training Prec@5 98.047 (97.721)	
2022-04-03 12:16:36,989: ============================================================
2022-04-03 12:17:21,298: time cost, forward:0.010933248118283447, backward:0.05866536561259112, data cost:0.36019623271623186 
2022-04-03 12:17:21,298: ============================================================
2022-04-03 12:17:21,298: Epoch 3/26 Batch 7500/7662 eta: 21:42:37.249612	Training Loss 5.7547 (5.9353)	Training Prec@1 96.484 (95.362)	Training Prec@5 98.242 (97.722)	
2022-04-03 12:17:21,299: ============================================================
2022-04-03 12:18:05,937: time cost, forward:0.01092651533851468, backward:0.058676847330377764, data cost:0.36040273872327294 
2022-04-03 12:18:05,937: ============================================================
2022-04-03 12:18:05,937: Epoch 3/26 Batch 7600/7662 eta: 21:51:33.712170	Training Loss 5.8223 (5.9340)	Training Prec@1 95.117 (95.363)	Training Prec@5 96.875 (97.723)	
2022-04-03 12:18:05,938: ============================================================
2022-04-03 12:18:35,500: Epoch: 3/26 eta: 21:51:05.589577	Training Loss 5.4903 (5.9328)	Training Prec@1 97.070 (95.364)	Training Prec@5 99.219 (97.725)
2022-04-03 12:18:35,500: ============================================================
2022-04-03 12:19:19,862: time cost, forward:0.01345267440333511, backward:0.055807554360592, data cost:0.3730445751036056 
2022-04-03 12:19:19,862: ============================================================
2022-04-03 12:19:19,863: Epoch 4/26 Batch 100/7662 eta: 21:37:06.876500	Training Loss 5.2426 (5.4223)	Training Prec@1 97.852 (96.332)	Training Prec@5 98.828 (98.230)	
2022-04-03 12:19:19,863: ============================================================
2022-04-03 12:20:00,872: time cost, forward:0.012520878758262749, backward:0.056372586207174176, data cost:0.3568748720926256 
2022-04-03 12:20:00,873: ============================================================
2022-04-03 12:20:00,873: Epoch 4/26 Batch 200/7662 eta: 20:03:09.832262	Training Loss 5.5690 (5.4371)	Training Prec@1 95.508 (96.391)	Training Prec@5 97.266 (98.274)	
2022-04-03 12:20:00,874: ============================================================
2022-04-03 12:20:41,227: time cost, forward:0.012487775904677784, backward:0.0562275404914167, data cost:0.34948988981470214 
2022-04-03 12:20:41,228: ============================================================
2022-04-03 12:20:41,229: Epoch 4/26 Batch 300/7662 eta: 19:43:15.711251	Training Loss 5.6145 (5.4739)	Training Prec@1 96.484 (96.349)	Training Prec@5 98.438 (98.252)	
2022-04-03 12:20:41,229: ============================================================
2022-04-03 12:21:22,959: time cost, forward:0.01213894810592919, backward:0.05660469729201238, data cost:0.3489069245512922 
2022-04-03 12:21:22,959: ============================================================
2022-04-03 12:21:22,960: Epoch 4/26 Batch 400/7662 eta: 20:22:54.642370	Training Loss 5.5468 (5.4931)	Training Prec@1 97.070 (96.330)	Training Prec@5 98.438 (98.251)	
2022-04-03 12:21:22,960: ============================================================
2022-04-03 12:22:06,343: time cost, forward:0.011894444425502616, backward:0.05683817366559902, data cost:0.3520274167070408 
2022-04-03 12:22:06,344: ============================================================
2022-04-03 12:22:06,344: Epoch 4/26 Batch 500/7662 eta: 21:10:38.242236	Training Loss 5.6297 (5.5217)	Training Prec@1 95.898 (96.239)	Training Prec@5 98.242 (98.200)	
2022-04-03 12:22:06,344: ============================================================
2022-04-03 12:22:47,591: time cost, forward:0.01180787436751173, backward:0.05689815328594838, data cost:0.3506958146326132 
2022-04-03 12:22:47,592: ============================================================
2022-04-03 12:22:47,592: Epoch 4/26 Batch 600/7662 eta: 20:07:22.672950	Training Loss 5.4572 (5.5437)	Training Prec@1 96.289 (96.212)	Training Prec@5 98.047 (98.184)	
2022-04-03 12:22:47,592: ============================================================
2022-04-03 12:23:28,231: time cost, forward:0.011910540180997617, backward:0.05683179474695558, data cost:0.348712655096095 
2022-04-03 12:23:28,232: ============================================================
2022-04-03 12:23:28,232: Epoch 4/26 Batch 700/7662 eta: 19:48:53.864558	Training Loss 5.6408 (5.5645)	Training Prec@1 96.484 (96.179)	Training Prec@5 98.438 (98.170)	
2022-04-03 12:23:28,232: ============================================================
2022-04-03 12:24:10,008: time cost, forward:0.011781226708384718, backward:0.05701190747964069, data cost:0.34863411291072305 
2022-04-03 12:24:10,008: ============================================================
2022-04-03 12:24:10,009: Epoch 4/26 Batch 800/7662 eta: 20:21:27.315841	Training Loss 5.5163 (5.5844)	Training Prec@1 96.680 (96.143)	Training Prec@5 98.828 (98.151)	
2022-04-03 12:24:10,009: ============================================================
2022-04-03 12:24:51,161: time cost, forward:0.0117634286869885, backward:0.057073173586598226, data cost:0.34784439700066183 
2022-04-03 12:24:51,161: ============================================================
2022-04-03 12:24:51,162: Epoch 4/26 Batch 900/7662 eta: 20:02:32.318006	Training Loss 5.9602 (5.6036)	Training Prec@1 95.117 (96.094)	Training Prec@5 98.047 (98.130)	
2022-04-03 12:24:51,162: ============================================================
2022-04-03 12:25:34,061: time cost, forward:0.011715285174242846, backward:0.05716602556459658, data cost:0.3489122994549878 
2022-04-03 12:25:34,061: ============================================================
2022-04-03 12:25:34,061: Epoch 4/26 Batch 1000/7662 eta: 20:52:51.974167	Training Loss 5.7146 (5.6159)	Training Prec@1 94.922 (96.052)	Training Prec@5 97.070 (98.113)	
2022-04-03 12:25:34,062: ============================================================
2022-04-03 12:26:18,135: time cost, forward:0.011630506923352728, backward:0.05727563151671086, data cost:0.35098140341678025 
2022-04-03 12:26:18,135: ============================================================
2022-04-03 12:26:18,135: Epoch 4/26 Batch 1100/7662 eta: 21:26:25.595276	Training Loss 5.7646 (5.6276)	Training Prec@1 95.312 (96.034)	Training Prec@5 97.461 (98.104)	
2022-04-03 12:26:18,136: ============================================================
2022-04-03 12:27:02,943: time cost, forward:0.011593290922341494, backward:0.05732705893369393, data cost:0.3532718486642718 
2022-04-03 12:27:02,943: ============================================================
2022-04-03 12:27:02,943: Epoch 4/26 Batch 1200/7662 eta: 21:47:05.907609	Training Loss 5.8504 (5.6388)	Training Prec@1 93.945 (96.008)	Training Prec@5 96.484 (98.090)	
2022-04-03 12:27:02,943: ============================================================
2022-04-03 12:27:47,384: time cost, forward:0.011564223926006784, backward:0.05735341359139223, data cost:0.35491374513568835 
2022-04-03 12:27:47,384: ============================================================
2022-04-03 12:27:47,385: Epoch 4/26 Batch 1300/7662 eta: 21:35:39.980342	Training Loss 5.7888 (5.6485)	Training Prec@1 94.922 (95.976)	Training Prec@5 97.266 (98.078)	
2022-04-03 12:27:47,385: ============================================================
2022-04-03 12:28:31,179: time cost, forward:0.011530985228925027, backward:0.05740142942241808, data cost:0.3558985568354009 
2022-04-03 12:28:31,180: ============================================================
2022-04-03 12:28:31,180: Epoch 4/26 Batch 1400/7662 eta: 21:16:05.892850	Training Loss 5.4672 (5.6533)	Training Prec@1 95.898 (95.956)	Training Prec@5 98.438 (98.068)	
2022-04-03 12:28:31,180: ============================================================
2022-04-03 12:29:13,412: time cost, forward:0.01150652167795498, backward:0.057456681535910416, data cost:0.3556114561642067 
2022-04-03 12:29:13,413: ============================================================
2022-04-03 12:29:13,413: Epoch 4/26 Batch 1500/7662 eta: 20:29:52.508136	Training Loss 5.7769 (5.6592)	Training Prec@1 94.922 (95.930)	Training Prec@5 97.461 (98.052)	
2022-04-03 12:29:13,413: ============================================================
2022-04-03 12:29:56,377: time cost, forward:0.011541892767996248, backward:0.05741275885166266, data cost:0.35594814162167854 
2022-04-03 12:29:56,377: ============================================================
2022-04-03 12:29:56,378: Epoch 4/26 Batch 1600/7662 eta: 20:50:27.863804	Training Loss 6.0134 (5.6657)	Training Prec@1 94.727 (95.904)	Training Prec@5 98.047 (98.039)	
2022-04-03 12:29:56,378: ============================================================
2022-04-03 12:30:39,818: time cost, forward:0.011471557925910793, backward:0.05748061013965483, data cost:0.3564577303331273 
2022-04-03 12:30:39,818: ============================================================
2022-04-03 12:30:39,819: Epoch 4/26 Batch 1700/7662 eta: 21:03:36.350607	Training Loss 6.0258 (5.6690)	Training Prec@1 95.898 (95.887)	Training Prec@5 98.242 (98.030)	
2022-04-03 12:30:39,819: ============================================================
2022-04-03 12:31:23,666: time cost, forward:0.011387068805196273, backward:0.0575747150656513, data cost:0.35714706279888225 
2022-04-03 12:31:23,666: ============================================================
2022-04-03 12:31:23,667: Epoch 4/26 Batch 1800/7662 eta: 21:14:42.627534	Training Loss 5.6926 (5.6727)	Training Prec@1 97.656 (95.877)	Training Prec@5 98.828 (98.020)	
2022-04-03 12:31:23,667: ============================================================
2022-04-03 12:32:07,684: time cost, forward:0.011332072729559682, backward:0.05763499155491512, data cost:0.3578571782355688 
2022-04-03 12:32:07,684: ============================================================
2022-04-03 12:32:07,684: Epoch 4/26 Batch 1900/7662 eta: 21:18:55.094491	Training Loss 5.6695 (5.6753)	Training Prec@1 95.508 (95.867)	Training Prec@5 97.656 (98.015)	
2022-04-03 12:32:07,685: ============================================================
2022-04-03 12:32:51,745: time cost, forward:0.011304513044867771, backward:0.057666629478298106, data cost:0.3585126298615311 
2022-04-03 12:32:51,745: ============================================================
2022-04-03 12:32:51,746: Epoch 4/26 Batch 2000/7662 eta: 21:19:26.301138	Training Loss 5.7376 (5.6777)	Training Prec@1 95.508 (95.850)	Training Prec@5 97.461 (98.007)	
2022-04-03 12:32:51,746: ============================================================
2022-04-03 12:33:36,134: time cost, forward:0.011287440908358403, backward:0.05769016607538072, data cost:0.3592603299775653 
2022-04-03 12:33:36,134: ============================================================
2022-04-03 12:33:36,134: Epoch 4/26 Batch 2100/7662 eta: 21:28:13.127645	Training Loss 5.8847 (5.6814)	Training Prec@1 97.070 (95.840)	Training Prec@5 98.438 (97.999)	
2022-04-03 12:33:36,135: ============================================================
2022-04-03 12:34:19,894: time cost, forward:0.011326897518371333, backward:0.05764487734053448, data cost:0.35960442058169445 
2022-04-03 12:34:19,895: ============================================================
2022-04-03 12:34:19,895: Epoch 4/26 Batch 2200/7662 eta: 21:09:14.782369	Training Loss 5.7092 (5.6837)	Training Prec@1 94.727 (95.824)	Training Prec@5 97.266 (97.990)	
2022-04-03 12:34:19,895: ============================================================
2022-04-03 12:35:04,416: time cost, forward:0.01134101242125164, backward:0.05763900928157161, data cost:0.36035753260907427 
2022-04-03 12:35:04,417: ============================================================
2022-04-03 12:35:04,417: Epoch 4/26 Batch 2300/7662 eta: 21:30:35.839197	Training Loss 5.8677 (5.6856)	Training Prec@1 95.312 (95.814)	Training Prec@5 98.047 (97.987)	
2022-04-03 12:35:04,417: ============================================================
2022-04-03 12:35:48,404: time cost, forward:0.011358147414836749, backward:0.05762392801759441, data cost:0.36076979022962247 
2022-04-03 12:35:48,404: ============================================================
2022-04-03 12:35:48,404: Epoch 4/26 Batch 2400/7662 eta: 21:14:22.302811	Training Loss 5.8219 (5.6870)	Training Prec@1 96.289 (95.810)	Training Prec@5 98.438 (97.984)	
2022-04-03 12:35:48,405: ============================================================
2022-04-03 12:36:31,683: time cost, forward:0.011398451764281153, backward:0.05759293348992429, data cost:0.36086217056707937 
2022-04-03 12:36:31,683: ============================================================
2022-04-03 12:36:31,683: Epoch 4/26 Batch 2500/7662 eta: 20:53:07.141485	Training Loss 5.6124 (5.6891)	Training Prec@1 96.875 (95.800)	Training Prec@5 98.438 (97.979)	
2022-04-03 12:36:31,684: ============================================================
2022-04-03 12:37:15,401: time cost, forward:0.011459971171427158, backward:0.05753086291170432, data cost:0.3611167086322017 
2022-04-03 12:37:15,401: ============================================================
2022-04-03 12:37:15,401: Epoch 4/26 Batch 2600/7662 eta: 21:05:06.070019	Training Loss 5.7961 (5.6902)	Training Prec@1 95.703 (95.797)	Training Prec@5 98.438 (97.979)	
2022-04-03 12:37:15,401: ============================================================
2022-04-03 12:38:00,484: time cost, forward:0.01145275427969176, backward:0.057539318172346005, data cost:0.36187031950143234 
2022-04-03 12:38:00,485: ============================================================
2022-04-03 12:38:00,485: Epoch 4/26 Batch 2700/7662 eta: 21:43:52.695669	Training Loss 5.5701 (5.6926)	Training Prec@1 95.703 (95.787)	Training Prec@5 98.047 (97.977)	
2022-04-03 12:38:00,485: ============================================================
2022-04-03 12:38:44,895: time cost, forward:0.011433072582488829, backward:0.05756017445410606, data cost:0.3623149677786328 
2022-04-03 12:38:44,895: ============================================================
2022-04-03 12:38:44,895: Epoch 4/26 Batch 2800/7662 eta: 21:23:39.524609	Training Loss 5.7106 (5.6951)	Training Prec@1 94.727 (95.775)	Training Prec@5 97.852 (97.970)	
2022-04-03 12:38:44,896: ============================================================
2022-04-03 12:39:29,054: time cost, forward:0.011415306639367032, backward:0.0575773096693183, data cost:0.3626549706947561 
2022-04-03 12:39:29,054: ============================================================
2022-04-03 12:39:29,055: Epoch 4/26 Batch 2900/7662 eta: 21:15:39.519794	Training Loss 5.7739 (5.6957)	Training Prec@1 94.727 (95.768)	Training Prec@5 97.461 (97.964)	
2022-04-03 12:39:29,055: ============================================================
2022-04-03 12:40:13,579: time cost, forward:0.01140744171765853, backward:0.057590804286065125, data cost:0.3630836571244726 
2022-04-03 12:40:13,583: ============================================================
2022-04-03 12:40:13,583: Epoch 4/26 Batch 3000/7662 eta: 21:25:35.616117	Training Loss 5.8850 (5.6973)	Training Prec@1 95.508 (95.763)	Training Prec@5 97.266 (97.963)	
2022-04-03 12:40:13,583: ============================================================
2022-04-03 12:40:56,670: time cost, forward:0.011393746548062104, backward:0.057610814361350696, data cost:0.3630193549227276 
2022-04-03 12:40:56,670: ============================================================
2022-04-03 12:40:56,671: Epoch 4/26 Batch 3100/7662 eta: 20:43:15.811481	Training Loss 5.9626 (5.6976)	Training Prec@1 95.508 (95.757)	Training Prec@5 98.047 (97.961)	
2022-04-03 12:40:56,671: ============================================================
2022-04-03 12:41:41,325: time cost, forward:0.011375983307681333, backward:0.05763483226355183, data cost:0.36344743728935813 
2022-04-03 12:41:41,325: ============================================================
2022-04-03 12:41:41,326: Epoch 4/26 Batch 3200/7662 eta: 21:27:45.286831	Training Loss 5.7976 (5.6984)	Training Prec@1 95.312 (95.751)	Training Prec@5 97.461 (97.957)	
2022-04-03 12:41:41,326: ============================================================
2022-04-03 12:42:25,323: time cost, forward:0.011411466682343888, backward:0.05760156374766849, data cost:0.36360552210488367 
2022-04-03 12:42:25,324: ============================================================
2022-04-03 12:42:25,324: Epoch 4/26 Batch 3300/7662 eta: 21:08:05.486656	Training Loss 6.0036 (5.6987)	Training Prec@1 94.922 (95.748)	Training Prec@5 97.656 (97.952)	
2022-04-03 12:42:25,324: ============================================================
2022-04-03 12:43:08,829: time cost, forward:0.01139605168070152, backward:0.05762506814941514, data cost:0.36372227856747436 
2022-04-03 12:43:08,829: ============================================================
2022-04-03 12:43:08,830: Epoch 4/26 Batch 3400/7662 eta: 20:53:09.178923	Training Loss 5.8403 (5.6991)	Training Prec@1 95.312 (95.744)	Training Prec@5 98.242 (97.951)	
2022-04-03 12:43:08,830: ============================================================
2022-04-03 12:43:51,686: time cost, forward:0.011387232338642863, backward:0.057638582688598984, data cost:0.363561259231829 
2022-04-03 12:43:51,687: ============================================================
2022-04-03 12:43:51,687: Epoch 4/26 Batch 3500/7662 eta: 20:33:46.138529	Training Loss 5.6076 (5.6999)	Training Prec@1 96.094 (95.739)	Training Prec@5 97.852 (97.947)	
2022-04-03 12:43:51,687: ============================================================
2022-04-03 12:44:35,225: time cost, forward:0.011367794009306988, backward:0.05766050740724539, data cost:0.3636332835446268 
2022-04-03 12:44:35,225: ============================================================
2022-04-03 12:44:35,225: Epoch 4/26 Batch 3600/7662 eta: 20:52:39.200343	Training Loss 5.6659 (5.6997)	Training Prec@1 97.266 (95.737)	Training Prec@5 98.828 (97.945)	
2022-04-03 12:44:35,226: ============================================================
2022-04-03 12:45:19,593: time cost, forward:0.011355869059112789, backward:0.057673752775189685, data cost:0.3639049248361497 
2022-04-03 12:45:19,593: ============================================================
2022-04-03 12:45:19,594: Epoch 4/26 Batch 3700/7662 eta: 21:15:46.966571	Training Loss 6.0693 (5.6999)	Training Prec@1 94.336 (95.728)	Training Prec@5 98.047 (97.940)	
2022-04-03 12:45:19,594: ============================================================
2022-04-03 12:46:03,629: time cost, forward:0.01135636066317276, backward:0.05767454489747861, data cost:0.3640937601839062 
2022-04-03 12:46:03,629: ============================================================
2022-04-03 12:46:03,629: Epoch 4/26 Batch 3800/7662 eta: 21:05:29.539356	Training Loss 5.6539 (5.7003)	Training Prec@1 96.680 (95.723)	Training Prec@5 98.242 (97.938)	
2022-04-03 12:46:03,630: ============================================================
2022-04-03 12:46:47,535: time cost, forward:0.011342128749748596, backward:0.057688569129812746, data cost:0.3642311814688022 
2022-04-03 12:46:47,536: ============================================================
2022-04-03 12:46:47,536: Epoch 4/26 Batch 3900/7662 eta: 21:01:02.626241	Training Loss 5.5199 (5.7008)	Training Prec@1 95.508 (95.719)	Training Prec@5 97.461 (97.938)	
2022-04-03 12:46:47,536: ============================================================
2022-04-03 12:47:31,541: time cost, forward:0.011329840886411025, backward:0.05770461825795041, data cost:0.36437238619070583 
2022-04-03 12:47:31,541: ============================================================
2022-04-03 12:47:31,541: Epoch 4/26 Batch 4000/7662 eta: 21:03:09.355905	Training Loss 5.5509 (5.7007)	Training Prec@1 93.945 (95.717)	Training Prec@5 96.680 (97.937)	
2022-04-03 12:47:31,541: ============================================================
2022-04-03 12:48:12,191: time cost, forward:0.0113100593163927, backward:0.05772340981138424, data cost:0.36372162371503053 
2022-04-03 12:48:12,192: ============================================================
2022-04-03 12:48:12,193: Epoch 4/26 Batch 4100/7662 eta: 19:26:11.859788	Training Loss 5.7450 (5.7007)	Training Prec@1 95.703 (95.714)	Training Prec@5 97.852 (97.935)	
2022-04-03 12:48:12,193: ============================================================
2022-04-03 12:48:54,196: time cost, forward:0.011290064480339354, backward:0.05773879602200135, data cost:0.3634111228855657 
2022-04-03 12:48:54,196: ============================================================
2022-04-03 12:48:54,196: Epoch 4/26 Batch 4200/7662 eta: 20:04:17.646789	Training Loss 5.5483 (5.7004)	Training Prec@1 95.117 (95.711)	Training Prec@5 98.047 (97.934)	
2022-04-03 12:48:54,196: ============================================================
2022-04-03 12:49:37,999: time cost, forward:0.01129798474326248, backward:0.057730464886498745, data cost:0.3635253521918585 
2022-04-03 12:49:37,999: ============================================================
2022-04-03 12:49:38,000: Epoch 4/26 Batch 4300/7662 eta: 20:55:09.887982	Training Loss 5.7409 (5.7001)	Training Prec@1 95.508 (95.707)	Training Prec@5 97.852 (97.931)	
2022-04-03 12:49:38,000: ============================================================
2022-04-03 12:50:20,569: time cost, forward:0.011273048606399081, backward:0.05776234506666457, data cost:0.3633303713814782 
2022-04-03 12:50:20,570: ============================================================
2022-04-03 12:50:20,570: Epoch 4/26 Batch 4400/7662 eta: 20:19:07.216300	Training Loss 5.4531 (5.7002)	Training Prec@1 96.484 (95.704)	Training Prec@5 98.438 (97.931)	
2022-04-03 12:50:20,570: ============================================================
2022-04-03 12:51:03,867: time cost, forward:0.011259530697644723, backward:0.057783311302064655, data cost:0.3633404725603221 
2022-04-03 12:51:03,867: ============================================================
2022-04-03 12:51:03,868: Epoch 4/26 Batch 4500/7662 eta: 20:39:13.732248	Training Loss 5.9119 (5.6999)	Training Prec@1 96.484 (95.702)	Training Prec@5 98.438 (97.931)	
2022-04-03 12:51:03,868: ============================================================
2022-04-03 12:51:47,687: time cost, forward:0.011313361897627201, backward:0.0577268541364676, data cost:0.36346210809240237 
2022-04-03 12:51:47,687: ============================================================
2022-04-03 12:51:47,688: Epoch 4/26 Batch 4600/7662 eta: 20:53:26.913231	Training Loss 5.6201 (5.6992)	Training Prec@1 94.336 (95.704)	Training Prec@5 97.070 (97.930)	
2022-04-03 12:51:47,688: ============================================================
2022-04-03 12:52:31,336: time cost, forward:0.011297942831506626, backward:0.05774605966776222, data cost:0.3635220607307825 
2022-04-03 12:52:31,337: ============================================================
2022-04-03 12:52:31,337: Epoch 4/26 Batch 4700/7662 eta: 20:47:50.414726	Training Loss 5.8303 (5.6997)	Training Prec@1 96.875 (95.698)	Training Prec@5 98.242 (97.928)	
2022-04-03 12:52:31,337: ============================================================
2022-04-03 12:53:13,875: time cost, forward:0.011290204154871284, backward:0.05775774372297169, data cost:0.36337116336444936 
2022-04-03 12:53:13,875: ============================================================
2022-04-03 12:53:13,875: Epoch 4/26 Batch 4800/7662 eta: 20:15:22.422609	Training Loss 5.7858 (5.6993)	Training Prec@1 93.750 (95.700)	Training Prec@5 96.289 (97.929)	
2022-04-03 12:53:13,876: ============================================================
2022-04-03 12:53:55,581: time cost, forward:0.011277654847944968, backward:0.05777229555141296, data cost:0.3630361390079764 
2022-04-03 12:53:55,582: ============================================================
2022-04-03 12:53:55,582: Epoch 4/26 Batch 4900/7662 eta: 19:50:54.898512	Training Loss 5.7470 (5.6979)	Training Prec@1 94.336 (95.703)	Training Prec@5 97.852 (97.931)	
2022-04-03 12:53:55,582: ============================================================
2022-04-03 12:54:39,339: time cost, forward:0.011281120607819073, backward:0.05777364293201658, data cost:0.36313049691656774 
2022-04-03 12:54:39,340: ============================================================
2022-04-03 12:54:39,340: Epoch 4/26 Batch 5000/7662 eta: 20:48:45.797474	Training Loss 5.7559 (5.6971)	Training Prec@1 96.289 (95.702)	Training Prec@5 98.242 (97.931)	
2022-04-03 12:54:39,340: ============================================================
2022-04-03 12:55:21,815: time cost, forward:0.011274053620740371, backward:0.05778655881483336, data cost:0.3629787248311077 
2022-04-03 12:55:21,815: ============================================================
2022-04-03 12:55:21,815: Epoch 4/26 Batch 5100/7662 eta: 20:11:26.411366	Training Loss 5.9318 (5.6974)	Training Prec@1 95.508 (95.700)	Training Prec@5 97.461 (97.931)	
2022-04-03 12:55:21,816: ============================================================
2022-04-03 12:56:04,766: time cost, forward:0.011263376200375683, backward:0.05779499172086692, data cost:0.3629157325812866 
2022-04-03 12:56:04,766: ============================================================
2022-04-03 12:56:04,767: Epoch 4/26 Batch 5200/7662 eta: 20:24:18.278506	Training Loss 5.5360 (5.6966)	Training Prec@1 93.359 (95.697)	Training Prec@5 96.289 (97.930)	
2022-04-03 12:56:04,767: ============================================================
2022-04-03 12:56:47,213: time cost, forward:0.011247306662835048, backward:0.05780357238278566, data cost:0.3627774697426333 
2022-04-03 12:56:47,214: ============================================================
2022-04-03 12:56:47,214: Epoch 4/26 Batch 5300/7662 eta: 20:09:14.230973	Training Loss 5.5973 (5.6971)	Training Prec@1 95.312 (95.692)	Training Prec@5 98.242 (97.928)	
2022-04-03 12:56:47,214: ============================================================
2022-04-03 12:57:30,478: time cost, forward:0.011239744862222434, backward:0.05780683364839902, data cost:0.3627740709312228 
2022-04-03 12:57:30,479: ============================================================
2022-04-03 12:57:30,479: Epoch 4/26 Batch 5400/7662 eta: 20:31:48.254484	Training Loss 5.5969 (5.6969)	Training Prec@1 95.898 (95.690)	Training Prec@5 98.047 (97.927)	
2022-04-03 12:57:30,479: ============================================================
2022-04-03 12:58:14,185: time cost, forward:0.011227113850703347, backward:0.0578120172316431, data cost:0.36286723329752524 
2022-04-03 12:58:14,185: ============================================================
2022-04-03 12:58:14,185: Epoch 4/26 Batch 5500/7662 eta: 20:43:37.999759	Training Loss 5.7660 (5.6963)	Training Prec@1 95.898 (95.688)	Training Prec@5 98.047 (97.926)	
2022-04-03 12:58:14,185: ============================================================
2022-04-03 12:58:57,782: time cost, forward:0.011213489463657625, backward:0.05781529502882279, data cost:0.36294194080293507 
2022-04-03 12:58:57,782: ============================================================
2022-04-03 12:58:57,783: Epoch 4/26 Batch 5600/7662 eta: 20:39:48.937240	Training Loss 5.4532 (5.6952)	Training Prec@1 94.922 (95.688)	Training Prec@5 97.852 (97.927)	
2022-04-03 12:58:57,783: ============================================================
2022-04-03 12:59:41,174: time cost, forward:0.011210985195429665, backward:0.05781268512895179, data cost:0.362965909697169 
2022-04-03 12:59:41,174: ============================================================
2022-04-03 12:59:41,174: Epoch 4/26 Batch 5700/7662 eta: 20:33:14.730595	Training Loss 5.6191 (5.6953)	Training Prec@1 96.289 (95.683)	Training Prec@5 98.438 (97.924)	
2022-04-03 12:59:41,175: ============================================================
2022-04-03 13:00:24,758: time cost, forward:0.011198167575600024, backward:0.05781987363417655, data cost:0.3630292409451836 
2022-04-03 13:00:24,758: ============================================================
2022-04-03 13:00:24,758: Epoch 4/26 Batch 5800/7662 eta: 20:37:58.863236	Training Loss 5.8189 (5.6950)	Training Prec@1 94.727 (95.680)	Training Prec@5 96.094 (97.924)	
2022-04-03 13:00:24,759: ============================================================
2022-04-03 13:01:07,345: time cost, forward:0.011183125626376007, backward:0.057829119913010985, data cost:0.3629347892873751 
2022-04-03 13:01:07,345: ============================================================
2022-04-03 13:01:07,345: Epoch 4/26 Batch 5900/7662 eta: 20:08:57.199511	Training Loss 5.8916 (5.6952)	Training Prec@1 94.531 (95.677)	Training Prec@5 98.242 (97.922)	
2022-04-03 13:01:07,346: ============================================================
2022-04-03 13:01:50,217: time cost, forward:0.011171425436114962, backward:0.05783510700943749, data cost:0.3628797302605371 
2022-04-03 13:01:50,218: ============================================================
2022-04-03 13:01:50,218: Epoch 4/26 Batch 6000/7662 eta: 20:16:20.950762	Training Loss 5.8397 (5.6948)	Training Prec@1 95.898 (95.676)	Training Prec@5 97.852 (97.922)	
2022-04-03 13:01:50,218: ============================================================
2022-04-03 13:02:32,563: time cost, forward:0.011156868789993089, backward:0.057846718058075584, data cost:0.3627222149972936 
2022-04-03 13:02:32,563: ============================================================
2022-04-03 13:02:32,563: Epoch 4/26 Batch 6100/7662 eta: 20:00:40.281038	Training Loss 5.9081 (5.6946)	Training Prec@1 95.703 (95.677)	Training Prec@5 97.461 (97.924)	
2022-04-03 13:02:32,563: ============================================================
2022-04-03 13:03:15,042: time cost, forward:0.011144330182716258, backward:0.057856729404063625, data cost:0.36261090218472775 
2022-04-03 13:03:15,042: ============================================================
2022-04-03 13:03:15,042: Epoch 4/26 Batch 6200/7662 eta: 20:03:46.311068	Training Loss 5.8316 (5.6939)	Training Prec@1 94.922 (95.677)	Training Prec@5 97.070 (97.924)	
2022-04-03 13:03:15,043: ============================================================
2022-04-03 13:03:58,858: time cost, forward:0.01113634363850595, backward:0.05785879673967666, data cost:0.36271071547571676 
2022-04-03 13:03:58,859: ============================================================
2022-04-03 13:03:58,859: Epoch 4/26 Batch 6300/7662 eta: 20:40:55.667238	Training Loss 5.5614 (5.6931)	Training Prec@1 96.875 (95.678)	Training Prec@5 98.242 (97.924)	
2022-04-03 13:03:58,859: ============================================================
2022-04-03 13:04:42,332: time cost, forward:0.011135778942784773, backward:0.05785452702917667, data cost:0.362767092342171 
2022-04-03 13:04:42,332: ============================================================
2022-04-03 13:04:42,333: Epoch 4/26 Batch 6400/7662 eta: 20:30:30.994840	Training Loss 5.4365 (5.6925)	Training Prec@1 95.898 (95.677)	Training Prec@5 97.656 (97.924)	
2022-04-03 13:04:42,333: ============================================================
2022-04-03 13:05:25,275: time cost, forward:0.011213535014474038, backward:0.05777639402831806, data cost:0.36271691300315406 
2022-04-03 13:05:25,275: ============================================================
2022-04-03 13:05:25,276: Epoch 4/26 Batch 6500/7662 eta: 20:14:45.260775	Training Loss 5.5734 (5.6916)	Training Prec@1 94.922 (95.677)	Training Prec@5 97.656 (97.924)	
2022-04-03 13:05:25,276: ============================================================
2022-04-03 13:06:08,431: time cost, forward:0.011318109273585357, backward:0.05766715655129576, data cost:0.3627001046592457 
2022-04-03 13:06:08,432: ============================================================
2022-04-03 13:06:08,432: Epoch 4/26 Batch 6600/7662 eta: 20:20:05.278638	Training Loss 5.7858 (5.6910)	Training Prec@1 96.289 (95.678)	Training Prec@5 98.242 (97.924)	
2022-04-03 13:06:08,432: ============================================================
2022-04-03 13:06:52,320: time cost, forward:0.011307375273396317, backward:0.057668751256646354, data cost:0.3628079980892074 
2022-04-03 13:06:52,321: ============================================================
2022-04-03 13:06:52,321: Epoch 4/26 Batch 6700/7662 eta: 20:40:02.972950	Training Loss 5.5164 (5.6910)	Training Prec@1 96.289 (95.676)	Training Prec@5 97.852 (97.922)	
2022-04-03 13:06:52,321: ============================================================
2022-04-03 13:07:36,128: time cost, forward:0.011303699758232017, backward:0.0576680225210166, data cost:0.3629030758080228 
2022-04-03 13:07:36,129: ============================================================
2022-04-03 13:07:36,129: Epoch 4/26 Batch 6800/7662 eta: 20:37:02.553648	Training Loss 5.8396 (5.6903)	Training Prec@1 95.117 (95.675)	Training Prec@5 96.875 (97.921)	
2022-04-03 13:07:36,129: ============================================================
2022-04-03 13:08:18,678: time cost, forward:0.01128945390043578, backward:0.05767779423544624, data cost:0.36281400619166226 
2022-04-03 13:08:18,678: ============================================================
2022-04-03 13:08:18,678: Epoch 4/26 Batch 6900/7662 eta: 20:00:47.571825	Training Loss 5.7084 (5.6897)	Training Prec@1 95.508 (95.676)	Training Prec@5 97.461 (97.922)	
2022-04-03 13:08:18,678: ============================================================
2022-04-03 13:08:59,199: time cost, forward:0.011280416709931514, backward:0.05768092497193246, data cost:0.3624329163970598 
2022-04-03 13:08:59,200: ============================================================
2022-04-03 13:08:59,200: Epoch 4/26 Batch 7000/7662 eta: 19:02:53.659923	Training Loss 5.7454 (5.6893)	Training Prec@1 94.141 (95.675)	Training Prec@5 97.656 (97.922)	
2022-04-03 13:08:59,200: ============================================================
2022-04-03 13:09:39,837: time cost, forward:0.0112824558220979, backward:0.057677845465228465, data cost:0.362069919086171 
2022-04-03 13:09:39,837: ============================================================
2022-04-03 13:09:39,838: Epoch 4/26 Batch 7100/7662 eta: 19:05:29.392775	Training Loss 5.5644 (5.6890)	Training Prec@1 95.703 (95.674)	Training Prec@5 97.852 (97.921)	
2022-04-03 13:09:39,838: ============================================================
2022-04-03 13:10:20,170: time cost, forward:0.01126957025804823, backward:0.05768938719654997, data cost:0.3616828072947054 
2022-04-03 13:10:20,170: ============================================================
2022-04-03 13:10:20,171: Epoch 4/26 Batch 7200/7662 eta: 18:56:13.624353	Training Loss 5.7908 (5.6885)	Training Prec@1 95.508 (95.675)	Training Prec@5 97.461 (97.922)	
2022-04-03 13:10:20,171: ============================================================
2022-04-03 13:11:00,894: time cost, forward:0.011259053893114773, backward:0.057697297873799486, data cost:0.36135462033028376 
2022-04-03 13:11:00,895: ============================================================
2022-04-03 13:11:00,896: Epoch 4/26 Batch 7300/7662 eta: 19:06:35.624499	Training Loss 5.9196 (5.6884)	Training Prec@1 94.531 (95.672)	Training Prec@5 97.461 (97.921)	
2022-04-03 13:11:00,896: ============================================================
2022-04-03 13:11:43,848: time cost, forward:0.011254453291714489, backward:0.057700238238800085, data cost:0.36133354572786447 
2022-04-03 13:11:43,848: ============================================================
2022-04-03 13:11:43,848: Epoch 4/26 Batch 7400/7662 eta: 20:08:35.695892	Training Loss 5.6301 (5.6878)	Training Prec@1 96.875 (95.673)	Training Prec@5 98.633 (97.923)	
2022-04-03 13:11:43,849: ============================================================
2022-04-03 13:12:25,225: time cost, forward:0.01128662387630688, backward:0.05766528065100656, data cost:0.36111737693336937 
2022-04-03 13:12:25,225: ============================================================
2022-04-03 13:12:25,226: Epoch 4/26 Batch 7500/7662 eta: 19:23:34.420761	Training Loss 5.8105 (5.6876)	Training Prec@1 95.508 (95.672)	Training Prec@5 97.461 (97.923)	
2022-04-03 13:12:25,226: ============================================================
2022-04-03 13:13:08,573: time cost, forward:0.011277447971705936, backward:0.057669950388092514, data cost:0.3611520659783935 
2022-04-03 13:13:08,574: ============================================================
2022-04-03 13:13:08,574: Epoch 4/26 Batch 7600/7662 eta: 20:18:17.012185	Training Loss 5.9490 (5.6870)	Training Prec@1 93.750 (95.672)	Training Prec@5 96.875 (97.923)	
2022-04-03 13:13:08,574: ============================================================
2022-04-03 13:13:36,878: Epoch: 4/26 eta: 20:17:49.702728	Training Loss 5.7907 (5.6870)	Training Prec@1 93.750 (95.671)	Training Prec@5 96.680 (97.923)
2022-04-03 13:13:36,878: ============================================================
2022-04-03 13:14:21,659: time cost, forward:0.010950832655935577, backward:0.05798574649926388, data cost:0.3776893639805341 
2022-04-03 13:14:21,660: ============================================================
2022-04-03 13:14:21,660: Epoch 5/26 Batch 100/7662 eta: 20:53:57.844802	Training Loss 5.3477 (5.2789)	Training Prec@1 96.289 (96.480)	Training Prec@5 97.461 (98.305)	
2022-04-03 13:14:21,660: ============================================================
2022-04-03 13:15:05,356: time cost, forward:0.010785665943394954, backward:0.05808163887292296, data cost:0.3724601101036647 
2022-04-03 13:15:05,357: ============================================================
2022-04-03 13:15:05,357: Epoch 5/26 Batch 200/7662 eta: 20:26:10.753951	Training Loss 5.2377 (5.2744)	Training Prec@1 97.266 (96.553)	Training Prec@5 99.219 (98.382)	
2022-04-03 13:15:05,357: ============================================================
2022-04-03 13:15:49,069: time cost, forward:0.010651606779832106, backward:0.058120170963249077, data cost:0.37120862310148 
2022-04-03 13:15:49,070: ============================================================
2022-04-03 13:15:49,070: Epoch 5/26 Batch 300/7662 eta: 20:25:53.379069	Training Loss 5.4467 (5.2968)	Training Prec@1 97.070 (96.558)	Training Prec@5 98.047 (98.388)	
2022-04-03 13:15:49,070: ============================================================
2022-04-03 13:16:32,676: time cost, forward:0.010672395390675481, backward:0.058135107943886204, data cost:0.3700312910820906 
2022-04-03 13:16:32,677: ============================================================
2022-04-03 13:16:32,677: Epoch 5/26 Batch 400/7662 eta: 20:22:11.525304	Training Loss 5.2582 (5.3209)	Training Prec@1 96.680 (96.520)	Training Prec@5 98.438 (98.376)	
2022-04-03 13:16:32,677: ============================================================
2022-04-03 13:17:16,570: time cost, forward:0.010714816664884946, backward:0.05811402506245401, data cost:0.36972208443528903 
2022-04-03 13:17:16,571: ============================================================
2022-04-03 13:17:16,571: Epoch 5/26 Batch 500/7662 eta: 20:29:31.073073	Training Loss 5.3045 (5.3470)	Training Prec@1 94.141 (96.488)	Training Prec@5 97.656 (98.375)	
2022-04-03 13:17:16,571: ============================================================
2022-04-03 13:17:58,680: time cost, forward:0.011044627637019341, backward:0.05775051284114984, data cost:0.3669228661239446 
2022-04-03 13:17:58,681: ============================================================
2022-04-03 13:17:58,681: Epoch 5/26 Batch 600/7662 eta: 19:38:49.837066	Training Loss 5.4800 (5.3693)	Training Prec@1 97.070 (96.446)	Training Prec@5 98.047 (98.344)	
2022-04-03 13:17:58,681: ============================================================
2022-04-03 13:18:41,019: time cost, forward:0.011041472057075119, backward:0.05778293002487423, data cost:0.36497790073291086 
2022-04-03 13:18:41,020: ============================================================
2022-04-03 13:18:41,020: Epoch 5/26 Batch 700/7662 eta: 19:44:32.528820	Training Loss 5.5556 (5.3904)	Training Prec@1 97.461 (96.394)	Training Prec@5 98.438 (98.316)	
2022-04-03 13:18:41,020: ============================================================
2022-04-03 13:19:24,477: time cost, forward:0.011062155378625748, backward:0.057783044473698204, data cost:0.36499454828914024 
2022-04-03 13:19:24,478: ============================================================
2022-04-03 13:19:24,478: Epoch 5/26 Batch 800/7662 eta: 20:15:07.524398	Training Loss 5.7857 (5.4056)	Training Prec@1 94.922 (96.369)	Training Prec@5 97.656 (98.307)	
2022-04-03 13:19:24,478: ============================================================
2022-04-03 13:20:08,415: time cost, forward:0.011000084797452899, backward:0.05784531429956964, data cost:0.36558663990924567 
2022-04-03 13:20:08,415: ============================================================
2022-04-03 13:20:08,416: Epoch 5/26 Batch 900/7662 eta: 20:27:47.594312	Training Loss 5.3669 (5.4245)	Training Prec@1 96.094 (96.313)	Training Prec@5 97.852 (98.277)	
2022-04-03 13:20:08,416: ============================================================
2022-04-03 13:20:52,600: time cost, forward:0.010983736068756134, backward:0.05784527222076813, data cost:0.3663071509715434 
2022-04-03 13:20:52,601: ============================================================
2022-04-03 13:20:52,601: Epoch 5/26 Batch 1000/7662 eta: 20:33:58.972288	Training Loss 5.2616 (5.4352)	Training Prec@1 95.508 (96.289)	Training Prec@5 97.852 (98.275)	
2022-04-03 13:20:52,601: ============================================================
2022-04-03 13:21:36,327: time cost, forward:0.010961827849994691, backward:0.057870917584919954, data cost:0.36638655523694136 
2022-04-03 13:21:36,327: ============================================================
2022-04-03 13:21:36,327: Epoch 5/26 Batch 1100/7662 eta: 20:20:26.414792	Training Loss 5.7421 (5.4467)	Training Prec@1 94.922 (96.249)	Training Prec@5 98.438 (98.256)	
2022-04-03 13:21:36,327: ============================================================
2022-04-03 13:22:20,682: time cost, forward:0.011002969503203862, backward:0.05783115713868765, data cost:0.36706427418260995 
2022-04-03 13:22:20,683: ============================================================
2022-04-03 13:22:20,683: Epoch 5/26 Batch 1200/7662 eta: 20:37:16.621219	Training Loss 5.5748 (5.4579)	Training Prec@1 97.461 (96.220)	Training Prec@5 99.023 (98.239)	
2022-04-03 13:22:20,683: ============================================================
2022-04-03 13:23:04,374: time cost, forward:0.010986652623882103, backward:0.05784102693899858, data cost:0.36708624221619685 
2022-04-03 13:23:04,374: ============================================================
2022-04-03 13:23:04,374: Epoch 5/26 Batch 1300/7662 eta: 20:17:59.787813	Training Loss 5.6512 (5.4688)	Training Prec@1 94.922 (96.187)	Training Prec@5 97.461 (98.225)	
2022-04-03 13:23:04,375: ============================================================
2022-04-03 13:23:48,076: time cost, forward:0.011012866890711645, backward:0.05781280747305248, data cost:0.36714703786194197 
2022-04-03 13:23:48,077: ============================================================
2022-04-03 13:23:48,077: Epoch 5/26 Batch 1400/7662 eta: 20:17:35.336909	Training Loss 5.1749 (5.4790)	Training Prec@1 96.875 (96.155)	Training Prec@5 99.023 (98.209)	
2022-04-03 13:23:48,077: ============================================================
2022-04-03 13:24:31,507: time cost, forward:0.011062593600048552, backward:0.05775181351700491, data cost:0.366969007742731 
2022-04-03 13:24:31,507: ============================================================
2022-04-03 13:24:31,508: Epoch 5/26 Batch 1500/7662 eta: 20:09:17.550046	Training Loss 5.3160 (5.4845)	Training Prec@1 97.070 (96.125)	Training Prec@5 98.828 (98.194)	
2022-04-03 13:24:31,508: ============================================================
2022-04-03 13:25:14,091: time cost, forward:0.011051238962379823, backward:0.05776786043764726, data cost:0.36635360664095706 
2022-04-03 13:25:14,091: ============================================================
2022-04-03 13:25:14,091: Epoch 5/26 Batch 1600/7662 eta: 19:44:59.665618	Training Loss 5.6710 (5.4928)	Training Prec@1 95.312 (96.099)	Training Prec@5 97.461 (98.182)	
2022-04-03 13:25:14,091: ============================================================
2022-04-03 13:25:56,220: time cost, forward:0.011018570063042599, backward:0.057796399827702315, data cost:0.36547616581975745 
2022-04-03 13:25:56,221: ============================================================
2022-04-03 13:25:56,221: Epoch 5/26 Batch 1700/7662 eta: 19:31:39.571840	Training Loss 5.9992 (5.4999)	Training Prec@1 94.141 (96.079)	Training Prec@5 97.461 (98.172)	
2022-04-03 13:25:56,221: ============================================================
2022-04-03 13:26:40,009: time cost, forward:0.010998839467946128, backward:0.05780830841849021, data cost:0.36567641099735787 
2022-04-03 13:26:40,010: ============================================================
2022-04-03 13:26:40,010: Epoch 5/26 Batch 1800/7662 eta: 20:17:04.973214	Training Loss 5.5457 (5.5066)	Training Prec@1 95.312 (96.051)	Training Prec@5 98.438 (98.160)	
2022-04-03 13:26:40,010: ============================================================
2022-04-03 13:27:23,989: time cost, forward:0.010988579479376225, backward:0.05781957135192967, data cost:0.3659262328225729 
2022-04-03 13:27:23,989: ============================================================
2022-04-03 13:27:23,990: Epoch 5/26 Batch 1900/7662 eta: 20:21:38.708741	Training Loss 5.7151 (5.5108)	Training Prec@1 96.289 (96.034)	Training Prec@5 98.633 (98.150)	
2022-04-03 13:27:23,990: ============================================================
2022-04-03 13:28:07,943: time cost, forward:0.01098337788889562, backward:0.0578139812246211, data cost:0.3661421570198246 
2022-04-03 13:28:07,943: ============================================================
2022-04-03 13:28:07,944: Epoch 5/26 Batch 2000/7662 eta: 20:20:11.743409	Training Loss 5.6439 (5.5171)	Training Prec@1 96.875 (96.014)	Training Prec@5 97.852 (98.134)	
2022-04-03 13:28:07,944: ============================================================
2022-04-03 13:28:49,920: time cost, forward:0.010954876750239081, backward:0.05784125212205484, data cost:0.3654063068269945 
2022-04-03 13:28:49,921: ============================================================
2022-04-03 13:28:49,921: Epoch 5/26 Batch 2100/7662 eta: 19:24:37.810386	Training Loss 5.6616 (5.5217)	Training Prec@1 95.898 (96.000)	Training Prec@5 98.242 (98.124)	
2022-04-03 13:28:49,921: ============================================================
2022-04-03 13:29:31,377: time cost, forward:0.010928035920833988, backward:0.0578803677838626, data cost:0.3644993655407304 
2022-04-03 13:29:31,378: ============================================================
2022-04-03 13:29:31,378: Epoch 5/26 Batch 2200/7662 eta: 19:09:29.551350	Training Loss 5.5928 (5.5256)	Training Prec@1 95.703 (95.988)	Training Prec@5 98.242 (98.115)	
2022-04-03 13:29:31,378: ============================================================
2022-04-03 13:30:14,431: time cost, forward:0.011023088764656934, backward:0.057790310396324714, data cost:0.36431844662769614 
2022-04-03 13:30:14,431: ============================================================
2022-04-03 13:30:14,431: Epoch 5/26 Batch 2300/7662 eta: 19:53:03.135154	Training Loss 5.4582 (5.5289)	Training Prec@1 95.703 (95.981)	Training Prec@5 98.438 (98.113)	
2022-04-03 13:30:14,432: ============================================================
2022-04-03 13:30:58,706: time cost, forward:0.011010708238443467, backward:0.057798242509340236, data cost:0.364657490488985 
2022-04-03 13:30:58,706: ============================================================
2022-04-03 13:30:58,707: Epoch 5/26 Batch 2400/7662 eta: 20:26:09.964339	Training Loss 5.6022 (5.5315)	Training Prec@1 95.898 (95.974)	Training Prec@5 98.242 (98.110)	
2022-04-03 13:30:58,707: ============================================================
2022-04-03 13:31:42,376: time cost, forward:0.011002972680313581, backward:0.05780211931803361, data cost:0.3648258863138456 
2022-04-03 13:31:42,377: ============================================================
2022-04-03 13:31:42,377: Epoch 5/26 Batch 2500/7662 eta: 20:08:41.255540	Training Loss 5.7120 (5.5332)	Training Prec@1 96.289 (95.963)	Training Prec@5 98.047 (98.102)	
2022-04-03 13:31:42,377: ============================================================
2022-04-03 13:32:25,671: time cost, forward:0.010990263269974113, backward:0.05780787796366898, data cost:0.36476779231753614 
2022-04-03 13:32:25,671: ============================================================
2022-04-03 13:32:25,672: Epoch 5/26 Batch 2600/7662 eta: 19:57:33.575059	Training Loss 5.8279 (5.5347)	Training Prec@1 94.531 (95.962)	Training Prec@5 97.461 (98.103)	
2022-04-03 13:32:25,672: ============================================================
2022-04-03 13:33:09,427: time cost, forward:0.010972296498183102, backward:0.05781691831409953, data cost:0.36489261791148686 
2022-04-03 13:33:09,428: ============================================================
2022-04-03 13:33:09,428: Epoch 5/26 Batch 2700/7662 eta: 20:09:36.316954	Training Loss 5.3917 (5.5364)	Training Prec@1 96.094 (95.954)	Training Prec@5 97.656 (98.098)	
2022-04-03 13:33:09,428: ============================================================
2022-04-03 13:33:53,197: time cost, forward:0.010964111414667792, backward:0.05781739079215434, data cost:0.3650186942619441 
2022-04-03 13:33:53,197: ============================================================
2022-04-03 13:33:53,198: Epoch 5/26 Batch 2800/7662 eta: 20:09:15.032596	Training Loss 5.8014 (5.5378)	Training Prec@1 94.531 (95.944)	Training Prec@5 97.461 (98.093)	
2022-04-03 13:33:53,198: ============================================================
2022-04-03 13:34:37,695: time cost, forward:0.010946050024147731, backward:0.05783388194399647, data cost:0.3654119538290413 
2022-04-03 13:34:37,696: ============================================================
2022-04-03 13:34:37,696: Epoch 5/26 Batch 2900/7662 eta: 20:28:38.056683	Training Loss 5.5880 (5.5400)	Training Prec@1 95.508 (95.935)	Training Prec@5 97.266 (98.089)	
2022-04-03 13:34:37,696: ============================================================
2022-04-03 13:35:20,310: time cost, forward:0.01096481782430488, backward:0.05782420017513366, data cost:0.3651102035989281 
2022-04-03 13:35:20,310: ============================================================
2022-04-03 13:35:20,310: Epoch 5/26 Batch 3000/7662 eta: 19:35:54.761738	Training Loss 5.5947 (5.5412)	Training Prec@1 95.508 (95.928)	Training Prec@5 97.656 (98.081)	
2022-04-03 13:35:20,311: ============================================================
2022-04-03 13:36:04,259: time cost, forward:0.010964440237748773, backward:0.057831581272052617, data cost:0.36524858317786013 
2022-04-03 13:36:04,259: ============================================================
2022-04-03 13:36:04,259: Epoch 5/26 Batch 3100/7662 eta: 20:12:00.147956	Training Loss 5.6552 (5.5429)	Training Prec@1 95.898 (95.923)	Training Prec@5 98.438 (98.077)	
2022-04-03 13:36:04,259: ============================================================
2022-04-03 13:36:47,818: time cost, forward:0.01096663336412502, backward:0.05783736620071569, data cost:0.36528885144671636 
2022-04-03 13:36:47,819: ============================================================
2022-04-03 13:36:47,819: Epoch 5/26 Batch 3200/7662 eta: 20:00:32.756955	Training Loss 5.6196 (5.5438)	Training Prec@1 95.508 (95.914)	Training Prec@5 97.852 (98.070)	
2022-04-03 13:36:47,820: ============================================================
2022-04-03 13:37:31,214: time cost, forward:0.010964843351648013, backward:0.05783771189388704, data cost:0.3652694418994757 
2022-04-03 13:37:31,215: ============================================================
2022-04-03 13:37:31,215: Epoch 5/26 Batch 3300/7662 eta: 19:55:17.977251	Training Loss 5.7157 (5.5460)	Training Prec@1 95.312 (95.903)	Training Prec@5 97.852 (98.066)	
2022-04-03 13:37:31,215: ============================================================
2022-04-03 13:38:15,103: time cost, forward:0.01095961044381106, backward:0.05784381905454999, data cost:0.3654084786417625 
2022-04-03 13:38:15,104: ============================================================
2022-04-03 13:38:15,104: Epoch 5/26 Batch 3400/7662 eta: 20:08:09.362045	Training Loss 5.9418 (5.5470)	Training Prec@1 95.312 (95.898)	Training Prec@5 98.633 (98.065)	
2022-04-03 13:38:15,104: ============================================================
2022-04-03 13:38:56,403: time cost, forward:0.010956968774656529, backward:0.057844748732770436, data cost:0.3647805709571762 
2022-04-03 13:38:56,404: ============================================================
2022-04-03 13:38:56,404: Epoch 5/26 Batch 3500/7662 eta: 18:56:11.527724	Training Loss 5.6475 (5.5479)	Training Prec@1 94.141 (95.893)	Training Prec@5 97.266 (98.061)	
2022-04-03 13:38:56,404: ============================================================
2022-04-03 13:39:37,902: time cost, forward:0.010958022559871605, backward:0.05785336604413804, data cost:0.3642300011284254 
2022-04-03 13:39:37,902: ============================================================
2022-04-03 13:39:37,902: Epoch 5/26 Batch 3600/7662 eta: 19:00:58.046721	Training Loss 5.4618 (5.5498)	Training Prec@1 95.117 (95.885)	Training Prec@5 98.438 (98.056)	
2022-04-03 13:39:37,903: ============================================================
2022-04-03 13:40:21,585: time cost, forward:0.01096102636419267, backward:0.05785186776086168, data cost:0.3643156985200138 
2022-04-03 13:40:21,586: ============================================================
2022-04-03 13:40:21,586: Epoch 5/26 Batch 3700/7662 eta: 20:00:19.359731	Training Loss 5.3600 (5.5508)	Training Prec@1 96.484 (95.880)	Training Prec@5 97.461 (98.054)	
2022-04-03 13:40:21,586: ============================================================
2022-04-03 13:41:05,541: time cost, forward:0.010957989262166417, backward:0.05786010383712395, data cost:0.3644668097620294 
2022-04-03 13:41:05,541: ============================================================
2022-04-03 13:41:05,542: Epoch 5/26 Batch 3800/7662 eta: 20:07:03.055869	Training Loss 5.4881 (5.5516)	Training Prec@1 95.312 (95.873)	Training Prec@5 98.438 (98.051)	
2022-04-03 13:41:05,542: ============================================================
2022-04-03 13:41:47,436: time cost, forward:0.010958365704286217, backward:0.05786581478476004, data cost:0.3640986626256457 
2022-04-03 13:41:47,436: ============================================================
2022-04-03 13:41:47,437: Epoch 5/26 Batch 3900/7662 eta: 19:09:46.432341	Training Loss 5.5442 (5.5524)	Training Prec@1 95.898 (95.869)	Training Prec@5 98.242 (98.049)	
2022-04-03 13:41:47,437: ============================================================
2022-04-03 13:42:28,051: time cost, forward:0.01096264598786339, backward:0.05786929711248613, data cost:0.36338498157750193 
2022-04-03 13:42:28,051: ============================================================
2022-04-03 13:42:28,051: Epoch 5/26 Batch 4000/7662 eta: 18:33:57.629052	Training Loss 5.7208 (5.5537)	Training Prec@1 96.094 (95.864)	Training Prec@5 97.656 (98.045)	
2022-04-03 13:42:28,051: ============================================================
2022-04-03 13:43:09,788: time cost, forward:0.01098943815256916, backward:0.057850150720001166, data cost:0.3630024717912118 
2022-04-03 13:43:09,788: ============================================================
2022-04-03 13:43:09,788: Epoch 5/26 Batch 4100/7662 eta: 19:04:02.769971	Training Loss 5.5218 (5.5544)	Training Prec@1 95.508 (95.858)	Training Prec@5 98.047 (98.042)	
2022-04-03 13:43:09,789: ============================================================
2022-04-03 13:43:53,465: time cost, forward:0.010987569275683635, backward:0.0578528106936559, data cost:0.3631135507775761 
2022-04-03 13:43:53,466: ============================================================
2022-04-03 13:43:53,466: Epoch 5/26 Batch 4200/7662 eta: 19:56:30.909673	Training Loss 5.5561 (5.5547)	Training Prec@1 95.898 (95.856)	Training Prec@5 97.852 (98.040)	
2022-04-03 13:43:53,466: ============================================================
2022-04-03 13:44:34,998: time cost, forward:0.010990538190037296, backward:0.05785321973040648, data cost:0.3627063188200137 
2022-04-03 13:44:34,998: ============================================================
2022-04-03 13:44:34,999: Epoch 5/26 Batch 4300/7662 eta: 18:57:03.401902	Training Loss 5.5819 (5.5559)	Training Prec@1 94.922 (95.850)	Training Prec@5 97.852 (98.038)	
2022-04-03 13:44:34,999: ============================================================
2022-04-03 13:45:16,120: time cost, forward:0.010990525029089863, backward:0.057862061320393975, data cost:0.36222632702547575 
2022-04-03 13:45:16,120: ============================================================
2022-04-03 13:45:16,121: Epoch 5/26 Batch 4400/7662 eta: 18:45:07.890560	Training Loss 5.5766 (5.5561)	Training Prec@1 95.703 (95.847)	Training Prec@5 98.242 (98.035)	
2022-04-03 13:45:16,121: ============================================================
2022-04-03 13:45:59,680: time cost, forward:0.010988707435372193, backward:0.05786402916002072, data cost:0.36231507945521774 
2022-04-03 13:45:59,681: ============================================================
2022-04-03 13:45:59,681: Epoch 5/26 Batch 4500/7662 eta: 19:51:07.030747	Training Loss 5.4545 (5.5564)	Training Prec@1 96.289 (95.843)	Training Prec@5 98.828 (98.033)	
2022-04-03 13:45:59,681: ============================================================
2022-04-03 13:46:43,771: time cost, forward:0.010996080321004843, backward:0.05786069856308989, data cost:0.36250002390925173 
2022-04-03 13:46:43,772: ============================================================
2022-04-03 13:46:43,772: Epoch 5/26 Batch 4600/7662 eta: 20:04:53.808281	Training Loss 5.5992 (5.5569)	Training Prec@1 95.117 (95.838)	Training Prec@5 96.875 (98.031)	
2022-04-03 13:46:43,772: ============================================================
2022-04-03 13:47:26,384: time cost, forward:0.010992916727806817, backward:0.05786666131369685, data cost:0.3623812039321117 
2022-04-03 13:47:26,385: ============================================================
2022-04-03 13:47:26,385: Epoch 5/26 Batch 4700/7662 eta: 19:23:48.220112	Training Loss 5.6272 (5.5571)	Training Prec@1 95.508 (95.838)	Training Prec@5 97.852 (98.030)	
2022-04-03 13:47:26,385: ============================================================
2022-04-03 13:48:08,685: time cost, forward:0.010998130863123722, backward:0.05786227280707577, data cost:0.3622010034877923 
2022-04-03 13:48:08,685: ============================================================
2022-04-03 13:48:08,686: Epoch 5/26 Batch 4800/7662 eta: 19:14:33.313733	Training Loss 5.2129 (5.5563)	Training Prec@1 95.898 (95.837)	Training Prec@5 99.023 (98.029)	
2022-04-03 13:48:08,686: ============================================================
2022-04-03 13:48:52,086: time cost, forward:0.010995121239691175, backward:0.057865836031949384, data cost:0.36224694504108107 
2022-04-03 13:48:52,087: ============================================================
2022-04-03 13:48:52,087: Epoch 5/26 Batch 4900/7662 eta: 19:43:53.219475	Training Loss 5.5269 (5.5563)	Training Prec@1 96.484 (95.834)	Training Prec@5 98.047 (98.027)	
2022-04-03 13:48:52,087: ============================================================
2022-04-03 13:49:35,610: time cost, forward:0.010992839732726209, backward:0.05787254338456192, data cost:0.36232685150921784 
2022-04-03 13:49:35,610: ============================================================
2022-04-03 13:49:35,610: Epoch 5/26 Batch 5000/7662 eta: 19:46:28.503755	Training Loss 5.6301 (5.5565)	Training Prec@1 94.727 (95.829)	Training Prec@5 98.047 (98.025)	
2022-04-03 13:49:35,610: ============================================================
2022-04-03 13:50:17,324: time cost, forward:0.010994166714417091, backward:0.057872949616304445, data cost:0.3620426701106004 
2022-04-03 13:50:17,324: ============================================================
2022-04-03 13:50:17,324: Epoch 5/26 Batch 5100/7662 eta: 18:56:28.201244	Training Loss 5.5178 (5.5563)	Training Prec@1 95.703 (95.830)	Training Prec@5 97.656 (98.025)	
2022-04-03 13:50:17,325: ============================================================
2022-04-03 13:50:59,150: time cost, forward:0.010990148921452203, backward:0.057877431124030314, data cost:0.36178023490935113 
2022-04-03 13:50:59,151: ============================================================
2022-04-03 13:50:59,151: Epoch 5/26 Batch 5200/7662 eta: 18:58:49.973020	Training Loss 5.4653 (5.5566)	Training Prec@1 96.484 (95.828)	Training Prec@5 98.242 (98.024)	
2022-04-03 13:50:59,151: ============================================================
2022-04-03 13:51:43,867: time cost, forward:0.011002762134535445, backward:0.057864363496315706, data cost:0.36206710691788574 
2022-04-03 13:51:43,868: ============================================================
2022-04-03 13:51:43,869: Epoch 5/26 Batch 5300/7662 eta: 20:16:48.398844	Training Loss 5.3070 (5.5567)	Training Prec@1 95.508 (95.826)	Training Prec@5 97.266 (98.023)	
2022-04-03 13:51:43,869: ============================================================
2022-04-03 13:52:27,690: time cost, forward:0.011002494750541323, backward:0.057863675569865325, data cost:0.36219594447253745 
2022-04-03 13:52:27,691: ============================================================
2022-04-03 13:52:27,691: Epoch 5/26 Batch 5400/7662 eta: 19:51:42.566641	Training Loss 5.8526 (5.5575)	Training Prec@1 93.945 (95.821)	Training Prec@5 97.852 (98.021)	
2022-04-03 13:52:27,691: ============================================================
2022-04-03 13:53:12,176: time cost, forward:0.010998377649973558, backward:0.05786436218460119, data cost:0.36242890683146556 
2022-04-03 13:53:12,177: ============================================================
2022-04-03 13:53:12,177: Epoch 5/26 Batch 5500/7662 eta: 20:09:00.839407	Training Loss 5.2780 (5.5579)	Training Prec@1 97.461 (95.820)	Training Prec@5 98.633 (98.022)	
2022-04-03 13:53:12,177: ============================================================
2022-04-03 13:53:54,446: time cost, forward:0.010995224855439667, backward:0.057866143464914366, data cost:0.3622911204225486 
2022-04-03 13:53:54,447: ============================================================
2022-04-03 13:53:54,447: Epoch 5/26 Batch 5600/7662 eta: 19:08:05.924411	Training Loss 5.4488 (5.5583)	Training Prec@1 97.461 (95.819)	Training Prec@5 98.828 (98.021)	
2022-04-03 13:53:54,447: ============================================================
2022-04-03 13:54:38,232: time cost, forward:0.011042098953841464, backward:0.05782376722110575, data cost:0.3623885639844641 
2022-04-03 13:54:38,232: ============================================================
2022-04-03 13:54:38,232: Epoch 5/26 Batch 5700/7662 eta: 19:48:30.786365	Training Loss 5.4150 (5.5584)	Training Prec@1 97.070 (95.819)	Training Prec@5 99.219 (98.022)	
2022-04-03 13:54:38,233: ============================================================
2022-04-03 13:55:22,498: time cost, forward:0.011040237077784386, backward:0.05782544088684335, data cost:0.362584988070595 
2022-04-03 13:55:22,498: ============================================================
2022-04-03 13:55:22,498: Epoch 5/26 Batch 5800/7662 eta: 20:00:49.469579	Training Loss 5.7799 (5.5584)	Training Prec@1 94.141 (95.815)	Training Prec@5 97.656 (98.020)	
2022-04-03 13:55:22,499: ============================================================
2022-04-03 13:56:06,902: time cost, forward:0.011046551833578763, backward:0.05781968805138833, data cost:0.36277967187222193 
2022-04-03 13:56:06,903: ============================================================
2022-04-03 13:56:06,903: Epoch 5/26 Batch 5900/7662 eta: 20:03:50.954575	Training Loss 5.5173 (5.5586)	Training Prec@1 95.117 (95.812)	Training Prec@5 98.438 (98.018)	
2022-04-03 13:56:06,903: ============================================================
2022-04-03 13:56:51,165: time cost, forward:0.011073636539698959, backward:0.05779053183630479, data cost:0.36294929542865806 
2022-04-03 13:56:51,166: ============================================================
2022-04-03 13:56:51,166: Epoch 5/26 Batch 6000/7662 eta: 19:59:15.716524	Training Loss 5.4622 (5.5587)	Training Prec@1 95.508 (95.809)	Training Prec@5 98.242 (98.017)	
2022-04-03 13:56:51,166: ============================================================
2022-04-03 13:57:35,244: time cost, forward:0.011069881073626012, backward:0.05779436741291177, data cost:0.36309145997637393 
2022-04-03 13:57:35,244: ============================================================
2022-04-03 13:57:35,245: Epoch 5/26 Batch 6100/7662 eta: 19:53:32.788919	Training Loss 5.8472 (5.5583)	Training Prec@1 93.945 (95.810)	Training Prec@5 96.289 (98.017)	
2022-04-03 13:57:35,245: ============================================================
2022-04-03 13:58:17,788: time cost, forward:0.011069348289574668, backward:0.05779535529266963, data cost:0.36298233867749263 
2022-04-03 13:58:17,789: ============================================================
2022-04-03 13:58:17,789: Epoch 5/26 Batch 6200/7662 eta: 19:11:16.673845	Training Loss 5.8381 (5.5585)	Training Prec@1 93.945 (95.810)	Training Prec@5 97.266 (98.018)	
2022-04-03 13:58:17,789: ============================================================
2022-04-03 13:58:58,627: time cost, forward:0.011068188778879832, backward:0.057794690491718266, data cost:0.3626060171304458 
2022-04-03 13:58:58,627: ============================================================
2022-04-03 13:58:58,627: Epoch 5/26 Batch 6300/7662 eta: 18:24:26.500761	Training Loss 5.7348 (5.5586)	Training Prec@1 96.094 (95.808)	Training Prec@5 98.242 (98.017)	
2022-04-03 13:58:58,627: ============================================================
2022-04-03 13:59:41,148: time cost, forward:0.011060585061317869, backward:0.05780482977735827, data cost:0.36249139465788677 
2022-04-03 13:59:41,148: ============================================================
2022-04-03 13:59:41,148: Epoch 5/26 Batch 6400/7662 eta: 19:09:14.177955	Training Loss 5.6532 (5.5582)	Training Prec@1 96.094 (95.806)	Training Prec@5 99.414 (98.017)	
2022-04-03 13:59:41,148: ============================================================
2022-04-03 14:00:23,220: time cost, forward:0.01107518503089596, backward:0.0577923750800341, data cost:0.3623236165558087 
2022-04-03 14:00:23,221: ============================================================
2022-04-03 14:00:23,221: Epoch 5/26 Batch 6500/7662 eta: 18:56:25.154523	Training Loss 5.5750 (5.5579)	Training Prec@1 94.727 (95.805)	Training Prec@5 97.656 (98.015)	
2022-04-03 14:00:23,221: ============================================================
2022-04-03 14:01:06,579: time cost, forward:0.011070224656753783, backward:0.05779986353349751, data cost:0.36235326477064655 
2022-04-03 14:01:06,580: ============================================================
2022-04-03 14:01:06,580: Epoch 5/26 Batch 6600/7662 eta: 19:30:26.040540	Training Loss 5.6266 (5.5580)	Training Prec@1 95.898 (95.802)	Training Prec@5 97.656 (98.013)	
2022-04-03 14:01:06,580: ============================================================
2022-04-03 14:01:50,813: time cost, forward:0.011088659770810118, backward:0.05777869841681966, data cost:0.36250178343076317 
2022-04-03 14:01:50,813: ============================================================
2022-04-03 14:01:50,814: Epoch 5/26 Batch 6700/7662 eta: 19:53:19.151408	Training Loss 5.7435 (5.5577)	Training Prec@1 95.508 (95.801)	Training Prec@5 97.656 (98.013)	
2022-04-03 14:01:50,814: ============================================================
2022-04-03 14:02:34,208: time cost, forward:0.011086993400516502, backward:0.05778063979459556, data cost:0.36253402380053307 
2022-04-03 14:02:34,208: ============================================================
2022-04-03 14:02:34,208: Epoch 5/26 Batch 6800/7662 eta: 19:29:57.235213	Training Loss 5.5118 (5.5577)	Training Prec@1 96.289 (95.800)	Training Prec@5 98.828 (98.012)	
2022-04-03 14:02:34,208: ============================================================
2022-04-03 14:03:18,172: time cost, forward:0.011082058350993924, backward:0.05778491298328847, data cost:0.3626459483599936 
2022-04-03 14:03:18,173: ============================================================
2022-04-03 14:03:18,173: Epoch 5/26 Batch 6900/7662 eta: 19:44:35.294798	Training Loss 5.6591 (5.5573)	Training Prec@1 95.898 (95.800)	Training Prec@5 98.438 (98.012)	
2022-04-03 14:03:18,173: ============================================================
2022-04-03 14:04:02,666: time cost, forward:0.011097794550625763, backward:0.0577741168297807, data cost:0.3628275014278054 
2022-04-03 14:04:02,667: ============================================================
2022-04-03 14:04:02,667: Epoch 5/26 Batch 7000/7662 eta: 19:58:07.520309	Training Loss 5.6267 (5.5567)	Training Prec@1 96.094 (95.799)	Training Prec@5 97.656 (98.013)	
2022-04-03 14:04:02,667: ============================================================
2022-04-03 14:04:47,391: time cost, forward:0.011097582180175265, backward:0.05777509818028054, data cost:0.3630391292663372 
2022-04-03 14:04:47,391: ============================================================
2022-04-03 14:04:47,392: Epoch 5/26 Batch 7100/7662 eta: 20:03:34.055814	Training Loss 5.5597 (5.5562)	Training Prec@1 95.703 (95.799)	Training Prec@5 97.461 (98.013)	
2022-04-03 14:04:47,392: ============================================================
2022-04-03 14:05:31,373: time cost, forward:0.011097485629332233, backward:0.057779237849461665, data cost:0.36313363061479137 
2022-04-03 14:05:31,374: ============================================================
2022-04-03 14:05:31,374: Epoch 5/26 Batch 7200/7662 eta: 19:42:52.035387	Training Loss 5.6113 (5.5557)	Training Prec@1 94.531 (95.799)	Training Prec@5 97.852 (98.013)	
2022-04-03 14:05:31,374: ============================================================
2022-04-03 14:06:16,431: time cost, forward:0.011106519539693657, backward:0.057773029825461696, data cost:0.36337731452588595 
2022-04-03 14:06:16,432: ============================================================
2022-04-03 14:06:16,432: Epoch 5/26 Batch 7300/7662 eta: 20:11:02.921872	Training Loss 5.2569 (5.5560)	Training Prec@1 95.898 (95.797)	Training Prec@5 98.047 (98.012)	
2022-04-03 14:06:16,432: ============================================================
2022-04-03 14:06:59,195: time cost, forward:0.011103991286660194, backward:0.057773842265725475, data cost:0.363314340655619 
2022-04-03 14:06:59,196: ============================================================
2022-04-03 14:06:59,196: Epoch 5/26 Batch 7400/7662 eta: 19:08:40.410299	Training Loss 5.4965 (5.5555)	Training Prec@1 95.117 (95.797)	Training Prec@5 98.828 (98.012)	
2022-04-03 14:06:59,196: ============================================================
2022-04-03 14:07:40,398: time cost, forward:0.011092789635084076, backward:0.05778602689627823, data cost:0.36304525728781456 
2022-04-03 14:07:40,398: ============================================================
2022-04-03 14:07:40,398: Epoch 5/26 Batch 7500/7662 eta: 18:26:02.574853	Training Loss 5.6599 (5.5558)	Training Prec@1 95.898 (95.794)	Training Prec@5 97.656 (98.010)	
2022-04-03 14:07:40,398: ============================================================
2022-04-03 14:08:21,799: time cost, forward:0.011106200713298089, backward:0.05777339860630249, data cost:0.36279148640703535 
2022-04-03 14:08:21,799: ============================================================
2022-04-03 14:08:21,800: Epoch 5/26 Batch 7600/7662 eta: 18:30:41.585200	Training Loss 5.6297 (5.5556)	Training Prec@1 96.875 (95.795)	Training Prec@5 99.219 (98.013)	
2022-04-03 14:08:21,800: ============================================================
2022-04-03 14:08:49,649: Epoch: 5/26 eta: 18:30:15.502388	Training Loss 5.4066 (5.5555)	Training Prec@1 97.070 (95.795)	Training Prec@5 98.047 (98.013)
2022-04-03 14:08:49,649: ============================================================
2022-04-03 14:08:49,732: Save Checkpoint...
2022-04-03 14:08:49,732: ============================================================
2022-04-03 14:08:52,606: Save done!
2022-04-03 14:08:52,606: ============================================================
2022-04-03 14:09:33,915: time cost, forward:0.010816735450667565, backward:0.0578816370530562, data cost:0.3443107653145838 
2022-04-03 14:09:33,915: ============================================================
2022-04-03 14:09:33,915: Epoch 6/26 Batch 100/7662 eta: 18:27:04.321657	Training Loss 5.3490 (5.1198)	Training Prec@1 97.266 (96.603)	Training Prec@5 99.023 (98.400)	
2022-04-03 14:09:33,915: ============================================================
2022-04-03 14:10:17,819: time cost, forward:0.010855369232407767, backward:0.05788616559014249, data cost:0.35690531299341866 
2022-04-03 14:10:17,820: ============================================================
2022-04-03 14:10:17,820: Epoch 6/26 Batch 200/7662 eta: 19:35:56.513405	Training Loss 5.2773 (5.1569)	Training Prec@1 96.094 (96.608)	Training Prec@5 97.461 (98.418)	
2022-04-03 14:10:17,820: ============================================================
2022-04-03 14:11:01,172: time cost, forward:0.011024239868623357, backward:0.057898009501173346, data cost:0.3592980091388409 
2022-04-03 14:11:01,172: ============================================================
2022-04-03 14:11:01,173: Epoch 6/26 Batch 300/7662 eta: 19:20:25.266563	Training Loss 5.2402 (5.1855)	Training Prec@1 96.875 (96.552)	Training Prec@5 98.242 (98.422)	
2022-04-03 14:11:01,173: ============================================================
2022-04-03 14:11:46,046: time cost, forward:0.010921258376654527, backward:0.05798214599303434, data cost:0.3642454177215882 
2022-04-03 14:11:46,047: ============================================================
2022-04-03 14:11:46,047: Epoch 6/26 Batch 400/7662 eta: 20:00:24.886649	Training Loss 5.0649 (5.2146)	Training Prec@1 97.070 (96.502)	Training Prec@5 99.414 (98.391)	
2022-04-03 14:11:46,047: ============================================================
2022-04-03 14:12:30,374: time cost, forward:0.011030643401977295, backward:0.057876464121327374, data cost:0.3661931272976862 
2022-04-03 14:12:30,374: ============================================================
2022-04-03 14:12:30,375: Epoch 6/26 Batch 500/7662 eta: 19:45:02.540179	Training Loss 5.4719 (5.2514)	Training Prec@1 96.484 (96.461)	Training Prec@5 98.047 (98.359)	
2022-04-03 14:12:30,375: ============================================================
2022-04-03 14:13:15,194: time cost, forward:0.011005204587627531, backward:0.05795961071135405, data cost:0.3682536585303101 
2022-04-03 14:13:15,195: ============================================================
2022-04-03 14:13:15,195: Epoch 6/26 Batch 600/7662 eta: 19:57:28.463010	Training Loss 5.3795 (5.2704)	Training Prec@1 97.070 (96.458)	Training Prec@5 98.633 (98.369)	
2022-04-03 14:13:15,195: ============================================================
2022-04-03 14:13:58,012: time cost, forward:0.010970386824382733, backward:0.05797544603525143, data cost:0.3669173168351551 
2022-04-03 14:13:58,012: ============================================================
2022-04-03 14:13:58,013: Epoch 6/26 Batch 700/7662 eta: 19:03:15.143151	Training Loss 5.4909 (5.2880)	Training Prec@1 95.117 (96.423)	Training Prec@5 97.852 (98.352)	
2022-04-03 14:13:58,013: ============================================================
2022-04-03 14:14:41,431: time cost, forward:0.010949139600999663, backward:0.05799800493242743, data cost:0.36664264789958473 
2022-04-03 14:14:41,431: ============================================================
2022-04-03 14:14:41,432: Epoch 6/26 Batch 800/7662 eta: 19:18:35.209603	Training Loss 5.3954 (5.3100)	Training Prec@1 95.508 (96.374)	Training Prec@5 98.047 (98.321)	
2022-04-03 14:14:41,432: ============================================================
2022-04-03 14:15:24,273: time cost, forward:0.010914636003029625, backward:0.05802116935059544, data cost:0.3657680228766928 
2022-04-03 14:15:24,274: ============================================================
2022-04-03 14:15:24,274: Epoch 6/26 Batch 900/7662 eta: 19:02:28.856068	Training Loss 5.4277 (5.3250)	Training Prec@1 96.094 (96.346)	Training Prec@5 97.266 (98.311)	
2022-04-03 14:15:24,274: ============================================================
2022-04-03 14:16:06,685: time cost, forward:0.010842681050419927, backward:0.058075025632932736, data cost:0.36471396141701395 
2022-04-03 14:16:06,685: ============================================================
2022-04-03 14:16:06,685: Epoch 6/26 Batch 1000/7662 eta: 18:50:17.110600	Training Loss 5.1593 (5.3383)	Training Prec@1 97.266 (96.310)	Training Prec@5 98.438 (98.294)	
2022-04-03 14:16:06,686: ============================================================
2022-04-03 14:16:48,498: time cost, forward:0.010865486568489109, backward:0.058034396366817065, data cost:0.36320609000729254 
2022-04-03 14:16:48,499: ============================================================
2022-04-03 14:16:48,499: Epoch 6/26 Batch 1100/7662 eta: 18:33:39.113370	Training Loss 5.8368 (5.3519)	Training Prec@1 96.484 (96.277)	Training Prec@5 97.656 (98.276)	
2022-04-03 14:16:48,499: ============================================================
2022-04-03 14:17:32,933: time cost, forward:0.010878870942574724, backward:0.058009936075791205, data cost:0.3642152886871898 
2022-04-03 14:17:32,934: ============================================================
2022-04-03 14:17:32,934: Epoch 6/26 Batch 1200/7662 eta: 19:42:44.526756	Training Loss 5.3144 (5.3639)	Training Prec@1 96.289 (96.246)	Training Prec@5 98.242 (98.258)	
2022-04-03 14:17:32,934: ============================================================
2022-04-03 14:18:17,021: time cost, forward:0.010920000223126019, backward:0.05796781680141622, data cost:0.36476001967091665 
2022-04-03 14:18:17,022: ============================================================
2022-04-03 14:18:17,022: Epoch 6/26 Batch 1300/7662 eta: 19:32:45.233436	Training Loss 5.8974 (5.3731)	Training Prec@1 93.359 (96.228)	Training Prec@5 96.484 (98.256)	
2022-04-03 14:18:17,022: ============================================================
2022-04-03 14:19:01,179: time cost, forward:0.010915020689783648, backward:0.05797040794814289, data cost:0.36529469796808556 
2022-04-03 14:19:01,180: ============================================================
2022-04-03 14:19:01,180: Epoch 6/26 Batch 1400/7662 eta: 19:33:53.289474	Training Loss 5.3418 (5.3814)	Training Prec@1 95.312 (96.208)	Training Prec@5 98.047 (98.243)	
2022-04-03 14:19:01,180: ============================================================
2022-04-03 14:19:45,755: time cost, forward:0.010876825763989958, backward:0.05799483203188112, data cost:0.36604496667669806 
2022-04-03 14:19:45,755: ============================================================
2022-04-03 14:19:45,756: Epoch 6/26 Batch 1500/7662 eta: 19:44:15.333022	Training Loss 5.1567 (5.3903)	Training Prec@1 97.852 (96.186)	Training Prec@5 99.219 (98.235)	
2022-04-03 14:19:45,756: ============================================================
2022-04-03 14:20:30,529: time cost, forward:0.010872274432203186, backward:0.0579936581898511, data cost:0.3668118401420646 
2022-04-03 14:20:30,529: ============================================================
2022-04-03 14:20:30,529: Epoch 6/26 Batch 1600/7662 eta: 19:48:45.570429	Training Loss 5.4409 (5.3961)	Training Prec@1 94.922 (96.167)	Training Prec@5 97.656 (98.222)	
2022-04-03 14:20:30,529: ============================================================
2022-04-03 14:21:13,475: time cost, forward:0.010870254902786336, backward:0.05800640632153399, data cost:0.3664047144103429 
2022-04-03 14:21:13,476: ============================================================
2022-04-03 14:21:13,476: Epoch 6/26 Batch 1700/7662 eta: 18:59:32.880948	Training Loss 5.3720 (5.4014)	Training Prec@1 95.312 (96.152)	Training Prec@5 98.242 (98.218)	
2022-04-03 14:21:13,476: ============================================================
2022-04-03 14:21:56,820: time cost, forward:0.010854384447217584, backward:0.05801386963068743, data cost:0.3662696058316785 
2022-04-03 14:21:56,820: ============================================================
2022-04-03 14:21:56,821: Epoch 6/26 Batch 1800/7662 eta: 19:09:22.254275	Training Loss 5.3439 (5.4065)	Training Prec@1 96.484 (96.137)	Training Prec@5 98.828 (98.205)	
2022-04-03 14:21:56,821: ============================================================
2022-04-03 14:22:41,105: time cost, forward:0.010822874800414396, backward:0.05804252498962177, data cost:0.3666500078495582 
2022-04-03 14:22:41,106: ============================================================
2022-04-03 14:22:41,106: Epoch 6/26 Batch 1900/7662 eta: 19:33:34.837687	Training Loss 5.5085 (5.4124)	Training Prec@1 95.508 (96.116)	Training Prec@5 99.023 (98.198)	
2022-04-03 14:22:41,106: ============================================================
2022-04-03 14:23:24,221: time cost, forward:0.010800266456699419, backward:0.058061706834939074, data cost:0.3664244615536681 
2022-04-03 14:23:24,221: ============================================================
2022-04-03 14:23:24,222: Epoch 6/26 Batch 2000/7662 eta: 19:01:52.475688	Training Loss 5.8093 (5.4166)	Training Prec@1 96.094 (96.110)	Training Prec@5 98.438 (98.195)	
2022-04-03 14:23:24,222: ============================================================
2022-04-03 14:24:08,907: time cost, forward:0.010782608706477485, backward:0.05808581574409561, data cost:0.36694288935304653 
2022-04-03 14:24:08,908: ============================================================
2022-04-03 14:24:08,908: Epoch 6/26 Batch 2100/7662 eta: 19:42:42.768953	Training Loss 5.4814 (5.4198)	Training Prec@1 94.727 (96.097)	Training Prec@5 97.656 (98.183)	
2022-04-03 14:24:08,908: ============================================================
2022-04-03 14:24:53,436: time cost, forward:0.010782670844625808, backward:0.058080486407763525, data cost:0.367342096613233 
2022-04-03 14:24:53,436: ============================================================
2022-04-03 14:24:53,436: Epoch 6/26 Batch 2200/7662 eta: 19:37:48.404130	Training Loss 5.6151 (5.4244)	Training Prec@1 95.312 (96.079)	Training Prec@5 97.656 (98.174)	
2022-04-03 14:24:53,437: ============================================================
2022-04-03 14:25:36,999: time cost, forward:0.01077035169282028, backward:0.05809432042583584, data cost:0.3672992005043312 
2022-04-03 14:25:36,999: ============================================================
2022-04-03 14:25:36,999: Epoch 6/26 Batch 2300/7662 eta: 19:11:32.045595	Training Loss 5.5173 (5.4296)	Training Prec@1 95.703 (96.057)	Training Prec@5 98.438 (98.164)	
2022-04-03 14:25:37,000: ============================================================
2022-04-03 14:26:21,241: time cost, forward:0.010763988737366307, backward:0.058105013180693374, data cost:0.36753574606278083 
2022-04-03 14:26:21,241: ============================================================
2022-04-03 14:26:21,242: Epoch 6/26 Batch 2400/7662 eta: 19:28:45.508111	Training Loss 5.4480 (5.4328)	Training Prec@1 96.289 (96.055)	Training Prec@5 99.219 (98.159)	
2022-04-03 14:26:21,242: ============================================================
2022-04-03 14:27:05,320: time cost, forward:0.010759778383399258, backward:0.05811341441407496, data cost:0.3676811296875928 
2022-04-03 14:27:05,320: ============================================================
2022-04-03 14:27:05,321: Epoch 6/26 Batch 2500/7662 eta: 19:23:42.245740	Training Loss 5.7056 (5.4347)	Training Prec@1 93.555 (96.047)	Training Prec@5 96.875 (98.151)	
2022-04-03 14:27:05,321: ============================================================
2022-04-03 14:27:49,602: time cost, forward:0.010749987704609852, backward:0.05811471038251806, data cost:0.36791019203021647 
2022-04-03 14:27:49,602: ============================================================
2022-04-03 14:27:49,603: Epoch 6/26 Batch 2600/7662 eta: 19:28:19.572648	Training Loss 5.5471 (5.4375)	Training Prec@1 95.117 (96.036)	Training Prec@5 98.047 (98.146)	
2022-04-03 14:27:49,603: ============================================================
2022-04-03 14:28:34,246: time cost, forward:0.010737608962255127, backward:0.058129375976472046, data cost:0.3682534981763288 
2022-04-03 14:28:34,246: ============================================================
2022-04-03 14:28:34,246: Epoch 6/26 Batch 2700/7662 eta: 19:37:08.081774	Training Loss 5.2389 (5.4407)	Training Prec@1 96.289 (96.031)	Training Prec@5 98.438 (98.144)	
2022-04-03 14:28:34,247: ============================================================
2022-04-03 14:29:18,663: time cost, forward:0.01072549734766375, backward:0.058141491846682214, data cost:0.3684839614590137 
2022-04-03 14:29:18,663: ============================================================
2022-04-03 14:29:18,663: Epoch 6/26 Batch 2800/7662 eta: 19:30:24.536847	Training Loss 5.3877 (5.4436)	Training Prec@1 95.508 (96.021)	Training Prec@5 97.852 (98.138)	
2022-04-03 14:29:18,664: ============================================================
2022-04-03 14:30:03,023: time cost, forward:0.01072556448624273, backward:0.058145690597555234, data cost:0.3686720773901517 
2022-04-03 14:30:03,023: ============================================================
2022-04-03 14:30:03,023: Epoch 6/26 Batch 2900/7662 eta: 19:28:09.885020	Training Loss 5.4522 (5.4457)	Training Prec@1 96.875 (96.010)	Training Prec@5 98.633 (98.134)	
2022-04-03 14:30:03,024: ============================================================
2022-04-03 14:30:47,849: time cost, forward:0.010725456541798519, backward:0.05814375699301806, data cost:0.36901978136261687 
2022-04-03 14:30:47,850: ============================================================
2022-04-03 14:30:47,850: Epoch 6/26 Batch 3000/7662 eta: 19:39:42.568528	Training Loss 5.4860 (5.4476)	Training Prec@1 97.070 (96.005)	Training Prec@5 99.219 (98.130)	
2022-04-03 14:30:47,850: ============================================================
2022-04-03 14:31:31,615: time cost, forward:0.010705268856170447, backward:0.05816630426242529, data cost:0.3690074092536328 
2022-04-03 14:31:31,616: ============================================================
2022-04-03 14:31:31,616: Epoch 6/26 Batch 3100/7662 eta: 19:11:04.182178	Training Loss 5.3118 (5.4497)	Training Prec@1 95.898 (95.999)	Training Prec@5 98.047 (98.130)	
2022-04-03 14:31:31,616: ============================================================
2022-04-03 14:32:15,681: time cost, forward:0.010695527888492108, backward:0.058184148520743634, data cost:0.3690537558976245 
2022-04-03 14:32:15,682: ============================================================
2022-04-03 14:32:15,682: Epoch 6/26 Batch 3200/7662 eta: 19:18:13.333269	Training Loss 5.4999 (5.4513)	Training Prec@1 95.117 (95.995)	Training Prec@5 97.461 (98.127)	
2022-04-03 14:32:15,682: ============================================================
2022-04-03 14:33:00,609: time cost, forward:0.01068939068491584, backward:0.05818864344538758, data cost:0.36938173794753626 
2022-04-03 14:33:00,610: ============================================================
2022-04-03 14:33:00,610: Epoch 6/26 Batch 3300/7662 eta: 19:40:07.893458	Training Loss 5.4519 (5.4526)	Training Prec@1 94.336 (95.991)	Training Prec@5 97.852 (98.123)	
2022-04-03 14:33:00,610: ============================================================
2022-04-03 14:33:45,998: time cost, forward:0.010673049128241453, backward:0.058205326082566865, data cost:0.36982277738027414 
2022-04-03 14:33:45,998: ============================================================
2022-04-03 14:33:45,998: Epoch 6/26 Batch 3400/7662 eta: 19:51:28.207434	Training Loss 5.8227 (5.4546)	Training Prec@1 95.312 (95.984)	Training Prec@5 97.656 (98.119)	
2022-04-03 14:33:45,999: ============================================================
2022-04-03 14:34:29,089: time cost, forward:0.01065887468615475, backward:0.0582282800066638, data cost:0.3695721853866206 
2022-04-03 14:34:29,089: ============================================================
2022-04-03 14:34:29,090: Epoch 6/26 Batch 3500/7662 eta: 18:50:26.788425	Training Loss 5.5120 (5.4550)	Training Prec@1 95.898 (95.981)	Training Prec@5 98.438 (98.119)	
2022-04-03 14:34:29,090: ============================================================
2022-04-03 14:35:13,696: time cost, forward:0.010665098539025428, backward:0.05822158157908277, data cost:0.36977292736824036 
2022-04-03 14:35:13,696: ============================================================
2022-04-03 14:35:13,696: Epoch 6/26 Batch 3600/7662 eta: 19:29:27.799475	Training Loss 5.6909 (5.4570)	Training Prec@1 94.336 (95.972)	Training Prec@5 97.852 (98.114)	
2022-04-03 14:35:13,697: ============================================================
2022-04-03 14:35:58,393: time cost, forward:0.010659663217652325, backward:0.05822521307946025, data cost:0.369978067584217 
2022-04-03 14:35:58,393: ============================================================
2022-04-03 14:35:58,393: Epoch 6/26 Batch 3700/7662 eta: 19:31:04.893397	Training Loss 5.3177 (5.4588)	Training Prec@1 95.703 (95.964)	Training Prec@5 98.242 (98.110)	
2022-04-03 14:35:58,394: ============================================================
2022-04-03 14:36:43,123: time cost, forward:0.010647264396745803, backward:0.058240065357502466, data cost:0.3701887524859094 
2022-04-03 14:36:43,123: ============================================================
2022-04-03 14:36:43,123: Epoch 6/26 Batch 3800/7662 eta: 19:31:12.098516	Training Loss 5.4648 (5.4600)	Training Prec@1 97.070 (95.959)	Training Prec@5 98.242 (98.106)	
2022-04-03 14:36:43,123: ============================================================
2022-04-03 14:37:26,639: time cost, forward:0.010669645329994188, backward:0.05822441724056646, data cost:0.370071655910851 
2022-04-03 14:37:26,639: ============================================================
2022-04-03 14:37:26,639: Epoch 6/26 Batch 3900/7662 eta: 18:58:41.624297	Training Loss 5.2668 (5.4609)	Training Prec@1 95.898 (95.958)	Training Prec@5 97.656 (98.106)	
2022-04-03 14:37:26,640: ============================================================
2022-04-03 14:38:11,471: time cost, forward:0.010662001232768214, backward:0.05823133545656388, data cost:0.3702904956881539 
2022-04-03 14:38:11,472: ============================================================
2022-04-03 14:38:11,472: Epoch 6/26 Batch 4000/7662 eta: 19:32:23.658649	Training Loss 5.1606 (5.4615)	Training Prec@1 96.680 (95.956)	Training Prec@5 98.633 (98.105)	
2022-04-03 14:38:11,472: ============================================================
2022-04-03 14:38:55,785: time cost, forward:0.010647934510900382, backward:0.058245265387883854, data cost:0.37037358443368845 
2022-04-03 14:38:55,786: ============================================================
2022-04-03 14:38:55,786: Epoch 6/26 Batch 4100/7662 eta: 19:18:05.320861	Training Loss 5.4445 (5.4631)	Training Prec@1 96.875 (95.952)	Training Prec@5 98.828 (98.103)	
2022-04-03 14:38:55,786: ============================================================
2022-04-03 14:39:39,865: time cost, forward:0.010641173426098244, backward:0.058258651239186644, data cost:0.3703989604451197 
2022-04-03 14:39:39,865: ============================================================
2022-04-03 14:39:39,865: Epoch 6/26 Batch 4200/7662 eta: 19:11:13.715380	Training Loss 5.5835 (5.4638)	Training Prec@1 95.703 (95.947)	Training Prec@5 98.438 (98.101)	
2022-04-03 14:39:39,865: ============================================================
2022-04-03 14:40:24,004: time cost, forward:0.01063314646614183, backward:0.058271125627967144, data cost:0.3704255399772749 
2022-04-03 14:40:24,004: ============================================================
2022-04-03 14:40:24,004: Epoch 6/26 Batch 4300/7662 eta: 19:12:02.918173	Training Loss 5.3068 (5.4648)	Training Prec@1 96.680 (95.941)	Training Prec@5 97.656 (98.097)	
2022-04-03 14:40:24,004: ============================================================
2022-04-03 14:41:05,186: time cost, forward:0.010638697902352518, backward:0.05827576991074951, data cost:0.36978258742991293 
2022-04-03 14:41:05,186: ============================================================
2022-04-03 14:41:05,187: Epoch 6/26 Batch 4400/7662 eta: 17:54:11.851900	Training Loss 5.3433 (5.4650)	Training Prec@1 95.312 (95.936)	Training Prec@5 97.461 (98.093)	
2022-04-03 14:41:05,187: ============================================================
2022-04-03 14:41:49,703: time cost, forward:0.010638901699275593, backward:0.058277211101300505, data cost:0.3699121317828489 
2022-04-03 14:41:49,704: ============================================================
2022-04-03 14:41:49,704: Epoch 6/26 Batch 4500/7662 eta: 19:20:26.617030	Training Loss 5.5267 (5.4656)	Training Prec@1 95.898 (95.933)	Training Prec@5 97.656 (98.092)	
2022-04-03 14:41:49,704: ============================================================
2022-04-03 14:42:34,964: time cost, forward:0.010632882923840388, backward:0.0582898238555948, data cost:0.3701881050259996 
2022-04-03 14:42:34,965: ============================================================
2022-04-03 14:42:34,965: Epoch 6/26 Batch 4600/7662 eta: 19:39:04.035371	Training Loss 5.2909 (5.4662)	Training Prec@1 97.070 (95.930)	Training Prec@5 99.414 (98.089)	
2022-04-03 14:42:34,965: ============================================================
2022-04-03 14:43:19,467: time cost, forward:0.010633582839511206, backward:0.058295159219147984, data cost:0.370298599329216 
2022-04-03 14:43:19,468: ============================================================
2022-04-03 14:43:19,468: Epoch 6/26 Batch 4700/7662 eta: 19:18:35.372312	Training Loss 5.5221 (5.4666)	Training Prec@1 96.094 (95.924)	Training Prec@5 98.242 (98.085)	
2022-04-03 14:43:19,468: ============================================================
2022-04-03 14:44:04,101: time cost, forward:0.01062904206085364, backward:0.058303365759065584, data cost:0.3704322237947579 
2022-04-03 14:44:04,101: ============================================================
2022-04-03 14:44:04,102: Epoch 6/26 Batch 4800/7662 eta: 19:21:14.047315	Training Loss 5.4260 (5.4668)	Training Prec@1 95.117 (95.921)	Training Prec@5 97.656 (98.083)	
2022-04-03 14:44:04,102: ============================================================
2022-04-03 14:44:47,121: time cost, forward:0.010617730325035817, backward:0.05831318252985515, data cost:0.37024980891746123 
2022-04-03 14:44:47,122: ============================================================
2022-04-03 14:44:47,122: Epoch 6/26 Batch 4900/7662 eta: 18:38:33.368721	Training Loss 5.5086 (5.4671)	Training Prec@1 95.508 (95.921)	Training Prec@5 97.461 (98.085)	
2022-04-03 14:44:47,122: ============================================================
2022-04-03 14:45:27,672: time cost, forward:0.010607787861206886, backward:0.05832841682968246, data cost:0.369550844077278 
2022-04-03 14:45:27,673: ============================================================
2022-04-03 14:45:27,673: Epoch 6/26 Batch 5000/7662 eta: 17:33:39.882634	Training Loss 5.8119 (5.4680)	Training Prec@1 95.703 (95.919)	Training Prec@5 97.461 (98.084)	
2022-04-03 14:45:27,673: ============================================================
2022-04-03 14:46:10,114: time cost, forward:0.010596852228673773, backward:0.05834074267267503, data cost:0.3692652133661851 
2022-04-03 14:46:10,115: ============================================================
2022-04-03 14:46:10,115: Epoch 6/26 Batch 5100/7662 eta: 18:22:06.242697	Training Loss 5.1975 (5.4674)	Training Prec@1 94.727 (95.918)	Training Prec@5 97.656 (98.085)	
2022-04-03 14:46:10,115: ============================================================
2022-04-03 14:46:53,616: time cost, forward:0.010590046913629771, backward:0.05834577096886625, data cost:0.36919312065302073 
2022-04-03 14:46:53,616: ============================================================
2022-04-03 14:46:53,617: Epoch 6/26 Batch 5200/7662 eta: 18:48:53.263251	Training Loss 5.4619 (5.4668)	Training Prec@1 96.289 (95.918)	Training Prec@5 98.242 (98.085)	
2022-04-03 14:46:53,617: ============================================================
2022-04-03 14:47:38,115: time cost, forward:0.010587662340312842, backward:0.05834872953440473, data cost:0.3693056972235143 
2022-04-03 14:47:38,115: ============================================================
2022-04-03 14:47:38,116: Epoch 6/26 Batch 5300/7662 eta: 19:14:01.568362	Training Loss 5.3446 (5.4667)	Training Prec@1 95.508 (95.920)	Training Prec@5 98.047 (98.084)	
2022-04-03 14:47:38,116: ============================================================
2022-04-03 14:48:22,765: time cost, forward:0.01058669310186633, backward:0.058346716159581036, data cost:0.3694517687087281 
2022-04-03 14:48:22,765: ============================================================
2022-04-03 14:48:22,765: Epoch 6/26 Batch 5400/7662 eta: 19:17:11.549468	Training Loss 5.4502 (5.4667)	Training Prec@1 96.484 (95.917)	Training Prec@5 98.242 (98.083)	
2022-04-03 14:48:22,765: ============================================================
2022-04-03 14:49:07,754: time cost, forward:0.010626178846551758, backward:0.058305006023753145, data cost:0.3696546346453195 
2022-04-03 14:49:07,754: ============================================================
2022-04-03 14:49:07,754: Epoch 6/26 Batch 5500/7662 eta: 19:25:14.151314	Training Loss 5.6451 (5.4676)	Training Prec@1 93.945 (95.915)	Training Prec@5 96.484 (98.082)	
2022-04-03 14:49:07,754: ============================================================
2022-04-03 14:49:50,660: time cost, forward:0.010618691062007468, backward:0.05830658868202718, data cost:0.369489496106398 
2022-04-03 14:49:50,660: ============================================================
2022-04-03 14:49:50,661: Epoch 6/26 Batch 5600/7662 eta: 18:30:34.943000	Training Loss 5.4130 (5.4684)	Training Prec@1 96.289 (95.912)	Training Prec@5 99.219 (98.081)	
2022-04-03 14:49:50,661: ============================================================
2022-04-03 14:50:34,112: time cost, forward:0.010606867406510076, backward:0.05831251246486971, data cost:0.3694130806656004 
2022-04-03 14:50:34,113: ============================================================
2022-04-03 14:50:34,113: Epoch 6/26 Batch 5700/7662 eta: 18:43:59.372079	Training Loss 5.6295 (5.4685)	Training Prec@1 95.312 (95.907)	Training Prec@5 97.656 (98.077)	
2022-04-03 14:50:34,113: ============================================================
2022-04-03 14:51:19,177: time cost, forward:0.010598979133596748, backward:0.058318176070540746, data cost:0.3696179985691708 
2022-04-03 14:51:19,178: ============================================================
2022-04-03 14:51:19,178: Epoch 6/26 Batch 5800/7662 eta: 19:24:57.049444	Training Loss 5.2719 (5.4685)	Training Prec@1 97.461 (95.905)	Training Prec@5 98.438 (98.074)	
2022-04-03 14:51:19,178: ============================================================
2022-04-03 14:52:03,801: time cost, forward:0.010598878735989954, backward:0.058320922394044565, data cost:0.3697319625292537 
2022-04-03 14:52:03,801: ============================================================
2022-04-03 14:52:03,802: Epoch 6/26 Batch 5900/7662 eta: 19:12:48.094996	Training Loss 5.5312 (5.4682)	Training Prec@1 94.336 (95.904)	Training Prec@5 98.242 (98.075)	
2022-04-03 14:52:03,802: ============================================================
2022-04-03 14:52:48,516: time cost, forward:0.010591624716675904, backward:0.058324615644164676, data cost:0.3698741444589138 
2022-04-03 14:52:48,516: ============================================================
2022-04-03 14:52:48,516: Epoch 6/26 Batch 6000/7662 eta: 19:14:24.782510	Training Loss 5.1550 (5.4688)	Training Prec@1 96.094 (95.901)	Training Prec@5 98.047 (98.073)	
2022-04-03 14:52:48,517: ============================================================
2022-04-03 14:53:33,138: time cost, forward:0.010584996750871165, backward:0.05832957220695159, data cost:0.3699837467830325 
2022-04-03 14:53:33,138: ============================================================
2022-04-03 14:53:33,138: Epoch 6/26 Batch 6100/7662 eta: 19:11:16.064343	Training Loss 5.8514 (5.4692)	Training Prec@1 95.508 (95.899)	Training Prec@5 98.633 (98.072)	
2022-04-03 14:53:33,139: ============================================================
2022-04-03 14:54:17,172: time cost, forward:0.010579158575578281, backward:0.05833660508186745, data cost:0.3700003863573267 
2022-04-03 14:54:17,172: ============================================================
2022-04-03 14:54:17,172: Epoch 6/26 Batch 6200/7662 eta: 18:55:21.598005	Training Loss 5.8214 (5.4687)	Training Prec@1 95.312 (95.901)	Training Prec@5 97.461 (98.073)	
2022-04-03 14:54:17,172: ============================================================
2022-04-03 14:54:59,658: time cost, forward:0.010574709367971606, backward:0.058338073609953627, data cost:0.36976773546960434 
2022-04-03 14:54:59,658: ============================================================
2022-04-03 14:54:59,658: Epoch 6/26 Batch 6300/7662 eta: 18:14:44.898280	Training Loss 5.3770 (5.4689)	Training Prec@1 96.680 (95.900)	Training Prec@5 98.242 (98.072)	
2022-04-03 14:54:59,659: ============================================================
2022-04-03 14:55:43,134: time cost, forward:0.010571413066987414, backward:0.05834030590871104, data cost:0.36970561469862434 
2022-04-03 14:55:43,134: ============================================================
2022-04-03 14:55:43,134: Epoch 6/26 Batch 6400/7662 eta: 18:39:31.689394	Training Loss 5.3417 (5.4692)	Training Prec@1 96.289 (95.896)	Training Prec@5 98.438 (98.070)	
2022-04-03 14:55:43,135: ============================================================
2022-04-03 14:56:25,629: time cost, forward:0.010567298539327941, backward:0.05834769377214649, data cost:0.3694853481466467 
2022-04-03 14:56:25,630: ============================================================
2022-04-03 14:56:25,630: Epoch 6/26 Batch 6500/7662 eta: 18:13:34.794520	Training Loss 5.8218 (5.4688)	Training Prec@1 93.359 (95.897)	Training Prec@5 95.898 (98.071)	
2022-04-03 14:56:25,630: ============================================================
2022-04-03 14:57:08,817: time cost, forward:0.010563983829080345, backward:0.05835238722783722, data cost:0.36937509942983277 
2022-04-03 14:57:08,818: ============================================================
2022-04-03 14:57:08,818: Epoch 6/26 Batch 6600/7662 eta: 18:30:39.902803	Training Loss 5.7502 (5.4686)	Training Prec@1 95.508 (95.897)	Training Prec@5 98.047 (98.070)	
2022-04-03 14:57:08,818: ============================================================
2022-04-03 14:57:53,374: time cost, forward:0.010561461234416583, backward:0.058352760813773295, data cost:0.3694694223359799 
2022-04-03 14:57:53,375: ============================================================
2022-04-03 14:57:53,375: Epoch 6/26 Batch 6700/7662 eta: 19:05:08.145663	Training Loss 5.4129 (5.4686)	Training Prec@1 96.875 (95.897)	Training Prec@5 98.438 (98.071)	
2022-04-03 14:57:53,375: ============================================================
2022-04-03 14:58:38,825: time cost, forward:0.010561624332848218, backward:0.058353917215445195, data cost:0.36970083523119246 
2022-04-03 14:58:38,826: ============================================================
2022-04-03 14:58:38,826: Epoch 6/26 Batch 6800/7662 eta: 19:27:21.272927	Training Loss 5.2489 (5.4686)	Training Prec@1 97.070 (95.896)	Training Prec@5 98.242 (98.070)	
2022-04-03 14:58:38,826: ============================================================
2022-04-03 14:59:24,716: time cost, forward:0.010564491392512445, backward:0.058352174785175535, data cost:0.36998391932448643 
2022-04-03 14:59:24,716: ============================================================
2022-04-03 14:59:24,716: Epoch 6/26 Batch 6900/7662 eta: 19:37:52.486129	Training Loss 5.4095 (5.4689)	Training Prec@1 95.898 (95.895)	Training Prec@5 97.852 (98.070)	
2022-04-03 14:59:24,716: ============================================================
2022-04-03 15:00:10,897: time cost, forward:0.010560885380465467, backward:0.05835651016044589, data cost:0.37030977629852185 
2022-04-03 15:00:10,897: ============================================================
2022-04-03 15:00:10,898: Epoch 6/26 Batch 7000/7662 eta: 19:44:34.570776	Training Loss 5.2991 (5.4692)	Training Prec@1 96.289 (95.891)	Training Prec@5 97.656 (98.067)	
2022-04-03 15:00:10,898: ============================================================
2022-04-03 15:00:55,571: time cost, forward:0.01055727738497173, backward:0.05835886296461562, data cost:0.3704131523107606 
2022-04-03 15:00:55,572: ============================================================
2022-04-03 15:00:55,572: Epoch 6/26 Batch 7100/7662 eta: 19:05:10.533836	Training Loss 5.4964 (5.4689)	Training Prec@1 96.484 (95.891)	Training Prec@5 98.047 (98.066)	
2022-04-03 15:00:55,572: ============================================================
2022-04-03 15:01:40,407: time cost, forward:0.01055685181239526, backward:0.05835977228569776, data cost:0.37052489767672037 
2022-04-03 15:01:40,407: ============================================================
2022-04-03 15:01:40,407: Epoch 6/26 Batch 7200/7662 eta: 19:08:33.614840	Training Loss 5.4142 (5.4690)	Training Prec@1 98.047 (95.890)	Training Prec@5 99.414 (98.066)	
2022-04-03 15:01:40,408: ============================================================
2022-04-03 15:02:25,414: time cost, forward:0.010553304586268105, backward:0.058363113293567415, data cost:0.3706607371752418 
2022-04-03 15:02:25,414: ============================================================
2022-04-03 15:02:25,414: Epoch 6/26 Batch 7300/7662 eta: 19:12:11.954577	Training Loss 5.5978 (5.4689)	Training Prec@1 95.312 (95.888)	Training Prec@5 98.242 (98.065)	
2022-04-03 15:02:25,415: ============================================================
2022-04-03 15:03:08,161: time cost, forward:0.010549029299883862, backward:0.058371093180038136, data cost:0.370487449265506 
2022-04-03 15:03:08,162: ============================================================
2022-04-03 15:03:08,162: Epoch 6/26 Batch 7400/7662 eta: 18:13:38.579188	Training Loss 5.4974 (5.4691)	Training Prec@1 96.289 (95.887)	Training Prec@5 98.438 (98.064)	
2022-04-03 15:03:08,162: ============================================================
2022-04-03 15:03:51,709: time cost, forward:0.01054370277705932, backward:0.05837410709860802, data cost:0.3704329506685486 
2022-04-03 15:03:51,710: ============================================================
2022-04-03 15:03:51,710: Epoch 6/26 Batch 7500/7662 eta: 18:33:24.300307	Training Loss 5.4332 (5.4694)	Training Prec@1 94.727 (95.885)	Training Prec@5 98.047 (98.063)	
2022-04-03 15:03:51,710: ============================================================
2022-04-03 15:04:36,982: time cost, forward:0.010541291186049951, backward:0.05837807458927011, data cost:0.37059748663778663 
2022-04-03 15:04:36,982: ============================================================
2022-04-03 15:04:36,982: Epoch 6/26 Batch 7600/7662 eta: 19:16:43.909575	Training Loss 5.3135 (5.4687)	Training Prec@1 96.484 (95.887)	Training Prec@5 98.047 (98.064)	
2022-04-03 15:04:36,983: ============================================================
2022-04-03 15:05:06,797: Epoch: 6/26 eta: 19:16:15.387979	Training Loss 5.5811 (5.4690)	Training Prec@1 95.508 (95.885)	Training Prec@5 97.461 (98.063)
2022-04-03 15:05:06,798: ============================================================
2022-04-03 15:05:51,527: time cost, forward:0.01054925870413732, backward:0.05821302924493347, data cost:0.37679027306913127 
2022-04-03 15:05:51,527: ============================================================
2022-04-03 15:05:51,527: Epoch 7/26 Batch 100/7662 eta: 18:56:16.764102	Training Loss 4.8456 (5.0756)	Training Prec@1 96.875 (96.727)	Training Prec@5 97.852 (98.507)	
2022-04-03 15:05:51,528: ============================================================
2022-04-03 15:06:34,308: time cost, forward:0.010142369485979703, backward:0.05867727557618414, data cost:0.3674796286539816 
2022-04-03 15:06:34,309: ============================================================
2022-04-03 15:06:34,309: Epoch 7/26 Batch 200/7662 eta: 18:11:13.938690	Training Loss 5.4883 (5.1126)	Training Prec@1 96.094 (96.617)	Training Prec@5 98.047 (98.442)	
2022-04-03 15:06:34,309: ============================================================
2022-04-03 15:07:18,669: time cost, forward:0.00996606405762127, backward:0.058841039504494555, data cost:0.3698068518303709 
2022-04-03 15:07:18,670: ============================================================
2022-04-03 15:07:18,670: Epoch 7/26 Batch 300/7662 eta: 18:50:45.913159	Training Loss 5.5217 (5.1496)	Training Prec@1 96.094 (96.582)	Training Prec@5 98.242 (98.431)	
2022-04-03 15:07:18,670: ============================================================
2022-04-03 15:08:03,193: time cost, forward:0.009892114720547707, backward:0.058931469618527216, data cost:0.3712017482384703 
2022-04-03 15:08:03,194: ============================================================
2022-04-03 15:08:03,194: Epoch 7/26 Batch 400/7662 eta: 18:54:10.576178	Training Loss 5.3210 (5.1769)	Training Prec@1 96.680 (96.518)	Training Prec@5 98.828 (98.411)	
2022-04-03 15:08:03,194: ============================================================
2022-04-03 15:08:47,609: time cost, forward:0.009893525339558512, backward:0.058989568798241014, data cost:0.37188191117647895 
2022-04-03 15:08:47,610: ============================================================
2022-04-03 15:08:47,610: Epoch 7/26 Batch 500/7662 eta: 18:50:41.665259	Training Loss 5.4142 (5.1970)	Training Prec@1 96.094 (96.501)	Training Prec@5 98.828 (98.422)	
2022-04-03 15:08:47,610: ============================================================
2022-04-03 15:09:32,891: time cost, forward:0.009878000552347785, backward:0.05902372934981459, data cost:0.3738928048160916 
2022-04-03 15:09:32,892: ============================================================
2022-04-03 15:09:32,892: Epoch 7/26 Batch 600/7662 eta: 19:11:58.589475	Training Loss 5.7288 (5.2219)	Training Prec@1 95.898 (96.471)	Training Prec@5 97.266 (98.399)	
2022-04-03 15:09:32,892: ============================================================
2022-04-03 15:10:17,572: time cost, forward:0.009906546411255058, backward:0.059025426108779144, data cost:0.3743222254369733 
2022-04-03 15:10:17,572: ============================================================
2022-04-03 15:10:17,572: Epoch 7/26 Batch 700/7662 eta: 18:55:55.997176	Training Loss 5.1751 (5.2373)	Training Prec@1 96.484 (96.447)	Training Prec@5 98.047 (98.386)	
2022-04-03 15:10:17,572: ============================================================
2022-04-03 15:11:00,342: time cost, forward:0.009929827665059229, backward:0.05902040616442474, data cost:0.3723257295181217 
2022-04-03 15:11:00,343: ============================================================
2022-04-03 15:11:00,343: Epoch 7/26 Batch 800/7662 eta: 18:06:39.796720	Training Loss 5.2394 (5.2510)	Training Prec@1 96.680 (96.424)	Training Prec@5 98.242 (98.379)	
2022-04-03 15:11:00,343: ============================================================
2022-04-03 15:11:44,931: time cost, forward:0.009967453089916666, backward:0.05899604382583907, data cost:0.3726993047355677 
2022-04-03 15:11:44,931: ============================================================
2022-04-03 15:11:44,932: Epoch 7/26 Batch 900/7662 eta: 18:52:07.300139	Training Loss 5.8292 (5.2657)	Training Prec@1 95.508 (96.386)	Training Prec@5 97.656 (98.357)	
2022-04-03 15:11:44,932: ============================================================
2022-04-03 15:12:29,703: time cost, forward:0.009970304128286001, backward:0.05901520961039775, data cost:0.3732402140910442 
2022-04-03 15:12:29,703: ============================================================
2022-04-03 15:12:29,704: Epoch 7/26 Batch 1000/7662 eta: 18:56:01.294899	Training Loss 5.2129 (5.2793)	Training Prec@1 96.875 (96.351)	Training Prec@5 97.852 (98.335)	
2022-04-03 15:12:29,704: ============================================================
2022-04-03 15:13:12,785: time cost, forward:0.009965280709861081, backward:0.0590237325923458, data cost:0.37217002136258237 
2022-04-03 15:13:12,786: ============================================================
2022-04-03 15:13:12,786: Epoch 7/26 Batch 1100/7662 eta: 18:12:26.130698	Training Loss 5.2585 (5.2874)	Training Prec@1 96.680 (96.328)	Training Prec@5 97.461 (98.317)	
2022-04-03 15:13:12,786: ============================================================
2022-04-03 15:13:56,005: time cost, forward:0.010009905415042627, backward:0.058993386068972475, data cost:0.3713377597831109 
2022-04-03 15:13:56,005: ============================================================
2022-04-03 15:13:56,005: Epoch 7/26 Batch 1200/7662 eta: 18:15:10.834840	Training Loss 5.5300 (5.2981)	Training Prec@1 95.508 (96.297)	Training Prec@5 98.242 (98.306)	
2022-04-03 15:13:56,005: ============================================================
2022-04-03 15:14:39,457: time cost, forward:0.00998465825815766, backward:0.059027103940921165, data cost:0.37086542594240113 
2022-04-03 15:14:39,458: ============================================================
2022-04-03 15:14:39,458: Epoch 7/26 Batch 1300/7662 eta: 18:20:22.439585	Training Loss 5.5214 (5.3087)	Training Prec@1 95.898 (96.265)	Training Prec@5 98.047 (98.282)	
2022-04-03 15:14:39,458: ============================================================
2022-04-03 15:15:24,046: time cost, forward:0.009989571792897027, backward:0.05903316515526489, data cost:0.37120858186308703 
2022-04-03 15:15:24,046: ============================================================
2022-04-03 15:15:24,047: Epoch 7/26 Batch 1400/7662 eta: 18:48:23.818723	Training Loss 5.0789 (5.3177)	Training Prec@1 96.484 (96.241)	Training Prec@5 98.242 (98.266)	
2022-04-03 15:15:24,047: ============================================================
2022-04-03 15:16:08,569: time cost, forward:0.010023217586138155, backward:0.059011533309651504, data cost:0.37154199060716175 
2022-04-03 15:16:08,569: ============================================================
2022-04-03 15:16:08,570: Epoch 7/26 Batch 1500/7662 eta: 18:45:59.626982	Training Loss 5.2945 (5.3269)	Training Prec@1 96.289 (96.212)	Training Prec@5 98.438 (98.254)	
2022-04-03 15:16:08,570: ============================================================
2022-04-03 15:16:53,418: time cost, forward:0.010071394516573316, backward:0.05895683256964001, data cost:0.37199865541583377 
2022-04-03 15:16:53,419: ============================================================
2022-04-03 15:16:53,419: Epoch 7/26 Batch 1600/7662 eta: 18:53:29.614141	Training Loss 5.4939 (5.3347)	Training Prec@1 95.312 (96.198)	Training Prec@5 97.852 (98.247)	
2022-04-03 15:16:53,419: ============================================================
2022-04-03 15:17:38,538: time cost, forward:0.010076986754059861, backward:0.058946782662771674, data cost:0.37258018080524447 
2022-04-03 15:17:38,538: ============================================================
2022-04-03 15:17:38,538: Epoch 7/26 Batch 1700/7662 eta: 18:59:34.604243	Training Loss 5.6345 (5.3405)	Training Prec@1 94.922 (96.190)	Training Prec@5 97.852 (98.240)	
2022-04-03 15:17:38,538: ============================================================
2022-04-03 15:18:22,562: time cost, forward:0.01009426639105228, backward:0.05894212725428888, data cost:0.37245610000160817 
2022-04-03 15:18:22,563: ============================================================
2022-04-03 15:18:22,563: Epoch 7/26 Batch 1800/7662 eta: 18:31:11.387684	Training Loss 5.2470 (5.3466)	Training Prec@1 95.898 (96.164)	Training Prec@5 98.242 (98.231)	
2022-04-03 15:18:22,563: ============================================================
2022-04-03 15:19:06,330: time cost, forward:0.010105275680919646, backward:0.0589382934720972, data cost:0.3721851966078499 
2022-04-03 15:19:06,330: ============================================================
2022-04-03 15:19:06,331: Epoch 7/26 Batch 1900/7662 eta: 18:23:58.465049	Training Loss 5.5903 (5.3510)	Training Prec@1 94.336 (96.145)	Training Prec@5 97.852 (98.224)	
2022-04-03 15:19:06,331: ============================================================
2022-04-03 15:19:50,481: time cost, forward:0.01009025604740389, backward:0.0589420980307506, data cost:0.37220570741742176 
2022-04-03 15:19:50,482: ============================================================
2022-04-03 15:19:50,482: Epoch 7/26 Batch 2000/7662 eta: 18:32:54.643278	Training Loss 5.5074 (5.3553)	Training Prec@1 94.531 (96.134)	Training Prec@5 97.266 (98.217)	
2022-04-03 15:19:50,482: ============================================================
2022-04-03 15:20:35,187: time cost, forward:0.010102864161396436, backward:0.05893708627072898, data cost:0.37244706008478595 
2022-04-03 15:20:35,187: ============================================================
2022-04-03 15:20:35,188: Epoch 7/26 Batch 2100/7662 eta: 18:46:08.823533	Training Loss 5.4844 (5.3594)	Training Prec@1 95.703 (96.113)	Training Prec@5 97.266 (98.203)	
2022-04-03 15:20:35,188: ============================================================
2022-04-03 15:21:19,845: time cost, forward:0.010112663462466682, backward:0.05893807294098775, data cost:0.37264164830945523 
2022-04-03 15:21:19,845: ============================================================
2022-04-03 15:21:19,846: Epoch 7/26 Batch 2200/7662 eta: 18:44:11.741043	Training Loss 5.7839 (5.3631)	Training Prec@1 94.727 (96.097)	Training Prec@5 97.656 (98.194)	
2022-04-03 15:21:19,846: ============================================================
2022-04-03 15:22:04,690: time cost, forward:0.01013283088654215, backward:0.058916141386393, data cost:0.3729096057364193 
2022-04-03 15:22:04,690: ============================================================
2022-04-03 15:22:04,690: Epoch 7/26 Batch 2300/7662 eta: 18:48:08.982275	Training Loss 5.3459 (5.3668)	Training Prec@1 96.680 (96.087)	Training Prec@5 98.633 (98.191)	
2022-04-03 15:22:04,690: ============================================================
2022-04-03 15:22:49,441: time cost, forward:0.010129502536158306, backward:0.05891922614434303, data cost:0.3731417791105002 
2022-04-03 15:22:49,441: ============================================================
2022-04-03 15:22:49,441: Epoch 7/26 Batch 2400/7662 eta: 18:45:02.986347	Training Loss 5.8079 (5.3689)	Training Prec@1 94.336 (96.074)	Training Prec@5 97.266 (98.183)	
2022-04-03 15:22:49,441: ============================================================
2022-04-03 15:23:32,610: time cost, forward:0.01012083032981259, backward:0.05893662100841924, data cost:0.37260755380185523 
2022-04-03 15:23:32,610: ============================================================
2022-04-03 15:23:32,610: Epoch 7/26 Batch 2500/7662 eta: 18:04:33.414500	Training Loss 5.4957 (5.3718)	Training Prec@1 96.484 (96.063)	Training Prec@5 98.633 (98.182)	
2022-04-03 15:23:32,610: ============================================================
2022-04-03 15:24:17,366: time cost, forward:0.010119589625436005, backward:0.05894680149787295, data cost:0.3728721722496065 
2022-04-03 15:24:17,367: ============================================================
2022-04-03 15:24:17,367: Epoch 7/26 Batch 2600/7662 eta: 18:43:41.521370	Training Loss 5.3549 (5.3741)	Training Prec@1 97.070 (96.056)	Training Prec@5 98.828 (98.179)	
2022-04-03 15:24:17,367: ============================================================
2022-04-03 15:25:01,137: time cost, forward:0.010194795756218124, backward:0.05888042497652555, data cost:0.3726784163556659 
2022-04-03 15:25:01,138: ============================================================
2022-04-03 15:25:01,138: Epoch 7/26 Batch 2700/7662 eta: 18:18:13.523142	Training Loss 5.6338 (5.3767)	Training Prec@1 96.484 (96.050)	Training Prec@5 98.828 (98.176)	
2022-04-03 15:25:01,138: ============================================================
2022-04-03 15:25:46,446: time cost, forward:0.01023989935013259, backward:0.05883950699904681, data cost:0.3730666674048017 
2022-04-03 15:25:46,446: ============================================================
2022-04-03 15:25:46,447: Epoch 7/26 Batch 2800/7662 eta: 18:56:02.702241	Training Loss 5.4554 (5.3794)	Training Prec@1 94.531 (96.048)	Training Prec@5 97.461 (98.173)	
2022-04-03 15:25:46,447: ============================================================
2022-04-03 15:26:31,223: time cost, forward:0.010258358155665377, backward:0.05882603647627473, data cost:0.37323338971462033 
2022-04-03 15:26:31,224: ============================================================
2022-04-03 15:26:31,224: Epoch 7/26 Batch 2900/7662 eta: 18:41:59.098502	Training Loss 5.6441 (5.3804)	Training Prec@1 95.508 (96.045)	Training Prec@5 97.852 (98.173)	
2022-04-03 15:26:31,224: ============================================================
2022-04-03 15:27:14,524: time cost, forward:0.010288636976180375, backward:0.05880424434958239, data cost:0.37289702093334903 
2022-04-03 15:27:14,525: ============================================================
2022-04-03 15:27:14,525: Epoch 7/26 Batch 3000/7662 eta: 18:04:15.512430	Training Loss 5.4220 (5.3818)	Training Prec@1 96.094 (96.041)	Training Prec@5 97.461 (98.169)	
2022-04-03 15:27:14,525: ============================================================
2022-04-03 15:27:59,291: time cost, forward:0.010300094675886974, backward:0.05878360350695915, data cost:0.37306742938959664 
2022-04-03 15:27:59,291: ============================================================
2022-04-03 15:27:59,292: Epoch 7/26 Batch 3100/7662 eta: 18:40:13.195075	Training Loss 5.5249 (5.3837)	Training Prec@1 95.703 (96.034)	Training Prec@5 97.656 (98.166)	
2022-04-03 15:27:59,292: ============================================================
2022-04-03 15:28:43,466: time cost, forward:0.010498642287950435, backward:0.05858216959448597, data cost:0.37303584230881476 
2022-04-03 15:28:43,467: ============================================================
2022-04-03 15:28:43,467: Epoch 7/26 Batch 3200/7662 eta: 18:24:41.021632	Training Loss 5.3771 (5.3847)	Training Prec@1 95.508 (96.028)	Training Prec@5 97.852 (98.161)	
2022-04-03 15:28:43,467: ============================================================
2022-04-03 15:29:27,352: time cost, forward:0.010779207639529439, backward:0.05830198723318072, data cost:0.37293034511900336 
2022-04-03 15:29:27,352: ============================================================
2022-04-03 15:29:27,353: Epoch 7/26 Batch 3300/7662 eta: 18:16:42.495834	Training Loss 5.3413 (5.3859)	Training Prec@1 94.727 (96.023)	Training Prec@5 97.070 (98.159)	
2022-04-03 15:29:27,353: ============================================================
2022-04-03 15:30:11,426: time cost, forward:0.010763188045352444, backward:0.05832115360202773, data cost:0.3728692871782842 
2022-04-03 15:30:11,426: ============================================================
2022-04-03 15:30:11,427: Epoch 7/26 Batch 3400/7662 eta: 18:20:41.012547	Training Loss 5.3841 (5.3867)	Training Prec@1 95.312 (96.019)	Training Prec@5 98.047 (98.155)	
2022-04-03 15:30:11,427: ============================================================
2022-04-03 15:30:56,074: time cost, forward:0.010749131006729811, backward:0.058326407138467956, data cost:0.37299132599221463 
2022-04-03 15:30:56,075: ============================================================
2022-04-03 15:30:56,075: Epoch 7/26 Batch 3500/7662 eta: 18:34:17.037146	Training Loss 5.2937 (5.3890)	Training Prec@1 96.094 (96.010)	Training Prec@5 98.828 (98.149)	
2022-04-03 15:30:56,075: ============================================================
2022-04-03 15:31:38,503: time cost, forward:0.010728211958032741, backward:0.0583437257556327, data cost:0.37248989713625896 
2022-04-03 15:31:38,503: ============================================================
2022-04-03 15:31:38,504: Epoch 7/26 Batch 3600/7662 eta: 17:38:10.556818	Training Loss 5.5373 (5.3898)	Training Prec@1 95.117 (96.007)	Training Prec@5 98.047 (98.145)	
2022-04-03 15:31:38,504: ============================================================
2022-04-03 15:32:22,962: time cost, forward:0.010716796275827492, backward:0.058357246310751516, data cost:0.3725710053094563 
2022-04-03 15:32:22,962: ============================================================
2022-04-03 15:32:22,962: Epoch 7/26 Batch 3700/7662 eta: 18:28:03.553787	Training Loss 5.3489 (5.3905)	Training Prec@1 95.703 (96.005)	Training Prec@5 97.266 (98.144)	
2022-04-03 15:32:22,962: ============================================================
2022-04-03 15:33:06,820: time cost, forward:0.010702574557459772, backward:0.05838053136726654, data cost:0.37244213935920334 
2022-04-03 15:33:06,820: ============================================================
2022-04-03 15:33:06,820: Epoch 7/26 Batch 3800/7662 eta: 18:12:22.222558	Training Loss 5.7018 (5.3909)	Training Prec@1 94.922 (96.005)	Training Prec@5 98.242 (98.146)	
2022-04-03 15:33:06,820: ============================================================
2022-04-03 15:33:51,720: time cost, forward:0.01068952408286968, backward:0.05839072584830727, data cost:0.3726199891329362 
2022-04-03 15:33:51,720: ============================================================
2022-04-03 15:33:51,720: Epoch 7/26 Batch 3900/7662 eta: 18:37:34.215603	Training Loss 5.3718 (5.3919)	Training Prec@1 96.484 (96.000)	Training Prec@5 99.219 (98.142)	
2022-04-03 15:33:51,720: ============================================================
2022-04-03 15:34:35,599: time cost, forward:0.010686416928843874, backward:0.058398144696467695, data cost:0.37253560111295525 
2022-04-03 15:34:35,600: ============================================================
2022-04-03 15:34:35,600: Epoch 7/26 Batch 4000/7662 eta: 18:11:26.150735	Training Loss 5.2602 (5.3939)	Training Prec@1 96.484 (95.991)	Training Prec@5 97.656 (98.139)	
2022-04-03 15:34:35,600: ============================================================
2022-04-03 15:35:20,320: time cost, forward:0.010684749969013379, backward:0.058403269841514525, data cost:0.3726568963650408 
2022-04-03 15:35:20,320: ============================================================
2022-04-03 15:35:20,320: Epoch 7/26 Batch 4100/7662 eta: 18:31:36.802863	Training Loss 5.3351 (5.3946)	Training Prec@1 95.898 (95.986)	Training Prec@5 98.438 (98.135)	
2022-04-03 15:35:20,321: ============================================================
2022-04-03 15:36:03,437: time cost, forward:0.01068626883257625, backward:0.058406196057328046, data cost:0.3723944610969087 
2022-04-03 15:36:03,437: ============================================================
2022-04-03 15:36:03,438: Epoch 7/26 Batch 4200/7662 eta: 17:51:02.075283	Training Loss 5.4712 (5.3954)	Training Prec@1 94.141 (95.982)	Training Prec@5 97.656 (98.134)	
2022-04-03 15:36:03,438: ============================================================
2022-04-03 15:36:47,341: time cost, forward:0.010676740629502746, backward:0.058414623498306575, data cost:0.3723193519917941 
2022-04-03 15:36:47,341: ============================================================
2022-04-03 15:36:47,342: Epoch 7/26 Batch 4300/7662 eta: 18:09:51.205494	Training Loss 5.2964 (5.3958)	Training Prec@1 95.703 (95.978)	Training Prec@5 97.656 (98.132)	
2022-04-03 15:36:47,342: ============================================================
2022-04-03 15:37:32,313: time cost, forward:0.010679831041967796, backward:0.058412991374372, data cost:0.3724810863576387 
2022-04-03 15:37:32,313: ============================================================
2022-04-03 15:37:32,314: Epoch 7/26 Batch 4400/7662 eta: 18:35:36.899614	Training Loss 5.2885 (5.3971)	Training Prec@1 96.289 (95.977)	Training Prec@5 98.633 (98.130)	
2022-04-03 15:37:32,314: ============================================================
2022-04-03 15:38:17,209: time cost, forward:0.010666167902983567, backward:0.058426405753419515, data cost:0.3726455203478377 
2022-04-03 15:38:17,209: ============================================================
2022-04-03 15:38:17,209: Epoch 7/26 Batch 4500/7662 eta: 18:32:58.436514	Training Loss 5.5613 (5.3983)	Training Prec@1 94.922 (95.974)	Training Prec@5 98.242 (98.130)	
2022-04-03 15:38:17,210: ============================================================
2022-04-03 15:39:01,351: time cost, forward:0.010656925822683303, backward:0.05844015197977861, data cost:0.37261773425875916 
2022-04-03 15:39:01,351: ============================================================
2022-04-03 15:39:01,351: Epoch 7/26 Batch 4600/7662 eta: 18:13:32.776682	Training Loss 5.2775 (5.3990)	Training Prec@1 96.289 (95.971)	Training Prec@5 98.242 (98.129)	
2022-04-03 15:39:01,351: ============================================================
2022-04-03 15:39:45,865: time cost, forward:0.010666547823165371, backward:0.058428117381077824, data cost:0.3726926151806559 
2022-04-03 15:39:45,865: ============================================================
2022-04-03 15:39:45,866: Epoch 7/26 Batch 4700/7662 eta: 18:22:02.135266	Training Loss 5.3055 (5.4000)	Training Prec@1 96.094 (95.968)	Training Prec@5 98.047 (98.128)	
2022-04-03 15:39:45,866: ============================================================
2022-04-03 15:40:30,256: time cost, forward:0.010657291656783483, backward:0.05843487091922939, data cost:0.3727170548654641 
2022-04-03 15:40:30,256: ============================================================
2022-04-03 15:40:30,256: Epoch 7/26 Batch 4800/7662 eta: 18:18:13.804133	Training Loss 5.4458 (5.4012)	Training Prec@1 96.289 (95.966)	Training Prec@5 99.023 (98.127)	
2022-04-03 15:40:30,256: ============================================================
2022-04-03 15:41:13,983: time cost, forward:0.010649143761336792, backward:0.05843867913001069, data cost:0.3726213328763888 
2022-04-03 15:41:13,983: ============================================================
2022-04-03 15:41:13,983: Epoch 7/26 Batch 4900/7662 eta: 18:01:05.167388	Training Loss 5.3026 (5.4016)	Training Prec@1 96.484 (95.963)	Training Prec@5 98.633 (98.126)	
2022-04-03 15:41:13,983: ============================================================
2022-04-03 15:41:59,066: time cost, forward:0.010648229356335744, backward:0.05843531897030346, data cost:0.372795025189654 
2022-04-03 15:41:59,067: ============================================================
2022-04-03 15:41:59,067: Epoch 7/26 Batch 5000/7662 eta: 18:33:52.150163	Training Loss 5.4678 (5.4020)	Training Prec@1 94.922 (95.960)	Training Prec@5 96.875 (98.125)	
2022-04-03 15:41:59,067: ============================================================
2022-04-03 15:42:43,072: time cost, forward:0.010637911845011018, backward:0.058448281234842955, data cost:0.372744707669387 
2022-04-03 15:42:43,072: ============================================================
2022-04-03 15:42:43,073: Epoch 7/26 Batch 5100/7662 eta: 18:06:30.701064	Training Loss 5.6037 (5.4027)	Training Prec@1 96.094 (95.958)	Training Prec@5 98.242 (98.122)	
2022-04-03 15:42:43,073: ============================================================
2022-04-03 15:43:28,182: time cost, forward:0.010627171745160882, backward:0.05845635169789204, data cost:0.37290768275744274 
2022-04-03 15:43:28,183: ============================================================
2022-04-03 15:43:28,183: Epoch 7/26 Batch 5200/7662 eta: 18:33:01.905208	Training Loss 5.7305 (5.4029)	Training Prec@1 95.703 (95.955)	Training Prec@5 97.266 (98.120)	
2022-04-03 15:43:28,183: ============================================================
2022-04-03 15:44:13,127: time cost, forward:0.010621152704314121, backward:0.05846416205589581, data cost:0.37304906459051745 
2022-04-03 15:44:13,127: ============================================================
2022-04-03 15:44:13,127: Epoch 7/26 Batch 5300/7662 eta: 18:28:11.285559	Training Loss 5.2029 (5.4033)	Training Prec@1 96.875 (95.953)	Training Prec@5 98.047 (98.119)	
2022-04-03 15:44:13,128: ============================================================
2022-04-03 15:44:55,967: time cost, forward:0.010610317782045051, backward:0.0584750295590639, data cost:0.37278211653331933 
2022-04-03 15:44:55,967: ============================================================
2022-04-03 15:44:55,968: Epoch 7/26 Batch 5400/7662 eta: 17:35:35.298934	Training Loss 5.4656 (5.4038)	Training Prec@1 96.484 (95.950)	Training Prec@5 98.438 (98.119)	
2022-04-03 15:44:55,968: ============================================================
2022-04-03 15:45:40,139: time cost, forward:0.010607794081650987, backward:0.05848233156538937, data cost:0.37277038892110187 
2022-04-03 15:45:40,140: ============================================================
2022-04-03 15:45:40,140: Epoch 7/26 Batch 5500/7662 eta: 18:07:40.666578	Training Loss 5.2552 (5.4040)	Training Prec@1 97.070 (95.949)	Training Prec@5 98.633 (98.118)	
2022-04-03 15:45:40,140: ============================================================
2022-04-03 15:46:21,278: time cost, forward:0.010601239154159565, backward:0.05849550613059936, data cost:0.37221016975827975 
2022-04-03 15:46:21,279: ============================================================
2022-04-03 15:46:21,279: Epoch 7/26 Batch 5600/7662 eta: 16:52:17.646864	Training Loss 5.5807 (5.4038)	Training Prec@1 94.141 (95.950)	Training Prec@5 97.266 (98.118)	
2022-04-03 15:46:21,279: ============================================================
2022-04-03 15:47:03,264: time cost, forward:0.010596693179171888, backward:0.05850509204954866, data cost:0.3718215677482577 
2022-04-03 15:47:03,265: ============================================================
2022-04-03 15:47:03,265: Epoch 7/26 Batch 5700/7662 eta: 17:12:26.738474	Training Loss 5.4929 (5.4037)	Training Prec@1 95.703 (95.951)	Training Prec@5 98.828 (98.118)	
2022-04-03 15:47:03,265: ============================================================
2022-04-03 15:47:46,611: time cost, forward:0.010589928601523642, backward:0.058510871689203256, data cost:0.3716769671107103 
2022-04-03 15:47:46,612: ============================================================
2022-04-03 15:47:46,612: Epoch 7/26 Batch 5800/7662 eta: 17:45:11.475779	Training Loss 5.3479 (5.4042)	Training Prec@1 96.094 (95.949)	Training Prec@5 98.438 (98.116)	
2022-04-03 15:47:46,612: ============================================================
2022-04-03 15:48:31,944: time cost, forward:0.010586352323269235, backward:0.05851713789380351, data cost:0.37187384148536445 
2022-04-03 15:48:31,944: ============================================================
2022-04-03 15:48:31,944: Epoch 7/26 Batch 5900/7662 eta: 18:33:13.027532	Training Loss 5.3665 (5.4049)	Training Prec@1 96.484 (95.944)	Training Prec@5 98.242 (98.114)	
2022-04-03 15:48:31,944: ============================================================
2022-04-03 15:49:17,480: time cost, forward:0.010582642428853905, backward:0.05852785057217941, data cost:0.37210365727973554 
2022-04-03 15:49:17,480: ============================================================
2022-04-03 15:49:17,480: Epoch 7/26 Batch 6000/7662 eta: 18:37:27.767446	Training Loss 5.3496 (5.4054)	Training Prec@1 97.266 (95.941)	Training Prec@5 98.828 (98.113)	
2022-04-03 15:49:17,481: ============================================================
2022-04-03 15:50:03,729: time cost, forward:0.01058349951034023, backward:0.05852699217238882, data cost:0.37244185054276807 
2022-04-03 15:50:03,730: ============================================================
2022-04-03 15:50:03,730: Epoch 7/26 Batch 6100/7662 eta: 18:54:11.958606	Training Loss 5.4805 (5.4055)	Training Prec@1 96.094 (95.939)	Training Prec@5 98.438 (98.112)	
2022-04-03 15:50:03,730: ============================================================
2022-04-03 15:50:49,722: time cost, forward:0.010582611587359495, backward:0.05852547851872648, data cost:0.37272941575817264 
2022-04-03 15:50:49,722: ============================================================
2022-04-03 15:50:49,722: Epoch 7/26 Batch 6200/7662 eta: 18:47:07.686886	Training Loss 5.4209 (5.4063)	Training Prec@1 95.312 (95.936)	Training Prec@5 97.852 (98.111)	
2022-04-03 15:50:49,723: ============================================================
2022-04-03 15:51:35,952: time cost, forward:0.010577253168169364, backward:0.058536024089085904, data cost:0.3730562047781235 
2022-04-03 15:51:35,952: ============================================================
2022-04-03 15:51:35,952: Epoch 7/26 Batch 6300/7662 eta: 18:52:10.772478	Training Loss 5.4938 (5.4061)	Training Prec@1 95.312 (95.936)	Training Prec@5 98.828 (98.111)	
2022-04-03 15:51:35,952: ============================================================
2022-04-03 15:52:23,211: time cost, forward:0.010571615083792523, backward:0.05854460555587938, data cost:0.3735032272368674 
2022-04-03 15:52:23,212: ============================================================
2022-04-03 15:52:23,212: Epoch 7/26 Batch 6400/7662 eta: 19:16:36.405407	Training Loss 5.2368 (5.4065)	Training Prec@1 96.875 (95.935)	Training Prec@5 99.023 (98.111)	
2022-04-03 15:52:23,212: ============================================================
2022-04-03 15:53:09,967: time cost, forward:0.010566294459237156, backward:0.05855221828326278, data cost:0.3738918112945439 
2022-04-03 15:53:09,967: ============================================================
2022-04-03 15:53:09,967: Epoch 7/26 Batch 6500/7662 eta: 19:03:29.326735	Training Loss 5.6190 (5.4074)	Training Prec@1 94.336 (95.931)	Training Prec@5 96.875 (98.109)	
2022-04-03 15:53:09,967: ============================================================
2022-04-03 15:53:55,397: time cost, forward:0.01055924613144492, backward:0.05856265341048711, data cost:0.37400291948395076 
2022-04-03 15:53:55,397: ============================================================
2022-04-03 15:53:55,398: Epoch 7/26 Batch 6600/7662 eta: 18:30:19.696547	Training Loss 5.9539 (5.4078)	Training Prec@1 94.336 (95.932)	Training Prec@5 96.484 (98.109)	
2022-04-03 15:53:55,398: ============================================================
2022-04-03 15:54:41,440: time cost, forward:0.010558712996730415, backward:0.058564113456645216, data cost:0.3742884440748776 
2022-04-03 15:54:41,441: ============================================================
2022-04-03 15:54:41,441: Epoch 7/26 Batch 6700/7662 eta: 18:44:32.420784	Training Loss 5.0668 (5.4082)	Training Prec@1 95.508 (95.929)	Training Prec@5 98.047 (98.108)	
2022-04-03 15:54:41,441: ============================================================
2022-04-03 15:55:26,451: time cost, forward:0.010562421714826478, backward:0.05856393631599741, data cost:0.37437708543703685 
2022-04-03 15:55:26,451: ============================================================
2022-04-03 15:55:26,452: Epoch 7/26 Batch 6800/7662 eta: 18:18:33.991033	Training Loss 5.5815 (5.4083)	Training Prec@1 95.312 (95.928)	Training Prec@5 98.047 (98.107)	
2022-04-03 15:55:26,452: ============================================================
2022-04-03 15:56:11,118: time cost, forward:0.010557655459435924, backward:0.05857328653923065, data cost:0.3744060754395858 
2022-04-03 15:56:11,118: ============================================================
2022-04-03 15:56:11,118: Epoch 7/26 Batch 6900/7662 eta: 18:09:25.750059	Training Loss 5.3924 (5.4082)	Training Prec@1 96.289 (95.927)	Training Prec@5 97.852 (98.106)	
2022-04-03 15:56:11,119: ============================================================
2022-04-03 15:56:57,317: time cost, forward:0.010552923651078136, backward:0.05857655204590908, data cost:0.3746668766832195 
2022-04-03 15:56:57,318: ============================================================
2022-04-03 15:56:57,318: Epoch 7/26 Batch 7000/7662 eta: 18:46:02.829182	Training Loss 5.2108 (5.4078)	Training Prec@1 95.898 (95.929)	Training Prec@5 98.242 (98.107)	
2022-04-03 15:56:57,318: ============================================================
2022-04-03 15:57:42,530: time cost, forward:0.010549269623950528, backward:0.058583515565955216, data cost:0.3747784302828765 
2022-04-03 15:57:42,531: ============================================================
2022-04-03 15:57:42,531: Epoch 7/26 Batch 7100/7662 eta: 18:21:14.534252	Training Loss 5.3302 (5.4080)	Training Prec@1 94.922 (95.925)	Training Prec@5 98.242 (98.105)	
2022-04-03 15:57:42,531: ============================================================
2022-04-03 15:58:27,941: time cost, forward:0.01054461427257531, backward:0.058591476528656816, data cost:0.37490686639710785 
2022-04-03 15:58:27,942: ============================================================
2022-04-03 15:58:27,942: Epoch 7/26 Batch 7200/7662 eta: 18:25:18.896148	Training Loss 5.4928 (5.4080)	Training Prec@1 94.141 (95.924)	Training Prec@5 96.875 (98.105)	
2022-04-03 15:58:27,942: ============================================================
2022-04-03 15:59:14,112: time cost, forward:0.010544479832385954, backward:0.0585887476522182, data cost:0.3751518683884957 
2022-04-03 15:59:14,113: ============================================================
2022-04-03 15:59:14,113: Epoch 7/26 Batch 7300/7662 eta: 18:43:02.270541	Training Loss 5.4719 (5.4083)	Training Prec@1 95.508 (95.921)	Training Prec@5 98.242 (98.105)	
2022-04-03 15:59:14,113: ============================================================
2022-04-03 15:59:59,863: time cost, forward:0.010544095623894372, backward:0.05858900660130603, data cost:0.37531139035694727 
2022-04-03 15:59:59,863: ============================================================
2022-04-03 15:59:59,864: Epoch 7/26 Batch 7400/7662 eta: 18:32:03.268299	Training Loss 5.3127 (5.4085)	Training Prec@1 96.875 (95.920)	Training Prec@5 98.047 (98.103)	
2022-04-03 15:59:59,864: ============================================================
2022-04-03 16:00:46,164: time cost, forward:0.010542945840196907, backward:0.05859283660789985, data cost:0.3755267967397586 
2022-04-03 16:00:46,164: ============================================================
2022-04-03 16:00:46,165: Epoch 7/26 Batch 7500/7662 eta: 18:44:39.636833	Training Loss 5.3944 (5.4087)	Training Prec@1 95.312 (95.920)	Training Prec@5 98.438 (98.104)	
2022-04-03 16:00:46,165: ============================================================
2022-04-03 16:01:32,505: time cost, forward:0.010562795450035122, backward:0.058572378734614225, data cost:0.3757947510615009 
2022-04-03 16:01:32,505: ============================================================
2022-04-03 16:01:32,506: Epoch 7/26 Batch 7600/7662 eta: 18:44:51.185498	Training Loss 5.1121 (5.4089)	Training Prec@1 96.484 (95.920)	Training Prec@5 99.414 (98.104)	
2022-04-03 16:01:32,506: ============================================================
2022-04-03 16:02:02,141: Epoch: 7/26 eta: 18:44:21.990803	Training Loss 5.1831 (5.4089)	Training Prec@1 96.484 (95.920)	Training Prec@5 98.242 (98.104)
2022-04-03 16:02:02,142: ============================================================
2022-04-03 16:02:47,901: time cost, forward:0.010953190350773358, backward:0.05803233686119619, data cost:0.3877231159595528 
2022-04-03 16:02:47,902: ============================================================
2022-04-03 16:02:47,902: Epoch 8/26 Batch 100/7662 eta: 18:27:08.333703	Training Loss 5.2352 (5.0502)	Training Prec@1 96.484 (96.646)	Training Prec@5 98.438 (98.455)	
2022-04-03 16:02:47,902: ============================================================
2022-04-03 16:03:34,531: time cost, forward:0.010806378407693988, backward:0.058170590568427466, data cost:0.3923181073749485 
2022-04-03 16:03:34,531: ============================================================
2022-04-03 16:03:34,531: Epoch 8/26 Batch 200/7662 eta: 18:49:49.063948	Training Loss 4.9855 (5.0812)	Training Prec@1 96.680 (96.646)	Training Prec@5 98.633 (98.465)	
2022-04-03 16:03:34,532: ============================================================
2022-04-03 16:04:20,511: time cost, forward:0.010710330312467339, backward:0.05825972876022492, data cost:0.39163294125560133 
2022-04-03 16:04:20,511: ============================================================
2022-04-03 16:04:20,512: Epoch 8/26 Batch 300/7662 eta: 18:33:19.677360	Training Loss 5.0929 (5.0969)	Training Prec@1 96.094 (96.620)	Training Prec@5 98.438 (98.468)	
2022-04-03 16:04:20,512: ============================================================
2022-04-03 16:05:06,534: time cost, forward:0.01070477370929001, backward:0.0583588909684566, data cost:0.3913191786983557 
2022-04-03 16:05:06,534: ============================================================
2022-04-03 16:05:06,534: Epoch 8/26 Batch 400/7662 eta: 18:33:35.361502	Training Loss 5.2358 (5.1165)	Training Prec@1 96.875 (96.591)	Training Prec@5 97.852 (98.449)	
2022-04-03 16:05:06,535: ============================================================
2022-04-03 16:05:51,673: time cost, forward:0.010702116933757652, backward:0.05839590605848538, data cost:0.3894215514043529 
2022-04-03 16:05:51,674: ============================================================
2022-04-03 16:05:51,674: Epoch 8/26 Batch 500/7662 eta: 18:11:27.720955	Training Loss 5.2124 (5.1452)	Training Prec@1 96.094 (96.554)	Training Prec@5 99.219 (98.433)	
2022-04-03 16:05:51,674: ============================================================
2022-04-03 16:06:39,338: time cost, forward:0.010728001395529619, backward:0.058415952230335674, data cost:0.3922364365477395 
2022-04-03 16:06:39,338: ============================================================
2022-04-03 16:06:39,338: Epoch 8/26 Batch 600/7662 eta: 19:11:43.678257	Training Loss 5.4189 (5.1716)	Training Prec@1 97.852 (96.520)	Training Prec@5 98.633 (98.413)	
2022-04-03 16:06:39,339: ============================================================
2022-04-03 16:07:26,651: time cost, forward:0.01076342244346084, backward:0.05840737522927476, data cost:0.39388606885983707 
2022-04-03 16:07:26,651: ============================================================
2022-04-03 16:07:26,652: Epoch 8/26 Batch 700/7662 eta: 19:02:26.979796	Training Loss 5.1117 (5.1877)	Training Prec@1 96.484 (96.480)	Training Prec@5 97.656 (98.388)	
2022-04-03 16:07:26,652: ============================================================
2022-04-03 16:08:12,712: time cost, forward:0.010791362600123628, backward:0.05841569458886291, data cost:0.393425082086174 
2022-04-03 16:08:12,712: ============================================================
2022-04-03 16:08:12,712: Epoch 8/26 Batch 800/7662 eta: 18:31:26.087871	Training Loss 5.4368 (5.2021)	Training Prec@1 96.680 (96.457)	Training Prec@5 98.438 (98.382)	
2022-04-03 16:08:12,712: ============================================================
2022-04-03 16:08:58,889: time cost, forward:0.010802989011346565, backward:0.0583960065852283, data cost:0.39327879821896156 
2022-04-03 16:08:58,890: ============================================================
2022-04-03 16:08:58,890: Epoch 8/26 Batch 900/7662 eta: 18:33:29.229060	Training Loss 5.4912 (5.2179)	Training Prec@1 95.312 (96.420)	Training Prec@5 97.656 (98.362)	
2022-04-03 16:08:58,890: ============================================================
2022-04-03 16:09:44,404: time cost, forward:0.01082072720990644, backward:0.05841398167538571, data cost:0.3924752267392667 
2022-04-03 16:09:44,405: ============================================================
2022-04-03 16:09:44,405: Epoch 8/26 Batch 1000/7662 eta: 18:16:44.948620	Training Loss 5.0417 (5.2315)	Training Prec@1 98.047 (96.394)	Training Prec@5 99.609 (98.350)	
2022-04-03 16:09:44,405: ============================================================
2022-04-03 16:10:31,778: time cost, forward:0.01081310303456356, backward:0.05842395106481356, data cost:0.39350604208303214 
2022-04-03 16:10:31,779: ============================================================
2022-04-03 16:10:31,779: Epoch 8/26 Batch 1100/7662 eta: 19:00:45.475709	Training Loss 5.0685 (5.2408)	Training Prec@1 96.875 (96.377)	Training Prec@5 98.633 (98.348)	
2022-04-03 16:10:31,779: ============================================================
2022-04-03 16:11:17,943: time cost, forward:0.010808610438902841, backward:0.05842574623050642, data cost:0.39339540937326667 
2022-04-03 16:11:17,944: ============================================================
2022-04-03 16:11:17,944: Epoch 8/26 Batch 1200/7662 eta: 18:30:52.695757	Training Loss 5.5375 (5.2519)	Training Prec@1 93.164 (96.344)	Training Prec@5 97.852 (98.326)	
2022-04-03 16:11:17,944: ============================================================
2022-04-03 16:12:04,576: time cost, forward:0.01079454891859705, backward:0.05842443114523708, data cost:0.39362162145125673 
2022-04-03 16:12:04,576: ============================================================
2022-04-03 16:12:04,577: Epoch 8/26 Batch 1300/7662 eta: 18:41:21.242031	Training Loss 5.4057 (5.2587)	Training Prec@1 96.484 (96.324)	Training Prec@5 98.047 (98.317)	
2022-04-03 16:12:04,577: ============================================================
2022-04-03 16:12:50,813: time cost, forward:0.010773768673802036, backward:0.05842340665685014, data cost:0.3935815677888228 
2022-04-03 16:12:50,813: ============================================================
2022-04-03 16:12:50,813: Epoch 8/26 Batch 1400/7662 eta: 18:31:03.755808	Training Loss 5.3451 (5.2683)	Training Prec@1 96.289 (96.298)	Training Prec@5 98.242 (98.305)	
2022-04-03 16:12:50,813: ============================================================
2022-04-03 16:13:38,192: time cost, forward:0.010758082496078115, backward:0.05843241998877344, data cost:0.39428518421257075 
2022-04-03 16:13:38,192: ============================================================
2022-04-03 16:13:38,193: Epoch 8/26 Batch 1500/7662 eta: 18:57:43.513610	Training Loss 5.4335 (5.2768)	Training Prec@1 96.289 (96.273)	Training Prec@5 97.852 (98.292)	
2022-04-03 16:13:38,193: ============================================================
2022-04-03 16:14:24,460: time cost, forward:0.010882632891933496, backward:0.058289503439878806, data cost:0.3941941687731239 
2022-04-03 16:14:24,460: ============================================================
2022-04-03 16:14:24,461: Epoch 8/26 Batch 1600/7662 eta: 18:30:16.087875	Training Loss 5.2620 (5.2830)	Training Prec@1 96.484 (96.262)	Training Prec@5 98.438 (98.285)	
2022-04-03 16:14:24,461: ============================================================
2022-04-03 16:15:10,418: time cost, forward:0.01103730830394078, backward:0.05812745826815492, data cost:0.393964346890733 
2022-04-03 16:15:10,418: ============================================================
2022-04-03 16:15:10,418: Epoch 8/26 Batch 1700/7662 eta: 18:22:03.794795	Training Loss 5.2810 (5.2886)	Training Prec@1 94.727 (96.242)	Training Prec@5 97.461 (98.280)	
2022-04-03 16:15:10,419: ============================================================
2022-04-03 16:15:56,735: time cost, forward:0.011088996810870676, backward:0.058059308845643004, data cost:0.39382128559131635 
2022-04-03 16:15:56,735: ============================================================
2022-04-03 16:15:56,735: Epoch 8/26 Batch 1800/7662 eta: 18:29:54.032577	Training Loss 5.0610 (5.2922)	Training Prec@1 96.680 (96.229)	Training Prec@5 98.242 (98.272)	
2022-04-03 16:15:56,736: ============================================================
2022-04-03 16:16:43,562: time cost, forward:0.01106910243544094, backward:0.058073201764565256, data cost:0.39419376843850695 
2022-04-03 16:16:43,563: ============================================================
2022-04-03 16:16:43,563: Epoch 8/26 Batch 1900/7662 eta: 18:41:21.555524	Training Loss 5.4083 (5.2964)	Training Prec@1 95.312 (96.219)	Training Prec@5 97.266 (98.269)	
2022-04-03 16:16:43,563: ============================================================
2022-04-03 16:17:30,615: time cost, forward:0.011046420341136755, backward:0.058090850196521604, data cost:0.39457129513758193 
2022-04-03 16:17:30,616: ============================================================
2022-04-03 16:17:30,616: Epoch 8/26 Batch 2000/7662 eta: 18:45:58.134748	Training Loss 5.5509 (5.3022)	Training Prec@1 96.289 (96.199)	Training Prec@5 98.438 (98.259)	
2022-04-03 16:17:30,616: ============================================================
2022-04-03 16:18:16,362: time cost, forward:0.011034051709768032, backward:0.05810527724274685, data cost:0.3942351881920468 
2022-04-03 16:18:16,362: ============================================================
2022-04-03 16:18:16,363: Epoch 8/26 Batch 2100/7662 eta: 18:13:56.827031	Training Loss 5.3374 (5.3068)	Training Prec@1 94.531 (96.185)	Training Prec@5 97.852 (98.250)	
2022-04-03 16:18:16,363: ============================================================
2022-04-03 16:19:01,258: time cost, forward:0.011024932852654415, backward:0.05811951994191196, data cost:0.393523649933014 
2022-04-03 16:19:01,259: ============================================================
2022-04-03 16:19:01,259: Epoch 8/26 Batch 2200/7662 eta: 17:52:51.689356	Training Loss 5.3260 (5.3113)	Training Prec@1 95.898 (96.173)	Training Prec@5 98.242 (98.244)	
2022-04-03 16:19:01,259: ============================================================
2022-04-03 16:19:48,434: time cost, forward:0.011012536020266486, backward:0.0581311432886974, data cost:0.3938926445395597 
2022-04-03 16:19:48,435: ============================================================
2022-04-03 16:19:48,435: Epoch 8/26 Batch 2300/7662 eta: 18:46:33.228448	Training Loss 5.3743 (5.3152)	Training Prec@1 94.531 (96.164)	Training Prec@5 96.680 (98.241)	
2022-04-03 16:19:48,435: ============================================================
2022-04-03 16:20:36,457: time cost, forward:0.011003038494623717, backward:0.05815009516246521, data cost:0.3945828403418836 
2022-04-03 16:20:36,457: ============================================================
2022-04-03 16:20:36,458: Epoch 8/26 Batch 2400/7662 eta: 19:05:58.465771	Training Loss 5.2458 (5.3175)	Training Prec@1 95.703 (96.152)	Training Prec@5 97.852 (98.235)	
2022-04-03 16:20:36,458: ============================================================
2022-04-03 16:21:21,041: time cost, forward:0.011083162322240908, backward:0.05806390186842559, data cost:0.39385754940938167 
2022-04-03 16:21:21,041: ============================================================
2022-04-03 16:21:21,041: Epoch 8/26 Batch 2500/7662 eta: 17:43:10.211890	Training Loss 5.1806 (5.3200)	Training Prec@1 96.875 (96.141)	Training Prec@5 98.633 (98.228)	
2022-04-03 16:21:21,042: ============================================================
2022-04-03 16:22:06,868: time cost, forward:0.011097968564945352, backward:0.05804826902306598, data cost:0.39364408547715896 
2022-04-03 16:22:06,869: ============================================================
2022-04-03 16:22:06,869: Epoch 8/26 Batch 2600/7662 eta: 18:12:03.543885	Training Loss 5.2662 (5.3229)	Training Prec@1 97.656 (96.128)	Training Prec@5 99.414 (98.221)	
2022-04-03 16:22:06,869: ============================================================
2022-04-03 16:22:52,822: time cost, forward:0.011092650002574603, backward:0.05805384746168489, data cost:0.39351662462311526 
2022-04-03 16:22:52,823: ============================================================
2022-04-03 16:22:52,823: Epoch 8/26 Batch 2700/7662 eta: 18:14:18.401386	Training Loss 5.6280 (5.3251)	Training Prec@1 95.508 (96.118)	Training Prec@5 98.438 (98.216)	
2022-04-03 16:22:52,823: ============================================================
2022-04-03 16:23:39,158: time cost, forward:0.011079162902259623, backward:0.05807635919585233, data cost:0.39351242080080634 
2022-04-03 16:23:39,158: ============================================================
2022-04-03 16:23:39,158: Epoch 8/26 Batch 2800/7662 eta: 18:22:37.781233	Training Loss 5.3870 (5.3289)	Training Prec@1 95.508 (96.108)	Training Prec@5 98.438 (98.214)	
2022-04-03 16:23:39,159: ============================================================
2022-04-03 16:24:25,082: time cost, forward:0.01106829797863837, backward:0.058097523547485395, data cost:0.39332464704352355 
2022-04-03 16:24:25,083: ============================================================
2022-04-03 16:24:25,083: Epoch 8/26 Batch 2900/7662 eta: 18:12:04.294854	Training Loss 5.8381 (5.3316)	Training Prec@1 94.922 (96.102)	Training Prec@5 98.047 (98.210)	
2022-04-03 16:24:25,083: ============================================================
2022-04-03 16:25:12,927: time cost, forward:0.011057656778817019, backward:0.05810710214384002, data cost:0.3938357141583154 
2022-04-03 16:25:12,928: ============================================================
2022-04-03 16:25:12,928: Epoch 8/26 Batch 3000/7662 eta: 18:56:57.064004	Training Loss 5.3857 (5.3340)	Training Prec@1 95.898 (96.090)	Training Prec@5 98.242 (98.204)	
2022-04-03 16:25:12,928: ============================================================
2022-04-03 16:25:58,749: time cost, forward:0.011044129512893958, backward:0.05811513835824509, data cost:0.393647804380271 
2022-04-03 16:25:58,750: ============================================================
2022-04-03 16:25:58,750: Epoch 8/26 Batch 3100/7662 eta: 18:08:06.746781	Training Loss 5.3465 (5.3361)	Training Prec@1 96.484 (96.083)	Training Prec@5 98.047 (98.200)	
2022-04-03 16:25:58,750: ============================================================
2022-04-03 16:26:42,912: time cost, forward:0.011025260634331376, backward:0.058133927163723, data cost:0.39301985910289844 
2022-04-03 16:26:42,913: ============================================================
2022-04-03 16:26:42,913: Epoch 8/26 Batch 3200/7662 eta: 17:27:58.546667	Training Loss 5.2631 (5.3374)	Training Prec@1 96.680 (96.075)	Training Prec@5 98.438 (98.198)	
2022-04-03 16:26:42,913: ============================================================
2022-04-03 16:27:29,273: time cost, forward:0.011008530177648012, backward:0.05814103033731258, data cost:0.39306032364929977 
2022-04-03 16:27:29,274: ============================================================
2022-04-03 16:27:29,274: Epoch 8/26 Batch 3300/7662 eta: 18:19:22.205748	Training Loss 5.2528 (5.3379)	Training Prec@1 96.875 (96.069)	Training Prec@5 97.852 (98.194)	
2022-04-03 16:27:29,274: ============================================================
2022-04-03 16:28:15,509: time cost, forward:0.01100006788118547, backward:0.05814733698845751, data cost:0.3930446983751531 
2022-04-03 16:28:15,509: ============================================================
2022-04-03 16:28:15,509: Epoch 8/26 Batch 3400/7662 eta: 18:15:37.139819	Training Loss 5.6954 (5.3391)	Training Prec@1 94.531 (96.064)	Training Prec@5 97.656 (98.191)	
2022-04-03 16:28:15,509: ============================================================
2022-04-03 16:29:00,594: time cost, forward:0.011053076469070335, backward:0.058096013433015424, data cost:0.39269774557693105 
2022-04-03 16:29:00,594: ============================================================
2022-04-03 16:29:00,594: Epoch 8/26 Batch 3500/7662 eta: 17:47:36.525192	Training Loss 5.2587 (5.3407)	Training Prec@1 95.898 (96.057)	Training Prec@5 98.242 (98.188)	
2022-04-03 16:29:00,595: ============================================================
2022-04-03 16:29:45,471: time cost, forward:0.011041781742660892, backward:0.05810239342193731, data cost:0.3923244978461407 
2022-04-03 16:29:45,471: ============================================================
2022-04-03 16:29:45,472: Epoch 8/26 Batch 3600/7662 eta: 17:41:55.971816	Training Loss 5.3938 (5.3419)	Training Prec@1 96.680 (96.052)	Training Prec@5 98.047 (98.186)	
2022-04-03 16:29:45,472: ============================================================
2022-04-03 16:30:31,660: time cost, forward:0.01104578181646037, backward:0.05809900424840741, data cost:0.3923357325200939 
2022-04-03 16:30:31,661: ============================================================
2022-04-03 16:30:31,661: Epoch 8/26 Batch 3700/7662 eta: 18:12:13.045574	Training Loss 5.4090 (5.3426)	Training Prec@1 95.117 (96.050)	Training Prec@5 96.484 (98.184)	
2022-04-03 16:30:31,661: ============================================================
2022-04-03 16:31:18,097: time cost, forward:0.011025353022768926, backward:0.05811754412700013, data cost:0.39239704260608965 
2022-04-03 16:31:18,097: ============================================================
2022-04-03 16:31:18,098: Epoch 8/26 Batch 3800/7662 eta: 18:17:17.303466	Training Loss 5.1946 (5.3433)	Training Prec@1 96.094 (96.046)	Training Prec@5 98.633 (98.182)	
2022-04-03 16:31:18,098: ============================================================
2022-04-03 16:32:03,998: time cost, forward:0.01100906832886525, backward:0.05813300728828487, data cost:0.39231639686197034 
2022-04-03 16:32:03,998: ============================================================
2022-04-03 16:32:03,998: Epoch 8/26 Batch 3900/7662 eta: 18:03:51.991011	Training Loss 5.5151 (5.3450)	Training Prec@1 96.094 (96.042)	Training Prec@5 97.852 (98.179)	
2022-04-03 16:32:03,999: ============================================================
2022-04-03 16:32:49,356: time cost, forward:0.010994744199489051, backward:0.0581380362867206, data cost:0.3921234785362791 
2022-04-03 16:32:49,356: ============================================================
2022-04-03 16:32:49,357: Epoch 8/26 Batch 4000/7662 eta: 17:50:17.552074	Training Loss 5.4955 (5.3461)	Training Prec@1 95.508 (96.036)	Training Prec@5 98.242 (98.176)	
2022-04-03 16:32:49,357: ============================================================
2022-04-03 16:33:36,543: time cost, forward:0.010981396658590986, backward:0.05814822576894618, data cost:0.3923678514462443 
2022-04-03 16:33:36,543: ============================================================
2022-04-03 16:33:36,544: Epoch 8/26 Batch 4100/7662 eta: 18:32:39.656990	Training Loss 5.1103 (5.3468)	Training Prec@1 96.484 (96.034)	Training Prec@5 98.633 (98.175)	
2022-04-03 16:33:36,544: ============================================================
2022-04-03 16:34:22,489: time cost, forward:0.010968779518252812, backward:0.05815399303468076, data cost:0.3923286096514279 
2022-04-03 16:34:22,490: ============================================================
2022-04-03 16:34:22,490: Epoch 8/26 Batch 4200/7662 eta: 18:02:38.717155	Training Loss 5.4347 (5.3481)	Training Prec@1 95.508 (96.029)	Training Prec@5 97.461 (98.171)	
2022-04-03 16:34:22,490: ============================================================
2022-04-03 16:35:05,868: time cost, forward:0.010956963541120062, backward:0.05816628573023461, data cost:0.3916860220736752 
2022-04-03 16:35:05,868: ============================================================
2022-04-03 16:35:05,868: Epoch 8/26 Batch 4300/7662 eta: 17:01:24.002965	Training Loss 5.1871 (5.3491)	Training Prec@1 96.875 (96.025)	Training Prec@5 98.633 (98.170)	
2022-04-03 16:35:05,868: ============================================================
2022-04-03 16:35:51,368: time cost, forward:0.010945632962319872, backward:0.058172787501341, data cost:0.3915203673971271 
2022-04-03 16:35:51,369: ============================================================
2022-04-03 16:35:51,369: Epoch 8/26 Batch 4400/7662 eta: 17:50:37.429210	Training Loss 5.5440 (5.3504)	Training Prec@1 94.727 (96.024)	Training Prec@5 96.680 (98.169)	
2022-04-03 16:35:51,369: ============================================================
2022-04-03 16:36:38,189: time cost, forward:0.01093494401928795, backward:0.05818060017289202, data cost:0.3916815316102112 
2022-04-03 16:36:38,189: ============================================================
2022-04-03 16:36:38,189: Epoch 8/26 Batch 4500/7662 eta: 18:20:54.100247	Training Loss 5.2988 (5.3512)	Training Prec@1 96.875 (96.021)	Training Prec@5 98.242 (98.167)	
2022-04-03 16:36:38,190: ============================================================
2022-04-03 16:37:25,731: time cost, forward:0.010925632063319668, backward:0.058187233206758705, data cost:0.39199700519348596 
2022-04-03 16:37:25,732: ============================================================
2022-04-03 16:37:25,732: Epoch 8/26 Batch 4600/7662 eta: 18:37:04.993873	Training Loss 5.2425 (5.3516)	Training Prec@1 97.461 (96.021)	Training Prec@5 98.828 (98.167)	
2022-04-03 16:37:25,732: ============================================================
2022-04-03 16:38:12,668: time cost, forward:0.010919223417244356, backward:0.05819336412612061, data cost:0.39214565160807763 
2022-04-03 16:38:12,669: ============================================================
2022-04-03 16:38:12,669: Epoch 8/26 Batch 4700/7662 eta: 18:22:04.328922	Training Loss 5.5398 (5.3520)	Training Prec@1 96.484 (96.023)	Training Prec@5 97.656 (98.165)	
2022-04-03 16:38:12,669: ============================================================
2022-04-03 16:38:59,435: time cost, forward:0.01091006711811591, backward:0.05819489722898737, data cost:0.3922873954272166 
2022-04-03 16:38:59,435: ============================================================
2022-04-03 16:38:59,435: Epoch 8/26 Batch 4800/7662 eta: 18:17:17.230118	Training Loss 5.6294 (5.3527)	Training Prec@1 95.508 (96.021)	Training Prec@5 97.266 (98.161)	
2022-04-03 16:38:59,436: ============================================================
2022-04-03 16:39:46,059: time cost, forward:0.010899846323608598, backward:0.05820468372898604, data cost:0.39237823722848697 
2022-04-03 16:39:46,060: ============================================================
2022-04-03 16:39:46,060: Epoch 8/26 Batch 4900/7662 eta: 18:13:10.802592	Training Loss 5.3665 (5.3537)	Training Prec@1 93.555 (96.015)	Training Prec@5 97.461 (98.158)	
2022-04-03 16:39:46,060: ============================================================
2022-04-03 16:40:33,883: time cost, forward:0.01089103251940061, backward:0.05820907929297041, data cost:0.39270843384527737 
2022-04-03 16:40:33,884: ============================================================
2022-04-03 16:40:33,884: Epoch 8/26 Batch 5000/7662 eta: 18:40:30.927125	Training Loss 5.6131 (5.3548)	Training Prec@1 95.508 (96.010)	Training Prec@5 98.438 (98.155)	
2022-04-03 16:40:33,884: ============================================================
2022-04-03 16:41:21,702: time cost, forward:0.010884323969240819, backward:0.05821451618989838, data cost:0.39300831805773634 
2022-04-03 16:41:21,702: ============================================================
2022-04-03 16:41:21,702: Epoch 8/26 Batch 5100/7662 eta: 18:39:34.817708	Training Loss 5.3739 (5.3549)	Training Prec@1 95.898 (96.008)	Training Prec@5 98.633 (98.155)	
2022-04-03 16:41:21,703: ============================================================
2022-04-03 16:42:09,535: time cost, forward:0.010876598255431155, backward:0.05822148775224343, data cost:0.393313567714981 
2022-04-03 16:42:09,535: ============================================================
2022-04-03 16:42:09,535: Epoch 8/26 Batch 5200/7662 eta: 18:39:07.014411	Training Loss 5.4868 (5.3562)	Training Prec@1 95.898 (96.006)	Training Prec@5 98.633 (98.153)	
2022-04-03 16:42:09,535: ============================================================
2022-04-03 16:42:55,263: time cost, forward:0.010869139296802896, backward:0.05822398609025318, data cost:0.39322345070983805 
2022-04-03 16:42:55,264: ============================================================
2022-04-03 16:42:55,264: Epoch 8/26 Batch 5300/7662 eta: 17:49:07.768984	Training Loss 5.0920 (5.3572)	Training Prec@1 97.266 (96.002)	Training Prec@5 99.023 (98.152)	
2022-04-03 16:42:55,264: ============================================================
2022-04-03 16:43:40,939: time cost, forward:0.010863196432513204, backward:0.05823026508904316, data cost:0.3931085659323147 
2022-04-03 16:43:40,939: ============================================================
2022-04-03 16:43:40,939: Epoch 8/26 Batch 5400/7662 eta: 17:47:07.391516	Training Loss 5.6815 (5.3580)	Training Prec@1 95.117 (95.998)	Training Prec@5 98.047 (98.148)	
2022-04-03 16:43:40,939: ============================================================
2022-04-03 16:44:27,686: time cost, forward:0.010859083795486786, backward:0.058236995248886474, data cost:0.3931891925986582 
2022-04-03 16:44:27,686: ============================================================
2022-04-03 16:44:27,686: Epoch 8/26 Batch 5500/7662 eta: 18:11:22.416165	Training Loss 5.5053 (5.3585)	Training Prec@1 95.508 (95.997)	Training Prec@5 97.656 (98.147)	
2022-04-03 16:44:27,686: ============================================================
2022-04-03 16:45:12,445: time cost, forward:0.010851472163758208, backward:0.05824184583795775, data cost:0.392908455495601 
2022-04-03 16:45:12,446: ============================================================
2022-04-03 16:45:12,446: Epoch 8/26 Batch 5600/7662 eta: 17:24:14.600053	Training Loss 5.1826 (5.3588)	Training Prec@1 96.484 (95.997)	Training Prec@5 98.242 (98.147)	
2022-04-03 16:45:12,446: ============================================================
2022-04-03 16:45:58,145: time cost, forward:0.010843806359658724, backward:0.05824607823015954, data cost:0.39282979164484993 
2022-04-03 16:45:58,146: ============================================================
2022-04-03 16:45:58,146: Epoch 8/26 Batch 5700/7662 eta: 17:45:24.194483	Training Loss 5.7250 (5.3591)	Training Prec@1 94.336 (95.995)	Training Prec@5 97.070 (98.146)	
2022-04-03 16:45:58,146: ============================================================
2022-04-03 16:46:43,990: time cost, forward:0.010837852965142936, backward:0.058252125202448005, data cost:0.39274899793875834 
2022-04-03 16:46:43,990: ============================================================
2022-04-03 16:46:43,991: Epoch 8/26 Batch 5800/7662 eta: 17:48:01.437645	Training Loss 5.5369 (5.3592)	Training Prec@1 96.094 (95.994)	Training Prec@5 98.633 (98.145)	
2022-04-03 16:46:43,991: ============================================================
2022-04-03 16:47:28,985: time cost, forward:0.010830966835002573, backward:0.058259347714212185, data cost:0.3925562345450117 
2022-04-03 16:47:28,986: ============================================================
2022-04-03 16:47:28,986: Epoch 8/26 Batch 5900/7662 eta: 17:27:29.065754	Training Loss 5.0580 (5.3593)	Training Prec@1 97.266 (95.992)	Training Prec@5 98.828 (98.145)	
2022-04-03 16:47:28,986: ============================================================
2022-04-03 16:48:13,882: time cost, forward:0.010825117223758382, backward:0.05826847420908805, data cost:0.3923202928930029 
2022-04-03 16:48:13,883: ============================================================
2022-04-03 16:48:13,883: Epoch 8/26 Batch 6000/7662 eta: 17:24:26.877246	Training Loss 5.6061 (5.3596)	Training Prec@1 95.312 (95.989)	Training Prec@5 97.656 (98.143)	
2022-04-03 16:48:13,883: ============================================================
2022-04-03 16:48:59,774: time cost, forward:0.010819242946201318, backward:0.05827153192267767, data cost:0.39228434698721254 
2022-04-03 16:48:59,775: ============================================================
2022-04-03 16:48:59,775: Epoch 8/26 Batch 6100/7662 eta: 17:46:49.692980	Training Loss 4.9726 (5.3597)	Training Prec@1 96.875 (95.987)	Training Prec@5 98.438 (98.142)	
2022-04-03 16:48:59,775: ============================================================
2022-04-03 16:49:43,754: time cost, forward:0.01081311943108352, backward:0.05827853675426293, data cost:0.39192931916294876 
2022-04-03 16:49:43,754: ============================================================
2022-04-03 16:49:43,754: Epoch 8/26 Batch 6200/7662 eta: 17:01:37.761367	Training Loss 5.3418 (5.3597)	Training Prec@1 95.508 (95.987)	Training Prec@5 97.266 (98.142)	
2022-04-03 16:49:43,754: ============================================================
2022-04-03 16:50:27,761: time cost, forward:0.010807537960616308, backward:0.05828333635295378, data cost:0.39158404174352907 
2022-04-03 16:50:27,761: ============================================================
2022-04-03 16:50:27,761: Epoch 8/26 Batch 6300/7662 eta: 17:01:32.506831	Training Loss 5.2093 (5.3598)	Training Prec@1 96.289 (95.985)	Training Prec@5 97.852 (98.140)	
2022-04-03 16:50:27,761: ============================================================
2022-04-03 16:51:12,958: time cost, forward:0.010801946358636759, backward:0.05828871278394701, data cost:0.39143940437061747 
2022-04-03 16:51:12,958: ============================================================
2022-04-03 16:51:12,958: Epoch 8/26 Batch 6400/7662 eta: 17:28:24.723376	Training Loss 5.4721 (5.3592)	Training Prec@1 96.289 (95.984)	Training Prec@5 98.047 (98.139)	
2022-04-03 16:51:12,958: ============================================================
2022-04-03 16:52:00,220: time cost, forward:0.010795727346948265, backward:0.0582934980631645, data cost:0.3916196361984321 
2022-04-03 16:52:00,220: ============================================================
2022-04-03 16:52:00,221: Epoch 8/26 Batch 6500/7662 eta: 18:15:32.251237	Training Loss 5.7081 (5.3601)	Training Prec@1 94.531 (95.981)	Training Prec@5 97.461 (98.138)	
2022-04-03 16:52:00,221: ============================================================
2022-04-03 16:52:46,608: time cost, forward:0.010787802187669168, backward:0.05830208896452558, data cost:0.3916568262213233 
2022-04-03 16:52:46,608: ============================================================
2022-04-03 16:52:46,608: Epoch 8/26 Batch 6600/7662 eta: 17:54:29.001652	Training Loss 5.4297 (5.3607)	Training Prec@1 96.680 (95.979)	Training Prec@5 98.633 (98.137)	
2022-04-03 16:52:46,608: ============================================================
2022-04-03 16:53:32,608: time cost, forward:0.01077879975315065, backward:0.05831059197344554, data cost:0.39164199073166256 
2022-04-03 16:53:32,608: ============================================================
2022-04-03 16:53:32,609: Epoch 8/26 Batch 6700/7662 eta: 17:44:44.854550	Training Loss 5.3485 (5.3614)	Training Prec@1 95.703 (95.977)	Training Prec@5 97.461 (98.134)	
2022-04-03 16:53:32,609: ============================================================
2022-04-03 16:54:17,602: time cost, forward:0.010770692985221592, backward:0.05831542269660017, data cost:0.391477311528909 
2022-04-03 16:54:17,602: ============================================================
2022-04-03 16:54:17,602: Epoch 8/26 Batch 6800/7662 eta: 17:20:41.564099	Training Loss 5.5027 (5.3616)	Training Prec@1 94.336 (95.978)	Training Prec@5 97.461 (98.136)	
2022-04-03 16:54:17,602: ============================================================
2022-04-03 16:55:03,305: time cost, forward:0.010761814335840891, backward:0.05832117335453191, data cost:0.39141483178327424 
2022-04-03 16:55:03,305: ============================================================
2022-04-03 16:55:03,305: Epoch 8/26 Batch 6900/7662 eta: 17:36:20.707144	Training Loss 5.4410 (5.3629)	Training Prec@1 93.555 (95.976)	Training Prec@5 97.070 (98.133)	
2022-04-03 16:55:03,306: ============================================================
2022-04-03 16:55:48,604: time cost, forward:0.010753490155314458, backward:0.05832508363490753, data cost:0.3913201560529918 
2022-04-03 16:55:48,604: ============================================================
2022-04-03 16:55:48,605: Epoch 8/26 Batch 7000/7662 eta: 17:26:15.120959	Training Loss 5.2657 (5.3633)	Training Prec@1 95.117 (95.972)	Training Prec@5 98.047 (98.132)	
2022-04-03 16:55:48,605: ============================================================
2022-04-03 16:56:34,193: time cost, forward:0.010744916568223583, backward:0.058330722519471155, data cost:0.391245970912073 
2022-04-03 16:56:34,194: ============================================================
2022-04-03 16:56:34,194: Epoch 8/26 Batch 7100/7662 eta: 17:32:11.571635	Training Loss 5.4028 (5.3636)	Training Prec@1 95.898 (95.971)	Training Prec@5 98.633 (98.132)	
2022-04-03 16:56:34,194: ============================================================
2022-04-03 16:57:19,688: time cost, forward:0.010737284933101603, backward:0.05833701283290231, data cost:0.3911636692067785 
2022-04-03 16:57:19,689: ============================================================
2022-04-03 16:57:19,689: Epoch 8/26 Batch 7200/7662 eta: 17:29:15.455618	Training Loss 5.4268 (5.3638)	Training Prec@1 96.484 (95.968)	Training Prec@5 98.242 (98.132)	
2022-04-03 16:57:19,689: ============================================================
2022-04-03 16:58:05,360: time cost, forward:0.010729516004924824, backward:0.05834416520646181, data cost:0.39110770469202477 
2022-04-03 16:58:05,360: ============================================================
2022-04-03 16:58:05,360: Epoch 8/26 Batch 7300/7662 eta: 17:32:34.053549	Training Loss 5.4271 (5.3637)	Training Prec@1 94.922 (95.967)	Training Prec@5 96.875 (98.130)	
2022-04-03 16:58:05,360: ============================================================
2022-04-03 16:58:51,402: time cost, forward:0.010722808893314326, backward:0.05834883131647709, data cost:0.39111321973613766 
2022-04-03 16:58:51,403: ============================================================
2022-04-03 16:58:51,403: Epoch 8/26 Batch 7400/7662 eta: 17:40:21.303631	Training Loss 5.3027 (5.3642)	Training Prec@1 94.922 (95.963)	Training Prec@5 98.828 (98.129)	
2022-04-03 16:58:51,403: ============================================================
2022-04-03 16:59:35,121: time cost, forward:0.01071638929985383, backward:0.05835546193273564, data cost:0.3907932010487344 
2022-04-03 16:59:35,121: ============================================================
2022-04-03 16:59:35,121: Epoch 8/26 Batch 7500/7662 eta: 16:46:06.050357	Training Loss 5.3689 (5.3646)	Training Prec@1 96.680 (95.963)	Training Prec@5 98.242 (98.129)	
2022-04-03 16:59:35,122: ============================================================
2022-04-03 17:00:20,476: time cost, forward:0.010709561020280988, backward:0.05835944838485587, data cost:0.39070594340566744 
2022-04-03 17:00:20,476: ============================================================
2022-04-03 17:00:20,477: Epoch 8/26 Batch 7600/7662 eta: 17:23:00.677469	Training Loss 5.3332 (5.3647)	Training Prec@1 97.070 (95.963)	Training Prec@5 99.023 (98.128)	
2022-04-03 17:00:20,477: ============================================================
2022-04-03 17:00:50,128: Epoch: 8/26 eta: 17:22:32.103681	Training Loss 5.4264 (5.3650)	Training Prec@1 95.312 (95.963)	Training Prec@5 97.461 (98.128)
2022-04-03 17:00:50,128: ============================================================
2022-04-03 17:01:36,834: time cost, forward:0.010265759747437757, backward:0.05820812841858527, data cost:0.39795785480075413 
2022-04-03 17:01:36,835: ============================================================
2022-04-03 17:01:36,835: Epoch 9/26 Batch 100/7662 eta: 17:50:13.597822	Training Loss 5.0526 (4.9630)	Training Prec@1 95.898 (96.723)	Training Prec@5 98.047 (98.548)	
2022-04-03 17:01:36,835: ============================================================
2022-04-03 17:02:20,693: time cost, forward:0.010531242169327472, backward:0.058149742720714166, data cost:0.3834127002025968 
2022-04-03 17:02:20,693: ============================================================
2022-04-03 17:02:20,694: Epoch 9/26 Batch 200/7662 eta: 16:46:40.626539	Training Loss 5.0518 (4.9782)	Training Prec@1 96.875 (96.736)	Training Prec@5 98.242 (98.571)	
2022-04-03 17:02:20,694: ============================================================
2022-04-03 17:03:05,724: time cost, forward:0.010568358826398052, backward:0.05816889766067964, data cost:0.38252029450840774 
2022-04-03 17:03:05,724: ============================================================
2022-04-03 17:03:05,725: Epoch 9/26 Batch 300/7662 eta: 17:12:50.076208	Training Loss 5.2299 (5.0147)	Training Prec@1 96.484 (96.682)	Training Prec@5 99.023 (98.535)	
2022-04-03 17:03:05,725: ============================================================
2022-04-03 17:03:51,489: time cost, forward:0.01045239778389608, backward:0.058318372955895904, data cost:0.3841298725969511 
2022-04-03 17:03:51,490: ============================================================
2022-04-03 17:03:51,490: Epoch 9/26 Batch 400/7662 eta: 17:28:55.108633	Training Loss 5.2196 (5.0530)	Training Prec@1 96.484 (96.637)	Training Prec@5 98.047 (98.513)	
2022-04-03 17:03:51,490: ============================================================
2022-04-03 17:04:36,675: time cost, forward:0.010466386416632093, backward:0.05837185683852446, data cost:0.3837324999616237 
2022-04-03 17:04:36,676: ============================================================
2022-04-03 17:04:36,676: Epoch 9/26 Batch 500/7662 eta: 17:14:53.341437	Training Loss 5.2110 (5.0788)	Training Prec@1 96.094 (96.619)	Training Prec@5 98.438 (98.492)	
2022-04-03 17:04:36,676: ============================================================
2022-04-03 17:05:21,152: time cost, forward:0.010429371577471445, backward:0.05843333608917083, data cost:0.38228395626023537 
2022-04-03 17:05:21,153: ============================================================
2022-04-03 17:05:21,153: Epoch 9/26 Batch 600/7662 eta: 16:57:54.488635	Training Loss 4.9258 (5.1075)	Training Prec@1 96.289 (96.564)	Training Prec@5 97.852 (98.467)	
2022-04-03 17:05:21,153: ============================================================
2022-04-03 17:06:07,408: time cost, forward:0.010356906145938987, backward:0.05853631840925531, data cost:0.38370088309859685 
2022-04-03 17:06:07,408: ============================================================
2022-04-03 17:06:07,408: Epoch 9/26 Batch 700/7662 eta: 17:37:50.060800	Training Loss 5.3447 (5.1305)	Training Prec@1 95.703 (96.516)	Training Prec@5 97.656 (98.438)	
2022-04-03 17:06:07,408: ============================================================
2022-04-03 17:06:52,223: time cost, forward:0.010309794071469647, backward:0.05861407108092039, data cost:0.3831401841064568 
2022-04-03 17:06:52,223: ============================================================
2022-04-03 17:06:52,223: Epoch 9/26 Batch 800/7662 eta: 17:04:09.201025	Training Loss 5.3255 (5.1485)	Training Prec@1 96.875 (96.472)	Training Prec@5 98.633 (98.416)	
2022-04-03 17:06:52,224: ============================================================
2022-04-03 17:07:37,332: time cost, forward:0.010291101139565067, backward:0.05864143901990439, data cost:0.382944493723393 
2022-04-03 17:07:37,332: ============================================================
2022-04-03 17:07:37,332: Epoch 9/26 Batch 900/7662 eta: 17:10:06.618237	Training Loss 5.4098 (5.1685)	Training Prec@1 95.898 (96.421)	Training Prec@5 98.242 (98.391)	
2022-04-03 17:07:37,332: ============================================================
2022-04-03 17:08:22,712: time cost, forward:0.010291437009672026, backward:0.05864019293684859, data cost:0.3831237398229681 
2022-04-03 17:08:22,712: ============================================================
2022-04-03 17:08:22,712: Epoch 9/26 Batch 1000/7662 eta: 17:15:33.100912	Training Loss 5.2228 (5.1816)	Training Prec@1 96.289 (96.397)	Training Prec@5 98.633 (98.376)	
2022-04-03 17:08:22,712: ============================================================
2022-04-03 17:09:08,290: time cost, forward:0.010288303824746685, backward:0.05865025043053666, data cost:0.3834002477890584 
2022-04-03 17:09:08,290: ============================================================
2022-04-03 17:09:08,291: Epoch 9/26 Batch 1100/7662 eta: 17:19:19.172271	Training Loss 5.0918 (5.1953)	Training Prec@1 96.680 (96.353)	Training Prec@5 98.633 (98.348)	
2022-04-03 17:09:08,291: ============================================================
2022-04-03 17:09:54,237: time cost, forward:0.01029259548075901, backward:0.05862941733989445, data cost:0.3839089019384058 
2022-04-03 17:09:54,237: ============================================================
2022-04-03 17:09:54,238: Epoch 9/26 Batch 1200/7662 eta: 17:26:57.033742	Training Loss 5.5458 (5.2044)	Training Prec@1 95.703 (96.336)	Training Prec@5 98.633 (98.336)	
2022-04-03 17:09:54,238: ============================================================
2022-04-03 17:10:38,625: time cost, forward:0.010316898310707569, backward:0.05860416278002169, data cost:0.3832171561628052 
2022-04-03 17:10:38,626: ============================================================
2022-04-03 17:10:38,626: Epoch 9/26 Batch 1300/7662 eta: 16:50:41.946143	Training Loss 5.2853 (5.2150)	Training Prec@1 96.094 (96.319)	Training Prec@5 98.438 (98.328)	
2022-04-03 17:10:38,626: ============================================================
2022-04-03 17:11:24,082: time cost, forward:0.010332739123111967, backward:0.05857862090110097, data cost:0.38335909904796284 
2022-04-03 17:11:24,082: ============================================================
2022-04-03 17:11:24,082: Epoch 9/26 Batch 1400/7662 eta: 17:14:15.621690	Training Loss 5.4547 (5.2242)	Training Prec@1 95.703 (96.294)	Training Prec@5 98.242 (98.318)	
2022-04-03 17:11:24,082: ============================================================
2022-04-03 17:12:10,814: time cost, forward:0.010380588745259697, backward:0.058533510420623026, data cost:0.38432214035838347 
2022-04-03 17:12:10,815: ============================================================
2022-04-03 17:12:10,815: Epoch 9/26 Batch 1500/7662 eta: 17:42:31.331246	Training Loss 5.4565 (5.2342)	Training Prec@1 96.484 (96.270)	Training Prec@5 98.438 (98.306)	
2022-04-03 17:12:10,815: ============================================================
2022-04-03 17:12:56,474: time cost, forward:0.010430751851829161, backward:0.05849312185271969, data cost:0.3842505924100798 
2022-04-03 17:12:56,474: ============================================================
2022-04-03 17:12:56,475: Epoch 9/26 Batch 1600/7662 eta: 17:17:22.074513	Training Loss 5.0899 (5.2414)	Training Prec@1 97.656 (96.254)	Training Prec@5 99.414 (98.296)	
2022-04-03 17:12:56,475: ============================================================
2022-04-03 17:13:42,062: time cost, forward:0.010460888097537414, backward:0.058478800249913636, data cost:0.38459900353079757 
2022-04-03 17:13:42,063: ============================================================
2022-04-03 17:13:42,064: Epoch 9/26 Batch 1700/7662 eta: 17:14:59.842752	Training Loss 5.4465 (5.2483)	Training Prec@1 95.703 (96.239)	Training Prec@5 97.852 (98.289)	
2022-04-03 17:13:42,064: ============================================================
2022-04-03 17:14:27,334: time cost, forward:0.010466637115732971, backward:0.05848765055161837, data cost:0.3845035840300072 
2022-04-03 17:14:27,335: ============================================================
2022-04-03 17:14:27,335: Epoch 9/26 Batch 1800/7662 eta: 17:07:01.795655	Training Loss 5.4730 (5.2543)	Training Prec@1 97.070 (96.217)	Training Prec@5 98.828 (98.278)	
2022-04-03 17:14:27,335: ============================================================
2022-04-03 17:15:10,081: time cost, forward:0.010475550154876306, backward:0.058498770516442276, data cost:0.3831043441776478 
2022-04-03 17:15:10,081: ============================================================
2022-04-03 17:15:10,081: Epoch 9/26 Batch 1900/7662 eta: 16:09:02.346402	Training Loss 5.6527 (5.2597)	Training Prec@1 93.945 (96.200)	Training Prec@5 96.875 (98.268)	
2022-04-03 17:15:10,081: ============================================================
2022-04-03 17:15:52,859: time cost, forward:0.010502148652565723, backward:0.05847945292035361, data cost:0.3818435796563061 
2022-04-03 17:15:52,860: ============================================================
2022-04-03 17:15:52,860: Epoch 9/26 Batch 2000/7662 eta: 16:09:03.528425	Training Loss 5.5477 (5.2648)	Training Prec@1 95.898 (96.183)	Training Prec@5 98.828 (98.255)	
2022-04-03 17:15:52,860: ============================================================
2022-04-03 17:16:38,746: time cost, forward:0.010543698637527531, backward:0.058440459348179714, data cost:0.3821767612319154 
2022-04-03 17:16:38,747: ============================================================
2022-04-03 17:16:38,747: Epoch 9/26 Batch 2100/7662 eta: 17:18:42.655498	Training Loss 5.5786 (5.2690)	Training Prec@1 96.289 (96.173)	Training Prec@5 99.023 (98.253)	
2022-04-03 17:16:38,747: ============================================================
2022-04-03 17:17:25,325: time cost, forward:0.010554388578830388, backward:0.05844795785203962, data cost:0.3828114220748006 
2022-04-03 17:17:25,326: ============================================================
2022-04-03 17:17:25,326: Epoch 9/26 Batch 2200/7662 eta: 17:33:35.366772	Training Loss 5.2565 (5.2717)	Training Prec@1 96.680 (96.167)	Training Prec@5 98.828 (98.249)	
2022-04-03 17:17:25,326: ============================================================
2022-04-03 17:18:09,914: time cost, forward:0.01059763718812867, backward:0.058421903716423765, data cost:0.3824668520686418 
2022-04-03 17:18:09,914: ============================================================
2022-04-03 17:18:09,914: Epoch 9/26 Batch 2300/7662 eta: 16:47:49.565706	Training Loss 5.4399 (5.2751)	Training Prec@1 95.898 (96.152)	Training Prec@5 98.242 (98.242)	
2022-04-03 17:18:09,915: ============================================================
2022-04-03 17:18:53,843: time cost, forward:0.010587542491338808, backward:0.05844125125546314, data cost:0.38197232932535596 
2022-04-03 17:18:53,844: ============================================================
2022-04-03 17:18:53,844: Epoch 9/26 Batch 2400/7662 eta: 16:32:11.847279	Training Loss 5.2061 (5.2785)	Training Prec@1 95.508 (96.144)	Training Prec@5 98.242 (98.237)	
2022-04-03 17:18:53,844: ============================================================
2022-04-03 17:19:37,189: time cost, forward:0.0105848401105132, backward:0.05846013322550089, data cost:0.38122678518581504 
2022-04-03 17:19:37,189: ============================================================
2022-04-03 17:19:37,190: Epoch 9/26 Batch 2500/7662 eta: 16:18:17.510853	Training Loss 5.5002 (5.2825)	Training Prec@1 96.094 (96.131)	Training Prec@5 98.242 (98.228)	
2022-04-03 17:19:37,190: ============================================================
2022-04-03 17:20:22,138: time cost, forward:0.010590737303572005, backward:0.058465009563104055, data cost:0.38115652922072196 
2022-04-03 17:20:22,139: ============================================================
2022-04-03 17:20:22,139: Epoch 9/26 Batch 2600/7662 eta: 16:53:44.192755	Training Loss 5.3530 (5.2856)	Training Prec@1 95.898 (96.122)	Training Prec@5 98.438 (98.224)	
2022-04-03 17:20:22,139: ============================================================
2022-04-03 17:21:09,279: time cost, forward:0.010609784007911639, backward:0.058453882301502995, data cost:0.3819083825620557 
2022-04-03 17:21:09,280: ============================================================
2022-04-03 17:21:09,280: Epoch 9/26 Batch 2700/7662 eta: 17:42:22.568320	Training Loss 5.3868 (5.2884)	Training Prec@1 96.094 (96.112)	Training Prec@5 98.242 (98.218)	
2022-04-03 17:21:09,280: ============================================================
2022-04-03 17:21:56,073: time cost, forward:0.010614979560991064, backward:0.058456727546127664, data cost:0.38249702707449423 
2022-04-03 17:21:56,074: ============================================================
2022-04-03 17:21:56,074: Epoch 9/26 Batch 2800/7662 eta: 17:33:46.757421	Training Loss 5.5583 (5.2904)	Training Prec@1 96.094 (96.112)	Training Prec@5 98.047 (98.217)	
2022-04-03 17:21:56,074: ============================================================
2022-04-03 17:22:42,452: time cost, forward:0.01075901085444671, backward:0.05832362479281943, data cost:0.38287578471243977 
2022-04-03 17:22:42,453: ============================================================
2022-04-03 17:22:42,453: Epoch 9/26 Batch 2900/7662 eta: 17:23:39.624816	Training Loss 5.4219 (5.2928)	Training Prec@1 94.141 (96.106)	Training Prec@5 97.266 (98.211)	
2022-04-03 17:22:42,453: ============================================================
2022-04-03 17:23:27,266: time cost, forward:0.010758030768353449, backward:0.05832892475465251, data cost:0.3827396293766064 
2022-04-03 17:23:27,266: ============================================================
2022-04-03 17:23:27,267: Epoch 9/26 Batch 3000/7662 eta: 16:47:41.228809	Training Loss 5.3040 (5.2951)	Training Prec@1 96.875 (96.100)	Training Prec@5 99.023 (98.205)	
2022-04-03 17:23:27,267: ============================================================
2022-04-03 17:24:13,498: time cost, forward:0.01077283417343824, backward:0.058326432842637464, data cost:0.3830653989495828 
2022-04-03 17:24:13,498: ============================================================
2022-04-03 17:24:13,498: Epoch 9/26 Batch 3100/7662 eta: 17:18:47.778198	Training Loss 5.6336 (5.2966)	Training Prec@1 94.727 (96.097)	Training Prec@5 98.047 (98.203)	
2022-04-03 17:24:13,498: ============================================================
2022-04-03 17:25:00,524: time cost, forward:0.010775096940412936, backward:0.05833166150161347, data cost:0.3835865234203285 
2022-04-03 17:25:00,524: ============================================================
2022-04-03 17:25:00,524: Epoch 9/26 Batch 3200/7662 eta: 17:35:52.072659	Training Loss 5.2384 (5.2984)	Training Prec@1 95.898 (96.090)	Training Prec@5 97.852 (98.199)	
2022-04-03 17:25:00,524: ============================================================
2022-04-03 17:25:47,910: time cost, forward:0.01076828591496195, backward:0.05834356254792712, data cost:0.3842062589507206 
2022-04-03 17:25:47,910: ============================================================
2022-04-03 17:25:47,911: Epoch 9/26 Batch 3300/7662 eta: 17:43:10.142043	Training Loss 5.3593 (5.2996)	Training Prec@1 95.703 (96.086)	Training Prec@5 96.875 (98.197)	
2022-04-03 17:25:47,911: ============================================================
2022-04-03 17:26:34,080: time cost, forward:0.010770978840634065, backward:0.0583480953924724, data cost:0.3844174384088788 
2022-04-03 17:26:34,080: ============================================================
2022-04-03 17:26:34,080: Epoch 9/26 Batch 3400/7662 eta: 17:15:06.184383	Training Loss 5.4061 (5.3010)	Training Prec@1 95.898 (96.081)	Training Prec@5 98.242 (98.192)	
2022-04-03 17:26:34,081: ============================================================
2022-04-03 17:27:20,498: time cost, forward:0.010808082470453681, backward:0.058314716110709194, data cost:0.3847168193063793 
2022-04-03 17:27:20,499: ============================================================
2022-04-03 17:27:20,499: Epoch 9/26 Batch 3500/7662 eta: 17:19:54.401542	Training Loss 5.6420 (5.3030)	Training Prec@1 95.898 (96.078)	Training Prec@5 98.633 (98.192)	
2022-04-03 17:27:20,499: ============================================================
2022-04-03 17:28:06,156: time cost, forward:0.010799557939440915, backward:0.058337654594448944, data cost:0.38476319212355725 
2022-04-03 17:28:06,156: ============================================================
2022-04-03 17:28:06,157: Epoch 9/26 Batch 3600/7662 eta: 17:02:06.092701	Training Loss 5.2732 (5.3043)	Training Prec@1 96.094 (96.076)	Training Prec@5 98.633 (98.191)	
2022-04-03 17:28:06,157: ============================================================
2022-04-03 17:28:50,791: time cost, forward:0.01082698671712718, backward:0.058317362343694557, data cost:0.38452765960311786 
2022-04-03 17:28:50,791: ============================================================
2022-04-03 17:28:50,792: Epoch 9/26 Batch 3700/7662 eta: 16:38:27.908976	Training Loss 5.4325 (5.3058)	Training Prec@1 95.312 (96.073)	Training Prec@5 97.656 (98.191)	
2022-04-03 17:28:50,792: ============================================================
2022-04-03 17:29:36,040: time cost, forward:0.010850338284421451, backward:0.05830539079301136, data cost:0.38447124715163916 
2022-04-03 17:29:36,040: ============================================================
2022-04-03 17:29:36,040: Epoch 9/26 Batch 3800/7662 eta: 16:51:25.874293	Training Loss 5.5308 (5.3069)	Training Prec@1 95.898 (96.068)	Training Prec@5 97.266 (98.189)	
2022-04-03 17:29:36,040: ============================================================
2022-04-03 17:30:22,411: time cost, forward:0.010857105316275602, backward:0.05830447568010446, data cost:0.38470509756097554 
2022-04-03 17:30:22,411: ============================================================
2022-04-03 17:30:22,412: Epoch 9/26 Batch 3900/7662 eta: 17:15:45.416470	Training Loss 5.5012 (5.3080)	Training Prec@1 96.484 (96.069)	Training Prec@5 98.438 (98.189)	
2022-04-03 17:30:22,412: ============================================================
2022-04-03 17:31:09,760: time cost, forward:0.010846302967782199, backward:0.05832162640278982, data cost:0.38518763631843095 
2022-04-03 17:31:09,760: ============================================================
2022-04-03 17:31:09,761: Epoch 9/26 Batch 4000/7662 eta: 17:36:48.399571	Training Loss 5.1632 (5.3097)	Training Prec@1 95.898 (96.062)	Training Prec@5 98.438 (98.186)	
2022-04-03 17:31:09,761: ============================================================
2022-04-03 17:31:55,506: time cost, forward:0.010841495788920416, backward:0.058329108401780363, data cost:0.3852482407987045 
2022-04-03 17:31:55,506: ============================================================
2022-04-03 17:31:55,507: Epoch 9/26 Batch 4100/7662 eta: 17:00:15.940203	Training Loss 5.1620 (5.3106)	Training Prec@1 95.117 (96.058)	Training Prec@5 98.633 (98.184)	
2022-04-03 17:31:55,507: ============================================================
2022-04-03 17:32:41,553: time cost, forward:0.010849230174196138, backward:0.05832431259028087, data cost:0.385380906018509 
2022-04-03 17:32:41,554: ============================================================
2022-04-03 17:32:41,554: Epoch 9/26 Batch 4200/7662 eta: 17:06:12.988892	Training Loss 5.2589 (5.3119)	Training Prec@1 96.484 (96.054)	Training Prec@5 97.656 (98.183)	
2022-04-03 17:32:41,554: ============================================================
2022-04-03 17:33:27,657: time cost, forward:0.010849993460176711, backward:0.058328345809656124, data cost:0.3855122479485146 
2022-04-03 17:33:27,658: ============================================================
2022-04-03 17:33:27,658: Epoch 9/26 Batch 4300/7662 eta: 17:06:42.904451	Training Loss 5.4247 (5.3130)	Training Prec@1 95.117 (96.049)	Training Prec@5 97.266 (98.180)	
2022-04-03 17:33:27,658: ============================================================
2022-04-03 17:34:13,810: time cost, forward:0.010879500071063154, backward:0.05829999435487241, data cost:0.38563874917399965 
2022-04-03 17:34:13,811: ============================================================
2022-04-03 17:34:13,811: Epoch 9/26 Batch 4400/7662 eta: 17:07:02.041956	Training Loss 5.1538 (5.3136)	Training Prec@1 96.484 (96.049)	Training Prec@5 97.852 (98.181)	
2022-04-03 17:34:13,811: ============================================================
2022-04-03 17:35:00,680: time cost, forward:0.01088782532211409, backward:0.05829288594376699, data cost:0.3859340177427056 
2022-04-03 17:35:00,680: ============================================================
2022-04-03 17:35:00,681: Epoch 9/26 Batch 4500/7662 eta: 17:22:12.147589	Training Loss 5.0813 (5.3143)	Training Prec@1 96.875 (96.045)	Training Prec@5 98.242 (98.178)	
2022-04-03 17:35:00,681: ============================================================
2022-04-03 17:35:46,150: time cost, forward:0.010887130132626648, backward:0.05829458377702933, data cost:0.38592356452477394 
2022-04-03 17:35:46,151: ============================================================
2022-04-03 17:35:46,151: Epoch 9/26 Batch 4600/7662 eta: 16:50:19.734199	Training Loss 5.5329 (5.3151)	Training Prec@1 95.312 (96.044)	Training Prec@5 97.266 (98.176)	
2022-04-03 17:35:46,151: ============================================================
2022-04-03 17:36:32,608: time cost, forward:0.01088281138497836, backward:0.058303721434614916, data cost:0.3861051643876528 
2022-04-03 17:36:32,608: ============================================================
2022-04-03 17:36:32,609: Epoch 9/26 Batch 4700/7662 eta: 17:11:29.645065	Training Loss 5.6205 (5.3162)	Training Prec@1 95.898 (96.040)	Training Prec@5 98.633 (98.172)	
2022-04-03 17:36:32,609: ============================================================
2022-04-03 17:37:18,582: time cost, forward:0.010892087207483386, backward:0.0582991562974679, data cost:0.38618118083832237 
2022-04-03 17:37:18,583: ============================================================
2022-04-03 17:37:18,583: Epoch 9/26 Batch 4800/7662 eta: 16:59:59.494553	Training Loss 5.2271 (5.3168)	Training Prec@1 96.680 (96.040)	Training Prec@5 98.242 (98.174)	
2022-04-03 17:37:18,583: ============================================================
2022-04-03 17:38:04,701: time cost, forward:0.0108903505578774, backward:0.05830364495935574, data cost:0.3862860401349789 
2022-04-03 17:38:04,701: ============================================================
2022-04-03 17:38:04,701: Epoch 9/26 Batch 4900/7662 eta: 17:02:25.175888	Training Loss 5.3648 (5.3169)	Training Prec@1 95.312 (96.039)	Training Prec@5 98.242 (98.173)	
2022-04-03 17:38:04,701: ============================================================
2022-04-03 17:38:51,098: time cost, forward:0.010885734514227675, backward:0.058310469810331694, data cost:0.38643838954367715 
2022-04-03 17:38:51,098: ============================================================
2022-04-03 17:38:51,098: Epoch 9/26 Batch 5000/7662 eta: 17:07:49.554779	Training Loss 5.6578 (5.3168)	Training Prec@1 95.312 (96.039)	Training Prec@5 97.656 (98.173)	
2022-04-03 17:38:51,099: ============================================================
2022-04-03 17:39:38,123: time cost, forward:0.010884009054722237, backward:0.058317519795967096, data cost:0.3867114500616971 
2022-04-03 17:39:38,123: ============================================================
2022-04-03 17:39:38,124: Epoch 9/26 Batch 5100/7662 eta: 17:20:57.775132	Training Loss 5.3544 (5.3173)	Training Prec@1 96.289 (96.038)	Training Prec@5 98.242 (98.172)	
2022-04-03 17:39:38,124: ============================================================
2022-04-03 17:40:23,843: time cost, forward:0.010881713271760143, backward:0.058321568479352694, data cost:0.38672201402784884 
2022-04-03 17:40:23,844: ============================================================
2022-04-03 17:40:23,844: Epoch 9/26 Batch 5200/7662 eta: 16:51:18.751621	Training Loss 5.4087 (5.3184)	Training Prec@1 95.508 (96.033)	Training Prec@5 97.852 (98.169)	
2022-04-03 17:40:23,845: ============================================================
2022-04-03 17:41:09,327: time cost, forward:0.010886829649418969, backward:0.05832068351872306, data cost:0.3866884042056333 
2022-04-03 17:41:09,328: ============================================================
2022-04-03 17:41:09,328: Epoch 9/26 Batch 5300/7662 eta: 16:45:19.703101	Training Loss 5.4004 (5.3190)	Training Prec@1 95.508 (96.030)	Training Prec@5 98.633 (98.167)	
2022-04-03 17:41:09,329: ============================================================
2022-04-03 17:41:55,844: time cost, forward:0.01091525412904132, backward:0.05829189675541846, data cost:0.38685044228401333 
2022-04-03 17:41:55,844: ============================================================
2022-04-03 17:41:55,844: Epoch 9/26 Batch 5400/7662 eta: 17:07:21.816287	Training Loss 5.3978 (5.3196)	Training Prec@1 96.875 (96.027)	Training Prec@5 98.438 (98.166)	
2022-04-03 17:41:55,845: ============================================================
2022-04-03 17:42:41,868: time cost, forward:0.010907473532063979, backward:0.058302742239561355, data cost:0.3869107547814813 
2022-04-03 17:42:41,869: ============================================================
2022-04-03 17:42:41,869: Epoch 9/26 Batch 5500/7662 eta: 16:55:44.417667	Training Loss 5.6728 (5.3202)	Training Prec@1 94.531 (96.024)	Training Prec@5 97.070 (98.165)	
2022-04-03 17:42:41,869: ============================================================
2022-04-03 17:43:27,850: time cost, forward:0.010930531279149492, backward:0.05828318193057197, data cost:0.38696501799663663 
2022-04-03 17:43:27,850: ============================================================
2022-04-03 17:43:27,850: Epoch 9/26 Batch 5600/7662 eta: 16:54:01.248489	Training Loss 5.6013 (5.3210)	Training Prec@1 95.703 (96.021)	Training Prec@5 97.461 (98.166)	
2022-04-03 17:43:27,851: ============================================================
2022-04-03 17:44:12,503: time cost, forward:0.010928171604301746, backward:0.05828528614248345, data cost:0.3867886914435469 
2022-04-03 17:44:12,503: ============================================================
2022-04-03 17:44:12,503: Epoch 9/26 Batch 5700/7662 eta: 16:23:58.717832	Training Loss 5.4484 (5.3218)	Training Prec@1 94.727 (96.018)	Training Prec@5 97.461 (98.163)	
2022-04-03 17:44:12,504: ============================================================
2022-04-03 17:44:58,393: time cost, forward:0.010924900908123977, backward:0.05828736000666229, data cost:0.38682942091133865 
2022-04-03 17:44:58,393: ============================================================
2022-04-03 17:44:58,393: Epoch 9/26 Batch 5800/7662 eta: 16:50:28.461514	Training Loss 5.4967 (5.3223)	Training Prec@1 96.484 (96.015)	Training Prec@5 98.633 (98.160)	
2022-04-03 17:44:58,394: ============================================================
2022-04-03 17:45:43,250: time cost, forward:0.010922115765338955, backward:0.05829129410630708, data cost:0.3866658473867626 
2022-04-03 17:45:43,250: ============================================================
2022-04-03 17:45:43,250: Epoch 9/26 Batch 5900/7662 eta: 16:26:58.716331	Training Loss 5.3603 (5.3221)	Training Prec@1 96.094 (96.017)	Training Prec@5 98.633 (98.161)	
2022-04-03 17:45:43,250: ============================================================
2022-04-03 17:46:29,590: time cost, forward:0.0109208166291265, backward:0.0582944481228566, data cost:0.386819070369964 
2022-04-03 17:46:29,590: ============================================================
2022-04-03 17:46:29,591: Epoch 9/26 Batch 6000/7662 eta: 16:58:50.653145	Training Loss 5.2341 (5.3230)	Training Prec@1 96.289 (96.012)	Training Prec@5 98.047 (98.159)	
2022-04-03 17:46:29,591: ============================================================
2022-04-03 17:47:14,987: time cost, forward:0.010919462913254243, backward:0.058296996739129976, data cost:0.38677108665043497 
2022-04-03 17:47:14,988: ============================================================
2022-04-03 17:47:14,988: Epoch 9/26 Batch 6100/7662 eta: 16:37:21.617597	Training Loss 5.6696 (5.3233)	Training Prec@1 95.117 (96.010)	Training Prec@5 97.266 (98.159)	
2022-04-03 17:47:14,988: ============================================================
2022-04-03 17:47:59,841: time cost, forward:0.010919358542242788, backward:0.058298107385058466, data cost:0.38662020878207976 
2022-04-03 17:47:59,842: ============================================================
2022-04-03 17:47:59,842: Epoch 9/26 Batch 6200/7662 eta: 16:24:40.005396	Training Loss 5.1113 (5.3235)	Training Prec@1 96.094 (96.009)	Training Prec@5 98.633 (98.159)	
2022-04-03 17:47:59,842: ============================================================
2022-04-03 17:48:45,518: time cost, forward:0.010915231280789374, backward:0.05830467566741347, data cost:0.3866402611957313 
2022-04-03 17:48:45,518: ============================================================
2022-04-03 17:48:45,518: Epoch 9/26 Batch 6300/7662 eta: 16:41:58.290780	Training Loss 5.1875 (5.3240)	Training Prec@1 95.703 (96.006)	Training Prec@5 98.047 (98.158)	
2022-04-03 17:48:45,519: ============================================================
2022-04-03 17:49:29,212: time cost, forward:0.010911577175251859, backward:0.05831088839443163, data cost:0.38633350004049216 
2022-04-03 17:49:29,213: ============================================================
2022-04-03 17:49:29,213: Epoch 9/26 Batch 6400/7662 eta: 15:57:45.613372	Training Loss 5.2647 (5.3242)	Training Prec@1 97.266 (96.005)	Training Prec@5 98.828 (98.157)	
2022-04-03 17:49:29,213: ============================================================
2022-04-03 17:50:14,755: time cost, forward:0.010913580633123246, backward:0.05830778843036962, data cost:0.3863229123899287 
2022-04-03 17:50:14,755: ============================================================
2022-04-03 17:50:14,756: Epoch 9/26 Batch 6500/7662 eta: 16:37:31.182250	Training Loss 5.4629 (5.3246)	Training Prec@1 94.336 (96.006)	Training Prec@5 97.656 (98.157)	
2022-04-03 17:50:14,756: ============================================================
2022-04-03 17:50:59,967: time cost, forward:0.010915156511993802, backward:0.05830635047533382, data cost:0.38626242182547077 
2022-04-03 17:50:59,967: ============================================================
2022-04-03 17:50:59,968: Epoch 9/26 Batch 6600/7662 eta: 16:29:30.591059	Training Loss 5.3096 (5.3253)	Training Prec@1 96.680 (96.004)	Training Prec@5 98.438 (98.156)	
2022-04-03 17:50:59,968: ============================================================
2022-04-03 17:51:45,586: time cost, forward:0.010908583452993764, backward:0.058314473437878565, data cost:0.38627230866593487 
2022-04-03 17:51:45,586: ============================================================
2022-04-03 17:51:45,586: Epoch 9/26 Batch 6700/7662 eta: 16:37:39.684831	Training Loss 5.1499 (5.3254)	Training Prec@1 96.484 (96.002)	Training Prec@5 98.242 (98.156)	
2022-04-03 17:51:45,587: ============================================================
2022-04-03 17:52:31,740: time cost, forward:0.01090072140761694, backward:0.05832163921821326, data cost:0.3863461091248739 
2022-04-03 17:52:31,741: ============================================================
2022-04-03 17:52:31,741: Epoch 9/26 Batch 6800/7662 eta: 16:48:36.406716	Training Loss 5.4435 (5.3257)	Training Prec@1 96.094 (96.001)	Training Prec@5 98.242 (98.156)	
2022-04-03 17:52:31,741: ============================================================
2022-04-03 17:53:17,357: time cost, forward:0.010897043563780845, backward:0.058325820978974444, data cost:0.3863460502342515 
2022-04-03 17:53:17,357: ============================================================
2022-04-03 17:53:17,357: Epoch 9/26 Batch 6900/7662 eta: 16:36:05.470570	Training Loss 5.4505 (5.3265)	Training Prec@1 94.336 (95.998)	Training Prec@5 97.266 (98.155)	
2022-04-03 17:53:17,358: ============================================================
2022-04-03 17:54:02,978: time cost, forward:0.010939523345624605, backward:0.05828506365079916, data cost:0.3863524039279803 
2022-04-03 17:54:02,978: ============================================================
2022-04-03 17:54:02,978: Epoch 9/26 Batch 7000/7662 eta: 16:35:25.548813	Training Loss 5.3681 (5.3270)	Training Prec@1 95.898 (95.996)	Training Prec@5 98.047 (98.153)	
2022-04-03 17:54:02,979: ============================================================
2022-04-03 17:54:47,159: time cost, forward:0.010940890124791575, backward:0.058283943645650864, data cost:0.3861435293597157 
2022-04-03 17:54:47,160: ============================================================
2022-04-03 17:54:47,160: Epoch 9/26 Batch 7100/7662 eta: 16:03:16.917167	Training Loss 5.3280 (5.3269)	Training Prec@1 95.703 (95.995)	Training Prec@5 97.852 (98.153)	
2022-04-03 17:54:47,160: ============================================================
2022-04-03 17:55:33,097: time cost, forward:0.010938175917830893, backward:0.058288498940873866, data cost:0.38619202854799256 
2022-04-03 17:55:33,097: ============================================================
2022-04-03 17:55:33,097: Epoch 9/26 Batch 7200/7662 eta: 16:40:48.223162	Training Loss 5.3692 (5.3272)	Training Prec@1 94.922 (95.995)	Training Prec@5 98.438 (98.152)	
2022-04-03 17:55:33,098: ============================================================
2022-04-03 17:56:19,181: time cost, forward:0.010932717360540814, backward:0.05829600024376851, data cost:0.386253168720434 
2022-04-03 17:56:19,181: ============================================================
2022-04-03 17:56:19,182: Epoch 9/26 Batch 7300/7662 eta: 16:43:13.764512	Training Loss 5.2230 (5.3281)	Training Prec@1 96.289 (95.991)	Training Prec@5 99.023 (98.148)	
2022-04-03 17:56:19,182: ============================================================
2022-04-03 17:57:05,290: time cost, forward:0.010933794545424856, backward:0.05829687643122038, data cost:0.38632360566772467 
2022-04-03 17:57:05,290: ============================================================
2022-04-03 17:57:05,291: Epoch 9/26 Batch 7400/7662 eta: 16:42:59.947815	Training Loss 5.3496 (5.3285)	Training Prec@1 95.898 (95.989)	Training Prec@5 98.438 (98.147)	
2022-04-03 17:57:05,291: ============================================================
2022-04-03 17:57:51,286: time cost, forward:0.010932549808419281, backward:0.05829501053479087, data cost:0.38637367301439346 
2022-04-03 17:57:51,286: ============================================================
2022-04-03 17:57:51,286: Epoch 9/26 Batch 7500/7662 eta: 16:39:46.269439	Training Loss 5.5360 (5.3288)	Training Prec@1 95.312 (95.988)	Training Prec@5 98.047 (98.146)	
2022-04-03 17:57:51,286: ============================================================
2022-04-03 17:58:36,466: time cost, forward:0.010952822078700316, backward:0.05827683309988531, data cost:0.3863197302940661 
2022-04-03 17:58:36,467: ============================================================
2022-04-03 17:58:36,468: Epoch 9/26 Batch 7600/7662 eta: 16:21:18.903438	Training Loss 5.2795 (5.3294)	Training Prec@1 95.703 (95.988)	Training Prec@5 97.852 (98.146)	
2022-04-03 17:58:36,468: ============================================================
2022-04-03 17:59:05,903: Epoch: 9/26 eta: 16:20:50.439224	Training Loss 5.3925 (5.3292)	Training Prec@1 97.070 (95.988)	Training Prec@5 98.047 (98.145)
2022-04-03 17:59:05,903: ============================================================
2022-04-03 17:59:55,650: time cost, forward:0.010483592447608409, backward:0.059125519762135516, data cost:0.42798891934481537 
2022-04-03 17:59:55,651: ============================================================
2022-04-03 17:59:55,651: Epoch 10/26 Batch 100/7662 eta: 17:57:30.160795	Training Loss 4.1422 (4.4419)	Training Prec@1 97.461 (97.414)	Training Prec@5 99.023 (98.901)	
2022-04-03 17:59:55,651: ============================================================
2022-04-03 18:00:40,630: time cost, forward:0.010624608801836943, backward:0.0587364201569677, data cost:0.4037412027617795 
2022-04-03 18:00:40,630: ============================================================
2022-04-03 18:00:40,631: Epoch 10/26 Batch 200/7662 eta: 16:14:58.371586	Training Loss 3.8024 (4.2881)	Training Prec@1 97.852 (97.668)	Training Prec@5 99.609 (98.994)	
2022-04-03 18:00:40,631: ============================================================
2022-04-03 18:01:26,143: time cost, forward:0.01038371599637545, backward:0.05915553832931263, data cost:0.3973600130814772 
2022-04-03 18:01:26,143: ============================================================
2022-04-03 18:01:26,144: Epoch 10/26 Batch 300/7662 eta: 16:25:46.265796	Training Loss 3.4838 (4.1902)	Training Prec@1 98.242 (97.788)	Training Prec@5 99.219 (99.074)	
2022-04-03 18:01:26,144: ============================================================
2022-04-03 18:02:11,866: time cost, forward:0.010293108478823402, backward:0.05923765882812347, data cost:0.39492142768133254 
2022-04-03 18:02:11,867: ============================================================
2022-04-03 18:02:11,867: Epoch 10/26 Batch 400/7662 eta: 16:29:34.033604	Training Loss 4.1549 (4.1182)	Training Prec@1 97.852 (97.867)	Training Prec@5 98.633 (99.110)	
2022-04-03 18:02:11,867: ============================================================
2022-04-03 18:02:57,778: time cost, forward:0.010224855017805385, backward:0.05928018862355448, data cost:0.3937001108884334 
2022-04-03 18:02:57,779: ============================================================
2022-04-03 18:02:57,779: Epoch 10/26 Batch 500/7662 eta: 16:32:53.054270	Training Loss 3.8654 (4.0528)	Training Prec@1 98.242 (97.958)	Training Prec@5 99.023 (99.152)	
2022-04-03 18:02:57,779: ============================================================
2022-04-03 18:03:43,120: time cost, forward:0.010161085001415323, backward:0.059401505777553244, data cost:0.39186237053401485 
2022-04-03 18:03:43,120: ============================================================
2022-04-03 18:03:43,120: Epoch 10/26 Batch 600/7662 eta: 16:19:47.252019	Training Loss 3.6823 (3.9991)	Training Prec@1 98.633 (98.015)	Training Prec@5 99.414 (99.183)	
2022-04-03 18:03:43,120: ============================================================
2022-04-03 18:04:28,760: time cost, forward:0.010160825453773248, backward:0.059454570000775385, data cost:0.391094591484561 
2022-04-03 18:04:28,761: ============================================================
2022-04-03 18:04:28,761: Epoch 10/26 Batch 700/7662 eta: 16:25:29.762067	Training Loss 3.8026 (3.9511)	Training Prec@1 98.047 (98.063)	Training Prec@5 99.219 (99.212)	
2022-04-03 18:04:28,761: ============================================================
2022-04-03 18:05:14,826: time cost, forward:0.010155076527028567, backward:0.05951662176989196, data cost:0.39089884059748453 
2022-04-03 18:05:14,827: ============================================================
2022-04-03 18:05:14,827: Epoch 10/26 Batch 800/7662 eta: 16:33:55.049851	Training Loss 3.5732 (3.9083)	Training Prec@1 97.266 (98.101)	Training Prec@5 99.023 (99.230)	
2022-04-03 18:05:14,827: ============================================================
2022-04-03 18:05:59,320: time cost, forward:0.010174544422459417, backward:0.0595192861503966, data cost:0.38910766836003013 
2022-04-03 18:05:59,321: ============================================================
2022-04-03 18:05:59,321: Epoch 10/26 Batch 900/7662 eta: 15:59:15.316037	Training Loss 3.2881 (3.8671)	Training Prec@1 99.609 (98.141)	Training Prec@5 99.805 (99.250)	
2022-04-03 18:05:59,321: ============================================================
2022-04-03 18:06:44,582: time cost, forward:0.010184062971128477, backward:0.05952462276538929, data cost:0.38845098102176273 
2022-04-03 18:06:44,583: ============================================================
2022-04-03 18:06:44,583: Epoch 10/26 Batch 1000/7662 eta: 16:15:03.314079	Training Loss 3.5225 (3.8298)	Training Prec@1 98.242 (98.184)	Training Prec@5 99.805 (99.268)	
2022-04-03 18:06:44,583: ============================================================
2022-04-03 18:07:29,659: time cost, forward:0.010198239525195357, backward:0.059535648521235905, data cost:0.3877048290676155 
2022-04-03 18:07:29,659: ============================================================
2022-04-03 18:07:29,660: Epoch 10/26 Batch 1100/7662 eta: 16:10:18.927631	Training Loss 3.3859 (3.7943)	Training Prec@1 98.828 (98.226)	Training Prec@5 99.609 (99.288)	
2022-04-03 18:07:29,660: ============================================================
2022-04-03 18:08:15,965: time cost, forward:0.010231483370388816, backward:0.05951127238428722, data cost:0.38811773573785546 
2022-04-03 18:08:15,965: ============================================================
2022-04-03 18:08:15,965: Epoch 10/26 Batch 1200/7662 eta: 16:35:59.365834	Training Loss 3.3601 (3.7596)	Training Prec@1 99.414 (98.268)	Training Prec@5 99.805 (99.305)	
2022-04-03 18:08:15,965: ============================================================
2022-04-03 18:09:02,368: time cost, forward:0.010270261507570239, backward:0.0594913955832372, data cost:0.38848946533173756 
2022-04-03 18:09:02,369: ============================================================
2022-04-03 18:09:02,369: Epoch 10/26 Batch 1300/7662 eta: 16:37:19.857354	Training Loss 3.5243 (3.7276)	Training Prec@1 98.438 (98.309)	Training Prec@5 99.609 (99.321)	
2022-04-03 18:09:02,369: ============================================================
2022-04-03 18:09:48,292: time cost, forward:0.010269927330916912, backward:0.059472518788651965, data cost:0.38860685165819736 
2022-04-03 18:09:48,293: ============================================================
2022-04-03 18:09:48,293: Epoch 10/26 Batch 1400/7662 eta: 16:26:15.685741	Training Loss 3.1510 (3.6970)	Training Prec@1 98.242 (98.337)	Training Prec@5 99.219 (99.332)	
2022-04-03 18:09:48,293: ============================================================
2022-04-03 18:10:34,163: time cost, forward:0.010278735819301898, backward:0.05946435858361955, data cost:0.3885788578761268 
2022-04-03 18:10:34,163: ============================================================
2022-04-03 18:10:34,163: Epoch 10/26 Batch 1500/7662 eta: 16:24:20.290407	Training Loss 3.3622 (3.6661)	Training Prec@1 99.219 (98.366)	Training Prec@5 99.609 (99.344)	
2022-04-03 18:10:34,164: ============================================================
2022-04-03 18:11:19,366: time cost, forward:0.010448217093758169, backward:0.0592985266517892, data cost:0.3881476231110402 
2022-04-03 18:11:19,366: ============================================================
2022-04-03 18:11:19,367: Epoch 10/26 Batch 1600/7662 eta: 16:09:16.128013	Training Loss 3.0770 (3.6360)	Training Prec@1 98.828 (98.397)	Training Prec@5 99.609 (99.359)	
2022-04-03 18:11:19,367: ============================================================
2022-04-03 18:12:04,482: time cost, forward:0.01046419115611004, backward:0.059266240264192055, data cost:0.387733965778856 
2022-04-03 18:12:04,482: ============================================================
2022-04-03 18:12:04,482: Epoch 10/26 Batch 1700/7662 eta: 16:06:38.634650	Training Loss 3.1480 (3.6073)	Training Prec@1 98.828 (98.427)	Training Prec@5 99.609 (99.373)	
2022-04-03 18:12:04,483: ============================================================
2022-04-03 18:12:49,155: time cost, forward:0.010478429094561608, backward:0.0592247339803156, data cost:0.38712907447093986 
2022-04-03 18:12:49,155: ============================================================
2022-04-03 18:12:49,155: Epoch 10/26 Batch 1800/7662 eta: 15:56:24.410409	Training Loss 2.9487 (3.5794)	Training Prec@1 99.023 (98.457)	Training Prec@5 100.000 (99.387)	
2022-04-03 18:12:49,155: ============================================================
2022-04-03 18:13:33,840: time cost, forward:0.010489908628177492, backward:0.059230737651003354, data cost:0.386567906243604 
2022-04-03 18:13:33,840: ============================================================
2022-04-03 18:13:33,841: Epoch 10/26 Batch 1900/7662 eta: 15:55:55.862862	Training Loss 3.2050 (3.5538)	Training Prec@1 99.023 (98.483)	Training Prec@5 99.805 (99.400)	
2022-04-03 18:13:33,841: ============================================================
2022-04-03 18:14:18,852: time cost, forward:0.010480614051990595, backward:0.05922532701802409, data cost:0.3862706413860617 
2022-04-03 18:14:18,852: ============================================================
2022-04-03 18:14:18,852: Epoch 10/26 Batch 2000/7662 eta: 16:02:09.879263	Training Loss 3.2436 (3.5292)	Training Prec@1 98.047 (98.511)	Training Prec@5 99.219 (99.412)	
2022-04-03 18:14:18,852: ============================================================
2022-04-03 18:15:03,438: time cost, forward:0.010467204665955956, backward:0.059246337657999346, data cost:0.3857514349377229 
2022-04-03 18:15:03,439: ============================================================
2022-04-03 18:15:03,439: Epoch 10/26 Batch 2100/7662 eta: 15:52:20.482546	Training Loss 2.9115 (3.5053)	Training Prec@1 99.805 (98.534)	Training Prec@5 100.000 (99.422)	
2022-04-03 18:15:03,440: ============================================================
2022-04-03 18:15:47,610: time cost, forward:0.010468291932748307, backward:0.05924481378462489, data cost:0.3850707294399926 
2022-04-03 18:15:47,611: ============================================================
2022-04-03 18:15:47,612: Epoch 10/26 Batch 2200/7662 eta: 15:42:44.840420	Training Loss 2.9539 (3.4823)	Training Prec@1 99.023 (98.561)	Training Prec@5 99.609 (99.433)	
2022-04-03 18:15:47,612: ============================================================
2022-04-03 18:16:31,737: time cost, forward:0.010494089479185073, backward:0.05922278677603119, data cost:0.3844767411204202 
2022-04-03 18:16:31,738: ============================================================
2022-04-03 18:16:31,738: Epoch 10/26 Batch 2300/7662 eta: 15:41:01.738343	Training Loss 2.8744 (3.4599)	Training Prec@1 99.219 (98.584)	Training Prec@5 99.805 (99.443)	
2022-04-03 18:16:31,738: ============================================================
2022-04-03 18:17:16,442: time cost, forward:0.010499450056291512, backward:0.05921978709994877, data cost:0.3841475286599048 
2022-04-03 18:17:16,443: ============================================================
2022-04-03 18:17:16,443: Epoch 10/26 Batch 2400/7662 eta: 15:52:37.466999	Training Loss 3.2419 (3.4383)	Training Prec@1 99.219 (98.605)	Training Prec@5 99.609 (99.451)	
2022-04-03 18:17:16,443: ============================================================
2022-04-03 18:18:00,791: time cost, forward:0.010536776203401283, backward:0.05917167987953238, data cost:0.38374439951609307 
2022-04-03 18:18:00,791: ============================================================
2022-04-03 18:18:00,791: Epoch 10/26 Batch 2500/7662 eta: 15:44:17.391164	Training Loss 2.9243 (3.4183)	Training Prec@1 98.633 (98.628)	Training Prec@5 99.609 (99.461)	
2022-04-03 18:18:00,792: ============================================================
2022-04-03 18:18:46,013: time cost, forward:0.010537852870358463, backward:0.05916347894452085, data cost:0.38364634700993844 
2022-04-03 18:18:46,013: ============================================================
2022-04-03 18:18:46,014: Epoch 10/26 Batch 2600/7662 eta: 16:02:08.682048	Training Loss 2.8177 (3.3983)	Training Prec@1 99.219 (98.646)	Training Prec@5 99.805 (99.469)	
2022-04-03 18:18:46,014: ============================================================
2022-04-03 18:19:30,932: time cost, forward:0.010522961307340482, backward:0.0591758730324077, data cost:0.3834899582214469 
2022-04-03 18:19:30,933: ============================================================
2022-04-03 18:19:30,933: Epoch 10/26 Batch 2700/7662 eta: 15:54:56.809263	Training Loss 2.6826 (3.3791)	Training Prec@1 99.805 (98.666)	Training Prec@5 100.000 (99.479)	
2022-04-03 18:19:30,933: ============================================================
2022-04-03 18:20:15,770: time cost, forward:0.01052688904939783, backward:0.059168675917734115, data cost:0.38330844974211176 
2022-04-03 18:20:15,771: ============================================================
2022-04-03 18:20:15,771: Epoch 10/26 Batch 2800/7662 eta: 15:52:27.955728	Training Loss 2.7467 (3.3608)	Training Prec@1 99.219 (98.684)	Training Prec@5 99.609 (99.487)	
2022-04-03 18:20:15,771: ============================================================
2022-04-03 18:21:00,611: time cost, forward:0.010576558795703942, backward:0.05910688813450666, data cost:0.3831546738378835 
2022-04-03 18:21:00,612: ============================================================
2022-04-03 18:21:00,612: Epoch 10/26 Batch 2900/7662 eta: 15:51:47.364962	Training Loss 2.6333 (3.3428)	Training Prec@1 99.414 (98.702)	Training Prec@5 99.805 (99.494)	
2022-04-03 18:21:00,612: ============================================================
2022-04-03 18:21:44,765: time cost, forward:0.010612826698738243, backward:0.05905214879225794, data cost:0.38277183027416917 
2022-04-03 18:21:44,765: ============================================================
2022-04-03 18:21:44,765: Epoch 10/26 Batch 3000/7662 eta: 15:36:27.273176	Training Loss 2.8018 (3.3250)	Training Prec@1 99.609 (98.716)	Training Prec@5 100.000 (99.501)	
2022-04-03 18:21:44,765: ============================================================
2022-04-03 18:22:27,428: time cost, forward:0.010623997278696647, backward:0.05903142350225458, data cost:0.38190919793625344 
2022-04-03 18:22:27,428: ============================================================
2022-04-03 18:22:27,429: Epoch 10/26 Batch 3100/7662 eta: 15:04:08.663770	Training Loss 2.9006 (3.3077)	Training Prec@1 98.633 (98.731)	Training Prec@5 99.805 (99.509)	
2022-04-03 18:22:27,429: ============================================================
2022-04-03 18:23:11,605: time cost, forward:0.01060612986482058, backward:0.05904444406538615, data cost:0.3816107876340312 
2022-04-03 18:23:11,605: ============================================================
2022-04-03 18:23:11,606: Epoch 10/26 Batch 3200/7662 eta: 15:35:29.170106	Training Loss 2.9354 (3.2916)	Training Prec@1 98.828 (98.745)	Training Prec@5 99.609 (99.515)	
2022-04-03 18:23:11,606: ============================================================
2022-04-03 18:23:56,333: time cost, forward:0.01059779639531714, backward:0.05904451743441302, data cost:0.3814760064601754 
2022-04-03 18:23:56,334: ============================================================
2022-04-03 18:23:56,334: Epoch 10/26 Batch 3300/7662 eta: 15:46:24.910244	Training Loss 2.6612 (3.2757)	Training Prec@1 99.414 (98.762)	Training Prec@5 99.609 (99.523)	
2022-04-03 18:23:56,334: ============================================================
2022-04-03 18:24:41,308: time cost, forward:0.0106096981763489, backward:0.05903498724510684, data cost:0.3814127088890738 
2022-04-03 18:24:41,309: ============================================================
2022-04-03 18:24:41,309: Epoch 10/26 Batch 3400/7662 eta: 15:50:53.162249	Training Loss 2.8668 (3.2599)	Training Prec@1 99.219 (98.778)	Training Prec@5 99.609 (99.530)	
2022-04-03 18:24:41,309: ============================================================
2022-04-03 18:25:25,866: time cost, forward:0.010611182657368833, backward:0.05903096129533801, data cost:0.381248828580496 
2022-04-03 18:25:25,867: ============================================================
2022-04-03 18:25:25,867: Epoch 10/26 Batch 3500/7662 eta: 15:41:19.306247	Training Loss 2.8481 (3.2447)	Training Prec@1 98.438 (98.792)	Training Prec@5 99.609 (99.536)	
2022-04-03 18:25:25,867: ============================================================
2022-04-03 18:26:10,259: time cost, forward:0.01060728107302942, backward:0.0590352129028651, data cost:0.3810506564572507 
2022-04-03 18:26:10,260: ============================================================
2022-04-03 18:26:10,260: Epoch 10/26 Batch 3600/7662 eta: 15:37:06.157837	Training Loss 2.5351 (3.2304)	Training Prec@1 99.609 (98.806)	Training Prec@5 99.805 (99.542)	
2022-04-03 18:26:10,260: ============================================================
2022-04-03 18:26:54,147: time cost, forward:0.010610047402527564, backward:0.059028571990735794, data cost:0.3807112245051788 
2022-04-03 18:26:54,148: ============================================================
2022-04-03 18:26:54,148: Epoch 10/26 Batch 3700/7662 eta: 15:25:42.155477	Training Loss 2.7186 (3.2159)	Training Prec@1 99.219 (98.819)	Training Prec@5 99.805 (99.547)	
2022-04-03 18:26:54,148: ============================================================
2022-04-03 18:27:38,893: time cost, forward:0.010613712018086554, backward:0.05902636851345624, data cost:0.38060951590632164 
2022-04-03 18:27:38,894: ============================================================
2022-04-03 18:27:38,894: Epoch 10/26 Batch 3800/7662 eta: 15:43:03.564314	Training Loss 2.7837 (3.2023)	Training Prec@1 99.023 (98.833)	Training Prec@5 99.609 (99.553)	
2022-04-03 18:27:38,894: ============================================================
2022-04-03 18:28:24,000: time cost, forward:0.010662209409785656, backward:0.05897886320761333, data cost:0.38061550966621394 
2022-04-03 18:28:24,000: ============================================================
2022-04-03 18:28:24,000: Epoch 10/26 Batch 3900/7662 eta: 15:49:54.362246	Training Loss 2.8382 (3.1890)	Training Prec@1 99.219 (98.843)	Training Prec@5 99.609 (99.559)	
2022-04-03 18:28:24,001: ============================================================
2022-04-03 18:29:09,145: time cost, forward:0.010663611616424156, backward:0.05898136614441544, data cost:0.38062988987383944 
2022-04-03 18:29:09,145: ============================================================
2022-04-03 18:29:09,146: Epoch 10/26 Batch 4000/7662 eta: 15:49:58.212852	Training Loss 2.6522 (3.1757)	Training Prec@1 100.000 (98.857)	Training Prec@5 100.000 (99.564)	
2022-04-03 18:29:09,146: ============================================================
2022-04-03 18:29:54,061: time cost, forward:0.010651243811963564, backward:0.05899375012572959, data cost:0.38057003308575627 
2022-04-03 18:29:54,061: ============================================================
2022-04-03 18:29:54,062: Epoch 10/26 Batch 4100/7662 eta: 15:44:23.528211	Training Loss 2.6650 (3.1629)	Training Prec@1 98.633 (98.868)	Training Prec@5 99.609 (99.570)	
2022-04-03 18:29:54,062: ============================================================
2022-04-03 18:30:38,772: time cost, forward:0.010636877576406014, backward:0.05900619756213027, data cost:0.3805052941684128 
2022-04-03 18:30:38,772: ============================================================
2022-04-03 18:30:38,772: Epoch 10/26 Batch 4200/7662 eta: 15:39:20.316967	Training Loss 2.7793 (3.1511)	Training Prec@1 99.805 (98.877)	Training Prec@5 100.000 (99.574)	
2022-04-03 18:30:38,773: ============================================================
2022-04-03 18:31:23,859: time cost, forward:0.010634929808274789, backward:0.05901653574189077, data cost:0.38050438925731345 
2022-04-03 18:31:23,860: ============================================================
2022-04-03 18:31:23,860: Epoch 10/26 Batch 4300/7662 eta: 15:46:29.754139	Training Loss 2.6053 (3.1390)	Training Prec@1 99.609 (98.889)	Training Prec@5 100.000 (99.579)	
2022-04-03 18:31:23,860: ============================================================
2022-04-03 18:32:08,634: time cost, forward:0.010635743007846355, backward:0.059018257179702514, data cost:0.38043052550201173 
2022-04-03 18:32:08,635: ============================================================
2022-04-03 18:32:08,635: Epoch 10/26 Batch 4400/7662 eta: 15:39:11.883933	Training Loss 2.5913 (3.1277)	Training Prec@1 99.219 (98.900)	Training Prec@5 99.414 (99.584)	
2022-04-03 18:32:08,635: ============================================================
2022-04-03 18:32:52,647: time cost, forward:0.010630272631911231, backward:0.05902575079296186, data cost:0.3802048696308937 
2022-04-03 18:32:52,647: ============================================================
2022-04-03 18:32:52,647: Epoch 10/26 Batch 4500/7662 eta: 15:22:27.589629	Training Loss 2.5464 (3.1161)	Training Prec@1 99.414 (98.911)	Training Prec@5 100.000 (99.589)	
2022-04-03 18:32:52,648: ============================================================
2022-04-03 18:33:35,782: time cost, forward:0.010627274306915874, backward:0.059032384818936204, data cost:0.37979613088685343 
2022-04-03 18:33:35,783: ============================================================
2022-04-03 18:33:35,783: Epoch 10/26 Batch 4600/7662 eta: 15:03:22.105999	Training Loss 2.5082 (3.1051)	Training Prec@1 99.609 (98.920)	Training Prec@5 99.805 (99.593)	
2022-04-03 18:33:35,783: ============================================================
2022-04-03 18:34:18,919: time cost, forward:0.010637821859947086, backward:0.059027436439674896, data cost:0.37935427412831496 
2022-04-03 18:34:18,919: ============================================================
2022-04-03 18:34:18,920: Epoch 10/26 Batch 4700/7662 eta: 15:02:40.232689	Training Loss 2.7151 (3.0942)	Training Prec@1 99.219 (98.930)	Training Prec@5 100.000 (99.597)	
2022-04-03 18:34:18,920: ============================================================
2022-04-03 18:35:03,840: time cost, forward:0.01064067508906567, backward:0.05902116858579139, data cost:0.3793735001876618 
2022-04-03 18:35:03,841: ============================================================
2022-04-03 18:35:03,841: Epoch 10/26 Batch 4800/7662 eta: 15:39:16.192409	Training Loss 2.6096 (3.0832)	Training Prec@1 99.414 (98.940)	Training Prec@5 99.609 (99.601)	
2022-04-03 18:35:03,841: ============================================================
2022-04-03 18:35:47,519: time cost, forward:0.010652238238853055, backward:0.05900634598016593, data cost:0.3791223656622627 
2022-04-03 18:35:47,520: ============================================================
2022-04-03 18:35:47,520: Epoch 10/26 Batch 4900/7662 eta: 15:12:33.431658	Training Loss 2.4293 (3.0730)	Training Prec@1 99.609 (98.949)	Training Prec@5 99.805 (99.605)	
2022-04-03 18:35:47,520: ============================================================
2022-04-03 18:36:31,604: time cost, forward:0.010673065475521862, backward:0.05898866669658089, data cost:0.37895514397984575 
2022-04-03 18:36:31,604: ============================================================
2022-04-03 18:36:31,604: Epoch 10/26 Batch 5000/7662 eta: 15:20:18.169875	Training Loss 2.6033 (3.0628)	Training Prec@1 99.805 (98.959)	Training Prec@5 100.000 (99.609)	
2022-04-03 18:36:31,605: ============================================================
2022-04-03 18:37:15,584: time cost, forward:0.01066725051597091, backward:0.058999096746420385, data cost:0.3787626260213932 
2022-04-03 18:37:15,585: ============================================================
2022-04-03 18:37:15,586: Epoch 10/26 Batch 5100/7662 eta: 15:17:24.799144	Training Loss 2.6072 (3.0527)	Training Prec@1 99.023 (98.967)	Training Prec@5 99.609 (99.613)	
2022-04-03 18:37:15,586: ============================================================
2022-04-03 18:38:00,842: time cost, forward:0.010665039622707994, backward:0.05900146672761906, data cost:0.37883006074974734 
2022-04-03 18:38:00,843: ============================================================
2022-04-03 18:38:00,843: Epoch 10/26 Batch 5200/7662 eta: 15:43:16.761771	Training Loss 2.6917 (3.0433)	Training Prec@1 99.609 (98.976)	Training Prec@5 99.805 (99.616)	
2022-04-03 18:38:00,843: ============================================================
2022-04-03 18:38:45,204: time cost, forward:0.01065783434081559, backward:0.05900516026783583, data cost:0.37872657215264544 
2022-04-03 18:38:45,205: ============================================================
2022-04-03 18:38:45,205: Epoch 10/26 Batch 5300/7662 eta: 15:23:52.295774	Training Loss 2.5760 (3.0341)	Training Prec@1 99.414 (98.984)	Training Prec@5 100.000 (99.620)	
2022-04-03 18:38:45,205: ============================================================
2022-04-03 18:39:30,054: time cost, forward:0.010650708159156851, backward:0.0590191425758725, data cost:0.37871660336584356 
2022-04-03 18:39:30,054: ============================================================
2022-04-03 18:39:30,054: Epoch 10/26 Batch 5400/7662 eta: 15:33:16.367165	Training Loss 2.3930 (3.0246)	Training Prec@1 99.219 (98.993)	Training Prec@5 99.219 (99.623)	
2022-04-03 18:39:30,054: ============================================================
2022-04-03 18:40:13,064: time cost, forward:0.010645991651594347, backward:0.05903355501677518, data cost:0.3783576246997967 
2022-04-03 18:40:13,064: ============================================================
2022-04-03 18:40:13,064: Epoch 10/26 Batch 5500/7662 eta: 14:54:17.389911	Training Loss 2.2754 (3.0156)	Training Prec@1 100.000 (99.001)	Training Prec@5 100.000 (99.627)	
2022-04-03 18:40:13,065: ============================================================
2022-04-03 18:40:57,222: time cost, forward:0.010642394825355733, backward:0.059035584679201766, data cost:0.37824182196118233 
2022-04-03 18:40:57,222: ============================================================
2022-04-03 18:40:57,222: Epoch 10/26 Batch 5600/7662 eta: 15:17:24.904945	Training Loss 2.6131 (3.0067)	Training Prec@1 100.000 (99.010)	Training Prec@5 100.000 (99.630)	
2022-04-03 18:40:57,222: ============================================================
2022-04-03 18:41:41,962: time cost, forward:0.010638488219649902, backward:0.0590391981118519, data cost:0.3782234848288198 
2022-04-03 18:41:41,963: ============================================================
2022-04-03 18:41:41,963: Epoch 10/26 Batch 5700/7662 eta: 15:28:47.216912	Training Loss 2.6502 (2.9987)	Training Prec@1 99.023 (99.017)	Training Prec@5 99.609 (99.634)	
2022-04-03 18:41:41,963: ============================================================
2022-04-03 18:42:26,856: time cost, forward:0.01062819451623013, backward:0.05905137047271807, data cost:0.37820577103426833 
2022-04-03 18:42:26,856: ============================================================
2022-04-03 18:42:26,856: Epoch 10/26 Batch 5800/7662 eta: 15:31:11.592802	Training Loss 2.3707 (2.9903)	Training Prec@1 99.609 (99.025)	Training Prec@5 100.000 (99.637)	
2022-04-03 18:42:26,856: ============================================================
2022-04-03 18:43:10,875: time cost, forward:0.010618075614744251, backward:0.05905841912106147, data cost:0.37810054579555513 
2022-04-03 18:43:10,875: ============================================================
2022-04-03 18:43:10,875: Epoch 10/26 Batch 5900/7662 eta: 15:12:19.826330	Training Loss 2.6126 (2.9821)	Training Prec@1 99.609 (99.033)	Training Prec@5 99.609 (99.640)	
2022-04-03 18:43:10,875: ============================================================
2022-04-03 18:43:52,518: time cost, forward:0.010607839485151925, backward:0.05906968447422461, data cost:0.3775632139404012 
2022-04-03 18:43:52,518: ============================================================
2022-04-03 18:43:52,519: Epoch 10/26 Batch 6000/7662 eta: 14:22:24.074453	Training Loss 2.4437 (2.9739)	Training Prec@1 99.219 (99.041)	Training Prec@5 99.414 (99.643)	
2022-04-03 18:43:52,519: ============================================================
2022-04-03 18:44:35,092: time cost, forward:0.010596253164753912, backward:0.05908128034288638, data cost:0.37720228992811794 
2022-04-03 18:44:35,092: ============================================================
2022-04-03 18:44:35,092: Epoch 10/26 Batch 6100/7662 eta: 14:40:57.541163	Training Loss 2.5692 (2.9662)	Training Prec@1 100.000 (99.048)	Training Prec@5 100.000 (99.646)	
2022-04-03 18:44:35,093: ============================================================
2022-04-03 18:45:19,515: time cost, forward:0.010585638491794705, backward:0.05908561945153852, data cost:0.3771584955487141 
2022-04-03 18:45:19,516: ============================================================
2022-04-03 18:45:19,516: Epoch 10/26 Batch 6200/7662 eta: 15:18:29.264217	Training Loss 2.4906 (2.9592)	Training Prec@1 99.219 (99.055)	Training Prec@5 99.414 (99.649)	
2022-04-03 18:45:19,516: ============================================================
2022-04-03 18:46:04,078: time cost, forward:0.010580415781726344, backward:0.059086104767117016, data cost:0.37714151659358547 
2022-04-03 18:46:04,079: ============================================================
2022-04-03 18:46:04,079: Epoch 10/26 Batch 6300/7662 eta: 15:20:38.404989	Training Loss 2.4485 (2.9521)	Training Prec@1 99.219 (99.061)	Training Prec@5 99.609 (99.652)	
2022-04-03 18:46:04,079: ============================================================
2022-04-03 18:46:48,924: time cost, forward:0.01057795625791864, backward:0.059081971636040544, data cost:0.3771672853549433 
2022-04-03 18:46:48,925: ============================================================
2022-04-03 18:46:48,925: Epoch 10/26 Batch 6400/7662 eta: 15:25:43.955368	Training Loss 2.6073 (2.9447)	Training Prec@1 99.805 (99.067)	Training Prec@5 100.000 (99.655)	
2022-04-03 18:46:48,925: ============================================================
2022-04-03 18:47:33,709: time cost, forward:0.010570919427491643, backward:0.059084134902343655, data cost:0.3771696561372249 
2022-04-03 18:47:33,709: ============================================================
2022-04-03 18:47:33,710: Epoch 10/26 Batch 6500/7662 eta: 15:23:43.290039	Training Loss 2.4363 (2.9373)	Training Prec@1 99.609 (99.074)	Training Prec@5 99.805 (99.658)	
2022-04-03 18:47:33,710: ============================================================
2022-04-03 18:48:18,762: time cost, forward:0.010562147294270087, backward:0.05908817669752421, data cost:0.37722142213473703 
2022-04-03 18:48:18,763: ============================================================
2022-04-03 18:48:18,763: Epoch 10/26 Batch 6600/7662 eta: 15:28:31.093735	Training Loss 2.5947 (2.9304)	Training Prec@1 99.414 (99.080)	Training Prec@5 99.609 (99.661)	
2022-04-03 18:48:18,764: ============================================================
2022-04-03 18:49:02,995: time cost, forward:0.010555504506907369, backward:0.05909468334350039, data cost:0.3771507316853577 
2022-04-03 18:49:02,996: ============================================================
2022-04-03 18:49:02,996: Epoch 10/26 Batch 6700/7662 eta: 15:10:51.793924	Training Loss 2.5240 (2.9238)	Training Prec@1 99.609 (99.085)	Training Prec@5 100.000 (99.663)	
2022-04-03 18:49:02,996: ============================================================
2022-04-03 18:49:45,718: time cost, forward:0.010558044933224271, backward:0.05909051199418023, data cost:0.37685280467573556 
2022-04-03 18:49:45,719: ============================================================
2022-04-03 18:49:45,719: Epoch 10/26 Batch 6800/7662 eta: 14:39:03.236141	Training Loss 2.4015 (2.9174)	Training Prec@1 99.414 (99.090)	Training Prec@5 99.609 (99.666)	
2022-04-03 18:49:45,719: ============================================================
2022-04-03 18:50:30,445: time cost, forward:0.01055008280983972, backward:0.05910008754362523, data cost:0.3768530329477443 
2022-04-03 18:50:30,446: ============================================================
2022-04-03 18:50:30,446: Epoch 10/26 Batch 6900/7662 eta: 15:19:33.123781	Training Loss 2.4477 (2.9109)	Training Prec@1 99.609 (99.096)	Training Prec@5 99.609 (99.668)	
2022-04-03 18:50:30,446: ============================================================
2022-04-03 18:51:14,405: time cost, forward:0.010557577326938516, backward:0.05909333540415965, data cost:0.3767392173428623 
2022-04-03 18:51:14,405: ============================================================
2022-04-03 18:51:14,405: Epoch 10/26 Batch 7000/7662 eta: 15:03:02.260071	Training Loss 2.5047 (2.9047)	Training Prec@1 99.805 (99.102)	Training Prec@5 100.000 (99.671)	
2022-04-03 18:51:14,405: ============================================================
2022-04-03 18:51:59,092: time cost, forward:0.010603171534094277, backward:0.05904426845400614, data cost:0.3767493008593301 
2022-04-03 18:51:59,093: ============================================================
2022-04-03 18:51:59,093: Epoch 10/26 Batch 7100/7662 eta: 15:17:14.752328	Training Loss 2.4782 (2.8985)	Training Prec@1 99.609 (99.108)	Training Prec@5 100.000 (99.673)	
2022-04-03 18:51:59,093: ============================================================
2022-04-03 18:52:43,283: time cost, forward:0.010599616567762978, backward:0.05904547263059472, data cost:0.37667924809048514 
2022-04-03 18:52:43,284: ============================================================
2022-04-03 18:52:43,284: Epoch 10/26 Batch 7200/7662 eta: 15:06:19.333022	Training Loss 2.5105 (2.8926)	Training Prec@1 99.414 (99.113)	Training Prec@5 100.000 (99.676)	
2022-04-03 18:52:43,284: ============================================================
2022-04-03 18:53:26,592: time cost, forward:0.010616306181328968, backward:0.05902686000180614, data cost:0.376496801181662 
2022-04-03 18:53:26,592: ============================================================
2022-04-03 18:53:26,592: Epoch 10/26 Batch 7300/7662 eta: 14:47:29.964773	Training Loss 2.5293 (2.8867)	Training Prec@1 99.219 (99.119)	Training Prec@5 99.805 (99.678)	
2022-04-03 18:53:26,593: ============================================================
2022-04-03 18:54:09,348: time cost, forward:0.010611778917401558, backward:0.059029905550188916, data cost:0.37623284781103217 
2022-04-03 18:54:09,349: ============================================================
2022-04-03 18:54:09,349: Epoch 10/26 Batch 7400/7662 eta: 14:35:28.850745	Training Loss 2.2874 (2.8811)	Training Prec@1 100.000 (99.124)	Training Prec@5 100.000 (99.680)	
2022-04-03 18:54:09,349: ============================================================
2022-04-03 18:54:53,461: time cost, forward:0.010610106818309418, backward:0.05902668294437346, data cost:0.37617191039239395 
2022-04-03 18:54:53,462: ============================================================
2022-04-03 18:54:53,462: Epoch 10/26 Batch 7500/7662 eta: 15:02:30.735689	Training Loss 2.4663 (2.8757)	Training Prec@1 98.828 (99.129)	Training Prec@5 99.609 (99.683)	
2022-04-03 18:54:53,463: ============================================================
2022-04-03 18:55:37,808: time cost, forward:0.010612878537143527, backward:0.05902205829417052, data cost:0.3761339219310814 
2022-04-03 18:55:37,809: ============================================================
2022-04-03 18:55:37,809: Epoch 10/26 Batch 7600/7662 eta: 15:06:34.004835	Training Loss 2.3494 (2.8701)	Training Prec@1 99.414 (99.134)	Training Prec@5 99.805 (99.685)	
2022-04-03 18:55:37,809: ============================================================
2022-04-03 18:56:06,510: Epoch: 10/26 eta: 15:06:06.066127	Training Loss 2.4000 (2.8668)	Training Prec@1 99.609 (99.137)	Training Prec@5 100.000 (99.686)
2022-04-03 18:56:06,511: ============================================================
2022-04-03 18:56:06,634: Save Checkpoint...
2022-04-03 18:56:06,642: ============================================================
2022-04-03 18:56:34,205: Save done!
2022-04-03 18:56:34,205: ============================================================
2022-04-03 18:57:11,789: time cost, forward:0.011763240351821438, backward:0.057152280903825854, data cost:0.30720566258285986 
2022-04-03 18:57:11,789: ============================================================
2022-04-03 18:57:11,790: Epoch 11/26 Batch 100/7662 eta: 12:47:17.181951	Training Loss 2.0684 (2.0923)	Training Prec@1 100.000 (99.779)	Training Prec@5 100.000 (99.923)	
2022-04-03 18:57:11,790: ============================================================
2022-04-03 18:57:53,363: time cost, forward:0.011240602138653473, backward:0.05817327187887987, data cost:0.3253879283540812 
2022-04-03 18:57:53,364: ============================================================
2022-04-03 18:57:53,364: Epoch 11/26 Batch 200/7662 eta: 14:08:04.253084	Training Loss 2.1273 (2.0970)	Training Prec@1 99.805 (99.788)	Training Prec@5 100.000 (99.930)	
2022-04-03 18:57:53,364: ============================================================
2022-04-03 18:58:36,186: time cost, forward:0.010845148443777026, backward:0.058778192685998, data cost:0.3365891242904408 
2022-04-03 18:58:36,186: ============================================================
2022-04-03 18:58:36,187: Epoch 11/26 Batch 300/7662 eta: 14:32:49.167456	Training Loss 2.1682 (2.1085)	Training Prec@1 99.609 (99.790)	Training Prec@5 99.805 (99.930)	
2022-04-03 18:58:36,187: ============================================================
2022-04-03 18:59:19,769: time cost, forward:0.010655916424323442, backward:0.059054264149868994, data cost:0.3436502053922878 
2022-04-03 18:59:19,770: ============================================================
2022-04-03 18:59:19,770: Epoch 11/26 Batch 400/7662 eta: 14:47:35.922242	Training Loss 2.0930 (2.1086)	Training Prec@1 100.000 (99.793)	Training Prec@5 100.000 (99.932)	
2022-04-03 18:59:19,770: ============================================================
2022-04-03 19:00:03,732: time cost, forward:0.010587660726421104, backward:0.05909619254913024, data cost:0.3488967877351688 
2022-04-03 19:00:03,732: ============================================================
2022-04-03 19:00:03,732: Epoch 11/26 Batch 500/7662 eta: 14:54:34.582457	Training Loss 2.2019 (2.1133)	Training Prec@1 100.000 (99.785)	Training Prec@5 100.000 (99.931)	
2022-04-03 19:00:03,732: ============================================================
2022-04-03 19:00:47,693: time cost, forward:0.010598869275967147, backward:0.05911260176580617, data cost:0.3522538569614366 
2022-04-03 19:00:47,693: ============================================================
2022-04-03 19:00:47,693: Epoch 11/26 Batch 600/7662 eta: 14:53:49.571008	Training Loss 2.2211 (2.1201)	Training Prec@1 99.805 (99.786)	Training Prec@5 100.000 (99.931)	
2022-04-03 19:00:47,694: ============================================================
2022-04-03 19:01:31,502: time cost, forward:0.010556261256358484, backward:0.05912927394261176, data cost:0.35458145291679066 
2022-04-03 19:01:31,503: ============================================================
2022-04-03 19:01:31,503: Epoch 11/26 Batch 700/7662 eta: 14:50:00.782395	Training Loss 2.2475 (2.1266)	Training Prec@1 99.805 (99.784)	Training Prec@5 100.000 (99.930)	
2022-04-03 19:01:31,503: ============================================================
2022-04-03 19:02:15,395: time cost, forward:0.01071735616022714, backward:0.05897634109955407, data cost:0.35627993325864865 
2022-04-03 19:02:15,396: ============================================================
2022-04-03 19:02:15,396: Epoch 11/26 Batch 800/7662 eta: 14:50:58.918445	Training Loss 2.1125 (2.1312)	Training Prec@1 99.219 (99.781)	Training Prec@5 99.609 (99.928)	
2022-04-03 19:02:15,396: ============================================================
2022-04-03 19:02:58,972: time cost, forward:0.010755139542898957, backward:0.058922485727091654, data cost:0.35733829616041685 
2022-04-03 19:02:58,973: ============================================================
2022-04-03 19:02:58,973: Epoch 11/26 Batch 900/7662 eta: 14:43:49.711968	Training Loss 2.1866 (2.1390)	Training Prec@1 99.609 (99.780)	Training Prec@5 99.805 (99.929)	
2022-04-03 19:02:58,973: ============================================================
2022-04-03 19:03:42,086: time cost, forward:0.010801312921044824, backward:0.05886631016736035, data cost:0.3576819469501545 
2022-04-03 19:03:42,086: ============================================================
2022-04-03 19:03:42,086: Epoch 11/26 Batch 1000/7662 eta: 14:33:43.032697	Training Loss 2.1860 (2.1443)	Training Prec@1 99.805 (99.780)	Training Prec@5 100.000 (99.930)	
2022-04-03 19:03:42,087: ============================================================
2022-04-03 19:04:26,037: time cost, forward:0.010906111662554892, backward:0.05877052164815359, data cost:0.3587188586199468 
2022-04-03 19:04:26,038: ============================================================
2022-04-03 19:04:26,038: Epoch 11/26 Batch 1100/7662 eta: 14:49:58.102127	Training Loss 2.2216 (2.1500)	Training Prec@1 99.805 (99.778)	Training Prec@5 100.000 (99.928)	
2022-04-03 19:04:26,038: ============================================================
2022-04-03 19:05:09,825: time cost, forward:0.010861412498531389, backward:0.058829591709738276, data cost:0.3594594693760558 
2022-04-03 19:05:09,825: ============================================================
2022-04-03 19:05:09,825: Epoch 11/26 Batch 1200/7662 eta: 14:45:54.957733	Training Loss 2.1349 (2.1561)	Training Prec@1 100.000 (99.773)	Training Prec@5 100.000 (99.926)	
2022-04-03 19:05:09,826: ============================================================
2022-04-03 19:05:53,843: time cost, forward:0.011014048185047505, backward:0.0587119211867922, data cost:0.3602147897084554 
2022-04-03 19:05:53,844: ============================================================
2022-04-03 19:05:53,844: Epoch 11/26 Batch 1300/7662 eta: 14:49:51.766197	Training Loss 2.1985 (2.1626)	Training Prec@1 99.805 (99.773)	Training Prec@5 99.805 (99.926)	
2022-04-03 19:05:53,845: ============================================================
2022-04-03 19:06:37,839: time cost, forward:0.01099666925393487, backward:0.058776972888622055, data cost:0.3608529066681606 
2022-04-03 19:06:37,840: ============================================================
2022-04-03 19:06:37,840: Epoch 11/26 Batch 1400/7662 eta: 14:48:39.824715	Training Loss 2.0754 (2.1681)	Training Prec@1 99.805 (99.771)	Training Prec@5 100.000 (99.926)	
2022-04-03 19:06:37,840: ============================================================
2022-04-03 19:07:22,076: time cost, forward:0.011002782506096594, backward:0.05881133979761736, data cost:0.36157517515873416 
2022-04-03 19:07:22,077: ============================================================
2022-04-03 19:07:22,077: Epoch 11/26 Batch 1500/7662 eta: 14:52:47.768640	Training Loss 2.1315 (2.1742)	Training Prec@1 99.609 (99.767)	Training Prec@5 100.000 (99.925)	
2022-04-03 19:07:22,077: ============================================================
2022-04-03 19:08:04,953: time cost, forward:0.010949094419258695, backward:0.058931503540430315, data cost:0.3612546926740559 
2022-04-03 19:08:04,954: ============================================================
2022-04-03 19:08:04,954: Epoch 11/26 Batch 1600/7662 eta: 14:24:38.557869	Training Loss 2.1119 (2.1782)	Training Prec@1 100.000 (99.767)	Training Prec@5 100.000 (99.926)	
2022-04-03 19:08:04,955: ============================================================
2022-04-03 19:08:49,119: time cost, forward:0.010931332017338367, backward:0.05895837830963943, data cost:0.36186697288005754 
2022-04-03 19:08:49,120: ============================================================
2022-04-03 19:08:49,120: Epoch 11/26 Batch 1700/7662 eta: 14:49:53.156064	Training Loss 2.2147 (2.1841)	Training Prec@1 99.414 (99.765)	Training Prec@5 100.000 (99.927)	
2022-04-03 19:08:49,120: ============================================================
2022-04-03 19:09:29,855: time cost, forward:0.011024763479439533, backward:0.058877883453114684, data cost:0.3604716240796465 
2022-04-03 19:09:29,855: ============================================================
2022-04-03 19:09:29,856: Epoch 11/26 Batch 1800/7662 eta: 13:40:05.883474	Training Loss 2.3027 (2.1896)	Training Prec@1 99.414 (99.761)	Training Prec@5 100.000 (99.926)	
2022-04-03 19:09:29,856: ============================================================
2022-04-03 19:10:12,799: time cost, forward:0.011005575497442951, backward:0.058904330061259176, data cost:0.36037096115964035 
2022-04-03 19:10:12,800: ============================================================
2022-04-03 19:10:12,800: Epoch 11/26 Batch 1900/7662 eta: 14:23:50.835285	Training Loss 2.4940 (2.1945)	Training Prec@1 99.805 (99.758)	Training Prec@5 100.000 (99.925)	
2022-04-03 19:10:12,800: ============================================================
2022-04-03 19:10:56,619: time cost, forward:0.010990080444618366, backward:0.05889779046036232, data cost:0.3607686751481591 
2022-04-03 19:10:56,619: ============================================================
2022-04-03 19:10:56,619: Epoch 11/26 Batch 2000/7662 eta: 14:40:43.070188	Training Loss 2.1979 (2.1994)	Training Prec@1 99.609 (99.754)	Training Prec@5 100.000 (99.924)	
2022-04-03 19:10:56,620: ============================================================
2022-04-03 19:11:40,442: time cost, forward:0.011003101138968647, backward:0.05885765562743559, data cost:0.36112726206095686 
2022-04-03 19:11:40,442: ============================================================
2022-04-03 19:11:40,442: Epoch 11/26 Batch 2100/7662 eta: 14:40:03.455146	Training Loss 2.3961 (2.2027)	Training Prec@1 99.805 (99.753)	Training Prec@5 100.000 (99.924)	
2022-04-03 19:11:40,442: ============================================================
2022-04-03 19:12:24,604: time cost, forward:0.010995776504752527, backward:0.05886016969737165, data cost:0.36158349656039557 
2022-04-03 19:12:24,605: ============================================================
2022-04-03 19:12:24,605: Epoch 11/26 Batch 2200/7662 eta: 14:46:08.586353	Training Loss 2.2785 (2.2068)	Training Prec@1 99.414 (99.752)	Training Prec@5 99.609 (99.923)	
2022-04-03 19:12:24,605: ============================================================
2022-04-03 19:13:08,515: time cost, forward:0.010977536297300786, backward:0.058871187713676144, data cost:0.3618965661230166 
2022-04-03 19:13:08,515: ============================================================
2022-04-03 19:13:08,515: Epoch 11/26 Batch 2300/7662 eta: 14:40:21.244919	Training Loss 2.2920 (2.2113)	Training Prec@1 99.609 (99.750)	Training Prec@5 100.000 (99.923)	
2022-04-03 19:13:08,516: ============================================================
2022-04-03 19:13:52,273: time cost, forward:0.010971202011553632, backward:0.0588649062625365, data cost:0.3621394443432457 
2022-04-03 19:13:52,274: ============================================================
2022-04-03 19:13:52,274: Epoch 11/26 Batch 2400/7662 eta: 14:36:34.993887	Training Loss 2.3230 (2.2160)	Training Prec@1 99.805 (99.748)	Training Prec@5 100.000 (99.922)	
2022-04-03 19:13:52,274: ============================================================
2022-04-03 19:14:36,307: time cost, forward:0.010965087596012526, backward:0.058867904652400514, data cost:0.3624511908988754 
2022-04-03 19:14:36,307: ============================================================
2022-04-03 19:14:36,308: Epoch 11/26 Batch 2500/7662 eta: 14:41:21.298273	Training Loss 2.4307 (2.2205)	Training Prec@1 99.805 (99.744)	Training Prec@5 100.000 (99.921)	
2022-04-03 19:14:36,308: ============================================================
2022-04-03 19:15:19,953: time cost, forward:0.010945704406204019, backward:0.05887754901916809, data cost:0.36259504591973757 
2022-04-03 19:15:19,954: ============================================================
2022-04-03 19:15:19,954: Epoch 11/26 Batch 2600/7662 eta: 14:32:52.723993	Training Loss 2.3248 (2.2249)	Training Prec@1 99.609 (99.742)	Training Prec@5 99.805 (99.920)	
2022-04-03 19:15:19,954: ============================================================
2022-04-03 19:16:02,157: time cost, forward:0.010921533834761979, backward:0.05889501426784407, data cost:0.36219842065568764 
2022-04-03 19:16:02,157: ============================================================
2022-04-03 19:16:02,158: Epoch 11/26 Batch 2700/7662 eta: 14:03:18.906516	Training Loss 2.3664 (2.2291)	Training Prec@1 99.414 (99.740)	Training Prec@5 99.805 (99.919)	
2022-04-03 19:16:02,158: ============================================================
2022-04-03 19:16:43,564: time cost, forward:0.010907849655614745, backward:0.05890304610404682, data cost:0.36148171068813684 
2022-04-03 19:16:43,565: ============================================================
2022-04-03 19:16:43,566: Epoch 11/26 Batch 2800/7662 eta: 13:46:44.017668	Training Loss 2.3110 (2.2332)	Training Prec@1 99.805 (99.738)	Training Prec@5 100.000 (99.919)	
2022-04-03 19:16:43,566: ============================================================
2022-04-03 19:17:25,842: time cost, forward:0.010897884865636125, backward:0.0589229299842016, data cost:0.3612225712805462 
2022-04-03 19:17:25,843: ============================================================
2022-04-03 19:17:25,843: Epoch 11/26 Batch 2900/7662 eta: 14:03:23.151469	Training Loss 2.3345 (2.2366)	Training Prec@1 99.805 (99.737)	Training Prec@5 99.805 (99.918)	
2022-04-03 19:17:25,843: ============================================================
2022-04-03 19:18:09,431: time cost, forward:0.010914775839484744, backward:0.058914727630437154, data cost:0.36134348244776765 
2022-04-03 19:18:09,431: ============================================================
2022-04-03 19:18:09,431: Epoch 11/26 Batch 3000/7662 eta: 14:28:48.427582	Training Loss 2.3074 (2.2404)	Training Prec@1 99.219 (99.734)	Training Prec@5 100.000 (99.918)	
2022-04-03 19:18:09,432: ============================================================
2022-04-03 19:18:53,197: time cost, forward:0.010924729273064593, backward:0.05890355651784074, data cost:0.3615411215730158 
2022-04-03 19:18:53,198: ============================================================
2022-04-03 19:18:53,199: Epoch 11/26 Batch 3100/7662 eta: 14:31:38.943702	Training Loss 2.2877 (2.2435)	Training Prec@1 99.414 (99.732)	Training Prec@5 100.000 (99.917)	
2022-04-03 19:18:53,199: ============================================================
2022-04-03 19:19:36,906: time cost, forward:0.010899964926130289, backward:0.05894588328555585, data cost:0.36167594454146135 
2022-04-03 19:19:36,906: ============================================================
2022-04-03 19:19:36,906: Epoch 11/26 Batch 3200/7662 eta: 14:29:43.696876	Training Loss 2.3188 (2.2472)	Training Prec@1 100.000 (99.730)	Training Prec@5 100.000 (99.916)	
2022-04-03 19:19:36,906: ============================================================
2022-04-03 19:20:20,313: time cost, forward:0.010890043876719642, backward:0.058952568516148766, data cost:0.36176093588022795 
2022-04-03 19:20:20,314: ============================================================
2022-04-03 19:20:20,314: Epoch 11/26 Batch 3300/7662 eta: 14:23:02.605885	Training Loss 2.4402 (2.2507)	Training Prec@1 100.000 (99.728)	Training Prec@5 100.000 (99.916)	
2022-04-03 19:20:20,314: ============================================================
2022-04-03 19:21:03,445: time cost, forward:0.010868161031168045, backward:0.058959533481536174, data cost:0.3617426455459303 
2022-04-03 19:21:03,445: ============================================================
2022-04-03 19:21:03,446: Epoch 11/26 Batch 3400/7662 eta: 14:16:49.781375	Training Loss 2.5083 (2.2541)	Training Prec@1 99.219 (99.726)	Training Prec@5 99.805 (99.916)	
2022-04-03 19:21:03,446: ============================================================
2022-04-03 19:21:46,976: time cost, forward:0.010856574724387632, backward:0.058984065675912634, data cost:0.3618147959195399 
2022-04-03 19:21:46,977: ============================================================
2022-04-03 19:21:46,977: Epoch 11/26 Batch 3500/7662 eta: 14:24:02.652255	Training Loss 2.2495 (2.2572)	Training Prec@1 99.805 (99.725)	Training Prec@5 99.805 (99.915)	
2022-04-03 19:21:46,977: ============================================================
2022-04-03 19:22:29,962: time cost, forward:0.010851436537085191, backward:0.059005884569066865, data cost:0.3617372801649004 
2022-04-03 19:22:29,962: ============================================================
2022-04-03 19:22:29,962: Epoch 11/26 Batch 3600/7662 eta: 14:12:29.599954	Training Loss 2.2911 (2.2598)	Training Prec@1 99.609 (99.724)	Training Prec@5 99.805 (99.914)	
2022-04-03 19:22:29,963: ============================================================
2022-04-03 19:23:13,556: time cost, forward:0.010839968573309081, backward:0.059034209600749225, data cost:0.36180509487078877 
2022-04-03 19:23:13,557: ============================================================
2022-04-03 19:23:13,557: Epoch 11/26 Batch 3700/7662 eta: 14:23:51.560706	Training Loss 2.3687 (2.2629)	Training Prec@1 99.805 (99.722)	Training Prec@5 99.805 (99.914)	
2022-04-03 19:23:13,558: ============================================================
2022-04-03 19:23:56,449: time cost, forward:0.010828065821985786, backward:0.0590602777982643, data cost:0.36171855239938455 
2022-04-03 19:23:56,449: ============================================================
2022-04-03 19:23:56,450: Epoch 11/26 Batch 3800/7662 eta: 14:09:13.022903	Training Loss 2.5901 (2.2658)	Training Prec@1 99.414 (99.720)	Training Prec@5 100.000 (99.913)	
2022-04-03 19:23:56,450: ============================================================
2022-04-03 19:24:40,368: time cost, forward:0.010812495420700037, backward:0.05909122660026149, data cost:0.3618796875183935 
2022-04-03 19:24:40,369: ============================================================
2022-04-03 19:24:40,369: Epoch 11/26 Batch 3900/7662 eta: 14:28:49.180121	Training Loss 2.4400 (2.2688)	Training Prec@1 100.000 (99.718)	Training Prec@5 100.000 (99.913)	
2022-04-03 19:24:40,369: ============================================================
2022-04-03 19:25:24,147: time cost, forward:0.01079807933732014, backward:0.05911182576222669, data cost:0.36200685607221433 
2022-04-03 19:25:24,148: ============================================================
2022-04-03 19:25:24,148: Epoch 11/26 Batch 4000/7662 eta: 14:25:18.664397	Training Loss 2.4223 (2.2716)	Training Prec@1 99.609 (99.715)	Training Prec@5 100.000 (99.912)	
2022-04-03 19:25:24,148: ============================================================
2022-04-03 19:26:07,037: time cost, forward:0.010812872181464532, backward:0.05909888102793641, data cost:0.3619261059013045 
2022-04-03 19:26:07,037: ============================================================
2022-04-03 19:26:07,037: Epoch 11/26 Batch 4100/7662 eta: 14:07:01.091563	Training Loss 2.3827 (2.2741)	Training Prec@1 99.414 (99.714)	Training Prec@5 99.805 (99.913)	
2022-04-03 19:26:07,038: ============================================================
2022-04-03 19:26:50,887: time cost, forward:0.010833508970056667, backward:0.059069302741275795, data cost:0.3620792939339856 
2022-04-03 19:26:50,888: ============================================================
2022-04-03 19:26:50,888: Epoch 11/26 Batch 4200/7662 eta: 14:25:16.164498	Training Loss 2.4130 (2.2765)	Training Prec@1 99.805 (99.713)	Training Prec@5 99.805 (99.913)	
2022-04-03 19:26:50,888: ============================================================
2022-04-03 19:27:34,211: time cost, forward:0.01082877919795375, backward:0.059075781067295614, data cost:0.3620861460647352 
2022-04-03 19:27:34,211: ============================================================
2022-04-03 19:27:34,212: Epoch 11/26 Batch 4300/7662 eta: 14:14:08.498256	Training Loss 2.3403 (2.2792)	Training Prec@1 99.805 (99.712)	Training Prec@5 100.000 (99.912)	
2022-04-03 19:27:34,212: ============================================================
2022-04-03 19:28:18,104: time cost, forward:0.010827675817445832, backward:0.059075807218905006, data cost:0.3622327065516613 
2022-04-03 19:28:18,104: ============================================================
2022-04-03 19:28:18,104: Epoch 11/26 Batch 4400/7662 eta: 14:24:38.163391	Training Loss 2.5643 (2.2827)	Training Prec@1 99.414 (99.710)	Training Prec@5 99.805 (99.912)	
2022-04-03 19:28:18,105: ============================================================
2022-04-03 19:29:01,873: time cost, forward:0.010820199023567059, backward:0.05908026905106449, data cost:0.36236202454508665 
2022-04-03 19:29:01,874: ============================================================
2022-04-03 19:29:01,874: Epoch 11/26 Batch 4500/7662 eta: 14:21:29.033532	Training Loss 2.2832 (2.2851)	Training Prec@1 99.414 (99.708)	Training Prec@5 100.000 (99.911)	
2022-04-03 19:29:01,874: ============================================================
2022-04-03 19:29:44,895: time cost, forward:0.010817702891230971, backward:0.059075242826590775, data cost:0.36229865513150655 
2022-04-03 19:29:44,895: ============================================================
2022-04-03 19:29:44,895: Epoch 11/26 Batch 4600/7662 eta: 14:06:02.017950	Training Loss 2.3820 (2.2881)	Training Prec@1 100.000 (99.707)	Training Prec@5 100.000 (99.911)	
2022-04-03 19:29:44,895: ============================================================
2022-04-03 19:30:28,140: time cost, forward:0.010816672376481288, backward:0.059086010237403765, data cost:0.36229098002995347 
2022-04-03 19:30:28,140: ============================================================
2022-04-03 19:30:28,141: Epoch 11/26 Batch 4700/7662 eta: 14:09:43.291214	Training Loss 2.4824 (2.2906)	Training Prec@1 99.805 (99.705)	Training Prec@5 99.805 (99.910)	
2022-04-03 19:30:28,141: ============================================================
2022-04-03 19:31:08,932: time cost, forward:0.01080302746004302, backward:0.05910501631132437, data cost:0.3617383145024116 
2022-04-03 19:31:08,933: ============================================================
2022-04-03 19:31:08,933: Epoch 11/26 Batch 4800/7662 eta: 13:20:50.787621	Training Loss 2.3316 (2.2929)	Training Prec@1 99.609 (99.704)	Training Prec@5 99.805 (99.909)	
2022-04-03 19:31:08,933: ============================================================
2022-04-03 19:31:50,252: time cost, forward:0.01078959216047584, backward:0.059117339781095214, data cost:0.3613798773077026 
2022-04-03 19:31:50,253: ============================================================
2022-04-03 19:31:50,253: Epoch 11/26 Batch 4900/7662 eta: 13:30:30.391157	Training Loss 2.4920 (2.2958)	Training Prec@1 99.414 (99.703)	Training Prec@5 99.805 (99.909)	
2022-04-03 19:31:50,253: ============================================================
2022-04-03 19:32:34,268: time cost, forward:0.010781808766538463, backward:0.05912514514125664, data cost:0.36153504647691626 
2022-04-03 19:32:34,269: ============================================================
2022-04-03 19:32:34,269: Epoch 11/26 Batch 5000/7662 eta: 14:22:39.850428	Training Loss 2.5495 (2.2987)	Training Prec@1 99.219 (99.701)	Training Prec@5 99.805 (99.908)	
2022-04-03 19:32:34,269: ============================================================
2022-04-03 19:33:18,270: time cost, forward:0.010811403653836293, backward:0.059096013454625035, data cost:0.36169802106859916 
2022-04-03 19:33:18,271: ============================================================
2022-04-03 19:33:18,271: Epoch 11/26 Batch 5100/7662 eta: 14:21:39.419837	Training Loss 2.3574 (2.3015)	Training Prec@1 99.805 (99.698)	Training Prec@5 100.000 (99.908)	
2022-04-03 19:33:18,271: ============================================================
2022-04-03 19:34:02,284: time cost, forward:0.010802095407338114, backward:0.05910721346148392, data cost:0.3618479320741108 
2022-04-03 19:34:02,285: ============================================================
2022-04-03 19:34:02,285: Epoch 11/26 Batch 5200/7662 eta: 14:21:09.374820	Training Loss 2.5270 (2.3038)	Training Prec@1 99.609 (99.697)	Training Prec@5 100.000 (99.908)	
2022-04-03 19:34:02,285: ============================================================
2022-04-03 19:34:45,535: time cost, forward:0.010794397164434954, backward:0.05911890955145887, data cost:0.36185498250207937 
2022-04-03 19:34:45,535: ============================================================
2022-04-03 19:34:45,535: Epoch 11/26 Batch 5300/7662 eta: 14:05:29.495996	Training Loss 2.5447 (2.3063)	Training Prec@1 99.609 (99.694)	Training Prec@5 99.805 (99.907)	
2022-04-03 19:34:45,536: ============================================================
2022-04-03 19:35:27,937: time cost, forward:0.01078740449542579, backward:0.05912495944473032, data cost:0.3616946769392166 
2022-04-03 19:35:27,937: ============================================================
2022-04-03 19:35:27,937: Epoch 11/26 Batch 5400/7662 eta: 13:48:12.222184	Training Loss 2.5458 (2.3086)	Training Prec@1 99.805 (99.692)	Training Prec@5 100.000 (99.907)	
2022-04-03 19:35:27,938: ============================================================
2022-04-03 19:36:11,644: time cost, forward:0.010784751177918024, backward:0.05912460247198654, data cost:0.36178995665907315 
2022-04-03 19:36:11,645: ============================================================
2022-04-03 19:36:11,645: Epoch 11/26 Batch 5500/7662 eta: 14:12:58.378285	Training Loss 2.6054 (2.3106)	Training Prec@1 99.414 (99.691)	Training Prec@5 100.000 (99.907)	
2022-04-03 19:36:11,645: ============================================================
2022-04-03 19:36:54,782: time cost, forward:0.010779718178300948, backward:0.05912693233697792, data cost:0.3617682772079607 
2022-04-03 19:36:54,783: ============================================================
2022-04-03 19:36:54,783: Epoch 11/26 Batch 5600/7662 eta: 14:01:08.739370	Training Loss 2.5940 (2.3127)	Training Prec@1 99.414 (99.689)	Training Prec@5 99.805 (99.907)	
2022-04-03 19:36:54,783: ============================================================
2022-04-03 19:37:38,646: time cost, forward:0.01076695010795533, backward:0.059138009623072196, data cost:0.361886985177721 
2022-04-03 19:37:38,646: ============================================================
2022-04-03 19:37:38,646: Epoch 11/26 Batch 5700/7662 eta: 14:14:32.777328	Training Loss 2.4323 (2.3143)	Training Prec@1 100.000 (99.687)	Training Prec@5 100.000 (99.906)	
2022-04-03 19:37:38,646: ============================================================
2022-04-03 19:38:21,954: time cost, forward:0.010760308093172782, backward:0.05914026635497742, data cost:0.36191413541932954 
2022-04-03 19:38:21,955: ============================================================
2022-04-03 19:38:21,955: Epoch 11/26 Batch 5800/7662 eta: 14:03:01.707467	Training Loss 2.5843 (2.3162)	Training Prec@1 99.414 (99.687)	Training Prec@5 99.805 (99.906)	
2022-04-03 19:38:21,955: ============================================================
2022-04-03 19:39:03,230: time cost, forward:0.010748502015461254, backward:0.05914969661717173, data cost:0.36158104815065184 
2022-04-03 19:39:03,230: ============================================================
2022-04-03 19:39:03,230: Epoch 11/26 Batch 5900/7662 eta: 13:22:45.301281	Training Loss 2.4209 (2.3183)	Training Prec@1 99.609 (99.685)	Training Prec@5 99.805 (99.905)	
2022-04-03 19:39:03,231: ============================================================
2022-04-03 19:39:46,300: time cost, forward:0.010738705849524318, backward:0.05916073159747053, data cost:0.3615653732256564 
2022-04-03 19:39:46,300: ============================================================
2022-04-03 19:39:46,301: Epoch 11/26 Batch 6000/7662 eta: 13:56:56.932482	Training Loss 2.2356 (2.3205)	Training Prec@1 100.000 (99.684)	Training Prec@5 100.000 (99.905)	
2022-04-03 19:39:46,301: ============================================================
2022-04-03 19:40:30,451: time cost, forward:0.01073255850108144, backward:0.059163358841280135, data cost:0.3617104948456316 
2022-04-03 19:40:30,451: ============================================================
2022-04-03 19:40:30,451: Epoch 11/26 Batch 6100/7662 eta: 14:17:12.309803	Training Loss 2.5534 (2.3226)	Training Prec@1 99.219 (99.682)	Training Prec@5 99.414 (99.905)	
2022-04-03 19:40:30,451: ============================================================
2022-04-03 19:41:14,720: time cost, forward:0.010728567718478783, backward:0.059162503039573426, data cost:0.36188906687924044 
2022-04-03 19:41:14,721: ============================================================
2022-04-03 19:41:14,721: Epoch 11/26 Batch 6200/7662 eta: 14:18:46.813109	Training Loss 2.3589 (2.3247)	Training Prec@1 99.805 (99.681)	Training Prec@5 99.805 (99.904)	
2022-04-03 19:41:14,721: ============================================================
2022-04-03 19:41:58,584: time cost, forward:0.010722521279118973, backward:0.05916628278916101, data cost:0.3619897630143154 
2022-04-03 19:41:58,584: ============================================================
2022-04-03 19:41:58,584: Epoch 11/26 Batch 6300/7662 eta: 14:10:10.215405	Training Loss 2.4643 (2.3268)	Training Prec@1 99.805 (99.680)	Training Prec@5 100.000 (99.904)	
2022-04-03 19:41:58,585: ============================================================
2022-04-03 19:42:42,748: time cost, forward:0.010725115664136803, backward:0.05915632097399557, data cost:0.3621431600490498 
2022-04-03 19:42:42,748: ============================================================
2022-04-03 19:42:42,748: Epoch 11/26 Batch 6400/7662 eta: 14:15:15.506479	Training Loss 2.3130 (2.3291)	Training Prec@1 100.000 (99.679)	Training Prec@5 100.000 (99.903)	
2022-04-03 19:42:42,749: ============================================================
2022-04-03 19:43:26,622: time cost, forward:0.01071920235682715, backward:0.05916202616775966, data cost:0.3622281460014375 
2022-04-03 19:43:26,622: ============================================================
2022-04-03 19:43:26,623: Epoch 11/26 Batch 6500/7662 eta: 14:08:54.851602	Training Loss 2.4832 (2.3311)	Training Prec@1 99.414 (99.678)	Training Prec@5 99.805 (99.903)	
2022-04-03 19:43:26,623: ============================================================
2022-04-03 19:44:10,152: time cost, forward:0.010715820045430726, backward:0.05916457697195905, data cost:0.3622708008458784 
2022-04-03 19:44:10,153: ============================================================
2022-04-03 19:44:10,153: Epoch 11/26 Batch 6600/7662 eta: 14:01:32.307071	Training Loss 2.6264 (2.3330)	Training Prec@1 99.219 (99.677)	Training Prec@5 99.414 (99.902)	
2022-04-03 19:44:10,153: ============================================================
2022-04-03 19:44:54,110: time cost, forward:0.010714072863687987, backward:0.059162423510678866, data cost:0.3623752747387793 
2022-04-03 19:44:54,110: ============================================================
2022-04-03 19:44:54,110: Epoch 11/26 Batch 6700/7662 eta: 14:09:03.450760	Training Loss 2.5610 (2.3352)	Training Prec@1 99.805 (99.676)	Training Prec@5 99.805 (99.902)	
2022-04-03 19:44:54,111: ============================================================
2022-04-03 19:45:37,990: time cost, forward:0.010709574124728569, backward:0.0591654128792672, data cost:0.36246412479626744 
2022-04-03 19:45:37,991: ============================================================
2022-04-03 19:45:37,991: Epoch 11/26 Batch 6800/7662 eta: 14:06:50.683007	Training Loss 2.3448 (2.3371)	Training Prec@1 100.000 (99.675)	Training Prec@5 100.000 (99.902)	
2022-04-03 19:45:37,991: ============================================================
2022-04-03 19:46:21,608: time cost, forward:0.0107027468326766, backward:0.05917264658707711, data cost:0.3625123082321439 
2022-04-03 19:46:21,609: ============================================================
2022-04-03 19:46:21,609: Epoch 11/26 Batch 6900/7662 eta: 14:01:03.132207	Training Loss 2.5601 (2.3391)	Training Prec@1 99.609 (99.674)	Training Prec@5 100.000 (99.902)	
2022-04-03 19:46:21,609: ============================================================
2022-04-03 19:47:05,269: time cost, forward:0.010696667265016568, backward:0.059181287469549135, data cost:0.36256929240340524 
2022-04-03 19:47:05,269: ============================================================
2022-04-03 19:47:05,270: Epoch 11/26 Batch 7000/7662 eta: 14:01:08.496704	Training Loss 2.4098 (2.3410)	Training Prec@1 99.414 (99.673)	Training Prec@5 100.000 (99.902)	
2022-04-03 19:47:05,270: ============================================================
2022-04-03 19:47:47,290: time cost, forward:0.010691866200983498, backward:0.05918520688171, data cost:0.36239005871466606 
2022-04-03 19:47:47,290: ============================================================
2022-04-03 19:47:47,290: Epoch 11/26 Batch 7100/7662 eta: 13:28:50.857709	Training Loss 2.3359 (2.3428)	Training Prec@1 99.805 (99.671)	Training Prec@5 99.805 (99.901)	
2022-04-03 19:47:47,290: ============================================================
2022-04-03 19:48:30,684: time cost, forward:0.010688339377264294, backward:0.05918296603200038, data cost:0.362396124949603 
2022-04-03 19:48:30,684: ============================================================
2022-04-03 19:48:30,684: Epoch 11/26 Batch 7200/7662 eta: 13:54:33.836842	Training Loss 2.4426 (2.3445)	Training Prec@1 99.414 (99.670)	Training Prec@5 99.805 (99.901)	
2022-04-03 19:48:30,685: ============================================================
2022-04-03 19:49:12,713: time cost, forward:0.010684816849396676, backward:0.059187774609859585, data cost:0.36223518951312533 
2022-04-03 19:49:12,713: ============================================================
2022-04-03 19:49:12,714: Epoch 11/26 Batch 7300/7662 eta: 13:27:36.819929	Training Loss 2.8010 (2.3465)	Training Prec@1 99.609 (99.669)	Training Prec@5 99.805 (99.901)	
2022-04-03 19:49:12,714: ============================================================
2022-04-03 19:49:55,042: time cost, forward:0.010674867167281435, backward:0.05919499879979591, data cost:0.3621150420346539 
2022-04-03 19:49:55,042: ============================================================
2022-04-03 19:49:55,043: Epoch 11/26 Batch 7400/7662 eta: 13:32:39.988389	Training Loss 2.3680 (2.3484)	Training Prec@1 99.609 (99.668)	Training Prec@5 100.000 (99.900)	
2022-04-03 19:49:55,043: ============================================================
2022-04-03 19:50:36,432: time cost, forward:0.010672258812517368, backward:0.05919695577711753, data cost:0.3618617628491518 
2022-04-03 19:50:36,433: ============================================================
2022-04-03 19:50:36,433: Epoch 11/26 Batch 7500/7662 eta: 13:13:57.094899	Training Loss 2.3980 (2.3502)	Training Prec@1 99.609 (99.667)	Training Prec@5 100.000 (99.900)	
2022-04-03 19:50:36,433: ============================================================
2022-04-03 19:51:20,170: time cost, forward:0.010675282427505029, backward:0.05919010596206932, data cost:0.3619346384281139 
2022-04-03 19:51:20,171: ============================================================
2022-04-03 19:51:20,171: Epoch 11/26 Batch 7600/7662 eta: 13:58:15.815902	Training Loss 2.5479 (2.3522)	Training Prec@1 99.414 (99.666)	Training Prec@5 100.000 (99.899)	
2022-04-03 19:51:20,171: ============================================================
2022-04-03 19:51:49,623: Epoch: 11/26 eta: 13:57:48.260865	Training Loss 2.5226 (2.3536)	Training Prec@1 99.219 (99.665)	Training Prec@5 99.414 (99.899)
2022-04-03 19:51:49,623: ============================================================
2022-04-03 19:52:32,968: time cost, forward:0.01037953116677024, backward:0.058264231440996885, data cost:0.36525772316287264 
2022-04-03 19:52:32,969: ============================================================
2022-04-03 19:52:32,969: Epoch 12/26 Batch 100/7662 eta: 13:49:29.509126	Training Loss 2.1842 (2.0871)	Training Prec@1 99.609 (99.805)	Training Prec@5 100.000 (99.955)	
2022-04-03 19:52:32,969: ============================================================
2022-04-03 19:53:14,487: time cost, forward:0.010370452200348055, backward:0.05854860023038471, data cost:0.3551625893942675 
2022-04-03 19:53:14,487: ============================================================
2022-04-03 19:53:14,488: Epoch 12/26 Batch 200/7662 eta: 13:13:54.718628	Training Loss 2.1779 (2.0951)	Training Prec@1 100.000 (99.820)	Training Prec@5 100.000 (99.957)	
2022-04-03 19:53:14,488: ============================================================
2022-04-03 19:53:57,028: time cost, forward:0.010290581247080927, backward:0.05875822054502557, data cost:0.3552407285441523 
2022-04-03 19:53:57,028: ============================================================
2022-04-03 19:53:57,029: Epoch 12/26 Batch 300/7662 eta: 13:32:45.221684	Training Loss 1.9453 (2.1008)	Training Prec@1 100.000 (99.823)	Training Prec@5 100.000 (99.957)	
2022-04-03 19:53:57,029: ============================================================
2022-04-03 19:54:41,257: time cost, forward:0.010312147905354513, backward:0.058810310554982426, data cost:0.3595550962558067 
2022-04-03 19:54:41,258: ============================================================
2022-04-03 19:54:41,258: Epoch 12/26 Batch 400/7662 eta: 14:04:16.139187	Training Loss 2.1938 (2.1109)	Training Prec@1 99.609 (99.819)	Training Prec@5 100.000 (99.955)	
2022-04-03 19:54:41,258: ============================================================
2022-04-03 19:55:25,666: time cost, forward:0.010237517003305928, backward:0.05905998063708594, data cost:0.3623777042648835 
2022-04-03 19:55:25,666: ============================================================
2022-04-03 19:55:25,666: Epoch 12/26 Batch 500/7662 eta: 14:06:57.162338	Training Loss 2.2368 (2.1194)	Training Prec@1 99.609 (99.820)	Training Prec@5 100.000 (99.957)	
2022-04-03 19:55:25,667: ============================================================
2022-04-03 19:56:10,148: time cost, forward:0.01025645999558183, backward:0.059172261338401116, data cost:0.36436173832277224 
2022-04-03 19:56:10,148: ============================================================
2022-04-03 19:56:10,148: Epoch 12/26 Batch 600/7662 eta: 14:07:36.617963	Training Loss 2.3795 (2.1319)	Training Prec@1 99.609 (99.817)	Training Prec@5 99.805 (99.954)	
2022-04-03 19:56:10,149: ============================================================
2022-04-03 19:56:53,472: time cost, forward:0.010304085686483097, backward:0.059191617160737085, data cost:0.3641292032424643 
2022-04-03 19:56:53,472: ============================================================
2022-04-03 19:56:53,472: Epoch 12/26 Batch 700/7662 eta: 13:44:49.193736	Training Loss 2.3285 (2.1413)	Training Prec@1 99.414 (99.811)	Training Prec@5 100.000 (99.952)	
2022-04-03 19:56:53,472: ============================================================
2022-04-03 19:57:37,425: time cost, forward:0.01032026568998831, backward:0.0592742828612632, data cost:0.36470085091525234 
2022-04-03 19:57:37,425: ============================================================
2022-04-03 19:57:37,425: Epoch 12/26 Batch 800/7662 eta: 13:56:04.097284	Training Loss 2.2669 (2.1489)	Training Prec@1 99.805 (99.805)	Training Prec@5 99.805 (99.950)	
2022-04-03 19:57:37,426: ============================================================
2022-04-03 19:58:21,516: time cost, forward:0.010318096540661091, backward:0.05933791617795543, data cost:0.36530334320959446 
2022-04-03 19:58:21,516: ============================================================
2022-04-03 19:58:21,516: Epoch 12/26 Batch 900/7662 eta: 13:57:57.501825	Training Loss 2.1835 (2.1596)	Training Prec@1 99.414 (99.804)	Training Prec@5 99.805 (99.949)	
2022-04-03 19:58:21,517: ============================================================
2022-04-03 19:59:05,753: time cost, forward:0.010375443163576786, backward:0.05934023809385252, data cost:0.365929933639618 
2022-04-03 19:59:05,753: ============================================================
2022-04-03 19:59:05,754: Epoch 12/26 Batch 1000/7662 eta: 13:59:59.950364	Training Loss 2.3220 (2.1678)	Training Prec@1 99.805 (99.800)	Training Prec@5 99.805 (99.947)	
2022-04-03 19:59:05,754: ============================================================
2022-04-03 19:59:49,746: time cost, forward:0.010352938255469728, backward:0.05937601589310484, data cost:0.3662609576745072 
2022-04-03 19:59:49,746: ============================================================
2022-04-03 19:59:49,747: Epoch 12/26 Batch 1100/7662 eta: 13:54:37.571449	Training Loss 2.1298 (2.1770)	Training Prec@1 100.000 (99.797)	Training Prec@5 100.000 (99.947)	
2022-04-03 19:59:49,747: ============================================================
2022-04-03 20:00:33,680: time cost, forward:0.010389879805729526, backward:0.05937264341429137, data cost:0.3664902666392577 
2022-04-03 20:00:33,680: ============================================================
2022-04-03 20:00:33,680: Epoch 12/26 Batch 1200/7662 eta: 13:52:46.289861	Training Loss 2.4321 (2.1850)	Training Prec@1 99.414 (99.794)	Training Prec@5 99.609 (99.946)	
2022-04-03 20:00:33,681: ============================================================
2022-04-03 20:01:18,069: time cost, forward:0.010388906594879174, backward:0.05939785878047106, data cost:0.3669740957329143 
2022-04-03 20:01:18,069: ============================================================
2022-04-03 20:01:18,070: Epoch 12/26 Batch 1300/7662 eta: 14:00:40.061686	Training Loss 2.3742 (2.1932)	Training Prec@1 99.805 (99.792)	Training Prec@5 100.000 (99.946)	
2022-04-03 20:01:18,070: ============================================================
2022-04-03 20:02:01,527: time cost, forward:0.010490065050431879, backward:0.05931991641226626, data cost:0.36677552172761035 
2022-04-03 20:02:01,527: ============================================================
2022-04-03 20:02:01,528: Epoch 12/26 Batch 1400/7662 eta: 13:42:18.339812	Training Loss 2.4275 (2.2004)	Training Prec@1 99.805 (99.788)	Training Prec@5 100.000 (99.945)	
2022-04-03 20:02:01,528: ============================================================
2022-04-03 20:02:45,118: time cost, forward:0.010473884527805727, backward:0.05934678943575502, data cost:0.36670082994426706 
2022-04-03 20:02:45,119: ============================================================
2022-04-03 20:02:45,120: Epoch 12/26 Batch 1500/7662 eta: 13:44:06.885070	Training Loss 2.3355 (2.2076)	Training Prec@1 99.805 (99.786)	Training Prec@5 100.000 (99.944)	
2022-04-03 20:02:45,120: ============================================================
2022-04-03 20:03:28,604: time cost, forward:0.010489489004863956, backward:0.0593349344660298, data cost:0.3665487289130501 
2022-04-03 20:03:28,605: ============================================================
2022-04-03 20:03:28,605: Epoch 12/26 Batch 1600/7662 eta: 13:41:22.304070	Training Loss 2.4006 (2.2154)	Training Prec@1 99.609 (99.783)	Training Prec@5 100.000 (99.943)	
2022-04-03 20:03:28,605: ============================================================
2022-04-03 20:04:13,644: time cost, forward:0.010489841992185703, backward:0.05934932850752949, data cost:0.36733696936438404 
2022-04-03 20:04:13,644: ============================================================
2022-04-03 20:04:13,644: Epoch 12/26 Batch 1700/7662 eta: 14:09:58.315571	Training Loss 2.3382 (2.2223)	Training Prec@1 99.805 (99.780)	Training Prec@5 100.000 (99.942)	
2022-04-03 20:04:13,644: ============================================================
2022-04-03 20:04:58,566: time cost, forward:0.010579520560026567, backward:0.0592541967649603, data cost:0.3679594046013298 
2022-04-03 20:04:58,566: ============================================================
2022-04-03 20:04:58,567: Epoch 12/26 Batch 1800/7662 eta: 14:07:01.031682	Training Loss 2.4420 (2.2296)	Training Prec@1 99.805 (99.779)	Training Prec@5 100.000 (99.941)	
2022-04-03 20:04:58,567: ============================================================
2022-04-03 20:05:43,599: time cost, forward:0.010571121604521692, backward:0.059280564874143835, data cost:0.36857361514798087 
2022-04-03 20:05:43,600: ============================================================
2022-04-03 20:05:43,600: Epoch 12/26 Batch 1900/7662 eta: 14:08:21.782727	Training Loss 2.3751 (2.2351)	Training Prec@1 99.414 (99.777)	Training Prec@5 99.805 (99.941)	
2022-04-03 20:05:43,600: ============================================================
2022-04-03 20:06:28,426: time cost, forward:0.010569558732804208, backward:0.05929723413304247, data cost:0.3690412811424328 
2022-04-03 20:06:28,426: ============================================================
2022-04-03 20:06:28,426: Epoch 12/26 Batch 2000/7662 eta: 14:03:42.642006	Training Loss 2.1920 (2.2411)	Training Prec@1 99.805 (99.775)	Training Prec@5 99.805 (99.941)	
2022-04-03 20:06:28,426: ============================================================
2022-04-03 20:07:13,029: time cost, forward:0.010567897384992492, backward:0.059298638447856496, data cost:0.3693555231716816 
2022-04-03 20:07:13,030: ============================================================
2022-04-03 20:07:13,030: Epoch 12/26 Batch 2100/7662 eta: 13:58:47.089038	Training Loss 2.2255 (2.2478)	Training Prec@1 99.805 (99.772)	Training Prec@5 100.000 (99.940)	
2022-04-03 20:07:13,030: ============================================================
2022-04-03 20:07:57,619: time cost, forward:0.010570424640650314, backward:0.059290537567450924, data cost:0.36963243146222413 
2022-04-03 20:07:57,620: ============================================================
2022-04-03 20:07:57,620: Epoch 12/26 Batch 2200/7662 eta: 13:57:46.664377	Training Loss 2.1819 (2.2532)	Training Prec@1 100.000 (99.772)	Training Prec@5 100.000 (99.939)	
2022-04-03 20:07:57,620: ============================================================
2022-04-03 20:08:41,186: time cost, forward:0.010585348416328844, backward:0.059280096940135585, data cost:0.3694404553931503 
2022-04-03 20:08:41,186: ============================================================
2022-04-03 20:08:41,186: Epoch 12/26 Batch 2300/7662 eta: 13:37:49.272579	Training Loss 2.4095 (2.2598)	Training Prec@1 99.609 (99.768)	Training Prec@5 100.000 (99.938)	
2022-04-03 20:08:41,187: ============================================================
2022-04-03 20:09:25,146: time cost, forward:0.010586578680009034, backward:0.05928161075682678, data cost:0.36942819835444995 
2022-04-03 20:09:25,146: ============================================================
2022-04-03 20:09:25,146: Epoch 12/26 Batch 2400/7662 eta: 13:44:28.444666	Training Loss 2.3836 (2.2664)	Training Prec@1 99.805 (99.766)	Training Prec@5 100.000 (99.936)	
2022-04-03 20:09:25,146: ============================================================
2022-04-03 20:10:08,266: time cost, forward:0.010604532874551188, backward:0.05925078714499716, data cost:0.3691008338073389 
2022-04-03 20:10:08,266: ============================================================
2022-04-03 20:10:08,266: Epoch 12/26 Batch 2500/7662 eta: 13:28:00.054071	Training Loss 2.3832 (2.2713)	Training Prec@1 100.000 (99.765)	Training Prec@5 100.000 (99.937)	
2022-04-03 20:10:08,266: ============================================================
2022-04-03 20:10:53,193: time cost, forward:0.010614655117843645, backward:0.059215498410907785, data cost:0.3695075093621977 
2022-04-03 20:10:53,194: ============================================================
2022-04-03 20:10:53,194: Epoch 12/26 Batch 2600/7662 eta: 14:01:07.962648	Training Loss 2.2873 (2.2766)	Training Prec@1 99.805 (99.761)	Training Prec@5 99.805 (99.935)	
2022-04-03 20:10:53,194: ============================================================
2022-04-03 20:11:37,694: time cost, forward:0.010616706450279663, backward:0.059210854046607114, data cost:0.3697091038468238 
2022-04-03 20:11:37,694: ============================================================
2022-04-03 20:11:37,694: Epoch 12/26 Batch 2700/7662 eta: 13:52:23.211889	Training Loss 2.2414 (2.2820)	Training Prec@1 99.805 (99.759)	Training Prec@5 100.000 (99.934)	
2022-04-03 20:11:37,695: ============================================================
2022-04-03 20:12:22,776: time cost, forward:0.010621464904098266, backward:0.05919682941252779, data cost:0.3700787360091514 
2022-04-03 20:12:22,777: ============================================================
2022-04-03 20:12:22,777: Epoch 12/26 Batch 2800/7662 eta: 14:02:31.394694	Training Loss 2.4699 (2.2871)	Training Prec@1 99.805 (99.754)	Training Prec@5 100.000 (99.932)	
2022-04-03 20:12:22,777: ============================================================
2022-04-03 20:13:07,150: time cost, forward:0.01061194582041398, backward:0.059202593332654485, data cost:0.3702007318702637 
2022-04-03 20:13:07,151: ============================================================
2022-04-03 20:13:07,151: Epoch 12/26 Batch 2900/7662 eta: 13:48:32.601565	Training Loss 2.4815 (2.2924)	Training Prec@1 99.805 (99.751)	Training Prec@5 99.805 (99.931)	
2022-04-03 20:13:07,151: ============================================================
2022-04-03 20:13:51,703: time cost, forward:0.010618701939902412, backward:0.05918363771187381, data cost:0.3703810978667185 
2022-04-03 20:13:51,703: ============================================================
2022-04-03 20:13:51,704: Epoch 12/26 Batch 3000/7662 eta: 13:51:08.394501	Training Loss 2.3849 (2.2970)	Training Prec@1 100.000 (99.748)	Training Prec@5 100.000 (99.929)	
2022-04-03 20:13:51,704: ============================================================
2022-04-03 20:14:34,666: time cost, forward:0.010611764459157614, backward:0.05919178019188496, data cost:0.37002133999997167 
2022-04-03 20:14:34,666: ============================================================
2022-04-03 20:14:34,666: Epoch 12/26 Batch 3100/7662 eta: 13:20:45.760625	Training Loss 2.4673 (2.3014)	Training Prec@1 99.805 (99.746)	Training Prec@5 99.805 (99.928)	
2022-04-03 20:14:34,667: ============================================================
2022-04-03 20:15:18,479: time cost, forward:0.010610017227955109, backward:0.059192968480622034, data cost:0.3699595579395968 
2022-04-03 20:15:18,479: ============================================================
2022-04-03 20:15:18,479: Epoch 12/26 Batch 3200/7662 eta: 13:35:52.434471	Training Loss 2.3489 (2.3059)	Training Prec@1 100.000 (99.743)	Training Prec@5 100.000 (99.928)	
2022-04-03 20:15:18,479: ============================================================
2022-04-03 20:16:02,352: time cost, forward:0.010693796478137351, backward:0.05911278283823689, data cost:0.3699096529799615 
2022-04-03 20:16:02,352: ============================================================
2022-04-03 20:16:02,352: Epoch 12/26 Batch 3300/7662 eta: 13:36:16.053765	Training Loss 2.3901 (2.3102)	Training Prec@1 99.609 (99.740)	Training Prec@5 100.000 (99.926)	
2022-04-03 20:16:02,353: ============================================================
2022-04-03 20:16:46,431: time cost, forward:0.010683163715552217, backward:0.05911217524255504, data cost:0.36994103159263364 
2022-04-03 20:16:46,431: ============================================================
2022-04-03 20:16:46,432: Epoch 12/26 Batch 3400/7662 eta: 13:39:21.912755	Training Loss 2.3840 (2.3143)	Training Prec@1 100.000 (99.739)	Training Prec@5 100.000 (99.926)	
2022-04-03 20:16:46,432: ============================================================
2022-04-03 20:17:30,739: time cost, forward:0.010691307789600042, backward:0.059089442190697415, data cost:0.37004952343507097 
2022-04-03 20:17:30,739: ============================================================
2022-04-03 20:17:30,740: Epoch 12/26 Batch 3500/7662 eta: 13:42:52.832434	Training Loss 2.3791 (2.3181)	Training Prec@1 99.609 (99.736)	Training Prec@5 100.000 (99.924)	
2022-04-03 20:17:30,740: ============================================================
2022-04-03 20:18:15,855: time cost, forward:0.010677573878952582, backward:0.059100097071697194, data cost:0.3703326357507348 
2022-04-03 20:18:15,856: ============================================================
2022-04-03 20:18:15,856: Epoch 12/26 Batch 3600/7662 eta: 13:57:08.660591	Training Loss 2.7197 (2.3221)	Training Prec@1 99.219 (99.733)	Training Prec@5 100.000 (99.924)	
2022-04-03 20:18:15,856: ============================================================
2022-04-03 20:18:59,337: time cost, forward:0.01066695667338004, backward:0.05911060396675549, data cost:0.370181171273373 
2022-04-03 20:18:59,337: ============================================================
2022-04-03 20:18:59,338: Epoch 12/26 Batch 3700/7662 eta: 13:26:05.135498	Training Loss 2.5715 (2.3251)	Training Prec@1 99.414 (99.731)	Training Prec@5 99.805 (99.923)	
2022-04-03 20:18:59,338: ============================================================
2022-04-03 20:19:44,142: time cost, forward:0.010650864209774827, backward:0.059129576709402894, data cost:0.3703737354303668 
2022-04-03 20:19:44,142: ============================================================
2022-04-03 20:19:44,142: Epoch 12/26 Batch 3800/7662 eta: 13:49:51.734847	Training Loss 2.2737 (2.3283)	Training Prec@1 99.414 (99.728)	Training Prec@5 99.805 (99.922)	
2022-04-03 20:19:44,142: ============================================================
2022-04-03 20:20:29,146: time cost, forward:0.010638997016059462, backward:0.05914415980522741, data cost:0.3706082986482873 
2022-04-03 20:20:29,146: ============================================================
2022-04-03 20:20:29,146: Epoch 12/26 Batch 3900/7662 eta: 13:52:48.295884	Training Loss 2.2446 (2.3319)	Training Prec@1 99.414 (99.726)	Training Prec@5 99.805 (99.921)	
2022-04-03 20:20:29,146: ============================================================
2022-04-03 20:21:13,492: time cost, forward:0.010634040081313205, backward:0.05915538726314422, data cost:0.37065623139822357 
2022-04-03 20:21:13,492: ============================================================
2022-04-03 20:21:13,493: Epoch 12/26 Batch 4000/7662 eta: 13:39:53.768273	Training Loss 2.5788 (2.3352)	Training Prec@1 99.609 (99.724)	Training Prec@5 100.000 (99.921)	
2022-04-03 20:21:13,493: ============================================================
2022-04-03 20:21:58,404: time cost, forward:0.010618192331184263, backward:0.059171667096672424, data cost:0.37086702149273215 
2022-04-03 20:21:58,405: ============================================================
2022-04-03 20:21:58,405: Epoch 12/26 Batch 4100/7662 eta: 13:49:37.048078	Training Loss 2.5820 (2.3389)	Training Prec@1 99.805 (99.722)	Training Prec@5 99.805 (99.920)	
2022-04-03 20:21:58,405: ============================================================
2022-04-03 20:22:43,319: time cost, forward:0.010610890178403335, backward:0.05918817998227916, data cost:0.37104621317364483 
2022-04-03 20:22:43,319: ============================================================
2022-04-03 20:22:43,319: Epoch 12/26 Batch 4200/7662 eta: 13:48:53.821699	Training Loss 2.5496 (2.3422)	Training Prec@1 99.414 (99.720)	Training Prec@5 100.000 (99.920)	
2022-04-03 20:22:43,319: ============================================================
2022-04-03 20:23:28,019: time cost, forward:0.010601433578494761, backward:0.05920821562787216, data cost:0.37115793351268567 
2022-04-03 20:23:28,019: ============================================================
2022-04-03 20:23:28,020: Epoch 12/26 Batch 4300/7662 eta: 13:44:12.492529	Training Loss 2.3554 (2.3455)	Training Prec@1 99.609 (99.717)	Training Prec@5 100.000 (99.918)	
2022-04-03 20:23:28,022: ============================================================
2022-04-03 20:24:13,321: time cost, forward:0.010598709648862484, backward:0.059210711323312536, data cost:0.3714261799678122 
2022-04-03 20:24:13,322: ============================================================
2022-04-03 20:24:13,322: Epoch 12/26 Batch 4400/7662 eta: 13:54:33.360572	Training Loss 2.3802 (2.3488)	Training Prec@1 99.805 (99.714)	Training Prec@5 99.805 (99.918)	
2022-04-03 20:24:13,322: ============================================================
2022-04-03 20:24:58,154: time cost, forward:0.010594196069449896, backward:0.059210553702366935, data cost:0.3715783042042858 
2022-04-03 20:24:58,155: ============================================================
2022-04-03 20:24:58,155: Epoch 12/26 Batch 4500/7662 eta: 13:45:09.149454	Training Loss 2.5971 (2.3518)	Training Prec@1 99.805 (99.712)	Training Prec@5 99.805 (99.917)	
2022-04-03 20:24:58,155: ============================================================
2022-04-03 20:25:41,992: time cost, forward:0.010582390337514992, backward:0.05922525679191627, data cost:0.3715058439424386 
2022-04-03 20:25:41,992: ============================================================
2022-04-03 20:25:41,992: Epoch 12/26 Batch 4600/7662 eta: 13:26:06.366698	Training Loss 2.6181 (2.3549)	Training Prec@1 99.219 (99.710)	Training Prec@5 99.805 (99.916)	
2022-04-03 20:25:41,992: ============================================================
2022-04-03 20:26:26,283: time cost, forward:0.010565664088835131, backward:0.05924067808785675, data cost:0.37152108960416524 
2022-04-03 20:26:26,283: ============================================================
2022-04-03 20:26:26,283: Epoch 12/26 Batch 4700/7662 eta: 13:33:42.234428	Training Loss 2.4620 (2.3579)	Training Prec@1 99.023 (99.708)	Training Prec@5 100.000 (99.915)	
2022-04-03 20:26:26,283: ============================================================
2022-04-03 20:27:11,286: time cost, forward:0.010555002534854013, backward:0.05924779997688702, data cost:0.3717025011423902 
2022-04-03 20:27:11,286: ============================================================
2022-04-03 20:27:11,287: Epoch 12/26 Batch 4800/7662 eta: 13:46:02.780937	Training Loss 2.4997 (2.3602)	Training Prec@1 99.805 (99.706)	Training Prec@5 100.000 (99.914)	
2022-04-03 20:27:11,287: ============================================================
2022-04-03 20:27:55,885: time cost, forward:0.010553241238396469, backward:0.059248351301312764, data cost:0.37177904106252263 
2022-04-03 20:27:55,886: ============================================================
2022-04-03 20:27:55,886: Epoch 12/26 Batch 4900/7662 eta: 13:37:53.121003	Training Loss 2.5788 (2.3627)	Training Prec@1 99.023 (99.705)	Training Prec@5 99.805 (99.914)	
2022-04-03 20:27:55,886: ============================================================
2022-04-03 20:28:41,389: time cost, forward:0.010557277700046845, backward:0.059236474122064404, data cost:0.3720475285261673 
2022-04-03 20:28:41,389: ============================================================
2022-04-03 20:28:41,390: Epoch 12/26 Batch 5000/7662 eta: 13:53:42.622144	Training Loss 2.4650 (2.3654)	Training Prec@1 99.414 (99.703)	Training Prec@5 100.000 (99.914)	
2022-04-03 20:28:41,390: ============================================================
2022-04-03 20:29:26,606: time cost, forward:0.010558549505421918, backward:0.05923504505842007, data cost:0.37222950368283847 
2022-04-03 20:29:26,607: ============================================================
2022-04-03 20:29:26,607: Epoch 12/26 Batch 5100/7662 eta: 13:47:42.772952	Training Loss 2.8251 (2.3680)	Training Prec@1 99.414 (99.701)	Training Prec@5 99.609 (99.913)	
2022-04-03 20:29:26,607: ============================================================
2022-04-03 20:30:10,532: time cost, forward:0.01056034589276953, backward:0.059233812901533026, data cost:0.3721752766119239 
2022-04-03 20:30:10,532: ============================================================
2022-04-03 20:30:10,532: Epoch 12/26 Batch 5200/7662 eta: 13:23:19.577940	Training Loss 2.6417 (2.3703)	Training Prec@1 99.414 (99.699)	Training Prec@5 99.805 (99.912)	
2022-04-03 20:30:10,533: ============================================================
2022-04-03 20:30:55,159: time cost, forward:0.010564640707104897, backward:0.059228423542066616, data cost:0.3722515876483503 
2022-04-03 20:30:55,160: ============================================================
2022-04-03 20:30:55,160: Epoch 12/26 Batch 5300/7662 eta: 13:35:25.625557	Training Loss 2.6359 (2.3727)	Training Prec@1 99.805 (99.697)	Training Prec@5 100.000 (99.911)	
2022-04-03 20:30:55,160: ============================================================
2022-04-03 20:31:40,407: time cost, forward:0.010568658297405041, backward:0.059226189703604847, data cost:0.37241810033621225 
2022-04-03 20:31:40,408: ============================================================
2022-04-03 20:31:40,408: Epoch 12/26 Batch 5400/7662 eta: 13:46:00.924957	Training Loss 2.3540 (2.3750)	Training Prec@1 99.805 (99.697)	Training Prec@5 100.000 (99.911)	
2022-04-03 20:31:40,409: ============================================================
2022-04-03 20:32:24,883: time cost, forward:0.010583669668025245, backward:0.0592111086580922, data cost:0.37246421745287805 
2022-04-03 20:32:24,884: ============================================================
2022-04-03 20:32:24,884: Epoch 12/26 Batch 5500/7662 eta: 13:31:10.206812	Training Loss 2.6659 (2.3773)	Training Prec@1 99.219 (99.695)	Training Prec@5 99.805 (99.910)	
2022-04-03 20:32:24,884: ============================================================
2022-04-03 20:33:09,677: time cost, forward:0.010592801716949795, backward:0.059198380283083864, data cost:0.37255983783594515 
2022-04-03 20:33:09,677: ============================================================
2022-04-03 20:33:09,677: Epoch 12/26 Batch 5600/7662 eta: 13:36:12.879055	Training Loss 2.2766 (2.3797)	Training Prec@1 99.609 (99.694)	Training Prec@5 99.609 (99.910)	
2022-04-03 20:33:09,677: ============================================================
2022-04-03 20:33:54,846: time cost, forward:0.010593204335970594, backward:0.059191059158400165, data cost:0.37272623849136827 
2022-04-03 20:33:54,847: ============================================================
2022-04-03 20:33:54,847: Epoch 12/26 Batch 5700/7662 eta: 13:42:19.326625	Training Loss 2.4155 (2.3823)	Training Prec@1 99.805 (99.692)	Training Prec@5 99.805 (99.910)	
2022-04-03 20:33:54,847: ============================================================
2022-04-03 20:34:39,109: time cost, forward:0.010587403272262708, backward:0.05919748636171065, data cost:0.37271974789395296 
2022-04-03 20:34:39,110: ============================================================
2022-04-03 20:34:39,110: Epoch 12/26 Batch 5800/7662 eta: 13:25:04.686025	Training Loss 2.5671 (2.3846)	Training Prec@1 99.219 (99.690)	Training Prec@5 99.414 (99.909)	
2022-04-03 20:34:39,110: ============================================================
2022-04-03 20:35:23,852: time cost, forward:0.010586509382872283, backward:0.05920124502581325, data cost:0.37279028851291973 
2022-04-03 20:35:23,853: ============================================================
2022-04-03 20:35:23,853: Epoch 12/26 Batch 5900/7662 eta: 13:33:04.033587	Training Loss 2.4213 (2.3870)	Training Prec@1 99.414 (99.687)	Training Prec@5 99.609 (99.908)	
2022-04-03 20:35:23,853: ============================================================
2022-04-03 20:36:08,232: time cost, forward:0.010588704158632254, backward:0.05919862031976388, data cost:0.37280368542627484 
2022-04-03 20:36:08,232: ============================================================
2022-04-03 20:36:08,232: Epoch 12/26 Batch 6000/7662 eta: 13:25:42.569983	Training Loss 2.4658 (2.3892)	Training Prec@1 99.023 (99.685)	Training Prec@5 99.805 (99.907)	
2022-04-03 20:36:08,232: ============================================================
2022-04-03 20:36:50,350: time cost, forward:0.010583085180364842, backward:0.059197370332466775, data cost:0.37244788133271267 
2022-04-03 20:36:50,351: ============================================================
2022-04-03 20:36:50,351: Epoch 12/26 Batch 6100/7662 eta: 12:43:58.163246	Training Loss 2.5203 (2.3915)	Training Prec@1 99.805 (99.684)	Training Prec@5 100.000 (99.907)	
2022-04-03 20:36:50,351: ============================================================
2022-04-03 20:37:33,057: time cost, forward:0.010633730815291155, backward:0.059141241979129774, data cost:0.37220069315572346 
2022-04-03 20:37:33,057: ============================================================
2022-04-03 20:37:33,058: Epoch 12/26 Batch 6200/7662 eta: 12:53:55.536394	Training Loss 2.2791 (2.3936)	Training Prec@1 99.805 (99.682)	Training Prec@5 99.805 (99.906)	
2022-04-03 20:37:33,058: ============================================================
2022-04-03 20:38:17,004: time cost, forward:0.010631766427526551, backward:0.05914027264315394, data cost:0.37215483996731497 
2022-04-03 20:38:17,005: ============================================================
2022-04-03 20:38:17,005: Epoch 12/26 Batch 6300/7662 eta: 13:15:40.179816	Training Loss 2.5707 (2.3956)	Training Prec@1 99.414 (99.681)	Training Prec@5 99.609 (99.906)	
2022-04-03 20:38:17,005: ============================================================
2022-04-03 20:39:00,060: time cost, forward:0.010634150462590973, backward:0.05913387531227461, data cost:0.37196753374914354 
2022-04-03 20:39:00,060: ============================================================
2022-04-03 20:39:00,060: Epoch 12/26 Batch 6400/7662 eta: 12:58:48.744316	Training Loss 2.6602 (2.3973)	Training Prec@1 99.805 (99.679)	Training Prec@5 99.805 (99.905)	
2022-04-03 20:39:00,061: ============================================================
2022-04-03 20:39:45,154: time cost, forward:0.010636090865445551, backward:0.059128743535758053, data cost:0.3721120682546296 
2022-04-03 20:39:45,154: ============================================================
2022-04-03 20:39:45,154: Epoch 12/26 Batch 6500/7662 eta: 13:34:55.661712	Training Loss 2.5107 (2.3993)	Training Prec@1 99.414 (99.678)	Training Prec@5 100.000 (99.905)	
2022-04-03 20:39:45,154: ============================================================
2022-04-03 20:40:29,921: time cost, forward:0.01063940036945369, backward:0.05912405043808795, data cost:0.3721881139312735 
2022-04-03 20:40:29,921: ============================================================
2022-04-03 20:40:29,922: Epoch 12/26 Batch 6600/7662 eta: 13:28:16.836267	Training Loss 2.6086 (2.4014)	Training Prec@1 99.414 (99.676)	Training Prec@5 99.609 (99.904)	
2022-04-03 20:40:29,922: ============================================================
2022-04-03 20:41:13,969: time cost, forward:0.010631133520989332, backward:0.05913737941667346, data cost:0.3721642551501841 
2022-04-03 20:41:13,969: ============================================================
2022-04-03 20:41:13,969: Epoch 12/26 Batch 6700/7662 eta: 13:14:33.260949	Training Loss 2.4594 (2.4032)	Training Prec@1 99.414 (99.675)	Training Prec@5 100.000 (99.904)	
2022-04-03 20:41:13,970: ============================================================
2022-04-03 20:41:58,309: time cost, forward:0.010643921173360526, backward:0.059122161210188186, data cost:0.3721687116593469 
2022-04-03 20:41:58,309: ============================================================
2022-04-03 20:41:58,309: Epoch 12/26 Batch 6800/7662 eta: 13:19:05.357750	Training Loss 2.2756 (2.4053)	Training Prec@1 99.219 (99.674)	Training Prec@5 99.609 (99.903)	
2022-04-03 20:41:58,310: ============================================================
2022-04-03 20:42:43,700: time cost, forward:0.010638694794977345, backward:0.05912991485175473, data cost:0.3723296074439415 
2022-04-03 20:42:43,701: ============================================================
2022-04-03 20:42:43,701: Epoch 12/26 Batch 6900/7662 eta: 13:37:16.902951	Training Loss 2.4196 (2.4068)	Training Prec@1 99.805 (99.672)	Training Prec@5 99.805 (99.902)	
2022-04-03 20:42:43,701: ============================================================
2022-04-03 20:43:29,499: time cost, forward:0.010674927469355189, backward:0.059089688577555234, data cost:0.372553592512379 
2022-04-03 20:43:29,500: ============================================================
2022-04-03 20:43:29,500: Epoch 12/26 Batch 7000/7662 eta: 13:43:51.365293	Training Loss 2.5475 (2.4087)	Training Prec@1 99.414 (99.671)	Training Prec@5 99.805 (99.902)	
2022-04-03 20:43:29,500: ============================================================
2022-04-03 20:44:15,349: time cost, forward:0.010671444687478592, backward:0.05909487508958386, data cost:0.3727741916173948 
2022-04-03 20:44:15,350: ============================================================
2022-04-03 20:44:15,350: Epoch 12/26 Batch 7100/7662 eta: 13:44:00.519053	Training Loss 2.5176 (2.4102)	Training Prec@1 99.414 (99.670)	Training Prec@5 99.609 (99.902)	
2022-04-03 20:44:15,350: ============================================================
2022-04-03 20:45:00,908: time cost, forward:0.010672011231693862, backward:0.059093249210103845, data cost:0.3729494226394486 
2022-04-03 20:45:00,908: ============================================================
2022-04-03 20:45:00,908: Epoch 12/26 Batch 7200/7662 eta: 13:38:00.546783	Training Loss 2.6251 (2.4122)	Training Prec@1 99.805 (99.669)	Training Prec@5 99.805 (99.901)	
2022-04-03 20:45:00,909: ============================================================
2022-04-03 20:45:45,211: time cost, forward:0.010672366395357912, backward:0.059088685770919344, data cost:0.3729464933633445 
2022-04-03 20:45:45,212: ============================================================
2022-04-03 20:45:45,212: Epoch 12/26 Batch 7300/7662 eta: 13:14:44.689042	Training Loss 2.5009 (2.4138)	Training Prec@1 99.609 (99.667)	Training Prec@5 99.805 (99.901)	
2022-04-03 20:45:45,213: ============================================================
2022-04-03 20:46:30,228: time cost, forward:0.010665639572360094, backward:0.0590927055323828, data cost:0.3730441431916071 
2022-04-03 20:46:30,228: ============================================================
2022-04-03 20:46:30,228: Epoch 12/26 Batch 7400/7662 eta: 13:26:46.201911	Training Loss 2.4535 (2.4155)	Training Prec@1 99.609 (99.666)	Training Prec@5 100.000 (99.901)	
2022-04-03 20:46:30,228: ============================================================
2022-04-03 20:47:15,679: time cost, forward:0.01068247892265559, backward:0.05907281479337626, data cost:0.3732024217100203 
2022-04-03 20:47:15,679: ============================================================
2022-04-03 20:47:15,679: Epoch 12/26 Batch 7500/7662 eta: 13:33:48.431254	Training Loss 2.4494 (2.4173)	Training Prec@1 99.609 (99.665)	Training Prec@5 100.000 (99.901)	
2022-04-03 20:47:15,680: ============================================================
2022-04-03 20:48:01,759: time cost, forward:0.010684222167284022, backward:0.05907013463666524, data cost:0.3734268792633446 
2022-04-03 20:48:01,760: ============================================================
2022-04-03 20:48:01,761: Epoch 12/26 Batch 7600/7662 eta: 13:44:19.479181	Training Loss 2.5904 (2.4190)	Training Prec@1 99.805 (99.664)	Training Prec@5 99.805 (99.900)	
2022-04-03 20:48:01,761: ============================================================
2022-04-03 20:48:31,698: Epoch: 12/26 eta: 13:43:50.447986	Training Loss 2.4660 (2.4199)	Training Prec@1 99.219 (99.663)	Training Prec@5 100.000 (99.900)
2022-04-03 20:48:31,698: ============================================================
2022-04-03 20:49:17,966: time cost, forward:0.011240766506002408, backward:0.05792582396304968, data cost:0.393567159922436 
2022-04-03 20:49:17,966: ============================================================
2022-04-03 20:49:17,967: Epoch 13/26 Batch 100/7662 eta: 13:45:51.650287	Training Loss 2.0719 (2.1010)	Training Prec@1 100.000 (99.820)	Training Prec@5 100.000 (99.947)	
2022-04-03 20:49:17,967: ============================================================
2022-04-03 20:50:02,977: time cost, forward:0.011239955173664955, backward:0.057766027786024854, data cost:0.3868760834986241 
2022-04-03 20:50:02,977: ============================================================
2022-04-03 20:50:02,978: Epoch 13/26 Batch 200/7662 eta: 13:23:12.741220	Training Loss 2.1059 (2.1156)	Training Prec@1 99.805 (99.802)	Training Prec@5 100.000 (99.947)	
2022-04-03 20:50:02,978: ============================================================
2022-04-03 20:50:46,378: time cost, forward:0.011035194365077194, backward:0.05810650854206404, data cost:0.3794000930212014 
2022-04-03 20:50:46,379: ============================================================
2022-04-03 20:50:46,379: Epoch 13/26 Batch 300/7662 eta: 12:53:45.821272	Training Loss 2.0728 (2.1225)	Training Prec@1 100.000 (99.799)	Training Prec@5 100.000 (99.951)	
2022-04-03 20:50:46,379: ============================================================
2022-04-03 20:51:31,194: time cost, forward:0.010910544479102419, backward:0.058517969341803915, data cost:0.3788273549617681 
2022-04-03 20:51:31,194: ============================================================
2022-04-03 20:51:31,195: Epoch 13/26 Batch 400/7662 eta: 13:18:14.099664	Training Loss 2.1892 (2.1362)	Training Prec@1 100.000 (99.801)	Training Prec@5 100.000 (99.949)	
2022-04-03 20:51:31,195: ============================================================
2022-04-03 20:52:15,085: time cost, forward:0.01092484384357093, backward:0.058675668521491225, data cost:0.37676079669791857 
2022-04-03 20:52:15,086: ============================================================
2022-04-03 20:52:15,086: Epoch 13/26 Batch 500/7662 eta: 13:01:02.441046	Training Loss 2.2998 (2.1481)	Training Prec@1 99.609 (99.797)	Training Prec@5 100.000 (99.945)	
2022-04-03 20:52:15,086: ============================================================
2022-04-03 20:52:59,367: time cost, forward:0.011045036411444612, backward:0.058685304326485714, data cost:0.3759403009844543 
2022-04-03 20:52:59,368: ============================================================
2022-04-03 20:52:59,368: Epoch 13/26 Batch 600/7662 eta: 13:07:15.312119	Training Loss 2.1269 (2.1620)	Training Prec@1 99.805 (99.798)	Training Prec@5 100.000 (99.946)	
2022-04-03 20:52:59,368: ============================================================
2022-04-03 20:53:45,033: time cost, forward:0.011563287784101626, backward:0.05830590441844324, data cost:0.37729693141276915 
2022-04-03 20:53:45,033: ============================================================
2022-04-03 20:53:45,033: Epoch 13/26 Batch 700/7662 eta: 13:31:04.813336	Training Loss 2.1630 (2.1743)	Training Prec@1 99.805 (99.799)	Training Prec@5 100.000 (99.944)	
2022-04-03 20:53:45,033: ============================================================
2022-04-03 20:54:30,913: time cost, forward:0.011404499691329402, backward:0.058583978717407684, data cost:0.37845191012634355 
2022-04-03 20:54:30,913: ============================================================
2022-04-03 20:54:30,914: Epoch 13/26 Batch 800/7662 eta: 13:34:08.477644	Training Loss 2.4132 (2.1861)	Training Prec@1 100.000 (99.796)	Training Prec@5 100.000 (99.942)	
2022-04-03 20:54:30,914: ============================================================
2022-04-03 20:55:15,969: time cost, forward:0.011339844798087013, backward:0.058709502883164316, data cost:0.3786610249550112 
2022-04-03 20:55:15,969: ============================================================
2022-04-03 20:55:15,970: Epoch 13/26 Batch 900/7662 eta: 13:18:45.609279	Training Loss 2.1934 (2.1961)	Training Prec@1 100.000 (99.793)	Training Prec@5 100.000 (99.942)	
2022-04-03 20:55:15,970: ============================================================
2022-04-03 20:55:59,983: time cost, forward:0.011235471721645351, backward:0.05885534243540721, data cost:0.37772415946792437 
2022-04-03 20:55:59,984: ============================================================
2022-04-03 20:55:59,984: Epoch 13/26 Batch 1000/7662 eta: 12:59:33.404309	Training Loss 2.3422 (2.2058)	Training Prec@1 100.000 (99.794)	Training Prec@5 100.000 (99.941)	
2022-04-03 20:55:59,984: ============================================================
2022-04-03 20:56:44,950: time cost, forward:0.011216083800825236, backward:0.05893875817150501, data cost:0.3776165256725863 
2022-04-03 20:56:44,951: ============================================================
2022-04-03 20:56:44,951: Epoch 13/26 Batch 1100/7662 eta: 13:15:40.949691	Training Loss 2.1179 (2.2147)	Training Prec@1 100.000 (99.791)	Training Prec@5 100.000 (99.939)	
2022-04-03 20:56:44,951: ============================================================
2022-04-03 20:57:29,743: time cost, forward:0.01120055209009522, backward:0.05897216780967172, data cost:0.3776917270663582 
2022-04-03 20:57:29,743: ============================================================
2022-04-03 20:57:29,743: Epoch 13/26 Batch 1200/7662 eta: 13:11:50.970754	Training Loss 2.3561 (2.2217)	Training Prec@1 99.609 (99.789)	Training Prec@5 99.805 (99.938)	
2022-04-03 20:57:29,744: ============================================================
2022-04-03 20:58:14,252: time cost, forward:0.011167312787990555, backward:0.059056337472564724, data cost:0.3774122753172677 
2022-04-03 20:58:14,252: ============================================================
2022-04-03 20:58:14,252: Epoch 13/26 Batch 1300/7662 eta: 13:06:05.637932	Training Loss 2.1777 (2.2322)	Training Prec@1 99.805 (99.784)	Training Prec@5 99.805 (99.937)	
2022-04-03 20:58:14,252: ============================================================
2022-04-03 20:58:59,124: time cost, forward:0.01111936109077939, backward:0.059133583175190185, data cost:0.37741278085306423 
2022-04-03 20:58:59,124: ============================================================
2022-04-03 20:58:59,125: Epoch 13/26 Batch 1400/7662 eta: 13:11:45.865035	Training Loss 2.3282 (2.2406)	Training Prec@1 99.609 (99.778)	Training Prec@5 100.000 (99.936)	
2022-04-03 20:58:59,125: ============================================================
2022-04-03 20:59:44,050: time cost, forward:0.01107006123894608, backward:0.059220194100856466, data cost:0.37740637605551325 
2022-04-03 20:59:44,050: ============================================================
2022-04-03 20:59:44,050: Epoch 13/26 Batch 1500/7662 eta: 13:11:57.396501	Training Loss 2.4311 (2.2477)	Training Prec@1 100.000 (99.775)	Training Prec@5 100.000 (99.936)	
2022-04-03 20:59:44,050: ============================================================
2022-04-03 21:00:28,344: time cost, forward:0.011071609064069966, backward:0.0592143798038466, data cost:0.3771157884985451 
2022-04-03 21:00:28,344: ============================================================
2022-04-03 21:00:28,345: Epoch 13/26 Batch 1600/7662 eta: 13:00:05.463620	Training Loss 2.4954 (2.2553)	Training Prec@1 99.805 (99.773)	Training Prec@5 100.000 (99.936)	
2022-04-03 21:00:28,345: ============================================================
2022-04-03 21:01:10,700: time cost, forward:0.011073357782481768, backward:0.05924904493811272, data cost:0.37565369940000537 
2022-04-03 21:01:10,701: ============================================================
2022-04-03 21:01:10,701: Epoch 13/26 Batch 1700/7662 eta: 12:25:15.019274	Training Loss 2.4739 (2.2631)	Training Prec@1 100.000 (99.769)	Training Prec@5 100.000 (99.935)	
2022-04-03 21:01:10,701: ============================================================
2022-04-03 21:01:54,049: time cost, forward:0.011066990471204298, backward:0.05926390499986497, data cost:0.37490896823473807 
2022-04-03 21:01:54,049: ============================================================
2022-04-03 21:01:54,050: Epoch 13/26 Batch 1800/7662 eta: 12:41:59.714792	Training Loss 2.4265 (2.2699)	Training Prec@1 99.609 (99.763)	Training Prec@5 100.000 (99.934)	
2022-04-03 21:01:54,050: ============================================================
2022-04-03 21:02:38,579: time cost, forward:0.011040567284574504, backward:0.05931024692007088, data cost:0.37485784389521964 
2022-04-03 21:02:38,579: ============================================================
2022-04-03 21:02:38,580: Epoch 13/26 Batch 1900/7662 eta: 13:02:00.683026	Training Loss 2.1977 (2.2761)	Training Prec@1 99.609 (99.762)	Training Prec@5 99.805 (99.934)	
2022-04-03 21:02:38,580: ============================================================
2022-04-03 21:03:22,917: time cost, forward:0.011039172845700194, backward:0.05933069216722008, data cost:0.37473030052165973 
2022-04-03 21:03:22,917: ============================================================
2022-04-03 21:03:22,917: Epoch 13/26 Batch 2000/7662 eta: 12:57:53.864090	Training Loss 2.2820 (2.2817)	Training Prec@1 99.414 (99.761)	Training Prec@5 100.000 (99.933)	
2022-04-03 21:03:22,918: ============================================================
2022-04-03 21:04:07,939: time cost, forward:0.011017246209990133, backward:0.05935058427913351, data cost:0.3749492142301562 
2022-04-03 21:04:07,940: ============================================================
2022-04-03 21:04:07,940: Epoch 13/26 Batch 2100/7662 eta: 13:09:09.793052	Training Loss 2.6812 (2.2872)	Training Prec@1 99.023 (99.756)	Training Prec@5 99.609 (99.931)	
2022-04-03 21:04:07,940: ============================================================
2022-04-03 21:04:51,597: time cost, forward:0.011016317474240332, backward:0.05933781025788089, data cost:0.3745509602363243 
2022-04-03 21:04:51,598: ============================================================
2022-04-03 21:04:51,598: Epoch 13/26 Batch 2200/7662 eta: 12:44:30.917798	Training Loss 2.3186 (2.2929)	Training Prec@1 99.609 (99.754)	Training Prec@5 99.805 (99.931)	
2022-04-03 21:04:51,598: ============================================================
2022-04-03 21:05:35,090: time cost, forward:0.01102647889225625, backward:0.0593282347816444, data cost:0.3740883259319025 
2022-04-03 21:05:35,091: ============================================================
2022-04-03 21:05:35,091: Epoch 13/26 Batch 2300/7662 eta: 12:40:54.251542	Training Loss 2.2485 (2.2984)	Training Prec@1 99.805 (99.752)	Training Prec@5 100.000 (99.931)	
2022-04-03 21:05:35,091: ============================================================
2022-04-03 21:06:17,753: time cost, forward:0.0110125583427655, backward:0.059349401834956204, data cost:0.37332101114693655 
2022-04-03 21:06:17,753: ============================================================
2022-04-03 21:06:17,753: Epoch 13/26 Batch 2400/7662 eta: 12:25:39.720273	Training Loss 2.5300 (2.3036)	Training Prec@1 99.805 (99.750)	Training Prec@5 100.000 (99.930)	
2022-04-03 21:06:17,754: ============================================================
2022-04-03 21:07:02,179: time cost, forward:0.011005387777517013, backward:0.05935771143784662, data cost:0.373304733709127 
2022-04-03 21:07:02,180: ============================================================
2022-04-03 21:07:02,180: Epoch 13/26 Batch 2500/7662 eta: 12:55:45.183135	Training Loss 2.5296 (2.3080)	Training Prec@1 99.414 (99.748)	Training Prec@5 100.000 (99.930)	
2022-04-03 21:07:02,180: ============================================================
2022-04-03 21:07:45,166: time cost, forward:0.011018112009422007, backward:0.059320656323992506, data cost:0.3727979589398433 
2022-04-03 21:07:45,166: ============================================================
2022-04-03 21:07:45,167: Epoch 13/26 Batch 2600/7662 eta: 12:29:53.702418	Training Loss 2.4260 (2.3125)	Training Prec@1 99.805 (99.747)	Training Prec@5 100.000 (99.929)	
2022-04-03 21:07:45,167: ============================================================
2022-04-03 21:08:28,682: time cost, forward:0.010996954579757912, backward:0.05934823703306522, data cost:0.37246389254767526 
2022-04-03 21:08:28,682: ============================================================
2022-04-03 21:08:28,682: Epoch 13/26 Batch 2700/7662 eta: 12:38:23.979809	Training Loss 2.3995 (2.3173)	Training Prec@1 99.219 (99.743)	Training Prec@5 99.609 (99.928)	
2022-04-03 21:08:28,683: ============================================================
2022-04-03 21:09:13,266: time cost, forward:0.01096717831746899, backward:0.05937227533305701, data cost:0.3725533971789906 
2022-04-03 21:09:13,267: ============================================================
2022-04-03 21:09:13,267: Epoch 13/26 Batch 2800/7662 eta: 12:56:17.124600	Training Loss 2.2311 (2.3213)	Training Prec@1 99.805 (99.741)	Training Prec@5 100.000 (99.927)	
2022-04-03 21:09:13,267: ============================================================
2022-04-03 21:09:58,132: time cost, forward:0.010962487500714779, backward:0.05936194708035625, data cost:0.37274871879135507 
2022-04-03 21:09:58,132: ============================================================
2022-04-03 21:09:58,132: Epoch 13/26 Batch 2900/7662 eta: 13:00:25.666700	Training Loss 2.4440 (2.3262)	Training Prec@1 99.805 (99.738)	Training Prec@5 100.000 (99.926)	
2022-04-03 21:09:58,133: ============================================================
2022-04-03 21:10:42,071: time cost, forward:0.010972570124845897, backward:0.05932684412158382, data cost:0.3726490365938172 
2022-04-03 21:10:42,072: ============================================================
2022-04-03 21:10:42,072: Epoch 13/26 Batch 3000/7662 eta: 12:43:35.173936	Training Loss 2.6079 (2.3306)	Training Prec@1 99.219 (99.736)	Training Prec@5 99.609 (99.926)	
2022-04-03 21:10:42,072: ============================================================
2022-04-03 21:11:24,525: time cost, forward:0.010979837123406784, backward:0.059309687142065935, data cost:0.37204625076461356 
2022-04-03 21:11:24,525: ============================================================
2022-04-03 21:11:24,525: Epoch 13/26 Batch 3100/7662 eta: 12:17:03.236937	Training Loss 2.5304 (2.3345)	Training Prec@1 99.805 (99.735)	Training Prec@5 100.000 (99.926)	
2022-04-03 21:11:24,525: ============================================================
2022-04-03 21:12:07,287: time cost, forward:0.011045005925933656, backward:0.05923404303071051, data cost:0.37157931473896855 
2022-04-03 21:12:07,287: ============================================================
2022-04-03 21:12:07,288: Epoch 13/26 Batch 3200/7662 eta: 12:21:42.442408	Training Loss 2.3082 (2.3381)	Training Prec@1 99.805 (99.732)	Training Prec@5 100.000 (99.925)	
2022-04-03 21:12:07,288: ============================================================
2022-04-03 21:12:49,222: time cost, forward:0.011061973302933114, backward:0.05920277605926893, data cost:0.37088383541355785 
2022-04-03 21:12:49,222: ============================================================
2022-04-03 21:12:49,222: Epoch 13/26 Batch 3300/7662 eta: 12:06:39.125190	Training Loss 2.7837 (2.3421)	Training Prec@1 99.414 (99.730)	Training Prec@5 99.805 (99.924)	
2022-04-03 21:12:49,223: ============================================================
2022-04-03 21:13:32,742: time cost, forward:0.011073893117497829, backward:0.05919669206859996, data cost:0.37067215138935067 
2022-04-03 21:13:32,742: ============================================================
2022-04-03 21:13:32,742: Epoch 13/26 Batch 3400/7662 eta: 12:33:23.801162	Training Loss 2.5090 (2.3462)	Training Prec@1 99.219 (99.727)	Training Prec@5 99.805 (99.923)	
2022-04-03 21:13:32,743: ============================================================
2022-04-03 21:14:17,421: time cost, forward:0.011073046529180631, backward:0.059200800770042486, data cost:0.3708364687568292 
2022-04-03 21:14:17,421: ============================================================
2022-04-03 21:14:17,422: Epoch 13/26 Batch 3500/7662 eta: 12:52:43.157000	Training Loss 2.5070 (2.3501)	Training Prec@1 99.805 (99.725)	Training Prec@5 100.000 (99.922)	
2022-04-03 21:14:17,422: ============================================================
2022-04-03 21:15:02,082: time cost, forward:0.01106628248114558, backward:0.05920106624689126, data cost:0.37097698551113323 
2022-04-03 21:15:02,083: ============================================================
2022-04-03 21:15:02,083: Epoch 13/26 Batch 3600/7662 eta: 12:51:39.699601	Training Loss 2.5574 (2.3537)	Training Prec@1 99.609 (99.721)	Training Prec@5 100.000 (99.921)	
2022-04-03 21:15:02,083: ============================================================
2022-04-03 21:15:45,518: time cost, forward:0.011088580432921753, backward:0.059185102586006275, data cost:0.3707701312299998 
2022-04-03 21:15:45,518: ============================================================
2022-04-03 21:15:45,518: Epoch 13/26 Batch 3700/7662 eta: 12:29:45.732405	Training Loss 2.3670 (2.3570)	Training Prec@1 99.805 (99.720)	Training Prec@5 99.805 (99.921)	
2022-04-03 21:15:45,519: ============================================================
2022-04-03 21:16:29,711: time cost, forward:0.011101082771443857, backward:0.05918319785742422, data cost:0.37077020123997123 
2022-04-03 21:16:29,711: ============================================================
2022-04-03 21:16:29,711: Epoch 13/26 Batch 3800/7662 eta: 12:42:06.172675	Training Loss 2.5508 (2.3605)	Training Prec@1 99.219 (99.718)	Training Prec@5 99.805 (99.920)	
2022-04-03 21:16:29,712: ============================================================
2022-04-03 21:17:14,163: time cost, forward:0.011084172749525462, backward:0.05921351344012456, data cost:0.37085393662023436 
2022-04-03 21:17:14,164: ============================================================
2022-04-03 21:17:14,164: Epoch 13/26 Batch 3900/7662 eta: 12:45:50.156588	Training Loss 2.5460 (2.3636)	Training Prec@1 99.609 (99.716)	Training Prec@5 100.000 (99.920)	
2022-04-03 21:17:14,164: ============================================================
2022-04-03 21:17:58,971: time cost, forward:0.011085220741373088, backward:0.059222260127219, data cost:0.3709719519699833 
2022-04-03 21:17:58,971: ============================================================
2022-04-03 21:17:58,971: Epoch 13/26 Batch 4000/7662 eta: 12:51:12.053439	Training Loss 2.7261 (2.3670)	Training Prec@1 99.414 (99.714)	Training Prec@5 99.609 (99.919)	
2022-04-03 21:17:58,971: ============================================================
2022-04-03 21:18:43,857: time cost, forward:0.011101695961357762, backward:0.05920895095800999, data cost:0.3711504664005783 
2022-04-03 21:18:43,858: ============================================================
2022-04-03 21:18:43,858: Epoch 13/26 Batch 4100/7662 eta: 12:51:49.186492	Training Loss 2.3815 (2.3696)	Training Prec@1 100.000 (99.712)	Training Prec@5 100.000 (99.918)	
2022-04-03 21:18:43,858: ============================================================
2022-04-03 21:19:29,099: time cost, forward:0.01115118262029086, backward:0.05915440369515398, data cost:0.3713939419301472 
2022-04-03 21:19:29,100: ============================================================
2022-04-03 21:19:29,100: Epoch 13/26 Batch 4200/7662 eta: 12:57:10.593319	Training Loss 2.6570 (2.3723)	Training Prec@1 99.609 (99.709)	Training Prec@5 99.805 (99.917)	
2022-04-03 21:19:29,100: ============================================================
2022-04-03 21:20:12,835: time cost, forward:0.0111407878149884, backward:0.05916609440218102, data cost:0.37130083320140284 
2022-04-03 21:20:12,835: ============================================================
2022-04-03 21:20:12,835: Epoch 13/26 Batch 4300/7662 eta: 12:30:33.659962	Training Loss 2.5253 (2.3750)	Training Prec@1 99.219 (99.707)	Training Prec@5 100.000 (99.916)	
2022-04-03 21:20:12,835: ============================================================
2022-04-03 21:20:57,106: time cost, forward:0.011126758619231727, backward:0.05917081932610722, data cost:0.3713084512690193 
2022-04-03 21:20:57,107: ============================================================
2022-04-03 21:20:57,107: Epoch 13/26 Batch 4400/7662 eta: 12:39:01.973681	Training Loss 2.4125 (2.3776)	Training Prec@1 99.805 (99.707)	Training Prec@5 99.805 (99.916)	
2022-04-03 21:20:57,107: ============================================================
2022-04-03 21:21:41,822: time cost, forward:0.011222647147381085, backward:0.05906875341779578, data cost:0.37142600809687853 
2022-04-03 21:21:41,823: ============================================================
2022-04-03 21:21:41,823: Epoch 13/26 Batch 4500/7662 eta: 12:45:53.945022	Training Loss 2.5630 (2.3801)	Training Prec@1 100.000 (99.705)	Training Prec@5 100.000 (99.916)	
2022-04-03 21:21:41,823: ============================================================
2022-04-03 21:22:26,856: time cost, forward:0.011209041923511336, backward:0.05907567134756813, data cost:0.37161070529625034 
2022-04-03 21:22:26,857: ============================================================
2022-04-03 21:22:26,857: Epoch 13/26 Batch 4600/7662 eta: 12:50:36.038890	Training Loss 2.5573 (2.3830)	Training Prec@1 99.805 (99.703)	Training Prec@5 100.000 (99.916)	
2022-04-03 21:22:26,857: ============================================================
2022-04-03 21:23:11,499: time cost, forward:0.011187450407311925, backward:0.05909407846621692, data cost:0.371696684354923 
2022-04-03 21:23:11,499: ============================================================
2022-04-03 21:23:11,499: Epoch 13/26 Batch 4700/7662 eta: 12:43:09.119002	Training Loss 2.5102 (2.3855)	Training Prec@1 100.000 (99.701)	Training Prec@5 100.000 (99.915)	
2022-04-03 21:23:11,499: ============================================================
2022-04-03 21:23:56,345: time cost, forward:0.011242107094066991, backward:0.05903524695696695, data cost:0.3718102867589888 
2022-04-03 21:23:56,346: ============================================================
2022-04-03 21:23:56,346: Epoch 13/26 Batch 4800/7662 eta: 12:45:54.056345	Training Loss 2.5387 (2.3879)	Training Prec@1 99.609 (99.700)	Training Prec@5 100.000 (99.914)	
2022-04-03 21:23:56,346: ============================================================
2022-04-03 21:24:40,228: time cost, forward:0.011230339199018663, backward:0.059046433881536554, data cost:0.37173245857871046 
2022-04-03 21:24:40,228: ============================================================
2022-04-03 21:24:40,229: Epoch 13/26 Batch 4900/7662 eta: 12:28:42.138838	Training Loss 2.5000 (2.3904)	Training Prec@1 99.219 (99.698)	Training Prec@5 99.609 (99.914)	
2022-04-03 21:24:40,229: ============================================================
2022-04-03 21:25:24,416: time cost, forward:0.011204434337795293, backward:0.05906716635952618, data cost:0.37173472487657017 
2022-04-03 21:25:24,417: ============================================================
2022-04-03 21:25:24,417: Epoch 13/26 Batch 5000/7662 eta: 12:33:11.033364	Training Loss 2.4764 (2.3928)	Training Prec@1 99.219 (99.697)	Training Prec@5 99.609 (99.913)	
2022-04-03 21:25:24,417: ============================================================
2022-04-03 21:26:09,213: time cost, forward:0.01118182429941899, backward:0.05908289164228751, data cost:0.371854244996389 
2022-04-03 21:26:09,213: ============================================================
2022-04-03 21:26:09,213: Epoch 13/26 Batch 5100/7662 eta: 12:42:47.824500	Training Loss 2.7475 (2.3952)	Training Prec@1 99.023 (99.694)	Training Prec@5 100.000 (99.912)	
2022-04-03 21:26:09,213: ============================================================
2022-04-03 21:26:53,720: time cost, forward:0.011160391572576964, backward:0.059099981889836624, data cost:0.37190610978621247 
2022-04-03 21:26:53,720: ============================================================
2022-04-03 21:26:53,720: Epoch 13/26 Batch 5200/7662 eta: 12:37:07.892872	Training Loss 2.5273 (2.3978)	Training Prec@1 99.805 (99.691)	Training Prec@5 100.000 (99.911)	
2022-04-03 21:26:53,720: ============================================================
2022-04-03 21:27:38,569: time cost, forward:0.011139173736255514, backward:0.059118921249671844, data cost:0.3720148727339964 
2022-04-03 21:27:38,569: ============================================================
2022-04-03 21:27:38,569: Epoch 13/26 Batch 5300/7662 eta: 12:42:12.274681	Training Loss 2.7761 (2.3997)	Training Prec@1 99.023 (99.690)	Training Prec@5 100.000 (99.911)	
2022-04-03 21:27:38,570: ============================================================
2022-04-03 21:28:23,092: time cost, forward:0.011127167398078638, backward:0.059128044357695475, data cost:0.37206542405801296 
2022-04-03 21:28:23,093: ============================================================
2022-04-03 21:28:23,093: Epoch 13/26 Batch 5400/7662 eta: 12:35:55.566703	Training Loss 2.5279 (2.4017)	Training Prec@1 99.609 (99.689)	Training Prec@5 100.000 (99.911)	
2022-04-03 21:28:23,093: ============================================================
2022-04-03 21:29:07,265: time cost, forward:0.011107922814329834, backward:0.05914611347286587, data cost:0.37206098538655585 
2022-04-03 21:29:07,266: ============================================================
2022-04-03 21:29:07,266: Epoch 13/26 Batch 5500/7662 eta: 12:29:14.448857	Training Loss 2.6482 (2.4038)	Training Prec@1 99.805 (99.688)	Training Prec@5 99.805 (99.910)	
2022-04-03 21:29:07,266: ============================================================
2022-04-03 21:29:49,429: time cost, forward:0.011089520063500762, backward:0.059165974816460125, data cost:0.3716694193879373 
2022-04-03 21:29:49,429: ============================================================
2022-04-03 21:29:49,429: Epoch 13/26 Batch 5600/7662 eta: 11:54:27.117745	Training Loss 2.5693 (2.4058)	Training Prec@1 99.805 (99.686)	Training Prec@5 100.000 (99.910)	
2022-04-03 21:29:49,429: ============================================================
2022-04-03 21:30:33,623: time cost, forward:0.011070579619841902, backward:0.05918646766587629, data cost:0.3716546992582906 
2022-04-03 21:30:33,623: ============================================================
2022-04-03 21:30:33,623: Epoch 13/26 Batch 5700/7662 eta: 12:28:07.524703	Training Loss 2.6392 (2.4074)	Training Prec@1 99.609 (99.685)	Training Prec@5 99.805 (99.909)	
2022-04-03 21:30:33,624: ============================================================
2022-04-03 21:31:17,710: time cost, forward:0.011082568812481307, backward:0.059171468271307134, data cost:0.3716297358104866 
2022-04-03 21:31:17,710: ============================================================
2022-04-03 21:31:17,711: Epoch 13/26 Batch 5800/7662 eta: 12:25:34.931614	Training Loss 2.4707 (2.4092)	Training Prec@1 99.609 (99.683)	Training Prec@5 99.609 (99.909)	
2022-04-03 21:31:17,711: ============================================================
2022-04-03 21:32:01,774: time cost, forward:0.011067047667192147, backward:0.05918243788605849, data cost:0.3716108798576545 
2022-04-03 21:32:01,774: ============================================================
2022-04-03 21:32:01,775: Epoch 13/26 Batch 5900/7662 eta: 12:24:27.234841	Training Loss 2.4234 (2.4109)	Training Prec@1 99.805 (99.681)	Training Prec@5 100.000 (99.908)	
2022-04-03 21:32:01,775: ============================================================
2022-04-03 21:32:45,944: time cost, forward:0.0110543727238867, backward:0.05918295758230366, data cost:0.371613000348958 
2022-04-03 21:32:45,945: ============================================================
2022-04-03 21:32:45,946: Epoch 13/26 Batch 6000/7662 eta: 12:25:31.302312	Training Loss 2.2999 (2.4126)	Training Prec@1 99.805 (99.680)	Training Prec@5 99.805 (99.907)	
2022-04-03 21:32:45,946: ============================================================
2022-04-03 21:33:30,141: time cost, forward:0.011052324608088047, backward:0.05917903532218026, data cost:0.37159504275142924 
2022-04-03 21:33:30,142: ============================================================
2022-04-03 21:33:30,142: Epoch 13/26 Batch 6100/7662 eta: 12:25:13.058496	Training Loss 2.5738 (2.4142)	Training Prec@1 99.219 (99.678)	Training Prec@5 99.805 (99.907)	
2022-04-03 21:33:30,142: ============================================================
2022-04-03 21:34:13,368: time cost, forward:0.011037087398183829, backward:0.05919084058190223, data cost:0.37145873230683224 
2022-04-03 21:34:13,369: ============================================================
2022-04-03 21:34:13,369: Epoch 13/26 Batch 6200/7662 eta: 12:08:09.212774	Training Loss 2.6934 (2.4161)	Training Prec@1 99.219 (99.676)	Training Prec@5 99.414 (99.907)	
2022-04-03 21:34:13,369: ============================================================
2022-04-03 21:34:56,448: time cost, forward:0.01102628403569918, backward:0.05919419222170255, data cost:0.371279763501681 
2022-04-03 21:34:56,448: ============================================================
2022-04-03 21:34:56,448: Epoch 13/26 Batch 6300/7662 eta: 12:04:56.778545	Training Loss 2.5316 (2.4180)	Training Prec@1 99.414 (99.675)	Training Prec@5 100.000 (99.906)	
2022-04-03 21:34:56,448: ============================================================
2022-04-03 21:35:40,283: time cost, forward:0.01101526936100207, backward:0.05920612105989404, data cost:0.3712174421475257 
2022-04-03 21:35:40,284: ============================================================
2022-04-03 21:35:40,284: Epoch 13/26 Batch 6400/7662 eta: 12:16:56.402360	Training Loss 2.5375 (2.4196)	Training Prec@1 99.805 (99.673)	Training Prec@5 99.805 (99.906)	
2022-04-03 21:35:40,284: ============================================================
2022-04-03 21:36:22,843: time cost, forward:0.011001625910669607, backward:0.05921886880354875, data cost:0.3709652827765175 
2022-04-03 21:36:22,843: ============================================================
2022-04-03 21:36:22,843: Epoch 13/26 Batch 6500/7662 eta: 11:54:46.920198	Training Loss 2.4580 (2.4211)	Training Prec@1 100.000 (99.672)	Training Prec@5 100.000 (99.905)	
2022-04-03 21:36:22,844: ============================================================
2022-04-03 21:37:06,544: time cost, forward:0.011001971006790857, backward:0.059214570085502675, data cost:0.37089566433677207 
2022-04-03 21:37:06,545: ============================================================
2022-04-03 21:37:06,545: Epoch 13/26 Batch 6600/7662 eta: 12:13:13.854093	Training Loss 2.5959 (2.4227)	Training Prec@1 99.414 (99.670)	Training Prec@5 100.000 (99.905)	
2022-04-03 21:37:06,545: ============================================================
2022-04-03 21:37:50,353: time cost, forward:0.01098953996029945, backward:0.05922337734338009, data cost:0.3708491752460512 
2022-04-03 21:37:50,353: ============================================================
2022-04-03 21:37:50,354: Epoch 13/26 Batch 6700/7662 eta: 12:14:17.943534	Training Loss 2.3352 (2.4243)	Training Prec@1 100.000 (99.669)	Training Prec@5 100.000 (99.904)	
2022-04-03 21:37:50,354: ============================================================
2022-04-03 21:38:34,160: time cost, forward:0.010984214934764109, backward:0.059226530933225836, data cost:0.3708030144104731 
2022-04-03 21:38:34,160: ============================================================
2022-04-03 21:38:34,161: Epoch 13/26 Batch 6800/7662 eta: 12:13:32.506970	Training Loss 2.3214 (2.4256)	Training Prec@1 99.609 (99.668)	Training Prec@5 100.000 (99.904)	
2022-04-03 21:38:34,161: ============================================================
2022-04-03 21:39:18,647: time cost, forward:0.010981142287635167, backward:0.05922606323469996, data cost:0.37084321917649854 
2022-04-03 21:39:18,648: ============================================================
2022-04-03 21:39:18,648: Epoch 13/26 Batch 6900/7662 eta: 12:24:11.304426	Training Loss 2.3011 (2.4270)	Training Prec@1 99.609 (99.666)	Training Prec@5 100.000 (99.903)	
2022-04-03 21:39:18,648: ============================================================
2022-04-03 21:40:01,881: time cost, forward:0.010973168366431236, backward:0.059234841344424326, data cost:0.3707239594795411 
2022-04-03 21:40:01,882: ============================================================
2022-04-03 21:40:01,882: Epoch 13/26 Batch 7000/7662 eta: 12:02:30.346283	Training Loss 2.5416 (2.4282)	Training Prec@1 99.414 (99.665)	Training Prec@5 100.000 (99.903)	
2022-04-03 21:40:01,882: ============================================================
2022-04-03 21:40:43,857: time cost, forward:0.010966736693704005, backward:0.05923438421486633, data cost:0.37042357901785306 
2022-04-03 21:40:43,857: ============================================================
2022-04-03 21:40:43,857: Epoch 13/26 Batch 7100/7662 eta: 11:40:46.459479	Training Loss 2.5737 (2.4295)	Training Prec@1 99.414 (99.664)	Training Prec@5 99.805 (99.902)	
2022-04-03 21:40:43,858: ============================================================
2022-04-03 21:41:26,836: time cost, forward:0.010958582415384027, backward:0.05924322420001808, data cost:0.3702623570589642 
2022-04-03 21:41:26,836: ============================================================
2022-04-03 21:41:26,837: Epoch 13/26 Batch 7200/7662 eta: 11:56:48.756284	Training Loss 2.4639 (2.4308)	Training Prec@1 99.805 (99.663)	Training Prec@5 100.000 (99.902)	
2022-04-03 21:41:26,837: ============================================================
2022-04-03 21:42:10,401: time cost, forward:0.010957479182947726, backward:0.05924281807431849, data cost:0.3701929788031567 
2022-04-03 21:42:10,401: ============================================================
2022-04-03 21:42:10,402: Epoch 13/26 Batch 7300/7662 eta: 12:05:51.635054	Training Loss 2.5327 (2.4318)	Training Prec@1 99.414 (99.662)	Training Prec@5 100.000 (99.902)	
2022-04-03 21:42:10,402: ============================================================
2022-04-03 21:42:53,899: time cost, forward:0.01095014063792223, backward:0.05924495537066109, data cost:0.37011339706671464 
2022-04-03 21:42:53,900: ============================================================
2022-04-03 21:42:53,900: Epoch 13/26 Batch 7400/7662 eta: 12:04:01.085387	Training Loss 2.6682 (2.4333)	Training Prec@1 98.828 (99.660)	Training Prec@5 99.609 (99.902)	
2022-04-03 21:42:53,900: ============================================================
2022-04-03 21:43:36,569: time cost, forward:0.010948499849214921, backward:0.059245646357584, data cost:0.3699306430363913 
2022-04-03 21:43:36,570: ============================================================
2022-04-03 21:43:36,570: Epoch 13/26 Batch 7500/7662 eta: 11:49:31.591510	Training Loss 2.4802 (2.4344)	Training Prec@1 99.023 (99.659)	Training Prec@5 99.414 (99.901)	
2022-04-03 21:43:36,570: ============================================================
2022-04-03 21:44:19,041: time cost, forward:0.0109399538759276, backward:0.059250996824722096, data cost:0.36972505633086494 
2022-04-03 21:44:19,041: ============================================================
2022-04-03 21:44:19,041: Epoch 13/26 Batch 7600/7662 eta: 11:45:30.641942	Training Loss 2.6003 (2.4358)	Training Prec@1 99.805 (99.658)	Training Prec@5 100.000 (99.901)	
2022-04-03 21:44:19,041: ============================================================
2022-04-03 21:44:48,645: Epoch: 13/26 eta: 11:45:03.885072	Training Loss 2.5520 (2.4366)	Training Prec@1 100.000 (99.657)	Training Prec@5 100.000 (99.900)
2022-04-03 21:44:48,645: ============================================================
2022-04-03 21:45:35,338: time cost, forward:0.010603423070425938, backward:0.057778158573189166, data cost:0.3981804775469231 
2022-04-03 21:45:35,338: ============================================================
2022-04-03 21:45:35,339: Epoch 14/26 Batch 100/7662 eta: 12:52:19.603919	Training Loss 2.2226 (2.1049)	Training Prec@1 99.609 (99.832)	Training Prec@5 100.000 (99.945)	
2022-04-03 21:45:35,339: ============================================================
2022-04-03 21:46:15,874: time cost, forward:0.010537316451719658, backward:0.05822594441361164, data cost:0.36678420598782485 
2022-04-03 21:46:15,875: ============================================================
2022-04-03 21:46:15,875: Epoch 14/26 Batch 200/7662 eta: 11:11:35.978936	Training Loss 2.0033 (2.1110)	Training Prec@1 99.609 (99.814)	Training Prec@5 100.000 (99.949)	
2022-04-03 21:46:15,875: ============================================================
2022-04-03 21:46:55,878: time cost, forward:0.010507423343467074, backward:0.05841867421383044, data cost:0.35461090559943464 
2022-04-03 21:46:55,878: ============================================================
2022-04-03 21:46:55,878: Epoch 14/26 Batch 300/7662 eta: 11:02:06.264839	Training Loss 2.3363 (2.1246)	Training Prec@1 99.414 (99.800)	Training Prec@5 99.805 (99.947)	
2022-04-03 21:46:55,879: ============================================================
2022-04-03 21:47:38,024: time cost, forward:0.010543988163309885, backward:0.05859021017127169, data cost:0.3534896618740302 
2022-04-03 21:47:38,025: ============================================================
2022-04-03 21:47:38,025: Epoch 14/26 Batch 400/7662 eta: 11:36:52.315027	Training Loss 2.0607 (2.1323)	Training Prec@1 99.805 (99.803)	Training Prec@5 99.805 (99.946)	
2022-04-03 21:47:38,025: ============================================================
2022-04-03 21:48:21,239: time cost, forward:0.01060628508757016, backward:0.05858648659471042, data cost:0.35544034092125293 
2022-04-03 21:48:21,239: ============================================================
2022-04-03 21:48:21,240: Epoch 14/26 Batch 500/7662 eta: 11:53:48.680239	Training Loss 2.3142 (2.1399)	Training Prec@1 99.805 (99.798)	Training Prec@5 100.000 (99.945)	
2022-04-03 21:48:21,240: ============================================================
2022-04-03 21:49:03,058: time cost, forward:0.010618795337581475, backward:0.058631697958817265, data cost:0.35418882791904455 
2022-04-03 21:49:03,058: ============================================================
2022-04-03 21:49:03,058: Epoch 14/26 Batch 600/7662 eta: 11:30:03.648817	Training Loss 2.2748 (2.1518)	Training Prec@1 99.609 (99.802)	Training Prec@5 100.000 (99.947)	
2022-04-03 21:49:03,059: ============================================================
2022-04-03 21:49:46,771: time cost, forward:0.010584445811477683, backward:0.058728486512693044, data cost:0.35597361413194384 
2022-04-03 21:49:46,771: ============================================================
2022-04-03 21:49:46,771: Epoch 14/26 Batch 700/7662 eta: 12:00:35.119342	Training Loss 2.4219 (2.1611)	Training Prec@1 99.609 (99.800)	Training Prec@5 99.805 (99.943)	
2022-04-03 21:49:46,772: ============================================================
2022-04-03 21:50:31,611: time cost, forward:0.010547820259543025, backward:0.05878472238667169, data cost:0.3587988885084589 
2022-04-03 21:50:31,611: ============================================================
2022-04-03 21:50:31,612: Epoch 14/26 Batch 800/7662 eta: 12:18:25.238223	Training Loss 2.0948 (2.1691)	Training Prec@1 99.805 (99.796)	Training Prec@5 100.000 (99.942)	
2022-04-03 21:50:31,612: ============================================================
2022-04-03 21:51:15,499: time cost, forward:0.010515573690412307, backward:0.058840804423585746, data cost:0.35984586051626916 
2022-04-03 21:51:15,499: ============================================================
2022-04-03 21:51:15,499: Epoch 14/26 Batch 900/7662 eta: 12:02:00.308132	Training Loss 2.2263 (2.1798)	Training Prec@1 99.609 (99.793)	Training Prec@5 99.805 (99.942)	
2022-04-03 21:51:15,499: ============================================================
2022-04-03 21:51:59,782: time cost, forward:0.010500668524741172, backward:0.05882419337023486, data cost:0.3612719952045857 
2022-04-03 21:51:59,782: ============================================================
2022-04-03 21:51:59,782: Epoch 14/26 Batch 1000/7662 eta: 12:07:45.865560	Training Loss 2.3119 (2.1883)	Training Prec@1 99.609 (99.795)	Training Prec@5 100.000 (99.942)	
2022-04-03 21:51:59,782: ============================================================
2022-04-03 21:52:43,584: time cost, forward:0.010483009800030167, backward:0.05885806834296382, data cost:0.3618275049711163 
2022-04-03 21:52:43,584: ============================================================
2022-04-03 21:52:43,584: Epoch 14/26 Batch 1100/7662 eta: 11:59:08.299697	Training Loss 2.4178 (2.1980)	Training Prec@1 100.000 (99.791)	Training Prec@5 100.000 (99.940)	
2022-04-03 21:52:43,584: ============================================================
2022-04-03 21:53:27,132: time cost, forward:0.010489921752764246, backward:0.05885802536233452, data cost:0.36214584723624516 
2022-04-03 21:53:27,133: ============================================================
2022-04-03 21:53:27,133: Epoch 14/26 Batch 1200/7662 eta: 11:54:14.898446	Training Loss 2.1887 (2.2056)	Training Prec@1 100.000 (99.791)	Training Prec@5 100.000 (99.939)	
2022-04-03 21:53:27,133: ============================================================
2022-04-03 21:54:10,212: time cost, forward:0.010552738702141202, backward:0.05880316961169518, data cost:0.362049653036398 
2022-04-03 21:54:10,213: ============================================================
2022-04-03 21:54:10,213: Epoch 14/26 Batch 1300/7662 eta: 11:45:50.460050	Training Loss 2.2505 (2.2136)	Training Prec@1 99.414 (99.788)	Training Prec@5 100.000 (99.938)	
2022-04-03 21:54:10,213: ============================================================
2022-04-03 21:54:52,802: time cost, forward:0.0105845691307346, backward:0.05877887887388915, data cost:0.36157935222955667 
2022-04-03 21:54:52,803: ============================================================
2022-04-03 21:54:52,803: Epoch 14/26 Batch 1400/7662 eta: 11:37:06.658578	Training Loss 2.2723 (2.2211)	Training Prec@1 100.000 (99.784)	Training Prec@5 100.000 (99.938)	
2022-04-03 21:54:52,803: ============================================================
2022-04-03 21:55:36,692: time cost, forward:0.010598401533436028, backward:0.05877164254751581, data cost:0.3621162760647398 
2022-04-03 21:55:36,693: ============================================================
2022-04-03 21:55:36,693: Epoch 14/26 Batch 1500/7662 eta: 11:57:39.070010	Training Loss 2.1450 (2.2285)	Training Prec@1 100.000 (99.781)	Training Prec@5 100.000 (99.938)	
2022-04-03 21:55:36,693: ============================================================
2022-04-03 21:56:20,663: time cost, forward:0.010826401594208508, backward:0.05855277182535502, data cost:0.3625549693044981 
2022-04-03 21:56:20,663: ============================================================
2022-04-03 21:56:20,664: Epoch 14/26 Batch 1600/7662 eta: 11:58:14.246206	Training Loss 2.7132 (2.2362)	Training Prec@1 99.219 (99.778)	Training Prec@5 99.805 (99.938)	
2022-04-03 21:56:20,664: ============================================================
2022-04-03 21:57:04,200: time cost, forward:0.011353364195663695, backward:0.05805250095437035, data cost:0.36274132902584333 
2022-04-03 21:57:04,201: ============================================================
2022-04-03 21:57:04,201: Epoch 14/26 Batch 1700/7662 eta: 11:50:26.016332	Training Loss 2.2306 (2.2429)	Training Prec@1 100.000 (99.774)	Training Prec@5 100.000 (99.937)	
2022-04-03 21:57:04,201: ============================================================
2022-04-03 21:57:47,173: time cost, forward:0.011304704529368393, backward:0.0581025214510669, data cost:0.36255230487486334 
2022-04-03 21:57:47,173: ============================================================
2022-04-03 21:57:47,173: Epoch 14/26 Batch 1800/7662 eta: 11:40:30.166559	Training Loss 2.3368 (2.2480)	Training Prec@1 99.805 (99.772)	Training Prec@5 99.805 (99.937)	
2022-04-03 21:57:47,174: ============================================================
2022-04-03 21:58:31,574: time cost, forward:0.011265234422407507, backward:0.058140459658284765, data cost:0.3631529354810589 
2022-04-03 21:58:31,575: ============================================================
2022-04-03 21:58:31,575: Epoch 14/26 Batch 1900/7662 eta: 12:03:03.387802	Training Loss 2.4174 (2.2545)	Training Prec@1 100.000 (99.770)	Training Prec@5 100.000 (99.936)	
2022-04-03 21:58:31,575: ============================================================
2022-04-03 21:59:15,198: time cost, forward:0.011501970501051001, backward:0.05790911119183401, data cost:0.3632926617699185 
2022-04-03 21:59:15,199: ============================================================
2022-04-03 21:59:15,199: Epoch 14/26 Batch 2000/7662 eta: 11:49:40.141514	Training Loss 2.3609 (2.2602)	Training Prec@1 100.000 (99.767)	Training Prec@5 100.000 (99.935)	
2022-04-03 21:59:15,199: ============================================================
2022-04-03 21:59:58,818: time cost, forward:0.012106513340965006, backward:0.05728045130071326, data cost:0.363428515329311 
2022-04-03 21:59:58,818: ============================================================
2022-04-03 21:59:58,819: Epoch 14/26 Batch 2100/7662 eta: 11:48:52.223174	Training Loss 2.2642 (2.2657)	Training Prec@1 99.805 (99.764)	Training Prec@5 100.000 (99.935)	
2022-04-03 21:59:58,819: ============================================================
2022-04-03 22:00:42,046: time cost, forward:0.012046509409232702, backward:0.05736659081646831, data cost:0.36336456119282345 
2022-04-03 22:00:42,046: ============================================================
2022-04-03 22:00:42,047: Epoch 14/26 Batch 2200/7662 eta: 11:41:47.022875	Training Loss 2.2509 (2.2708)	Training Prec@1 100.000 (99.762)	Training Prec@5 100.000 (99.934)	
2022-04-03 22:00:42,047: ============================================================
2022-04-03 22:01:25,867: time cost, forward:0.01198990254777574, backward:0.05743709747145206, data cost:0.3635116787048048 
2022-04-03 22:01:25,867: ============================================================
2022-04-03 22:01:25,867: Epoch 14/26 Batch 2300/7662 eta: 11:50:40.462786	Training Loss 2.3280 (2.2759)	Training Prec@1 99.609 (99.759)	Training Prec@5 99.805 (99.932)	
2022-04-03 22:01:25,867: ============================================================
2022-04-03 22:02:09,789: time cost, forward:0.011974394246904788, backward:0.057464875395768084, data cost:0.36377292605627076 
2022-04-03 22:02:09,790: ============================================================
2022-04-03 22:02:09,790: Epoch 14/26 Batch 2400/7662 eta: 11:51:36.088868	Training Loss 2.5808 (2.2811)	Training Prec@1 99.023 (99.757)	Training Prec@5 99.609 (99.931)	
2022-04-03 22:02:09,790: ============================================================
2022-04-03 22:02:53,344: time cost, forward:0.011996843376938177, backward:0.057445818541192115, data cost:0.3638537532093526 
2022-04-03 22:02:53,345: ============================================================
2022-04-03 22:02:53,345: Epoch 14/26 Batch 2500/7662 eta: 11:44:54.957388	Training Loss 2.3201 (2.2857)	Training Prec@1 99.414 (99.756)	Training Prec@5 100.000 (99.931)	
2022-04-03 22:02:53,345: ============================================================
2022-04-03 22:03:35,411: time cost, forward:0.012088482450549077, backward:0.05736493624004321, data cost:0.36333002590958824 
2022-04-03 22:03:35,412: ============================================================
2022-04-03 22:03:35,412: Epoch 14/26 Batch 2600/7662 eta: 11:20:07.889967	Training Loss 2.5103 (2.2907)	Training Prec@1 99.414 (99.753)	Training Prec@5 99.609 (99.931)	
2022-04-03 22:03:35,412: ============================================================
2022-04-03 22:04:16,170: time cost, forward:0.012117693891521735, backward:0.05734818456083724, data cost:0.3623844688580892 
2022-04-03 22:04:16,170: ============================================================
2022-04-03 22:04:16,170: Epoch 14/26 Batch 2700/7662 eta: 10:58:17.836919	Training Loss 2.3458 (2.2954)	Training Prec@1 99.805 (99.751)	Training Prec@5 100.000 (99.931)	
2022-04-03 22:04:16,171: ============================================================
2022-04-03 22:04:59,033: time cost, forward:0.012095095899199621, backward:0.05737632340556939, data cost:0.36223943423441196 
2022-04-03 22:04:59,033: ============================================================
2022-04-03 22:04:59,033: Epoch 14/26 Batch 2800/7662 eta: 11:31:34.306086	Training Loss 2.4634 (2.2996)	Training Prec@1 100.000 (99.750)	Training Prec@5 100.000 (99.930)	
2022-04-03 22:04:59,034: ============================================================
2022-04-03 22:05:42,814: time cost, forward:0.012055579198973472, backward:0.05742035063434034, data cost:0.3624248312193182 
2022-04-03 22:05:42,815: ============================================================
2022-04-03 22:05:42,815: Epoch 14/26 Batch 2900/7662 eta: 11:45:39.982583	Training Loss 2.4834 (2.3044)	Training Prec@1 99.609 (99.747)	Training Prec@5 99.805 (99.929)	
2022-04-03 22:05:42,815: ============================================================
2022-04-03 22:06:26,243: time cost, forward:0.012307329152416651, backward:0.05718275394865814, data cost:0.36246752309656094 
2022-04-03 22:06:26,243: ============================================================
2022-04-03 22:06:26,244: Epoch 14/26 Batch 3000/7662 eta: 11:39:15.135619	Training Loss 2.2799 (2.3080)	Training Prec@1 99.414 (99.744)	Training Prec@5 99.609 (99.928)	
2022-04-03 22:06:26,244: ============================================================
2022-04-03 22:07:09,828: time cost, forward:0.01274300921767248, backward:0.05676526429384668, data cost:0.36256186344347374 
2022-04-03 22:07:09,828: ============================================================
2022-04-03 22:07:09,828: Epoch 14/26 Batch 3100/7662 eta: 11:41:02.131452	Training Loss 2.3544 (2.3118)	Training Prec@1 100.000 (99.742)	Training Prec@5 100.000 (99.928)	
2022-04-03 22:07:09,829: ============================================================
2022-04-03 22:07:51,274: time cost, forward:0.013150766142534815, backward:0.05637258244663822, data cost:0.3619822562206682 
2022-04-03 22:07:51,275: ============================================================
2022-04-03 22:07:51,275: Epoch 14/26 Batch 3200/7662 eta: 11:05:57.635088	Training Loss 2.3852 (2.3148)	Training Prec@1 100.000 (99.742)	Training Prec@5 100.000 (99.928)	
2022-04-03 22:07:51,275: ============================================================
2022-04-03 22:08:34,662: time cost, forward:0.013444874134162009, backward:0.05609453002696111, data cost:0.36202914138821696 
2022-04-03 22:08:34,663: ============================================================
2022-04-03 22:08:34,663: Epoch 14/26 Batch 3300/7662 eta: 11:36:25.597821	Training Loss 2.4057 (2.3191)	Training Prec@1 99.023 (99.739)	Training Prec@5 100.000 (99.928)	
2022-04-03 22:08:34,663: ============================================================
2022-04-03 22:09:18,130: time cost, forward:0.013346798457128576, backward:0.05619373353799324, data cost:0.362091986703045 
2022-04-03 22:09:18,130: ============================================================
2022-04-03 22:09:18,131: Epoch 14/26 Batch 3400/7662 eta: 11:36:58.937343	Training Loss 2.2498 (2.3228)	Training Prec@1 99.219 (99.737)	Training Prec@5 100.000 (99.927)	
2022-04-03 22:09:18,131: ============================================================
2022-04-03 22:10:01,484: time cost, forward:0.013261586129580201, backward:0.05628922545047922, data cost:0.3621229978928262 
2022-04-03 22:10:01,484: ============================================================
2022-04-03 22:10:01,484: Epoch 14/26 Batch 3500/7662 eta: 11:34:25.807485	Training Loss 2.3557 (2.3264)	Training Prec@1 99.805 (99.734)	Training Prec@5 100.000 (99.926)	
2022-04-03 22:10:01,484: ============================================================
2022-04-03 22:10:43,827: time cost, forward:0.01317909910600031, backward:0.05637665297064923, data cost:0.3618921645318975 
2022-04-03 22:10:43,828: ============================================================
2022-04-03 22:10:43,828: Epoch 14/26 Batch 3600/7662 eta: 11:17:32.980314	Training Loss 2.4034 (2.3299)	Training Prec@1 99.414 (99.732)	Training Prec@5 100.000 (99.925)	
2022-04-03 22:10:43,828: ============================================================
2022-04-03 22:11:25,334: time cost, forward:0.013104112575620728, backward:0.05645958763033869, data cost:0.36141973116746556 
2022-04-03 22:11:25,334: ============================================================
2022-04-03 22:11:25,335: Epoch 14/26 Batch 3700/7662 eta: 11:03:27.775699	Training Loss 2.3456 (2.3326)	Training Prec@1 99.805 (99.729)	Training Prec@5 100.000 (99.925)	
2022-04-03 22:11:25,335: ============================================================
2022-04-03 22:12:06,860: time cost, forward:0.013027366885200052, backward:0.056546568023308104, data cost:0.3609907557444059 
2022-04-03 22:12:06,860: ============================================================
2022-04-03 22:12:06,860: Epoch 14/26 Batch 3800/7662 eta: 11:03:04.357313	Training Loss 2.3228 (2.3358)	Training Prec@1 99.805 (99.727)	Training Prec@5 99.805 (99.924)	
2022-04-03 22:12:06,860: ============================================================
2022-04-03 22:12:48,748: time cost, forward:0.012955265553922768, backward:0.05662349983189894, data cost:0.36066160204472314 
2022-04-03 22:12:48,749: ============================================================
2022-04-03 22:12:48,749: Epoch 14/26 Batch 3900/7662 eta: 11:08:10.526732	Training Loss 2.5202 (2.3386)	Training Prec@1 99.805 (99.726)	Training Prec@5 99.805 (99.924)	
2022-04-03 22:12:48,749: ============================================================
2022-04-03 22:13:30,169: time cost, forward:0.01288328036036185, backward:0.05670306705838294, data cost:0.36021074738374914 
2022-04-03 22:13:30,169: ============================================================
2022-04-03 22:13:30,170: Epoch 14/26 Batch 4000/7662 eta: 11:00:01.021703	Training Loss 2.5123 (2.3416)	Training Prec@1 99.805 (99.725)	Training Prec@5 100.000 (99.923)	
2022-04-03 22:13:30,170: ============================================================
2022-04-03 22:14:12,591: time cost, forward:0.012823557091736451, backward:0.056769537268455045, data cost:0.3600796803406722 
2022-04-03 22:14:12,592: ============================================================
2022-04-03 22:14:12,592: Epoch 14/26 Batch 4100/7662 eta: 11:15:16.341983	Training Loss 2.6541 (2.3448)	Training Prec@1 99.609 (99.723)	Training Prec@5 99.805 (99.923)	
2022-04-03 22:14:12,592: ============================================================
2022-04-03 22:14:56,020: time cost, forward:0.012767053155792301, backward:0.05682977053857355, data cost:0.36017685369185876 
2022-04-03 22:14:56,020: ============================================================
2022-04-03 22:14:56,021: Epoch 14/26 Batch 4200/7662 eta: 11:30:33.862145	Training Loss 2.5417 (2.3478)	Training Prec@1 99.609 (99.722)	Training Prec@5 99.609 (99.922)	
2022-04-03 22:14:56,021: ============================================================
2022-04-03 22:15:39,771: time cost, forward:0.012709721766895792, backward:0.05689453540721254, data cost:0.3603312889901281 
2022-04-03 22:15:39,771: ============================================================
2022-04-03 22:15:39,771: Epoch 14/26 Batch 4300/7662 eta: 11:34:57.263324	Training Loss 2.5201 (2.3509)	Training Prec@1 99.609 (99.720)	Training Prec@5 99.609 (99.922)	
2022-04-03 22:15:39,771: ============================================================
2022-04-03 22:16:21,976: time cost, forward:0.012663670847919428, backward:0.05694755491112329, data cost:0.36013547657131745 
2022-04-03 22:16:21,977: ============================================================
2022-04-03 22:16:21,977: Epoch 14/26 Batch 4400/7662 eta: 11:09:43.144136	Training Loss 2.5003 (2.3540)	Training Prec@1 99.805 (99.718)	Training Prec@5 100.000 (99.921)	
2022-04-03 22:16:21,977: ============================================================
2022-04-03 22:17:04,573: time cost, forward:0.012610545765693836, backward:0.057010205116873984, data cost:0.36003629894727174 
2022-04-03 22:17:04,573: ============================================================
2022-04-03 22:17:04,574: Epoch 14/26 Batch 4500/7662 eta: 11:15:12.133680	Training Loss 2.2531 (2.3568)	Training Prec@1 99.609 (99.716)	Training Prec@5 100.000 (99.921)	
2022-04-03 22:17:04,574: ============================================================
2022-04-03 22:17:46,548: time cost, forward:0.012563045503367908, backward:0.05706032106839566, data cost:0.35981016139357885 
2022-04-03 22:17:46,549: ============================================================
2022-04-03 22:17:46,549: Epoch 14/26 Batch 4600/7662 eta: 11:04:39.573007	Training Loss 2.5488 (2.3590)	Training Prec@1 98.828 (99.714)	Training Prec@5 99.805 (99.920)	
2022-04-03 22:17:46,549: ============================================================
2022-04-03 22:18:29,084: time cost, forward:0.012515562700448986, backward:0.057115536493097224, data cost:0.35969555228282657 
2022-04-03 22:18:29,084: ============================================================
2022-04-03 22:18:29,084: Epoch 14/26 Batch 4700/7662 eta: 11:12:48.986690	Training Loss 2.6596 (2.3614)	Training Prec@1 99.609 (99.712)	Training Prec@5 99.805 (99.919)	
2022-04-03 22:18:29,084: ============================================================
2022-04-03 22:19:13,216: time cost, forward:0.012470493964489163, backward:0.05716662164478656, data cost:0.359927514017212 
2022-04-03 22:19:13,216: ============================================================
2022-04-03 22:19:13,217: Epoch 14/26 Batch 4800/7662 eta: 11:37:20.643380	Training Loss 2.4478 (2.3636)	Training Prec@1 99.414 (99.709)	Training Prec@5 100.000 (99.918)	
2022-04-03 22:19:13,217: ============================================================
2022-04-03 22:19:56,211: time cost, forward:0.012435009100408451, backward:0.057201311427200294, data cost:0.35993352980729537 
2022-04-03 22:19:56,211: ============================================================
2022-04-03 22:19:56,212: Epoch 14/26 Batch 4900/7662 eta: 11:18:39.133869	Training Loss 2.4016 (2.3657)	Training Prec@1 99.414 (99.707)	Training Prec@5 99.805 (99.917)	
2022-04-03 22:19:56,212: ============================================================
2022-04-03 22:20:39,969: time cost, forward:0.012390839049615344, backward:0.05725177633068423, data cost:0.3600780674876583 
2022-04-03 22:20:39,970: ============================================================
2022-04-03 22:20:39,970: Epoch 14/26 Batch 5000/7662 eta: 11:29:58.541709	Training Loss 2.5199 (2.3681)	Training Prec@1 99.414 (99.705)	Training Prec@5 100.000 (99.917)	
2022-04-03 22:20:39,970: ============================================================
2022-04-03 22:21:22,507: time cost, forward:0.01235425535382699, backward:0.05729464400770805, data cost:0.35997175515738394 
2022-04-03 22:21:22,507: ============================================================
2022-04-03 22:21:22,507: Epoch 14/26 Batch 5100/7662 eta: 11:10:00.938018	Training Loss 2.4659 (2.3703)	Training Prec@1 99.609 (99.704)	Training Prec@5 99.805 (99.916)	
2022-04-03 22:21:22,508: ============================================================
2022-04-03 22:22:05,935: time cost, forward:0.012322620741104387, backward:0.057326926385285554, data cost:0.3600473919839303 
2022-04-03 22:22:05,935: ============================================================
2022-04-03 22:22:05,936: Epoch 14/26 Batch 5200/7662 eta: 11:23:19.073735	Training Loss 2.3795 (2.3726)	Training Prec@1 100.000 (99.703)	Training Prec@5 100.000 (99.916)	
2022-04-03 22:22:05,936: ============================================================
2022-04-03 22:22:49,299: time cost, forward:0.012299265000342783, backward:0.057349989472256224, data cost:0.3601151354966647 
2022-04-03 22:22:49,299: ============================================================
2022-04-03 22:22:49,299: Epoch 14/26 Batch 5300/7662 eta: 11:21:35.222577	Training Loss 2.5283 (2.3751)	Training Prec@1 99.805 (99.701)	Training Prec@5 100.000 (99.915)	
2022-04-03 22:22:49,300: ============================================================
2022-04-03 22:23:33,555: time cost, forward:0.012264778314199375, backward:0.05739071078158282, data cost:0.36033079875445095 
2022-04-03 22:23:33,555: ============================================================
2022-04-03 22:23:33,556: Epoch 14/26 Batch 5400/7662 eta: 11:34:52.365408	Training Loss 2.5019 (2.3770)	Training Prec@1 99.414 (99.700)	Training Prec@5 100.000 (99.915)	
2022-04-03 22:23:33,556: ============================================================
2022-04-03 22:24:17,100: time cost, forward:0.012227627207396528, backward:0.0574342309615681, data cost:0.3604177097165166 
2022-04-03 22:24:17,100: ============================================================
2022-04-03 22:24:17,100: Epoch 14/26 Batch 5500/7662 eta: 11:22:58.636095	Training Loss 2.4891 (2.3788)	Training Prec@1 99.609 (99.698)	Training Prec@5 99.609 (99.914)	
2022-04-03 22:24:17,100: ============================================================
2022-04-03 22:24:59,535: time cost, forward:0.012191894374206293, backward:0.057469925639416025, data cost:0.36032281775286334 
2022-04-03 22:24:59,536: ============================================================
2022-04-03 22:24:59,536: Epoch 14/26 Batch 5600/7662 eta: 11:04:52.500426	Training Loss 2.5162 (2.3805)	Training Prec@1 100.000 (99.696)	Training Prec@5 100.000 (99.914)	
2022-04-03 22:24:59,536: ============================================================
2022-04-03 22:25:40,733: time cost, forward:0.012155535137847884, backward:0.0575126661587481, data cost:0.3599910714329701 
2022-04-03 22:25:40,733: ============================================================
2022-04-03 22:25:40,734: Epoch 14/26 Batch 5700/7662 eta: 10:44:47.404155	Training Loss 2.3646 (2.3824)	Training Prec@1 99.609 (99.694)	Training Prec@5 100.000 (99.913)	
2022-04-03 22:25:40,734: ============================================================
2022-04-03 22:26:21,005: time cost, forward:0.012121140083211685, backward:0.05754997414090465, data cost:0.3595065131929953 
2022-04-03 22:26:21,006: ============================================================
2022-04-03 22:26:21,006: Epoch 14/26 Batch 5800/7662 eta: 10:29:38.404877	Training Loss 2.6027 (2.3841)	Training Prec@1 99.805 (99.693)	Training Prec@5 100.000 (99.913)	
2022-04-03 22:26:21,006: ============================================================
2022-04-03 22:27:02,972: time cost, forward:0.01208910159608796, backward:0.057586787494285, data cost:0.35932825233678045 
2022-04-03 22:27:02,973: ============================================================
2022-04-03 22:27:02,973: Epoch 14/26 Batch 5900/7662 eta: 10:55:25.733630	Training Loss 2.4474 (2.3860)	Training Prec@1 100.000 (99.692)	Training Prec@5 100.000 (99.912)	
2022-04-03 22:27:02,973: ============================================================
2022-04-03 22:27:45,466: time cost, forward:0.012058790414844837, backward:0.05761625993686987, data cost:0.35925155879060594 
2022-04-03 22:27:45,466: ============================================================
2022-04-03 22:27:45,466: Epoch 14/26 Batch 6000/7662 eta: 11:02:56.942540	Training Loss 2.4352 (2.3877)	Training Prec@1 100.000 (99.689)	Training Prec@5 100.000 (99.912)	
2022-04-03 22:27:45,466: ============================================================
2022-04-03 22:28:27,557: time cost, forward:0.01203327328284308, backward:0.057646289499573365, data cost:0.3591103053792693 
2022-04-03 22:28:27,557: ============================================================
2022-04-03 22:28:27,558: Epoch 14/26 Batch 6100/7662 eta: 10:55:58.293843	Training Loss 2.5599 (2.3896)	Training Prec@1 99.414 (99.688)	Training Prec@5 100.000 (99.911)	
2022-04-03 22:28:27,558: ============================================================
2022-04-03 22:29:09,761: time cost, forward:0.012006199077206825, backward:0.05767930352047463, data cost:0.3589853462739844 
2022-04-03 22:29:09,761: ============================================================
2022-04-03 22:29:09,761: Epoch 14/26 Batch 6200/7662 eta: 10:57:01.153109	Training Loss 2.6552 (2.3909)	Training Prec@1 99.609 (99.687)	Training Prec@5 100.000 (99.911)	
2022-04-03 22:29:09,761: ============================================================
2022-04-03 22:29:53,306: time cost, forward:0.011980529360628106, backward:0.057703138627898484, data cost:0.3590892436183016 
2022-04-03 22:29:53,306: ============================================================
2022-04-03 22:29:53,307: Epoch 14/26 Batch 6300/7662 eta: 11:17:10.861351	Training Loss 2.4416 (2.3922)	Training Prec@1 99.609 (99.686)	Training Prec@5 100.000 (99.911)	
2022-04-03 22:29:53,307: ============================================================
2022-04-03 22:30:36,578: time cost, forward:0.011952276024190238, backward:0.05773508818862326, data cost:0.35913063314002386 
2022-04-03 22:30:36,578: ============================================================
2022-04-03 22:30:36,578: Epoch 14/26 Batch 6400/7662 eta: 11:12:12.373109	Training Loss 2.4356 (2.3940)	Training Prec@1 99.609 (99.685)	Training Prec@5 99.609 (99.910)	
2022-04-03 22:30:36,579: ============================================================
2022-04-03 22:31:20,377: time cost, forward:0.011929799417547675, backward:0.057761964806778136, data cost:0.3592605036503536 
2022-04-03 22:31:20,378: ============================================================
2022-04-03 22:31:20,378: Epoch 14/26 Batch 6500/7662 eta: 11:19:40.539417	Training Loss 2.5273 (2.3953)	Training Prec@1 99.023 (99.683)	Training Prec@5 99.805 (99.910)	
2022-04-03 22:31:20,378: ============================================================
2022-04-03 22:32:03,713: time cost, forward:0.011904133361548181, backward:0.057790908981117446, data cost:0.359316542105596 
2022-04-03 22:32:03,713: ============================================================
2022-04-03 22:32:03,714: Epoch 14/26 Batch 6600/7662 eta: 11:11:45.046935	Training Loss 2.4545 (2.3965)	Training Prec@1 99.609 (99.682)	Training Prec@5 100.000 (99.909)	
2022-04-03 22:32:03,714: ============================================================
2022-04-03 22:32:46,882: time cost, forward:0.011884337771310791, backward:0.05781040769634825, data cost:0.35934351048979907 
2022-04-03 22:32:46,882: ============================================================
2022-04-03 22:32:46,882: Epoch 14/26 Batch 6700/7662 eta: 11:08:26.783740	Training Loss 2.4701 (2.3977)	Training Prec@1 99.609 (99.680)	Training Prec@5 99.805 (99.909)	
2022-04-03 22:32:46,882: ============================================================
2022-04-03 22:33:30,236: time cost, forward:0.011860694897877923, backward:0.057839015806960895, data cost:0.3594053233085371 
2022-04-03 22:33:30,236: ============================================================
2022-04-03 22:33:30,236: Epoch 14/26 Batch 6800/7662 eta: 11:10:35.543325	Training Loss 2.3904 (2.3990)	Training Prec@1 100.000 (99.678)	Training Prec@5 100.000 (99.908)	
2022-04-03 22:33:30,236: ============================================================
2022-04-03 22:34:13,335: time cost, forward:0.011842056605622014, backward:0.057862808055023404, data cost:0.3594175817171963 
2022-04-03 22:34:13,335: ============================================================
2022-04-03 22:34:13,335: Epoch 14/26 Batch 6900/7662 eta: 11:05:55.924516	Training Loss 2.4476 (2.4000)	Training Prec@1 100.000 (99.678)	Training Prec@5 100.000 (99.908)	
2022-04-03 22:34:13,336: ============================================================
2022-04-03 22:34:55,558: time cost, forward:0.011816189210403645, backward:0.05788896839726668, data cost:0.3593174328990009 
2022-04-03 22:34:55,559: ============================================================
2022-04-03 22:34:55,559: Epoch 14/26 Batch 7000/7662 eta: 10:51:41.919086	Training Loss 2.3074 (2.4013)	Training Prec@1 99.219 (99.677)	Training Prec@5 99.805 (99.907)	
2022-04-03 22:34:55,559: ============================================================
2022-04-03 22:35:36,524: time cost, forward:0.011788931845409599, backward:0.057917612810372665, data cost:0.35903743616811556 
2022-04-03 22:35:36,525: ============================================================
2022-04-03 22:35:36,525: Epoch 14/26 Batch 7100/7662 eta: 10:31:36.171115	Training Loss 2.2951 (2.4024)	Training Prec@1 99.609 (99.675)	Training Prec@5 100.000 (99.907)	
2022-04-03 22:35:36,525: ============================================================
2022-04-03 22:36:17,073: time cost, forward:0.011763982929145484, backward:0.057945873989365404, data cost:0.35870013420474844 
2022-04-03 22:36:17,073: ============================================================
2022-04-03 22:36:17,074: Epoch 14/26 Batch 7200/7662 eta: 10:24:30.060255	Training Loss 2.3829 (2.4037)	Training Prec@1 99.609 (99.673)	Training Prec@5 99.609 (99.906)	
2022-04-03 22:36:17,074: ============================================================
2022-04-03 22:36:59,931: time cost, forward:0.011738183155731398, backward:0.05797159562357192, data cost:0.3586943692124891 
2022-04-03 22:36:59,931: ============================================================
2022-04-03 22:36:59,931: Epoch 14/26 Batch 7300/7662 eta: 10:59:20.595618	Training Loss 2.4918 (2.4052)	Training Prec@1 99.414 (99.672)	Training Prec@5 100.000 (99.906)	
2022-04-03 22:36:59,931: ============================================================
2022-04-03 22:37:44,071: time cost, forward:0.011722408093090136, backward:0.05798866124004266, data cost:0.3588634064139861 
2022-04-03 22:37:44,071: ============================================================
2022-04-03 22:37:44,071: Epoch 14/26 Batch 7400/7662 eta: 11:18:20.217822	Training Loss 2.4890 (2.4065)	Training Prec@1 99.805 (99.670)	Training Prec@5 100.000 (99.905)	
2022-04-03 22:37:44,072: ============================================================
2022-04-03 22:38:26,878: time cost, forward:0.011700219608240246, backward:0.058013713428188535, data cost:0.3588450222686857 
2022-04-03 22:38:26,879: ============================================================
2022-04-03 22:38:26,879: Epoch 14/26 Batch 7500/7662 eta: 10:57:08.719731	Training Loss 2.5150 (2.4077)	Training Prec@1 99.414 (99.669)	Training Prec@5 100.000 (99.905)	
2022-04-03 22:38:26,879: ============================================================
2022-04-03 22:39:09,600: time cost, forward:0.01167857422610932, backward:0.05803785237501696, data cost:0.35879171608403915 
2022-04-03 22:39:09,600: ============================================================
2022-04-03 22:39:09,601: Epoch 14/26 Batch 7600/7662 eta: 10:55:07.039149	Training Loss 2.5405 (2.4089)	Training Prec@1 99.414 (99.667)	Training Prec@5 99.805 (99.905)	
2022-04-03 22:39:09,601: ============================================================
2022-04-03 22:39:38,043: Epoch: 14/26 eta: 10:54:40.124421	Training Loss 2.4638 (2.4096)	Training Prec@1 99.414 (99.666)	Training Prec@5 99.805 (99.905)
2022-04-03 22:39:38,043: ============================================================
2022-04-03 22:40:21,541: time cost, forward:0.01044260130988227, backward:0.05877937692584413, data cost:0.3652776949333422 
2022-04-03 22:40:21,542: ============================================================
2022-04-03 22:40:21,542: Epoch 15/26 Batch 100/7662 eta: 11:03:14.142909	Training Loss 1.9411 (2.0562)	Training Prec@1 100.000 (99.818)	Training Prec@5 100.000 (99.935)	
2022-04-03 22:40:21,542: ============================================================
2022-04-03 22:41:01,563: time cost, forward:0.010241786439215118, backward:0.05890778800350937, data cost:0.34750177153390854 
2022-04-03 22:41:01,563: ============================================================
2022-04-03 22:41:01,564: Epoch 15/26 Batch 200/7662 eta: 10:11:57.678685	Training Loss 2.1313 (2.0785)	Training Prec@1 100.000 (99.807)	Training Prec@5 100.000 (99.934)	
2022-04-03 22:41:01,564: ============================================================
2022-04-03 22:41:43,075: time cost, forward:0.010231081857330425, backward:0.059252491762805545, data cost:0.3461793473731714 
2022-04-03 22:41:43,076: ============================================================
2022-04-03 22:41:43,076: Epoch 15/26 Batch 300/7662 eta: 10:34:03.817997	Training Loss 1.9732 (2.0869)	Training Prec@1 100.000 (99.813)	Training Prec@5 100.000 (99.941)	
2022-04-03 22:41:43,076: ============================================================
2022-04-03 22:42:25,058: time cost, forward:0.01022563183815557, backward:0.059528518738902005, data cost:0.347020143255554 
2022-04-03 22:42:25,059: ============================================================
2022-04-03 22:42:25,059: Epoch 15/26 Batch 400/7662 eta: 10:40:33.254884	Training Loss 2.1538 (2.0966)	Training Prec@1 100.000 (99.813)	Training Prec@5 100.000 (99.943)	
2022-04-03 22:42:25,059: ============================================================
2022-04-03 22:43:07,201: time cost, forward:0.01050712493713012, backward:0.05939979065874058, data cost:0.34767009308916297 
2022-04-03 22:43:07,201: ============================================================
2022-04-03 22:43:07,202: Epoch 15/26 Batch 500/7662 eta: 10:42:17.481583	Training Loss 2.2699 (2.1044)	Training Prec@1 100.000 (99.811)	Training Prec@5 100.000 (99.946)	
2022-04-03 22:43:07,202: ============================================================
2022-04-03 22:43:49,787: time cost, forward:0.010528675104819474, backward:0.059488982310478195, data cost:0.3488736689986291 
2022-04-03 22:43:49,788: ============================================================
2022-04-03 22:43:49,788: Epoch 15/26 Batch 600/7662 eta: 10:48:20.722861	Training Loss 1.8362 (2.1141)	Training Prec@1 99.805 (99.807)	Training Prec@5 100.000 (99.947)	
2022-04-03 22:43:49,788: ============================================================
2022-04-03 22:44:33,202: time cost, forward:0.010556191674970591, backward:0.05958032505706656, data cost:0.3508491284175322 
2022-04-03 22:44:33,202: ============================================================
2022-04-03 22:44:33,203: Epoch 15/26 Batch 700/7662 eta: 11:00:13.464368	Training Loss 2.1376 (2.1227)	Training Prec@1 99.805 (99.806)	Training Prec@5 100.000 (99.947)	
2022-04-03 22:44:33,203: ============================================================
2022-04-03 22:45:15,853: time cost, forward:0.01048764866195125, backward:0.059745518824036635, data cost:0.3513792381716312 
2022-04-03 22:45:15,854: ============================================================
2022-04-03 22:45:15,854: Epoch 15/26 Batch 800/7662 eta: 10:47:54.399349	Training Loss 2.1717 (2.1331)	Training Prec@1 100.000 (99.801)	Training Prec@5 100.000 (99.948)	
2022-04-03 22:45:15,854: ============================================================
2022-04-03 22:45:59,406: time cost, forward:0.010470555542043106, backward:0.0597790900008697, data cost:0.3528621263047877 
2022-04-03 22:45:59,407: ============================================================
2022-04-03 22:45:59,407: Epoch 15/26 Batch 900/7662 eta: 11:00:52.879403	Training Loss 2.2051 (2.1429)	Training Prec@1 99.805 (99.800)	Training Prec@5 99.805 (99.947)	
2022-04-03 22:45:59,407: ============================================================
2022-04-03 22:46:41,714: time cost, forward:0.010465082582888063, backward:0.059777485119091256, data cost:0.3527827472896786 
2022-04-03 22:46:41,714: ============================================================
2022-04-03 22:46:41,715: Epoch 15/26 Batch 1000/7662 eta: 10:41:16.889906	Training Loss 2.2090 (2.1504)	Training Prec@1 99.414 (99.799)	Training Prec@5 99.609 (99.947)	
2022-04-03 22:46:41,715: ============================================================
2022-04-03 22:47:23,762: time cost, forward:0.01063777599907442, backward:0.059629662672534, data cost:0.352404258596127 
2022-04-03 22:47:23,762: ============================================================
2022-04-03 22:47:23,763: Epoch 15/26 Batch 1100/7662 eta: 10:36:38.502006	Training Loss 2.2173 (2.1594)	Training Prec@1 99.805 (99.797)	Training Prec@5 100.000 (99.946)	
2022-04-03 22:47:23,763: ============================================================
2022-04-03 22:48:05,764: time cost, forward:0.010684553437475566, backward:0.05958369993189159, data cost:0.35221319202585355 
2022-04-03 22:48:05,764: ============================================================
2022-04-03 22:48:05,764: Epoch 15/26 Batch 1200/7662 eta: 10:35:14.329660	Training Loss 2.2517 (2.1677)	Training Prec@1 99.805 (99.796)	Training Prec@5 100.000 (99.944)	
2022-04-03 22:48:05,764: ============================================================
2022-04-03 22:48:47,564: time cost, forward:0.010657177052193188, backward:0.05958086752359274, data cost:0.35185849400462327 
2022-04-03 22:48:47,564: ============================================================
2022-04-03 22:48:47,565: Epoch 15/26 Batch 1300/7662 eta: 10:31:29.949257	Training Loss 2.3958 (2.1773)	Training Prec@1 99.805 (99.794)	Training Prec@5 99.805 (99.943)	
2022-04-03 22:48:47,565: ============================================================
2022-04-03 22:49:29,579: time cost, forward:0.010623889109166373, backward:0.05961365730443795, data cost:0.3516932128581769 
2022-04-03 22:49:29,580: ============================================================
2022-04-03 22:49:29,580: Epoch 15/26 Batch 1400/7662 eta: 10:34:03.007719	Training Loss 2.1284 (2.1865)	Training Prec@1 99.805 (99.794)	Training Prec@5 100.000 (99.944)	
2022-04-03 22:49:29,580: ============================================================
2022-04-03 22:50:12,266: time cost, forward:0.010620802223404063, backward:0.05961731292948554, data cost:0.35200348609761445 
2022-04-03 22:50:12,267: ============================================================
2022-04-03 22:50:12,267: Epoch 15/26 Batch 1500/7662 eta: 10:43:27.919710	Training Loss 2.1456 (2.1932)	Training Prec@1 99.805 (99.791)	Training Prec@5 99.805 (99.944)	
2022-04-03 22:50:12,267: ============================================================
2022-04-03 22:50:54,772: time cost, forward:0.01060425034905315, backward:0.05962191140972278, data cost:0.35208270682477444 
2022-04-03 22:50:54,772: ============================================================
2022-04-03 22:50:54,773: Epoch 15/26 Batch 1600/7662 eta: 10:40:01.802121	Training Loss 2.4357 (2.2007)	Training Prec@1 99.805 (99.789)	Training Prec@5 100.000 (99.944)	
2022-04-03 22:50:54,773: ============================================================
2022-04-03 22:51:35,581: time cost, forward:0.010595031595707221, backward:0.05964360635655287, data cost:0.35127152885809726 
2022-04-03 22:51:35,581: ============================================================
2022-04-03 22:51:35,581: Epoch 15/26 Batch 1700/7662 eta: 10:13:47.814619	Training Loss 2.2005 (2.2076)	Training Prec@1 100.000 (99.785)	Training Prec@5 100.000 (99.943)	
2022-04-03 22:51:35,581: ============================================================
2022-04-03 22:52:17,629: time cost, forward:0.010586698562851079, backward:0.059672204834544176, data cost:0.3511110542216786 
2022-04-03 22:52:17,629: ============================================================
2022-04-03 22:52:17,630: Epoch 15/26 Batch 1800/7662 eta: 10:31:44.498949	Training Loss 2.3671 (2.2136)	Training Prec@1 99.805 (99.782)	Training Prec@5 100.000 (99.943)	
2022-04-03 22:52:17,630: ============================================================
2022-04-03 22:53:00,055: time cost, forward:0.010556167021997983, backward:0.05971213037431585, data cost:0.3512622019439826 
2022-04-03 22:53:00,055: ============================================================
2022-04-03 22:53:00,056: Epoch 15/26 Batch 1900/7662 eta: 10:36:42.381030	Training Loss 2.3296 (2.2204)	Training Prec@1 99.805 (99.779)	Training Prec@5 99.805 (99.942)	
2022-04-03 22:53:00,056: ============================================================
2022-04-03 22:53:42,938: time cost, forward:0.010548961466702894, backward:0.05971372586718317, data cost:0.3515866725906364 
2022-04-03 22:53:42,939: ============================================================
2022-04-03 22:53:42,939: Epoch 15/26 Batch 2000/7662 eta: 10:42:51.652087	Training Loss 2.4507 (2.2264)	Training Prec@1 99.023 (99.776)	Training Prec@5 99.805 (99.941)	
2022-04-03 22:53:42,939: ============================================================
2022-04-03 22:54:24,776: time cost, forward:0.010528500958134186, backward:0.05971553701625204, data cost:0.35144179681757054 
2022-04-03 22:54:24,776: ============================================================
2022-04-03 22:54:24,776: Epoch 15/26 Batch 2100/7662 eta: 10:26:28.718385	Training Loss 2.2954 (2.2312)	Training Prec@1 100.000 (99.775)	Training Prec@5 100.000 (99.940)	
2022-04-03 22:54:24,777: ============================================================
2022-04-03 22:55:07,106: time cost, forward:0.010536006495539521, backward:0.059691812299283435, data cost:0.35149707952484643 
2022-04-03 22:55:07,106: ============================================================
2022-04-03 22:55:07,107: Epoch 15/26 Batch 2200/7662 eta: 10:33:09.264697	Training Loss 2.4498 (2.2358)	Training Prec@1 99.805 (99.772)	Training Prec@5 100.000 (99.939)	
2022-04-03 22:55:07,107: ============================================================
2022-04-03 22:55:49,589: time cost, forward:0.010517782105109442, backward:0.059687804325397456, data cost:0.35161721462682827 
2022-04-03 22:55:49,589: ============================================================
2022-04-03 22:55:49,589: Epoch 15/26 Batch 2300/7662 eta: 10:34:43.579110	Training Loss 2.4282 (2.2419)	Training Prec@1 100.000 (99.770)	Training Prec@5 100.000 (99.938)	
2022-04-03 22:55:49,589: ============================================================
2022-04-03 22:56:32,026: time cost, forward:0.010504259969751852, backward:0.05970971382573626, data cost:0.3517132736633797 
2022-04-03 22:56:32,027: ============================================================
2022-04-03 22:56:32,027: Epoch 15/26 Batch 2400/7662 eta: 10:33:20.773166	Training Loss 2.3484 (2.2471)	Training Prec@1 99.609 (99.767)	Training Prec@5 99.805 (99.938)	
2022-04-03 22:56:32,027: ============================================================
2022-04-03 22:57:13,001: time cost, forward:0.010495527404076865, backward:0.05971336679584553, data cost:0.35120624768920017 
2022-04-03 22:57:13,001: ============================================================
2022-04-03 22:57:13,001: Epoch 15/26 Batch 2500/7662 eta: 10:10:49.632729	Training Loss 2.3923 (2.2523)	Training Prec@1 100.000 (99.766)	Training Prec@5 100.000 (99.937)	
2022-04-03 22:57:13,002: ============================================================
2022-04-03 22:57:55,796: time cost, forward:0.010620816481393226, backward:0.05957615214983011, data cost:0.35143947922389934 
2022-04-03 22:57:55,797: ============================================================
2022-04-03 22:57:55,797: Epoch 15/26 Batch 2600/7662 eta: 10:37:15.586683	Training Loss 2.2352 (2.2567)	Training Prec@1 99.805 (99.764)	Training Prec@5 100.000 (99.935)	
2022-04-03 22:57:55,797: ============================================================
2022-04-03 22:58:38,630: time cost, forward:0.010618562034078332, backward:0.05958951628177243, data cost:0.35166098277362995 
2022-04-03 22:58:38,630: ============================================================
2022-04-03 22:58:38,630: Epoch 15/26 Batch 2700/7662 eta: 10:37:06.720183	Training Loss 2.5240 (2.2618)	Training Prec@1 99.609 (99.762)	Training Prec@5 99.805 (99.935)	
2022-04-03 22:58:38,631: ============================================================
2022-04-03 22:59:21,416: time cost, forward:0.010588045757385015, backward:0.059605693510490984, data cost:0.3518826441919859 
2022-04-03 22:59:21,417: ============================================================
2022-04-03 22:59:21,417: Epoch 15/26 Batch 2800/7662 eta: 10:35:42.186296	Training Loss 2.3968 (2.2667)	Training Prec@1 99.609 (99.758)	Training Prec@5 100.000 (99.934)	
2022-04-03 22:59:21,418: ============================================================
2022-04-03 23:00:01,299: time cost, forward:0.010593765396297122, backward:0.059606807402143316, data cost:0.3510567566245619 
2022-04-03 23:00:01,300: ============================================================
2022-04-03 23:00:01,300: Epoch 15/26 Batch 2900/7662 eta: 9:51:53.979880	Training Loss 2.2947 (2.2712)	Training Prec@1 99.805 (99.756)	Training Prec@5 99.805 (99.933)	
2022-04-03 23:00:01,300: ============================================================
2022-04-03 23:00:44,168: time cost, forward:0.010583807286042775, backward:0.05960332786850072, data cost:0.3512840081787618 
2022-04-03 23:00:44,168: ============================================================
2022-04-03 23:00:44,168: Epoch 15/26 Batch 3000/7662 eta: 10:35:29.151932	Training Loss 2.4244 (2.2754)	Training Prec@1 100.000 (99.754)	Training Prec@5 100.000 (99.933)	
2022-04-03 23:00:44,169: ============================================================
2022-04-03 23:01:27,196: time cost, forward:0.010622415591840323, backward:0.05955962166935446, data cost:0.351558345177359 
2022-04-03 23:01:27,196: ============================================================
2022-04-03 23:01:27,196: Epoch 15/26 Batch 3100/7662 eta: 10:37:08.092408	Training Loss 2.4475 (2.2796)	Training Prec@1 99.805 (99.751)	Training Prec@5 100.000 (99.931)	
2022-04-03 23:01:27,197: ============================================================
2022-04-03 23:02:08,300: time cost, forward:0.010600946142584803, backward:0.05958652377091336, data cost:0.35119031086009755 
2022-04-03 23:02:08,301: ============================================================
2022-04-03 23:02:08,301: Epoch 15/26 Batch 3200/7662 eta: 10:07:58.367998	Training Loss 2.2840 (2.2831)	Training Prec@1 99.805 (99.748)	Training Prec@5 100.000 (99.931)	
2022-04-03 23:02:08,301: ============================================================
2022-04-03 23:02:49,574: time cost, forward:0.010669038237207187, backward:0.059510478398119834, data cost:0.35092142554043493 
2022-04-03 23:02:49,574: ============================================================
2022-04-03 23:02:49,574: Epoch 15/26 Batch 3300/7662 eta: 10:09:46.831697	Training Loss 2.5411 (2.2869)	Training Prec@1 99.414 (99.746)	Training Prec@5 99.805 (99.931)	
2022-04-03 23:02:49,575: ============================================================
2022-04-03 23:03:32,425: time cost, forward:0.010656949736574672, backward:0.059512280898782986, data cost:0.3511279535560125 
2022-04-03 23:03:32,426: ============================================================
2022-04-03 23:03:32,426: Epoch 15/26 Batch 3400/7662 eta: 10:32:22.738685	Training Loss 2.3664 (2.2904)	Training Prec@1 99.805 (99.744)	Training Prec@5 100.000 (99.930)	
2022-04-03 23:03:32,426: ============================================================
2022-04-03 23:04:15,076: time cost, forward:0.010660947748987154, backward:0.059498032149876076, data cost:0.35128317529319114 
2022-04-03 23:04:15,077: ============================================================
2022-04-03 23:04:15,077: Epoch 15/26 Batch 3500/7662 eta: 10:28:43.046835	Training Loss 2.3251 (2.2941)	Training Prec@1 100.000 (99.743)	Training Prec@5 100.000 (99.930)	
2022-04-03 23:04:15,078: ============================================================
2022-04-03 23:04:57,994: time cost, forward:0.010646880948235505, backward:0.05950439754675812, data cost:0.35148896532411145 
2022-04-03 23:04:57,994: ============================================================
2022-04-03 23:04:57,995: Epoch 15/26 Batch 3600/7662 eta: 10:31:55.389565	Training Loss 2.3874 (2.2972)	Training Prec@1 99.609 (99.741)	Training Prec@5 99.805 (99.930)	
2022-04-03 23:04:57,995: ============================================================
2022-04-03 23:05:41,548: time cost, forward:0.010638044150528568, backward:0.059513515058354, data cost:0.3518515792721895 
2022-04-03 23:05:41,548: ============================================================
2022-04-03 23:05:41,548: Epoch 15/26 Batch 3700/7662 eta: 10:40:34.029864	Training Loss 2.3598 (2.3001)	Training Prec@1 100.000 (99.739)	Training Prec@5 100.000 (99.929)	
2022-04-03 23:05:41,549: ============================================================
2022-04-03 23:06:24,496: time cost, forward:0.010649581305696388, backward:0.05949629498456898, data cost:0.3520410171964665 
2022-04-03 23:06:24,497: ============================================================
2022-04-03 23:06:24,497: Epoch 15/26 Batch 3800/7662 eta: 10:30:56.853118	Training Loss 2.2751 (2.3030)	Training Prec@1 100.000 (99.737)	Training Prec@5 100.000 (99.929)	
2022-04-03 23:06:24,497: ============================================================
2022-04-03 23:07:07,359: time cost, forward:0.010649068137259628, backward:0.059487509647984785, data cost:0.3521556051366297 
2022-04-03 23:07:07,360: ============================================================
2022-04-03 23:07:07,360: Epoch 15/26 Batch 3900/7662 eta: 10:28:58.788102	Training Loss 2.4384 (2.3062)	Training Prec@1 99.609 (99.736)	Training Prec@5 99.805 (99.928)	
2022-04-03 23:07:07,360: ============================================================
2022-04-03 23:07:50,110: time cost, forward:0.010657755486158526, backward:0.059472826666520755, data cost:0.35231780516979067 
2022-04-03 23:07:50,111: ============================================================
2022-04-03 23:07:50,111: Epoch 15/26 Batch 4000/7662 eta: 10:26:37.234370	Training Loss 2.4013 (2.3091)	Training Prec@1 99.414 (99.734)	Training Prec@5 99.609 (99.927)	
2022-04-03 23:07:50,111: ============================================================
2022-04-03 23:08:32,925: time cost, forward:0.010648017977760839, backward:0.059488365957870167, data cost:0.35245056831711646 
2022-04-03 23:08:32,926: ============================================================
2022-04-03 23:08:32,926: Epoch 15/26 Batch 4100/7662 eta: 10:26:50.964767	Training Loss 2.2976 (2.3123)	Training Prec@1 100.000 (99.733)	Training Prec@5 100.000 (99.927)	
2022-04-03 23:08:32,926: ============================================================
2022-04-03 23:09:13,972: time cost, forward:0.01063657340676366, backward:0.05950404615963206, data cost:0.35214177856390805 
2022-04-03 23:09:13,973: ============================================================
2022-04-03 23:09:13,973: Epoch 15/26 Batch 4200/7662 eta: 10:00:16.592602	Training Loss 2.3648 (2.3149)	Training Prec@1 99.414 (99.730)	Training Prec@5 100.000 (99.926)	
2022-04-03 23:09:13,973: ============================================================
2022-04-03 23:09:56,380: time cost, forward:0.010633803378928398, backward:0.05949800406591536, data cost:0.3521731732251562 
2022-04-03 23:09:56,380: ============================================================
2022-04-03 23:09:56,380: Epoch 15/26 Batch 4300/7662 eta: 10:19:28.050475	Training Loss 2.4148 (2.3170)	Training Prec@1 99.609 (99.729)	Training Prec@5 100.000 (99.926)	
2022-04-03 23:09:56,381: ============================================================
2022-04-03 23:10:39,104: time cost, forward:0.01063621648470633, backward:0.05949338486747976, data cost:0.3522774270242603 
2022-04-03 23:10:39,104: ============================================================
2022-04-03 23:10:39,104: Epoch 15/26 Batch 4400/7662 eta: 10:23:22.542729	Training Loss 2.3046 (2.3196)	Training Prec@1 99.609 (99.726)	Training Prec@5 100.000 (99.925)	
2022-04-03 23:10:39,104: ============================================================
2022-04-03 23:11:21,827: time cost, forward:0.010626146278796818, backward:0.05951109969051554, data cost:0.35235645654970443 
2022-04-03 23:11:21,827: ============================================================
2022-04-03 23:11:21,828: Epoch 15/26 Batch 4500/7662 eta: 10:22:39.612955	Training Loss 2.4381 (2.3217)	Training Prec@1 99.805 (99.725)	Training Prec@5 100.000 (99.924)	
2022-04-03 23:11:21,828: ============================================================
2022-04-03 23:12:04,546: time cost, forward:0.010618795957687653, backward:0.059517049872374946, data cost:0.35245589117144316 
2022-04-03 23:12:04,547: ============================================================
2022-04-03 23:12:04,547: Epoch 15/26 Batch 4600/7662 eta: 10:21:52.933129	Training Loss 2.5062 (2.3241)	Training Prec@1 99.219 (99.723)	Training Prec@5 99.805 (99.924)	
2022-04-03 23:12:04,547: ============================================================
2022-04-03 23:12:46,865: time cost, forward:0.01065474770175165, backward:0.059473551697212475, data cost:0.3524684736033048 
2022-04-03 23:12:46,866: ============================================================
2022-04-03 23:12:46,866: Epoch 15/26 Batch 4700/7662 eta: 10:15:21.520031	Training Loss 2.5204 (2.3268)	Training Prec@1 99.414 (99.720)	Training Prec@5 99.805 (99.923)	
2022-04-03 23:12:46,866: ============================================================
2022-04-03 23:13:28,696: time cost, forward:0.01065584708561771, backward:0.05947174561920452, data cost:0.35237135154849714 
2022-04-03 23:13:28,697: ============================================================
2022-04-03 23:13:28,697: Epoch 15/26 Batch 4800/7662 eta: 10:07:33.401052	Training Loss 2.2161 (2.3297)	Training Prec@1 99.414 (99.719)	Training Prec@5 99.805 (99.922)	
2022-04-03 23:13:28,697: ============================================================
2022-04-03 23:14:09,976: time cost, forward:0.010660585955129056, backward:0.059469542860571135, data cost:0.3521637884931531 
2022-04-03 23:14:09,976: ============================================================
2022-04-03 23:14:09,977: Epoch 15/26 Batch 4900/7662 eta: 9:58:52.279741	Training Loss 2.3613 (2.3324)	Training Prec@1 99.414 (99.717)	Training Prec@5 99.414 (99.922)	
2022-04-03 23:14:09,977: ============================================================
2022-04-03 23:14:52,606: time cost, forward:0.01066344541224224, backward:0.059462732352073444, data cost:0.3522314848387616 
2022-04-03 23:14:52,607: ============================================================
2022-04-03 23:14:52,607: Epoch 15/26 Batch 5000/7662 eta: 10:17:44.777146	Training Loss 2.5356 (2.3343)	Training Prec@1 99.609 (99.717)	Training Prec@5 99.805 (99.922)	
2022-04-03 23:14:52,607: ============================================================
2022-04-03 23:15:35,471: time cost, forward:0.010658242137181008, backward:0.059466258383984893, data cost:0.35234607217545183 
2022-04-03 23:15:35,471: ============================================================
2022-04-03 23:15:35,471: Epoch 15/26 Batch 5100/7662 eta: 10:20:25.534682	Training Loss 2.6110 (2.3364)	Training Prec@1 99.805 (99.715)	Training Prec@5 99.805 (99.921)	
2022-04-03 23:15:35,472: ============================================================
2022-04-03 23:16:17,696: time cost, forward:0.010662787005084596, backward:0.05946405462678475, data cost:0.3523234900063472 
2022-04-03 23:16:17,697: ============================================================
2022-04-03 23:16:17,697: Epoch 15/26 Batch 5200/7662 eta: 10:10:28.445334	Training Loss 2.3547 (2.3385)	Training Prec@1 99.805 (99.714)	Training Prec@5 100.000 (99.921)	
2022-04-03 23:16:17,697: ============================================================
2022-04-03 23:17:00,238: time cost, forward:0.010668085529840674, backward:0.05945788403460835, data cost:0.35237262608488 
2022-04-03 23:17:00,238: ============================================================
2022-04-03 23:17:00,239: Epoch 15/26 Batch 5300/7662 eta: 10:14:20.339531	Training Loss 2.4358 (2.3404)	Training Prec@1 99.805 (99.712)	Training Prec@5 99.805 (99.921)	
2022-04-03 23:17:00,239: ============================================================
2022-04-03 23:17:43,153: time cost, forward:0.010655562244845576, backward:0.05946852030809731, data cost:0.352415968475794 
2022-04-03 23:17:43,153: ============================================================
2022-04-03 23:17:43,153: Epoch 15/26 Batch 5400/7662 eta: 10:19:00.479890	Training Loss 2.3230 (2.3425)	Training Prec@1 99.805 (99.710)	Training Prec@5 100.000 (99.920)	
2022-04-03 23:17:43,153: ============================================================
2022-04-03 23:18:25,787: time cost, forward:0.010653057885746628, backward:0.05946982234234072, data cost:0.3525465931279331 
2022-04-03 23:18:25,787: ============================================================
2022-04-03 23:18:25,787: Epoch 15/26 Batch 5500/7662 eta: 10:14:14.802038	Training Loss 2.4537 (2.3443)	Training Prec@1 100.000 (99.708)	Training Prec@5 100.000 (99.919)	
2022-04-03 23:18:25,787: ============================================================
2022-04-03 23:19:08,191: time cost, forward:0.010645628145793269, backward:0.05947654633505852, data cost:0.3525661521563468 
2022-04-03 23:19:08,191: ============================================================
2022-04-03 23:19:08,191: Epoch 15/26 Batch 5600/7662 eta: 10:10:13.756689	Training Loss 2.5842 (2.3460)	Training Prec@1 100.000 (99.707)	Training Prec@5 100.000 (99.919)	
2022-04-03 23:19:08,191: ============================================================
2022-04-03 23:19:51,011: time cost, forward:0.010636442438471337, backward:0.059487078770940234, data cost:0.3526519187439281 
2022-04-03 23:19:51,012: ============================================================
2022-04-03 23:19:51,012: Epoch 15/26 Batch 5700/7662 eta: 10:15:30.725403	Training Loss 2.7653 (2.3479)	Training Prec@1 99.414 (99.706)	Training Prec@5 99.805 (99.919)	
2022-04-03 23:19:51,012: ============================================================
2022-04-03 23:20:33,193: time cost, forward:0.010631977761484545, backward:0.05949489546965105, data cost:0.35262901385419637 
2022-04-03 23:20:33,194: ============================================================
2022-04-03 23:20:33,194: Epoch 15/26 Batch 5800/7662 eta: 10:05:37.539241	Training Loss 2.6119 (2.3498)	Training Prec@1 99.805 (99.704)	Training Prec@5 100.000 (99.918)	
2022-04-03 23:20:33,194: ============================================================
2022-04-03 23:21:13,069: time cost, forward:0.010630200244265304, backward:0.05950285523882315, data cost:0.3522019265041167 
2022-04-03 23:21:13,070: ============================================================
2022-04-03 23:21:13,070: Epoch 15/26 Batch 5900/7662 eta: 9:31:51.376144	Training Loss 2.4465 (2.3514)	Training Prec@1 99.609 (99.703)	Training Prec@5 99.805 (99.917)	
2022-04-03 23:21:13,070: ============================================================
2022-04-03 23:21:55,388: time cost, forward:0.010637310668416253, backward:0.05949429059589002, data cost:0.3522002515365211 
2022-04-03 23:21:55,389: ============================================================
2022-04-03 23:21:55,389: Epoch 15/26 Batch 6000/7662 eta: 10:06:11.203893	Training Loss 2.2871 (2.3528)	Training Prec@1 100.000 (99.702)	Training Prec@5 100.000 (99.917)	
2022-04-03 23:21:55,389: ============================================================
2022-04-03 23:22:38,001: time cost, forward:0.010630972953404847, backward:0.05950624592129491, data cost:0.35225257933735943 
2022-04-03 23:22:38,002: ============================================================
2022-04-03 23:22:38,002: Epoch 15/26 Batch 6100/7662 eta: 10:09:41.082499	Training Loss 2.2923 (2.3542)	Training Prec@1 99.805 (99.701)	Training Prec@5 99.805 (99.916)	
2022-04-03 23:22:38,002: ============================================================
2022-04-03 23:23:20,482: time cost, forward:0.01062502197958535, backward:0.05951827378941459, data cost:0.3522827845655116 
2022-04-03 23:23:20,482: ============================================================
2022-04-03 23:23:20,483: Epoch 15/26 Batch 6200/7662 eta: 10:07:05.105463	Training Loss 2.5721 (2.3557)	Training Prec@1 99.023 (99.700)	Training Prec@5 99.609 (99.916)	
2022-04-03 23:23:20,483: ============================================================
2022-04-03 23:24:02,635: time cost, forward:0.010624183021020958, backward:0.05952435782039368, data cost:0.3522480984191362 
2022-04-03 23:24:02,636: ============================================================
2022-04-03 23:24:02,636: Epoch 15/26 Batch 6300/7662 eta: 10:01:42.299802	Training Loss 2.6003 (2.3574)	Training Prec@1 99.219 (99.697)	Training Prec@5 99.805 (99.915)	
2022-04-03 23:24:02,636: ============================================================
2022-04-03 23:24:44,490: time cost, forward:0.010619011385810806, backward:0.05952678465958703, data cost:0.35218574002601705 
2022-04-03 23:24:44,490: ============================================================
2022-04-03 23:24:44,490: Epoch 15/26 Batch 6400/7662 eta: 9:56:44.208130	Training Loss 2.5625 (2.3591)	Training Prec@1 99.023 (99.696)	Training Prec@5 99.805 (99.915)	
2022-04-03 23:24:44,491: ============================================================
2022-04-03 23:25:25,525: time cost, forward:0.010618815148384832, backward:0.05952514899952776, data cost:0.3519981053081324 
2022-04-03 23:25:25,525: ============================================================
2022-04-03 23:25:25,525: Epoch 15/26 Batch 6500/7662 eta: 9:44:22.483554	Training Loss 2.5904 (2.3608)	Training Prec@1 100.000 (99.695)	Training Prec@5 100.000 (99.914)	
2022-04-03 23:25:25,526: ============================================================
2022-04-03 23:26:06,637: time cost, forward:0.010612887096217155, backward:0.059532032932073965, data cost:0.35181704295875627 
2022-04-03 23:26:06,638: ============================================================
2022-04-03 23:26:06,638: Epoch 15/26 Batch 6600/7662 eta: 9:44:47.299895	Training Loss 2.2383 (2.3621)	Training Prec@1 99.414 (99.694)	Training Prec@5 100.000 (99.914)	
2022-04-03 23:26:06,638: ============================================================
2022-04-03 23:26:47,657: time cost, forward:0.010647845456877436, backward:0.059497248754517, data cost:0.3516343846430012 
2022-04-03 23:26:47,657: ============================================================
2022-04-03 23:26:47,657: Epoch 15/26 Batch 6700/7662 eta: 9:42:46.965682	Training Loss 2.4850 (2.3637)	Training Prec@1 100.000 (99.693)	Training Prec@5 100.000 (99.914)	
2022-04-03 23:26:47,657: ============================================================
2022-04-03 23:27:30,505: time cost, forward:0.010655533445111127, backward:0.05949016805430829, data cost:0.3517265823732879 
2022-04-03 23:27:30,506: ============================================================
2022-04-03 23:27:30,506: Epoch 15/26 Batch 6800/7662 eta: 10:08:03.653749	Training Loss 2.3676 (2.3652)	Training Prec@1 100.000 (99.692)	Training Prec@5 100.000 (99.913)	
2022-04-03 23:27:30,506: ============================================================
2022-04-03 23:28:13,095: time cost, forward:0.010650710206668365, backward:0.05949354738511112, data cost:0.35177183953000596 
2022-04-03 23:28:13,095: ============================================================
2022-04-03 23:28:13,095: Epoch 15/26 Batch 6900/7662 eta: 10:03:40.031184	Training Loss 2.5359 (2.3668)	Training Prec@1 99.609 (99.690)	Training Prec@5 100.000 (99.913)	
2022-04-03 23:28:13,095: ============================================================
2022-04-03 23:28:55,612: time cost, forward:0.010651599987862297, backward:0.05949015003525371, data cost:0.3518213368361465 
2022-04-03 23:28:55,613: ============================================================
2022-04-03 23:28:55,613: Epoch 15/26 Batch 7000/7662 eta: 10:01:56.598661	Training Loss 2.5930 (2.3683)	Training Prec@1 99.609 (99.689)	Training Prec@5 99.805 (99.913)	
2022-04-03 23:28:55,613: ============================================================
2022-04-03 23:29:36,211: time cost, forward:0.010651044735422872, backward:0.05949217834209351, data cost:0.3515863840404338 
2022-04-03 23:29:36,212: ============================================================
2022-04-03 23:29:36,212: Epoch 15/26 Batch 7100/7662 eta: 9:34:06.160238	Training Loss 2.3053 (2.3693)	Training Prec@1 99.805 (99.688)	Training Prec@5 100.000 (99.912)	
2022-04-03 23:29:36,212: ============================================================
2022-04-03 23:30:17,769: time cost, forward:0.010641979399547426, backward:0.05950051851613039, data cost:0.35149867439587956 
2022-04-03 23:30:17,770: ============================================================
2022-04-03 23:30:17,770: Epoch 15/26 Batch 7200/7662 eta: 9:46:58.202511	Training Loss 2.3812 (2.3704)	Training Prec@1 100.000 (99.687)	Training Prec@5 100.000 (99.912)	
2022-04-03 23:30:17,770: ============================================================
2022-04-03 23:30:59,387: time cost, forward:0.010636478143941051, backward:0.05950690501519206, data cost:0.351404928445718 
2022-04-03 23:30:59,387: ============================================================
2022-04-03 23:30:59,387: Epoch 15/26 Batch 7300/7662 eta: 9:47:07.333530	Training Loss 2.5893 (2.3715)	Training Prec@1 99.414 (99.686)	Training Prec@5 100.000 (99.912)	
2022-04-03 23:30:59,388: ============================================================
2022-04-03 23:31:40,958: time cost, forward:0.010664747734136849, backward:0.05947685238476911, data cost:0.35132653636857614 
2022-04-03 23:31:40,958: ============================================================
2022-04-03 23:31:40,959: Epoch 15/26 Batch 7400/7662 eta: 9:45:46.267544	Training Loss 2.3981 (2.3725)	Training Prec@1 99.609 (99.685)	Training Prec@5 100.000 (99.912)	
2022-04-03 23:31:40,959: ============================================================
2022-04-03 23:32:23,654: time cost, forward:0.010660504321922285, backward:0.05948144621110818, data cost:0.3513720937849188 
2022-04-03 23:32:23,654: ============================================================
2022-04-03 23:32:23,654: Epoch 15/26 Batch 7500/7662 eta: 10:00:54.318977	Training Loss 2.4024 (2.3738)	Training Prec@1 99.805 (99.683)	Training Prec@5 100.000 (99.912)	
2022-04-03 23:32:23,654: ============================================================
2022-04-03 23:33:05,364: time cost, forward:0.010656731554451295, backward:0.05948972435338919, data cost:0.351322457921836 
2022-04-03 23:33:05,365: ============================================================
2022-04-03 23:33:05,365: Epoch 15/26 Batch 7600/7662 eta: 9:46:20.776326	Training Loss 2.4999 (2.3749)	Training Prec@1 100.000 (99.682)	Training Prec@5 100.000 (99.911)	
2022-04-03 23:33:05,365: ============================================================
2022-04-03 23:33:32,807: Epoch: 15/26 eta: 9:45:54.498670	Training Loss 2.4933 (2.3756)	Training Prec@1 99.609 (99.681)	Training Prec@5 100.000 (99.911)
2022-04-03 23:33:32,808: ============================================================
2022-04-03 23:33:32,810: Save Checkpoint...
2022-04-03 23:33:32,814: ============================================================
2022-04-03 23:33:35,803: Save done!
2022-04-03 23:33:35,803: ============================================================
2022-04-03 23:34:22,781: time cost, forward:0.010865917109479808, backward:0.058603250619136925, data cost:0.40211553043789333 
2022-04-03 23:34:22,782: ============================================================
2022-04-03 23:34:22,783: Epoch 16/26 Batch 100/7662 eta: 10:59:05.973931	Training Loss 2.0536 (2.0270)	Training Prec@1 100.000 (99.836)	Training Prec@5 100.000 (99.966)	
2022-04-03 23:34:22,783: ============================================================
2022-04-03 23:35:01,634: time cost, forward:0.010914758222186984, backward:0.058911940560268994, data cost:0.3594076429779206 
2022-04-03 23:35:01,635: ============================================================
2022-04-03 23:35:01,635: Epoch 16/26 Batch 200/7662 eta: 9:04:28.358769	Training Loss 2.0025 (2.0337)	Training Prec@1 100.000 (99.856)	Training Prec@5 100.000 (99.970)	
2022-04-03 23:35:01,635: ============================================================
2022-04-03 23:35:43,843: time cost, forward:0.011051599796001729, backward:0.058591098689714, data cost:0.35672121063921364 
2022-04-03 23:35:43,844: ============================================================
2022-04-03 23:35:43,844: Epoch 16/26 Batch 300/7662 eta: 9:50:48.365341	Training Loss 2.1806 (2.0410)	Training Prec@1 99.414 (99.847)	Training Prec@5 99.805 (99.964)	
2022-04-03 23:35:43,844: ============================================================
2022-04-03 23:36:26,188: time cost, forward:0.011269635126405492, backward:0.05843707254357206, data cost:0.35579712349071835 
2022-04-03 23:36:26,189: ============================================================
2022-04-03 23:36:26,189: Epoch 16/26 Batch 400/7662 eta: 9:52:00.275573	Training Loss 2.0124 (2.0510)	Training Prec@1 99.609 (99.841)	Training Prec@5 99.805 (99.956)	
2022-04-03 23:36:26,189: ============================================================
2022-04-03 23:37:08,077: time cost, forward:0.011029097264658711, backward:0.05898842639579085, data cost:0.35416290086352514 
2022-04-03 23:37:08,077: ============================================================
2022-04-03 23:37:08,077: Epoch 16/26 Batch 500/7662 eta: 9:44:55.256163	Training Loss 2.0446 (2.0623)	Training Prec@1 99.805 (99.839)	Training Prec@5 99.805 (99.956)	
2022-04-03 23:37:08,078: ============================================================
2022-04-03 23:37:49,991: time cost, forward:0.010865919578055508, backward:0.05930124578969506, data cost:0.353116066109557 
2022-04-03 23:37:49,992: ============================================================
2022-04-03 23:37:49,992: Epoch 16/26 Batch 600/7662 eta: 9:44:35.395030	Training Loss 2.0452 (2.0749)	Training Prec@1 99.609 (99.832)	Training Prec@5 99.805 (99.956)	
2022-04-03 23:37:49,992: ============================================================
2022-04-03 23:38:32,694: time cost, forward:0.010780942286544604, backward:0.059446547334968444, data cost:0.3534941134364138 
2022-04-03 23:38:32,695: ============================================================
2022-04-03 23:38:32,695: Epoch 16/26 Batch 700/7662 eta: 9:54:52.464888	Training Loss 2.2036 (2.0887)	Training Prec@1 99.805 (99.829)	Training Prec@5 100.000 (99.956)	
2022-04-03 23:38:32,695: ============================================================
2022-04-03 23:39:15,227: time cost, forward:0.011081179331181494, backward:0.059155941009521484, data cost:0.3535992111521161 
2022-04-03 23:39:15,227: ============================================================
2022-04-03 23:39:15,228: Epoch 16/26 Batch 800/7662 eta: 9:51:47.485619	Training Loss 2.2116 (2.1017)	Training Prec@1 99.609 (99.823)	Training Prec@5 100.000 (99.955)	
2022-04-03 23:39:15,228: ============================================================
2022-04-03 23:39:57,417: time cost, forward:0.01146156981471383, backward:0.058777389590016195, data cost:0.35322964231217396 
2022-04-03 23:39:57,417: ============================================================
2022-04-03 23:39:57,417: Epoch 16/26 Batch 900/7662 eta: 9:46:19.039446	Training Loss 2.1928 (2.1096)	Training Prec@1 99.805 (99.823)	Training Prec@5 99.805 (99.956)	
2022-04-03 23:39:57,418: ============================================================
2022-04-03 23:40:39,551: time cost, forward:0.011331749869299843, backward:0.05897952892162182, data cost:0.352925898911836 
2022-04-03 23:40:39,552: ============================================================
2022-04-03 23:40:39,552: Epoch 16/26 Batch 1000/7662 eta: 9:44:51.053569	Training Loss 2.1146 (2.1187)	Training Prec@1 99.609 (99.821)	Training Prec@5 100.000 (99.955)	
2022-04-03 23:40:39,552: ============================================================
2022-04-03 23:41:20,401: time cost, forward:0.011326149444996606, backward:0.05904769441884035, data cost:0.35150049403106437 
2022-04-03 23:41:20,402: ============================================================
2022-04-03 23:41:20,402: Epoch 16/26 Batch 1100/7662 eta: 9:26:20.080896	Training Loss 2.3392 (2.1304)	Training Prec@1 99.414 (99.811)	Training Prec@5 99.609 (99.953)	
2022-04-03 23:41:20,402: ============================================================
2022-04-03 23:42:01,862: time cost, forward:0.011344398827827205, backward:0.059074918661045965, data cost:0.3507708815160247 
2022-04-03 23:42:01,863: ============================================================
2022-04-03 23:42:01,863: Epoch 16/26 Batch 1200/7662 eta: 9:34:07.196514	Training Loss 2.2385 (2.1401)	Training Prec@1 100.000 (99.811)	Training Prec@5 100.000 (99.953)	
2022-04-03 23:42:01,863: ============================================================
2022-04-03 23:42:42,327: time cost, forward:0.011400641800349633, backward:0.05902646742388319, data cost:0.3493979757248759 
2022-04-03 23:42:42,327: ============================================================
2022-04-03 23:42:42,328: Epoch 16/26 Batch 1300/7662 eta: 9:19:38.751158	Training Loss 2.2030 (2.1471)	Training Prec@1 99.805 (99.808)	Training Prec@5 100.000 (99.951)	
2022-04-03 23:42:42,328: ============================================================
2022-04-03 23:43:23,847: time cost, forward:0.011316994754990312, backward:0.059155573071199626, data cost:0.34899465691796194 
2022-04-03 23:43:23,847: ============================================================
2022-04-03 23:43:23,847: Epoch 16/26 Batch 1400/7662 eta: 9:33:32.590600	Training Loss 2.2085 (2.1549)	Training Prec@1 99.609 (99.806)	Training Prec@5 100.000 (99.951)	
2022-04-03 23:43:23,847: ============================================================
2022-04-03 23:44:04,750: time cost, forward:0.01124934803413661, backward:0.05926538817957292, data cost:0.348204556904768 
2022-04-03 23:44:04,750: ============================================================
2022-04-03 23:44:04,751: Epoch 16/26 Batch 1500/7662 eta: 9:24:21.093155	Training Loss 2.1948 (2.1628)	Training Prec@1 100.000 (99.803)	Training Prec@5 100.000 (99.949)	
2022-04-03 23:44:04,751: ============================================================
2022-04-03 23:44:44,682: time cost, forward:0.011203620641063049, backward:0.059351401302201665, data cost:0.34693393474671896 
2022-04-03 23:44:44,683: ============================================================
2022-04-03 23:44:44,683: Epoch 16/26 Batch 1600/7662 eta: 9:10:17.264293	Training Loss 2.3862 (2.1697)	Training Prec@1 100.000 (99.799)	Training Prec@5 100.000 (99.947)	
2022-04-03 23:44:44,683: ============================================================
2022-04-03 23:45:25,965: time cost, forward:0.011143109460239062, backward:0.05945623348992737, data cost:0.3465855932712836 
2022-04-03 23:45:25,966: ============================================================
2022-04-03 23:45:25,966: Epoch 16/26 Batch 1700/7662 eta: 9:28:12.707790	Training Loss 2.2985 (2.1766)	Training Prec@1 99.805 (99.796)	Training Prec@5 100.000 (99.946)	
2022-04-03 23:45:25,966: ============================================================
2022-04-03 23:46:06,414: time cost, forward:0.011120169609370928, backward:0.05951690660575286, data cost:0.3458170424308162 
2022-04-03 23:46:06,415: ============================================================
2022-04-03 23:46:06,415: Epoch 16/26 Batch 1800/7662 eta: 9:16:03.486430	Training Loss 2.3964 (2.1832)	Training Prec@1 99.609 (99.792)	Training Prec@5 99.805 (99.945)	
2022-04-03 23:46:06,415: ============================================================
2022-04-03 23:46:48,403: time cost, forward:0.011068172489987855, backward:0.05958344360098455, data cost:0.3459478361221161 
2022-04-03 23:46:48,404: ============================================================
2022-04-03 23:46:48,404: Epoch 16/26 Batch 1900/7662 eta: 9:36:31.873165	Training Loss 2.0674 (2.1890)	Training Prec@1 100.000 (99.788)	Training Prec@5 100.000 (99.943)	
2022-04-03 23:46:48,404: ============================================================
2022-04-03 23:47:30,472: time cost, forward:0.011029542476430782, backward:0.05960665147503714, data cost:0.34613247547464526 
2022-04-03 23:47:30,473: ============================================================
2022-04-03 23:47:30,473: Epoch 16/26 Batch 2000/7662 eta: 9:36:55.619188	Training Loss 2.1765 (2.1950)	Training Prec@1 99.805 (99.784)	Training Prec@5 100.000 (99.942)	
2022-04-03 23:47:30,473: ============================================================
2022-04-03 23:48:12,661: time cost, forward:0.011011890367759642, backward:0.05962236692020585, data cost:0.346354600416586 
2022-04-03 23:48:12,661: ============================================================
2022-04-03 23:48:12,662: Epoch 16/26 Batch 2100/7662 eta: 9:37:52.008455	Training Loss 2.2906 (2.2008)	Training Prec@1 99.609 (99.783)	Training Prec@5 100.000 (99.942)	
2022-04-03 23:48:12,662: ============================================================
2022-04-03 23:48:53,599: time cost, forward:0.01097420087018952, backward:0.059645185366496545, data cost:0.34598592955071905 
2022-04-03 23:48:53,599: ============================================================
2022-04-03 23:48:53,599: Epoch 16/26 Batch 2200/7662 eta: 9:20:02.828715	Training Loss 1.9937 (2.2059)	Training Prec@1 99.609 (99.781)	Training Prec@5 99.805 (99.941)	
2022-04-03 23:48:53,599: ============================================================
2022-04-03 23:49:36,206: time cost, forward:0.010929723675741533, backward:0.05969649182552356, data cost:0.34642294304637405 
2022-04-03 23:49:36,206: ============================================================
2022-04-03 23:49:36,207: Epoch 16/26 Batch 2300/7662 eta: 9:42:10.807297	Training Loss 2.5241 (2.2106)	Training Prec@1 99.609 (99.778)	Training Prec@5 99.805 (99.939)	
2022-04-03 23:49:36,207: ============================================================
2022-04-03 23:50:17,034: time cost, forward:0.010894261781947719, backward:0.059723905048155695, data cost:0.3459950284492776 
2022-04-03 23:50:17,034: ============================================================
2022-04-03 23:50:17,034: Epoch 16/26 Batch 2400/7662 eta: 9:17:10.808852	Training Loss 2.4328 (2.2151)	Training Prec@1 99.805 (99.776)	Training Prec@5 100.000 (99.939)	
2022-04-03 23:50:17,034: ============================================================
2022-04-03 23:50:58,775: time cost, forward:0.010857691522501335, backward:0.05976342420284154, data cost:0.34601598608345924 
2022-04-03 23:50:58,776: ============================================================
2022-04-03 23:50:58,776: Epoch 16/26 Batch 2500/7662 eta: 9:28:57.619722	Training Loss 2.4471 (2.2201)	Training Prec@1 99.023 (99.774)	Training Prec@5 99.805 (99.938)	
2022-04-03 23:50:58,776: ============================================================
2022-04-03 23:51:38,959: time cost, forward:0.01083431761280396, backward:0.05977980060364568, data cost:0.34545291566353387 
2022-04-03 23:51:38,959: ============================================================
2022-04-03 23:51:38,959: Epoch 16/26 Batch 2600/7662 eta: 9:07:02.982599	Training Loss 2.1859 (2.2248)	Training Prec@1 99.805 (99.772)	Training Prec@5 99.805 (99.937)	
2022-04-03 23:51:38,959: ============================================================
2022-04-03 23:52:19,550: time cost, forward:0.010821953222635898, backward:0.05978283806172244, data cost:0.3450516451284063 
2022-04-03 23:52:19,550: ============================================================
2022-04-03 23:52:19,550: Epoch 16/26 Batch 2700/7662 eta: 9:11:55.357346	Training Loss 2.3139 (2.2301)	Training Prec@1 99.219 (99.770)	Training Prec@5 100.000 (99.937)	
2022-04-03 23:52:19,550: ============================================================
2022-04-03 23:53:01,130: time cost, forward:0.01079256571203779, backward:0.0598167999168088, data cost:0.34502746029043246 
2022-04-03 23:53:01,131: ============================================================
2022-04-03 23:53:01,131: Epoch 16/26 Batch 2800/7662 eta: 9:24:41.306234	Training Loss 2.3760 (2.2349)	Training Prec@1 100.000 (99.768)	Training Prec@5 100.000 (99.936)	
2022-04-03 23:53:01,131: ============================================================
2022-04-03 23:53:42,996: time cost, forward:0.010838860846996801, backward:0.05977836860875172, data cost:0.34508791821872253 
2022-04-03 23:53:42,997: ============================================================
2022-04-03 23:53:42,997: Epoch 16/26 Batch 2900/7662 eta: 9:27:51.859117	Training Loss 2.4325 (2.2386)	Training Prec@1 99.805 (99.767)	Training Prec@5 100.000 (99.936)	
2022-04-03 23:53:42,998: ============================================================
2022-04-03 23:54:25,315: time cost, forward:0.010804184042004276, backward:0.05984122342131622, data cost:0.34531006100735057 
2022-04-03 23:54:25,315: ============================================================
2022-04-03 23:54:25,316: Epoch 16/26 Batch 3000/7662 eta: 9:33:17.630500	Training Loss 2.3199 (2.2426)	Training Prec@1 100.000 (99.765)	Training Prec@5 100.000 (99.935)	
2022-04-03 23:54:25,316: ============================================================
2022-04-03 23:55:05,598: time cost, forward:0.0108076456709422, backward:0.05984291741062495, data cost:0.3448439059852977 
2022-04-03 23:55:05,598: ============================================================
2022-04-03 23:55:05,598: Epoch 16/26 Batch 3100/7662 eta: 9:05:02.776007	Training Loss 2.4636 (2.2464)	Training Prec@1 99.805 (99.764)	Training Prec@5 100.000 (99.935)	
2022-04-03 23:55:05,598: ============================================================
2022-04-03 23:55:47,044: time cost, forward:0.010784884101340606, backward:0.05986593074446807, data cost:0.3448144369253556 
2022-04-03 23:55:47,044: ============================================================
2022-04-03 23:55:47,044: Epoch 16/26 Batch 3200/7662 eta: 9:20:05.768905	Training Loss 2.3425 (2.2499)	Training Prec@1 99.609 (99.761)	Training Prec@5 99.805 (99.934)	
2022-04-03 23:55:47,045: ============================================================
2022-04-03 23:56:27,797: time cost, forward:0.01077165868145728, backward:0.05987917592793604, data cost:0.3445337841314921 
2022-04-03 23:56:27,798: ============================================================
2022-04-03 23:56:27,798: Epoch 16/26 Batch 3300/7662 eta: 9:10:03.347038	Training Loss 2.4831 (2.2541)	Training Prec@1 99.805 (99.758)	Training Prec@5 100.000 (99.934)	
2022-04-03 23:56:27,798: ============================================================
2022-04-03 23:57:09,622: time cost, forward:0.010768306925213312, backward:0.05990074907691734, data cost:0.344605668638341 
2022-04-03 23:57:09,623: ============================================================
2022-04-03 23:57:09,623: Epoch 16/26 Batch 3400/7662 eta: 9:23:49.342750	Training Loss 2.3807 (2.2577)	Training Prec@1 99.219 (99.757)	Training Prec@5 100.000 (99.934)	
2022-04-03 23:57:09,623: ============================================================
2022-04-03 23:57:52,153: time cost, forward:0.010792631801791653, backward:0.05988685428568144, data cost:0.34486295250900545 
2022-04-03 23:57:52,153: ============================================================
2022-04-03 23:57:52,154: Epoch 16/26 Batch 3500/7662 eta: 9:32:37.514686	Training Loss 2.5087 (2.2610)	Training Prec@1 99.219 (99.756)	Training Prec@5 99.805 (99.933)	
2022-04-03 23:57:52,154: ============================================================
2022-04-03 23:58:33,953: time cost, forward:0.01077850569152408, backward:0.05992237048932134, data cost:0.34488086344037133 
2022-04-03 23:58:33,954: ============================================================
2022-04-03 23:58:33,954: Epoch 16/26 Batch 3600/7662 eta: 9:22:05.800396	Training Loss 2.3202 (2.2647)	Training Prec@1 100.000 (99.754)	Training Prec@5 100.000 (99.933)	
2022-04-03 23:58:33,954: ============================================================
2022-04-03 23:59:14,574: time cost, forward:0.010773860302832552, backward:0.0599303776008047, data cost:0.34457223297422335 
2022-04-03 23:59:14,575: ============================================================
2022-04-03 23:59:14,575: Epoch 16/26 Batch 3700/7662 eta: 9:05:33.676188	Training Loss 2.2107 (2.2679)	Training Prec@1 99.805 (99.754)	Training Prec@5 99.805 (99.933)	
2022-04-03 23:59:14,575: ============================================================
2022-04-03 23:59:56,724: time cost, forward:0.010767961496050403, backward:0.059923731549597625, data cost:0.34478051262675036 
2022-04-03 23:59:56,724: ============================================================
2022-04-03 23:59:56,724: Epoch 16/26 Batch 3800/7662 eta: 9:25:22.986275	Training Loss 2.3802 (2.2715)	Training Prec@1 99.219 (99.750)	Training Prec@5 100.000 (99.931)	
2022-04-03 23:59:56,725: ============================================================
2022-04-04 00:00:38,191: time cost, forward:0.01075139936039649, backward:0.05994767621713713, data cost:0.3447510099129727 
2022-04-04 00:00:38,192: ============================================================
2022-04-04 00:00:38,192: Epoch 16/26 Batch 3900/7662 eta: 9:15:33.076352	Training Loss 2.3033 (2.2742)	Training Prec@1 99.805 (99.749)	Training Prec@5 100.000 (99.931)	
2022-04-04 00:00:38,192: ============================================================
2022-04-04 00:01:18,583: time cost, forward:0.010751927068872015, backward:0.0599504831761949, data cost:0.3444351131065275 
2022-04-04 00:01:18,584: ============================================================
2022-04-04 00:01:18,584: Epoch 16/26 Batch 4000/7662 eta: 9:00:27.803861	Training Loss 2.4189 (2.2769)	Training Prec@1 99.805 (99.748)	Training Prec@5 100.000 (99.931)	
2022-04-04 00:01:18,584: ============================================================
2022-04-04 00:02:00,080: time cost, forward:0.010735657483259333, backward:0.05996574050305849, data cost:0.3444319971889134 
2022-04-04 00:02:00,080: ============================================================
2022-04-04 00:02:00,080: Epoch 16/26 Batch 4100/7662 eta: 9:14:33.116049	Training Loss 2.3191 (2.2795)	Training Prec@1 99.414 (99.746)	Training Prec@5 99.609 (99.929)	
2022-04-04 00:02:00,081: ============================================================
2022-04-04 00:02:41,013: time cost, forward:0.010720627056357122, backward:0.05999075977482606, data cost:0.34426975818042616 
2022-04-04 00:02:41,013: ============================================================
2022-04-04 00:02:41,013: Epoch 16/26 Batch 4200/7662 eta: 9:06:20.297514	Training Loss 2.4640 (2.2822)	Training Prec@1 99.414 (99.745)	Training Prec@5 99.805 (99.929)	
2022-04-04 00:02:41,014: ============================================================
2022-04-04 00:03:22,510: time cost, forward:0.010709964000615831, backward:0.060017794280530244, data cost:0.3442313595687714 
2022-04-04 00:03:22,511: ============================================================
2022-04-04 00:03:22,511: Epoch 16/26 Batch 4300/7662 eta: 9:13:10.933556	Training Loss 2.3774 (2.2848)	Training Prec@1 99.805 (99.743)	Training Prec@5 99.805 (99.928)	
2022-04-04 00:03:22,511: ============================================================
2022-04-04 00:04:04,516: time cost, forward:0.010707429279709817, backward:0.06002412196803456, data cost:0.34433798314116437 
2022-04-04 00:04:04,517: ============================================================
2022-04-04 00:04:04,517: Epoch 16/26 Batch 4400/7662 eta: 9:19:15.930317	Training Loss 2.3123 (2.2869)	Training Prec@1 99.414 (99.742)	Training Prec@5 99.609 (99.927)	
2022-04-04 00:04:04,518: ============================================================
2022-04-04 00:04:46,393: time cost, forward:0.010707002079309318, backward:0.06002827473920461, data cost:0.3443985673209566 
2022-04-04 00:04:46,394: ============================================================
2022-04-04 00:04:46,394: Epoch 16/26 Batch 4500/7662 eta: 9:16:50.633968	Training Loss 2.2800 (2.2892)	Training Prec@1 99.609 (99.740)	Training Prec@5 100.000 (99.927)	
2022-04-04 00:04:46,394: ============================================================
2022-04-04 00:05:27,772: time cost, forward:0.010688050152504281, backward:0.06005925747538992, data cost:0.34435002247544316 
2022-04-04 00:05:27,773: ============================================================
2022-04-04 00:05:27,773: Epoch 16/26 Batch 4600/7662 eta: 9:09:31.908842	Training Loss 2.3151 (2.2921)	Training Prec@1 99.805 (99.738)	Training Prec@5 100.000 (99.926)	
2022-04-04 00:05:27,773: ============================================================
2022-04-04 00:06:07,835: time cost, forward:0.010717789907104336, backward:0.06002716836484855, data cost:0.34403140414494304 
2022-04-04 00:06:07,836: ============================================================
2022-04-04 00:06:07,836: Epoch 16/26 Batch 4700/7662 eta: 8:51:23.355856	Training Loss 2.2220 (2.2945)	Training Prec@1 99.414 (99.736)	Training Prec@5 99.805 (99.926)	
2022-04-04 00:06:07,836: ============================================================
2022-04-04 00:06:48,676: time cost, forward:0.010767486200255139, backward:0.059963116126150906, data cost:0.3438987849180488 
2022-04-04 00:06:48,677: ============================================================
2022-04-04 00:06:48,677: Epoch 16/26 Batch 4800/7662 eta: 9:01:01.829468	Training Loss 2.1905 (2.2968)	Training Prec@1 99.805 (99.734)	Training Prec@5 99.805 (99.925)	
2022-04-04 00:06:48,678: ============================================================
2022-04-04 00:07:30,082: time cost, forward:0.01082776648386519, backward:0.05990504337637053, data cost:0.343884778524034 
2022-04-04 00:07:30,082: ============================================================
2022-04-04 00:07:30,082: Epoch 16/26 Batch 4900/7662 eta: 9:07:48.607590	Training Loss 2.4037 (2.2990)	Training Prec@1 99.023 (99.732)	Training Prec@5 99.805 (99.925)	
2022-04-04 00:07:30,082: ============================================================
2022-04-04 00:08:10,478: time cost, forward:0.010886759489959515, backward:0.059853604851448194, data cost:0.34363904288349734 
2022-04-04 00:08:10,478: ============================================================
2022-04-04 00:08:10,478: Epoch 16/26 Batch 5000/7662 eta: 8:53:47.252474	Training Loss 2.4417 (2.3012)	Training Prec@1 99.805 (99.730)	Training Prec@5 100.000 (99.924)	
2022-04-04 00:08:10,479: ============================================================
2022-04-04 00:08:52,236: time cost, forward:0.010899629750002082, backward:0.05983739199416734, data cost:0.3436985727992098 
2022-04-04 00:08:52,237: ============================================================
2022-04-04 00:08:52,237: Epoch 16/26 Batch 5100/7662 eta: 9:11:05.764718	Training Loss 2.4289 (2.3031)	Training Prec@1 99.805 (99.729)	Training Prec@5 100.000 (99.924)	
2022-04-04 00:08:52,237: ============================================================
2022-04-04 00:09:32,907: time cost, forward:0.010919736884928456, backward:0.05981992262788726, data cost:0.34353460484134346 
2022-04-04 00:09:32,908: ============================================================
2022-04-04 00:09:32,908: Epoch 16/26 Batch 5200/7662 eta: 8:56:03.595221	Training Loss 2.3190 (2.3052)	Training Prec@1 99.609 (99.726)	Training Prec@5 99.609 (99.923)	
2022-04-04 00:09:32,908: ============================================================
2022-04-04 00:10:13,985: time cost, forward:0.010929114684943411, backward:0.0598086273699442, data cost:0.3434567253507293 
2022-04-04 00:10:13,986: ============================================================
2022-04-04 00:10:13,986: Epoch 16/26 Batch 5300/7662 eta: 9:00:44.596496	Training Loss 2.5322 (2.3075)	Training Prec@1 99.805 (99.724)	Training Prec@5 100.000 (99.922)	
2022-04-04 00:10:13,986: ============================================================
2022-04-04 00:10:54,577: time cost, forward:0.01096278045945398, backward:0.05977227613205688, data cost:0.34331311709705514 
2022-04-04 00:10:54,578: ============================================================
2022-04-04 00:10:54,578: Epoch 16/26 Batch 5400/7662 eta: 8:53:40.376942	Training Loss 2.4168 (2.3096)	Training Prec@1 99.805 (99.723)	Training Prec@5 100.000 (99.922)	
2022-04-04 00:10:54,578: ============================================================
2022-04-04 00:11:34,632: time cost, forward:0.011011595855216195, backward:0.05971991276606622, data cost:0.34305298170147647 
2022-04-04 00:11:34,633: ============================================================
2022-04-04 00:11:34,633: Epoch 16/26 Batch 5500/7662 eta: 8:45:56.517179	Training Loss 2.5880 (2.3118)	Training Prec@1 98.828 (99.722)	Training Prec@5 99.219 (99.921)	
2022-04-04 00:11:34,633: ============================================================
2022-04-04 00:12:16,016: time cost, forward:0.011009367092696018, backward:0.059726351434619414, data cost:0.3430361728153818 
2022-04-04 00:12:16,016: ============================================================
2022-04-04 00:12:16,017: Epoch 16/26 Batch 5600/7662 eta: 9:02:41.832097	Training Loss 2.3529 (2.3139)	Training Prec@1 99.414 (99.720)	Training Prec@5 99.805 (99.921)	
2022-04-04 00:12:16,017: ============================================================
2022-04-04 00:12:57,355: time cost, forward:0.01100520506974458, backward:0.05973056643275676, data cost:0.3430214187600651 
2022-04-04 00:12:57,355: ============================================================
2022-04-04 00:12:57,356: Epoch 16/26 Batch 5700/7662 eta: 9:01:25.458210	Training Loss 2.3118 (2.3153)	Training Prec@1 99.805 (99.719)	Training Prec@5 100.000 (99.921)	
2022-04-04 00:12:57,356: ============================================================
2022-04-04 00:13:38,644: time cost, forward:0.01101895072662043, backward:0.059724025468124074, data cost:0.34297198602959583 
2022-04-04 00:13:38,644: ============================================================
2022-04-04 00:13:38,645: Epoch 16/26 Batch 5800/7662 eta: 9:00:04.781528	Training Loss 2.4697 (2.3174)	Training Prec@1 99.414 (99.718)	Training Prec@5 100.000 (99.921)	
2022-04-04 00:13:38,645: ============================================================
2022-04-04 00:14:20,585: time cost, forward:0.011007534041002982, backward:0.05973750507453677, data cost:0.3430721197598747 
2022-04-04 00:14:20,585: ============================================================
2022-04-04 00:14:20,585: Epoch 16/26 Batch 5900/7662 eta: 9:07:54.389949	Training Loss 2.4920 (2.3192)	Training Prec@1 99.219 (99.716)	Training Prec@5 100.000 (99.920)	
2022-04-04 00:14:20,585: ============================================================
2022-04-04 00:15:01,696: time cost, forward:0.011001782608858882, backward:0.059745593078137635, data cost:0.34299785658843834 
2022-04-04 00:15:01,696: ============================================================
2022-04-04 00:15:01,696: Epoch 16/26 Batch 6000/7662 eta: 8:56:23.014325	Training Loss 2.4067 (2.3208)	Training Prec@1 99.805 (99.715)	Training Prec@5 100.000 (99.920)	
2022-04-04 00:15:01,697: ============================================================
2022-04-04 00:15:43,003: time cost, forward:0.011010639158149765, backward:0.059737890543439656, data cost:0.3429958238662667 
2022-04-04 00:15:43,003: ============================================================
2022-04-04 00:15:43,004: Epoch 16/26 Batch 6100/7662 eta: 8:58:15.244489	Training Loss 2.4926 (2.3228)	Training Prec@1 99.609 (99.713)	Training Prec@5 100.000 (99.920)	
2022-04-04 00:15:43,004: ============================================================
2022-04-04 00:16:23,545: time cost, forward:0.010993174880449763, backward:0.05976155473832489, data cost:0.34284030750771266 
2022-04-04 00:16:23,545: ============================================================
2022-04-04 00:16:23,545: Epoch 16/26 Batch 6200/7662 eta: 8:47:36.213872	Training Loss 2.3263 (2.3241)	Training Prec@1 99.805 (99.711)	Training Prec@5 99.805 (99.919)	
2022-04-04 00:16:23,546: ============================================================
2022-04-04 00:17:05,506: time cost, forward:0.010980766412662615, backward:0.059778348853387876, data cost:0.34292410918503907 
2022-04-04 00:17:05,506: ============================================================
2022-04-04 00:17:05,507: Epoch 16/26 Batch 6300/7662 eta: 9:05:22.720658	Training Loss 2.2557 (2.3254)	Training Prec@1 100.000 (99.711)	Training Prec@5 100.000 (99.919)	
2022-04-04 00:17:05,507: ============================================================
2022-04-04 00:17:46,101: time cost, forward:0.010972045849852122, backward:0.059795689184156356, data cost:0.3427885807870161 
2022-04-04 00:17:46,102: ============================================================
2022-04-04 00:17:46,102: Epoch 16/26 Batch 6400/7662 eta: 8:46:56.724755	Training Loss 2.4163 (2.3267)	Training Prec@1 99.414 (99.710)	Training Prec@5 100.000 (99.918)	
2022-04-04 00:17:46,102: ============================================================
2022-04-04 00:18:27,271: time cost, forward:0.010980321546942845, backward:0.059797632820809105, data cost:0.3427312174179422 
2022-04-04 00:18:27,272: ============================================================
2022-04-04 00:18:27,272: Epoch 16/26 Batch 6500/7662 eta: 8:53:43.288420	Training Loss 2.6288 (2.3281)	Training Prec@1 99.023 (99.708)	Training Prec@5 99.805 (99.918)	
2022-04-04 00:18:27,272: ============================================================
2022-04-04 00:19:08,897: time cost, forward:0.01096805833942837, backward:0.059817406928508565, data cost:0.3427665767967385 
2022-04-04 00:19:08,897: ============================================================
2022-04-04 00:19:08,897: Epoch 16/26 Batch 6600/7662 eta: 8:58:55.858978	Training Loss 2.1910 (2.3299)	Training Prec@1 99.805 (99.707)	Training Prec@5 100.000 (99.917)	
2022-04-04 00:19:08,898: ============================================================
2022-04-04 00:19:51,032: time cost, forward:0.010953477255033546, backward:0.059827013111128736, data cost:0.34288096417240427 
2022-04-04 00:19:51,032: ============================================================
2022-04-04 00:19:51,032: Epoch 16/26 Batch 6700/7662 eta: 9:04:49.701922	Training Loss 2.3956 (2.3313)	Training Prec@1 99.805 (99.706)	Training Prec@5 100.000 (99.917)	
2022-04-04 00:19:51,033: ============================================================
2022-04-04 00:20:33,183: time cost, forward:0.010942733293071286, backward:0.05984325951768258, data cost:0.3429817220606792 
2022-04-04 00:20:33,184: ============================================================
2022-04-04 00:20:33,184: Epoch 16/26 Batch 6800/7662 eta: 9:04:20.314163	Training Loss 2.3082 (2.3324)	Training Prec@1 100.000 (99.705)	Training Prec@5 100.000 (99.917)	
2022-04-04 00:20:33,184: ============================================================
2022-04-04 00:21:15,609: time cost, forward:0.010931848183734327, backward:0.05985770033380055, data cost:0.34311772961774795 
2022-04-04 00:21:15,609: ============================================================
2022-04-04 00:21:15,609: Epoch 16/26 Batch 6900/7662 eta: 9:07:09.777195	Training Loss 2.2971 (2.3340)	Training Prec@1 99.609 (99.704)	Training Prec@5 99.805 (99.917)	
2022-04-04 00:21:15,609: ============================================================
2022-04-04 00:21:57,197: time cost, forward:0.01091837085882482, backward:0.059870998013579924, data cost:0.3431485107343935 
2022-04-04 00:21:57,197: ============================================================
2022-04-04 00:21:57,197: Epoch 16/26 Batch 7000/7662 eta: 8:55:40.519865	Training Loss 2.4500 (2.3355)	Training Prec@1 99.805 (99.703)	Training Prec@5 99.805 (99.916)	
2022-04-04 00:21:57,197: ============================================================
2022-04-04 00:22:36,912: time cost, forward:0.010906931043829879, backward:0.059888798143682656, data cost:0.34288776963676326 
2022-04-04 00:22:36,912: ============================================================
2022-04-04 00:22:36,912: Epoch 16/26 Batch 7100/7662 eta: 8:30:53.408354	Training Loss 2.3418 (2.3370)	Training Prec@1 99.609 (99.702)	Training Prec@5 100.000 (99.916)	
2022-04-04 00:22:36,913: ============================================================
2022-04-04 00:23:18,397: time cost, forward:0.010897836679881737, backward:0.059904265426930364, data cost:0.3428936144729044 
2022-04-04 00:23:18,398: ============================================================
2022-04-04 00:23:18,398: Epoch 16/26 Batch 7200/7662 eta: 8:52:58.337509	Training Loss 2.6233 (2.3384)	Training Prec@1 99.609 (99.700)	Training Prec@5 99.609 (99.916)	
2022-04-04 00:23:18,398: ============================================================
2022-04-04 00:24:00,324: time cost, forward:0.010891980709384803, backward:0.059905672876912286, data cost:0.34296956217800173 
2022-04-04 00:24:00,324: ============================================================
2022-04-04 00:24:00,324: Epoch 16/26 Batch 7300/7662 eta: 8:57:56.017296	Training Loss 2.3814 (2.3400)	Training Prec@1 99.609 (99.699)	Training Prec@5 100.000 (99.915)	
2022-04-04 00:24:00,324: ============================================================
2022-04-04 00:24:39,859: time cost, forward:0.010886588375670537, backward:0.05991188502501823, data cost:0.34272480671559497 
2022-04-04 00:24:39,859: ============================================================
2022-04-04 00:24:39,860: Epoch 16/26 Batch 7400/7662 eta: 8:26:36.111314	Training Loss 2.3921 (2.3414)	Training Prec@1 99.609 (99.697)	Training Prec@5 100.000 (99.915)	
2022-04-04 00:24:39,860: ============================================================
2022-04-04 00:25:20,903: time cost, forward:0.010887764758913655, backward:0.05991440831001384, data cost:0.34265934494212874 
2022-04-04 00:25:20,903: ============================================================
2022-04-04 00:25:20,903: Epoch 16/26 Batch 7500/7662 eta: 8:45:14.609052	Training Loss 2.5428 (2.3426)	Training Prec@1 99.609 (99.696)	Training Prec@5 99.609 (99.914)	
2022-04-04 00:25:20,904: ============================================================
2022-04-04 00:26:03,157: time cost, forward:0.010904235202303873, backward:0.0599010202159598, data cost:0.34277041125633256 
2022-04-04 00:26:03,157: ============================================================
2022-04-04 00:26:03,158: Epoch 16/26 Batch 7600/7662 eta: 9:00:01.969536	Training Loss 2.4352 (2.3439)	Training Prec@1 100.000 (99.695)	Training Prec@5 100.000 (99.914)	
2022-04-04 00:26:03,159: ============================================================
2022-04-04 00:26:31,915: Epoch: 16/26 eta: 8:59:35.349241	Training Loss 2.6688 (2.3444)	Training Prec@1 99.609 (99.695)	Training Prec@5 99.805 (99.913)
2022-04-04 00:26:31,915: ============================================================
2022-04-04 00:27:22,865: time cost, forward:0.013352596398555872, backward:0.05601106027160028, data cost:0.4399565879744713 
2022-04-04 00:27:22,866: ============================================================
2022-04-04 00:27:22,866: Epoch 17/26 Batch 100/7662 eta: 10:46:57.587601	Training Loss 2.0178 (2.0033)	Training Prec@1 99.805 (99.801)	Training Prec@5 100.000 (99.947)	
2022-04-04 00:27:22,866: ============================================================
2022-04-04 00:28:01,682: time cost, forward:0.011625821865982745, backward:0.058144150067813434, data cost:0.378077242242631 
2022-04-04 00:28:01,683: ============================================================
2022-04-04 00:28:01,683: Epoch 17/26 Batch 200/7662 eta: 8:14:24.113937	Training Loss 2.0530 (2.0116)	Training Prec@1 99.219 (99.808)	Training Prec@5 99.805 (99.944)	
2022-04-04 00:28:01,683: ============================================================
2022-04-04 00:28:43,290: time cost, forward:0.01124304513070097, backward:0.05872818458837809, data cost:0.36700028559834663 
2022-04-04 00:28:43,291: ============================================================
2022-04-04 00:28:43,291: Epoch 17/26 Batch 300/7662 eta: 8:49:15.733420	Training Loss 2.1275 (2.0196)	Training Prec@1 100.000 (99.813)	Training Prec@5 100.000 (99.943)	
2022-04-04 00:28:43,291: ============================================================
2022-04-04 00:29:25,609: time cost, forward:0.011062761894742349, backward:0.05927175447755589, data cost:0.3630143275535794 
2022-04-04 00:29:25,609: ============================================================
2022-04-04 00:29:25,610: Epoch 17/26 Batch 400/7662 eta: 8:57:35.613720	Training Loss 2.1025 (2.0284)	Training Prec@1 100.000 (99.816)	Training Prec@5 100.000 (99.947)	
2022-04-04 00:29:25,610: ============================================================
2022-04-04 00:30:07,601: time cost, forward:0.01122405629358693, backward:0.05923326698716035, data cost:0.360077681665669 
2022-04-04 00:30:07,602: ============================================================
2022-04-04 00:30:07,602: Epoch 17/26 Batch 500/7662 eta: 8:52:45.062519	Training Loss 2.1709 (2.0423)	Training Prec@1 99.414 (99.820)	Training Prec@5 99.805 (99.945)	
2022-04-04 00:30:07,602: ============================================================
2022-04-04 00:30:49,537: time cost, forward:0.011056588368742215, backward:0.05944745727691905, data cost:0.35798124518736774 
2022-04-04 00:30:49,537: ============================================================
2022-04-04 00:30:49,538: Epoch 17/26 Batch 600/7662 eta: 8:51:19.818284	Training Loss 2.1065 (2.0551)	Training Prec@1 99.805 (99.811)	Training Prec@5 100.000 (99.945)	
2022-04-04 00:30:49,538: ============================================================
2022-04-04 00:31:31,185: time cost, forward:0.01108294972704886, backward:0.059495516259953356, data cost:0.35623202235231416 
2022-04-04 00:31:31,185: ============================================================
2022-04-04 00:31:31,185: Epoch 17/26 Batch 700/7662 eta: 8:46:59.429834	Training Loss 2.2073 (2.0656)	Training Prec@1 99.609 (99.814)	Training Prec@5 100.000 (99.947)	
2022-04-04 00:31:31,186: ============================================================
2022-04-04 00:32:10,730: time cost, forward:0.011055357315961052, backward:0.0596229072207951, data cost:0.3519694271016031 
2022-04-04 00:32:10,731: ============================================================
2022-04-04 00:32:10,731: Epoch 17/26 Batch 800/7662 eta: 8:19:43.897890	Training Loss 2.1762 (2.0733)	Training Prec@1 99.609 (99.811)	Training Prec@5 100.000 (99.948)	
2022-04-04 00:32:10,731: ============================================================
2022-04-04 00:32:50,194: time cost, forward:0.011007686345542764, backward:0.059740424553995274, data cost:0.3487963408596391 
2022-04-04 00:32:50,194: ============================================================
2022-04-04 00:32:50,195: Epoch 17/26 Batch 900/7662 eta: 8:18:02.233037	Training Loss 2.0651 (2.0840)	Training Prec@1 100.000 (99.810)	Training Prec@5 100.000 (99.949)	
2022-04-04 00:32:50,195: ============================================================
2022-04-04 00:33:31,106: time cost, forward:0.011347292421816348, backward:0.05940134890444644, data cost:0.34771831138236625 
2022-04-04 00:33:31,106: ============================================================
2022-04-04 00:33:31,107: Epoch 17/26 Batch 1000/7662 eta: 8:35:38.095748	Training Loss 2.0494 (2.0935)	Training Prec@1 100.000 (99.809)	Training Prec@5 100.000 (99.948)	
2022-04-04 00:33:31,107: ============================================================
2022-04-04 00:34:11,098: time cost, forward:0.011377877815947736, backward:0.05942393997997669, data cost:0.34581748413106767 
2022-04-04 00:34:11,099: ============================================================
2022-04-04 00:34:11,099: Epoch 17/26 Batch 1100/7662 eta: 8:23:22.525490	Training Loss 2.0717 (2.1017)	Training Prec@1 99.609 (99.804)	Training Prec@5 99.805 (99.947)	
2022-04-04 00:34:11,099: ============================================================
2022-04-04 00:34:50,351: time cost, forward:0.01131508626770834, backward:0.059487373258194594, data cost:0.3438359149999674 
2022-04-04 00:34:50,351: ============================================================
2022-04-04 00:34:50,351: Epoch 17/26 Batch 1200/7662 eta: 8:13:24.614042	Training Loss 1.9969 (2.1081)	Training Prec@1 100.000 (99.803)	Training Prec@5 100.000 (99.948)	
2022-04-04 00:34:50,352: ============================================================
2022-04-04 00:35:30,568: time cost, forward:0.01123820478132452, backward:0.05959364393291518, data cost:0.34276366655967894 
2022-04-04 00:35:30,568: ============================================================
2022-04-04 00:35:30,569: Epoch 17/26 Batch 1300/7662 eta: 8:24:52.036211	Training Loss 2.1424 (2.1150)	Training Prec@1 99.805 (99.800)	Training Prec@5 100.000 (99.948)	
2022-04-04 00:35:30,569: ============================================================
2022-04-04 00:36:12,408: time cost, forward:0.011188344157875394, backward:0.05965839904746982, data cost:0.34308597034348004 
2022-04-04 00:36:12,408: ============================================================
2022-04-04 00:36:12,408: Epoch 17/26 Batch 1400/7662 eta: 8:44:32.127919	Training Loss 2.0976 (2.1242)	Training Prec@1 100.000 (99.797)	Training Prec@5 100.000 (99.947)	
2022-04-04 00:36:12,408: ============================================================
2022-04-04 00:36:54,826: time cost, forward:0.011136705037193986, backward:0.05970931975661794, data cost:0.34373183342677266 
2022-04-04 00:36:54,826: ============================================================
2022-04-04 00:36:54,827: Epoch 17/26 Batch 1500/7662 eta: 8:51:05.212628	Training Loss 2.3200 (2.1319)	Training Prec@1 99.805 (99.796)	Training Prec@5 99.805 (99.946)	
2022-04-04 00:36:54,827: ============================================================
2022-04-04 00:37:36,949: time cost, forward:0.011131007646008384, backward:0.05973419478120023, data cost:0.3441126662690316 
2022-04-04 00:37:36,949: ============================================================
2022-04-04 00:37:36,950: Epoch 17/26 Batch 1600/7662 eta: 8:46:40.948734	Training Loss 2.2712 (2.1388)	Training Prec@1 99.609 (99.793)	Training Prec@5 99.805 (99.946)	
2022-04-04 00:37:36,950: ============================================================
2022-04-04 00:38:17,694: time cost, forward:0.011127822745751465, backward:0.05974272210995123, data cost:0.3436256611326149 
2022-04-04 00:38:17,694: ============================================================
2022-04-04 00:38:17,694: Epoch 17/26 Batch 1700/7662 eta: 8:28:46.280029	Training Loss 2.1302 (2.1455)	Training Prec@1 99.805 (99.791)	Training Prec@5 100.000 (99.945)	
2022-04-04 00:38:17,694: ============================================================
2022-04-04 00:38:57,471: time cost, forward:0.011078558344520284, backward:0.059767951164860535, data cost:0.34268348637125506 
2022-04-04 00:38:57,472: ============================================================
2022-04-04 00:38:57,472: Epoch 17/26 Batch 1800/7662 eta: 8:16:02.109625	Training Loss 2.2829 (2.1513)	Training Prec@1 100.000 (99.788)	Training Prec@5 100.000 (99.945)	
2022-04-04 00:38:57,472: ============================================================
2022-04-04 00:39:38,618: time cost, forward:0.011129391701865535, backward:0.05973205671867865, data cost:0.3425118832791586 
2022-04-04 00:39:38,619: ============================================================
2022-04-04 00:39:38,619: Epoch 17/26 Batch 1900/7662 eta: 8:32:25.455448	Training Loss 2.1925 (2.1584)	Training Prec@1 100.000 (99.786)	Training Prec@5 100.000 (99.944)	
2022-04-04 00:39:38,619: ============================================================
2022-04-04 00:40:19,811: time cost, forward:0.011118410228788405, backward:0.05973569615713771, data cost:0.3424269684318783 
2022-04-04 00:40:19,812: ============================================================
2022-04-04 00:40:19,812: Epoch 17/26 Batch 2000/7662 eta: 8:32:18.565964	Training Loss 2.3357 (2.1642)	Training Prec@1 99.414 (99.783)	Training Prec@5 100.000 (99.943)	
2022-04-04 00:40:19,812: ============================================================
2022-04-04 00:41:01,572: time cost, forward:0.011114975905179864, backward:0.05970447412157354, data cost:0.3426449946303093 
2022-04-04 00:41:01,573: ============================================================
2022-04-04 00:41:01,573: Epoch 17/26 Batch 2100/7662 eta: 8:38:40.720079	Training Loss 2.2241 (2.1695)	Training Prec@1 99.805 (99.782)	Training Prec@5 100.000 (99.942)	
2022-04-04 00:41:01,573: ============================================================
2022-04-04 00:41:41,993: time cost, forward:0.011118363770315354, backward:0.059669659429379296, data cost:0.3421918828685807 
2022-04-04 00:41:41,994: ============================================================
2022-04-04 00:41:41,994: Epoch 17/26 Batch 2200/7662 eta: 8:21:22.005888	Training Loss 2.0578 (2.1742)	Training Prec@1 100.000 (99.782)	Training Prec@5 100.000 (99.942)	
2022-04-04 00:41:41,995: ============================================================
2022-04-04 00:42:22,695: time cost, forward:0.011178060115135561, backward:0.05960003994713145, data cost:0.34192084975738324 
2022-04-04 00:42:22,695: ============================================================
2022-04-04 00:42:22,696: Epoch 17/26 Batch 2300/7662 eta: 8:24:09.640037	Training Loss 2.2869 (2.1803)	Training Prec@1 100.000 (99.780)	Training Prec@5 100.000 (99.941)	
2022-04-04 00:42:22,696: ============================================================
2022-04-04 00:43:04,594: time cost, forward:0.011147183346321008, backward:0.05960576620734001, data cost:0.34220094718551475 
2022-04-04 00:43:04,595: ============================================================
2022-04-04 00:43:04,595: Epoch 17/26 Batch 2400/7662 eta: 8:38:18.405126	Training Loss 2.2450 (2.1861)	Training Prec@1 99.805 (99.776)	Training Prec@5 100.000 (99.939)	
2022-04-04 00:43:04,596: ============================================================
2022-04-04 00:43:46,177: time cost, forward:0.011149106191701534, backward:0.059564674601835364, data cost:0.34233743842003966 
2022-04-04 00:43:46,177: ============================================================
2022-04-04 00:43:46,177: Epoch 17/26 Batch 2500/7662 eta: 8:33:41.068808	Training Loss 2.2970 (2.1919)	Training Prec@1 100.000 (99.774)	Training Prec@5 100.000 (99.938)	
2022-04-04 00:43:46,178: ============================================================
2022-04-04 00:44:26,876: time cost, forward:0.011116973800629825, backward:0.05957431479480093, data cost:0.34210014765241503 
2022-04-04 00:44:26,877: ============================================================
2022-04-04 00:44:26,877: Epoch 17/26 Batch 2600/7662 eta: 8:22:06.144132	Training Loss 2.2472 (2.1963)	Training Prec@1 99.805 (99.771)	Training Prec@5 100.000 (99.937)	
2022-04-04 00:44:26,877: ============================================================
2022-04-04 00:45:08,351: time cost, forward:0.01114556841516371, backward:0.05953948556957266, data cost:0.3421718964712758 
2022-04-04 00:45:08,351: ============================================================
2022-04-04 00:45:08,351: Epoch 17/26 Batch 2700/7662 eta: 8:30:58.267640	Training Loss 2.2767 (2.2015)	Training Prec@1 99.805 (99.770)	Training Prec@5 99.805 (99.937)	
2022-04-04 00:45:08,351: ============================================================
2022-04-04 00:45:47,560: time cost, forward:0.011140113645214913, backward:0.05952839580507268, data cost:0.34141401922587794 
2022-04-04 00:45:47,560: ============================================================
2022-04-04 00:45:47,560: Epoch 17/26 Batch 2800/7662 eta: 8:02:24.503604	Training Loss 2.2899 (2.2062)	Training Prec@1 99.609 (99.768)	Training Prec@5 100.000 (99.937)	
2022-04-04 00:45:47,561: ============================================================
2022-04-04 00:46:28,646: time cost, forward:0.011106063678948046, backward:0.0595666433704767, data cost:0.34133410478468884 
2022-04-04 00:46:28,646: ============================================================
2022-04-04 00:46:28,647: Epoch 17/26 Batch 2900/7662 eta: 8:24:49.165059	Training Loss 2.4052 (2.2108)	Training Prec@1 99.805 (99.767)	Training Prec@5 100.000 (99.936)	
2022-04-04 00:46:28,647: ============================================================
2022-04-04 00:47:09,620: time cost, forward:0.01112082601587309, backward:0.05955084000638661, data cost:0.34126643325218003 
2022-04-04 00:47:09,620: ============================================================
2022-04-04 00:47:09,620: Epoch 17/26 Batch 3000/7662 eta: 8:22:45.253504	Training Loss 2.3242 (2.2142)	Training Prec@1 99.609 (99.766)	Training Prec@5 99.805 (99.936)	
2022-04-04 00:47:09,620: ============================================================
2022-04-04 00:47:50,659: time cost, forward:0.011103259551598204, backward:0.05956184467833901, data cost:0.341178435054507 
2022-04-04 00:47:50,659: ============================================================
2022-04-04 00:47:50,659: Epoch 17/26 Batch 3100/7662 eta: 8:22:52.323531	Training Loss 2.4250 (2.2185)	Training Prec@1 99.805 (99.765)	Training Prec@5 100.000 (99.935)	
2022-04-04 00:47:50,660: ============================================================
2022-04-04 00:48:31,123: time cost, forward:0.011089583865252462, backward:0.05956083336782739, data cost:0.3409668255985137 
2022-04-04 00:48:31,123: ============================================================
2022-04-04 00:48:31,123: Epoch 17/26 Batch 3200/7662 eta: 8:15:09.077456	Training Loss 2.3062 (2.2230)	Training Prec@1 99.805 (99.762)	Training Prec@5 99.805 (99.934)	
2022-04-04 00:48:31,124: ============================================================
2022-04-04 00:49:12,191: time cost, forward:0.011070204995263162, backward:0.0595814253785965, data cost:0.3409159614231125 
2022-04-04 00:49:12,192: ============================================================
2022-04-04 00:49:12,192: Epoch 17/26 Batch 3300/7662 eta: 8:21:52.070036	Training Loss 2.5835 (2.2272)	Training Prec@1 99.414 (99.761)	Training Prec@5 99.609 (99.933)	
2022-04-04 00:49:12,192: ============================================================
2022-04-04 00:49:53,185: time cost, forward:0.01104765150188593, backward:0.059596721198005374, data cost:0.3408569524343591 
2022-04-04 00:49:53,185: ============================================================
2022-04-04 00:49:53,186: Epoch 17/26 Batch 3400/7662 eta: 8:20:15.821477	Training Loss 2.4089 (2.2309)	Training Prec@1 99.805 (99.760)	Training Prec@5 100.000 (99.932)	
2022-04-04 00:49:53,186: ============================================================
2022-04-04 00:50:33,720: time cost, forward:0.011029470236037724, backward:0.05961260348601013, data cost:0.3406711128242495 
2022-04-04 00:50:33,721: ============================================================
2022-04-04 00:50:33,721: Epoch 17/26 Batch 3500/7662 eta: 8:13:59.849151	Training Loss 2.4311 (2.2338)	Training Prec@1 99.609 (99.759)	Training Prec@5 100.000 (99.932)	
2022-04-04 00:50:33,721: ============================================================
2022-04-04 00:51:13,799: time cost, forward:0.011024612425167914, backward:0.05962180905820397, data cost:0.34034992708501366 
2022-04-04 00:51:13,799: ============================================================
2022-04-04 00:51:13,799: Epoch 17/26 Batch 3600/7662 eta: 8:07:45.473596	Training Loss 2.6062 (2.2365)	Training Prec@1 99.219 (99.757)	Training Prec@5 100.000 (99.932)	
2022-04-04 00:51:13,799: ============================================================
2022-04-04 00:51:54,182: time cost, forward:0.011030934120584547, backward:0.059613900559758716, data cost:0.3401446376629345 
2022-04-04 00:51:54,183: ============================================================
2022-04-04 00:51:54,183: Epoch 17/26 Batch 3700/7662 eta: 8:10:48.212925	Training Loss 2.1114 (2.2404)	Training Prec@1 99.414 (99.754)	Training Prec@5 99.805 (99.931)	
2022-04-04 00:51:54,183: ============================================================
2022-04-04 00:52:34,756: time cost, forward:0.011013492153455911, backward:0.05963633775271752, data cost:0.3399888819598875 
2022-04-04 00:52:34,756: ============================================================
2022-04-04 00:52:34,757: Epoch 17/26 Batch 3800/7662 eta: 8:12:26.212064	Training Loss 2.4455 (2.2440)	Training Prec@1 99.609 (99.752)	Training Prec@5 99.805 (99.931)	
2022-04-04 00:52:34,757: ============================================================
2022-04-04 00:53:14,238: time cost, forward:0.011072917912794585, backward:0.05957590546110221, data cost:0.3395787945586188 
2022-04-04 00:53:14,238: ============================================================
2022-04-04 00:53:14,238: Epoch 17/26 Batch 3900/7662 eta: 7:58:31.539550	Training Loss 2.4272 (2.2470)	Training Prec@1 99.805 (99.751)	Training Prec@5 100.000 (99.931)	
2022-04-04 00:53:14,239: ============================================================
2022-04-04 00:53:55,907: time cost, forward:0.011047717242516348, backward:0.05960439985828061, data cost:0.3397195809601128 
2022-04-04 00:53:55,907: ============================================================
2022-04-04 00:53:55,907: Epoch 17/26 Batch 4000/7662 eta: 8:24:20.393175	Training Loss 2.4040 (2.2499)	Training Prec@1 99.805 (99.750)	Training Prec@5 99.805 (99.930)	
2022-04-04 00:53:55,907: ============================================================
2022-04-04 00:54:36,025: time cost, forward:0.0110689403662364, backward:0.059584443294062615, data cost:0.3394837149703581 
2022-04-04 00:54:36,025: ============================================================
2022-04-04 00:54:36,026: Epoch 17/26 Batch 4100/7662 eta: 8:04:54.245742	Training Loss 2.2613 (2.2528)	Training Prec@1 99.414 (99.748)	Training Prec@5 100.000 (99.930)	
2022-04-04 00:54:36,026: ============================================================
2022-04-04 00:55:18,343: time cost, forward:0.011060303522025043, backward:0.059581826431009136, data cost:0.3397926550077296 
2022-04-04 00:55:18,343: ============================================================
2022-04-04 00:55:18,344: Epoch 17/26 Batch 4200/7662 eta: 8:30:47.048044	Training Loss 2.4242 (2.2560)	Training Prec@1 100.000 (99.747)	Training Prec@5 100.000 (99.930)	
2022-04-04 00:55:18,344: ============================================================
2022-04-04 00:55:58,849: time cost, forward:0.011045755134346486, backward:0.059593230520578064, data cost:0.33966666106485605 
2022-04-04 00:55:58,850: ============================================================
2022-04-04 00:55:58,850: Epoch 17/26 Batch 4300/7662 eta: 8:08:14.592068	Training Loss 2.4656 (2.2589)	Training Prec@1 99.414 (99.745)	Training Prec@5 99.609 (99.929)	
2022-04-04 00:55:58,850: ============================================================
2022-04-04 00:56:38,761: time cost, forward:0.01106459808826555, backward:0.05956506539431722, data cost:0.33938279664632975 
2022-04-04 00:56:38,761: ============================================================
2022-04-04 00:56:38,761: Epoch 17/26 Batch 4400/7662 eta: 8:00:24.440490	Training Loss 2.4100 (2.2616)	Training Prec@1 99.805 (99.744)	Training Prec@5 99.805 (99.929)	
2022-04-04 00:56:38,762: ============================================================
2022-04-04 00:57:19,687: time cost, forward:0.01105488393274406, backward:0.05957476767891644, data cost:0.33930977595385037 
2022-04-04 00:57:19,687: ============================================================
2022-04-04 00:57:19,687: Epoch 17/26 Batch 4500/7662 eta: 8:11:56.155946	Training Loss 2.2751 (2.2642)	Training Prec@1 99.609 (99.742)	Training Prec@5 99.805 (99.929)	
2022-04-04 00:57:19,687: ============================================================
2022-04-04 00:58:01,154: time cost, forward:0.011040619804330897, backward:0.05958574319513084, data cost:0.3394530314055441 
2022-04-04 00:58:01,155: ============================================================
2022-04-04 00:58:01,155: Epoch 17/26 Batch 4600/7662 eta: 8:17:45.450331	Training Loss 2.4038 (2.2669)	Training Prec@1 100.000 (99.740)	Training Prec@5 100.000 (99.929)	
2022-04-04 00:58:01,155: ============================================================
2022-04-04 00:58:42,496: time cost, forward:0.011026781197430403, backward:0.05960014820809211, data cost:0.339529746338316 
2022-04-04 00:58:42,496: ============================================================
2022-04-04 00:58:42,497: Epoch 17/26 Batch 4700/7662 eta: 8:15:33.292437	Training Loss 2.3780 (2.2691)	Training Prec@1 100.000 (99.739)	Training Prec@5 100.000 (99.928)	
2022-04-04 00:58:42,497: ============================================================
2022-04-04 00:59:23,957: time cost, forward:0.011020443742040248, backward:0.05961027466324276, data cost:0.33959067218078626 
2022-04-04 00:59:23,957: ============================================================
2022-04-04 00:59:23,958: Epoch 17/26 Batch 4800/7662 eta: 8:16:17.676189	Training Loss 2.3560 (2.2714)	Training Prec@1 99.609 (99.737)	Training Prec@5 99.805 (99.927)	
2022-04-04 00:59:23,958: ============================================================
2022-04-04 01:00:06,180: time cost, forward:0.011007835388572928, backward:0.059622906159079544, data cost:0.3398280699999144 
2022-04-04 01:00:06,180: ============================================================
2022-04-04 01:00:06,180: Epoch 17/26 Batch 4900/7662 eta: 8:24:42.536084	Training Loss 2.4762 (2.2737)	Training Prec@1 100.000 (99.736)	Training Prec@5 100.000 (99.927)	
2022-04-04 01:00:06,180: ============================================================
2022-04-04 01:00:46,651: time cost, forward:0.010993620900541193, backward:0.0596346687760251, data cost:0.33970166650097905 
2022-04-04 01:00:46,652: ============================================================
2022-04-04 01:00:46,652: Epoch 17/26 Batch 5000/7662 eta: 8:03:06.228539	Training Loss 2.4464 (2.2760)	Training Prec@1 99.805 (99.734)	Training Prec@5 99.805 (99.926)	
2022-04-04 01:00:46,652: ============================================================
2022-04-04 01:01:26,167: time cost, forward:0.010975883530270564, backward:0.059657179063197376, data cost:0.3393869486994125 
2022-04-04 01:01:26,167: ============================================================
2022-04-04 01:01:26,167: Epoch 17/26 Batch 5100/7662 eta: 7:51:01.683684	Training Loss 2.2875 (2.2782)	Training Prec@1 99.609 (99.731)	Training Prec@5 100.000 (99.925)	
2022-04-04 01:01:26,167: ============================================================
2022-04-04 01:02:07,348: time cost, forward:0.010962188369976967, backward:0.05967796928815187, data cost:0.3393863258647974 
2022-04-04 01:02:07,348: ============================================================
2022-04-04 01:02:07,349: Epoch 17/26 Batch 5200/7662 eta: 8:10:12.171143	Training Loss 2.2840 (2.2803)	Training Prec@1 99.609 (99.730)	Training Prec@5 99.609 (99.925)	
2022-04-04 01:02:07,349: ============================================================
2022-04-04 01:02:47,436: time cost, forward:0.01095940095340335, backward:0.05967538314937398, data cost:0.3392415187970313 
2022-04-04 01:02:47,436: ============================================================
2022-04-04 01:02:47,437: Epoch 17/26 Batch 5300/7662 eta: 7:56:31.131744	Training Loss 2.4278 (2.2827)	Training Prec@1 99.609 (99.729)	Training Prec@5 100.000 (99.925)	
2022-04-04 01:02:47,437: ============================================================
2022-04-04 01:03:28,047: time cost, forward:0.010953267297605205, backward:0.05967785566244816, data cost:0.3391491729123744 
2022-04-04 01:03:28,047: ============================================================
2022-04-04 01:03:28,047: Epoch 17/26 Batch 5400/7662 eta: 8:02:03.516884	Training Loss 2.2524 (2.2849)	Training Prec@1 99.805 (99.727)	Training Prec@5 100.000 (99.924)	
2022-04-04 01:03:28,048: ============================================================
2022-04-04 01:04:07,610: time cost, forward:0.01094760212340687, backward:0.059689657235930324, data cost:0.33887537853742516 
2022-04-04 01:04:07,610: ============================================================
2022-04-04 01:04:07,610: Epoch 17/26 Batch 5500/7662 eta: 7:48:57.469621	Training Loss 2.4808 (2.2868)	Training Prec@1 100.000 (99.726)	Training Prec@5 100.000 (99.923)	
2022-04-04 01:04:07,611: ============================================================
2022-04-04 01:04:49,106: time cost, forward:0.010935784195295124, backward:0.05970327278017295, data cost:0.33896829992942584 
2022-04-04 01:04:49,107: ============================================================
2022-04-04 01:04:49,107: Epoch 17/26 Batch 5600/7662 eta: 8:11:11.340863	Training Loss 2.2749 (2.2888)	Training Prec@1 99.805 (99.725)	Training Prec@5 99.805 (99.923)	
2022-04-04 01:04:49,107: ============================================================
2022-04-04 01:05:29,090: time cost, forward:0.010928454786502471, backward:0.05971800040562836, data cost:0.33876937944693697 
2022-04-04 01:05:29,090: ============================================================
2022-04-04 01:05:29,090: Epoch 17/26 Batch 5700/7662 eta: 7:52:36.579676	Training Loss 2.3219 (2.2908)	Training Prec@1 99.414 (99.723)	Training Prec@5 99.805 (99.923)	
2022-04-04 01:05:29,091: ============================================================
2022-04-04 01:06:10,686: time cost, forward:0.010922455915111286, backward:0.05972840280692358, data cost:0.33887031473441664 
2022-04-04 01:06:10,686: ============================================================
2022-04-04 01:06:10,686: Epoch 17/26 Batch 5800/7662 eta: 8:10:58.726937	Training Loss 2.4043 (2.2924)	Training Prec@1 99.805 (99.722)	Training Prec@5 100.000 (99.922)	
2022-04-04 01:06:10,687: ============================================================
2022-04-04 01:06:52,050: time cost, forward:0.010910958996423727, backward:0.059738607805933985, data cost:0.3389312334233653 
2022-04-04 01:06:52,050: ============================================================
2022-04-04 01:06:52,051: Epoch 17/26 Batch 5900/7662 eta: 8:07:33.150672	Training Loss 2.4362 (2.2945)	Training Prec@1 99.219 (99.721)	Training Prec@5 100.000 (99.921)	
2022-04-04 01:06:52,051: ============================================================
2022-04-04 01:07:32,516: time cost, forward:0.010900578353380756, backward:0.05975151904564457, data cost:0.33883843049941054 
2022-04-04 01:07:32,516: ============================================================
2022-04-04 01:07:32,517: Epoch 17/26 Batch 6000/7662 eta: 7:56:17.487518	Training Loss 2.5632 (2.2962)	Training Prec@1 99.414 (99.719)	Training Prec@5 99.609 (99.921)	
2022-04-04 01:07:32,517: ============================================================
2022-04-04 01:08:13,350: time cost, forward:0.010892896696004071, backward:0.05976068119393702, data cost:0.3388091457693435 
2022-04-04 01:08:13,351: ============================================================
2022-04-04 01:08:13,351: Epoch 17/26 Batch 6100/7662 eta: 7:59:56.788846	Training Loss 2.3484 (2.2981)	Training Prec@1 99.805 (99.719)	Training Prec@5 100.000 (99.921)	
2022-04-04 01:08:13,351: ============================================================
2022-04-04 01:08:53,238: time cost, forward:0.010885541949431383, backward:0.059764901329036835, data cost:0.33862580747676674 
2022-04-04 01:08:53,238: ============================================================
2022-04-04 01:08:53,238: Epoch 17/26 Batch 6200/7662 eta: 7:48:09.081379	Training Loss 2.3855 (2.2998)	Training Prec@1 99.609 (99.717)	Training Prec@5 100.000 (99.921)	
2022-04-04 01:08:53,238: ============================================================
2022-04-04 01:09:34,861: time cost, forward:0.010904309824925223, backward:0.059746576464541436, data cost:0.3387343642408459 
2022-04-04 01:09:34,862: ============================================================
2022-04-04 01:09:34,862: Epoch 17/26 Batch 6300/7662 eta: 8:07:50.070230	Training Loss 2.2442 (2.3015)	Training Prec@1 99.609 (99.716)	Training Prec@5 99.805 (99.921)	
2022-04-04 01:09:34,862: ============================================================
2022-04-04 01:10:15,093: time cost, forward:0.010908297103426385, backward:0.05973103859030021, data cost:0.338635502727465 
2022-04-04 01:10:15,094: ============================================================
2022-04-04 01:10:15,094: Epoch 17/26 Batch 6400/7662 eta: 7:50:51.378595	Training Loss 2.2735 (2.3031)	Training Prec@1 99.805 (99.715)	Training Prec@5 100.000 (99.921)	
2022-04-04 01:10:15,094: ============================================================
2022-04-04 01:10:55,051: time cost, forward:0.010898241613035589, backward:0.05973237814362516, data cost:0.33848889887672257 
2022-04-04 01:10:55,052: ============================================================
2022-04-04 01:10:55,052: Epoch 17/26 Batch 6500/7662 eta: 7:46:59.127190	Training Loss 2.3113 (2.3045)	Training Prec@1 100.000 (99.714)	Training Prec@5 100.000 (99.920)	
2022-04-04 01:10:55,052: ============================================================
2022-04-04 01:11:34,193: time cost, forward:0.01089124080538298, backward:0.059745071150711364, data cost:0.3381942596051129 
2022-04-04 01:11:34,194: ============================================================
2022-04-04 01:11:34,194: Epoch 17/26 Batch 6600/7662 eta: 7:36:47.438659	Training Loss 2.2227 (2.3060)	Training Prec@1 99.609 (99.713)	Training Prec@5 100.000 (99.920)	
2022-04-04 01:11:34,194: ============================================================
2022-04-04 01:12:15,779: time cost, forward:0.01089021653840036, backward:0.05974439827964135, data cost:0.33829013026104093 
2022-04-04 01:12:15,779: ============================================================
2022-04-04 01:12:15,780: Epoch 17/26 Batch 6700/7662 eta: 8:04:37.297691	Training Loss 2.4068 (2.3075)	Training Prec@1 99.219 (99.712)	Training Prec@5 99.805 (99.920)	
2022-04-04 01:12:15,780: ============================================================
2022-04-04 01:12:57,080: time cost, forward:0.010913566309382835, backward:0.05971488161531682, data cost:0.3383527456758513 
2022-04-04 01:12:57,080: ============================================================
2022-04-04 01:12:57,080: Epoch 17/26 Batch 6800/7662 eta: 8:00:36.498954	Training Loss 2.5056 (2.3090)	Training Prec@1 99.805 (99.711)	Training Prec@5 100.000 (99.919)	
2022-04-04 01:12:57,081: ============================================================
2022-04-04 01:13:37,316: time cost, forward:0.010909833118766612, backward:0.059720678007383246, data cost:0.33824582282383037 
2022-04-04 01:13:37,317: ============================================================
2022-04-04 01:13:37,317: Epoch 17/26 Batch 6900/7662 eta: 7:47:33.473864	Training Loss 2.3582 (2.3102)	Training Prec@1 99.219 (99.710)	Training Prec@5 99.414 (99.919)	
2022-04-04 01:13:37,317: ============================================================
2022-04-04 01:14:18,946: time cost, forward:0.010901997644299354, backward:0.05973426102399656, data cost:0.3383384088155695 
2022-04-04 01:14:18,946: ============================================================
2022-04-04 01:14:18,947: Epoch 17/26 Batch 7000/7662 eta: 8:03:02.759601	Training Loss 2.4257 (2.3116)	Training Prec@1 99.805 (99.709)	Training Prec@5 100.000 (99.919)	
2022-04-04 01:14:18,947: ============================================================
2022-04-04 01:15:00,548: time cost, forward:0.010889677182606097, backward:0.059750160913699814, data cost:0.3384130105852728 
2022-04-04 01:15:00,549: ============================================================
2022-04-04 01:15:00,549: Epoch 17/26 Batch 7100/7662 eta: 8:02:02.400239	Training Loss 2.5754 (2.3131)	Training Prec@1 99.414 (99.708)	Training Prec@5 100.000 (99.918)	
2022-04-04 01:15:00,549: ============================================================
2022-04-04 01:15:41,371: time cost, forward:0.010881821767110464, backward:0.059758017933820747, data cost:0.3383886644882963 
2022-04-04 01:15:41,371: ============================================================
2022-04-04 01:15:41,371: Epoch 17/26 Batch 7200/7662 eta: 7:52:19.432738	Training Loss 2.3924 (2.3147)	Training Prec@1 99.609 (99.706)	Training Prec@5 100.000 (99.918)	
2022-04-04 01:15:41,372: ============================================================
2022-04-04 01:16:22,537: time cost, forward:0.01087075309371896, backward:0.05977148466819704, data cost:0.3384395908829218 
2022-04-04 01:16:22,538: ============================================================
2022-04-04 01:16:22,538: Epoch 17/26 Batch 7300/7662 eta: 7:55:37.080102	Training Loss 2.4670 (2.3160)	Training Prec@1 99.609 (99.706)	Training Prec@5 99.805 (99.918)	
2022-04-04 01:16:22,538: ============================================================
2022-04-04 01:17:04,097: time cost, forward:0.010863959813443434, backward:0.0597791543182835, data cost:0.3385058830422088 
2022-04-04 01:17:04,097: ============================================================
2022-04-04 01:17:04,097: Epoch 17/26 Batch 7400/7662 eta: 7:59:27.757734	Training Loss 2.3451 (2.3170)	Training Prec@1 100.000 (99.705)	Training Prec@5 100.000 (99.918)	
2022-04-04 01:17:04,098: ============================================================
2022-04-04 01:17:44,733: time cost, forward:0.010858606634052265, backward:0.059783901051054446, data cost:0.3384650048613151 
2022-04-04 01:17:44,734: ============================================================
2022-04-04 01:17:44,734: Epoch 17/26 Batch 7500/7662 eta: 7:48:08.406665	Training Loss 2.4867 (2.3182)	Training Prec@1 99.609 (99.704)	Training Prec@5 99.805 (99.917)	
2022-04-04 01:17:44,734: ============================================================
2022-04-04 01:18:24,470: time cost, forward:0.010858273314777088, backward:0.05978167792780962, data cost:0.3383086656077722 
2022-04-04 01:18:24,471: ============================================================
2022-04-04 01:18:24,471: Epoch 17/26 Batch 7600/7662 eta: 7:37:06.823584	Training Loss 2.2654 (2.3193)	Training Prec@1 100.000 (99.703)	Training Prec@5 100.000 (99.917)	
2022-04-04 01:18:24,471: ============================================================
2022-04-04 01:18:51,136: Epoch: 17/26 eta: 7:36:41.789321	Training Loss 2.3126 (2.3200)	Training Prec@1 99.805 (99.702)	Training Prec@5 99.805 (99.917)
2022-04-04 01:18:51,136: ============================================================
2022-04-04 01:19:33,545: time cost, forward:0.011369062192512281, backward:0.05882295454391325, data cost:0.35318100813663367 
2022-04-04 01:19:33,546: ============================================================
2022-04-04 01:19:33,546: Epoch 18/26 Batch 100/7662 eta: 8:05:50.095207	Training Loss 1.9142 (1.9734)	Training Prec@1 99.805 (99.836)	Training Prec@5 100.000 (99.963)	
2022-04-04 01:19:33,546: ============================================================
2022-04-04 01:20:15,057: time cost, forward:0.011390289469579956, backward:0.05842726434295501, data cost:0.34934952510661216 
2022-04-04 01:20:15,058: ============================================================
2022-04-04 01:20:15,058: Epoch 18/26 Batch 200/7662 eta: 7:55:43.092203	Training Loss 1.9630 (1.9790)	Training Prec@1 99.805 (99.854)	Training Prec@5 100.000 (99.965)	
2022-04-04 01:20:15,058: ============================================================
2022-04-04 01:20:55,259: time cost, forward:0.011065068452254585, backward:0.05863152379574983, data cost:0.3435764496143048 
2022-04-04 01:20:55,259: ============================================================
2022-04-04 01:20:55,259: Epoch 18/26 Batch 300/7662 eta: 7:40:01.920179	Training Loss 2.0977 (1.9952)	Training Prec@1 100.000 (99.858)	Training Prec@5 100.000 (99.964)	
2022-04-04 01:20:55,260: ============================================================
2022-04-04 01:21:35,465: time cost, forward:0.010846844293121109, backward:0.05888507180942927, data cost:0.3406245863826054 
2022-04-04 01:21:35,465: ============================================================
2022-04-04 01:21:35,466: Epoch 18/26 Batch 400/7662 eta: 7:39:24.894533	Training Loss 1.9529 (2.0096)	Training Prec@1 99.805 (99.853)	Training Prec@5 100.000 (99.958)	
2022-04-04 01:21:35,466: ============================================================
2022-04-04 01:22:17,535: time cost, forward:0.010654078695721521, backward:0.059122261399018744, data cost:0.3425546820034723 
2022-04-04 01:22:17,535: ============================================================
2022-04-04 01:22:17,535: Epoch 18/26 Batch 500/7662 eta: 8:00:00.415784	Training Loss 2.1981 (2.0160)	Training Prec@1 99.805 (99.843)	Training Prec@5 100.000 (99.959)	
2022-04-04 01:22:17,535: ============================================================
2022-04-04 01:22:59,732: time cost, forward:0.010550631903646784, backward:0.059216494950308826, data cost:0.34408108101464274 
2022-04-04 01:22:59,732: ============================================================
2022-04-04 01:22:59,733: Epoch 18/26 Batch 600/7662 eta: 8:00:45.846714	Training Loss 2.0141 (2.0260)	Training Prec@1 99.805 (99.844)	Training Prec@5 100.000 (99.960)	
2022-04-04 01:22:59,733: ============================================================
2022-04-04 01:23:41,259: time cost, forward:0.010493447340609178, backward:0.05927439650070343, data cost:0.34420936097402943 
2022-04-04 01:23:41,259: ============================================================
2022-04-04 01:23:41,260: Epoch 18/26 Batch 700/7662 eta: 7:52:25.837268	Training Loss 2.0619 (2.0290)	Training Prec@1 100.000 (99.845)	Training Prec@5 100.000 (99.962)	
2022-04-04 01:23:41,260: ============================================================
2022-04-04 01:24:21,696: time cost, forward:0.010447389640855849, backward:0.059339992394286195, data cost:0.34293482479673154 
2022-04-04 01:24:21,696: ============================================================
2022-04-04 01:24:21,697: Epoch 18/26 Batch 800/7662 eta: 7:39:21.512869	Training Loss 2.0271 (2.0387)	Training Prec@1 99.414 (99.840)	Training Prec@5 100.000 (99.960)	
2022-04-04 01:24:21,697: ============================================================
2022-04-04 01:25:02,356: time cost, forward:0.010359170572113274, backward:0.05945569787327785, data cost:0.34217727197555864 
2022-04-04 01:25:02,356: ============================================================
2022-04-04 01:25:02,357: Epoch 18/26 Batch 900/7662 eta: 7:41:12.699726	Training Loss 2.1043 (2.0497)	Training Prec@1 100.000 (99.835)	Training Prec@5 100.000 (99.958)	
2022-04-04 01:25:02,357: ============================================================
2022-04-04 01:25:42,498: time cost, forward:0.01035743575912338, backward:0.05945667347034535, data cost:0.34104325200940994 
2022-04-04 01:25:42,498: ============================================================
2022-04-04 01:25:42,499: Epoch 18/26 Batch 1000/7662 eta: 7:34:40.141125	Training Loss 1.9567 (2.0601)	Training Prec@1 100.000 (99.833)	Training Prec@5 100.000 (99.958)	
2022-04-04 01:25:42,499: ============================================================
2022-04-04 01:26:21,922: time cost, forward:0.010360611689101577, backward:0.05948792727455646, data cost:0.3394617776202548 
2022-04-04 01:26:21,922: ============================================================
2022-04-04 01:26:21,922: Epoch 18/26 Batch 1100/7662 eta: 7:25:52.604849	Training Loss 2.1165 (2.0727)	Training Prec@1 100.000 (99.825)	Training Prec@5 100.000 (99.955)	
2022-04-04 01:26:21,923: ============================================================
2022-04-04 01:27:03,015: time cost, forward:0.010308295513213526, backward:0.05963443675768982, data cost:0.33942993607890914 
2022-04-04 01:27:03,015: ============================================================
2022-04-04 01:27:03,016: Epoch 18/26 Batch 1200/7662 eta: 7:44:04.446536	Training Loss 2.2125 (2.0817)	Training Prec@1 99.609 (99.825)	Training Prec@5 100.000 (99.954)	
2022-04-04 01:27:03,016: ============================================================
2022-04-04 01:27:43,611: time cost, forward:0.010274180639148034, backward:0.059734732669715795, data cost:0.3390638541955045 
2022-04-04 01:27:43,612: ============================================================
2022-04-04 01:27:43,612: Epoch 18/26 Batch 1300/7662 eta: 7:37:46.816316	Training Loss 2.2523 (2.0904)	Training Prec@1 99.805 (99.821)	Training Prec@5 100.000 (99.953)	
2022-04-04 01:27:43,612: ============================================================
2022-04-04 01:28:24,096: time cost, forward:0.010241678904600872, backward:0.05983167601279313, data cost:0.33870545568595706 
2022-04-04 01:28:24,097: ============================================================
2022-04-04 01:28:24,097: Epoch 18/26 Batch 1400/7662 eta: 7:35:51.340166	Training Loss 2.0659 (2.0992)	Training Prec@1 99.609 (99.818)	Training Prec@5 99.805 (99.952)	
2022-04-04 01:28:24,097: ============================================================
2022-04-04 01:29:05,366: time cost, forward:0.010206642430809994, backward:0.05991960462528201, data cost:0.33887538820843127 
2022-04-04 01:29:05,366: ============================================================
2022-04-04 01:29:05,367: Epoch 18/26 Batch 1500/7662 eta: 7:44:00.109426	Training Loss 2.2946 (2.1085)	Training Prec@1 100.000 (99.815)	Training Prec@5 100.000 (99.952)	
2022-04-04 01:29:05,367: ============================================================
2022-04-04 01:29:44,509: time cost, forward:0.010167152155481926, backward:0.059982264019534916, data cost:0.3376953275297641 
2022-04-04 01:29:44,510: ============================================================
2022-04-04 01:29:44,510: Epoch 18/26 Batch 1600/7662 eta: 7:19:26.634252	Training Loss 2.3310 (2.1165)	Training Prec@1 99.414 (99.813)	Training Prec@5 100.000 (99.952)	
2022-04-04 01:29:44,510: ============================================================
2022-04-04 01:30:26,087: time cost, forward:0.010207486054418787, backward:0.05990644719335456, data cost:0.3381687480607687 
2022-04-04 01:30:26,088: ============================================================
2022-04-04 01:30:26,088: Epoch 18/26 Batch 1700/7662 eta: 7:46:04.885970	Training Loss 2.1933 (2.1237)	Training Prec@1 99.805 (99.810)	Training Prec@5 100.000 (99.952)	
2022-04-04 01:30:26,088: ============================================================
2022-04-04 01:31:07,905: time cost, forward:0.010228688879898352, backward:0.05986879493475888, data cost:0.3387229265008389 
2022-04-04 01:31:07,906: ============================================================
2022-04-04 01:31:07,906: Epoch 18/26 Batch 1800/7662 eta: 7:48:04.705508	Training Loss 2.2122 (2.1296)	Training Prec@1 99.805 (99.809)	Training Prec@5 100.000 (99.951)	
2022-04-04 01:31:07,906: ============================================================
2022-04-04 01:31:48,668: time cost, forward:0.010210200069200497, backward:0.059912477687134626, data cost:0.33859829415516707 
2022-04-04 01:31:48,668: ============================================================
2022-04-04 01:31:48,668: Epoch 18/26 Batch 1900/7662 eta: 7:35:34.657266	Training Loss 2.1864 (2.1364)	Training Prec@1 99.805 (99.806)	Training Prec@5 100.000 (99.950)	
2022-04-04 01:31:48,668: ============================================================
2022-04-04 01:32:29,580: time cost, forward:0.010193359619262756, backward:0.05996373667008523, data cost:0.3385487886116825 
2022-04-04 01:32:29,581: ============================================================
2022-04-04 01:32:29,581: Epoch 18/26 Batch 2000/7662 eta: 7:36:34.803717	Training Loss 2.2861 (2.1429)	Training Prec@1 99.609 (99.804)	Training Prec@5 99.805 (99.949)	
2022-04-04 01:32:29,581: ============================================================
2022-04-04 01:33:08,862: time cost, forward:0.010187753783685359, backward:0.06000788453762278, data cost:0.3377614579012191 
2022-04-04 01:33:08,863: ============================================================
2022-04-04 01:33:08,863: Epoch 18/26 Batch 2100/7662 eta: 7:17:43.424422	Training Loss 2.3335 (2.1488)	Training Prec@1 100.000 (99.800)	Training Prec@5 100.000 (99.948)	
2022-04-04 01:33:08,863: ============================================================
2022-04-04 01:33:48,433: time cost, forward:0.010177887911794402, backward:0.06005575408605946, data cost:0.3371074843699415 
2022-04-04 01:33:48,434: ============================================================
2022-04-04 01:33:48,434: Epoch 18/26 Batch 2200/7662 eta: 7:20:17.404983	Training Loss 2.1632 (2.1536)	Training Prec@1 99.219 (99.798)	Training Prec@5 100.000 (99.947)	
2022-04-04 01:33:48,434: ============================================================
2022-04-04 01:34:29,371: time cost, forward:0.01016813819954944, backward:0.06010036926883467, data cost:0.33716716959249354 
2022-04-04 01:34:29,371: ============================================================
2022-04-04 01:34:29,372: Epoch 18/26 Batch 2300/7662 eta: 7:34:48.530350	Training Loss 2.2589 (2.1598)	Training Prec@1 100.000 (99.796)	Training Prec@5 100.000 (99.945)	
2022-04-04 01:34:29,372: ============================================================
2022-04-04 01:35:10,577: time cost, forward:0.01018694292857976, backward:0.06011552321707124, data cost:0.3372828694073644 
2022-04-04 01:35:10,578: ============================================================
2022-04-04 01:35:10,578: Epoch 18/26 Batch 2400/7662 eta: 7:37:06.555661	Training Loss 2.3549 (2.1647)	Training Prec@1 99.414 (99.793)	Training Prec@5 99.805 (99.945)	
2022-04-04 01:35:10,578: ============================================================
2022-04-04 01:35:50,340: time cost, forward:0.01019287748592479, backward:0.060130359555015854, data cost:0.3368450015389762 
2022-04-04 01:35:50,340: ============================================================
2022-04-04 01:35:50,341: Epoch 18/26 Batch 2500/7662 eta: 7:20:25.838657	Training Loss 2.1824 (2.1697)	Training Prec@1 99.805 (99.790)	Training Prec@5 99.805 (99.944)	
2022-04-04 01:35:50,341: ============================================================
2022-04-04 01:36:31,507: time cost, forward:0.010196635520380247, backward:0.060153074015007885, data cost:0.33697653027762353 
2022-04-04 01:36:31,507: ============================================================
2022-04-04 01:36:31,508: Epoch 18/26 Batch 2600/7662 eta: 7:35:17.923341	Training Loss 2.4955 (2.1742)	Training Prec@1 99.219 (99.788)	Training Prec@5 100.000 (99.944)	
2022-04-04 01:36:31,508: ============================================================
2022-04-04 01:37:10,890: time cost, forward:0.010201981086208008, backward:0.06017287919679453, data cost:0.33643502127289465 
2022-04-04 01:37:10,890: ============================================================
2022-04-04 01:37:10,890: Epoch 18/26 Batch 2700/7662 eta: 7:14:54.614608	Training Loss 2.3144 (2.1785)	Training Prec@1 99.609 (99.785)	Training Prec@5 99.805 (99.942)	
2022-04-04 01:37:10,890: ============================================================
2022-04-04 01:37:52,017: time cost, forward:0.010203006140629536, backward:0.0601921223793425, data cost:0.3365498241589469 
2022-04-04 01:37:52,017: ============================================================
2022-04-04 01:37:52,017: Epoch 18/26 Batch 2800/7662 eta: 7:33:29.247325	Training Loss 2.2907 (2.1834)	Training Prec@1 99.805 (99.784)	Training Prec@5 99.805 (99.941)	
2022-04-04 01:37:52,018: ============================================================
2022-04-04 01:38:31,633: time cost, forward:0.01020745114237327, backward:0.06020351227664586, data cost:0.3361442411468127 
2022-04-04 01:38:31,633: ============================================================
2022-04-04 01:38:31,634: Epoch 18/26 Batch 2900/7662 eta: 7:16:10.152162	Training Loss 2.4518 (2.1885)	Training Prec@1 99.414 (99.781)	Training Prec@5 100.000 (99.941)	
2022-04-04 01:38:31,634: ============================================================
2022-04-04 01:39:11,278: time cost, forward:0.010208519350174626, backward:0.060208910741421255, data cost:0.3357518927659063 
2022-04-04 01:39:11,279: ============================================================
2022-04-04 01:39:11,279: Epoch 18/26 Batch 3000/7662 eta: 7:15:49.575433	Training Loss 2.4264 (2.1924)	Training Prec@1 100.000 (99.779)	Training Prec@5 100.000 (99.939)	
2022-04-04 01:39:11,279: ============================================================
2022-04-04 01:39:50,792: time cost, forward:0.01021005684962462, backward:0.06021392980134268, data cost:0.33540673739066157 
2022-04-04 01:39:50,793: ============================================================
2022-04-04 01:39:50,793: Epoch 18/26 Batch 3100/7662 eta: 7:13:43.518154	Training Loss 2.2663 (2.1967)	Training Prec@1 100.000 (99.777)	Training Prec@5 100.000 (99.939)	
2022-04-04 01:39:50,793: ============================================================
2022-04-04 01:40:31,202: time cost, forward:0.01020410411914612, backward:0.06024123102696697, data cost:0.3353105420878471 
2022-04-04 01:40:31,202: ============================================================
2022-04-04 01:40:31,202: Epoch 18/26 Batch 3200/7662 eta: 7:22:52.810909	Training Loss 2.4060 (2.2002)	Training Prec@1 99.609 (99.774)	Training Prec@5 99.805 (99.938)	
2022-04-04 01:40:31,202: ============================================================
2022-04-04 01:41:11,629: time cost, forward:0.010253289715020214, backward:0.06020573407601284, data cost:0.3352264331015141 
2022-04-04 01:41:11,630: ============================================================
2022-04-04 01:41:11,630: Epoch 18/26 Batch 3300/7662 eta: 7:22:24.556320	Training Loss 2.2614 (2.2038)	Training Prec@1 99.805 (99.772)	Training Prec@5 100.000 (99.938)	
2022-04-04 01:41:11,630: ============================================================
2022-04-04 01:41:51,666: time cost, forward:0.010328290040930006, backward:0.06014149635810998, data cost:0.3350444044846582 
2022-04-04 01:41:51,666: ============================================================
2022-04-04 01:41:51,666: Epoch 18/26 Batch 3400/7662 eta: 7:17:27.213128	Training Loss 2.2869 (2.2069)	Training Prec@1 100.000 (99.771)	Training Prec@5 100.000 (99.937)	
2022-04-04 01:41:51,666: ============================================================
2022-04-04 01:42:31,962: time cost, forward:0.010328207127739273, backward:0.06016069298030377, data cost:0.3349463245329703 
2022-04-04 01:42:31,963: ============================================================
2022-04-04 01:42:31,963: Epoch 18/26 Batch 3500/7662 eta: 7:19:37.868043	Training Loss 2.4077 (2.2103)	Training Prec@1 99.805 (99.770)	Training Prec@5 99.805 (99.937)	
2022-04-04 01:42:31,963: ============================================================
2022-04-04 01:43:10,583: time cost, forward:0.010408667466083345, backward:0.06008814122485399, data cost:0.3343761334256286 
2022-04-04 01:43:10,584: ============================================================
2022-04-04 01:43:10,584: Epoch 18/26 Batch 3600/7662 eta: 7:00:42.423307	Training Loss 2.4801 (2.2138)	Training Prec@1 100.000 (99.769)	Training Prec@5 100.000 (99.936)	
2022-04-04 01:43:10,585: ============================================================
2022-04-04 01:43:51,458: time cost, forward:0.01041466959684918, backward:0.06008883378543735, data cost:0.33446346717642655 
2022-04-04 01:43:51,459: ============================================================
2022-04-04 01:43:51,459: Epoch 18/26 Batch 3700/7662 eta: 7:24:34.406360	Training Loss 2.4733 (2.2170)	Training Prec@1 99.609 (99.768)	Training Prec@5 100.000 (99.936)	
2022-04-04 01:43:51,459: ============================================================
2022-04-04 01:44:32,656: time cost, forward:0.010412319486597457, backward:0.060101569969737555, data cost:0.33461011287631975 
2022-04-04 01:44:32,656: ============================================================
2022-04-04 01:44:32,656: Epoch 18/26 Batch 3800/7662 eta: 7:27:23.828530	Training Loss 2.4157 (2.2203)	Training Prec@1 99.609 (99.766)	Training Prec@5 99.805 (99.936)	
2022-04-04 01:44:32,656: ============================================================
2022-04-04 01:45:14,435: time cost, forward:0.01041044782876785, backward:0.060115170497165395, data cost:0.334925180583405 
2022-04-04 01:45:14,435: ============================================================
2022-04-04 01:45:14,436: Epoch 18/26 Batch 3900/7662 eta: 7:33:01.197718	Training Loss 2.2769 (2.2235)	Training Prec@1 99.219 (99.763)	Training Prec@5 100.000 (99.935)	
2022-04-04 01:45:14,436: ============================================================
2022-04-04 01:45:54,271: time cost, forward:0.010425639468510469, backward:0.060099678237487686, data cost:0.33472527060159357 
2022-04-04 01:45:54,271: ============================================================
2022-04-04 01:45:54,271: Epoch 18/26 Batch 4000/7662 eta: 7:11:16.853181	Training Loss 2.4060 (2.2268)	Training Prec@1 99.609 (99.761)	Training Prec@5 100.000 (99.934)	
2022-04-04 01:45:54,271: ============================================================
2022-04-04 01:46:34,496: time cost, forward:0.010425136740191968, backward:0.06009636276609928, data cost:0.3346470842480107 
2022-04-04 01:46:34,496: ============================================================
2022-04-04 01:46:34,496: Epoch 18/26 Batch 4100/7662 eta: 7:14:49.443309	Training Loss 2.2810 (2.2291)	Training Prec@1 100.000 (99.759)	Training Prec@5 100.000 (99.934)	
2022-04-04 01:46:34,496: ============================================================
2022-04-04 01:47:14,806: time cost, forward:0.010412966702545958, backward:0.06011807603420431, data cost:0.33458293140090684 
2022-04-04 01:47:14,807: ============================================================
2022-04-04 01:47:14,807: Epoch 18/26 Batch 4200/7662 eta: 7:15:04.758311	Training Loss 2.4268 (2.2318)	Training Prec@1 99.609 (99.757)	Training Prec@5 99.805 (99.933)	
2022-04-04 01:47:14,807: ============================================================
2022-04-04 01:47:54,398: time cost, forward:0.010413341118474704, backward:0.060126581866399, data cost:0.3343348983943005 
2022-04-04 01:47:54,398: ============================================================
2022-04-04 01:47:54,398: Epoch 18/26 Batch 4300/7662 eta: 7:06:39.481425	Training Loss 2.3606 (2.2352)	Training Prec@1 100.000 (99.755)	Training Prec@5 100.000 (99.932)	
2022-04-04 01:47:54,399: ============================================================
2022-04-04 01:48:34,663: time cost, forward:0.010419508629859808, backward:0.060128481774526336, data cost:0.33427213939598244 
2022-04-04 01:48:34,664: ============================================================
2022-04-04 01:48:34,664: Epoch 18/26 Batch 4400/7662 eta: 7:13:15.164267	Training Loss 2.4583 (2.2379)	Training Prec@1 100.000 (99.754)	Training Prec@5 100.000 (99.932)	
2022-04-04 01:48:34,664: ============================================================
2022-04-04 01:49:14,446: time cost, forward:0.010424930907853791, backward:0.06013472542865564, data cost:0.33409423281230194 
2022-04-04 01:49:14,447: ============================================================
2022-04-04 01:49:14,447: Epoch 18/26 Batch 4500/7662 eta: 7:07:23.584422	Training Loss 2.4200 (2.2404)	Training Prec@1 99.414 (99.752)	Training Prec@5 99.805 (99.931)	
2022-04-04 01:49:14,447: ============================================================
2022-04-04 01:49:54,953: time cost, forward:0.010426962938120014, backward:0.060142148653044084, data cost:0.3340738146272424 
2022-04-04 01:49:54,954: ============================================================
2022-04-04 01:49:54,954: Epoch 18/26 Batch 4600/7662 eta: 7:14:29.867427	Training Loss 2.4876 (2.2429)	Training Prec@1 99.414 (99.750)	Training Prec@5 100.000 (99.931)	
2022-04-04 01:49:54,954: ============================================================
2022-04-04 01:50:34,992: time cost, forward:0.01042493644433469, backward:0.06015030488888744, data cost:0.33397045387159285 
2022-04-04 01:50:34,992: ============================================================
2022-04-04 01:50:34,992: Epoch 18/26 Batch 4700/7662 eta: 7:08:48.455430	Training Loss 2.2642 (2.2455)	Training Prec@1 99.414 (99.748)	Training Prec@5 100.000 (99.930)	
2022-04-04 01:50:34,993: ============================================================
2022-04-04 01:51:15,027: time cost, forward:0.010429189264289934, backward:0.06014899319225263, data cost:0.3338748748462929 
2022-04-04 01:51:15,027: ============================================================
2022-04-04 01:51:15,027: Epoch 18/26 Batch 4800/7662 eta: 7:08:05.998037	Training Loss 2.3533 (2.2479)	Training Prec@1 99.805 (99.746)	Training Prec@5 100.000 (99.930)	
2022-04-04 01:51:15,028: ============================================================
2022-04-04 01:51:54,680: time cost, forward:0.010425263070213379, backward:0.0601572808403705, data cost:0.3337026456103663 
2022-04-04 01:51:54,681: ============================================================
2022-04-04 01:51:54,681: Epoch 18/26 Batch 4900/7662 eta: 7:03:21.669828	Training Loss 2.4016 (2.2503)	Training Prec@1 99.609 (99.744)	Training Prec@5 99.609 (99.929)	
2022-04-04 01:51:54,681: ============================================================
2022-04-04 01:52:35,237: time cost, forward:0.01042385033593938, backward:0.06017002307741517, data cost:0.33369183783579837 
2022-04-04 01:52:35,238: ============================================================
2022-04-04 01:52:35,238: Epoch 18/26 Batch 5000/7662 eta: 7:12:19.818642	Training Loss 2.4672 (2.2526)	Training Prec@1 99.609 (99.742)	Training Prec@5 99.805 (99.929)	
2022-04-04 01:52:35,238: ============================================================
2022-04-04 01:53:16,285: time cost, forward:0.010423235108651795, backward:0.06017391628834705, data cost:0.3337917078193624 
2022-04-04 01:53:16,285: ============================================================
2022-04-04 01:53:16,285: Epoch 18/26 Batch 5100/7662 eta: 7:16:52.569699	Training Loss 2.2656 (2.2549)	Training Prec@1 100.000 (99.740)	Training Prec@5 100.000 (99.928)	
2022-04-04 01:53:16,286: ============================================================
2022-04-04 01:53:56,520: time cost, forward:0.010419081623541849, backward:0.06018139931256323, data cost:0.33375188625186747 
2022-04-04 01:53:56,520: ============================================================
2022-04-04 01:53:56,521: Epoch 18/26 Batch 5200/7662 eta: 7:07:33.551241	Training Loss 2.2750 (2.2571)	Training Prec@1 99.609 (99.738)	Training Prec@5 99.805 (99.927)	
2022-04-04 01:53:56,521: ============================================================
2022-04-04 01:54:37,724: time cost, forward:0.010413297686313184, backward:0.06019762624635137, data cost:0.33387219953096053 
2022-04-04 01:54:37,725: ============================================================
2022-04-04 01:54:37,725: Epoch 18/26 Batch 5300/7662 eta: 7:17:10.162877	Training Loss 2.4129 (2.2591)	Training Prec@1 99.219 (99.738)	Training Prec@5 100.000 (99.927)	
2022-04-04 01:54:37,725: ============================================================
2022-04-04 01:55:17,219: time cost, forward:0.010414013842296371, backward:0.060203744650196206, data cost:0.3336856492825582 
2022-04-04 01:55:17,219: ============================================================
2022-04-04 01:55:17,219: Epoch 18/26 Batch 5400/7662 eta: 6:58:22.327996	Training Loss 2.5416 (2.2612)	Training Prec@1 100.000 (99.735)	Training Prec@5 100.000 (99.926)	
2022-04-04 01:55:17,220: ============================================================
2022-04-04 01:55:58,245: time cost, forward:0.010411536570006359, backward:0.060207342880382216, data cost:0.3337762716965884 
2022-04-04 01:55:58,246: ============================================================
2022-04-04 01:55:58,246: Epoch 18/26 Batch 5500/7662 eta: 7:13:55.056706	Training Loss 2.3391 (2.2628)	Training Prec@1 99.805 (99.734)	Training Prec@5 100.000 (99.926)	
2022-04-04 01:55:58,246: ============================================================
2022-04-04 01:56:38,083: time cost, forward:0.010416255931510182, backward:0.06020419468601211, data cost:0.3336717470519605 
2022-04-04 01:56:38,083: ============================================================
2022-04-04 01:56:38,083: Epoch 18/26 Batch 5600/7662 eta: 7:00:40.575219	Training Loss 2.4225 (2.2646)	Training Prec@1 99.414 (99.734)	Training Prec@5 99.805 (99.926)	
2022-04-04 01:56:38,084: ============================================================
2022-04-04 01:57:17,388: time cost, forward:0.010416493036805967, backward:0.06020525171581455, data cost:0.3334542777919418 
2022-04-04 01:57:17,388: ============================================================
2022-04-04 01:57:17,388: Epoch 18/26 Batch 5700/7662 eta: 6:54:24.006701	Training Loss 2.3263 (2.2667)	Training Prec@1 100.000 (99.732)	Training Prec@5 100.000 (99.926)	
2022-04-04 01:57:17,389: ============================================================
2022-04-04 01:57:56,911: time cost, forward:0.010412345407008713, backward:0.06020711824634524, data cost:0.3332932599763826 
2022-04-04 01:57:56,911: ============================================================
2022-04-04 01:57:56,912: Epoch 18/26 Batch 5800/7662 eta: 6:56:02.465590	Training Loss 2.4456 (2.2686)	Training Prec@1 99.219 (99.731)	Training Prec@5 99.805 (99.925)	
2022-04-04 01:57:56,912: ============================================================
2022-04-04 01:58:37,654: time cost, forward:0.0104062034631507, backward:0.060216190977043206, data cost:0.3333415962069858 
2022-04-04 01:58:37,655: ============================================================
2022-04-04 01:58:37,656: Epoch 18/26 Batch 5900/7662 eta: 7:08:12.794264	Training Loss 2.4468 (2.2705)	Training Prec@1 99.805 (99.729)	Training Prec@5 100.000 (99.925)	
2022-04-04 01:58:37,656: ============================================================
2022-04-04 01:59:18,335: time cost, forward:0.01041184423128393, backward:0.06021327462906161, data cost:0.3333805363701669 
2022-04-04 01:59:18,336: ============================================================
2022-04-04 01:59:18,336: Epoch 18/26 Batch 6000/7662 eta: 7:06:51.888610	Training Loss 2.2370 (2.2726)	Training Prec@1 99.609 (99.727)	Training Prec@5 100.000 (99.925)	
2022-04-04 01:59:18,336: ============================================================
2022-04-04 01:59:59,821: time cost, forward:0.01041399594075681, backward:0.06020760329009314, data cost:0.33354290588348884 
2022-04-04 01:59:59,822: ============================================================
2022-04-04 01:59:59,822: Epoch 18/26 Batch 6100/7662 eta: 7:14:37.742777	Training Loss 2.5262 (2.2744)	Training Prec@1 100.000 (99.726)	Training Prec@5 100.000 (99.924)	
2022-04-04 01:59:59,823: ============================================================
2022-04-04 02:00:39,587: time cost, forward:0.01040891459496257, backward:0.060213789860651096, data cost:0.3334309256717185 
2022-04-04 02:00:39,588: ============================================================
2022-04-04 02:00:39,588: Epoch 18/26 Batch 6200/7662 eta: 6:55:56.743511	Training Loss 2.3095 (2.2764)	Training Prec@1 99.805 (99.725)	Training Prec@5 100.000 (99.924)	
2022-04-04 02:00:39,588: ============================================================
2022-04-04 02:01:18,753: time cost, forward:0.010412069062691565, backward:0.06020981051615636, data cost:0.33322816762607765 
2022-04-04 02:01:18,753: ============================================================
2022-04-04 02:01:18,753: Epoch 18/26 Batch 6300/7662 eta: 6:49:00.410472	Training Loss 2.4125 (2.2777)	Training Prec@1 99.805 (99.724)	Training Prec@5 100.000 (99.923)	
2022-04-04 02:01:18,753: ============================================================
2022-04-04 02:02:00,525: time cost, forward:0.010409892732453619, backward:0.060214354258288555, data cost:0.3334292194809387 
2022-04-04 02:02:00,525: ============================================================
2022-04-04 02:02:00,526: Epoch 18/26 Batch 6400/7662 eta: 7:15:32.495438	Training Loss 2.4628 (2.2794)	Training Prec@1 99.609 (99.723)	Training Prec@5 100.000 (99.923)	
2022-04-04 02:02:00,526: ============================================================
2022-04-04 02:02:40,615: time cost, forward:0.010405034867776946, backward:0.06021430166267692, data cost:0.33337983605971355 
2022-04-04 02:02:40,615: ============================================================
2022-04-04 02:02:40,616: Epoch 18/26 Batch 6500/7662 eta: 6:57:19.885865	Training Loss 2.3593 (2.2812)	Training Prec@1 99.414 (99.721)	Training Prec@5 99.805 (99.923)	
2022-04-04 02:02:40,616: ============================================================
2022-04-04 02:03:21,513: time cost, forward:0.010400194998202243, backward:0.06021858161282297, data cost:0.3334508192215856 
2022-04-04 02:03:21,514: ============================================================
2022-04-04 02:03:21,515: Epoch 18/26 Batch 6600/7662 eta: 7:05:03.992381	Training Loss 2.3140 (2.2830)	Training Prec@1 99.414 (99.720)	Training Prec@5 100.000 (99.923)	
2022-04-04 02:03:21,515: ============================================================
2022-04-04 02:04:01,973: time cost, forward:0.010394254430476757, backward:0.060229802740244816, data cost:0.3334408396125676 
2022-04-04 02:04:01,974: ============================================================
2022-04-04 02:04:01,974: Epoch 18/26 Batch 6700/7662 eta: 6:59:49.573574	Training Loss 2.3679 (2.2846)	Training Prec@1 100.000 (99.719)	Training Prec@5 100.000 (99.922)	
2022-04-04 02:04:01,974: ============================================================
2022-04-04 02:04:42,059: time cost, forward:0.010388750769773254, backward:0.0602397254888302, data cost:0.3333929660197899 
2022-04-04 02:04:42,059: ============================================================
2022-04-04 02:04:42,059: Epoch 18/26 Batch 6800/7662 eta: 6:55:16.676145	Training Loss 2.3820 (2.2860)	Training Prec@1 99.219 (99.718)	Training Prec@5 100.000 (99.922)	
2022-04-04 02:04:42,059: ============================================================
2022-04-04 02:05:21,809: time cost, forward:0.010377599702639621, backward:0.060253586418681566, data cost:0.3332636059496883 
2022-04-04 02:05:21,810: ============================================================
2022-04-04 02:05:21,810: Epoch 18/26 Batch 6900/7662 eta: 6:51:09.039902	Training Loss 2.3292 (2.2877)	Training Prec@1 99.609 (99.717)	Training Prec@5 99.805 (99.922)	
2022-04-04 02:05:21,810: ============================================================
2022-04-04 02:06:01,185: time cost, forward:0.010377786554324829, backward:0.06025475991727761, data cost:0.33313522633185877 
2022-04-04 02:06:01,185: ============================================================
2022-04-04 02:06:01,186: Epoch 18/26 Batch 7000/7662 eta: 6:46:36.631751	Training Loss 2.5393 (2.2890)	Training Prec@1 98.828 (99.717)	Training Prec@5 99.805 (99.922)	
2022-04-04 02:06:01,186: ============================================================
2022-04-04 02:06:40,670: time cost, forward:0.010380627655919161, backward:0.060250462705206745, data cost:0.33299262440696636 
2022-04-04 02:06:40,671: ============================================================
2022-04-04 02:06:40,671: Epoch 18/26 Batch 7100/7662 eta: 6:47:05.230202	Training Loss 2.3240 (2.2903)	Training Prec@1 100.000 (99.716)	Training Prec@5 100.000 (99.922)	
2022-04-04 02:06:40,671: ============================================================
2022-04-04 02:07:20,952: time cost, forward:0.010382352926479741, backward:0.06025016398906111, data cost:0.3329822071593145 
2022-04-04 02:07:20,952: ============================================================
2022-04-04 02:07:20,952: Epoch 18/26 Batch 7200/7662 eta: 6:54:37.422051	Training Loss 2.5321 (2.2915)	Training Prec@1 99.414 (99.714)	Training Prec@5 100.000 (99.921)	
2022-04-04 02:07:20,953: ============================================================
2022-04-04 02:08:00,950: time cost, forward:0.010383839998560126, backward:0.06025011589435996, data cost:0.3329165840266518 
2022-04-04 02:08:00,950: ============================================================
2022-04-04 02:08:00,950: Epoch 18/26 Batch 7300/7662 eta: 6:51:02.363822	Training Loss 2.4781 (2.2927)	Training Prec@1 99.609 (99.714)	Training Prec@5 99.609 (99.921)	
2022-04-04 02:08:00,951: ============================================================
2022-04-04 02:08:41,703: time cost, forward:0.010379842591134256, backward:0.06025746748695214, data cost:0.33295890450042587 
2022-04-04 02:08:41,703: ============================================================
2022-04-04 02:08:41,703: Epoch 18/26 Batch 7400/7662 eta: 6:58:06.998239	Training Loss 2.5379 (2.2939)	Training Prec@1 99.805 (99.712)	Training Prec@5 99.805 (99.920)	
2022-04-04 02:08:41,703: ============================================================
2022-04-04 02:09:21,976: time cost, forward:0.010376465703697423, backward:0.06026802595209513, data cost:0.3329358138407305 
2022-04-04 02:09:21,976: ============================================================
2022-04-04 02:09:21,976: Epoch 18/26 Batch 7500/7662 eta: 6:52:31.373400	Training Loss 2.5068 (2.2952)	Training Prec@1 99.414 (99.710)	Training Prec@5 99.609 (99.920)	
2022-04-04 02:09:21,976: ============================================================
2022-04-04 02:10:02,603: time cost, forward:0.010374761691358878, backward:0.06027470643402071, data cost:0.3329532227715092 
2022-04-04 02:10:02,603: ============================================================
2022-04-04 02:10:02,603: Epoch 18/26 Batch 7600/7662 eta: 6:55:28.387696	Training Loss 2.4617 (2.2965)	Training Prec@1 99.609 (99.710)	Training Prec@5 99.805 (99.920)	
2022-04-04 02:10:02,603: ============================================================
2022-04-04 02:10:29,130: Epoch: 18/26 eta: 6:55:02.792618	Training Loss 2.4717 (2.2973)	Training Prec@1 99.805 (99.709)	Training Prec@5 100.000 (99.919)
2022-04-04 02:10:29,130: ============================================================
2022-04-04 02:11:16,671: time cost, forward:0.010783072673913204, backward:0.057546526494652334, data cost:0.40716507218100806 
2022-04-04 02:11:16,672: ============================================================
2022-04-04 02:11:16,672: Epoch 19/26 Batch 100/7662 eta: 8:03:53.663869	Training Loss 2.0482 (1.9520)	Training Prec@1 100.000 (99.846)	Training Prec@5 100.000 (99.957)	
2022-04-04 02:11:16,672: ============================================================
2022-04-04 02:11:56,192: time cost, forward:0.010671223827342891, backward:0.05764589357615715, data cost:0.3668478589561117 
2022-04-04 02:11:56,192: ============================================================
2022-04-04 02:11:56,193: Epoch 19/26 Batch 200/7662 eta: 6:42:25.941963	Training Loss 1.9185 (1.9519)	Training Prec@1 100.000 (99.855)	Training Prec@5 100.000 (99.962)	
2022-04-04 02:11:56,193: ============================================================
2022-04-04 02:12:35,579: time cost, forward:0.010437467823857847, backward:0.058049591089969495, data cost:0.3525435501915157 
2022-04-04 02:12:35,579: ============================================================
2022-04-04 02:12:35,579: Epoch 19/26 Batch 300/7662 eta: 6:40:24.629143	Training Loss 2.0390 (1.9657)	Training Prec@1 99.805 (99.857)	Training Prec@5 100.000 (99.964)	
2022-04-04 02:12:35,579: ============================================================
2022-04-04 02:13:14,778: time cost, forward:0.010291911008065207, backward:0.05842289589999015, data cost:0.3448008552828528 
2022-04-04 02:13:14,778: ============================================================
2022-04-04 02:13:14,779: Epoch 19/26 Batch 400/7662 eta: 6:37:51.270347	Training Loss 1.9802 (1.9786)	Training Prec@1 99.609 (99.855)	Training Prec@5 99.805 (99.965)	
2022-04-04 02:13:14,779: ============================================================
2022-04-04 02:13:54,672: time cost, forward:0.010228335737943172, backward:0.05854317563808036, data cost:0.34173752549654973 
2022-04-04 02:13:54,672: ============================================================
2022-04-04 02:13:54,672: Epoch 19/26 Batch 500/7662 eta: 6:44:14.169240	Training Loss 2.1566 (1.9933)	Training Prec@1 99.805 (99.847)	Training Prec@5 100.000 (99.962)	
2022-04-04 02:13:54,673: ============================================================
2022-04-04 02:14:34,646: time cost, forward:0.01020048098492503, backward:0.058656809126992455, data cost:0.3397066035931417 
2022-04-04 02:14:34,647: ============================================================
2022-04-04 02:14:34,647: Epoch 19/26 Batch 600/7662 eta: 6:44:23.441907	Training Loss 1.8486 (2.0040)	Training Prec@1 100.000 (99.839)	Training Prec@5 100.000 (99.959)	
2022-04-04 02:14:34,647: ============================================================
2022-04-04 02:15:15,215: time cost, forward:0.010215457416910982, backward:0.058714739413391025, data cost:0.3390993993510845 
2022-04-04 02:15:15,215: ============================================================
2022-04-04 02:15:15,215: Epoch 19/26 Batch 700/7662 eta: 6:49:43.129847	Training Loss 2.1068 (2.0162)	Training Prec@1 100.000 (99.838)	Training Prec@5 100.000 (99.961)	
2022-04-04 02:15:15,215: ============================================================
2022-04-04 02:15:56,445: time cost, forward:0.01029527590182308, backward:0.05877165979378215, data cost:0.33944100671178556 
2022-04-04 02:15:56,446: ============================================================
2022-04-04 02:15:56,446: Epoch 19/26 Batch 800/7662 eta: 6:55:43.245287	Training Loss 2.1452 (2.0254)	Training Prec@1 99.805 (99.834)	Training Prec@5 100.000 (99.958)	
2022-04-04 02:15:56,446: ============================================================
2022-04-04 02:16:35,658: time cost, forward:0.010385103299965184, backward:0.058776878806719925, data cost:0.33747017768121534 
2022-04-04 02:16:35,659: ============================================================
2022-04-04 02:16:35,659: Epoch 19/26 Batch 900/7662 eta: 6:34:43.445262	Training Loss 2.1180 (2.0327)	Training Prec@1 100.000 (99.835)	Training Prec@5 100.000 (99.957)	
2022-04-04 02:16:35,659: ============================================================
2022-04-04 02:17:16,123: time cost, forward:0.010735147111528032, backward:0.058517030767492345, data cost:0.3371216957275574 
2022-04-04 02:17:16,124: ============================================================
2022-04-04 02:17:16,124: Epoch 19/26 Batch 1000/7662 eta: 6:46:39.242671	Training Loss 2.0845 (2.0404)	Training Prec@1 100.000 (99.832)	Training Prec@5 100.000 (99.957)	
2022-04-04 02:17:16,124: ============================================================
2022-04-04 02:17:56,065: time cost, forward:0.010739920028672639, backward:0.05856269419030562, data cost:0.33638996097366847 
2022-04-04 02:17:56,066: ============================================================
2022-04-04 02:17:56,066: Epoch 19/26 Batch 1100/7662 eta: 6:40:43.876071	Training Loss 2.2333 (2.0477)	Training Prec@1 100.000 (99.830)	Training Prec@5 100.000 (99.958)	
2022-04-04 02:17:56,066: ============================================================
2022-04-04 02:18:35,927: time cost, forward:0.01069865791473516, backward:0.05864401993103282, data cost:0.33571889501894586 
2022-04-04 02:18:35,927: ============================================================
2022-04-04 02:18:35,927: Epoch 19/26 Batch 1200/7662 eta: 6:39:15.556357	Training Loss 2.0806 (2.0577)	Training Prec@1 99.805 (99.828)	Training Prec@5 100.000 (99.957)	
2022-04-04 02:18:35,928: ============================================================
2022-04-04 02:19:17,068: time cost, forward:0.010666380670090838, backward:0.05875009110195991, data cost:0.3361087757592205 
2022-04-04 02:19:17,069: ============================================================
2022-04-04 02:19:17,069: Epoch 19/26 Batch 1300/7662 eta: 6:51:23.685064	Training Loss 2.2348 (2.0656)	Training Prec@1 100.000 (99.824)	Training Prec@5 100.000 (99.955)	
2022-04-04 02:19:17,069: ============================================================
2022-04-04 02:19:56,931: time cost, forward:0.010680632390151115, backward:0.05878342552812207, data cost:0.3355258370059315 
2022-04-04 02:19:56,931: ============================================================
2022-04-04 02:19:56,931: Epoch 19/26 Batch 1400/7662 eta: 6:37:56.353343	Training Loss 2.1799 (2.0753)	Training Prec@1 99.609 (99.820)	Training Prec@5 100.000 (99.953)	
2022-04-04 02:19:56,931: ============================================================
2022-04-04 02:20:37,076: time cost, forward:0.010656960890084763, backward:0.05884946418492455, data cost:0.33519290557617026 
2022-04-04 02:20:37,076: ============================================================
2022-04-04 02:20:37,077: Epoch 19/26 Batch 1500/7662 eta: 6:40:05.755274	Training Loss 2.2730 (2.0821)	Training Prec@1 99.805 (99.818)	Training Prec@5 99.805 (99.953)	
2022-04-04 02:20:37,077: ============================================================
2022-04-04 02:21:17,152: time cost, forward:0.010679825161903482, backward:0.05882624777650147, data cost:0.33493385842772405 
2022-04-04 02:21:17,152: ============================================================
2022-04-04 02:21:17,152: Epoch 19/26 Batch 1600/7662 eta: 6:38:43.995495	Training Loss 2.0929 (2.0892)	Training Prec@1 99.805 (99.816)	Training Prec@5 99.805 (99.952)	
2022-04-04 02:21:17,153: ============================================================
2022-04-04 02:21:58,292: time cost, forward:0.010670891644464935, backward:0.05884023622037945, data cost:0.33532313194746405 
2022-04-04 02:21:58,293: ============================================================
2022-04-04 02:21:58,293: Epoch 19/26 Batch 1700/7662 eta: 6:48:38.518035	Training Loss 2.0649 (2.0966)	Training Prec@1 99.805 (99.813)	Training Prec@5 99.805 (99.951)	
2022-04-04 02:21:58,293: ============================================================
2022-04-04 02:22:39,740: time cost, forward:0.01068723698733183, backward:0.05884874218235154, data cost:0.3357740352391004 
2022-04-04 02:22:39,740: ============================================================
2022-04-04 02:22:39,740: Epoch 19/26 Batch 1800/7662 eta: 6:51:00.005026	Training Loss 2.3273 (2.1032)	Training Prec@1 99.414 (99.812)	Training Prec@5 99.805 (99.951)	
2022-04-04 02:22:39,741: ============================================================
2022-04-04 02:23:21,157: time cost, forward:0.010673107129137663, backward:0.05885794063566106, data cost:0.33622238710091074 
2022-04-04 02:23:21,158: ============================================================
2022-04-04 02:23:21,158: Epoch 19/26 Batch 1900/7662 eta: 6:50:00.714534	Training Loss 2.2206 (2.1103)	Training Prec@1 99.609 (99.808)	Training Prec@5 99.805 (99.950)	
2022-04-04 02:23:21,158: ============================================================
2022-04-04 02:24:01,783: time cost, forward:0.010670368643985384, backward:0.05883757742480554, data cost:0.33627382572321013 
2022-04-04 02:24:01,783: ============================================================
2022-04-04 02:24:01,784: Epoch 19/26 Batch 2000/7662 eta: 6:41:29.941920	Training Loss 2.0932 (2.1163)	Training Prec@1 99.414 (99.805)	Training Prec@5 100.000 (99.948)	
2022-04-04 02:24:01,784: ============================================================
2022-04-04 02:24:42,593: time cost, forward:0.010650930999857634, backward:0.058852533205967394, data cost:0.33630337585660036 
2022-04-04 02:24:42,593: ============================================================
2022-04-04 02:24:42,594: Epoch 19/26 Batch 2100/7662 eta: 6:42:38.252055	Training Loss 2.2964 (2.1221)	Training Prec@1 99.414 (99.803)	Training Prec@5 100.000 (99.946)	
2022-04-04 02:24:42,594: ============================================================
2022-04-04 02:25:23,395: time cost, forward:0.010656894906752215, backward:0.05885645832566577, data cost:0.33641236226306065 
2022-04-04 02:25:23,395: ============================================================
2022-04-04 02:25:23,396: Epoch 19/26 Batch 2200/7662 eta: 6:41:53.056812	Training Loss 2.3361 (2.1276)	Training Prec@1 99.414 (99.801)	Training Prec@5 99.805 (99.946)	
2022-04-04 02:25:23,397: ============================================================
2022-04-04 02:26:02,112: time cost, forward:0.010647766587007248, backward:0.05890348902366741, data cost:0.3355223006297838 
2022-04-04 02:26:02,112: ============================================================
2022-04-04 02:26:02,112: Epoch 19/26 Batch 2300/7662 eta: 6:20:41.251420	Training Loss 2.1115 (2.1335)	Training Prec@1 99.805 (99.799)	Training Prec@5 99.805 (99.945)	
2022-04-04 02:26:02,112: ============================================================
2022-04-04 02:26:42,563: time cost, forward:0.010645658982798874, backward:0.05891664776517829, data cost:0.33548248604269215 
2022-04-04 02:26:42,564: ============================================================
2022-04-04 02:26:42,564: Epoch 19/26 Batch 2400/7662 eta: 6:37:04.867221	Training Loss 2.2625 (2.1398)	Training Prec@1 100.000 (99.798)	Training Prec@5 100.000 (99.945)	
2022-04-04 02:26:42,564: ============================================================
2022-04-04 02:27:22,132: time cost, forward:0.010622448804808789, backward:0.0589501442743235, data cost:0.33507309440805133 
2022-04-04 02:27:22,132: ============================================================
2022-04-04 02:27:22,132: Epoch 19/26 Batch 2500/7662 eta: 6:27:45.078493	Training Loss 2.2511 (2.1450)	Training Prec@1 100.000 (99.796)	Training Prec@5 100.000 (99.945)	
2022-04-04 02:27:22,133: ============================================================
2022-04-04 02:28:01,869: time cost, forward:0.010622989402087023, backward:0.058962871405471975, data cost:0.33475768323034544 
2022-04-04 02:28:01,870: ============================================================
2022-04-04 02:28:01,870: Epoch 19/26 Batch 2600/7662 eta: 6:28:44.852315	Training Loss 2.2157 (2.1501)	Training Prec@1 99.609 (99.794)	Training Prec@5 100.000 (99.945)	
2022-04-04 02:28:01,870: ============================================================
2022-04-04 02:28:42,270: time cost, forward:0.010610302274604336, backward:0.058982578636584966, data cost:0.3346246203125384 
2022-04-04 02:28:42,271: ============================================================
2022-04-04 02:28:42,271: Epoch 19/26 Batch 2700/7662 eta: 6:34:33.744226	Training Loss 2.2128 (2.1552)	Training Prec@1 100.000 (99.791)	Training Prec@5 100.000 (99.944)	
2022-04-04 02:28:42,271: ============================================================
2022-04-04 02:29:22,588: time cost, forward:0.010623750707088687, backward:0.058981173121107185, data cost:0.33462918209322606 
2022-04-04 02:29:22,589: ============================================================
2022-04-04 02:29:22,589: Epoch 19/26 Batch 2800/7662 eta: 6:33:04.697077	Training Loss 2.2303 (2.1598)	Training Prec@1 99.609 (99.790)	Training Prec@5 100.000 (99.943)	
2022-04-04 02:29:22,589: ============================================================
2022-04-04 02:30:01,608: time cost, forward:0.010716177422904113, backward:0.05889931379741289, data cost:0.3341461283949253 
2022-04-04 02:30:01,609: ============================================================
2022-04-04 02:30:01,609: Epoch 19/26 Batch 2900/7662 eta: 6:19:46.605039	Training Loss 2.2606 (2.1641)	Training Prec@1 99.609 (99.788)	Training Prec@5 99.805 (99.943)	
2022-04-04 02:30:01,609: ============================================================
2022-04-04 02:30:41,496: time cost, forward:0.01084817135560588, backward:0.05877102983518615, data cost:0.3339255130382409 
2022-04-04 02:30:41,496: ============================================================
2022-04-04 02:30:41,497: Epoch 19/26 Batch 3000/7662 eta: 6:27:33.314447	Training Loss 2.1778 (2.1684)	Training Prec@1 99.609 (99.788)	Training Prec@5 99.805 (99.943)	
2022-04-04 02:30:41,497: ============================================================
2022-04-04 02:31:22,483: time cost, forward:0.010844148794040637, backward:0.0587848671485086, data cost:0.33411150041723603 
2022-04-04 02:31:22,483: ============================================================
2022-04-04 02:31:22,484: Epoch 19/26 Batch 3100/7662 eta: 6:37:33.183709	Training Loss 2.2207 (2.1721)	Training Prec@1 100.000 (99.785)	Training Prec@5 100.000 (99.942)	
2022-04-04 02:31:22,484: ============================================================
2022-04-04 02:32:02,090: time cost, forward:0.010824055178309276, backward:0.05881304851208824, data cost:0.333834825138928 
2022-04-04 02:32:02,090: ============================================================
2022-04-04 02:32:02,090: Epoch 19/26 Batch 3200/7662 eta: 6:23:30.343527	Training Loss 2.1986 (2.1757)	Training Prec@1 99.805 (99.783)	Training Prec@5 100.000 (99.942)	
2022-04-04 02:32:02,091: ============================================================
2022-04-04 02:32:43,513: time cost, forward:0.010807807462148213, backward:0.05882466551245036, data cost:0.3341624871208004 
2022-04-04 02:32:43,513: ============================================================
2022-04-04 02:32:43,513: Epoch 19/26 Batch 3300/7662 eta: 6:40:24.024495	Training Loss 2.3057 (2.1795)	Training Prec@1 100.000 (99.781)	Training Prec@5 100.000 (99.941)	
2022-04-04 02:32:43,514: ============================================================
2022-04-04 02:33:22,928: time cost, forward:0.010787114777190436, backward:0.058847217427944215, data cost:0.3338760981737919 
2022-04-04 02:33:22,929: ============================================================
2022-04-04 02:33:22,929: Epoch 19/26 Batch 3400/7662 eta: 6:20:20.387713	Training Loss 2.3267 (2.1836)	Training Prec@1 99.023 (99.778)	Training Prec@5 100.000 (99.942)	
2022-04-04 02:33:22,929: ============================================================
2022-04-04 02:34:03,019: time cost, forward:0.010782409511521462, backward:0.05886501978383333, data cost:0.3337568457244498 
2022-04-04 02:34:03,019: ============================================================
2022-04-04 02:34:03,020: Epoch 19/26 Batch 3500/7662 eta: 6:26:11.311948	Training Loss 2.3224 (2.1876)	Training Prec@1 99.414 (99.777)	Training Prec@5 99.609 (99.941)	
2022-04-04 02:34:03,020: ============================================================
2022-04-04 02:34:43,071: time cost, forward:0.010777329033896405, backward:0.058869489731805856, data cost:0.3336628541975559 
2022-04-04 02:34:43,071: ============================================================
2022-04-04 02:34:43,072: Epoch 19/26 Batch 3600/7662 eta: 6:25:08.725295	Training Loss 2.3430 (2.1919)	Training Prec@1 99.609 (99.774)	Training Prec@5 100.000 (99.940)	
2022-04-04 02:34:43,072: ============================================================
2022-04-04 02:35:22,803: time cost, forward:0.010767629965797377, backward:0.05889536974139393, data cost:0.33347435080060833 
2022-04-04 02:35:22,804: ============================================================
2022-04-04 02:35:22,804: Epoch 19/26 Batch 3700/7662 eta: 6:21:24.710080	Training Loss 2.0978 (2.1960)	Training Prec@1 99.805 (99.772)	Training Prec@5 99.805 (99.939)	
2022-04-04 02:35:22,804: ============================================================
2022-04-04 02:36:02,515: time cost, forward:0.010760038455682982, backward:0.0589134296513633, data cost:0.3332817920354455 
2022-04-04 02:36:02,515: ============================================================
2022-04-04 02:36:02,515: Epoch 19/26 Batch 3800/7662 eta: 6:20:32.830913	Training Loss 2.2030 (2.1988)	Training Prec@1 99.805 (99.769)	Training Prec@5 100.000 (99.938)	
2022-04-04 02:36:02,516: ============================================================
2022-04-04 02:36:43,718: time cost, forward:0.010747988672249131, backward:0.058937121000189635, data cost:0.3334975912192443 
2022-04-04 02:36:43,719: ============================================================
2022-04-04 02:36:43,719: Epoch 19/26 Batch 3900/7662 eta: 6:34:09.665421	Training Loss 2.3772 (2.2019)	Training Prec@1 100.000 (99.768)	Training Prec@5 100.000 (99.937)	
2022-04-04 02:36:43,719: ============================================================
2022-04-04 02:37:23,490: time cost, forward:0.010749318415476519, backward:0.058945256610249366, data cost:0.3333351322936249 
2022-04-04 02:37:23,490: ============================================================
2022-04-04 02:37:23,490: Epoch 19/26 Batch 4000/7662 eta: 6:19:47.789127	Training Loss 2.3206 (2.2052)	Training Prec@1 99.609 (99.766)	Training Prec@5 99.805 (99.937)	
2022-04-04 02:37:23,491: ============================================================
2022-04-04 02:38:04,969: time cost, forward:0.010868942949881813, backward:0.058832988124790646, data cost:0.3335897173349902 
2022-04-04 02:38:04,970: ============================================================
2022-04-04 02:38:04,970: Epoch 19/26 Batch 4100/7662 eta: 6:35:25.096603	Training Loss 2.2209 (2.2084)	Training Prec@1 99.805 (99.764)	Training Prec@5 100.000 (99.936)	
2022-04-04 02:38:04,970: ============================================================
2022-04-04 02:38:43,559: time cost, forward:0.010846019444166976, backward:0.058864986195283776, data cost:0.3331384060921684 
2022-04-04 02:38:43,559: ============================================================
2022-04-04 02:38:43,560: Epoch 19/26 Batch 4200/7662 eta: 6:07:13.516485	Training Loss 2.1590 (2.2112)	Training Prec@1 99.414 (99.761)	Training Prec@5 99.805 (99.936)	
2022-04-04 02:38:43,560: ============================================================
2022-04-04 02:39:24,158: time cost, forward:0.010837999436155977, backward:0.058883777300294926, data cost:0.3332087328667473 
2022-04-04 02:39:24,158: ============================================================
2022-04-04 02:39:24,158: Epoch 19/26 Batch 4300/7662 eta: 6:25:40.086997	Training Loss 2.3903 (2.2142)	Training Prec@1 99.414 (99.760)	Training Prec@5 100.000 (99.935)	
2022-04-04 02:39:24,159: ============================================================
2022-04-04 02:40:03,779: time cost, forward:0.010832201705571873, backward:0.058900286810429, data cost:0.3330331946752591 
2022-04-04 02:40:03,779: ============================================================
2022-04-04 02:40:03,779: Epoch 19/26 Batch 4400/7662 eta: 6:15:43.161756	Training Loss 2.4418 (2.2169)	Training Prec@1 99.609 (99.759)	Training Prec@5 99.805 (99.935)	
2022-04-04 02:40:03,780: ============================================================
2022-04-04 02:40:43,862: time cost, forward:0.010819616252036857, backward:0.058920041485133766, data cost:0.332971188830757 
2022-04-04 02:40:43,862: ============================================================
2022-04-04 02:40:43,863: Epoch 19/26 Batch 4500/7662 eta: 6:19:26.048998	Training Loss 2.3228 (2.2192)	Training Prec@1 99.609 (99.757)	Training Prec@5 100.000 (99.935)	
2022-04-04 02:40:43,863: ============================================================
2022-04-04 02:41:22,423: time cost, forward:0.010808716651848488, backward:0.05893264995706836, data cost:0.33258130447220147 
2022-04-04 02:41:22,423: ============================================================
2022-04-04 02:41:22,424: Epoch 19/26 Batch 4600/7662 eta: 6:04:22.883055	Training Loss 2.3453 (2.2218)	Training Prec@1 99.023 (99.756)	Training Prec@5 99.609 (99.934)	
2022-04-04 02:41:22,424: ============================================================
2022-04-04 02:42:02,366: time cost, forward:0.010795364990770169, backward:0.05895699321221585, data cost:0.3325033225412444 
2022-04-04 02:42:02,366: ============================================================
2022-04-04 02:42:02,366: Epoch 19/26 Batch 4700/7662 eta: 6:16:46.390243	Training Loss 2.3159 (2.2242)	Training Prec@1 99.805 (99.754)	Training Prec@5 100.000 (99.934)	
2022-04-04 02:42:02,367: ============================================================
2022-04-04 02:42:42,129: time cost, forward:0.010787551714544819, backward:0.05897160872093562, data cost:0.3323855035924544 
2022-04-04 02:42:42,129: ============================================================
2022-04-04 02:42:42,129: Epoch 19/26 Batch 4800/7662 eta: 6:14:24.890936	Training Loss 2.1637 (2.2265)	Training Prec@1 99.805 (99.752)	Training Prec@5 100.000 (99.933)	
2022-04-04 02:42:42,129: ============================================================
2022-04-04 02:43:22,830: time cost, forward:0.01078224099395372, backward:0.05898391176034149, data cost:0.33246394156631 
2022-04-04 02:43:22,830: ============================================================
2022-04-04 02:43:22,831: Epoch 19/26 Batch 4900/7662 eta: 6:22:34.378532	Training Loss 2.2999 (2.2292)	Training Prec@1 99.805 (99.750)	Training Prec@5 99.805 (99.932)	
2022-04-04 02:43:22,831: ============================================================
2022-04-04 02:44:03,642: time cost, forward:0.010771442113053349, backward:0.058998643028471416, data cost:0.33259243215410966 
2022-04-04 02:44:03,643: ============================================================
2022-04-04 02:44:03,643: Epoch 19/26 Batch 5000/7662 eta: 6:22:55.989108	Training Loss 2.4405 (2.2318)	Training Prec@1 99.805 (99.748)	Training Prec@5 99.805 (99.932)	
2022-04-04 02:44:03,643: ============================================================
2022-04-04 02:44:42,896: time cost, forward:0.010762609671461603, backward:0.059005424915096014, data cost:0.33237295039473014 
2022-04-04 02:44:42,897: ============================================================
2022-04-04 02:44:42,897: Epoch 19/26 Batch 5100/7662 eta: 6:07:39.679816	Training Loss 2.4918 (2.2341)	Training Prec@1 99.219 (99.747)	Training Prec@5 99.609 (99.931)	
2022-04-04 02:44:42,897: ============================================================
2022-04-04 02:45:21,864: time cost, forward:0.010815318994142386, backward:0.058954429388000405, data cost:0.3321195607186281 
2022-04-04 02:45:21,865: ============================================================
2022-04-04 02:45:21,865: Epoch 19/26 Batch 5200/7662 eta: 6:04:20.039953	Training Loss 2.1982 (2.2366)	Training Prec@1 99.414 (99.745)	Training Prec@5 100.000 (99.931)	
2022-04-04 02:45:21,866: ============================================================
2022-04-04 02:46:02,878: time cost, forward:0.010821183822496496, backward:0.058948715760316864, data cost:0.3322552843664385 
2022-04-04 02:46:02,878: ============================================================
2022-04-04 02:46:02,878: Epoch 19/26 Batch 5300/7662 eta: 6:22:46.097278	Training Loss 2.3217 (2.2390)	Training Prec@1 100.000 (99.743)	Training Prec@5 100.000 (99.930)	
2022-04-04 02:46:02,879: ============================================================
2022-04-04 02:46:42,576: time cost, forward:0.010862424166517405, backward:0.05890871812114232, data cost:0.3321609071370164 
2022-04-04 02:46:42,576: ============================================================
2022-04-04 02:46:42,576: Epoch 19/26 Batch 5400/7662 eta: 6:09:49.912539	Training Loss 2.4251 (2.2410)	Training Prec@1 99.805 (99.742)	Training Prec@5 100.000 (99.930)	
2022-04-04 02:46:42,576: ============================================================
2022-04-04 02:47:22,471: time cost, forward:0.010851025646394936, backward:0.058923764973689174, data cost:0.33209251065452783 
2022-04-04 02:47:22,471: ============================================================
2022-04-04 02:47:22,472: Epoch 19/26 Batch 5500/7662 eta: 6:11:00.424525	Training Loss 2.2901 (2.2427)	Training Prec@1 100.000 (99.740)	Training Prec@5 100.000 (99.929)	
2022-04-04 02:47:22,472: ============================================================
2022-04-04 02:48:02,169: time cost, forward:0.010856143617911049, backward:0.05892025838900643, data cost:0.33197685777555513 
2022-04-04 02:48:02,170: ============================================================
2022-04-04 02:48:02,170: Epoch 19/26 Batch 5600/7662 eta: 6:08:30.877483	Training Loss 2.3879 (2.2448)	Training Prec@1 99.414 (99.739)	Training Prec@5 99.609 (99.928)	
2022-04-04 02:48:02,170: ============================================================
2022-04-04 02:48:43,472: time cost, forward:0.010907014308634255, backward:0.05887381979029813, data cost:0.3321673432909244 
2022-04-04 02:48:43,473: ============================================================
2022-04-04 02:48:43,473: Epoch 19/26 Batch 5700/7662 eta: 6:22:43.127757	Training Loss 2.4013 (2.2468)	Training Prec@1 100.000 (99.737)	Training Prec@5 100.000 (99.928)	
2022-04-04 02:48:43,473: ============================================================
2022-04-04 02:49:22,139: time cost, forward:0.010907864402051342, backward:0.058881562462056954, data cost:0.33189688783038135 
2022-04-04 02:49:22,139: ============================================================
2022-04-04 02:49:22,140: Epoch 19/26 Batch 5800/7662 eta: 5:57:38.882517	Training Loss 2.3241 (2.2488)	Training Prec@1 100.000 (99.735)	Training Prec@5 100.000 (99.927)	
2022-04-04 02:49:22,140: ============================================================
2022-04-04 02:50:02,935: time cost, forward:0.0109004684981097, backward:0.05889442638333196, data cost:0.33198039639620563 
2022-04-04 02:50:02,936: ============================================================
2022-04-04 02:50:02,936: Epoch 19/26 Batch 5900/7662 eta: 6:16:39.986766	Training Loss 2.2498 (2.2508)	Training Prec@1 99.609 (99.733)	Training Prec@5 100.000 (99.927)	
2022-04-04 02:50:02,936: ============================================================
2022-04-04 02:50:41,948: time cost, forward:0.010890019538104883, backward:0.05890918632490791, data cost:0.3317763581636012 
2022-04-04 02:50:41,948: ============================================================
2022-04-04 02:50:41,948: Epoch 19/26 Batch 6000/7662 eta: 5:59:32.541230	Training Loss 2.4469 (2.2529)	Training Prec@1 99.609 (99.731)	Training Prec@5 99.805 (99.926)	
2022-04-04 02:50:41,948: ============================================================
2022-04-04 02:51:21,114: time cost, forward:0.010877508475245325, backward:0.058926026886419146, data cost:0.33160866485460605 
2022-04-04 02:51:21,114: ============================================================
2022-04-04 02:51:21,115: Epoch 19/26 Batch 6100/7662 eta: 6:00:18.669493	Training Loss 2.3045 (2.2546)	Training Prec@1 99.609 (99.729)	Training Prec@5 99.805 (99.926)	
2022-04-04 02:51:21,115: ============================================================
2022-04-04 02:52:01,793: time cost, forward:0.010865579095266004, backward:0.05895008400844593, data cost:0.33166291710253126 
2022-04-04 02:52:01,793: ============================================================
2022-04-04 02:52:01,793: Epoch 19/26 Batch 6200/7662 eta: 6:13:32.739644	Training Loss 2.4519 (2.2565)	Training Prec@1 100.000 (99.729)	Training Prec@5 100.000 (99.926)	
2022-04-04 02:52:01,793: ============================================================
2022-04-04 02:52:40,805: time cost, forward:0.010858315970334084, backward:0.05895423874020066, data cost:0.3314861809569591 
2022-04-04 02:52:40,806: ============================================================
2022-04-04 02:52:40,806: Epoch 19/26 Batch 6300/7662 eta: 5:57:35.749626	Training Loss 2.2220 (2.2583)	Training Prec@1 99.805 (99.728)	Training Prec@5 100.000 (99.926)	
2022-04-04 02:52:40,806: ============================================================
2022-04-04 02:53:21,295: time cost, forward:0.010848140172575354, backward:0.0589687450171672, data cost:0.33152022758933375 
2022-04-04 02:53:21,296: ============================================================
2022-04-04 02:53:21,296: Epoch 19/26 Batch 6400/7662 eta: 6:10:27.898181	Training Loss 2.4365 (2.2597)	Training Prec@1 99.805 (99.727)	Training Prec@5 99.805 (99.925)	
2022-04-04 02:53:21,296: ============================================================
2022-04-04 02:54:00,833: time cost, forward:0.010842972341767274, backward:0.05897315305312756, data cost:0.33142795476900244 
2022-04-04 02:54:00,833: ============================================================
2022-04-04 02:54:00,834: Epoch 19/26 Batch 6500/7662 eta: 6:01:05.438814	Training Loss 2.2771 (2.2611)	Training Prec@1 99.805 (99.726)	Training Prec@5 99.805 (99.924)	
2022-04-04 02:54:00,834: ============================================================
2022-04-04 02:54:39,409: time cost, forward:0.010831504721481849, backward:0.05898206449671394, data cost:0.33118146302971374 
2022-04-04 02:54:39,410: ============================================================
2022-04-04 02:54:39,410: Epoch 19/26 Batch 6600/7662 eta: 5:51:39.929703	Training Loss 2.3307 (2.2626)	Training Prec@1 99.805 (99.725)	Training Prec@5 100.000 (99.924)	
2022-04-04 02:54:39,410: ============================================================
2022-04-04 02:55:17,688: time cost, forward:0.01081923848391469, backward:0.05900002291067658, data cost:0.330891041742152 
2022-04-04 02:55:17,688: ============================================================
2022-04-04 02:55:17,689: Epoch 19/26 Batch 6700/7662 eta: 5:48:19.127989	Training Loss 2.3812 (2.2641)	Training Prec@1 100.000 (99.724)	Training Prec@5 100.000 (99.924)	
2022-04-04 02:55:17,689: ============================================================
2022-04-04 02:55:57,945: time cost, forward:0.010818402019208416, backward:0.05900791757754463, data cost:0.3309101915338457 
2022-04-04 02:55:57,946: ============================================================
2022-04-04 02:55:57,946: Epoch 19/26 Batch 6800/7662 eta: 6:05:38.968234	Training Loss 2.4054 (2.2656)	Training Prec@1 99.219 (99.722)	Training Prec@5 99.805 (99.924)	
2022-04-04 02:55:57,946: ============================================================
2022-04-04 02:56:38,305: time cost, forward:0.01080793763506428, backward:0.059023371467142455, data cost:0.33093290737460085 
2022-04-04 02:56:38,306: ============================================================
2022-04-04 02:56:38,306: Epoch 19/26 Batch 6900/7662 eta: 6:05:54.765450	Training Loss 2.2570 (2.2673)	Training Prec@1 99.805 (99.721)	Training Prec@5 100.000 (99.923)	
2022-04-04 02:56:38,306: ============================================================
2022-04-04 02:57:18,809: time cost, forward:0.010801564729082566, backward:0.059032794355852194, data cost:0.3309867966258538 
2022-04-04 02:57:18,809: ============================================================
2022-04-04 02:57:18,809: Epoch 19/26 Batch 7000/7662 eta: 6:06:32.035349	Training Loss 2.4115 (2.2689)	Training Prec@1 99.609 (99.720)	Training Prec@5 100.000 (99.923)	
2022-04-04 02:57:18,810: ============================================================
2022-04-04 02:57:59,323: time cost, forward:0.01079386361032527, backward:0.05903945474292816, data cost:0.3310388421521991 
2022-04-04 02:57:59,324: ============================================================
2022-04-04 02:57:59,324: Epoch 19/26 Batch 7100/7662 eta: 6:05:57.794178	Training Loss 2.5564 (2.2704)	Training Prec@1 99.609 (99.718)	Training Prec@5 99.805 (99.923)	
2022-04-04 02:57:59,324: ============================================================
2022-04-04 02:58:38,356: time cost, forward:0.010786073706947875, backward:0.059051393750542185, data cost:0.33088955665267267 
2022-04-04 02:58:38,357: ============================================================
2022-04-04 02:58:38,357: Epoch 19/26 Batch 7200/7662 eta: 5:51:55.518334	Training Loss 2.3123 (2.2718)	Training Prec@1 100.000 (99.717)	Training Prec@5 100.000 (99.922)	
2022-04-04 02:58:38,357: ============================================================
2022-04-04 02:59:18,810: time cost, forward:0.010777024410084218, backward:0.05905916158720832, data cost:0.3309288958455295 
2022-04-04 02:59:18,811: ============================================================
2022-04-04 02:59:18,811: Epoch 19/26 Batch 7300/7662 eta: 6:04:03.893209	Training Loss 2.3746 (2.2731)	Training Prec@1 99.805 (99.716)	Training Prec@5 99.805 (99.922)	
2022-04-04 02:59:18,811: ============================================================
2022-04-04 02:59:58,297: time cost, forward:0.010771511792975481, backward:0.05906223931784951, data cost:0.33084972785411454 
2022-04-04 02:59:58,297: ============================================================
2022-04-04 02:59:58,298: Epoch 19/26 Batch 7400/7662 eta: 5:54:42.190934	Training Loss 2.3986 (2.2744)	Training Prec@1 99.609 (99.715)	Training Prec@5 99.805 (99.922)	
2022-04-04 02:59:58,298: ============================================================
2022-04-04 03:00:38,204: time cost, forward:0.010764521715688393, backward:0.059068862685109316, data cost:0.33081865892487855 
2022-04-04 03:00:38,205: ============================================================
2022-04-04 03:00:38,205: Epoch 19/26 Batch 7500/7662 eta: 5:57:49.007392	Training Loss 2.2484 (2.2758)	Training Prec@1 99.609 (99.713)	Training Prec@5 100.000 (99.921)	
2022-04-04 03:00:38,205: ============================================================
2022-04-04 03:01:18,653: time cost, forward:0.010755519958558342, backward:0.05907949364048852, data cost:0.3308642256305412 
2022-04-04 03:01:18,654: ============================================================
2022-04-04 03:01:18,654: Epoch 19/26 Batch 7600/7662 eta: 6:01:59.936977	Training Loss 2.4901 (2.2774)	Training Prec@1 99.219 (99.713)	Training Prec@5 99.609 (99.921)	
2022-04-04 03:01:18,654: ============================================================
2022-04-04 03:01:45,340: Epoch: 19/26 eta: 6:01:34.454063	Training Loss 2.3876 (2.2782)	Training Prec@1 99.414 (99.711)	Training Prec@5 99.609 (99.920)
2022-04-04 03:01:45,341: ============================================================
2022-04-04 03:02:25,472: time cost, forward:0.010306218657830749, backward:0.058504398423011854, data cost:0.33126046922471786 
2022-04-04 03:02:25,472: ============================================================
2022-04-04 03:02:25,472: Epoch 20/26 Batch 100/7662 eta: 5:56:14.846211	Training Loss 1.7565 (1.8165)	Training Prec@1 99.805 (99.872)	Training Prec@5 100.000 (99.966)	
2022-04-04 03:02:25,472: ============================================================
2022-04-04 03:03:05,536: time cost, forward:0.010303689007783057, backward:0.058461549893096466, data cost:0.331097674729237 
2022-04-04 03:03:05,537: ============================================================
2022-04-04 03:03:05,537: Epoch 20/26 Batch 200/7662 eta: 5:56:48.693159	Training Loss 1.8066 (1.7839)	Training Prec@1 99.805 (99.874)	Training Prec@5 100.000 (99.969)	
2022-04-04 03:03:05,538: ============================================================
2022-04-04 03:03:43,860: time cost, forward:0.010509742143560812, backward:0.0582414255493062, data cost:0.3253469315659641 
2022-04-04 03:03:43,861: ============================================================
2022-04-04 03:03:43,861: Epoch 20/26 Batch 300/7662 eta: 5:40:39.934687	Training Loss 1.7119 (1.7632)	Training Prec@1 99.805 (99.881)	Training Prec@5 100.000 (99.971)	
2022-04-04 03:03:43,861: ============================================================
2022-04-04 03:04:23,535: time cost, forward:0.010440227680636528, backward:0.05838405518304734, data cost:0.3257893314935211 
2022-04-04 03:04:23,536: ============================================================
2022-04-04 03:04:23,536: Epoch 20/26 Batch 400/7662 eta: 5:52:01.058443	Training Loss 1.6052 (1.7485)	Training Prec@1 99.805 (99.880)	Training Prec@5 99.805 (99.969)	
2022-04-04 03:04:23,536: ============================================================
2022-04-04 03:05:04,904: time cost, forward:0.01041993397271227, backward:0.058513578288779705, data cost:0.32935549214273274 
2022-04-04 03:05:04,905: ============================================================
2022-04-04 03:05:04,905: Epoch 20/26 Batch 500/7662 eta: 6:06:21.279536	Training Loss 1.7264 (1.7363)	Training Prec@1 100.000 (99.883)	Training Prec@5 100.000 (99.969)	
2022-04-04 03:05:04,905: ============================================================
2022-04-04 03:05:45,351: time cost, forward:0.010348330356043847, backward:0.058631979762413265, data cost:0.3303390134356058 
2022-04-04 03:05:45,351: ============================================================
2022-04-04 03:05:45,351: Epoch 20/26 Batch 600/7662 eta: 5:57:30.854921	Training Loss 1.6162 (1.7279)	Training Prec@1 99.805 (99.886)	Training Prec@5 100.000 (99.969)	
2022-04-04 03:05:45,352: ============================================================
2022-04-04 03:06:24,775: time cost, forward:0.010281208758702094, backward:0.0587215723738991, data cost:0.3294869267377731 
2022-04-04 03:06:24,775: ============================================================
2022-04-04 03:06:24,775: Epoch 20/26 Batch 700/7662 eta: 5:47:49.109937	Training Loss 1.7720 (1.7187)	Training Prec@1 100.000 (99.888)	Training Prec@5 100.000 (99.971)	
2022-04-04 03:06:24,776: ============================================================
2022-04-04 03:07:03,523: time cost, forward:0.01024057629409809, backward:0.05882258021339159, data cost:0.32795901949026707 
2022-04-04 03:07:03,524: ============================================================
2022-04-04 03:07:03,524: Epoch 20/26 Batch 800/7662 eta: 5:41:12.747106	Training Loss 1.7559 (1.7117)	Training Prec@1 100.000 (99.890)	Training Prec@5 100.000 (99.972)	
2022-04-04 03:07:03,524: ============================================================
2022-04-04 03:07:44,102: time cost, forward:0.010188184139858496, backward:0.05887830588921026, data cost:0.32886465372842993 
2022-04-04 03:07:44,102: ============================================================
2022-04-04 03:07:44,102: Epoch 20/26 Batch 900/7662 eta: 5:56:39.103550	Training Loss 1.6088 (1.7066)	Training Prec@1 99.805 (99.889)	Training Prec@5 100.000 (99.971)	
2022-04-04 03:07:44,103: ============================================================
2022-04-04 03:08:22,938: time cost, forward:0.010176841680471366, backward:0.058929219021572846, data cost:0.32778737351701065 
2022-04-04 03:08:22,938: ============================================================
2022-04-04 03:08:22,939: Epoch 20/26 Batch 1000/7662 eta: 5:40:41.439015	Training Loss 1.5980 (1.6996)	Training Prec@1 100.000 (99.891)	Training Prec@5 100.000 (99.971)	
2022-04-04 03:08:22,939: ============================================================
2022-04-04 03:09:02,384: time cost, forward:0.010163255774833811, backward:0.058968870286186574, data cost:0.3275428751146284 
2022-04-04 03:09:02,384: ============================================================
2022-04-04 03:09:02,384: Epoch 20/26 Batch 1100/7662 eta: 5:45:22.768648	Training Loss 1.5335 (1.6942)	Training Prec@1 100.000 (99.890)	Training Prec@5 100.000 (99.971)	
2022-04-04 03:09:02,384: ============================================================
2022-04-04 03:09:42,535: time cost, forward:0.010150306119433634, backward:0.05900042587961128, data cost:0.32782790559445746 
2022-04-04 03:09:42,535: ============================================================
2022-04-04 03:09:42,536: Epoch 20/26 Batch 1200/7662 eta: 5:50:53.332005	Training Loss 1.7369 (1.6898)	Training Prec@1 99.805 (99.891)	Training Prec@5 100.000 (99.971)	
2022-04-04 03:09:42,536: ============================================================
2022-04-04 03:10:22,841: time cost, forward:0.010177484744323777, backward:0.05898021054873566, data cost:0.3282972382434613 
2022-04-04 03:10:22,841: ============================================================
2022-04-04 03:10:22,842: Epoch 20/26 Batch 1300/7662 eta: 5:51:34.197753	Training Loss 1.5639 (1.6855)	Training Prec@1 100.000 (99.891)	Training Prec@5 100.000 (99.972)	
2022-04-04 03:10:22,842: ============================================================
2022-04-04 03:11:02,758: time cost, forward:0.010188042393235158, backward:0.05898432598700261, data cost:0.3283399189259854 
2022-04-04 03:11:02,758: ============================================================
2022-04-04 03:11:02,758: Epoch 20/26 Batch 1400/7662 eta: 5:47:30.504625	Training Loss 1.4902 (1.6814)	Training Prec@1 99.609 (99.891)	Training Prec@5 99.805 (99.972)	
2022-04-04 03:11:02,759: ============================================================
2022-04-04 03:11:42,746: time cost, forward:0.010251090079645381, backward:0.05897183096989383, data cost:0.32839639159820333 
2022-04-04 03:11:42,746: ============================================================
2022-04-04 03:11:42,747: Epoch 20/26 Batch 1500/7662 eta: 5:47:27.828404	Training Loss 1.6596 (1.6779)	Training Prec@1 100.000 (99.891)	Training Prec@5 100.000 (99.971)	
2022-04-04 03:11:42,747: ============================================================
2022-04-04 03:12:22,171: time cost, forward:0.010272349768537817, backward:0.05894737559754525, data cost:0.3281359402666694 
2022-04-04 03:12:22,171: ============================================================
2022-04-04 03:12:22,172: Epoch 20/26 Batch 1600/7662 eta: 5:41:54.976629	Training Loss 1.5410 (1.6726)	Training Prec@1 100.000 (99.893)	Training Prec@5 100.000 (99.973)	
2022-04-04 03:12:22,172: ============================================================
2022-04-04 03:13:01,022: time cost, forward:0.010273799677327354, backward:0.05896627236422965, data cost:0.32761148370806786 
2022-04-04 03:13:01,023: ============================================================
2022-04-04 03:13:01,024: Epoch 20/26 Batch 1700/7662 eta: 5:36:17.533105	Training Loss 1.7092 (1.6686)	Training Prec@1 100.000 (99.893)	Training Prec@5 100.000 (99.972)	
2022-04-04 03:13:01,024: ============================================================
2022-04-04 03:13:40,027: time cost, forward:0.010305275182845925, backward:0.05894342841805187, data cost:0.32702679167594295 
2022-04-04 03:13:40,028: ============================================================
2022-04-04 03:13:40,028: Epoch 20/26 Batch 1800/7662 eta: 5:36:57.886999	Training Loss 1.5085 (1.6645)	Training Prec@1 99.805 (99.892)	Training Prec@5 100.000 (99.972)	
2022-04-04 03:13:40,028: ============================================================
2022-04-04 03:14:19,572: time cost, forward:0.010295286374446152, backward:0.058959150640759864, data cost:0.32708772274617964 
2022-04-04 03:14:19,572: ============================================================
2022-04-04 03:14:19,572: Epoch 20/26 Batch 1900/7662 eta: 5:40:58.373529	Training Loss 1.5734 (1.6617)	Training Prec@1 100.000 (99.892)	Training Prec@5 100.000 (99.971)	
2022-04-04 03:14:19,573: ============================================================
2022-04-04 03:14:59,801: time cost, forward:0.010298285143204843, backward:0.05896747464117496, data cost:0.32732311638073064 
2022-04-04 03:14:59,802: ============================================================
2022-04-04 03:14:59,802: Epoch 20/26 Batch 2000/7662 eta: 5:46:12.572279	Training Loss 1.6714 (1.6575)	Training Prec@1 99.805 (99.893)	Training Prec@5 100.000 (99.972)	
2022-04-04 03:14:59,802: ============================================================
2022-04-04 03:15:39,244: time cost, forward:0.010393562289633713, backward:0.05889086918696839, data cost:0.32717325143327936 
2022-04-04 03:15:39,245: ============================================================
2022-04-04 03:15:39,245: Epoch 20/26 Batch 2100/7662 eta: 5:38:46.847249	Training Loss 1.5094 (1.6536)	Training Prec@1 100.000 (99.894)	Training Prec@5 100.000 (99.972)	
2022-04-04 03:15:39,245: ============================================================
2022-04-04 03:16:19,612: time cost, forward:0.010404631461594092, backward:0.05891431847069685, data cost:0.3274130965428441 
2022-04-04 03:16:19,612: ============================================================
2022-04-04 03:16:19,612: Epoch 20/26 Batch 2200/7662 eta: 5:46:03.094172	Training Loss 1.5217 (1.6507)	Training Prec@1 100.000 (99.896)	Training Prec@5 100.000 (99.973)	
2022-04-04 03:16:19,613: ============================================================
2022-04-04 03:16:59,428: time cost, forward:0.010396094776433983, backward:0.05894216831583933, data cost:0.3274677463488353 
2022-04-04 03:16:59,428: ============================================================
2022-04-04 03:16:59,429: Epoch 20/26 Batch 2300/7662 eta: 5:40:39.684098	Training Loss 1.6805 (1.6484)	Training Prec@1 99.805 (99.896)	Training Prec@5 100.000 (99.973)	
2022-04-04 03:16:59,429: ============================================================
2022-04-04 03:17:40,242: time cost, forward:0.010398269445014626, backward:0.05896110353791848, data cost:0.3278898357003368 
2022-04-04 03:17:40,242: ============================================================
2022-04-04 03:17:40,243: Epoch 20/26 Batch 2400/7662 eta: 5:48:30.972345	Training Loss 1.5816 (1.6451)	Training Prec@1 100.000 (99.897)	Training Prec@5 100.000 (99.973)	
2022-04-04 03:17:40,243: ============================================================
2022-04-04 03:18:20,365: time cost, forward:0.010411492153471496, backward:0.05894836438756411, data cost:0.3280322129080514 
2022-04-04 03:18:20,366: ============================================================
2022-04-04 03:18:20,366: Epoch 20/26 Batch 2500/7662 eta: 5:41:57.065708	Training Loss 1.7258 (1.6431)	Training Prec@1 100.000 (99.897)	Training Prec@5 100.000 (99.973)	
2022-04-04 03:18:20,366: ============================================================
2022-04-04 03:19:00,223: time cost, forward:0.010508495920114491, backward:0.058848024561296015, data cost:0.3280537062399476 
2022-04-04 03:19:00,223: ============================================================
2022-04-04 03:19:00,223: Epoch 20/26 Batch 2600/7662 eta: 5:39:01.235376	Training Loss 1.6083 (1.6398)	Training Prec@1 100.000 (99.898)	Training Prec@5 100.000 (99.973)	
2022-04-04 03:19:00,223: ============================================================
2022-04-04 03:19:38,169: time cost, forward:0.010510933580289024, backward:0.05887348681036832, data cost:0.3273460974557261 
2022-04-04 03:19:38,169: ============================================================
2022-04-04 03:19:38,170: Epoch 20/26 Batch 2700/7662 eta: 5:22:07.883558	Training Loss 1.6077 (1.6373)	Training Prec@1 99.805 (99.899)	Training Prec@5 99.805 (99.973)	
2022-04-04 03:19:38,170: ============================================================
2022-04-04 03:20:17,427: time cost, forward:0.010515386694539825, backward:0.058873546511073245, data cost:0.3271763703788166 
2022-04-04 03:20:17,427: ============================================================
2022-04-04 03:20:17,427: Epoch 20/26 Batch 2800/7662 eta: 5:32:36.802793	Training Loss 1.5656 (1.6345)	Training Prec@1 100.000 (99.900)	Training Prec@5 100.000 (99.974)	
2022-04-04 03:20:17,428: ============================================================
2022-04-04 03:20:56,358: time cost, forward:0.010509780704173272, backward:0.05888792160010494, data cost:0.3269157468059549 
2022-04-04 03:20:56,358: ============================================================
2022-04-04 03:20:56,359: Epoch 20/26 Batch 2900/7662 eta: 5:29:11.735020	Training Loss 1.4210 (1.6323)	Training Prec@1 100.000 (99.900)	Training Prec@5 100.000 (99.974)	
2022-04-04 03:20:56,359: ============================================================
2022-04-04 03:21:36,262: time cost, forward:0.01051458735273615, backward:0.058897547182857134, data cost:0.326972203717386 
2022-04-04 03:21:36,262: ============================================================
2022-04-04 03:21:36,262: Epoch 20/26 Batch 3000/7662 eta: 5:36:45.130867	Training Loss 1.5139 (1.6301)	Training Prec@1 100.000 (99.901)	Training Prec@5 100.000 (99.975)	
2022-04-04 03:21:36,262: ============================================================
2022-04-04 03:22:13,996: time cost, forward:0.010523496269602743, backward:0.05890015441781284, data cost:0.3263054019445448 
2022-04-04 03:22:13,996: ============================================================
2022-04-04 03:22:13,996: Epoch 20/26 Batch 3100/7662 eta: 5:17:48.966283	Training Loss 1.7694 (1.6282)	Training Prec@1 99.609 (99.901)	Training Prec@5 99.805 (99.974)	
2022-04-04 03:22:13,997: ============================================================
2022-04-04 03:22:52,936: time cost, forward:0.010531887929116834, backward:0.058895133964416944, data cost:0.32609932427854976 
2022-04-04 03:22:52,936: ============================================================
2022-04-04 03:22:52,937: Epoch 20/26 Batch 3200/7662 eta: 5:27:19.678101	Training Loss 1.5469 (1.6259)	Training Prec@1 100.000 (99.902)	Training Prec@5 100.000 (99.975)	
2022-04-04 03:22:52,937: ============================================================
2022-04-04 03:23:31,880: time cost, forward:0.010532869212950458, backward:0.058909432459470175, data cost:0.3258790979243727 
2022-04-04 03:23:31,881: ============================================================
2022-04-04 03:23:31,881: Epoch 20/26 Batch 3300/7662 eta: 5:26:42.458923	Training Loss 1.4932 (1.6239)	Training Prec@1 100.000 (99.903)	Training Prec@5 100.000 (99.975)	
2022-04-04 03:23:31,881: ============================================================
2022-04-04 03:24:12,114: time cost, forward:0.01054519946240579, backward:0.0589107652733206, data cost:0.32605373912013325 
2022-04-04 03:24:12,114: ============================================================
2022-04-04 03:24:12,114: Epoch 20/26 Batch 3400/7662 eta: 5:36:51.226985	Training Loss 1.6001 (1.6224)	Training Prec@1 99.609 (99.902)	Training Prec@5 99.805 (99.975)	
2022-04-04 03:24:12,115: ============================================================
2022-04-04 03:24:51,478: time cost, forward:0.010549233211180455, backward:0.058912442458905846, data cost:0.32599406407267134 
2022-04-04 03:24:51,478: ============================================================
2022-04-04 03:24:51,479: Epoch 20/26 Batch 3500/7662 eta: 5:28:55.243043	Training Loss 1.5010 (1.6208)	Training Prec@1 99.805 (99.903)	Training Prec@5 100.000 (99.975)	
2022-04-04 03:24:51,479: ============================================================
2022-04-04 03:25:30,650: time cost, forward:0.010545276608457827, backward:0.05892852068808583, data cost:0.32586669511151134 
2022-04-04 03:25:30,650: ============================================================
2022-04-04 03:25:30,650: Epoch 20/26 Batch 3600/7662 eta: 5:26:39.543394	Training Loss 1.3965 (1.6189)	Training Prec@1 100.000 (99.903)	Training Prec@5 100.000 (99.975)	
2022-04-04 03:25:30,650: ============================================================
2022-04-04 03:26:09,167: time cost, forward:0.010539686012732141, backward:0.058948335340777806, data cost:0.325552399141075 
2022-04-04 03:26:09,167: ============================================================
2022-04-04 03:26:09,167: Epoch 20/26 Batch 3700/7662 eta: 5:20:33.611438	Training Loss 1.6145 (1.6168)	Training Prec@1 99.609 (99.903)	Training Prec@5 99.805 (99.975)	
2022-04-04 03:26:09,168: ============================================================
2022-04-04 03:26:47,713: time cost, forward:0.010548273429458912, backward:0.058951988945700175, data cost:0.32527494110474936 
2022-04-04 03:26:47,714: ============================================================
2022-04-04 03:26:47,715: Epoch 20/26 Batch 3800/7662 eta: 5:20:09.975715	Training Loss 1.5046 (1.6151)	Training Prec@1 99.805 (99.903)	Training Prec@5 100.000 (99.975)	
2022-04-04 03:26:47,715: ============================================================
2022-04-04 03:27:26,543: time cost, forward:0.010590277931328827, backward:0.05891357999362833, data cost:0.32508891880527524 
2022-04-04 03:27:26,544: ============================================================
2022-04-04 03:27:26,544: Epoch 20/26 Batch 3900/7662 eta: 5:21:51.805916	Training Loss 1.4950 (1.6132)	Training Prec@1 100.000 (99.903)	Training Prec@5 100.000 (99.975)	
2022-04-04 03:27:26,544: ============================================================
2022-04-04 03:28:08,123: time cost, forward:0.010596441370035655, backward:0.058910949673167345, data cost:0.32560115064433526 
2022-04-04 03:28:08,124: ============================================================
2022-04-04 03:28:08,124: Epoch 20/26 Batch 4000/7662 eta: 5:43:58.270712	Training Loss 1.5446 (1.6114)	Training Prec@1 100.000 (99.903)	Training Prec@5 100.000 (99.975)	
2022-04-04 03:28:08,124: ============================================================
2022-04-04 03:28:47,682: time cost, forward:0.01058706687002189, backward:0.05891204089704273, data cost:0.32560628075284415 
2022-04-04 03:28:47,682: ============================================================
2022-04-04 03:28:47,683: Epoch 20/26 Batch 4100/7662 eta: 5:26:35.293552	Training Loss 1.6866 (1.6095)	Training Prec@1 99.805 (99.904)	Training Prec@5 100.000 (99.975)	
2022-04-04 03:28:47,683: ============================================================
2022-04-04 03:29:27,918: time cost, forward:0.010583784103847794, backward:0.05892224713829933, data cost:0.3257582229669675 
2022-04-04 03:29:27,918: ============================================================
2022-04-04 03:29:27,919: Epoch 20/26 Batch 4200/7662 eta: 5:31:30.644708	Training Loss 1.4615 (1.6080)	Training Prec@1 100.000 (99.904)	Training Prec@5 100.000 (99.976)	
2022-04-04 03:29:27,919: ============================================================
2022-04-04 03:30:07,355: time cost, forward:0.010569455818288075, backward:0.05894413053171389, data cost:0.325716344609763 
2022-04-04 03:30:07,356: ============================================================
2022-04-04 03:30:07,356: Epoch 20/26 Batch 4300/7662 eta: 5:24:16.497330	Training Loss 1.5923 (1.6065)	Training Prec@1 99.805 (99.904)	Training Prec@5 100.000 (99.976)	
2022-04-04 03:30:07,356: ============================================================
2022-04-04 03:30:45,972: time cost, forward:0.01057118669264044, backward:0.05894195748936401, data cost:0.32549647386303326 
2022-04-04 03:30:45,973: ============================================================
2022-04-04 03:30:45,973: Epoch 20/26 Batch 4400/7662 eta: 5:16:52.886432	Training Loss 1.6625 (1.6048)	Training Prec@1 100.000 (99.904)	Training Prec@5 100.000 (99.976)	
2022-04-04 03:30:45,973: ============================================================
2022-04-04 03:31:24,480: time cost, forward:0.010569708748482736, backward:0.05895458419843896, data cost:0.32525981164132256 
2022-04-04 03:31:24,480: ============================================================
2022-04-04 03:31:24,480: Epoch 20/26 Batch 4500/7662 eta: 5:15:20.685045	Training Loss 1.4026 (1.6031)	Training Prec@1 100.000 (99.905)	Training Prec@5 100.000 (99.976)	
2022-04-04 03:31:24,480: ============================================================
2022-04-04 03:32:02,588: time cost, forward:0.010570123626450193, backward:0.05895980940510019, data cost:0.32494343148804045 
2022-04-04 03:32:02,589: ============================================================
2022-04-04 03:32:02,589: Epoch 20/26 Batch 4600/7662 eta: 5:11:26.688628	Training Loss 1.5827 (1.6015)	Training Prec@1 100.000 (99.905)	Training Prec@5 100.000 (99.976)	
2022-04-04 03:32:02,589: ============================================================
2022-04-04 03:32:42,934: time cost, forward:0.01058164462811847, backward:0.05895046448042911, data cost:0.3251190838546899 
2022-04-04 03:32:42,935: ============================================================
2022-04-04 03:32:42,935: Epoch 20/26 Batch 4700/7662 eta: 5:29:03.246593	Training Loss 1.6071 (1.6003)	Training Prec@1 100.000 (99.905)	Training Prec@5 100.000 (99.976)	
2022-04-04 03:32:42,935: ============================================================
2022-04-04 03:33:22,043: time cost, forward:0.010579729557136715, backward:0.05895877813493045, data cost:0.3250127593833572 
2022-04-04 03:33:22,044: ============================================================
2022-04-04 03:33:22,044: Epoch 20/26 Batch 4800/7662 eta: 5:18:18.801659	Training Loss 1.6153 (1.5987)	Training Prec@1 99.609 (99.905)	Training Prec@5 99.805 (99.976)	
2022-04-04 03:33:22,044: ============================================================
2022-04-04 03:34:01,788: time cost, forward:0.010575293910627488, backward:0.05897047155169619, data cost:0.32505533904001455 
2022-04-04 03:34:01,789: ============================================================
2022-04-04 03:34:01,789: Epoch 20/26 Batch 4900/7662 eta: 5:22:49.804589	Training Loss 1.5335 (1.5973)	Training Prec@1 99.609 (99.905)	Training Prec@5 99.805 (99.975)	
2022-04-04 03:34:01,789: ============================================================
2022-04-04 03:34:43,098: time cost, forward:0.010578105582740693, backward:0.05896805200273453, data cost:0.32541904336906813 
2022-04-04 03:34:43,099: ============================================================
2022-04-04 03:34:43,099: Epoch 20/26 Batch 5000/7662 eta: 5:34:50.965644	Training Loss 1.5736 (1.5957)	Training Prec@1 100.000 (99.905)	Training Prec@5 100.000 (99.975)	
2022-04-04 03:34:43,099: ============================================================
2022-04-04 03:35:24,658: time cost, forward:0.01058250704239948, backward:0.05896552629764465, data cost:0.32581921740358166 
2022-04-04 03:35:24,659: ============================================================
2022-04-04 03:35:24,659: Epoch 20/26 Batch 5100/7662 eta: 5:36:11.154420	Training Loss 1.5113 (1.5943)	Training Prec@1 100.000 (99.906)	Training Prec@5 100.000 (99.976)	
2022-04-04 03:35:24,659: ============================================================
2022-04-04 03:36:04,166: time cost, forward:0.010582454618661995, backward:0.05897047501799005, data cost:0.3257907217432614 
2022-04-04 03:36:04,166: ============================================================
2022-04-04 03:36:04,166: Epoch 20/26 Batch 5200/7662 eta: 5:18:55.438192	Training Loss 1.6139 (1.5933)	Training Prec@1 100.000 (99.906)	Training Prec@5 100.000 (99.976)	
2022-04-04 03:36:04,166: ============================================================
2022-04-04 03:36:44,838: time cost, forward:0.010580061156472118, backward:0.05897560950202028, data cost:0.32599705330581796 
2022-04-04 03:36:44,838: ============================================================
2022-04-04 03:36:44,839: Epoch 20/26 Batch 5300/7662 eta: 5:27:38.995435	Training Loss 1.3107 (1.5919)	Training Prec@1 100.000 (99.906)	Training Prec@5 100.000 (99.976)	
2022-04-04 03:36:44,839: ============================================================
2022-04-04 03:37:22,562: time cost, forward:0.010578181836798933, backward:0.05898759020194011, data cost:0.32563726847691543 
2022-04-04 03:37:22,563: ============================================================
2022-04-04 03:37:22,563: Epoch 20/26 Batch 5400/7662 eta: 5:03:16.369191	Training Loss 1.6774 (1.5905)	Training Prec@1 99.805 (99.906)	Training Prec@5 99.805 (99.976)	
2022-04-04 03:37:22,563: ============================================================
2022-04-04 03:38:02,031: time cost, forward:0.010613584457733215, backward:0.0589576984973664, data cost:0.3256143046890872 
2022-04-04 03:38:02,032: ============================================================
2022-04-04 03:38:02,032: Epoch 20/26 Batch 5500/7662 eta: 5:16:38.444972	Training Loss 1.5146 (1.5892)	Training Prec@1 99.609 (99.906)	Training Prec@5 100.000 (99.976)	
2022-04-04 03:38:02,032: ============================================================
2022-04-04 03:38:41,050: time cost, forward:0.010609154404008106, backward:0.058961350910577165, data cost:0.32552619950433653 
2022-04-04 03:38:41,051: ============================================================
2022-04-04 03:38:41,051: Epoch 20/26 Batch 5600/7662 eta: 5:12:22.796374	Training Loss 1.5028 (1.5877)	Training Prec@1 99.805 (99.906)	Training Prec@5 100.000 (99.976)	
2022-04-04 03:38:41,051: ============================================================
2022-04-04 03:39:19,786: time cost, forward:0.010610024538724585, backward:0.05896489125298793, data cost:0.3253547714392037 
2022-04-04 03:39:19,786: ============================================================
2022-04-04 03:39:19,786: Epoch 20/26 Batch 5700/7662 eta: 5:09:27.759343	Training Loss 1.5387 (1.5862)	Training Prec@1 100.000 (99.906)	Training Prec@5 100.000 (99.976)	
2022-04-04 03:39:19,787: ============================================================
2022-04-04 03:39:59,132: time cost, forward:0.010604596791708956, backward:0.058973591087974134, data cost:0.32532084495944386 
2022-04-04 03:39:59,133: ============================================================
2022-04-04 03:39:59,133: Epoch 20/26 Batch 5800/7662 eta: 5:13:41.439066	Training Loss 1.4741 (1.5848)	Training Prec@1 100.000 (99.907)	Training Prec@5 100.000 (99.976)	
2022-04-04 03:39:59,133: ============================================================
2022-04-04 03:40:40,189: time cost, forward:0.010601330013634048, backward:0.058978829914926575, data cost:0.3255870252933557 
2022-04-04 03:40:40,190: ============================================================
2022-04-04 03:40:40,190: Epoch 20/26 Batch 5900/7662 eta: 5:26:38.575756	Training Loss 1.2217 (1.5835)	Training Prec@1 100.000 (99.907)	Training Prec@5 100.000 (99.976)	
2022-04-04 03:40:40,190: ============================================================
2022-04-04 03:41:18,876: time cost, forward:0.01059359958875694, backward:0.05899034247515221, data cost:0.32542951136037573 
2022-04-04 03:41:18,877: ============================================================
2022-04-04 03:41:18,877: Epoch 20/26 Batch 6000/7662 eta: 5:07:08.479668	Training Loss 1.3418 (1.5820)	Training Prec@1 100.000 (99.907)	Training Prec@5 100.000 (99.976)	
2022-04-04 03:41:18,877: ============================================================
2022-04-04 03:41:58,086: time cost, forward:0.010604823880712407, backward:0.05898167520570919, data cost:0.3253731672481193 
2022-04-04 03:41:58,087: ============================================================
2022-04-04 03:41:58,087: Epoch 20/26 Batch 6100/7662 eta: 5:10:38.509898	Training Loss 1.5795 (1.5809)	Training Prec@1 100.000 (99.908)	Training Prec@5 100.000 (99.976)	
2022-04-04 03:41:58,087: ============================================================
2022-04-04 03:42:37,838: time cost, forward:0.010604670632748973, backward:0.05898284815957343, data cost:0.3253992273838679 
2022-04-04 03:42:37,839: ============================================================
2022-04-04 03:42:37,839: Epoch 20/26 Batch 6200/7662 eta: 5:14:16.266359	Training Loss 1.4388 (1.5798)	Training Prec@1 99.805 (99.908)	Training Prec@5 99.805 (99.976)	
2022-04-04 03:42:37,839: ============================================================
2022-04-04 03:43:18,074: time cost, forward:0.010597883245077828, backward:0.05899112143957874, data cost:0.32551037441985836 
2022-04-04 03:43:18,074: ============================================================
2022-04-04 03:43:18,075: Epoch 20/26 Batch 6300/7662 eta: 5:17:25.594726	Training Loss 1.5239 (1.5786)	Training Prec@1 100.000 (99.908)	Training Prec@5 100.000 (99.976)	
2022-04-04 03:43:18,075: ============================================================
2022-04-04 03:43:56,033: time cost, forward:0.0105978405313541, backward:0.058988304021936375, data cost:0.3252604922795225 
2022-04-04 03:43:56,034: ============================================================
2022-04-04 03:43:56,034: Epoch 20/26 Batch 6400/7662 eta: 4:58:50.158486	Training Loss 1.3357 (1.5775)	Training Prec@1 100.000 (99.908)	Training Prec@5 100.000 (99.976)	
2022-04-04 03:43:56,034: ============================================================
2022-04-04 03:44:33,544: time cost, forward:0.010590396526869049, backward:0.059004791847906364, data cost:0.3249352860953335 
2022-04-04 03:44:33,545: ============================================================
2022-04-04 03:44:33,545: Epoch 20/26 Batch 6500/7662 eta: 4:54:40.730135	Training Loss 1.4867 (1.5762)	Training Prec@1 100.000 (99.909)	Training Prec@5 100.000 (99.976)	
2022-04-04 03:44:33,545: ============================================================
2022-04-04 03:45:13,670: time cost, forward:0.010595264173236864, backward:0.05900359916080036, data cost:0.32502761680549846 
2022-04-04 03:45:13,671: ============================================================
2022-04-04 03:45:13,671: Epoch 20/26 Batch 6600/7662 eta: 5:14:33.358712	Training Loss 1.4176 (1.5750)	Training Prec@1 100.000 (99.909)	Training Prec@5 100.000 (99.976)	
2022-04-04 03:45:13,671: ============================================================
2022-04-04 03:45:52,741: time cost, forward:0.010589447746100327, backward:0.05900745759136304, data cost:0.3249575546524884 
2022-04-04 03:45:52,742: ============================================================
2022-04-04 03:45:52,742: Epoch 20/26 Batch 6700/7662 eta: 5:05:37.983744	Training Loss 1.4859 (1.5740)	Training Prec@1 99.805 (99.909)	Training Prec@5 100.000 (99.976)	
2022-04-04 03:45:52,742: ============================================================
2022-04-04 03:46:31,343: time cost, forward:0.010583741890365437, backward:0.05901478262294091, data cost:0.32483204734169363 
2022-04-04 03:46:31,343: ============================================================
2022-04-04 03:46:31,343: Epoch 20/26 Batch 6800/7662 eta: 5:01:18.822378	Training Loss 1.5337 (1.5729)	Training Prec@1 100.000 (99.909)	Training Prec@5 100.000 (99.976)	
2022-04-04 03:46:31,343: ============================================================
2022-04-04 03:47:09,227: time cost, forward:0.010584229299133628, backward:0.05902238586084067, data cost:0.32458529826229354 
2022-04-04 03:47:09,227: ============================================================
2022-04-04 03:47:09,227: Epoch 20/26 Batch 6900/7662 eta: 4:55:05.182586	Training Loss 1.3870 (1.5721)	Training Prec@1 99.805 (99.909)	Training Prec@5 100.000 (99.976)	
2022-04-04 03:47:09,228: ============================================================
2022-04-04 03:47:46,683: time cost, forward:0.010592417370201708, backward:0.059012437244878015, data cost:0.3243068451710404 
2022-04-04 03:47:46,683: ============================================================
2022-04-04 03:47:46,684: Epoch 20/26 Batch 7000/7662 eta: 4:51:07.664904	Training Loss 1.5557 (1.5710)	Training Prec@1 99.805 (99.910)	Training Prec@5 100.000 (99.976)	
2022-04-04 03:47:46,684: ============================================================
2022-04-04 03:48:25,989: time cost, forward:0.010594166740764613, backward:0.059010790072456014, data cost:0.3242765728361692 
2022-04-04 03:48:25,989: ============================================================
2022-04-04 03:48:25,990: Epoch 20/26 Batch 7100/7662 eta: 5:04:51.129643	Training Loss 1.7069 (1.5699)	Training Prec@1 99.805 (99.910)	Training Prec@5 100.000 (99.976)	
2022-04-04 03:48:25,990: ============================================================
2022-04-04 03:49:05,611: time cost, forward:0.010591965215804593, backward:0.059018000411828336, data cost:0.3242988782817249 
2022-04-04 03:49:05,611: ============================================================
2022-04-04 03:49:05,612: Epoch 20/26 Batch 7200/7662 eta: 5:06:38.378598	Training Loss 1.4470 (1.5689)	Training Prec@1 100.000 (99.910)	Training Prec@5 100.000 (99.976)	
2022-04-04 03:49:05,612: ============================================================
2022-04-04 03:49:46,353: time cost, forward:0.010585862719076826, backward:0.059028737691023986, data cost:0.32447192322343876 
2022-04-04 03:49:46,353: ============================================================
2022-04-04 03:49:46,353: Epoch 20/26 Batch 7300/7662 eta: 5:14:37.667769	Training Loss 1.5045 (1.5676)	Training Prec@1 100.000 (99.910)	Training Prec@5 100.000 (99.977)	
2022-04-04 03:49:46,353: ============================================================
2022-04-04 03:50:27,042: time cost, forward:0.01058997078704937, backward:0.05902971794740914, data cost:0.3246277541562599 
2022-04-04 03:50:27,042: ============================================================
2022-04-04 03:50:27,042: Epoch 20/26 Batch 7400/7662 eta: 5:13:32.672088	Training Loss 1.6252 (1.5667)	Training Prec@1 100.000 (99.911)	Training Prec@5 100.000 (99.977)	
2022-04-04 03:50:27,043: ============================================================
2022-04-04 03:51:05,466: time cost, forward:0.010585548337546487, backward:0.05903582789767884, data cost:0.32449826197173376 
2022-04-04 03:51:05,466: ============================================================
2022-04-04 03:51:05,467: Epoch 20/26 Batch 7500/7662 eta: 4:55:26.964989	Training Loss 1.4978 (1.5657)	Training Prec@1 100.000 (99.911)	Training Prec@5 100.000 (99.977)	
2022-04-04 03:51:05,467: ============================================================
2022-04-04 03:51:44,416: time cost, forward:0.010581791440128167, backward:0.05904050792011874, data cost:0.32442582191676117 
2022-04-04 03:51:44,416: ============================================================
2022-04-04 03:51:44,417: Epoch 20/26 Batch 7600/7662 eta: 4:58:50.574242	Training Loss 1.3802 (1.5645)	Training Prec@1 100.000 (99.911)	Training Prec@5 100.000 (99.977)	
2022-04-04 03:51:44,417: ============================================================
2022-04-04 03:52:10,885: Epoch: 20/26 eta: 4:58:26.035821	Training Loss 1.4692 (1.5638)	Training Prec@1 99.805 (99.911)	Training Prec@5 99.805 (99.977)
2022-04-04 03:52:10,885: ============================================================
2022-04-04 03:52:10,888: Save Checkpoint...
2022-04-04 03:52:10,888: ============================================================
2022-04-04 03:52:14,564: Save done!
2022-04-04 03:52:14,564: ============================================================
2022-04-04 03:53:12,729: time cost, forward:0.011587713703964695, backward:0.05621964522082396, data cost:0.5162803476507013 
2022-04-04 03:53:12,729: ============================================================
2022-04-04 03:53:12,729: Epoch 21/26 Batch 100/7662 eta: 7:24:35.577179	Training Loss 1.4579 (1.3405)	Training Prec@1 100.000 (99.953)	Training Prec@5 100.000 (99.996)	
2022-04-04 03:53:12,730: ============================================================
2022-04-04 03:53:48,042: time cost, forward:0.011261115721122704, backward:0.05704791941235413, data cost:0.39940856928801416 
2022-04-04 03:53:48,043: ============================================================
2022-04-04 03:53:48,043: Epoch 21/26 Batch 200/7662 eta: 4:29:24.121003	Training Loss 1.4474 (1.3368)	Training Prec@1 100.000 (99.951)	Training Prec@5 100.000 (99.993)	
2022-04-04 03:53:48,043: ============================================================
2022-04-04 03:54:25,209: time cost, forward:0.010970419465897474, backward:0.057553878994689736, data cost:0.3669315875573302 
2022-04-04 03:54:25,209: ============================================================
2022-04-04 03:54:25,209: Epoch 21/26 Batch 300/7662 eta: 4:42:54.896276	Training Loss 1.2453 (1.3377)	Training Prec@1 100.000 (99.957)	Training Prec@5 100.000 (99.993)	
2022-04-04 03:54:25,209: ============================================================
2022-04-04 03:55:03,199: time cost, forward:0.010829341142697442, backward:0.057903301745727845, data cost:0.35247593714778586 
2022-04-04 03:55:03,199: ============================================================
2022-04-04 03:55:03,200: Epoch 21/26 Batch 400/7662 eta: 4:48:33.436630	Training Loss 1.3055 (1.3383)	Training Prec@1 100.000 (99.962)	Training Prec@5 100.000 (99.994)	
2022-04-04 03:55:03,200: ============================================================
2022-04-04 03:55:41,962: time cost, forward:0.01083650952111743, backward:0.05794981247437502, data cost:0.3456922413590915 
2022-04-04 03:55:41,963: ============================================================
2022-04-04 03:55:41,963: Epoch 21/26 Batch 500/7662 eta: 4:53:46.768815	Training Loss 1.4356 (1.3398)	Training Prec@1 100.000 (99.960)	Training Prec@5 100.000 (99.993)	
2022-04-04 03:55:41,963: ============================================================
2022-04-04 03:56:19,432: time cost, forward:0.010770232132161798, backward:0.058195236728267, data cost:0.33874597055884154 
2022-04-04 03:56:19,433: ============================================================
2022-04-04 03:56:19,433: Epoch 21/26 Batch 600/7662 eta: 4:43:21.374536	Training Loss 1.3073 (1.3403)	Training Prec@1 100.000 (99.957)	Training Prec@5 100.000 (99.992)	
2022-04-04 03:56:19,433: ============================================================
2022-04-04 03:56:56,372: time cost, forward:0.010675871321060116, backward:0.05837991820896132, data cost:0.3330852784141792 
2022-04-04 03:56:56,373: ============================================================
2022-04-04 03:56:56,373: Epoch 21/26 Batch 700/7662 eta: 4:38:43.768941	Training Loss 1.3088 (1.3399)	Training Prec@1 100.000 (99.956)	Training Prec@5 100.000 (99.990)	
2022-04-04 03:56:56,373: ============================================================
2022-04-04 03:57:35,125: time cost, forward:0.010548580871505642, backward:0.05849462575996026, data cost:0.3312236206403214 
2022-04-04 03:57:35,126: ============================================================
2022-04-04 03:57:35,126: Epoch 21/26 Batch 800/7662 eta: 4:51:45.927487	Training Loss 1.3966 (1.3397)	Training Prec@1 100.000 (99.956)	Training Prec@5 100.000 (99.991)	
2022-04-04 03:57:35,126: ============================================================
2022-04-04 03:58:15,223: time cost, forward:0.010614188812731105, backward:0.05846125000178217, data cost:0.3311579312312855 
2022-04-04 03:58:15,224: ============================================================
2022-04-04 03:58:15,224: Epoch 21/26 Batch 900/7662 eta: 5:01:13.282906	Training Loss 1.4090 (1.3418)	Training Prec@1 100.000 (99.954)	Training Prec@5 100.000 (99.990)	
2022-04-04 03:58:15,224: ============================================================
2022-04-04 03:58:53,731: time cost, forward:0.010641987736638004, backward:0.05847836566997601, data cost:0.32956159604084984 
2022-04-04 03:58:53,732: ============================================================
2022-04-04 03:58:53,732: Epoch 21/26 Batch 1000/7662 eta: 4:48:38.324278	Training Loss 1.4303 (1.3421)	Training Prec@1 99.805 (99.956)	Training Prec@5 99.805 (99.990)	
2022-04-04 03:58:53,732: ============================================================
2022-04-04 03:59:33,455: time cost, forward:0.010736489534594993, backward:0.0584709459917452, data cost:0.3292917606503015 
2022-04-04 03:59:33,455: ============================================================
2022-04-04 03:59:33,456: Epoch 21/26 Batch 1100/7662 eta: 4:57:05.048062	Training Loss 1.3308 (1.3421)	Training Prec@1 100.000 (99.957)	Training Prec@5 100.000 (99.990)	
2022-04-04 03:59:33,456: ============================================================
2022-04-04 04:00:11,896: time cost, forward:0.010675771719619967, backward:0.05856129683684667, data cost:0.3280417493624524 
2022-04-04 04:00:11,897: ============================================================
2022-04-04 04:00:11,897: Epoch 21/26 Batch 1200/7662 eta: 4:46:51.391209	Training Loss 1.3382 (1.3425)	Training Prec@1 100.000 (99.957)	Training Prec@5 100.000 (99.989)	
2022-04-04 04:00:11,897: ============================================================
2022-04-04 04:00:50,670: time cost, forward:0.010699447803629464, backward:0.05856174446235169, data cost:0.3272694040023886 
2022-04-04 04:00:50,671: ============================================================
2022-04-04 04:00:50,671: Epoch 21/26 Batch 1300/7662 eta: 4:48:41.462977	Training Loss 1.3409 (1.3438)	Training Prec@1 100.000 (99.957)	Training Prec@5 100.000 (99.990)	
2022-04-04 04:00:50,671: ============================================================
2022-04-04 04:01:28,337: time cost, forward:0.010675486536687233, backward:0.058620740039762725, data cost:0.32573711267107297 
2022-04-04 04:01:28,337: ============================================================
2022-04-04 04:01:28,338: Epoch 21/26 Batch 1400/7662 eta: 4:39:49.201307	Training Loss 1.2973 (1.3436)	Training Prec@1 100.000 (99.957)	Training Prec@5 100.000 (99.990)	
2022-04-04 04:01:28,338: ============================================================
2022-04-04 04:02:07,429: time cost, forward:0.010681189084705152, backward:0.058663241938005053, data cost:0.32538469749104587 
2022-04-04 04:02:07,429: ============================================================
2022-04-04 04:02:07,430: Epoch 21/26 Batch 1500/7662 eta: 4:49:45.456311	Training Loss 1.2446 (1.3444)	Training Prec@1 100.000 (99.957)	Training Prec@5 100.000 (99.990)	
2022-04-04 04:02:07,430: ============================================================
2022-04-04 04:02:46,675: time cost, forward:0.01064225552304228, backward:0.058735684054281055, data cost:0.32519434242415535 
2022-04-04 04:02:46,675: ============================================================
2022-04-04 04:02:46,676: Epoch 21/26 Batch 1600/7662 eta: 4:50:14.525830	Training Loss 1.5394 (1.3454)	Training Prec@1 100.000 (99.956)	Training Prec@5 100.000 (99.989)	
2022-04-04 04:02:46,676: ============================================================
2022-04-04 04:03:25,723: time cost, forward:0.010718786976069405, backward:0.05867796620598535, data cost:0.3249222638678593 
2022-04-04 04:03:25,723: ============================================================
2022-04-04 04:03:25,723: Epoch 21/26 Batch 1700/7662 eta: 4:48:07.567078	Training Loss 1.4220 (1.3463)	Training Prec@1 100.000 (99.955)	Training Prec@5 100.000 (99.989)	
2022-04-04 04:03:25,723: ============================================================
2022-04-04 04:04:05,021: time cost, forward:0.010731558457820398, backward:0.05872972982999283, data cost:0.32471510501223316 
2022-04-04 04:04:05,022: ============================================================
2022-04-04 04:04:05,022: Epoch 21/26 Batch 1800/7662 eta: 4:49:19.431538	Training Loss 1.2027 (1.3472)	Training Prec@1 99.805 (99.955)	Training Prec@5 100.000 (99.989)	
2022-04-04 04:04:05,022: ============================================================
2022-04-04 04:04:45,453: time cost, forward:0.010735418622025443, backward:0.05877304930885319, data cost:0.32519225762855886 
2022-04-04 04:04:45,454: ============================================================
2022-04-04 04:04:45,454: Epoch 21/26 Batch 1900/7662 eta: 4:56:59.562541	Training Loss 1.3857 (1.3480)	Training Prec@1 100.000 (99.956)	Training Prec@5 100.000 (99.989)	
2022-04-04 04:04:45,454: ============================================================
2022-04-04 04:05:23,731: time cost, forward:0.010767076181256217, backward:0.05879742923887328, data cost:0.3245139984323598 
2022-04-04 04:05:23,732: ============================================================
2022-04-04 04:05:23,732: Epoch 21/26 Batch 2000/7662 eta: 4:40:32.046742	Training Loss 1.3842 (1.3491)	Training Prec@1 100.000 (99.956)	Training Prec@5 100.000 (99.988)	
2022-04-04 04:05:23,732: ============================================================
2022-04-04 04:06:04,034: time cost, forward:0.010737218761398657, backward:0.0588620245144332, data cost:0.32485505397573095 
2022-04-04 04:06:04,034: ============================================================
2022-04-04 04:06:04,034: Epoch 21/26 Batch 2100/7662 eta: 4:54:41.816249	Training Loss 1.2967 (1.3500)	Training Prec@1 100.000 (99.956)	Training Prec@5 100.000 (99.988)	
2022-04-04 04:06:04,035: ============================================================
2022-04-04 04:06:44,241: time cost, forward:0.010735748463622435, backward:0.058850050514641, data cost:0.32520945379006533 
2022-04-04 04:06:44,242: ============================================================
2022-04-04 04:06:44,242: Epoch 21/26 Batch 2200/7662 eta: 4:53:19.979499	Training Loss 1.3236 (1.3504)	Training Prec@1 100.000 (99.956)	Training Prec@5 100.000 (99.988)	
2022-04-04 04:06:44,242: ============================================================
2022-04-04 04:07:24,941: time cost, forward:0.010730052834336994, backward:0.05886995776833115, data cost:0.3257287498555426 
2022-04-04 04:07:24,942: ============================================================
2022-04-04 04:07:24,942: Epoch 21/26 Batch 2300/7662 eta: 4:56:15.063667	Training Loss 1.2907 (1.3513)	Training Prec@1 100.000 (99.956)	Training Prec@5 100.000 (99.988)	
2022-04-04 04:07:24,942: ============================================================
2022-04-04 04:08:03,571: time cost, forward:0.010729439013100703, backward:0.05888304475845521, data cost:0.3252883063797754 
2022-04-04 04:08:03,572: ============================================================
2022-04-04 04:08:03,572: Epoch 21/26 Batch 2400/7662 eta: 4:40:32.268961	Training Loss 1.3640 (1.3523)	Training Prec@1 100.000 (99.955)	Training Prec@5 100.000 (99.988)	
2022-04-04 04:08:03,572: ============================================================
2022-04-04 04:08:41,883: time cost, forward:0.010724935878892573, backward:0.058899679485441635, data cost:0.3247795484694732 
2022-04-04 04:08:41,884: ============================================================
2022-04-04 04:08:41,884: Epoch 21/26 Batch 2500/7662 eta: 4:37:35.335353	Training Loss 1.2960 (1.3529)	Training Prec@1 100.000 (99.955)	Training Prec@5 100.000 (99.988)	
2022-04-04 04:08:41,884: ============================================================
2022-04-04 04:09:21,017: time cost, forward:0.010779472074402255, backward:0.05886645627141045, data cost:0.3246334104548972 
2022-04-04 04:09:21,017: ============================================================
2022-04-04 04:09:21,018: Epoch 21/26 Batch 2600/7662 eta: 4:42:53.437732	Training Loss 1.4701 (1.3533)	Training Prec@1 99.805 (99.955)	Training Prec@5 100.000 (99.988)	
2022-04-04 04:09:21,018: ============================================================
2022-04-04 04:09:58,564: time cost, forward:0.0111690425307453, backward:0.05847994510047124, data cost:0.32391280852321697 
2022-04-04 04:09:58,564: ============================================================
2022-04-04 04:09:58,565: Epoch 21/26 Batch 2700/7662 eta: 4:30:47.705336	Training Loss 1.4204 (1.3534)	Training Prec@1 100.000 (99.956)	Training Prec@5 100.000 (99.988)	
2022-04-04 04:09:58,565: ============================================================
2022-04-04 04:10:37,014: time cost, forward:0.011194965506332522, backward:0.05845402385047948, data cost:0.3235925387893246 
2022-04-04 04:10:37,015: ============================================================
2022-04-04 04:10:37,015: Epoch 21/26 Batch 2800/7662 eta: 4:36:40.150686	Training Loss 1.4013 (1.3537)	Training Prec@1 100.000 (99.956)	Training Prec@5 100.000 (99.988)	
2022-04-04 04:10:37,015: ============================================================
2022-04-04 04:11:15,359: time cost, forward:0.011179470612946031, backward:0.05845801178115366, data cost:0.3232329303784879 
2022-04-04 04:11:15,360: ============================================================
2022-04-04 04:11:15,360: Epoch 21/26 Batch 2900/7662 eta: 4:35:16.318756	Training Loss 1.2534 (1.3542)	Training Prec@1 100.000 (99.955)	Training Prec@5 100.000 (99.988)	
2022-04-04 04:11:15,360: ============================================================
2022-04-04 04:11:52,955: time cost, forward:0.01114510408676875, backward:0.0584966678466746, data cost:0.3226344269806244 
2022-04-04 04:11:52,955: ============================================================
2022-04-04 04:11:52,955: Epoch 21/26 Batch 3000/7662 eta: 4:29:15.879787	Training Loss 1.4865 (1.3552)	Training Prec@1 100.000 (99.955)	Training Prec@5 100.000 (99.988)	
2022-04-04 04:11:52,956: ============================================================
2022-04-04 04:12:32,321: time cost, forward:0.011115148937598318, backward:0.05856059019932558, data cost:0.3226514207274347 
2022-04-04 04:12:32,322: ============================================================
2022-04-04 04:12:32,322: Epoch 21/26 Batch 3100/7662 eta: 4:41:17.731772	Training Loss 1.3355 (1.3551)	Training Prec@1 100.000 (99.955)	Training Prec@5 100.000 (99.988)	
2022-04-04 04:12:32,322: ============================================================
2022-04-04 04:13:12,868: time cost, forward:0.011080459417049196, backward:0.05863105375046058, data cost:0.32298656864887704 
2022-04-04 04:13:12,869: ============================================================
2022-04-04 04:13:12,869: Epoch 21/26 Batch 3200/7662 eta: 4:49:03.080171	Training Loss 1.3082 (1.3555)	Training Prec@1 100.000 (99.955)	Training Prec@5 100.000 (99.987)	
2022-04-04 04:13:12,869: ============================================================
2022-04-04 04:13:51,536: time cost, forward:0.011047736194213979, backward:0.058687577431185314, data cost:0.32276997518524975 
2022-04-04 04:13:51,536: ============================================================
2022-04-04 04:13:51,536: Epoch 21/26 Batch 3300/7662 eta: 4:35:00.575263	Training Loss 1.3842 (1.3562)	Training Prec@1 100.000 (99.954)	Training Prec@5 100.000 (99.987)	
2022-04-04 04:13:51,537: ============================================================
2022-04-04 04:14:29,633: time cost, forward:0.011019019738264945, backward:0.05874166175806372, data cost:0.32238883486773273 
2022-04-04 04:14:29,634: ============================================================
2022-04-04 04:14:29,634: Epoch 21/26 Batch 3400/7662 eta: 4:30:19.232471	Training Loss 1.3852 (1.3564)	Training Prec@1 100.000 (99.954)	Training Prec@5 100.000 (99.987)	
2022-04-04 04:14:29,634: ============================================================
2022-04-04 04:15:09,452: time cost, forward:0.010996705976749496, backward:0.05877948338796698, data cost:0.3225337727882754 
2022-04-04 04:15:09,452: ============================================================
2022-04-04 04:15:09,452: Epoch 21/26 Batch 3500/7662 eta: 4:41:52.084283	Training Loss 1.3350 (1.3566)	Training Prec@1 100.000 (99.955)	Training Prec@5 100.000 (99.987)	
2022-04-04 04:15:09,453: ============================================================
2022-04-04 04:15:49,326: time cost, forward:0.010969490168922045, backward:0.05882019544846815, data cost:0.322662469511994 
2022-04-04 04:15:49,327: ============================================================
2022-04-04 04:15:49,327: Epoch 21/26 Batch 3600/7662 eta: 4:41:35.980480	Training Loss 1.3281 (1.3570)	Training Prec@1 100.000 (99.954)	Training Prec@5 100.000 (99.987)	
2022-04-04 04:15:49,327: ============================================================
2022-04-04 04:16:28,425: time cost, forward:0.0109602968639282, backward:0.05883949245752983, data cost:0.3226206256235313 
2022-04-04 04:16:28,425: ============================================================
2022-04-04 04:16:28,426: Epoch 21/26 Batch 3700/7662 eta: 4:35:28.276620	Training Loss 1.2846 (1.3573)	Training Prec@1 100.000 (99.954)	Training Prec@5 100.000 (99.987)	
2022-04-04 04:16:28,426: ============================================================
2022-04-04 04:17:09,241: time cost, forward:0.010941828072275039, backward:0.05887943846704333, data cost:0.3229902091230898 
2022-04-04 04:17:09,242: ============================================================
2022-04-04 04:17:09,242: Epoch 21/26 Batch 3800/7662 eta: 4:46:53.456555	Training Loss 1.3623 (1.3576)	Training Prec@1 100.000 (99.954)	Training Prec@5 100.000 (99.987)	
2022-04-04 04:17:09,242: ============================================================
2022-04-04 04:17:49,700: time cost, forward:0.01092857432750654, backward:0.05889296476643463, data cost:0.3232975848731887 
2022-04-04 04:17:49,700: ============================================================
2022-04-04 04:17:49,700: Epoch 21/26 Batch 3900/7662 eta: 4:43:42.031440	Training Loss 1.5308 (1.3582)	Training Prec@1 99.609 (99.954)	Training Prec@5 100.000 (99.987)	
2022-04-04 04:17:49,700: ============================================================
2022-04-04 04:18:28,914: time cost, forward:0.010936950379295568, backward:0.05889742992674896, data cost:0.3232381909034884 
2022-04-04 04:18:28,914: ============================================================
2022-04-04 04:18:28,914: Epoch 21/26 Batch 4000/7662 eta: 4:34:19.304823	Training Loss 1.2611 (1.3589)	Training Prec@1 100.000 (99.953)	Training Prec@5 100.000 (99.986)	
2022-04-04 04:18:28,915: ============================================================
2022-04-04 04:19:07,142: time cost, forward:0.010935970503227047, backward:0.05891503360568677, data cost:0.32294548165655684 
2022-04-04 04:19:07,142: ============================================================
2022-04-04 04:19:07,142: Epoch 21/26 Batch 4100/7662 eta: 4:26:47.161091	Training Loss 1.3669 (1.3593)	Training Prec@1 100.000 (99.954)	Training Prec@5 100.000 (99.986)	
2022-04-04 04:19:07,142: ============================================================
2022-04-04 04:19:47,034: time cost, forward:0.010924021384068176, backward:0.058935111066959506, data cost:0.32305179104460907 
2022-04-04 04:19:47,035: ============================================================
2022-04-04 04:19:47,035: Epoch 21/26 Batch 4200/7662 eta: 4:37:44.408328	Training Loss 1.4110 (1.3596)	Training Prec@1 100.000 (99.954)	Training Prec@5 100.000 (99.987)	
2022-04-04 04:19:47,035: ============================================================
2022-04-04 04:20:25,324: time cost, forward:0.010911731948462107, backward:0.05894092899002178, data cost:0.3228267552991833 
2022-04-04 04:20:25,324: ============================================================
2022-04-04 04:20:25,325: Epoch 21/26 Batch 4300/7662 eta: 4:25:56.455367	Training Loss 1.3400 (1.3597)	Training Prec@1 100.000 (99.954)	Training Prec@5 100.000 (99.987)	
2022-04-04 04:20:25,325: ============================================================
2022-04-04 04:21:03,777: time cost, forward:0.010897402330863799, backward:0.05896165864688208, data cost:0.32263503201470156 
2022-04-04 04:21:03,777: ============================================================
2022-04-04 04:21:03,778: Epoch 21/26 Batch 4400/7662 eta: 4:26:26.077414	Training Loss 1.3197 (1.3601)	Training Prec@1 100.000 (99.954)	Training Prec@5 100.000 (99.987)	
2022-04-04 04:21:03,778: ============================================================
2022-04-04 04:21:41,928: time cost, forward:0.01099283400046134, backward:0.05886900586588008, data cost:0.32236380623721844 
2022-04-04 04:21:41,928: ============================================================
2022-04-04 04:21:41,928: Epoch 21/26 Batch 4500/7662 eta: 4:23:42.220667	Training Loss 1.2680 (1.3604)	Training Prec@1 100.000 (99.954)	Training Prec@5 100.000 (99.987)	
2022-04-04 04:21:41,929: ============================================================
2022-04-04 04:22:20,515: time cost, forward:0.010978574933215675, backward:0.05889004415780416, data cost:0.3222164020094568 
2022-04-04 04:22:20,516: ============================================================
2022-04-04 04:22:20,516: Epoch 21/26 Batch 4600/7662 eta: 4:26:04.918372	Training Loss 1.4292 (1.3607)	Training Prec@1 100.000 (99.954)	Training Prec@5 100.000 (99.987)	
2022-04-04 04:22:20,516: ============================================================
2022-04-04 04:23:00,500: time cost, forward:0.010963968582218266, backward:0.05890523674488575, data cost:0.3223623532796317 
2022-04-04 04:23:00,500: ============================================================
2022-04-04 04:23:00,500: Epoch 21/26 Batch 4700/7662 eta: 4:35:02.635864	Training Loss 1.3354 (1.3614)	Training Prec@1 100.000 (99.953)	Training Prec@5 100.000 (99.987)	
2022-04-04 04:23:00,500: ============================================================
2022-04-04 04:23:39,907: time cost, forward:0.010987795847459346, backward:0.058879923189548336, data cost:0.3223968011733268 
2022-04-04 04:23:39,908: ============================================================
2022-04-04 04:23:39,908: Epoch 21/26 Batch 4800/7662 eta: 4:30:25.370925	Training Loss 1.3796 (1.3617)	Training Prec@1 100.000 (99.954)	Training Prec@5 100.000 (99.987)	
2022-04-04 04:23:39,909: ============================================================
2022-04-04 04:24:17,994: time cost, forward:0.010972779146090506, backward:0.05889368285984865, data cost:0.32215228108002913 
2022-04-04 04:24:17,994: ============================================================
2022-04-04 04:24:17,994: Epoch 21/26 Batch 4900/7662 eta: 4:20:43.161279	Training Loss 1.3886 (1.3619)	Training Prec@1 99.805 (99.954)	Training Prec@5 99.805 (99.987)	
2022-04-04 04:24:17,994: ============================================================
2022-04-04 04:24:57,565: time cost, forward:0.010957351277460692, backward:0.058911307474736524, data cost:0.32220944401549684 
2022-04-04 04:24:57,565: ============================================================
2022-04-04 04:24:57,566: Epoch 21/26 Batch 5000/7662 eta: 4:30:13.625446	Training Loss 1.2565 (1.3623)	Training Prec@1 99.805 (99.953)	Training Prec@5 100.000 (99.987)	
2022-04-04 04:24:57,566: ============================================================
2022-04-04 04:25:37,900: time cost, forward:0.010948552737448304, backward:0.058925318236350076, data cost:0.32240267673364503 
2022-04-04 04:25:37,900: ============================================================
2022-04-04 04:25:37,900: Epoch 21/26 Batch 5100/7662 eta: 4:34:46.003437	Training Loss 1.4123 (1.3627)	Training Prec@1 100.000 (99.953)	Training Prec@5 100.000 (99.987)	
2022-04-04 04:25:37,901: ============================================================
2022-04-04 04:26:17,369: time cost, forward:0.010937301074800456, backward:0.05894094509536382, data cost:0.3224432821066523 
2022-04-04 04:26:17,370: ============================================================
2022-04-04 04:26:17,370: Epoch 21/26 Batch 5200/7662 eta: 4:28:12.786886	Training Loss 1.3278 (1.3629)	Training Prec@1 100.000 (99.953)	Training Prec@5 100.000 (99.987)	
2022-04-04 04:26:17,370: ============================================================
2022-04-04 04:26:57,027: time cost, forward:0.010920846747956112, backward:0.058962524015963316, data cost:0.3225192645289444 
2022-04-04 04:26:57,027: ============================================================
2022-04-04 04:26:57,027: Epoch 21/26 Batch 5300/7662 eta: 4:28:49.854355	Training Loss 1.2206 (1.3632)	Training Prec@1 100.000 (99.953)	Training Prec@5 100.000 (99.987)	
2022-04-04 04:26:57,027: ============================================================
2022-04-04 04:27:34,805: time cost, forward:0.010901464270450249, backward:0.0589894809906605, data cost:0.32222707908801357 
2022-04-04 04:27:34,805: ============================================================
2022-04-04 04:27:34,805: Epoch 21/26 Batch 5400/7662 eta: 4:15:27.665569	Training Loss 1.3505 (1.3635)	Training Prec@1 100.000 (99.953)	Training Prec@5 100.000 (99.987)	
2022-04-04 04:27:34,805: ============================================================
2022-04-04 04:28:12,755: time cost, forward:0.01088869404762436, backward:0.059006829460353544, data cost:0.3219754571892127 
2022-04-04 04:28:12,755: ============================================================
2022-04-04 04:28:12,755: Epoch 21/26 Batch 5500/7662 eta: 4:15:59.550223	Training Loss 1.3619 (1.3637)	Training Prec@1 100.000 (99.953)	Training Prec@5 100.000 (99.987)	
2022-04-04 04:28:12,755: ============================================================
2022-04-04 04:28:52,303: time cost, forward:0.010878946125816077, backward:0.05901662220506077, data cost:0.32203679813787667 
2022-04-04 04:28:52,303: ============================================================
2022-04-04 04:28:52,303: Epoch 21/26 Batch 5600/7662 eta: 4:26:06.747962	Training Loss 1.4147 (1.3643)	Training Prec@1 100.000 (99.953)	Training Prec@5 100.000 (99.987)	
2022-04-04 04:28:52,303: ============================================================
2022-04-04 04:29:31,083: time cost, forward:0.010867418291527339, backward:0.059030001363036384, data cost:0.321949420842942 
2022-04-04 04:29:31,084: ============================================================
2022-04-04 04:29:31,084: Epoch 21/26 Batch 5700/7662 eta: 4:20:18.036556	Training Loss 1.5596 (1.3648)	Training Prec@1 100.000 (99.953)	Training Prec@5 100.000 (99.987)	
2022-04-04 04:29:31,084: ============================================================
2022-04-04 04:30:09,931: time cost, forward:0.010863290776218046, backward:0.05903716477099565, data cost:0.32187582505409174 
2022-04-04 04:30:09,931: ============================================================
2022-04-04 04:30:09,931: Epoch 21/26 Batch 5800/7662 eta: 4:20:06.198547	Training Loss 1.4658 (1.3649)	Training Prec@1 100.000 (99.953)	Training Prec@5 100.000 (99.987)	
2022-04-04 04:30:09,931: ============================================================
2022-04-04 04:30:49,494: time cost, forward:0.010856339114664935, backward:0.05904096877257649, data cost:0.32194174332302655 
2022-04-04 04:30:49,494: ============================================================
2022-04-04 04:30:49,494: Epoch 21/26 Batch 5900/7662 eta: 4:24:14.118619	Training Loss 1.3098 (1.3651)	Training Prec@1 100.000 (99.954)	Training Prec@5 100.000 (99.987)	
2022-04-04 04:30:49,495: ============================================================
2022-04-04 04:31:28,729: time cost, forward:0.010856096218736754, backward:0.05904458152947773, data cost:0.321936122654557 
2022-04-04 04:31:28,729: ============================================================
2022-04-04 04:31:28,730: Epoch 21/26 Batch 6000/7662 eta: 4:21:23.546413	Training Loss 1.3755 (1.3654)	Training Prec@1 100.000 (99.953)	Training Prec@5 100.000 (99.987)	
2022-04-04 04:31:28,730: ============================================================
2022-04-04 04:32:09,026: time cost, forward:0.010855580064229719, backward:0.05904516119862369, data cost:0.3221113480472393 
2022-04-04 04:32:09,026: ============================================================
2022-04-04 04:32:09,027: Epoch 21/26 Batch 6100/7662 eta: 4:27:47.559279	Training Loss 1.4183 (1.3656)	Training Prec@1 99.805 (99.953)	Training Prec@5 100.000 (99.987)	
2022-04-04 04:32:09,027: ============================================================
2022-04-04 04:32:49,762: time cost, forward:0.010848880871820303, backward:0.05905231588751025, data cost:0.32234266266205136 
2022-04-04 04:32:49,763: ============================================================
2022-04-04 04:32:49,763: Epoch 21/26 Batch 6200/7662 eta: 4:30:02.006777	Training Loss 1.3101 (1.3658)	Training Prec@1 99.805 (99.953)	Training Prec@5 100.000 (99.987)	
2022-04-04 04:32:49,763: ============================================================
2022-04-04 04:33:29,964: time cost, forward:0.010841214442976052, backward:0.059066320832030395, data cost:0.32250227392959413 
2022-04-04 04:33:29,964: ============================================================
2022-04-04 04:33:29,964: Epoch 21/26 Batch 6300/7662 eta: 4:25:49.160840	Training Loss 1.3688 (1.3661)	Training Prec@1 100.000 (99.953)	Training Prec@5 100.000 (99.987)	
2022-04-04 04:33:29,964: ============================================================
2022-04-04 04:34:09,693: time cost, forward:0.010833296482964294, backward:0.059082287590025664, data cost:0.32255306346730567 
2022-04-04 04:34:09,694: ============================================================
2022-04-04 04:34:09,694: Epoch 21/26 Batch 6400/7662 eta: 4:22:02.345926	Training Loss 1.5306 (1.3662)	Training Prec@1 100.000 (99.953)	Training Prec@5 100.000 (99.987)	
2022-04-04 04:34:09,695: ============================================================
2022-04-04 04:34:49,506: time cost, forward:0.010827758639092482, backward:0.05908554303570882, data cost:0.3226321431045661 
2022-04-04 04:34:49,506: ============================================================
2022-04-04 04:34:49,506: Epoch 21/26 Batch 6500/7662 eta: 4:21:55.035571	Training Loss 1.4086 (1.3666)	Training Prec@1 99.805 (99.953)	Training Prec@5 100.000 (99.987)	
2022-04-04 04:34:49,507: ============================================================
2022-04-04 04:35:29,837: time cost, forward:0.01081762803036221, backward:0.05910286388174659, data cost:0.3227603153706247 
2022-04-04 04:35:29,837: ============================================================
2022-04-04 04:35:29,838: Epoch 21/26 Batch 6600/7662 eta: 4:24:39.644634	Training Loss 1.4116 (1.3669)	Training Prec@1 100.000 (99.953)	Training Prec@5 100.000 (99.987)	
2022-04-04 04:35:29,838: ============================================================
2022-04-04 04:36:09,625: time cost, forward:0.010805364366182018, backward:0.05912358277875072, data cost:0.3228492969576148 
2022-04-04 04:36:09,626: ============================================================
2022-04-04 04:36:09,626: Epoch 21/26 Batch 6700/7662 eta: 4:20:26.114224	Training Loss 1.3517 (1.3672)	Training Prec@1 100.000 (99.952)	Training Prec@5 100.000 (99.987)	
2022-04-04 04:36:09,626: ============================================================
2022-04-04 04:36:48,439: time cost, forward:0.010798707641666646, backward:0.05913665750865148, data cost:0.3227523534959652 
2022-04-04 04:36:48,439: ============================================================
2022-04-04 04:36:48,440: Epoch 21/26 Batch 6800/7662 eta: 4:13:24.385335	Training Loss 1.2799 (1.3674)	Training Prec@1 100.000 (99.952)	Training Prec@5 100.000 (99.987)	
2022-04-04 04:36:48,440: ============================================================
2022-04-04 04:37:26,660: time cost, forward:0.010792188911200226, backward:0.05915071771082316, data cost:0.3225630722040369 
2022-04-04 04:37:26,661: ============================================================
2022-04-04 04:37:26,661: Epoch 21/26 Batch 6900/7662 eta: 4:08:54.347682	Training Loss 1.2728 (1.3677)	Training Prec@1 100.000 (99.952)	Training Prec@5 100.000 (99.987)	
2022-04-04 04:37:26,662: ============================================================
2022-04-04 04:38:05,974: time cost, forward:0.010785730315338016, backward:0.05916694270353485, data cost:0.3225819518147477 
2022-04-04 04:38:05,974: ============================================================
2022-04-04 04:38:05,974: Epoch 21/26 Batch 7000/7662 eta: 4:15:21.539567	Training Loss 1.4002 (1.3680)	Training Prec@1 100.000 (99.952)	Training Prec@5 100.000 (99.987)	
2022-04-04 04:38:05,975: ============================================================
2022-04-04 04:38:45,284: time cost, forward:0.010781458254044519, backward:0.059173800337732736, data cost:0.32258333204699025 
2022-04-04 04:38:45,284: ============================================================
2022-04-04 04:38:45,285: Epoch 21/26 Batch 7100/7662 eta: 4:14:41.030032	Training Loss 1.4212 (1.3684)	Training Prec@1 100.000 (99.951)	Training Prec@5 100.000 (99.987)	
2022-04-04 04:38:45,285: ============================================================
2022-04-04 04:39:24,174: time cost, forward:0.010775359144871856, backward:0.059185457521055224, data cost:0.3225125882969679 
2022-04-04 04:39:24,174: ============================================================
2022-04-04 04:39:24,174: Epoch 21/26 Batch 7200/7662 eta: 4:11:18.770099	Training Loss 1.4701 (1.3689)	Training Prec@1 100.000 (99.951)	Training Prec@5 100.000 (99.987)	
2022-04-04 04:39:24,175: ============================================================
2022-04-04 04:40:03,380: time cost, forward:0.01077029172288733, backward:0.05919257969640023, data cost:0.3225047505707067 
2022-04-04 04:40:03,380: ============================================================
2022-04-04 04:40:03,380: Epoch 21/26 Batch 7300/7662 eta: 4:12:42.110505	Training Loss 1.2389 (1.3692)	Training Prec@1 100.000 (99.951)	Training Prec@5 100.000 (99.987)	
2022-04-04 04:40:03,381: ============================================================
2022-04-04 04:40:42,921: time cost, forward:0.010762681218639776, backward:0.0592007098576236, data cost:0.3225233573207244 
2022-04-04 04:40:42,921: ============================================================
2022-04-04 04:40:42,922: Epoch 21/26 Batch 7400/7662 eta: 4:14:12.211964	Training Loss 1.3271 (1.3694)	Training Prec@1 100.000 (99.951)	Training Prec@5 100.000 (99.987)	
2022-04-04 04:40:42,922: ============================================================
2022-04-04 04:41:22,201: time cost, forward:0.01075521041940317, backward:0.059212411112873724, data cost:0.3225174594647186 
2022-04-04 04:41:22,201: ============================================================
2022-04-04 04:41:22,202: Epoch 21/26 Batch 7500/7662 eta: 4:11:52.196866	Training Loss 1.2608 (1.3696)	Training Prec@1 100.000 (99.951)	Training Prec@5 100.000 (99.987)	
2022-04-04 04:41:22,202: ============================================================
2022-04-04 04:42:00,139: time cost, forward:0.010753681666287235, backward:0.0592111078810262, data cost:0.3223606980086973 
2022-04-04 04:42:00,139: ============================================================
2022-04-04 04:42:00,139: Epoch 21/26 Batch 7600/7662 eta: 4:02:37.889076	Training Loss 1.6099 (1.3698)	Training Prec@1 100.000 (99.951)	Training Prec@5 100.000 (99.987)	
2022-04-04 04:42:00,140: ============================================================
2022-04-04 04:42:26,972: Epoch: 21/26 eta: 4:02:13.988234	Training Loss 1.4310 (1.3699)	Training Prec@1 99.805 (99.951)	Training Prec@5 100.000 (99.987)
2022-04-04 04:42:26,972: ============================================================
2022-04-04 04:43:08,187: time cost, forward:0.010884022471880672, backward:0.057791844762936986, data cost:0.34236744196728025 
2022-04-04 04:43:08,187: ============================================================
2022-04-04 04:43:08,188: Epoch 22/26 Batch 100/7662 eta: 4:21:37.600239	Training Loss 1.1504 (1.2358)	Training Prec@1 100.000 (99.984)	Training Prec@5 100.000 (99.994)	
2022-04-04 04:43:08,188: ============================================================
2022-04-04 04:43:46,526: time cost, forward:0.011170836549308432, backward:0.057474468221616504, data cost:0.32842233073172256 
2022-04-04 04:43:46,527: ============================================================
2022-04-04 04:43:46,527: Epoch 22/26 Batch 200/7662 eta: 4:03:31.497043	Training Loss 1.2211 (1.2408)	Training Prec@1 100.000 (99.980)	Training Prec@5 100.000 (99.997)	
2022-04-04 04:43:46,527: ============================================================
2022-04-04 04:44:24,073: time cost, forward:0.011305967700919977, backward:0.05768576991996638, data cost:0.3206748627499992 
2022-04-04 04:44:24,073: ============================================================
2022-04-04 04:44:24,073: Epoch 22/26 Batch 300/7662 eta: 3:57:51.745728	Training Loss 1.1887 (1.2406)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-04-04 04:44:24,073: ============================================================
2022-04-04 04:45:01,627: time cost, forward:0.011079262970085432, backward:0.05818460220681097, data cost:0.3167300164550169 
2022-04-04 04:45:01,627: ============================================================
2022-04-04 04:45:01,628: Epoch 22/26 Batch 400/7662 eta: 3:57:17.230223	Training Loss 1.2145 (1.2446)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-04-04 04:45:01,628: ============================================================
2022-04-04 04:45:41,234: time cost, forward:0.011030718415438054, backward:0.05833544807586976, data cost:0.3184654502448195 
2022-04-04 04:45:41,235: ============================================================
2022-04-04 04:45:41,235: Epoch 22/26 Batch 500/7662 eta: 4:09:35.961834	Training Loss 1.2684 (1.2477)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.993)	
2022-04-04 04:45:41,236: ============================================================
2022-04-04 04:46:20,549: time cost, forward:0.01095812547585005, backward:0.05852307302127895, data cost:0.31918962809796725 
2022-04-04 04:46:20,550: ============================================================
2022-04-04 04:46:20,550: Epoch 22/26 Batch 600/7662 eta: 4:07:06.062679	Training Loss 1.2226 (1.2486)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.992)	
2022-04-04 04:46:20,550: ============================================================
2022-04-04 04:47:00,202: time cost, forward:0.010833679862288446, backward:0.05866544509309215, data cost:0.32021642413432677 
2022-04-04 04:47:00,202: ============================================================
2022-04-04 04:47:00,203: Epoch 22/26 Batch 700/7662 eta: 4:08:33.766217	Training Loss 1.1532 (1.2491)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.993)	
2022-04-04 04:47:00,203: ============================================================
2022-04-04 04:47:38,430: time cost, forward:0.010790529179483541, backward:0.058800359243743855, data cost:0.31915717071227645 
2022-04-04 04:47:38,430: ============================================================
2022-04-04 04:47:38,430: Epoch 22/26 Batch 800/7662 eta: 3:58:59.501413	Training Loss 1.2305 (1.2509)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.992)	
2022-04-04 04:47:38,430: ============================================================
2022-04-04 04:48:16,267: time cost, forward:0.010739214030468423, backward:0.05889160906247488, data cost:0.31789391059366295 
2022-04-04 04:48:16,267: ============================================================
2022-04-04 04:48:16,267: Epoch 22/26 Batch 900/7662 eta: 3:55:55.233835	Training Loss 1.1165 (1.2510)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.992)	
2022-04-04 04:48:16,267: ============================================================
2022-04-04 04:48:54,898: time cost, forward:0.010651597747573623, backward:0.05902825127373467, data cost:0.3176982491104691 
2022-04-04 04:48:54,898: ============================================================
2022-04-04 04:48:54,898: Epoch 22/26 Batch 1000/7662 eta: 4:00:13.632797	Training Loss 1.2425 (1.2513)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.992)	
2022-04-04 04:48:54,898: ============================================================
2022-04-04 04:49:34,762: time cost, forward:0.010620776906243447, backward:0.059090854039075054, data cost:0.31863347479600707 
2022-04-04 04:49:34,763: ============================================================
2022-04-04 04:49:34,763: Epoch 22/26 Batch 1100/7662 eta: 4:07:14.091518	Training Loss 1.3532 (1.2526)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.992)	
2022-04-04 04:49:34,763: ============================================================
2022-04-04 04:50:13,702: time cost, forward:0.01058353793133886, backward:0.05912266541163657, data cost:0.3187339622045776 
2022-04-04 04:50:13,703: ============================================================
2022-04-04 04:50:13,703: Epoch 22/26 Batch 1200/7662 eta: 4:00:51.002452	Training Loss 1.4706 (1.2536)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.992)	
2022-04-04 04:50:13,703: ============================================================
2022-04-04 04:50:53,177: time cost, forward:0.01071447331323543, backward:0.058976325739155004, data cost:0.31913934091681057 
2022-04-04 04:50:53,178: ============================================================
2022-04-04 04:50:53,178: Epoch 22/26 Batch 1300/7662 eta: 4:03:30.017474	Training Loss 1.3315 (1.2554)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.992)	
2022-04-04 04:50:53,178: ============================================================
2022-04-04 04:51:30,913: time cost, forward:0.010672795934452169, backward:0.05903268934063097, data cost:0.3182603213683122 
2022-04-04 04:51:30,914: ============================================================
2022-04-04 04:51:30,914: Epoch 22/26 Batch 1400/7662 eta: 3:52:08.894707	Training Loss 1.1523 (1.2565)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.992)	
2022-04-04 04:51:30,915: ============================================================
2022-04-04 04:52:10,227: time cost, forward:0.010665949540904874, backward:0.05900499532825554, data cost:0.31862562954465573 
2022-04-04 04:52:10,228: ============================================================
2022-04-04 04:52:10,228: Epoch 22/26 Batch 1500/7662 eta: 4:01:11.744766	Training Loss 1.2709 (1.2578)	Training Prec@1 99.609 (99.972)	Training Prec@5 100.000 (99.992)	
2022-04-04 04:52:10,228: ============================================================
2022-04-04 04:52:49,108: time cost, forward:0.010631498506175048, backward:0.05902151781145374, data cost:0.31864053312877777 
2022-04-04 04:52:49,109: ============================================================
2022-04-04 04:52:49,109: Epoch 22/26 Batch 1600/7662 eta: 3:57:53.663706	Training Loss 1.1594 (1.2580)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.992)	
2022-04-04 04:52:49,110: ============================================================
2022-04-04 04:53:27,786: time cost, forward:0.01060795783996582, backward:0.059066855675897714, data cost:0.318498576368003 
2022-04-04 04:53:27,786: ============================================================
2022-04-04 04:53:27,786: Epoch 22/26 Batch 1700/7662 eta: 3:56:00.140272	Training Loss 1.2385 (1.2594)	Training Prec@1 100.000 (99.971)	Training Prec@5 100.000 (99.992)	
2022-04-04 04:53:27,787: ============================================================
2022-04-04 04:54:04,712: time cost, forward:0.010646978042203893, backward:0.0590542244076265, data cost:0.31741412856169315 
2022-04-04 04:54:04,712: ============================================================
2022-04-04 04:54:04,713: Epoch 22/26 Batch 1800/7662 eta: 3:44:42.138256	Training Loss 1.4386 (1.2608)	Training Prec@1 100.000 (99.971)	Training Prec@5 100.000 (99.992)	
2022-04-04 04:54:04,713: ============================================================
2022-04-04 04:54:44,722: time cost, forward:0.01065502033665533, backward:0.05904320969965786, data cost:0.3180214810082635 
2022-04-04 04:54:44,722: ============================================================
2022-04-04 04:54:44,722: Epoch 22/26 Batch 1900/7662 eta: 4:02:47.953678	Training Loss 1.4203 (1.2615)	Training Prec@1 100.000 (99.971)	Training Prec@5 100.000 (99.992)	
2022-04-04 04:54:44,723: ============================================================
2022-04-04 04:55:24,293: time cost, forward:0.010660064763102071, backward:0.05902922004386745, data cost:0.3184467844512237 
2022-04-04 04:55:24,293: ============================================================
2022-04-04 04:55:24,293: Epoch 22/26 Batch 2000/7662 eta: 3:59:28.579184	Training Loss 1.2474 (1.2627)	Training Prec@1 100.000 (99.971)	Training Prec@5 100.000 (99.992)	
2022-04-04 04:55:24,293: ============================================================
2022-04-04 04:56:03,176: time cost, forward:0.010939549241195468, backward:0.05874295913928915, data cost:0.318440328160032 
2022-04-04 04:56:03,177: ============================================================
2022-04-04 04:56:03,177: Epoch 22/26 Batch 2100/7662 eta: 3:54:40.327221	Training Loss 1.1716 (1.2634)	Training Prec@1 99.805 (99.971)	Training Prec@5 99.805 (99.992)	
2022-04-04 04:56:03,178: ============================================================
2022-04-04 04:56:41,648: time cost, forward:0.010930644322005441, backward:0.05873012987252201, data cost:0.3182877310301402 
2022-04-04 04:56:41,648: ============================================================
2022-04-04 04:56:41,649: Epoch 22/26 Batch 2200/7662 eta: 3:51:32.356638	Training Loss 1.4343 (1.2647)	Training Prec@1 100.000 (99.971)	Training Prec@5 100.000 (99.992)	
2022-04-04 04:56:41,649: ============================================================
2022-04-04 04:57:20,954: time cost, forward:0.010916586075725116, backward:0.05873754616663113, data cost:0.31847928222649613 
2022-04-04 04:57:20,955: ============================================================
2022-04-04 04:57:20,955: Epoch 22/26 Batch 2300/7662 eta: 3:55:54.657089	Training Loss 1.4059 (1.2661)	Training Prec@1 100.000 (99.971)	Training Prec@5 100.000 (99.992)	
2022-04-04 04:57:20,955: ============================================================
2022-04-04 04:58:00,617: time cost, forward:0.010919161963929927, backward:0.05873292642317498, data cost:0.31882740299420437 
2022-04-04 04:58:00,617: ============================================================
2022-04-04 04:58:00,617: Epoch 22/26 Batch 2400/7662 eta: 3:57:23.060868	Training Loss 1.3842 (1.2668)	Training Prec@1 100.000 (99.971)	Training Prec@5 100.000 (99.992)	
2022-04-04 04:58:00,617: ============================================================
2022-04-04 04:58:40,039: time cost, forward:0.010910513783607925, backward:0.05872651737849681, data cost:0.3190315920336335 
2022-04-04 04:58:40,040: ============================================================
2022-04-04 04:58:40,040: Epoch 22/26 Batch 2500/7662 eta: 3:55:17.593743	Training Loss 1.1983 (1.2680)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.992)	
2022-04-04 04:58:40,040: ============================================================
2022-04-04 04:59:18,851: time cost, forward:0.010891067380857449, backward:0.05874990150991794, data cost:0.31900650953136533 
2022-04-04 04:59:18,851: ============================================================
2022-04-04 04:59:18,852: Epoch 22/26 Batch 2600/7662 eta: 3:51:00.092712	Training Loss 1.2544 (1.2688)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.992)	
2022-04-04 04:59:18,852: ============================================================
2022-04-04 04:59:57,731: time cost, forward:0.0108749241950822, backward:0.05875547411884366, data cost:0.3189919814660665 
2022-04-04 04:59:57,731: ============================================================
2022-04-04 04:59:57,731: Epoch 22/26 Batch 2700/7662 eta: 3:50:45.452155	Training Loss 1.3410 (1.2697)	Training Prec@1 99.805 (99.969)	Training Prec@5 99.805 (99.991)	
2022-04-04 04:59:57,731: ============================================================
2022-04-04 05:00:36,301: time cost, forward:0.010858381846497083, backward:0.058764591179561856, data cost:0.3188754053957422 
2022-04-04 05:00:36,302: ============================================================
2022-04-04 05:00:36,302: Epoch 22/26 Batch 2800/7662 eta: 3:48:16.817546	Training Loss 1.2265 (1.2702)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.991)	
2022-04-04 05:00:36,302: ============================================================
2022-04-04 05:01:14,719: time cost, forward:0.010852193371844152, backward:0.058769779478364585, data cost:0.3187187524777768 
2022-04-04 05:01:14,719: ============================================================
2022-04-04 05:01:14,719: Epoch 22/26 Batch 2900/7662 eta: 3:46:43.882388	Training Loss 1.3240 (1.2713)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.992)	
2022-04-04 05:01:14,719: ============================================================
2022-04-04 05:01:53,067: time cost, forward:0.010836180626213172, backward:0.05878091558053836, data cost:0.3185440387356953 
2022-04-04 05:01:53,067: ============================================================
2022-04-04 05:01:53,067: Epoch 22/26 Batch 3000/7662 eta: 3:45:41.080314	Training Loss 1.4092 (1.2720)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.992)	
2022-04-04 05:01:53,067: ============================================================
2022-04-04 05:02:30,481: time cost, forward:0.010841747990497738, backward:0.058775722615062594, data cost:0.31807506734534746 
2022-04-04 05:02:30,482: ============================================================
2022-04-04 05:02:30,482: Epoch 22/26 Batch 3100/7662 eta: 3:39:34.138467	Training Loss 1.3119 (1.2732)	Training Prec@1 99.609 (99.970)	Training Prec@5 100.000 (99.992)	
2022-04-04 05:02:30,482: ============================================================
2022-04-04 05:03:08,279: time cost, forward:0.010830089352063069, backward:0.05878451460039068, data cost:0.3177506983298814 
2022-04-04 05:03:08,280: ============================================================
2022-04-04 05:03:08,280: Epoch 22/26 Batch 3200/7662 eta: 3:41:11.246104	Training Loss 1.2454 (1.2739)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.992)	
2022-04-04 05:03:08,280: ============================================================
2022-04-04 05:03:47,546: time cost, forward:0.010822464603841503, backward:0.058784104361972074, data cost:0.3179013479041417 
2022-04-04 05:03:47,546: ============================================================
2022-04-04 05:03:47,547: Epoch 22/26 Batch 3300/7662 eta: 3:49:07.672444	Training Loss 1.3310 (1.2752)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.992)	
2022-04-04 05:03:47,547: ============================================================
2022-04-04 05:04:26,177: time cost, forward:0.01082819894889973, backward:0.05877201905773822, data cost:0.3178488910110532 
2022-04-04 05:04:26,177: ============================================================
2022-04-04 05:04:26,177: Epoch 22/26 Batch 3400/7662 eta: 3:44:46.278234	Training Loss 1.3285 (1.2762)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.991)	
2022-04-04 05:04:26,178: ============================================================
2022-04-04 05:05:04,488: time cost, forward:0.01081394767652208, backward:0.05878321229815313, data cost:0.31772404358910983 
2022-04-04 05:05:04,489: ============================================================
2022-04-04 05:05:04,489: Epoch 22/26 Batch 3500/7662 eta: 3:42:16.754229	Training Loss 1.3988 (1.2770)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.991)	
2022-04-04 05:05:04,489: ============================================================
2022-04-04 05:05:44,736: time cost, forward:0.010792424195870719, backward:0.0588075219011532, data cost:0.3181257903095615 
2022-04-04 05:05:44,737: ============================================================
2022-04-04 05:05:44,737: Epoch 22/26 Batch 3600/7662 eta: 3:52:50.506420	Training Loss 1.4051 (1.2780)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.991)	
2022-04-04 05:05:44,737: ============================================================
2022-04-04 05:06:22,159: time cost, forward:0.010776880529320668, backward:0.05883330279152017, data cost:0.31774213153563763 
2022-04-04 05:06:22,160: ============================================================
2022-04-04 05:06:22,160: Epoch 22/26 Batch 3700/7662 eta: 3:35:52.470603	Training Loss 1.2725 (1.2788)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.991)	
2022-04-04 05:06:22,160: ============================================================
2022-04-04 05:07:00,870: time cost, forward:0.010829229359879058, backward:0.05878341916549454, data cost:0.3177125662306354 
2022-04-04 05:07:00,871: ============================================================
2022-04-04 05:07:00,871: Epoch 22/26 Batch 3800/7662 eta: 3:42:39.418752	Training Loss 1.2606 (1.2791)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.991)	
2022-04-04 05:07:00,871: ============================================================
2022-04-04 05:07:40,528: time cost, forward:0.010830754712778166, backward:0.05877434476640598, data cost:0.3179448749750631 
2022-04-04 05:07:40,529: ============================================================
2022-04-04 05:07:40,529: Epoch 22/26 Batch 3900/7662 eta: 3:47:26.720613	Training Loss 1.3490 (1.2799)	Training Prec@1 99.805 (99.968)	Training Prec@5 99.805 (99.991)	
2022-04-04 05:07:40,529: ============================================================
2022-04-04 05:08:20,222: time cost, forward:0.010821315937562118, backward:0.05878678510474634, data cost:0.3181627991498187 
2022-04-04 05:08:20,222: ============================================================
2022-04-04 05:08:20,223: Epoch 22/26 Batch 4000/7662 eta: 3:46:59.399507	Training Loss 1.3249 (1.2809)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.991)	
2022-04-04 05:08:20,223: ============================================================
2022-04-04 05:08:59,056: time cost, forward:0.01082488018351376, backward:0.05878678028919139, data cost:0.3181655436616085 
2022-04-04 05:08:59,056: ============================================================
2022-04-04 05:08:59,057: Epoch 22/26 Batch 4100/7662 eta: 3:41:25.500920	Training Loss 1.3993 (1.2819)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.991)	
2022-04-04 05:08:59,057: ============================================================
2022-04-04 05:09:38,412: time cost, forward:0.010821963810131476, backward:0.05879243472327105, data cost:0.31827959886020807 
2022-04-04 05:09:38,412: ============================================================
2022-04-04 05:09:38,412: Epoch 22/26 Batch 4200/7662 eta: 3:43:44.510601	Training Loss 1.3788 (1.2825)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.991)	
2022-04-04 05:09:38,412: ============================================================
2022-04-04 05:10:18,347: time cost, forward:0.010821656976696724, backward:0.05878636204217528, data cost:0.31856013503455094 
2022-04-04 05:10:18,347: ============================================================
2022-04-04 05:10:18,347: Epoch 22/26 Batch 4300/7662 eta: 3:46:22.352836	Training Loss 1.3351 (1.2831)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.991)	
2022-04-04 05:10:18,347: ============================================================
2022-04-04 05:10:56,203: time cost, forward:0.01081364559677412, backward:0.058797322178082076, data cost:0.31831522279502206 
2022-04-04 05:10:56,203: ============================================================
2022-04-04 05:10:56,204: Epoch 22/26 Batch 4400/7662 eta: 3:33:57.482111	Training Loss 1.3333 (1.2839)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.991)	
2022-04-04 05:10:56,204: ============================================================
2022-04-04 05:11:34,733: time cost, forward:0.010809384072772873, backward:0.0588105537807128, data cost:0.3182461396353222 
2022-04-04 05:11:34,734: ============================================================
2022-04-04 05:11:34,734: Epoch 22/26 Batch 4500/7662 eta: 3:37:07.477765	Training Loss 1.3090 (1.2849)	Training Prec@1 99.805 (99.967)	Training Prec@5 100.000 (99.991)	
2022-04-04 05:11:34,734: ============================================================
2022-04-04 05:12:14,894: time cost, forward:0.010796173055888933, backward:0.058830385857184156, data cost:0.31852392912896 
2022-04-04 05:12:14,895: ============================================================
2022-04-04 05:12:14,895: Epoch 22/26 Batch 4600/7662 eta: 3:45:38.592010	Training Loss 1.3593 (1.2857)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.991)	
2022-04-04 05:12:14,895: ============================================================
2022-04-04 05:12:52,630: time cost, forward:0.010784299405591745, backward:0.058846285658254095, data cost:0.3182696829351574 
2022-04-04 05:12:52,631: ============================================================
2022-04-04 05:12:52,631: Epoch 22/26 Batch 4700/7662 eta: 3:31:23.473746	Training Loss 1.3857 (1.2867)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.991)	
2022-04-04 05:12:52,631: ============================================================
2022-04-04 05:13:32,854: time cost, forward:0.010816332746928224, backward:0.058819967499621886, data cost:0.3185503845985891 
2022-04-04 05:13:32,854: ============================================================
2022-04-04 05:13:32,854: Epoch 22/26 Batch 4800/7662 eta: 3:44:39.349502	Training Loss 1.3534 (1.2874)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.991)	
2022-04-04 05:13:32,855: ============================================================
2022-04-04 05:14:11,293: time cost, forward:0.010852300042788771, backward:0.05878598448159038, data cost:0.31846505691869376 
2022-04-04 05:14:11,293: ============================================================
2022-04-04 05:14:11,294: Epoch 22/26 Batch 4900/7662 eta: 3:34:02.869150	Training Loss 1.2483 (1.2881)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.991)	
2022-04-04 05:14:11,294: ============================================================
2022-04-04 05:14:49,511: time cost, forward:0.01085010483923567, backward:0.05878722655770778, data cost:0.3183292730208945 
2022-04-04 05:14:49,512: ============================================================
2022-04-04 05:14:49,512: Epoch 22/26 Batch 5000/7662 eta: 3:32:11.037726	Training Loss 1.3676 (1.2891)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.991)	
2022-04-04 05:14:49,513: ============================================================
2022-04-04 05:15:28,969: time cost, forward:0.010839892827101514, backward:0.05880503089644437, data cost:0.31844387954065534 
2022-04-04 05:15:28,969: ============================================================
2022-04-04 05:15:28,969: Epoch 22/26 Batch 5100/7662 eta: 3:38:24.083279	Training Loss 1.2194 (1.2898)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.991)	
2022-04-04 05:15:28,969: ============================================================
2022-04-04 05:16:08,215: time cost, forward:0.010833003746131036, backward:0.05881579648212507, data cost:0.3185084581971283 
2022-04-04 05:16:08,216: ============================================================
2022-04-04 05:16:08,216: Epoch 22/26 Batch 5200/7662 eta: 3:36:34.909094	Training Loss 1.4481 (1.2908)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.991)	
2022-04-04 05:16:08,216: ============================================================
2022-04-04 05:16:46,727: time cost, forward:0.01088796865042481, backward:0.05875737196005702, data cost:0.31845374169451357 
2022-04-04 05:16:46,728: ============================================================
2022-04-04 05:16:46,728: Epoch 22/26 Batch 5300/7662 eta: 3:31:53.215630	Training Loss 1.3199 (1.2914)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.991)	
2022-04-04 05:16:46,728: ============================================================
2022-04-04 05:17:23,208: time cost, forward:0.010881287982274392, backward:0.05876858642000162, data cost:0.3180088833937669 
2022-04-04 05:17:23,208: ============================================================
2022-04-04 05:17:23,208: Epoch 22/26 Batch 5400/7662 eta: 3:20:06.074594	Training Loss 1.3846 (1.2924)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.991)	
2022-04-04 05:17:23,209: ============================================================
2022-04-04 05:18:01,368: time cost, forward:0.010877022766637724, backward:0.05877637355885607, data cost:0.31787334235934134 
2022-04-04 05:18:01,368: ============================================================
2022-04-04 05:18:01,369: Epoch 22/26 Batch 5500/7662 eta: 3:28:40.796299	Training Loss 1.1793 (1.2932)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.991)	
2022-04-04 05:18:01,369: ============================================================
2022-04-04 05:18:38,730: time cost, forward:0.010869606453769014, backward:0.05878635746471625, data cost:0.3176193943320055 
2022-04-04 05:18:38,731: ============================================================
2022-04-04 05:18:38,731: Epoch 22/26 Batch 5600/7662 eta: 3:23:41.519613	Training Loss 1.3058 (1.2939)	Training Prec@1 100.000 (99.966)	Training Prec@5 100.000 (99.991)	
2022-04-04 05:18:38,731: ============================================================
2022-04-04 05:19:15,713: time cost, forward:0.010863686595219942, backward:0.058797015958050716, data cost:0.3172944643389114 
2022-04-04 05:19:15,714: ============================================================
2022-04-04 05:19:15,714: Epoch 22/26 Batch 5700/7662 eta: 3:21:00.537417	Training Loss 1.4745 (1.2946)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.991)	
2022-04-04 05:19:15,714: ============================================================
2022-04-04 05:19:54,078: time cost, forward:0.010861061712568598, backward:0.05880129968406702, data cost:0.3172226417555976 
2022-04-04 05:19:54,079: ============================================================
2022-04-04 05:19:54,079: Epoch 22/26 Batch 5800/7662 eta: 3:27:53.018005	Training Loss 1.2549 (1.2954)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.991)	
2022-04-04 05:19:54,080: ============================================================
2022-04-04 05:20:33,364: time cost, forward:0.010950974800522437, backward:0.05871255617259741, data cost:0.3173149983586649 
2022-04-04 05:20:33,365: ============================================================
2022-04-04 05:20:33,365: Epoch 22/26 Batch 5900/7662 eta: 3:32:12.884081	Training Loss 1.3039 (1.2961)	Training Prec@1 100.000 (99.966)	Training Prec@5 100.000 (99.991)	
2022-04-04 05:20:33,365: ============================================================
2022-04-04 05:21:11,262: time cost, forward:0.010955658927125163, backward:0.058711273508442303, data cost:0.3171659240446045 
2022-04-04 05:21:11,262: ============================================================
2022-04-04 05:21:11,263: Epoch 22/26 Batch 6000/7662 eta: 3:24:05.068710	Training Loss 1.4581 (1.2969)	Training Prec@1 100.000 (99.966)	Training Prec@5 100.000 (99.991)	
2022-04-04 05:21:11,263: ============================================================
2022-04-04 05:21:49,133: time cost, forward:0.010948417889991732, backward:0.05871951327907939, data cost:0.3170317781423033 
2022-04-04 05:21:49,133: ============================================================
2022-04-04 05:21:49,133: Epoch 22/26 Batch 6100/7662 eta: 3:23:18.483602	Training Loss 1.2691 (1.2974)	Training Prec@1 100.000 (99.966)	Training Prec@5 100.000 (99.991)	
2022-04-04 05:21:49,133: ============================================================
2022-04-04 05:22:26,939: time cost, forward:0.010934980939830344, backward:0.05874125521728003, data cost:0.3168722380167208 
2022-04-04 05:22:26,940: ============================================================
2022-04-04 05:22:26,940: Epoch 22/26 Batch 6200/7662 eta: 3:22:20.249996	Training Loss 1.4648 (1.2983)	Training Prec@1 100.000 (99.966)	Training Prec@5 100.000 (99.991)	
2022-04-04 05:22:26,941: ============================================================
2022-04-04 05:23:07,008: time cost, forward:0.010931267627062619, backward:0.05874572838842159, data cost:0.31708742804254003 
2022-04-04 05:23:07,008: ============================================================
2022-04-04 05:23:07,008: Epoch 22/26 Batch 6300/7662 eta: 3:33:46.197575	Training Loss 1.2944 (1.2990)	Training Prec@1 100.000 (99.966)	Training Prec@5 100.000 (99.991)	
2022-04-04 05:23:07,009: ============================================================
2022-04-04 05:23:44,490: time cost, forward:0.010925909637901854, backward:0.05874866454894514, data cost:0.31688086217894257 
2022-04-04 05:23:44,490: ============================================================
2022-04-04 05:23:44,490: Epoch 22/26 Batch 6400/7662 eta: 3:19:20.831375	Training Loss 1.1871 (1.2996)	Training Prec@1 100.000 (99.966)	Training Prec@5 100.000 (99.991)	
2022-04-04 05:23:44,490: ============================================================
2022-04-04 05:24:21,881: time cost, forward:0.010917682210414809, backward:0.05875987187773104, data cost:0.3166914044169027 
2022-04-04 05:24:21,881: ============================================================
2022-04-04 05:24:21,882: Epoch 22/26 Batch 6500/7662 eta: 3:18:14.583974	Training Loss 1.4296 (1.3001)	Training Prec@1 100.000 (99.965)	Training Prec@5 100.000 (99.991)	
2022-04-04 05:24:21,882: ============================================================
2022-04-04 05:25:00,222: time cost, forward:0.010914538516874005, backward:0.05876169762551414, data cost:0.3166377893775354 
2022-04-04 05:25:00,222: ============================================================
2022-04-04 05:25:00,222: Epoch 22/26 Batch 6600/7662 eta: 3:22:38.181622	Training Loss 1.3370 (1.3009)	Training Prec@1 100.000 (99.965)	Training Prec@5 100.000 (99.991)	
2022-04-04 05:25:00,222: ============================================================
2022-04-04 05:25:38,546: time cost, forward:0.010910165222710079, backward:0.058763290380502674, data cost:0.3165743722188186 
2022-04-04 05:25:38,547: ============================================================
2022-04-04 05:25:38,547: Epoch 22/26 Batch 6700/7662 eta: 3:21:54.759304	Training Loss 1.4019 (1.3015)	Training Prec@1 100.000 (99.965)	Training Prec@5 100.000 (99.991)	
2022-04-04 05:25:38,547: ============================================================
2022-04-04 05:26:17,839: time cost, forward:0.010907163267925322, backward:0.05876531532922726, data cost:0.3166723276240139 
2022-04-04 05:26:17,840: ============================================================
2022-04-04 05:26:17,840: Epoch 22/26 Batch 6800/7662 eta: 3:26:21.692202	Training Loss 1.3238 (1.3023)	Training Prec@1 100.000 (99.965)	Training Prec@5 100.000 (99.991)	
2022-04-04 05:26:17,840: ============================================================
2022-04-04 05:26:55,854: time cost, forward:0.010903487846218585, backward:0.05876760552596106, data cost:0.3165760655423181 
2022-04-04 05:26:55,854: ============================================================
2022-04-04 05:26:55,855: Epoch 22/26 Batch 6900/7662 eta: 3:19:00.808780	Training Loss 1.3969 (1.3031)	Training Prec@1 100.000 (99.965)	Training Prec@5 100.000 (99.991)	
2022-04-04 05:26:55,855: ============================================================
2022-04-04 05:27:33,988: time cost, forward:0.010894600638901783, backward:0.058779571955332434, data cost:0.31649860877244024 
2022-04-04 05:27:33,989: ============================================================
2022-04-04 05:27:33,989: Epoch 22/26 Batch 7000/7662 eta: 3:19:00.294348	Training Loss 1.3351 (1.3037)	Training Prec@1 100.000 (99.965)	Training Prec@5 100.000 (99.991)	
2022-04-04 05:27:33,990: ============================================================
2022-04-04 05:28:12,936: time cost, forward:0.01089716001301857, backward:0.05877919918484278, data cost:0.31653251535775945 
2022-04-04 05:28:12,937: ============================================================
2022-04-04 05:28:12,937: Epoch 22/26 Batch 7100/7662 eta: 3:22:36.059894	Training Loss 1.4598 (1.3044)	Training Prec@1 100.000 (99.964)	Training Prec@5 100.000 (99.991)	
2022-04-04 05:28:12,938: ============================================================
2022-04-04 05:28:51,457: time cost, forward:0.010893001773652475, backward:0.058780540474786876, data cost:0.3165169345751324 
2022-04-04 05:28:51,457: ============================================================
2022-04-04 05:28:51,457: Epoch 22/26 Batch 7200/7662 eta: 3:19:43.925077	Training Loss 1.3939 (1.3050)	Training Prec@1 100.000 (99.964)	Training Prec@5 100.000 (99.991)	
2022-04-04 05:28:51,457: ============================================================
2022-04-04 05:29:30,837: time cost, forward:0.010886938412853554, backward:0.058786688708070044, data cost:0.31660329033077733 
2022-04-04 05:29:30,837: ============================================================
2022-04-04 05:29:30,838: Epoch 22/26 Batch 7300/7662 eta: 3:23:32.259227	Training Loss 1.3660 (1.3056)	Training Prec@1 100.000 (99.965)	Training Prec@5 100.000 (99.991)	
2022-04-04 05:29:30,838: ============================================================
2022-04-04 05:30:10,846: time cost, forward:0.010885853624969, backward:0.058784197497841535, data cost:0.316794468947626 
2022-04-04 05:30:10,846: ============================================================
2022-04-04 05:30:10,847: Epoch 22/26 Batch 7400/7662 eta: 3:26:07.215763	Training Loss 1.2480 (1.3059)	Training Prec@1 100.000 (99.965)	Training Prec@5 100.000 (99.991)	
2022-04-04 05:30:10,847: ============================================================
2022-04-04 05:30:50,613: time cost, forward:0.010882911181065191, backward:0.058780659356265405, data cost:0.31694148336828415 
2022-04-04 05:30:50,614: ============================================================
2022-04-04 05:30:50,614: Epoch 22/26 Batch 7500/7662 eta: 3:24:12.673312	Training Loss 1.3362 (1.3066)	Training Prec@1 100.000 (99.965)	Training Prec@5 100.000 (99.991)	
2022-04-04 05:30:50,614: ============================================================
2022-04-04 05:31:29,834: time cost, forward:0.01088077216607079, backward:0.058782465160795064, data cost:0.31699135294398567 
2022-04-04 05:31:29,834: ============================================================
2022-04-04 05:31:29,834: Epoch 22/26 Batch 7600/7662 eta: 3:20:45.030671	Training Loss 1.3713 (1.3071)	Training Prec@1 100.000 (99.965)	Training Prec@5 100.000 (99.991)	
2022-04-04 05:31:29,835: ============================================================
2022-04-04 05:31:55,754: Epoch: 22/26 eta: 3:20:20.321709	Training Loss 1.3274 (1.3075)	Training Prec@1 100.000 (99.965)	Training Prec@5 100.000 (99.991)
2022-04-04 05:31:55,754: ============================================================
2022-04-04 05:32:39,329: time cost, forward:0.016391580755060368, backward:0.057502060225515655, data cost:0.35894936022132334 
2022-04-04 05:32:39,329: ============================================================
2022-04-04 05:32:39,329: Epoch 23/26 Batch 100/7662 eta: 3:39:40.533126	Training Loss 1.2070 (1.1922)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.996)	
2022-04-04 05:32:39,329: ============================================================
2022-04-04 05:33:16,463: time cost, forward:0.013098800601671689, backward:0.05813870957149333, data cost:0.33030649166011333 
2022-04-04 05:33:16,464: ============================================================
2022-04-04 05:33:16,464: Epoch 23/26 Batch 200/7662 eta: 3:08:27.111572	Training Loss 1.2611 (1.1914)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.997)	
2022-04-04 05:33:16,464: ============================================================
2022-04-04 05:33:54,696: time cost, forward:0.012336137701436429, backward:0.05801103665278508, data cost:0.32456023477790347 
2022-04-04 05:33:54,697: ============================================================
2022-04-04 05:33:54,697: Epoch 23/26 Batch 300/7662 eta: 3:13:23.423123	Training Loss 1.2629 (1.1931)	Training Prec@1 100.000 (99.983)	Training Prec@5 100.000 (99.997)	
2022-04-04 05:33:54,697: ============================================================
2022-04-04 05:34:33,944: time cost, forward:0.011884287186433798, backward:0.058153380726214336, data cost:0.3240312609756202 
2022-04-04 05:34:33,944: ============================================================
2022-04-04 05:34:33,945: Epoch 23/26 Batch 400/7662 eta: 3:17:51.991331	Training Loss 1.3085 (1.1971)	Training Prec@1 100.000 (99.983)	Training Prec@5 100.000 (99.998)	
2022-04-04 05:34:33,945: ============================================================
2022-04-04 05:35:12,507: time cost, forward:0.01168364274477911, backward:0.0581666931121765, data cost:0.3224439066732097 
2022-04-04 05:35:12,507: ============================================================
2022-04-04 05:35:12,507: Epoch 23/26 Batch 500/7662 eta: 3:13:46.282953	Training Loss 1.1425 (1.2012)	Training Prec@1 100.000 (99.982)	Training Prec@5 100.000 (99.997)	
2022-04-04 05:35:12,508: ============================================================
2022-04-04 05:35:51,072: time cost, forward:0.011465712660342107, backward:0.0582350410881743, data cost:0.321355369134817 
2022-04-04 05:35:51,072: ============================================================
2022-04-04 05:35:51,072: Epoch 23/26 Batch 600/7662 eta: 3:13:08.345141	Training Loss 1.2663 (1.2033)	Training Prec@1 100.000 (99.981)	Training Prec@5 100.000 (99.996)	
2022-04-04 05:35:51,072: ============================================================
2022-04-04 05:36:29,425: time cost, forward:0.011374090533058701, backward:0.05830390941090509, data cost:0.3202723931515848 
2022-04-04 05:36:29,426: ============================================================
2022-04-04 05:36:29,426: Epoch 23/26 Batch 700/7662 eta: 3:11:26.557516	Training Loss 1.1411 (1.2057)	Training Prec@1 100.000 (99.980)	Training Prec@5 100.000 (99.996)	
2022-04-04 05:36:29,426: ============================================================
2022-04-04 05:37:08,650: time cost, forward:0.011370446714799903, backward:0.058272656272439396, data cost:0.320495888646762 
2022-04-04 05:37:08,650: ============================================================
2022-04-04 05:37:08,650: Epoch 23/26 Batch 800/7662 eta: 3:15:08.025839	Training Loss 1.1093 (1.2079)	Training Prec@1 100.000 (99.979)	Training Prec@5 100.000 (99.995)	
2022-04-04 05:37:08,650: ============================================================
2022-04-04 05:37:47,682: time cost, forward:0.011244998757910808, backward:0.05837181306654407, data cost:0.3203763980356286 
2022-04-04 05:37:47,682: ============================================================
2022-04-04 05:37:47,682: Epoch 23/26 Batch 900/7662 eta: 3:13:31.730487	Training Loss 1.2822 (1.2099)	Training Prec@1 100.000 (99.979)	Training Prec@5 100.000 (99.995)	
2022-04-04 05:37:47,684: ============================================================
2022-04-04 05:38:26,789: time cost, forward:0.011189833775654927, backward:0.05846847523678769, data cost:0.3205356366402871 
2022-04-04 05:38:26,790: ============================================================
2022-04-04 05:38:26,790: Epoch 23/26 Batch 1000/7662 eta: 3:13:15.026313	Training Loss 1.2812 (1.2109)	Training Prec@1 100.000 (99.980)	Training Prec@5 100.000 (99.995)	
2022-04-04 05:38:26,790: ============================================================
2022-04-04 05:39:05,453: time cost, forward:0.011107865412523793, backward:0.058568524706895185, data cost:0.3200776279786156 
2022-04-04 05:39:05,454: ============================================================
2022-04-04 05:39:05,454: Epoch 23/26 Batch 1100/7662 eta: 3:10:24.770489	Training Loss 1.1870 (1.2104)	Training Prec@1 99.805 (99.979)	Training Prec@5 100.000 (99.995)	
2022-04-04 05:39:05,454: ============================================================
2022-04-04 05:39:44,449: time cost, forward:0.011085439066373874, backward:0.05857769840453644, data cost:0.3201465495334654 
2022-04-04 05:39:44,450: ============================================================
2022-04-04 05:39:44,450: Epoch 23/26 Batch 1200/7662 eta: 3:11:23.899547	Training Loss 1.2509 (1.2126)	Training Prec@1 99.805 (99.978)	Training Prec@5 100.000 (99.995)	
2022-04-04 05:39:44,450: ============================================================
2022-04-04 05:40:23,096: time cost, forward:0.011096510729301517, backward:0.05860175271507774, data cost:0.31977855929785093 
2022-04-04 05:40:23,096: ============================================================
2022-04-04 05:40:23,096: Epoch 23/26 Batch 1300/7662 eta: 3:09:02.363067	Training Loss 1.1819 (1.2144)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.995)	
2022-04-04 05:40:23,097: ============================================================
2022-04-04 05:41:00,136: time cost, forward:0.011239290067006044, backward:0.05845077247428758, data cost:0.3183804412157387 
2022-04-04 05:41:00,137: ============================================================
2022-04-04 05:41:00,137: Epoch 23/26 Batch 1400/7662 eta: 3:00:33.972127	Training Loss 1.1621 (1.2154)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.995)	
2022-04-04 05:41:00,137: ============================================================
2022-04-04 05:41:39,357: time cost, forward:0.011211095292064013, backward:0.058492136128828316, data cost:0.31863432426783467 
2022-04-04 05:41:39,357: ============================================================
2022-04-04 05:41:39,357: Epoch 23/26 Batch 1500/7662 eta: 3:10:32.367211	Training Loss 1.2079 (1.2170)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.995)	
2022-04-04 05:41:39,357: ============================================================
2022-04-04 05:42:16,949: time cost, forward:0.011157795069290743, backward:0.058544045168582616, data cost:0.31777124437710286 
2022-04-04 05:42:16,949: ============================================================
2022-04-04 05:42:16,949: Epoch 23/26 Batch 1600/7662 eta: 3:02:00.108601	Training Loss 1.2825 (1.2187)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.994)	
2022-04-04 05:42:16,950: ============================================================
2022-04-04 05:42:54,800: time cost, forward:0.01116160338874983, backward:0.05849937244749827, data cost:0.3172807231799794 
2022-04-04 05:42:54,800: ============================================================
2022-04-04 05:42:54,801: Epoch 23/26 Batch 1700/7662 eta: 3:02:37.557170	Training Loss 1.1817 (1.2198)	Training Prec@1 99.805 (99.977)	Training Prec@5 100.000 (99.994)	
2022-04-04 05:42:54,801: ============================================================
2022-04-04 05:43:31,795: time cost, forward:0.011110706684521797, backward:0.05853970160810334, data cost:0.31628558263306883 
2022-04-04 05:43:31,795: ============================================================
2022-04-04 05:43:31,795: Epoch 23/26 Batch 1800/7662 eta: 2:57:52.636756	Training Loss 1.2133 (1.2209)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-04-04 05:43:31,796: ============================================================
2022-04-04 05:44:09,785: time cost, forward:0.011085633418006354, backward:0.05853716959257764, data cost:0.31597415744285323 
2022-04-04 05:44:09,786: ============================================================
2022-04-04 05:44:09,786: Epoch 23/26 Batch 1900/7662 eta: 3:02:01.963069	Training Loss 1.2116 (1.2224)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-04-04 05:44:09,786: ============================================================
2022-04-04 05:44:48,542: time cost, forward:0.011147129947152837, backward:0.058462898155162785, data cost:0.3160710235784625 
2022-04-04 05:44:48,543: ============================================================
2022-04-04 05:44:48,543: Epoch 23/26 Batch 2000/7662 eta: 3:05:03.455081	Training Loss 1.2779 (1.2230)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-04-04 05:44:48,543: ============================================================
2022-04-04 05:45:25,869: time cost, forward:0.011149454253125383, backward:0.05844020900299232, data cost:0.3154826332353989 
2022-04-04 05:45:25,870: ============================================================
2022-04-04 05:45:25,870: Epoch 23/26 Batch 2100/7662 eta: 2:57:36.496433	Training Loss 1.1713 (1.2245)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-04-04 05:45:25,870: ============================================================
2022-04-04 05:46:02,771: time cost, forward:0.011145216381078201, backward:0.058426004260602245, data cost:0.3147395336936961 
2022-04-04 05:46:02,772: ============================================================
2022-04-04 05:46:02,772: Epoch 23/26 Batch 2200/7662 eta: 2:54:58.263260	Training Loss 1.2527 (1.2257)	Training Prec@1 99.805 (99.977)	Training Prec@5 99.805 (99.994)	
2022-04-04 05:46:02,772: ============================================================
2022-04-04 05:46:40,106: time cost, forward:0.011187515968133596, backward:0.05837206541843754, data cost:0.31427936078984614 
2022-04-04 05:46:40,106: ============================================================
2022-04-04 05:46:40,107: Epoch 23/26 Batch 2300/7662 eta: 2:56:23.969322	Training Loss 1.3212 (1.2274)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-04-04 05:46:40,107: ============================================================
2022-04-04 05:47:17,478: time cost, forward:0.011146823382963982, backward:0.05839220023542804, data cost:0.31384779682453595 
2022-04-04 05:47:17,479: ============================================================
2022-04-04 05:47:17,479: Epoch 23/26 Batch 2400/7662 eta: 2:55:57.308679	Training Loss 1.3701 (1.2291)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-04-04 05:47:17,479: ============================================================
2022-04-04 05:47:56,468: time cost, forward:0.01114275198833806, backward:0.05838956571474415, data cost:0.3140606706549807 
2022-04-04 05:47:56,468: ============================================================
2022-04-04 05:47:56,469: Epoch 23/26 Batch 2500/7662 eta: 3:02:55.197051	Training Loss 1.2687 (1.2311)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.993)	
2022-04-04 05:47:56,469: ============================================================
2022-04-04 05:48:35,409: time cost, forward:0.01112360557990608, backward:0.05840070571473765, data cost:0.3142775823263628 
2022-04-04 05:48:35,410: ============================================================
2022-04-04 05:48:35,410: Epoch 23/26 Batch 2600/7662 eta: 3:02:02.666279	Training Loss 1.3052 (1.2317)	Training Prec@1 99.805 (99.975)	Training Prec@5 100.000 (99.993)	
2022-04-04 05:48:35,410: ============================================================
2022-04-04 05:49:15,123: time cost, forward:0.011118201425049913, backward:0.058402569835474864, data cost:0.3147712897795048 
2022-04-04 05:49:15,123: ============================================================
2022-04-04 05:49:15,123: Epoch 23/26 Batch 2700/7662 eta: 3:04:59.474212	Training Loss 1.2655 (1.2329)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.993)	
2022-04-04 05:49:15,124: ============================================================
2022-04-04 05:49:54,187: time cost, forward:0.011109389931698193, backward:0.05840257646016199, data cost:0.3149713889834454 
2022-04-04 05:49:54,187: ============================================================
2022-04-04 05:49:54,187: Epoch 23/26 Batch 2800/7662 eta: 3:01:18.931006	Training Loss 1.1058 (1.2337)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.993)	
2022-04-04 05:49:54,187: ============================================================
2022-04-04 05:50:33,181: time cost, forward:0.011106305304951979, backward:0.058406233088482494, data cost:0.3151399015187806 
2022-04-04 05:50:33,182: ============================================================
2022-04-04 05:50:33,182: Epoch 23/26 Batch 2900/7662 eta: 3:00:20.719475	Training Loss 1.3560 (1.2349)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.993)	
2022-04-04 05:50:33,183: ============================================================
2022-04-04 05:51:11,870: time cost, forward:0.011097915254461245, backward:0.05841569385356846, data cost:0.3152082623064856 
2022-04-04 05:51:11,871: ============================================================
2022-04-04 05:51:11,871: Epoch 23/26 Batch 3000/7662 eta: 2:58:16.986905	Training Loss 1.2034 (1.2360)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.993)	
2022-04-04 05:51:11,871: ============================================================
2022-04-04 05:51:49,297: time cost, forward:0.011084743990902748, backward:0.058416014680865505, data cost:0.3148763729857414 
2022-04-04 05:51:49,297: ============================================================
2022-04-04 05:51:49,298: Epoch 23/26 Batch 3100/7662 eta: 2:51:50.683914	Training Loss 1.1243 (1.2370)	Training Prec@1 99.805 (99.975)	Training Prec@5 100.000 (99.993)	
2022-04-04 05:51:49,298: ============================================================
2022-04-04 05:52:27,282: time cost, forward:0.011091708689788312, backward:0.058399417468181586, data cost:0.3147234163943139 
2022-04-04 05:52:27,283: ============================================================
2022-04-04 05:52:27,283: Epoch 23/26 Batch 3200/7662 eta: 2:53:46.614988	Training Loss 1.1113 (1.2383)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.993)	
2022-04-04 05:52:27,283: ============================================================
2022-04-04 05:53:05,529: time cost, forward:0.011058762348865372, backward:0.05843361893289918, data cost:0.3145187399032514 
2022-04-04 05:53:05,530: ============================================================
2022-04-04 05:53:05,530: Epoch 23/26 Batch 3300/7662 eta: 2:54:20.220863	Training Loss 1.2832 (1.2393)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.993)	
2022-04-04 05:53:05,530: ============================================================
2022-04-04 05:53:44,218: time cost, forward:0.0110407016599273, backward:0.058433674124627646, data cost:0.3147224578200876 
2022-04-04 05:53:44,218: ============================================================
2022-04-04 05:53:44,218: Epoch 23/26 Batch 3400/7662 eta: 2:55:42.120006	Training Loss 1.3582 (1.2404)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.993)	
2022-04-04 05:53:44,218: ============================================================
2022-04-04 05:54:23,542: time cost, forward:0.011050309273609947, backward:0.05841575625556712, data cost:0.3148647251385353 
2022-04-04 05:54:23,543: ============================================================
2022-04-04 05:54:23,543: Epoch 23/26 Batch 3500/7662 eta: 2:57:56.296429	Training Loss 1.3141 (1.2413)	Training Prec@1 99.609 (99.975)	Training Prec@5 100.000 (99.993)	
2022-04-04 05:54:23,544: ============================================================
2022-04-04 05:55:00,818: time cost, forward:0.011069150923622685, backward:0.05840239202886795, data cost:0.31464286677272296 
2022-04-04 05:55:00,818: ============================================================
2022-04-04 05:55:00,818: Epoch 23/26 Batch 3600/7662 eta: 2:48:02.577202	Training Loss 1.2612 (1.2423)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.993)	
2022-04-04 05:55:00,819: ============================================================
2022-04-04 05:55:39,169: time cost, forward:0.01107594631078534, backward:0.05839496272484913, data cost:0.3146030431052871 
2022-04-04 05:55:39,169: ============================================================
2022-04-04 05:55:39,169: Epoch 23/26 Batch 3700/7662 eta: 2:52:15.254250	Training Loss 1.3931 (1.2433)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.993)	
2022-04-04 05:55:39,170: ============================================================
2022-04-04 05:56:18,201: time cost, forward:0.011052435214471176, backward:0.05841849803548011, data cost:0.3147591998558918 
2022-04-04 05:56:18,201: ============================================================
2022-04-04 05:56:18,202: Epoch 23/26 Batch 3800/7662 eta: 2:54:39.735816	Training Loss 1.1770 (1.2440)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.993)	
2022-04-04 05:56:18,202: ============================================================
2022-04-04 05:56:56,833: time cost, forward:0.011029422757074631, backward:0.058440043272559965, data cost:0.3147755527104987 
2022-04-04 05:56:56,834: ============================================================
2022-04-04 05:56:56,834: Epoch 23/26 Batch 3900/7662 eta: 2:52:13.743951	Training Loss 1.2411 (1.2450)	Training Prec@1 99.805 (99.975)	Training Prec@5 100.000 (99.993)	
2022-04-04 05:56:56,834: ============================================================
2022-04-04 05:57:35,834: time cost, forward:0.011016650747197602, backward:0.05845830058359927, data cost:0.31491741158718406 
2022-04-04 05:57:35,835: ============================================================
2022-04-04 05:57:35,835: Epoch 23/26 Batch 4000/7662 eta: 2:53:13.403664	Training Loss 1.1939 (1.2459)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.993)	
2022-04-04 05:57:35,835: ============================================================
2022-04-04 05:58:12,888: time cost, forward:0.011017094475084702, backward:0.058454012225156414, data cost:0.3145787904366658 
2022-04-04 05:58:12,888: ============================================================
2022-04-04 05:58:12,889: Epoch 23/26 Batch 4100/7662 eta: 2:43:57.361739	Training Loss 1.4146 (1.2472)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.993)	
2022-04-04 05:58:12,889: ============================================================
2022-04-04 05:58:49,962: time cost, forward:0.01100780112767793, backward:0.05846398317918916, data cost:0.3141498149477547 
2022-04-04 05:58:49,963: ============================================================
2022-04-04 05:58:49,963: Epoch 23/26 Batch 4200/7662 eta: 2:43:25.818699	Training Loss 1.3546 (1.2482)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.993)	
2022-04-04 05:58:49,963: ============================================================
2022-04-04 05:59:27,890: time cost, forward:0.011003823467786158, backward:0.058470471622389844, data cost:0.31409589044713343 
2022-04-04 05:59:27,891: ============================================================
2022-04-04 05:59:27,891: Epoch 23/26 Batch 4300/7662 eta: 2:46:33.593619	Training Loss 1.3079 (1.2499)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.993)	
2022-04-04 05:59:27,891: ============================================================
2022-04-04 06:00:05,538: time cost, forward:0.011003885358050348, backward:0.05847661872971299, data cost:0.3139509972075653 
2022-04-04 06:00:05,538: ============================================================
2022-04-04 06:00:05,538: Epoch 23/26 Batch 4400/7662 eta: 2:44:42.051356	Training Loss 1.1846 (1.2508)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.993)	
2022-04-04 06:00:05,538: ============================================================
2022-04-04 06:00:43,150: time cost, forward:0.010988406007304195, backward:0.05849527798644382, data cost:0.3137755284814947 
2022-04-04 06:00:43,150: ============================================================
2022-04-04 06:00:43,151: Epoch 23/26 Batch 4500/7662 eta: 2:43:55.259071	Training Loss 1.2183 (1.2519)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.993)	
2022-04-04 06:00:43,151: ============================================================
2022-04-04 06:01:21,516: time cost, forward:0.01097864787405951, backward:0.0585056038674232, data cost:0.31375840768318486 
2022-04-04 06:01:21,516: ============================================================
2022-04-04 06:01:21,516: Epoch 23/26 Batch 4600/7662 eta: 2:46:33.932432	Training Loss 1.2767 (1.2529)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.993)	
2022-04-04 06:01:21,517: ============================================================
2022-04-04 06:01:59,726: time cost, forward:0.01096970767613598, backward:0.058518393137628, data cost:0.31373617816006893 
2022-04-04 06:01:59,727: ============================================================
2022-04-04 06:01:59,727: Epoch 23/26 Batch 4700/7662 eta: 2:45:15.192966	Training Loss 1.2173 (1.2538)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-04-04 06:01:59,727: ============================================================
2022-04-04 06:02:36,865: time cost, forward:0.010964571572661673, backward:0.058526398813160636, data cost:0.31346762783951154 
2022-04-04 06:02:36,866: ============================================================
2022-04-04 06:02:36,866: Epoch 23/26 Batch 4800/7662 eta: 2:40:00.082959	Training Loss 1.3495 (1.2547)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-04-04 06:02:36,866: ============================================================
2022-04-04 06:03:14,678: time cost, forward:0.01095156052521867, backward:0.058548743930683496, data cost:0.31334574112091096 
2022-04-04 06:03:14,678: ============================================================
2022-04-04 06:03:14,679: Epoch 23/26 Batch 4900/7662 eta: 2:42:16.464695	Training Loss 1.3748 (1.2557)	Training Prec@1 99.805 (99.973)	Training Prec@5 100.000 (99.993)	
2022-04-04 06:03:14,679: ============================================================
2022-04-04 06:03:54,683: time cost, forward:0.010943790272870858, backward:0.05855890888527742, data cost:0.3136738153142103 
2022-04-04 06:03:54,683: ============================================================
2022-04-04 06:03:54,684: Epoch 23/26 Batch 5000/7662 eta: 2:51:00.847134	Training Loss 1.4335 (1.2568)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.992)	
2022-04-04 06:03:54,684: ============================================================
2022-04-04 06:04:34,132: time cost, forward:0.010938845795494688, backward:0.05856723143881876, data cost:0.31388504394341227 
2022-04-04 06:04:34,133: ============================================================
2022-04-04 06:04:34,133: Epoch 23/26 Batch 5100/7662 eta: 2:47:58.902096	Training Loss 1.2519 (1.2578)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.992)	
2022-04-04 06:04:34,133: ============================================================
2022-04-04 06:05:12,253: time cost, forward:0.010922327571750766, backward:0.058587511220008597, data cost:0.31382897180372715 
2022-04-04 06:05:12,254: ============================================================
2022-04-04 06:05:12,254: Epoch 23/26 Batch 5200/7662 eta: 2:41:41.364945	Training Loss 1.1979 (1.2587)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.993)	
2022-04-04 06:05:12,254: ============================================================
2022-04-04 06:05:50,691: time cost, forward:0.010911022228752808, backward:0.05859721343592442, data cost:0.3138412904640395 
2022-04-04 06:05:50,692: ============================================================
2022-04-04 06:05:50,692: Epoch 23/26 Batch 5300/7662 eta: 2:42:23.697746	Training Loss 1.3956 (1.2597)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.992)	
2022-04-04 06:05:50,692: ============================================================
2022-04-04 06:06:29,756: time cost, forward:0.010902515935288423, backward:0.05860519925848955, data cost:0.3139681721599174 
2022-04-04 06:06:29,757: ============================================================
2022-04-04 06:06:29,757: Epoch 23/26 Batch 5400/7662 eta: 2:44:23.605359	Training Loss 1.2176 (1.2605)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.992)	
2022-04-04 06:06:29,758: ============================================================
2022-04-04 06:07:08,059: time cost, forward:0.010904871695560637, backward:0.05860480232051468, data cost:0.3139445529805246 
2022-04-04 06:07:08,060: ============================================================
2022-04-04 06:07:08,060: Epoch 23/26 Batch 5500/7662 eta: 2:40:32.721270	Training Loss 1.4439 (1.2614)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.992)	
2022-04-04 06:07:08,060: ============================================================
2022-04-04 06:07:47,847: time cost, forward:0.010901966783101484, backward:0.058608680479142, data cost:0.31419629943351657 
2022-04-04 06:07:47,847: ============================================================
2022-04-04 06:07:47,847: Epoch 23/26 Batch 5600/7662 eta: 2:46:06.325164	Training Loss 1.3256 (1.2625)	Training Prec@1 100.000 (99.971)	Training Prec@5 100.000 (99.992)	
2022-04-04 06:07:47,847: ============================================================
2022-04-04 06:08:25,553: time cost, forward:0.010901923136954601, backward:0.058606724882150955, data cost:0.31407145592889824 
2022-04-04 06:08:25,554: ============================================================
2022-04-04 06:08:25,554: Epoch 23/26 Batch 5700/7662 eta: 2:36:47.451386	Training Loss 1.2402 (1.2636)	Training Prec@1 100.000 (99.971)	Training Prec@5 100.000 (99.992)	
2022-04-04 06:08:25,554: ============================================================
2022-04-04 06:09:03,689: time cost, forward:0.010894187176344744, backward:0.05861770093266276, data cost:0.3140164944072657 
2022-04-04 06:09:03,690: ============================================================
2022-04-04 06:09:03,690: Epoch 23/26 Batch 5800/7662 eta: 2:37:56.422381	Training Loss 1.3566 (1.2645)	Training Prec@1 100.000 (99.971)	Training Prec@5 100.000 (99.992)	
2022-04-04 06:09:03,690: ============================================================
2022-04-04 06:09:41,490: time cost, forward:0.010888477809794132, backward:0.058623376913567, data cost:0.3139191387992609 
2022-04-04 06:09:41,490: ============================================================
2022-04-04 06:09:41,490: Epoch 23/26 Batch 5900/7662 eta: 2:35:55.153675	Training Loss 1.4233 (1.2657)	Training Prec@1 100.000 (99.971)	Training Prec@5 100.000 (99.992)	
2022-04-04 06:09:41,490: ============================================================
2022-04-04 06:10:19,238: time cost, forward:0.010882627051916694, backward:0.05863163295955057, data cost:0.3138067286736688 
2022-04-04 06:10:19,238: ============================================================
2022-04-04 06:10:19,238: Epoch 23/26 Batch 6000/7662 eta: 2:35:04.492097	Training Loss 1.3297 (1.2666)	Training Prec@1 100.000 (99.971)	Training Prec@5 100.000 (99.992)	
2022-04-04 06:10:19,238: ============================================================
2022-04-04 06:10:57,336: time cost, forward:0.010867829752038748, backward:0.05864694189255228, data cost:0.3137589945404583 
2022-04-04 06:10:57,336: ============================================================
2022-04-04 06:10:57,337: Epoch 23/26 Batch 6100/7662 eta: 2:35:52.815810	Training Loss 1.3393 (1.2675)	Training Prec@1 100.000 (99.971)	Training Prec@5 100.000 (99.992)	
2022-04-04 06:10:57,337: ============================================================
2022-04-04 06:11:35,262: time cost, forward:0.010865056258975584, backward:0.058651525102367055, data cost:0.31367468937767534 
2022-04-04 06:11:35,262: ============================================================
2022-04-04 06:11:35,262: Epoch 23/26 Batch 6200/7662 eta: 2:34:32.414918	Training Loss 1.3849 (1.2683)	Training Prec@1 100.000 (99.971)	Training Prec@5 100.000 (99.992)	
2022-04-04 06:11:35,263: ============================================================
2022-04-04 06:12:14,155: time cost, forward:0.010859507949678911, backward:0.05865990311252747, data cost:0.3137649324398643 
2022-04-04 06:12:14,155: ============================================================
2022-04-04 06:12:14,155: Epoch 23/26 Batch 6300/7662 eta: 2:37:50.097470	Training Loss 1.3507 (1.2693)	Training Prec@1 100.000 (99.971)	Training Prec@5 100.000 (99.992)	
2022-04-04 06:12:14,156: ============================================================
2022-04-04 06:12:51,482: time cost, forward:0.01085575235357581, backward:0.058662957894762974, data cost:0.3136056103283846 
2022-04-04 06:12:51,483: ============================================================
2022-04-04 06:12:51,483: Epoch 23/26 Batch 6400/7662 eta: 2:30:51.623665	Training Loss 1.3820 (1.2702)	Training Prec@1 99.609 (99.971)	Training Prec@5 100.000 (99.992)	
2022-04-04 06:12:51,484: ============================================================
2022-04-04 06:13:30,150: time cost, forward:0.010848863544161823, backward:0.0586711206625454, data cost:0.31364968483733074 
2022-04-04 06:13:30,151: ============================================================
2022-04-04 06:13:30,151: Epoch 23/26 Batch 6500/7662 eta: 2:35:37.844346	Training Loss 1.3736 (1.2710)	Training Prec@1 100.000 (99.971)	Training Prec@5 100.000 (99.993)	
2022-04-04 06:13:30,151: ============================================================
2022-04-04 06:14:07,645: time cost, forward:0.010844162872911024, backward:0.05867447085697771, data cost:0.3135189673343849 
2022-04-04 06:14:07,645: ============================================================
2022-04-04 06:14:07,645: Epoch 23/26 Batch 6600/7662 eta: 2:30:17.033250	Training Loss 1.4809 (1.2718)	Training Prec@1 100.000 (99.971)	Training Prec@5 100.000 (99.993)	
2022-04-04 06:14:07,646: ============================================================
2022-04-04 06:14:45,817: time cost, forward:0.010843244626070425, backward:0.058675118641526615, data cost:0.3134902451070036 
2022-04-04 06:14:45,817: ============================================================
2022-04-04 06:14:45,817: Epoch 23/26 Batch 6700/7662 eta: 2:32:21.823169	Training Loss 1.3773 (1.2727)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.992)	
2022-04-04 06:14:45,818: ============================================================
2022-04-04 06:15:24,526: time cost, forward:0.010836709683599639, backward:0.05868152243755446, data cost:0.31353729958919274 
2022-04-04 06:15:24,526: ============================================================
2022-04-04 06:15:24,527: Epoch 23/26 Batch 6800/7662 eta: 2:33:51.781081	Training Loss 1.3138 (1.2738)	Training Prec@1 99.805 (99.970)	Training Prec@5 100.000 (99.992)	
2022-04-04 06:15:24,527: ============================================================
2022-04-04 06:16:03,669: time cost, forward:0.01084522092354472, backward:0.05867318309447198, data cost:0.31364803757248 
2022-04-04 06:16:03,670: ============================================================
2022-04-04 06:16:03,670: Epoch 23/26 Batch 6900/7662 eta: 2:34:56.206653	Training Loss 1.1363 (1.2744)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.992)	
2022-04-04 06:16:03,671: ============================================================
2022-04-04 06:16:43,205: time cost, forward:0.010841103992661095, backward:0.058675832451369224, data cost:0.3138186414849164 
2022-04-04 06:16:43,206: ============================================================
2022-04-04 06:16:43,206: Epoch 23/26 Batch 7000/7662 eta: 2:35:49.816150	Training Loss 1.3567 (1.2753)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.992)	
2022-04-04 06:16:43,206: ============================================================
2022-04-04 06:17:22,338: time cost, forward:0.010835807345957635, backward:0.058684044009212843, data cost:0.3139238847882198 
2022-04-04 06:17:22,338: ============================================================
2022-04-04 06:17:22,338: Epoch 23/26 Batch 7100/7662 eta: 2:33:35.292983	Training Loss 1.3545 (1.2764)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.992)	
2022-04-04 06:17:22,339: ============================================================
2022-04-04 06:18:01,250: time cost, forward:0.01085401743811888, backward:0.05867373729715879, data cost:0.3139868127354186 
2022-04-04 06:18:01,250: ============================================================
2022-04-04 06:18:01,250: Epoch 23/26 Batch 7200/7662 eta: 2:32:04.415214	Training Loss 1.3777 (1.2772)	Training Prec@1 99.805 (99.970)	Training Prec@5 100.000 (99.992)	
2022-04-04 06:18:01,250: ============================================================
2022-04-04 06:18:39,185: time cost, forward:0.010849456719167103, backward:0.0586821685377613, data cost:0.31391948666502667 
2022-04-04 06:18:39,185: ============================================================
2022-04-04 06:18:39,185: Epoch 23/26 Batch 7300/7662 eta: 2:27:37.473866	Training Loss 1.3947 (1.2780)	Training Prec@1 99.805 (99.970)	Training Prec@5 99.805 (99.992)	
2022-04-04 06:18:39,186: ============================================================
2022-04-04 06:19:17,264: time cost, forward:0.010866690719590056, backward:0.05867048785048154, data cost:0.3138661818949656 
2022-04-04 06:19:17,264: ============================================================
2022-04-04 06:19:17,264: Epoch 23/26 Batch 7400/7662 eta: 2:27:33.006276	Training Loss 1.3588 (1.2789)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.992)	
2022-04-04 06:19:17,265: ============================================================
2022-04-04 06:19:56,450: time cost, forward:0.010859757840657238, backward:0.0586755188612449, data cost:0.31397775634636416 
2022-04-04 06:19:56,450: ============================================================
2022-04-04 06:19:56,451: Epoch 23/26 Batch 7500/7662 eta: 2:31:11.279038	Training Loss 1.2720 (1.2798)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.992)	
2022-04-04 06:19:56,451: ============================================================
2022-04-04 06:20:35,082: time cost, forward:0.0108645772726885, backward:0.05867194470519658, data cost:0.31400130896023 
2022-04-04 06:20:35,082: ============================================================
2022-04-04 06:20:35,082: Epoch 23/26 Batch 7600/7662 eta: 2:28:24.180701	Training Loss 1.3126 (1.2805)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.992)	
2022-04-04 06:20:35,083: ============================================================
2022-04-04 06:20:59,772: Epoch: 23/26 eta: 2:27:59.842839	Training Loss 1.2854 (1.2811)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.992)
2022-04-04 06:20:59,772: ============================================================
2022-04-04 06:21:44,310: time cost, forward:0.01163581886676827, backward:0.05641302195462314, data cost:0.37595665816104773 
2022-04-04 06:21:44,311: ============================================================
2022-04-04 06:21:44,312: Epoch 24/26 Batch 100/7662 eta: 2:49:06.255786	Training Loss 1.1715 (1.1632)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.998)	
2022-04-04 06:21:44,312: ============================================================
2022-04-04 06:22:21,507: time cost, forward:0.011253202380846494, backward:0.05699215941692717, data cost:0.3394371756357164 
2022-04-04 06:22:21,508: ============================================================
2022-04-04 06:22:21,508: Epoch 24/26 Batch 200/7662 eta: 2:21:15.938816	Training Loss 1.2052 (1.1757)	Training Prec@1 100.000 (99.982)	Training Prec@5 100.000 (99.997)	
2022-04-04 06:22:21,508: ============================================================
2022-04-04 06:22:59,691: time cost, forward:0.01085284481877866, backward:0.057473785502456104, data cost:0.3304704112751428 
2022-04-04 06:22:59,692: ============================================================
2022-04-04 06:22:59,692: Epoch 24/26 Batch 300/7662 eta: 2:24:22.822799	Training Loss 1.1490 (1.1768)	Training Prec@1 99.805 (99.983)	Training Prec@5 100.000 (99.997)	
2022-04-04 06:22:59,692: ============================================================
2022-04-04 06:23:37,875: time cost, forward:0.010678389914950034, backward:0.05775394654811773, data cost:0.3258635489862963 
2022-04-04 06:23:37,875: ============================================================
2022-04-04 06:23:37,875: Epoch 24/26 Batch 400/7662 eta: 2:23:44.412486	Training Loss 1.1061 (1.1814)	Training Prec@1 100.000 (99.981)	Training Prec@5 100.000 (99.996)	
2022-04-04 06:23:37,875: ============================================================
2022-04-04 06:24:15,249: time cost, forward:0.010587145665843406, backward:0.057889171974931306, data cost:0.32167902785933805 
2022-04-04 06:24:15,250: ============================================================
2022-04-04 06:24:15,250: Epoch 24/26 Batch 500/7662 eta: 2:20:04.448751	Training Loss 1.2079 (1.1811)	Training Prec@1 100.000 (99.980)	Training Prec@5 100.000 (99.996)	
2022-04-04 06:24:15,250: ============================================================
2022-04-04 06:24:52,786: time cost, forward:0.010547973078757973, backward:0.05794308500019258, data cost:0.31908638767885644 
2022-04-04 06:24:52,787: ============================================================
2022-04-04 06:24:52,787: Epoch 24/26 Batch 600/7662 eta: 2:20:03.395474	Training Loss 1.1495 (1.1839)	Training Prec@1 100.000 (99.980)	Training Prec@5 100.000 (99.995)	
2022-04-04 06:24:52,787: ============================================================
2022-04-04 06:25:29,065: time cost, forward:0.010584979950955326, backward:0.058063946738945736, data cost:0.31534530233074837 
2022-04-04 06:25:29,065: ============================================================
2022-04-04 06:25:29,065: Epoch 24/26 Batch 700/7662 eta: 2:14:45.373425	Training Loss 1.3339 (1.1843)	Training Prec@1 100.000 (99.981)	Training Prec@5 100.000 (99.996)	
2022-04-04 06:25:29,065: ============================================================
2022-04-04 06:26:07,020: time cost, forward:0.01057434738502932, backward:0.05810560452027971, data cost:0.3145992857344607 
2022-04-04 06:26:07,020: ============================================================
2022-04-04 06:26:07,020: Epoch 24/26 Batch 800/7662 eta: 2:20:21.082075	Training Loss 1.3467 (1.1864)	Training Prec@1 100.000 (99.980)	Training Prec@5 100.000 (99.996)	
2022-04-04 06:26:07,021: ============================================================
2022-04-04 06:26:44,354: time cost, forward:0.010611790040708887, backward:0.05809883360602832, data cost:0.31346108438706105 
2022-04-04 06:26:44,354: ============================================================
2022-04-04 06:26:44,354: Epoch 24/26 Batch 900/7662 eta: 2:17:25.968977	Training Loss 1.2627 (1.1876)	Training Prec@1 100.000 (99.980)	Training Prec@5 100.000 (99.996)	
2022-04-04 06:26:44,355: ============================================================
2022-04-04 06:27:22,087: time cost, forward:0.010680456657906075, backward:0.05810140036009215, data cost:0.3127778671883248 
2022-04-04 06:27:22,087: ============================================================
2022-04-04 06:27:22,088: Epoch 24/26 Batch 1000/7662 eta: 2:18:16.420298	Training Loss 1.2363 (1.1889)	Training Prec@1 100.000 (99.980)	Training Prec@5 100.000 (99.995)	
2022-04-04 06:27:22,088: ============================================================
2022-04-04 06:27:59,435: time cost, forward:0.010697777429637961, backward:0.05812031643514312, data cost:0.312010515593094 
2022-04-04 06:27:59,436: ============================================================
2022-04-04 06:27:59,436: Epoch 24/26 Batch 1100/7662 eta: 2:16:14.418242	Training Loss 1.3337 (1.1905)	Training Prec@1 100.000 (99.980)	Training Prec@5 100.000 (99.995)	
2022-04-04 06:27:59,436: ============================================================
2022-04-04 06:28:36,952: time cost, forward:0.01065637132741691, backward:0.05821219357577237, data cost:0.31140230395974866 
2022-04-04 06:28:36,953: ============================================================
2022-04-04 06:28:36,953: Epoch 24/26 Batch 1200/7662 eta: 2:16:13.823587	Training Loss 1.2222 (1.1916)	Training Prec@1 99.805 (99.980)	Training Prec@5 100.000 (99.995)	
2022-04-04 06:28:36,953: ============================================================
2022-04-04 06:29:14,915: time cost, forward:0.010626182453369892, backward:0.05828790466449552, data cost:0.3112657468441911 
2022-04-04 06:29:14,915: ============================================================
2022-04-04 06:29:14,916: Epoch 24/26 Batch 1300/7662 eta: 2:17:12.946061	Training Loss 1.3482 (1.1937)	Training Prec@1 99.805 (99.980)	Training Prec@5 100.000 (99.995)	
2022-04-04 06:29:14,916: ============================================================
2022-04-04 06:29:53,066: time cost, forward:0.010693270960733497, backward:0.058243277585872846, data cost:0.3112834992793903 
2022-04-04 06:29:53,066: ============================================================
2022-04-04 06:29:53,066: Epoch 24/26 Batch 1400/7662 eta: 2:17:15.599246	Training Loss 1.2382 (1.1961)	Training Prec@1 100.000 (99.980)	Training Prec@5 100.000 (99.995)	
2022-04-04 06:29:53,067: ============================================================
2022-04-04 06:30:30,489: time cost, forward:0.010693338411978835, backward:0.05829172089864923, data cost:0.310817796918374 
2022-04-04 06:30:30,489: ============================================================
2022-04-04 06:30:30,489: Epoch 24/26 Batch 1500/7662 eta: 2:14:01.104211	Training Loss 1.2480 (1.1963)	Training Prec@1 100.000 (99.980)	Training Prec@5 100.000 (99.995)	
2022-04-04 06:30:30,490: ============================================================
2022-04-04 06:31:08,801: time cost, forward:0.010738570217492806, backward:0.05827967176741552, data cost:0.3109552654495382 
2022-04-04 06:31:08,802: ============================================================
2022-04-04 06:31:08,802: Epoch 24/26 Batch 1600/7662 eta: 2:16:33.903400	Training Loss 1.2069 (1.1992)	Training Prec@1 100.000 (99.979)	Training Prec@5 100.000 (99.995)	
2022-04-04 06:31:08,802: ============================================================
2022-04-04 06:31:48,224: time cost, forward:0.01073387989652655, backward:0.05828536868867206, data cost:0.3117262229560192 
2022-04-04 06:31:48,224: ============================================================
2022-04-04 06:31:48,224: Epoch 24/26 Batch 1700/7662 eta: 2:19:51.872070	Training Loss 1.1874 (1.2010)	Training Prec@1 99.805 (99.980)	Training Prec@5 100.000 (99.995)	
2022-04-04 06:31:48,225: ============================================================
2022-04-04 06:32:26,117: time cost, forward:0.01072253075621405, backward:0.05831840636002613, data cost:0.31160766751054525 
2022-04-04 06:32:26,117: ============================================================
2022-04-04 06:32:26,117: Epoch 24/26 Batch 1800/7662 eta: 2:13:48.328259	Training Loss 1.2191 (1.2025)	Training Prec@1 100.000 (99.979)	Training Prec@5 100.000 (99.995)	
2022-04-04 06:32:26,117: ============================================================
2022-04-04 06:33:04,502: time cost, forward:0.010727618982316068, backward:0.058332627292932364, data cost:0.3117016752874807 
2022-04-04 06:33:04,503: ============================================================
2022-04-04 06:33:04,503: Epoch 24/26 Batch 1900/7662 eta: 2:14:54.423023	Training Loss 1.1372 (1.2046)	Training Prec@1 99.805 (99.978)	Training Prec@5 99.805 (99.995)	
2022-04-04 06:33:04,503: ============================================================
2022-04-04 06:33:43,566: time cost, forward:0.010725302717696434, backward:0.0583372497749424, data cost:0.31217236874281257 
2022-04-04 06:33:43,567: ============================================================
2022-04-04 06:33:43,567: Epoch 24/26 Batch 2000/7662 eta: 2:16:38.333536	Training Loss 1.3056 (1.2057)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.995)	
2022-04-04 06:33:43,567: ============================================================
2022-04-04 06:34:24,016: time cost, forward:0.010722685791640806, backward:0.05836108901944826, data cost:0.31325304684268684 
2022-04-04 06:34:24,016: ============================================================
2022-04-04 06:34:24,017: Epoch 24/26 Batch 2100/7662 eta: 2:20:48.719053	Training Loss 1.1831 (1.2063)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.995)	
2022-04-04 06:34:24,017: ============================================================
2022-04-04 06:35:03,334: time cost, forward:0.010723267538323084, backward:0.05838525257310091, data cost:0.31366798041787347 
2022-04-04 06:35:03,334: ============================================================
2022-04-04 06:35:03,334: Epoch 24/26 Batch 2200/7662 eta: 2:16:12.964036	Training Loss 1.2295 (1.2081)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.995)	
2022-04-04 06:35:03,334: ============================================================
2022-04-04 06:35:42,547: time cost, forward:0.010935259777963446, backward:0.05818291465424102, data cost:0.3140886606678542 
2022-04-04 06:35:42,548: ============================================================
2022-04-04 06:35:42,548: Epoch 24/26 Batch 2300/7662 eta: 2:15:12.116478	Training Loss 1.2188 (1.2098)	Training Prec@1 100.000 (99.979)	Training Prec@5 100.000 (99.995)	
2022-04-04 06:35:42,548: ============================================================
2022-04-04 06:36:21,758: time cost, forward:0.010922312786202473, backward:0.05823135912641976, data cost:0.31435176649407676 
2022-04-04 06:36:21,759: ============================================================
2022-04-04 06:36:21,759: Epoch 24/26 Batch 2400/7662 eta: 2:14:32.356979	Training Loss 1.1963 (1.2108)	Training Prec@1 99.805 (99.979)	Training Prec@5 100.000 (99.995)	
2022-04-04 06:36:21,759: ============================================================
2022-04-04 06:37:00,382: time cost, forward:0.010926624258406976, backward:0.05823014802387019, data cost:0.3144803080572134 
2022-04-04 06:37:00,382: ============================================================
2022-04-04 06:37:00,382: Epoch 24/26 Batch 2500/7662 eta: 2:11:52.819913	Training Loss 1.2098 (1.2126)	Training Prec@1 100.000 (99.979)	Training Prec@5 100.000 (99.995)	
2022-04-04 06:37:00,383: ============================================================
2022-04-04 06:37:37,435: time cost, forward:0.010936109778421481, backward:0.05820739347231117, data cost:0.3139466085356903 
2022-04-04 06:37:37,436: ============================================================
2022-04-04 06:37:37,436: Epoch 24/26 Batch 2600/7662 eta: 2:05:54.070153	Training Loss 1.2550 (1.2142)	Training Prec@1 100.000 (99.979)	Training Prec@5 100.000 (99.995)	
2022-04-04 06:37:37,436: ============================================================
2022-04-04 06:38:16,281: time cost, forward:0.010931529306225884, backward:0.058207206082988905, data cost:0.3141362032832018 
2022-04-04 06:38:16,281: ============================================================
2022-04-04 06:38:16,281: Epoch 24/26 Batch 2700/7662 eta: 2:11:20.625810	Training Loss 1.1883 (1.2152)	Training Prec@1 100.000 (99.979)	Training Prec@5 100.000 (99.995)	
2022-04-04 06:38:16,282: ============================================================
2022-04-04 06:38:53,005: time cost, forward:0.010917498240005805, backward:0.05821596958586982, data cost:0.31356760901014646 
2022-04-04 06:38:53,005: ============================================================
2022-04-04 06:38:53,006: Epoch 24/26 Batch 2800/7662 eta: 2:03:33.526625	Training Loss 1.2581 (1.2168)	Training Prec@1 99.805 (99.979)	Training Prec@5 99.805 (99.995)	
2022-04-04 06:38:53,006: ============================================================
2022-04-04 06:39:30,130: time cost, forward:0.010906261919119638, backward:0.058226749871508256, data cost:0.31308890375938037 
2022-04-04 06:39:30,130: ============================================================
2022-04-04 06:39:30,130: Epoch 24/26 Batch 2900/7662 eta: 2:04:17.226913	Training Loss 1.2820 (1.2176)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.995)	
2022-04-04 06:39:30,131: ============================================================
2022-04-04 06:40:07,305: time cost, forward:0.01089884027237493, backward:0.05822921888396596, data cost:0.31276098486978876 
2022-04-04 06:40:07,306: ============================================================
2022-04-04 06:40:07,306: Epoch 24/26 Batch 3000/7662 eta: 2:03:50.246963	Training Loss 1.3479 (1.2188)	Training Prec@1 100.000 (99.979)	Training Prec@5 100.000 (99.995)	
2022-04-04 06:40:07,306: ============================================================
2022-04-04 06:40:44,067: time cost, forward:0.010903440394221524, backward:0.05822032488096372, data cost:0.3122431619508146 
2022-04-04 06:40:44,067: ============================================================
2022-04-04 06:40:44,067: Epoch 24/26 Batch 3100/7662 eta: 2:01:50.740990	Training Loss 1.2638 (1.2206)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.994)	
2022-04-04 06:40:44,067: ============================================================
2022-04-04 06:41:21,219: time cost, forward:0.010898015915732638, backward:0.058227351249177293, data cost:0.31196716786474316 
2022-04-04 06:41:21,220: ============================================================
2022-04-04 06:41:21,220: Epoch 24/26 Batch 3200/7662 eta: 2:02:31.443612	Training Loss 1.3306 (1.2217)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.995)	
2022-04-04 06:41:21,220: ============================================================
2022-04-04 06:41:58,343: time cost, forward:0.01087565160440871, backward:0.05824768004832249, data cost:0.3116687945648915 
2022-04-04 06:41:58,343: ============================================================
2022-04-04 06:41:58,343: Epoch 24/26 Batch 3300/7662 eta: 2:01:48.414520	Training Loss 1.3055 (1.2231)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.994)	
2022-04-04 06:41:58,343: ============================================================
2022-04-04 06:42:35,984: time cost, forward:0.01129005031748427, backward:0.057839353002496034, data cost:0.3115113919256154 
2022-04-04 06:42:35,985: ============================================================
2022-04-04 06:42:35,985: Epoch 24/26 Batch 3400/7662 eta: 2:02:52.868390	Training Loss 1.2260 (1.2246)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.994)	
2022-04-04 06:42:35,985: ============================================================
2022-04-04 06:43:14,078: time cost, forward:0.011272681103532196, backward:0.0578638671908797, data cost:0.3114924901006698 
2022-04-04 06:43:14,078: ============================================================
2022-04-04 06:43:14,079: Epoch 24/26 Batch 3500/7662 eta: 2:03:43.347275	Training Loss 1.3040 (1.2257)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.994)	
2022-04-04 06:43:14,079: ============================================================
2022-04-04 06:43:51,615: time cost, forward:0.011255697728395794, backward:0.0578794618486265, data cost:0.31129774301374713 
2022-04-04 06:43:51,616: ============================================================
2022-04-04 06:43:51,616: Epoch 24/26 Batch 3600/7662 eta: 2:01:17.328223	Training Loss 1.3745 (1.2266)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-04-04 06:43:51,616: ============================================================
2022-04-04 06:44:29,177: time cost, forward:0.011234598953874088, backward:0.05790347220221543, data cost:0.3111993265525816 
2022-04-04 06:44:29,177: ============================================================
2022-04-04 06:44:29,177: Epoch 24/26 Batch 3700/7662 eta: 2:00:44.471114	Training Loss 1.2188 (1.2278)	Training Prec@1 99.805 (99.977)	Training Prec@5 100.000 (99.994)	
2022-04-04 06:44:29,177: ============================================================
2022-04-04 06:45:08,148: time cost, forward:0.011216303335110995, backward:0.05792573565839309, data cost:0.31141557879245857 
2022-04-04 06:45:08,148: ============================================================
2022-04-04 06:45:08,148: Epoch 24/26 Batch 3800/7662 eta: 2:04:37.384746	Training Loss 1.2732 (1.2292)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-04-04 06:45:08,148: ============================================================
2022-04-04 06:45:45,145: time cost, forward:0.01122433694701037, backward:0.0579195295917465, data cost:0.3111317969187922 
2022-04-04 06:45:45,146: ============================================================
2022-04-04 06:45:45,146: Epoch 24/26 Batch 3900/7662 eta: 1:57:41.759049	Training Loss 1.1982 (1.2304)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-04-04 06:45:45,146: ============================================================
2022-04-04 06:46:23,541: time cost, forward:0.011222607852757409, backward:0.057926589711125596, data cost:0.311213472420706 
2022-04-04 06:46:23,541: ============================================================
2022-04-04 06:46:23,542: Epoch 24/26 Batch 4000/7662 eta: 2:01:30.190695	Training Loss 1.2422 (1.2320)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-04-04 06:46:23,542: ============================================================
2022-04-04 06:47:00,947: time cost, forward:0.011206692734937256, backward:0.05794635340189695, data cost:0.3110274689812345 
2022-04-04 06:47:00,948: ============================================================
2022-04-04 06:47:00,948: Epoch 24/26 Batch 4100/7662 eta: 1:57:44.891645	Training Loss 1.2088 (1.2330)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-04-04 06:47:00,948: ============================================================
2022-04-04 06:47:38,912: time cost, forward:0.011188286603930791, backward:0.05796132680489126, data cost:0.3109967042560037 
2022-04-04 06:47:38,913: ============================================================
2022-04-04 06:47:38,913: Epoch 24/26 Batch 4200/7662 eta: 1:58:52.491566	Training Loss 1.2837 (1.2340)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-04-04 06:47:38,913: ============================================================
2022-04-04 06:48:15,855: time cost, forward:0.011179107653592792, backward:0.05797524440008475, data cost:0.3107330482431444 
2022-04-04 06:48:15,856: ============================================================
2022-04-04 06:48:15,856: Epoch 24/26 Batch 4300/7662 eta: 1:55:03.575404	Training Loss 1.3887 (1.2351)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-04-04 06:48:15,856: ============================================================
2022-04-04 06:48:52,948: time cost, forward:0.01116587395395954, backward:0.057989783762909926, data cost:0.31053864649681373 
2022-04-04 06:48:52,948: ============================================================
2022-04-04 06:48:52,948: Epoch 24/26 Batch 4400/7662 eta: 1:54:54.299436	Training Loss 1.2883 (1.2358)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-04-04 06:48:52,948: ============================================================
2022-04-04 06:49:30,005: time cost, forward:0.011161317770203953, backward:0.057998474769312476, data cost:0.3103199589117338 
2022-04-04 06:49:30,006: ============================================================
2022-04-04 06:49:30,006: Epoch 24/26 Batch 4500/7662 eta: 1:54:10.860775	Training Loss 1.3155 (1.2369)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-04-04 06:49:30,006: ============================================================
2022-04-04 06:50:07,262: time cost, forward:0.01115210260041617, backward:0.058016126843788596, data cost:0.31013471822578975 
2022-04-04 06:50:07,263: ============================================================
2022-04-04 06:50:07,263: Epoch 24/26 Batch 4600/7662 eta: 1:54:10.496401	Training Loss 1.2491 (1.2377)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-04-04 06:50:07,264: ============================================================
2022-04-04 06:50:44,790: time cost, forward:0.011168639896828765, backward:0.05799969061051665, data cost:0.31002980512516326 
2022-04-04 06:50:44,791: ============================================================
2022-04-04 06:50:44,791: Epoch 24/26 Batch 4700/7662 eta: 1:54:22.776163	Training Loss 1.2119 (1.2388)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-04-04 06:50:44,792: ============================================================
2022-04-04 06:51:21,748: time cost, forward:0.01116489469818732, backward:0.05801387329006175, data cost:0.30981361749247227 
2022-04-04 06:51:21,748: ============================================================
2022-04-04 06:51:21,748: Epoch 24/26 Batch 4800/7662 eta: 1:52:01.325582	Training Loss 1.3444 (1.2398)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-04-04 06:51:21,748: ============================================================
2022-04-04 06:52:00,553: time cost, forward:0.011164442863627876, backward:0.05801656178538472, data cost:0.3099731364817638 
2022-04-04 06:52:00,554: ============================================================
2022-04-04 06:52:00,554: Epoch 24/26 Batch 4900/7662 eta: 1:56:58.816941	Training Loss 1.4825 (1.2407)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-04-04 06:52:00,554: ============================================================
2022-04-04 06:52:37,394: time cost, forward:0.011186224385532625, backward:0.05799628773029386, data cost:0.3097679333630551 
2022-04-04 06:52:37,395: ============================================================
2022-04-04 06:52:37,395: Epoch 24/26 Batch 5000/7662 eta: 1:50:26.539009	Training Loss 1.2864 (1.2419)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-04-04 06:52:37,395: ============================================================
2022-04-04 06:53:14,773: time cost, forward:0.011176350070439406, backward:0.05801044302515994, data cost:0.30964851907758906 
2022-04-04 06:53:14,774: ============================================================
2022-04-04 06:53:14,774: Epoch 24/26 Batch 5100/7662 eta: 1:51:26.023940	Training Loss 1.1894 (1.2429)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-04-04 06:53:14,774: ============================================================
2022-04-04 06:53:52,548: time cost, forward:0.011160503926013933, backward:0.05802848944872199, data cost:0.3096205024312014 
2022-04-04 06:53:52,549: ============================================================
2022-04-04 06:53:52,549: Epoch 24/26 Batch 5200/7662 eta: 1:51:59.015519	Training Loss 1.3029 (1.2440)	Training Prec@1 99.609 (99.976)	Training Prec@5 100.000 (99.994)	
2022-04-04 06:53:52,549: ============================================================
2022-04-04 06:54:29,172: time cost, forward:0.011146741535196127, backward:0.05804676302290566, data cost:0.3093529935377142 
2022-04-04 06:54:29,172: ============================================================
2022-04-04 06:54:29,173: Epoch 24/26 Batch 5300/7662 eta: 1:47:57.668170	Training Loss 1.1796 (1.2451)	Training Prec@1 99.805 (99.976)	Training Prec@5 100.000 (99.994)	
2022-04-04 06:54:29,173: ============================================================
2022-04-04 06:55:06,374: time cost, forward:0.011141716672173473, backward:0.058059532745256756, data cost:0.309220143834139 
2022-04-04 06:55:06,374: ============================================================
2022-04-04 06:55:06,374: Epoch 24/26 Batch 5400/7662 eta: 1:49:02.670438	Training Loss 1.2583 (1.2463)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-04-04 06:55:06,375: ============================================================
2022-04-04 06:55:43,953: time cost, forward:0.011132816332733659, backward:0.05806930916247357, data cost:0.30916368881124306 
2022-04-04 06:55:43,954: ============================================================
2022-04-04 06:55:43,954: Epoch 24/26 Batch 5500/7662 eta: 1:49:31.546628	Training Loss 1.3715 (1.2474)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-04-04 06:55:43,954: ============================================================
2022-04-04 06:56:22,511: time cost, forward:0.011140596528077982, backward:0.05806602531510776, data cost:0.3092818400714627 
2022-04-04 06:56:22,511: ============================================================
2022-04-04 06:56:22,511: Epoch 24/26 Batch 5600/7662 eta: 1:51:43.916479	Training Loss 1.3735 (1.2487)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-04-04 06:56:22,511: ============================================================
2022-04-04 06:57:00,488: time cost, forward:0.011139429876900154, backward:0.058068525876930295, data cost:0.30928737796342337 
2022-04-04 06:57:00,488: ============================================================
2022-04-04 06:57:00,488: Epoch 24/26 Batch 5700/7662 eta: 1:49:25.109873	Training Loss 1.1852 (1.2497)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-04-04 06:57:00,488: ============================================================
2022-04-04 06:57:37,687: time cost, forward:0.0111382247291982, backward:0.05808009869436865, data cost:0.3091598469381765 
2022-04-04 06:57:37,687: ============================================================
2022-04-04 06:57:37,687: Epoch 24/26 Batch 5800/7662 eta: 1:46:33.361090	Training Loss 1.2729 (1.2507)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-04-04 06:57:37,687: ============================================================
2022-04-04 06:58:15,234: time cost, forward:0.011140930307054948, backward:0.058080031520573845, data cost:0.30909254179503637 
2022-04-04 06:58:15,235: ============================================================
2022-04-04 06:58:15,235: Epoch 24/26 Batch 5900/7662 eta: 1:46:55.775976	Training Loss 1.2067 (1.2517)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-04-04 06:58:15,235: ============================================================
2022-04-04 06:58:55,120: time cost, forward:0.011132617456989699, backward:0.05808969568582272, data cost:0.3094259782480506 
2022-04-04 06:58:55,121: ============================================================
2022-04-04 06:58:55,121: Epoch 24/26 Batch 6000/7662 eta: 1:52:55.433834	Training Loss 1.3279 (1.2528)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.993)	
2022-04-04 06:58:55,121: ============================================================
2022-04-04 06:59:33,711: time cost, forward:0.011129271810143516, backward:0.05809485183267989, data cost:0.30953360952535874 
2022-04-04 06:59:33,712: ============================================================
2022-04-04 06:59:33,712: Epoch 24/26 Batch 6100/7662 eta: 1:48:36.862626	Training Loss 1.4246 (1.2540)	Training Prec@1 99.609 (99.975)	Training Prec@5 100.000 (99.993)	
2022-04-04 06:59:33,712: ============================================================
2022-04-04 07:00:11,560: time cost, forward:0.01113155257761488, backward:0.05809244653412864, data cost:0.30952881001372323 
2022-04-04 07:00:11,561: ============================================================
2022-04-04 07:00:11,561: Epoch 24/26 Batch 6200/7662 eta: 1:45:53.732078	Training Loss 1.2956 (1.2550)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.993)	
2022-04-04 07:00:11,561: ============================================================
2022-04-04 07:00:47,973: time cost, forward:0.011128710269700878, backward:0.05809604820703245, data cost:0.30928892816015796 
2022-04-04 07:00:47,974: ============================================================
2022-04-04 07:00:47,974: Epoch 24/26 Batch 6300/7662 eta: 1:41:16.231957	Training Loss 1.3413 (1.2560)	Training Prec@1 99.805 (99.975)	Training Prec@5 99.805 (99.993)	
2022-04-04 07:00:47,974: ============================================================
2022-04-04 07:01:25,758: time cost, forward:0.011159189493698261, backward:0.0580721403364279, data cost:0.30924780161273835 
2022-04-04 07:01:25,758: ============================================================
2022-04-04 07:01:25,758: Epoch 24/26 Batch 6400/7662 eta: 1:44:27.275884	Training Loss 1.3817 (1.2570)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-04-04 07:01:25,758: ============================================================
2022-04-04 07:02:03,307: time cost, forward:0.011151203468664368, backward:0.05808527188257798, data cost:0.30920520142823626 
2022-04-04 07:02:03,308: ============================================================
2022-04-04 07:02:03,308: Epoch 24/26 Batch 6500/7662 eta: 1:43:10.837989	Training Loss 1.1957 (1.2581)	Training Prec@1 99.805 (99.975)	Training Prec@5 100.000 (99.994)	
2022-04-04 07:02:03,308: ============================================================
2022-04-04 07:02:40,053: time cost, forward:0.011191113968115176, backward:0.058048161255046984, data cost:0.30901857469457267 
2022-04-04 07:02:40,054: ============================================================
2022-04-04 07:02:40,054: Epoch 24/26 Batch 6600/7662 eta: 1:40:21.579687	Training Loss 1.2725 (1.2589)	Training Prec@1 99.805 (99.975)	Training Prec@5 100.000 (99.994)	
2022-04-04 07:02:40,054: ============================================================
2022-04-04 07:03:16,768: time cost, forward:0.011210057927274156, backward:0.05803285354748646, data cost:0.30883372369177714 
2022-04-04 07:03:16,769: ============================================================
2022-04-04 07:03:16,769: Epoch 24/26 Batch 6700/7662 eta: 1:39:39.754135	Training Loss 1.2553 (1.2598)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-04-04 07:03:16,769: ============================================================
2022-04-04 07:03:53,151: time cost, forward:0.011199156314700049, backward:0.058043618958949134, data cost:0.3086141244613663 
2022-04-04 07:03:53,152: ============================================================
2022-04-04 07:03:53,152: Epoch 24/26 Batch 6800/7662 eta: 1:38:09.279028	Training Loss 1.2406 (1.2609)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-04-04 07:03:53,152: ============================================================
2022-04-04 07:04:30,432: time cost, forward:0.011186319289820525, backward:0.058057440555792025, data cost:0.30853900216181807 
2022-04-04 07:04:30,433: ============================================================
2022-04-04 07:04:30,433: Epoch 24/26 Batch 6900/7662 eta: 1:39:57.407187	Training Loss 1.3455 (1.2619)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.993)	
2022-04-04 07:04:30,433: ============================================================
2022-04-04 07:05:08,293: time cost, forward:0.011167313477229622, backward:0.0580808572350851, data cost:0.30854608345277 
2022-04-04 07:05:08,293: ============================================================
2022-04-04 07:05:08,293: Epoch 24/26 Batch 7000/7662 eta: 1:40:52.762076	Training Loss 1.2807 (1.2629)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.993)	
2022-04-04 07:05:08,294: ============================================================
2022-04-04 07:05:45,597: time cost, forward:0.01114862296661536, backward:0.05810025050986366, data cost:0.30846782797977174 
2022-04-04 07:05:45,597: ============================================================
2022-04-04 07:05:45,597: Epoch 24/26 Batch 7100/7662 eta: 1:38:46.462336	Training Loss 1.2571 (1.2637)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.993)	
2022-04-04 07:05:45,597: ============================================================
2022-04-04 07:06:24,288: time cost, forward:0.01114160469098627, backward:0.058108281089061, data cost:0.30858046883658447 
2022-04-04 07:06:24,288: ============================================================
2022-04-04 07:06:24,288: Epoch 24/26 Batch 7200/7662 eta: 1:41:48.144968	Training Loss 1.4524 (1.2646)	Training Prec@1 99.805 (99.974)	Training Prec@5 100.000 (99.993)	
2022-04-04 07:06:24,288: ============================================================
2022-04-04 07:07:02,524: time cost, forward:0.011130218359522173, backward:0.05812101524845348, data cost:0.3086324903242783 
2022-04-04 07:07:02,525: ============================================================
2022-04-04 07:07:02,525: Epoch 24/26 Batch 7300/7662 eta: 1:39:58.214476	Training Loss 1.4058 (1.2654)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.993)	
2022-04-04 07:07:02,526: ============================================================
2022-04-04 07:07:41,159: time cost, forward:0.011125197650967682, backward:0.05812562554410091, data cost:0.3087445159331578 
2022-04-04 07:07:41,160: ============================================================
2022-04-04 07:07:41,160: Epoch 24/26 Batch 7400/7662 eta: 1:40:22.018013	Training Loss 1.3530 (1.2662)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.993)	
2022-04-04 07:07:41,160: ============================================================
2022-04-04 07:08:19,607: time cost, forward:0.011131002769770344, backward:0.05812302550119883, data cost:0.30882833868459886 
2022-04-04 07:08:19,608: ============================================================
2022-04-04 07:08:19,608: Epoch 24/26 Batch 7500/7662 eta: 1:39:14.425137	Training Loss 1.3754 (1.2671)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.993)	
2022-04-04 07:08:19,608: ============================================================
2022-04-04 07:08:57,817: time cost, forward:0.011143291384032689, backward:0.0581107110094908, data cost:0.3088534279926339 
2022-04-04 07:08:57,818: ============================================================
2022-04-04 07:08:57,818: Epoch 24/26 Batch 7600/7662 eta: 1:37:59.428945	Training Loss 1.2787 (1.2681)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.993)	
2022-04-04 07:08:57,819: ============================================================
2022-04-04 07:09:24,145: Epoch: 24/26 eta: 1:37:35.356414	Training Loss 1.2096 (1.2687)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.993)
2022-04-04 07:09:24,145: ============================================================
2022-04-04 07:10:44,825: time cost, forward:0.01093698511219988, backward:0.056854248046875, data cost:0.7433043923040833 
2022-04-04 07:10:44,826: ============================================================
2022-04-04 07:10:44,826: Epoch 25/26 Batch 100/7662 eta: 3:24:24.094750	Training Loss 1.1423 (1.1677)	Training Prec@1 100.000 (99.988)	Training Prec@5 100.000 (99.994)	
2022-04-04 07:10:44,826: ============================================================
2022-04-04 07:11:21,414: time cost, forward:0.011142912821554059, backward:0.05695658592722524, data cost:0.5186406356006411 
2022-04-04 07:11:21,414: ============================================================
2022-04-04 07:11:21,414: Epoch 25/26 Batch 200/7662 eta: 1:32:13.977236	Training Loss 1.1582 (1.1614)	Training Prec@1 100.000 (99.988)	Training Prec@5 100.000 (99.995)	
2022-04-04 07:11:21,415: ============================================================
2022-04-04 07:11:56,723: time cost, forward:0.011474415610067821, backward:0.05704510172075253, data cost:0.4399425784082317 
2022-04-04 07:11:56,723: ============================================================
2022-04-04 07:11:56,724: Epoch 25/26 Batch 300/7662 eta: 1:28:25.255524	Training Loss 1.1027 (1.1617)	Training Prec@1 100.000 (99.988)	Training Prec@5 100.000 (99.994)	
2022-04-04 07:11:56,724: ============================================================
2022-04-04 07:12:34,142: time cost, forward:0.011237021974453651, backward:0.05760752766353445, data cost:0.4057364947813794 
2022-04-04 07:12:34,143: ============================================================
2022-04-04 07:12:34,143: Epoch 25/26 Batch 400/7662 eta: 1:33:04.830217	Training Loss 1.1451 (1.1629)	Training Prec@1 100.000 (99.988)	Training Prec@5 100.000 (99.996)	
2022-04-04 07:12:34,144: ============================================================
2022-04-04 07:13:12,945: time cost, forward:0.011163280578796753, backward:0.0578689842759249, data cost:0.388119872442945 
2022-04-04 07:13:12,945: ============================================================
2022-04-04 07:13:12,945: Epoch 25/26 Batch 500/7662 eta: 1:35:52.434645	Training Loss 1.2762 (1.1648)	Training Prec@1 100.000 (99.986)	Training Prec@5 100.000 (99.996)	
2022-04-04 07:13:12,946: ============================================================
2022-04-04 07:13:49,885: time cost, forward:0.011563446764555917, backward:0.05754503543070441, data cost:0.3733396745086313 
2022-04-04 07:13:49,885: ============================================================
2022-04-04 07:13:49,885: Epoch 25/26 Batch 600/7662 eta: 1:30:39.418695	Training Loss 1.1881 (1.1683)	Training Prec@1 100.000 (99.985)	Training Prec@5 100.000 (99.994)	
2022-04-04 07:13:49,886: ============================================================
2022-04-04 07:14:27,319: time cost, forward:0.011548388498876568, backward:0.057674313478374345, data cost:0.36334958574461496 
2022-04-04 07:14:27,320: ============================================================
2022-04-04 07:14:27,320: Epoch 25/26 Batch 700/7662 eta: 1:31:14.778850	Training Loss 1.1742 (1.1704)	Training Prec@1 99.805 (99.984)	Training Prec@5 100.000 (99.995)	
2022-04-04 07:14:27,320: ============================================================
2022-04-04 07:15:06,173: time cost, forward:0.011578903329536525, backward:0.057690428851990584, data cost:0.35766113207247735 
2022-04-04 07:15:06,173: ============================================================
2022-04-04 07:15:06,173: Epoch 25/26 Batch 800/7662 eta: 1:34:03.445059	Training Loss 1.1788 (1.1724)	Training Prec@1 100.000 (99.983)	Training Prec@5 100.000 (99.995)	
2022-04-04 07:15:06,173: ============================================================
2022-04-04 07:15:44,247: time cost, forward:0.0114812386844792, backward:0.05784034198595499, data cost:0.35241613610833056 
2022-04-04 07:15:44,248: ============================================================
2022-04-04 07:15:44,248: Epoch 25/26 Batch 900/7662 eta: 1:31:32.276902	Training Loss 1.2188 (1.1741)	Training Prec@1 100.000 (99.984)	Training Prec@5 100.000 (99.995)	
2022-04-04 07:15:44,248: ============================================================
2022-04-04 07:16:20,377: time cost, forward:0.011364727526217012, backward:0.05803915282508155, data cost:0.3462396835063671 
2022-04-04 07:16:20,378: ============================================================
2022-04-04 07:16:20,378: Epoch 25/26 Batch 1000/7662 eta: 1:26:15.647039	Training Loss 1.3189 (1.1768)	Training Prec@1 100.000 (99.984)	Training Prec@5 100.000 (99.996)	
2022-04-04 07:16:20,378: ============================================================
2022-04-04 07:16:58,285: time cost, forward:0.011255453455111891, backward:0.05818579151372241, data cost:0.34281929131526095 
2022-04-04 07:16:58,285: ============================================================
2022-04-04 07:16:58,285: Epoch 25/26 Batch 1100/7662 eta: 1:29:52.303318	Training Loss 1.2192 (1.1791)	Training Prec@1 100.000 (99.983)	Training Prec@5 100.000 (99.995)	
2022-04-04 07:16:58,285: ============================================================
2022-04-04 07:17:36,761: time cost, forward:0.01123409772336831, backward:0.058243270711763585, data cost:0.34046774968393057 
2022-04-04 07:17:36,762: ============================================================
2022-04-04 07:17:36,762: Epoch 25/26 Batch 1200/7662 eta: 1:30:34.855033	Training Loss 1.3298 (1.1809)	Training Prec@1 100.000 (99.984)	Training Prec@5 100.000 (99.996)	
2022-04-04 07:17:36,762: ============================================================
2022-04-04 07:18:15,503: time cost, forward:0.011204236465935711, backward:0.058277630824323245, data cost:0.33868368356571094 
2022-04-04 07:18:15,504: ============================================================
2022-04-04 07:18:15,504: Epoch 25/26 Batch 1300/7662 eta: 1:30:33.543044	Training Loss 1.2273 (1.1818)	Training Prec@1 100.000 (99.984)	Training Prec@5 100.000 (99.995)	
2022-04-04 07:18:15,504: ============================================================
2022-04-04 07:18:53,711: time cost, forward:0.011351185751608902, backward:0.058124686241831584, data cost:0.33683080772061785 
2022-04-04 07:18:53,711: ============================================================
2022-04-04 07:18:53,711: Epoch 25/26 Batch 1400/7662 eta: 1:28:40.351711	Training Loss 1.2281 (1.1837)	Training Prec@1 100.000 (99.983)	Training Prec@5 100.000 (99.996)	
2022-04-04 07:18:53,711: ============================================================
2022-04-04 07:19:31,366: time cost, forward:0.011351677161045596, backward:0.05811611933259665, data cost:0.3347634437324366 
2022-04-04 07:19:31,367: ============================================================
2022-04-04 07:19:31,367: Epoch 25/26 Batch 1500/7662 eta: 1:26:45.899861	Training Loss 1.3188 (1.1854)	Training Prec@1 100.000 (99.983)	Training Prec@5 100.000 (99.995)	
2022-04-04 07:19:31,367: ============================================================
2022-04-04 07:20:08,147: time cost, forward:0.011314326334625873, backward:0.05817513752162568, data cost:0.33234002129445606 
2022-04-04 07:20:08,148: ============================================================
2022-04-04 07:20:08,148: Epoch 25/26 Batch 1600/7662 eta: 1:24:08.214422	Training Loss 1.1473 (1.1873)	Training Prec@1 100.000 (99.983)	Training Prec@5 100.000 (99.995)	
2022-04-04 07:20:08,148: ============================================================
2022-04-04 07:20:45,261: time cost, forward:0.0112856768944321, backward:0.05820937027574778, data cost:0.3306056104596044 
2022-04-04 07:20:45,262: ============================================================
2022-04-04 07:20:45,262: Epoch 25/26 Batch 1700/7662 eta: 1:24:16.783908	Training Loss 1.3073 (1.1890)	Training Prec@1 100.000 (99.983)	Training Prec@5 100.000 (99.995)	
2022-04-04 07:20:45,262: ============================================================
2022-04-04 07:21:22,248: time cost, forward:0.011266210199793953, backward:0.05822705930971715, data cost:0.3288840807564329 
2022-04-04 07:21:22,248: ============================================================
2022-04-04 07:21:22,249: Epoch 25/26 Batch 1800/7662 eta: 1:23:22.426934	Training Loss 1.2244 (1.1901)	Training Prec@1 100.000 (99.983)	Training Prec@5 100.000 (99.995)	
2022-04-04 07:21:22,249: ============================================================
2022-04-04 07:21:59,176: time cost, forward:0.011246156792944516, backward:0.05824344443170067, data cost:0.32735776348827134 
2022-04-04 07:21:59,176: ============================================================
2022-04-04 07:21:59,177: Epoch 25/26 Batch 1900/7662 eta: 1:22:37.575866	Training Loss 1.2000 (1.1912)	Training Prec@1 100.000 (99.983)	Training Prec@5 100.000 (99.995)	
2022-04-04 07:21:59,177: ============================================================
2022-04-04 07:22:37,632: time cost, forward:0.01128031767386684, backward:0.058199232849495124, data cost:0.326691441323651 
2022-04-04 07:22:37,632: ============================================================
2022-04-04 07:22:37,633: Epoch 25/26 Batch 2000/7662 eta: 1:25:24.255499	Training Loss 1.1228 (1.1932)	Training Prec@1 100.000 (99.982)	Training Prec@5 100.000 (99.995)	
2022-04-04 07:22:37,633: ============================================================
2022-04-04 07:23:14,511: time cost, forward:0.011264347246341786, backward:0.05821713985517628, data cost:0.3253852426011884 
2022-04-04 07:23:14,511: ============================================================
2022-04-04 07:23:14,512: Epoch 25/26 Batch 2100/7662 eta: 1:21:17.244401	Training Loss 1.1596 (1.1947)	Training Prec@1 100.000 (99.982)	Training Prec@5 100.000 (99.995)	
2022-04-04 07:23:14,512: ============================================================
2022-04-04 07:23:52,921: time cost, forward:0.011240733217358209, backward:0.05823527340891146, data cost:0.3248524145409973 
2022-04-04 07:23:52,921: ============================================================
2022-04-04 07:23:52,922: Epoch 25/26 Batch 2200/7662 eta: 1:24:01.310728	Training Loss 1.1937 (1.1959)	Training Prec@1 100.000 (99.982)	Training Prec@5 100.000 (99.995)	
2022-04-04 07:23:52,922: ============================================================
2022-04-04 07:24:29,929: time cost, forward:0.011232165680495797, backward:0.05824821127036594, data cost:0.32377018115477957 
2022-04-04 07:24:29,929: ============================================================
2022-04-04 07:24:29,930: Epoch 25/26 Batch 2300/7662 eta: 1:20:20.323382	Training Loss 1.1996 (1.1977)	Training Prec@1 100.000 (99.982)	Training Prec@5 100.000 (99.995)	
2022-04-04 07:24:29,930: ============================================================
2022-04-04 07:25:07,330: time cost, forward:0.011209510872392865, backward:0.058282180844172186, data cost:0.32293770540848826 
2022-04-04 07:25:07,331: ============================================================
2022-04-04 07:25:07,331: Epoch 25/26 Batch 2400/7662 eta: 1:20:34.127757	Training Loss 1.2085 (1.1996)	Training Prec@1 100.000 (99.982)	Training Prec@5 100.000 (99.995)	
2022-04-04 07:25:07,331: ============================================================
2022-04-04 07:25:44,966: time cost, forward:0.011183424633281046, backward:0.058318517264388664, data cost:0.3222319988214097 
2022-04-04 07:25:44,967: ============================================================
2022-04-04 07:25:44,967: Epoch 25/26 Batch 2500/7662 eta: 1:20:26.812586	Training Loss 1.2401 (1.2015)	Training Prec@1 100.000 (99.982)	Training Prec@5 100.000 (99.995)	
2022-04-04 07:25:44,967: ============================================================
2022-04-04 07:26:22,014: time cost, forward:0.011184150322256935, backward:0.0583216149607912, data cost:0.3214233292208676 
2022-04-04 07:26:22,015: ============================================================
2022-04-04 07:26:22,015: Epoch 25/26 Batch 2600/7662 eta: 1:18:34.330525	Training Loss 1.2469 (1.2030)	Training Prec@1 100.000 (99.982)	Training Prec@5 100.000 (99.995)	
2022-04-04 07:26:22,015: ============================================================
2022-04-04 07:26:58,548: time cost, forward:0.011191087989906066, backward:0.058305175006720875, data cost:0.3204601712030762 
2022-04-04 07:26:58,549: ============================================================
2022-04-04 07:26:58,549: Epoch 25/26 Batch 2700/7662 eta: 1:16:52.415925	Training Loss 1.2738 (1.2048)	Training Prec@1 100.000 (99.982)	Training Prec@5 100.000 (99.995)	
2022-04-04 07:26:58,549: ============================================================
2022-04-04 07:27:36,141: time cost, forward:0.011176122261311762, backward:0.05832025961349504, data cost:0.31994668267888227 
2022-04-04 07:27:36,142: ============================================================
2022-04-04 07:27:36,142: Epoch 25/26 Batch 2800/7662 eta: 1:18:28.520196	Training Loss 1.3409 (1.2060)	Training Prec@1 100.000 (99.981)	Training Prec@5 100.000 (99.995)	
2022-04-04 07:27:36,142: ============================================================
2022-04-04 07:28:13,190: time cost, forward:0.011162399217645724, backward:0.0583437772075157, data cost:0.31926418238979 
2022-04-04 07:28:13,190: ============================================================
2022-04-04 07:28:13,191: Epoch 25/26 Batch 2900/7662 eta: 1:16:43.307800	Training Loss 1.3281 (1.2075)	Training Prec@1 100.000 (99.982)	Training Prec@5 100.000 (99.995)	
2022-04-04 07:28:13,191: ============================================================
2022-04-04 07:28:50,819: time cost, forward:0.011149536812055027, backward:0.05834985224554323, data cost:0.3188165638915059 
2022-04-04 07:28:50,819: ============================================================
2022-04-04 07:28:50,819: Epoch 25/26 Batch 3000/7662 eta: 1:17:17.752763	Training Loss 1.1917 (1.2087)	Training Prec@1 100.000 (99.982)	Training Prec@5 100.000 (99.995)	
2022-04-04 07:28:50,820: ============================================================
2022-04-04 07:29:27,441: time cost, forward:0.011138664210523548, backward:0.05837426457954399, data cost:0.31808924936563515 
2022-04-04 07:29:27,441: ============================================================
2022-04-04 07:29:27,442: Epoch 25/26 Batch 3100/7662 eta: 1:14:37.084995	Training Loss 1.3105 (1.2102)	Training Prec@1 100.000 (99.981)	Training Prec@5 100.000 (99.995)	
2022-04-04 07:29:27,442: ============================================================
2022-04-04 07:30:05,926: time cost, forward:0.011134710562307411, backward:0.05837168146498913, data cost:0.31798176915990667 
2022-04-04 07:30:05,926: ============================================================
2022-04-04 07:30:05,926: Epoch 25/26 Batch 3200/7662 eta: 1:17:46.236539	Training Loss 1.3113 (1.2118)	Training Prec@1 100.000 (99.982)	Training Prec@5 100.000 (99.995)	
2022-04-04 07:30:05,926: ============================================================
2022-04-04 07:30:44,138: time cost, forward:0.01113474423251538, backward:0.05836303294084404, data cost:0.31780527432277805 
2022-04-04 07:30:44,138: ============================================================
2022-04-04 07:30:44,138: Epoch 25/26 Batch 3300/7662 eta: 1:16:34.994851	Training Loss 1.1694 (1.2129)	Training Prec@1 100.000 (99.981)	Training Prec@5 100.000 (99.995)	
2022-04-04 07:30:44,138: ============================================================
2022-04-04 07:31:22,354: time cost, forward:0.011120643570830662, backward:0.058373697647875845, data cost:0.31766249439792793 
2022-04-04 07:31:22,355: ============================================================
2022-04-04 07:31:22,355: Epoch 25/26 Batch 3400/7662 eta: 1:15:57.323629	Training Loss 1.2214 (1.2143)	Training Prec@1 100.000 (99.981)	Training Prec@5 100.000 (99.995)	
2022-04-04 07:31:22,355: ============================================================
2022-04-04 07:31:59,892: time cost, forward:0.011097979225339668, backward:0.0583894293660537, data cost:0.31731512533592887 
2022-04-04 07:31:59,892: ============================================================
2022-04-04 07:31:59,893: Epoch 25/26 Batch 3500/7662 eta: 1:13:58.856502	Training Loss 1.3868 (1.2157)	Training Prec@1 99.805 (99.981)	Training Prec@5 99.805 (99.995)	
2022-04-04 07:31:59,893: ============================================================
2022-04-04 07:32:37,699: time cost, forward:0.01108047285819259, backward:0.05841012728416314, data cost:0.31705131137261755 
2022-04-04 07:32:37,699: ============================================================
2022-04-04 07:32:37,699: Epoch 25/26 Batch 3600/7662 eta: 1:13:52.844016	Training Loss 1.1737 (1.2173)	Training Prec@1 100.000 (99.980)	Training Prec@5 100.000 (99.994)	
2022-04-04 07:32:37,700: ============================================================
2022-04-04 07:33:15,176: time cost, forward:0.01111834917432007, backward:0.05838128907450407, data cost:0.3166974242489607 
2022-04-04 07:33:15,177: ============================================================
2022-04-04 07:33:15,177: Epoch 25/26 Batch 3700/7662 eta: 1:12:36.742187	Training Loss 1.2453 (1.2186)	Training Prec@1 100.000 (99.980)	Training Prec@5 100.000 (99.994)	
2022-04-04 07:33:15,177: ============================================================
2022-04-04 07:33:52,829: time cost, forward:0.011108957990027315, backward:0.05838843194018166, data cost:0.31643285278145594 
2022-04-04 07:33:52,830: ============================================================
2022-04-04 07:33:52,830: Epoch 25/26 Batch 3800/7662 eta: 1:12:19.527360	Training Loss 1.2977 (1.2197)	Training Prec@1 100.000 (99.980)	Training Prec@5 100.000 (99.994)	
2022-04-04 07:33:52,830: ============================================================
2022-04-04 07:34:30,152: time cost, forward:0.011087883738683841, backward:0.05842161294771299, data cost:0.31606719016295026 
2022-04-04 07:34:30,153: ============================================================
2022-04-04 07:34:30,153: Epoch 25/26 Batch 3900/7662 eta: 1:11:04.157839	Training Loss 1.1946 (1.2214)	Training Prec@1 99.805 (99.981)	Training Prec@5 100.000 (99.994)	
2022-04-04 07:34:30,153: ============================================================
2022-04-04 07:35:09,758: time cost, forward:0.011070221237732072, backward:0.058447816426171514, data cost:0.31631879181705674 
2022-04-04 07:35:09,758: ============================================================
2022-04-04 07:35:09,759: Epoch 25/26 Batch 4000/7662 eta: 1:14:45.323224	Training Loss 1.2171 (1.2227)	Training Prec@1 100.000 (99.980)	Training Prec@5 100.000 (99.994)	
2022-04-04 07:35:09,759: ============================================================
2022-04-04 07:35:48,604: time cost, forward:0.011109313315721686, backward:0.05838728270957632, data cost:0.31640642309921724 
2022-04-04 07:35:48,604: ============================================================
2022-04-04 07:35:48,604: Epoch 25/26 Batch 4100/7662 eta: 1:12:40.411041	Training Loss 1.2343 (1.2241)	Training Prec@1 99.805 (99.980)	Training Prec@5 100.000 (99.995)	
2022-04-04 07:35:48,604: ============================================================
2022-04-04 07:36:26,038: time cost, forward:0.011125918029745184, backward:0.05835500448253729, data cost:0.31612641126038094 
2022-04-04 07:36:26,038: ============================================================
2022-04-04 07:36:26,038: Epoch 25/26 Batch 4200/7662 eta: 1:09:24.537143	Training Loss 1.2864 (1.2253)	Training Prec@1 100.000 (99.980)	Training Prec@5 100.000 (99.995)	
2022-04-04 07:36:26,038: ============================================================
2022-04-04 07:37:04,825: time cost, forward:0.011150860570147582, backward:0.05831676190552198, data cost:0.3161723566598797 
2022-04-04 07:37:04,826: ============================================================
2022-04-04 07:37:04,826: Epoch 25/26 Batch 4300/7662 eta: 1:11:16.337715	Training Loss 1.3751 (1.2265)	Training Prec@1 100.000 (99.980)	Training Prec@5 100.000 (99.995)	
2022-04-04 07:37:04,826: ============================================================
2022-04-04 07:37:44,400: time cost, forward:0.0111843744010431, backward:0.058262596566125896, data cost:0.31641752661886907 
2022-04-04 07:37:44,400: ============================================================
2022-04-04 07:37:44,401: Epoch 25/26 Batch 4400/7662 eta: 1:12:03.537499	Training Loss 1.1559 (1.2275)	Training Prec@1 100.000 (99.980)	Training Prec@5 100.000 (99.995)	
2022-04-04 07:37:44,401: ============================================================
2022-04-04 07:38:22,587: time cost, forward:0.01122735982260245, backward:0.058204201916425224, data cost:0.3163188503275556 
2022-04-04 07:38:22,588: ============================================================
2022-04-04 07:38:22,588: Epoch 25/26 Batch 4500/7662 eta: 1:08:53.824129	Training Loss 1.2576 (1.2286)	Training Prec@1 100.000 (99.980)	Training Prec@5 100.000 (99.995)	
2022-04-04 07:38:22,589: ============================================================
2022-04-04 07:38:59,699: time cost, forward:0.011359300165493661, backward:0.05805897878599986, data cost:0.3159954789462984 
2022-04-04 07:38:59,699: ============================================================
2022-04-04 07:38:59,700: Epoch 25/26 Batch 4600/7662 eta: 1:06:20.178409	Training Loss 1.2394 (1.2302)	Training Prec@1 100.000 (99.980)	Training Prec@5 100.000 (99.995)	
2022-04-04 07:38:59,700: ============================================================
2022-04-04 07:39:38,763: time cost, forward:0.0114140587681074, backward:0.05799355814370177, data cost:0.3161100601485294 
2022-04-04 07:39:38,764: ============================================================
2022-04-04 07:39:38,764: Epoch 25/26 Batch 4700/7662 eta: 1:09:10.591837	Training Loss 1.3769 (1.2315)	Training Prec@1 100.000 (99.979)	Training Prec@5 100.000 (99.994)	
2022-04-04 07:39:38,764: ============================================================
2022-04-04 07:40:17,874: time cost, forward:0.01141009735151936, backward:0.0579836237403248, data cost:0.31622757661290457 
2022-04-04 07:40:17,874: ============================================================
2022-04-04 07:40:17,874: Epoch 25/26 Batch 4800/7662 eta: 1:08:36.348417	Training Loss 1.3136 (1.2327)	Training Prec@1 100.000 (99.980)	Training Prec@5 100.000 (99.995)	
2022-04-04 07:40:17,874: ============================================================
2022-04-04 07:40:55,061: time cost, forward:0.011416390224923209, backward:0.05796216093391563, data cost:0.3159442456018246 
2022-04-04 07:40:55,061: ============================================================
2022-04-04 07:40:55,062: Epoch 25/26 Batch 4900/7662 eta: 1:04:36.808582	Training Loss 1.3324 (1.2340)	Training Prec@1 99.805 (99.979)	Training Prec@5 99.805 (99.994)	
2022-04-04 07:40:55,062: ============================================================
2022-04-04 07:41:33,887: time cost, forward:0.01141598735434648, backward:0.05795043262154323, data cost:0.3160115646157033 
2022-04-04 07:41:33,887: ============================================================
2022-04-04 07:41:33,887: Epoch 25/26 Batch 5000/7662 eta: 1:06:48.739473	Training Loss 1.2619 (1.2349)	Training Prec@1 100.000 (99.979)	Training Prec@5 100.000 (99.994)	
2022-04-04 07:41:33,887: ============================================================
2022-04-04 07:42:11,240: time cost, forward:0.011424215991582607, backward:0.05793017260021592, data cost:0.3157761169429105 
2022-04-04 07:42:11,240: ============================================================
2022-04-04 07:42:11,240: Epoch 25/26 Batch 5100/7662 eta: 1:03:39.341561	Training Loss 1.2894 (1.2359)	Training Prec@1 99.805 (99.979)	Training Prec@5 100.000 (99.994)	
2022-04-04 07:42:11,241: ============================================================
2022-04-04 07:42:48,611: time cost, forward:0.011452054078589496, backward:0.057885625862712974, data cost:0.3155736104184147 
2022-04-04 07:42:48,612: ============================================================
2022-04-04 07:42:48,612: Epoch 25/26 Batch 5200/7662 eta: 1:03:03.885885	Training Loss 1.2210 (1.2371)	Training Prec@1 100.000 (99.979)	Training Prec@5 100.000 (99.994)	
2022-04-04 07:42:48,612: ============================================================
2022-04-04 07:43:25,550: time cost, forward:0.011473468034351562, backward:0.05785416449931775, data cost:0.3152003388603716 
2022-04-04 07:43:25,550: ============================================================
2022-04-04 07:43:25,550: Epoch 25/26 Batch 5300/7662 eta: 1:01:43.073862	Training Loss 1.2841 (1.2382)	Training Prec@1 100.000 (99.979)	Training Prec@5 100.000 (99.994)	
2022-04-04 07:43:25,551: ============================================================
2022-04-04 07:44:04,355: time cost, forward:0.011470077081529449, backward:0.05784710558901718, data cost:0.31533941014384004 
2022-04-04 07:44:04,356: ============================================================
2022-04-04 07:44:04,356: Epoch 25/26 Batch 5400/7662 eta: 1:04:11.469920	Training Loss 1.2922 (1.2392)	Training Prec@1 99.805 (99.979)	Training Prec@5 99.805 (99.994)	
2022-04-04 07:44:04,356: ============================================================
2022-04-04 07:44:42,204: time cost, forward:0.011462189366891614, backward:0.05784083401252842, data cost:0.3152368444597793 
2022-04-04 07:44:42,241: ============================================================
2022-04-04 07:44:42,241: Epoch 25/26 Batch 5500/7662 eta: 1:02:02.234184	Training Loss 1.1691 (1.2406)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.994)	
2022-04-04 07:44:42,242: ============================================================
2022-04-04 07:45:20,294: time cost, forward:0.011470011205071955, backward:0.05782264086748366, data cost:0.3151686955060378 
2022-04-04 07:45:20,295: ============================================================
2022-04-04 07:45:20,295: Epoch 25/26 Batch 5600/7662 eta: 1:01:40.704260	Training Loss 1.2837 (1.2417)	Training Prec@1 100.000 (99.979)	Training Prec@5 100.000 (99.994)	
2022-04-04 07:45:20,295: ============================================================
2022-04-04 07:45:58,047: time cost, forward:0.011460011330460807, backward:0.05782065543820511, data cost:0.3150246523204321 
2022-04-04 07:45:58,048: ============================================================
2022-04-04 07:45:58,048: Epoch 25/26 Batch 5700/7662 eta: 1:00:33.737152	Training Loss 1.2927 (1.2428)	Training Prec@1 100.000 (99.979)	Training Prec@5 100.000 (99.994)	
2022-04-04 07:45:58,048: ============================================================
2022-04-04 07:46:35,295: time cost, forward:0.011451533589409969, backward:0.057821058162143876, data cost:0.3148412437228463 
2022-04-04 07:46:35,296: ============================================================
2022-04-04 07:46:35,296: Epoch 25/26 Batch 5800/7662 eta: 0:59:07.870629	Training Loss 1.3420 (1.2439)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.994)	
2022-04-04 07:46:35,296: ============================================================
2022-04-04 07:47:12,216: time cost, forward:0.01144072459418605, backward:0.057826511414096726, data cost:0.3145864352995631 
2022-04-04 07:47:12,217: ============================================================
2022-04-04 07:47:12,217: Epoch 25/26 Batch 5900/7662 eta: 0:57:59.771196	Training Loss 1.2585 (1.2449)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.994)	
2022-04-04 07:47:12,217: ============================================================
2022-04-04 07:47:48,927: time cost, forward:0.011434934639616754, backward:0.05782396250077935, data cost:0.31429552233086006 
2022-04-04 07:47:48,928: ============================================================
2022-04-04 07:47:48,928: Epoch 25/26 Batch 6000/7662 eta: 0:57:03.313153	Training Loss 1.3638 (1.2459)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.994)	
2022-04-04 07:47:48,928: ============================================================
2022-04-04 07:48:26,471: time cost, forward:0.011429016463853118, backward:0.05782384312647369, data cost:0.31417164526565833 
2022-04-04 07:48:26,471: ============================================================
2022-04-04 07:48:26,471: Epoch 25/26 Batch 6100/7662 eta: 0:57:43.364314	Training Loss 1.3475 (1.2469)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.994)	
2022-04-04 07:48:26,471: ============================================================
2022-04-04 07:49:04,573: time cost, forward:0.011432912584696494, backward:0.057813253147330164, data cost:0.3141269825373682 
2022-04-04 07:49:04,574: ============================================================
2022-04-04 07:49:04,574: Epoch 25/26 Batch 6200/7662 eta: 0:57:56.881295	Training Loss 1.2115 (1.2478)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.994)	
2022-04-04 07:49:04,574: ============================================================
2022-04-04 07:49:43,455: time cost, forward:0.011430533126453158, backward:0.057804371709198325, data cost:0.3142165247079474 
2022-04-04 07:49:43,456: ============================================================
2022-04-04 07:49:43,456: Epoch 25/26 Batch 6300/7662 eta: 0:58:29.131439	Training Loss 1.3666 (1.2487)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-04-04 07:49:43,457: ============================================================
2022-04-04 07:50:20,851: time cost, forward:0.011426061703872264, backward:0.05780234368895531, data cost:0.31406702181569746 
2022-04-04 07:50:20,851: ============================================================
2022-04-04 07:50:20,851: Epoch 25/26 Batch 6400/7662 eta: 0:55:37.503195	Training Loss 1.2545 (1.2498)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-04-04 07:50:20,851: ============================================================
2022-04-04 07:50:58,109: time cost, forward:0.011410970434003067, backward:0.057815142641949424, data cost:0.31389766107028877 
2022-04-04 07:50:58,110: ============================================================
2022-04-04 07:50:58,110: Epoch 25/26 Batch 6500/7662 eta: 0:54:48.079172	Training Loss 1.3358 (1.2508)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-04-04 07:50:58,110: ============================================================
2022-04-04 07:51:34,345: time cost, forward:0.011401784945697671, backward:0.05782227202570245, data cost:0.3135789801341365 
2022-04-04 07:51:34,345: ============================================================
2022-04-04 07:51:34,345: Epoch 25/26 Batch 6600/7662 eta: 0:52:41.530908	Training Loss 1.3385 (1.2519)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-04-04 07:51:34,345: ============================================================
2022-04-04 07:52:11,446: time cost, forward:0.011388392248408511, backward:0.057844328122239344, data cost:0.31336741864565576 
2022-04-04 07:52:11,447: ============================================================
2022-04-04 07:52:11,447: Epoch 25/26 Batch 6700/7662 eta: 0:53:20.024160	Training Loss 1.2360 (1.2529)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-04-04 07:52:11,447: ============================================================
2022-04-04 07:52:48,613: time cost, forward:0.01137974423895094, backward:0.05785694776659311, data cost:0.3132112094594689 
2022-04-04 07:52:48,613: ============================================================
2022-04-04 07:52:48,613: Epoch 25/26 Batch 6800/7662 eta: 0:52:48.426389	Training Loss 1.2723 (1.2539)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-04-04 07:52:48,613: ============================================================
2022-04-04 07:53:27,451: time cost, forward:0.011365945105242338, backward:0.057874786489198894, data cost:0.31326635285795107 
2022-04-04 07:53:27,452: ============================================================
2022-04-04 07:53:27,452: Epoch 25/26 Batch 6900/7662 eta: 0:54:32.144270	Training Loss 1.3682 (1.2550)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-04-04 07:53:27,452: ============================================================
2022-04-04 07:54:05,661: time cost, forward:0.011370573406271262, backward:0.05787341086110621, data cost:0.3132680436341588 
2022-04-04 07:54:05,662: ============================================================
2022-04-04 07:54:05,662: Epoch 25/26 Batch 7000/7662 eta: 0:53:01.003840	Training Loss 1.2999 (1.2560)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-04-04 07:54:05,662: ============================================================
2022-04-04 07:54:42,937: time cost, forward:0.0113692848862754, backward:0.05787676827204632, data cost:0.3131222466647348 
2022-04-04 07:54:42,938: ============================================================
2022-04-04 07:54:42,938: Epoch 25/26 Batch 7100/7662 eta: 0:51:05.922430	Training Loss 1.3107 (1.2569)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-04-04 07:54:42,938: ============================================================
2022-04-04 07:55:18,991: time cost, forward:0.011384398196369166, backward:0.057871719982445544, data cost:0.3127975525467209 
2022-04-04 07:55:18,991: ============================================================
2022-04-04 07:55:18,991: Epoch 25/26 Batch 7200/7662 eta: 0:48:49.354076	Training Loss 1.2438 (1.2578)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-04-04 07:55:18,992: ============================================================
2022-04-04 07:55:55,698: time cost, forward:0.011374308256469927, backward:0.05787995146111048, data cost:0.3125876830953297 
2022-04-04 07:55:55,698: ============================================================
2022-04-04 07:55:55,699: Epoch 25/26 Batch 7300/7662 eta: 0:49:05.756133	Training Loss 1.2881 (1.2589)	Training Prec@1 99.805 (99.976)	Training Prec@5 100.000 (99.994)	
2022-04-04 07:55:55,699: ============================================================
2022-04-04 07:56:32,910: time cost, forward:0.011361932574067346, backward:0.057890692986834934, data cost:0.31242677510985006 
2022-04-04 07:56:32,911: ============================================================
2022-04-04 07:56:32,911: Epoch 25/26 Batch 7400/7662 eta: 0:49:09.085285	Training Loss 1.3882 (1.2599)	Training Prec@1 99.805 (99.976)	Training Prec@5 99.805 (99.994)	
2022-04-04 07:56:32,911: ============================================================
2022-04-04 07:57:09,891: time cost, forward:0.011352379586890882, backward:0.05790126802190365, data cost:0.3122783581850322 
2022-04-04 07:57:09,891: ============================================================
2022-04-04 07:57:09,892: Epoch 25/26 Batch 7500/7662 eta: 0:48:13.735019	Training Loss 1.2174 (1.2608)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-04-04 07:57:09,892: ============================================================
2022-04-04 07:57:48,195: time cost, forward:0.011337441603656443, backward:0.05791664431010097, data cost:0.3122882248775192 
2022-04-04 07:57:48,195: ============================================================
2022-04-04 07:57:48,195: Epoch 25/26 Batch 7600/7662 eta: 0:49:18.946273	Training Loss 1.2918 (1.2618)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-04-04 07:57:48,195: ============================================================
2022-04-04 07:58:13,469: Epoch: 25/26 eta: 0:48:54.815060	Training Loss 1.2924 (1.2624)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.993)
2022-04-04 07:58:13,469: ============================================================
2022-04-04 07:58:13,606: Save Checkpoint...
2022-04-04 07:58:13,615: ============================================================
2022-04-04 07:58:16,829: Save done!
2022-04-04 07:58:16,829: ============================================================
2022-04-04 07:59:12,992: time cost, forward:0.010938393949258208, backward:0.05715360063495058, data cost:0.4953627321455214 
2022-04-04 07:59:12,992: ============================================================
2022-04-04 07:59:12,992: Epoch 26/26 Batch 100/7662 eta: 1:10:42.234318	Training Loss 1.0624 (1.1483)	Training Prec@1 100.000 (99.986)	Training Prec@5 100.000 (99.998)	
2022-04-04 07:59:12,993: ============================================================
2022-04-04 07:59:48,579: time cost, forward:0.01060348539496187, backward:0.05777985366744612, data cost:0.3904376197699925 
2022-04-04 07:59:48,579: ============================================================
2022-04-04 07:59:48,579: Epoch 26/26 Batch 200/7662 eta: 0:44:15.855453	Training Loss 1.3084 (1.1495)	Training Prec@1 100.000 (99.986)	Training Prec@5 100.000 (99.998)	
2022-04-04 07:59:48,579: ============================================================
2022-04-04 08:00:25,164: time cost, forward:0.010614238853837336, backward:0.05794614692994185, data cost:0.35880184014106675 
2022-04-04 08:00:25,165: ============================================================
2022-04-04 08:00:25,165: Epoch 26/26 Batch 300/7662 eta: 0:44:53.800003	Training Loss 1.1165 (1.1494)	Training Prec@1 100.000 (99.982)	Training Prec@5 100.000 (99.995)	
2022-04-04 08:00:25,165: ============================================================
2022-04-04 08:01:02,160: time cost, forward:0.010815411880799104, backward:0.057807498109669314, data cost:0.34431136520882893 
2022-04-04 08:01:02,160: ============================================================
2022-04-04 08:01:02,160: Epoch 26/26 Batch 400/7662 eta: 0:44:46.985907	Training Loss 1.1543 (1.1517)	Training Prec@1 100.000 (99.983)	Training Prec@5 100.000 (99.996)	
2022-04-04 08:01:02,161: ============================================================
2022-04-04 08:01:39,030: time cost, forward:0.010767901827672679, backward:0.05788325307842247, data cost:0.33540402911230177 
2022-04-04 08:01:39,031: ============================================================
2022-04-04 08:01:39,031: Epoch 26/26 Batch 500/7662 eta: 0:44:01.024614	Training Loss 1.1807 (1.1544)	Training Prec@1 100.000 (99.982)	Training Prec@5 100.000 (99.996)	
2022-04-04 08:01:39,031: ============================================================
2022-04-04 08:02:16,197: time cost, forward:0.010680001645733, backward:0.05802533940998262, data cost:0.3297792209408717 
2022-04-04 08:02:16,197: ============================================================
2022-04-04 08:02:16,197: Epoch 26/26 Batch 600/7662 eta: 0:43:45.064580	Training Loss 1.1167 (1.1579)	Training Prec@1 100.000 (99.982)	Training Prec@5 100.000 (99.996)	
2022-04-04 08:02:16,197: ============================================================
2022-04-04 08:02:53,066: time cost, forward:0.010662785927113545, backward:0.058024512169528246, data cost:0.32549401448349413 
2022-04-04 08:02:53,066: ============================================================
2022-04-04 08:02:53,066: Epoch 26/26 Batch 700/7662 eta: 0:42:47.190127	Training Loss 1.2303 (1.1606)	Training Prec@1 100.000 (99.982)	Training Prec@5 100.000 (99.996)	
2022-04-04 08:02:53,067: ============================================================
2022-04-04 08:03:30,318: time cost, forward:0.010647013429109385, backward:0.05806585605511528, data cost:0.3226415481376409 
2022-04-04 08:03:30,319: ============================================================
2022-04-04 08:03:30,319: Epoch 26/26 Batch 800/7662 eta: 0:42:36.652660	Training Loss 1.2324 (1.1639)	Training Prec@1 100.000 (99.983)	Training Prec@5 100.000 (99.996)	
2022-04-04 08:03:30,319: ============================================================
2022-04-04 08:04:08,032: time cost, forward:0.0106413263632803, backward:0.0580893220572636, data cost:0.32101947314481977 
2022-04-04 08:04:08,033: ============================================================
2022-04-04 08:04:08,033: Epoch 26/26 Batch 900/7662 eta: 0:42:30.600351	Training Loss 1.2150 (1.1655)	Training Prec@1 100.000 (99.984)	Training Prec@5 100.000 (99.996)	
2022-04-04 08:04:08,033: ============================================================
2022-04-04 08:04:46,040: time cost, forward:0.010827468083546803, backward:0.05787647474516142, data cost:0.31994316384599014 
2022-04-04 08:04:46,041: ============================================================
2022-04-04 08:04:46,041: Epoch 26/26 Batch 1000/7662 eta: 0:42:12.474892	Training Loss 1.0988 (1.1683)	Training Prec@1 100.000 (99.984)	Training Prec@5 100.000 (99.996)	
2022-04-04 08:04:46,041: ============================================================
2022-04-04 08:05:24,787: time cost, forward:0.010828110605505405, backward:0.05788184730869949, data cost:0.31976658675321346 
2022-04-04 08:05:24,787: ============================================================
2022-04-04 08:05:24,787: Epoch 26/26 Batch 1100/7662 eta: 0:42:22.901955	Training Loss 1.2151 (1.1700)	Training Prec@1 99.805 (99.983)	Training Prec@5 99.805 (99.996)	
2022-04-04 08:05:24,787: ============================================================
2022-04-04 08:06:04,404: time cost, forward:0.01080036640564932, backward:0.05790463181910065, data cost:0.32043689842319567 
2022-04-04 08:06:04,404: ============================================================
2022-04-04 08:06:04,404: Epoch 26/26 Batch 1200/7662 eta: 0:42:40.454745	Training Loss 1.1117 (1.1726)	Training Prec@1 100.000 (99.983)	Training Prec@5 100.000 (99.996)	
2022-04-04 08:06:04,404: ============================================================
2022-04-04 08:06:43,481: time cost, forward:0.010803270193133747, backward:0.057876995474306595, data cost:0.320513699768689 
2022-04-04 08:06:43,481: ============================================================
2022-04-04 08:06:43,482: Epoch 26/26 Batch 1300/7662 eta: 0:41:26.494626	Training Loss 1.2748 (1.1743)	Training Prec@1 99.805 (99.982)	Training Prec@5 100.000 (99.996)	
2022-04-04 08:06:43,482: ============================================================
2022-04-04 08:07:22,828: time cost, forward:0.010774132862868184, backward:0.057908779727807634, data cost:0.3207971850320899 
2022-04-04 08:07:22,829: ============================================================
2022-04-04 08:07:22,829: Epoch 26/26 Batch 1400/7662 eta: 0:41:04.314489	Training Loss 1.1226 (1.1772)	Training Prec@1 100.000 (99.982)	Training Prec@5 100.000 (99.996)	
2022-04-04 08:07:22,829: ============================================================
2022-04-04 08:08:00,082: time cost, forward:0.010723361657252703, backward:0.05795350481940557, data cost:0.3196342738967804 
2022-04-04 08:08:00,082: ============================================================
2022-04-04 08:08:00,082: Epoch 26/26 Batch 1500/7662 eta: 0:38:15.941947	Training Loss 1.1532 (1.1792)	Training Prec@1 100.000 (99.982)	Training Prec@5 100.000 (99.996)	
2022-04-04 08:08:00,083: ============================================================
2022-04-04 08:08:38,727: time cost, forward:0.010691677800859042, backward:0.05799741339430055, data cost:0.3193743309428947 
2022-04-04 08:08:38,727: ============================================================
2022-04-04 08:08:38,727: Epoch 26/26 Batch 1600/7662 eta: 0:39:03.036664	Training Loss 1.1652 (1.1808)	Training Prec@1 100.000 (99.982)	Training Prec@5 100.000 (99.996)	
2022-04-04 08:08:38,728: ============================================================
2022-04-04 08:09:16,498: time cost, forward:0.010646160102157189, backward:0.05807215736640629, data cost:0.3187952657669274 
2022-04-04 08:09:16,499: ============================================================
2022-04-04 08:09:16,499: Epoch 26/26 Batch 1700/7662 eta: 0:37:32.327233	Training Loss 1.1795 (1.1823)	Training Prec@1 100.000 (99.982)	Training Prec@5 100.000 (99.996)	
2022-04-04 08:09:16,499: ============================================================
2022-04-04 08:09:54,543: time cost, forward:0.010601904340556358, backward:0.05813971395423639, data cost:0.31833312576383005 
2022-04-04 08:09:54,544: ============================================================
2022-04-04 08:09:54,544: Epoch 26/26 Batch 1800/7662 eta: 0:37:10.569534	Training Loss 1.2480 (1.1844)	Training Prec@1 100.000 (99.982)	Training Prec@5 100.000 (99.996)	
2022-04-04 08:09:54,544: ============================================================
2022-04-04 08:10:33,268: time cost, forward:0.010574847789360638, backward:0.05818636797804026, data cost:0.3182424730599209 
2022-04-04 08:10:33,268: ============================================================
2022-04-04 08:10:33,268: Epoch 26/26 Batch 1900/7662 eta: 0:37:11.684797	Training Loss 1.1983 (1.1858)	Training Prec@1 100.000 (99.982)	Training Prec@5 100.000 (99.996)	
2022-04-04 08:10:33,268: ============================================================
2022-04-04 08:11:10,094: time cost, forward:0.010549524893099932, backward:0.058227535126625506, data cost:0.3173368537706277 
2022-04-04 08:11:10,095: ============================================================
2022-04-04 08:11:10,095: Epoch 26/26 Batch 2000/7662 eta: 0:34:45.487810	Training Loss 1.1885 (1.1879)	Training Prec@1 100.000 (99.982)	Training Prec@5 100.000 (99.996)	
2022-04-04 08:11:10,095: ============================================================
2022-04-04 08:11:47,967: time cost, forward:0.010522230515427791, backward:0.05826061370544288, data cost:0.3169575710987238 
2022-04-04 08:11:47,967: ============================================================
2022-04-04 08:11:47,967: Epoch 26/26 Batch 2100/7662 eta: 0:35:06.845355	Training Loss 1.2828 (1.1898)	Training Prec@1 100.000 (99.982)	Training Prec@5 100.000 (99.996)	
2022-04-04 08:11:47,967: ============================================================
2022-04-04 08:12:25,663: time cost, forward:0.010504041709049878, backward:0.058305410972341945, data cost:0.3165065697942771 
2022-04-04 08:12:25,663: ============================================================
2022-04-04 08:12:25,663: Epoch 26/26 Batch 2200/7662 eta: 0:34:19.337526	Training Loss 1.2489 (1.1916)	Training Prec@1 99.805 (99.982)	Training Prec@5 100.000 (99.996)	
2022-04-04 08:12:25,664: ============================================================
2022-04-04 08:13:03,802: time cost, forward:0.010490612550215288, backward:0.05834160705606229, data cost:0.31628492833635713 
2022-04-04 08:13:03,803: ============================================================
2022-04-04 08:13:03,803: Epoch 26/26 Batch 2300/7662 eta: 0:34:05.412557	Training Loss 1.1909 (1.1930)	Training Prec@1 100.000 (99.982)	Training Prec@5 100.000 (99.996)	
2022-04-04 08:13:03,803: ============================================================
2022-04-04 08:13:41,915: time cost, forward:0.010471386231696323, backward:0.05837627657754762, data cost:0.3161053301742446 
2022-04-04 08:13:41,916: ============================================================
2022-04-04 08:13:41,916: Epoch 26/26 Batch 2400/7662 eta: 0:33:25.906509	Training Loss 1.1817 (1.1945)	Training Prec@1 100.000 (99.982)	Training Prec@5 100.000 (99.995)	
2022-04-04 08:13:41,916: ============================================================
2022-04-04 08:14:20,116: time cost, forward:0.010456247108370936, backward:0.058415762087305624, data cost:0.3159090541467136 
2022-04-04 08:14:20,116: ============================================================
2022-04-04 08:14:20,116: Epoch 26/26 Batch 2500/7662 eta: 0:32:52.277647	Training Loss 1.4337 (1.1957)	Training Prec@1 99.805 (99.982)	Training Prec@5 100.000 (99.995)	
2022-04-04 08:14:20,116: ============================================================
2022-04-04 08:14:58,876: time cost, forward:0.010439641019755853, backward:0.058436574546957804, data cost:0.3160100616185011 
2022-04-04 08:14:58,877: ============================================================
2022-04-04 08:14:58,877: Epoch 26/26 Batch 2600/7662 eta: 0:32:42.442845	Training Loss 1.2797 (1.1972)	Training Prec@1 100.000 (99.982)	Training Prec@5 100.000 (99.995)	
2022-04-04 08:14:58,877: ============================================================
2022-04-04 08:15:37,873: time cost, forward:0.010425139109529183, backward:0.05847365231635881, data cost:0.3161682927992751 
2022-04-04 08:15:37,874: ============================================================
2022-04-04 08:15:37,874: Epoch 26/26 Batch 2700/7662 eta: 0:32:15.424197	Training Loss 1.2293 (1.1987)	Training Prec@1 100.000 (99.982)	Training Prec@5 100.000 (99.995)	
2022-04-04 08:15:37,874: ============================================================
2022-04-04 08:16:16,615: time cost, forward:0.010409726718358799, backward:0.058510204773794205, data cost:0.31618830287997407 
2022-04-04 08:16:16,615: ============================================================
2022-04-04 08:16:16,615: Epoch 26/26 Batch 2800/7662 eta: 0:31:23.996543	Training Loss 1.3315 (1.2004)	Training Prec@1 100.000 (99.982)	Training Prec@5 100.000 (99.995)	
2022-04-04 08:16:16,615: ============================================================
2022-04-04 08:16:55,729: time cost, forward:0.010393729494456053, backward:0.05853956294248909, data cost:0.31638731632449785 
2022-04-04 08:16:55,729: ============================================================
2022-04-04 08:16:55,730: Epoch 26/26 Batch 2900/7662 eta: 0:31:03.014223	Training Loss 1.1983 (1.2020)	Training Prec@1 100.000 (99.982)	Training Prec@5 100.000 (99.995)	
2022-04-04 08:16:55,730: ============================================================
2022-04-04 08:17:34,682: time cost, forward:0.010384576644210587, backward:0.05856257782414898, data cost:0.316494641442345 
2022-04-04 08:17:34,682: ============================================================
2022-04-04 08:17:34,683: Epoch 26/26 Batch 3000/7662 eta: 0:30:16.374502	Training Loss 1.2407 (1.2034)	Training Prec@1 100.000 (99.982)	Training Prec@5 100.000 (99.995)	
2022-04-04 08:17:34,683: ============================================================
2022-04-04 08:18:12,461: time cost, forward:0.0103814227998776, backward:0.05857851690690569, data cost:0.31623104065608576 
2022-04-04 08:18:12,462: ============================================================
2022-04-04 08:18:12,462: Epoch 26/26 Batch 3100/7662 eta: 0:28:43.869752	Training Loss 1.2877 (1.2047)	Training Prec@1 100.000 (99.982)	Training Prec@5 100.000 (99.995)	
2022-04-04 08:18:12,462: ============================================================
2022-04-04 08:18:51,347: time cost, forward:0.010376707171231144, backward:0.0585843029153388, data cost:0.3163114515234806 
2022-04-04 08:18:51,348: ============================================================
2022-04-04 08:18:51,348: Epoch 26/26 Batch 3200/7662 eta: 0:28:55.499382	Training Loss 1.3381 (1.2064)	Training Prec@1 100.000 (99.981)	Training Prec@5 100.000 (99.995)	
2022-04-04 08:18:51,349: ============================================================
2022-04-04 08:19:29,033: time cost, forward:0.010360265869413516, backward:0.05860433588609004, data cost:0.31603465719127627 
2022-04-04 08:19:29,034: ============================================================
2022-04-04 08:19:29,034: Epoch 26/26 Batch 3300/7662 eta: 0:27:24.222875	Training Loss 1.1125 (1.2078)	Training Prec@1 100.000 (99.981)	Training Prec@5 100.000 (99.995)	
2022-04-04 08:19:29,034: ============================================================
2022-04-04 08:20:07,547: time cost, forward:0.010346874134370108, backward:0.058628199625871014, data cost:0.3160175623420969 
2022-04-04 08:20:07,547: ============================================================
2022-04-04 08:20:07,548: Epoch 26/26 Batch 3400/7662 eta: 0:27:21.842579	Training Loss 1.1799 (1.2093)	Training Prec@1 100.000 (99.981)	Training Prec@5 100.000 (99.995)	
2022-04-04 08:20:07,548: ============================================================
2022-04-04 08:20:45,086: time cost, forward:0.010335430140902772, backward:0.05865006877477253, data cost:0.3157296855301815 
2022-04-04 08:20:45,087: ============================================================
2022-04-04 08:20:45,087: Epoch 26/26 Batch 3500/7662 eta: 0:26:02.760502	Training Loss 1.2380 (1.2104)	Training Prec@1 99.805 (99.981)	Training Prec@5 100.000 (99.994)	
2022-04-04 08:20:45,087: ============================================================
2022-04-04 08:21:22,023: time cost, forward:0.010328010043424844, backward:0.05867959579251547, data cost:0.3152418416153891 
2022-04-04 08:21:22,023: ============================================================
2022-04-04 08:21:22,023: Epoch 26/26 Batch 3600/7662 eta: 0:25:00.721638	Training Loss 1.2172 (1.2118)	Training Prec@1 100.000 (99.981)	Training Prec@5 100.000 (99.994)	
2022-04-04 08:21:22,023: ============================================================
2022-04-04 08:21:58,879: time cost, forward:0.01032426854216366, backward:0.05869413098956353, data cost:0.31481415054288286 
2022-04-04 08:21:58,879: ============================================================
2022-04-04 08:21:58,879: Epoch 26/26 Batch 3700/7662 eta: 0:24:20.610837	Training Loss 1.2941 (1.2132)	Training Prec@1 100.000 (99.981)	Training Prec@5 100.000 (99.995)	
2022-04-04 08:21:58,880: ============================================================
2022-04-04 08:22:37,866: time cost, forward:0.010315895833665366, backward:0.058709177477606414, data cost:0.3149334690890271 
2022-04-04 08:22:37,866: ============================================================
2022-04-04 08:22:37,867: Epoch 26/26 Batch 3800/7662 eta: 0:25:06.074929	Training Loss 1.2573 (1.2145)	Training Prec@1 99.805 (99.980)	Training Prec@5 100.000 (99.994)	
2022-04-04 08:22:37,867: ============================================================
2022-04-04 08:23:14,656: time cost, forward:0.010308743746166322, backward:0.05872062482293308, data cost:0.31450653314651605 
2022-04-04 08:23:14,657: ============================================================
2022-04-04 08:23:14,657: Epoch 26/26 Batch 3900/7662 eta: 0:23:04.412561	Training Loss 1.4526 (1.2162)	Training Prec@1 100.000 (99.980)	Training Prec@5 100.000 (99.994)	
2022-04-04 08:23:14,657: ============================================================
2022-04-04 08:23:52,527: time cost, forward:0.010298015893057127, backward:0.05873203128539017, data cost:0.3143874639628917 
2022-04-04 08:23:52,528: ============================================================
2022-04-04 08:23:52,528: Epoch 26/26 Batch 4000/7662 eta: 0:23:07.225028	Training Loss 1.1885 (1.2176)	Training Prec@1 100.000 (99.980)	Training Prec@5 100.000 (99.994)	
2022-04-04 08:23:52,528: ============================================================
2022-04-04 08:24:30,222: time cost, forward:0.010290104402335977, backward:0.058753692048094455, data cost:0.31419593265912216 
2022-04-04 08:24:30,223: ============================================================
2022-04-04 08:24:30,223: Epoch 26/26 Batch 4100/7662 eta: 0:22:23.061923	Training Loss 1.1675 (1.2187)	Training Prec@1 99.805 (99.980)	Training Prec@5 100.000 (99.994)	
2022-04-04 08:24:30,223: ============================================================
2022-04-04 08:25:07,529: time cost, forward:0.010280038436613471, backward:0.05877035406266658, data cost:0.31392910429965204 
2022-04-04 08:25:07,529: ============================================================
2022-04-04 08:25:07,530: Epoch 26/26 Batch 4200/7662 eta: 0:21:31.936685	Training Loss 1.1176 (1.2198)	Training Prec@1 100.000 (99.980)	Training Prec@5 100.000 (99.994)	
2022-04-04 08:25:07,530: ============================================================
2022-04-04 08:25:44,656: time cost, forward:0.010269477828266066, backward:0.05878287998846338, data cost:0.3136561716620549 
2022-04-04 08:25:44,656: ============================================================
2022-04-04 08:25:44,657: Epoch 26/26 Batch 4300/7662 eta: 0:20:48.580099	Training Loss 1.2476 (1.2209)	Training Prec@1 100.000 (99.980)	Training Prec@5 100.000 (99.994)	
2022-04-04 08:25:44,657: ============================================================
2022-04-04 08:26:22,059: time cost, forward:0.01026089897641379, backward:0.05880522787584503, data cost:0.31342584167076365 
2022-04-04 08:26:22,059: ============================================================
2022-04-04 08:26:22,059: Epoch 26/26 Batch 4400/7662 eta: 0:20:20.452729	Training Loss 1.1303 (1.2219)	Training Prec@1 100.000 (99.980)	Training Prec@5 100.000 (99.994)	
2022-04-04 08:26:22,059: ============================================================
2022-04-04 08:27:01,182: time cost, forward:0.010258190683270328, backward:0.05881258232589827, data cost:0.31361394973563256 
2022-04-04 08:27:01,182: ============================================================
2022-04-04 08:27:01,182: Epoch 26/26 Batch 4500/7662 eta: 0:20:37.455578	Training Loss 1.2925 (1.2233)	Training Prec@1 99.805 (99.980)	Training Prec@5 99.805 (99.995)	
2022-04-04 08:27:01,182: ============================================================
2022-04-04 08:27:39,285: time cost, forward:0.010254240212271488, backward:0.05881772147077248, data cost:0.31355244083284267 
2022-04-04 08:27:39,285: ============================================================
2022-04-04 08:27:39,285: Epoch 26/26 Batch 4600/7662 eta: 0:19:27.100306	Training Loss 1.3994 (1.2245)	Training Prec@1 99.609 (99.980)	Training Prec@5 100.000 (99.995)	
2022-04-04 08:27:39,286: ============================================================
2022-04-04 08:28:15,747: time cost, forward:0.010252104233772, backward:0.05882801495097652, data cost:0.3131635889750284 
2022-04-04 08:28:15,747: ============================================================
2022-04-04 08:28:15,747: Epoch 26/26 Batch 4700/7662 eta: 0:18:00.367686	Training Loss 1.2141 (1.2258)	Training Prec@1 99.805 (99.979)	Training Prec@5 100.000 (99.994)	
2022-04-04 08:28:15,747: ============================================================
2022-04-04 08:28:55,106: time cost, forward:0.010249837584037486, backward:0.058829561971977216, data cost:0.31338806305360883 
2022-04-04 08:28:55,106: ============================================================
2022-04-04 08:28:55,106: Epoch 26/26 Batch 4800/7662 eta: 0:18:46.846476	Training Loss 1.3559 (1.2271)	Training Prec@1 100.000 (99.979)	Training Prec@5 100.000 (99.994)	
2022-04-04 08:28:55,106: ============================================================
2022-04-04 08:29:34,069: time cost, forward:0.010249055388217606, backward:0.058832065892185474, data cost:0.31351600838914456 
2022-04-04 08:29:34,070: ============================================================
2022-04-04 08:29:34,070: Epoch 26/26 Batch 4900/7662 eta: 0:17:56.565037	Training Loss 1.3225 (1.2282)	Training Prec@1 100.000 (99.979)	Training Prec@5 100.000 (99.994)	
2022-04-04 08:29:34,070: ============================================================
2022-04-04 08:30:12,688: time cost, forward:0.01024900915432415, backward:0.05883480067442932, data cost:0.3135829207944403 
2022-04-04 08:30:12,688: ============================================================
2022-04-04 08:30:12,688: Epoch 26/26 Batch 5000/7662 eta: 0:17:08.411944	Training Loss 1.4124 (1.2292)	Training Prec@1 99.805 (99.979)	Training Prec@5 99.805 (99.994)	
2022-04-04 08:30:12,689: ============================================================
2022-04-04 08:30:50,667: time cost, forward:0.010258560672557267, backward:0.05882962003925964, data cost:0.31348842053956716 
2022-04-04 08:30:50,667: ============================================================
2022-04-04 08:30:50,668: Epoch 26/26 Batch 5100/7662 eta: 0:16:13.402145	Training Loss 1.2260 (1.2305)	Training Prec@1 100.000 (99.979)	Training Prec@5 100.000 (99.994)	
2022-04-04 08:30:50,668: ============================================================
2022-04-04 08:31:28,829: time cost, forward:0.0102590014095787, backward:0.058835243486307934, data cost:0.31346957448308893 
2022-04-04 08:31:28,829: ============================================================
2022-04-04 08:31:28,829: Epoch 26/26 Batch 5200/7662 eta: 0:15:39.920669	Training Loss 1.2979 (1.2315)	Training Prec@1 100.000 (99.979)	Training Prec@5 100.000 (99.994)	
2022-04-04 08:31:28,829: ============================================================
2022-04-04 08:32:07,524: time cost, forward:0.010257451843374022, backward:0.05884794847855907, data cost:0.31353846638354294 
2022-04-04 08:32:07,524: ============================================================
2022-04-04 08:32:07,525: Epoch 26/26 Batch 5300/7662 eta: 0:15:14.375040	Training Loss 1.4315 (1.2328)	Training Prec@1 100.000 (99.979)	Training Prec@5 100.000 (99.994)	
2022-04-04 08:32:07,525: ============================================================
2022-04-04 08:32:45,792: time cost, forward:0.010255711015495333, backward:0.05885438460689007, data cost:0.31352266065940565 
2022-04-04 08:32:45,792: ============================================================
2022-04-04 08:32:45,792: Epoch 26/26 Batch 5400/7662 eta: 0:14:25.994484	Training Loss 1.3114 (1.2341)	Training Prec@1 100.000 (99.979)	Training Prec@5 100.000 (99.995)	
2022-04-04 08:32:45,792: ============================================================
2022-04-04 08:33:23,732: time cost, forward:0.0102518855669126, backward:0.058869051790211416, data cost:0.3134518058153906 
2022-04-04 08:33:23,733: ============================================================
2022-04-04 08:33:23,733: Epoch 26/26 Batch 5500/7662 eta: 0:13:40.658539	Training Loss 1.2084 (1.2354)	Training Prec@1 100.000 (99.979)	Training Prec@5 100.000 (99.994)	
2022-04-04 08:33:23,733: ============================================================
2022-04-04 08:34:02,442: time cost, forward:0.010250164325970968, backward:0.0588802256995513, data cost:0.313519171932634 
2022-04-04 08:34:02,443: ============================================================
2022-04-04 08:34:02,443: Epoch 26/26 Batch 5600/7662 eta: 0:13:18.585791	Training Loss 1.3286 (1.2367)	Training Prec@1 99.805 (99.978)	Training Prec@5 100.000 (99.994)	
2022-04-04 08:34:02,443: ============================================================
2022-04-04 08:34:40,269: time cost, forward:0.010242820601857406, backward:0.05888854639428522, data cost:0.31341717640210254 
2022-04-04 08:34:40,269: ============================================================
2022-04-04 08:34:40,270: Epoch 26/26 Batch 5700/7662 eta: 0:12:22.535827	Training Loss 1.3066 (1.2378)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.994)	
2022-04-04 08:34:40,270: ============================================================
2022-04-04 08:35:18,091: time cost, forward:0.010242226782040793, backward:0.05889361725734994, data cost:0.3133345193381062 
2022-04-04 08:35:18,091: ============================================================
2022-04-04 08:35:18,091: Epoch 26/26 Batch 5800/7662 eta: 0:11:44.619925	Training Loss 1.3374 (1.2391)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.994)	
2022-04-04 08:35:18,091: ============================================================
2022-04-04 08:35:58,300: time cost, forward:0.010242726847688552, backward:0.05888917232331714, data cost:0.3136617976096671 
2022-04-04 08:35:58,300: ============================================================
2022-04-04 08:35:58,300: Epoch 26/26 Batch 5900/7662 eta: 0:11:48.886244	Training Loss 1.2938 (1.2404)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.994)	
2022-04-04 08:35:58,301: ============================================================
2022-04-04 08:36:35,621: time cost, forward:0.010301535557579808, backward:0.05883216583683086, data cost:0.3134868472074346 
2022-04-04 08:36:35,621: ============================================================
2022-04-04 08:36:35,621: Epoch 26/26 Batch 6000/7662 eta: 0:10:20.646249	Training Loss 1.2284 (1.2416)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.994)	
2022-04-04 08:36:35,621: ============================================================
2022-04-04 08:37:13,631: time cost, forward:0.010299170558658617, backward:0.05883783405971324, data cost:0.3134328964441052 
2022-04-04 08:37:13,631: ============================================================
2022-04-04 08:37:13,631: Epoch 26/26 Batch 6100/7662 eta: 0:09:54.095439	Training Loss 1.2836 (1.2425)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.994)	
2022-04-04 08:37:13,631: ============================================================
2022-04-04 08:37:51,779: time cost, forward:0.010296758556965956, backward:0.058839542209227096, data cost:0.3134154798061853 
2022-04-04 08:37:51,779: ============================================================
2022-04-04 08:37:51,780: Epoch 26/26 Batch 6200/7662 eta: 0:09:18.110950	Training Loss 1.2387 (1.2435)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.995)	
2022-04-04 08:37:51,780: ============================================================
2022-04-04 08:38:31,023: time cost, forward:0.010298816074093366, backward:0.058845166611962894, data cost:0.3135299679967672 
2022-04-04 08:38:31,023: ============================================================
2022-04-04 08:38:31,024: Epoch 26/26 Batch 6300/7662 eta: 0:08:54.895021	Training Loss 1.2279 (1.2447)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.994)	
2022-04-04 08:38:31,024: ============================================================
2022-04-04 08:39:09,990: time cost, forward:0.010300456778968493, backward:0.0588517235971872, data cost:0.3136464600861864 
2022-04-04 08:39:09,990: ============================================================
2022-04-04 08:39:09,991: Epoch 26/26 Batch 6400/7662 eta: 0:08:12.154878	Training Loss 1.4540 (1.2456)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.995)	
2022-04-04 08:39:09,991: ============================================================
2022-04-04 08:39:47,405: time cost, forward:0.010297664185086843, backward:0.05885360053473756, data cost:0.3135131614944498 
2022-04-04 08:39:47,406: ============================================================
2022-04-04 08:39:47,406: Epoch 26/26 Batch 6500/7662 eta: 0:07:15.140595	Training Loss 1.3054 (1.2465)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.995)	
2022-04-04 08:39:47,406: ============================================================
2022-04-04 08:40:24,842: time cost, forward:0.010294434915511675, backward:0.05885857407803571, data cost:0.3133771133018201 
2022-04-04 08:40:24,842: ============================================================
2022-04-04 08:40:24,842: Epoch 26/26 Batch 6600/7662 eta: 0:06:37.947824	Training Loss 1.1860 (1.2476)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.995)	
2022-04-04 08:40:24,843: ============================================================
2022-04-04 08:41:02,623: time cost, forward:0.010291610409704888, backward:0.058868152808032655, data cost:0.3132952203108564 
2022-04-04 08:41:02,624: ============================================================
2022-04-04 08:41:02,624: Epoch 26/26 Batch 6700/7662 eta: 0:06:03.837632	Training Loss 1.3454 (1.2487)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-04-04 08:41:02,624: ============================================================
2022-04-04 08:41:42,071: time cost, forward:0.010289340461767988, backward:0.058876394822257705, data cost:0.31344557211738877 
2022-04-04 08:41:42,071: ============================================================
2022-04-04 08:41:42,072: Epoch 26/26 Batch 6800/7662 eta: 0:05:40.433976	Training Loss 1.3437 (1.2497)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-04-04 08:41:42,072: ============================================================
2022-04-04 08:42:20,721: time cost, forward:0.010289998897038815, backward:0.058882823040872785, data cost:0.313500336243253 
2022-04-04 08:42:20,721: ============================================================
2022-04-04 08:42:20,722: Epoch 26/26 Batch 6900/7662 eta: 0:04:54.897656	Training Loss 1.3739 (1.2507)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-04-04 08:42:20,722: ============================================================
2022-04-04 08:42:58,461: time cost, forward:0.010285453977610728, backward:0.058887540621320796, data cost:0.3134118058474034 
2022-04-04 08:42:58,462: ============================================================
2022-04-04 08:42:58,462: Epoch 26/26 Batch 7000/7662 eta: 0:04:10.218924	Training Loss 1.3855 (1.2519)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-04-04 08:42:58,462: ============================================================
2022-04-04 08:43:36,701: time cost, forward:0.01031264981378517, backward:0.058865353765244516, data cost:0.31339838646183316 
2022-04-04 08:43:36,701: ============================================================
2022-04-04 08:43:36,701: Epoch 26/26 Batch 7100/7662 eta: 0:03:35.287030	Training Loss 1.4842 (1.2530)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-04-04 08:43:36,701: ============================================================
2022-04-04 08:44:13,425: time cost, forward:0.01031006798344795, backward:0.058871147615708545, data cost:0.3131735158605797 
2022-04-04 08:44:13,426: ============================================================
2022-04-04 08:44:13,426: Epoch 26/26 Batch 7200/7662 eta: 0:02:50.037149	Training Loss 1.4168 (1.2541)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-04-04 08:44:13,427: ============================================================
2022-04-04 08:44:52,545: time cost, forward:0.010303724888400324, backward:0.058877085182565195, data cost:0.313278504145735 
2022-04-04 08:44:52,545: ============================================================
2022-04-04 08:44:52,545: Epoch 26/26 Batch 7300/7662 eta: 0:02:22.001169	Training Loss 1.4065 (1.2553)	Training Prec@1 99.805 (99.976)	Training Prec@5 99.805 (99.994)	
2022-04-04 08:44:52,545: ============================================================
2022-04-04 08:45:30,099: time cost, forward:0.010298529159766562, backward:0.05888454278331622, data cost:0.3131911715618226 
2022-04-04 08:45:30,100: ============================================================
2022-04-04 08:45:30,100: Epoch 26/26 Batch 7400/7662 eta: 0:01:38.769428	Training Loss 1.3915 (1.2563)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-04-04 08:45:30,100: ============================================================
2022-04-04 08:46:08,646: time cost, forward:0.01029074444804514, backward:0.05889161912134956, data cost:0.31322154284699916 
2022-04-04 08:46:08,646: ============================================================
2022-04-04 08:46:08,646: Epoch 26/26 Batch 7500/7662 eta: 0:01:02.830539	Training Loss 1.3757 (1.2574)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-04-04 08:46:08,647: ============================================================
2022-04-04 08:46:47,251: time cost, forward:0.01028168987390132, backward:0.05889189953960264, data cost:0.31327602982222996 
2022-04-04 08:46:47,251: ============================================================
2022-04-04 08:46:47,251: Epoch 26/26 Batch 7600/7662 eta: 0:00:24.321226	Training Loss 1.3623 (1.2584)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-04-04 08:46:47,252: ============================================================
2022-04-04 08:47:12,454: Epoch: 26/26 eta: 0:00:00	Training Loss 1.4402 (1.2591)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)
2022-04-04 08:47:12,465: ============================================================
