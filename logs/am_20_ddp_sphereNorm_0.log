2022-03-25 23:36:35,635: [('name', 'amsoft-20'), ('backbone_model_name', 'SimpleResnet_20'), ('classify_model_name', 'MarginCosineProduct'), ('resume_net_model', None), ('resume_net_classifier', None), ('no_cuda', False), ('gpu_num', 2), ('log_interval', 100), ('log_path', './logs/am_20_ddp_sphereNorm.log'), ('log_pic_path', './logs/pic/am_20_ddp_sphereNorm/'), ('save_path', 'snapshot/am_20_ddp_sphereNorm/'), ('lmdb_path', '/home/ubuntu/data4/lk/data/lmdb_default'), ('batch_size', 512), ('datanum', 3923399), ('num_class', 86876), ('lmdb_workers', 4), ('num_workers', 4), ('start_epoch', 1), ('max_epoch', 38), ('lr', 0.1), ('base', 'epoch'), ('step_size', [10, 20, 30]), ('momentum', 0.9), ('gama', 0.1), ('weight_decay', 0.0005), ('rank', 0), ('dist_url', 'env://'), ('world_size', 2), ('gpu', 0), ('dist_backend', 'nccl'), ('distributed', True), ('master_port', 22345), ('multiprocessing_distributed', False), ('SEED', 1337), ('local_rank', 0)]
2022-03-25 23:36:35,638: SimpleResidualBackbone(
  (conv1): ConvPrelu(
    (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (prelu): PReLU(num_parameters=64)
  )
  (layer1): Sequential(
    (0): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=64)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=64)
      )
    )
  )
  (conv2): ConvPrelu(
    (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (prelu): PReLU(num_parameters=128)
  )
  (layer2): Sequential(
    (0): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
    )
    (1): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
    )
  )
  (conv3): ConvPrelu(
    (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (prelu): PReLU(num_parameters=256)
  )
  (layer3): Sequential(
    (0): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
    (1): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
    (2): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
    (3): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
  )
  (conv4): ConvPrelu(
    (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (prelu): PReLU(num_parameters=512)
  )
  (layer4): Sequential(
    (0): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=512)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=512)
      )
    )
  )
  (fc5): Linear(in_features=25088, out_features=512, bias=True)
)
2022-03-25 23:36:38,848: data balance
2022-03-25 23:38:04,917: time cost, forward:0.028672225547559334, backward:0.06025793817308214, data cost:0.7585438911360923 
2022-03-25 23:38:04,936: ============================================================
2022-03-25 23:38:04,938: Epoch 1/38 Batch 100/7662 eta: 2 days, 21:16:11.594323	Training Loss 22.2169 (22.4335)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.008)	
2022-03-25 23:38:04,938: ============================================================
2022-03-25 23:39:26,898: time cost, forward:0.024095480166487958, backward:0.052980528404964276, data cost:0.7568613236872994 
2022-03-25 23:39:26,899: ============================================================
2022-03-25 23:39:26,899: Epoch 1/38 Batch 200/7662 eta: 2 days, 18:14:35.601574	Training Loss 22.2439 (22.3479)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.009)	
2022-03-25 23:39:26,900: ============================================================
2022-03-25 23:40:50,609: time cost, forward:0.023239056003532283, backward:0.05051204911043811, data cost:0.7610484852041289 
2022-03-25 23:40:50,610: ============================================================
2022-03-25 23:40:50,610: Epoch 1/38 Batch 300/7662 eta: 2 days, 19:37:58.199186	Training Loss 22.2249 (22.3165)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.008)	
2022-03-25 23:40:50,610: ============================================================
2022-03-25 23:42:10,771: time cost, forward:0.02231654786227042, backward:0.04867470832098098, data cost:0.7540963903106842 
2022-03-25 23:42:10,793: ============================================================
2022-03-25 23:42:10,795: Epoch 1/38 Batch 400/7662 eta: 2 days, 16:45:41.146113	Training Loss 22.3314 (22.3069)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.010)	
2022-03-25 23:42:10,796: ============================================================
2022-03-25 23:43:32,198: time cost, forward:0.021682654210704123, backward:0.047637650866307814, data cost:0.7548202584406178 
2022-03-25 23:43:32,199: ============================================================
2022-03-25 23:43:32,199: Epoch 1/38 Batch 500/7662 eta: 2 days, 17:43:29.449959	Training Loss 22.3283 (22.3121)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.012)	
2022-03-25 23:43:32,200: ============================================================
2022-03-25 23:44:52,756: time cost, forward:0.02126307161105097, backward:0.046868883906700375, data cost:0.752726126592824 
2022-03-25 23:44:52,757: ============================================================
2022-03-25 23:44:52,757: Epoch 1/38 Batch 600/7662 eta: 2 days, 17:01:05.533222	Training Loss 22.3425 (22.3232)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.013)	
2022-03-25 23:44:52,757: ============================================================
2022-03-25 23:46:14,987: time cost, forward:0.021045745868710147, backward:0.04644925024717492, data cost:0.7533111633660967 
2022-03-25 23:46:15,017: ============================================================
2022-03-25 23:46:15,019: Epoch 1/38 Batch 700/7662 eta: 2 days, 18:22:13.386535	Training Loss 22.4205 (22.3373)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.014)	
2022-03-25 23:46:15,019: ============================================================
2022-03-25 23:47:36,110: time cost, forward:0.020825240430008336, backward:0.04605100629326697, data cost:0.7518579679376939 
2022-03-25 23:47:36,112: ============================================================
2022-03-25 23:47:36,113: Epoch 1/38 Batch 800/7662 eta: 2 days, 17:24:24.208975	Training Loss 22.2655 (22.3393)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.016)	
2022-03-25 23:47:36,114: ============================================================
2022-03-25 23:48:55,969: time cost, forward:0.0205101303847401, backward:0.045826317338444895, data cost:0.7506043088847193 
2022-03-25 23:48:55,969: ============================================================
2022-03-25 23:48:55,969: Epoch 1/38 Batch 900/7662 eta: 2 days, 16:23:08.962608	Training Loss 22.0182 (22.3182)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.027)	
2022-03-25 23:48:55,970: ============================================================
2022-03-25 23:50:19,846: time cost, forward:0.020398008692133294, backward:0.045380967754024164, data cost:0.7531218609891019 
2022-03-25 23:50:19,847: ============================================================
2022-03-25 23:50:19,848: Epoch 1/38 Batch 1000/7662 eta: 2 days, 19:36:19.048650	Training Loss 21.6939 (22.2728)	Training Prec@1 0.195 (0.011)	Training Prec@5 0.195 (0.045)	
2022-03-25 23:50:19,848: ============================================================
2022-03-25 23:51:40,570: time cost, forward:0.020123644456524974, backward:0.04494844858379555, data cost:0.7525667961995313 
2022-03-25 23:51:40,595: ============================================================
2022-03-25 23:51:40,595: Epoch 1/38 Batch 1100/7662 eta: 2 days, 17:03:32.880352	Training Loss 21.5837 (22.2077)	Training Prec@1 0.000 (0.021)	Training Prec@5 0.586 (0.077)	
2022-03-25 23:51:40,595: ============================================================
2022-03-25 23:53:00,164: time cost, forward:0.019963100614698855, backward:0.044740540072558024, data cost:0.7508108220168012 
2022-03-25 23:53:00,164: ============================================================
2022-03-25 23:53:00,165: Epoch 1/38 Batch 1200/7662 eta: 2 days, 16:05:17.554864	Training Loss 21.0872 (22.1305)	Training Prec@1 0.195 (0.040)	Training Prec@5 1.172 (0.126)	
2022-03-25 23:53:00,165: ============================================================
2022-03-25 23:54:18,486: time cost, forward:0.01982749765702997, backward:0.044631825491866305, data cost:0.7486831734417217 
2022-03-25 23:54:18,486: ============================================================
2022-03-25 23:54:18,487: Epoch 1/38 Batch 1300/7662 eta: 2 days, 15:03:41.899132	Training Loss 20.6875 (22.0415)	Training Prec@1 0.586 (0.069)	Training Prec@5 2.344 (0.206)	
2022-03-25 23:54:18,487: ============================================================
2022-03-25 23:55:38,319: time cost, forward:0.019794272047183273, backward:0.044456694618645015, data cost:0.7477398992351671 
2022-03-25 23:55:38,347: ============================================================
2022-03-25 23:55:38,349: Epoch 1/38 Batch 1400/7662 eta: 2 days, 16:16:43.419630	Training Loss 20.6515 (21.9429)	Training Prec@1 0.977 (0.115)	Training Prec@5 1.953 (0.330)	
2022-03-25 23:55:38,349: ============================================================
2022-03-25 23:56:58,482: time cost, forward:0.01972256715175229, backward:0.04439817801406178, data cost:0.7470294635561484 
2022-03-25 23:56:58,482: ============================================================
2022-03-25 23:56:58,482: Epoch 1/38 Batch 1500/7662 eta: 2 days, 16:28:35.149378	Training Loss 19.9605 (21.8356)	Training Prec@1 1.172 (0.180)	Training Prec@5 3.125 (0.500)	
2022-03-25 23:56:58,483: ============================================================
2022-03-25 23:58:16,896: time cost, forward:0.019566903791254652, backward:0.044154274978065136, data cost:0.7450695212294416 
2022-03-25 23:58:16,902: ============================================================
2022-03-25 23:58:16,903: Epoch 1/38 Batch 1600/7662 eta: 2 days, 15:04:31.046973	Training Loss 19.9371 (21.7195)	Training Prec@1 1.172 (0.288)	Training Prec@5 3.516 (0.738)	
2022-03-25 23:58:16,905: ============================================================
2022-03-25 23:59:33,094: time cost, forward:0.019412009978448733, backward:0.043842925963645966, data cost:0.7427583857800696 
2022-03-25 23:59:33,098: ============================================================
2022-03-25 23:59:33,099: Epoch 1/38 Batch 1700/7662 eta: 2 days, 13:15:53.469002	Training Loss 19.4069 (21.5956)	Training Prec@1 5.078 (0.447)	Training Prec@5 8.984 (1.078)	
2022-03-25 23:59:33,099: ============================================================
2022-03-26 00:00:50,537: time cost, forward:0.019341742747223598, backward:0.04374870543615098, data cost:0.7415551619770926 
2022-03-26 00:00:50,538: ============================================================
2022-03-26 00:00:50,538: Epoch 1/38 Batch 1800/7662 eta: 2 days, 14:14:37.302097	Training Loss 19.0093 (21.4633)	Training Prec@1 6.250 (0.669)	Training Prec@5 11.719 (1.529)	
2022-03-26 00:00:50,538: ============================================================
2022-03-26 00:02:11,477: time cost, forward:0.019346761979700203, backward:0.04367165429897218, data cost:0.7414064244134229 
2022-03-26 00:02:11,506: ============================================================
2022-03-26 00:02:11,508: Epoch 1/38 Batch 1900/7662 eta: 2 days, 17:03:27.937185	Training Loss 18.5963 (21.3220)	Training Prec@1 8.789 (0.972)	Training Prec@5 14.844 (2.091)	
2022-03-26 00:02:11,508: ============================================================
2022-03-26 00:03:30,181: time cost, forward:0.019267659595216615, backward:0.04348507113549756, data cost:0.7405491223509398 
2022-03-26 00:03:30,182: ============================================================
2022-03-26 00:03:30,183: Epoch 1/38 Batch 2000/7662 eta: 2 days, 15:11:36.055169	Training Loss 18.3683 (21.1718)	Training Prec@1 9.375 (1.360)	Training Prec@5 17.578 (2.791)	
2022-03-26 00:03:30,183: ============================================================
2022-03-26 00:04:50,200: time cost, forward:0.019177428309607357, backward:0.04332277478349385, data cost:0.7410102385802176 
2022-03-26 00:04:50,245: ============================================================
2022-03-26 00:04:50,246: Epoch 1/38 Batch 2100/7662 eta: 2 days, 16:17:07.711319	Training Loss 17.7999 (21.0124)	Training Prec@1 11.523 (1.865)	Training Prec@5 19.141 (3.626)	
2022-03-26 00:04:50,246: ============================================================
2022-03-26 00:06:09,792: time cost, forward:0.019087672070949496, backward:0.04323373593325613, data cost:0.7408534077526819 
2022-03-26 00:06:09,792: ============================================================
2022-03-26 00:06:09,793: Epoch 1/38 Batch 2200/7662 eta: 2 days, 15:50:56.892584	Training Loss 17.0138 (20.8451)	Training Prec@1 16.211 (2.488)	Training Prec@5 28.711 (4.610)	
2022-03-26 00:06:09,793: ============================================================
2022-03-26 00:07:26,695: time cost, forward:0.019028473750774422, backward:0.043097587086004294, data cost:0.7393149451205605 
2022-03-26 00:07:26,723: ============================================================
2022-03-26 00:07:26,723: Epoch 1/38 Batch 2300/7662 eta: 2 days, 13:43:37.954061	Training Loss 16.4139 (20.6676)	Training Prec@1 22.852 (3.231)	Training Prec@5 34.375 (5.735)	
2022-03-26 00:07:26,723: ============================================================
2022-03-26 00:08:44,563: time cost, forward:0.01901182834184781, backward:0.04306345663750455, data cost:0.7384225325367758 
2022-03-26 00:08:44,566: ============================================================
2022-03-26 00:08:44,568: Epoch 1/38 Batch 2400/7662 eta: 2 days, 14:26:20.733948	Training Loss 15.7026 (20.4817)	Training Prec@1 27.539 (4.120)	Training Prec@5 39.648 (6.994)	
2022-03-26 00:08:44,568: ============================================================
2022-03-26 00:10:06,201: time cost, forward:0.01903178702358629, backward:0.0430582908212113, data cost:0.7389787912082557 
2022-03-26 00:10:06,229: ============================================================
2022-03-26 00:10:06,231: Epoch 1/38 Batch 2500/7662 eta: 2 days, 17:28:45.620048	Training Loss 15.1766 (20.2893)	Training Prec@1 36.133 (5.122)	Training Prec@5 45.312 (8.364)	
2022-03-26 00:10:06,231: ============================================================
2022-03-26 00:11:21,466: time cost, forward:0.018921500859511914, backward:0.042992998701464724, data cost:0.7372612504603175 
2022-03-26 00:11:21,467: ============================================================
2022-03-26 00:11:21,467: Epoch 1/38 Batch 2600/7662 eta: 2 days, 12:18:21.287446	Training Loss 14.7457 (20.0916)	Training Prec@1 36.133 (6.227)	Training Prec@5 51.562 (9.813)	
2022-03-26 00:11:21,467: ============================================================
2022-03-26 00:12:42,285: time cost, forward:0.01887126735688669, backward:0.04294242952522767, data cost:0.7373692142208138 
2022-03-26 00:12:42,444: ============================================================
2022-03-26 00:12:42,446: Epoch 1/38 Batch 2700/7662 eta: 2 days, 16:53:07.238114	Training Loss 14.0603 (19.8893)	Training Prec@1 43.359 (7.425)	Training Prec@5 57.031 (11.336)	
2022-03-26 00:12:42,446: ============================================================
2022-03-26 00:14:03,069: time cost, forward:0.018887268129780106, backward:0.04289768669766245, data cost:0.7378887720472602 
2022-03-26 00:14:03,069: ============================================================
2022-03-26 00:14:03,070: Epoch 1/38 Batch 2800/7662 eta: 2 days, 16:34:45.847822	Training Loss 14.1476 (19.6830)	Training Prec@1 42.578 (8.703)	Training Prec@5 54.297 (12.916)	
2022-03-26 00:14:03,070: ============================================================
2022-03-26 00:15:23,391: time cost, forward:0.018992263475505596, backward:0.043048934469390794, data cost:0.7373752382633069 
2022-03-26 00:15:23,416: ============================================================
2022-03-26 00:15:23,417: Epoch 1/38 Batch 2900/7662 eta: 2 days, 16:20:05.593046	Training Loss 13.5997 (19.4737)	Training Prec@1 48.242 (10.041)	Training Prec@5 60.156 (14.539)	
2022-03-26 00:15:23,418: ============================================================
2022-03-26 00:16:43,116: time cost, forward:0.018977816401421526, backward:0.04308818419323877, data cost:0.7375407557600376 
2022-03-26 00:16:43,117: ============================================================
2022-03-26 00:16:43,117: Epoch 1/38 Batch 3000/7662 eta: 2 days, 15:47:41.605242	Training Loss 12.6221 (19.2632)	Training Prec@1 56.641 (11.428)	Training Prec@5 69.531 (16.178)	
2022-03-26 00:16:43,117: ============================================================
2022-03-26 00:18:01,917: time cost, forward:0.019002899888178038, backward:0.04309135554259191, data cost:0.7370881484223397 
2022-03-26 00:18:01,918: ============================================================
2022-03-26 00:18:01,918: Epoch 1/38 Batch 3100/7662 eta: 2 days, 15:03:11.979594	Training Loss 12.4015 (19.0509)	Training Prec@1 58.398 (12.863)	Training Prec@5 70.312 (17.833)	
2022-03-26 00:18:01,918: ============================================================
2022-03-26 00:19:21,939: time cost, forward:0.01895560320931399, backward:0.043061620408797796, data cost:0.7368185462784715 
2022-03-26 00:19:21,954: ============================================================
2022-03-26 00:19:21,956: Epoch 1/38 Batch 3200/7662 eta: 2 days, 16:01:12.282601	Training Loss 11.9611 (18.8393)	Training Prec@1 61.523 (14.315)	Training Prec@5 73.633 (19.477)	
2022-03-26 00:19:21,956: ============================================================
2022-03-26 00:20:39,961: time cost, forward:0.01895061483091208, backward:0.04310693304334203, data cost:0.7361917413339791 
2022-03-26 00:20:39,966: ============================================================
2022-03-26 00:20:39,967: Epoch 1/38 Batch 3300/7662 eta: 2 days, 14:22:41.671651	Training Loss 11.8286 (18.6289)	Training Prec@1 66.016 (15.781)	Training Prec@5 73.242 (21.105)	
2022-03-26 00:20:39,969: ============================================================
2022-03-26 00:21:58,416: time cost, forward:0.01893701136690899, backward:0.043045247712883046, data cost:0.7360935740065455 
2022-03-26 00:21:58,416: ============================================================
2022-03-26 00:21:58,417: Epoch 1/38 Batch 3400/7662 eta: 2 days, 14:42:25.195807	Training Loss 11.2028 (18.4223)	Training Prec@1 68.945 (17.232)	Training Prec@5 78.125 (22.694)	
2022-03-26 00:21:58,417: ============================================================
2022-03-26 00:23:17,217: time cost, forward:0.018933777742366785, backward:0.0430099902135299, data cost:0.735589459065745 
2022-03-26 00:23:17,221: ============================================================
2022-03-26 00:23:17,222: Epoch 1/38 Batch 3500/7662 eta: 2 days, 14:58:06.256223	Training Loss 11.1500 (18.2167)	Training Prec@1 69.922 (18.683)	Training Prec@5 77.930 (24.264)	
2022-03-26 00:23:17,222: ============================================================
2022-03-26 00:24:38,163: time cost, forward:0.01896272039506196, backward:0.043053546194302836, data cost:0.7359428113617809 
2022-03-26 00:24:38,164: ============================================================
2022-03-26 00:24:38,164: Epoch 1/38 Batch 3600/7662 eta: 2 days, 16:39:18.159486	Training Loss 10.8929 (18.0148)	Training Prec@1 72.656 (20.118)	Training Prec@5 81.055 (25.803)	
2022-03-26 00:24:38,165: ============================================================
2022-03-26 00:25:56,436: time cost, forward:0.018944874232638426, backward:0.04297981960897866, data cost:0.7354299995698745 
2022-03-26 00:25:56,440: ============================================================
2022-03-26 00:25:56,441: Epoch 1/38 Batch 3700/7662 eta: 2 days, 14:30:11.414266	Training Loss 10.2662 (17.8169)	Training Prec@1 75.000 (21.531)	Training Prec@5 82.812 (27.302)	
2022-03-26 00:25:56,442: ============================================================
2022-03-26 00:27:13,337: time cost, forward:0.018882598271963626, backward:0.042906389389580316, data cost:0.73492659145545 
2022-03-26 00:27:13,338: ============================================================
2022-03-26 00:27:13,338: Epoch 1/38 Batch 3800/7662 eta: 2 days, 13:22:48.804941	Training Loss 10.0088 (17.6226)	Training Prec@1 77.148 (22.921)	Training Prec@5 83.398 (28.766)	
2022-03-26 00:27:13,338: ============================================================
2022-03-26 00:28:31,058: time cost, forward:0.018837700626366444, backward:0.042861476315079854, data cost:0.7342736705751657 
2022-03-26 00:28:31,062: ============================================================
2022-03-26 00:28:31,062: Epoch 1/38 Batch 3900/7662 eta: 2 days, 14:01:07.929219	Training Loss 10.1031 (17.4335)	Training Prec@1 78.125 (24.271)	Training Prec@5 86.328 (30.172)	
2022-03-26 00:28:31,063: ============================================================
2022-03-26 00:29:49,753: time cost, forward:0.01882558680975786, backward:0.04284417119494794, data cost:0.7341521375922746 
2022-03-26 00:29:49,757: ============================================================
2022-03-26 00:29:49,758: Epoch 1/38 Batch 4000/7662 eta: 2 days, 14:46:19.645540	Training Loss 9.9024 (17.2497)	Training Prec@1 77.148 (25.583)	Training Prec@5 83.984 (31.537)	
2022-03-26 00:29:49,759: ============================================================
2022-03-26 00:31:08,835: time cost, forward:0.01881354469937736, backward:0.04284267246388726, data cost:0.7340820729659807 
2022-03-26 00:31:08,856: ============================================================
2022-03-26 00:31:08,857: Epoch 1/38 Batch 4100/7662 eta: 2 days, 15:04:18.512804	Training Loss 9.7851 (17.0699)	Training Prec@1 78.125 (26.869)	Training Prec@5 85.742 (32.862)	
2022-03-26 00:31:08,858: ============================================================
2022-03-26 00:32:27,372: time cost, forward:0.018774038213978328, backward:0.04276269366270476, data cost:0.7338478308571155 
2022-03-26 00:32:27,373: ============================================================
2022-03-26 00:32:27,373: Epoch 1/38 Batch 4200/7662 eta: 2 days, 14:35:08.173505	Training Loss 9.7045 (16.8942)	Training Prec@1 79.492 (28.122)	Training Prec@5 86.719 (34.146)	
2022-03-26 00:32:27,373: ============================================================
2022-03-26 00:33:45,113: time cost, forward:0.018746409756717472, backward:0.04275540685509493, data cost:0.7334963702467825 
2022-03-26 00:33:45,114: ============================================================
2022-03-26 00:33:45,114: Epoch 1/38 Batch 4300/7662 eta: 2 days, 13:56:46.051429	Training Loss 9.3983 (16.7233)	Training Prec@1 81.836 (29.337)	Training Prec@5 87.891 (35.382)	
2022-03-26 00:33:45,114: ============================================================
2022-03-26 00:35:03,368: time cost, forward:0.01870597181170603, backward:0.042711456354760834, data cost:0.7333037197982812 
2022-03-26 00:35:03,369: ============================================================
2022-03-26 00:35:03,369: Epoch 1/38 Batch 4400/7662 eta: 2 days, 14:20:01.409001	Training Loss 9.4774 (16.5574)	Training Prec@1 82.227 (30.520)	Training Prec@5 88.281 (36.581)	
2022-03-26 00:35:03,369: ============================================================
2022-03-26 00:36:22,386: time cost, forward:0.01867030561963938, backward:0.04268115778768505, data cost:0.7330101888745222 
2022-03-26 00:36:22,412: ============================================================
2022-03-26 00:36:22,413: Epoch 1/38 Batch 4500/7662 eta: 2 days, 14:56:23.147449	Training Loss 9.5730 (16.3965)	Training Prec@1 80.273 (31.663)	Training Prec@5 86.523 (37.738)	
2022-03-26 00:36:22,413: ============================================================
2022-03-26 00:37:39,881: time cost, forward:0.018656122500441803, backward:0.04263215662215321, data cost:0.7327890747602828 
2022-03-26 00:37:39,885: ============================================================
2022-03-26 00:37:39,886: Epoch 1/38 Batch 4600/7662 eta: 2 days, 13:40:04.750202	Training Loss 9.2374 (16.2399)	Training Prec@1 83.594 (32.770)	Training Prec@5 90.234 (38.855)	
2022-03-26 00:37:39,887: ============================================================
2022-03-26 00:38:58,993: time cost, forward:0.01860695758964894, backward:0.042545607861723636, data cost:0.7328793782836758 
2022-03-26 00:38:58,994: ============================================================
2022-03-26 00:38:58,994: Epoch 1/38 Batch 4700/7662 eta: 2 days, 14:56:51.564718	Training Loss 8.9886 (16.0878)	Training Prec@1 84.375 (33.849)	Training Prec@5 89.453 (39.935)	
2022-03-26 00:38:58,994: ============================================================
2022-03-26 00:40:16,678: time cost, forward:0.01857877488085617, backward:0.04250773923499904, data cost:0.7324290538385625 
2022-03-26 00:40:16,704: ============================================================
2022-03-26 00:40:16,705: Epoch 1/38 Batch 4800/7662 eta: 2 days, 13:48:49.802634	Training Loss 9.1140 (15.9407)	Training Prec@1 84.375 (34.892)	Training Prec@5 90.430 (40.978)	
2022-03-26 00:40:16,705: ============================================================
2022-03-26 00:41:34,811: time cost, forward:0.018588278628923767, backward:0.042436434313043524, data cost:0.732304991788099 
2022-03-26 00:41:34,812: ============================================================
2022-03-26 00:41:34,812: Epoch 1/38 Batch 4900/7662 eta: 2 days, 14:06:27.575665	Training Loss 8.9017 (15.7972)	Training Prec@1 82.812 (35.899)	Training Prec@5 89.844 (41.985)	
2022-03-26 00:41:34,812: ============================================================
2022-03-26 00:42:53,525: time cost, forward:0.01855903655248872, backward:0.042391766689138, data cost:0.7321751613716145 
2022-03-26 00:42:53,525: ============================================================
2022-03-26 00:42:53,526: Epoch 1/38 Batch 5000/7662 eta: 2 days, 14:34:04.656920	Training Loss 8.8121 (15.6577)	Training Prec@1 85.547 (36.881)	Training Prec@5 90.430 (42.961)	
2022-03-26 00:42:53,526: ============================================================
2022-03-26 00:44:09,744: time cost, forward:0.018527704352232773, backward:0.04238624805608294, data cost:0.7315035262840078 
2022-03-26 00:44:09,761: ============================================================
2022-03-26 00:44:09,763: Epoch 1/38 Batch 5100/7662 eta: 2 days, 12:34:40.047434	Training Loss 8.8594 (15.5216)	Training Prec@1 84.961 (37.841)	Training Prec@5 91.016 (43.914)	
2022-03-26 00:44:09,763: ============================================================
2022-03-26 00:45:27,459: time cost, forward:0.018497757875912464, backward:0.042313206124750556, data cost:0.7314148936553239 
2022-03-26 00:45:27,460: ============================================================
2022-03-26 00:45:27,460: Epoch 1/38 Batch 5200/7662 eta: 2 days, 13:43:02.357716	Training Loss 8.6478 (15.3897)	Training Prec@1 85.742 (38.764)	Training Prec@5 91.211 (44.826)	
2022-03-26 00:45:27,460: ============================================================
2022-03-26 00:46:45,874: time cost, forward:0.01853281467629955, backward:0.042339527420242634, data cost:0.7311762765930112 
2022-03-26 00:46:45,874: ============================================================
2022-03-26 00:46:45,875: Epoch 1/38 Batch 5300/7662 eta: 2 days, 14:15:53.976541	Training Loss 8.7827 (15.2616)	Training Prec@1 85.547 (39.661)	Training Prec@5 90.430 (45.708)	
2022-03-26 00:46:45,875: ============================================================
2022-03-26 00:48:05,956: time cost, forward:0.018546928275755367, backward:0.04232564774414503, data cost:0.7312987775885633 
2022-03-26 00:48:06,021: ============================================================
2022-03-26 00:48:06,021: Epoch 1/38 Batch 5400/7662 eta: 2 days, 15:37:03.600714	Training Loss 8.5969 (15.1365)	Training Prec@1 86.328 (40.532)	Training Prec@5 91.992 (46.564)	
2022-03-26 00:48:06,021: ============================================================
2022-03-26 00:49:21,553: time cost, forward:0.018516251251337247, backward:0.04224742675048695, data cost:0.7305603099749465 
2022-03-26 00:49:21,556: ============================================================
2022-03-26 00:49:21,557: Epoch 1/38 Batch 5500/7662 eta: 2 days, 11:56:11.933944	Training Loss 8.3708 (15.0146)	Training Prec@1 88.477 (41.381)	Training Prec@5 93.750 (47.398)	
2022-03-26 00:49:21,557: ============================================================
2022-03-26 00:50:40,967: time cost, forward:0.018507389452525985, backward:0.04215228321254626, data cost:0.7308079933647514 
2022-03-26 00:50:40,968: ============================================================
2022-03-26 00:50:40,968: Epoch 1/38 Batch 5600/7662 eta: 2 days, 14:59:26.336084	Training Loss 8.2597 (14.8963)	Training Prec@1 88.281 (42.203)	Training Prec@5 93.359 (48.204)	
2022-03-26 00:50:40,969: ============================================================
2022-03-26 00:51:59,648: time cost, forward:0.018484100163411753, backward:0.042007100814307946, data cost:0.7307876486760688 
2022-03-26 00:51:59,648: ============================================================
2022-03-26 00:51:59,648: Epoch 1/38 Batch 5700/7662 eta: 2 days, 14:23:17.713435	Training Loss 8.4869 (14.7809)	Training Prec@1 87.695 (43.003)	Training Prec@5 92.188 (48.987)	
2022-03-26 00:51:59,649: ============================================================
2022-03-26 00:53:16,606: time cost, forward:0.01844419576234089, backward:0.041962324740414295, data cost:0.7305462431097713 
2022-03-26 00:53:16,627: ============================================================
2022-03-26 00:53:16,628: Epoch 1/38 Batch 5800/7662 eta: 2 days, 13:01:05.138779	Training Loss 8.5857 (14.6696)	Training Prec@1 85.938 (43.775)	Training Prec@5 91.992 (49.741)	
2022-03-26 00:53:16,629: ============================================================
2022-03-26 00:54:32,881: time cost, forward:0.018401170953044773, backward:0.0419179463633078, data cost:0.7300247252846314 
2022-03-26 00:54:32,885: ============================================================
2022-03-26 00:54:32,885: Epoch 1/38 Batch 5900/7662 eta: 2 days, 12:25:29.319301	Training Loss 8.1871 (14.5601)	Training Prec@1 89.453 (44.530)	Training Prec@5 93.945 (50.476)	
2022-03-26 00:54:32,886: ============================================================
2022-03-26 00:55:48,309: time cost, forward:0.018362588893574346, backward:0.04188061265234829, data cost:0.7296127358920019 
2022-03-26 00:55:48,309: ============================================================
2022-03-26 00:55:48,310: Epoch 1/38 Batch 6000/7662 eta: 2 days, 11:44:38.370607	Training Loss 8.1498 (14.4537)	Training Prec@1 89.062 (45.262)	Training Prec@5 93.750 (51.190)	
2022-03-26 00:55:48,310: ============================================================
2022-03-26 00:57:04,395: time cost, forward:0.01833420781781193, backward:0.041842864759438624, data cost:0.7291646545139331 
2022-03-26 00:57:04,396: ============================================================
2022-03-26 00:57:04,396: Epoch 1/38 Batch 6100/7662 eta: 2 days, 12:14:49.596426	Training Loss 7.8297 (14.3497)	Training Prec@1 88.867 (45.977)	Training Prec@5 95.117 (51.885)	
2022-03-26 00:57:04,396: ============================================================
2022-03-26 00:58:21,439: time cost, forward:0.018334387617546584, backward:0.041799365406864054, data cost:0.7288658615080921 
2022-03-26 00:58:21,454: ============================================================
2022-03-26 00:58:21,455: Epoch 1/38 Batch 6200/7662 eta: 2 days, 12:59:44.461650	Training Loss 7.9432 (14.2495)	Training Prec@1 90.234 (46.663)	Training Prec@5 93.359 (52.553)	
2022-03-26 00:58:21,455: ============================================================
2022-03-26 00:59:41,466: time cost, forward:0.018310766936219067, backward:0.041774286961135346, data cost:0.7290970141744969 
2022-03-26 00:59:41,467: ============================================================
2022-03-26 00:59:41,467: Epoch 1/38 Batch 6300/7662 eta: 2 days, 15:18:40.741363	Training Loss 7.8895 (14.1511)	Training Prec@1 89.258 (47.334)	Training Prec@5 92.578 (53.204)	
2022-03-26 00:59:41,467: ============================================================
2022-03-26 01:01:00,010: time cost, forward:0.018299285537247585, backward:0.041750091969137884, data cost:0.7290410252171842 
2022-03-26 01:01:00,010: ============================================================
2022-03-26 01:01:00,010: Epoch 1/38 Batch 6400/7662 eta: 2 days, 14:07:37.748887	Training Loss 8.0171 (14.0550)	Training Prec@1 91.797 (47.987)	Training Prec@5 95.312 (53.839)	
2022-03-26 01:01:00,011: ============================================================
2022-03-26 01:02:16,924: time cost, forward:0.018299919070601738, backward:0.04174544092581298, data cost:0.7287060670402165 
2022-03-26 01:02:16,924: ============================================================
2022-03-26 01:02:16,925: Epoch 1/38 Batch 6500/7662 eta: 2 days, 12:49:01.407448	Training Loss 7.5663 (13.9608)	Training Prec@1 92.188 (48.629)	Training Prec@5 96.094 (54.458)	
2022-03-26 01:02:16,925: ============================================================
2022-03-26 01:03:37,027: time cost, forward:0.018264477389168424, backward:0.041737135006886826, data cost:0.7289138858400342 
2022-03-26 01:03:37,073: ============================================================
2022-03-26 01:03:37,073: Epoch 1/38 Batch 6600/7662 eta: 2 days, 15:21:08.805456	Training Loss 8.0337 (13.8697)	Training Prec@1 87.695 (49.248)	Training Prec@5 93.164 (55.053)	
2022-03-26 01:03:37,073: ============================================================
2022-03-26 01:04:52,050: time cost, forward:0.018263559267403102, backward:0.04168010676222108, data cost:0.7283507746571053 
2022-03-26 01:04:52,050: ============================================================
2022-03-26 01:04:52,050: Epoch 1/38 Batch 6700/7662 eta: 2 days, 11:14:37.012235	Training Loss 7.8818 (13.7804)	Training Prec@1 91.602 (49.851)	Training Prec@5 94.727 (55.636)	
2022-03-26 01:04:52,050: ============================================================
2022-03-26 01:06:08,963: time cost, forward:0.018269648813538594, backward:0.04165753236078553, data cost:0.7280738295869172 
2022-03-26 01:06:08,963: ============================================================
2022-03-26 01:06:08,963: Epoch 1/38 Batch 6800/7662 eta: 2 days, 12:45:07.614289	Training Loss 7.7423 (13.6931)	Training Prec@1 91.016 (50.442)	Training Prec@5 93.945 (56.206)	
2022-03-26 01:06:08,963: ============================================================
2022-03-26 01:07:26,815: time cost, forward:0.018256611816432792, backward:0.041626795355280785, data cost:0.7278518266203715 
2022-03-26 01:07:26,818: ============================================================
2022-03-26 01:07:26,819: Epoch 1/38 Batch 6900/7662 eta: 2 days, 13:28:28.708269	Training Loss 7.8286 (13.6078)	Training Prec@1 88.672 (51.017)	Training Prec@5 92.773 (56.761)	
2022-03-26 01:07:26,820: ============================================================
2022-03-26 01:08:46,037: time cost, forward:0.018230677604811552, backward:0.04161673567093752, data cost:0.7280415545056285 
2022-03-26 01:08:46,037: ============================================================
2022-03-26 01:08:46,038: Epoch 1/38 Batch 7000/7662 eta: 2 days, 14:31:46.954014	Training Loss 7.8538 (13.5245)	Training Prec@1 89.648 (51.577)	Training Prec@5 93.750 (57.297)	
2022-03-26 01:08:46,038: ============================================================
2022-03-26 01:10:02,688: time cost, forward:0.018227836450635086, backward:0.04161503684740702, data cost:0.7277278260019971 
2022-03-26 01:10:02,688: ============================================================
2022-03-26 01:10:02,689: Epoch 1/38 Batch 7100/7662 eta: 2 days, 12:28:52.084154	Training Loss 7.9756 (13.4437)	Training Prec@1 89.648 (52.120)	Training Prec@5 93.750 (57.818)	
2022-03-26 01:10:02,689: ============================================================
2022-03-26 01:11:17,595: time cost, forward:0.018200675883811784, backward:0.04158168306680566, data cost:0.7271477434267218 
2022-03-26 01:11:17,597: ============================================================
2022-03-26 01:11:17,598: Epoch 1/38 Batch 7200/7662 eta: 2 days, 11:05:10.013723	Training Loss 7.7369 (13.3644)	Training Prec@1 90.234 (52.651)	Training Prec@5 95.117 (58.328)	
2022-03-26 01:11:17,599: ============================================================
2022-03-26 01:12:33,436: time cost, forward:0.01819768666012481, backward:0.041623669367062584, data cost:0.7267756629013038 
2022-03-26 01:12:33,448: ============================================================
2022-03-26 01:12:33,448: Epoch 1/38 Batch 7300/7662 eta: 2 days, 11:48:26.275967	Training Loss 7.7903 (13.2867)	Training Prec@1 91.211 (53.171)	Training Prec@5 94.922 (58.828)	
2022-03-26 01:12:33,448: ============================================================
2022-03-26 01:13:51,082: time cost, forward:0.01819236601731442, backward:0.04165425524870791, data cost:0.7264895264498848 
2022-03-26 01:13:51,085: ============================================================
2022-03-26 01:13:51,087: Epoch 1/38 Batch 7400/7662 eta: 2 days, 13:11:44.720319	Training Loss 7.6255 (13.2116)	Training Prec@1 89.844 (53.674)	Training Prec@5 94.336 (59.312)	
2022-03-26 01:13:51,088: ============================================================
2022-03-26 01:15:06,435: time cost, forward:0.01819470227917189, backward:0.04161946575456277, data cost:0.7261402036908754 
2022-03-26 01:15:06,435: ============================================================
2022-03-26 01:15:06,435: Epoch 1/38 Batch 7500/7662 eta: 2 days, 11:22:11.643649	Training Loss 7.4354 (13.1370)	Training Prec@1 91.992 (54.170)	Training Prec@5 95.117 (59.786)	
2022-03-26 01:15:06,436: ============================================================
2022-03-26 01:16:22,908: time cost, forward:0.018188755423446317, backward:0.04159835480219252, data cost:0.7258141998366817 
2022-03-26 01:16:22,912: ============================================================
2022-03-26 01:16:22,913: Epoch 1/38 Batch 7600/7662 eta: 2 days, 12:14:15.710435	Training Loss 7.7833 (13.0643)	Training Prec@1 90.625 (54.654)	Training Prec@5 94.531 (60.248)	
2022-03-26 01:16:22,914: ============================================================
2022-03-26 01:17:12,051: Epoch: 1/38 eta: 2 days, 12:13:27.529964	Training Loss 7.5232 (13.0194)	Training Prec@1 91.016 (54.952)	Training Prec@5 94.922 (60.533)
2022-03-26 01:17:12,052: ============================================================
2022-03-26 01:18:32,122: time cost, forward:0.018936662962942413, backward:0.04416818570609045, data cost:0.7385509977437029 
2022-03-26 01:18:32,124: ============================================================
2022-03-26 01:18:32,125: Epoch 2/38 Batch 100/7662 eta: 2 days, 15:01:12.383648	Training Loss 7.2807 (7.1041)	Training Prec@1 90.234 (92.698)	Training Prec@5 93.359 (95.981)	
2022-03-26 01:18:32,125: ============================================================
2022-03-26 01:19:50,848: time cost, forward:0.018879587326816577, backward:0.042744329826316645, data cost:0.7323861373728843 
2022-03-26 01:19:50,848: ============================================================
2022-03-26 01:19:50,848: Epoch 2/38 Batch 200/7662 eta: 2 days, 13:57:00.936897	Training Loss 7.2653 (7.1395)	Training Prec@1 91.211 (92.642)	Training Prec@5 94.531 (95.993)	
2022-03-26 01:19:50,848: ============================================================
2022-03-26 01:21:05,839: time cost, forward:0.018706842409727167, backward:0.04182198374566426, data cost:0.7156935423911615 
2022-03-26 01:21:05,841: ============================================================
2022-03-26 01:21:05,841: Epoch 2/38 Batch 300/7662 eta: 2 days, 10:59:35.668199	Training Loss 7.1406 (7.1591)	Training Prec@1 91.406 (92.645)	Training Prec@5 94.531 (95.983)	
2022-03-26 01:21:05,842: ============================================================
2022-03-26 01:22:22,940: time cost, forward:0.018873000802252824, backward:0.04168230369873812, data cost:0.7148482237842149 
2022-03-26 01:22:22,943: ============================================================
2022-03-26 01:22:22,944: Epoch 2/38 Batch 400/7662 eta: 2 days, 12:37:54.120734	Training Loss 7.2338 (7.1896)	Training Prec@1 92.188 (92.587)	Training Prec@5 94.531 (95.927)	
2022-03-26 01:22:22,946: ============================================================
2022-03-26 01:23:40,127: time cost, forward:0.0189502874691644, backward:0.04188044563324036, data cost:0.7126765771953758 
2022-03-26 01:23:40,128: ============================================================
2022-03-26 01:23:40,129: Epoch 2/38 Batch 500/7662 eta: 2 days, 12:40:28.607000	Training Loss 7.5894 (7.2154)	Training Prec@1 91.797 (92.490)	Training Prec@5 95.117 (95.862)	
2022-03-26 01:23:40,129: ============================================================
2022-03-26 01:24:56,281: time cost, forward:0.0192217026807629, backward:0.04212206194118188, data cost:0.7112886416096122 
2022-03-26 01:24:56,305: ============================================================
2022-03-26 01:24:56,305: Epoch 2/38 Batch 600/7662 eta: 2 days, 11:51:40.448775	Training Loss 7.4046 (7.2292)	Training Prec@1 92.188 (92.466)	Training Prec@5 95.898 (95.870)	
2022-03-26 01:24:56,305: ============================================================
2022-03-26 01:26:12,160: time cost, forward:0.018669654712485995, backward:0.04162365206662507, data cost:0.7101927202658592 
2022-03-26 01:26:12,160: ============================================================
2022-03-26 01:26:12,161: Epoch 2/38 Batch 700/7662 eta: 2 days, 11:35:14.864017	Training Loss 7.4113 (7.2380)	Training Prec@1 90.820 (92.445)	Training Prec@5 94.727 (95.862)	
2022-03-26 01:26:12,161: ============================================================
2022-03-26 01:27:27,209: time cost, forward:0.018575900487219438, backward:0.04164539171249905, data cost:0.7074829275825892 
2022-03-26 01:27:27,210: ============================================================
2022-03-26 01:27:27,210: Epoch 2/38 Batch 800/7662 eta: 2 days, 10:56:00.593571	Training Loss 7.3022 (7.2533)	Training Prec@1 91.406 (92.398)	Training Prec@5 95.898 (95.833)	
2022-03-26 01:27:27,211: ============================================================
2022-03-26 01:28:42,580: time cost, forward:0.018539330320177936, backward:0.04167370881068958, data cost:0.7056415359488584 
2022-03-26 01:28:42,580: ============================================================
2022-03-26 01:28:42,581: Epoch 2/38 Batch 900/7662 eta: 2 days, 11:09:53.873127	Training Loss 7.4807 (7.2668)	Training Prec@1 91.016 (92.357)	Training Prec@5 95.117 (95.808)	
2022-03-26 01:28:42,581: ============================================================
2022-03-26 01:29:59,437: time cost, forward:0.01854630347128745, backward:0.041810039285424955, data cost:0.7057750513842395 
2022-03-26 01:29:59,437: ============================================================
2022-03-26 01:29:59,437: Epoch 2/38 Batch 1000/7662 eta: 2 days, 12:18:36.063077	Training Loss 7.4501 (7.2724)	Training Prec@1 92.969 (92.352)	Training Prec@5 95.703 (95.825)	
2022-03-26 01:29:59,437: ============================================================
2022-03-26 01:31:15,023: time cost, forward:0.01845990364067765, backward:0.041611415023040076, data cost:0.7045844724983167 
2022-03-26 01:31:15,027: ============================================================
2022-03-26 01:31:15,028: Epoch 2/38 Batch 1100/7662 eta: 2 days, 11:17:41.403325	Training Loss 7.3082 (7.2777)	Training Prec@1 91.406 (92.332)	Training Prec@5 95.703 (95.810)	
2022-03-26 01:31:15,028: ============================================================
2022-03-26 01:32:31,263: time cost, forward:0.018332446387054724, backward:0.041444999760046314, data cost:0.7048599944699298 
2022-03-26 01:32:31,264: ============================================================
2022-03-26 01:32:31,264: Epoch 2/38 Batch 1200/7662 eta: 2 days, 11:46:54.064942	Training Loss 7.1735 (7.2786)	Training Prec@1 93.164 (92.327)	Training Prec@5 96.094 (95.796)	
2022-03-26 01:32:31,265: ============================================================
2022-03-26 01:33:46,763: time cost, forward:0.018361053070350276, backward:0.04162576861157612, data cost:0.7031858345469297 
2022-03-26 01:33:46,766: ============================================================
2022-03-26 01:33:46,766: Epoch 2/38 Batch 1300/7662 eta: 2 days, 11:11:01.603617	Training Loss 7.3966 (7.2794)	Training Prec@1 90.039 (92.297)	Training Prec@5 94.531 (95.773)	
2022-03-26 01:33:46,767: ============================================================
2022-03-26 01:35:01,336: time cost, forward:0.01825774866312721, backward:0.041538442007723324, data cost:0.7024992265558141 
2022-03-26 01:35:01,337: ============================================================
2022-03-26 01:35:01,338: Epoch 2/38 Batch 1400/7662 eta: 2 days, 10:26:03.561988	Training Loss 7.3878 (7.2810)	Training Prec@1 92.773 (92.282)	Training Prec@5 96.484 (95.772)	
2022-03-26 01:35:01,339: ============================================================
2022-03-26 01:36:17,637: time cost, forward:0.01823282035054009, backward:0.041616654539203705, data cost:0.7019332635394727 
2022-03-26 01:36:17,641: ============================================================
2022-03-26 01:36:17,642: Epoch 2/38 Batch 1500/7662 eta: 2 days, 11:46:11.777648	Training Loss 7.5053 (7.2793)	Training Prec@1 90.625 (92.284)	Training Prec@5 93.555 (95.767)	
2022-03-26 01:36:17,643: ============================================================
2022-03-26 01:37:33,182: time cost, forward:0.018193265361439965, backward:0.04147063336423071, data cost:0.7016139034929687 
2022-03-26 01:37:33,186: ============================================================
2022-03-26 01:37:33,187: Epoch 2/38 Batch 1600/7662 eta: 2 days, 11:09:16.897810	Training Loss 7.2598 (7.2791)	Training Prec@1 91.797 (92.280)	Training Prec@5 95.508 (95.762)	
2022-03-26 01:37:33,187: ============================================================
2022-03-26 01:38:47,724: time cost, forward:0.018147137952313975, backward:0.041384011314082245, data cost:0.7012340172099113 
2022-03-26 01:38:47,747: ============================================================
2022-03-26 01:38:47,748: Epoch 2/38 Batch 1700/7662 eta: 2 days, 10:21:50.544865	Training Loss 6.8322 (7.2756)	Training Prec@1 93.164 (92.275)	Training Prec@5 96.289 (95.767)	
2022-03-26 01:38:47,748: ============================================================
2022-03-26 01:40:00,438: time cost, forward:0.018100274941071727, backward:0.04132926483960069, data cost:0.6993930414029133 
2022-03-26 01:40:00,438: ============================================================
2022-03-26 01:40:00,439: Epoch 2/38 Batch 1800/7662 eta: 2 days, 8:52:46.742489	Training Loss 7.2598 (7.2729)	Training Prec@1 90.039 (92.281)	Training Prec@5 93.945 (95.770)	
2022-03-26 01:40:00,439: ============================================================
2022-03-26 01:41:14,463: time cost, forward:0.018056454188953016, backward:0.041301442548562, data cost:0.6983696780373009 
2022-03-26 01:41:14,463: ============================================================
2022-03-26 01:41:14,463: Epoch 2/38 Batch 1900/7662 eta: 2 days, 9:54:10.053156	Training Loss 7.3173 (7.2698)	Training Prec@1 91.602 (92.285)	Training Prec@5 96.875 (95.777)	
2022-03-26 01:41:14,464: ============================================================
2022-03-26 01:42:31,709: time cost, forward:0.018053431103025572, backward:0.04133207598825047, data cost:0.6985910384878031 
2022-03-26 01:42:31,713: ============================================================
2022-03-26 01:42:31,715: Epoch 2/38 Batch 2000/7662 eta: 2 days, 12:24:17.565334	Training Loss 7.2775 (7.2668)	Training Prec@1 92.188 (92.290)	Training Prec@5 95.898 (95.783)	
2022-03-26 01:42:31,716: ============================================================
2022-03-26 01:43:47,671: time cost, forward:0.01799904181310936, backward:0.041283079872476654, data cost:0.6991159451354283 
2022-03-26 01:43:47,671: ============================================================
2022-03-26 01:43:47,671: Epoch 2/38 Batch 2100/7662 eta: 2 days, 11:22:19.324985	Training Loss 7.2100 (7.2635)	Training Prec@1 91.406 (92.287)	Training Prec@5 93.750 (95.779)	
2022-03-26 01:43:47,672: ============================================================
2022-03-26 01:45:02,841: time cost, forward:0.01797467874038648, backward:0.041248711199584794, data cost:0.698603420921107 
2022-03-26 01:45:02,843: ============================================================
2022-03-26 01:45:02,843: Epoch 2/38 Batch 2200/7662 eta: 2 days, 10:44:13.916295	Training Loss 7.1704 (7.2576)	Training Prec@1 92.578 (92.303)	Training Prec@5 97.266 (95.789)	
2022-03-26 01:45:02,843: ============================================================
2022-03-26 01:46:20,546: time cost, forward:0.017990682269241977, backward:0.04111833922911748, data cost:0.6996650720690063 
2022-03-26 01:46:20,548: ============================================================
2022-03-26 01:46:20,549: Epoch 2/38 Batch 2300/7662 eta: 2 days, 12:41:44.452385	Training Loss 6.9428 (7.2533)	Training Prec@1 92.383 (92.310)	Training Prec@5 95.117 (95.795)	
2022-03-26 01:46:20,549: ============================================================
2022-03-26 01:47:37,643: time cost, forward:0.017975791388126452, backward:0.041098042397063786, data cost:0.6998117020747323 
2022-03-26 01:47:37,646: ============================================================
2022-03-26 01:47:37,647: Epoch 2/38 Batch 2400/7662 eta: 2 days, 12:11:58.157462	Training Loss 6.9720 (7.2498)	Training Prec@1 91.992 (92.311)	Training Prec@5 95.898 (95.796)	
2022-03-26 01:47:37,648: ============================================================
2022-03-26 01:48:52,765: time cost, forward:0.017995852000620805, backward:0.041055810026952674, data cost:0.6997948001985218 
2022-03-26 01:48:52,790: ============================================================
2022-03-26 01:48:52,792: Epoch 2/38 Batch 2500/7662 eta: 2 days, 10:39:11.063165	Training Loss 7.3802 (7.2460)	Training Prec@1 93.750 (92.315)	Training Prec@5 96.484 (95.798)	
2022-03-26 01:48:52,792: ============================================================
2022-03-26 01:50:10,572: time cost, forward:0.01793757912377845, backward:0.04096821199338589, data cost:0.700605934241406 
2022-03-26 01:50:10,572: ============================================================
2022-03-26 01:50:10,572: Epoch 2/38 Batch 2600/7662 eta: 2 days, 12:41:24.759257	Training Loss 7.2127 (7.2404)	Training Prec@1 93.555 (92.331)	Training Prec@5 95.508 (95.810)	
2022-03-26 01:50:10,573: ============================================================
2022-03-26 01:51:27,155: time cost, forward:0.017880010710861472, backward:0.040865133143478345, data cost:0.7006366846516381 
2022-03-26 01:51:27,158: ============================================================
2022-03-26 01:51:27,159: Epoch 2/38 Batch 2700/7662 eta: 2 days, 11:44:11.066494	Training Loss 6.9106 (7.2359)	Training Prec@1 93.945 (92.330)	Training Prec@5 97.461 (95.816)	
2022-03-26 01:51:27,160: ============================================================
2022-03-26 01:52:44,293: time cost, forward:0.01788472916322676, backward:0.040863208065462266, data cost:0.7013172866532359 
2022-03-26 01:52:44,296: ============================================================
2022-03-26 01:52:44,297: Epoch 2/38 Batch 2800/7662 eta: 2 days, 12:08:41.149928	Training Loss 7.0200 (7.2307)	Training Prec@1 92.773 (92.340)	Training Prec@5 96.094 (95.825)	
2022-03-26 01:52:44,298: ============================================================
2022-03-26 01:53:59,873: time cost, forward:0.017799366009815187, backward:0.0408361493492587, data cost:0.7012239827415622 
2022-03-26 01:53:59,873: ============================================================
2022-03-26 01:53:59,874: Epoch 2/38 Batch 2900/7662 eta: 2 days, 10:54:25.726418	Training Loss 6.7593 (7.2263)	Training Prec@1 91.992 (92.340)	Training Prec@5 95.508 (95.829)	
2022-03-26 01:53:59,874: ============================================================
2022-03-26 01:55:17,868: time cost, forward:0.017832342725310497, backward:0.04086568769751966, data cost:0.7018029037099077 
2022-03-26 01:55:17,869: ============================================================
2022-03-26 01:55:17,869: Epoch 2/38 Batch 3000/7662 eta: 2 days, 12:46:12.469493	Training Loss 7.1624 (7.2206)	Training Prec@1 91.211 (92.356)	Training Prec@5 95.898 (95.840)	
2022-03-26 01:55:17,869: ============================================================
2022-03-26 01:56:35,808: time cost, forward:0.01780194249911707, backward:0.04085226249756371, data cost:0.7021144154995785 
2022-03-26 01:56:35,834: ============================================================
2022-03-26 01:56:35,835: Epoch 2/38 Batch 3100/7662 eta: 2 days, 12:43:31.399482	Training Loss 6.9488 (7.2156)	Training Prec@1 93.555 (92.366)	Training Prec@5 96.875 (95.845)	
2022-03-26 01:56:35,836: ============================================================
2022-03-26 01:57:49,617: time cost, forward:0.01783424513382478, backward:0.040864210868112816, data cost:0.7015741135262444 
2022-03-26 01:57:49,617: ============================================================
2022-03-26 01:57:49,618: Epoch 2/38 Batch 3200/7662 eta: 2 days, 9:26:50.589103	Training Loss 7.2263 (7.2100)	Training Prec@1 90.820 (92.375)	Training Prec@5 94.922 (95.853)	
2022-03-26 01:57:49,618: ============================================================
2022-03-26 01:59:05,589: time cost, forward:0.017779660752485216, backward:0.04080588545138708, data cost:0.7016392257149272 
2022-03-26 01:59:05,589: ============================================================
2022-03-26 01:59:05,590: Epoch 2/38 Batch 3300/7662 eta: 2 days, 11:07:49.350932	Training Loss 7.0389 (7.2052)	Training Prec@1 91.992 (92.384)	Training Prec@5 95.703 (95.859)	
2022-03-26 01:59:05,590: ============================================================
2022-03-26 02:00:21,721: time cost, forward:0.01772853590944789, backward:0.040750283709551596, data cost:0.7017103337862801 
2022-03-26 02:00:21,723: ============================================================
2022-03-26 02:00:21,724: Epoch 2/38 Batch 3400/7662 eta: 2 days, 11:14:07.182224	Training Loss 7.1164 (7.1999)	Training Prec@1 91.992 (92.398)	Training Prec@5 96.289 (95.866)	
2022-03-26 02:00:21,724: ============================================================
2022-03-26 02:01:39,690: time cost, forward:0.01774931730764803, backward:0.04074143682012697, data cost:0.7020365670600187 
2022-03-26 02:01:39,690: ============================================================
2022-03-26 02:01:39,690: Epoch 2/38 Batch 3500/7662 eta: 2 days, 12:38:23.160948	Training Loss 6.8095 (7.1940)	Training Prec@1 93.750 (92.415)	Training Prec@5 96.484 (95.875)	
2022-03-26 02:01:39,690: ============================================================
2022-03-26 02:02:57,054: time cost, forward:0.017728754400246405, backward:0.04073124006080044, data cost:0.7023249471409515 
2022-03-26 02:02:57,054: ============================================================
2022-03-26 02:02:57,055: Epoch 2/38 Batch 3600/7662 eta: 2 days, 12:08:58.544595	Training Loss 7.0500 (7.1883)	Training Prec@1 93.750 (92.432)	Training Prec@5 97.070 (95.888)	
2022-03-26 02:02:57,055: ============================================================
2022-03-26 02:04:12,760: time cost, forward:0.01772824613814033, backward:0.0407001570644621, data cost:0.7024572809569479 
2022-03-26 02:04:12,760: ============================================================
2022-03-26 02:04:12,760: Epoch 2/38 Batch 3700/7662 eta: 2 days, 10:50:21.033929	Training Loss 7.2905 (7.1830)	Training Prec@1 92.773 (92.451)	Training Prec@5 95.703 (95.896)	
2022-03-26 02:04:12,760: ============================================================
2022-03-26 02:05:27,190: time cost, forward:0.01772758420375373, backward:0.040577061272320164, data cost:0.7020834449342315 
2022-03-26 02:05:27,190: ============================================================
2022-03-26 02:05:27,190: Epoch 2/38 Batch 3800/7662 eta: 2 days, 9:49:37.296769	Training Loss 6.9359 (7.1773)	Training Prec@1 92.383 (92.465)	Training Prec@5 96.094 (95.906)	
2022-03-26 02:05:27,191: ============================================================
2022-03-26 02:06:44,326: time cost, forward:0.01769600546827803, backward:0.0404018708209742, data cost:0.7024854181607156 
2022-03-26 02:06:44,326: ============================================================
2022-03-26 02:06:44,326: Epoch 2/38 Batch 3900/7662 eta: 2 days, 11:54:27.984341	Training Loss 6.8043 (7.1720)	Training Prec@1 94.531 (92.480)	Training Prec@5 97.656 (95.917)	
2022-03-26 02:06:44,326: ============================================================
2022-03-26 02:07:57,661: time cost, forward:0.017675667233573226, backward:0.040213505188564445, data cost:0.7018180523672293 
2022-03-26 02:07:57,680: ============================================================
2022-03-26 02:07:57,681: Epoch 2/38 Batch 4000/7662 eta: 2 days, 8:57:00.204806	Training Loss 7.3033 (7.1670)	Training Prec@1 91.406 (92.489)	Training Prec@5 95.117 (95.920)	
2022-03-26 02:07:57,681: ============================================================
2022-03-26 02:09:16,828: time cost, forward:0.01767222588746889, backward:0.040148652800992515, data cost:0.7026220628999448 
2022-03-26 02:09:16,831: ============================================================
2022-03-26 02:09:16,832: Epoch 2/38 Batch 4100/7662 eta: 2 days, 13:25:44.452098	Training Loss 6.9167 (7.1614)	Training Prec@1 93.164 (92.501)	Training Prec@5 94.531 (95.928)	
2022-03-26 02:09:16,833: ============================================================
2022-03-26 02:10:29,606: time cost, forward:0.017673769233396548, backward:0.04013301509140389, data cost:0.7020166664073569 
2022-03-26 02:10:29,606: ============================================================
2022-03-26 02:10:29,607: Epoch 2/38 Batch 4200/7662 eta: 2 days, 8:27:37.480549	Training Loss 6.6685 (7.1562)	Training Prec@1 92.578 (92.513)	Training Prec@5 96.289 (95.934)	
2022-03-26 02:10:29,607: ============================================================
2022-03-26 02:11:44,045: time cost, forward:0.017654670230397847, backward:0.04007099827768415, data cost:0.7017199924364287 
2022-03-26 02:11:44,046: ============================================================
2022-03-26 02:11:44,046: Epoch 2/38 Batch 4300/7662 eta: 2 days, 9:43:51.167915	Training Loss 6.8372 (7.1507)	Training Prec@1 94.727 (92.525)	Training Prec@5 96.680 (95.941)	
2022-03-26 02:11:44,046: ============================================================
2022-03-26 02:13:00,358: time cost, forward:0.017710071499983434, backward:0.040157672626697415, data cost:0.7014882328239834 
2022-03-26 02:13:00,359: ============================================================
2022-03-26 02:13:00,359: Epoch 2/38 Batch 4400/7662 eta: 2 days, 11:09:46.256994	Training Loss 6.7648 (7.1460)	Training Prec@1 94.922 (92.536)	Training Prec@5 97.266 (95.949)	
2022-03-26 02:13:00,359: ============================================================
2022-03-26 02:14:17,518: time cost, forward:0.017725285860558937, backward:0.040163908886575624, data cost:0.7017186363688255 
2022-03-26 02:14:17,519: ============================================================
2022-03-26 02:14:17,519: Epoch 2/38 Batch 4500/7662 eta: 2 days, 11:47:52.143799	Training Loss 6.9913 (7.1407)	Training Prec@1 93.945 (92.551)	Training Prec@5 96.875 (95.960)	
2022-03-26 02:14:17,519: ============================================================
2022-03-26 02:15:34,374: time cost, forward:0.017741644374700598, backward:0.04022863979675532, data cost:0.7019159593227559 
2022-03-26 02:15:34,374: ============================================================
2022-03-26 02:15:34,374: Epoch 2/38 Batch 4600/7662 eta: 2 days, 11:32:25.888016	Training Loss 7.0121 (7.1360)	Training Prec@1 91.211 (92.561)	Training Prec@5 95.508 (95.968)	
2022-03-26 02:15:34,375: ============================================================
2022-03-26 02:16:49,361: time cost, forward:0.01772841287942916, backward:0.04016810763412446, data cost:0.7016655985764632 
2022-03-26 02:16:49,366: ============================================================
2022-03-26 02:16:49,367: Epoch 2/38 Batch 4700/7662 eta: 2 days, 10:04:34.045727	Training Loss 6.4795 (7.1315)	Training Prec@1 93.945 (92.571)	Training Prec@5 97.070 (95.974)	
2022-03-26 02:16:49,368: ============================================================
2022-03-26 02:18:07,564: time cost, forward:0.01773977319407796, backward:0.040222150729482035, data cost:0.7021140407884983 
2022-03-26 02:18:07,587: ============================================================
2022-03-26 02:18:07,588: Epoch 2/38 Batch 4800/7662 eta: 2 days, 12:33:18.271645	Training Loss 6.7754 (7.1265)	Training Prec@1 94.141 (92.581)	Training Prec@5 97.070 (95.980)	
2022-03-26 02:18:07,588: ============================================================
2022-03-26 02:19:23,200: time cost, forward:0.01775355873411591, backward:0.04022238604461302, data cost:0.7019940025588887 
2022-03-26 02:19:23,201: ============================================================
2022-03-26 02:19:23,201: Epoch 2/38 Batch 4900/7662 eta: 2 days, 10:30:54.227084	Training Loss 6.6967 (7.1208)	Training Prec@1 92.578 (92.597)	Training Prec@5 96.094 (95.990)	
2022-03-26 02:19:23,201: ============================================================
2022-03-26 02:20:37,965: time cost, forward:0.017762336999946986, backward:0.04021500439423517, data cost:0.7017085305164518 
2022-03-26 02:20:37,966: ============================================================
2022-03-26 02:20:37,966: Epoch 2/38 Batch 5000/7662 eta: 2 days, 9:50:17.677444	Training Loss 6.8633 (7.1155)	Training Prec@1 94.336 (92.611)	Training Prec@5 98.242 (95.999)	
2022-03-26 02:20:37,966: ============================================================
2022-03-26 02:21:55,549: time cost, forward:0.01775511355230822, backward:0.04017360814998468, data cost:0.7020261154896746 
2022-03-26 02:21:55,550: ============================================================
2022-03-26 02:21:55,551: Epoch 2/38 Batch 5100/7662 eta: 2 days, 11:59:50.212738	Training Loss 6.8751 (7.1105)	Training Prec@1 93.359 (92.625)	Training Prec@5 97.461 (96.007)	
2022-03-26 02:21:55,551: ============================================================
2022-03-26 02:23:11,764: time cost, forward:0.017744205804668175, backward:0.04017298385303143, data cost:0.7020482454742003 
2022-03-26 02:23:11,765: ============================================================
2022-03-26 02:23:11,765: Epoch 2/38 Batch 5200/7662 eta: 2 days, 10:55:02.123964	Training Loss 6.7333 (7.1056)	Training Prec@1 94.727 (92.638)	Training Prec@5 97.070 (96.015)	
2022-03-26 02:23:11,765: ============================================================
2022-03-26 02:24:27,910: time cost, forward:0.017731441059389706, backward:0.0401999065844062, data cost:0.7020327600809195 
2022-03-26 02:24:27,910: ============================================================
2022-03-26 02:24:27,911: Epoch 2/38 Batch 5300/7662 eta: 2 days, 10:50:34.184700	Training Loss 6.8597 (7.1007)	Training Prec@1 93.945 (92.650)	Training Prec@5 96.680 (96.022)	
2022-03-26 02:24:27,911: ============================================================
2022-03-26 02:25:45,326: time cost, forward:0.017736412812480444, backward:0.04023188669431163, data cost:0.7022246297012106 
2022-03-26 02:25:45,326: ============================================================
2022-03-26 02:25:45,326: Epoch 2/38 Batch 5400/7662 eta: 2 days, 11:48:08.511195	Training Loss 6.7684 (7.0956)	Training Prec@1 93.359 (92.663)	Training Prec@5 96.680 (96.030)	
2022-03-26 02:25:45,327: ============================================================
2022-03-26 02:27:02,602: time cost, forward:0.01773606523380949, backward:0.04020532739663215, data cost:0.7023125733217558 
2022-03-26 02:27:02,605: ============================================================
2022-03-26 02:27:02,606: Epoch 2/38 Batch 5500/7662 eta: 2 days, 11:40:32.879604	Training Loss 6.6796 (7.0906)	Training Prec@1 93.164 (92.677)	Training Prec@5 96.484 (96.039)	
2022-03-26 02:27:02,607: ============================================================
2022-03-26 02:28:21,072: time cost, forward:0.017725771336624466, backward:0.04026995618165785, data cost:0.7028164859754015 
2022-03-26 02:28:21,073: ============================================================
2022-03-26 02:28:21,073: Epoch 2/38 Batch 5600/7662 eta: 2 days, 12:34:16.226125	Training Loss 6.5710 (7.0855)	Training Prec@1 93.359 (92.690)	Training Prec@5 95.898 (96.047)	
2022-03-26 02:28:21,073: ============================================================
2022-03-26 02:29:36,649: time cost, forward:0.017698621599271352, backward:0.04019431964119896, data cost:0.702822627802024 
2022-03-26 02:29:36,650: ============================================================
2022-03-26 02:29:36,651: Epoch 2/38 Batch 5700/7662 eta: 2 days, 10:19:11.910589	Training Loss 6.6027 (7.0805)	Training Prec@1 93.945 (92.704)	Training Prec@5 96.484 (96.057)	
2022-03-26 02:29:36,651: ============================================================
2022-03-26 02:30:52,445: time cost, forward:0.017684093609537044, backward:0.04019920902840946, data cost:0.7027108110545277 
2022-03-26 02:30:52,445: ============================================================
2022-03-26 02:30:52,445: Epoch 2/38 Batch 5800/7662 eta: 2 days, 10:27:56.790927	Training Loss 6.7149 (7.0757)	Training Prec@1 93.750 (92.713)	Training Prec@5 97.266 (96.062)	
2022-03-26 02:30:52,445: ============================================================
2022-03-26 02:32:07,495: time cost, forward:0.017675558052379855, backward:0.04018837275151823, data cost:0.7025720323823553 
2022-03-26 02:32:07,496: ============================================================
2022-03-26 02:32:07,496: Epoch 2/38 Batch 5900/7662 eta: 2 days, 9:52:17.162602	Training Loss 7.0170 (7.0706)	Training Prec@1 92.969 (92.725)	Training Prec@5 95.898 (96.070)	
2022-03-26 02:32:07,496: ============================================================
2022-03-26 02:33:24,559: time cost, forward:0.017660651013818973, backward:0.04016556515656306, data cost:0.7026189610766935 
2022-03-26 02:33:24,559: ============================================================
2022-03-26 02:33:24,560: Epoch 2/38 Batch 6000/7662 eta: 2 days, 11:24:08.182815	Training Loss 6.6754 (7.0652)	Training Prec@1 93.945 (92.740)	Training Prec@5 97.266 (96.078)	
2022-03-26 02:33:24,560: ============================================================
2022-03-26 02:34:39,767: time cost, forward:0.017635393893255486, backward:0.04013152883998448, data cost:0.7025192599352079 
2022-03-26 02:34:39,768: ============================================================
2022-03-26 02:34:39,769: Epoch 2/38 Batch 6100/7662 eta: 2 days, 9:57:04.936436	Training Loss 6.8866 (7.0604)	Training Prec@1 93.359 (92.752)	Training Prec@5 96.680 (96.084)	
2022-03-26 02:34:39,769: ============================================================
2022-03-26 02:35:56,145: time cost, forward:0.01764983987785151, backward:0.04011993055132863, data cost:0.7026831623738303 
2022-03-26 02:35:56,146: ============================================================
2022-03-26 02:35:56,146: Epoch 2/38 Batch 6200/7662 eta: 2 days, 10:49:50.176264	Training Loss 6.9193 (7.0557)	Training Prec@1 92.578 (92.763)	Training Prec@5 98.047 (96.093)	
2022-03-26 02:35:56,146: ============================================================
2022-03-26 02:37:13,118: time cost, forward:0.017659250223971603, backward:0.040149349658370755, data cost:0.7027534488496903 
2022-03-26 02:37:13,118: ============================================================
2022-03-26 02:37:13,119: Epoch 2/38 Batch 6300/7662 eta: 2 days, 11:16:05.076839	Training Loss 6.7322 (7.0508)	Training Prec@1 93.750 (92.778)	Training Prec@5 96.484 (96.103)	
2022-03-26 02:37:13,119: ============================================================
2022-03-26 02:38:29,934: time cost, forward:0.017658732984006022, backward:0.04017728238315168, data cost:0.7028384879336244 
2022-03-26 02:38:29,935: ============================================================
2022-03-26 02:38:29,935: Epoch 2/38 Batch 6400/7662 eta: 2 days, 11:07:34.323783	Training Loss 6.8552 (7.0460)	Training Prec@1 92.188 (92.788)	Training Prec@5 95.703 (96.109)	
2022-03-26 02:38:29,935: ============================================================
2022-03-26 02:39:48,504: time cost, forward:0.017683621937906877, backward:0.04017577697394682, data cost:0.7030408046010421 
2022-03-26 02:39:48,507: ============================================================
2022-03-26 02:39:48,508: Epoch 2/38 Batch 6500/7662 eta: 2 days, 12:27:20.393921	Training Loss 6.8023 (7.0412)	Training Prec@1 92.969 (92.799)	Training Prec@5 95.703 (96.115)	
2022-03-26 02:39:48,508: ============================================================
2022-03-26 02:41:07,755: time cost, forward:0.01769961933599022, backward:0.04021277104675598, data cost:0.7034575253801827 
2022-03-26 02:41:07,759: ============================================================
2022-03-26 02:41:07,761: Epoch 2/38 Batch 6600/7662 eta: 2 days, 12:57:27.658444	Training Loss 6.6054 (7.0366)	Training Prec@1 92.773 (92.813)	Training Prec@5 96.875 (96.124)	
2022-03-26 02:41:07,761: ============================================================
2022-03-26 02:42:25,704: time cost, forward:0.01770889874731788, backward:0.040231591072486826, data cost:0.7037641995699482 
2022-03-26 02:42:25,704: ============================================================
2022-03-26 02:42:25,704: Epoch 2/38 Batch 6700/7662 eta: 2 days, 11:55:45.895972	Training Loss 6.9602 (7.0322)	Training Prec@1 91.797 (92.824)	Training Prec@5 96.289 (96.133)	
2022-03-26 02:42:25,705: ============================================================
2022-03-26 02:43:41,492: time cost, forward:0.017703097784303536, backward:0.04025575051782482, data cost:0.7036896839021216 
2022-03-26 02:43:41,493: ============================================================
2022-03-26 02:43:41,493: Epoch 2/38 Batch 6800/7662 eta: 2 days, 10:15:02.638654	Training Loss 6.6144 (7.0277)	Training Prec@1 94.531 (92.837)	Training Prec@5 97.461 (96.140)	
2022-03-26 02:43:41,493: ============================================================
2022-03-26 02:45:00,603: time cost, forward:0.017731731742132332, backward:0.04028462212851884, data cost:0.7040112383867765 
2022-03-26 02:45:00,604: ============================================================
2022-03-26 02:45:00,604: Epoch 2/38 Batch 6900/7662 eta: 2 days, 12:46:57.645003	Training Loss 6.8185 (7.0232)	Training Prec@1 92.383 (92.850)	Training Prec@5 95.898 (96.147)	
2022-03-26 02:45:00,604: ============================================================
2022-03-26 02:46:19,454: time cost, forward:0.017758875987345466, backward:0.04032358780539467, data cost:0.704302736036538 
2022-03-26 02:46:19,457: ============================================================
2022-03-26 02:46:19,458: Epoch 2/38 Batch 7000/7662 eta: 2 days, 12:33:45.824989	Training Loss 6.6873 (7.0184)	Training Prec@1 92.969 (92.864)	Training Prec@5 96.289 (96.157)	
2022-03-26 02:46:19,458: ============================================================
2022-03-26 02:47:38,357: time cost, forward:0.017773132321531965, backward:0.040361273572518466, data cost:0.704591296864053 
2022-03-26 02:47:38,358: ============================================================
2022-03-26 02:47:38,358: Epoch 2/38 Batch 7100/7662 eta: 2 days, 12:34:36.324784	Training Loss 6.9409 (7.0136)	Training Prec@1 93.359 (92.877)	Training Prec@5 95.312 (96.167)	
2022-03-26 02:47:38,358: ============================================================
2022-03-26 02:48:56,468: time cost, forward:0.017795389171175898, backward:0.04039446462076693, data cost:0.7047183369245608 
2022-03-26 02:48:56,471: ============================================================
2022-03-26 02:48:56,472: Epoch 2/38 Batch 7200/7662 eta: 2 days, 11:57:03.249186	Training Loss 6.7231 (7.0092)	Training Prec@1 94.141 (92.887)	Training Prec@5 96.875 (96.172)	
2022-03-26 02:48:56,472: ============================================================
2022-03-26 02:50:13,645: time cost, forward:0.017817843889664224, backward:0.04041582647293034, data cost:0.7047409309983531 
2022-03-26 02:50:13,648: ============================================================
2022-03-26 02:50:13,649: Epoch 2/38 Batch 7300/7662 eta: 2 days, 11:12:40.285523	Training Loss 6.6134 (7.0047)	Training Prec@1 92.188 (92.896)	Training Prec@5 94.531 (96.179)	
2022-03-26 02:50:13,650: ============================================================
2022-03-26 02:51:29,474: time cost, forward:0.01781888213700935, backward:0.040347952055824754, data cost:0.7047342274829912 
2022-03-26 02:51:29,477: ============================================================
2022-03-26 02:51:29,478: Epoch 2/38 Batch 7400/7662 eta: 2 days, 10:09:20.194052	Training Loss 6.4213 (6.9998)	Training Prec@1 96.289 (92.910)	Training Prec@5 98.438 (96.188)	
2022-03-26 02:51:29,479: ============================================================
2022-03-26 02:52:47,024: time cost, forward:0.01781601107172973, backward:0.04029396798296251, data cost:0.7050384989991667 
2022-03-26 02:52:47,024: ============================================================
2022-03-26 02:52:47,025: Epoch 2/38 Batch 7500/7662 eta: 2 days, 11:27:05.730597	Training Loss 6.7098 (6.9963)	Training Prec@1 94.727 (92.917)	Training Prec@5 97.461 (96.191)	
2022-03-26 02:52:47,025: ============================================================
2022-03-26 02:54:05,303: time cost, forward:0.017808503172149437, backward:0.040276916172335316, data cost:0.7052501018838924 
2022-03-26 02:54:05,303: ============================================================
2022-03-26 02:54:05,304: Epoch 2/38 Batch 7600/7662 eta: 2 days, 11:59:27.949785	Training Loss 6.4731 (6.9920)	Training Prec@1 94.336 (92.927)	Training Prec@5 96.680 (96.197)	
2022-03-26 02:54:05,304: ============================================================
2022-03-26 02:54:55,730: Epoch: 2/38 eta: 2 days, 11:58:38.633992	Training Loss 6.6965 (6.9896)	Training Prec@1 94.336 (92.932)	Training Prec@5 96.484 (96.200)
2022-03-26 02:54:55,730: ============================================================
2022-03-26 02:56:16,949: time cost, forward:0.01591701941056685, backward:0.03500722634671914, data cost:0.7607500962536744 
2022-03-26 02:56:16,950: ============================================================
2022-03-26 02:56:16,950: Epoch 3/38 Batch 100/7662 eta: 2 days, 14:01:29.994230	Training Loss 6.2580 (6.2317)	Training Prec@1 95.703 (94.922)	Training Prec@5 97.461 (97.380)	
2022-03-26 02:56:16,951: ============================================================
2022-03-26 02:57:30,376: time cost, forward:0.0156676589544095, backward:0.03622697226366206, data cost:0.7164256177355895 
2022-03-26 02:57:30,378: ============================================================
2022-03-26 02:57:30,379: Epoch 3/38 Batch 200/7662 eta: 2 days, 8:13:12.351181	Training Loss 6.6872 (6.2622)	Training Prec@1 94.336 (94.882)	Training Prec@5 97.266 (97.423)	
2022-03-26 02:57:30,379: ============================================================
2022-03-26 02:58:49,188: time cost, forward:0.01638685261525438, backward:0.036973920554221676, data cost:0.7202076584997783 
2022-03-26 02:58:49,189: ============================================================
2022-03-26 02:58:49,190: Epoch 3/38 Batch 300/7662 eta: 2 days, 12:19:09.916806	Training Loss 6.2015 (6.3041)	Training Prec@1 94.922 (94.803)	Training Prec@5 97.656 (97.358)	
2022-03-26 02:58:49,190: ============================================================
2022-03-26 03:00:03,476: time cost, forward:0.015740489601192616, backward:0.03608911497551098, data cost:0.7139957124428044 
2022-03-26 03:00:03,479: ============================================================
2022-03-26 03:00:03,481: Epoch 3/38 Batch 400/7662 eta: 2 days, 8:50:21.429989	Training Loss 6.4284 (6.3351)	Training Prec@1 93.945 (94.720)	Training Prec@5 96.484 (97.308)	
2022-03-26 03:00:03,483: ============================================================
2022-03-26 03:01:20,655: time cost, forward:0.01577355245311179, backward:0.03586795525942632, data cost:0.7148246019780039 
2022-03-26 03:01:20,659: ============================================================
2022-03-26 03:01:20,659: Epoch 3/38 Batch 500/7662 eta: 2 days, 11:01:38.605260	Training Loss 6.4734 (6.3580)	Training Prec@1 93.359 (94.677)	Training Prec@5 96.484 (97.273)	
2022-03-26 03:01:20,660: ============================================================
2022-03-26 03:02:38,648: time cost, forward:0.015790503888774992, backward:0.036064931665716664, data cost:0.7167357526756886 
2022-03-26 03:02:38,652: ============================================================
2022-03-26 03:02:38,652: Epoch 3/38 Batch 600/7662 eta: 2 days, 11:37:42.232946	Training Loss 6.4967 (6.3829)	Training Prec@1 94.727 (94.634)	Training Prec@5 98.047 (97.233)	
2022-03-26 03:02:38,653: ============================================================
2022-03-26 03:03:53,309: time cost, forward:0.015673718568422593, backward:0.03584981987916349, data cost:0.7149054792647027 
2022-03-26 03:03:53,309: ============================================================
2022-03-26 03:03:53,310: Epoch 3/38 Batch 700/7662 eta: 2 days, 9:03:27.857740	Training Loss 6.5726 (6.4006)	Training Prec@1 93.945 (94.620)	Training Prec@5 97.461 (97.225)	
2022-03-26 03:03:53,310: ============================================================
2022-03-26 03:05:12,060: time cost, forward:0.01586698590590151, backward:0.0361229869092958, data cost:0.7162327447134502 
2022-03-26 03:05:12,060: ============================================================
2022-03-26 03:05:12,061: Epoch 3/38 Batch 800/7662 eta: 2 days, 12:09:51.240254	Training Loss 6.1557 (6.4170)	Training Prec@1 96.875 (94.589)	Training Prec@5 98.438 (97.213)	
2022-03-26 03:05:12,061: ============================================================
2022-03-26 03:06:29,623: time cost, forward:0.015953074307807694, backward:0.036147353646487364, data cost:0.7170589463464145 
2022-03-26 03:06:29,627: ============================================================
2022-03-26 03:06:29,628: Epoch 3/38 Batch 900/7662 eta: 2 days, 11:14:15.851553	Training Loss 6.5804 (6.4319)	Training Prec@1 94.141 (94.546)	Training Prec@5 96.875 (97.186)	
2022-03-26 03:06:29,630: ============================================================
2022-03-26 03:07:45,761: time cost, forward:0.016004767384495702, backward:0.03655186835471336, data cost:0.7159375552539233 
2022-03-26 03:07:45,761: ============================================================
2022-03-26 03:07:45,762: Epoch 3/38 Batch 1000/7662 eta: 2 days, 10:07:22.494567	Training Loss 6.4314 (6.4444)	Training Prec@1 95.117 (94.520)	Training Prec@5 97.461 (97.167)	
2022-03-26 03:07:45,762: ============================================================
2022-03-26 03:09:07,935: time cost, forward:0.01607336642201973, backward:0.03669844853867174, data cost:0.7204338686372932 
2022-03-26 03:09:07,936: ============================================================
2022-03-26 03:09:07,936: Epoch 3/38 Batch 1100/7662 eta: 2 days, 14:42:40.219493	Training Loss 6.6375 (6.4571)	Training Prec@1 94.141 (94.469)	Training Prec@5 97.070 (97.139)	
2022-03-26 03:09:07,936: ============================================================
2022-03-26 03:10:23,145: time cost, forward:0.01615354197536338, backward:0.03676290587647146, data cost:0.7183425231612256 
2022-03-26 03:10:23,145: ============================================================
2022-03-26 03:10:23,146: Epoch 3/38 Batch 1200/7662 eta: 2 days, 9:22:30.630815	Training Loss 6.6255 (6.4674)	Training Prec@1 94.336 (94.437)	Training Prec@5 97.266 (97.123)	
2022-03-26 03:10:23,146: ============================================================
2022-03-26 03:11:38,286: time cost, forward:0.016008468478160974, backward:0.0366384236054571, data cost:0.7169564043768926 
2022-03-26 03:11:38,287: ============================================================
2022-03-26 03:11:38,287: Epoch 3/38 Batch 1300/7662 eta: 2 days, 9:18:07.835862	Training Loss 6.6520 (6.4741)	Training Prec@1 95.312 (94.420)	Training Prec@5 97.266 (97.111)	
2022-03-26 03:11:38,287: ============================================================
2022-03-26 03:12:54,769: time cost, forward:0.01607730526682136, backward:0.03674293399453589, data cost:0.7158233609857347 
2022-03-26 03:12:54,772: ============================================================
2022-03-26 03:12:54,773: Epoch 3/38 Batch 1400/7662 eta: 2 days, 10:18:22.473189	Training Loss 6.4127 (6.4818)	Training Prec@1 93.555 (94.385)	Training Prec@5 97.266 (97.089)	
2022-03-26 03:12:54,775: ============================================================
2022-03-26 03:14:12,678: time cost, forward:0.016021641832419123, backward:0.03664348346539702, data cost:0.7170850131573718 
2022-03-26 03:14:12,678: ============================================================
2022-03-26 03:14:12,678: Epoch 3/38 Batch 1500/7662 eta: 2 days, 11:22:00.027484	Training Loss 6.6371 (6.4877)	Training Prec@1 91.992 (94.349)	Training Prec@5 96.094 (97.069)	
2022-03-26 03:14:12,679: ============================================================
2022-03-26 03:15:33,036: time cost, forward:0.015969831098087733, backward:0.03674038266151528, data cost:0.7185119076622062 
2022-03-26 03:15:33,039: ============================================================
2022-03-26 03:15:33,041: Epoch 3/38 Batch 1600/7662 eta: 2 days, 13:12:58.357803	Training Loss 6.9475 (6.4918)	Training Prec@1 93.359 (94.335)	Training Prec@5 96.680 (97.062)	
2022-03-26 03:15:33,041: ============================================================
2022-03-26 03:16:52,541: time cost, forward:0.01607796400697741, backward:0.03684350769263004, data cost:0.7200965067440794 
2022-03-26 03:16:52,542: ============================================================
2022-03-26 03:16:52,542: Epoch 3/38 Batch 1700/7662 eta: 2 days, 12:32:21.285889	Training Loss 6.6322 (6.4970)	Training Prec@1 93.945 (94.314)	Training Prec@5 96.484 (97.051)	
2022-03-26 03:16:52,542: ============================================================
2022-03-26 03:18:09,698: time cost, forward:0.01608376956237827, backward:0.03718893338469017, data cost:0.7194970080824677 
2022-03-26 03:18:09,698: ============================================================
2022-03-26 03:18:09,699: Epoch 3/38 Batch 1800/7662 eta: 2 days, 10:43:53.896248	Training Loss 6.3904 (6.5007)	Training Prec@1 94.336 (94.297)	Training Prec@5 97.852 (97.043)	
2022-03-26 03:18:09,699: ============================================================
2022-03-26 03:19:22,521: time cost, forward:0.016030554899483872, backward:0.03724218934005408, data cost:0.7171733639251564 
2022-03-26 03:19:22,522: ============================================================
2022-03-26 03:19:22,522: Epoch 3/38 Batch 1900/7662 eta: 2 days, 7:24:47.144774	Training Loss 6.2738 (6.5035)	Training Prec@1 95.508 (94.288)	Training Prec@5 98.242 (97.039)	
2022-03-26 03:19:22,522: ============================================================
2022-03-26 03:20:44,390: time cost, forward:0.016119561951538512, backward:0.03738267687692113, data cost:0.7189095143141181 
2022-03-26 03:20:44,390: ============================================================
2022-03-26 03:20:44,391: Epoch 3/38 Batch 2000/7662 eta: 2 days, 14:16:23.469687	Training Loss 6.5066 (6.5087)	Training Prec@1 94.727 (94.260)	Training Prec@5 98.047 (97.023)	
2022-03-26 03:20:44,391: ============================================================
2022-03-26 03:22:00,210: time cost, forward:0.016138315314392408, backward:0.037611425803240395, data cost:0.7182467505158329 
2022-03-26 03:22:00,211: ============================================================
2022-03-26 03:22:00,211: Epoch 3/38 Batch 2100/7662 eta: 2 days, 9:39:04.864901	Training Loss 6.5672 (6.5102)	Training Prec@1 93.750 (94.249)	Training Prec@5 96.289 (97.013)	
2022-03-26 03:22:00,211: ============================================================
2022-03-26 03:23:17,334: time cost, forward:0.016076508626551887, backward:0.037606504083818174, data cost:0.7182283706153291 
2022-03-26 03:23:17,335: ============================================================
2022-03-26 03:23:17,335: Epoch 3/38 Batch 2200/7662 eta: 2 days, 10:37:17.565837	Training Loss 6.4254 (6.5126)	Training Prec@1 94.336 (94.235)	Training Prec@5 96.484 (97.002)	
2022-03-26 03:23:17,335: ============================================================
2022-03-26 03:24:35,641: time cost, forward:0.0160423779083159, backward:0.037636570538474766, data cost:0.7186678337397499 
2022-03-26 03:24:35,641: ============================================================
2022-03-26 03:24:35,642: Epoch 3/38 Batch 2300/7662 eta: 2 days, 11:29:54.012881	Training Loss 6.5399 (6.5120)	Training Prec@1 94.727 (94.239)	Training Prec@5 97.852 (97.008)	
2022-03-26 03:24:35,642: ============================================================
2022-03-26 03:25:52,136: time cost, forward:0.01611385458755016, backward:0.03788178918161905, data cost:0.7179558574283754 
2022-03-26 03:25:52,136: ============================================================
2022-03-26 03:25:52,137: Epoch 3/38 Batch 2400/7662 eta: 2 days, 10:06:02.468079	Training Loss 6.4247 (6.5116)	Training Prec@1 94.922 (94.232)	Training Prec@5 97.070 (97.004)	
2022-03-26 03:25:52,137: ============================================================
2022-03-26 03:27:12,847: time cost, forward:0.016191704361951078, backward:0.038048876815435645, data cost:0.7187233565568256 
2022-03-26 03:27:12,849: ============================================================
2022-03-26 03:27:12,850: Epoch 3/38 Batch 2500/7662 eta: 2 days, 13:16:54.817401	Training Loss 6.5873 (6.5125)	Training Prec@1 93.164 (94.218)	Training Prec@5 95.703 (96.997)	
2022-03-26 03:27:12,850: ============================================================
2022-03-26 03:28:28,958: time cost, forward:0.01627376438242144, backward:0.038150337394635095, data cost:0.7183661026971163 
2022-03-26 03:28:28,958: ============================================================
2022-03-26 03:28:28,958: Epoch 3/38 Batch 2600/7662 eta: 2 days, 9:45:54.799651	Training Loss 6.7439 (6.5124)	Training Prec@1 94.141 (94.209)	Training Prec@5 97.266 (96.994)	
2022-03-26 03:28:28,959: ============================================================
2022-03-26 03:29:43,041: time cost, forward:0.016332681199363888, backward:0.038087163513878974, data cost:0.7169778677391626 
2022-03-26 03:29:43,043: ============================================================
2022-03-26 03:29:43,043: Epoch 3/38 Batch 2700/7662 eta: 2 days, 8:12:30.054380	Training Loss 6.6652 (6.5136)	Training Prec@1 94.336 (94.200)	Training Prec@5 96.680 (96.987)	
2022-03-26 03:29:43,044: ============================================================
2022-03-26 03:31:01,788: time cost, forward:0.01646165278776495, backward:0.038149017229724164, data cost:0.7174363614150822 
2022-03-26 03:31:01,789: ============================================================
2022-03-26 03:31:01,789: Epoch 3/38 Batch 2800/7662 eta: 2 days, 11:43:21.617870	Training Loss 6.5815 (6.5139)	Training Prec@1 93.555 (94.197)	Training Prec@5 96.484 (96.987)	
2022-03-26 03:31:01,789: ============================================================
2022-03-26 03:32:15,065: time cost, forward:0.01637565139738927, backward:0.038090993388433546, data cost:0.7159434205377954 
2022-03-26 03:32:15,067: ============================================================
2022-03-26 03:32:15,069: Epoch 3/38 Batch 2900/7662 eta: 2 days, 7:33:23.412622	Training Loss 6.4414 (6.5153)	Training Prec@1 95.117 (94.185)	Training Prec@5 97.070 (96.980)	
2022-03-26 03:32:15,069: ============================================================
2022-03-26 03:33:34,524: time cost, forward:0.016406557090125826, backward:0.0381880412303674, data cost:0.7167272418290228 
2022-03-26 03:33:34,525: ============================================================
2022-03-26 03:33:34,525: Epoch 3/38 Batch 3000/7662 eta: 2 days, 12:13:05.276575	Training Loss 6.3081 (6.5150)	Training Prec@1 93.945 (94.177)	Training Prec@5 97.852 (96.976)	
2022-03-26 03:33:34,526: ============================================================
2022-03-26 03:34:50,121: time cost, forward:0.016451160997758184, backward:0.038285361370297165, data cost:0.7161109193596927 
2022-03-26 03:34:50,121: ============================================================
2022-03-26 03:34:50,122: Epoch 3/38 Batch 3100/7662 eta: 2 days, 9:16:16.079329	Training Loss 6.5630 (6.5138)	Training Prec@1 93.164 (94.182)	Training Prec@5 96.680 (96.979)	
2022-03-26 03:34:50,122: ============================================================
2022-03-26 03:36:08,246: time cost, forward:0.016535140082552195, backward:0.03840316403989085, data cost:0.716197576102483 
2022-03-26 03:36:08,248: ============================================================
2022-03-26 03:36:08,249: Epoch 3/38 Batch 3200/7662 eta: 2 days, 11:09:59.828813	Training Loss 6.4086 (6.5130)	Training Prec@1 95.117 (94.179)	Training Prec@5 97.070 (96.974)	
2022-03-26 03:36:08,249: ============================================================
2022-03-26 03:37:24,343: time cost, forward:0.016552420954662368, backward:0.03846874075175849, data cost:0.7155718076370022 
2022-03-26 03:37:24,343: ============================================================
2022-03-26 03:37:24,343: Epoch 3/38 Batch 3300/7662 eta: 2 days, 9:36:23.150175	Training Loss 6.2140 (6.5130)	Training Prec@1 94.336 (94.175)	Training Prec@5 97.070 (96.971)	
2022-03-26 03:37:24,344: ============================================================
2022-03-26 03:38:39,896: time cost, forward:0.01660150007206961, backward:0.038605368673959244, data cost:0.7149153738451131 
2022-03-26 03:38:39,897: ============================================================
2022-03-26 03:38:39,897: Epoch 3/38 Batch 3400/7662 eta: 2 days, 9:10:33.241968	Training Loss 6.6365 (6.5130)	Training Prec@1 94.336 (94.168)	Training Prec@5 96.289 (96.967)	
2022-03-26 03:38:39,897: ============================================================
2022-03-26 03:39:52,954: time cost, forward:0.01662024180185253, backward:0.03869103199756292, data cost:0.7137620673925068 
2022-03-26 03:39:52,954: ============================================================
2022-03-26 03:39:52,954: Epoch 3/38 Batch 3500/7662 eta: 2 days, 7:15:59.068231	Training Loss 6.4708 (6.5133)	Training Prec@1 93.555 (94.164)	Training Prec@5 96.289 (96.965)	
2022-03-26 03:39:52,955: ============================================================
2022-03-26 03:41:09,934: time cost, forward:0.01660706805467407, backward:0.038751034578968335, data cost:0.7135989436774692 
2022-03-26 03:41:09,934: ============================================================
2022-03-26 03:41:09,935: Epoch 3/38 Batch 3600/7662 eta: 2 days, 10:12:45.726739	Training Loss 6.8082 (6.5132)	Training Prec@1 93.945 (94.158)	Training Prec@5 96.875 (96.965)	
2022-03-26 03:41:09,935: ============================================================
2022-03-26 03:42:27,674: time cost, forward:0.016630608895624868, backward:0.03885014606959499, data cost:0.7136199710239556 
2022-03-26 03:42:27,675: ============================================================
2022-03-26 03:42:27,676: Epoch 3/38 Batch 3700/7662 eta: 2 days, 10:45:58.577326	Training Loss 6.4607 (6.5124)	Training Prec@1 94.336 (94.154)	Training Prec@5 97.266 (96.962)	
2022-03-26 03:42:27,676: ============================================================
2022-03-26 03:43:42,658: time cost, forward:0.016637840783103385, backward:0.038899579152335426, data cost:0.7131568646236419 
2022-03-26 03:43:42,659: ============================================================
2022-03-26 03:43:42,659: Epoch 3/38 Batch 3800/7662 eta: 2 days, 8:39:40.709013	Training Loss 6.9756 (6.5116)	Training Prec@1 90.430 (94.151)	Training Prec@5 94.336 (96.959)	
2022-03-26 03:43:42,660: ============================================================
2022-03-26 03:44:59,651: time cost, forward:0.016656107766776857, backward:0.03900340343934201, data cost:0.7130238567752452 
2022-03-26 03:44:59,651: ============================================================
2022-03-26 03:44:59,652: Epoch 3/38 Batch 3900/7662 eta: 2 days, 10:09:27.042698	Training Loss 6.7388 (6.5115)	Training Prec@1 93.555 (94.148)	Training Prec@5 96.680 (96.956)	
2022-03-26 03:44:59,652: ============================================================
2022-03-26 03:46:16,721: time cost, forward:0.01666176483076076, backward:0.03908589888465616, data cost:0.7127942166110223 
2022-03-26 03:46:16,723: ============================================================
2022-03-26 03:46:16,724: Epoch 3/38 Batch 4000/7662 eta: 2 days, 10:11:47.589984	Training Loss 6.5060 (6.5118)	Training Prec@1 96.289 (94.145)	Training Prec@5 97.266 (96.955)	
2022-03-26 03:46:16,725: ============================================================
2022-03-26 03:47:30,946: time cost, forward:0.016675828578676298, backward:0.03912203292725697, data cost:0.712079340901483 
2022-03-26 03:47:30,948: ============================================================
2022-03-26 03:47:30,949: Epoch 3/38 Batch 4100/7662 eta: 2 days, 8:01:33.236563	Training Loss 6.0789 (6.5108)	Training Prec@1 95.508 (94.145)	Training Prec@5 96.680 (96.955)	
2022-03-26 03:47:30,950: ============================================================
2022-03-26 03:48:50,765: time cost, forward:0.016729957803597647, backward:0.039256813072482584, data cost:0.7125290633099622 
2022-03-26 03:48:50,767: ============================================================
2022-03-26 03:48:50,767: Epoch 3/38 Batch 4200/7662 eta: 2 days, 12:13:32.967207	Training Loss 6.4732 (6.5101)	Training Prec@1 93.164 (94.150)	Training Prec@5 96.289 (96.958)	
2022-03-26 03:48:50,767: ============================================================
2022-03-26 03:50:05,701: time cost, forward:0.016731119067149264, backward:0.0392676533363841, data cost:0.7121580801167635 
2022-03-26 03:50:05,702: ============================================================
2022-03-26 03:50:05,702: Epoch 3/38 Batch 4300/7662 eta: 2 days, 8:31:14.261373	Training Loss 6.2467 (6.5086)	Training Prec@1 95.508 (94.153)	Training Prec@5 98.438 (96.960)	
2022-03-26 03:50:05,702: ============================================================
2022-03-26 03:51:21,241: time cost, forward:0.016726104203449863, backward:0.03928675383810402, data cost:0.7116678840167199 
2022-03-26 03:51:21,242: ============================================================
2022-03-26 03:51:21,243: Epoch 3/38 Batch 4400/7662 eta: 2 days, 8:57:20.521748	Training Loss 6.6155 (6.5069)	Training Prec@1 93.164 (94.153)	Training Prec@5 96.289 (96.961)	
2022-03-26 03:51:21,243: ============================================================
2022-03-26 03:52:36,881: time cost, forward:0.016748571904613378, backward:0.03928918768549315, data cost:0.7115611046996481 
2022-03-26 03:52:36,882: ============================================================
2022-03-26 03:52:36,882: Epoch 3/38 Batch 4500/7662 eta: 2 days, 9:00:36.163100	Training Loss 6.2122 (6.5052)	Training Prec@1 95.508 (94.154)	Training Prec@5 98.828 (96.961)	
2022-03-26 03:52:36,882: ============================================================
2022-03-26 03:53:51,986: time cost, forward:0.016739007467082023, backward:0.03932711517688994, data cost:0.7110579265255232 
2022-03-26 03:53:51,987: ============================================================
2022-03-26 03:53:51,987: Epoch 3/38 Batch 4600/7662 eta: 2 days, 8:35:09.229127	Training Loss 6.2497 (6.5039)	Training Prec@1 95.508 (94.156)	Training Prec@5 97.656 (96.963)	
2022-03-26 03:53:51,987: ============================================================
2022-03-26 03:55:06,500: time cost, forward:0.01670525438812444, backward:0.039332681423706, data cost:0.7106725718016623 
2022-03-26 03:55:06,501: ============================================================
2022-03-26 03:55:06,501: Epoch 3/38 Batch 4700/7662 eta: 2 days, 8:07:11.654949	Training Loss 6.2322 (6.5027)	Training Prec@1 96.094 (94.156)	Training Prec@5 97.656 (96.964)	
2022-03-26 03:55:06,501: ============================================================
2022-03-26 03:56:22,507: time cost, forward:0.01671645049627534, backward:0.03935423526298903, data cost:0.7104313712886136 
2022-03-26 03:56:22,510: ============================================================
2022-03-26 03:56:22,511: Epoch 3/38 Batch 4800/7662 eta: 2 days, 9:13:30.266666	Training Loss 6.5653 (6.5018)	Training Prec@1 93.945 (94.155)	Training Prec@5 96.875 (96.963)	
2022-03-26 03:56:22,511: ============================================================
2022-03-26 03:57:41,911: time cost, forward:0.01673908008802032, backward:0.039394749454343334, data cost:0.7109385132911279 
2022-03-26 03:57:41,912: ============================================================
2022-03-26 03:57:41,912: Epoch 3/38 Batch 4900/7662 eta: 2 days, 11:45:24.630831	Training Loss 6.4112 (6.5005)	Training Prec@1 95.117 (94.156)	Training Prec@5 96.875 (96.965)	
2022-03-26 03:57:41,912: ============================================================
2022-03-26 03:58:57,343: time cost, forward:0.0167146684837761, backward:0.039409304313789396, data cost:0.7106416060891622 
2022-03-26 03:58:57,346: ============================================================
2022-03-26 03:58:57,348: Epoch 3/38 Batch 5000/7662 eta: 2 days, 8:45:03.328625	Training Loss 6.0945 (6.4996)	Training Prec@1 94.922 (94.154)	Training Prec@5 97.070 (96.965)	
2022-03-26 03:58:57,348: ============================================================
2022-03-26 04:00:15,075: time cost, forward:0.016772156674433138, backward:0.0394901280591104, data cost:0.7105112238990767 
2022-03-26 04:00:15,076: ============================================================
2022-03-26 04:00:15,077: Epoch 3/38 Batch 5100/7662 eta: 2 days, 10:27:20.050926	Training Loss 6.3427 (6.4988)	Training Prec@1 94.922 (94.154)	Training Prec@5 97.266 (96.966)	
2022-03-26 04:00:15,077: ============================================================
2022-03-26 04:01:30,100: time cost, forward:0.016767716907634025, backward:0.03952912491866088, data cost:0.7103257173757228 
2022-03-26 04:01:30,101: ============================================================
2022-03-26 04:01:30,101: Epoch 3/38 Batch 5200/7662 eta: 2 days, 8:24:01.369673	Training Loss 6.5277 (6.4971)	Training Prec@1 94.727 (94.153)	Training Prec@5 97.656 (96.965)	
2022-03-26 04:01:30,102: ============================================================
2022-03-26 04:02:46,348: time cost, forward:0.016768935986972572, backward:0.03956261786183539, data cost:0.7101406617802615 
2022-03-26 04:02:46,349: ============================================================
2022-03-26 04:02:46,349: Epoch 3/38 Batch 5300/7662 eta: 2 days, 9:17:54.653535	Training Loss 6.4883 (6.4960)	Training Prec@1 93.750 (94.154)	Training Prec@5 96.875 (96.966)	
2022-03-26 04:02:46,349: ============================================================
2022-03-26 04:04:00,572: time cost, forward:0.01677370345201685, backward:0.03959626722256328, data cost:0.7096550197021942 
2022-03-26 04:04:00,572: ============================================================
2022-03-26 04:04:00,572: Epoch 3/38 Batch 5400/7662 eta: 2 days, 7:45:24.951914	Training Loss 6.3196 (6.4947)	Training Prec@1 94.531 (94.155)	Training Prec@5 97.852 (96.968)	
2022-03-26 04:04:00,573: ============================================================
2022-03-26 04:05:17,021: time cost, forward:0.016802532799917256, backward:0.039615730607177935, data cost:0.7095517126250904 
2022-03-26 04:05:17,022: ============================================================
2022-03-26 04:05:17,022: Epoch 3/38 Batch 5500/7662 eta: 2 days, 9:24:28.424286	Training Loss 6.5873 (6.4939)	Training Prec@1 94.336 (94.157)	Training Prec@5 97.656 (96.969)	
2022-03-26 04:05:17,022: ============================================================
2022-03-26 04:06:36,159: time cost, forward:0.016824823125044477, backward:0.03963073212497042, data cost:0.7098064983416975 
2022-03-26 04:06:36,159: ============================================================
2022-03-26 04:06:36,159: Epoch 3/38 Batch 5600/7662 eta: 2 days, 11:24:15.520667	Training Loss 6.4833 (6.4923)	Training Prec@1 94.922 (94.158)	Training Prec@5 97.266 (96.970)	
2022-03-26 04:06:36,160: ============================================================
2022-03-26 04:07:50,236: time cost, forward:0.016819956177555693, backward:0.039699527417845756, data cost:0.7092610255189685 
2022-03-26 04:07:50,236: ============================================================
2022-03-26 04:07:50,237: Epoch 3/38 Batch 5700/7662 eta: 2 days, 7:35:06.520042	Training Loss 6.4547 (6.4912)	Training Prec@1 94.531 (94.156)	Training Prec@5 96.094 (96.969)	
2022-03-26 04:07:50,237: ============================================================
2022-03-26 04:09:01,458: time cost, forward:0.01678602743568164, backward:0.03970442613377039, data cost:0.7084897295485942 
2022-03-26 04:09:01,458: ============================================================
2022-03-26 04:09:01,459: Epoch 3/38 Batch 5800/7662 eta: 2 days, 5:25:23.671010	Training Loss 6.3798 (6.4900)	Training Prec@1 95.508 (94.157)	Training Prec@5 98.047 (96.972)	
2022-03-26 04:09:01,459: ============================================================
2022-03-26 04:10:17,059: time cost, forward:0.0167677554059259, backward:0.03971518021677486, data cost:0.7082553869749575 
2022-03-26 04:10:17,060: ============================================================
2022-03-26 04:10:17,060: Epoch 3/38 Batch 5900/7662 eta: 2 days, 8:41:13.438276	Training Loss 6.3534 (6.4889)	Training Prec@1 93.555 (94.158)	Training Prec@5 97.070 (96.971)	
2022-03-26 04:10:17,061: ============================================================
2022-03-26 04:11:34,130: time cost, forward:0.016769420506457803, backward:0.03975013177143293, data cost:0.7083564317709288 
2022-03-26 04:11:34,130: ============================================================
2022-03-26 04:11:34,131: Epoch 3/38 Batch 6000/7662 eta: 2 days, 9:46:01.201305	Training Loss 6.5075 (6.4869)	Training Prec@1 93.164 (94.158)	Training Prec@5 96.484 (96.974)	
2022-03-26 04:11:34,131: ============================================================
2022-03-26 04:12:53,497: time cost, forward:0.016754144956917426, backward:0.039784125176232886, data cost:0.7087569582323536 
2022-03-26 04:12:53,498: ============================================================
2022-03-26 04:12:53,498: Epoch 3/38 Batch 6100/7662 eta: 2 days, 11:28:00.622559	Training Loss 6.3161 (6.4860)	Training Prec@1 93.164 (94.159)	Training Prec@5 96.484 (96.974)	
2022-03-26 04:12:53,499: ============================================================
2022-03-26 04:14:06,197: time cost, forward:0.016726954749830887, backward:0.03979284429880934, data cost:0.7081664686992218 
2022-03-26 04:14:06,198: ============================================================
2022-03-26 04:14:06,198: Epoch 3/38 Batch 6200/7662 eta: 2 days, 6:27:02.970629	Training Loss 6.6814 (6.4849)	Training Prec@1 94.141 (94.160)	Training Prec@5 96.875 (96.974)	
2022-03-26 04:14:06,198: ============================================================
2022-03-26 04:15:25,694: time cost, forward:0.016753619881845084, backward:0.03985632777422227, data cost:0.7084801871543045 
2022-03-26 04:15:25,695: ============================================================
2022-03-26 04:15:25,695: Epoch 3/38 Batch 6300/7662 eta: 2 days, 11:31:10.754985	Training Loss 6.4132 (6.4838)	Training Prec@1 94.727 (94.161)	Training Prec@5 96.484 (96.973)	
2022-03-26 04:15:25,695: ============================================================
2022-03-26 04:16:41,840: time cost, forward:0.016765797505212548, backward:0.03988239187284417, data cost:0.7084051218418838 
2022-03-26 04:16:41,840: ============================================================
2022-03-26 04:16:41,841: Epoch 3/38 Batch 6400/7662 eta: 2 days, 8:59:21.281520	Training Loss 6.7222 (6.4822)	Training Prec@1 94.531 (94.163)	Training Prec@5 96.484 (96.975)	
2022-03-26 04:16:41,841: ============================================================
2022-03-26 04:17:56,618: time cost, forward:0.016783597304612274, backward:0.03991214956461714, data cost:0.7079950225300047 
2022-03-26 04:17:56,619: ============================================================
2022-03-26 04:17:56,619: Epoch 3/38 Batch 6500/7662 eta: 2 days, 7:56:42.368524	Training Loss 6.3431 (6.4807)	Training Prec@1 93.555 (94.164)	Training Prec@5 97.266 (96.977)	
2022-03-26 04:17:56,619: ============================================================
2022-03-26 04:19:15,311: time cost, forward:0.016822066663304755, backward:0.040007857124558684, data cost:0.7082260426002337 
2022-03-26 04:19:15,312: ============================================================
2022-03-26 04:19:15,312: Epoch 3/38 Batch 6600/7662 eta: 2 days, 10:51:07.364425	Training Loss 6.3713 (6.4792)	Training Prec@1 94.922 (94.164)	Training Prec@5 97.266 (96.977)	
2022-03-26 04:19:15,312: ============================================================
2022-03-26 04:20:29,229: time cost, forward:0.01682259584829191, backward:0.03998991755838447, data cost:0.7077694447792579 
2022-03-26 04:20:29,230: ============================================================
2022-03-26 04:20:29,230: Epoch 3/38 Batch 6700/7662 eta: 2 days, 7:15:37.417762	Training Loss 6.6476 (6.4778)	Training Prec@1 93.555 (94.167)	Training Prec@5 96.094 (96.977)	
2022-03-26 04:20:29,230: ============================================================
2022-03-26 04:21:45,097: time cost, forward:0.01682613467202325, backward:0.039961827890121475, data cost:0.7077279021098589 
2022-03-26 04:21:45,100: ============================================================
2022-03-26 04:21:45,100: Epoch 3/38 Batch 6800/7662 eta: 2 days, 8:41:56.026965	Training Loss 6.2901 (6.4769)	Training Prec@1 94.141 (94.166)	Training Prec@5 97.070 (96.976)	
2022-03-26 04:21:45,101: ============================================================
2022-03-26 04:23:02,704: time cost, forward:0.016834587683831805, backward:0.039975213147467645, data cost:0.707787458439429 
2022-03-26 04:23:02,706: ============================================================
2022-03-26 04:23:02,707: Epoch 3/38 Batch 6900/7662 eta: 2 days, 9:58:29.925693	Training Loss 6.5101 (6.4762)	Training Prec@1 93.945 (94.167)	Training Prec@5 96.094 (96.977)	
2022-03-26 04:23:02,708: ============================================================
2022-03-26 04:24:15,902: time cost, forward:0.01683625167975308, backward:0.03996912975586522, data cost:0.7074121501313259 
2022-03-26 04:24:15,903: ============================================================
2022-03-26 04:24:15,903: Epoch 3/38 Batch 7000/7662 eta: 2 days, 6:39:35.274709	Training Loss 6.6874 (6.4748)	Training Prec@1 92.383 (94.168)	Training Prec@5 96.680 (96.978)	
2022-03-26 04:24:15,903: ============================================================
2022-03-26 04:25:32,227: time cost, forward:0.016825056593255908, backward:0.039974761220800625, data cost:0.7073380685151505 
2022-03-26 04:25:32,227: ============================================================
2022-03-26 04:25:32,228: Epoch 3/38 Batch 7100/7662 eta: 2 days, 8:58:29.569229	Training Loss 6.6701 (6.4738)	Training Prec@1 93.359 (94.168)	Training Prec@5 97.266 (96.980)	
2022-03-26 04:25:32,228: ============================================================
2022-03-26 04:26:52,066: time cost, forward:0.016833426373123146, backward:0.040061428275666715, data cost:0.7077617014360222 
2022-03-26 04:26:52,067: ============================================================
2022-03-26 04:26:52,067: Epoch 3/38 Batch 7200/7662 eta: 2 days, 11:34:35.185619	Training Loss 6.2144 (6.4718)	Training Prec@1 95.703 (94.172)	Training Prec@5 97.656 (96.983)	
2022-03-26 04:26:52,067: ============================================================
2022-03-26 04:28:03,481: time cost, forward:0.01680176061119898, backward:0.04003240771776422, data cost:0.7071022733562139 
2022-03-26 04:28:03,482: ============================================================
2022-03-26 04:28:03,482: Epoch 3/38 Batch 7300/7662 eta: 2 days, 5:16:12.719563	Training Loss 6.4988 (6.4705)	Training Prec@1 94.727 (94.175)	Training Prec@5 97.461 (96.985)	
2022-03-26 04:28:03,482: ============================================================
2022-03-26 04:29:19,919: time cost, forward:0.01679398453159902, backward:0.040045541981649266, data cost:0.7070937447329441 
2022-03-26 04:29:19,919: ============================================================
2022-03-26 04:29:19,920: Epoch 3/38 Batch 7400/7662 eta: 2 days, 8:59:43.717573	Training Loss 6.4321 (6.4693)	Training Prec@1 93.945 (94.176)	Training Prec@5 97.266 (96.985)	
2022-03-26 04:29:19,920: ============================================================
2022-03-26 04:30:35,387: time cost, forward:0.016819661355746685, backward:0.040055989074554425, data cost:0.7068947511508411 
2022-03-26 04:30:35,387: ============================================================
2022-03-26 04:30:35,387: Epoch 3/38 Batch 7500/7662 eta: 2 days, 8:15:04.927063	Training Loss 6.3312 (6.4679)	Training Prec@1 95.703 (94.178)	Training Prec@5 97.852 (96.987)	
2022-03-26 04:30:35,388: ============================================================
2022-03-26 04:31:49,725: time cost, forward:0.01681854129072898, backward:0.040053058414180616, data cost:0.7065191692169567 
2022-03-26 04:31:49,727: ============================================================
2022-03-26 04:31:49,728: Epoch 3/38 Batch 7600/7662 eta: 2 days, 7:23:24.504700	Training Loss 6.3172 (6.4667)	Training Prec@1 93.359 (94.178)	Training Prec@5 97.070 (96.988)	
2022-03-26 04:31:49,729: ============================================================
2022-03-26 04:32:38,729: Epoch: 3/38 eta: 2 days, 7:22:37.670478	Training Loss 6.0598 (6.4659)	Training Prec@1 95.508 (94.179)	Training Prec@5 98.242 (96.989)
2022-03-26 04:32:38,731: ============================================================
2022-03-26 04:33:54,973: time cost, forward:0.02030115175728846, backward:0.045944890590629194, data cost:0.6957284248236454 
2022-03-26 04:33:54,974: ============================================================
2022-03-26 04:33:54,974: Epoch 4/38 Batch 100/7662 eta: 2 days, 8:37:45.899022	Training Loss 5.8790 (5.9603)	Training Prec@1 97.461 (95.460)	Training Prec@5 98.828 (97.727)	
2022-03-26 04:33:54,974: ============================================================
2022-03-26 04:35:15,238: time cost, forward:0.0192133769318087, backward:0.04538984035127726, data cost:0.7175151523034177 
2022-03-26 04:35:15,239: ============================================================
2022-03-26 04:35:15,239: Epoch 4/38 Batch 200/7662 eta: 2 days, 11:44:46.550957	Training Loss 6.1111 (5.9760)	Training Prec@1 93.945 (95.488)	Training Prec@5 97.852 (97.750)	
2022-03-26 04:35:15,239: ============================================================
2022-03-26 04:36:25,558: time cost, forward:0.018244522471093014, backward:0.044275800519962376, data cost:0.6926295677555045 
2022-03-26 04:36:25,558: ============================================================
2022-03-26 04:36:25,559: Epoch 4/38 Batch 300/7662 eta: 2 days, 4:19:26.264333	Training Loss 6.2344 (6.0142)	Training Prec@1 95.312 (95.354)	Training Prec@5 97.852 (97.688)	
2022-03-26 04:36:25,559: ============================================================
2022-03-26 04:37:40,582: time cost, forward:0.01815207440751537, backward:0.04464624519634964, data cost:0.6902471281830829 
2022-03-26 04:37:40,583: ============================================================
2022-03-26 04:37:40,583: Epoch 4/38 Batch 400/7662 eta: 2 days, 7:48:13.279035	Training Loss 6.0375 (6.0358)	Training Prec@1 95.898 (95.352)	Training Prec@5 98.633 (97.667)	
2022-03-26 04:37:40,583: ============================================================
2022-03-26 04:38:54,746: time cost, forward:0.017742597029538815, backward:0.043733313470660805, data cost:0.6893177887719715 
2022-03-26 04:38:54,747: ============================================================
2022-03-26 04:38:54,747: Epoch 4/38 Batch 500/7662 eta: 2 days, 7:08:35.290788	Training Loss 6.1538 (6.0674)	Training Prec@1 94.531 (95.222)	Training Prec@5 97.656 (97.587)	
2022-03-26 04:38:54,747: ============================================================
2022-03-26 04:40:10,719: time cost, forward:0.01757060944138465, backward:0.043570102554728866, data cost:0.691140678768763 
2022-03-26 04:40:10,719: ============================================================
2022-03-26 04:40:10,719: Epoch 4/38 Batch 600/7662 eta: 2 days, 8:28:00.616794	Training Loss 6.0040 (6.0913)	Training Prec@1 94.336 (95.175)	Training Prec@5 97.070 (97.563)	
2022-03-26 04:40:10,720: ============================================================
2022-03-26 04:41:26,050: time cost, forward:0.01785824772967119, backward:0.04336942009659796, data cost:0.6907033480288133 
2022-03-26 04:41:26,051: ============================================================
2022-03-26 04:41:26,052: Epoch 4/38 Batch 700/7662 eta: 2 days, 7:58:11.728853	Training Loss 6.1709 (6.1137)	Training Prec@1 95.312 (95.118)	Training Prec@5 97.656 (97.540)	
2022-03-26 04:41:26,052: ============================================================
2022-03-26 04:42:44,804: time cost, forward:0.01807515940469257, backward:0.04346986437619702, data cost:0.6937661117248153 
2022-03-26 04:42:44,807: ============================================================
2022-03-26 04:42:44,808: Epoch 4/38 Batch 800/7662 eta: 2 days, 10:29:31.332135	Training Loss 6.1663 (6.1331)	Training Prec@1 94.531 (95.083)	Training Prec@5 97.656 (97.522)	
2022-03-26 04:42:44,809: ============================================================
2022-03-26 04:43:59,314: time cost, forward:0.018129089119967415, backward:0.04329910745079711, data cost:0.693506048836883 
2022-03-26 04:43:59,315: ============================================================
2022-03-26 04:43:59,316: Epoch 4/38 Batch 900/7662 eta: 2 days, 7:18:57.590115	Training Loss 6.4811 (6.1523)	Training Prec@1 93.555 (95.037)	Training Prec@5 96.680 (97.489)	
2022-03-26 04:43:59,316: ============================================================
2022-03-26 04:45:17,342: time cost, forward:0.01846112885155358, backward:0.04350023990398174, data cost:0.695080959761107 
2022-03-26 04:45:17,343: ============================================================
2022-03-26 04:45:17,343: Epoch 4/38 Batch 1000/7662 eta: 2 days, 9:54:26.159393	Training Loss 6.3134 (6.1657)	Training Prec@1 93.945 (94.982)	Training Prec@5 96.680 (97.460)	
2022-03-26 04:45:17,343: ============================================================
2022-03-26 04:46:36,205: time cost, forward:0.018456618063443352, backward:0.043093773101653916, data cost:0.6980125021131827 
2022-03-26 04:46:36,206: ============================================================
2022-03-26 04:46:36,206: Epoch 4/38 Batch 1100/7662 eta: 2 days, 10:30:20.075156	Training Loss 6.2862 (6.1774)	Training Prec@1 94.531 (94.963)	Training Prec@5 96.875 (97.447)	
2022-03-26 04:46:36,206: ============================================================
2022-03-26 04:47:48,110: time cost, forward:0.018194399245884937, backward:0.04246177585846787, data cost:0.6955353756364532 
2022-03-26 04:47:48,110: ============================================================
2022-03-26 04:47:48,111: Epoch 4/38 Batch 1200/7662 eta: 2 days, 5:19:24.896610	Training Loss 6.4057 (6.1886)	Training Prec@1 92.969 (94.939)	Training Prec@5 95.703 (97.428)	
2022-03-26 04:47:48,111: ============================================================
2022-03-26 04:49:02,880: time cost, forward:0.018305330114973976, backward:0.04270633208558961, data cost:0.6947283109763295 
2022-03-26 04:49:02,881: ============================================================
2022-03-26 04:49:02,881: Epoch 4/38 Batch 1300/7662 eta: 2 days, 7:25:40.119823	Training Loss 6.3032 (6.1985)	Training Prec@1 93.750 (94.910)	Training Prec@5 96.680 (97.417)	
2022-03-26 04:49:02,881: ============================================================
2022-03-26 04:50:19,568: time cost, forward:0.01829895860727895, backward:0.04261941412161554, data cost:0.6949647553398236 
2022-03-26 04:50:19,569: ============================================================
2022-03-26 04:50:19,569: Epoch 4/38 Batch 1400/7662 eta: 2 days, 8:49:41.998860	Training Loss 6.0257 (6.2039)	Training Prec@1 95.117 (94.891)	Training Prec@5 97.266 (97.402)	
2022-03-26 04:50:19,570: ============================================================
2022-03-26 04:51:37,520: time cost, forward:0.018382284941873685, backward:0.04237067436996979, data cost:0.6971486435483661 
2022-03-26 04:51:37,521: ============================================================
2022-03-26 04:51:37,521: Epoch 4/38 Batch 1500/7662 eta: 2 days, 9:44:34.413798	Training Loss 6.3132 (6.2095)	Training Prec@1 94.141 (94.869)	Training Prec@5 95.898 (97.390)	
2022-03-26 04:51:37,521: ============================================================
2022-03-26 04:52:49,987: time cost, forward:0.018200461457415325, backward:0.04198812573607673, data cost:0.6955150728899662 
2022-03-26 04:52:49,987: ============================================================
2022-03-26 04:52:49,987: Epoch 4/38 Batch 1600/7662 eta: 2 days, 5:39:34.413254	Training Loss 6.6076 (6.2163)	Training Prec@1 94.336 (94.836)	Training Prec@5 97.070 (97.374)	
2022-03-26 04:52:49,987: ============================================================
2022-03-26 04:54:07,027: time cost, forward:0.01824627685995927, backward:0.04231854997851555, data cost:0.6959262939675406 
2022-03-26 04:54:07,027: ============================================================
2022-03-26 04:54:07,027: Epoch 4/38 Batch 1700/7662 eta: 2 days, 9:01:29.746857	Training Loss 6.4859 (6.2202)	Training Prec@1 94.336 (94.819)	Training Prec@5 98.047 (97.362)	
2022-03-26 04:54:07,028: ============================================================
2022-03-26 04:55:20,776: time cost, forward:0.018145839792943916, backward:0.04235373608863241, data cost:0.6948732103885313 
2022-03-26 04:55:20,777: ============================================================
2022-03-26 04:55:20,777: Epoch 4/38 Batch 1800/7662 eta: 2 days, 6:34:08.019972	Training Loss 6.2403 (6.2252)	Training Prec@1 94.727 (94.798)	Training Prec@5 98.047 (97.353)	
2022-03-26 04:55:20,777: ============================================================
2022-03-26 04:56:37,527: time cost, forward:0.01818431384190564, backward:0.04239964133629741, data cost:0.6953813517451475 
2022-03-26 04:56:37,528: ============================================================
2022-03-26 04:56:37,528: Epoch 4/38 Batch 1900/7662 eta: 2 days, 8:46:05.222056	Training Loss 6.2558 (6.2280)	Training Prec@1 93.750 (94.783)	Training Prec@5 97.656 (97.349)	
2022-03-26 04:56:37,528: ============================================================
2022-03-26 04:57:52,857: time cost, forward:0.018116754910658454, backward:0.04229148869039775, data cost:0.6953467442549247 
2022-03-26 04:57:52,857: ============================================================
2022-03-26 04:57:52,857: Epoch 4/38 Batch 2000/7662 eta: 2 days, 7:41:45.221147	Training Loss 6.3745 (6.2306)	Training Prec@1 93.555 (94.761)	Training Prec@5 97.266 (97.337)	
2022-03-26 04:57:52,858: ============================================================
2022-03-26 04:59:08,368: time cost, forward:0.018111403298525654, backward:0.042295405386515376, data cost:0.695208684667739 
2022-03-26 04:59:08,368: ============================================================
2022-03-26 04:59:08,369: Epoch 4/38 Batch 2100/7662 eta: 2 days, 7:48:33.130777	Training Loss 6.4991 (6.2352)	Training Prec@1 92.969 (94.746)	Training Prec@5 97.266 (97.327)	
2022-03-26 04:59:08,369: ============================================================
2022-03-26 05:00:22,317: time cost, forward:0.018145016075644293, backward:0.042357070926321044, data cost:0.6940209416705622 
2022-03-26 05:00:22,319: ============================================================
2022-03-26 05:00:22,320: Epoch 4/38 Batch 2200/7662 eta: 2 days, 6:38:08.270581	Training Loss 6.2443 (6.2377)	Training Prec@1 94.922 (94.731)	Training Prec@5 96.484 (97.316)	
2022-03-26 05:00:22,320: ============================================================
2022-03-26 05:01:37,426: time cost, forward:0.018161260236497025, backward:0.042454392975338026, data cost:0.6939801032152213 
2022-03-26 05:01:37,426: ============================================================
2022-03-26 05:01:37,427: Epoch 4/38 Batch 2300/7662 eta: 2 days, 7:28:07.499633	Training Loss 6.4775 (6.2397)	Training Prec@1 92.969 (94.717)	Training Prec@5 96.289 (97.309)	
2022-03-26 05:01:37,427: ============================================================
2022-03-26 05:02:56,258: time cost, forward:0.018224231200001547, backward:0.04246832281910116, data cost:0.6950014386886654 
2022-03-26 05:02:56,258: ============================================================
2022-03-26 05:02:56,259: Epoch 4/38 Batch 2400/7662 eta: 2 days, 10:11:53.017408	Training Loss 6.3402 (6.2419)	Training Prec@1 94.727 (94.705)	Training Prec@5 97.266 (97.301)	
2022-03-26 05:02:56,259: ============================================================
2022-03-26 05:04:12,113: time cost, forward:0.018182536801036334, backward:0.04247811442615987, data cost:0.6952870196464206 
2022-03-26 05:04:12,114: ============================================================
2022-03-26 05:04:12,114: Epoch 4/38 Batch 2500/7662 eta: 2 days, 7:58:44.964495	Training Loss 6.2326 (6.2446)	Training Prec@1 94.141 (94.694)	Training Prec@5 97.461 (97.295)	
2022-03-26 05:04:12,114: ============================================================
2022-03-26 05:05:26,519: time cost, forward:0.018132146939537807, backward:0.04247331490834065, data cost:0.6948651421661788 
2022-03-26 05:05:26,519: ============================================================
2022-03-26 05:05:26,520: Epoch 4/38 Batch 2600/7662 eta: 2 days, 6:53:19.910809	Training Loss 6.4694 (6.2462)	Training Prec@1 93.359 (94.692)	Training Prec@5 96.484 (97.296)	
2022-03-26 05:05:26,520: ============================================================
2022-03-26 05:06:44,289: time cost, forward:0.018177715395503065, backward:0.04257701785090059, data cost:0.6954094854802192 
2022-03-26 05:06:44,290: ============================================================
2022-03-26 05:06:44,290: Epoch 4/38 Batch 2700/7662 eta: 2 days, 9:20:58.596709	Training Loss 6.2686 (6.2491)	Training Prec@1 94.336 (94.683)	Training Prec@5 97.656 (97.292)	
2022-03-26 05:06:44,290: ============================================================
2022-03-26 05:07:59,088: time cost, forward:0.018184942107151218, backward:0.042581771347683726, data cost:0.6950643502119909 
2022-03-26 05:07:59,089: ============================================================
2022-03-26 05:07:59,089: Epoch 4/38 Batch 2800/7662 eta: 2 days, 7:08:14.997977	Training Loss 6.3633 (6.2520)	Training Prec@1 93.945 (94.666)	Training Prec@5 97.070 (97.285)	
2022-03-26 05:07:59,089: ============================================================
2022-03-26 05:09:15,102: time cost, forward:0.018175083918997484, backward:0.04250288305713539, data cost:0.6950086636064627 
2022-03-26 05:09:15,103: ============================================================
2022-03-26 05:09:15,103: Epoch 4/38 Batch 2900/7662 eta: 2 days, 8:00:42.608890	Training Loss 6.4127 (6.2527)	Training Prec@1 93.164 (94.661)	Training Prec@5 96.289 (97.279)	
2022-03-26 05:09:15,103: ============================================================
2022-03-26 05:10:27,286: time cost, forward:0.018131018718428198, backward:0.04250304052614299, data cost:0.6941468512149365 
2022-03-26 05:10:27,287: ============================================================
2022-03-26 05:10:27,287: Epoch 4/38 Batch 3000/7662 eta: 2 days, 5:10:11.479761	Training Loss 6.4524 (6.2545)	Training Prec@1 92.773 (94.650)	Training Prec@5 96.289 (97.276)	
2022-03-26 05:10:27,288: ============================================================
2022-03-26 05:11:42,067: time cost, forward:0.018085878639307357, backward:0.04248759007215423, data cost:0.6937089141779232 
2022-03-26 05:11:42,070: ============================================================
2022-03-26 05:11:42,072: Epoch 4/38 Batch 3100/7662 eta: 2 days, 7:03:50.602263	Training Loss 6.5486 (6.2555)	Training Prec@1 95.508 (94.643)	Training Prec@5 98.047 (97.274)	
2022-03-26 05:11:42,073: ============================================================
2022-03-26 05:13:00,176: time cost, forward:0.0181014847107029, backward:0.04249255550619437, data cost:0.694457289650128 
2022-03-26 05:13:00,180: ============================================================
2022-03-26 05:13:00,181: Epoch 4/38 Batch 3200/7662 eta: 2 days, 9:29:26.569136	Training Loss 6.3168 (6.2569)	Training Prec@1 94.141 (94.639)	Training Prec@5 96.484 (97.268)	
2022-03-26 05:13:00,182: ============================================================
2022-03-26 05:14:16,176: time cost, forward:0.018086302818837184, backward:0.04255547050853034, data cost:0.6947948137678208 
2022-03-26 05:14:16,177: ============================================================
2022-03-26 05:14:16,177: Epoch 4/38 Batch 3300/7662 eta: 2 days, 7:54:52.479265	Training Loss 6.6203 (6.2578)	Training Prec@1 93.945 (94.631)	Training Prec@5 96.484 (97.264)	
2022-03-26 05:14:16,177: ============================================================
2022-03-26 05:15:32,627: time cost, forward:0.018071642901203708, backward:0.04260144552156202, data cost:0.694723300563479 
2022-03-26 05:15:32,629: ============================================================
2022-03-26 05:15:32,629: Epoch 4/38 Batch 3400/7662 eta: 2 days, 8:13:42.787789	Training Loss 6.5311 (6.2584)	Training Prec@1 93.555 (94.626)	Training Prec@5 96.289 (97.262)	
2022-03-26 05:15:32,630: ============================================================
2022-03-26 05:16:46,799: time cost, forward:0.018020923357753967, backward:0.042563805276238945, data cost:0.694574660456293 
2022-03-26 05:16:46,802: ============================================================
2022-03-26 05:16:46,803: Epoch 4/38 Batch 3500/7662 eta: 2 days, 6:31:55.228168	Training Loss 6.1571 (6.2600)	Training Prec@1 94.922 (94.619)	Training Prec@5 97.266 (97.258)	
2022-03-26 05:16:46,803: ============================================================
2022-03-26 05:18:02,011: time cost, forward:0.018034844373325136, backward:0.04256022284513846, data cost:0.694257961044248 
2022-03-26 05:18:02,014: ============================================================
2022-03-26 05:18:02,015: Epoch 4/38 Batch 3600/7662 eta: 2 days, 7:16:29.564757	Training Loss 6.1356 (6.2597)	Training Prec@1 95.898 (94.616)	Training Prec@5 98.047 (97.257)	
2022-03-26 05:18:02,016: ============================================================
2022-03-26 05:19:19,223: time cost, forward:0.01800823243897359, backward:0.04255079552752806, data cost:0.6947188392204993 
2022-03-26 05:19:19,227: ============================================================
2022-03-26 05:19:19,228: Epoch 4/38 Batch 3700/7662 eta: 2 days, 8:43:24.497096	Training Loss 6.6252 (6.2598)	Training Prec@1 92.188 (94.608)	Training Prec@5 97.266 (97.253)	
2022-03-26 05:19:19,229: ============================================================
2022-03-26 05:20:34,778: time cost, forward:0.018019584267664722, backward:0.0426103503304301, data cost:0.6948453281138501 
2022-03-26 05:20:34,778: ============================================================
2022-03-26 05:20:34,779: Epoch 4/38 Batch 3800/7662 eta: 2 days, 7:28:56.669765	Training Loss 6.2480 (6.2606)	Training Prec@1 94.727 (94.598)	Training Prec@5 96.875 (97.247)	
2022-03-26 05:20:34,779: ============================================================
2022-03-26 05:21:46,911: time cost, forward:0.01801032731397912, backward:0.04256866809251095, data cost:0.693985112296156 
2022-03-26 05:21:46,911: ============================================================
2022-03-26 05:21:46,912: Epoch 4/38 Batch 3900/7662 eta: 2 days, 4:57:06.124454	Training Loss 6.0725 (6.2615)	Training Prec@1 93.555 (94.591)	Training Prec@5 96.289 (97.243)	
2022-03-26 05:21:46,912: ============================================================
2022-03-26 05:23:00,995: time cost, forward:0.018029075349739535, backward:0.04261940924875079, data cost:0.69353502963477 
2022-03-26 05:23:00,996: ============================================================
2022-03-26 05:23:00,996: Epoch 4/38 Batch 4000/7662 eta: 2 days, 6:21:49.400018	Training Loss 6.1188 (6.2617)	Training Prec@1 93.164 (94.588)	Training Prec@5 95.508 (97.241)	
2022-03-26 05:23:00,996: ============================================================
2022-03-26 05:24:16,470: time cost, forward:0.018021419240835675, backward:0.04256325385779339, data cost:0.6934260181404667 
2022-03-26 05:24:16,471: ============================================================
2022-03-26 05:24:16,471: Epoch 4/38 Batch 4100/7662 eta: 2 days, 7:21:48.122783	Training Loss 6.3301 (6.2624)	Training Prec@1 95.508 (94.585)	Training Prec@5 97.266 (97.239)	
2022-03-26 05:24:16,471: ============================================================
2022-03-26 05:25:32,093: time cost, forward:0.01804261952532164, backward:0.04259045608386053, data cost:0.6934058848492558 
2022-03-26 05:25:32,095: ============================================================
2022-03-26 05:25:32,096: Epoch 4/38 Batch 4200/7662 eta: 2 days, 7:27:06.736404	Training Loss 6.0763 (6.2621)	Training Prec@1 95.508 (94.580)	Training Prec@5 97.266 (97.238)	
2022-03-26 05:25:32,097: ============================================================
2022-03-26 05:26:50,011: time cost, forward:0.018037174767908812, backward:0.04262054546069589, data cost:0.6938687735142944 
2022-03-26 05:26:50,012: ============================================================
2022-03-26 05:26:50,013: Epoch 4/38 Batch 4300/7662 eta: 2 days, 9:06:39.477015	Training Loss 6.2540 (6.2618)	Training Prec@1 94.922 (94.576)	Training Prec@5 96.875 (97.236)	
2022-03-26 05:26:50,013: ============================================================
2022-03-26 05:28:04,336: time cost, forward:0.01804081313472955, backward:0.0426344431430325, data cost:0.6935815064845829 
2022-03-26 05:28:04,337: ============================================================
2022-03-26 05:28:04,337: Epoch 4/38 Batch 4400/7662 eta: 2 days, 6:27:26.619872	Training Loss 5.9566 (6.2622)	Training Prec@1 95.898 (94.572)	Training Prec@5 97.461 (97.233)	
2022-03-26 05:28:04,337: ============================================================
2022-03-26 05:29:19,990: time cost, forward:0.0180574693953257, backward:0.042672657600957356, data cost:0.693718420661643 
2022-03-26 05:29:19,991: ============================================================
2022-03-26 05:29:19,991: Epoch 4/38 Batch 4500/7662 eta: 2 days, 7:24:39.086727	Training Loss 6.4972 (6.2620)	Training Prec@1 94.727 (94.570)	Training Prec@5 97.656 (97.232)	
2022-03-26 05:29:19,992: ============================================================
2022-03-26 05:30:35,648: time cost, forward:0.018037094761947363, backward:0.04268935784797975, data cost:0.6937376885705472 
2022-03-26 05:30:35,649: ============================================================
2022-03-26 05:30:35,649: Epoch 4/38 Batch 4600/7662 eta: 2 days, 7:23:30.827223	Training Loss 6.2367 (6.2614)	Training Prec@1 92.773 (94.571)	Training Prec@5 95.898 (97.232)	
2022-03-26 05:30:35,649: ============================================================
2022-03-26 05:31:52,315: time cost, forward:0.018008667450048588, backward:0.04268329289142668, data cost:0.693945451552981 
2022-03-26 05:31:52,316: ============================================================
2022-03-26 05:31:52,316: Epoch 4/38 Batch 4700/7662 eta: 2 days, 8:06:36.684254	Training Loss 6.3229 (6.2622)	Training Prec@1 95.898 (94.564)	Training Prec@5 98.047 (97.228)	
2022-03-26 05:31:52,317: ============================================================
2022-03-26 05:33:04,547: time cost, forward:0.017996872581772867, backward:0.042699781301792125, data cost:0.6933025952601686 
2022-03-26 05:33:04,548: ============================================================
2022-03-26 05:33:04,548: Epoch 4/38 Batch 4800/7662 eta: 2 days, 4:50:36.987517	Training Loss 6.3073 (6.2621)	Training Prec@1 92.773 (94.563)	Training Prec@5 95.898 (97.227)	
2022-03-26 05:33:04,548: ============================================================
2022-03-26 05:34:17,670: time cost, forward:0.017972068315526616, backward:0.0426431260904163, data cost:0.6928910267890825 
2022-03-26 05:34:17,670: ============================================================
2022-03-26 05:34:17,671: Epoch 4/38 Batch 4900/7662 eta: 2 days, 5:28:30.724735	Training Loss 6.3168 (6.2609)	Training Prec@1 94.141 (94.567)	Training Prec@5 96.094 (97.230)	
2022-03-26 05:34:17,671: ============================================================
2022-03-26 05:35:32,832: time cost, forward:0.01795106855576743, backward:0.04264299262402224, data cost:0.6928140281033196 
2022-03-26 05:35:32,832: ============================================================
2022-03-26 05:35:32,833: Epoch 4/38 Batch 5000/7662 eta: 2 days, 6:56:44.401767	Training Loss 6.3674 (6.2599)	Training Prec@1 92.969 (94.567)	Training Prec@5 97.266 (97.230)	
2022-03-26 05:35:32,833: ============================================================
2022-03-26 05:36:44,245: time cost, forward:0.017911620129788943, backward:0.042575290844145415, data cost:0.6921364629846106 
2022-03-26 05:36:44,246: ============================================================
2022-03-26 05:36:44,246: Epoch 4/38 Batch 5100/7662 eta: 2 days, 4:11:07.722683	Training Loss 6.4876 (6.2603)	Training Prec@1 93.555 (94.564)	Training Prec@5 97.070 (97.229)	
2022-03-26 05:36:44,246: ============================================================
2022-03-26 05:38:08,478: time cost, forward:0.0179314124490188, backward:0.04252661230656293, data cost:0.6938860480155732 
2022-03-26 05:38:08,479: ============================================================
2022-03-26 05:38:08,479: Epoch 4/38 Batch 5200/7662 eta: 2 days, 13:31:48.601412	Training Loss 6.0484 (6.2597)	Training Prec@1 94.336 (94.561)	Training Prec@5 95.898 (97.227)	
2022-03-26 05:38:08,479: ============================================================
2022-03-26 05:39:19,298: time cost, forward:0.017903753126943128, backward:0.04252987574757124, data cost:0.6929687083633604 
2022-03-26 05:39:19,301: ============================================================
2022-03-26 05:39:19,302: Epoch 4/38 Batch 5300/7662 eta: 2 days, 3:42:52.669441	Training Loss 6.1619 (6.2605)	Training Prec@1 94.141 (94.554)	Training Prec@5 96.875 (97.223)	
2022-03-26 05:39:19,303: ============================================================
2022-03-26 05:40:34,200: time cost, forward:0.0178980818057992, backward:0.04250110933396039, data cost:0.6927956978376981 
2022-03-26 05:40:34,202: ============================================================
2022-03-26 05:40:34,203: Epoch 4/38 Batch 5400/7662 eta: 2 days, 6:40:16.678362	Training Loss 6.1734 (6.2602)	Training Prec@1 95.508 (94.551)	Training Prec@5 97.070 (97.222)	
2022-03-26 05:40:34,203: ============================================================
2022-03-26 05:41:49,909: time cost, forward:0.017868905657962314, backward:0.042499471564881694, data cost:0.6929936334423031 
2022-03-26 05:41:49,912: ============================================================
2022-03-26 05:41:49,913: Epoch 4/38 Batch 5500/7662 eta: 2 days, 7:14:29.293866	Training Loss 6.4516 (6.2596)	Training Prec@1 93.750 (94.550)	Training Prec@5 97.070 (97.220)	
2022-03-26 05:41:49,913: ============================================================
2022-03-26 05:43:06,143: time cost, forward:0.017870608600767026, backward:0.04253500605251219, data cost:0.6930993406405128 
2022-03-26 05:43:06,143: ============================================================
2022-03-26 05:43:06,144: Epoch 4/38 Batch 5600/7662 eta: 2 days, 7:36:00.402463	Training Loss 6.0209 (6.2589)	Training Prec@1 94.336 (94.551)	Training Prec@5 97.461 (97.221)	
2022-03-26 05:43:06,144: ============================================================
2022-03-26 05:44:21,163: time cost, forward:0.01787777050772682, backward:0.042520101498377746, data cost:0.6929992917421136 
2022-03-26 05:44:21,167: ============================================================
2022-03-26 05:44:21,168: Epoch 4/38 Batch 5700/7662 eta: 2 days, 6:41:54.574526	Training Loss 6.1590 (6.2590)	Training Prec@1 95.312 (94.550)	Training Prec@5 97.461 (97.219)	
2022-03-26 05:44:21,168: ============================================================
2022-03-26 05:45:37,107: time cost, forward:0.01787891842657419, backward:0.042488108628534985, data cost:0.6931345977954236 
2022-03-26 05:45:37,108: ============================================================
2022-03-26 05:45:37,108: Epoch 4/38 Batch 5800/7662 eta: 2 days, 7:20:46.825780	Training Loss 6.4230 (6.2586)	Training Prec@1 93.359 (94.548)	Training Prec@5 96.289 (97.219)	
2022-03-26 05:45:37,108: ============================================================
2022-03-26 05:46:50,694: time cost, forward:0.017845725221014727, backward:0.042428316716764676, data cost:0.6928466721942291 
2022-03-26 05:46:50,695: ============================================================
2022-03-26 05:46:50,695: Epoch 4/38 Batch 5900/7662 eta: 2 days, 5:36:37.120999	Training Loss 6.3733 (6.2587)	Training Prec@1 94.141 (94.546)	Training Prec@5 97.266 (97.219)	
2022-03-26 05:46:50,695: ============================================================
2022-03-26 05:48:06,044: time cost, forward:0.017862815939599146, backward:0.04243860842486504, data cost:0.69287288353868 
2022-03-26 05:48:06,045: ============================================================
2022-03-26 05:48:06,045: Epoch 4/38 Batch 6000/7662 eta: 2 days, 6:52:25.907631	Training Loss 6.4692 (6.2585)	Training Prec@1 93.945 (94.548)	Training Prec@5 97.070 (97.220)	
2022-03-26 05:48:06,045: ============================================================
2022-03-26 05:49:23,208: time cost, forward:0.017833168965164688, backward:0.042369826970911156, data cost:0.6932537591267773 
2022-03-26 05:49:23,208: ============================================================
2022-03-26 05:49:23,208: Epoch 4/38 Batch 6100/7662 eta: 2 days, 8:10:23.358714	Training Loss 6.5286 (6.2583)	Training Prec@1 93.750 (94.548)	Training Prec@5 96.680 (97.220)	
2022-03-26 05:49:23,209: ============================================================
2022-03-26 05:50:35,004: time cost, forward:0.017796554379279354, backward:0.04223529841365651, data cost:0.6927411667780254 
2022-03-26 05:50:35,007: ============================================================
2022-03-26 05:50:35,008: Epoch 4/38 Batch 6200/7662 eta: 2 days, 4:14:52.599578	Training Loss 6.3227 (6.2578)	Training Prec@1 94.141 (94.548)	Training Prec@5 96.094 (97.220)	
2022-03-26 05:50:35,008: ============================================================
2022-03-26 05:51:46,733: time cost, forward:0.017761217902474678, backward:0.0421548728091998, data cost:0.6923265286448798 
2022-03-26 05:51:46,733: ============================================================
2022-03-26 05:51:46,734: Epoch 4/38 Batch 6300/7662 eta: 2 days, 4:10:29.842136	Training Loss 6.1924 (6.2572)	Training Prec@1 95.898 (94.549)	Training Prec@5 98.047 (97.220)	
2022-03-26 05:51:46,734: ============================================================
2022-03-26 05:53:02,689: time cost, forward:0.01775844467116587, backward:0.04216453887127511, data cost:0.692372737852628 
2022-03-26 05:53:02,689: ============================================================
2022-03-26 05:53:02,690: Epoch 4/38 Batch 6400/7662 eta: 2 days, 7:13:51.160454	Training Loss 6.0605 (6.2570)	Training Prec@1 94.141 (94.546)	Training Prec@5 97.070 (97.219)	
2022-03-26 05:53:02,690: ============================================================
2022-03-26 05:54:09,388: time cost, forward:0.017703411230253686, backward:0.04208940721545004, data cost:0.6912415276345591 
2022-03-26 05:54:09,388: ============================================================
2022-03-26 05:54:09,388: Epoch 4/38 Batch 6500/7662 eta: 2 days, 0:28:50.543754	Training Loss 6.2269 (6.2561)	Training Prec@1 93.555 (94.547)	Training Prec@5 96.484 (97.219)	
2022-03-26 05:54:09,388: ============================================================
2022-03-26 05:55:22,235: time cost, forward:0.017665559404780422, backward:0.04201480312263592, data cost:0.6909877176916334 
2022-03-26 05:55:22,236: ============================================================
2022-03-26 05:55:22,236: Epoch 4/38 Batch 6600/7662 eta: 2 days, 4:55:48.230052	Training Loss 6.3141 (6.2555)	Training Prec@1 95.117 (94.546)	Training Prec@5 97.852 (97.219)	
2022-03-26 05:55:22,236: ============================================================
2022-03-26 05:56:37,733: time cost, forward:0.017674841583976284, backward:0.042035611356651806, data cost:0.690965261685704 
2022-03-26 05:56:37,735: ============================================================
2022-03-26 05:56:37,736: Epoch 4/38 Batch 6700/7662 eta: 2 days, 6:50:09.815781	Training Loss 6.0787 (6.2556)	Training Prec@1 94.531 (94.544)	Training Prec@5 96.680 (97.217)	
2022-03-26 05:56:37,736: ============================================================
2022-03-26 05:57:51,457: time cost, forward:0.01764555912996885, backward:0.04198149411638689, data cost:0.690811043926014 
2022-03-26 05:57:51,457: ============================================================
2022-03-26 05:57:51,457: Epoch 4/38 Batch 6800/7662 eta: 2 days, 5:31:26.806010	Training Loss 6.3701 (6.2551)	Training Prec@1 94.922 (94.542)	Training Prec@5 96.875 (97.217)	
2022-03-26 05:57:51,457: ============================================================
2022-03-26 05:59:01,438: time cost, forward:0.01759312843685479, backward:0.04191081640357158, data cost:0.6902151400497952 
2022-03-26 05:59:01,438: ============================================================
2022-03-26 05:59:01,438: Epoch 4/38 Batch 6900/7662 eta: 2 days, 2:47:20.068960	Training Loss 6.2525 (6.2545)	Training Prec@1 94.531 (94.544)	Training Prec@5 96.875 (97.218)	
2022-03-26 05:59:01,438: ============================================================
2022-03-26 06:00:15,919: time cost, forward:0.017604675543684674, backward:0.04196093504489158, data cost:0.6899627825416383 
2022-03-26 06:00:15,919: ============================================================
2022-03-26 06:00:15,920: Epoch 4/38 Batch 7000/7662 eta: 2 days, 6:02:03.286704	Training Loss 6.3448 (6.2541)	Training Prec@1 92.969 (94.543)	Training Prec@5 96.680 (97.218)	
2022-03-26 06:00:15,920: ============================================================
2022-03-26 06:01:29,236: time cost, forward:0.017582424661948287, backward:0.04195499020506755, data cost:0.6898038982757297 
2022-03-26 06:01:29,237: ============================================================
2022-03-26 06:01:29,237: Epoch 4/38 Batch 7100/7662 eta: 2 days, 5:10:11.156474	Training Loss 6.1558 (6.2540)	Training Prec@1 94.336 (94.541)	Training Prec@5 96.875 (97.217)	
2022-03-26 06:01:29,237: ============================================================
2022-03-26 06:02:43,403: time cost, forward:0.017596112405083082, backward:0.0419563933501129, data cost:0.6896917975632776 
2022-03-26 06:02:43,406: ============================================================
2022-03-26 06:02:43,407: Epoch 4/38 Batch 7200/7662 eta: 2 days, 5:46:00.797786	Training Loss 6.4551 (6.2536)	Training Prec@1 93.945 (94.542)	Training Prec@5 97.070 (97.218)	
2022-03-26 06:02:43,408: ============================================================
2022-03-26 06:03:54,937: time cost, forward:0.017564052064903208, backward:0.04193824479834382, data cost:0.6892896431539953 
2022-03-26 06:03:54,938: ============================================================
2022-03-26 06:03:54,938: Epoch 4/38 Batch 7300/7662 eta: 2 days, 3:50:04.099354	Training Loss 6.4156 (6.2532)	Training Prec@1 93.164 (94.539)	Training Prec@5 96.680 (97.217)	
2022-03-26 06:03:54,938: ============================================================
2022-03-26 06:05:07,034: time cost, forward:0.01756766432442364, backward:0.04196055226429747, data cost:0.6888694909476383 
2022-03-26 06:05:07,034: ============================================================
2022-03-26 06:05:07,034: Epoch 4/38 Batch 7400/7662 eta: 2 days, 4:13:26.561123	Training Loss 6.1791 (6.2527)	Training Prec@1 95.312 (94.539)	Training Prec@5 97.656 (97.217)	
2022-03-26 06:05:07,034: ============================================================
2022-03-26 06:06:17,777: time cost, forward:0.01753432083994663, backward:0.041923161204107, data cost:0.6883521674235418 
2022-03-26 06:06:17,777: ============================================================
2022-03-26 06:06:17,777: Epoch 4/38 Batch 7500/7662 eta: 2 days, 3:13:26.923759	Training Loss 6.4129 (6.2525)	Training Prec@1 93.359 (94.539)	Training Prec@5 97.266 (97.218)	
2022-03-26 06:06:17,778: ============================================================
2022-03-26 06:07:30,191: time cost, forward:0.01752558412136475, backward:0.04189930939175515, data cost:0.6879726431686355 
2022-03-26 06:07:30,273: ============================================================
2022-03-26 06:07:30,277: Epoch 4/38 Batch 7600/7662 eta: 2 days, 4:28:29.404466	Training Loss 6.5050 (6.2523)	Training Prec@1 92.578 (94.537)	Training Prec@5 96.875 (97.217)	
2022-03-26 06:07:30,277: ============================================================
2022-03-26 06:08:17,542: Epoch: 4/38 eta: 2 days, 4:27:43.730571	Training Loss 6.3205 (6.2524)	Training Prec@1 92.969 (94.536)	Training Prec@5 95.312 (97.216)
2022-03-26 06:08:17,542: ============================================================
2022-03-26 06:09:34,388: time cost, forward:0.021345420317216354, backward:0.038495966882416695, data cost:0.7103206244381991 
2022-03-26 06:09:34,389: ============================================================
2022-03-26 06:09:34,389: Epoch 5/38 Batch 100/7662 eta: 2 days, 7:32:26.360027	Training Loss 5.8283 (5.8366)	Training Prec@1 95.117 (95.539)	Training Prec@5 96.875 (97.788)	
2022-03-26 06:09:34,390: ============================================================
2022-03-26 06:10:47,962: time cost, forward:0.020000175016010226, backward:0.042004187502453674, data cost:0.6880880528358958 
2022-03-26 06:10:47,963: ============================================================
2022-03-26 06:10:47,964: Epoch 5/38 Batch 200/7662 eta: 2 days, 5:12:00.452727	Training Loss 5.8608 (5.8372)	Training Prec@1 95.703 (95.597)	Training Prec@5 98.633 (97.855)	
2022-03-26 06:10:47,964: ============================================================
2022-03-26 06:11:57,747: time cost, forward:0.019722905844749016, backward:0.04308706621661234, data cost:0.670332075361424 
2022-03-26 06:11:57,748: ============================================================
2022-03-26 06:11:57,748: Epoch 5/38 Batch 300/7662 eta: 2 days, 2:26:25.611341	Training Loss 6.1504 (5.8632)	Training Prec@1 94.336 (95.554)	Training Prec@5 96.875 (97.845)	
2022-03-26 06:11:57,748: ============================================================
2022-03-26 06:13:10,202: time cost, forward:0.019825745345954607, backward:0.043695193484313506, data cost:0.6669383616674514 
2022-03-26 06:13:10,202: ============================================================
2022-03-26 06:13:10,203: Epoch 5/38 Batch 400/7662 eta: 2 days, 4:21:00.357165	Training Loss 5.8310 (5.8903)	Training Prec@1 96.094 (95.528)	Training Prec@5 97.852 (97.829)	
2022-03-26 06:13:10,203: ============================================================
2022-03-26 06:14:30,040: time cost, forward:0.021012300957658724, backward:0.0457202542520955, data cost:0.6755909771623019 
2022-03-26 06:14:30,043: ============================================================
2022-03-26 06:14:30,044: Epoch 5/38 Batch 500/7662 eta: 2 days, 9:39:54.160944	Training Loss 5.9667 (5.9189)	Training Prec@1 93.164 (95.505)	Training Prec@5 96.094 (97.815)	
2022-03-26 06:14:30,045: ============================================================
2022-03-26 06:15:38,077: time cost, forward:0.020761358519030333, backward:0.045330924064368755, data cost:0.6669672868884664 
2022-03-26 06:15:38,078: ============================================================
2022-03-26 06:15:38,078: Epoch 5/38 Batch 600/7662 eta: 2 days, 1:07:08.073351	Training Loss 6.0287 (5.9466)	Training Prec@1 94.336 (95.423)	Training Prec@5 97.266 (97.769)	
2022-03-26 06:15:38,079: ============================================================
2022-03-26 06:16:51,702: time cost, forward:0.020762346674273794, backward:0.04546010647720533, data cost:0.6667901944363748 
2022-03-26 06:16:51,703: ============================================================
2022-03-26 06:16:51,703: Epoch 5/38 Batch 700/7662 eta: 2 days, 5:08:03.717793	Training Loss 6.1808 (5.9686)	Training Prec@1 95.703 (95.359)	Training Prec@5 97.656 (97.724)	
2022-03-26 06:16:51,703: ============================================================
2022-03-26 06:18:02,730: time cost, forward:0.020723545208144397, backward:0.04558634340240899, data cost:0.6627144995559291 
2022-03-26 06:18:02,733: ============================================================
2022-03-26 06:18:02,736: Epoch 5/38 Batch 800/7662 eta: 2 days, 3:14:35.141632	Training Loss 6.3445 (5.9842)	Training Prec@1 94.141 (95.347)	Training Prec@5 97.852 (97.717)	
2022-03-26 06:18:02,738: ============================================================
2022-03-26 06:19:15,454: time cost, forward:0.02065133889339392, backward:0.04597648577111979, data cost:0.6619779716211643 
2022-03-26 06:19:15,457: ============================================================
2022-03-26 06:19:15,458: Epoch 5/38 Batch 900/7662 eta: 2 days, 4:26:35.727396	Training Loss 5.8572 (6.0033)	Training Prec@1 95.508 (95.278)	Training Prec@5 97.070 (97.680)	
2022-03-26 06:19:15,459: ============================================================
2022-03-26 06:20:28,922: time cost, forward:0.020790624904918956, backward:0.04647690230781013, data cost:0.6622457007865409 
2022-03-26 06:20:28,923: ============================================================
2022-03-26 06:20:28,923: Epoch 5/38 Batch 1000/7662 eta: 2 days, 4:57:28.871934	Training Loss 5.8913 (6.0142)	Training Prec@1 95.117 (95.246)	Training Prec@5 97.852 (97.669)	
2022-03-26 06:20:28,923: ============================================================
2022-03-26 06:21:38,278: time cost, forward:0.0205899671167542, backward:0.04642404698587961, data cost:0.6593131546110755 
2022-03-26 06:21:38,282: ============================================================
2022-03-26 06:21:38,283: Epoch 5/38 Batch 1100/7662 eta: 2 days, 1:58:43.987957	Training Loss 6.3419 (6.0265)	Training Prec@1 94.141 (95.198)	Training Prec@5 96.875 (97.643)	
2022-03-26 06:21:38,283: ============================================================
2022-03-26 06:22:53,400: time cost, forward:0.02059770107666983, backward:0.04673900059404922, data cost:0.6609362677000681 
2022-03-26 06:22:53,400: ============================================================
2022-03-26 06:22:53,401: Epoch 5/38 Batch 1200/7662 eta: 2 days, 6:06:28.942742	Training Loss 6.0997 (6.0392)	Training Prec@1 96.484 (95.167)	Training Prec@5 99.023 (97.625)	
2022-03-26 06:22:53,401: ============================================================
2022-03-26 06:24:03,667: time cost, forward:0.020435107130560168, backward:0.04651462490325528, data cost:0.6592490373894836 
2022-03-26 06:24:03,668: ============================================================
2022-03-26 06:24:03,668: Epoch 5/38 Batch 1300/7662 eta: 2 days, 2:35:39.245096	Training Loss 6.2284 (6.0494)	Training Prec@1 93.945 (95.121)	Training Prec@5 96.094 (97.599)	
2022-03-26 06:24:03,668: ============================================================
2022-03-26 06:25:19,214: time cost, forward:0.020601854740167364, backward:0.046349916055936996, data cost:0.6612462602060467 
2022-03-26 06:25:19,215: ============================================================
2022-03-26 06:25:19,215: Epoch 5/38 Batch 1400/7662 eta: 2 days, 6:22:29.136593	Training Loss 5.8898 (6.0590)	Training Prec@1 95.703 (95.084)	Training Prec@5 98.242 (97.577)	
2022-03-26 06:25:19,215: ============================================================
2022-03-26 06:26:31,609: time cost, forward:0.020585861899520334, backward:0.046439384125804326, data cost:0.6608053468878544 
2022-03-26 06:26:31,610: ============================================================
2022-03-26 06:26:31,610: Epoch 5/38 Batch 1500/7662 eta: 2 days, 4:05:10.024322	Training Loss 6.0132 (6.0647)	Training Prec@1 95.312 (95.058)	Training Prec@5 98.047 (97.556)	
2022-03-26 06:26:31,611: ============================================================
2022-03-26 06:27:40,376: time cost, forward:0.020567892789095175, backward:0.04628992975317291, data cost:0.6583383393481494 
2022-03-26 06:27:40,376: ============================================================
2022-03-26 06:27:40,376: Epoch 5/38 Batch 1600/7662 eta: 2 days, 1:27:21.028454	Training Loss 6.2082 (6.0728)	Training Prec@1 94.922 (95.034)	Training Prec@5 96.484 (97.540)	
2022-03-26 06:27:40,376: ============================================================
2022-03-26 06:28:52,929: time cost, forward:0.02072616181982623, backward:0.04630787727620898, data cost:0.657800633462476 
2022-03-26 06:28:52,929: ============================================================
2022-03-26 06:28:52,930: Epoch 5/38 Batch 1700/7662 eta: 2 days, 4:09:34.591507	Training Loss 6.5328 (6.0797)	Training Prec@1 93.359 (95.006)	Training Prec@5 97.461 (97.525)	
2022-03-26 06:28:52,930: ============================================================
2022-03-26 06:30:06,770: time cost, forward:0.0207895860200196, backward:0.046376082948872355, data cost:0.6583359180522534 
2022-03-26 06:30:06,774: ============================================================
2022-03-26 06:30:06,776: Epoch 5/38 Batch 1800/7662 eta: 2 days, 5:04:04.429053	Training Loss 6.1225 (6.0858)	Training Prec@1 95.312 (94.986)	Training Prec@5 97.461 (97.512)	
2022-03-26 06:30:06,778: ============================================================
2022-03-26 06:31:20,548: time cost, forward:0.020874809628728192, backward:0.04654714783723258, data cost:0.6586702692314096 
2022-03-26 06:31:20,549: ============================================================
2022-03-26 06:31:20,549: Epoch 5/38 Batch 1900/7662 eta: 2 days, 4:59:46.323709	Training Loss 6.3752 (6.0901)	Training Prec@1 94.727 (94.970)	Training Prec@5 97.266 (97.498)	
2022-03-26 06:31:20,549: ============================================================
2022-03-26 06:32:32,837: time cost, forward:0.0207778072881961, backward:0.046479788108012746, data cost:0.6585141195542458 
2022-03-26 06:32:32,841: ============================================================
2022-03-26 06:32:32,844: Epoch 5/38 Batch 2000/7662 eta: 2 days, 3:54:45.905164	Training Loss 6.3223 (6.0964)	Training Prec@1 93.945 (94.941)	Training Prec@5 96.680 (97.480)	
2022-03-26 06:32:32,846: ============================================================
2022-03-26 06:33:44,158: time cost, forward:0.020744488658423422, backward:0.04644026956199294, data cost:0.6580653874405001 
2022-03-26 06:33:44,248: ============================================================
2022-03-26 06:33:44,248: Epoch 5/38 Batch 2100/7662 eta: 2 days, 3:15:17.304943	Training Loss 6.1822 (6.1012)	Training Prec@1 95.312 (94.922)	Training Prec@5 97.070 (97.466)	
2022-03-26 06:33:44,248: ============================================================
2022-03-26 06:34:59,386: time cost, forward:0.02068215361938199, backward:0.04647924922823418, data cost:0.6593681703431328 
2022-03-26 06:34:59,386: ============================================================
2022-03-26 06:34:59,386: Epoch 5/38 Batch 2200/7662 eta: 2 days, 5:54:49.328071	Training Loss 6.2160 (6.1058)	Training Prec@1 94.727 (94.899)	Training Prec@5 97.266 (97.453)	
2022-03-26 06:34:59,387: ============================================================
2022-03-26 06:36:07,321: time cost, forward:0.02060990470448179, backward:0.04635302581803702, data cost:0.6574428371887406 
2022-03-26 06:36:07,321: ============================================================
2022-03-26 06:36:07,321: Epoch 5/38 Batch 2300/7662 eta: 2 days, 0:43:33.997124	Training Loss 6.0389 (6.1094)	Training Prec@1 94.727 (94.891)	Training Prec@5 97.852 (97.451)	
2022-03-26 06:36:07,322: ============================================================
2022-03-26 06:37:16,029: time cost, forward:0.020536969134389186, backward:0.04623477515601873, data cost:0.6556616078917809 
2022-03-26 06:37:16,032: ============================================================
2022-03-26 06:37:16,033: Epoch 5/38 Batch 2400/7662 eta: 2 days, 1:15:49.185671	Training Loss 6.1475 (6.1120)	Training Prec@1 94.922 (94.882)	Training Prec@5 98.047 (97.448)	
2022-03-26 06:37:16,033: ============================================================
2022-03-26 06:38:28,280: time cost, forward:0.020493376011751135, backward:0.04620057699822483, data cost:0.6560140750369057 
2022-03-26 06:38:28,281: ============================================================
2022-03-26 06:38:28,281: Epoch 5/38 Batch 2500/7662 eta: 2 days, 3:46:48.624253	Training Loss 6.3230 (6.1134)	Training Prec@1 93.555 (94.866)	Training Prec@5 97.461 (97.438)	
2022-03-26 06:38:28,281: ============================================================
2022-03-26 06:39:38,584: time cost, forward:0.02051490304469145, backward:0.04618563327297608, data cost:0.6552044156424217 
2022-03-26 06:39:38,585: ============================================================
2022-03-26 06:39:38,586: Epoch 5/38 Batch 2600/7662 eta: 2 days, 2:22:00.794443	Training Loss 6.3181 (6.1146)	Training Prec@1 94.727 (94.862)	Training Prec@5 96.875 (97.435)	
2022-03-26 06:39:38,586: ============================================================
2022-03-26 06:40:57,409: time cost, forward:0.020630488531728195, backward:0.04642399049061411, data cost:0.6571027191977626 
2022-03-26 06:40:57,410: ============================================================
2022-03-26 06:40:57,410: Epoch 5/38 Batch 2700/7662 eta: 2 days, 8:26:56.694145	Training Loss 5.9716 (6.1168)	Training Prec@1 95.312 (94.847)	Training Prec@5 97.070 (97.427)	
2022-03-26 06:40:57,411: ============================================================
2022-03-26 06:42:05,864: time cost, forward:0.02058061449474077, backward:0.04639222043546109, data cost:0.6558524957508988 
2022-03-26 06:42:05,864: ============================================================
2022-03-26 06:42:05,864: Epoch 5/38 Batch 2800/7662 eta: 2 days, 1:00:13.006696	Training Loss 6.3784 (6.1183)	Training Prec@1 92.578 (94.837)	Training Prec@5 96.289 (97.420)	
2022-03-26 06:42:05,864: ============================================================
2022-03-26 06:43:16,380: time cost, forward:0.020571032981701497, backward:0.04637854359979751, data cost:0.654982795794284 
2022-03-26 06:43:16,383: ============================================================
2022-03-26 06:43:16,384: Epoch 5/38 Batch 2900/7662 eta: 2 days, 2:27:44.881594	Training Loss 6.0945 (6.1206)	Training Prec@1 94.922 (94.829)	Training Prec@5 96.680 (97.414)	
2022-03-26 06:43:16,385: ============================================================
2022-03-26 06:44:27,094: time cost, forward:0.02056468037932505, backward:0.046438773897100424, data cost:0.6544584370168219 
2022-03-26 06:44:27,096: ============================================================
2022-03-26 06:44:27,096: Epoch 5/38 Batch 3000/7662 eta: 2 days, 2:34:49.827042	Training Loss 6.2413 (6.1223)	Training Prec@1 92.773 (94.818)	Training Prec@5 97.266 (97.408)	
2022-03-26 06:44:27,097: ============================================================
2022-03-26 06:45:41,378: time cost, forward:0.02054742645086416, backward:0.04644799570992671, data cost:0.654937975942877 
2022-03-26 06:45:41,381: ============================================================
2022-03-26 06:45:41,382: Epoch 5/38 Batch 3100/7662 eta: 2 days, 5:06:58.391332	Training Loss 6.1623 (6.1242)	Training Prec@1 94.336 (94.813)	Training Prec@5 96.680 (97.406)	
2022-03-26 06:45:41,383: ============================================================
2022-03-26 06:46:52,853: time cost, forward:0.020530083806263578, backward:0.04650048890610194, data cost:0.6549003985048123 
2022-03-26 06:46:52,853: ============================================================
2022-03-26 06:46:52,853: Epoch 5/38 Batch 3200/7662 eta: 2 days, 3:05:02.063100	Training Loss 6.0817 (6.1249)	Training Prec@1 93.750 (94.803)	Training Prec@5 97.266 (97.400)	
2022-03-26 06:46:52,853: ============================================================
2022-03-26 06:48:05,913: time cost, forward:0.02048373063357175, backward:0.04654943455201491, data cost:0.6548996750749795 
2022-03-26 06:48:05,918: ============================================================
2022-03-26 06:48:05,920: Epoch 5/38 Batch 3300/7662 eta: 2 days, 4:12:12.072795	Training Loss 6.2545 (6.1270)	Training Prec@1 93.945 (94.794)	Training Prec@5 97.656 (97.394)	
2022-03-26 06:48:05,921: ============================================================
2022-03-26 06:49:17,537: time cost, forward:0.020477673908513096, backward:0.04655938262131397, data cost:0.654895785767459 
2022-03-26 06:49:17,538: ============================================================
2022-03-26 06:49:17,538: Epoch 5/38 Batch 3400/7662 eta: 2 days, 3:08:58.809396	Training Loss 6.5251 (6.1282)	Training Prec@1 94.531 (94.787)	Training Prec@5 97.266 (97.391)	
2022-03-26 06:49:17,538: ============================================================
2022-03-26 06:50:31,191: time cost, forward:0.02050800356193078, backward:0.04658565087875798, data cost:0.6550748472249177 
2022-03-26 06:50:31,192: ============================================================
2022-03-26 06:50:31,192: Epoch 5/38 Batch 3500/7662 eta: 2 days, 4:34:56.736778	Training Loss 6.2588 (6.1292)	Training Prec@1 93.555 (94.779)	Training Prec@5 96.680 (97.385)	
2022-03-26 06:50:31,192: ============================================================
2022-03-26 06:51:45,468: time cost, forward:0.02053398826315059, backward:0.04669844816048366, data cost:0.6555839509691057 
2022-03-26 06:51:45,468: ============================================================
2022-03-26 06:51:45,469: Epoch 5/38 Batch 3600/7662 eta: 2 days, 5:00:23.443339	Training Loss 6.1356 (6.1311)	Training Prec@1 94.141 (94.769)	Training Prec@5 97.070 (97.378)	
2022-03-26 06:51:45,469: ============================================================
2022-03-26 06:52:58,055: time cost, forward:0.020507950368975587, backward:0.046694425351879475, data cost:0.6556608851583109 
2022-03-26 06:52:58,055: ============================================================
2022-03-26 06:52:58,055: Epoch 5/38 Batch 3700/7662 eta: 2 days, 3:46:49.613026	Training Loss 5.9478 (6.1320)	Training Prec@1 94.531 (94.765)	Training Prec@5 96.680 (97.377)	
2022-03-26 06:52:58,056: ============================================================
2022-03-26 06:54:08,393: time cost, forward:0.020480787041752737, backward:0.04662310245571152, data cost:0.6551554836264156 
2022-03-26 06:54:08,394: ============================================================
2022-03-26 06:54:08,394: Epoch 5/38 Batch 3800/7662 eta: 2 days, 2:09:25.239214	Training Loss 6.0619 (6.1328)	Training Prec@1 95.312 (94.757)	Training Prec@5 97.656 (97.372)	
2022-03-26 06:54:08,394: ============================================================
2022-03-26 06:55:25,039: time cost, forward:0.020539993565949027, backward:0.04669528638561373, data cost:0.6561757900006161 
2022-03-26 06:55:25,040: ============================================================
2022-03-26 06:55:25,040: Epoch 5/38 Batch 3900/7662 eta: 2 days, 6:38:00.237792	Training Loss 6.1576 (6.1334)	Training Prec@1 94.336 (94.749)	Training Prec@5 97.266 (97.368)	
2022-03-26 06:55:25,040: ============================================================
2022-03-26 06:56:33,918: time cost, forward:0.020505810415902773, backward:0.046722444721268665, data cost:0.65518846646581 
2022-03-26 06:56:33,921: ============================================================
2022-03-26 06:56:33,922: Epoch 5/38 Batch 4000/7662 eta: 2 days, 1:04:47.607673	Training Loss 6.3576 (6.1346)	Training Prec@1 93.945 (94.742)	Training Prec@5 96.094 (97.363)	
2022-03-26 06:56:33,922: ============================================================
2022-03-26 06:57:47,923: time cost, forward:0.020501165687819754, backward:0.046690400154540006, data cost:0.6556985559158716 
2022-03-26 06:57:47,924: ============================================================
2022-03-26 06:57:47,924: Epoch 5/38 Batch 4100/7662 eta: 2 days, 4:42:29.420662	Training Loss 6.2372 (6.1355)	Training Prec@1 94.336 (94.738)	Training Prec@5 97.266 (97.361)	
2022-03-26 06:57:47,924: ============================================================
2022-03-26 06:59:00,939: time cost, forward:0.02046275218346767, backward:0.04664925218451787, data cost:0.6558614288747069 
2022-03-26 06:59:00,939: ============================================================
2022-03-26 06:59:00,939: Epoch 5/38 Batch 4200/7662 eta: 2 days, 3:59:04.969306	Training Loss 6.1263 (6.1360)	Training Prec@1 94.141 (94.733)	Training Prec@5 97.461 (97.357)	
2022-03-26 06:59:00,940: ============================================================
2022-03-26 07:00:12,930: time cost, forward:0.02043181487254471, backward:0.04660258012528917, data cost:0.6558636028452179 
2022-03-26 07:00:12,931: ============================================================
2022-03-26 07:00:12,931: Epoch 5/38 Batch 4300/7662 eta: 2 days, 3:14:09.151566	Training Loss 6.1726 (6.1375)	Training Prec@1 93.945 (94.725)	Training Prec@5 96.484 (97.355)	
2022-03-26 07:00:12,931: ============================================================
2022-03-26 07:01:23,926: time cost, forward:0.02041023659364666, backward:0.04655714120667586, data cost:0.6556116423571101 
2022-03-26 07:01:23,927: ============================================================
2022-03-26 07:01:23,927: Epoch 5/38 Batch 4400/7662 eta: 2 days, 2:30:26.585231	Training Loss 6.1955 (6.1381)	Training Prec@1 95.117 (94.721)	Training Prec@5 97.070 (97.351)	
2022-03-26 07:01:23,927: ============================================================
2022-03-26 07:02:36,713: time cost, forward:0.020420759300253978, backward:0.046640477039517764, data cost:0.6555170385433213 
2022-03-26 07:02:36,713: ============================================================
2022-03-26 07:02:36,714: Epoch 5/38 Batch 4500/7662 eta: 2 days, 3:45:40.532127	Training Loss 6.0767 (6.1384)	Training Prec@1 94.531 (94.718)	Training Prec@5 98.242 (97.349)	
2022-03-26 07:02:36,714: ============================================================
2022-03-26 07:03:49,613: time cost, forward:0.02042775538776926, backward:0.046624562511705374, data cost:0.6557259153194804 
2022-03-26 07:03:49,614: ============================================================
2022-03-26 07:03:49,614: Epoch 5/38 Batch 4600/7662 eta: 2 days, 3:49:18.045019	Training Loss 6.1409 (6.1388)	Training Prec@1 94.531 (94.714)	Training Prec@5 97.070 (97.347)	
2022-03-26 07:03:49,614: ============================================================
2022-03-26 07:05:00,593: time cost, forward:0.02043799999851601, backward:0.046640786497510224, data cost:0.6553677646980359 
2022-03-26 07:05:00,595: ============================================================
2022-03-26 07:05:00,595: Epoch 5/38 Batch 4700/7662 eta: 2 days, 2:26:16.064876	Training Loss 6.0953 (6.1390)	Training Prec@1 94.727 (94.711)	Training Prec@5 97.266 (97.346)	
2022-03-26 07:05:00,596: ============================================================
2022-03-26 07:06:15,175: time cost, forward:0.020452262461495962, backward:0.04667623407221208, data cost:0.6555892133444492 
2022-03-26 07:06:15,177: ============================================================
2022-03-26 07:06:15,179: Epoch 5/38 Batch 4800/7662 eta: 2 days, 4:58:35.888379	Training Loss 5.7908 (6.1384)	Training Prec@1 95.117 (94.710)	Training Prec@5 97.852 (97.345)	
2022-03-26 07:06:15,180: ============================================================
2022-03-26 07:07:24,349: time cost, forward:0.020432496270395634, backward:0.04661538606274977, data cost:0.6550681168606243 
2022-03-26 07:07:24,351: ============================================================
2022-03-26 07:07:24,352: Epoch 5/38 Batch 4900/7662 eta: 2 days, 1:06:53.718585	Training Loss 6.1536 (6.1385)	Training Prec@1 95.508 (94.709)	Training Prec@5 97.656 (97.343)	
2022-03-26 07:07:24,353: ============================================================
2022-03-26 07:08:40,814: time cost, forward:0.020392416429223955, backward:0.0466563246635991, data cost:0.656010083089616 
2022-03-26 07:08:40,814: ============================================================
2022-03-26 07:08:40,815: Epoch 5/38 Batch 5000/7662 eta: 2 days, 6:16:09.763972	Training Loss 6.1782 (6.1389)	Training Prec@1 94.336 (94.705)	Training Prec@5 97.070 (97.341)	
2022-03-26 07:08:40,815: ============================================================
2022-03-26 07:09:51,719: time cost, forward:0.020354934990885306, backward:0.04661847540246994, data cost:0.6557477943849087 
2022-03-26 07:09:51,719: ============================================================
2022-03-26 07:09:51,719: Epoch 5/38 Batch 5100/7662 eta: 2 days, 2:18:17.212463	Training Loss 6.0141 (6.1385)	Training Prec@1 94.727 (94.703)	Training Prec@5 96.875 (97.341)	
2022-03-26 07:09:51,720: ============================================================
2022-03-26 07:11:02,626: time cost, forward:0.020367830343993035, backward:0.04665758922068425, data cost:0.6554379974518585 
2022-03-26 07:11:02,626: ============================================================
2022-03-26 07:11:02,626: Epoch 5/38 Batch 5200/7662 eta: 2 days, 2:17:11.815837	Training Loss 6.0877 (6.1390)	Training Prec@1 95.117 (94.700)	Training Prec@5 97.656 (97.339)	
2022-03-26 07:11:02,627: ============================================================
2022-03-26 07:12:12,181: time cost, forward:0.020337099713139947, backward:0.04660069584779007, data cost:0.6549815618670151 
2022-03-26 07:12:12,182: ============================================================
2022-03-26 07:12:12,182: Epoch 5/38 Batch 5300/7662 eta: 2 days, 1:18:31.698322	Training Loss 5.9257 (6.1391)	Training Prec@1 93.945 (94.696)	Training Prec@5 96.680 (97.338)	
2022-03-26 07:12:12,182: ============================================================
2022-03-26 07:13:25,026: time cost, forward:0.020302084910249155, backward:0.04656375936058456, data cost:0.6551643395163347 
2022-03-26 07:13:25,027: ============================================================
2022-03-26 07:13:25,027: Epoch 5/38 Batch 5400/7662 eta: 2 days, 3:37:13.865864	Training Loss 6.4446 (6.1399)	Training Prec@1 92.578 (94.693)	Training Prec@5 96.875 (97.335)	
2022-03-26 07:13:25,027: ============================================================
2022-03-26 07:14:38,006: time cost, forward:0.020268527740434118, backward:0.046558052523610026, data cost:0.6551656392210721 
2022-03-26 07:14:38,008: ============================================================
2022-03-26 07:14:38,009: Epoch 5/38 Batch 5500/7662 eta: 2 days, 3:41:49.660621	Training Loss 5.7581 (6.1404)	Training Prec@1 96.289 (94.690)	Training Prec@5 98.047 (97.335)	
2022-03-26 07:14:38,010: ============================================================
2022-03-26 07:15:51,776: time cost, forward:0.02025987595655084, backward:0.04655364309598088, data cost:0.6554682662730176 
2022-03-26 07:15:51,777: ============================================================
2022-03-26 07:15:51,777: Epoch 5/38 Batch 5600/7662 eta: 2 days, 4:14:03.422877	Training Loss 6.0240 (6.1409)	Training Prec@1 95.117 (94.688)	Training Prec@5 97.656 (97.334)	
2022-03-26 07:15:51,778: ============================================================
2022-03-26 07:17:03,529: time cost, forward:0.020281267074100343, backward:0.04659593404437559, data cost:0.6553640358488608 
2022-03-26 07:17:03,530: ============================================================
2022-03-26 07:17:03,530: Epoch 5/38 Batch 5700/7662 eta: 2 days, 2:47:12.137702	Training Loss 5.9967 (6.1409)	Training Prec@1 95.898 (94.690)	Training Prec@5 99.023 (97.337)	
2022-03-26 07:17:03,530: ============================================================
2022-03-26 07:18:17,302: time cost, forward:0.02027962232051296, backward:0.04659461695524223, data cost:0.6555442963412844 
2022-03-26 07:18:17,306: ============================================================
2022-03-26 07:18:17,307: Epoch 5/38 Batch 5800/7662 eta: 2 days, 4:11:54.506626	Training Loss 6.3883 (6.1408)	Training Prec@1 93.750 (94.688)	Training Prec@5 97.266 (97.335)	
2022-03-26 07:18:17,308: ============================================================
2022-03-26 07:19:26,389: time cost, forward:0.020252848625344773, backward:0.04659085331134502, data cost:0.6551035036170133 
2022-03-26 07:19:26,390: ============================================================
2022-03-26 07:19:26,390: Epoch 5/38 Batch 5900/7662 eta: 2 days, 0:51:34.112800	Training Loss 6.2089 (6.1410)	Training Prec@1 94.141 (94.685)	Training Prec@5 97.461 (97.333)	
2022-03-26 07:19:26,390: ============================================================
2022-03-26 07:20:42,135: time cost, forward:0.0202870605428689, backward:0.046642787497447796, data cost:0.6555743213891387 
2022-03-26 07:20:42,135: ============================================================
2022-03-26 07:20:42,136: Epoch 5/38 Batch 6000/7662 eta: 2 days, 5:32:59.046250	Training Loss 6.0762 (6.1412)	Training Prec@1 94.141 (94.681)	Training Prec@5 97.656 (97.332)	
2022-03-26 07:20:42,136: ============================================================
2022-03-26 07:21:53,173: time cost, forward:0.020281085070478544, backward:0.046671904663821484, data cost:0.655239730257346 
2022-03-26 07:21:53,174: ============================================================
2022-03-26 07:21:53,174: Epoch 5/38 Batch 6100/7662 eta: 2 days, 2:12:08.769514	Training Loss 6.3579 (6.1408)	Training Prec@1 92.969 (94.682)	Training Prec@5 96.094 (97.333)	
2022-03-26 07:21:53,175: ============================================================
2022-03-26 07:23:06,626: time cost, forward:0.020298139224765494, backward:0.04665813859114052, data cost:0.6554627527362167 
2022-03-26 07:23:06,627: ============================================================
2022-03-26 07:23:06,627: Epoch 5/38 Batch 6200/7662 eta: 2 days, 3:53:17.469287	Training Loss 6.5483 (6.1409)	Training Prec@1 93.164 (94.683)	Training Prec@5 96.094 (97.334)	
2022-03-26 07:23:06,628: ============================================================
2022-03-26 07:24:18,248: time cost, forward:0.020295022309517213, backward:0.046616012699207746, data cost:0.6554062492526851 
2022-03-26 07:24:18,249: ============================================================
2022-03-26 07:24:18,249: Epoch 5/38 Batch 6300/7662 eta: 2 days, 2:34:28.566256	Training Loss 6.3950 (6.1409)	Training Prec@1 93.555 (94.682)	Training Prec@5 97.070 (97.333)	
2022-03-26 07:24:18,249: ============================================================
2022-03-26 07:25:31,404: time cost, forward:0.02030657626517323, backward:0.04663726165343456, data cost:0.6554697690335712 
2022-03-26 07:25:31,405: ============================================================
2022-03-26 07:25:31,405: Epoch 5/38 Batch 6400/7662 eta: 2 days, 3:38:16.315420	Training Loss 6.2115 (6.1407)	Training Prec@1 95.508 (94.683)	Training Prec@5 98.633 (97.333)	
2022-03-26 07:25:31,405: ============================================================
2022-03-26 07:26:42,724: time cost, forward:0.020312792852413178, backward:0.04662978728013069, data cost:0.6553320360103008 
2022-03-26 07:26:42,727: ============================================================
2022-03-26 07:26:42,728: Epoch 5/38 Batch 6500/7662 eta: 2 days, 2:19:26.375666	Training Loss 6.2484 (6.1406)	Training Prec@1 93.359 (94.680)	Training Prec@5 96.484 (97.330)	
2022-03-26 07:26:42,728: ============================================================
2022-03-26 07:27:56,239: time cost, forward:0.02031567342752109, backward:0.04662268222109949, data cost:0.6553859511258512 
2022-03-26 07:27:56,242: ============================================================
2022-03-26 07:27:56,244: Epoch 5/38 Batch 6600/7662 eta: 2 days, 3:51:02.393582	Training Loss 6.2247 (6.1407)	Training Prec@1 95.508 (94.678)	Training Prec@5 97.656 (97.327)	
2022-03-26 07:27:56,244: ============================================================
2022-03-26 07:29:12,966: time cost, forward:0.020328435351162067, backward:0.04667632261983208, data cost:0.6560854535616054 
2022-03-26 07:29:12,967: ============================================================
2022-03-26 07:29:12,967: Epoch 5/38 Batch 6700/7662 eta: 2 days, 6:05:31.619543	Training Loss 6.3198 (6.1406)	Training Prec@1 94.141 (94.676)	Training Prec@5 96.680 (97.326)	
2022-03-26 07:29:12,967: ============================================================
2022-03-26 07:30:25,635: time cost, forward:0.02030685491852242, backward:0.04664982797679068, data cost:0.6561517113007979 
2022-03-26 07:30:25,635: ============================================================
2022-03-26 07:30:25,636: Epoch 5/38 Batch 6800/7662 eta: 2 days, 3:12:46.689059	Training Loss 6.0548 (6.1407)	Training Prec@1 94.727 (94.675)	Training Prec@5 97.852 (97.325)	
2022-03-26 07:30:25,636: ============================================================
2022-03-26 07:31:35,786: time cost, forward:0.020298879480755906, backward:0.04660703590217233, data cost:0.6558824474698548 
2022-03-26 07:31:35,786: ============================================================
2022-03-26 07:31:35,787: Epoch 5/38 Batch 6900/7662 eta: 2 days, 1:25:09.232113	Training Loss 6.2037 (6.1406)	Training Prec@1 94.727 (94.674)	Training Prec@5 96.875 (97.325)	
2022-03-26 07:31:35,787: ============================================================
2022-03-26 07:32:50,349: time cost, forward:0.020280858485558013, backward:0.046601541486190445, data cost:0.6562057326292716 
2022-03-26 07:32:50,350: ============================================================
2022-03-26 07:32:50,350: Epoch 5/38 Batch 7000/7662 eta: 2 days, 4:30:24.902584	Training Loss 6.1528 (6.1401)	Training Prec@1 95.703 (94.673)	Training Prec@5 97.070 (97.324)	
2022-03-26 07:32:50,350: ============================================================
2022-03-26 07:34:05,647: time cost, forward:0.02030990099903563, backward:0.04664004485461725, data cost:0.6565398296716768 
2022-03-26 07:34:05,647: ============================================================
2022-03-26 07:34:05,647: Epoch 5/38 Batch 7100/7662 eta: 2 days, 5:00:09.940667	Training Loss 6.0841 (6.1397)	Training Prec@1 94.531 (94.672)	Training Prec@5 97.461 (97.324)	
2022-03-26 07:34:05,647: ============================================================
2022-03-26 07:35:19,444: time cost, forward:0.02030586490930493, backward:0.04663505612487411, data cost:0.6567190326341474 
2022-03-26 07:35:19,445: ============================================================
2022-03-26 07:35:19,445: Epoch 5/38 Batch 7200/7662 eta: 2 days, 3:55:36.022452	Training Loss 6.2097 (6.1394)	Training Prec@1 92.578 (94.671)	Training Prec@5 96.484 (97.324)	
2022-03-26 07:35:19,445: ============================================================
2022-03-26 07:36:33,579: time cost, forward:0.020329926892296388, backward:0.046648481215887126, data cost:0.6568687293999553 
2022-03-26 07:36:33,581: ============================================================
2022-03-26 07:36:33,582: Epoch 5/38 Batch 7300/7662 eta: 2 days, 4:08:40.131817	Training Loss 5.8511 (6.1396)	Training Prec@1 94.727 (94.668)	Training Prec@5 97.461 (97.324)	
2022-03-26 07:36:33,582: ============================================================
2022-03-26 07:37:50,754: time cost, forward:0.02036516175654824, backward:0.046697943415862836, data cost:0.6573752817519212 
2022-03-26 07:37:50,802: ============================================================
2022-03-26 07:37:50,804: Epoch 5/38 Batch 7400/7662 eta: 2 days, 6:17:35.663320	Training Loss 6.1459 (6.1392)	Training Prec@1 93.359 (94.668)	Training Prec@5 96.680 (97.323)	
2022-03-26 07:37:50,805: ============================================================
2022-03-26 07:39:05,849: time cost, forward:0.020394023092035644, backward:0.046722847424375005, data cost:0.6576444036023651 
2022-03-26 07:39:05,852: ============================================================
2022-03-26 07:39:05,854: Epoch 5/38 Batch 7500/7662 eta: 2 days, 4:44:42.769390	Training Loss 6.2870 (6.1396)	Training Prec@1 93.750 (94.666)	Training Prec@5 97.266 (97.322)	
2022-03-26 07:39:05,854: ============================================================
2022-03-26 07:40:18,616: time cost, forward:0.020420047449020824, backward:0.046748293247767574, data cost:0.6576018471171282 
2022-03-26 07:40:18,616: ============================================================
2022-03-26 07:40:18,616: Epoch 5/38 Batch 7600/7662 eta: 2 days, 3:07:04.392772	Training Loss 6.1860 (6.1395)	Training Prec@1 94.727 (94.666)	Training Prec@5 97.656 (97.323)	
2022-03-26 07:40:18,617: ============================================================
2022-03-26 07:41:08,743: Epoch: 5/38 eta: 2 days, 3:06:18.552028	Training Loss 5.9909 (6.1395)	Training Prec@1 96.289 (94.665)	Training Prec@5 98.047 (97.322)
2022-03-26 07:41:08,746: ============================================================
2022-03-26 07:41:08,841: Save Checkpoint...
2022-03-26 07:41:08,841: ============================================================
2022-03-26 07:41:12,881: Save done!
2022-03-26 07:41:12,881: ============================================================
2022-03-26 07:42:26,343: time cost, forward:0.019927296975646356, backward:0.04812578239826241, data cost:0.6627748662775214 
2022-03-26 07:42:26,344: ============================================================
2022-03-26 07:42:26,344: Epoch 6/38 Batch 100/7662 eta: 2 days, 3:32:59.356879	Training Loss 5.9788 (5.6816)	Training Prec@1 95.898 (95.752)	Training Prec@5 98.047 (97.893)	
2022-03-26 07:42:26,344: ============================================================
2022-03-26 07:43:37,673: time cost, forward:0.01788447011056258, backward:0.045482038852557465, data cost:0.6563366777333782 
2022-03-26 07:43:37,675: ============================================================
2022-03-26 07:43:37,675: Epoch 6/38 Batch 200/7662 eta: 2 days, 2:03:34.808976	Training Loss 5.8033 (5.7210)	Training Prec@1 95.312 (95.723)	Training Prec@5 97.656 (97.910)	
2022-03-26 07:43:37,675: ============================================================
2022-03-26 07:44:47,080: time cost, forward:0.018048567118054647, backward:0.04454324317217671, data cost:0.6507816832998524 
2022-03-26 07:44:47,081: ============================================================
2022-03-26 07:44:47,081: Epoch 6/38 Batch 300/7662 eta: 2 days, 0:41:23.891710	Training Loss 5.6970 (5.7560)	Training Prec@1 95.508 (95.667)	Training Prec@5 97.852 (97.914)	
2022-03-26 07:44:47,082: ============================================================
2022-03-26 07:45:58,845: time cost, forward:0.01821155954423106, backward:0.04576579908978073, data cost:0.6501605887162057 
2022-03-26 07:45:58,846: ============================================================
2022-03-26 07:45:58,846: Epoch 6/38 Batch 400/7662 eta: 2 days, 2:19:28.916034	Training Loss 5.6872 (5.7909)	Training Prec@1 97.266 (95.591)	Training Prec@5 98.633 (97.868)	
2022-03-26 07:45:58,847: ============================================================
2022-03-26 07:47:11,045: time cost, forward:0.018751554355353774, backward:0.04554655413350505, data cost:0.6509791739240199 
2022-03-26 07:47:11,048: ============================================================
2022-03-26 07:47:11,049: Epoch 6/38 Batch 500/7662 eta: 2 days, 2:36:39.815937	Training Loss 6.1377 (5.8271)	Training Prec@1 95.508 (95.527)	Training Prec@5 97.852 (97.816)	
2022-03-26 07:47:11,050: ============================================================
2022-03-26 07:48:26,961: time cost, forward:0.019237995147705078, backward:0.04580578541317846, data cost:0.6566352235255934 
2022-03-26 07:48:26,962: ============================================================
2022-03-26 07:48:26,962: Epoch 6/38 Batch 600/7662 eta: 2 days, 5:11:30.065982	Training Loss 6.0167 (5.8508)	Training Prec@1 93.750 (95.492)	Training Prec@5 97.461 (97.813)	
2022-03-26 07:48:26,963: ============================================================
2022-03-26 07:49:42,694: time cost, forward:0.019285839514670965, backward:0.046044676771150296, data cost:0.6609079199969683 
2022-03-26 07:49:42,694: ============================================================
2022-03-26 07:49:42,695: Epoch 6/38 Batch 700/7662 eta: 2 days, 5:02:36.853644	Training Loss 6.0234 (5.8690)	Training Prec@1 93.359 (95.460)	Training Prec@5 97.070 (97.793)	
2022-03-26 07:49:42,695: ============================================================
2022-03-26 07:50:54,438: time cost, forward:0.019126342742404292, backward:0.045529711679164996, data cost:0.6609614008806823 
2022-03-26 07:50:54,438: ============================================================
2022-03-26 07:50:54,439: Epoch 6/38 Batch 800/7662 eta: 2 days, 2:13:48.442732	Training Loss 6.0699 (5.8945)	Training Prec@1 93.555 (95.385)	Training Prec@5 97.461 (97.750)	
2022-03-26 07:50:54,439: ============================================================
2022-03-26 07:52:08,863: time cost, forward:0.019034717982019545, backward:0.04561777030002819, data cost:0.6629290800869001 
2022-03-26 07:52:08,863: ============================================================
2022-03-26 07:52:08,863: Epoch 6/38 Batch 900/7662 eta: 2 days, 4:05:10.436148	Training Loss 6.0485 (5.9123)	Training Prec@1 94.336 (95.338)	Training Prec@5 96.484 (97.718)	
2022-03-26 07:52:08,863: ============================================================
2022-03-26 07:53:23,281: time cost, forward:0.018869416730420606, backward:0.045471539607157815, data cost:0.6647736527420975 
2022-03-26 07:53:23,282: ============================================================
2022-03-26 07:53:23,282: Epoch 6/38 Batch 1000/7662 eta: 2 days, 4:03:42.154406	Training Loss 5.7509 (5.9258)	Training Prec@1 96.289 (95.285)	Training Prec@5 97.266 (97.685)	
2022-03-26 07:53:23,282: ============================================================
2022-03-26 07:54:36,718: time cost, forward:0.0188929939183243, backward:0.04518297241426143, data cost:0.6653038251389147 
2022-03-26 07:54:36,718: ============================================================
2022-03-26 07:54:36,718: Epoch 6/38 Batch 1100/7662 eta: 2 days, 3:21:13.461382	Training Loss 6.2942 (5.9374)	Training Prec@1 94.727 (95.249)	Training Prec@5 97.266 (97.669)	
2022-03-26 07:54:36,719: ============================================================
2022-03-26 07:55:45,108: time cost, forward:0.018702011689034178, backward:0.04499728029424494, data cost:0.6616834160484206 
2022-03-26 07:55:45,109: ============================================================
2022-03-26 07:55:45,109: Epoch 6/38 Batch 1200/7662 eta: 1 day, 23:48:23.410873	Training Loss 5.8814 (5.9504)	Training Prec@1 96.094 (95.214)	Training Prec@5 98.242 (97.651)	
2022-03-26 07:55:45,109: ============================================================
2022-03-26 07:56:53,397: time cost, forward:0.018509244258078913, backward:0.044783125848748113, data cost:0.6584837014533814 
2022-03-26 07:56:53,399: ============================================================
2022-03-26 07:56:53,401: Epoch 6/38 Batch 1300/7662 eta: 1 day, 23:43:03.897320	Training Loss 6.4493 (5.9612)	Training Prec@1 92.578 (95.185)	Training Prec@5 95.898 (97.641)	
2022-03-26 07:56:53,401: ============================================================
2022-03-26 07:58:06,553: time cost, forward:0.01853907781468706, backward:0.04497266548543934, data cost:0.6589268244020081 
2022-03-26 07:58:06,553: ============================================================
2022-03-26 07:58:06,554: Epoch 6/38 Batch 1400/7662 eta: 2 days, 3:05:41.680052	Training Loss 6.0516 (5.9703)	Training Prec@1 94.336 (95.167)	Training Prec@5 96.875 (97.625)	
2022-03-26 07:58:06,554: ============================================================
2022-03-26 07:59:17,338: time cost, forward:0.018500215455323078, backward:0.04501597733399008, data cost:0.6580759456270611 
2022-03-26 07:59:17,338: ============================================================
2022-03-26 07:59:17,339: Epoch 6/38 Batch 1500/7662 eta: 2 days, 1:25:15.886075	Training Loss 5.8074 (5.9796)	Training Prec@1 96.484 (95.151)	Training Prec@5 99.023 (97.611)	
2022-03-26 07:59:17,339: ============================================================
2022-03-26 08:00:31,904: time cost, forward:0.018657687010058318, backward:0.04509618805675972, data cost:0.6590136437955836 
2022-03-26 08:00:31,905: ============================================================
2022-03-26 08:00:31,905: Epoch 6/38 Batch 1600/7662 eta: 2 days, 4:02:26.750651	Training Loss 6.0764 (5.9860)	Training Prec@1 93.750 (95.128)	Training Prec@5 97.070 (97.597)	
2022-03-26 08:00:31,906: ============================================================
2022-03-26 08:01:45,212: time cost, forward:0.018653765083973095, backward:0.04528645152832354, data cost:0.6593599842884318 
2022-03-26 08:01:45,213: ============================================================
2022-03-26 08:01:45,213: Epoch 6/38 Batch 1700/7662 eta: 2 days, 3:08:30.454970	Training Loss 5.9444 (5.9910)	Training Prec@1 95.117 (95.108)	Training Prec@5 96.875 (97.586)	
2022-03-26 08:01:45,213: ============================================================
2022-03-26 08:03:00,393: time cost, forward:0.01863635056810024, backward:0.04559677385369429, data cost:0.6607369431659471 
2022-03-26 08:03:00,394: ============================================================
2022-03-26 08:03:00,394: Epoch 6/38 Batch 1800/7662 eta: 2 days, 4:25:38.762804	Training Loss 5.9673 (5.9972)	Training Prec@1 95.508 (95.085)	Training Prec@5 98.047 (97.572)	
2022-03-26 08:03:00,394: ============================================================
2022-03-26 08:04:13,784: time cost, forward:0.01868328061337343, backward:0.045582961132176116, data cost:0.6610734333422009 
2022-03-26 08:04:13,784: ============================================================
2022-03-26 08:04:13,784: Epoch 6/38 Batch 1900/7662 eta: 2 days, 3:09:31.228890	Training Loss 6.0460 (6.0029)	Training Prec@1 95.312 (95.062)	Training Prec@5 97.266 (97.559)	
2022-03-26 08:04:13,785: ============================================================
2022-03-26 08:05:23,590: time cost, forward:0.01875038991396638, backward:0.04550692377953961, data cost:0.6596318052195501 
2022-03-26 08:05:23,590: ============================================================
2022-03-26 08:05:23,590: Epoch 6/38 Batch 2000/7662 eta: 2 days, 0:38:26.555241	Training Loss 6.3348 (6.0081)	Training Prec@1 93.750 (95.044)	Training Prec@5 96.875 (97.553)	
2022-03-26 08:05:23,591: ============================================================
2022-03-26 08:06:36,818: time cost, forward:0.018777515957502027, backward:0.045709497875233616, data cost:0.6596927003328887 
2022-03-26 08:06:36,818: ============================================================
2022-03-26 08:06:36,818: Epoch 6/38 Batch 2100/7662 eta: 2 days, 3:00:17.235963	Training Loss 6.1197 (6.0112)	Training Prec@1 93.750 (95.031)	Training Prec@5 97.266 (97.541)	
2022-03-26 08:06:36,819: ============================================================
2022-03-26 08:07:50,735: time cost, forward:0.01878491701349013, backward:0.04571803107268163, data cost:0.6603017775998326 
2022-03-26 08:07:50,735: ============================================================
2022-03-26 08:07:50,736: Epoch 6/38 Batch 2200/7662 eta: 2 days, 3:27:51.153075	Training Loss 6.0892 (6.0162)	Training Prec@1 94.531 (95.004)	Training Prec@5 97.070 (97.526)	
2022-03-26 08:07:50,736: ============================================================
2022-03-26 08:09:00,481: time cost, forward:0.018757960961247693, backward:0.04557698267654213, data cost:0.6592457343205622 
2022-03-26 08:09:00,508: ============================================================
2022-03-26 08:09:00,508: Epoch 6/38 Batch 2300/7662 eta: 2 days, 0:33:33.316050	Training Loss 6.1059 (6.0217)	Training Prec@1 94.727 (94.979)	Training Prec@5 97.461 (97.512)	
2022-03-26 08:09:00,508: ============================================================
2022-03-26 08:10:17,575: time cost, forward:0.018831520788169694, backward:0.04570891689190819, data cost:0.6608725038355915 
2022-03-26 08:10:17,575: ============================================================
2022-03-26 08:10:17,576: Epoch 6/38 Batch 2400/7662 eta: 2 days, 5:36:52.698042	Training Loss 6.0102 (6.0251)	Training Prec@1 95.312 (94.967)	Training Prec@5 98.047 (97.503)	
2022-03-26 08:10:17,576: ============================================================
2022-03-26 08:11:27,165: time cost, forward:0.018858324866048715, backward:0.04586790131778419, data cost:0.6591314033013718 
2022-03-26 08:11:27,167: ============================================================
2022-03-26 08:11:27,169: Epoch 6/38 Batch 2500/7662 eta: 2 days, 0:23:42.931081	Training Loss 6.2801 (6.0273)	Training Prec@1 94.141 (94.960)	Training Prec@5 96.484 (97.495)	
2022-03-26 08:11:27,169: ============================================================
2022-03-26 08:12:39,323: time cost, forward:0.018797863625984734, backward:0.045913333753385466, data cost:0.6590710747650194 
2022-03-26 08:12:39,324: ============================================================
2022-03-26 08:12:39,324: Epoch 6/38 Batch 2600/7662 eta: 2 days, 2:09:27.541323	Training Loss 6.2382 (6.0305)	Training Prec@1 93.750 (94.948)	Training Prec@5 97.266 (97.488)	
2022-03-26 08:12:39,324: ============================================================
2022-03-26 08:13:49,030: time cost, forward:0.018751743768223483, backward:0.04600559017666184, data cost:0.6580502376506928 
2022-03-26 08:13:49,032: ============================================================
2022-03-26 08:13:49,033: Epoch 6/38 Batch 2700/7662 eta: 2 days, 0:26:14.300367	Training Loss 5.8814 (6.0338)	Training Prec@1 93.555 (94.935)	Training Prec@5 96.484 (97.486)	
2022-03-26 08:13:49,034: ============================================================
2022-03-26 08:15:03,644: time cost, forward:0.018768179284627626, backward:0.04598422415046106, data cost:0.6590092113163694 
2022-03-26 08:15:03,645: ============================================================
2022-03-26 08:15:03,645: Epoch 6/38 Batch 2800/7662 eta: 2 days, 3:49:26.066177	Training Loss 6.0531 (6.0362)	Training Prec@1 93.750 (94.923)	Training Prec@5 96.680 (97.479)	
2022-03-26 08:15:03,645: ============================================================
2022-03-26 08:16:16,263: time cost, forward:0.01877012685398761, backward:0.04601955298680032, data cost:0.6587095491719188 
2022-03-26 08:16:16,264: ============================================================
2022-03-26 08:16:16,264: Epoch 6/38 Batch 2900/7662 eta: 2 days, 2:25:08.744257	Training Loss 6.0309 (6.0386)	Training Prec@1 95.312 (94.913)	Training Prec@5 98.047 (97.470)	
2022-03-26 08:16:16,264: ============================================================
2022-03-26 08:17:31,847: time cost, forward:0.018793023320268335, backward:0.04603515231001174, data cost:0.6597080578125092 
2022-03-26 08:17:31,850: ============================================================
2022-03-26 08:17:31,851: Epoch 6/38 Batch 3000/7662 eta: 2 days, 4:27:31.299426	Training Loss 6.0945 (6.0407)	Training Prec@1 95.312 (94.905)	Training Prec@5 99.023 (97.465)	
2022-03-26 08:17:31,852: ============================================================
2022-03-26 08:18:45,635: time cost, forward:0.01881880220115935, backward:0.04608206673567047, data cost:0.6600479727292992 
2022-03-26 08:18:45,636: ============================================================
2022-03-26 08:18:45,636: Epoch 6/38 Batch 3100/7662 eta: 2 days, 3:11:15.921222	Training Loss 5.8731 (6.0422)	Training Prec@1 95.117 (94.897)	Training Prec@5 98.047 (97.465)	
2022-03-26 08:18:45,636: ============================================================
2022-03-26 08:19:55,974: time cost, forward:0.01876446767761097, backward:0.04598228571451467, data cost:0.6597003919625886 
2022-03-26 08:19:55,974: ============================================================
2022-03-26 08:19:55,974: Epoch 6/38 Batch 3200/7662 eta: 2 days, 0:46:37.438514	Training Loss 6.0988 (6.0436)	Training Prec@1 94.531 (94.896)	Training Prec@5 96.680 (97.464)	
2022-03-26 08:19:55,974: ============================================================
2022-03-26 08:21:12,034: time cost, forward:0.01875448870131304, backward:0.0460989082101693, data cost:0.6605788869328773 
2022-03-26 08:21:12,034: ============================================================
2022-03-26 08:21:12,035: Epoch 6/38 Batch 3300/7662 eta: 2 days, 4:43:26.506502	Training Loss 6.0374 (6.0449)	Training Prec@1 93.555 (94.890)	Training Prec@5 96.680 (97.458)	
2022-03-26 08:21:12,035: ============================================================
2022-03-26 08:22:26,594: time cost, forward:0.01879661172303988, backward:0.04619157016189634, data cost:0.6608799438190376 
2022-03-26 08:22:26,595: ============================================================
2022-03-26 08:22:26,595: Epoch 6/38 Batch 3400/7662 eta: 2 days, 3:39:48.504971	Training Loss 6.3721 (6.0469)	Training Prec@1 92.969 (94.881)	Training Prec@5 96.875 (97.452)	
2022-03-26 08:22:26,595: ============================================================
2022-03-26 08:23:43,773: time cost, forward:0.018818248302877275, backward:0.04624397545482268, data cost:0.6622505312001374 
2022-03-26 08:23:43,773: ============================================================
2022-03-26 08:23:43,774: Epoch 6/38 Batch 3500/7662 eta: 2 days, 5:27:22.299801	Training Loss 6.1625 (6.0476)	Training Prec@1 93.750 (94.879)	Training Prec@5 97.266 (97.450)	
2022-03-26 08:23:43,774: ============================================================
2022-03-26 08:24:56,575: time cost, forward:0.018816135962428766, backward:0.046201688576221596, data cost:0.6622537119781418 
2022-03-26 08:24:56,575: ============================================================
2022-03-26 08:24:56,576: Epoch 6/38 Batch 3600/7662 eta: 2 days, 2:24:16.846217	Training Loss 6.3576 (6.0497)	Training Prec@1 92.969 (94.869)	Training Prec@5 97.070 (97.445)	
2022-03-26 08:24:56,576: ============================================================
2022-03-26 08:26:12,214: time cost, forward:0.01887361369735004, backward:0.04628124021781268, data cost:0.6627975832162338 
2022-03-26 08:26:12,217: ============================================================
2022-03-26 08:26:12,218: Epoch 6/38 Batch 3700/7662 eta: 2 days, 4:20:59.499206	Training Loss 5.9814 (6.0518)	Training Prec@1 93.359 (94.857)	Training Prec@5 96.484 (97.440)	
2022-03-26 08:26:12,218: ============================================================
2022-03-26 08:27:24,313: time cost, forward:0.018891131322488687, backward:0.04635612837230886, data cost:0.6625453165626174 
2022-03-26 08:27:24,314: ============================================================
2022-03-26 08:27:24,315: Epoch 6/38 Batch 3800/7662 eta: 2 days, 1:52:35.385612	Training Loss 6.1171 (6.0530)	Training Prec@1 95.312 (94.850)	Training Prec@5 97.461 (97.436)	
2022-03-26 08:27:24,315: ============================================================
2022-03-26 08:28:40,065: time cost, forward:0.018926313211441528, backward:0.046502544623700494, data cost:0.6630657473782082 
2022-03-26 08:28:40,066: ============================================================
2022-03-26 08:28:40,066: Epoch 6/38 Batch 3900/7662 eta: 2 days, 4:23:02.049743	Training Loss 5.8554 (6.0540)	Training Prec@1 94.727 (94.845)	Training Prec@5 96.680 (97.436)	
2022-03-26 08:28:40,067: ============================================================
2022-03-26 08:29:53,386: time cost, forward:0.018913413441518034, backward:0.04651161318094798, data cost:0.6630819003621946 
2022-03-26 08:29:53,389: ============================================================
2022-03-26 08:29:53,390: Epoch 6/38 Batch 4000/7662 eta: 2 days, 2:41:02.249446	Training Loss 5.7925 (6.0548)	Training Prec@1 94.922 (94.841)	Training Prec@5 97.461 (97.435)	
2022-03-26 08:29:53,390: ============================================================
2022-03-26 08:31:10,476: time cost, forward:0.01893306697511359, backward:0.04646973296996296, data cost:0.6639518658688488 
2022-03-26 08:31:10,477: ============================================================
2022-03-26 08:31:10,477: Epoch 6/38 Batch 4100/7662 eta: 2 days, 5:15:52.534878	Training Loss 6.1153 (6.0567)	Training Prec@1 95.508 (94.836)	Training Prec@5 98.047 (97.433)	
2022-03-26 08:31:10,477: ============================================================
2022-03-26 08:32:21,767: time cost, forward:0.018943760161684878, backward:0.04639367961860833, data cost:0.6637630818656127 
2022-03-26 08:32:21,768: ============================================================
2022-03-26 08:32:21,768: Epoch 6/38 Batch 4200/7662 eta: 2 days, 1:14:22.946130	Training Loss 6.1648 (6.0574)	Training Prec@1 94.727 (94.831)	Training Prec@5 96.875 (97.429)	
2022-03-26 08:32:21,768: ============================================================
2022-03-26 08:33:38,514: time cost, forward:0.018930589190525465, backward:0.04642059670461835, data cost:0.6644523986191715 
2022-03-26 08:33:38,516: ============================================================
2022-03-26 08:33:38,517: Epoch 6/38 Batch 4300/7662 eta: 2 days, 4:59:16.334561	Training Loss 5.8497 (6.0587)	Training Prec@1 96.094 (94.822)	Training Prec@5 98.242 (97.423)	
2022-03-26 08:33:38,517: ============================================================
2022-03-26 08:34:50,744: time cost, forward:0.018944854870740054, backward:0.04638662032578094, data cost:0.6642933964973202 
2022-03-26 08:34:50,744: ============================================================
2022-03-26 08:34:50,745: Epoch 6/38 Batch 4400/7662 eta: 2 days, 1:50:48.316153	Training Loss 6.0679 (6.0587)	Training Prec@1 93.945 (94.821)	Training Prec@5 96.289 (97.419)	
2022-03-26 08:34:50,745: ============================================================
2022-03-26 08:35:59,983: time cost, forward:0.01889468495330166, backward:0.046349826137816595, data cost:0.6634712653256544 
2022-03-26 08:35:59,984: ============================================================
2022-03-26 08:35:59,984: Epoch 6/38 Batch 4500/7662 eta: 1 day, 23:45:54.804995	Training Loss 6.1292 (6.0594)	Training Prec@1 95.312 (94.820)	Training Prec@5 98.242 (97.420)	
2022-03-26 08:35:59,984: ============================================================
2022-03-26 08:37:11,018: time cost, forward:0.018936666205386074, backward:0.046345011102917354, data cost:0.6631778874949907 
2022-03-26 08:37:11,018: ============================================================
2022-03-26 08:37:11,019: Epoch 6/38 Batch 4600/7662 eta: 2 days, 0:59:01.249305	Training Loss 5.9275 (6.0598)	Training Prec@1 96.289 (94.816)	Training Prec@5 98.242 (97.416)	
2022-03-26 08:37:11,019: ============================================================
2022-03-26 08:38:23,261: time cost, forward:0.01893832607963385, backward:0.046382126592021976, data cost:0.6628884413719787 
2022-03-26 08:38:23,263: ============================================================
2022-03-26 08:38:23,264: Epoch 6/38 Batch 4700/7662 eta: 2 days, 1:47:52.158097	Training Loss 6.0565 (6.0603)	Training Prec@1 94.727 (94.812)	Training Prec@5 97.070 (97.412)	
2022-03-26 08:38:23,264: ============================================================
2022-03-26 08:39:32,378: time cost, forward:0.018878622486283813, backward:0.04627026198034014, data cost:0.662286663283952 
2022-03-26 08:39:32,379: ============================================================
2022-03-26 08:39:32,379: Epoch 6/38 Batch 4800/7662 eta: 1 day, 23:37:19.255989	Training Loss 5.9449 (6.0609)	Training Prec@1 94.727 (94.807)	Training Prec@5 97.070 (97.408)	
2022-03-26 08:39:32,379: ============================================================
2022-03-26 08:40:45,444: time cost, forward:0.018929811613149463, backward:0.04628413627283455, data cost:0.6623230634550339 
2022-03-26 08:40:45,444: ============================================================
2022-03-26 08:40:45,445: Epoch 6/38 Batch 4900/7662 eta: 2 days, 2:19:24.379792	Training Loss 6.0618 (6.0612)	Training Prec@1 95.117 (94.806)	Training Prec@5 96.875 (97.410)	
2022-03-26 08:40:45,445: ============================================================
2022-03-26 08:41:58,432: time cost, forward:0.018947165258933744, backward:0.04627792180407212, data cost:0.6622040502594385 
2022-03-26 08:41:58,432: ============================================================
2022-03-26 08:41:58,433: Epoch 6/38 Batch 5000/7662 eta: 2 days, 2:14:58.773199	Training Loss 6.3044 (6.0621)	Training Prec@1 93.750 (94.803)	Training Prec@5 97.461 (97.410)	
2022-03-26 08:41:58,433: ============================================================
2022-03-26 08:43:08,217: time cost, forward:0.01888093248865936, backward:0.04625831802444473, data cost:0.6616993360038738 
2022-03-26 08:43:08,218: ============================================================
2022-03-26 08:43:08,218: Epoch 6/38 Batch 5100/7662 eta: 2 days, 0:01:31.294973	Training Loss 5.7827 (6.0616)	Training Prec@1 94.922 (94.803)	Training Prec@5 97.266 (97.411)	
2022-03-26 08:43:08,218: ============================================================
2022-03-26 08:44:19,121: time cost, forward:0.018834184421716138, backward:0.04615522371069425, data cost:0.6615778110329521 
2022-03-26 08:44:19,122: ============================================================
2022-03-26 08:44:19,122: Epoch 6/38 Batch 5200/7662 eta: 2 days, 0:46:30.805920	Training Loss 6.1761 (6.0612)	Training Prec@1 92.969 (94.803)	Training Prec@5 96.875 (97.411)	
2022-03-26 08:44:19,122: ============================================================
2022-03-26 08:45:29,084: time cost, forward:0.018767391967197525, backward:0.04613675232495108, data cost:0.661140818531996 
2022-03-26 08:45:29,085: ============================================================
2022-03-26 08:45:29,085: Epoch 6/38 Batch 5300/7662 eta: 2 days, 0:06:31.949892	Training Loss 5.9391 (6.0609)	Training Prec@1 95.117 (94.804)	Training Prec@5 97.070 (97.411)	
2022-03-26 08:45:29,085: ============================================================
2022-03-26 08:46:43,574: time cost, forward:0.018791599789467713, backward:0.04622652394216488, data cost:0.6612831829521121 
2022-03-26 08:46:43,576: ============================================================
2022-03-26 08:46:43,577: Epoch 6/38 Batch 5400/7662 eta: 2 days, 3:12:06.398290	Training Loss 6.1269 (6.0610)	Training Prec@1 94.922 (94.802)	Training Prec@5 97.656 (97.412)	
2022-03-26 08:46:43,577: ============================================================
2022-03-26 08:47:53,034: time cost, forward:0.01877143079962681, backward:0.04624603132396032, data cost:0.660730059872239 
2022-03-26 08:47:53,034: ============================================================
2022-03-26 08:47:53,034: Epoch 6/38 Batch 5500/7662 eta: 1 day, 23:43:22.370530	Training Loss 6.2746 (6.0621)	Training Prec@1 92.969 (94.798)	Training Prec@5 96.094 (97.410)	
2022-03-26 08:47:53,035: ============================================================
2022-03-26 08:49:02,999: time cost, forward:0.01873110962629446, backward:0.04616582272286542, data cost:0.6603171840312758 
2022-03-26 08:49:03,000: ============================================================
2022-03-26 08:49:03,000: Epoch 6/38 Batch 5600/7662 eta: 2 days, 0:03:08.427706	Training Loss 6.0206 (6.0629)	Training Prec@1 95.898 (94.794)	Training Prec@5 98.438 (97.408)	
2022-03-26 08:49:03,000: ============================================================
2022-03-26 08:50:15,054: time cost, forward:0.018734859570973296, backward:0.04624045194293516, data cost:0.6600217984462751 
2022-03-26 08:50:15,056: ============================================================
2022-03-26 08:50:15,057: Epoch 6/38 Batch 5700/7662 eta: 2 days, 1:28:03.935310	Training Loss 6.2492 (6.0632)	Training Prec@1 94.336 (94.792)	Training Prec@5 97.266 (97.403)	
2022-03-26 08:50:15,057: ============================================================
2022-03-26 08:51:27,633: time cost, forward:0.018744301109360012, backward:0.046224468308166095, data cost:0.6600378703446116 
2022-03-26 08:51:27,635: ============================================================
2022-03-26 08:51:27,636: Epoch 6/38 Batch 5800/7662 eta: 2 days, 1:48:24.291008	Training Loss 5.8847 (6.0632)	Training Prec@1 95.898 (94.788)	Training Prec@5 97.656 (97.400)	
2022-03-26 08:51:27,636: ============================================================
2022-03-26 08:52:36,389: time cost, forward:0.018712541656507074, backward:0.046164479452101816, data cost:0.6594916925852249 
2022-03-26 08:52:36,391: ============================================================
2022-03-26 08:52:36,392: Epoch 6/38 Batch 5900/7662 eta: 1 day, 23:09:52.229468	Training Loss 6.1102 (6.0628)	Training Prec@1 93.359 (94.789)	Training Prec@5 97.070 (97.401)	
2022-03-26 08:52:36,393: ============================================================
2022-03-26 08:53:46,902: time cost, forward:0.018705165233189193, backward:0.046135926926249286, data cost:0.6592823719457699 
2022-03-26 08:53:46,902: ============================================================
2022-03-26 08:53:46,902: Epoch 6/38 Batch 6000/7662 eta: 2 days, 0:20:53.101493	Training Loss 5.7844 (6.0633)	Training Prec@1 95.508 (94.789)	Training Prec@5 97.070 (97.400)	
2022-03-26 08:53:46,902: ============================================================
2022-03-26 08:54:59,776: time cost, forward:0.01872679018000928, backward:0.0461619380341727, data cost:0.6592564041017607 
2022-03-26 08:54:59,777: ============================================================
2022-03-26 08:54:59,777: Epoch 6/38 Batch 6100/7662 eta: 2 days, 1:56:56.783888	Training Loss 6.5792 (6.0634)	Training Prec@1 93.359 (94.786)	Training Prec@5 96.484 (97.398)	
2022-03-26 08:54:59,777: ============================================================
2022-03-26 08:56:08,487: time cost, forward:0.018687837565016373, backward:0.04611058192092347, data cost:0.658762420910292 
2022-03-26 08:56:08,488: ============================================================
2022-03-26 08:56:08,488: Epoch 6/38 Batch 6200/7662 eta: 1 day, 23:04:32.696255	Training Loss 6.3774 (6.0634)	Training Prec@1 94.727 (94.788)	Training Prec@5 97.656 (97.400)	
2022-03-26 08:56:08,488: ============================================================
2022-03-26 08:57:21,035: time cost, forward:0.01866283434159151, backward:0.04605302274709733, data cost:0.6587038012151964 
2022-03-26 08:57:21,038: ============================================================
2022-03-26 08:57:21,038: Epoch 6/38 Batch 6300/7662 eta: 2 days, 1:41:10.458533	Training Loss 6.0304 (6.0638)	Training Prec@1 94.922 (94.787)	Training Prec@5 98.047 (97.400)	
2022-03-26 08:57:21,039: ============================================================
2022-03-26 08:58:39,332: time cost, forward:0.0186815243211458, backward:0.04605847318613226, data cost:0.6596915704009123 
2022-03-26 08:58:39,351: ============================================================
2022-03-26 08:58:39,353: Epoch 6/38 Batch 6400/7662 eta: 2 days, 5:36:41.639576	Training Loss 5.9587 (6.0640)	Training Prec@1 95.508 (94.785)	Training Prec@5 97.461 (97.398)	
2022-03-26 08:58:39,353: ============================================================
2022-03-26 08:59:56,548: time cost, forward:0.018694946923280133, backward:0.046058046981029686, data cost:0.6604122351015287 
2022-03-26 08:59:56,549: ============================================================
2022-03-26 08:59:56,549: Epoch 6/38 Batch 6500/7662 eta: 2 days, 4:49:32.508927	Training Loss 6.4268 (6.0637)	Training Prec@1 92.969 (94.786)	Training Prec@5 95.312 (97.399)	
2022-03-26 08:59:56,549: ============================================================
2022-03-26 09:01:03,122: time cost, forward:0.018698444581786905, backward:0.04598540402773854, data cost:0.6595500368550973 
2022-03-26 09:01:03,123: ============================================================
2022-03-26 09:01:03,123: Epoch 6/38 Batch 6600/7662 eta: 1 day, 21:32:16.963606	Training Loss 6.1958 (6.0635)	Training Prec@1 94.141 (94.786)	Training Prec@5 97.461 (97.398)	
2022-03-26 09:01:03,124: ============================================================
2022-03-26 09:02:11,182: time cost, forward:0.018673061630515523, backward:0.04596143527642384, data cost:0.658933017694838 
2022-03-26 09:02:11,184: ============================================================
2022-03-26 09:02:11,185: Epoch 6/38 Batch 6700/7662 eta: 1 day, 22:32:11.719108	Training Loss 5.9002 (6.0635)	Training Prec@1 95.508 (94.787)	Training Prec@5 97.461 (97.398)	
2022-03-26 09:02:11,187: ============================================================
2022-03-26 09:03:21,444: time cost, forward:0.018663403356333028, backward:0.04594684162636437, data cost:0.6586230421508125 
2022-03-26 09:03:21,444: ============================================================
2022-03-26 09:03:21,444: Epoch 6/38 Batch 6800/7662 eta: 2 days, 0:01:10.906308	Training Loss 5.8143 (6.0637)	Training Prec@1 96.484 (94.785)	Training Prec@5 98.828 (97.397)	
2022-03-26 09:03:21,444: ============================================================
2022-03-26 09:04:30,848: time cost, forward:0.018643273186175646, backward:0.04590135540611797, data cost:0.6582565419586487 
2022-03-26 09:04:30,848: ============================================================
2022-03-26 09:04:30,849: Epoch 6/38 Batch 6900/7662 eta: 1 day, 23:24:57.861679	Training Loss 6.0907 (6.0641)	Training Prec@1 94.531 (94.782)	Training Prec@5 96.875 (97.396)	
2022-03-26 09:04:30,849: ============================================================
2022-03-26 09:05:38,733: time cost, forward:0.01859003456171316, backward:0.045813641185027426, data cost:0.6577366282044351 
2022-03-26 09:05:38,734: ============================================================
2022-03-26 09:05:38,734: Epoch 6/38 Batch 7000/7662 eta: 1 day, 22:21:33.932853	Training Loss 5.7934 (6.0643)	Training Prec@1 94.141 (94.780)	Training Prec@5 96.484 (97.393)	
2022-03-26 09:05:38,734: ============================================================
2022-03-26 09:06:51,030: time cost, forward:0.018561673611045673, backward:0.04577300383652041, data cost:0.6577977769424217 
2022-03-26 09:06:51,031: ============================================================
2022-03-26 09:06:51,031: Epoch 6/38 Batch 7100/7662 eta: 2 days, 1:21:07.781660	Training Loss 6.0695 (6.0640)	Training Prec@1 94.336 (94.778)	Training Prec@5 97.461 (97.392)	
2022-03-26 09:06:51,031: ============================================================
2022-03-26 09:08:03,495: time cost, forward:0.018588038811602182, backward:0.045781138804674576, data cost:0.6576714478262365 
2022-03-26 09:08:03,497: ============================================================
2022-03-26 09:08:03,498: Epoch 6/38 Batch 7200/7662 eta: 2 days, 1:26:51.716011	Training Loss 6.0781 (6.0641)	Training Prec@1 95.312 (94.777)	Training Prec@5 98.633 (97.392)	
2022-03-26 09:08:03,498: ============================================================
2022-03-26 09:09:14,245: time cost, forward:0.01858505171804432, backward:0.04575483575881809, data cost:0.657547068507692 
2022-03-26 09:09:14,246: ============================================================
2022-03-26 09:09:14,247: Epoch 6/38 Batch 7300/7662 eta: 2 days, 0:15:22.139120	Training Loss 6.2926 (6.0640)	Training Prec@1 93.945 (94.776)	Training Prec@5 97.266 (97.392)	
2022-03-26 09:09:14,247: ============================================================
2022-03-26 09:10:22,031: time cost, forward:0.018584503581643444, backward:0.04571243991302725, data cost:0.6570099498600811 
2022-03-26 09:10:22,032: ============================================================
2022-03-26 09:10:22,032: Epoch 6/38 Batch 7400/7662 eta: 1 day, 22:12:57.933926	Training Loss 6.0559 (6.0642)	Training Prec@1 95.898 (94.774)	Training Prec@5 97.656 (97.390)	
2022-03-26 09:10:22,032: ============================================================
2022-03-26 09:11:30,496: time cost, forward:0.0185824700523526, backward:0.045719337520606994, data cost:0.6563874916929231 
2022-03-26 09:11:30,497: ============================================================
2022-03-26 09:11:30,497: Epoch 6/38 Batch 7500/7662 eta: 1 day, 22:39:37.279018	Training Loss 6.0229 (6.0643)	Training Prec@1 94.336 (94.772)	Training Prec@5 96.875 (97.390)	
2022-03-26 09:11:30,498: ============================================================
2022-03-26 09:12:42,286: time cost, forward:0.018567805416349642, backward:0.04570989540367162, data cost:0.6564613804878067 
2022-03-26 09:12:42,286: ============================================================
2022-03-26 09:12:42,286: Epoch 6/38 Batch 7600/7662 eta: 2 days, 0:54:20.256064	Training Loss 5.8817 (6.0641)	Training Prec@1 96.289 (94.772)	Training Prec@5 98.242 (97.390)	
2022-03-26 09:12:42,286: ============================================================
2022-03-26 09:13:28,406: Epoch: 6/38 eta: 2 days, 0:53:35.029023	Training Loss 6.1897 (6.0643)	Training Prec@1 93.359 (94.768)	Training Prec@5 96.484 (97.387)
2022-03-26 09:13:28,407: ============================================================
2022-03-26 09:14:45,396: time cost, forward:0.022508931882453686, backward:0.048945537721267855, data cost:0.6979007022549407 
2022-03-26 09:14:45,398: ============================================================
2022-03-26 09:14:45,398: Epoch 7/38 Batch 100/7662 eta: 2 days, 4:20:09.188411	Training Loss 5.4811 (5.6341)	Training Prec@1 96.094 (95.906)	Training Prec@5 97.656 (97.958)	
2022-03-26 09:14:45,399: ============================================================
2022-03-26 09:15:58,801: time cost, forward:0.020705590895072897, backward:0.045663881541496545, data cost:0.684567479032967 
2022-03-26 09:15:58,801: ============================================================
2022-03-26 09:15:58,802: Epoch 7/38 Batch 200/7662 eta: 2 days, 1:57:07.550653	Training Loss 6.0446 (5.6863)	Training Prec@1 95.508 (95.742)	Training Prec@5 97.852 (97.902)	
2022-03-26 09:15:58,802: ============================================================
2022-03-26 09:17:07,644: time cost, forward:0.019421414786756637, backward:0.04319730889438387, data cost:0.6673091797525668 
2022-03-26 09:17:07,645: ============================================================
2022-03-26 09:17:07,645: Epoch 7/38 Batch 300/7662 eta: 1 day, 22:49:47.508653	Training Loss 6.0907 (5.7311)	Training Prec@1 95.703 (95.622)	Training Prec@5 97.656 (97.863)	
2022-03-26 09:17:07,645: ============================================================
2022-03-26 09:18:19,700: time cost, forward:0.018909964645118044, backward:0.04346926050974911, data cost:0.6647541092750722 
2022-03-26 09:18:19,701: ============================================================
2022-03-26 09:18:19,701: Epoch 7/38 Batch 400/7662 eta: 2 days, 0:59:42.308183	Training Loss 5.9290 (5.7651)	Training Prec@1 96.680 (95.553)	Training Prec@5 98.047 (97.845)	
2022-03-26 09:18:19,701: ============================================================
2022-03-26 09:19:31,903: time cost, forward:0.018827327984368394, backward:0.04389851126737728, data cost:0.6629797399402382 
2022-03-26 09:19:31,904: ============================================================
2022-03-26 09:19:31,905: Epoch 7/38 Batch 500/7662 eta: 2 days, 1:04:31.089718	Training Loss 6.0234 (5.7863)	Training Prec@1 95.117 (95.508)	Training Prec@5 98.438 (97.838)	
2022-03-26 09:19:31,905: ============================================================
2022-03-26 09:20:44,054: time cost, forward:0.018795506584027375, backward:0.04393775276031239, data cost:0.6607334386924273 
2022-03-26 09:20:44,057: ============================================================
2022-03-26 09:20:44,059: Epoch 7/38 Batch 600/7662 eta: 2 days, 1:01:16.858596	Training Loss 6.3391 (5.8131)	Training Prec@1 94.336 (95.472)	Training Prec@5 96.875 (97.810)	
2022-03-26 09:20:44,060: ============================================================
2022-03-26 09:21:58,594: time cost, forward:0.019006480815925653, backward:0.04452405398836804, data cost:0.6640163880049414 
2022-03-26 09:21:58,595: ============================================================
2022-03-26 09:21:58,595: Epoch 7/38 Batch 700/7662 eta: 2 days, 2:37:10.753159	Training Loss 5.8070 (5.8282)	Training Prec@1 95.703 (95.437)	Training Prec@5 98.242 (97.798)	
2022-03-26 09:21:58,595: ============================================================
2022-03-26 09:23:08,906: time cost, forward:0.018929508660403598, backward:0.04447511856785704, data cost:0.660518124345247 
2022-03-26 09:23:08,906: ============================================================
2022-03-26 09:23:08,907: Epoch 7/38 Batch 800/7662 eta: 1 day, 23:43:51.688211	Training Loss 5.8407 (5.8436)	Training Prec@1 94.727 (95.392)	Training Prec@5 97.266 (97.779)	
2022-03-26 09:23:08,907: ============================================================
2022-03-26 09:24:21,181: time cost, forward:0.01895969834290569, backward:0.044645281867005004, data cost:0.6603261196573531 
2022-03-26 09:24:21,182: ============================================================
2022-03-26 09:24:21,182: Epoch 7/38 Batch 900/7662 eta: 2 days, 1:02:38.269386	Training Loss 6.4705 (5.8588)	Training Prec@1 93.945 (95.368)	Training Prec@5 96.875 (97.761)	
2022-03-26 09:24:21,182: ============================================================
2022-03-26 09:25:38,705: time cost, forward:0.019195368101408292, backward:0.04488556115357606, data cost:0.6642970556730742 
2022-03-26 09:25:38,706: ============================================================
2022-03-26 09:25:38,707: Epoch 7/38 Batch 1000/7662 eta: 2 days, 4:35:02.441481	Training Loss 5.8934 (5.8734)	Training Prec@1 96.289 (95.319)	Training Prec@5 97.266 (97.730)	
2022-03-26 09:25:38,707: ============================================================
2022-03-26 09:26:47,631: time cost, forward:0.01914718153261943, backward:0.04463026044149633, data cost:0.6606561254652334 
2022-03-26 09:26:47,635: ============================================================
2022-03-26 09:26:47,636: Epoch 7/38 Batch 1100/7662 eta: 1 day, 22:44:03.873598	Training Loss 5.8133 (5.8816)	Training Prec@1 95.508 (95.295)	Training Prec@5 97.266 (97.718)	
2022-03-26 09:26:47,637: ============================================================
2022-03-26 09:28:00,609: time cost, forward:0.019340946636565833, backward:0.0447672429534174, data cost:0.6611276205824851 
2022-03-26 09:28:00,610: ============================================================
2022-03-26 09:28:00,610: Epoch 7/38 Batch 1200/7662 eta: 2 days, 1:27:28.064570	Training Loss 6.1159 (5.8918)	Training Prec@1 94.141 (95.260)	Training Prec@5 96.875 (97.701)	
2022-03-26 09:28:00,610: ============================================================
2022-03-26 09:29:15,748: time cost, forward:0.01945012362761347, backward:0.04489173312844268, data cost:0.6628025976669981 
2022-03-26 09:29:15,750: ============================================================
2022-03-26 09:29:15,751: Epoch 7/38 Batch 1300/7662 eta: 2 days, 2:54:16.613269	Training Loss 6.1287 (5.9041)	Training Prec@1 94.336 (95.226)	Training Prec@5 97.852 (97.676)	
2022-03-26 09:29:15,751: ============================================================
2022-03-26 09:30:28,152: time cost, forward:0.019340061135936244, backward:0.04498501706753909, data cost:0.662460877096082 
2022-03-26 09:30:28,154: ============================================================
2022-03-26 09:30:28,154: Epoch 7/38 Batch 1400/7662 eta: 2 days, 1:01:48.490222	Training Loss 5.7433 (5.9127)	Training Prec@1 95.117 (95.197)	Training Prec@5 98.047 (97.657)	
2022-03-26 09:30:28,155: ============================================================
2022-03-26 09:31:42,108: time cost, forward:0.019275666396565402, backward:0.04500867956236571, data cost:0.6633739676612309 
2022-03-26 09:31:42,109: ============================================================
2022-03-26 09:31:42,109: Epoch 7/38 Batch 1500/7662 eta: 2 days, 2:03:37.751093	Training Loss 5.9183 (5.9215)	Training Prec@1 95.117 (95.174)	Training Prec@5 97.461 (97.639)	
2022-03-26 09:31:42,109: ============================================================
2022-03-26 09:32:55,052: time cost, forward:0.019363187416558566, backward:0.045045120109238425, data cost:0.6632722124895355 
2022-03-26 09:32:55,053: ============================================================
2022-03-26 09:32:55,053: Epoch 7/38 Batch 1600/7662 eta: 2 days, 1:21:19.913570	Training Loss 6.0969 (5.9304)	Training Prec@1 93.945 (95.156)	Training Prec@5 98.047 (97.625)	
2022-03-26 09:32:55,053: ============================================================
2022-03-26 09:34:07,718: time cost, forward:0.019416368730353073, backward:0.04518334538604036, data cost:0.6626346490185284 
2022-03-26 09:34:07,719: ============================================================
2022-03-26 09:34:07,719: Epoch 7/38 Batch 1700/7662 eta: 2 days, 1:08:52.144431	Training Loss 6.1515 (5.9362)	Training Prec@1 93.555 (95.140)	Training Prec@5 97.656 (97.617)	
2022-03-26 09:34:07,720: ============================================================
2022-03-26 09:35:21,397: time cost, forward:0.01947665559112396, backward:0.045122816935057375, data cost:0.6631361411106859 
2022-03-26 09:35:21,402: ============================================================
2022-03-26 09:35:21,403: Epoch 7/38 Batch 1800/7662 eta: 2 days, 1:48:52.433780	Training Loss 5.8178 (5.9421)	Training Prec@1 93.945 (95.111)	Training Prec@5 96.875 (97.602)	
2022-03-26 09:35:21,403: ============================================================
2022-03-26 09:36:35,778: time cost, forward:0.01953384310022789, backward:0.04502187859955557, data cost:0.6640451353684798 
2022-03-26 09:36:35,779: ============================================================
2022-03-26 09:36:35,779: Epoch 7/38 Batch 1900/7662 eta: 2 days, 2:15:48.109039	Training Loss 6.2234 (5.9467)	Training Prec@1 92.383 (95.090)	Training Prec@5 96.680 (97.587)	
2022-03-26 09:36:35,779: ============================================================
2022-03-26 09:37:50,617: time cost, forward:0.019602321397667828, backward:0.04512472531985139, data cost:0.6647804448937344 
2022-03-26 09:37:50,618: ============================================================
2022-03-26 09:37:50,618: Epoch 7/38 Batch 2000/7662 eta: 2 days, 2:33:16.634202	Training Loss 6.1818 (5.9511)	Training Prec@1 94.336 (95.073)	Training Prec@5 97.070 (97.576)	
2022-03-26 09:37:50,618: ============================================================
2022-03-26 09:39:06,694: time cost, forward:0.019775036120766854, backward:0.04535702298288404, data cost:0.665502233128141 
2022-03-26 09:39:06,696: ============================================================
2022-03-26 09:39:06,697: Epoch 7/38 Batch 2100/7662 eta: 2 days, 3:22:15.448464	Training Loss 6.0308 (5.9556)	Training Prec@1 95.508 (95.051)	Training Prec@5 96.680 (97.559)	
2022-03-26 09:39:06,698: ============================================================
2022-03-26 09:40:18,212: time cost, forward:0.019762941141896164, backward:0.04538910147166892, data cost:0.6650043030444358 
2022-03-26 09:40:18,213: ============================================================
2022-03-26 09:40:18,213: Epoch 7/38 Batch 2200/7662 eta: 2 days, 0:16:15.011142	Training Loss 6.3449 (5.9595)	Training Prec@1 95.312 (95.035)	Training Prec@5 97.266 (97.548)	
2022-03-26 09:40:18,213: ============================================================
2022-03-26 09:41:31,216: time cost, forward:0.01970581782284173, backward:0.04538815090997471, data cost:0.6648481246853662 
2022-03-26 09:41:31,216: ============================================================
2022-03-26 09:41:31,216: Epoch 7/38 Batch 2300/7662 eta: 2 days, 1:15:13.816661	Training Loss 6.0043 (5.9633)	Training Prec@1 94.922 (95.026)	Training Prec@5 97.461 (97.543)	
2022-03-26 09:41:31,217: ============================================================
2022-03-26 09:42:45,066: time cost, forward:0.019766753790228502, backward:0.04560869184321491, data cost:0.6647303469134351 
2022-03-26 09:42:45,066: ============================================================
2022-03-26 09:42:45,067: Epoch 7/38 Batch 2400/7662 eta: 2 days, 1:48:17.046421	Training Loss 6.4129 (5.9650)	Training Prec@1 94.336 (95.015)	Training Prec@5 97.070 (97.534)	
2022-03-26 09:42:45,067: ============================================================
2022-03-26 09:43:58,756: time cost, forward:0.019783779829680895, backward:0.045616594015383254, data cost:0.6652048088255382 
2022-03-26 09:43:58,756: ============================================================
2022-03-26 09:43:58,756: Epoch 7/38 Batch 2500/7662 eta: 2 days, 1:40:34.172193	Training Loss 6.0734 (5.9680)	Training Prec@1 94.336 (95.006)	Training Prec@5 98.047 (97.529)	
2022-03-26 09:43:58,757: ============================================================
2022-03-26 09:45:12,025: time cost, forward:0.01976516238539528, backward:0.04572770961572134, data cost:0.6651168795171358 
2022-03-26 09:45:12,025: ============================================================
2022-03-26 09:45:12,026: Epoch 7/38 Batch 2600/7662 eta: 2 days, 1:22:20.058955	Training Loss 6.0230 (5.9708)	Training Prec@1 96.094 (95.002)	Training Prec@5 97.656 (97.525)	
2022-03-26 09:45:12,026: ============================================================
2022-03-26 09:46:29,298: time cost, forward:0.01978472728736315, backward:0.04585842540326848, data cost:0.6662380717426991 
2022-03-26 09:46:29,299: ============================================================
2022-03-26 09:46:29,300: Epoch 7/38 Batch 2700/7662 eta: 2 days, 4:02:57.059754	Training Loss 6.1641 (5.9731)	Training Prec@1 94.727 (94.994)	Training Prec@5 96.875 (97.525)	
2022-03-26 09:46:29,300: ============================================================
2022-03-26 09:47:45,434: time cost, forward:0.019890038870879267, backward:0.04596211757775757, data cost:0.6669453037939314 
2022-03-26 09:47:45,435: ============================================================
2022-03-26 09:47:45,436: Epoch 7/38 Batch 2800/7662 eta: 2 days, 3:15:42.283854	Training Loss 6.0347 (5.9760)	Training Prec@1 93.750 (94.986)	Training Prec@5 96.289 (97.520)	
2022-03-26 09:47:45,436: ============================================================
2022-03-26 09:48:57,847: time cost, forward:0.019885780400923918, backward:0.045955463375211295, data cost:0.6668738205295548 
2022-03-26 09:48:57,847: ============================================================
2022-03-26 09:48:57,848: Epoch 7/38 Batch 2900/7662 eta: 2 days, 0:44:04.303642	Training Loss 6.1588 (5.9770)	Training Prec@1 93.945 (94.985)	Training Prec@5 96.289 (97.517)	
2022-03-26 09:48:57,848: ============================================================
2022-03-26 09:50:15,314: time cost, forward:0.02000670251785894, backward:0.04602162668648542, data cost:0.667838290915087 
2022-03-26 09:50:15,318: ============================================================
2022-03-26 09:50:15,319: Epoch 7/38 Batch 3000/7662 eta: 2 days, 4:07:02.877943	Training Loss 6.0131 (5.9789)	Training Prec@1 94.531 (94.980)	Training Prec@5 97.461 (97.512)	
2022-03-26 09:50:15,320: ============================================================
2022-03-26 09:51:29,339: time cost, forward:0.0200296056082111, backward:0.0459957048176719, data cost:0.6678901961942995 
2022-03-26 09:51:29,341: ============================================================
2022-03-26 09:51:29,342: Epoch 7/38 Batch 3100/7662 eta: 2 days, 1:46:38.301933	Training Loss 6.0442 (5.9811)	Training Prec@1 94.531 (94.969)	Training Prec@5 97.656 (97.506)	
2022-03-26 09:51:29,343: ============================================================
2022-03-26 09:52:49,546: time cost, forward:0.02009438723092826, backward:0.04608412651987365, data cost:0.6701087748195723 
2022-03-26 09:52:49,546: ============================================================
2022-03-26 09:52:49,547: Epoch 7/38 Batch 3200/7662 eta: 2 days, 5:54:44.625233	Training Loss 5.9893 (5.9820)	Training Prec@1 94.141 (94.961)	Training Prec@5 96.875 (97.503)	
2022-03-26 09:52:49,547: ============================================================
2022-03-26 09:54:00,485: time cost, forward:0.020070056981771563, backward:0.04605670046105317, data cost:0.6690763502129644 
2022-03-26 09:54:00,488: ============================================================
2022-03-26 09:54:00,490: Epoch 7/38 Batch 3300/7662 eta: 1 day, 23:39:59.355213	Training Loss 5.8590 (5.9835)	Training Prec@1 94.336 (94.957)	Training Prec@5 97.070 (97.499)	
2022-03-26 09:54:00,491: ============================================================
2022-03-26 09:55:14,615: time cost, forward:0.020089457195693865, backward:0.046175443203738946, data cost:0.6693000428709572 
2022-03-26 09:55:14,615: ============================================================
2022-03-26 09:55:14,616: Epoch 7/38 Batch 3400/7662 eta: 2 days, 1:47:05.873472	Training Loss 6.0297 (5.9844)	Training Prec@1 94.336 (94.952)	Training Prec@5 97.852 (97.498)	
2022-03-26 09:55:14,616: ============================================================
2022-03-26 09:56:29,593: time cost, forward:0.020078973860085163, backward:0.04622745875053046, data cost:0.6696014112661688 
2022-03-26 09:56:29,594: ============================================================
2022-03-26 09:56:29,594: Epoch 7/38 Batch 3500/7662 eta: 2 days, 2:20:12.493330	Training Loss 5.9113 (5.9870)	Training Prec@1 96.484 (94.943)	Training Prec@5 98.242 (97.493)	
2022-03-26 09:56:29,595: ============================================================
2022-03-26 09:57:47,505: time cost, forward:0.020185112125113727, backward:0.04635231115315218, data cost:0.6703889999299554 
2022-03-26 09:57:47,508: ============================================================
2022-03-26 09:57:47,509: Epoch 7/38 Batch 3600/7662 eta: 2 days, 4:17:08.592853	Training Loss 6.1845 (5.9882)	Training Prec@1 93.750 (94.941)	Training Prec@5 96.875 (97.490)	
2022-03-26 09:57:47,510: ============================================================
2022-03-26 09:59:01,885: time cost, forward:0.0202164863309012, backward:0.046538238365542536, data cost:0.6703435155822638 
2022-03-26 09:59:01,889: ============================================================
2022-03-26 09:59:01,889: Epoch 7/38 Batch 3700/7662 eta: 2 days, 1:53:37.852521	Training Loss 5.9631 (5.9889)	Training Prec@1 94.531 (94.936)	Training Prec@5 96.094 (97.488)	
2022-03-26 09:59:01,890: ============================================================
2022-03-26 10:00:17,710: time cost, forward:0.020219283531954114, backward:0.046564403914501555, data cost:0.6706947908805653 
2022-03-26 10:00:17,711: ============================================================
2022-03-26 10:00:17,711: Epoch 7/38 Batch 3800/7662 eta: 2 days, 2:50:22.793765	Training Loss 6.2423 (5.9894)	Training Prec@1 92.969 (94.935)	Training Prec@5 96.289 (97.489)	
2022-03-26 10:00:17,712: ============================================================
2022-03-26 10:01:32,989: time cost, forward:0.02021129921969159, backward:0.046562334304285156, data cost:0.6712544484760982 
2022-03-26 10:01:32,989: ============================================================
2022-03-26 10:01:32,990: Epoch 7/38 Batch 3900/7662 eta: 2 days, 2:27:16.103418	Training Loss 5.9107 (5.9903)	Training Prec@1 95.508 (94.930)	Training Prec@5 98.047 (97.486)	
2022-03-26 10:01:32,990: ============================================================
2022-03-26 10:02:47,621: time cost, forward:0.02017890354727888, backward:0.04657683440463845, data cost:0.6712455025134191 
2022-03-26 10:02:47,623: ============================================================
2022-03-26 10:02:47,625: Epoch 7/38 Batch 4000/7662 eta: 2 days, 2:00:07.358047	Training Loss 5.8700 (5.9923)	Training Prec@1 95.312 (94.922)	Training Prec@5 96.875 (97.479)	
2022-03-26 10:02:47,625: ============================================================
2022-03-26 10:04:03,674: time cost, forward:0.020208339628343844, backward:0.0466079724128725, data cost:0.6718049797380107 
2022-03-26 10:04:03,677: ============================================================
2022-03-26 10:04:03,678: Epoch 7/38 Batch 4100/7662 eta: 2 days, 2:55:53.701029	Training Loss 6.0037 (5.9932)	Training Prec@1 94.336 (94.916)	Training Prec@5 96.875 (97.475)	
2022-03-26 10:04:03,679: ============================================================
2022-03-26 10:05:16,552: time cost, forward:0.02016914830545097, backward:0.04662294307189999, data cost:0.6716525057833318 
2022-03-26 10:05:16,552: ============================================================
2022-03-26 10:05:16,553: Epoch 7/38 Batch 4200/7662 eta: 2 days, 0:46:57.370599	Training Loss 6.1373 (5.9944)	Training Prec@1 92.773 (94.908)	Training Prec@5 96.875 (97.473)	
2022-03-26 10:05:16,553: ============================================================
2022-03-26 10:06:32,063: time cost, forward:0.020163699176927643, backward:0.0465630247693307, data cost:0.672063349845604 
2022-03-26 10:06:32,064: ============================================================
2022-03-26 10:06:32,064: Epoch 7/38 Batch 4300/7662 eta: 2 days, 2:31:35.520989	Training Loss 5.8567 (5.9951)	Training Prec@1 94.336 (94.902)	Training Prec@5 96.875 (97.469)	
2022-03-26 10:06:32,064: ============================================================
2022-03-26 10:07:45,782: time cost, forward:0.020196283153578163, backward:0.04650227544957547, data cost:0.6718886222154288 
2022-03-26 10:07:45,782: ============================================================
2022-03-26 10:07:45,782: Epoch 7/38 Batch 4400/7662 eta: 2 days, 1:18:22.961963	Training Loss 5.8182 (5.9965)	Training Prec@1 95.703 (94.899)	Training Prec@5 97.461 (97.468)	
2022-03-26 10:07:45,783: ============================================================
2022-03-26 10:09:02,367: time cost, forward:0.020190567354489285, backward:0.046513112022177755, data cost:0.6723951608717614 
2022-03-26 10:09:02,370: ============================================================
2022-03-26 10:09:02,371: Epoch 7/38 Batch 4500/7662 eta: 2 days, 3:12:16.243401	Training Loss 6.0646 (5.9977)	Training Prec@1 96.680 (94.898)	Training Prec@5 97.852 (97.468)	
2022-03-26 10:09:02,372: ============================================================
2022-03-26 10:10:18,535: time cost, forward:0.020242496686646357, backward:0.04648632141630866, data cost:0.6728980441175354 
2022-03-26 10:10:18,540: ============================================================
2022-03-26 10:10:18,542: Epoch 7/38 Batch 4600/7662 eta: 2 days, 2:54:14.430418	Training Loss 5.9049 (5.9984)	Training Prec@1 95.703 (94.895)	Training Prec@5 98.047 (97.467)	
2022-03-26 10:10:18,543: ============================================================
2022-03-26 10:11:33,773: time cost, forward:0.020262214370828202, backward:0.04650850508105986, data cost:0.6731779763586446 
2022-03-26 10:11:33,773: ============================================================
2022-03-26 10:11:33,773: Epoch 7/38 Batch 4700/7662 eta: 2 days, 2:15:21.990246	Training Loss 5.8312 (5.9993)	Training Prec@1 95.117 (94.891)	Training Prec@5 98.047 (97.463)	
2022-03-26 10:11:33,773: ============================================================
2022-03-26 10:12:51,730: time cost, forward:0.02029760819371727, backward:0.04657417159449138, data cost:0.6737887403770744 
2022-03-26 10:12:51,730: ============================================================
2022-03-26 10:12:51,730: Epoch 7/38 Batch 4800/7662 eta: 2 days, 4:03:17.481250	Training Loss 6.0457 (6.0000)	Training Prec@1 95.508 (94.891)	Training Prec@5 97.852 (97.462)	
2022-03-26 10:12:51,731: ============================================================
2022-03-26 10:14:04,309: time cost, forward:0.020272616002724644, backward:0.04653214430122819, data cost:0.6735988136310191 
2022-03-26 10:14:04,309: ============================================================
2022-03-26 10:14:04,309: Epoch 7/38 Batch 4900/7662 eta: 2 days, 0:26:36.149377	Training Loss 5.9737 (6.0005)	Training Prec@1 95.508 (94.889)	Training Prec@5 98.242 (97.461)	
2022-03-26 10:14:04,310: ============================================================
2022-03-26 10:15:20,385: time cost, forward:0.0203283321478291, backward:0.046537543516393706, data cost:0.6739045956965136 
2022-03-26 10:15:20,389: ============================================================
2022-03-26 10:15:20,390: Epoch 7/38 Batch 5000/7662 eta: 2 days, 2:45:32.769005	Training Loss 6.1053 (6.0010)	Training Prec@1 93.945 (94.887)	Training Prec@5 95.703 (97.460)	
2022-03-26 10:15:20,391: ============================================================
2022-03-26 10:16:36,426: time cost, forward:0.020366127010793586, backward:0.04655912946920625, data cost:0.6742027154691689 
2022-03-26 10:16:36,426: ============================================================
2022-03-26 10:16:36,427: Epoch 7/38 Batch 5100/7662 eta: 2 days, 2:42:34.280760	Training Loss 6.1272 (6.0017)	Training Prec@1 95.898 (94.883)	Training Prec@5 97.852 (97.457)	
2022-03-26 10:16:36,427: ============================================================
2022-03-26 10:17:53,334: time cost, forward:0.020368553900127113, backward:0.046558915617191284, data cost:0.6746455523389466 
2022-03-26 10:17:53,335: ============================================================
2022-03-26 10:17:53,335: Epoch 7/38 Batch 5200/7662 eta: 2 days, 3:16:08.263987	Training Loss 6.3842 (6.0021)	Training Prec@1 93.555 (94.880)	Training Prec@5 96.484 (97.454)	
2022-03-26 10:17:53,335: ============================================================
2022-03-26 10:19:09,476: time cost, forward:0.02045547865453498, backward:0.04659979450048017, data cost:0.6749358261772137 
2022-03-26 10:19:09,476: ============================================================
2022-03-26 10:19:09,476: Epoch 7/38 Batch 5300/7662 eta: 2 days, 2:44:11.869690	Training Loss 5.8511 (6.0027)	Training Prec@1 95.312 (94.877)	Training Prec@5 97.266 (97.453)	
2022-03-26 10:19:09,477: ============================================================
2022-03-26 10:20:24,398: time cost, forward:0.0204775895558368, backward:0.04665550374834598, data cost:0.6749682414971098 
2022-03-26 10:20:24,398: ============================================================
2022-03-26 10:20:24,399: Epoch 7/38 Batch 5400/7662 eta: 2 days, 1:54:12.225770	Training Loss 6.0975 (6.0031)	Training Prec@1 94.922 (94.873)	Training Prec@5 97.852 (97.451)	
2022-03-26 10:20:24,399: ============================================================
2022-03-26 10:21:42,585: time cost, forward:0.020505996070399806, backward:0.04665688623794969, data cost:0.6756130038748916 
2022-03-26 10:21:42,586: ============================================================
2022-03-26 10:21:42,586: Epoch 7/38 Batch 5500/7662 eta: 2 days, 4:03:22.670472	Training Loss 5.9117 (6.0031)	Training Prec@1 94.922 (94.872)	Training Prec@5 98.047 (97.453)	
2022-03-26 10:21:42,586: ============================================================
2022-03-26 10:22:58,907: time cost, forward:0.020496958131171864, backward:0.04658054832816869, data cost:0.6759107424587325 
2022-03-26 10:22:58,908: ============================================================
2022-03-26 10:22:58,909: Epoch 7/38 Batch 5600/7662 eta: 2 days, 2:47:38.189827	Training Loss 6.0282 (6.0029)	Training Prec@1 94.727 (94.875)	Training Prec@5 96.875 (97.454)	
2022-03-26 10:22:58,909: ============================================================
2022-03-26 10:24:15,517: time cost, forward:0.020501775770025057, backward:0.04655273551793658, data cost:0.6764498200410708 
2022-03-26 10:24:15,517: ============================================================
2022-03-26 10:24:15,517: Epoch 7/38 Batch 5700/7662 eta: 2 days, 2:57:46.347568	Training Loss 6.0466 (6.0029)	Training Prec@1 94.531 (94.876)	Training Prec@5 98.047 (97.454)	
2022-03-26 10:24:15,518: ============================================================
2022-03-26 10:25:32,804: time cost, forward:0.020520726325779583, backward:0.04656734140109638, data cost:0.6768582277122007 
2022-03-26 10:25:32,805: ============================================================
2022-03-26 10:25:32,805: Epoch 7/38 Batch 5800/7662 eta: 2 days, 3:23:35.928139	Training Loss 5.8736 (6.0034)	Training Prec@1 95.312 (94.874)	Training Prec@5 98.047 (97.452)	
2022-03-26 10:25:32,806: ============================================================
2022-03-26 10:26:47,401: time cost, forward:0.02053471548433202, backward:0.046589158837887, data cost:0.6768432640790899 
2022-03-26 10:26:47,401: ============================================================
2022-03-26 10:26:47,401: Epoch 7/38 Batch 5900/7662 eta: 2 days, 1:34:57.116654	Training Loss 5.9841 (6.0041)	Training Prec@1 94.727 (94.869)	Training Prec@5 97.852 (97.449)	
2022-03-26 10:26:47,402: ============================================================
2022-03-26 10:28:05,145: time cost, forward:0.02057402331464627, backward:0.04665832734938601, data cost:0.6772475657134797 
2022-03-26 10:28:05,145: ============================================================
2022-03-26 10:28:05,145: Epoch 7/38 Batch 6000/7662 eta: 2 days, 3:39:11.867115	Training Loss 5.9204 (6.0048)	Training Prec@1 94.922 (94.865)	Training Prec@5 97.852 (97.446)	
2022-03-26 10:28:05,146: ============================================================
2022-03-26 10:29:20,573: time cost, forward:0.02056985844313307, backward:0.046706247728444415, data cost:0.6773357383930052 
2022-03-26 10:29:20,573: ============================================================
2022-03-26 10:29:20,574: Epoch 7/38 Batch 6100/7662 eta: 2 days, 2:05:37.459543	Training Loss 6.0777 (6.0051)	Training Prec@1 95.312 (94.861)	Training Prec@5 98.242 (97.444)	
2022-03-26 10:29:20,574: ============================================================
2022-03-26 10:30:40,526: time cost, forward:0.0205863422877482, backward:0.046784670627161386, data cost:0.6781040773716333 
2022-03-26 10:30:40,527: ============================================================
2022-03-26 10:30:40,528: Epoch 7/38 Batch 6200/7662 eta: 2 days, 5:04:38.515881	Training Loss 6.0294 (6.0060)	Training Prec@1 93.750 (94.857)	Training Prec@5 97.266 (97.442)	
2022-03-26 10:30:40,528: ============================================================
2022-03-26 10:31:55,749: time cost, forward:0.020624277572401706, backward:0.04683876079232906, data cost:0.6780075458027593 
2022-03-26 10:31:55,752: ============================================================
2022-03-26 10:31:55,753: Epoch 7/38 Batch 6300/7662 eta: 2 days, 1:54:59.374050	Training Loss 6.1438 (6.0059)	Training Prec@1 94.336 (94.857)	Training Prec@5 96.680 (97.443)	
2022-03-26 10:31:55,754: ============================================================
2022-03-26 10:33:05,527: time cost, forward:0.020683787282248327, backward:0.04691914354083798, data cost:0.6772029364476038 
2022-03-26 10:33:05,527: ============================================================
2022-03-26 10:33:05,528: Epoch 7/38 Batch 6400/7662 eta: 1 day, 22:16:53.920837	Training Loss 5.8731 (6.0061)	Training Prec@1 94.727 (94.855)	Training Prec@5 98.438 (97.442)	
2022-03-26 10:33:05,528: ============================================================
2022-03-26 10:34:20,530: time cost, forward:0.020737246048048764, backward:0.04699287408681113, data cost:0.6771180387606418 
2022-03-26 10:34:20,531: ============================================================
2022-03-26 10:34:20,531: Epoch 7/38 Batch 6500/7662 eta: 2 days, 1:43:41.958826	Training Loss 6.1755 (6.0069)	Training Prec@1 94.141 (94.853)	Training Prec@5 96.875 (97.441)	
2022-03-26 10:34:20,531: ============================================================
2022-03-26 10:35:36,466: time cost, forward:0.020714461613756396, backward:0.046987764400719764, data cost:0.6772393018011794 
2022-03-26 10:35:36,469: ============================================================
2022-03-26 10:35:36,470: Epoch 7/38 Batch 6600/7662 eta: 2 days, 2:19:36.953665	Training Loss 6.5656 (6.0076)	Training Prec@1 92.578 (94.850)	Training Prec@5 95.508 (97.440)	
2022-03-26 10:35:36,471: ============================================================
2022-03-26 10:36:56,264: time cost, forward:0.020757468819066576, backward:0.04707502354292892, data cost:0.6778609410989354 
2022-03-26 10:36:56,267: ============================================================
2022-03-26 10:36:56,269: Epoch 7/38 Batch 6700/7662 eta: 2 days, 4:51:48.198864	Training Loss 5.6879 (6.0080)	Training Prec@1 94.922 (94.847)	Training Prec@5 97.656 (97.438)	
2022-03-26 10:36:56,269: ============================================================
2022-03-26 10:38:11,326: time cost, forward:0.020791073163864734, backward:0.047132387356225804, data cost:0.6778090229839555 
2022-03-26 10:38:11,332: ============================================================
2022-03-26 10:38:11,334: Epoch 7/38 Batch 6800/7662 eta: 2 days, 1:42:23.120665	Training Loss 6.1867 (6.0080)	Training Prec@1 94.922 (94.848)	Training Prec@5 97.070 (97.437)	
2022-03-26 10:38:11,336: ============================================================
2022-03-26 10:39:26,977: time cost, forward:0.02082975008536429, backward:0.04718714839290028, data cost:0.6779740978832054 
2022-03-26 10:39:26,977: ============================================================
2022-03-26 10:39:26,977: Epoch 7/38 Batch 6900/7662 eta: 2 days, 2:04:08.322571	Training Loss 6.0153 (6.0081)	Training Prec@1 94.336 (94.845)	Training Prec@5 97.656 (97.437)	
2022-03-26 10:39:26,977: ============================================================
2022-03-26 10:40:44,399: time cost, forward:0.0208877412433845, backward:0.04727399838040566, data cost:0.6780896598670394 
2022-03-26 10:40:44,402: ============================================================
2022-03-26 10:40:44,403: Epoch 7/38 Batch 7000/7662 eta: 2 days, 3:13:35.999663	Training Loss 5.7724 (6.0080)	Training Prec@1 94.531 (94.845)	Training Prec@5 97.852 (97.437)	
2022-03-26 10:40:44,404: ============================================================
2022-03-26 10:41:57,370: time cost, forward:0.020900578914620303, backward:0.04731256825132325, data cost:0.6778155936541935 
2022-03-26 10:41:57,370: ============================================================
2022-03-26 10:41:57,371: Epoch 7/38 Batch 7100/7662 eta: 2 days, 0:15:25.126986	Training Loss 5.8750 (6.0080)	Training Prec@1 94.141 (94.842)	Training Prec@5 97.461 (97.436)	
2022-03-26 10:41:57,371: ============================================================
2022-03-26 10:43:16,518: time cost, forward:0.02093125439498272, backward:0.04739226459016203, data cost:0.6783352816563577 
2022-03-26 10:43:16,519: ============================================================
2022-03-26 10:43:16,519: Epoch 7/38 Batch 7200/7662 eta: 2 days, 4:19:21.896381	Training Loss 6.0969 (6.0079)	Training Prec@1 92.969 (94.840)	Training Prec@5 95.703 (97.435)	
2022-03-26 10:43:16,519: ============================================================
2022-03-26 10:44:34,850: time cost, forward:0.020973842819188782, backward:0.04746310530271999, data cost:0.6786719164565452 
2022-03-26 10:44:34,852: ============================================================
2022-03-26 10:44:34,853: Epoch 7/38 Batch 7300/7662 eta: 2 days, 3:45:44.206613	Training Loss 6.0512 (6.0083)	Training Prec@1 93.945 (94.837)	Training Prec@5 96.680 (97.433)	
2022-03-26 10:44:34,854: ============================================================
2022-03-26 10:45:48,908: time cost, forward:0.020981280928383746, backward:0.047480229349261376, data cost:0.6785634101476359 
2022-03-26 10:45:48,909: ============================================================
2022-03-26 10:45:48,909: Epoch 7/38 Batch 7400/7662 eta: 2 days, 0:54:55.112930	Training Loss 5.9729 (6.0087)	Training Prec@1 95.117 (94.834)	Training Prec@5 97.461 (97.431)	
2022-03-26 10:45:48,910: ============================================================
2022-03-26 10:47:06,466: time cost, forward:0.0210306637445153, backward:0.04751776456673919, data cost:0.6788873314491859 
2022-03-26 10:47:06,467: ============================================================
2022-03-26 10:47:06,467: Epoch 7/38 Batch 7500/7662 eta: 2 days, 3:12:22.559470	Training Loss 5.9907 (6.0091)	Training Prec@1 93.359 (94.833)	Training Prec@5 97.852 (97.431)	
2022-03-26 10:47:06,467: ============================================================
2022-03-26 10:48:24,226: time cost, forward:0.02104574461519161, backward:0.04754314565049894, data cost:0.6792267528485744 
2022-03-26 10:48:24,227: ============================================================
2022-03-26 10:48:24,227: Epoch 7/38 Batch 7600/7662 eta: 2 days, 3:19:06.688481	Training Loss 5.7213 (6.0095)	Training Prec@1 96.289 (94.833)	Training Prec@5 98.047 (97.430)	
2022-03-26 10:48:24,227: ============================================================
2022-03-26 10:49:12,884: Epoch: 7/38 eta: 2 days, 3:18:17.699524	Training Loss 5.8100 (6.0093)	Training Prec@1 95.312 (94.834)	Training Prec@5 97.266 (97.430)
2022-03-26 10:49:12,885: ============================================================
2022-03-26 10:50:35,172: time cost, forward:0.022589278943610912, backward:0.04733368363043274, data cost:0.7539797142298534 
2022-03-26 10:50:35,172: ============================================================
2022-03-26 10:50:35,173: Epoch 8/38 Batch 100/7662 eta: 2 days, 6:15:20.304390	Training Loss 5.8253 (5.6442)	Training Prec@1 95.508 (95.788)	Training Prec@5 98.242 (97.893)	
2022-03-26 10:50:35,173: ============================================================
2022-03-26 10:51:56,169: time cost, forward:0.022296858792328955, backward:0.047300059591705475, data cost:0.7434945597720506 
2022-03-26 10:51:56,172: ============================================================
2022-03-26 10:51:56,173: Epoch 8/38 Batch 200/7662 eta: 2 days, 5:23:51.940636	Training Loss 5.5931 (5.6805)	Training Prec@1 97.461 (95.701)	Training Prec@5 98.438 (97.897)	
2022-03-26 10:51:56,174: ============================================================
2022-03-26 10:53:10,776: time cost, forward:0.02232617359097586, backward:0.047704990890911195, data cost:0.7210133155452767 
2022-03-26 10:53:10,778: ============================================================
2022-03-26 10:53:10,778: Epoch 8/38 Batch 300/7662 eta: 2 days, 1:09:40.913732	Training Loss 5.6431 (5.6922)	Training Prec@1 96.875 (95.733)	Training Prec@5 98.438 (97.931)	
2022-03-26 10:53:10,779: ============================================================
2022-03-26 10:54:27,167: time cost, forward:0.022238640558151973, backward:0.04752702103521591, data cost:0.7143500030488896 
2022-03-26 10:54:27,167: ============================================================
2022-03-26 10:54:27,167: Epoch 8/38 Batch 400/7662 eta: 2 days, 2:18:56.789486	Training Loss 5.8899 (5.7152)	Training Prec@1 94.727 (95.699)	Training Prec@5 97.266 (97.914)	
2022-03-26 10:54:27,168: ============================================================
2022-03-26 10:55:45,801: time cost, forward:0.022269273329832272, backward:0.048144530198855964, data cost:0.713744776043481 
2022-03-26 10:55:45,802: ============================================================
2022-03-26 10:55:45,803: Epoch 8/38 Batch 500/7662 eta: 2 days, 3:46:23.483027	Training Loss 5.7956 (5.7445)	Training Prec@1 96.094 (95.650)	Training Prec@5 98.828 (97.892)	
2022-03-26 10:55:45,803: ============================================================
2022-03-26 10:57:01,809: time cost, forward:0.0219374853302919, backward:0.047947647575544, data cost:0.7086529978527648 
2022-03-26 10:57:01,811: ============================================================
2022-03-26 10:57:01,812: Epoch 8/38 Batch 600/7662 eta: 2 days, 2:01:23.092432	Training Loss 6.0599 (5.7732)	Training Prec@1 97.266 (95.591)	Training Prec@5 98.438 (97.858)	
2022-03-26 10:57:01,813: ============================================================
2022-03-26 10:58:22,648: time cost, forward:0.022166460198223676, backward:0.04818676265012553, data cost:0.7134980892759877 
2022-03-26 10:58:22,648: ============================================================
2022-03-26 10:58:22,649: Epoch 8/38 Batch 700/7662 eta: 2 days, 5:10:40.444514	Training Loss 5.7390 (5.7893)	Training Prec@1 94.922 (95.537)	Training Prec@5 97.266 (97.837)	
2022-03-26 10:58:22,649: ============================================================
2022-03-26 10:59:35,238: time cost, forward:0.021907910536764857, backward:0.04798259126379135, data cost:0.7057816498867412 
2022-03-26 10:59:35,242: ============================================================
2022-03-26 10:59:35,242: Epoch 8/38 Batch 800/7662 eta: 1 day, 23:44:05.177775	Training Loss 6.0411 (5.8034)	Training Prec@1 95.117 (95.498)	Training Prec@5 97.656 (97.817)	
2022-03-26 10:59:35,243: ============================================================
2022-03-26 11:00:53,678: time cost, forward:0.022112497896188094, backward:0.04823869168426887, data cost:0.7057302075047647 
2022-03-26 11:00:53,680: ============================================================
2022-03-26 11:00:53,680: Epoch 8/38 Batch 900/7662 eta: 2 days, 3:33:22.393222	Training Loss 6.1467 (5.8209)	Training Prec@1 94.531 (95.445)	Training Prec@5 97.461 (97.793)	
2022-03-26 11:00:53,681: ============================================================
2022-03-26 11:02:09,983: time cost, forward:0.022017328827469436, backward:0.04833530783056616, data cost:0.7042580913375687 
2022-03-26 11:02:09,985: ============================================================
2022-03-26 11:02:09,986: Epoch 8/38 Batch 1000/7662 eta: 2 days, 2:08:00.149191	Training Loss 5.6982 (5.8346)	Training Prec@1 97.070 (95.419)	Training Prec@5 98.438 (97.776)	
2022-03-26 11:02:09,986: ============================================================
2022-03-26 11:03:32,239: time cost, forward:0.02229252503718757, backward:0.04868500182800015, data cost:0.7085756975699816 
2022-03-26 11:03:32,242: ============================================================
2022-03-26 11:03:32,242: Epoch 8/38 Batch 1100/7662 eta: 2 days, 6:01:12.378617	Training Loss 5.6713 (5.8450)	Training Prec@1 95.117 (95.399)	Training Prec@5 97.266 (97.761)	
2022-03-26 11:03:32,243: ============================================================
2022-03-26 11:04:50,698: time cost, forward:0.02237401354601226, backward:0.04884235793297444, data cost:0.708563611346349 
2022-03-26 11:04:50,698: ============================================================
2022-03-26 11:04:50,698: Epoch 8/38 Batch 1200/7662 eta: 2 days, 3:30:10.451492	Training Loss 6.0833 (5.8571)	Training Prec@1 93.750 (95.361)	Training Prec@5 96.484 (97.734)	
2022-03-26 11:04:50,698: ============================================================
2022-03-26 11:06:09,188: time cost, forward:0.022765118126872874, backward:0.04925131834498546, data cost:0.7078587931793777 
2022-03-26 11:06:09,189: ============================================================
2022-03-26 11:06:09,189: Epoch 8/38 Batch 1300/7662 eta: 2 days, 3:30:13.013624	Training Loss 6.0297 (5.8651)	Training Prec@1 95.117 (95.336)	Training Prec@5 97.852 (97.726)	
2022-03-26 11:06:09,189: ============================================================
2022-03-26 11:07:28,495: time cost, forward:0.02271154201226715, backward:0.04943374074127437, data cost:0.7084730169106757 
2022-03-26 11:07:28,497: ============================================================
2022-03-26 11:07:28,498: Epoch 8/38 Batch 1400/7662 eta: 2 days, 4:01:05.583117	Training Loss 5.9296 (5.8746)	Training Prec@1 96.680 (95.301)	Training Prec@5 98.242 (97.706)	
2022-03-26 11:07:28,498: ============================================================
2022-03-26 11:08:49,457: time cost, forward:0.022912976740200253, backward:0.049515506599329566, data cost:0.7100839433549164 
2022-03-26 11:08:49,458: ============================================================
2022-03-26 11:08:49,458: Epoch 8/38 Batch 1500/7662 eta: 2 days, 5:04:45.434683	Training Loss 6.0130 (5.8835)	Training Prec@1 95.312 (95.266)	Training Prec@5 97.266 (97.687)	
2022-03-26 11:08:49,458: ============================================================
2022-03-26 11:10:07,234: time cost, forward:0.022892934520070147, backward:0.049488657485551577, data cost:0.7096816476543968 
2022-03-26 11:10:07,234: ============================================================
2022-03-26 11:10:07,234: Epoch 8/38 Batch 1600/7662 eta: 2 days, 2:58:12.357884	Training Loss 5.8937 (5.8912)	Training Prec@1 94.531 (95.242)	Training Prec@5 97.266 (97.674)	
2022-03-26 11:10:07,234: ============================================================
2022-03-26 11:11:30,302: time cost, forward:0.02288000060222372, backward:0.049588364948589286, data cost:0.7124864666373537 
2022-03-26 11:11:30,302: ============================================================
2022-03-26 11:11:30,303: Epoch 8/38 Batch 1700/7662 eta: 2 days, 6:24:54.527087	Training Loss 5.9692 (5.8966)	Training Prec@1 93.164 (95.218)	Training Prec@5 97.266 (97.661)	
2022-03-26 11:11:30,303: ============================================================
2022-03-26 11:12:45,804: time cost, forward:0.02280865953391363, backward:0.04953845823520154, data cost:0.7108808686297228 
2022-03-26 11:12:45,805: ============================================================
2022-03-26 11:12:45,805: Epoch 8/38 Batch 1800/7662 eta: 2 days, 1:26:16.270387	Training Loss 5.6566 (5.8996)	Training Prec@1 96.289 (95.201)	Training Prec@5 97.852 (97.654)	
2022-03-26 11:12:45,805: ============================================================
2022-03-26 11:14:05,936: time cost, forward:0.022819632288655085, backward:0.04950936673000149, data cost:0.7112339234716205 
2022-03-26 11:14:05,938: ============================================================
2022-03-26 11:14:05,939: Epoch 8/38 Batch 1900/7662 eta: 2 days, 4:26:52.056423	Training Loss 6.0263 (5.9036)	Training Prec@1 93.945 (95.183)	Training Prec@5 95.898 (97.649)	
2022-03-26 11:14:05,939: ============================================================
2022-03-26 11:15:24,699: time cost, forward:0.022907323632137724, backward:0.049900229779883225, data cost:0.7113360553577341 
2022-03-26 11:15:24,699: ============================================================
2022-03-26 11:15:24,699: Epoch 8/38 Batch 2000/7662 eta: 2 days, 3:31:40.624724	Training Loss 6.1892 (5.9091)	Training Prec@1 95.117 (95.160)	Training Prec@5 97.461 (97.637)	
2022-03-26 11:15:24,700: ============================================================
2022-03-26 11:16:45,920: time cost, forward:0.022880161984186048, backward:0.049837487944538905, data cost:0.712462317438112 
2022-03-26 11:16:45,923: ============================================================
2022-03-26 11:16:45,924: Epoch 8/38 Batch 2100/7662 eta: 2 days, 5:07:00.674591	Training Loss 5.9079 (5.9141)	Training Prec@1 94.531 (95.143)	Training Prec@5 97.266 (97.624)	
2022-03-26 11:16:45,924: ============================================================
2022-03-26 11:18:03,838: time cost, forward:0.022855364663755963, backward:0.04970043417864249, data cost:0.7123209536753226 
2022-03-26 11:18:03,838: ============================================================
2022-03-26 11:18:03,839: Epoch 8/38 Batch 2200/7662 eta: 2 days, 2:55:51.747044	Training Loss 6.1074 (5.9194)	Training Prec@1 93.945 (95.126)	Training Prec@5 96.680 (97.612)	
2022-03-26 11:18:03,839: ============================================================
2022-03-26 11:19:25,152: time cost, forward:0.02288103456235855, backward:0.04964406306767474, data cost:0.7135454831614916 
2022-03-26 11:19:25,154: ============================================================
2022-03-26 11:19:25,155: Epoch 8/38 Batch 2300/7662 eta: 2 days, 5:07:53.318869	Training Loss 6.0041 (5.9232)	Training Prec@1 92.969 (95.118)	Training Prec@5 96.289 (97.603)	
2022-03-26 11:19:25,155: ============================================================
2022-03-26 11:20:43,957: time cost, forward:0.022861495918410676, backward:0.049614895279579435, data cost:0.7136492843476868 
2022-03-26 11:20:43,958: ============================================================
2022-03-26 11:20:43,958: Epoch 8/38 Batch 2400/7662 eta: 2 days, 3:28:05.490064	Training Loss 5.9128 (5.9251)	Training Prec@1 95.312 (95.107)	Training Prec@5 97.266 (97.596)	
2022-03-26 11:20:43,958: ============================================================
2022-03-26 11:22:03,070: time cost, forward:0.022877424323305983, backward:0.04961474297665844, data cost:0.7136407750470488 
2022-03-26 11:22:03,071: ============================================================
2022-03-26 11:22:03,071: Epoch 8/38 Batch 2500/7662 eta: 2 days, 3:38:53.620837	Training Loss 5.7795 (5.9275)	Training Prec@1 94.727 (95.093)	Training Prec@5 98.047 (97.588)	
2022-03-26 11:22:03,071: ============================================================
2022-03-26 11:23:24,382: time cost, forward:0.0229441520570562, backward:0.049738359432947, data cost:0.7142912670941296 
2022-03-26 11:23:24,384: ============================================================
2022-03-26 11:23:24,385: Epoch 8/38 Batch 2600/7662 eta: 2 days, 5:03:43.618866	Training Loss 5.9188 (5.9314)	Training Prec@1 95.898 (95.079)	Training Prec@5 98.633 (97.578)	
2022-03-26 11:23:24,385: ============================================================
2022-03-26 11:24:43,872: time cost, forward:0.02291632564300164, backward:0.049838700706139896, data cost:0.7146934978870959 
2022-03-26 11:24:43,873: ============================================================
2022-03-26 11:24:43,873: Epoch 8/38 Batch 2700/7662 eta: 2 days, 3:50:57.487782	Training Loss 6.2800 (5.9330)	Training Prec@1 92.773 (95.072)	Training Prec@5 97.070 (97.571)	
2022-03-26 11:24:43,873: ============================================================
2022-03-26 11:26:01,052: time cost, forward:0.02288858393934549, backward:0.04977902628430812, data cost:0.7141439837189647 
2022-03-26 11:26:01,053: ============================================================
2022-03-26 11:26:01,053: Epoch 8/38 Batch 2800/7662 eta: 2 days, 2:19:19.683319	Training Loss 6.0201 (5.9373)	Training Prec@1 95.312 (95.059)	Training Prec@5 97.852 (97.566)	
2022-03-26 11:26:01,053: ============================================================
2022-03-26 11:27:19,311: time cost, forward:0.022803193003854163, backward:0.04969242886454124, data cost:0.7140227276195777 
2022-03-26 11:27:19,313: ============================================================
2022-03-26 11:27:19,314: Epoch 8/38 Batch 2900/7662 eta: 2 days, 3:00:16.726135	Training Loss 6.4846 (5.9400)	Training Prec@1 93.164 (95.048)	Training Prec@5 97.070 (97.558)	
2022-03-26 11:27:19,314: ============================================================
2022-03-26 11:28:38,160: time cost, forward:0.022753863542944085, backward:0.04965872055453116, data cost:0.7139757397414128 
2022-03-26 11:28:38,162: ============================================================
2022-03-26 11:28:38,163: Epoch 8/38 Batch 3000/7662 eta: 2 days, 3:21:57.558478	Training Loss 5.9629 (5.9427)	Training Prec@1 95.312 (95.034)	Training Prec@5 97.461 (97.554)	
2022-03-26 11:28:38,163: ============================================================
2022-03-26 11:29:58,302: time cost, forward:0.02273460594674548, backward:0.049643764421992934, data cost:0.714455095019099 
2022-03-26 11:29:58,302: ============================================================
2022-03-26 11:29:58,302: Epoch 8/38 Batch 3100/7662 eta: 2 days, 4:11:07.191036	Training Loss 6.0019 (5.9448)	Training Prec@1 93.359 (95.023)	Training Prec@5 97.070 (97.548)	
2022-03-26 11:29:58,303: ============================================================
2022-03-26 11:31:16,501: time cost, forward:0.02268294164187165, backward:0.04956894600603796, data cost:0.7144817194740413 
2022-03-26 11:31:16,504: ============================================================
2022-03-26 11:31:16,505: Epoch 8/38 Batch 3200/7662 eta: 2 days, 2:54:05.134241	Training Loss 5.8079 (5.9463)	Training Prec@1 94.727 (95.011)	Training Prec@5 98.047 (97.543)	
2022-03-26 11:31:16,505: ============================================================
2022-03-26 11:32:36,780: time cost, forward:0.02270719158754236, backward:0.049650109872994334, data cost:0.7146470936980165 
2022-03-26 11:32:36,784: ============================================================
2022-03-26 11:32:36,785: Epoch 8/38 Batch 3300/7662 eta: 2 days, 4:13:54.114322	Training Loss 5.8659 (5.9469)	Training Prec@1 95.703 (95.006)	Training Prec@5 97.461 (97.538)	
2022-03-26 11:32:36,785: ============================================================
2022-03-26 11:33:58,723: time cost, forward:0.022680781174491665, backward:0.04956042384287651, data cost:0.7158888648207941 
2022-03-26 11:33:58,724: ============================================================
2022-03-26 11:33:58,724: Epoch 8/38 Batch 3400/7662 eta: 2 days, 5:17:19.731016	Training Loss 6.3093 (5.9479)	Training Prec@1 93.945 (94.998)	Training Prec@5 96.875 (97.535)	
2022-03-26 11:33:58,724: ============================================================
2022-03-26 11:35:22,832: time cost, forward:0.02264955678167395, backward:0.049497973275000655, data cost:0.7174570661301134 
2022-03-26 11:35:22,833: ============================================================
2022-03-26 11:35:22,833: Epoch 8/38 Batch 3500/7662 eta: 2 days, 6:40:34.966854	Training Loss 5.8068 (5.9498)	Training Prec@1 94.727 (94.990)	Training Prec@5 96.680 (97.530)	
2022-03-26 11:35:22,833: ============================================================
2022-03-26 11:36:38,728: time cost, forward:0.022669863588248865, backward:0.04947655689189685, data cost:0.7165319232617394 
2022-03-26 11:36:38,728: ============================================================
2022-03-26 11:36:38,728: Epoch 8/38 Batch 3600/7662 eta: 2 days, 1:18:56.094488	Training Loss 6.1419 (5.9510)	Training Prec@1 94.531 (94.982)	Training Prec@5 96.094 (97.525)	
2022-03-26 11:36:38,729: ============================================================
2022-03-26 11:37:56,254: time cost, forward:0.0226586234991729, backward:0.04957221024227838, data cost:0.7160894363498198 
2022-03-26 11:37:56,254: ============================================================
2022-03-26 11:37:56,254: Epoch 8/38 Batch 3700/7662 eta: 2 days, 2:21:13.876031	Training Loss 5.8412 (5.9517)	Training Prec@1 94.531 (94.979)	Training Prec@5 97.266 (97.524)	
2022-03-26 11:37:56,255: ============================================================
2022-03-26 11:39:15,702: time cost, forward:0.022688976116135233, backward:0.04961728032999021, data cost:0.7158746912028169 
2022-03-26 11:39:15,703: ============================================================
2022-03-26 11:39:15,703: Epoch 8/38 Batch 3800/7662 eta: 2 days, 3:34:49.805302	Training Loss 5.8384 (5.9527)	Training Prec@1 94.336 (94.977)	Training Prec@5 97.070 (97.521)	
2022-03-26 11:39:15,704: ============================================================
2022-03-26 11:40:36,729: time cost, forward:0.02270777233443709, backward:0.049692868758360834, data cost:0.7164941969575807 
2022-03-26 11:40:36,729: ============================================================
2022-03-26 11:40:36,730: Epoch 8/38 Batch 3900/7662 eta: 2 days, 4:34:56.362938	Training Loss 6.1846 (5.9543)	Training Prec@1 94.922 (94.971)	Training Prec@5 97.070 (97.518)	
2022-03-26 11:40:36,730: ============================================================
2022-03-26 11:41:55,238: time cost, forward:0.022642934939419518, backward:0.04967801730076531, data cost:0.7162556583269085 
2022-03-26 11:41:55,241: ============================================================
2022-03-26 11:41:55,242: Epoch 8/38 Batch 4000/7662 eta: 2 days, 2:55:43.264499	Training Loss 6.1130 (5.9551)	Training Prec@1 92.773 (94.966)	Training Prec@5 96.094 (97.515)	
2022-03-26 11:41:55,242: ============================================================
2022-03-26 11:43:16,188: time cost, forward:0.022688278194519625, backward:0.04977495672063555, data cost:0.7167343215612005 
2022-03-26 11:43:16,188: ============================================================
2022-03-26 11:43:16,188: Epoch 8/38 Batch 4100/7662 eta: 2 days, 4:29:08.597541	Training Loss 5.6868 (5.9558)	Training Prec@1 95.898 (94.963)	Training Prec@5 98.633 (97.513)	
2022-03-26 11:43:16,189: ============================================================
2022-03-26 11:44:34,703: time cost, forward:0.022732268971867663, backward:0.049870035426336744, data cost:0.7164408408281036 
2022-03-26 11:44:34,705: ============================================================
2022-03-26 11:44:34,706: Epoch 8/38 Batch 4200/7662 eta: 2 days, 2:53:19.453101	Training Loss 6.1044 (5.9570)	Training Prec@1 94.531 (94.958)	Training Prec@5 97.070 (97.511)	
2022-03-26 11:44:34,707: ============================================================
2022-03-26 11:45:54,642: time cost, forward:0.02273875498499918, backward:0.04985865667049872, data cost:0.7167327303086694 
2022-03-26 11:45:54,642: ============================================================
2022-03-26 11:45:54,643: Epoch 8/38 Batch 4300/7662 eta: 2 days, 3:47:10.616618	Training Loss 5.8880 (5.9577)	Training Prec@1 95.508 (94.955)	Training Prec@5 98.047 (97.508)	
2022-03-26 11:45:54,643: ============================================================
2022-03-26 11:47:12,386: time cost, forward:0.022772810030427946, backward:0.0499155742522125, data cost:0.7162173531439717 
2022-03-26 11:47:12,386: ============================================================
2022-03-26 11:47:12,387: Epoch 8/38 Batch 4400/7662 eta: 2 days, 2:20:39.207273	Training Loss 6.1256 (5.9589)	Training Prec@1 94.727 (94.953)	Training Prec@5 96.289 (97.507)	
2022-03-26 11:47:12,387: ============================================================
2022-03-26 11:48:28,367: time cost, forward:0.022724315255820738, backward:0.04985121913315535, data cost:0.7157139708185546 
2022-03-26 11:48:28,370: ============================================================
2022-03-26 11:48:28,371: Epoch 8/38 Batch 4500/7662 eta: 2 days, 1:10:59.711787	Training Loss 5.8827 (5.9599)	Training Prec@1 96.094 (94.949)	Training Prec@5 98.047 (97.504)	
2022-03-26 11:48:28,371: ============================================================
2022-03-26 11:49:47,553: time cost, forward:0.02273564303431933, backward:0.04984260014954742, data cost:0.7157467659412972 
2022-03-26 11:49:47,554: ============================================================
2022-03-26 11:49:47,554: Epoch 8/38 Batch 4600/7662 eta: 2 days, 3:13:56.617145	Training Loss 5.8374 (5.9602)	Training Prec@1 95.703 (94.949)	Training Prec@5 98.438 (97.505)	
2022-03-26 11:49:47,554: ============================================================
2022-03-26 11:51:09,005: time cost, forward:0.022740179286355234, backward:0.04987117665248821, data cost:0.7162787114642838 
2022-03-26 11:51:09,006: ============================================================
2022-03-26 11:51:09,006: Epoch 8/38 Batch 4700/7662 eta: 2 days, 4:40:39.112409	Training Loss 6.0822 (5.9608)	Training Prec@1 95.508 (94.947)	Training Prec@5 97.852 (97.504)	
2022-03-26 11:51:09,006: ============================================================
2022-03-26 11:52:28,905: time cost, forward:0.022771669591707747, backward:0.04987283621412636, data cost:0.7164085520434116 
2022-03-26 11:52:28,906: ============================================================
2022-03-26 11:52:28,906: Epoch 8/38 Batch 4800/7662 eta: 2 days, 3:39:05.737146	Training Loss 6.2149 (5.9620)	Training Prec@1 93.750 (94.943)	Training Prec@5 96.875 (97.501)	
2022-03-26 11:52:28,906: ============================================================
2022-03-26 11:53:46,106: time cost, forward:0.022771141436129693, backward:0.04984213362228727, data cost:0.7158803475538208 
2022-03-26 11:53:46,110: ============================================================
2022-03-26 11:53:46,112: Epoch 8/38 Batch 4900/7662 eta: 2 days, 1:53:17.892540	Training Loss 6.0291 (5.9628)	Training Prec@1 92.773 (94.938)	Training Prec@5 97.266 (97.499)	
2022-03-26 11:53:46,113: ============================================================
2022-03-26 11:55:06,978: time cost, forward:0.022819249623774244, backward:0.04989937124883778, data cost:0.7161842228102908 
2022-03-26 11:55:06,980: ============================================================
2022-03-26 11:55:06,981: Epoch 8/38 Batch 5000/7662 eta: 2 days, 4:13:58.460416	Training Loss 6.1624 (5.9636)	Training Prec@1 92.578 (94.933)	Training Prec@5 97.070 (97.497)	
2022-03-26 11:55:06,981: ============================================================
2022-03-26 11:56:27,031: time cost, forward:0.022884277952350946, backward:0.04996940504688683, data cost:0.7162744840422572 
2022-03-26 11:56:27,034: ============================================================
2022-03-26 11:56:27,035: Epoch 8/38 Batch 5100/7662 eta: 2 days, 3:41:04.134833	Training Loss 5.9710 (5.9638)	Training Prec@1 95.312 (94.930)	Training Prec@5 98.828 (97.497)	
2022-03-26 11:56:27,036: ============================================================
2022-03-26 11:57:52,580: time cost, forward:0.02291702540889798, backward:0.050041188228861784, data cost:0.717338637999329 
2022-03-26 11:57:52,581: ============================================================
2022-03-26 11:57:52,582: Epoch 8/38 Batch 5200/7662 eta: 2 days, 7:12:26.235138	Training Loss 6.1117 (5.9650)	Training Prec@1 94.531 (94.925)	Training Prec@5 98.242 (97.494)	
2022-03-26 11:57:52,582: ============================================================
2022-03-26 11:59:16,238: time cost, forward:0.022943176083079733, backward:0.05011188581228751, data cost:0.7181520811632728 
2022-03-26 11:59:16,239: ============================================================
2022-03-26 11:59:16,239: Epoch 8/38 Batch 5300/7662 eta: 2 days, 5:57:50.848966	Training Loss 5.6313 (5.9658)	Training Prec@1 97.461 (94.925)	Training Prec@5 98.242 (97.494)	
2022-03-26 11:59:16,239: ============================================================
2022-03-26 12:00:36,812: time cost, forward:0.022903588065882042, backward:0.050098416319068306, data cost:0.7185297403584633 
2022-03-26 12:00:36,812: ============================================================
2022-03-26 12:00:36,812: Epoch 8/38 Batch 5400/7662 eta: 2 days, 3:57:09.358464	Training Loss 6.2879 (5.9665)	Training Prec@1 93.164 (94.919)	Training Prec@5 96.875 (97.491)	
2022-03-26 12:00:36,813: ============================================================
2022-03-26 12:01:58,035: time cost, forward:0.022909013590697355, backward:0.050163395124297724, data cost:0.7187000796412919 
2022-03-26 12:01:58,036: ============================================================
2022-03-26 12:01:58,037: Epoch 8/38 Batch 5500/7662 eta: 2 days, 4:20:58.922397	Training Loss 6.1692 (5.9669)	Training Prec@1 93.945 (94.917)	Training Prec@5 97.070 (97.489)	
2022-03-26 12:01:58,038: ============================================================
2022-03-26 12:03:18,954: time cost, forward:0.022905346750680795, backward:0.050096821584836096, data cost:0.7190051014922861 
2022-03-26 12:03:18,956: ============================================================
2022-03-26 12:03:18,957: Epoch 8/38 Batch 5600/7662 eta: 2 days, 4:07:52.495982	Training Loss 5.8017 (5.9674)	Training Prec@1 96.484 (94.915)	Training Prec@5 98.633 (97.487)	
2022-03-26 12:03:18,958: ============================================================
2022-03-26 12:04:36,459: time cost, forward:0.022882230115744247, backward:0.050098938865815575, data cost:0.7188481261676227 
2022-03-26 12:04:36,460: ============================================================
2022-03-26 12:04:36,460: Epoch 8/38 Batch 5700/7662 eta: 2 days, 1:54:29.565840	Training Loss 6.3235 (5.9676)	Training Prec@1 93.359 (94.913)	Training Prec@5 96.680 (97.488)	
2022-03-26 12:04:36,460: ============================================================
2022-03-26 12:05:56,786: time cost, forward:0.022893455567535068, backward:0.05009149271653714, data cost:0.7188702280469178 
2022-03-26 12:05:56,789: ============================================================
2022-03-26 12:05:56,790: Epoch 8/38 Batch 5800/7662 eta: 2 days, 3:42:21.625543	Training Loss 6.1192 (5.9680)	Training Prec@1 94.727 (94.908)	Training Prec@5 98.047 (97.484)	
2022-03-26 12:05:56,791: ============================================================
2022-03-26 12:07:15,256: time cost, forward:0.022870306403662395, backward:0.05004876297315231, data cost:0.718816784887642 
2022-03-26 12:07:15,256: ============================================================
2022-03-26 12:07:15,256: Epoch 8/38 Batch 5900/7662 eta: 2 days, 2:29:08.193197	Training Loss 5.6919 (5.9682)	Training Prec@1 95.508 (94.907)	Training Prec@5 98.633 (97.484)	
2022-03-26 12:07:15,257: ============================================================
2022-03-26 12:08:35,327: time cost, forward:0.022896508094290332, backward:0.05007737643481453, data cost:0.718884555195387 
2022-03-26 12:08:35,328: ============================================================
2022-03-26 12:08:35,328: Epoch 8/38 Batch 6000/7662 eta: 2 days, 3:29:44.139464	Training Loss 6.1663 (5.9682)	Training Prec@1 93.164 (94.904)	Training Prec@5 96.289 (97.482)	
2022-03-26 12:08:35,329: ============================================================
2022-03-26 12:09:56,787: time cost, forward:0.022890486625750196, backward:0.05010918027593535, data cost:0.7193129938691342 
2022-03-26 12:09:56,787: ============================================================
2022-03-26 12:09:56,788: Epoch 8/38 Batch 6100/7662 eta: 2 days, 4:21:55.979683	Training Loss 5.6357 (5.9682)	Training Prec@1 95.117 (94.903)	Training Prec@5 97.656 (97.482)	
2022-03-26 12:09:56,788: ============================================================
2022-03-26 12:11:19,339: time cost, forward:0.022917212853798618, backward:0.05015121519344433, data cost:0.7196532571136922 
2022-03-26 12:11:19,342: ============================================================
2022-03-26 12:11:19,343: Epoch 8/38 Batch 6200/7662 eta: 2 days, 5:02:49.467207	Training Loss 5.8753 (5.9683)	Training Prec@1 94.531 (94.903)	Training Prec@5 97.266 (97.482)	
2022-03-26 12:11:19,343: ============================================================
2022-03-26 12:12:37,517: time cost, forward:0.02288208156942394, backward:0.05016577245697443, data cost:0.7195488137467586 
2022-03-26 12:12:37,518: ============================================================
2022-03-26 12:12:37,518: Epoch 8/38 Batch 6300/7662 eta: 2 days, 2:12:38.585653	Training Loss 5.8206 (5.9684)	Training Prec@1 94.727 (94.901)	Training Prec@5 97.266 (97.480)	
2022-03-26 12:12:37,518: ============================================================
2022-03-26 12:13:57,384: time cost, forward:0.022891456660935238, backward:0.05019911148898731, data cost:0.7195612892804248 
2022-03-26 12:13:57,384: ============================================================
2022-03-26 12:13:57,385: Epoch 8/38 Batch 6400/7662 eta: 2 days, 3:16:30.506855	Training Loss 6.0769 (5.9681)	Training Prec@1 95.117 (94.899)	Training Prec@5 97.266 (97.479)	
2022-03-26 12:13:57,385: ============================================================
2022-03-26 12:15:15,928: time cost, forward:0.022901296982454838, backward:0.05019429431069464, data cost:0.7192980166416312 
2022-03-26 12:15:15,929: ============================================================
2022-03-26 12:15:15,929: Epoch 8/38 Batch 6500/7662 eta: 2 days, 2:24:15.613185	Training Loss 6.3940 (5.9689)	Training Prec@1 92.383 (94.897)	Training Prec@5 95.898 (97.477)	
2022-03-26 12:15:15,930: ============================================================
2022-03-26 12:16:34,177: time cost, forward:0.022894540940799357, backward:0.05019243223447839, data cost:0.7192418857819566 
2022-03-26 12:16:34,178: ============================================================
2022-03-26 12:16:34,178: Epoch 8/38 Batch 6600/7662 eta: 2 days, 2:11:34.673066	Training Loss 6.0120 (5.9697)	Training Prec@1 94.922 (94.896)	Training Prec@5 98.242 (97.477)	
2022-03-26 12:16:34,178: ============================================================
2022-03-26 12:17:53,738: time cost, forward:0.022887793027174832, backward:0.05020757336494798, data cost:0.7192739554173306 
2022-03-26 12:17:53,738: ============================================================
2022-03-26 12:17:53,738: Epoch 8/38 Batch 6700/7662 eta: 2 days, 3:00:43.863358	Training Loss 5.8945 (5.9703)	Training Prec@1 95.703 (94.892)	Training Prec@5 97.852 (97.474)	
2022-03-26 12:17:53,739: ============================================================
2022-03-26 12:19:15,688: time cost, forward:0.02292515653286774, backward:0.05026609029011054, data cost:0.7195465765660046 
2022-03-26 12:19:15,688: ============================================================
2022-03-26 12:19:15,688: Epoch 8/38 Batch 6800/7662 eta: 2 days, 4:31:17.228518	Training Loss 6.1256 (5.9705)	Training Prec@1 93.164 (94.893)	Training Prec@5 97.266 (97.475)	
2022-03-26 12:19:15,689: ============================================================
2022-03-26 12:20:37,656: time cost, forward:0.022958620922654275, backward:0.05031214166091895, data cost:0.7198342098535222 
2022-03-26 12:20:37,656: ============================================================
2022-03-26 12:20:37,657: Epoch 8/38 Batch 6900/7662 eta: 2 days, 4:30:37.972688	Training Loss 6.0923 (5.9717)	Training Prec@1 92.578 (94.890)	Training Prec@5 95.508 (97.473)	
2022-03-26 12:20:37,657: ============================================================
2022-03-26 12:21:56,879: time cost, forward:0.022944935186707406, backward:0.050320313920087685, data cost:0.7197631934929412 
2022-03-26 12:21:56,879: ============================================================
2022-03-26 12:21:56,880: Epoch 8/38 Batch 7000/7662 eta: 2 days, 2:43:47.200130	Training Loss 5.8556 (5.9721)	Training Prec@1 94.531 (94.884)	Training Prec@5 96.875 (97.469)	
2022-03-26 12:21:56,880: ============================================================
2022-03-26 12:23:14,308: time cost, forward:0.02291086694357647, backward:0.05025003540430258, data cost:0.7196183852837748 
2022-03-26 12:23:14,309: ============================================================
2022-03-26 12:23:14,309: Epoch 8/38 Batch 7100/7662 eta: 2 days, 1:33:34.263447	Training Loss 6.0849 (5.9723)	Training Prec@1 94.336 (94.882)	Training Prec@5 96.875 (97.468)	
2022-03-26 12:23:14,309: ============================================================
2022-03-26 12:24:33,984: time cost, forward:0.022898896764857783, backward:0.050272879724387314, data cost:0.7195370389051049 
2022-03-26 12:24:33,986: ============================================================
2022-03-26 12:24:33,987: Epoch 8/38 Batch 7200/7662 eta: 2 days, 2:58:35.925197	Training Loss 5.9428 (5.9720)	Training Prec@1 96.289 (94.880)	Training Prec@5 97.266 (97.467)	
2022-03-26 12:24:33,987: ============================================================
2022-03-26 12:25:54,190: time cost, forward:0.022883979371678815, backward:0.05022845514540248, data cost:0.7197780059713063 
2022-03-26 12:25:54,192: ============================================================
2022-03-26 12:25:54,192: Epoch 8/38 Batch 7300/7662 eta: 2 days, 3:17:31.883450	Training Loss 6.0067 (5.9720)	Training Prec@1 94.336 (94.880)	Training Prec@5 97.070 (97.467)	
2022-03-26 12:25:54,193: ============================================================
2022-03-26 12:27:15,898: time cost, forward:0.022897836662237832, backward:0.050191051268161896, data cost:0.7200064838923447 
2022-03-26 12:27:15,900: ============================================================
2022-03-26 12:27:15,900: Epoch 8/38 Batch 7400/7662 eta: 2 days, 4:13:48.710329	Training Loss 6.0057 (5.9724)	Training Prec@1 94.531 (94.877)	Training Prec@5 97.266 (97.464)	
2022-03-26 12:27:15,901: ============================================================
2022-03-26 12:28:31,809: time cost, forward:0.022863328766864147, backward:0.05014499458794213, data cost:0.7196756508337973 
2022-03-26 12:28:31,809: ============================================================
2022-03-26 12:28:31,810: Epoch 8/38 Batch 7500/7662 eta: 2 days, 0:30:09.488250	Training Loss 6.0108 (5.9728)	Training Prec@1 95.508 (94.876)	Training Prec@5 97.070 (97.464)	
2022-03-26 12:28:31,810: ============================================================
2022-03-26 12:29:52,363: time cost, forward:0.022882356880871712, backward:0.0501727508171434, data cost:0.7197024130416491 
2022-03-26 12:29:52,365: ============================================================
2022-03-26 12:29:52,365: Epoch 8/38 Batch 7600/7662 eta: 2 days, 3:26:55.362498	Training Loss 5.8789 (5.9726)	Training Prec@1 96.484 (94.878)	Training Prec@5 98.047 (97.464)	
2022-03-26 12:29:52,366: ============================================================
2022-03-26 12:30:44,225: Epoch: 8/38 eta: 2 days, 3:26:04.612604	Training Loss 6.0638 (5.9727)	Training Prec@1 95.117 (94.878)	Training Prec@5 96.875 (97.463)
2022-03-26 12:30:44,225: ============================================================
2022-03-26 12:32:10,484: time cost, forward:0.023689428965250652, backward:0.04748497105608083, data cost:0.787625334479592 
2022-03-26 12:32:10,484: ============================================================
2022-03-26 12:32:10,484: Epoch 9/38 Batch 100/7662 eta: 2 days, 6:57:16.716485	Training Loss 5.7682 (5.5628)	Training Prec@1 93.945 (95.756)	Training Prec@5 96.875 (97.988)	
2022-03-26 12:32:10,485: ============================================================
2022-03-26 12:33:25,001: time cost, forward:0.02146695966097578, backward:0.04626668997146376, data cost:0.7335745401717909 
2022-03-26 12:33:25,004: ============================================================
2022-03-26 12:33:25,005: Epoch 9/38 Batch 200/7662 eta: 1 day, 23:32:23.246838	Training Loss 5.6847 (5.5867)	Training Prec@1 94.531 (95.791)	Training Prec@5 98.438 (98.002)	
2022-03-26 12:33:25,006: ============================================================
2022-03-26 12:34:41,494: time cost, forward:0.02187348129757272, backward:0.047565035198045814, data cost:0.717720386575297 
2022-03-26 12:34:41,501: ============================================================
2022-03-26 12:34:41,502: Epoch 9/38 Batch 300/7662 eta: 2 days, 0:46:47.330117	Training Loss 5.9223 (5.6261)	Training Prec@1 96.289 (95.714)	Training Prec@5 98.633 (97.970)	
2022-03-26 12:34:41,503: ============================================================
2022-03-26 12:36:00,858: time cost, forward:0.02285376646763699, backward:0.048207345761750876, data cost:0.7187091479624125 
2022-03-26 12:36:00,861: ============================================================
2022-03-26 12:36:00,862: Epoch 9/38 Batch 400/7662 eta: 2 days, 2:35:00.870840	Training Loss 5.7738 (5.6628)	Training Prec@1 95.312 (95.634)	Training Prec@5 97.852 (97.920)	
2022-03-26 12:36:00,863: ============================================================
2022-03-26 12:37:18,983: time cost, forward:0.022489806693159267, backward:0.04789422604746236, data cost:0.7168742583127681 
2022-03-26 12:37:18,984: ============================================================
2022-03-26 12:37:18,985: Epoch 9/38 Batch 500/7662 eta: 2 days, 1:46:23.644600	Training Loss 5.8502 (5.6889)	Training Prec@1 94.531 (95.600)	Training Prec@5 96.875 (97.905)	
2022-03-26 12:37:18,986: ============================================================
2022-03-26 12:38:37,528: time cost, forward:0.022164738834998844, backward:0.047788040068790394, data cost:0.7160071072872971 
2022-03-26 12:38:37,531: ============================================================
2022-03-26 12:38:37,532: Epoch 9/38 Batch 600/7662 eta: 2 days, 2:01:16.291781	Training Loss 5.5377 (5.7187)	Training Prec@1 95.117 (95.562)	Training Prec@5 98.047 (97.887)	
2022-03-26 12:38:37,532: ============================================================
2022-03-26 12:39:54,901: time cost, forward:0.021871001935312166, backward:0.047733361117317956, data cost:0.7154259211004036 
2022-03-26 12:39:54,902: ============================================================
2022-03-26 12:39:54,902: Epoch 9/38 Batch 700/7662 eta: 2 days, 1:15:04.392910	Training Loss 5.9764 (5.7438)	Training Prec@1 95.312 (95.513)	Training Prec@5 96.875 (97.864)	
2022-03-26 12:39:54,903: ============================================================
2022-03-26 12:41:13,516: time cost, forward:0.02189810613219222, backward:0.047889668293978005, data cost:0.7152454384575797 
2022-03-26 12:41:13,517: ============================================================
2022-03-26 12:41:13,517: Epoch 9/38 Batch 800/7662 eta: 2 days, 2:01:15.445573	Training Loss 6.0217 (5.7615)	Training Prec@1 96.289 (95.479)	Training Prec@5 98.633 (97.840)	
2022-03-26 12:41:13,517: ============================================================
2022-03-26 12:42:34,527: time cost, forward:0.022258037189487885, backward:0.04855656438197389, data cost:0.7167945563196473 
2022-03-26 12:42:34,527: ============================================================
2022-03-26 12:42:34,528: Epoch 9/38 Batch 900/7662 eta: 2 days, 3:31:23.053458	Training Loss 5.9697 (5.7804)	Training Prec@1 93.555 (95.426)	Training Prec@5 97.266 (97.805)	
2022-03-26 12:42:34,528: ============================================================
2022-03-26 12:43:51,297: time cost, forward:0.02215070266265411, backward:0.04826452949264267, data cost:0.7149217283880865 
2022-03-26 12:43:51,298: ============================================================
2022-03-26 12:43:51,298: Epoch 9/38 Batch 1000/7662 eta: 2 days, 0:48:17.400488	Training Loss 5.8260 (5.7941)	Training Prec@1 94.531 (95.395)	Training Prec@5 96.875 (97.787)	
2022-03-26 12:43:51,298: ============================================================
2022-03-26 12:45:07,279: time cost, forward:0.02214504351281816, backward:0.04830191393566739, data cost:0.7124359937447434 
2022-03-26 12:45:07,280: ============================================================
2022-03-26 12:45:07,280: Epoch 9/38 Batch 1100/7662 eta: 2 days, 0:16:56.874576	Training Loss 5.6249 (5.8081)	Training Prec@1 96.484 (95.355)	Training Prec@5 98.242 (97.761)	
2022-03-26 12:45:07,280: ============================================================
2022-03-26 12:46:26,479: time cost, forward:0.022279623451582884, backward:0.04840369677921451, data cost:0.7127359812213939 
2022-03-26 12:46:26,479: ============================================================
2022-03-26 12:46:26,480: Epoch 9/38 Batch 1200/7662 eta: 2 days, 2:18:19.030724	Training Loss 6.1909 (5.8174)	Training Prec@1 92.773 (95.338)	Training Prec@5 96.680 (97.741)	
2022-03-26 12:46:26,480: ============================================================
2022-03-26 12:47:44,571: time cost, forward:0.022230767029078766, backward:0.04834671714289359, data cost:0.7125410962049735 
2022-03-26 12:47:44,571: ============================================================
2022-03-26 12:47:44,571: Epoch 9/38 Batch 1300/7662 eta: 2 days, 1:34:47.277420	Training Loss 5.9142 (5.8280)	Training Prec@1 96.094 (95.304)	Training Prec@5 97.461 (97.719)	
2022-03-26 12:47:44,572: ============================================================
2022-03-26 12:48:59,838: time cost, forward:0.022138599841572543, backward:0.04821373702288526, data cost:0.7102386370311898 
2022-03-26 12:48:59,841: ============================================================
2022-03-26 12:48:59,842: Epoch 9/38 Batch 1400/7662 eta: 1 day, 23:46:02.749894	Training Loss 6.1592 (5.8372)	Training Prec@1 93.359 (95.275)	Training Prec@5 96.680 (97.705)	
2022-03-26 12:48:59,842: ============================================================
2022-03-26 12:50:18,317: time cost, forward:0.02213399644053881, backward:0.048206112081007294, data cost:0.7101667159553208 
2022-03-26 12:50:18,320: ============================================================
2022-03-26 12:50:18,321: Epoch 9/38 Batch 1500/7662 eta: 2 days, 1:46:56.268949	Training Loss 6.1572 (5.8473)	Training Prec@1 94.531 (95.242)	Training Prec@5 97.266 (97.685)	
2022-03-26 12:50:18,322: ============================================================
2022-03-26 12:51:36,506: time cost, forward:0.02197925175183113, backward:0.048209377047865, data cost:0.710268555617914 
2022-03-26 12:51:36,510: ============================================================
2022-03-26 12:51:36,511: Epoch 9/38 Batch 1600/7662 eta: 2 days, 1:34:35.542701	Training Loss 5.7084 (5.8538)	Training Prec@1 96.875 (95.227)	Training Prec@5 98.047 (97.676)	
2022-03-26 12:51:36,512: ============================================================
2022-03-26 12:52:51,480: time cost, forward:0.022040746575457126, backward:0.04825600180084246, data cost:0.7087206833498698 
2022-03-26 12:52:51,481: ============================================================
2022-03-26 12:52:51,482: Epoch 9/38 Batch 1700/7662 eta: 1 day, 23:30:55.075510	Training Loss 6.1034 (5.8611)	Training Prec@1 94.336 (95.204)	Training Prec@5 96.680 (97.667)	
2022-03-26 12:52:51,482: ============================================================
2022-03-26 12:54:07,964: time cost, forward:0.022002555848228196, backward:0.04839266996505593, data cost:0.7077592226317885 
2022-03-26 12:54:07,966: ============================================================
2022-03-26 12:54:07,966: Epoch 9/38 Batch 1800/7662 eta: 2 days, 0:27:11.838466	Training Loss 6.1160 (5.8671)	Training Prec@1 95.508 (95.180)	Training Prec@5 98.633 (97.658)	
2022-03-26 12:54:07,968: ============================================================
2022-03-26 12:55:24,676: time cost, forward:0.02209095103669129, backward:0.04870903247152271, data cost:0.7063956841975529 
2022-03-26 12:55:24,680: ============================================================
2022-03-26 12:55:24,680: Epoch 9/38 Batch 1900/7662 eta: 2 days, 0:34:37.222672	Training Loss 6.2587 (5.8719)	Training Prec@1 92.383 (95.164)	Training Prec@5 96.680 (97.646)	
2022-03-26 12:55:24,681: ============================================================
2022-03-26 12:56:45,056: time cost, forward:0.022113600988993946, backward:0.048803569198310706, data cost:0.7076613544046193 
2022-03-26 12:56:45,056: ============================================================
2022-03-26 12:56:45,057: Epoch 9/38 Batch 2000/7662 eta: 2 days, 2:52:27.244570	Training Loss 6.0837 (5.8767)	Training Prec@1 94.336 (95.142)	Training Prec@5 97.461 (97.629)	
2022-03-26 12:56:45,057: ============================================================
2022-03-26 12:58:04,659: time cost, forward:0.022107060720035723, backward:0.04883854181326929, data cost:0.7084405496042078 
2022-03-26 12:58:04,660: ============================================================
2022-03-26 12:58:04,660: Epoch 9/38 Batch 2100/7662 eta: 2 days, 2:21:45.390165	Training Loss 6.2605 (5.8809)	Training Prec@1 94.922 (95.133)	Training Prec@5 97.461 (97.621)	
2022-03-26 12:58:04,660: ============================================================
2022-03-26 12:59:21,932: time cost, forward:0.0221745104830934, backward:0.048913279139166155, data cost:0.708002796819287 
2022-03-26 12:59:21,932: ============================================================
2022-03-26 12:59:21,933: Epoch 9/38 Batch 2200/7662 eta: 2 days, 0:51:59.248610	Training Loss 5.9573 (5.8840)	Training Prec@1 95.898 (95.124)	Training Prec@5 97.852 (97.616)	
2022-03-26 12:59:21,933: ============================================================
2022-03-26 13:00:36,688: time cost, forward:0.022176976409255034, backward:0.04896376173410171, data cost:0.7064973213922567 
2022-03-26 13:00:36,689: ============================================================
2022-03-26 13:00:36,689: Epoch 9/38 Batch 2300/7662 eta: 1 day, 23:15:16.701371	Training Loss 6.0028 (5.8881)	Training Prec@1 95.117 (95.107)	Training Prec@5 97.852 (97.607)	
2022-03-26 13:00:36,689: ============================================================
2022-03-26 13:01:50,132: time cost, forward:0.02210512972215952, backward:0.04890577730510373, data cost:0.704668273524276 
2022-03-26 13:01:50,133: ============================================================
2022-03-26 13:01:50,133: Epoch 9/38 Batch 2400/7662 eta: 1 day, 22:24:16.551215	Training Loss 5.8295 (5.8914)	Training Prec@1 94.141 (95.101)	Training Prec@5 98.047 (97.604)	
2022-03-26 13:01:50,133: ============================================================
2022-03-26 13:03:05,620: time cost, forward:0.02212399957465286, backward:0.049138773532331634, data cost:0.7036016494953999 
2022-03-26 13:03:05,620: ============================================================
2022-03-26 13:03:05,620: Epoch 9/38 Batch 2500/7662 eta: 1 day, 23:40:28.781878	Training Loss 6.0938 (5.8954)	Training Prec@1 94.531 (95.083)	Training Prec@5 96.484 (97.589)	
2022-03-26 13:03:05,621: ============================================================
2022-03-26 13:04:25,347: time cost, forward:0.022117068740944535, backward:0.049285503202513944, data cost:0.703897044492621 
2022-03-26 13:04:25,349: ============================================================
2022-03-26 13:04:25,350: Epoch 9/38 Batch 2600/7662 eta: 2 days, 2:19:53.394834	Training Loss 5.9176 (5.8984)	Training Prec@1 95.703 (95.072)	Training Prec@5 97.852 (97.586)	
2022-03-26 13:04:25,351: ============================================================
2022-03-26 13:05:42,870: time cost, forward:0.022201572360264543, backward:0.04934756594174171, data cost:0.7039321812491542 
2022-03-26 13:05:42,871: ============================================================
2022-03-26 13:05:42,871: Epoch 9/38 Batch 2700/7662 eta: 2 days, 0:54:58.436682	Training Loss 6.0357 (5.9014)	Training Prec@1 94.531 (95.058)	Training Prec@5 97.266 (97.577)	
2022-03-26 13:05:42,871: ============================================================
2022-03-26 13:07:03,801: time cost, forward:0.02223787720010041, backward:0.04933072635641095, data cost:0.7050364640151743 
2022-03-26 13:07:03,805: ============================================================
2022-03-26 13:07:03,806: Epoch 9/38 Batch 2800/7662 eta: 2 days, 3:02:51.353030	Training Loss 6.2639 (5.9031)	Training Prec@1 94.336 (95.055)	Training Prec@5 97.266 (97.577)	
2022-03-26 13:07:03,807: ============================================================
2022-03-26 13:08:22,034: time cost, forward:0.022281936959341997, backward:0.04929716902052217, data cost:0.705223749077867 
2022-03-26 13:08:22,035: ============================================================
2022-03-26 13:08:22,035: Epoch 9/38 Batch 2900/7662 eta: 2 days, 1:19:09.795999	Training Loss 6.0258 (5.9060)	Training Prec@1 94.336 (95.044)	Training Prec@5 97.070 (97.571)	
2022-03-26 13:08:22,036: ============================================================
2022-03-26 13:09:39,773: time cost, forward:0.02236866076495815, backward:0.04940479165039368, data cost:0.7049866065298489 
2022-03-26 13:09:39,773: ============================================================
2022-03-26 13:09:39,773: Epoch 9/38 Batch 3000/7662 eta: 2 days, 0:59:17.494982	Training Loss 5.9763 (5.9085)	Training Prec@1 95.703 (95.033)	Training Prec@5 98.242 (97.565)	
2022-03-26 13:09:39,774: ============================================================
2022-03-26 13:10:57,117: time cost, forward:0.022306099750411708, backward:0.04940558618482139, data cost:0.7048748107293453 
2022-03-26 13:10:57,117: ============================================================
2022-03-26 13:10:57,118: Epoch 9/38 Batch 3100/7662 eta: 2 days, 0:43:06.924992	Training Loss 6.2913 (5.9101)	Training Prec@1 94.336 (95.028)	Training Prec@5 96.484 (97.563)	
2022-03-26 13:10:57,118: ============================================================
2022-03-26 13:12:14,304: time cost, forward:0.022354164880750774, backward:0.04938985631405543, data cost:0.704397606305608 
2022-03-26 13:12:14,305: ============================================================
2022-03-26 13:12:14,305: Epoch 9/38 Batch 3200/7662 eta: 2 days, 0:35:53.196327	Training Loss 5.8224 (5.9118)	Training Prec@1 94.922 (95.022)	Training Prec@5 97.461 (97.557)	
2022-03-26 13:12:14,305: ============================================================
2022-03-26 13:13:27,609: time cost, forward:0.022353089914498237, backward:0.049329442882508935, data cost:0.7033137574850628 
2022-03-26 13:13:27,610: ============================================================
2022-03-26 13:13:27,610: Epoch 9/38 Batch 3300/7662 eta: 1 day, 22:08:01.245034	Training Loss 5.9770 (5.9129)	Training Prec@1 94.531 (95.015)	Training Prec@5 96.875 (97.554)	
2022-03-26 13:13:27,610: ============================================================
2022-03-26 13:14:47,631: time cost, forward:0.02235644654197951, backward:0.0493527301166576, data cost:0.703750134145698 
2022-03-26 13:14:47,632: ============================================================
2022-03-26 13:14:47,632: Epoch 9/38 Batch 3400/7662 eta: 2 days, 2:20:18.661003	Training Loss 6.0180 (5.9143)	Training Prec@1 94.336 (95.010)	Training Prec@5 97.461 (97.550)	
2022-03-26 13:14:47,633: ============================================================
2022-03-26 13:16:06,456: time cost, forward:0.022375206362693505, backward:0.04939284028922466, data cost:0.7042451535813908 
2022-03-26 13:16:06,459: ============================================================
2022-03-26 13:16:06,459: Epoch 9/38 Batch 3500/7662 eta: 2 days, 1:33:52.880419	Training Loss 6.2577 (5.9162)	Training Prec@1 95.117 (95.005)	Training Prec@5 97.461 (97.548)	
2022-03-26 13:16:06,460: ============================================================
2022-03-26 13:17:26,138: time cost, forward:0.02235829283641954, backward:0.04942121469964581, data cost:0.7047898750829842 
2022-03-26 13:17:26,163: ============================================================
2022-03-26 13:17:26,164: Epoch 9/38 Batch 3600/7662 eta: 2 days, 2:05:39.609037	Training Loss 5.8555 (5.9175)	Training Prec@1 93.945 (95.000)	Training Prec@5 97.656 (97.545)	
2022-03-26 13:17:26,164: ============================================================
2022-03-26 13:18:45,893: time cost, forward:0.02235059127126974, backward:0.0494478689267462, data cost:0.7050847774520053 
2022-03-26 13:18:45,894: ============================================================
2022-03-26 13:18:45,894: Epoch 9/38 Batch 3700/7662 eta: 2 days, 2:05:20.089244	Training Loss 5.9709 (5.9190)	Training Prec@1 95.312 (94.995)	Training Prec@5 97.852 (97.541)	
2022-03-26 13:18:45,895: ============================================================
2022-03-26 13:19:59,642: time cost, forward:0.02237541608416303, backward:0.04945476326888472, data cost:0.7041799489935312 
2022-03-26 13:19:59,643: ============================================================
2022-03-26 13:19:59,643: Epoch 9/38 Batch 3800/7662 eta: 1 day, 22:18:37.120172	Training Loss 6.1731 (5.9204)	Training Prec@1 95.117 (94.989)	Training Prec@5 97.070 (97.541)	
2022-03-26 13:19:59,643: ============================================================
2022-03-26 13:21:22,193: time cost, forward:0.022369371190625112, backward:0.04946672943929245, data cost:0.7053755838218546 
2022-03-26 13:21:22,193: ============================================================
2022-03-26 13:21:22,194: Epoch 9/38 Batch 3900/7662 eta: 2 days, 3:48:52.464151	Training Loss 6.1605 (5.9212)	Training Prec@1 93.750 (94.989)	Training Prec@5 97.266 (97.541)	
2022-03-26 13:21:22,194: ============================================================
2022-03-26 13:22:36,375: time cost, forward:0.022323658955815614, backward:0.049366101350567286, data cost:0.7045832365326478 
2022-03-26 13:22:36,375: ============================================================
2022-03-26 13:22:36,375: Epoch 9/38 Batch 4000/7662 eta: 1 day, 22:32:27.400717	Training Loss 5.7713 (5.9229)	Training Prec@1 96.094 (94.983)	Training Prec@5 97.852 (97.536)	
2022-03-26 13:22:36,376: ============================================================
2022-03-26 13:23:53,683: time cost, forward:0.02236167138074776, backward:0.04947483938011957, data cost:0.7041161077201119 
2022-03-26 13:23:53,684: ============================================================
2022-03-26 13:23:53,684: Epoch 9/38 Batch 4100/7662 eta: 2 days, 0:28:53.035960	Training Loss 5.7838 (5.9234)	Training Prec@1 94.922 (94.980)	Training Prec@5 97.852 (97.534)	
2022-03-26 13:23:53,684: ============================================================
2022-03-26 13:25:11,450: time cost, forward:0.022405617973525686, backward:0.04953045531606981, data cost:0.7041909997876016 
2022-03-26 13:25:11,451: ============================================================
2022-03-26 13:25:11,451: Epoch 9/38 Batch 4200/7662 eta: 2 days, 0:44:49.562198	Training Loss 5.9552 (5.9243)	Training Prec@1 95.312 (94.975)	Training Prec@5 96.875 (97.530)	
2022-03-26 13:25:11,451: ============================================================
2022-03-26 13:26:28,842: time cost, forward:0.02247624903064629, backward:0.0494868516866538, data cost:0.703965823243845 
2022-03-26 13:26:28,844: ============================================================
2022-03-26 13:26:28,845: Epoch 9/38 Batch 4300/7662 eta: 2 days, 0:29:29.878631	Training Loss 6.0599 (5.9254)	Training Prec@1 94.336 (94.969)	Training Prec@5 97.266 (97.526)	
2022-03-26 13:26:28,845: ============================================================
2022-03-26 13:27:47,550: time cost, forward:0.02252017533028497, backward:0.04955764601625728, data cost:0.7041531137022872 
2022-03-26 13:27:47,551: ============================================================
2022-03-26 13:27:47,551: Epoch 9/38 Batch 4400/7662 eta: 2 days, 1:17:32.282009	Training Loss 5.7110 (5.9262)	Training Prec@1 94.922 (94.967)	Training Prec@5 98.242 (97.526)	
2022-03-26 13:27:47,551: ============================================================
2022-03-26 13:29:03,095: time cost, forward:0.022497170181850986, backward:0.04955238558287407, data cost:0.70370128319565 
2022-03-26 13:29:03,095: ============================================================
2022-03-26 13:29:03,096: Epoch 9/38 Batch 4500/7662 eta: 1 day, 23:17:28.085371	Training Loss 5.6887 (5.9272)	Training Prec@1 93.750 (94.965)	Training Prec@5 96.484 (97.524)	
2022-03-26 13:29:03,096: ============================================================
2022-03-26 13:30:20,029: time cost, forward:0.022441794805408536, backward:0.04951071117100028, data cost:0.7036269061537923 
2022-03-26 13:30:20,030: ============================================================
2022-03-26 13:30:20,030: Epoch 9/38 Batch 4600/7662 eta: 2 days, 0:08:23.107667	Training Loss 6.1225 (5.9281)	Training Prec@1 93.164 (94.962)	Training Prec@5 97.266 (97.522)	
2022-03-26 13:30:20,030: ============================================================
2022-03-26 13:31:36,137: time cost, forward:0.022414378496808534, backward:0.04950198682731049, data cost:0.7033031681898579 
2022-03-26 13:31:36,138: ============================================================
2022-03-26 13:31:36,138: Epoch 9/38 Batch 4700/7662 eta: 1 day, 23:36:04.899442	Training Loss 6.1427 (5.9294)	Training Prec@1 94.922 (94.954)	Training Prec@5 98.242 (97.517)	
2022-03-26 13:31:36,138: ============================================================
2022-03-26 13:32:54,638: time cost, forward:0.02245649831397853, backward:0.04951049656042285, data cost:0.7032597603512745 
2022-03-26 13:32:54,640: ============================================================
2022-03-26 13:32:54,641: Epoch 9/38 Batch 4800/7662 eta: 2 days, 1:04:39.419559	Training Loss 5.8259 (5.9301)	Training Prec@1 94.922 (94.953)	Training Prec@5 98.438 (97.518)	
2022-03-26 13:32:54,642: ============================================================
2022-03-26 13:34:11,386: time cost, forward:0.022475036948913212, backward:0.04949122984863393, data cost:0.7030882732701268 
2022-03-26 13:34:11,388: ============================================================
2022-03-26 13:34:11,389: Epoch 9/38 Batch 4900/7662 eta: 1 day, 23:57:32.511876	Training Loss 5.9147 (5.9298)	Training Prec@1 94.141 (94.954)	Training Prec@5 97.266 (97.518)	
2022-03-26 13:34:11,389: ============================================================
2022-03-26 13:35:27,016: time cost, forward:0.02246184691497626, backward:0.04946853289916101, data cost:0.7028631026517346 
2022-03-26 13:35:27,017: ============================================================
2022-03-26 13:35:27,017: Epoch 9/38 Batch 5000/7662 eta: 1 day, 23:14:18.964359	Training Loss 6.2367 (5.9296)	Training Prec@1 93.750 (94.952)	Training Prec@5 96.680 (97.517)	
2022-03-26 13:35:27,017: ============================================================
2022-03-26 13:36:44,684: time cost, forward:0.022434701403348346, backward:0.049411793366720407, data cost:0.7027666386400258 
2022-03-26 13:36:44,686: ============================================================
2022-03-26 13:36:44,687: Epoch 9/38 Batch 5100/7662 eta: 2 days, 0:29:30.589745	Training Loss 6.0482 (5.9299)	Training Prec@1 94.922 (94.950)	Training Prec@5 96.680 (97.518)	
2022-03-26 13:36:44,687: ============================================================
2022-03-26 13:38:03,405: time cost, forward:0.02243922210285402, backward:0.0494192517888296, data cost:0.7030353460387098 
2022-03-26 13:38:03,405: ============================================================
2022-03-26 13:38:03,405: Epoch 9/38 Batch 5200/7662 eta: 2 days, 1:07:30.874070	Training Loss 5.9200 (5.9309)	Training Prec@1 95.898 (94.946)	Training Prec@5 97.266 (97.515)	
2022-03-26 13:38:03,406: ============================================================
2022-03-26 13:39:21,544: time cost, forward:0.022470030880892226, backward:0.04940378344223215, data cost:0.7031749818297597 
2022-03-26 13:39:21,545: ============================================================
2022-03-26 13:39:21,545: Epoch 9/38 Batch 5300/7662 eta: 2 days, 0:44:31.172715	Training Loss 6.0703 (5.9314)	Training Prec@1 93.945 (94.944)	Training Prec@5 96.094 (97.513)	
2022-03-26 13:39:21,545: ============================================================
2022-03-26 13:40:40,432: time cost, forward:0.02250134395126679, backward:0.049411929079858787, data cost:0.7033809831262099 
2022-03-26 13:40:40,432: ============================================================
2022-03-26 13:40:40,432: Epoch 9/38 Batch 5400/7662 eta: 2 days, 1:11:11.386779	Training Loss 5.8365 (5.9318)	Training Prec@1 95.508 (94.942)	Training Prec@5 97.461 (97.510)	
2022-03-26 13:40:40,433: ============================================================
2022-03-26 13:41:54,186: time cost, forward:0.022457405315093246, backward:0.049375463602954334, data cost:0.7026541488000232 
2022-03-26 13:41:54,187: ============================================================
2022-03-26 13:41:54,187: Epoch 9/38 Batch 5500/7662 eta: 1 day, 21:57:57.049804	Training Loss 6.2246 (5.9322)	Training Prec@1 94.141 (94.940)	Training Prec@5 97.070 (97.509)	
2022-03-26 13:41:54,187: ============================================================
2022-03-26 13:43:12,662: time cost, forward:0.02245678499694977, backward:0.04935406454760467, data cost:0.7028694402364604 
2022-03-26 13:43:12,663: ============================================================
2022-03-26 13:43:12,663: Epoch 9/38 Batch 5600/7662 eta: 2 days, 0:53:10.759889	Training Loss 6.1913 (5.9331)	Training Prec@1 94.531 (94.938)	Training Prec@5 96.875 (97.508)	
2022-03-26 13:43:12,664: ============================================================
2022-03-26 13:44:27,718: time cost, forward:0.022424174141603553, backward:0.049317068918940686, data cost:0.7025263401934464 
2022-03-26 13:44:27,719: ============================================================
2022-03-26 13:44:27,719: Epoch 9/38 Batch 5700/7662 eta: 1 day, 22:44:05.994221	Training Loss 6.0128 (5.9338)	Training Prec@1 93.359 (94.936)	Training Prec@5 97.461 (97.507)	
2022-03-26 13:44:27,719: ============================================================
2022-03-26 13:45:45,365: time cost, forward:0.02236322222711465, backward:0.049237842250639124, data cost:0.7026664083796259 
2022-03-26 13:45:45,370: ============================================================
2022-03-26 13:45:45,371: Epoch 9/38 Batch 5800/7662 eta: 2 days, 0:19:47.280285	Training Loss 6.1209 (5.9343)	Training Prec@1 93.945 (94.932)	Training Prec@5 97.266 (97.506)	
2022-03-26 13:45:45,372: ============================================================
2022-03-26 13:47:04,924: time cost, forward:0.02236583087783402, backward:0.04920916962288137, data cost:0.7028938296852041 
2022-03-26 13:47:04,926: ============================================================
2022-03-26 13:47:04,928: Epoch 9/38 Batch 5900/7662 eta: 2 days, 1:29:35.680779	Training Loss 5.9516 (5.9342)	Training Prec@1 95.508 (94.934)	Training Prec@5 98.242 (97.507)	
2022-03-26 13:47:04,928: ============================================================
2022-03-26 13:48:19,648: time cost, forward:0.022327875610112468, backward:0.0491474789566826, data cost:0.7026531941931652 
2022-03-26 13:48:19,649: ============================================================
2022-03-26 13:48:19,649: Epoch 9/38 Batch 6000/7662 eta: 1 day, 22:27:52.185387	Training Loss 5.7974 (5.9353)	Training Prec@1 95.117 (94.930)	Training Prec@5 97.656 (97.504)	
2022-03-26 13:48:19,649: ============================================================
2022-03-26 13:49:38,064: time cost, forward:0.02233352471930333, backward:0.049154847503627086, data cost:0.702772332832723 
2022-03-26 13:49:38,064: ============================================================
2022-03-26 13:49:38,064: Epoch 9/38 Batch 6100/7662 eta: 2 days, 0:44:23.170216	Training Loss 6.3130 (5.9357)	Training Prec@1 93.555 (94.927)	Training Prec@5 97.266 (97.503)	
2022-03-26 13:49:38,065: ============================================================
2022-03-26 13:50:55,753: time cost, forward:0.02233936621654724, backward:0.04919106611457058, data cost:0.7026090442720854 
2022-03-26 13:50:55,757: ============================================================
2022-03-26 13:50:55,758: Epoch 9/38 Batch 6200/7662 eta: 2 days, 0:16:08.718007	Training Loss 5.7593 (5.9359)	Training Prec@1 93.945 (94.926)	Training Prec@5 97.266 (97.503)	
2022-03-26 13:50:55,758: ============================================================
2022-03-26 13:52:12,510: time cost, forward:0.022345299947108516, backward:0.04919467121480968, data cost:0.7025082715826766 
2022-03-26 13:52:12,511: ============================================================
2022-03-26 13:52:12,511: Epoch 9/38 Batch 6300/7662 eta: 1 day, 23:39:51.769437	Training Loss 5.7740 (5.9367)	Training Prec@1 94.922 (94.922)	Training Prec@5 97.461 (97.500)	
2022-03-26 13:52:12,512: ============================================================
2022-03-26 13:53:33,249: time cost, forward:0.022343212486263513, backward:0.0492435534832384, data cost:0.7029346199888125 
2022-03-26 13:53:33,250: ============================================================
2022-03-26 13:53:33,250: Epoch 9/38 Batch 6400/7662 eta: 2 days, 2:07:00.411393	Training Loss 5.9098 (5.9370)	Training Prec@1 95.508 (94.918)	Training Prec@5 97.852 (97.499)	
2022-03-26 13:53:33,251: ============================================================
2022-03-26 13:54:49,011: time cost, forward:0.022351371964998916, backward:0.04924867149132328, data cost:0.7027513669406218 
2022-03-26 13:54:49,011: ============================================================
2022-03-26 13:54:49,012: Epoch 9/38 Batch 6500/7662 eta: 1 day, 23:00:20.947196	Training Loss 6.0066 (5.9375)	Training Prec@1 94.727 (94.917)	Training Prec@5 97.656 (97.500)	
2022-03-26 13:54:49,012: ============================================================
2022-03-26 13:56:06,292: time cost, forward:0.02233357439620655, backward:0.04924467629168066, data cost:0.7026325031959174 
2022-03-26 13:56:06,294: ============================================================
2022-03-26 13:56:06,295: Epoch 9/38 Batch 6600/7662 eta: 1 day, 23:55:42.646909	Training Loss 5.9025 (5.9384)	Training Prec@1 95.312 (94.914)	Training Prec@5 97.266 (97.499)	
2022-03-26 13:56:06,296: ============================================================
2022-03-26 13:57:25,370: time cost, forward:0.02233324223159765, backward:0.04927333092792726, data cost:0.7027666103948425 
2022-03-26 13:57:25,371: ============================================================
2022-03-26 13:57:25,372: Epoch 9/38 Batch 6700/7662 eta: 2 days, 1:01:09.405238	Training Loss 5.8451 (5.9385)	Training Prec@1 94.531 (94.914)	Training Prec@5 96.875 (97.499)	
2022-03-26 13:57:25,372: ============================================================
2022-03-26 13:58:40,679: time cost, forward:0.022285734279872144, backward:0.04925884413603457, data cost:0.7026240855810449 
2022-03-26 13:58:40,680: ============================================================
2022-03-26 13:58:40,680: Epoch 9/38 Batch 6800/7662 eta: 1 day, 22:39:43.733222	Training Loss 6.1023 (5.9388)	Training Prec@1 93.945 (94.912)	Training Prec@5 96.875 (97.499)	
2022-03-26 13:58:40,680: ============================================================
2022-03-26 13:59:56,828: time cost, forward:0.02224917151924838, backward:0.04919424453046395, data cost:0.7025244111927683 
2022-03-26 13:59:56,828: ============================================================
2022-03-26 13:59:56,829: Epoch 9/38 Batch 6900/7662 eta: 1 day, 23:09:41.477740	Training Loss 6.0038 (5.9396)	Training Prec@1 94.531 (94.910)	Training Prec@5 95.898 (97.496)	
2022-03-26 13:59:56,829: ============================================================
2022-03-26 14:01:11,045: time cost, forward:0.022201874712941168, backward:0.04906398859308828, data cost:0.7022127218119739 
2022-03-26 14:01:11,045: ============================================================
2022-03-26 14:01:11,045: Epoch 9/38 Batch 7000/7662 eta: 1 day, 21:56:40.493343	Training Loss 5.9679 (5.9399)	Training Prec@1 95.703 (94.907)	Training Prec@5 97.852 (97.496)	
2022-03-26 14:01:11,046: ============================================================
2022-03-26 14:02:30,055: time cost, forward:0.02218670830926117, backward:0.04902649251553925, data cost:0.7024835065848929 
2022-03-26 14:02:30,056: ============================================================
2022-03-26 14:02:30,056: Epoch 9/38 Batch 7100/7662 eta: 2 days, 0:53:24.309471	Training Loss 5.9689 (5.9399)	Training Prec@1 94.141 (94.907)	Training Prec@5 96.875 (97.495)	
2022-03-26 14:02:30,056: ============================================================
2022-03-26 14:03:48,798: time cost, forward:0.022176322580658905, backward:0.049040644942828227, data cost:0.7025846478541306 
2022-03-26 14:03:48,800: ============================================================
2022-03-26 14:03:48,801: Epoch 9/38 Batch 7200/7662 eta: 2 days, 0:42:14.327220	Training Loss 6.0144 (5.9402)	Training Prec@1 93.555 (94.905)	Training Prec@5 96.875 (97.493)	
2022-03-26 14:03:48,801: ============================================================
2022-03-26 14:05:10,390: time cost, forward:0.022179099889238628, backward:0.049027838630535156, data cost:0.7031770770656587 
2022-03-26 14:05:10,390: ============================================================
2022-03-26 14:05:10,391: Epoch 9/38 Batch 7300/7662 eta: 2 days, 2:26:27.108473	Training Loss 5.8482 (5.9411)	Training Prec@1 94.531 (94.902)	Training Prec@5 98.047 (97.491)	
2022-03-26 14:05:10,391: ============================================================
2022-03-26 14:06:27,693: time cost, forward:0.022172234834634156, backward:0.048980870397046766, data cost:0.7030862487801218 
2022-03-26 14:06:27,694: ============================================================
2022-03-26 14:06:27,695: Epoch 9/38 Batch 7400/7662 eta: 1 day, 23:46:11.261297	Training Loss 5.9448 (5.9414)	Training Prec@1 94.727 (94.899)	Training Prec@5 98.047 (97.490)	
2022-03-26 14:06:27,696: ============================================================
2022-03-26 14:07:44,848: time cost, forward:0.022154096063414737, backward:0.04895934280927602, data cost:0.7031609503996183 
2022-03-26 14:07:44,849: ============================================================
2022-03-26 14:07:44,849: Epoch 9/38 Batch 7500/7662 eta: 1 day, 23:39:21.493375	Training Loss 6.2060 (5.9415)	Training Prec@1 94.336 (94.898)	Training Prec@5 97.266 (97.489)	
2022-03-26 14:07:44,849: ============================================================
2022-03-26 14:09:04,702: time cost, forward:0.022127774565262864, backward:0.048932733716486564, data cost:0.7034207965405557 
2022-03-26 14:09:04,704: ============================================================
2022-03-26 14:09:04,705: Epoch 9/38 Batch 7600/7662 eta: 2 days, 1:18:06.358380	Training Loss 5.8348 (5.9419)	Training Prec@1 95.508 (94.897)	Training Prec@5 97.852 (97.489)	
2022-03-26 14:09:04,705: ============================================================
2022-03-26 14:09:53,802: Epoch: 9/38 eta: 2 days, 1:17:16.049776	Training Loss 6.0362 (5.9418)	Training Prec@1 96.094 (94.897)	Training Prec@5 97.656 (97.489)
2022-03-26 14:09:53,804: ============================================================
2022-03-26 14:11:16,910: time cost, forward:0.023402469326751402, backward:0.048176654661544645, data cost:0.7497431726166697 
2022-03-26 14:11:16,914: ============================================================
2022-03-26 14:11:16,915: Epoch 10/38 Batch 100/7662 eta: 2 days, 3:03:04.016465	Training Loss 4.7329 (5.0307)	Training Prec@1 96.484 (96.688)	Training Prec@5 98.438 (98.485)	
2022-03-26 14:11:16,916: ============================================================
2022-03-26 14:12:37,274: time cost, forward:0.022832805786899585, backward:0.047705650329589844, data cost:0.7424281829565613 
2022-03-26 14:12:37,275: ============================================================
2022-03-26 14:12:37,275: Epoch 10/38 Batch 200/7662 eta: 2 days, 1:33:18.559187	Training Loss 4.4089 (4.8816)	Training Prec@1 97.266 (96.920)	Training Prec@5 99.609 (98.599)	
2022-03-26 14:12:37,275: ============================================================
2022-03-26 14:13:52,707: time cost, forward:0.02206271627674932, backward:0.04645828658521774, data cost:0.725114564831839 
2022-03-26 14:13:52,708: ============================================================
2022-03-26 14:13:52,709: Epoch 10/38 Batch 300/7662 eta: 1 day, 22:29:46.771110	Training Loss 4.0676 (4.7861)	Training Prec@1 98.438 (97.070)	Training Prec@5 99.219 (98.674)	
2022-03-26 14:13:52,709: ============================================================
2022-03-26 14:15:10,892: time cost, forward:0.022435323337564494, backward:0.047592115880253916, data cost:0.7207092199110448 
2022-03-26 14:15:10,893: ============================================================
2022-03-26 14:15:10,893: Epoch 10/38 Batch 400/7662 eta: 2 days, 0:10:12.492518	Training Loss 4.7634 (4.7164)	Training Prec@1 96.875 (97.155)	Training Prec@5 98.438 (98.721)	
2022-03-26 14:15:10,893: ============================================================
2022-03-26 14:16:32,873: time cost, forward:0.02281161157306067, backward:0.04846372776375505, data cost:0.7250734312023094 
2022-03-26 14:16:32,874: ============================================================
2022-03-26 14:16:32,874: Epoch 10/38 Batch 500/7662 eta: 2 days, 2:29:10.448157	Training Loss 4.5039 (4.6523)	Training Prec@1 97.461 (97.264)	Training Prec@5 98.633 (98.775)	
2022-03-26 14:16:32,874: ============================================================
2022-03-26 14:17:50,413: time cost, forward:0.02282100965662273, backward:0.048669409075245036, data cost:0.7210224200170705 
2022-03-26 14:17:50,413: ============================================================
2022-03-26 14:17:50,414: Epoch 10/38 Batch 600/7662 eta: 1 day, 23:43:47.334069	Training Loss 4.2870 (4.5998)	Training Prec@1 98.438 (97.335)	Training Prec@5 99.414 (98.807)	
2022-03-26 14:17:50,414: ============================================================
2022-03-26 14:19:10,996: time cost, forward:0.02307504816287236, backward:0.04936847939170652, data cost:0.7217561959879252 
2022-03-26 14:19:10,997: ============================================================
2022-03-26 14:19:10,997: Epoch 10/38 Batch 700/7662 eta: 2 days, 1:34:51.615833	Training Loss 4.4677 (4.5514)	Training Prec@1 98.047 (97.407)	Training Prec@5 99.023 (98.845)	
2022-03-26 14:19:10,997: ============================================================
2022-03-26 14:20:29,428: time cost, forward:0.02305166921269461, backward:0.04923037295049063, data cost:0.7203929206456648 
2022-03-26 14:20:29,428: ============================================================
2022-03-26 14:20:29,429: Epoch 10/38 Batch 800/7662 eta: 2 days, 0:14:06.658468	Training Loss 4.2394 (4.5089)	Training Prec@1 97.266 (97.461)	Training Prec@5 98.633 (98.878)	
2022-03-26 14:20:29,429: ============================================================
2022-03-26 14:21:49,558: time cost, forward:0.023464433873720773, backward:0.04950256209750064, data cost:0.7195597811455986 
2022-03-26 14:21:49,561: ============================================================
2022-03-26 14:21:49,561: Epoch 10/38 Batch 900/7662 eta: 2 days, 1:15:32.220532	Training Loss 3.9245 (4.4675)	Training Prec@1 98.828 (97.515)	Training Prec@5 99.609 (98.908)	
2022-03-26 14:21:49,562: ============================================================
2022-03-26 14:23:11,320: time cost, forward:0.023625877407100704, backward:0.049894067260238144, data cost:0.7220247543609895 
2022-03-26 14:23:11,323: ============================================================
2022-03-26 14:23:11,323: Epoch 10/38 Batch 1000/7662 eta: 2 days, 2:14:16.074725	Training Loss 4.1826 (4.4300)	Training Prec@1 97.852 (97.565)	Training Prec@5 99.609 (98.929)	
2022-03-26 14:23:11,323: ============================================================
2022-03-26 14:24:31,015: time cost, forward:0.023688659329540195, backward:0.05004366014739185, data cost:0.7215183967888843 
2022-03-26 14:24:31,016: ============================================================
2022-03-26 14:24:31,017: Epoch 10/38 Batch 1100/7662 eta: 2 days, 0:56:42.495799	Training Loss 3.9600 (4.3938)	Training Prec@1 98.047 (97.626)	Training Prec@5 99.414 (98.957)	
2022-03-26 14:24:31,018: ============================================================
2022-03-26 14:25:54,619: time cost, forward:0.023834368305667625, backward:0.050525762320956756, data cost:0.723728168398465 
2022-03-26 14:25:54,620: ============================================================
2022-03-26 14:25:54,620: Epoch 10/38 Batch 1200/7662 eta: 2 days, 3:19:22.212166	Training Loss 3.9149 (4.3586)	Training Prec@1 98.242 (97.677)	Training Prec@5 99.219 (98.979)	
2022-03-26 14:25:54,620: ============================================================
2022-03-26 14:27:12,558: time cost, forward:0.023752584009559638, backward:0.05047612010377292, data cost:0.7228227685835841 
2022-03-26 14:27:12,561: ============================================================
2022-03-26 14:27:12,562: Epoch 10/38 Batch 1300/7662 eta: 1 day, 23:49:31.537880	Training Loss 4.0674 (4.3253)	Training Prec@1 98.633 (97.725)	Training Prec@5 99.414 (99.001)	
2022-03-26 14:27:12,562: ============================================================
2022-03-26 14:28:36,748: time cost, forward:0.023865646255962162, backward:0.05089886432208701, data cost:0.7254025729917645 
2022-03-26 14:28:36,748: ============================================================
2022-03-26 14:28:36,749: Epoch 10/38 Batch 1400/7662 eta: 2 days, 3:38:04.471666	Training Loss 3.7443 (4.2938)	Training Prec@1 97.656 (97.766)	Training Prec@5 98.242 (99.018)	
2022-03-26 14:28:36,749: ============================================================
2022-03-26 14:29:57,439: time cost, forward:0.02393324236777562, backward:0.05104153215129666, data cost:0.7252893610108766 
2022-03-26 14:29:57,442: ============================================================
2022-03-26 14:29:57,443: Epoch 10/38 Batch 1500/7662 eta: 2 days, 1:28:09.835531	Training Loss 3.9251 (4.2616)	Training Prec@1 98.633 (97.802)	Training Prec@5 99.609 (99.032)	
2022-03-26 14:29:57,444: ============================================================
2022-03-26 14:31:17,600: time cost, forward:0.02406622500178067, backward:0.051136774148994715, data cost:0.7250342621066705 
2022-03-26 14:31:17,600: ============================================================
2022-03-26 14:31:17,601: Epoch 10/38 Batch 1600/7662 eta: 2 days, 1:07:08.487991	Training Loss 3.6577 (4.2307)	Training Prec@1 98.047 (97.841)	Training Prec@5 99.805 (99.053)	
2022-03-26 14:31:17,601: ============================================================
2022-03-26 14:32:38,642: time cost, forward:0.02427832655095577, backward:0.05155972440920555, data cost:0.7245608925328246 
2022-03-26 14:32:38,645: ============================================================
2022-03-26 14:32:38,645: Epoch 10/38 Batch 1700/7662 eta: 2 days, 1:38:21.763461	Training Loss 3.7599 (4.2012)	Training Prec@1 98.242 (97.877)	Training Prec@5 99.414 (99.072)	
2022-03-26 14:32:38,646: ============================================================
2022-03-26 14:34:02,057: time cost, forward:0.02439617792588595, backward:0.0515776809683901, data cost:0.7263871139125602 
2022-03-26 14:34:02,058: ============================================================
2022-03-26 14:34:02,059: Epoch 10/38 Batch 1800/7662 eta: 2 days, 3:04:02.915176	Training Loss 3.5724 (4.1724)	Training Prec@1 98.438 (97.914)	Training Prec@5 99.805 (99.093)	
2022-03-26 14:34:02,059: ============================================================
2022-03-26 14:35:23,029: time cost, forward:0.024337105527559414, backward:0.05151485040854504, data cost:0.7270581709704568 
2022-03-26 14:35:23,030: ============================================================
2022-03-26 14:35:23,030: Epoch 10/38 Batch 1900/7662 eta: 2 days, 1:32:59.691386	Training Loss 3.8296 (4.1460)	Training Prec@1 98.242 (97.948)	Training Prec@5 99.609 (99.111)	
2022-03-26 14:35:23,030: ============================================================
2022-03-26 14:36:44,532: time cost, forward:0.024252015271742623, backward:0.05135594933792732, data cost:0.7274950941304316 
2022-03-26 14:36:44,535: ============================================================
2022-03-26 14:36:44,537: Epoch 10/38 Batch 2000/7662 eta: 2 days, 1:51:15.917303	Training Loss 3.7922 (4.1207)	Training Prec@1 98.047 (97.976)	Training Prec@5 99.219 (99.123)	
2022-03-26 14:36:44,538: ============================================================
2022-03-26 14:38:04,121: time cost, forward:0.024328243056611257, backward:0.05139905535192249, data cost:0.7270452373081188 
2022-03-26 14:38:04,122: ============================================================
2022-03-26 14:38:04,122: Epoch 10/38 Batch 2100/7662 eta: 2 days, 0:39:26.530191	Training Loss 3.5032 (4.0957)	Training Prec@1 99.414 (98.009)	Training Prec@5 99.805 (99.140)	
2022-03-26 14:38:04,122: ============================================================
2022-03-26 14:39:24,744: time cost, forward:0.024305279876167745, backward:0.051440144951314264, data cost:0.7269740878803831 
2022-03-26 14:39:24,748: ============================================================
2022-03-26 14:39:24,750: Epoch 10/38 Batch 2200/7662 eta: 2 days, 1:16:19.597864	Training Loss 3.5114 (4.0717)	Training Prec@1 99.414 (98.043)	Training Prec@5 99.609 (99.156)	
2022-03-26 14:39:24,750: ============================================================
2022-03-26 14:40:44,062: time cost, forward:0.024258290751699055, backward:0.05145883166100368, data cost:0.7264966422342746 
2022-03-26 14:40:44,065: ============================================================
2022-03-26 14:40:44,066: Epoch 10/38 Batch 2300/7662 eta: 2 days, 0:26:54.809792	Training Loss 3.4247 (4.0484)	Training Prec@1 98.633 (98.069)	Training Prec@5 99.609 (99.170)	
2022-03-26 14:40:44,066: ============================================================
2022-03-26 14:42:03,383: time cost, forward:0.024284292032640147, backward:0.05151617432594697, data cost:0.7259755216076157 
2022-03-26 14:42:03,387: ============================================================
2022-03-26 14:42:03,388: Epoch 10/38 Batch 2400/7662 eta: 2 days, 0:25:48.615399	Training Loss 3.7698 (4.0260)	Training Prec@1 99.219 (98.097)	Training Prec@5 99.609 (99.183)	
2022-03-26 14:42:03,388: ============================================================
2022-03-26 14:43:22,387: time cost, forward:0.024351660086184133, backward:0.05155264544172161, data cost:0.7252905536718777 
2022-03-26 14:43:22,391: ============================================================
2022-03-26 14:43:22,393: Epoch 10/38 Batch 2500/7662 eta: 2 days, 0:12:53.900764	Training Loss 3.4193 (4.0051)	Training Prec@1 98.438 (98.126)	Training Prec@5 99.414 (99.198)	
2022-03-26 14:43:22,395: ============================================================
2022-03-26 14:44:43,498: time cost, forward:0.024404920583140075, backward:0.051722994580916504, data cost:0.7253565844227232 
2022-03-26 14:44:43,501: ============================================================
2022-03-26 14:44:43,503: Epoch 10/38 Batch 2600/7662 eta: 2 days, 1:28:36.275891	Training Loss 3.3540 (3.9839)	Training Prec@1 99.219 (98.149)	Training Prec@5 99.609 (99.210)	
2022-03-26 14:44:43,504: ============================================================
2022-03-26 14:46:06,638: time cost, forward:0.024503793129880325, backward:0.051813827262361126, data cost:0.7263837997539699 
2022-03-26 14:46:06,638: ============================================================
2022-03-26 14:46:06,638: Epoch 10/38 Batch 2700/7662 eta: 2 days, 2:41:22.632464	Training Loss 3.2569 (3.9639)	Training Prec@1 99.414 (98.175)	Training Prec@5 99.805 (99.223)	
2022-03-26 14:46:06,639: ============================================================
2022-03-26 14:47:26,773: time cost, forward:0.02445993690926844, backward:0.05178503583013351, data cost:0.7264520979728304 
2022-03-26 14:47:26,774: ============================================================
2022-03-26 14:47:26,775: Epoch 10/38 Batch 2800/7662 eta: 2 days, 0:50:17.731540	Training Loss 3.3432 (3.9449)	Training Prec@1 98.633 (98.199)	Training Prec@5 99.609 (99.233)	
2022-03-26 14:47:26,775: ============================================================
2022-03-26 14:48:48,934: time cost, forward:0.024515942237672415, backward:0.05183406590017297, data cost:0.7269073277763269 
2022-03-26 14:48:48,936: ============================================================
2022-03-26 14:48:48,938: Epoch 10/38 Batch 2900/7662 eta: 2 days, 2:03:01.657261	Training Loss 3.1586 (3.9259)	Training Prec@1 99.805 (98.221)	Training Prec@5 100.000 (99.243)	
2022-03-26 14:48:48,938: ============================================================
2022-03-26 14:50:09,127: time cost, forward:0.024494751408403022, backward:0.05184214701053102, data cost:0.726779594624905 
2022-03-26 14:50:09,128: ============================================================
2022-03-26 14:50:09,128: Epoch 10/38 Batch 3000/7662 eta: 2 days, 0:49:37.243968	Training Loss 3.3548 (3.9075)	Training Prec@1 99.023 (98.241)	Training Prec@5 99.609 (99.252)	
2022-03-26 14:50:09,128: ============================================================
2022-03-26 14:51:28,191: time cost, forward:0.024465097385516048, backward:0.05182374104564134, data cost:0.7264508253222475 
2022-03-26 14:51:28,191: ============================================================
2022-03-26 14:51:28,192: Epoch 10/38 Batch 3100/7662 eta: 2 days, 0:07:08.091490	Training Loss 3.5004 (3.8895)	Training Prec@1 97.266 (98.262)	Training Prec@5 99.414 (99.263)	
2022-03-26 14:51:28,192: ============================================================
2022-03-26 14:52:47,172: time cost, forward:0.024446796349862025, backward:0.051759382157297425, data cost:0.7260581611580832 
2022-03-26 14:52:47,172: ============================================================
2022-03-26 14:52:47,173: Epoch 10/38 Batch 3200/7662 eta: 2 days, 0:02:47.343705	Training Loss 3.4853 (3.8727)	Training Prec@1 98.438 (98.280)	Training Prec@5 99.414 (99.271)	
2022-03-26 14:52:47,173: ============================================================
2022-03-26 14:54:07,511: time cost, forward:0.024420285738031226, backward:0.051740807885652454, data cost:0.7260297675246938 
2022-03-26 14:54:07,511: ============================================================
2022-03-26 14:54:07,511: Epoch 10/38 Batch 3300/7662 eta: 2 days, 0:51:00.754035	Training Loss 3.2239 (3.8560)	Training Prec@1 98.828 (98.302)	Training Prec@5 99.609 (99.282)	
2022-03-26 14:54:07,512: ============================================================
2022-03-26 14:55:29,308: time cost, forward:0.024445961208405233, backward:0.05180157749538528, data cost:0.7261410003621707 
2022-03-26 14:55:29,312: ============================================================
2022-03-26 14:55:29,313: Epoch 10/38 Batch 3400/7662 eta: 2 days, 1:42:59.970044	Training Loss 3.4284 (3.8394)	Training Prec@1 99.023 (98.321)	Training Prec@5 99.609 (99.291)	
2022-03-26 14:55:29,313: ============================================================
2022-03-26 14:56:47,759: time cost, forward:0.02444429934518819, backward:0.051874847335793624, data cost:0.7257600504522768 
2022-03-26 14:56:47,760: ============================================================
2022-03-26 14:56:47,760: Epoch 10/38 Batch 3500/7662 eta: 1 day, 23:39:23.934503	Training Loss 3.3631 (3.8235)	Training Prec@1 98.828 (98.340)	Training Prec@5 99.219 (99.301)	
2022-03-26 14:56:47,760: ============================================================
2022-03-26 14:58:09,285: time cost, forward:0.02438930598654062, backward:0.05183709492515146, data cost:0.7259587563220313 
2022-03-26 14:58:09,286: ============================================================
2022-03-26 14:58:09,287: Epoch 10/38 Batch 3600/7662 eta: 2 days, 1:30:15.957352	Training Loss 3.0438 (3.8084)	Training Prec@1 99.609 (98.357)	Training Prec@5 99.609 (99.310)	
2022-03-26 14:58:09,287: ============================================================
2022-03-26 14:59:27,291: time cost, forward:0.024363507319540872, backward:0.05179080263154833, data cost:0.7255878200979612 
2022-03-26 14:59:27,291: ============================================================
2022-03-26 14:59:27,292: Epoch 10/38 Batch 3700/7662 eta: 1 day, 23:20:40.138428	Training Loss 3.2721 (3.7932)	Training Prec@1 99.219 (98.375)	Training Prec@5 99.805 (99.318)	
2022-03-26 14:59:27,292: ============================================================
2022-03-26 15:00:48,264: time cost, forward:0.024355225325823144, backward:0.05176033324773577, data cost:0.725742393620675 
2022-03-26 15:00:48,265: ============================================================
2022-03-26 15:00:48,266: Epoch 10/38 Batch 3800/7662 eta: 2 days, 1:07:26.457760	Training Loss 3.3255 (3.7789)	Training Prec@1 99.414 (98.391)	Training Prec@5 99.609 (99.326)	
2022-03-26 15:00:48,266: ============================================================
2022-03-26 15:02:11,195: time cost, forward:0.0244445241882606, backward:0.051831791907831715, data cost:0.7261986904310611 
2022-03-26 15:02:11,196: ============================================================
2022-03-26 15:02:11,196: Epoch 10/38 Batch 3900/7662 eta: 2 days, 2:17:17.009160	Training Loss 3.4073 (3.7649)	Training Prec@1 99.414 (98.406)	Training Prec@5 99.609 (99.334)	
2022-03-26 15:02:11,197: ============================================================
2022-03-26 15:03:30,121: time cost, forward:0.02442618130624041, backward:0.051886613144222334, data cost:0.7258546664792915 
2022-03-26 15:03:30,121: ============================================================
2022-03-26 15:03:30,122: Epoch 10/38 Batch 4000/7662 eta: 1 day, 23:50:14.162549	Training Loss 3.2208 (3.7508)	Training Prec@1 99.219 (98.424)	Training Prec@5 99.805 (99.342)	
2022-03-26 15:03:30,122: ============================================================
2022-03-26 15:04:49,251: time cost, forward:0.02438390938413815, backward:0.05177901273356557, data cost:0.725695072252246 
2022-03-26 15:04:49,252: ============================================================
2022-03-26 15:04:49,253: Epoch 10/38 Batch 4100/7662 eta: 1 day, 23:56:23.647308	Training Loss 3.2393 (3.7372)	Training Prec@1 99.023 (98.438)	Training Prec@5 99.609 (99.350)	
2022-03-26 15:04:49,253: ============================================================
2022-03-26 15:06:09,396: time cost, forward:0.024398159600348947, backward:0.05188511240678221, data cost:0.7253982166813566 
2022-03-26 15:06:09,399: ============================================================
2022-03-26 15:06:09,401: Epoch 10/38 Batch 4200/7662 eta: 2 days, 0:32:01.969501	Training Loss 3.2936 (3.7248)	Training Prec@1 99.609 (98.451)	Training Prec@5 99.609 (99.357)	
2022-03-26 15:06:09,402: ============================================================
2022-03-26 15:07:30,904: time cost, forward:0.024441870236624173, backward:0.05192731291395366, data cost:0.7256733356284164 
2022-03-26 15:07:30,905: ============================================================
2022-03-26 15:07:30,905: Epoch 10/38 Batch 4300/7662 eta: 2 days, 1:19:56.721387	Training Loss 3.0654 (3.7120)	Training Prec@1 99.414 (98.466)	Training Prec@5 99.805 (99.365)	
2022-03-26 15:07:30,905: ============================================================
2022-03-26 15:08:50,970: time cost, forward:0.024415341256070772, backward:0.05192049266696383, data cost:0.7256651955535396 
2022-03-26 15:08:50,970: ============================================================
2022-03-26 15:08:50,970: Epoch 10/38 Batch 4400/7662 eta: 2 days, 0:26:21.967957	Training Loss 3.1047 (3.7000)	Training Prec@1 99.219 (98.482)	Training Prec@5 99.219 (99.372)	
2022-03-26 15:08:50,971: ============================================================
2022-03-26 15:10:11,857: time cost, forward:0.024407406493435174, backward:0.051829834942500784, data cost:0.72574342258985 
2022-03-26 15:10:11,859: ============================================================
2022-03-26 15:10:11,860: Epoch 10/38 Batch 4500/7662 eta: 2 days, 0:54:54.570967	Training Loss 3.0581 (3.6877)	Training Prec@1 99.219 (98.495)	Training Prec@5 100.000 (99.379)	
2022-03-26 15:10:11,860: ============================================================
2022-03-26 15:11:33,352: time cost, forward:0.024388712886935553, backward:0.05188897880011731, data cost:0.726057607522605 
2022-03-26 15:11:33,353: ============================================================
2022-03-26 15:11:33,353: Epoch 10/38 Batch 4600/7662 eta: 2 days, 1:15:29.194097	Training Loss 3.0587 (3.6761)	Training Prec@1 99.414 (98.507)	Training Prec@5 99.805 (99.384)	
2022-03-26 15:11:33,353: ============================================================
2022-03-26 15:12:56,812: time cost, forward:0.024426968002806422, backward:0.05200018961902983, data cost:0.7265329857688428 
2022-03-26 15:12:56,812: ============================================================
2022-03-26 15:12:56,813: Epoch 10/38 Batch 4700/7662 eta: 2 days, 2:25:24.362127	Training Loss 3.2407 (3.6646)	Training Prec@1 99.219 (98.520)	Training Prec@5 99.609 (99.389)	
2022-03-26 15:12:56,813: ============================================================
2022-03-26 15:14:17,807: time cost, forward:0.024481759316773682, backward:0.0519950860836874, data cost:0.7264224082933264 
2022-03-26 15:14:17,810: ============================================================
2022-03-26 15:14:17,811: Epoch 10/38 Batch 4800/7662 eta: 2 days, 0:54:47.524248	Training Loss 3.1250 (3.6530)	Training Prec@1 99.219 (98.533)	Training Prec@5 100.000 (99.395)	
2022-03-26 15:14:17,812: ============================================================
2022-03-26 15:15:37,463: time cost, forward:0.024456063687351193, backward:0.051947681240510836, data cost:0.7263399021653258 
2022-03-26 15:15:37,464: ============================================================
2022-03-26 15:15:37,465: Epoch 10/38 Batch 4900/7662 eta: 2 days, 0:04:48.396224	Training Loss 2.9498 (3.6421)	Training Prec@1 99.609 (98.546)	Training Prec@5 99.805 (99.400)	
2022-03-26 15:15:37,465: ============================================================
2022-03-26 15:16:57,777: time cost, forward:0.02446930955519412, backward:0.05193709778676011, data cost:0.7263608057991603 
2022-03-26 15:16:57,782: ============================================================
2022-03-26 15:16:57,783: Epoch 10/38 Batch 5000/7662 eta: 2 days, 0:27:29.966524	Training Loss 3.1063 (3.6312)	Training Prec@1 99.023 (98.558)	Training Prec@5 99.609 (99.406)	
2022-03-26 15:16:57,784: ============================================================
2022-03-26 15:18:17,348: time cost, forward:0.02449424034428377, backward:0.0518766688140941, data cost:0.7263148413566684 
2022-03-26 15:18:17,349: ============================================================
2022-03-26 15:18:17,349: Epoch 10/38 Batch 5100/7662 eta: 1 day, 23:58:58.211336	Training Loss 3.1266 (3.6207)	Training Prec@1 99.219 (98.568)	Training Prec@5 99.805 (99.412)	
2022-03-26 15:18:17,350: ============================================================
2022-03-26 15:19:38,157: time cost, forward:0.024474744499589553, backward:0.05183892040028896, data cost:0.7264718067923471 
2022-03-26 15:19:38,157: ============================================================
2022-03-26 15:19:38,158: Epoch 10/38 Batch 5200/7662 eta: 2 days, 0:42:32.929270	Training Loss 3.2304 (3.6107)	Training Prec@1 99.414 (98.580)	Training Prec@5 99.805 (99.417)	
2022-03-26 15:19:38,158: ============================================================
2022-03-26 15:20:58,189: time cost, forward:0.02450206865115219, backward:0.051874618526673986, data cost:0.7262858717278233 
2022-03-26 15:20:58,189: ============================================================
2022-03-26 15:20:58,189: Epoch 10/38 Batch 5300/7662 eta: 2 days, 0:13:08.222561	Training Loss 3.1124 (3.6010)	Training Prec@1 98.633 (98.590)	Training Prec@5 99.805 (99.423)	
2022-03-26 15:20:58,190: ============================================================
2022-03-26 15:22:21,377: time cost, forward:0.024515550386952037, backward:0.0519004786184572, data cost:0.7266059711832187 
2022-03-26 15:22:21,378: ============================================================
2022-03-26 15:22:21,378: Epoch 10/38 Batch 5400/7662 eta: 2 days, 2:05:52.181240	Training Loss 2.9064 (3.5909)	Training Prec@1 99.219 (98.602)	Training Prec@5 99.219 (99.428)	
2022-03-26 15:22:21,379: ============================================================
2022-03-26 15:23:42,652: time cost, forward:0.02449696227450179, backward:0.051942331701175674, data cost:0.7268098633296708 
2022-03-26 15:23:42,655: ============================================================
2022-03-26 15:23:42,656: Epoch 10/38 Batch 5500/7662 eta: 2 days, 0:55:26.756630	Training Loss 2.7951 (3.5813)	Training Prec@1 99.805 (98.613)	Training Prec@5 100.000 (99.433)	
2022-03-26 15:23:42,656: ============================================================
2022-03-26 15:25:05,730: time cost, forward:0.02452740142932639, backward:0.05199033525463172, data cost:0.7271459276792428 
2022-03-26 15:25:05,731: ============================================================
2022-03-26 15:25:05,731: Epoch 10/38 Batch 5600/7662 eta: 2 days, 1:59:01.974193	Training Loss 3.1555 (3.5719)	Training Prec@1 99.805 (98.625)	Training Prec@5 100.000 (99.438)	
2022-03-26 15:25:05,732: ============================================================
2022-03-26 15:26:27,831: time cost, forward:0.024548086874902113, backward:0.05201873161809908, data cost:0.7274816369650594 
2022-03-26 15:26:27,833: ============================================================
2022-03-26 15:26:27,833: Epoch 10/38 Batch 5700/7662 eta: 2 days, 1:22:29.000372	Training Loss 3.1833 (3.5634)	Training Prec@1 98.828 (98.635)	Training Prec@5 99.609 (99.443)	
2022-03-26 15:26:27,834: ============================================================
2022-03-26 15:27:50,873: time cost, forward:0.024574204629239264, backward:0.05204965357411255, data cost:0.7278599988223973 
2022-03-26 15:27:50,873: ============================================================
2022-03-26 15:27:50,874: Epoch 10/38 Batch 5800/7662 eta: 2 days, 1:54:58.976533	Training Loss 2.8215 (3.5546)	Training Prec@1 99.414 (98.645)	Training Prec@5 99.805 (99.448)	
2022-03-26 15:27:50,874: ============================================================
2022-03-26 15:29:04,709: time cost, forward:0.024569052561882652, backward:0.05201676631907443, data cost:0.7266097232878743 
2022-03-26 15:29:04,710: ============================================================
2022-03-26 15:29:04,711: Epoch 10/38 Batch 5900/7662 eta: 1 day, 20:21:48.545425	Training Loss 3.1630 (3.5459)	Training Prec@1 99.023 (98.655)	Training Prec@5 99.609 (99.453)	
2022-03-26 15:29:04,711: ============================================================
2022-03-26 15:30:20,221: time cost, forward:0.024528863490035205, backward:0.05198070454108634, data cost:0.7258513149847128 
2022-03-26 15:30:20,224: ============================================================
2022-03-26 15:30:20,225: Epoch 10/38 Batch 6000/7662 eta: 1 day, 21:21:00.816849	Training Loss 3.0130 (3.5373)	Training Prec@1 98.633 (98.665)	Training Prec@5 99.219 (99.457)	
2022-03-26 15:30:20,226: ============================================================
2022-03-26 15:31:36,353: time cost, forward:0.0245008069113603, backward:0.052005120976515766, data cost:0.7252463239747045 
2022-03-26 15:31:36,355: ============================================================
2022-03-26 15:31:36,356: Epoch 10/38 Batch 6100/7662 eta: 1 day, 21:41:58.620365	Training Loss 3.1263 (3.5291)	Training Prec@1 99.609 (98.675)	Training Prec@5 100.000 (99.461)	
2022-03-26 15:31:36,357: ============================================================
2022-03-26 15:32:52,638: time cost, forward:0.02446873719931841, backward:0.052056146871853226, data cost:0.7246122043697002 
2022-03-26 15:32:52,638: ============================================================
2022-03-26 15:32:52,639: Epoch 10/38 Batch 6200/7662 eta: 1 day, 21:46:09.797209	Training Loss 2.9911 (3.5217)	Training Prec@1 99.219 (98.683)	Training Prec@5 99.609 (99.465)	
2022-03-26 15:32:52,639: ============================================================
2022-03-26 15:34:11,826: time cost, forward:0.02443267326730455, backward:0.05206054565470868, data cost:0.7244230657744964 
2022-03-26 15:34:11,827: ============================================================
2022-03-26 15:34:11,828: Epoch 10/38 Batch 6300/7662 eta: 1 day, 23:29:27.665376	Training Loss 2.9513 (3.5140)	Training Prec@1 98.828 (98.691)	Training Prec@5 99.219 (99.469)	
2022-03-26 15:34:11,828: ============================================================
2022-03-26 15:35:29,358: time cost, forward:0.024415121132143773, backward:0.05210814686152391, data cost:0.7239280036882155 
2022-03-26 15:35:29,361: ============================================================
2022-03-26 15:35:29,362: Epoch 10/38 Batch 6400/7662 eta: 1 day, 22:28:37.771933	Training Loss 3.1314 (3.5061)	Training Prec@1 99.414 (98.699)	Training Prec@5 100.000 (99.474)	
2022-03-26 15:35:29,363: ============================================================
2022-03-26 15:36:47,465: time cost, forward:0.024383522873934388, backward:0.052101807624381366, data cost:0.7237264648146364 
2022-03-26 15:36:47,465: ============================================================
2022-03-26 15:36:47,466: Epoch 10/38 Batch 6500/7662 eta: 1 day, 22:47:50.251188	Training Loss 2.9804 (3.4983)	Training Prec@1 99.609 (98.708)	Training Prec@5 99.805 (99.478)	
2022-03-26 15:36:47,466: ============================================================
2022-03-26 15:38:05,008: time cost, forward:0.024326143706995602, backward:0.05210322773010374, data cost:0.7233648411449762 
2022-03-26 15:38:05,008: ============================================================
2022-03-26 15:38:05,009: Epoch 10/38 Batch 6600/7662 eta: 1 day, 22:26:21.918654	Training Loss 3.1323 (3.4911)	Training Prec@1 99.414 (98.715)	Training Prec@5 99.609 (99.481)	
2022-03-26 15:38:05,009: ============================================================
2022-03-26 15:39:22,472: time cost, forward:0.024294104677898738, backward:0.05216912515733932, data cost:0.722911746844656 
2022-03-26 15:39:22,473: ============================================================
2022-03-26 15:39:22,473: Epoch 10/38 Batch 6700/7662 eta: 1 day, 22:22:15.566473	Training Loss 3.0741 (3.4841)	Training Prec@1 99.414 (98.723)	Training Prec@5 99.805 (99.485)	
2022-03-26 15:39:22,474: ============================================================
2022-03-26 15:40:43,653: time cost, forward:0.024277258066591718, backward:0.05219518081074796, data cost:0.7229657930948398 
2022-03-26 15:40:43,657: ============================================================
2022-03-26 15:40:43,658: Epoch 10/38 Batch 6800/7662 eta: 2 days, 0:34:29.135948	Training Loss 2.9171 (3.4772)	Training Prec@1 99.023 (98.731)	Training Prec@5 99.609 (99.488)	
2022-03-26 15:40:43,659: ============================================================
2022-03-26 15:42:05,506: time cost, forward:0.024308422714545252, backward:0.05227268400494992, data cost:0.7232051271341006 
2022-03-26 15:42:05,507: ============================================================
2022-03-26 15:42:05,507: Epoch 10/38 Batch 6900/7662 eta: 2 days, 0:57:02.446373	Training Loss 2.9401 (3.4703)	Training Prec@1 99.219 (98.739)	Training Prec@5 99.414 (99.492)	
2022-03-26 15:42:05,508: ============================================================
2022-03-26 15:43:29,225: time cost, forward:0.02431232415875259, backward:0.052328988541397205, data cost:0.7236444567216943 
2022-03-26 15:43:29,226: ============================================================
2022-03-26 15:43:29,226: Epoch 10/38 Batch 7000/7662 eta: 2 days, 2:02:41.105233	Training Loss 3.0873 (3.4638)	Training Prec@1 99.805 (98.747)	Training Prec@5 100.000 (99.495)	
2022-03-26 15:43:29,226: ============================================================
2022-03-26 15:44:53,550: time cost, forward:0.024351168290076584, backward:0.05236671628843212, data cost:0.7241088083250823 
2022-03-26 15:44:53,553: ============================================================
2022-03-26 15:44:53,554: Epoch 10/38 Batch 7100/7662 eta: 2 days, 2:23:08.432552	Training Loss 3.0448 (3.4573)	Training Prec@1 99.609 (98.754)	Training Prec@5 99.805 (99.498)	
2022-03-26 15:44:53,555: ============================================================
2022-03-26 15:46:13,741: time cost, forward:0.024375973981127903, backward:0.05239490887111617, data cost:0.7240865363695834 
2022-03-26 15:46:13,742: ============================================================
2022-03-26 15:46:13,743: Epoch 10/38 Batch 7200/7662 eta: 1 day, 23:53:25.065009	Training Loss 3.0349 (3.4510)	Training Prec@1 99.023 (98.760)	Training Prec@5 99.609 (99.502)	
2022-03-26 15:46:13,743: ============================================================
2022-03-26 15:47:38,302: time cost, forward:0.024376253017514907, backward:0.052355988546011624, data cost:0.7246082398087574 
2022-03-26 15:47:38,304: ============================================================
2022-03-26 15:47:38,304: Epoch 10/38 Batch 7300/7662 eta: 2 days, 2:28:41.751434	Training Loss 3.0464 (3.4448)	Training Prec@1 99.609 (98.768)	Training Prec@5 99.805 (99.506)	
2022-03-26 15:47:38,305: ============================================================
2022-03-26 15:48:58,443: time cost, forward:0.024348875141930043, backward:0.052328951118088746, data cost:0.7247184531594276 
2022-03-26 15:48:58,447: ============================================================
2022-03-26 15:48:58,448: Epoch 10/38 Batch 7400/7662 eta: 1 day, 23:49:07.795754	Training Loss 2.8456 (3.4388)	Training Prec@1 99.805 (98.774)	Training Prec@5 100.000 (99.509)	
2022-03-26 15:48:58,449: ============================================================
2022-03-26 15:50:18,220: time cost, forward:0.024355482174438038, backward:0.052324813784782306, data cost:0.7246510650908443 
2022-03-26 15:50:18,221: ============================================================
2022-03-26 15:50:18,221: Epoch 10/38 Batch 7500/7662 eta: 1 day, 23:34:32.331847	Training Loss 3.0089 (3.4330)	Training Prec@1 99.219 (98.782)	Training Prec@5 99.219 (99.512)	
2022-03-26 15:50:18,221: ============================================================
2022-03-26 15:51:35,048: time cost, forward:0.024332196606760167, backward:0.0522843168383916, data cost:0.7242681490369401 
2022-03-26 15:51:35,049: ============================================================
2022-03-26 15:51:35,049: Epoch 10/38 Batch 7600/7662 eta: 1 day, 21:47:52.367503	Training Loss 2.8944 (3.4272)	Training Prec@1 99.023 (98.789)	Training Prec@5 99.414 (99.516)	
2022-03-26 15:51:35,050: ============================================================
2022-03-26 15:52:27,989: Epoch: 10/38 eta: 1 day, 21:47:03.965790	Training Loss 2.9293 (3.4237)	Training Prec@1 99.805 (98.793)	Training Prec@5 100.000 (99.517)
2022-03-26 15:52:27,989: ============================================================
2022-03-26 15:52:27,991: Save Checkpoint...
2022-03-26 15:52:27,993: ============================================================
2022-03-26 15:52:31,150: Save done!
2022-03-26 15:52:31,151: ============================================================
2022-03-26 15:53:53,167: time cost, forward:0.02730123924486565, backward:0.05289020201172492, data cost:0.7404913252050226 
2022-03-26 15:53:53,168: ============================================================
2022-03-26 15:53:53,169: Epoch 11/38 Batch 100/7662 eta: 2 days, 0:51:04.379375	Training Loss 2.6084 (2.6025)	Training Prec@1 99.805 (99.645)	Training Prec@5 100.000 (99.882)	
2022-03-26 15:53:53,169: ============================================================
2022-03-26 15:55:15,256: time cost, forward:0.026247986597032404, backward:0.05356311678287372, data cost:0.7379720965821539 
2022-03-26 15:55:15,259: ============================================================
2022-03-26 15:55:15,261: Epoch 11/38 Batch 200/7662 eta: 2 days, 0:52:32.235645	Training Loss 2.6124 (2.6106)	Training Prec@1 99.805 (99.661)	Training Prec@5 100.000 (99.888)	
2022-03-26 15:55:15,261: ============================================================
2022-03-26 15:56:35,106: time cost, forward:0.0262371768122134, backward:0.053979752454470634, data cost:0.7321655989490624 
2022-03-26 15:56:35,106: ============================================================
2022-03-26 15:56:35,107: Epoch 11/38 Batch 300/7662 eta: 1 day, 23:31:00.526398	Training Loss 2.6869 (2.6248)	Training Prec@1 99.414 (99.660)	Training Prec@5 99.805 (99.886)	
2022-03-26 15:56:35,107: ============================================================
2022-03-26 15:57:56,763: time cost, forward:0.02649764010780736, backward:0.053188257050095944, data cost:0.7310753908372463 
2022-03-26 15:57:56,763: ============================================================
2022-03-26 15:57:56,764: Epoch 11/38 Batch 400/7662 eta: 2 days, 0:34:17.930895	Training Loss 2.6142 (2.6256)	Training Prec@1 99.609 (99.650)	Training Prec@5 100.000 (99.884)	
2022-03-26 15:57:56,764: ============================================================
2022-03-26 15:59:18,826: time cost, forward:0.026419089170161614, backward:0.05350653489749274, data cost:0.7341574036286684 
2022-03-26 15:59:18,827: ============================================================
2022-03-26 15:59:18,827: Epoch 11/38 Batch 500/7662 eta: 2 days, 0:47:25.538914	Training Loss 2.7432 (2.6307)	Training Prec@1 100.000 (99.643)	Training Prec@5 100.000 (99.882)	
2022-03-26 15:59:18,827: ============================================================
2022-03-26 16:00:38,667: time cost, forward:0.025862971211912635, backward:0.05305393550153169, data cost:0.7314757158441815 
2022-03-26 16:00:38,667: ============================================================
2022-03-26 16:00:38,668: Epoch 11/38 Batch 600/7662 eta: 1 day, 23:26:48.951189	Training Loss 2.7435 (2.6379)	Training Prec@1 99.805 (99.647)	Training Prec@5 100.000 (99.883)	
2022-03-26 16:00:38,668: ============================================================
2022-03-26 16:01:59,445: time cost, forward:0.025703903602087106, backward:0.05267537373500491, data cost:0.7310696531604117 
2022-03-26 16:01:59,447: ============================================================
2022-03-26 16:01:59,447: Epoch 11/38 Batch 700/7662 eta: 1 day, 23:58:56.733208	Training Loss 2.7867 (2.6451)	Training Prec@1 99.609 (99.648)	Training Prec@5 100.000 (99.881)	
2022-03-26 16:01:59,448: ============================================================
2022-03-26 16:03:19,048: time cost, forward:0.025449311479609063, backward:0.05230984669901403, data cost:0.7305005277053584 
2022-03-26 16:03:19,052: ============================================================
2022-03-26 16:03:19,053: Epoch 11/38 Batch 800/7662 eta: 1 day, 23:15:45.263472	Training Loss 2.6335 (2.6501)	Training Prec@1 99.023 (99.646)	Training Prec@5 99.609 (99.880)	
2022-03-26 16:03:19,053: ============================================================
2022-03-26 16:04:39,201: time cost, forward:0.025273743672949055, backward:0.05229865404071744, data cost:0.7298382811074262 
2022-03-26 16:04:39,202: ============================================================
2022-03-26 16:04:39,202: Epoch 11/38 Batch 900/7662 eta: 1 day, 23:33:49.632434	Training Loss 2.6969 (2.6590)	Training Prec@1 99.609 (99.642)	Training Prec@5 99.805 (99.878)	
2022-03-26 16:04:39,202: ============================================================
2022-03-26 16:06:00,387: time cost, forward:0.025119980772932968, backward:0.052013570481950454, data cost:0.7304994740166344 
2022-03-26 16:06:00,387: ============================================================
2022-03-26 16:06:00,387: Epoch 11/38 Batch 1000/7662 eta: 2 days, 0:09:20.803469	Training Loss 2.6817 (2.6647)	Training Prec@1 99.609 (99.642)	Training Prec@5 99.805 (99.880)	
2022-03-26 16:06:00,388: ============================================================
2022-03-26 16:07:21,845: time cost, forward:0.02492943538981638, backward:0.05167304439041374, data cost:0.731341505180824 
2022-03-26 16:07:21,846: ============================================================
2022-03-26 16:07:21,846: Epoch 11/38 Batch 1100/7662 eta: 2 days, 0:17:42.198321	Training Loss 2.7522 (2.6711)	Training Prec@1 99.805 (99.640)	Training Prec@5 100.000 (99.879)	
2022-03-26 16:07:21,846: ============================================================
2022-03-26 16:08:39,048: time cost, forward:0.02470592820117432, backward:0.05160494065463692, data cost:0.728517591406446 
2022-03-26 16:08:39,049: ============================================================
2022-03-26 16:08:39,049: Epoch 11/38 Batch 1200/7662 eta: 1 day, 21:45:03.168006	Training Loss 2.7081 (2.6776)	Training Prec@1 99.805 (99.634)	Training Prec@5 100.000 (99.875)	
2022-03-26 16:08:39,049: ============================================================
2022-03-26 16:10:00,123: time cost, forward:0.024556154650481873, backward:0.05170785307058286, data cost:0.7288450816670595 
2022-03-26 16:10:00,124: ============================================================
2022-03-26 16:10:00,124: Epoch 11/38 Batch 1300/7662 eta: 2 days, 0:01:21.990888	Training Loss 2.7765 (2.6840)	Training Prec@1 99.805 (99.633)	Training Prec@5 100.000 (99.875)	
2022-03-26 16:10:00,124: ============================================================
2022-03-26 16:11:19,572: time cost, forward:0.024546241998842908, backward:0.051699510210322173, data cost:0.7277908693304055 
2022-03-26 16:11:19,573: ============================================================
2022-03-26 16:11:19,573: Epoch 11/38 Batch 1400/7662 eta: 1 day, 23:02:14.682328	Training Loss 2.5671 (2.6902)	Training Prec@1 100.000 (99.630)	Training Prec@5 100.000 (99.874)	
2022-03-26 16:11:19,574: ============================================================
2022-03-26 16:12:44,467: time cost, forward:0.02457115712207186, backward:0.05173617573560597, data cost:0.7302411900431892 
2022-03-26 16:12:44,468: ============================================================
2022-03-26 16:12:44,468: Epoch 11/38 Batch 1500/7662 eta: 2 days, 2:14:18.821646	Training Loss 2.6578 (2.6970)	Training Prec@1 99.805 (99.626)	Training Prec@5 99.805 (99.874)	
2022-03-26 16:12:44,469: ============================================================
2022-03-26 16:13:59,101: time cost, forward:0.024346578411939667, backward:0.0513885036120197, data cost:0.7274802703272931 
2022-03-26 16:13:59,102: ============================================================
2022-03-26 16:13:59,102: Epoch 11/38 Batch 1600/7662 eta: 1 day, 20:08:42.810788	Training Loss 2.6065 (2.7017)	Training Prec@1 100.000 (99.625)	Training Prec@5 100.000 (99.874)	
2022-03-26 16:13:59,102: ============================================================
2022-03-26 16:15:15,354: time cost, forward:0.024213210493764716, backward:0.051520345069296994, data cost:0.7249970970748802 
2022-03-26 16:15:15,354: ============================================================
2022-03-26 16:15:15,355: Epoch 11/38 Batch 1700/7662 eta: 1 day, 21:04:53.720793	Training Loss 2.7231 (2.7085)	Training Prec@1 99.609 (99.624)	Training Prec@5 99.805 (99.874)	
2022-03-26 16:15:15,355: ============================================================
2022-03-26 16:16:34,077: time cost, forward:0.024244490168106564, backward:0.051488549792812956, data cost:0.7241193723387026 
2022-03-26 16:16:34,078: ============================================================
2022-03-26 16:16:34,078: Epoch 11/38 Batch 1800/7662 eta: 1 day, 22:31:13.174829	Training Loss 2.7854 (2.7149)	Training Prec@1 99.219 (99.618)	Training Prec@5 99.609 (99.871)	
2022-03-26 16:16:34,078: ============================================================
2022-03-26 16:17:52,151: time cost, forward:0.024195604038087865, backward:0.051364930320125055, data cost:0.7228884742158284 
2022-03-26 16:17:52,151: ============================================================
2022-03-26 16:17:52,152: Epoch 11/38 Batch 1900/7662 eta: 1 day, 22:06:53.808597	Training Loss 3.0181 (2.7202)	Training Prec@1 99.609 (99.616)	Training Prec@5 100.000 (99.870)	
2022-03-26 16:17:52,152: ============================================================
2022-03-26 16:19:14,525: time cost, forward:0.02424681502738674, backward:0.051433189920689716, data cost:0.7237440184869427 
2022-03-26 16:19:14,553: ============================================================
2022-03-26 16:19:14,555: Epoch 11/38 Batch 2000/7662 eta: 2 days, 0:38:56.171661	Training Loss 2.7486 (2.7256)	Training Prec@1 99.219 (99.610)	Training Prec@5 99.805 (99.867)	
2022-03-26 16:19:14,556: ============================================================
2022-03-26 16:20:35,215: time cost, forward:0.024187707060459057, backward:0.051518177179679124, data cost:0.7244612284647163 
2022-03-26 16:20:35,215: ============================================================
2022-03-26 16:20:35,215: Epoch 11/38 Batch 2100/7662 eta: 1 day, 23:35:53.547756	Training Loss 2.9193 (2.7291)	Training Prec@1 99.805 (99.611)	Training Prec@5 100.000 (99.868)	
2022-03-26 16:20:35,215: ============================================================
2022-03-26 16:21:56,507: time cost, forward:0.024175307489406418, backward:0.05145141415945125, data cost:0.7249820130475275 
2022-03-26 16:21:56,507: ============================================================
2022-03-26 16:21:56,507: Epoch 11/38 Batch 2200/7662 eta: 1 day, 23:56:53.235639	Training Loss 2.7991 (2.7337)	Training Prec@1 99.219 (99.607)	Training Prec@5 100.000 (99.868)	
2022-03-26 16:21:56,508: ============================================================
2022-03-26 16:23:16,983: time cost, forward:0.02407502194703688, backward:0.0514878702972598, data cost:0.7247887525728548 
2022-03-26 16:23:16,985: ============================================================
2022-03-26 16:23:16,986: Epoch 11/38 Batch 2300/7662 eta: 1 day, 23:26:44.055763	Training Loss 2.8192 (2.7385)	Training Prec@1 99.219 (99.604)	Training Prec@5 99.805 (99.867)	
2022-03-26 16:23:16,987: ============================================================
2022-03-26 16:24:36,782: time cost, forward:0.02396424475586777, backward:0.05129971718877591, data cost:0.7252743654620801 
2022-03-26 16:24:36,782: ============================================================
2022-03-26 16:24:36,782: Epoch 11/38 Batch 2400/7662 eta: 1 day, 23:01:18.820128	Training Loss 2.8306 (2.7436)	Training Prec@1 99.414 (99.601)	Training Prec@5 100.000 (99.866)	
2022-03-26 16:24:36,783: ============================================================
2022-03-26 16:25:57,170: time cost, forward:0.024004855314318112, backward:0.051404007247277575, data cost:0.7252087346932181 
2022-03-26 16:25:57,170: ============================================================
2022-03-26 16:25:57,170: Epoch 11/38 Batch 2500/7662 eta: 1 day, 23:20:52.460806	Training Loss 3.0385 (2.7486)	Training Prec@1 99.609 (99.597)	Training Prec@5 100.000 (99.865)	
2022-03-26 16:25:57,171: ============================================================
2022-03-26 16:27:18,096: time cost, forward:0.023952999221402527, backward:0.051326925638044, data cost:0.7255633722226773 
2022-03-26 16:27:18,096: ============================================================
2022-03-26 16:27:18,096: Epoch 11/38 Batch 2600/7662 eta: 1 day, 23:38:31.963554	Training Loss 2.8511 (2.7533)	Training Prec@1 99.414 (99.594)	Training Prec@5 99.805 (99.863)	
2022-03-26 16:27:18,097: ============================================================
2022-03-26 16:28:36,530: time cost, forward:0.023842026631714638, backward:0.05137074634118096, data cost:0.7246473034296534 
2022-03-26 16:28:36,533: ============================================================
2022-03-26 16:28:36,534: Epoch 11/38 Batch 2700/7662 eta: 1 day, 22:09:19.274142	Training Loss 2.9791 (2.7579)	Training Prec@1 99.219 (99.590)	Training Prec@5 99.609 (99.862)	
2022-03-26 16:28:36,536: ============================================================
2022-03-26 16:29:55,879: time cost, forward:0.02383365516962431, backward:0.05149254913030245, data cost:0.7245303519754249 
2022-03-26 16:29:55,879: ============================================================
2022-03-26 16:29:55,880: Epoch 11/38 Batch 2800/7662 eta: 1 day, 22:40:04.349747	Training Loss 2.8471 (2.7624)	Training Prec@1 99.609 (99.588)	Training Prec@5 100.000 (99.861)	
2022-03-26 16:29:55,880: ============================================================
2022-03-26 16:31:15,784: time cost, forward:0.023812816981078427, backward:0.051494201983859435, data cost:0.7243423549912641 
2022-03-26 16:31:15,787: ============================================================
2022-03-26 16:31:15,788: Epoch 11/38 Batch 2900/7662 eta: 1 day, 22:58:35.344536	Training Loss 2.8873 (2.7658)	Training Prec@1 99.609 (99.585)	Training Prec@5 100.000 (99.861)	
2022-03-26 16:31:15,789: ============================================================
2022-03-26 16:32:35,327: time cost, forward:0.02379619657854193, backward:0.05160406503171752, data cost:0.7241354047476987 
2022-03-26 16:32:35,327: ============================================================
2022-03-26 16:32:35,327: Epoch 11/38 Batch 3000/7662 eta: 1 day, 22:44:15.136218	Training Loss 2.8006 (2.7698)	Training Prec@1 99.414 (99.582)	Training Prec@5 100.000 (99.860)	
2022-03-26 16:32:35,327: ============================================================
2022-03-26 16:33:56,271: time cost, forward:0.023821720349169347, backward:0.0516787779335054, data cost:0.724321448983743 
2022-03-26 16:33:56,271: ============================================================
2022-03-26 16:33:56,272: Epoch 11/38 Batch 3100/7662 eta: 1 day, 23:32:26.475706	Training Loss 2.8752 (2.7732)	Training Prec@1 99.414 (99.580)	Training Prec@5 100.000 (99.860)	
2022-03-26 16:33:56,272: ============================================================
2022-03-26 16:35:15,535: time cost, forward:0.023808310053504308, backward:0.051751142071350995, data cost:0.7239432926660927 
2022-03-26 16:35:15,538: ============================================================
2022-03-26 16:35:15,539: Epoch 11/38 Batch 3200/7662 eta: 1 day, 22:32:00.050760	Training Loss 2.8683 (2.7772)	Training Prec@1 99.805 (99.577)	Training Prec@5 100.000 (99.858)	
2022-03-26 16:35:15,539: ============================================================
2022-03-26 16:36:35,785: time cost, forward:0.023741802398852777, backward:0.051689775686041446, data cost:0.7240649387669512 
2022-03-26 16:36:35,786: ============================================================
2022-03-26 16:36:35,786: Epoch 11/38 Batch 3300/7662 eta: 1 day, 23:05:12.845078	Training Loss 2.9734 (2.7811)	Training Prec@1 99.414 (99.574)	Training Prec@5 100.000 (99.857)	
2022-03-26 16:36:35,786: ============================================================
2022-03-26 16:37:59,369: time cost, forward:0.02375476793107933, backward:0.05176327880181506, data cost:0.7249073619595623 
2022-03-26 16:37:59,372: ============================================================
2022-03-26 16:37:59,373: Epoch 11/38 Batch 3400/7662 eta: 2 days, 1:01:20.750753	Training Loss 3.0717 (2.7848)	Training Prec@1 99.414 (99.571)	Training Prec@5 99.805 (99.857)	
2022-03-26 16:37:59,374: ============================================================
2022-03-26 16:39:18,309: time cost, forward:0.02371079658024241, backward:0.05168280699621715, data cost:0.7247728637778169 
2022-03-26 16:39:18,310: ============================================================
2022-03-26 16:39:18,310: Epoch 11/38 Batch 3500/7662 eta: 1 day, 22:16:28.140439	Training Loss 2.8021 (2.7882)	Training Prec@1 99.414 (99.568)	Training Prec@5 99.805 (99.855)	
2022-03-26 16:39:18,310: ============================================================
2022-03-26 16:40:38,303: time cost, forward:0.023693576061781924, backward:0.05166528456142857, data cost:0.7247711720483838 
2022-03-26 16:40:38,303: ============================================================
2022-03-26 16:40:38,303: Epoch 11/38 Batch 3600/7662 eta: 1 day, 22:52:15.707531	Training Loss 2.7896 (2.7911)	Training Prec@1 99.414 (99.566)	Training Prec@5 99.805 (99.854)	
2022-03-26 16:40:38,304: ============================================================
2022-03-26 16:42:01,226: time cost, forward:0.02364833273092261, backward:0.0515339805100795, data cost:0.7256333110589664 
2022-03-26 16:42:01,228: ============================================================
2022-03-26 16:42:01,229: Epoch 11/38 Batch 3700/7662 eta: 2 days, 0:33:57.204461	Training Loss 2.9144 (2.7946)	Training Prec@1 99.609 (99.564)	Training Prec@5 99.805 (99.854)	
2022-03-26 16:42:01,230: ============================================================
2022-03-26 16:43:22,134: time cost, forward:0.023677826429800347, backward:0.051551911792619566, data cost:0.7258116645416356 
2022-03-26 16:43:22,134: ============================================================
2022-03-26 16:43:22,135: Epoch 11/38 Batch 3800/7662 eta: 1 day, 23:21:38.546906	Training Loss 3.1778 (2.7976)	Training Prec@1 99.219 (99.561)	Training Prec@5 99.609 (99.853)	
2022-03-26 16:43:22,135: ============================================================
2022-03-26 16:44:43,927: time cost, forward:0.023677576563547256, backward:0.05155842412462844, data cost:0.7260663097838495 
2022-03-26 16:44:43,929: ============================================================
2022-03-26 16:44:43,930: Epoch 11/38 Batch 3900/7662 eta: 1 day, 23:51:30.833621	Training Loss 2.9603 (2.8007)	Training Prec@1 100.000 (99.558)	Training Prec@5 100.000 (99.853)	
2022-03-26 16:44:43,931: ============================================================
2022-03-26 16:46:03,017: time cost, forward:0.023658839366709657, backward:0.051581637148083254, data cost:0.7257847768063842 
2022-03-26 16:46:03,019: ============================================================
2022-03-26 16:46:03,020: Epoch 11/38 Batch 4000/7662 eta: 1 day, 22:15:12.506409	Training Loss 2.9705 (2.8037)	Training Prec@1 99.609 (99.557)	Training Prec@5 100.000 (99.853)	
2022-03-26 16:46:03,021: ============================================================
2022-03-26 16:47:23,693: time cost, forward:0.023637524928427755, backward:0.051540567747526966, data cost:0.7258993345052622 
2022-03-26 16:47:23,694: ============================================================
2022-03-26 16:47:23,694: Epoch 11/38 Batch 4100/7662 eta: 1 day, 23:09:29.283020	Training Loss 2.8532 (2.8064)	Training Prec@1 99.609 (99.556)	Training Prec@5 100.000 (99.852)	
2022-03-26 16:47:23,695: ============================================================
2022-03-26 16:48:47,689: time cost, forward:0.02367353427975085, backward:0.051658447483205375, data cost:0.7266607434444695 
2022-03-26 16:48:47,689: ============================================================
2022-03-26 16:48:47,690: Epoch 11/38 Batch 4200/7662 eta: 2 days, 1:04:34.270959	Training Loss 2.9823 (2.8089)	Training Prec@1 99.414 (99.555)	Training Prec@5 100.000 (99.852)	
2022-03-26 16:48:47,690: ============================================================
2022-03-26 16:50:09,988: time cost, forward:0.023714926942167352, backward:0.05174456221692977, data cost:0.7268173254820102 
2022-03-26 16:50:09,989: ============================================================
2022-03-26 16:50:09,990: Epoch 11/38 Batch 4300/7662 eta: 2 days, 0:03:43.761199	Training Loss 2.8753 (2.8118)	Training Prec@1 99.414 (99.552)	Training Prec@5 99.805 (99.852)	
2022-03-26 16:50:09,990: ============================================================
2022-03-26 16:51:30,513: time cost, forward:0.023670845233356174, backward:0.051577985815146644, data cost:0.7270918986720913 
2022-03-26 16:51:30,518: ============================================================
2022-03-26 16:51:30,519: Epoch 11/38 Batch 4400/7662 eta: 1 day, 23:00:21.835047	Training Loss 3.1008 (2.8155)	Training Prec@1 99.609 (99.550)	Training Prec@5 99.805 (99.851)	
2022-03-26 16:51:30,520: ============================================================
2022-03-26 16:52:49,493: time cost, forward:0.023681407611776548, backward:0.051593516821012306, data cost:0.7269193417073674 
2022-03-26 16:52:49,494: ============================================================
2022-03-26 16:52:49,494: Epoch 11/38 Batch 4500/7662 eta: 1 day, 22:04:37.916883	Training Loss 2.8218 (2.8182)	Training Prec@1 99.414 (99.547)	Training Prec@5 99.609 (99.850)	
2022-03-26 16:52:49,494: ============================================================
2022-03-26 16:54:13,988: time cost, forward:0.023650824129387047, backward:0.0516121649799152, data cost:0.7277418409489786 
2022-03-26 16:54:13,989: ============================================================
2022-03-26 16:54:13,990: Epoch 11/38 Batch 4600/7662 eta: 2 days, 1:16:27.421629	Training Loss 2.9021 (2.8213)	Training Prec@1 99.805 (99.545)	Training Prec@5 100.000 (99.849)	
2022-03-26 16:54:13,990: ============================================================
2022-03-26 16:55:32,025: time cost, forward:0.023602926317593677, backward:0.051572581610037284, data cost:0.7273933174610645 
2022-03-26 16:55:32,025: ============================================================
2022-03-26 16:55:32,025: Epoch 11/38 Batch 4700/7662 eta: 1 day, 21:29:07.681930	Training Loss 3.0821 (2.8239)	Training Prec@1 99.609 (99.541)	Training Prec@5 99.805 (99.848)	
2022-03-26 16:55:32,026: ============================================================
2022-03-26 16:56:54,003: time cost, forward:0.023587440396130248, backward:0.05166873124073535, data cost:0.7276226369309708 
2022-03-26 16:56:54,005: ============================================================
2022-03-26 16:56:54,006: Epoch 11/38 Batch 4800/7662 eta: 1 day, 23:45:43.365241	Training Loss 2.8355 (2.8262)	Training Prec@1 98.828 (99.539)	Training Prec@5 99.805 (99.848)	
2022-03-26 16:56:54,007: ============================================================
2022-03-26 16:58:19,648: time cost, forward:0.023625757529263984, backward:0.05175347030345312, data cost:0.7284831268783978 
2022-03-26 16:58:19,648: ============================================================
2022-03-26 16:58:19,648: Epoch 11/38 Batch 4900/7662 eta: 2 days, 1:52:18.178636	Training Loss 3.0704 (2.8293)	Training Prec@1 99.609 (99.537)	Training Prec@5 99.805 (99.847)	
2022-03-26 16:58:19,649: ============================================================
2022-03-26 16:59:39,795: time cost, forward:0.023585105328637137, backward:0.051705734756952, data cost:0.7284287841683937 
2022-03-26 16:59:39,798: ============================================================
2022-03-26 16:59:39,799: Epoch 11/38 Batch 5000/7662 eta: 1 day, 22:39:02.860089	Training Loss 3.0427 (2.8325)	Training Prec@1 98.828 (99.535)	Training Prec@5 99.609 (99.846)	
2022-03-26 16:59:39,799: ============================================================
2022-03-26 17:01:01,241: time cost, forward:0.02357130996104104, backward:0.05165409934265891, data cost:0.7287958977993481 
2022-03-26 17:01:01,242: ============================================================
2022-03-26 17:01:01,242: Epoch 11/38 Batch 5100/7662 eta: 1 day, 23:22:54.513438	Training Loss 2.8943 (2.8355)	Training Prec@1 99.609 (99.532)	Training Prec@5 100.000 (99.845)	
2022-03-26 17:01:01,243: ============================================================
2022-03-26 17:02:26,181: time cost, forward:0.023632415236590296, backward:0.0516571965119453, data cost:0.7294169613250656 
2022-03-26 17:02:26,183: ============================================================
2022-03-26 17:02:26,184: Epoch 11/38 Batch 5200/7662 eta: 2 days, 1:23:33.917873	Training Loss 3.0459 (2.8378)	Training Prec@1 99.219 (99.531)	Training Prec@5 100.000 (99.844)	
2022-03-26 17:02:26,184: ============================================================
2022-03-26 17:03:46,048: time cost, forward:0.02365548085617466, backward:0.05170319934772262, data cost:0.729338130268832 
2022-03-26 17:03:46,048: ============================================================
2022-03-26 17:03:46,049: Epoch 11/38 Batch 5300/7662 eta: 1 day, 22:25:06.750936	Training Loss 3.0996 (2.8404)	Training Prec@1 99.609 (99.528)	Training Prec@5 99.805 (99.843)	
2022-03-26 17:03:46,049: ============================================================
2022-03-26 17:05:05,782: time cost, forward:0.02364332403468079, backward:0.05165245802805675, data cost:0.7291960903926566 
2022-03-26 17:05:05,783: ============================================================
2022-03-26 17:05:05,783: Epoch 11/38 Batch 5400/7662 eta: 1 day, 22:19:14.080342	Training Loss 3.0914 (2.8429)	Training Prec@1 99.414 (99.526)	Training Prec@5 99.805 (99.842)	
2022-03-26 17:05:05,783: ============================================================
2022-03-26 17:06:26,213: time cost, forward:0.0236600074448961, backward:0.05171393507024249, data cost:0.7289482518355832 
2022-03-26 17:06:26,216: ============================================================
2022-03-26 17:06:26,217: Epoch 11/38 Batch 5500/7662 eta: 1 day, 22:42:16.611789	Training Loss 3.1781 (2.8452)	Training Prec@1 98.828 (99.524)	Training Prec@5 99.609 (99.842)	
2022-03-26 17:06:26,218: ============================================================
2022-03-26 17:07:47,821: time cost, forward:0.023677188682862744, backward:0.05175792623745754, data cost:0.7292249152481098 
2022-03-26 17:07:47,822: ============================================================
2022-03-26 17:07:47,822: Epoch 11/38 Batch 5600/7662 eta: 1 day, 23:21:43.484231	Training Loss 3.1778 (2.8475)	Training Prec@1 99.219 (99.521)	Training Prec@5 99.805 (99.841)	
2022-03-26 17:07:47,822: ============================================================
2022-03-26 17:09:08,527: time cost, forward:0.02370381208862583, backward:0.05178426738202854, data cost:0.7291821967846345 
2022-03-26 17:09:08,527: ============================================================
2022-03-26 17:09:08,528: Epoch 11/38 Batch 5700/7662 eta: 1 day, 22:49:02.852189	Training Loss 3.0015 (2.8491)	Training Prec@1 99.414 (99.519)	Training Prec@5 100.000 (99.840)	
2022-03-26 17:09:08,528: ============================================================
2022-03-26 17:10:28,513: time cost, forward:0.023698634249441665, backward:0.051761299602984145, data cost:0.7289266515999215 
2022-03-26 17:10:28,514: ============================================================
2022-03-26 17:10:28,514: Epoch 11/38 Batch 5800/7662 eta: 1 day, 22:22:41.477291	Training Loss 3.1189 (2.8513)	Training Prec@1 98.633 (99.517)	Training Prec@5 99.805 (99.840)	
2022-03-26 17:10:28,514: ============================================================
2022-03-26 17:11:50,262: time cost, forward:0.023696781962902834, backward:0.051771211228061075, data cost:0.7291187770812466 
2022-03-26 17:11:50,266: ============================================================
2022-03-26 17:11:50,268: Epoch 11/38 Batch 5900/7662 eta: 1 day, 23:22:46.322191	Training Loss 2.9852 (2.8536)	Training Prec@1 99.219 (99.514)	Training Prec@5 99.805 (99.839)	
2022-03-26 17:11:50,269: ============================================================
2022-03-26 17:13:09,972: time cost, forward:0.02367972997769373, backward:0.05173395045261857, data cost:0.7290223976993068 
2022-03-26 17:13:09,974: ============================================================
2022-03-26 17:13:09,975: Epoch 11/38 Batch 6000/7662 eta: 1 day, 22:10:20.436176	Training Loss 2.8077 (2.8560)	Training Prec@1 99.805 (99.513)	Training Prec@5 100.000 (99.838)	
2022-03-26 17:13:09,976: ============================================================
2022-03-26 17:14:30,820: time cost, forward:0.023687285152609806, backward:0.05179257106734096, data cost:0.729099460734092 
2022-03-26 17:14:30,820: ============================================================
2022-03-26 17:14:30,820: Epoch 11/38 Batch 6100/7662 eta: 1 day, 22:48:32.269765	Training Loss 3.0741 (2.8582)	Training Prec@1 98.828 (99.511)	Training Prec@5 99.414 (99.838)	
2022-03-26 17:14:30,821: ============================================================
2022-03-26 17:15:54,490: time cost, forward:0.02370378989945652, backward:0.051801588712613186, data cost:0.7294600077609243 
2022-03-26 17:15:54,490: ============================================================
2022-03-26 17:15:54,491: Epoch 11/38 Batch 6200/7662 eta: 2 days, 0:25:15.799528	Training Loss 2.8843 (2.8603)	Training Prec@1 99.805 (99.509)	Training Prec@5 99.805 (99.837)	
2022-03-26 17:15:54,491: ============================================================
2022-03-26 17:17:14,400: time cost, forward:0.02367679466045287, backward:0.05180892817159175, data cost:0.7293529114584674 
2022-03-26 17:17:14,401: ============================================================
2022-03-26 17:17:14,401: Epoch 11/38 Batch 6300/7662 eta: 1 day, 22:13:23.155006	Training Loss 3.0484 (2.8627)	Training Prec@1 99.609 (99.508)	Training Prec@5 99.805 (99.837)	
2022-03-26 17:17:14,402: ============================================================
2022-03-26 17:18:34,605: time cost, forward:0.023681852291814794, backward:0.051779765750415846, data cost:0.7294102725171916 
2022-03-26 17:18:34,605: ============================================================
2022-03-26 17:18:34,606: Epoch 11/38 Batch 6400/7662 eta: 1 day, 22:22:14.985016	Training Loss 2.8351 (2.8650)	Training Prec@1 100.000 (99.506)	Training Prec@5 100.000 (99.836)	
2022-03-26 17:18:34,606: ============================================================
2022-03-26 17:19:58,464: time cost, forward:0.023687401300651292, backward:0.05178456938180544, data cost:0.7299094679979641 
2022-03-26 17:19:58,465: ============================================================
2022-03-26 17:19:58,465: Epoch 11/38 Batch 6500/7662 eta: 2 days, 0:27:38.970896	Training Loss 2.9847 (2.8672)	Training Prec@1 99.414 (99.504)	Training Prec@5 99.805 (99.835)	
2022-03-26 17:19:58,465: ============================================================
2022-03-26 17:21:20,904: time cost, forward:0.023682209158832512, backward:0.05182440636067304, data cost:0.7299959770493984 
2022-03-26 17:21:20,907: ============================================================
2022-03-26 17:21:20,908: Epoch 11/38 Batch 6600/7662 eta: 1 day, 23:37:08.394535	Training Loss 3.1651 (2.8693)	Training Prec@1 98.633 (99.502)	Training Prec@5 99.414 (99.835)	
2022-03-26 17:21:20,908: ============================================================
2022-03-26 17:22:42,021: time cost, forward:0.023699608217835302, backward:0.051870064266334094, data cost:0.7301227470924114 
2022-03-26 17:22:42,022: ============================================================
2022-03-26 17:22:42,022: Epoch 11/38 Batch 6700/7662 eta: 1 day, 22:49:45.755657	Training Loss 3.1429 (2.8716)	Training Prec@1 99.609 (99.500)	Training Prec@5 100.000 (99.834)	
2022-03-26 17:22:42,022: ============================================================
2022-03-26 17:24:03,095: time cost, forward:0.02370724009668008, backward:0.05187831596164672, data cost:0.7301226825394302 
2022-03-26 17:24:03,095: ============================================================
2022-03-26 17:24:03,095: Epoch 11/38 Batch 6800/7662 eta: 1 day, 22:46:59.244449	Training Loss 2.8761 (2.8736)	Training Prec@1 99.805 (99.498)	Training Prec@5 100.000 (99.833)	
2022-03-26 17:24:03,096: ============================================================
2022-03-26 17:25:24,559: time cost, forward:0.023731789047743274, backward:0.051912652597788156, data cost:0.7301735362724595 
2022-03-26 17:25:24,560: ============================================================
2022-03-26 17:25:24,561: Epoch 11/38 Batch 6900/7662 eta: 1 day, 22:59:12.245727	Training Loss 3.1188 (2.8757)	Training Prec@1 99.414 (99.497)	Training Prec@5 99.609 (99.833)	
2022-03-26 17:25:24,561: ============================================================
2022-03-26 17:26:45,290: time cost, forward:0.023729132829282705, backward:0.05190263960868704, data cost:0.7302047270573042 
2022-03-26 17:26:45,291: ============================================================
2022-03-26 17:26:45,291: Epoch 11/38 Batch 7000/7662 eta: 1 day, 22:32:25.149583	Training Loss 2.9861 (2.8778)	Training Prec@1 99.023 (99.496)	Training Prec@5 99.609 (99.833)	
2022-03-26 17:26:45,291: ============================================================
2022-03-26 17:28:08,022: time cost, forward:0.023737462276572124, backward:0.051927691161556974, data cost:0.7304460552649223 
2022-03-26 17:28:08,022: ============================================================
2022-03-26 17:28:08,023: Epoch 11/38 Batch 7100/7662 eta: 1 day, 23:40:16.252358	Training Loss 2.8985 (2.8796)	Training Prec@1 99.414 (99.494)	Training Prec@5 99.805 (99.832)	
2022-03-26 17:28:08,023: ============================================================
2022-03-26 17:29:25,729: time cost, forward:0.023719780874643114, backward:0.05190810681647899, data cost:0.7300166777064857 
2022-03-26 17:29:25,731: ============================================================
2022-03-26 17:29:25,732: Epoch 11/38 Batch 7200/7662 eta: 1 day, 20:45:19.173909	Training Loss 2.9480 (2.8813)	Training Prec@1 99.219 (99.493)	Training Prec@5 99.805 (99.832)	
2022-03-26 17:29:25,732: ============================================================
2022-03-26 17:30:49,741: time cost, forward:0.023711596176810158, backward:0.051931708459087164, data cost:0.7304701112626203 
2022-03-26 17:30:49,742: ============================================================
2022-03-26 17:30:49,742: Epoch 11/38 Batch 7300/7662 eta: 2 days, 0:21:40.078395	Training Loss 3.3618 (2.8834)	Training Prec@1 99.414 (99.490)	Training Prec@5 99.805 (99.830)	
2022-03-26 17:30:49,742: ============================================================
2022-03-26 17:32:12,176: time cost, forward:0.0237127328051121, backward:0.051922039045387225, data cost:0.7307052922612961 
2022-03-26 17:32:12,176: ============================================================
2022-03-26 17:32:12,176: Epoch 11/38 Batch 7400/7662 eta: 1 day, 23:25:52.534923	Training Loss 2.9298 (2.8854)	Training Prec@1 99.414 (99.489)	Training Prec@5 100.000 (99.830)	
2022-03-26 17:32:12,177: ============================================================
2022-03-26 17:33:32,783: time cost, forward:0.023736789204594547, backward:0.0519335852382755, data cost:0.7305190394696974 
2022-03-26 17:33:32,785: ============================================================
2022-03-26 17:33:32,786: Epoch 11/38 Batch 7500/7662 eta: 1 day, 22:21:30.578667	Training Loss 2.9613 (2.8873)	Training Prec@1 99.414 (99.487)	Training Prec@5 100.000 (99.829)	
2022-03-26 17:33:32,787: ============================================================
2022-03-26 17:34:51,972: time cost, forward:0.023743855261397936, backward:0.0519186035082958, data cost:0.7303984894974009 
2022-03-26 17:34:51,973: ============================================================
2022-03-26 17:34:51,973: Epoch 11/38 Batch 7600/7662 eta: 1 day, 21:31:07.994134	Training Loss 3.1300 (2.8895)	Training Prec@1 99.414 (99.485)	Training Prec@5 100.000 (99.829)	
2022-03-26 17:34:51,973: ============================================================
2022-03-26 17:35:41,142: Epoch: 11/38 eta: 1 day, 21:30:18.106083	Training Loss 3.0008 (2.8909)	Training Prec@1 99.023 (99.484)	Training Prec@5 99.219 (99.828)
2022-03-26 17:35:41,143: ============================================================
2022-03-26 17:37:09,994: time cost, forward:0.02033048446732338, backward:0.03958234883318044, data cost:0.8209748460788919 
2022-03-26 17:37:09,997: ============================================================
2022-03-26 17:37:09,997: Epoch 12/38 Batch 100/7662 eta: 2 days, 2:55:49.743234	Training Loss 2.7264 (2.6093)	Training Prec@1 99.414 (99.690)	Training Prec@5 100.000 (99.905)	
2022-03-26 17:37:09,998: ============================================================
2022-03-26 17:38:27,342: time cost, forward:0.018917749874555884, backward:0.03924484228968021, data cost:0.7725401260145944 
2022-03-26 17:38:27,342: ============================================================
2022-03-26 17:38:27,342: Epoch 12/38 Batch 200/7662 eta: 1 day, 20:24:13.516458	Training Loss 2.6581 (2.6150)	Training Prec@1 99.805 (99.696)	Training Prec@5 100.000 (99.913)	
2022-03-26 17:38:27,342: ============================================================
2022-03-26 17:39:47,474: time cost, forward:0.020340980893393423, backward:0.04307387026656033, data cost:0.7561037404880078 
2022-03-26 17:39:47,475: ============================================================
2022-03-26 17:39:47,475: Epoch 12/38 Batch 300/7662 eta: 1 day, 21:58:53.912190	Training Loss 2.4314 (2.6230)	Training Prec@1 99.805 (99.700)	Training Prec@5 100.000 (99.914)	
2022-03-26 17:39:47,475: ============================================================
2022-03-26 17:41:06,946: time cost, forward:0.020672466521872615, backward:0.043768613858330516, data cost:0.7473830304348976 
2022-03-26 17:41:06,947: ============================================================
2022-03-26 17:41:06,947: Epoch 12/38 Batch 400/7662 eta: 1 day, 21:34:49.748256	Training Loss 2.7006 (2.6350)	Training Prec@1 100.000 (99.704)	Training Prec@5 100.000 (99.913)	
2022-03-26 17:41:06,947: ============================================================
2022-03-26 17:42:30,029: time cost, forward:0.02135360217046642, backward:0.045792047867555176, data cost:0.749205687241946 
2022-03-26 17:42:30,030: ============================================================
2022-03-26 17:42:30,030: Epoch 12/38 Batch 500/7662 eta: 1 day, 23:37:43.199973	Training Loss 2.7345 (2.6458)	Training Prec@1 99.414 (99.700)	Training Prec@5 100.000 (99.913)	
2022-03-26 17:42:30,030: ============================================================
2022-03-26 17:43:44,246: time cost, forward:0.02126489338373302, backward:0.04620219789482715, data cost:0.7356456778881347 
2022-03-26 17:43:44,247: ============================================================
2022-03-26 17:43:44,247: Epoch 12/38 Batch 600/7662 eta: 1 day, 18:31:31.396599	Training Loss 2.9794 (2.6608)	Training Prec@1 99.219 (99.695)	Training Prec@5 99.805 (99.912)	
2022-03-26 17:43:44,248: ============================================================
2022-03-26 17:45:02,179: time cost, forward:0.021521532825475427, backward:0.04651547365093095, data cost:0.7316749338087265 
2022-03-26 17:45:02,182: ============================================================
2022-03-26 17:45:02,183: Epoch 12/38 Batch 700/7662 eta: 1 day, 20:38:02.539220	Training Loss 2.8621 (2.6715)	Training Prec@1 99.219 (99.683)	Training Prec@5 99.805 (99.907)	
2022-03-26 17:45:02,183: ============================================================
2022-03-26 17:46:20,047: time cost, forward:0.021801370255490567, backward:0.04689937061601049, data cost:0.727282257641063 
2022-03-26 17:46:20,049: ============================================================
2022-03-26 17:46:20,050: Epoch 12/38 Batch 800/7662 eta: 1 day, 20:34:25.418827	Training Loss 2.7748 (2.6796)	Training Prec@1 99.609 (99.675)	Training Prec@5 99.805 (99.903)	
2022-03-26 17:46:20,051: ============================================================
2022-03-26 17:47:38,015: time cost, forward:0.02197332138214281, backward:0.04741480379666847, data cost:0.7252383070342135 
2022-03-26 17:47:38,018: ============================================================
2022-03-26 17:47:38,019: Epoch 12/38 Batch 900/7662 eta: 1 day, 20:36:35.415832	Training Loss 2.7591 (2.6912)	Training Prec@1 99.414 (99.670)	Training Prec@5 99.609 (99.900)	
2022-03-26 17:47:38,020: ============================================================
2022-03-26 17:48:57,314: time cost, forward:0.02188214358386096, backward:0.047477544129670445, data cost:0.7244816408739673 
2022-03-26 17:48:57,316: ============================================================
2022-03-26 17:48:57,316: Epoch 12/38 Batch 1000/7662 eta: 1 day, 21:20:54.013580	Training Loss 2.8548 (2.7004)	Training Prec@1 99.609 (99.668)	Training Prec@5 99.805 (99.900)	
2022-03-26 17:48:57,317: ============================================================
2022-03-26 17:50:13,268: time cost, forward:0.021862671091081448, backward:0.047777263330697366, data cost:0.7209875954618445 
2022-03-26 17:50:13,270: ============================================================
2022-03-26 17:50:13,271: Epoch 12/38 Batch 1100/7662 eta: 1 day, 19:24:55.543023	Training Loss 2.6706 (2.7107)	Training Prec@1 99.805 (99.663)	Training Prec@5 100.000 (99.898)	
2022-03-26 17:50:13,272: ============================================================
2022-03-26 17:51:35,013: time cost, forward:0.022030607872550144, backward:0.048325860967628156, data cost:0.7227225601921686 
2022-03-26 17:51:35,017: ============================================================
2022-03-26 17:51:35,018: Epoch 12/38 Batch 1200/7662 eta: 1 day, 22:42:13.673275	Training Loss 3.0233 (2.7200)	Training Prec@1 99.219 (99.659)	Training Prec@5 99.414 (99.896)	
2022-03-26 17:51:35,019: ============================================================
2022-03-26 17:52:53,135: time cost, forward:0.021977752607725876, backward:0.048385773006083876, data cost:0.7213106054448457 
2022-03-26 17:52:53,137: ============================================================
2022-03-26 17:52:53,138: Epoch 12/38 Batch 1300/7662 eta: 1 day, 20:36:34.297240	Training Loss 2.8949 (2.7292)	Training Prec@1 99.805 (99.656)	Training Prec@5 100.000 (99.894)	
2022-03-26 17:52:53,139: ============================================================
2022-03-26 17:54:14,810: time cost, forward:0.02208052421144454, backward:0.04861593621385532, data cost:0.722710410384641 
2022-03-26 17:54:14,810: ============================================================
2022-03-26 17:54:14,811: Epoch 12/38 Batch 1400/7662 eta: 1 day, 22:36:57.902152	Training Loss 2.9407 (2.7367)	Training Prec@1 99.805 (99.652)	Training Prec@5 100.000 (99.893)	
2022-03-26 17:54:14,811: ============================================================
2022-03-26 17:55:35,744: time cost, forward:0.022152065037885773, backward:0.04887802144382062, data cost:0.7236025265012287 
2022-03-26 17:55:35,745: ============================================================
2022-03-26 17:55:35,745: Epoch 12/38 Batch 1500/7662 eta: 1 day, 22:10:18.442461	Training Loss 2.8495 (2.7453)	Training Prec@1 99.805 (99.647)	Training Prec@5 99.805 (99.893)	
2022-03-26 17:55:35,745: ============================================================
2022-03-26 17:56:52,632: time cost, forward:0.022066386660014637, backward:0.048685315849633426, data cost:0.7221149921119027 
2022-03-26 17:56:52,633: ============================================================
2022-03-26 17:56:52,633: Epoch 12/38 Batch 1600/7662 eta: 1 day, 19:50:32.603062	Training Loss 3.0486 (2.7537)	Training Prec@1 99.609 (99.643)	Training Prec@5 100.000 (99.891)	
2022-03-26 17:56:52,634: ============================================================
2022-03-26 17:58:11,205: time cost, forward:0.02214428493034987, backward:0.04881712196152515, data cost:0.7208311393585115 
2022-03-26 17:58:11,208: ============================================================
2022-03-26 17:58:11,208: Epoch 12/38 Batch 1700/7662 eta: 1 day, 20:46:55.794077	Training Loss 2.8494 (2.7610)	Training Prec@1 99.414 (99.639)	Training Prec@5 99.609 (99.890)	
2022-03-26 17:58:11,209: ============================================================
2022-03-26 17:59:29,240: time cost, forward:0.022256376347056756, backward:0.04893848483863309, data cost:0.7199614209688789 
2022-03-26 17:59:29,240: ============================================================
2022-03-26 17:59:29,240: Epoch 12/38 Batch 1800/7662 eta: 1 day, 20:27:04.369090	Training Loss 2.9595 (2.7693)	Training Prec@1 99.805 (99.636)	Training Prec@5 99.805 (99.888)	
2022-03-26 17:59:29,240: ============================================================
2022-03-26 18:00:45,151: time cost, forward:0.022188785265721166, backward:0.04872536684350631, data cost:0.7184396501965997 
2022-03-26 18:00:45,153: ============================================================
2022-03-26 18:00:45,154: Epoch 12/38 Batch 1900/7662 eta: 1 day, 19:13:23.300435	Training Loss 2.9194 (2.7751)	Training Prec@1 98.633 (99.633)	Training Prec@5 99.609 (99.887)	
2022-03-26 18:00:45,154: ============================================================
2022-03-26 18:02:00,523: time cost, forward:0.022160844363946806, backward:0.048876964193156146, data cost:0.716500058777634 
2022-03-26 18:02:00,526: ============================================================
2022-03-26 18:02:00,526: Epoch 12/38 Batch 2000/7662 eta: 1 day, 18:53:39.329150	Training Loss 2.7073 (2.7817)	Training Prec@1 99.805 (99.631)	Training Prec@5 99.805 (99.886)	
2022-03-26 18:02:00,527: ============================================================
2022-03-26 18:03:21,430: time cost, forward:0.02234940349402571, backward:0.04920000016774491, data cost:0.7172143085619676 
2022-03-26 18:03:21,430: ============================================================
2022-03-26 18:03:21,430: Epoch 12/38 Batch 2100/7662 eta: 1 day, 22:01:11.880358	Training Loss 2.7586 (2.7888)	Training Prec@1 99.609 (99.625)	Training Prec@5 100.000 (99.886)	
2022-03-26 18:03:21,431: ============================================================
2022-03-26 18:04:42,889: time cost, forward:0.02234101230418373, backward:0.049224386436389544, data cost:0.7178887937111224 
2022-03-26 18:04:42,891: ============================================================
2022-03-26 18:04:42,892: Epoch 12/38 Batch 2200/7662 eta: 1 day, 22:18:51.356211	Training Loss 2.7176 (2.7947)	Training Prec@1 99.609 (99.623)	Training Prec@5 100.000 (99.884)	
2022-03-26 18:04:42,893: ============================================================
2022-03-26 18:06:04,547: time cost, forward:0.02230671116869156, backward:0.049358911647025064, data cost:0.7189235878073686 
2022-03-26 18:06:04,550: ============================================================
2022-03-26 18:06:04,551: Epoch 12/38 Batch 2300/7662 eta: 1 day, 22:24:12.940668	Training Loss 2.9766 (2.8021)	Training Prec@1 99.414 (99.619)	Training Prec@5 99.805 (99.882)	
2022-03-26 18:06:04,552: ============================================================
2022-03-26 18:07:21,224: time cost, forward:0.022270563892048068, backward:0.04945918359871753, data cost:0.7181381146676246 
2022-03-26 18:07:21,225: ============================================================
2022-03-26 18:07:21,225: Epoch 12/38 Batch 2400/7662 eta: 1 day, 19:32:59.802134	Training Loss 2.9429 (2.8088)	Training Prec@1 100.000 (99.616)	Training Prec@5 100.000 (99.880)	
2022-03-26 18:07:21,225: ============================================================
2022-03-26 18:08:39,135: time cost, forward:0.0222805577690671, backward:0.04941240431261616, data cost:0.7176723623333 
2022-03-26 18:08:39,136: ============================================================
2022-03-26 18:08:39,137: Epoch 12/38 Batch 2500/7662 eta: 1 day, 20:13:52.001813	Training Loss 2.9231 (2.8142)	Training Prec@1 100.000 (99.615)	Training Prec@5 100.000 (99.880)	
2022-03-26 18:08:39,137: ============================================================
2022-03-26 18:10:00,215: time cost, forward:0.022300944047599813, backward:0.04948178187110141, data cost:0.718344731989527 
2022-03-26 18:10:00,215: ============================================================
2022-03-26 18:10:00,215: Epoch 12/38 Batch 2600/7662 eta: 1 day, 22:00:23.240848	Training Loss 2.7982 (2.8200)	Training Prec@1 99.414 (99.609)	Training Prec@5 99.609 (99.879)	
2022-03-26 18:10:00,215: ============================================================
2022-03-26 18:11:20,515: time cost, forward:0.02234480565633982, backward:0.04958740496202591, data cost:0.7182494310504112 
2022-03-26 18:11:20,518: ============================================================
2022-03-26 18:11:20,519: Epoch 12/38 Batch 2700/7662 eta: 1 day, 21:32:39.480174	Training Loss 2.7762 (2.8258)	Training Prec@1 99.609 (99.604)	Training Prec@5 100.000 (99.877)	
2022-03-26 18:11:20,520: ============================================================
2022-03-26 18:12:44,138: time cost, forward:0.022396389268559615, backward:0.04945007661871929, data cost:0.7202414008028467 
2022-03-26 18:12:44,138: ============================================================
2022-03-26 18:12:44,139: Epoch 12/38 Batch 2800/7662 eta: 1 day, 23:24:07.313334	Training Loss 2.9995 (2.8310)	Training Prec@1 99.414 (99.598)	Training Prec@5 100.000 (99.875)	
2022-03-26 18:12:44,139: ============================================================
2022-03-26 18:14:00,191: time cost, forward:0.02233849627760288, backward:0.0494379414160032, data cost:0.7191790725165871 
2022-03-26 18:14:00,192: ============================================================
2022-03-26 18:14:00,192: Epoch 12/38 Batch 2900/7662 eta: 1 day, 19:05:29.756898	Training Loss 3.0480 (2.8367)	Training Prec@1 99.609 (99.593)	Training Prec@5 100.000 (99.873)	
2022-03-26 18:14:00,192: ============================================================
2022-03-26 18:15:18,408: time cost, forward:0.02228045264813613, backward:0.049444292099645196, data cost:0.7188750046338587 
2022-03-26 18:15:18,408: ============================================================
2022-03-26 18:15:18,409: Epoch 12/38 Batch 3000/7662 eta: 1 day, 20:17:44.279297	Training Loss 2.9508 (2.8416)	Training Prec@1 100.000 (99.588)	Training Prec@5 100.000 (99.871)	
2022-03-26 18:15:18,409: ============================================================
2022-03-26 18:16:32,647: time cost, forward:0.02225410157382469, backward:0.04952536547864857, data cost:0.717213427185743 
2022-03-26 18:16:32,648: ============================================================
2022-03-26 18:16:32,648: Epoch 12/38 Batch 3100/7662 eta: 1 day, 18:01:21.675309	Training Loss 3.0245 (2.8463)	Training Prec@1 99.219 (99.586)	Training Prec@5 100.000 (99.869)	
2022-03-26 18:16:32,648: ============================================================
2022-03-26 18:17:53,169: time cost, forward:0.022289737905327622, backward:0.04969388874443891, data cost:0.7172737326537046 
2022-03-26 18:17:53,170: ============================================================
2022-03-26 18:17:53,171: Epoch 12/38 Batch 3200/7662 eta: 1 day, 21:33:24.239344	Training Loss 2.8777 (2.8511)	Training Prec@1 99.609 (99.582)	Training Prec@5 100.000 (99.868)	
2022-03-26 18:17:53,171: ============================================================
2022-03-26 18:19:09,308: time cost, forward:0.02229728211630977, backward:0.04957014974517221, data cost:0.7166267794238759 
2022-03-26 18:19:09,309: ============================================================
2022-03-26 18:19:09,309: Epoch 12/38 Batch 3300/7662 eta: 1 day, 19:03:18.242698	Training Loss 2.9228 (2.8554)	Training Prec@1 99.414 (99.579)	Training Prec@5 100.000 (99.867)	
2022-03-26 18:19:09,309: ============================================================
2022-03-26 18:20:28,780: time cost, forward:0.02227891231502074, backward:0.04950602295188982, data cost:0.7166607598060368 
2022-03-26 18:20:28,782: ============================================================
2022-03-26 18:20:28,782: Epoch 12/38 Batch 3400/7662 eta: 1 day, 20:55:08.187012	Training Loss 2.9198 (2.8596)	Training Prec@1 99.609 (99.576)	Training Prec@5 100.000 (99.866)	
2022-03-26 18:20:28,783: ============================================================
2022-03-26 18:21:45,629: time cost, forward:0.022217472746359275, backward:0.04949330622620431, data cost:0.716331893220974 
2022-03-26 18:21:45,630: ============================================================
2022-03-26 18:21:45,630: Epoch 12/38 Batch 3500/7662 eta: 1 day, 19:24:48.987328	Training Loss 2.9000 (2.8634)	Training Prec@1 99.805 (99.573)	Training Prec@5 99.805 (99.865)	
2022-03-26 18:21:45,630: ============================================================
2022-03-26 18:23:05,526: time cost, forward:0.02219334036881939, backward:0.04953868622977259, data cost:0.7164028840914274 
2022-03-26 18:23:05,527: ============================================================
2022-03-26 18:23:05,527: Epoch 12/38 Batch 3600/7662 eta: 1 day, 21:06:50.896364	Training Loss 3.2538 (2.8676)	Training Prec@1 99.414 (99.569)	Training Prec@5 99.805 (99.864)	
2022-03-26 18:23:05,527: ============================================================
2022-03-26 18:24:21,750: time cost, forward:0.022136774086314107, backward:0.049529227607151595, data cost:0.7158703909077558 
2022-03-26 18:24:21,751: ============================================================
2022-03-26 18:24:21,751: Epoch 12/38 Batch 3700/7662 eta: 1 day, 19:01:08.297481	Training Loss 3.1762 (2.8709)	Training Prec@1 99.023 (99.567)	Training Prec@5 99.414 (99.863)	
2022-03-26 18:24:21,751: ============================================================
2022-03-26 18:25:40,227: time cost, forward:0.022176323579656165, backward:0.04965624811775467, data cost:0.7155937461295734 
2022-03-26 18:25:40,228: ============================================================
2022-03-26 18:25:40,228: Epoch 12/38 Batch 3800/7662 eta: 1 day, 20:16:06.923241	Training Loss 2.7604 (2.8740)	Training Prec@1 99.609 (99.563)	Training Prec@5 99.805 (99.862)	
2022-03-26 18:25:40,228: ============================================================
2022-03-26 18:27:03,789: time cost, forward:0.022259182855391326, backward:0.04977574541679435, data cost:0.7165499622621851 
2022-03-26 18:27:03,790: ============================================================
2022-03-26 18:27:03,790: Epoch 12/38 Batch 3900/7662 eta: 1 day, 23:06:50.426888	Training Loss 2.7513 (2.8778)	Training Prec@1 99.219 (99.560)	Training Prec@5 100.000 (99.861)	
2022-03-26 18:27:03,790: ============================================================
2022-03-26 18:28:24,131: time cost, forward:0.022277320733992093, backward:0.049841383273197905, data cost:0.7166778189923114 
2022-03-26 18:28:24,133: ============================================================
2022-03-26 18:28:24,134: Epoch 12/38 Batch 4000/7662 eta: 1 day, 21:16:36.858974	Training Loss 3.1563 (2.8813)	Training Prec@1 99.609 (99.557)	Training Prec@5 99.609 (99.860)	
2022-03-26 18:28:24,135: ============================================================
2022-03-26 18:29:41,617: time cost, forward:0.022276420190759507, backward:0.04983516564221462, data cost:0.7164373860821023 
2022-03-26 18:29:41,617: ============================================================
2022-03-26 18:29:41,618: Epoch 12/38 Batch 4100/7662 eta: 1 day, 19:38:38.232180	Training Loss 3.1908 (2.8850)	Training Prec@1 99.414 (99.555)	Training Prec@5 99.805 (99.859)	
2022-03-26 18:29:41,618: ============================================================
2022-03-26 18:30:59,082: time cost, forward:0.02232406564654836, backward:0.04987996713011911, data cost:0.7159493726388305 
2022-03-26 18:30:59,083: ============================================================
2022-03-26 18:30:59,083: Epoch 12/38 Batch 4200/7662 eta: 1 day, 19:36:42.963653	Training Loss 3.1144 (2.8884)	Training Prec@1 99.219 (99.551)	Training Prec@5 99.609 (99.858)	
2022-03-26 18:30:59,083: ============================================================
2022-03-26 18:32:16,059: time cost, forward:0.0223396572575344, backward:0.04991876394090389, data cost:0.7154314103695536 
2022-03-26 18:32:16,059: ============================================================
2022-03-26 18:32:16,060: Epoch 12/38 Batch 4300/7662 eta: 1 day, 19:18:54.862886	Training Loss 2.8343 (2.8919)	Training Prec@1 99.609 (99.548)	Training Prec@5 100.000 (99.856)	
2022-03-26 18:32:16,060: ============================================================
2022-03-26 18:33:34,850: time cost, forward:0.022392635807229, backward:0.04998324756921489, data cost:0.7150669826868312 
2022-03-26 18:33:34,851: ============================================================
2022-03-26 18:33:34,851: Epoch 12/38 Batch 4400/7662 eta: 1 day, 20:18:53.080156	Training Loss 2.9230 (2.8954)	Training Prec@1 99.805 (99.545)	Training Prec@5 100.000 (99.856)	
2022-03-26 18:33:34,851: ============================================================
2022-03-26 18:34:52,441: time cost, forward:0.022463864659065403, backward:0.050037260875884206, data cost:0.7148552130635353 
2022-03-26 18:34:52,441: ============================================================
2022-03-26 18:34:52,441: Epoch 12/38 Batch 4500/7662 eta: 1 day, 19:37:03.639511	Training Loss 3.1029 (2.8984)	Training Prec@1 99.609 (99.543)	Training Prec@5 99.609 (99.855)	
2022-03-26 18:34:52,442: ============================================================
2022-03-26 18:36:10,029: time cost, forward:0.02250864656626284, backward:0.05007956131148997, data cost:0.714269714372058 
2022-03-26 18:36:10,031: ============================================================
2022-03-26 18:36:10,032: Epoch 12/38 Batch 4600/7662 eta: 1 day, 19:35:45.623241	Training Loss 3.1147 (2.9018)	Training Prec@1 99.805 (99.540)	Training Prec@5 100.000 (99.854)	
2022-03-26 18:36:10,033: ============================================================
2022-03-26 18:37:25,339: time cost, forward:0.022517038066480026, backward:0.05006401141569142, data cost:0.7136926997542559 
2022-03-26 18:37:25,339: ============================================================
2022-03-26 18:37:25,340: Epoch 12/38 Batch 4700/7662 eta: 1 day, 18:17:33.967976	Training Loss 2.9988 (2.9050)	Training Prec@1 98.828 (99.538)	Training Prec@5 99.609 (99.853)	
2022-03-26 18:37:25,340: ============================================================
2022-03-26 18:38:46,244: time cost, forward:0.022580686771116992, backward:0.0500997822839634, data cost:0.7138548616718118 
2022-03-26 18:38:46,245: ============================================================
2022-03-26 18:38:46,246: Epoch 12/38 Batch 4800/7662 eta: 1 day, 21:24:49.752378	Training Loss 3.0504 (2.9075)	Training Prec@1 99.805 (99.535)	Training Prec@5 100.000 (99.852)	
2022-03-26 18:38:46,246: ============================================================
2022-03-26 18:40:03,850: time cost, forward:0.022607941558395607, backward:0.050115222418933625, data cost:0.7137556636204498 
2022-03-26 18:40:03,850: ============================================================
2022-03-26 18:40:03,851: Epoch 12/38 Batch 4900/7662 eta: 1 day, 19:32:23.493339	Training Loss 3.1428 (2.9102)	Training Prec@1 99.414 (99.533)	Training Prec@5 99.805 (99.852)	
2022-03-26 18:40:03,851: ============================================================
2022-03-26 18:41:23,330: time cost, forward:0.022646201040821566, backward:0.05024918748703354, data cost:0.7136455083947393 
2022-03-26 18:41:23,331: ============================================================
2022-03-26 18:41:23,331: Epoch 12/38 Batch 5000/7662 eta: 1 day, 20:34:11.017724	Training Loss 3.0286 (2.9129)	Training Prec@1 98.828 (99.530)	Training Prec@5 99.414 (99.851)	
2022-03-26 18:41:23,331: ============================================================
2022-03-26 18:42:41,069: time cost, forward:0.022721780190446326, backward:0.05024877280014406, data cost:0.713408297897671 
2022-03-26 18:42:41,070: ============================================================
2022-03-26 18:42:41,070: Epoch 12/38 Batch 5100/7662 eta: 1 day, 19:34:17.903496	Training Loss 3.3943 (2.9156)	Training Prec@1 99.219 (99.527)	Training Prec@5 99.609 (99.849)	
2022-03-26 18:42:41,070: ============================================================
2022-03-26 18:43:59,190: time cost, forward:0.02274615761407822, backward:0.05027457603378281, data cost:0.7132315265144104 
2022-03-26 18:43:59,191: ============================================================
2022-03-26 18:43:59,191: Epoch 12/38 Batch 5200/7662 eta: 1 day, 19:45:50.344619	Training Loss 3.1810 (2.9180)	Training Prec@1 99.219 (99.525)	Training Prec@5 99.805 (99.848)	
2022-03-26 18:43:59,191: ============================================================
2022-03-26 18:45:16,659: time cost, forward:0.02278133369117531, backward:0.05033470482438392, data cost:0.7128760189712217 
2022-03-26 18:45:16,660: ============================================================
2022-03-26 18:45:16,660: Epoch 12/38 Batch 5300/7662 eta: 1 day, 19:22:37.960576	Training Loss 3.1608 (2.9204)	Training Prec@1 99.609 (99.522)	Training Prec@5 99.805 (99.847)	
2022-03-26 18:45:16,660: ============================================================
2022-03-26 18:46:34,169: time cost, forward:0.02279888075531622, backward:0.05037917700447977, data cost:0.7125850280228976 
2022-03-26 18:46:34,170: ============================================================
2022-03-26 18:46:34,170: Epoch 12/38 Batch 5400/7662 eta: 1 day, 19:22:43.802311	Training Loss 2.9278 (2.9227)	Training Prec@1 99.805 (99.520)	Training Prec@5 100.000 (99.847)	
2022-03-26 18:46:34,170: ============================================================
2022-03-26 18:47:49,087: time cost, forward:0.022770772393908713, backward:0.05031193614244504, data cost:0.7119825009888661 
2022-03-26 18:47:49,087: ============================================================
2022-03-26 18:47:49,088: Epoch 12/38 Batch 5500/7662 eta: 1 day, 17:54:24.966828	Training Loss 3.2580 (2.9252)	Training Prec@1 99.414 (99.517)	Training Prec@5 99.805 (99.845)	
2022-03-26 18:47:49,088: ============================================================
2022-03-26 18:49:09,245: time cost, forward:0.022835811816660244, backward:0.05036622265616279, data cost:0.7119769741326789 
2022-03-26 18:49:09,245: ============================================================
2022-03-26 18:49:09,246: Epoch 12/38 Batch 5600/7662 eta: 1 day, 20:48:58.204036	Training Loss 2.7989 (2.9275)	Training Prec@1 99.023 (99.516)	Training Prec@5 99.805 (99.845)	
2022-03-26 18:49:09,246: ============================================================
2022-03-26 18:50:25,910: time cost, forward:0.02280114504052246, backward:0.050327528608663186, data cost:0.7117982063822254 
2022-03-26 18:50:25,910: ============================================================
2022-03-26 18:50:25,911: Epoch 12/38 Batch 5700/7662 eta: 1 day, 18:50:30.840533	Training Loss 2.9834 (2.9301)	Training Prec@1 99.414 (99.513)	Training Prec@5 99.805 (99.844)	
2022-03-26 18:50:25,911: ============================================================
2022-03-26 18:51:46,205: time cost, forward:0.02282220788157424, backward:0.050360325308252275, data cost:0.7119039337600915 
2022-03-26 18:51:46,206: ============================================================
2022-03-26 18:51:46,207: Epoch 12/38 Batch 5800/7662 eta: 1 day, 20:50:55.334936	Training Loss 3.1100 (2.9326)	Training Prec@1 99.023 (99.511)	Training Prec@5 99.805 (99.844)	
2022-03-26 18:51:46,208: ============================================================
2022-03-26 18:53:02,271: time cost, forward:0.022832531588706833, backward:0.05037088587357243, data cost:0.7115994166632712 
2022-03-26 18:53:02,274: ============================================================
2022-03-26 18:53:02,274: Epoch 12/38 Batch 5900/7662 eta: 1 day, 18:27:55.799697	Training Loss 3.0461 (2.9350)	Training Prec@1 99.414 (99.509)	Training Prec@5 99.609 (99.843)	
2022-03-26 18:53:02,275: ============================================================
2022-03-26 18:54:21,807: time cost, forward:0.02291200657370965, backward:0.0504029005005829, data cost:0.7114765979504859 
2022-03-26 18:54:21,810: ============================================================
2022-03-26 18:54:21,811: Epoch 12/38 Batch 6000/7662 eta: 1 day, 20:22:49.239825	Training Loss 2.9950 (2.9374)	Training Prec@1 99.023 (99.506)	Training Prec@5 99.609 (99.841)	
2022-03-26 18:54:21,812: ============================================================
2022-03-26 18:55:36,085: time cost, forward:0.022911820925343405, backward:0.05043009954078175, data cost:0.7108445497082186 
2022-03-26 18:55:36,086: ============================================================
2022-03-26 18:55:36,086: Epoch 12/38 Batch 6100/7662 eta: 1 day, 17:25:26.209693	Training Loss 3.0871 (2.9397)	Training Prec@1 99.609 (99.504)	Training Prec@5 100.000 (99.840)	
2022-03-26 18:55:36,086: ============================================================
2022-03-26 18:56:53,143: time cost, forward:0.022869364102630196, backward:0.05041067887552517, data cost:0.7106645964176198 
2022-03-26 18:56:53,143: ============================================================
2022-03-26 18:56:53,144: Epoch 12/38 Batch 6200/7662 eta: 1 day, 18:57:15.701027	Training Loss 2.8395 (2.9420)	Training Prec@1 99.609 (99.502)	Training Prec@5 100.000 (99.839)	
2022-03-26 18:56:53,144: ============================================================
2022-03-26 18:58:12,274: time cost, forward:0.02290417031837581, backward:0.05047782464034218, data cost:0.7105366139019041 
2022-03-26 18:58:12,277: ============================================================
2022-03-26 18:58:12,279: Epoch 12/38 Batch 6300/7662 eta: 1 day, 20:05:23.529440	Training Loss 3.1408 (2.9439)	Training Prec@1 99.219 (99.500)	Training Prec@5 99.609 (99.839)	
2022-03-26 18:58:12,279: ============================================================
2022-03-26 18:59:30,986: time cost, forward:0.022905756783012227, backward:0.05048712843525203, data cost:0.7106711900612398 
2022-03-26 18:59:30,986: ============================================================
2022-03-26 18:59:30,987: Epoch 12/38 Batch 6400/7662 eta: 1 day, 19:49:51.042518	Training Loss 3.1966 (2.9457)	Training Prec@1 99.414 (99.498)	Training Prec@5 99.805 (99.838)	
2022-03-26 18:59:30,987: ============================================================
2022-03-26 19:00:54,680: time cost, forward:0.022972218640713825, backward:0.050531973488827195, data cost:0.7112266657480479 
2022-03-26 19:00:54,683: ============================================================
2022-03-26 19:00:54,684: Epoch 12/38 Batch 6500/7662 eta: 1 day, 22:35:07.680832	Training Loss 3.0618 (2.9477)	Training Prec@1 100.000 (99.496)	Training Prec@5 100.000 (99.837)	
2022-03-26 19:00:54,685: ============================================================
2022-03-26 19:02:10,327: time cost, forward:0.02297088734614775, backward:0.050499361994628164, data cost:0.7109049811365388 
2022-03-26 19:02:10,327: ============================================================
2022-03-26 19:02:10,328: Epoch 12/38 Batch 6600/7662 eta: 1 day, 18:04:55.864012	Training Loss 3.1516 (2.9498)	Training Prec@1 99.219 (99.494)	Training Prec@5 99.805 (99.836)	
2022-03-26 19:02:10,328: ============================================================
2022-03-26 19:03:26,692: time cost, forward:0.022981639512707396, backward:0.05050855285108116, data cost:0.7105716095164314 
2022-03-26 19:03:26,693: ============================================================
2022-03-26 19:03:26,693: Epoch 12/38 Batch 6700/7662 eta: 1 day, 18:27:43.976188	Training Loss 2.9789 (2.9516)	Training Prec@1 99.414 (99.492)	Training Prec@5 99.805 (99.836)	
2022-03-26 19:03:26,693: ============================================================
2022-03-26 19:04:44,401: time cost, forward:0.022989833156823025, backward:0.05051420393858364, data cost:0.7104147593227094 
2022-03-26 19:04:44,402: ============================================================
2022-03-26 19:04:44,402: Epoch 12/38 Batch 6800/7662 eta: 1 day, 19:11:16.251919	Training Loss 2.8219 (2.9537)	Training Prec@1 99.219 (99.490)	Training Prec@5 99.414 (99.835)	
2022-03-26 19:04:44,402: ============================================================
2022-03-26 19:06:03,366: time cost, forward:0.022986114949553854, backward:0.05053922908515891, data cost:0.7103982959074946 
2022-03-26 19:06:03,366: ============================================================
2022-03-26 19:06:03,367: Epoch 12/38 Batch 6900/7662 eta: 1 day, 19:51:50.456918	Training Loss 2.9952 (2.9553)	Training Prec@1 99.414 (99.488)	Training Prec@5 99.609 (99.834)	
2022-03-26 19:06:03,367: ============================================================
2022-03-26 19:07:23,257: time cost, forward:0.023073375318744965, backward:0.05061109612066076, data cost:0.7104198278265521 
2022-03-26 19:07:23,260: ============================================================
2022-03-26 19:07:23,260: Epoch 12/38 Batch 7000/7662 eta: 1 day, 20:21:26.438034	Training Loss 3.1521 (2.9572)	Training Prec@1 99.023 (99.486)	Training Prec@5 100.000 (99.834)	
2022-03-26 19:07:23,260: ============================================================
2022-03-26 19:08:38,678: time cost, forward:0.023074877700397272, backward:0.050618616657066316, data cost:0.7100224571843301 
2022-03-26 19:08:38,679: ============================================================
2022-03-26 19:08:38,679: Epoch 12/38 Batch 7100/7662 eta: 1 day, 17:51:08.663820	Training Loss 3.0459 (2.9588)	Training Prec@1 99.414 (99.484)	Training Prec@5 99.609 (99.833)	
2022-03-26 19:08:38,679: ============================================================
2022-03-26 19:09:56,784: time cost, forward:0.02309628072124767, backward:0.05065598138787213, data cost:0.7097874255060471 
2022-03-26 19:09:56,786: ============================================================
2022-03-26 19:09:56,788: Epoch 12/38 Batch 7200/7662 eta: 1 day, 19:19:21.523534	Training Loss 3.1237 (2.9609)	Training Prec@1 99.805 (99.481)	Training Prec@5 100.000 (99.832)	
2022-03-26 19:09:56,788: ============================================================
2022-03-26 19:11:15,696: time cost, forward:0.023122488888898507, backward:0.05067970285939589, data cost:0.7097680011764423 
2022-03-26 19:11:15,697: ============================================================
2022-03-26 19:11:15,697: Epoch 12/38 Batch 7300/7662 eta: 1 day, 19:44:44.379057	Training Loss 3.0637 (2.9624)	Training Prec@1 98.828 (99.479)	Training Prec@5 99.805 (99.832)	
2022-03-26 19:11:15,697: ============================================================
2022-03-26 19:12:36,324: time cost, forward:0.023157659262028042, backward:0.05071141913478834, data cost:0.7100539636992171 
2022-03-26 19:12:36,325: ============================================================
2022-03-26 19:12:36,325: Epoch 12/38 Batch 7400/7662 eta: 1 day, 20:40:33.004087	Training Loss 2.9483 (2.9642)	Training Prec@1 99.805 (99.478)	Training Prec@5 99.805 (99.831)	
2022-03-26 19:12:36,325: ============================================================
2022-03-26 19:13:50,247: time cost, forward:0.023151077927231933, backward:0.050707634329271244, data cost:0.709493795479595 
2022-03-26 19:13:50,247: ============================================================
2022-03-26 19:13:50,247: Epoch 12/38 Batch 7500/7662 eta: 1 day, 16:56:22.368116	Training Loss 2.9751 (2.9660)	Training Prec@1 99.805 (99.476)	Training Prec@5 100.000 (99.830)	
2022-03-26 19:13:50,247: ============================================================
2022-03-26 19:15:11,029: time cost, forward:0.02314800195810685, backward:0.05070665811673483, data cost:0.7098043915597619 
2022-03-26 19:15:11,029: ============================================================
2022-03-26 19:15:11,030: Epoch 12/38 Batch 7600/7662 eta: 1 day, 20:42:58.981053	Training Loss 3.1296 (2.9677)	Training Prec@1 99.414 (99.474)	Training Prec@5 99.609 (99.830)	
2022-03-26 19:15:11,030: ============================================================
2022-03-26 19:15:59,383: Epoch: 12/38 eta: 1 day, 20:42:08.088187	Training Loss 3.0150 (2.9687)	Training Prec@1 99.609 (99.473)	Training Prec@5 100.000 (99.830)
2022-03-26 19:15:59,383: ============================================================
2022-03-26 19:17:21,926: time cost, forward:0.022156171124390882, backward:0.0495500395996402, data cost:0.7541913239642827 
2022-03-26 19:17:21,927: ============================================================
2022-03-26 19:17:21,927: Epoch 13/38 Batch 100/7662 eta: 1 day, 21:33:24.776863	Training Loss 2.6053 (2.6255)	Training Prec@1 100.000 (99.698)	Training Prec@5 100.000 (99.917)	
2022-03-26 19:17:21,927: ============================================================
2022-03-26 19:18:35,592: time cost, forward:0.019979018062802414, backward:0.04713250644242943, data cost:0.713168323938571 
2022-03-26 19:18:35,593: ============================================================
2022-03-26 19:18:35,594: Epoch 13/38 Batch 200/7662 eta: 1 day, 16:43:26.500187	Training Loss 2.6310 (2.6433)	Training Prec@1 99.609 (99.684)	Training Prec@5 99.805 (99.907)	
2022-03-26 19:18:35,596: ============================================================
2022-03-26 19:19:51,865: time cost, forward:0.019891329832300294, backward:0.04749819028337664, data cost:0.7062370346541389 
2022-03-26 19:19:51,867: ============================================================
2022-03-26 19:19:51,869: Epoch 13/38 Batch 300/7662 eta: 1 day, 18:08:39.713862	Training Loss 2.5939 (2.6513)	Training Prec@1 100.000 (99.687)	Training Prec@5 100.000 (99.905)	
2022-03-26 19:19:51,870: ============================================================
2022-03-26 19:21:03,127: time cost, forward:0.019109939274035002, backward:0.04709996316665994, data cost:0.6918640321956242 
2022-03-26 19:21:03,128: ============================================================
2022-03-26 19:21:03,128: Epoch 13/38 Batch 400/7662 eta: 1 day, 15:21:13.333229	Training Loss 2.6825 (2.6672)	Training Prec@1 99.609 (99.692)	Training Prec@5 99.805 (99.900)	
2022-03-26 19:21:03,128: ============================================================
2022-03-26 19:22:18,847: time cost, forward:0.019309763917942084, backward:0.046847560362729856, data cost:0.6913291084503602 
2022-03-26 19:22:18,847: ============================================================
2022-03-26 19:22:18,847: Epoch 13/38 Batch 500/7662 eta: 1 day, 17:47:44.471687	Training Loss 2.9015 (2.6804)	Training Prec@1 100.000 (99.687)	Training Prec@5 100.000 (99.901)	
2022-03-26 19:22:18,847: ============================================================
2022-03-26 19:23:30,122: time cost, forward:0.018965121302660398, backward:0.045744612141324206, data cost:0.6844152429068029 
2022-03-26 19:23:30,123: ============================================================
2022-03-26 19:23:30,123: Epoch 13/38 Batch 600/7662 eta: 1 day, 15:19:22.788704	Training Loss 2.6911 (2.6960)	Training Prec@1 99.609 (99.683)	Training Prec@5 99.805 (99.899)	
2022-03-26 19:23:30,123: ============================================================
2022-03-26 19:24:43,456: time cost, forward:0.01896188153388333, backward:0.04642851021838973, data cost:0.6806726844525645 
2022-03-26 19:24:43,458: ============================================================
2022-03-26 19:24:43,458: Epoch 13/38 Batch 700/7662 eta: 1 day, 16:26:19.342974	Training Loss 2.7720 (2.7098)	Training Prec@1 99.805 (99.679)	Training Prec@5 100.000 (99.900)	
2022-03-26 19:24:43,459: ============================================================
2022-03-26 19:25:54,602: time cost, forward:0.018947937610898358, backward:0.04618895934132372, data cost:0.6771481526509692 
2022-03-26 19:25:54,602: ============================================================
2022-03-26 19:25:54,603: Epoch 13/38 Batch 800/7662 eta: 1 day, 15:12:40.179495	Training Loss 3.0097 (2.7240)	Training Prec@1 99.609 (99.667)	Training Prec@5 100.000 (99.898)	
2022-03-26 19:25:54,603: ============================================================
2022-03-26 19:27:11,925: time cost, forward:0.019213349455853592, backward:0.04593477259753676, data cost:0.6804119927997186 
2022-03-26 19:27:11,926: ============================================================
2022-03-26 19:27:11,927: Epoch 13/38 Batch 900/7662 eta: 1 day, 18:35:42.892346	Training Loss 2.7281 (2.7342)	Training Prec@1 100.000 (99.665)	Training Prec@5 100.000 (99.895)	
2022-03-26 19:27:11,927: ============================================================
2022-03-26 19:28:26,112: time cost, forward:0.019258893884576717, backward:0.04592412250774639, data cost:0.6799030067684414 
2022-03-26 19:28:26,113: ============================================================
2022-03-26 19:28:26,113: Epoch 13/38 Batch 1000/7662 eta: 1 day, 16:50:47.823763	Training Loss 2.9037 (2.7455)	Training Prec@1 99.805 (99.662)	Training Prec@5 100.000 (99.895)	
2022-03-26 19:28:26,113: ============================================================
2022-03-26 19:29:39,647: time cost, forward:0.019180879905291097, backward:0.04585351436326892, data cost:0.6789168237663595 
2022-03-26 19:29:39,647: ============================================================
2022-03-26 19:29:39,648: Epoch 13/38 Batch 1100/7662 eta: 1 day, 16:28:02.021573	Training Loss 2.6817 (2.7556)	Training Prec@1 99.609 (99.655)	Training Prec@5 100.000 (99.890)	
2022-03-26 19:29:39,648: ============================================================
2022-03-26 19:30:54,138: time cost, forward:0.019110436037841492, backward:0.04565837882378382, data cost:0.6792706363493448 
2022-03-26 19:30:54,139: ============================================================
2022-03-26 19:30:54,139: Epoch 13/38 Batch 1200/7662 eta: 1 day, 16:58:21.689501	Training Loss 2.9693 (2.7635)	Training Prec@1 99.219 (99.651)	Training Prec@5 99.609 (99.889)	
2022-03-26 19:30:54,139: ============================================================
2022-03-26 19:32:04,942: time cost, forward:0.01902312017386468, backward:0.045221532648393424, data cost:0.6768563439792812 
2022-03-26 19:32:04,942: ============================================================
2022-03-26 19:32:04,942: Epoch 13/38 Batch 1300/7662 eta: 1 day, 14:55:29.520047	Training Loss 2.7629 (2.7749)	Training Prec@1 99.805 (99.641)	Training Prec@5 99.805 (99.886)	
2022-03-26 19:32:04,942: ============================================================
2022-03-26 19:33:14,238: time cost, forward:0.01902629120849217, backward:0.04485304224397388, data cost:0.6736460434189007 
2022-03-26 19:33:14,239: ============================================================
2022-03-26 19:33:14,239: Epoch 13/38 Batch 1400/7662 eta: 1 day, 14:04:37.536888	Training Loss 2.7643 (2.7844)	Training Prec@1 99.414 (99.636)	Training Prec@5 99.609 (99.884)	
2022-03-26 19:33:14,239: ============================================================
2022-03-26 19:34:27,578: time cost, forward:0.018964561961188644, backward:0.04470802482722042, data cost:0.6729478032848213 
2022-03-26 19:34:27,579: ============================================================
2022-03-26 19:34:27,580: Epoch 13/38 Batch 1500/7662 eta: 1 day, 16:16:44.148925	Training Loss 2.9823 (2.7923)	Training Prec@1 100.000 (99.633)	Training Prec@5 100.000 (99.883)	
2022-03-26 19:34:27,580: ============================================================
2022-03-26 19:35:40,805: time cost, forward:0.018962708169628188, backward:0.04471434124415185, data cost:0.672977688761336 
2022-03-26 19:35:40,807: ============================================================
2022-03-26 19:35:40,807: Epoch 13/38 Batch 1600/7662 eta: 1 day, 16:11:46.478105	Training Loss 3.0154 (2.8003)	Training Prec@1 99.609 (99.631)	Training Prec@5 100.000 (99.881)	
2022-03-26 19:35:40,808: ============================================================
2022-03-26 19:36:52,705: time cost, forward:0.01891547304661994, backward:0.044666360728245334, data cost:0.6718600528811342 
2022-03-26 19:36:52,708: ============================================================
2022-03-26 19:36:52,709: Epoch 13/38 Batch 1700/7662 eta: 1 day, 15:26:54.633549	Training Loss 3.0422 (2.8088)	Training Prec@1 99.805 (99.625)	Training Prec@5 100.000 (99.880)	
2022-03-26 19:36:52,709: ============================================================
2022-03-26 19:38:03,481: time cost, forward:0.018816956418828874, backward:0.04457483933063399, data cost:0.6703681283158816 
2022-03-26 19:38:03,484: ============================================================
2022-03-26 19:38:03,485: Epoch 13/38 Batch 1800/7662 eta: 1 day, 14:48:40.840423	Training Loss 2.9573 (2.8162)	Training Prec@1 99.414 (99.618)	Training Prec@5 99.805 (99.879)	
2022-03-26 19:38:03,485: ============================================================
2022-03-26 19:39:12,881: time cost, forward:0.018826572062656588, backward:0.04447330858532914, data cost:0.6684023790324343 
2022-03-26 19:39:12,882: ============================================================
2022-03-26 19:39:12,882: Epoch 13/38 Batch 1900/7662 eta: 1 day, 14:02:11.404642	Training Loss 2.6895 (2.8231)	Training Prec@1 99.609 (99.615)	Training Prec@5 100.000 (99.878)	
2022-03-26 19:39:12,883: ============================================================
2022-03-26 19:40:25,197: time cost, forward:0.01886666578433107, backward:0.04476226849100362, data cost:0.6675437477125175 
2022-03-26 19:40:25,198: ============================================================
2022-03-26 19:40:25,198: Epoch 13/38 Batch 2000/7662 eta: 1 day, 15:36:55.580222	Training Loss 2.8022 (2.8294)	Training Prec@1 99.414 (99.611)	Training Prec@5 99.805 (99.877)	
2022-03-26 19:40:25,198: ============================================================
2022-03-26 19:41:38,051: time cost, forward:0.01889773764571671, backward:0.04494732388318749, data cost:0.6667498364341776 
2022-03-26 19:41:38,054: ============================================================
2022-03-26 19:41:38,055: Epoch 13/38 Batch 2100/7662 eta: 1 day, 15:53:29.667445	Training Loss 3.2771 (2.8355)	Training Prec@1 98.828 (99.605)	Training Prec@5 99.023 (99.874)	
2022-03-26 19:41:38,056: ============================================================
2022-03-26 19:42:53,487: time cost, forward:0.01886573559915873, backward:0.045071889292711345, data cost:0.6680626655611573 
2022-03-26 19:42:53,487: ============================================================
2022-03-26 19:42:53,488: Epoch 13/38 Batch 2200/7662 eta: 1 day, 17:16:53.140097	Training Loss 2.8691 (2.8417)	Training Prec@1 99.219 (99.601)	Training Prec@5 99.805 (99.873)	
2022-03-26 19:42:53,488: ============================================================
2022-03-26 19:44:04,650: time cost, forward:0.018934346323896876, backward:0.04507775999453338, data cost:0.6669704294972132 
2022-03-26 19:44:04,651: ============================================================
2022-03-26 19:44:04,651: Epoch 13/38 Batch 2300/7662 eta: 1 day, 14:55:30.147683	Training Loss 2.8114 (2.8474)	Training Prec@1 99.609 (99.597)	Training Prec@5 100.000 (99.872)	
2022-03-26 19:44:04,651: ============================================================
2022-03-26 19:45:18,200: time cost, forward:0.018872643669926657, backward:0.04507869370235111, data cost:0.6671585650084266 
2022-03-26 19:45:18,200: ============================================================
2022-03-26 19:45:18,200: Epoch 13/38 Batch 2400/7662 eta: 1 day, 16:12:34.065212	Training Loss 3.1255 (2.8528)	Training Prec@1 99.414 (99.594)	Training Prec@5 99.805 (99.871)	
2022-03-26 19:45:18,200: ============================================================
2022-03-26 19:46:30,281: time cost, forward:0.018885911584329777, backward:0.04495976504539194, data cost:0.6668001382338519 
2022-03-26 19:46:30,281: ============================================================
2022-03-26 19:46:30,282: Epoch 13/38 Batch 2500/7662 eta: 1 day, 15:23:13.574268	Training Loss 3.0862 (2.8575)	Training Prec@1 99.219 (99.591)	Training Prec@5 99.414 (99.870)	
2022-03-26 19:46:30,282: ============================================================
2022-03-26 19:47:45,655: time cost, forward:0.01884987749655277, backward:0.04510808422181092, data cost:0.6672081278580434 
2022-03-26 19:47:45,655: ============================================================
2022-03-26 19:47:45,656: Epoch 13/38 Batch 2600/7662 eta: 1 day, 17:09:55.236048	Training Loss 2.9629 (2.8626)	Training Prec@1 99.219 (99.589)	Training Prec@5 100.000 (99.869)	
2022-03-26 19:47:45,656: ============================================================
2022-03-26 19:48:56,871: time cost, forward:0.01880621256409596, backward:0.04503662474025572, data cost:0.6668191833291155 
2022-03-26 19:48:56,872: ============================================================
2022-03-26 19:48:56,872: Epoch 13/38 Batch 2700/7662 eta: 1 day, 14:52:29.015428	Training Loss 2.9557 (2.8676)	Training Prec@1 99.219 (99.585)	Training Prec@5 99.805 (99.867)	
2022-03-26 19:48:56,872: ============================================================
2022-03-26 19:50:10,571: time cost, forward:0.01884601336796397, backward:0.04511974299963392, data cost:0.6668511904661636 
2022-03-26 19:50:10,571: ============================================================
2022-03-26 19:50:10,572: Epoch 13/38 Batch 2800/7662 eta: 1 day, 16:12:35.623877	Training Loss 2.8265 (2.8720)	Training Prec@1 99.805 (99.584)	Training Prec@5 100.000 (99.866)	
2022-03-26 19:50:10,572: ============================================================
2022-03-26 19:51:22,109: time cost, forward:0.018916156629974902, backward:0.04517818089393387, data cost:0.6661462188383841 
2022-03-26 19:51:22,109: ============================================================
2022-03-26 19:51:22,110: Epoch 13/38 Batch 2900/7662 eta: 1 day, 15:00:38.394618	Training Loss 2.9594 (2.8773)	Training Prec@1 99.609 (99.580)	Training Prec@5 100.000 (99.865)	
2022-03-26 19:51:22,110: ============================================================
2022-03-26 19:52:36,017: time cost, forward:0.018893129788227343, backward:0.04524818091600805, data cost:0.6662684706458651 
2022-03-26 19:52:36,017: ============================================================
2022-03-26 19:52:36,017: Epoch 13/38 Batch 3000/7662 eta: 1 day, 16:16:55.871350	Training Loss 3.1412 (2.8819)	Training Prec@1 99.219 (99.577)	Training Prec@5 99.609 (99.865)	
2022-03-26 19:52:36,017: ============================================================
2022-03-26 19:53:50,050: time cost, forward:0.018910991795488465, backward:0.04522602625068598, data cost:0.6664790959464384 
2022-03-26 19:53:50,050: ============================================================
2022-03-26 19:53:50,051: Epoch 13/38 Batch 3100/7662 eta: 1 day, 16:19:49.546411	Training Loss 3.1093 (2.8858)	Training Prec@1 99.609 (99.574)	Training Prec@5 100.000 (99.864)	
2022-03-26 19:53:50,051: ============================================================
2022-03-26 19:55:01,242: time cost, forward:0.018854402087188655, backward:0.04519461676194244, data cost:0.6660002731986253 
2022-03-26 19:55:01,242: ============================================================
2022-03-26 19:55:01,242: Epoch 13/38 Batch 3200/7662 eta: 1 day, 14:45:45.435991	Training Loss 2.8936 (2.8898)	Training Prec@1 99.609 (99.570)	Training Prec@5 100.000 (99.862)	
2022-03-26 19:55:01,243: ============================================================
2022-03-26 19:56:15,440: time cost, forward:0.01884051820443377, backward:0.04531497556392118, data cost:0.6661252711678534 
2022-03-26 19:56:15,441: ============================================================
2022-03-26 19:56:15,441: Epoch 13/38 Batch 3300/7662 eta: 1 day, 16:22:43.884042	Training Loss 3.3489 (2.8938)	Training Prec@1 99.023 (99.567)	Training Prec@5 99.805 (99.861)	
2022-03-26 19:56:15,441: ============================================================
2022-03-26 19:57:26,918: time cost, forward:0.01881992617015384, backward:0.0452935250936869, data cost:0.665772459373014 
2022-03-26 19:57:26,918: ============================================================
2022-03-26 19:57:26,918: Epoch 13/38 Batch 3400/7662 eta: 1 day, 14:52:42.639896	Training Loss 3.0177 (2.8982)	Training Prec@1 99.219 (99.563)	Training Prec@5 99.805 (99.859)	
2022-03-26 19:57:26,919: ============================================================
2022-03-26 19:58:41,023: time cost, forward:0.018856034888032846, backward:0.04537978360366058, data cost:0.6659329368169391 
2022-03-26 19:58:41,023: ============================================================
2022-03-26 19:58:41,023: Epoch 13/38 Batch 3500/7662 eta: 1 day, 16:17:13.005300	Training Loss 3.0428 (2.9020)	Training Prec@1 100.000 (99.559)	Training Prec@5 100.000 (99.858)	
2022-03-26 19:58:41,023: ============================================================
2022-03-26 19:59:55,836: time cost, forward:0.018874794882381914, backward:0.04548318719294178, data cost:0.666210023453912 
2022-03-26 19:59:55,837: ============================================================
2022-03-26 19:59:55,837: Epoch 13/38 Batch 3600/7662 eta: 1 day, 16:39:04.873782	Training Loss 3.1091 (2.9058)	Training Prec@1 99.414 (99.554)	Training Prec@5 99.609 (99.856)	
2022-03-26 19:59:55,837: ============================================================
2022-03-26 20:01:10,418: time cost, forward:0.01889480001444944, backward:0.04553872032660541, data cost:0.666375040589039 
2022-03-26 20:01:10,418: ============================================================
2022-03-26 20:01:10,419: Epoch 13/38 Batch 3700/7662 eta: 1 day, 16:30:17.185922	Training Loss 2.8990 (2.9095)	Training Prec@1 99.609 (99.550)	Training Prec@5 99.805 (99.856)	
2022-03-26 20:01:10,419: ============================================================
2022-03-26 20:02:23,529: time cost, forward:0.018912911132687987, backward:0.04552224869162009, data cost:0.6665085955461912 
2022-03-26 20:02:23,529: ============================================================
2022-03-26 20:02:23,530: Epoch 13/38 Batch 3800/7662 eta: 1 day, 15:41:08.281608	Training Loss 3.0973 (2.9133)	Training Prec@1 99.414 (99.547)	Training Prec@5 99.805 (99.855)	
2022-03-26 20:02:23,530: ============================================================
2022-03-26 20:03:34,885: time cost, forward:0.018878809028052158, backward:0.04540904750271191, data cost:0.666146523709724 
2022-03-26 20:03:34,885: ============================================================
2022-03-26 20:03:34,886: Epoch 13/38 Batch 3900/7662 eta: 1 day, 14:42:47.614956	Training Loss 3.0873 (2.9164)	Training Prec@1 99.023 (99.543)	Training Prec@5 99.805 (99.854)	
2022-03-26 20:03:34,886: ============================================================
2022-03-26 20:04:44,847: time cost, forward:0.018843679077537635, backward:0.04534434318304002, data cost:0.665441379931069 
2022-03-26 20:04:44,847: ============================================================
2022-03-26 20:04:44,847: Epoch 13/38 Batch 4000/7662 eta: 1 day, 13:56:13.947046	Training Loss 3.2661 (2.9200)	Training Prec@1 99.219 (99.540)	Training Prec@5 99.414 (99.853)	
2022-03-26 20:04:44,847: ============================================================
2022-03-26 20:05:58,265: time cost, forward:0.01885924597547298, backward:0.04530487347882269, data cost:0.6653529618187165 
2022-03-26 20:05:58,265: ============================================================
2022-03-26 20:05:58,265: Epoch 13/38 Batch 4100/7662 eta: 1 day, 15:47:28.075797	Training Loss 2.8737 (2.9227)	Training Prec@1 100.000 (99.538)	Training Prec@5 100.000 (99.852)	
2022-03-26 20:05:58,265: ============================================================
2022-03-26 20:07:09,796: time cost, forward:0.01881741727923007, backward:0.04526604780500121, data cost:0.6652234065643405 
2022-03-26 20:07:09,796: ============================================================
2022-03-26 20:07:09,796: Epoch 13/38 Batch 4200/7662 eta: 1 day, 14:44:54.480558	Training Loss 3.2286 (2.9257)	Training Prec@1 98.828 (99.534)	Training Prec@5 99.805 (99.851)	
2022-03-26 20:07:09,796: ============================================================
2022-03-26 20:08:22,402: time cost, forward:0.018807900065625927, backward:0.045319403956507104, data cost:0.6650268992148712 
2022-03-26 20:08:22,405: ============================================================
2022-03-26 20:08:22,406: Epoch 13/38 Batch 4300/7662 eta: 1 day, 15:18:45.581379	Training Loss 3.0718 (2.9284)	Training Prec@1 99.609 (99.532)	Training Prec@5 100.000 (99.851)	
2022-03-26 20:08:22,406: ============================================================
2022-03-26 20:09:35,099: time cost, forward:0.01885039862190276, backward:0.04537804529433306, data cost:0.6648632705035494 
2022-03-26 20:09:35,100: ============================================================
2022-03-26 20:09:35,100: Epoch 13/38 Batch 4400/7662 eta: 1 day, 15:20:17.605149	Training Loss 2.9654 (2.9313)	Training Prec@1 99.414 (99.531)	Training Prec@5 99.805 (99.850)	
2022-03-26 20:09:35,100: ============================================================
2022-03-26 20:10:50,230: time cost, forward:0.018868281433756656, backward:0.045392261608146675, data cost:0.6653005939559106 
2022-03-26 20:10:50,231: ============================================================
2022-03-26 20:10:50,231: Epoch 13/38 Batch 4500/7662 eta: 1 day, 16:38:09.666273	Training Loss 3.1259 (2.9340)	Training Prec@1 100.000 (99.530)	Training Prec@5 100.000 (99.849)	
2022-03-26 20:10:50,231: ============================================================
2022-03-26 20:12:02,275: time cost, forward:0.018853321622884594, backward:0.04535955640382677, data cost:0.665085822298465 
2022-03-26 20:12:02,279: ============================================================
2022-03-26 20:12:02,280: Epoch 13/38 Batch 4600/7662 eta: 1 day, 14:56:55.745568	Training Loss 3.0986 (2.9371)	Training Prec@1 99.414 (99.528)	Training Prec@5 99.805 (99.849)	
2022-03-26 20:12:02,281: ============================================================
2022-03-26 20:13:14,763: time cost, forward:0.01884501587712884, backward:0.045274623380516105, data cost:0.665060787765136 
2022-03-26 20:13:14,763: ============================================================
2022-03-26 20:13:14,764: Epoch 13/38 Batch 4700/7662 eta: 1 day, 15:09:51.358899	Training Loss 3.1404 (2.9397)	Training Prec@1 99.609 (99.525)	Training Prec@5 100.000 (99.848)	
2022-03-26 20:13:14,764: ============================================================
2022-03-26 20:14:27,572: time cost, forward:0.018812499311621624, backward:0.045259141703401166, data cost:0.6650302315732046 
2022-03-26 20:14:27,572: ============================================================
2022-03-26 20:14:27,572: Epoch 13/38 Batch 4800/7662 eta: 1 day, 15:19:09.766747	Training Loss 3.0371 (2.9421)	Training Prec@1 99.219 (99.522)	Training Prec@5 99.805 (99.847)	
2022-03-26 20:14:27,573: ============================================================
2022-03-26 20:15:36,368: time cost, forward:0.018775070217293754, backward:0.0452171071350976, data cost:0.6642445406881637 
2022-03-26 20:15:36,368: ============================================================
2022-03-26 20:15:36,369: Epoch 13/38 Batch 4900/7662 eta: 1 day, 13:07:59.943500	Training Loss 3.0449 (2.9444)	Training Prec@1 99.414 (99.520)	Training Prec@5 99.609 (99.846)	
2022-03-26 20:15:36,369: ============================================================
2022-03-26 20:16:49,436: time cost, forward:0.018777591940354624, backward:0.04513858437275834, data cost:0.664190075974103 
2022-03-26 20:16:49,439: ============================================================
2022-03-26 20:16:49,440: Epoch 13/38 Batch 5000/7662 eta: 1 day, 15:25:12.359031	Training Loss 3.0610 (2.9470)	Training Prec@1 99.219 (99.518)	Training Prec@5 99.414 (99.846)	
2022-03-26 20:16:49,440: ============================================================
2022-03-26 20:18:03,751: time cost, forward:0.018783369399117684, backward:0.04520071826978954, data cost:0.6644794390607894 
2022-03-26 20:18:03,753: ============================================================
2022-03-26 20:18:03,753: Epoch 13/38 Batch 5100/7662 eta: 1 day, 16:04:13.557147	Training Loss 3.2306 (2.9496)	Training Prec@1 99.414 (99.515)	Training Prec@5 99.805 (99.844)	
2022-03-26 20:18:03,754: ============================================================
2022-03-26 20:19:19,348: time cost, forward:0.01880686694462727, backward:0.045253266460919844, data cost:0.6648264411413387 
2022-03-26 20:19:19,349: ============================================================
2022-03-26 20:19:19,350: Epoch 13/38 Batch 5200/7662 eta: 1 day, 16:44:27.134065	Training Loss 3.1363 (2.9523)	Training Prec@1 99.219 (99.511)	Training Prec@5 99.805 (99.843)	
2022-03-26 20:19:19,350: ============================================================
2022-03-26 20:20:30,522: time cost, forward:0.01879374849096652, backward:0.045213377280018424, data cost:0.6646377861691007 
2022-03-26 20:20:30,522: ============================================================
2022-03-26 20:20:30,522: Epoch 13/38 Batch 5300/7662 eta: 1 day, 14:20:12.034848	Training Loss 3.3541 (2.9543)	Training Prec@1 99.023 (99.509)	Training Prec@5 99.609 (99.842)	
2022-03-26 20:20:30,522: ============================================================
2022-03-26 20:21:44,191: time cost, forward:0.018844430414388127, backward:0.045286492299848095, data cost:0.6646041669631848 
2022-03-26 20:21:44,192: ============================================================
2022-03-26 20:21:44,192: Epoch 13/38 Batch 5400/7662 eta: 1 day, 15:39:41.739202	Training Loss 3.0946 (2.9565)	Training Prec@1 99.219 (99.507)	Training Prec@5 99.805 (99.842)	
2022-03-26 20:21:44,192: ============================================================
2022-03-26 20:22:55,656: time cost, forward:0.018863949738409026, backward:0.045297961643466646, data cost:0.664285644701902 
2022-03-26 20:22:55,659: ============================================================
2022-03-26 20:22:55,660: Epoch 13/38 Batch 5500/7662 eta: 1 day, 14:27:21.506613	Training Loss 3.2392 (2.9586)	Training Prec@1 99.805 (99.504)	Training Prec@5 99.805 (99.841)	
2022-03-26 20:22:55,660: ============================================================
2022-03-26 20:24:08,150: time cost, forward:0.01884902253877395, backward:0.04528782763296333, data cost:0.6641214482378461 
2022-03-26 20:24:08,153: ============================================================
2022-03-26 20:24:08,154: Epoch 13/38 Batch 5600/7662 eta: 1 day, 14:59:17.677042	Training Loss 3.1165 (2.9605)	Training Prec@1 99.414 (99.502)	Training Prec@5 99.609 (99.840)	
2022-03-26 20:24:08,154: ============================================================
2022-03-26 20:25:09,859: time cost, forward:0.01884317615614123, backward:0.04522503779883719, data cost:0.662248538322335 
2022-03-26 20:25:09,860: ============================================================
2022-03-26 20:25:09,860: Epoch 13/38 Batch 5700/7662 eta: 1 day, 9:10:10.665089	Training Loss 3.2461 (2.9624)	Training Prec@1 99.414 (99.500)	Training Prec@5 99.805 (99.839)	
2022-03-26 20:25:09,860: ============================================================
2022-03-26 20:26:15,388: time cost, forward:0.018817972614757355, backward:0.0451418608504136, data cost:0.6611862135747524 
2022-03-26 20:26:15,388: ============================================================
2022-03-26 20:26:15,388: Epoch 13/38 Batch 5800/7662 eta: 1 day, 11:12:20.347808	Training Loss 3.0634 (2.9642)	Training Prec@1 99.219 (99.497)	Training Prec@5 99.609 (99.839)	
2022-03-26 20:26:15,389: ============================================================
2022-03-26 20:27:25,750: time cost, forward:0.018837647147856844, backward:0.04506959279001032, data cost:0.6608168310908104 
2022-03-26 20:27:25,751: ============================================================
2022-03-26 20:27:25,751: Epoch 13/38 Batch 5900/7662 eta: 1 day, 13:46:59.297242	Training Loss 2.9499 (2.9660)	Training Prec@1 99.414 (99.496)	Training Prec@5 100.000 (99.839)	
2022-03-26 20:27:25,751: ============================================================
2022-03-26 20:28:40,980: time cost, forward:0.01883373142858608, backward:0.04511241742741527, data cost:0.6612333058317337 
2022-03-26 20:28:40,980: ============================================================
2022-03-26 20:28:40,980: Epoch 13/38 Batch 6000/7662 eta: 1 day, 16:22:33.494098	Training Loss 2.8921 (2.9678)	Training Prec@1 99.414 (99.493)	Training Prec@5 99.805 (99.838)	
2022-03-26 20:28:40,980: ============================================================
2022-03-26 20:29:50,623: time cost, forward:0.018796596591209542, backward:0.045061244908307964, data cost:0.6608205108217263 
2022-03-26 20:29:50,624: ============================================================
2022-03-26 20:29:50,624: Epoch 13/38 Batch 6100/7662 eta: 1 day, 13:21:30.798280	Training Loss 3.1447 (2.9694)	Training Prec@1 99.219 (99.491)	Training Prec@5 99.805 (99.837)	
2022-03-26 20:29:50,624: ============================================================
2022-03-26 20:31:01,948: time cost, forward:0.01882263398358929, backward:0.04510426875140748, data cost:0.660543288621504 
2022-03-26 20:31:01,948: ============================================================
2022-03-26 20:31:01,949: Epoch 13/38 Batch 6200/7662 eta: 1 day, 14:14:26.128429	Training Loss 3.2257 (2.9714)	Training Prec@1 99.609 (99.489)	Training Prec@5 100.000 (99.837)	
2022-03-26 20:31:01,949: ============================================================
2022-03-26 20:32:14,385: time cost, forward:0.018833493974440098, backward:0.04509461877989114, data cost:0.6604761052347399 
2022-03-26 20:32:14,386: ============================================================
2022-03-26 20:32:14,386: Epoch 13/38 Batch 6300/7662 eta: 1 day, 14:49:00.975384	Training Loss 3.1026 (2.9734)	Training Prec@1 98.438 (99.487)	Training Prec@5 99.609 (99.836)	
2022-03-26 20:32:14,386: ============================================================
2022-03-26 20:33:27,273: time cost, forward:0.018795575065749904, backward:0.04502639667673732, data cost:0.6606095021246821 
2022-03-26 20:33:27,274: ============================================================
2022-03-26 20:33:27,274: Epoch 13/38 Batch 6400/7662 eta: 1 day, 15:02:17.618071	Training Loss 3.1205 (2.9751)	Training Prec@1 99.414 (99.485)	Training Prec@5 99.805 (99.834)	
2022-03-26 20:33:27,274: ============================================================
2022-03-26 20:34:38,408: time cost, forward:0.018771149191714777, backward:0.044992549325121534, data cost:0.6604099488291378 
2022-03-26 20:34:38,409: ============================================================
2022-03-26 20:34:38,410: Epoch 13/38 Batch 6500/7662 eta: 1 day, 14:04:47.090916	Training Loss 2.9977 (2.9767)	Training Prec@1 99.805 (99.484)	Training Prec@5 100.000 (99.834)	
2022-03-26 20:34:38,410: ============================================================
2022-03-26 20:35:52,994: time cost, forward:0.018817876284547713, backward:0.045069016548951006, data cost:0.6606227329850721 
2022-03-26 20:35:52,995: ============================================================
2022-03-26 20:35:52,995: Epoch 13/38 Batch 6600/7662 eta: 1 day, 15:54:21.665778	Training Loss 3.1136 (2.9782)	Training Prec@1 99.219 (99.482)	Training Prec@5 99.805 (99.833)	
2022-03-26 20:35:52,995: ============================================================
2022-03-26 20:37:08,118: time cost, forward:0.018818607008587087, backward:0.045110742019742155, data cost:0.6610055090438289 
2022-03-26 20:37:08,119: ============================================================
2022-03-26 20:37:08,119: Epoch 13/38 Batch 6700/7662 eta: 1 day, 16:10:22.574907	Training Loss 2.8761 (2.9798)	Training Prec@1 99.609 (99.480)	Training Prec@5 100.000 (99.832)	
2022-03-26 20:37:08,119: ============================================================
2022-03-26 20:38:19,480: time cost, forward:0.018817901751594975, backward:0.0451436008069599, data cost:0.6607690912640293 
2022-03-26 20:38:19,480: ============================================================
2022-03-26 20:38:19,480: Epoch 13/38 Batch 6800/7662 eta: 1 day, 14:08:29.002598	Training Loss 2.8379 (2.9811)	Training Prec@1 99.609 (99.479)	Training Prec@5 100.000 (99.832)	
2022-03-26 20:38:19,480: ============================================================
2022-03-26 20:39:33,301: time cost, forward:0.01882144219116087, backward:0.04513259607219129, data cost:0.6609399252342891 
2022-03-26 20:39:33,301: ============================================================
2022-03-26 20:39:33,301: Epoch 13/38 Batch 6900/7662 eta: 1 day, 15:26:07.333153	Training Loss 2.8708 (2.9824)	Training Prec@1 99.219 (99.478)	Training Prec@5 100.000 (99.831)	
2022-03-26 20:39:33,301: ============================================================
2022-03-26 20:40:44,091: time cost, forward:0.018835115098905557, backward:0.045142198770552776, data cost:0.6606610512832247 
2022-03-26 20:40:44,091: ============================================================
2022-03-26 20:40:44,091: Epoch 13/38 Batch 7000/7662 eta: 1 day, 13:47:47.538174	Training Loss 3.0578 (2.9836)	Training Prec@1 99.805 (99.476)	Training Prec@5 100.000 (99.830)	
2022-03-26 20:40:44,091: ============================================================
2022-03-26 20:41:53,784: time cost, forward:0.018834748827650405, backward:0.045110471753406434, data cost:0.6602578521161067 
2022-03-26 20:41:53,785: ============================================================
2022-03-26 20:41:53,785: Epoch 13/38 Batch 7100/7662 eta: 1 day, 13:11:30.112050	Training Loss 3.1115 (2.9848)	Training Prec@1 99.414 (99.475)	Training Prec@5 100.000 (99.830)	
2022-03-26 20:41:53,785: ============================================================
2022-03-26 20:43:07,718: time cost, forward:0.018836809638672892, backward:0.04512931436511407, data cost:0.6604397493296985 
2022-03-26 20:43:07,719: ============================================================
2022-03-26 20:43:07,719: Epoch 13/38 Batch 7200/7662 eta: 1 day, 15:26:03.645895	Training Loss 3.0160 (2.9861)	Training Prec@1 99.805 (99.473)	Training Prec@5 100.000 (99.829)	
2022-03-26 20:43:07,719: ============================================================
2022-03-26 20:44:20,542: time cost, forward:0.01885677501099912, backward:0.04516190439891384, data cost:0.6604166711613093 
2022-03-26 20:44:20,542: ============================================================
2022-03-26 20:44:20,543: Epoch 13/38 Batch 7300/7662 eta: 1 day, 14:49:17.912103	Training Loss 3.0720 (2.9873)	Training Prec@1 99.023 (99.471)	Training Prec@5 99.805 (99.829)	
2022-03-26 20:44:20,543: ============================================================
2022-03-26 20:45:32,435: time cost, forward:0.018837648688949337, backward:0.045196224667120824, data cost:0.6601961141406628 
2022-03-26 20:45:32,438: ============================================================
2022-03-26 20:45:32,439: Epoch 13/38 Batch 7400/7662 eta: 1 day, 14:18:25.576133	Training Loss 3.2061 (2.9888)	Training Prec@1 98.633 (99.469)	Training Prec@5 99.414 (99.828)	
2022-03-26 20:45:32,439: ============================================================
2022-03-26 20:46:43,119: time cost, forward:0.018807622015770315, backward:0.045180760251472656, data cost:0.6600864052152551 
2022-03-26 20:46:43,119: ============================================================
2022-03-26 20:46:43,119: Epoch 13/38 Batch 7500/7662 eta: 1 day, 13:38:24.352420	Training Loss 3.0155 (2.9901)	Training Prec@1 98.828 (99.468)	Training Prec@5 99.219 (99.828)	
2022-03-26 20:46:43,120: ============================================================
2022-03-26 20:47:54,376: time cost, forward:0.018820406841845837, backward:0.04516990772437572, data cost:0.6598105407071782 
2022-03-26 20:47:54,378: ============================================================
2022-03-26 20:47:54,379: Epoch 13/38 Batch 7600/7662 eta: 1 day, 13:55:41.219067	Training Loss 3.1539 (2.9915)	Training Prec@1 99.414 (99.466)	Training Prec@5 99.805 (99.827)	
2022-03-26 20:47:54,379: ============================================================
2022-03-26 20:48:41,867: Epoch: 13/38 eta: 1 day, 13:54:56.325992	Training Loss 3.1865 (2.9925)	Training Prec@1 99.805 (99.464)	Training Prec@5 100.000 (99.826)
2022-03-26 20:48:41,867: ============================================================
2022-03-26 20:49:55,217: time cost, forward:0.01805477190499354, backward:0.042791089626273725, data cost:0.6739496847595832 
2022-03-26 20:49:55,217: ============================================================
2022-03-26 20:49:55,218: Epoch 14/38 Batch 100/7662 eta: 1 day, 15:00:14.192362	Training Loss 2.7745 (2.6262)	Training Prec@1 99.609 (99.716)	Training Prec@5 99.805 (99.913)	
2022-03-26 20:49:55,218: ============================================================
2022-03-26 20:51:06,825: time cost, forward:0.018640860840303815, backward:0.04277682783615649, data cost:0.6625766861977889 
2022-03-26 20:51:06,825: ============================================================
2022-03-26 20:51:06,825: Epoch 14/38 Batch 200/7662 eta: 1 day, 14:03:42.140111	Training Loss 2.5388 (2.6425)	Training Prec@1 99.219 (99.696)	Training Prec@5 100.000 (99.905)	
2022-03-26 20:51:06,826: ============================================================
2022-03-26 20:52:20,656: time cost, forward:0.020117946293043053, backward:0.04571829990399721, data cost:0.6620944088518022 
2022-03-26 20:52:20,657: ============================================================
2022-03-26 20:52:20,657: Epoch 14/38 Batch 300/7662 eta: 1 day, 15:13:24.172974	Training Loss 2.9425 (2.6618)	Training Prec@1 99.219 (99.681)	Training Prec@5 99.609 (99.894)	
2022-03-26 20:52:20,658: ============================================================
2022-03-26 20:53:35,832: time cost, forward:0.02042355872037118, backward:0.04700954695393268, data cost:0.6645221489115167 
2022-03-26 20:53:35,836: ============================================================
2022-03-26 20:53:35,836: Epoch 14/38 Batch 400/7662 eta: 1 day, 15:55:04.682740	Training Loss 2.5924 (2.6717)	Training Prec@1 99.219 (99.670)	Training Prec@5 99.805 (99.892)	
2022-03-26 20:53:35,837: ============================================================
2022-03-26 20:54:51,372: time cost, forward:0.020616244696424098, backward:0.04686089938054821, data cost:0.6704733624964774 
2022-03-26 20:54:51,372: ============================================================
2022-03-26 20:54:51,372: Epoch 14/38 Batch 500/7662 eta: 1 day, 16:05:13.193021	Training Loss 2.8425 (2.6802)	Training Prec@1 99.805 (99.671)	Training Prec@5 100.000 (99.897)	
2022-03-26 20:54:51,373: ============================================================
2022-03-26 20:56:04,690: time cost, forward:0.021122890641175843, backward:0.04670802301078886, data cost:0.6687841916920148 
2022-03-26 20:56:04,690: ============================================================
2022-03-26 20:56:04,691: Epoch 14/38 Batch 600/7662 eta: 1 day, 14:53:21.645084	Training Loss 2.8182 (2.6940)	Training Prec@1 99.414 (99.669)	Training Prec@5 99.805 (99.897)	
2022-03-26 20:56:04,691: ============================================================
2022-03-26 20:57:17,386: time cost, forward:0.020809640188585537, backward:0.04626173522850986, data cost:0.6674873286562416 
2022-03-26 20:57:17,394: ============================================================
2022-03-26 20:57:17,395: Epoch 14/38 Batch 700/7662 eta: 1 day, 14:32:36.307393	Training Loss 2.9437 (2.7039)	Training Prec@1 99.609 (99.667)	Training Prec@5 99.805 (99.894)	
2022-03-26 20:57:17,396: ============================================================
2022-03-26 20:58:31,618: time cost, forward:0.020784974844196114, backward:0.04642661820365132, data cost:0.6686218145941017 
2022-03-26 20:58:31,619: ============================================================
2022-03-26 20:58:31,619: Epoch 14/38 Batch 800/7662 eta: 1 day, 15:19:44.088669	Training Loss 2.6731 (2.7135)	Training Prec@1 99.609 (99.660)	Training Prec@5 100.000 (99.890)	
2022-03-26 20:58:31,619: ============================================================
2022-03-26 20:59:43,946: time cost, forward:0.02052439200599679, backward:0.04629043185538524, data cost:0.6674382089905532 
2022-03-26 20:59:43,947: ============================================================
2022-03-26 20:59:43,947: Epoch 14/38 Batch 900/7662 eta: 1 day, 14:18:13.576318	Training Loss 2.7531 (2.7259)	Training Prec@1 99.609 (99.657)	Training Prec@5 99.805 (99.889)	
2022-03-26 20:59:43,947: ============================================================
2022-03-26 21:00:57,085: time cost, forward:0.020687555765604472, backward:0.046364298573246705, data cost:0.6659568632925833 
2022-03-26 21:00:57,088: ============================================================
2022-03-26 21:00:57,090: Epoch 14/38 Batch 1000/7662 eta: 1 day, 14:42:52.857320	Training Loss 2.9221 (2.7360)	Training Prec@1 99.219 (99.655)	Training Prec@5 99.805 (99.888)	
2022-03-26 21:00:57,090: ============================================================
2022-03-26 21:02:09,238: time cost, forward:0.02067716583758728, backward:0.04633466019426507, data cost:0.6650362025617577 
2022-03-26 21:02:09,241: ============================================================
2022-03-26 21:02:09,242: Epoch 14/38 Batch 1100/7662 eta: 1 day, 14:10:14.708990	Training Loss 3.0033 (2.7472)	Training Prec@1 99.414 (99.649)	Training Prec@5 100.000 (99.886)	
2022-03-26 21:02:09,242: ============================================================
2022-03-26 21:03:22,981: time cost, forward:0.02092034385242096, backward:0.046500768931932106, data cost:0.6654479628905741 
2022-03-26 21:03:22,981: ============================================================
2022-03-26 21:03:22,982: Epoch 14/38 Batch 1200/7662 eta: 1 day, 14:59:25.382455	Training Loss 2.7034 (2.7553)	Training Prec@1 100.000 (99.645)	Training Prec@5 100.000 (99.885)	
2022-03-26 21:03:22,982: ============================================================
2022-03-26 21:04:37,601: time cost, forward:0.02108501378529984, backward:0.04637285247961313, data cost:0.6658928662286161 
2022-03-26 21:04:37,602: ============================================================
2022-03-26 21:04:37,602: Epoch 14/38 Batch 1300/7662 eta: 1 day, 15:26:06.822325	Training Loss 2.8262 (2.7642)	Training Prec@1 99.609 (99.641)	Training Prec@5 99.805 (99.885)	
2022-03-26 21:04:37,603: ============================================================
2022-03-26 21:05:47,902: time cost, forward:0.021160413061745938, backward:0.046398332239986746, data cost:0.6637274458887238 
2022-03-26 21:05:47,902: ============================================================
2022-03-26 21:05:47,903: Epoch 14/38 Batch 1400/7662 eta: 1 day, 13:07:56.623039	Training Loss 2.8455 (2.7727)	Training Prec@1 99.609 (99.636)	Training Prec@5 99.609 (99.885)	
2022-03-26 21:05:47,903: ============================================================
2022-03-26 21:07:04,106: time cost, forward:0.021262820837416596, backward:0.046751556275605045, data cost:0.6651162622450509 
2022-03-26 21:07:04,106: ============================================================
2022-03-26 21:07:04,106: Epoch 14/38 Batch 1500/7662 eta: 1 day, 16:13:45.889027	Training Loss 2.6915 (2.7812)	Training Prec@1 100.000 (99.631)	Training Prec@5 100.000 (99.884)	
2022-03-26 21:07:04,107: ============================================================
2022-03-26 21:08:14,971: time cost, forward:0.021162367672231362, backward:0.04675795958890551, data cost:0.6635877163131361 
2022-03-26 21:08:14,972: ============================================================
2022-03-26 21:08:14,972: Epoch 14/38 Batch 1600/7662 eta: 1 day, 13:23:30.054644	Training Loss 3.3110 (2.7899)	Training Prec@1 98.633 (99.629)	Training Prec@5 99.805 (99.883)	
2022-03-26 21:08:14,972: ============================================================
2022-03-26 21:09:28,977: time cost, forward:0.020965274886007235, backward:0.04667910356392504, data cost:0.6638729499325182 
2022-03-26 21:09:28,978: ============================================================
2022-03-26 21:09:28,979: Epoch 14/38 Batch 1700/7662 eta: 1 day, 15:01:42.912278	Training Loss 2.7709 (2.7974)	Training Prec@1 99.805 (99.625)	Training Prec@5 99.805 (99.883)	
2022-03-26 21:09:28,980: ============================================================
2022-03-26 21:10:42,229: time cost, forward:0.0211134313410557, backward:0.046673092463070845, data cost:0.6641326768322744 
2022-03-26 21:10:42,229: ============================================================
2022-03-26 21:10:42,230: Epoch 14/38 Batch 1800/7662 eta: 1 day, 14:36:33.738956	Training Loss 2.8838 (2.8031)	Training Prec@1 99.609 (99.622)	Training Prec@5 99.609 (99.882)	
2022-03-26 21:10:42,230: ============================================================
2022-03-26 21:11:56,147: time cost, forward:0.0210106357767307, backward:0.04657724683318658, data cost:0.6646381158964328 
2022-03-26 21:11:56,148: ============================================================
2022-03-26 21:11:56,149: Epoch 14/38 Batch 1900/7662 eta: 1 day, 14:56:28.167284	Training Loss 3.0221 (2.8102)	Training Prec@1 99.609 (99.618)	Training Prec@5 100.000 (99.881)	
2022-03-26 21:11:56,149: ============================================================
2022-03-26 21:13:08,142: time cost, forward:0.021024053009704925, backward:0.046405055750722346, data cost:0.6641247787733207 
2022-03-26 21:13:08,145: ============================================================
2022-03-26 21:13:08,146: Epoch 14/38 Batch 2000/7662 eta: 1 day, 13:54:30.671438	Training Loss 2.9521 (2.8164)	Training Prec@1 99.219 (99.611)	Training Prec@5 100.000 (99.880)	
2022-03-26 21:13:08,146: ============================================================
2022-03-26 21:14:23,341: time cost, forward:0.021084967995326026, backward:0.04654160222875441, data cost:0.6647825996440726 
2022-03-26 21:14:23,342: ============================================================
2022-03-26 21:14:23,342: Epoch 14/38 Batch 2100/7662 eta: 1 day, 15:34:21.256680	Training Loss 2.8651 (2.8225)	Training Prec@1 99.805 (99.610)	Training Prec@5 100.000 (99.880)	
2022-03-26 21:14:23,343: ============================================================
2022-03-26 21:15:34,878: time cost, forward:0.02106546867755718, backward:0.046425327489244876, data cost:0.6640685215057054 
2022-03-26 21:15:34,879: ============================================================
2022-03-26 21:15:34,879: Epoch 14/38 Batch 2200/7662 eta: 1 day, 13:37:34.897492	Training Loss 2.7678 (2.8281)	Training Prec@1 99.805 (99.607)	Training Prec@5 100.000 (99.878)	
2022-03-26 21:15:34,879: ============================================================
2022-03-26 21:16:46,999: time cost, forward:0.021005901371514916, backward:0.04633700355025362, data cost:0.6636948881070476 
2022-03-26 21:16:47,000: ============================================================
2022-03-26 21:16:47,000: Epoch 14/38 Batch 2300/7662 eta: 1 day, 13:54:49.833378	Training Loss 2.8574 (2.8335)	Training Prec@1 99.609 (99.602)	Training Prec@5 99.805 (99.876)	
2022-03-26 21:16:47,000: ============================================================
2022-03-26 21:17:57,338: time cost, forward:0.020937099512441302, backward:0.04633401194529118, data cost:0.6624325409985026 
2022-03-26 21:17:57,340: ============================================================
2022-03-26 21:17:57,341: Epoch 14/38 Batch 2400/7662 eta: 1 day, 12:57:30.273031	Training Loss 3.1629 (2.8392)	Training Prec@1 98.828 (99.599)	Training Prec@5 99.609 (99.875)	
2022-03-26 21:17:57,341: ============================================================
2022-03-26 21:19:10,530: time cost, forward:0.02094900813184771, backward:0.046422209726328274, data cost:0.662149897762755 
2022-03-26 21:19:10,530: ============================================================
2022-03-26 21:19:10,530: Epoch 14/38 Batch 2500/7662 eta: 1 day, 14:26:05.781108	Training Loss 2.8706 (2.8442)	Training Prec@1 99.805 (99.598)	Training Prec@5 100.000 (99.874)	
2022-03-26 21:19:10,531: ============================================================
2022-03-26 21:20:20,601: time cost, forward:0.02089559568630452, backward:0.04641740933983727, data cost:0.6613455298498255 
2022-03-26 21:20:20,602: ============================================================
2022-03-26 21:20:20,602: Epoch 14/38 Batch 2600/7662 eta: 1 day, 12:46:40.787470	Training Loss 3.0832 (2.8494)	Training Prec@1 98.633 (99.594)	Training Prec@5 99.609 (99.873)	
2022-03-26 21:20:20,602: ============================================================
2022-03-26 21:21:33,720: time cost, forward:0.020879830462528892, backward:0.04639431740363999, data cost:0.6614239992323342 
2022-03-26 21:21:33,720: ============================================================
2022-03-26 21:21:33,721: Epoch 14/38 Batch 2700/7662 eta: 1 day, 14:21:25.719923	Training Loss 2.9011 (2.8540)	Training Prec@1 99.609 (99.589)	Training Prec@5 99.609 (99.870)	
2022-03-26 21:21:33,721: ============================================================
2022-03-26 21:22:44,999: time cost, forward:0.020865029290387697, backward:0.04624423660436414, data cost:0.6609514296246495 
2022-03-26 21:22:45,000: ============================================================
2022-03-26 21:22:45,000: Epoch 14/38 Batch 2800/7662 eta: 1 day, 13:22:20.285741	Training Loss 3.0319 (2.8584)	Training Prec@1 99.609 (99.587)	Training Prec@5 100.000 (99.870)	
2022-03-26 21:22:45,000: ============================================================
2022-03-26 21:24:02,928: time cost, forward:0.020924555675536857, backward:0.04628460552824822, data cost:0.6625480147714079 
2022-03-26 21:24:02,929: ============================================================
2022-03-26 21:24:02,929: Epoch 14/38 Batch 2900/7662 eta: 1 day, 16:50:14.255448	Training Loss 3.0809 (2.8636)	Training Prec@1 99.023 (99.583)	Training Prec@5 99.805 (99.868)	
2022-03-26 21:24:02,929: ============================================================
2022-03-26 21:25:12,349: time cost, forward:0.0208503433607864, backward:0.04614364834537742, data cost:0.6613524988040244 
2022-03-26 21:25:12,350: ============================================================
2022-03-26 21:25:12,351: Epoch 14/38 Batch 3000/7662 eta: 1 day, 12:21:34.672120	Training Loss 2.8673 (2.8673)	Training Prec@1 99.023 (99.579)	Training Prec@5 99.414 (99.868)	
2022-03-26 21:25:12,351: ============================================================
2022-03-26 21:26:22,600: time cost, forward:0.0207723946523651, backward:0.04595151913862299, data cost:0.6607159365758314 
2022-03-26 21:26:22,603: ============================================================
2022-03-26 21:26:22,603: Epoch 14/38 Batch 3100/7662 eta: 1 day, 12:46:30.969168	Training Loss 2.9481 (2.8713)	Training Prec@1 99.805 (99.575)	Training Prec@5 100.000 (99.867)	
2022-03-26 21:26:22,603: ============================================================
2022-03-26 21:27:33,848: time cost, forward:0.020750784583298928, backward:0.046025670293943326, data cost:0.6602607642385728 
2022-03-26 21:27:33,848: ============================================================
2022-03-26 21:27:33,849: Epoch 14/38 Batch 3200/7662 eta: 1 day, 13:16:31.931604	Training Loss 2.9243 (2.8744)	Training Prec@1 99.805 (99.574)	Training Prec@5 100.000 (99.867)	
2022-03-26 21:27:33,849: ============================================================
2022-03-26 21:28:45,053: time cost, forward:0.020747706614757676, backward:0.04602187588273413, data cost:0.6596012969709375 
2022-03-26 21:28:45,057: ============================================================
2022-03-26 21:28:45,058: Epoch 14/38 Batch 3300/7662 eta: 1 day, 13:14:11.409291	Training Loss 3.0117 (2.8788)	Training Prec@1 98.828 (99.570)	Training Prec@5 99.609 (99.866)	
2022-03-26 21:28:45,058: ============================================================
2022-03-26 21:29:57,970: time cost, forward:0.020767364827420087, backward:0.04591428633822031, data cost:0.6597976866944042 
2022-03-26 21:29:57,971: ============================================================
2022-03-26 21:29:57,971: Epoch 14/38 Batch 3400/7662 eta: 1 day, 14:06:27.600636	Training Loss 2.7922 (2.8826)	Training Prec@1 99.414 (99.566)	Training Prec@5 100.000 (99.864)	
2022-03-26 21:29:57,971: ============================================================
2022-03-26 21:31:08,720: time cost, forward:0.020820020982012404, backward:0.04592983339063847, data cost:0.6590627841044576 
2022-03-26 21:31:08,722: ============================================================
2022-03-26 21:31:08,722: Epoch 14/38 Batch 3500/7662 eta: 1 day, 12:57:28.132349	Training Loss 2.9462 (2.8863)	Training Prec@1 99.609 (99.563)	Training Prec@5 100.000 (99.864)	
2022-03-26 21:31:08,723: ============================================================
2022-03-26 21:32:19,884: time cost, forward:0.020782582459763773, backward:0.045914295614676595, data cost:0.6588626917483708 
2022-03-26 21:32:19,887: ============================================================
2022-03-26 21:32:19,888: Epoch 14/38 Batch 3600/7662 eta: 1 day, 13:09:15.711764	Training Loss 2.9820 (2.8899)	Training Prec@1 98.828 (99.561)	Training Prec@5 99.609 (99.864)	
2022-03-26 21:32:19,889: ============================================================
2022-03-26 21:33:34,248: time cost, forward:0.020832400284576624, backward:0.045937026504182465, data cost:0.6591751277688452 
2022-03-26 21:33:34,249: ============================================================
2022-03-26 21:33:34,249: Epoch 14/38 Batch 3700/7662 eta: 1 day, 14:48:08.988468	Training Loss 2.9389 (2.8925)	Training Prec@1 99.805 (99.558)	Training Prec@5 100.000 (99.862)	
2022-03-26 21:33:34,249: ============================================================
2022-03-26 21:34:43,989: time cost, forward:0.020840751650961616, backward:0.04596785395733461, data cost:0.6584087948825492 
2022-03-26 21:34:43,990: ============================================================
2022-03-26 21:34:43,990: Epoch 14/38 Batch 3800/7662 eta: 1 day, 12:22:19.139202	Training Loss 2.8670 (2.8958)	Training Prec@1 99.609 (99.555)	Training Prec@5 99.805 (99.861)	
2022-03-26 21:34:43,990: ============================================================
2022-03-26 21:35:55,578: time cost, forward:0.020818631567689632, backward:0.04589637770778737, data cost:0.6582249880876563 
2022-03-26 21:35:55,578: ============================================================
2022-03-26 21:35:55,579: Epoch 14/38 Batch 3900/7662 eta: 1 day, 13:18:56.921385	Training Loss 3.0954 (2.8986)	Training Prec@1 99.805 (99.552)	Training Prec@5 99.805 (99.861)	
2022-03-26 21:35:55,579: ============================================================
2022-03-26 21:37:06,874: time cost, forward:0.02081668934365397, backward:0.04592209781638143, data cost:0.6578678404518771 
2022-03-26 21:37:06,874: ============================================================
2022-03-26 21:37:06,874: Epoch 14/38 Batch 4000/7662 eta: 1 day, 13:08:35.987592	Training Loss 3.0499 (2.9017)	Training Prec@1 99.414 (99.550)	Training Prec@5 99.609 (99.859)	
2022-03-26 21:37:06,875: ============================================================
2022-03-26 21:38:17,355: time cost, forward:0.020782135556051864, backward:0.045917061952068385, data cost:0.657187277935109 
2022-03-26 21:38:17,358: ============================================================
2022-03-26 21:38:17,358: Epoch 14/38 Batch 4100/7662 eta: 1 day, 12:42:01.730179	Training Loss 3.2453 (2.9051)	Training Prec@1 98.828 (99.547)	Training Prec@5 99.414 (99.859)	
2022-03-26 21:38:17,358: ============================================================
2022-03-26 21:39:28,694: time cost, forward:0.020775403542642394, backward:0.04585955068593253, data cost:0.6571312155658843 
2022-03-26 21:39:28,695: ============================================================
2022-03-26 21:39:28,696: Epoch 14/38 Batch 4200/7662 eta: 1 day, 13:07:31.838286	Training Loss 3.1635 (2.9082)	Training Prec@1 99.414 (99.545)	Training Prec@5 99.609 (99.859)	
2022-03-26 21:39:28,696: ============================================================
2022-03-26 21:40:40,345: time cost, forward:0.020727322417155174, backward:0.045886344592442035, data cost:0.656789262063505 
2022-03-26 21:40:40,346: ============================================================
2022-03-26 21:40:40,347: Epoch 14/38 Batch 4300/7662 eta: 1 day, 13:16:08.280601	Training Loss 3.1059 (2.9113)	Training Prec@1 99.414 (99.542)	Training Prec@5 99.805 (99.858)	
2022-03-26 21:40:40,348: ============================================================
2022-03-26 21:41:48,898: time cost, forward:0.020652227440756215, backward:0.04580931664597151, data cost:0.6562284678051379 
2022-03-26 21:41:48,898: ============================================================
2022-03-26 21:41:48,899: Epoch 14/38 Batch 4400/7662 eta: 1 day, 11:38:15.108396	Training Loss 3.0862 (2.9145)	Training Prec@1 99.219 (99.539)	Training Prec@5 99.805 (99.858)	
2022-03-26 21:41:48,899: ============================================================
2022-03-26 21:43:03,377: time cost, forward:0.020617070529799535, backward:0.04574755823169716, data cost:0.6566536001534853 
2022-03-26 21:43:03,377: ============================================================
2022-03-26 21:43:03,377: Epoch 14/38 Batch 4500/7662 eta: 1 day, 14:41:53.274294	Training Loss 2.7806 (2.9173)	Training Prec@1 99.609 (99.536)	Training Prec@5 99.805 (99.857)	
2022-03-26 21:43:03,378: ============================================================
2022-03-26 21:44:09,413: time cost, forward:0.02052839944403595, backward:0.04565940719242847, data cost:0.6553811708671369 
2022-03-26 21:44:09,415: ============================================================
2022-03-26 21:44:09,416: Epoch 14/38 Batch 4600/7662 eta: 1 day, 10:17:38.373525	Training Loss 3.1277 (2.9196)	Training Prec@1 98.438 (99.533)	Training Prec@5 99.805 (99.856)	
2022-03-26 21:44:09,417: ============================================================
2022-03-26 21:45:19,947: time cost, forward:0.020516495675222752, backward:0.04568067883704413, data cost:0.6551567316308988 
2022-03-26 21:45:19,947: ============================================================
2022-03-26 21:45:19,947: Epoch 14/38 Batch 4700/7662 eta: 1 day, 12:36:29.906035	Training Loss 3.2986 (2.9222)	Training Prec@1 99.219 (99.529)	Training Prec@5 99.805 (99.854)	
2022-03-26 21:45:19,948: ============================================================
2022-03-26 21:46:29,618: time cost, forward:0.020535909277519897, backward:0.04570226888901046, data cost:0.6545465253347853 
2022-03-26 21:46:29,618: ============================================================
2022-03-26 21:46:29,619: Epoch 14/38 Batch 4800/7662 eta: 1 day, 12:08:32.172146	Training Loss 3.0428 (2.9245)	Training Prec@1 99.023 (99.526)	Training Prec@5 99.414 (99.852)	
2022-03-26 21:46:29,619: ============================================================
2022-03-26 21:47:41,197: time cost, forward:0.02053993671469407, backward:0.0456918123961225, data cost:0.6542497376661734 
2022-03-26 21:47:41,198: ============================================================
2022-03-26 21:47:41,199: Epoch 14/38 Batch 4900/7662 eta: 1 day, 13:06:44.157748	Training Loss 3.0051 (2.9268)	Training Prec@1 98.828 (99.523)	Training Prec@5 99.219 (99.851)	
2022-03-26 21:47:41,199: ============================================================
2022-03-26 21:48:53,866: time cost, forward:0.020546029724820086, backward:0.04573670838637027, data cost:0.6544563758370876 
2022-03-26 21:48:53,866: ============================================================
2022-03-26 21:48:53,866: Epoch 14/38 Batch 5000/7662 eta: 1 day, 13:39:22.554630	Training Loss 3.1232 (2.9293)	Training Prec@1 99.219 (99.520)	Training Prec@5 100.000 (99.850)	
2022-03-26 21:48:53,867: ============================================================
2022-03-26 21:50:05,210: time cost, forward:0.020563713871607433, backward:0.045781083470771165, data cost:0.6542203867288168 
2022-03-26 21:50:05,211: ============================================================
2022-03-26 21:50:05,211: Epoch 14/38 Batch 5100/7662 eta: 1 day, 12:57:02.308437	Training Loss 3.0248 (2.9318)	Training Prec@1 99.219 (99.518)	Training Prec@5 99.805 (99.849)	
2022-03-26 21:50:05,211: ============================================================
2022-03-26 21:51:15,965: time cost, forward:0.02058369495658192, backward:0.04580708842342646, data cost:0.6538250416511525 
2022-03-26 21:51:15,966: ============================================================
2022-03-26 21:51:15,966: Epoch 14/38 Batch 5200/7662 eta: 1 day, 12:37:33.281607	Training Loss 2.9208 (2.9341)	Training Prec@1 99.609 (99.516)	Training Prec@5 99.805 (99.848)	
2022-03-26 21:51:15,966: ============================================================
2022-03-26 21:52:29,359: time cost, forward:0.02059221983090912, backward:0.045822418057754326, data cost:0.6540473140530101 
2022-03-26 21:52:29,360: ============================================================
2022-03-26 21:52:29,360: Epoch 14/38 Batch 5300/7662 eta: 1 day, 13:58:16.800598	Training Loss 3.0847 (2.9368)	Training Prec@1 99.805 (99.514)	Training Prec@5 99.805 (99.847)	
2022-03-26 21:52:29,360: ============================================================
2022-03-26 21:53:39,419: time cost, forward:0.020570859575209783, backward:0.04581709746233422, data cost:0.6536147541901782 
2022-03-26 21:53:39,420: ============================================================
2022-03-26 21:53:39,421: Epoch 14/38 Batch 5400/7662 eta: 1 day, 12:13:39.250093	Training Loss 3.0389 (2.9388)	Training Prec@1 99.414 (99.511)	Training Prec@5 99.805 (99.846)	
2022-03-26 21:53:39,422: ============================================================
2022-03-26 21:54:50,111: time cost, forward:0.02058178946243067, backward:0.04579949452673702, data cost:0.6533700153380659 
2022-03-26 21:54:50,112: ============================================================
2022-03-26 21:54:50,112: Epoch 14/38 Batch 5500/7662 eta: 1 day, 12:32:01.194833	Training Loss 3.0613 (2.9405)	Training Prec@1 99.219 (99.509)	Training Prec@5 100.000 (99.845)	
2022-03-26 21:54:50,112: ============================================================
2022-03-26 21:55:59,388: time cost, forward:0.020559535407236505, backward:0.04576744678127359, data cost:0.6529587166802034 
2022-03-26 21:55:59,389: ============================================================
2022-03-26 21:55:59,389: Epoch 14/38 Batch 5600/7662 eta: 1 day, 11:47:01.116791	Training Loss 3.0595 (2.9423)	Training Prec@1 99.805 (99.507)	Training Prec@5 100.000 (99.845)	
2022-03-26 21:55:59,389: ============================================================
2022-03-26 21:57:10,717: time cost, forward:0.020521021826389818, backward:0.045748193005884626, data cost:0.6529122631807958 
2022-03-26 21:57:10,718: ============================================================
2022-03-26 21:57:10,718: Epoch 14/38 Batch 5700/7662 eta: 1 day, 12:49:25.643388	Training Loss 2.8698 (2.9442)	Training Prec@1 99.023 (99.504)	Training Prec@5 100.000 (99.844)	
2022-03-26 21:57:10,718: ============================================================
2022-03-26 21:58:20,362: time cost, forward:0.020524308113707285, backward:0.045683687525507624, data cost:0.6524833977931654 
2022-03-26 21:58:20,362: ============================================================
2022-03-26 21:58:20,363: Epoch 14/38 Batch 5800/7662 eta: 1 day, 11:56:05.723690	Training Loss 3.1351 (2.9461)	Training Prec@1 99.609 (99.503)	Training Prec@5 100.000 (99.844)	
2022-03-26 21:58:20,363: ============================================================
2022-03-26 21:59:27,475: time cost, forward:0.020504156034424015, backward:0.045580248849677686, data cost:0.6517178968244295 
2022-03-26 21:59:27,478: ============================================================
2022-03-26 21:59:27,479: Epoch 14/38 Batch 5900/7662 eta: 1 day, 10:36:40.494609	Training Loss 2.9990 (2.9480)	Training Prec@1 99.609 (99.501)	Training Prec@5 99.805 (99.843)	
2022-03-26 21:59:27,479: ============================================================
2022-03-26 22:00:39,247: time cost, forward:0.020521205710379117, backward:0.04563138309687967, data cost:0.6517373456778497 
2022-03-26 22:00:39,248: ============================================================
2022-03-26 22:00:39,248: Epoch 14/38 Batch 6000/7662 eta: 1 day, 12:59:29.949568	Training Loss 3.0387 (2.9496)	Training Prec@1 99.805 (99.499)	Training Prec@5 100.000 (99.843)	
2022-03-26 22:00:39,248: ============================================================
2022-03-26 22:01:51,144: time cost, forward:0.02050948557374438, backward:0.045619415052407374, data cost:0.6517002449639216 
2022-03-26 22:01:51,145: ============================================================
2022-03-26 22:01:51,145: Epoch 14/38 Batch 6100/7662 eta: 1 day, 13:02:13.440318	Training Loss 3.1204 (2.9515)	Training Prec@1 99.414 (99.498)	Training Prec@5 100.000 (99.842)	
2022-03-26 22:01:51,145: ============================================================
2022-03-26 22:03:02,765: time cost, forward:0.020474079444074193, backward:0.04554864206051015, data cost:0.6518183588731633 
2022-03-26 22:03:02,766: ============================================================
2022-03-26 22:03:02,766: Epoch 14/38 Batch 6200/7662 eta: 1 day, 12:52:30.388288	Training Loss 3.1829 (2.9528)	Training Prec@1 99.805 (99.496)	Training Prec@5 100.000 (99.841)	
2022-03-26 22:03:02,766: ============================================================
2022-03-26 22:04:12,309: time cost, forward:0.020473393509739597, backward:0.04557474107283565, data cost:0.651406317897251 
2022-03-26 22:04:12,310: ============================================================
2022-03-26 22:04:12,310: Epoch 14/38 Batch 6300/7662 eta: 1 day, 11:47:10.688945	Training Loss 3.0334 (2.9540)	Training Prec@1 99.414 (99.495)	Training Prec@5 99.805 (99.841)	
2022-03-26 22:04:12,310: ============================================================
2022-03-26 22:05:22,726: time cost, forward:0.020439308757874385, backward:0.04557357230844451, data cost:0.6512051947248375 
2022-03-26 22:05:22,727: ============================================================
2022-03-26 22:05:22,727: Epoch 14/38 Batch 6400/7662 eta: 1 day, 12:12:58.192072	Training Loss 3.0092 (2.9558)	Training Prec@1 99.219 (99.493)	Training Prec@5 99.609 (99.840)	
2022-03-26 22:05:22,727: ============================================================
2022-03-26 22:06:31,515: time cost, forward:0.020408095570963555, backward:0.045535818102323454, data cost:0.6507600486636217 
2022-03-26 22:06:31,517: ============================================================
2022-03-26 22:06:31,518: Epoch 14/38 Batch 6500/7662 eta: 1 day, 11:21:37.603757	Training Loss 3.1082 (2.9571)	Training Prec@1 98.438 (99.492)	Training Prec@5 99.609 (99.840)	
2022-03-26 22:06:31,519: ============================================================
2022-03-26 22:07:41,898: time cost, forward:0.020411194770837266, backward:0.04551361575056557, data cost:0.6505847541937992 
2022-03-26 22:07:41,899: ============================================================
2022-03-26 22:07:41,899: Epoch 14/38 Batch 6600/7662 eta: 1 day, 12:09:31.095377	Training Loss 3.0093 (2.9585)	Training Prec@1 99.219 (99.490)	Training Prec@5 100.000 (99.839)	
2022-03-26 22:07:41,899: ============================================================
2022-03-26 22:08:55,284: time cost, forward:0.02039007941970791, backward:0.04549733957864933, data cost:0.6507411101341675 
2022-03-26 22:08:55,287: ============================================================
2022-03-26 22:08:55,288: Epoch 14/38 Batch 6700/7662 eta: 1 day, 13:40:59.489795	Training Loss 3.0443 (2.9597)	Training Prec@1 99.023 (99.488)	Training Prec@5 99.609 (99.839)	
2022-03-26 22:08:55,288: ============================================================
2022-03-26 22:10:06,664: time cost, forward:0.020384853141134952, backward:0.045491246550131204, data cost:0.6508144039777398 
2022-03-26 22:10:06,664: ============================================================
2022-03-26 22:10:06,665: Epoch 14/38 Batch 6800/7662 eta: 1 day, 12:37:49.433809	Training Loss 2.9409 (2.9610)	Training Prec@1 99.609 (99.486)	Training Prec@5 99.805 (99.838)	
2022-03-26 22:10:06,665: ============================================================
2022-03-26 22:11:14,195: time cost, forward:0.020365306131562247, backward:0.045448797062559915, data cost:0.6502335891289579 
2022-03-26 22:11:14,196: ============================================================
2022-03-26 22:11:14,196: Epoch 14/38 Batch 6900/7662 eta: 1 day, 10:38:18.070556	Training Loss 2.9482 (2.9620)	Training Prec@1 99.414 (99.485)	Training Prec@5 99.805 (99.837)	
2022-03-26 22:11:14,197: ============================================================
2022-03-26 22:12:25,184: time cost, forward:0.020327327080770362, backward:0.045401794805852394, data cost:0.6501710542288316 
2022-03-26 22:12:25,186: ============================================================
2022-03-26 22:12:25,187: Epoch 14/38 Batch 7000/7662 eta: 1 day, 12:23:32.442955	Training Loss 2.8460 (2.9632)	Training Prec@1 99.219 (99.484)	Training Prec@5 99.805 (99.837)	
2022-03-26 22:12:25,187: ============================================================
2022-03-26 22:13:38,032: time cost, forward:0.020340019891859528, backward:0.045397366582717605, data cost:0.6503677153557115 
2022-03-26 22:13:38,033: ============================================================
2022-03-26 22:13:38,033: Epoch 14/38 Batch 7100/7662 eta: 1 day, 13:19:26.615611	Training Loss 2.8247 (2.9644)	Training Prec@1 99.609 (99.482)	Training Prec@5 100.000 (99.836)	
2022-03-26 22:13:38,033: ============================================================
2022-03-26 22:14:47,176: time cost, forward:0.020312198418215723, backward:0.045331926110022965, data cost:0.6499794993670157 
2022-03-26 22:14:47,177: ============================================================
2022-03-26 22:14:47,177: Epoch 14/38 Batch 7200/7662 eta: 1 day, 11:24:27.637957	Training Loss 2.9257 (2.9658)	Training Prec@1 99.414 (99.479)	Training Prec@5 99.609 (99.835)	
2022-03-26 22:14:47,177: ============================================================
2022-03-26 22:15:57,628: time cost, forward:0.02030130101648287, backward:0.04533569622340309, data cost:0.6499302018454735 
2022-03-26 22:15:57,629: ============================================================
2022-03-26 22:15:57,629: Epoch 14/38 Batch 7300/7662 eta: 1 day, 12:03:28.172574	Training Loss 3.1047 (2.9672)	Training Prec@1 99.609 (99.478)	Training Prec@5 100.000 (99.834)	
2022-03-26 22:15:57,629: ============================================================
2022-03-26 22:17:08,018: time cost, forward:0.020277480432062088, backward:0.04533632401921231, data cost:0.6497728983153039 
2022-03-26 22:17:08,019: ============================================================
2022-03-26 22:17:08,019: Epoch 14/38 Batch 7400/7662 eta: 1 day, 12:00:23.696789	Training Loss 3.0260 (2.9685)	Training Prec@1 99.414 (99.475)	Training Prec@5 100.000 (99.834)	
2022-03-26 22:17:08,019: ============================================================
2022-03-26 22:18:19,146: time cost, forward:0.020282657102896923, backward:0.04536769698184082, data cost:0.649567585179672 
2022-03-26 22:18:19,149: ============================================================
2022-03-26 22:18:19,150: Epoch 14/38 Batch 7500/7662 eta: 1 day, 12:21:56.683243	Training Loss 2.9649 (2.9697)	Training Prec@1 99.609 (99.473)	Training Prec@5 100.000 (99.833)	
2022-03-26 22:18:19,150: ============================================================
2022-03-26 22:19:31,057: time cost, forward:0.02026874496052337, backward:0.04539183752052658, data cost:0.6496842341731137 
2022-03-26 22:19:31,058: ============================================================
2022-03-26 22:19:31,058: Epoch 14/38 Batch 7600/7662 eta: 1 day, 12:44:36.168363	Training Loss 3.0788 (2.9709)	Training Prec@1 99.414 (99.471)	Training Prec@5 99.609 (99.832)	
2022-03-26 22:19:31,058: ============================================================
2022-03-26 22:20:16,889: Epoch: 14/38 eta: 1 day, 12:43:50.866089	Training Loss 3.0049 (2.9716)	Training Prec@1 99.609 (99.470)	Training Prec@5 100.000 (99.832)
2022-03-26 22:20:16,889: ============================================================
2022-03-26 22:21:28,987: time cost, forward:0.01857718795236915, backward:0.03826852278275923, data cost:0.6566484046704841 
2022-03-26 22:21:28,988: ============================================================
2022-03-26 22:21:28,989: Epoch 15/38 Batch 100/7662 eta: 1 day, 12:42:47.309583	Training Loss 2.4662 (2.5909)	Training Prec@1 100.000 (99.706)	Training Prec@5 100.000 (99.903)	
2022-03-26 22:21:28,989: ============================================================
2022-03-26 22:22:39,385: time cost, forward:0.019057797427153467, backward:0.04107608747242683, data cost:0.6500131089483673 
2022-03-26 22:22:39,386: ============================================================
2022-03-26 22:22:39,386: Epoch 15/38 Batch 200/7662 eta: 1 day, 11:55:12.837415	Training Loss 2.6943 (2.6181)	Training Prec@1 100.000 (99.694)	Training Prec@5 100.000 (99.906)	
2022-03-26 22:22:39,386: ============================================================
2022-03-26 22:23:51,146: time cost, forward:0.018517842659583457, backward:0.04089447168203501, data cost:0.6531016013295355 
2022-03-26 22:23:51,149: ============================================================
2022-03-26 22:23:51,149: Epoch 15/38 Batch 300/7662 eta: 1 day, 12:35:48.553451	Training Loss 2.4840 (2.6270)	Training Prec@1 99.805 (99.693)	Training Prec@5 100.000 (99.906)	
2022-03-26 22:23:51,150: ============================================================
2022-03-26 22:25:02,307: time cost, forward:0.018575594837504223, backward:0.040506106570251006, data cost:0.6529240112256884 
2022-03-26 22:25:02,307: ============================================================
2022-03-26 22:25:02,308: Epoch 15/38 Batch 400/7662 eta: 1 day, 12:16:08.454394	Training Loss 2.7129 (2.6411)	Training Prec@1 99.805 (99.686)	Training Prec@5 100.000 (99.903)	
2022-03-26 22:25:02,308: ============================================================
2022-03-26 22:26:14,063: time cost, forward:0.018737359610731474, backward:0.040784758890797954, data cost:0.6523143122334757 
2022-03-26 22:26:14,067: ============================================================
2022-03-26 22:26:14,068: Epoch 15/38 Batch 500/7662 eta: 1 day, 12:33:19.260363	Training Loss 2.8496 (2.6508)	Training Prec@1 100.000 (99.687)	Training Prec@5 100.000 (99.904)	
2022-03-26 22:26:14,069: ============================================================
2022-03-26 22:27:27,742: time cost, forward:0.01889800627362947, backward:0.04097618085514126, data cost:0.6566405204779318 
2022-03-26 22:27:27,742: ============================================================
2022-03-26 22:27:27,742: Epoch 15/38 Batch 600/7662 eta: 1 day, 13:30:37.990621	Training Loss 2.3529 (2.6618)	Training Prec@1 100.000 (99.682)	Training Prec@5 100.000 (99.908)	
2022-03-26 22:27:27,742: ============================================================
2022-03-26 22:28:39,202: time cost, forward:0.018989937499869023, backward:0.04140784709750327, data cost:0.6549078746244461 
2022-03-26 22:28:39,206: ============================================================
2022-03-26 22:28:39,207: Epoch 15/38 Batch 700/7662 eta: 1 day, 12:21:54.856047	Training Loss 2.7199 (2.6720)	Training Prec@1 99.609 (99.683)	Training Prec@5 100.000 (99.907)	
2022-03-26 22:28:39,208: ============================================================
2022-03-26 22:29:49,573: time cost, forward:0.019390962896717056, backward:0.041752357805178074, data cost:0.65293222882124 
2022-03-26 22:29:49,574: ============================================================
2022-03-26 22:29:49,575: Epoch 15/38 Batch 800/7662 eta: 1 day, 11:47:15.840150	Training Loss 2.6922 (2.6830)	Training Prec@1 100.000 (99.678)	Training Prec@5 100.000 (99.910)	
2022-03-26 22:29:49,575: ============================================================
2022-03-26 22:30:59,028: time cost, forward:0.01940782555483605, backward:0.04195778521069961, data cost:0.6504901914097974 
2022-03-26 22:30:59,028: ============================================================
2022-03-26 22:30:59,029: Epoch 15/38 Batch 900/7662 eta: 1 day, 11:18:13.520788	Training Loss 2.7836 (2.6943)	Training Prec@1 99.414 (99.672)	Training Prec@5 99.609 (99.907)	
2022-03-26 22:30:59,029: ============================================================
2022-03-26 22:32:11,542: time cost, forward:0.019324984755721298, backward:0.04219763653653043, data cost:0.6510892735348569 
2022-03-26 22:32:11,546: ============================================================
2022-03-26 22:32:11,547: Epoch 15/38 Batch 1000/7662 eta: 1 day, 12:50:26.077825	Training Loss 2.7886 (2.7028)	Training Prec@1 99.414 (99.670)	Training Prec@5 99.805 (99.903)	
2022-03-26 22:32:11,547: ============================================================
2022-03-26 22:33:24,679: time cost, forward:0.019398720292637193, backward:0.042599603194773905, data cost:0.6522478901114217 
2022-03-26 22:33:24,680: ============================================================
2022-03-26 22:33:24,680: Epoch 15/38 Batch 1100/7662 eta: 1 day, 13:08:01.627322	Training Loss 2.8224 (2.7134)	Training Prec@1 99.805 (99.667)	Training Prec@5 100.000 (99.902)	
2022-03-26 22:33:24,681: ============================================================
2022-03-26 22:34:34,803: time cost, forward:0.019285439649554866, backward:0.042848982544517994, data cost:0.6503850751563447 
2022-03-26 22:34:34,805: ============================================================
2022-03-26 22:34:34,806: Epoch 15/38 Batch 1200/7662 eta: 1 day, 11:35:11.196123	Training Loss 2.8433 (2.7230)	Training Prec@1 99.609 (99.661)	Training Prec@5 100.000 (99.900)	
2022-03-26 22:34:34,807: ============================================================
2022-03-26 22:35:45,816: time cost, forward:0.01932718517047979, backward:0.0429377710020845, data cost:0.6506317306060438 
2022-03-26 22:35:45,816: ============================================================
2022-03-26 22:35:45,817: Epoch 15/38 Batch 1300/7662 eta: 1 day, 12:00:57.911578	Training Loss 2.9455 (2.7335)	Training Prec@1 99.609 (99.659)	Training Prec@5 100.000 (99.897)	
2022-03-26 22:35:45,817: ============================================================
2022-03-26 22:36:56,390: time cost, forward:0.01927650238975105, backward:0.042992819199142836, data cost:0.6498257137350392 
2022-03-26 22:36:56,394: ============================================================
2022-03-26 22:36:56,396: Epoch 15/38 Batch 1400/7662 eta: 1 day, 11:46:37.819668	Training Loss 2.6776 (2.7438)	Training Prec@1 99.805 (99.655)	Training Prec@5 100.000 (99.896)	
2022-03-26 22:36:56,396: ============================================================
2022-03-26 22:38:06,992: time cost, forward:0.01937364593516039, backward:0.04315368408676463, data cost:0.6492226386245208 
2022-03-26 22:38:06,993: ============================================================
2022-03-26 22:38:06,993: Epoch 15/38 Batch 1500/7662 eta: 1 day, 11:46:02.913691	Training Loss 2.7532 (2.7514)	Training Prec@1 99.609 (99.653)	Training Prec@5 99.609 (99.897)	
2022-03-26 22:38:06,993: ============================================================
2022-03-26 22:39:16,734: time cost, forward:0.019273816234548068, backward:0.04334812182199217, data cost:0.6476482262530873 
2022-03-26 22:39:16,737: ============================================================
2022-03-26 22:39:16,738: Epoch 15/38 Batch 1600/7662 eta: 1 day, 11:18:56.154663	Training Loss 2.9873 (2.7596)	Training Prec@1 99.609 (99.651)	Training Prec@5 100.000 (99.895)	
2022-03-26 22:39:16,738: ============================================================
2022-03-26 22:40:27,006: time cost, forward:0.019386012389984043, backward:0.04334123363348931, data cost:0.6474371446168303 
2022-03-26 22:40:27,009: ============================================================
2022-03-26 22:40:27,010: Epoch 15/38 Batch 1700/7662 eta: 1 day, 11:33:47.427662	Training Loss 2.7310 (2.7673)	Training Prec@1 100.000 (99.646)	Training Prec@5 100.000 (99.895)	
2022-03-26 22:40:27,010: ============================================================
2022-03-26 22:41:36,403: time cost, forward:0.019451821758191806, backward:0.043663766531231274, data cost:0.6458527739674863 
2022-03-26 22:41:36,404: ============================================================
2022-03-26 22:41:36,405: Epoch 15/38 Batch 1800/7662 eta: 1 day, 11:06:01.793737	Training Loss 2.9275 (2.7742)	Training Prec@1 99.609 (99.639)	Training Prec@5 100.000 (99.893)	
2022-03-26 22:41:36,405: ============================================================
2022-03-26 22:42:47,847: time cost, forward:0.019545033456401614, backward:0.04378401373109421, data cost:0.6459037337320739 
2022-03-26 22:42:47,848: ============================================================
2022-03-26 22:42:47,848: Epoch 15/38 Batch 1900/7662 eta: 1 day, 12:06:58.881301	Training Loss 2.8735 (2.7816)	Training Prec@1 99.609 (99.636)	Training Prec@5 100.000 (99.891)	
2022-03-26 22:42:47,848: ============================================================
2022-03-26 22:44:01,806: time cost, forward:0.019562125861972736, backward:0.04376604558230043, data cost:0.6474635368469299 
2022-03-26 22:44:01,807: ============================================================
2022-03-26 22:44:01,807: Epoch 15/38 Batch 2000/7662 eta: 1 day, 13:22:02.802183	Training Loss 2.9910 (2.7881)	Training Prec@1 99.023 (99.633)	Training Prec@5 100.000 (99.890)	
2022-03-26 22:44:01,807: ============================================================
2022-03-26 22:45:16,311: time cost, forward:0.019588694906393762, backward:0.0438626960892516, data cost:0.6486890451177749 
2022-03-26 22:45:16,312: ============================================================
2022-03-26 22:45:16,312: Epoch 15/38 Batch 2100/7662 eta: 1 day, 13:37:22.143440	Training Loss 2.9046 (2.7934)	Training Prec@1 99.805 (99.631)	Training Prec@5 100.000 (99.890)	
2022-03-26 22:45:16,312: ============================================================
2022-03-26 22:46:19,484: time cost, forward:0.019485874249751917, backward:0.04365183364916737, data cost:0.6454053861870447 
2022-03-26 22:46:19,484: ============================================================
2022-03-26 22:46:19,484: Epoch 15/38 Batch 2200/7662 eta: 1 day, 7:52:57.531851	Training Loss 3.0685 (2.7985)	Training Prec@1 99.609 (99.628)	Training Prec@5 100.000 (99.888)	
2022-03-26 22:46:19,485: ============================================================
2022-03-26 22:47:28,295: time cost, forward:0.01948377742825409, backward:0.043639853084642195, data cost:0.6441299600049484 
2022-03-26 22:47:28,297: ============================================================
2022-03-26 22:47:28,298: Epoch 15/38 Batch 2300/7662 eta: 1 day, 10:42:37.273611	Training Loss 3.0250 (2.8051)	Training Prec@1 99.219 (99.623)	Training Prec@5 100.000 (99.886)	
2022-03-26 22:47:28,298: ============================================================
2022-03-26 22:48:37,829: time cost, forward:0.019521214257383804, backward:0.04382408365899198, data cost:0.6436907483816843 
2022-03-26 22:48:37,829: ============================================================
2022-03-26 22:48:37,829: Epoch 15/38 Batch 2400/7662 eta: 1 day, 11:03:12.224993	Training Loss 2.9697 (2.8106)	Training Prec@1 99.609 (99.620)	Training Prec@5 99.609 (99.885)	
2022-03-26 22:48:37,830: ============================================================
2022-03-26 22:49:46,073: time cost, forward:0.019479191460672403, backward:0.04383751715407843, data cost:0.6426722047423401 
2022-03-26 22:49:46,073: ============================================================
2022-03-26 22:49:46,073: Epoch 15/38 Batch 2500/7662 eta: 1 day, 10:23:07.248770	Training Loss 2.9540 (2.8159)	Training Prec@1 99.219 (99.616)	Training Prec@5 100.000 (99.884)	
2022-03-26 22:49:46,074: ============================================================
2022-03-26 22:50:55,861: time cost, forward:0.01939012115393386, backward:0.043724638079165865, data cost:0.6423211931586036 
2022-03-26 22:50:55,862: ============================================================
2022-03-26 22:50:55,862: Epoch 15/38 Batch 2600/7662 eta: 1 day, 11:08:39.178181	Training Loss 2.8100 (2.8208)	Training Prec@1 99.414 (99.614)	Training Prec@5 99.805 (99.883)	
2022-03-26 22:50:55,862: ============================================================
2022-03-26 22:52:04,594: time cost, forward:0.01928779512654856, backward:0.043754544157414754, data cost:0.6417561804378152 
2022-03-26 22:52:04,597: ============================================================
2022-03-26 22:52:04,597: Epoch 15/38 Batch 2700/7662 eta: 1 day, 10:35:40.018342	Training Loss 3.1081 (2.8263)	Training Prec@1 99.414 (99.610)	Training Prec@5 99.805 (99.881)	
2022-03-26 22:52:04,598: ============================================================
2022-03-26 22:53:13,212: time cost, forward:0.019246865783942177, backward:0.04370819598106283, data cost:0.641183068386867 
2022-03-26 22:53:13,213: ============================================================
2022-03-26 22:53:13,214: Epoch 15/38 Batch 2800/7662 eta: 1 day, 10:30:56.854927	Training Loss 3.0111 (2.8315)	Training Prec@1 99.414 (99.604)	Training Prec@5 99.805 (99.879)	
2022-03-26 22:53:13,214: ============================================================
2022-03-26 22:54:23,703: time cost, forward:0.019200029600155932, backward:0.043705498526613644, data cost:0.64124360624039 
2022-03-26 22:54:23,704: ============================================================
2022-03-26 22:54:23,704: Epoch 15/38 Batch 2900/7662 eta: 1 day, 11:26:19.786480	Training Loss 2.8343 (2.8360)	Training Prec@1 99.609 (99.601)	Training Prec@5 99.805 (99.877)	
2022-03-26 22:54:23,704: ============================================================
2022-03-26 22:55:37,793: time cost, forward:0.01925835032270685, backward:0.04390934070931867, data cost:0.6421752986450042 
2022-03-26 22:55:37,794: ============================================================
2022-03-26 22:55:37,794: Epoch 15/38 Batch 3000/7662 eta: 1 day, 13:13:40.853586	Training Loss 2.9683 (2.8405)	Training Prec@1 99.805 (99.599)	Training Prec@5 100.000 (99.877)	
2022-03-26 22:55:37,794: ============================================================
2022-03-26 22:56:45,531: time cost, forward:0.019251367437258655, backward:0.04390231529794689, data cost:0.6411939346624905 
2022-03-26 22:56:45,531: ============================================================
2022-03-26 22:56:45,532: Epoch 15/38 Batch 3100/7662 eta: 1 day, 10:01:02.308703	Training Loss 2.9977 (2.8450)	Training Prec@1 99.805 (99.595)	Training Prec@5 100.000 (99.875)	
2022-03-26 22:56:45,532: ============================================================
2022-03-26 22:57:54,777: time cost, forward:0.01918565671717461, backward:0.04382306547901264, data cost:0.640901699555073 
2022-03-26 22:57:54,777: ============================================================
2022-03-26 22:57:54,778: Epoch 15/38 Batch 3200/7662 eta: 1 day, 10:45:19.922696	Training Loss 2.8386 (2.8487)	Training Prec@1 99.805 (99.589)	Training Prec@5 100.000 (99.873)	
2022-03-26 22:57:54,778: ============================================================
2022-03-26 22:59:01,976: time cost, forward:0.019155514677498115, backward:0.04380772387703175, data cost:0.6399710004927354 
2022-03-26 22:59:01,977: ============================================================
2022-03-26 22:59:01,977: Epoch 15/38 Batch 3300/7662 eta: 1 day, 9:42:34.225786	Training Loss 3.1749 (2.8527)	Training Prec@1 99.219 (99.585)	Training Prec@5 99.414 (99.872)	
2022-03-26 22:59:01,977: ============================================================
2022-03-26 23:00:13,198: time cost, forward:0.019167441345376453, backward:0.04386386986373628, data cost:0.6400763451193809 
2022-03-26 23:00:13,198: ============================================================
2022-03-26 23:00:13,199: Epoch 15/38 Batch 3400/7662 eta: 1 day, 11:42:27.361999	Training Loss 2.9643 (2.8564)	Training Prec@1 99.805 (99.582)	Training Prec@5 100.000 (99.871)	
2022-03-26 23:00:13,199: ============================================================
2022-03-26 23:01:22,311: time cost, forward:0.019191377740071208, backward:0.043936359572322004, data cost:0.6394130963535096 
2022-03-26 23:01:22,316: ============================================================
2022-03-26 23:01:22,317: Epoch 15/38 Batch 3500/7662 eta: 1 day, 10:38:00.756849	Training Loss 2.8901 (2.8603)	Training Prec@1 99.609 (99.580)	Training Prec@5 100.000 (99.871)	
2022-03-26 23:01:22,317: ============================================================
2022-03-26 23:02:31,093: time cost, forward:0.019148801160739772, backward:0.04395009809548605, data cost:0.6390061328794665 
2022-03-26 23:02:31,099: ============================================================
2022-03-26 23:02:31,100: Epoch 15/38 Batch 3600/7662 eta: 1 day, 10:26:48.679754	Training Loss 2.9181 (2.8633)	Training Prec@1 99.023 (99.577)	Training Prec@5 99.805 (99.870)	
2022-03-26 23:02:31,101: ============================================================
2022-03-26 23:03:44,740: time cost, forward:0.01917343695249452, backward:0.043963161730450465, data cost:0.6399954031144777 
2022-03-26 23:03:44,740: ============================================================
2022-03-26 23:03:44,741: Epoch 15/38 Batch 3700/7662 eta: 1 day, 12:51:32.945462	Training Loss 2.8551 (2.8663)	Training Prec@1 99.609 (99.575)	Training Prec@5 100.000 (99.869)	
2022-03-26 23:03:44,741: ============================================================
2022-03-26 23:04:54,396: time cost, forward:0.019237667424140965, backward:0.04407589797692476, data cost:0.6396663272402794 
2022-03-26 23:04:54,397: ============================================================
2022-03-26 23:04:54,397: Epoch 15/38 Batch 3800/7662 eta: 1 day, 10:50:43.823277	Training Loss 2.8350 (2.8691)	Training Prec@1 100.000 (99.571)	Training Prec@5 100.000 (99.868)	
2022-03-26 23:04:54,397: ============================================================
2022-03-26 23:06:05,995: time cost, forward:0.01928874051518916, backward:0.044115526060411095, data cost:0.639861543535055 
2022-03-26 23:06:05,996: ============================================================
2022-03-26 23:06:05,996: Epoch 15/38 Batch 3900/7662 eta: 1 day, 11:47:50.059297	Training Loss 3.0247 (2.8723)	Training Prec@1 99.219 (99.568)	Training Prec@5 99.609 (99.866)	
2022-03-26 23:06:05,996: ============================================================
2022-03-26 23:07:16,175: time cost, forward:0.01925246654137518, backward:0.04422655091282129, data cost:0.639489297957443 
2022-03-26 23:07:16,180: ============================================================
2022-03-26 23:07:16,181: Epoch 15/38 Batch 4000/7662 eta: 1 day, 11:04:14.257356	Training Loss 2.9914 (2.8754)	Training Prec@1 99.414 (99.566)	Training Prec@5 99.609 (99.865)	
2022-03-26 23:07:16,183: ============================================================
2022-03-26 23:08:21,110: time cost, forward:0.0191907010796187, backward:0.044176921055764214, data cost:0.6384717890564248 
2022-03-26 23:08:21,111: ============================================================
2022-03-26 23:08:21,111: Epoch 15/38 Batch 4100/7662 eta: 1 day, 8:25:36.991819	Training Loss 2.8826 (2.8786)	Training Prec@1 99.609 (99.563)	Training Prec@5 100.000 (99.865)	
2022-03-26 23:08:21,111: ============================================================
2022-03-26 23:09:31,381: time cost, forward:0.019236318098133195, backward:0.04424390925711522, data cost:0.6383447985502617 
2022-03-26 23:09:31,382: ============================================================
2022-03-26 23:09:31,382: Epoch 15/38 Batch 4200/7662 eta: 1 day, 11:04:29.921064	Training Loss 2.9418 (2.8814)	Training Prec@1 100.000 (99.560)	Training Prec@5 100.000 (99.864)	
2022-03-26 23:09:31,382: ============================================================
2022-03-26 23:10:39,671: time cost, forward:0.019271343856335905, backward:0.04426158159437443, data cost:0.6378125252072604 
2022-03-26 23:10:39,671: ============================================================
2022-03-26 23:10:39,672: Epoch 15/38 Batch 4300/7662 eta: 1 day, 10:04:00.260167	Training Loss 3.0283 (2.8837)	Training Prec@1 99.609 (99.557)	Training Prec@5 99.805 (99.863)	
2022-03-26 23:10:39,672: ============================================================
2022-03-26 23:11:49,825: time cost, forward:0.01925392117275924, backward:0.044219182929984, data cost:0.6376552012162361 
2022-03-26 23:11:49,829: ============================================================
2022-03-26 23:11:49,830: Epoch 15/38 Batch 4400/7662 eta: 1 day, 10:58:46.286307	Training Loss 2.8467 (2.8866)	Training Prec@1 99.023 (99.553)	Training Prec@5 99.609 (99.862)	
2022-03-26 23:11:49,831: ============================================================
2022-03-26 23:12:59,279: time cost, forward:0.019267591430653888, backward:0.044233626910224706, data cost:0.6376000332498476 
2022-03-26 23:12:59,279: ============================================================
2022-03-26 23:12:59,280: Epoch 15/38 Batch 4500/7662 eta: 1 day, 10:36:25.814556	Training Loss 2.9964 (2.8889)	Training Prec@1 99.414 (99.550)	Training Prec@5 100.000 (99.861)	
2022-03-26 23:12:59,280: ============================================================
2022-03-26 23:14:07,426: time cost, forward:0.019289347471737762, backward:0.04426316723509389, data cost:0.6371146250507266 
2022-03-26 23:14:07,426: ============================================================
2022-03-26 23:14:07,427: Epoch 15/38 Batch 4600/7662 eta: 1 day, 9:56:19.600485	Training Loss 3.0560 (2.8913)	Training Prec@1 99.414 (99.547)	Training Prec@5 99.805 (99.860)	
2022-03-26 23:14:07,427: ============================================================
2022-03-26 23:15:14,813: time cost, forward:0.01930515647923903, backward:0.04431671060179365, data cost:0.6364429807328092 
2022-03-26 23:15:14,814: ============================================================
2022-03-26 23:15:14,814: Epoch 15/38 Batch 4700/7662 eta: 1 day, 9:32:30.911415	Training Loss 3.0900 (2.8941)	Training Prec@1 99.609 (99.544)	Training Prec@5 99.805 (99.858)	
2022-03-26 23:15:14,814: ============================================================
2022-03-26 23:16:27,058: time cost, forward:0.019303286167501682, backward:0.044340124128261785, data cost:0.6368526004955007 
2022-03-26 23:16:27,059: ============================================================
2022-03-26 23:16:27,060: Epoch 15/38 Batch 4800/7662 eta: 1 day, 11:56:22.974232	Training Loss 2.8198 (2.8972)	Training Prec@1 99.414 (99.542)	Training Prec@5 99.609 (99.858)	
2022-03-26 23:16:27,060: ============================================================
2022-03-26 23:17:38,008: time cost, forward:0.019341729178334235, backward:0.04440909377115798, data cost:0.6368935674179522 
2022-03-26 23:17:38,009: ============================================================
2022-03-26 23:17:38,009: Epoch 15/38 Batch 4900/7662 eta: 1 day, 11:16:32.716069	Training Loss 2.8970 (2.8998)	Training Prec@1 99.414 (99.540)	Training Prec@5 99.414 (99.856)	
2022-03-26 23:17:38,009: ============================================================
2022-03-26 23:18:46,304: time cost, forward:0.019314195232692778, backward:0.04439392316863641, data cost:0.6365364319945745 
2022-03-26 23:18:46,304: ============================================================
2022-03-26 23:18:46,304: Epoch 15/38 Batch 5000/7662 eta: 1 day, 9:56:12.298985	Training Loss 3.1127 (2.9016)	Training Prec@1 99.609 (99.538)	Training Prec@5 99.805 (99.856)	
2022-03-26 23:18:46,305: ============================================================
2022-03-26 23:19:56,306: time cost, forward:0.019280301002596704, backward:0.04441939416785501, data cost:0.6364707006943369 
2022-03-26 23:19:56,307: ============================================================
2022-03-26 23:19:56,307: Epoch 15/38 Batch 5100/7662 eta: 1 day, 10:45:57.673085	Training Loss 3.2157 (2.9039)	Training Prec@1 99.219 (99.535)	Training Prec@5 99.609 (99.855)	
2022-03-26 23:19:56,308: ============================================================
2022-03-26 23:21:03,294: time cost, forward:0.019286516240569897, backward:0.04441794640147977, data cost:0.6358655325883534 
2022-03-26 23:21:03,295: ============================================================
2022-03-26 23:21:03,295: Epoch 15/38 Batch 5200/7662 eta: 1 day, 9:14:59.308275	Training Loss 2.9658 (2.9059)	Training Prec@1 99.609 (99.533)	Training Prec@5 100.000 (99.854)	
2022-03-26 23:21:03,295: ============================================================
2022-03-26 23:22:12,041: time cost, forward:0.019255180812417436, backward:0.04435437408162189, data cost:0.635640752880185 
2022-03-26 23:22:12,042: ============================================================
2022-03-26 23:22:12,042: Epoch 15/38 Batch 5300/7662 eta: 1 day, 10:06:15.304486	Training Loss 2.9456 (2.9078)	Training Prec@1 99.609 (99.531)	Training Prec@5 100.000 (99.853)	
2022-03-26 23:22:12,042: ============================================================
2022-03-26 23:23:19,966: time cost, forward:0.01921060951269651, backward:0.04432184353076125, data cost:0.6354177728099367 
2022-03-26 23:23:19,966: ============================================================
2022-03-26 23:23:19,966: Epoch 15/38 Batch 5400/7662 eta: 1 day, 9:40:36.968409	Training Loss 2.8801 (2.9098)	Training Prec@1 99.609 (99.529)	Training Prec@5 99.805 (99.852)	
2022-03-26 23:23:19,966: ============================================================
2022-03-26 23:24:30,584: time cost, forward:0.019201842757393433, backward:0.04434846617738037, data cost:0.6353534519683233 
2022-03-26 23:24:30,587: ============================================================
2022-03-26 23:24:30,588: Epoch 15/38 Batch 5500/7662 eta: 1 day, 10:59:40.407961	Training Loss 2.9667 (2.9116)	Training Prec@1 100.000 (99.527)	Training Prec@5 100.000 (99.852)	
2022-03-26 23:24:30,589: ============================================================
2022-03-26 23:25:38,703: time cost, forward:0.019220681462166118, backward:0.044380472395798634, data cost:0.6351147496842938 
2022-03-26 23:25:38,703: ============================================================
2022-03-26 23:25:38,703: Epoch 15/38 Batch 5600/7662 eta: 1 day, 9:44:03.202930	Training Loss 3.1863 (2.9133)	Training Prec@1 99.805 (99.524)	Training Prec@5 100.000 (99.851)	
2022-03-26 23:25:38,704: ============================================================
2022-03-26 23:26:46,733: time cost, forward:0.019193525794598695, backward:0.044368064786325656, data cost:0.6347891006747512 
2022-03-26 23:26:46,734: ============================================================
2022-03-26 23:26:46,734: Epoch 15/38 Batch 5700/7662 eta: 1 day, 9:40:22.606680	Training Loss 3.3428 (2.9154)	Training Prec@1 99.414 (99.522)	Training Prec@5 99.805 (99.850)	
2022-03-26 23:26:46,734: ============================================================
2022-03-26 23:27:52,600: time cost, forward:0.019178842959639984, backward:0.04434672239053288, data cost:0.6341274484393309 
2022-03-26 23:27:52,601: ============================================================
2022-03-26 23:27:52,601: Epoch 15/38 Batch 5800/7662 eta: 1 day, 8:35:02.194317	Training Loss 3.1885 (2.9174)	Training Prec@1 99.219 (99.520)	Training Prec@5 100.000 (99.849)	
2022-03-26 23:27:52,601: ============================================================
2022-03-26 23:28:59,960: time cost, forward:0.019136030848985366, backward:0.04432452878905143, data cost:0.6337580872018532 
2022-03-26 23:28:59,960: ============================================================
2022-03-26 23:28:59,961: Epoch 15/38 Batch 5900/7662 eta: 1 day, 9:18:12.496514	Training Loss 3.0610 (2.9191)	Training Prec@1 99.023 (99.518)	Training Prec@5 99.805 (99.848)	
2022-03-26 23:28:59,961: ============================================================
2022-03-26 23:30:08,978: time cost, forward:0.019114458237037717, backward:0.04434301098459342, data cost:0.6335597579172004 
2022-03-26 23:30:08,979: ============================================================
2022-03-26 23:30:08,979: Epoch 15/38 Batch 6000/7662 eta: 1 day, 10:06:16.043098	Training Loss 2.8720 (2.9203)	Training Prec@1 100.000 (99.518)	Training Prec@5 100.000 (99.848)	
2022-03-26 23:30:08,979: ============================================================
2022-03-26 23:31:17,482: time cost, forward:0.019124833848324346, backward:0.04428620728572327, data cost:0.6333522307988092 
2022-03-26 23:31:17,483: ============================================================
2022-03-26 23:31:17,483: Epoch 15/38 Batch 6100/7662 eta: 1 day, 9:49:53.094452	Training Loss 2.8253 (2.9216)	Training Prec@1 99.805 (99.516)	Training Prec@5 100.000 (99.847)	
2022-03-26 23:31:17,483: ============================================================
2022-03-26 23:32:23,386: time cost, forward:0.019094608775798997, backward:0.044198805563948694, data cost:0.6328331715715645 
2022-03-26 23:32:23,390: ============================================================
2022-03-26 23:32:23,391: Epoch 15/38 Batch 6200/7662 eta: 1 day, 8:31:49.694812	Training Loss 3.1853 (2.9233)	Training Prec@1 98.828 (99.514)	Training Prec@5 99.414 (99.847)	
2022-03-26 23:32:23,392: ============================================================
2022-03-26 23:33:28,350: time cost, forward:0.01908877263430244, backward:0.04411198309743796, data cost:0.6322559314524301 
2022-03-26 23:33:28,351: ============================================================
2022-03-26 23:33:28,351: Epoch 15/38 Batch 6300/7662 eta: 1 day, 8:02:42.961472	Training Loss 3.1454 (2.9250)	Training Prec@1 99.219 (99.512)	Training Prec@5 99.805 (99.846)	
2022-03-26 23:33:28,351: ============================================================
2022-03-26 23:34:36,107: time cost, forward:0.019074194467445894, backward:0.04415366686513823, data cost:0.6319281090645329 
2022-03-26 23:34:36,107: ============================================================
2022-03-26 23:34:36,108: Epoch 15/38 Batch 6400/7662 eta: 1 day, 9:24:20.446011	Training Loss 3.0767 (2.9268)	Training Prec@1 99.219 (99.511)	Training Prec@5 99.805 (99.845)	
2022-03-26 23:34:36,108: ============================================================
2022-03-26 23:35:43,623: time cost, forward:0.01905382811280283, backward:0.044104139444222354, data cost:0.6315820808501624 
2022-03-26 23:35:43,625: ============================================================
2022-03-26 23:35:43,626: Epoch 15/38 Batch 6500/7662 eta: 1 day, 9:16:09.906179	Training Loss 3.1919 (2.9283)	Training Prec@1 99.219 (99.508)	Training Prec@5 99.805 (99.845)	
2022-03-26 23:35:43,627: ============================================================
2022-03-26 23:36:53,889: time cost, forward:0.019048102571487716, backward:0.044124989206817296, data cost:0.6316634936303076 
2022-03-26 23:36:53,890: ============================================================
2022-03-26 23:36:53,890: Epoch 15/38 Batch 6600/7662 eta: 1 day, 10:36:10.318758	Training Loss 2.7486 (2.9297)	Training Prec@1 99.414 (99.507)	Training Prec@5 99.805 (99.845)	
2022-03-26 23:36:53,890: ============================================================
2022-03-26 23:38:00,483: time cost, forward:0.019017817387208598, backward:0.04403765622600368, data cost:0.6313804137313486 
2022-03-26 23:38:00,484: ============================================================
2022-03-26 23:38:00,484: Epoch 15/38 Batch 6700/7662 eta: 1 day, 8:46:38.074646	Training Loss 3.0955 (2.9313)	Training Prec@1 99.609 (99.505)	Training Prec@5 100.000 (99.845)	
2022-03-26 23:38:00,484: ============================================================
2022-03-26 23:39:06,031: time cost, forward:0.018998952696719296, backward:0.04399844824803158, data cost:0.6308771974813554 
2022-03-26 23:39:06,031: ============================================================
2022-03-26 23:39:06,031: Epoch 15/38 Batch 6800/7662 eta: 1 day, 8:14:36.820991	Training Loss 2.8714 (2.9329)	Training Prec@1 99.805 (99.503)	Training Prec@5 100.000 (99.844)	
2022-03-26 23:39:06,032: ============================================================
2022-03-26 23:40:15,007: time cost, forward:0.019003941055864056, backward:0.04398368831855142, data cost:0.6307995827375313 
2022-03-26 23:40:15,007: ============================================================
2022-03-26 23:40:15,007: Epoch 15/38 Batch 6900/7662 eta: 1 day, 9:54:39.953020	Training Loss 3.1183 (2.9344)	Training Prec@1 99.219 (99.501)	Training Prec@5 99.609 (99.843)	
2022-03-26 23:40:15,008: ============================================================
2022-03-26 23:41:21,374: time cost, forward:0.01901083902761517, backward:0.04394567685563967, data cost:0.6303667461451402 
2022-03-26 23:41:21,374: ============================================================
2022-03-26 23:41:21,375: Epoch 15/38 Batch 7000/7662 eta: 1 day, 8:36:35.997460	Training Loss 3.1402 (2.9358)	Training Prec@1 99.414 (99.500)	Training Prec@5 99.805 (99.843)	
2022-03-26 23:41:21,375: ============================================================
2022-03-26 23:42:32,410: time cost, forward:0.01903819927011918, backward:0.04398202422572317, data cost:0.6305349262386397 
2022-03-26 23:42:32,410: ============================================================
2022-03-26 23:42:32,410: Epoch 15/38 Batch 7100/7662 eta: 1 day, 10:53:03.643547	Training Loss 2.8334 (2.9368)	Training Prec@1 99.414 (99.499)	Training Prec@5 100.000 (99.843)	
2022-03-26 23:42:32,411: ============================================================
2022-03-26 23:43:38,346: time cost, forward:0.01903419190602992, backward:0.04397607545154528, data cost:0.6300415026345076 
2022-03-26 23:43:38,346: ============================================================
2022-03-26 23:43:38,347: Epoch 15/38 Batch 7200/7662 eta: 1 day, 8:21:42.000873	Training Loss 2.9711 (2.9379)	Training Prec@1 100.000 (99.497)	Training Prec@5 100.000 (99.843)	
2022-03-26 23:43:38,347: ============================================================
2022-03-26 23:44:46,151: time cost, forward:0.019038669539406, backward:0.04399306876379458, data cost:0.6297952781917134 
2022-03-26 23:44:46,151: ============================================================
2022-03-26 23:44:46,152: Epoch 15/38 Batch 7300/7662 eta: 1 day, 9:15:36.145044	Training Loss 3.1933 (2.9391)	Training Prec@1 99.219 (99.495)	Training Prec@5 100.000 (99.842)	
2022-03-26 23:44:46,152: ============================================================
2022-03-26 23:45:53,290: time cost, forward:0.019036507216607063, backward:0.043956103719945114, data cost:0.6295163807055002 
2022-03-26 23:45:53,291: ============================================================
2022-03-26 23:45:53,291: Epoch 15/38 Batch 7400/7662 eta: 1 day, 8:54:53.743198	Training Loss 2.9412 (2.9401)	Training Prec@1 99.219 (99.494)	Training Prec@5 99.609 (99.841)	
2022-03-26 23:45:53,291: ============================================================
2022-03-26 23:47:01,368: time cost, forward:0.019029203105376615, backward:0.044004024354787424, data cost:0.629294571232392 
2022-03-26 23:47:01,368: ============================================================
2022-03-26 23:47:01,369: Epoch 15/38 Batch 7500/7662 eta: 1 day, 9:21:21.528657	Training Loss 2.9664 (2.9414)	Training Prec@1 100.000 (99.492)	Training Prec@5 100.000 (99.840)	
2022-03-26 23:47:01,369: ============================================================
2022-03-26 23:48:09,044: time cost, forward:0.01902848247603878, backward:0.044032882429891736, data cost:0.6290329299266126 
2022-03-26 23:48:09,044: ============================================================
2022-03-26 23:48:09,045: Epoch 15/38 Batch 7600/7662 eta: 1 day, 9:08:25.372429	Training Loss 3.1039 (2.9425)	Training Prec@1 99.609 (99.491)	Training Prec@5 99.805 (99.839)	
2022-03-26 23:48:09,045: ============================================================
2022-03-26 23:48:51,406: Epoch: 15/38 eta: 1 day, 9:07:42.736539	Training Loss 3.0877 (2.9431)	Training Prec@1 99.023 (99.490)	Training Prec@5 100.000 (99.839)
2022-03-26 23:48:51,407: ============================================================
2022-03-26 23:48:51,525: Save Checkpoint...
2022-03-26 23:48:51,526: ============================================================
2022-03-26 23:48:53,842: Save done!
2022-03-26 23:48:53,842: ============================================================
2022-03-26 23:52:04,373: time cost, forward:0.011496902716280235, backward:0.026524849612303454, data cost:1.8812996763171572 
2022-03-26 23:52:04,373: ============================================================
2022-03-26 23:52:04,373: Epoch 16/38 Batch 100/7662 eta: 3 days, 21:11:28.700052	Training Loss 2.6035 (2.5718)	Training Prec@1 99.609 (99.684)	Training Prec@5 100.000 (99.913)	
2022-03-26 23:52:04,374: ============================================================
2022-03-26 23:53:03,933: time cost, forward:0.013437628146991058, backward:0.031007039487062387, data cost:1.20655574151619 
2022-03-26 23:53:03,935: ============================================================
2022-03-26 23:53:03,937: Epoch 16/38 Batch 200/7662 eta: 1 day, 5:07:26.890600	Training Loss 2.5404 (2.5791)	Training Prec@1 100.000 (99.707)	Training Prec@5 100.000 (99.920)	
2022-03-26 23:53:03,938: ============================================================
2022-03-26 23:54:08,041: time cost, forward:0.0146901703199814, backward:0.034769205744051214, data cost:0.9989352808349508 
2022-03-26 23:54:08,042: ============================================================
2022-03-26 23:54:08,042: Epoch 16/38 Batch 300/7662 eta: 1 day, 7:19:39.542319	Training Loss 2.7773 (2.5866)	Training Prec@1 99.219 (99.701)	Training Prec@5 100.000 (99.917)	
2022-03-26 23:54:08,042: ============================================================
2022-03-26 23:55:15,618: time cost, forward:0.015404169422044492, backward:0.03719634997814819, data cost:0.900867039697212 
2022-03-26 23:55:15,620: ============================================================
2022-03-26 23:55:15,621: Epoch 16/38 Batch 400/7662 eta: 1 day, 9:00:21.565332	Training Loss 2.5722 (2.5987)	Training Prec@1 99.805 (99.698)	Training Prec@5 99.805 (99.914)	
2022-03-26 23:55:15,622: ============================================================
2022-03-26 23:56:21,318: time cost, forward:0.01586827964247587, backward:0.03871295542898541, data cost:0.839343473285377 
2022-03-26 23:56:21,319: ============================================================
2022-03-26 23:56:21,319: Epoch 16/38 Batch 500/7662 eta: 1 day, 8:04:09.707161	Training Loss 2.5640 (2.6132)	Training Prec@1 99.805 (99.694)	Training Prec@5 99.805 (99.914)	
2022-03-26 23:56:21,320: ============================================================
2022-03-26 23:57:31,164: time cost, forward:0.01638827260229146, backward:0.0395516807925522, data cost:0.8057261138209119 
2022-03-26 23:57:31,165: ============================================================
2022-03-26 23:57:31,165: Epoch 16/38 Batch 600/7662 eta: 1 day, 10:04:28.173895	Training Loss 2.5401 (2.6276)	Training Prec@1 99.609 (99.691)	Training Prec@5 99.805 (99.913)	
2022-03-26 23:57:31,165: ============================================================
2022-03-26 23:58:38,457: time cost, forward:0.01651048421518656, backward:0.04016000347928769, data cost:0.7765646079749678 
2022-03-26 23:58:39,002: ============================================================
2022-03-26 23:58:39,002: Epoch 16/38 Batch 700/7662 eta: 1 day, 9:04:31.989665	Training Loss 2.7459 (2.6431)	Training Prec@1 99.609 (99.685)	Training Prec@5 99.609 (99.914)	
2022-03-26 23:58:39,002: ============================================================
2022-03-26 23:59:42,458: time cost, forward:0.016373431727346104, backward:0.04026233209984771, data cost:0.7530156736529068 
2022-03-26 23:59:42,458: ============================================================
2022-03-26 23:59:42,458: Epoch 16/38 Batch 800/7662 eta: 1 day, 6:55:19.646136	Training Loss 2.7370 (2.6580)	Training Prec@1 99.609 (99.683)	Training Prec@5 100.000 (99.911)	
2022-03-26 23:59:42,459: ============================================================
2022-03-27 00:00:47,055: time cost, forward:0.01638822269121452, backward:0.04027714692180494, data cost:0.7341947075522384 
2022-03-27 00:00:47,058: ============================================================
2022-03-27 00:00:47,059: Epoch 16/38 Batch 900/7662 eta: 1 day, 7:27:40.659124	Training Loss 2.8102 (2.6681)	Training Prec@1 99.609 (99.682)	Training Prec@5 99.805 (99.912)	
2022-03-27 00:00:47,060: ============================================================
2022-03-27 00:01:53,202: time cost, forward:0.016786666245789856, backward:0.040817881012344744, data cost:0.7200559755942008 
2022-03-27 00:01:53,202: ============================================================
2022-03-27 00:01:53,203: Epoch 16/38 Batch 1000/7662 eta: 1 day, 8:11:43.136262	Training Loss 2.7545 (2.6781)	Training Prec@1 99.609 (99.676)	Training Prec@5 99.805 (99.912)	
2022-03-27 00:01:53,203: ============================================================
2022-03-27 00:02:58,936: time cost, forward:0.01653585052143128, backward:0.040799500618987565, data cost:0.7099968712366744 
2022-03-27 00:02:58,936: ============================================================
2022-03-27 00:02:58,937: Epoch 16/38 Batch 1100/7662 eta: 1 day, 7:58:37.698617	Training Loss 2.8885 (2.6914)	Training Prec@1 99.414 (99.663)	Training Prec@5 99.805 (99.905)	
2022-03-27 00:02:58,937: ============================================================
2022-03-27 00:04:03,371: time cost, forward:0.016460262009061505, backward:0.040843717250553545, data cost:0.6995910385233646 
2022-03-27 00:04:03,371: ============================================================
2022-03-27 00:04:03,371: Epoch 16/38 Batch 1200/7662 eta: 1 day, 7:19:38.157443	Training Loss 2.8312 (2.7022)	Training Prec@1 100.000 (99.662)	Training Prec@5 100.000 (99.905)	
2022-03-27 00:04:03,371: ============================================================
2022-03-27 00:05:09,574: time cost, forward:0.01638983890953387, backward:0.04082980093541193, data cost:0.6920477591449247 
2022-03-27 00:05:09,579: ============================================================
2022-03-27 00:05:09,581: Epoch 16/38 Batch 1300/7662 eta: 1 day, 8:10:16.491754	Training Loss 2.7975 (2.7096)	Training Prec@1 99.414 (99.657)	Training Prec@5 99.805 (99.903)	
2022-03-27 00:05:09,582: ============================================================
2022-03-27 00:06:15,348: time cost, forward:0.016550158670410417, backward:0.041099346561718195, data cost:0.6851293200505811 
2022-03-27 00:06:15,348: ============================================================
2022-03-27 00:06:15,349: Epoch 16/38 Batch 1400/7662 eta: 1 day, 7:56:21.373254	Training Loss 2.7687 (2.7192)	Training Prec@1 99.805 (99.658)	Training Prec@5 100.000 (99.905)	
2022-03-27 00:06:15,349: ============================================================
2022-03-27 00:07:22,627: time cost, forward:0.01658966972320536, backward:0.041256813306344044, data cost:0.6802465764580765 
2022-03-27 00:07:22,627: ============================================================
2022-03-27 00:07:22,627: Epoch 16/38 Batch 1500/7662 eta: 1 day, 8:39:14.237643	Training Loss 2.7683 (2.7279)	Training Prec@1 99.805 (99.652)	Training Prec@5 100.000 (99.901)	
2022-03-27 00:07:22,628: ============================================================
2022-03-27 00:08:28,440: time cost, forward:0.01663231611102726, backward:0.04144857196676649, data cost:0.674822749757558 
2022-03-27 00:08:28,441: ============================================================
2022-03-27 00:08:28,441: Epoch 16/38 Batch 1600/7662 eta: 1 day, 7:55:28.070573	Training Loss 3.0144 (2.7353)	Training Prec@1 99.414 (99.646)	Training Prec@5 100.000 (99.898)	
2022-03-27 00:08:28,441: ============================================================
2022-03-27 00:09:32,536: time cost, forward:0.016630667528732865, backward:0.04168600191292586, data cost:0.6692383209349759 
2022-03-27 00:09:32,561: ============================================================
2022-03-27 00:09:32,561: Epoch 16/38 Batch 1700/7662 eta: 1 day, 7:05:06.866575	Training Loss 2.8838 (2.7426)	Training Prec@1 99.805 (99.641)	Training Prec@5 99.805 (99.896)	
2022-03-27 00:09:32,561: ============================================================
2022-03-27 00:10:39,611: time cost, forward:0.016749250153291883, backward:0.041784425786364536, data cost:0.6657681340572237 
2022-03-27 00:10:39,614: ============================================================
2022-03-27 00:10:39,615: Epoch 16/38 Batch 1800/7662 eta: 1 day, 8:29:19.708591	Training Loss 2.9487 (2.7502)	Training Prec@1 99.414 (99.637)	Training Prec@5 99.805 (99.896)	
2022-03-27 00:10:39,615: ============================================================
2022-03-27 00:11:48,289: time cost, forward:0.01690147976425838, backward:0.042083397484127004, data cost:0.6632289732048674 
2022-03-27 00:11:48,289: ============================================================
2022-03-27 00:11:48,290: Epoch 16/38 Batch 1900/7662 eta: 1 day, 9:15:18.878056	Training Loss 2.6548 (2.7563)	Training Prec@1 99.805 (99.634)	Training Prec@5 99.805 (99.893)	
2022-03-27 00:11:48,290: ============================================================
2022-03-27 00:12:54,545: time cost, forward:0.016976337423319814, backward:0.04232024049210274, data cost:0.6595862326829537 
2022-03-27 00:12:54,546: ============================================================
2022-03-27 00:12:54,546: Epoch 16/38 Batch 2000/7662 eta: 1 day, 8:03:56.529494	Training Loss 2.7455 (2.7625)	Training Prec@1 99.805 (99.630)	Training Prec@5 100.000 (99.892)	
2022-03-27 00:12:54,546: ============================================================
2022-03-27 00:14:01,975: time cost, forward:0.01707047062183687, backward:0.042377303361097594, data cost:0.6575469130161207 
2022-03-27 00:14:01,976: ============================================================
2022-03-27 00:14:01,976: Epoch 16/38 Batch 2100/7662 eta: 1 day, 8:36:54.236422	Training Loss 2.8101 (2.7687)	Training Prec@1 99.219 (99.627)	Training Prec@5 99.609 (99.890)	
2022-03-27 00:14:01,976: ============================================================
2022-03-27 00:15:09,548: time cost, forward:0.01711746018927116, backward:0.0424704885634578, data cost:0.6554647995808711 
2022-03-27 00:15:09,549: ============================================================
2022-03-27 00:15:09,549: Epoch 16/38 Batch 2200/7662 eta: 1 day, 8:39:54.672135	Training Loss 2.5414 (2.7747)	Training Prec@1 99.609 (99.624)	Training Prec@5 100.000 (99.888)	
2022-03-27 00:15:09,549: ============================================================
2022-03-27 00:16:15,373: time cost, forward:0.01721628285740292, backward:0.04262905195517455, data cost:0.6526575703473649 
2022-03-27 00:16:15,373: ============================================================
2022-03-27 00:16:15,373: Epoch 16/38 Batch 2300/7662 eta: 1 day, 7:48:06.337335	Training Loss 3.1181 (2.7798)	Training Prec@1 99.414 (99.618)	Training Prec@5 99.805 (99.885)	
2022-03-27 00:16:15,373: ============================================================
2022-03-27 00:17:19,048: time cost, forward:0.01721825705015843, backward:0.042585441101188705, data cost:0.6493537640661039 
2022-03-27 00:17:19,048: ============================================================
2022-03-27 00:17:19,048: Epoch 16/38 Batch 2400/7662 eta: 1 day, 6:44:44.741269	Training Loss 2.9838 (2.7843)	Training Prec@1 99.414 (99.617)	Training Prec@5 99.805 (99.885)	
2022-03-27 00:17:19,049: ============================================================
2022-03-27 00:18:25,793: time cost, forward:0.017267842252715295, backward:0.042637278910587675, data cost:0.647364194701318 
2022-03-27 00:18:25,796: ============================================================
2022-03-27 00:18:25,797: Epoch 16/38 Batch 2500/7662 eta: 1 day, 8:12:39.415430	Training Loss 3.0170 (2.7897)	Training Prec@1 98.438 (99.613)	Training Prec@5 99.805 (99.884)	
2022-03-27 00:18:25,798: ============================================================
2022-03-27 00:19:31,175: time cost, forward:0.01731482603404099, backward:0.042763941927385495, data cost:0.6453546084271526 
2022-03-27 00:19:31,175: ============================================================
2022-03-27 00:19:31,176: Epoch 16/38 Batch 2600/7662 eta: 1 day, 7:31:55.492751	Training Loss 2.7706 (2.7946)	Training Prec@1 99.805 (99.611)	Training Prec@5 99.805 (99.882)	
2022-03-27 00:19:31,176: ============================================================
2022-03-27 00:20:37,392: time cost, forward:0.017354053936873864, backward:0.04277629797526667, data cost:0.6436207696392431 
2022-03-27 00:20:37,393: ============================================================
2022-03-27 00:20:37,393: Epoch 16/38 Batch 2700/7662 eta: 1 day, 7:55:04.647073	Training Loss 2.9450 (2.8003)	Training Prec@1 99.023 (99.607)	Training Prec@5 99.805 (99.881)	
2022-03-27 00:20:37,393: ============================================================
2022-03-27 00:21:41,946: time cost, forward:0.017323763551947133, backward:0.0426901439634039, data cost:0.6415672762217629 
2022-03-27 00:21:41,947: ============================================================
2022-03-27 00:21:41,947: Epoch 16/38 Batch 2800/7662 eta: 1 day, 7:05:54.711681	Training Loss 2.9414 (2.8054)	Training Prec@1 99.805 (99.604)	Training Prec@5 100.000 (99.881)	
2022-03-27 00:21:41,947: ============================================================
2022-03-27 00:22:50,571: time cost, forward:0.017352672147931784, backward:0.042805014663254155, data cost:0.6407387341331227 
2022-03-27 00:22:50,571: ============================================================
2022-03-27 00:22:50,572: Epoch 16/38 Batch 2900/7662 eta: 1 day, 9:02:24.778086	Training Loss 3.0545 (2.8094)	Training Prec@1 99.414 (99.603)	Training Prec@5 99.609 (99.881)	
2022-03-27 00:22:50,572: ============================================================
2022-03-27 00:23:55,919: time cost, forward:0.017422205609216337, backward:0.042872435174492365, data cost:0.6390511320208899 
2022-03-27 00:23:55,920: ============================================================
2022-03-27 00:23:55,920: Epoch 16/38 Batch 3000/7662 eta: 1 day, 7:26:41.149062	Training Loss 2.9396 (2.8134)	Training Prec@1 99.609 (99.600)	Training Prec@5 100.000 (99.880)	
2022-03-27 00:23:55,920: ============================================================
2022-03-27 00:25:03,666: time cost, forward:0.017460912533366475, backward:0.04293216632696535, data cost:0.6382682673505676 
2022-03-27 00:25:03,667: ============================================================
2022-03-27 00:25:03,667: Epoch 16/38 Batch 3100/7662 eta: 1 day, 8:34:48.198819	Training Loss 3.0401 (2.8177)	Training Prec@1 99.219 (99.597)	Training Prec@5 99.805 (99.879)	
2022-03-27 00:25:03,667: ============================================================
2022-03-27 00:26:09,188: time cost, forward:0.017473373609842753, backward:0.042933666694905843, data cost:0.6368499739015799 
2022-03-27 00:26:09,191: ============================================================
2022-03-27 00:26:09,192: Epoch 16/38 Batch 3200/7662 eta: 1 day, 7:29:35.444406	Training Loss 2.8875 (2.8216)	Training Prec@1 99.219 (99.593)	Training Prec@5 99.805 (99.878)	
2022-03-27 00:26:09,193: ============================================================
2022-03-27 00:27:15,285: time cost, forward:0.01749583192578443, backward:0.04296622062387088, data cost:0.6353989716333561 
2022-03-27 00:27:15,288: ============================================================
2022-03-27 00:27:15,289: Epoch 16/38 Batch 3300/7662 eta: 1 day, 7:44:58.724926	Training Loss 3.0156 (2.8259)	Training Prec@1 99.219 (99.588)	Training Prec@5 100.000 (99.876)	
2022-03-27 00:27:15,289: ============================================================
2022-03-27 00:28:21,599: time cost, forward:0.017516476717301065, backward:0.0430125636049985, data cost:0.6344680768596876 
2022-03-27 00:28:21,601: ============================================================
2022-03-27 00:28:21,602: Epoch 16/38 Batch 3400/7662 eta: 1 day, 7:50:06.912253	Training Loss 2.9214 (2.8295)	Training Prec@1 99.414 (99.587)	Training Prec@5 100.000 (99.876)	
2022-03-27 00:28:21,602: ============================================================
2022-03-27 00:29:26,936: time cost, forward:0.017572976480589215, backward:0.0429911096970263, data cost:0.6331171879737028 
2022-03-27 00:29:26,938: ============================================================
2022-03-27 00:29:26,939: Epoch 16/38 Batch 3500/7662 eta: 1 day, 7:20:55.146336	Training Loss 3.0914 (2.8329)	Training Prec@1 99.414 (99.583)	Training Prec@5 99.609 (99.874)	
2022-03-27 00:29:26,940: ============================================================
2022-03-27 00:30:31,439: time cost, forward:0.017608265970839032, backward:0.0429684687203982, data cost:0.6319095308696538 
2022-03-27 00:30:31,440: ============================================================
2022-03-27 00:30:31,440: Epoch 16/38 Batch 3600/7662 eta: 1 day, 6:55:46.630919	Training Loss 2.8771 (2.8367)	Training Prec@1 99.414 (99.582)	Training Prec@5 100.000 (99.874)	
2022-03-27 00:30:31,440: ============================================================
2022-03-27 00:31:39,511: time cost, forward:0.017687544947735327, backward:0.04305445339010032, data cost:0.631355571308533 
2022-03-27 00:31:39,512: ============================================================
2022-03-27 00:31:39,512: Epoch 16/38 Batch 3700/7662 eta: 1 day, 8:37:23.062806	Training Loss 2.7953 (2.8397)	Training Prec@1 99.805 (99.581)	Training Prec@5 99.805 (99.873)	
2022-03-27 00:31:39,513: ============================================================
2022-03-27 00:32:44,183: time cost, forward:0.017702361413383834, backward:0.043056652714748636, data cost:0.629946901974599 
2022-03-27 00:32:44,184: ============================================================
2022-03-27 00:32:44,185: Epoch 16/38 Batch 3800/7662 eta: 1 day, 6:58:31.693742	Training Loss 2.8988 (2.8434)	Training Prec@1 99.023 (99.578)	Training Prec@5 99.805 (99.872)	
2022-03-27 00:32:44,185: ============================================================
2022-03-27 00:33:48,691: time cost, forward:0.01769344285073174, backward:0.04303461461533152, data cost:0.6289409393223471 
2022-03-27 00:33:48,692: ============================================================
2022-03-27 00:33:48,692: Epoch 16/38 Batch 3900/7662 eta: 1 day, 6:52:43.961846	Training Loss 2.8513 (2.8462)	Training Prec@1 99.805 (99.576)	Training Prec@5 100.000 (99.871)	
2022-03-27 00:33:48,692: ============================================================
2022-03-27 00:34:53,472: time cost, forward:0.017674442588403602, backward:0.04301456023109171, data cost:0.6278964394061199 
2022-03-27 00:34:53,473: ============================================================
2022-03-27 00:34:53,473: Epoch 16/38 Batch 4000/7662 eta: 1 day, 6:59:31.078554	Training Loss 2.9476 (2.8489)	Training Prec@1 99.805 (99.574)	Training Prec@5 100.000 (99.870)	
2022-03-27 00:34:53,473: ============================================================
2022-03-27 00:36:00,493: time cost, forward:0.01766443473590703, backward:0.04307344728168786, data cost:0.6273302764943763 
2022-03-27 00:36:00,493: ============================================================
2022-03-27 00:36:00,494: Epoch 16/38 Batch 4100/7662 eta: 1 day, 8:02:40.288118	Training Loss 2.8712 (2.8517)	Training Prec@1 99.414 (99.571)	Training Prec@5 100.000 (99.868)	
2022-03-27 00:36:00,494: ============================================================
2022-03-27 00:37:04,950: time cost, forward:0.017681726304426965, backward:0.043032712781960185, data cost:0.6261403386892095 
2022-03-27 00:37:04,950: ============================================================
2022-03-27 00:37:04,951: Epoch 16/38 Batch 4200/7662 eta: 1 day, 6:48:03.220301	Training Loss 3.0983 (2.8544)	Training Prec@1 99.219 (99.569)	Training Prec@5 99.609 (99.868)	
2022-03-27 00:37:04,951: ============================================================
2022-03-27 00:38:08,669: time cost, forward:0.017696239305501984, backward:0.04304817632953353, data cost:0.6250931684791723 
2022-03-27 00:38:08,669: ============================================================
2022-03-27 00:38:08,670: Epoch 16/38 Batch 4300/7662 eta: 1 day, 6:25:50.346892	Training Loss 2.9005 (2.8572)	Training Prec@1 99.609 (99.566)	Training Prec@5 99.805 (99.866)	
2022-03-27 00:38:08,670: ============================================================
2022-03-27 00:39:14,950: time cost, forward:0.017758111190622462, backward:0.04311066298193215, data cost:0.6243932513275805 
2022-03-27 00:39:14,951: ============================================================
2022-03-27 00:39:14,951: Epoch 16/38 Batch 4400/7662 eta: 1 day, 7:38:09.574219	Training Loss 2.8347 (2.8594)	Training Prec@1 99.219 (99.564)	Training Prec@5 99.414 (99.865)	
2022-03-27 00:39:14,951: ============================================================
2022-03-27 00:40:20,528: time cost, forward:0.017771372028816325, backward:0.04310895056426724, data cost:0.6236993966035828 
2022-03-27 00:40:20,528: ============================================================
2022-03-27 00:40:20,529: Epoch 16/38 Batch 4500/7662 eta: 1 day, 7:16:54.233481	Training Loss 2.8267 (2.8617)	Training Prec@1 99.609 (99.563)	Training Prec@5 99.805 (99.864)	
2022-03-27 00:40:20,529: ============================================================
2022-03-27 00:41:28,566: time cost, forward:0.017811443681793646, backward:0.04310279308285084, data cost:0.6234785237242849 
2022-03-27 00:41:28,569: ============================================================
2022-03-27 00:41:28,570: Epoch 16/38 Batch 4600/7662 eta: 1 day, 8:26:16.326282	Training Loss 2.8121 (2.8649)	Training Prec@1 99.805 (99.559)	Training Prec@5 100.000 (99.862)	
2022-03-27 00:41:28,571: ============================================================
2022-03-27 00:42:31,198: time cost, forward:0.017799758129765263, backward:0.04307173830216224, data cost:0.622342027636583 
2022-03-27 00:42:31,199: ============================================================
2022-03-27 00:42:31,199: Epoch 16/38 Batch 4700/7662 eta: 1 day, 5:50:26.732964	Training Loss 2.7227 (2.8673)	Training Prec@1 99.609 (99.557)	Training Prec@5 99.805 (99.862)	
2022-03-27 00:42:31,199: ============================================================
2022-03-27 00:43:38,909: time cost, forward:0.017815196084389962, backward:0.0431009176051177, data cost:0.6220625524944156 
2022-03-27 00:43:38,910: ============================================================
2022-03-27 00:43:38,910: Epoch 16/38 Batch 4800/7662 eta: 1 day, 8:14:35.111249	Training Loss 2.8082 (2.8699)	Training Prec@1 99.414 (99.554)	Training Prec@5 99.805 (99.862)	
2022-03-27 00:43:38,911: ============================================================
2022-03-27 00:44:42,777: time cost, forward:0.01780130722542689, backward:0.04305189053460904, data cost:0.6212677321499235 
2022-03-27 00:44:42,778: ============================================================
2022-03-27 00:44:42,778: Epoch 16/38 Batch 4900/7662 eta: 1 day, 6:23:42.834718	Training Loss 2.9889 (2.8720)	Training Prec@1 99.609 (99.552)	Training Prec@5 99.609 (99.861)	
2022-03-27 00:44:42,778: ============================================================
2022-03-27 00:45:46,715: time cost, forward:0.017822181637178875, backward:0.0430938224597892, data cost:0.6203122152808095 
2022-03-27 00:45:46,716: ============================================================
2022-03-27 00:45:46,716: Epoch 16/38 Batch 5000/7662 eta: 1 day, 6:24:39.007341	Training Loss 3.0478 (2.8743)	Training Prec@1 99.414 (99.549)	Training Prec@5 100.000 (99.860)	
2022-03-27 00:45:46,716: ============================================================
2022-03-27 00:46:50,507: time cost, forward:0.017813895772218376, backward:0.04308216238423969, data cost:0.6194616111266096 
2022-03-27 00:46:50,507: ============================================================
2022-03-27 00:46:50,508: Epoch 16/38 Batch 5100/7662 eta: 1 day, 6:19:24.308186	Training Loss 3.0259 (2.8763)	Training Prec@1 99.023 (99.547)	Training Prec@5 100.000 (99.859)	
2022-03-27 00:46:50,508: ============================================================
2022-03-27 00:47:56,558: time cost, forward:0.01784570759639164, backward:0.04312018665769371, data cost:0.6189952806959612 
2022-03-27 00:47:56,558: ============================================================
2022-03-27 00:47:56,558: Epoch 16/38 Batch 5200/7662 eta: 1 day, 7:22:44.801355	Training Loss 2.8718 (2.8786)	Training Prec@1 99.414 (99.544)	Training Prec@5 99.805 (99.857)	
2022-03-27 00:47:56,559: ============================================================
2022-03-27 00:49:03,427: time cost, forward:0.01788203665435843, backward:0.043162666732217934, data cost:0.6186063314388554 
2022-03-27 00:49:03,430: ============================================================
2022-03-27 00:49:03,430: Epoch 16/38 Batch 5300/7662 eta: 1 day, 7:45:01.525853	Training Loss 3.1297 (2.8810)	Training Prec@1 99.219 (99.542)	Training Prec@5 99.805 (99.856)	
2022-03-27 00:49:03,431: ============================================================
2022-03-27 00:50:08,606: time cost, forward:0.017883420100938966, backward:0.04315121965643255, data cost:0.6181080220341352 
2022-03-27 00:50:08,607: ============================================================
2022-03-27 00:50:08,607: Epoch 16/38 Batch 5400/7662 eta: 1 day, 6:55:40.644942	Training Loss 3.0119 (2.8830)	Training Prec@1 99.805 (99.539)	Training Prec@5 100.000 (99.856)	
2022-03-27 00:50:08,608: ============================================================
2022-03-27 00:51:13,341: time cost, forward:0.017933327624051653, backward:0.04319188446971715, data cost:0.6174097973382523 
2022-03-27 00:51:13,342: ============================================================
2022-03-27 00:51:13,342: Epoch 16/38 Batch 5500/7662 eta: 1 day, 6:41:59.969815	Training Loss 3.1325 (2.8853)	Training Prec@1 98.438 (99.536)	Training Prec@5 98.828 (99.855)	
2022-03-27 00:51:13,343: ============================================================
2022-03-27 00:52:21,916: time cost, forward:0.01801094563438714, backward:0.043235530383162336, data cost:0.6174216933028147 
2022-03-27 00:52:21,916: ============================================================
2022-03-27 00:52:21,917: Epoch 16/38 Batch 5600/7662 eta: 1 day, 8:30:06.233928	Training Loss 2.8315 (2.8874)	Training Prec@1 98.633 (99.534)	Training Prec@5 99.805 (99.854)	
2022-03-27 00:52:21,917: ============================================================
2022-03-27 00:53:28,335: time cost, forward:0.018010540413509274, backward:0.04322214435330398, data cost:0.6171294131348438 
2022-03-27 00:53:28,336: ============================================================
2022-03-27 00:53:28,336: Epoch 16/38 Batch 5700/7662 eta: 1 day, 7:27:43.074030	Training Loss 2.8992 (2.8886)	Training Prec@1 99.609 (99.533)	Training Prec@5 100.000 (99.854)	
2022-03-27 00:53:28,336: ============================================================
2022-03-27 00:54:32,176: time cost, forward:0.0180313051887824, backward:0.043262821864539086, data cost:0.6163595071803457 
2022-03-27 00:54:32,177: ============================================================
2022-03-27 00:54:32,177: Epoch 16/38 Batch 5800/7662 eta: 1 day, 6:13:22.243914	Training Loss 3.0077 (2.8908)	Training Prec@1 99.414 (99.531)	Training Prec@5 99.609 (99.853)	
2022-03-27 00:54:32,177: ============================================================
2022-03-27 00:55:38,617: time cost, forward:0.018037928062124686, backward:0.04322729011292497, data cost:0.6161471957533132 
2022-03-27 00:55:38,618: ============================================================
2022-03-27 00:55:38,618: Epoch 16/38 Batch 5900/7662 eta: 1 day, 7:26:07.318998	Training Loss 3.0351 (2.8926)	Training Prec@1 98.828 (99.529)	Training Prec@5 99.805 (99.853)	
2022-03-27 00:55:38,618: ============================================================
2022-03-27 00:56:41,735: time cost, forward:0.018025014257009753, backward:0.04322011833648758, data cost:0.6152991756118721 
2022-03-27 00:56:41,736: ============================================================
2022-03-27 00:56:41,736: Epoch 16/38 Batch 6000/7662 eta: 1 day, 5:50:43.896175	Training Loss 2.9182 (2.8942)	Training Prec@1 99.609 (99.526)	Training Prec@5 100.000 (99.852)	
2022-03-27 00:56:41,736: ============================================================
2022-03-27 00:57:42,487: time cost, forward:0.01802705451882771, backward:0.043205150249923406, data cost:0.6142232356295857 
2022-03-27 00:57:42,487: ============================================================
2022-03-27 00:57:42,487: Epoch 16/38 Batch 6100/7662 eta: 1 day, 4:42:33.948155	Training Loss 3.0498 (2.8963)	Training Prec@1 99.414 (99.523)	Training Prec@5 100.000 (99.851)	
2022-03-27 00:57:42,487: ============================================================
2022-03-27 00:58:45,303: time cost, forward:0.017964822781780184, backward:0.04312830695145975, data cost:0.6135633790621855 
2022-03-27 00:58:45,304: ============================================================
2022-03-27 00:58:45,305: Epoch 16/38 Batch 6200/7662 eta: 1 day, 5:40:06.199335	Training Loss 2.8678 (2.8976)	Training Prec@1 99.805 (99.521)	Training Prec@5 99.805 (99.851)	
2022-03-27 00:58:45,305: ============================================================
2022-03-27 00:59:48,993: time cost, forward:0.01795758855098731, backward:0.04313867450574217, data cost:0.6129656308491015 
2022-03-27 00:59:48,994: ============================================================
2022-03-27 00:59:48,994: Epoch 16/38 Batch 6300/7662 eta: 1 day, 6:03:45.949333	Training Loss 2.7791 (2.8989)	Training Prec@1 99.609 (99.520)	Training Prec@5 100.000 (99.850)	
2022-03-27 00:59:48,994: ============================================================
2022-03-27 01:00:52,437: time cost, forward:0.01793012382053066, backward:0.04310147571161326, data cost:0.612360854282251 
2022-03-27 01:00:52,437: ============================================================
2022-03-27 01:00:52,438: Epoch 16/38 Batch 6400/7662 eta: 1 day, 5:55:44.086733	Training Loss 2.9812 (2.9001)	Training Prec@1 99.219 (99.518)	Training Prec@5 99.609 (99.850)	
2022-03-27 01:00:52,438: ============================================================
2022-03-27 01:01:57,204: time cost, forward:0.017936821074866573, backward:0.0431163562299802, data cost:0.6118432380801293 
2022-03-27 01:01:57,206: ============================================================
2022-03-27 01:01:57,206: Epoch 16/38 Batch 6500/7662 eta: 1 day, 6:32:09.285758	Training Loss 3.2173 (2.9015)	Training Prec@1 98.828 (99.516)	Training Prec@5 99.414 (99.849)	
2022-03-27 01:01:57,207: ============================================================
2022-03-27 01:03:00,403: time cost, forward:0.017894301202770867, backward:0.04312208385643841, data cost:0.6113499596473357 
2022-03-27 01:03:00,403: ============================================================
2022-03-27 01:03:00,403: Epoch 16/38 Batch 6600/7662 eta: 1 day, 5:46:39.616864	Training Loss 2.7961 (2.9034)	Training Prec@1 99.219 (99.514)	Training Prec@5 99.805 (99.849)	
2022-03-27 01:03:00,403: ============================================================
2022-03-27 01:04:04,553: time cost, forward:0.01788681876323066, backward:0.043071385550310336, data cost:0.6109271809349738 
2022-03-27 01:04:04,554: ============================================================
2022-03-27 01:04:04,554: Epoch 16/38 Batch 6700/7662 eta: 1 day, 6:12:32.419044	Training Loss 2.9338 (2.9049)	Training Prec@1 99.609 (99.512)	Training Prec@5 100.000 (99.848)	
2022-03-27 01:04:04,554: ============================================================
2022-03-27 01:05:09,546: time cost, forward:0.017892125144147192, backward:0.04310872449929582, data cost:0.6105317825744355 
2022-03-27 01:05:09,546: ============================================================
2022-03-27 01:05:09,547: Epoch 16/38 Batch 6800/7662 eta: 1 day, 6:35:15.674812	Training Loss 2.8462 (2.9060)	Training Prec@1 100.000 (99.511)	Training Prec@5 100.000 (99.848)	
2022-03-27 01:05:09,547: ============================================================
2022-03-27 01:06:18,326: time cost, forward:0.017928379863081573, backward:0.04311712888172181, data cost:0.6106078036195351 
2022-03-27 01:06:18,328: ============================================================
2022-03-27 01:06:18,328: Epoch 16/38 Batch 6900/7662 eta: 1 day, 8:21:05.239702	Training Loss 2.8361 (2.9076)	Training Prec@1 99.609 (99.509)	Training Prec@5 99.609 (99.848)	
2022-03-27 01:06:18,328: ============================================================
2022-03-27 01:07:21,719: time cost, forward:0.017910812697865007, backward:0.04311838240636419, data cost:0.6101660254274476 
2022-03-27 01:07:21,736: ============================================================
2022-03-27 01:07:21,736: Epoch 16/38 Batch 7000/7662 eta: 1 day, 5:48:23.827742	Training Loss 3.0215 (2.9091)	Training Prec@1 99.609 (99.508)	Training Prec@5 100.000 (99.847)	
2022-03-27 01:07:21,736: ============================================================
2022-03-27 01:08:29,112: time cost, forward:0.017907434860607793, backward:0.043108767532163784, data cost:0.6101780384422137 
2022-03-27 01:08:29,113: ============================================================
2022-03-27 01:08:29,114: Epoch 16/38 Batch 7100/7662 eta: 1 day, 7:39:13.653394	Training Loss 2.8984 (2.9106)	Training Prec@1 99.414 (99.506)	Training Prec@5 99.609 (99.846)	
2022-03-27 01:08:29,114: ============================================================
2022-03-27 01:09:30,035: time cost, forward:0.017900293908991536, backward:0.043082182995891186, data cost:0.6093594286736225 
2022-03-27 01:09:30,036: ============================================================
2022-03-27 01:09:30,036: Epoch 16/38 Batch 7200/7662 eta: 1 day, 4:36:14.996352	Training Loss 3.1976 (2.9119)	Training Prec@1 99.609 (99.504)	Training Prec@5 99.609 (99.846)	
2022-03-27 01:09:30,036: ============================================================
2022-03-27 01:10:33,455: time cost, forward:0.017886200479031066, backward:0.04311931732664828, data cost:0.6088238233147394 
2022-03-27 01:10:33,455: ============================================================
2022-03-27 01:10:33,455: Epoch 16/38 Batch 7300/7662 eta: 1 day, 5:45:32.219954	Training Loss 3.0205 (2.9135)	Training Prec@1 99.414 (99.503)	Training Prec@5 100.000 (99.845)	
2022-03-27 01:10:33,455: ============================================================
2022-03-27 01:11:37,607: time cost, forward:0.01790225800670052, backward:0.04311558249383734, data cost:0.6083868185979867 
2022-03-27 01:11:37,608: ============================================================
2022-03-27 01:11:37,608: Epoch 16/38 Batch 7400/7662 eta: 1 day, 6:05:07.009508	Training Loss 2.9437 (2.9148)	Training Prec@1 99.219 (99.500)	Training Prec@5 99.805 (99.844)	
2022-03-27 01:11:37,608: ============================================================
2022-03-27 01:12:40,604: time cost, forward:0.017880513073841975, backward:0.04307709345580387, data cost:0.6078399645994466 
2022-03-27 01:12:40,607: ============================================================
2022-03-27 01:12:40,608: Epoch 16/38 Batch 7500/7662 eta: 1 day, 5:31:36.630192	Training Loss 3.1088 (2.9160)	Training Prec@1 99.609 (99.499)	Training Prec@5 99.805 (99.844)	
2022-03-27 01:12:40,608: ============================================================
2022-03-27 01:13:46,016: time cost, forward:0.017881801244788678, backward:0.04307121822027364, data cost:0.6076942153440712 
2022-03-27 01:13:46,017: ============================================================
2022-03-27 01:13:46,018: Epoch 16/38 Batch 7600/7662 eta: 1 day, 6:38:19.993080	Training Loss 3.0803 (2.9174)	Training Prec@1 99.609 (99.497)	Training Prec@5 100.000 (99.843)	
2022-03-27 01:13:46,018: ============================================================
2022-03-27 01:14:29,565: Epoch: 16/38 eta: 1 day, 6:37:38.784380	Training Loss 3.2577 (2.9178)	Training Prec@1 99.023 (99.496)	Training Prec@5 99.805 (99.843)
2022-03-27 01:14:29,566: ============================================================
2022-03-27 01:15:39,805: time cost, forward:0.0157115724351671, backward:0.03994647661844889, data cost:0.6451475138616081 
2022-03-27 01:15:39,806: ============================================================
2022-03-27 01:15:39,806: Epoch 17/38 Batch 100/7662 eta: 1 day, 8:44:49.563003	Training Loss 2.5264 (2.5340)	Training Prec@1 99.609 (99.682)	Training Prec@5 100.000 (99.891)	
2022-03-27 01:15:39,806: ============================================================
2022-03-27 01:16:39,725: time cost, forward:0.015400477989235117, backward:0.03735195452244437, data cost:0.5963403579577728 
2022-03-27 01:16:39,726: ============================================================
2022-03-27 01:16:39,726: Epoch 17/38 Batch 200/7662 eta: 1 day, 4:01:24.455849	Training Loss 2.5737 (2.5497)	Training Prec@1 99.023 (99.688)	Training Prec@5 99.609 (99.892)	
2022-03-27 01:16:39,726: ============================================================
2022-03-27 01:17:40,131: time cost, forward:0.015543216048275747, backward:0.03757685562439986, data cost:0.5808272856135034 
2022-03-27 01:17:40,132: ============================================================
2022-03-27 01:17:40,132: Epoch 17/38 Batch 300/7662 eta: 1 day, 4:14:02.087129	Training Loss 2.7540 (2.5634)	Training Prec@1 99.805 (99.692)	Training Prec@5 100.000 (99.898)	
2022-03-27 01:17:40,132: ============================================================
2022-03-27 01:18:43,217: time cost, forward:0.0157923680499084, backward:0.03709571463123599, data cost:0.5798957180558589 
2022-03-27 01:18:43,217: ============================================================
2022-03-27 01:18:43,218: Epoch 17/38 Batch 400/7662 eta: 1 day, 5:28:07.874614	Training Loss 2.6753 (2.5747)	Training Prec@1 99.219 (99.694)	Training Prec@5 99.609 (99.901)	
2022-03-27 01:18:43,218: ============================================================
2022-03-27 01:19:45,169: time cost, forward:0.015890475982176754, backward:0.038134621236032853, data cost:0.575756033819042 
2022-03-27 01:19:45,169: ============================================================
2022-03-27 01:19:45,169: Epoch 17/38 Batch 500/7662 eta: 1 day, 4:55:18.933826	Training Loss 2.7309 (2.5938)	Training Prec@1 99.414 (99.685)	Training Prec@5 100.000 (99.897)	
2022-03-27 01:19:45,169: ============================================================
2022-03-27 01:20:47,444: time cost, forward:0.015874143036856674, backward:0.0386508649498075, data cost:0.5730975597649066 
2022-03-27 01:20:47,446: ============================================================
2022-03-27 01:20:47,447: Epoch 17/38 Batch 600/7662 eta: 1 day, 5:03:23.054783	Training Loss 2.6323 (2.6100)	Training Prec@1 99.609 (99.677)	Training Prec@5 100.000 (99.895)	
2022-03-27 01:20:47,447: ============================================================
2022-03-27 01:21:48,442: time cost, forward:0.01587922753864774, backward:0.03893157238612359, data cost:0.5708072502725626 
2022-03-27 01:21:48,442: ============================================================
2022-03-27 01:21:48,443: Epoch 17/38 Batch 700/7662 eta: 1 day, 4:26:31.588247	Training Loss 2.7677 (2.6223)	Training Prec@1 99.805 (99.676)	Training Prec@5 99.805 (99.897)	
2022-03-27 01:21:48,443: ============================================================
2022-03-27 01:22:54,581: time cost, forward:0.016175983545926396, backward:0.03903347261259344, data cost:0.574349431132196 
2022-03-27 01:22:54,583: ============================================================
2022-03-27 01:22:54,584: Epoch 17/38 Batch 800/7662 eta: 1 day, 6:49:21.379507	Training Loss 2.7307 (2.6308)	Training Prec@1 100.000 (99.677)	Training Prec@5 100.000 (99.898)	
2022-03-27 01:22:54,584: ============================================================
2022-03-27 01:23:56,358: time cost, forward:0.016203639239437455, backward:0.0389812233981089, data cost:0.5731714257143761 
2022-03-27 01:23:56,358: ============================================================
2022-03-27 01:23:56,359: Epoch 17/38 Batch 900/7662 eta: 1 day, 4:46:15.332132	Training Loss 2.6032 (2.6427)	Training Prec@1 99.805 (99.675)	Training Prec@5 100.000 (99.899)	
2022-03-27 01:23:56,359: ============================================================
2022-03-27 01:24:57,252: time cost, forward:0.01622551816839117, backward:0.0389951525985061, data cost:0.5710445087593239 
2022-03-27 01:24:57,253: ============================================================
2022-03-27 01:24:57,253: Epoch 17/38 Batch 1000/7662 eta: 1 day, 4:20:37.436688	Training Loss 2.5849 (2.6535)	Training Prec@1 99.805 (99.674)	Training Prec@5 100.000 (99.898)	
2022-03-27 01:24:57,253: ============================================================
2022-03-27 01:25:59,367: time cost, forward:0.016243134768471272, backward:0.038779044389941675, data cost:0.5705550630272682 
2022-03-27 01:25:59,368: ============================================================
2022-03-27 01:25:59,368: Epoch 17/38 Batch 1100/7662 eta: 1 day, 4:53:41.420982	Training Loss 2.6601 (2.6625)	Training Prec@1 99.414 (99.666)	Training Prec@5 99.805 (99.894)	
2022-03-27 01:25:59,369: ============================================================
2022-03-27 01:27:03,741: time cost, forward:0.016264681024686607, backward:0.038727731879698024, data cost:0.5720363106699762 
2022-03-27 01:27:03,743: ============================================================
2022-03-27 01:27:03,745: Epoch 17/38 Batch 1200/7662 eta: 1 day, 5:55:43.420593	Training Loss 2.5473 (2.6702)	Training Prec@1 99.414 (99.665)	Training Prec@5 100.000 (99.898)	
2022-03-27 01:27:03,745: ============================================================
2022-03-27 01:28:09,472: time cost, forward:0.01635126208598289, backward:0.039062472285446154, data cost:0.5738649397652548 
2022-03-27 01:28:09,472: ============================================================
2022-03-27 01:28:09,472: Epoch 17/38 Batch 1300/7662 eta: 1 day, 6:32:19.539088	Training Loss 2.6692 (2.6784)	Training Prec@1 100.000 (99.662)	Training Prec@5 100.000 (99.898)	
2022-03-27 01:28:09,473: ============================================================
2022-03-27 01:29:09,064: time cost, forward:0.016393889010676833, backward:0.03891038383391178, data cost:0.57145271700054 
2022-03-27 01:29:09,064: ============================================================
2022-03-27 01:29:09,065: Epoch 17/38 Batch 1400/7662 eta: 1 day, 3:40:17.460221	Training Loss 2.6836 (2.6891)	Training Prec@1 99.805 (99.657)	Training Prec@5 100.000 (99.897)	
2022-03-27 01:29:09,065: ============================================================
2022-03-27 01:30:10,696: time cost, forward:0.01639888428146637, backward:0.038886915452485085, data cost:0.5707329571286863 
2022-03-27 01:30:10,696: ============================================================
2022-03-27 01:30:10,696: Epoch 17/38 Batch 1500/7662 eta: 1 day, 4:36:04.747936	Training Loss 2.9469 (2.6976)	Training Prec@1 99.219 (99.655)	Training Prec@5 99.805 (99.897)	
2022-03-27 01:30:10,696: ============================================================
2022-03-27 01:31:13,500: time cost, forward:0.016374363759072443, backward:0.03894443046755907, data cost:0.5702843918063776 
2022-03-27 01:31:13,500: ============================================================
2022-03-27 01:31:13,501: Epoch 17/38 Batch 1600/7662 eta: 1 day, 5:07:41.601270	Training Loss 2.8792 (2.7060)	Training Prec@1 99.219 (99.648)	Training Prec@5 99.805 (99.895)	
2022-03-27 01:31:13,501: ============================================================
2022-03-27 01:32:17,328: time cost, forward:0.01633195374698201, backward:0.03898119280940298, data cost:0.5714198583150485 
2022-03-27 01:32:17,328: ============================================================
2022-03-27 01:32:17,329: Epoch 17/38 Batch 1700/7662 eta: 1 day, 5:35:06.368730	Training Loss 2.7145 (2.7139)	Training Prec@1 99.219 (99.643)	Training Prec@5 99.805 (99.894)	
2022-03-27 01:32:17,329: ============================================================
2022-03-27 01:33:19,408: time cost, forward:0.016303870862162465, backward:0.03904624883833032, data cost:0.5709319487089843 
2022-03-27 01:33:19,409: ============================================================
2022-03-27 01:33:19,409: Epoch 17/38 Batch 1800/7662 eta: 1 day, 4:45:28.433912	Training Loss 2.8529 (2.7199)	Training Prec@1 100.000 (99.642)	Training Prec@5 100.000 (99.892)	
2022-03-27 01:33:19,409: ============================================================
2022-03-27 01:34:20,741: time cost, forward:0.01634377413765263, backward:0.03900328167116347, data cost:0.570178296830919 
2022-03-27 01:34:20,743: ============================================================
2022-03-27 01:34:20,744: Epoch 17/38 Batch 1900/7662 eta: 1 day, 4:23:43.266141	Training Loss 2.7689 (2.7273)	Training Prec@1 99.805 (99.637)	Training Prec@5 100.000 (99.890)	
2022-03-27 01:34:20,744: ============================================================
2022-03-27 01:35:23,626: time cost, forward:0.01641951578148846, backward:0.039029912748236605, data cost:0.5700503117206873 
2022-03-27 01:35:23,627: ============================================================
2022-03-27 01:35:23,627: Epoch 17/38 Batch 2000/7662 eta: 1 day, 5:05:41.798689	Training Loss 2.9132 (2.7339)	Training Prec@1 99.219 (99.634)	Training Prec@5 100.000 (99.889)	
2022-03-27 01:35:23,627: ============================================================
2022-03-27 01:36:26,385: time cost, forward:0.01653722776237586, backward:0.03918812523687834, data cost:0.5697561351954227 
2022-03-27 01:36:26,387: ============================================================
2022-03-27 01:36:26,388: Epoch 17/38 Batch 2100/7662 eta: 1 day, 5:01:14.997308	Training Loss 2.7673 (2.7398)	Training Prec@1 99.805 (99.632)	Training Prec@5 100.000 (99.889)	
2022-03-27 01:36:26,389: ============================================================
2022-03-27 01:37:28,740: time cost, forward:0.016494240637202867, backward:0.039090658546090395, data cost:0.5699472587831782 
2022-03-27 01:37:28,742: ============================================================
2022-03-27 01:37:28,743: Epoch 17/38 Batch 2200/7662 eta: 1 day, 4:48:55.817304	Training Loss 2.5627 (2.7449)	Training Prec@1 99.805 (99.630)	Training Prec@5 100.000 (99.889)	
2022-03-27 01:37:28,743: ============================================================
2022-03-27 01:38:31,790: time cost, forward:0.016548712702614682, backward:0.039102860874277244, data cost:0.570041800126038 
2022-03-27 01:38:31,790: ============================================================
2022-03-27 01:38:31,791: Epoch 17/38 Batch 2300/7662 eta: 1 day, 5:07:07.328980	Training Loss 2.9176 (2.7519)	Training Prec@1 98.438 (99.627)	Training Prec@5 99.805 (99.887)	
2022-03-27 01:38:31,791: ============================================================
2022-03-27 01:39:34,624: time cost, forward:0.01664271410329484, backward:0.03927749561836144, data cost:0.5698344329835574 
2022-03-27 01:39:34,624: ============================================================
2022-03-27 01:39:34,625: Epoch 17/38 Batch 2400/7662 eta: 1 day, 5:00:07.850455	Training Loss 2.8182 (2.7583)	Training Prec@1 99.609 (99.622)	Training Prec@5 100.000 (99.884)	
2022-03-27 01:39:34,625: ============================================================
2022-03-27 01:40:37,811: time cost, forward:0.016604491356326467, backward:0.039321047823731546, data cost:0.5699900018066919 
2022-03-27 01:40:37,812: ============================================================
2022-03-27 01:40:37,812: Epoch 17/38 Batch 2500/7662 eta: 1 day, 5:08:52.505191	Training Loss 2.8509 (2.7643)	Training Prec@1 100.000 (99.618)	Training Prec@5 100.000 (99.883)	
2022-03-27 01:40:37,813: ============================================================
2022-03-27 01:41:39,769: time cost, forward:0.01654451679568788, backward:0.0392857930806106, data cost:0.5697896967671752 
2022-03-27 01:41:39,771: ============================================================
2022-03-27 01:41:39,773: Epoch 17/38 Batch 2600/7662 eta: 1 day, 4:33:51.258798	Training Loss 2.8228 (2.7687)	Training Prec@1 100.000 (99.615)	Training Prec@5 100.000 (99.882)	
2022-03-27 01:41:39,774: ============================================================
2022-03-27 01:42:46,024: time cost, forward:0.016676565151207533, backward:0.03932886823277511, data cost:0.5706606261065025 
2022-03-27 01:42:46,027: ============================================================
2022-03-27 01:42:46,027: Epoch 17/38 Batch 2700/7662 eta: 1 day, 6:31:33.522178	Training Loss 2.8368 (2.7746)	Training Prec@1 99.805 (99.612)	Training Prec@5 99.805 (99.882)	
2022-03-27 01:42:46,027: ============================================================
2022-03-27 01:43:46,437: time cost, forward:0.016646318837718138, backward:0.03923322720883701, data cost:0.570224262808595 
2022-03-27 01:43:46,438: ============================================================
2022-03-27 01:43:46,438: Epoch 17/38 Batch 2800/7662 eta: 1 day, 3:49:00.851425	Training Loss 2.8251 (2.7796)	Training Prec@1 99.414 (99.609)	Training Prec@5 99.805 (99.881)	
2022-03-27 01:43:46,438: ============================================================
2022-03-27 01:44:46,898: time cost, forward:0.016737684540684448, backward:0.03923959672841667, data cost:0.5692943707545406 
2022-03-27 01:44:46,898: ============================================================
2022-03-27 01:44:46,898: Epoch 17/38 Batch 2900/7662 eta: 1 day, 3:49:21.524740	Training Loss 2.9771 (2.7845)	Training Prec@1 99.609 (99.608)	Training Prec@5 100.000 (99.879)	
2022-03-27 01:44:46,899: ============================================================
2022-03-27 01:45:50,302: time cost, forward:0.016723687826056766, backward:0.03928162026858481, data cost:0.5692666766245232 
2022-03-27 01:45:50,305: ============================================================
2022-03-27 01:45:50,306: Epoch 17/38 Batch 3000/7662 eta: 1 day, 5:09:39.650447	Training Loss 2.9389 (2.7881)	Training Prec@1 99.805 (99.606)	Training Prec@5 100.000 (99.880)	
2022-03-27 01:45:50,307: ============================================================
2022-03-27 01:46:54,117: time cost, forward:0.016764870994742664, backward:0.03925659588053366, data cost:0.5696401743013345 
2022-03-27 01:46:54,119: ============================================================
2022-03-27 01:46:54,120: Epoch 17/38 Batch 3100/7662 eta: 1 day, 5:19:49.463696	Training Loss 3.0338 (2.7923)	Training Prec@1 99.609 (99.603)	Training Prec@5 99.805 (99.879)	
2022-03-27 01:46:54,120: ============================================================
2022-03-27 01:47:54,713: time cost, forward:0.016778510002167235, backward:0.03926150833826283, data cost:0.5691490086886092 
2022-03-27 01:47:54,713: ============================================================
2022-03-27 01:47:54,714: Epoch 17/38 Batch 3200/7662 eta: 1 day, 3:50:01.830089	Training Loss 2.8971 (2.7970)	Training Prec@1 99.805 (99.599)	Training Prec@5 99.805 (99.876)	
2022-03-27 01:47:54,714: ============================================================
2022-03-27 01:48:59,414: time cost, forward:0.016801079463582936, backward:0.03940870177207408, data cost:0.5695958332641083 
2022-03-27 01:48:59,414: ============================================================
2022-03-27 01:48:59,415: Epoch 17/38 Batch 3300/7662 eta: 1 day, 5:42:08.314471	Training Loss 3.1296 (2.8013)	Training Prec@1 99.414 (99.598)	Training Prec@5 99.609 (99.875)	
2022-03-27 01:48:59,415: ============================================================
2022-03-27 01:50:04,247: time cost, forward:0.016816609184262893, backward:0.03952126357091739, data cost:0.5701373833423153 
2022-03-27 01:50:04,248: ============================================================
2022-03-27 01:50:04,248: Epoch 17/38 Batch 3400/7662 eta: 1 day, 5:44:41.839407	Training Loss 3.0083 (2.8054)	Training Prec@1 99.805 (99.595)	Training Prec@5 100.000 (99.874)	
2022-03-27 01:50:04,248: ============================================================
2022-03-27 01:51:05,138: time cost, forward:0.016782723825023528, backward:0.03955067692909557, data cost:0.5695971944530408 
2022-03-27 01:51:05,138: ============================================================
2022-03-27 01:51:05,138: Epoch 17/38 Batch 3500/7662 eta: 1 day, 3:55:08.698508	Training Loss 3.0015 (2.8087)	Training Prec@1 99.023 (99.592)	Training Prec@5 99.414 (99.873)	
2022-03-27 01:51:05,139: ============================================================
2022-03-27 01:52:10,198: time cost, forward:0.016800788482979754, backward:0.03956639650762992, data cost:0.5701909577988955 
2022-03-27 01:52:10,199: ============================================================
2022-03-27 01:52:10,199: Epoch 17/38 Batch 3600/7662 eta: 1 day, 5:48:47.266843	Training Loss 3.2167 (2.8115)	Training Prec@1 99.219 (99.590)	Training Prec@5 99.805 (99.873)	
2022-03-27 01:52:10,199: ============================================================
2022-03-27 01:53:11,096: time cost, forward:0.01678936627788394, backward:0.0395484312897471, data cost:0.5695378092631485 
2022-03-27 01:53:11,096: ============================================================
2022-03-27 01:53:11,097: Epoch 17/38 Batch 3700/7662 eta: 1 day, 3:53:19.028206	Training Loss 2.6583 (2.8155)	Training Prec@1 99.219 (99.587)	Training Prec@5 99.805 (99.871)	
2022-03-27 01:53:11,097: ============================================================
2022-03-27 01:54:10,301: time cost, forward:0.016776366747188142, backward:0.03942318463457293, data cost:0.5689522681596499 
2022-03-27 01:54:10,301: ============================================================
2022-03-27 01:54:10,301: Epoch 17/38 Batch 3800/7662 eta: 1 day, 3:05:48.408280	Training Loss 3.0036 (2.8190)	Training Prec@1 99.219 (99.583)	Training Prec@5 99.609 (99.870)	
2022-03-27 01:54:10,301: ============================================================
2022-03-27 01:55:12,732: time cost, forward:0.01679414356326592, backward:0.0394666885284009, data cost:0.5688463208858219 
2022-03-27 01:55:12,733: ============================================================
2022-03-27 01:55:12,733: Epoch 17/38 Batch 3900/7662 eta: 1 day, 4:33:23.278531	Training Loss 2.9812 (2.8222)	Training Prec@1 99.805 (99.580)	Training Prec@5 99.805 (99.869)	
2022-03-27 01:55:12,733: ============================================================
2022-03-27 01:56:15,486: time cost, forward:0.016745611261385445, backward:0.03940619060652767, data cost:0.5688670531127655 
2022-03-27 01:56:15,486: ============================================================
2022-03-27 01:56:15,486: Epoch 17/38 Batch 4000/7662 eta: 1 day, 4:41:10.107351	Training Loss 2.9522 (2.8253)	Training Prec@1 99.609 (99.578)	Training Prec@5 99.805 (99.869)	
2022-03-27 01:56:15,487: ============================================================
2022-03-27 01:57:20,438: time cost, forward:0.01674464680154488, backward:0.03949903563541097, data cost:0.5692408350102056 
2022-03-27 01:57:20,439: ============================================================
2022-03-27 01:57:20,439: Epoch 17/38 Batch 4100/7662 eta: 1 day, 5:40:24.371233	Training Loss 2.8039 (2.8281)	Training Prec@1 99.219 (99.575)	Training Prec@5 99.609 (99.868)	
2022-03-27 01:57:20,439: ============================================================
2022-03-27 01:58:21,407: time cost, forward:0.016709234805923612, backward:0.03945397859415743, data cost:0.5689248285795513 
2022-03-27 01:58:21,409: ============================================================
2022-03-27 01:58:21,409: Epoch 17/38 Batch 4200/7662 eta: 1 day, 3:50:12.866768	Training Loss 3.0678 (2.8315)	Training Prec@1 99.805 (99.573)	Training Prec@5 100.000 (99.868)	
2022-03-27 01:58:21,409: ============================================================
2022-03-27 01:59:24,134: time cost, forward:0.01671758217156058, backward:0.03940869786346145, data cost:0.5691608545197308 
2022-03-27 01:59:24,134: ============================================================
2022-03-27 01:59:24,134: Epoch 17/38 Batch 4300/7662 eta: 1 day, 4:37:15.787794	Training Loss 3.0588 (2.8344)	Training Prec@1 99.023 (99.570)	Training Prec@5 99.414 (99.867)	
2022-03-27 01:59:24,134: ============================================================
2022-03-27 02:00:27,351: time cost, forward:0.016729169716805756, backward:0.039422457910283204, data cost:0.5690974636927711 
2022-03-27 02:00:27,353: ============================================================
2022-03-27 02:00:27,354: Epoch 17/38 Batch 4400/7662 eta: 1 day, 4:49:44.695423	Training Loss 2.9199 (2.8372)	Training Prec@1 99.414 (99.568)	Training Prec@5 99.609 (99.866)	
2022-03-27 02:00:27,355: ============================================================
2022-03-27 02:01:28,439: time cost, forward:0.01668379587129795, backward:0.039336455241922114, data cost:0.5690516057770155 
2022-03-27 02:01:28,439: ============================================================
2022-03-27 02:01:28,440: Epoch 17/38 Batch 4500/7662 eta: 1 day, 3:50:20.082043	Training Loss 2.8380 (2.8398)	Training Prec@1 99.609 (99.566)	Training Prec@5 99.805 (99.865)	
2022-03-27 02:01:28,440: ============================================================
2022-03-27 02:02:30,250: time cost, forward:0.016674342687349263, backward:0.039308395248880905, data cost:0.5687646171170023 
2022-03-27 02:02:30,253: ============================================================
2022-03-27 02:02:30,254: Epoch 17/38 Batch 4600/7662 eta: 1 day, 4:09:13.371442	Training Loss 3.0556 (2.8425)	Training Prec@1 99.609 (99.563)	Training Prec@5 99.805 (99.864)	
2022-03-27 02:02:30,255: ============================================================
2022-03-27 02:03:33,181: time cost, forward:0.016651943506751067, backward:0.0392854036638447, data cost:0.5689186937734405 
2022-03-27 02:03:33,182: ============================================================
2022-03-27 02:03:33,182: Epoch 17/38 Batch 4700/7662 eta: 1 day, 4:38:37.512552	Training Loss 2.9881 (2.8448)	Training Prec@1 99.414 (99.562)	Training Prec@5 100.000 (99.863)	
2022-03-27 02:03:33,182: ============================================================
2022-03-27 02:04:31,378: time cost, forward:0.01660058408460162, backward:0.03921767457571346, data cost:0.5682057607519202 
2022-03-27 02:04:31,379: ============================================================
2022-03-27 02:04:31,379: Epoch 17/38 Batch 4800/7662 eta: 1 day, 2:28:26.125385	Training Loss 2.9087 (2.8473)	Training Prec@1 99.023 (99.559)	Training Prec@5 99.023 (99.863)	
2022-03-27 02:04:31,379: ============================================================
2022-03-27 02:05:34,787: time cost, forward:0.01657709843724522, backward:0.03925693991428055, data cost:0.5683951981823453 
2022-03-27 02:05:34,788: ============================================================
2022-03-27 02:05:34,788: Epoch 17/38 Batch 4900/7662 eta: 1 day, 4:49:38.608962	Training Loss 3.0065 (2.8497)	Training Prec@1 100.000 (99.557)	Training Prec@5 100.000 (99.862)	
2022-03-27 02:05:34,788: ============================================================
2022-03-27 02:06:35,725: time cost, forward:0.016558554630848044, backward:0.03921378720018906, data cost:0.568123946263328 
2022-03-27 02:06:35,726: ============================================================
2022-03-27 02:06:35,726: Epoch 17/38 Batch 5000/7662 eta: 1 day, 3:41:13.319584	Training Loss 3.0051 (2.8521)	Training Prec@1 99.023 (99.555)	Training Prec@5 99.805 (99.861)	
2022-03-27 02:06:35,726: ============================================================
2022-03-27 02:07:39,541: time cost, forward:0.016577162633201237, backward:0.03920586423842106, data cost:0.568371833130574 
2022-03-27 02:07:39,542: ============================================================
2022-03-27 02:07:39,542: Epoch 17/38 Batch 5100/7662 eta: 1 day, 4:58:37.011836	Training Loss 2.8211 (2.8544)	Training Prec@1 99.023 (99.552)	Training Prec@5 100.000 (99.860)	
2022-03-27 02:07:39,543: ============================================================
2022-03-27 02:08:38,813: time cost, forward:0.01657099168010344, backward:0.03919914420418245, data cost:0.567753734073173 
2022-03-27 02:08:38,814: ============================================================
2022-03-27 02:08:38,814: Epoch 17/38 Batch 5200/7662 eta: 1 day, 2:53:49.587632	Training Loss 2.8533 (2.8566)	Training Prec@1 99.805 (99.551)	Training Prec@5 99.805 (99.859)	
2022-03-27 02:08:38,815: ============================================================
2022-03-27 02:09:41,384: time cost, forward:0.016588602229815022, backward:0.039227055972377, data cost:0.5676986926860417 
2022-03-27 02:09:41,387: ============================================================
2022-03-27 02:09:41,387: Epoch 17/38 Batch 5300/7662 eta: 1 day, 4:22:39.678364	Training Loss 3.0316 (2.8591)	Training Prec@1 99.023 (99.549)	Training Prec@5 100.000 (99.859)	
2022-03-27 02:09:41,388: ============================================================
2022-03-27 02:10:48,736: time cost, forward:0.016598899754402173, backward:0.03929841873888219, data cost:0.5684635117222234 
2022-03-27 02:10:48,736: ============================================================
2022-03-27 02:10:48,737: Epoch 17/38 Batch 5400/7662 eta: 1 day, 6:31:31.248054	Training Loss 2.8621 (2.8613)	Training Prec@1 99.805 (99.546)	Training Prec@5 100.000 (99.858)	
2022-03-27 02:10:48,737: ============================================================
2022-03-27 02:11:47,692: time cost, forward:0.01657867392619581, backward:0.03927931258365834, data cost:0.567850581557778 
2022-03-27 02:11:47,692: ============================================================
2022-03-27 02:11:47,692: Epoch 17/38 Batch 5500/7662 eta: 1 day, 2:42:15.623771	Training Loss 3.0236 (2.8632)	Training Prec@1 99.805 (99.545)	Training Prec@5 100.000 (99.858)	
2022-03-27 02:11:47,693: ============================================================
2022-03-27 02:12:50,725: time cost, forward:0.01656190785665047, backward:0.0392860769267422, data cost:0.5680161394973294 
2022-03-27 02:12:50,726: ============================================================
2022-03-27 02:12:50,726: Epoch 17/38 Batch 5600/7662 eta: 1 day, 4:32:02.841213	Training Loss 2.8761 (2.8651)	Training Prec@1 99.414 (99.542)	Training Prec@5 100.000 (99.857)	
2022-03-27 02:12:50,726: ============================================================
2022-03-27 02:13:52,051: time cost, forward:0.01654731237923896, backward:0.039270221360797816, data cost:0.5678026256989671 
2022-03-27 02:13:52,052: ============================================================
2022-03-27 02:13:52,052: Epoch 17/38 Batch 5700/7662 eta: 1 day, 3:44:38.522295	Training Loss 2.8733 (2.8673)	Training Prec@1 99.609 (99.541)	Training Prec@5 99.609 (99.856)	
2022-03-27 02:13:52,052: ============================================================
2022-03-27 02:14:54,480: time cost, forward:0.016531666551587665, backward:0.03925712989679512, data cost:0.5677132359001632 
2022-03-27 02:14:54,482: ============================================================
2022-03-27 02:14:54,483: Epoch 17/38 Batch 5800/7662 eta: 1 day, 4:13:35.425198	Training Loss 3.0062 (2.8690)	Training Prec@1 99.414 (99.539)	Training Prec@5 99.805 (99.856)	
2022-03-27 02:14:54,484: ============================================================
2022-03-27 02:16:00,494: time cost, forward:0.016539526220135093, backward:0.03932363058595582, data cost:0.5682469969140127 
2022-03-27 02:16:00,496: ============================================================
2022-03-27 02:16:00,497: Epoch 17/38 Batch 5900/7662 eta: 1 day, 5:49:41.326674	Training Loss 3.0311 (2.8713)	Training Prec@1 99.219 (99.537)	Training Prec@5 100.000 (99.854)	
2022-03-27 02:16:00,498: ============================================================
2022-03-27 02:17:03,027: time cost, forward:0.01653631306982255, backward:0.03933029934691874, data cost:0.5682788157904222 
2022-03-27 02:17:03,027: ============================================================
2022-03-27 02:17:03,028: Epoch 17/38 Batch 6000/7662 eta: 1 day, 4:14:13.570759	Training Loss 3.2087 (2.8731)	Training Prec@1 99.414 (99.536)	Training Prec@5 99.609 (99.854)	
2022-03-27 02:17:03,028: ============================================================
2022-03-27 02:18:03,017: time cost, forward:0.016524078572728747, backward:0.03927767001169395, data cost:0.5680069775244392 
2022-03-27 02:18:03,017: ============================================================
2022-03-27 02:18:03,018: Epoch 17/38 Batch 6100/7662 eta: 1 day, 3:04:22.444025	Training Loss 2.9264 (2.8749)	Training Prec@1 99.219 (99.535)	Training Prec@5 99.805 (99.854)	
2022-03-27 02:18:03,018: ============================================================
2022-03-27 02:19:08,093: time cost, forward:0.016514125880281238, backward:0.0392785391166799, data cost:0.5684400386321081 
2022-03-27 02:19:08,094: ============================================================
2022-03-27 02:19:08,094: Epoch 17/38 Batch 6200/7662 eta: 1 day, 5:21:01.136278	Training Loss 2.8984 (2.8765)	Training Prec@1 99.414 (99.533)	Training Prec@5 100.000 (99.853)	
2022-03-27 02:19:08,094: ============================================================
2022-03-27 02:20:07,329: time cost, forward:0.01647137524419634, backward:0.039227805945358116, data cost:0.5678890305183145 
2022-03-27 02:20:07,330: ============================================================
2022-03-27 02:20:07,330: Epoch 17/38 Batch 6300/7662 eta: 1 day, 2:41:59.546964	Training Loss 2.8332 (2.8781)	Training Prec@1 99.414 (99.531)	Training Prec@5 99.805 (99.852)	
2022-03-27 02:20:07,330: ============================================================
2022-03-27 02:21:10,581: time cost, forward:0.01645545345448874, backward:0.039271375353885155, data cost:0.5680975925924256 
2022-03-27 02:21:10,581: ============================================================
2022-03-27 02:21:10,582: Epoch 17/38 Batch 6400/7662 eta: 1 day, 4:29:32.224346	Training Loss 2.8316 (2.8798)	Training Prec@1 99.414 (99.530)	Training Prec@5 99.805 (99.852)	
2022-03-27 02:21:10,582: ============================================================
2022-03-27 02:22:14,781: time cost, forward:0.016441999242606208, backward:0.039297082164064155, data cost:0.5682851779935983 
2022-03-27 02:22:14,782: ============================================================
2022-03-27 02:22:14,782: Epoch 17/38 Batch 6500/7662 eta: 1 day, 4:54:05.861451	Training Loss 2.8983 (2.8810)	Training Prec@1 99.414 (99.529)	Training Prec@5 99.805 (99.852)	
2022-03-27 02:22:14,782: ============================================================
2022-03-27 02:23:15,061: time cost, forward:0.016424743383829297, backward:0.039281545145653615, data cost:0.5680294842191819 
2022-03-27 02:23:15,062: ============================================================
2022-03-27 02:23:15,062: Epoch 17/38 Batch 6600/7662 eta: 1 day, 3:07:12.972676	Training Loss 2.7687 (2.8825)	Training Prec@1 100.000 (99.528)	Training Prec@5 100.000 (99.851)	
2022-03-27 02:23:15,062: ============================================================
2022-03-27 02:24:19,489: time cost, forward:0.01646891574856772, backward:0.039307003431239045, data cost:0.5681951432143384 
2022-03-27 02:24:19,489: ============================================================
2022-03-27 02:24:19,490: Epoch 17/38 Batch 6700/7662 eta: 1 day, 4:58:05.376073	Training Loss 3.0286 (2.8840)	Training Prec@1 99.219 (99.526)	Training Prec@5 99.609 (99.851)	
2022-03-27 02:24:19,490: ============================================================
2022-03-27 02:25:18,661: time cost, forward:0.016443953582128544, backward:0.039302106814658684, data cost:0.5677121774048153 
2022-03-27 02:25:18,663: ============================================================
2022-03-27 02:25:18,663: Epoch 17/38 Batch 6800/7662 eta: 1 day, 2:35:21.965321	Training Loss 3.0955 (2.8855)	Training Prec@1 100.000 (99.525)	Training Prec@5 100.000 (99.851)	
2022-03-27 02:25:18,664: ============================================================
2022-03-27 02:26:23,066: time cost, forward:0.016426230568974964, backward:0.039283611062886595, data cost:0.568026849404161 
2022-03-27 02:26:23,067: ============================================================
2022-03-27 02:26:23,067: Epoch 17/38 Batch 6900/7662 eta: 1 day, 4:55:19.259734	Training Loss 2.9406 (2.8867)	Training Prec@1 99.023 (99.523)	Training Prec@5 99.414 (99.850)	
2022-03-27 02:26:23,068: ============================================================
2022-03-27 02:27:24,555: time cost, forward:0.016427173531384176, backward:0.039304399204213275, data cost:0.5679385835127347 
2022-03-27 02:27:24,556: ============================================================
2022-03-27 02:27:24,556: Epoch 17/38 Batch 7000/7662 eta: 1 day, 3:35:44.208384	Training Loss 2.9622 (2.8881)	Training Prec@1 99.414 (99.521)	Training Prec@5 100.000 (99.849)	
2022-03-27 02:27:24,556: ============================================================
2022-03-27 02:28:25,296: time cost, forward:0.016424537830108287, backward:0.039241632754944765, data cost:0.5677517890459989 
2022-03-27 02:28:25,297: ============================================================
2022-03-27 02:28:25,297: Epoch 17/38 Batch 7100/7662 eta: 1 day, 3:14:35.782767	Training Loss 3.0717 (2.8895)	Training Prec@1 99.414 (99.519)	Training Prec@5 99.609 (99.848)	
2022-03-27 02:28:25,298: ============================================================
2022-03-27 02:29:26,892: time cost, forward:0.016406680928582797, backward:0.039251397924135754, data cost:0.5676505122520573 
2022-03-27 02:29:26,893: ============================================================
2022-03-27 02:29:26,893: Epoch 17/38 Batch 7200/7662 eta: 1 day, 3:36:33.675513	Training Loss 2.9884 (2.8911)	Training Prec@1 99.609 (99.517)	Training Prec@5 99.609 (99.848)	
2022-03-27 02:29:26,893: ============================================================
2022-03-27 02:30:33,831: time cost, forward:0.016429381136012937, backward:0.03929650909297351, data cost:0.5681891530519447 
2022-03-27 02:30:33,832: ============================================================
2022-03-27 02:30:33,833: Epoch 17/38 Batch 7300/7662 eta: 1 day, 5:59:10.177838	Training Loss 3.0315 (2.8922)	Training Prec@1 99.023 (99.515)	Training Prec@5 100.000 (99.847)	
2022-03-27 02:30:33,833: ============================================================
2022-03-27 02:31:31,868: time cost, forward:0.01641694402868707, backward:0.03929593437732047, data cost:0.5675398380567229 
2022-03-27 02:31:31,869: ============================================================
2022-03-27 02:31:31,869: Epoch 17/38 Batch 7400/7662 eta: 1 day, 1:58:54.491759	Training Loss 2.9442 (2.8933)	Training Prec@1 99.414 (99.515)	Training Prec@5 99.805 (99.847)	
2022-03-27 02:31:31,869: ============================================================
2022-03-27 02:32:34,533: time cost, forward:0.01640739023152916, backward:0.03931700685752648, data cost:0.5676186262472326 
2022-03-27 02:32:34,534: ============================================================
2022-03-27 02:32:34,534: Epoch 17/38 Batch 7500/7662 eta: 1 day, 4:02:11.300395	Training Loss 3.0002 (2.8944)	Training Prec@1 99.414 (99.513)	Training Prec@5 99.805 (99.847)	
2022-03-27 02:32:34,534: ============================================================
2022-03-27 02:33:37,691: time cost, forward:0.016400308416993827, backward:0.03928608222295774, data cost:0.5677505567962048 
2022-03-27 02:33:37,691: ============================================================
2022-03-27 02:33:37,692: Epoch 17/38 Batch 7600/7662 eta: 1 day, 4:14:22.127320	Training Loss 2.8697 (2.8956)	Training Prec@1 100.000 (99.512)	Training Prec@5 100.000 (99.846)	
2022-03-27 02:33:37,692: ============================================================
2022-03-27 02:34:14,000: Epoch: 17/38 eta: 1 day, 4:13:42.337838	Training Loss 2.8750 (2.8963)	Training Prec@1 99.609 (99.510)	Training Prec@5 99.609 (99.845)
2022-03-27 02:34:14,000: ============================================================
2022-03-27 02:35:18,170: time cost, forward:0.015494996851140802, backward:0.038896666632758245, data cost:0.5762115247321852 
2022-03-27 02:35:18,173: ============================================================
2022-03-27 02:35:18,174: Epoch 18/38 Batch 100/7662 eta: 1 day, 4:33:57.497338	Training Loss 2.4576 (2.5146)	Training Prec@1 99.414 (99.722)	Training Prec@5 100.000 (99.921)	
2022-03-27 02:35:18,174: ============================================================
2022-03-27 02:36:23,238: time cost, forward:0.01602336150317935, backward:0.04213901141181064, data cost:0.5867614758074583 
2022-03-27 02:36:23,238: ============================================================
2022-03-27 02:36:23,238: Epoch 18/38 Batch 200/7662 eta: 1 day, 5:02:41.651872	Training Loss 2.4064 (2.5260)	Training Prec@1 99.609 (99.718)	Training Prec@5 100.000 (99.921)	
2022-03-27 02:36:23,239: ============================================================
2022-03-27 02:37:26,036: time cost, forward:0.015044249021089993, backward:0.04072741600980727, data cost:0.5801560161105765 
2022-03-27 02:37:26,040: ============================================================
2022-03-27 02:37:26,041: Epoch 18/38 Batch 300/7662 eta: 1 day, 4:01:02.759973	Training Loss 2.6419 (2.5445)	Training Prec@1 99.805 (99.726)	Training Prec@5 100.000 (99.920)	
2022-03-27 02:37:26,042: ============================================================
2022-03-27 02:38:25,614: time cost, forward:0.01503639292896242, backward:0.0402150763604874, data cost:0.570531754266648 
2022-03-27 02:38:25,618: ============================================================
2022-03-27 02:38:25,619: Epoch 18/38 Batch 400/7662 eta: 1 day, 2:33:44.284585	Training Loss 2.4950 (2.5634)	Training Prec@1 100.000 (99.720)	Training Prec@5 100.000 (99.923)	
2022-03-27 02:38:25,620: ============================================================
2022-03-27 02:39:25,444: time cost, forward:0.015072187584244416, backward:0.039657654408701434, data cost:0.5668107063354615 
2022-03-27 02:39:25,445: ============================================================
2022-03-27 02:39:25,445: Epoch 18/38 Batch 500/7662 eta: 1 day, 2:39:23.408531	Training Loss 2.7367 (2.5713)	Training Prec@1 99.805 (99.713)	Training Prec@5 99.805 (99.919)	
2022-03-27 02:39:25,445: ============================================================
2022-03-27 02:40:24,893: time cost, forward:0.015477059878570608, backward:0.038772587386116955, data cost:0.5627264072978636 
2022-03-27 02:40:24,893: ============================================================
2022-03-27 02:40:24,894: Epoch 18/38 Batch 600/7662 eta: 1 day, 2:28:17.241146	Training Loss 2.6089 (2.5825)	Training Prec@1 99.609 (99.714)	Training Prec@5 100.000 (99.922)	
2022-03-27 02:40:24,894: ============================================================
2022-03-27 02:41:23,880: time cost, forward:0.015401993016146113, backward:0.038538658567764214, data cost:0.5589175841668474 
2022-03-27 02:41:23,880: ============================================================
2022-03-27 02:41:23,880: Epoch 18/38 Batch 700/7662 eta: 1 day, 2:14:58.414586	Training Loss 2.6087 (2.5890)	Training Prec@1 99.805 (99.718)	Training Prec@5 100.000 (99.924)	
2022-03-27 02:41:23,880: ============================================================
2022-03-27 02:42:30,193: time cost, forward:0.015421332047788313, backward:0.03942223156199736, data cost:0.5641315072886786 
2022-03-27 02:42:30,193: ============================================================
2022-03-27 02:42:30,193: Epoch 18/38 Batch 800/7662 eta: 1 day, 5:29:29.494354	Training Loss 2.5581 (2.6003)	Training Prec@1 99.805 (99.711)	Training Prec@5 100.000 (99.921)	
2022-03-27 02:42:30,194: ============================================================
2022-03-27 02:43:28,679: time cost, forward:0.015267093401729596, backward:0.03917595409312689, data cost:0.5603401483232373 
2022-03-27 02:43:28,680: ============================================================
2022-03-27 02:43:28,680: Epoch 18/38 Batch 900/7662 eta: 1 day, 1:59:39.809398	Training Loss 2.6657 (2.6123)	Training Prec@1 99.609 (99.703)	Training Prec@5 100.000 (99.919)	
2022-03-27 02:43:28,680: ============================================================
2022-03-27 02:44:28,295: time cost, forward:0.015387696666163844, backward:0.03894853591918945, data cost:0.558412374318899 
2022-03-27 02:44:28,295: ============================================================
2022-03-27 02:44:28,296: Epoch 18/38 Batch 1000/7662 eta: 1 day, 2:28:47.511993	Training Loss 2.5276 (2.6239)	Training Prec@1 99.805 (99.695)	Training Prec@5 100.000 (99.916)	
2022-03-27 02:44:28,296: ============================================================
2022-03-27 02:45:31,081: time cost, forward:0.015272328808049487, backward:0.03904708457925951, data cost:0.5599733906729423 
2022-03-27 02:45:31,081: ============================================================
2022-03-27 02:45:31,081: Epoch 18/38 Batch 1100/7662 eta: 1 day, 3:52:13.465069	Training Loss 2.7281 (2.6388)	Training Prec@1 99.805 (99.687)	Training Prec@5 100.000 (99.911)	
2022-03-27 02:45:31,081: ============================================================
2022-03-27 02:46:30,703: time cost, forward:0.01519777041062203, backward:0.03867388527228297, data cost:0.5587207640678908 
2022-03-27 02:46:30,703: ============================================================
2022-03-27 02:46:30,704: Epoch 18/38 Batch 1200/7662 eta: 1 day, 2:26:58.594771	Training Loss 2.8099 (2.6493)	Training Prec@1 99.414 (99.683)	Training Prec@5 99.805 (99.910)	
2022-03-27 02:46:30,704: ============================================================
2022-03-27 02:47:31,458: time cost, forward:0.015209212497714118, backward:0.0388294982396244, data cost:0.5579945659343787 
2022-03-27 02:47:31,459: ============================================================
2022-03-27 02:47:31,459: Epoch 18/38 Batch 1300/7662 eta: 1 day, 2:56:07.818830	Training Loss 2.8258 (2.6597)	Training Prec@1 100.000 (99.685)	Training Prec@5 100.000 (99.909)	
2022-03-27 02:47:31,460: ============================================================
2022-03-27 02:48:29,860: time cost, forward:0.015078539504077794, backward:0.03858148327378225, data cost:0.5563642746896041 
2022-03-27 02:48:29,861: ============================================================
2022-03-27 02:48:29,861: Epoch 18/38 Batch 1400/7662 eta: 1 day, 1:52:32.399315	Training Loss 2.6193 (2.6694)	Training Prec@1 99.414 (99.679)	Training Prec@5 99.805 (99.908)	
2022-03-27 02:48:29,861: ============================================================
2022-03-27 02:49:31,067: time cost, forward:0.01501330508638653, backward:0.03870072501591637, data cost:0.5561071678031835 
2022-03-27 02:49:31,072: ============================================================
2022-03-27 02:49:31,073: Epoch 18/38 Batch 1500/7662 eta: 1 day, 3:06:12.204859	Training Loss 2.8421 (2.6792)	Training Prec@1 99.414 (99.672)	Training Prec@5 100.000 (99.906)	
2022-03-27 02:49:31,073: ============================================================
2022-03-27 02:50:35,452: time cost, forward:0.015260446511483923, backward:0.03908812574776655, data cost:0.5571726199013506 
2022-03-27 02:50:35,454: ============================================================
2022-03-27 02:50:35,455: Epoch 18/38 Batch 1600/7662 eta: 1 day, 4:29:23.166133	Training Loss 2.8841 (2.6878)	Training Prec@1 99.414 (99.667)	Training Prec@5 99.609 (99.905)	
2022-03-27 02:50:35,455: ============================================================
2022-03-27 02:51:33,134: time cost, forward:0.015091510293342002, backward:0.03881565313468336, data cost:0.555987292840384 
2022-03-27 02:51:33,135: ============================================================
2022-03-27 02:51:33,135: Epoch 18/38 Batch 1700/7662 eta: 1 day, 1:30:29.232218	Training Loss 2.7620 (2.6960)	Training Prec@1 99.805 (99.664)	Training Prec@5 99.805 (99.903)	
2022-03-27 02:51:33,136: ============================================================
2022-03-27 02:52:32,924: time cost, forward:0.01510757920210596, backward:0.0386818467808671, data cost:0.5553629781353003 
2022-03-27 02:52:32,925: ============================================================
2022-03-27 02:52:32,925: Epoch 18/38 Batch 1800/7662 eta: 1 day, 2:25:27.796301	Training Loss 2.7934 (2.7023)	Training Prec@1 99.414 (99.660)	Training Prec@5 99.805 (99.903)	
2022-03-27 02:52:32,926: ============================================================
2022-03-27 02:53:34,264: time cost, forward:0.015115902259388744, backward:0.03876668217936712, data cost:0.555340536774429 
2022-03-27 02:53:34,265: ============================================================
2022-03-27 02:53:34,265: Epoch 18/38 Batch 1900/7662 eta: 1 day, 3:05:31.575353	Training Loss 2.7699 (2.7098)	Training Prec@1 99.805 (99.657)	Training Prec@5 99.805 (99.901)	
2022-03-27 02:53:34,265: ============================================================
2022-03-27 02:54:37,449: time cost, forward:0.015185151951738808, backward:0.038734818053519866, data cost:0.5561931368230044 
2022-03-27 02:54:37,451: ============================================================
2022-03-27 02:54:37,452: Epoch 18/38 Batch 2000/7662 eta: 1 day, 3:53:26.289469	Training Loss 2.8667 (2.7173)	Training Prec@1 99.805 (99.654)	Training Prec@5 99.805 (99.900)	
2022-03-27 02:54:37,453: ============================================================
2022-03-27 02:55:37,547: time cost, forward:0.01516946614952869, backward:0.03862080533144416, data cost:0.5560579796300836 
2022-03-27 02:55:37,547: ============================================================
2022-03-27 02:55:37,548: Epoch 18/38 Batch 2100/7662 eta: 1 day, 2:30:33.766939	Training Loss 2.9315 (2.7238)	Training Prec@1 99.805 (99.649)	Training Prec@5 100.000 (99.898)	
2022-03-27 02:55:37,548: ============================================================
2022-03-27 02:56:37,549: time cost, forward:0.015162720144635279, backward:0.038594315517160124, data cost:0.5555477816714868 
2022-03-27 02:56:37,550: ============================================================
2022-03-27 02:56:37,550: Epoch 18/38 Batch 2200/7662 eta: 1 day, 2:27:05.505450	Training Loss 2.7611 (2.7286)	Training Prec@1 99.219 (99.647)	Training Prec@5 100.000 (99.896)	
2022-03-27 02:56:37,550: ============================================================
2022-03-27 02:57:38,368: time cost, forward:0.015182716424385326, backward:0.03866445992292659, data cost:0.5554074801378222 
2022-03-27 02:57:38,368: ============================================================
2022-03-27 02:57:38,369: Epoch 18/38 Batch 2300/7662 eta: 1 day, 2:47:40.058266	Training Loss 2.8599 (2.7355)	Training Prec@1 99.805 (99.642)	Training Prec@5 99.805 (99.893)	
2022-03-27 02:57:38,369: ============================================================
2022-03-27 02:58:39,807: time cost, forward:0.015210942359405937, backward:0.03867765246157151, data cost:0.5554891392905397 
2022-03-27 02:58:39,807: ============================================================
2022-03-27 02:58:39,808: Epoch 18/38 Batch 2400/7662 eta: 1 day, 3:03:03.052904	Training Loss 3.0017 (2.7410)	Training Prec@1 98.828 (99.639)	Training Prec@5 99.805 (99.892)	
2022-03-27 02:58:39,808: ============================================================
2022-03-27 02:59:41,825: time cost, forward:0.015220635125235396, backward:0.03889165729844794, data cost:0.5556790289663228 
2022-03-27 02:59:41,825: ============================================================
2022-03-27 02:59:41,825: Epoch 18/38 Batch 2500/7662 eta: 1 day, 3:17:17.474659	Training Loss 2.6980 (2.7464)	Training Prec@1 99.805 (99.635)	Training Prec@5 99.805 (99.891)	
2022-03-27 02:59:41,826: ============================================================
2022-03-27 03:00:42,324: time cost, forward:0.015297392231998833, backward:0.03897172435057443, data cost:0.5552546097343359 
2022-03-27 03:00:42,324: ============================================================
2022-03-27 03:00:42,325: Epoch 18/38 Batch 2600/7662 eta: 1 day, 2:36:12.467684	Training Loss 3.0348 (2.7510)	Training Prec@1 99.023 (99.632)	Training Prec@5 99.805 (99.889)	
2022-03-27 03:00:42,325: ============================================================
2022-03-27 03:01:42,444: time cost, forward:0.015356948438420389, backward:0.03904785090528094, data cost:0.5544936034183848 
2022-03-27 03:01:42,445: ============================================================
2022-03-27 03:01:42,445: Epoch 18/38 Batch 2700/7662 eta: 1 day, 2:25:11.909712	Training Loss 2.8428 (2.7557)	Training Prec@1 99.805 (99.629)	Training Prec@5 100.000 (99.887)	
2022-03-27 03:01:42,445: ============================================================
2022-03-27 03:02:47,844: time cost, forward:0.015386737129781109, backward:0.03912267705379703, data cost:0.5562371061971759 
2022-03-27 03:02:47,845: ============================================================
2022-03-27 03:02:47,845: Epoch 18/38 Batch 2800/7662 eta: 1 day, 4:43:20.013515	Training Loss 2.8716 (2.7608)	Training Prec@1 99.805 (99.626)	Training Prec@5 99.805 (99.887)	
2022-03-27 03:02:47,845: ============================================================
2022-03-27 03:03:45,615: time cost, forward:0.015309158462045438, backward:0.03904792291207657, data cost:0.5551043407141484 
2022-03-27 03:03:45,616: ============================================================
2022-03-27 03:03:45,616: Epoch 18/38 Batch 2900/7662 eta: 1 day, 1:21:19.567544	Training Loss 2.9878 (2.7662)	Training Prec@1 99.609 (99.621)	Training Prec@5 99.805 (99.885)	
2022-03-27 03:03:45,616: ============================================================
2022-03-27 03:04:45,179: time cost, forward:0.015245978933209059, backward:0.0389580411011078, data cost:0.5548380841092692 
2022-03-27 03:04:45,179: ============================================================
2022-03-27 03:04:45,179: Epoch 18/38 Batch 3000/7662 eta: 1 day, 2:07:32.169291	Training Loss 2.9920 (2.7704)	Training Prec@1 99.609 (99.616)	Training Prec@5 100.000 (99.885)	
2022-03-27 03:04:45,179: ============================================================
2022-03-27 03:05:40,785: time cost, forward:0.015165582169406297, backward:0.03875610119837182, data cost:0.5532561961817487 
2022-03-27 03:05:40,786: ============================================================
2022-03-27 03:05:40,786: Epoch 18/38 Batch 3100/7662 eta: 1 day, 0:22:28.717153	Training Loss 2.8758 (2.7749)	Training Prec@1 99.219 (99.614)	Training Prec@5 100.000 (99.883)	
2022-03-27 03:05:40,786: ============================================================
2022-03-27 03:06:36,500: time cost, forward:0.01503819478754328, backward:0.038442758218539284, data cost:0.5522143872092016 
2022-03-27 03:06:36,500: ============================================================
2022-03-27 03:06:36,500: Epoch 18/38 Batch 3200/7662 eta: 1 day, 0:24:23.390858	Training Loss 3.0655 (2.7788)	Training Prec@1 99.609 (99.609)	Training Prec@5 100.000 (99.883)	
2022-03-27 03:06:36,501: ============================================================
2022-03-27 03:07:37,718: time cost, forward:0.015072864993263931, backward:0.03850830096337028, data cost:0.5521746017095283 
2022-03-27 03:07:37,719: ============================================================
2022-03-27 03:07:37,720: Epoch 18/38 Batch 3300/7662 eta: 1 day, 2:48:02.990499	Training Loss 2.8345 (2.7827)	Training Prec@1 99.609 (99.607)	Training Prec@5 99.805 (99.882)	
2022-03-27 03:07:37,720: ============================================================
2022-03-27 03:08:38,424: time cost, forward:0.015092221453948104, backward:0.038498952761226696, data cost:0.5520818495827585 
2022-03-27 03:08:38,425: ============================================================
2022-03-27 03:08:38,425: Epoch 18/38 Batch 3400/7662 eta: 1 day, 2:33:33.521603	Training Loss 2.7875 (2.7861)	Training Prec@1 99.609 (99.605)	Training Prec@5 100.000 (99.881)	
2022-03-27 03:08:38,425: ============================================================
2022-03-27 03:09:38,610: time cost, forward:0.015056372915345895, backward:0.03852411275865283, data cost:0.5521018581412185 
2022-03-27 03:09:38,610: ============================================================
2022-03-27 03:09:38,610: Epoch 18/38 Batch 3500/7662 eta: 1 day, 2:18:53.377493	Training Loss 2.9567 (2.7896)	Training Prec@1 99.609 (99.602)	Training Prec@5 100.000 (99.880)	
2022-03-27 03:09:38,611: ============================================================
2022-03-27 03:10:35,495: time cost, forward:0.015063185664010267, backward:0.03849396708277273, data cost:0.551050035580558 
2022-03-27 03:10:35,496: ============================================================
2022-03-27 03:10:35,496: Epoch 18/38 Batch 3600/7662 eta: 1 day, 0:51:23.115548	Training Loss 3.0910 (2.7933)	Training Prec@1 99.805 (99.600)	Training Prec@5 100.000 (99.880)	
2022-03-27 03:10:35,497: ============================================================
2022-03-27 03:11:35,664: time cost, forward:0.015042268382307322, backward:0.038481106787766915, data cost:0.550983700245643 
2022-03-27 03:11:35,665: ============================================================
2022-03-27 03:11:35,665: Epoch 18/38 Batch 3700/7662 eta: 1 day, 2:16:26.612386	Training Loss 3.0200 (2.7965)	Training Prec@1 98.828 (99.599)	Training Prec@5 99.805 (99.880)	
2022-03-27 03:11:35,665: ============================================================
2022-03-27 03:12:35,503: time cost, forward:0.01500754081503157, backward:0.03851999254972253, data cost:0.5507623175314521 
2022-03-27 03:12:35,504: ============================================================
2022-03-27 03:12:35,504: Epoch 18/38 Batch 3800/7662 eta: 1 day, 2:06:48.962284	Training Loss 2.9755 (2.7998)	Training Prec@1 99.219 (99.595)	Training Prec@5 99.609 (99.879)	
2022-03-27 03:12:35,504: ============================================================
2022-03-27 03:13:37,086: time cost, forward:0.015006618519323427, backward:0.03849789019455265, data cost:0.5510682402344416 
2022-03-27 03:13:37,087: ============================================================
2022-03-27 03:13:37,087: Epoch 18/38 Batch 3900/7662 eta: 1 day, 2:51:27.581887	Training Loss 2.8279 (2.8030)	Training Prec@1 99.609 (99.593)	Training Prec@5 100.000 (99.878)	
2022-03-27 03:13:37,087: ============================================================
2022-03-27 03:14:39,988: time cost, forward:0.015004136080025255, backward:0.03850248432898706, data cost:0.5514381565013865 
2022-03-27 03:14:39,990: ============================================================
2022-03-27 03:14:39,991: Epoch 18/38 Batch 4000/7662 eta: 1 day, 3:24:57.655673	Training Loss 3.0054 (2.8064)	Training Prec@1 99.023 (99.592)	Training Prec@5 100.000 (99.877)	
2022-03-27 03:14:39,991: ============================================================
2022-03-27 03:15:40,046: time cost, forward:0.014999522439268456, backward:0.03847531598787478, data cost:0.5515263308022307 
2022-03-27 03:15:40,046: ============================================================
2022-03-27 03:15:40,047: Epoch 18/38 Batch 4100/7662 eta: 1 day, 2:09:29.447047	Training Loss 2.8585 (2.8086)	Training Prec@1 99.609 (99.588)	Training Prec@5 100.000 (99.876)	
2022-03-27 03:15:40,047: ============================================================
2022-03-27 03:16:40,320: time cost, forward:0.015036550866163581, backward:0.038557112628603354, data cost:0.5511333584700292 
2022-03-27 03:16:40,322: ============================================================
2022-03-27 03:16:40,322: Epoch 18/38 Batch 4200/7662 eta: 1 day, 2:14:13.804163	Training Loss 3.0104 (2.8115)	Training Prec@1 99.414 (99.585)	Training Prec@5 100.000 (99.875)	
2022-03-27 03:16:40,323: ============================================================
2022-03-27 03:17:45,794: time cost, forward:0.015106363223302804, backward:0.038700287384775024, data cost:0.5521771824063187 
2022-03-27 03:17:45,795: ============================================================
2022-03-27 03:17:45,795: Epoch 18/38 Batch 4300/7662 eta: 1 day, 4:28:52.025135	Training Loss 2.8977 (2.8151)	Training Prec@1 99.609 (99.582)	Training Prec@5 100.000 (99.874)	
2022-03-27 03:17:45,795: ============================================================
2022-03-27 03:18:44,615: time cost, forward:0.01506338240911159, backward:0.03866623910781226, data cost:0.5518414462038158 
2022-03-27 03:18:44,616: ============================================================
2022-03-27 03:18:44,616: Epoch 18/38 Batch 4400/7662 eta: 1 day, 1:34:16.420085	Training Loss 3.0677 (2.8177)	Training Prec@1 99.805 (99.579)	Training Prec@5 100.000 (99.873)	
2022-03-27 03:18:44,616: ============================================================
2022-03-27 03:19:42,730: time cost, forward:0.015015881282537613, backward:0.03862093824576102, data cost:0.5513858157122075 
2022-03-27 03:19:42,730: ============================================================
2022-03-27 03:19:42,731: Epoch 18/38 Batch 4500/7662 eta: 1 day, 1:14:53.286505	Training Loss 2.9839 (2.8205)	Training Prec@1 99.414 (99.577)	Training Prec@5 99.414 (99.872)	
2022-03-27 03:19:42,731: ============================================================
2022-03-27 03:20:44,645: time cost, forward:0.015034897323794198, backward:0.038700798849199976, data cost:0.5515749726147204 
2022-03-27 03:20:44,646: ============================================================
2022-03-27 03:20:44,646: Epoch 18/38 Batch 4600/7662 eta: 1 day, 2:52:55.790184	Training Loss 3.1210 (2.8230)	Training Prec@1 99.023 (99.575)	Training Prec@5 100.000 (99.872)	
2022-03-27 03:20:44,646: ============================================================
2022-03-27 03:21:46,766: time cost, forward:0.015059857298450588, backward:0.03872001498373145, data cost:0.551758253718975 
2022-03-27 03:21:46,767: ============================================================
2022-03-27 03:21:46,768: Epoch 18/38 Batch 4700/7662 eta: 1 day, 2:57:15.312238	Training Loss 2.8520 (2.8257)	Training Prec@1 99.414 (99.574)	Training Prec@5 99.609 (99.871)	
2022-03-27 03:21:46,768: ============================================================
2022-03-27 03:22:47,454: time cost, forward:0.01507443814358132, backward:0.038741567974960985, data cost:0.5517302232624268 
2022-03-27 03:22:47,455: ============================================================
2022-03-27 03:22:47,455: Epoch 18/38 Batch 4800/7662 eta: 1 day, 2:18:55.470743	Training Loss 2.8565 (2.8280)	Training Prec@1 99.609 (99.572)	Training Prec@5 100.000 (99.871)	
2022-03-27 03:22:47,455: ============================================================
2022-03-27 03:23:49,036: time cost, forward:0.015076328185315667, backward:0.03875011282323404, data cost:0.5519525723497243 
2022-03-27 03:23:49,037: ============================================================
2022-03-27 03:23:49,037: Epoch 18/38 Batch 4900/7662 eta: 1 day, 2:41:09.471050	Training Loss 2.9824 (2.8304)	Training Prec@1 99.609 (99.570)	Training Prec@5 99.609 (99.870)	
2022-03-27 03:23:49,037: ============================================================
2022-03-27 03:24:48,778: time cost, forward:0.01508274167078594, backward:0.038850156801608735, data cost:0.5516000998737955 
2022-03-27 03:24:48,778: ============================================================
2022-03-27 03:24:48,779: Epoch 18/38 Batch 5000/7662 eta: 1 day, 1:52:18.716993	Training Loss 3.0612 (2.8326)	Training Prec@1 99.414 (99.566)	Training Prec@5 99.609 (99.869)	
2022-03-27 03:24:48,779: ============================================================
2022-03-27 03:25:52,954: time cost, forward:0.015065667394984819, backward:0.03885705968075393, data cost:0.5523411883492403 
2022-03-27 03:25:52,955: ============================================================
2022-03-27 03:25:52,955: Epoch 18/38 Batch 5100/7662 eta: 1 day, 3:46:29.066580	Training Loss 2.8211 (2.8350)	Training Prec@1 99.805 (99.564)	Training Prec@5 100.000 (99.867)	
2022-03-27 03:25:52,955: ============================================================
2022-03-27 03:26:49,469: time cost, forward:0.015029728011365899, backward:0.038821844532756215, data cost:0.5515867371494024 
2022-03-27 03:26:49,469: ============================================================
2022-03-27 03:26:49,470: Epoch 18/38 Batch 5200/7662 eta: 1 day, 0:26:34.642969	Training Loss 2.8310 (2.8372)	Training Prec@1 99.609 (99.562)	Training Prec@5 99.805 (99.866)	
2022-03-27 03:26:49,470: ============================================================
2022-03-27 03:27:50,424: time cost, forward:0.015031327839549205, backward:0.03877179837267362, data cost:0.5515941313739812 
2022-03-27 03:27:50,425: ============================================================
2022-03-27 03:27:50,425: Epoch 18/38 Batch 5300/7662 eta: 1 day, 2:20:48.322348	Training Loss 3.0262 (2.8393)	Training Prec@1 99.414 (99.560)	Training Prec@5 100.000 (99.866)	
2022-03-27 03:27:50,425: ============================================================
2022-03-27 03:28:53,235: time cost, forward:0.015055300063790161, backward:0.03882424702002265, data cost:0.5520001646102988 
2022-03-27 03:28:53,235: ============================================================
2022-03-27 03:28:53,235: Epoch 18/38 Batch 5400/7662 eta: 1 day, 3:07:52.067449	Training Loss 3.1149 (2.8415)	Training Prec@1 99.609 (99.557)	Training Prec@5 100.000 (99.864)	
2022-03-27 03:28:53,235: ============================================================
2022-03-27 03:29:56,793: time cost, forward:0.015049879801102086, backward:0.038858138381144984, data cost:0.5524871117809855 
2022-03-27 03:29:56,793: ============================================================
2022-03-27 03:29:56,794: Epoch 18/38 Batch 5500/7662 eta: 1 day, 3:26:11.484229	Training Loss 2.9579 (2.8432)	Training Prec@1 99.609 (99.556)	Training Prec@5 99.805 (99.863)	
2022-03-27 03:29:56,794: ============================================================
2022-03-27 03:30:53,772: time cost, forward:0.01502090118722972, backward:0.03881161509720124, data cost:0.5518909975724 
2022-03-27 03:30:53,773: ============================================================
2022-03-27 03:30:53,773: Epoch 18/38 Batch 5600/7662 eta: 1 day, 0:34:50.229069	Training Loss 2.9517 (2.8450)	Training Prec@1 99.609 (99.554)	Training Prec@5 99.805 (99.863)	
2022-03-27 03:30:53,773: ============================================================
2022-03-27 03:31:53,821: time cost, forward:0.014999535025619879, backward:0.03876979260261403, data cost:0.5518485055218288 
2022-03-27 03:31:53,822: ============================================================
2022-03-27 03:31:53,822: Epoch 18/38 Batch 5700/7662 eta: 1 day, 1:53:17.847658	Training Loss 2.9705 (2.8472)	Training Prec@1 99.414 (99.552)	Training Prec@5 99.805 (99.862)	
2022-03-27 03:31:53,822: ============================================================
2022-03-27 03:32:52,315: time cost, forward:0.014971972334115622, backward:0.03873513813449671, data cost:0.5515178705334849 
2022-03-27 03:32:52,315: ============================================================
2022-03-27 03:32:52,316: Epoch 18/38 Batch 5800/7662 eta: 1 day, 1:12:05.702842	Training Loss 2.9914 (2.8491)	Training Prec@1 98.828 (99.550)	Training Prec@5 99.805 (99.861)	
2022-03-27 03:32:52,316: ============================================================
2022-03-27 03:33:53,486: time cost, forward:0.01497262929491844, backward:0.038776416013878996, data cost:0.5515138402917179 
2022-03-27 03:33:53,488: ============================================================
2022-03-27 03:33:53,489: Epoch 18/38 Batch 5900/7662 eta: 1 day, 2:20:20.316093	Training Loss 3.0088 (2.8511)	Training Prec@1 98.828 (99.547)	Training Prec@5 100.000 (99.860)	
2022-03-27 03:33:53,489: ============================================================
2022-03-27 03:34:55,565: time cost, forward:0.014963502465814208, backward:0.03878161386164611, data cost:0.551791880802028 
2022-03-27 03:34:55,568: ============================================================
2022-03-27 03:34:55,569: Epoch 18/38 Batch 6000/7662 eta: 1 day, 2:42:43.356089	Training Loss 2.8198 (2.8530)	Training Prec@1 100.000 (99.545)	Training Prec@5 100.000 (99.859)	
2022-03-27 03:34:55,569: ============================================================
2022-03-27 03:35:56,247: time cost, forward:0.014933173627926885, backward:0.03874269229972103, data cost:0.5518674906755514 
2022-03-27 03:35:56,248: ============================================================
2022-03-27 03:35:56,248: Epoch 18/38 Batch 6100/7662 eta: 1 day, 2:05:33.331121	Training Loss 3.1425 (2.8549)	Training Prec@1 99.414 (99.543)	Training Prec@5 99.805 (99.859)	
2022-03-27 03:35:56,248: ============================================================
2022-03-27 03:36:57,149: time cost, forward:0.014918254294459291, backward:0.038707357315233316, data cost:0.5519518534932181 
2022-03-27 03:36:57,150: ============================================================
2022-03-27 03:36:57,150: Epoch 18/38 Batch 6200/7662 eta: 1 day, 2:10:17.160493	Training Loss 2.9520 (2.8569)	Training Prec@1 99.609 (99.541)	Training Prec@5 100.000 (99.858)	
2022-03-27 03:36:57,150: ============================================================
2022-03-27 03:38:00,594: time cost, forward:0.014948262167574963, backward:0.03878806242584747, data cost:0.5522405507356747 
2022-03-27 03:38:00,594: ============================================================
2022-03-27 03:38:00,594: Epoch 18/38 Batch 6300/7662 eta: 1 day, 3:14:47.384480	Training Loss 2.9455 (2.8581)	Training Prec@1 99.414 (99.539)	Training Prec@5 100.000 (99.858)	
2022-03-27 03:38:00,595: ============================================================
2022-03-27 03:39:04,852: time cost, forward:0.015003702122264588, backward:0.03882798360164957, data cost:0.5527316029136266 
2022-03-27 03:39:04,853: ============================================================
2022-03-27 03:39:04,853: Epoch 18/38 Batch 6400/7662 eta: 1 day, 3:34:41.653355	Training Loss 3.0712 (2.8598)	Training Prec@1 99.609 (99.537)	Training Prec@5 100.000 (99.857)	
2022-03-27 03:39:04,853: ============================================================
2022-03-27 03:40:02,516: time cost, forward:0.014965461793175512, backward:0.03881755240569942, data cost:0.5523035069908944 
2022-03-27 03:40:02,516: ============================================================
2022-03-27 03:40:02,516: Epoch 18/38 Batch 6500/7662 eta: 1 day, 0:43:53.253700	Training Loss 2.8821 (2.8617)	Training Prec@1 99.414 (99.536)	Training Prec@5 99.805 (99.857)	
2022-03-27 03:40:02,516: ============================================================
2022-03-27 03:41:02,029: time cost, forward:0.014940904656907504, backward:0.03883437345128725, data cost:0.5521284537814678 
2022-03-27 03:41:02,029: ============================================================
2022-03-27 03:41:02,030: Epoch 18/38 Batch 6600/7662 eta: 1 day, 1:30:31.129846	Training Loss 2.9734 (2.8635)	Training Prec@1 99.219 (99.534)	Training Prec@5 100.000 (99.856)	
2022-03-27 03:41:02,030: ============================================================
2022-03-27 03:41:59,650: time cost, forward:0.01494692948206554, backward:0.03885415323208759, data cost:0.5516451157497139 
2022-03-27 03:41:59,650: ============================================================
2022-03-27 03:41:59,650: Epoch 18/38 Batch 6700/7662 eta: 1 day, 0:40:52.938649	Training Loss 3.0171 (2.8651)	Training Prec@1 99.414 (99.533)	Training Prec@5 99.609 (99.856)	
2022-03-27 03:41:59,651: ============================================================
2022-03-27 03:42:58,866: time cost, forward:0.014950044506839977, backward:0.03885385095590983, data cost:0.5514193946674547 
2022-03-27 03:42:58,868: ============================================================
2022-03-27 03:42:58,869: Epoch 18/38 Batch 6800/7662 eta: 1 day, 1:20:56.549473	Training Loss 2.9623 (2.8664)	Training Prec@1 98.828 (99.531)	Training Prec@5 99.609 (99.856)	
2022-03-27 03:42:58,869: ============================================================
2022-03-27 03:43:58,576: time cost, forward:0.014958030055408668, backward:0.03888085448650333, data cost:0.551227992817118 
2022-03-27 03:43:58,577: ============================================================
2022-03-27 03:43:58,577: Epoch 18/38 Batch 6900/7662 eta: 1 day, 1:32:33.206428	Training Loss 2.9500 (2.8681)	Training Prec@1 99.609 (99.530)	Training Prec@5 99.805 (99.855)	
2022-03-27 03:43:58,577: ============================================================
2022-03-27 03:44:56,957: time cost, forward:0.014953967451555318, backward:0.03881820795757121, data cost:0.5509529398890763 
2022-03-27 03:44:56,957: ============================================================
2022-03-27 03:44:56,958: Epoch 18/38 Batch 7000/7662 eta: 1 day, 0:57:29.525603	Training Loss 3.1658 (2.8695)	Training Prec@1 99.023 (99.528)	Training Prec@5 99.219 (99.854)	
2022-03-27 03:44:56,958: ============================================================
2022-03-27 03:45:58,146: time cost, forward:0.014971632271656638, backward:0.03883500706395526, data cost:0.5509994981792347 
2022-03-27 03:45:58,148: ============================================================
2022-03-27 03:45:58,149: Epoch 18/38 Batch 7100/7662 eta: 1 day, 2:08:34.119180	Training Loss 2.9336 (2.8707)	Training Prec@1 99.609 (99.527)	Training Prec@5 99.805 (99.854)	
2022-03-27 03:45:58,150: ============================================================
2022-03-27 03:46:59,188: time cost, forward:0.014993548343572074, backward:0.03887278511385435, data cost:0.5509989140083068 
2022-03-27 03:46:59,190: ============================================================
2022-03-27 03:46:59,190: Epoch 18/38 Batch 7200/7662 eta: 1 day, 2:03:41.533640	Training Loss 3.1061 (2.8719)	Training Prec@1 99.609 (99.525)	Training Prec@5 99.609 (99.853)	
2022-03-27 03:46:59,190: ============================================================
2022-03-27 03:47:58,159: time cost, forward:0.014993195469076624, backward:0.03888166550169711, data cost:0.5507920043470762 
2022-03-27 03:47:58,161: ============================================================
2022-03-27 03:47:58,162: Epoch 18/38 Batch 7300/7662 eta: 1 day, 1:09:42.634270	Training Loss 3.1197 (2.8733)	Training Prec@1 99.414 (99.524)	Training Prec@5 99.609 (99.853)	
2022-03-27 03:47:58,163: ============================================================
2022-03-27 03:48:59,534: time cost, forward:0.014987293232581248, backward:0.03888737325620645, data cost:0.5508241803279711 
2022-03-27 03:48:59,534: ============================================================
2022-03-27 03:48:59,534: Epoch 18/38 Batch 7400/7662 eta: 1 day, 2:10:08.834268	Training Loss 3.0363 (2.8744)	Training Prec@1 99.414 (99.522)	Training Prec@5 99.805 (99.852)	
2022-03-27 03:48:59,535: ============================================================
2022-03-27 03:49:56,896: time cost, forward:0.014988806902972805, backward:0.038890873754735086, data cost:0.5504225731086756 
2022-03-27 03:49:56,897: ============================================================
2022-03-27 03:49:56,897: Epoch 18/38 Batch 7500/7662 eta: 1 day, 0:26:35.367885	Training Loss 3.0144 (2.8756)	Training Prec@1 98.828 (99.520)	Training Prec@5 99.414 (99.851)	
2022-03-27 03:49:56,897: ============================================================
2022-03-27 03:50:57,120: time cost, forward:0.015001592894638349, backward:0.03889759224737172, data cost:0.5503973963386465 
2022-03-27 03:50:57,121: ============================================================
2022-03-27 03:50:57,122: Epoch 18/38 Batch 7600/7662 eta: 1 day, 1:38:46.733431	Training Loss 3.0230 (2.8769)	Training Prec@1 99.414 (99.519)	Training Prec@5 100.000 (99.851)	
2022-03-27 03:50:57,124: ============================================================
2022-03-27 03:51:37,081: Epoch: 18/38 eta: 1 day, 1:38:08.791681	Training Loss 3.0646 (2.8778)	Training Prec@1 99.023 (99.518)	Training Prec@5 100.000 (99.850)
2022-03-27 03:51:37,089: ============================================================
2022-03-27 03:52:38,232: time cost, forward:0.012723708393597844, backward:0.032994985580444336, data cost:0.5635632986974235 
2022-03-27 03:52:38,232: ============================================================
2022-03-27 03:52:38,232: Epoch 19/38 Batch 100/7662 eta: 1 day, 1:57:17.849814	Training Loss 2.6044 (2.5108)	Training Prec@1 100.000 (99.747)	Training Prec@5 100.000 (99.925)	
2022-03-27 03:52:38,233: ============================================================
2022-03-27 03:53:38,200: time cost, forward:0.013615059493175104, backward:0.03608022143493345, data cost:0.553709643570023 
2022-03-27 03:53:38,201: ============================================================
2022-03-27 03:53:38,201: Epoch 19/38 Batch 200/7662 eta: 1 day, 1:29:36.415282	Training Loss 2.4590 (2.5137)	Training Prec@1 100.000 (99.735)	Training Prec@5 100.000 (99.928)	
2022-03-27 03:53:38,201: ============================================================
2022-03-27 03:54:39,183: time cost, forward:0.01515744043433148, backward:0.03781859452110469, data cost:0.5526490139722027 
2022-03-27 03:54:39,184: ============================================================
2022-03-27 03:54:39,184: Epoch 19/38 Batch 300/7662 eta: 1 day, 1:54:27.947009	Training Loss 2.6287 (2.5295)	Training Prec@1 99.805 (99.729)	Training Prec@5 100.000 (99.923)	
2022-03-27 03:54:39,184: ============================================================
2022-03-27 03:55:38,501: time cost, forward:0.01507128928239483, backward:0.03759075286693143, data cost:0.5497230832140547 
2022-03-27 03:55:38,501: ============================================================
2022-03-27 03:55:38,501: Epoch 19/38 Batch 400/7662 eta: 1 day, 1:11:01.404961	Training Loss 2.5523 (2.5420)	Training Prec@1 99.609 (99.730)	Training Prec@5 99.805 (99.924)	
2022-03-27 03:55:38,501: ============================================================
2022-03-27 03:56:39,064: time cost, forward:0.015188351422846915, backward:0.037211623124942514, data cost:0.5499792796576429 
2022-03-27 03:56:39,067: ============================================================
2022-03-27 03:56:39,068: Epoch 19/38 Batch 500/7662 eta: 1 day, 1:41:49.996768	Training Loss 2.7350 (2.5592)	Training Prec@1 99.805 (99.723)	Training Prec@5 100.000 (99.921)	
2022-03-27 03:56:39,069: ============================================================
2022-03-27 03:57:42,948: time cost, forward:0.015481020651994045, backward:0.03817298257092203, data cost:0.5547405459446979 
2022-03-27 03:57:42,951: ============================================================
2022-03-27 03:57:42,952: Epoch 19/38 Batch 600/7662 eta: 1 day, 3:05:13.019685	Training Loss 2.4460 (2.5731)	Training Prec@1 100.000 (99.717)	Training Prec@5 100.000 (99.919)	
2022-03-27 03:57:42,953: ============================================================
2022-03-27 03:58:43,636: time cost, forward:0.015275691200223604, backward:0.03812587789882065, data cost:0.5547889025937845 
2022-03-27 03:58:43,637: ============================================================
2022-03-27 03:58:43,637: Epoch 19/38 Batch 700/7662 eta: 1 day, 1:42:49.683969	Training Loss 2.6906 (2.5862)	Training Prec@1 99.609 (99.719)	Training Prec@5 100.000 (99.922)	
2022-03-27 03:58:43,637: ============================================================
2022-03-27 03:59:42,635: time cost, forward:0.015135381636541986, backward:0.03778864445167131, data cost:0.5527301631373667 
2022-03-27 03:59:42,636: ============================================================
2022-03-27 03:59:42,636: Epoch 19/38 Batch 800/7662 eta: 1 day, 0:58:58.945919	Training Loss 2.7571 (2.5977)	Training Prec@1 100.000 (99.714)	Training Prec@5 100.000 (99.916)	
2022-03-27 03:59:42,636: ============================================================
2022-03-27 04:00:43,749: time cost, forward:0.015096508223434975, backward:0.03764210288331028, data cost:0.5534047393565449 
2022-03-27 04:00:43,749: ============================================================
2022-03-27 04:00:43,749: Epoch 19/38 Batch 900/7662 eta: 1 day, 1:51:40.545289	Training Loss 2.7136 (2.6059)	Training Prec@1 100.000 (99.710)	Training Prec@5 100.000 (99.916)	
2022-03-27 04:00:43,750: ============================================================
2022-03-27 04:01:44,543: time cost, forward:0.014964706069594986, backward:0.037443821375315135, data cost:0.5538410169106943 
2022-03-27 04:01:44,546: ============================================================
2022-03-27 04:01:44,547: Epoch 19/38 Batch 1000/7662 eta: 1 day, 1:42:38.384615	Training Loss 2.7019 (2.6149)	Training Prec@1 100.000 (99.705)	Training Prec@5 100.000 (99.917)	
2022-03-27 04:01:44,547: ============================================================
2022-03-27 04:02:42,889: time cost, forward:0.014837579796594095, backward:0.03755080884320829, data cost:0.5513259642117668 
2022-03-27 04:02:42,892: ============================================================
2022-03-27 04:02:42,893: Epoch 19/38 Batch 1100/7662 eta: 1 day, 0:39:27.431859	Training Loss 2.8767 (2.6233)	Training Prec@1 99.805 (99.701)	Training Prec@5 100.000 (99.916)	
2022-03-27 04:02:42,893: ============================================================
2022-03-27 04:03:43,421: time cost, forward:0.014942526519049993, backward:0.03746778155685565, data cost:0.551213534699568 
2022-03-27 04:03:43,421: ============================================================
2022-03-27 04:03:43,422: Epoch 19/38 Batch 1200/7662 eta: 1 day, 1:33:49.363486	Training Loss 2.6521 (2.6344)	Training Prec@1 100.000 (99.697)	Training Prec@5 100.000 (99.914)	
2022-03-27 04:03:43,422: ============================================================
2022-03-27 04:04:43,150: time cost, forward:0.01497160167855607, backward:0.03740666901909268, data cost:0.5510775628137625 
2022-03-27 04:04:43,150: ============================================================
2022-03-27 04:04:43,150: Epoch 19/38 Batch 1300/7662 eta: 1 day, 1:12:32.435027	Training Loss 2.8586 (2.6431)	Training Prec@1 99.805 (99.692)	Training Prec@5 100.000 (99.911)	
2022-03-27 04:04:43,151: ============================================================
2022-03-27 04:05:41,832: time cost, forward:0.014940693857330694, backward:0.03733407198488073, data cost:0.5498956689841411 
2022-03-27 04:05:41,833: ============================================================
2022-03-27 04:05:41,833: Epoch 19/38 Batch 1400/7662 eta: 1 day, 0:45:03.928123	Training Loss 2.7909 (2.6537)	Training Prec@1 99.609 (99.684)	Training Prec@5 99.805 (99.908)	
2022-03-27 04:05:41,833: ============================================================
2022-03-27 04:06:42,903: time cost, forward:0.014844973935056639, backward:0.037474695724833404, data cost:0.5503786411819814 
2022-03-27 04:06:42,904: ============================================================
2022-03-27 04:06:42,904: Epoch 19/38 Batch 1500/7662 eta: 1 day, 1:44:29.825852	Training Loss 2.8736 (2.6613)	Training Prec@1 99.805 (99.681)	Training Prec@5 99.805 (99.907)	
2022-03-27 04:06:42,904: ============================================================
2022-03-27 04:07:44,300: time cost, forward:0.014839824845896727, backward:0.03745982764734933, data cost:0.5510553140204872 
2022-03-27 04:07:44,301: ============================================================
2022-03-27 04:07:44,301: Epoch 19/38 Batch 1600/7662 eta: 1 day, 1:51:43.030306	Training Loss 2.7022 (2.6691)	Training Prec@1 99.805 (99.676)	Training Prec@5 99.805 (99.904)	
2022-03-27 04:07:44,301: ============================================================
2022-03-27 04:08:43,910: time cost, forward:0.014811054266783124, backward:0.03743298703463657, data cost:0.5505940195670753 
2022-03-27 04:08:43,911: ============================================================
2022-03-27 04:08:43,911: Epoch 19/38 Batch 1700/7662 eta: 1 day, 1:05:34.251485	Training Loss 2.7060 (2.6773)	Training Prec@1 99.805 (99.673)	Training Prec@5 99.805 (99.904)	
2022-03-27 04:08:43,912: ============================================================
2022-03-27 04:09:44,170: time cost, forward:0.01479985927329453, backward:0.03749502440702259, data cost:0.5500813500625416 
2022-03-27 04:09:44,171: ============================================================
2022-03-27 04:09:44,171: Epoch 19/38 Batch 1800/7662 eta: 1 day, 1:20:58.157749	Training Loss 2.9651 (2.6844)	Training Prec@1 99.414 (99.668)	Training Prec@5 99.609 (99.902)	
2022-03-27 04:09:44,171: ============================================================
2022-03-27 04:10:43,716: time cost, forward:0.014681273350406785, backward:0.037324143058692485, data cost:0.5502901221652481 
2022-03-27 04:10:43,716: ============================================================
2022-03-27 04:10:43,716: Epoch 19/38 Batch 1900/7662 eta: 1 day, 1:01:56.006143	Training Loss 2.8075 (2.6921)	Training Prec@1 99.414 (99.664)	Training Prec@5 99.609 (99.901)	
2022-03-27 04:10:43,716: ============================================================
2022-03-27 04:11:44,275: time cost, forward:0.014604147342874624, backward:0.03734048859604363, data cost:0.5504625622423486 
2022-03-27 04:11:44,276: ============================================================
2022-03-27 04:11:44,276: Epoch 19/38 Batch 2000/7662 eta: 1 day, 1:26:31.322704	Training Loss 2.7031 (2.6983)	Training Prec@1 99.414 (99.661)	Training Prec@5 99.805 (99.899)	
2022-03-27 04:11:44,276: ============================================================
2022-03-27 04:12:44,797: time cost, forward:0.014626527979806698, backward:0.037334079910540025, data cost:0.5504052850278915 
2022-03-27 04:12:44,800: ============================================================
2022-03-27 04:12:44,801: Epoch 19/38 Batch 2100/7662 eta: 1 day, 1:24:37.134390	Training Loss 2.9157 (2.7044)	Training Prec@1 99.023 (99.657)	Training Prec@5 99.805 (99.897)	
2022-03-27 04:12:44,801: ============================================================
2022-03-27 04:13:43,573: time cost, forward:0.014550728817428443, backward:0.037145600746088865, data cost:0.5500550865313854 
2022-03-27 04:13:43,574: ============================================================
2022-03-27 04:13:43,574: Epoch 19/38 Batch 2200/7662 eta: 1 day, 0:39:32.022665	Training Loss 2.9767 (2.7100)	Training Prec@1 99.414 (99.655)	Training Prec@5 99.609 (99.897)	
2022-03-27 04:13:43,574: ============================================================
2022-03-27 04:14:44,626: time cost, forward:0.014558223186756746, backward:0.03721089371394572, data cost:0.5502886840601287 
2022-03-27 04:14:44,627: ============================================================
2022-03-27 04:14:44,627: Epoch 19/38 Batch 2300/7662 eta: 1 day, 1:35:53.713235	Training Loss 2.7545 (2.7161)	Training Prec@1 99.609 (99.651)	Training Prec@5 99.805 (99.896)	
2022-03-27 04:14:44,627: ============================================================
2022-03-27 04:15:47,929: time cost, forward:0.01460840315459022, backward:0.037339795972467116, data cost:0.5513480660715616 
2022-03-27 04:15:47,932: ============================================================
2022-03-27 04:15:47,932: Epoch 19/38 Batch 2400/7662 eta: 1 day, 2:31:29.989375	Training Loss 2.8939 (2.7228)	Training Prec@1 99.609 (99.647)	Training Prec@5 99.805 (99.895)	
2022-03-27 04:15:47,933: ============================================================
2022-03-27 04:16:46,175: time cost, forward:0.01457495983241319, backward:0.03731323147163528, data cost:0.5504213138884093 
2022-03-27 04:16:46,177: ============================================================
2022-03-27 04:16:46,178: Epoch 19/38 Batch 2500/7662 eta: 1 day, 0:23:20.115958	Training Loss 2.9353 (2.7283)	Training Prec@1 100.000 (99.644)	Training Prec@5 100.000 (99.894)	
2022-03-27 04:16:46,178: ============================================================
2022-03-27 04:17:44,676: time cost, forward:0.014483182418341818, backward:0.03731120857379674, data cost:0.5499335089386679 
2022-03-27 04:17:44,677: ============================================================
2022-03-27 04:17:44,677: Epoch 19/38 Batch 2600/7662 eta: 1 day, 0:28:44.013842	Training Loss 2.8830 (2.7337)	Training Prec@1 99.609 (99.641)	Training Prec@5 99.805 (99.893)	
2022-03-27 04:17:44,677: ============================================================
2022-03-27 04:18:46,242: time cost, forward:0.014531014715578433, backward:0.037304629215976846, data cost:0.5503587751045806 
2022-03-27 04:18:46,242: ============================================================
2022-03-27 04:18:46,242: Epoch 19/38 Batch 2700/7662 eta: 1 day, 1:44:41.329077	Training Loss 2.8123 (2.7389)	Training Prec@1 100.000 (99.636)	Training Prec@5 100.000 (99.892)	
2022-03-27 04:18:46,243: ============================================================
2022-03-27 04:19:48,287: time cost, forward:0.014529055976663244, backward:0.03736068325921781, data cost:0.5509096892998447 
2022-03-27 04:19:48,287: ============================================================
2022-03-27 04:19:48,287: Epoch 19/38 Batch 2800/7662 eta: 1 day, 1:55:40.944605	Training Loss 2.7490 (2.7432)	Training Prec@1 99.609 (99.633)	Training Prec@5 100.000 (99.891)	
2022-03-27 04:19:48,287: ============================================================
2022-03-27 04:20:45,002: time cost, forward:0.014493237449695998, backward:0.03721171923858127, data cost:0.549663224850247 
2022-03-27 04:20:45,005: ============================================================
2022-03-27 04:20:45,005: Epoch 19/38 Batch 2900/7662 eta: 23:41:10.097156	Training Loss 2.8295 (2.7474)	Training Prec@1 99.219 (99.628)	Training Prec@5 99.609 (99.889)	
2022-03-27 04:20:45,006: ============================================================
2022-03-27 04:21:43,943: time cost, forward:0.0145206081743994, backward:0.03727573146419392, data cost:0.5493025537251075 
2022-03-27 04:21:43,944: ============================================================
2022-03-27 04:21:43,944: Epoch 19/38 Batch 3000/7662 eta: 1 day, 0:35:50.171729	Training Loss 2.7744 (2.7519)	Training Prec@1 99.609 (99.625)	Training Prec@5 99.805 (99.889)	
2022-03-27 04:21:43,944: ============================================================
2022-03-27 04:22:41,062: time cost, forward:0.014498798183257751, backward:0.037169991173487245, data cost:0.5484263639213116 
2022-03-27 04:22:41,063: ============================================================
2022-03-27 04:22:41,063: Epoch 19/38 Batch 3100/7662 eta: 23:49:19.618345	Training Loss 2.7872 (2.7558)	Training Prec@1 99.609 (99.621)	Training Prec@5 99.805 (99.888)	
2022-03-27 04:22:41,063: ============================================================
2022-03-27 04:23:41,389: time cost, forward:0.014446809687589102, backward:0.03701446882893645, data cost:0.5483872139219121 
2022-03-27 04:23:41,390: ============================================================
2022-03-27 04:23:41,391: Epoch 19/38 Batch 3200/7662 eta: 1 day, 1:08:35.494348	Training Loss 2.7743 (2.7593)	Training Prec@1 100.000 (99.620)	Training Prec@5 100.000 (99.888)	
2022-03-27 04:23:41,391: ============================================================
2022-03-27 04:24:42,204: time cost, forward:0.014441505494570147, backward:0.0370386378914705, data cost:0.5487014377937421 
2022-03-27 04:24:42,204: ============================================================
2022-03-27 04:24:42,205: Epoch 19/38 Batch 3300/7662 eta: 1 day, 1:19:45.463837	Training Loss 2.8328 (2.7634)	Training Prec@1 100.000 (99.617)	Training Prec@5 100.000 (99.887)	
2022-03-27 04:24:42,205: ============================================================
2022-03-27 04:25:43,022: time cost, forward:0.014464817176183626, backward:0.03704542403853827, data cost:0.5490479111566232 
2022-03-27 04:25:43,023: ============================================================
2022-03-27 04:25:43,023: Epoch 19/38 Batch 3400/7662 eta: 1 day, 1:18:50.607446	Training Loss 2.8545 (2.7676)	Training Prec@1 99.219 (99.615)	Training Prec@5 99.805 (99.886)	
2022-03-27 04:25:43,023: ============================================================
2022-03-27 04:26:45,281: time cost, forward:0.014600923246027709, backward:0.03713167889113425, data cost:0.5493998934317058 
2022-03-27 04:26:45,282: ============================================================
2022-03-27 04:26:45,282: Epoch 19/38 Batch 3500/7662 eta: 1 day, 1:53:47.037220	Training Loss 2.9305 (2.7718)	Training Prec@1 99.414 (99.612)	Training Prec@5 99.609 (99.885)	
2022-03-27 04:26:45,282: ============================================================
2022-03-27 04:27:41,831: time cost, forward:0.014541151590498331, backward:0.03707820602707414, data cost:0.5485013721054811 
2022-03-27 04:27:41,831: ============================================================
2022-03-27 04:27:41,831: Epoch 19/38 Batch 3600/7662 eta: 23:30:21.581206	Training Loss 2.9367 (2.7762)	Training Prec@1 99.219 (99.608)	Training Prec@5 99.805 (99.884)	
2022-03-27 04:27:41,832: ============================================================
2022-03-27 04:28:40,717: time cost, forward:0.01454685455594523, backward:0.037101594523243984, data cost:0.548107500751781 
2022-03-27 04:28:40,718: ============================================================
2022-03-27 04:28:40,718: Epoch 19/38 Batch 3700/7662 eta: 1 day, 0:27:39.112455	Training Loss 2.6340 (2.7804)	Training Prec@1 99.219 (99.604)	Training Prec@5 100.000 (99.883)	
2022-03-27 04:28:40,718: ============================================================
2022-03-27 04:29:41,685: time cost, forward:0.014554932858637052, backward:0.03718225546151784, data cost:0.548061574813911 
2022-03-27 04:29:41,688: ============================================================
2022-03-27 04:29:41,688: Epoch 19/38 Batch 3800/7662 eta: 1 day, 1:18:34.407197	Training Loss 2.8018 (2.7834)	Training Prec@1 99.805 (99.600)	Training Prec@5 100.000 (99.881)	
2022-03-27 04:29:41,688: ============================================================
2022-03-27 04:30:41,175: time cost, forward:0.014528532889171207, backward:0.037178726127802576, data cost:0.5481287646091849 
2022-03-27 04:30:41,176: ============================================================
2022-03-27 04:30:41,176: Epoch 19/38 Batch 3900/7662 eta: 1 day, 0:40:40.356003	Training Loss 2.9847 (2.7864)	Training Prec@1 99.414 (99.598)	Training Prec@5 100.000 (99.880)	
2022-03-27 04:30:41,176: ============================================================
2022-03-27 04:31:41,822: time cost, forward:0.014548159265673198, backward:0.03717902023275366, data cost:0.548256915221962 
2022-03-27 04:31:41,822: ============================================================
2022-03-27 04:31:41,822: Epoch 19/38 Batch 4000/7662 eta: 1 day, 1:08:28.991341	Training Loss 2.8462 (2.7896)	Training Prec@1 99.609 (99.595)	Training Prec@5 99.609 (99.880)	
2022-03-27 04:31:41,823: ============================================================
2022-03-27 04:32:42,894: time cost, forward:0.01453643096426866, backward:0.03713318160988407, data cost:0.5485384520684023 
2022-03-27 04:32:42,895: ============================================================
2022-03-27 04:32:42,895: Epoch 19/38 Batch 4100/7662 eta: 1 day, 1:18:03.939864	Training Loss 2.7654 (2.7929)	Training Prec@1 99.609 (99.591)	Training Prec@5 99.805 (99.878)	
2022-03-27 04:32:42,895: ============================================================
2022-03-27 04:33:41,414: time cost, forward:0.014498275301234442, backward:0.036996101589252844, data cost:0.5483308071237316 
2022-03-27 04:33:41,414: ============================================================
2022-03-27 04:33:41,414: Epoch 19/38 Batch 4200/7662 eta: 1 day, 0:13:38.030964	Training Loss 2.7110 (2.7957)	Training Prec@1 99.609 (99.589)	Training Prec@5 99.805 (99.877)	
2022-03-27 04:33:41,414: ============================================================
2022-03-27 04:34:40,037: time cost, forward:0.014482246440187335, backward:0.03695179446127892, data cost:0.5480454806034774 
2022-03-27 04:34:40,037: ============================================================
2022-03-27 04:34:40,037: Epoch 19/38 Batch 4300/7662 eta: 1 day, 0:15:13.849899	Training Loss 2.9437 (2.7986)	Training Prec@1 99.414 (99.588)	Training Prec@5 99.805 (99.877)	
2022-03-27 04:34:40,038: ============================================================
2022-03-27 04:35:41,543: time cost, forward:0.014473830930046885, backward:0.03697616508208126, data cost:0.5483552735348836 
2022-03-27 04:35:41,543: ============================================================
2022-03-27 04:35:41,544: Epoch 19/38 Batch 4400/7662 eta: 1 day, 1:25:46.460287	Training Loss 3.0331 (2.8014)	Training Prec@1 99.219 (99.585)	Training Prec@5 99.609 (99.876)	
2022-03-27 04:35:41,544: ============================================================
2022-03-27 04:36:40,517: time cost, forward:0.014495561164759297, backward:0.03692882414472503, data cost:0.5481270831223195 
2022-03-27 04:36:40,518: ============================================================
2022-03-27 04:36:40,518: Epoch 19/38 Batch 4500/7662 eta: 1 day, 0:21:58.868386	Training Loss 2.8789 (2.8035)	Training Prec@1 99.609 (99.583)	Training Prec@5 100.000 (99.876)	
2022-03-27 04:36:40,518: ============================================================
2022-03-27 04:37:40,117: time cost, forward:0.014503688857876288, backward:0.036928939103924675, data cost:0.548015023501289 
2022-03-27 04:37:40,118: ============================================================
2022-03-27 04:37:40,118: Epoch 19/38 Batch 4600/7662 eta: 1 day, 0:36:30.240340	Training Loss 2.9211 (2.8061)	Training Prec@1 98.633 (99.581)	Training Prec@5 99.023 (99.875)	
2022-03-27 04:37:40,118: ============================================================
2022-03-27 04:38:41,598: time cost, forward:0.014516583248056434, backward:0.036945625933517065, data cost:0.5481158575369313 
2022-03-27 04:38:41,599: ============================================================
2022-03-27 04:38:41,600: Epoch 19/38 Batch 4700/7662 eta: 1 day, 1:22:05.648074	Training Loss 2.8825 (2.8086)	Training Prec@1 99.609 (99.579)	Training Prec@5 100.000 (99.874)	
2022-03-27 04:38:41,600: ============================================================
2022-03-27 04:39:39,213: time cost, forward:0.014474717893558732, backward:0.03687618752026662, data cost:0.5478856059307107 
2022-03-27 04:39:39,213: ============================================================
2022-03-27 04:39:39,214: Epoch 19/38 Batch 4800/7662 eta: 23:45:22.703014	Training Loss 2.7573 (2.8110)	Training Prec@1 99.805 (99.576)	Training Prec@5 100.000 (99.873)	
2022-03-27 04:39:39,214: ============================================================
2022-03-27 04:40:37,585: time cost, forward:0.01446312440855451, backward:0.03688596355401635, data cost:0.5474736150319928 
2022-03-27 04:40:37,585: ============================================================
2022-03-27 04:40:37,585: Epoch 19/38 Batch 4900/7662 eta: 1 day, 0:03:09.079395	Training Loss 2.8268 (2.8137)	Training Prec@1 99.805 (99.573)	Training Prec@5 99.805 (99.872)	
2022-03-27 04:40:37,586: ============================================================
2022-03-27 04:41:39,380: time cost, forward:0.014449267178493682, backward:0.03684804620302112, data cost:0.5479488175352661 
2022-03-27 04:41:39,381: ============================================================
2022-03-27 04:41:39,381: Epoch 19/38 Batch 5000/7662 eta: 1 day, 1:26:46.266861	Training Loss 3.0713 (2.8164)	Training Prec@1 99.609 (99.570)	Training Prec@5 99.609 (99.871)	
2022-03-27 04:41:39,381: ============================================================
2022-03-27 04:42:38,332: time cost, forward:0.014443189262245, backward:0.03684494279837884, data cost:0.5477319412265111 
2022-03-27 04:42:38,332: ============================================================
2022-03-27 04:42:38,332: Epoch 19/38 Batch 5100/7662 eta: 1 day, 0:15:31.232034	Training Loss 3.0545 (2.8187)	Training Prec@1 98.438 (99.569)	Training Prec@5 99.805 (99.870)	
2022-03-27 04:42:38,333: ============================================================
2022-03-27 04:43:37,418: time cost, forward:0.014419716810992095, backward:0.036814740218206375, data cost:0.547626469726401 
2022-03-27 04:43:37,419: ============================================================
2022-03-27 04:43:37,419: Epoch 19/38 Batch 5200/7662 eta: 1 day, 0:17:52.290892	Training Loss 2.7605 (2.8209)	Training Prec@1 99.609 (99.566)	Training Prec@5 99.609 (99.870)	
2022-03-27 04:43:37,419: ============================================================
2022-03-27 04:44:35,352: time cost, forward:0.014398264511505778, backward:0.03677645992121397, data cost:0.5472488572044538 
2022-03-27 04:44:35,353: ============================================================
2022-03-27 04:44:35,353: Epoch 19/38 Batch 5300/7662 eta: 23:48:27.948847	Training Loss 2.9656 (2.8234)	Training Prec@1 99.609 (99.564)	Training Prec@5 100.000 (99.869)	
2022-03-27 04:44:35,353: ============================================================
2022-03-27 04:45:34,172: time cost, forward:0.014390923266367551, backward:0.03676646765701681, data cost:0.5470694179644429 
2022-03-27 04:45:34,172: ============================================================
2022-03-27 04:45:34,173: Epoch 19/38 Batch 5400/7662 eta: 1 day, 0:09:19.894574	Training Loss 3.0635 (2.8254)	Training Prec@1 99.414 (99.562)	Training Prec@5 100.000 (99.868)	
2022-03-27 04:45:34,173: ============================================================
2022-03-27 04:46:32,327: time cost, forward:0.014411157468250176, backward:0.03676338164583946, data cost:0.5467002781592059 
2022-03-27 04:46:32,332: ============================================================
2022-03-27 04:46:32,333: Epoch 19/38 Batch 5500/7662 eta: 23:52:06.473586	Training Loss 2.8286 (2.8268)	Training Prec@1 99.805 (99.560)	Training Prec@5 100.000 (99.867)	
2022-03-27 04:46:32,335: ============================================================
2022-03-27 04:47:32,945: time cost, forward:0.014383796283785286, backward:0.0367259755690708, data cost:0.5469190997723108 
2022-03-27 04:47:32,945: ============================================================
2022-03-27 04:47:32,945: Epoch 19/38 Batch 5600/7662 eta: 1 day, 0:51:28.706045	Training Loss 2.9870 (2.8289)	Training Prec@1 99.414 (99.559)	Training Prec@5 99.609 (99.866)	
2022-03-27 04:47:32,945: ============================================================
2022-03-27 04:48:30,788: time cost, forward:0.01439357021436877, backward:0.036744420456037034, data cost:0.5465209318014755 
2022-03-27 04:48:30,789: ============================================================
2022-03-27 04:48:30,789: Epoch 19/38 Batch 5700/7662 eta: 23:42:23.094170	Training Loss 2.9873 (2.8308)	Training Prec@1 99.805 (99.557)	Training Prec@5 100.000 (99.865)	
2022-03-27 04:48:30,789: ============================================================
2022-03-27 04:49:31,751: time cost, forward:0.014385626837803919, backward:0.036741910340108014, data cost:0.5467414533214171 
2022-03-27 04:49:31,752: ============================================================
2022-03-27 04:49:31,752: Epoch 19/38 Batch 5800/7662 eta: 1 day, 0:58:04.223152	Training Loss 2.9941 (2.8327)	Training Prec@1 99.805 (99.555)	Training Prec@5 100.000 (99.865)	
2022-03-27 04:49:31,752: ============================================================
2022-03-27 04:50:31,251: time cost, forward:0.014383054745563067, backward:0.036681098803804574, data cost:0.5467246181380043 
2022-03-27 04:50:31,252: ============================================================
2022-03-27 04:50:31,252: Epoch 19/38 Batch 5900/7662 eta: 1 day, 0:21:08.079778	Training Loss 2.9073 (2.8348)	Training Prec@1 99.023 (99.552)	Training Prec@5 99.805 (99.863)	
2022-03-27 04:50:31,252: ============================================================
2022-03-27 04:51:32,592: time cost, forward:0.014362486467140478, backward:0.03662192068371818, data cost:0.5470272198699478 
2022-03-27 04:51:32,597: ============================================================
2022-03-27 04:51:32,598: Epoch 19/38 Batch 6000/7662 eta: 1 day, 1:05:25.974081	Training Loss 3.0208 (2.8368)	Training Prec@1 99.219 (99.549)	Training Prec@5 100.000 (99.862)	
2022-03-27 04:51:32,599: ============================================================
2022-03-27 04:52:34,510: time cost, forward:0.01439026352381546, backward:0.036644756139194525, data cost:0.5473096369915194 
2022-03-27 04:52:34,511: ============================================================
2022-03-27 04:52:34,511: Epoch 19/38 Batch 6100/7662 eta: 1 day, 1:18:19.600433	Training Loss 2.9324 (2.8385)	Training Prec@1 99.414 (99.547)	Training Prec@5 99.805 (99.861)	
2022-03-27 04:52:34,511: ============================================================
2022-03-27 04:53:32,975: time cost, forward:0.014349080378210416, backward:0.03661800115449637, data cost:0.5471604075772587 
2022-03-27 04:53:32,975: ============================================================
2022-03-27 04:53:32,976: Epoch 19/38 Batch 6200/7662 eta: 23:52:47.203606	Training Loss 3.0638 (2.8404)	Training Prec@1 100.000 (99.547)	Training Prec@5 100.000 (99.861)	
2022-03-27 04:53:32,976: ============================================================
2022-03-27 04:54:33,506: time cost, forward:0.014342298846828463, backward:0.0365895954724966, data cost:0.5472944204457924 
2022-03-27 04:54:33,506: ============================================================
2022-03-27 04:54:33,506: Epoch 19/38 Batch 6300/7662 eta: 1 day, 0:42:24.687350	Training Loss 2.8487 (2.8422)	Training Prec@1 99.414 (99.546)	Training Prec@5 100.000 (99.860)	
2022-03-27 04:54:33,507: ============================================================
2022-03-27 04:55:33,346: time cost, forward:0.014345898593211661, backward:0.03659569511079736, data cost:0.5472730887198862 
2022-03-27 04:55:33,346: ============================================================
2022-03-27 04:55:33,347: Epoch 19/38 Batch 6400/7662 eta: 1 day, 0:24:29.782059	Training Loss 3.0362 (2.8436)	Training Prec@1 100.000 (99.544)	Training Prec@5 100.000 (99.860)	
2022-03-27 04:55:33,347: ============================================================
2022-03-27 04:56:30,902: time cost, forward:0.014356127811002812, backward:0.03661906060704379, data cost:0.5468008919557547 
2022-03-27 04:56:30,903: ============================================================
2022-03-27 04:56:30,904: Epoch 19/38 Batch 6500/7662 eta: 23:27:39.785128	Training Loss 2.8814 (2.8448)	Training Prec@1 99.414 (99.542)	Training Prec@5 99.805 (99.859)	
2022-03-27 04:56:30,905: ============================================================
2022-03-27 04:57:28,811: time cost, forward:0.014352920615757969, backward:0.036622475595036355, data cost:0.546543173472761 
2022-03-27 04:57:28,811: ============================================================
2022-03-27 04:57:28,811: Epoch 19/38 Batch 6600/7662 eta: 23:35:16.664343	Training Loss 2.8802 (2.8462)	Training Prec@1 99.805 (99.541)	Training Prec@5 100.000 (99.858)	
2022-03-27 04:57:28,812: ============================================================
2022-03-27 04:58:30,437: time cost, forward:0.014372251873355175, backward:0.03664166561826554, data cost:0.5467572079823789 
2022-03-27 04:58:30,438: ============================================================
2022-03-27 04:58:30,438: Epoch 19/38 Batch 6700/7662 eta: 1 day, 1:05:07.774763	Training Loss 2.9320 (2.8476)	Training Prec@1 99.609 (99.539)	Training Prec@5 100.000 (99.858)	
2022-03-27 04:58:30,438: ============================================================
2022-03-27 04:59:30,568: time cost, forward:0.014366027484449994, backward:0.036633871218477526, data cost:0.5468301233394581 
2022-03-27 04:59:30,569: ============================================================
2022-03-27 04:59:30,569: Epoch 19/38 Batch 6800/7662 eta: 1 day, 0:27:36.572890	Training Loss 2.9465 (2.8491)	Training Prec@1 99.219 (99.537)	Training Prec@5 99.805 (99.857)	
2022-03-27 04:59:30,569: ============================================================
2022-03-27 05:00:32,139: time cost, forward:0.01438630029833443, backward:0.03668364837111243, data cost:0.5469267630269518 
2022-03-27 05:00:32,140: ============================================================
2022-03-27 05:00:32,140: Epoch 19/38 Batch 6900/7662 eta: 1 day, 1:01:43.836367	Training Loss 2.8393 (2.8507)	Training Prec@1 99.805 (99.535)	Training Prec@5 100.000 (99.857)	
2022-03-27 05:00:32,140: ============================================================
2022-03-27 05:01:31,138: time cost, forward:0.014381467929855894, backward:0.03666996087222665, data cost:0.5468845176328879 
2022-03-27 05:01:31,139: ============================================================
2022-03-27 05:01:31,139: Epoch 19/38 Batch 7000/7662 eta: 23:58:00.392977	Training Loss 3.0194 (2.8523)	Training Prec@1 99.414 (99.533)	Training Prec@5 99.805 (99.856)	
2022-03-27 05:01:31,139: ============================================================
2022-03-27 05:02:32,888: time cost, forward:0.014375924929747666, backward:0.0367010591197709, data cost:0.5470812254547149 
2022-03-27 05:02:32,903: ============================================================
2022-03-27 05:02:32,903: Epoch 19/38 Batch 7100/7662 eta: 1 day, 1:04:23.342471	Training Loss 3.1183 (2.8537)	Training Prec@1 99.609 (99.532)	Training Prec@5 99.805 (99.855)	
2022-03-27 05:02:32,904: ============================================================
2022-03-27 05:03:33,197: time cost, forward:0.014384312701897582, backward:0.03673030290525479, data cost:0.5471050350810773 
2022-03-27 05:03:33,198: ============================================================
2022-03-27 05:03:33,198: Epoch 19/38 Batch 7200/7662 eta: 1 day, 0:27:34.729210	Training Loss 2.9103 (2.8552)	Training Prec@1 99.219 (99.530)	Training Prec@5 100.000 (99.854)	
2022-03-27 05:03:33,198: ============================================================
2022-03-27 05:04:33,900: time cost, forward:0.014369635994196885, backward:0.03673019799847752, data cost:0.5472491753070318 
2022-03-27 05:04:33,901: ============================================================
2022-03-27 05:04:33,901: Epoch 19/38 Batch 7300/7662 eta: 1 day, 0:36:30.792890	Training Loss 2.9972 (2.8565)	Training Prec@1 99.219 (99.529)	Training Prec@5 99.805 (99.854)	
2022-03-27 05:04:33,901: ============================================================
2022-03-27 05:05:34,091: time cost, forward:0.014374898017814214, backward:0.03671346205056463, data cost:0.5472639590795821 
2022-03-27 05:05:34,092: ============================================================
2022-03-27 05:05:34,092: Epoch 19/38 Batch 7400/7662 eta: 1 day, 0:23:03.301979	Training Loss 2.9996 (2.8577)	Training Prec@1 99.219 (99.527)	Training Prec@5 99.805 (99.853)	
2022-03-27 05:05:34,092: ============================================================
2022-03-27 05:06:30,621: time cost, forward:0.014351753826728899, backward:0.036678080559412726, data cost:0.5468897458982079 
2022-03-27 05:06:30,621: ============================================================
2022-03-27 05:06:30,622: Epoch 19/38 Batch 7500/7662 eta: 22:53:06.768755	Training Loss 2.8310 (2.8591)	Training Prec@1 99.805 (99.525)	Training Prec@5 99.805 (99.853)	
2022-03-27 05:06:30,622: ============================================================
2022-03-27 05:07:27,929: time cost, forward:0.01432254794773765, backward:0.036639203459263664, data cost:0.5466233464130713 
2022-03-27 05:07:27,929: ============================================================
2022-03-27 05:07:27,929: Epoch 19/38 Batch 7600/7662 eta: 23:11:03.282230	Training Loss 3.0535 (2.8606)	Training Prec@1 99.219 (99.524)	Training Prec@5 99.805 (99.853)	
2022-03-27 05:07:27,929: ============================================================
2022-03-27 05:08:09,610: Epoch: 19/38 eta: 23:10:27.178477	Training Loss 2.9113 (2.8614)	Training Prec@1 98.828 (99.523)	Training Prec@5 99.805 (99.852)
2022-03-27 05:08:09,611: ============================================================
2022-03-27 05:09:08,481: time cost, forward:0.014132357606984149, backward:0.033713321493129535, data cost:0.5392195480038421 
2022-03-27 05:09:08,482: ============================================================
2022-03-27 05:09:08,482: Epoch 20/38 Batch 100/7662 eta: 23:41:58.517402	Training Loss 2.2549 (2.3536)	Training Prec@1 99.414 (99.783)	Training Prec@5 100.000 (99.937)	
2022-03-27 05:09:08,482: ============================================================
2022-03-27 05:10:04,412: time cost, forward:0.01527337572682443, backward:0.037701792453401654, data cost:0.5192152878746914 
2022-03-27 05:10:04,413: ============================================================
2022-03-27 05:10:04,413: Epoch 20/38 Batch 200/7662 eta: 22:35:12.378729	Training Loss 2.3379 (2.3236)	Training Prec@1 100.000 (99.784)	Training Prec@5 100.000 (99.939)	
2022-03-27 05:10:04,413: ============================================================
2022-03-27 05:11:01,239: time cost, forward:0.01579767645003405, backward:0.03773824825733402, data cost:0.5171797411098926 
2022-03-27 05:11:01,240: ============================================================
2022-03-27 05:11:01,240: Epoch 20/38 Batch 300/7662 eta: 22:55:57.110434	Training Loss 2.2475 (2.3032)	Training Prec@1 99.805 (99.791)	Training Prec@5 100.000 (99.942)	
2022-03-27 05:11:01,240: ============================================================
2022-03-27 05:12:01,872: time cost, forward:0.016100735891432988, backward:0.03774006743180124, data cost:0.524005142967205 
2022-03-27 05:12:01,876: ============================================================
2022-03-27 05:12:01,877: Epoch 20/38 Batch 400/7662 eta: 1 day, 0:27:12.010016	Training Loss 2.1558 (2.2905)	Training Prec@1 99.805 (99.787)	Training Prec@5 100.000 (99.939)	
2022-03-27 05:12:01,878: ============================================================
2022-03-27 05:13:02,488: time cost, forward:0.015999798784275092, backward:0.03730892657278057, data cost:0.531170485731595 
2022-03-27 05:13:02,489: ============================================================
2022-03-27 05:13:02,489: Epoch 20/38 Batch 500/7662 eta: 1 day, 0:25:35.801269	Training Loss 2.3067 (2.2780)	Training Prec@1 100.000 (99.796)	Training Prec@5 100.000 (99.943)	
2022-03-27 05:13:02,489: ============================================================
2022-03-27 05:14:03,358: time cost, forward:0.01607164556474638, backward:0.03760670978756301, data cost:0.5345920991021922 
2022-03-27 05:14:03,358: ============================================================
2022-03-27 05:14:03,358: Epoch 20/38 Batch 600/7662 eta: 1 day, 0:30:47.843314	Training Loss 2.1165 (2.2707)	Training Prec@1 99.609 (99.792)	Training Prec@5 99.805 (99.944)	
2022-03-27 05:14:03,359: ============================================================
2022-03-27 05:15:02,333: time cost, forward:0.01583097557482631, backward:0.0376417657336452, data cost:0.5344805209251262 
2022-03-27 05:15:02,333: ============================================================
2022-03-27 05:15:02,334: Epoch 20/38 Batch 700/7662 eta: 23:44:02.574565	Training Loss 2.3741 (2.2626)	Training Prec@1 99.805 (99.800)	Training Prec@5 99.805 (99.945)	
2022-03-27 05:15:02,334: ============================================================
2022-03-27 05:16:03,983: time cost, forward:0.01579610098885356, backward:0.03761909959910062, data cost:0.5382459471013877 
2022-03-27 05:16:03,984: ============================================================
2022-03-27 05:16:03,984: Epoch 20/38 Batch 800/7662 eta: 1 day, 0:47:36.864607	Training Loss 2.3196 (2.2556)	Training Prec@1 99.609 (99.804)	Training Prec@5 100.000 (99.945)	
2022-03-27 05:16:03,984: ============================================================
2022-03-27 05:17:04,330: time cost, forward:0.015657976286297247, backward:0.03768904111011408, data cost:0.5389661343397367 
2022-03-27 05:17:04,331: ============================================================
2022-03-27 05:17:04,331: Epoch 20/38 Batch 900/7662 eta: 1 day, 0:15:09.724333	Training Loss 2.1461 (2.2504)	Training Prec@1 99.805 (99.801)	Training Prec@5 100.000 (99.944)	
2022-03-27 05:17:04,331: ============================================================
2022-03-27 05:18:03,183: time cost, forward:0.01553779202061253, backward:0.03738469953412885, data cost:0.5393678385454852 
2022-03-27 05:18:03,184: ============================================================
2022-03-27 05:18:03,184: Epoch 20/38 Batch 1000/7662 eta: 23:38:08.857118	Training Loss 2.1104 (2.2432)	Training Prec@1 100.000 (99.806)	Training Prec@5 100.000 (99.946)	
2022-03-27 05:18:03,184: ============================================================
2022-03-27 05:19:05,796: time cost, forward:0.015444236413471476, backward:0.037116689612585595, data cost:0.5420684580156432 
2022-03-27 05:19:05,799: ============================================================
2022-03-27 05:19:05,800: Epoch 20/38 Batch 1100/7662 eta: 1 day, 1:07:46.122132	Training Loss 2.0379 (2.2387)	Training Prec@1 100.000 (99.805)	Training Prec@5 100.000 (99.946)	
2022-03-27 05:19:05,800: ============================================================
2022-03-27 05:20:06,948: time cost, forward:0.015527569720703328, backward:0.03737766867980448, data cost:0.5432991766750663 
2022-03-27 05:20:06,951: ============================================================
2022-03-27 05:20:06,951: Epoch 20/38 Batch 1200/7662 eta: 1 day, 0:31:29.960654	Training Loss 2.2846 (2.2342)	Training Prec@1 100.000 (99.804)	Training Prec@5 100.000 (99.945)	
2022-03-27 05:20:06,952: ============================================================
2022-03-27 05:21:08,467: time cost, forward:0.015483620535694149, backward:0.037701381730335874, data cost:0.5446584024642228 
2022-03-27 05:21:08,468: ============================================================
2022-03-27 05:21:08,468: Epoch 20/38 Batch 1300/7662 eta: 1 day, 0:39:16.116844	Training Loss 2.0812 (2.2303)	Training Prec@1 100.000 (99.805)	Training Prec@5 100.000 (99.946)	
2022-03-27 05:21:08,468: ============================================================
2022-03-27 05:22:09,761: time cost, forward:0.015609965314176612, backward:0.03794732104036278, data cost:0.5451848406379269 
2022-03-27 05:22:09,781: ============================================================
2022-03-27 05:22:09,781: Epoch 20/38 Batch 1400/7662 eta: 1 day, 0:33:20.979655	Training Loss 2.0264 (2.2263)	Training Prec@1 99.609 (99.804)	Training Prec@5 99.805 (99.946)	
2022-03-27 05:22:09,782: ============================================================
2022-03-27 05:23:11,081: time cost, forward:0.015665305304956724, backward:0.03806884595757727, data cost:0.5452494594238058 
2022-03-27 05:23:11,085: ============================================================
2022-03-27 05:23:11,087: Epoch 20/38 Batch 1500/7662 eta: 1 day, 0:32:06.838223	Training Loss 2.1754 (2.2231)	Training Prec@1 100.000 (99.805)	Training Prec@5 100.000 (99.946)	
2022-03-27 05:23:11,087: ============================================================
2022-03-27 05:24:09,376: time cost, forward:0.015617220456932692, backward:0.038017572798976454, data cost:0.5448867854213177 
2022-03-27 05:24:09,378: ============================================================
2022-03-27 05:24:09,379: Epoch 20/38 Batch 1600/7662 eta: 23:18:49.757741	Training Loss 2.0842 (2.2174)	Training Prec@1 100.000 (99.806)	Training Prec@5 100.000 (99.947)	
2022-03-27 05:24:09,380: ============================================================
2022-03-27 05:25:11,693: time cost, forward:0.015638139964974297, backward:0.03813871781639382, data cost:0.5460732930404008 
2022-03-27 05:25:11,696: ============================================================
2022-03-27 05:25:11,698: Epoch 20/38 Batch 1700/7662 eta: 1 day, 0:54:23.488178	Training Loss 2.2830 (2.2136)	Training Prec@1 100.000 (99.805)	Training Prec@5 100.000 (99.945)	
2022-03-27 05:25:11,698: ============================================================
2022-03-27 05:26:15,286: time cost, forward:0.015655046174630913, backward:0.038251208225311736, data cost:0.5478812908715444 
2022-03-27 05:26:15,289: ============================================================
2022-03-27 05:26:15,290: Epoch 20/38 Batch 1800/7662 eta: 1 day, 1:23:51.866961	Training Loss 2.0183 (2.2095)	Training Prec@1 99.805 (99.804)	Training Prec@5 100.000 (99.944)	
2022-03-27 05:26:15,292: ============================================================
2022-03-27 05:27:15,818: time cost, forward:0.015684814563608596, backward:0.03825403000568954, data cost:0.5480067496427804 
2022-03-27 05:27:15,819: ============================================================
2022-03-27 05:27:15,819: Epoch 20/38 Batch 1900/7662 eta: 1 day, 0:09:27.476703	Training Loss 2.1384 (2.2067)	Training Prec@1 100.000 (99.804)	Training Prec@5 100.000 (99.944)	
2022-03-27 05:27:15,819: ============================================================
2022-03-27 05:28:14,457: time cost, forward:0.01577363996997125, backward:0.038394540712319354, data cost:0.5468616944781061 
2022-03-27 05:28:14,458: ============================================================
2022-03-27 05:28:14,458: Epoch 20/38 Batch 2000/7662 eta: 23:23:13.606367	Training Loss 2.2044 (2.2021)	Training Prec@1 99.805 (99.806)	Training Prec@5 100.000 (99.944)	
2022-03-27 05:28:14,458: ============================================================
2022-03-27 05:29:15,881: time cost, forward:0.015762198703978502, backward:0.038391943373187146, data cost:0.547521427508023 
2022-03-27 05:29:15,881: ============================================================
2022-03-27 05:29:15,882: Epoch 20/38 Batch 2100/7662 eta: 1 day, 0:28:50.271436	Training Loss 2.0462 (2.1980)	Training Prec@1 100.000 (99.807)	Training Prec@5 100.000 (99.945)	
2022-03-27 05:29:15,882: ============================================================
2022-03-27 05:30:17,366: time cost, forward:0.01587438821901024, backward:0.03842544197873562, data cost:0.5477715384260857 
2022-03-27 05:30:17,366: ============================================================
2022-03-27 05:30:17,367: Epoch 20/38 Batch 2200/7662 eta: 1 day, 0:29:16.038914	Training Loss 2.0827 (2.1953)	Training Prec@1 100.000 (99.808)	Training Prec@5 100.000 (99.945)	
2022-03-27 05:30:17,367: ============================================================
2022-03-27 05:31:22,005: time cost, forward:0.015877726079070502, backward:0.03863228140005914, data cost:0.5492821935468676 
2022-03-27 05:31:22,006: ============================================================
2022-03-27 05:31:22,007: Epoch 20/38 Batch 2300/7662 eta: 1 day, 1:43:35.989152	Training Loss 2.2221 (2.1930)	Training Prec@1 99.609 (99.809)	Training Prec@5 100.000 (99.945)	
2022-03-27 05:31:22,007: ============================================================
2022-03-27 05:32:21,255: time cost, forward:0.01589299530325059, backward:0.03869018916439742, data cost:0.5488958188820601 
2022-03-27 05:32:21,255: ============================================================
2022-03-27 05:32:21,255: Epoch 20/38 Batch 2400/7662 eta: 23:33:51.477902	Training Loss 2.1667 (2.1897)	Training Prec@1 99.805 (99.811)	Training Prec@5 100.000 (99.946)	
2022-03-27 05:32:21,255: ============================================================
2022-03-27 05:33:20,891: time cost, forward:0.01596578496510909, backward:0.03859688215801457, data cost:0.5486093489061884 
2022-03-27 05:33:20,892: ============================================================
2022-03-27 05:33:20,892: Epoch 20/38 Batch 2500/7662 eta: 23:42:07.543726	Training Loss 2.3071 (2.1878)	Training Prec@1 99.805 (99.812)	Training Prec@5 100.000 (99.947)	
2022-03-27 05:33:20,892: ============================================================
2022-03-27 05:34:22,196: time cost, forward:0.015999114527157427, backward:0.03863660387462632, data cost:0.5488369263975196 
2022-03-27 05:34:22,197: ============================================================
2022-03-27 05:34:22,197: Epoch 20/38 Batch 2600/7662 eta: 1 day, 0:20:53.125373	Training Loss 2.2157 (2.1846)	Training Prec@1 99.805 (99.812)	Training Prec@5 100.000 (99.947)	
2022-03-27 05:34:22,197: ============================================================
2022-03-27 05:35:26,047: time cost, forward:0.016011006393093406, backward:0.03872699859452362, data cost:0.5496957752606567 
2022-03-27 05:35:26,050: ============================================================
2022-03-27 05:35:26,051: Epoch 20/38 Batch 2700/7662 eta: 1 day, 1:20:33.520077	Training Loss 2.1523 (2.1820)	Training Prec@1 99.414 (99.812)	Training Prec@5 99.609 (99.946)	
2022-03-27 05:35:26,051: ============================================================
2022-03-27 05:36:24,390: time cost, forward:0.016058351960340625, backward:0.03875057132553313, data cost:0.5491098966629175 
2022-03-27 05:36:24,390: ============================================================
2022-03-27 05:36:24,391: Epoch 20/38 Batch 2800/7662 eta: 23:08:17.226607	Training Loss 2.1505 (2.1791)	Training Prec@1 99.609 (99.813)	Training Prec@5 100.000 (99.947)	
2022-03-27 05:36:24,391: ============================================================
2022-03-27 05:37:21,567: time cost, forward:0.015993237536543196, backward:0.03870178716435191, data cost:0.5480574966916218 
2022-03-27 05:37:21,567: ============================================================
2022-03-27 05:37:21,567: Epoch 20/38 Batch 2900/7662 eta: 22:39:38.954821	Training Loss 1.9786 (2.1771)	Training Prec@1 100.000 (99.813)	Training Prec@5 100.000 (99.948)	
2022-03-27 05:37:21,567: ============================================================
2022-03-27 05:38:24,331: time cost, forward:0.01595400913272869, backward:0.038840746394631545, data cost:0.5487318410997432 
2022-03-27 05:38:24,332: ============================================================
2022-03-27 05:38:24,332: Epoch 20/38 Batch 3000/7662 eta: 1 day, 0:51:28.989858	Training Loss 2.0727 (2.1748)	Training Prec@1 100.000 (99.815)	Training Prec@5 100.000 (99.948)	
2022-03-27 05:38:24,332: ============================================================
2022-03-27 05:39:24,565: time cost, forward:0.01590603957371621, backward:0.03886522212771686, data cost:0.5487159276324035 
2022-03-27 05:39:24,565: ============================================================
2022-03-27 05:39:24,565: Epoch 20/38 Batch 3100/7662 eta: 23:50:20.122100	Training Loss 2.3197 (2.1730)	Training Prec@1 99.609 (99.815)	Training Prec@5 99.805 (99.949)	
2022-03-27 05:39:24,566: ============================================================
2022-03-27 05:40:29,076: time cost, forward:0.015972799045959836, backward:0.03892799637100778, data cost:0.5496646059643816 
2022-03-27 05:40:29,077: ============================================================
2022-03-27 05:40:29,077: Epoch 20/38 Batch 3200/7662 eta: 1 day, 1:30:51.392596	Training Loss 2.0752 (2.1708)	Training Prec@1 99.805 (99.815)	Training Prec@5 100.000 (99.949)	
2022-03-27 05:40:29,077: ============================================================
2022-03-27 05:41:25,613: time cost, forward:0.015919447956969788, backward:0.03884490940490612, data cost:0.5486977273097505 
2022-03-27 05:41:25,614: ============================================================
2022-03-27 05:41:25,614: Epoch 20/38 Batch 3300/7662 eta: 22:20:39.982007	Training Loss 2.0579 (2.1687)	Training Prec@1 99.805 (99.816)	Training Prec@5 100.000 (99.949)	
2022-03-27 05:41:25,614: ============================================================
2022-03-27 05:42:25,275: time cost, forward:0.015887332474634766, backward:0.038830450262241974, data cost:0.5485370894957023 
2022-03-27 05:42:25,275: ============================================================
2022-03-27 05:42:25,275: Epoch 20/38 Batch 3400/7662 eta: 23:33:45.936257	Training Loss 2.1324 (2.1671)	Training Prec@1 99.609 (99.816)	Training Prec@5 99.805 (99.949)	
2022-03-27 05:42:25,276: ============================================================
2022-03-27 05:43:27,387: time cost, forward:0.01591163670958775, backward:0.03883118968788097, data cost:0.5489955043138589 
2022-03-27 05:43:27,388: ============================================================
2022-03-27 05:43:27,388: Epoch 20/38 Batch 3500/7662 eta: 1 day, 0:30:48.961079	Training Loss 2.0492 (2.1656)	Training Prec@1 99.609 (99.816)	Training Prec@5 100.000 (99.949)	
2022-03-27 05:43:27,388: ============================================================
2022-03-27 05:44:26,506: time cost, forward:0.015885602901232976, backward:0.03889865880543803, data cost:0.5485848269551354 
2022-03-27 05:44:26,507: ============================================================
2022-03-27 05:44:26,507: Epoch 20/38 Batch 3600/7662 eta: 23:18:56.711523	Training Loss 1.9119 (2.1637)	Training Prec@1 99.805 (99.817)	Training Prec@5 100.000 (99.949)	
2022-03-27 05:44:26,507: ============================================================
2022-03-27 05:45:23,404: time cost, forward:0.01583139991141487, backward:0.038830474119761337, data cost:0.5477364823185904 
2022-03-27 05:45:23,405: ============================================================
2022-03-27 05:45:23,405: Epoch 20/38 Batch 3700/7662 eta: 22:25:25.785051	Training Loss 2.1797 (2.1615)	Training Prec@1 99.414 (99.817)	Training Prec@5 99.805 (99.949)	
2022-03-27 05:45:23,405: ============================================================
2022-03-27 05:46:23,944: time cost, forward:0.015863708522201182, backward:0.03892367982525485, data cost:0.5476486377259184 
2022-03-27 05:46:23,944: ============================================================
2022-03-27 05:46:23,945: Epoch 20/38 Batch 3800/7662 eta: 23:50:32.743561	Training Loss 2.0582 (2.1598)	Training Prec@1 99.609 (99.817)	Training Prec@5 99.805 (99.949)	
2022-03-27 05:46:23,945: ============================================================
2022-03-27 05:47:24,571: time cost, forward:0.015923026770498547, backward:0.03897882694157309, data cost:0.5475782396610531 
2022-03-27 05:47:24,572: ============================================================
2022-03-27 05:47:24,572: Epoch 20/38 Batch 3900/7662 eta: 23:51:36.196989	Training Loss 2.0489 (2.1578)	Training Prec@1 99.805 (99.818)	Training Prec@5 100.000 (99.949)	
2022-03-27 05:47:24,572: ============================================================
2022-03-27 05:48:27,344: time cost, forward:0.015944770885485654, backward:0.03892764636175905, data cost:0.5482067256964693 
2022-03-27 05:48:27,345: ============================================================
2022-03-27 05:48:27,345: Epoch 20/38 Batch 4000/7662 eta: 1 day, 0:41:13.161877	Training Loss 2.0522 (2.1559)	Training Prec@1 100.000 (99.819)	Training Prec@5 100.000 (99.950)	
2022-03-27 05:48:27,345: ============================================================
2022-03-27 05:49:28,000: time cost, forward:0.01593269014044429, backward:0.03891272136542122, data cost:0.5482804702531713 
2022-03-27 05:49:28,001: ============================================================
2022-03-27 05:49:28,001: Epoch 20/38 Batch 4100/7662 eta: 23:50:16.110946	Training Loss 2.2340 (2.1541)	Training Prec@1 100.000 (99.820)	Training Prec@5 100.000 (99.950)	
2022-03-27 05:49:28,001: ============================================================
2022-03-27 05:50:27,350: time cost, forward:0.01593731743689235, backward:0.03892072390079158, data cost:0.5480269915037252 
2022-03-27 05:50:27,351: ============================================================
2022-03-27 05:50:27,351: Epoch 20/38 Batch 4200/7662 eta: 23:18:28.473780	Training Loss 1.9741 (2.1527)	Training Prec@1 99.609 (99.820)	Training Prec@5 100.000 (99.950)	
2022-03-27 05:50:27,351: ============================================================
2022-03-27 05:51:27,776: time cost, forward:0.015949917604934895, backward:0.03895772582127566, data cost:0.5479399372627913 
2022-03-27 05:51:27,781: ============================================================
2022-03-27 05:51:27,782: Epoch 20/38 Batch 4300/7662 eta: 23:42:54.875542	Training Loss 2.1198 (2.1511)	Training Prec@1 99.805 (99.821)	Training Prec@5 100.000 (99.950)	
2022-03-27 05:51:27,783: ============================================================
2022-03-27 05:52:28,836: time cost, forward:0.016001226306368098, backward:0.03898301019427938, data cost:0.5480132337103217 
2022-03-27 05:52:28,837: ============================================================
2022-03-27 05:52:28,837: Epoch 20/38 Batch 4400/7662 eta: 23:56:38.326639	Training Loss 2.1739 (2.1494)	Training Prec@1 99.805 (99.822)	Training Prec@5 100.000 (99.951)	
2022-03-27 05:52:28,837: ============================================================
2022-03-27 05:53:29,238: time cost, forward:0.016010159464723984, backward:0.0389853054800413, data cost:0.5479088166629666 
2022-03-27 05:53:29,241: ============================================================
2022-03-27 05:53:29,242: Epoch 20/38 Batch 4500/7662 eta: 23:40:18.002003	Training Loss 1.9840 (2.1477)	Training Prec@1 99.609 (99.822)	Training Prec@5 100.000 (99.951)	
2022-03-27 05:53:29,244: ============================================================
2022-03-27 05:54:28,443: time cost, forward:0.016034379215908195, backward:0.03904890200189207, data cost:0.5475945463904248 
2022-03-27 05:54:28,444: ============================================================
2022-03-27 05:54:28,444: Epoch 20/38 Batch 4600/7662 eta: 23:11:02.673481	Training Loss 2.1302 (2.1460)	Training Prec@1 99.805 (99.823)	Training Prec@5 100.000 (99.951)	
2022-03-27 05:54:28,444: ============================================================
2022-03-27 05:55:31,189: time cost, forward:0.016022469038962303, backward:0.0390678504904069, data cost:0.548112394049158 
2022-03-27 05:55:31,190: ============================================================
2022-03-27 05:55:31,190: Epoch 20/38 Batch 4700/7662 eta: 1 day, 0:33:15.906847	Training Loss 2.2140 (2.1448)	Training Prec@1 99.805 (99.823)	Training Prec@5 100.000 (99.951)	
2022-03-27 05:55:31,190: ============================================================
2022-03-27 05:56:32,189: time cost, forward:0.015987306715275103, backward:0.039035909447627255, data cost:0.5483349211689432 
2022-03-27 05:56:32,190: ============================================================
2022-03-27 05:56:32,190: Epoch 20/38 Batch 4800/7662 eta: 23:51:15.162813	Training Loss 2.1618 (2.1432)	Training Prec@1 99.609 (99.823)	Training Prec@5 99.805 (99.951)	
2022-03-27 05:56:32,190: ============================================================
2022-03-27 05:57:31,463: time cost, forward:0.015963266226290976, backward:0.03904281024617501, data cost:0.5481068411513867 
2022-03-27 05:57:31,464: ============================================================
2022-03-27 05:57:31,464: Epoch 20/38 Batch 4900/7662 eta: 23:09:45.893267	Training Loss 2.0682 (2.1417)	Training Prec@1 99.414 (99.823)	Training Prec@5 99.805 (99.951)	
2022-03-27 05:57:31,464: ============================================================
2022-03-27 05:58:30,009: time cost, forward:0.015932245096174996, backward:0.03900841556327012, data cost:0.5477248528261713 
2022-03-27 05:58:30,013: ============================================================
2022-03-27 05:58:30,014: Epoch 20/38 Batch 5000/7662 eta: 22:51:48.371639	Training Loss 2.1709 (2.1400)	Training Prec@1 100.000 (99.824)	Training Prec@5 100.000 (99.951)	
2022-03-27 05:58:30,014: ============================================================
2022-03-27 05:59:29,197: time cost, forward:0.01593962064512245, backward:0.03906204948754469, data cost:0.5474931237089281 
2022-03-27 05:59:29,197: ============================================================
2022-03-27 05:59:29,197: Epoch 20/38 Batch 5100/7662 eta: 23:05:40.865975	Training Loss 2.0587 (2.1386)	Training Prec@1 99.805 (99.824)	Training Prec@5 100.000 (99.951)	
2022-03-27 05:59:29,197: ============================================================
2022-03-27 06:00:31,976: time cost, forward:0.01596138105412634, backward:0.03912998901282074, data cost:0.5478757440321582 
2022-03-27 06:00:31,976: ============================================================
2022-03-27 06:00:31,976: Epoch 20/38 Batch 5200/7662 eta: 1 day, 0:28:48.650952	Training Loss 2.1569 (2.1376)	Training Prec@1 99.805 (99.824)	Training Prec@5 100.000 (99.952)	
2022-03-27 06:00:31,977: ============================================================
2022-03-27 06:01:35,143: time cost, forward:0.01595470351438564, backward:0.0391733915901652, data cost:0.5483650823745396 
2022-03-27 06:01:35,144: ============================================================
2022-03-27 06:01:35,144: Epoch 20/38 Batch 5300/7662 eta: 1 day, 0:36:51.150065	Training Loss 1.7681 (2.1362)	Training Prec@1 100.000 (99.825)	Training Prec@5 100.000 (99.952)	
2022-03-27 06:01:35,145: ============================================================
2022-03-27 06:02:30,665: time cost, forward:0.01592917551837998, backward:0.03913057515037835, data cost:0.547517212215762 
2022-03-27 06:02:30,665: ============================================================
2022-03-27 06:02:30,665: Epoch 20/38 Batch 5400/7662 eta: 21:37:09.071222	Training Loss 2.2556 (2.1348)	Training Prec@1 99.609 (99.825)	Training Prec@5 100.000 (99.952)	
2022-03-27 06:02:30,666: ============================================================
2022-03-27 06:03:32,530: time cost, forward:0.01591288507971076, backward:0.03905945843968701, data cost:0.5477736558149372 
2022-03-27 06:03:32,533: ============================================================
2022-03-27 06:03:32,535: Epoch 20/38 Batch 5500/7662 eta: 1 day, 0:04:25.277736	Training Loss 2.0072 (2.1334)	Training Prec@1 99.805 (99.825)	Training Prec@5 99.805 (99.952)	
2022-03-27 06:03:32,535: ============================================================
2022-03-27 06:04:30,094: time cost, forward:0.015869558996591298, backward:0.038959816963167186, data cost:0.5474692361017149 
2022-03-27 06:04:30,097: ============================================================
2022-03-27 06:04:30,098: Epoch 20/38 Batch 5600/7662 eta: 22:22:56.543574	Training Loss 2.0352 (2.1320)	Training Prec@1 99.609 (99.825)	Training Prec@5 100.000 (99.952)	
2022-03-27 06:04:30,099: ============================================================
2022-03-27 06:05:31,026: time cost, forward:0.015880028099987797, backward:0.03896201729962733, data cost:0.5475762294539026 
2022-03-27 06:05:31,027: ============================================================
2022-03-27 06:05:31,027: Epoch 20/38 Batch 5700/7662 eta: 23:40:27.015173	Training Loss 2.1209 (2.1305)	Training Prec@1 99.805 (99.825)	Training Prec@5 100.000 (99.952)	
2022-03-27 06:05:31,027: ============================================================
2022-03-27 06:06:30,547: time cost, forward:0.015877545013532987, backward:0.038985928948078924, data cost:0.5473935729903504 
2022-03-27 06:06:30,548: ============================================================
2022-03-27 06:06:30,548: Epoch 20/38 Batch 5800/7662 eta: 23:06:38.449664	Training Loss 2.0202 (2.1291)	Training Prec@1 100.000 (99.826)	Training Prec@5 100.000 (99.952)	
2022-03-27 06:06:30,549: ============================================================
2022-03-27 06:07:30,813: time cost, forward:0.015881386989859286, backward:0.038990273275988085, data cost:0.5472476249994879 
2022-03-27 06:07:30,817: ============================================================
2022-03-27 06:07:30,818: Epoch 20/38 Batch 5900/7662 eta: 23:23:03.467607	Training Loss 1.7239 (2.1277)	Training Prec@1 100.000 (99.826)	Training Prec@5 100.000 (99.953)	
2022-03-27 06:07:30,819: ============================================================
2022-03-27 06:08:30,667: time cost, forward:0.015884582311595594, backward:0.03896753774879177, data cost:0.5472028338525629 
2022-03-27 06:08:30,670: ============================================================
2022-03-27 06:08:30,671: Epoch 20/38 Batch 6000/7662 eta: 23:12:22.606790	Training Loss 1.7590 (2.1261)	Training Prec@1 100.000 (99.826)	Training Prec@5 100.000 (99.952)	
2022-03-27 06:08:30,673: ============================================================
2022-03-27 06:09:31,109: time cost, forward:0.015889097421086015, backward:0.03896550237790427, data cost:0.5473455663860225 
2022-03-27 06:09:31,110: ============================================================
2022-03-27 06:09:31,110: Epoch 20/38 Batch 6100/7662 eta: 23:24:59.746578	Training Loss 2.1399 (2.1251)	Training Prec@1 100.000 (99.826)	Training Prec@5 100.000 (99.952)	
2022-03-27 06:09:31,110: ============================================================
2022-03-27 06:10:28,324: time cost, forward:0.015863389233501328, backward:0.038839732971782163, data cost:0.5469596278265535 
2022-03-27 06:10:28,324: ============================================================
2022-03-27 06:10:28,324: Epoch 20/38 Batch 6200/7662 eta: 22:09:05.012840	Training Loss 1.9694 (2.1239)	Training Prec@1 99.805 (99.827)	Training Prec@5 100.000 (99.952)	
2022-03-27 06:10:28,324: ============================================================
2022-03-27 06:11:27,278: time cost, forward:0.01588401807302671, backward:0.03877740599727192, data cost:0.5468196663748255 
2022-03-27 06:11:27,278: ============================================================
2022-03-27 06:11:27,279: Epoch 20/38 Batch 6300/7662 eta: 22:48:31.028133	Training Loss 2.0600 (2.1227)	Training Prec@1 100.000 (99.827)	Training Prec@5 100.000 (99.952)	
2022-03-27 06:11:27,279: ============================================================
2022-03-27 06:12:29,061: time cost, forward:0.015878266627983407, backward:0.038773119607965055, data cost:0.5469883399599138 
2022-03-27 06:12:29,065: ============================================================
2022-03-27 06:12:29,065: Epoch 20/38 Batch 6400/7662 eta: 23:53:13.276658	Training Loss 1.8584 (2.1216)	Training Prec@1 100.000 (99.827)	Training Prec@5 100.000 (99.953)	
2022-03-27 06:12:29,066: ============================================================
2022-03-27 06:13:27,321: time cost, forward:0.015888751002527565, backward:0.0387615765731396, data cost:0.5466723615966552 
2022-03-27 06:13:27,322: ============================================================
2022-03-27 06:13:27,323: Epoch 20/38 Batch 6500/7662 eta: 22:30:23.899588	Training Loss 1.9869 (2.1203)	Training Prec@1 99.805 (99.827)	Training Prec@5 100.000 (99.953)	
2022-03-27 06:13:27,323: ============================================================
2022-03-27 06:14:28,748: time cost, forward:0.01591238330252009, backward:0.03878298996614496, data cost:0.5468680372670268 
2022-03-27 06:14:28,748: ============================================================
2022-03-27 06:14:28,749: Epoch 20/38 Batch 6600/7662 eta: 23:42:49.643628	Training Loss 1.9520 (2.1191)	Training Prec@1 100.000 (99.828)	Training Prec@5 100.000 (99.953)	
2022-03-27 06:14:28,749: ============================================================
2022-03-27 06:15:31,690: time cost, forward:0.01592296143933399, backward:0.03880081537642182, data cost:0.5472575123051349 
2022-03-27 06:15:31,690: ============================================================
2022-03-27 06:15:31,690: Epoch 20/38 Batch 6700/7662 eta: 1 day, 0:16:52.937618	Training Loss 2.0014 (2.1180)	Training Prec@1 100.000 (99.829)	Training Prec@5 100.000 (99.953)	
2022-03-27 06:15:31,691: ============================================================
2022-03-27 06:16:29,852: time cost, forward:0.015917983050205406, backward:0.03882747156547438, data cost:0.5469187356949133 
2022-03-27 06:16:29,852: ============================================================
2022-03-27 06:16:29,852: Epoch 20/38 Batch 6800/7662 eta: 22:25:16.581348	Training Loss 2.0762 (2.1169)	Training Prec@1 99.805 (99.829)	Training Prec@5 100.000 (99.953)	
2022-03-27 06:16:29,853: ============================================================
2022-03-27 06:17:27,926: time cost, forward:0.0158866583946771, backward:0.038800082322151215, data cost:0.5465687577802905 
2022-03-27 06:17:27,928: ============================================================
2022-03-27 06:17:27,928: Epoch 20/38 Batch 6900/7662 eta: 22:22:18.746171	Training Loss 1.8846 (2.1162)	Training Prec@1 99.805 (99.829)	Training Prec@5 99.805 (99.953)	
2022-03-27 06:17:27,929: ============================================================
2022-03-27 06:18:28,362: time cost, forward:0.015897565440529327, backward:0.038811389336093426, data cost:0.5466328759349437 
2022-03-27 06:18:28,363: ============================================================
2022-03-27 06:18:28,363: Epoch 20/38 Batch 7000/7662 eta: 23:15:50.369893	Training Loss 2.1181 (2.1151)	Training Prec@1 99.609 (99.830)	Training Prec@5 100.000 (99.953)	
2022-03-27 06:18:28,364: ============================================================
2022-03-27 06:19:28,373: time cost, forward:0.01588793351022538, backward:0.03877606444299045, data cost:0.5466586756259559 
2022-03-27 06:19:28,374: ============================================================
2022-03-27 06:19:28,374: Epoch 20/38 Batch 7100/7662 eta: 23:05:02.119508	Training Loss 2.3046 (2.1140)	Training Prec@1 100.000 (99.830)	Training Prec@5 100.000 (99.953)	
2022-03-27 06:19:28,374: ============================================================
2022-03-27 06:20:30,909: time cost, forward:0.015877450832245597, backward:0.038776312922252386, data cost:0.5469884673726776 
2022-03-27 06:20:30,909: ============================================================
2022-03-27 06:20:30,909: Epoch 20/38 Batch 7200/7662 eta: 1 day, 0:02:15.649897	Training Loss 1.9967 (2.1129)	Training Prec@1 100.000 (99.830)	Training Prec@5 100.000 (99.953)	
2022-03-27 06:20:30,909: ============================================================
2022-03-27 06:21:28,523: time cost, forward:0.01586431750762559, backward:0.03878674113206593, data cost:0.5466215064352808 
2022-03-27 06:21:28,524: ============================================================
2022-03-27 06:21:28,524: Epoch 20/38 Batch 7300/7662 eta: 22:07:49.666751	Training Loss 2.0926 (2.1116)	Training Prec@1 100.000 (99.831)	Training Prec@5 100.000 (99.954)	
2022-03-27 06:21:28,525: ============================================================
2022-03-27 06:22:28,499: time cost, forward:0.01586172506283676, backward:0.03880151556478769, data cost:0.5465834786528139 
2022-03-27 06:22:28,499: ============================================================
2022-03-27 06:22:28,499: Epoch 20/38 Batch 7400/7662 eta: 23:01:12.864672	Training Loss 2.2036 (2.1107)	Training Prec@1 100.000 (99.831)	Training Prec@5 100.000 (99.954)	
2022-03-27 06:22:28,500: ============================================================
2022-03-27 06:23:30,496: time cost, forward:0.01587528008622382, backward:0.038802565312541344, data cost:0.5467946368831843 
2022-03-27 06:23:30,496: ============================================================
2022-03-27 06:23:30,496: Epoch 20/38 Batch 7500/7662 eta: 23:46:44.934717	Training Loss 2.0499 (2.1097)	Training Prec@1 100.000 (99.832)	Training Prec@5 100.000 (99.954)	
2022-03-27 06:23:30,497: ============================================================
2022-03-27 06:24:28,134: time cost, forward:0.01585197894255383, backward:0.03878315700827688, data cost:0.5464965294404851 
2022-03-27 06:24:28,135: ============================================================
2022-03-27 06:24:28,135: Epoch 20/38 Batch 7600/7662 eta: 22:05:28.956140	Training Loss 1.9477 (2.1085)	Training Prec@1 100.000 (99.832)	Training Prec@5 100.000 (99.954)	
2022-03-27 06:24:28,135: ============================================================
2022-03-27 06:25:06,158: Epoch: 20/38 eta: 22:04:52.643917	Training Loss 1.9646 (2.1078)	Training Prec@1 99.805 (99.832)	Training Prec@5 99.805 (99.954)
2022-03-27 06:25:06,158: ============================================================
2022-03-27 06:25:06,232: Save Checkpoint...
2022-03-27 06:25:06,233: ============================================================
2022-03-27 06:25:09,104: Save done!
2022-03-27 06:25:09,104: ============================================================
2022-03-27 06:26:10,050: time cost, forward:0.013009100249319366, backward:0.03742328797928011, data cost:0.5579105916649404 
2022-03-27 06:26:10,054: ============================================================
2022-03-27 06:26:10,055: Epoch 21/38 Batch 100/7662 eta: 23:18:57.194417	Training Loss 1.9908 (1.8652)	Training Prec@1 99.805 (99.909)	Training Prec@5 99.805 (99.976)	
2022-03-27 06:26:10,056: ============================================================
2022-03-27 06:27:09,197: time cost, forward:0.013132803404151495, backward:0.03540042536941605, data cost:0.5511893363454234 
2022-03-27 06:27:09,197: ============================================================
2022-03-27 06:27:09,197: Epoch 21/38 Batch 200/7662 eta: 22:37:29.472969	Training Loss 2.0043 (1.8594)	Training Prec@1 100.000 (99.912)	Training Prec@5 100.000 (99.970)	
2022-03-27 06:27:09,197: ============================================================
2022-03-27 06:28:10,760: time cost, forward:0.013814522669865536, backward:0.03604422763837221, data cost:0.5549434945734847 
2022-03-27 06:28:10,761: ============================================================
2022-03-27 06:28:10,761: Epoch 21/38 Batch 300/7662 eta: 23:32:02.390286	Training Loss 1.7703 (1.8601)	Training Prec@1 100.000 (99.914)	Training Prec@5 100.000 (99.975)	
2022-03-27 06:28:10,761: ============================================================
2022-03-27 06:29:13,814: time cost, forward:0.01398720179584092, backward:0.03679891875513215, data cost:0.5593091987428211 
2022-03-27 06:29:13,814: ============================================================
2022-03-27 06:29:13,814: Epoch 21/38 Batch 400/7662 eta: 1 day, 0:05:09.077248	Training Loss 1.8218 (1.8619)	Training Prec@1 100.000 (99.918)	Training Prec@5 100.000 (99.979)	
2022-03-27 06:29:13,815: ============================================================
2022-03-27 06:30:15,538: time cost, forward:0.014136663658585482, backward:0.03669635470740064, data cost:0.5610323176833097 
2022-03-27 06:30:15,538: ============================================================
2022-03-27 06:30:15,538: Epoch 21/38 Batch 500/7662 eta: 23:33:39.161259	Training Loss 2.0047 (1.8629)	Training Prec@1 100.000 (99.920)	Training Prec@5 100.000 (99.980)	
2022-03-27 06:30:15,539: ============================================================
2022-03-27 06:31:16,407: time cost, forward:0.01437021814324024, backward:0.03682468649939026, data cost:0.5600684059283172 
2022-03-27 06:31:16,407: ============================================================
2022-03-27 06:31:16,407: Epoch 21/38 Batch 600/7662 eta: 23:13:03.474196	Training Loss 1.8131 (1.8638)	Training Prec@1 100.000 (99.914)	Training Prec@5 100.000 (99.979)	
2022-03-27 06:31:16,408: ============================================================
2022-03-27 06:32:16,734: time cost, forward:0.014569970841742039, backward:0.036819726100807026, data cost:0.5584613922157342 
2022-03-27 06:32:16,734: ============================================================
2022-03-27 06:32:16,734: Epoch 21/38 Batch 700/7662 eta: 22:59:39.003818	Training Loss 1.7766 (1.8639)	Training Prec@1 100.000 (99.913)	Training Prec@5 100.000 (99.978)	
2022-03-27 06:32:16,735: ============================================================
2022-03-27 06:33:17,833: time cost, forward:0.014576604578163805, backward:0.03694884201164389, data cost:0.5583675952071093 
2022-03-27 06:33:17,834: ============================================================
2022-03-27 06:33:17,834: Epoch 21/38 Batch 800/7662 eta: 23:16:17.649647	Training Loss 1.8990 (1.8632)	Training Prec@1 100.000 (99.914)	Training Prec@5 100.000 (99.980)	
2022-03-27 06:33:17,834: ============================================================
2022-03-27 06:34:19,229: time cost, forward:0.015000602692465097, backward:0.037409837837346534, data cost:0.5577561606024211 
2022-03-27 06:34:19,230: ============================================================
2022-03-27 06:34:19,230: Epoch 21/38 Batch 900/7662 eta: 23:22:02.938574	Training Loss 1.9378 (1.8660)	Training Prec@1 100.000 (99.912)	Training Prec@5 100.000 (99.978)	
2022-03-27 06:34:19,230: ============================================================
2022-03-27 06:35:21,216: time cost, forward:0.01503900937489919, backward:0.03749790683284297, data cost:0.5584839232810386 
2022-03-27 06:35:21,217: ============================================================
2022-03-27 06:35:21,217: Epoch 21/38 Batch 1000/7662 eta: 23:34:30.964056	Training Loss 1.9729 (1.8661)	Training Prec@1 100.000 (99.915)	Training Prec@5 100.000 (99.979)	
2022-03-27 06:35:21,217: ============================================================
2022-03-27 06:36:25,820: time cost, forward:0.015243201607243378, backward:0.03778659765887412, data cost:0.5610268489136492 
2022-03-27 06:36:25,821: ============================================================
2022-03-27 06:36:25,821: Epoch 21/38 Batch 1100/7662 eta: 1 day, 0:33:09.086814	Training Loss 1.8866 (1.8662)	Training Prec@1 99.805 (99.915)	Training Prec@5 100.000 (99.978)	
2022-03-27 06:36:25,821: ============================================================
2022-03-27 06:37:27,072: time cost, forward:0.015447647796261798, backward:0.038092981685291634, data cost:0.5602516563262813 
2022-03-27 06:37:27,074: ============================================================
2022-03-27 06:37:27,074: Epoch 21/38 Batch 1200/7662 eta: 23:15:43.601080	Training Loss 1.8690 (1.8665)	Training Prec@1 100.000 (99.915)	Training Prec@5 100.000 (99.978)	
2022-03-27 06:37:27,075: ============================================================
2022-03-27 06:38:27,807: time cost, forward:0.015654866561419786, backward:0.038558120632098215, data cost:0.5588139659905085 
2022-03-27 06:38:27,808: ============================================================
2022-03-27 06:38:27,808: Epoch 21/38 Batch 1300/7662 eta: 23:02:53.090555	Training Loss 1.8793 (1.8684)	Training Prec@1 100.000 (99.914)	Training Prec@5 100.000 (99.978)	
2022-03-27 06:38:27,809: ============================================================
2022-03-27 06:39:30,392: time cost, forward:0.01568770289335871, backward:0.03843738472061212, data cost:0.559649048744567 
2022-03-27 06:39:30,393: ============================================================
2022-03-27 06:39:30,393: Epoch 21/38 Batch 1400/7662 eta: 23:43:58.743329	Training Loss 1.8251 (1.8682)	Training Prec@1 100.000 (99.914)	Training Prec@5 100.000 (99.977)	
2022-03-27 06:39:30,393: ============================================================
2022-03-27 06:40:28,088: time cost, forward:0.015547113946630924, backward:0.03817780976934859, data cost:0.5576976880460998 
2022-03-27 06:40:28,089: ============================================================
2022-03-27 06:40:28,089: Epoch 21/38 Batch 1500/7662 eta: 21:51:47.411349	Training Loss 1.7833 (1.8691)	Training Prec@1 100.000 (99.914)	Training Prec@5 100.000 (99.978)	
2022-03-27 06:40:28,089: ============================================================
2022-03-27 06:41:29,450: time cost, forward:0.015611247169442144, backward:0.03834597746829378, data cost:0.5575323877221275 
2022-03-27 06:41:29,451: ============================================================
2022-03-27 06:41:29,451: Epoch 21/38 Batch 1600/7662 eta: 23:14:06.331492	Training Loss 2.1242 (1.8704)	Training Prec@1 99.609 (99.913)	Training Prec@5 100.000 (99.978)	
2022-03-27 06:41:29,451: ============================================================
2022-03-27 06:42:30,244: time cost, forward:0.015738613820202283, backward:0.038570598829066216, data cost:0.5568969589320963 
2022-03-27 06:42:30,244: ============================================================
2022-03-27 06:42:30,244: Epoch 21/38 Batch 1700/7662 eta: 23:00:11.190294	Training Loss 1.9321 (1.8716)	Training Prec@1 100.000 (99.912)	Training Prec@5 100.000 (99.978)	
2022-03-27 06:42:30,245: ============================================================
2022-03-27 06:43:33,313: time cost, forward:0.01583856751747831, backward:0.038615512609349284, data cost:0.5575016110787596 
2022-03-27 06:43:33,314: ============================================================
2022-03-27 06:43:33,314: Epoch 21/38 Batch 1800/7662 eta: 23:50:48.553372	Training Loss 1.6893 (1.8729)	Training Prec@1 99.805 (99.912)	Training Prec@5 99.805 (99.978)	
2022-03-27 06:43:33,314: ============================================================
2022-03-27 06:44:33,688: time cost, forward:0.01582092307252969, backward:0.03864340696791839, data cost:0.5572367372357135 
2022-03-27 06:44:33,688: ============================================================
2022-03-27 06:44:33,689: Epoch 21/38 Batch 1900/7662 eta: 22:48:39.758182	Training Loss 1.9067 (1.8741)	Training Prec@1 100.000 (99.911)	Training Prec@5 100.000 (99.977)	
2022-03-27 06:44:33,689: ============================================================
2022-03-27 06:45:33,605: time cost, forward:0.0158250703997705, backward:0.03856946636045379, data cost:0.5566207310627436 
2022-03-27 06:45:33,606: ============================================================
2022-03-27 06:45:33,606: Epoch 21/38 Batch 2000/7662 eta: 22:37:17.782688	Training Loss 1.9287 (1.8756)	Training Prec@1 100.000 (99.911)	Training Prec@5 100.000 (99.977)	
2022-03-27 06:45:33,606: ============================================================
2022-03-27 06:46:33,572: time cost, forward:0.015846097736258686, backward:0.03861661170879507, data cost:0.5559580462384417 
2022-03-27 06:46:33,572: ============================================================
2022-03-27 06:46:33,573: Epoch 21/38 Batch 2100/7662 eta: 22:37:24.793327	Training Loss 1.7937 (1.8766)	Training Prec@1 100.000 (99.912)	Training Prec@5 100.000 (99.977)	
2022-03-27 06:46:33,573: ============================================================
2022-03-27 06:47:35,806: time cost, forward:0.015943266576721, backward:0.03871080982733879, data cost:0.5561339772793855 
2022-03-27 06:47:35,807: ============================================================
2022-03-27 06:47:35,807: Epoch 21/38 Batch 2200/7662 eta: 23:27:42.799508	Training Loss 1.8705 (1.8773)	Training Prec@1 100.000 (99.912)	Training Prec@5 100.000 (99.978)	
2022-03-27 06:47:35,807: ============================================================
2022-03-27 06:48:38,364: time cost, forward:0.016120217478031593, backward:0.03885239297900837, data cost:0.5564220136225145 
2022-03-27 06:48:38,365: ============================================================
2022-03-27 06:48:38,366: Epoch 21/38 Batch 2300/7662 eta: 23:33:59.972008	Training Loss 1.8097 (1.8784)	Training Prec@1 100.000 (99.912)	Training Prec@5 100.000 (99.977)	
2022-03-27 06:48:38,366: ============================================================
2022-03-27 06:49:38,706: time cost, forward:0.016077519158812153, backward:0.03876673673380907, data cost:0.5560188244759614 
2022-03-27 06:49:38,707: ============================================================
2022-03-27 06:49:38,707: Epoch 21/38 Batch 2400/7662 eta: 22:42:52.757015	Training Loss 1.8952 (1.8798)	Training Prec@1 99.805 (99.911)	Training Prec@5 100.000 (99.977)	
2022-03-27 06:49:38,707: ============================================================
2022-03-27 06:50:39,338: time cost, forward:0.016097708576533643, backward:0.038821306358389304, data cost:0.555742873244879 
2022-03-27 06:50:39,339: ============================================================
2022-03-27 06:50:39,339: Epoch 21/38 Batch 2500/7662 eta: 22:48:26.230406	Training Loss 1.8157 (1.8806)	Training Prec@1 100.000 (99.911)	Training Prec@5 100.000 (99.977)	
2022-03-27 06:50:39,339: ============================================================
2022-03-27 06:51:40,042: time cost, forward:0.0161070969527664, backward:0.038884816145887735, data cost:0.5555327654160092 
2022-03-27 06:51:40,042: ============================================================
2022-03-27 06:51:40,043: Epoch 21/38 Batch 2600/7662 eta: 22:49:02.009637	Training Loss 2.0352 (1.8811)	Training Prec@1 99.609 (99.910)	Training Prec@5 99.805 (99.976)	
2022-03-27 06:51:40,043: ============================================================
2022-03-27 06:52:42,235: time cost, forward:0.01608259009184242, backward:0.03888971022033126, data cost:0.5559721909085218 
2022-03-27 06:52:42,235: ============================================================
2022-03-27 06:52:42,235: Epoch 21/38 Batch 2700/7662 eta: 23:21:35.379963	Training Loss 1.9418 (1.8812)	Training Prec@1 99.805 (99.910)	Training Prec@5 100.000 (99.976)	
2022-03-27 06:52:42,236: ============================================================
2022-03-27 06:53:42,623: time cost, forward:0.016077722639388465, backward:0.03886220939843388, data cost:0.5557161409882998 
2022-03-27 06:53:42,624: ============================================================
2022-03-27 06:53:42,624: Epoch 21/38 Batch 2800/7662 eta: 22:39:55.239363	Training Loss 1.9305 (1.8816)	Training Prec@1 99.805 (99.909)	Training Prec@5 100.000 (99.976)	
2022-03-27 06:53:42,624: ============================================================
2022-03-27 06:54:45,857: time cost, forward:0.016157180862453074, backward:0.03897498220606235, data cost:0.5561277877877359 
2022-03-27 06:54:45,858: ============================================================
2022-03-27 06:54:45,859: Epoch 21/38 Batch 2900/7662 eta: 23:42:57.305458	Training Loss 1.8021 (1.8822)	Training Prec@1 99.805 (99.909)	Training Prec@5 100.000 (99.976)	
2022-03-27 06:54:45,859: ============================================================
2022-03-27 06:55:48,029: time cost, forward:0.016185404102418293, backward:0.038966131114927915, data cost:0.5564807757968782 
2022-03-27 06:55:48,034: ============================================================
2022-03-27 06:55:48,035: Epoch 21/38 Batch 3000/7662 eta: 23:18:05.535704	Training Loss 2.0433 (1.8835)	Training Prec@1 100.000 (99.909)	Training Prec@5 100.000 (99.976)	
2022-03-27 06:55:48,036: ============================================================
2022-03-27 06:56:49,936: time cost, forward:0.01623442696924939, backward:0.03900154731703712, data cost:0.5566011343743964 
2022-03-27 06:56:49,939: ============================================================
2022-03-27 06:56:49,941: Epoch 21/38 Batch 3100/7662 eta: 23:11:00.874206	Training Loss 1.8603 (1.8835)	Training Prec@1 100.000 (99.909)	Training Prec@5 100.000 (99.975)	
2022-03-27 06:56:49,942: ============================================================
2022-03-27 06:57:50,010: time cost, forward:0.01622939497353547, backward:0.03907902436764697, data cost:0.5561552985305523 
2022-03-27 06:57:50,010: ============================================================
2022-03-27 06:57:50,011: Epoch 21/38 Batch 3200/7662 eta: 22:28:43.970240	Training Loss 1.7642 (1.8842)	Training Prec@1 100.000 (99.908)	Training Prec@5 100.000 (99.975)	
2022-03-27 06:57:50,011: ============================================================
2022-03-27 06:58:49,879: time cost, forward:0.016209249606310292, backward:0.03916533486920438, data cost:0.5555249701560935 
2022-03-27 06:58:49,880: ============================================================
2022-03-27 06:58:49,880: Epoch 21/38 Batch 3300/7662 eta: 22:23:14.683260	Training Loss 1.9197 (1.8851)	Training Prec@1 99.805 (99.907)	Training Prec@5 99.805 (99.975)	
2022-03-27 06:58:49,881: ============================================================
2022-03-27 06:59:52,506: time cost, forward:0.016217038504479035, backward:0.039236204594014217, data cost:0.5558950141374768 
2022-03-27 06:59:52,506: ============================================================
2022-03-27 06:59:52,506: Epoch 21/38 Batch 3400/7662 eta: 23:24:02.587458	Training Loss 1.8866 (1.8853)	Training Prec@1 100.000 (99.908)	Training Prec@5 100.000 (99.975)	
2022-03-27 06:59:52,507: ============================================================
2022-03-27 07:00:53,952: time cost, forward:0.01619931778658387, backward:0.03925510643890634, data cost:0.5560563873924437 
2022-03-27 07:00:53,952: ============================================================
2022-03-27 07:00:53,952: Epoch 21/38 Batch 3500/7662 eta: 22:56:33.734392	Training Loss 1.8529 (1.8857)	Training Prec@1 100.000 (99.908)	Training Prec@5 100.000 (99.975)	
2022-03-27 07:00:53,952: ============================================================
2022-03-27 07:01:54,237: time cost, forward:0.016249529816568412, backward:0.039358328368538587, data cost:0.5556228243002928 
2022-03-27 07:01:54,237: ============================================================
2022-03-27 07:01:54,237: Epoch 21/38 Batch 3600/7662 eta: 22:29:33.249187	Training Loss 1.8795 (1.8861)	Training Prec@1 100.000 (99.908)	Training Prec@5 100.000 (99.975)	
2022-03-27 07:01:54,238: ============================================================
2022-03-27 07:02:55,994: time cost, forward:0.01625192890492089, backward:0.03939209328564027, data cost:0.5557162746219063 
2022-03-27 07:02:55,997: ============================================================
2022-03-27 07:02:55,998: Epoch 21/38 Batch 3700/7662 eta: 23:01:32.458227	Training Loss 1.8280 (1.8865)	Training Prec@1 100.000 (99.908)	Training Prec@5 100.000 (99.975)	
2022-03-27 07:02:55,999: ============================================================
2022-03-27 07:03:57,503: time cost, forward:0.016262794990670088, backward:0.039431753708331574, data cost:0.5557333189865639 
2022-03-27 07:03:57,504: ============================================================
2022-03-27 07:03:57,504: Epoch 21/38 Batch 3800/7662 eta: 22:54:50.749035	Training Loss 1.9109 (1.8869)	Training Prec@1 100.000 (99.908)	Training Prec@5 100.000 (99.974)	
2022-03-27 07:03:57,504: ============================================================
2022-03-27 07:05:00,785: time cost, forward:0.016307718725074832, backward:0.039459903229808586, data cost:0.5561249210272547 
2022-03-27 07:05:00,786: ============================================================
2022-03-27 07:05:00,786: Epoch 21/38 Batch 3900/7662 eta: 23:33:28.424906	Training Loss 2.0641 (1.8876)	Training Prec@1 99.609 (99.908)	Training Prec@5 99.805 (99.974)	
2022-03-27 07:05:00,786: ============================================================
2022-03-27 07:05:59,828: time cost, forward:0.016307034710700226, backward:0.03945053729691426, data cost:0.5555305501823874 
2022-03-27 07:05:59,829: ============================================================
2022-03-27 07:05:59,829: Epoch 21/38 Batch 4000/7662 eta: 21:57:49.241678	Training Loss 1.7613 (1.8887)	Training Prec@1 99.805 (99.908)	Training Prec@5 100.000 (99.974)	
2022-03-27 07:05:59,830: ============================================================
2022-03-27 07:07:01,007: time cost, forward:0.01629896488501462, backward:0.039395926027188624, data cost:0.5556428733759609 
2022-03-27 07:07:01,007: ============================================================
2022-03-27 07:07:01,008: Epoch 21/38 Batch 4100/7662 eta: 22:44:26.747994	Training Loss 1.8713 (1.8892)	Training Prec@1 100.000 (99.908)	Training Prec@5 100.000 (99.974)	
2022-03-27 07:07:01,008: ============================================================
2022-03-27 07:08:05,728: time cost, forward:0.016332211452428715, backward:0.03944701216112406, data cost:0.5562865143589929 
2022-03-27 07:08:05,730: ============================================================
2022-03-27 07:08:05,730: Epoch 21/38 Batch 4200/7662 eta: 1 day, 0:02:24.847716	Training Loss 1.9848 (1.8895)	Training Prec@1 100.000 (99.908)	Training Prec@5 100.000 (99.974)	
2022-03-27 07:08:05,730: ============================================================
2022-03-27 07:09:04,829: time cost, forward:0.016323124816124315, backward:0.03942064707654663, data cost:0.5558913832183326 
2022-03-27 07:09:04,830: ============================================================
2022-03-27 07:09:04,830: Epoch 21/38 Batch 4300/7662 eta: 21:56:07.787998	Training Loss 1.8834 (1.8897)	Training Prec@1 100.000 (99.907)	Training Prec@5 100.000 (99.974)	
2022-03-27 07:09:04,831: ============================================================
2022-03-27 07:10:07,461: time cost, forward:0.016353030994985016, backward:0.0394263946622522, data cost:0.5561521044642471 
2022-03-27 07:10:07,461: ============================================================
2022-03-27 07:10:07,461: Epoch 21/38 Batch 4400/7662 eta: 23:13:43.432466	Training Loss 1.9180 (1.8901)	Training Prec@1 99.609 (99.907)	Training Prec@5 100.000 (99.974)	
2022-03-27 07:10:07,462: ============================================================
2022-03-27 07:11:11,113: time cost, forward:0.01644644877146975, backward:0.03948330603644275, data cost:0.556533052646258 
2022-03-27 07:11:11,114: ============================================================
2022-03-27 07:11:11,114: Epoch 21/38 Batch 4500/7662 eta: 23:35:23.081179	Training Loss 1.7639 (1.8906)	Training Prec@1 99.805 (99.907)	Training Prec@5 100.000 (99.974)	
2022-03-27 07:11:11,114: ============================================================
2022-03-27 07:12:09,615: time cost, forward:0.016420556193047126, backward:0.039479429344945326, data cost:0.5559382451101603 
2022-03-27 07:12:09,619: ============================================================
2022-03-27 07:12:09,620: Epoch 21/38 Batch 4600/7662 eta: 21:39:58.036907	Training Loss 1.9749 (1.8909)	Training Prec@1 100.000 (99.907)	Training Prec@5 100.000 (99.974)	
2022-03-27 07:12:09,621: ============================================================
2022-03-27 07:13:11,347: time cost, forward:0.01648108866347179, backward:0.03949588373585644, data cost:0.5559384096275114 
2022-03-27 07:13:11,347: ============================================================
2022-03-27 07:13:11,348: Epoch 21/38 Batch 4700/7662 eta: 22:50:32.770259	Training Loss 1.8511 (1.8918)	Training Prec@1 99.805 (99.907)	Training Prec@5 100.000 (99.974)	
2022-03-27 07:13:11,348: ============================================================
2022-03-27 07:14:09,024: time cost, forward:0.016478880715136677, backward:0.039439946369569386, data cost:0.5552328315519447 
2022-03-27 07:14:09,025: ============================================================
2022-03-27 07:14:09,025: Epoch 21/38 Batch 4800/7662 eta: 21:19:38.373610	Training Loss 1.9309 (1.8923)	Training Prec@1 99.805 (99.907)	Training Prec@5 100.000 (99.974)	
2022-03-27 07:14:09,025: ============================================================
2022-03-27 07:15:07,174: time cost, forward:0.016458482639135987, backward:0.039409180810729395, data cost:0.554641111355992 
2022-03-27 07:15:07,174: ============================================================
2022-03-27 07:15:07,174: Epoch 21/38 Batch 4900/7662 eta: 21:29:08.272158	Training Loss 1.9223 (1.8926)	Training Prec@1 99.805 (99.907)	Training Prec@5 99.805 (99.975)	
2022-03-27 07:15:07,175: ============================================================
2022-03-27 07:16:05,304: time cost, forward:0.01640159159952413, backward:0.039284438031939276, data cost:0.5542338362310524 
2022-03-27 07:16:05,305: ============================================================
2022-03-27 07:16:05,305: Epoch 21/38 Batch 5000/7662 eta: 21:27:45.520555	Training Loss 1.7443 (1.8932)	Training Prec@1 100.000 (99.907)	Training Prec@5 100.000 (99.974)	
2022-03-27 07:16:05,305: ============================================================
2022-03-27 07:17:04,950: time cost, forward:0.016407905267392636, backward:0.039330578617171506, data cost:0.5538658376159937 
2022-03-27 07:17:04,951: ============================================================
2022-03-27 07:17:04,951: Epoch 21/38 Batch 5100/7662 eta: 22:00:20.196795	Training Loss 1.9666 (1.8937)	Training Prec@1 100.000 (99.907)	Training Prec@5 100.000 (99.974)	
2022-03-27 07:17:04,951: ============================================================
2022-03-27 07:18:08,305: time cost, forward:0.016397582129529634, backward:0.03931874572187462, data cost:0.5543322108713199 
2022-03-27 07:18:08,306: ============================================================
2022-03-27 07:18:08,306: Epoch 21/38 Batch 5200/7662 eta: 23:21:22.622489	Training Loss 1.8734 (1.8941)	Training Prec@1 99.805 (99.906)	Training Prec@5 100.000 (99.974)	
2022-03-27 07:18:08,307: ============================================================
2022-03-27 07:19:10,507: time cost, forward:0.016450001352529386, backward:0.03938053454694084, data cost:0.5544253063327885 
2022-03-27 07:19:10,508: ============================================================
2022-03-27 07:19:10,508: Epoch 21/38 Batch 5300/7662 eta: 22:54:50.344003	Training Loss 1.7630 (1.8945)	Training Prec@1 100.000 (99.907)	Training Prec@5 100.000 (99.974)	
2022-03-27 07:19:10,508: ============================================================
2022-03-27 07:20:09,162: time cost, forward:0.01642711437682484, backward:0.03936189531198054, data cost:0.5539993138020955 
2022-03-27 07:20:09,163: ============================================================
2022-03-27 07:20:09,163: Epoch 21/38 Batch 5400/7662 eta: 21:35:27.943307	Training Loss 1.8435 (1.8949)	Training Prec@1 99.609 (99.907)	Training Prec@5 100.000 (99.974)	
2022-03-27 07:20:09,163: ============================================================
2022-03-27 07:21:12,853: time cost, forward:0.01640935836434039, backward:0.03936388276234218, data cost:0.5543247795382463 
2022-03-27 07:21:12,853: ============================================================
2022-03-27 07:21:12,854: Epoch 21/38 Batch 5500/7662 eta: 23:25:37.525499	Training Loss 1.8520 (1.8951)	Training Prec@1 100.000 (99.906)	Training Prec@5 100.000 (99.974)	
2022-03-27 07:21:12,855: ============================================================
2022-03-27 07:22:11,846: time cost, forward:0.01639799825590324, backward:0.03931629485286843, data cost:0.5541514683928015 
2022-03-27 07:22:11,847: ============================================================
2022-03-27 07:22:11,847: Epoch 21/38 Batch 5600/7662 eta: 21:40:57.633776	Training Loss 1.9543 (1.8958)	Training Prec@1 100.000 (99.906)	Training Prec@5 100.000 (99.974)	
2022-03-27 07:22:11,847: ============================================================
2022-03-27 07:23:14,899: time cost, forward:0.016376406126931, backward:0.03932493744157536, data cost:0.5544094949840432 
2022-03-27 07:23:14,902: ============================================================
2022-03-27 07:23:14,902: Epoch 21/38 Batch 5700/7662 eta: 23:09:29.432906	Training Loss 2.1365 (1.8964)	Training Prec@1 100.000 (99.906)	Training Prec@5 100.000 (99.974)	
2022-03-27 07:23:14,904: ============================================================
2022-03-27 07:24:16,500: time cost, forward:0.016401058806491568, backward:0.03930761119706361, data cost:0.5545927151911709 
2022-03-27 07:24:16,501: ============================================================
2022-03-27 07:24:16,501: Epoch 21/38 Batch 5800/7662 eta: 22:36:23.039332	Training Loss 2.0422 (1.8967)	Training Prec@1 99.609 (99.906)	Training Prec@5 99.805 (99.974)	
2022-03-27 07:24:16,501: ============================================================
2022-03-27 07:25:18,813: time cost, forward:0.016391812633469786, backward:0.039297166729927224, data cost:0.5547567800174913 
2022-03-27 07:25:18,815: ============================================================
2022-03-27 07:25:18,816: Epoch 21/38 Batch 5900/7662 eta: 22:51:05.658048	Training Loss 1.8290 (1.8970)	Training Prec@1 100.000 (99.906)	Training Prec@5 100.000 (99.974)	
2022-03-27 07:25:18,816: ============================================================
2022-03-27 07:26:20,071: time cost, forward:0.016402603288673722, backward:0.039304627877788795, data cost:0.5546748038430396 
2022-03-27 07:26:20,096: ============================================================
2022-03-27 07:26:20,097: Epoch 21/38 Batch 6000/7662 eta: 22:27:19.783323	Training Loss 1.9468 (1.8973)	Training Prec@1 100.000 (99.906)	Training Prec@5 100.000 (99.974)	
2022-03-27 07:26:20,098: ============================================================
2022-03-27 07:27:22,464: time cost, forward:0.016413717665502644, backward:0.03933467460784937, data cost:0.5549231911315392 
2022-03-27 07:27:22,464: ============================================================
2022-03-27 07:27:22,465: Epoch 21/38 Batch 6100/7662 eta: 22:50:12.011274	Training Loss 1.9122 (1.8975)	Training Prec@1 99.805 (99.906)	Training Prec@5 100.000 (99.974)	
2022-03-27 07:27:22,465: ============================================================
2022-03-27 07:28:19,956: time cost, forward:0.016404613407797766, backward:0.039302985655490306, data cost:0.5543987271016135 
2022-03-27 07:28:19,956: ============================================================
2022-03-27 07:28:19,957: Epoch 21/38 Batch 6200/7662 eta: 21:02:06.674654	Training Loss 1.8343 (1.8979)	Training Prec@1 99.805 (99.905)	Training Prec@5 100.000 (99.974)	
2022-03-27 07:28:19,957: ============================================================
2022-03-27 07:29:21,366: time cost, forward:0.016400146605495727, backward:0.03931759826568104, data cost:0.5544277233705764 
2022-03-27 07:29:21,367: ============================================================
2022-03-27 07:29:21,367: Epoch 21/38 Batch 6300/7662 eta: 22:27:06.011737	Training Loss 1.9296 (1.8983)	Training Prec@1 100.000 (99.905)	Training Prec@5 100.000 (99.974)	
2022-03-27 07:29:21,367: ============================================================
2022-03-27 07:30:22,920: time cost, forward:0.016365480974402758, backward:0.039297245055143676, data cost:0.554494333818641 
2022-03-27 07:30:22,921: ============================================================
2022-03-27 07:30:22,921: Epoch 21/38 Batch 6400/7662 eta: 22:29:14.450035	Training Loss 2.0540 (1.8986)	Training Prec@1 100.000 (99.905)	Training Prec@5 100.000 (99.974)	
2022-03-27 07:30:22,921: ============================================================
2022-03-27 07:31:25,487: time cost, forward:0.016357428771859958, backward:0.039325913863468946, data cost:0.55468556744848 
2022-03-27 07:31:25,489: ============================================================
2022-03-27 07:31:25,491: Epoch 21/38 Batch 6500/7662 eta: 22:50:26.320910	Training Loss 1.9631 (1.8991)	Training Prec@1 99.805 (99.905)	Training Prec@5 99.805 (99.974)	
2022-03-27 07:31:25,491: ============================================================
2022-03-27 07:32:25,313: time cost, forward:0.016356452231444017, backward:0.039349637658040726, data cost:0.5545119033616354 
2022-03-27 07:32:25,313: ============================================================
2022-03-27 07:32:25,313: Epoch 21/38 Batch 6600/7662 eta: 21:49:17.979869	Training Loss 1.9513 (1.8995)	Training Prec@1 100.000 (99.904)	Training Prec@5 100.000 (99.974)	
2022-03-27 07:32:25,314: ============================================================
2022-03-27 07:33:26,910: time cost, forward:0.016363301870092953, backward:0.039370259556739715, data cost:0.5544367312744387 
2022-03-27 07:33:26,912: ============================================================
2022-03-27 07:33:26,912: Epoch 21/38 Batch 6700/7662 eta: 22:27:07.687807	Training Loss 1.8471 (1.8999)	Training Prec@1 99.805 (99.904)	Training Prec@5 100.000 (99.974)	
2022-03-27 07:33:26,913: ============================================================
2022-03-27 07:34:29,111: time cost, forward:0.016339943853962646, backward:0.03934947997967204, data cost:0.5547591263554625 
2022-03-27 07:34:29,111: ============================================================
2022-03-27 07:34:29,111: Epoch 21/38 Batch 6800/7662 eta: 22:39:14.009425	Training Loss 1.7619 (1.9002)	Training Prec@1 100.000 (99.904)	Training Prec@5 100.000 (99.974)	
2022-03-27 07:34:29,112: ============================================================
2022-03-27 07:35:29,991: time cost, forward:0.01632165656536969, backward:0.039406177876289035, data cost:0.5546623984183552 
2022-03-27 07:35:30,018: ============================================================
2022-03-27 07:35:30,021: Epoch 21/38 Batch 6900/7662 eta: 22:10:00.170147	Training Loss 1.7889 (1.9006)	Training Prec@1 100.000 (99.903)	Training Prec@5 100.000 (99.974)	
2022-03-27 07:35:30,021: ============================================================
2022-03-27 07:36:32,366: time cost, forward:0.01632671002609966, backward:0.03941995148182528, data cost:0.5548277050448343 
2022-03-27 07:36:32,367: ============================================================
2022-03-27 07:36:32,367: Epoch 21/38 Batch 7000/7662 eta: 22:40:23.047196	Training Loss 1.9088 (1.9010)	Training Prec@1 100.000 (99.903)	Training Prec@5 100.000 (99.974)	
2022-03-27 07:36:32,367: ============================================================
2022-03-27 07:37:31,347: time cost, forward:0.016306641236512254, backward:0.039381480717393676, data cost:0.5545783864392212 
2022-03-27 07:37:31,348: ============================================================
2022-03-27 07:37:31,348: Epoch 21/38 Batch 7100/7662 eta: 21:25:57.199028	Training Loss 1.9266 (1.9014)	Training Prec@1 100.000 (99.903)	Training Prec@5 100.000 (99.973)	
2022-03-27 07:37:31,348: ============================================================
2022-03-27 07:38:35,730: time cost, forward:0.01629168080826537, backward:0.03939552286595566, data cost:0.554959256279086 
2022-03-27 07:38:35,730: ============================================================
2022-03-27 07:38:35,731: Epoch 21/38 Batch 7200/7662 eta: 23:22:39.180040	Training Loss 2.0275 (1.9019)	Training Prec@1 100.000 (99.903)	Training Prec@5 100.000 (99.973)	
2022-03-27 07:38:35,731: ============================================================
2022-03-27 07:39:34,781: time cost, forward:0.01629340454297027, backward:0.03937689365303864, data cost:0.5547465934445065 
2022-03-27 07:39:34,782: ============================================================
2022-03-27 07:39:34,782: Epoch 21/38 Batch 7300/7662 eta: 21:25:30.846622	Training Loss 1.7229 (1.9024)	Training Prec@1 100.000 (99.902)	Training Prec@5 100.000 (99.973)	
2022-03-27 07:39:34,782: ============================================================
2022-03-27 07:40:38,659: time cost, forward:0.016286094247658426, backward:0.03942884524330317, data cost:0.5550768038343298 
2022-03-27 07:40:38,680: ============================================================
2022-03-27 07:40:38,680: Epoch 21/38 Batch 7400/7662 eta: 23:09:57.720300	Training Loss 1.8316 (1.9027)	Training Prec@1 100.000 (99.903)	Training Prec@5 100.000 (99.973)	
2022-03-27 07:40:38,680: ============================================================
2022-03-27 07:41:41,326: time cost, forward:0.016307780195481143, backward:0.0394999933554373, data cost:0.5551516118248648 
2022-03-27 07:41:41,327: ============================================================
2022-03-27 07:41:41,327: Epoch 21/38 Batch 7500/7662 eta: 22:41:42.388148	Training Loss 1.8177 (1.9029)	Training Prec@1 100.000 (99.903)	Training Prec@5 100.000 (99.973)	
2022-03-27 07:41:41,327: ============================================================
2022-03-27 07:42:44,145: time cost, forward:0.01631854179423488, backward:0.03953847142799479, data cost:0.5552149842108279 
2022-03-27 07:42:44,148: ============================================================
2022-03-27 07:42:44,148: Epoch 21/38 Batch 7600/7662 eta: 22:44:26.868980	Training Loss 2.1844 (1.9031)	Training Prec@1 99.609 (99.903)	Training Prec@5 100.000 (99.973)	
2022-03-27 07:42:44,150: ============================================================
2022-03-27 07:43:25,028: Epoch: 21/38 eta: 22:43:47.291543	Training Loss 1.9593 (1.9033)	Training Prec@1 99.805 (99.903)	Training Prec@5 100.000 (99.973)
2022-03-27 07:43:25,028: ============================================================
2022-03-27 07:44:28,994: time cost, forward:0.017989459663930566, backward:0.0389306087686558, data cost:0.5832805657627607 
2022-03-27 07:44:28,994: ============================================================
2022-03-27 07:44:28,995: Epoch 22/38 Batch 100/7662 eta: 23:07:28.529807	Training Loss 1.6255 (1.7526)	Training Prec@1 100.000 (99.933)	Training Prec@5 100.000 (99.982)	
2022-03-27 07:44:28,995: ============================================================
2022-03-27 07:45:34,043: time cost, forward:0.01796266421600802, backward:0.04063185255731171, data cost:0.5860231473817298 
2022-03-27 07:45:34,044: ============================================================
2022-03-27 07:45:34,044: Epoch 22/38 Batch 200/7662 eta: 23:29:59.932173	Training Loss 1.7368 (1.7601)	Training Prec@1 100.000 (99.927)	Training Prec@5 100.000 (99.982)	
2022-03-27 07:45:34,044: ============================================================
2022-03-27 07:46:37,075: time cost, forward:0.017064044308104244, backward:0.04050582069218358, data cost:0.5795904051101327 
2022-03-27 07:46:37,075: ============================================================
2022-03-27 07:46:37,075: Epoch 22/38 Batch 300/7662 eta: 22:45:12.453036	Training Loss 1.6673 (1.7596)	Training Prec@1 100.000 (99.929)	Training Prec@5 100.000 (99.980)	
2022-03-27 07:46:37,075: ============================================================
2022-03-27 07:47:41,060: time cost, forward:0.017018838036329226, backward:0.04220646007317947, data cost:0.5802875586918422 
2022-03-27 07:47:41,060: ============================================================
2022-03-27 07:47:41,060: Epoch 22/38 Batch 400/7662 eta: 23:04:47.825639	Training Loss 1.7559 (1.7634)	Training Prec@1 100.000 (99.934)	Training Prec@5 100.000 (99.981)	
2022-03-27 07:47:41,061: ============================================================
2022-03-27 07:48:38,920: time cost, forward:0.016414174097095557, backward:0.040262975291403116, data cost:0.57039205344741 
2022-03-27 07:48:38,920: ============================================================
2022-03-27 07:48:38,920: Epoch 22/38 Batch 500/7662 eta: 20:51:16.113242	Training Loss 1.7691 (1.7677)	Training Prec@1 100.000 (99.936)	Training Prec@5 100.000 (99.980)	
2022-03-27 07:48:38,920: ============================================================
2022-03-27 07:49:43,375: time cost, forward:0.016744078300234073, backward:0.041065879576592294, data cost:0.5718356428639917 
2022-03-27 07:49:43,394: ============================================================
2022-03-27 07:49:43,395: Epoch 22/38 Batch 600/7662 eta: 23:13:14.159419	Training Loss 1.7817 (1.7691)	Training Prec@1 100.000 (99.936)	Training Prec@5 100.000 (99.981)	
2022-03-27 07:49:43,395: ============================================================
2022-03-27 07:50:46,276: time cost, forward:0.01694537266470673, backward:0.04118641933828635, data cost:0.5711923627894324 
2022-03-27 07:50:46,276: ============================================================
2022-03-27 07:50:46,276: Epoch 22/38 Batch 700/7662 eta: 22:37:46.470811	Training Loss 1.6499 (1.7697)	Training Prec@1 100.000 (99.937)	Training Prec@5 100.000 (99.982)	
2022-03-27 07:50:46,276: ============================================================
2022-03-27 07:51:48,750: time cost, forward:0.016974658930256906, backward:0.040728074886622806, data cost:0.5708965097410658 
2022-03-27 07:51:48,751: ============================================================
2022-03-27 07:51:48,751: Epoch 22/38 Batch 800/7662 eta: 22:27:56.265749	Training Loss 1.8088 (1.7724)	Training Prec@1 100.000 (99.937)	Training Prec@5 100.000 (99.982)	
2022-03-27 07:51:48,751: ============================================================
2022-03-27 07:52:49,113: time cost, forward:0.01672667656114555, backward:0.040568989031306894, data cost:0.5683335167945294 
2022-03-27 07:52:49,113: ============================================================
2022-03-27 07:52:49,113: Epoch 22/38 Batch 900/7662 eta: 21:41:21.891150	Training Loss 1.6331 (1.7726)	Training Prec@1 100.000 (99.939)	Training Prec@5 100.000 (99.982)	
2022-03-27 07:52:49,113: ============================================================
2022-03-27 07:53:53,696: time cost, forward:0.016788433025310467, backward:0.040678808042356324, data cost:0.5693938207101297 
2022-03-27 07:53:53,698: ============================================================
2022-03-27 07:53:53,699: Epoch 22/38 Batch 1000/7662 eta: 23:11:19.544574	Training Loss 1.7354 (1.7732)	Training Prec@1 100.000 (99.940)	Training Prec@5 100.000 (99.983)	
2022-03-27 07:53:53,700: ============================================================
2022-03-27 07:54:56,049: time cost, forward:0.016866595664818358, backward:0.041038286913732056, data cost:0.5688888404020078 
2022-03-27 07:54:56,049: ============================================================
2022-03-27 07:54:56,049: Epoch 22/38 Batch 1100/7662 eta: 22:22:09.404580	Training Loss 1.8977 (1.7747)	Training Prec@1 99.805 (99.937)	Training Prec@5 99.805 (99.982)	
2022-03-27 07:54:56,050: ============================================================
2022-03-27 07:55:59,424: time cost, forward:0.016887784899026776, backward:0.04120162330735615, data cost:0.5692093935084402 
2022-03-27 07:55:59,425: ============================================================
2022-03-27 07:55:59,425: Epoch 22/38 Batch 1200/7662 eta: 22:43:09.237940	Training Loss 2.0455 (1.7756)	Training Prec@1 99.805 (99.936)	Training Prec@5 100.000 (99.982)	
2022-03-27 07:55:59,425: ============================================================
2022-03-27 07:57:00,593: time cost, forward:0.016892152166623535, backward:0.041331590552620014, data cost:0.5679359937099606 
2022-03-27 07:57:00,593: ============================================================
2022-03-27 07:57:00,594: Epoch 22/38 Batch 1300/7662 eta: 21:54:40.364235	Training Loss 1.8814 (1.7778)	Training Prec@1 100.000 (99.937)	Training Prec@5 100.000 (99.982)	
2022-03-27 07:57:00,594: ============================================================
2022-03-27 07:58:05,431: time cost, forward:0.01685634010429464, backward:0.04137794642554086, data cost:0.5688438025263909 
2022-03-27 07:58:05,432: ============================================================
2022-03-27 07:58:05,433: Epoch 22/38 Batch 1400/7662 eta: 23:12:27.679619	Training Loss 1.6853 (1.7791)	Training Prec@1 100.000 (99.937)	Training Prec@5 100.000 (99.983)	
2022-03-27 07:58:05,433: ============================================================
2022-03-27 07:59:08,655: time cost, forward:0.016997294874490303, backward:0.0411939999514854, data cost:0.5697210243815498 
2022-03-27 07:59:08,656: ============================================================
2022-03-27 07:59:08,656: Epoch 22/38 Batch 1500/7662 eta: 22:36:43.277154	Training Loss 1.8191 (1.7806)	Training Prec@1 99.805 (99.935)	Training Prec@5 100.000 (99.982)	
2022-03-27 07:59:08,656: ============================================================
2022-03-27 08:00:10,249: time cost, forward:0.01690920029974789, backward:0.041245184666369394, data cost:0.5689231126736372 
2022-03-27 08:00:10,250: ============================================================
2022-03-27 08:00:10,250: Epoch 22/38 Batch 1600/7662 eta: 22:00:43.947326	Training Loss 1.6885 (1.7805)	Training Prec@1 99.805 (99.936)	Training Prec@5 100.000 (99.982)	
2022-03-27 08:00:10,250: ============================================================
2022-03-27 08:01:10,368: time cost, forward:0.016904323503787268, backward:0.0411768108343222, data cost:0.5673753273634436 
2022-03-27 08:01:10,368: ============================================================
2022-03-27 08:01:10,369: Epoch 22/38 Batch 1700/7662 eta: 21:28:05.532908	Training Loss 1.7788 (1.7818)	Training Prec@1 100.000 (99.936)	Training Prec@5 100.000 (99.982)	
2022-03-27 08:01:10,369: ============================================================
2022-03-27 08:02:14,390: time cost, forward:0.01687341030602193, backward:0.041298171558136275, data cost:0.5679386007977963 
2022-03-27 08:02:14,451: ============================================================
2022-03-27 08:02:14,454: Epoch 22/38 Batch 1800/7662 eta: 22:51:59.306312	Training Loss 1.9824 (1.7836)	Training Prec@1 100.000 (99.936)	Training Prec@5 100.000 (99.982)	
2022-03-27 08:02:14,454: ============================================================
2022-03-27 08:03:16,585: time cost, forward:0.016916272764522317, backward:0.04138610248756509, data cost:0.5676284692612619 
2022-03-27 08:03:16,585: ============================================================
2022-03-27 08:03:16,586: Epoch 22/38 Batch 1900/7662 eta: 22:09:10.308917	Training Loss 1.9718 (1.7845)	Training Prec@1 100.000 (99.936)	Training Prec@5 100.000 (99.983)	
2022-03-27 08:03:16,586: ============================================================
2022-03-27 08:04:20,624: time cost, forward:0.016935271224479426, backward:0.041350737161908284, data cost:0.5683426718642677 
2022-03-27 08:04:20,624: ============================================================
2022-03-27 08:04:20,625: Epoch 22/38 Batch 2000/7662 eta: 22:48:53.197478	Training Loss 1.7990 (1.7858)	Training Prec@1 100.000 (99.935)	Training Prec@5 100.000 (99.982)	
2022-03-27 08:04:20,625: ============================================================
2022-03-27 08:05:26,794: time cost, forward:0.01701031224167648, backward:0.0414375650025141, data cost:0.5695303431461401 
2022-03-27 08:05:26,794: ============================================================
2022-03-27 08:05:26,795: Epoch 22/38 Batch 2100/7662 eta: 23:33:20.542168	Training Loss 1.6879 (1.7867)	Training Prec@1 99.805 (99.935)	Training Prec@5 99.805 (99.982)	
2022-03-27 08:05:26,795: ============================================================
2022-03-27 08:06:26,934: time cost, forward:0.01704338866507481, backward:0.0414456611007059, data cost:0.5682394992443256 
2022-03-27 08:06:26,935: ============================================================
2022-03-27 08:06:26,935: Epoch 22/38 Batch 2200/7662 eta: 21:23:32.756161	Training Loss 1.9499 (1.7885)	Training Prec@1 100.000 (99.935)	Training Prec@5 100.000 (99.982)	
2022-03-27 08:06:26,936: ============================================================
2022-03-27 08:07:26,733: time cost, forward:0.017037785328072326, backward:0.04144259285231993, data cost:0.5671522702378468 
2022-03-27 08:07:26,734: ============================================================
2022-03-27 08:07:26,734: Epoch 22/38 Batch 2300/7662 eta: 21:15:15.778755	Training Loss 2.0151 (1.7901)	Training Prec@1 100.000 (99.936)	Training Prec@5 100.000 (99.983)	
2022-03-27 08:07:26,734: ============================================================
2022-03-27 08:08:32,130: time cost, forward:0.01706681772290095, backward:0.041546091033598444, data cost:0.5681485167738297 
2022-03-27 08:08:32,130: ============================================================
2022-03-27 08:08:32,130: Epoch 22/38 Batch 2400/7662 eta: 23:13:32.435196	Training Loss 1.9111 (1.7910)	Training Prec@1 100.000 (99.936)	Training Prec@5 100.000 (99.982)	
2022-03-27 08:08:32,131: ============================================================
2022-03-27 08:09:34,596: time cost, forward:0.017060980981900817, backward:0.041645966133340546, data cost:0.5678671285981128 
2022-03-27 08:09:34,596: ============================================================
2022-03-27 08:09:34,596: Epoch 22/38 Batch 2500/7662 eta: 22:10:03.039996	Training Loss 1.6791 (1.7922)	Training Prec@1 100.000 (99.936)	Training Prec@5 100.000 (99.982)	
2022-03-27 08:09:34,596: ============================================================
2022-03-27 08:10:37,164: time cost, forward:0.017156330701615912, backward:0.04171290357280759, data cost:0.5673125875413578 
2022-03-27 08:10:37,166: ============================================================
2022-03-27 08:10:37,167: Epoch 22/38 Batch 2600/7662 eta: 22:11:14.362209	Training Loss 1.7915 (1.7933)	Training Prec@1 100.000 (99.936)	Training Prec@5 100.000 (99.982)	
2022-03-27 08:10:37,168: ============================================================
2022-03-27 08:11:38,520: time cost, forward:0.017111977103375735, backward:0.041684120131581306, data cost:0.5671187148530556 
2022-03-27 08:11:38,540: ============================================================
2022-03-27 08:11:38,541: Epoch 22/38 Batch 2700/7662 eta: 21:44:45.490533	Training Loss 1.8995 (1.7943)	Training Prec@1 99.805 (99.936)	Training Prec@5 99.805 (99.983)	
2022-03-27 08:11:38,542: ============================================================
2022-03-27 08:12:42,208: time cost, forward:0.017118758071784933, backward:0.0416477567257733, data cost:0.5675904727825398 
2022-03-27 08:12:42,209: ============================================================
2022-03-27 08:12:42,209: Epoch 22/38 Batch 2800/7662 eta: 22:32:28.360244	Training Loss 1.7305 (1.7950)	Training Prec@1 100.000 (99.937)	Training Prec@5 100.000 (99.982)	
2022-03-27 08:12:42,209: ============================================================
2022-03-27 08:13:48,871: time cost, forward:0.017189848048804586, backward:0.04180033069596121, data cost:0.5686746850100909 
2022-03-27 08:13:48,872: ============================================================
2022-03-27 08:13:48,872: Epoch 22/38 Batch 2900/7662 eta: 23:34:58.951028	Training Loss 1.9117 (1.7963)	Training Prec@1 100.000 (99.936)	Training Prec@5 100.000 (99.982)	
2022-03-27 08:13:48,873: ============================================================
2022-03-27 08:14:51,853: time cost, forward:0.017248409674460986, backward:0.04181048742092701, data cost:0.5685220219445809 
2022-03-27 08:14:51,855: ============================================================
2022-03-27 08:14:51,855: Epoch 22/38 Batch 3000/7662 eta: 22:15:48.854382	Training Loss 1.9667 (1.7971)	Training Prec@1 100.000 (99.936)	Training Prec@5 100.000 (99.982)	
2022-03-27 08:14:51,856: ============================================================
2022-03-27 08:15:52,652: time cost, forward:0.017244846830832723, backward:0.04172713681935264, data cost:0.5679449590416484 
2022-03-27 08:15:52,654: ============================================================
2022-03-27 08:15:52,655: Epoch 22/38 Batch 3100/7662 eta: 21:28:29.320452	Training Loss 1.8613 (1.7985)	Training Prec@1 99.414 (99.936)	Training Prec@5 100.000 (99.982)	
2022-03-27 08:15:52,655: ============================================================
2022-03-27 08:16:56,701: time cost, forward:0.017283098143911168, backward:0.04178292075333352, data cost:0.568336100457571 
2022-03-27 08:16:56,702: ============================================================
2022-03-27 08:16:56,702: Epoch 22/38 Batch 3200/7662 eta: 22:36:15.413162	Training Loss 1.8208 (1.7995)	Training Prec@1 100.000 (99.936)	Training Prec@5 100.000 (99.982)	
2022-03-27 08:16:56,702: ============================================================
2022-03-27 08:17:58,798: time cost, forward:0.017251801151114906, backward:0.04173582588119484, data cost:0.567996287714463 
2022-03-27 08:17:58,798: ============================================================
2022-03-27 08:17:58,799: Epoch 22/38 Batch 3300/7662 eta: 21:53:54.959863	Training Loss 1.8493 (1.8012)	Training Prec@1 100.000 (99.934)	Training Prec@5 100.000 (99.982)	
2022-03-27 08:17:58,799: ============================================================
2022-03-27 08:18:58,896: time cost, forward:0.01725918449139237, backward:0.04173069422509468, data cost:0.56711323726314 
2022-03-27 08:18:58,901: ============================================================
2022-03-27 08:18:58,903: Epoch 22/38 Batch 3400/7662 eta: 21:10:44.389450	Training Loss 1.8424 (1.8021)	Training Prec@1 100.000 (99.934)	Training Prec@5 100.000 (99.982)	
2022-03-27 08:18:58,903: ============================================================
2022-03-27 08:19:59,486: time cost, forward:0.017256077441803963, backward:0.04170152806458932, data cost:0.5667936329706699 
2022-03-27 08:19:59,487: ============================================================
2022-03-27 08:19:59,487: Epoch 22/38 Batch 3500/7662 eta: 21:19:54.236954	Training Loss 1.9703 (1.8032)	Training Prec@1 100.000 (99.933)	Training Prec@5 100.000 (99.981)	
2022-03-27 08:19:59,487: ============================================================
2022-03-27 08:21:02,766: time cost, forward:0.01732469804090207, backward:0.04180573403553752, data cost:0.5667698684749619 
2022-03-27 08:21:02,766: ============================================================
2022-03-27 08:21:02,766: Epoch 22/38 Batch 3600/7662 eta: 22:15:46.365374	Training Loss 1.9457 (1.8044)	Training Prec@1 100.000 (99.933)	Training Prec@5 100.000 (99.981)	
2022-03-27 08:21:02,766: ============================================================
2022-03-27 08:22:06,250: time cost, forward:0.017310180158736286, backward:0.04185280215904564, data cost:0.5667207124395027 
2022-03-27 08:22:06,255: ============================================================
2022-03-27 08:22:06,258: Epoch 22/38 Batch 3700/7662 eta: 22:19:10.087234	Training Loss 1.8245 (1.8052)	Training Prec@1 100.000 (99.933)	Training Prec@5 100.000 (99.981)	
2022-03-27 08:22:06,258: ============================================================
2022-03-27 08:23:06,372: time cost, forward:0.017305067759747567, backward:0.041874003931232806, data cost:0.5662331233435036 
2022-03-27 08:23:06,373: ============================================================
2022-03-27 08:23:06,373: Epoch 22/38 Batch 3800/7662 eta: 21:07:00.039260	Training Loss 1.7931 (1.8055)	Training Prec@1 99.805 (99.934)	Training Prec@5 100.000 (99.981)	
2022-03-27 08:23:06,373: ============================================================
2022-03-27 08:24:09,335: time cost, forward:0.01733891980468875, backward:0.04193061821030849, data cost:0.5662238133751634 
2022-03-27 08:24:09,336: ============================================================
2022-03-27 08:24:09,336: Epoch 22/38 Batch 3900/7662 eta: 22:05:57.170757	Training Loss 1.8749 (1.8066)	Training Prec@1 99.805 (99.933)	Training Prec@5 99.805 (99.981)	
2022-03-27 08:24:09,336: ============================================================
2022-03-27 08:25:13,393: time cost, forward:0.017304880912973452, backward:0.041895969655102984, data cost:0.5665406248336377 
2022-03-27 08:25:13,394: ============================================================
2022-03-27 08:25:13,394: Epoch 22/38 Batch 4000/7662 eta: 22:27:56.294661	Training Loss 1.8553 (1.8077)	Training Prec@1 100.000 (99.932)	Training Prec@5 100.000 (99.981)	
2022-03-27 08:25:13,394: ============================================================
2022-03-27 08:26:14,471: time cost, forward:0.01731025553180055, backward:0.04186831046442021, data cost:0.5662183124107627 
2022-03-27 08:26:14,471: ============================================================
2022-03-27 08:26:14,471: Epoch 22/38 Batch 4100/7662 eta: 21:24:12.065198	Training Loss 1.8994 (1.8089)	Training Prec@1 99.805 (99.932)	Training Prec@5 100.000 (99.981)	
2022-03-27 08:26:14,471: ============================================================
2022-03-27 08:27:14,044: time cost, forward:0.01730731283661637, backward:0.04182287697906748, data cost:0.5655468844549801 
2022-03-27 08:27:14,045: ============================================================
2022-03-27 08:27:14,045: Epoch 22/38 Batch 4200/7662 eta: 20:51:35.346770	Training Loss 1.9557 (1.8097)	Training Prec@1 99.805 (99.931)	Training Prec@5 100.000 (99.980)	
2022-03-27 08:27:14,045: ============================================================
2022-03-27 08:28:18,091: time cost, forward:0.017315119026594036, backward:0.04183286776457257, data cost:0.5657804074967343 
2022-03-27 08:28:18,092: ============================================================
2022-03-27 08:28:18,092: Epoch 22/38 Batch 4300/7662 eta: 22:24:30.869034	Training Loss 1.8821 (1.8105)	Training Prec@1 100.000 (99.931)	Training Prec@5 100.000 (99.980)	
2022-03-27 08:28:18,093: ============================================================
2022-03-27 08:29:19,865: time cost, forward:0.017296048233958368, backward:0.041786972949059885, data cost:0.5657718324693773 
2022-03-27 08:29:19,866: ============================================================
2022-03-27 08:29:19,866: Epoch 22/38 Batch 4400/7662 eta: 21:35:45.474672	Training Loss 1.8789 (1.8115)	Training Prec@1 100.000 (99.932)	Training Prec@5 100.000 (99.980)	
2022-03-27 08:29:19,866: ============================================================
2022-03-27 08:30:23,367: time cost, forward:0.017286784226535613, backward:0.04178460366621524, data cost:0.5659819194596989 
2022-03-27 08:30:23,368: ============================================================
2022-03-27 08:30:23,368: Epoch 22/38 Batch 4500/7662 eta: 22:10:57.056849	Training Loss 1.8664 (1.8128)	Training Prec@1 100.000 (99.931)	Training Prec@5 100.000 (99.980)	
2022-03-27 08:30:23,368: ============================================================
2022-03-27 08:31:24,847: time cost, forward:0.017293927306116962, backward:0.04179639130940928, data cost:0.5656998337909278 
2022-03-27 08:31:24,848: ============================================================
2022-03-27 08:31:24,848: Epoch 22/38 Batch 4600/7662 eta: 21:27:32.649386	Training Loss 1.9036 (1.8137)	Training Prec@1 100.000 (99.931)	Training Prec@5 100.000 (99.980)	
2022-03-27 08:31:24,848: ============================================================
2022-03-27 08:32:27,337: time cost, forward:0.017293342658118202, backward:0.04180296235044958, data cost:0.5656682838148501 
2022-03-27 08:32:27,337: ============================================================
2022-03-27 08:32:27,338: Epoch 22/38 Batch 4700/7662 eta: 21:47:38.824393	Training Loss 1.9698 (1.8149)	Training Prec@1 100.000 (99.931)	Training Prec@5 100.000 (99.981)	
2022-03-27 08:32:27,338: ============================================================
2022-03-27 08:33:30,957: time cost, forward:0.017328543671967463, backward:0.04189130742740174, data cost:0.5656009549571962 
2022-03-27 08:33:30,959: ============================================================
2022-03-27 08:33:30,960: Epoch 22/38 Batch 4800/7662 eta: 22:10:16.764417	Training Loss 1.8893 (1.8156)	Training Prec@1 100.000 (99.931)	Training Prec@5 100.000 (99.981)	
2022-03-27 08:33:30,960: ============================================================
2022-03-27 08:34:32,845: time cost, forward:0.017305703960308907, backward:0.04182100086753333, data cost:0.5656770279174387 
2022-03-27 08:34:32,845: ============================================================
2022-03-27 08:34:32,845: Epoch 22/38 Batch 4900/7662 eta: 21:32:56.974034	Training Loss 1.8089 (1.8165)	Training Prec@1 99.609 (99.930)	Training Prec@5 99.805 (99.981)	
2022-03-27 08:34:32,846: ============================================================
2022-03-27 08:35:34,577: time cost, forward:0.017276430301700597, backward:0.04176084984300327, data cost:0.5655991006646306 
2022-03-27 08:35:34,578: ============================================================
2022-03-27 08:35:34,579: Epoch 22/38 Batch 5000/7662 eta: 21:28:43.778201	Training Loss 1.9402 (1.8176)	Training Prec@1 100.000 (99.930)	Training Prec@5 100.000 (99.981)	
2022-03-27 08:35:34,579: ============================================================
2022-03-27 08:36:37,463: time cost, forward:0.0173154659518122, backward:0.04176263697920277, data cost:0.565555082533635 
2022-03-27 08:36:37,464: ============================================================
2022-03-27 08:36:37,464: Epoch 22/38 Batch 5100/7662 eta: 21:51:44.797742	Training Loss 1.7420 (1.8185)	Training Prec@1 100.000 (99.930)	Training Prec@5 100.000 (99.981)	
2022-03-27 08:36:37,465: ============================================================
2022-03-27 08:37:39,882: time cost, forward:0.017356205408470885, backward:0.04176757257244729, data cost:0.565456040847024 
2022-03-27 08:37:39,885: ============================================================
2022-03-27 08:37:39,886: Epoch 22/38 Batch 5200/7662 eta: 21:41:01.176075	Training Loss 2.0284 (1.8197)	Training Prec@1 100.000 (99.929)	Training Prec@5 100.000 (99.981)	
2022-03-27 08:37:39,887: ============================================================
2022-03-27 08:38:43,510: time cost, forward:0.017408372276480365, backward:0.041766470750562876, data cost:0.5656225391549194 
2022-03-27 08:38:43,513: ============================================================
2022-03-27 08:38:43,515: Epoch 22/38 Batch 5300/7662 eta: 22:05:06.599205	Training Loss 1.8446 (1.8204)	Training Prec@1 100.000 (99.929)	Training Prec@5 100.000 (99.981)	
2022-03-27 08:38:43,515: ============================================================
2022-03-27 08:39:45,697: time cost, forward:0.017461193427043307, backward:0.04178186566062626, data cost:0.5655463235116398 
2022-03-27 08:39:45,698: ============================================================
2022-03-27 08:39:45,698: Epoch 22/38 Batch 5400/7662 eta: 21:33:59.663245	Training Loss 1.9284 (1.8216)	Training Prec@1 100.000 (99.929)	Training Prec@5 100.000 (99.981)	
2022-03-27 08:39:45,698: ============================================================
2022-03-27 08:40:50,662: time cost, forward:0.017453594757526825, backward:0.04181942195757061, data cost:0.5657993314655981 
2022-03-27 08:40:50,666: ============================================================
2022-03-27 08:40:50,667: Epoch 22/38 Batch 5500/7662 eta: 22:30:51.146579	Training Loss 1.7126 (1.8225)	Training Prec@1 100.000 (99.929)	Training Prec@5 100.000 (99.981)	
2022-03-27 08:40:50,667: ============================================================
2022-03-27 08:41:51,206: time cost, forward:0.01744926288779835, backward:0.04180088982579537, data cost:0.565549117834531 
2022-03-27 08:41:51,207: ============================================================
2022-03-27 08:41:51,207: Epoch 22/38 Batch 5600/7662 eta: 20:57:46.969114	Training Loss 1.8510 (1.8235)	Training Prec@1 100.000 (99.929)	Training Prec@5 100.000 (99.981)	
2022-03-27 08:41:51,208: ============================================================
2022-03-27 08:42:55,981: time cost, forward:0.017472089978974627, backward:0.04183574797166274, data cost:0.5657541703332786 
2022-03-27 08:42:55,983: ============================================================
2022-03-27 08:42:55,984: Epoch 22/38 Batch 5700/7662 eta: 22:24:42.100511	Training Loss 2.0309 (1.8242)	Training Prec@1 100.000 (99.929)	Training Prec@5 100.000 (99.981)	
2022-03-27 08:42:55,985: ============================================================
2022-03-27 08:44:02,202: time cost, forward:0.017488236179802413, backward:0.04188027606377994, data cost:0.566461111640371 
2022-03-27 08:44:02,203: ============================================================
2022-03-27 08:44:02,203: Epoch 22/38 Batch 5800/7662 eta: 22:53:33.334301	Training Loss 1.7968 (1.8252)	Training Prec@1 99.805 (99.929)	Training Prec@5 100.000 (99.981)	
2022-03-27 08:44:02,203: ============================================================
2022-03-27 08:45:00,663: time cost, forward:0.017483239376781392, backward:0.041866806447051264, data cost:0.5657578754635216 
2022-03-27 08:45:00,664: ============================================================
2022-03-27 08:45:00,664: Epoch 22/38 Batch 5900/7662 eta: 20:11:39.171467	Training Loss 1.8505 (1.8260)	Training Prec@1 100.000 (99.929)	Training Prec@5 100.000 (99.981)	
2022-03-27 08:45:00,664: ============================================================
2022-03-27 08:46:03,125: time cost, forward:0.017471296228077197, backward:0.04185050462639159, data cost:0.5657477870864219 
2022-03-27 08:46:03,126: ============================================================
2022-03-27 08:46:03,126: Epoch 22/38 Batch 6000/7662 eta: 21:33:32.546347	Training Loss 2.0416 (1.8269)	Training Prec@1 100.000 (99.929)	Training Prec@5 100.000 (99.981)	
2022-03-27 08:46:03,126: ============================================================
2022-03-27 08:47:03,739: time cost, forward:0.017447345353361232, backward:0.041811751349868684, data cost:0.5654580292496101 
2022-03-27 08:47:03,740: ============================================================
2022-03-27 08:47:03,740: Epoch 22/38 Batch 6100/7662 eta: 20:54:15.378996	Training Loss 1.8604 (1.8276)	Training Prec@1 99.609 (99.928)	Training Prec@5 100.000 (99.981)	
2022-03-27 08:47:03,740: ============================================================
2022-03-27 08:48:09,146: time cost, forward:0.01743446871010906, backward:0.04180164097931947, data cost:0.5659578919583779 
2022-03-27 08:48:09,146: ============================================================
2022-03-27 08:48:09,146: Epoch 22/38 Batch 6200/7662 eta: 22:32:19.644763	Training Loss 2.0475 (1.8287)	Training Prec@1 100.000 (99.928)	Training Prec@5 100.000 (99.981)	
2022-03-27 08:48:09,147: ============================================================
2022-03-27 08:49:11,055: time cost, forward:0.01740742108238597, backward:0.04179807563947674, data cost:0.5657639097724572 
2022-03-27 08:49:11,055: ============================================================
2022-03-27 08:49:11,056: Epoch 22/38 Batch 6300/7662 eta: 21:18:59.744148	Training Loss 1.8827 (1.8295)	Training Prec@1 100.000 (99.927)	Training Prec@5 100.000 (99.980)	
2022-03-27 08:49:11,056: ============================================================
2022-03-27 08:50:14,659: time cost, forward:0.017378887360422736, backward:0.04178284209004453, data cost:0.5660652860586932 
2022-03-27 08:50:14,659: ============================================================
2022-03-27 08:50:14,659: Epoch 22/38 Batch 6400/7662 eta: 21:52:56.154948	Training Loss 1.6428 (1.8303)	Training Prec@1 100.000 (99.927)	Training Prec@5 100.000 (99.981)	
2022-03-27 08:50:14,659: ============================================================
2022-03-27 08:51:14,929: time cost, forward:0.01735938481320453, backward:0.04180552475561379, data cost:0.5656837251190406 
2022-03-27 08:51:14,930: ============================================================
2022-03-27 08:51:14,930: Epoch 22/38 Batch 6500/7662 eta: 20:43:08.046655	Training Loss 2.0203 (1.8309)	Training Prec@1 100.000 (99.927)	Training Prec@5 100.000 (99.980)	
2022-03-27 08:51:14,930: ============================================================
2022-03-27 08:52:16,317: time cost, forward:0.017361010759414045, backward:0.04178925217381209, data cost:0.5654533954981078 
2022-03-27 08:52:16,317: ============================================================
2022-03-27 08:52:16,317: Epoch 22/38 Batch 6600/7662 eta: 21:05:08.539242	Training Loss 1.8704 (1.8318)	Training Prec@1 100.000 (99.926)	Training Prec@5 100.000 (99.980)	
2022-03-27 08:52:16,317: ============================================================
2022-03-27 08:53:20,509: time cost, forward:0.017347277839035398, backward:0.04179220154029538, data cost:0.5657781769863117 
2022-03-27 08:53:20,510: ============================================================
2022-03-27 08:53:20,510: Epoch 22/38 Batch 6700/7662 eta: 22:01:53.299799	Training Loss 1.9047 (1.8326)	Training Prec@1 100.000 (99.926)	Training Prec@5 100.000 (99.980)	
2022-03-27 08:53:20,510: ============================================================
2022-03-27 08:54:21,792: time cost, forward:0.017319789229464682, backward:0.041738045182293314, data cost:0.5655674119436805 
2022-03-27 08:54:21,793: ============================================================
2022-03-27 08:54:21,793: Epoch 22/38 Batch 6800/7662 eta: 21:00:57.198727	Training Loss 1.9107 (1.8336)	Training Prec@1 99.805 (99.926)	Training Prec@5 99.805 (99.980)	
2022-03-27 08:54:21,794: ============================================================
2022-03-27 08:55:26,247: time cost, forward:0.017326441929467883, backward:0.041763007666757446, data cost:0.565877282977156 
2022-03-27 08:55:26,248: ============================================================
2022-03-27 08:55:26,248: Epoch 22/38 Batch 6900/7662 eta: 22:05:08.122234	Training Loss 1.9301 (1.8345)	Training Prec@1 99.805 (99.926)	Training Prec@5 100.000 (99.980)	
2022-03-27 08:55:26,248: ============================================================
2022-03-27 08:56:29,948: time cost, forward:0.017322725969683293, backward:0.04177747216969324, data cost:0.566036669488191 
2022-03-27 08:56:29,948: ============================================================
2022-03-27 08:56:29,949: Epoch 22/38 Batch 7000/7662 eta: 21:48:34.119759	Training Loss 1.8275 (1.8353)	Training Prec@1 100.000 (99.926)	Training Prec@5 100.000 (99.980)	
2022-03-27 08:56:29,949: ============================================================
2022-03-27 08:57:33,332: time cost, forward:0.017321910097794158, backward:0.04174154237015581, data cost:0.5661721633914357 
2022-03-27 08:57:33,333: ============================================================
2022-03-27 08:57:33,333: Epoch 22/38 Batch 7100/7662 eta: 21:41:00.834531	Training Loss 2.0025 (1.8361)	Training Prec@1 99.805 (99.925)	Training Prec@5 100.000 (99.980)	
2022-03-27 08:57:33,333: ============================================================
2022-03-27 08:58:38,069: time cost, forward:0.017320822867970945, backward:0.04173625788931748, data cost:0.5664676068673318 
2022-03-27 08:58:38,069: ============================================================
2022-03-27 08:58:38,070: Epoch 22/38 Batch 7200/7662 eta: 22:07:41.767967	Training Loss 1.9168 (1.8367)	Training Prec@1 100.000 (99.925)	Training Prec@5 100.000 (99.980)	
2022-03-27 08:58:38,070: ============================================================
2022-03-27 08:59:44,971: time cost, forward:0.017340896096616955, backward:0.0417821438676087, data cost:0.5669087880212063 
2022-03-27 08:59:44,972: ============================================================
2022-03-27 08:59:44,972: Epoch 22/38 Batch 7300/7662 eta: 22:50:59.721939	Training Loss 1.9408 (1.8374)	Training Prec@1 100.000 (99.925)	Training Prec@5 100.000 (99.980)	
2022-03-27 08:59:44,972: ============================================================
2022-03-27 09:00:44,972: time cost, forward:0.017342119027447228, backward:0.04179378944017514, data cost:0.5665407402158702 
2022-03-27 09:00:44,973: ============================================================
2022-03-27 09:00:44,973: Epoch 22/38 Batch 7400/7662 eta: 20:28:34.484756	Training Loss 1.7752 (1.8378)	Training Prec@1 100.000 (99.925)	Training Prec@5 100.000 (99.980)	
2022-03-27 09:00:44,974: ============================================================
2022-03-27 09:01:51,167: time cost, forward:0.017348315242386322, backward:0.04184848716345163, data cost:0.5670041661212278 
2022-03-27 09:01:51,167: ============================================================
2022-03-27 09:01:51,168: Epoch 22/38 Batch 7500/7662 eta: 22:34:16.935223	Training Loss 1.9329 (1.8386)	Training Prec@1 100.000 (99.925)	Training Prec@5 100.000 (99.980)	
2022-03-27 09:01:51,168: ============================================================
2022-03-27 09:02:52,585: time cost, forward:0.017323423301033133, backward:0.041840970100486166, data cost:0.566855920429433 
2022-03-27 09:02:52,586: ============================================================
2022-03-27 09:02:52,586: Epoch 22/38 Batch 7600/7662 eta: 20:55:32.748231	Training Loss 1.9257 (1.8393)	Training Prec@1 100.000 (99.925)	Training Prec@5 100.000 (99.980)	
2022-03-27 09:02:52,586: ============================================================
2022-03-27 09:03:34,776: Epoch: 22/38 eta: 20:54:54.054634	Training Loss 1.8803 (1.8397)	Training Prec@1 100.000 (99.925)	Training Prec@5 100.000 (99.980)
2022-03-27 09:03:34,776: ============================================================
2022-03-27 09:04:39,302: time cost, forward:0.0158997280429108, backward:0.03866850727736348, data cost:0.5897419886155562 
2022-03-27 09:04:39,306: ============================================================
2022-03-27 09:04:39,307: Epoch 23/38 Batch 100/7662 eta: 21:53:38.367956	Training Loss 1.7265 (1.7082)	Training Prec@1 100.000 (99.966)	Training Prec@5 100.000 (99.994)	
2022-03-27 09:04:39,308: ============================================================
2022-03-27 09:05:40,120: time cost, forward:0.014655533747457379, backward:0.03880418005900167, data cost:0.5723534648741909 
2022-03-27 09:05:40,120: ============================================================
2022-03-27 09:05:40,121: Epoch 23/38 Batch 200/7662 eta: 20:40:32.805780	Training Loss 1.8308 (1.7096)	Training Prec@1 99.805 (99.953)	Training Prec@5 100.000 (99.995)	
2022-03-27 09:05:40,121: ============================================================
2022-03-27 09:06:41,487: time cost, forward:0.015351063431704722, backward:0.03994720596134862, data cost:0.5661869942145205 
2022-03-27 09:06:41,487: ============================================================
2022-03-27 09:06:41,487: Epoch 23/38 Batch 300/7662 eta: 20:50:47.068429	Training Loss 1.7363 (1.7108)	Training Prec@1 100.000 (99.960)	Training Prec@5 100.000 (99.996)	
2022-03-27 09:06:41,488: ============================================================
2022-03-27 09:07:42,846: time cost, forward:0.01526324671312681, backward:0.03922911813683378, data cost:0.5634034331281084 
2022-03-27 09:07:42,848: ============================================================
2022-03-27 09:07:42,849: Epoch 23/38 Batch 400/7662 eta: 20:49:39.398585	Training Loss 1.8008 (1.7162)	Training Prec@1 100.000 (99.960)	Training Prec@5 100.000 (99.995)	
2022-03-27 09:07:42,850: ============================================================
2022-03-27 09:08:41,626: time cost, forward:0.015499495313258352, backward:0.03867733789111426, data cost:0.5577167083839615 
2022-03-27 09:08:41,627: ============================================================
2022-03-27 09:08:41,627: Epoch 23/38 Batch 500/7662 eta: 19:56:03.677554	Training Loss 1.6467 (1.7201)	Training Prec@1 100.000 (99.959)	Training Prec@5 100.000 (99.992)	
2022-03-27 09:08:41,627: ============================================================
2022-03-27 09:09:44,352: time cost, forward:0.015555242067187378, backward:0.038464897264025244, data cost:0.5607208294144059 
2022-03-27 09:09:44,352: ============================================================
2022-03-27 09:09:44,353: Epoch 23/38 Batch 600/7662 eta: 21:15:21.111416	Training Loss 1.7949 (1.7234)	Training Prec@1 100.000 (99.959)	Training Prec@5 100.000 (99.991)	
2022-03-27 09:09:44,353: ============================================================
2022-03-27 09:10:44,382: time cost, forward:0.015601456591670265, backward:0.038642857037218176, data cost:0.5578537052110882 
2022-03-27 09:10:44,382: ============================================================
2022-03-27 09:10:44,382: Epoch 23/38 Batch 700/7662 eta: 20:19:32.124039	Training Loss 1.6110 (1.7255)	Training Prec@1 100.000 (99.955)	Training Prec@5 100.000 (99.988)	
2022-03-27 09:10:44,383: ============================================================
2022-03-27 09:11:46,083: time cost, forward:0.01562605065308763, backward:0.03865291001053716, data cost:0.5586817527145558 
2022-03-27 09:11:46,084: ============================================================
2022-03-27 09:11:46,084: Epoch 23/38 Batch 800/7662 eta: 20:52:28.373225	Training Loss 1.6529 (1.7278)	Training Prec@1 100.000 (99.954)	Training Prec@5 100.000 (99.987)	
2022-03-27 09:11:46,084: ============================================================
2022-03-27 09:12:50,175: time cost, forward:0.015567404011863224, backward:0.038462968769009835, data cost:0.5610362242273282 
2022-03-27 09:12:50,178: ============================================================
2022-03-27 09:12:50,179: Epoch 23/38 Batch 900/7662 eta: 21:39:58.064736	Training Loss 1.8426 (1.7304)	Training Prec@1 100.000 (99.953)	Training Prec@5 100.000 (99.987)	
2022-03-27 09:12:50,179: ============================================================
2022-03-27 09:13:52,146: time cost, forward:0.015528814690010445, backward:0.03838098013365233, data cost:0.5619085589209357 
2022-03-27 09:13:52,146: ============================================================
2022-03-27 09:13:52,146: Epoch 23/38 Batch 1000/7662 eta: 20:55:48.626084	Training Loss 1.8446 (1.7312)	Training Prec@1 100.000 (99.953)	Training Prec@5 100.000 (99.987)	
2022-03-27 09:13:52,146: ============================================================
2022-03-27 09:14:54,747: time cost, forward:0.015501398298282641, backward:0.03839858994904814, data cost:0.5630548306223042 
2022-03-27 09:14:54,747: ============================================================
2022-03-27 09:14:54,748: Epoch 23/38 Batch 1100/7662 eta: 21:07:36.475486	Training Loss 1.6884 (1.7306)	Training Prec@1 100.000 (99.952)	Training Prec@5 100.000 (99.987)	
2022-03-27 09:14:54,748: ============================================================
2022-03-27 09:15:54,069: time cost, forward:0.01556235318187876, backward:0.038340140621894794, data cost:0.5609185942219534 
2022-03-27 09:15:54,069: ============================================================
2022-03-27 09:15:54,070: Epoch 23/38 Batch 1200/7662 eta: 20:00:12.548265	Training Loss 1.7644 (1.7332)	Training Prec@1 99.805 (99.951)	Training Prec@5 100.000 (99.987)	
2022-03-27 09:15:54,070: ============================================================
2022-03-27 09:16:56,809: time cost, forward:0.015684586841386496, backward:0.038480930276977916, data cost:0.5615314580184666 
2022-03-27 09:16:56,809: ============================================================
2022-03-27 09:16:56,810: Epoch 23/38 Batch 1300/7662 eta: 21:08:19.219536	Training Loss 1.7261 (1.7355)	Training Prec@1 100.000 (99.951)	Training Prec@5 100.000 (99.987)	
2022-03-27 09:16:56,810: ============================================================
2022-03-27 09:17:59,688: time cost, forward:0.01572584986601496, backward:0.03841768476773876, data cost:0.5621674786813775 
2022-03-27 09:17:59,691: ============================================================
2022-03-27 09:17:59,691: Epoch 23/38 Batch 1400/7662 eta: 21:10:08.097082	Training Loss 1.6564 (1.7364)	Training Prec@1 100.000 (99.950)	Training Prec@5 100.000 (99.987)	
2022-03-27 09:17:59,692: ============================================================
2022-03-27 09:19:00,135: time cost, forward:0.01575096055934873, backward:0.03838347831990736, data cost:0.5611568739447615 
2022-03-27 09:19:00,137: ============================================================
2022-03-27 09:19:00,137: Epoch 23/38 Batch 1500/7662 eta: 20:19:55.313940	Training Loss 1.7043 (1.7384)	Training Prec@1 100.000 (99.951)	Training Prec@5 100.000 (99.987)	
2022-03-27 09:19:00,137: ============================================================
2022-03-27 09:19:58,760: time cost, forward:0.015903524043337863, backward:0.038753770603993445, data cost:0.5590545093364608 
2022-03-27 09:19:58,760: ============================================================
2022-03-27 09:19:58,760: Epoch 23/38 Batch 1600/7662 eta: 19:42:10.312159	Training Loss 1.8544 (1.7403)	Training Prec@1 100.000 (99.951)	Training Prec@5 100.000 (99.987)	
2022-03-27 09:19:58,760: ============================================================
2022-03-27 09:21:01,775: time cost, forward:0.01597886537368891, backward:0.03882042810171755, data cost:0.5598179088612737 
2022-03-27 09:21:01,776: ============================================================
2022-03-27 09:21:01,776: Epoch 23/38 Batch 1700/7662 eta: 21:09:41.591365	Training Loss 1.7222 (1.7416)	Training Prec@1 99.805 (99.950)	Training Prec@5 100.000 (99.987)	
2022-03-27 09:21:01,776: ============================================================
2022-03-27 09:22:01,948: time cost, forward:0.015877104521195316, backward:0.0388338642692884, data cost:0.5591169844209121 
2022-03-27 09:22:01,948: ============================================================
2022-03-27 09:22:01,948: Epoch 23/38 Batch 1800/7662 eta: 20:11:23.870590	Training Loss 1.7082 (1.7433)	Training Prec@1 100.000 (99.950)	Training Prec@5 100.000 (99.987)	
2022-03-27 09:22:01,948: ============================================================
2022-03-27 09:23:04,051: time cost, forward:0.015950349081560712, backward:0.03870082504188092, data cost:0.559427415778475 
2022-03-27 09:23:04,052: ============================================================
2022-03-27 09:23:04,052: Epoch 23/38 Batch 1900/7662 eta: 20:49:15.158386	Training Loss 1.6728 (1.7453)	Training Prec@1 100.000 (99.950)	Training Prec@5 100.000 (99.986)	
2022-03-27 09:23:04,052: ============================================================
2022-03-27 09:24:05,062: time cost, forward:0.015946198368501877, backward:0.03876702996597939, data cost:0.5591478135479636 
2022-03-27 09:24:05,063: ============================================================
2022-03-27 09:24:05,063: Epoch 23/38 Batch 2000/7662 eta: 20:26:14.738379	Training Loss 1.7909 (1.7458)	Training Prec@1 100.000 (99.950)	Training Prec@5 100.000 (99.986)	
2022-03-27 09:24:05,063: ============================================================
2022-03-27 09:25:08,277: time cost, forward:0.01604592646798274, backward:0.038574879029752415, data cost:0.5600451825629421 
2022-03-27 09:25:08,277: ============================================================
2022-03-27 09:25:08,277: Epoch 23/38 Batch 2100/7662 eta: 21:09:28.705852	Training Loss 1.6715 (1.7477)	Training Prec@1 100.000 (99.949)	Training Prec@5 100.000 (99.986)	
2022-03-27 09:25:08,277: ============================================================
2022-03-27 09:26:13,108: time cost, forward:0.016017784796936396, backward:0.03859439195422163, data cost:0.5612133629162672 
2022-03-27 09:26:13,109: ============================================================
2022-03-27 09:26:13,109: Epoch 23/38 Batch 2200/7662 eta: 21:40:52.742573	Training Loss 1.7338 (1.7493)	Training Prec@1 99.805 (99.949)	Training Prec@5 99.805 (99.986)	
2022-03-27 09:26:13,109: ============================================================
2022-03-27 09:27:14,894: time cost, forward:0.01609679884161831, backward:0.038666136838291565, data cost:0.5613757138046922 
2022-03-27 09:27:14,895: ============================================================
2022-03-27 09:27:14,895: Epoch 23/38 Batch 2300/7662 eta: 20:38:44.245042	Training Loss 1.8785 (1.7512)	Training Prec@1 100.000 (99.949)	Training Prec@5 100.000 (99.986)	
2022-03-27 09:27:14,895: ============================================================
2022-03-27 09:28:15,191: time cost, forward:0.016073650894387656, backward:0.03863207078467016, data cost:0.5608389056588571 
2022-03-27 09:28:15,191: ============================================================
2022-03-27 09:28:15,192: Epoch 23/38 Batch 2400/7662 eta: 20:07:52.661941	Training Loss 1.8734 (1.7534)	Training Prec@1 100.000 (99.948)	Training Prec@5 100.000 (99.986)	
2022-03-27 09:28:15,192: ============================================================
2022-03-27 09:29:20,491: time cost, forward:0.016185941768675244, backward:0.038789737696836545, data cost:0.5619767169181515 
2022-03-27 09:29:20,491: ============================================================
2022-03-27 09:29:20,491: Epoch 23/38 Batch 2500/7662 eta: 21:47:00.105902	Training Loss 1.7585 (1.7556)	Training Prec@1 100.000 (99.947)	Training Prec@5 100.000 (99.985)	
2022-03-27 09:29:20,491: ============================================================
2022-03-27 09:30:23,549: time cost, forward:0.016281464137495275, backward:0.038972171832617086, data cost:0.5620680973593113 
2022-03-27 09:30:23,551: ============================================================
2022-03-27 09:30:23,552: Epoch 23/38 Batch 2600/7662 eta: 21:01:08.005991	Training Loss 1.8412 (1.7563)	Training Prec@1 99.805 (99.946)	Training Prec@5 100.000 (99.985)	
2022-03-27 09:30:23,552: ============================================================
2022-03-27 09:31:25,678: time cost, forward:0.01625800159252233, backward:0.03902609810293847, data cost:0.5621447965099706 
2022-03-27 09:31:25,678: ============================================================
2022-03-27 09:31:25,678: Epoch 23/38 Batch 2700/7662 eta: 20:41:25.470297	Training Loss 1.7863 (1.7576)	Training Prec@1 100.000 (99.945)	Training Prec@5 100.000 (99.985)	
2022-03-27 09:31:25,678: ============================================================
2022-03-27 09:32:26,965: time cost, forward:0.016324039270469826, backward:0.03915110039855804, data cost:0.5618253354729819 
2022-03-27 09:32:26,965: ============================================================
2022-03-27 09:32:26,966: Epoch 23/38 Batch 2800/7662 eta: 20:23:37.852579	Training Loss 1.6017 (1.7586)	Training Prec@1 100.000 (99.945)	Training Prec@5 100.000 (99.985)	
2022-03-27 09:32:26,966: ============================================================
2022-03-27 09:33:29,305: time cost, forward:0.016314359400427806, backward:0.03911380563862943, data cost:0.5617965107418086 
2022-03-27 09:33:29,307: ============================================================
2022-03-27 09:33:29,308: Epoch 23/38 Batch 2900/7662 eta: 20:43:39.200411	Training Loss 1.9248 (1.7601)	Training Prec@1 100.000 (99.945)	Training Prec@5 100.000 (99.985)	
2022-03-27 09:33:29,308: ============================================================
2022-03-27 09:34:32,753: time cost, forward:0.016362240728675304, backward:0.03921115402381951, data cost:0.562433031250056 
2022-03-27 09:34:32,754: ============================================================
2022-03-27 09:34:32,754: Epoch 23/38 Batch 3000/7662 eta: 21:04:37.600193	Training Loss 1.7855 (1.7616)	Training Prec@1 100.000 (99.944)	Training Prec@5 100.000 (99.985)	
2022-03-27 09:34:32,755: ============================================================
2022-03-27 09:35:34,562: time cost, forward:0.016371829696684815, backward:0.03934030288186678, data cost:0.5622172530292119 
2022-03-27 09:35:34,563: ============================================================
2022-03-27 09:35:34,563: Epoch 23/38 Batch 3100/7662 eta: 20:30:57.273976	Training Loss 1.6471 (1.7629)	Training Prec@1 99.609 (99.944)	Training Prec@5 99.805 (99.985)	
2022-03-27 09:35:34,563: ============================================================
2022-03-27 09:36:39,579: time cost, forward:0.01643314358591102, backward:0.03944569246662375, data cost:0.5627788210257995 
2022-03-27 09:36:39,581: ============================================================
2022-03-27 09:36:39,582: Epoch 23/38 Batch 3200/7662 eta: 21:33:47.684694	Training Loss 1.6224 (1.7645)	Training Prec@1 99.805 (99.944)	Training Prec@5 100.000 (99.985)	
2022-03-27 09:36:39,582: ============================================================
2022-03-27 09:37:42,730: time cost, forward:0.016426575548831677, backward:0.03948882414594351, data cost:0.5633295627390482 
2022-03-27 09:37:42,731: ============================================================
2022-03-27 09:37:42,731: Epoch 23/38 Batch 3300/7662 eta: 20:55:32.879722	Training Loss 1.8337 (1.7658)	Training Prec@1 99.805 (99.944)	Training Prec@5 100.000 (99.985)	
2022-03-27 09:37:42,732: ============================================================
2022-03-27 09:38:47,805: time cost, forward:0.01651361101548368, backward:0.03953228020675044, data cost:0.5640505808667248 
2022-03-27 09:38:47,807: ============================================================
2022-03-27 09:38:47,808: Epoch 23/38 Batch 3400/7662 eta: 21:32:46.507818	Training Loss 1.9057 (1.7672)	Training Prec@1 100.000 (99.944)	Training Prec@5 100.000 (99.985)	
2022-03-27 09:38:47,808: ============================================================
2022-03-27 09:39:51,115: time cost, forward:0.016484502520892372, backward:0.039499041147659966, data cost:0.5644661798992304 
2022-03-27 09:39:51,115: ============================================================
2022-03-27 09:39:51,116: Epoch 23/38 Batch 3500/7662 eta: 20:56:35.360768	Training Loss 1.8297 (1.7681)	Training Prec@1 99.805 (99.944)	Training Prec@5 100.000 (99.985)	
2022-03-27 09:39:51,116: ============================================================
2022-03-27 09:40:56,500: time cost, forward:0.01653281136597816, backward:0.03952649269676368, data cost:0.5652865020723334 
2022-03-27 09:40:56,501: ============================================================
2022-03-27 09:40:56,501: Epoch 23/38 Batch 3600/7662 eta: 21:36:44.262149	Training Loss 1.7493 (1.7691)	Training Prec@1 100.000 (99.944)	Training Prec@5 100.000 (99.985)	
2022-03-27 09:40:56,501: ============================================================
2022-03-27 09:41:59,476: time cost, forward:0.016537095766255713, backward:0.03960269842640263, data cost:0.5653951554144998 
2022-03-27 09:41:59,479: ============================================================
2022-03-27 09:41:59,479: Epoch 23/38 Batch 3700/7662 eta: 20:47:56.032068	Training Loss 1.9366 (1.7703)	Training Prec@1 99.805 (99.944)	Training Prec@5 100.000 (99.985)	
2022-03-27 09:41:59,479: ============================================================
2022-03-27 09:43:01,881: time cost, forward:0.01654555609929747, backward:0.03968267297707096, data cost:0.5653302578525689 
2022-03-27 09:43:01,881: ============================================================
2022-03-27 09:43:01,881: Epoch 23/38 Batch 3800/7662 eta: 20:35:29.674272	Training Loss 1.6824 (1.7711)	Training Prec@1 100.000 (99.944)	Training Prec@5 100.000 (99.985)	
2022-03-27 09:43:01,882: ============================================================
2022-03-27 09:44:05,137: time cost, forward:0.01662944444909283, backward:0.039705343263581584, data cost:0.5654654402584869 
2022-03-27 09:44:05,137: ============================================================
2022-03-27 09:44:05,138: Epoch 23/38 Batch 3900/7662 eta: 20:51:20.744378	Training Loss 1.7510 (1.7723)	Training Prec@1 99.805 (99.944)	Training Prec@5 100.000 (99.985)	
2022-03-27 09:44:05,138: ============================================================
2022-03-27 09:45:10,180: time cost, forward:0.016590845707089463, backward:0.0397466973502447, data cost:0.5661332536918219 
2022-03-27 09:45:10,181: ============================================================
2022-03-27 09:45:10,181: Epoch 23/38 Batch 4000/7662 eta: 21:25:36.667775	Training Loss 1.6986 (1.7733)	Training Prec@1 100.000 (99.944)	Training Prec@5 100.000 (99.985)	
2022-03-27 09:45:10,181: ============================================================
2022-03-27 09:46:15,983: time cost, forward:0.01667180914040105, backward:0.03977481171281549, data cost:0.5668453674079093 
2022-03-27 09:46:15,983: ============================================================
2022-03-27 09:46:15,983: Epoch 23/38 Batch 4100/7662 eta: 21:39:31.427811	Training Loss 1.9274 (1.7748)	Training Prec@1 100.000 (99.944)	Training Prec@5 100.000 (99.985)	
2022-03-27 09:46:15,984: ============================================================
2022-03-27 09:47:19,590: time cost, forward:0.01667646420345502, backward:0.03983268723030208, data cost:0.5670449004113092 
2022-03-27 09:47:19,591: ============================================================
2022-03-27 09:47:19,591: Epoch 23/38 Batch 4200/7662 eta: 20:55:07.298393	Training Loss 1.8653 (1.7760)	Training Prec@1 100.000 (99.944)	Training Prec@5 100.000 (99.985)	
2022-03-27 09:47:19,591: ============================================================
2022-03-27 09:48:25,048: time cost, forward:0.01670974513823888, backward:0.03984975515340311, data cost:0.5676953680544683 
2022-03-27 09:48:25,049: ============================================================
2022-03-27 09:48:25,049: Epoch 23/38 Batch 4300/7662 eta: 21:30:31.873411	Training Loss 1.8566 (1.7780)	Training Prec@1 100.000 (99.943)	Training Prec@5 100.000 (99.985)	
2022-03-27 09:48:25,049: ============================================================
2022-03-27 09:49:28,852: time cost, forward:0.01668639561348976, backward:0.03979951935915764, data cost:0.5680449175330611 
2022-03-27 09:49:28,853: ============================================================
2022-03-27 09:49:28,853: Epoch 23/38 Batch 4400/7662 eta: 20:56:51.839059	Training Loss 1.6598 (1.7790)	Training Prec@1 100.000 (99.943)	Training Prec@5 100.000 (99.985)	
2022-03-27 09:49:28,853: ============================================================
2022-03-27 09:50:32,584: time cost, forward:0.01666316813324578, backward:0.03976636198950651, data cost:0.5683540716571897 
2022-03-27 09:50:32,584: ============================================================
2022-03-27 09:50:32,584: Epoch 23/38 Batch 4500/7662 eta: 20:54:22.248731	Training Loss 1.7513 (1.7804)	Training Prec@1 100.000 (99.943)	Training Prec@5 100.000 (99.985)	
2022-03-27 09:50:32,584: ============================================================
2022-03-27 09:51:36,386: time cost, forward:0.016637808500515116, backward:0.039770212969745755, data cost:0.568642134665406 
2022-03-27 09:51:36,387: ============================================================
2022-03-27 09:51:36,387: Epoch 23/38 Batch 4600/7662 eta: 20:54:42.872617	Training Loss 1.8057 (1.7817)	Training Prec@1 100.000 (99.942)	Training Prec@5 100.000 (99.985)	
2022-03-27 09:51:36,387: ============================================================
2022-03-27 09:52:40,193: time cost, forward:0.01669297098580714, backward:0.03983628838639179, data cost:0.5687358304778929 
2022-03-27 09:52:40,194: ============================================================
2022-03-27 09:52:40,194: Epoch 23/38 Batch 4700/7662 eta: 20:53:43.895910	Training Loss 1.7505 (1.7828)	Training Prec@1 100.000 (99.942)	Training Prec@5 100.000 (99.985)	
2022-03-27 09:52:40,194: ============================================================
2022-03-27 09:53:42,769: time cost, forward:0.016670560956026124, backward:0.039773185691825544, data cost:0.5687959262246165 
2022-03-27 09:53:42,769: ============================================================
2022-03-27 09:53:42,770: Epoch 23/38 Batch 4800/7662 eta: 20:28:29.570805	Training Loss 1.8447 (1.7839)	Training Prec@1 99.805 (99.942)	Training Prec@5 100.000 (99.984)	
2022-03-27 09:53:42,770: ============================================================
2022-03-27 09:54:45,862: time cost, forward:0.01664397107700738, backward:0.03975505039482171, data cost:0.5689310978373403 
2022-03-27 09:54:45,863: ============================================================
2022-03-27 09:54:45,863: Epoch 23/38 Batch 4900/7662 eta: 20:37:37.011087	Training Loss 1.9126 (1.7852)	Training Prec@1 99.805 (99.941)	Training Prec@5 100.000 (99.984)	
2022-03-27 09:54:45,864: ============================================================
2022-03-27 09:55:50,411: time cost, forward:0.016626486804013636, backward:0.039650560116906194, data cost:0.5694603289478086 
2022-03-27 09:55:50,411: ============================================================
2022-03-27 09:55:50,412: Epoch 23/38 Batch 5000/7662 eta: 21:05:04.406933	Training Loss 1.9683 (1.7864)	Training Prec@1 100.000 (99.941)	Training Prec@5 100.000 (99.984)	
2022-03-27 09:55:50,412: ============================================================
2022-03-27 09:56:52,736: time cost, forward:0.016612872864176512, backward:0.03962025457233699, data cost:0.5692458345881161 
2022-03-27 09:56:52,738: ============================================================
2022-03-27 09:56:52,738: Epoch 23/38 Batch 5100/7662 eta: 20:20:29.004813	Training Loss 1.7622 (1.7876)	Training Prec@1 100.000 (99.940)	Training Prec@5 100.000 (99.984)	
2022-03-27 09:56:52,739: ============================================================
2022-03-27 09:57:55,672: time cost, forward:0.016617559657506838, backward:0.03962269652965184, data cost:0.5694473759672646 
2022-03-27 09:57:55,672: ============================================================
2022-03-27 09:57:55,672: Epoch 23/38 Batch 5200/7662 eta: 20:31:20.400041	Training Loss 1.7026 (1.7886)	Training Prec@1 100.000 (99.940)	Training Prec@5 100.000 (99.984)	
2022-03-27 09:57:55,673: ============================================================
2022-03-27 09:58:58,612: time cost, forward:0.016597058508031254, backward:0.03960665929405211, data cost:0.5695539240703018 
2022-03-27 09:58:58,613: ============================================================
2022-03-27 09:58:58,613: Epoch 23/38 Batch 5300/7662 eta: 20:30:25.290354	Training Loss 1.9415 (1.7899)	Training Prec@1 100.000 (99.940)	Training Prec@5 100.000 (99.984)	
2022-03-27 09:58:58,614: ============================================================
2022-03-27 10:00:02,021: time cost, forward:0.01661292577942426, backward:0.03959670290281914, data cost:0.5696304140763937 
2022-03-27 10:00:02,024: ============================================================
2022-03-27 10:00:02,024: Epoch 23/38 Batch 5400/7662 eta: 20:38:33.115217	Training Loss 1.7629 (1.7907)	Training Prec@1 100.000 (99.940)	Training Prec@5 100.000 (99.984)	
2022-03-27 10:00:02,025: ============================================================
2022-03-27 10:01:05,912: time cost, forward:0.016640356571636625, backward:0.03966346986295093, data cost:0.5697248530487599 
2022-03-27 10:01:05,915: ============================================================
2022-03-27 10:01:05,916: Epoch 23/38 Batch 5500/7662 eta: 20:46:52.419652	Training Loss 1.9637 (1.7918)	Training Prec@1 99.805 (99.939)	Training Prec@5 100.000 (99.984)	
2022-03-27 10:01:05,916: ============================================================
2022-03-27 10:02:09,636: time cost, forward:0.016617531520082475, backward:0.03962595361878902, data cost:0.5700313140503273 
2022-03-27 10:02:09,636: ============================================================
2022-03-27 10:02:09,637: Epoch 23/38 Batch 5600/7662 eta: 20:42:29.125099	Training Loss 1.9138 (1.7930)	Training Prec@1 99.805 (99.939)	Training Prec@5 99.805 (99.983)	
2022-03-27 10:02:09,637: ============================================================
2022-03-27 10:03:13,474: time cost, forward:0.016575461627098737, backward:0.03958500467030327, data cost:0.5702002474792716 
2022-03-27 10:03:13,475: ============================================================
2022-03-27 10:03:13,475: Epoch 23/38 Batch 5700/7662 eta: 20:43:42.455235	Training Loss 1.7759 (1.7942)	Training Prec@1 100.000 (99.939)	Training Prec@5 100.000 (99.983)	
2022-03-27 10:03:13,475: ============================================================
2022-03-27 10:04:14,588: time cost, forward:0.01658224368798443, backward:0.039623183903148985, data cost:0.5699705661093496 
2022-03-27 10:04:14,588: ============================================================
2022-03-27 10:04:14,589: Epoch 23/38 Batch 5800/7662 eta: 19:49:36.617379	Training Loss 1.8931 (1.7954)	Training Prec@1 100.000 (99.939)	Training Prec@5 100.000 (99.983)	
2022-03-27 10:04:14,589: ============================================================
2022-03-27 10:05:18,381: time cost, forward:0.016621036112439858, backward:0.03967115628070641, data cost:0.5700035509890996 
2022-03-27 10:05:18,381: ============================================================
2022-03-27 10:05:18,382: Epoch 23/38 Batch 5900/7662 eta: 20:40:41.932918	Training Loss 1.9620 (1.7969)	Training Prec@1 100.000 (99.938)	Training Prec@5 100.000 (99.983)	
2022-03-27 10:05:18,382: ============================================================
2022-03-27 10:06:22,814: time cost, forward:0.016607920077070036, backward:0.03966316880335667, data cost:0.5703615445577218 
2022-03-27 10:06:22,814: ============================================================
2022-03-27 10:06:22,814: Epoch 23/38 Batch 6000/7662 eta: 20:52:04.041167	Training Loss 1.8989 (1.7978)	Training Prec@1 100.000 (99.938)	Training Prec@5 100.000 (99.983)	
2022-03-27 10:06:22,815: ============================================================
2022-03-27 10:07:25,564: time cost, forward:0.01658295080063284, backward:0.039629603823905575, data cost:0.5704084119360493 
2022-03-27 10:07:25,565: ============================================================
2022-03-27 10:07:25,565: Epoch 23/38 Batch 6100/7662 eta: 20:18:19.834659	Training Loss 1.8707 (1.7989)	Training Prec@1 100.000 (99.938)	Training Prec@5 100.000 (99.983)	
2022-03-27 10:07:25,565: ============================================================
2022-03-27 10:08:32,078: time cost, forward:0.016627467818982486, backward:0.039624699009370566, data cost:0.5709357848954327 
2022-03-27 10:08:32,078: ============================================================
2022-03-27 10:08:32,079: Epoch 23/38 Batch 6200/7662 eta: 21:30:17.469562	Training Loss 1.9159 (1.8000)	Training Prec@1 100.000 (99.938)	Training Prec@5 100.000 (99.983)	
2022-03-27 10:08:32,079: ============================================================
2022-03-27 10:09:34,403: time cost, forward:0.016605337303126497, backward:0.03960817911299775, data cost:0.5709279109644765 
2022-03-27 10:09:34,404: ============================================================
2022-03-27 10:09:34,404: Epoch 23/38 Batch 6300/7662 eta: 20:08:00.012398	Training Loss 1.8704 (1.8012)	Training Prec@1 100.000 (99.937)	Training Prec@5 100.000 (99.983)	
2022-03-27 10:09:34,404: ============================================================
2022-03-27 10:10:39,181: time cost, forward:0.016632407992160737, backward:0.03965847166949351, data cost:0.5711493754427887 
2022-03-27 10:10:39,181: ============================================================
2022-03-27 10:10:39,182: Epoch 23/38 Batch 6400/7662 eta: 20:54:27.003306	Training Loss 1.9390 (1.8023)	Training Prec@1 100.000 (99.937)	Training Prec@5 100.000 (99.983)	
2022-03-27 10:10:39,182: ============================================================
2022-03-27 10:11:44,716: time cost, forward:0.016639249877647942, backward:0.03967173871012317, data cost:0.5715048894971715 
2022-03-27 10:11:44,717: ============================================================
2022-03-27 10:11:44,717: Epoch 23/38 Batch 6500/7662 eta: 21:08:01.951205	Training Loss 1.9214 (1.8032)	Training Prec@1 100.000 (99.937)	Training Prec@5 100.000 (99.983)	
2022-03-27 10:11:44,717: ============================================================
2022-03-27 10:12:48,250: time cost, forward:0.016645025350701035, backward:0.03968817372270779, data cost:0.5714813494866573 
2022-03-27 10:12:48,253: ============================================================
2022-03-27 10:12:48,254: Epoch 23/38 Batch 6600/7662 eta: 20:28:17.344022	Training Loss 2.0633 (1.8041)	Training Prec@1 99.805 (99.936)	Training Prec@5 100.000 (99.984)	
2022-03-27 10:12:48,254: ============================================================
2022-03-27 10:13:50,591: time cost, forward:0.016640447968777516, backward:0.039708799525043255, data cost:0.5715048197828704 
2022-03-27 10:13:50,592: ============================================================
2022-03-27 10:13:50,592: Epoch 23/38 Batch 6700/7662 eta: 20:04:06.538636	Training Loss 1.9223 (1.8051)	Training Prec@1 100.000 (99.936)	Training Prec@5 100.000 (99.983)	
2022-03-27 10:13:50,592: ============================================================
2022-03-27 10:14:56,124: time cost, forward:0.016673784428509673, backward:0.03970993885416759, data cost:0.5718534508598676 
2022-03-27 10:14:56,125: ============================================================
2022-03-27 10:14:56,125: Epoch 23/38 Batch 6800/7662 eta: 21:04:42.393676	Training Loss 1.8640 (1.8064)	Training Prec@1 99.805 (99.935)	Training Prec@5 100.000 (99.983)	
2022-03-27 10:14:56,125: ============================================================
2022-03-27 10:16:00,502: time cost, forward:0.01669280064902559, backward:0.03973902465813677, data cost:0.5719340084635498 
2022-03-27 10:16:00,503: ============================================================
2022-03-27 10:16:00,503: Epoch 23/38 Batch 6900/7662 eta: 20:41:21.164220	Training Loss 1.6489 (1.8073)	Training Prec@1 99.805 (99.935)	Training Prec@5 100.000 (99.983)	
2022-03-27 10:16:00,503: ============================================================
2022-03-27 10:17:04,773: time cost, forward:0.016692824185890954, backward:0.039750116350719254, data cost:0.5721878527845549 
2022-03-27 10:17:04,773: ============================================================
2022-03-27 10:17:04,774: Epoch 23/38 Batch 7000/7662 eta: 20:38:12.117700	Training Loss 1.9116 (1.8084)	Training Prec@1 100.000 (99.935)	Training Prec@5 100.000 (99.983)	
2022-03-27 10:17:04,774: ============================================================
2022-03-27 10:18:08,892: time cost, forward:0.01672202208492517, backward:0.0397695149984439, data cost:0.5721807975906069 
2022-03-27 10:18:08,893: ============================================================
2022-03-27 10:18:08,893: Epoch 23/38 Batch 7100/7662 eta: 20:34:13.601507	Training Loss 1.9086 (1.8096)	Training Prec@1 99.805 (99.935)	Training Prec@5 100.000 (99.983)	
2022-03-27 10:18:08,893: ============================================================
2022-03-27 10:19:13,480: time cost, forward:0.016731825184865136, backward:0.03978998413647624, data cost:0.5724639519003799 
2022-03-27 10:19:13,481: ============================================================
2022-03-27 10:19:13,481: Epoch 23/38 Batch 7200/7662 eta: 20:42:10.131326	Training Loss 1.8879 (1.8106)	Training Prec@1 100.000 (99.935)	Training Prec@5 100.000 (99.983)	
2022-03-27 10:19:13,482: ============================================================
2022-03-27 10:20:14,140: time cost, forward:0.016722070956854056, backward:0.039825972897955156, data cost:0.5721361200717038 
2022-03-27 10:20:14,141: ============================================================
2022-03-27 10:20:14,141: Epoch 23/38 Batch 7300/7662 eta: 19:25:36.169296	Training Loss 1.9550 (1.8115)	Training Prec@1 99.805 (99.934)	Training Prec@5 99.805 (99.983)	
2022-03-27 10:20:14,141: ============================================================
2022-03-27 10:21:18,411: time cost, forward:0.01673138136798618, backward:0.039841798499301084, data cost:0.5722823765877534 
2022-03-27 10:21:18,412: ============================================================
2022-03-27 10:21:18,412: Epoch 23/38 Batch 7400/7662 eta: 20:33:55.849745	Training Loss 1.9274 (1.8125)	Training Prec@1 100.000 (99.934)	Training Prec@5 100.000 (99.983)	
2022-03-27 10:21:18,412: ============================================================
2022-03-27 10:22:21,684: time cost, forward:0.01673004041911602, backward:0.03984570751223251, data cost:0.5723080356560766 
2022-03-27 10:22:21,684: ============================================================
2022-03-27 10:22:21,685: Epoch 23/38 Batch 7500/7662 eta: 20:13:42.495890	Training Loss 1.7649 (1.8136)	Training Prec@1 100.000 (99.934)	Training Prec@5 100.000 (99.983)	
2022-03-27 10:22:21,685: ============================================================
2022-03-27 10:23:25,739: time cost, forward:0.016743352655078692, backward:0.03988714295949634, data cost:0.5723697873758224 
2022-03-27 10:23:25,739: ============================================================
2022-03-27 10:23:25,740: Epoch 23/38 Batch 7600/7662 eta: 20:27:38.629967	Training Loss 1.8229 (1.8145)	Training Prec@1 100.000 (99.934)	Training Prec@5 100.000 (99.983)	
2022-03-27 10:23:25,740: ============================================================
2022-03-27 10:24:06,730: Epoch: 23/38 eta: 20:26:58.275392	Training Loss 1.8348 (1.8151)	Training Prec@1 100.000 (99.934)	Training Prec@5 100.000 (99.983)
2022-03-27 10:24:06,730: ============================================================
2022-03-27 10:25:13,864: time cost, forward:0.015580820314811937, backward:0.0380727064729941, data cost:0.6170548622054283 
2022-03-27 10:25:13,864: ============================================================
2022-03-27 10:25:13,865: Epoch 24/38 Batch 100/7662 eta: 21:21:31.624209	Training Loss 1.7261 (1.6770)	Training Prec@1 99.609 (99.951)	Training Prec@5 99.805 (99.988)	
2022-03-27 10:25:13,865: ============================================================
2022-03-27 10:26:20,371: time cost, forward:0.01653601895624669, backward:0.03991791351356698, data cost:0.6094365431435743 
2022-03-27 10:26:20,371: ============================================================
2022-03-27 10:26:20,372: Epoch 24/38 Batch 200/7662 eta: 21:11:44.097992	Training Loss 1.7234 (1.6936)	Training Prec@1 100.000 (99.963)	Training Prec@5 100.000 (99.989)	
2022-03-27 10:26:20,372: ============================================================
2022-03-27 10:27:23,923: time cost, forward:0.015779507200056095, backward:0.038730519272411945, data cost:0.5990134218464727 
2022-03-27 10:27:23,925: ============================================================
2022-03-27 10:27:23,926: Epoch 24/38 Batch 300/7662 eta: 20:14:12.628808	Training Loss 1.6883 (1.6951)	Training Prec@1 99.805 (99.963)	Training Prec@5 100.000 (99.990)	
2022-03-27 10:27:23,927: ============================================================
2022-03-27 10:28:30,014: time cost, forward:0.016369465299716272, backward:0.03932630985900573, data cost:0.6013451913245639 
2022-03-27 10:28:30,014: ============================================================
2022-03-27 10:28:30,015: Epoch 24/38 Batch 400/7662 eta: 21:01:32.068722	Training Loss 1.5756 (1.7013)	Training Prec@1 100.000 (99.961)	Training Prec@5 100.000 (99.990)	
2022-03-27 10:28:30,015: ============================================================
2022-03-27 10:29:37,802: time cost, forward:0.016614531706234736, backward:0.03969260303673142, data cost:0.6043490742394824 
2022-03-27 10:29:37,805: ============================================================
2022-03-27 10:29:37,806: Epoch 24/38 Batch 500/7662 eta: 21:32:53.784581	Training Loss 1.7422 (1.7001)	Training Prec@1 100.000 (99.962)	Training Prec@5 100.000 (99.990)	
2022-03-27 10:29:37,806: ============================================================
2022-03-27 10:30:42,459: time cost, forward:0.01655757049089282, backward:0.03901648242803965, data cost:0.6026335558628598 
2022-03-27 10:30:42,460: ============================================================
2022-03-27 10:30:42,460: Epoch 24/38 Batch 600/7662 eta: 20:31:59.946956	Training Loss 1.6366 (1.7032)	Training Prec@1 100.000 (99.958)	Training Prec@5 100.000 (99.989)	
2022-03-27 10:30:42,460: ============================================================
2022-03-27 10:31:47,743: time cost, forward:0.016771633737588644, backward:0.03927073526450663, data cost:0.6010589469996985 
2022-03-27 10:31:47,743: ============================================================
2022-03-27 10:31:47,744: Epoch 24/38 Batch 700/7662 eta: 20:42:54.471444	Training Loss 1.8641 (1.7042)	Training Prec@1 100.000 (99.956)	Training Prec@5 100.000 (99.989)	
2022-03-27 10:31:47,744: ============================================================
2022-03-27 10:32:56,773: time cost, forward:0.01702133794600734, backward:0.040386927441154165, data cost:0.603829211377083 
2022-03-27 10:32:56,773: ============================================================
2022-03-27 10:32:56,773: Epoch 24/38 Batch 800/7662 eta: 21:53:04.111443	Training Loss 1.8531 (1.7061)	Training Prec@1 100.000 (99.956)	Training Prec@5 100.000 (99.989)	
2022-03-27 10:32:56,774: ============================================================
2022-03-27 10:34:00,142: time cost, forward:0.01715191824152419, backward:0.040407391358270525, data cost:0.6003623334929198 
2022-03-27 10:34:00,142: ============================================================
2022-03-27 10:34:00,142: Epoch 24/38 Batch 900/7662 eta: 20:04:20.081680	Training Loss 1.8000 (1.7073)	Training Prec@1 100.000 (99.956)	Training Prec@5 100.000 (99.989)	
2022-03-27 10:34:00,142: ============================================================
2022-03-27 10:35:06,574: time cost, forward:0.01717175855054273, backward:0.040626430416011716, data cost:0.6007941246510029 
2022-03-27 10:35:06,575: ============================================================
2022-03-27 10:35:06,575: Epoch 24/38 Batch 1000/7662 eta: 21:01:27.905466	Training Loss 1.7490 (1.7089)	Training Prec@1 99.805 (99.956)	Training Prec@5 100.000 (99.989)	
2022-03-27 10:35:06,575: ============================================================
2022-03-27 10:36:10,860: time cost, forward:0.0173707025717127, backward:0.0409563592176637, data cost:0.5979297601493301 
2022-03-27 10:36:10,862: ============================================================
2022-03-27 10:36:10,863: Epoch 24/38 Batch 1100/7662 eta: 20:19:39.317061	Training Loss 1.8239 (1.7104)	Training Prec@1 100.000 (99.956)	Training Prec@5 100.000 (99.989)	
2022-03-27 10:36:10,864: ============================================================
2022-03-27 10:37:14,569: time cost, forward:0.01730914092044019, backward:0.04103847858406684, data cost:0.5968857404090048 
2022-03-27 10:37:14,570: ============================================================
2022-03-27 10:37:14,570: Epoch 24/38 Batch 1200/7662 eta: 20:07:34.901038	Training Loss 1.7772 (1.7119)	Training Prec@1 99.805 (99.956)	Training Prec@5 99.805 (99.989)	
2022-03-27 10:37:14,570: ============================================================
2022-03-27 10:38:18,874: time cost, forward:0.01735735123115287, backward:0.04112237962600908, data cost:0.5956987706948648 
2022-03-27 10:38:18,874: ============================================================
2022-03-27 10:38:18,874: Epoch 24/38 Batch 1300/7662 eta: 20:17:49.498654	Training Loss 1.8841 (1.7145)	Training Prec@1 99.805 (99.957)	Training Prec@5 100.000 (99.988)	
2022-03-27 10:38:18,875: ============================================================
2022-03-27 10:39:24,726: time cost, forward:0.017429033801588015, backward:0.041251803398814006, data cost:0.5957155808795768 
2022-03-27 10:39:24,726: ============================================================
2022-03-27 10:39:24,726: Epoch 24/38 Batch 1400/7662 eta: 20:46:02.250056	Training Loss 1.7884 (1.7177)	Training Prec@1 100.000 (99.955)	Training Prec@5 100.000 (99.988)	
2022-03-27 10:39:24,726: ============================================================
2022-03-27 10:40:32,816: time cost, forward:0.017640793458710835, backward:0.04140484674999601, data cost:0.596655629649808 
2022-03-27 10:40:32,817: ============================================================
2022-03-27 10:40:32,818: Epoch 24/38 Batch 1500/7662 eta: 21:27:17.033302	Training Loss 1.7387 (1.7177)	Training Prec@1 100.000 (99.956)	Training Prec@5 100.000 (99.989)	
2022-03-27 10:40:32,818: ============================================================
2022-03-27 10:41:39,610: time cost, forward:0.017723867190935376, backward:0.04152649115442559, data cost:0.5972443533510324 
2022-03-27 10:41:39,610: ============================================================
2022-03-27 10:41:39,610: Epoch 24/38 Batch 1600/7662 eta: 21:01:36.580096	Training Loss 1.7178 (1.7213)	Training Prec@1 100.000 (99.955)	Training Prec@5 100.000 (99.988)	
2022-03-27 10:41:39,611: ============================================================
2022-03-27 10:42:45,883: time cost, forward:0.017791421922815062, backward:0.04174601842263925, data cost:0.5971049876547057 
2022-03-27 10:42:45,886: ============================================================
2022-03-27 10:42:45,887: Epoch 24/38 Batch 1700/7662 eta: 20:50:45.679222	Training Loss 1.6878 (1.7234)	Training Prec@1 99.609 (99.956)	Training Prec@5 99.805 (99.989)	
2022-03-27 10:42:45,888: ============================================================
2022-03-27 10:43:49,799: time cost, forward:0.017862073576006377, backward:0.041855330464573556, data cost:0.5961746078785954 
2022-03-27 10:43:49,800: ============================================================
2022-03-27 10:43:49,800: Epoch 24/38 Batch 1800/7662 eta: 20:05:05.458498	Training Loss 1.7425 (1.7251)	Training Prec@1 100.000 (99.955)	Training Prec@5 100.000 (99.988)	
2022-03-27 10:43:49,800: ============================================================
2022-03-27 10:44:56,727: time cost, forward:0.017981949952353044, backward:0.04202537765121259, data cost:0.5964301929403569 
2022-03-27 10:44:56,728: ============================================================
2022-03-27 10:44:56,728: Epoch 24/38 Batch 1900/7662 eta: 21:00:49.434002	Training Loss 1.6558 (1.7276)	Training Prec@1 99.805 (99.953)	Training Prec@5 99.805 (99.988)	
2022-03-27 10:44:56,728: ============================================================
2022-03-27 10:45:59,021: time cost, forward:0.017882888349310764, backward:0.04201468149979989, data cost:0.5948949344400288 
2022-03-27 10:45:59,022: ============================================================
2022-03-27 10:45:59,022: Epoch 24/38 Batch 2000/7662 eta: 19:32:28.820242	Training Loss 1.8511 (1.7291)	Training Prec@1 100.000 (99.954)	Training Prec@5 100.000 (99.987)	
2022-03-27 10:45:59,022: ============================================================
2022-03-27 10:47:07,881: time cost, forward:0.01793179743740887, backward:0.04213730683492558, data cost:0.5959323097717881 
2022-03-27 10:47:07,882: ============================================================
2022-03-27 10:47:07,882: Epoch 24/38 Batch 2100/7662 eta: 21:34:55.445043	Training Loss 1.6607 (1.7297)	Training Prec@1 100.000 (99.953)	Training Prec@5 100.000 (99.988)	
2022-03-27 10:47:07,882: ============================================================
2022-03-27 10:48:10,276: time cost, forward:0.01799221654651706, backward:0.04228671424331422, data cost:0.594513498473677 
2022-03-27 10:48:10,276: ============================================================
2022-03-27 10:48:10,277: Epoch 24/38 Batch 2200/7662 eta: 19:32:18.494259	Training Loss 1.7601 (1.7320)	Training Prec@1 100.000 (99.953)	Training Prec@5 100.000 (99.988)	
2022-03-27 10:48:10,277: ============================================================
2022-03-27 10:49:16,460: time cost, forward:0.018057310565651474, backward:0.04228298443200641, data cost:0.5945307150671097 
2022-03-27 10:49:16,465: ============================================================
2022-03-27 10:49:16,468: Epoch 24/38 Batch 2300/7662 eta: 20:42:30.264815	Training Loss 1.7688 (1.7341)	Training Prec@1 100.000 (99.953)	Training Prec@5 100.000 (99.988)	
2022-03-27 10:49:16,468: ============================================================
2022-03-27 10:50:23,427: time cost, forward:0.018117691388275285, backward:0.042386584303785536, data cost:0.5950837199913556 
2022-03-27 10:50:23,427: ============================================================
2022-03-27 10:50:23,428: Epoch 24/38 Batch 2400/7662 eta: 20:55:51.773139	Training Loss 1.7160 (1.7354)	Training Prec@1 99.609 (99.953)	Training Prec@5 100.000 (99.988)	
2022-03-27 10:50:23,428: ============================================================
2022-03-27 10:51:29,208: time cost, forward:0.01812226765629958, backward:0.04245676351290028, data cost:0.5948305992471451 
2022-03-27 10:51:29,209: ============================================================
2022-03-27 10:51:29,209: Epoch 24/38 Batch 2500/7662 eta: 20:32:38.412109	Training Loss 1.7637 (1.7376)	Training Prec@1 100.000 (99.953)	Training Prec@5 100.000 (99.988)	
2022-03-27 10:51:29,209: ============================================================
2022-03-27 10:52:35,961: time cost, forward:0.01808730791788369, backward:0.04256437034871129, data cost:0.595372317524404 
2022-03-27 10:52:35,961: ============================================================
2022-03-27 10:52:35,962: Epoch 24/38 Batch 2600/7662 eta: 20:49:44.141050	Training Loss 1.7830 (1.7396)	Training Prec@1 100.000 (99.953)	Training Prec@5 100.000 (99.988)	
2022-03-27 10:52:35,962: ============================================================
2022-03-27 10:53:40,052: time cost, forward:0.018038238671674867, backward:0.04245332056789674, data cost:0.5949249617388267 
2022-03-27 10:53:40,052: ============================================================
2022-03-27 10:53:40,052: Epoch 24/38 Batch 2700/7662 eta: 19:58:49.742055	Training Loss 1.7427 (1.7409)	Training Prec@1 100.000 (99.953)	Training Prec@5 100.000 (99.988)	
2022-03-27 10:53:40,053: ============================================================
2022-03-27 10:54:47,957: time cost, forward:0.018073700972649404, backward:0.042576916177769396, data cost:0.5955610380891648 
2022-03-27 10:54:47,958: ============================================================
2022-03-27 10:54:47,958: Epoch 24/38 Batch 2800/7662 eta: 21:09:03.210504	Training Loss 1.7847 (1.7427)	Training Prec@1 100.000 (99.954)	Training Prec@5 100.000 (99.988)	
2022-03-27 10:54:47,958: ============================================================
2022-03-27 10:55:50,845: time cost, forward:0.018027833183291205, backward:0.042615570171654904, data cost:0.5945843828674348 
2022-03-27 10:55:50,845: ============================================================
2022-03-27 10:55:50,845: Epoch 24/38 Batch 2900/7662 eta: 19:34:13.356018	Training Loss 1.8418 (1.7438)	Training Prec@1 99.805 (99.954)	Training Prec@5 100.000 (99.988)	
2022-03-27 10:55:50,846: ============================================================
2022-03-27 10:56:56,888: time cost, forward:0.018054482220569903, backward:0.042657298777810174, data cost:0.5946395617399505 
2022-03-27 10:56:56,888: ============================================================
2022-03-27 10:56:56,888: Epoch 24/38 Batch 3000/7662 eta: 20:32:02.600185	Training Loss 1.9234 (1.7454)	Training Prec@1 100.000 (99.953)	Training Prec@5 100.000 (99.988)	
2022-03-27 10:56:56,889: ============================================================
2022-03-27 10:58:03,537: time cost, forward:0.018091479437164278, backward:0.042727909460495504, data cost:0.5948640514704904 
2022-03-27 10:58:03,537: ============================================================
2022-03-27 10:58:03,538: Epoch 24/38 Batch 3100/7662 eta: 20:42:14.439881	Training Loss 1.8183 (1.7476)	Training Prec@1 100.000 (99.952)	Training Prec@5 100.000 (99.988)	
2022-03-27 10:58:03,538: ============================================================
2022-03-27 10:59:06,654: time cost, forward:0.018132156414999073, backward:0.04263887736304695, data cost:0.5940855013724229 
2022-03-27 10:59:06,654: ============================================================
2022-03-27 10:59:06,655: Epoch 24/38 Batch 3200/7662 eta: 19:35:21.267373	Training Loss 1.8701 (1.7491)	Training Prec@1 99.805 (99.952)	Training Prec@5 100.000 (99.988)	
2022-03-27 10:59:06,655: ============================================================
2022-03-27 11:00:11,708: time cost, forward:0.018132822554774195, backward:0.042617818520769415, data cost:0.5939177858283861 
2022-03-27 11:00:11,709: ============================================================
2022-03-27 11:00:11,709: Epoch 24/38 Batch 3300/7662 eta: 20:10:20.830385	Training Loss 1.8480 (1.7507)	Training Prec@1 100.000 (99.951)	Training Prec@5 100.000 (99.988)	
2022-03-27 11:00:11,709: ============================================================
2022-03-27 11:01:18,987: time cost, forward:0.018175611709208655, backward:0.04270255716452356, data cost:0.5943068306247569 
2022-03-27 11:01:18,987: ============================================================
2022-03-27 11:01:18,988: Epoch 24/38 Batch 3400/7662 eta: 20:50:36.532037	Training Loss 1.7824 (1.7527)	Training Prec@1 100.000 (99.951)	Training Prec@5 100.000 (99.988)	
2022-03-27 11:01:18,988: ============================================================
2022-03-27 11:02:25,584: time cost, forward:0.0181712903237813, backward:0.04264464082633403, data cost:0.5946160752148449 
2022-03-27 11:02:25,584: ============================================================
2022-03-27 11:02:25,584: Epoch 24/38 Batch 3500/7662 eta: 20:36:49.401402	Training Loss 1.8301 (1.7541)	Training Prec@1 99.805 (99.950)	Training Prec@5 100.000 (99.987)	
2022-03-27 11:02:25,584: ============================================================
2022-03-27 11:03:30,062: time cost, forward:0.01815251609821325, backward:0.04259784839722341, data cost:0.5943665737640729 
2022-03-27 11:03:30,063: ============================================================
2022-03-27 11:03:30,063: Epoch 24/38 Batch 3600/7662 eta: 19:56:24.883868	Training Loss 1.9677 (1.7550)	Training Prec@1 99.805 (99.950)	Training Prec@5 100.000 (99.987)	
2022-03-27 11:03:30,063: ============================================================
2022-03-27 11:04:35,505: time cost, forward:0.0181931439332944, backward:0.042616208974462354, data cost:0.5942364966879022 
2022-03-27 11:04:35,508: ============================================================
2022-03-27 11:04:35,509: Epoch 24/38 Batch 3700/7662 eta: 20:13:15.547415	Training Loss 1.7579 (1.7563)	Training Prec@1 99.805 (99.949)	Training Prec@5 100.000 (99.987)	
2022-03-27 11:04:35,509: ============================================================
2022-03-27 11:05:41,274: time cost, forward:0.018210079331685444, backward:0.04259080785172461, data cost:0.5940988221335455 
2022-03-27 11:05:41,274: ============================================================
2022-03-27 11:05:41,275: Epoch 24/38 Batch 3800/7662 eta: 20:18:06.370838	Training Loss 1.8259 (1.7578)	Training Prec@1 100.000 (99.949)	Training Prec@5 100.000 (99.987)	
2022-03-27 11:05:41,276: ============================================================
2022-03-27 11:06:49,193: time cost, forward:0.018269581438853637, backward:0.042840498720997267, data cost:0.5945428226751742 
2022-03-27 11:06:49,194: ============================================================
2022-03-27 11:06:49,194: Epoch 24/38 Batch 3900/7662 eta: 20:56:51.487336	Training Loss 1.7188 (1.7594)	Training Prec@1 100.000 (99.949)	Training Prec@5 100.000 (99.987)	
2022-03-27 11:06:49,194: ============================================================
2022-03-27 11:07:56,603: time cost, forward:0.018292894837974936, backward:0.04291979161820789, data cost:0.5948613271858728 
2022-03-27 11:07:56,604: ============================================================
2022-03-27 11:07:56,604: Epoch 24/38 Batch 4000/7662 eta: 20:46:18.419515	Training Loss 1.7673 (1.7613)	Training Prec@1 100.000 (99.949)	Training Prec@5 100.000 (99.987)	
2022-03-27 11:07:56,604: ============================================================
2022-03-27 11:09:02,789: time cost, forward:0.01832569154421566, backward:0.04296453175355121, data cost:0.5949045958010619 
2022-03-27 11:09:02,790: ============================================================
2022-03-27 11:09:02,790: Epoch 24/38 Batch 4100/7662 eta: 20:22:34.883499	Training Loss 1.7524 (1.7626)	Training Prec@1 100.000 (99.948)	Training Prec@5 100.000 (99.987)	
2022-03-27 11:09:02,790: ============================================================
2022-03-27 11:10:10,072: time cost, forward:0.018380872690555567, backward:0.043054330970707835, data cost:0.5948944885579142 
2022-03-27 11:10:10,075: ============================================================
2022-03-27 11:10:10,077: Epoch 24/38 Batch 4200/7662 eta: 20:41:46.497107	Training Loss 1.7945 (1.7638)	Training Prec@1 99.805 (99.948)	Training Prec@5 100.000 (99.987)	
2022-03-27 11:10:10,078: ============================================================
2022-03-27 11:11:16,277: time cost, forward:0.01839873501799167, backward:0.04310153911046634, data cost:0.5951461087661889 
2022-03-27 11:11:16,278: ============================================================
2022-03-27 11:11:16,278: Epoch 24/38 Batch 4300/7662 eta: 20:20:39.614566	Training Loss 1.9400 (1.7652)	Training Prec@1 99.805 (99.948)	Training Prec@5 100.000 (99.987)	
2022-03-27 11:11:16,278: ============================================================
2022-03-27 11:12:22,652: time cost, forward:0.01844020929356059, backward:0.04310872278909408, data cost:0.5952032764111359 
2022-03-27 11:12:22,652: ============================================================
2022-03-27 11:12:22,652: Epoch 24/38 Batch 4400/7662 eta: 20:22:44.422616	Training Loss 1.8220 (1.7662)	Training Prec@1 100.000 (99.948)	Training Prec@5 100.000 (99.986)	
2022-03-27 11:12:22,653: ============================================================
2022-03-27 11:13:30,568: time cost, forward:0.018448625519212603, backward:0.043126290574235955, data cost:0.5955525987756123 
2022-03-27 11:13:30,569: ============================================================
2022-03-27 11:13:30,569: Epoch 24/38 Batch 4500/7662 eta: 20:50:01.365724	Training Loss 1.8707 (1.7675)	Training Prec@1 100.000 (99.948)	Training Prec@5 100.000 (99.986)	
2022-03-27 11:13:30,570: ============================================================
2022-03-27 11:14:33,769: time cost, forward:0.01843117298989691, backward:0.043159668900236196, data cost:0.5948713504379017 
2022-03-27 11:14:33,774: ============================================================
2022-03-27 11:14:33,776: Epoch 24/38 Batch 4600/7662 eta: 19:22:15.282177	Training Loss 1.7811 (1.7685)	Training Prec@1 100.000 (99.948)	Training Prec@5 100.000 (99.986)	
2022-03-27 11:14:33,776: ============================================================
2022-03-27 11:15:39,599: time cost, forward:0.01845625015643587, backward:0.04317227696631659, data cost:0.5949067550406707 
2022-03-27 11:15:39,601: ============================================================
2022-03-27 11:15:39,602: Epoch 24/38 Batch 4700/7662 eta: 20:09:21.579974	Training Loss 1.7203 (1.7698)	Training Prec@1 100.000 (99.948)	Training Prec@5 100.000 (99.986)	
2022-03-27 11:15:39,603: ============================================================
2022-03-27 11:16:47,669: time cost, forward:0.018532994489516782, backward:0.04325706711856741, data cost:0.5953276583144356 
2022-03-27 11:16:47,670: ============================================================
2022-03-27 11:16:47,670: Epoch 24/38 Batch 4800/7662 eta: 20:49:24.225962	Training Loss 1.8895 (1.7712)	Training Prec@1 99.609 (99.948)	Training Prec@5 99.805 (99.986)	
2022-03-27 11:16:47,670: ============================================================
2022-03-27 11:17:51,357: time cost, forward:0.01853464267331256, backward:0.043260103392343076, data cost:0.594900902886127 
2022-03-27 11:17:51,357: ============================================================
2022-03-27 11:17:51,358: Epoch 24/38 Batch 4900/7662 eta: 19:27:55.913375	Training Loss 2.0353 (1.7723)	Training Prec@1 100.000 (99.948)	Training Prec@5 100.000 (99.986)	
2022-03-27 11:17:51,358: ============================================================
2022-03-27 11:18:56,239: time cost, forward:0.018544613921563608, backward:0.04325332572923276, data cost:0.5946947020706022 
2022-03-27 11:18:56,241: ============================================================
2022-03-27 11:18:56,241: Epoch 24/38 Batch 5000/7662 eta: 19:48:47.080232	Training Loss 1.8136 (1.7736)	Training Prec@1 100.000 (99.948)	Training Prec@5 100.000 (99.986)	
2022-03-27 11:18:56,242: ============================================================
2022-03-27 11:20:04,538: time cost, forward:0.018575645797648695, backward:0.043263391972429774, data cost:0.595144731293802 
2022-03-27 11:20:04,539: ============================================================
2022-03-27 11:20:04,540: Epoch 24/38 Batch 5100/7662 eta: 20:50:12.611635	Training Loss 1.6724 (1.7749)	Training Prec@1 100.000 (99.948)	Training Prec@5 100.000 (99.987)	
2022-03-27 11:20:04,540: ============================================================
2022-03-27 11:21:09,002: time cost, forward:0.018566033546226164, backward:0.04324528285461473, data cost:0.5948222735955822 
2022-03-27 11:21:09,005: ============================================================
2022-03-27 11:21:09,006: Epoch 24/38 Batch 5200/7662 eta: 19:38:59.816788	Training Loss 1.8674 (1.7762)	Training Prec@1 99.414 (99.947)	Training Prec@5 100.000 (99.986)	
2022-03-27 11:21:09,007: ============================================================
2022-03-27 11:22:12,857: time cost, forward:0.018557671309192354, backward:0.043263492864985625, data cost:0.5945386625636544 
2022-03-27 11:22:12,858: ============================================================
2022-03-27 11:22:12,858: Epoch 24/38 Batch 5300/7662 eta: 19:26:41.597096	Training Loss 1.6932 (1.7775)	Training Prec@1 99.805 (99.947)	Training Prec@5 100.000 (99.986)	
2022-03-27 11:22:12,858: ============================================================
2022-03-27 11:23:19,192: time cost, forward:0.018565531946328154, backward:0.043273619179991486, data cost:0.594624018178955 
2022-03-27 11:23:19,193: ============================================================
2022-03-27 11:23:19,193: Epoch 24/38 Batch 5400/7662 eta: 20:10:57.623136	Training Loss 1.8044 (1.7790)	Training Prec@1 100.000 (99.946)	Training Prec@5 100.000 (99.986)	
2022-03-27 11:23:19,193: ============================================================
2022-03-27 11:24:26,851: time cost, forward:0.018603313357250368, backward:0.04331902751794271, data cost:0.5948425540709023 
2022-03-27 11:24:26,854: ============================================================
2022-03-27 11:24:26,856: Epoch 24/38 Batch 5500/7662 eta: 20:34:02.898941	Training Loss 1.9525 (1.7803)	Training Prec@1 100.000 (99.946)	Training Prec@5 100.000 (99.986)	
2022-03-27 11:24:26,856: ============================================================
2022-03-27 11:25:29,509: time cost, forward:0.018589609455777017, backward:0.04327954469269611, data cost:0.5942293503685154 
2022-03-27 11:25:29,511: ============================================================
2022-03-27 11:25:29,512: Epoch 24/38 Batch 5600/7662 eta: 19:01:42.782887	Training Loss 1.9163 (1.7818)	Training Prec@1 99.805 (99.946)	Training Prec@5 100.000 (99.986)	
2022-03-27 11:25:29,513: ============================================================
2022-03-27 11:26:34,214: time cost, forward:0.018584912650353825, backward:0.0432877524691018, data cost:0.5941731323587579 
2022-03-27 11:26:34,215: ============================================================
2022-03-27 11:26:34,215: Epoch 24/38 Batch 5700/7662 eta: 19:37:56.665292	Training Loss 1.6909 (1.7830)	Training Prec@1 100.000 (99.946)	Training Prec@5 100.000 (99.986)	
2022-03-27 11:26:34,216: ============================================================
2022-03-27 11:27:41,751: time cost, forward:0.018642272223972373, backward:0.043325985396888915, data cost:0.5943812909136972 
2022-03-27 11:27:41,752: ============================================================
2022-03-27 11:27:41,752: Epoch 24/38 Batch 5800/7662 eta: 20:28:23.455533	Training Loss 1.7874 (1.7841)	Training Prec@1 100.000 (99.946)	Training Prec@5 100.000 (99.986)	
2022-03-27 11:27:41,752: ============================================================
2022-03-27 11:28:46,957: time cost, forward:0.018647390980905627, backward:0.04338487856952714, data cost:0.594223198637677 
2022-03-27 11:28:46,958: ============================================================
2022-03-27 11:28:46,958: Epoch 24/38 Batch 5900/7662 eta: 19:44:54.780993	Training Loss 1.7050 (1.7854)	Training Prec@1 100.000 (99.945)	Training Prec@5 100.000 (99.986)	
2022-03-27 11:28:46,958: ============================================================
2022-03-27 11:29:50,959: time cost, forward:0.018655677460932617, backward:0.04337175970654584, data cost:0.5939206626737569 
2022-03-27 11:29:50,960: ============================================================
2022-03-27 11:29:50,960: Epoch 24/38 Batch 6000/7662 eta: 19:21:57.899514	Training Loss 1.8730 (1.7866)	Training Prec@1 99.609 (99.945)	Training Prec@5 99.805 (99.986)	
2022-03-27 11:29:50,960: ============================================================
2022-03-27 11:30:57,069: time cost, forward:0.01869301910106423, backward:0.04345061239951516, data cost:0.5938506242114416 
2022-03-27 11:30:57,073: ============================================================
2022-03-27 11:30:57,073: Epoch 24/38 Batch 6100/7662 eta: 19:59:11.770546	Training Loss 2.0243 (1.7880)	Training Prec@1 99.609 (99.944)	Training Prec@5 100.000 (99.986)	
2022-03-27 11:30:57,073: ============================================================
2022-03-27 11:31:59,295: time cost, forward:0.018679363532573257, backward:0.04342939500213342, data cost:0.5933368982547982 
2022-03-27 11:31:59,295: ============================================================
2022-03-27 11:31:59,296: Epoch 24/38 Batch 6200/7662 eta: 18:47:34.989990	Training Loss 1.7845 (1.7892)	Training Prec@1 100.000 (99.944)	Training Prec@5 100.000 (99.986)	
2022-03-27 11:31:59,296: ============================================================
2022-03-27 11:33:05,462: time cost, forward:0.018672511357696382, backward:0.04342225109287473, data cost:0.5933094477346916 
2022-03-27 11:33:05,462: ============================================================
2022-03-27 11:33:05,463: Epoch 24/38 Batch 6300/7662 eta: 19:57:58.160539	Training Loss 1.9053 (1.7903)	Training Prec@1 99.805 (99.944)	Training Prec@5 100.000 (99.986)	
2022-03-27 11:33:05,463: ============================================================
2022-03-27 11:34:11,599: time cost, forward:0.018674847669462837, backward:0.04342423127691976, data cost:0.5934458505475795 
2022-03-27 11:34:11,600: ============================================================
2022-03-27 11:34:11,601: Epoch 24/38 Batch 6400/7662 eta: 19:56:20.181817	Training Loss 1.9438 (1.7915)	Training Prec@1 100.000 (99.944)	Training Prec@5 100.000 (99.986)	
2022-03-27 11:34:11,602: ============================================================
2022-03-27 11:35:18,331: time cost, forward:0.018683065908067793, backward:0.043421277010838866, data cost:0.5936438667533911 
2022-03-27 11:35:18,331: ============================================================
2022-03-27 11:35:18,331: Epoch 24/38 Batch 6500/7662 eta: 20:05:56.535252	Training Loss 1.7577 (1.7928)	Training Prec@1 99.609 (99.943)	Training Prec@5 100.000 (99.985)	
2022-03-27 11:35:18,331: ============================================================
2022-03-27 11:36:23,272: time cost, forward:0.018684508421508123, backward:0.043418963292563104, data cost:0.5935361611154842 
2022-03-27 11:36:23,273: ============================================================
2022-03-27 11:36:23,273: Epoch 24/38 Batch 6600/7662 eta: 19:32:31.843721	Training Loss 1.7741 (1.7937)	Training Prec@1 99.805 (99.943)	Training Prec@5 99.805 (99.985)	
2022-03-27 11:36:23,273: ============================================================
2022-03-27 11:37:26,646: time cost, forward:0.018656588789419837, backward:0.043391608252313925, data cost:0.5931216100558075 
2022-03-27 11:37:26,648: ============================================================
2022-03-27 11:37:26,649: Epoch 24/38 Batch 6700/7662 eta: 19:03:12.433324	Training Loss 1.7774 (1.7948)	Training Prec@1 100.000 (99.943)	Training Prec@5 100.000 (99.985)	
2022-03-27 11:37:26,650: ============================================================
2022-03-27 11:38:33,423: time cost, forward:0.01869475166487999, backward:0.043436329896738644, data cost:0.5933037027924846 
2022-03-27 11:38:33,423: ============================================================
2022-03-27 11:38:33,423: Epoch 24/38 Batch 6800/7662 eta: 20:03:23.970830	Training Loss 1.7367 (1.7961)	Training Prec@1 100.000 (99.943)	Training Prec@5 100.000 (99.985)	
2022-03-27 11:38:33,424: ============================================================
2022-03-27 11:39:39,145: time cost, forward:0.018696603472292603, backward:0.04341747232374376, data cost:0.5933381063140878 
2022-03-27 11:39:39,145: ============================================================
2022-03-27 11:39:39,146: Epoch 24/38 Batch 6900/7662 eta: 19:43:20.376579	Training Loss 1.8954 (1.7972)	Training Prec@1 99.609 (99.942)	Training Prec@5 100.000 (99.985)	
2022-03-27 11:39:39,146: ============================================================
2022-03-27 11:40:45,595: time cost, forward:0.018687586798669952, backward:0.043408130846597205, data cost:0.5934672571962468 
2022-03-27 11:40:45,596: ============================================================
2022-03-27 11:40:45,596: Epoch 24/38 Batch 7000/7662 eta: 19:55:20.271525	Training Loss 1.8310 (1.7983)	Training Prec@1 100.000 (99.942)	Training Prec@5 100.000 (99.985)	
2022-03-27 11:40:45,596: ============================================================
2022-03-27 11:41:47,582: time cost, forward:0.018680935695920633, backward:0.04338888665927533, data cost:0.5929726185740207 
2022-03-27 11:41:47,584: ============================================================
2022-03-27 11:41:47,584: Epoch 24/38 Batch 7100/7662 eta: 18:34:02.582269	Training Loss 1.7933 (1.7993)	Training Prec@1 99.805 (99.942)	Training Prec@5 99.805 (99.985)	
2022-03-27 11:41:47,584: ============================================================
2022-03-27 11:42:54,499: time cost, forward:0.018711520658795874, backward:0.043461054393791096, data cost:0.5929715860914995 
2022-03-27 11:42:54,500: ============================================================
2022-03-27 11:42:54,500: Epoch 24/38 Batch 7200/7662 eta: 20:01:29.308975	Training Loss 2.0554 (1.8003)	Training Prec@1 99.805 (99.942)	Training Prec@5 100.000 (99.985)	
2022-03-27 11:42:54,500: ============================================================
2022-03-27 11:43:59,438: time cost, forward:0.018695628517277355, backward:0.0434762222307286, data cost:0.5929555714595871 
2022-03-27 11:43:59,439: ============================================================
2022-03-27 11:43:59,439: Epoch 24/38 Batch 7300/7662 eta: 19:24:54.632261	Training Loss 1.9924 (1.8014)	Training Prec@1 100.000 (99.941)	Training Prec@5 100.000 (99.985)	
2022-03-27 11:43:59,439: ============================================================
2022-03-27 11:45:06,319: time cost, forward:0.018713827245315034, backward:0.04351724184982067, data cost:0.5929713372620945 
2022-03-27 11:45:06,321: ============================================================
2022-03-27 11:45:06,322: Epoch 24/38 Batch 7400/7662 eta: 19:58:39.026187	Training Loss 1.8431 (1.8022)	Training Prec@1 99.805 (99.941)	Training Prec@5 100.000 (99.985)	
2022-03-27 11:45:06,322: ============================================================
2022-03-27 11:46:13,479: time cost, forward:0.01871611093072704, backward:0.043529084466714704, data cost:0.5932387529269649 
2022-03-27 11:46:13,479: ============================================================
2022-03-27 11:46:13,480: Epoch 24/38 Batch 7500/7662 eta: 20:02:28.868025	Training Loss 1.9502 (1.8033)	Training Prec@1 100.000 (99.941)	Training Prec@5 100.000 (99.985)	
2022-03-27 11:46:13,480: ============================================================
2022-03-27 11:47:14,633: time cost, forward:0.018695460101274586, backward:0.04352417844332336, data cost:0.5926687587859019 
2022-03-27 11:47:14,634: ============================================================
2022-03-27 11:47:14,634: Epoch 24/38 Batch 7600/7662 eta: 18:13:57.247640	Training Loss 1.8030 (1.8045)	Training Prec@1 100.000 (99.941)	Training Prec@5 100.000 (99.985)	
2022-03-27 11:47:14,634: ============================================================
2022-03-27 11:47:58,086: Epoch: 24/38 eta: 18:13:18.720592	Training Loss 1.8051 (1.8052)	Training Prec@1 100.000 (99.940)	Training Prec@5 100.000 (99.985)
2022-03-27 11:47:58,086: ============================================================
2022-03-27 11:49:04,653: time cost, forward:0.017231575166336215, backward:0.04229891661441687, data cost:0.5995278840113167 
2022-03-27 11:49:04,655: ============================================================
2022-03-27 11:49:04,656: Epoch 25/38 Batch 100/7662 eta: 19:48:57.308343	Training Loss 1.6769 (1.6918)	Training Prec@1 100.000 (99.964)	Training Prec@5 100.000 (99.996)	
2022-03-27 11:49:04,657: ============================================================
2022-03-27 11:50:10,642: time cost, forward:0.01901589206714726, backward:0.04359036234755013, data cost:0.5973190865924011 
2022-03-27 11:50:10,644: ============================================================
2022-03-27 11:50:10,646: Epoch 25/38 Batch 200/7662 eta: 19:37:34.451223	Training Loss 1.6787 (1.6833)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.997)	
2022-03-27 11:50:10,646: ============================================================
2022-03-27 11:51:15,626: time cost, forward:0.01917690975610229, backward:0.043396357309858136, data cost:0.5951817761296812 
2022-03-27 11:51:15,626: ============================================================
2022-03-27 11:51:15,627: Epoch 25/38 Batch 300/7662 eta: 19:18:29.867068	Training Loss 1.6401 (1.6832)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.995)	
2022-03-27 11:51:15,627: ============================================================
2022-03-27 11:52:23,419: time cost, forward:0.019198752883681676, backward:0.04437703237796487, data cost:0.596744908426041 
2022-03-27 11:52:23,422: ============================================================
2022-03-27 11:52:23,423: Epoch 25/38 Batch 400/7662 eta: 20:07:32.943170	Training Loss 1.6426 (1.6850)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.995)	
2022-03-27 11:52:23,424: ============================================================
2022-03-27 11:53:26,802: time cost, forward:0.019096601941064748, backward:0.04361691073568646, data cost:0.59388333905436 
2022-03-27 11:53:26,803: ============================================================
2022-03-27 11:53:26,803: Epoch 25/38 Batch 500/7662 eta: 18:47:50.640597	Training Loss 1.7823 (1.6878)	Training Prec@1 100.000 (99.966)	Training Prec@5 100.000 (99.993)	
2022-03-27 11:53:26,803: ============================================================
2022-03-27 11:54:33,211: time cost, forward:0.018946507140272646, backward:0.04377780693003252, data cost:0.5933903935357605 
2022-03-27 11:54:33,214: ============================================================
2022-03-27 11:54:33,215: Epoch 25/38 Batch 600/7662 eta: 19:40:39.732162	Training Loss 1.7103 (1.6918)	Training Prec@1 100.000 (99.964)	Training Prec@5 100.000 (99.992)	
2022-03-27 11:54:33,215: ============================================================
2022-03-27 11:55:42,934: time cost, forward:0.01884210979478042, backward:0.04378308963366333, data cost:0.6002318381581013 
2022-03-27 11:55:42,934: ============================================================
2022-03-27 11:55:42,935: Epoch 25/38 Batch 700/7662 eta: 20:38:20.452087	Training Loss 1.6610 (1.6937)	Training Prec@1 99.805 (99.963)	Training Prec@5 99.805 (99.991)	
2022-03-27 11:55:42,935: ============================================================
2022-03-27 11:56:47,150: time cost, forward:0.018940678227678854, backward:0.04375542806594333, data cost:0.5976840500837572 
2022-03-27 11:56:47,150: ============================================================
2022-03-27 11:56:47,150: Epoch 25/38 Batch 800/7662 eta: 18:59:29.927006	Training Loss 1.6726 (1.6958)	Training Prec@1 100.000 (99.962)	Training Prec@5 100.000 (99.991)	
2022-03-27 11:56:47,151: ============================================================
2022-03-27 11:57:50,328: time cost, forward:0.018767038892718392, backward:0.0436569336921938, data cost:0.5945003830948979 
2022-03-27 11:57:50,329: ============================================================
2022-03-27 11:57:50,330: Epoch 25/38 Batch 900/7662 eta: 18:40:03.103973	Training Loss 1.7477 (1.6974)	Training Prec@1 100.000 (99.962)	Training Prec@5 100.000 (99.991)	
2022-03-27 11:57:50,330: ============================================================
2022-03-27 11:58:53,073: time cost, forward:0.018384664027659862, backward:0.04310922221736507, data cost:0.591918435301986 
2022-03-27 11:58:53,074: ============================================================
2022-03-27 11:58:53,075: Epoch 25/38 Batch 1000/7662 eta: 18:31:18.482408	Training Loss 1.8774 (1.7005)	Training Prec@1 100.000 (99.961)	Training Prec@5 100.000 (99.991)	
2022-03-27 11:58:53,075: ============================================================
2022-03-27 11:59:56,842: time cost, forward:0.018306527818952287, backward:0.04293085207605058, data cost:0.5910467444169076 
2022-03-27 11:59:56,843: ============================================================
2022-03-27 11:59:56,843: Epoch 25/38 Batch 1100/7662 eta: 18:48:22.270016	Training Loss 1.7840 (1.7029)	Training Prec@1 100.000 (99.960)	Training Prec@5 100.000 (99.990)	
2022-03-27 11:59:56,843: ============================================================
2022-03-27 12:01:02,869: time cost, forward:0.018334910310835915, backward:0.04301673974267039, data cost:0.5913794329009322 
2022-03-27 12:01:02,870: ============================================================
2022-03-27 12:01:02,871: Epoch 25/38 Batch 1200/7662 eta: 19:27:14.650720	Training Loss 1.8829 (1.7048)	Training Prec@1 99.805 (99.959)	Training Prec@5 100.000 (99.991)	
2022-03-27 12:01:02,871: ============================================================
2022-03-27 12:02:12,105: time cost, forward:0.01844531522520328, backward:0.04307297305752444, data cost:0.5942922411192556 
2022-03-27 12:02:12,105: ============================================================
2022-03-27 12:02:12,105: Epoch 25/38 Batch 1300/7662 eta: 20:22:47.461447	Training Loss 1.7948 (1.7061)	Training Prec@1 100.000 (99.960)	Training Prec@5 100.000 (99.990)	
2022-03-27 12:02:12,105: ============================================================
2022-03-27 12:03:14,581: time cost, forward:0.018185221526859658, backward:0.04291330123475997, data cost:0.5923723163904677 
2022-03-27 12:03:14,582: ============================================================
2022-03-27 12:03:14,583: Epoch 25/38 Batch 1400/7662 eta: 18:22:23.995736	Training Loss 1.7817 (1.7089)	Training Prec@1 100.000 (99.960)	Training Prec@5 100.000 (99.990)	
2022-03-27 12:03:14,583: ============================================================
2022-03-27 12:04:20,151: time cost, forward:0.018157482147216797, backward:0.042695324129864244, data cost:0.5926593003708812 
2022-03-27 12:04:20,152: ============================================================
2022-03-27 12:04:20,152: Epoch 25/38 Batch 1500/7662 eta: 19:15:52.347405	Training Loss 1.8971 (1.7106)	Training Prec@1 100.000 (99.959)	Training Prec@5 100.000 (99.990)	
2022-03-27 12:04:20,152: ============================================================
2022-03-27 12:05:25,862: time cost, forward:0.018033700857108797, backward:0.042712603158097925, data cost:0.592909253784237 
2022-03-27 12:05:25,863: ============================================================
2022-03-27 12:05:25,863: Epoch 25/38 Batch 1600/7662 eta: 19:17:16.124558	Training Loss 1.6911 (1.7130)	Training Prec@1 100.000 (99.959)	Training Prec@5 100.000 (99.989)	
2022-03-27 12:05:25,863: ============================================================
2022-03-27 12:06:32,060: time cost, forward:0.01801294800532152, backward:0.04245683261406569, data cost:0.5935960904930254 
2022-03-27 12:06:32,060: ============================================================
2022-03-27 12:06:32,060: Epoch 25/38 Batch 1700/7662 eta: 19:24:43.723390	Training Loss 1.8411 (1.7147)	Training Prec@1 100.000 (99.959)	Training Prec@5 100.000 (99.989)	
2022-03-27 12:06:32,061: ============================================================
2022-03-27 12:07:38,283: time cost, forward:0.01794017017252118, backward:0.04217826080958402, data cost:0.5943634573653912 
2022-03-27 12:07:38,283: ============================================================
2022-03-27 12:07:38,283: Epoch 25/38 Batch 1800/7662 eta: 19:24:04.543557	Training Loss 1.7900 (1.7163)	Training Prec@1 100.000 (99.958)	Training Prec@5 100.000 (99.988)	
2022-03-27 12:07:38,283: ============================================================
2022-03-27 12:08:45,100: time cost, forward:0.01797422878110704, backward:0.042254993951967225, data cost:0.5949099058851309 
2022-03-27 12:08:45,101: ============================================================
2022-03-27 12:08:45,101: Epoch 25/38 Batch 1900/7662 eta: 19:33:25.494427	Training Loss 1.7392 (1.7176)	Training Prec@1 99.805 (99.957)	Training Prec@5 99.805 (99.988)	
2022-03-27 12:08:45,101: ============================================================
2022-03-27 12:09:52,214: time cost, forward:0.017948693546907733, backward:0.04234273294140661, data cost:0.5953740831492482 
2022-03-27 12:09:52,214: ============================================================
2022-03-27 12:09:52,215: Epoch 25/38 Batch 2000/7662 eta: 19:37:29.506141	Training Loss 1.6203 (1.7199)	Training Prec@1 100.000 (99.956)	Training Prec@5 100.000 (99.988)	
2022-03-27 12:09:52,215: ============================================================
2022-03-27 12:10:59,481: time cost, forward:0.018025219582443637, backward:0.042464055238081305, data cost:0.5958113141034886 
2022-03-27 12:10:59,484: ============================================================
2022-03-27 12:10:59,486: Epoch 25/38 Batch 2100/7662 eta: 19:39:07.803106	Training Loss 1.6550 (1.7218)	Training Prec@1 100.000 (99.955)	Training Prec@5 100.000 (99.988)	
2022-03-27 12:10:59,487: ============================================================
2022-03-27 12:12:05,400: time cost, forward:0.01808045006925922, backward:0.0424738465899389, data cost:0.5960895028532825 
2022-03-27 12:12:05,400: ============================================================
2022-03-27 12:12:05,401: Epoch 25/38 Batch 2200/7662 eta: 19:14:16.677207	Training Loss 1.7475 (1.7233)	Training Prec@1 100.000 (99.955)	Training Prec@5 100.000 (99.988)	
2022-03-27 12:12:05,401: ============================================================
2022-03-27 12:13:13,093: time cost, forward:0.018077850238091536, backward:0.04253512167215036, data cost:0.5968313508575094 
2022-03-27 12:13:13,093: ============================================================
2022-03-27 12:13:13,094: Epoch 25/38 Batch 2300/7662 eta: 19:44:16.531610	Training Loss 1.6990 (1.7255)	Training Prec@1 100.000 (99.955)	Training Prec@5 100.000 (99.988)	
2022-03-27 12:13:13,094: ============================================================
2022-03-27 12:14:20,778: time cost, forward:0.01806110011979708, backward:0.04266171596506428, data cost:0.5971258285891369 
2022-03-27 12:14:20,779: ============================================================
2022-03-27 12:14:20,779: Epoch 25/38 Batch 2400/7662 eta: 19:43:01.181155	Training Loss 1.8051 (1.7277)	Training Prec@1 100.000 (99.955)	Training Prec@5 100.000 (99.989)	
2022-03-27 12:14:20,780: ============================================================
2022-03-27 12:15:25,311: time cost, forward:0.017965546890753373, backward:0.04252910852527657, data cost:0.5971249106789933 
2022-03-27 12:15:25,312: ============================================================
2022-03-27 12:15:25,312: Epoch 25/38 Batch 2500/7662 eta: 18:46:50.191839	Training Loss 1.7711 (1.7302)	Training Prec@1 100.000 (99.955)	Training Prec@5 100.000 (99.989)	
2022-03-27 12:15:25,312: ============================================================
2022-03-27 12:16:28,957: time cost, forward:0.017898522326009646, backward:0.04239798738847287, data cost:0.5964933450793523 
2022-03-27 12:16:28,957: ============================================================
2022-03-27 12:16:28,957: Epoch 25/38 Batch 2600/7662 eta: 18:30:17.342415	Training Loss 1.7477 (1.7319)	Training Prec@1 100.000 (99.956)	Training Prec@5 100.000 (99.989)	
2022-03-27 12:16:28,958: ============================================================
2022-03-27 12:17:36,820: time cost, forward:0.017968642177207242, backward:0.042518138090475, data cost:0.5970644995034646 
2022-03-27 12:17:36,821: ============================================================
2022-03-27 12:17:36,821: Epoch 25/38 Batch 2700/7662 eta: 19:42:43.997203	Training Loss 1.8170 (1.7341)	Training Prec@1 99.805 (99.955)	Training Prec@5 99.805 (99.989)	
2022-03-27 12:17:36,821: ============================================================
2022-03-27 12:18:41,307: time cost, forward:0.017936678348417237, backward:0.04241834950898536, data cost:0.596354611731717 
2022-03-27 12:18:41,309: ============================================================
2022-03-27 12:18:41,309: Epoch 25/38 Batch 2800/7662 eta: 18:42:49.947461	Training Loss 1.8773 (1.7355)	Training Prec@1 100.000 (99.955)	Training Prec@5 100.000 (99.989)	
2022-03-27 12:18:41,309: ============================================================
2022-03-27 12:19:45,434: time cost, forward:0.017935545619663266, backward:0.04246095510629507, data cost:0.5959936706474543 
2022-03-27 12:19:45,434: ============================================================
2022-03-27 12:19:45,434: Epoch 25/38 Batch 2900/7662 eta: 18:35:27.176650	Training Loss 1.8970 (1.7373)	Training Prec@1 100.000 (99.955)	Training Prec@5 100.000 (99.989)	
2022-03-27 12:19:45,435: ============================================================
2022-03-27 12:20:49,096: time cost, forward:0.017888398677677105, backward:0.04241855759030781, data cost:0.595426915684872 
2022-03-27 12:20:49,097: ============================================================
2022-03-27 12:20:49,098: Epoch 25/38 Batch 3000/7662 eta: 18:26:20.976685	Training Loss 1.7503 (1.7387)	Training Prec@1 100.000 (99.955)	Training Prec@5 100.000 (99.989)	
2022-03-27 12:20:49,098: ============================================================
2022-03-27 12:21:59,247: time cost, forward:0.01797657960766783, backward:0.04257292861359933, data cost:0.5965246502604551 
2022-03-27 12:21:59,247: ============================================================
2022-03-27 12:21:59,248: Epoch 25/38 Batch 3100/7662 eta: 20:17:54.636551	Training Loss 1.9384 (1.7406)	Training Prec@1 99.805 (99.955)	Training Prec@5 100.000 (99.989)	
2022-03-27 12:21:59,248: ============================================================
2022-03-27 12:23:01,913: time cost, forward:0.01791069126755195, backward:0.04238632232854425, data cost:0.5958371999376303 
2022-03-27 12:23:01,914: ============================================================
2022-03-27 12:23:01,914: Epoch 25/38 Batch 3200/7662 eta: 18:06:56.092064	Training Loss 1.8371 (1.7425)	Training Prec@1 100.000 (99.955)	Training Prec@5 100.000 (99.989)	
2022-03-27 12:23:01,914: ============================================================
2022-03-27 12:24:04,154: time cost, forward:0.017866445765707773, backward:0.04231476183911821, data cost:0.594871664379683 
2022-03-27 12:24:04,155: ============================================================
2022-03-27 12:24:04,155: Epoch 25/38 Batch 3300/7662 eta: 17:58:31.536093	Training Loss 1.7210 (1.7438)	Training Prec@1 100.000 (99.954)	Training Prec@5 100.000 (99.988)	
2022-03-27 12:24:04,155: ============================================================
2022-03-27 12:25:08,661: time cost, forward:0.01782518774314851, backward:0.04230552548764558, data cost:0.5944637341091092 
2022-03-27 12:25:08,662: ============================================================
2022-03-27 12:25:08,663: Epoch 25/38 Batch 3400/7662 eta: 18:36:43.550673	Training Loss 1.7202 (1.7456)	Training Prec@1 100.000 (99.954)	Training Prec@5 100.000 (99.988)	
2022-03-27 12:25:08,663: ============================================================
2022-03-27 12:26:14,946: time cost, forward:0.017889396978739706, backward:0.042362199370675035, data cost:0.5947009930443035 
2022-03-27 12:26:14,946: ============================================================
2022-03-27 12:26:14,946: Epoch 25/38 Batch 3500/7662 eta: 19:06:21.810177	Training Loss 1.9440 (1.7471)	Training Prec@1 99.805 (99.953)	Training Prec@5 99.805 (99.988)	
2022-03-27 12:26:14,947: ============================================================
2022-03-27 12:27:20,336: time cost, forward:0.017915893906055143, backward:0.04238031983011197, data cost:0.5946017227162252 
2022-03-27 12:27:20,337: ============================================================
2022-03-27 12:27:20,337: Epoch 25/38 Batch 3600/7662 eta: 18:49:49.704952	Training Loss 1.7357 (1.7491)	Training Prec@1 100.000 (99.953)	Training Prec@5 100.000 (99.988)	
2022-03-27 12:27:20,337: ============================================================
2022-03-27 12:28:26,613: time cost, forward:0.017928368209277852, backward:0.04246056779199885, data cost:0.5946733733711129 
2022-03-27 12:28:26,613: ============================================================
2022-03-27 12:28:26,613: Epoch 25/38 Batch 3700/7662 eta: 19:04:01.786289	Training Loss 1.7511 (1.7507)	Training Prec@1 99.805 (99.953)	Training Prec@5 100.000 (99.988)	
2022-03-27 12:28:26,613: ============================================================
2022-03-27 12:29:30,458: time cost, forward:0.017907755222405907, backward:0.04238237045601375, data cost:0.5943006888035882 
2022-03-27 12:29:30,459: ============================================================
2022-03-27 12:29:30,459: Epoch 25/38 Batch 3800/7662 eta: 18:21:00.351205	Training Loss 1.8254 (1.7521)	Training Prec@1 100.000 (99.952)	Training Prec@5 100.000 (99.988)	
2022-03-27 12:29:30,459: ============================================================
2022-03-27 12:30:37,641: time cost, forward:0.017951382952306357, backward:0.042468444479829566, data cost:0.5945612522050887 
2022-03-27 12:30:37,641: ============================================================
2022-03-27 12:30:37,642: Epoch 25/38 Batch 3900/7662 eta: 19:17:26.042936	Training Loss 1.6958 (1.7542)	Training Prec@1 99.805 (99.952)	Training Prec@5 100.000 (99.988)	
2022-03-27 12:30:37,642: ============================================================
2022-03-27 12:31:43,172: time cost, forward:0.017952776277145765, backward:0.042426053987022753, data cost:0.5945947935176391 
2022-03-27 12:31:43,172: ============================================================
2022-03-27 12:31:43,172: Epoch 25/38 Batch 4000/7662 eta: 18:47:53.064251	Training Loss 1.7302 (1.7556)	Training Prec@1 100.000 (99.952)	Training Prec@5 100.000 (99.988)	
2022-03-27 12:31:43,173: ============================================================
2022-03-27 12:32:48,010: time cost, forward:0.017956738473148163, backward:0.042404409966023265, data cost:0.5944077306097384 
2022-03-27 12:32:48,011: ============================================================
2022-03-27 12:32:48,011: Epoch 25/38 Batch 4100/7662 eta: 18:34:53.206015	Training Loss 1.7634 (1.7573)	Training Prec@1 100.000 (99.952)	Training Prec@5 100.000 (99.988)	
2022-03-27 12:32:48,011: ============================================================
2022-03-27 12:33:56,337: time cost, forward:0.01796194132409456, backward:0.04239901805894947, data cost:0.5950296377675764 
2022-03-27 12:33:56,338: ============================================================
2022-03-27 12:33:56,338: Epoch 25/38 Batch 4200/7662 eta: 19:33:44.159245	Training Loss 1.8031 (1.7588)	Training Prec@1 100.000 (99.952)	Training Prec@5 100.000 (99.988)	
2022-03-27 12:33:56,338: ============================================================
2022-03-27 12:35:05,717: time cost, forward:0.01795977097551444, backward:0.042446569610013606, data cost:0.5957158322277721 
2022-03-27 12:35:05,718: ============================================================
2022-03-27 12:35:05,719: Epoch 25/38 Batch 4300/7662 eta: 19:50:40.484948	Training Loss 1.9767 (1.7602)	Training Prec@1 100.000 (99.951)	Training Prec@5 100.000 (99.988)	
2022-03-27 12:35:05,719: ============================================================
2022-03-27 12:36:09,149: time cost, forward:0.01793321763203615, backward:0.04238558541809762, data cost:0.5954287167055061 
2022-03-27 12:36:09,150: ============================================================
2022-03-27 12:36:09,150: Epoch 25/38 Batch 4400/7662 eta: 18:07:30.892775	Training Loss 1.6698 (1.7614)	Training Prec@1 100.000 (99.951)	Training Prec@5 100.000 (99.988)	
2022-03-27 12:36:09,150: ============================================================
2022-03-27 12:37:14,790: time cost, forward:0.017942356358477476, backward:0.042370169765288415, data cost:0.5954068696453826 
2022-03-27 12:37:14,790: ============================================================
2022-03-27 12:37:14,791: Epoch 25/38 Batch 4500/7662 eta: 18:44:18.358713	Training Loss 1.8401 (1.7628)	Training Prec@1 100.000 (99.951)	Training Prec@5 100.000 (99.987)	
2022-03-27 12:37:14,791: ============================================================
2022-03-27 12:38:17,019: time cost, forward:0.01791436761896308, backward:0.042328199321069154, data cost:0.5947331898521926 
2022-03-27 12:38:17,019: ============================================================
2022-03-27 12:38:17,019: Epoch 25/38 Batch 4600/7662 eta: 17:44:49.527379	Training Loss 1.8140 (1.7647)	Training Prec@1 100.000 (99.951)	Training Prec@5 100.000 (99.987)	
2022-03-27 12:38:17,019: ============================================================
2022-03-27 12:39:23,939: time cost, forward:0.017928134382823903, backward:0.04231677427776927, data cost:0.5950002117749604 
2022-03-27 12:39:23,940: ============================================================
2022-03-27 12:39:23,940: Epoch 25/38 Batch 4700/7662 eta: 19:04:00.152808	Training Loss 1.9761 (1.7662)	Training Prec@1 100.000 (99.951)	Training Prec@5 100.000 (99.987)	
2022-03-27 12:39:23,940: ============================================================
2022-03-27 12:40:31,261: time cost, forward:0.017913164856980857, backward:0.042363605441637746, data cost:0.5953270346702548 
2022-03-27 12:40:31,261: ============================================================
2022-03-27 12:40:31,261: Epoch 25/38 Batch 4800/7662 eta: 19:09:43.515942	Training Loss 1.8540 (1.7678)	Training Prec@1 100.000 (99.951)	Training Prec@5 100.000 (99.987)	
2022-03-27 12:40:31,262: ============================================================
2022-03-27 12:41:36,853: time cost, forward:0.017915949331884312, backward:0.04233264241760715, data cost:0.5952365133173004 
2022-03-27 12:41:36,855: ============================================================
2022-03-27 12:41:36,856: Epoch 25/38 Batch 4900/7662 eta: 18:39:07.565138	Training Loss 1.8489 (1.7692)	Training Prec@1 99.805 (99.950)	Training Prec@5 99.805 (99.987)	
2022-03-27 12:41:36,856: ============================================================
2022-03-27 12:42:45,236: time cost, forward:0.01796291765868127, backward:0.04241799568982095, data cost:0.5955729844165244 
2022-03-27 12:42:45,236: ============================================================
2022-03-27 12:42:45,237: Epoch 25/38 Batch 5000/7662 eta: 19:25:33.207177	Training Loss 1.7851 (1.7704)	Training Prec@1 99.805 (99.950)	Training Prec@5 100.000 (99.987)	
2022-03-27 12:42:45,238: ============================================================
2022-03-27 12:43:48,321: time cost, forward:0.017991752385111224, backward:0.0425101935010163, data cost:0.5949735830381445 
2022-03-27 12:43:48,324: ============================================================
2022-03-27 12:43:48,325: Epoch 25/38 Batch 5100/7662 eta: 17:54:16.195601	Training Loss 1.8887 (1.7715)	Training Prec@1 99.609 (99.950)	Training Prec@5 99.805 (99.987)	
2022-03-27 12:43:48,326: ============================================================
2022-03-27 12:44:58,448: time cost, forward:0.01803166895193374, backward:0.04252408967382244, data cost:0.5957348240318379 
2022-03-27 12:44:58,449: ============================================================
2022-03-27 12:44:58,450: Epoch 25/38 Batch 5200/7662 eta: 19:52:55.855344	Training Loss 1.7426 (1.7730)	Training Prec@1 100.000 (99.949)	Training Prec@5 100.000 (99.987)	
2022-03-27 12:44:58,451: ============================================================
2022-03-27 12:46:02,647: time cost, forward:0.018003970547697864, backward:0.04247206592361845, data cost:0.5956085323500034 
2022-03-27 12:46:02,647: ============================================================
2022-03-27 12:46:02,648: Epoch 25/38 Batch 5300/7662 eta: 18:11:02.001199	Training Loss 1.8387 (1.7744)	Training Prec@1 100.000 (99.949)	Training Prec@5 100.000 (99.987)	
2022-03-27 12:46:02,648: ============================================================
2022-03-27 12:47:04,836: time cost, forward:0.01797921318856847, backward:0.042490701936840854, data cost:0.5950099852686128 
2022-03-27 12:47:04,836: ============================================================
2022-03-27 12:47:04,837: Epoch 25/38 Batch 5400/7662 eta: 17:35:51.121643	Training Loss 1.8142 (1.7755)	Training Prec@1 99.805 (99.949)	Training Prec@5 99.805 (99.986)	
2022-03-27 12:47:04,837: ============================================================
2022-03-27 12:48:08,751: time cost, forward:0.017963411591663904, backward:0.04249357626554771, data cost:0.5947002617526779 
2022-03-27 12:48:08,751: ============================================================
2022-03-27 12:48:08,752: Epoch 25/38 Batch 5500/7662 eta: 18:04:05.591770	Training Loss 1.6722 (1.7770)	Training Prec@1 100.000 (99.949)	Training Prec@5 100.000 (99.986)	
2022-03-27 12:48:08,752: ============================================================
2022-03-27 12:49:18,345: time cost, forward:0.01799578380533618, backward:0.04254949137576458, data cost:0.5953218437429197 
2022-03-27 12:49:18,346: ============================================================
2022-03-27 12:49:18,346: Epoch 25/38 Batch 5600/7662 eta: 19:39:16.123655	Training Loss 1.8035 (1.7784)	Training Prec@1 100.000 (99.949)	Training Prec@5 100.000 (99.986)	
2022-03-27 12:49:18,346: ============================================================
2022-03-27 12:50:22,542: time cost, forward:0.01796452115138051, backward:0.042511275367248184, data cost:0.5951160690118857 
2022-03-27 12:50:22,543: ============================================================
2022-03-27 12:50:22,543: Epoch 25/38 Batch 5700/7662 eta: 18:06:44.306412	Training Loss 1.7997 (1.7797)	Training Prec@1 100.000 (99.949)	Training Prec@5 100.000 (99.986)	
2022-03-27 12:50:22,543: ============================================================
2022-03-27 12:51:29,341: time cost, forward:0.017973913984435205, backward:0.04257271770445062, data cost:0.5952208091070126 
2022-03-27 12:51:29,342: ============================================================
2022-03-27 12:51:29,343: Epoch 25/38 Batch 5800/7662 eta: 18:49:40.442567	Training Loss 1.8675 (1.7809)	Training Prec@1 100.000 (99.949)	Training Prec@5 100.000 (99.986)	
2022-03-27 12:51:29,343: ============================================================
2022-03-27 12:52:36,267: time cost, forward:0.017977162243289692, backward:0.042607964732158304, data cost:0.595266537618629 
2022-03-27 12:52:36,267: ============================================================
2022-03-27 12:52:36,267: Epoch 25/38 Batch 5900/7662 eta: 18:50:41.178550	Training Loss 1.7777 (1.7821)	Training Prec@1 99.805 (99.948)	Training Prec@5 100.000 (99.986)	
2022-03-27 12:52:36,268: ============================================================
2022-03-27 12:53:41,024: time cost, forward:0.017953807502056007, backward:0.042587642253170535, data cost:0.5952804295256409 
2022-03-27 12:53:41,025: ============================================================
2022-03-27 12:53:41,025: Epoch 25/38 Batch 6000/7662 eta: 18:12:59.625599	Training Loss 1.9582 (1.7832)	Training Prec@1 100.000 (99.948)	Training Prec@5 100.000 (99.986)	
2022-03-27 12:53:41,025: ============================================================
2022-03-27 12:54:45,497: time cost, forward:0.01796429589999115, backward:0.042562500807785134, data cost:0.5950881918447294 
2022-03-27 12:54:45,498: ============================================================
2022-03-27 12:54:45,498: Epoch 25/38 Batch 6100/7662 eta: 18:07:06.833902	Training Loss 1.9053 (1.7845)	Training Prec@1 100.000 (99.947)	Training Prec@5 100.000 (99.986)	
2022-03-27 12:54:45,499: ============================================================
2022-03-27 12:55:53,768: time cost, forward:0.017992508221026448, backward:0.04263227311694481, data cost:0.5953621926625364 
2022-03-27 12:55:53,769: ============================================================
2022-03-27 12:55:53,770: Epoch 25/38 Batch 6200/7662 eta: 19:10:01.081480	Training Loss 1.7166 (1.7855)	Training Prec@1 100.000 (99.947)	Training Prec@5 100.000 (99.986)	
2022-03-27 12:55:53,770: ============================================================
2022-03-27 12:56:59,081: time cost, forward:0.017997132159165114, backward:0.042615325663993994, data cost:0.5953550956839322 
2022-03-27 12:56:59,081: ============================================================
2022-03-27 12:56:59,081: Epoch 25/38 Batch 6300/7662 eta: 18:19:04.676882	Training Loss 1.9134 (1.7866)	Training Prec@1 100.000 (99.947)	Training Prec@5 100.000 (99.986)	
2022-03-27 12:56:59,082: ============================================================
2022-03-27 12:58:04,445: time cost, forward:0.01798485703609161, backward:0.04260139313316435, data cost:0.5951920998694469 
2022-03-27 12:58:04,447: ============================================================
2022-03-27 12:58:04,447: Epoch 25/38 Batch 6400/7662 eta: 18:18:53.501157	Training Loss 1.8180 (1.7878)	Training Prec@1 99.805 (99.947)	Training Prec@5 100.000 (99.986)	
2022-03-27 12:58:04,448: ============================================================
2022-03-27 12:59:11,036: time cost, forward:0.018008887942047518, backward:0.04264013700108103, data cost:0.5953867611178509 
2022-03-27 12:59:11,037: ============================================================
2022-03-27 12:59:11,037: Epoch 25/38 Batch 6500/7662 eta: 18:38:22.225970	Training Loss 1.8580 (1.7890)	Training Prec@1 100.000 (99.946)	Training Prec@5 100.000 (99.986)	
2022-03-27 12:59:11,037: ============================================================
2022-03-27 13:00:15,346: time cost, forward:0.018007552014966684, backward:0.042617669086019855, data cost:0.5951963856574676 
2022-03-27 13:00:15,346: ============================================================
2022-03-27 13:00:15,346: Epoch 25/38 Batch 6600/7662 eta: 17:58:59.362593	Training Loss 1.8774 (1.7903)	Training Prec@1 99.805 (99.946)	Training Prec@5 100.000 (99.986)	
2022-03-27 13:00:15,346: ============================================================
2022-03-27 13:01:22,279: time cost, forward:0.018030600505794123, backward:0.0426269232078993, data cost:0.5952494414569122 
2022-03-27 13:01:22,279: ============================================================
2022-03-27 13:01:22,280: Epoch 25/38 Batch 6700/7662 eta: 18:41:54.556914	Training Loss 1.7940 (1.7914)	Training Prec@1 100.000 (99.946)	Training Prec@5 100.000 (99.986)	
2022-03-27 13:01:22,280: ============================================================
2022-03-27 13:02:28,281: time cost, forward:0.018055703573708046, backward:0.042632493609487176, data cost:0.5953584575779316 
2022-03-27 13:02:28,281: ============================================================
2022-03-27 13:02:28,282: Epoch 25/38 Batch 6800/7662 eta: 18:25:11.850093	Training Loss 1.8063 (1.7926)	Training Prec@1 100.000 (99.945)	Training Prec@5 100.000 (99.986)	
2022-03-27 13:02:28,283: ============================================================
2022-03-27 13:03:35,866: time cost, forward:0.0180585763820411, backward:0.042659161315135016, data cost:0.5955121306720583 
2022-03-27 13:03:35,868: ============================================================
2022-03-27 13:03:35,869: Epoch 25/38 Batch 6900/7662 eta: 18:50:36.017831	Training Loss 1.9159 (1.7939)	Training Prec@1 100.000 (99.945)	Training Prec@5 100.000 (99.986)	
2022-03-27 13:03:35,870: ============================================================
2022-03-27 13:04:40,762: time cost, forward:0.018056824848062227, backward:0.04266767628551602, data cost:0.5954488360348693 
2022-03-27 13:04:40,762: ============================================================
2022-03-27 13:04:40,763: Epoch 25/38 Batch 7000/7662 eta: 18:04:28.268957	Training Loss 1.8195 (1.7950)	Training Prec@1 100.000 (99.945)	Training Prec@5 100.000 (99.986)	
2022-03-27 13:04:40,763: ============================================================
2022-03-27 13:05:45,304: time cost, forward:0.018043550542919277, backward:0.04268550160804724, data cost:0.5952236160692622 
2022-03-27 13:05:45,306: ============================================================
2022-03-27 13:05:45,307: Epoch 25/38 Batch 7100/7662 eta: 17:57:32.888929	Training Loss 1.8108 (1.7960)	Training Prec@1 100.000 (99.944)	Training Prec@5 100.000 (99.986)	
2022-03-27 13:05:45,307: ============================================================
2022-03-27 13:06:53,885: time cost, forward:0.018063120518083092, backward:0.042715114493356146, data cost:0.5956294209050675 
2022-03-27 13:06:53,886: ============================================================
2022-03-27 13:06:53,886: Epoch 25/38 Batch 7200/7662 eta: 19:03:47.076053	Training Loss 1.7320 (1.7971)	Training Prec@1 100.000 (99.944)	Training Prec@5 100.000 (99.985)	
2022-03-27 13:06:53,886: ============================================================
2022-03-27 13:08:00,400: time cost, forward:0.01806567554392869, backward:0.04270090121310906, data cost:0.5957265976831216 
2022-03-27 13:08:00,401: ============================================================
2022-03-27 13:08:00,401: Epoch 25/38 Batch 7300/7662 eta: 18:28:13.925693	Training Loss 1.8665 (1.7982)	Training Prec@1 100.000 (99.943)	Training Prec@5 100.000 (99.985)	
2022-03-27 13:08:00,401: ============================================================
2022-03-27 13:09:05,735: time cost, forward:0.01804390558118288, backward:0.042658366549899566, data cost:0.5956343925551862 
2022-03-27 13:09:05,737: ============================================================
2022-03-27 13:09:05,737: Epoch 25/38 Batch 7400/7662 eta: 18:07:30.909115	Training Loss 1.9991 (1.7994)	Training Prec@1 99.609 (99.943)	Training Prec@5 99.805 (99.985)	
2022-03-27 13:09:05,738: ============================================================
2022-03-27 13:10:10,530: time cost, forward:0.018017170985296004, backward:0.04261238477376004, data cost:0.5955693960539546 
2022-03-27 13:10:10,533: ============================================================
2022-03-27 13:10:10,534: Epoch 25/38 Batch 7500/7662 eta: 17:57:26.280093	Training Loss 1.6795 (1.8004)	Training Prec@1 100.000 (99.943)	Training Prec@5 100.000 (99.985)	
2022-03-27 13:10:10,535: ============================================================
2022-03-27 13:11:16,527: time cost, forward:0.018019052159866232, backward:0.04260619625729595, data cost:0.5956922079453517 
2022-03-27 13:11:16,527: ============================================================
2022-03-27 13:11:16,528: Epoch 25/38 Batch 7600/7662 eta: 18:16:15.803151	Training Loss 1.8634 (1.8016)	Training Prec@1 100.000 (99.942)	Training Prec@5 100.000 (99.985)	
2022-03-27 13:11:16,528: ============================================================
2022-03-27 13:11:59,567: Epoch: 25/38 eta: 18:15:34.226777	Training Loss 1.8328 (1.8023)	Training Prec@1 99.805 (99.942)	Training Prec@5 100.000 (99.985)
2022-03-27 13:11:59,567: ============================================================
2022-03-27 13:11:59,642: Save Checkpoint...
2022-03-27 13:11:59,643: ============================================================
2022-03-27 13:12:02,376: Save done!
2022-03-27 13:12:02,376: ============================================================
2022-03-27 13:13:07,949: time cost, forward:0.017578647594259242, backward:0.04162073857856519, data cost:0.5966126509387084 
2022-03-27 13:13:07,950: ============================================================
2022-03-27 13:13:07,951: Epoch 26/38 Batch 100/7662 eta: 18:07:01.879596	Training Loss 1.5688 (1.6723)	Training Prec@1 100.000 (99.980)	Training Prec@5 100.000 (99.996)	
2022-03-27 13:13:07,951: ============================================================
2022-03-27 13:14:14,499: time cost, forward:0.01798438906070575, backward:0.04299303395065231, data cost:0.599413012739402 
2022-03-27 13:14:14,500: ============================================================
2022-03-27 13:14:14,500: Epoch 26/38 Batch 200/7662 eta: 18:22:34.473951	Training Loss 1.8701 (1.6717)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.994)	
2022-03-27 13:14:14,500: ============================================================
2022-03-27 13:15:20,429: time cost, forward:0.016930089746430566, backward:0.04312896409561004, data cost:0.5980089420458944 
2022-03-27 13:15:20,431: ============================================================
2022-03-27 13:15:20,432: Epoch 26/38 Batch 300/7662 eta: 18:11:14.503982	Training Loss 1.6288 (1.6711)	Training Prec@1 100.000 (99.961)	Training Prec@5 100.000 (99.989)	
2022-03-27 13:15:20,432: ============================================================
2022-03-27 13:16:27,910: time cost, forward:0.0175584838503883, backward:0.043288048048664755, data cost:0.6022420353758007 
2022-03-27 13:16:27,910: ============================================================
2022-03-27 13:16:27,911: Epoch 26/38 Batch 400/7662 eta: 18:35:44.007520	Training Loss 1.6591 (1.6744)	Training Prec@1 100.000 (99.961)	Training Prec@5 100.000 (99.991)	
2022-03-27 13:16:27,911: ============================================================
2022-03-27 13:17:34,416: time cost, forward:0.017850886365932548, backward:0.043793800120841046, data cost:0.6015523698382482 
2022-03-27 13:17:34,417: ============================================================
2022-03-27 13:17:34,417: Epoch 26/38 Batch 500/7662 eta: 18:18:32.644219	Training Loss 1.7152 (1.6779)	Training Prec@1 100.000 (99.960)	Training Prec@5 100.000 (99.991)	
2022-03-27 13:17:34,417: ============================================================
2022-03-27 13:18:45,461: time cost, forward:0.018468691232009404, backward:0.04398029077431197, data cost:0.6083371901949977 
2022-03-27 13:18:45,462: ============================================================
2022-03-27 13:18:45,462: Epoch 26/38 Batch 600/7662 eta: 19:32:19.456423	Training Loss 1.6127 (1.6822)	Training Prec@1 100.000 (99.959)	Training Prec@5 100.000 (99.991)	
2022-03-27 13:18:45,462: ============================================================
2022-03-27 13:19:50,121: time cost, forward:0.018320015742202343, backward:0.04419064385355457, data cost:0.6034127226544381 
2022-03-27 13:19:50,124: ============================================================
2022-03-27 13:19:50,125: Epoch 26/38 Batch 700/7662 eta: 17:45:55.514523	Training Loss 1.7384 (1.6851)	Training Prec@1 100.000 (99.960)	Training Prec@5 100.000 (99.991)	
2022-03-27 13:19:50,126: ============================================================
2022-03-27 13:20:53,870: time cost, forward:0.018051632951586058, backward:0.0439143180847168, data cost:0.6005059902897765 
2022-03-27 13:20:53,873: ============================================================
2022-03-27 13:20:53,875: Epoch 26/38 Batch 800/7662 eta: 17:29:49.634469	Training Loss 1.7425 (1.6889)	Training Prec@1 100.000 (99.961)	Training Prec@5 100.000 (99.991)	
2022-03-27 13:20:53,876: ============================================================
2022-03-27 13:22:01,052: time cost, forward:0.01826469598543127, backward:0.044346495120225676, data cost:0.6014130818300173 
2022-03-27 13:22:01,052: ============================================================
2022-03-27 13:22:01,053: Epoch 26/38 Batch 900/7662 eta: 18:25:09.202048	Training Loss 1.7034 (1.6910)	Training Prec@1 100.000 (99.962)	Training Prec@5 100.000 (99.991)	
2022-03-27 13:22:01,053: ============================================================
2022-03-27 13:23:05,591: time cost, forward:0.018016212814682356, backward:0.0437869128283557, data cost:0.5999951913908079 
2022-03-27 13:23:05,591: ============================================================
2022-03-27 13:23:05,591: Epoch 26/38 Batch 1000/7662 eta: 17:40:39.640982	Training Loss 1.6414 (1.6942)	Training Prec@1 100.000 (99.961)	Training Prec@5 100.000 (99.991)	
2022-03-27 13:23:05,591: ============================================================
2022-03-27 13:24:15,129: time cost, forward:0.01787931470029239, backward:0.04336695089678638, data cost:0.6034582954195004 
2022-03-27 13:24:15,129: ============================================================
2022-03-27 13:24:15,129: Epoch 26/38 Batch 1100/7662 eta: 19:01:39.920127	Training Loss 1.7682 (1.6961)	Training Prec@1 99.805 (99.961)	Training Prec@5 99.805 (99.991)	
2022-03-27 13:24:15,130: ============================================================
2022-03-27 13:25:18,479: time cost, forward:0.017763491965413988, backward:0.04333679511012188, data cost:0.6010873655759861 
2022-03-27 13:25:18,479: ============================================================
2022-03-27 13:25:18,480: Epoch 26/38 Batch 1200/7662 eta: 17:19:01.191968	Training Loss 1.6312 (1.6992)	Training Prec@1 100.000 (99.961)	Training Prec@5 100.000 (99.991)	
2022-03-27 13:25:18,480: ============================================================
2022-03-27 13:26:26,730: time cost, forward:0.01776424052625367, backward:0.04318213297643508, data cost:0.6026583751226224 
2022-03-27 13:26:26,730: ============================================================
2022-03-27 13:26:26,731: Epoch 26/38 Batch 1300/7662 eta: 18:38:15.473935	Training Loss 1.8195 (1.7018)	Training Prec@1 99.805 (99.960)	Training Prec@5 100.000 (99.990)	
2022-03-27 13:26:26,731: ============================================================
2022-03-27 13:27:31,230: time cost, forward:0.01772597246804009, backward:0.04289643128826586, data cost:0.6009845022988201 
2022-03-27 13:27:31,232: ============================================================
2022-03-27 13:27:31,232: Epoch 26/38 Batch 1400/7662 eta: 17:35:45.120055	Training Loss 1.6540 (1.7053)	Training Prec@1 100.000 (99.960)	Training Prec@5 100.000 (99.990)	
2022-03-27 13:27:31,233: ============================================================
2022-03-27 13:28:37,469: time cost, forward:0.017657580576076595, backward:0.04271540536810511, data cost:0.6017380869332912 
2022-03-27 13:28:37,470: ============================================================
2022-03-27 13:28:37,470: Epoch 26/38 Batch 1500/7662 eta: 18:03:03.783134	Training Loss 1.6778 (1.7076)	Training Prec@1 100.000 (99.959)	Training Prec@5 100.000 (99.990)	
2022-03-27 13:28:37,470: ============================================================
2022-03-27 13:29:44,487: time cost, forward:0.01767993554836366, backward:0.042842073691047824, data cost:0.6020260203100876 
2022-03-27 13:29:44,488: ============================================================
2022-03-27 13:29:44,488: Epoch 26/38 Batch 1600/7662 eta: 18:14:42.071546	Training Loss 1.7269 (1.7092)	Training Prec@1 100.000 (99.959)	Training Prec@5 100.000 (99.989)	
2022-03-27 13:29:44,488: ============================================================
2022-03-27 13:30:48,772: time cost, forward:0.017638673355749174, backward:0.042849525133955825, data cost:0.6008015119587414 
2022-03-27 13:30:48,773: ============================================================
2022-03-27 13:30:48,773: Epoch 26/38 Batch 1700/7662 eta: 17:28:59.843001	Training Loss 1.6992 (1.7109)	Training Prec@1 100.000 (99.959)	Training Prec@5 100.000 (99.989)	
2022-03-27 13:30:48,773: ============================================================
2022-03-27 13:31:53,279: time cost, forward:0.017658547072227693, backward:0.04294519387330527, data cost:0.5994182664066503 
2022-03-27 13:31:53,280: ============================================================
2022-03-27 13:31:53,280: Epoch 26/38 Batch 1800/7662 eta: 17:31:32.208954	Training Loss 1.8047 (1.7137)	Training Prec@1 100.000 (99.959)	Training Prec@5 100.000 (99.989)	
2022-03-27 13:31:53,280: ============================================================
2022-03-27 13:33:00,175: time cost, forward:0.017718057496852783, backward:0.04295106019516755, data cost:0.5999302390752936 
2022-03-27 13:33:00,176: ============================================================
2022-03-27 13:33:00,176: Epoch 26/38 Batch 1900/7662 eta: 18:09:22.020120	Training Loss 1.7161 (1.7158)	Training Prec@1 100.000 (99.959)	Training Prec@5 100.000 (99.989)	
2022-03-27 13:33:00,176: ============================================================
2022-03-27 13:34:08,902: time cost, forward:0.01770395252214425, backward:0.04307354373178105, data cost:0.6011866641796011 
2022-03-27 13:34:08,903: ============================================================
2022-03-27 13:34:08,903: Epoch 26/38 Batch 2000/7662 eta: 18:38:02.413387	Training Loss 1.7408 (1.7183)	Training Prec@1 100.000 (99.959)	Training Prec@5 100.000 (99.989)	
2022-03-27 13:34:08,903: ============================================================
2022-03-27 13:35:13,735: time cost, forward:0.017691087586474225, backward:0.04307281794918327, data cost:0.6001710063676257 
2022-03-27 13:35:13,738: ============================================================
2022-03-27 13:35:13,739: Epoch 26/38 Batch 2100/7662 eta: 17:33:39.402757	Training Loss 1.8018 (1.7206)	Training Prec@1 100.000 (99.959)	Training Prec@5 100.000 (99.989)	
2022-03-27 13:35:13,740: ============================================================
2022-03-27 13:36:20,713: time cost, forward:0.01775230077680212, backward:0.04323022633370837, data cost:0.6003129323974096 
2022-03-27 13:36:20,715: ============================================================
2022-03-27 13:36:20,715: Epoch 26/38 Batch 2200/7662 eta: 18:07:19.385311	Training Loss 1.7305 (1.7227)	Training Prec@1 99.805 (99.959)	Training Prec@5 100.000 (99.989)	
2022-03-27 13:36:20,715: ============================================================
2022-03-27 13:37:25,644: time cost, forward:0.017702216011070592, backward:0.04324557377805706, data cost:0.6000190998689668 
2022-03-27 13:37:25,645: ============================================================
2022-03-27 13:37:25,645: Epoch 26/38 Batch 2300/7662 eta: 17:33:01.516596	Training Loss 1.7054 (1.7243)	Training Prec@1 100.000 (99.959)	Training Prec@5 100.000 (99.989)	
2022-03-27 13:37:25,645: ============================================================
2022-03-27 13:38:32,786: time cost, forward:0.017733180955232505, backward:0.04327708793312572, data cost:0.6003214025954596 
2022-03-27 13:38:32,786: ============================================================
2022-03-27 13:38:32,787: Epoch 26/38 Batch 2400/7662 eta: 18:07:46.318322	Training Loss 1.6540 (1.7259)	Training Prec@1 99.609 (99.958)	Training Prec@5 100.000 (99.989)	
2022-03-27 13:38:32,787: ============================================================
2022-03-27 13:39:42,636: time cost, forward:0.017810526825323636, backward:0.043482285015293956, data cost:0.6014619246632064 
2022-03-27 13:39:42,637: ============================================================
2022-03-27 13:39:42,637: Epoch 26/38 Batch 2500/7662 eta: 18:50:29.444535	Training Loss 2.0395 (1.7277)	Training Prec@1 100.000 (99.958)	Training Prec@5 100.000 (99.989)	
2022-03-27 13:39:42,637: ============================================================
2022-03-27 13:40:49,235: time cost, forward:0.017847451121589687, backward:0.043463915116331034, data cost:0.6011815399516313 
2022-03-27 13:40:49,236: ============================================================
2022-03-27 13:40:49,236: Epoch 26/38 Batch 2600/7662 eta: 17:56:46.127644	Training Loss 1.8139 (1.7293)	Training Prec@1 100.000 (99.958)	Training Prec@5 100.000 (99.989)	
2022-03-27 13:40:49,237: ============================================================
2022-03-27 13:41:51,214: time cost, forward:0.017863809024461687, backward:0.043508411381323275, data cost:0.5995859947854743 
2022-03-27 13:41:51,217: ============================================================
2022-03-27 13:41:51,217: Epoch 26/38 Batch 2700/7662 eta: 16:41:03.788067	Training Loss 1.7444 (1.7310)	Training Prec@1 100.000 (99.958)	Training Prec@5 100.000 (99.989)	
2022-03-27 13:41:51,218: ============================================================
2022-03-27 13:42:54,084: time cost, forward:0.0178304509888295, backward:0.04339542521796681, data cost:0.5987141119577749 
2022-03-27 13:42:54,084: ============================================================
2022-03-27 13:42:54,084: Epoch 26/38 Batch 2800/7662 eta: 16:54:19.763653	Training Loss 1.8978 (1.7332)	Training Prec@1 100.000 (99.959)	Training Prec@5 100.000 (99.989)	
2022-03-27 13:42:54,084: ============================================================
2022-03-27 13:44:01,109: time cost, forward:0.0177891175473053, backward:0.04337199649633149, data cost:0.599132685630064 
2022-03-27 13:44:01,109: ============================================================
2022-03-27 13:44:01,109: Epoch 26/38 Batch 2900/7662 eta: 18:00:18.091876	Training Loss 1.7636 (1.7351)	Training Prec@1 100.000 (99.958)	Training Prec@5 100.000 (99.988)	
2022-03-27 13:44:01,110: ============================================================
2022-03-27 13:45:08,305: time cost, forward:0.017835684719384612, backward:0.04343112240874318, data cost:0.5993540318817566 
2022-03-27 13:45:08,305: ============================================================
2022-03-27 13:45:08,305: Epoch 26/38 Batch 3000/7662 eta: 18:01:56.022311	Training Loss 1.8026 (1.7367)	Training Prec@1 100.000 (99.958)	Training Prec@5 100.000 (99.988)	
2022-03-27 13:45:08,306: ============================================================
2022-03-27 13:46:18,587: time cost, forward:0.017898233831601974, backward:0.043569411797537344, data cost:0.6004698321141516 
2022-03-27 13:46:18,588: ============================================================
2022-03-27 13:46:18,588: Epoch 26/38 Batch 3100/7662 eta: 18:50:27.727650	Training Loss 1.8302 (1.7384)	Training Prec@1 100.000 (99.957)	Training Prec@5 100.000 (99.988)	
2022-03-27 13:46:18,588: ============================================================
2022-03-27 13:47:26,785: time cost, forward:0.01790890808439359, backward:0.04355329683178028, data cost:0.600785214441126 
2022-03-27 13:47:26,788: ============================================================
2022-03-27 13:47:26,789: Epoch 26/38 Batch 3200/7662 eta: 18:15:50.214874	Training Loss 1.8967 (1.7402)	Training Prec@1 100.000 (99.957)	Training Prec@5 100.000 (99.988)	
2022-03-27 13:47:26,790: ============================================================
2022-03-27 13:48:32,647: time cost, forward:0.01799550248695598, backward:0.04358003478441935, data cost:0.6007720869792234 
2022-03-27 13:48:32,647: ============================================================
2022-03-27 13:48:32,648: Epoch 26/38 Batch 3300/7662 eta: 17:37:06.599552	Training Loss 1.6602 (1.7419)	Training Prec@1 100.000 (99.956)	Training Prec@5 100.000 (99.988)	
2022-03-27 13:48:32,648: ============================================================
2022-03-27 13:49:43,476: time cost, forward:0.01807887472100523, backward:0.04362394151073163, data cost:0.6019370062065742 
2022-03-27 13:49:43,477: ============================================================
2022-03-27 13:49:43,477: Epoch 26/38 Batch 3400/7662 eta: 18:55:42.743204	Training Loss 1.7223 (1.7437)	Training Prec@1 100.000 (99.956)	Training Prec@5 100.000 (99.988)	
2022-03-27 13:49:43,477: ============================================================
2022-03-27 13:50:48,762: time cost, forward:0.018183003360457202, backward:0.043719384151719304, data cost:0.601196139292841 
2022-03-27 13:50:48,765: ============================================================
2022-03-27 13:50:48,766: Epoch 26/38 Batch 3500/7662 eta: 17:25:46.581148	Training Loss 1.7760 (1.7451)	Training Prec@1 99.805 (99.956)	Training Prec@5 100.000 (99.988)	
2022-03-27 13:50:48,766: ============================================================
2022-03-27 13:51:56,621: time cost, forward:0.018162870645589316, backward:0.043721073499882544, data cost:0.6017944637223329 
2022-03-27 13:51:56,621: ============================================================
2022-03-27 13:51:56,621: Epoch 26/38 Batch 3600/7662 eta: 18:05:46.678796	Training Loss 1.6987 (1.7468)	Training Prec@1 100.000 (99.956)	Training Prec@5 100.000 (99.988)	
2022-03-27 13:51:56,622: ============================================================
2022-03-27 13:53:05,417: time cost, forward:0.018186821232424714, backward:0.04379323960381864, data cost:0.6023055511282792 
2022-03-27 13:53:05,417: ============================================================
2022-03-27 13:53:05,417: Epoch 26/38 Batch 3700/7662 eta: 18:19:40.074769	Training Loss 1.8418 (1.7483)	Training Prec@1 100.000 (99.956)	Training Prec@5 100.000 (99.988)	
2022-03-27 13:53:05,417: ============================================================
2022-03-27 13:54:13,362: time cost, forward:0.018167636054978616, backward:0.043720371505403935, data cost:0.6025209053468316 
2022-03-27 13:54:13,365: ============================================================
2022-03-27 13:54:13,366: Epoch 26/38 Batch 3800/7662 eta: 18:04:59.495838	Training Loss 1.8051 (1.7498)	Training Prec@1 99.805 (99.956)	Training Prec@5 99.805 (99.988)	
2022-03-27 13:54:13,367: ============================================================
2022-03-27 13:55:19,729: time cost, forward:0.018164496630942342, backward:0.043666615245219344, data cost:0.6027377104875399 
2022-03-27 13:55:19,729: ============================================================
2022-03-27 13:55:19,730: Epoch 26/38 Batch 3900/7662 eta: 17:38:34.700115	Training Loss 2.0288 (1.7518)	Training Prec@1 100.000 (99.955)	Training Prec@5 100.000 (99.987)	
2022-03-27 13:55:19,730: ============================================================
2022-03-27 13:56:28,331: time cost, forward:0.018172638271414777, backward:0.04364547183377113, data cost:0.6032552829412378 
2022-03-27 13:56:28,332: ============================================================
2022-03-27 13:56:28,332: Epoch 26/38 Batch 4000/7662 eta: 18:13:08.910898	Training Loss 1.7303 (1.7535)	Training Prec@1 100.000 (99.955)	Training Prec@5 100.000 (99.987)	
2022-03-27 13:56:28,332: ============================================================
2022-03-27 13:57:36,787: time cost, forward:0.018216393987967868, backward:0.043702903681483087, data cost:0.6035840874271993 
2022-03-27 13:57:36,788: ============================================================
2022-03-27 13:57:36,788: Epoch 26/38 Batch 4100/7662 eta: 18:09:40.020618	Training Loss 1.6858 (1.7548)	Training Prec@1 99.805 (99.954)	Training Prec@5 100.000 (99.987)	
2022-03-27 13:57:36,788: ============================================================
2022-03-27 13:58:44,286: time cost, forward:0.018257634075916105, backward:0.043751883149061865, data cost:0.6036652864572916 
2022-03-27 13:58:44,286: ============================================================
2022-03-27 13:58:44,286: Epoch 26/38 Batch 4200/7662 eta: 17:53:18.263973	Training Loss 1.6523 (1.7562)	Training Prec@1 100.000 (99.954)	Training Prec@5 100.000 (99.987)	
2022-03-27 13:58:44,287: ============================================================
2022-03-27 13:59:54,666: time cost, forward:0.018323205409701077, backward:0.04382740666517465, data cost:0.6041788554629716 
2022-03-27 13:59:54,669: ============================================================
2022-03-27 13:59:54,670: Epoch 26/38 Batch 4300/7662 eta: 18:37:59.925712	Training Loss 1.7882 (1.7576)	Training Prec@1 100.000 (99.954)	Training Prec@5 100.000 (99.987)	
2022-03-27 13:59:54,671: ============================================================
2022-03-27 14:01:03,597: time cost, forward:0.018301421985162283, backward:0.043822762911415666, data cost:0.6046963941782652 
2022-03-27 14:01:03,598: ============================================================
2022-03-27 14:01:03,598: Epoch 26/38 Batch 4400/7662 eta: 18:13:44.807100	Training Loss 1.6158 (1.7587)	Training Prec@1 100.000 (99.954)	Training Prec@5 100.000 (99.987)	
2022-03-27 14:01:03,598: ============================================================
2022-03-27 14:02:09,602: time cost, forward:0.018341270651544936, backward:0.04390938188214121, data cost:0.6045847908341373 
2022-03-27 14:02:09,602: ============================================================
2022-03-27 14:02:09,602: Epoch 26/38 Batch 4500/7662 eta: 17:26:14.481826	Training Loss 1.8231 (1.7603)	Training Prec@1 99.805 (99.953)	Training Prec@5 99.805 (99.987)	
2022-03-27 14:02:09,602: ============================================================
2022-03-27 14:03:16,707: time cost, forward:0.018313805003040744, backward:0.043937706693303824, data cost:0.6046197016256274 
2022-03-27 14:03:16,707: ============================================================
2022-03-27 14:03:16,707: Epoch 26/38 Batch 4600/7662 eta: 17:42:34.752483	Training Loss 1.9021 (1.7617)	Training Prec@1 99.805 (99.953)	Training Prec@5 99.805 (99.987)	
2022-03-27 14:03:16,708: ============================================================
2022-03-27 14:04:23,691: time cost, forward:0.018298908050173417, backward:0.043902899159043614, data cost:0.6047252700490682 
2022-03-27 14:04:23,692: ============================================================
2022-03-27 14:04:23,692: Epoch 26/38 Batch 4700/7662 eta: 17:39:32.943598	Training Loss 1.7390 (1.7633)	Training Prec@1 99.609 (99.953)	Training Prec@5 99.805 (99.987)	
2022-03-27 14:04:23,692: ============================================================
2022-03-27 14:05:33,398: time cost, forward:0.018330197355155523, backward:0.043804973332825785, data cost:0.6053953631318194 
2022-03-27 14:05:33,398: ============================================================
2022-03-27 14:05:33,398: Epoch 26/38 Batch 4800/7662 eta: 18:21:26.603757	Training Loss 1.9340 (1.7648)	Training Prec@1 100.000 (99.953)	Training Prec@5 100.000 (99.987)	
2022-03-27 14:05:33,399: ============================================================
2022-03-27 14:06:40,758: time cost, forward:0.018331464686474525, backward:0.04381330992937526, data cost:0.6054564425594394 
2022-03-27 14:06:40,758: ============================================================
2022-03-27 14:06:40,759: Epoch 26/38 Batch 4900/7662 eta: 17:43:14.900189	Training Loss 1.9245 (1.7663)	Training Prec@1 100.000 (99.952)	Training Prec@5 100.000 (99.987)	
2022-03-27 14:06:40,759: ============================================================
2022-03-27 14:07:49,136: time cost, forward:0.018376983912331172, backward:0.043844666378954504, data cost:0.6056841357895603 
2022-03-27 14:07:49,137: ============================================================
2022-03-27 14:07:49,137: Epoch 26/38 Batch 5000/7662 eta: 17:58:10.586732	Training Loss 1.9586 (1.7675)	Training Prec@1 99.805 (99.952)	Training Prec@5 99.805 (99.987)	
2022-03-27 14:07:49,137: ============================================================
2022-03-27 14:08:58,479: time cost, forward:0.018384858284961666, backward:0.04388715879990555, data cost:0.606109695917112 
2022-03-27 14:08:58,480: ============================================================
2022-03-27 14:08:58,480: Epoch 26/38 Batch 5100/7662 eta: 18:12:14.305752	Training Loss 1.7515 (1.7689)	Training Prec@1 100.000 (99.952)	Training Prec@5 100.000 (99.987)	
2022-03-27 14:08:58,480: ============================================================
2022-03-27 14:10:05,845: time cost, forward:0.018384963830036943, backward:0.04394155127379866, data cost:0.605967507680624 
2022-03-27 14:10:05,847: ============================================================
2022-03-27 14:10:05,848: Epoch 26/38 Batch 5200/7662 eta: 17:39:59.275654	Training Loss 1.8797 (1.7703)	Training Prec@1 100.000 (99.952)	Training Prec@5 100.000 (99.987)	
2022-03-27 14:10:05,849: ============================================================
2022-03-27 14:11:14,139: time cost, forward:0.01841719232880635, backward:0.044015402658005034, data cost:0.6062592637608649 
2022-03-27 14:11:14,139: ============================================================
2022-03-27 14:11:14,139: Epoch 26/38 Batch 5300/7662 eta: 17:53:24.091748	Training Loss 2.0646 (1.7718)	Training Prec@1 99.805 (99.951)	Training Prec@5 99.805 (99.987)	
2022-03-27 14:11:14,140: ============================================================
2022-03-27 14:12:23,247: time cost, forward:0.018422194157823146, backward:0.044054910195582574, data cost:0.606444204266501 
2022-03-27 14:12:23,249: ============================================================
2022-03-27 14:12:23,250: Epoch 26/38 Batch 5400/7662 eta: 18:05:06.113952	Training Loss 1.8190 (1.7733)	Training Prec@1 100.000 (99.951)	Training Prec@5 100.000 (99.986)	
2022-03-27 14:12:23,250: ============================================================
2022-03-27 14:13:30,644: time cost, forward:0.018417952775651704, backward:0.044016151910349334, data cost:0.606711151383534 
2022-03-27 14:13:30,644: ============================================================
2022-03-27 14:13:30,645: Epoch 26/38 Batch 5500/7662 eta: 17:37:03.934289	Training Loss 1.7406 (1.7748)	Training Prec@1 100.000 (99.951)	Training Prec@5 100.000 (99.986)	
2022-03-27 14:13:30,645: ============================================================
2022-03-27 14:14:38,081: time cost, forward:0.018437566576652985, backward:0.04399173177551172, data cost:0.6067815429079765 
2022-03-27 14:14:38,081: ============================================================
2022-03-27 14:14:38,081: Epoch 26/38 Batch 5600/7662 eta: 17:36:35.256322	Training Loss 1.9354 (1.7765)	Training Prec@1 100.000 (99.950)	Training Prec@5 100.000 (99.986)	
2022-03-27 14:14:38,082: ============================================================
2022-03-27 14:15:46,011: time cost, forward:0.018429419977201832, backward:0.04398782145749019, data cost:0.606942289313594 
2022-03-27 14:15:46,012: ============================================================
2022-03-27 14:15:46,012: Epoch 26/38 Batch 5700/7662 eta: 17:43:11.764453	Training Loss 1.8528 (1.7776)	Training Prec@1 100.000 (99.950)	Training Prec@5 100.000 (99.986)	
2022-03-27 14:15:46,012: ============================================================
2022-03-27 14:16:57,632: time cost, forward:0.01848163763435365, backward:0.04401680699174292, data cost:0.607611946328629 
2022-03-27 14:16:57,633: ============================================================
2022-03-27 14:16:57,633: Epoch 26/38 Batch 5800/7662 eta: 18:39:45.576825	Training Loss 1.8683 (1.7792)	Training Prec@1 100.000 (99.950)	Training Prec@5 100.000 (99.986)	
2022-03-27 14:16:57,633: ============================================================
2022-03-27 14:18:06,635: time cost, forward:0.018518832441628393, backward:0.04408036403523439, data cost:0.6078478783990472 
2022-03-27 14:18:06,635: ============================================================
2022-03-27 14:18:06,636: Epoch 26/38 Batch 5900/7662 eta: 17:57:40.120226	Training Loss 1.8434 (1.7806)	Training Prec@1 100.000 (99.949)	Training Prec@5 100.000 (99.986)	
2022-03-27 14:18:06,636: ============================================================
2022-03-27 14:19:14,516: time cost, forward:0.018508999680336126, backward:0.044097002793757355, data cost:0.6078615015318919 
2022-03-27 14:19:14,516: ============================================================
2022-03-27 14:19:14,517: Epoch 26/38 Batch 6000/7662 eta: 17:39:01.363692	Training Loss 1.7633 (1.7819)	Training Prec@1 99.805 (99.949)	Training Prec@5 100.000 (99.986)	
2022-03-27 14:19:14,517: ============================================================
2022-03-27 14:20:22,527: time cost, forward:0.018485818344719157, backward:0.04407747289473394, data cost:0.6079803756620673 
2022-03-27 14:20:22,528: ============================================================
2022-03-27 14:20:22,528: Epoch 26/38 Batch 6100/7662 eta: 17:39:55.178119	Training Loss 1.8135 (1.7830)	Training Prec@1 100.000 (99.949)	Training Prec@5 100.000 (99.986)	
2022-03-27 14:20:22,528: ============================================================
2022-03-27 14:21:30,330: time cost, forward:0.018503977918186424, backward:0.04407730812525668, data cost:0.608144580250614 
2022-03-27 14:21:30,333: ============================================================
2022-03-27 14:21:30,334: Epoch 26/38 Batch 6200/7662 eta: 17:35:34.620644	Training Loss 1.7896 (1.7842)	Training Prec@1 100.000 (99.949)	Training Prec@5 100.000 (99.986)	
2022-03-27 14:21:30,334: ============================================================
2022-03-27 14:22:36,915: time cost, forward:0.018475605431275247, backward:0.04403042959814924, data cost:0.608053243279476 
2022-03-27 14:22:36,918: ============================================================
2022-03-27 14:22:36,920: Epoch 26/38 Batch 6300/7662 eta: 17:15:29.638356	Training Loss 1.7947 (1.7855)	Training Prec@1 100.000 (99.949)	Training Prec@5 100.000 (99.986)	
2022-03-27 14:22:36,921: ============================================================
2022-03-27 14:23:46,726: time cost, forward:0.01851066233013026, backward:0.04407743536544826, data cost:0.6085053486532672 
2022-03-27 14:23:46,727: ============================================================
2022-03-27 14:23:46,727: Epoch 26/38 Batch 6400/7662 eta: 18:04:25.725975	Training Loss 2.0147 (1.7866)	Training Prec@1 99.805 (99.949)	Training Prec@5 100.000 (99.986)	
2022-03-27 14:23:46,727: ============================================================
2022-03-27 14:24:53,208: time cost, forward:0.018499163448452895, backward:0.04408280294406302, data cost:0.6083519226185156 
2022-03-27 14:24:53,209: ============================================================
2022-03-27 14:24:53,209: Epoch 26/38 Batch 6500/7662 eta: 17:11:39.274641	Training Loss 1.8638 (1.7877)	Training Prec@1 100.000 (99.948)	Training Prec@5 100.000 (99.986)	
2022-03-27 14:24:53,209: ============================================================
2022-03-27 14:25:58,382: time cost, forward:0.018481394940749282, backward:0.04407906951389813, data cost:0.6081136081196681 
2022-03-27 14:25:58,383: ============================================================
2022-03-27 14:25:58,383: Epoch 26/38 Batch 6600/7662 eta: 16:50:16.409034	Training Loss 1.7201 (1.7891)	Training Prec@1 100.000 (99.948)	Training Prec@5 100.000 (99.986)	
2022-03-27 14:25:58,383: ============================================================
2022-03-27 14:27:07,154: time cost, forward:0.01849449832219831, backward:0.04406860483673228, data cost:0.6083325562076366 
2022-03-27 14:27:07,155: ============================================================
2022-03-27 14:27:07,155: Epoch 26/38 Batch 6700/7662 eta: 17:44:54.276557	Training Loss 1.8838 (1.7903)	Training Prec@1 99.805 (99.948)	Training Prec@5 100.000 (99.986)	
2022-03-27 14:27:07,156: ============================================================
2022-03-27 14:28:18,048: time cost, forward:0.018505762457619663, backward:0.04409172714133528, data cost:0.6088301101700841 
2022-03-27 14:28:18,048: ============================================================
2022-03-27 14:28:18,048: Epoch 26/38 Batch 6800/7662 eta: 18:16:33.598697	Training Loss 1.8418 (1.7915)	Training Prec@1 100.000 (99.947)	Training Prec@5 100.000 (99.986)	
2022-03-27 14:28:18,048: ============================================================
2022-03-27 14:29:25,970: time cost, forward:0.018499568677117884, backward:0.04408989099164444, data cost:0.6089432263377784 
2022-03-27 14:29:25,971: ============================================================
2022-03-27 14:29:25,972: Epoch 26/38 Batch 6900/7662 eta: 17:29:30.005638	Training Loss 1.9517 (1.7927)	Training Prec@1 100.000 (99.947)	Training Prec@5 100.000 (99.986)	
2022-03-27 14:29:25,972: ============================================================
2022-03-27 14:30:35,310: time cost, forward:0.018530541717163035, backward:0.04416363176949996, data cost:0.6091258252990435 
2022-03-27 14:30:35,311: ============================================================
2022-03-27 14:30:35,311: Epoch 26/38 Batch 7000/7662 eta: 17:50:12.809668	Training Loss 1.9445 (1.7941)	Training Prec@1 100.000 (99.947)	Training Prec@5 100.000 (99.986)	
2022-03-27 14:30:35,311: ============================================================
2022-03-27 14:31:45,140: time cost, forward:0.01853352325838172, backward:0.044156303438003135, data cost:0.609380670023025 
2022-03-27 14:31:45,141: ============================================================
2022-03-27 14:31:45,141: Epoch 26/38 Batch 7100/7662 eta: 17:56:37.839175	Training Loss 2.0646 (1.7954)	Training Prec@1 100.000 (99.947)	Training Prec@5 100.000 (99.986)	
2022-03-27 14:31:45,141: ============================================================
2022-03-27 14:32:53,247: time cost, forward:0.018539765159658862, backward:0.04418732116811556, data cost:0.6095303631371998 
2022-03-27 14:32:53,247: ============================================================
2022-03-27 14:32:53,248: Epoch 26/38 Batch 7200/7662 eta: 17:28:55.203996	Training Loss 2.0392 (1.7966)	Training Prec@1 99.609 (99.946)	Training Prec@5 100.000 (99.986)	
2022-03-27 14:32:53,248: ============================================================
2022-03-27 14:34:04,813: time cost, forward:0.01856558217399985, backward:0.044224962434926775, data cost:0.6100221981266 
2022-03-27 14:34:04,816: ============================================================
2022-03-27 14:34:04,817: Epoch 26/38 Batch 7300/7662 eta: 18:21:02.599106	Training Loss 1.9800 (1.7980)	Training Prec@1 99.805 (99.946)	Training Prec@5 99.805 (99.986)	
2022-03-27 14:34:04,817: ============================================================
2022-03-27 14:35:12,811: time cost, forward:0.018575016107570803, backward:0.04421806599678486, data cost:0.6100866614136926 
2022-03-27 14:35:12,815: ============================================================
2022-03-27 14:35:12,816: Epoch 26/38 Batch 7400/7662 eta: 17:25:00.006613	Training Loss 1.9842 (1.7992)	Training Prec@1 100.000 (99.946)	Training Prec@5 100.000 (99.986)	
2022-03-27 14:35:12,816: ============================================================
2022-03-27 14:36:24,004: time cost, forward:0.018581032005846224, backward:0.044210244280637974, data cost:0.6105970063675624 
2022-03-27 14:36:24,004: ============================================================
2022-03-27 14:36:24,005: Epoch 26/38 Batch 7500/7662 eta: 18:12:50.350786	Training Loss 1.9814 (1.8004)	Training Prec@1 100.000 (99.945)	Training Prec@5 100.000 (99.985)	
2022-03-27 14:36:24,005: ============================================================
2022-03-27 14:37:33,648: time cost, forward:0.018613735834757488, backward:0.04425051545199477, data cost:0.6108319404517715 
2022-03-27 14:37:33,649: ============================================================
2022-03-27 14:37:33,649: Epoch 26/38 Batch 7600/7662 eta: 17:47:57.592259	Training Loss 1.9401 (1.8016)	Training Prec@1 100.000 (99.945)	Training Prec@5 100.000 (99.985)	
2022-03-27 14:37:33,649: ============================================================
2022-03-27 14:38:18,208: Epoch: 26/38 eta: 17:47:13.716377	Training Loss 1.9677 (1.8024)	Training Prec@1 99.805 (99.945)	Training Prec@5 100.000 (99.985)
2022-03-27 14:38:18,208: ============================================================
2022-03-27 14:39:31,737: time cost, forward:0.014777104059855143, backward:0.035537091168490326, data cost:0.6810006734096643 
2022-03-27 14:39:31,738: ============================================================
2022-03-27 14:39:31,738: Epoch 27/38 Batch 100/7662 eta: 18:42:45.416059	Training Loss 1.7073 (1.6590)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.984)	
2022-03-27 14:39:31,738: ============================================================
2022-03-27 14:40:39,936: time cost, forward:0.015513876574722366, backward:0.036361812946185394, data cost:0.6546831286732276 
2022-03-27 14:40:39,938: ============================================================
2022-03-27 14:40:39,939: Epoch 27/38 Batch 200/7662 eta: 17:22:50.622012	Training Loss 1.6349 (1.6638)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.989)	
2022-03-27 14:40:39,940: ============================================================
2022-03-27 14:41:50,113: time cost, forward:0.01599802699774803, backward:0.03732195028094543, data cost:0.6490416486925106 
2022-03-27 14:41:50,117: ============================================================
2022-03-27 14:41:50,119: Epoch 27/38 Batch 300/7662 eta: 17:51:55.604983	Training Loss 1.6494 (1.6657)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.988)	
2022-03-27 14:41:50,119: ============================================================
2022-03-27 14:42:55,942: time cost, forward:0.016816318483280957, backward:0.037832453137352354, data cost:0.638400664006857 
2022-03-27 14:42:55,943: ============================================================
2022-03-27 14:42:55,943: Epoch 27/38 Batch 400/7662 eta: 16:44:19.524013	Training Loss 1.7235 (1.6730)	Training Prec@1 99.805 (99.964)	Training Prec@5 100.000 (99.987)	
2022-03-27 14:42:55,943: ============================================================
2022-03-27 14:44:02,750: time cost, forward:0.017133750036388694, backward:0.038866944685727656, data cost:0.6314124205786145 
2022-03-27 14:44:02,751: ============================================================
2022-03-27 14:44:02,751: Epoch 27/38 Batch 500/7662 eta: 16:58:12.289418	Training Loss 1.6624 (1.6746)	Training Prec@1 100.000 (99.964)	Training Prec@5 100.000 (99.988)	
2022-03-27 14:44:02,751: ============================================================
2022-03-27 14:45:13,462: time cost, forward:0.017554919190319235, backward:0.039030981780292594, data cost:0.6329060524254291 
2022-03-27 14:45:13,465: ============================================================
2022-03-27 14:45:13,465: Epoch 27/38 Batch 600/7662 eta: 17:56:33.822415	Training Loss 1.6150 (1.6768)	Training Prec@1 100.000 (99.964)	Training Prec@5 100.000 (99.989)	
2022-03-27 14:45:13,465: ============================================================
2022-03-27 14:46:21,999: time cost, forward:0.017840161002927242, backward:0.03976805595539841, data cost:0.6317152366447176 
2022-03-27 14:46:22,001: ============================================================
2022-03-27 14:46:22,002: Epoch 27/38 Batch 700/7662 eta: 17:22:16.058484	Training Loss 1.6501 (1.6815)	Training Prec@1 100.000 (99.965)	Training Prec@5 100.000 (99.990)	
2022-03-27 14:46:22,005: ============================================================
2022-03-27 14:47:31,963: time cost, forward:0.018064949778054326, backward:0.040292962770139766, data cost:0.6320193136141208 
2022-03-27 14:47:31,964: ============================================================
2022-03-27 14:47:31,964: Epoch 27/38 Batch 800/7662 eta: 17:42:47.627549	Training Loss 1.7070 (1.6863)	Training Prec@1 100.000 (99.965)	Training Prec@5 100.000 (99.990)	
2022-03-27 14:47:31,965: ============================================================
2022-03-27 14:48:41,728: time cost, forward:0.018547098416507708, backward:0.04109998035749153, data cost:0.6310603130646092 
2022-03-27 14:48:41,733: ============================================================
2022-03-27 14:48:41,734: Epoch 27/38 Batch 900/7662 eta: 17:38:41.175462	Training Loss 1.6378 (1.6890)	Training Prec@1 100.000 (99.966)	Training Prec@5 100.000 (99.991)	
2022-03-27 14:48:41,736: ============================================================
2022-03-27 14:49:51,505: time cost, forward:0.018561098787996982, backward:0.041467749201380334, data cost:0.6316273420064656 
2022-03-27 14:49:51,519: ============================================================
2022-03-27 14:49:51,519: Epoch 27/38 Batch 1000/7662 eta: 17:37:47.067221	Training Loss 1.6677 (1.6923)	Training Prec@1 100.000 (99.966)	Training Prec@5 100.000 (99.990)	
2022-03-27 14:49:51,520: ============================================================
2022-03-27 14:50:57,591: time cost, forward:0.018622072530508692, backward:0.04172748278443438, data cost:0.6284471480167378 
2022-03-27 14:50:57,591: ============================================================
2022-03-27 14:50:57,591: Epoch 27/38 Batch 1100/7662 eta: 16:40:23.092830	Training Loss 1.6526 (1.6963)	Training Prec@1 100.000 (99.965)	Training Prec@5 100.000 (99.991)	
2022-03-27 14:50:57,592: ============================================================
2022-03-27 14:52:05,626: time cost, forward:0.018657778381207666, backward:0.042168721842507306, data cost:0.6270880219934383 
2022-03-27 14:52:05,628: ============================================================
2022-03-27 14:52:05,628: Epoch 27/38 Batch 1200/7662 eta: 17:08:59.885467	Training Loss 1.7521 (1.6996)	Training Prec@1 100.000 (99.964)	Training Prec@5 100.000 (99.991)	
2022-03-27 14:52:05,629: ============================================================
2022-03-27 14:53:12,909: time cost, forward:0.018750875706485457, backward:0.042252747070982054, data cost:0.6256670522359448 
2022-03-27 14:53:12,909: ============================================================
2022-03-27 14:53:12,910: Epoch 27/38 Batch 1300/7662 eta: 16:56:27.236020	Training Loss 1.7099 (1.7024)	Training Prec@1 100.000 (99.964)	Training Prec@5 100.000 (99.990)	
2022-03-27 14:53:12,910: ============================================================
2022-03-27 14:54:22,585: time cost, forward:0.018827897808737545, backward:0.0424419286167562, data cost:0.6259690668857294 
2022-03-27 14:54:22,585: ============================================================
2022-03-27 14:54:22,585: Epoch 27/38 Batch 1400/7662 eta: 17:31:28.011258	Training Loss 1.6022 (1.7045)	Training Prec@1 100.000 (99.963)	Training Prec@5 100.000 (99.990)	
2022-03-27 14:54:22,586: ============================================================
2022-03-27 14:55:32,869: time cost, forward:0.018861544140185253, backward:0.04269130823212993, data cost:0.6265503577664345 
2022-03-27 14:55:32,870: ============================================================
2022-03-27 14:55:32,870: Epoch 27/38 Batch 1500/7662 eta: 17:39:28.891824	Training Loss 1.6842 (1.7058)	Training Prec@1 100.000 (99.963)	Training Prec@5 100.000 (99.990)	
2022-03-27 14:55:32,870: ============================================================
2022-03-27 14:56:42,567: time cost, forward:0.01888779523299589, backward:0.042732477486319954, data cost:0.6264391962329323 
2022-03-27 14:56:42,570: ============================================================
2022-03-27 14:56:42,571: Epoch 27/38 Batch 1600/7662 eta: 17:29:30.543448	Training Loss 1.8113 (1.7080)	Training Prec@1 100.000 (99.963)	Training Prec@5 100.000 (99.990)	
2022-03-27 14:56:42,571: ============================================================
2022-03-27 14:57:52,078: time cost, forward:0.018931364858760912, backward:0.04280286076631597, data cost:0.6268959441137286 
2022-03-27 14:57:52,079: ============================================================
2022-03-27 14:57:52,079: Epoch 27/38 Batch 1700/7662 eta: 17:25:28.372148	Training Loss 1.7591 (1.7101)	Training Prec@1 100.000 (99.963)	Training Prec@5 100.000 (99.991)	
2022-03-27 14:57:52,079: ============================================================
2022-03-27 14:59:00,928: time cost, forward:0.019021618425879232, backward:0.042828362408182635, data cost:0.6269454884489355 
2022-03-27 14:59:00,929: ============================================================
2022-03-27 14:59:00,929: Epoch 27/38 Batch 1800/7662 eta: 17:14:24.875828	Training Loss 1.6989 (1.7127)	Training Prec@1 100.000 (99.963)	Training Prec@5 100.000 (99.991)	
2022-03-27 14:59:00,929: ============================================================
2022-03-27 15:00:11,969: time cost, forward:0.01915381568679689, backward:0.043087902164509445, data cost:0.6276017616396518 
2022-03-27 15:00:11,970: ============================================================
2022-03-27 15:00:11,970: Epoch 27/38 Batch 1900/7662 eta: 17:46:08.894542	Training Loss 1.7999 (1.7143)	Training Prec@1 99.805 (99.962)	Training Prec@5 100.000 (99.991)	
2022-03-27 15:00:11,971: ============================================================
2022-03-27 15:01:22,760: time cost, forward:0.019171132869634587, backward:0.04316323754070639, data cost:0.628259713080837 
2022-03-27 15:01:22,760: ============================================================
2022-03-27 15:01:22,760: Epoch 27/38 Batch 2000/7662 eta: 17:41:12.222011	Training Loss 1.7225 (1.7159)	Training Prec@1 100.000 (99.962)	Training Prec@5 100.000 (99.991)	
2022-03-27 15:01:22,761: ============================================================
2022-03-27 15:02:30,129: time cost, forward:0.019236833155297166, backward:0.04325408194961294, data cost:0.6273022403371737 
2022-03-27 15:02:30,129: ============================================================
2022-03-27 15:02:30,130: Epoch 27/38 Batch 2100/7662 eta: 16:48:47.824316	Training Loss 1.7816 (1.7177)	Training Prec@1 100.000 (99.962)	Training Prec@5 100.000 (99.991)	
2022-03-27 15:02:30,130: ============================================================
2022-03-27 15:03:38,911: time cost, forward:0.019242675806403757, backward:0.04345011830384106, data cost:0.6269415337804124 
2022-03-27 15:03:38,911: ============================================================
2022-03-27 15:03:38,912: Epoch 27/38 Batch 2200/7662 eta: 17:08:48.391408	Training Loss 1.8049 (1.7194)	Training Prec@1 100.000 (99.962)	Training Prec@5 100.000 (99.991)	
2022-03-27 15:03:38,912: ============================================================
2022-03-27 15:04:47,751: time cost, forward:0.01929038335261733, backward:0.04351255208214971, data cost:0.6266983830965099 
2022-03-27 15:04:47,752: ============================================================
2022-03-27 15:04:47,752: Epoch 27/38 Batch 2300/7662 eta: 17:08:32.319813	Training Loss 1.7564 (1.7215)	Training Prec@1 99.805 (99.961)	Training Prec@5 100.000 (99.990)	
2022-03-27 15:04:47,753: ============================================================
2022-03-27 15:05:56,000: time cost, forward:0.019321799526715488, backward:0.04360486885665506, data cost:0.6262213236692301 
2022-03-27 15:05:56,001: ============================================================
2022-03-27 15:05:56,001: Epoch 27/38 Batch 2400/7662 eta: 16:58:33.325015	Training Loss 1.6991 (1.7227)	Training Prec@1 100.000 (99.961)	Training Prec@5 100.000 (99.991)	
2022-03-27 15:05:56,001: ============================================================
2022-03-27 15:07:05,645: time cost, forward:0.019339721362177684, backward:0.04355597896736209, data cost:0.6262812789987211 
2022-03-27 15:07:05,647: ============================================================
2022-03-27 15:07:05,649: Epoch 27/38 Batch 2500/7662 eta: 17:18:15.571340	Training Loss 1.8264 (1.7245)	Training Prec@1 100.000 (99.961)	Training Prec@5 100.000 (99.991)	
2022-03-27 15:07:05,650: ============================================================
2022-03-27 15:08:13,148: time cost, forward:0.01935613581931513, backward:0.043568117520404626, data cost:0.6257355874572731 
2022-03-27 15:08:13,148: ============================================================
2022-03-27 15:08:13,149: Epoch 27/38 Batch 2600/7662 eta: 16:45:08.459513	Training Loss 1.7652 (1.7264)	Training Prec@1 100.000 (99.960)	Training Prec@5 100.000 (99.990)	
2022-03-27 15:08:13,149: ============================================================
2022-03-27 15:09:20,998: time cost, forward:0.019368522650403154, backward:0.043683705660271265, data cost:0.6252697313569483 
2022-03-27 15:09:20,998: ============================================================
2022-03-27 15:09:20,999: Epoch 27/38 Batch 2700/7662 eta: 16:49:13.013918	Training Loss 1.8180 (1.7285)	Training Prec@1 100.000 (99.961)	Training Prec@5 100.000 (99.990)	
2022-03-27 15:09:20,999: ============================================================
2022-03-27 15:10:27,525: time cost, forward:0.01929396175835634, backward:0.0436735445365347, data cost:0.624456872255217 
2022-03-27 15:10:27,526: ============================================================
2022-03-27 15:10:27,526: Epoch 27/38 Batch 2800/7662 eta: 16:28:25.734274	Training Loss 1.6802 (1.7303)	Training Prec@1 100.000 (99.961)	Training Prec@5 100.000 (99.990)	
2022-03-27 15:10:27,527: ============================================================
2022-03-27 15:11:37,124: time cost, forward:0.01929501625289996, backward:0.04372671457272885, data cost:0.6244018331977078 
2022-03-27 15:11:37,126: ============================================================
2022-03-27 15:11:37,126: Epoch 27/38 Batch 2900/7662 eta: 17:12:55.248158	Training Loss 1.7621 (1.7323)	Training Prec@1 100.000 (99.961)	Training Prec@5 100.000 (99.990)	
2022-03-27 15:11:37,127: ============================================================
2022-03-27 15:12:48,419: time cost, forward:0.019302779016752328, backward:0.043736445104809514, data cost:0.6251481265455693 
2022-03-27 15:12:48,420: ============================================================
2022-03-27 15:12:48,421: Epoch 27/38 Batch 3000/7662 eta: 17:36:52.462853	Training Loss 1.8610 (1.7346)	Training Prec@1 100.000 (99.960)	Training Prec@5 100.000 (99.990)	
2022-03-27 15:12:48,422: ============================================================
2022-03-27 15:13:55,924: time cost, forward:0.019266544060770177, backward:0.043600700331642074, data cost:0.6249706419716731 
2022-03-27 15:13:55,925: ============================================================
2022-03-27 15:13:55,925: Epoch 27/38 Batch 3100/7662 eta: 16:39:34.909283	Training Loss 1.7318 (1.7364)	Training Prec@1 99.805 (99.960)	Training Prec@5 100.000 (99.990)	
2022-03-27 15:13:55,926: ============================================================
2022-03-27 15:15:02,355: time cost, forward:0.019184073719168946, backward:0.04358615059895827, data cost:0.6244295178521011 
2022-03-27 15:15:02,356: ============================================================
2022-03-27 15:15:02,357: Epoch 27/38 Batch 3200/7662 eta: 16:22:34.333553	Training Loss 1.9359 (1.7382)	Training Prec@1 100.000 (99.960)	Training Prec@5 100.000 (99.990)	
2022-03-27 15:15:02,358: ============================================================
2022-03-27 15:16:13,206: time cost, forward:0.019274522839766193, backward:0.043659245039196076, data cost:0.6248669513755584 
2022-03-27 15:16:13,206: ============================================================
2022-03-27 15:16:13,206: Epoch 27/38 Batch 3300/7662 eta: 17:26:44.927254	Training Loss 1.6902 (1.7407)	Training Prec@1 100.000 (99.959)	Training Prec@5 100.000 (99.990)	
2022-03-27 15:16:13,207: ============================================================
2022-03-27 15:17:21,684: time cost, forward:0.019363983829921397, backward:0.043669406579992076, data cost:0.6246296927381102 
2022-03-27 15:17:21,684: ============================================================
2022-03-27 15:17:21,684: Epoch 27/38 Batch 3400/7662 eta: 16:50:33.769246	Training Loss 1.8058 (1.7425)	Training Prec@1 99.805 (99.958)	Training Prec@5 99.805 (99.990)	
2022-03-27 15:17:21,684: ============================================================
2022-03-27 15:18:30,861: time cost, forward:0.01934083818401327, backward:0.04372485776259648, data cost:0.6246582903702554 
2022-03-27 15:18:30,861: ============================================================
2022-03-27 15:18:30,862: Epoch 27/38 Batch 3500/7662 eta: 16:59:43.817205	Training Loss 1.7893 (1.7440)	Training Prec@1 99.805 (99.957)	Training Prec@5 100.000 (99.990)	
2022-03-27 15:18:30,862: ============================================================
2022-03-27 15:19:41,220: time cost, forward:0.019373396430687296, backward:0.04375203909824941, data cost:0.6249730673787594 
2022-03-27 15:19:41,221: ============================================================
2022-03-27 15:19:41,221: Epoch 27/38 Batch 3600/7662 eta: 17:15:58.734770	Training Loss 1.8356 (1.7462)	Training Prec@1 100.000 (99.957)	Training Prec@5 100.000 (99.989)	
2022-03-27 15:19:41,221: ============================================================
2022-03-27 15:20:52,320: time cost, forward:0.019406387051172147, backward:0.04372335814501537, data cost:0.6255612690470032 
2022-03-27 15:20:52,321: ============================================================
2022-03-27 15:20:52,321: Epoch 27/38 Batch 3700/7662 eta: 17:25:42.344715	Training Loss 1.8428 (1.7481)	Training Prec@1 100.000 (99.957)	Training Prec@5 100.000 (99.989)	
2022-03-27 15:20:52,321: ============================================================
2022-03-27 15:22:03,615: time cost, forward:0.01943285008988025, backward:0.043865807089688874, data cost:0.6260054226955887 
2022-03-27 15:22:03,616: ============================================================
2022-03-27 15:22:03,616: Epoch 27/38 Batch 3800/7662 eta: 17:27:22.885349	Training Loss 1.7337 (1.7494)	Training Prec@1 100.000 (99.957)	Training Prec@5 100.000 (99.989)	
2022-03-27 15:22:03,616: ============================================================
2022-03-27 15:23:12,370: time cost, forward:0.019427271738025463, backward:0.0437942656164568, data cost:0.6259649342284749 
2022-03-27 15:23:12,373: ============================================================
2022-03-27 15:23:12,375: Epoch 27/38 Batch 3900/7662 eta: 16:48:58.527210	Training Loss 1.8341 (1.7518)	Training Prec@1 99.805 (99.957)	Training Prec@5 100.000 (99.989)	
2022-03-27 15:23:12,375: ============================================================
2022-03-27 15:24:23,467: time cost, forward:0.019481635743542055, backward:0.04389392062704931, data cost:0.6262244581430965 
2022-03-27 15:24:23,470: ============================================================
2022-03-27 15:24:23,471: Epoch 27/38 Batch 4000/7662 eta: 17:22:05.159726	Training Loss 1.8307 (1.7536)	Training Prec@1 100.000 (99.956)	Training Prec@5 100.000 (99.989)	
2022-03-27 15:24:23,472: ============================================================
2022-03-27 15:25:32,675: time cost, forward:0.019469126284660493, backward:0.04392503203052112, data cost:0.626133170585046 
2022-03-27 15:25:32,677: ============================================================
2022-03-27 15:25:32,678: Epoch 27/38 Batch 4100/7662 eta: 16:53:14.976710	Training Loss 1.9376 (1.7551)	Training Prec@1 99.609 (99.956)	Training Prec@5 99.805 (99.989)	
2022-03-27 15:25:32,679: ============================================================
2022-03-27 15:26:42,873: time cost, forward:0.019500017393257085, backward:0.044025743311432095, data cost:0.6263873250065999 
2022-03-27 15:26:42,874: ============================================================
2022-03-27 15:26:42,875: Epoch 27/38 Batch 4200/7662 eta: 17:06:34.187594	Training Loss 1.8488 (1.7568)	Training Prec@1 100.000 (99.956)	Training Prec@5 100.000 (99.988)	
2022-03-27 15:26:42,875: ============================================================
2022-03-27 15:27:52,283: time cost, forward:0.019590736905151424, backward:0.04408038669088381, data cost:0.6261477575770199 
2022-03-27 15:27:52,283: ============================================================
2022-03-27 15:27:52,284: Epoch 27/38 Batch 4300/7662 eta: 16:53:53.974771	Training Loss 1.7597 (1.7582)	Training Prec@1 100.000 (99.955)	Training Prec@5 100.000 (99.988)	
2022-03-27 15:27:52,284: ============================================================
2022-03-27 15:29:01,601: time cost, forward:0.019615920952001088, backward:0.04409508917596726, data cost:0.626348523395553 
2022-03-27 15:29:01,602: ============================================================
2022-03-27 15:29:01,602: Epoch 27/38 Batch 4400/7662 eta: 16:51:24.891089	Training Loss 1.6457 (1.7596)	Training Prec@1 100.000 (99.955)	Training Prec@5 100.000 (99.988)	
2022-03-27 15:29:01,602: ============================================================
2022-03-27 15:30:10,551: time cost, forward:0.019601605208244926, backward:0.0440544884955785, data cost:0.6263460353046663 
2022-03-27 15:30:10,553: ============================================================
2022-03-27 15:30:10,554: Epoch 27/38 Batch 4500/7662 eta: 16:44:54.546763	Training Loss 1.9434 (1.7616)	Training Prec@1 100.000 (99.954)	Training Prec@5 100.000 (99.988)	
2022-03-27 15:30:10,555: ============================================================
2022-03-27 15:31:18,765: time cost, forward:0.019595188378095367, backward:0.043992440579740555, data cost:0.6261896792119626 
2022-03-27 15:31:18,766: ============================================================
2022-03-27 15:31:18,766: Epoch 27/38 Batch 4600/7662 eta: 16:32:59.786509	Training Loss 2.0271 (1.7630)	Training Prec@1 100.000 (99.954)	Training Prec@5 100.000 (99.988)	
2022-03-27 15:31:18,766: ============================================================
2022-03-27 15:32:29,804: time cost, forward:0.019603238204205942, backward:0.04401371716996359, data cost:0.6264310298155764 
2022-03-27 15:32:29,808: ============================================================
2022-03-27 15:32:29,808: Epoch 27/38 Batch 4700/7662 eta: 17:13:00.745002	Training Loss 1.8037 (1.7646)	Training Prec@1 99.805 (99.954)	Training Prec@5 100.000 (99.988)	
2022-03-27 15:32:29,809: ============================================================
2022-03-27 15:33:36,116: time cost, forward:0.019585710188875, backward:0.04409376813312649, data cost:0.6259052478713178 
2022-03-27 15:33:36,117: ============================================================
2022-03-27 15:33:36,117: Epoch 27/38 Batch 4800/7662 eta: 16:03:04.878749	Training Loss 1.9008 (1.7658)	Training Prec@1 100.000 (99.954)	Training Prec@5 100.000 (99.988)	
2022-03-27 15:33:36,117: ============================================================
2022-03-27 15:34:45,404: time cost, forward:0.019573250116681925, backward:0.04406738782517884, data cost:0.6257943259280272 
2022-03-27 15:34:45,407: ============================================================
2022-03-27 15:34:45,408: Epoch 27/38 Batch 4900/7662 eta: 16:45:14.241900	Training Loss 2.0480 (1.7674)	Training Prec@1 100.000 (99.953)	Training Prec@5 100.000 (99.988)	
2022-03-27 15:34:45,409: ============================================================
2022-03-27 15:35:54,682: time cost, forward:0.0195804002833953, backward:0.044095674498745574, data cost:0.6258133314780937 
2022-03-27 15:35:54,685: ============================================================
2022-03-27 15:35:54,687: Epoch 27/38 Batch 5000/7662 eta: 16:43:54.457437	Training Loss 1.9493 (1.7690)	Training Prec@1 99.805 (99.953)	Training Prec@5 100.000 (99.988)	
2022-03-27 15:35:54,689: ============================================================
2022-03-27 15:37:02,300: time cost, forward:0.01957955073319035, backward:0.04414584702616885, data cost:0.6256384458652219 
2022-03-27 15:37:02,301: ============================================================
2022-03-27 15:37:02,301: Epoch 27/38 Batch 5100/7662 eta: 16:18:39.820640	Training Loss 1.8618 (1.7705)	Training Prec@1 100.000 (99.953)	Training Prec@5 100.000 (99.988)	
2022-03-27 15:37:02,301: ============================================================
2022-03-27 15:38:12,199: time cost, forward:0.01960890736573475, backward:0.044164610450188456, data cost:0.6257247742746261 
2022-03-27 15:38:12,201: ============================================================
2022-03-27 15:38:12,202: Epoch 27/38 Batch 5200/7662 eta: 16:50:34.984442	Training Loss 1.7801 (1.7720)	Training Prec@1 100.000 (99.953)	Training Prec@5 100.000 (99.988)	
2022-03-27 15:38:12,202: ============================================================
2022-03-27 15:39:21,644: time cost, forward:0.0195992882464557, backward:0.04415415489216934, data cost:0.6256689090372414 
2022-03-27 15:39:21,647: ============================================================
2022-03-27 15:39:21,648: Epoch 27/38 Batch 5300/7662 eta: 16:42:51.704519	Training Loss 1.8730 (1.7734)	Training Prec@1 100.000 (99.953)	Training Prec@5 100.000 (99.988)	
2022-03-27 15:39:21,649: ============================================================
2022-03-27 15:40:30,167: time cost, forward:0.019626356756539228, backward:0.04415635445268535, data cost:0.6256690794151124 
2022-03-27 15:40:30,167: ============================================================
2022-03-27 15:40:30,167: Epoch 27/38 Batch 5400/7662 eta: 16:28:20.239050	Training Loss 1.9523 (1.7747)	Training Prec@1 100.000 (99.952)	Training Prec@5 100.000 (99.988)	
2022-03-27 15:40:30,168: ============================================================
2022-03-27 15:41:40,614: time cost, forward:0.019649496076756943, backward:0.044185613194125894, data cost:0.6258020369784141 
2022-03-27 15:41:40,614: ============================================================
2022-03-27 15:41:40,614: Epoch 27/38 Batch 5500/7662 eta: 16:54:57.886502	Training Loss 1.9413 (1.7761)	Training Prec@1 99.805 (99.952)	Training Prec@5 100.000 (99.988)	
2022-03-27 15:41:40,615: ============================================================
2022-03-27 15:42:48,371: time cost, forward:0.019636759099672472, backward:0.044172301507886126, data cost:0.6255062955855302 
2022-03-27 15:42:48,372: ============================================================
2022-03-27 15:42:48,373: Epoch 27/38 Batch 5600/7662 eta: 16:15:05.819377	Training Loss 2.0880 (1.7775)	Training Prec@1 100.000 (99.952)	Training Prec@5 100.000 (99.988)	
2022-03-27 15:42:48,373: ============================================================
2022-03-27 15:43:55,632: time cost, forward:0.01961729563753068, backward:0.04414354192309054, data cost:0.625291901986878 
2022-03-27 15:43:55,635: ============================================================
2022-03-27 15:43:55,636: Epoch 27/38 Batch 5700/7662 eta: 16:06:50.859210	Training Loss 1.7251 (1.7786)	Training Prec@1 100.000 (99.952)	Training Prec@5 100.000 (99.988)	
2022-03-27 15:43:55,637: ============================================================
2022-03-27 15:45:05,602: time cost, forward:0.019622733992201477, backward:0.04416149162921356, data cost:0.6255102104144912 
2022-03-27 15:45:05,602: ============================================================
2022-03-27 15:45:05,602: Epoch 27/38 Batch 5800/7662 eta: 16:44:32.683978	Training Loss 1.9390 (1.7799)	Training Prec@1 100.000 (99.951)	Training Prec@5 100.000 (99.988)	
2022-03-27 15:45:05,602: ============================================================
2022-03-27 15:46:15,072: time cost, forward:0.01963593855128892, backward:0.044186148244984215, data cost:0.6255379327779544 
2022-03-27 15:46:15,073: ============================================================
2022-03-27 15:46:15,073: Epoch 27/38 Batch 5900/7662 eta: 16:36:16.498544	Training Loss 1.9803 (1.7816)	Training Prec@1 100.000 (99.951)	Training Prec@5 100.000 (99.987)	
2022-03-27 15:46:15,074: ============================================================
2022-03-27 15:47:27,486: time cost, forward:0.019650607570884108, backward:0.04430397468162469, data cost:0.6259684497504497 
2022-03-27 15:47:27,486: ============================================================
2022-03-27 15:47:27,487: Epoch 27/38 Batch 6000/7662 eta: 17:17:15.521787	Training Loss 1.9081 (1.7828)	Training Prec@1 100.000 (99.950)	Training Prec@5 100.000 (99.987)	
2022-03-27 15:47:27,487: ============================================================
2022-03-27 15:48:38,245: time cost, forward:0.019684541340753044, backward:0.044381708410025075, data cost:0.6260274192664951 
2022-03-27 15:48:38,246: ============================================================
2022-03-27 15:48:38,246: Epoch 27/38 Batch 6100/7662 eta: 16:52:23.468033	Training Loss 1.7083 (1.7837)	Training Prec@1 99.805 (99.950)	Training Prec@5 100.000 (99.987)	
2022-03-27 15:48:38,246: ============================================================
2022-03-27 15:49:47,317: time cost, forward:0.019691959698943672, backward:0.04438640425562532, data cost:0.6260723108475315 
2022-03-27 15:49:47,318: ============================================================
2022-03-27 15:49:47,318: Epoch 27/38 Batch 6200/7662 eta: 16:27:05.704037	Training Loss 1.8209 (1.7853)	Training Prec@1 100.000 (99.950)	Training Prec@5 100.000 (99.987)	
2022-03-27 15:49:47,318: ============================================================
2022-03-27 15:50:57,842: time cost, forward:0.019703951084835223, backward:0.04437897030863237, data cost:0.6261338219791769 
2022-03-27 15:50:57,845: ============================================================
2022-03-27 15:50:57,846: Epoch 27/38 Batch 6300/7662 eta: 16:46:43.045133	Training Loss 1.8277 (1.7866)	Training Prec@1 100.000 (99.950)	Training Prec@5 100.000 (99.987)	
2022-03-27 15:50:57,847: ============================================================
2022-03-27 15:52:05,555: time cost, forward:0.01968815438839435, backward:0.04438505241285545, data cost:0.6260429685014098 
2022-03-27 15:52:05,555: ============================================================
2022-03-27 15:52:05,556: Epoch 27/38 Batch 6400/7662 eta: 16:05:22.894606	Training Loss 1.9596 (1.7878)	Training Prec@1 99.805 (99.950)	Training Prec@5 99.805 (99.987)	
2022-03-27 15:52:05,556: ============================================================
2022-03-27 15:53:15,094: time cost, forward:0.01967474988358335, backward:0.04438296969734094, data cost:0.6259958818520486 
2022-03-27 15:53:15,096: ============================================================
2022-03-27 15:53:15,096: Epoch 27/38 Batch 6500/7662 eta: 16:30:18.658314	Training Loss 1.9200 (1.7889)	Training Prec@1 99.414 (99.950)	Training Prec@5 100.000 (99.987)	
2022-03-27 15:53:15,097: ============================================================
2022-03-27 15:54:21,330: time cost, forward:0.019658761848950317, backward:0.04440034597385, data cost:0.6256818446919383 
2022-03-27 15:54:21,331: ============================================================
2022-03-27 15:54:21,331: Epoch 27/38 Batch 6600/7662 eta: 15:42:08.105813	Training Loss 1.8313 (1.7902)	Training Prec@1 100.000 (99.950)	Training Prec@5 100.000 (99.987)	
2022-03-27 15:54:21,331: ============================================================
2022-03-27 15:55:30,599: time cost, forward:0.01966179077403548, backward:0.04437809062370668, data cost:0.6257083189987499 
2022-03-27 15:55:30,601: ============================================================
2022-03-27 15:55:30,601: Epoch 27/38 Batch 6700/7662 eta: 16:24:09.397448	Training Loss 1.8164 (1.7916)	Training Prec@1 100.000 (99.949)	Training Prec@5 100.000 (99.987)	
2022-03-27 15:55:30,602: ============================================================
2022-03-27 15:56:39,336: time cost, forward:0.019664902426877746, backward:0.044362870818254685, data cost:0.6256815753871684 
2022-03-27 15:56:39,336: ============================================================
2022-03-27 15:56:39,337: Epoch 27/38 Batch 6800/7662 eta: 16:15:24.960314	Training Loss 1.8197 (1.7929)	Training Prec@1 99.805 (99.949)	Training Prec@5 100.000 (99.987)	
2022-03-27 15:56:39,337: ============================================================
2022-03-27 15:57:45,837: time cost, forward:0.019651518159715105, backward:0.04441011085045789, data cost:0.6251696623448169 
2022-03-27 15:57:45,839: ============================================================
2022-03-27 15:57:45,840: Epoch 27/38 Batch 6900/7662 eta: 15:42:37.254545	Training Loss 1.7649 (1.7941)	Training Prec@1 100.000 (99.949)	Training Prec@5 100.000 (99.987)	
2022-03-27 15:57:45,841: ============================================================
2022-03-27 15:58:51,587: time cost, forward:0.019640427178051627, backward:0.044429532015795435, data cost:0.6247126630994827 
2022-03-27 15:58:51,588: ============================================================
2022-03-27 15:58:51,588: Epoch 27/38 Batch 7000/7662 eta: 15:30:50.091568	Training Loss 1.8680 (1.7953)	Training Prec@1 100.000 (99.949)	Training Prec@5 100.000 (99.987)	
2022-03-27 15:58:51,588: ============================================================
2022-03-27 16:00:00,422: time cost, forward:0.019633866478178028, backward:0.044470537009415854, data cost:0.6246755853272237 
2022-03-27 16:00:00,423: ============================================================
2022-03-27 16:00:00,423: Epoch 27/38 Batch 7100/7662 eta: 16:13:23.108579	Training Loss 1.8127 (1.7967)	Training Prec@1 100.000 (99.948)	Training Prec@5 100.000 (99.987)	
2022-03-27 16:00:00,423: ============================================================
2022-03-27 16:01:07,935: time cost, forward:0.019614391748168963, backward:0.04448811424028577, data cost:0.6244912863870613 
2022-03-27 16:01:07,935: ============================================================
2022-03-27 16:01:07,936: Epoch 27/38 Batch 7200/7662 eta: 15:53:33.470590	Training Loss 1.9495 (1.7979)	Training Prec@1 100.000 (99.948)	Training Prec@5 100.000 (99.987)	
2022-03-27 16:01:07,936: ============================================================
2022-03-27 16:02:19,404: time cost, forward:0.019641141725543557, backward:0.04446951045224333, data cost:0.6248139350899998 
2022-03-27 16:02:19,405: ============================================================
2022-03-27 16:02:19,405: Epoch 27/38 Batch 7300/7662 eta: 16:48:15.240473	Training Loss 1.9041 (1.7993)	Training Prec@1 100.000 (99.948)	Training Prec@5 100.000 (99.987)	
2022-03-27 16:02:19,405: ============================================================
2022-03-27 16:03:30,426: time cost, forward:0.019641449103759485, backward:0.04445518588903772, data cost:0.6250484939974246 
2022-03-27 16:03:30,427: ============================================================
2022-03-27 16:03:30,428: Epoch 27/38 Batch 7400/7662 eta: 16:40:45.925893	Training Loss 1.8221 (1.8008)	Training Prec@1 99.805 (99.947)	Training Prec@5 100.000 (99.986)	
2022-03-27 16:03:30,428: ============================================================
2022-03-27 16:04:43,277: time cost, forward:0.019669489218944198, backward:0.04447762183084983, data cost:0.6254889109497437 
2022-03-27 16:04:43,277: ============================================================
2022-03-27 16:04:43,278: Epoch 27/38 Batch 7500/7662 eta: 17:05:18.301608	Training Loss 1.9297 (1.8021)	Training Prec@1 100.000 (99.947)	Training Prec@5 100.000 (99.986)	
2022-03-27 16:04:43,278: ============================================================
2022-03-27 16:05:54,381: time cost, forward:0.0197066998447238, backward:0.04449630213467788, data cost:0.6257510273091682 
2022-03-27 16:05:54,381: ============================================================
2022-03-27 16:05:54,382: Epoch 27/38 Batch 7600/7662 eta: 16:39:32.738054	Training Loss 1.7716 (1.8033)	Training Prec@1 100.000 (99.946)	Training Prec@5 100.000 (99.986)	
2022-03-27 16:05:54,382: ============================================================
2022-03-27 16:06:39,631: Epoch: 27/38 eta: 16:38:47.942482	Training Loss 2.0061 (1.8040)	Training Prec@1 99.414 (99.946)	Training Prec@5 99.609 (99.986)
2022-03-27 16:06:39,631: ============================================================
2022-03-27 16:07:51,439: time cost, forward:0.018224388662010732, backward:0.042616155412462026, data cost:0.6590847439236112 
2022-03-27 16:07:51,439: ============================================================
2022-03-27 16:07:51,440: Epoch 28/38 Batch 100/7662 eta: 16:46:48.057726	Training Loss 1.6435 (1.6449)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.996)	
2022-03-27 16:07:51,440: ============================================================
2022-03-27 16:09:01,801: time cost, forward:0.017662994825660285, backward:0.04267376631348577, data cost:0.6461216756446877 
2022-03-27 16:09:01,805: ============================================================
2022-03-27 16:09:01,806: Epoch 28/38 Batch 200/7662 eta: 16:26:04.950635	Training Loss 1.5662 (1.6501)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.996)	
2022-03-27 16:09:01,807: ============================================================
2022-03-27 16:10:14,658: time cost, forward:0.018088788093133117, backward:0.04249349884364916, data cost:0.655321071777854 
2022-03-27 16:10:14,659: ============================================================
2022-03-27 16:10:14,659: Epoch 28/38 Batch 300/7662 eta: 16:59:45.142691	Training Loss 1.6427 (1.6595)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.997)	
2022-03-27 16:10:14,659: ============================================================
2022-03-27 16:11:19,913: time cost, forward:0.018208680595072888, backward:0.042838842348944875, data cost:0.6379404181525821 
2022-03-27 16:11:19,914: ============================================================
2022-03-27 16:11:19,914: Epoch 28/38 Batch 400/7662 eta: 15:12:17.955142	Training Loss 1.8613 (1.6645)	Training Prec@1 100.000 (99.971)	Training Prec@5 100.000 (99.998)	
2022-03-27 16:11:19,915: ============================================================
2022-03-27 16:12:26,643: time cost, forward:0.01781391141887657, backward:0.04204076038811632, data cost:0.6331219630155391 
2022-03-27 16:12:26,643: ============================================================
2022-03-27 16:12:26,644: Epoch 28/38 Batch 500/7662 eta: 15:31:47.933485	Training Loss 1.7288 (1.6689)	Training Prec@1 100.000 (99.971)	Training Prec@5 100.000 (99.996)	
2022-03-27 16:12:26,644: ============================================================
2022-03-27 16:13:36,601: time cost, forward:0.017572731326935886, backward:0.04178639485163362, data cost:0.6346068652922005 
2022-03-27 16:13:36,602: ============================================================
2022-03-27 16:13:36,602: Epoch 28/38 Batch 600/7662 eta: 16:15:43.161787	Training Loss 1.5929 (1.6756)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.995)	
2022-03-27 16:13:36,602: ============================================================
2022-03-27 16:14:47,607: time cost, forward:0.01781287213763454, backward:0.042353470779113334, data cost:0.6355574884810332 
2022-03-27 16:14:47,608: ============================================================
2022-03-27 16:14:47,609: Epoch 28/38 Batch 700/7662 eta: 16:29:09.259674	Training Loss 1.6852 (1.6790)	Training Prec@1 100.000 (99.965)	Training Prec@5 100.000 (99.993)	
2022-03-27 16:14:47,609: ============================================================
2022-03-27 16:16:00,424: time cost, forward:0.01799580242219049, backward:0.04276278439690085, data cost:0.6380057612408386 
2022-03-27 16:16:00,429: ============================================================
2022-03-27 16:16:00,431: Epoch 28/38 Batch 800/7662 eta: 16:53:13.575883	Training Loss 1.6693 (1.6827)	Training Prec@1 100.000 (99.965)	Training Prec@5 100.000 (99.993)	
2022-03-27 16:16:00,431: ============================================================
2022-03-27 16:17:11,219: time cost, forward:0.017994831083083446, backward:0.042808812505278626, data cost:0.6389011944228735 
2022-03-27 16:17:11,219: ============================================================
2022-03-27 16:17:11,219: Epoch 28/38 Batch 900/7662 eta: 16:23:46.294672	Training Loss 1.5369 (1.6859)	Training Prec@1 99.805 (99.965)	Training Prec@5 99.805 (99.992)	
2022-03-27 16:17:11,220: ============================================================
2022-03-27 16:18:19,597: time cost, forward:0.017848504556191934, backward:0.04251837205361795, data cost:0.6384435325294167 
2022-03-27 16:18:19,598: ============================================================
2022-03-27 16:18:19,598: Epoch 28/38 Batch 1000/7662 eta: 15:49:07.695529	Training Loss 1.7275 (1.6894)	Training Prec@1 100.000 (99.964)	Training Prec@5 100.000 (99.991)	
2022-03-27 16:18:19,598: ============================================================
2022-03-27 16:19:28,163: time cost, forward:0.01787204065574528, backward:0.042520283568003046, data cost:0.636298793787518 
2022-03-27 16:19:28,166: ============================================================
2022-03-27 16:19:28,167: Epoch 28/38 Batch 1100/7662 eta: 15:50:37.173954	Training Loss 1.6569 (1.6914)	Training Prec@1 100.000 (99.963)	Training Prec@5 100.000 (99.991)	
2022-03-27 16:19:28,167: ============================================================
2022-03-27 16:20:37,870: time cost, forward:0.01809224672770878, backward:0.042947467711689676, data cost:0.6362931231243397 
2022-03-27 16:20:37,870: ============================================================
2022-03-27 16:20:37,871: Epoch 28/38 Batch 1200/7662 eta: 16:05:12.537011	Training Loss 1.8714 (1.6936)	Training Prec@1 100.000 (99.962)	Training Prec@5 100.000 (99.991)	
2022-03-27 16:20:37,871: ============================================================
2022-03-27 16:21:50,840: time cost, forward:0.018126843799711467, backward:0.043229189352221996, data cost:0.637798858111046 
2022-03-27 16:21:50,842: ============================================================
2022-03-27 16:21:50,843: Epoch 28/38 Batch 1300/7662 eta: 16:49:14.447256	Training Loss 1.8572 (1.6958)	Training Prec@1 100.000 (99.963)	Training Prec@5 100.000 (99.991)	
2022-03-27 16:21:50,844: ============================================================
2022-03-27 16:23:00,917: time cost, forward:0.018183269698420452, backward:0.04352432340277017, data cost:0.6374024192804605 
2022-03-27 16:23:00,919: ============================================================
2022-03-27 16:23:00,920: Epoch 28/38 Batch 1400/7662 eta: 16:08:01.671238	Training Loss 1.7488 (1.6991)	Training Prec@1 99.805 (99.963)	Training Prec@5 100.000 (99.991)	
2022-03-27 16:23:00,921: ============================================================
2022-03-27 16:24:11,551: time cost, forward:0.018118341737305664, backward:0.04348096694844496, data cost:0.6377941098827136 
2022-03-27 16:24:11,553: ============================================================
2022-03-27 16:24:11,554: Epoch 28/38 Batch 1500/7662 eta: 16:14:33.010194	Training Loss 1.6951 (1.7012)	Training Prec@1 100.000 (99.963)	Training Prec@5 100.000 (99.991)	
2022-03-27 16:24:11,555: ============================================================
2022-03-27 16:25:20,107: time cost, forward:0.018017776464208206, backward:0.04326498068594202, data cost:0.6377366884862579 
2022-03-27 16:25:20,110: ============================================================
2022-03-27 16:25:20,111: Epoch 28/38 Batch 1600/7662 eta: 15:44:45.019926	Training Loss 1.9136 (1.7038)	Training Prec@1 100.000 (99.962)	Training Prec@5 100.000 (99.991)	
2022-03-27 16:25:20,112: ============================================================
2022-03-27 16:26:35,930: time cost, forward:0.01808580403611406, backward:0.043364011658999134, data cost:0.6409555625185818 
2022-03-27 16:26:35,931: ============================================================
2022-03-27 16:26:35,931: Epoch 28/38 Batch 1700/7662 eta: 17:23:34.362223	Training Loss 1.7452 (1.7065)	Training Prec@1 99.805 (99.963)	Training Prec@5 100.000 (99.991)	
2022-03-27 16:26:35,931: ============================================================
2022-03-27 16:27:42,625: time cost, forward:0.018088673273015513, backward:0.04336770737813936, data cost:0.6386745288810709 
2022-03-27 16:27:42,625: ============================================================
2022-03-27 16:27:42,625: Epoch 28/38 Batch 1800/7662 eta: 15:16:51.777997	Training Loss 1.5801 (1.7091)	Training Prec@1 100.000 (99.962)	Training Prec@5 100.000 (99.990)	
2022-03-27 16:27:42,626: ============================================================
2022-03-27 16:28:50,911: time cost, forward:0.01816037154436237, backward:0.04342472157772118, data cost:0.6377507563074242 
2022-03-27 16:28:50,912: ============================================================
2022-03-27 16:28:50,913: Epoch 28/38 Batch 1900/7662 eta: 15:37:36.994065	Training Loss 1.6413 (1.7109)	Training Prec@1 100.000 (99.961)	Training Prec@5 100.000 (99.990)	
2022-03-27 16:28:50,913: ============================================================
2022-03-27 16:30:05,057: time cost, forward:0.018297420375761, backward:0.043710086034380716, data cost:0.6393668540660711 
2022-03-27 16:30:05,057: ============================================================
2022-03-27 16:30:05,057: Epoch 28/38 Batch 2000/7662 eta: 16:56:48.484327	Training Loss 1.6100 (1.7128)	Training Prec@1 99.805 (99.960)	Training Prec@5 99.805 (99.990)	
2022-03-27 16:30:05,057: ============================================================
2022-03-27 16:31:13,357: time cost, forward:0.018217798526540378, backward:0.04369872646595308, data cost:0.6385047677700266 
2022-03-27 16:31:13,358: ============================================================
2022-03-27 16:31:13,358: Epoch 28/38 Batch 2100/7662 eta: 15:35:31.918890	Training Loss 1.6547 (1.7146)	Training Prec@1 100.000 (99.961)	Training Prec@5 100.000 (99.990)	
2022-03-27 16:31:13,359: ============================================================
2022-03-27 16:32:24,459: time cost, forward:0.01835493924347798, backward:0.04374927322991386, data cost:0.6386364694615286 
2022-03-27 16:32:24,462: ============================================================
2022-03-27 16:32:24,464: Epoch 28/38 Batch 2200/7662 eta: 16:12:45.120688	Training Loss 1.7858 (1.7165)	Training Prec@1 100.000 (99.961)	Training Prec@5 100.000 (99.990)	
2022-03-27 16:32:24,465: ============================================================
2022-03-27 16:33:35,585: time cost, forward:0.018341986808428405, backward:0.04375924219925438, data cost:0.6391173939748451 
2022-03-27 16:33:35,586: ============================================================
2022-03-27 16:33:35,586: Epoch 28/38 Batch 2300/7662 eta: 16:11:48.438877	Training Loss 1.7649 (1.7191)	Training Prec@1 99.805 (99.960)	Training Prec@5 100.000 (99.990)	
2022-03-27 16:33:35,586: ============================================================
2022-03-27 16:34:44,547: time cost, forward:0.01838381879773921, backward:0.04381284081672519, data cost:0.6384692583644623 
2022-03-27 16:34:44,548: ============================================================
2022-03-27 16:34:44,548: Epoch 28/38 Batch 2400/7662 eta: 15:41:07.957977	Training Loss 1.7357 (1.7212)	Training Prec@1 100.000 (99.959)	Training Prec@5 100.000 (99.989)	
2022-03-27 16:34:44,548: ============================================================
2022-03-27 16:35:55,975: time cost, forward:0.01840875510360394, backward:0.043858746997639385, data cost:0.6388874552926335 
2022-03-27 16:35:55,976: ============================================================
2022-03-27 16:35:55,976: Epoch 28/38 Batch 2500/7662 eta: 16:13:36.053641	Training Loss 1.7034 (1.7232)	Training Prec@1 100.000 (99.958)	Training Prec@5 100.000 (99.989)	
2022-03-27 16:35:55,976: ============================================================
2022-03-27 16:37:05,936: time cost, forward:0.01836894942779365, backward:0.04387197122063807, data cost:0.6388211674119657 
2022-03-27 16:37:05,937: ============================================================
2022-03-27 16:37:05,937: Epoch 28/38 Batch 2600/7662 eta: 15:52:26.190436	Training Loss 1.7950 (1.7253)	Training Prec@1 99.805 (99.957)	Training Prec@5 100.000 (99.988)	
2022-03-27 16:37:05,937: ============================================================
2022-03-27 16:38:20,025: time cost, forward:0.018507721336650247, backward:0.04406316406685319, data cost:0.6398407384703538 
2022-03-27 16:38:20,026: ============================================================
2022-03-27 16:38:20,026: Epoch 28/38 Batch 2700/7662 eta: 16:47:24.021857	Training Loss 1.8623 (1.7275)	Training Prec@1 100.000 (99.958)	Training Prec@5 100.000 (99.989)	
2022-03-27 16:38:20,026: ============================================================
2022-03-27 16:39:27,878: time cost, forward:0.01849616242545381, backward:0.04406493934148888, data cost:0.6390002658001736 
2022-03-27 16:39:27,879: ============================================================
2022-03-27 16:39:27,879: Epoch 28/38 Batch 2800/7662 eta: 15:21:28.556772	Training Loss 1.8552 (1.7294)	Training Prec@1 100.000 (99.958)	Training Prec@5 100.000 (99.989)	
2022-03-27 16:39:27,879: ============================================================
2022-03-27 16:40:35,313: time cost, forward:0.018495106623065024, backward:0.04403470729539706, data cost:0.6379303230668562 
2022-03-27 16:40:35,313: ============================================================
2022-03-27 16:40:35,314: Epoch 28/38 Batch 2900/7662 eta: 15:14:40.618242	Training Loss 1.7512 (1.7318)	Training Prec@1 100.000 (99.957)	Training Prec@5 100.000 (99.988)	
2022-03-27 16:40:35,314: ============================================================
2022-03-27 16:41:46,787: time cost, forward:0.018520508260876388, backward:0.04410307540143081, data cost:0.6383525238469586 
2022-03-27 16:41:46,789: ============================================================
2022-03-27 16:41:46,789: Epoch 28/38 Batch 3000/7662 eta: 16:08:17.126883	Training Loss 1.6707 (1.7334)	Training Prec@1 99.805 (99.956)	Training Prec@5 100.000 (99.988)	
2022-03-27 16:41:46,789: ============================================================
2022-03-27 16:42:57,758: time cost, forward:0.018529234951101762, backward:0.0441354662805036, data cost:0.6385284509532642 
2022-03-27 16:42:57,758: ============================================================
2022-03-27 16:42:57,759: Epoch 28/38 Batch 3100/7662 eta: 16:00:15.189174	Training Loss 1.7484 (1.7352)	Training Prec@1 100.000 (99.957)	Training Prec@5 100.000 (99.988)	
2022-03-27 16:42:57,759: ============================================================
2022-03-27 16:44:07,484: time cost, forward:0.0185516482779815, backward:0.044181963845169814, data cost:0.6381417019883705 
2022-03-27 16:44:07,487: ============================================================
2022-03-27 16:44:07,488: Epoch 28/38 Batch 3200/7662 eta: 15:42:18.210297	Training Loss 1.5727 (1.7371)	Training Prec@1 100.000 (99.957)	Training Prec@5 100.000 (99.988)	
2022-03-27 16:44:07,489: ============================================================
2022-03-27 16:45:22,138: time cost, forward:0.018619812051611766, backward:0.04436028744459658, data cost:0.6392676437143197 
2022-03-27 16:45:22,139: ============================================================
2022-03-27 16:45:22,140: Epoch 28/38 Batch 3300/7662 eta: 16:47:35.449586	Training Loss 1.6952 (1.7392)	Training Prec@1 100.000 (99.957)	Training Prec@5 100.000 (99.988)	
2022-03-27 16:45:22,140: ============================================================
2022-03-27 16:46:27,637: time cost, forward:0.018599538811517834, backward:0.04434587549342587, data cost:0.6378583941048613 
2022-03-27 16:46:27,637: ============================================================
2022-03-27 16:46:27,638: Epoch 28/38 Batch 3400/7662 eta: 14:42:56.644095	Training Loss 1.8174 (1.7410)	Training Prec@1 100.000 (99.957)	Training Prec@5 100.000 (99.989)	
2022-03-27 16:46:27,638: ============================================================
2022-03-27 16:47:37,449: time cost, forward:0.018611826464665825, backward:0.04435614580152784, data cost:0.6376936107950573 
2022-03-27 16:47:37,450: ============================================================
2022-03-27 16:47:37,450: Epoch 28/38 Batch 3500/7662 eta: 15:39:56.950438	Training Loss 1.8276 (1.7430)	Training Prec@1 100.000 (99.957)	Training Prec@5 100.000 (99.989)	
2022-03-27 16:47:37,451: ============================================================
2022-03-27 16:48:50,383: time cost, forward:0.01860474612720147, backward:0.044417375192008904, data cost:0.6382831355935171 
2022-03-27 16:48:50,384: ============================================================
2022-03-27 16:48:50,384: Epoch 28/38 Batch 3600/7662 eta: 16:20:45.219390	Training Loss 1.8393 (1.7449)	Training Prec@1 100.000 (99.957)	Training Prec@5 100.000 (99.989)	
2022-03-27 16:48:50,384: ============================================================
2022-03-27 16:49:59,994: time cost, forward:0.018577513162365923, backward:0.04438486038655583, data cost:0.6384206084374899 
2022-03-27 16:49:59,995: ============================================================
2022-03-27 16:49:59,995: Epoch 28/38 Batch 3700/7662 eta: 15:34:54.624302	Training Loss 1.9869 (1.7473)	Training Prec@1 100.000 (99.957)	Training Prec@5 100.000 (99.989)	
2022-03-27 16:49:59,995: ============================================================
2022-03-27 16:51:15,392: time cost, forward:0.018594473718059286, backward:0.0443552243894701, data cost:0.6397864880703662 
2022-03-27 16:51:15,392: ============================================================
2022-03-27 16:51:15,392: Epoch 28/38 Batch 3800/7662 eta: 16:51:22.001288	Training Loss 1.9020 (1.7493)	Training Prec@1 100.000 (99.957)	Training Prec@5 100.000 (99.989)	
2022-03-27 16:51:15,393: ============================================================
2022-03-27 16:52:22,430: time cost, forward:0.01857378709680088, backward:0.044355099737476034, data cost:0.6389252478478963 
2022-03-27 16:52:22,430: ============================================================
2022-03-27 16:52:22,431: Epoch 28/38 Batch 3900/7662 eta: 14:58:07.327151	Training Loss 1.7112 (1.7512)	Training Prec@1 100.000 (99.956)	Training Prec@5 100.000 (99.989)	
2022-03-27 16:52:22,431: ============================================================
2022-03-27 16:53:35,402: time cost, forward:0.01861192113490485, backward:0.044361365917594056, data cost:0.6394985240827533 
2022-03-27 16:53:35,403: ============================================================
2022-03-27 16:53:35,403: Epoch 28/38 Batch 4000/7662 eta: 16:16:24.191633	Training Loss 1.7518 (1.7533)	Training Prec@1 99.805 (99.956)	Training Prec@5 99.805 (99.989)	
2022-03-27 16:53:35,403: ============================================================
2022-03-27 16:54:43,665: time cost, forward:0.018625601526294343, backward:0.0443568485601555, data cost:0.6389920030404487 
2022-03-27 16:54:43,666: ============================================================
2022-03-27 16:54:43,666: Epoch 28/38 Batch 4100/7662 eta: 15:12:15.532543	Training Loss 1.7989 (1.7547)	Training Prec@1 100.000 (99.956)	Training Prec@5 100.000 (99.989)	
2022-03-27 16:54:43,666: ============================================================
2022-03-27 16:55:55,262: time cost, forward:0.018737524683971184, backward:0.04435785369209858, data cost:0.6391983254235766 
2022-03-27 16:55:55,262: ============================================================
2022-03-27 16:55:55,263: Epoch 28/38 Batch 4200/7662 eta: 15:55:36.841358	Training Loss 1.8519 (1.7563)	Training Prec@1 100.000 (99.955)	Training Prec@5 100.000 (99.989)	
2022-03-27 16:55:55,263: ============================================================
2022-03-27 16:57:04,202: time cost, forward:0.01868797629676494, backward:0.044360698669781436, data cost:0.6388808143613061 
2022-03-27 16:57:04,202: ============================================================
2022-03-27 16:57:04,202: Epoch 28/38 Batch 4300/7662 eta: 15:18:59.842984	Training Loss 1.9025 (1.7582)	Training Prec@1 100.000 (99.955)	Training Prec@5 100.000 (99.989)	
2022-03-27 16:57:04,202: ============================================================
2022-03-27 16:58:14,645: time cost, forward:0.01872143850567179, backward:0.04442734234873396, data cost:0.6387987003512858 
2022-03-27 16:58:14,646: ============================================================
2022-03-27 16:58:14,646: Epoch 28/38 Batch 4400/7662 eta: 15:37:52.761669	Training Loss 1.9278 (1.7598)	Training Prec@1 100.000 (99.955)	Training Prec@5 100.000 (99.989)	
2022-03-27 16:58:14,646: ============================================================
2022-03-27 16:59:28,065: time cost, forward:0.01877921357317007, backward:0.0445082196661514, data cost:0.639290731200697 
2022-03-27 16:59:28,066: ============================================================
2022-03-27 16:59:28,066: Epoch 28/38 Batch 4500/7662 eta: 16:16:16.557492	Training Loss 1.8978 (1.7615)	Training Prec@1 100.000 (99.955)	Training Prec@5 100.000 (99.988)	
2022-03-27 16:59:28,066: ============================================================
2022-03-27 17:00:37,624: time cost, forward:0.018780097932394598, backward:0.04455040387159639, data cost:0.6390084993271601 
2022-03-27 17:00:37,625: ============================================================
2022-03-27 17:00:37,625: Epoch 28/38 Batch 4600/7662 eta: 15:23:46.591404	Training Loss 1.7242 (1.7634)	Training Prec@1 100.000 (99.954)	Training Prec@5 100.000 (99.988)	
2022-03-27 17:00:37,625: ============================================================
2022-03-27 17:01:46,052: time cost, forward:0.018784978537388013, backward:0.0445611644334097, data cost:0.6385552952659462 
2022-03-27 17:01:46,054: ============================================================
2022-03-27 17:01:46,054: Epoch 28/38 Batch 4700/7662 eta: 15:07:37.888560	Training Loss 1.8908 (1.7651)	Training Prec@1 100.000 (99.954)	Training Prec@5 100.000 (99.988)	
2022-03-27 17:01:46,055: ============================================================
2022-03-27 17:02:58,625: time cost, forward:0.018773867701907834, backward:0.04454924181417317, data cost:0.6390577601651197 
2022-03-27 17:02:58,629: ============================================================
2022-03-27 17:02:58,631: Epoch 28/38 Batch 4800/7662 eta: 16:01:25.876168	Training Loss 1.9147 (1.7667)	Training Prec@1 100.000 (99.954)	Training Prec@5 100.000 (99.988)	
2022-03-27 17:02:58,632: ============================================================
2022-03-27 17:04:10,924: time cost, forward:0.018786381351434348, backward:0.04456988444837363, data cost:0.6394702653832327 
2022-03-27 17:04:10,927: ============================================================
2022-03-27 17:04:10,928: Epoch 28/38 Batch 4900/7662 eta: 15:56:31.330053	Training Loss 1.7467 (1.7683)	Training Prec@1 100.000 (99.954)	Training Prec@5 100.000 (99.988)	
2022-03-27 17:04:10,928: ============================================================
2022-03-27 17:05:18,805: time cost, forward:0.018772833059730234, backward:0.04452238299413117, data cost:0.6390539087946832 
2022-03-27 17:05:18,806: ============================================================
2022-03-27 17:05:18,806: Epoch 28/38 Batch 5000/7662 eta: 14:56:56.073527	Training Loss 1.8546 (1.7702)	Training Prec@1 99.805 (99.954)	Training Prec@5 100.000 (99.988)	
2022-03-27 17:05:18,806: ============================================================
2022-03-27 17:06:27,466: time cost, forward:0.0187970491735859, backward:0.0444958422739942, data cost:0.6387225392519855 
2022-03-27 17:06:27,467: ============================================================
2022-03-27 17:06:27,467: Epoch 28/38 Batch 5100/7662 eta: 15:06:07.850213	Training Loss 1.6673 (1.7718)	Training Prec@1 100.000 (99.953)	Training Prec@5 100.000 (99.988)	
2022-03-27 17:06:27,467: ============================================================
2022-03-27 17:07:38,098: time cost, forward:0.01879933009264125, backward:0.04448737082836329, data cost:0.6388055305569006 
2022-03-27 17:07:38,098: ============================================================
2022-03-27 17:07:38,098: Epoch 28/38 Batch 5200/7662 eta: 15:30:57.575519	Training Loss 1.8663 (1.7735)	Training Prec@1 100.000 (99.953)	Training Prec@5 100.000 (99.988)	
2022-03-27 17:07:38,099: ============================================================
2022-03-27 17:08:50,268: time cost, forward:0.018788843385272036, backward:0.04449110176005798, data cost:0.63897593229711 
2022-03-27 17:08:50,270: ============================================================
2022-03-27 17:08:50,271: Epoch 28/38 Batch 5300/7662 eta: 15:50:03.905035	Training Loss 1.9845 (1.7752)	Training Prec@1 100.000 (99.953)	Training Prec@5 100.000 (99.989)	
2022-03-27 17:08:50,272: ============================================================
2022-03-27 17:10:01,762: time cost, forward:0.018769023682943514, backward:0.04449682558967264, data cost:0.6392164720078489 
2022-03-27 17:10:01,762: ============================================================
2022-03-27 17:10:01,763: Epoch 28/38 Batch 5400/7662 eta: 15:39:54.975763	Training Loss 1.8227 (1.7768)	Training Prec@1 100.000 (99.953)	Training Prec@5 100.000 (99.988)	
2022-03-27 17:10:01,763: ============================================================
2022-03-27 17:11:11,921: time cost, forward:0.01881335344850464, backward:0.044529727381518766, data cost:0.6392460002056315 
2022-03-27 17:11:11,922: ============================================================
2022-03-27 17:11:11,922: Epoch 28/38 Batch 5500/7662 eta: 15:21:13.598572	Training Loss 1.8479 (1.7782)	Training Prec@1 100.000 (99.952)	Training Prec@5 100.000 (99.988)	
2022-03-27 17:11:11,922: ============================================================
2022-03-27 17:12:25,056: time cost, forward:0.018848424384499858, backward:0.044537443117406414, data cost:0.639634292878132 
2022-03-27 17:12:25,057: ============================================================
2022-03-27 17:12:25,058: Epoch 28/38 Batch 5600/7662 eta: 15:59:05.112007	Training Loss 1.7055 (1.7796)	Training Prec@1 100.000 (99.952)	Training Prec@5 100.000 (99.988)	
2022-03-27 17:12:25,058: ============================================================
2022-03-27 17:13:33,032: time cost, forward:0.018846820124117276, backward:0.044506512727417805, data cost:0.6392821249448954 
2022-03-27 17:13:33,033: ============================================================
2022-03-27 17:13:33,033: Epoch 28/38 Batch 5700/7662 eta: 14:50:17.282239	Training Loss 1.9517 (1.7811)	Training Prec@1 99.805 (99.952)	Training Prec@5 100.000 (99.988)	
2022-03-27 17:13:33,033: ============================================================
2022-03-27 17:14:44,148: time cost, forward:0.018883248653303326, backward:0.044504450608747005, data cost:0.6393609053514233 
2022-03-27 17:14:44,149: ============================================================
2022-03-27 17:14:44,150: Epoch 28/38 Batch 5800/7662 eta: 15:30:14.116183	Training Loss 1.9682 (1.7825)	Training Prec@1 99.805 (99.951)	Training Prec@5 99.805 (99.988)	
2022-03-27 17:14:44,150: ============================================================
2022-03-27 17:15:53,361: time cost, forward:0.01893741346088622, backward:0.04453362099375436, data cost:0.6390706585875849 
2022-03-27 17:15:53,361: ============================================================
2022-03-27 17:15:53,362: Epoch 28/38 Batch 5900/7662 eta: 15:04:10.811898	Training Loss 1.7161 (1.7839)	Training Prec@1 100.000 (99.951)	Training Prec@5 100.000 (99.988)	
2022-03-27 17:15:53,362: ============================================================
2022-03-27 17:17:07,423: time cost, forward:0.01896761119077555, backward:0.04453308209913495, data cost:0.6395053563067905 
2022-03-27 17:17:07,426: ============================================================
2022-03-27 17:17:07,428: Epoch 28/38 Batch 6000/7662 eta: 16:06:20.688662	Training Loss 1.8267 (1.7854)	Training Prec@1 99.805 (99.951)	Training Prec@5 100.000 (99.988)	
2022-03-27 17:17:07,428: ============================================================
2022-03-27 17:18:15,605: time cost, forward:0.018951377041477868, backward:0.04449696196046183, data cost:0.6393285883628144 
2022-03-27 17:18:15,605: ============================================================
2022-03-27 17:18:15,605: Epoch 28/38 Batch 6100/7662 eta: 14:48:23.674315	Training Loss 2.0547 (1.7866)	Training Prec@1 100.000 (99.951)	Training Prec@5 100.000 (99.988)	
2022-03-27 17:18:15,606: ============================================================
2022-03-27 17:19:27,410: time cost, forward:0.01894906902144005, backward:0.044483230890506965, data cost:0.6395413284052531 
2022-03-27 17:19:27,411: ============================================================
2022-03-27 17:19:27,411: Epoch 28/38 Batch 6200/7662 eta: 15:34:27.739657	Training Loss 1.7736 (1.7879)	Training Prec@1 100.000 (99.950)	Training Prec@5 100.000 (99.988)	
2022-03-27 17:19:27,411: ============================================================
2022-03-27 17:20:40,631: time cost, forward:0.01897288534561402, backward:0.044517555583524486, data cost:0.6399306196090739 
2022-03-27 17:20:40,633: ============================================================
2022-03-27 17:20:40,633: Epoch 28/38 Batch 6300/7662 eta: 15:51:40.853659	Training Loss 1.6843 (1.7892)	Training Prec@1 100.000 (99.950)	Training Prec@5 100.000 (99.988)	
2022-03-27 17:20:40,634: ============================================================
2022-03-27 17:21:51,559: time cost, forward:0.018987290094300793, backward:0.04447888880898234, data cost:0.640036873117725 
2022-03-27 17:21:51,560: ============================================================
2022-03-27 17:21:51,560: Epoch 28/38 Batch 6400/7662 eta: 15:20:40.168289	Training Loss 2.0407 (1.7906)	Training Prec@1 100.000 (99.950)	Training Prec@5 100.000 (99.987)	
2022-03-27 17:21:51,560: ============================================================
2022-03-27 17:23:02,092: time cost, forward:0.01897904612060913, backward:0.04450279809012929, data cost:0.6399845147723509 
2022-03-27 17:23:02,092: ============================================================
2022-03-27 17:23:02,093: Epoch 28/38 Batch 6500/7662 eta: 15:14:22.254069	Training Loss 1.9206 (1.7921)	Training Prec@1 100.000 (99.950)	Training Prec@5 100.000 (99.987)	
2022-03-27 17:23:02,093: ============================================================
2022-03-27 17:24:12,954: time cost, forward:0.018977352156207713, backward:0.04448930316485136, data cost:0.6400860419940327 
2022-03-27 17:24:12,955: ============================================================
2022-03-27 17:24:12,955: Epoch 28/38 Batch 6600/7662 eta: 15:17:28.410508	Training Loss 1.8917 (1.7934)	Training Prec@1 99.805 (99.949)	Training Prec@5 99.805 (99.987)	
2022-03-27 17:24:12,956: ============================================================
2022-03-27 17:25:23,344: time cost, forward:0.018971611588975354, backward:0.04446261305295811, data cost:0.6401150224101705 
2022-03-27 17:25:23,345: ============================================================
2022-03-27 17:25:23,345: Epoch 28/38 Batch 6700/7662 eta: 15:10:10.376531	Training Loss 2.0069 (1.7948)	Training Prec@1 99.805 (99.949)	Training Prec@5 99.805 (99.987)	
2022-03-27 17:25:23,345: ============================================================
2022-03-27 17:26:31,609: time cost, forward:0.01894815246188162, backward:0.044466423767422, data cost:0.6397263180036583 
2022-03-27 17:26:31,612: ============================================================
2022-03-27 17:26:31,613: Epoch 28/38 Batch 6800/7662 eta: 14:41:35.564906	Training Loss 1.8903 (1.7961)	Training Prec@1 99.805 (99.948)	Training Prec@5 100.000 (99.987)	
2022-03-27 17:26:31,613: ============================================================
2022-03-27 17:27:42,080: time cost, forward:0.018947994489568888, backward:0.044461406509260074, data cost:0.6398011037691346 
2022-03-27 17:27:42,083: ============================================================
2022-03-27 17:27:42,084: Epoch 28/38 Batch 6900/7662 eta: 15:08:52.320584	Training Loss 1.9546 (1.7975)	Training Prec@1 100.000 (99.947)	Training Prec@5 100.000 (99.987)	
2022-03-27 17:27:42,084: ============================================================
2022-03-27 17:28:53,865: time cost, forward:0.018925620583333806, backward:0.04440792500419197, data cost:0.6399995104417339 
2022-03-27 17:28:53,865: ============================================================
2022-03-27 17:28:53,866: Epoch 28/38 Batch 7000/7662 eta: 15:24:35.882130	Training Loss 1.8506 (1.7987)	Training Prec@1 100.000 (99.947)	Training Prec@5 100.000 (99.986)	
2022-03-27 17:28:53,866: ============================================================
2022-03-27 17:30:05,073: time cost, forward:0.018909957782032288, backward:0.04438132970395903, data cost:0.6401887541506421 
2022-03-27 17:30:05,075: ============================================================
2022-03-27 17:30:05,076: Epoch 28/38 Batch 7100/7662 eta: 15:16:01.480491	Training Loss 1.9906 (1.8002)	Training Prec@1 99.805 (99.947)	Training Prec@5 100.000 (99.986)	
2022-03-27 17:30:05,077: ============================================================
2022-03-27 17:31:13,491: time cost, forward:0.018875998380300418, backward:0.04431744995572895, data cost:0.6400146672818078 
2022-03-27 17:31:13,491: ============================================================
2022-03-27 17:31:13,492: Epoch 28/38 Batch 7200/7662 eta: 14:38:57.418172	Training Loss 2.0002 (1.8014)	Training Prec@1 99.805 (99.946)	Training Prec@5 100.000 (99.986)	
2022-03-27 17:31:13,492: ============================================================
2022-03-27 17:32:24,884: time cost, forward:0.018860440431253307, backward:0.04432378688696754, data cost:0.6401700538418884 
2022-03-27 17:32:24,885: ============================================================
2022-03-27 17:32:24,885: Epoch 28/38 Batch 7300/7662 eta: 15:16:00.981881	Training Loss 2.0006 (1.8026)	Training Prec@1 100.000 (99.946)	Training Prec@5 100.000 (99.986)	
2022-03-27 17:32:24,886: ============================================================
2022-03-27 17:33:35,890: time cost, forward:0.018858816224443766, backward:0.04432779051900184, data cost:0.6402345118707604 
2022-03-27 17:33:35,891: ============================================================
2022-03-27 17:33:35,891: Epoch 28/38 Batch 7400/7662 eta: 15:09:51.246427	Training Loss 1.7126 (1.8038)	Training Prec@1 100.000 (99.946)	Training Prec@5 100.000 (99.986)	
2022-03-27 17:33:35,891: ============================================================
2022-03-27 17:34:48,824: time cost, forward:0.018873327619982713, backward:0.044347110852064615, data cost:0.6405229965898733 
2022-03-27 17:34:48,825: ============================================================
2022-03-27 17:34:48,825: Epoch 28/38 Batch 7500/7662 eta: 15:33:21.097944	Training Loss 1.9988 (1.8050)	Training Prec@1 100.000 (99.945)	Training Prec@5 100.000 (99.986)	
2022-03-27 17:34:48,825: ============================================================
2022-03-27 17:36:00,821: time cost, forward:0.018863036893264042, backward:0.04435564913488027, data cost:0.6406116317111985 
2022-03-27 17:36:00,823: ============================================================
2022-03-27 17:36:00,824: Epoch 28/38 Batch 7600/7662 eta: 15:20:10.374723	Training Loss 1.8817 (1.8062)	Training Prec@1 100.000 (99.945)	Training Prec@5 100.000 (99.986)	
2022-03-27 17:36:00,825: ============================================================
2022-03-27 17:36:45,242: Epoch: 28/38 eta: 15:19:25.015862	Training Loss 1.7989 (1.8070)	Training Prec@1 100.000 (99.945)	Training Prec@5 100.000 (99.986)
2022-03-27 17:36:45,242: ============================================================
2022-03-27 17:37:59,399: time cost, forward:0.01996602915754222, backward:0.04762138501562253, data cost:0.6738902222026478 
2022-03-27 17:37:59,402: ============================================================
2022-03-27 17:37:59,404: Epoch 29/38 Batch 100/7662 eta: 15:45:15.692317	Training Loss 1.5571 (1.6555)	Training Prec@1 100.000 (99.963)	Training Prec@5 100.000 (99.990)	
2022-03-27 17:37:59,405: ============================================================
2022-03-27 17:39:09,357: time cost, forward:0.01970568374173725, backward:0.04692863339754804, data cost:0.6518643693109254 
2022-03-27 17:39:09,359: ============================================================
2022-03-27 17:39:09,361: Epoch 29/38 Batch 200/7662 eta: 14:51:01.898017	Training Loss 1.6151 (1.6624)	Training Prec@1 100.000 (99.963)	Training Prec@5 100.000 (99.989)	
2022-03-27 17:39:09,361: ============================================================
2022-03-27 17:40:18,394: time cost, forward:0.01965196316058819, backward:0.04633716994703414, data cost:0.64069318611885 
2022-03-27 17:40:18,399: ============================================================
2022-03-27 17:40:18,401: Epoch 29/38 Batch 300/7662 eta: 14:38:12.033474	Training Loss 1.6985 (1.6661)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.992)	
2022-03-27 17:40:18,403: ============================================================
2022-03-27 17:41:30,111: time cost, forward:0.019754664939746522, backward:0.046286144949738546, data cost:0.6436056469317367 
2022-03-27 17:41:30,113: ============================================================
2022-03-27 17:41:30,114: Epoch 29/38 Batch 400/7662 eta: 15:11:00.634001	Training Loss 1.7578 (1.6708)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.992)	
2022-03-27 17:41:30,115: ============================================================
2022-03-27 17:42:40,352: time cost, forward:0.020087598559851635, backward:0.04646967981525796, data cost:0.6424875703746665 
2022-03-27 17:42:40,353: ============================================================
2022-03-27 17:42:40,353: Epoch 29/38 Batch 500/7662 eta: 14:51:07.116362	Training Loss 1.6193 (1.6723)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.993)	
2022-03-27 17:42:40,354: ============================================================
2022-03-27 17:43:55,797: time cost, forward:0.020130732620697787, backward:0.046590817392568956, data cost:0.648346418132368 
2022-03-27 17:43:55,800: ============================================================
2022-03-27 17:43:55,801: Epoch 29/38 Batch 600/7662 eta: 15:55:55.868931	Training Loss 1.7982 (1.6746)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.993)	
2022-03-27 17:43:55,801: ============================================================
2022-03-27 17:45:07,188: time cost, forward:0.020213833864836904, backward:0.046385022533127505, data cost:0.6490894786278065 
2022-03-27 17:45:07,191: ============================================================
2022-03-27 17:45:07,192: Epoch 29/38 Batch 700/7662 eta: 15:03:20.317661	Training Loss 1.6539 (1.6755)	Training Prec@1 100.000 (99.971)	Training Prec@5 100.000 (99.994)	
2022-03-27 17:45:07,192: ============================================================
2022-03-27 17:46:15,807: time cost, forward:0.02003311782665038, backward:0.046291811146933086, data cost:0.6450210142792092 
2022-03-27 17:46:15,809: ============================================================
2022-03-27 17:46:15,810: Epoch 29/38 Batch 800/7662 eta: 14:27:07.091156	Training Loss 1.8190 (1.6788)	Training Prec@1 99.805 (99.970)	Training Prec@5 100.000 (99.994)	
2022-03-27 17:46:15,811: ============================================================
2022-03-27 17:47:28,082: time cost, forward:0.02007279274063195, backward:0.0462013386247951, data cost:0.6466634724376199 
2022-03-27 17:47:28,083: ============================================================
2022-03-27 17:47:28,083: Epoch 29/38 Batch 900/7662 eta: 15:12:05.984202	Training Loss 1.6321 (1.6813)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.994)	
2022-03-27 17:47:28,083: ============================================================
2022-03-27 17:48:37,297: time cost, forward:0.02012565066745212, backward:0.04611012957117579, data cost:0.6442104307142226 
2022-03-27 17:48:37,298: ============================================================
2022-03-27 17:48:37,298: Epoch 29/38 Batch 1000/7662 eta: 14:32:21.217157	Training Loss 1.7758 (1.6847)	Training Prec@1 99.805 (99.967)	Training Prec@5 99.805 (99.993)	
2022-03-27 17:48:37,298: ============================================================
2022-03-27 17:49:47,613: time cost, forward:0.020244162119552152, backward:0.046014086564526546, data cost:0.6433826501636314 
2022-03-27 17:49:47,613: ============================================================
2022-03-27 17:49:47,613: Epoch 29/38 Batch 1100/7662 eta: 14:45:02.809241	Training Loss 1.6100 (1.6867)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.993)	
2022-03-27 17:49:47,614: ============================================================
2022-03-27 17:50:56,251: time cost, forward:0.020263133593854354, backward:0.0458630272703831, data cost:0.6416013423754237 
2022-03-27 17:50:56,252: ============================================================
2022-03-27 17:50:56,253: Epoch 29/38 Batch 1200/7662 eta: 14:22:48.380002	Training Loss 1.7405 (1.6896)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.993)	
2022-03-27 17:50:56,253: ============================================================
2022-03-27 17:52:08,390: time cost, forward:0.020233959670797323, backward:0.04599887100525137, data cost:0.6424414509530247 
2022-03-27 17:52:08,390: ============================================================
2022-03-27 17:52:08,391: Epoch 29/38 Batch 1300/7662 eta: 15:05:35.022942	Training Loss 1.7150 (1.6926)	Training Prec@1 99.805 (99.966)	Training Prec@5 100.000 (99.993)	
2022-03-27 17:52:08,391: ============================================================
2022-03-27 17:53:20,287: time cost, forward:0.020328153790193766, backward:0.046060240720322165, data cost:0.6429331215728258 
2022-03-27 17:53:20,288: ============================================================
2022-03-27 17:53:20,288: Epoch 29/38 Batch 1400/7662 eta: 15:01:21.994472	Training Loss 1.8078 (1.6960)	Training Prec@1 100.000 (99.965)	Training Prec@5 100.000 (99.993)	
2022-03-27 17:53:20,288: ============================================================
2022-03-27 17:54:32,464: time cost, forward:0.020469492160931996, backward:0.04620007708360546, data cost:0.6428554277566372 
2022-03-27 17:54:32,465: ============================================================
2022-03-27 17:54:32,465: Epoch 29/38 Batch 1500/7662 eta: 15:03:40.088145	Training Loss 1.8445 (1.6986)	Training Prec@1 99.805 (99.964)	Training Prec@5 99.805 (99.992)	
2022-03-27 17:54:32,465: ============================================================
2022-03-27 17:55:42,353: time cost, forward:0.02061812187299794, backward:0.04616696451364867, data cost:0.6423936485125916 
2022-03-27 17:55:42,355: ============================================================
2022-03-27 17:55:42,355: Epoch 29/38 Batch 1600/7662 eta: 14:33:52.189857	Training Loss 1.5774 (1.7012)	Training Prec@1 100.000 (99.964)	Training Prec@5 100.000 (99.992)	
2022-03-27 17:55:42,356: ============================================================
2022-03-27 17:56:52,003: time cost, forward:0.020593951490782792, backward:0.04614623326845489, data cost:0.6416089199373762 
2022-03-27 17:56:52,004: ============================================================
2022-03-27 17:56:52,004: Epoch 29/38 Batch 1700/7662 eta: 14:29:41.672042	Training Loss 1.7520 (1.7037)	Training Prec@1 100.000 (99.965)	Training Prec@5 100.000 (99.992)	
2022-03-27 17:56:52,004: ============================================================
2022-03-27 17:58:05,028: time cost, forward:0.020747606061179483, backward:0.04618698467871691, data cost:0.6424895089622866 
2022-03-27 17:58:05,029: ============================================================
2022-03-27 17:58:05,029: Epoch 29/38 Batch 1800/7662 eta: 15:10:38.240110	Training Loss 1.6950 (1.7052)	Training Prec@1 100.000 (99.965)	Training Prec@5 100.000 (99.992)	
2022-03-27 17:58:05,029: ============================================================
2022-03-27 17:59:14,536: time cost, forward:0.02082474687464806, backward:0.04629382414212661, data cost:0.6410845046673654 
2022-03-27 17:59:14,539: ============================================================
2022-03-27 17:59:14,540: Epoch 29/38 Batch 1900/7662 eta: 14:25:38.531107	Training Loss 1.8787 (1.7086)	Training Prec@1 100.000 (99.964)	Training Prec@5 100.000 (99.992)	
2022-03-27 17:59:14,540: ============================================================
2022-03-27 18:00:25,789: time cost, forward:0.020922463079760707, backward:0.04624653625869942, data cost:0.6413677211043953 
2022-03-27 18:00:25,790: ============================================================
2022-03-27 18:00:25,790: Epoch 29/38 Batch 2000/7662 eta: 14:46:08.273593	Training Loss 1.7819 (1.7109)	Training Prec@1 100.000 (99.964)	Training Prec@5 100.000 (99.992)	
2022-03-27 18:00:25,791: ============================================================
2022-03-27 18:01:36,527: time cost, forward:0.02084290123712795, backward:0.04620656494642224, data cost:0.6415493704126585 
2022-03-27 18:01:36,527: ============================================================
2022-03-27 18:01:36,528: Epoch 29/38 Batch 2100/7662 eta: 14:38:34.171345	Training Loss 1.5989 (1.7133)	Training Prec@1 100.000 (99.964)	Training Prec@5 100.000 (99.992)	
2022-03-27 18:01:36,528: ============================================================
2022-03-27 18:02:50,250: time cost, forward:0.02081687160923894, backward:0.04616341508481111, data cost:0.6423899045365677 
2022-03-27 18:02:50,254: ============================================================
2022-03-27 18:02:50,256: Epoch 29/38 Batch 2200/7662 eta: 15:14:28.468080	Training Loss 1.7713 (1.7164)	Training Prec@1 100.000 (99.964)	Training Prec@5 100.000 (99.992)	
2022-03-27 18:02:50,257: ============================================================
2022-03-27 18:04:00,108: time cost, forward:0.020804111311465773, backward:0.046176600010304825, data cost:0.6422137504766795 
2022-03-27 18:04:00,108: ============================================================
2022-03-27 18:04:00,109: Epoch 29/38 Batch 2300/7662 eta: 14:25:16.027148	Training Loss 1.8821 (1.7198)	Training Prec@1 100.000 (99.964)	Training Prec@5 100.000 (99.992)	
2022-03-27 18:04:00,109: ============================================================
2022-03-27 18:05:10,786: time cost, forward:0.020773472613024185, backward:0.04619434178993572, data cost:0.6420988617165976 
2022-03-27 18:05:10,786: ============================================================
2022-03-27 18:05:10,786: Epoch 29/38 Batch 2400/7662 eta: 14:34:17.775910	Training Loss 1.7190 (1.7222)	Training Prec@1 99.805 (99.964)	Training Prec@5 100.000 (99.992)	
2022-03-27 18:05:10,787: ============================================================
2022-03-27 18:06:18,960: time cost, forward:0.020636596694952394, backward:0.04604337166766731, data cost:0.641255944287505 
2022-03-27 18:06:18,960: ============================================================
2022-03-27 18:06:18,961: Epoch 29/38 Batch 2500/7662 eta: 14:02:11.385571	Training Loss 1.7722 (1.7241)	Training Prec@1 100.000 (99.964)	Training Prec@5 100.000 (99.992)	
2022-03-27 18:06:18,961: ============================================================
2022-03-27 18:07:27,464: time cost, forward:0.02062633790709322, backward:0.04598949266516644, data cost:0.6403669714698337 
2022-03-27 18:07:27,465: ============================================================
2022-03-27 18:07:27,466: Epoch 29/38 Batch 2600/7662 eta: 14:05:07.899772	Training Loss 1.6848 (1.7264)	Training Prec@1 100.000 (99.964)	Training Prec@5 100.000 (99.992)	
2022-03-27 18:07:27,466: ============================================================
2022-03-27 18:08:34,158: time cost, forward:0.020609148611356348, backward:0.04590476049498833, data cost:0.6388243454922213 
2022-03-27 18:08:34,159: ============================================================
2022-03-27 18:08:34,160: Epoch 29/38 Batch 2700/7662 eta: 13:41:41.175408	Training Loss 1.9008 (1.7279)	Training Prec@1 100.000 (99.963)	Training Prec@5 100.000 (99.992)	
2022-03-27 18:08:34,160: ============================================================
2022-03-27 18:09:45,208: time cost, forward:0.020605148013552073, backward:0.045893179940172245, data cost:0.6389090395604087 
2022-03-27 18:09:45,208: ============================================================
2022-03-27 18:09:45,208: Epoch 29/38 Batch 2800/7662 eta: 14:34:08.759871	Training Loss 1.8171 (1.7301)	Training Prec@1 100.000 (99.962)	Training Prec@5 100.000 (99.992)	
2022-03-27 18:09:45,209: ============================================================
2022-03-27 18:10:54,234: time cost, forward:0.020657926314697057, backward:0.045879867497128676, data cost:0.6384396677224461 
2022-03-27 18:10:54,235: ============================================================
2022-03-27 18:10:54,235: Epoch 29/38 Batch 2900/7662 eta: 14:08:06.917433	Training Loss 1.6241 (1.7322)	Training Prec@1 100.000 (99.962)	Training Prec@5 100.000 (99.991)	
2022-03-27 18:10:54,235: ============================================================
2022-03-27 18:12:01,432: time cost, forward:0.02059933534261583, backward:0.04579846490896237, data cost:0.6374465608326504 
2022-03-27 18:12:01,432: ============================================================
2022-03-27 18:12:01,432: Epoch 29/38 Batch 3000/7662 eta: 13:44:31.480420	Training Loss 1.7620 (1.7349)	Training Prec@1 99.805 (99.961)	Training Prec@5 100.000 (99.991)	
2022-03-27 18:12:01,432: ============================================================
2022-03-27 18:13:08,660: time cost, forward:0.020540497617669243, backward:0.045735528600642894, data cost:0.636459336891679 
2022-03-27 18:13:08,661: ============================================================
2022-03-27 18:13:08,661: Epoch 29/38 Batch 3100/7662 eta: 13:43:47.100987	Training Loss 1.6958 (1.7367)	Training Prec@1 100.000 (99.960)	Training Prec@5 100.000 (99.991)	
2022-03-27 18:13:08,661: ============================================================
2022-03-27 18:14:14,060: time cost, forward:0.020482767667946274, backward:0.045739343666441556, data cost:0.634938586313451 
2022-03-27 18:14:14,061: ============================================================
2022-03-27 18:14:14,061: Epoch 29/38 Batch 3200/7662 eta: 13:20:17.432623	Training Loss 1.7312 (1.7383)	Training Prec@1 99.805 (99.959)	Training Prec@5 100.000 (99.991)	
2022-03-27 18:14:14,061: ============================================================
2022-03-27 18:15:24,395: time cost, forward:0.020523683704654894, backward:0.04583352079677668, data cost:0.6348310053872498 
2022-03-27 18:15:24,396: ============================================================
2022-03-27 18:15:24,396: Epoch 29/38 Batch 3300/7662 eta: 14:19:30.417853	Training Loss 1.9192 (1.7404)	Training Prec@1 99.805 (99.959)	Training Prec@5 100.000 (99.991)	
2022-03-27 18:15:24,396: ============================================================
2022-03-27 18:16:25,176: time cost, forward:0.020473625913161535, backward:0.04584487398500546, data cost:0.6320862918785299 
2022-03-27 18:16:25,176: ============================================================
2022-03-27 18:16:25,177: Epoch 29/38 Batch 3400/7662 eta: 12:21:44.282236	Training Loss 1.8397 (1.7422)	Training Prec@1 100.000 (99.959)	Training Prec@5 100.000 (99.990)	
2022-03-27 18:16:25,177: ============================================================
2022-03-27 18:17:31,703: time cost, forward:0.02045333177643389, backward:0.04584811332737524, data cost:0.6310469793503405 
2022-03-27 18:17:31,703: ============================================================
2022-03-27 18:17:31,704: Epoch 29/38 Batch 3500/7662 eta: 13:30:45.004883	Training Loss 1.8651 (1.7442)	Training Prec@1 100.000 (99.959)	Training Prec@5 100.000 (99.990)	
2022-03-27 18:17:31,704: ============================================================
2022-03-27 18:18:40,951: time cost, forward:0.020427148850237737, backward:0.04592258660585955, data cost:0.6308893183596633 
2022-03-27 18:18:40,951: ============================================================
2022-03-27 18:18:40,951: Epoch 29/38 Batch 3600/7662 eta: 14:02:45.330792	Training Loss 1.9225 (1.7463)	Training Prec@1 99.609 (99.958)	Training Prec@5 100.000 (99.990)	
2022-03-27 18:18:40,951: ============================================================
2022-03-27 18:19:50,444: time cost, forward:0.020388674110810672, backward:0.04587150367732691, data cost:0.630686359039414 
2022-03-27 18:19:50,447: ============================================================
2022-03-27 18:19:50,448: Epoch 29/38 Batch 3700/7662 eta: 14:04:37.190194	Training Loss 1.9034 (1.7478)	Training Prec@1 100.000 (99.958)	Training Prec@5 100.000 (99.990)	
2022-03-27 18:19:50,449: ============================================================
2022-03-27 18:20:58,779: time cost, forward:0.020418903394007752, backward:0.045872691431369364, data cost:0.6303733431938354 
2022-03-27 18:20:58,779: ============================================================
2022-03-27 18:20:58,780: Epoch 29/38 Batch 3800/7662 eta: 13:49:20.203031	Training Loss 1.7124 (1.7494)	Training Prec@1 100.000 (99.958)	Training Prec@5 100.000 (99.990)	
2022-03-27 18:20:58,780: ============================================================
2022-03-27 18:22:01,924: time cost, forward:0.02029655376560537, backward:0.045778065040864284, data cost:0.6289526622519795 
2022-03-27 18:22:01,924: ============================================================
2022-03-27 18:22:01,924: Epoch 29/38 Batch 3900/7662 eta: 12:45:19.525289	Training Loss 1.9026 (1.7517)	Training Prec@1 100.000 (99.957)	Training Prec@5 100.000 (99.990)	
2022-03-27 18:22:01,925: ============================================================
2022-03-27 18:23:09,509: time cost, forward:0.020246907215352116, backward:0.04575109487773479, data cost:0.6285060955661927 
2022-03-27 18:23:09,510: ============================================================
2022-03-27 18:23:09,510: Epoch 29/38 Batch 4000/7662 eta: 13:38:01.158262	Training Loss 1.7407 (1.7536)	Training Prec@1 99.805 (99.957)	Training Prec@5 99.805 (99.990)	
2022-03-27 18:23:09,510: ============================================================
2022-03-27 18:24:14,825: time cost, forward:0.02019001216706953, backward:0.04572195668254256, data cost:0.6275566459487316 
2022-03-27 18:24:14,826: ============================================================
2022-03-27 18:24:14,826: Epoch 29/38 Batch 4100/7662 eta: 13:09:28.152646	Training Loss 1.8278 (1.7556)	Training Prec@1 100.000 (99.956)	Training Prec@5 100.000 (99.990)	
2022-03-27 18:24:14,826: ============================================================
2022-03-27 18:25:21,554: time cost, forward:0.020199867508813977, backward:0.04576393387720227, data cost:0.6267303276925066 
2022-03-27 18:25:21,556: ============================================================
2022-03-27 18:25:21,557: Epoch 29/38 Batch 4200/7662 eta: 13:25:26.966358	Training Loss 1.9833 (1.7573)	Training Prec@1 100.000 (99.956)	Training Prec@5 100.000 (99.989)	
2022-03-27 18:25:21,557: ============================================================
2022-03-27 18:26:28,582: time cost, forward:0.020186703436373, backward:0.04570657493181355, data cost:0.6263161132046721 
2022-03-27 18:26:28,583: ============================================================
2022-03-27 18:26:28,583: Epoch 29/38 Batch 4300/7662 eta: 13:27:53.891581	Training Loss 1.8410 (1.7589)	Training Prec@1 100.000 (99.956)	Training Prec@5 100.000 (99.989)	
2022-03-27 18:26:28,583: ============================================================
2022-03-27 18:27:35,372: time cost, forward:0.020159809067455795, backward:0.04565189756786696, data cost:0.6258306894608047 
2022-03-27 18:27:35,373: ============================================================
2022-03-27 18:27:35,374: Epoch 29/38 Batch 4400/7662 eta: 13:23:56.908318	Training Loss 1.8528 (1.7606)	Training Prec@1 100.000 (99.956)	Training Prec@5 100.000 (99.989)	
2022-03-27 18:27:35,374: ============================================================
2022-03-27 18:28:44,470: time cost, forward:0.020173953040013393, backward:0.04569286392858013, data cost:0.6256257773346572 
2022-03-27 18:28:44,471: ============================================================
2022-03-27 18:28:44,471: Epoch 29/38 Batch 4500/7662 eta: 13:50:33.992539	Training Loss 1.9399 (1.7623)	Training Prec@1 100.000 (99.955)	Training Prec@5 100.000 (99.989)	
2022-03-27 18:28:44,472: ============================================================
2022-03-27 18:29:50,594: time cost, forward:0.02017277980737257, backward:0.04566910562890591, data cost:0.6250808809756921 
2022-03-27 18:29:50,594: ============================================================
2022-03-27 18:29:50,594: Epoch 29/38 Batch 4600/7662 eta: 13:13:42.503973	Training Loss 1.8677 (1.7643)	Training Prec@1 100.000 (99.955)	Training Prec@5 100.000 (99.989)	
2022-03-27 18:29:50,595: ============================================================
2022-03-27 18:31:00,101: time cost, forward:0.020148962907371025, backward:0.045707175365836857, data cost:0.6251187096709621 
2022-03-27 18:31:00,101: ============================================================
2022-03-27 18:31:00,102: Epoch 29/38 Batch 4700/7662 eta: 13:53:10.273657	Training Loss 1.8436 (1.7659)	Training Prec@1 99.805 (99.954)	Training Prec@5 100.000 (99.988)	
2022-03-27 18:31:00,102: ============================================================
2022-03-27 18:32:03,553: time cost, forward:0.020085076039769945, backward:0.04561458614672887, data cost:0.6240773811566876 
2022-03-27 18:32:03,554: ============================================================
2022-03-27 18:32:03,554: Epoch 29/38 Batch 4800/7662 eta: 12:39:32.042873	Training Loss 1.7040 (1.7676)	Training Prec@1 99.805 (99.954)	Training Prec@5 99.805 (99.988)	
2022-03-27 18:32:03,554: ============================================================
2022-03-27 18:33:08,186: time cost, forward:0.020053484946471085, backward:0.04558747450802662, data cost:0.6232104506826469 
2022-03-27 18:33:08,186: ============================================================
2022-03-27 18:33:08,187: Epoch 29/38 Batch 4900/7662 eta: 12:52:35.242682	Training Loss 1.8545 (1.7696)	Training Prec@1 100.000 (99.954)	Training Prec@5 100.000 (99.988)	
2022-03-27 18:33:08,187: ============================================================
2022-03-27 18:34:14,508: time cost, forward:0.02012466425703964, backward:0.0456116517130483, data cost:0.6225726162345201 
2022-03-27 18:34:14,508: ============================================================
2022-03-27 18:34:14,509: Epoch 29/38 Batch 5000/7662 eta: 13:11:40.470247	Training Loss 1.7550 (1.7713)	Training Prec@1 100.000 (99.954)	Training Prec@5 100.000 (99.989)	
2022-03-27 18:34:14,509: ============================================================
2022-03-27 18:35:21,889: time cost, forward:0.020113920880243063, backward:0.04558175038907967, data cost:0.622290024548845 
2022-03-27 18:35:21,890: ============================================================
2022-03-27 18:35:21,890: Epoch 29/38 Batch 5100/7662 eta: 13:23:11.678947	Training Loss 1.8515 (1.7730)	Training Prec@1 100.000 (99.953)	Training Prec@5 100.000 (99.988)	
2022-03-27 18:35:21,890: ============================================================
2022-03-27 18:36:26,958: time cost, forward:0.020080810557147315, backward:0.04550925560423126, data cost:0.6216281118427797 
2022-03-27 18:36:26,963: ============================================================
2022-03-27 18:36:26,964: Epoch 29/38 Batch 5200/7662 eta: 12:54:36.202102	Training Loss 1.8729 (1.7747)	Training Prec@1 100.000 (99.952)	Training Prec@5 100.000 (99.988)	
2022-03-27 18:36:26,966: ============================================================
2022-03-27 18:37:33,841: time cost, forward:0.020051016000379458, backward:0.04550953837335504, data cost:0.6212900162283082 
2022-03-27 18:37:33,842: ============================================================
2022-03-27 18:37:33,842: Epoch 29/38 Batch 5300/7662 eta: 13:14:58.373484	Training Loss 1.8383 (1.7763)	Training Prec@1 100.000 (99.952)	Training Prec@5 100.000 (99.988)	
2022-03-27 18:37:33,842: ============================================================
2022-03-27 18:38:41,006: time cost, forward:0.02005490472436415, backward:0.04545424483091351, data cost:0.621056188762486 
2022-03-27 18:38:41,006: ============================================================
2022-03-27 18:38:41,006: Epoch 29/38 Batch 5400/7662 eta: 13:17:15.278296	Training Loss 1.8925 (1.7781)	Training Prec@1 100.000 (99.952)	Training Prec@5 100.000 (99.988)	
2022-03-27 18:38:41,007: ============================================================
2022-03-27 18:39:50,372: time cost, forward:0.020059627670659913, backward:0.0454134018036599, data cost:0.6210387030131688 
2022-03-27 18:39:50,375: ============================================================
2022-03-27 18:39:50,378: Epoch 29/38 Batch 5500/7662 eta: 13:42:17.072046	Training Loss 1.8506 (1.7798)	Training Prec@1 100.000 (99.951)	Training Prec@5 100.000 (99.988)	
2022-03-27 18:39:50,379: ============================================================
2022-03-27 18:40:56,360: time cost, forward:0.020053789432101173, backward:0.04543346787248473, data cost:0.6206687185717046 
2022-03-27 18:40:56,360: ============================================================
2022-03-27 18:40:56,361: Epoch 29/38 Batch 5600/7662 eta: 13:01:02.104794	Training Loss 1.8281 (1.7814)	Training Prec@1 100.000 (99.951)	Training Prec@5 100.000 (99.988)	
2022-03-27 18:40:56,361: ============================================================
2022-03-27 18:42:04,672: time cost, forward:0.020035237758949068, backward:0.045451116469852296, data cost:0.6205876503184837 
2022-03-27 18:42:04,673: ============================================================
2022-03-27 18:42:04,673: Epoch 29/38 Batch 5700/7662 eta: 13:27:27.816310	Training Loss 1.8456 (1.7829)	Training Prec@1 100.000 (99.950)	Training Prec@5 100.000 (99.988)	
2022-03-27 18:42:04,673: ============================================================
2022-03-27 18:43:09,412: time cost, forward:0.019992817268430788, backward:0.04537482622636353, data cost:0.6200304992200177 
2022-03-27 18:43:09,412: ============================================================
2022-03-27 18:43:09,412: Epoch 29/38 Batch 5800/7662 eta: 12:44:08.960395	Training Loss 1.7143 (1.7843)	Training Prec@1 100.000 (99.950)	Training Prec@5 100.000 (99.988)	
2022-03-27 18:43:09,412: ============================================================
2022-03-27 18:44:16,949: time cost, forward:0.01995224426471292, backward:0.045376169335985615, data cost:0.6198326463839992 
2022-03-27 18:44:16,950: ============================================================
2022-03-27 18:44:16,950: Epoch 29/38 Batch 5900/7662 eta: 13:16:03.438446	Training Loss 2.0566 (1.7859)	Training Prec@1 100.000 (99.950)	Training Prec@5 100.000 (99.987)	
2022-03-27 18:44:16,950: ============================================================
2022-03-27 18:45:29,576: time cost, forward:0.019964386093793342, backward:0.04536428867250428, data cost:0.6204356330099613 
2022-03-27 18:45:29,576: ============================================================
2022-03-27 18:45:29,577: Epoch 29/38 Batch 6000/7662 eta: 14:14:49.553922	Training Loss 1.8534 (1.7872)	Training Prec@1 100.000 (99.950)	Training Prec@5 100.000 (99.987)	
2022-03-27 18:45:29,577: ============================================================
2022-03-27 18:46:34,240: time cost, forward:0.019883077170814056, backward:0.04523758861662462, data cost:0.6200841863265993 
2022-03-27 18:46:34,241: ============================================================
2022-03-27 18:46:34,241: Epoch 29/38 Batch 6100/7662 eta: 12:40:02.073229	Training Loss 1.6623 (1.7886)	Training Prec@1 100.000 (99.949)	Training Prec@5 100.000 (99.987)	
2022-03-27 18:46:34,241: ============================================================
2022-03-27 18:47:41,847: time cost, forward:0.01988957800929018, backward:0.04524510040227819, data cost:0.6198730899126497 
2022-03-27 18:47:41,847: ============================================================
2022-03-27 18:47:41,848: Epoch 29/38 Batch 6200/7662 eta: 13:13:29.464099	Training Loss 1.7821 (1.7902)	Training Prec@1 100.000 (99.949)	Training Prec@5 100.000 (99.987)	
2022-03-27 18:47:41,848: ============================================================
2022-03-27 18:48:49,047: time cost, forward:0.01988293515593121, backward:0.04519611052964146, data cost:0.6196181101919375 
2022-03-27 18:48:49,048: ============================================================
2022-03-27 18:48:49,048: Epoch 29/38 Batch 6300/7662 eta: 13:07:35.809443	Training Loss 2.0079 (1.7915)	Training Prec@1 100.000 (99.949)	Training Prec@5 100.000 (99.987)	
2022-03-27 18:48:49,049: ============================================================
2022-03-27 18:49:57,751: time cost, forward:0.019879329947870884, backward:0.045149168682798856, data cost:0.6197734595574631 
2022-03-27 18:49:57,751: ============================================================
2022-03-27 18:49:57,752: Epoch 29/38 Batch 6400/7662 eta: 13:24:04.365287	Training Loss 1.7201 (1.7929)	Training Prec@1 100.000 (99.949)	Training Prec@5 100.000 (99.987)	
2022-03-27 18:49:57,752: ============================================================
2022-03-27 18:51:05,270: time cost, forward:0.019886888197925133, backward:0.04514153301945135, data cost:0.6195972378500829 
2022-03-27 18:51:05,270: ============================================================
2022-03-27 18:51:05,271: Epoch 29/38 Batch 6500/7662 eta: 13:09:04.839707	Training Loss 1.7921 (1.7942)	Training Prec@1 100.000 (99.949)	Training Prec@5 100.000 (99.987)	
2022-03-27 18:51:05,271: ============================================================
2022-03-27 18:52:15,858: time cost, forward:0.01986262599235774, backward:0.045145426144797184, data cost:0.6199217018963333 
2022-03-27 18:52:15,858: ============================================================
2022-03-27 18:52:15,859: Epoch 29/38 Batch 6600/7662 eta: 13:43:46.440383	Training Loss 1.8601 (1.7957)	Training Prec@1 100.000 (99.948)	Training Prec@5 100.000 (99.987)	
2022-03-27 18:52:15,859: ============================================================
2022-03-27 18:53:22,891: time cost, forward:0.019887819808354072, backward:0.0451721508728246, data cost:0.6196351750677496 
2022-03-27 18:53:22,892: ============================================================
2022-03-27 18:53:22,892: Epoch 29/38 Batch 6700/7662 eta: 13:01:10.442326	Training Loss 1.8843 (1.7971)	Training Prec@1 100.000 (99.948)	Training Prec@5 100.000 (99.987)	
2022-03-27 18:53:22,892: ============================================================
2022-03-27 18:54:30,814: time cost, forward:0.019889011192293724, backward:0.04516500784274602, data cost:0.619524770492069 
2022-03-27 18:54:30,815: ============================================================
2022-03-27 18:54:30,815: Epoch 29/38 Batch 6800/7662 eta: 13:10:24.484105	Training Loss 1.8543 (1.7983)	Training Prec@1 100.000 (99.948)	Training Prec@5 100.000 (99.987)	
2022-03-27 18:54:30,815: ============================================================
2022-03-27 18:55:40,449: time cost, forward:0.019885643234562572, backward:0.04515151954039333, data cost:0.6196883108706073 
2022-03-27 18:55:40,449: ============================================================
2022-03-27 18:55:40,450: Epoch 29/38 Batch 6900/7662 eta: 13:29:10.016377	Training Loss 1.9609 (1.7998)	Training Prec@1 100.000 (99.948)	Training Prec@5 100.000 (99.987)	
2022-03-27 18:55:40,450: ============================================================
2022-03-27 18:56:48,078: time cost, forward:0.019895726024193292, backward:0.045153540566165475, data cost:0.6195344275313627 
2022-03-27 18:56:48,079: ============================================================
2022-03-27 18:56:48,080: Epoch 29/38 Batch 7000/7662 eta: 13:04:44.326332	Training Loss 1.9732 (1.8010)	Training Prec@1 100.000 (99.948)	Training Prec@5 100.000 (99.987)	
2022-03-27 18:56:48,080: ============================================================
2022-03-27 18:57:59,806: time cost, forward:0.019909519564183534, backward:0.0451381984672541, data cost:0.6198691349161194 
2022-03-27 18:57:59,809: ============================================================
2022-03-27 18:57:59,810: Epoch 29/38 Batch 7100/7662 eta: 13:51:07.433203	Training Loss 1.8663 (1.8024)	Training Prec@1 100.000 (99.947)	Training Prec@5 100.000 (99.987)	
2022-03-27 18:57:59,810: ============================================================
2022-03-27 18:59:08,027: time cost, forward:0.019925064768356024, backward:0.04517144314993386, data cost:0.6198331550651663 
2022-03-27 18:59:08,031: ============================================================
2022-03-27 18:59:08,032: Epoch 29/38 Batch 7200/7662 eta: 13:09:20.513212	Training Loss 1.8590 (1.8039)	Training Prec@1 100.000 (99.947)	Training Prec@5 100.000 (99.987)	
2022-03-27 18:59:08,033: ============================================================
2022-03-27 19:00:20,035: time cost, forward:0.019946785557186757, backward:0.04521863596751961, data cost:0.6202629989655905 
2022-03-27 19:00:20,036: ============================================================
2022-03-27 19:00:20,036: Epoch 29/38 Batch 7300/7662 eta: 13:51:54.367472	Training Loss 1.8118 (1.8053)	Training Prec@1 100.000 (99.947)	Training Prec@5 100.000 (99.987)	
2022-03-27 19:00:20,036: ============================================================
2022-03-27 19:01:28,688: time cost, forward:0.019924054904344325, backward:0.04518827107616785, data cost:0.6203029544663793 
2022-03-27 19:01:28,689: ============================================================
2022-03-27 19:01:28,689: Epoch 29/38 Batch 7400/7662 eta: 13:12:02.015951	Training Loss 1.8725 (1.8068)	Training Prec@1 100.000 (99.947)	Training Prec@5 100.000 (99.987)	
2022-03-27 19:01:28,689: ============================================================
2022-03-27 19:02:39,309: time cost, forward:0.019937399181147737, backward:0.04523463340771486, data cost:0.6205069302145457 
2022-03-27 19:02:39,310: ============================================================
2022-03-27 19:02:39,310: Epoch 29/38 Batch 7500/7662 eta: 13:33:34.265767	Training Loss 1.8871 (1.8081)	Training Prec@1 100.000 (99.946)	Training Prec@5 100.000 (99.987)	
2022-03-27 19:02:39,311: ============================================================
2022-03-27 19:03:49,769: time cost, forward:0.019936382935257048, backward:0.045239327565386574, data cost:0.620632235855472 
2022-03-27 19:03:49,771: ============================================================
2022-03-27 19:03:49,772: Epoch 29/38 Batch 7600/7662 eta: 13:30:33.046079	Training Loss 1.8450 (1.8093)	Training Prec@1 100.000 (99.946)	Training Prec@5 100.000 (99.987)	
2022-03-27 19:03:49,773: ============================================================
2022-03-27 19:04:37,843: Epoch: 29/38 eta: 13:29:48.655504	Training Loss 1.8372 (1.8100)	Training Prec@1 100.000 (99.946)	Training Prec@5 100.000 (99.986)
2022-03-27 19:04:37,843: ============================================================
2022-03-27 19:05:53,195: time cost, forward:0.018720593115296027, backward:0.04247514888493702, data cost:0.6944382889102204 
2022-03-27 19:05:53,195: ============================================================
2022-03-27 19:05:53,196: Epoch 30/38 Batch 100/7662 eta: 14:24:43.964560	Training Loss 1.7218 (1.6418)	Training Prec@1 100.000 (99.963)	Training Prec@5 100.000 (99.992)	
2022-03-27 19:05:53,196: ============================================================
2022-03-27 19:07:03,779: time cost, forward:0.017640337872145764, backward:0.040790035497004065, data cost:0.6667291279414191 
2022-03-27 19:07:03,780: ============================================================
2022-03-27 19:07:03,781: Epoch 30/38 Batch 200/7662 eta: 13:28:53.630832	Training Loss 1.7605 (1.6278)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.992)	
2022-03-27 19:07:03,782: ============================================================
2022-03-27 19:08:12,523: time cost, forward:0.0178145453284018, backward:0.041554565812433046, data cost:0.6547802602965697 
2022-03-27 19:08:12,523: ============================================================
2022-03-27 19:08:12,524: Epoch 30/38 Batch 300/7662 eta: 13:06:38.339876	Training Loss 1.5767 (1.6233)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.992)	
2022-03-27 19:08:12,524: ============================================================
2022-03-27 19:09:21,123: time cost, forward:0.017869838198324793, backward:0.04169513169386632, data cost:0.6458012603578114 
2022-03-27 19:09:21,128: ============================================================
2022-03-27 19:09:21,130: Epoch 30/38 Batch 400/7662 eta: 13:03:55.098766	Training Loss 1.5478 (1.6251)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.992)	
2022-03-27 19:09:21,131: ============================================================
2022-03-27 19:10:25,927: time cost, forward:0.017593150148410834, backward:0.04170331209599375, data cost:0.6360102411740289 
2022-03-27 19:10:25,927: ============================================================
2022-03-27 19:10:25,927: Epoch 30/38 Batch 500/7662 eta: 12:19:20.142864	Training Loss 1.6216 (1.6219)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.992)	
2022-03-27 19:10:25,927: ============================================================
2022-03-27 19:11:32,195: time cost, forward:0.017869414789648805, backward:0.04187979682260045, data cost:0.6298633712360975 
2022-03-27 19:11:32,198: ============================================================
2022-03-27 19:11:32,198: Epoch 30/38 Batch 600/7662 eta: 12:35:02.078252	Training Loss 1.6602 (1.6187)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.992)	
2022-03-27 19:11:32,199: ============================================================
2022-03-27 19:12:42,644: time cost, forward:0.01807436206310092, backward:0.042285480553841216, data cost:0.631162977355062 
2022-03-27 19:12:42,644: ============================================================
2022-03-27 19:12:42,644: Epoch 30/38 Batch 700/7662 eta: 13:21:25.934241	Training Loss 1.6760 (1.6173)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.991)	
2022-03-27 19:12:42,645: ============================================================
2022-03-27 19:13:50,312: time cost, forward:0.018245250023948088, backward:0.04212074524470056, data cost:0.6290923641978277 
2022-03-27 19:13:50,312: ============================================================
2022-03-27 19:13:50,313: Epoch 30/38 Batch 800/7662 eta: 12:48:42.004687	Training Loss 1.6406 (1.6175)	Training Prec@1 99.805 (99.973)	Training Prec@5 100.000 (99.991)	
2022-03-27 19:13:50,313: ============================================================
2022-03-27 19:14:57,193: time cost, forward:0.018380829967036265, backward:0.042215361080657654, data cost:0.6260009302578461 
2022-03-27 19:14:57,193: ============================================================
2022-03-27 19:14:57,193: Epoch 30/38 Batch 900/7662 eta: 12:38:38.382908	Training Loss 1.7197 (1.6150)	Training Prec@1 99.805 (99.972)	Training Prec@5 100.000 (99.991)	
2022-03-27 19:14:57,194: ============================================================
2022-03-27 19:16:03,844: time cost, forward:0.018414907149963074, backward:0.04241826107074787, data cost:0.6239717383761783 
2022-03-27 19:16:03,844: ============================================================
2022-03-27 19:16:03,845: Epoch 30/38 Batch 1000/7662 eta: 12:34:55.730790	Training Loss 1.5941 (1.6134)	Training Prec@1 100.000 (99.971)	Training Prec@5 100.000 (99.991)	
2022-03-27 19:16:03,845: ============================================================
2022-03-27 19:17:13,042: time cost, forward:0.01838353311505721, backward:0.04249414299920649, data cost:0.6237088937559814 
2022-03-27 19:17:13,050: ============================================================
2022-03-27 19:17:13,053: Epoch 30/38 Batch 1100/7662 eta: 13:02:43.173935	Training Loss 1.5750 (1.6118)	Training Prec@1 100.000 (99.971)	Training Prec@5 100.000 (99.991)	
2022-03-27 19:17:13,056: ============================================================
2022-03-27 19:18:18,880: time cost, forward:0.018316650907629427, backward:0.04237406645544973, data cost:0.6218200724158712 
2022-03-27 19:18:18,884: ============================================================
2022-03-27 19:18:18,886: Epoch 30/38 Batch 1200/7662 eta: 12:23:27.575648	Training Loss 1.6084 (1.6119)	Training Prec@1 100.000 (99.971)	Training Prec@5 100.000 (99.991)	
2022-03-27 19:18:18,887: ============================================================
2022-03-27 19:19:27,856: time cost, forward:0.01840006194727709, backward:0.04255490416834408, data cost:0.6218458914224508 
2022-03-27 19:19:27,857: ============================================================
2022-03-27 19:19:27,858: Epoch 30/38 Batch 1300/7662 eta: 12:57:46.214009	Training Loss 1.4857 (1.6112)	Training Prec@1 100.000 (99.971)	Training Prec@5 100.000 (99.991)	
2022-03-27 19:19:27,859: ============================================================
2022-03-27 19:20:37,863: time cost, forward:0.01839432791354743, backward:0.042885482439064315, data cost:0.623201099440743 
2022-03-27 19:20:37,870: ============================================================
2022-03-27 19:20:37,871: Epoch 30/38 Batch 1400/7662 eta: 13:08:19.899537	Training Loss 1.5117 (1.6100)	Training Prec@1 99.805 (99.970)	Training Prec@5 100.000 (99.991)	
2022-03-27 19:20:37,871: ============================================================
2022-03-27 19:21:48,438: time cost, forward:0.01851449973428941, backward:0.042939365824673316, data cost:0.6243440142625805 
2022-03-27 19:21:48,441: ============================================================
2022-03-27 19:21:48,442: Epoch 30/38 Batch 1500/7662 eta: 13:13:26.375317	Training Loss 1.6023 (1.6090)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.991)	
2022-03-27 19:21:48,443: ============================================================
2022-03-27 19:22:58,474: time cost, forward:0.018522504421231746, backward:0.0428066231296389, data cost:0.6252482332536173 
2022-03-27 19:22:58,475: ============================================================
2022-03-27 19:22:58,475: Epoch 30/38 Batch 1600/7662 eta: 13:06:14.101312	Training Loss 1.5671 (1.6078)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.991)	
2022-03-27 19:22:58,476: ============================================================
2022-03-27 19:24:07,893: time cost, forward:0.0186087652961951, backward:0.042948383945377526, data cost:0.6254166516926515 
2022-03-27 19:24:07,894: ============================================================
2022-03-27 19:24:07,894: Epoch 30/38 Batch 1700/7662 eta: 12:58:10.428454	Training Loss 1.8456 (1.6074)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.991)	
2022-03-27 19:24:07,894: ============================================================
2022-03-27 19:25:14,302: time cost, forward:0.018569582763680356, backward:0.04289391333689751, data cost:0.6240950162176161 
2022-03-27 19:25:14,304: ============================================================
2022-03-27 19:25:14,305: Epoch 30/38 Batch 1800/7662 eta: 12:23:20.751821	Training Loss 1.6549 (1.6070)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.992)	
2022-03-27 19:25:14,306: ============================================================
2022-03-27 19:26:22,983: time cost, forward:0.018508988345780457, backward:0.042893763402062, data cost:0.6240745435707691 
2022-03-27 19:26:22,984: ============================================================
2022-03-27 19:26:22,985: Epoch 30/38 Batch 1900/7662 eta: 12:47:35.923632	Training Loss 1.5658 (1.6069)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.991)	
2022-03-27 19:26:22,985: ============================================================
2022-03-27 19:27:32,856: time cost, forward:0.018572731099169276, backward:0.04292868744915518, data cost:0.624676621634105 
2022-03-27 19:27:32,856: ============================================================
2022-03-27 19:27:32,857: Epoch 30/38 Batch 2000/7662 eta: 12:59:45.641955	Training Loss 1.5847 (1.6065)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.991)	
2022-03-27 19:27:32,857: ============================================================
2022-03-27 19:28:42,547: time cost, forward:0.0185241763963195, backward:0.04302195073764287, data cost:0.625018285762247 
2022-03-27 19:28:42,547: ============================================================
2022-03-27 19:28:42,548: Epoch 30/38 Batch 2100/7662 eta: 12:56:34.733097	Training Loss 1.5745 (1.6064)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.992)	
2022-03-27 19:28:42,548: ============================================================
2022-03-27 19:29:54,617: time cost, forward:0.018575237034775552, backward:0.04308140402547117, data cost:0.6264175689995641 
2022-03-27 19:29:54,618: ============================================================
2022-03-27 19:29:54,618: Epoch 30/38 Batch 2200/7662 eta: 13:21:53.455098	Training Loss 1.6998 (1.6067)	Training Prec@1 99.805 (99.969)	Training Prec@5 99.805 (99.992)	
2022-03-27 19:29:54,618: ============================================================
2022-03-27 19:31:04,678: time cost, forward:0.018563571832863442, backward:0.04307456346323512, data cost:0.6269633170572142 
2022-03-27 19:31:04,679: ============================================================
2022-03-27 19:31:04,679: Epoch 30/38 Batch 2300/7662 eta: 12:58:22.110977	Training Loss 1.5440 (1.6064)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.992)	
2022-03-27 19:31:04,680: ============================================================
2022-03-27 19:32:16,389: time cost, forward:0.01860912346054783, backward:0.04300286244133603, data cost:0.6276944132833095 
2022-03-27 19:32:16,393: ============================================================
2022-03-27 19:32:16,394: Epoch 30/38 Batch 2400/7662 eta: 13:15:32.258517	Training Loss 1.7405 (1.6061)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.992)	
2022-03-27 19:32:16,395: ============================================================
2022-03-27 19:33:27,242: time cost, forward:0.01862932711231465, backward:0.04305767469188603, data cost:0.628698814005888 
2022-03-27 19:33:27,242: ============================================================
2022-03-27 19:33:27,242: Epoch 30/38 Batch 2500/7662 eta: 13:04:45.306032	Training Loss 1.5307 (1.6063)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.992)	
2022-03-27 19:33:27,242: ============================================================
2022-03-27 19:34:36,614: time cost, forward:0.018709746632680567, backward:0.04322269321542926, data cost:0.6285461513479658 
2022-03-27 19:34:36,615: ============================================================
2022-03-27 19:34:36,615: Epoch 30/38 Batch 2600/7662 eta: 12:47:14.990424	Training Loss 1.4253 (1.6063)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.992)	
2022-03-27 19:34:36,615: ============================================================
2022-03-27 19:35:46,502: time cost, forward:0.01881878346856235, backward:0.043382156950847094, data cost:0.6284987668542342 
2022-03-27 19:35:46,502: ============================================================
2022-03-27 19:35:46,503: Epoch 30/38 Batch 2700/7662 eta: 12:51:47.020419	Training Loss 1.6747 (1.6062)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.992)	
2022-03-27 19:35:46,503: ============================================================
2022-03-27 19:37:01,929: time cost, forward:0.018869458031935453, backward:0.0435599126573885, data cost:0.6305045483579973 
2022-03-27 19:37:01,929: ============================================================
2022-03-27 19:37:01,930: Epoch 30/38 Batch 2800/7662 eta: 13:51:41.641543	Training Loss 1.3756 (1.6061)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.992)	
2022-03-27 19:37:01,930: ============================================================
2022-03-27 19:38:18,253: time cost, forward:0.018955887741530997, backward:0.04373769720655838, data cost:0.6326059186487373 
2022-03-27 19:38:18,272: ============================================================
2022-03-27 19:38:18,273: Epoch 30/38 Batch 2900/7662 eta: 14:00:31.528480	Training Loss 1.5928 (1.6056)	Training Prec@1 99.805 (99.970)	Training Prec@5 100.000 (99.992)	
2022-03-27 19:38:18,273: ============================================================
2022-03-27 19:39:29,071: time cost, forward:0.01895701992547524, backward:0.0438006992696245, data cost:0.6328885144255646 
2022-03-27 19:39:29,072: ============================================================
2022-03-27 19:39:29,072: Epoch 30/38 Batch 3000/7662 eta: 12:58:18.515919	Training Loss 1.6162 (1.6057)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.992)	
2022-03-27 19:39:29,072: ============================================================
2022-03-27 19:40:35,817: time cost, forward:0.018901292259903175, backward:0.04373258950441797, data cost:0.6320555164722443 
2022-03-27 19:40:35,817: ============================================================
2022-03-27 19:40:35,818: Epoch 30/38 Batch 3100/7662 eta: 12:12:37.985165	Training Loss 1.6151 (1.6055)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.992)	
2022-03-27 19:40:35,818: ============================================================
2022-03-27 19:41:44,773: time cost, forward:0.018930049567119744, backward:0.0437647451196249, data cost:0.6318019395621355 
2022-03-27 19:41:44,774: ============================================================
2022-03-27 19:41:44,774: Epoch 30/38 Batch 3200/7662 eta: 12:35:44.969724	Training Loss 1.5702 (1.6053)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.992)	
2022-03-27 19:41:44,774: ============================================================
2022-03-27 19:42:52,978: time cost, forward:0.01888469119041607, backward:0.04380949600858015, data cost:0.6313901123909489 
2022-03-27 19:42:52,979: ============================================================
2022-03-27 19:42:52,979: Epoch 30/38 Batch 3300/7662 eta: 12:26:22.750956	Training Loss 1.7363 (1.6055)	Training Prec@1 99.805 (99.969)	Training Prec@5 100.000 (99.992)	
2022-03-27 19:42:52,979: ============================================================
2022-03-27 19:43:58,570: time cost, forward:0.01883624637432048, backward:0.04375147061966629, data cost:0.6301474747990258 
2022-03-27 19:43:58,573: ============================================================
2022-03-27 19:43:58,574: Epoch 30/38 Batch 3400/7662 eta: 11:56:42.942462	Training Loss 1.6316 (1.6056)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.992)	
2022-03-27 19:43:58,574: ============================================================
2022-03-27 19:45:06,851: time cost, forward:0.018783834056194663, backward:0.04372582738145347, data cost:0.6300168530741362 
2022-03-27 19:45:06,853: ============================================================
2022-03-27 19:45:06,854: Epoch 30/38 Batch 3500/7662 eta: 12:24:55.513647	Training Loss 1.7717 (1.6063)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.992)	
2022-03-27 19:45:06,854: ============================================================
2022-03-27 19:46:17,121: time cost, forward:0.01879989382093832, backward:0.043796684782383806, data cost:0.6302234608453325 
2022-03-27 19:46:17,121: ============================================================
2022-03-27 19:46:17,121: Epoch 30/38 Batch 3600/7662 eta: 12:45:26.325385	Training Loss 1.5588 (1.6061)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.992)	
2022-03-27 19:46:17,122: ============================================================
2022-03-27 19:47:27,037: time cost, forward:0.018748618680485264, backward:0.04379529526311664, data cost:0.6304153311281598 
2022-03-27 19:47:27,037: ============================================================
2022-03-27 19:47:27,037: Epoch 30/38 Batch 3700/7662 eta: 12:40:26.420288	Training Loss 1.5153 (1.6057)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.992)	
2022-03-27 19:47:27,037: ============================================================
2022-03-27 19:48:37,300: time cost, forward:0.018737265799477966, backward:0.04385238743104505, data cost:0.6305929563270803 
2022-03-27 19:48:37,300: ============================================================
2022-03-27 19:48:37,301: Epoch 30/38 Batch 3800/7662 eta: 12:43:02.960393	Training Loss 1.4532 (1.6060)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.992)	
2022-03-27 19:48:37,301: ============================================================
2022-03-27 19:49:48,557: time cost, forward:0.018805551908052283, backward:0.044031699885769236, data cost:0.6307851811438593 
2022-03-27 19:49:48,560: ============================================================
2022-03-27 19:49:48,560: Epoch 30/38 Batch 3900/7662 eta: 12:52:40.498017	Training Loss 1.6649 (1.6060)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.992)	
2022-03-27 19:49:48,561: ============================================================
2022-03-27 19:51:00,255: time cost, forward:0.018838834512171134, backward:0.04407256047229047, data cost:0.631112216740556 
2022-03-27 19:51:00,256: ============================================================
2022-03-27 19:51:00,256: Epoch 30/38 Batch 4000/7662 eta: 12:56:12.951892	Training Loss 1.5298 (1.6062)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.992)	
2022-03-27 19:51:00,256: ============================================================
2022-03-27 19:52:10,431: time cost, forward:0.018863940884584797, backward:0.0440539584912507, data cost:0.6313302603021544 
2022-03-27 19:52:10,431: ============================================================
2022-03-27 19:52:10,432: Epoch 30/38 Batch 4100/7662 eta: 12:38:35.295889	Training Loss 1.6078 (1.6067)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.992)	
2022-03-27 19:52:10,432: ============================================================
2022-03-27 19:53:20,065: time cost, forward:0.01888406801916469, backward:0.04407056106445647, data cost:0.6313508882156921 
2022-03-27 19:53:20,066: ============================================================
2022-03-27 19:53:20,066: Epoch 30/38 Batch 4200/7662 eta: 12:31:34.682453	Training Loss 1.5496 (1.6063)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.992)	
2022-03-27 19:53:20,066: ============================================================
2022-03-27 19:54:29,987: time cost, forward:0.018935604743221025, backward:0.04418055510404471, data cost:0.6312654230810371 
2022-03-27 19:54:29,988: ============================================================
2022-03-27 19:54:29,988: Epoch 30/38 Batch 4300/7662 eta: 12:33:30.713781	Training Loss 1.5264 (1.6064)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.992)	
2022-03-27 19:54:29,988: ============================================================
2022-03-27 19:55:41,031: time cost, forward:0.018948519492750955, backward:0.04411018228064778, data cost:0.6316781211479275 
2022-03-27 19:55:41,031: ============================================================
2022-03-27 19:55:41,031: Epoch 30/38 Batch 4400/7662 eta: 12:44:24.875083	Training Loss 1.7113 (1.6063)	Training Prec@1 99.609 (99.969)	Training Prec@5 99.805 (99.992)	
2022-03-27 19:55:41,032: ============================================================
2022-03-27 19:56:52,135: time cost, forward:0.018965893730796105, backward:0.04410557048430467, data cost:0.6319145777406203 
2022-03-27 19:56:52,135: ============================================================
2022-03-27 19:56:52,136: Epoch 30/38 Batch 4500/7662 eta: 12:43:53.165780	Training Loss 1.5673 (1.6064)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.992)	
2022-03-27 19:56:52,136: ============================================================
2022-03-27 19:58:01,451: time cost, forward:0.018978537308389557, backward:0.044114338208551276, data cost:0.6318811155656391 
2022-03-27 19:58:01,452: ============================================================
2022-03-27 19:58:01,452: Epoch 30/38 Batch 4600/7662 eta: 12:23:31.107907	Training Loss 1.5719 (1.6065)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.993)	
2022-03-27 19:58:01,452: ============================================================
2022-03-27 19:59:12,427: time cost, forward:0.01898052114505772, backward:0.04409997324711162, data cost:0.6320878029072582 
2022-03-27 19:59:12,427: ============================================================
2022-03-27 19:59:12,428: Epoch 30/38 Batch 4700/7662 eta: 12:40:08.438776	Training Loss 1.6455 (1.6066)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.993)	
2022-03-27 19:59:12,428: ============================================================
2022-03-27 20:00:22,199: time cost, forward:0.01895958499427536, backward:0.044078654163851046, data cost:0.6322306005824082 
2022-03-27 20:00:22,199: ============================================================
2022-03-27 20:00:22,200: Epoch 30/38 Batch 4800/7662 eta: 12:26:05.011409	Training Loss 1.4965 (1.6067)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.993)	
2022-03-27 20:00:22,200: ============================================================
2022-03-27 20:01:33,233: time cost, forward:0.019025727811456335, backward:0.04417617911342505, data cost:0.6323103713463657 
2022-03-27 20:01:33,233: ============================================================
2022-03-27 20:01:33,234: Epoch 30/38 Batch 4900/7662 eta: 12:38:23.548284	Training Loss 1.4978 (1.6068)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.993)	
2022-03-27 20:01:33,234: ============================================================
2022-03-27 20:02:40,332: time cost, forward:0.019047252367343587, backward:0.04413168595823962, data cost:0.6318169356012469 
2022-03-27 20:02:40,337: ============================================================
2022-03-27 20:02:40,338: Epoch 30/38 Batch 5000/7662 eta: 11:55:18.944030	Training Loss 1.5282 (1.6067)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.993)	
2022-03-27 20:02:40,340: ============================================================
2022-03-27 20:03:49,461: time cost, forward:0.019063469568264907, backward:0.04411174723110285, data cost:0.6317648542560907 
2022-03-27 20:03:49,461: ============================================================
2022-03-27 20:03:49,461: Epoch 30/38 Batch 5100/7662 eta: 12:15:41.878002	Training Loss 1.5808 (1.6066)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.993)	
2022-03-27 20:03:49,462: ============================================================
2022-03-27 20:05:02,767: time cost, forward:0.01908293979217007, backward:0.044176651711967455, data cost:0.632330019672597 
2022-03-27 20:05:02,768: ============================================================
2022-03-27 20:05:02,768: Epoch 30/38 Batch 5200/7662 eta: 12:58:59.621432	Training Loss 1.5181 (1.6065)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.993)	
2022-03-27 20:05:02,768: ============================================================
2022-03-27 20:06:12,224: time cost, forward:0.01909991614569761, backward:0.04417428333234238, data cost:0.6321800050251347 
2022-03-27 20:06:12,228: ============================================================
2022-03-27 20:06:12,229: Epoch 30/38 Batch 5300/7662 eta: 12:16:57.901434	Training Loss 1.6779 (1.6063)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.993)	
2022-03-27 20:06:12,230: ============================================================
2022-03-27 20:07:17,503: time cost, forward:0.01904140650994205, backward:0.044093744161725595, data cost:0.6316210347472528 
2022-03-27 20:07:17,505: ============================================================
2022-03-27 20:07:17,506: Epoch 30/38 Batch 5400/7662 eta: 11:31:29.254437	Training Loss 1.7074 (1.6064)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.993)	
2022-03-27 20:07:17,506: ============================================================
2022-03-27 20:08:26,523: time cost, forward:0.019062809086556998, backward:0.04408038865654962, data cost:0.6314438783725753 
2022-03-27 20:08:26,527: ============================================================
2022-03-27 20:08:26,528: Epoch 30/38 Batch 5500/7662 eta: 12:10:00.846987	Training Loss 1.5546 (1.6065)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.993)	
2022-03-27 20:08:26,530: ============================================================
2022-03-27 20:09:33,254: time cost, forward:0.019054613106590144, backward:0.04402868456873729, data cost:0.6310439194541123 
2022-03-27 20:09:33,255: ============================================================
2022-03-27 20:09:33,255: Epoch 30/38 Batch 5600/7662 eta: 11:44:37.675792	Training Loss 1.4886 (1.6067)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.993)	
2022-03-27 20:09:33,255: ============================================================
2022-03-27 20:10:41,551: time cost, forward:0.01907783095136737, backward:0.04399168991293692, data cost:0.6308505594950011 
2022-03-27 20:10:41,552: ============================================================
2022-03-27 20:10:41,552: Epoch 30/38 Batch 5700/7662 eta: 12:00:04.005521	Training Loss 1.6722 (1.6067)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.993)	
2022-03-27 20:10:41,552: ============================================================
2022-03-27 20:11:54,176: time cost, forward:0.019102005614023986, backward:0.04402632848170939, data cost:0.6313099414649802 
2022-03-27 20:11:54,176: ============================================================
2022-03-27 20:11:54,176: Epoch 30/38 Batch 5800/7662 eta: 12:44:28.715081	Training Loss 1.6215 (1.6068)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.993)	
2022-03-27 20:11:54,177: ============================================================
2022-03-27 20:13:03,552: time cost, forward:0.01910057405755366, backward:0.043975732592854144, data cost:0.631193055361282 
2022-03-27 20:13:03,554: ============================================================
2022-03-27 20:13:03,555: Epoch 30/38 Batch 5900/7662 eta: 12:09:09.119490	Training Loss 1.5921 (1.6071)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.993)	
2022-03-27 20:13:03,555: ============================================================
2022-03-27 20:14:10,616: time cost, forward:0.019107990094792308, backward:0.043964479978650106, data cost:0.6308028047771171 
2022-03-27 20:14:10,619: ============================================================
2022-03-27 20:14:10,620: Epoch 30/38 Batch 6000/7662 eta: 11:43:43.467496	Training Loss 1.5030 (1.6072)	Training Prec@1 99.805 (99.970)	Training Prec@5 100.000 (99.993)	
2022-03-27 20:14:10,621: ============================================================
2022-03-27 20:15:17,221: time cost, forward:0.019113755495866063, backward:0.04393957782757245, data cost:0.6303899978531992 
2022-03-27 20:15:17,222: ============================================================
2022-03-27 20:15:17,222: Epoch 30/38 Batch 6100/7662 eta: 11:37:45.576130	Training Loss 1.5481 (1.6071)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.993)	
2022-03-27 20:15:17,222: ============================================================
2022-03-27 20:16:24,030: time cost, forward:0.019115115888927576, backward:0.043889607743190784, data cost:0.6300522605340929 
2022-03-27 20:16:24,030: ============================================================
2022-03-27 20:16:24,031: Epoch 30/38 Batch 6200/7662 eta: 11:38:48.516975	Training Loss 1.7677 (1.6073)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.993)	
2022-03-27 20:16:24,031: ============================================================
2022-03-27 20:17:33,649: time cost, forward:0.019096212474897487, backward:0.04388618276202124, data cost:0.6299651110053044 
2022-03-27 20:17:33,651: ============================================================
2022-03-27 20:17:33,652: Epoch 30/38 Batch 6300/7662 eta: 12:07:03.669446	Training Loss 1.6440 (1.6072)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.992)	
2022-03-27 20:17:33,653: ============================================================
2022-03-27 20:18:40,940: time cost, forward:0.019054906557157348, backward:0.0438935405333576, data cost:0.6298099344718231 
2022-03-27 20:18:40,941: ============================================================
2022-03-27 20:18:40,941: Epoch 30/38 Batch 6400/7662 eta: 11:41:35.666792	Training Loss 1.5675 (1.6073)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.993)	
2022-03-27 20:18:40,941: ============================================================
2022-03-27 20:19:50,558: time cost, forward:0.019046433211510172, backward:0.04388136331036121, data cost:0.6298521265724583 
2022-03-27 20:19:50,558: ============================================================
2022-03-27 20:19:50,558: Epoch 30/38 Batch 6500/7662 eta: 12:04:42.345523	Training Loss 1.6677 (1.6074)	Training Prec@1 99.805 (99.970)	Training Prec@5 100.000 (99.993)	
2022-03-27 20:19:50,559: ============================================================
2022-03-27 20:20:59,931: time cost, forward:0.019067314831230347, backward:0.04394546301550243, data cost:0.6297553515936465 
2022-03-27 20:20:59,931: ============================================================
2022-03-27 20:20:59,931: Epoch 30/38 Batch 6600/7662 eta: 12:01:00.195275	Training Loss 1.4622 (1.6074)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.993)	
2022-03-27 20:20:59,931: ============================================================
2022-03-27 20:22:07,653: time cost, forward:0.019081349443332316, backward:0.043955472249169014, data cost:0.6294787879274183 
2022-03-27 20:22:07,654: ============================================================
2022-03-27 20:22:07,654: Epoch 30/38 Batch 6700/7662 eta: 11:42:43.502140	Training Loss 1.5129 (1.6076)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.992)	
2022-03-27 20:22:07,654: ============================================================
2022-03-27 20:23:19,467: time cost, forward:0.019066011718063252, backward:0.04398413920581367, data cost:0.6298234725387715 
2022-03-27 20:23:19,468: ============================================================
2022-03-27 20:23:19,468: Epoch 30/38 Batch 6800/7662 eta: 12:23:58.762825	Training Loss 1.6113 (1.6078)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.992)	
2022-03-27 20:23:19,468: ============================================================
2022-03-27 20:24:26,650: time cost, forward:0.019056876235499662, backward:0.04396442223811672, data cost:0.6295219431546896 
2022-03-27 20:24:26,651: ============================================================
2022-03-27 20:24:26,651: Epoch 30/38 Batch 6900/7662 eta: 11:34:53.212546	Training Loss 1.5467 (1.6079)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.992)	
2022-03-27 20:24:26,652: ============================================================
2022-03-27 20:25:35,012: time cost, forward:0.019045123748735696, backward:0.04395274115146986, data cost:0.6293868374051256 
2022-03-27 20:25:35,013: ============================================================
2022-03-27 20:25:35,013: Epoch 30/38 Batch 7000/7662 eta: 11:45:56.377892	Training Loss 1.6788 (1.6081)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.992)	
2022-03-27 20:25:35,013: ============================================================
2022-03-27 20:26:43,371: time cost, forward:0.019046821901875156, backward:0.043948604416084856, data cost:0.6291229492477135 
2022-03-27 20:26:43,372: ============================================================
2022-03-27 20:26:43,372: Epoch 30/38 Batch 7100/7662 eta: 11:44:46.161344	Training Loss 1.5887 (1.6082)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.992)	
2022-03-27 20:26:43,372: ============================================================
2022-03-27 20:27:51,398: time cost, forward:0.019029536202874908, backward:0.043912015999169926, data cost:0.6291016685182741 
2022-03-27 20:27:51,399: ============================================================
2022-03-27 20:27:51,399: Epoch 30/38 Batch 7200/7662 eta: 11:40:12.765892	Training Loss 1.5879 (1.6081)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.992)	
2022-03-27 20:27:51,399: ============================================================
2022-03-27 20:28:59,097: time cost, forward:0.01904579766369271, backward:0.04393256901224797, data cost:0.6288450464906391 
2022-03-27 20:28:59,097: ============================================================
2022-03-27 20:28:59,097: Epoch 30/38 Batch 7300/7662 eta: 11:35:42.084583	Training Loss 1.5940 (1.6081)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.992)	
2022-03-27 20:28:59,097: ============================================================
2022-03-27 20:30:09,581: time cost, forward:0.019031735074924512, backward:0.043981949273501394, data cost:0.6289753216571914 
2022-03-27 20:30:09,581: ============================================================
2022-03-27 20:30:09,581: Epoch 30/38 Batch 7400/7662 eta: 12:03:09.320685	Training Loss 1.5849 (1.6085)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.992)	
2022-03-27 20:30:09,582: ============================================================
2022-03-27 20:31:16,873: time cost, forward:0.019030980514453115, backward:0.04397867704839893, data cost:0.6286876075727842 
2022-03-27 20:31:16,874: ============================================================
2022-03-27 20:31:16,874: Epoch 30/38 Batch 7500/7662 eta: 11:29:17.401769	Training Loss 1.5306 (1.6085)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.992)	
2022-03-27 20:31:16,874: ============================================================
2022-03-27 20:32:24,445: time cost, forward:0.019028777306857023, backward:0.04402716490199243, data cost:0.6284602764861053 
2022-03-27 20:32:24,446: ============================================================
2022-03-27 20:32:24,446: Epoch 30/38 Batch 7600/7662 eta: 11:31:01.332921	Training Loss 1.6449 (1.6087)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.992)	
2022-03-27 20:32:24,446: ============================================================
2022-03-27 20:33:06,003: Epoch: 30/38 eta: 11:30:18.762736	Training Loss 1.5079 (1.6088)	Training Prec@1 99.805 (99.970)	Training Prec@5 100.000 (99.992)
2022-03-27 20:33:06,003: ============================================================
2022-03-27 20:33:06,025: Save Checkpoint...
2022-03-27 20:33:06,026: ============================================================
2022-03-27 20:33:09,845: Save done!
2022-03-27 20:33:09,845: ============================================================
2022-03-27 20:34:21,462: time cost, forward:0.016152461369832356, backward:0.03760677636271775, data cost:0.6629740999202536 
2022-03-27 20:34:21,462: ============================================================
2022-03-27 20:34:21,462: Epoch 31/38 Batch 100/7662 eta: 12:10:26.057783	Training Loss 1.5556 (1.5812)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (100.000)	
2022-03-27 20:34:21,463: ============================================================
2022-03-27 20:35:31,370: time cost, forward:0.017177593767942496, backward:0.04081490890464591, data cost:0.6489150188676077 
2022-03-27 20:35:31,371: ============================================================
2022-03-27 20:35:31,371: Epoch 31/38 Batch 200/7662 eta: 11:51:52.131688	Training Loss 1.5410 (1.5753)	Training Prec@1 99.805 (99.978)	Training Prec@5 100.000 (100.000)	
2022-03-27 20:35:31,371: ============================================================
2022-03-27 20:36:41,210: time cost, forward:0.01830907968374399, backward:0.041212378536977096, data cost:0.641642234795867 
2022-03-27 20:36:41,215: ============================================================
2022-03-27 20:36:41,217: Epoch 31/38 Batch 300/7662 eta: 11:50:03.614693	Training Loss 1.5110 (1.5825)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.996)	
2022-03-27 20:36:41,218: ============================================================
2022-03-27 20:37:47,257: time cost, forward:0.018111772704542728, backward:0.040956932799260416, data cost:0.6329858757200695 
2022-03-27 20:37:47,257: ============================================================
2022-03-27 20:37:47,258: Epoch 31/38 Batch 400/7662 eta: 11:10:16.985234	Training Loss 1.6738 (1.5814)	Training Prec@1 99.805 (99.977)	Training Prec@5 100.000 (99.997)	
2022-03-27 20:37:47,258: ============================================================
2022-03-27 20:38:56,357: time cost, forward:0.018331736027597186, backward:0.041664597027765246, data cost:0.6321493728844102 
2022-03-27 20:38:56,358: ============================================================
2022-03-27 20:38:56,358: Epoch 31/38 Batch 500/7662 eta: 11:40:10.989739	Training Loss 1.6290 (1.5832)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.996)	
2022-03-27 20:38:56,358: ============================================================
2022-03-27 20:40:04,109: time cost, forward:0.01835847378573155, backward:0.04170489112204423, data cost:0.6291898128783364 
2022-03-27 20:40:04,109: ============================================================
2022-03-27 20:40:04,110: Epoch 31/38 Batch 600/7662 eta: 11:25:23.220795	Training Loss 1.5006 (1.5832)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.996)	
2022-03-27 20:40:04,110: ============================================================
2022-03-27 20:41:12,366: time cost, forward:0.01851498688409939, backward:0.041754674161111505, data cost:0.6279375266619507 
2022-03-27 20:41:12,367: ============================================================
2022-03-27 20:41:12,367: Epoch 31/38 Batch 700/7662 eta: 11:29:21.786735	Training Loss 1.5830 (1.5828)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.996)	
2022-03-27 20:41:12,367: ============================================================
2022-03-27 20:42:20,871: time cost, forward:0.018501272487998457, backward:0.04235925752021494, data cost:0.6267483467154569 
2022-03-27 20:42:20,871: ============================================================
2022-03-27 20:42:20,871: Epoch 31/38 Batch 800/7662 eta: 11:30:43.136013	Training Loss 1.5762 (1.5816)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.995)	
2022-03-27 20:42:20,871: ============================================================
2022-03-27 20:43:29,926: time cost, forward:0.01847338039962548, backward:0.04245723553573727, data cost:0.6268751226092074 
2022-03-27 20:43:29,927: ============================================================
2022-03-27 20:43:29,927: Epoch 31/38 Batch 900/7662 eta: 11:35:07.570303	Training Loss 1.7187 (1.5806)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.995)	
2022-03-27 20:43:29,927: ============================================================
2022-03-27 20:44:38,711: time cost, forward:0.01847738809175081, backward:0.042280423867929205, data cost:0.6263289442052832 
2022-03-27 20:44:38,712: ============================================================
2022-03-27 20:44:38,712: Epoch 31/38 Batch 1000/7662 eta: 11:31:15.339086	Training Loss 1.6502 (1.5825)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.995)	
2022-03-27 20:44:38,712: ============================================================
2022-03-27 20:45:48,387: time cost, forward:0.01837677864512061, backward:0.04223598991338506, data cost:0.6277132784918941 
2022-03-27 20:45:48,388: ============================================================
2022-03-27 20:45:48,388: Epoch 31/38 Batch 1100/7662 eta: 11:39:02.816439	Training Loss 1.6980 (1.5836)	Training Prec@1 99.805 (99.974)	Training Prec@5 100.000 (99.994)	
2022-03-27 20:45:48,388: ============================================================
2022-03-27 20:46:54,907: time cost, forward:0.018439125676668118, backward:0.042241068459034366, data cost:0.6251682521304655 
2022-03-27 20:46:54,908: ============================================================
2022-03-27 20:46:54,908: Epoch 31/38 Batch 1200/7662 eta: 11:06:16.487135	Training Loss 1.5798 (1.5848)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.994)	
2022-03-27 20:46:54,908: ============================================================
2022-03-27 20:48:04,344: time cost, forward:0.018548433371375763, backward:0.04225727078362187, data cost:0.6260131800330723 
2022-03-27 20:48:04,344: ============================================================
2022-03-27 20:48:04,345: Epoch 31/38 Batch 1300/7662 eta: 11:34:19.906637	Training Loss 1.6698 (1.5846)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.994)	
2022-03-27 20:48:04,345: ============================================================
2022-03-27 20:49:08,377: time cost, forward:0.018396213277908118, backward:0.04203026562268773, data cost:0.6229506038273123 
2022-03-27 20:49:08,378: ============================================================
2022-03-27 20:49:08,378: Epoch 31/38 Batch 1400/7662 eta: 10:39:14.200877	Training Loss 1.4963 (1.5851)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.994)	
2022-03-27 20:49:08,378: ============================================================
2022-03-27 20:50:18,779: time cost, forward:0.01850437179575609, backward:0.04210005799001499, data cost:0.6240167557358185 
2022-03-27 20:50:18,780: ============================================================
2022-03-27 20:50:18,780: Epoch 31/38 Batch 1500/7662 eta: 11:41:38.155172	Training Loss 1.5769 (1.5853)	Training Prec@1 99.805 (99.974)	Training Prec@5 100.000 (99.994)	
2022-03-27 20:50:18,780: ============================================================
2022-03-27 20:51:25,902: time cost, forward:0.018549179568597866, backward:0.042191172182895455, data cost:0.623005280276997 
2022-03-27 20:51:25,904: ============================================================
2022-03-27 20:51:25,905: Epoch 31/38 Batch 1600/7662 eta: 11:07:51.346661	Training Loss 1.5331 (1.5853)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 20:51:25,906: ============================================================
2022-03-27 20:52:34,394: time cost, forward:0.018651249129467674, backward:0.04232246080098817, data cost:0.6226680318070131 
2022-03-27 20:52:34,395: ============================================================
2022-03-27 20:52:34,395: Epoch 31/38 Batch 1700/7662 eta: 11:20:18.251725	Training Loss 1.5367 (1.5856)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 20:52:34,395: ============================================================
2022-03-27 20:53:43,518: time cost, forward:0.0186313725366004, backward:0.04235098890757282, data cost:0.6226672555023329 
2022-03-27 20:53:43,520: ============================================================
2022-03-27 20:53:43,522: Epoch 31/38 Batch 1800/7662 eta: 11:25:27.973344	Training Loss 1.4545 (1.5856)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 20:53:43,522: ============================================================
2022-03-27 20:54:55,181: time cost, forward:0.018605343601212746, backward:0.04242298413478054, data cost:0.6244016450728286 
2022-03-27 20:54:55,197: ============================================================
2022-03-27 20:54:55,198: Epoch 31/38 Batch 1900/7662 eta: 11:49:33.689054	Training Loss 1.5475 (1.5863)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 20:54:55,199: ============================================================
2022-03-27 20:56:04,233: time cost, forward:0.018585037028211068, backward:0.04262308647419107, data cost:0.624632776588604 
2022-03-27 20:56:04,234: ============================================================
2022-03-27 20:56:04,234: Epoch 31/38 Batch 2000/7662 eta: 11:22:16.630083	Training Loss 1.7573 (1.5865)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 20:56:04,234: ============================================================
2022-03-27 20:57:13,130: time cost, forward:0.018579262560353273, backward:0.04268784020956838, data cost:0.6246606039398905 
2022-03-27 20:57:13,131: ============================================================
2022-03-27 20:57:13,131: Epoch 31/38 Batch 2100/7662 eta: 11:19:44.741336	Training Loss 1.4182 (1.5863)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 20:57:13,131: ============================================================
2022-03-27 20:58:23,568: time cost, forward:0.018546226188343944, backward:0.04275224196905437, data cost:0.6250220651570207 
2022-03-27 20:58:23,573: ============================================================
2022-03-27 20:58:23,574: Epoch 31/38 Batch 2200/7662 eta: 11:33:49.263113	Training Loss 1.5730 (1.5861)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 20:58:23,575: ============================================================
2022-03-27 20:59:34,754: time cost, forward:0.018594555359085833, backward:0.04279853085322503, data cost:0.6260224998178768 
2022-03-27 20:59:34,762: ============================================================
2022-03-27 20:59:34,764: Epoch 31/38 Batch 2300/7662 eta: 11:39:59.761924	Training Loss 1.6207 (1.5866)	Training Prec@1 99.805 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 20:59:34,766: ============================================================
2022-03-27 21:00:43,680: time cost, forward:0.018615621981793715, backward:0.04283549597781119, data cost:0.6262666618590457 
2022-03-27 21:00:43,681: ============================================================
2022-03-27 21:00:43,681: Epoch 31/38 Batch 2400/7662 eta: 11:16:30.576456	Training Loss 1.7389 (1.5873)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:00:43,681: ============================================================
2022-03-27 21:01:55,027: time cost, forward:0.018618189654096503, backward:0.04277893980773462, data cost:0.6272636194522975 
2022-03-27 21:01:55,027: ============================================================
2022-03-27 21:01:55,028: Epoch 31/38 Batch 2500/7662 eta: 11:39:09.776646	Training Loss 1.6124 (1.5873)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:01:55,028: ============================================================
2022-03-27 21:03:02,894: time cost, forward:0.018590389741939415, backward:0.04274947526776914, data cost:0.6268935515450349 
2022-03-27 21:03:02,894: ============================================================
2022-03-27 21:03:02,894: Epoch 31/38 Batch 2600/7662 eta: 11:03:55.608123	Training Loss 1.4597 (1.5876)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:03:02,894: ============================================================
2022-03-27 21:04:09,178: time cost, forward:0.0185148451848576, backward:0.04268980061579475, data cost:0.6258008020725371 
2022-03-27 21:04:09,179: ============================================================
2022-03-27 21:04:09,179: Epoch 31/38 Batch 2700/7662 eta: 10:47:21.085486	Training Loss 1.6336 (1.5877)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:04:09,180: ============================================================
2022-03-27 21:05:16,072: time cost, forward:0.01849540176882238, backward:0.042655897293826774, data cost:0.6254330555342401 
2022-03-27 21:05:16,073: ============================================================
2022-03-27 21:05:16,073: Epoch 31/38 Batch 2800/7662 eta: 10:52:10.660622	Training Loss 1.5712 (1.5875)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:05:16,073: ============================================================
2022-03-27 21:06:21,527: time cost, forward:0.018422980191749556, backward:0.04260908155122187, data cost:0.6243964480959 
2022-03-27 21:06:21,528: ============================================================
2022-03-27 21:06:21,528: Epoch 31/38 Batch 2900/7662 eta: 10:37:03.990768	Training Loss 1.7068 (1.5876)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.992)	
2022-03-27 21:06:21,528: ============================================================
2022-03-27 21:07:29,763: time cost, forward:0.01846121453809595, backward:0.04272913630702727, data cost:0.6240201364480961 
2022-03-27 21:07:29,765: ============================================================
2022-03-27 21:07:29,765: Epoch 31/38 Batch 3000/7662 eta: 11:03:00.017277	Training Loss 1.6924 (1.5883)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:07:29,766: ============================================================
2022-03-27 21:08:39,933: time cost, forward:0.01846246743979243, backward:0.04276576085258353, data cost:0.6244386404166109 
2022-03-27 21:08:39,935: ============================================================
2022-03-27 21:08:39,935: Epoch 31/38 Batch 3100/7662 eta: 11:20:36.771673	Training Loss 1.5135 (1.5887)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:08:39,936: ============================================================
2022-03-27 21:09:53,887: time cost, forward:0.018561512501994757, backward:0.04291258062486091, data cost:0.6259109533440511 
2022-03-27 21:09:53,888: ============================================================
2022-03-27 21:09:53,888: Epoch 31/38 Batch 3200/7662 eta: 11:56:04.611440	Training Loss 1.6600 (1.5886)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:09:53,888: ============================================================
2022-03-27 21:10:58,944: time cost, forward:0.018519244001792685, backward:0.04282962209927599, data cost:0.6245911336732872 
2022-03-27 21:10:58,947: ============================================================
2022-03-27 21:10:58,948: Epoch 31/38 Batch 3300/7662 eta: 10:28:52.325485	Training Loss 1.4859 (1.5885)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:10:58,949: ============================================================
2022-03-27 21:12:08,607: time cost, forward:0.018577498946339987, backward:0.04289319172225373, data cost:0.6247429138564053 
2022-03-27 21:12:08,613: ============================================================
2022-03-27 21:12:08,614: Epoch 31/38 Batch 3400/7662 eta: 11:12:14.601257	Training Loss 1.4865 (1.5890)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:12:08,616: ============================================================
2022-03-27 21:13:13,328: time cost, forward:0.018545088477732966, backward:0.042862231338252406, data cost:0.6238670952833186 
2022-03-27 21:13:13,329: ============================================================
2022-03-27 21:13:13,329: Epoch 31/38 Batch 3500/7662 eta: 10:23:23.617464	Training Loss 1.5287 (1.5887)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:13:13,330: ============================================================
2022-03-27 21:14:23,645: time cost, forward:0.018589020371602687, backward:0.04291498028394016, data cost:0.6240307912458212 
2022-03-27 21:14:23,651: ============================================================
2022-03-27 21:14:23,653: Epoch 31/38 Batch 3600/7662 eta: 11:16:14.021929	Training Loss 1.5673 (1.5886)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:14:23,654: ============================================================
2022-03-27 21:15:33,172: time cost, forward:0.018610767107713734, backward:0.04295812770784723, data cost:0.6243977615014061 
2022-03-27 21:15:33,173: ============================================================
2022-03-27 21:15:33,173: Epoch 31/38 Batch 3700/7662 eta: 11:07:22.013338	Training Loss 1.6385 (1.5885)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:15:33,173: ============================================================
2022-03-27 21:16:39,774: time cost, forward:0.01864041175049021, backward:0.04313405239760923, data cost:0.6235701399559911 
2022-03-27 21:16:39,777: ============================================================
2022-03-27 21:16:39,778: Epoch 31/38 Batch 3800/7662 eta: 10:38:15.708522	Training Loss 1.6943 (1.5887)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:16:39,779: ============================================================
2022-03-27 21:17:49,304: time cost, forward:0.018656372993412492, backward:0.04316571566593222, data cost:0.6237984016082874 
2022-03-27 21:17:49,304: ============================================================
2022-03-27 21:17:49,304: Epoch 31/38 Batch 3900/7662 eta: 11:05:06.371382	Training Loss 1.6279 (1.5889)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:17:49,305: ============================================================
2022-03-27 21:18:59,057: time cost, forward:0.018670352765040626, backward:0.043180388610164475, data cost:0.6238754348297004 
2022-03-27 21:18:59,061: ============================================================
2022-03-27 21:18:59,062: Epoch 31/38 Batch 4000/7662 eta: 11:06:08.696550	Training Loss 1.7315 (1.5891)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:18:59,064: ============================================================
2022-03-27 21:20:04,075: time cost, forward:0.018621271312105916, backward:0.043176032124742934, data cost:0.6231309427055216 
2022-03-27 21:20:04,075: ============================================================
2022-03-27 21:20:04,076: Epoch 31/38 Batch 4100/7662 eta: 10:19:46.010089	Training Loss 1.6611 (1.5892)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:20:04,076: ============================================================
2022-03-27 21:21:12,008: time cost, forward:0.018670042459951693, backward:0.0432313464033686, data cost:0.6228831101099801 
2022-03-27 21:21:12,008: ============================================================
2022-03-27 21:21:12,008: Epoch 31/38 Batch 4200/7662 eta: 10:46:27.599968	Training Loss 1.4435 (1.5893)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:21:12,009: ============================================================
2022-03-27 21:22:20,849: time cost, forward:0.018696930165012428, backward:0.04329378140696428, data cost:0.6227691352686291 
2022-03-27 21:22:20,850: ============================================================
2022-03-27 21:22:20,850: Epoch 31/38 Batch 4300/7662 eta: 10:53:57.620491	Training Loss 1.7512 (1.5894)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:22:20,850: ============================================================
2022-03-27 21:23:29,822: time cost, forward:0.01867152951364762, backward:0.043257053669649624, data cost:0.6229930106117715 
2022-03-27 21:23:29,823: ============================================================
2022-03-27 21:23:29,823: Epoch 31/38 Batch 4400/7662 eta: 10:54:03.655199	Training Loss 1.6848 (1.5898)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:23:29,823: ============================================================
2022-03-27 21:24:40,379: time cost, forward:0.018695431938434235, backward:0.04325977392423468, data cost:0.6233960496343276 
2022-03-27 21:24:40,379: ============================================================
2022-03-27 21:24:40,379: Epoch 31/38 Batch 4500/7662 eta: 11:07:53.772430	Training Loss 1.7181 (1.5899)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:24:40,379: ============================================================
2022-03-27 21:25:49,647: time cost, forward:0.01870376826836042, backward:0.04329149913310901, data cost:0.6234026520789823 
2022-03-27 21:25:49,649: ============================================================
2022-03-27 21:25:49,650: Epoch 31/38 Batch 4600/7662 eta: 10:54:34.262776	Training Loss 1.5649 (1.5899)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:25:49,650: ============================================================
2022-03-27 21:26:56,701: time cost, forward:0.018679348299619515, backward:0.043316485298824044, data cost:0.6230852536937992 
2022-03-27 21:26:56,702: ============================================================
2022-03-27 21:26:56,702: Epoch 31/38 Batch 4700/7662 eta: 10:32:29.637176	Training Loss 1.7473 (1.5906)	Training Prec@1 99.805 (99.972)	Training Prec@5 99.805 (99.993)	
2022-03-27 21:26:56,702: ============================================================
2022-03-27 21:28:07,994: time cost, forward:0.018709202959379025, backward:0.043431237877148046, data cost:0.6235262036050302 
2022-03-27 21:28:07,994: ============================================================
2022-03-27 21:28:07,995: Epoch 31/38 Batch 4800/7662 eta: 11:11:18.090600	Training Loss 1.6443 (1.5910)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:28:07,995: ============================================================
2022-03-27 21:29:16,467: time cost, forward:0.01868384710305271, backward:0.043411820098852034, data cost:0.6234081010473921 
2022-03-27 21:29:16,470: ============================================================
2022-03-27 21:29:16,471: Epoch 31/38 Batch 4900/7662 eta: 10:43:38.205379	Training Loss 1.6758 (1.5912)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:29:16,471: ============================================================
2022-03-27 21:30:25,673: time cost, forward:0.018671200689875524, backward:0.04338117117022342, data cost:0.6236770051935955 
2022-03-27 21:30:25,674: ============================================================
2022-03-27 21:30:25,674: Epoch 31/38 Batch 5000/7662 eta: 10:49:19.634944	Training Loss 1.5848 (1.5913)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:30:25,674: ============================================================
2022-03-27 21:31:34,935: time cost, forward:0.018666116928067668, backward:0.04338874361472495, data cost:0.623776923490286 
2022-03-27 21:31:34,936: ============================================================
2022-03-27 21:31:34,937: Epoch 31/38 Batch 5100/7662 eta: 10:48:43.582208	Training Loss 1.6560 (1.5913)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:31:34,937: ============================================================
2022-03-27 21:32:43,780: time cost, forward:0.01871539583846362, backward:0.043407915325938885, data cost:0.6237290491161724 
2022-03-27 21:32:43,781: ============================================================
2022-03-27 21:32:43,781: Epoch 31/38 Batch 5200/7662 eta: 10:43:39.745210	Training Loss 1.6148 (1.5915)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:32:43,782: ============================================================
2022-03-27 21:33:49,289: time cost, forward:0.018675485226900584, backward:0.043390763393099024, data cost:0.6231657196202578 
2022-03-27 21:33:49,289: ============================================================
2022-03-27 21:33:49,289: Epoch 31/38 Batch 5300/7662 eta: 10:11:22.419912	Training Loss 1.5970 (1.5918)	Training Prec@1 99.805 (99.972)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:33:49,289: ============================================================
2022-03-27 21:35:00,347: time cost, forward:0.018703601430535073, backward:0.04341336911995116, data cost:0.6234574178828864 
2022-03-27 21:35:00,349: ============================================================
2022-03-27 21:35:00,350: Epoch 31/38 Batch 5400/7662 eta: 11:02:00.609804	Training Loss 1.5025 (1.5921)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:35:00,351: ============================================================
2022-03-27 21:36:09,023: time cost, forward:0.01873127961943509, backward:0.0434664211006116, data cost:0.6234291045530035 
2022-03-27 21:36:09,026: ============================================================
2022-03-27 21:36:09,026: Epoch 31/38 Batch 5500/7662 eta: 10:38:39.358373	Training Loss 1.7055 (1.5920)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:36:09,027: ============================================================
2022-03-27 21:37:16,628: time cost, forward:0.018770429018800397, backward:0.04351883212207236, data cost:0.6231778428945867 
2022-03-27 21:37:16,629: ============================================================
2022-03-27 21:37:16,629: Epoch 31/38 Batch 5600/7662 eta: 10:27:32.823348	Training Loss 1.6149 (1.5920)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:37:16,629: ============================================================
2022-03-27 21:38:25,893: time cost, forward:0.01875806992713726, backward:0.04350957600228262, data cost:0.6232993649189713 
2022-03-27 21:38:25,893: ============================================================
2022-03-27 21:38:25,893: Epoch 31/38 Batch 5700/7662 eta: 10:41:48.930857	Training Loss 1.5692 (1.5922)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:38:25,894: ============================================================
2022-03-27 21:39:31,989: time cost, forward:0.018764048943253998, backward:0.043456543271018215, data cost:0.6228989050457818 
2022-03-27 21:39:31,989: ============================================================
2022-03-27 21:39:31,990: Epoch 31/38 Batch 5800/7662 eta: 10:11:21.468576	Training Loss 1.7476 (1.5926)	Training Prec@1 100.000 (99.971)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:39:31,990: ============================================================
2022-03-27 21:40:40,275: time cost, forward:0.018764776342055377, backward:0.043467376854161445, data cost:0.6228258365250215 
2022-03-27 21:40:40,275: ============================================================
2022-03-27 21:40:40,276: Epoch 31/38 Batch 5900/7662 eta: 10:30:28.368352	Training Loss 1.6265 (1.5929)	Training Prec@1 100.000 (99.971)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:40:40,276: ============================================================
2022-03-27 21:41:52,104: time cost, forward:0.018784935344435965, backward:0.0435962239430932, data cost:0.6231982765207292 
2022-03-27 21:41:52,104: ============================================================
2022-03-27 21:41:52,104: Epoch 31/38 Batch 6000/7662 eta: 11:01:59.152926	Training Loss 1.6073 (1.5930)	Training Prec@1 99.805 (99.971)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:41:52,105: ============================================================
2022-03-27 21:42:59,215: time cost, forward:0.018777897991612613, backward:0.0435628735798268, data cost:0.6228377944153828 
2022-03-27 21:42:59,220: ============================================================
2022-03-27 21:42:59,222: Epoch 31/38 Batch 6100/7662 eta: 10:17:26.410653	Training Loss 1.5976 (1.5931)	Training Prec@1 100.000 (99.971)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:42:59,223: ============================================================
2022-03-27 21:44:06,631: time cost, forward:0.018783083652792333, backward:0.04356940651463009, data cost:0.6226390620781003 
2022-03-27 21:44:06,633: ============================================================
2022-03-27 21:44:06,634: Epoch 31/38 Batch 6200/7662 eta: 10:19:02.002875	Training Loss 1.6293 (1.5933)	Training Prec@1 100.000 (99.971)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:44:06,634: ============================================================
2022-03-27 21:45:14,296: time cost, forward:0.01881007626617233, backward:0.04360715024602623, data cost:0.6225426484713726 
2022-03-27 21:45:14,298: ============================================================
2022-03-27 21:45:14,299: Epoch 31/38 Batch 6300/7662 eta: 10:20:14.017285	Training Loss 1.7455 (1.5936)	Training Prec@1 100.000 (99.971)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:45:14,300: ============================================================
2022-03-27 21:46:22,835: time cost, forward:0.01884002010418784, backward:0.04360129908111472, data cost:0.6224994591240361 
2022-03-27 21:46:22,835: ============================================================
2022-03-27 21:46:22,836: Epoch 31/38 Batch 6400/7662 eta: 10:27:04.562494	Training Loss 1.4758 (1.5939)	Training Prec@1 100.000 (99.971)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:46:22,836: ============================================================
2022-03-27 21:47:30,925: time cost, forward:0.018857871666195247, backward:0.043616811721797065, data cost:0.6223888865322824 
2022-03-27 21:47:30,925: ============================================================
2022-03-27 21:47:30,926: Epoch 31/38 Batch 6500/7662 eta: 10:21:51.350676	Training Loss 1.5868 (1.5939)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:47:30,926: ============================================================
2022-03-27 21:48:40,290: time cost, forward:0.018880182440524067, backward:0.04358699911018992, data cost:0.6223656717150984 
2022-03-27 21:48:40,292: ============================================================
2022-03-27 21:48:40,293: Epoch 31/38 Batch 6600/7662 eta: 10:32:21.775763	Training Loss 1.6210 (1.5942)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:48:40,294: ============================================================
2022-03-27 21:49:48,682: time cost, forward:0.018877491664131964, backward:0.043604498390725055, data cost:0.6224492377426255 
2022-03-27 21:49:48,682: ============================================================
2022-03-27 21:49:48,683: Epoch 31/38 Batch 6700/7662 eta: 10:22:18.698310	Training Loss 1.5391 (1.5947)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:49:48,683: ============================================================
2022-03-27 21:50:55,101: time cost, forward:0.018851465855578953, backward:0.043548609933742335, data cost:0.6220843395006483 
2022-03-27 21:50:55,102: ============================================================
2022-03-27 21:50:55,102: Epoch 31/38 Batch 6800/7662 eta: 10:03:16.673306	Training Loss 1.6086 (1.5948)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:50:55,102: ============================================================
2022-03-27 21:52:03,059: time cost, forward:0.018873171316296972, backward:0.04354407621788139, data cost:0.6220952777140969 
2022-03-27 21:52:03,060: ============================================================
2022-03-27 21:52:03,060: Epoch 31/38 Batch 6900/7662 eta: 10:16:07.165496	Training Loss 1.6121 (1.5948)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:52:03,060: ============================================================
2022-03-27 21:53:11,151: time cost, forward:0.018873543070970153, backward:0.04354193578840818, data cost:0.6220259814624157 
2022-03-27 21:53:11,151: ============================================================
2022-03-27 21:53:11,152: Epoch 31/38 Batch 7000/7662 eta: 10:16:11.667281	Training Loss 1.6819 (1.5950)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:53:11,152: ============================================================
2022-03-27 21:54:18,534: time cost, forward:0.018888253731733647, backward:0.043557210612723586, data cost:0.6217896649830441 
2022-03-27 21:54:18,534: ============================================================
2022-03-27 21:54:18,535: Epoch 31/38 Batch 7100/7662 eta: 10:08:39.534605	Training Loss 1.6610 (1.5952)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:54:18,535: ============================================================
2022-03-27 21:55:25,686: time cost, forward:0.018870861037834964, backward:0.04353242702725232, data cost:0.6216650606609249 
2022-03-27 21:55:25,687: ============================================================
2022-03-27 21:55:25,687: Epoch 31/38 Batch 7200/7662 eta: 10:05:27.404301	Training Loss 1.6330 (1.5953)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:55:25,687: ============================================================
2022-03-27 21:56:36,920: time cost, forward:0.01889437668159214, backward:0.04354164449788721, data cost:0.621991792726654 
2022-03-27 21:56:36,920: ============================================================
2022-03-27 21:56:36,920: Epoch 31/38 Batch 7300/7662 eta: 10:41:03.797223	Training Loss 1.6282 (1.5953)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:56:36,920: ============================================================
2022-03-27 21:57:45,564: time cost, forward:0.018910369481214207, backward:0.04354141608881522, data cost:0.6219778800110572 
2022-03-27 21:57:45,565: ============================================================
2022-03-27 21:57:45,565: Epoch 31/38 Batch 7400/7662 eta: 10:16:37.514684	Training Loss 1.6263 (1.5955)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:57:45,565: ============================================================
2022-03-27 21:58:52,039: time cost, forward:0.01893440916277851, backward:0.04353289684306337, data cost:0.6216881803583028 
2022-03-27 21:58:52,039: ============================================================
2022-03-27 21:58:52,039: Epoch 31/38 Batch 7500/7662 eta: 9:56:01.042779	Training Loss 1.6322 (1.5957)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:58:52,039: ============================================================
2022-03-27 21:59:59,031: time cost, forward:0.01894318836270892, backward:0.043518913123211996, data cost:0.6214871780545104 
2022-03-27 21:59:59,031: ============================================================
2022-03-27 21:59:59,031: Epoch 31/38 Batch 7600/7662 eta: 9:59:32.766757	Training Loss 1.5859 (1.5959)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.993)	
2022-03-27 21:59:59,032: ============================================================
2022-03-27 22:00:42,954: Epoch: 31/38 eta: 9:58:50.561712	Training Loss 1.6756 (1.5960)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.993)
2022-03-27 22:00:42,954: ============================================================
2022-03-27 22:00:43,027: Save Checkpoint...
2022-03-27 22:00:43,028: ============================================================
2022-03-27 22:00:45,136: Save done!
2022-03-27 22:00:45,137: ============================================================
2022-03-27 22:01:52,837: time cost, forward:0.015983795878863095, backward:0.04120304126932164, data cost:0.6214362611674299 
2022-03-27 22:01:52,837: ============================================================
2022-03-27 22:01:52,838: Epoch 32/38 Batch 100/7662 eta: 10:03:44.778482	Training Loss 1.6320 (1.5750)	Training Prec@1 99.805 (99.978)	Training Prec@5 100.000 (99.992)	
2022-03-27 22:01:52,838: ============================================================
2022-03-27 22:03:03,271: time cost, forward:0.016249843578242777, backward:0.04114429315729956, data cost:0.6320062558255602 
2022-03-27 22:03:03,274: ============================================================
2022-03-27 22:03:03,275: Epoch 32/38 Batch 200/7662 eta: 10:27:18.062566	Training Loss 1.5019 (1.5790)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.992)	
2022-03-27 22:03:03,276: ============================================================
2022-03-27 22:04:12,160: time cost, forward:0.01648758885055083, backward:0.04188250060065534, data cost:0.6310466069441575 
2022-03-27 22:04:12,162: ============================================================
2022-03-27 22:04:12,162: Epoch 32/38 Batch 300/7662 eta: 10:12:20.997720	Training Loss 1.5238 (1.5721)	Training Prec@1 100.000 (99.971)	Training Prec@5 100.000 (99.992)	
2022-03-27 22:04:12,162: ============================================================
2022-03-27 22:05:21,892: time cost, forward:0.017155046749832037, backward:0.042777442095572486, data cost:0.629662921852934 
2022-03-27 22:05:21,897: ============================================================
2022-03-27 22:05:21,899: Epoch 32/38 Batch 400/7662 eta: 10:18:44.029567	Training Loss 1.7378 (1.5731)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 22:05:21,900: ============================================================
2022-03-27 22:06:34,142: time cost, forward:0.017602496252270165, backward:0.043478871156314096, data cost:0.6357721465384076 
2022-03-27 22:06:34,144: ============================================================
2022-03-27 22:06:34,146: Epoch 32/38 Batch 500/7662 eta: 10:39:48.453574	Training Loss 1.5004 (1.5727)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.993)	
2022-03-27 22:06:34,146: ============================================================
2022-03-27 22:07:44,273: time cost, forward:0.01814176721843535, backward:0.043912558006324834, data cost:0.6350944571582622 
2022-03-27 22:07:44,274: ============================================================
2022-03-27 22:07:44,274: Epoch 32/38 Batch 600/7662 eta: 10:19:52.800563	Training Loss 1.5291 (1.5724)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-27 22:07:44,274: ============================================================
2022-03-27 22:08:53,624: time cost, forward:0.018176741524997868, backward:0.04374780845914958, data cost:0.6344373284150261 
2022-03-27 22:08:53,629: ============================================================
2022-03-27 22:08:53,630: Epoch 32/38 Batch 700/7662 eta: 10:11:53.245571	Training Loss 1.8544 (1.5710)	Training Prec@1 99.805 (99.974)	Training Prec@5 100.000 (99.993)	
2022-03-27 22:08:53,632: ============================================================
2022-03-27 22:10:02,019: time cost, forward:0.01827040124446788, backward:0.04380005799485685, data cost:0.6328476513730122 
2022-03-27 22:10:02,020: ============================================================
2022-03-27 22:10:02,020: Epoch 32/38 Batch 800/7662 eta: 10:02:14.116176	Training Loss 1.5385 (1.5696)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.993)	
2022-03-27 22:10:02,020: ============================================================
2022-03-27 22:11:12,183: time cost, forward:0.018535310885267078, backward:0.04405542634618163, data cost:0.6321447900723297 
2022-03-27 22:11:12,185: ============================================================
2022-03-27 22:11:12,185: Epoch 32/38 Batch 900/7662 eta: 10:16:41.515747	Training Loss 1.5149 (1.5704)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.992)	
2022-03-27 22:11:12,185: ============================================================
2022-03-27 22:12:19,207: time cost, forward:0.018587608117837686, backward:0.04400280836943511, data cost:0.6297385783286186 
2022-03-27 22:12:19,208: ============================================================
2022-03-27 22:12:19,209: Epoch 32/38 Batch 1000/7662 eta: 9:47:57.872039	Training Loss 1.6917 (1.5721)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.991)	
2022-03-27 22:12:19,209: ============================================================
2022-03-27 22:13:30,407: time cost, forward:0.01868568039461089, backward:0.04413629077151214, data cost:0.6314424559460432 
2022-03-27 22:13:30,409: ============================================================
2022-03-27 22:13:30,409: Epoch 32/38 Batch 1100/7662 eta: 10:23:25.152370	Training Loss 1.7412 (1.5719)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.991)	
2022-03-27 22:13:30,409: ============================================================
2022-03-27 22:14:40,494: time cost, forward:0.018703606249989818, backward:0.044179492438207374, data cost:0.6312054655172111 
2022-03-27 22:14:40,495: ============================================================
2022-03-27 22:14:40,496: Epoch 32/38 Batch 1200/7662 eta: 10:12:29.859238	Training Loss 1.5234 (1.5726)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.992)	
2022-03-27 22:14:40,496: ============================================================
2022-03-27 22:15:46,895: time cost, forward:0.01871985669682997, backward:0.04431996114259504, data cost:0.6293303103883786 
2022-03-27 22:15:46,895: ============================================================
2022-03-27 22:15:46,896: Epoch 32/38 Batch 1300/7662 eta: 9:39:10.481351	Training Loss 1.6112 (1.5729)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.992)	
2022-03-27 22:15:46,896: ============================================================
2022-03-27 22:16:56,671: time cost, forward:0.01882882336363612, backward:0.04433548032939221, data cost:0.6293238824908438 
2022-03-27 22:16:56,672: ============================================================
2022-03-27 22:16:56,672: Epoch 32/38 Batch 1400/7662 eta: 10:07:27.550152	Training Loss 1.5140 (1.5738)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.992)	
2022-03-27 22:16:56,672: ============================================================
2022-03-27 22:18:05,404: time cost, forward:0.01875144231311475, backward:0.04421674227062426, data cost:0.6289527384418897 
2022-03-27 22:18:05,407: ============================================================
2022-03-27 22:18:05,408: Epoch 32/38 Batch 1500/7662 eta: 9:57:15.173424	Training Loss 1.6054 (1.5732)	Training Prec@1 99.805 (99.973)	Training Prec@5 99.805 (99.992)	
2022-03-27 22:18:05,408: ============================================================
2022-03-27 22:19:15,610: time cost, forward:0.01868416727744765, backward:0.04420272941660926, data cost:0.6293296171323145 
2022-03-27 22:19:15,613: ============================================================
2022-03-27 22:19:15,614: Epoch 32/38 Batch 1600/7662 eta: 10:08:51.867693	Training Loss 1.5262 (1.5738)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.992)	
2022-03-27 22:19:15,615: ============================================================
2022-03-27 22:20:26,462: time cost, forward:0.018808621248825638, backward:0.04439402735184192, data cost:0.6303334499963106 
2022-03-27 22:20:26,462: ============================================================
2022-03-27 22:20:26,462: Epoch 32/38 Batch 1700/7662 eta: 10:13:15.196837	Training Loss 1.5759 (1.5745)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 22:20:26,462: ============================================================
2022-03-27 22:21:33,805: time cost, forward:0.01870329675573717, backward:0.04436385094821287, data cost:0.6290910583260724 
2022-03-27 22:21:33,806: ============================================================
2022-03-27 22:21:33,806: Epoch 32/38 Batch 1800/7662 eta: 9:41:47.596108	Training Loss 1.5972 (1.5747)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 22:21:33,806: ============================================================
2022-03-27 22:22:40,423: time cost, forward:0.01860566551023687, backward:0.044226687980238044, data cost:0.6280967555214317 
2022-03-27 22:22:40,424: ============================================================
2022-03-27 22:22:40,424: Epoch 32/38 Batch 1900/7662 eta: 9:34:24.872148	Training Loss 1.5953 (1.5754)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.992)	
2022-03-27 22:22:40,424: ============================================================
2022-03-27 22:23:51,378: time cost, forward:0.01866527281146219, backward:0.044293756184427664, data cost:0.6284084716041187 
2022-03-27 22:23:51,397: ============================================================
2022-03-27 22:23:51,399: Epoch 32/38 Batch 2000/7662 eta: 10:10:47.253892	Training Loss 1.6114 (1.5753)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.992)	
2022-03-27 22:23:51,399: ============================================================
2022-03-27 22:25:00,145: time cost, forward:0.018563725143003713, backward:0.0441232591995232, data cost:0.6284490314309173 
2022-03-27 22:25:00,147: ============================================================
2022-03-27 22:25:00,148: Epoch 32/38 Batch 2100/7662 eta: 9:50:30.154859	Training Loss 1.5380 (1.5757)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 22:25:00,148: ============================================================
2022-03-27 22:26:07,067: time cost, forward:0.018579660409577817, backward:0.044162265275380135, data cost:0.627737217244369 
2022-03-27 22:26:07,068: ============================================================
2022-03-27 22:26:07,068: Epoch 32/38 Batch 2200/7662 eta: 9:33:40.762640	Training Loss 1.6294 (1.5754)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 22:26:07,069: ============================================================
2022-03-27 22:27:13,817: time cost, forward:0.01862275450060605, backward:0.04424148043532535, data cost:0.6265250807899452 
2022-03-27 22:27:13,817: ============================================================
2022-03-27 22:27:13,818: Epoch 32/38 Batch 2300/7662 eta: 9:31:05.688166	Training Loss 1.5044 (1.5768)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 22:27:13,818: ============================================================
2022-03-27 22:28:20,414: time cost, forward:0.018588711689690243, backward:0.04421887680012368, data cost:0.6255503798982113 
2022-03-27 22:28:20,414: ============================================================
2022-03-27 22:28:20,415: Epoch 32/38 Batch 2400/7662 eta: 9:28:40.964584	Training Loss 1.6053 (1.5768)	Training Prec@1 99.805 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 22:28:20,415: ============================================================
2022-03-27 22:29:27,963: time cost, forward:0.018580273085949468, backward:0.04412250282192955, data cost:0.625047356570039 
2022-03-27 22:29:27,963: ============================================================
2022-03-27 22:29:27,963: Epoch 32/38 Batch 2500/7662 eta: 9:35:41.068879	Training Loss 1.6215 (1.5778)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 22:29:27,964: ============================================================
2022-03-27 22:30:35,131: time cost, forward:0.018552950135833166, backward:0.04406170149682439, data cost:0.6243905438602589 
2022-03-27 22:30:35,133: ============================================================
2022-03-27 22:30:35,134: Epoch 32/38 Batch 2600/7662 eta: 9:31:20.375993	Training Loss 1.7147 (1.5776)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 22:30:35,135: ============================================================
2022-03-27 22:31:46,244: time cost, forward:0.018630001093555972, backward:0.04420249097300442, data cost:0.625072970307284 
2022-03-27 22:31:46,244: ============================================================
2022-03-27 22:31:46,245: Epoch 32/38 Batch 2700/7662 eta: 10:03:40.479689	Training Loss 1.5900 (1.5781)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 22:31:46,245: ============================================================
2022-03-27 22:32:55,218: time cost, forward:0.0186138502313819, backward:0.04419068925591101, data cost:0.625137963010482 
2022-03-27 22:32:55,219: ============================================================
2022-03-27 22:32:55,219: Epoch 32/38 Batch 2800/7662 eta: 9:44:22.910951	Training Loss 1.5282 (1.5788)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 22:32:55,219: ============================================================
2022-03-27 22:34:04,011: time cost, forward:0.01860270363661946, backward:0.044025318916191845, data cost:0.6252631627925308 
2022-03-27 22:34:04,012: ============================================================
2022-03-27 22:34:04,012: Epoch 32/38 Batch 2900/7662 eta: 9:41:42.146927	Training Loss 1.5862 (1.5790)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 22:34:04,012: ============================================================
2022-03-27 22:35:11,341: time cost, forward:0.018587508174569337, backward:0.04398429914489115, data cost:0.6247975793668691 
2022-03-27 22:35:11,342: ============================================================
2022-03-27 22:35:11,342: Epoch 32/38 Batch 3000/7662 eta: 9:28:12.657010	Training Loss 1.5605 (1.5792)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.993)	
2022-03-27 22:35:11,342: ============================================================
2022-03-27 22:36:17,781: time cost, forward:0.018562168719576957, backward:0.04391165885974531, data cost:0.6240897519467684 
2022-03-27 22:36:17,783: ============================================================
2022-03-27 22:36:17,784: Epoch 32/38 Batch 3100/7662 eta: 9:19:36.436583	Training Loss 1.5085 (1.5797)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 22:36:17,786: ============================================================
2022-03-27 22:37:30,225: time cost, forward:0.01862368005333412, backward:0.04397585526895955, data cost:0.6251244752919088 
2022-03-27 22:37:30,225: ============================================================
2022-03-27 22:37:30,226: Epoch 32/38 Batch 3200/7662 eta: 10:08:55.899238	Training Loss 1.5872 (1.5803)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.993)	
2022-03-27 22:37:30,226: ============================================================
2022-03-27 22:38:37,955: time cost, forward:0.018577726438718335, backward:0.0439045440792929, data cost:0.6247786970418957 
2022-03-27 22:38:37,957: ============================================================
2022-03-27 22:38:37,958: Epoch 32/38 Batch 3300/7662 eta: 9:28:12.826652	Training Loss 1.6886 (1.5807)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.993)	
2022-03-27 22:38:37,958: ============================================================
2022-03-27 22:39:44,845: time cost, forward:0.018560742728673, backward:0.04376561012503749, data cost:0.6244718493977586 
2022-03-27 22:39:44,846: ============================================================
2022-03-27 22:39:44,846: Epoch 32/38 Batch 3400/7662 eta: 9:20:01.383946	Training Loss 1.8039 (1.5810)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.994)	
2022-03-27 22:39:44,846: ============================================================
2022-03-27 22:40:53,459: time cost, forward:0.01854377898123306, backward:0.043730093023033614, data cost:0.6244147925010304 
2022-03-27 22:40:53,459: ============================================================
2022-03-27 22:40:53,460: Epoch 32/38 Batch 3500/7662 eta: 9:33:19.509290	Training Loss 1.5171 (1.5810)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.993)	
2022-03-27 22:40:53,460: ============================================================
2022-03-27 22:42:02,825: time cost, forward:0.018517954079897477, backward:0.0436714349372018, data cost:0.6246606869709495 
2022-03-27 22:42:02,826: ============================================================
2022-03-27 22:42:02,826: Epoch 32/38 Batch 3600/7662 eta: 9:38:27.409291	Training Loss 1.5731 (1.5813)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.993)	
2022-03-27 22:42:02,826: ============================================================
2022-03-27 22:43:10,672: time cost, forward:0.018527600532546176, backward:0.04371937631626134, data cost:0.6242965519444367 
2022-03-27 22:43:10,673: ============================================================
2022-03-27 22:43:10,673: Epoch 32/38 Batch 3700/7662 eta: 9:24:39.274742	Training Loss 1.6659 (1.5816)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.993)	
2022-03-27 22:43:10,673: ============================================================
2022-03-27 22:44:18,040: time cost, forward:0.018510007456623588, backward:0.043620902822343384, data cost:0.6239690905528559 
2022-03-27 22:44:18,040: ============================================================
2022-03-27 22:44:18,041: Epoch 32/38 Batch 3800/7662 eta: 9:19:32.770219	Training Loss 1.5617 (1.5818)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.993)	
2022-03-27 22:44:18,041: ============================================================
2022-03-27 22:45:25,042: time cost, forward:0.01845330512043634, backward:0.04363917179308233, data cost:0.6236688733620654 
2022-03-27 22:45:25,045: ============================================================
2022-03-27 22:45:25,046: Epoch 32/38 Batch 3900/7662 eta: 9:15:25.065226	Training Loss 1.5598 (1.5823)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.993)	
2022-03-27 22:45:25,047: ============================================================
2022-03-27 22:46:36,474: time cost, forward:0.01842442724996282, backward:0.04358024780796182, data cost:0.6244330913551333 
2022-03-27 22:46:36,475: ============================================================
2022-03-27 22:46:36,475: Epoch 32/38 Batch 4000/7662 eta: 9:50:53.748481	Training Loss 1.5212 (1.5828)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 22:46:36,475: ============================================================
2022-03-27 22:47:43,331: time cost, forward:0.018405207077681538, backward:0.043573577452299214, data cost:0.6239884989701937 
2022-03-27 22:47:43,332: ============================================================
2022-03-27 22:47:43,332: Epoch 32/38 Batch 4100/7662 eta: 9:11:57.674056	Training Loss 1.5859 (1.5830)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.993)	
2022-03-27 22:47:43,332: ============================================================
2022-03-27 22:48:45,991: time cost, forward:0.01846411836292097, backward:0.043559143389370024, data cost:0.6225030761186382 
2022-03-27 22:48:45,991: ============================================================
2022-03-27 22:48:45,992: Epoch 32/38 Batch 4200/7662 eta: 8:36:15.820179	Training Loss 1.7060 (1.5835)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.993)	
2022-03-27 22:48:45,992: ============================================================
2022-03-27 22:49:48,441: time cost, forward:0.018442402165500086, backward:0.04356407747625833, data cost:0.6210727582396006 
2022-03-27 22:49:48,442: ============================================================
2022-03-27 22:49:48,442: Epoch 32/38 Batch 4300/7662 eta: 8:33:29.962767	Training Loss 1.6878 (1.5836)	Training Prec@1 99.805 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 22:49:48,443: ============================================================
2022-03-27 22:50:56,370: time cost, forward:0.01841464295227925, backward:0.04360539676330664, data cost:0.6209636643464578 
2022-03-27 22:50:56,371: ============================================================
2022-03-27 22:50:56,371: Epoch 32/38 Batch 4400/7662 eta: 9:17:24.779361	Training Loss 1.5059 (1.5837)	Training Prec@1 99.805 (99.973)	Training Prec@5 99.805 (99.993)	
2022-03-27 22:50:56,371: ============================================================
2022-03-27 22:52:04,984: time cost, forward:0.01837711722142274, backward:0.04358729062331573, data cost:0.6208759128424718 
2022-03-27 22:52:04,985: ============================================================
2022-03-27 22:52:04,986: Epoch 32/38 Batch 4500/7662 eta: 9:21:53.585704	Training Loss 1.7240 (1.5837)	Training Prec@1 99.805 (99.974)	Training Prec@5 100.000 (99.993)	
2022-03-27 22:52:04,986: ============================================================
2022-03-27 22:53:13,386: time cost, forward:0.018354048441741537, backward:0.04360811781380378, data cost:0.6209048527586742 
2022-03-27 22:53:13,389: ============================================================
2022-03-27 22:53:13,390: Epoch 32/38 Batch 4600/7662 eta: 9:19:01.814208	Training Loss 1.6390 (1.5839)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 22:53:13,390: ============================================================
2022-03-27 22:54:18,816: time cost, forward:0.018317395866005996, backward:0.04352646067843181, data cost:0.6203339744765953 
2022-03-27 22:54:18,819: ============================================================
2022-03-27 22:54:18,820: Epoch 32/38 Batch 4700/7662 eta: 8:53:38.217084	Training Loss 1.5703 (1.5844)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 22:54:18,820: ============================================================
2022-03-27 22:55:27,243: time cost, forward:0.018320312100565665, backward:0.04348430436808608, data cost:0.6204765530073735 
2022-03-27 22:55:27,244: ============================================================
2022-03-27 22:55:27,244: Epoch 32/38 Batch 4800/7662 eta: 9:16:55.314146	Training Loss 1.6361 (1.5849)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 22:55:27,245: ============================================================
2022-03-27 22:56:33,962: time cost, forward:0.018273743640940927, backward:0.04343241427620714, data cost:0.6201644335554239 
2022-03-27 22:56:33,964: ============================================================
2022-03-27 22:56:33,965: Epoch 32/38 Batch 4900/7662 eta: 9:01:56.010256	Training Loss 1.6164 (1.5853)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 22:56:33,965: ============================================================
2022-03-27 22:57:45,822: time cost, forward:0.018303850789765496, backward:0.04352152287948129, data cost:0.6207811978369338 
2022-03-27 22:57:45,825: ============================================================
2022-03-27 22:57:45,826: Epoch 32/38 Batch 5000/7662 eta: 9:42:29.798793	Training Loss 1.5035 (1.5854)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 22:57:45,827: ============================================================
2022-03-27 22:58:48,906: time cost, forward:0.018253162903607092, backward:0.043439776739856266, data cost:0.619937462861876 
2022-03-27 22:58:48,907: ============================================================
2022-03-27 22:58:48,907: Epoch 32/38 Batch 5100/7662 eta: 8:30:16.538588	Training Loss 1.4672 (1.5853)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 22:58:48,907: ============================================================
2022-03-27 22:59:56,060: time cost, forward:0.01824828968022415, backward:0.04343490780351437, data cost:0.619618345623086 
2022-03-27 22:59:56,061: ============================================================
2022-03-27 22:59:56,061: Epoch 32/38 Batch 5200/7662 eta: 9:02:06.046850	Training Loss 1.5759 (1.5857)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 22:59:56,062: ============================================================
2022-03-27 23:01:03,075: time cost, forward:0.01825616786695467, backward:0.04341723298459576, data cost:0.6193991638755186 
2022-03-27 23:01:03,080: ============================================================
2022-03-27 23:01:03,082: Epoch 32/38 Batch 5300/7662 eta: 8:59:54.112151	Training Loss 1.6190 (1.5857)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 23:01:03,083: ============================================================
2022-03-27 23:02:10,936: time cost, forward:0.018263749666491313, backward:0.043439932455948536, data cost:0.6194656664496286 
2022-03-27 23:02:10,936: ============================================================
2022-03-27 23:02:10,937: Epoch 32/38 Batch 5400/7662 eta: 9:05:29.963335	Training Loss 1.5425 (1.5859)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 23:02:10,937: ============================================================
2022-03-27 23:03:17,207: time cost, forward:0.01823207408130158, backward:0.04343269529895883, data cost:0.619102749657167 
2022-03-27 23:03:17,211: ============================================================
2022-03-27 23:03:17,212: Epoch 32/38 Batch 5500/7662 eta: 8:51:41.254968	Training Loss 1.5717 (1.5861)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 23:03:17,212: ============================================================
2022-03-27 23:04:25,653: time cost, forward:0.01823645677922517, backward:0.043421506115231566, data cost:0.6190357173760249 
2022-03-27 23:04:25,675: ============================================================
2022-03-27 23:04:25,676: Epoch 32/38 Batch 5600/7662 eta: 9:08:06.729120	Training Loss 1.6739 (1.5865)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 23:04:25,676: ============================================================
2022-03-27 23:05:34,497: time cost, forward:0.018237243976315234, backward:0.04334228978823896, data cost:0.6193764414739601 
2022-03-27 23:05:34,497: ============================================================
2022-03-27 23:05:34,497: Epoch 32/38 Batch 5700/7662 eta: 9:09:49.855541	Training Loss 1.5809 (1.5867)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 23:05:34,498: ============================================================
2022-03-27 23:06:44,981: time cost, forward:0.01825770716725557, backward:0.04334034613852543, data cost:0.619738337952097 
2022-03-27 23:06:44,981: ============================================================
2022-03-27 23:06:44,982: Epoch 32/38 Batch 5800/7662 eta: 9:21:56.153223	Training Loss 1.5425 (1.5869)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 23:06:44,982: ============================================================
2022-03-27 23:07:50,051: time cost, forward:0.01822728443032585, backward:0.04324748613487201, data cost:0.6193217193298288 
2022-03-27 23:07:50,052: ============================================================
2022-03-27 23:07:50,052: Epoch 32/38 Batch 5900/7662 eta: 8:37:41.424750	Training Loss 1.5827 (1.5870)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 23:07:50,052: ============================================================
2022-03-27 23:08:56,301: time cost, forward:0.018227793173226422, backward:0.043219692171722834, data cost:0.6190110834703224 
2022-03-27 23:08:56,302: ============================================================
2022-03-27 23:08:56,302: Epoch 32/38 Batch 6000/7662 eta: 8:45:58.196586	Training Loss 1.5821 (1.5873)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 23:08:56,303: ============================================================
2022-03-27 23:10:03,645: time cost, forward:0.018223203622155314, backward:0.043212604319429686, data cost:0.6188818705162077 
2022-03-27 23:10:03,646: ============================================================
2022-03-27 23:10:03,646: Epoch 32/38 Batch 6100/7662 eta: 8:53:31.935882	Training Loss 1.6489 (1.5876)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 23:10:03,646: ============================================================
2022-03-27 23:11:11,962: time cost, forward:0.01819593399873682, backward:0.043160729070578226, data cost:0.618890873250086 
2022-03-27 23:11:11,962: ============================================================
2022-03-27 23:11:11,962: Epoch 32/38 Batch 6200/7662 eta: 9:00:05.680795	Training Loss 1.4762 (1.5879)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 23:11:11,962: ============================================================
2022-03-27 23:12:16,969: time cost, forward:0.01818969166833345, backward:0.04311099448342572, data cost:0.6185219716336883 
2022-03-27 23:12:16,970: ============================================================
2022-03-27 23:12:16,970: Epoch 32/38 Batch 6300/7662 eta: 8:32:51.604803	Training Loss 1.6294 (1.5882)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 23:12:16,971: ============================================================
2022-03-27 23:13:25,133: time cost, forward:0.0181728148203303, backward:0.04315287356340134, data cost:0.6184128723883744 
2022-03-27 23:13:25,136: ============================================================
2022-03-27 23:13:25,137: Epoch 32/38 Batch 6400/7662 eta: 8:56:38.210723	Training Loss 1.6983 (1.5886)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.993)	
2022-03-27 23:13:25,137: ============================================================
2022-03-27 23:14:28,122: time cost, forward:0.018155354135750732, backward:0.04315193023364679, data cost:0.6177629184532136 
2022-03-27 23:14:28,123: ============================================================
2022-03-27 23:14:28,123: Epoch 32/38 Batch 6500/7662 eta: 8:14:48.721849	Training Loss 1.6523 (1.5889)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.993)	
2022-03-27 23:14:28,123: ============================================================
2022-03-27 23:15:33,454: time cost, forward:0.018145418687379077, backward:0.0431478280048512, data cost:0.6173597716764891 
2022-03-27 23:15:33,455: ============================================================
2022-03-27 23:15:33,455: Epoch 32/38 Batch 6600/7662 eta: 8:32:08.978090	Training Loss 1.6240 (1.5891)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 23:15:33,455: ============================================================
2022-03-27 23:16:37,793: time cost, forward:0.018106011031794714, backward:0.043070310549089, data cost:0.6169348490168789 
2022-03-27 23:16:37,794: ============================================================
2022-03-27 23:16:37,794: Epoch 32/38 Batch 6700/7662 eta: 8:23:17.357681	Training Loss 1.5303 (1.5894)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 23:16:37,794: ============================================================
2022-03-27 23:17:40,472: time cost, forward:0.018082852818752354, backward:0.043040574026521575, data cost:0.6162111757432456 
2022-03-27 23:17:40,473: ============================================================
2022-03-27 23:17:40,473: Epoch 32/38 Batch 6800/7662 eta: 8:09:15.762755	Training Loss 1.6228 (1.5895)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 23:17:40,473: ============================================================
2022-03-27 23:18:43,980: time cost, forward:0.018061906190035327, backward:0.0430026982276055, data cost:0.6155969548145919 
2022-03-27 23:18:43,981: ============================================================
2022-03-27 23:18:43,981: Epoch 32/38 Batch 6900/7662 eta: 8:14:40.548992	Training Loss 1.5837 (1.5897)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 23:18:43,981: ============================================================
2022-03-27 23:19:48,563: time cost, forward:0.018081098986550866, backward:0.04300807588252702, data cost:0.6151567592776185 
2022-03-27 23:19:48,563: ============================================================
2022-03-27 23:19:48,563: Epoch 32/38 Batch 7000/7662 eta: 8:21:57.868744	Training Loss 1.4508 (1.5900)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.993)	
2022-03-27 23:19:48,563: ============================================================
2022-03-27 23:20:54,335: time cost, forward:0.018090527231281184, backward:0.04304034902371392, data cost:0.614817671682452 
2022-03-27 23:20:54,336: ============================================================
2022-03-27 23:20:54,336: Epoch 32/38 Batch 7100/7662 eta: 8:30:07.241658	Training Loss 1.5885 (1.5901)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 23:20:54,336: ============================================================
2022-03-27 23:21:59,904: time cost, forward:0.018102963610910214, backward:0.04305693218651406, data cost:0.6144923279891165 
2022-03-27 23:21:59,904: ============================================================
2022-03-27 23:21:59,905: Epoch 32/38 Batch 7200/7662 eta: 8:27:26.889538	Training Loss 1.7592 (1.5901)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 23:21:59,905: ============================================================
2022-03-27 23:23:10,062: time cost, forward:0.01811216471701195, backward:0.04310093195181315, data cost:0.6147644305199789 
2022-03-27 23:23:10,062: ============================================================
2022-03-27 23:23:10,063: Epoch 32/38 Batch 7300/7662 eta: 9:01:47.689301	Training Loss 1.6712 (1.5905)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.993)	
2022-03-27 23:23:10,063: ============================================================
2022-03-27 23:24:10,229: time cost, forward:0.018083677338271355, backward:0.04301515052827375, data cost:0.6137453478274273 
2022-03-27 23:24:10,230: ============================================================
2022-03-27 23:24:10,230: Epoch 32/38 Batch 7400/7662 eta: 7:43:38.505144	Training Loss 1.5797 (1.5907)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.993)	
2022-03-27 23:24:10,230: ============================================================
2022-03-27 23:25:12,964: time cost, forward:0.018069498601603912, backward:0.0430201987518217, data cost:0.6132340580642279 
2022-03-27 23:25:12,967: ============================================================
2022-03-27 23:25:12,968: Epoch 32/38 Batch 7500/7662 eta: 8:02:23.715825	Training Loss 1.5947 (1.5908)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 23:25:12,968: ============================================================
2022-03-27 23:26:17,756: time cost, forward:0.018038536313490297, backward:0.043035610425878564, data cost:0.6127791209885408 
2022-03-27 23:26:17,756: ============================================================
2022-03-27 23:26:17,757: Epoch 32/38 Batch 7600/7662 eta: 8:17:05.739532	Training Loss 1.6217 (1.5911)	Training Prec@1 99.805 (99.972)	Training Prec@5 100.000 (99.993)	
2022-03-27 23:26:17,757: ============================================================
2022-03-27 23:26:59,978: Epoch: 32/38 eta: 8:16:24.922293	Training Loss 1.5441 (1.5913)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.993)
2022-03-27 23:26:59,981: ============================================================
2022-03-27 23:26:59,985: Save Checkpoint...
2022-03-27 23:26:59,987: ============================================================
2022-03-27 23:27:03,555: Save done!
2022-03-27 23:27:03,555: ============================================================
2022-03-27 23:28:09,218: time cost, forward:0.01528083916866418, backward:0.04181395155010802, data cost:0.6009723586265487 
2022-03-27 23:28:09,218: ============================================================
2022-03-27 23:28:09,219: Epoch 33/38 Batch 100/7662 eta: 8:22:00.735720	Training Loss 1.5528 (1.5692)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.990)	
2022-03-27 23:28:09,219: ============================================================
2022-03-27 23:29:15,596: time cost, forward:0.016304042471114114, backward:0.04408791556430222, data cost:0.5998508630685471 
2022-03-27 23:29:15,597: ============================================================
2022-03-27 23:29:15,597: Epoch 33/38 Batch 200/7662 eta: 8:26:23.397186	Training Loss 1.6201 (1.5663)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.988)	
2022-03-27 23:29:15,597: ============================================================
2022-03-27 23:30:19,350: time cost, forward:0.016586400992096864, backward:0.042319080103998596, data cost:0.5902659462447151 
2022-03-27 23:30:19,352: ============================================================
2022-03-27 23:30:19,353: Epoch 33/38 Batch 300/7662 eta: 8:05:19.086248	Training Loss 1.4643 (1.5677)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.989)	
2022-03-27 23:30:19,353: ============================================================
2022-03-27 23:31:24,607: time cost, forward:0.0164909661563118, backward:0.04196054654611382, data cost:0.5927963537679878 
2022-03-27 23:31:24,607: ============================================================
2022-03-27 23:31:24,608: Epoch 33/38 Batch 400/7662 eta: 8:15:38.597096	Training Loss 1.6566 (1.5658)	Training Prec@1 100.000 (99.971)	Training Prec@5 100.000 (99.990)	
2022-03-27 23:31:24,608: ============================================================
2022-03-27 23:32:33,788: time cost, forward:0.01678249448955895, backward:0.04281240379165313, data cost:0.5999464463136478 
2022-03-27 23:32:33,789: ============================================================
2022-03-27 23:32:33,789: Epoch 33/38 Batch 500/7662 eta: 8:44:19.037587	Training Loss 1.4411 (1.5657)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.991)	
2022-03-27 23:32:33,790: ============================================================
2022-03-27 23:33:38,220: time cost, forward:0.016594388449132344, backward:0.04256516585564971, data cost:0.5976601164408638 
2022-03-27 23:33:38,223: ============================================================
2022-03-27 23:33:38,224: Epoch 33/38 Batch 600/7662 eta: 8:07:15.889042	Training Loss 1.7180 (1.5653)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.992)	
2022-03-27 23:33:38,225: ============================================================
2022-03-27 23:34:42,703: time cost, forward:0.01666783024483655, backward:0.04267989992242685, data cost:0.5956052413825825 
2022-03-27 23:34:42,704: ============================================================
2022-03-27 23:34:42,704: Epoch 33/38 Batch 700/7662 eta: 8:06:32.033647	Training Loss 1.6191 (1.5665)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.992)	
2022-03-27 23:34:42,704: ============================================================
2022-03-27 23:35:48,848: time cost, forward:0.01682421382288163, backward:0.04251394253946813, data cost:0.5952534523416073 
2022-03-27 23:35:48,850: ============================================================
2022-03-27 23:35:48,851: Epoch 33/38 Batch 800/7662 eta: 8:18:00.445948	Training Loss 1.5070 (1.5665)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.992)	
2022-03-27 23:35:48,853: ============================================================
2022-03-27 23:36:52,109: time cost, forward:0.016920854835807284, backward:0.04238025365072044, data cost:0.5928098781488098 
2022-03-27 23:36:52,109: ============================================================
2022-03-27 23:36:52,110: Epoch 33/38 Batch 900/7662 eta: 7:55:12.731677	Training Loss 1.5225 (1.5680)	Training Prec@1 99.805 (99.973)	Training Prec@5 99.805 (99.992)	
2022-03-27 23:36:52,110: ============================================================
2022-03-27 23:37:57,283: time cost, forward:0.01719610397522156, backward:0.04274183207446033, data cost:0.592647061333642 
2022-03-27 23:37:57,283: ============================================================
2022-03-27 23:37:57,283: Epoch 33/38 Batch 1000/7662 eta: 8:08:30.538871	Training Loss 1.5772 (1.5685)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 23:37:57,284: ============================================================
2022-03-27 23:39:04,443: time cost, forward:0.017506156648908342, backward:0.042915267874914696, data cost:0.5937726521513699 
2022-03-27 23:39:04,443: ============================================================
2022-03-27 23:39:04,443: Epoch 33/38 Batch 1100/7662 eta: 8:22:16.719784	Training Loss 1.5109 (1.5689)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 23:39:04,444: ============================================================
2022-03-27 23:40:08,033: time cost, forward:0.017557858028841376, backward:0.042760393239737945, data cost:0.592239210862135 
2022-03-27 23:40:08,034: ============================================================
2022-03-27 23:40:08,034: Epoch 33/38 Batch 1200/7662 eta: 7:54:31.360206	Training Loss 1.6758 (1.5700)	Training Prec@1 99.805 (99.973)	Training Prec@5 99.805 (99.993)	
2022-03-27 23:40:08,034: ============================================================
2022-03-27 23:41:12,192: time cost, forward:0.017557212992573446, backward:0.042751523326964816, data cost:0.5912351485304506 
2022-03-27 23:41:12,192: ============================================================
2022-03-27 23:41:12,193: Epoch 33/38 Batch 1300/7662 eta: 7:57:41.672709	Training Loss 1.5856 (1.5710)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 23:41:12,193: ============================================================
2022-03-27 23:42:16,194: time cost, forward:0.017499151188957427, backward:0.042794008439059256, data cost:0.5904241508036703 
2022-03-27 23:42:16,194: ============================================================
2022-03-27 23:42:16,195: Epoch 33/38 Batch 1400/7662 eta: 7:55:27.554647	Training Loss 1.6234 (1.5722)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 23:42:16,195: ============================================================
2022-03-27 23:43:21,113: time cost, forward:0.017549770843831598, backward:0.04276640245006274, data cost:0.5900578064629044 
2022-03-27 23:43:21,114: ============================================================
2022-03-27 23:43:21,114: Epoch 33/38 Batch 1500/7662 eta: 8:01:11.574533	Training Loss 1.6721 (1.5731)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-27 23:43:21,114: ============================================================
2022-03-27 23:44:28,753: time cost, forward:0.017588640765296884, backward:0.04281355113517947, data cost:0.5911507791396303 
2022-03-27 23:44:28,754: ============================================================
2022-03-27 23:44:28,754: Epoch 33/38 Batch 1600/7662 eta: 8:20:13.901372	Training Loss 1.5240 (1.5737)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.994)	
2022-03-27 23:44:28,754: ============================================================
2022-03-27 23:45:34,059: time cost, forward:0.0175681376611576, backward:0.04270828380663301, data cost:0.591565901844413 
2022-03-27 23:45:34,059: ============================================================
2022-03-27 23:45:34,060: Epoch 33/38 Batch 1700/7662 eta: 8:01:52.765567	Training Loss 1.6569 (1.5747)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-27 23:45:34,060: ============================================================
2022-03-27 23:46:36,950: time cost, forward:0.017423938551898, backward:0.042582341205285215, data cost:0.5906339253631813 
2022-03-27 23:46:36,952: ============================================================
2022-03-27 23:46:36,953: Epoch 33/38 Batch 1800/7662 eta: 7:43:01.869019	Training Loss 1.4375 (1.5746)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-27 23:46:36,953: ============================================================
2022-03-27 23:47:43,138: time cost, forward:0.01749385941210642, backward:0.042676543863024316, data cost:0.5910109244502803 
2022-03-27 23:47:43,139: ============================================================
2022-03-27 23:47:43,139: Epoch 33/38 Batch 1900/7662 eta: 8:06:10.087002	Training Loss 1.6670 (1.5746)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-27 23:47:43,139: ============================================================
2022-03-27 23:48:46,290: time cost, forward:0.017498125846294118, backward:0.042589663505077126, data cost:0.5900404601171053 
2022-03-27 23:48:46,291: ============================================================
2022-03-27 23:48:46,291: Epoch 33/38 Batch 2000/7662 eta: 7:42:49.900858	Training Loss 1.6300 (1.5748)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.993)	
2022-03-27 23:48:46,291: ============================================================
2022-03-27 23:49:50,831: time cost, forward:0.01748774425366653, backward:0.042344593218021476, data cost:0.5898647251556236 
2022-03-27 23:49:50,834: ============================================================
2022-03-27 23:49:50,835: Epoch 33/38 Batch 2100/7662 eta: 7:51:57.354876	Training Loss 1.4474 (1.5753)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.994)	
2022-03-27 23:49:50,836: ============================================================
2022-03-27 23:50:57,104: time cost, forward:0.017483889378976582, backward:0.04235605892131089, data cost:0.5905249603448428 
2022-03-27 23:50:57,105: ============================================================
2022-03-27 23:50:57,105: Epoch 33/38 Batch 2200/7662 eta: 8:03:28.422091	Training Loss 1.4673 (1.5759)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-27 23:50:57,105: ============================================================
2022-03-27 23:52:02,427: time cost, forward:0.017478284549588687, backward:0.04224831760318552, data cost:0.5907002715973192 
2022-03-27 23:52:02,428: ============================================================
2022-03-27 23:52:02,428: Epoch 33/38 Batch 2300/7662 eta: 7:55:28.466081	Training Loss 1.5477 (1.5758)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-27 23:52:02,428: ============================================================
2022-03-27 23:53:05,706: time cost, forward:0.017397499720520553, backward:0.0422150540123288, data cost:0.5900397766824065 
2022-03-27 23:53:05,706: ============================================================
2022-03-27 23:53:05,707: Epoch 33/38 Batch 2400/7662 eta: 7:39:32.497396	Training Loss 1.5447 (1.5763)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-27 23:53:05,707: ============================================================
2022-03-27 23:54:09,454: time cost, forward:0.01741183581663256, backward:0.04226560800635562, data cost:0.589423184301339 
2022-03-27 23:54:09,455: ============================================================
2022-03-27 23:54:09,455: Epoch 33/38 Batch 2500/7662 eta: 7:41:53.204172	Training Loss 1.5905 (1.5764)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-27 23:54:09,455: ============================================================
2022-03-27 23:55:13,201: time cost, forward:0.017451911671613904, backward:0.04229619889224479, data cost:0.5888349189809672 
2022-03-27 23:55:13,201: ============================================================
2022-03-27 23:55:13,201: Epoch 33/38 Batch 2600/7662 eta: 7:40:48.804921	Training Loss 1.6012 (1.5766)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-27 23:55:13,202: ============================================================
2022-03-27 23:56:15,298: time cost, forward:0.01742094231782555, backward:0.042169271905848876, data cost:0.5878960920201712 
2022-03-27 23:56:15,298: ============================================================
2022-03-27 23:56:15,299: Epoch 33/38 Batch 2700/7662 eta: 7:27:51.298622	Training Loss 1.6278 (1.5762)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.995)	
2022-03-27 23:56:15,299: ============================================================
2022-03-27 23:57:21,812: time cost, forward:0.01745231912237442, backward:0.0422445398094229, data cost:0.5883791969690463 
2022-03-27 23:57:21,813: ============================================================
2022-03-27 23:57:21,813: Epoch 33/38 Batch 2800/7662 eta: 7:58:36.165261	Training Loss 1.4284 (1.5764)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.995)	
2022-03-27 23:57:21,813: ============================================================
2022-03-27 23:58:25,939: time cost, forward:0.017455284412090596, backward:0.04231096292701661, data cost:0.5877915371200387 
2022-03-27 23:58:25,942: ============================================================
2022-03-27 23:58:25,943: Epoch 33/38 Batch 2900/7662 eta: 7:40:22.710842	Training Loss 1.5948 (1.5762)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.995)	
2022-03-27 23:58:25,945: ============================================================
2022-03-27 23:59:28,665: time cost, forward:0.017425930154208305, backward:0.0421354176800185, data cost:0.5875400862482318 
2022-03-27 23:59:28,665: ============================================================
2022-03-27 23:59:28,665: Epoch 33/38 Batch 3000/7662 eta: 7:29:13.772748	Training Loss 1.5607 (1.5765)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.995)	
2022-03-27 23:59:28,666: ============================================================
2022-03-28 00:00:34,161: time cost, forward:0.017381712020155152, backward:0.042201397302805435, data cost:0.5877390442528467 
2022-03-28 00:00:34,162: ============================================================
2022-03-28 00:00:34,162: Epoch 33/38 Batch 3100/7662 eta: 7:48:00.320789	Training Loss 1.5583 (1.5765)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.995)	
2022-03-28 00:00:34,162: ============================================================
2022-03-28 00:01:36,680: time cost, forward:0.01731104715126088, backward:0.042128045173614015, data cost:0.5871429750419251 
2022-03-28 00:01:36,680: ============================================================
2022-03-28 00:01:36,681: Epoch 33/38 Batch 3200/7662 eta: 7:25:41.096069	Training Loss 1.6971 (1.5772)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.995)	
2022-03-28 00:01:36,681: ============================================================
2022-03-28 00:02:46,192: time cost, forward:0.017356407356898182, backward:0.042254033396554085, data cost:0.5883822610935466 
2022-03-28 00:02:46,192: ============================================================
2022-03-28 00:02:46,192: Epoch 33/38 Batch 3300/7662 eta: 8:14:22.799737	Training Loss 1.4988 (1.5774)	Training Prec@1 99.805 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 00:02:46,193: ============================================================
2022-03-28 00:03:46,897: time cost, forward:0.017360981438713376, backward:0.04217160417950129, data cost:0.5869564897139377 
2022-03-28 00:03:46,901: ============================================================
2022-03-28 00:03:46,902: Epoch 33/38 Batch 3400/7662 eta: 7:10:45.547408	Training Loss 1.4599 (1.5775)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.995)	
2022-03-28 00:03:46,902: ============================================================
2022-03-28 00:04:49,859: time cost, forward:0.017354736671545874, backward:0.04216086929203545, data cost:0.5866894240923083 
2022-03-28 00:04:49,859: ============================================================
2022-03-28 00:04:49,859: Epoch 33/38 Batch 3500/7662 eta: 7:25:40.224226	Training Loss 1.6388 (1.5777)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.995)	
2022-03-28 00:04:49,860: ============================================================
2022-03-28 00:05:52,747: time cost, forward:0.01730895784372222, backward:0.0421512561494955, data cost:0.5862104897367918 
2022-03-28 00:05:52,747: ============================================================
2022-03-28 00:05:52,748: Epoch 33/38 Batch 3600/7662 eta: 7:24:07.639534	Training Loss 1.7167 (1.5781)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.995)	
2022-03-28 00:05:52,748: ============================================================
2022-03-28 00:06:57,785: time cost, forward:0.017329106752406457, backward:0.042148225144393765, data cost:0.5862217882769467 
2022-03-28 00:06:57,787: ============================================================
2022-03-28 00:06:57,787: Epoch 33/38 Batch 3700/7662 eta: 7:38:14.143198	Training Loss 1.5918 (1.5782)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.995)	
2022-03-28 00:06:57,788: ============================================================
2022-03-28 00:08:01,277: time cost, forward:0.017317558721857154, backward:0.04218043858015277, data cost:0.5859731038202264 
2022-03-28 00:08:01,278: ============================================================
2022-03-28 00:08:01,278: Epoch 33/38 Batch 3800/7662 eta: 7:26:16.047539	Training Loss 1.4758 (1.5783)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.995)	
2022-03-28 00:08:01,279: ============================================================
2022-03-28 00:09:04,012: time cost, forward:0.017282833591978745, backward:0.04211542018715251, data cost:0.5855881668231707 
2022-03-28 00:09:04,012: ============================================================
2022-03-28 00:09:04,012: Epoch 33/38 Batch 3900/7662 eta: 7:19:54.018730	Training Loss 1.6099 (1.5784)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 00:09:04,012: ============================================================
2022-03-28 00:10:08,879: time cost, forward:0.017274521147796408, backward:0.042134699090536486, data cost:0.5856417200809182 
2022-03-28 00:10:08,880: ============================================================
2022-03-28 00:10:08,880: Epoch 33/38 Batch 4000/7662 eta: 7:33:47.047454	Training Loss 1.5678 (1.5787)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 00:10:08,880: ============================================================
2022-03-28 00:11:13,616: time cost, forward:0.01724533035453281, backward:0.042094400842819714, data cost:0.5855848042957373 
2022-03-28 00:11:13,619: ============================================================
2022-03-28 00:11:13,619: Epoch 33/38 Batch 4100/7662 eta: 7:31:48.130856	Training Loss 1.6946 (1.5788)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 00:11:13,620: ============================================================
2022-03-28 00:12:16,515: time cost, forward:0.01722340834768195, backward:0.04209082136270006, data cost:0.5853362518936488 
2022-03-28 00:12:16,516: ============================================================
2022-03-28 00:12:16,516: Epoch 33/38 Batch 4200/7662 eta: 7:17:53.801502	Training Loss 1.6653 (1.5792)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 00:12:16,516: ============================================================
2022-03-28 00:13:21,294: time cost, forward:0.017225634416720845, backward:0.042203849458394976, data cost:0.5851728419809459 
2022-03-28 00:13:21,297: ============================================================
2022-03-28 00:13:21,298: Epoch 33/38 Batch 4300/7662 eta: 7:29:56.597621	Training Loss 1.6872 (1.5796)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 00:13:21,298: ============================================================
2022-03-28 00:14:24,805: time cost, forward:0.017223038709171797, backward:0.04220184528656942, data cost:0.5850165668035752 
2022-03-28 00:14:24,805: ============================================================
2022-03-28 00:14:24,805: Epoch 33/38 Batch 4400/7662 eta: 7:20:02.018641	Training Loss 1.5836 (1.5801)	Training Prec@1 99.805 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 00:14:24,806: ============================================================
2022-03-28 00:15:28,331: time cost, forward:0.01723567203141022, backward:0.04221703137628607, data cost:0.5847520995177171 
2022-03-28 00:15:28,331: ============================================================
2022-03-28 00:15:28,331: Epoch 33/38 Batch 4500/7662 eta: 7:19:06.154898	Training Loss 1.6217 (1.5804)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 00:15:28,332: ============================================================
2022-03-28 00:16:32,836: time cost, forward:0.017236662159849443, backward:0.04213927123411294, data cost:0.5847981598201486 
2022-03-28 00:16:32,836: ============================================================
2022-03-28 00:16:32,837: Epoch 33/38 Batch 4600/7662 eta: 7:24:47.760032	Training Loss 1.5611 (1.5806)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 00:16:32,837: ============================================================
2022-03-28 00:17:35,594: time cost, forward:0.01720660669952282, backward:0.0421457698584161, data cost:0.5844772380066567 
2022-03-28 00:17:35,594: ============================================================
2022-03-28 00:17:35,595: Epoch 33/38 Batch 4700/7662 eta: 7:11:42.093159	Training Loss 1.5795 (1.5809)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 00:17:35,595: ============================================================
2022-03-28 00:18:39,414: time cost, forward:0.01720787570187886, backward:0.04211690590316541, data cost:0.5843098042383371 
2022-03-28 00:18:39,415: ============================================================
2022-03-28 00:18:39,415: Epoch 33/38 Batch 4800/7662 eta: 7:17:56.840632	Training Loss 1.6330 (1.5814)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 00:18:39,415: ============================================================
2022-03-28 00:19:41,259: time cost, forward:0.017178361769670563, backward:0.04205773226653685, data cost:0.5838995626639969 
2022-03-28 00:19:41,259: ============================================================
2022-03-28 00:19:41,259: Epoch 33/38 Batch 4900/7662 eta: 7:03:21.153063	Training Loss 1.6369 (1.5816)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 00:19:41,259: ============================================================
2022-03-28 00:20:47,893: time cost, forward:0.017166521149078448, backward:0.042065375135955534, data cost:0.5843428888185473 
2022-03-28 00:20:47,893: ============================================================
2022-03-28 00:20:47,894: Epoch 33/38 Batch 5000/7662 eta: 7:35:02.078086	Training Loss 1.6454 (1.5819)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 00:20:47,894: ============================================================
2022-03-28 00:21:49,326: time cost, forward:0.01716591886829736, backward:0.04199326279163828, data cost:0.5837315411445182 
2022-03-28 00:21:49,327: ============================================================
2022-03-28 00:21:49,327: Epoch 33/38 Batch 5100/7662 eta: 6:58:29.888520	Training Loss 1.6383 (1.5819)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 00:21:49,328: ============================================================
2022-03-28 00:22:53,484: time cost, forward:0.017166911604129757, backward:0.04201002707043894, data cost:0.583610273090824 
2022-03-28 00:22:53,485: ============================================================
2022-03-28 00:22:53,485: Epoch 33/38 Batch 5200/7662 eta: 7:15:58.965192	Training Loss 1.5108 (1.5821)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 00:22:53,485: ============================================================
2022-03-28 00:23:55,871: time cost, forward:0.017133303691045498, backward:0.04196302201032954, data cost:0.5834343566109851 
2022-03-28 00:23:55,871: ============================================================
2022-03-28 00:23:55,872: Epoch 33/38 Batch 5300/7662 eta: 7:02:54.454309	Training Loss 1.5888 (1.5824)	Training Prec@1 99.805 (99.975)	Training Prec@5 99.805 (99.994)	
2022-03-28 00:23:55,872: ============================================================
2022-03-28 00:25:01,042: time cost, forward:0.01714624561939356, backward:0.04199941857343781, data cost:0.5835261047272842 
2022-03-28 00:25:01,042: ============================================================
2022-03-28 00:25:01,042: Epoch 33/38 Batch 5400/7662 eta: 7:20:41.759990	Training Loss 1.5475 (1.5823)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 00:25:01,042: ============================================================
2022-03-28 00:26:04,146: time cost, forward:0.01714406648231086, backward:0.04194877190597709, data cost:0.583339808008458 
2022-03-28 00:26:04,147: ============================================================
2022-03-28 00:26:04,148: Epoch 33/38 Batch 5500/7662 eta: 7:05:40.664498	Training Loss 1.5587 (1.5825)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 00:26:04,148: ============================================================
2022-03-28 00:27:12,764: time cost, forward:0.017190190974591693, backward:0.04192731213965657, data cost:0.5840828078072887 
2022-03-28 00:27:12,764: ============================================================
2022-03-28 00:27:12,765: Epoch 33/38 Batch 5600/7662 eta: 7:41:42.642403	Training Loss 1.5016 (1.5825)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 00:27:12,765: ============================================================
2022-03-28 00:28:14,874: time cost, forward:0.017167393712333095, backward:0.04188903923054749, data cost:0.5837042404907087 
2022-03-28 00:28:14,874: ============================================================
2022-03-28 00:28:14,875: Epoch 33/38 Batch 5700/7662 eta: 6:56:53.577253	Training Loss 1.5817 (1.5827)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 00:28:14,875: ============================================================
2022-03-28 00:29:18,061: time cost, forward:0.017185275976895092, backward:0.041930564540607146, data cost:0.5833691722217316 
2022-03-28 00:29:18,061: ============================================================
2022-03-28 00:29:18,062: Epoch 33/38 Batch 5800/7662 eta: 7:03:04.184114	Training Loss 1.4692 (1.5832)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 00:29:18,062: ============================================================
2022-03-28 00:30:20,650: time cost, forward:0.017181778301685862, backward:0.04193987105130786, data cost:0.5831528540525746 
2022-03-28 00:30:20,651: ============================================================
2022-03-28 00:30:20,651: Epoch 33/38 Batch 5900/7662 eta: 6:58:01.438914	Training Loss 1.5614 (1.5834)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.994)	
2022-03-28 00:30:20,651: ============================================================
2022-03-28 00:31:25,573: time cost, forward:0.0171912080904984, backward:0.041941480450599186, data cost:0.5832355596320116 
2022-03-28 00:31:25,574: ============================================================
2022-03-28 00:31:25,574: Epoch 33/38 Batch 6000/7662 eta: 7:12:31.572190	Training Loss 1.4968 (1.5835)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.994)	
2022-03-28 00:31:25,574: ============================================================
2022-03-28 00:32:30,462: time cost, forward:0.017199405628572743, backward:0.04198025324087023, data cost:0.5832693943099363 
2022-03-28 00:32:30,463: ============================================================
2022-03-28 00:32:30,463: Epoch 33/38 Batch 6100/7662 eta: 7:11:13.260533	Training Loss 1.7037 (1.5841)	Training Prec@1 99.805 (99.974)	Training Prec@5 100.000 (99.994)	
2022-03-28 00:32:30,463: ============================================================
2022-03-28 00:33:35,986: time cost, forward:0.01722852147996647, backward:0.04201493095555485, data cost:0.5834008008169539 
2022-03-28 00:33:35,986: ============================================================
2022-03-28 00:33:35,987: Epoch 33/38 Batch 6200/7662 eta: 7:14:20.690279	Training Loss 1.6427 (1.5845)	Training Prec@1 99.805 (99.974)	Training Prec@5 99.805 (99.994)	
2022-03-28 00:33:35,987: ============================================================
2022-03-28 00:34:38,894: time cost, forward:0.017244469988893035, backward:0.042033930622711886, data cost:0.5830192068565988 
2022-03-28 00:34:38,896: ============================================================
2022-03-28 00:34:38,897: Epoch 33/38 Batch 6300/7662 eta: 6:55:58.158249	Training Loss 1.4702 (1.5848)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.994)	
2022-03-28 00:34:38,897: ============================================================
2022-03-28 00:35:43,492: time cost, forward:0.017243249618666193, backward:0.04203290934860008, data cost:0.5830573629524433 
2022-03-28 00:35:43,494: ============================================================
2022-03-28 00:35:43,495: Epoch 33/38 Batch 6400/7662 eta: 7:06:03.537992	Training Loss 1.6488 (1.5852)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.994)	
2022-03-28 00:35:43,496: ============================================================
2022-03-28 00:36:44,920: time cost, forward:0.017229668707788165, backward:0.042014881837806405, data cost:0.5827365945826899 
2022-03-28 00:36:44,921: ============================================================
2022-03-28 00:36:44,921: Epoch 33/38 Batch 6500/7662 eta: 6:44:06.684086	Training Loss 1.5793 (1.5855)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.994)	
2022-03-28 00:36:44,921: ============================================================
2022-03-28 00:37:50,335: time cost, forward:0.017219253011970272, backward:0.04202695780946443, data cost:0.5827597939149776 
2022-03-28 00:37:50,338: ============================================================
2022-03-28 00:37:50,339: Epoch 33/38 Batch 6600/7662 eta: 7:09:16.969336	Training Loss 1.5880 (1.5857)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.994)	
2022-03-28 00:37:50,340: ============================================================
2022-03-28 00:38:55,096: time cost, forward:0.017208452597716473, backward:0.04201639906864306, data cost:0.5829009285505573 
2022-03-28 00:38:55,098: ============================================================
2022-03-28 00:38:55,099: Epoch 33/38 Batch 6700/7662 eta: 7:03:53.231126	Training Loss 1.6167 (1.5859)	Training Prec@1 99.805 (99.974)	Training Prec@5 99.805 (99.994)	
2022-03-28 00:38:55,100: ============================================================
2022-03-28 00:39:56,991: time cost, forward:0.017203979307035256, backward:0.04200848061681793, data cost:0.5826308770396461 
2022-03-28 00:39:56,992: ============================================================
2022-03-28 00:39:56,992: Epoch 33/38 Batch 6800/7662 eta: 6:44:05.370623	Training Loss 1.4715 (1.5862)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.994)	
2022-03-28 00:39:56,992: ============================================================
2022-03-28 00:41:00,558: time cost, forward:0.01721231462921262, backward:0.04198338028520307, data cost:0.5824574448609977 
2022-03-28 00:41:00,559: ============================================================
2022-03-28 00:41:00,560: Epoch 33/38 Batch 6900/7662 eta: 6:53:57.872502	Training Loss 1.6473 (1.5864)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.994)	
2022-03-28 00:41:00,560: ============================================================
2022-03-28 00:42:03,437: time cost, forward:0.01717485232189019, backward:0.04196263187390461, data cost:0.5823975940962692 
2022-03-28 00:42:03,437: ============================================================
2022-03-28 00:42:03,438: Epoch 33/38 Batch 7000/7662 eta: 6:48:25.338136	Training Loss 1.7165 (1.5866)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.994)	
2022-03-28 00:42:03,438: ============================================================
2022-03-28 00:43:07,394: time cost, forward:0.017177683717013247, backward:0.04197189458273955, data cost:0.5823365926641799 
2022-03-28 00:43:07,394: ============================================================
2022-03-28 00:43:07,394: Epoch 33/38 Batch 7100/7662 eta: 6:54:21.904614	Training Loss 1.6142 (1.5869)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.994)	
2022-03-28 00:43:07,394: ============================================================
2022-03-28 00:44:10,729: time cost, forward:0.01716367501917109, backward:0.04195287651875927, data cost:0.5822393185464123 
2022-03-28 00:44:10,730: ============================================================
2022-03-28 00:44:10,730: Epoch 33/38 Batch 7200/7662 eta: 6:49:17.036716	Training Loss 1.6090 (1.5872)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.994)	
2022-03-28 00:44:10,730: ============================================================
2022-03-28 00:45:12,941: time cost, forward:0.017163955899097607, backward:0.041964670879773236, data cost:0.5819379014337793 
2022-03-28 00:45:12,941: ============================================================
2022-03-28 00:45:12,942: Epoch 33/38 Batch 7300/7662 eta: 6:40:59.211774	Training Loss 1.6512 (1.5874)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.994)	
2022-03-28 00:45:12,942: ============================================================
2022-03-28 00:46:13,872: time cost, forward:0.017146235914677604, backward:0.041924811228012164, data cost:0.5814974581910107 
2022-03-28 00:46:13,872: ============================================================
2022-03-28 00:46:13,872: Epoch 33/38 Batch 7400/7662 eta: 6:31:42.841883	Training Loss 1.6248 (1.5876)	Training Prec@1 99.805 (99.973)	Training Prec@5 99.805 (99.994)	
2022-03-28 00:46:13,873: ============================================================
2022-03-28 00:47:18,333: time cost, forward:0.017180606228047204, backward:0.04197843714799384, data cost:0.5815000228523206 
2022-03-28 00:47:18,333: ============================================================
2022-03-28 00:47:18,333: Epoch 33/38 Batch 7500/7662 eta: 6:53:20.061805	Training Loss 1.4086 (1.5878)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-28 00:47:18,334: ============================================================
2022-03-28 00:48:22,758: time cost, forward:0.01717558260386924, backward:0.04197734722198193, data cost:0.5814098170092583 
2022-03-28 00:48:22,758: ============================================================
2022-03-28 00:48:22,759: Epoch 33/38 Batch 7600/7662 eta: 6:52:01.911084	Training Loss 1.5686 (1.5880)	Training Prec@1 99.805 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-28 00:48:22,759: ============================================================
2022-03-28 00:49:04,124: Epoch: 33/38 eta: 6:51:21.323160	Training Loss 1.5172 (1.5880)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)
2022-03-28 00:49:04,124: ============================================================
2022-03-28 00:49:04,213: Save Checkpoint...
2022-03-28 00:49:04,234: ============================================================
2022-03-28 00:49:06,412: Save done!
2022-03-28 00:49:06,413: ============================================================
2022-03-28 00:50:14,574: time cost, forward:0.012528720528188379, backward:0.03475655690588132, data cost:0.6357042717211174 
2022-03-28 00:50:14,574: ============================================================
2022-03-28 00:50:14,575: Epoch 34/38 Batch 100/7662 eta: 7:13:47.586820	Training Loss 1.5250 (1.5632)	Training Prec@1 100.000 (99.986)	Training Prec@5 100.000 (99.998)	
2022-03-28 00:50:14,575: ============================================================
2022-03-28 00:51:16,667: time cost, forward:0.013507418896085652, backward:0.03827695990327615, data cost:0.5991646368898939 
2022-03-28 00:51:16,668: ============================================================
2022-03-28 00:51:16,668: Epoch 34/38 Batch 200/7662 eta: 6:34:24.524984	Training Loss 1.4940 (1.5633)	Training Prec@1 100.000 (99.984)	Training Prec@5 100.000 (99.996)	
2022-03-28 00:51:16,669: ============================================================
2022-03-28 00:52:21,871: time cost, forward:0.014696385150769084, backward:0.039111099115582214, data cost:0.59633411531863 
2022-03-28 00:52:21,872: ============================================================
2022-03-28 00:52:21,873: Epoch 34/38 Batch 300/7662 eta: 6:53:04.808076	Training Loss 1.7186 (1.5640)	Training Prec@1 100.000 (99.982)	Training Prec@5 100.000 (99.996)	
2022-03-28 00:52:21,873: ============================================================
2022-03-28 00:53:23,768: time cost, forward:0.015076522540329094, backward:0.03996633527272925, data cost:0.5874867176352289 
2022-03-28 00:53:23,781: ============================================================
2022-03-28 00:53:23,781: Epoch 34/38 Batch 400/7662 eta: 6:31:10.178510	Training Loss 1.6341 (1.5666)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.994)	
2022-03-28 00:53:23,781: ============================================================
2022-03-28 00:54:25,342: time cost, forward:0.015352077140120084, backward:0.04008683938540533, data cost:0.5805399780999683 
2022-03-28 00:54:25,342: ============================================================
2022-03-28 00:54:25,343: Epoch 34/38 Batch 500/7662 eta: 6:27:57.207924	Training Loss 1.5387 (1.5668)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-03-28 00:54:25,343: ============================================================
2022-03-28 00:55:28,429: time cost, forward:0.015707936629230073, backward:0.039842221096083395, data cost:0.5800803587313288 
2022-03-28 00:55:28,430: ============================================================
2022-03-28 00:55:28,430: Epoch 34/38 Batch 600/7662 eta: 6:36:30.645743	Training Loss 1.6028 (1.5661)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.994)	
2022-03-28 00:55:28,430: ============================================================
2022-03-28 00:56:34,897: time cost, forward:0.015919152929718062, backward:0.0402155035043479, data cost:0.5835647296496216 
2022-03-28 00:56:34,898: ============================================================
2022-03-28 00:56:34,898: Epoch 34/38 Batch 700/7662 eta: 6:56:39.354062	Training Loss 1.5488 (1.5660)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.994)	
2022-03-28 00:56:34,898: ============================================================
2022-03-28 00:57:37,419: time cost, forward:0.01609596352702536, backward:0.04021398743640198, data cost:0.581164548334401 
2022-03-28 00:57:37,420: ============================================================
2022-03-28 00:57:37,420: Epoch 34/38 Batch 800/7662 eta: 6:30:52.600260	Training Loss 1.5570 (1.5660)	Training Prec@1 99.805 (99.978)	Training Prec@5 100.000 (99.995)	
2022-03-28 00:57:37,420: ============================================================
2022-03-28 00:58:39,127: time cost, forward:0.01602424662953887, backward:0.040386708347630314, data cost:0.5779947709453782 
2022-03-28 00:58:39,131: ============================================================
2022-03-28 00:58:39,132: Epoch 34/38 Batch 900/7662 eta: 6:24:46.895036	Training Loss 1.5348 (1.5652)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.994)	
2022-03-28 00:58:39,134: ============================================================
2022-03-28 00:59:36,803: time cost, forward:0.015804157839403733, backward:0.040032069604318064, data cost:0.5734611020551191 
2022-03-28 00:59:36,804: ============================================================
2022-03-28 00:59:36,804: Epoch 34/38 Batch 1000/7662 eta: 5:58:38.132706	Training Loss 1.7683 (1.5654)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-03-28 00:59:36,804: ============================================================
2022-03-28 01:00:35,675: time cost, forward:0.015518448589279827, backward:0.04008187718343691, data cost:0.5698746070740329 
2022-03-28 01:00:35,676: ============================================================
2022-03-28 01:00:35,676: Epoch 34/38 Batch 1100/7662 eta: 6:05:06.861509	Training Loss 1.6153 (1.5676)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:00:35,676: ============================================================
2022-03-28 01:01:39,619: time cost, forward:0.015740071066823774, backward:0.04036417774999013, data cost:0.5701771373048835 
2022-03-28 01:01:39,621: ============================================================
2022-03-28 01:01:39,622: Epoch 34/38 Batch 1200/7662 eta: 6:35:30.902858	Training Loss 1.5618 (1.5685)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:01:39,623: ============================================================
2022-03-28 01:02:44,743: time cost, forward:0.015987215453244063, backward:0.04065494155590125, data cost:0.5716431697026136 
2022-03-28 01:02:44,744: ============================================================
2022-03-28 01:02:44,744: Epoch 34/38 Batch 1300/7662 eta: 6:41:42.364034	Training Loss 1.7135 (1.5689)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:02:44,744: ============================================================
2022-03-28 01:03:47,503: time cost, forward:0.015984755060006416, backward:0.04063424832314743, data cost:0.5711642369958143 
2022-03-28 01:03:47,504: ============================================================
2022-03-28 01:03:47,504: Epoch 34/38 Batch 1400/7662 eta: 6:26:05.421831	Training Loss 1.5698 (1.5697)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:03:47,504: ============================================================
2022-03-28 01:04:51,341: time cost, forward:0.016049213294906564, backward:0.04072327865132338, data cost:0.5714647892397829 
2022-03-28 01:04:51,343: ============================================================
2022-03-28 01:04:51,344: Epoch 34/38 Batch 1500/7662 eta: 6:31:39.939633	Training Loss 1.5617 (1.5702)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:04:51,344: ============================================================
2022-03-28 01:05:52,705: time cost, forward:0.016071827431035236, backward:0.04091060198866777, data cost:0.5707726386131683 
2022-03-28 01:05:52,705: ============================================================
2022-03-28 01:05:52,706: Epoch 34/38 Batch 1600/7662 eta: 6:15:26.549637	Training Loss 1.6889 (1.5707)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:05:52,706: ============================================================
2022-03-28 01:06:57,141: time cost, forward:0.016140789337337823, backward:0.040999030000395884, data cost:0.570928256325051 
2022-03-28 01:06:57,142: ============================================================
2022-03-28 01:06:57,143: Epoch 34/38 Batch 1700/7662 eta: 6:33:10.943756	Training Loss 1.5387 (1.5706)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:06:57,143: ============================================================
2022-03-28 01:08:00,291: time cost, forward:0.01619372744239523, backward:0.04109818939370139, data cost:0.5713305088995296 
2022-03-28 01:08:00,292: ============================================================
2022-03-28 01:08:00,292: Epoch 34/38 Batch 1800/7662 eta: 6:24:16.549161	Training Loss 1.6318 (1.5710)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:08:00,292: ============================================================
2022-03-28 01:09:04,176: time cost, forward:0.016212106943758242, backward:0.041093257680072354, data cost:0.5716872614518538 
2022-03-28 01:09:04,176: ============================================================
2022-03-28 01:09:04,177: Epoch 34/38 Batch 1900/7662 eta: 6:27:41.008917	Training Loss 1.6381 (1.5711)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:09:04,177: ============================================================
2022-03-28 01:10:10,388: time cost, forward:0.016237818401655356, backward:0.0412912587036545, data cost:0.5732359429369455 
2022-03-28 01:10:10,388: ============================================================
2022-03-28 01:10:10,388: Epoch 34/38 Batch 2000/7662 eta: 6:40:42.229325	Training Loss 1.6266 (1.5709)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:10:10,389: ============================================================
2022-03-28 01:11:16,604: time cost, forward:0.016404207801182763, backward:0.04145111113062582, data cost:0.5742776107651781 
2022-03-28 01:11:16,605: ============================================================
2022-03-28 01:11:16,605: Epoch 34/38 Batch 2100/7662 eta: 6:39:37.581462	Training Loss 1.6442 (1.5713)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:11:16,605: ============================================================
2022-03-28 01:12:16,102: time cost, forward:0.016422114734380773, backward:0.04132934937210395, data cost:0.5726699913670227 
2022-03-28 01:12:16,104: ============================================================
2022-03-28 01:12:16,104: Epoch 34/38 Batch 2200/7662 eta: 5:58:05.674273	Training Loss 1.7006 (1.5718)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:12:16,104: ============================================================
2022-03-28 01:13:18,275: time cost, forward:0.016381351260218013, backward:0.04122884463309827, data cost:0.5722977374625652 
2022-03-28 01:13:18,276: ============================================================
2022-03-28 01:13:18,276: Epoch 34/38 Batch 2300/7662 eta: 6:13:08.832303	Training Loss 1.7676 (1.5723)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:13:18,276: ============================================================
2022-03-28 01:14:21,828: time cost, forward:0.01647206135917177, backward:0.04126191924342815, data cost:0.5722445373288688 
2022-03-28 01:14:21,851: ============================================================
2022-03-28 01:14:21,852: Epoch 34/38 Batch 2400/7662 eta: 6:20:30.652006	Training Loss 1.5226 (1.5726)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:14:21,852: ============================================================
2022-03-28 01:15:23,469: time cost, forward:0.016463589983112384, backward:0.04115809961145713, data cost:0.571629181724875 
2022-03-28 01:15:23,472: ============================================================
2022-03-28 01:15:23,473: Epoch 34/38 Batch 2500/7662 eta: 6:07:47.027597	Training Loss 1.5366 (1.5724)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:15:23,474: ============================================================
2022-03-28 01:16:25,037: time cost, forward:0.0163905493063668, backward:0.040860282590454385, data cost:0.5716351709626372 
2022-03-28 01:16:25,038: ============================================================
2022-03-28 01:16:25,038: Epoch 34/38 Batch 2600/7662 eta: 6:06:25.621911	Training Loss 1.4067 (1.5717)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:16:25,038: ============================================================
2022-03-28 01:17:28,192: time cost, forward:0.01635296568246893, backward:0.040859419401153986, data cost:0.5716408449175093 
2022-03-28 01:17:28,193: ============================================================
2022-03-28 01:17:28,193: Epoch 34/38 Batch 2700/7662 eta: 6:14:50.257706	Training Loss 1.6366 (1.5718)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:17:28,194: ============================================================
2022-03-28 01:18:30,442: time cost, forward:0.016370757471965695, backward:0.04087177614264507, data cost:0.5714534280469649 
2022-03-28 01:18:30,443: ============================================================
2022-03-28 01:18:30,443: Epoch 34/38 Batch 2800/7662 eta: 6:08:25.558639	Training Loss 1.5503 (1.5729)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:18:30,444: ============================================================
2022-03-28 01:19:34,273: time cost, forward:0.016458988765388902, backward:0.041002360735732386, data cost:0.571297588986584 
2022-03-28 01:19:34,279: ============================================================
2022-03-28 01:19:34,281: Epoch 34/38 Batch 2900/7662 eta: 6:16:45.422104	Training Loss 1.7009 (1.5729)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:19:34,283: ============================================================
2022-03-28 01:20:37,741: time cost, forward:0.016446472128537067, backward:0.04097139696233787, data cost:0.571561143015893 
2022-03-28 01:20:37,744: ============================================================
2022-03-28 01:20:37,745: Epoch 34/38 Batch 3000/7662 eta: 6:13:29.611984	Training Loss 1.5281 (1.5728)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:20:37,745: ============================================================
2022-03-28 01:21:39,496: time cost, forward:0.016475555088182308, backward:0.04098525675083984, data cost:0.571306059228947 
2022-03-28 01:21:39,497: ============================================================
2022-03-28 01:21:39,497: Epoch 34/38 Batch 3100/7662 eta: 6:02:23.709985	Training Loss 1.6060 (1.5734)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:21:39,497: ============================================================
2022-03-28 01:22:46,517: time cost, forward:0.016539910540948922, backward:0.0410449704590273, data cost:0.5721391011268208 
2022-03-28 01:22:46,519: ============================================================
2022-03-28 01:22:46,520: Epoch 34/38 Batch 3200/7662 eta: 6:32:12.216748	Training Loss 1.6999 (1.5735)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:22:46,520: ============================================================
2022-03-28 01:23:47,493: time cost, forward:0.016496332893591283, backward:0.04104679481446219, data cost:0.5718084014737631 
2022-03-28 01:23:47,493: ============================================================
2022-03-28 01:23:47,494: Epoch 34/38 Batch 3300/7662 eta: 5:55:47.817400	Training Loss 1.4553 (1.5744)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:23:47,494: ============================================================
2022-03-28 01:24:48,714: time cost, forward:0.016494058657828832, backward:0.04093423693556756, data cost:0.571381697061308 
2022-03-28 01:24:48,714: ============================================================
2022-03-28 01:24:48,715: Epoch 34/38 Batch 3400/7662 eta: 5:56:12.813021	Training Loss 1.4752 (1.5747)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:24:48,715: ============================================================
2022-03-28 01:25:51,319: time cost, forward:0.01650562201884516, backward:0.040732564909794086, data cost:0.5714553921316037 
2022-03-28 01:25:51,320: ============================================================
2022-03-28 01:25:51,320: Epoch 34/38 Batch 3500/7662 eta: 6:03:13.488306	Training Loss 1.6240 (1.5750)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:25:51,320: ============================================================
2022-03-28 01:26:51,891: time cost, forward:0.0164703303292315, backward:0.04063153379524572, data cost:0.5709075264614071 
2022-03-28 01:26:51,892: ============================================================
2022-03-28 01:26:51,892: Epoch 34/38 Batch 3600/7662 eta: 5:50:25.164308	Training Loss 1.5654 (1.5753)	Training Prec@1 99.805 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:26:51,892: ============================================================
2022-03-28 01:27:55,655: time cost, forward:0.01644365540643936, backward:0.040577962031780816, data cost:0.5712202549238532 
2022-03-28 01:27:55,655: ============================================================
2022-03-28 01:27:55,655: Epoch 34/38 Batch 3700/7662 eta: 6:07:49.082075	Training Loss 1.6097 (1.5753)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:27:55,655: ============================================================
2022-03-28 01:29:00,913: time cost, forward:0.01642777983155116, backward:0.04058956660606824, data cost:0.5716166733503028 
2022-03-28 01:29:00,916: ============================================================
2022-03-28 01:29:00,917: Epoch 34/38 Batch 3800/7662 eta: 6:15:22.436789	Training Loss 1.5685 (1.5755)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:29:00,918: ============================================================
2022-03-28 01:30:01,755: time cost, forward:0.01637073106171382, backward:0.04053841666950266, data cost:0.5711757727053325 
2022-03-28 01:30:01,758: ============================================================
2022-03-28 01:30:01,759: Epoch 34/38 Batch 3900/7662 eta: 5:48:56.124934	Training Loss 1.6054 (1.5756)	Training Prec@1 99.805 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:30:01,759: ============================================================
2022-03-28 01:31:07,091: time cost, forward:0.01639689675388589, backward:0.04061516376399016, data cost:0.5718859080285781 
2022-03-28 01:31:07,092: ============================================================
2022-03-28 01:31:07,092: Epoch 34/38 Batch 4000/7662 eta: 6:13:36.702232	Training Loss 1.5995 (1.5759)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:31:07,092: ============================================================
2022-03-28 01:32:07,965: time cost, forward:0.016378173597791364, backward:0.040587922834018055, data cost:0.5713910504532139 
2022-03-28 01:32:07,967: ============================================================
2022-03-28 01:32:07,968: Epoch 34/38 Batch 4100/7662 eta: 5:47:06.151876	Training Loss 1.4115 (1.5762)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:32:07,969: ============================================================
2022-03-28 01:33:09,443: time cost, forward:0.01635341741948447, backward:0.0405157231864375, data cost:0.571140796975256 
2022-03-28 01:33:09,444: ============================================================
2022-03-28 01:33:09,444: Epoch 34/38 Batch 4200/7662 eta: 5:49:30.086923	Training Loss 1.5104 (1.5769)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:33:09,444: ============================================================
2022-03-28 01:34:12,892: time cost, forward:0.016375289181826642, backward:0.04054328146910329, data cost:0.5712155481637092 
2022-03-28 01:34:12,893: ============================================================
2022-03-28 01:34:12,893: Epoch 34/38 Batch 4300/7662 eta: 5:59:39.722222	Training Loss 1.5272 (1.5771)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:34:12,893: ============================================================
2022-03-28 01:35:16,029: time cost, forward:0.016371142406251166, backward:0.04055945459727023, data cost:0.5712085979368016 
2022-03-28 01:35:16,070: ============================================================
2022-03-28 01:35:16,073: Epoch 34/38 Batch 4400/7662 eta: 5:57:04.796480	Training Loss 1.7355 (1.5770)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:35:16,074: ============================================================
2022-03-28 01:36:19,571: time cost, forward:0.016418248819070117, backward:0.04054859978115593, data cost:0.5713424392741743 
2022-03-28 01:36:19,572: ============================================================
2022-03-28 01:36:19,572: Epoch 34/38 Batch 4500/7662 eta: 5:57:49.693186	Training Loss 1.7282 (1.5774)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:36:19,572: ============================================================
2022-03-28 01:37:21,244: time cost, forward:0.016442227503558195, backward:0.040612300599909626, data cost:0.5709758171907687 
2022-03-28 01:37:21,245: ============================================================
2022-03-28 01:37:21,246: Epoch 34/38 Batch 4600/7662 eta: 5:46:30.792587	Training Loss 1.6422 (1.5779)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:37:21,246: ============================================================
2022-03-28 01:38:24,435: time cost, forward:0.01646489507468565, backward:0.04064135161783625, data cost:0.5709751277914654 
2022-03-28 01:38:24,435: ============================================================
2022-03-28 01:38:24,435: Epoch 34/38 Batch 4700/7662 eta: 5:53:58.796128	Training Loss 1.7349 (1.5786)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:38:24,436: ============================================================
2022-03-28 01:39:29,177: time cost, forward:0.016473781369482136, backward:0.04066138680862074, data cost:0.5713302568486145 
2022-03-28 01:39:29,177: ============================================================
2022-03-28 01:39:29,177: Epoch 34/38 Batch 4800/7662 eta: 6:01:35.704038	Training Loss 1.6024 (1.5789)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:39:29,178: ============================================================
2022-03-28 01:40:30,469: time cost, forward:0.01647015673015818, backward:0.04064381188289271, data cost:0.5708367477560268 
2022-03-28 01:40:30,472: ============================================================
2022-03-28 01:40:30,473: Epoch 34/38 Batch 4900/7662 eta: 5:41:19.384873	Training Loss 1.6006 (1.5792)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:40:30,474: ============================================================
2022-03-28 01:41:31,279: time cost, forward:0.016483241926553035, backward:0.04051121727755891, data cost:0.5706402681712796 
2022-03-28 01:41:31,283: ============================================================
2022-03-28 01:41:31,284: Epoch 34/38 Batch 5000/7662 eta: 5:37:36.507713	Training Loss 1.6022 (1.5794)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:41:31,284: ============================================================
2022-03-28 01:42:34,552: time cost, forward:0.016499500083885933, backward:0.04056226568938377, data cost:0.5706279356354801 
2022-03-28 01:42:34,553: ============================================================
2022-03-28 01:42:34,553: Epoch 34/38 Batch 5100/7662 eta: 5:50:12.593518	Training Loss 1.5756 (1.5796)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:42:34,553: ============================================================
2022-03-28 01:43:33,741: time cost, forward:0.016491621176676925, backward:0.04051082490567726, data cost:0.5700001540516954 
2022-03-28 01:43:33,743: ============================================================
2022-03-28 01:43:33,744: Epoch 34/38 Batch 5200/7662 eta: 5:26:38.511755	Training Loss 1.5182 (1.5798)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:43:33,744: ============================================================
2022-03-28 01:44:38,039: time cost, forward:0.016447284262592916, backward:0.04051466770139724, data cost:0.5702049513541656 
2022-03-28 01:44:38,042: ============================================================
2022-03-28 01:44:38,042: Epoch 34/38 Batch 5300/7662 eta: 5:53:45.585332	Training Loss 1.5108 (1.5802)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:44:38,043: ============================================================
2022-03-28 01:45:39,939: time cost, forward:0.01642660331584763, backward:0.04047938054701778, data cost:0.5701680285419705 
2022-03-28 01:45:39,942: ============================================================
2022-03-28 01:45:39,943: Epoch 34/38 Batch 5400/7662 eta: 5:39:32.109433	Training Loss 1.6176 (1.5804)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:45:39,945: ============================================================
2022-03-28 01:46:42,427: time cost, forward:0.016426379647248874, backward:0.0404660715625858, data cost:0.5702026023889026 
2022-03-28 01:46:42,427: ============================================================
2022-03-28 01:46:42,427: Epoch 34/38 Batch 5500/7662 eta: 5:41:41.792480	Training Loss 1.6320 (1.5809)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:46:42,428: ============================================================
2022-03-28 01:47:45,286: time cost, forward:0.016459676575971558, backward:0.040497593889067825, data cost:0.570120853363435 
2022-03-28 01:47:45,286: ============================================================
2022-03-28 01:47:45,287: Epoch 34/38 Batch 5600/7662 eta: 5:42:41.923449	Training Loss 1.7708 (1.5810)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:47:45,287: ============================================================
2022-03-28 01:48:46,402: time cost, forward:0.0164466069903075, backward:0.040467128311882816, data cost:0.5698186093661886 
2022-03-28 01:48:46,403: ============================================================
2022-03-28 01:48:46,403: Epoch 34/38 Batch 5700/7662 eta: 5:32:10.786531	Training Loss 1.6279 (1.5811)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:48:46,404: ============================================================
2022-03-28 01:49:48,790: time cost, forward:0.016443502164992983, backward:0.04049876752157091, data cost:0.5697702366147581 
2022-03-28 01:49:48,790: ============================================================
2022-03-28 01:49:48,791: Epoch 34/38 Batch 5800/7662 eta: 5:38:02.710691	Training Loss 1.5408 (1.5815)	Training Prec@1 99.805 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:49:48,791: ============================================================
2022-03-28 01:50:52,604: time cost, forward:0.016471217660342947, backward:0.04055202995483947, data cost:0.5698596486642737 
2022-03-28 01:50:52,604: ============================================================
2022-03-28 01:50:52,604: Epoch 34/38 Batch 5900/7662 eta: 5:44:42.664553	Training Loss 1.4641 (1.5818)	Training Prec@1 99.805 (99.975)	Training Prec@5 99.805 (99.994)	
2022-03-28 01:50:52,605: ============================================================
2022-03-28 01:51:54,601: time cost, forward:0.016468090819485845, backward:0.04058880590561887, data cost:0.56969090850577 
2022-03-28 01:51:54,601: ============================================================
2022-03-28 01:51:54,602: Epoch 34/38 Batch 6000/7662 eta: 5:33:51.897655	Training Loss 1.6011 (1.5819)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:51:54,602: ============================================================
2022-03-28 01:52:55,139: time cost, forward:0.01641981874182295, backward:0.04053669156432445, data cost:0.56929728190886 
2022-03-28 01:52:55,142: ============================================================
2022-03-28 01:52:55,143: Epoch 34/38 Batch 6100/7662 eta: 5:25:00.808638	Training Loss 1.5881 (1.5822)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:52:55,143: ============================================================
2022-03-28 01:53:56,931: time cost, forward:0.016432457690201262, backward:0.04054670696163162, data cost:0.5692406586436115 
2022-03-28 01:53:56,931: ============================================================
2022-03-28 01:53:56,932: Epoch 34/38 Batch 6200/7662 eta: 5:30:41.108214	Training Loss 1.6261 (1.5821)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:53:56,932: ============================================================
2022-03-28 01:54:58,700: time cost, forward:0.016429922205623247, backward:0.04052943804090336, data cost:0.5691013221873955 
2022-03-28 01:54:58,700: ============================================================
2022-03-28 01:54:58,701: Epoch 34/38 Batch 6300/7662 eta: 5:29:32.902998	Training Loss 1.4694 (1.5823)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:54:58,701: ============================================================
2022-03-28 01:55:59,190: time cost, forward:0.016430605163908058, backward:0.04056060692354522, data cost:0.5686919533809585 
2022-03-28 01:55:59,192: ============================================================
2022-03-28 01:55:59,192: Epoch 34/38 Batch 6400/7662 eta: 5:21:43.346975	Training Loss 1.5325 (1.5826)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:55:59,193: ============================================================
2022-03-28 01:57:02,047: time cost, forward:0.016420222407286855, backward:0.04057758381631232, data cost:0.5687413332296859 
2022-03-28 01:57:02,047: ============================================================
2022-03-28 01:57:02,048: Epoch 34/38 Batch 6500/7662 eta: 5:33:15.006937	Training Loss 1.5756 (1.5829)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:57:02,048: ============================================================
2022-03-28 01:58:02,890: time cost, forward:0.016451187252293827, backward:0.040606938305904075, data cost:0.5683899577557453 
2022-03-28 01:58:02,890: ============================================================
2022-03-28 01:58:02,891: Epoch 34/38 Batch 6600/7662 eta: 5:21:33.901179	Training Loss 1.6714 (1.5832)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:58:02,891: ============================================================
2022-03-28 01:59:04,932: time cost, forward:0.0164378263786989, backward:0.04060324278673604, data cost:0.5683249228569016 
2022-03-28 01:59:04,932: ============================================================
2022-03-28 01:59:04,933: Epoch 34/38 Batch 6700/7662 eta: 5:26:52.114952	Training Loss 1.5010 (1.5834)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.994)	
2022-03-28 01:59:04,933: ============================================================
2022-03-28 02:00:07,241: time cost, forward:0.01644695701099771, backward:0.04058966343499997, data cost:0.5681990651387224 
2022-03-28 02:00:07,242: ============================================================
2022-03-28 02:00:07,243: Epoch 34/38 Batch 6800/7662 eta: 5:27:14.473129	Training Loss 1.5385 (1.5837)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.994)	
2022-03-28 02:00:07,243: ============================================================
2022-03-28 02:01:07,754: time cost, forward:0.016444743483079345, backward:0.0406205875663796, data cost:0.5679269089942774 
2022-03-28 02:01:07,754: ============================================================
2022-03-28 02:01:07,755: Epoch 34/38 Batch 6900/7662 eta: 5:16:47.468082	Training Loss 1.5576 (1.5838)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.993)	
2022-03-28 02:01:07,755: ============================================================
2022-03-28 02:02:10,845: time cost, forward:0.016441087958505792, backward:0.040593638762795495, data cost:0.5680320768769187 
2022-03-28 02:02:10,846: ============================================================
2022-03-28 02:02:10,846: Epoch 34/38 Batch 7000/7662 eta: 5:29:14.581146	Training Loss 1.4856 (1.5841)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.993)	
2022-03-28 02:02:10,846: ============================================================
2022-03-28 02:03:14,659: time cost, forward:0.016468335044335303, backward:0.04062471925112408, data cost:0.5680218249714732 
2022-03-28 02:03:14,660: ============================================================
2022-03-28 02:03:14,661: Epoch 34/38 Batch 7100/7662 eta: 5:31:57.101209	Training Loss 1.5444 (1.5842)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.993)	
2022-03-28 02:03:14,661: ============================================================
2022-03-28 02:04:15,020: time cost, forward:0.016465297191072495, backward:0.04062319646396311, data cost:0.567817782441648 
2022-03-28 02:04:15,020: ============================================================
2022-03-28 02:04:15,021: Epoch 34/38 Batch 7200/7662 eta: 5:12:58.628495	Training Loss 1.6316 (1.5843)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-28 02:04:15,021: ============================================================
2022-03-28 02:05:19,009: time cost, forward:0.016485095791725905, backward:0.04063279214893764, data cost:0.5679776983108238 
2022-03-28 02:05:19,010: ============================================================
2022-03-28 02:05:19,011: Epoch 34/38 Batch 7300/7662 eta: 5:30:44.001009	Training Loss 1.7283 (1.5846)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-28 02:05:19,011: ============================================================
2022-03-28 02:06:17,780: time cost, forward:0.016447379115723745, backward:0.04056692948323969, data cost:0.5675024761994444 
2022-03-28 02:06:17,780: ============================================================
2022-03-28 02:06:17,781: Epoch 34/38 Batch 7400/7662 eta: 5:02:46.299919	Training Loss 1.6357 (1.5848)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-28 02:06:17,781: ============================================================
2022-03-28 02:07:18,910: time cost, forward:0.016477204590006532, backward:0.04057100452189605, data cost:0.5672465065095024 
2022-03-28 02:07:18,910: ============================================================
2022-03-28 02:07:18,911: Epoch 34/38 Batch 7500/7662 eta: 5:13:54.746852	Training Loss 1.6776 (1.5850)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.993)	
2022-03-28 02:07:18,911: ============================================================
2022-03-28 02:08:21,536: time cost, forward:0.01646245729140442, backward:0.04056866995079421, data cost:0.5673622504584585 
2022-03-28 02:08:21,537: ============================================================
2022-03-28 02:08:21,537: Epoch 34/38 Batch 7600/7662 eta: 5:20:33.254988	Training Loss 1.6015 (1.5855)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.993)	
2022-03-28 02:08:21,537: ============================================================
2022-03-28 02:09:02,234: Epoch: 34/38 eta: 5:19:53.800230	Training Loss 1.6508 (1.5856)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.993)
2022-03-28 02:09:02,235: ============================================================
2022-03-28 02:09:02,417: Save Checkpoint...
2022-03-28 02:09:02,418: ============================================================
2022-03-28 02:09:04,686: Save done!
2022-03-28 02:09:04,686: ============================================================
2022-03-28 02:10:09,900: time cost, forward:0.014479971895314227, backward:0.03001416331589824, data cost:0.6004815053458166 
2022-03-28 02:10:09,903: ============================================================
2022-03-28 02:10:09,904: Epoch 35/38 Batch 100/7662 eta: 5:31:49.842045	Training Loss 1.5408 (1.5543)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.994)	
2022-03-28 02:10:09,904: ============================================================
2022-03-28 02:11:08,269: time cost, forward:0.014741274579685538, backward:0.034572868490937964, data cost:0.5684186190216984 
2022-03-28 02:11:08,270: ============================================================
2022-03-28 02:11:08,270: Epoch 35/38 Batch 200/7662 eta: 4:56:12.076027	Training Loss 1.6886 (1.5546)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 02:11:08,270: ============================================================
2022-03-28 02:12:10,128: time cost, forward:0.015322033776886089, backward:0.036376564000362537, data cost:0.5658453890312476 
2022-03-28 02:12:10,129: ============================================================
2022-03-28 02:12:10,129: Epoch 35/38 Batch 300/7662 eta: 5:12:53.484718	Training Loss 1.6086 (1.5564)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.993)	
2022-03-28 02:12:10,129: ============================================================
2022-03-28 02:13:09,561: time cost, forward:0.015385873335644715, backward:0.03623417385837488, data cost:0.5596886607339806 
2022-03-28 02:13:09,562: ============================================================
2022-03-28 02:13:09,562: Epoch 35/38 Batch 400/7662 eta: 4:59:37.916684	Training Loss 1.4916 (1.5577)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.994)	
2022-03-28 02:13:09,562: ============================================================
2022-03-28 02:14:13,749: time cost, forward:0.015630564852085763, backward:0.03712599024266184, data cost:0.5638644934178354 
2022-03-28 02:14:13,749: ============================================================
2022-03-28 02:14:13,749: Epoch 35/38 Batch 500/7662 eta: 5:22:31.856885	Training Loss 1.6692 (1.5612)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.995)	
2022-03-28 02:14:13,750: ============================================================
2022-03-28 02:15:14,925: time cost, forward:0.015680557101318156, backward:0.037294773506202764, data cost:0.5629916943373385 
2022-03-28 02:15:14,926: ============================================================
2022-03-28 02:15:14,926: Epoch 35/38 Batch 600/7662 eta: 5:06:23.003167	Training Loss 1.3512 (1.5618)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.995)	
2022-03-28 02:15:14,926: ============================================================
2022-03-28 02:16:15,476: time cost, forward:0.015781725936693185, backward:0.03808065954707723, data cost:0.5604929497654687 
2022-03-28 02:16:15,477: ============================================================
2022-03-28 02:16:15,477: Epoch 35/38 Batch 700/7662 eta: 5:02:14.441732	Training Loss 1.4755 (1.5620)	Training Prec@1 99.805 (99.973)	Training Prec@5 100.000 (99.995)	
2022-03-28 02:16:15,478: ============================================================
2022-03-28 02:17:19,047: time cost, forward:0.015890888338244154, backward:0.03855178591903667, data cost:0.5625472549204534 
2022-03-28 02:17:19,048: ============================================================
2022-03-28 02:17:19,048: Epoch 35/38 Batch 800/7662 eta: 5:16:15.303479	Training Loss 1.6320 (1.5625)	Training Prec@1 99.805 (99.975)	Training Prec@5 99.805 (99.995)	
2022-03-28 02:17:19,048: ============================================================
2022-03-28 02:18:19,144: time cost, forward:0.016036305995088266, backward:0.038206938509150794, data cost:0.5605537265506019 
2022-03-28 02:18:19,145: ============================================================
2022-03-28 02:18:19,145: Epoch 35/38 Batch 900/7662 eta: 4:57:58.117762	Training Loss 1.4387 (1.5640)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 02:18:19,145: ============================================================
2022-03-28 02:19:22,262: time cost, forward:0.0161771149010033, backward:0.038300229503108456, data cost:0.5620388407129664 
2022-03-28 02:19:22,262: ============================================================
2022-03-28 02:19:22,262: Epoch 35/38 Batch 1000/7662 eta: 5:11:53.762379	Training Loss 1.6850 (1.5647)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.995)	
2022-03-28 02:19:22,263: ============================================================
2022-03-28 02:20:24,723: time cost, forward:0.016306990379632007, backward:0.038692292134473276, data cost:0.5613829317257771 
2022-03-28 02:20:24,727: ============================================================
2022-03-28 02:20:24,729: Epoch 35/38 Batch 1100/7662 eta: 5:07:38.172908	Training Loss 1.6062 (1.5649)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.995)	
2022-03-28 02:20:24,730: ============================================================
2022-03-28 02:21:28,400: time cost, forward:0.01640979462210788, backward:0.03894272976064801, data cost:0.5627763094357195 
2022-03-28 02:21:28,403: ============================================================
2022-03-28 02:21:28,404: Epoch 35/38 Batch 1200/7662 eta: 5:12:31.488687	Training Loss 1.5763 (1.5643)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.995)	
2022-03-28 02:21:28,404: ============================================================
2022-03-28 02:22:30,664: time cost, forward:0.016449587449741142, backward:0.03914428821795715, data cost:0.5631779965480719 
2022-03-28 02:22:30,665: ============================================================
2022-03-28 02:22:30,665: Epoch 35/38 Batch 1300/7662 eta: 5:04:33.158319	Training Loss 1.5897 (1.5654)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.995)	
2022-03-28 02:22:30,665: ============================================================
2022-03-28 02:23:29,980: time cost, forward:0.016460621331401006, backward:0.03907306046039399, data cost:0.5612595234707989 
2022-03-28 02:23:29,980: ============================================================
2022-03-28 02:23:29,980: Epoch 35/38 Batch 1400/7662 eta: 4:49:09.152526	Training Loss 1.5921 (1.5662)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.995)	
2022-03-28 02:23:29,981: ============================================================
2022-03-28 02:24:36,069: time cost, forward:0.016670754784500703, backward:0.03949985494607285, data cost:0.5634567115686988 
2022-03-28 02:24:36,070: ============================================================
2022-03-28 02:24:36,070: Epoch 35/38 Batch 1500/7662 eta: 5:21:04.508123	Training Loss 1.5108 (1.5660)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.995)	
2022-03-28 02:24:36,070: ============================================================
2022-03-28 02:25:34,212: time cost, forward:0.016586183681571536, backward:0.03955784479180599, data cost:0.5610867761834999 
2022-03-28 02:25:34,213: ============================================================
2022-03-28 02:25:34,213: Epoch 35/38 Batch 1600/7662 eta: 4:41:29.950964	Training Loss 1.5662 (1.5656)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.995)	
2022-03-28 02:25:34,213: ============================================================
2022-03-28 02:26:37,138: time cost, forward:0.016474912558112724, backward:0.0396350663574111, data cost:0.5613740450357816 
2022-03-28 02:26:37,141: ============================================================
2022-03-28 02:26:37,141: Epoch 35/38 Batch 1700/7662 eta: 5:03:37.018085	Training Loss 1.5841 (1.5663)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 02:26:37,142: ============================================================
2022-03-28 02:27:37,137: time cost, forward:0.01648633582118884, backward:0.03987171399454199, data cost:0.5605076378487825 
2022-03-28 02:27:37,137: ============================================================
2022-03-28 02:27:37,138: Epoch 35/38 Batch 1800/7662 eta: 4:48:28.376739	Training Loss 1.5257 (1.5670)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 02:27:37,138: ============================================================
2022-03-28 02:28:39,135: time cost, forward:0.016518409532142224, backward:0.03999631777758847, data cost:0.5604443848917772 
2022-03-28 02:28:39,135: ============================================================
2022-03-28 02:28:39,135: Epoch 35/38 Batch 1900/7662 eta: 4:57:03.770585	Training Loss 1.5919 (1.5671)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 02:28:39,136: ============================================================
2022-03-28 02:29:39,640: time cost, forward:0.01641904466923861, backward:0.040109698923901954, data cost:0.5596916267667906 
2022-03-28 02:29:39,640: ============================================================
2022-03-28 02:29:39,641: Epoch 35/38 Batch 2000/7662 eta: 4:48:54.155487	Training Loss 1.5320 (1.5678)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 02:29:39,641: ============================================================
2022-03-28 02:30:43,629: time cost, forward:0.016524814094118188, backward:0.040333676531293265, data cost:0.5603754874806907 
2022-03-28 02:30:43,632: ============================================================
2022-03-28 02:30:43,633: Epoch 35/38 Batch 2100/7662 eta: 5:04:29.071481	Training Loss 1.5244 (1.5675)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 02:30:43,633: ============================================================
2022-03-28 02:31:44,224: time cost, forward:0.016537468343390396, backward:0.04044388423675079, data cost:0.5598271609762139 
2022-03-28 02:31:44,224: ============================================================
2022-03-28 02:31:44,225: Epoch 35/38 Batch 2200/7662 eta: 4:47:17.825272	Training Loss 1.4556 (1.5679)	Training Prec@1 99.805 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 02:31:44,225: ============================================================
2022-03-28 02:32:46,777: time cost, forward:0.0165692679308559, backward:0.040469190772588794, data cost:0.5600944371159152 
2022-03-28 02:32:46,778: ============================================================
2022-03-28 02:32:46,778: Epoch 35/38 Batch 2300/7662 eta: 4:55:33.209982	Training Loss 1.5707 (1.5679)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 02:32:46,778: ============================================================
2022-03-28 02:33:50,423: time cost, forward:0.016530119413731247, backward:0.04045185768489989, data cost:0.5608935810318089 
2022-03-28 02:33:50,423: ============================================================
2022-03-28 02:33:50,423: Epoch 35/38 Batch 2400/7662 eta: 4:59:39.180102	Training Loss 1.5189 (1.5681)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 02:33:50,424: ============================================================
2022-03-28 02:34:51,970: time cost, forward:0.0165019183218026, backward:0.0404071296487345, data cost:0.560800303359564 
2022-03-28 02:34:51,971: ============================================================
2022-03-28 02:34:51,971: Epoch 35/38 Batch 2500/7662 eta: 4:48:45.020376	Training Loss 1.7469 (1.5683)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.995)	
2022-03-28 02:34:51,971: ============================================================
2022-03-28 02:35:53,513: time cost, forward:0.01644848951609055, backward:0.040354211498288384, data cost:0.5607982275347473 
2022-03-28 02:35:53,513: ============================================================
2022-03-28 02:35:53,514: Epoch 35/38 Batch 2600/7662 eta: 4:47:42.102575	Training Loss 1.4633 (1.5692)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.995)	
2022-03-28 02:35:53,514: ============================================================
2022-03-28 02:36:55,288: time cost, forward:0.01642367494419885, backward:0.040338129235798006, data cost:0.560782035309635 
2022-03-28 02:36:55,288: ============================================================
2022-03-28 02:36:55,288: Epoch 35/38 Batch 2700/7662 eta: 4:47:45.417613	Training Loss 1.6290 (1.5694)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.995)	
2022-03-28 02:36:55,288: ============================================================
2022-03-28 02:37:53,943: time cost, forward:0.016417420476877335, backward:0.040241544269672164, data cost:0.5597283686855599 
2022-03-28 02:37:53,944: ============================================================
2022-03-28 02:37:53,944: Epoch 35/38 Batch 2800/7662 eta: 4:32:15.011078	Training Loss 1.4482 (1.5695)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.995)	
2022-03-28 02:37:53,944: ============================================================
2022-03-28 02:38:54,807: time cost, forward:0.01640703473349364, backward:0.0402935480569798, data cost:0.5593976214574344 
2022-03-28 02:38:54,808: ============================================================
2022-03-28 02:38:54,808: Epoch 35/38 Batch 2900/7662 eta: 4:41:29.247578	Training Loss 1.6313 (1.5697)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.995)	
2022-03-28 02:38:54,808: ============================================================
2022-03-28 02:39:56,376: time cost, forward:0.016447275151567246, backward:0.04029997947733575, data cost:0.5592888637795851 
2022-03-28 02:39:56,377: ============================================================
2022-03-28 02:39:56,377: Epoch 35/38 Batch 3000/7662 eta: 4:43:43.107866	Training Loss 1.6739 (1.5700)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 02:39:56,377: ============================================================
2022-03-28 02:40:59,273: time cost, forward:0.01642878096347549, backward:0.040319577460521346, data cost:0.5596603244764261 
2022-03-28 02:40:59,274: ============================================================
2022-03-28 02:40:59,274: Epoch 35/38 Batch 3100/7662 eta: 4:48:47.554715	Training Loss 1.5678 (1.5706)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 02:40:59,274: ============================================================
2022-03-28 02:42:07,638: time cost, forward:0.01646520376727148, backward:0.040397572793152675, data cost:0.5613474084198866 
2022-03-28 02:42:07,640: ============================================================
2022-03-28 02:42:07,641: Epoch 35/38 Batch 3200/7662 eta: 5:12:46.037047	Training Loss 1.5383 (1.5707)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 02:42:07,642: ============================================================
2022-03-28 02:43:08,635: time cost, forward:0.016515851562837646, backward:0.040421025830350094, data cost:0.5612449354025478 
2022-03-28 02:43:08,636: ============================================================
2022-03-28 02:43:08,636: Epoch 35/38 Batch 3300/7662 eta: 4:38:01.442447	Training Loss 1.4589 (1.5708)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 02:43:08,636: ============================================================
2022-03-28 02:44:10,488: time cost, forward:0.016493541207444003, backward:0.04035682901279756, data cost:0.5613107895914264 
2022-03-28 02:44:10,488: ============================================================
2022-03-28 02:44:10,489: Epoch 35/38 Batch 3400/7662 eta: 4:40:54.247419	Training Loss 1.7262 (1.5710)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 02:44:10,489: ============================================================
2022-03-28 02:45:11,394: time cost, forward:0.016521831211549074, backward:0.04034001461333225, data cost:0.5609974895214551 
2022-03-28 02:45:11,394: ============================================================
2022-03-28 02:45:11,394: Epoch 35/38 Batch 3500/7662 eta: 4:35:35.332111	Training Loss 1.5797 (1.5717)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 02:45:11,395: ============================================================
2022-03-28 02:46:11,070: time cost, forward:0.016468258624806872, backward:0.04021706233987811, data cost:0.5604964398980041 
2022-03-28 02:46:11,071: ============================================================
2022-03-28 02:46:11,072: Epoch 35/38 Batch 3600/7662 eta: 4:29:02.088171	Training Loss 1.7088 (1.5725)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 02:46:11,072: ============================================================
2022-03-28 02:47:13,973: time cost, forward:0.01652905199133921, backward:0.040137004839403946, data cost:0.560848221903912 
2022-03-28 02:47:13,976: ============================================================
2022-03-28 02:47:13,977: Epoch 35/38 Batch 3700/7662 eta: 4:42:32.273904	Training Loss 1.6751 (1.5728)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 02:47:13,977: ============================================================
2022-03-28 02:48:15,560: time cost, forward:0.016509821992950962, backward:0.04009579871635306, data cost:0.5608092880650676 
2022-03-28 02:48:15,561: ============================================================
2022-03-28 02:48:15,561: Epoch 35/38 Batch 3800/7662 eta: 4:35:34.760204	Training Loss 1.6407 (1.5732)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 02:48:15,561: ============================================================
2022-03-28 02:49:15,664: time cost, forward:0.0165095279754263, backward:0.04008742998000382, data cost:0.560314591709361 
2022-03-28 02:49:15,669: ============================================================
2022-03-28 02:49:15,670: Epoch 35/38 Batch 3900/7662 eta: 4:27:58.426684	Training Loss 1.4913 (1.5736)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 02:49:15,673: ============================================================
2022-03-28 02:50:18,758: time cost, forward:0.01648962721284493, backward:0.04004374639068016, data cost:0.5605880307924691 
2022-03-28 02:50:18,761: ============================================================
2022-03-28 02:50:18,762: Epoch 35/38 Batch 4000/7662 eta: 4:40:13.389687	Training Loss 1.6576 (1.5738)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 02:50:18,763: ============================================================
2022-03-28 02:51:18,953: time cost, forward:0.016485008270922565, backward:0.03999785616154146, data cost:0.5604193120445964 
2022-03-28 02:51:18,953: ============================================================
2022-03-28 02:51:18,954: Epoch 35/38 Batch 4100/7662 eta: 4:26:20.394818	Training Loss 1.6412 (1.5737)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 02:51:18,954: ============================================================
2022-03-28 02:52:21,181: time cost, forward:0.01650703938468975, backward:0.040067274078183814, data cost:0.5603843814107627 
2022-03-28 02:52:21,181: ============================================================
2022-03-28 02:52:21,182: Epoch 35/38 Batch 4200/7662 eta: 4:34:18.637793	Training Loss 1.6761 (1.5742)	Training Prec@1 99.805 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 02:52:21,182: ============================================================
2022-03-28 02:53:24,212: time cost, forward:0.01648039284293722, backward:0.04009494656156623, data cost:0.560688838816765 
2022-03-28 02:53:24,213: ============================================================
2022-03-28 02:53:24,213: Epoch 35/38 Batch 4300/7662 eta: 4:36:48.199927	Training Loss 1.5939 (1.5747)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 02:53:24,213: ============================================================
2022-03-28 02:54:25,874: time cost, forward:0.016488777992264145, backward:0.04011739441198933, data cost:0.5606305912479159 
2022-03-28 02:54:25,875: ============================================================
2022-03-28 02:54:25,875: Epoch 35/38 Batch 4400/7662 eta: 4:29:45.638839	Training Loss 1.5265 (1.5748)	Training Prec@1 99.805 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 02:54:25,875: ============================================================
2022-03-28 02:55:27,538: time cost, forward:0.016485353871752723, backward:0.0400841396685361, data cost:0.5606281024452102 
2022-03-28 02:55:27,538: ============================================================
2022-03-28 02:55:27,539: Epoch 35/38 Batch 4500/7662 eta: 4:28:44.410017	Training Loss 1.4839 (1.5752)	Training Prec@1 99.805 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 02:55:27,539: ============================================================
2022-03-28 02:56:28,671: time cost, forward:0.01651607277238335, backward:0.0401518789678326, data cost:0.5602690788371897 
2022-03-28 02:56:28,673: ============================================================
2022-03-28 02:56:28,674: Epoch 35/38 Batch 4600/7662 eta: 4:25:24.933365	Training Loss 1.4994 (1.5755)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 02:56:28,674: ============================================================
2022-03-28 02:57:29,924: time cost, forward:0.0165140671942127, backward:0.04013891198782749, data cost:0.5602544143520078 
2022-03-28 02:57:29,924: ============================================================
2022-03-28 02:57:29,924: Epoch 35/38 Batch 4700/7662 eta: 4:24:54.070104	Training Loss 1.4933 (1.5759)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 02:57:29,925: ============================================================
2022-03-28 02:58:28,890: time cost, forward:0.016523508658928782, backward:0.04012457995048089, data cost:0.5596664435765624 
2022-03-28 02:58:28,891: ============================================================
2022-03-28 02:58:28,891: Epoch 35/38 Batch 4800/7662 eta: 4:14:02.226376	Training Loss 1.5598 (1.5764)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 02:58:28,891: ============================================================
2022-03-28 02:59:31,361: time cost, forward:0.016557300059156385, backward:0.04015123929313602, data cost:0.5597370726937152 
2022-03-28 02:59:31,361: ============================================================
2022-03-28 02:59:31,362: Epoch 35/38 Batch 4900/7662 eta: 4:28:05.633161	Training Loss 1.5523 (1.5766)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 02:59:31,362: ============================================================
2022-03-28 03:00:33,909: time cost, forward:0.016587423023926684, backward:0.04018307156647699, data cost:0.5597503067946811 
2022-03-28 03:00:33,910: ============================================================
2022-03-28 03:00:33,911: Epoch 35/38 Batch 5000/7662 eta: 4:27:23.125749	Training Loss 1.4692 (1.5769)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 03:00:33,911: ============================================================
2022-03-28 03:01:36,747: time cost, forward:0.016602357711762068, backward:0.04022817519113676, data cost:0.55998741815922 
2022-03-28 03:01:36,747: ============================================================
2022-03-28 03:01:36,748: Epoch 35/38 Batch 5100/7662 eta: 4:27:34.241854	Training Loss 1.5471 (1.5771)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 03:01:36,748: ============================================================
2022-03-28 03:02:35,370: time cost, forward:0.01657559473162822, backward:0.04022313815214286, data cost:0.5594057725883259 
2022-03-28 03:02:35,370: ============================================================
2022-03-28 03:02:35,371: Epoch 35/38 Batch 5200/7662 eta: 4:08:38.945039	Training Loss 1.7011 (1.5775)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 03:02:35,371: ============================================================
2022-03-28 03:03:36,990: time cost, forward:0.016567293934876975, backward:0.04021596296662811, data cost:0.5593994422371961 
2022-03-28 03:03:36,991: ============================================================
2022-03-28 03:03:36,991: Epoch 35/38 Batch 5300/7662 eta: 4:20:20.120674	Training Loss 1.5876 (1.5778)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 03:03:36,991: ============================================================
2022-03-28 03:04:38,919: time cost, forward:0.01655813348935829, backward:0.040227386284192465, data cost:0.559440094843068 
2022-03-28 03:04:38,919: ============================================================
2022-03-28 03:04:38,919: Epoch 35/38 Batch 5400/7662 eta: 4:20:36.333992	Training Loss 1.6601 (1.5780)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 03:04:38,920: ============================================================
2022-03-28 03:05:34,436: time cost, forward:0.016557777463403436, backward:0.04021074546859749, data cost:0.5582508674034705 
2022-03-28 03:05:34,438: ============================================================
2022-03-28 03:05:34,439: Epoch 35/38 Batch 5500/7662 eta: 3:52:42.581731	Training Loss 1.5121 (1.5783)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 03:05:34,439: ============================================================
2022-03-28 03:06:33,491: time cost, forward:0.01651673726597776, backward:0.04019750197203292, data cost:0.5579152843061782 
2022-03-28 03:06:33,491: ============================================================
2022-03-28 03:06:33,491: Epoch 35/38 Batch 5600/7662 eta: 4:06:32.081152	Training Loss 1.5572 (1.5786)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 03:06:33,492: ============================================================
2022-03-28 03:07:33,684: time cost, forward:0.016470127177669366, backward:0.0402374080574958, data cost:0.5576765493753396 
2022-03-28 03:07:33,685: ============================================================
2022-03-28 03:07:33,685: Epoch 35/38 Batch 5700/7662 eta: 4:10:17.729979	Training Loss 1.4732 (1.5787)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 03:07:33,685: ============================================================
2022-03-28 03:08:34,068: time cost, forward:0.016439496412176905, backward:0.0401852137468091, data cost:0.5574685515443052 
2022-03-28 03:08:34,071: ============================================================
2022-03-28 03:08:34,072: Epoch 35/38 Batch 5800/7662 eta: 4:10:05.308648	Training Loss 1.5319 (1.5790)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 03:08:34,072: ============================================================
2022-03-28 03:09:35,986: time cost, forward:0.016466927540506382, backward:0.0401879165269173, data cost:0.5575533279788193 
2022-03-28 03:09:35,986: ============================================================
2022-03-28 03:09:35,986: Epoch 35/38 Batch 5900/7662 eta: 4:15:23.408542	Training Loss 1.6582 (1.5792)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 03:09:35,987: ============================================================
2022-03-28 03:10:35,763: time cost, forward:0.016470065651823827, backward:0.0401747254932656, data cost:0.5572998198613979 
2022-03-28 03:10:35,764: ============================================================
2022-03-28 03:10:35,764: Epoch 35/38 Batch 6000/7662 eta: 4:05:34.602380	Training Loss 1.6001 (1.5796)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 03:10:35,764: ============================================================
2022-03-28 03:11:38,223: time cost, forward:0.01648598433439996, backward:0.04023527665145281, data cost:0.5572730742002788 
2022-03-28 03:11:38,224: ============================================================
2022-03-28 03:11:38,224: Epoch 35/38 Batch 6100/7662 eta: 4:15:33.298210	Training Loss 1.4438 (1.5797)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 03:11:38,224: ============================================================
2022-03-28 03:12:39,438: time cost, forward:0.01649265813142912, backward:0.0402639267963447, data cost:0.5572981452880357 
2022-03-28 03:12:39,439: ============================================================
2022-03-28 03:12:39,439: Epoch 35/38 Batch 6200/7662 eta: 4:09:26.417265	Training Loss 1.7145 (1.5798)	Training Prec@1 99.805 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 03:12:39,439: ============================================================
2022-03-28 03:13:39,690: time cost, forward:0.016481245334308513, backward:0.0402856575608121, data cost:0.5570124001858026 
2022-03-28 03:13:39,691: ============================================================
2022-03-28 03:13:39,691: Epoch 35/38 Batch 6300/7662 eta: 4:04:30.770823	Training Loss 1.5629 (1.5800)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 03:13:39,691: ============================================================
2022-03-28 03:14:39,302: time cost, forward:0.016464152397970087, backward:0.0402346623094776, data cost:0.5567227842510073 
2022-03-28 03:14:39,303: ============================================================
2022-03-28 03:14:39,304: Epoch 35/38 Batch 6400/7662 eta: 4:00:55.439970	Training Loss 1.7155 (1.5802)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 03:14:39,304: ============================================================
2022-03-28 03:15:40,349: time cost, forward:0.016483909406190947, backward:0.04022780013535642, data cost:0.556765001871931 
2022-03-28 03:15:40,350: ============================================================
2022-03-28 03:15:40,350: Epoch 35/38 Batch 6500/7662 eta: 4:05:42.106035	Training Loss 1.6704 (1.5807)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 03:15:40,350: ============================================================
2022-03-28 03:16:41,959: time cost, forward:0.016452218785685542, backward:0.04020416322919993, data cost:0.5567371918949544 
2022-03-28 03:16:41,961: ============================================================
2022-03-28 03:16:41,961: Epoch 35/38 Batch 6600/7662 eta: 4:06:56.779349	Training Loss 1.5575 (1.5808)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 03:16:41,961: ============================================================
2022-03-28 03:17:44,163: time cost, forward:0.016450381773695125, backward:0.04022940846944428, data cost:0.5569001555282654 
2022-03-28 03:17:44,164: ============================================================
2022-03-28 03:17:44,164: Epoch 35/38 Batch 6700/7662 eta: 4:08:17.039596	Training Loss 1.6421 (1.5809)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 03:17:44,164: ============================================================
2022-03-28 03:18:44,657: time cost, forward:0.016453799122763936, backward:0.04023528193740183, data cost:0.5567772312714153 
2022-03-28 03:18:44,658: ============================================================
2022-03-28 03:18:44,658: Epoch 35/38 Batch 6800/7662 eta: 4:00:27.265054	Training Loss 1.5708 (1.5814)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 03:18:44,658: ============================================================
2022-03-28 03:19:45,770: time cost, forward:0.01645812547315738, backward:0.040235725895773414, data cost:0.5566737312806794 
2022-03-28 03:19:45,770: ============================================================
2022-03-28 03:19:45,771: Epoch 35/38 Batch 6900/7662 eta: 4:01:53.571319	Training Loss 1.6069 (1.5816)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.994)	
2022-03-28 03:19:45,771: ============================================================
2022-03-28 03:20:46,176: time cost, forward:0.016451501764558285, backward:0.04022118837122475, data cost:0.5566013608767078 
2022-03-28 03:20:46,176: ============================================================
2022-03-28 03:20:46,176: Epoch 35/38 Batch 7000/7662 eta: 3:58:05.287264	Training Loss 1.5928 (1.5820)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 03:20:46,176: ============================================================
2022-03-28 03:21:48,036: time cost, forward:0.016502310413930733, backward:0.040254731667950246, data cost:0.5565602482162844 
2022-03-28 03:21:48,037: ============================================================
2022-03-28 03:21:48,037: Epoch 35/38 Batch 7100/7662 eta: 4:02:47.669812	Training Loss 1.6597 (1.5823)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.994)	
2022-03-28 03:21:48,037: ============================================================
2022-03-28 03:22:51,909: time cost, forward:0.01650329175335216, backward:0.04024623294458868, data cost:0.5568164331513257 
2022-03-28 03:22:51,910: ============================================================
2022-03-28 03:22:51,910: Epoch 35/38 Batch 7200/7662 eta: 4:09:37.508299	Training Loss 1.4881 (1.5825)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 03:22:51,910: ============================================================
2022-03-28 03:23:52,746: time cost, forward:0.016488187655077712, backward:0.04028075975103727, data cost:0.5568034327802699 
2022-03-28 03:23:52,746: ============================================================
2022-03-28 03:23:52,746: Epoch 35/38 Batch 7300/7662 eta: 3:56:44.720715	Training Loss 1.4954 (1.5826)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.994)	
2022-03-28 03:23:52,747: ============================================================
2022-03-28 03:24:51,215: time cost, forward:0.016456942797383838, backward:0.04025586886508414, data cost:0.5564514831491928 
2022-03-28 03:24:51,215: ============================================================
2022-03-28 03:24:51,216: Epoch 35/38 Batch 7400/7662 eta: 3:46:33.509882	Training Loss 1.6388 (1.5829)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 03:24:51,216: ============================================================
2022-03-28 03:25:50,697: time cost, forward:0.016430445998044694, backward:0.04022182746161809, data cost:0.5562574371272269 
2022-03-28 03:25:50,698: ============================================================
2022-03-28 03:25:50,698: Epoch 35/38 Batch 7500/7662 eta: 3:49:29.554325	Training Loss 1.6345 (1.5833)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.994)	
2022-03-28 03:25:50,698: ============================================================
2022-03-28 03:26:51,282: time cost, forward:0.01642337757155274, backward:0.04020195955476536, data cost:0.556059658597968 
2022-03-28 03:26:51,285: ============================================================
2022-03-28 03:26:51,286: Epoch 35/38 Batch 7600/7662 eta: 3:52:44.768495	Training Loss 1.5893 (1.5835)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.994)	
2022-03-28 03:26:51,286: ============================================================
2022-03-28 03:27:35,157: Epoch: 35/38 eta: 3:52:06.598491	Training Loss 1.6163 (1.5835)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.994)
2022-03-28 03:27:35,158: ============================================================
2022-03-28 03:27:35,160: Save Checkpoint...
2022-03-28 03:27:35,161: ============================================================
2022-03-28 03:27:37,320: Save done!
2022-03-28 03:27:37,320: ============================================================
2022-03-28 03:28:37,198: time cost, forward:0.013105426171813348, backward:0.03346204516863582, data cost:0.5529646680812643 
2022-03-28 03:28:37,199: ============================================================
2022-03-28 03:28:37,199: Epoch 36/38 Batch 100/7662 eta: 3:48:24.141175	Training Loss 1.6677 (1.5594)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.992)	
2022-03-28 03:28:37,199: ============================================================
2022-03-28 03:29:35,192: time cost, forward:0.01266442471413157, backward:0.032624750281099096, data cost:0.5436522313697854 
2022-03-28 03:29:35,192: ============================================================
2022-03-28 03:29:35,193: Epoch 36/38 Batch 200/7662 eta: 3:40:14.989166	Training Loss 1.5750 (1.5607)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.991)	
2022-03-28 03:29:35,193: ============================================================
2022-03-28 03:30:36,090: time cost, forward:0.013476972994597061, backward:0.03355678268100904, data cost:0.5479411496765239 
2022-03-28 03:30:36,091: ============================================================
2022-03-28 03:30:36,091: Epoch 36/38 Batch 300/7662 eta: 3:50:15.993898	Training Loss 1.6407 (1.5665)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.992)	
2022-03-28 03:30:36,091: ============================================================
2022-03-28 03:31:38,494: time cost, forward:0.013410509678355435, backward:0.03296742642433721, data cost:0.5559011772461703 
2022-03-28 03:31:38,494: ============================================================
2022-03-28 03:31:38,494: Epoch 36/38 Batch 400/7662 eta: 3:54:55.040921	Training Loss 1.6066 (1.5647)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.992)	
2022-03-28 03:31:38,495: ============================================================
2022-03-28 03:32:39,398: time cost, forward:0.013158735626924014, backward:0.03260728113636942, data cost:0.5573587551384507 
2022-03-28 03:32:39,398: ============================================================
2022-03-28 03:32:39,398: Epoch 36/38 Batch 500/7662 eta: 3:48:15.502434	Training Loss 1.5569 (1.5645)	Training Prec@1 100.000 (99.971)	Training Prec@5 100.000 (99.993)	
2022-03-28 03:32:39,399: ============================================================
2022-03-28 03:33:38,797: time cost, forward:0.013521862746479117, backward:0.03318289245707364, data cost:0.5549100599623283 
2022-03-28 03:33:38,799: ============================================================
2022-03-28 03:33:38,799: Epoch 36/38 Batch 600/7662 eta: 3:41:37.997367	Training Loss 1.6050 (1.5635)	Training Prec@1 99.805 (99.971)	Training Prec@5 99.805 (99.993)	
2022-03-28 03:33:38,799: ============================================================
2022-03-28 03:34:43,775: time cost, forward:0.0138541789184483, backward:0.03343915257160585, data cost:0.560992219417392 
2022-03-28 03:34:43,776: ============================================================
2022-03-28 03:34:43,776: Epoch 36/38 Batch 700/7662 eta: 4:01:21.386688	Training Loss 1.5353 (1.5642)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.993)	
2022-03-28 03:34:43,776: ============================================================
2022-03-28 03:35:46,869: time cost, forward:0.014199544849324137, backward:0.034234511538948374, data cost:0.5614575921966973 
2022-03-28 03:35:46,871: ============================================================
2022-03-28 03:35:46,873: Epoch 36/38 Batch 800/7662 eta: 3:53:19.156272	Training Loss 1.4432 (1.5652)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.992)	
2022-03-28 03:35:46,873: ============================================================
2022-03-28 03:36:45,464: time cost, forward:0.014454268507485395, backward:0.03437835435580889, data cost:0.5592084686801219 
2022-03-28 03:36:45,465: ============================================================
2022-03-28 03:36:45,465: Epoch 36/38 Batch 900/7662 eta: 3:35:41.338844	Training Loss 1.6863 (1.5656)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.993)	
2022-03-28 03:36:45,465: ============================================================
2022-03-28 03:37:42,625: time cost, forward:0.014431771812018927, backward:0.03426524206205412, data cost:0.5553080016547615 
2022-03-28 03:37:42,630: ============================================================
2022-03-28 03:37:42,631: Epoch 36/38 Batch 1000/7662 eta: 3:29:28.955403	Training Loss 1.5147 (1.5650)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.993)	
2022-03-28 03:37:42,633: ============================================================
2022-03-28 03:38:45,658: time cost, forward:0.014680583440140229, backward:0.035111403877459625, data cost:0.5565897097253496 
2022-03-28 03:38:45,658: ============================================================
2022-03-28 03:38:45,658: Epoch 36/38 Batch 1100/7662 eta: 3:49:54.954353	Training Loss 1.4552 (1.5644)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.993)	
2022-03-28 03:38:45,659: ============================================================
2022-03-28 03:39:47,424: time cost, forward:0.01488053331383076, backward:0.0354182455716678, data cost:0.5563304245322819 
2022-03-28 03:39:47,426: ============================================================
2022-03-28 03:39:47,427: Epoch 36/38 Batch 1200/7662 eta: 3:44:17.419952	Training Loss 1.5171 (1.5665)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.993)	
2022-03-28 03:39:47,427: ============================================================
2022-03-28 03:40:49,393: time cost, forward:0.015009206106701294, backward:0.03573965732642006, data cost:0.5573669078260133 
2022-03-28 03:40:49,393: ============================================================
2022-03-28 03:40:49,393: Epoch 36/38 Batch 1300/7662 eta: 3:43:58.754905	Training Loss 1.5698 (1.5668)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 03:40:49,394: ============================================================
2022-03-28 03:41:49,469: time cost, forward:0.015063761983112066, backward:0.03584021802797242, data cost:0.556568783807107 
2022-03-28 03:41:49,469: ============================================================
2022-03-28 03:41:49,469: Epoch 36/38 Batch 1400/7662 eta: 3:36:08.612857	Training Loss 1.4834 (1.5660)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 03:41:49,470: ============================================================
2022-03-28 03:42:53,172: time cost, forward:0.015203716756503848, backward:0.03600341753612923, data cost:0.5581943268295604 
2022-03-28 03:42:53,173: ============================================================
2022-03-28 03:42:53,173: Epoch 36/38 Batch 1500/7662 eta: 3:48:08.014955	Training Loss 1.5782 (1.5654)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.993)	
2022-03-28 03:42:53,173: ============================================================
2022-03-28 03:43:53,377: time cost, forward:0.015235502769083736, backward:0.03620873756003126, data cost:0.5574134135708502 
2022-03-28 03:43:53,378: ============================================================
2022-03-28 03:43:53,378: Epoch 36/38 Batch 1600/7662 eta: 3:34:36.002439	Training Loss 1.6477 (1.5649)	Training Prec@1 99.805 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 03:43:53,378: ============================================================
2022-03-28 03:44:53,249: time cost, forward:0.015431750164514714, backward:0.0364785806230407, data cost:0.5562516204604968 
2022-03-28 03:44:53,250: ============================================================
2022-03-28 03:44:53,250: Epoch 36/38 Batch 1700/7662 eta: 3:32:24.971312	Training Loss 1.5789 (1.5647)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 03:44:53,250: ============================================================
2022-03-28 03:45:53,434: time cost, forward:0.015649282912402234, backward:0.03672271758201985, data cost:0.5552486583482829 
2022-03-28 03:45:53,439: ============================================================
2022-03-28 03:45:53,440: Epoch 36/38 Batch 1800/7662 eta: 3:32:32.230627	Training Loss 1.5507 (1.5656)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 03:45:53,441: ============================================================
2022-03-28 03:46:53,650: time cost, forward:0.01569798332945556, backward:0.036882259269461246, data cost:0.5547797859436967 
2022-03-28 03:46:53,653: ============================================================
2022-03-28 03:46:53,654: Epoch 36/38 Batch 1900/7662 eta: 3:31:37.412299	Training Loss 1.4401 (1.5662)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 03:46:53,655: ============================================================
2022-03-28 03:47:54,630: time cost, forward:0.015760996152067733, backward:0.0369882568113204, data cost:0.5542377967605476 
2022-03-28 03:47:54,658: ============================================================
2022-03-28 03:47:54,659: Epoch 36/38 Batch 2000/7662 eta: 3:33:23.036663	Training Loss 1.4849 (1.5675)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-03-28 03:47:54,660: ============================================================
2022-03-28 03:48:53,850: time cost, forward:0.015780261495443912, backward:0.0369767865548536, data cost:0.553829781835337 
2022-03-28 03:48:53,851: ============================================================
2022-03-28 03:48:53,851: Epoch 36/38 Batch 2100/7662 eta: 3:26:03.569519	Training Loss 1.5786 (1.5681)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 03:48:53,851: ============================================================
2022-03-28 03:49:54,549: time cost, forward:0.015726940585245267, backward:0.03702852117738815, data cost:0.5538016875910184 
2022-03-28 03:49:54,549: ============================================================
2022-03-28 03:49:54,550: Epoch 36/38 Batch 2200/7662 eta: 3:30:17.428500	Training Loss 1.4748 (1.5683)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 03:49:54,550: ============================================================
2022-03-28 03:50:55,480: time cost, forward:0.015667848143177274, backward:0.03722744612343262, data cost:0.5535603342184869 
2022-03-28 03:50:55,481: ============================================================
2022-03-28 03:50:55,481: Epoch 36/38 Batch 2300/7662 eta: 3:30:04.934513	Training Loss 1.5742 (1.5690)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 03:50:55,482: ============================================================
2022-03-28 03:51:55,204: time cost, forward:0.015703830186304026, backward:0.03723677340623188, data cost:0.5531988678598663 
2022-03-28 03:51:55,205: ============================================================
2022-03-28 03:51:55,206: Epoch 36/38 Batch 2400/7662 eta: 3:24:55.441426	Training Loss 1.6003 (1.5694)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 03:51:55,206: ============================================================
2022-03-28 03:52:55,304: time cost, forward:0.01572647024126423, backward:0.037373891683901345, data cost:0.5527302590118689 
2022-03-28 03:52:55,305: ============================================================
2022-03-28 03:52:55,305: Epoch 36/38 Batch 2500/7662 eta: 3:25:12.581818	Training Loss 1.6817 (1.5699)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 03:52:55,305: ============================================================
2022-03-28 03:53:53,780: time cost, forward:0.015768817224242036, backward:0.037469128912896, data cost:0.5516429806085861 
2022-03-28 03:53:53,783: ============================================================
2022-03-28 03:53:53,784: Epoch 36/38 Batch 2600/7662 eta: 3:18:42.070052	Training Loss 1.5742 (1.5704)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 03:53:53,785: ============================================================
2022-03-28 03:54:55,219: time cost, forward:0.0159090338216176, backward:0.037598738188035136, data cost:0.5517976324661611 
2022-03-28 03:54:55,219: ============================================================
2022-03-28 03:54:55,220: Epoch 36/38 Batch 2700/7662 eta: 3:27:43.458270	Training Loss 1.5913 (1.5706)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 03:54:55,220: ============================================================
2022-03-28 03:55:56,684: time cost, forward:0.015900476271018423, backward:0.037646828825535966, data cost:0.5521143295373947 
2022-03-28 03:55:56,685: ============================================================
2022-03-28 03:55:56,685: Epoch 36/38 Batch 2800/7662 eta: 3:26:48.067702	Training Loss 1.5040 (1.5703)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 03:55:56,685: ============================================================
2022-03-28 03:56:57,890: time cost, forward:0.015926622612470593, backward:0.03774116984232823, data cost:0.552179081927665 
2022-03-28 03:56:57,891: ============================================================
2022-03-28 03:56:57,891: Epoch 36/38 Batch 2900/7662 eta: 3:24:54.404795	Training Loss 1.4389 (1.5703)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 03:56:57,891: ============================================================
2022-03-28 03:57:54,861: time cost, forward:0.01585246881432198, backward:0.0376846432566603, data cost:0.5510455883117706 
2022-03-28 03:57:54,862: ============================================================
2022-03-28 03:57:54,862: Epoch 36/38 Batch 3000/7662 eta: 3:09:46.783278	Training Loss 1.5725 (1.5704)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 03:57:54,862: ============================================================
2022-03-28 03:58:53,532: time cost, forward:0.015861324280760064, backward:0.03775528662817907, data cost:0.5503487367713094 
2022-03-28 03:58:53,532: ============================================================
2022-03-28 03:58:53,532: Epoch 36/38 Batch 3100/7662 eta: 3:14:27.795278	Training Loss 1.5782 (1.5706)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 03:58:53,533: ============================================================
2022-03-28 03:59:54,062: time cost, forward:0.015884931551810165, backward:0.03775539834933864, data cost:0.5503197342353002 
2022-03-28 03:59:54,062: ============================================================
2022-03-28 03:59:54,062: Epoch 36/38 Batch 3200/7662 eta: 3:19:37.047978	Training Loss 1.4877 (1.5709)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 03:59:54,063: ============================================================
2022-03-28 04:00:53,546: time cost, forward:0.015897961882758625, backward:0.0377211093758048, data cost:0.5499903495183819 
2022-03-28 04:00:53,546: ============================================================
2022-03-28 04:00:53,547: Epoch 36/38 Batch 3300/7662 eta: 3:15:10.670554	Training Loss 1.4585 (1.5713)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 04:00:53,547: ============================================================
2022-03-28 04:02:00,810: time cost, forward:0.01598367560572679, backward:0.03783641692013136, data cost:0.5515676465024665 
2022-03-28 04:02:00,811: ============================================================
2022-03-28 04:02:00,812: Epoch 36/38 Batch 3400/7662 eta: 3:39:35.199447	Training Loss 1.4989 (1.5716)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 04:02:00,812: ============================================================
2022-03-28 04:02:55,626: time cost, forward:0.015963271468937414, backward:0.03778210289991389, data cost:0.5502139305039521 
2022-03-28 04:02:55,626: ============================================================
2022-03-28 04:02:55,626: Epoch 36/38 Batch 3500/7662 eta: 2:58:01.762915	Training Loss 1.6454 (1.5721)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 04:02:55,627: ============================================================
2022-03-28 04:03:54,182: time cost, forward:0.01592899720249457, backward:0.037699797180633675, data cost:0.5497819149153005 
2022-03-28 04:03:54,182: ============================================================
2022-03-28 04:03:54,183: Epoch 36/38 Batch 3600/7662 eta: 3:09:12.292025	Training Loss 1.4520 (1.5719)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.993)	
2022-03-28 04:03:54,183: ============================================================
2022-03-28 04:04:53,449: time cost, forward:0.015932493707430495, backward:0.03770823664328768, data cost:0.5493342090084863 
2022-03-28 04:04:53,455: ============================================================
2022-03-28 04:04:53,460: Epoch 36/38 Batch 3700/7662 eta: 3:10:32.521475	Training Loss 1.6031 (1.5719)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.993)	
2022-03-28 04:04:53,463: ============================================================
2022-03-28 04:05:54,336: time cost, forward:0.015981504809828174, backward:0.03780967199541952, data cost:0.5494217381850139 
2022-03-28 04:05:54,337: ============================================================
2022-03-28 04:05:54,337: Epoch 36/38 Batch 3800/7662 eta: 3:14:40.767719	Training Loss 1.6345 (1.5715)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 04:05:54,337: ============================================================
2022-03-28 04:06:57,105: time cost, forward:0.016048587203239838, backward:0.037994075781505945, data cost:0.5496314827923164 
2022-03-28 04:06:57,105: ============================================================
2022-03-28 04:06:57,105: Epoch 36/38 Batch 3900/7662 eta: 3:19:40.594397	Training Loss 1.5315 (1.5719)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 04:06:57,106: ============================================================
2022-03-28 04:07:58,203: time cost, forward:0.0160731188384674, backward:0.03803786488585724, data cost:0.5497028671464016 
2022-03-28 04:07:58,206: ============================================================
2022-03-28 04:07:58,208: Epoch 36/38 Batch 4000/7662 eta: 3:13:21.413698	Training Loss 1.3882 (1.5720)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 04:07:58,210: ============================================================
2022-03-28 04:08:57,576: time cost, forward:0.016116598694171518, backward:0.0380403377219333, data cost:0.5494811060254706 
2022-03-28 04:08:57,577: ============================================================
2022-03-28 04:08:57,578: Epoch 36/38 Batch 4100/7662 eta: 3:06:53.220479	Training Loss 1.6993 (1.5721)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 04:08:57,578: ============================================================
2022-03-28 04:09:57,164: time cost, forward:0.016128325468019292, backward:0.038064782067008404, data cost:0.5492440547566098 
2022-03-28 04:09:57,165: ============================================================
2022-03-28 04:09:57,165: Epoch 36/38 Batch 4200/7662 eta: 3:06:34.728502	Training Loss 1.5765 (1.5725)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 04:09:57,165: ============================================================
2022-03-28 04:10:56,857: time cost, forward:0.01613214310448401, backward:0.03810675744817378, data cost:0.5490141408502792 
2022-03-28 04:10:56,857: ============================================================
2022-03-28 04:10:56,857: Epoch 36/38 Batch 4300/7662 eta: 3:05:54.651731	Training Loss 1.4961 (1.5727)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 04:10:56,858: ============================================================
2022-03-28 04:11:55,937: time cost, forward:0.016135220799724685, backward:0.03812185177127728, data cost:0.5486847434051472 
2022-03-28 04:11:55,937: ============================================================
2022-03-28 04:11:55,937: Epoch 36/38 Batch 4400/7662 eta: 3:03:01.206986	Training Loss 1.5529 (1.5728)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 04:11:55,937: ============================================================
2022-03-28 04:12:57,366: time cost, forward:0.016157868915887694, backward:0.03818645151913709, data cost:0.5488030689508286 
2022-03-28 04:12:57,366: ============================================================
2022-03-28 04:12:57,367: Epoch 36/38 Batch 4500/7662 eta: 3:09:16.459122	Training Loss 1.4966 (1.5731)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 04:12:57,367: ============================================================
2022-03-28 04:14:01,400: time cost, forward:0.016204694842068778, backward:0.038277081702942174, data cost:0.5494023192107717 
2022-03-28 04:14:01,402: ============================================================
2022-03-28 04:14:01,403: Epoch 36/38 Batch 4600/7662 eta: 3:16:14.296561	Training Loss 1.6280 (1.5736)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 04:14:01,404: ============================================================
2022-03-28 04:14:59,827: time cost, forward:0.016208214261578, backward:0.03829184956539436, data cost:0.5489968944037308 
2022-03-28 04:14:59,828: ============================================================
2022-03-28 04:14:59,828: Epoch 36/38 Batch 4700/7662 eta: 2:58:04.211307	Training Loss 1.5555 (1.5740)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 04:14:59,828: ============================================================
2022-03-28 04:15:57,902: time cost, forward:0.016180598852559413, backward:0.038301270861107996, data cost:0.5484439691272123 
2022-03-28 04:15:57,904: ============================================================
2022-03-28 04:15:57,905: Epoch 36/38 Batch 4800/7662 eta: 2:56:02.455300	Training Loss 1.6371 (1.5744)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 04:15:57,906: ============================================================
2022-03-28 04:16:57,405: time cost, forward:0.016178292093239992, backward:0.03837002941870548, data cost:0.5482606569049941 
2022-03-28 04:16:57,405: ============================================================
2022-03-28 04:16:57,405: Epoch 36/38 Batch 4900/7662 eta: 2:59:21.870823	Training Loss 1.4174 (1.5744)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 04:16:57,406: ============================================================
2022-03-28 04:17:56,917: time cost, forward:0.01616384125061096, backward:0.038391037878214684, data cost:0.5480605839109106 
2022-03-28 04:17:56,917: ============================================================
2022-03-28 04:17:56,917: Epoch 36/38 Batch 5000/7662 eta: 2:58:24.427915	Training Loss 1.4973 (1.5745)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 04:17:56,918: ============================================================
2022-03-28 04:18:57,337: time cost, forward:0.016178277596045204, backward:0.03838997486643427, data cost:0.547983285468521 
2022-03-28 04:18:57,338: ============================================================
2022-03-28 04:18:57,339: Epoch 36/38 Batch 5100/7662 eta: 3:00:07.463672	Training Loss 1.6605 (1.5751)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 04:18:57,339: ============================================================
2022-03-28 04:20:01,619: time cost, forward:0.016233314846909763, backward:0.03851732030972354, data cost:0.5486095994911553 
2022-03-28 04:20:01,619: ============================================================
2022-03-28 04:20:01,619: Epoch 36/38 Batch 5200/7662 eta: 3:10:33.657551	Training Loss 1.5798 (1.5752)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 04:20:01,619: ============================================================
2022-03-28 04:21:00,918: time cost, forward:0.016240482443704945, backward:0.03852104506282947, data cost:0.5483669188140046 
2022-03-28 04:21:00,919: ============================================================
2022-03-28 04:21:00,920: Epoch 36/38 Batch 5300/7662 eta: 2:54:48.420594	Training Loss 1.7019 (1.5754)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 04:21:00,920: ============================================================
2022-03-28 04:22:00,989: time cost, forward:0.016248073505458843, backward:0.03853978746841298, data cost:0.5482923155207173 
2022-03-28 04:22:00,989: ============================================================
2022-03-28 04:22:00,989: Epoch 36/38 Batch 5400/7662 eta: 2:56:04.483172	Training Loss 1.5865 (1.5757)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 04:22:00,989: ============================================================
2022-03-28 04:23:01,845: time cost, forward:0.016235812704527154, backward:0.03858142051724526, data cost:0.5482601098395148 
2022-03-28 04:23:01,846: ============================================================
2022-03-28 04:23:01,846: Epoch 36/38 Batch 5500/7662 eta: 2:57:22.026712	Training Loss 1.4290 (1.5759)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 04:23:01,846: ============================================================
2022-03-28 04:24:02,721: time cost, forward:0.016258742643650313, backward:0.03859355880184075, data cost:0.5482249942117982 
2022-03-28 04:24:02,722: ============================================================
2022-03-28 04:24:02,722: Epoch 36/38 Batch 5600/7662 eta: 2:56:24.511558	Training Loss 1.5869 (1.5762)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 04:24:02,722: ============================================================
2022-03-28 04:25:02,245: time cost, forward:0.016255878778816756, backward:0.038584594790151944, data cost:0.5482195994167458 
2022-03-28 04:25:02,245: ============================================================
2022-03-28 04:25:02,246: Epoch 36/38 Batch 5700/7662 eta: 2:51:29.813220	Training Loss 1.5757 (1.5763)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 04:25:02,246: ============================================================
2022-03-28 04:26:01,479: time cost, forward:0.016279691045583168, backward:0.038637598499509256, data cost:0.5479438827045623 
2022-03-28 04:26:01,480: ============================================================
2022-03-28 04:26:01,480: Epoch 36/38 Batch 5800/7662 eta: 2:49:40.621743	Training Loss 1.5185 (1.5766)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 04:26:01,480: ============================================================
2022-03-28 04:27:03,183: time cost, forward:0.01630365834395387, backward:0.038647959729052536, data cost:0.5481288524416872 
2022-03-28 04:27:03,184: ============================================================
2022-03-28 04:27:03,184: Epoch 36/38 Batch 5900/7662 eta: 2:55:43.341377	Training Loss 1.5462 (1.5764)	Training Prec@1 99.805 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 04:27:03,184: ============================================================
2022-03-28 04:28:02,737: time cost, forward:0.01631947628039681, backward:0.03869957744250557, data cost:0.5478150062033248 
2022-03-28 04:28:02,740: ============================================================
2022-03-28 04:28:02,741: Epoch 36/38 Batch 6000/7662 eta: 2:48:36.808621	Training Loss 1.5823 (1.5768)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 04:28:02,741: ============================================================
2022-03-28 04:29:01,517: time cost, forward:0.016344279534583367, backward:0.038671878228951406, data cost:0.5476386769909725 
2022-03-28 04:29:01,518: ============================================================
2022-03-28 04:29:01,518: Epoch 36/38 Batch 6100/7662 eta: 2:45:25.841041	Training Loss 1.5036 (1.5771)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 04:29:01,518: ============================================================
2022-03-28 04:29:59,916: time cost, forward:0.016315868428146134, backward:0.03865059100152754, data cost:0.5473731473715656 
2022-03-28 04:29:59,916: ============================================================
2022-03-28 04:29:59,916: Epoch 36/38 Batch 6200/7662 eta: 2:43:23.331855	Training Loss 1.6864 (1.5778)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 04:29:59,917: ============================================================
2022-03-28 04:30:59,524: time cost, forward:0.016331030009454878, backward:0.038625636844904505, data cost:0.5472507103224902 
2022-03-28 04:30:59,525: ============================================================
2022-03-28 04:30:59,525: Epoch 36/38 Batch 6300/7662 eta: 2:45:46.841512	Training Loss 1.5380 (1.5782)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 04:30:59,525: ============================================================
2022-03-28 04:31:58,299: time cost, forward:0.01632955264702386, backward:0.03860548530300812, data cost:0.5470416341690109 
2022-03-28 04:31:58,300: ============================================================
2022-03-28 04:31:58,300: Epoch 36/38 Batch 6400/7662 eta: 2:42:29.062851	Training Loss 1.5927 (1.5783)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 04:31:58,300: ============================================================
2022-03-28 04:32:57,024: time cost, forward:0.01632096980567858, backward:0.038631171075210774, data cost:0.5467579583788601 
2022-03-28 04:32:57,028: ============================================================
2022-03-28 04:32:57,030: Epoch 36/38 Batch 6500/7662 eta: 2:41:22.682556	Training Loss 1.4199 (1.5785)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 04:32:57,031: ============================================================
2022-03-28 04:33:59,069: time cost, forward:0.016341956714226055, backward:0.03865215463662874, data cost:0.5469895971058029 
2022-03-28 04:33:59,069: ============================================================
2022-03-28 04:33:59,070: Epoch 36/38 Batch 6600/7662 eta: 2:49:26.522963	Training Loss 1.6432 (1.5787)	Training Prec@1 99.805 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 04:33:59,070: ============================================================
2022-03-28 04:34:59,702: time cost, forward:0.016356325590854297, backward:0.03866812613032117, data cost:0.547002954614004 
2022-03-28 04:34:59,702: ============================================================
2022-03-28 04:34:59,703: Epoch 36/38 Batch 6700/7662 eta: 2:44:35.315954	Training Loss 1.5114 (1.5791)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 04:34:59,703: ============================================================
2022-03-28 04:35:58,268: time cost, forward:0.01638072942140997, backward:0.038670493567896376, data cost:0.5467234766997034 
2022-03-28 04:35:58,268: ============================================================
2022-03-28 04:35:58,269: Epoch 36/38 Batch 6800/7662 eta: 2:38:00.063173	Training Loss 1.5357 (1.5793)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 04:35:58,269: ============================================================
2022-03-28 04:36:58,804: time cost, forward:0.0163844045754325, backward:0.038652258448746604, data cost:0.5467536805384158 
2022-03-28 04:36:58,805: ============================================================
2022-03-28 04:36:58,806: Epoch 36/38 Batch 6900/7662 eta: 2:42:18.585109	Training Loss 1.5737 (1.5795)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 04:36:58,806: ============================================================
2022-03-28 04:37:57,047: time cost, forward:0.016368025455292267, backward:0.03863439333065865, data cost:0.5464678146546527 
2022-03-28 04:37:57,048: ============================================================
2022-03-28 04:37:57,048: Epoch 36/38 Batch 7000/7662 eta: 2:35:11.238663	Training Loss 1.5388 (1.5798)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 04:37:57,048: ============================================================
2022-03-28 04:38:57,756: time cost, forward:0.016360712145429075, backward:0.038619122650946074, data cost:0.5465577023854506 
2022-03-28 04:38:57,757: ============================================================
2022-03-28 04:38:57,757: Epoch 36/38 Batch 7100/7662 eta: 2:40:44.799228	Training Loss 1.7362 (1.5801)	Training Prec@1 99.805 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 04:38:57,757: ============================================================
2022-03-28 04:39:56,898: time cost, forward:0.016357724774892272, backward:0.03865203643477713, data cost:0.546293332885083 
2022-03-28 04:39:56,899: ============================================================
2022-03-28 04:39:56,899: Epoch 36/38 Batch 7200/7662 eta: 2:35:36.765751	Training Loss 1.5363 (1.5804)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 04:39:56,899: ============================================================
2022-03-28 04:40:55,736: time cost, forward:0.016370068414355978, backward:0.0386724680772398, data cost:0.5461087632561435 
2022-03-28 04:40:55,736: ============================================================
2022-03-28 04:40:55,737: Epoch 36/38 Batch 7300/7662 eta: 2:33:49.839538	Training Loss 1.6151 (1.5806)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 04:40:55,737: ============================================================
2022-03-28 04:41:54,325: time cost, forward:0.01636794229216923, backward:0.03866330416303403, data cost:0.5459413492030301 
2022-03-28 04:41:54,326: ============================================================
2022-03-28 04:41:54,326: Epoch 36/38 Batch 7400/7662 eta: 2:32:12.341976	Training Loss 1.6975 (1.5808)	Training Prec@1 99.805 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 04:41:54,326: ============================================================
2022-03-28 04:42:53,822: time cost, forward:0.016350770603896683, backward:0.038694297906509606, data cost:0.5458380899392441 
2022-03-28 04:42:53,822: ============================================================
2022-03-28 04:42:53,822: Epoch 36/38 Batch 7500/7662 eta: 2:33:34.156716	Training Loss 1.6655 (1.5812)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 04:42:53,822: ============================================================
2022-03-28 04:43:51,516: time cost, forward:0.016316594191484818, backward:0.03864755124100762, data cost:0.5455903162029421 
2022-03-28 04:43:51,517: ============================================================
2022-03-28 04:43:51,517: Epoch 36/38 Batch 7600/7662 eta: 2:27:57.485544	Training Loss 1.6251 (1.5816)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 04:43:51,517: ============================================================
2022-03-28 04:44:33,485: Epoch: 36/38 eta: 2:27:21.137874	Training Loss 1.5895 (1.5817)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)
2022-03-28 04:44:33,485: ============================================================
2022-03-28 04:44:33,626: Save Checkpoint...
2022-03-28 04:44:33,627: ============================================================
2022-03-28 04:44:36,218: Save done!
2022-03-28 04:44:36,218: ============================================================
2022-03-28 04:45:35,798: time cost, forward:0.012910761014379636, backward:0.031268088504521535, data cost:0.5527293152279324 
2022-03-28 04:45:35,799: ============================================================
2022-03-28 04:45:35,800: Epoch 37/38 Batch 100/7662 eta: 2:31:05.336843	Training Loss 1.5831 (1.5561)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.992)	
2022-03-28 04:45:35,800: ============================================================
2022-03-28 04:46:33,837: time cost, forward:0.01344624236600483, backward:0.03263129541023293, data cost:0.5375220488064253 
2022-03-28 04:46:33,838: ============================================================
2022-03-28 04:46:33,838: Epoch 37/38 Batch 200/7662 eta: 2:26:18.288265	Training Loss 1.5316 (1.5540)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.994)	
2022-03-28 04:46:33,838: ============================================================
2022-03-28 04:47:30,098: time cost, forward:0.013522534864802026, backward:0.0342836459743538, data cost:0.531151868029183 
2022-03-28 04:47:30,098: ============================================================
2022-03-28 04:47:30,098: Epoch 37/38 Batch 300/7662 eta: 2:20:53.108702	Training Loss 1.5374 (1.5569)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.994)	
2022-03-28 04:47:30,099: ============================================================
2022-03-28 04:48:29,068: time cost, forward:0.014206830122715848, backward:0.03481413009471463, data cost:0.5322544503032713 
2022-03-28 04:48:29,069: ============================================================
2022-03-28 04:48:29,069: Epoch 37/38 Batch 400/7662 eta: 2:26:41.391782	Training Loss 1.5266 (1.5572)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.995)	
2022-03-28 04:48:29,069: ============================================================
2022-03-28 04:49:26,719: time cost, forward:0.01470780515957452, backward:0.03540594735460912, data cost:0.5298841305390627 
2022-03-28 04:49:26,720: ============================================================
2022-03-28 04:49:26,721: Epoch 37/38 Batch 500/7662 eta: 2:22:26.814267	Training Loss 1.7589 (1.5596)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.996)	
2022-03-28 04:49:26,721: ============================================================
2022-03-28 04:50:25,605: time cost, forward:0.014883581107367259, backward:0.03578752906175209, data cost:0.5295560857489432 
2022-03-28 04:50:25,605: ============================================================
2022-03-28 04:50:25,606: Epoch 37/38 Batch 600/7662 eta: 2:24:30.806278	Training Loss 1.4869 (1.5596)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.995)	
2022-03-28 04:50:25,606: ============================================================
2022-03-28 04:51:23,207: time cost, forward:0.014872744018598347, backward:0.03565085155940022, data cost:0.5298019420776585 
2022-03-28 04:51:23,208: ============================================================
2022-03-28 04:51:23,208: Epoch 37/38 Batch 700/7662 eta: 2:20:24.327717	Training Loss 1.6367 (1.5604)	Training Prec@1 99.805 (99.978)	Training Prec@5 100.000 (99.995)	
2022-03-28 04:51:23,208: ============================================================
2022-03-28 04:52:21,349: time cost, forward:0.015098955216485358, backward:0.03593432530294521, data cost:0.5293430527101023 
2022-03-28 04:52:21,350: ============================================================
2022-03-28 04:52:21,350: Epoch 37/38 Batch 800/7662 eta: 2:20:45.170410	Training Loss 1.5966 (1.5610)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.995)	
2022-03-28 04:52:21,351: ============================================================
2022-03-28 04:53:17,095: time cost, forward:0.014988971101296227, backward:0.035842284212123036, data cost:0.5268762461733367 
2022-03-28 04:53:17,096: ============================================================
2022-03-28 04:53:17,096: Epoch 37/38 Batch 900/7662 eta: 2:14:01.306650	Training Loss 1.6225 (1.5624)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.995)	
2022-03-28 04:53:17,096: ============================================================
2022-03-28 04:54:16,785: time cost, forward:0.015125078004640382, backward:0.03616139074942252, data cost:0.5277828716778302 
2022-03-28 04:54:16,789: ============================================================
2022-03-28 04:54:16,790: Epoch 37/38 Batch 1000/7662 eta: 2:22:31.114100	Training Loss 1.5233 (1.5634)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.995)	
2022-03-28 04:54:16,790: ============================================================
2022-03-28 04:55:14,810: time cost, forward:0.015306130878701875, backward:0.03645151761361314, data cost:0.5276185808884652 
2022-03-28 04:55:14,810: ============================================================
2022-03-28 04:55:14,811: Epoch 37/38 Batch 1100/7662 eta: 2:17:33.513182	Training Loss 1.3498 (1.5632)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.994)	
2022-03-28 04:55:14,811: ============================================================
2022-03-28 04:56:12,702: time cost, forward:0.01524440381206802, backward:0.03659965576381859, data cost:0.5274596114870506 
2022-03-28 04:56:12,702: ============================================================
2022-03-28 04:56:12,702: Epoch 37/38 Batch 1200/7662 eta: 2:16:17.220983	Training Loss 1.4570 (1.5645)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-03-28 04:56:12,703: ============================================================
2022-03-28 04:57:10,583: time cost, forward:0.015300824515538733, backward:0.03664720379636323, data cost:0.5271139289894133 
2022-03-28 04:57:10,583: ============================================================
2022-03-28 04:57:10,584: Epoch 37/38 Batch 1300/7662 eta: 2:15:17.807246	Training Loss 1.6563 (1.5653)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-03-28 04:57:10,584: ============================================================
2022-03-28 04:58:09,006: time cost, forward:0.015248844843408394, backward:0.03659603662197721, data cost:0.5274645130152017 
2022-03-28 04:58:09,006: ============================================================
2022-03-28 04:58:09,007: Epoch 37/38 Batch 1400/7662 eta: 2:15:35.416409	Training Loss 1.4627 (1.5644)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-03-28 04:58:09,007: ============================================================
2022-03-28 04:59:07,266: time cost, forward:0.01526677902735735, backward:0.0363371843016092, data cost:0.5278742898695464 
2022-03-28 04:59:07,266: ============================================================
2022-03-28 04:59:07,267: Epoch 37/38 Batch 1500/7662 eta: 2:14:14.444109	Training Loss 1.5213 (1.5636)	Training Prec@1 99.805 (99.977)	Training Prec@5 100.000 (99.994)	
2022-03-28 04:59:07,267: ============================================================
2022-03-28 05:00:07,539: time cost, forward:0.0152866239470195, backward:0.03647042260161037, data cost:0.5291373711813234 
2022-03-28 05:00:07,540: ============================================================
2022-03-28 05:00:07,540: Epoch 37/38 Batch 1600/7662 eta: 2:17:52.492418	Training Loss 1.4917 (1.5644)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:00:07,540: ============================================================
2022-03-28 05:01:07,828: time cost, forward:0.01535164517048459, backward:0.03664522272057222, data cost:0.5297479365698515 
2022-03-28 05:01:07,829: ============================================================
2022-03-28 05:01:07,829: Epoch 37/38 Batch 1700/7662 eta: 2:16:54.417120	Training Loss 1.5245 (1.5642)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:01:07,829: ============================================================
2022-03-28 05:02:06,177: time cost, forward:0.015317151916232489, backward:0.036712869529660505, data cost:0.5301000593502433 
2022-03-28 05:02:06,178: ============================================================
2022-03-28 05:02:06,178: Epoch 37/38 Batch 1800/7662 eta: 2:11:31.717209	Training Loss 1.5975 (1.5641)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:02:06,178: ============================================================
2022-03-28 05:03:02,691: time cost, forward:0.015282999157215055, backward:0.03686968221860286, data cost:0.5290049759572025 
2022-03-28 05:03:02,692: ============================================================
2022-03-28 05:03:02,692: Epoch 37/38 Batch 1900/7662 eta: 2:06:26.960737	Training Loss 1.4488 (1.5642)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:03:02,692: ============================================================
2022-03-28 05:03:59,000: time cost, forward:0.015250811879786328, backward:0.03687225418606062, data cost:0.5280503685203656 
2022-03-28 05:03:59,000: ============================================================
2022-03-28 05:03:59,001: Epoch 37/38 Batch 2000/7662 eta: 2:05:03.130919	Training Loss 1.5597 (1.5647)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:03:59,001: ============================================================
2022-03-28 05:04:57,518: time cost, forward:0.015496823718401295, backward:0.0370406441145593, data cost:0.5278161999837395 
2022-03-28 05:04:57,519: ============================================================
2022-03-28 05:04:57,519: Epoch 37/38 Batch 2100/7662 eta: 2:08:59.041588	Training Loss 1.5597 (1.5652)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:04:57,519: ============================================================
2022-03-28 05:05:55,804: time cost, forward:0.015434178399627671, backward:0.03700929937063428, data cost:0.5279565313936851 
2022-03-28 05:05:55,805: ============================================================
2022-03-28 05:05:55,805: Epoch 37/38 Batch 2200/7662 eta: 2:07:30.048517	Training Loss 1.5943 (1.5658)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:05:55,805: ============================================================
2022-03-28 05:06:52,025: time cost, forward:0.015417951768042991, backward:0.03695082062998768, data cost:0.5270840089805441 
2022-03-28 05:06:52,026: ============================================================
2022-03-28 05:06:52,027: Epoch 37/38 Batch 2300/7662 eta: 2:02:02.852911	Training Loss 1.5811 (1.5661)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.995)	
2022-03-28 05:06:52,027: ============================================================
2022-03-28 05:07:48,512: time cost, forward:0.015444022707762246, backward:0.037003329317984154, data cost:0.5263635848849553 
2022-03-28 05:07:48,513: ============================================================
2022-03-28 05:07:48,514: Epoch 37/38 Batch 2400/7662 eta: 2:01:40.935750	Training Loss 1.6527 (1.5664)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.995)	
2022-03-28 05:07:48,514: ============================================================
2022-03-28 05:08:43,395: time cost, forward:0.015404988499153324, backward:0.03706951082205954, data cost:0.5251774577056469 
2022-03-28 05:08:43,396: ============================================================
2022-03-28 05:08:43,396: Epoch 37/38 Batch 2500/7662 eta: 1:57:18.719144	Training Loss 1.6431 (1.5669)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:08:43,396: ============================================================
2022-03-28 05:09:37,514: time cost, forward:0.015368742684118104, backward:0.0369974911877998, data cost:0.5238417594787844 
2022-03-28 05:09:37,517: ============================================================
2022-03-28 05:09:37,518: Epoch 37/38 Batch 2600/7662 eta: 1:54:46.963365	Training Loss 1.5211 (1.5673)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.995)	
2022-03-28 05:09:37,519: ============================================================
2022-03-28 05:10:37,726: time cost, forward:0.01541022796814598, backward:0.03714250193211095, data cost:0.5245488571564151 
2022-03-28 05:10:37,726: ============================================================
2022-03-28 05:10:37,726: Epoch 37/38 Batch 2700/7662 eta: 2:06:41.332565	Training Loss 1.5659 (1.5674)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:10:37,727: ============================================================
2022-03-28 05:11:35,972: time cost, forward:0.015467272608907958, backward:0.037225604610981455, data cost:0.5245471444458738 
2022-03-28 05:11:35,972: ============================================================
2022-03-28 05:11:35,973: Epoch 37/38 Batch 2800/7662 eta: 2:01:35.340682	Training Loss 1.5537 (1.5676)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:11:35,973: ============================================================
2022-03-28 05:12:34,393: time cost, forward:0.015533772202432876, backward:0.03721084969748543, data cost:0.5247142909518108 
2022-03-28 05:12:34,393: ============================================================
2022-03-28 05:12:34,394: Epoch 37/38 Batch 2900/7662 eta: 2:00:58.821159	Training Loss 1.6658 (1.5680)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:12:34,394: ============================================================
2022-03-28 05:13:37,496: time cost, forward:0.01566667745971171, backward:0.037355691840466596, data cost:0.5261740076339178 
2022-03-28 05:13:37,496: ============================================================
2022-03-28 05:13:37,496: Epoch 37/38 Batch 3000/7662 eta: 2:09:37.418617	Training Loss 1.5924 (1.5685)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:13:37,497: ============================================================
2022-03-28 05:14:32,365: time cost, forward:0.015601280390273836, backward:0.03719188321517644, data cost:0.5253811006432159 
2022-03-28 05:14:32,366: ============================================================
2022-03-28 05:14:32,366: Epoch 37/38 Batch 3100/7662 eta: 1:51:47.796249	Training Loss 1.5961 (1.5685)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:14:32,366: ============================================================
2022-03-28 05:15:30,483: time cost, forward:0.015581669006991587, backward:0.037249981145927334, data cost:0.5252332706755495 
2022-03-28 05:15:30,484: ============================================================
2022-03-28 05:15:30,485: Epoch 37/38 Batch 3200/7662 eta: 1:57:26.860406	Training Loss 1.4474 (1.5686)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:15:30,485: ============================================================
2022-03-28 05:16:26,959: time cost, forward:0.015557327498880868, backward:0.03720598475215434, data cost:0.5250112362867704 
2022-03-28 05:16:26,959: ============================================================
2022-03-28 05:16:26,960: Epoch 37/38 Batch 3300/7662 eta: 1:53:11.143825	Training Loss 1.4920 (1.5689)	Training Prec@1 99.805 (99.977)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:16:26,960: ============================================================
2022-03-28 05:17:25,543: time cost, forward:0.015532161741265132, backward:0.03716383880992327, data cost:0.5252676891838673 
2022-03-28 05:17:25,543: ============================================================
2022-03-28 05:17:25,544: Epoch 37/38 Batch 3400/7662 eta: 1:56:26.118444	Training Loss 1.5340 (1.5692)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:17:25,544: ============================================================
2022-03-28 05:18:24,007: time cost, forward:0.015549095946402167, backward:0.037158279358982936, data cost:0.5254169959073477 
2022-03-28 05:18:24,007: ============================================================
2022-03-28 05:18:24,007: Epoch 37/38 Batch 3500/7662 eta: 1:55:13.349870	Training Loss 1.6820 (1.5695)	Training Prec@1 99.805 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:18:24,008: ============================================================
2022-03-28 05:19:21,856: time cost, forward:0.015571917186481616, backward:0.03712893791018542, data cost:0.5253427810356265 
2022-03-28 05:19:21,856: ============================================================
2022-03-28 05:19:21,856: Epoch 37/38 Batch 3600/7662 eta: 1:53:02.805702	Training Loss 1.5395 (1.5699)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:19:21,857: ============================================================
2022-03-28 05:20:18,296: time cost, forward:0.01554162239957481, backward:0.037080348520931214, data cost:0.5250885951322425 
2022-03-28 05:20:18,296: ============================================================
2022-03-28 05:20:18,296: Epoch 37/38 Batch 3700/7662 eta: 1:49:21.144297	Training Loss 1.5800 (1.5700)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:20:18,297: ============================================================
2022-03-28 05:21:15,546: time cost, forward:0.015586563962859585, backward:0.03704065622609363, data cost:0.524905835179537 
2022-03-28 05:21:15,546: ============================================================
2022-03-28 05:21:15,546: Epoch 37/38 Batch 3800/7662 eta: 1:49:58.061813	Training Loss 1.5864 (1.5699)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:21:15,547: ============================================================
2022-03-28 05:22:13,106: time cost, forward:0.015563959890709501, backward:0.03698532169798944, data cost:0.5249028186915501 
2022-03-28 05:22:13,116: ============================================================
2022-03-28 05:22:13,116: Epoch 37/38 Batch 3900/7662 eta: 1:49:37.352444	Training Loss 1.5836 (1.5701)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:22:13,117: ============================================================
2022-03-28 05:23:11,708: time cost, forward:0.015575512077367792, backward:0.03702274481336246, data cost:0.5250400414792381 
2022-03-28 05:23:11,709: ============================================================
2022-03-28 05:23:11,709: Epoch 37/38 Batch 4000/7662 eta: 1:50:35.645146	Training Loss 1.5625 (1.5703)	Training Prec@1 99.805 (99.976)	Training Prec@5 99.805 (99.994)	
2022-03-28 05:23:11,709: ============================================================
2022-03-28 05:24:09,161: time cost, forward:0.015561527320599376, backward:0.03699161146116943, data cost:0.5249709225073184 
2022-03-28 05:24:09,161: ============================================================
2022-03-28 05:24:09,161: Epoch 37/38 Batch 4100/7662 eta: 1:47:28.990040	Training Loss 1.6518 (1.5703)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:24:09,161: ============================================================
2022-03-28 05:25:06,771: time cost, forward:0.015592653031972626, backward:0.036991559144683495, data cost:0.5247861802450218 
2022-03-28 05:25:06,772: ============================================================
2022-03-28 05:25:06,772: Epoch 37/38 Batch 4200/7662 eta: 1:46:49.241873	Training Loss 1.5026 (1.5706)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:25:06,773: ============================================================
2022-03-28 05:26:10,469: time cost, forward:0.0156461045641654, backward:0.03707442075104236, data cost:0.5260784553355687 
2022-03-28 05:26:10,470: ============================================================
2022-03-28 05:26:10,471: Epoch 37/38 Batch 4300/7662 eta: 1:57:02.720529	Training Loss 1.6572 (1.5712)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:26:10,472: ============================================================
2022-03-28 05:27:05,722: time cost, forward:0.015619746553109272, backward:0.03701854819843893, data cost:0.5254141469791982 
2022-03-28 05:27:05,723: ============================================================
2022-03-28 05:27:05,724: Epoch 37/38 Batch 4400/7662 eta: 1:40:36.417394	Training Loss 1.5703 (1.5716)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:27:05,725: ============================================================
2022-03-28 05:28:04,332: time cost, forward:0.015617180994071545, backward:0.03695016724450187, data cost:0.5257847162320047 
2022-03-28 05:28:04,332: ============================================================
2022-03-28 05:28:04,332: Epoch 37/38 Batch 4500/7662 eta: 1:45:44.366744	Training Loss 1.5775 (1.5722)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:28:04,332: ============================================================
2022-03-28 05:29:01,950: time cost, forward:0.015611121021527057, backward:0.036965365408814246, data cost:0.5256988900100233 
2022-03-28 05:29:01,951: ============================================================
2022-03-28 05:29:01,951: Epoch 37/38 Batch 4600/7662 eta: 1:42:59.616906	Training Loss 1.5649 (1.5719)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:29:01,951: ============================================================
2022-03-28 05:29:58,587: time cost, forward:0.015561340260591932, backward:0.036909843815415684, data cost:0.5255186834292707 
2022-03-28 05:29:58,590: ============================================================
2022-03-28 05:29:58,590: Epoch 37/38 Batch 4700/7662 eta: 1:40:17.875049	Training Loss 1.5807 (1.5722)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:29:58,590: ============================================================
2022-03-28 05:30:56,014: time cost, forward:0.015522802936755063, backward:0.036913801367319136, data cost:0.5254750358087119 
2022-03-28 05:30:56,015: ============================================================
2022-03-28 05:30:56,015: Epoch 37/38 Batch 4800/7662 eta: 1:40:43.990580	Training Loss 1.5042 (1.5725)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:30:56,015: ============================================================
2022-03-28 05:31:54,044: time cost, forward:0.01550386822644631, backward:0.03690031699487983, data cost:0.5254590811596084 
2022-03-28 05:31:54,044: ============================================================
2022-03-28 05:31:54,045: Epoch 37/38 Batch 4900/7662 eta: 1:40:49.589568	Training Loss 1.5844 (1.5728)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:31:54,045: ============================================================
2022-03-28 05:32:51,511: time cost, forward:0.0155116823058673, backward:0.03688527679748596, data cost:0.5254563400091518 
2022-03-28 05:32:51,512: ============================================================
2022-03-28 05:32:51,512: Epoch 37/38 Batch 5000/7662 eta: 1:38:53.505636	Training Loss 1.5595 (1.5730)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:32:51,512: ============================================================
2022-03-28 05:33:48,222: time cost, forward:0.015517504829171826, backward:0.036901224077998666, data cost:0.5250996392622815 
2022-03-28 05:33:48,223: ============================================================
2022-03-28 05:33:48,224: Epoch 37/38 Batch 5100/7662 eta: 1:36:38.739654	Training Loss 1.6176 (1.5730)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:33:48,224: ============================================================
2022-03-28 05:34:46,935: time cost, forward:0.015494309060503414, backward:0.036965351422077464, data cost:0.5252226165772218 
2022-03-28 05:34:46,936: ============================================================
2022-03-28 05:34:46,936: Epoch 37/38 Batch 5200/7662 eta: 1:39:04.674672	Training Loss 1.4916 (1.5731)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:34:46,937: ============================================================
2022-03-28 05:35:44,077: time cost, forward:0.015481565646077803, backward:0.036952188136915504, data cost:0.525089582242388 
2022-03-28 05:35:44,079: ============================================================
2022-03-28 05:35:44,080: Epoch 37/38 Batch 5300/7662 eta: 1:35:28.641095	Training Loss 1.4862 (1.5736)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:35:44,081: ============================================================
2022-03-28 05:36:43,053: time cost, forward:0.015515363223024112, backward:0.03692268786507197, data cost:0.5253479432167665 
2022-03-28 05:36:43,056: ============================================================
2022-03-28 05:36:43,056: Epoch 37/38 Batch 5400/7662 eta: 1:37:33.376455	Training Loss 1.4041 (1.5739)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:36:43,056: ============================================================
2022-03-28 05:37:41,805: time cost, forward:0.015514394113596492, backward:0.036872924338862946, data cost:0.5255826158639756 
2022-03-28 05:37:41,805: ============================================================
2022-03-28 05:37:41,805: Epoch 37/38 Batch 5500/7662 eta: 1:36:12.115282	Training Loss 1.7998 (1.5743)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:37:41,806: ============================================================
2022-03-28 05:38:39,553: time cost, forward:0.015536928330176343, backward:0.03690518760578955, data cost:0.5254637342965013 
2022-03-28 05:38:39,554: ============================================================
2022-03-28 05:38:39,554: Epoch 37/38 Batch 5600/7662 eta: 1:33:36.045554	Training Loss 1.6141 (1.5748)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:38:39,554: ============================================================
2022-03-28 05:39:37,710: time cost, forward:0.015504023718779538, backward:0.03689147476816119, data cost:0.5255440988338167 
2022-03-28 05:39:37,711: ============================================================
2022-03-28 05:39:37,711: Epoch 37/38 Batch 5700/7662 eta: 1:33:17.620114	Training Loss 1.7771 (1.5750)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:39:37,711: ============================================================
2022-03-28 05:40:34,951: time cost, forward:0.015464395382297843, backward:0.03684473642091707, data cost:0.5255649903043013 
2022-03-28 05:40:34,952: ============================================================
2022-03-28 05:40:34,952: Epoch 37/38 Batch 5800/7662 eta: 1:30:52.190437	Training Loss 1.6677 (1.5754)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:40:34,952: ============================================================
2022-03-28 05:41:32,779: time cost, forward:0.015457188523326977, backward:0.036834978778436236, data cost:0.5255650106295223 
2022-03-28 05:41:32,780: ============================================================
2022-03-28 05:41:32,780: Epoch 37/38 Batch 5900/7662 eta: 1:30:50.293523	Training Loss 1.5385 (1.5756)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:41:32,780: ============================================================
2022-03-28 05:42:32,572: time cost, forward:0.015479271363011795, backward:0.036900238824657726, data cost:0.5257996231501332 
2022-03-28 05:42:32,573: ============================================================
2022-03-28 05:42:32,573: Epoch 37/38 Batch 6000/7662 eta: 1:32:55.724172	Training Loss 1.5247 (1.5760)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:42:32,573: ============================================================
2022-03-28 05:43:29,371: time cost, forward:0.015462527569834766, backward:0.036909443058915206, data cost:0.5256177147679064 
2022-03-28 05:43:29,373: ============================================================
2022-03-28 05:43:29,373: Epoch 37/38 Batch 6100/7662 eta: 1:27:19.788625	Training Loss 1.5724 (1.5762)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:43:29,374: ============================================================
2022-03-28 05:44:28,961: time cost, forward:0.015494262927923497, backward:0.03696728987277641, data cost:0.5258041614293091 
2022-03-28 05:44:28,962: ============================================================
2022-03-28 05:44:28,962: Epoch 37/38 Batch 6200/7662 eta: 1:30:37.474493	Training Loss 1.4490 (1.5765)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:44:28,962: ============================================================
2022-03-28 05:45:27,092: time cost, forward:0.015490309664854493, backward:0.036964570970682134, data cost:0.5257214077466403 
2022-03-28 05:45:27,095: ============================================================
2022-03-28 05:45:27,095: Epoch 37/38 Batch 6300/7662 eta: 1:27:26.503563	Training Loss 1.4397 (1.5766)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:45:27,096: ============================================================
2022-03-28 05:46:23,402: time cost, forward:0.015488762094706628, backward:0.036945765755068125, data cost:0.5256048230607727 
2022-03-28 05:46:23,403: ============================================================
2022-03-28 05:46:23,403: Epoch 37/38 Batch 6400/7662 eta: 1:23:45.494902	Training Loss 1.6871 (1.5770)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:46:23,403: ============================================================
2022-03-28 05:47:22,074: time cost, forward:0.015470034857129368, backward:0.0369383963021265, data cost:0.5257457997142617 
2022-03-28 05:47:22,075: ============================================================
2022-03-28 05:47:22,075: Epoch 37/38 Batch 6500/7662 eta: 1:26:17.829621	Training Loss 1.5418 (1.5771)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:47:22,076: ============================================================
2022-03-28 05:48:21,353: time cost, forward:0.015479331306299127, backward:0.036971888373811816, data cost:0.5258657512095394 
2022-03-28 05:48:21,354: ============================================================
2022-03-28 05:48:21,354: Epoch 37/38 Batch 6600/7662 eta: 1:26:12.053646	Training Loss 1.8017 (1.5774)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:48:21,354: ============================================================
2022-03-28 05:49:16,867: time cost, forward:0.015458983046774687, backward:0.03695834204409973, data cost:0.5255663082802148 
2022-03-28 05:49:16,868: ============================================================
2022-03-28 05:49:16,868: Epoch 37/38 Batch 6700/7662 eta: 1:19:48.096499	Training Loss 1.7085 (1.5775)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:49:16,868: ============================================================
2022-03-28 05:50:14,714: time cost, forward:0.015444545434457202, backward:0.036950098765143616, data cost:0.5255410711911518 
2022-03-28 05:50:14,714: ============================================================
2022-03-28 05:50:14,715: Epoch 37/38 Batch 6800/7662 eta: 1:22:11.433366	Training Loss 1.6633 (1.5777)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:50:14,715: ============================================================
2022-03-28 05:51:12,167: time cost, forward:0.015441327842184903, backward:0.03695716396900757, data cost:0.5255199915638072 
2022-03-28 05:51:12,168: ============================================================
2022-03-28 05:51:12,168: Epoch 37/38 Batch 6900/7662 eta: 1:20:40.428413	Training Loss 1.7300 (1.5781)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:51:12,168: ============================================================
2022-03-28 05:52:11,029: time cost, forward:0.015445705549531978, backward:0.036988738639505615, data cost:0.525622430878514 
2022-03-28 05:52:11,029: ============================================================
2022-03-28 05:52:11,030: Epoch 37/38 Batch 7000/7662 eta: 1:21:40.241393	Training Loss 1.6328 (1.5786)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:52:11,030: ============================================================
2022-03-28 05:53:07,574: time cost, forward:0.01542241453435962, backward:0.03699475460479689, data cost:0.5254215531188646 
2022-03-28 05:53:07,576: ============================================================
2022-03-28 05:53:07,576: Epoch 37/38 Batch 7100/7662 eta: 1:17:30.945602	Training Loss 1.5600 (1.5788)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:53:07,577: ============================================================
2022-03-28 05:54:04,187: time cost, forward:0.015425556847611672, backward:0.036982972550051035, data cost:0.525266215973123 
2022-03-28 05:54:04,188: ============================================================
2022-03-28 05:54:04,189: Epoch 37/38 Batch 7200/7662 eta: 1:16:39.759597	Training Loss 1.6085 (1.5789)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:54:04,189: ============================================================
2022-03-28 05:55:03,622: time cost, forward:0.015417304426403074, backward:0.036970529446521516, data cost:0.5255099627919059 
2022-03-28 05:55:03,622: ============================================================
2022-03-28 05:55:03,622: Epoch 37/38 Batch 7300/7662 eta: 1:19:29.573010	Training Loss 1.6466 (1.5791)	Training Prec@1 99.805 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:55:03,623: ============================================================
2022-03-28 05:56:03,724: time cost, forward:0.015434615723844122, backward:0.0370074360575897, data cost:0.5257471786155654 
2022-03-28 05:56:03,725: ============================================================
2022-03-28 05:56:03,725: Epoch 37/38 Batch 7400/7662 eta: 1:19:23.132985	Training Loss 1.6382 (1.5795)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:56:03,725: ============================================================
2022-03-28 05:57:00,000: time cost, forward:0.015415808950714913, backward:0.03695792979535333, data cost:0.5255980506899007 
2022-03-28 05:57:00,001: ============================================================
2022-03-28 05:57:00,001: Epoch 37/38 Batch 7500/7662 eta: 1:13:23.583196	Training Loss 1.4775 (1.5799)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:57:00,001: ============================================================
2022-03-28 05:57:56,118: time cost, forward:0.015411860065281995, backward:0.036943275311351186, data cost:0.5253741347424246 
2022-03-28 05:57:56,118: ============================================================
2022-03-28 05:57:56,118: Epoch 37/38 Batch 7600/7662 eta: 1:12:15.079974	Training Loss 1.6246 (1.5801)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:57:56,119: ============================================================
2022-03-28 05:58:34,421: Epoch: 37/38 eta: 1:11:39.725924	Training Loss 1.6631 (1.5802)	Training Prec@1 99.805 (99.975)	Training Prec@5 99.805 (99.994)
2022-03-28 05:58:34,421: ============================================================
2022-03-28 05:58:34,581: Save Checkpoint...
2022-03-28 05:58:34,583: ============================================================
2022-03-28 05:58:39,354: Save done!
2022-03-28 05:58:39,354: ============================================================
2022-03-28 05:59:36,019: time cost, forward:0.01293451858289314, backward:0.03544844039762863, data cost:0.5106099615193377 
2022-03-28 05:59:36,020: ============================================================
2022-03-28 05:59:36,020: Epoch 38/38 Batch 100/7662 eta: 1:11:13.514343	Training Loss 1.5190 (1.5455)	Training Prec@1 99.805 (99.968)	Training Prec@5 100.000 (99.994)	
2022-03-28 05:59:36,020: ============================================================
2022-03-28 06:00:33,871: time cost, forward:0.0128371188388997, backward:0.03703408864275295, data cost:0.5217595028517833 
2022-03-28 06:00:33,871: ============================================================
2022-03-28 06:00:33,871: Epoch 38/38 Batch 200/7662 eta: 1:11:57.432252	Training Loss 1.5253 (1.5553)	Training Prec@1 100.000 (99.971)	Training Prec@5 100.000 (99.993)	
2022-03-28 06:00:33,871: ============================================================
2022-03-28 06:01:30,786: time cost, forward:0.01351778323833759, backward:0.03742272399340984, data cost:0.5193258216947217 
2022-03-28 06:01:30,787: ============================================================
2022-03-28 06:01:30,787: Epoch 38/38 Batch 300/7662 eta: 1:09:50.695317	Training Loss 1.6006 (1.5549)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:01:30,787: ============================================================
2022-03-28 06:02:31,173: time cost, forward:0.014168353307814826, backward:0.03786268210351318, data cost:0.5264427321297782 
2022-03-28 06:02:31,174: ============================================================
2022-03-28 06:02:31,174: Epoch 38/38 Batch 400/7662 eta: 1:13:05.895470	Training Loss 1.4640 (1.5524)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.995)	
2022-03-28 06:02:31,174: ============================================================
2022-03-28 06:03:29,223: time cost, forward:0.014399049277296048, backward:0.03793443611007415, data cost:0.5263525030178154 
2022-03-28 06:03:29,224: ============================================================
2022-03-28 06:03:29,224: Epoch 38/38 Batch 500/7662 eta: 1:09:18.154218	Training Loss 1.6075 (1.5577)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:03:29,224: ============================================================
2022-03-28 06:04:27,185: time cost, forward:0.014362885279329074, backward:0.03826747553575417, data cost:0.526028464751968 
2022-03-28 06:04:27,186: ============================================================
2022-03-28 06:04:27,186: Epoch 38/38 Batch 600/7662 eta: 1:08:13.856760	Training Loss 1.6740 (1.5589)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.995)	
2022-03-28 06:04:27,186: ============================================================
2022-03-28 06:05:27,776: time cost, forward:0.014830466162663843, backward:0.03877422976732595, data cost:0.5286908221347137 
2022-03-28 06:05:27,776: ============================================================
2022-03-28 06:05:27,777: Epoch 38/38 Batch 700/7662 eta: 1:10:18.906911	Training Loss 1.5427 (1.5578)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:05:27,777: ============================================================
2022-03-28 06:06:26,095: time cost, forward:0.014999355332872298, backward:0.038599464860517484, data cost:0.5277747543941302 
2022-03-28 06:06:26,098: ============================================================
2022-03-28 06:06:26,099: Epoch 38/38 Batch 800/7662 eta: 1:06:42.629699	Training Loss 1.5519 (1.5582)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.995)	
2022-03-28 06:06:26,099: ============================================================
2022-03-28 06:07:25,217: time cost, forward:0.01502330045944061, backward:0.03861887940310265, data cost:0.5292117805183928 
2022-03-28 06:07:25,221: ============================================================
2022-03-28 06:07:25,222: Epoch 38/38 Batch 900/7662 eta: 1:06:38.511348	Training Loss 1.4770 (1.5599)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.995)	
2022-03-28 06:07:25,223: ============================================================
2022-03-28 06:08:25,701: time cost, forward:0.015216639092018654, backward:0.03858940713517778, data cost:0.5306966006457507 
2022-03-28 06:08:25,703: ============================================================
2022-03-28 06:08:25,704: Epoch 38/38 Batch 1000/7662 eta: 1:07:09.919734	Training Loss 1.4672 (1.5605)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.995)	
2022-03-28 06:08:25,706: ============================================================
2022-03-28 06:09:22,686: time cost, forward:0.015211422948863313, backward:0.038248937709207856, data cost:0.5294710546325184 
2022-03-28 06:09:22,691: ============================================================
2022-03-28 06:09:22,692: Epoch 38/38 Batch 1100/7662 eta: 1:02:20.069374	Training Loss 1.5565 (1.5608)	Training Prec@1 99.805 (99.977)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:09:22,693: ============================================================
2022-03-28 06:10:20,297: time cost, forward:0.015494154332775787, backward:0.038584180629879755, data cost:0.5286066182162783 
2022-03-28 06:10:20,298: ============================================================
2022-03-28 06:10:20,298: Epoch 38/38 Batch 1200/7662 eta: 1:02:03.123606	Training Loss 1.6115 (1.5612)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:10:20,298: ============================================================
2022-03-28 06:11:20,595: time cost, forward:0.015793828252097842, backward:0.03878277829282554, data cost:0.5295246152165672 
2022-03-28 06:11:20,597: ============================================================
2022-03-28 06:11:20,598: Epoch 38/38 Batch 1300/7662 eta: 1:03:56.870641	Training Loss 1.6408 (1.5611)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:11:20,598: ============================================================
2022-03-28 06:12:18,670: time cost, forward:0.01575044532432311, backward:0.038896571575871015, data cost:0.5292671088068037 
2022-03-28 06:12:18,671: ============================================================
2022-03-28 06:12:18,672: Epoch 38/38 Batch 1400/7662 eta: 1:00:37.159666	Training Loss 1.5498 (1.5622)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:12:18,672: ============================================================
2022-03-28 06:13:16,585: time cost, forward:0.015956825697875324, backward:0.038965757406895125, data cost:0.5281457907363046 
2022-03-28 06:13:16,587: ============================================================
2022-03-28 06:13:16,588: Epoch 38/38 Batch 1500/7662 eta: 0:59:29.337006	Training Loss 1.6058 (1.5630)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:13:16,588: ============================================================
2022-03-28 06:14:16,177: time cost, forward:0.01590895578218595, backward:0.038857128711101634, data cost:0.5289363328779839 
2022-03-28 06:14:16,178: ============================================================
2022-03-28 06:14:16,178: Epoch 38/38 Batch 1600/7662 eta: 1:00:13.002956	Training Loss 1.5957 (1.5625)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:14:16,178: ============================================================
2022-03-28 06:15:11,867: time cost, forward:0.015804278422552675, backward:0.03866155811307569, data cost:0.5280022775516432 
2022-03-28 06:15:11,867: ============================================================
2022-03-28 06:15:11,867: Epoch 38/38 Batch 1700/7662 eta: 0:55:20.747233	Training Loss 1.4524 (1.5637)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:15:11,867: ============================================================
2022-03-28 06:16:11,421: time cost, forward:0.015920980166169656, backward:0.038812033264686026, data cost:0.5284576895768408 
2022-03-28 06:16:11,422: ============================================================
2022-03-28 06:16:11,422: Epoch 38/38 Batch 1800/7662 eta: 0:58:11.689735	Training Loss 1.5382 (1.5646)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:16:11,422: ============================================================
2022-03-28 06:17:09,115: time cost, forward:0.015968380255596208, backward:0.03886389883020289, data cost:0.5275982150659867 
2022-03-28 06:17:09,118: ============================================================
2022-03-28 06:17:09,119: Epoch 38/38 Batch 1900/7662 eta: 0:55:25.033168	Training Loss 1.5529 (1.5650)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:17:09,119: ============================================================
2022-03-28 06:18:06,007: time cost, forward:0.015956846220962044, backward:0.03883119068365207, data cost:0.5272771064611361 
2022-03-28 06:18:06,008: ============================================================
2022-03-28 06:18:06,008: Epoch 38/38 Batch 2000/7662 eta: 0:53:41.668190	Training Loss 1.6604 (1.5655)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:18:06,008: ============================================================
2022-03-28 06:19:04,824: time cost, forward:0.015877694729227516, backward:0.03872594576667978, data cost:0.5276565393872236 
2022-03-28 06:19:04,825: ============================================================
2022-03-28 06:19:04,825: Epoch 38/38 Batch 2100/7662 eta: 0:54:31.990103	Training Loss 1.6581 (1.5653)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:19:04,825: ============================================================
2022-03-28 06:20:03,104: time cost, forward:0.015924611596857326, backward:0.03880867810615793, data cost:0.5274740949225675 
2022-03-28 06:20:03,104: ============================================================
2022-03-28 06:20:03,104: Epoch 38/38 Batch 2200/7662 eta: 0:53:03.792870	Training Loss 1.4623 (1.5661)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:20:03,105: ============================================================
2022-03-28 06:21:05,164: time cost, forward:0.015968907237208476, backward:0.03917024974565809, data cost:0.5287416082923959 
2022-03-28 06:21:05,165: ============================================================
2022-03-28 06:21:05,165: Epoch 38/38 Batch 2300/7662 eta: 0:55:28.317844	Training Loss 1.5025 (1.5658)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:21:05,165: ============================================================
2022-03-28 06:22:01,657: time cost, forward:0.0159206311868697, backward:0.039116763134408164, data cost:0.5279700049463537 
2022-03-28 06:22:01,658: ============================================================
2022-03-28 06:22:01,658: Epoch 38/38 Batch 2400/7662 eta: 0:49:33.223053	Training Loss 1.6509 (1.5660)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:22:01,658: ============================================================
2022-03-28 06:23:02,859: time cost, forward:0.015998483896732522, backward:0.039231039038082276, data cost:0.5288911148184249 
2022-03-28 06:23:02,859: ============================================================
2022-03-28 06:23:02,860: Epoch 38/38 Batch 2500/7662 eta: 0:52:39.843843	Training Loss 1.6209 (1.5662)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:23:02,860: ============================================================
2022-03-28 06:24:01,258: time cost, forward:0.01616656170206925, backward:0.039281877566870016, data cost:0.5285156957458285 
2022-03-28 06:24:01,261: ============================================================
2022-03-28 06:24:01,262: Epoch 38/38 Batch 2600/7662 eta: 0:49:16.886123	Training Loss 1.3872 (1.5663)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:24:01,263: ============================================================
2022-03-28 06:24:59,003: time cost, forward:0.016155001586258256, backward:0.03924170782407949, data cost:0.5282351187133224 
2022-03-28 06:24:59,003: ============================================================
2022-03-28 06:24:59,004: Epoch 38/38 Batch 2700/7662 eta: 0:47:45.733643	Training Loss 1.5384 (1.5667)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:24:59,004: ============================================================
2022-03-28 06:25:58,620: time cost, forward:0.016239105356127163, backward:0.03913004298685448, data cost:0.5288036622588828 
2022-03-28 06:25:58,621: ============================================================
2022-03-28 06:25:58,621: Epoch 38/38 Batch 2800/7662 eta: 0:48:19.188315	Training Loss 1.4363 (1.5664)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:25:58,621: ============================================================
2022-03-28 06:26:57,388: time cost, forward:0.016256275157263952, backward:0.03912486418151329, data cost:0.5287474577654719 
2022-03-28 06:26:57,389: ============================================================
2022-03-28 06:26:57,390: Epoch 38/38 Batch 2900/7662 eta: 0:46:39.148395	Training Loss 1.6584 (1.5666)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:26:57,390: ============================================================
2022-03-28 06:27:55,860: time cost, forward:0.016231247408066484, backward:0.03912220306498244, data cost:0.5288886321946437 
2022-03-28 06:27:55,861: ============================================================
2022-03-28 06:27:55,861: Epoch 38/38 Batch 3000/7662 eta: 0:45:26.525007	Training Loss 1.6138 (1.5667)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:27:55,861: ============================================================
2022-03-28 06:28:55,693: time cost, forward:0.016241571217746494, backward:0.039247966112725845, data cost:0.5291611188148136 
2022-03-28 06:28:55,694: ============================================================
2022-03-28 06:28:55,694: Epoch 38/38 Batch 3100/7662 eta: 0:45:30.186021	Training Loss 1.5687 (1.5669)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:28:55,694: ============================================================
2022-03-28 06:29:55,084: time cost, forward:0.016333418736125423, backward:0.03941119473663931, data cost:0.5291445373780804 
2022-03-28 06:29:55,084: ============================================================
2022-03-28 06:29:55,085: Epoch 38/38 Batch 3200/7662 eta: 0:44:10.597380	Training Loss 1.6604 (1.5674)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:29:55,085: ============================================================
2022-03-28 06:30:53,966: time cost, forward:0.016358706328897053, backward:0.03945520286236289, data cost:0.5291438949726032 
2022-03-28 06:30:53,967: ============================================================
2022-03-28 06:30:53,967: Epoch 38/38 Batch 3300/7662 eta: 0:42:49.044856	Training Loss 1.6291 (1.5678)	Training Prec@1 99.805 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:30:53,967: ============================================================
2022-03-28 06:31:51,040: time cost, forward:0.016328999981455115, backward:0.03943648160152766, data cost:0.5287414745359991 
2022-03-28 06:31:51,042: ============================================================
2022-03-28 06:31:51,042: Epoch 38/38 Batch 3400/7662 eta: 0:40:33.098511	Training Loss 1.7004 (1.5677)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:31:51,043: ============================================================
2022-03-28 06:32:49,381: time cost, forward:0.01640243283610032, backward:0.039586392154895296, data cost:0.528455055792286 
2022-03-28 06:32:49,381: ============================================================
2022-03-28 06:32:49,381: Epoch 38/38 Batch 3500/7662 eta: 0:40:28.670395	Training Loss 1.5734 (1.5678)	Training Prec@1 99.805 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:32:49,382: ============================================================
2022-03-28 06:33:46,218: time cost, forward:0.016398072077122353, backward:0.039558042914180434, data cost:0.5279887277704373 
2022-03-28 06:33:46,219: ============================================================
2022-03-28 06:33:46,219: Epoch 38/38 Batch 3600/7662 eta: 0:38:29.314603	Training Loss 1.4548 (1.5681)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:33:46,219: ============================================================
2022-03-28 06:34:46,523: time cost, forward:0.016398219103167334, backward:0.03947560952849954, data cost:0.5284147077587754 
2022-03-28 06:34:46,527: ============================================================
2022-03-28 06:34:46,528: Epoch 38/38 Batch 3700/7662 eta: 0:39:50.034502	Training Loss 1.6758 (1.5686)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:34:46,529: ============================================================
2022-03-28 06:35:46,065: time cost, forward:0.016388677364589353, backward:0.03956112481318326, data cost:0.5287362867733403 
2022-03-28 06:35:46,065: ============================================================
2022-03-28 06:35:46,065: Epoch 38/38 Batch 3800/7662 eta: 0:38:19.928114	Training Loss 1.7018 (1.5690)	Training Prec@1 99.805 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:35:46,065: ============================================================
2022-03-28 06:36:47,400: time cost, forward:0.016400093786470032, backward:0.039666205560528155, data cost:0.5293135281005374 
2022-03-28 06:36:47,401: ============================================================
2022-03-28 06:36:47,401: Epoch 38/38 Batch 3900/7662 eta: 0:38:28.067246	Training Loss 1.6689 (1.5691)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:36:47,401: ============================================================
2022-03-28 06:37:48,062: time cost, forward:0.016432316787960113, backward:0.039719310812009335, data cost:0.5297312012133703 
2022-03-28 06:37:48,062: ============================================================
2022-03-28 06:37:48,063: Epoch 38/38 Batch 4000/7662 eta: 0:37:02.029181	Training Loss 1.5086 (1.5689)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:37:48,063: ============================================================
2022-03-28 06:38:44,315: time cost, forward:0.016388680592313805, backward:0.039658749327481625, data cost:0.5292466164914885 
2022-03-28 06:38:44,316: ============================================================
2022-03-28 06:38:44,316: Epoch 38/38 Batch 4100/7662 eta: 0:33:24.321167	Training Loss 1.5592 (1.5693)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:38:44,317: ============================================================
2022-03-28 06:39:43,543: time cost, forward:0.016420968858137902, backward:0.03967695396325224, data cost:0.5292948539213329 
2022-03-28 06:39:43,544: ============================================================
2022-03-28 06:39:43,544: Epoch 38/38 Batch 4200/7662 eta: 0:34:11.061311	Training Loss 1.7599 (1.5696)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:39:43,545: ============================================================
2022-03-28 06:40:42,774: time cost, forward:0.016432219035238907, backward:0.03965547651045542, data cost:0.5294520135091111 
2022-03-28 06:40:42,777: ============================================================
2022-03-28 06:40:42,779: Epoch 38/38 Batch 4300/7662 eta: 0:33:12.054405	Training Loss 1.5735 (1.5700)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:40:42,779: ============================================================
2022-03-28 06:41:42,007: time cost, forward:0.016422036128251168, backward:0.039592321148295924, data cost:0.5296264854608056 
2022-03-28 06:41:42,007: ============================================================
2022-03-28 06:41:42,007: Epoch 38/38 Batch 4400/7662 eta: 0:32:12.632408	Training Loss 1.5938 (1.5703)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:41:42,008: ============================================================
2022-03-28 06:42:40,424: time cost, forward:0.016420101425228557, backward:0.039622040954423655, data cost:0.5295567005362662 
2022-03-28 06:42:40,425: ============================================================
2022-03-28 06:42:40,425: Epoch 38/38 Batch 4500/7662 eta: 0:30:47.750412	Training Loss 1.5753 (1.5704)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:42:40,425: ============================================================
2022-03-28 06:43:39,308: time cost, forward:0.016411830197471357, backward:0.03962538298847209, data cost:0.5296212054512038 
2022-03-28 06:43:39,309: ============================================================
2022-03-28 06:43:39,309: Epoch 38/38 Batch 4600/7662 eta: 0:30:03.609802	Training Loss 1.5395 (1.5704)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:43:39,309: ============================================================
2022-03-28 06:44:36,213: time cost, forward:0.01652535029385135, backward:0.03970148036215604, data cost:0.5290330782624655 
2022-03-28 06:44:36,214: ============================================================
2022-03-28 06:44:36,214: Epoch 38/38 Batch 4700/7662 eta: 0:28:06.092783	Training Loss 1.5215 (1.5707)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:44:36,214: ============================================================
2022-03-28 06:45:34,822: time cost, forward:0.016541752921563683, backward:0.03964518069922862, data cost:0.5290695031649572 
2022-03-28 06:45:34,823: ============================================================
2022-03-28 06:45:34,823: Epoch 38/38 Batch 4800/7662 eta: 0:27:57.975580	Training Loss 1.6043 (1.5708)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:45:34,823: ============================================================
2022-03-28 06:46:34,759: time cost, forward:0.016569469675382174, backward:0.03967092591515607, data cost:0.5292846517043105 
2022-03-28 06:46:34,759: ============================================================
2022-03-28 06:46:34,760: Epoch 38/38 Batch 4900/7662 eta: 0:27:36.053382	Training Loss 1.5313 (1.5709)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:46:34,760: ============================================================
2022-03-28 06:47:33,227: time cost, forward:0.01656075691456651, backward:0.039706521235506255, data cost:0.5291615534982912 
2022-03-28 06:47:33,228: ============================================================
2022-03-28 06:47:33,229: Epoch 38/38 Batch 5000/7662 eta: 0:25:57.027828	Training Loss 1.6354 (1.5713)	Training Prec@1 99.805 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:47:33,229: ============================================================
2022-03-28 06:48:32,651: time cost, forward:0.016590941581194903, backward:0.03973087630428083, data cost:0.5292775604766499 
2022-03-28 06:48:32,652: ============================================================
2022-03-28 06:48:32,652: Epoch 38/38 Batch 5100/7662 eta: 0:25:23.031719	Training Loss 1.5933 (1.5718)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:48:32,653: ============================================================
2022-03-28 06:49:29,867: time cost, forward:0.016584531369863233, backward:0.03971979172786031, data cost:0.5290343301941464 
2022-03-28 06:49:29,884: ============================================================
2022-03-28 06:49:29,884: Epoch 38/38 Batch 5200/7662 eta: 0:23:29.624486	Training Loss 1.6755 (1.5720)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:49:29,885: ============================================================
2022-03-28 06:50:28,377: time cost, forward:0.016586920116775147, backward:0.03968303778144994, data cost:0.5290471605814545 
2022-03-28 06:50:28,377: ============================================================
2022-03-28 06:50:28,377: Epoch 38/38 Batch 5300/7662 eta: 0:23:02.189760	Training Loss 1.6326 (1.5723)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:50:28,378: ============================================================
2022-03-28 06:51:27,496: time cost, forward:0.016581672587909616, backward:0.0396457966841422, data cost:0.5291626099679929 
2022-03-28 06:51:27,496: ============================================================
2022-03-28 06:51:27,496: Epoch 38/38 Batch 5400/7662 eta: 0:22:17.862489	Training Loss 1.6321 (1.5727)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:51:27,496: ============================================================
2022-03-28 06:52:26,289: time cost, forward:0.016571714826487782, backward:0.03968404522590755, data cost:0.529154509582353 
2022-03-28 06:52:26,289: ============================================================
2022-03-28 06:52:26,290: Epoch 38/38 Batch 5500/7662 eta: 0:21:11.697272	Training Loss 1.7348 (1.5730)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:52:26,290: ============================================================
2022-03-28 06:53:24,210: time cost, forward:0.01654920784101505, backward:0.039690969330558906, data cost:0.5290323375995553 
2022-03-28 06:53:24,210: ============================================================
2022-03-28 06:53:24,211: Epoch 38/38 Batch 5600/7662 eta: 0:19:54.910609	Training Loss 1.6604 (1.5733)	Training Prec@1 99.805 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:53:24,211: ============================================================
2022-03-28 06:54:23,518: time cost, forward:0.016552173666712234, backward:0.03970914586507807, data cost:0.529058601588905 
2022-03-28 06:54:23,518: ============================================================
2022-03-28 06:54:23,519: Epoch 38/38 Batch 5700/7662 eta: 0:19:24.216580	Training Loss 1.6040 (1.5734)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:54:23,519: ============================================================
2022-03-28 06:55:20,060: time cost, forward:0.016528352948586927, backward:0.03965551435053195, data cost:0.5288283540002435 
2022-03-28 06:55:20,060: ============================================================
2022-03-28 06:55:20,060: Epoch 38/38 Batch 5800/7662 eta: 0:17:33.372837	Training Loss 1.5785 (1.5739)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:55:20,061: ============================================================
2022-03-28 06:56:18,491: time cost, forward:0.016530396393101627, backward:0.03965649675122559, data cost:0.5287825650210137 
2022-03-28 06:56:18,491: ============================================================
2022-03-28 06:56:18,492: Epoch 38/38 Batch 5900/7662 eta: 0:17:10.141128	Training Loss 1.4956 (1.5741)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:56:18,492: ============================================================
2022-03-28 06:57:19,505: time cost, forward:0.016525390247917906, backward:0.039633368269406395, data cost:0.5291681974445667 
2022-03-28 06:57:19,506: ============================================================
2022-03-28 06:57:19,506: Epoch 38/38 Batch 6000/7662 eta: 0:16:54.670765	Training Loss 1.5719 (1.5744)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:57:19,506: ============================================================
2022-03-28 06:58:18,115: time cost, forward:0.01653199040277959, backward:0.0396023855617465, data cost:0.5292285190368993 
2022-03-28 06:58:18,116: ============================================================
2022-03-28 06:58:18,116: Epoch 38/38 Batch 6100/7662 eta: 0:15:16.074261	Training Loss 1.5913 (1.5747)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:58:18,116: ============================================================
2022-03-28 06:59:20,251: time cost, forward:0.016541620669278008, backward:0.03962520073067471, data cost:0.5296335213413967 
2022-03-28 06:59:20,251: ============================================================
2022-03-28 06:59:20,252: Epoch 38/38 Batch 6200/7662 eta: 0:15:09.044959	Training Loss 1.5626 (1.5750)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 06:59:20,252: ============================================================
2022-03-28 07:00:14,676: time cost, forward:0.016511517264461078, backward:0.039543392507211235, data cost:0.5291852985115009 
2022-03-28 07:00:14,677: ============================================================
2022-03-28 07:00:14,677: Epoch 38/38 Batch 6300/7662 eta: 0:12:21.820779	Training Loss 1.5510 (1.5753)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 07:00:14,678: ============================================================
2022-03-28 07:01:14,395: time cost, forward:0.016532612025765708, backward:0.03955555912255682, data cost:0.5292200434485493 
2022-03-28 07:01:14,400: ============================================================
2022-03-28 07:01:14,402: Epoch 38/38 Batch 6400/7662 eta: 0:12:34.312364	Training Loss 1.5464 (1.5756)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 07:01:14,403: ============================================================
2022-03-28 07:02:14,469: time cost, forward:0.01655703978385168, backward:0.0395992994858753, data cost:0.5294673653048063 
2022-03-28 07:02:14,469: ============================================================
2022-03-28 07:02:14,469: Epoch 38/38 Batch 6500/7662 eta: 0:11:38.593067	Training Loss 1.5591 (1.5758)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 07:02:14,470: ============================================================
2022-03-28 07:03:10,249: time cost, forward:0.01653373749044054, backward:0.039520116082862176, data cost:0.5291287150052773 
2022-03-28 07:03:10,250: ============================================================
2022-03-28 07:03:10,250: Epoch 38/38 Batch 6600/7662 eta: 0:09:52.947399	Training Loss 1.7817 (1.5760)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 07:03:10,250: ============================================================
2022-03-28 07:04:12,007: time cost, forward:0.01653118097242944, backward:0.03950731005841608, data cost:0.5296107437169664 
2022-03-28 07:04:12,007: ============================================================
2022-03-28 07:04:12,007: Epoch 38/38 Batch 6700/7662 eta: 0:09:54.724336	Training Loss 1.4742 (1.5765)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 07:04:12,008: ============================================================
2022-03-28 07:05:12,202: time cost, forward:0.016519332952509208, backward:0.039505616867081136, data cost:0.5298441364968904 
2022-03-28 07:05:12,203: ============================================================
2022-03-28 07:05:12,203: Epoch 38/38 Batch 6800/7662 eta: 0:08:39.486393	Training Loss 1.5663 (1.5766)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 07:05:12,203: ============================================================
2022-03-28 07:06:07,894: time cost, forward:0.01649676279531629, backward:0.03949518569363496, data cost:0.5294327382022599 
2022-03-28 07:06:07,894: ============================================================
2022-03-28 07:06:07,894: Epoch 38/38 Batch 6900/7662 eta: 0:07:04.925839	Training Loss 1.7945 (1.5770)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 07:06:07,894: ============================================================
2022-03-28 07:07:05,600: time cost, forward:0.016496801771492868, backward:0.03946701201869345, data cost:0.5292162793008647 
2022-03-28 07:07:05,602: ============================================================
2022-03-28 07:07:05,604: Epoch 38/38 Batch 7000/7662 eta: 0:06:22.609152	Training Loss 1.4736 (1.5773)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 07:07:05,604: ============================================================
2022-03-28 07:08:01,412: time cost, forward:0.01646996582204279, backward:0.03944706177943222, data cost:0.5289292359355471 
2022-03-28 07:08:01,412: ============================================================
2022-03-28 07:08:01,412: Epoch 38/38 Batch 7100/7662 eta: 0:05:14.205267	Training Loss 1.5964 (1.5776)	Training Prec@1 99.805 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 07:08:01,414: ============================================================
2022-03-28 07:08:54,170: time cost, forward:0.016444254358670234, backward:0.03939947960757269, data cost:0.5282325157772785 
2022-03-28 07:08:54,170: ============================================================
2022-03-28 07:08:54,170: Epoch 38/38 Batch 7200/7662 eta: 0:04:04.270073	Training Loss 1.8090 (1.5778)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 07:08:54,171: ============================================================
2022-03-28 07:09:53,839: time cost, forward:0.016436717954134678, backward:0.03938054777135717, data cost:0.5282958314620987 
2022-03-28 07:09:53,842: ============================================================
2022-03-28 07:09:53,843: Epoch 38/38 Batch 7300/7662 eta: 0:03:36.611070	Training Loss 1.5380 (1.5780)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 07:09:53,844: ============================================================
2022-03-28 07:10:48,196: time cost, forward:0.0164093821415113, backward:0.039320683508309855, data cost:0.5279398932781134 
2022-03-28 07:10:48,197: ============================================================
2022-03-28 07:10:48,197: Epoch 38/38 Batch 7400/7662 eta: 0:02:22.951433	Training Loss 1.6102 (1.5782)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 07:10:48,198: ============================================================
2022-03-28 07:11:46,642: time cost, forward:0.016411202385324147, backward:0.039286147532327634, data cost:0.5279616440657156 
2022-03-28 07:11:46,643: ============================================================
2022-03-28 07:11:46,643: Epoch 38/38 Batch 7500/7662 eta: 0:01:35.266696	Training Loss 1.4904 (1.5784)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 07:11:46,643: ============================================================
2022-03-28 07:12:42,202: time cost, forward:0.01638388853352985, backward:0.03927552886723939, data cost:0.5276173007913382 
2022-03-28 07:12:42,203: ============================================================
2022-03-28 07:12:42,203: Epoch 38/38 Batch 7600/7662 eta: 0:00:35.002804	Training Loss 1.3804 (1.5785)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)	
2022-03-28 07:12:42,203: ============================================================
2022-03-28 07:13:23,854: Epoch: 38/38 eta: 0:00:00	Training Loss 1.6935 (1.5788)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.994)
2022-03-28 07:13:23,855: ============================================================
2022-03-28 07:13:23,858: Save Checkpoint...
2022-03-28 07:13:23,860: ============================================================
2022-03-28 07:13:25,887: Save done!
2022-03-28 07:13:25,887: ============================================================
