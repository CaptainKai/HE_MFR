2022-03-25 23:10:48,448: [('name', 'amsoft-36'), ('backbone_model_name', 'SimpleResnet_36'), ('classify_model_name', 'Sphereface2'), ('resume_net_model', None), ('resume_net_classifier', None), ('no_cuda', False), ('gpu_num', 1), ('log_interval', 100), ('log_path', './logs/SR_36_ddp_sphereface2.log'), ('log_pic_path', './logs/pic/SR_36_ddp_sphereface2/'), ('save_path', 'snapshot/SR_36_ddp_sphereface2/'), ('lmdb_path', '/home/ubuntu/data4/lk/data/lmdb_default'), ('batch_size', 512), ('datanum', 3923399), ('num_class', 86876), ('lmdb_workers', 4), ('num_workers', 4), ('start_epoch', 1), ('max_epoch', 26), ('lr', 0.01), ('base', 'epoch'), ('step_size', [10, 20, 30]), ('momentum', 0.9), ('gama', 0.1), ('weight_decay', 0.0005), ('rank', 0), ('dist_url', 'env://'), ('world_size', 2), ('gpu', 0), ('dist_backend', 'nccl'), ('distributed', True), ('master_port', 22000), ('multiprocessing_distributed', False), ('SEED', 1337), ('local_rank', 0)]
2022-03-25 23:10:48,449: SimpleResidualBackbone(
  (conv1): ConvPrelu(
    (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (prelu): PReLU(num_parameters=64)
  )
  (layer1): Sequential(
    (0): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=64)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=64)
      )
    )
    (1): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=64)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=64)
      )
    )
  )
  (conv2): ConvPrelu(
    (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (prelu): PReLU(num_parameters=128)
  )
  (layer2): Sequential(
    (0): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
    )
    (1): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
    )
    (2): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
    )
    (3): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
    )
  )
  (conv3): ConvPrelu(
    (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (prelu): PReLU(num_parameters=256)
  )
  (layer3): Sequential(
    (0): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
    (1): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
    (2): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
    (3): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
    (4): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
    (5): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
    (6): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
    (7): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
  )
  (conv4): ConvPrelu(
    (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (prelu): PReLU(num_parameters=512)
  )
  (layer4): Sequential(
    (0): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=512)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=512)
      )
    )
    (1): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=512)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=512)
      )
    )
  )
  (fc5): Linear(in_features=25088, out_features=512, bias=True)
)
2022-03-25 23:10:49,010: data balance
2022-03-25 23:11:24,801: time cost, forward:0.11675640308495724, backward:0.04449519966587876, data cost:0.19524312741828687 
2022-03-25 23:11:24,802: ============================================================
2022-03-25 23:11:24,802: Epoch 1/26 Batch 100/7662 eta: 19:40:04.665762	Training Loss 0.8427 (0.8528)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.006)	
2022-03-25 23:11:24,802: ============================================================
2022-03-25 23:12:04,985: time cost, forward:0.11055293634309242, backward:0.03876992685710964, data cost:0.22970047308571973 
2022-03-25 23:12:04,985: ============================================================
2022-03-25 23:12:04,986: Epoch 1/26 Batch 200/7662 eta: 22:12:50.787050	Training Loss 0.8364 (0.8458)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.007)	
2022-03-25 23:12:04,986: ============================================================
2022-03-25 23:12:45,854: time cost, forward:0.1082839423597457, backward:0.03706550199451255, data cost:0.24345554954630874 
2022-03-25 23:12:45,854: ============================================================
2022-03-25 23:12:45,855: Epoch 1/26 Batch 300/7662 eta: 22:34:53.736339	Training Loss 0.8316 (0.8420)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.010)	
2022-03-25 23:12:45,855: ============================================================
2022-03-25 23:13:29,174: time cost, forward:0.10727211227990631, backward:0.03624495826568221, data cost:0.25622711862836567 
2022-03-25 23:13:29,174: ============================================================
2022-03-25 23:13:29,174: Epoch 1/26 Batch 400/7662 eta: 23:55:25.205120	Training Loss 0.8316 (0.8395)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.010)	
2022-03-25 23:13:29,174: ============================================================
2022-03-25 23:14:12,453: time cost, forward:0.10655467591448155, backward:0.03577416979956006, data cost:0.26379060984135627 
2022-03-25 23:14:12,453: ============================================================
2022-03-25 23:14:12,454: Epoch 1/26 Batch 500/7662 eta: 23:53:21.449437	Training Loss 0.8299 (0.8377)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.010)	
2022-03-25 23:14:12,454: ============================================================
2022-03-25 23:14:56,552: time cost, forward:0.1061668591029656, backward:0.035259231303092435, data cost:0.2706167120766361 
2022-03-25 23:14:56,552: ============================================================
2022-03-25 23:14:56,553: Epoch 1/26 Batch 600/7662 eta: 1 day, 0:19:46.584537	Training Loss 0.8289 (0.8363)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.009)	
2022-03-25 23:14:56,553: ============================================================
2022-03-25 23:15:41,349: time cost, forward:0.10598232783643644, backward:0.03497848149191839, data cost:0.2761136950000332 
2022-03-25 23:15:41,349: ============================================================
2022-03-25 23:15:41,349: Epoch 1/26 Batch 700/7662 eta: 1 day, 0:42:06.996197	Training Loss 0.8290 (0.8353)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.009)	
2022-03-25 23:15:41,349: ============================================================
2022-03-25 23:16:25,881: time cost, forward:0.10573233173547011, backward:0.034888272888221786, data cost:0.27991214801134245 
2022-03-25 23:16:25,882: ============================================================
2022-03-25 23:16:25,882: Epoch 1/26 Batch 800/7662 eta: 1 day, 0:32:38.564940	Training Loss 0.8279 (0.8344)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.010)	
2022-03-25 23:16:25,882: ============================================================
2022-03-25 23:17:10,836: time cost, forward:0.10558689794232769, backward:0.0346101977270888, data cost:0.28353891754574717 
2022-03-25 23:17:10,836: ============================================================
2022-03-25 23:17:10,836: Epoch 1/26 Batch 900/7662 eta: 1 day, 0:45:50.348474	Training Loss 0.8278 (0.8337)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.009)	
2022-03-25 23:17:10,836: ============================================================
2022-03-25 23:17:55,120: time cost, forward:0.10545553077567925, backward:0.034485968741568715, data cost:0.28565498873278183 
2022-03-25 23:17:55,120: ============================================================
2022-03-25 23:17:55,120: Epoch 1/26 Batch 1000/7662 eta: 1 day, 0:22:56.933033	Training Loss 0.8277 (0.8331)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.010)	
2022-03-25 23:17:55,121: ============================================================
2022-03-25 23:18:39,130: time cost, forward:0.10533873768043692, backward:0.03438604019033139, data cost:0.28720331756064194 
2022-03-25 23:18:39,130: ============================================================
2022-03-25 23:18:39,131: Epoch 1/26 Batch 1100/7662 eta: 1 day, 0:13:09.918126	Training Loss 0.8277 (0.8326)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.009)	
2022-03-25 23:18:39,131: ============================================================
2022-03-25 23:19:24,810: time cost, forward:0.10589879209345038, backward:0.034287688730158736, data cost:0.2891503122073596 
2022-03-25 23:19:24,811: ============================================================
2022-03-25 23:19:24,811: Epoch 1/26 Batch 1200/7662 eta: 1 day, 1:07:33.551829	Training Loss 0.8265 (0.8321)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.011)	
2022-03-25 23:19:24,811: ============================================================
2022-03-25 23:20:12,037: time cost, forward:0.10668154585076993, backward:0.03430463590467774, data cost:0.2916354433768891 
2022-03-25 23:20:12,037: ============================================================
2022-03-25 23:20:12,038: Epoch 1/26 Batch 1300/7662 eta: 1 day, 1:57:46.998446	Training Loss 0.8268 (0.8317)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.011)	
2022-03-25 23:20:12,038: ============================================================
2022-03-25 23:20:57,340: time cost, forward:0.106493571726572, backward:0.0342484381132419, data cost:0.2932693977028749 
2022-03-25 23:20:57,341: ============================================================
2022-03-25 23:20:57,341: Epoch 1/26 Batch 1400/7662 eta: 1 day, 0:53:36.262794	Training Loss 0.8270 (0.8314)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.011)	
2022-03-25 23:20:57,341: ============================================================
2022-03-25 23:21:43,806: time cost, forward:0.10642970363802716, backward:0.03418817990934793, data cost:0.29546089328234 
2022-03-25 23:21:43,806: ============================================================
2022-03-25 23:21:43,807: Epoch 1/26 Batch 1500/7662 eta: 1 day, 1:31:08.282864	Training Loss 0.8263 (0.8311)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.011)	
2022-03-25 23:21:43,807: ============================================================
2022-03-25 23:22:31,731: time cost, forward:0.10697985709347227, backward:0.03434601405622662, data cost:0.2973598937379934 
2022-03-25 23:22:31,731: ============================================================
2022-03-25 23:22:31,732: Epoch 1/26 Batch 1600/7662 eta: 1 day, 2:18:26.228979	Training Loss 0.8264 (0.8308)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.010)	
2022-03-25 23:22:31,732: ============================================================
2022-03-25 23:23:34,017: time cost, forward:0.11111139184661022, backward:0.03479921558171318, data cost:0.30339257755021337 
2022-03-25 23:23:34,055: ============================================================
2022-03-25 23:23:34,055: Epoch 1/26 Batch 1700/7662 eta: 1 day, 10:11:36.555729	Training Loss 0.8264 (0.8305)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.011)	
2022-03-25 23:23:34,055: ============================================================
2022-03-25 23:24:29,141: time cost, forward:0.11297891151911686, backward:0.035055686527652966, data cost:0.30706078745114135 
2022-03-25 23:24:29,141: ============================================================
2022-03-25 23:24:29,142: Epoch 1/26 Batch 1800/7662 eta: 1 day, 6:12:28.006240	Training Loss 0.8262 (0.8303)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.195 (0.011)	
2022-03-25 23:24:29,142: ============================================================
2022-03-25 23:25:18,305: time cost, forward:0.11338047695009253, backward:0.03523896931974181, data cost:0.3082708496366946 
2022-03-25 23:25:18,306: ============================================================
2022-03-25 23:25:18,306: Epoch 1/26 Batch 1900/7662 eta: 1 day, 2:56:47.725486	Training Loss 0.8274 (0.8301)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.011)	
2022-03-25 23:25:18,306: ============================================================
2022-03-25 23:26:08,001: time cost, forward:0.11408638727551643, backward:0.03534895888324258, data cost:0.30952411284740117 
2022-03-25 23:26:08,002: ============================================================
2022-03-25 23:26:08,002: Epoch 1/26 Batch 2000/7662 eta: 1 day, 3:13:27.097747	Training Loss 0.8262 (0.8299)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.012)	
2022-03-25 23:26:08,002: ============================================================
2022-03-25 23:26:59,495: time cost, forward:0.11506585906720718, backward:0.03542391955142592, data cost:0.3111468000943573 
2022-03-25 23:26:59,496: ============================================================
2022-03-25 23:26:59,496: Epoch 1/26 Batch 2100/7662 eta: 1 day, 4:11:41.249709	Training Loss 0.8258 (0.8297)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.012)	
2022-03-25 23:26:59,496: ============================================================
2022-03-25 23:27:52,426: time cost, forward:0.11601606354273249, backward:0.035641311135493715, data cost:0.3130100098671074 
2022-03-25 23:27:52,427: ============================================================
2022-03-25 23:27:52,427: Epoch 1/26 Batch 2200/7662 eta: 1 day, 4:58:00.899820	Training Loss 0.8262 (0.8296)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.012)	
2022-03-25 23:27:52,427: ============================================================
2022-03-25 23:28:39,133: time cost, forward:0.11590822866140318, backward:0.03574094506853194, data cost:0.3130841269706736 
2022-03-25 23:28:39,133: ============================================================
2022-03-25 23:28:39,133: Epoch 1/26 Batch 2300/7662 eta: 1 day, 1:32:50.985946	Training Loss 0.8277 (0.8295)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.012)	
2022-03-25 23:28:39,134: ============================================================
2022-03-25 23:29:27,806: time cost, forward:0.11606238920920191, backward:0.03572634231452894, data cost:0.3138636490264104 
2022-03-25 23:29:27,806: ============================================================
2022-03-25 23:29:27,806: Epoch 1/26 Batch 2400/7662 eta: 1 day, 2:36:35.044601	Training Loss 0.8262 (0.8293)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.011)	
2022-03-25 23:29:27,807: ============================================================
2022-03-25 23:30:17,427: time cost, forward:0.11637718594517885, backward:0.0357487682534867, data cost:0.31470161144520675 
2022-03-25 23:30:17,428: ============================================================
2022-03-25 23:30:17,428: Epoch 1/26 Batch 2500/7662 eta: 1 day, 3:06:51.607866	Training Loss 0.8260 (0.8292)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.011)	
2022-03-25 23:30:17,428: ============================================================
2022-03-25 23:31:04,330: time cost, forward:0.11600538298183792, backward:0.03567578197213584, data cost:0.31518219314478324 
2022-03-25 23:31:04,330: ============================================================
2022-03-25 23:31:04,331: Epoch 1/26 Batch 2600/7662 eta: 1 day, 1:36:56.870137	Training Loss 0.8261 (0.8291)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.012)	
2022-03-25 23:31:04,331: ============================================================
2022-03-25 23:32:04,186: time cost, forward:0.1174225020117122, backward:0.03568866969303274, data cost:0.31856220357724585 
2022-03-25 23:32:04,212: ============================================================
2022-03-25 23:32:04,213: Epoch 1/26 Batch 2700/7662 eta: 1 day, 8:41:16.369536	Training Loss 0.8258 (0.8290)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.012)	
2022-03-25 23:32:04,213: ============================================================
2022-03-25 23:32:59,893: time cost, forward:0.11846119942687247, backward:0.03578682148528976, data cost:0.32037155259375316 
2022-03-25 23:32:59,894: ============================================================
2022-03-25 23:32:59,895: Epoch 1/26 Batch 2800/7662 eta: 1 day, 6:22:45.764453	Training Loss 0.8270 (0.8289)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.195 (0.012)	
2022-03-25 23:32:59,895: ============================================================
2022-03-25 23:33:50,078: time cost, forward:0.11890338445046969, backward:0.035833299386168235, data cost:0.3209330079143481 
2022-03-25 23:33:50,079: ============================================================
2022-03-25 23:33:50,079: Epoch 1/26 Batch 2900/7662 eta: 1 day, 3:21:59.234293	Training Loss 0.8266 (0.8288)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.012)	
2022-03-25 23:33:50,079: ============================================================
2022-03-25 23:34:46,518: time cost, forward:0.11995922235219866, backward:0.0359945599338777, data cost:0.3224758332313876 
2022-03-25 23:34:46,519: ============================================================
2022-03-25 23:34:46,520: Epoch 1/26 Batch 3000/7662 eta: 1 day, 6:45:43.432234	Training Loss 0.8253 (0.8287)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.012)	
2022-03-25 23:34:46,520: ============================================================
2022-03-25 23:35:48,706: time cost, forward:0.12138484785271368, backward:0.036142828926881615, data cost:0.32559448036312016 
2022-03-25 23:35:48,726: ============================================================
2022-03-25 23:35:48,727: Epoch 1/26 Batch 3100/7662 eta: 1 day, 9:53:15.999449	Training Loss 0.8255 (0.8286)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.012)	
2022-03-25 23:35:48,727: ============================================================
2022-03-25 23:36:51,825: time cost, forward:0.12275911368739423, backward:0.03632784158075254, data cost:0.3286577884612064 
2022-03-25 23:36:51,840: ============================================================
2022-03-25 23:36:51,840: Epoch 1/26 Batch 3200/7662 eta: 1 day, 10:21:50.822477	Training Loss 0.8256 (0.8285)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.195 (0.012)	
2022-03-25 23:36:51,840: ============================================================
2022-03-25 23:38:51,747: time cost, forward:0.13037945654002708, backward:0.03659311826751607, data cost:0.3422512350461092 
2022-03-25 23:38:51,748: ============================================================
2022-03-25 23:38:51,748: Epoch 1/26 Batch 3300/7662 eta: 2 days, 17:15:14.905076	Training Loss 0.8266 (0.8285)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.012)	
2022-03-25 23:38:51,748: ============================================================
2022-03-25 23:40:53,082: time cost, forward:0.13767097991647073, backward:0.03694333353965694, data cost:0.35530748448676314 
2022-03-25 23:40:53,107: ============================================================
2022-03-25 23:40:53,107: Epoch 1/26 Batch 3400/7662 eta: 2 days, 18:00:37.168262	Training Loss 0.8255 (0.8284)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.012)	
2022-03-25 23:40:53,107: ============================================================
2022-03-25 23:42:53,160: time cost, forward:0.14443021121792332, backward:0.03715682452186308, data cost:0.3674582953315423 
2022-03-25 23:42:53,162: ============================================================
2022-03-25 23:42:53,164: Epoch 1/26 Batch 3500/7662 eta: 2 days, 17:16:05.142342	Training Loss 0.8261 (0.8283)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.012)	
2022-03-25 23:42:53,164: ============================================================
2022-03-25 23:44:52,791: time cost, forward:0.15041077233049796, backward:0.03742072111237344, data cost:0.3792031840106851 
2022-03-25 23:44:52,815: ============================================================
2022-03-25 23:44:52,815: Epoch 1/26 Batch 3600/7662 eta: 2 days, 17:00:54.835882	Training Loss 0.8257 (0.8283)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.012)	
2022-03-25 23:44:52,815: ============================================================
2022-03-25 23:46:53,653: time cost, forward:0.15609468134972623, backward:0.03768080361761509, data cost:0.39037736791892774 
2022-03-25 23:46:53,655: ============================================================
2022-03-25 23:46:53,656: Epoch 1/26 Batch 3700/7662 eta: 2 days, 17:37:38.145831	Training Loss 0.8268 (0.8282)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.012)	
2022-03-25 23:46:53,658: ============================================================
2022-03-25 23:48:51,123: time cost, forward:0.16139657957423953, backward:0.037872474235621026, data cost:0.4003978845601836 
2022-03-25 23:48:51,136: ============================================================
2022-03-25 23:48:51,138: Epoch 1/26 Batch 3800/7662 eta: 2 days, 15:46:13.530328	Training Loss 0.8255 (0.8282)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.012)	
2022-03-25 23:48:51,138: ============================================================
2022-03-25 23:50:53,035: time cost, forward:0.16666460685407117, backward:0.03813965842185127, data cost:0.4107828815951351 
2022-03-25 23:50:53,038: ============================================================
2022-03-25 23:50:53,038: Epoch 1/26 Batch 3900/7662 eta: 2 days, 18:08:09.433362	Training Loss 0.8264 (0.8281)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.012)	
2022-03-25 23:50:53,039: ============================================================
2022-03-25 23:52:50,979: time cost, forward:0.17145403727020853, backward:0.03829706904589459, data cost:0.4199965930813758 
2022-03-25 23:52:50,996: ============================================================
2022-03-25 23:52:51,003: Epoch 1/26 Batch 4000/7662 eta: 2 days, 15:58:02.044873	Training Loss 0.8257 (0.8281)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.012)	
2022-03-25 23:52:51,003: ============================================================
2022-03-25 23:54:49,274: time cost, forward:0.1762866424798791, backward:0.03851456675886614, data cost:0.42825689011010987 
2022-03-25 23:54:49,278: ============================================================
2022-03-25 23:54:49,279: Epoch 1/26 Batch 4100/7662 eta: 2 days, 16:06:11.343012	Training Loss 0.8258 (0.8280)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.012)	
2022-03-25 23:54:49,280: ============================================================
2022-03-25 23:56:47,496: time cost, forward:0.1802842078761959, backward:0.038676146468425765, data cost:0.43706881463399927 
2022-03-25 23:56:47,520: ============================================================
2022-03-25 23:56:47,521: Epoch 1/26 Batch 4200/7662 eta: 2 days, 16:03:07.633855	Training Loss 0.8245 (0.8280)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.012)	
2022-03-25 23:56:47,521: ============================================================
2022-03-25 23:58:46,079: time cost, forward:0.18412890387679512, backward:0.03869819940592306, data cost:0.4453229466048083 
2022-03-25 23:58:46,082: ============================================================
2022-03-25 23:58:46,083: Epoch 1/26 Batch 4300/7662 eta: 2 days, 16:11:32.678171	Training Loss 0.8267 (0.8279)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.012)	
2022-03-25 23:58:46,083: ============================================================
2022-03-26 00:00:41,100: time cost, forward:0.18760842034751163, backward:0.038639836052272176, data cost:0.45289400377770017 
2022-03-26 00:00:41,128: ============================================================
2022-03-26 00:00:41,129: Epoch 1/26 Batch 4400/7662 eta: 2 days, 14:15:24.152467	Training Loss 0.8260 (0.8279)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.012)	
2022-03-26 00:00:41,129: ============================================================
2022-03-26 00:02:38,319: time cost, forward:0.19122115599629508, backward:0.03884648842185199, data cost:0.46007384123021056 
2022-03-26 00:02:38,323: ============================================================
2022-03-26 00:02:38,325: Epoch 1/26 Batch 4500/7662 eta: 2 days, 15:23:15.072870	Training Loss 0.8271 (0.8279)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.011)	
2022-03-26 00:02:38,325: ============================================================
2022-03-26 00:04:40,173: time cost, forward:0.19507055330286857, backward:0.03899015471011977, data cost:0.46759002782593967 
2022-03-26 00:04:40,173: ============================================================
2022-03-26 00:04:40,173: Epoch 1/26 Batch 4600/7662 eta: 2 days, 17:52:14.692636	Training Loss 0.8258 (0.8278)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.011)	
2022-03-26 00:04:40,174: ============================================================
2022-03-26 00:06:35,065: time cost, forward:0.19836142905901583, backward:0.039070533726869375, data cost:0.47370103415744713 
2022-03-26 00:06:35,081: ============================================================
2022-03-26 00:06:35,082: Epoch 1/26 Batch 4700/7662 eta: 2 days, 14:05:11.149673	Training Loss 0.8253 (0.8278)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.011)	
2022-03-26 00:06:35,082: ============================================================
2022-03-26 00:08:32,053: time cost, forward:0.20130733813710897, backward:0.039208782143979354, data cost:0.4801031597258275 
2022-03-26 00:08:32,054: ============================================================
2022-03-26 00:08:32,054: Epoch 1/26 Batch 4800/7662 eta: 2 days, 15:10:10.196203	Training Loss 0.8250 (0.8277)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.011)	
2022-03-26 00:08:32,054: ============================================================
2022-03-26 00:10:29,638: time cost, forward:0.2044232647913917, backward:0.03930370119986035, data cost:0.48617122124155876 
2022-03-26 00:10:29,663: ============================================================
2022-03-26 00:10:29,664: Epoch 1/26 Batch 4900/7662 eta: 2 days, 15:28:50.021781	Training Loss 0.8259 (0.8277)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.011)	
2022-03-26 00:10:29,664: ============================================================
2022-03-26 00:12:28,009: time cost, forward:0.20756586949141842, backward:0.03946972522861506, data cost:0.49196571177257303 
2022-03-26 00:12:28,025: ============================================================
2022-03-26 00:12:28,025: Epoch 1/26 Batch 5000/7662 eta: 2 days, 15:51:13.048685	Training Loss 0.8259 (0.8277)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.012)	
2022-03-26 00:12:28,025: ============================================================
2022-03-26 00:14:24,200: time cost, forward:0.2105296275315974, backward:0.03957605301153195, data cost:0.49711744096564836 
2022-03-26 00:14:24,206: ============================================================
2022-03-26 00:14:24,209: Epoch 1/26 Batch 5100/7662 eta: 2 days, 14:38:46.542526	Training Loss 0.8256 (0.8277)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.012)	
2022-03-26 00:14:24,209: ============================================================
2022-03-26 00:16:21,865: time cost, forward:0.21367168151362398, backward:0.03969835762703366, data cost:0.5021066938507761 
2022-03-26 00:16:21,988: ============================================================
2022-03-26 00:16:21,989: Epoch 1/26 Batch 5200/7662 eta: 2 days, 15:28:29.418893	Training Loss 0.8261 (0.8276)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.195 (0.012)	
2022-03-26 00:16:21,989: ============================================================
2022-03-26 00:18:21,106: time cost, forward:0.2164939465804423, backward:0.03981890321160335, data cost:0.5073965390373297 
2022-03-26 00:18:21,135: ============================================================
2022-03-26 00:18:21,136: Epoch 1/26 Batch 5300/7662 eta: 2 days, 16:10:41.580045	Training Loss 0.8261 (0.8276)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.012)	
2022-03-26 00:18:21,136: ============================================================
2022-03-26 00:20:18,266: time cost, forward:0.2190862925190863, backward:0.03995067977446012, data cost:0.5122281424887513 
2022-03-26 00:20:18,381: ============================================================
2022-03-26 00:20:18,381: Epoch 1/26 Batch 5400/7662 eta: 2 days, 15:07:16.427766	Training Loss 0.8267 (0.8276)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.012)	
2022-03-26 00:20:18,381: ============================================================
2022-03-26 00:22:15,479: time cost, forward:0.22159332699245876, backward:0.04005207666853901, data cost:0.5167897536681335 
2022-03-26 00:22:15,482: ============================================================
2022-03-26 00:22:15,483: Epoch 1/26 Batch 5500/7662 eta: 2 days, 15:00:42.409205	Training Loss 0.8252 (0.8275)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.012)	
2022-03-26 00:22:15,484: ============================================================
2022-03-26 00:24:15,043: time cost, forward:0.22422571811618114, backward:0.04021116975674269, data cost:0.5214833520016173 
2022-03-26 00:24:15,061: ============================================================
2022-03-26 00:24:15,061: Epoch 1/26 Batch 5600/7662 eta: 2 days, 16:18:38.234301	Training Loss 0.8253 (0.8275)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.012)	
2022-03-26 00:24:15,061: ============================================================
2022-03-26 00:26:13,107: time cost, forward:0.22638057750408055, backward:0.04033170392333802, data cost:0.5261194113577263 
2022-03-26 00:26:13,108: ============================================================
2022-03-26 00:26:13,108: Epoch 1/26 Batch 5700/7662 eta: 2 days, 15:27:16.604709	Training Loss 0.8257 (0.8275)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.012)	
2022-03-26 00:26:13,108: ============================================================
2022-03-26 00:28:09,171: time cost, forward:0.22876989642059542, backward:0.040423150513989904, data cost:0.5299562148995226 
2022-03-26 00:28:09,189: ============================================================
2022-03-26 00:28:09,190: Epoch 1/26 Batch 5800/7662 eta: 2 days, 14:21:56.691408	Training Loss 0.8260 (0.8275)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.012)	
2022-03-26 00:28:09,190: ============================================================
2022-03-26 00:30:05,137: time cost, forward:0.2308905396669229, backward:0.04050620294542793, data cost:0.5338597954845283 
2022-03-26 00:30:05,139: ============================================================
2022-03-26 00:30:05,140: Epoch 1/26 Batch 5900/7662 eta: 2 days, 14:15:46.442950	Training Loss 0.8240 (0.8274)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.195 (0.013)	
2022-03-26 00:30:05,141: ============================================================
2022-03-26 00:32:03,982: time cost, forward:0.23306627058152218, backward:0.04070616455987446, data cost:0.5378306778416393 
2022-03-26 00:32:04,001: ============================================================
2022-03-26 00:32:04,002: Epoch 1/26 Batch 6000/7662 eta: 2 days, 15:47:36.730087	Training Loss 0.8257 (0.8274)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.013)	
2022-03-26 00:32:04,002: ============================================================
2022-03-26 00:33:58,955: time cost, forward:0.23510015771161885, backward:0.040815387794005516, data cost:0.5411478854296813 
2022-03-26 00:33:58,959: ============================================================
2022-03-26 00:33:58,960: Epoch 1/26 Batch 6100/7662 eta: 2 days, 13:39:59.361784	Training Loss 0.8257 (0.8274)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.013)	
2022-03-26 00:33:58,961: ============================================================
2022-03-26 00:35:57,507: time cost, forward:0.23713833086912547, backward:0.04085892884072459, data cost:0.5450892984569025 
2022-03-26 00:35:57,532: ============================================================
2022-03-26 00:35:57,533: Epoch 1/26 Batch 6200/7662 eta: 2 days, 15:34:20.540505	Training Loss 0.8247 (0.8273)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.013)	
2022-03-26 00:35:57,533: ============================================================
2022-03-26 00:37:53,366: time cost, forward:0.2389175934646977, backward:0.040855869109109384, data cost:0.54861155822743 
2022-03-26 00:37:53,366: ============================================================
2022-03-26 00:37:53,367: Epoch 1/26 Batch 6300/7662 eta: 2 days, 14:04:18.870390	Training Loss 0.8254 (0.8273)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.014)	
2022-03-26 00:37:53,367: ============================================================
2022-03-26 00:39:50,805: time cost, forward:0.24063839009263066, backward:0.040935992635699206, data cost:0.5521733342045675 
2022-03-26 00:39:50,830: ============================================================
2022-03-26 00:39:50,830: Epoch 1/26 Batch 6400/7662 eta: 2 days, 14:54:45.397536	Training Loss 0.8251 (0.8273)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.195 (0.014)	
2022-03-26 00:39:50,830: ============================================================
2022-03-26 00:41:45,660: time cost, forward:0.24226283880357907, backward:0.04103105753123678, data cost:0.5552850886296632 
2022-03-26 00:41:45,665: ============================================================
2022-03-26 00:41:45,667: Epoch 1/26 Batch 6500/7662 eta: 2 days, 13:28:23.739342	Training Loss 0.8252 (0.8272)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.195 (0.014)	
2022-03-26 00:41:45,667: ============================================================
2022-03-26 00:43:41,848: time cost, forward:0.24404088962004028, backward:0.04106027412674683, data cost:0.5583434675042964 
2022-03-26 00:43:41,984: ============================================================
2022-03-26 00:43:41,985: Epoch 1/26 Batch 6600/7662 eta: 2 days, 14:14:04.065707	Training Loss 0.8254 (0.8272)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.015)	
2022-03-26 00:43:41,985: ============================================================
2022-03-26 00:45:38,725: time cost, forward:0.2458006401064859, backward:0.04108209353024291, data cost:0.561418211234116 
2022-03-26 00:45:38,728: ============================================================
2022-03-26 00:45:38,729: Epoch 1/26 Batch 6700/7662 eta: 2 days, 14:25:46.506400	Training Loss 0.8260 (0.8272)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.015)	
2022-03-26 00:45:38,729: ============================================================
2022-03-26 00:47:35,269: time cost, forward:0.24745430155946396, backward:0.041116857339326275, data cost:0.5643753628114301 
2022-03-26 00:47:35,290: ============================================================
2022-03-26 00:47:35,291: Epoch 1/26 Batch 6800/7662 eta: 2 days, 14:18:01.806365	Training Loss 0.8239 (0.8271)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.015)	
2022-03-26 00:47:35,292: ============================================================
2022-03-26 00:49:30,954: time cost, forward:0.24873624803156313, backward:0.04115805592739439, data cost:0.5674299590050924 
2022-03-26 00:49:30,960: ============================================================
2022-03-26 00:49:30,963: Epoch 1/26 Batch 6900/7662 eta: 2 days, 13:47:30.909904	Training Loss 0.8248 (0.8271)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.016)	
2022-03-26 00:49:30,964: ============================================================
2022-03-26 00:51:28,939: time cost, forward:0.2502279990842503, backward:0.04118818939711506, data cost:0.5704643734865043 
2022-03-26 00:51:28,960: ============================================================
2022-03-26 00:51:28,962: Epoch 1/26 Batch 7000/7662 eta: 2 days, 15:00:08.448765	Training Loss 0.8242 (0.8270)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.016)	
2022-03-26 00:51:28,962: ============================================================
2022-03-26 00:53:25,366: time cost, forward:0.2515609955549207, backward:0.04127914701688288, data cost:0.5732914793237798 
2022-03-26 00:53:25,371: ============================================================
2022-03-26 00:53:25,372: Epoch 1/26 Batch 7100/7662 eta: 2 days, 14:07:18.848813	Training Loss 0.8252 (0.8270)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-26 00:53:25,373: ============================================================
2022-03-26 00:55:19,973: time cost, forward:0.2529446904502622, backward:0.04134526185185268, data cost:0.5757442633796689 
2022-03-26 00:55:19,973: ============================================================
2022-03-26 00:55:19,973: Epoch 1/26 Batch 7200/7662 eta: 2 days, 13:07:31.668495	Training Loss 0.8229 (0.8269)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-26 00:55:19,974: ============================================================
2022-03-26 00:57:14,646: time cost, forward:0.25421264854616166, backward:0.0413835164308058, data cost:0.5782265348260672 
2022-03-26 00:57:14,717: ============================================================
2022-03-26 00:57:14,717: Epoch 1/26 Batch 7300/7662 eta: 2 days, 13:10:07.915516	Training Loss 0.8223 (0.8269)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-26 00:57:14,717: ============================================================
2022-03-26 00:59:12,597: time cost, forward:0.25562041961658577, backward:0.04148245424914318, data cost:0.5807599367555983 
2022-03-26 00:59:12,601: ============================================================
2022-03-26 00:59:12,602: Epoch 1/26 Batch 7400/7662 eta: 2 days, 14:48:37.531707	Training Loss 0.8232 (0.8268)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.019)	
2022-03-26 00:59:12,603: ============================================================
2022-03-26 01:01:08,987: time cost, forward:0.2567304678480853, backward:0.04156843082541417, data cost:0.5834325191608698 
2022-03-26 01:01:08,988: ============================================================
2022-03-26 01:01:08,988: Epoch 1/26 Batch 7500/7662 eta: 2 days, 13:58:48.627353	Training Loss 0.8214 (0.8267)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.195 (0.020)	
2022-03-26 01:01:08,989: ============================================================
2022-03-26 01:03:04,802: time cost, forward:0.2578326393889979, backward:0.041615265014062104, data cost:0.5859100253570392 
2022-03-26 01:03:04,824: ============================================================
2022-03-26 01:03:04,824: Epoch 1/26 Batch 7600/7662 eta: 2 days, 13:39:15.773373	Training Loss 0.8227 (0.8267)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.195 (0.020)	
2022-03-26 01:03:04,824: ============================================================
2022-03-26 01:04:17,518: Epoch: 1/26 eta: 2 days, 13:38:02.797042	Training Loss 0.8207 (0.8266)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.021)
2022-03-26 01:04:17,518: ============================================================
2022-03-26 01:06:14,419: time cost, forward:0.33677694773433187, backward:0.04224184305980952, data cost:0.7868881297833992 
2022-03-26 01:06:14,419: ============================================================
2022-03-26 01:06:14,420: Epoch 2/26 Batch 100/7662 eta: 2 days, 14:06:31.905916	Training Loss 0.8191 (0.8200)	Training Prec@1 0.000 (0.030)	Training Prec@5 0.000 (0.091)	
2022-03-26 01:06:14,420: ============================================================
2022-03-26 01:08:12,924: time cost, forward:0.3313283165495599, backward:0.0463310150644887, data cost:0.7975230863944969 
2022-03-26 01:08:12,926: ============================================================
2022-03-26 01:08:12,927: Epoch 2/26 Batch 200/7662 eta: 2 days, 14:59:23.779315	Training Loss 0.8200 (0.8199)	Training Prec@1 0.000 (0.028)	Training Prec@5 0.391 (0.115)	
2022-03-26 01:08:12,927: ============================================================
2022-03-26 01:10:04,709: time cost, forward:0.3320761061831063, backward:0.04677493755634014, data cost:0.7791344641044387 
2022-03-26 01:10:04,734: ============================================================
2022-03-26 01:10:04,735: Epoch 2/26 Batch 300/7662 eta: 2 days, 11:23:53.670652	Training Loss 0.8193 (0.8196)	Training Prec@1 0.000 (0.031)	Training Prec@5 0.000 (0.112)	
2022-03-26 01:10:04,735: ============================================================
2022-03-26 01:11:58,036: time cost, forward:0.3266297241201377, backward:0.04743579396030359, data cost:0.7774934338447743 
2022-03-26 01:11:58,037: ============================================================
2022-03-26 01:11:58,037: Epoch 2/26 Batch 400/7662 eta: 2 days, 12:09:39.145263	Training Loss 0.8169 (0.8195)	Training Prec@1 0.000 (0.033)	Training Prec@5 0.195 (0.120)	
2022-03-26 01:11:58,038: ============================================================
2022-03-26 01:13:54,794: time cost, forward:0.3238706201732995, backward:0.04829633833172326, data cost:0.7809822048118453 
2022-03-26 01:13:54,797: ============================================================
2022-03-26 01:13:54,798: Epoch 2/26 Batch 500/7662 eta: 2 days, 13:57:51.192221	Training Loss 0.8198 (0.8193)	Training Prec@1 0.000 (0.033)	Training Prec@5 0.391 (0.124)	
2022-03-26 01:13:54,798: ============================================================
2022-03-26 01:15:46,907: time cost, forward:0.3229247791341231, backward:0.048809008128654977, data cost:0.7770360228613342 
2022-03-26 01:15:47,088: ============================================================
2022-03-26 01:15:47,090: Epoch 2/26 Batch 600/7662 eta: 2 days, 11:33:42.270900	Training Loss 0.8183 (0.8191)	Training Prec@1 0.195 (0.036)	Training Prec@5 0.195 (0.133)	
2022-03-26 01:15:47,090: ============================================================
2022-03-26 01:17:37,484: time cost, forward:0.32298560033369816, backward:0.04910053169949031, data cost:0.7704969325631814 
2022-03-26 01:17:37,488: ============================================================
2022-03-26 01:17:37,489: Epoch 2/26 Batch 700/7662 eta: 2 days, 10:31:38.306103	Training Loss 0.8147 (0.8188)	Training Prec@1 0.195 (0.040)	Training Prec@5 0.586 (0.143)	
2022-03-26 01:17:37,490: ============================================================
2022-03-26 01:19:35,521: time cost, forward:0.32278448440255747, backward:0.04877442442281673, data cost:0.7747651853310749 
2022-03-26 01:19:35,523: ============================================================
2022-03-26 01:19:35,523: Epoch 2/26 Batch 800/7662 eta: 2 days, 14:32:31.847435	Training Loss 0.8141 (0.8185)	Training Prec@1 0.195 (0.043)	Training Prec@5 0.391 (0.153)	
2022-03-26 01:19:35,524: ============================================================
2022-03-26 01:21:27,878: time cost, forward:0.32140905758960625, backward:0.04910444258582738, data cost:0.7739454190908736 
2022-03-26 01:21:27,881: ============================================================
2022-03-26 01:21:27,882: Epoch 2/26 Batch 900/7662 eta: 2 days, 11:30:12.502933	Training Loss 0.8153 (0.8183)	Training Prec@1 0.000 (0.045)	Training Prec@5 0.195 (0.162)	
2022-03-26 01:21:27,883: ============================================================
2022-03-26 01:23:21,460: time cost, forward:0.3214149728074327, backward:0.04910813294373475, data cost:0.7727562436112413 
2022-03-26 01:23:21,482: ============================================================
2022-03-26 01:23:21,483: Epoch 2/26 Batch 1000/7662 eta: 2 days, 12:07:47.539983	Training Loss 0.8179 (0.8180)	Training Prec@1 0.000 (0.049)	Training Prec@5 0.000 (0.171)	
2022-03-26 01:23:21,483: ============================================================
2022-03-26 01:25:13,746: time cost, forward:0.32062318479071106, backward:0.04904985362774031, data cost:0.7712858614865165 
2022-03-26 01:25:13,752: ============================================================
2022-03-26 01:25:13,753: Epoch 2/26 Batch 1100/7662 eta: 2 days, 11:23:38.759178	Training Loss 0.8135 (0.8177)	Training Prec@1 0.195 (0.053)	Training Prec@5 0.781 (0.186)	
2022-03-26 01:25:13,754: ============================================================
2022-03-26 01:27:07,183: time cost, forward:0.3205139090161805, backward:0.049215355746640675, data cost:0.7707320434834383 
2022-03-26 01:27:07,185: ============================================================
2022-03-26 01:27:07,186: Epoch 2/26 Batch 1200/7662 eta: 2 days, 11:58:41.113220	Training Loss 0.8149 (0.8174)	Training Prec@1 0.000 (0.056)	Training Prec@5 0.391 (0.198)	
2022-03-26 01:27:07,186: ============================================================
2022-03-26 01:29:00,158: time cost, forward:0.3201941416023143, backward:0.04917802968513424, data cost:0.7706156470759086 
2022-03-26 01:29:00,159: ============================================================
2022-03-26 01:29:00,159: Epoch 2/26 Batch 1300/7662 eta: 2 days, 11:42:13.526036	Training Loss 0.8128 (0.8171)	Training Prec@1 0.195 (0.060)	Training Prec@5 0.586 (0.212)	
2022-03-26 01:29:00,159: ============================================================
2022-03-26 01:30:52,136: time cost, forward:0.32108593157481263, backward:0.04935786637176012, data cost:0.7680635285258208 
2022-03-26 01:30:52,137: ============================================================
2022-03-26 01:30:52,137: Epoch 2/26 Batch 1400/7662 eta: 2 days, 11:08:47.297972	Training Loss 0.8133 (0.8168)	Training Prec@1 0.195 (0.064)	Training Prec@5 0.586 (0.227)	
2022-03-26 01:30:52,137: ============================================================
2022-03-26 01:32:46,666: time cost, forward:0.3216238238160971, backward:0.0493846693541544, data cost:0.7678508434079344 
2022-03-26 01:32:46,667: ============================================================
2022-03-26 01:32:46,667: Epoch 2/26 Batch 1500/7662 eta: 2 days, 12:27:44.822553	Training Loss 0.8139 (0.8165)	Training Prec@1 0.000 (0.069)	Training Prec@5 0.586 (0.243)	
2022-03-26 01:32:46,667: ============================================================
2022-03-26 01:34:40,418: time cost, forward:0.3220443449742053, backward:0.049607719906871954, data cost:0.7666870131203352 
2022-03-26 01:34:40,419: ============================================================
2022-03-26 01:34:40,419: Epoch 2/26 Batch 1600/7662 eta: 2 days, 12:01:13.621908	Training Loss 0.8098 (0.8162)	Training Prec@1 0.391 (0.075)	Training Prec@5 0.977 (0.257)	
2022-03-26 01:34:40,419: ============================================================
2022-03-26 01:36:33,199: time cost, forward:0.3215967170486316, backward:0.0495254886788856, data cost:0.7668067035147412 
2022-03-26 01:36:33,199: ============================================================
2022-03-26 01:36:33,200: Epoch 2/26 Batch 1700/7662 eta: 2 days, 11:28:34.567452	Training Loss 0.8073 (0.8158)	Training Prec@1 0.000 (0.082)	Training Prec@5 0.781 (0.276)	
2022-03-26 01:36:33,200: ============================================================
2022-03-26 01:38:25,475: time cost, forward:0.3213370588502995, backward:0.04980768966568782, data cost:0.7659418854599466 
2022-03-26 01:38:25,548: ============================================================
2022-03-26 01:38:25,549: Epoch 2/26 Batch 1800/7662 eta: 2 days, 11:13:03.820539	Training Loss 0.8080 (0.8155)	Training Prec@1 0.000 (0.088)	Training Prec@5 0.391 (0.292)	
2022-03-26 01:38:25,549: ============================================================
2022-03-26 01:40:18,464: time cost, forward:0.32067598538250597, backward:0.05014372386701362, data cost:0.7657113411729118 
2022-03-26 01:40:18,465: ============================================================
2022-03-26 01:40:18,465: Epoch 2/26 Batch 1900/7662 eta: 2 days, 11:29:06.887702	Training Loss 0.8078 (0.8151)	Training Prec@1 0.000 (0.097)	Training Prec@5 0.391 (0.313)	
2022-03-26 01:40:18,465: ============================================================
2022-03-26 01:42:11,363: time cost, forward:0.3203280746131733, backward:0.050328002684470595, data cost:0.7656303641198575 
2022-03-26 01:42:11,363: ============================================================
2022-03-26 01:42:11,364: Epoch 2/26 Batch 2000/7662 eta: 2 days, 11:26:40.457565	Training Loss 0.8080 (0.8148)	Training Prec@1 0.391 (0.107)	Training Prec@5 0.977 (0.333)	
2022-03-26 01:42:11,364: ============================================================
2022-03-26 01:44:06,256: time cost, forward:0.3196168860235119, backward:0.05030045820566062, data cost:0.7665728913880121 
2022-03-26 01:44:06,260: ============================================================
2022-03-26 01:44:06,261: Epoch 2/26 Batch 2100/7662 eta: 2 days, 12:27:52.715674	Training Loss 0.8057 (0.8144)	Training Prec@1 0.195 (0.113)	Training Prec@5 1.367 (0.355)	
2022-03-26 01:44:06,261: ============================================================
2022-03-26 01:45:58,268: time cost, forward:0.32002239966728624, backward:0.050217217887299014, data cost:0.765801725305173 
2022-03-26 01:45:58,268: ============================================================
2022-03-26 01:45:58,268: Epoch 2/26 Batch 2200/7662 eta: 2 days, 10:54:48.429955	Training Loss 0.8047 (0.8141)	Training Prec@1 0.977 (0.122)	Training Prec@5 2.148 (0.381)	
2022-03-26 01:45:58,268: ============================================================
2022-03-26 01:47:49,913: time cost, forward:0.3199784842819274, backward:0.05034672036903119, data cost:0.7648147309847945 
2022-03-26 01:47:49,913: ============================================================
2022-03-26 01:47:49,913: Epoch 2/26 Batch 2300/7662 eta: 2 days, 10:41:29.046541	Training Loss 0.8031 (0.8137)	Training Prec@1 0.195 (0.130)	Training Prec@5 0.781 (0.405)	
2022-03-26 01:47:49,913: ============================================================
2022-03-26 01:49:42,977: time cost, forward:0.32013791647987, backward:0.05022166340785406, data cost:0.764536857903128 
2022-03-26 01:49:42,977: ============================================================
2022-03-26 01:49:42,977: Epoch 2/26 Batch 2400/7662 eta: 2 days, 11:24:21.626455	Training Loss 0.8031 (0.8133)	Training Prec@1 0.586 (0.142)	Training Prec@5 1.172 (0.436)	
2022-03-26 01:49:42,977: ============================================================
2022-03-26 01:51:37,666: time cost, forward:0.320914544597441, backward:0.050175341189790126, data cost:0.7640122941800621 
2022-03-26 01:51:37,693: ============================================================
2022-03-26 01:51:37,695: Epoch 2/26 Batch 2500/7662 eta: 2 days, 12:14:33.021336	Training Loss 0.8062 (0.8129)	Training Prec@1 0.000 (0.152)	Training Prec@5 0.391 (0.469)	
2022-03-26 01:51:37,695: ============================================================
2022-03-26 01:53:33,394: time cost, forward:0.3222467640630554, backward:0.050053635575579604, data cost:0.7638785166665195 
2022-03-26 01:53:33,394: ============================================================
2022-03-26 01:53:33,394: Epoch 2/26 Batch 2600/7662 eta: 2 days, 12:43:37.000851	Training Loss 0.8026 (0.8125)	Training Prec@1 0.195 (0.161)	Training Prec@5 0.781 (0.499)	
2022-03-26 01:53:33,394: ============================================================
2022-03-26 01:55:29,200: time cost, forward:0.3237190058426576, backward:0.050127295486659375, data cost:0.7631000640349019 
2022-03-26 01:55:29,200: ============================================================
2022-03-26 01:55:29,201: Epoch 2/26 Batch 2700/7662 eta: 2 days, 12:45:01.196531	Training Loss 0.8003 (0.8121)	Training Prec@1 0.195 (0.175)	Training Prec@5 1.758 (0.536)	
2022-03-26 01:55:29,201: ============================================================
2022-03-26 01:57:23,696: time cost, forward:0.3249478283930183, backward:0.05009913768202716, data cost:0.7618622606930966 
2022-03-26 01:57:23,698: ============================================================
2022-03-26 01:57:23,698: Epoch 2/26 Batch 2800/7662 eta: 2 days, 12:01:54.922307	Training Loss 0.7975 (0.8117)	Training Prec@1 0.586 (0.189)	Training Prec@5 1.953 (0.574)	
2022-03-26 01:57:23,699: ============================================================
2022-03-26 01:59:17,046: time cost, forward:0.32585545110883446, backward:0.050059950158447185, data cost:0.7611529760502174 
2022-03-26 01:59:17,069: ============================================================
2022-03-26 01:59:17,069: Epoch 2/26 Batch 2900/7662 eta: 2 days, 11:24:35.304915	Training Loss 0.7982 (0.8113)	Training Prec@1 0.977 (0.203)	Training Prec@5 1.953 (0.610)	
2022-03-26 01:59:17,069: ============================================================
2022-03-26 02:01:11,204: time cost, forward:0.3273530566879176, backward:0.05000279728036278, data cost:0.7598154381856635 
2022-03-26 02:01:11,205: ============================================================
2022-03-26 02:01:11,206: Epoch 2/26 Batch 3000/7662 eta: 2 days, 11:46:46.095845	Training Loss 0.7972 (0.8109)	Training Prec@1 0.781 (0.217)	Training Prec@5 1.758 (0.649)	
2022-03-26 02:01:11,206: ============================================================
2022-03-26 02:03:04,744: time cost, forward:0.32844673991010975, backward:0.050014104332297644, data cost:0.7585685479329378 
2022-03-26 02:03:04,745: ============================================================
2022-03-26 02:03:04,745: Epoch 2/26 Batch 3100/7662 eta: 2 days, 11:26:06.764356	Training Loss 0.7979 (0.8105)	Training Prec@1 1.172 (0.231)	Training Prec@5 2.344 (0.689)	
2022-03-26 02:03:04,746: ============================================================
2022-03-26 02:04:59,164: time cost, forward:0.3293215918444067, backward:0.04984556179040669, data cost:0.7580825368029209 
2022-03-26 02:04:59,164: ============================================================
2022-03-26 02:04:59,165: Epoch 2/26 Batch 3200/7662 eta: 2 days, 11:51:49.630047	Training Loss 0.7977 (0.8101)	Training Prec@1 0.781 (0.248)	Training Prec@5 1.953 (0.732)	
2022-03-26 02:04:59,165: ============================================================
2022-03-26 02:06:54,222: time cost, forward:0.3296410078422775, backward:0.049673028482238826, data cost:0.7583725265243915 
2022-03-26 02:06:54,222: ============================================================
2022-03-26 02:06:54,223: Epoch 2/26 Batch 3300/7662 eta: 2 days, 12:09:57.912045	Training Loss 0.7956 (0.8096)	Training Prec@1 0.781 (0.265)	Training Prec@5 1.562 (0.777)	
2022-03-26 02:06:54,223: ============================================================
2022-03-26 02:08:46,399: time cost, forward:0.3302435636450242, backward:0.04968426591615601, data cost:0.7572510899709021 
2022-03-26 02:08:46,418: ============================================================
2022-03-26 02:08:46,418: Epoch 2/26 Batch 3400/7662 eta: 2 days, 10:38:17.376683	Training Loss 0.7958 (0.8092)	Training Prec@1 1.172 (0.285)	Training Prec@5 2.539 (0.823)	
2022-03-26 02:08:46,418: ============================================================
2022-03-26 02:10:41,941: time cost, forward:0.33106390099145233, backward:0.04979519940812644, data cost:0.7567998575939386 
2022-03-26 02:10:41,943: ============================================================
2022-03-26 02:10:41,944: Epoch 2/26 Batch 3500/7662 eta: 2 days, 12:20:46.401697	Training Loss 0.7941 (0.8088)	Training Prec@1 0.586 (0.308)	Training Prec@5 2.148 (0.879)	
2022-03-26 02:10:41,944: ============================================================
2022-03-26 02:12:33,187: time cost, forward:0.33102273629684853, backward:0.049738174546059714, data cost:0.7561880461074605 
2022-03-26 02:12:33,187: ============================================================
2022-03-26 02:12:33,188: Epoch 2/26 Batch 3600/7662 eta: 2 days, 10:04:44.009160	Training Loss 0.7902 (0.8084)	Training Prec@1 1.758 (0.328)	Training Prec@5 3.516 (0.931)	
2022-03-26 02:12:33,188: ============================================================
2022-03-26 02:14:27,214: time cost, forward:0.3317132151491032, backward:0.04960654632050658, data cost:0.755711434756978 
2022-03-26 02:14:27,225: ============================================================
2022-03-26 02:14:27,226: Epoch 2/26 Batch 3700/7662 eta: 2 days, 11:30:21.666004	Training Loss 0.7935 (0.8079)	Training Prec@1 1.172 (0.350)	Training Prec@5 2.539 (0.987)	
2022-03-26 02:14:27,226: ============================================================
2022-03-26 02:16:20,411: time cost, forward:0.33155242773569643, backward:0.049654443065063926, data cost:0.7556252195885947 
2022-03-26 02:16:20,412: ============================================================
2022-03-26 02:16:20,413: Epoch 2/26 Batch 3800/7662 eta: 2 days, 11:01:49.101333	Training Loss 0.7894 (0.8075)	Training Prec@1 0.977 (0.375)	Training Prec@5 2.930 (1.045)	
2022-03-26 02:16:20,413: ============================================================
2022-03-26 02:18:14,680: time cost, forward:0.33164414206233567, backward:0.04967989240373884, data cost:0.7555501761880402 
2022-03-26 02:18:14,681: ============================================================
2022-03-26 02:18:14,681: Epoch 2/26 Batch 3900/7662 eta: 2 days, 11:33:45.781328	Training Loss 0.7875 (0.8070)	Training Prec@1 1.367 (0.401)	Training Prec@5 3.711 (1.108)	
2022-03-26 02:18:14,681: ============================================================
2022-03-26 02:20:05,618: time cost, forward:0.33150301602042354, backward:0.04962927957092651, data cost:0.7551721170205539 
2022-03-26 02:20:05,619: ============================================================
2022-03-26 02:20:05,619: Epoch 2/26 Batch 4000/7662 eta: 2 days, 9:47:45.800956	Training Loss 0.7896 (0.8066)	Training Prec@1 1.953 (0.428)	Training Prec@5 3.906 (1.172)	
2022-03-26 02:20:05,619: ============================================================
2022-03-26 02:21:57,666: time cost, forward:0.33139723764742024, backward:0.04947333022948444, data cost:0.7550227428593558 
2022-03-26 02:21:57,667: ============================================================
2022-03-26 02:21:57,667: Epoch 2/26 Batch 4100/7662 eta: 2 days, 10:20:34.827171	Training Loss 0.7861 (0.8061)	Training Prec@1 1.172 (0.458)	Training Prec@5 5.078 (1.242)	
2022-03-26 02:21:57,667: ============================================================
2022-03-26 02:23:49,284: time cost, forward:0.33053136553245377, backward:0.04933803675997453, data cost:0.755423836152762 
2022-03-26 02:23:49,310: ============================================================
2022-03-26 02:23:49,311: Epoch 2/26 Batch 4200/7662 eta: 2 days, 10:06:05.666339	Training Loss 0.7844 (0.8056)	Training Prec@1 1.758 (0.489)	Training Prec@5 4.883 (1.317)	
2022-03-26 02:23:49,311: ============================================================
2022-03-26 02:25:41,608: time cost, forward:0.3298728104440743, backward:0.04920226730671448, data cost:0.756020681612379 
2022-03-26 02:25:41,609: ============================================================
2022-03-26 02:25:41,609: Epoch 2/26 Batch 4300/7662 eta: 2 days, 10:24:39.776395	Training Loss 0.7852 (0.8052)	Training Prec@1 1.172 (0.522)	Training Prec@5 3.711 (1.392)	
2022-03-26 02:25:41,609: ============================================================
2022-03-26 02:27:34,246: time cost, forward:0.32999533928370145, backward:0.049058553873882915, data cost:0.7558482536594281 
2022-03-26 02:27:34,247: ============================================================
2022-03-26 02:27:34,247: Epoch 2/26 Batch 4400/7662 eta: 2 days, 10:33:23.351778	Training Loss 0.7841 (0.8047)	Training Prec@1 2.344 (0.558)	Training Prec@5 5.078 (1.469)	
2022-03-26 02:27:34,247: ============================================================
2022-03-26 02:29:31,609: time cost, forward:0.3304310988574379, backward:0.04893297379640612, data cost:0.7562353383649533 
2022-03-26 02:29:31,610: ============================================================
2022-03-26 02:29:31,611: Epoch 2/26 Batch 4500/7662 eta: 2 days, 12:58:49.067679	Training Loss 0.7865 (0.8043)	Training Prec@1 2.344 (0.592)	Training Prec@5 4.492 (1.548)	
2022-03-26 02:29:31,611: ============================================================
2022-03-26 02:31:24,760: time cost, forward:0.33017745052220693, backward:0.048836973600476744, data cost:0.756642744732463 
2022-03-26 02:31:24,760: ============================================================
2022-03-26 02:31:24,760: Epoch 2/26 Batch 4600/7662 eta: 2 days, 10:45:35.373589	Training Loss 0.7839 (0.8038)	Training Prec@1 1.562 (0.634)	Training Prec@5 5.859 (1.637)	
2022-03-26 02:31:24,761: ============================================================
2022-03-26 02:33:16,997: time cost, forward:0.32963768307973434, backward:0.048792166769770925, data cost:0.7568854051185279 
2022-03-26 02:33:17,114: ============================================================
2022-03-26 02:33:17,115: Epoch 2/26 Batch 4700/7662 eta: 2 days, 10:18:55.012407	Training Loss 0.7771 (0.8033)	Training Prec@1 2.930 (0.672)	Training Prec@5 6.641 (1.722)	
2022-03-26 02:33:17,115: ============================================================
2022-03-26 02:35:09,397: time cost, forward:0.3292495229637208, backward:0.04870563175410473, data cost:0.7570223161443419 
2022-03-26 02:35:09,398: ============================================================
2022-03-26 02:35:09,399: Epoch 2/26 Batch 4800/7662 eta: 2 days, 10:14:50.662746	Training Loss 0.7794 (0.8028)	Training Prec@1 2.734 (0.716)	Training Prec@5 5.664 (1.816)	
2022-03-26 02:35:09,399: ============================================================
2022-03-26 02:37:01,693: time cost, forward:0.32849542976374724, backward:0.04860576358856681, data cost:0.75775850498085 
2022-03-26 02:37:01,693: ============================================================
2022-03-26 02:37:01,693: Epoch 2/26 Batch 4900/7662 eta: 2 days, 10:13:19.791769	Training Loss 0.7756 (0.8023)	Training Prec@1 4.883 (0.763)	Training Prec@5 8.398 (1.911)	
2022-03-26 02:37:01,693: ============================================================
2022-03-26 02:38:54,101: time cost, forward:0.32806423211674807, backward:0.048515731512391344, data cost:0.7579972647170731 
2022-03-26 02:38:54,101: ============================================================
2022-03-26 02:38:54,102: Epoch 2/26 Batch 5000/7662 eta: 2 days, 10:14:58.792467	Training Loss 0.7795 (0.8019)	Training Prec@1 3.320 (0.807)	Training Prec@5 6.055 (2.008)	
2022-03-26 02:38:54,102: ============================================================
2022-03-26 02:40:48,674: time cost, forward:0.32761485863255624, backward:0.04839521750535982, data cost:0.7588274044531377 
2022-03-26 02:40:48,675: ============================================================
2022-03-26 02:40:48,675: Epoch 2/26 Batch 5100/7662 eta: 2 days, 11:20:23.327421	Training Loss 0.7772 (0.8014)	Training Prec@1 3.125 (0.854)	Training Prec@5 6.641 (2.107)	
2022-03-26 02:40:48,675: ============================================================
2022-03-26 02:42:41,997: time cost, forward:0.3274486332724796, backward:0.048243598218926285, data cost:0.7590543530862774 
2022-03-26 02:42:41,997: ============================================================
2022-03-26 02:42:41,997: Epoch 2/26 Batch 5200/7662 eta: 2 days, 10:39:37.139227	Training Loss 0.7749 (0.8009)	Training Prec@1 3.320 (0.908)	Training Prec@5 6.055 (2.212)	
2022-03-26 02:42:41,998: ============================================================
2022-03-26 02:44:37,336: time cost, forward:0.32708248472996626, backward:0.0481486720484503, data cost:0.7599161481560345 
2022-03-26 02:44:37,337: ============================================================
2022-03-26 02:44:37,337: Epoch 2/26 Batch 5300/7662 eta: 2 days, 11:40:21.166550	Training Loss 0.7762 (0.8004)	Training Prec@1 4.492 (0.961)	Training Prec@5 7.227 (2.321)	
2022-03-26 02:44:37,337: ============================================================
2022-03-26 02:46:30,846: time cost, forward:0.3269416267594975, backward:0.04808346512892176, data cost:0.7600965448211003 
2022-03-26 02:46:30,846: ============================================================
2022-03-26 02:46:30,847: Epoch 2/26 Batch 5400/7662 eta: 2 days, 10:41:39.250917	Training Loss 0.7707 (0.7999)	Training Prec@1 3.711 (1.019)	Training Prec@5 7.617 (2.436)	
2022-03-26 02:46:30,847: ============================================================
2022-03-26 02:48:26,388: time cost, forward:0.32691706993684355, backward:0.047993506707154875, data cost:0.7605946540919233 
2022-03-26 02:48:26,389: ============================================================
2022-03-26 02:48:26,389: Epoch 2/26 Batch 5500/7662 eta: 2 days, 11:42:47.926142	Training Loss 0.7698 (0.7994)	Training Prec@1 5.078 (1.079)	Training Prec@5 11.914 (2.556)	
2022-03-26 02:48:26,389: ============================================================
2022-03-26 02:50:18,832: time cost, forward:0.326548402320915, backward:0.047861762591016405, data cost:0.7608709964268462 
2022-03-26 02:50:18,833: ============================================================
2022-03-26 02:50:18,833: Epoch 2/26 Batch 5600/7662 eta: 2 days, 10:04:51.286431	Training Loss 0.7667 (0.7988)	Training Prec@1 4.883 (1.140)	Training Prec@5 8.789 (2.675)	
2022-03-26 02:50:18,833: ============================================================
2022-03-26 02:52:11,196: time cost, forward:0.32623373794856875, backward:0.0477368970527254, data cost:0.7611131408294475 
2022-03-26 02:52:11,196: ============================================================
2022-03-26 02:52:11,196: Epoch 2/26 Batch 5700/7662 eta: 2 days, 10:00:27.551159	Training Loss 0.7671 (0.7983)	Training Prec@1 5.664 (1.206)	Training Prec@5 10.938 (2.802)	
2022-03-26 02:52:11,196: ============================================================
2022-03-26 02:54:03,490: time cost, forward:0.32601098595744354, backward:0.04764605181076174, data cost:0.7610785753937873 
2022-03-26 02:54:03,491: ============================================================
2022-03-26 02:54:03,492: Epoch 2/26 Batch 5800/7662 eta: 2 days, 9:56:29.585586	Training Loss 0.7659 (0.7978)	Training Prec@1 5.469 (1.275)	Training Prec@5 11.719 (2.934)	
2022-03-26 02:54:03,492: ============================================================
2022-03-26 02:55:54,361: time cost, forward:0.32554457563124467, backward:0.0475231973897362, data cost:0.7613385167035396 
2022-03-26 02:55:54,362: ============================================================
2022-03-26 02:55:54,363: Epoch 2/26 Batch 5900/7662 eta: 2 days, 9:10:32.833484	Training Loss 0.7700 (0.7973)	Training Prec@1 4.688 (1.349)	Training Prec@5 8.984 (3.069)	
2022-03-26 02:55:54,363: ============================================================
2022-03-26 02:57:46,520: time cost, forward:0.32493445324408926, backward:0.04744306010471858, data cost:0.7617357834356391 
2022-03-26 02:57:46,520: ============================================================
2022-03-26 02:57:46,520: Epoch 2/26 Batch 6000/7662 eta: 2 days, 9:48:29.968950	Training Loss 0.7612 (0.7968)	Training Prec@1 6.836 (1.422)	Training Prec@5 11.719 (3.207)	
2022-03-26 02:57:46,520: ============================================================
2022-03-26 02:59:40,804: time cost, forward:0.3243248810199738, backward:0.04741335892446668, data cost:0.7625032575194182 
2022-03-26 02:59:40,805: ============================================================
2022-03-26 02:59:40,806: Epoch 2/26 Batch 6100/7662 eta: 2 days, 10:52:23.096878	Training Loss 0.7633 (0.7962)	Training Prec@1 5.859 (1.500)	Training Prec@5 12.500 (3.349)	
2022-03-26 02:59:40,807: ============================================================
2022-03-26 03:01:33,341: time cost, forward:0.32367315944653785, backward:0.047360448534209065, data cost:0.763013214579627 
2022-03-26 03:01:33,342: ============================================================
2022-03-26 03:01:33,343: Epoch 2/26 Batch 6200/7662 eta: 2 days, 9:56:28.786194	Training Loss 0.7622 (0.7957)	Training Prec@1 5.859 (1.582)	Training Prec@5 11.328 (3.499)	
2022-03-26 03:01:33,343: ============================================================
2022-03-26 03:03:27,897: time cost, forward:0.3230828319131088, backward:0.047321264280896655, data cost:0.763961811598605 
2022-03-26 03:03:27,897: ============================================================
2022-03-26 03:03:27,898: Epoch 2/26 Batch 6300/7662 eta: 2 days, 10:56:54.220456	Training Loss 0.7633 (0.7951)	Training Prec@1 6.641 (1.665)	Training Prec@5 12.500 (3.646)	
2022-03-26 03:03:27,898: ============================================================
2022-03-26 03:05:18,673: time cost, forward:0.3225010361293644, backward:0.04721623194331321, data cost:0.7640696972827461 
2022-03-26 03:05:18,674: ============================================================
2022-03-26 03:05:18,674: Epoch 2/26 Batch 6400/7662 eta: 2 days, 8:58:23.342813	Training Loss 0.7607 (0.7946)	Training Prec@1 6.055 (1.749)	Training Prec@5 14.453 (3.801)	
2022-03-26 03:05:18,674: ============================================================
2022-03-26 03:07:11,039: time cost, forward:0.32206205537381916, backward:0.0471212640507879, data cost:0.764593698810038 
2022-03-26 03:07:11,040: ============================================================
2022-03-26 03:07:11,040: Epoch 2/26 Batch 6500/7662 eta: 2 days, 9:45:34.421103	Training Loss 0.7577 (0.7940)	Training Prec@1 9.570 (1.840)	Training Prec@5 16.406 (3.957)	
2022-03-26 03:07:11,040: ============================================================
2022-03-26 03:09:08,169: time cost, forward:0.32155614991064485, backward:0.04705920987534584, data cost:0.7657101280058057 
2022-03-26 03:09:08,170: ============================================================
2022-03-26 03:09:08,170: Epoch 2/26 Batch 6600/7662 eta: 2 days, 12:10:33.485294	Training Loss 0.7550 (0.7935)	Training Prec@1 8.789 (1.931)	Training Prec@5 16.797 (4.118)	
2022-03-26 03:09:08,170: ============================================================
2022-03-26 03:10:58,974: time cost, forward:0.32111398599667057, backward:0.04699688926528222, data cost:0.7657916907819995 
2022-03-26 03:10:58,975: ============================================================
2022-03-26 03:10:58,976: Epoch 2/26 Batch 6700/7662 eta: 2 days, 8:53:45.910465	Training Loss 0.7606 (0.7929)	Training Prec@1 6.836 (2.026)	Training Prec@5 15.820 (4.280)	
2022-03-26 03:10:58,976: ============================================================
2022-03-26 03:12:50,081: time cost, forward:0.320766219007108, backward:0.04689708473507421, data cost:0.765917814835185 
2022-03-26 03:12:50,082: ============================================================
2022-03-26 03:12:50,082: Epoch 2/26 Batch 6800/7662 eta: 2 days, 9:01:08.933242	Training Loss 0.7529 (0.7924)	Training Prec@1 8.203 (2.121)	Training Prec@5 14.648 (4.444)	
2022-03-26 03:12:50,082: ============================================================
2022-03-26 03:14:45,725: time cost, forward:0.3204082088688868, backward:0.04685118806968652, data cost:0.7665776217358754 
2022-03-26 03:14:45,726: ============================================================
2022-03-26 03:14:45,726: Epoch 2/26 Batch 6900/7662 eta: 2 days, 11:18:58.156053	Training Loss 0.7543 (0.7918)	Training Prec@1 8.594 (2.222)	Training Prec@5 14.648 (4.616)	
2022-03-26 03:14:45,726: ============================================================
2022-03-26 03:16:39,529: time cost, forward:0.3200366237126413, backward:0.04678469297630069, data cost:0.7671136659525993 
2022-03-26 03:16:39,530: ============================================================
2022-03-26 03:16:39,530: Epoch 2/26 Batch 7000/7662 eta: 2 days, 10:20:26.008453	Training Loss 0.7522 (0.7912)	Training Prec@1 9.570 (2.324)	Training Prec@5 17.969 (4.795)	
2022-03-26 03:16:39,530: ============================================================
2022-03-26 03:18:31,768: time cost, forward:0.3196657278249257, backward:0.04675745722239648, data cost:0.7672934092204492 
2022-03-26 03:18:31,770: ============================================================
2022-03-26 03:18:31,770: Epoch 2/26 Batch 7100/7662 eta: 2 days, 9:30:28.390824	Training Loss 0.7506 (0.7907)	Training Prec@1 10.742 (2.436)	Training Prec@5 19.141 (4.980)	
2022-03-26 03:18:31,771: ============================================================
2022-03-26 03:20:28,023: time cost, forward:0.31942498622660603, backward:0.04668745843548463, data cost:0.7680168700294373 
2022-03-26 03:20:28,024: ============================================================
2022-03-26 03:20:28,024: Epoch 2/26 Batch 7200/7662 eta: 2 days, 11:31:55.026419	Training Loss 0.7480 (0.7901)	Training Prec@1 12.109 (2.547)	Training Prec@5 21.094 (5.168)	
2022-03-26 03:20:28,024: ============================================================
2022-03-26 03:22:18,178: time cost, forward:0.31907313666060816, backward:0.046653308057020684, data cost:0.7680039398309907 
2022-03-26 03:22:18,178: ============================================================
2022-03-26 03:22:18,179: Epoch 2/26 Batch 7300/7662 eta: 2 days, 8:22:40.994482	Training Loss 0.7460 (0.7895)	Training Prec@1 12.695 (2.664)	Training Prec@5 20.508 (5.360)	
2022-03-26 03:22:18,179: ============================================================
2022-03-26 03:24:12,544: time cost, forward:0.3188161762973266, backward:0.0466278531548461, data cost:0.7684074151611019 
2022-03-26 03:24:12,545: ============================================================
2022-03-26 03:24:12,545: Epoch 2/26 Batch 7400/7662 eta: 2 days, 10:30:07.112065	Training Loss 0.7438 (0.7889)	Training Prec@1 13.281 (2.784)	Training Prec@5 21.680 (5.558)	
2022-03-26 03:24:12,545: ============================================================
2022-03-26 03:26:05,764: time cost, forward:0.31842958683935163, backward:0.04658263730182538, data cost:0.7688165198073162 
2022-03-26 03:26:05,765: ============================================================
2022-03-26 03:26:05,766: Epoch 2/26 Batch 7500/7662 eta: 2 days, 9:53:03.724412	Training Loss 0.7421 (0.7883)	Training Prec@1 12.109 (2.903)	Training Prec@5 22.070 (5.751)	
2022-03-26 03:26:05,766: ============================================================
2022-03-26 03:28:01,831: time cost, forward:0.31812199374094874, backward:0.04654818501091581, data cost:0.7693984239944456 
2022-03-26 03:28:01,831: ============================================================
2022-03-26 03:28:01,832: Epoch 2/26 Batch 7600/7662 eta: 2 days, 11:18:24.413693	Training Loss 0.7406 (0.7877)	Training Prec@1 12.305 (3.028)	Training Prec@5 20.312 (5.949)	
2022-03-26 03:28:01,832: ============================================================
2022-03-26 03:29:14,297: Epoch: 2/26 eta: 2 days, 11:17:11.292165	Training Loss 0.7424 (0.7873)	Training Prec@1 11.133 (3.108)	Training Prec@5 19.727 (6.075)
2022-03-26 03:29:14,298: ============================================================
2022-03-26 03:31:12,594: time cost, forward:0.33669121819313125, backward:0.05439279777835114, data cost:0.7953298332715275 
2022-03-26 03:31:12,595: ============================================================
2022-03-26 03:31:12,595: Epoch 3/26 Batch 100/7662 eta: 2 days, 12:19:28.588055	Training Loss 0.7330 (0.7337)	Training Prec@1 16.211 (15.357)	Training Prec@5 25.000 (24.923)	
2022-03-26 03:31:12,595: ============================================================
2022-03-26 03:33:03,429: time cost, forward:0.312669038772583, backward:0.047664820848397876, data cost:0.7855212700426878 
2022-03-26 03:33:03,429: ============================================================
2022-03-26 03:33:03,430: Epoch 3/26 Batch 200/7662 eta: 2 days, 8:33:11.521033	Training Loss 0.7361 (0.7329)	Training Prec@1 15.039 (15.482)	Training Prec@5 22.656 (25.260)	
2022-03-26 03:33:03,430: ============================================================
2022-03-26 03:34:57,008: time cost, forward:0.3024433783464209, backward:0.046075708491347706, data cost:0.7948949711777294 
2022-03-26 03:34:57,010: ============================================================
2022-03-26 03:34:57,010: Epoch 3/26 Batch 300/7662 eta: 2 days, 9:55:20.965151	Training Loss 0.7299 (0.7324)	Training Prec@1 17.773 (15.631)	Training Prec@5 27.344 (25.528)	
2022-03-26 03:34:57,010: ============================================================
2022-03-26 03:36:50,075: time cost, forward:0.2964631513246618, backward:0.045383369713498836, data cost:0.7982044721904554 
2022-03-26 03:36:50,076: ============================================================
2022-03-26 03:36:50,076: Epoch 3/26 Batch 400/7662 eta: 2 days, 9:37:43.188431	Training Loss 0.7305 (0.7318)	Training Prec@1 16.016 (15.868)	Training Prec@5 27.344 (25.780)	
2022-03-26 03:36:50,076: ============================================================
2022-03-26 03:38:41,982: time cost, forward:0.291251153410795, backward:0.04468040905877918, data cost:0.7999782614813061 
2022-03-26 03:38:41,982: ============================================================
2022-03-26 03:38:41,983: Epoch 3/26 Batch 500/7662 eta: 2 days, 9:00:24.748393	Training Loss 0.7255 (0.7311)	Training Prec@1 18.945 (16.082)	Training Prec@5 29.883 (26.105)	
2022-03-26 03:38:41,983: ============================================================
2022-03-26 03:40:31,676: time cost, forward:0.2881835649327961, backward:0.04478533558535058, data cost:0.7963695908229618 
2022-03-26 03:40:31,677: ============================================================
2022-03-26 03:40:31,677: Epoch 3/26 Batch 600/7662 eta: 2 days, 7:50:57.873390	Training Loss 0.7252 (0.7304)	Training Prec@1 17.578 (16.349)	Training Prec@5 26.758 (26.439)	
2022-03-26 03:40:31,677: ============================================================
2022-03-26 03:42:24,704: time cost, forward:0.2886206851326174, backward:0.04453419138263053, data cost:0.7951848483051523 
2022-03-26 03:42:24,705: ============================================================
2022-03-26 03:42:24,705: Epoch 3/26 Batch 700/7662 eta: 2 days, 9:30:55.133049	Training Loss 0.7240 (0.7296)	Training Prec@1 18.945 (16.631)	Training Prec@5 30.664 (26.780)	
2022-03-26 03:42:24,706: ============================================================
2022-03-26 03:44:19,454: time cost, forward:0.2877551202332421, backward:0.044230212258158694, data cost:0.7996118432738456 
2022-03-26 03:44:19,454: ============================================================
2022-03-26 03:44:19,455: Epoch 3/26 Batch 800/7662 eta: 2 days, 10:21:33.841331	Training Loss 0.7168 (0.7289)	Training Prec@1 22.461 (16.923)	Training Prec@5 34.375 (27.099)	
2022-03-26 03:44:19,455: ============================================================
2022-03-26 03:46:09,893: time cost, forward:0.2876601155528237, backward:0.04400292201355116, data cost:0.7965751365241538 
2022-03-26 03:46:09,894: ============================================================
2022-03-26 03:46:09,894: Epoch 3/26 Batch 900/7662 eta: 2 days, 8:08:11.324909	Training Loss 0.7203 (0.7281)	Training Prec@1 20.312 (17.189)	Training Prec@5 32.031 (27.423)	
2022-03-26 03:46:09,894: ============================================================
2022-03-26 03:47:59,559: time cost, forward:0.28749732737307315, backward:0.04403983102785097, data cost:0.7936018255499151 
2022-03-26 03:47:59,560: ============================================================
2022-03-26 03:47:59,560: Epoch 3/26 Batch 1000/7662 eta: 2 days, 7:42:47.957068	Training Loss 0.7178 (0.7274)	Training Prec@1 20.898 (17.474)	Training Prec@5 31.641 (27.749)	
2022-03-26 03:47:59,561: ============================================================
2022-03-26 03:49:52,671: time cost, forward:0.2865998024719211, backward:0.043982357193493, data cost:0.7948635429333729 
2022-03-26 03:49:52,673: ============================================================
2022-03-26 03:49:52,673: Epoch 3/26 Batch 1100/7662 eta: 2 days, 9:25:57.461175	Training Loss 0.7196 (0.7267)	Training Prec@1 18.359 (17.708)	Training Prec@5 31.836 (28.054)	
2022-03-26 03:49:52,673: ============================================================
2022-03-26 03:51:44,574: time cost, forward:0.2857610568888889, backward:0.0438818647227156, data cost:0.7950539736075636 
2022-03-26 03:51:44,575: ============================================================
2022-03-26 03:51:44,575: Epoch 3/26 Batch 1200/7662 eta: 2 days, 8:47:13.265369	Training Loss 0.7207 (0.7259)	Training Prec@1 19.922 (18.005)	Training Prec@5 30.078 (28.411)	
2022-03-26 03:51:44,576: ============================================================
2022-03-26 03:53:34,802: time cost, forward:0.2853258977586072, backward:0.04369989682198305, data cost:0.7942445837965004 
2022-03-26 03:53:34,803: ============================================================
2022-03-26 03:53:34,804: Epoch 3/26 Batch 1300/7662 eta: 2 days, 7:54:24.972876	Training Loss 0.7136 (0.7251)	Training Prec@1 23.047 (18.294)	Training Prec@5 33.984 (28.723)	
2022-03-26 03:53:34,804: ============================================================
2022-03-26 03:55:27,426: time cost, forward:0.28463129046305835, backward:0.04376740196587956, data cost:0.7951399461979352 
2022-03-26 03:55:27,426: ============================================================
2022-03-26 03:55:27,426: Epoch 3/26 Batch 1400/7662 eta: 2 days, 9:05:23.742664	Training Loss 0.7101 (0.7244)	Training Prec@1 24.414 (18.564)	Training Prec@5 34.766 (29.059)	
2022-03-26 03:55:27,426: ============================================================
2022-03-26 03:57:18,992: time cost, forward:0.28424583521582747, backward:0.04369759973165908, data cost:0.7944074214657917 
2022-03-26 03:57:18,993: ============================================================
2022-03-26 03:57:18,993: Epoch 3/26 Batch 1500/7662 eta: 2 days, 8:31:25.591939	Training Loss 0.7121 (0.7236)	Training Prec@1 22.852 (18.850)	Training Prec@5 32.617 (29.393)	
2022-03-26 03:57:18,993: ============================================================
2022-03-26 03:59:11,354: time cost, forward:0.28394179436622224, backward:0.04367672987026002, data cost:0.7952224010970907 
2022-03-26 03:59:11,355: ============================================================
2022-03-26 03:59:11,355: Epoch 3/26 Batch 1600/7662 eta: 2 days, 8:53:42.989431	Training Loss 0.7158 (0.7228)	Training Prec@1 22.266 (19.142)	Training Prec@5 30.859 (29.722)	
2022-03-26 03:59:11,355: ============================================================
2022-03-26 04:01:05,589: time cost, forward:0.28325115069703116, backward:0.04373471873026865, data cost:0.7970811969887305 
2022-03-26 04:01:05,589: ============================================================
2022-03-26 04:01:05,590: Epoch 3/26 Batch 1700/7662 eta: 2 days, 9:48:43.128755	Training Loss 0.7142 (0.7220)	Training Prec@1 22.656 (19.422)	Training Prec@5 34.375 (30.046)	
2022-03-26 04:01:05,590: ============================================================
2022-03-26 04:02:56,774: time cost, forward:0.28313738230270036, backward:0.043667568240714376, data cost:0.7962842977596959 
2022-03-26 04:02:56,776: ============================================================
2022-03-26 04:02:56,777: Epoch 3/26 Batch 1800/7662 eta: 2 days, 8:14:19.321242	Training Loss 0.7042 (0.7212)	Training Prec@1 26.172 (19.697)	Training Prec@5 36.328 (30.371)	
2022-03-26 04:02:56,777: ============================================================
2022-03-26 04:04:49,574: time cost, forward:0.2837648340248321, backward:0.043592225381611144, data cost:0.7962299881011577 
2022-03-26 04:04:49,575: ============================================================
2022-03-26 04:04:49,576: Epoch 3/26 Batch 1900/7662 eta: 2 days, 9:01:21.467994	Training Loss 0.6964 (0.7204)	Training Prec@1 28.711 (19.972)	Training Prec@5 40.430 (30.688)	
2022-03-26 04:04:49,576: ============================================================
2022-03-26 04:06:40,267: time cost, forward:0.28368781434708445, backward:0.043615854639241315, data cost:0.7952972844339956 
2022-03-26 04:06:40,268: ============================================================
2022-03-26 04:06:40,268: Epoch 3/26 Batch 2000/7662 eta: 2 days, 7:55:37.049177	Training Loss 0.7063 (0.7196)	Training Prec@1 24.023 (20.265)	Training Prec@5 35.547 (31.006)	
2022-03-26 04:06:40,268: ============================================================
2022-03-26 04:08:29,713: time cost, forward:0.2830945197146753, backward:0.0435512578163674, data cost:0.7945542277581014 
2022-03-26 04:08:29,714: ============================================================
2022-03-26 04:08:29,715: Epoch 3/26 Batch 2100/7662 eta: 2 days, 7:16:01.948082	Training Loss 0.7000 (0.7188)	Training Prec@1 26.758 (20.559)	Training Prec@5 38.867 (31.337)	
2022-03-26 04:08:29,715: ============================================================
2022-03-26 04:10:20,582: time cost, forward:0.2827673047279542, backward:0.04364445796062752, data cost:0.7941297538283739 
2022-03-26 04:10:20,584: ============================================================
2022-03-26 04:10:20,584: Epoch 3/26 Batch 2200/7662 eta: 2 days, 7:57:18.099833	Training Loss 0.6908 (0.7179)	Training Prec@1 30.469 (20.866)	Training Prec@5 41.602 (31.668)	
2022-03-26 04:10:20,585: ============================================================
2022-03-26 04:12:14,591: time cost, forward:0.28330378057439204, backward:0.043655723216690256, data cost:0.7945907680093335 
2022-03-26 04:12:14,591: ============================================================
2022-03-26 04:12:14,592: Epoch 3/26 Batch 2300/7662 eta: 2 days, 9:30:25.193350	Training Loss 0.6973 (0.7170)	Training Prec@1 28.125 (21.164)	Training Prec@5 39.453 (32.007)	
2022-03-26 04:12:14,592: ============================================================
2022-03-26 04:14:06,007: time cost, forward:0.28346437710232913, backward:0.043601764446002535, data cost:0.7941663992708055 
2022-03-26 04:14:06,008: ============================================================
2022-03-26 04:14:06,008: Epoch 3/26 Batch 2400/7662 eta: 2 days, 8:10:08.203762	Training Loss 0.6919 (0.7162)	Training Prec@1 29.883 (21.468)	Training Prec@5 43.164 (32.347)	
2022-03-26 04:14:06,008: ============================================================
2022-03-26 04:15:58,011: time cost, forward:0.28343398049145807, backward:0.043644494655467166, data cost:0.7939208034707719 
2022-03-26 04:15:58,011: ============================================================
2022-03-26 04:15:58,011: Epoch 3/26 Batch 2500/7662 eta: 2 days, 8:26:01.656667	Training Loss 0.6925 (0.7153)	Training Prec@1 29.883 (21.759)	Training Prec@5 41.602 (32.673)	
2022-03-26 04:15:58,011: ============================================================
2022-03-26 04:17:52,601: time cost, forward:0.28377792494899723, backward:0.04362133862009962, data cost:0.7947184152445366 
2022-03-26 04:17:52,602: ============================================================
2022-03-26 04:17:52,602: Epoch 3/26 Batch 2600/7662 eta: 2 days, 9:42:20.183115	Training Loss 0.6956 (0.7145)	Training Prec@1 27.930 (22.059)	Training Prec@5 37.891 (33.014)	
2022-03-26 04:17:52,602: ============================================================
2022-03-26 04:19:43,266: time cost, forward:0.2838404874706233, backward:0.04350575149920571, data cost:0.7941782481584694 
2022-03-26 04:19:43,266: ============================================================
2022-03-26 04:19:43,266: Epoch 3/26 Batch 2700/7662 eta: 2 days, 7:41:51.563951	Training Loss 0.6944 (0.7136)	Training Prec@1 27.539 (22.362)	Training Prec@5 37.305 (33.350)	
2022-03-26 04:19:43,266: ============================================================
2022-03-26 04:21:32,787: time cost, forward:0.2834512338164705, backward:0.04348827498689129, data cost:0.7936145110230822 
2022-03-26 04:21:32,788: ============================================================
2022-03-26 04:21:32,788: Epoch 3/26 Batch 2800/7662 eta: 2 days, 7:05:32.179006	Training Loss 0.6874 (0.7128)	Training Prec@1 33.984 (22.671)	Training Prec@5 44.531 (33.685)	
2022-03-26 04:21:32,788: ============================================================
2022-03-26 04:23:25,268: time cost, forward:0.28330881441819666, backward:0.043494963242950914, data cost:0.7936922236531716 
2022-03-26 04:23:25,269: ============================================================
2022-03-26 04:23:25,269: Epoch 3/26 Batch 2900/7662 eta: 2 days, 8:32:58.697848	Training Loss 0.6841 (0.7119)	Training Prec@1 31.641 (22.967)	Training Prec@5 44.336 (34.011)	
2022-03-26 04:23:25,270: ============================================================
2022-03-26 04:25:17,570: time cost, forward:0.2828194971043255, backward:0.043517287710023826, data cost:0.794402672792125 
2022-03-26 04:25:17,571: ============================================================
2022-03-26 04:25:17,572: Epoch 3/26 Batch 3000/7662 eta: 2 days, 8:25:42.054136	Training Loss 0.6769 (0.7111)	Training Prec@1 33.594 (23.273)	Training Prec@5 47.461 (34.350)	
2022-03-26 04:25:17,573: ============================================================
2022-03-26 04:27:10,027: time cost, forward:0.2826916337513316, backward:0.043437097333407705, data cost:0.7946388322947755 
2022-03-26 04:27:10,028: ============================================================
2022-03-26 04:27:10,028: Epoch 3/26 Batch 3100/7662 eta: 2 days, 8:28:29.172830	Training Loss 0.6835 (0.7102)	Training Prec@1 34.180 (23.583)	Training Prec@5 44.531 (34.693)	
2022-03-26 04:27:10,028: ============================================================
2022-03-26 04:29:00,865: time cost, forward:0.28251519714455636, backward:0.04336402713600342, data cost:0.7944112330833499 
2022-03-26 04:29:00,866: ============================================================
2022-03-26 04:29:00,867: Epoch 3/26 Batch 3200/7662 eta: 2 days, 7:37:53.004447	Training Loss 0.6756 (0.7093)	Training Prec@1 34.961 (23.892)	Training Prec@5 45.703 (35.027)	
2022-03-26 04:29:00,867: ============================================================
2022-03-26 04:30:49,971: time cost, forward:0.28221236521202564, backward:0.04331432960003786, data cost:0.7939504178663788 
2022-03-26 04:30:49,972: ============================================================
2022-03-26 04:30:49,973: Epoch 3/26 Batch 3300/7662 eta: 2 days, 6:43:53.157825	Training Loss 0.6766 (0.7084)	Training Prec@1 35.156 (24.196)	Training Prec@5 47.656 (35.349)	
2022-03-26 04:30:49,973: ============================================================
2022-03-26 04:32:39,754: time cost, forward:0.2817694588105936, backward:0.043323323178831426, data cost:0.7938231112291336 
2022-03-26 04:32:39,754: ============================================================
2022-03-26 04:32:39,755: Epoch 3/26 Batch 3400/7662 eta: 2 days, 7:02:24.888514	Training Loss 0.6781 (0.7075)	Training Prec@1 33.008 (24.499)	Training Prec@5 46.094 (35.677)	
2022-03-26 04:32:39,755: ============================================================
2022-03-26 04:34:29,393: time cost, forward:0.28118632888412365, backward:0.043287560543900865, data cost:0.7937827493232058 
2022-03-26 04:34:29,393: ============================================================
2022-03-26 04:34:29,394: Epoch 3/26 Batch 3500/7662 eta: 2 days, 6:56:16.602272	Training Loss 0.6753 (0.7067)	Training Prec@1 36.328 (24.796)	Training Prec@5 46.875 (35.986)	
2022-03-26 04:34:29,394: ============================================================
2022-03-26 04:36:22,027: time cost, forward:0.2810460037905562, backward:0.04325284445143369, data cost:0.7941131294353302 
2022-03-26 04:36:22,028: ============================================================
2022-03-26 04:36:22,028: Epoch 3/26 Batch 3600/7662 eta: 2 days, 8:24:27.403990	Training Loss 0.6832 (0.7058)	Training Prec@1 34.570 (25.095)	Training Prec@5 45.117 (36.311)	
2022-03-26 04:36:22,028: ============================================================
2022-03-26 04:38:11,455: time cost, forward:0.28107533489700653, backward:0.04321950092351769, data cost:0.7934287149991883 
2022-03-26 04:38:11,456: ============================================================
2022-03-26 04:38:11,457: Epoch 3/26 Batch 3700/7662 eta: 2 days, 6:46:18.002470	Training Loss 0.6733 (0.7050)	Training Prec@1 36.133 (25.401)	Training Prec@5 48.242 (36.639)	
2022-03-26 04:38:11,457: ============================================================
2022-03-26 04:40:02,065: time cost, forward:0.28098245337311295, backward:0.043222486486432427, data cost:0.793261607467077 
2022-03-26 04:40:02,066: ============================================================
2022-03-26 04:40:02,066: Epoch 3/26 Batch 3800/7662 eta: 2 days, 7:19:55.339241	Training Loss 0.6761 (0.7041)	Training Prec@1 33.984 (25.704)	Training Prec@5 46.875 (36.966)	
2022-03-26 04:40:02,066: ============================================================
2022-03-26 04:41:54,933: time cost, forward:0.2809959788541361, backward:0.04325691826314797, data cost:0.7934909443514077 
2022-03-26 04:41:54,933: ============================================================
2022-03-26 04:41:54,933: Epoch 3/26 Batch 3900/7662 eta: 2 days, 8:25:48.864982	Training Loss 0.6690 (0.7032)	Training Prec@1 36.133 (26.005)	Training Prec@5 49.023 (37.281)	
2022-03-26 04:41:54,933: ============================================================
2022-03-26 04:43:48,887: time cost, forward:0.28118901748781233, backward:0.04325611736214617, data cost:0.7936473400123598 
2022-03-26 04:43:48,889: ============================================================
2022-03-26 04:43:48,889: Epoch 3/26 Batch 4000/7662 eta: 2 days, 8:56:33.751875	Training Loss 0.6744 (0.7023)	Training Prec@1 35.156 (26.301)	Training Prec@5 48.047 (37.599)	
2022-03-26 04:43:48,889: ============================================================
2022-03-26 04:45:40,636: time cost, forward:0.2812969458338748, backward:0.04324505159871757, data cost:0.7936549665404983 
2022-03-26 04:45:40,636: ============================================================
2022-03-26 04:45:40,637: Epoch 3/26 Batch 4100/7662 eta: 2 days, 7:48:29.869558	Training Loss 0.6490 (0.7014)	Training Prec@1 41.602 (26.613)	Training Prec@5 55.664 (37.926)	
2022-03-26 04:45:40,637: ============================================================
2022-03-26 04:47:31,624: time cost, forward:0.28142962015137896, backward:0.04325174876524454, data cost:0.7933459227980532 
2022-03-26 04:47:31,624: ============================================================
2022-03-26 04:47:31,625: Epoch 3/26 Batch 4200/7662 eta: 2 days, 7:23:53.310710	Training Loss 0.6651 (0.7005)	Training Prec@1 37.695 (26.921)	Training Prec@5 50.391 (38.248)	
2022-03-26 04:47:31,625: ============================================================
2022-03-26 04:49:24,061: time cost, forward:0.2816505570776603, backward:0.043299399023417624, data cost:0.793109094688964 
2022-03-26 04:49:24,062: ============================================================
2022-03-26 04:49:24,063: Epoch 3/26 Batch 4300/7662 eta: 2 days, 8:05:26.319147	Training Loss 0.6583 (0.6996)	Training Prec@1 42.383 (27.234)	Training Prec@5 51.953 (38.572)	
2022-03-26 04:49:24,063: ============================================================
2022-03-26 04:51:16,977: time cost, forward:0.2818029414634592, backward:0.04332702543063986, data cost:0.7932976349615786 
2022-03-26 04:51:16,977: ============================================================
2022-03-26 04:51:16,978: Epoch 3/26 Batch 4400/7662 eta: 2 days, 8:17:49.768489	Training Loss 0.6600 (0.6987)	Training Prec@1 41.211 (27.546)	Training Prec@5 54.492 (38.893)	
2022-03-26 04:51:16,978: ============================================================
2022-03-26 04:53:08,746: time cost, forward:0.28198826336865956, backward:0.04334270596424721, data cost:0.7929753240783312 
2022-03-26 04:53:08,747: ============================================================
2022-03-26 04:53:08,748: Epoch 3/26 Batch 4500/7662 eta: 2 days, 7:41:43.182353	Training Loss 0.6511 (0.6978)	Training Prec@1 41.016 (27.845)	Training Prec@5 55.078 (39.208)	
2022-03-26 04:53:08,748: ============================================================
2022-03-26 04:55:00,598: time cost, forward:0.28214041874133444, backward:0.04335586048515239, data cost:0.7928152591877851 
2022-03-26 04:55:00,599: ============================================================
2022-03-26 04:55:00,599: Epoch 3/26 Batch 4600/7662 eta: 2 days, 7:42:17.543616	Training Loss 0.6528 (0.6969)	Training Prec@1 44.922 (28.149)	Training Prec@5 56.055 (39.522)	
2022-03-26 04:55:00,600: ============================================================
2022-03-26 04:56:50,952: time cost, forward:0.2820496947797315, backward:0.043366337411072334, data cost:0.792636245736469 
2022-03-26 04:56:50,954: ============================================================
2022-03-26 04:56:50,954: Epoch 3/26 Batch 4700/7662 eta: 2 days, 6:55:43.874448	Training Loss 0.6489 (0.6959)	Training Prec@1 45.703 (28.451)	Training Prec@5 58.203 (39.830)	
2022-03-26 04:56:50,954: ============================================================
2022-03-26 04:58:43,209: time cost, forward:0.28230765904702604, backward:0.04336728054077632, data cost:0.7923974787649897 
2022-03-26 04:58:43,210: ============================================================
2022-03-26 04:58:43,210: Epoch 3/26 Batch 4800/7662 eta: 2 days, 7:50:37.572344	Training Loss 0.6564 (0.6950)	Training Prec@1 41.797 (28.755)	Training Prec@5 53.320 (40.141)	
2022-03-26 04:58:43,210: ============================================================
2022-03-26 05:00:33,382: time cost, forward:0.2824166631377408, backward:0.0433773929232309, data cost:0.7919964206829487 
2022-03-26 05:00:33,383: ============================================================
2022-03-26 05:00:33,383: Epoch 3/26 Batch 4900/7662 eta: 2 days, 6:46:37.882723	Training Loss 0.6417 (0.6941)	Training Prec@1 46.094 (29.059)	Training Prec@5 56.250 (40.451)	
2022-03-26 05:00:33,383: ============================================================
2022-03-26 05:02:25,839: time cost, forward:0.2825434280886939, backward:0.043415976228845625, data cost:0.7919497571484664 
2022-03-26 05:02:25,840: ============================================================
2022-03-26 05:02:25,840: Epoch 3/26 Batch 5000/7662 eta: 2 days, 7:52:53.190392	Training Loss 0.6411 (0.6932)	Training Prec@1 47.852 (29.362)	Training Prec@5 60.742 (40.758)	
2022-03-26 05:02:25,840: ============================================================
2022-03-26 05:04:19,012: time cost, forward:0.28264016987272605, backward:0.043458441702331554, data cost:0.7919370158323238 
2022-03-26 05:04:19,013: ============================================================
2022-03-26 05:04:19,014: Epoch 3/26 Batch 5100/7662 eta: 2 days, 8:12:21.338069	Training Loss 0.6414 (0.6923)	Training Prec@1 44.531 (29.667)	Training Prec@5 55.664 (41.065)	
2022-03-26 05:04:19,014: ============================================================
2022-03-26 05:06:10,541: time cost, forward:0.2827857642660785, backward:0.04345768753164753, data cost:0.7918842335026134 
2022-03-26 05:06:10,543: ============================================================
2022-03-26 05:06:10,544: Epoch 3/26 Batch 5200/7662 eta: 2 days, 7:21:32.581659	Training Loss 0.6523 (0.6914)	Training Prec@1 44.531 (29.978)	Training Prec@5 54.102 (41.380)	
2022-03-26 05:06:10,545: ============================================================
2022-03-26 05:08:01,916: time cost, forward:0.2826807672605354, backward:0.0434810359830293, data cost:0.7917572935924685 
2022-03-26 05:08:01,917: ============================================================
2022-03-26 05:08:01,917: Epoch 3/26 Batch 5300/7662 eta: 2 days, 7:15:00.408797	Training Loss 0.6426 (0.6905)	Training Prec@1 47.266 (30.281)	Training Prec@5 58.789 (41.686)	
2022-03-26 05:08:01,917: ============================================================
2022-03-26 05:09:52,355: time cost, forward:0.2826692225602318, backward:0.043461183725319256, data cost:0.7916396511199408 
2022-03-26 05:09:52,355: ============================================================
2022-03-26 05:09:52,355: Epoch 3/26 Batch 5400/7662 eta: 2 days, 6:45:20.498388	Training Loss 0.6345 (0.6896)	Training Prec@1 50.781 (30.580)	Training Prec@5 60.352 (41.987)	
2022-03-26 05:09:52,356: ============================================================
2022-03-26 05:11:43,990: time cost, forward:0.28281479541725146, backward:0.04348688057106741, data cost:0.7913473336604275 
2022-03-26 05:11:43,991: ============================================================
2022-03-26 05:11:43,991: Epoch 3/26 Batch 5500/7662 eta: 2 days, 7:19:05.437978	Training Loss 0.6466 (0.6886)	Training Prec@1 43.164 (30.873)	Training Prec@5 54.492 (42.281)	
2022-03-26 05:11:43,991: ============================================================
2022-03-26 05:13:39,455: time cost, forward:0.2830545242225768, backward:0.04352767664655061, data cost:0.791767936111412 
2022-03-26 05:13:39,455: ============================================================
2022-03-26 05:13:39,455: Epoch 3/26 Batch 5600/7662 eta: 2 days, 9:11:00.024958	Training Loss 0.6315 (0.6877)	Training Prec@1 49.414 (31.172)	Training Prec@5 61.719 (42.584)	
2022-03-26 05:13:39,455: ============================================================
2022-03-26 05:15:31,150: time cost, forward:0.28345600992655584, backward:0.043611134326464254, data cost:0.7912496620990829 
2022-03-26 05:15:31,151: ============================================================
2022-03-26 05:15:31,152: Epoch 3/26 Batch 5700/7662 eta: 2 days, 7:17:10.961464	Training Loss 0.6366 (0.6868)	Training Prec@1 47.070 (31.477)	Training Prec@5 59.766 (42.891)	
2022-03-26 05:15:31,152: ============================================================
2022-03-26 05:17:22,566: time cost, forward:0.28353522670414966, backward:0.043641413999315086, data cost:0.7911015103286372 
2022-03-26 05:17:22,569: ============================================================
2022-03-26 05:17:22,570: Epoch 3/26 Batch 5800/7662 eta: 2 days, 7:07:02.019061	Training Loss 0.6356 (0.6859)	Training Prec@1 45.703 (31.775)	Training Prec@5 59.766 (43.190)	
2022-03-26 05:17:22,570: ============================================================
2022-03-26 05:19:15,490: time cost, forward:0.2835282465829185, backward:0.04362678649082368, data cost:0.791290586005633 
2022-03-26 05:19:15,491: ============================================================
2022-03-26 05:19:15,491: Epoch 3/26 Batch 5900/7662 eta: 2 days, 7:49:48.118045	Training Loss 0.6222 (0.6850)	Training Prec@1 53.711 (32.075)	Training Prec@5 63.867 (43.485)	
2022-03-26 05:19:15,491: ============================================================
2022-03-26 05:21:06,424: time cost, forward:0.2836609069536797, backward:0.04359285289753594, data cost:0.7910450674490365 
2022-03-26 05:21:06,425: ============================================================
2022-03-26 05:21:06,425: Epoch 3/26 Batch 6000/7662 eta: 2 days, 6:49:00.061880	Training Loss 0.6286 (0.6840)	Training Prec@1 52.148 (32.382)	Training Prec@5 64.258 (43.787)	
2022-03-26 05:21:06,425: ============================================================
2022-03-26 05:22:56,734: time cost, forward:0.2836811748913691, backward:0.04359988342212603, data cost:0.7906174047948259 
2022-03-26 05:22:56,735: ============================================================
2022-03-26 05:22:56,737: Epoch 3/26 Batch 6100/7662 eta: 2 days, 6:28:40.973614	Training Loss 0.6240 (0.6831)	Training Prec@1 52.148 (32.679)	Training Prec@5 61.133 (44.077)	
2022-03-26 05:22:56,737: ============================================================
2022-03-26 05:24:47,770: time cost, forward:0.283661183435545, backward:0.043623437033793414, data cost:0.7905367270729814 
2022-03-26 05:24:47,771: ============================================================
2022-03-26 05:24:47,772: Epoch 3/26 Batch 6200/7662 eta: 2 days, 6:48:17.115598	Training Loss 0.6338 (0.6822)	Training Prec@1 47.266 (32.975)	Training Prec@5 59.570 (44.368)	
2022-03-26 05:24:47,772: ============================================================
2022-03-26 05:26:41,395: time cost, forward:0.2837110301921776, backward:0.043645068224809874, data cost:0.7908394493778881 
2022-03-26 05:26:41,396: ============================================================
2022-03-26 05:26:41,396: Epoch 3/26 Batch 6300/7662 eta: 2 days, 8:03:05.430965	Training Loss 0.6193 (0.6813)	Training Prec@1 55.273 (33.271)	Training Prec@5 65.039 (44.660)	
2022-03-26 05:26:41,397: ============================================================
2022-03-26 05:28:29,609: time cost, forward:0.2837623668696884, backward:0.04362875011716528, data cost:0.7901620966584483 
2022-03-26 05:28:29,610: ============================================================
2022-03-26 05:28:29,610: Epoch 3/26 Batch 6400/7662 eta: 2 days, 5:21:07.440329	Training Loss 0.6279 (0.6804)	Training Prec@1 51.758 (33.566)	Training Prec@5 62.305 (44.952)	
2022-03-26 05:28:29,610: ============================================================
2022-03-26 05:30:22,004: time cost, forward:0.28367900257753326, backward:0.04362049691951134, data cost:0.7904054305244912 
2022-03-26 05:30:22,005: ============================================================
2022-03-26 05:30:22,005: Epoch 3/26 Batch 6500/7662 eta: 2 days, 7:22:56.416845	Training Loss 0.6224 (0.6794)	Training Prec@1 49.805 (33.865)	Training Prec@5 60.742 (45.246)	
2022-03-26 05:30:22,005: ============================================================
2022-03-26 05:32:13,595: time cost, forward:0.283509215291187, backward:0.043633924034223864, data cost:0.790391332363609 
2022-03-26 05:32:13,596: ============================================================
2022-03-26 05:32:13,596: Epoch 3/26 Batch 6600/7662 eta: 2 days, 6:57:18.129803	Training Loss 0.6195 (0.6785)	Training Prec@1 52.539 (34.157)	Training Prec@5 64.062 (45.532)	
2022-03-26 05:32:13,596: ============================================================
2022-03-26 05:34:03,859: time cost, forward:0.28348860478717935, backward:0.0436483282244976, data cost:0.7903162363590207 
2022-03-26 05:34:03,860: ============================================================
2022-03-26 05:34:03,860: Epoch 3/26 Batch 6700/7662 eta: 2 days, 6:16:15.974145	Training Loss 0.6228 (0.6776)	Training Prec@1 50.586 (34.448)	Training Prec@5 61.523 (45.820)	
2022-03-26 05:34:03,860: ============================================================
2022-03-26 05:35:54,131: time cost, forward:0.2833977695562714, backward:0.04363656520913639, data cost:0.7901575797129106 
2022-03-26 05:35:54,132: ============================================================
2022-03-26 05:35:54,132: Epoch 3/26 Batch 6800/7662 eta: 2 days, 6:14:39.782341	Training Loss 0.6129 (0.6767)	Training Prec@1 53.125 (34.735)	Training Prec@5 63.281 (46.098)	
2022-03-26 05:35:54,132: ============================================================
2022-03-26 05:37:46,715: time cost, forward:0.2834598868804525, backward:0.04364047946921638, data cost:0.7901310688828296 
2022-03-26 05:37:46,716: ============================================================
2022-03-26 05:37:46,716: Epoch 3/26 Batch 6900/7662 eta: 2 days, 7:21:01.362628	Training Loss 0.6173 (0.6758)	Training Prec@1 51.562 (35.021)	Training Prec@5 62.109 (46.376)	
2022-03-26 05:37:46,717: ============================================================
2022-03-26 05:39:41,301: time cost, forward:0.2837267272522457, backward:0.04367084894236164, data cost:0.7903553144406176 
2022-03-26 05:39:41,301: ============================================================
2022-03-26 05:39:41,302: Epoch 3/26 Batch 7000/7662 eta: 2 days, 8:18:09.058221	Training Loss 0.6248 (0.6749)	Training Prec@1 51.953 (35.312)	Training Prec@5 61.523 (46.656)	
2022-03-26 05:39:41,302: ============================================================
2022-03-26 05:41:30,847: time cost, forward:0.283653833913474, backward:0.043685907578028364, data cost:0.790091495914247 
2022-03-26 05:41:30,847: ============================================================
2022-03-26 05:41:30,847: Epoch 3/26 Batch 7100/7662 eta: 2 days, 5:47:44.960559	Training Loss 0.6145 (0.6739)	Training Prec@1 55.664 (35.602)	Training Prec@5 66.406 (46.934)	
2022-03-26 05:41:30,848: ============================================================
2022-03-26 05:43:21,425: time cost, forward:0.28374369877347483, backward:0.043674831043301166, data cost:0.7897637600467543 
2022-03-26 05:43:21,425: ============================================================
2022-03-26 05:43:21,425: Epoch 3/26 Batch 7200/7662 eta: 2 days, 6:16:19.063967	Training Loss 0.6034 (0.6730)	Training Prec@1 59.570 (35.895)	Training Prec@5 70.508 (47.214)	
2022-03-26 05:43:21,426: ============================================================
2022-03-26 05:45:15,111: time cost, forward:0.2837522401599333, backward:0.0437382416359969, data cost:0.789975008355018 
2022-03-26 05:45:15,112: ============================================================
2022-03-26 05:45:15,112: Epoch 3/26 Batch 7300/7662 eta: 2 days, 7:45:57.577423	Training Loss 0.6048 (0.6721)	Training Prec@1 56.055 (36.180)	Training Prec@5 67.188 (47.489)	
2022-03-26 05:45:15,112: ============================================================
2022-03-26 05:47:05,262: time cost, forward:0.2837530706908062, backward:0.04377912166779517, data cost:0.7897631337729994 
2022-03-26 05:47:05,263: ============================================================
2022-03-26 05:47:05,263: Epoch 3/26 Batch 7400/7662 eta: 2 days, 6:00:04.784709	Training Loss 0.6028 (0.6712)	Training Prec@1 56.445 (36.463)	Training Prec@5 65.820 (47.764)	
2022-03-26 05:47:05,263: ============================================================
2022-03-26 05:49:00,535: time cost, forward:0.28384706306050567, backward:0.04377590737226471, data cost:0.7901165689813533 
2022-03-26 05:49:00,536: ============================================================
2022-03-26 05:49:00,536: Epoch 3/26 Batch 7500/7662 eta: 2 days, 8:28:48.904590	Training Loss 0.6083 (0.6703)	Training Prec@1 54.102 (36.749)	Training Prec@5 66.406 (48.039)	
2022-03-26 05:49:00,537: ============================================================
2022-03-26 05:50:46,874: time cost, forward:0.28385602952555805, backward:0.043778522749734025, data cost:0.7893823334254282 
2022-03-26 05:50:46,874: ============================================================
2022-03-26 05:50:46,875: Epoch 3/26 Batch 7600/7662 eta: 2 days, 4:04:22.982476	Training Loss 0.5948 (0.6694)	Training Prec@1 60.547 (37.033)	Training Prec@5 71.680 (48.310)	
2022-03-26 05:50:46,875: ============================================================
2022-03-26 05:51:56,345: Epoch: 3/26 eta: 2 days, 4:03:15.989255	Training Loss 0.5982 (0.6688)	Training Prec@1 60.547 (37.209)	Training Prec@5 71.094 (48.480)
2022-03-26 05:51:56,346: ============================================================
2022-03-26 05:53:50,172: time cost, forward:0.2780963387152161, backward:0.04260596121200407, data cost:0.815618365702003 
2022-03-26 05:53:50,172: ============================================================
2022-03-26 05:53:50,172: Epoch 4/26 Batch 100/7662 eta: 2 days, 7:35:51.647228	Training Loss 0.8847 (0.7641)	Training Prec@1 0.000 (26.703)	Training Prec@5 0.195 (30.992)	
2022-03-26 05:53:50,173: ============================================================
2022-03-26 05:55:40,156: time cost, forward:0.27964584911288926, backward:0.041596435422274335, data cost:0.7990836006912154 
2022-03-26 05:55:40,157: ============================================================
2022-03-26 05:55:40,157: Epoch 4/26 Batch 200/7662 eta: 2 days, 5:46:42.759413	Training Loss 0.8873 (0.8015)	Training Prec@1 0.000 (13.881)	Training Prec@5 0.195 (16.637)	
2022-03-26 05:55:40,157: ============================================================
2022-03-26 05:57:30,045: time cost, forward:0.2810283066038304, backward:0.04250320702492194, data cost:0.7895479648806977 
2022-03-26 05:57:30,046: ============================================================
2022-03-26 05:57:30,046: Epoch 4/26 Batch 300/7662 eta: 2 days, 5:42:04.140735	Training Loss 0.8346 (0.8213)	Training Prec@1 0.000 (9.240)	Training Prec@5 0.000 (11.079)	
2022-03-26 05:57:30,046: ============================================================
2022-03-26 05:59:20,605: time cost, forward:0.28051919745920895, backward:0.04254497382276339, data cost:0.7872702818466607 
2022-03-26 05:59:20,606: ============================================================
2022-03-26 05:59:20,606: Epoch 4/26 Batch 400/7662 eta: 2 days, 5:59:54.222106	Training Loss 0.8251 (0.8233)	Training Prec@1 0.000 (6.928)	Training Prec@5 0.195 (8.313)	
2022-03-26 05:59:20,606: ============================================================
2022-03-26 06:01:09,722: time cost, forward:0.28073000000091736, backward:0.042357507831825764, data cost:0.7836459609931838 
2022-03-26 06:01:09,723: ============================================================
2022-03-26 06:01:09,724: Epoch 4/26 Batch 500/7662 eta: 2 days, 5:15:49.365177	Training Loss 0.7913 (0.8218)	Training Prec@1 1.367 (5.587)	Training Prec@5 4.297 (6.788)	
2022-03-26 06:01:09,724: ============================================================
2022-03-26 06:02:58,029: time cost, forward:0.2799823248326679, backward:0.042711922242764835, data cost:0.7801172999985428 
2022-03-26 06:02:58,029: ============================================================
2022-03-26 06:02:58,029: Epoch 4/26 Batch 600/7662 eta: 2 days, 4:50:14.066088	Training Loss 0.8211 (0.8245)	Training Prec@1 0.000 (4.682)	Training Prec@5 0.000 (5.724)	
2022-03-26 06:02:58,030: ============================================================
2022-03-26 06:04:48,084: time cost, forward:0.2807267411413452, backward:0.042700281811715535, data cost:0.778863746209206 
2022-03-26 06:04:48,085: ============================================================
2022-03-26 06:04:48,086: Epoch 4/26 Batch 700/7662 eta: 2 days, 5:39:38.065835	Training Loss 0.7516 (0.8205)	Training Prec@1 9.766 (4.279)	Training Prec@5 17.383 (5.469)	
2022-03-26 06:04:48,086: ============================================================
2022-03-26 06:06:34,960: time cost, forward:0.28182756736669434, backward:0.042623445895198585, data cost:0.7733155764984398 
2022-03-26 06:06:34,961: ============================================================
2022-03-26 06:06:34,962: Epoch 4/26 Batch 800/7662 eta: 2 days, 4:04:49.548606	Training Loss 0.8696 (0.8170)	Training Prec@1 0.000 (5.125)	Training Prec@5 0.000 (6.907)	
2022-03-26 06:06:34,962: ============================================================
2022-03-26 06:08:18,442: time cost, forward:0.28133931812375484, backward:0.042506496155752624, data cost:0.7673506667802278 
2022-03-26 06:08:18,442: ============================================================
2022-03-26 06:08:18,442: Epoch 4/26 Batch 900/7662 eta: 2 days, 2:23:49.295916	Training Loss 0.8396 (0.8209)	Training Prec@1 0.000 (4.555)	Training Prec@5 0.000 (6.140)	
2022-03-26 06:08:18,442: ============================================================
2022-03-26 06:10:08,350: time cost, forward:0.28127420390093766, backward:0.04244009749190108, data cost:0.7680842122277459 
2022-03-26 06:10:08,350: ============================================================
2022-03-26 06:10:08,350: Epoch 4/26 Batch 1000/7662 eta: 2 days, 5:29:48.535431	Training Loss 0.8335 (0.8224)	Training Prec@1 0.000 (4.100)	Training Prec@5 0.000 (5.526)	
2022-03-26 06:10:08,350: ============================================================
2022-03-26 06:11:55,540: time cost, forward:0.2806320279375654, backward:0.042484420554219214, data cost:0.7666991407812672 
2022-03-26 06:11:55,541: ============================================================
2022-03-26 06:11:55,541: Epoch 4/26 Batch 1100/7662 eta: 2 days, 4:08:39.672316	Training Loss 0.8335 (0.8234)	Training Prec@1 0.000 (3.727)	Training Prec@5 0.195 (5.024)	
2022-03-26 06:11:55,541: ============================================================
2022-03-26 06:13:44,538: time cost, forward:0.2807468216651872, backward:0.042678363329177106, data cost:0.7657776214959127 
2022-03-26 06:13:44,538: ============================================================
2022-03-26 06:13:44,539: Epoch 4/26 Batch 1200/7662 eta: 2 days, 4:59:35.441894	Training Loss 0.8328 (0.8242)	Training Prec@1 0.000 (3.416)	Training Prec@5 0.000 (4.607)	
2022-03-26 06:13:44,539: ============================================================
2022-03-26 06:15:35,806: time cost, forward:0.2803351014646041, backward:0.042777269229786134, data cost:0.7678686041754883 
2022-03-26 06:15:35,827: ============================================================
2022-03-26 06:15:35,828: Epoch 4/26 Batch 1300/7662 eta: 2 days, 6:04:34.126230	Training Loss 0.8312 (0.8247)	Training Prec@1 0.000 (3.153)	Training Prec@5 0.000 (4.253)	
2022-03-26 06:15:35,828: ============================================================
2022-03-26 06:17:24,762: time cost, forward:0.2807152739927716, backward:0.04277168911980935, data cost:0.767961501052671 
2022-03-26 06:17:24,764: ============================================================
2022-03-26 06:17:24,764: Epoch 4/26 Batch 1400/7662 eta: 2 days, 4:54:10.532108	Training Loss 0.8285 (0.8251)	Training Prec@1 0.000 (2.928)	Training Prec@5 0.000 (3.950)	
2022-03-26 06:17:24,764: ============================================================
2022-03-26 06:19:14,472: time cost, forward:0.2803681901966118, backward:0.042910996717640044, data cost:0.7682709021119772 
2022-03-26 06:19:14,473: ============================================================
2022-03-26 06:19:14,474: Epoch 4/26 Batch 1500/7662 eta: 2 days, 5:14:52.178183	Training Loss 0.8285 (0.8255)	Training Prec@1 0.000 (2.733)	Training Prec@5 0.000 (3.688)	
2022-03-26 06:19:14,474: ============================================================
2022-03-26 06:21:02,326: time cost, forward:0.28050142903116215, backward:0.04296190743151122, data cost:0.767315728132094 
2022-03-26 06:21:02,326: ============================================================
2022-03-26 06:21:02,327: Epoch 4/26 Batch 1600/7662 eta: 2 days, 4:19:00.664686	Training Loss 0.8299 (0.8257)	Training Prec@1 0.000 (2.562)	Training Prec@5 0.000 (3.458)	
2022-03-26 06:21:02,327: ============================================================
2022-03-26 06:22:51,804: time cost, forward:0.2806978415151846, backward:0.04299173865899259, data cost:0.7670932489679168 
2022-03-26 06:22:51,804: ============================================================
2022-03-26 06:22:51,804: Epoch 4/26 Batch 1700/7662 eta: 2 days, 5:04:28.095954	Training Loss 0.8272 (0.8259)	Training Prec@1 0.000 (2.411)	Training Prec@5 0.000 (3.256)	
2022-03-26 06:22:51,804: ============================================================
2022-03-26 06:24:37,253: time cost, forward:0.2811462598220715, backward:0.043091437099641264, data cost:0.7647612707160326 
2022-03-26 06:24:37,254: ============================================================
2022-03-26 06:24:37,254: Epoch 4/26 Batch 1800/7662 eta: 2 days, 3:05:32.713490	Training Loss 0.8270 (0.8259)	Training Prec@1 0.000 (2.278)	Training Prec@5 0.000 (3.077)	
2022-03-26 06:24:37,254: ============================================================
2022-03-26 06:26:25,929: time cost, forward:0.28089101117431897, backward:0.04307438537533375, data cost:0.764511574187236 
2022-03-26 06:26:25,930: ============================================================
2022-03-26 06:26:25,930: Epoch 4/26 Batch 1900/7662 eta: 2 days, 4:37:31.885041	Training Loss 0.8225 (0.8259)	Training Prec@1 0.195 (2.159)	Training Prec@5 0.195 (2.919)	
2022-03-26 06:26:25,930: ============================================================
2022-03-26 06:28:13,881: time cost, forward:0.28025865578663356, backward:0.04305940893305845, data cost:0.7651137518489164 
2022-03-26 06:28:13,882: ============================================================
2022-03-26 06:28:13,882: Epoch 4/26 Batch 2000/7662 eta: 2 days, 4:14:41.139574	Training Loss 0.8210 (0.8256)	Training Prec@1 0.000 (2.052)	Training Prec@5 0.195 (2.778)	
2022-03-26 06:28:13,882: ============================================================
2022-03-26 06:30:02,427: time cost, forward:0.28071063220245374, backward:0.04308079401046222, data cost:0.7642169940352384 
2022-03-26 06:30:02,427: ============================================================
2022-03-26 06:30:02,427: Epoch 4/26 Batch 2100/7662 eta: 2 days, 4:30:07.151967	Training Loss 0.7883 (0.8250)	Training Prec@1 1.953 (1.964)	Training Prec@5 6.250 (2.678)	
2022-03-26 06:30:02,428: ============================================================
2022-03-26 06:31:50,471: time cost, forward:0.28112603795154356, backward:0.04283394115304014, data cost:0.7637910814705953 
2022-03-26 06:31:50,471: ============================================================
2022-03-26 06:31:50,472: Epoch 4/26 Batch 2200/7662 eta: 2 days, 4:13:46.210533	Training Loss 0.8573 (0.8267)	Training Prec@1 0.000 (1.882)	Training Prec@5 0.000 (2.573)	
2022-03-26 06:31:50,472: ============================================================
2022-03-26 06:33:41,457: time cost, forward:0.28174519818883814, backward:0.04288572205207098, data cost:0.7641889688086126 
2022-03-26 06:33:41,458: ============================================================
2022-03-26 06:33:41,458: Epoch 4/26 Batch 2300/7662 eta: 2 days, 5:37:15.152353	Training Loss 0.8312 (0.8275)	Training Prec@1 0.000 (1.800)	Training Prec@5 0.000 (2.463)	
2022-03-26 06:33:41,458: ============================================================
2022-03-26 06:35:30,023: time cost, forward:0.28172954125621014, backward:0.04301921881055176, data cost:0.7638922635094729 
2022-03-26 06:35:30,025: ============================================================
2022-03-26 06:35:30,026: Epoch 4/26 Batch 2400/7662 eta: 2 days, 4:25:19.955414	Training Loss 0.8211 (0.8274)	Training Prec@1 0.000 (1.726)	Training Prec@5 0.195 (2.363)	
2022-03-26 06:35:30,026: ============================================================
2022-03-26 06:37:17,268: time cost, forward:0.28169936807501933, backward:0.04304491190397057, data cost:0.7629585343391813 
2022-03-26 06:37:17,269: ============================================================
2022-03-26 06:37:17,270: Epoch 4/26 Batch 2500/7662 eta: 2 days, 3:45:11.587478	Training Loss 0.8097 (0.8270)	Training Prec@1 0.000 (1.659)	Training Prec@5 0.391 (2.277)	
2022-03-26 06:37:17,270: ============================================================
2022-03-26 06:39:04,641: time cost, forward:0.2820134414256009, backward:0.0430742931989763, data cost:0.7623214904231812 
2022-03-26 06:39:04,641: ============================================================
2022-03-26 06:39:04,642: Epoch 4/26 Batch 2600/7662 eta: 2 days, 3:47:07.019602	Training Loss 0.7582 (0.8254)	Training Prec@1 4.883 (1.683)	Training Prec@5 11.914 (2.386)	
2022-03-26 06:39:04,642: ============================================================
2022-03-26 06:40:57,165: time cost, forward:0.28227620400424885, backward:0.0429597686246043, data cost:0.7634364889921547 
2022-03-26 06:40:57,166: ============================================================
2022-03-26 06:40:57,166: Epoch 4/26 Batch 2700/7662 eta: 2 days, 6:14:19.475021	Training Loss 0.7100 (0.8220)	Training Prec@1 24.609 (2.223)	Training Prec@5 35.742 (3.267)	
2022-03-26 06:40:57,166: ============================================================
2022-03-26 06:42:44,628: time cost, forward:0.28189571604808766, backward:0.042697387663284854, data cost:0.7637332783890179 
2022-03-26 06:42:44,628: ============================================================
2022-03-26 06:42:44,628: Epoch 4/26 Batch 2800/7662 eta: 2 days, 3:46:08.882949	Training Loss 0.7363 (0.8202)	Training Prec@1 15.234 (2.539)	Training Prec@5 28.320 (3.758)	
2022-03-26 06:42:44,628: ============================================================
2022-03-26 06:44:30,025: time cost, forward:0.281454913654834, backward:0.042758476656031795, data cost:0.7628711599775658 
2022-03-26 06:44:30,026: ============================================================
2022-03-26 06:44:30,026: Epoch 4/26 Batch 2900/7662 eta: 2 days, 2:44:43.148899	Training Loss 0.6781 (0.8159)	Training Prec@1 38.672 (3.509)	Training Prec@5 50.000 (5.097)	
2022-03-26 06:44:30,027: ============================================================
2022-03-26 06:46:18,948: time cost, forward:0.2813059988718265, backward:0.042740857931088116, data cost:0.7630052628537821 
2022-03-26 06:46:18,948: ============================================================
2022-03-26 06:46:18,949: Epoch 4/26 Batch 3000/7662 eta: 2 days, 4:24:42.971152	Training Loss 0.6617 (0.8125)	Training Prec@1 42.578 (4.328)	Training Prec@5 53.320 (6.185)	
2022-03-26 06:46:18,949: ============================================================
2022-03-26 06:48:08,366: time cost, forward:0.2812475388801725, backward:0.04270846461357321, data cost:0.7634363253680534 
2022-03-26 06:48:08,367: ============================================================
2022-03-26 06:48:08,367: Epoch 4/26 Batch 3100/7662 eta: 2 days, 4:37:12.328265	Training Loss 0.6426 (0.8071)	Training Prec@1 48.828 (5.727)	Training Prec@5 59.766 (7.894)	
2022-03-26 06:48:08,367: ============================================================
2022-03-26 06:49:57,658: time cost, forward:0.281249266410105, backward:0.042673860277448385, data cost:0.7636320055108697 
2022-03-26 06:49:57,658: ============================================================
2022-03-26 06:49:57,658: Epoch 4/26 Batch 3200/7662 eta: 2 days, 4:31:43.799326	Training Loss 0.6257 (0.8024)	Training Prec@1 56.250 (6.948)	Training Prec@5 65.625 (9.416)	
2022-03-26 06:49:57,658: ============================================================
2022-03-26 06:51:47,049: time cost, forward:0.2813836559811373, backward:0.04270254774287311, data cost:0.7636364129284144 
2022-03-26 06:51:47,049: ============================================================
2022-03-26 06:51:47,049: Epoch 4/26 Batch 3300/7662 eta: 2 days, 4:32:46.563082	Training Loss 0.6222 (0.7969)	Training Prec@1 52.930 (8.385)	Training Prec@5 63.281 (11.108)	
2022-03-26 06:51:47,049: ============================================================
2022-03-26 06:53:38,756: time cost, forward:0.2813762083724163, backward:0.04279126388671013, data cost:0.7643744411732246 
2022-03-26 06:53:38,757: ============================================================
2022-03-26 06:53:38,757: Epoch 4/26 Batch 3400/7662 eta: 2 days, 5:37:40.873863	Training Loss 0.6196 (0.7927)	Training Prec@1 52.734 (9.509)	Training Prec@5 65.625 (12.480)	
2022-03-26 06:53:38,757: ============================================================
2022-03-26 06:55:26,864: time cost, forward:0.2814561434901418, backward:0.04288791485873929, data cost:0.7640245204041365 
2022-03-26 06:55:26,865: ============================================================
2022-03-26 06:55:26,865: Epoch 4/26 Batch 3500/7662 eta: 2 days, 3:52:11.737762	Training Loss 0.5993 (0.7874)	Training Prec@1 59.180 (10.882)	Training Prec@5 70.117 (14.074)	
2022-03-26 06:55:26,865: ============================================================
2022-03-26 06:57:16,572: time cost, forward:0.28159878584503234, backward:0.04290668227070403, data cost:0.7639216211445632 
2022-03-26 06:57:16,573: ============================================================
2022-03-26 06:57:16,573: Epoch 4/26 Batch 3600/7662 eta: 2 days, 4:36:25.396936	Training Loss 0.5992 (0.7822)	Training Prec@1 60.938 (12.234)	Training Prec@5 71.484 (15.624)	
2022-03-26 06:57:16,573: ============================================================
2022-03-26 06:59:04,114: time cost, forward:0.28155560356824905, backward:0.04298748961008056, data cost:0.7636880915240359 
2022-03-26 06:59:04,114: ============================================================
2022-03-26 06:59:04,114: Epoch 4/26 Batch 3700/7662 eta: 2 days, 3:32:18.086843	Training Loss 0.6153 (0.7772)	Training Prec@1 56.836 (13.539)	Training Prec@5 66.211 (17.116)	
2022-03-26 06:59:04,114: ============================================================
2022-03-26 07:00:52,495: time cost, forward:0.28160309044741805, backward:0.04302085773290286, data cost:0.7634761320913926 
2022-03-26 07:00:52,495: ============================================================
2022-03-26 07:00:52,495: Epoch 4/26 Batch 3800/7662 eta: 2 days, 3:54:38.205606	Training Loss 0.5957 (0.7724)	Training Prec@1 61.523 (14.785)	Training Prec@5 72.266 (18.539)	
2022-03-26 07:00:52,495: ============================================================
2022-03-26 07:02:42,501: time cost, forward:0.2817988460508485, backward:0.04305300427632749, data cost:0.763340081945998 
2022-03-26 07:02:42,501: ============================================================
2022-03-26 07:02:42,502: Epoch 4/26 Batch 3900/7662 eta: 2 days, 4:39:31.568090	Training Loss 0.5845 (0.7678)	Training Prec@1 62.305 (15.986)	Training Prec@5 75.195 (19.905)	
2022-03-26 07:02:42,502: ============================================================
2022-03-26 07:04:33,593: time cost, forward:0.28193135290153026, backward:0.043122646778218296, data cost:0.7637934485624122 
2022-03-26 07:04:33,593: ============================================================
2022-03-26 07:04:33,594: Epoch 4/26 Batch 4000/7662 eta: 2 days, 5:08:49.252278	Training Loss 0.5821 (0.7633)	Training Prec@1 65.234 (17.140)	Training Prec@5 74.805 (21.211)	
2022-03-26 07:04:33,594: ============================================================
2022-03-26 07:06:23,399: time cost, forward:0.28223444752996796, backward:0.04311536806157287, data cost:0.7637468455157125 
2022-03-26 07:06:23,401: ============================================================
2022-03-26 07:06:23,401: Epoch 4/26 Batch 4100/7662 eta: 2 days, 4:30:08.076268	Training Loss 0.5905 (0.7591)	Training Prec@1 58.594 (18.243)	Training Prec@5 71.680 (22.462)	
2022-03-26 07:06:23,401: ============================================================
2022-03-26 07:08:12,422: time cost, forward:0.28247745737174373, backward:0.043113307857490714, data cost:0.7634405717306916 
2022-03-26 07:08:12,422: ============================================================
2022-03-26 07:08:12,422: Epoch 4/26 Batch 4200/7662 eta: 2 days, 4:05:46.417636	Training Loss 0.5828 (0.7550)	Training Prec@1 63.672 (19.313)	Training Prec@5 75.391 (23.672)	
2022-03-26 07:08:12,423: ============================================================
2022-03-26 07:10:02,147: time cost, forward:0.28259405570685736, backward:0.04313043994553063, data cost:0.7636271656654856 
2022-03-26 07:10:02,147: ============================================================
2022-03-26 07:10:02,147: Epoch 4/26 Batch 4300/7662 eta: 2 days, 4:24:07.116197	Training Loss 0.5840 (0.7510)	Training Prec@1 63.867 (20.338)	Training Prec@5 74.023 (24.825)	
2022-03-26 07:10:02,148: ============================================================
2022-03-26 07:11:50,357: time cost, forward:0.28264516449755067, backward:0.0431453706893522, data cost:0.7633786871910746 
2022-03-26 07:11:50,358: ============================================================
2022-03-26 07:11:50,358: Epoch 4/26 Batch 4400/7662 eta: 2 days, 3:38:54.743589	Training Loss 0.5711 (0.7472)	Training Prec@1 64.453 (21.329)	Training Prec@5 74.805 (25.936)	
2022-03-26 07:11:50,358: ============================================================
2022-03-26 07:13:38,770: time cost, forward:0.2826499339076354, backward:0.04315007546393705, data cost:0.763263168057274 
2022-03-26 07:13:38,770: ============================================================
2022-03-26 07:13:38,770: Epoch 4/26 Batch 4500/7662 eta: 2 days, 3:42:53.288054	Training Loss 0.5850 (0.7435)	Training Prec@1 63.672 (22.284)	Training Prec@5 74.805 (27.005)	
2022-03-26 07:13:38,770: ============================================================
2022-03-26 07:15:29,846: time cost, forward:0.28292647530965687, backward:0.043206388780826534, data cost:0.7633829390543859 
2022-03-26 07:15:29,847: ============================================================
2022-03-26 07:15:29,847: Epoch 4/26 Batch 4600/7662 eta: 2 days, 4:57:17.320200	Training Loss 0.5724 (0.7399)	Training Prec@1 65.234 (23.212)	Training Prec@5 73.438 (28.039)	
2022-03-26 07:15:29,847: ============================================================
2022-03-26 07:17:17,753: time cost, forward:0.2829763888297981, backward:0.04319829752049971, data cost:0.7629885719187287 
2022-03-26 07:17:17,754: ============================================================
2022-03-26 07:17:17,754: Epoch 4/26 Batch 4700/7662 eta: 2 days, 3:24:50.041592	Training Loss 0.5853 (0.7364)	Training Prec@1 64.258 (24.092)	Training Prec@5 73.633 (29.016)	
2022-03-26 07:17:17,754: ============================================================
2022-03-26 07:19:06,571: time cost, forward:0.2829870651552741, backward:0.04323240110441456, data cost:0.7629234470360278 
2022-03-26 07:19:06,571: ============================================================
2022-03-26 07:19:06,571: Epoch 4/26 Batch 4800/7662 eta: 2 days, 3:49:02.202765	Training Loss 0.8707 (0.7370)	Training Prec@1 0.000 (24.019)	Training Prec@5 0.195 (28.939)	
2022-03-26 07:19:06,572: ============================================================
2022-03-26 07:20:56,632: time cost, forward:0.2831366412565158, backward:0.04323352144844412, data cost:0.763021480650239 
2022-03-26 07:20:56,633: ============================================================
2022-03-26 07:20:56,633: Epoch 4/26 Batch 4900/7662 eta: 2 days, 4:22:45.465310	Training Loss 0.8003 (0.7378)	Training Prec@1 2.148 (23.856)	Training Prec@5 4.297 (28.802)	
2022-03-26 07:20:56,633: ============================================================
2022-03-26 07:22:48,649: time cost, forward:0.283278269776346, backward:0.043241526513463094, data cost:0.7635041961051817 
2022-03-26 07:22:48,650: ============================================================
2022-03-26 07:22:48,650: Epoch 4/26 Batch 5000/7662 eta: 2 days, 5:16:43.714302	Training Loss 0.6054 (0.7363)	Training Prec@1 59.375 (24.212)	Training Prec@5 69.922 (29.269)	
2022-03-26 07:22:48,651: ============================================================
2022-03-26 07:24:33,003: time cost, forward:0.28321394043170744, backward:0.043261331818949644, data cost:0.7625883689322269 
2022-03-26 07:24:33,004: ============================================================
2022-03-26 07:24:33,005: Epoch 4/26 Batch 5100/7662 eta: 2 days, 1:36:17.991320	Training Loss 0.5924 (0.7334)	Training Prec@1 63.867 (24.948)	Training Prec@5 73.828 (30.098)	
2022-03-26 07:24:33,005: ============================================================
2022-03-26 07:26:21,622: time cost, forward:0.28322747891443145, backward:0.04328701238857826, data cost:0.7625873871642045 
2022-03-26 07:26:21,623: ============================================================
2022-03-26 07:26:21,623: Epoch 4/26 Batch 5200/7662 eta: 2 days, 3:36:06.643117	Training Loss 0.5721 (0.7304)	Training Prec@1 65.039 (25.703)	Training Prec@5 75.586 (30.941)	
2022-03-26 07:26:21,623: ============================================================
2022-03-26 07:28:10,309: time cost, forward:0.28316117025901966, backward:0.04316885765149112, data cost:0.7626686556021163 
2022-03-26 07:28:10,310: ============================================================
2022-03-26 07:28:10,310: Epoch 4/26 Batch 5300/7662 eta: 2 days, 3:36:15.924506	Training Loss 0.5767 (0.7276)	Training Prec@1 62.891 (26.437)	Training Prec@5 73.828 (31.756)	
2022-03-26 07:28:10,310: ============================================================
2022-03-26 07:30:00,614: time cost, forward:0.2832335505050119, backward:0.04299832512038927, data cost:0.7629821378669378 
2022-03-26 07:30:00,614: ============================================================
2022-03-26 07:30:00,615: Epoch 4/26 Batch 5400/7662 eta: 2 days, 4:20:29.904639	Training Loss 0.5707 (0.7247)	Training Prec@1 66.016 (27.170)	Training Prec@5 75.195 (32.562)	
2022-03-26 07:30:00,615: ============================================================
2022-03-26 07:31:50,257: time cost, forward:0.2831384527789482, backward:0.04301302999686189, data cost:0.7632440484465415 
2022-03-26 07:31:50,257: ============================================================
2022-03-26 07:31:50,257: Epoch 4/26 Batch 5500/7662 eta: 2 days, 3:59:50.092073	Training Loss 0.5777 (0.7220)	Training Prec@1 64.062 (27.878)	Training Prec@5 73.242 (33.339)	
2022-03-26 07:31:50,258: ============================================================
2022-03-26 07:33:42,274: time cost, forward:0.28319362504798656, backward:0.04300620620177034, data cost:0.7636269640339168 
2022-03-26 07:33:42,274: ============================================================
2022-03-26 07:33:42,275: Epoch 4/26 Batch 5600/7662 eta: 2 days, 5:05:31.686279	Training Loss 0.6888 (0.7199)	Training Prec@1 40.625 (28.464)	Training Prec@5 50.000 (34.004)	
2022-03-26 07:33:42,275: ============================================================
2022-03-26 07:35:35,691: time cost, forward:0.28355644217372505, backward:0.0430393176322277, data cost:0.7641096452722049 
2022-03-26 07:35:35,692: ============================================================
2022-03-26 07:35:35,692: Epoch 4/26 Batch 5700/7662 eta: 2 days, 5:43:27.180132	Training Loss 0.5619 (0.7175)	Training Prec@1 68.555 (29.077)	Training Prec@5 77.539 (34.688)	
2022-03-26 07:35:35,692: ============================================================
2022-03-26 07:37:29,547: time cost, forward:0.28441523658672185, backward:0.04308291064560218, data cost:0.764068262394923 
2022-03-26 07:37:29,576: ============================================================
2022-03-26 07:37:29,577: Epoch 4/26 Batch 5800/7662 eta: 2 days, 5:54:49.986433	Training Loss 0.5707 (0.7149)	Training Prec@1 67.969 (29.732)	Training Prec@5 78.125 (35.406)	
2022-03-26 07:37:29,577: ============================================================
2022-03-26 07:39:19,539: time cost, forward:0.2845722950804252, backward:0.04314625447110455, data cost:0.7639465670723857 
2022-03-26 07:39:19,539: ============================================================
2022-03-26 07:39:19,540: Epoch 4/26 Batch 5900/7662 eta: 2 days, 4:01:36.833019	Training Loss 0.5729 (0.7124)	Training Prec@1 65.820 (30.368)	Training Prec@5 74.609 (36.101)	
2022-03-26 07:39:19,540: ============================================================
2022-03-26 07:41:11,173: time cost, forward:0.28491586600766416, backward:0.043144122503820825, data cost:0.763969555559268 
2022-03-26 07:41:11,173: ============================================================
2022-03-26 07:41:11,173: Epoch 4/26 Batch 6000/7662 eta: 2 days, 4:47:10.753920	Training Loss 0.5671 (0.7100)	Training Prec@1 66.406 (30.992)	Training Prec@5 77.148 (36.779)	
2022-03-26 07:41:11,174: ============================================================
2022-03-26 07:42:55,679: time cost, forward:0.2849608593093389, backward:0.043118543753097795, data cost:0.7632449539123275 
2022-03-26 07:42:55,679: ============================================================
2022-03-26 07:42:55,679: Epoch 4/26 Batch 6100/7662 eta: 2 days, 1:23:12.190152	Training Loss 0.5741 (0.7076)	Training Prec@1 66.406 (31.599)	Training Prec@5 76.367 (37.438)	
2022-03-26 07:42:55,679: ============================================================
2022-03-26 07:44:44,851: time cost, forward:0.28509250851019025, backward:0.043093420263451324, data cost:0.7631216114577718 
2022-03-26 07:44:44,851: ============================================================
2022-03-26 07:44:44,852: Epoch 4/26 Batch 6200/7662 eta: 2 days, 3:33:42.843550	Training Loss 0.5681 (0.7052)	Training Prec@1 68.945 (32.204)	Training Prec@5 78.125 (38.089)	
2022-03-26 07:44:44,852: ============================================================
2022-03-26 07:46:34,053: time cost, forward:0.28518018693768005, backward:0.04307520031872241, data cost:0.7630270391934485 
2022-03-26 07:46:34,054: ============================================================
2022-03-26 07:46:34,054: Epoch 4/26 Batch 6300/7662 eta: 2 days, 3:32:44.292107	Training Loss 0.5515 (0.7029)	Training Prec@1 68.750 (32.791)	Training Prec@5 78.906 (38.722)	
2022-03-26 07:46:34,054: ============================================================
2022-03-26 07:48:25,609: time cost, forward:0.2853404603762298, backward:0.043074539889207314, data cost:0.7632194162626008 
2022-03-26 07:48:25,610: ============================================================
2022-03-26 07:48:25,610: Epoch 4/26 Batch 6400/7662 eta: 2 days, 4:37:32.014569	Training Loss 0.5554 (0.7006)	Training Prec@1 67.969 (33.360)	Training Prec@5 75.391 (39.335)	
2022-03-26 07:48:25,610: ============================================================
2022-03-26 07:50:17,452: time cost, forward:0.28554092922436675, backward:0.043057394717395954, data cost:0.7634560075388044 
2022-03-26 07:50:17,452: ============================================================
2022-03-26 07:50:17,452: Epoch 4/26 Batch 6500/7662 eta: 2 days, 4:43:46.832115	Training Loss 0.5538 (0.6984)	Training Prec@1 70.312 (33.920)	Training Prec@5 78.711 (39.938)	
2022-03-26 07:50:17,452: ============================================================
2022-03-26 07:52:05,762: time cost, forward:0.2854713184361314, backward:0.04306099710726055, data cost:0.7633278662552525 
2022-03-26 07:52:05,763: ============================================================
2022-03-26 07:52:05,763: Epoch 4/26 Batch 6600/7662 eta: 2 days, 3:02:04.579232	Training Loss 0.5639 (0.6963)	Training Prec@1 67.969 (34.463)	Training Prec@5 78.320 (40.522)	
2022-03-26 07:52:05,763: ============================================================
2022-03-26 07:53:58,953: time cost, forward:0.28539339978937994, backward:0.04306682484739662, data cost:0.7640904501883516 
2022-03-26 07:53:58,954: ============================================================
2022-03-26 07:53:58,954: Epoch 4/26 Batch 6700/7662 eta: 2 days, 5:18:08.909636	Training Loss 0.5594 (0.6942)	Training Prec@1 73.047 (34.990)	Training Prec@5 82.227 (41.091)	
2022-03-26 07:53:58,954: ============================================================
2022-03-26 07:55:43,335: time cost, forward:0.2850135991390636, backward:0.043071475900750174, data cost:0.7636431266427268 
2022-03-26 07:55:43,335: ============================================================
2022-03-26 07:55:43,335: Epoch 4/26 Batch 6800/7662 eta: 2 days, 1:07:30.347876	Training Loss 0.5616 (0.6921)	Training Prec@1 67.188 (35.512)	Training Prec@5 75.977 (41.649)	
2022-03-26 07:55:43,336: ============================================================
2022-03-26 07:57:32,958: time cost, forward:0.28480892144073383, backward:0.043097120866445134, data cost:0.7638698850685072 
2022-03-26 07:57:32,959: ============================================================
2022-03-26 07:57:32,959: Epoch 4/26 Batch 6900/7662 eta: 2 days, 3:33:42.469854	Training Loss 0.5587 (0.6901)	Training Prec@1 68.750 (36.021)	Training Prec@5 78.906 (42.189)	
2022-03-26 07:57:32,959: ============================================================
2022-03-26 07:59:16,858: time cost, forward:0.2845381016832775, backward:0.0431144177564503, data cost:0.7634740736266854 
2022-03-26 07:59:16,859: ============================================================
2022-03-26 07:59:16,860: Epoch 4/26 Batch 7000/7662 eta: 2 days, 0:50:27.512026	Training Loss 0.5460 (0.6881)	Training Prec@1 72.070 (36.522)	Training Prec@5 81.250 (42.720)	
2022-03-26 07:59:16,860: ============================================================
2022-03-26 08:01:06,792: time cost, forward:0.2843505579546348, backward:0.04311505759798451, data cost:0.7637652927325601 
2022-03-26 08:01:06,792: ============================================================
2022-03-26 08:01:06,792: Epoch 4/26 Batch 7100/7662 eta: 2 days, 3:38:45.693519	Training Loss 0.5489 (0.6862)	Training Prec@1 71.875 (37.010)	Training Prec@5 82.031 (43.238)	
2022-03-26 08:01:06,792: ============================================================
2022-03-26 08:02:55,944: time cost, forward:0.28407042913096436, backward:0.04312595550774501, data cost:0.7640260870812055 
2022-03-26 08:02:55,945: ============================================================
2022-03-26 08:02:55,946: Epoch 4/26 Batch 7200/7662 eta: 2 days, 3:14:58.402990	Training Loss 0.5596 (0.6843)	Training Prec@1 68.555 (37.491)	Training Prec@5 78.906 (43.747)	
2022-03-26 08:02:55,946: ============================================================
2022-03-26 08:04:45,792: time cost, forward:0.2839960681524876, backward:0.04312160720987211, data cost:0.7641126923012985 
2022-03-26 08:04:45,793: ============================================================
2022-03-26 08:04:45,793: Epoch 4/26 Batch 7300/7662 eta: 2 days, 3:32:42.495667	Training Loss 0.5587 (0.6824)	Training Prec@1 70.508 (37.961)	Training Prec@5 78.906 (44.245)	
2022-03-26 08:04:45,793: ============================================================
2022-03-26 08:06:33,117: time cost, forward:0.2839252681309411, backward:0.04311150211726577, data cost:0.7640065595513663 
2022-03-26 08:06:33,117: ============================================================
2022-03-26 08:06:33,117: Epoch 4/26 Batch 7400/7662 eta: 2 days, 2:19:52.245506	Training Loss 0.5491 (0.6806)	Training Prec@1 72.852 (38.421)	Training Prec@5 80.469 (44.731)	
2022-03-26 08:06:33,117: ============================================================
2022-03-26 08:08:21,995: time cost, forward:0.28377805695341085, backward:0.04310035982168838, data cost:0.7641087733740679 
2022-03-26 08:08:21,996: ============================================================
2022-03-26 08:08:21,996: Epoch 4/26 Batch 7500/7662 eta: 2 days, 3:01:47.534882	Training Loss 0.5553 (0.6788)	Training Prec@1 69.922 (38.871)	Training Prec@5 79.297 (45.208)	
2022-03-26 08:08:21,996: ============================================================
2022-03-26 08:10:14,494: time cost, forward:0.2837218348800171, backward:0.04302922894035708, data cost:0.7646783045176252 
2022-03-26 08:10:14,494: ============================================================
2022-03-26 08:10:14,495: Epoch 4/26 Batch 7600/7662 eta: 2 days, 4:41:43.127607	Training Loss 0.5588 (0.6770)	Training Prec@1 67.578 (39.310)	Training Prec@5 79.297 (45.672)	
2022-03-26 08:10:14,495: ============================================================
2022-03-26 08:11:22,079: Epoch: 4/26 eta: 2 days, 4:40:32.253447	Training Loss 0.5404 (0.6760)	Training Prec@1 73.633 (39.584)	Training Prec@5 81.250 (45.960)
2022-03-26 08:11:22,080: ============================================================
2022-03-26 08:13:12,178: time cost, forward:0.26907891938180634, backward:0.042569991314049926, data cost:0.7879969519798202 
2022-03-26 08:13:12,179: ============================================================
2022-03-26 08:13:12,179: Epoch 5/26 Batch 100/7662 eta: 2 days, 3:30:51.941187	Training Loss 0.5237 (0.5471)	Training Prec@1 74.609 (74.763)	Training Prec@5 84.570 (82.479)	
2022-03-26 08:13:12,179: ============================================================
2022-03-26 08:15:02,482: time cost, forward:0.2702089709852209, backward:0.04179303969570141, data cost:0.7919868344637617 
2022-03-26 08:15:02,482: ============================================================
2022-03-26 08:15:02,482: Epoch 5/26 Batch 200/7662 eta: 2 days, 3:35:12.934442	Training Loss 0.5146 (0.5342)	Training Prec@1 78.320 (76.380)	Training Prec@5 85.156 (83.742)	
2022-03-26 08:15:02,483: ============================================================
2022-03-26 08:16:51,651: time cost, forward:0.2740240120967495, backward:0.04171495692785767, data cost:0.7837338878159539 
2022-03-26 08:16:51,653: ============================================================
2022-03-26 08:16:51,653: Epoch 5/26 Batch 300/7662 eta: 2 days, 3:01:35.432988	Training Loss 0.5308 (0.5303)	Training Prec@1 77.734 (76.885)	Training Prec@5 86.133 (84.201)	
2022-03-26 08:16:51,653: ============================================================
2022-03-26 08:18:42,287: time cost, forward:0.2730976507478489, backward:0.04216542040793818, data cost:0.7854200192262655 
2022-03-26 08:18:42,287: ============================================================
2022-03-26 08:18:42,288: Epoch 5/26 Batch 400/7662 eta: 2 days, 3:40:49.195779	Training Loss 0.5143 (0.5284)	Training Prec@1 78.320 (77.137)	Training Prec@5 84.180 (84.361)	
2022-03-26 08:18:42,288: ============================================================
2022-03-26 08:20:31,264: time cost, forward:0.27854030309077016, backward:0.04241584584803763, data cost:0.7780158462409744 
2022-03-26 08:20:31,264: ============================================================
2022-03-26 08:20:31,264: Epoch 5/26 Batch 500/7662 eta: 2 days, 2:52:31.393650	Training Loss 0.5153 (0.5275)	Training Prec@1 77.539 (77.249)	Training Prec@5 84.570 (84.456)	
2022-03-26 08:20:31,264: ============================================================
2022-03-26 08:22:21,148: time cost, forward:0.2808312147806005, backward:0.04301688985553926, data cost:0.7741054266641454 
2022-03-26 08:22:21,149: ============================================================
2022-03-26 08:22:21,149: Epoch 5/26 Batch 600/7662 eta: 2 days, 3:16:08.621757	Training Loss 0.5200 (0.5268)	Training Prec@1 78.711 (77.318)	Training Prec@5 84.961 (84.530)	
2022-03-26 08:22:21,150: ============================================================
2022-03-26 08:24:14,620: time cost, forward:0.2826816449008445, backward:0.0432407729786012, data cost:0.7774767244663703 
2022-03-26 08:24:14,620: ============================================================
2022-03-26 08:24:14,621: Epoch 5/26 Batch 700/7662 eta: 2 days, 4:54:38.332208	Training Loss 0.5276 (0.5264)	Training Prec@1 76.562 (77.408)	Training Prec@5 83.789 (84.602)	
2022-03-26 08:24:14,621: ============================================================
2022-03-26 08:26:04,149: time cost, forward:0.2833254229888152, backward:0.043456797605760406, data cost:0.7755821947759024 
2022-03-26 08:26:04,149: ============================================================
2022-03-26 08:26:04,149: Epoch 5/26 Batch 800/7662 eta: 2 days, 3:02:31.043736	Training Loss 0.5404 (0.5260)	Training Prec@1 75.000 (77.492)	Training Prec@5 82.812 (84.675)	
2022-03-26 08:26:04,150: ============================================================
2022-03-26 08:27:56,149: time cost, forward:0.2838003380810459, backward:0.043508747130532946, data cost:0.7770834899982966 
2022-03-26 08:27:56,149: ============================================================
2022-03-26 08:27:56,150: Epoch 5/26 Batch 900/7662 eta: 2 days, 4:09:45.186953	Training Loss 0.5137 (0.5257)	Training Prec@1 77.930 (77.526)	Training Prec@5 86.523 (84.718)	
2022-03-26 08:27:56,150: ============================================================
2022-03-26 08:29:47,789: time cost, forward:0.28348680635591644, backward:0.04363434951942604, data cost:0.778657264060325 
2022-03-26 08:29:47,790: ============================================================
2022-03-26 08:29:47,790: Epoch 5/26 Batch 1000/7662 eta: 2 days, 3:57:50.025208	Training Loss 0.5078 (0.5253)	Training Prec@1 79.297 (77.591)	Training Prec@5 86.719 (84.776)	
2022-03-26 08:29:47,790: ============================================================
2022-03-26 08:31:38,800: time cost, forward:0.282949118531759, backward:0.043638175134771626, data cost:0.7787941986045803 
2022-03-26 08:31:38,801: ============================================================
2022-03-26 08:31:38,802: Epoch 5/26 Batch 1100/7662 eta: 2 days, 3:38:25.561596	Training Loss 0.5292 (0.5250)	Training Prec@1 77.734 (77.623)	Training Prec@5 87.109 (84.786)	
2022-03-26 08:31:38,802: ============================================================
2022-03-26 08:33:32,586: time cost, forward:0.2828055310985066, backward:0.043643385892713736, data cost:0.7822762593515125 
2022-03-26 08:33:32,586: ============================================================
2022-03-26 08:33:32,586: Epoch 5/26 Batch 1200/7662 eta: 2 days, 4:53:55.720320	Training Loss 0.5239 (0.5250)	Training Prec@1 79.102 (77.644)	Training Prec@5 86.133 (84.804)	
2022-03-26 08:33:32,586: ============================================================
2022-03-26 08:35:20,852: time cost, forward:0.28241490381694556, backward:0.043583527448270945, data cost:0.7804236410212939 
2022-03-26 08:35:20,852: ============================================================
2022-03-26 08:35:20,853: Epoch 5/26 Batch 1300/7662 eta: 2 days, 2:18:11.677280	Training Loss 0.5178 (0.5248)	Training Prec@1 76.562 (77.668)	Training Prec@5 84.375 (84.834)	
2022-03-26 08:35:20,853: ============================================================
2022-03-26 08:37:08,292: time cost, forward:0.2826894541311639, backward:0.04362732125146633, data cost:0.7779440772456727 
2022-03-26 08:37:08,292: ============================================================
2022-03-26 08:37:08,292: Epoch 5/26 Batch 1400/7662 eta: 2 days, 1:53:21.406926	Training Loss 0.5119 (0.5246)	Training Prec@1 79.297 (77.703)	Training Prec@5 86.133 (84.864)	
2022-03-26 08:37:08,292: ============================================================
2022-03-26 08:38:53,502: time cost, forward:0.28190278116268186, backward:0.04366801483301897, data cost:0.7748548722092194 
2022-03-26 08:38:53,503: ============================================================
2022-03-26 08:38:53,503: Epoch 5/26 Batch 1500/7662 eta: 2 days, 0:49:30.788161	Training Loss 0.5158 (0.5244)	Training Prec@1 79.102 (77.732)	Training Prec@5 87.695 (84.892)	
2022-03-26 08:38:53,504: ============================================================
2022-03-26 08:40:43,939: time cost, forward:0.2822081813072696, backward:0.043687364173874844, data cost:0.7750621319115348 
2022-03-26 08:40:43,940: ============================================================
2022-03-26 08:40:43,940: Epoch 5/26 Batch 1600/7662 eta: 2 days, 3:13:10.631156	Training Loss 0.5249 (0.5242)	Training Prec@1 78.125 (77.750)	Training Prec@5 84.766 (84.913)	
2022-03-26 08:40:43,940: ============================================================
2022-03-26 08:42:32,554: time cost, forward:0.2818219764152648, backward:0.043743662724711044, data cost:0.7744835173824102 
2022-03-26 08:42:32,554: ============================================================
2022-03-26 08:42:32,555: Epoch 5/26 Batch 1700/7662 eta: 2 days, 2:20:39.739464	Training Loss 0.5303 (0.5240)	Training Prec@1 73.828 (77.782)	Training Prec@5 81.445 (84.943)	
2022-03-26 08:42:32,555: ============================================================
2022-03-26 08:44:19,883: time cost, forward:0.28128490797873007, backward:0.04371973247644701, data cost:0.7735541114679901 
2022-03-26 08:44:19,883: ============================================================
2022-03-26 08:44:19,883: Epoch 5/26 Batch 1800/7662 eta: 2 days, 1:43:06.959140	Training Loss 0.5122 (0.5237)	Training Prec@1 79.688 (77.833)	Training Prec@5 86.328 (84.979)	
2022-03-26 08:44:19,883: ============================================================
2022-03-26 08:46:10,107: time cost, forward:0.2804024323719059, backward:0.043817607398532826, data cost:0.7745075670275454 
2022-03-26 08:46:10,108: ============================================================
2022-03-26 08:46:10,108: Epoch 5/26 Batch 1900/7662 eta: 2 days, 3:01:45.790776	Training Loss 0.5429 (0.5296)	Training Prec@1 73.242 (76.586)	Training Prec@5 83.008 (83.814)	
2022-03-26 08:46:10,108: ============================================================
2022-03-26 08:47:57,280: time cost, forward:0.2805908568326445, backward:0.043844754246248493, data cost:0.7727998255967736 
2022-03-26 08:47:57,280: ============================================================
2022-03-26 08:47:57,281: Epoch 5/26 Batch 2000/7662 eta: 2 days, 1:35:12.128608	Training Loss 0.5191 (0.5295)	Training Prec@1 77.734 (76.618)	Training Prec@5 85.547 (83.837)	
2022-03-26 08:47:57,281: ============================================================
2022-03-26 08:49:44,986: time cost, forward:0.2809314667582228, backward:0.04387019679000004, data cost:0.7714554384357876 
2022-03-26 08:49:44,987: ============================================================
2022-03-26 08:49:44,987: Epoch 5/26 Batch 2100/7662 eta: 2 days, 1:48:13.093093	Training Loss 0.5269 (0.5291)	Training Prec@1 76.758 (76.690)	Training Prec@5 84.180 (83.893)	
2022-03-26 08:49:44,987: ============================================================
2022-03-26 08:51:32,710: time cost, forward:0.2807356826605283, backward:0.043880282992284476, data cost:0.7708255230919672 
2022-03-26 08:51:32,711: ============================================================
2022-03-26 08:51:32,711: Epoch 5/26 Batch 2200/7662 eta: 2 days, 1:46:55.315767	Training Loss 0.5193 (0.5286)	Training Prec@1 78.516 (76.780)	Training Prec@5 84.961 (83.963)	
2022-03-26 08:51:32,711: ============================================================
2022-03-26 08:53:21,153: time cost, forward:0.280868684586985, backward:0.043861967421138015, data cost:0.7701803183960054 
2022-03-26 08:53:21,154: ============================================================
2022-03-26 08:53:21,154: Epoch 5/26 Batch 2300/7662 eta: 2 days, 2:05:02.843668	Training Loss 0.5161 (0.5281)	Training Prec@1 77.148 (76.870)	Training Prec@5 83.008 (84.043)	
2022-03-26 08:53:21,154: ============================================================
2022-03-26 08:55:08,336: time cost, forward:0.28129574078825825, backward:0.043915536116440626, data cost:0.768584596459793 
2022-03-26 08:55:08,336: ============================================================
2022-03-26 08:55:08,336: Epoch 5/26 Batch 2400/7662 eta: 2 days, 1:28:19.295028	Training Loss 0.5048 (0.5276)	Training Prec@1 81.445 (76.967)	Training Prec@5 86.133 (84.119)	
2022-03-26 08:55:08,336: ============================================================
2022-03-26 08:56:54,366: time cost, forward:0.28122830228740664, backward:0.04402657831702627, data cost:0.7671508589664808 
2022-03-26 08:56:54,366: ============================================================
2022-03-26 08:56:54,366: Epoch 5/26 Batch 2500/7662 eta: 2 days, 0:54:38.826354	Training Loss 0.5116 (0.5271)	Training Prec@1 77.734 (77.053)	Training Prec@5 85.156 (84.192)	
2022-03-26 08:56:54,367: ============================================================
2022-03-26 08:58:56,509: time cost, forward:0.28528896236749923, backward:0.04400480963166469, data cost:0.7682618279326829 
2022-03-26 08:58:56,562: ============================================================
2022-03-26 08:58:56,562: Epoch 5/26 Batch 2600/7662 eta: 2 days, 8:20:02.755777	Training Loss 0.5181 (0.5267)	Training Prec@1 80.469 (77.132)	Training Prec@5 86.133 (84.260)	
2022-03-26 08:58:56,563: ============================================================
2022-03-26 09:00:45,638: time cost, forward:0.2862134172369613, backward:0.043993719951803484, data cost:0.7670955756011827 
2022-03-26 09:00:45,638: ============================================================
2022-03-26 09:00:45,639: Epoch 5/26 Batch 2700/7662 eta: 2 days, 2:15:18.929900	Training Loss 0.5066 (0.5262)	Training Prec@1 82.227 (77.209)	Training Prec@5 87.109 (84.325)	
2022-03-26 09:00:45,639: ============================================================
2022-03-26 09:02:28,740: time cost, forward:0.2854132174423398, backward:0.04398420726712068, data cost:0.7655085673201037 
2022-03-26 09:02:28,741: ============================================================
2022-03-26 09:02:28,741: Epoch 5/26 Batch 2800/7662 eta: 1 day, 23:28:27.700581	Training Loss 0.5245 (0.5258)	Training Prec@1 78.125 (77.293)	Training Prec@5 83.789 (84.390)	
2022-03-26 09:02:28,741: ============================================================
2022-03-26 09:04:17,334: time cost, forward:0.28502714761416226, backward:0.043977867697550944, data cost:0.7654156633885658 
2022-03-26 09:04:17,335: ============================================================
2022-03-26 09:04:17,335: Epoch 5/26 Batch 2900/7662 eta: 2 days, 1:58:22.056334	Training Loss 0.5087 (0.5254)	Training Prec@1 79.492 (77.367)	Training Prec@5 86.914 (84.449)	
2022-03-26 09:04:17,335: ============================================================
2022-03-26 09:06:02,639: time cost, forward:0.28417300263735884, backward:0.04398276878222103, data cost:0.7650387701331556 
2022-03-26 09:06:02,640: ============================================================
2022-03-26 09:06:02,640: Epoch 5/26 Batch 3000/7662 eta: 2 days, 0:25:48.179545	Training Loss 0.5133 (0.5250)	Training Prec@1 78.125 (77.447)	Training Prec@5 82.812 (84.507)	
2022-03-26 09:06:02,640: ============================================================
2022-03-26 09:07:51,105: time cost, forward:0.28400791287614513, backward:0.04400975806515384, data cost:0.7646349117270436 
2022-03-26 09:07:51,106: ============================================================
2022-03-26 09:07:51,106: Epoch 5/26 Batch 3100/7662 eta: 2 days, 1:51:13.243757	Training Loss 0.5123 (0.5246)	Training Prec@1 79.297 (77.523)	Training Prec@5 87.109 (84.571)	
2022-03-26 09:07:51,106: ============================================================
2022-03-26 09:09:39,821: time cost, forward:0.2835557559163319, backward:0.044015785946477835, data cost:0.7650946721169083 
2022-03-26 09:09:39,822: ============================================================
2022-03-26 09:09:39,822: Epoch 5/26 Batch 3200/7662 eta: 2 days, 1:56:18.856572	Training Loss 0.5117 (0.5242)	Training Prec@1 79.492 (77.592)	Training Prec@5 85.742 (84.625)	
2022-03-26 09:09:39,822: ============================================================
2022-03-26 09:11:25,378: time cost, forward:0.2830732506164893, backward:0.04403489226462372, data cost:0.7644429055081241 
2022-03-26 09:11:25,378: ============================================================
2022-03-26 09:11:25,378: Epoch 5/26 Batch 3300/7662 eta: 2 days, 0:27:27.509927	Training Loss 0.5112 (0.5239)	Training Prec@1 79.883 (77.662)	Training Prec@5 87.305 (84.680)	
2022-03-26 09:11:25,379: ============================================================
2022-03-26 09:13:12,930: time cost, forward:0.2827729711675686, backward:0.04400986564548691, data cost:0.7642028472745513 
2022-03-26 09:13:12,930: ============================================================
2022-03-26 09:13:12,931: Epoch 5/26 Batch 3400/7662 eta: 2 days, 1:20:38.488089	Training Loss 0.5261 (0.5235)	Training Prec@1 75.195 (77.735)	Training Prec@5 84.375 (84.736)	
2022-03-26 09:13:12,931: ============================================================
2022-03-26 09:14:58,547: time cost, forward:0.28210886460299084, backward:0.04403331662014778, data cost:0.7637970604941517 
2022-03-26 09:14:58,548: ============================================================
2022-03-26 09:14:58,548: Epoch 5/26 Batch 3500/7662 eta: 2 days, 0:25:37.156552	Training Loss 0.5093 (0.5230)	Training Prec@1 80.273 (77.810)	Training Prec@5 86.328 (84.796)	
2022-03-26 09:14:58,548: ============================================================
2022-03-26 09:16:46,901: time cost, forward:0.2817197589286005, backward:0.04406568718539506, data cost:0.7640844740845091 
2022-03-26 09:16:46,901: ============================================================
2022-03-26 09:16:46,902: Epoch 5/26 Batch 3600/7662 eta: 2 days, 1:39:05.827781	Training Loss 0.5111 (0.5227)	Training Prec@1 80.273 (77.875)	Training Prec@5 84.766 (84.854)	
2022-03-26 09:16:46,902: ============================================================
2022-03-26 09:18:34,890: time cost, forward:0.2813700007309492, backward:0.044083851806277614, data cost:0.7640555369657386 
2022-03-26 09:18:34,892: ============================================================
2022-03-26 09:18:34,893: Epoch 5/26 Batch 3700/7662 eta: 2 days, 1:27:18.805854	Training Loss 0.4995 (0.5223)	Training Prec@1 81.445 (77.944)	Training Prec@5 88.281 (84.904)	
2022-03-26 09:18:34,893: ============================================================
2022-03-26 09:20:22,973: time cost, forward:0.28116899987652794, backward:0.044083289203909894, data cost:0.7640416796629791 
2022-03-26 09:20:22,973: ============================================================
2022-03-26 09:20:22,973: Epoch 5/26 Batch 3800/7662 eta: 2 days, 1:27:59.157368	Training Loss 0.4968 (0.5219)	Training Prec@1 81.445 (78.011)	Training Prec@5 86.719 (84.957)	
2022-03-26 09:20:22,973: ============================================================
2022-03-26 09:22:15,167: time cost, forward:0.2810387259784433, backward:0.044054270830176434, data cost:0.765053227303058 
2022-03-26 09:22:15,169: ============================================================
2022-03-26 09:22:15,169: Epoch 5/26 Batch 3900/7662 eta: 2 days, 3:19:07.043009	Training Loss 0.5040 (0.5216)	Training Prec@1 80.078 (78.075)	Training Prec@5 87.500 (85.009)	
2022-03-26 09:22:15,169: ============================================================
2022-03-26 09:24:06,048: time cost, forward:0.2808468064000291, backward:0.04411659696216016, data cost:0.7655490731918744 
2022-03-26 09:24:06,048: ============================================================
2022-03-26 09:24:06,048: Epoch 5/26 Batch 4000/7662 eta: 2 days, 2:41:08.566536	Training Loss 0.5082 (0.5212)	Training Prec@1 81.055 (78.142)	Training Prec@5 87.500 (85.061)	
2022-03-26 09:24:06,048: ============================================================
2022-03-26 09:25:57,269: time cost, forward:0.28059044265840133, backward:0.04410227108769488, data cost:0.7664338467498616 
2022-03-26 09:25:57,270: ============================================================
2022-03-26 09:25:57,270: Epoch 5/26 Batch 4100/7662 eta: 2 days, 2:48:40.649625	Training Loss 0.5079 (0.5209)	Training Prec@1 81.641 (78.208)	Training Prec@5 87.695 (85.109)	
2022-03-26 09:25:57,270: ============================================================
2022-03-26 09:27:48,238: time cost, forward:0.2805874679848875, backward:0.044145532096105125, data cost:0.7668253778133769 
2022-03-26 09:27:48,238: ============================================================
2022-03-26 09:27:48,238: Epoch 5/26 Batch 4200/7662 eta: 2 days, 2:39:53.238878	Training Loss 0.4998 (0.5205)	Training Prec@1 79.883 (78.275)	Training Prec@5 86.914 (85.162)	
2022-03-26 09:27:48,238: ============================================================
2022-03-26 09:29:37,153: time cost, forward:0.2804446070103846, backward:0.04412402178304477, data cost:0.766829307923957 
2022-03-26 09:29:37,153: ============================================================
2022-03-26 09:29:37,153: Epoch 5/26 Batch 4300/7662 eta: 2 days, 1:41:49.692695	Training Loss 0.5042 (0.5202)	Training Prec@1 82.812 (78.342)	Training Prec@5 88.477 (85.212)	
2022-03-26 09:29:37,153: ============================================================
2022-03-26 09:31:29,015: time cost, forward:0.2804738668236686, backward:0.04415175610711613, data cost:0.7672930552380062 
2022-03-26 09:31:29,016: ============================================================
2022-03-26 09:31:29,016: Epoch 5/26 Batch 4400/7662 eta: 2 days, 3:00:38.882044	Training Loss 0.5035 (0.5198)	Training Prec@1 81.250 (78.410)	Training Prec@5 89.062 (85.267)	
2022-03-26 09:31:29,016: ============================================================
2022-03-26 09:33:17,256: time cost, forward:0.280423418472385, backward:0.04411453802232134, data cost:0.7673341214166638 
2022-03-26 09:33:17,256: ============================================================
2022-03-26 09:33:17,257: Epoch 5/26 Batch 4500/7662 eta: 2 days, 1:19:45.272274	Training Loss 0.5039 (0.5194)	Training Prec@1 81.836 (78.471)	Training Prec@5 87.305 (85.316)	
2022-03-26 09:33:17,257: ============================================================
2022-03-26 09:35:07,691: time cost, forward:0.28037496000871787, backward:0.0438898261875452, data cost:0.7677806145887215 
2022-03-26 09:35:07,692: ============================================================
2022-03-26 09:35:07,693: Epoch 5/26 Batch 4600/7662 eta: 2 days, 2:17:56.196808	Training Loss 0.5094 (0.5191)	Training Prec@1 82.812 (78.533)	Training Prec@5 89.062 (85.367)	
2022-03-26 09:35:07,693: ============================================================
2022-03-26 09:36:57,944: time cost, forward:0.28031837937679155, backward:0.04363794107593407, data cost:0.7683875460298956 
2022-03-26 09:36:57,944: ============================================================
2022-03-26 09:36:57,945: Epoch 5/26 Batch 4700/7662 eta: 2 days, 2:11:04.620840	Training Loss 0.4895 (0.5187)	Training Prec@1 84.766 (78.600)	Training Prec@5 90.234 (85.422)	
2022-03-26 09:36:57,945: ============================================================
2022-03-26 09:38:49,179: time cost, forward:0.280360392317918, backward:0.043475469367457914, data cost:0.7689336311521567 
2022-03-26 09:38:49,179: ============================================================
2022-03-26 09:38:49,180: Epoch 5/26 Batch 4800/7662 eta: 2 days, 2:36:03.945649	Training Loss 0.4955 (0.5184)	Training Prec@1 83.789 (78.668)	Training Prec@5 88.672 (85.478)	
2022-03-26 09:38:49,180: ============================================================
2022-03-26 09:40:41,082: time cost, forward:0.28043069146462524, backward:0.04346551771527968, data cost:0.7693622120547523 
2022-03-26 09:40:41,083: ============================================================
2022-03-26 09:40:41,083: Epoch 5/26 Batch 4900/7662 eta: 2 days, 2:52:26.861845	Training Loss 0.4994 (0.5180)	Training Prec@1 83.008 (78.733)	Training Prec@5 90.039 (85.528)	
2022-03-26 09:40:41,084: ============================================================
2022-03-26 09:42:33,019: time cost, forward:0.28030130390549546, backward:0.043482672717481116, data cost:0.7698961411697622 
2022-03-26 09:42:33,019: ============================================================
2022-03-26 09:42:33,020: Epoch 5/26 Batch 5000/7662 eta: 2 days, 2:51:28.808824	Training Loss 0.5001 (0.5176)	Training Prec@1 82.812 (78.797)	Training Prec@5 89.062 (85.576)	
2022-03-26 09:42:33,020: ============================================================
2022-03-26 09:44:23,058: time cost, forward:0.28044557290863675, backward:0.04351899230636833, data cost:0.7699503435717304 
2022-03-26 09:44:23,058: ============================================================
2022-03-26 09:44:23,059: Epoch 5/26 Batch 5100/7662 eta: 2 days, 1:57:55.315712	Training Loss 0.4960 (0.5173)	Training Prec@1 83.789 (78.863)	Training Prec@5 88.477 (85.629)	
2022-03-26 09:44:23,059: ============================================================
2022-03-26 09:46:18,058: time cost, forward:0.28048365532056396, backward:0.043517350783644326, data cost:0.7709773963954637 
2022-03-26 09:46:18,058: ============================================================
2022-03-26 09:46:18,058: Epoch 5/26 Batch 5200/7662 eta: 2 days, 4:11:09.047356	Training Loss 0.5036 (0.5169)	Training Prec@1 82.617 (78.928)	Training Prec@5 89.258 (85.680)	
2022-03-26 09:46:18,058: ============================================================
2022-03-26 09:48:10,621: time cost, forward:0.2807805148986943, backward:0.04356288770433416, data cost:0.7712162140743488 
2022-03-26 09:48:10,622: ============================================================
2022-03-26 09:48:10,622: Epoch 5/26 Batch 5300/7662 eta: 2 days, 3:02:56.958919	Training Loss 0.4847 (0.5166)	Training Prec@1 84.570 (78.984)	Training Prec@5 90.234 (85.725)	
2022-03-26 09:48:10,622: ============================================================
2022-03-26 09:50:01,993: time cost, forward:0.28082580260820666, backward:0.043600853206184446, data cost:0.7714517063554911 
2022-03-26 09:50:01,994: ============================================================
2022-03-26 09:50:01,994: Epoch 5/26 Batch 5400/7662 eta: 2 days, 2:28:40.129601	Training Loss 0.4985 (0.5162)	Training Prec@1 81.250 (79.046)	Training Prec@5 87.891 (85.770)	
2022-03-26 09:50:01,994: ============================================================
2022-03-26 09:51:52,411: time cost, forward:0.28085574658919865, backward:0.04362454273891917, data cost:0.7715562281337168 
2022-03-26 09:51:52,412: ============================================================
2022-03-26 09:51:52,412: Epoch 5/26 Batch 5500/7662 eta: 2 days, 2:00:53.495006	Training Loss 0.4788 (0.5159)	Training Prec@1 85.938 (79.106)	Training Prec@5 91.016 (85.818)	
2022-03-26 09:51:52,412: ============================================================
2022-03-26 09:53:49,277: time cost, forward:0.2810436041999404, backward:0.04362155944454944, data cost:0.7725333452948632 
2022-03-26 09:53:49,277: ============================================================
2022-03-26 09:53:49,277: Epoch 5/26 Batch 5600/7662 eta: 2 days, 4:54:09.211617	Training Loss 0.8284 (0.5161)	Training Prec@1 2.148 (79.084)	Training Prec@5 4.102 (85.789)	
2022-03-26 09:53:49,277: ============================================================
2022-03-26 09:55:39,636: time cost, forward:0.28119040225802605, backward:0.04363520360030632, data cost:0.7725965222008795 
2022-03-26 09:55:39,637: ============================================================
2022-03-26 09:55:39,637: Epoch 5/26 Batch 5700/7662 eta: 2 days, 1:55:37.307485	Training Loss 0.8252 (0.5219)	Training Prec@1 0.000 (77.698)	Training Prec@5 0.195 (84.288)	
2022-03-26 09:55:39,637: ============================================================
2022-03-26 09:57:34,929: time cost, forward:0.2813450585441109, backward:0.04365039163672692, data cost:0.7732865313740306 
2022-03-26 09:57:34,930: ============================================================
2022-03-26 09:57:34,930: Epoch 5/26 Batch 5800/7662 eta: 2 days, 4:07:36.842349	Training Loss 0.8842 (0.5277)	Training Prec@1 0.000 (76.375)	Training Prec@5 0.000 (82.864)	
2022-03-26 09:57:34,930: ============================================================
2022-03-26 09:59:25,734: time cost, forward:0.28138601547541264, backward:0.04363914533557882, data cost:0.7735119202638565 
2022-03-26 09:59:25,735: ============================================================
2022-03-26 09:59:25,736: Epoch 5/26 Batch 5900/7662 eta: 2 days, 2:04:01.959761	Training Loss 0.8709 (0.5337)	Training Prec@1 0.000 (75.080)	Training Prec@5 0.000 (81.460)	
2022-03-26 09:59:25,736: ============================================================
2022-03-26 10:01:20,184: time cost, forward:0.28154061555584226, backward:0.043703127670415266, data cost:0.7740520893245721 
2022-03-26 10:01:20,184: ============================================================
2022-03-26 10:01:20,184: Epoch 5/26 Batch 6000/7662 eta: 2 days, 3:40:53.490705	Training Loss 0.8645 (0.5392)	Training Prec@1 0.000 (73.829)	Training Prec@5 0.000 (80.102)	
2022-03-26 10:01:20,184: ============================================================
2022-03-26 10:03:12,824: time cost, forward:0.28162825258076435, backward:0.0437348800167566, data cost:0.7743663699886099 
2022-03-26 10:03:12,825: ============================================================
2022-03-26 10:03:12,825: Epoch 5/26 Batch 6100/7662 eta: 2 days, 2:50:01.651832	Training Loss 0.8550 (0.5445)	Training Prec@1 0.000 (72.618)	Training Prec@5 0.000 (78.789)	
2022-03-26 10:03:12,825: ============================================================
2022-03-26 10:05:04,890: time cost, forward:0.2816931801008436, backward:0.043651516350224476, data cost:0.7746911989256036 
2022-03-26 10:05:04,890: ============================================================
2022-03-26 10:05:04,891: Epoch 5/26 Batch 6200/7662 eta: 2 days, 2:32:35.471570	Training Loss 0.8468 (0.5494)	Training Prec@1 0.000 (71.447)	Training Prec@5 0.195 (77.518)	
2022-03-26 10:05:04,891: ============================================================
2022-03-26 10:06:57,315: time cost, forward:0.2818448920158341, backward:0.04365437260543113, data cost:0.7748611901824219 
2022-03-26 10:06:57,315: ============================================================
2022-03-26 10:06:57,315: Epoch 5/26 Batch 6300/7662 eta: 2 days, 2:40:26.105457	Training Loss 0.8406 (0.5541)	Training Prec@1 0.000 (70.313)	Training Prec@5 0.000 (76.288)	
2022-03-26 10:06:57,316: ============================================================
2022-03-26 10:08:49,523: time cost, forward:0.28182411596241885, backward:0.043651109673973544, data cost:0.7751778844260185 
2022-03-26 10:08:49,523: ============================================================
2022-03-26 10:08:49,524: Epoch 5/26 Batch 6400/7662 eta: 2 days, 2:32:41.970496	Training Loss 0.8361 (0.5585)	Training Prec@1 0.000 (69.214)	Training Prec@5 0.000 (75.096)	
2022-03-26 10:08:49,524: ============================================================
2022-03-26 10:10:44,094: time cost, forward:0.28185378406428985, backward:0.0436521718861195, data cost:0.7759395387837072 
2022-03-26 10:10:44,094: ============================================================
2022-03-26 10:10:44,095: Epoch 5/26 Batch 6500/7662 eta: 2 days, 3:34:39.987053	Training Loss 0.8349 (0.5628)	Training Prec@1 0.000 (68.149)	Training Prec@5 0.000 (73.941)	
2022-03-26 10:10:44,095: ============================================================
2022-03-26 10:12:38,156: time cost, forward:0.28186572044252317, backward:0.043666730163349925, data cost:0.7765091685277619 
2022-03-26 10:12:38,157: ============================================================
2022-03-26 10:12:38,157: Epoch 5/26 Batch 6600/7662 eta: 2 days, 3:19:00.536122	Training Loss 0.8338 (0.5669)	Training Prec@1 0.000 (67.116)	Training Prec@5 0.000 (72.821)	
2022-03-26 10:12:38,157: ============================================================
2022-03-26 10:14:30,075: time cost, forward:0.2820618370786178, backward:0.04369817984461838, data cost:0.7764773390901357 
2022-03-26 10:14:30,076: ============================================================
2022-03-26 10:14:30,076: Epoch 5/26 Batch 6700/7662 eta: 2 days, 2:19:17.616653	Training Loss 0.8309 (0.5709)	Training Prec@1 0.000 (66.115)	Training Prec@5 0.000 (71.734)	
2022-03-26 10:14:30,076: ============================================================
2022-03-26 10:16:21,926: time cost, forward:0.2821075085910528, backward:0.043720512183944446, data cost:0.7767096291676849 
2022-03-26 10:16:21,927: ============================================================
2022-03-26 10:16:21,927: Epoch 5/26 Batch 6800/7662 eta: 2 days, 2:15:35.717041	Training Loss 0.8310 (0.5747)	Training Prec@1 0.000 (65.142)	Training Prec@5 0.000 (70.679)	
2022-03-26 10:16:21,927: ============================================================
2022-03-26 10:18:15,598: time cost, forward:0.2822163972427472, backward:0.04373603831997711, data cost:0.7770538783830255 
2022-03-26 10:18:15,599: ============================================================
2022-03-26 10:18:15,600: Epoch 5/26 Batch 6900/7662 eta: 2 days, 3:02:49.067855	Training Loss 0.8293 (0.5784)	Training Prec@1 0.000 (64.198)	Training Prec@5 0.000 (69.655)	
2022-03-26 10:18:15,600: ============================================================
2022-03-26 10:20:10,033: time cost, forward:0.2823339310147487, backward:0.04369085276871174, data cost:0.7775059637469485 
2022-03-26 10:20:10,034: ============================================================
2022-03-26 10:20:10,034: Epoch 5/26 Batch 7000/7662 eta: 2 days, 3:21:26.761666	Training Loss 0.8296 (0.5820)	Training Prec@1 0.000 (63.281)	Training Prec@5 0.000 (68.660)	
2022-03-26 10:20:10,035: ============================================================
2022-03-26 10:22:02,549: time cost, forward:0.28233816983381077, backward:0.0436471319984493, data cost:0.7779251668701408 
2022-03-26 10:22:02,550: ============================================================
2022-03-26 10:22:02,550: Epoch 5/26 Batch 7100/7662 eta: 2 days, 2:27:53.084817	Training Loss 0.8266 (0.5855)	Training Prec@1 0.000 (62.390)	Training Prec@5 0.000 (67.694)	
2022-03-26 10:22:02,550: ============================================================
2022-03-26 10:23:55,170: time cost, forward:0.2825032530070709, backward:0.043677116967121885, data cost:0.7779109363407538 
2022-03-26 10:23:55,171: ============================================================
2022-03-26 10:23:55,172: Epoch 5/26 Batch 7200/7662 eta: 2 days, 2:28:51.566928	Training Loss 0.8270 (0.5888)	Training Prec@1 0.000 (61.523)	Training Prec@5 0.000 (66.754)	
2022-03-26 10:23:55,172: ============================================================
2022-03-26 10:25:49,669: time cost, forward:0.2826678635306776, backward:0.04373010639818356, data cost:0.7782480898973533 
2022-03-26 10:25:49,671: ============================================================
2022-03-26 10:25:49,672: Epoch 5/26 Batch 7300/7662 eta: 2 days, 3:17:28.197384	Training Loss 0.8242 (0.5920)	Training Prec@1 0.000 (60.680)	Training Prec@5 0.000 (65.840)	
2022-03-26 10:25:49,672: ============================================================
2022-03-26 10:27:41,491: time cost, forward:0.2828614241948948, backward:0.04375563819499608, data cost:0.7782720479631379 
2022-03-26 10:27:41,491: ============================================================
2022-03-26 10:27:41,491: Epoch 5/26 Batch 7400/7662 eta: 2 days, 2:03:34.770520	Training Loss 0.8168 (0.5952)	Training Prec@1 0.000 (59.861)	Training Prec@5 0.000 (64.952)	
2022-03-26 10:27:41,491: ============================================================
2022-03-26 10:29:34,522: time cost, forward:0.28298620774533245, backward:0.04377282010760208, data cost:0.7785145571302106 
2022-03-26 10:29:34,523: ============================================================
2022-03-26 10:29:34,524: Epoch 5/26 Batch 7500/7662 eta: 2 days, 2:34:15.367233	Training Loss 0.8035 (0.5980)	Training Prec@1 0.586 (59.064)	Training Prec@5 1.758 (64.091)	
2022-03-26 10:29:34,524: ============================================================
2022-03-26 10:31:29,856: time cost, forward:0.28297527709561343, backward:0.04382798454921204, data cost:0.7790825810930041 
2022-03-26 10:31:29,856: ============================================================
2022-03-26 10:31:29,856: Epoch 5/26 Batch 7600/7662 eta: 2 days, 3:34:05.575313	Training Loss 0.7929 (0.6007)	Training Prec@1 0.391 (58.294)	Training Prec@5 2.148 (63.269)	
2022-03-26 10:31:29,856: ============================================================
2022-03-26 10:32:42,909: Epoch: 5/26 eta: 2 days, 3:32:52.915597	Training Loss 0.8477 (0.6024)	Training Prec@1 0.000 (57.821)	Training Prec@5 0.000 (62.766)
2022-03-26 10:32:42,910: ============================================================
2022-03-26 10:32:42,997: Save Checkpoint...
2022-03-26 10:32:42,999: ============================================================
2022-03-26 10:32:49,367: Save done!
2022-03-26 10:32:49,367: ============================================================
2022-03-26 10:34:44,591: time cost, forward:0.28699721712054627, backward:0.04274453298010007, data cost:0.8266969088352087 
2022-03-26 10:34:44,591: ============================================================
2022-03-26 10:34:44,592: Epoch 6/26 Batch 100/7662 eta: 2 days, 3:25:12.109161	Training Loss 0.8129 (0.8282)	Training Prec@1 0.195 (0.041)	Training Prec@5 0.586 (0.164)	
2022-03-26 10:34:44,592: ============================================================
2022-03-26 10:36:37,316: time cost, forward:0.28849700587478716, backward:0.04287075996398926, data cost:0.8102157834786267 
2022-03-26 10:36:37,316: ============================================================
2022-03-26 10:36:37,316: Epoch 6/26 Batch 200/7662 eta: 2 days, 2:19:12.133605	Training Loss 0.7729 (0.8047)	Training Prec@1 4.102 (1.078)	Training Prec@5 8.008 (2.623)	
2022-03-26 10:36:37,317: ============================================================
2022-03-26 10:38:33,284: time cost, forward:0.28904042515068945, backward:0.04350559926750668, data cost:0.814621414229224 
2022-03-26 10:38:33,285: ============================================================
2022-03-26 10:38:33,285: Epoch 6/26 Batch 300/7662 eta: 2 days, 3:44:08.671253	Training Loss 0.7603 (0.7986)	Training Prec@1 7.617 (1.623)	Training Prec@5 13.477 (3.826)	
2022-03-26 10:38:33,285: ============================================================
2022-03-26 10:40:22,795: time cost, forward:0.2873215729132631, backward:0.04351508527770078, data cost:0.8017569418837851 
2022-03-26 10:40:22,795: ============================================================
2022-03-26 10:40:22,795: Epoch 6/26 Batch 400/7662 eta: 2 days, 0:49:27.663763	Training Loss 0.8468 (0.8032)	Training Prec@1 0.000 (1.831)	Training Prec@5 0.000 (4.092)	
2022-03-26 10:40:22,795: ============================================================
2022-03-26 10:42:17,902: time cost, forward:0.28671104348971993, backward:0.04331047262600763, data cost:0.8071097243047191 
2022-03-26 10:42:17,902: ============================================================
2022-03-26 10:42:17,902: Epoch 6/26 Batch 500/7662 eta: 2 days, 3:17:15.042383	Training Loss 0.8401 (0.8115)	Training Prec@1 0.000 (1.465)	Training Prec@5 0.000 (3.275)	
2022-03-26 10:42:17,902: ============================================================
2022-03-26 10:44:12,251: time cost, forward:0.288174201331672, backward:0.04318819221152686, data cost:0.8052757256019095 
2022-03-26 10:44:12,251: ============================================================
2022-03-26 10:44:12,252: Epoch 6/26 Batch 600/7662 eta: 2 days, 2:55:05.462952	Training Loss 0.8395 (0.8162)	Training Prec@1 0.000 (1.221)	Training Prec@5 0.000 (2.730)	
2022-03-26 10:44:12,252: ============================================================
2022-03-26 10:46:03,889: time cost, forward:0.2882669592790508, backward:0.04274698934159395, data cost:0.8028997511993321 
2022-03-26 10:46:03,889: ============================================================
2022-03-26 10:46:03,890: Epoch 6/26 Batch 700/7662 eta: 2 days, 1:40:47.614989	Training Loss 0.8345 (0.8192)	Training Prec@1 0.000 (1.048)	Training Prec@5 0.000 (2.342)	
2022-03-26 10:46:03,890: ============================================================
2022-03-26 10:47:58,809: time cost, forward:0.28862486762905004, backward:0.04231955590325691, data cost:0.8047099877358677 
2022-03-26 10:47:58,810: ============================================================
2022-03-26 10:47:58,810: Epoch 6/26 Batch 800/7662 eta: 2 days, 3:06:31.168179	Training Loss 0.8327 (0.8211)	Training Prec@1 0.000 (0.916)	Training Prec@5 0.000 (2.050)	
2022-03-26 10:47:58,811: ============================================================
2022-03-26 10:49:49,488: time cost, forward:0.28818346820233, backward:0.0418419464013733, data cost:0.8019426757422119 
2022-03-26 10:49:49,489: ============================================================
2022-03-26 10:49:49,490: Epoch 6/26 Batch 900/7662 eta: 2 days, 1:11:29.884246	Training Loss 0.8301 (0.8223)	Training Prec@1 0.000 (0.816)	Training Prec@5 0.000 (1.826)	
2022-03-26 10:49:49,490: ============================================================
2022-03-26 10:51:49,833: time cost, forward:0.2933772827411915, backward:0.04181097911762165, data cost:0.8047333830469722 
2022-03-26 10:51:49,834: ============================================================
2022-03-26 10:51:49,834: Epoch 6/26 Batch 1000/7662 eta: 2 days, 5:27:14.093087	Training Loss 0.8269 (0.8229)	Training Prec@1 0.000 (0.736)	Training Prec@5 0.000 (1.649)	
2022-03-26 10:51:49,834: ============================================================
2022-03-26 10:53:41,644: time cost, forward:0.29270629583433394, backward:0.041965556860620916, data cost:0.8026823919398661 
2022-03-26 10:53:41,645: ============================================================
2022-03-26 10:53:41,646: Epoch 6/26 Batch 1100/7662 eta: 2 days, 1:37:59.026430	Training Loss 0.8236 (0.8232)	Training Prec@1 0.000 (0.670)	Training Prec@5 0.195 (1.506)	
2022-03-26 10:53:41,646: ============================================================
2022-03-26 10:55:34,968: time cost, forward:0.29204442642250095, backward:0.042249432198697076, data cost:0.8031625212779931 
2022-03-26 10:55:34,968: ============================================================
2022-03-26 10:55:34,969: Epoch 6/26 Batch 1200/7662 eta: 2 days, 2:16:19.892120	Training Loss 0.8183 (0.8230)	Training Prec@1 0.000 (0.618)	Training Prec@5 0.195 (1.392)	
2022-03-26 10:55:34,969: ============================================================
2022-03-26 10:57:31,532: time cost, forward:0.2915936902085114, backward:0.04241261104146181, data cost:0.8049979347554971 
2022-03-26 10:57:31,533: ============================================================
2022-03-26 10:57:31,533: Epoch 6/26 Batch 1300/7662 eta: 2 days, 3:40:40.026597	Training Loss 0.7939 (0.8220)	Training Prec@1 0.195 (0.587)	Training Prec@5 1.953 (1.335)	
2022-03-26 10:57:31,533: ============================================================
2022-03-26 10:59:24,448: time cost, forward:0.2900527563156444, backward:0.042597986784383514, data cost:0.8061676204332375 
2022-03-26 10:59:24,448: ============================================================
2022-03-26 10:59:24,448: Epoch 6/26 Batch 1400/7662 eta: 2 days, 2:01:43.129547	Training Loss 0.7509 (0.8180)	Training Prec@1 8.008 (0.880)	Training Prec@5 16.406 (1.955)	
2022-03-26 10:59:24,448: ============================================================
2022-03-26 11:01:18,079: time cost, forward:0.28977308884074165, backward:0.042820556550283606, data cost:0.8055309846927676 
2022-03-26 11:01:18,079: ============================================================
2022-03-26 11:01:18,079: Epoch 6/26 Batch 1500/7662 eta: 2 days, 2:18:51.782805	Training Loss 0.7287 (0.8130)	Training Prec@1 16.211 (1.579)	Training Prec@5 27.539 (3.207)	
2022-03-26 11:01:18,080: ============================================================
2022-03-26 11:03:12,775: time cost, forward:0.28993068284135526, backward:0.042886532419096166, data cost:0.8058201977429799 
2022-03-26 11:03:12,776: ============================================================
2022-03-26 11:03:12,776: Epoch 6/26 Batch 1600/7662 eta: 2 days, 2:45:14.772933	Training Loss 0.7122 (0.8073)	Training Prec@1 24.609 (2.756)	Training Prec@5 34.766 (5.003)	
2022-03-26 11:03:12,776: ============================================================
2022-03-26 11:05:07,211: time cost, forward:0.29081344843051093, backward:0.04305376930753226, data cost:0.8054646137814581 
2022-03-26 11:05:07,211: ============================================================
2022-03-26 11:05:07,211: Epoch 6/26 Batch 1700/7662 eta: 2 days, 2:36:24.655163	Training Loss 0.6871 (0.8015)	Training Prec@1 36.719 (4.145)	Training Prec@5 47.070 (6.979)	
2022-03-26 11:05:07,211: ============================================================
2022-03-26 11:07:02,071: time cost, forward:0.29110584913723464, backward:0.04329334649196792, data cost:0.8051004107625302 
2022-03-26 11:07:02,072: ============================================================
2022-03-26 11:07:02,072: Epoch 6/26 Batch 1800/7662 eta: 2 days, 2:45:47.323101	Training Loss 0.8371 (0.8007)	Training Prec@1 0.000 (4.562)	Training Prec@5 0.000 (7.486)	
2022-03-26 11:07:02,072: ============================================================
2022-03-26 11:08:55,765: time cost, forward:0.2920816145550897, backward:0.04342254831515971, data cost:0.8041030608584467 
2022-03-26 11:08:55,766: ============================================================
2022-03-26 11:08:55,766: Epoch 6/26 Batch 1900/7662 eta: 2 days, 2:12:56.479985	Training Loss 0.8350 (0.8026)	Training Prec@1 0.000 (4.322)	Training Prec@5 0.000 (7.092)	
2022-03-26 11:08:55,767: ============================================================
2022-03-26 11:10:52,805: time cost, forward:0.2924608893248962, backward:0.0435459321591185, data cost:0.8048412291749589 
2022-03-26 11:10:52,806: ============================================================
2022-03-26 11:10:52,807: Epoch 6/26 Batch 2000/7662 eta: 2 days, 3:39:40.666698	Training Loss 0.8342 (0.8041)	Training Prec@1 0.000 (4.105)	Training Prec@5 0.000 (6.737)	
2022-03-26 11:10:52,807: ============================================================
2022-03-26 11:12:51,966: time cost, forward:0.2931052881970526, backward:0.043579048631076533, data cost:0.8065215916563182 
2022-03-26 11:12:51,967: ============================================================
2022-03-26 11:12:51,967: Epoch 6/26 Batch 2100/7662 eta: 2 days, 4:33:51.059601	Training Loss 0.8023 (0.8050)	Training Prec@1 0.391 (3.914)	Training Prec@5 1.172 (6.430)	
2022-03-26 11:12:51,968: ============================================================
2022-03-26 11:14:47,437: time cost, forward:0.2938004998306406, backward:0.04363496773022855, data cost:0.8066721252009456 
2022-03-26 11:14:47,437: ============================================================
2022-03-26 11:14:47,437: Epoch 6/26 Batch 2200/7662 eta: 2 days, 2:54:14.232686	Training Loss 0.6764 (0.8007)	Training Prec@1 39.258 (4.960)	Training Prec@5 49.805 (7.841)	
2022-03-26 11:14:47,437: ============================================================
2022-03-26 11:16:45,452: time cost, forward:0.29540495926424337, backward:0.04374885154631201, data cost:0.8062852519965784 
2022-03-26 11:16:45,453: ============================================================
2022-03-26 11:16:45,453: Epoch 6/26 Batch 2300/7662 eta: 2 days, 3:59:36.711202	Training Loss 0.6446 (0.7945)	Training Prec@1 53.320 (6.772)	Training Prec@5 62.109 (10.040)	
2022-03-26 11:16:45,453: ============================================================
2022-03-26 11:18:40,850: time cost, forward:0.29596468745395016, backward:0.04383421560385268, data cost:0.806193550212426 
2022-03-26 11:18:40,850: ============================================================
2022-03-26 11:18:40,851: Epoch 6/26 Batch 2400/7662 eta: 2 days, 2:48:28.582246	Training Loss 0.6990 (0.7893)	Training Prec@1 33.789 (8.253)	Training Prec@5 47.656 (11.855)	
2022-03-26 11:18:40,851: ============================================================
2022-03-26 11:20:34,873: time cost, forward:0.2960890627422539, backward:0.04379540913197554, data cost:0.8058460099356515 
2022-03-26 11:20:34,874: ============================================================
2022-03-26 11:20:34,874: Epoch 6/26 Batch 2500/7662 eta: 2 days, 2:10:16.070982	Training Loss 0.6145 (0.7829)	Training Prec@1 61.914 (10.147)	Training Prec@5 70.312 (14.040)	
2022-03-26 11:20:34,874: ============================================================
2022-03-26 11:22:28,958: time cost, forward:0.29612136015574625, backward:0.043697065369538865, data cost:0.8054460766408112 
2022-03-26 11:22:28,959: ============================================================
2022-03-26 11:22:28,959: Epoch 6/26 Batch 2600/7662 eta: 2 days, 2:09:59.861364	Training Loss 0.6034 (0.7761)	Training Prec@1 61.328 (12.156)	Training Prec@5 71.484 (16.274)	
2022-03-26 11:22:28,959: ============================================================
2022-03-26 11:24:24,376: time cost, forward:0.29612894012292873, backward:0.04376911136475966, data cost:0.8056392691761708 
2022-03-26 11:24:24,376: ============================================================
2022-03-26 11:24:24,377: Epoch 6/26 Batch 2700/7662 eta: 2 days, 2:43:14.426958	Training Loss 0.8192 (0.7734)	Training Prec@1 0.000 (12.997)	Training Prec@5 0.195 (17.155)	
2022-03-26 11:24:24,377: ============================================================
2022-03-26 11:26:18,971: time cost, forward:0.29626398837834694, backward:0.04379092671693159, data cost:0.8055539518733159 
2022-03-26 11:26:18,972: ============================================================
2022-03-26 11:26:18,972: Epoch 6/26 Batch 2800/7662 eta: 2 days, 2:19:39.224157	Training Loss 0.5810 (0.7698)	Training Prec@1 65.820 (14.007)	Training Prec@5 76.758 (18.306)	
2022-03-26 11:26:18,972: ============================================================
2022-03-26 11:28:15,254: time cost, forward:0.29632439346879297, backward:0.04385736441768503, data cost:0.8062074606317452 
2022-03-26 11:28:15,254: ============================================================
2022-03-26 11:28:15,254: Epoch 6/26 Batch 2900/7662 eta: 2 days, 3:02:08.946851	Training Loss 0.5646 (0.7632)	Training Prec@1 70.703 (15.872)	Training Prec@5 78.711 (20.332)	
2022-03-26 11:28:15,254: ============================================================
2022-03-26 11:30:10,362: time cost, forward:0.2963680182746666, backward:0.043930166361529896, data cost:0.8062359963150253 
2022-03-26 11:30:10,363: ============================================================
2022-03-26 11:30:10,363: Epoch 6/26 Batch 3000/7662 eta: 2 days, 2:29:20.619183	Training Loss 0.5605 (0.7568)	Training Prec@1 69.922 (17.685)	Training Prec@5 79.102 (22.286)	
2022-03-26 11:30:10,364: ============================================================
2022-03-26 11:32:07,448: time cost, forward:0.29609374024476415, backward:0.04403221387946248, data cost:0.8071449877716488 
2022-03-26 11:32:07,449: ============================================================
2022-03-26 11:32:07,450: Epoch 6/26 Batch 3100/7662 eta: 2 days, 3:19:25.720914	Training Loss 0.5474 (0.7506)	Training Prec@1 73.633 (19.427)	Training Prec@5 81.836 (24.145)	
2022-03-26 11:32:07,450: ============================================================
2022-03-26 11:34:02,625: time cost, forward:0.295955430943357, backward:0.04411903229606416, data cost:0.8073396443500859 
2022-03-26 11:34:02,625: ============================================================
2022-03-26 11:34:02,626: Epoch 6/26 Batch 3200/7662 eta: 2 days, 2:27:16.348116	Training Loss 0.5550 (0.7445)	Training Prec@1 73.438 (21.096)	Training Prec@5 81.445 (25.919)	
2022-03-26 11:34:02,626: ============================================================
2022-03-26 11:36:02,188: time cost, forward:0.2963177164817225, backward:0.04413591323024615, data cost:0.8084311592972759 
2022-03-26 11:36:02,189: ============================================================
2022-03-26 11:36:02,189: Epoch 6/26 Batch 3300/7662 eta: 2 days, 4:20:35.109304	Training Loss 0.5525 (0.7387)	Training Prec@1 72.852 (22.682)	Training Prec@5 81.641 (27.599)	
2022-03-26 11:36:02,189: ============================================================
2022-03-26 11:37:55,928: time cost, forward:0.2963298226356787, backward:0.044198265774315265, data cost:0.807988002322007 
2022-03-26 11:37:55,928: ============================================================
2022-03-26 11:37:55,928: Epoch 6/26 Batch 3400/7662 eta: 2 days, 1:45:42.274212	Training Loss 0.5543 (0.7331)	Training Prec@1 69.922 (24.195)	Training Prec@5 80.664 (29.199)	
2022-03-26 11:37:55,928: ============================================================
2022-03-26 11:39:52,613: time cost, forward:0.29657619890058745, backward:0.04421958421836345, data cost:0.8081052444362068 
2022-03-26 11:39:52,614: ============================================================
2022-03-26 11:39:52,614: Epoch 6/26 Batch 3500/7662 eta: 2 days, 3:01:07.690316	Training Loss 0.5441 (0.7277)	Training Prec@1 76.758 (25.655)	Training Prec@5 83.203 (30.743)	
2022-03-26 11:39:52,614: ============================================================
2022-03-26 11:41:48,715: time cost, forward:0.296804399151178, backward:0.044220307297957014, data cost:0.8083318572270933 
2022-03-26 11:41:48,717: ============================================================
2022-03-26 11:41:48,717: Epoch 6/26 Batch 3600/7662 eta: 2 days, 2:43:53.386461	Training Loss 0.5478 (0.7225)	Training Prec@1 73.242 (27.035)	Training Prec@5 80.469 (32.191)	
2022-03-26 11:41:48,718: ============================================================
2022-03-26 11:43:43,981: time cost, forward:0.2966746774742042, backward:0.044293281999140954, data cost:0.8084197681831263 
2022-03-26 11:43:43,981: ============================================================
2022-03-26 11:43:43,981: Epoch 6/26 Batch 3700/7662 eta: 2 days, 2:19:58.906965	Training Loss 0.5266 (0.7175)	Training Prec@1 78.320 (28.353)	Training Prec@5 86.523 (33.575)	
2022-03-26 11:43:43,982: ============================================================
2022-03-26 11:45:41,753: time cost, forward:0.296613286752141, backward:0.044317555195345755, data cost:0.8092490974681319 
2022-03-26 11:45:41,753: ============================================================
2022-03-26 11:45:41,753: Epoch 6/26 Batch 3800/7662 eta: 2 days, 3:23:42.828006	Training Loss 0.5366 (0.7127)	Training Prec@1 76.953 (29.621)	Training Prec@5 85.352 (34.895)	
2022-03-26 11:45:41,753: ============================================================
2022-03-26 11:47:37,977: time cost, forward:0.2964330758458989, backward:0.04442571633655189, data cost:0.8095724699466037 
2022-03-26 11:47:37,977: ============================================================
2022-03-26 11:47:37,977: Epoch 6/26 Batch 3900/7662 eta: 2 days, 2:41:15.720310	Training Loss 0.5156 (0.7082)	Training Prec@1 82.617 (30.833)	Training Prec@5 87.695 (36.158)	
2022-03-26 11:47:37,978: ============================================================
2022-03-26 11:49:31,463: time cost, forward:0.29614682721030444, backward:0.04442063520240259, data cost:0.8093198749177841 
2022-03-26 11:49:31,463: ============================================================
2022-03-26 11:49:31,464: Epoch 6/26 Batch 4000/7662 eta: 2 days, 1:27:43.149660	Training Loss 0.5252 (0.7038)	Training Prec@1 79.297 (31.992)	Training Prec@5 85.352 (37.360)	
2022-03-26 11:49:31,464: ============================================================
2022-03-26 11:51:25,585: time cost, forward:0.2962085695259744, backward:0.044450886280369716, data cost:0.8090698577683564 
2022-03-26 11:51:25,585: ============================================================
2022-03-26 11:51:25,586: Epoch 6/26 Batch 4100/7662 eta: 2 days, 1:42:26.884120	Training Loss 0.8373 (0.7004)	Training Prec@1 0.000 (32.890)	Training Prec@5 0.000 (38.290)	
2022-03-26 11:51:25,586: ============================================================
2022-03-26 11:53:18,885: time cost, forward:0.29606139390177316, backward:0.04447485225829206, data cost:0.808853847465506 
2022-03-26 11:53:18,886: ============================================================
2022-03-26 11:53:18,886: Epoch 6/26 Batch 4200/7662 eta: 2 days, 1:19:05.220738	Training Loss 0.8330 (0.7036)	Training Prec@1 0.000 (32.107)	Training Prec@5 0.000 (37.379)	
2022-03-26 11:53:18,886: ============================================================
2022-03-26 11:55:17,984: time cost, forward:0.2961333154606026, backward:0.04451279158812951, data cost:0.8097206289531409 
2022-03-26 11:55:17,984: ============================================================
2022-03-26 11:55:17,984: Epoch 6/26 Batch 4300/7662 eta: 2 days, 3:48:31.187006	Training Loss 0.8332 (0.7066)	Training Prec@1 0.000 (31.360)	Training Prec@5 0.000 (36.509)	
2022-03-26 11:55:17,984: ============================================================
2022-03-26 11:57:15,092: time cost, forward:0.2963043284107268, backward:0.04458681229272467, data cost:0.8099761909993027 
2022-03-26 11:57:15,093: ============================================================
2022-03-26 11:57:15,093: Epoch 6/26 Batch 4400/7662 eta: 2 days, 2:54:38.512775	Training Loss 0.8317 (0.7095)	Training Prec@1 0.000 (30.648)	Training Prec@5 0.000 (35.680)	
2022-03-26 11:57:15,093: ============================================================
2022-03-26 11:59:24,332: time cost, forward:0.29860038056747734, backward:0.044619624576030185, data cost:0.8106070712132569 
2022-03-26 11:59:24,333: ============================================================
2022-03-26 11:59:24,333: Epoch 6/26 Batch 4500/7662 eta: 2 days, 8:08:55.529564	Training Loss 0.8332 (0.7122)	Training Prec@1 0.000 (29.966)	Training Prec@5 0.000 (34.887)	
2022-03-26 11:59:24,333: ============================================================
2022-03-26 12:01:26,857: time cost, forward:0.30023391367586105, backward:0.04452207659244226, data cost:0.8107765898234846 
2022-03-26 12:01:26,857: ============================================================
2022-03-26 12:01:26,857: Epoch 6/26 Batch 4600/7662 eta: 2 days, 5:11:49.011820	Training Loss 0.8326 (0.7149)	Training Prec@1 0.000 (29.315)	Training Prec@5 0.000 (34.128)	
2022-03-26 12:01:26,857: ============================================================
2022-03-26 12:03:26,738: time cost, forward:0.30076668114833666, backward:0.04456374999892841, data cost:0.8110985620449542 
2022-03-26 12:03:26,738: ============================================================
2022-03-26 12:03:26,738: Epoch 6/26 Batch 4700/7662 eta: 2 days, 4:00:57.619805	Training Loss 0.8335 (0.7174)	Training Prec@1 0.000 (28.691)	Training Prec@5 0.000 (33.402)	
2022-03-26 12:03:26,738: ============================================================
2022-03-26 12:05:23,637: time cost, forward:0.30084532930295055, backward:0.04459489894723068, data cost:0.8112481556030133 
2022-03-26 12:05:23,637: ============================================================
2022-03-26 12:05:23,637: Epoch 6/26 Batch 4800/7662 eta: 2 days, 2:41:22.726391	Training Loss 0.8338 (0.7198)	Training Prec@1 0.000 (28.093)	Training Prec@5 0.000 (32.706)	
2022-03-26 12:05:23,637: ============================================================
2022-03-26 12:07:22,053: time cost, forward:0.30067881254985346, backward:0.044620134850428234, data cost:0.8117786251931659 
2022-03-26 12:07:22,054: ============================================================
2022-03-26 12:07:22,054: Epoch 6/26 Batch 4900/7662 eta: 2 days, 3:18:53.306772	Training Loss 0.8330 (0.7221)	Training Prec@1 0.000 (27.520)	Training Prec@5 0.000 (32.039)	
2022-03-26 12:07:22,054: ============================================================
2022-03-26 12:09:17,366: time cost, forward:0.30040130440677065, backward:0.04464647154208063, data cost:0.8120968336104202 
2022-03-26 12:09:17,366: ============================================================
2022-03-26 12:09:17,366: Epoch 6/26 Batch 5000/7662 eta: 2 days, 1:56:15.902977	Training Loss 0.8006 (0.7233)	Training Prec@1 15.039 (27.198)	Training Prec@5 22.266 (31.692)	
2022-03-26 12:09:17,367: ============================================================
2022-03-26 12:11:15,408: time cost, forward:0.3003350214108132, backward:0.04468788280513245, data cost:0.8124368203390017 
2022-03-26 12:11:15,409: ============================================================
2022-03-26 12:11:15,409: Epoch 6/26 Batch 5100/7662 eta: 2 days, 3:05:14.077992	Training Loss 0.8710 (0.7247)	Training Prec@1 0.000 (26.952)	Training Prec@5 0.000 (31.435)	
2022-03-26 12:11:15,409: ============================================================
2022-03-26 12:13:09,683: time cost, forward:0.30003449847593194, backward:0.044719621754077836, data cost:0.8125491768242098 
2022-03-26 12:13:09,683: ============================================================
2022-03-26 12:13:09,684: Epoch 6/26 Batch 5200/7662 eta: 2 days, 1:25:28.995703	Training Loss 0.8355 (0.7269)	Training Prec@1 0.000 (26.433)	Training Prec@5 0.000 (30.831)	
2022-03-26 12:13:09,684: ============================================================
2022-03-26 12:15:05,348: time cost, forward:0.29999966287549923, backward:0.0447217856607115, data cost:0.8124852052700476 
2022-03-26 12:15:05,349: ============================================================
2022-03-26 12:15:05,349: Epoch 6/26 Batch 5300/7662 eta: 2 days, 1:59:38.375351	Training Loss 0.8327 (0.7290)	Training Prec@1 0.000 (25.935)	Training Prec@5 0.000 (30.249)	
2022-03-26 12:15:05,349: ============================================================
2022-03-26 12:17:01,937: time cost, forward:0.29992800223471877, backward:0.04470879944590953, data cost:0.8128182547559206 
2022-03-26 12:17:01,938: ============================================================
2022-03-26 12:17:01,938: Epoch 6/26 Batch 5400/7662 eta: 2 days, 2:21:39.631411	Training Loss 0.8325 (0.7309)	Training Prec@1 0.000 (25.454)	Training Prec@5 0.000 (29.689)	
2022-03-26 12:17:01,938: ============================================================
2022-03-26 12:18:59,769: time cost, forward:0.30003179804067825, backward:0.044735975754566684, data cost:0.8129653096480854 
2022-03-26 12:18:59,770: ============================================================
2022-03-26 12:18:59,770: Epoch 6/26 Batch 5500/7662 eta: 2 days, 2:51:54.290329	Training Loss 0.8326 (0.7328)	Training Prec@1 0.000 (24.991)	Training Prec@5 0.000 (29.149)	
2022-03-26 12:18:59,770: ============================================================
2022-03-26 12:20:54,188: time cost, forward:0.29996315554478997, backward:0.0447299007348321, data cost:0.8127976852903454 
2022-03-26 12:20:54,189: ============================================================
2022-03-26 12:20:54,190: Epoch 6/26 Batch 5600/7662 eta: 2 days, 1:21:37.112504	Training Loss 0.8329 (0.7346)	Training Prec@1 0.000 (24.545)	Training Prec@5 0.000 (28.629)	
2022-03-26 12:20:54,190: ============================================================
2022-03-26 12:22:50,156: time cost, forward:0.29989548782901526, backward:0.04474812445880698, data cost:0.8129471427705293 
2022-03-26 12:22:50,157: ============================================================
2022-03-26 12:22:50,157: Epoch 6/26 Batch 5700/7662 eta: 2 days, 1:59:44.614553	Training Loss 0.8322 (0.7363)	Training Prec@1 0.000 (24.114)	Training Prec@5 0.000 (28.127)	
2022-03-26 12:22:50,157: ============================================================
2022-03-26 12:24:45,573: time cost, forward:0.29984253339673717, backward:0.044736521473052605, data cost:0.812942947513339 
2022-03-26 12:24:45,574: ============================================================
2022-03-26 12:24:45,574: Epoch 6/26 Batch 5800/7662 eta: 2 days, 1:43:35.332399	Training Loss 0.8309 (0.7379)	Training Prec@1 0.000 (23.699)	Training Prec@5 0.000 (27.642)	
2022-03-26 12:24:45,574: ============================================================
2022-03-26 12:26:40,451: time cost, forward:0.299777661446576, backward:0.04477425295733904, data cost:0.8128169255047294 
2022-03-26 12:26:40,452: ============================================================
2022-03-26 12:26:40,453: Epoch 6/26 Batch 5900/7662 eta: 2 days, 1:27:45.804640	Training Loss 0.8277 (0.7395)	Training Prec@1 0.000 (23.297)	Training Prec@5 0.195 (27.174)	
2022-03-26 12:26:40,453: ============================================================
2022-03-26 12:28:39,089: time cost, forward:0.29963342359332684, backward:0.044828482043009876, data cost:0.8133852074873171 
2022-03-26 12:28:39,089: ============================================================
2022-03-26 12:28:39,089: Epoch 6/26 Batch 6000/7662 eta: 2 days, 3:02:51.710139	Training Loss 0.8062 (0.7408)	Training Prec@1 0.391 (22.910)	Training Prec@5 1.953 (26.726)	
2022-03-26 12:28:39,090: ============================================================
2022-03-26 12:30:32,519: time cost, forward:0.2995235429745968, backward:0.04484116438862378, data cost:0.8130968628329983 
2022-03-26 12:30:32,520: ============================================================
2022-03-26 12:30:32,520: Epoch 6/26 Batch 6100/7662 eta: 2 days, 0:46:33.797032	Training Loss 0.8743 (0.7422)	Training Prec@1 0.000 (22.572)	Training Prec@5 0.000 (26.351)	
2022-03-26 12:30:32,520: ============================================================
2022-03-26 12:32:22,688: time cost, forward:0.29932234529180474, backward:0.04490660717264647, data cost:0.8123279152464186 
2022-03-26 12:32:22,688: ============================================================
2022-03-26 12:32:22,688: Epoch 6/26 Batch 6200/7662 eta: 1 day, 23:20:33.586452	Training Loss 0.8381 (0.7440)	Training Prec@1 0.000 (22.208)	Training Prec@5 0.000 (25.926)	
2022-03-26 12:32:22,688: ============================================================
2022-03-26 12:34:13,557: time cost, forward:0.2991163121232685, backward:0.044943112383798715, data cost:0.8115946579630516 
2022-03-26 12:34:13,557: ============================================================
2022-03-26 12:34:13,558: Epoch 6/26 Batch 6300/7662 eta: 1 day, 23:36:47.400458	Training Loss 0.8355 (0.7454)	Training Prec@1 0.000 (21.855)	Training Prec@5 0.000 (25.514)	
2022-03-26 12:34:13,558: ============================================================
2022-03-26 12:36:08,253: time cost, forward:0.2989464648572108, backward:0.044942542191016746, data cost:0.8116470872470971 
2022-03-26 12:36:08,254: ============================================================
2022-03-26 12:36:08,254: Epoch 6/26 Batch 6400/7662 eta: 2 days, 1:13:29.695572	Training Loss 0.8343 (0.7468)	Training Prec@1 0.000 (21.514)	Training Prec@5 0.000 (25.116)	
2022-03-26 12:36:08,254: ============================================================
2022-03-26 12:38:03,028: time cost, forward:0.298890065149007, backward:0.0449637891622961, data cost:0.8116350349306528 
2022-03-26 12:38:03,029: ============================================================
2022-03-26 12:38:03,029: Epoch 6/26 Batch 6500/7662 eta: 2 days, 1:13:35.473171	Training Loss 0.8344 (0.7482)	Training Prec@1 0.000 (21.183)	Training Prec@5 0.000 (24.730)	
2022-03-26 12:38:03,029: ============================================================
2022-03-26 12:39:54,665: time cost, forward:0.2987378838387813, backward:0.04497007901676858, data cost:0.8112084081198595 
2022-03-26 12:39:54,665: ============================================================
2022-03-26 12:39:54,665: Epoch 6/26 Batch 6600/7662 eta: 1 day, 23:50:57.940495	Training Loss 0.8348 (0.7495)	Training Prec@1 0.000 (20.862)	Training Prec@5 0.000 (24.355)	
2022-03-26 12:39:54,665: ============================================================
2022-03-26 12:41:49,409: time cost, forward:0.2987117959165025, backward:0.04496900948824714, data cost:0.8111242350401638 
2022-03-26 12:41:49,409: ============================================================
2022-03-26 12:41:49,410: Epoch 6/26 Batch 6700/7662 eta: 2 days, 1:08:59.568200	Training Loss 0.8349 (0.7508)	Training Prec@1 0.000 (20.551)	Training Prec@5 0.000 (23.992)	
2022-03-26 12:41:49,410: ============================================================
2022-03-26 12:43:46,467: time cost, forward:0.2985829319528209, backward:0.04495207876611377, data cost:0.8113995274124224 
2022-03-26 12:43:46,468: ============================================================
2022-03-26 12:43:46,469: Epoch 6/26 Batch 6800/7662 eta: 2 days, 2:06:31.269500	Training Loss 0.8348 (0.7520)	Training Prec@1 0.000 (20.248)	Training Prec@5 0.000 (23.639)	
2022-03-26 12:43:46,469: ============================================================
2022-03-26 12:45:41,477: time cost, forward:0.298545302887173, backward:0.04492667551091796, data cost:0.8114807108447663 
2022-03-26 12:45:41,478: ============================================================
2022-03-26 12:45:41,478: Epoch 6/26 Batch 6900/7662 eta: 2 days, 1:11:57.599331	Training Loss 0.8349 (0.7532)	Training Prec@1 0.000 (19.955)	Training Prec@5 0.000 (23.297)	
2022-03-26 12:45:41,478: ============================================================
2022-03-26 12:47:34,958: time cost, forward:0.29832939874071585, backward:0.044942743830347694, data cost:0.8113827486688162 
2022-03-26 12:47:34,958: ============================================================
2022-03-26 12:47:34,958: Epoch 6/26 Batch 7000/7662 eta: 2 days, 0:30:49.691708	Training Loss 0.8340 (0.7544)	Training Prec@1 0.000 (19.670)	Training Prec@5 0.000 (22.964)	
2022-03-26 12:47:34,958: ============================================================
2022-03-26 12:49:28,670: time cost, forward:0.29815101838477953, backward:0.044970731866881955, data cost:0.8112825396229203 
2022-03-26 12:49:28,670: ============================================================
2022-03-26 12:49:28,670: Epoch 6/26 Batch 7100/7662 eta: 2 days, 0:34:52.807489	Training Loss 0.8362 (0.7555)	Training Prec@1 0.000 (19.393)	Training Prec@5 0.000 (22.640)	
2022-03-26 12:49:28,671: ============================================================
2022-03-26 12:51:23,842: time cost, forward:0.2981522416452481, backward:0.0450163634721894, data cost:0.8110813145704411 
2022-03-26 12:51:23,844: ============================================================
2022-03-26 12:51:23,844: Epoch 6/26 Batch 7200/7662 eta: 2 days, 1:10:25.571876	Training Loss 0.8352 (0.7566)	Training Prec@1 0.000 (19.123)	Training Prec@5 0.000 (22.326)	
2022-03-26 12:51:23,844: ============================================================
2022-03-26 12:53:17,019: time cost, forward:0.29803936859404717, backward:0.044929473297875916, data cost:0.8110809009652348 
2022-03-26 12:53:17,020: ============================================================
2022-03-26 12:53:17,020: Epoch 6/26 Batch 7300/7662 eta: 2 days, 0:17:21.659683	Training Loss 0.8362 (0.7576)	Training Prec@1 0.000 (18.861)	Training Prec@5 0.000 (22.020)	
2022-03-26 12:53:17,020: ============================================================
2022-03-26 12:55:11,001: time cost, forward:0.2980542699458358, backward:0.04479299701376692, data cost:0.8109765379537456 
2022-03-26 12:55:11,001: ============================================================
2022-03-26 12:55:11,001: Epoch 6/26 Batch 7400/7662 eta: 2 days, 0:36:04.572018	Training Loss 0.8346 (0.7587)	Training Prec@1 0.000 (18.607)	Training Prec@5 0.000 (21.723)	
2022-03-26 12:55:11,001: ============================================================
2022-03-26 12:57:06,066: time cost, forward:0.298035743220963, backward:0.044630749541324746, data cost:0.8110374933497908 
2022-03-26 12:57:06,067: ============================================================
2022-03-26 12:57:06,067: Epoch 6/26 Batch 7500/7662 eta: 2 days, 1:01:54.474683	Training Loss 0.8340 (0.7597)	Training Prec@1 0.000 (18.358)	Training Prec@5 0.000 (21.433)	
2022-03-26 12:57:06,067: ============================================================
2022-03-26 12:59:01,590: time cost, forward:0.2981340756838628, backward:0.04464533821911165, data cost:0.8110349129682969 
2022-03-26 12:59:01,591: ============================================================
2022-03-26 12:59:01,591: Epoch 6/26 Batch 7600/7662 eta: 2 days, 1:11:41.889193	Training Loss 0.8343 (0.7607)	Training Prec@1 0.000 (18.117)	Training Prec@5 0.000 (21.151)	
2022-03-26 12:59:01,592: ============================================================
2022-03-26 13:00:16,949: Epoch: 6/26 eta: 2 days, 1:10:29.109019	Training Loss 0.8335 (0.7613)	Training Prec@1 0.000 (17.968)	Training Prec@5 0.000 (20.977)
2022-03-26 13:00:16,950: ============================================================
2022-03-26 13:02:05,873: time cost, forward:0.2726795504791568, backward:0.049730948727540296, data cost:0.7662399320891409 
2022-03-26 13:02:05,875: ============================================================
2022-03-26 13:02:05,875: Epoch 7/26 Batch 100/7662 eta: 1 day, 22:19:06.221792	Training Loss 0.8338 (0.8341)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.195 (0.016)	
2022-03-26 13:02:05,875: ============================================================
2022-03-26 13:03:59,317: time cost, forward:0.28020636759810713, backward:0.0500804084030228, data cost:0.7820374953686892 
2022-03-26 13:03:59,330: ============================================================
2022-03-26 13:03:59,330: Epoch 7/26 Batch 200/7662 eta: 2 days, 0:13:53.198791	Training Loss 0.8354 (0.8341)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.014)	
2022-03-26 13:03:59,330: ============================================================
2022-03-26 13:05:53,725: time cost, forward:0.28714302152295573, backward:0.049660546325122235, data cost:0.7864918413768245 
2022-03-26 13:05:53,726: ============================================================
2022-03-26 13:05:53,726: Epoch 7/26 Batch 300/7662 eta: 2 days, 0:35:58.082475	Training Loss 0.8335 (0.8342)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.011)	
2022-03-26 13:05:53,726: ============================================================
2022-03-26 13:07:48,873: time cost, forward:0.2900538211478327, backward:0.04938497459679319, data cost:0.790731640387896 
2022-03-26 13:07:48,875: ============================================================
2022-03-26 13:07:48,876: Epoch 7/26 Batch 400/7662 eta: 2 days, 0:53:15.606683	Training Loss 0.8337 (0.8342)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.012)	
2022-03-26 13:07:48,876: ============================================================
2022-03-26 13:09:45,437: time cost, forward:0.29374391234709407, backward:0.049030737790889393, data cost:0.7928550080928153 
2022-03-26 13:09:45,438: ============================================================
2022-03-26 13:09:45,439: Epoch 7/26 Batch 500/7662 eta: 2 days, 1:27:19.062427	Training Loss 0.8358 (0.8342)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.013)	
2022-03-26 13:09:45,439: ============================================================
2022-03-26 13:11:40,467: time cost, forward:0.2936691827885496, backward:0.048517375637175446, data cost:0.7972153506812348 
2022-03-26 13:11:40,467: ============================================================
2022-03-26 13:11:40,468: Epoch 7/26 Batch 600/7662 eta: 2 days, 0:46:21.699090	Training Loss 0.8351 (0.8343)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.014)	
2022-03-26 13:11:40,468: ============================================================
2022-03-26 13:13:32,957: time cost, forward:0.2929530351799786, backward:0.048383281977903175, data cost:0.7950584458690856 
2022-03-26 13:13:32,957: ============================================================
2022-03-26 13:13:32,957: Epoch 7/26 Batch 700/7662 eta: 1 day, 23:39:53.122881	Training Loss 0.8320 (0.8342)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.013)	
2022-03-26 13:13:32,957: ============================================================
2022-03-26 13:15:27,451: time cost, forward:0.2940397134262868, backward:0.04851534130874653, data cost:0.7952663958147261 
2022-03-26 13:15:27,452: ============================================================
2022-03-26 13:15:27,453: Epoch 7/26 Batch 800/7662 eta: 2 days, 0:28:57.372204	Training Loss 0.8320 (0.8343)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.013)	
2022-03-26 13:15:27,453: ============================================================
2022-03-26 13:17:23,997: time cost, forward:0.2954103299587534, backward:0.04882792344480521, data cost:0.796797991859767 
2022-03-26 13:17:23,998: ============================================================
2022-03-26 13:17:23,998: Epoch 7/26 Batch 900/7662 eta: 2 days, 1:19:06.898387	Training Loss 0.8358 (0.8343)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.013)	
2022-03-26 13:17:23,998: ============================================================
2022-03-26 13:19:17,580: time cost, forward:0.29542670522008213, backward:0.04875590994551375, data cost:0.7961541852196893 
2022-03-26 13:19:17,580: ============================================================
2022-03-26 13:19:17,580: Epoch 7/26 Batch 1000/7662 eta: 2 days, 0:01:58.774818	Training Loss 0.8336 (0.8342)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.013)	
2022-03-26 13:19:17,581: ============================================================
2022-03-26 13:21:11,649: time cost, forward:0.2951261942987555, backward:0.04867734054308571, data cost:0.7959581297890939 
2022-03-26 13:21:11,649: ============================================================
2022-03-26 13:21:11,650: Epoch 7/26 Batch 1100/7662 eta: 2 days, 0:12:26.111952	Training Loss 0.8328 (0.8342)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.195 (0.013)	
2022-03-26 13:21:11,650: ============================================================
2022-03-26 13:23:04,757: time cost, forward:0.295115619027883, backward:0.04864711717728081, data cost:0.7958375888630388 
2022-03-26 13:23:04,758: ============================================================
2022-03-26 13:23:04,758: Epoch 7/26 Batch 1200/7662 eta: 1 day, 23:46:11.131006	Training Loss 0.8348 (0.8342)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.013)	
2022-03-26 13:23:04,758: ============================================================
2022-03-26 13:24:59,533: time cost, forward:0.29554034784447697, backward:0.048608239381656544, data cost:0.7961115585647243 
2022-03-26 13:24:59,533: ============================================================
2022-03-26 13:24:59,533: Epoch 7/26 Batch 1300/7662 eta: 2 days, 0:26:30.619793	Training Loss 0.8343 (0.8342)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.012)	
2022-03-26 13:24:59,533: ============================================================
2022-03-26 13:26:52,740: time cost, forward:0.29540543474411435, backward:0.04837382734460947, data cost:0.7952435236474802 
2022-03-26 13:26:52,741: ============================================================
2022-03-26 13:26:52,741: Epoch 7/26 Batch 1400/7662 eta: 1 day, 23:44:55.421767	Training Loss 0.8327 (0.8341)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.012)	
2022-03-26 13:26:52,741: ============================================================
2022-03-26 13:28:47,198: time cost, forward:0.2947906631879444, backward:0.04836880612007533, data cost:0.7962328091393001 
2022-03-26 13:28:47,199: ============================================================
2022-03-26 13:28:47,200: Epoch 7/26 Batch 1500/7662 eta: 2 days, 0:14:40.647447	Training Loss 0.8319 (0.8341)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.012)	
2022-03-26 13:28:47,200: ============================================================
2022-03-26 13:30:41,544: time cost, forward:0.2949507234989665, backward:0.048304439112870225, data cost:0.7967760870052621 
2022-03-26 13:30:41,544: ============================================================
2022-03-26 13:30:41,544: Epoch 7/26 Batch 1600/7662 eta: 2 days, 0:09:53.987178	Training Loss 0.8336 (0.8340)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.012)	
2022-03-26 13:30:41,545: ============================================================
2022-03-26 13:32:36,411: time cost, forward:0.294920234837344, backward:0.04822264368776857, data cost:0.7969451928714081 
2022-03-26 13:32:36,411: ============================================================
2022-03-26 13:32:36,412: Epoch 7/26 Batch 1700/7662 eta: 2 days, 0:21:10.861125	Training Loss 0.8334 (0.8340)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.012)	
2022-03-26 13:32:36,412: ============================================================
2022-03-26 13:34:30,701: time cost, forward:0.2950288089796727, backward:0.04817800908833494, data cost:0.797497381032209 
2022-03-26 13:34:30,701: ============================================================
2022-03-26 13:34:30,701: Epoch 7/26 Batch 1800/7662 eta: 2 days, 0:04:40.988382	Training Loss 0.8326 (0.8339)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.013)	
2022-03-26 13:34:30,701: ============================================================
2022-03-26 13:36:24,576: time cost, forward:0.29508588413240533, backward:0.04826118344693136, data cost:0.7969243978437089 
2022-03-26 13:36:24,577: ============================================================
2022-03-26 13:36:24,577: Epoch 7/26 Batch 1900/7662 eta: 1 day, 23:52:20.744009	Training Loss 0.8318 (0.8338)	Training Prec@1 0.195 (0.002)	Training Prec@5 0.391 (0.013)	
2022-03-26 13:36:24,577: ============================================================
2022-03-26 13:38:19,465: time cost, forward:0.29516473694286566, backward:0.048292435306856306, data cost:0.7973946647205133 
2022-03-26 13:38:19,466: ============================================================
2022-03-26 13:38:19,466: Epoch 7/26 Batch 2000/7662 eta: 2 days, 0:15:59.396439	Training Loss 0.8303 (0.8337)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.195 (0.013)	
2022-03-26 13:38:19,466: ============================================================
2022-03-26 13:40:13,744: time cost, forward:0.2949725652433907, backward:0.04827760162099081, data cost:0.7977554348322708 
2022-03-26 13:40:13,744: ============================================================
2022-03-26 13:40:13,744: Epoch 7/26 Batch 2100/7662 eta: 1 day, 23:58:41.507091	Training Loss 0.8313 (0.8335)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.014)	
2022-03-26 13:40:13,744: ============================================================
2022-03-26 13:42:05,873: time cost, forward:0.2945567742972658, backward:0.04826530438761865, data cost:0.7971208653920561 
2022-03-26 13:42:05,875: ============================================================
2022-03-26 13:42:05,875: Epoch 7/26 Batch 2200/7662 eta: 1 day, 23:02:43.350561	Training Loss 0.8303 (0.8333)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.015)	
2022-03-26 13:42:05,875: ============================================================
2022-03-26 13:44:00,035: time cost, forward:0.29411866551847654, backward:0.04828051869482411, data cost:0.7977495511856842 
2022-03-26 13:44:00,035: ============================================================
2022-03-26 13:44:00,035: Epoch 7/26 Batch 2300/7662 eta: 1 day, 23:51:54.775820	Training Loss 0.8276 (0.8331)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.016)	
2022-03-26 13:44:00,036: ============================================================
2022-03-26 13:45:56,111: time cost, forward:0.29379158677931577, backward:0.04825813276363244, data cost:0.7989301042489183 
2022-03-26 13:45:56,111: ============================================================
2022-03-26 13:45:56,111: Epoch 7/26 Batch 2400/7662 eta: 2 days, 0:38:09.704987	Training Loss 0.8261 (0.8328)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.018)	
2022-03-26 13:45:56,111: ============================================================
2022-03-26 13:47:52,200: time cost, forward:0.2937363975283717, backward:0.04829594391543849, data cost:0.7997380583321585 
2022-03-26 13:47:52,200: ============================================================
2022-03-26 13:47:52,200: Epoch 7/26 Batch 2500/7662 eta: 2 days, 0:36:34.104022	Training Loss 0.8195 (0.8323)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.195 (0.022)	
2022-03-26 13:47:52,200: ============================================================
2022-03-26 13:49:45,114: time cost, forward:0.29353577726480823, backward:0.048401572604324324, data cost:0.799270837203316 
2022-03-26 13:49:45,114: ============================================================
2022-03-26 13:49:45,114: Epoch 7/26 Batch 2600/7662 eta: 1 day, 23:14:55.002187	Training Loss 0.8120 (0.8317)	Training Prec@1 0.195 (0.007)	Training Prec@5 0.586 (0.032)	
2022-03-26 13:49:45,115: ============================================================
2022-03-26 13:51:40,045: time cost, forward:0.29334048696604864, backward:0.048420010694268455, data cost:0.7997258076980495 
2022-03-26 13:51:40,046: ============================================================
2022-03-26 13:51:40,047: Epoch 7/26 Batch 2700/7662 eta: 2 days, 0:03:40.097132	Training Loss 0.8041 (0.8308)	Training Prec@1 0.195 (0.014)	Training Prec@5 1.172 (0.056)	
2022-03-26 13:51:40,047: ============================================================
2022-03-26 13:53:37,508: time cost, forward:0.29362756135251616, backward:0.048273858363051717, data cost:0.8008207932418054 
2022-03-26 13:53:37,509: ============================================================
2022-03-26 13:53:37,509: Epoch 7/26 Batch 2800/7662 eta: 2 days, 1:05:11.199870	Training Loss 0.8431 (0.8306)	Training Prec@1 0.000 (0.022)	Training Prec@5 0.000 (0.078)	
2022-03-26 13:53:37,509: ============================================================
2022-03-26 13:55:30,034: time cost, forward:0.29390556345976154, backward:0.04825539768215047, data cost:0.7998919830769661 
2022-03-26 13:55:30,035: ============================================================
2022-03-26 13:55:30,036: Epoch 7/26 Batch 2900/7662 eta: 1 day, 22:59:34.057131	Training Loss 0.7978 (0.8300)	Training Prec@1 0.391 (0.028)	Training Prec@5 1.367 (0.096)	
2022-03-26 13:55:30,036: ============================================================
2022-03-26 13:57:28,529: time cost, forward:0.2937102068977063, backward:0.048262156975909284, data cost:0.8012363677741926 
2022-03-26 13:57:28,529: ============================================================
2022-03-26 13:57:28,529: Epoch 7/26 Batch 3000/7662 eta: 2 days, 1:27:05.938966	Training Loss 0.7857 (0.8287)	Training Prec@1 1.562 (0.057)	Training Prec@5 3.125 (0.175)	
2022-03-26 13:57:28,529: ============================================================
2022-03-26 13:59:22,264: time cost, forward:0.29343176372745955, backward:0.04826630550494076, data cost:0.8012914289078739 
2022-03-26 13:59:22,265: ============================================================
2022-03-26 13:59:22,266: Epoch 7/26 Batch 3100/7662 eta: 1 day, 23:26:04.411881	Training Loss 0.8490 (0.8273)	Training Prec@1 0.000 (0.118)	Training Prec@5 0.195 (0.325)	
2022-03-26 13:59:22,266: ============================================================
2022-03-26 14:01:14,198: time cost, forward:0.2928778539414926, backward:0.04827249135848841, data cost:0.8011079046941616 
2022-03-26 14:01:14,199: ============================================================
2022-03-26 14:01:14,200: Epoch 7/26 Batch 3200/7662 eta: 1 day, 22:39:07.525064	Training Loss 0.8567 (0.8283)	Training Prec@1 0.000 (0.114)	Training Prec@5 0.000 (0.315)	
2022-03-26 14:01:14,200: ============================================================
2022-03-26 14:03:08,969: time cost, forward:0.29303495448153827, backward:0.04818246313281838, data cost:0.8014122135316144 
2022-03-26 14:03:08,970: ============================================================
2022-03-26 14:03:08,970: Epoch 7/26 Batch 3300/7662 eta: 1 day, 23:48:07.525188	Training Loss 0.8457 (0.8290)	Training Prec@1 0.195 (0.111)	Training Prec@5 0.195 (0.306)	
2022-03-26 14:03:08,970: ============================================================
2022-03-26 14:05:05,773: time cost, forward:0.29295840485020924, backward:0.04816438366855443, data cost:0.8022556408744379 
2022-03-26 14:05:05,774: ============================================================
2022-03-26 14:05:05,775: Epoch 7/26 Batch 3400/7662 eta: 2 days, 0:37:01.384676	Training Loss 0.8407 (0.8295)	Training Prec@1 0.000 (0.108)	Training Prec@5 0.000 (0.298)	
2022-03-26 14:05:05,775: ============================================================
2022-03-26 14:06:59,699: time cost, forward:0.2927358341271552, backward:0.048157557857891733, data cost:0.8021460300379053 
2022-03-26 14:06:59,700: ============================================================
2022-03-26 14:06:59,700: Epoch 7/26 Batch 3500/7662 eta: 1 day, 23:23:12.701222	Training Loss 0.8381 (0.8298)	Training Prec@1 0.000 (0.105)	Training Prec@5 0.195 (0.290)	
2022-03-26 14:06:59,700: ============================================================
2022-03-26 14:08:56,919: time cost, forward:0.2929277282915171, backward:0.04809909411422674, data cost:0.803032466192052 
2022-03-26 14:08:56,920: ============================================================
2022-03-26 14:08:56,920: Epoch 7/26 Batch 3600/7662 eta: 2 days, 0:43:29.108888	Training Loss 0.8355 (0.8300)	Training Prec@1 0.000 (0.102)	Training Prec@5 0.195 (0.283)	
2022-03-26 14:08:56,920: ============================================================
2022-03-26 14:10:41,016: time cost, forward:0.2919495650387094, backward:0.04803207469134758, data cost:0.8010565710570497 
2022-03-26 14:10:41,018: ============================================================
2022-03-26 14:10:41,018: Epoch 7/26 Batch 3700/7662 eta: 1 day, 19:14:29.040867	Training Loss 0.8357 (0.8301)	Training Prec@1 0.000 (0.100)	Training Prec@5 0.000 (0.276)	
2022-03-26 14:10:41,018: ============================================================
2022-03-26 14:12:37,937: time cost, forward:0.2918780524657255, backward:0.04803488693227263, data cost:0.8019346103256518 
2022-03-26 14:12:37,937: ============================================================
2022-03-26 14:12:37,938: Epoch 7/26 Batch 3800/7662 eta: 2 days, 0:32:06.216720	Training Loss 0.8335 (0.8301)	Training Prec@1 0.000 (0.097)	Training Prec@5 0.000 (0.270)	
2022-03-26 14:12:37,938: ============================================================
2022-03-26 14:14:29,833: time cost, forward:0.29166142651288135, backward:0.04794294634180883, data cost:0.8017407941585872 
2022-03-26 14:14:29,834: ============================================================
2022-03-26 14:14:29,834: Epoch 7/26 Batch 3900/7662 eta: 1 day, 22:25:07.107975	Training Loss 0.8282 (0.8301)	Training Prec@1 0.195 (0.095)	Training Prec@5 0.195 (0.265)	
2022-03-26 14:14:29,834: ============================================================
2022-03-26 14:16:25,811: time cost, forward:0.2915685947133947, backward:0.04782748574106417, data cost:0.8023289650432704 
2022-03-26 14:16:25,811: ============================================================
2022-03-26 14:16:25,811: Epoch 7/26 Batch 4000/7662 eta: 2 days, 0:04:45.795337	Training Loss 0.8281 (0.8301)	Training Prec@1 0.000 (0.093)	Training Prec@5 0.195 (0.259)	
2022-03-26 14:16:25,812: ============================================================
2022-03-26 14:18:23,224: time cost, forward:0.29153828947798277, backward:0.047833786327160115, data cost:0.8032313821722339 
2022-03-26 14:18:23,224: ============================================================
2022-03-26 14:18:23,225: Epoch 7/26 Batch 4100/7662 eta: 2 days, 0:38:31.081078	Training Loss 0.8253 (0.8300)	Training Prec@1 0.000 (0.091)	Training Prec@5 0.195 (0.254)	
2022-03-26 14:18:23,225: ============================================================
2022-03-26 14:20:21,167: time cost, forward:0.2914850176388549, backward:0.047755925591203764, data cost:0.8041034073567328 
2022-03-26 14:20:21,168: ============================================================
2022-03-26 14:20:21,169: Epoch 7/26 Batch 4200/7662 eta: 2 days, 0:49:45.017965	Training Loss 0.8235 (0.8299)	Training Prec@1 0.000 (0.090)	Training Prec@5 0.000 (0.251)	
2022-03-26 14:20:21,169: ============================================================
2022-03-26 14:22:17,811: time cost, forward:0.2916145343008527, backward:0.04772672062004464, data cost:0.8046593926179739 
2022-03-26 14:22:17,811: ============================================================
2022-03-26 14:22:17,811: Epoch 7/26 Batch 4300/7662 eta: 2 days, 0:15:28.885061	Training Loss 0.8154 (0.8297)	Training Prec@1 0.586 (0.089)	Training Prec@5 0.781 (0.250)	
2022-03-26 14:22:17,812: ============================================================
2022-03-26 14:24:15,754: time cost, forward:0.29183291527162114, backward:0.047627721870181286, data cost:0.8051539285260456 
2022-03-26 14:24:15,755: ============================================================
2022-03-26 14:24:15,755: Epoch 7/26 Batch 4400/7662 eta: 2 days, 0:45:48.253315	Training Loss 0.7985 (0.8292)	Training Prec@1 0.781 (0.093)	Training Prec@5 1.562 (0.261)	
2022-03-26 14:24:15,755: ============================================================
2022-03-26 14:26:13,834: time cost, forward:0.292163067591087, backward:0.047575767847346476, data cost:0.8058183174658998 
2022-03-26 14:26:13,834: ============================================================
2022-03-26 14:26:13,834: Epoch 7/26 Batch 4500/7662 eta: 2 days, 0:47:12.837556	Training Loss 0.7852 (0.8283)	Training Prec@1 1.953 (0.117)	Training Prec@5 4.297 (0.323)	
2022-03-26 14:26:13,835: ============================================================
2022-03-26 14:28:11,376: time cost, forward:0.2925788746576875, backward:0.04755817726659474, data cost:0.8060836237289253 
2022-03-26 14:28:11,377: ============================================================
2022-03-26 14:28:11,377: Epoch 7/26 Batch 4600/7662 eta: 2 days, 0:31:56.112140	Training Loss 0.7679 (0.8271)	Training Prec@1 3.516 (0.179)	Training Prec@5 9.180 (0.464)	
2022-03-26 14:28:11,377: ============================================================
2022-03-26 14:30:09,742: time cost, forward:0.2930896903738414, backward:0.04747174120527756, data cost:0.8063834903341173 
2022-03-26 14:30:09,742: ============================================================
2022-03-26 14:30:09,743: Epoch 7/26 Batch 4700/7662 eta: 2 days, 0:50:21.747439	Training Loss 0.8310 (0.8265)	Training Prec@1 0.195 (0.230)	Training Prec@5 0.391 (0.572)	
2022-03-26 14:30:09,743: ============================================================
2022-03-26 14:32:05,484: time cost, forward:0.293533132433469, backward:0.047452735066239995, data cost:0.8062083502068175 
2022-03-26 14:32:05,484: ============================================================
2022-03-26 14:32:05,484: Epoch 7/26 Batch 4800/7662 eta: 1 day, 23:43:28.410726	Training Loss 0.7954 (0.8263)	Training Prec@1 0.781 (0.229)	Training Prec@5 2.539 (0.570)	
2022-03-26 14:32:05,485: ============================================================
2022-03-26 14:34:03,474: time cost, forward:0.293681325122127, backward:0.04741578020351618, data cost:0.8067653950537241 
2022-03-26 14:34:03,474: ============================================================
2022-03-26 14:34:03,475: Epoch 7/26 Batch 4900/7662 eta: 2 days, 0:37:07.799851	Training Loss 0.7526 (0.8250)	Training Prec@1 8.789 (0.338)	Training Prec@5 15.820 (0.791)	
2022-03-26 14:34:03,475: ============================================================
2022-03-26 14:36:03,672: time cost, forward:0.29395611769296, backward:0.047373588239223774, data cost:0.807468541075311 
2022-03-26 14:36:03,673: ============================================================
2022-03-26 14:36:03,673: Epoch 7/26 Batch 5000/7662 eta: 2 days, 1:29:43.341984	Training Loss 0.7385 (0.8234)	Training Prec@1 11.914 (0.538)	Training Prec@5 21.484 (1.151)	
2022-03-26 14:36:03,673: ============================================================
2022-03-26 14:37:59,417: time cost, forward:0.2940124288496491, backward:0.04730384081900178, data cost:0.807773554879185 
2022-03-26 14:37:59,417: ============================================================
2022-03-26 14:37:59,417: Epoch 7/26 Batch 5100/7662 eta: 1 day, 23:37:44.439771	Training Loss 0.8258 (0.8227)	Training Prec@1 0.195 (0.651)	Training Prec@5 0.586 (1.344)	
2022-03-26 14:37:59,417: ============================================================
2022-03-26 14:39:59,390: time cost, forward:0.294058819967271, backward:0.047318748016269375, data cost:0.8085531625272586 
2022-03-26 14:39:59,390: ============================================================
2022-03-26 14:39:59,391: Epoch 7/26 Batch 5200/7662 eta: 2 days, 1:20:09.833619	Training Loss 0.7304 (0.8217)	Training Prec@1 16.016 (0.775)	Training Prec@5 26.172 (1.557)	
2022-03-26 14:39:59,391: ============================================================
2022-03-26 14:41:55,273: time cost, forward:0.2941319871385225, backward:0.047228934787808555, data cost:0.80888984135399 
2022-03-26 14:41:55,273: ============================================================
2022-03-26 14:41:55,274: Epoch 7/26 Batch 5300/7662 eta: 1 day, 23:37:18.259010	Training Loss 0.7014 (0.8198)	Training Prec@1 27.344 (1.134)	Training Prec@5 38.281 (2.110)	
2022-03-26 14:41:55,274: ============================================================
2022-03-26 14:43:51,902: time cost, forward:0.2943232709510522, backward:0.04722689955206707, data cost:0.8088802616117972 
2022-03-26 14:43:51,902: ============================================================
2022-03-26 14:43:51,902: Epoch 7/26 Batch 5400/7662 eta: 1 day, 23:53:45.221093	Training Loss 0.7394 (0.8178)	Training Prec@1 9.961 (1.558)	Training Prec@5 18.555 (2.724)	
2022-03-26 14:43:51,903: ============================================================
2022-03-26 14:45:50,198: time cost, forward:0.2944828615467816, backward:0.047197632972577154, data cost:0.8093404030231893 
2022-03-26 14:45:50,199: ============================================================
2022-03-26 14:45:50,199: Epoch 7/26 Batch 5500/7662 eta: 2 days, 0:32:52.564460	Training Loss 0.6657 (0.8154)	Training Prec@1 38.281 (2.116)	Training Prec@5 50.977 (3.480)	
2022-03-26 14:45:50,199: ============================================================
2022-03-26 14:47:46,696: time cost, forward:0.2945954243952429, backward:0.047174747979391855, data cost:0.8095809461645067 
2022-03-26 14:47:46,696: ============================================================
2022-03-26 14:47:46,697: Epoch 7/26 Batch 5600/7662 eta: 1 day, 23:46:38.248484	Training Loss 0.8156 (0.8151)	Training Prec@1 0.000 (2.223)	Training Prec@5 0.781 (3.611)	
2022-03-26 14:47:46,697: ============================================================
2022-03-26 14:49:43,982: time cost, forward:0.29456154177703026, backward:0.04713391483739962, data cost:0.8100078835113359 
2022-03-26 14:49:43,982: ============================================================
2022-03-26 14:49:43,983: Epoch 7/26 Batch 5700/7662 eta: 2 days, 0:04:04.855318	Training Loss 0.6667 (0.8134)	Training Prec@1 41.016 (2.593)	Training Prec@5 52.539 (4.117)	
2022-03-26 14:49:43,983: ============================================================
2022-03-26 14:51:40,701: time cost, forward:0.29444877927437757, backward:0.04708150099589714, data cost:0.8104563767097185 
2022-03-26 14:51:40,701: ============================================================
2022-03-26 14:51:40,701: Epoch 7/26 Batch 5800/7662 eta: 1 day, 23:48:11.331558	Training Loss 0.6353 (0.8107)	Training Prec@1 52.930 (3.302)	Training Prec@5 62.695 (5.005)	
2022-03-26 14:51:40,701: ============================================================
2022-03-26 14:53:35,858: time cost, forward:0.2944147892373359, backward:0.04704791211459491, data cost:0.8104927505875346 
2022-03-26 14:53:35,859: ============================================================
2022-03-26 14:53:35,859: Epoch 7/26 Batch 5900/7662 eta: 1 day, 23:07:54.129564	Training Loss 0.6851 (0.8078)	Training Prec@1 36.914 (4.107)	Training Prec@5 50.586 (5.974)	
2022-03-26 14:53:35,859: ============================================================
2022-03-26 14:55:32,809: time cost, forward:0.29447411616497543, backward:0.047030320384538575, data cost:0.8106125280208877 
2022-03-26 14:55:32,810: ============================================================
2022-03-26 14:55:32,810: Epoch 7/26 Batch 6000/7662 eta: 1 day, 23:50:00.084459	Training Loss 0.6005 (0.8046)	Training Prec@1 61.133 (4.963)	Training Prec@5 71.875 (6.980)	
2022-03-26 14:55:32,810: ============================================================
2022-03-26 14:57:28,996: time cost, forward:0.29435881803731173, backward:0.04705030117919942, data cost:0.810943188012907 
2022-03-26 14:57:28,996: ============================================================
2022-03-26 14:57:28,996: Epoch 7/26 Batch 6100/7662 eta: 1 day, 23:29:17.913172	Training Loss 0.8699 (0.8050)	Training Prec@1 0.000 (5.069)	Training Prec@5 0.000 (7.089)	
2022-03-26 14:57:28,997: ============================================================
2022-03-26 14:59:26,344: time cost, forward:0.29437563545878115, backward:0.04703507409554986, data cost:0.8113274018521038 
2022-03-26 14:59:26,344: ============================================================
2022-03-26 14:59:26,344: Epoch 7/26 Batch 6200/7662 eta: 1 day, 23:55:48.899739	Training Loss 0.8437 (0.8058)	Training Prec@1 0.000 (4.987)	Training Prec@5 0.000 (6.975)	
2022-03-26 14:59:26,344: ============================================================
2022-03-26 15:01:24,524: time cost, forward:0.2944079868603101, backward:0.0470158828215138, data cost:0.8116886461324249 
2022-03-26 15:01:24,525: ============================================================
2022-03-26 15:01:24,526: Epoch 7/26 Batch 6300/7662 eta: 2 days, 0:14:17.439399	Training Loss 0.8363 (0.8064)	Training Prec@1 0.000 (4.908)	Training Prec@5 0.000 (6.864)	
2022-03-26 15:01:24,526: ============================================================
2022-03-26 15:03:21,127: time cost, forward:0.29451417460965446, backward:0.04698657281586185, data cost:0.8118584074812357 
2022-03-26 15:03:21,128: ============================================================
2022-03-26 15:03:21,129: Epoch 7/26 Batch 6400/7662 eta: 1 day, 23:33:40.798962	Training Loss 0.8344 (0.8068)	Training Prec@1 0.000 (4.832)	Training Prec@5 0.000 (6.757)	
2022-03-26 15:03:21,129: ============================================================
2022-03-26 15:05:17,237: time cost, forward:0.29455991740739607, backward:0.047001201788413195, data cost:0.81190824380268 
2022-03-26 15:05:17,238: ============================================================
2022-03-26 15:05:17,238: Epoch 7/26 Batch 6500/7662 eta: 1 day, 23:19:40.238146	Training Loss 0.8292 (0.8072)	Training Prec@1 0.000 (4.757)	Training Prec@5 0.000 (6.654)	
2022-03-26 15:05:17,238: ============================================================
2022-03-26 15:07:15,519: time cost, forward:0.2946334192654927, backward:0.04698192135712146, data cost:0.8123109578038549 
2022-03-26 15:07:15,520: ============================================================
2022-03-26 15:07:15,520: Epoch 7/26 Batch 6600/7662 eta: 2 days, 0:10:49.594107	Training Loss 0.8292 (0.8076)	Training Prec@1 0.000 (4.685)	Training Prec@5 0.195 (6.554)	
2022-03-26 15:07:15,520: ============================================================
2022-03-26 15:09:13,639: time cost, forward:0.2947690053775535, backward:0.04680713733144083, data cost:0.8126306153354511 
2022-03-26 15:09:13,640: ============================================================
2022-03-26 15:09:13,640: Epoch 7/26 Batch 6700/7662 eta: 2 days, 0:04:54.376122	Training Loss 0.8228 (0.8079)	Training Prec@1 0.000 (4.616)	Training Prec@5 0.000 (6.457)	
2022-03-26 15:09:13,640: ============================================================
2022-03-26 15:11:08,528: time cost, forward:0.2947006616229116, backward:0.04676198236976306, data cost:0.8127756558160323 
2022-03-26 15:11:08,529: ============================================================
2022-03-26 15:11:08,529: Epoch 7/26 Batch 6800/7662 eta: 1 day, 22:44:04.371363	Training Loss 0.8136 (0.8081)	Training Prec@1 0.195 (4.549)	Training Prec@5 0.586 (6.365)	
2022-03-26 15:11:08,529: ============================================================
2022-03-26 15:13:05,480: time cost, forward:0.2947231879664912, backward:0.04673949751858781, data cost:0.8128951883157072 
2022-03-26 15:13:05,480: ============================================================
2022-03-26 15:13:05,481: Epoch 7/26 Batch 6900/7662 eta: 1 day, 23:32:28.710128	Training Loss 0.8555 (0.8081)	Training Prec@1 0.000 (4.501)	Training Prec@5 0.000 (6.314)	
2022-03-26 15:13:05,481: ============================================================
2022-03-26 15:15:03,102: time cost, forward:0.2947080321679168, backward:0.0467684411341709, data cost:0.8133067946073617 
2022-03-26 15:15:03,102: ============================================================
2022-03-26 15:15:03,103: Epoch 7/26 Batch 7000/7662 eta: 1 day, 23:46:51.318425	Training Loss 0.8410 (0.8087)	Training Prec@1 0.000 (4.437)	Training Prec@5 0.000 (6.224)	
2022-03-26 15:15:03,103: ============================================================
2022-03-26 15:17:00,805: time cost, forward:0.2947042957630472, backward:0.04678783394582071, data cost:0.8135977162158159 
2022-03-26 15:17:00,805: ============================================================
2022-03-26 15:17:00,805: Epoch 7/26 Batch 7100/7662 eta: 1 day, 23:46:51.598483	Training Loss 0.8350 (0.8091)	Training Prec@1 0.000 (4.375)	Training Prec@5 0.000 (6.138)	
2022-03-26 15:17:00,805: ============================================================
2022-03-26 15:18:55,112: time cost, forward:0.2947637901353843, backward:0.04677433148906171, data cost:0.8133338224657676 
2022-03-26 15:18:55,113: ============================================================
2022-03-26 15:18:55,113: Epoch 7/26 Batch 7200/7662 eta: 1 day, 22:22:16.433247	Training Loss 0.8233 (0.8094)	Training Prec@1 0.195 (4.315)	Training Prec@5 0.195 (6.056)	
2022-03-26 15:18:55,113: ============================================================
2022-03-26 15:20:51,676: time cost, forward:0.29478006311305044, backward:0.046737649993122986, data cost:0.8134169763106975 
2022-03-26 15:20:51,676: ============================================================
2022-03-26 15:20:51,677: Epoch 7/26 Batch 7300/7662 eta: 1 day, 23:15:14.111057	Training Loss 0.7781 (0.8094)	Training Prec@1 4.688 (4.266)	Training Prec@5 9.180 (5.997)	
2022-03-26 15:20:51,677: ============================================================
2022-03-26 15:22:49,041: time cost, forward:0.29480907997258177, backward:0.04669458026063653, data cost:0.8138019913579181 
2022-03-26 15:22:49,041: ============================================================
2022-03-26 15:22:49,041: Epoch 7/26 Batch 7400/7662 eta: 1 day, 23:32:45.735411	Training Loss 0.7957 (0.8085)	Training Prec@1 0.391 (4.431)	Training Prec@5 1.562 (6.259)	
2022-03-26 15:22:49,041: ============================================================
2022-03-26 15:24:45,981: time cost, forward:0.2948943476531327, backward:0.0466765009064502, data cost:0.8139222486287153 
2022-03-26 15:24:45,981: ============================================================
2022-03-26 15:24:45,981: Epoch 7/26 Batch 7500/7662 eta: 1 day, 23:20:29.309007	Training Loss 0.8463 (0.8075)	Training Prec@1 0.000 (4.687)	Training Prec@5 0.000 (6.605)	
2022-03-26 15:24:45,981: ============================================================
2022-03-26 15:26:43,949: time cost, forward:0.2949404300459279, backward:0.046654365520474785, data cost:0.8140939014305298 
2022-03-26 15:26:43,950: ============================================================
2022-03-26 15:26:43,950: Epoch 7/26 Batch 7600/7662 eta: 1 day, 23:43:31.468946	Training Loss 0.8367 (0.8080)	Training Prec@1 0.000 (4.625)	Training Prec@5 0.000 (6.518)	
2022-03-26 15:26:43,951: ============================================================
2022-03-26 15:28:05,382: Epoch: 7/26 eta: 1 day, 23:42:17.148373	Training Loss 0.8325 (0.8082)	Training Prec@1 0.000 (4.587)	Training Prec@5 0.000 (6.465)
2022-03-26 15:28:05,383: ============================================================
2022-03-26 15:30:00,399: time cost, forward:0.2657970394751038, backward:0.03984873704235963, data cost:0.8471326346349235 
2022-03-26 15:30:00,400: ============================================================
2022-03-26 15:30:00,400: Epoch 8/26 Batch 100/7662 eta: 1 day, 22:20:40.671258	Training Loss 0.8316 (0.8301)	Training Prec@1 0.000 (0.018)	Training Prec@5 0.195 (0.077)	
2022-03-26 15:30:00,400: ============================================================
2022-03-26 15:31:52,895: time cost, forward:0.26965072166979615, backward:0.04078307702912757, data cost:0.826696306017775 
2022-03-26 15:31:52,896: ============================================================
2022-03-26 15:31:52,896: Epoch 8/26 Batch 200/7662 eta: 1 day, 21:25:45.400474	Training Loss 0.8223 (0.8281)	Training Prec@1 0.195 (0.029)	Training Prec@5 0.195 (0.096)	
2022-03-26 15:31:52,896: ============================================================
2022-03-26 15:33:45,575: time cost, forward:0.2763654699293666, backward:0.04152452507146625, data cost:0.816853018508707 
2022-03-26 15:33:45,575: ============================================================
2022-03-26 15:33:45,576: Epoch 8/26 Batch 300/7662 eta: 1 day, 21:28:19.525568	Training Loss 0.8182 (0.8257)	Training Prec@1 0.195 (0.048)	Training Prec@5 0.195 (0.150)	
2022-03-26 15:33:45,576: ============================================================
2022-03-26 15:35:42,304: time cost, forward:0.2781940020415418, backward:0.042259472653381806, data cost:0.8221587035291475 
2022-03-26 15:35:42,305: ============================================================
2022-03-26 15:35:42,305: Epoch 8/26 Batch 400/7662 eta: 1 day, 23:04:26.842378	Training Loss 0.8044 (0.8220)	Training Prec@1 0.586 (0.107)	Training Prec@5 1.562 (0.303)	
2022-03-26 15:35:42,305: ============================================================
2022-03-26 15:37:36,699: time cost, forward:0.2790183700874955, backward:0.04250385049349798, data cost:0.8213327380124935 
2022-03-26 15:37:36,699: ============================================================
2022-03-26 15:37:36,699: Epoch 8/26 Batch 500/7662 eta: 1 day, 22:06:01.940790	Training Loss 0.7065 (0.8090)	Training Prec@1 25.391 (2.239)	Training Prec@5 39.453 (3.743)	
2022-03-26 15:37:36,699: ============================================================
2022-03-26 15:39:32,198: time cost, forward:0.2783987056432861, backward:0.042954068749098226, data cost:0.8234194089255866 
2022-03-26 15:39:32,198: ============================================================
2022-03-26 15:39:32,199: Epoch 8/26 Batch 600/7662 eta: 1 day, 22:30:49.823133	Training Loss 0.6642 (0.7881)	Training Prec@1 42.773 (8.005)	Training Prec@5 53.711 (11.262)	
2022-03-26 15:39:32,199: ============================================================
2022-03-26 15:41:30,922: time cost, forward:0.279868044055071, backward:0.04362322946474787, data cost:0.8267119896087864 
2022-03-26 15:41:30,923: ============================================================
2022-03-26 15:41:30,923: Epoch 8/26 Batch 700/7662 eta: 1 day, 23:46:46.790205	Training Loss 0.6476 (0.7708)	Training Prec@1 47.266 (12.973)	Training Prec@5 58.398 (17.413)	
2022-03-26 15:41:30,923: ============================================================
2022-03-26 15:43:29,146: time cost, forward:0.2809625734226575, backward:0.04434405996444377, data cost:0.8293216419458688 
2022-03-26 15:43:29,147: ============================================================
2022-03-26 15:43:29,147: Epoch 8/26 Batch 800/7662 eta: 1 day, 23:32:43.181128	Training Loss 0.6116 (0.7527)	Training Prec@1 59.961 (18.192)	Training Prec@5 68.359 (23.429)	
2022-03-26 15:43:29,147: ============================================================
2022-03-26 15:45:29,026: time cost, forward:0.285300000490946, backward:0.04449601831107304, data cost:0.8297568781092116 
2022-03-26 15:45:29,026: ============================================================
2022-03-26 15:45:29,026: Epoch 8/26 Batch 900/7662 eta: 2 days, 0:10:40.389585	Training Loss 0.6970 (0.7494)	Training Prec@1 34.180 (19.127)	Training Prec@5 45.898 (24.446)	
2022-03-26 15:45:29,026: ============================================================
2022-03-26 15:47:29,348: time cost, forward:0.2872842983440594, backward:0.04457569265508795, data cost:0.8313984131073212 
2022-03-26 15:47:29,349: ============================================================
2022-03-26 15:47:29,349: Epoch 8/26 Batch 1000/7662 eta: 2 days, 0:19:21.357501	Training Loss 0.7946 (0.7541)	Training Prec@1 2.344 (17.828)	Training Prec@5 3.906 (22.931)	
2022-03-26 15:47:29,349: ============================================================
2022-03-26 15:49:26,028: time cost, forward:0.29001326795270815, backward:0.04440205329325765, data cost:0.8294580332033193 
2022-03-26 15:49:26,029: ============================================================
2022-03-26 15:49:26,029: Epoch 8/26 Batch 1100/7662 eta: 1 day, 22:49:38.070084	Training Loss 0.6168 (0.7457)	Training Prec@1 55.469 (20.063)	Training Prec@5 66.211 (25.641)	
2022-03-26 15:49:26,029: ============================================================
2022-03-26 15:51:23,609: time cost, forward:0.29110839985329673, backward:0.044419609973388875, data cost:0.829582386358864 
2022-03-26 15:51:23,609: ============================================================
2022-03-26 15:51:23,610: Epoch 8/26 Batch 1200/7662 eta: 1 day, 23:09:21.757501	Training Loss 0.6375 (0.7354)	Training Prec@1 54.492 (23.076)	Training Prec@5 65.625 (29.069)	
2022-03-26 15:51:23,610: ============================================================
2022-03-26 15:53:15,468: time cost, forward:0.29196022748029443, backward:0.04450878773954302, data cost:0.8250088093370727 
2022-03-26 15:53:15,469: ============================================================
2022-03-26 15:53:15,469: Epoch 8/26 Batch 1300/7662 eta: 1 day, 20:49:49.403279	Training Loss 0.5914 (0.7250)	Training Prec@1 63.672 (25.990)	Training Prec@5 73.828 (32.293)	
2022-03-26 15:53:15,469: ============================================================
2022-03-26 15:55:15,425: time cost, forward:0.29321950840217204, backward:0.04488334304695048, data cost:0.8256531160503221 
2022-03-26 15:55:15,425: ============================================================
2022-03-26 15:55:15,426: Epoch 8/26 Batch 1400/7662 eta: 2 days, 0:02:32.400868	Training Loss 0.5841 (0.7152)	Training Prec@1 65.430 (28.694)	Training Prec@5 74.219 (35.241)	
2022-03-26 15:55:15,426: ============================================================
2022-03-26 15:57:13,704: time cost, forward:0.29359289278102924, backward:0.04472863045909391, data cost:0.8270567931518148 
2022-03-26 15:57:13,704: ============================================================
2022-03-26 15:57:13,704: Epoch 8/26 Batch 1500/7662 eta: 1 day, 23:20:14.492497	Training Loss 0.5894 (0.7063)	Training Prec@1 62.891 (31.150)	Training Prec@5 75.195 (37.875)	
2022-03-26 15:57:13,704: ============================================================
2022-03-26 15:59:11,688: time cost, forward:0.29502498484761214, backward:0.044902530739350646, data cost:0.8263199004327751 
2022-03-26 15:59:11,689: ============================================================
2022-03-26 15:59:11,689: Epoch 8/26 Batch 1600/7662 eta: 1 day, 23:11:13.447243	Training Loss 0.5685 (0.6981)	Training Prec@1 66.797 (33.377)	Training Prec@5 75.781 (40.248)	
2022-03-26 15:59:11,689: ============================================================
2022-03-26 16:01:11,056: time cost, forward:0.2962796491619557, backward:0.04495960154766332, data cost:0.8266425066796943 
2022-03-26 16:01:11,056: ============================================================
2022-03-26 16:01:11,056: Epoch 8/26 Batch 1700/7662 eta: 1 day, 23:42:24.436451	Training Loss 0.5593 (0.6911)	Training Prec@1 70.312 (35.353)	Training Prec@5 77.930 (42.356)	
2022-03-26 16:01:11,056: ============================================================
2022-03-26 16:03:06,670: time cost, forward:0.29683682850959103, backward:0.04495064201058117, data cost:0.8254043753773984 
2022-03-26 16:03:06,670: ============================================================
2022-03-26 16:03:06,670: Epoch 8/26 Batch 1800/7662 eta: 1 day, 22:10:28.447843	Training Loss 0.5582 (0.6842)	Training Prec@1 71.484 (37.186)	Training Prec@5 79.883 (44.295)	
2022-03-26 16:03:06,670: ============================================================
2022-03-26 16:05:09,634: time cost, forward:0.29887396589965176, backward:0.0451345953456724, data cost:0.8260038874537271 
2022-03-26 16:05:09,635: ============================================================
2022-03-26 16:05:09,636: Epoch 8/26 Batch 1900/7662 eta: 2 days, 1:04:35.236431	Training Loss 0.5684 (0.6779)	Training Prec@1 73.047 (38.876)	Training Prec@5 79.883 (46.064)	
2022-03-26 16:05:09,636: ============================================================
2022-03-26 16:07:09,092: time cost, forward:0.3011700373521264, backward:0.045160044664857145, data cost:0.8248913835560816 
2022-03-26 16:07:09,093: ============================================================
2022-03-26 16:07:09,093: Epoch 8/26 Batch 2000/7662 eta: 1 day, 23:38:35.942776	Training Loss 0.5667 (0.6722)	Training Prec@1 67.578 (40.395)	Training Prec@5 78.320 (47.664)	
2022-03-26 16:07:09,093: ============================================================
2022-03-26 16:09:06,321: time cost, forward:0.30263129184790144, backward:0.045106980617754, data cost:0.8238547194736693 
2022-03-26 16:09:06,321: ============================================================
2022-03-26 16:09:06,321: Epoch 8/26 Batch 2100/7662 eta: 1 day, 22:43:17.772393	Training Loss 0.8756 (0.6775)	Training Prec@1 0.000 (39.549)	Training Prec@5 0.391 (46.626)	
2022-03-26 16:09:06,321: ============================================================
2022-03-26 16:11:06,086: time cost, forward:0.30490156475551133, backward:0.04508793402824038, data cost:0.8227494404824445 
2022-03-26 16:11:06,087: ============================================================
2022-03-26 16:11:06,087: Epoch 8/26 Batch 2200/7662 eta: 1 day, 23:41:59.250114	Training Loss 0.8360 (0.6855)	Training Prec@1 0.000 (37.751)	Training Prec@5 0.000 (44.506)	
2022-03-26 16:11:06,087: ============================================================
2022-03-26 16:13:03,541: time cost, forward:0.30521382348026177, backward:0.04515584472367534, data cost:0.8225216795019918 
2022-03-26 16:13:03,541: ============================================================
2022-03-26 16:13:03,541: Epoch 8/26 Batch 2300/7662 eta: 1 day, 22:44:47.058078	Training Loss 0.8300 (0.6919)	Training Prec@1 0.000 (36.109)	Training Prec@5 0.000 (42.572)	
2022-03-26 16:13:03,541: ============================================================
2022-03-26 16:14:58,993: time cost, forward:0.30558751801144535, backward:0.045159823102422336, data cost:0.8212513903768522 
2022-03-26 16:14:58,994: ============================================================
2022-03-26 16:14:58,994: Epoch 8/26 Batch 2400/7662 eta: 1 day, 21:55:04.330125	Training Loss 0.8268 (0.6977)	Training Prec@1 0.000 (34.604)	Training Prec@5 0.195 (40.799)	
2022-03-26 16:14:58,994: ============================================================
2022-03-26 16:16:57,363: time cost, forward:0.30624718969466447, backward:0.04519652060958661, data cost:0.8207766737829165 
2022-03-26 16:16:57,364: ============================================================
2022-03-26 16:16:57,364: Epoch 8/26 Batch 2500/7662 eta: 1 day, 23:02:42.346740	Training Loss 0.7838 (0.7025)	Training Prec@1 5.078 (33.231)	Training Prec@5 9.180 (39.193)	
2022-03-26 16:16:57,364: ============================================================
2022-03-26 16:18:55,270: time cost, forward:0.30735290449552694, backward:0.04473772072801227, data cost:0.8206927513057978 
2022-03-26 16:18:55,271: ============================================================
2022-03-26 16:18:55,271: Epoch 8/26 Batch 2600/7662 eta: 1 day, 22:49:42.048158	Training Loss 0.8605 (0.7087)	Training Prec@1 0.000 (31.962)	Training Prec@5 0.000 (37.704)	
2022-03-26 16:18:55,271: ============================================================
2022-03-26 16:20:55,894: time cost, forward:0.30849679225725174, backward:0.044705893031399796, data cost:0.8207545321091054 
2022-03-26 16:20:55,895: ============================================================
2022-03-26 16:20:55,895: Epoch 8/26 Batch 2700/7662 eta: 1 day, 23:52:26.296593	Training Loss 0.8507 (0.7142)	Training Prec@1 0.000 (30.777)	Training Prec@5 0.000 (36.307)	
2022-03-26 16:20:55,895: ============================================================
2022-03-26 16:22:56,148: time cost, forward:0.309486189498438, backward:0.04467307205241082, data cost:0.8208040039468638 
2022-03-26 16:22:56,149: ============================================================
2022-03-26 16:22:56,149: Epoch 8/26 Batch 2800/7662 eta: 1 day, 23:41:37.642409	Training Loss 0.8464 (0.7190)	Training Prec@1 0.000 (29.678)	Training Prec@5 0.000 (35.011)	
2022-03-26 16:22:56,149: ============================================================
2022-03-26 16:24:54,053: time cost, forward:0.3099328829280752, backward:0.04469113145955228, data cost:0.8205120595581329 
2022-03-26 16:24:54,054: ============================================================
2022-03-26 16:24:54,054: Epoch 8/26 Batch 2900/7662 eta: 1 day, 22:43:46.246400	Training Loss 0.8404 (0.7232)	Training Prec@1 0.000 (28.654)	Training Prec@5 0.000 (33.804)	
2022-03-26 16:24:54,055: ============================================================
2022-03-26 16:26:52,995: time cost, forward:0.3104176572975853, backward:0.04472454868582496, data cost:0.8204860026616182 
2022-03-26 16:26:52,996: ============================================================
2022-03-26 16:26:52,996: Epoch 8/26 Batch 3000/7662 eta: 1 day, 23:06:25.614129	Training Loss 0.8344 (0.7270)	Training Prec@1 0.000 (27.699)	Training Prec@5 0.195 (32.677)	
2022-03-26 16:26:52,996: ============================================================
2022-03-26 16:28:53,420: time cost, forward:0.31131281426507607, backward:0.044767319752193724, data cost:0.820200248855512 
2022-03-26 16:28:53,421: ============================================================
2022-03-26 16:28:53,421: Epoch 8/26 Batch 3100/7662 eta: 1 day, 23:39:40.257552	Training Loss 0.8342 (0.7304)	Training Prec@1 0.000 (26.806)	Training Prec@5 0.000 (31.624)	
2022-03-26 16:28:53,421: ============================================================
2022-03-26 16:30:49,296: time cost, forward:0.31145374407504417, backward:0.04480424870845488, data cost:0.8196810026696489 
2022-03-26 16:30:49,296: ============================================================
2022-03-26 16:30:49,296: Epoch 8/26 Batch 3200/7662 eta: 1 day, 21:49:42.379112	Training Loss 0.8289 (0.7336)	Training Prec@1 0.000 (25.968)	Training Prec@5 0.195 (30.637)	
2022-03-26 16:30:49,296: ============================================================
2022-03-26 16:32:47,088: time cost, forward:0.3112159565962889, backward:0.04483973680029641, data cost:0.8199578011603238 
2022-03-26 16:32:47,088: ============================================================
2022-03-26 16:32:47,088: Epoch 8/26 Batch 3300/7662 eta: 1 day, 22:33:12.995153	Training Loss 0.8294 (0.7365)	Training Prec@1 0.000 (25.182)	Training Prec@5 0.000 (29.710)	
2022-03-26 16:32:47,088: ============================================================
2022-03-26 16:34:43,396: time cost, forward:0.3110652460214425, backward:0.04486362293700184, data cost:0.8196911071110697 
2022-03-26 16:34:43,396: ============================================================
2022-03-26 16:34:43,396: Epoch 8/26 Batch 3400/7662 eta: 1 day, 21:56:05.633817	Training Loss 0.8276 (0.7391)	Training Prec@1 0.000 (24.442)	Training Prec@5 0.000 (28.838)	
2022-03-26 16:34:43,396: ============================================================
2022-03-26 16:36:43,602: time cost, forward:0.3111509163402155, backward:0.04484720317320539, data cost:0.8200945388115826 
2022-03-26 16:36:43,603: ============================================================
2022-03-26 16:36:43,603: Epoch 8/26 Batch 3500/7662 eta: 1 day, 23:26:28.805319	Training Loss 0.8227 (0.7416)	Training Prec@1 0.000 (23.744)	Training Prec@5 0.195 (28.017)	
2022-03-26 16:36:43,603: ============================================================
2022-03-26 16:38:43,804: time cost, forward:0.3117438111910723, backward:0.04487582099672886, data cost:0.8204350707331576 
2022-03-26 16:38:43,804: ============================================================
2022-03-26 16:38:43,805: Epoch 8/26 Batch 3600/7662 eta: 1 day, 23:24:20.863903	Training Loss 0.8201 (0.7438)	Training Prec@1 0.000 (23.085)	Training Prec@5 0.195 (27.243)	
2022-03-26 16:38:43,805: ============================================================
2022-03-26 16:40:40,482: time cost, forward:0.3116924681512689, backward:0.04491181204724421, data cost:0.820137734347403 
2022-03-26 16:40:40,483: ============================================================
2022-03-26 16:40:40,483: Epoch 8/26 Batch 3700/7662 eta: 1 day, 21:59:01.863049	Training Loss 0.8136 (0.7458)	Training Prec@1 0.000 (22.463)	Training Prec@5 0.586 (26.514)	
2022-03-26 16:40:40,483: ============================================================
2022-03-26 16:42:42,007: time cost, forward:0.31161560269210425, backward:0.044986861917526356, data cost:0.8209378795894895 
2022-03-26 16:42:42,008: ============================================================
2022-03-26 16:42:42,008: Epoch 8/26 Batch 3800/7662 eta: 1 day, 23:51:37.196927	Training Loss 0.7874 (0.7473)	Training Prec@1 2.148 (21.890)	Training Prec@5 3.711 (25.862)	
2022-03-26 16:42:42,008: ============================================================
2022-03-26 16:44:38,914: time cost, forward:0.3112652817271434, backward:0.04503200292036942, data cost:0.8210016233121838 
2022-03-26 16:44:38,914: ============================================================
2022-03-26 16:44:38,915: Epoch 8/26 Batch 3900/7662 eta: 1 day, 22:00:32.039321	Training Loss 0.7667 (0.7480)	Training Prec@1 5.469 (21.433)	Training Prec@5 10.547 (25.414)	
2022-03-26 16:44:38,915: ============================================================
2022-03-26 16:46:36,868: time cost, forward:0.31106308502803953, backward:0.04500422980911167, data cost:0.821282875838951 
2022-03-26 16:46:36,869: ============================================================
2022-03-26 16:46:36,869: Epoch 8/26 Batch 4000/7662 eta: 1 day, 22:23:19.041159	Training Loss 0.7370 (0.7484)	Training Prec@1 17.578 (21.115)	Training Prec@5 25.586 (25.154)	
2022-03-26 16:46:36,870: ============================================================
2022-03-26 16:48:35,316: time cost, forward:0.3110600691011517, backward:0.04500121283920895, data cost:0.8215730597432517 
2022-03-26 16:48:35,318: ============================================================
2022-03-26 16:48:35,318: Epoch 8/26 Batch 4100/7662 eta: 1 day, 22:32:59.997076	Training Loss 0.8420 (0.7506)	Training Prec@1 0.000 (20.633)	Training Prec@5 0.000 (24.596)	
2022-03-26 16:48:35,318: ============================================================
2022-03-26 16:50:35,100: time cost, forward:0.3112940814955571, backward:0.04501096161526423, data cost:0.821904230810512 
2022-03-26 16:50:35,102: ============================================================
2022-03-26 16:50:35,102: Epoch 8/26 Batch 4200/7662 eta: 1 day, 23:02:29.392258	Training Loss 0.8383 (0.7527)	Training Prec@1 0.000 (20.141)	Training Prec@5 0.000 (24.011)	
2022-03-26 16:50:35,102: ============================================================
2022-03-26 16:52:32,999: time cost, forward:0.311657466065415, backward:0.045017237495782625, data cost:0.8213963210790705 
2022-03-26 16:52:32,999: ============================================================
2022-03-26 16:52:33,000: Epoch 8/26 Batch 4300/7662 eta: 1 day, 22:16:04.797113	Training Loss 0.8309 (0.7546)	Training Prec@1 0.000 (19.673)	Training Prec@5 0.000 (23.453)	
2022-03-26 16:52:33,000: ============================================================
2022-03-26 16:54:31,477: time cost, forward:0.3116054840590851, backward:0.04502977997532051, data cost:0.821659447686676 
2022-03-26 16:54:31,478: ============================================================
2022-03-26 16:54:31,479: Epoch 8/26 Batch 4400/7662 eta: 1 day, 22:27:47.172344	Training Loss 0.8306 (0.7564)	Training Prec@1 0.000 (19.226)	Training Prec@5 0.195 (22.921)	
2022-03-26 16:54:31,479: ============================================================
2022-03-26 16:56:29,701: time cost, forward:0.3114606336795852, backward:0.04502951163507933, data cost:0.8219237991056593 
2022-03-26 16:56:29,701: ============================================================
2022-03-26 16:56:29,701: Epoch 8/26 Batch 4500/7662 eta: 1 day, 22:19:47.293448	Training Loss 0.8279 (0.7580)	Training Prec@1 0.000 (18.799)	Training Prec@5 0.195 (22.412)	
2022-03-26 16:56:29,701: ============================================================
2022-03-26 16:58:32,668: time cost, forward:0.3116754174465769, backward:0.045071797309737795, data cost:0.8226729291603601 
2022-03-26 16:58:32,670: ============================================================
2022-03-26 16:58:32,670: Epoch 8/26 Batch 4600/7662 eta: 2 days, 0:09:20.028688	Training Loss 0.8260 (0.7595)	Training Prec@1 0.000 (18.391)	Training Prec@5 0.195 (21.927)	
2022-03-26 16:58:32,670: ============================================================
2022-03-26 17:00:29,648: time cost, forward:0.3119414716255008, backward:0.045066207539505035, data cost:0.8222401535341044 
2022-03-26 17:00:29,648: ============================================================
2022-03-26 17:00:29,648: Epoch 8/26 Batch 4700/7662 eta: 1 day, 21:46:38.095851	Training Loss 0.8256 (0.7609)	Training Prec@1 0.000 (18.000)	Training Prec@5 0.000 (21.463)	
2022-03-26 17:00:29,648: ============================================================
2022-03-26 17:02:32,276: time cost, forward:0.312353241664714, backward:0.045069093728070456, data cost:0.8227794515661807 
2022-03-26 17:02:32,277: ============================================================
2022-03-26 17:02:32,277: Epoch 8/26 Batch 4800/7662 eta: 1 day, 23:57:15.488142	Training Loss 0.8220 (0.7622)	Training Prec@1 0.000 (17.626)	Training Prec@5 0.195 (21.018)	
2022-03-26 17:02:32,277: ============================================================
2022-03-26 17:04:32,072: time cost, forward:0.3125238699873118, backward:0.04499507665780156, data cost:0.8230578500315909 
2022-03-26 17:04:32,073: ============================================================
2022-03-26 17:04:32,073: Epoch 8/26 Batch 4900/7662 eta: 1 day, 22:48:48.076126	Training Loss 0.8201 (0.7634)	Training Prec@1 0.195 (17.267)	Training Prec@5 0.391 (20.592)	
2022-03-26 17:04:32,074: ============================================================
2022-03-26 17:06:30,689: time cost, forward:0.3128026578158802, backward:0.04500394493228174, data cost:0.8229025565855359 
2022-03-26 17:06:30,690: ============================================================
2022-03-26 17:06:30,690: Epoch 8/26 Batch 5000/7662 eta: 1 day, 22:19:10.152501	Training Loss 0.8130 (0.7645)	Training Prec@1 0.000 (16.924)	Training Prec@5 0.391 (20.187)	
2022-03-26 17:06:30,690: ============================================================
2022-03-26 17:08:27,967: time cost, forward:0.3127191536658931, backward:0.04505479333447017, data cost:0.8225936698876168 
2022-03-26 17:08:27,968: ============================================================
2022-03-26 17:08:27,968: Epoch 8/26 Batch 5100/7662 eta: 1 day, 21:45:50.940683	Training Loss 0.8044 (0.7654)	Training Prec@1 0.391 (16.597)	Training Prec@5 1.172 (19.806)	
2022-03-26 17:08:27,968: ============================================================
2022-03-26 17:10:26,612: time cost, forward:0.312601377377489, backward:0.04507759177333966, data cost:0.8229844294091467 
2022-03-26 17:10:26,613: ============================================================
2022-03-26 17:10:26,614: Epoch 8/26 Batch 5200/7662 eta: 1 day, 22:15:53.905552	Training Loss 0.7609 (0.7657)	Training Prec@1 8.203 (16.325)	Training Prec@5 14.844 (19.527)	
2022-03-26 17:10:26,614: ============================================================
2022-03-26 17:12:26,922: time cost, forward:0.3125546185514526, backward:0.04512359358540435, data cost:0.8234363440905771 
2022-03-26 17:12:26,923: ============================================================
2022-03-26 17:12:26,923: Epoch 8/26 Batch 5300/7662 eta: 1 day, 22:52:48.093902	Training Loss 0.6994 (0.7651)	Training Prec@1 31.055 (16.344)	Training Prec@5 45.312 (19.676)	
2022-03-26 17:12:26,923: ============================================================
2022-03-26 17:14:23,788: time cost, forward:0.3124243014166589, backward:0.04513242598440188, data cost:0.8231800047638991 
2022-03-26 17:14:23,788: ============================================================
2022-03-26 17:14:23,788: Epoch 8/26 Batch 5400/7662 eta: 1 day, 21:30:21.127835	Training Loss 0.8331 (0.7652)	Training Prec@1 0.000 (16.325)	Training Prec@5 0.000 (19.701)	
2022-03-26 17:14:23,788: ============================================================
2022-03-26 17:16:22,888: time cost, forward:0.3123164891893158, backward:0.045036150165245, data cost:0.8236492130187971 
2022-03-26 17:16:22,889: ============================================================
2022-03-26 17:16:22,889: Epoch 8/26 Batch 5500/7662 eta: 1 day, 22:20:35.066075	Training Loss 0.7374 (0.7659)	Training Prec@1 16.016 (16.073)	Training Prec@5 25.586 (19.424)	
2022-03-26 17:16:22,890: ============================================================
2022-03-26 17:18:20,282: time cost, forward:0.31242809953125783, backward:0.04482544543679686, data cost:0.8236162810692682 
2022-03-26 17:18:20,283: ============================================================
2022-03-26 17:18:20,283: Epoch 8/26 Batch 5600/7662 eta: 1 day, 21:38:47.202309	Training Loss 0.6562 (0.7644)	Training Prec@1 46.094 (16.452)	Training Prec@5 57.227 (19.951)	
2022-03-26 17:18:20,284: ============================================================
2022-03-26 17:20:18,335: time cost, forward:0.31230133277195593, backward:0.04480047421740699, data cost:0.8236390515197095 
2022-03-26 17:20:18,336: ============================================================
2022-03-26 17:20:18,336: Epoch 8/26 Batch 5700/7662 eta: 1 day, 21:52:10.787553	Training Loss 0.6740 (0.7623)	Training Prec@1 40.039 (17.049)	Training Prec@5 52.539 (20.682)	
2022-03-26 17:20:18,336: ============================================================
2022-03-26 17:22:16,295: time cost, forward:0.31246432836229665, backward:0.044850915110220185, data cost:0.8234548756615379 
2022-03-26 17:22:16,296: ============================================================
2022-03-26 17:22:16,297: Epoch 8/26 Batch 5800/7662 eta: 1 day, 21:48:04.271572	Training Loss 0.6133 (0.7599)	Training Prec@1 58.008 (17.722)	Training Prec@5 66.797 (21.475)	
2022-03-26 17:22:16,298: ============================================================
2022-03-26 17:24:12,334: time cost, forward:0.3123770960106003, backward:0.044887949479072854, data cost:0.8232520151631391 
2022-03-26 17:24:12,335: ============================================================
2022-03-26 17:24:12,335: Epoch 8/26 Batch 5900/7662 eta: 1 day, 21:01:21.026879	Training Loss 0.7114 (0.7574)	Training Prec@1 63.281 (18.419)	Training Prec@5 73.633 (22.275)	
2022-03-26 17:24:12,335: ============================================================
2022-03-26 17:26:11,508: time cost, forward:0.3126789819679572, backward:0.04490354574209532, data cost:0.8231137007112244 
2022-03-26 17:26:11,508: ============================================================
2022-03-26 17:26:11,508: Epoch 8/26 Batch 6000/7662 eta: 1 day, 22:12:21.407606	Training Loss 0.5869 (0.7550)	Training Prec@1 61.719 (19.043)	Training Prec@5 71.289 (23.011)	
2022-03-26 17:26:11,509: ============================================================
2022-03-26 17:28:10,781: time cost, forward:0.3127714261244039, backward:0.04488521721504188, data cost:0.8232181161754463 
2022-03-26 17:28:10,781: ============================================================
2022-03-26 17:28:10,782: Epoch 8/26 Batch 6100/7662 eta: 1 day, 22:12:40.931997	Training Loss 0.5738 (0.7523)	Training Prec@1 70.508 (19.786)	Training Prec@5 77.734 (23.843)	
2022-03-26 17:28:10,782: ============================================================
2022-03-26 17:30:07,348: time cost, forward:0.31259676252070656, backward:0.04489055559084788, data cost:0.8231548573013505 
2022-03-26 17:30:07,349: ============================================================
2022-03-26 17:30:07,349: Epoch 8/26 Batch 6200/7662 eta: 1 day, 21:07:50.264405	Training Loss 0.5686 (0.7495)	Training Prec@1 66.016 (20.526)	Training Prec@5 77.930 (24.668)	
2022-03-26 17:30:07,349: ============================================================
2022-03-26 17:32:08,523: time cost, forward:0.31278908954837775, backward:0.04490719649276576, data cost:0.8232929430645333 
2022-03-26 17:32:08,523: ============================================================
2022-03-26 17:32:08,524: Epoch 8/26 Batch 6300/7662 eta: 1 day, 22:52:51.132928	Training Loss 0.5668 (0.7467)	Training Prec@1 67.773 (21.259)	Training Prec@5 80.078 (25.480)	
2022-03-26 17:32:08,524: ============================================================
2022-03-26 17:34:05,632: time cost, forward:0.31288232831661356, backward:0.044892943264972715, data cost:0.8230948431042139 
2022-03-26 17:34:05,633: ============================================================
2022-03-26 17:34:05,633: Epoch 8/26 Batch 6400/7662 eta: 1 day, 21:16:31.541555	Training Loss 0.5694 (0.7440)	Training Prec@1 67.969 (21.984)	Training Prec@5 75.977 (26.277)	
2022-03-26 17:34:05,634: ============================================================
2022-03-26 17:35:56,746: time cost, forward:0.3125058625877628, backward:0.044886202899506136, data cost:0.8224010908121255 
2022-03-26 17:35:56,747: ============================================================
2022-03-26 17:35:56,747: Epoch 8/26 Batch 6500/7662 eta: 1 day, 18:55:36.587017	Training Loss 0.5838 (0.7413)	Training Prec@1 66.992 (22.688)	Training Prec@5 76.172 (27.050)	
2022-03-26 17:35:56,748: ============================================================
2022-03-26 17:37:57,216: time cost, forward:0.31257523589286684, backward:0.04488862480317341, data cost:0.822792116629931 
2022-03-26 17:37:57,217: ============================================================
2022-03-26 17:37:57,217: Epoch 8/26 Batch 6600/7662 eta: 1 day, 22:30:27.220012	Training Loss 0.5636 (0.7387)	Training Prec@1 67.773 (23.382)	Training Prec@5 78.320 (27.813)	
2022-03-26 17:37:57,217: ============================================================
2022-03-26 17:39:56,009: time cost, forward:0.3126811869092122, backward:0.044865111767987666, data cost:0.8226920868642544 
2022-03-26 17:39:56,010: ============================================================
2022-03-26 17:39:56,010: Epoch 8/26 Batch 6700/7662 eta: 1 day, 21:49:39.020494	Training Loss 0.5578 (0.7360)	Training Prec@1 70.117 (24.064)	Training Prec@5 79.102 (28.557)	
2022-03-26 17:39:56,010: ============================================================
2022-03-26 17:41:53,093: time cost, forward:0.312633653373679, backward:0.044885571519492885, data cost:0.822684061844606 
2022-03-26 17:41:53,094: ============================================================
2022-03-26 17:41:53,095: Epoch 8/26 Batch 6800/7662 eta: 1 day, 21:08:08.542516	Training Loss 0.5687 (0.7335)	Training Prec@1 67.969 (24.736)	Training Prec@5 76.172 (29.286)	
2022-03-26 17:41:53,095: ============================================================
2022-03-26 17:43:50,549: time cost, forward:0.3125701532240864, backward:0.044887374528751356, data cost:0.8225768787789335 
2022-03-26 17:43:50,550: ============================================================
2022-03-26 17:43:50,550: Epoch 8/26 Batch 6900/7662 eta: 1 day, 21:14:46.364965	Training Loss 0.5537 (0.7309)	Training Prec@1 70.703 (25.393)	Training Prec@5 78.516 (29.999)	
2022-03-26 17:43:50,551: ============================================================
2022-03-26 17:45:48,669: time cost, forward:0.312372810449885, backward:0.04487547320559257, data cost:0.8227649805698757 
2022-03-26 17:45:48,671: ============================================================
2022-03-26 17:45:48,671: Epoch 8/26 Batch 7000/7662 eta: 1 day, 21:28:10.525990	Training Loss 0.5530 (0.7285)	Training Prec@1 73.438 (26.033)	Training Prec@5 81.250 (30.694)	
2022-03-26 17:45:48,671: ============================================================
2022-03-26 17:47:43,913: time cost, forward:0.31212725678301645, backward:0.044893638401539294, data cost:0.8226775164200497 
2022-03-26 17:47:43,913: ============================================================
2022-03-26 17:47:43,913: Epoch 8/26 Batch 7100/7662 eta: 1 day, 20:19:46.080586	Training Loss 0.5613 (0.7260)	Training Prec@1 69.922 (26.667)	Training Prec@5 79.102 (31.381)	
2022-03-26 17:47:43,913: ============================================================
2022-03-26 17:49:39,391: time cost, forward:0.3119144469172545, backward:0.04489224946305129, data cost:0.8225233651214315 
2022-03-26 17:49:39,391: ============================================================
2022-03-26 17:49:39,391: Epoch 8/26 Batch 7200/7662 eta: 1 day, 20:23:17.126329	Training Loss 0.5564 (0.7236)	Training Prec@1 70.508 (27.290)	Training Prec@5 81.250 (32.050)	
2022-03-26 17:49:39,391: ============================================================
2022-03-26 17:51:36,330: time cost, forward:0.3119748613412682, backward:0.04486535718823512, data cost:0.8223933615020113 
2022-03-26 17:51:36,331: ============================================================
2022-03-26 17:51:36,331: Epoch 8/26 Batch 7300/7662 eta: 1 day, 20:55:03.250693	Training Loss 0.5573 (0.7212)	Training Prec@1 71.680 (27.902)	Training Prec@5 80.078 (32.706)	
2022-03-26 17:51:36,331: ============================================================
2022-03-26 17:53:35,859: time cost, forward:0.31208731574228543, backward:0.044776749137221586, data cost:0.822584582367593 
2022-03-26 17:53:35,859: ============================================================
2022-03-26 17:53:35,859: Epoch 8/26 Batch 7400/7662 eta: 1 day, 21:52:43.384630	Training Loss 0.5460 (0.7189)	Training Prec@1 72.656 (28.497)	Training Prec@5 80.273 (33.348)	
2022-03-26 17:53:35,860: ============================================================
2022-03-26 17:55:36,192: time cost, forward:0.31239279029623385, backward:0.0448181949340275, data cost:0.8225638862609355 
2022-03-26 17:55:36,192: ============================================================
2022-03-26 17:55:36,192: Epoch 8/26 Batch 7500/7662 eta: 1 day, 22:09:14.402507	Training Loss 0.5464 (0.7166)	Training Prec@1 75.000 (29.082)	Training Prec@5 83.008 (33.974)	
2022-03-26 17:55:36,192: ============================================================
2022-03-26 17:57:32,392: time cost, forward:0.3125127842746639, backward:0.04483801867714335, data cost:0.8221819985303491 
2022-03-26 17:57:32,392: ============================================================
2022-03-26 17:57:32,392: Epoch 8/26 Batch 7600/7662 eta: 1 day, 20:32:11.810908	Training Loss 0.5426 (0.7144)	Training Prec@1 75.391 (29.657)	Training Prec@5 82.422 (34.590)	
2022-03-26 17:57:32,393: ============================================================
2022-03-26 17:58:47,951: Epoch: 8/26 eta: 1 day, 20:30:58.604811	Training Loss 0.5487 (0.7130)	Training Prec@1 74.219 (30.017)	Training Prec@5 79.492 (34.973)
2022-03-26 17:58:47,951: ============================================================
2022-03-26 18:00:41,224: time cost, forward:0.28453577407682784, backward:0.0416536210763334, data cost:0.8038975590407246 
2022-03-26 18:00:41,224: ============================================================
2022-03-26 18:00:41,224: Epoch 9/26 Batch 100/7662 eta: 1 day, 19:20:31.522421	Training Loss 0.8333 (0.6422)	Training Prec@1 0.000 (50.600)	Training Prec@5 0.000 (55.571)	
2022-03-26 18:00:41,224: ============================================================
2022-03-26 18:02:34,847: time cost, forward:0.2877171051562132, backward:0.04292955710061232, data cost:0.80431527708044 
2022-03-26 18:02:34,848: ============================================================
2022-03-26 18:02:34,849: Epoch 9/26 Batch 200/7662 eta: 1 day, 19:28:00.372888	Training Loss 0.8337 (0.7382)	Training Prec@1 0.000 (25.175)	Training Prec@5 0.000 (27.654)	
2022-03-26 18:02:34,849: ============================================================
2022-03-26 18:04:33,886: time cost, forward:0.29929920582468295, backward:0.04339230499139996, data cost:0.8095221017116687 
2022-03-26 18:04:33,887: ============================================================
2022-03-26 18:04:33,887: Epoch 9/26 Batch 300/7662 eta: 1 day, 21:30:16.631569	Training Loss 0.8312 (0.7695)	Training Prec@1 0.000 (16.757)	Training Prec@5 0.000 (18.413)	
2022-03-26 18:04:33,887: ============================================================
2022-03-26 18:06:31,838: time cost, forward:0.3036112510470818, backward:0.043412121316245326, data cost:0.8133605661846343 
2022-03-26 18:06:31,839: ============================================================
2022-03-26 18:06:31,839: Epoch 9/26 Batch 400/7662 eta: 1 day, 21:03:23.893347	Training Loss 0.8206 (0.7840)	Training Prec@1 0.000 (12.563)	Training Prec@5 0.195 (13.814)	
2022-03-26 18:06:31,839: ============================================================
2022-03-26 18:08:29,961: time cost, forward:0.31078463852524996, backward:0.043390103475842066, data cost:0.8087164146866731 
2022-03-26 18:08:29,963: ============================================================
2022-03-26 18:08:29,963: Epoch 9/26 Batch 500/7662 eta: 1 day, 21:05:22.698641	Training Loss 0.8489 (0.7975)	Training Prec@1 0.000 (10.055)	Training Prec@5 0.000 (11.089)	
2022-03-26 18:08:29,963: ============================================================
2022-03-26 18:10:30,721: time cost, forward:0.31500933962393685, backward:0.04346490304338713, data cost:0.8127495983805203 
2022-03-26 18:10:30,722: ============================================================
2022-03-26 18:10:30,722: Epoch 9/26 Batch 600/7662 eta: 1 day, 22:03:42.501559	Training Loss 0.8317 (0.8039)	Training Prec@1 0.195 (8.377)	Training Prec@5 0.195 (9.240)	
2022-03-26 18:10:30,722: ============================================================
2022-03-26 18:12:28,814: time cost, forward:0.3191277547626195, backward:0.04327175238613407, data cost:0.8102911606708139 
2022-03-26 18:12:28,814: ============================================================
2022-03-26 18:12:28,814: Epoch 9/26 Batch 700/7662 eta: 1 day, 21:00:43.006951	Training Loss 0.8319 (0.8079)	Training Prec@1 0.000 (7.180)	Training Prec@5 0.000 (7.921)	
2022-03-26 18:12:28,815: ============================================================
2022-03-26 18:14:27,640: time cost, forward:0.31998500597193485, backward:0.04300876552978057, data cost:0.810876397525563 
2022-03-26 18:14:27,641: ============================================================
2022-03-26 18:14:27,642: Epoch 9/26 Batch 800/7662 eta: 1 day, 21:15:32.533324	Training Loss 0.8309 (0.8107)	Training Prec@1 0.000 (6.282)	Training Prec@5 0.000 (6.934)	
2022-03-26 18:14:27,642: ============================================================
2022-03-26 18:16:24,470: time cost, forward:0.3205910720867628, backward:0.04291900458670034, data cost:0.8093481976145234 
2022-03-26 18:16:24,470: ============================================================
2022-03-26 18:16:24,471: Epoch 9/26 Batch 900/7662 eta: 1 day, 20:27:55.241384	Training Loss 0.8285 (0.8126)	Training Prec@1 0.000 (5.584)	Training Prec@5 0.195 (6.167)	
2022-03-26 18:16:24,471: ============================================================
2022-03-26 18:18:21,011: time cost, forward:0.32032257586986096, backward:0.0434806862392941, data cost:0.8089577757918441 
2022-03-26 18:18:21,012: ============================================================
2022-03-26 18:18:21,012: Epoch 9/26 Batch 1000/7662 eta: 1 day, 20:19:25.134494	Training Loss 0.8192 (0.8137)	Training Prec@1 0.000 (5.028)	Training Prec@5 0.000 (5.562)	
2022-03-26 18:18:21,012: ============================================================
2022-03-26 18:20:18,330: time cost, forward:0.31929468913334297, backward:0.04354318821831548, data cost:0.80924940434665 
2022-03-26 18:20:18,331: ============================================================
2022-03-26 18:20:18,331: Epoch 9/26 Batch 1100/7662 eta: 1 day, 20:35:12.408327	Training Loss 0.8713 (0.8162)	Training Prec@1 0.000 (4.606)	Training Prec@5 0.195 (5.152)	
2022-03-26 18:20:18,331: ============================================================
2022-03-26 18:22:13,791: time cost, forward:0.31791068435808933, backward:0.04349191632242974, data cost:0.8091411312189174 
2022-03-26 18:22:13,792: ============================================================
2022-03-26 18:22:13,792: Epoch 9/26 Batch 1200/7662 eta: 1 day, 19:50:54.920282	Training Loss 0.8514 (0.8201)	Training Prec@1 0.000 (4.224)	Training Prec@5 0.195 (4.727)	
2022-03-26 18:22:13,792: ============================================================
2022-03-26 18:24:10,523: time cost, forward:0.31737966662282846, backward:0.04345238199593748, data cost:0.8100755827715068 
2022-03-26 18:24:10,523: ============================================================
2022-03-26 18:24:10,524: Epoch 9/26 Batch 1300/7662 eta: 1 day, 20:17:55.063787	Training Loss 0.8287 (0.8217)	Training Prec@1 0.195 (3.903)	Training Prec@5 0.977 (4.377)	
2022-03-26 18:24:10,524: ============================================================
2022-03-26 18:26:06,972: time cost, forward:0.3171144211777966, backward:0.04353739041102793, data cost:0.8097604009575124 
2022-03-26 18:26:06,972: ============================================================
2022-03-26 18:26:06,972: Epoch 9/26 Batch 1400/7662 eta: 1 day, 20:09:32.371961	Training Loss 0.7673 (0.8208)	Training Prec@1 6.836 (3.689)	Training Prec@5 14.844 (4.223)	
2022-03-26 18:26:06,973: ============================================================
2022-03-26 18:28:06,346: time cost, forward:0.31706405099508683, backward:0.043794100725149776, data cost:0.811084233577288 
2022-03-26 18:28:06,347: ============================================================
2022-03-26 18:28:06,347: Epoch 9/26 Batch 1500/7662 eta: 1 day, 21:14:07.567381	Training Loss 0.8378 (0.8181)	Training Prec@1 0.000 (4.322)	Training Prec@5 0.000 (5.159)	
2022-03-26 18:28:06,347: ============================================================
2022-03-26 18:30:03,725: time cost, forward:0.3166025282816264, backward:0.043833844582687104, data cost:0.8111917332905095 
2022-03-26 18:30:03,725: ============================================================
2022-03-26 18:30:03,726: Epoch 9/26 Batch 1600/7662 eta: 1 day, 20:26:46.652546	Training Loss 0.8223 (0.8188)	Training Prec@1 0.000 (4.055)	Training Prec@5 0.781 (4.846)	
2022-03-26 18:30:03,726: ============================================================
2022-03-26 18:32:00,936: time cost, forward:0.3167185460630061, backward:0.04386450263456151, data cost:0.8112432010879651 
2022-03-26 18:32:00,937: ============================================================
2022-03-26 18:32:00,937: Epoch 9/26 Batch 1700/7662 eta: 1 day, 20:21:01.750480	Training Loss 0.7451 (0.8177)	Training Prec@1 15.625 (3.949)	Training Prec@5 26.758 (4.817)	
2022-03-26 18:32:00,937: ============================================================
2022-03-26 18:33:56,328: time cost, forward:0.3162975879826103, backward:0.043880382466806575, data cost:0.8107605697447356 
2022-03-26 18:33:56,328: ============================================================
2022-03-26 18:33:56,328: Epoch 9/26 Batch 1800/7662 eta: 1 day, 19:37:47.328623	Training Loss 0.8465 (0.8121)	Training Prec@1 0.000 (5.343)	Training Prec@5 0.000 (6.702)	
2022-03-26 18:33:56,328: ============================================================
2022-03-26 18:35:53,704: time cost, forward:0.3164710217617009, backward:0.044003006280755416, data cost:0.810232103341752 
2022-03-26 18:35:53,705: ============================================================
2022-03-26 18:35:53,705: Epoch 9/26 Batch 1900/7662 eta: 1 day, 20:20:52.179999	Training Loss 0.8199 (0.8133)	Training Prec@1 0.586 (5.066)	Training Prec@5 0.977 (6.359)	
2022-03-26 18:35:53,705: ============================================================
2022-03-26 18:37:47,190: time cost, forward:0.3160014131058449, backward:0.044049780150542804, data cost:0.8089083217870837 
2022-03-26 18:37:47,191: ============================================================
2022-03-26 18:37:47,191: Epoch 9/26 Batch 2000/7662 eta: 1 day, 18:50:46.612130	Training Loss 0.7357 (0.8118)	Training Prec@1 24.414 (5.150)	Training Prec@5 36.328 (6.586)	
2022-03-26 18:37:47,191: ============================================================
2022-03-26 18:39:45,613: time cost, forward:0.31513222664410073, backward:0.04416649247306253, data cost:0.8105948934559597 
2022-03-26 18:39:45,614: ============================================================
2022-03-26 18:39:45,614: Epoch 9/26 Batch 2100/7662 eta: 1 day, 20:40:38.948141	Training Loss 0.8272 (0.8058)	Training Prec@1 0.391 (6.825)	Training Prec@5 0.781 (8.630)	
2022-03-26 18:39:45,615: ============================================================
2022-03-26 18:41:41,791: time cost, forward:0.3150171007335918, backward:0.04412457041981113, data cost:0.810014410851597 
2022-03-26 18:41:41,792: ============================================================
2022-03-26 18:41:41,792: Epoch 9/26 Batch 2200/7662 eta: 1 day, 19:47:52.724791	Training Loss 0.6157 (0.8026)	Training Prec@1 58.203 (7.633)	Training Prec@5 70.898 (9.622)	
2022-03-26 18:41:41,792: ============================================================
2022-03-26 18:43:37,981: time cost, forward:0.3148130954686016, backward:0.04410959327153508, data cost:0.8101009543743689 
2022-03-26 18:43:37,981: ============================================================
2022-03-26 18:43:37,981: Epoch 9/26 Batch 2300/7662 eta: 1 day, 19:46:12.880860	Training Loss 0.5727 (0.7932)	Training Prec@1 66.016 (10.197)	Training Prec@5 75.391 (12.483)	
2022-03-26 18:43:37,981: ============================================================
2022-03-26 18:45:29,838: time cost, forward:0.31424400954506904, backward:0.044069411407763284, data cost:0.8086881122771975 
2022-03-26 18:45:29,839: ============================================================
2022-03-26 18:45:29,840: Epoch 9/26 Batch 2400/7662 eta: 1 day, 18:06:26.982969	Training Loss 0.5496 (0.7837)	Training Prec@1 75.391 (12.756)	Training Prec@5 81.641 (15.279)	
2022-03-26 18:45:29,840: ============================================================
2022-03-26 18:47:23,771: time cost, forward:0.3143064579805311, backward:0.04398779832825464, data cost:0.8076529776682707 
2022-03-26 18:47:23,771: ============================================================
2022-03-26 18:47:23,771: Epoch 9/26 Batch 2500/7662 eta: 1 day, 18:51:22.429780	Training Loss 0.5464 (0.7743)	Training Prec@1 75.586 (15.193)	Training Prec@5 81.641 (17.920)	
2022-03-26 18:47:23,771: ============================================================
2022-03-26 18:49:17,498: time cost, forward:0.31408149721806855, backward:0.043989232981741636, data cost:0.8065381699591795 
2022-03-26 18:49:17,499: ============================================================
2022-03-26 18:49:17,499: Epoch 9/26 Batch 2600/7662 eta: 1 day, 18:44:53.186353	Training Loss 0.5461 (0.7656)	Training Prec@1 74.414 (17.470)	Training Prec@5 82.227 (20.386)	
2022-03-26 18:49:17,499: ============================================================
2022-03-26 18:51:15,927: time cost, forward:0.31409770031689094, backward:0.04402864398935098, data cost:0.8072695423824428 
2022-03-26 18:51:15,928: ============================================================
2022-03-26 18:51:15,928: Epoch 9/26 Batch 2700/7662 eta: 1 day, 20:28:56.490581	Training Loss 0.5405 (0.7573)	Training Prec@1 75.977 (19.607)	Training Prec@5 83.008 (22.685)	
2022-03-26 18:51:15,928: ============================================================
2022-03-26 18:53:12,671: time cost, forward:0.3143493381301264, backward:0.044033648414925276, data cost:0.8071636521590527 
2022-03-26 18:53:12,672: ============================================================
2022-03-26 18:53:12,672: Epoch 9/26 Batch 2800/7662 eta: 1 day, 19:49:00.727876	Training Loss 0.5464 (0.7495)	Training Prec@1 74.023 (21.607)	Training Prec@5 82.031 (24.837)	
2022-03-26 18:53:12,672: ============================================================
2022-03-26 18:55:07,646: time cost, forward:0.3143514113904855, backward:0.04406677948766513, data cost:0.806426426179247 
2022-03-26 18:55:07,647: ============================================================
2022-03-26 18:55:07,647: Epoch 9/26 Batch 2900/7662 eta: 1 day, 19:07:15.770835	Training Loss 0.5333 (0.7422)	Training Prec@1 75.781 (23.458)	Training Prec@5 82.422 (26.834)	
2022-03-26 18:55:07,647: ============================================================
2022-03-26 18:57:02,698: time cost, forward:0.31424208329732756, backward:0.04408359774035905, data cost:0.8061974111418996 
2022-03-26 18:57:02,698: ============================================================
2022-03-26 18:57:02,699: Epoch 9/26 Batch 3000/7662 eta: 1 day, 19:07:04.286804	Training Loss 0.6884 (0.7411)	Training Prec@1 38.477 (23.787)	Training Prec@5 51.367 (27.206)	
2022-03-26 18:57:02,699: ============================================================
2022-03-26 18:58:59,378: time cost, forward:0.31399036623193743, backward:0.04414936602981139, data cost:0.8061736911756449 
2022-03-26 18:58:59,379: ============================================================
2022-03-26 18:58:59,379: Epoch 9/26 Batch 3100/7662 eta: 1 day, 19:41:44.664690	Training Loss 0.5494 (0.7365)	Training Prec@1 71.094 (24.995)	Training Prec@5 81.055 (28.585)	
2022-03-26 18:58:59,379: ============================================================
2022-03-26 19:00:55,509: time cost, forward:0.3136695175105313, backward:0.04419720385290005, data cost:0.8065448941644857 
2022-03-26 19:00:55,510: ============================================================
2022-03-26 19:00:55,510: Epoch 9/26 Batch 3200/7662 eta: 1 day, 19:27:28.609487	Training Loss 0.5369 (0.7303)	Training Prec@1 74.609 (26.561)	Training Prec@5 82.617 (30.267)	
2022-03-26 19:00:55,511: ============================================================
2022-03-26 19:02:50,157: time cost, forward:0.31349938137670763, backward:0.0441696818722635, data cost:0.8062470601738927 
2022-03-26 19:02:50,157: ============================================================
2022-03-26 19:02:50,157: Epoch 9/26 Batch 3300/7662 eta: 1 day, 18:52:14.049112	Training Loss 0.5442 (0.7244)	Training Prec@1 75.977 (28.053)	Training Prec@5 83.789 (31.869)	
2022-03-26 19:02:50,157: ============================================================
2022-03-26 19:04:43,120: time cost, forward:0.31300767732739765, backward:0.044206495599278146, data cost:0.8056653115496141 
2022-03-26 19:04:43,120: ============================================================
2022-03-26 19:04:43,120: Epoch 9/26 Batch 3400/7662 eta: 1 day, 18:12:34.742505	Training Loss 0.5296 (0.7189)	Training Prec@1 77.344 (29.470)	Training Prec@5 83.984 (33.385)	
2022-03-26 19:04:43,120: ============================================================
2022-03-26 19:06:39,947: time cost, forward:0.31323793991254584, backward:0.044193628005349116, data cost:0.8054596812222882 
2022-03-26 19:06:39,947: ============================================================
2022-03-26 19:06:39,948: Epoch 9/26 Batch 3500/7662 eta: 1 day, 19:37:15.868270	Training Loss 0.5485 (0.7136)	Training Prec@1 71.484 (30.804)	Training Prec@5 79.102 (34.811)	
2022-03-26 19:06:39,948: ============================================================
2022-03-26 19:08:35,234: time cost, forward:0.3129556272453187, backward:0.04419052557800836, data cost:0.8055864325759476 
2022-03-26 19:08:35,234: ============================================================
2022-03-26 19:08:35,234: Epoch 9/26 Batch 3600/7662 eta: 1 day, 19:00:49.168667	Training Loss 0.5260 (0.7085)	Training Prec@1 79.297 (32.069)	Training Prec@5 85.352 (36.163)	
2022-03-26 19:08:35,234: ============================================================
2022-03-26 19:10:28,130: time cost, forward:0.3126461985434156, backward:0.044176976466120885, data cost:0.804991781276508 
2022-03-26 19:10:28,132: ============================================================
2022-03-26 19:10:28,132: Epoch 9/26 Batch 3700/7662 eta: 1 day, 18:05:28.275383	Training Loss 0.5330 (0.7037)	Training Prec@1 76.172 (33.273)	Training Prec@5 83.008 (37.452)	
2022-03-26 19:10:28,132: ============================================================
2022-03-26 19:12:25,475: time cost, forward:0.31268893834571204, backward:0.04414836241402542, data cost:0.8052600195734838 
2022-03-26 19:12:25,476: ============================================================
2022-03-26 19:12:25,476: Epoch 9/26 Batch 3800/7662 eta: 1 day, 19:42:58.109043	Training Loss 0.5459 (0.6992)	Training Prec@1 73.047 (34.414)	Training Prec@5 82.227 (38.667)	
2022-03-26 19:12:25,476: ============================================================
2022-03-26 19:14:19,591: time cost, forward:0.3122452124781289, backward:0.044083699473175336, data cost:0.8050225786931638 
2022-03-26 19:14:19,592: ============================================================
2022-03-26 19:14:19,592: Epoch 9/26 Batch 3900/7662 eta: 1 day, 18:28:55.446726	Training Loss 0.5380 (0.6948)	Training Prec@1 75.586 (35.506)	Training Prec@5 82.227 (39.828)	
2022-03-26 19:14:19,593: ============================================================
2022-03-26 19:16:13,510: time cost, forward:0.312068623642708, backward:0.0441311235039137, data cost:0.8047736745144195 
2022-03-26 19:16:13,510: ============================================================
2022-03-26 19:16:13,511: Epoch 9/26 Batch 4000/7662 eta: 1 day, 18:22:35.953412	Training Loss 0.5245 (0.6907)	Training Prec@1 75.781 (36.546)	Training Prec@5 83.789 (40.933)	
2022-03-26 19:16:13,511: ============================================================
2022-03-26 19:18:17,272: time cost, forward:0.31497698610775293, backward:0.04406580409645365, data cost:0.803756625456297 
2022-03-26 19:18:17,272: ============================================================
2022-03-26 19:18:17,273: Epoch 9/26 Batch 4100/7662 eta: 1 day, 22:00:14.510467	Training Loss 0.5163 (0.6866)	Training Prec@1 79.492 (37.541)	Training Prec@5 84.570 (41.993)	
2022-03-26 19:18:17,273: ============================================================
2022-03-26 19:20:13,614: time cost, forward:0.3161741650425329, backward:0.04379135780488914, data cost:0.802862080825911 
2022-03-26 19:20:13,615: ============================================================
2022-03-26 19:20:13,615: Epoch 9/26 Batch 4200/7662 eta: 1 day, 19:12:49.192829	Training Loss 0.5294 (0.6828)	Training Prec@1 76.758 (38.486)	Training Prec@5 84.570 (42.997)	
2022-03-26 19:20:13,615: ============================================================
2022-03-26 19:22:08,096: time cost, forward:0.31687087739836645, backward:0.04348987810942816, data cost:0.8020601975804125 
2022-03-26 19:22:08,097: ============================================================
2022-03-26 19:22:08,097: Epoch 9/26 Batch 4300/7662 eta: 1 day, 18:29:27.576241	Training Loss 0.5214 (0.6792)	Training Prec@1 76.367 (39.385)	Training Prec@5 83.398 (43.952)	
2022-03-26 19:22:08,097: ============================================================
2022-03-26 19:23:55,110: time cost, forward:0.31700071640300814, backward:0.043214563132145375, data cost:0.8000261450279949 
2022-03-26 19:23:55,110: ============================================================
2022-03-26 19:23:55,110: Epoch 9/26 Batch 4400/7662 eta: 1 day, 15:41:21.131360	Training Loss 0.5167 (0.6757)	Training Prec@1 79.297 (40.250)	Training Prec@5 86.914 (44.874)	
2022-03-26 19:23:55,110: ============================================================
2022-03-26 19:25:46,399: time cost, forward:0.31712225363715063, backward:0.04312252245841754, data cost:0.7989671577954721 
2022-03-26 19:25:46,399: ============================================================
2022-03-26 19:25:46,399: Epoch 9/26 Batch 4500/7662 eta: 1 day, 17:14:38.342114	Training Loss 0.5158 (0.6724)	Training Prec@1 78.320 (41.068)	Training Prec@5 85.742 (45.745)	
2022-03-26 19:25:46,399: ============================================================
2022-03-26 19:27:38,402: time cost, forward:0.31719491216871476, backward:0.043080803984583756, data cost:0.7981109854500562 
2022-03-26 19:27:38,402: ============================================================
2022-03-26 19:27:38,402: Epoch 9/26 Batch 4600/7662 eta: 1 day, 17:28:38.690218	Training Loss 0.5240 (0.6692)	Training Prec@1 76.953 (41.858)	Training Prec@5 83.203 (46.582)	
2022-03-26 19:27:38,402: ============================================================
2022-03-26 19:29:30,953: time cost, forward:0.3169295639148492, backward:0.043125672248049626, data cost:0.7974661848701855 
2022-03-26 19:29:30,954: ============================================================
2022-03-26 19:29:30,954: Epoch 9/26 Batch 4700/7662 eta: 1 day, 17:38:58.157785	Training Loss 0.5342 (0.6661)	Training Prec@1 77.148 (42.622)	Training Prec@5 85.742 (47.395)	
2022-03-26 19:29:30,954: ============================================================
2022-03-26 19:31:21,964: time cost, forward:0.3168667771215612, backward:0.043131218872658535, data cost:0.7965254357368357 
2022-03-26 19:31:21,964: ============================================================
2022-03-26 19:31:21,965: Epoch 9/26 Batch 4800/7662 eta: 1 day, 17:02:54.291550	Training Loss 0.5285 (0.6631)	Training Prec@1 79.102 (43.356)	Training Prec@5 86.523 (48.175)	
2022-03-26 19:31:21,965: ============================================================
2022-03-26 19:33:11,522: time cost, forward:0.31611962575381036, backward:0.04314301407660823, data cost:0.7961474257747746 
2022-03-26 19:33:11,522: ============================================================
2022-03-26 19:33:11,522: Epoch 9/26 Batch 4900/7662 eta: 1 day, 16:28:50.550592	Training Loss 0.5235 (0.6602)	Training Prec@1 77.734 (44.063)	Training Prec@5 83.594 (48.926)	
2022-03-26 19:33:11,523: ============================================================
2022-03-26 19:35:01,258: time cost, forward:0.3156143736185897, backward:0.04317039135671372, data cost:0.7953226976953618 
2022-03-26 19:35:01,272: ============================================================
2022-03-26 19:35:01,273: Epoch 9/26 Batch 5000/7662 eta: 1 day, 16:31:16.437922	Training Loss 0.5232 (0.6574)	Training Prec@1 76.172 (44.749)	Training Prec@5 85.156 (49.652)	
2022-03-26 19:35:01,273: ============================================================
2022-03-26 19:36:51,259: time cost, forward:0.31534435080883433, backward:0.04320781444610159, data cost:0.7946205427188877 
2022-03-26 19:36:51,260: ============================================================
2022-03-26 19:36:51,260: Epoch 9/26 Batch 5100/7662 eta: 1 day, 16:34:41.702303	Training Loss 0.5241 (0.6547)	Training Prec@1 79.492 (45.407)	Training Prec@5 86.719 (50.348)	
2022-03-26 19:36:51,260: ============================================================
2022-03-26 19:38:37,747: time cost, forward:0.3145280119134133, backward:0.043222001709142865, data cost:0.7936893256037574 
2022-03-26 19:38:37,747: ============================================================
2022-03-26 19:38:37,747: Epoch 9/26 Batch 5200/7662 eta: 1 day, 15:15:26.771350	Training Loss 0.5134 (0.6522)	Training Prec@1 78.711 (46.040)	Training Prec@5 85.156 (51.016)	
2022-03-26 19:38:37,747: ============================================================
2022-03-26 19:40:26,709: time cost, forward:0.3139289945313381, backward:0.04326355743012263, data cost:0.7930924388952448 
2022-03-26 19:40:26,709: ============================================================
2022-03-26 19:40:26,709: Epoch 9/26 Batch 5300/7662 eta: 1 day, 16:08:22.065522	Training Loss 0.5183 (0.6496)	Training Prec@1 75.781 (46.657)	Training Prec@5 83.398 (51.663)	
2022-03-26 19:40:26,709: ============================================================
2022-03-26 19:42:18,850: time cost, forward:0.31353120212975333, backward:0.04327143870320314, data cost:0.7928111104528911 
2022-03-26 19:42:18,851: ============================================================
2022-03-26 19:42:18,851: Epoch 9/26 Batch 5400/7662 eta: 1 day, 17:16:46.944902	Training Loss 0.5061 (0.6472)	Training Prec@1 79.297 (47.251)	Training Prec@5 85.938 (52.288)	
2022-03-26 19:42:18,851: ============================================================
2022-03-26 19:44:10,852: time cost, forward:0.3137424244493067, backward:0.04330900669704894, data cost:0.7921033661719733 
2022-03-26 19:44:10,852: ============================================================
2022-03-26 19:44:10,853: Epoch 9/26 Batch 5500/7662 eta: 1 day, 17:11:49.441897	Training Loss 0.5258 (0.6449)	Training Prec@1 77.344 (47.821)	Training Prec@5 83.984 (52.890)	
2022-03-26 19:44:10,853: ============================================================
2022-03-26 19:46:02,620: time cost, forward:0.3137313370024185, backward:0.04334093668904128, data cost:0.791555086274853 
2022-03-26 19:46:02,621: ============================================================
2022-03-26 19:46:02,621: Epoch 9/26 Batch 5600/7662 eta: 1 day, 17:04:48.341077	Training Loss 0.5271 (0.6426)	Training Prec@1 78.320 (48.378)	Training Prec@5 86.328 (53.471)	
2022-03-26 19:46:02,621: ============================================================
2022-03-26 19:47:54,401: time cost, forward:0.31367654674072853, backward:0.04334742785713342, data cost:0.7909509470053233 
2022-03-26 19:47:54,402: ============================================================
2022-03-26 19:47:54,403: Epoch 9/26 Batch 5700/7662 eta: 1 day, 17:03:14.507557	Training Loss 0.5134 (0.6404)	Training Prec@1 81.641 (48.912)	Training Prec@5 87.500 (54.032)	
2022-03-26 19:47:54,403: ============================================================
2022-03-26 19:49:48,118: time cost, forward:0.31368755706324003, backward:0.043356379839362184, data cost:0.7907209509836227 
2022-03-26 19:49:48,118: ============================================================
2022-03-26 19:49:48,119: Epoch 9/26 Batch 5800/7662 eta: 1 day, 17:43:58.187985	Training Loss 0.5212 (0.6383)	Training Prec@1 79.688 (49.436)	Training Prec@5 86.328 (54.583)	
2022-03-26 19:49:48,119: ============================================================
2022-03-26 19:51:38,065: time cost, forward:0.3134841656236249, backward:0.043370417446014255, data cost:0.7901040559139145 
2022-03-26 19:51:38,065: ============================================================
2022-03-26 19:51:38,066: Epoch 9/26 Batch 5900/7662 eta: 1 day, 16:19:08.689793	Training Loss 0.5107 (0.6362)	Training Prec@1 78.516 (49.948)	Training Prec@5 85.742 (55.118)	
2022-03-26 19:51:38,066: ============================================================
2022-03-26 19:53:29,989: time cost, forward:0.31370043500222095, backward:0.043421563555308434, data cost:0.7894664591283554 
2022-03-26 19:53:29,989: ============================================================
2022-03-26 19:53:29,990: Epoch 9/26 Batch 6000/7662 eta: 1 day, 17:00:46.467025	Training Loss 0.5084 (0.6342)	Training Prec@1 81.836 (50.435)	Training Prec@5 86.133 (55.630)	
2022-03-26 19:53:29,990: ============================================================
2022-03-26 19:55:26,579: time cost, forward:0.31400353729891023, backward:0.043439621611840805, data cost:0.7894582973970588 
2022-03-26 19:55:26,579: ============================================================
2022-03-26 19:55:26,579: Epoch 9/26 Batch 6100/7662 eta: 1 day, 18:41:24.822006	Training Loss 0.5215 (0.6322)	Training Prec@1 77.539 (50.912)	Training Prec@5 82.617 (56.128)	
2022-03-26 19:55:26,579: ============================================================
2022-03-26 19:57:16,422: time cost, forward:0.3142125139622597, backward:0.043472214771251676, data cost:0.7884222330018616 
2022-03-26 19:57:16,422: ============================================================
2022-03-26 19:57:16,422: Epoch 9/26 Batch 6200/7662 eta: 1 day, 16:11:22.564332	Training Loss 0.4957 (0.6302)	Training Prec@1 78.320 (51.379)	Training Prec@5 84.570 (56.613)	
2022-03-26 19:57:16,423: ============================================================
2022-03-26 19:59:10,508: time cost, forward:0.3144042146718773, backward:0.04348490862339938, data cost:0.7881390203235831 
2022-03-26 19:59:10,508: ============================================================
2022-03-26 19:59:10,509: Epoch 9/26 Batch 6300/7662 eta: 1 day, 17:42:36.823497	Training Loss 0.5040 (0.6293)	Training Prec@1 81.055 (51.661)	Training Prec@5 86.133 (56.930)	
2022-03-26 19:59:10,509: ============================================================
2022-03-26 20:01:01,254: time cost, forward:0.314689274895357, backward:0.04350971173338451, data cost:0.7872220725822419 
2022-03-26 20:01:01,255: ============================================================
2022-03-26 20:01:01,255: Epoch 9/26 Batch 6400/7662 eta: 1 day, 16:27:30.070245	Training Loss 0.5091 (0.6275)	Training Prec@1 80.859 (52.098)	Training Prec@5 86.523 (57.387)	
2022-03-26 20:01:01,255: ============================================================
2022-03-26 20:02:55,427: time cost, forward:0.31508919576036504, backward:0.04353165534812316, data cost:0.786726840919193 
2022-03-26 20:02:55,427: ============================================================
2022-03-26 20:02:55,427: Epoch 9/26 Batch 6500/7662 eta: 1 day, 17:40:41.698827	Training Loss 0.5133 (0.6257)	Training Prec@1 79.883 (52.524)	Training Prec@5 87.109 (57.833)	
2022-03-26 20:02:55,427: ============================================================
2022-03-26 20:04:47,047: time cost, forward:0.3151494351494112, backward:0.04354152334045327, data cost:0.786137526099258 
2022-03-26 20:04:47,048: ============================================================
2022-03-26 20:04:47,049: Epoch 9/26 Batch 6600/7662 eta: 1 day, 16:42:57.777250	Training Loss 0.5080 (0.6240)	Training Prec@1 78.906 (52.939)	Training Prec@5 86.328 (58.267)	
2022-03-26 20:04:47,049: ============================================================
2022-03-26 20:06:38,812: time cost, forward:0.31542706756489297, backward:0.04357172898666808, data cost:0.7853817299846962 
2022-03-26 20:06:38,813: ============================================================
2022-03-26 20:06:38,814: Epoch 9/26 Batch 6700/7662 eta: 1 day, 16:44:14.930777	Training Loss 0.5075 (0.6222)	Training Prec@1 81.055 (53.351)	Training Prec@5 85.156 (58.693)	
2022-03-26 20:06:38,814: ============================================================
2022-03-26 20:08:31,208: time cost, forward:0.3155849354813109, backward:0.04360443452716417, data cost:0.7849942975437699 
2022-03-26 20:08:31,209: ============================================================
2022-03-26 20:08:31,209: Epoch 9/26 Batch 6800/7662 eta: 1 day, 16:56:09.357889	Training Loss 0.5138 (0.6206)	Training Prec@1 79.297 (53.748)	Training Prec@5 86.133 (59.103)	
2022-03-26 20:08:31,209: ============================================================
2022-03-26 20:10:21,692: time cost, forward:0.31565660786881, backward:0.043622204075172026, data cost:0.7843324616950981 
2022-03-26 20:10:21,693: ============================================================
2022-03-26 20:10:21,693: Epoch 9/26 Batch 6900/7662 eta: 1 day, 16:12:32.782879	Training Loss 0.5090 (0.6190)	Training Prec@1 80.859 (54.136)	Training Prec@5 85.742 (59.502)	
2022-03-26 20:10:21,693: ============================================================
2022-03-26 20:12:15,531: time cost, forward:0.31599286413649214, backward:0.04363105589704082, data cost:0.7838813047576656 
2022-03-26 20:12:15,531: ============================================================
2022-03-26 20:12:15,532: Epoch 9/26 Batch 7000/7662 eta: 1 day, 17:23:54.068933	Training Loss 0.5097 (0.6173)	Training Prec@1 81.641 (54.516)	Training Prec@5 86.914 (59.891)	
2022-03-26 20:12:15,532: ============================================================
2022-03-26 20:14:05,786: time cost, forward:0.31596794301715597, backward:0.04362915367924977, data cost:0.7832749669762427 
2022-03-26 20:14:05,786: ============================================================
2022-03-26 20:14:05,787: Epoch 9/26 Batch 7100/7662 eta: 1 day, 16:03:52.523657	Training Loss 0.5064 (0.6158)	Training Prec@1 79.492 (54.886)	Training Prec@5 85.938 (60.272)	
2022-03-26 20:14:05,787: ============================================================
2022-03-26 20:15:59,765: time cost, forward:0.3162078465963672, backward:0.04361387272148699, data cost:0.7830478406843335 
2022-03-26 20:15:59,765: ============================================================
2022-03-26 20:15:59,765: Epoch 9/26 Batch 7200/7662 eta: 1 day, 17:23:09.114575	Training Loss 0.5075 (0.6143)	Training Prec@1 78.906 (55.246)	Training Prec@5 86.523 (60.644)	
2022-03-26 20:15:59,765: ============================================================
2022-03-26 20:17:54,844: time cost, forward:0.31642668465095475, backward:0.04359394407448727, data cost:0.7829479625378917 
2022-03-26 20:17:54,845: ============================================================
2022-03-26 20:17:54,846: Epoch 9/26 Batch 7300/7662 eta: 1 day, 17:45:14.371421	Training Loss 0.4984 (0.6128)	Training Prec@1 81.836 (55.599)	Training Prec@5 87.500 (61.004)	
2022-03-26 20:17:54,846: ============================================================
2022-03-26 20:19:50,662: time cost, forward:0.31657273415891457, backward:0.04361137584635238, data cost:0.7830157446883823 
2022-03-26 20:19:50,662: ============================================================
2022-03-26 20:19:50,663: Epoch 9/26 Batch 7400/7662 eta: 1 day, 17:59:21.249988	Training Loss 0.5028 (0.6113)	Training Prec@1 82.812 (55.942)	Training Prec@5 88.672 (61.356)	
2022-03-26 20:19:50,663: ============================================================
2022-03-26 20:21:44,820: time cost, forward:0.3169864737076638, backward:0.04360652815613656, data cost:0.7825770302444541 
2022-03-26 20:21:44,820: ============================================================
2022-03-26 20:21:44,821: Epoch 9/26 Batch 7500/7662 eta: 1 day, 17:21:21.425480	Training Loss 0.8640 (0.6113)	Training Prec@1 0.195 (55.988)	Training Prec@5 0.977 (61.398)	
2022-03-26 20:21:44,821: ============================================================
2022-03-26 20:23:38,268: time cost, forward:0.3172131332382903, backward:0.04360222719204804, data cost:0.7821932437310393 
2022-03-26 20:23:38,269: ============================================================
2022-03-26 20:23:38,269: Epoch 9/26 Batch 7600/7662 eta: 1 day, 17:04:02.959404	Training Loss 0.8825 (0.6144)	Training Prec@1 0.000 (55.279)	Training Prec@5 0.000 (60.630)	
2022-03-26 20:23:38,270: ============================================================
2022-03-26 20:24:52,518: Epoch: 9/26 eta: 1 day, 17:02:51.486715	Training Loss 0.8750 (0.6166)	Training Prec@1 0.000 (54.824)	Training Prec@5 0.000 (60.132)
2022-03-26 20:24:52,519: ============================================================
2022-03-26 20:26:49,623: time cost, forward:0.2647422588232792, backward:0.04543660867093789, data cost:0.8631766372256808 
2022-03-26 20:26:49,624: ============================================================
2022-03-26 20:26:49,624: Epoch 10/26 Batch 100/7662 eta: 1 day, 18:16:52.576416	Training Loss 0.8741 (0.8739)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.008)	
2022-03-26 20:26:49,624: ============================================================
2022-03-26 20:28:41,694: time cost, forward:0.28427017394022724, backward:0.04545869659538844, data cost:0.8180787790959804 
2022-03-26 20:28:41,695: ============================================================
2022-03-26 20:28:41,695: Epoch 10/26 Batch 200/7662 eta: 1 day, 16:29:14.037163	Training Loss 0.8701 (0.8733)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.011)	
2022-03-26 20:28:41,695: ============================================================
2022-03-26 20:30:30,973: time cost, forward:0.2918356102844544, backward:0.04527486447107832, data cost:0.7912590216633468 
2022-03-26 20:30:30,974: ============================================================
2022-03-26 20:30:30,974: Epoch 10/26 Batch 300/7662 eta: 1 day, 15:26:53.155491	Training Loss 0.8691 (0.8726)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.016)	
2022-03-26 20:30:30,974: ============================================================
2022-03-26 20:32:21,633: time cost, forward:0.29849866279085774, backward:0.044823903487738515, data cost:0.7801158422216735 
2022-03-26 20:32:21,633: ============================================================
2022-03-26 20:32:21,633: Epoch 10/26 Batch 400/7662 eta: 1 day, 15:54:56.702552	Training Loss 0.8714 (0.8721)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.017)	
2022-03-26 20:32:21,633: ============================================================
2022-03-26 20:34:14,811: time cost, forward:0.3042383939326407, backward:0.04489519027526488, data cost:0.7758624008996692 
2022-03-26 20:34:14,811: ============================================================
2022-03-26 20:34:14,812: Epoch 10/26 Batch 500/7662 eta: 1 day, 16:47:34.566459	Training Loss 0.8685 (0.8714)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.195 (0.016)	
2022-03-26 20:34:14,812: ============================================================
2022-03-26 20:36:07,168: time cost, forward:0.3119114245317615, backward:0.04468971580416213, data cost:0.7672956320200619 
2022-03-26 20:36:07,168: ============================================================
2022-03-26 20:36:07,168: Epoch 10/26 Batch 600/7662 eta: 1 day, 16:27:56.026761	Training Loss 0.8693 (0.8708)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-26 20:36:07,168: ============================================================
2022-03-26 20:38:00,865: time cost, forward:0.31748192300100697, backward:0.044806569772046355, data cost:0.7640015952747438 
2022-03-26 20:38:00,866: ============================================================
2022-03-26 20:38:00,866: Epoch 10/26 Batch 700/7662 eta: 1 day, 16:55:00.789626	Training Loss 0.8642 (0.8702)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-26 20:38:00,866: ============================================================
2022-03-26 20:39:58,331: time cost, forward:0.3234719573630857, backward:0.044937254042738815, data cost:0.7639809791674751 
2022-03-26 20:39:58,331: ============================================================
2022-03-26 20:39:58,331: Epoch 10/26 Batch 800/7662 eta: 1 day, 18:14:25.046818	Training Loss 0.8648 (0.8696)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.019)	
2022-03-26 20:39:58,331: ============================================================
2022-03-26 20:41:47,475: time cost, forward:0.3243481677949627, backward:0.044656077004115495, data cost:0.7580224735718283 
2022-03-26 20:41:47,475: ============================================================
2022-03-26 20:41:47,476: Epoch 10/26 Batch 900/7662 eta: 1 day, 15:13:03.534610	Training Loss 0.8612 (0.8690)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.019)	
2022-03-26 20:41:47,476: ============================================================
2022-03-26 20:43:41,907: time cost, forward:0.3273376700159785, backward:0.04457135768504711, data cost:0.7567225302065218 
2022-03-26 20:43:41,916: ============================================================
2022-03-26 20:43:41,916: Epoch 10/26 Batch 1000/7662 eta: 1 day, 17:05:19.633785	Training Loss 0.8596 (0.8684)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.019)	
2022-03-26 20:43:41,916: ============================================================
2022-03-26 20:45:36,687: time cost, forward:0.3298481697381031, backward:0.04440339030299651, data cost:0.7566391731848816 
2022-03-26 20:45:36,688: ============================================================
2022-03-26 20:45:36,688: Epoch 10/26 Batch 1100/7662 eta: 1 day, 17:10:34.337128	Training Loss 0.8609 (0.8677)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.019)	
2022-03-26 20:45:36,689: ============================================================
2022-03-26 20:47:31,474: time cost, forward:0.3317692090910211, backward:0.04417827946628701, data cost:0.7562474142620224 
2022-03-26 20:47:31,475: ============================================================
2022-03-26 20:47:31,475: Epoch 10/26 Batch 1200/7662 eta: 1 day, 17:08:57.920622	Training Loss 0.8598 (0.8669)	Training Prec@1 0.195 (0.005)	Training Prec@5 0.195 (0.020)	
2022-03-26 20:47:31,475: ============================================================
2022-03-26 20:49:16,656: time cost, forward:0.3301882391438473, backward:0.04430254979533723, data cost:0.7514960290469785 
2022-03-26 20:49:16,656: ============================================================
2022-03-26 20:49:16,656: Epoch 10/26 Batch 1300/7662 eta: 1 day, 13:40:36.473989	Training Loss 0.8593 (0.8662)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.020)	
2022-03-26 20:49:16,656: ============================================================
2022-03-26 20:51:03,262: time cost, forward:0.3258589597324374, backward:0.04446778815503288, data cost:0.7513080110202268 
2022-03-26 20:51:03,263: ============================================================
2022-03-26 20:51:03,264: Epoch 10/26 Batch 1400/7662 eta: 1 day, 14:09:28.837085	Training Loss 0.8537 (0.8654)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.391 (0.021)	
2022-03-26 20:51:03,264: ============================================================
2022-03-26 20:52:55,716: time cost, forward:0.3236941519858759, backward:0.04458875143981282, data cost:0.7531514380914994 
2022-03-26 20:52:55,717: ============================================================
2022-03-26 20:52:55,717: Epoch 10/26 Batch 1500/7662 eta: 1 day, 16:13:09.240275	Training Loss 0.8508 (0.8645)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.022)	
2022-03-26 20:52:55,717: ============================================================
2022-03-26 20:54:47,941: time cost, forward:0.32190554569929075, backward:0.04456559459144731, data cost:0.7550448540824141 
2022-03-26 20:54:47,942: ============================================================
2022-03-26 20:54:47,942: Epoch 10/26 Batch 1600/7662 eta: 1 day, 16:06:23.143257	Training Loss 0.8439 (0.8635)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.023)	
2022-03-26 20:54:47,942: ============================================================
2022-03-26 20:56:39,240: time cost, forward:0.3215264368927289, backward:0.0447210816511903, data cost:0.7547533983620144 
2022-03-26 20:56:39,240: ============================================================
2022-03-26 20:56:39,240: Epoch 10/26 Batch 1700/7662 eta: 1 day, 15:44:39.768364	Training Loss 0.8298 (0.8618)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.195 (0.026)	
2022-03-26 20:56:39,240: ============================================================
2022-03-26 20:58:31,612: time cost, forward:0.321188543557193, backward:0.04472286347351583, data cost:0.7556271258826518 
2022-03-26 20:58:31,613: ============================================================
2022-03-26 20:58:31,613: Epoch 10/26 Batch 1800/7662 eta: 1 day, 16:05:48.071832	Training Loss 0.8240 (0.8598)	Training Prec@1 0.000 (0.009)	Training Prec@5 0.195 (0.032)	
2022-03-26 20:58:31,613: ============================================================
2022-03-26 21:00:24,210: time cost, forward:0.3208565173367565, backward:0.04482616243267009, data cost:0.7556229141148973 
2022-03-26 21:00:24,211: ============================================================
2022-03-26 21:00:24,211: Epoch 10/26 Batch 1900/7662 eta: 1 day, 16:08:45.398907	Training Loss 0.8216 (0.8578)	Training Prec@1 0.195 (0.010)	Training Prec@5 0.391 (0.040)	
2022-03-26 21:00:24,211: ============================================================
2022-03-26 21:02:14,147: time cost, forward:0.3207507950476016, backward:0.04490006894335382, data cost:0.7549804539129459 
2022-03-26 21:02:14,148: ============================================================
2022-03-26 21:02:14,148: Epoch 10/26 Batch 2000/7662 eta: 1 day, 15:09:59.296068	Training Loss 0.8203 (0.8559)	Training Prec@1 0.000 (0.014)	Training Prec@5 0.586 (0.050)	
2022-03-26 21:02:14,148: ============================================================
2022-03-26 21:04:09,833: time cost, forward:0.32126303171191456, backward:0.044901719372746146, data cost:0.7560009875713274 
2022-03-26 21:04:09,833: ============================================================
2022-03-26 21:04:09,834: Epoch 10/26 Batch 2100/7662 eta: 1 day, 17:10:57.303303	Training Loss 0.8179 (0.8541)	Training Prec@1 0.000 (0.018)	Training Prec@5 0.391 (0.063)	
2022-03-26 21:04:09,834: ============================================================
2022-03-26 21:05:58,590: time cost, forward:0.32168933357526736, backward:0.044857125761510026, data cost:0.754198469970377 
2022-03-26 21:05:58,591: ============================================================
2022-03-26 21:05:58,591: Epoch 10/26 Batch 2200/7662 eta: 1 day, 14:41:08.922858	Training Loss 0.8174 (0.8525)	Training Prec@1 0.000 (0.021)	Training Prec@5 0.195 (0.078)	
2022-03-26 21:05:58,591: ============================================================
2022-03-26 21:07:50,166: time cost, forward:0.3216271467860132, backward:0.04478079539477799, data cost:0.754072662849642 
2022-03-26 21:07:50,167: ============================================================
2022-03-26 21:07:50,167: Epoch 10/26 Batch 2300/7662 eta: 1 day, 15:39:27.547895	Training Loss 0.8145 (0.8509)	Training Prec@1 0.000 (0.026)	Training Prec@5 0.586 (0.096)	
2022-03-26 21:07:50,167: ============================================================
2022-03-26 21:09:41,829: time cost, forward:0.3207845742526577, backward:0.04490105486651568, data cost:0.7545281229738694 
2022-03-26 21:09:41,830: ============================================================
2022-03-26 21:09:41,831: Epoch 10/26 Batch 2400/7662 eta: 1 day, 15:39:27.053735	Training Loss 0.8154 (0.8494)	Training Prec@1 0.195 (0.033)	Training Prec@5 0.586 (0.118)	
2022-03-26 21:09:41,831: ============================================================
2022-03-26 21:11:33,840: time cost, forward:0.3205160166369099, backward:0.044821452884590114, data cost:0.7549580706267798 
2022-03-26 21:11:33,840: ============================================================
2022-03-26 21:11:33,840: Epoch 10/26 Batch 2500/7662 eta: 1 day, 15:44:58.354166	Training Loss 0.8581 (0.8480)	Training Prec@1 0.195 (0.042)	Training Prec@5 0.195 (0.143)	
2022-03-26 21:11:33,840: ============================================================
2022-03-26 21:13:24,631: time cost, forward:0.3198158164903172, backward:0.04476396860458063, data cost:0.7549173049442398 
2022-03-26 21:13:24,632: ============================================================
2022-03-26 21:13:24,632: Epoch 10/26 Batch 2600/7662 eta: 1 day, 15:17:11.217535	Training Loss 0.8526 (0.8484)	Training Prec@1 0.000 (0.040)	Training Prec@5 0.000 (0.139)	
2022-03-26 21:13:24,632: ============================================================
2022-03-26 21:15:18,412: time cost, forward:0.32013043486307885, backward:0.0449039551804533, data cost:0.7553044217919898 
2022-03-26 21:15:18,432: ============================================================
2022-03-26 21:15:18,433: Epoch 10/26 Batch 2700/7662 eta: 1 day, 16:19:18.101156	Training Loss 0.8136 (0.8474)	Training Prec@1 0.391 (0.043)	Training Prec@5 0.781 (0.151)	
2022-03-26 21:15:18,433: ============================================================
2022-03-26 21:17:09,073: time cost, forward:0.31975165542937806, backward:0.04489698057389336, data cost:0.755153405065833 
2022-03-26 21:17:09,073: ============================================================
2022-03-26 21:17:09,073: Epoch 10/26 Batch 2800/7662 eta: 1 day, 15:10:16.868811	Training Loss 0.8095 (0.8461)	Training Prec@1 0.391 (0.051)	Training Prec@5 1.562 (0.175)	
2022-03-26 21:17:09,073: ============================================================
2022-03-26 21:18:57,146: time cost, forward:0.3189493340843914, backward:0.04488018851068029, data cost:0.7545727457248494 
2022-03-26 21:18:57,147: ============================================================
2022-03-26 21:18:57,147: Epoch 10/26 Batch 2900/7662 eta: 1 day, 14:13:57.898213	Training Loss 0.8072 (0.8449)	Training Prec@1 0.781 (0.062)	Training Prec@5 0.977 (0.207)	
2022-03-26 21:18:57,148: ============================================================
2022-03-26 21:20:47,461: time cost, forward:0.3183160118358697, backward:0.0448706869524135, data cost:0.7546294805565529 
2022-03-26 21:20:47,462: ============================================================
2022-03-26 21:20:47,462: Epoch 10/26 Batch 3000/7662 eta: 1 day, 14:59:40.637300	Training Loss 0.8579 (0.8442)	Training Prec@1 0.000 (0.072)	Training Prec@5 0.000 (0.237)	
2022-03-26 21:20:47,462: ============================================================
2022-03-26 21:22:37,499: time cost, forward:0.317608801077627, backward:0.044861007021411305, data cost:0.7547949723714242 
2022-03-26 21:22:37,500: ============================================================
2022-03-26 21:22:37,501: Epoch 10/26 Batch 3100/7662 eta: 1 day, 14:51:59.693959	Training Loss 0.8582 (0.8446)	Training Prec@1 0.000 (0.070)	Training Prec@5 0.000 (0.229)	
2022-03-26 21:22:37,501: ============================================================
2022-03-26 21:24:32,017: time cost, forward:0.3171993449689001, backward:0.044849078928764705, data cost:0.7560527769615218 
2022-03-26 21:24:32,018: ============================================================
2022-03-26 21:24:32,018: Epoch 10/26 Batch 3200/7662 eta: 1 day, 16:25:00.605751	Training Loss 0.8560 (0.8450)	Training Prec@1 0.000 (0.068)	Training Prec@5 0.000 (0.223)	
2022-03-26 21:24:32,019: ============================================================
2022-03-26 21:26:19,443: time cost, forward:0.3165014626293986, backward:0.04484137581058906, data cost:0.755600956072407 
2022-03-26 21:26:19,444: ============================================================
2022-03-26 21:26:19,444: Epoch 10/26 Batch 3300/7662 eta: 1 day, 13:53:02.431157	Training Loss 0.8552 (0.8454)	Training Prec@1 0.000 (0.066)	Training Prec@5 0.000 (0.216)	
2022-03-26 21:26:19,444: ============================================================
2022-03-26 21:28:08,870: time cost, forward:0.3161156326926922, backward:0.044901483442615714, data cost:0.755289884201391 
2022-03-26 21:28:08,870: ============================================================
2022-03-26 21:28:08,870: Epoch 10/26 Batch 3400/7662 eta: 1 day, 14:33:32.596221	Training Loss 0.8584 (0.8457)	Training Prec@1 0.000 (0.064)	Training Prec@5 0.000 (0.210)	
2022-03-26 21:28:08,870: ============================================================
2022-03-26 21:29:58,889: time cost, forward:0.3153948859508871, backward:0.04488987873608332, data cost:0.7555535926448171 
2022-03-26 21:29:58,890: ============================================================
2022-03-26 21:29:58,890: Epoch 10/26 Batch 3500/7662 eta: 1 day, 14:44:15.412171	Training Loss 0.8548 (0.8459)	Training Prec@1 0.000 (0.063)	Training Prec@5 0.000 (0.204)	
2022-03-26 21:29:58,890: ============================================================
2022-03-26 21:31:48,452: time cost, forward:0.3149981339728378, backward:0.04496139961999468, data cost:0.7550947704590768 
2022-03-26 21:31:48,453: ============================================================
2022-03-26 21:31:48,453: Epoch 10/26 Batch 3600/7662 eta: 1 day, 14:32:46.949359	Training Loss 0.8512 (0.8461)	Training Prec@1 0.000 (0.061)	Training Prec@5 0.000 (0.199)	
2022-03-26 21:31:48,453: ============================================================
2022-03-26 21:33:39,999: time cost, forward:0.31481523544732287, backward:0.04489394528506801, data cost:0.7554722882889837 
2022-03-26 21:33:40,000: ============================================================
2022-03-26 21:33:40,000: Epoch 10/26 Batch 3700/7662 eta: 1 day, 15:12:48.313608	Training Loss 0.8495 (0.8463)	Training Prec@1 0.000 (0.059)	Training Prec@5 0.000 (0.194)	
2022-03-26 21:33:40,000: ============================================================
2022-03-26 21:35:30,241: time cost, forward:0.31496952144244245, backward:0.04480184753118738, data cost:0.7550622719028932 
2022-03-26 21:35:30,241: ============================================================
2022-03-26 21:35:30,241: Epoch 10/26 Batch 3800/7662 eta: 1 day, 14:43:25.646903	Training Loss 0.8527 (0.8465)	Training Prec@1 0.000 (0.058)	Training Prec@5 0.000 (0.189)	
2022-03-26 21:35:30,241: ============================================================
2022-03-26 21:37:18,900: time cost, forward:0.3151022171662324, backward:0.044742101704533147, data cost:0.7542750908185593 
2022-03-26 21:37:18,901: ============================================================
2022-03-26 21:37:18,901: Epoch 10/26 Batch 3900/7662 eta: 1 day, 14:08:17.051495	Training Loss 0.8528 (0.8466)	Training Prec@1 0.000 (0.056)	Training Prec@5 0.000 (0.185)	
2022-03-26 21:37:18,901: ============================================================
2022-03-26 21:39:08,937: time cost, forward:0.3147519499279613, backward:0.04470141019246435, data cost:0.7543771026074275 
2022-03-26 21:39:08,937: ============================================================
2022-03-26 21:39:08,937: Epoch 10/26 Batch 4000/7662 eta: 1 day, 14:35:26.024061	Training Loss 0.8515 (0.8467)	Training Prec@1 0.000 (0.055)	Training Prec@5 0.000 (0.181)	
2022-03-26 21:39:08,937: ============================================================
2022-03-26 21:41:00,100: time cost, forward:0.31468387492315514, backward:0.0446682954654661, data cost:0.7542377724011197 
2022-03-26 21:41:00,101: ============================================================
2022-03-26 21:41:00,102: Epoch 10/26 Batch 4100/7662 eta: 1 day, 14:57:19.587004	Training Loss 0.8498 (0.8468)	Training Prec@1 0.000 (0.054)	Training Prec@5 0.000 (0.176)	
2022-03-26 21:41:00,102: ============================================================
2022-03-26 21:42:47,198: time cost, forward:0.31413603203726487, backward:0.04461828048071937, data cost:0.7539794314444193 
2022-03-26 21:42:47,199: ============================================================
2022-03-26 21:42:47,199: Epoch 10/26 Batch 4200/7662 eta: 1 day, 13:30:01.946078	Training Loss 0.8493 (0.8468)	Training Prec@1 0.000 (0.053)	Training Prec@5 0.000 (0.173)	
2022-03-26 21:42:47,199: ============================================================
2022-03-26 21:44:37,603: time cost, forward:0.3137202260105464, backward:0.044666588874882555, data cost:0.7541094284940526 
2022-03-26 21:44:37,603: ============================================================
2022-03-26 21:44:37,603: Epoch 10/26 Batch 4300/7662 eta: 1 day, 14:37:39.291589	Training Loss 0.8445 (0.8468)	Training Prec@1 0.000 (0.051)	Training Prec@5 0.000 (0.169)	
2022-03-26 21:44:37,603: ============================================================
2022-03-26 21:46:23,947: time cost, forward:0.31366709411943683, backward:0.044653938423099504, data cost:0.7529222244944294 
2022-03-26 21:46:23,948: ============================================================
2022-03-26 21:46:23,949: Epoch 10/26 Batch 4400/7662 eta: 1 day, 13:10:40.627012	Training Loss 0.8442 (0.8468)	Training Prec@1 0.000 (0.050)	Training Prec@5 0.000 (0.165)	
2022-03-26 21:46:23,949: ============================================================
2022-03-26 21:48:14,423: time cost, forward:0.3136624632795325, backward:0.044725751580066433, data cost:0.7527660387148988 
2022-03-26 21:48:14,423: ============================================================
2022-03-26 21:48:14,424: Epoch 10/26 Batch 4500/7662 eta: 1 day, 14:35:28.101474	Training Loss 0.8456 (0.8468)	Training Prec@1 0.000 (0.049)	Training Prec@5 0.000 (0.162)	
2022-03-26 21:48:14,424: ============================================================
2022-03-26 21:50:01,505: time cost, forward:0.3137093762984403, backward:0.04473481341065674, data cost:0.7517286660127418 
2022-03-26 21:50:01,506: ============================================================
2022-03-26 21:50:01,506: Epoch 10/26 Batch 4600/7662 eta: 1 day, 13:22:34.230745	Training Loss 0.8445 (0.8468)	Training Prec@1 0.000 (0.048)	Training Prec@5 0.391 (0.159)	
2022-03-26 21:50:01,506: ============================================================
2022-03-26 21:51:48,765: time cost, forward:0.3133348295297438, backward:0.04472704587223226, data cost:0.751415998130485 
2022-03-26 21:51:48,765: ============================================================
2022-03-26 21:51:48,766: Epoch 10/26 Batch 4700/7662 eta: 1 day, 13:24:29.954427	Training Loss 0.8435 (0.8468)	Training Prec@1 0.000 (0.047)	Training Prec@5 0.000 (0.156)	
2022-03-26 21:51:48,766: ============================================================
2022-03-26 21:53:39,058: time cost, forward:0.3131856620249636, backward:0.04474410356941708, data cost:0.7513992682077607 
2022-03-26 21:53:39,058: ============================================================
2022-03-26 21:53:39,059: Epoch 10/26 Batch 4800/7662 eta: 1 day, 14:26:08.050825	Training Loss 0.8444 (0.8467)	Training Prec@1 0.195 (0.047)	Training Prec@5 0.195 (0.153)	
2022-03-26 21:53:39,059: ============================================================
2022-03-26 21:55:26,210: time cost, forward:0.3128480960895003, backward:0.04472050313488224, data cost:0.7510220026283708 
2022-03-26 21:55:26,211: ============================================================
2022-03-26 21:55:26,211: Epoch 10/26 Batch 4900/7662 eta: 1 day, 13:18:41.113400	Training Loss 0.8428 (0.8467)	Training Prec@1 0.000 (0.046)	Training Prec@5 0.000 (0.150)	
2022-03-26 21:55:26,211: ============================================================
2022-03-26 21:57:15,252: time cost, forward:0.3125344047691374, backward:0.04471452251914311, data cost:0.7509361206710183 
2022-03-26 21:57:15,253: ============================================================
2022-03-26 21:57:15,253: Epoch 10/26 Batch 5000/7662 eta: 1 day, 13:56:20.438015	Training Loss 0.8439 (0.8466)	Training Prec@1 0.000 (0.045)	Training Prec@5 0.000 (0.148)	
2022-03-26 21:57:15,253: ============================================================
2022-03-26 21:58:59,935: time cost, forward:0.3122522208147784, backward:0.04473835287152096, data cost:0.7500425198658421 
2022-03-26 21:58:59,936: ============================================================
2022-03-26 21:58:59,936: Epoch 10/26 Batch 5100/7662 eta: 1 day, 12:23:35.564751	Training Loss 0.8401 (0.8465)	Training Prec@1 0.000 (0.044)	Training Prec@5 0.391 (0.145)	
2022-03-26 21:58:59,936: ============================================================
2022-03-26 22:00:50,348: time cost, forward:0.3121076306142952, backward:0.044735000875964256, data cost:0.7499528697509678 
2022-03-26 22:00:50,349: ============================================================
2022-03-26 22:00:50,349: Epoch 10/26 Batch 5200/7662 eta: 1 day, 14:21:17.404539	Training Loss 0.8433 (0.8464)	Training Prec@1 0.000 (0.043)	Training Prec@5 0.000 (0.143)	
2022-03-26 22:00:50,349: ============================================================
2022-03-26 22:02:37,803: time cost, forward:0.3118665767269419, backward:0.04470582389903532, data cost:0.7497628358292746 
2022-03-26 22:02:37,803: ============================================================
2022-03-26 22:02:37,803: Epoch 10/26 Batch 5300/7662 eta: 1 day, 13:17:48.851950	Training Loss 0.8430 (0.8463)	Training Prec@1 0.000 (0.042)	Training Prec@5 0.000 (0.140)	
2022-03-26 22:02:37,803: ============================================================
2022-03-26 22:04:26,029: time cost, forward:0.311368984654118, backward:0.04470616809790566, data cost:0.7498095251935835 
2022-03-26 22:04:26,030: ============================================================
2022-03-26 22:04:26,030: Epoch 10/26 Batch 5400/7662 eta: 1 day, 13:32:07.274806	Training Loss 0.8380 (0.8462)	Training Prec@1 0.000 (0.042)	Training Prec@5 0.000 (0.139)	
2022-03-26 22:04:26,031: ============================================================
2022-03-26 22:06:17,065: time cost, forward:0.31115063725221936, backward:0.0446737513669644, data cost:0.75014656178408 
2022-03-26 22:06:17,065: ============================================================
2022-03-26 22:06:17,065: Epoch 10/26 Batch 5500/7662 eta: 1 day, 14:28:41.424057	Training Loss 0.8314 (0.8459)	Training Prec@1 0.000 (0.042)	Training Prec@5 0.000 (0.139)	
2022-03-26 22:06:17,065: ============================================================
2022-03-26 22:08:04,880: time cost, forward:0.3110967216842578, backward:0.044652431005664246, data cost:0.7496276451106751 
2022-03-26 22:08:04,881: ============================================================
2022-03-26 22:08:04,881: Epoch 10/26 Batch 5600/7662 eta: 1 day, 13:19:57.956914	Training Loss 0.8223 (0.8456)	Training Prec@1 0.000 (0.043)	Training Prec@5 0.000 (0.140)	
2022-03-26 22:08:04,881: ============================================================
2022-03-26 22:09:54,932: time cost, forward:0.31111873553748465, backward:0.04466314691475639, data cost:0.7495875718782274 
2022-03-26 22:09:54,932: ============================================================
2022-03-26 22:09:54,932: Epoch 10/26 Batch 5700/7662 eta: 1 day, 14:04:34.307390	Training Loss 0.8055 (0.8451)	Training Prec@1 0.391 (0.046)	Training Prec@5 1.758 (0.154)	
2022-03-26 22:09:54,932: ============================================================
2022-03-26 22:11:42,972: time cost, forward:0.31075840182172, backward:0.044700564464878925, data cost:0.7494276887200005 
2022-03-26 22:11:42,972: ============================================================
2022-03-26 22:11:42,972: Epoch 10/26 Batch 5800/7662 eta: 1 day, 13:21:01.329721	Training Loss 0.8009 (0.8443)	Training Prec@1 0.586 (0.056)	Training Prec@5 1.562 (0.181)	
2022-03-26 22:11:42,972: ============================================================
2022-03-26 22:13:29,719: time cost, forward:0.3104372043127851, backward:0.044657192142924365, data cost:0.7491837723171495 
2022-03-26 22:13:29,719: ============================================================
2022-03-26 22:13:29,720: Epoch 10/26 Batch 5900/7662 eta: 1 day, 12:52:25.444107	Training Loss 0.8005 (0.8436)	Training Prec@1 0.977 (0.072)	Training Prec@5 2.539 (0.224)	
2022-03-26 22:13:29,720: ============================================================
2022-03-26 22:15:16,781: time cost, forward:0.3099528256009511, backward:0.04465582490384648, data cost:0.7491183983602013 
2022-03-26 22:15:16,781: ============================================================
2022-03-26 22:15:16,782: Epoch 10/26 Batch 6000/7662 eta: 1 day, 12:57:09.844597	Training Loss 0.7955 (0.8428)	Training Prec@1 2.148 (0.093)	Training Prec@5 2.930 (0.277)	
2022-03-26 22:15:16,782: ============================================================
2022-03-26 22:17:06,368: time cost, forward:0.30964335845638286, backward:0.04467687964107115, data cost:0.7492652662583386 
2022-03-26 22:17:06,369: ============================================================
2022-03-26 22:17:06,369: Epoch 10/26 Batch 6100/7662 eta: 1 day, 13:47:37.919691	Training Loss 0.7968 (0.8422)	Training Prec@1 0.781 (0.109)	Training Prec@5 3.516 (0.316)	
2022-03-26 22:17:06,369: ============================================================
2022-03-26 22:18:57,758: time cost, forward:0.3093545794544691, backward:0.04466848466488253, data cost:0.7496001662352639 
2022-03-26 22:18:57,759: ============================================================
2022-03-26 22:18:57,759: Epoch 10/26 Batch 6200/7662 eta: 1 day, 14:23:05.219850	Training Loss 0.7895 (0.8414)	Training Prec@1 1.172 (0.139)	Training Prec@5 5.078 (0.392)	
2022-03-26 22:18:57,759: ============================================================
2022-03-26 22:20:37,260: time cost, forward:0.30866291814804986, backward:0.044662541483182494, data cost:0.7486844773632436 
2022-03-26 22:20:37,261: ============================================================
2022-03-26 22:20:37,261: Epoch 10/26 Batch 6300/7662 eta: 1 day, 10:15:38.005363	Training Loss 0.8063 (0.8411)	Training Prec@1 1.367 (0.148)	Training Prec@5 2.930 (0.414)	
2022-03-26 22:20:37,262: ============================================================
2022-03-26 22:22:24,606: time cost, forward:0.30809298998341933, backward:0.04467102597888363, data cost:0.7487982962909835 
2022-03-26 22:22:24,606: ============================================================
2022-03-26 22:22:24,607: Epoch 10/26 Batch 6400/7662 eta: 1 day, 12:55:52.670388	Training Loss 0.7852 (0.8402)	Training Prec@1 1.953 (0.185)	Training Prec@5 6.641 (0.499)	
2022-03-26 22:22:24,607: ============================================================
2022-03-26 22:24:13,652: time cost, forward:0.30760082759789675, backward:0.0446025430835161, data cost:0.7490595335372687 
2022-03-26 22:24:13,653: ============================================================
2022-03-26 22:24:13,654: Epoch 10/26 Batch 6500/7662 eta: 1 day, 13:29:11.144271	Training Loss 0.7786 (0.8393)	Training Prec@1 4.297 (0.239)	Training Prec@5 8.594 (0.615)	
2022-03-26 22:24:13,654: ============================================================
2022-03-26 22:26:02,156: time cost, forward:0.30718535487444804, backward:0.04452850132534803, data cost:0.7492986580949423 
2022-03-26 22:26:02,157: ============================================================
2022-03-26 22:26:02,157: Epoch 10/26 Batch 6600/7662 eta: 1 day, 13:16:09.421528	Training Loss 0.8340 (0.8389)	Training Prec@1 0.000 (0.265)	Training Prec@5 0.391 (0.665)	
2022-03-26 22:26:02,157: ============================================================
2022-03-26 22:27:51,349: time cost, forward:0.3068625518396232, backward:0.044560566502269444, data cost:0.7494522174946816 
2022-03-26 22:27:51,349: ============================================================
2022-03-26 22:27:51,350: Epoch 10/26 Batch 6700/7662 eta: 1 day, 13:28:33.179414	Training Loss 0.7980 (0.8387)	Training Prec@1 0.586 (0.267)	Training Prec@5 4.102 (0.670)	
2022-03-26 22:27:51,350: ============================================================
2022-03-26 22:29:41,226: time cost, forward:0.30665458646096244, backward:0.04453992366720638, data cost:0.7496360503043966 
2022-03-26 22:29:41,226: ============================================================
2022-03-26 22:29:41,227: Epoch 10/26 Batch 6800/7662 eta: 1 day, 13:40:48.709628	Training Loss 0.7771 (0.8378)	Training Prec@1 4.297 (0.332)	Training Prec@5 9.570 (0.803)	
2022-03-26 22:29:41,227: ============================================================
2022-03-26 22:31:29,129: time cost, forward:0.306291752508506, backward:0.0445570408356226, data cost:0.7497752317917107 
2022-03-26 22:31:29,129: ============================================================
2022-03-26 22:31:29,129: Epoch 10/26 Batch 6900/7662 eta: 1 day, 12:58:23.588743	Training Loss 0.8405 (0.8376)	Training Prec@1 0.000 (0.349)	Training Prec@5 0.000 (0.836)	
2022-03-26 22:31:29,130: ============================================================
2022-03-26 22:33:19,638: time cost, forward:0.30608324201332876, backward:0.04458027584993221, data cost:0.749902241739959 
2022-03-26 22:33:19,639: ============================================================
2022-03-26 22:33:19,639: Epoch 10/26 Batch 7000/7662 eta: 1 day, 13:50:08.185399	Training Loss 0.8348 (0.8376)	Training Prec@1 0.195 (0.345)	Training Prec@5 0.195 (0.824)	
2022-03-26 22:33:19,639: ============================================================
2022-03-26 22:35:09,896: time cost, forward:0.3058957656280543, backward:0.04459062178784113, data cost:0.7502279945252093 
2022-03-26 22:35:09,896: ============================================================
2022-03-26 22:35:09,896: Epoch 10/26 Batch 7100/7662 eta: 1 day, 13:43:07.731509	Training Loss 0.8393 (0.8376)	Training Prec@1 0.000 (0.340)	Training Prec@5 0.000 (0.813)	
2022-03-26 22:35:09,896: ============================================================
2022-03-26 22:36:57,295: time cost, forward:0.30558912845796504, backward:0.04458970751327216, data cost:0.750164903192193 
2022-03-26 22:36:57,296: ============================================================
2022-03-26 22:36:57,296: Epoch 10/26 Batch 7200/7662 eta: 1 day, 12:42:40.382127	Training Loss 0.8399 (0.8376)	Training Prec@1 0.000 (0.335)	Training Prec@5 0.000 (0.802)	
2022-03-26 22:36:57,296: ============================================================
2022-03-26 22:38:47,878: time cost, forward:0.30539682787205197, backward:0.04459606681658578, data cost:0.7503824970921126 
2022-03-26 22:38:47,878: ============================================================
2022-03-26 22:38:47,878: Epoch 10/26 Batch 7300/7662 eta: 1 day, 13:46:06.256128	Training Loss 0.8361 (0.8376)	Training Prec@1 0.000 (0.331)	Training Prec@5 0.000 (0.791)	
2022-03-26 22:38:47,878: ============================================================
2022-03-26 22:40:34,774: time cost, forward:0.3053030485655105, backward:0.04460044612206548, data cost:0.7500774236543225 
2022-03-26 22:40:34,774: ============================================================
2022-03-26 22:40:34,774: Epoch 10/26 Batch 7400/7662 eta: 1 day, 12:28:47.239737	Training Loss 0.8342 (0.8376)	Training Prec@1 0.000 (0.326)	Training Prec@5 0.000 (0.781)	
2022-03-26 22:40:34,774: ============================================================
2022-03-26 22:42:22,159: time cost, forward:0.30543818097382264, backward:0.04460127459540178, data cost:0.7494702816073108 
2022-03-26 22:42:22,160: ============================================================
2022-03-26 22:42:22,160: Epoch 10/26 Batch 7500/7662 eta: 1 day, 12:37:01.472891	Training Loss 0.8376 (0.8376)	Training Prec@1 0.000 (0.322)	Training Prec@5 0.000 (0.770)	
2022-03-26 22:42:22,160: ============================================================
2022-03-26 22:44:13,120: time cost, forward:0.3055787701122948, backward:0.044604428427237275, data cost:0.7495649574085009 
2022-03-26 22:44:13,120: ============================================================
2022-03-26 22:44:13,120: Epoch 10/26 Batch 7600/7662 eta: 1 day, 13:48:18.620578	Training Loss 0.8355 (0.8376)	Training Prec@1 0.000 (0.318)	Training Prec@5 0.000 (0.761)	
2022-03-26 22:44:13,121: ============================================================
2022-03-26 22:45:26,221: Epoch: 10/26 eta: 1 day, 13:47:08.715453	Training Loss 0.8368 (0.8376)	Training Prec@1 0.000 (0.315)	Training Prec@5 0.000 (0.755)
2022-03-26 22:45:26,222: ============================================================
2022-03-26 22:45:26,227: Save Checkpoint...
2022-03-26 22:45:26,231: ============================================================
2022-03-26 22:45:36,740: Save done!
2022-03-26 22:45:36,740: ============================================================
2022-03-26 22:47:25,751: time cost, forward:0.31736792458428276, backward:0.04163992525351168, data cost:0.7358442460647737 
2022-03-26 22:47:25,752: ============================================================
2022-03-26 22:47:25,752: Epoch 11/26 Batch 100/7662 eta: 1 day, 13:04:39.327787	Training Loss 0.8345 (0.8348)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.022)	
2022-03-26 22:47:25,752: ============================================================
2022-03-26 22:49:15,657: time cost, forward:0.30044570280678906, backward:0.04392303773506203, data cost:0.7517785115457659 
2022-03-26 22:49:15,667: ============================================================
2022-03-26 22:49:15,667: Epoch 11/26 Batch 200/7662 eta: 1 day, 13:22:08.117957	Training Loss 0.8368 (0.8348)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.018)	
2022-03-26 22:49:15,667: ============================================================
2022-03-26 22:51:00,996: time cost, forward:0.2906153385455792, backward:0.04390059266999414, data cost:0.7475357829129018 
2022-03-26 22:51:00,996: ============================================================
2022-03-26 22:51:00,997: Epoch 11/26 Batch 300/7662 eta: 1 day, 11:46:50.773621	Training Loss 0.8328 (0.8346)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.018)	
2022-03-26 22:51:00,997: ============================================================
2022-03-26 22:52:47,306: time cost, forward:0.28684365958498237, backward:0.04351698187060822, data cost:0.7468735251510352 
2022-03-26 22:52:47,306: ============================================================
2022-03-26 22:52:47,307: Epoch 11/26 Batch 400/7662 eta: 1 day, 12:05:03.233439	Training Loss 0.8312 (0.8344)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.017)	
2022-03-26 22:52:47,307: ============================================================
2022-03-26 22:54:33,153: time cost, forward:0.28491067838573264, backward:0.04349746971665499, data cost:0.7449695734318368 
2022-03-26 22:54:33,154: ============================================================
2022-03-26 22:54:33,154: Epoch 11/26 Batch 500/7662 eta: 1 day, 11:53:52.220611	Training Loss 0.8347 (0.8343)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.017)	
2022-03-26 22:54:33,154: ============================================================
2022-03-26 22:56:21,628: time cost, forward:0.28551204097091853, backward:0.04385691851327734, data cost:0.7454796840432092 
2022-03-26 22:56:21,629: ============================================================
2022-03-26 22:56:21,629: Epoch 11/26 Batch 600/7662 eta: 1 day, 12:45:32.331571	Training Loss 0.8348 (0.8342)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.015)	
2022-03-26 22:56:21,630: ============================================================
2022-03-26 22:58:07,484: time cost, forward:0.28494325830189454, backward:0.04404649782249003, data cost:0.7437992832691372 
2022-03-26 22:58:07,484: ============================================================
2022-03-26 22:58:07,484: Epoch 11/26 Batch 700/7662 eta: 1 day, 11:50:29.881381	Training Loss 0.8327 (0.8340)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-26 22:58:07,484: ============================================================
2022-03-26 22:59:56,356: time cost, forward:0.2843821188982795, backward:0.04434005518878655, data cost:0.7461051979709478 
2022-03-26 22:59:56,356: ============================================================
2022-03-26 22:59:56,357: Epoch 11/26 Batch 800/7662 eta: 1 day, 12:49:58.720594	Training Loss 0.8327 (0.8339)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-26 22:59:56,357: ============================================================
2022-03-26 23:01:41,339: time cost, forward:0.28260147982630235, backward:0.04407629022608875, data cost:0.7452882227298283 
2022-03-26 23:01:41,339: ============================================================
2022-03-26 23:01:41,339: Epoch 11/26 Batch 900/7662 eta: 1 day, 11:29:16.660494	Training Loss 0.8328 (0.8338)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-26 23:01:41,339: ============================================================
2022-03-26 23:03:28,269: time cost, forward:0.2817360679427902, backward:0.04391019265572946, data cost:0.7452402014632125 
2022-03-26 23:03:28,270: ============================================================
2022-03-26 23:03:28,270: Epoch 11/26 Batch 1000/7662 eta: 1 day, 12:07:00.408763	Training Loss 0.8320 (0.8336)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-26 23:03:28,270: ============================================================
2022-03-26 23:05:17,838: time cost, forward:0.2814984362813101, backward:0.043745022236595814, data cost:0.7477793491786995 
2022-03-26 23:05:17,838: ============================================================
2022-03-26 23:05:17,839: Epoch 11/26 Batch 1100/7662 eta: 1 day, 12:58:38.229236	Training Loss 0.8321 (0.8335)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-26 23:05:17,839: ============================================================
2022-03-26 23:07:03,258: time cost, forward:0.28053965421395066, backward:0.043433586292410016, data cost:0.7481622411570418 
2022-03-26 23:07:03,258: ============================================================
2022-03-26 23:07:03,259: Epoch 11/26 Batch 1200/7662 eta: 1 day, 11:32:52.156568	Training Loss 0.8315 (0.8334)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.016)	
2022-03-26 23:07:03,259: ============================================================
2022-03-26 23:08:48,787: time cost, forward:0.2803587135303195, backward:0.043414414158410713, data cost:0.7470135934725461 
2022-03-26 23:08:48,788: ============================================================
2022-03-26 23:08:48,788: Epoch 11/26 Batch 1300/7662 eta: 1 day, 11:33:20.150927	Training Loss 0.8331 (0.8333)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.016)	
2022-03-26 23:08:48,789: ============================================================
2022-03-26 23:10:35,770: time cost, forward:0.2801988734953569, backward:0.04352804402780158, data cost:0.7469034286973475 
2022-03-26 23:10:35,771: ============================================================
2022-03-26 23:10:35,772: Epoch 11/26 Batch 1400/7662 eta: 1 day, 12:00:56.462883	Training Loss 0.8321 (0.8332)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.015)	
2022-03-26 23:10:35,772: ============================================================
2022-03-26 23:12:26,236: time cost, forward:0.2800371790027682, backward:0.04364500386147121, data cost:0.7493030232855127 
2022-03-26 23:12:26,237: ============================================================
2022-03-26 23:12:26,237: Epoch 11/26 Batch 1500/7662 eta: 1 day, 13:09:25.517750	Training Loss 0.8321 (0.8331)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.016)	
2022-03-26 23:12:26,237: ============================================================
2022-03-26 23:14:09,100: time cost, forward:0.28032956964303135, backward:0.04366119553552261, data cost:0.7461832617878392 
2022-03-26 23:14:09,101: ============================================================
2022-03-26 23:14:09,101: Epoch 11/26 Batch 1600/7662 eta: 1 day, 10:34:18.419047	Training Loss 0.8299 (0.8329)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.015)	
2022-03-26 23:14:09,101: ============================================================
2022-03-26 23:15:53,912: time cost, forward:0.28062368730294696, backward:0.04369931504472415, data cost:0.7444974957949417 
2022-03-26 23:15:53,913: ============================================================
2022-03-26 23:15:53,913: Epoch 11/26 Batch 1700/7662 eta: 1 day, 11:11:50.282717	Training Loss 0.8300 (0.8328)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.015)	
2022-03-26 23:15:53,913: ============================================================
2022-03-26 23:17:43,752: time cost, forward:0.2820052219272124, backward:0.04384319049375066, data cost:0.7445423039812191 
2022-03-26 23:17:43,753: ============================================================
2022-03-26 23:17:43,753: Epoch 11/26 Batch 1800/7662 eta: 1 day, 12:51:19.104535	Training Loss 0.8314 (0.8327)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.015)	
2022-03-26 23:17:43,753: ============================================================
2022-03-26 23:19:30,038: time cost, forward:0.2826569856248949, backward:0.04400871928708688, data cost:0.74339133667406 
2022-03-26 23:19:30,038: ============================================================
2022-03-26 23:19:30,038: Epoch 11/26 Batch 1900/7662 eta: 1 day, 11:37:58.976426	Training Loss 0.8331 (0.8326)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.016)	
2022-03-26 23:19:30,038: ============================================================
2022-03-26 23:21:16,168: time cost, forward:0.2831026699138678, backward:0.04408465056731857, data cost:0.7423789466602198 
2022-03-26 23:21:16,169: ============================================================
2022-03-26 23:21:16,170: Epoch 11/26 Batch 2000/7662 eta: 1 day, 11:33:06.763317	Training Loss 0.8326 (0.8326)	Training Prec@1 0.195 (0.003)	Training Prec@5 0.195 (0.016)	
2022-03-26 23:21:16,170: ============================================================
2022-03-26 23:23:04,065: time cost, forward:0.2838976195791098, backward:0.04405656424291137, data cost:0.7418895636699835 
2022-03-26 23:23:04,066: ============================================================
2022-03-26 23:23:04,067: Epoch 11/26 Batch 2100/7662 eta: 1 day, 12:06:48.130056	Training Loss 0.8322 (0.8325)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.015)	
2022-03-26 23:23:04,067: ============================================================
2022-03-26 23:24:49,542: time cost, forward:0.28433526988027313, backward:0.04408746635225373, data cost:0.7408814411805185 
2022-03-26 23:24:49,543: ============================================================
2022-03-26 23:24:49,543: Epoch 11/26 Batch 2200/7662 eta: 1 day, 11:16:26.263556	Training Loss 0.8283 (0.8324)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.195 (0.015)	
2022-03-26 23:24:49,543: ============================================================
2022-03-26 23:26:36,639: time cost, forward:0.284476987068007, backward:0.04412435831946879, data cost:0.7407637202464896 
2022-03-26 23:26:36,640: ============================================================
2022-03-26 23:26:36,640: Epoch 11/26 Batch 2300/7662 eta: 1 day, 11:47:10.226765	Training Loss 0.8302 (0.8323)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.015)	
2022-03-26 23:26:36,640: ============================================================
2022-03-26 23:28:21,695: time cost, forward:0.28463576554556397, backward:0.04417804411521997, data cost:0.7396493428147997 
2022-03-26 23:28:21,696: ============================================================
2022-03-26 23:28:21,697: Epoch 11/26 Batch 2400/7662 eta: 1 day, 11:04:30.276157	Training Loss 0.8321 (0.8322)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.015)	
2022-03-26 23:28:21,697: ============================================================
2022-03-26 23:30:08,245: time cost, forward:0.28475033077729994, backward:0.04425127947984003, data cost:0.7391168945262125 
2022-03-26 23:30:08,245: ============================================================
2022-03-26 23:30:08,246: Epoch 11/26 Batch 2500/7662 eta: 1 day, 11:32:38.435761	Training Loss 0.8300 (0.8321)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.015)	
2022-03-26 23:30:08,246: ============================================================
2022-03-26 23:31:53,783: time cost, forward:0.28444382409583424, backward:0.04429994091798636, data cost:0.7391854055389252 
2022-03-26 23:31:53,784: ============================================================
2022-03-26 23:31:53,784: Epoch 11/26 Batch 2600/7662 eta: 1 day, 11:10:38.425030	Training Loss 0.8295 (0.8320)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.015)	
2022-03-26 23:31:53,784: ============================================================
2022-03-26 23:33:36,791: time cost, forward:0.28408170868264787, backward:0.04432443858694703, data cost:0.7380203628328033 
2022-03-26 23:33:36,792: ============================================================
2022-03-26 23:33:36,792: Epoch 11/26 Batch 2700/7662 eta: 1 day, 10:18:19.978165	Training Loss 0.8277 (0.8319)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.015)	
2022-03-26 23:33:36,793: ============================================================
2022-03-26 23:35:21,588: time cost, forward:0.2835969242635647, backward:0.044337919244769645, data cost:0.7378317746744705 
2022-03-26 23:35:21,588: ============================================================
2022-03-26 23:35:21,589: Epoch 11/26 Batch 2800/7662 eta: 1 day, 10:52:18.592452	Training Loss 0.8299 (0.8318)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.015)	
2022-03-26 23:35:21,589: ============================================================
2022-03-26 23:37:07,750: time cost, forward:0.28362775950976266, backward:0.04437801483459578, data cost:0.7376534977465837 
2022-03-26 23:37:07,750: ============================================================
2022-03-26 23:37:07,750: Epoch 11/26 Batch 2900/7662 eta: 1 day, 11:17:47.922407	Training Loss 0.8306 (0.8317)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.016)	
2022-03-26 23:37:07,750: ============================================================
2022-03-26 23:38:52,276: time cost, forward:0.28368603575026924, backward:0.04431551422584689, data cost:0.7369627402440116 
2022-03-26 23:38:52,276: ============================================================
2022-03-26 23:38:52,276: Epoch 11/26 Batch 3000/7662 eta: 1 day, 10:43:26.183524	Training Loss 0.8296 (0.8316)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.016)	
2022-03-26 23:38:52,277: ============================================================
2022-03-26 23:40:37,417: time cost, forward:0.28367092817896755, backward:0.04432324503036652, data cost:0.7365150148540053 
2022-03-26 23:40:37,417: ============================================================
2022-03-26 23:40:37,417: Epoch 11/26 Batch 3100/7662 eta: 1 day, 10:53:55.796715	Training Loss 0.8282 (0.8315)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.195 (0.017)	
2022-03-26 23:40:37,417: ============================================================
2022-03-26 23:42:22,306: time cost, forward:0.2832711059699099, backward:0.044302648512711186, data cost:0.7362740655435775 
2022-03-26 23:42:22,306: ============================================================
2022-03-26 23:42:22,307: Epoch 11/26 Batch 3200/7662 eta: 1 day, 10:47:10.508551	Training Loss 0.8247 (0.8314)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.019)	
2022-03-26 23:42:22,307: ============================================================
2022-03-26 23:44:07,574: time cost, forward:0.2832472807857332, backward:0.04425448524334027, data cost:0.7360774408365315 
2022-03-26 23:44:07,574: ============================================================
2022-03-26 23:44:07,575: Epoch 11/26 Batch 3300/7662 eta: 1 day, 10:52:57.380134	Training Loss 0.8232 (0.8312)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.022)	
2022-03-26 23:44:07,575: ============================================================
2022-03-26 23:45:52,020: time cost, forward:0.28348333178354945, backward:0.04419520477155757, data cost:0.7353888295194126 
2022-03-26 23:45:52,020: ============================================================
2022-03-26 23:45:52,021: Epoch 11/26 Batch 3400/7662 eta: 1 day, 10:34:52.502772	Training Loss 0.8255 (0.8310)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.195 (0.026)	
2022-03-26 23:45:52,021: ============================================================
2022-03-26 23:47:38,393: time cost, forward:0.28333525856619873, backward:0.04418772498210112, data cost:0.7355054309961625 
2022-03-26 23:47:38,393: ============================================================
2022-03-26 23:47:38,393: Epoch 11/26 Batch 3500/7662 eta: 1 day, 11:11:21.932182	Training Loss 0.8222 (0.8308)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.030)	
2022-03-26 23:47:38,393: ============================================================
2022-03-26 23:49:08,099: time cost, forward:0.28229031923182246, backward:0.04411494927328141, data cost:0.7320925029458918 
2022-03-26 23:49:08,100: ============================================================
2022-03-26 23:49:08,100: Epoch 11/26 Batch 3600/7662 eta: 1 day, 5:39:05.067836	Training Loss 0.8231 (0.8306)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.033)	
2022-03-26 23:49:08,100: ============================================================
2022-03-26 23:50:15,017: time cost, forward:0.28013669165059274, backward:0.04389100378995072, data cost:0.7239396337497296 
2022-03-26 23:50:15,029: ============================================================
2022-03-26 23:50:15,029: Epoch 11/26 Batch 3700/7662 eta: 22:06:14.327850	Training Loss 0.8228 (0.8304)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.037)	
2022-03-26 23:50:15,030: ============================================================
2022-03-26 23:51:21,552: time cost, forward:0.2780737382984689, backward:0.04368476398244096, data cost:0.7161274921520662 
2022-03-26 23:51:21,552: ============================================================
2022-03-26 23:51:21,552: Epoch 11/26 Batch 3800/7662 eta: 21:57:04.750377	Training Loss 0.8264 (0.8302)	Training Prec@1 0.195 (0.010)	Training Prec@5 0.391 (0.042)	
2022-03-26 23:51:21,553: ============================================================
2022-03-26 23:52:47,124: time cost, forward:0.27679204965255355, backward:0.04359725843059249, data cost:0.7127869765738335 
2022-03-26 23:52:47,124: ============================================================
2022-03-26 23:52:47,124: Epoch 11/26 Batch 3900/7662 eta: 1 day, 4:12:47.996914	Training Loss 0.8225 (0.8300)	Training Prec@1 0.000 (0.012)	Training Prec@5 0.195 (0.048)	
2022-03-26 23:52:47,125: ============================================================
2022-03-26 23:54:28,939: time cost, forward:0.27631925427636433, backward:0.043563620809854105, data cost:0.7129262961516174 
2022-03-26 23:54:28,940: ============================================================
2022-03-26 23:54:28,940: Epoch 11/26 Batch 4000/7662 eta: 1 day, 9:32:25.738414	Training Loss 0.8221 (0.8298)	Training Prec@1 0.000 (0.013)	Training Prec@5 0.195 (0.054)	
2022-03-26 23:54:28,940: ============================================================
2022-03-26 23:56:13,860: time cost, forward:0.27633939443142946, backward:0.0435940856961513, data cost:0.7130199952601339 
2022-03-26 23:56:13,861: ============================================================
2022-03-26 23:56:13,862: Epoch 11/26 Batch 4100/7662 eta: 1 day, 10:32:04.793422	Training Loss 0.8198 (0.8295)	Training Prec@1 0.000 (0.015)	Training Prec@5 0.000 (0.060)	
2022-03-26 23:56:13,862: ============================================================
2022-03-26 23:57:59,682: time cost, forward:0.27607667761264626, backward:0.04366220273015385, data cost:0.7140528755433277 
2022-03-26 23:57:59,682: ============================================================
2022-03-26 23:57:59,682: Epoch 11/26 Batch 4200/7662 eta: 1 day, 10:48:04.330907	Training Loss 0.8190 (0.8293)	Training Prec@1 0.000 (0.018)	Training Prec@5 0.195 (0.069)	
2022-03-26 23:57:59,682: ============================================================
2022-03-26 23:59:41,680: time cost, forward:0.2759508102210241, backward:0.04367924390989394, data cost:0.7138125283076447 
2022-03-26 23:59:41,680: ============================================================
2022-03-26 23:59:41,681: Epoch 11/26 Batch 4300/7662 eta: 1 day, 9:30:56.994355	Training Loss 0.8180 (0.8290)	Training Prec@1 0.000 (0.022)	Training Prec@5 0.781 (0.082)	
2022-03-26 23:59:41,681: ============================================================
2022-03-27 00:01:22,947: time cost, forward:0.27596894717536263, backward:0.04367790365251635, data cost:0.7132745844907559 
2022-03-27 00:01:22,948: ============================================================
2022-03-27 00:01:22,948: Epoch 11/26 Batch 4400/7662 eta: 1 day, 9:14:51.093649	Training Loss 0.8136 (0.8287)	Training Prec@1 0.391 (0.028)	Training Prec@5 1.172 (0.104)	
2022-03-27 00:01:22,948: ============================================================
2022-03-27 00:03:06,736: time cost, forward:0.2758640896932208, backward:0.043657130838950814, data cost:0.7133760952000937 
2022-03-27 00:03:06,737: ============================================================
2022-03-27 00:03:06,737: Epoch 11/26 Batch 4500/7662 eta: 1 day, 10:02:47.886182	Training Loss 0.7844 (0.8281)	Training Prec@1 2.539 (0.064)	Training Prec@5 6.836 (0.194)	
2022-03-27 00:03:06,738: ============================================================
2022-03-27 00:04:49,659: time cost, forward:0.2759966038962918, backward:0.043637873427093896, data cost:0.7133575024410911 
2022-03-27 00:04:49,659: ============================================================
2022-03-27 00:04:49,659: Epoch 11/26 Batch 4600/7662 eta: 1 day, 9:44:00.554800	Training Loss 0.7761 (0.8270)	Training Prec@1 3.711 (0.167)	Training Prec@5 9.375 (0.408)	
2022-03-27 00:04:49,659: ============================================================
2022-03-27 00:06:32,236: time cost, forward:0.276026633679296, backward:0.04363835007618224, data cost:0.7131341562597872 
2022-03-27 00:06:32,237: ============================================================
2022-03-27 00:06:32,237: Epoch 11/26 Batch 4700/7662 eta: 1 day, 9:35:32.138833	Training Loss 0.7727 (0.8259)	Training Prec@1 5.078 (0.301)	Training Prec@5 12.695 (0.668)	
2022-03-27 00:06:32,237: ============================================================
2022-03-27 00:08:15,855: time cost, forward:0.2760132712904526, backward:0.04366937282806289, data cost:0.7131848947831456 
2022-03-27 00:08:15,855: ============================================================
2022-03-27 00:08:15,856: Epoch 11/26 Batch 4800/7662 eta: 1 day, 9:54:15.402045	Training Loss 0.7665 (0.8247)	Training Prec@1 7.031 (0.466)	Training Prec@5 13.867 (0.974)	
2022-03-27 00:08:15,856: ============================================================
2022-03-27 00:09:57,286: time cost, forward:0.27600514725729697, backward:0.04367068724428836, data cost:0.7127846480632564 
2022-03-27 00:09:57,287: ============================================================
2022-03-27 00:09:57,287: Epoch 11/26 Batch 4900/7662 eta: 1 day, 9:09:37.907129	Training Loss 0.7653 (0.8234)	Training Prec@1 8.008 (0.658)	Training Prec@5 14.258 (1.314)	
2022-03-27 00:09:57,287: ============================================================
2022-03-27 00:11:42,067: time cost, forward:0.2762478689928965, backward:0.043700799486069086, data cost:0.7127269089376957 
2022-03-27 00:11:42,068: ============================================================
2022-03-27 00:11:42,068: Epoch 11/26 Batch 5000/7662 eta: 1 day, 10:13:35.372978	Training Loss 0.7568 (0.8221)	Training Prec@1 13.086 (0.881)	Training Prec@5 22.461 (1.695)	
2022-03-27 00:11:42,069: ============================================================
2022-03-27 00:13:27,204: time cost, forward:0.2762516418329102, backward:0.043722282977496016, data cost:0.7131717927457305 
2022-03-27 00:13:27,204: ============================================================
2022-03-27 00:13:27,204: Epoch 11/26 Batch 5100/7662 eta: 1 day, 10:18:47.411811	Training Loss 0.8281 (0.8219)	Training Prec@1 0.000 (0.938)	Training Prec@5 0.000 (1.788)	
2022-03-27 00:13:27,204: ============================================================
2022-03-27 00:15:11,446: time cost, forward:0.2762364355227791, backward:0.043726243521530234, data cost:0.7133687576621192 
2022-03-27 00:15:11,446: ============================================================
2022-03-27 00:15:11,446: Epoch 11/26 Batch 5200/7662 eta: 1 day, 9:59:32.534933	Training Loss 0.8297 (0.8220)	Training Prec@1 0.000 (0.920)	Training Prec@5 0.000 (1.754)	
2022-03-27 00:15:11,446: ============================================================
2022-03-27 00:16:54,703: time cost, forward:0.27601952448411354, backward:0.043741977716486594, data cost:0.7135433519892163 
2022-03-27 00:16:54,703: ============================================================
2022-03-27 00:16:54,703: Epoch 11/26 Batch 5300/7662 eta: 1 day, 9:38:33.127547	Training Loss 0.8296 (0.8221)	Training Prec@1 0.000 (0.903)	Training Prec@5 0.000 (1.721)	
2022-03-27 00:16:54,703: ============================================================
2022-03-27 00:18:38,812: time cost, forward:0.27588557304994205, backward:0.043739835472764034, data cost:0.7136576071031051 
2022-03-27 00:18:38,813: ============================================================
2022-03-27 00:18:38,813: Epoch 11/26 Batch 5400/7662 eta: 1 day, 9:53:29.882249	Training Loss 0.8287 (0.8222)	Training Prec@1 0.000 (0.886)	Training Prec@5 0.000 (1.690)	
2022-03-27 00:18:38,814: ============================================================
2022-03-27 00:20:22,233: time cost, forward:0.27581488043422114, backward:0.04375788969958039, data cost:0.7138855829306529 
2022-03-27 00:20:22,233: ============================================================
2022-03-27 00:20:22,234: Epoch 11/26 Batch 5500/7662 eta: 1 day, 9:38:17.971250	Training Loss 0.8296 (0.8223)	Training Prec@1 0.195 (0.870)	Training Prec@5 0.195 (1.659)	
2022-03-27 00:20:22,234: ============================================================
2022-03-27 00:22:03,994: time cost, forward:0.27590138487654897, backward:0.043723447000497066, data cost:0.7135117194933175 
2022-03-27 00:22:03,995: ============================================================
2022-03-27 00:22:03,996: Epoch 11/26 Batch 5600/7662 eta: 1 day, 9:04:14.132804	Training Loss 0.8296 (0.8225)	Training Prec@1 0.000 (0.854)	Training Prec@5 0.000 (1.630)	
2022-03-27 00:22:03,996: ============================================================
2022-03-27 00:23:45,725: time cost, forward:0.27584493668545, backward:0.043572130527887915, data cost:0.7134390594373985 
2022-03-27 00:23:45,726: ============================================================
2022-03-27 00:23:45,726: Epoch 11/26 Batch 5700/7662 eta: 1 day, 9:01:55.917789	Training Loss 0.8308 (0.8226)	Training Prec@1 0.000 (0.839)	Training Prec@5 0.195 (1.601)	
2022-03-27 00:23:45,726: ============================================================
2022-03-27 00:25:31,216: time cost, forward:0.2758762536737133, backward:0.04358045732919503, data cost:0.7137959042095402 
2022-03-27 00:25:31,216: ============================================================
2022-03-27 00:25:31,217: Epoch 11/26 Batch 5800/7662 eta: 1 day, 10:13:25.545809	Training Loss 0.8287 (0.8227)	Training Prec@1 0.000 (0.825)	Training Prec@5 0.000 (1.574)	
2022-03-27 00:25:31,217: ============================================================
2022-03-27 00:27:15,403: time cost, forward:0.2759383756198162, backward:0.0435887414088672, data cost:0.713744252672598 
2022-03-27 00:27:15,404: ============================================================
2022-03-27 00:27:15,404: Epoch 11/26 Batch 5900/7662 eta: 1 day, 9:46:19.644017	Training Loss 0.8296 (0.8227)	Training Prec@1 0.000 (0.811)	Training Prec@5 0.000 (1.548)	
2022-03-27 00:27:15,404: ============================================================
2022-03-27 00:28:59,184: time cost, forward:0.27589539838524774, backward:0.04355360448588966, data cost:0.7139179708163208 
2022-03-27 00:28:59,185: ============================================================
2022-03-27 00:28:59,186: Epoch 11/26 Batch 6000/7662 eta: 1 day, 9:36:41.445147	Training Loss 0.8262 (0.8228)	Training Prec@1 0.000 (0.797)	Training Prec@5 0.195 (1.522)	
2022-03-27 00:28:59,186: ============================================================
2022-03-27 00:30:39,672: time cost, forward:0.27555698733932565, backward:0.04335799821577496, data cost:0.7140667636700586 
2022-03-27 00:30:39,673: ============================================================
2022-03-27 00:30:39,673: Epoch 11/26 Batch 6100/7662 eta: 1 day, 8:31:01.059410	Training Loss 0.8279 (0.8229)	Training Prec@1 0.000 (0.784)	Training Prec@5 0.000 (1.497)	
2022-03-27 00:30:39,673: ============================================================
2022-03-27 00:32:24,726: time cost, forward:0.27550142379437054, backward:0.04331569572401962, data cost:0.7144313250497226 
2022-03-27 00:32:24,726: ============================================================
2022-03-27 00:32:24,727: Epoch 11/26 Batch 6200/7662 eta: 1 day, 9:57:55.232095	Training Loss 0.8295 (0.8230)	Training Prec@1 0.000 (0.772)	Training Prec@5 0.195 (1.473)	
2022-03-27 00:32:24,727: ============================================================
2022-03-27 00:34:06,584: time cost, forward:0.2753703814874586, backward:0.04332283701777818, data cost:0.71429749995418 
2022-03-27 00:34:06,585: ============================================================
2022-03-27 00:34:06,586: Epoch 11/26 Batch 6300/7662 eta: 1 day, 8:54:14.698293	Training Loss 0.8265 (0.8231)	Training Prec@1 0.000 (0.759)	Training Prec@5 0.000 (1.450)	
2022-03-27 00:34:06,586: ============================================================
2022-03-27 00:35:50,614: time cost, forward:0.27535300367343124, backward:0.04333681254708072, data cost:0.7144367819298877 
2022-03-27 00:35:50,614: ============================================================
2022-03-27 00:35:50,614: Epoch 11/26 Batch 6400/7662 eta: 1 day, 9:34:34.364494	Training Loss 0.8278 (0.8231)	Training Prec@1 0.000 (0.748)	Training Prec@5 0.000 (1.428)	
2022-03-27 00:35:50,615: ============================================================
2022-03-27 00:37:31,566: time cost, forward:0.27531229699459564, backward:0.0433803054071753, data cost:0.7140599609356804 
2022-03-27 00:37:31,566: ============================================================
2022-03-27 00:37:31,566: Epoch 11/26 Batch 6500/7662 eta: 1 day, 8:33:17.809718	Training Loss 0.8280 (0.8232)	Training Prec@1 0.000 (0.736)	Training Prec@5 0.000 (1.406)	
2022-03-27 00:37:31,566: ============================================================
2022-03-27 00:39:10,948: time cost, forward:0.27519882561709236, backward:0.04342970213649453, data cost:0.7135278130141257 
2022-03-27 00:39:10,948: ============================================================
2022-03-27 00:39:10,949: Epoch 11/26 Batch 6600/7662 eta: 1 day, 8:01:16.493977	Training Loss 0.8303 (0.8233)	Training Prec@1 0.000 (0.725)	Training Prec@5 0.000 (1.385)	
2022-03-27 00:39:10,949: ============================================================
2022-03-27 00:40:54,622: time cost, forward:0.27524107843214835, backward:0.04344382515984305, data cost:0.713546172845433 
2022-03-27 00:40:54,623: ============================================================
2022-03-27 00:40:54,623: Epoch 11/26 Batch 6700/7662 eta: 1 day, 9:22:31.954684	Training Loss 0.8260 (0.8233)	Training Prec@1 0.000 (0.714)	Training Prec@5 0.000 (1.365)	
2022-03-27 00:40:54,624: ============================================================
2022-03-27 00:42:37,727: time cost, forward:0.27512849592289373, backward:0.04351467447327172, data cost:0.713534581904938 
2022-03-27 00:42:37,728: ============================================================
2022-03-27 00:42:37,729: Epoch 11/26 Batch 6800/7662 eta: 1 day, 9:09:48.430923	Training Loss 0.8258 (0.8234)	Training Prec@1 0.000 (0.704)	Training Prec@5 0.000 (1.345)	
2022-03-27 00:42:37,729: ============================================================
2022-03-27 00:44:20,880: time cost, forward:0.27508528340742333, backward:0.0435505310751974, data cost:0.7135580153478404 
2022-03-27 00:44:20,880: ============================================================
2022-03-27 00:44:20,880: Epoch 11/26 Batch 6900/7662 eta: 1 day, 9:08:59.421808	Training Loss 0.8273 (0.8234)	Training Prec@1 0.000 (0.694)	Training Prec@5 0.000 (1.326)	
2022-03-27 00:44:20,880: ============================================================
2022-03-27 00:46:00,864: time cost, forward:0.275023861908371, backward:0.04350730520876021, data cost:0.7131788006747241 
2022-03-27 00:46:00,865: ============================================================
2022-03-27 00:46:00,865: Epoch 11/26 Batch 7000/7662 eta: 1 day, 8:06:15.057651	Training Loss 0.8282 (0.8235)	Training Prec@1 0.000 (0.684)	Training Prec@5 0.000 (1.307)	
2022-03-27 00:46:00,865: ============================================================
2022-03-27 00:47:41,216: time cost, forward:0.2749695591833209, backward:0.04350019256940004, data cost:0.7128394729806632 
2022-03-27 00:47:41,216: ============================================================
2022-03-27 00:47:41,216: Epoch 11/26 Batch 7100/7662 eta: 1 day, 8:11:38.903414	Training Loss 0.8246 (0.8235)	Training Prec@1 0.000 (0.674)	Training Prec@5 0.195 (1.289)	
2022-03-27 00:47:41,216: ============================================================
2022-03-27 00:49:23,591: time cost, forward:0.27497440153467173, backward:0.0435236252120906, data cost:0.712665635623076 
2022-03-27 00:49:23,591: ============================================================
2022-03-27 00:49:23,591: Epoch 11/26 Batch 7200/7662 eta: 1 day, 8:48:53.858043	Training Loss 0.8231 (0.8235)	Training Prec@1 0.195 (0.665)	Training Prec@5 0.195 (1.272)	
2022-03-27 00:49:23,592: ============================================================
2022-03-27 00:51:04,832: time cost, forward:0.27509277398365134, backward:0.043521748093452044, data cost:0.7123254421459908 
2022-03-27 00:51:04,833: ============================================================
2022-03-27 00:51:04,833: Epoch 11/26 Batch 7300/7662 eta: 1 day, 8:25:24.251979	Training Loss 0.8235 (0.8235)	Training Prec@1 0.000 (0.657)	Training Prec@5 0.391 (1.257)	
2022-03-27 00:51:04,833: ============================================================
2022-03-27 00:52:45,848: time cost, forward:0.27512174932549716, backward:0.043519845958142074, data cost:0.7120154443375564 
2022-03-27 00:52:45,848: ============================================================
2022-03-27 00:52:45,849: Epoch 11/26 Batch 7400/7662 eta: 1 day, 8:19:23.396895	Training Loss 0.8201 (0.8235)	Training Prec@1 0.000 (0.649)	Training Prec@5 0.000 (1.244)	
2022-03-27 00:52:45,850: ============================================================
2022-03-27 00:54:29,732: time cost, forward:0.27510341114482173, backward:0.04354622335748078, data cost:0.7120986916666302 
2022-03-27 00:54:29,733: ============================================================
2022-03-27 00:54:29,733: Epoch 11/26 Batch 7500/7662 eta: 1 day, 9:12:43.225364	Training Loss 0.8194 (0.8234)	Training Prec@1 0.000 (0.641)	Training Prec@5 0.000 (1.231)	
2022-03-27 00:54:29,733: ============================================================
2022-03-27 00:56:11,087: time cost, forward:0.2749734609468091, backward:0.0435404374985683, data cost:0.7120199229218706 
2022-03-27 00:56:11,088: ============================================================
2022-03-27 00:56:11,088: Epoch 11/26 Batch 7600/7662 eta: 1 day, 8:22:31.350377	Training Loss 0.8210 (0.8234)	Training Prec@1 0.195 (0.633)	Training Prec@5 0.391 (1.219)	
2022-03-27 00:56:11,088: ============================================================
2022-03-27 00:57:15,749: Epoch: 11/26 eta: 1 day, 8:21:27.496620	Training Loss 0.8199 (0.8234)	Training Prec@1 0.195 (0.629)	Training Prec@5 0.586 (1.213)
2022-03-27 00:57:15,757: ============================================================
2022-03-27 00:59:05,945: time cost, forward:0.26128448139537463, backward:0.03720069413233285, data cost:0.8056417474843035 
2022-03-27 00:59:05,946: ============================================================
2022-03-27 00:59:05,947: Epoch 12/26 Batch 100/7662 eta: 1 day, 11:03:24.901827	Training Loss 0.8171 (0.8176)	Training Prec@1 0.195 (0.182)	Training Prec@5 1.758 (0.618)	
2022-03-27 00:59:05,947: ============================================================
2022-03-27 01:00:46,568: time cost, forward:0.2670472363131729, backward:0.03562544937708869, data cost:0.7480934528849232 
2022-03-27 01:00:46,569: ============================================================
2022-03-27 01:00:46,569: Epoch 12/26 Batch 200/7662 eta: 1 day, 8:04:05.373013	Training Loss 0.8145 (0.8169)	Training Prec@1 0.391 (0.221)	Training Prec@5 0.977 (0.668)	
2022-03-27 01:00:46,570: ============================================================
2022-03-27 01:02:26,073: time cost, forward:0.27232824918817117, backward:0.03742742697929459, data cost:0.7248591244420081 
2022-03-27 01:02:26,073: ============================================================
2022-03-27 01:02:26,073: Epoch 12/26 Batch 300/7662 eta: 1 day, 7:41:02.871563	Training Loss 0.8106 (0.8158)	Training Prec@1 0.195 (0.269)	Training Prec@5 1.172 (0.859)	
2022-03-27 01:02:26,074: ============================================================
2022-03-27 01:04:07,696: time cost, forward:0.27137712846722517, backward:0.03853313904955871, data cost:0.7199432186614302 
2022-03-27 01:04:07,697: ============================================================
2022-03-27 01:04:07,698: Epoch 12/26 Batch 400/7662 eta: 1 day, 8:19:51.233649	Training Loss 0.7702 (0.8099)	Training Prec@1 5.273 (1.078)	Training Prec@5 12.500 (2.501)	
2022-03-27 01:04:07,698: ============================================================
2022-03-27 01:05:50,699: time cost, forward:0.2723050461503451, backward:0.037840496800944416, data cost:0.718291552128916 
2022-03-27 01:05:50,699: ============================================================
2022-03-27 01:05:50,700: Epoch 12/26 Batch 500/7662 eta: 1 day, 8:44:26.088590	Training Loss 0.7600 (0.8006)	Training Prec@1 11.328 (2.979)	Training Prec@5 19.727 (5.667)	
2022-03-27 01:05:50,700: ============================================================
2022-03-27 01:07:33,017: time cost, forward:0.27236502198424684, backward:0.0380958547576242, data cost:0.7181179686659366 
2022-03-27 01:07:33,018: ============================================================
2022-03-27 01:07:33,018: Epoch 12/26 Batch 600/7662 eta: 1 day, 8:29:41.638621	Training Loss 0.7588 (0.7932)	Training Prec@1 12.695 (4.707)	Training Prec@5 20.508 (8.402)	
2022-03-27 01:07:33,018: ============================================================
2022-03-27 01:09:15,853: time cost, forward:0.27274926981018677, backward:0.038632737379387896, data cost:0.7168768598286379 
2022-03-27 01:09:15,854: ============================================================
2022-03-27 01:09:15,854: Epoch 12/26 Batch 700/7662 eta: 1 day, 8:37:51.044852	Training Loss 0.8280 (0.7903)	Training Prec@1 0.000 (5.598)	Training Prec@5 0.000 (9.742)	
2022-03-27 01:09:15,855: ============================================================
2022-03-27 01:10:56,089: time cost, forward:0.271936008718345, backward:0.03934537752698151, data cost:0.7139747632161547 
2022-03-27 01:10:56,089: ============================================================
2022-03-27 01:10:56,090: Epoch 12/26 Batch 800/7662 eta: 1 day, 7:46:39.471676	Training Loss 0.8252 (0.7950)	Training Prec@1 0.000 (4.897)	Training Prec@5 0.195 (8.525)	
2022-03-27 01:10:56,090: ============================================================
2022-03-27 01:12:37,201: time cost, forward:0.2709787966014281, backward:0.03960807914861185, data cost:0.713122925583327 
2022-03-27 01:12:37,201: ============================================================
2022-03-27 01:12:37,201: Epoch 12/26 Batch 900/7662 eta: 1 day, 8:01:38.601132	Training Loss 0.8275 (0.7985)	Training Prec@1 0.000 (4.352)	Training Prec@5 0.000 (7.577)	
2022-03-27 01:12:37,201: ============================================================
2022-03-27 01:14:18,502: time cost, forward:0.27186261641012655, backward:0.04004913001685768, data cost:0.7103008686959207 
2022-03-27 01:14:18,502: ============================================================
2022-03-27 01:14:18,502: Epoch 12/26 Batch 1000/7662 eta: 1 day, 8:03:33.422809	Training Loss 0.8296 (0.8014)	Training Prec@1 0.000 (3.917)	Training Prec@5 0.000 (6.820)	
2022-03-27 01:14:18,502: ============================================================
2022-03-27 01:16:01,194: time cost, forward:0.2770600373144037, backward:0.04043288183168892, data cost:0.7055108445248244 
2022-03-27 01:16:01,194: ============================================================
2022-03-27 01:16:01,195: Epoch 12/26 Batch 1100/7662 eta: 1 day, 8:28:15.448477	Training Loss 0.8260 (0.8037)	Training Prec@1 0.000 (3.562)	Training Prec@5 0.000 (6.202)	
2022-03-27 01:16:01,195: ============================================================
2022-03-27 01:17:35,414: time cost, forward:0.27585992323944625, backward:0.040661684963681284, data cost:0.6996786465139763 
2022-03-27 01:17:35,415: ============================================================
2022-03-27 01:17:35,415: Epoch 12/26 Batch 1200/7662 eta: 1 day, 5:45:57.727308	Training Loss 0.8258 (0.8056)	Training Prec@1 0.000 (3.265)	Training Prec@5 0.000 (5.686)	
2022-03-27 01:17:35,415: ============================================================
2022-03-27 01:19:15,595: time cost, forward:0.27507356481427314, backward:0.040790287873853255, data cost:0.6988684949368307 
2022-03-27 01:19:15,619: ============================================================
2022-03-27 01:19:15,619: Epoch 12/26 Batch 1300/7662 eta: 1 day, 7:37:43.083301	Training Loss 0.8272 (0.8072)	Training Prec@1 0.000 (3.014)	Training Prec@5 0.000 (5.250)	
2022-03-27 01:19:15,620: ============================================================
2022-03-27 01:20:56,045: time cost, forward:0.27464391334811816, backward:0.04106501803558328, data cost:0.6986203880460029 
2022-03-27 01:20:56,046: ============================================================
2022-03-27 01:20:56,046: Epoch 12/26 Batch 1400/7662 eta: 1 day, 7:40:15.373298	Training Loss 0.8289 (0.8086)	Training Prec@1 0.000 (2.799)	Training Prec@5 0.000 (4.877)	
2022-03-27 01:20:56,046: ============================================================
2022-03-27 01:22:33,184: time cost, forward:0.27437017821247695, backward:0.041414555110002534, data cost:0.6950611995012462 
2022-03-27 01:22:33,185: ============================================================
2022-03-27 01:22:33,185: Epoch 12/26 Batch 1500/7662 eta: 1 day, 6:36:26.332908	Training Loss 0.8253 (0.8098)	Training Prec@1 0.000 (2.613)	Training Prec@5 0.000 (4.553)	
2022-03-27 01:22:33,186: ============================================================
2022-03-27 01:24:13,320: time cost, forward:0.27437986277877874, backward:0.04156277103674568, data cost:0.6946574129709383 
2022-03-27 01:24:13,321: ============================================================
2022-03-27 01:24:13,321: Epoch 12/26 Batch 1600/7662 eta: 1 day, 7:31:24.582908	Training Loss 0.8274 (0.8108)	Training Prec@1 0.000 (2.450)	Training Prec@5 0.000 (4.269)	
2022-03-27 01:24:13,321: ============================================================
2022-03-27 01:25:51,755: time cost, forward:0.2739053287528556, backward:0.04157780660749394, data cost:0.6936739943461112 
2022-03-27 01:25:51,755: ============================================================
2022-03-27 01:25:51,756: Epoch 12/26 Batch 1700/7662 eta: 1 day, 6:57:38.499874	Training Loss 0.8250 (0.8117)	Training Prec@1 0.000 (2.306)	Training Prec@5 0.000 (4.019)	
2022-03-27 01:25:51,756: ============================================================
2022-03-27 01:27:35,439: time cost, forward:0.2744151001973176, backward:0.0417188817491261, data cost:0.6945834909961779 
2022-03-27 01:27:35,440: ============================================================
2022-03-27 01:27:35,440: Epoch 12/26 Batch 1800/7662 eta: 1 day, 8:34:59.378563	Training Loss 0.8256 (0.8125)	Training Prec@1 0.000 (2.178)	Training Prec@5 0.000 (3.796)	
2022-03-27 01:27:35,440: ============================================================
2022-03-27 01:29:14,682: time cost, forward:0.27510802478398566, backward:0.04168164296926104, data cost:0.6926298695152969 
2022-03-27 01:29:14,684: ============================================================
2022-03-27 01:29:14,685: Epoch 12/26 Batch 1900/7662 eta: 1 day, 7:09:36.886320	Training Loss 0.8262 (0.8132)	Training Prec@1 0.000 (2.064)	Training Prec@5 0.000 (3.598)	
2022-03-27 01:29:14,685: ============================================================
2022-03-27 01:30:54,572: time cost, forward:0.27468167143264016, backward:0.041863243957946994, data cost:0.6924725524659989 
2022-03-27 01:30:54,572: ============================================================
2022-03-27 01:30:54,572: Epoch 12/26 Batch 2000/7662 eta: 1 day, 7:20:04.163231	Training Loss 0.8244 (0.8139)	Training Prec@1 0.000 (1.960)	Training Prec@5 0.195 (3.419)	
2022-03-27 01:30:54,572: ============================================================
2022-03-27 01:32:33,540: time cost, forward:0.2751464162229526, backward:0.04194760686048387, data cost:0.6908892626532945 
2022-03-27 01:32:33,541: ============================================================
2022-03-27 01:32:33,541: Epoch 12/26 Batch 2100/7662 eta: 1 day, 7:01:07.736446	Training Loss 0.8263 (0.8144)	Training Prec@1 0.000 (1.867)	Training Prec@5 0.000 (3.257)	
2022-03-27 01:32:33,542: ============================================================
2022-03-27 01:34:14,671: time cost, forward:0.2757827038654364, backward:0.04187133833732102, data cost:0.6906625974064472 
2022-03-27 01:34:14,671: ============================================================
2022-03-27 01:34:14,671: Epoch 12/26 Batch 2200/7662 eta: 1 day, 7:40:05.226227	Training Loss 0.8252 (0.8150)	Training Prec@1 0.000 (1.782)	Training Prec@5 0.000 (3.110)	
2022-03-27 01:34:14,672: ============================================================
2022-03-27 01:35:51,769: time cost, forward:0.27583859432464375, backward:0.04183251197154546, data cost:0.6889200201237808 
2022-03-27 01:35:51,770: ============================================================
2022-03-27 01:35:51,770: Epoch 12/26 Batch 2300/7662 eta: 1 day, 6:22:42.719117	Training Loss 0.8250 (0.8154)	Training Prec@1 0.000 (1.705)	Training Prec@5 0.000 (2.975)	
2022-03-27 01:35:51,770: ============================================================
2022-03-27 01:37:32,592: time cost, forward:0.27623889107364274, backward:0.04192861182931166, data cost:0.6883447638349068 
2022-03-27 01:37:32,592: ============================================================
2022-03-27 01:37:32,593: Epoch 12/26 Batch 2400/7662 eta: 1 day, 7:30:57.054151	Training Loss 0.8270 (0.8159)	Training Prec@1 0.000 (1.634)	Training Prec@5 0.000 (2.852)	
2022-03-27 01:37:32,593: ============================================================
2022-03-27 01:39:11,860: time cost, forward:0.2764047394279672, backward:0.04196817696499987, data cost:0.6877790858813313 
2022-03-27 01:39:11,860: ============================================================
2022-03-27 01:39:11,861: Epoch 12/26 Batch 2500/7662 eta: 1 day, 7:00:07.859399	Training Loss 0.8257 (0.8163)	Training Prec@1 0.000 (1.569)	Training Prec@5 0.000 (2.739)	
2022-03-27 01:39:11,861: ============================================================
2022-03-27 01:40:52,824: time cost, forward:0.2762190500283617, backward:0.04200000137308553, data cost:0.6879088406197701 
2022-03-27 01:40:52,824: ============================================================
2022-03-27 01:40:52,825: Epoch 12/26 Batch 2600/7662 eta: 1 day, 7:30:14.014375	Training Loss 0.8260 (0.8166)	Training Prec@1 0.000 (1.509)	Training Prec@5 0.000 (2.635)	
2022-03-27 01:40:52,825: ============================================================
2022-03-27 01:42:32,109: time cost, forward:0.27606321750370916, backward:0.04204562762438169, data cost:0.6876219780014903 
2022-03-27 01:42:32,109: ============================================================
2022-03-27 01:42:32,109: Epoch 12/26 Batch 2700/7662 eta: 1 day, 6:57:07.810729	Training Loss 0.8246 (0.8169)	Training Prec@1 0.000 (1.453)	Training Prec@5 0.000 (2.538)	
2022-03-27 01:42:32,109: ============================================================
2022-03-27 01:44:11,616: time cost, forward:0.2757467819818985, backward:0.04211225020710849, data cost:0.6874951479817425 
2022-03-27 01:44:11,616: ============================================================
2022-03-27 01:44:11,616: Epoch 12/26 Batch 2800/7662 eta: 1 day, 6:59:38.711976	Training Loss 0.8246 (0.8172)	Training Prec@1 0.000 (1.402)	Training Prec@5 0.000 (2.448)	
2022-03-27 01:44:11,617: ============================================================
2022-03-27 01:45:50,524: time cost, forward:0.27570610566154025, backward:0.042114932934306085, data cost:0.6866787619819391 
2022-03-27 01:45:50,524: ============================================================
2022-03-27 01:45:50,525: Epoch 12/26 Batch 2900/7662 eta: 1 day, 6:46:47.968171	Training Loss 0.8264 (0.8175)	Training Prec@1 0.000 (1.353)	Training Prec@5 0.000 (2.365)	
2022-03-27 01:45:50,525: ============================================================
2022-03-27 01:47:29,830: time cost, forward:0.27564246640995604, backward:0.04212657886173138, data cost:0.6866177363807497 
2022-03-27 01:47:29,831: ============================================================
2022-03-27 01:47:29,831: Epoch 12/26 Batch 3000/7662 eta: 1 day, 6:52:34.486000	Training Loss 0.8253 (0.8178)	Training Prec@1 0.000 (1.308)	Training Prec@5 0.195 (2.287)	
2022-03-27 01:47:29,831: ============================================================
2022-03-27 01:49:10,664: time cost, forward:0.275598292890846, backward:0.04224434695962399, data cost:0.6866712594809321 
2022-03-27 01:49:10,681: ============================================================
2022-03-27 01:49:10,681: Epoch 12/26 Batch 3100/7662 eta: 1 day, 7:19:41.238643	Training Loss 0.8257 (0.8180)	Training Prec@1 0.000 (1.266)	Training Prec@5 0.000 (2.214)	
2022-03-27 01:49:10,681: ============================================================
2022-03-27 01:50:51,174: time cost, forward:0.27555985151137663, backward:0.042321221535561344, data cost:0.6866401417175656 
2022-03-27 01:50:51,174: ============================================================
2022-03-27 01:50:51,175: Epoch 12/26 Batch 3200/7662 eta: 1 day, 7:11:22.705750	Training Loss 0.8252 (0.8182)	Training Prec@1 0.000 (1.227)	Training Prec@5 0.195 (2.146)	
2022-03-27 01:50:51,175: ============================================================
2022-03-27 01:52:31,848: time cost, forward:0.27545437627794095, backward:0.04228696327348231, data cost:0.6868223799254252 
2022-03-27 01:52:31,848: ============================================================
2022-03-27 01:52:31,849: Epoch 12/26 Batch 3300/7662 eta: 1 day, 7:13:03.350650	Training Loss 0.8250 (0.8184)	Training Prec@1 0.000 (1.190)	Training Prec@5 0.000 (2.081)	
2022-03-27 01:52:31,849: ============================================================
2022-03-27 01:54:09,341: time cost, forward:0.2752053089512205, backward:0.04231432600209348, data cost:0.6861662395423425 
2022-03-27 01:54:09,342: ============================================================
2022-03-27 01:54:09,342: Epoch 12/26 Batch 3400/7662 eta: 1 day, 6:12:15.359276	Training Loss 0.8240 (0.8186)	Training Prec@1 0.000 (1.155)	Training Prec@5 0.000 (2.021)	
2022-03-27 01:54:09,342: ============================================================
2022-03-27 01:55:48,518: time cost, forward:0.27510179400818796, backward:0.04234144741482447, data cost:0.6858741388759738 
2022-03-27 01:55:48,519: ============================================================
2022-03-27 01:55:48,520: Epoch 12/26 Batch 3500/7662 eta: 1 day, 6:41:55.002879	Training Loss 0.8250 (0.8188)	Training Prec@1 0.000 (1.123)	Training Prec@5 0.000 (1.965)	
2022-03-27 01:55:48,520: ============================================================
2022-03-27 01:57:27,386: time cost, forward:0.2748041692194789, backward:0.04237748808779959, data cost:0.6857418676123549 
2022-03-27 01:57:27,387: ============================================================
2022-03-27 01:57:27,387: Epoch 12/26 Batch 3600/7662 eta: 1 day, 6:34:29.497254	Training Loss 0.8236 (0.8190)	Training Prec@1 0.000 (1.092)	Training Prec@5 0.000 (1.911)	
2022-03-27 01:57:27,387: ============================================================
2022-03-27 01:59:07,584: time cost, forward:0.27488917922870504, backward:0.04240018285651825, data cost:0.6855702788225861 
2022-03-27 01:59:07,585: ============================================================
2022-03-27 01:59:07,585: Epoch 12/26 Batch 3700/7662 eta: 1 day, 6:57:31.160157	Training Loss 0.8270 (0.8191)	Training Prec@1 0.000 (1.062)	Training Prec@5 0.000 (1.860)	
2022-03-27 01:59:07,585: ============================================================
2022-03-27 02:00:46,919: time cost, forward:0.2746637957633938, backward:0.042403953644626236, data cost:0.6853444853654878 
2022-03-27 02:00:46,919: ============================================================
2022-03-27 02:00:46,920: Epoch 12/26 Batch 3800/7662 eta: 1 day, 6:39:51.898875	Training Loss 0.8245 (0.8192)	Training Prec@1 0.000 (1.034)	Training Prec@5 0.000 (1.812)	
2022-03-27 02:00:46,920: ============================================================
2022-03-27 02:02:25,527: time cost, forward:0.2743757014459266, backward:0.042417995377545724, data cost:0.6854227549236657 
2022-03-27 02:02:25,527: ============================================================
2022-03-27 02:02:25,527: Epoch 12/26 Batch 3900/7662 eta: 1 day, 6:24:45.146216	Training Loss 0.8231 (0.8194)	Training Prec@1 0.000 (1.008)	Training Prec@5 0.000 (1.766)	
2022-03-27 02:02:25,528: ============================================================
2022-03-27 02:04:03,734: time cost, forward:0.27405764419277123, backward:0.042464475984661604, data cost:0.6851536574200351 
2022-03-27 02:04:03,734: ============================================================
2022-03-27 02:04:03,734: Epoch 12/26 Batch 4000/7662 eta: 1 day, 6:15:41.552019	Training Loss 0.8255 (0.8195)	Training Prec@1 0.000 (0.983)	Training Prec@5 0.000 (1.723)	
2022-03-27 02:04:03,734: ============================================================
2022-03-27 02:05:44,310: time cost, forward:0.27389151650424354, backward:0.04248122303449226, data cost:0.6854099404902015 
2022-03-27 02:05:44,311: ============================================================
2022-03-27 02:05:44,311: Epoch 12/26 Batch 4100/7662 eta: 1 day, 6:57:50.381138	Training Loss 0.8246 (0.8196)	Training Prec@1 0.000 (0.959)	Training Prec@5 0.000 (1.682)	
2022-03-27 02:05:44,311: ============================================================
2022-03-27 02:07:24,295: time cost, forward:0.27371956320369945, backward:0.04252915145045492, data cost:0.6852861601104336 
2022-03-27 02:07:24,296: ============================================================
2022-03-27 02:07:24,297: Epoch 12/26 Batch 4200/7662 eta: 1 day, 6:45:15.076906	Training Loss 0.8248 (0.8197)	Training Prec@1 0.000 (0.937)	Training Prec@5 0.000 (1.643)	
2022-03-27 02:07:24,297: ============================================================
2022-03-27 02:08:59,744: time cost, forward:0.27337475232286046, backward:0.04251613015766947, data cost:0.6847138343286614 
2022-03-27 02:08:59,745: ============================================================
2022-03-27 02:08:59,746: Epoch 12/26 Batch 4300/7662 eta: 1 day, 5:19:56.278015	Training Loss 0.8243 (0.8198)	Training Prec@1 0.000 (0.915)	Training Prec@5 0.195 (1.606)	
2022-03-27 02:08:59,746: ============================================================
2022-03-27 02:10:42,826: time cost, forward:0.2733868535851099, backward:0.04255243804569162, data cost:0.6851690534191475 
2022-03-27 02:10:42,826: ============================================================
2022-03-27 02:10:42,827: Epoch 12/26 Batch 4400/7662 eta: 1 day, 7:38:56.320540	Training Loss 0.8227 (0.8199)	Training Prec@1 0.000 (0.895)	Training Prec@5 0.195 (1.571)	
2022-03-27 02:10:42,827: ============================================================
2022-03-27 02:12:20,591: time cost, forward:0.2732304169035244, backward:0.0426021431466955, data cost:0.6849307968341448 
2022-03-27 02:12:20,592: ============================================================
2022-03-27 02:12:20,592: Epoch 12/26 Batch 4500/7662 eta: 1 day, 5:59:23.319858	Training Loss 0.8220 (0.8199)	Training Prec@1 0.000 (0.875)	Training Prec@5 0.391 (1.538)	
2022-03-27 02:12:20,592: ============================================================
2022-03-27 02:14:00,095: time cost, forward:0.27315788166397004, backward:0.042610592156758796, data cost:0.6847527486963307 
2022-03-27 02:14:00,096: ============================================================
2022-03-27 02:14:00,096: Epoch 12/26 Batch 4600/7662 eta: 1 day, 6:29:44.185376	Training Loss 0.8240 (0.8200)	Training Prec@1 0.000 (0.857)	Training Prec@5 0.000 (1.506)	
2022-03-27 02:14:00,096: ============================================================
2022-03-27 02:15:40,254: time cost, forward:0.27308063421839984, backward:0.04258931203202051, data cost:0.6849600177390648 
2022-03-27 02:15:40,255: ============================================================
2022-03-27 02:15:40,255: Epoch 12/26 Batch 4700/7662 eta: 1 day, 6:40:05.799135	Training Loss 0.8223 (0.8201)	Training Prec@1 0.000 (0.838)	Training Prec@5 0.000 (1.475)	
2022-03-27 02:15:40,255: ============================================================
2022-03-27 02:17:21,210: time cost, forward:0.2731528770528651, backward:0.04261991952354398, data cost:0.6850364849601693 
2022-03-27 02:17:21,210: ============================================================
2022-03-27 02:17:21,210: Epoch 12/26 Batch 4800/7662 eta: 1 day, 6:53:03.204429	Training Loss 0.8231 (0.8201)	Training Prec@1 0.000 (0.822)	Training Prec@5 0.000 (1.446)	
2022-03-27 02:17:21,210: ============================================================
2022-03-27 02:18:58,481: time cost, forward:0.2729663073128402, backward:0.04262850123489358, data cost:0.6845747252147182 
2022-03-27 02:18:58,482: ============================================================
2022-03-27 02:18:58,483: Epoch 12/26 Batch 4900/7662 eta: 1 day, 5:43:49.533314	Training Loss 0.8218 (0.8201)	Training Prec@1 0.000 (0.805)	Training Prec@5 0.195 (1.419)	
2022-03-27 02:18:58,483: ============================================================
2022-03-27 02:20:38,797: time cost, forward:0.2729858424478017, backward:0.04272174396427137, data cost:0.6845703868537837 
2022-03-27 02:20:38,797: ============================================================
2022-03-27 02:20:38,797: Epoch 12/26 Batch 5000/7662 eta: 1 day, 6:37:57.201463	Training Loss 0.8210 (0.8202)	Training Prec@1 0.000 (0.790)	Training Prec@5 0.000 (1.393)	
2022-03-27 02:20:38,798: ============================================================
2022-03-27 02:22:19,955: time cost, forward:0.2728965547557531, backward:0.042769216700941234, data cost:0.684814825504989 
2022-03-27 02:22:19,956: ============================================================
2022-03-27 02:22:19,956: Epoch 12/26 Batch 5100/7662 eta: 1 day, 6:51:43.603144	Training Loss 0.8204 (0.8202)	Training Prec@1 0.000 (0.775)	Training Prec@5 0.195 (1.368)	
2022-03-27 02:22:19,956: ============================================================
2022-03-27 02:23:59,713: time cost, forward:0.27293639133517206, backward:0.04276806773027793, data cost:0.6847389819737145 
2022-03-27 02:23:59,714: ============================================================
2022-03-27 02:23:59,714: Epoch 12/26 Batch 5200/7662 eta: 1 day, 6:24:25.075705	Training Loss 0.8203 (0.8202)	Training Prec@1 0.000 (0.760)	Training Prec@5 0.000 (1.344)	
2022-03-27 02:23:59,714: ============================================================
2022-03-27 02:25:37,368: time cost, forward:0.27286530908806683, backward:0.04279487734584229, data cost:0.6843182217244675 
2022-03-27 02:25:37,369: ============================================================
2022-03-27 02:25:37,369: Epoch 12/26 Batch 5300/7662 eta: 1 day, 5:44:20.119562	Training Loss 0.8203 (0.8202)	Training Prec@1 0.195 (0.747)	Training Prec@5 0.195 (1.323)	
2022-03-27 02:25:37,369: ============================================================
2022-03-27 02:27:16,195: time cost, forward:0.2727946472026658, backward:0.04275915851900369, data cost:0.6841984462861684 
2022-03-27 02:27:16,195: ============================================================
2022-03-27 02:27:16,196: Epoch 12/26 Batch 5400/7662 eta: 1 day, 6:04:05.921319	Training Loss 0.8176 (0.8202)	Training Prec@1 0.195 (0.735)	Training Prec@5 0.391 (1.303)	
2022-03-27 02:27:16,196: ============================================================
2022-03-27 02:28:54,710: time cost, forward:0.272481632484135, backward:0.04275700516604493, data cost:0.6842500954936864 
2022-03-27 02:28:54,710: ============================================================
2022-03-27 02:28:54,710: Epoch 12/26 Batch 5500/7662 eta: 1 day, 5:56:45.774698	Training Loss 0.8100 (0.8201)	Training Prec@1 0.000 (0.724)	Training Prec@5 0.391 (1.288)	
2022-03-27 02:28:54,710: ============================================================
2022-03-27 02:30:35,154: time cost, forward:0.2724399078230833, backward:0.04277386595509184, data cost:0.6843562161503018 
2022-03-27 02:30:35,154: ============================================================
2022-03-27 02:30:35,154: Epoch 12/26 Batch 5600/7662 eta: 1 day, 6:30:16.504457	Training Loss 0.7794 (0.8196)	Training Prec@1 4.492 (0.749)	Training Prec@5 8.203 (1.355)	
2022-03-27 02:30:35,155: ============================================================
2022-03-27 02:32:10,711: time cost, forward:0.27234286616864717, backward:0.04278442599853312, data cost:0.6836540812378412 
2022-03-27 02:32:10,711: ============================================================
2022-03-27 02:32:10,711: Epoch 12/26 Batch 5700/7662 eta: 1 day, 4:59:37.440266	Training Loss 0.8252 (0.8190)	Training Prec@1 0.000 (0.816)	Training Prec@5 0.000 (1.494)	
2022-03-27 02:32:10,711: ============================================================
2022-03-27 02:33:50,614: time cost, forward:0.2722794574218529, backward:0.042807607573463004, data cost:0.6836939651116274 
2022-03-27 02:33:50,614: ============================================================
2022-03-27 02:33:50,614: Epoch 12/26 Batch 5800/7662 eta: 1 day, 6:17:05.435509	Training Loss 0.8181 (0.8190)	Training Prec@1 0.000 (0.803)	Training Prec@5 0.391 (1.470)	
2022-03-27 02:33:50,614: ============================================================
2022-03-27 02:35:26,373: time cost, forward:0.27258418390035105, backward:0.042782788317897474, data cost:0.6826786772641797 
2022-03-27 02:35:26,374: ============================================================
2022-03-27 02:35:26,375: Epoch 12/26 Batch 5900/7662 eta: 1 day, 5:00:07.926500	Training Loss 0.8121 (0.8190)	Training Prec@1 0.391 (0.792)	Training Prec@5 0.586 (1.454)	
2022-03-27 02:35:26,375: ============================================================
2022-03-27 02:37:10,315: time cost, forward:0.2735219797028524, backward:0.04278738285267546, data cost:0.6823464088150611 
2022-03-27 02:37:10,315: ============================================================
2022-03-27 02:37:10,315: Epoch 12/26 Batch 6000/7662 eta: 1 day, 7:27:04.182099	Training Loss 0.7978 (0.8187)	Training Prec@1 1.562 (0.800)	Training Prec@5 4.688 (1.481)	
2022-03-27 02:37:10,316: ============================================================
2022-03-27 02:38:49,119: time cost, forward:0.2743217292663054, backward:0.04280956011558091, data cost:0.6813253864614196 
2022-03-27 02:38:49,120: ============================================================
2022-03-27 02:38:49,121: Epoch 12/26 Batch 6100/7662 eta: 1 day, 5:52:10.429664	Training Loss 0.7717 (0.8180)	Training Prec@1 8.594 (0.904)	Training Prec@5 15.430 (1.675)	
2022-03-27 02:38:49,121: ============================================================
2022-03-27 02:40:27,878: time cost, forward:0.27476678969187396, backward:0.04277867316276648, data cost:0.6808361203694732 
2022-03-27 02:40:27,879: ============================================================
2022-03-27 02:40:27,879: Epoch 12/26 Batch 6200/7662 eta: 1 day, 5:49:41.160219	Training Loss 0.8239 (0.8180)	Training Prec@1 0.000 (0.900)	Training Prec@5 0.000 (1.667)	
2022-03-27 02:40:27,879: ============================================================
2022-03-27 02:42:07,920: time cost, forward:0.2751407803836598, backward:0.042750734547846544, data cost:0.6805302182309759 
2022-03-27 02:42:07,920: ============================================================
2022-03-27 02:42:07,921: Epoch 12/26 Batch 6300/7662 eta: 1 day, 6:11:16.284759	Training Loss 0.8261 (0.8182)	Training Prec@1 0.000 (0.885)	Training Prec@5 0.000 (1.641)	
2022-03-27 02:42:07,921: ============================================================
2022-03-27 02:43:46,996: time cost, forward:0.275483166916256, backward:0.04272954634231112, data cost:0.6800713106922329 
2022-03-27 02:43:46,996: ============================================================
2022-03-27 02:43:46,996: Epoch 12/26 Batch 6400/7662 eta: 1 day, 5:52:07.870527	Training Loss 0.8262 (0.8183)	Training Prec@1 0.000 (0.872)	Training Prec@5 0.000 (1.616)	
2022-03-27 02:43:46,997: ============================================================
2022-03-27 02:45:27,820: time cost, forward:0.27600448930202987, backward:0.04272358640191518, data cost:0.6796970806556182 
2022-03-27 02:45:27,844: ============================================================
2022-03-27 02:45:27,845: Epoch 12/26 Batch 6500/7662 eta: 1 day, 6:22:30.949153	Training Loss 0.8251 (0.8184)	Training Prec@1 0.000 (0.858)	Training Prec@5 0.195 (1.591)	
2022-03-27 02:45:27,846: ============================================================
2022-03-27 02:47:02,823: time cost, forward:0.27616616411089157, backward:0.04270266991598098, data cost:0.678809850500251 
2022-03-27 02:47:02,823: ============================================================
2022-03-27 02:47:02,823: Epoch 12/26 Batch 6600/7662 eta: 1 day, 4:34:51.315234	Training Loss 0.8189 (0.8184)	Training Prec@1 0.000 (0.847)	Training Prec@5 0.391 (1.571)	
2022-03-27 02:47:02,824: ============================================================
2022-03-27 02:48:40,865: time cost, forward:0.2763240576893701, backward:0.04274331129990615, data cost:0.6782902477570195 
2022-03-27 02:48:40,865: ============================================================
2022-03-27 02:48:40,866: Epoch 12/26 Batch 6700/7662 eta: 1 day, 5:28:31.973068	Training Loss 0.8148 (0.8184)	Training Prec@1 0.000 (0.836)	Training Prec@5 0.781 (1.554)	
2022-03-27 02:48:40,866: ============================================================
2022-03-27 02:50:16,780: time cost, forward:0.27635728946449584, backward:0.04275130078904435, data cost:0.6777642889046672 
2022-03-27 02:50:16,781: ============================================================
2022-03-27 02:50:16,781: Epoch 12/26 Batch 6800/7662 eta: 1 day, 4:48:34.389998	Training Loss 0.8131 (0.8184)	Training Prec@1 0.000 (0.827)	Training Prec@5 0.586 (1.542)	
2022-03-27 02:50:16,781: ============================================================
2022-03-27 02:51:53,996: time cost, forward:0.2765939528742706, backward:0.04269240614054324, data cost:0.677209943943325 
2022-03-27 02:51:53,997: ============================================================
2022-03-27 02:51:53,997: Epoch 12/26 Batch 6900/7662 eta: 1 day, 5:10:23.043318	Training Loss 0.7706 (0.8180)	Training Prec@1 7.617 (0.861)	Training Prec@5 14.258 (1.615)	
2022-03-27 02:51:53,997: ============================================================
2022-03-27 02:53:31,569: time cost, forward:0.27675459394796964, backward:0.04270303101177845, data cost:0.6767400902226101 
2022-03-27 02:53:31,570: ============================================================
2022-03-27 02:53:31,571: Epoch 12/26 Batch 7000/7662 eta: 1 day, 5:15:12.388980	Training Loss 0.7651 (0.8173)	Training Prec@1 11.328 (0.994)	Training Prec@5 17.188 (1.844)	
2022-03-27 02:53:31,571: ============================================================
2022-03-27 02:55:11,935: time cost, forward:0.2771622511950626, backward:0.04272117475704973, data cost:0.6764251379450201 
2022-03-27 02:55:11,935: ============================================================
2022-03-27 02:55:11,935: Epoch 12/26 Batch 7100/7662 eta: 1 day, 6:03:44.209353	Training Loss 0.8256 (0.8168)	Training Prec@1 0.000 (1.080)	Training Prec@5 0.000 (1.986)	
2022-03-27 02:55:11,935: ============================================================
2022-03-27 02:56:50,388: time cost, forward:0.27750975546828244, backward:0.04273579355444672, data cost:0.6758397382271755 
2022-03-27 02:56:50,388: ============================================================
2022-03-27 02:56:50,389: Epoch 12/26 Batch 7200/7662 eta: 1 day, 5:27:44.922397	Training Loss 0.8274 (0.8170)	Training Prec@1 0.000 (1.065)	Training Prec@5 0.000 (1.959)	
2022-03-27 02:56:50,389: ============================================================
2022-03-27 02:58:28,210: time cost, forward:0.2778225034242592, backward:0.042707393554518164, data cost:0.6753510910773183 
2022-03-27 02:58:28,210: ============================================================
2022-03-27 02:58:28,210: Epoch 12/26 Batch 7300/7662 eta: 1 day, 5:14:46.245389	Training Loss 0.8278 (0.8171)	Training Prec@1 0.000 (1.050)	Training Prec@5 0.000 (1.932)	
2022-03-27 02:58:28,210: ============================================================
2022-03-27 03:00:08,559: time cost, forward:0.2781713138739633, backward:0.04268253276534686, data cost:0.6751303940564334 
2022-03-27 03:00:08,560: ============================================================
2022-03-27 03:00:08,560: Epoch 12/26 Batch 7400/7662 eta: 1 day, 5:58:27.050236	Training Loss 0.8267 (0.8172)	Training Prec@1 0.000 (1.036)	Training Prec@5 0.000 (1.906)	
2022-03-27 03:00:08,560: ============================================================
2022-03-27 03:01:47,425: time cost, forward:0.278578186944447, backward:0.04270013053666148, data cost:0.674548141987169 
2022-03-27 03:01:47,443: ============================================================
2022-03-27 03:01:47,443: Epoch 12/26 Batch 7500/7662 eta: 1 day, 5:30:31.176963	Training Loss 0.8255 (0.8173)	Training Prec@1 0.000 (1.023)	Training Prec@5 0.000 (1.881)	
2022-03-27 03:01:47,443: ============================================================
2022-03-27 03:03:27,724: time cost, forward:0.27907876492111383, backward:0.04270057352550219, data cost:0.6741812235745243 
2022-03-27 03:03:27,724: ============================================================
2022-03-27 03:03:27,725: Epoch 12/26 Batch 7600/7662 eta: 1 day, 5:53:53.282735	Training Loss 0.8258 (0.8174)	Training Prec@1 0.000 (1.009)	Training Prec@5 0.000 (1.857)	
2022-03-27 03:03:27,725: ============================================================
2022-03-27 03:04:31,952: Epoch: 12/26 eta: 1 day, 5:52:50.105304	Training Loss 0.8264 (0.8175)	Training Prec@1 0.000 (1.001)	Training Prec@5 0.000 (1.841)
2022-03-27 03:04:31,953: ============================================================
2022-03-27 03:06:07,280: time cost, forward:0.2562685663049871, backward:0.03814924606169113, data cost:0.6598806790631226 
2022-03-27 03:06:07,280: ============================================================
2022-03-27 03:06:07,281: Epoch 13/26 Batch 100/7662 eta: 1 day, 4:18:09.076136	Training Loss 0.8246 (0.8254)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.028)	
2022-03-27 03:06:07,281: ============================================================
2022-03-27 03:07:43,597: time cost, forward:0.26651040153886807, backward:0.03896407865399691, data cost:0.6519074535849106 
2022-03-27 03:07:43,597: ============================================================
2022-03-27 03:07:43,597: Epoch 13/26 Batch 200/7662 eta: 1 day, 4:38:45.155960	Training Loss 0.8255 (0.8255)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.018)	
2022-03-27 03:07:43,598: ============================================================
2022-03-27 03:09:20,087: time cost, forward:0.270460584091901, backward:0.04026460807060318, data cost:0.647336176805273 
2022-03-27 03:09:20,088: ============================================================
2022-03-27 03:09:20,088: Epoch 13/26 Batch 300/7662 eta: 1 day, 4:40:15.425333	Training Loss 0.8239 (0.8255)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.018)	
2022-03-27 03:09:20,089: ============================================================
2022-03-27 03:10:57,019: time cost, forward:0.27328526047536905, backward:0.04107583256293658, data cost:0.6480013314345128 
2022-03-27 03:10:57,020: ============================================================
2022-03-27 03:10:57,020: Epoch 13/26 Batch 400/7662 eta: 1 day, 4:46:29.679337	Training Loss 0.8241 (0.8255)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.018)	
2022-03-27 03:10:57,020: ============================================================
2022-03-27 03:12:34,814: time cost, forward:0.27753395451333573, backward:0.04135302360167723, data cost:0.6466711895738193 
2022-03-27 03:12:34,815: ============================================================
2022-03-27 03:12:34,815: Epoch 13/26 Batch 500/7662 eta: 1 day, 5:00:14.645118	Training Loss 0.8263 (0.8255)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.018)	
2022-03-27 03:12:34,815: ============================================================
2022-03-27 03:14:15,750: time cost, forward:0.28112875081859967, backward:0.04167106036152784, data cost:0.6489844314244037 
2022-03-27 03:14:15,767: ============================================================
2022-03-27 03:14:15,767: Epoch 13/26 Batch 600/7662 eta: 1 day, 5:54:45.029204	Training Loss 0.8267 (0.8256)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.017)	
2022-03-27 03:14:15,768: ============================================================
2022-03-27 03:15:52,552: time cost, forward:0.2835136469512197, backward:0.04189470227013671, data cost:0.6466485901451929 
2022-03-27 03:15:52,553: ============================================================
2022-03-27 03:15:52,553: Epoch 13/26 Batch 700/7662 eta: 1 day, 4:39:03.559327	Training Loss 0.8261 (0.8256)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.019)	
2022-03-27 03:15:52,553: ============================================================
2022-03-27 03:17:34,590: time cost, forward:0.2887924379938386, backward:0.042108231700854246, data cost:0.647155684135733 
2022-03-27 03:17:34,591: ============================================================
2022-03-27 03:17:34,591: Epoch 13/26 Batch 800/7662 eta: 1 day, 6:10:38.632214	Training Loss 0.8248 (0.8256)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.020)	
2022-03-27 03:17:34,591: ============================================================
2022-03-27 03:19:12,019: time cost, forward:0.2916010600971566, backward:0.041937532891686155, data cost:0.6437416148265291 
2022-03-27 03:19:12,020: ============================================================
2022-03-27 03:19:12,020: Epoch 13/26 Batch 900/7662 eta: 1 day, 4:47:14.881841	Training Loss 0.8265 (0.8256)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.018)	
2022-03-27 03:19:12,021: ============================================================
2022-03-27 03:20:52,597: time cost, forward:0.2947192760081859, backward:0.04201651860524465, data cost:0.643292226829567 
2022-03-27 03:20:52,598: ============================================================
2022-03-27 03:20:52,599: Epoch 13/26 Batch 1000/7662 eta: 1 day, 5:41:23.612660	Training Loss 0.8263 (0.8256)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.019)	
2022-03-27 03:20:52,599: ============================================================
2022-03-27 03:22:31,411: time cost, forward:0.2964141728988661, backward:0.042037546471968036, data cost:0.6426471288471031 
2022-03-27 03:22:31,412: ============================================================
2022-03-27 03:22:31,412: Epoch 13/26 Batch 1100/7662 eta: 1 day, 5:08:29.066799	Training Loss 0.8258 (0.8256)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.017)	
2022-03-27 03:22:31,412: ============================================================
2022-03-27 03:24:12,101: time cost, forward:0.2975787327029091, backward:0.04198998168073564, data cost:0.6433500440245972 
2022-03-27 03:24:12,102: ============================================================
2022-03-27 03:24:12,103: Epoch 13/26 Batch 1200/7662 eta: 1 day, 5:40:01.589305	Training Loss 0.8266 (0.8256)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.017)	
2022-03-27 03:24:12,103: ============================================================
2022-03-27 03:25:53,460: time cost, forward:0.2993683427732848, backward:0.04196768985334225, data cost:0.6440463286349184 
2022-03-27 03:25:53,460: ============================================================
2022-03-27 03:25:53,460: Epoch 13/26 Batch 1300/7662 eta: 1 day, 5:50:07.561848	Training Loss 0.8252 (0.8256)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-27 03:25:53,460: ============================================================
2022-03-27 03:27:31,158: time cost, forward:0.2996447212445557, backward:0.04184916702826761, data cost:0.6433603012024973 
2022-03-27 03:27:31,179: ============================================================
2022-03-27 03:27:31,179: Epoch 13/26 Batch 1400/7662 eta: 1 day, 4:44:13.916949	Training Loss 0.8246 (0.8256)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-27 03:27:31,179: ============================================================
2022-03-27 03:29:13,084: time cost, forward:0.3000400960246589, backward:0.041931188289446385, data cost:0.6451555709189936 
2022-03-27 03:29:13,085: ============================================================
2022-03-27 03:29:13,085: Epoch 13/26 Batch 1500/7662 eta: 1 day, 5:56:24.747982	Training Loss 0.8256 (0.8256)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-27 03:29:13,085: ============================================================
2022-03-27 03:30:49,911: time cost, forward:0.2998674290116091, backward:0.041829211626893806, data cost:0.6437359369121692 
2022-03-27 03:30:49,913: ============================================================
2022-03-27 03:30:49,914: Epoch 13/26 Batch 1600/7662 eta: 1 day, 4:25:17.601131	Training Loss 0.8248 (0.8256)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-27 03:30:49,914: ============================================================
2022-03-27 03:32:27,447: time cost, forward:0.2997498856073551, backward:0.041769505810078066, data cost:0.6437166952399243 
2022-03-27 03:32:27,447: ============================================================
2022-03-27 03:32:27,448: Epoch 13/26 Batch 1700/7662 eta: 1 day, 4:36:05.944738	Training Loss 0.8241 (0.8256)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-27 03:32:27,448: ============================================================
2022-03-27 03:34:07,182: time cost, forward:0.30028534386143413, backward:0.0418250714493434, data cost:0.6438362719020028 
2022-03-27 03:34:07,183: ============================================================
2022-03-27 03:34:07,183: Epoch 13/26 Batch 1800/7662 eta: 1 day, 5:13:09.975505	Training Loss 0.8262 (0.8256)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-27 03:34:07,183: ============================================================
2022-03-27 03:35:46,390: time cost, forward:0.3009840039719777, backward:0.04186407285592881, data cost:0.6433469513455713 
2022-03-27 03:35:46,391: ============================================================
2022-03-27 03:35:46,392: Epoch 13/26 Batch 1900/7662 eta: 1 day, 5:02:15.053759	Training Loss 0.8243 (0.8256)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.016)	
2022-03-27 03:35:46,392: ============================================================
2022-03-27 03:37:27,414: time cost, forward:0.30160078756686387, backward:0.04184964157570118, data cost:0.6439766325671533 
2022-03-27 03:37:27,415: ============================================================
2022-03-27 03:37:27,415: Epoch 13/26 Batch 2000/7662 eta: 1 day, 5:32:26.586297	Training Loss 0.8267 (0.8256)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-27 03:37:27,416: ============================================================
2022-03-27 03:39:09,347: time cost, forward:0.30274663430387033, backward:0.04196096909165439, data cost:0.6442029122910993 
2022-03-27 03:39:09,348: ============================================================
2022-03-27 03:39:09,348: Epoch 13/26 Batch 2100/7662 eta: 1 day, 5:46:41.497621	Training Loss 0.8258 (0.8256)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-27 03:39:09,348: ============================================================
2022-03-27 03:40:47,405: time cost, forward:0.3030564815361644, backward:0.041955871113650955, data cost:0.6431431789840553 
2022-03-27 03:40:47,406: ============================================================
2022-03-27 03:40:47,407: Epoch 13/26 Batch 2200/7662 eta: 1 day, 4:37:09.378258	Training Loss 0.8252 (0.8256)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-27 03:40:47,407: ============================================================
2022-03-27 03:42:23,558: time cost, forward:0.3027178665615777, backward:0.04198679907418376, data cost:0.642556390953147 
2022-03-27 03:42:23,559: ============================================================
2022-03-27 03:42:23,559: Epoch 13/26 Batch 2300/7662 eta: 1 day, 4:02:10.135692	Training Loss 0.8260 (0.8255)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.195 (0.018)	
2022-03-27 03:42:23,559: ============================================================
2022-03-27 03:43:59,975: time cost, forward:0.3024314636486478, backward:0.04197166312878805, data cost:0.6419122070011968 
2022-03-27 03:43:59,995: ============================================================
2022-03-27 03:43:59,995: Epoch 13/26 Batch 2400/7662 eta: 1 day, 4:05:31.646723	Training Loss 0.8253 (0.8255)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-27 03:43:59,995: ============================================================
2022-03-27 03:45:36,110: time cost, forward:0.3017177747792843, backward:0.041958534894060165, data cost:0.641651563999318 
2022-03-27 03:45:36,111: ============================================================
2022-03-27 03:45:36,111: Epoch 13/26 Batch 2500/7662 eta: 1 day, 3:58:19.342088	Training Loss 0.8264 (0.8255)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-27 03:45:36,111: ============================================================
2022-03-27 03:47:14,135: time cost, forward:0.3012682141226592, backward:0.04208208423891908, data cost:0.6416325304956793 
2022-03-27 03:47:14,136: ============================================================
2022-03-27 03:47:14,137: Epoch 13/26 Batch 2600/7662 eta: 1 day, 4:30:02.524771	Training Loss 0.8245 (0.8255)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-27 03:47:14,137: ============================================================
2022-03-27 03:48:53,093: time cost, forward:0.30128492607633994, backward:0.04207091571755567, data cost:0.6419263672236823 
2022-03-27 03:48:53,094: ============================================================
2022-03-27 03:48:53,094: Epoch 13/26 Batch 2700/7662 eta: 1 day, 4:44:38.888599	Training Loss 0.8245 (0.8255)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.195 (0.017)	
2022-03-27 03:48:53,094: ============================================================
2022-03-27 03:50:29,930: time cost, forward:0.30114157807192404, backward:0.04204342015175446, data cost:0.6413900691213332 
2022-03-27 03:50:29,931: ============================================================
2022-03-27 03:50:29,931: Epoch 13/26 Batch 2800/7662 eta: 1 day, 4:06:04.959500	Training Loss 0.8255 (0.8255)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-27 03:50:29,932: ============================================================
2022-03-27 03:52:01,480: time cost, forward:0.3000778077017977, backward:0.04206102451154716, data cost:0.6401302310342253 
2022-03-27 03:52:01,480: ============================================================
2022-03-27 03:52:01,480: Epoch 13/26 Batch 2900/7662 eta: 1 day, 2:32:28.772103	Training Loss 0.8253 (0.8255)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-27 03:52:01,480: ============================================================
2022-03-27 03:53:38,068: time cost, forward:0.29937906080820276, backward:0.042077435060674725, data cost:0.6401831470119352 
2022-03-27 03:53:38,069: ============================================================
2022-03-27 03:53:38,069: Epoch 13/26 Batch 3000/7662 eta: 1 day, 3:58:31.860603	Training Loss 0.8250 (0.8255)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-27 03:53:38,069: ============================================================
2022-03-27 03:55:15,508: time cost, forward:0.2995793547081001, backward:0.042051089660088144, data cost:0.6398325507276941 
2022-03-27 03:55:15,509: ============================================================
2022-03-27 03:55:15,509: Epoch 13/26 Batch 3100/7662 eta: 1 day, 4:11:42.451732	Training Loss 0.8260 (0.8255)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-27 03:55:15,509: ============================================================
2022-03-27 03:56:56,023: time cost, forward:0.3000798229129287, backward:0.04206443063986976, data cost:0.6398511850375539 
2022-03-27 03:56:56,025: ============================================================
2022-03-27 03:56:56,025: Epoch 13/26 Batch 3200/7662 eta: 1 day, 5:03:25.856134	Training Loss 0.8251 (0.8255)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-27 03:56:56,025: ============================================================
2022-03-27 03:58:38,661: time cost, forward:0.30084093399718514, backward:0.04205598098359421, data cost:0.640541875026341 
2022-03-27 03:58:38,663: ============================================================
2022-03-27 03:58:38,664: Epoch 13/26 Batch 3300/7662 eta: 1 day, 5:38:32.345980	Training Loss 0.8241 (0.8255)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-27 03:58:38,664: ============================================================
2022-03-27 04:00:14,673: time cost, forward:0.3008680006937968, backward:0.04206048996878498, data cost:0.6397513596932304 
2022-03-27 04:00:14,674: ============================================================
2022-03-27 04:00:14,675: Epoch 13/26 Batch 3400/7662 eta: 1 day, 3:42:05.722463	Training Loss 0.8247 (0.8255)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-27 04:00:14,675: ============================================================
2022-03-27 04:01:53,164: time cost, forward:0.30124733120279673, backward:0.04206444134402868, data cost:0.6395401215342053 
2022-03-27 04:01:53,165: ============================================================
2022-03-27 04:01:53,166: Epoch 13/26 Batch 3500/7662 eta: 1 day, 4:23:23.150960	Training Loss 0.8251 (0.8255)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-27 04:01:53,166: ============================================================
2022-03-27 04:03:30,833: time cost, forward:0.3013686468681384, backward:0.04203125350042726, data cost:0.6392320049044224 
2022-03-27 04:03:30,834: ============================================================
2022-03-27 04:03:30,834: Epoch 13/26 Batch 3600/7662 eta: 1 day, 4:07:31.808663	Training Loss 0.8251 (0.8255)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-27 04:03:30,834: ============================================================
2022-03-27 04:05:07,847: time cost, forward:0.3015479975759935, backward:0.042015992618631946, data cost:0.6387746988292899 
2022-03-27 04:05:07,848: ============================================================
2022-03-27 04:05:07,848: Epoch 13/26 Batch 3700/7662 eta: 1 day, 3:54:36.115258	Training Loss 0.8253 (0.8254)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-27 04:05:07,848: ============================================================
2022-03-27 04:06:49,713: time cost, forward:0.3018767976798519, backward:0.042040470180526535, data cost:0.6393545143978945 
2022-03-27 04:06:49,714: ============================================================
2022-03-27 04:06:49,714: Epoch 13/26 Batch 3800/7662 eta: 1 day, 5:16:40.060805	Training Loss 0.8257 (0.8254)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-27 04:06:49,714: ============================================================
2022-03-27 04:08:27,236: time cost, forward:0.3016938459387068, backward:0.04209137091302786, data cost:0.6392878793881287 
2022-03-27 04:08:27,236: ============================================================
2022-03-27 04:08:27,236: Epoch 13/26 Batch 3900/7662 eta: 1 day, 4:00:07.958390	Training Loss 0.8253 (0.8254)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-27 04:08:27,237: ============================================================
2022-03-27 04:10:01,882: time cost, forward:0.30143128206921266, backward:0.0420500923914145, data cost:0.6386372910704903 
2022-03-27 04:10:01,883: ============================================================
2022-03-27 04:10:01,883: Epoch 13/26 Batch 4000/7662 eta: 1 day, 3:09:00.535317	Training Loss 0.8256 (0.8254)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-27 04:10:01,883: ============================================================
2022-03-27 04:11:41,407: time cost, forward:0.3015872692881517, backward:0.04209077622896871, data cost:0.6387464508076184 
2022-03-27 04:11:41,418: ============================================================
2022-03-27 04:11:41,418: Epoch 13/26 Batch 4100/7662 eta: 1 day, 4:31:29.308514	Training Loss 0.8251 (0.8254)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-27 04:11:41,418: ============================================================
2022-03-27 04:13:19,778: time cost, forward:0.3015890240129842, backward:0.042065324712918184, data cost:0.6388082227754605 
2022-03-27 04:13:19,780: ============================================================
2022-03-27 04:13:19,780: Epoch 13/26 Batch 4200/7662 eta: 1 day, 4:09:40.776212	Training Loss 0.8261 (0.8254)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.195 (0.018)	
2022-03-27 04:13:19,781: ============================================================
2022-03-27 04:14:58,680: time cost, forward:0.30174022886636065, backward:0.0420928330276145, data cost:0.6387777179860881 
2022-03-27 04:14:58,680: ============================================================
2022-03-27 04:14:58,680: Epoch 13/26 Batch 4300/7662 eta: 1 day, 4:17:16.640850	Training Loss 0.8252 (0.8254)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-27 04:14:58,681: ============================================================
2022-03-27 04:16:39,168: time cost, forward:0.30210391319077184, backward:0.04209399017373874, data cost:0.6389129109804292 
2022-03-27 04:16:39,168: ============================================================
2022-03-27 04:16:39,168: Epoch 13/26 Batch 4400/7662 eta: 1 day, 4:42:50.806879	Training Loss 0.8236 (0.8254)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-27 04:16:39,168: ============================================================
2022-03-27 04:18:17,589: time cost, forward:0.3021221861995096, backward:0.0420637994534335, data cost:0.6389169697762596 
2022-03-27 04:18:17,589: ============================================================
2022-03-27 04:18:17,590: Epoch 13/26 Batch 4500/7662 eta: 1 day, 4:05:46.603371	Training Loss 0.8243 (0.8253)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-27 04:18:17,590: ============================================================
2022-03-27 04:20:00,294: time cost, forward:0.30256775758348875, backward:0.0420817703650189, data cost:0.6393552527891135 
2022-03-27 04:20:00,294: ============================================================
2022-03-27 04:20:00,294: Epoch 13/26 Batch 4600/7662 eta: 1 day, 5:17:25.797377	Training Loss 0.8244 (0.8253)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.019)	
2022-03-27 04:20:00,294: ============================================================
2022-03-27 04:21:35,685: time cost, forward:0.30238885401563204, backward:0.04207233896557892, data cost:0.6389449840151115 
2022-03-27 04:21:35,686: ============================================================
2022-03-27 04:21:35,686: Epoch 13/26 Batch 4700/7662 eta: 1 day, 3:10:42.232837	Training Loss 0.8209 (0.8253)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.019)	
2022-03-27 04:21:35,686: ============================================================
2022-03-27 04:23:10,077: time cost, forward:0.30199391530389263, backward:0.042076525824297016, data cost:0.6385055084629937 
2022-03-27 04:23:10,077: ============================================================
2022-03-27 04:23:10,077: Epoch 13/26 Batch 4800/7662 eta: 1 day, 2:52:01.781337	Training Loss 0.8198 (0.8252)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.022)	
2022-03-27 04:23:10,077: ============================================================
2022-03-27 04:24:47,953: time cost, forward:0.301906870150717, backward:0.042080955374944114, data cost:0.6384996673870534 
2022-03-27 04:24:47,975: ============================================================
2022-03-27 04:24:47,976: Epoch 13/26 Batch 4900/7662 eta: 1 day, 3:50:17.768636	Training Loss 0.8186 (0.8250)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.195 (0.026)	
2022-03-27 04:24:47,976: ============================================================
2022-03-27 04:26:26,292: time cost, forward:0.3018269448262211, backward:0.04206926661936086, data cost:0.6386212352562676 
2022-03-27 04:26:26,293: ============================================================
2022-03-27 04:26:26,293: Epoch 13/26 Batch 5000/7662 eta: 1 day, 3:55:47.911147	Training Loss 0.8183 (0.8249)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.032)	
2022-03-27 04:26:26,293: ============================================================
2022-03-27 04:28:01,277: time cost, forward:0.3014545444414461, backward:0.04211122275661267, data cost:0.6382838671617495 
2022-03-27 04:28:01,278: ============================================================
2022-03-27 04:28:01,279: Epoch 13/26 Batch 5100/7662 eta: 1 day, 2:57:25.747774	Training Loss 0.8184 (0.8248)	Training Prec@1 0.000 (0.009)	Training Prec@5 0.586 (0.037)	
2022-03-27 04:28:01,279: ============================================================
2022-03-27 04:29:39,057: time cost, forward:0.3012555605816277, backward:0.042150955563394994, data cost:0.638260721036805 
2022-03-27 04:29:39,058: ============================================================
2022-03-27 04:29:39,058: Epoch 13/26 Batch 5200/7662 eta: 1 day, 3:43:22.777853	Training Loss 0.8172 (0.8246)	Training Prec@1 0.000 (0.010)	Training Prec@5 0.000 (0.044)	
2022-03-27 04:29:39,058: ============================================================
2022-03-27 04:31:17,464: time cost, forward:0.3010857688366051, backward:0.04214827041172446, data cost:0.6385669844581128 
2022-03-27 04:31:17,464: ============================================================
2022-03-27 04:31:17,465: Epoch 13/26 Batch 5300/7662 eta: 1 day, 3:52:24.206747	Training Loss 0.8171 (0.8245)	Training Prec@1 0.391 (0.013)	Training Prec@5 0.391 (0.052)	
2022-03-27 04:31:17,465: ============================================================
2022-03-27 04:32:54,696: time cost, forward:0.30099701506050675, backward:0.04219932511109382, data cost:0.63842356503065 
2022-03-27 04:32:54,697: ============================================================
2022-03-27 04:32:54,698: Epoch 13/26 Batch 5400/7662 eta: 1 day, 3:30:50.304727	Training Loss 0.8143 (0.8243)	Training Prec@1 0.391 (0.016)	Training Prec@5 1.172 (0.064)	
2022-03-27 04:32:54,698: ============================================================
2022-03-27 04:34:31,086: time cost, forward:0.3008444023513863, backward:0.04220790359232074, data cost:0.6382268932347386 
2022-03-27 04:34:31,086: ============================================================
2022-03-27 04:34:31,087: Epoch 13/26 Batch 5500/7662 eta: 1 day, 3:14:53.939128	Training Loss 0.8145 (0.8241)	Training Prec@1 0.586 (0.021)	Training Prec@5 0.977 (0.078)	
2022-03-27 04:34:31,087: ============================================================
2022-03-27 04:36:10,189: time cost, forward:0.300849398197202, backward:0.04219376123213389, data cost:0.6383658517448152 
2022-03-27 04:36:10,189: ============================================================
2022-03-27 04:36:10,189: Epoch 13/26 Batch 5600/7662 eta: 1 day, 3:59:16.647703	Training Loss 0.8097 (0.8239)	Training Prec@1 0.195 (0.027)	Training Prec@5 1.172 (0.096)	
2022-03-27 04:36:10,189: ============================================================
2022-03-27 04:37:48,321: time cost, forward:0.3007869335157157, backward:0.042176105616740706, data cost:0.6383470158176184 
2022-03-27 04:37:48,322: ============================================================
2022-03-27 04:37:48,323: Epoch 13/26 Batch 5700/7662 eta: 1 day, 3:41:13.209388	Training Loss 0.8010 (0.8235)	Training Prec@1 0.977 (0.042)	Training Prec@5 3.906 (0.134)	
2022-03-27 04:37:48,323: ============================================================
2022-03-27 04:39:27,159: time cost, forward:0.3007978022273275, backward:0.04220520350250176, data cost:0.6385656609003205 
2022-03-27 04:39:27,160: ============================================================
2022-03-27 04:39:27,160: Epoch 13/26 Batch 5800/7662 eta: 1 day, 3:51:29.612880	Training Loss 0.7673 (0.8228)	Training Prec@1 10.156 (0.158)	Training Prec@5 17.383 (0.351)	
2022-03-27 04:39:27,160: ============================================================
2022-03-27 04:41:06,485: time cost, forward:0.30099394402679375, backward:0.04221011008382106, data cost:0.6384470092985545 
2022-03-27 04:41:06,487: ============================================================
2022-03-27 04:41:06,487: Epoch 13/26 Batch 5900/7662 eta: 1 day, 3:58:06.368904	Training Loss 0.7607 (0.8217)	Training Prec@1 9.766 (0.342)	Training Prec@5 18.945 (0.666)	
2022-03-27 04:41:06,487: ============================================================
2022-03-27 04:42:42,283: time cost, forward:0.30086697230916915, backward:0.04215136916066313, data cost:0.6383150049518954 
2022-03-27 04:42:42,284: ============================================================
2022-03-27 04:42:42,284: Epoch 13/26 Batch 6000/7662 eta: 1 day, 2:56:52.842771	Training Loss 0.7508 (0.8206)	Training Prec@1 17.773 (0.568)	Training Prec@5 26.367 (1.034)	
2022-03-27 04:42:42,284: ============================================================
2022-03-27 04:44:21,426: time cost, forward:0.30095898215742184, backward:0.04215033720078713, data cost:0.6383995106423912 
2022-03-27 04:44:21,427: ============================================================
2022-03-27 04:44:21,427: Epoch 13/26 Batch 6100/7662 eta: 1 day, 3:51:41.732149	Training Loss 0.7530 (0.8195)	Training Prec@1 14.258 (0.808)	Training Prec@5 22.070 (1.415)	
2022-03-27 04:44:21,427: ============================================================
2022-03-27 04:45:57,732: time cost, forward:0.3009499143950303, backward:0.042152613050458046, data cost:0.6381006486993929 
2022-03-27 04:45:57,733: ============================================================
2022-03-27 04:45:57,734: Epoch 13/26 Batch 6200/7662 eta: 1 day, 3:02:16.015720	Training Loss 0.7439 (0.8183)	Training Prec@1 18.555 (1.073)	Training Prec@5 28.125 (1.825)	
2022-03-27 04:45:57,734: ============================================================
2022-03-27 04:47:35,937: time cost, forward:0.30101129425425516, backward:0.042132758889847056, data cost:0.6380657372275578 
2022-03-27 04:47:35,937: ============================================================
2022-03-27 04:47:35,938: Epoch 13/26 Batch 6300/7662 eta: 1 day, 3:32:35.756119	Training Loss 0.7420 (0.8171)	Training Prec@1 20.508 (1.356)	Training Prec@5 31.641 (2.260)	
2022-03-27 04:47:35,938: ============================================================
2022-03-27 04:49:14,693: time cost, forward:0.3009863243678302, backward:0.042176436960631974, data cost:0.6381503014028733 
2022-03-27 04:49:14,693: ============================================================
2022-03-27 04:49:14,693: Epoch 13/26 Batch 6400/7662 eta: 1 day, 3:40:14.082183	Training Loss 0.7408 (0.8159)	Training Prec@1 21.094 (1.671)	Training Prec@5 29.492 (2.726)	
2022-03-27 04:49:14,694: ============================================================
2022-03-27 04:50:50,804: time cost, forward:0.3008570304594144, backward:0.04215953628509517, data cost:0.6379867853577604 
2022-03-27 04:50:50,804: ============================================================
2022-03-27 04:50:50,805: Epoch 13/26 Batch 6500/7662 eta: 1 day, 2:54:10.220985	Training Loss 0.7310 (0.8146)	Training Prec@1 24.805 (2.000)	Training Prec@5 34.961 (3.203)	
2022-03-27 04:50:50,805: ============================================================
2022-03-27 04:52:31,656: time cost, forward:0.30107676171772335, backward:0.04214871625210918, data cost:0.638186754214256 
2022-03-27 04:52:31,656: ============================================================
2022-03-27 04:52:31,657: Epoch 13/26 Batch 6600/7662 eta: 1 day, 4:12:06.821565	Training Loss 0.7247 (0.8133)	Training Prec@1 28.516 (2.343)	Training Prec@5 38.672 (3.695)	
2022-03-27 04:52:31,657: ============================================================
2022-03-27 04:54:11,534: time cost, forward:0.30127288131753727, backward:0.04218285666381909, data cost:0.6382152009213179 
2022-03-27 04:54:11,535: ============================================================
2022-03-27 04:54:11,536: Epoch 13/26 Batch 6700/7662 eta: 1 day, 3:54:07.149370	Training Loss 0.8206 (0.8121)	Training Prec@1 0.000 (2.693)	Training Prec@5 0.000 (4.187)	
2022-03-27 04:54:11,536: ============================================================
2022-03-27 04:55:47,004: time cost, forward:0.3010505791498749, backward:0.0421728374221988, data cost:0.6380029349208562 
2022-03-27 04:55:47,005: ============================================================
2022-03-27 04:55:47,005: Epoch 13/26 Batch 6800/7662 eta: 1 day, 2:38:37.184950	Training Loss 0.8243 (0.8123)	Training Prec@1 0.000 (2.653)	Training Prec@5 0.000 (4.126)	
2022-03-27 04:55:47,005: ============================================================
2022-03-27 04:57:24,004: time cost, forward:0.3010354966491111, backward:0.04218588823649413, data cost:0.6378718512112515 
2022-03-27 04:57:24,004: ============================================================
2022-03-27 04:57:24,004: Epoch 13/26 Batch 6900/7662 eta: 1 day, 3:02:37.326490	Training Loss 0.8235 (0.8124)	Training Prec@1 0.000 (2.615)	Training Prec@5 0.000 (4.067)	
2022-03-27 04:57:24,004: ============================================================
2022-03-27 04:59:02,163: time cost, forward:0.3010333230928415, backward:0.042200424037911, data cost:0.6378340660835917 
2022-03-27 04:59:02,165: ============================================================
2022-03-27 04:59:02,166: Epoch 13/26 Batch 7000/7662 eta: 1 day, 3:20:25.279493	Training Loss 0.8250 (0.8126)	Training Prec@1 0.000 (2.578)	Training Prec@5 0.000 (4.009)	
2022-03-27 04:59:02,166: ============================================================
2022-03-27 05:00:44,362: time cost, forward:0.30142819278591837, backward:0.04220521367759936, data cost:0.638040089476258 
2022-03-27 05:00:44,362: ============================================================
2022-03-27 05:00:44,362: Epoch 13/26 Batch 7100/7662 eta: 1 day, 4:26:09.470553	Training Loss 0.8232 (0.8128)	Training Prec@1 0.000 (2.541)	Training Prec@5 0.000 (3.953)	
2022-03-27 05:00:44,362: ============================================================
2022-03-27 05:02:19,949: time cost, forward:0.3014642062626343, backward:0.042181883641192776, data cost:0.637658130097578 
2022-03-27 05:02:19,949: ============================================================
2022-03-27 05:02:19,950: Epoch 13/26 Batch 7200/7662 eta: 1 day, 2:34:13.096403	Training Loss 0.8054 (0.8128)	Training Prec@1 1.367 (2.510)	Training Prec@5 3.516 (3.909)	
2022-03-27 05:02:19,950: ============================================================
2022-03-27 05:03:57,017: time cost, forward:0.3014281371927111, backward:0.04219296965342317, data cost:0.6375263968401207 
2022-03-27 05:03:57,017: ============================================================
2022-03-27 05:03:57,018: Epoch 13/26 Batch 7300/7662 eta: 1 day, 2:57:17.992180	Training Loss 0.7300 (0.8120)	Training Prec@1 25.586 (2.716)	Training Prec@5 34.570 (4.217)	
2022-03-27 05:03:57,018: ============================================================
2022-03-27 05:05:35,518: time cost, forward:0.3013542394796599, backward:0.04223086924500716, data cost:0.6376080663804509 
2022-03-27 05:05:35,518: ============================================================
2022-03-27 05:05:35,518: Epoch 13/26 Batch 7400/7662 eta: 1 day, 3:19:31.463833	Training Loss 0.7191 (0.8108)	Training Prec@1 31.836 (3.054)	Training Prec@5 41.406 (4.687)	
2022-03-27 05:05:35,518: ============================================================
2022-03-27 05:07:10,050: time cost, forward:0.3011717670741821, backward:0.04222971955241005, data cost:0.6372621941684102 
2022-03-27 05:07:10,051: ============================================================
2022-03-27 05:07:10,051: Epoch 13/26 Batch 7500/7662 eta: 1 day, 2:11:54.624719	Training Loss 0.7115 (0.8096)	Training Prec@1 33.008 (3.415)	Training Prec@5 46.875 (5.177)	
2022-03-27 05:07:10,051: ============================================================
2022-03-27 05:08:42,762: time cost, forward:0.30085636346116473, backward:0.0422341059283028, data cost:0.6369102886278765 
2022-03-27 05:08:42,762: ============================================================
2022-03-27 05:08:42,762: Epoch 13/26 Batch 7600/7662 eta: 1 day, 1:40:04.069049	Training Loss 0.7122 (0.8083)	Training Prec@1 35.547 (3.790)	Training Prec@5 46.094 (5.677)	
2022-03-27 05:08:42,762: ============================================================
2022-03-27 05:09:41,773: Epoch: 13/26 eta: 1 day, 1:39:05.661156	Training Loss 0.7106 (0.8075)	Training Prec@1 33.203 (4.028)	Training Prec@5 43.164 (5.994)
2022-03-27 05:09:41,774: ============================================================
2022-03-27 05:11:17,569: time cost, forward:0.25678534459586094, backward:0.03681170338332051, data cost:0.6677083391131777 
2022-03-27 05:11:17,570: ============================================================
2022-03-27 05:11:17,570: Epoch 14/26 Batch 100/7662 eta: 1 day, 2:27:17.534329	Training Loss 0.8245 (0.7166)	Training Prec@1 0.000 (33.073)	Training Prec@5 0.000 (43.768)	
2022-03-27 05:11:17,570: ============================================================
2022-03-27 05:12:52,944: time cost, forward:0.2508570740570375, backward:0.037090736417914154, data cost:0.6692167143126828 
2022-03-27 05:12:52,944: ============================================================
2022-03-27 05:12:52,945: Epoch 14/26 Batch 200/7662 eta: 1 day, 2:20:09.055338	Training Loss 0.8260 (0.7712)	Training Prec@1 0.000 (16.453)	Training Prec@5 0.000 (21.780)	
2022-03-27 05:12:52,945: ============================================================
2022-03-27 05:14:28,129: time cost, forward:0.25359904247781506, backward:0.03862804154488554, data cost:0.6630023259382981 
2022-03-27 05:14:28,130: ============================================================
2022-03-27 05:14:28,130: Epoch 14/26 Batch 300/7662 eta: 1 day, 2:15:25.487223	Training Loss 0.8263 (0.7894)	Training Prec@1 0.000 (10.951)	Training Prec@5 0.000 (14.503)	
2022-03-27 05:14:28,130: ============================================================
2022-03-27 05:16:05,597: time cost, forward:0.2552623306599476, backward:0.03971562349706664, data cost:0.6648844734469154 
2022-03-27 05:16:05,598: ============================================================
2022-03-27 05:16:05,598: Epoch 14/26 Batch 400/7662 eta: 1 day, 2:51:35.069944	Training Loss 0.8256 (0.7984)	Training Prec@1 0.000 (8.208)	Training Prec@5 0.000 (10.871)	
2022-03-27 05:16:05,598: ============================================================
2022-03-27 05:17:42,532: time cost, forward:0.256306800192487, backward:0.04111924152336044, data cost:0.6645174948629253 
2022-03-27 05:17:42,532: ============================================================
2022-03-27 05:17:42,532: Epoch 14/26 Batch 500/7662 eta: 1 day, 2:41:08.987132	Training Loss 0.8257 (0.8038)	Training Prec@1 0.000 (6.564)	Training Prec@5 0.000 (8.697)	
2022-03-27 05:17:42,533: ============================================================
2022-03-27 05:19:19,040: time cost, forward:0.2582461427965626, backward:0.04183882385343064, data cost:0.6622089575447503 
2022-03-27 05:19:19,040: ============================================================
2022-03-27 05:19:19,041: Epoch 14/26 Batch 600/7662 eta: 1 day, 2:32:29.822046	Training Loss 0.8263 (0.8074)	Training Prec@1 0.000 (5.468)	Training Prec@5 0.000 (7.248)	
2022-03-27 05:19:19,041: ============================================================
2022-03-27 05:20:58,026: time cost, forward:0.2626971990424335, backward:0.041998774538053806, data cost:0.6615353210460133 
2022-03-27 05:20:58,026: ============================================================
2022-03-27 05:20:58,026: Epoch 14/26 Batch 700/7662 eta: 1 day, 3:11:43.909522	Training Loss 0.8257 (0.8100)	Training Prec@1 0.000 (4.686)	Training Prec@5 0.000 (6.213)	
2022-03-27 05:20:58,027: ============================================================
2022-03-27 05:22:37,116: time cost, forward:0.2664685025531449, backward:0.042001356619022066, data cost:0.6606309184144823 
2022-03-27 05:22:37,117: ============================================================
2022-03-27 05:22:37,117: Epoch 14/26 Batch 800/7662 eta: 1 day, 3:11:48.069645	Training Loss 0.8249 (0.8119)	Training Prec@1 0.000 (4.100)	Training Prec@5 0.000 (5.437)	
2022-03-27 05:22:37,117: ============================================================
2022-03-27 05:24:15,521: time cost, forward:0.2706856531348987, backward:0.04207845763184205, data cost:0.6581239191125312 
2022-03-27 05:24:15,546: ============================================================
2022-03-27 05:24:15,546: Epoch 14/26 Batch 900/7662 eta: 1 day, 2:59:17.008114	Training Loss 0.8266 (0.8134)	Training Prec@1 0.000 (3.644)	Training Prec@5 0.000 (4.834)	
2022-03-27 05:24:15,547: ============================================================
2022-03-27 05:25:51,782: time cost, forward:0.2709122369955252, backward:0.042041309602983724, data cost:0.6570613262531636 
2022-03-27 05:25:51,782: ============================================================
2022-03-27 05:25:51,782: Epoch 14/26 Batch 1000/7662 eta: 1 day, 2:21:35.144116	Training Loss 0.8261 (0.8146)	Training Prec@1 0.000 (3.280)	Training Prec@5 0.000 (4.353)	
2022-03-27 05:25:51,782: ============================================================
2022-03-27 05:27:32,321: time cost, forward:0.2739094930740787, backward:0.042072801182116024, data cost:0.6571134397178698 
2022-03-27 05:27:32,322: ============================================================
2022-03-27 05:27:32,322: Epoch 14/26 Batch 1100/7662 eta: 1 day, 3:30:38.731556	Training Loss 0.8261 (0.8156)	Training Prec@1 0.000 (2.982)	Training Prec@5 0.000 (3.958)	
2022-03-27 05:27:32,322: ============================================================
2022-03-27 05:29:10,748: time cost, forward:0.2751509672010611, backward:0.042049385091480956, data cost:0.6568824300376249 
2022-03-27 05:29:10,748: ============================================================
2022-03-27 05:29:10,748: Epoch 14/26 Batch 1200/7662 eta: 1 day, 2:54:18.238405	Training Loss 0.8257 (0.8164)	Training Prec@1 0.000 (2.733)	Training Prec@5 0.195 (3.630)	
2022-03-27 05:29:10,748: ============================================================
2022-03-27 05:30:50,301: time cost, forward:0.27673984069471824, backward:0.04223609576324392, data cost:0.6561398715400255 
2022-03-27 05:30:50,301: ============================================================
2022-03-27 05:30:50,301: Epoch 14/26 Batch 1300/7662 eta: 1 day, 3:11:07.600028	Training Loss 0.8242 (0.8171)	Training Prec@1 0.000 (2.524)	Training Prec@5 0.000 (3.353)	
2022-03-27 05:30:50,301: ============================================================
2022-03-27 05:32:27,111: time cost, forward:0.278237250807287, backward:0.04233288645659113, data cost:0.6545762110813078 
2022-03-27 05:32:27,112: ============================================================
2022-03-27 05:32:27,112: Epoch 14/26 Batch 1400/7662 eta: 1 day, 2:24:34.916636	Training Loss 0.8251 (0.8177)	Training Prec@1 0.000 (2.343)	Training Prec@5 0.000 (3.114)	
2022-03-27 05:32:27,112: ============================================================
2022-03-27 05:34:05,090: time cost, forward:0.2788955901287809, backward:0.04237193676374052, data cost:0.6540777455814049 
2022-03-27 05:34:05,090: ============================================================
2022-03-27 05:34:05,091: Epoch 14/26 Batch 1500/7662 eta: 1 day, 2:42:03.958221	Training Loss 0.8238 (0.8182)	Training Prec@1 0.000 (2.187)	Training Prec@5 0.000 (2.907)	
2022-03-27 05:34:05,091: ============================================================
2022-03-27 05:35:43,609: time cost, forward:0.2796543610699852, backward:0.042365647316575425, data cost:0.6539870444650274 
2022-03-27 05:35:43,609: ============================================================
2022-03-27 05:35:43,610: Epoch 14/26 Batch 1600/7662 eta: 1 day, 2:49:15.611718	Training Loss 0.8258 (0.8186)	Training Prec@1 0.000 (2.051)	Training Prec@5 0.000 (2.726)	
2022-03-27 05:35:43,610: ============================================================
2022-03-27 05:37:17,491: time cost, forward:0.27960483167647193, backward:0.04219730143128878, data cost:0.6520336590632753 
2022-03-27 05:37:17,491: ============================================================
2022-03-27 05:37:17,491: Epoch 14/26 Batch 1700/7662 eta: 1 day, 1:31:56.451200	Training Loss 0.8264 (0.8190)	Training Prec@1 0.000 (1.930)	Training Prec@5 0.000 (2.566)	
2022-03-27 05:37:17,491: ============================================================
2022-03-27 05:38:54,510: time cost, forward:0.28008506376256936, backward:0.04234069078879067, data cost:0.6511784367192911 
2022-03-27 05:38:54,510: ============================================================
2022-03-27 05:38:54,510: Epoch 14/26 Batch 1800/7662 eta: 1 day, 2:21:31.493708	Training Loss 0.8246 (0.8194)	Training Prec@1 0.000 (1.823)	Training Prec@5 0.000 (2.425)	
2022-03-27 05:38:54,510: ============================================================
2022-03-27 05:40:34,478: time cost, forward:0.2803973796306126, backward:0.04242859356274035, data cost:0.6521489743247291 
2022-03-27 05:40:34,478: ============================================================
2022-03-27 05:40:34,479: Epoch 14/26 Batch 1900/7662 eta: 1 day, 3:07:56.161629	Training Loss 0.8243 (0.8197)	Training Prec@1 0.000 (1.727)	Training Prec@5 0.000 (2.298)	
2022-03-27 05:40:34,479: ============================================================
2022-03-27 05:42:10,580: time cost, forward:0.28031536935269086, backward:0.042491672872721764, data cost:0.6510291425152502 
2022-03-27 05:42:10,580: ============================================================
2022-03-27 05:42:10,581: Epoch 14/26 Batch 2000/7662 eta: 1 day, 2:03:22.294963	Training Loss 0.8259 (0.8199)	Training Prec@1 0.000 (1.641)	Training Prec@5 0.195 (2.184)	
2022-03-27 05:42:10,581: ============================================================
2022-03-27 05:43:48,600: time cost, forward:0.27983097384917616, backward:0.04247394557678455, data cost:0.6521904283389982 
2022-03-27 05:43:48,601: ============================================================
2022-03-27 05:43:48,601: Epoch 14/26 Batch 2100/7662 eta: 1 day, 2:32:56.995805	Training Loss 0.8248 (0.8202)	Training Prec@1 0.000 (1.563)	Training Prec@5 0.000 (2.081)	
2022-03-27 05:43:48,601: ============================================================
2022-03-27 05:45:23,075: time cost, forward:0.2791521317203135, backward:0.04252851069000647, data cost:0.6514630673310061 
2022-03-27 05:45:23,076: ============================================================
2022-03-27 05:45:23,076: Epoch 14/26 Batch 2200/7662 eta: 1 day, 1:33:44.862085	Training Loss 0.8243 (0.8204)	Training Prec@1 0.000 (1.492)	Training Prec@5 0.000 (1.987)	
2022-03-27 05:45:23,076: ============================================================
2022-03-27 05:46:58,422: time cost, forward:0.2784818363687483, backward:0.042457861193059165, data cost:0.6512502174161734 
2022-03-27 05:46:58,424: ============================================================
2022-03-27 05:46:58,424: Epoch 14/26 Batch 2300/7662 eta: 1 day, 1:46:20.151273	Training Loss 0.8244 (0.8206)	Training Prec@1 0.000 (1.428)	Training Prec@5 0.000 (1.901)	
2022-03-27 05:46:58,424: ============================================================
2022-03-27 05:48:36,641: time cost, forward:0.278216422622827, backward:0.0424969935725261, data cost:0.6519232148078642 
2022-03-27 05:48:36,641: ============================================================
2022-03-27 05:48:36,641: Epoch 14/26 Batch 2400/7662 eta: 1 day, 2:31:14.140579	Training Loss 0.8247 (0.8208)	Training Prec@1 0.000 (1.368)	Training Prec@5 0.000 (1.822)	
2022-03-27 05:48:36,641: ============================================================
2022-03-27 05:50:12,867: time cost, forward:0.2773933884810333, backward:0.04249948470675502, data cost:0.6523658455539199 
2022-03-27 05:50:12,868: ============================================================
2022-03-27 05:50:12,868: Epoch 14/26 Batch 2500/7662 eta: 1 day, 1:57:22.915811	Training Loss 0.8253 (0.8210)	Training Prec@1 0.000 (1.313)	Training Prec@5 0.000 (1.750)	
2022-03-27 05:50:12,868: ============================================================
2022-03-27 05:51:47,452: time cost, forward:0.2771693133720759, backward:0.04256348731014168, data cost:0.6514337284833754 
2022-03-27 05:51:47,452: ============================================================
2022-03-27 05:51:47,453: Epoch 14/26 Batch 2600/7662 eta: 1 day, 1:29:13.845255	Training Loss 0.8241 (0.8211)	Training Prec@1 0.000 (1.263)	Training Prec@5 0.195 (1.683)	
2022-03-27 05:51:47,453: ============================================================
2022-03-27 05:53:24,912: time cost, forward:0.27693868699273433, backward:0.04258652720993737, data cost:0.651796064627705 
2022-03-27 05:53:24,912: ============================================================
2022-03-27 05:53:24,912: Epoch 14/26 Batch 2700/7662 eta: 1 day, 2:14:05.316406	Training Loss 0.8229 (0.8212)	Training Prec@1 0.000 (1.216)	Training Prec@5 0.000 (1.622)	
2022-03-27 05:53:24,912: ============================================================
2022-03-27 05:55:01,177: time cost, forward:0.2764197219563791, backward:0.042671292285571656, data cost:0.6518872458835123 
2022-03-27 05:55:01,178: ============================================================
2022-03-27 05:55:01,178: Epoch 14/26 Batch 2800/7662 eta: 1 day, 1:53:11.914602	Training Loss 0.8242 (0.8214)	Training Prec@1 0.000 (1.173)	Training Prec@5 0.391 (1.565)	
2022-03-27 05:55:01,178: ============================================================
2022-03-27 05:56:38,194: time cost, forward:0.27619356753785845, backward:0.04268214940284605, data cost:0.6519053291558973 
2022-03-27 05:56:38,195: ============================================================
2022-03-27 05:56:38,195: Epoch 14/26 Batch 2900/7662 eta: 1 day, 2:03:42.057917	Training Loss 0.8238 (0.8215)	Training Prec@1 0.000 (1.133)	Training Prec@5 0.000 (1.511)	
2022-03-27 05:56:38,195: ============================================================
2022-03-27 05:58:13,716: time cost, forward:0.2760282455582983, backward:0.04263400053652019, data cost:0.6517427585330873 
2022-03-27 05:58:13,717: ============================================================
2022-03-27 05:58:13,717: Epoch 14/26 Batch 3000/7662 eta: 1 day, 1:38:00.928017	Training Loss 0.8250 (0.8216)	Training Prec@1 0.000 (1.095)	Training Prec@5 0.000 (1.462)	
2022-03-27 05:58:13,717: ============================================================
2022-03-27 05:59:50,035: time cost, forward:0.27572510549428964, backward:0.04262412252176881, data cost:0.6516722528809076 
2022-03-27 05:59:50,035: ============================================================
2022-03-27 05:59:50,036: Epoch 14/26 Batch 3100/7662 eta: 1 day, 1:49:14.339882	Training Loss 0.8222 (0.8216)	Training Prec@1 0.000 (1.060)	Training Prec@5 0.000 (1.416)	
2022-03-27 05:59:50,036: ============================================================
2022-03-27 06:01:31,402: time cost, forward:0.2757437908116562, backward:0.04275903190512626, data cost:0.6527919496510617 
2022-03-27 06:01:31,403: ============================================================
2022-03-27 06:01:31,403: Epoch 14/26 Batch 3200/7662 eta: 1 day, 3:08:45.062155	Training Loss 0.8232 (0.8217)	Training Prec@1 0.000 (1.027)	Training Prec@5 0.000 (1.372)	
2022-03-27 06:01:31,403: ============================================================
2022-03-27 06:03:05,253: time cost, forward:0.27537008848071787, backward:0.04272149735849964, data cost:0.6523993013121208 
2022-03-27 06:03:05,254: ============================================================
2022-03-27 06:03:05,255: Epoch 14/26 Batch 3300/7662 eta: 1 day, 1:06:25.829342	Training Loss 0.8240 (0.8218)	Training Prec@1 0.000 (0.996)	Training Prec@5 0.000 (1.332)	
2022-03-27 06:03:05,255: ============================================================
2022-03-27 06:04:41,599: time cost, forward:0.2750034612850359, backward:0.04275704840064996, data cost:0.6525191704502313 
2022-03-27 06:04:41,599: ============================================================
2022-03-27 06:04:41,599: Epoch 14/26 Batch 3400/7662 eta: 1 day, 1:44:50.374295	Training Loss 0.8222 (0.8218)	Training Prec@1 0.000 (0.967)	Training Prec@5 0.000 (1.295)	
2022-03-27 06:04:41,600: ============================================================
2022-03-27 06:06:16,340: time cost, forward:0.27474396744602986, backward:0.04273684599223086, data cost:0.6521263250660031 
2022-03-27 06:06:16,340: ============================================================
2022-03-27 06:06:16,341: Epoch 14/26 Batch 3500/7662 eta: 1 day, 1:17:32.922764	Training Loss 0.8227 (0.8218)	Training Prec@1 0.000 (0.940)	Training Prec@5 0.000 (1.260)	
2022-03-27 06:06:16,341: ============================================================
2022-03-27 06:07:55,649: time cost, forward:0.27487399903361287, backward:0.0426886058509532, data cost:0.6524922256835404 
2022-03-27 06:07:55,649: ============================================================
2022-03-27 06:07:55,650: Epoch 14/26 Batch 3600/7662 eta: 1 day, 2:29:03.519771	Training Loss 0.8206 (0.8218)	Training Prec@1 0.000 (0.914)	Training Prec@5 0.195 (1.226)	
2022-03-27 06:07:55,650: ============================================================
2022-03-27 06:09:31,733: time cost, forward:0.27456068464084776, backward:0.04271892645321011, data cost:0.652716541393411 
2022-03-27 06:09:31,734: ============================================================
2022-03-27 06:09:31,734: Epoch 14/26 Batch 3700/7662 eta: 1 day, 1:35:51.961564	Training Loss 0.8215 (0.8218)	Training Prec@1 0.195 (0.890)	Training Prec@5 0.195 (1.195)	
2022-03-27 06:09:31,735: ============================================================
2022-03-27 06:11:04,827: time cost, forward:0.2744027950726675, backward:0.0426974206197949, data cost:0.6518601996549088 
2022-03-27 06:11:04,827: ============================================================
2022-03-27 06:11:04,828: Epoch 14/26 Batch 3800/7662 eta: 1 day, 0:46:29.869021	Training Loss 0.8207 (0.8218)	Training Prec@1 0.000 (0.867)	Training Prec@5 0.000 (1.166)	
2022-03-27 06:11:04,828: ============================================================
2022-03-27 06:12:42,239: time cost, forward:0.2741401308651122, backward:0.04271462343386669, data cost:0.6522453152298713 
2022-03-27 06:12:42,239: ============================================================
2022-03-27 06:12:42,240: Epoch 14/26 Batch 3900/7662 eta: 1 day, 1:53:50.178540	Training Loss 0.8222 (0.8218)	Training Prec@1 0.000 (0.846)	Training Prec@5 0.000 (1.139)	
2022-03-27 06:12:42,240: ============================================================
2022-03-27 06:14:18,907: time cost, forward:0.27406851080961003, backward:0.042716375795952465, data cost:0.6522480395174706 
2022-03-27 06:14:18,907: ============================================================
2022-03-27 06:14:18,907: Epoch 14/26 Batch 4000/7662 eta: 1 day, 1:40:21.201506	Training Loss 0.8214 (0.8218)	Training Prec@1 0.000 (0.825)	Training Prec@5 0.195 (1.113)	
2022-03-27 06:14:18,908: ============================================================
2022-03-27 06:15:55,948: time cost, forward:0.27400815949320184, backward:0.042689934391078495, data cost:0.6523210286919621 
2022-03-27 06:15:55,948: ============================================================
2022-03-27 06:15:55,948: Epoch 14/26 Batch 4100/7662 eta: 1 day, 1:44:40.677705	Training Loss 0.8208 (0.8217)	Training Prec@1 0.000 (0.806)	Training Prec@5 0.000 (1.089)	
2022-03-27 06:15:55,948: ============================================================
2022-03-27 06:17:31,215: time cost, forward:0.27377903856076236, backward:0.04261075101826525, data cost:0.6522394548458382 
2022-03-27 06:17:31,215: ============================================================
2022-03-27 06:17:31,215: Epoch 14/26 Batch 4200/7662 eta: 1 day, 1:14:51.313635	Training Loss 0.8199 (0.8217)	Training Prec@1 0.000 (0.788)	Training Prec@5 0.195 (1.067)	
2022-03-27 06:17:31,215: ============================================================
2022-03-27 06:19:07,836: time cost, forward:0.273275904279444, backward:0.042479096193262574, data cost:0.6526968430352504 
2022-03-27 06:19:07,837: ============================================================
2022-03-27 06:19:07,837: Epoch 14/26 Batch 4300/7662 eta: 1 day, 1:34:47.508160	Training Loss 0.8207 (0.8216)	Training Prec@1 0.000 (0.770)	Training Prec@5 0.000 (1.046)	
2022-03-27 06:19:07,837: ============================================================
2022-03-27 06:20:44,688: time cost, forward:0.2734674289297532, backward:0.04250170767754418, data cost:0.6525518172815404 
2022-03-27 06:20:44,689: ============================================================
2022-03-27 06:20:44,689: Epoch 14/26 Batch 4400/7662 eta: 1 day, 1:36:49.558133	Training Loss 0.8211 (0.8216)	Training Prec@1 0.000 (0.754)	Training Prec@5 0.000 (1.026)	
2022-03-27 06:20:44,689: ============================================================
2022-03-27 06:22:18,879: time cost, forward:0.2731995685388311, backward:0.04252573086648921, data cost:0.6522230634585463 
2022-03-27 06:22:18,880: ============================================================
2022-03-27 06:22:18,880: Epoch 14/26 Batch 4500/7662 eta: 1 day, 0:53:02.187191	Training Loss 0.8188 (0.8215)	Training Prec@1 0.000 (0.739)	Training Prec@5 0.195 (1.009)	
2022-03-27 06:22:18,880: ============================================================
2022-03-27 06:23:56,055: time cost, forward:0.2731141600305035, backward:0.04258868237582723, data cost:0.6522214207915695 
2022-03-27 06:23:56,055: ============================================================
2022-03-27 06:23:56,056: Epoch 14/26 Batch 4600/7662 eta: 1 day, 1:38:43.975477	Training Loss 0.8184 (0.8215)	Training Prec@1 0.195 (0.724)	Training Prec@5 0.391 (0.991)	
2022-03-27 06:23:56,056: ============================================================
2022-03-27 06:25:22,237: time cost, forward:0.2722285526005302, backward:0.04253834484739236, data cost:0.6509673750687214 
2022-03-27 06:25:22,238: ============================================================
2022-03-27 06:25:22,238: Epoch 14/26 Batch 4700/7662 eta: 22:43:13.235801	Training Loss 0.8176 (0.8214)	Training Prec@1 0.000 (0.710)	Training Prec@5 0.391 (0.976)	
2022-03-27 06:25:22,239: ============================================================
2022-03-27 06:27:00,493: time cost, forward:0.27189979262092656, backward:0.04256147984589952, data cost:0.6515238404298828 
2022-03-27 06:27:00,493: ============================================================
2022-03-27 06:27:00,493: Epoch 14/26 Batch 4800/7662 eta: 1 day, 1:52:32.822522	Training Loss 0.8174 (0.8213)	Training Prec@1 0.195 (0.697)	Training Prec@5 0.586 (0.961)	
2022-03-27 06:27:00,494: ============================================================
2022-03-27 06:28:35,281: time cost, forward:0.27155383306270864, backward:0.04258674917281416, data cost:0.6515589310310645 
2022-03-27 06:28:35,282: ============================================================
2022-03-27 06:28:35,282: Epoch 14/26 Batch 4900/7662 eta: 1 day, 0:56:11.269345	Training Loss 0.8175 (0.8212)	Training Prec@1 0.000 (0.684)	Training Prec@5 0.391 (0.948)	
2022-03-27 06:28:35,282: ============================================================
2022-03-27 06:30:14,954: time cost, forward:0.27151479251767713, backward:0.04257933104794177, data cost:0.6522565405472299 
2022-03-27 06:30:14,954: ============================================================
2022-03-27 06:30:14,954: Epoch 14/26 Batch 5000/7662 eta: 1 day, 2:11:37.292124	Training Loss 0.8168 (0.8212)	Training Prec@1 0.000 (0.673)	Training Prec@5 0.000 (0.937)	
2022-03-27 06:30:14,955: ============================================================
2022-03-27 06:31:51,202: time cost, forward:0.2712839130888642, backward:0.04263661103661001, data cost:0.6523320060964892 
2022-03-27 06:31:51,202: ============================================================
2022-03-27 06:31:51,202: Epoch 14/26 Batch 5100/7662 eta: 1 day, 1:16:00.645726	Training Loss 0.8160 (0.8211)	Training Prec@1 0.000 (0.662)	Training Prec@5 0.000 (0.927)	
2022-03-27 06:31:51,202: ============================================================
2022-03-27 06:33:28,055: time cost, forward:0.2711089795129669, backward:0.04263401036079995, data cost:0.6525446661483052 
2022-03-27 06:33:28,056: ============================================================
2022-03-27 06:33:28,056: Epoch 14/26 Batch 5200/7662 eta: 1 day, 1:23:56.715702	Training Loss 0.8138 (0.8209)	Training Prec@1 0.195 (0.653)	Training Prec@5 0.586 (0.920)	
2022-03-27 06:33:28,056: ============================================================
2022-03-27 06:35:06,610: time cost, forward:0.27098659714070505, backward:0.042630006151618674, data cost:0.6530340284328457 
2022-03-27 06:35:06,611: ============================================================
2022-03-27 06:35:06,611: Epoch 14/26 Batch 5300/7662 eta: 1 day, 1:49:04.272232	Training Loss 0.8135 (0.8208)	Training Prec@1 0.000 (0.644)	Training Prec@5 0.391 (0.912)	
2022-03-27 06:35:06,611: ============================================================
2022-03-27 06:36:45,616: time cost, forward:0.2709127965073251, backward:0.04263128768870027, data cost:0.6534136973789255 
2022-03-27 06:36:45,616: ============================================================
2022-03-27 06:36:45,616: Epoch 14/26 Batch 5400/7662 eta: 1 day, 1:54:29.813630	Training Loss 0.8116 (0.8207)	Training Prec@1 0.781 (0.636)	Training Prec@5 1.562 (0.909)	
2022-03-27 06:36:45,616: ============================================================
2022-03-27 06:38:22,560: time cost, forward:0.2708183008229696, backward:0.04263893741545926, data cost:0.6536571454472879 
2022-03-27 06:38:22,560: ============================================================
2022-03-27 06:38:22,560: Epoch 14/26 Batch 5500/7662 eta: 1 day, 1:20:31.448851	Training Loss 0.8092 (0.8205)	Training Prec@1 0.391 (0.630)	Training Prec@5 0.977 (0.909)	
2022-03-27 06:38:22,560: ============================================================
2022-03-27 06:40:01,972: time cost, forward:0.27071890398356974, backward:0.042605680660555076, data cost:0.6542668686229899 
2022-03-27 06:40:01,973: ============================================================
2022-03-27 06:40:01,973: Epoch 14/26 Batch 5600/7662 eta: 1 day, 1:57:34.771318	Training Loss 0.8075 (0.8203)	Training Prec@1 0.391 (0.627)	Training Prec@5 0.977 (0.917)	
2022-03-27 06:40:01,973: ============================================================
2022-03-27 06:41:39,239: time cost, forward:0.2707164858617078, backward:0.04261788959606925, data cost:0.6543340137034556 
2022-03-27 06:41:39,240: ============================================================
2022-03-27 06:41:39,240: Epoch 14/26 Batch 5700/7662 eta: 1 day, 1:22:20.449111	Training Loss 0.7993 (0.8200)	Training Prec@1 0.586 (0.629)	Training Prec@5 2.344 (0.939)	
2022-03-27 06:41:39,240: ============================================================
2022-03-27 06:43:17,665: time cost, forward:0.2706693342830173, backward:0.042630604576049, data cost:0.6546371784430575 
2022-03-27 06:43:17,665: ============================================================
2022-03-27 06:43:17,666: Epoch 14/26 Batch 5800/7662 eta: 1 day, 1:38:50.169289	Training Loss 0.7779 (0.8195)	Training Prec@1 7.227 (0.664)	Training Prec@5 12.695 (1.025)	
2022-03-27 06:43:17,666: ============================================================
2022-03-27 06:44:55,099: time cost, forward:0.2706279141516135, backward:0.04266201950651364, data cost:0.6547595184725167 
2022-03-27 06:44:55,099: ============================================================
2022-03-27 06:44:55,099: Epoch 14/26 Batch 5900/7662 eta: 1 day, 1:21:42.080269	Training Loss 0.7621 (0.8187)	Training Prec@1 11.523 (0.810)	Training Prec@5 18.164 (1.285)	
2022-03-27 06:44:55,099: ============================================================
2022-03-27 06:46:32,434: time cost, forward:0.270554874952405, backward:0.04264766801534285, data cost:0.6549350044532187 
2022-03-27 06:46:32,435: ============================================================
2022-03-27 06:46:32,435: Epoch 14/26 Batch 6000/7662 eta: 1 day, 1:18:32.907324	Training Loss 0.7444 (0.8176)	Training Prec@1 19.141 (1.047)	Training Prec@5 29.688 (1.660)	
2022-03-27 06:46:32,435: ============================================================
2022-03-27 06:48:09,933: time cost, forward:0.27035559656424957, backward:0.042638052289731034, data cost:0.6552476493584013 
2022-03-27 06:48:09,934: ============================================================
2022-03-27 06:48:09,934: Epoch 14/26 Batch 6100/7662 eta: 1 day, 1:19:28.523315	Training Loss 0.7361 (0.8164)	Training Prec@1 21.289 (1.354)	Training Prec@5 31.641 (2.125)	
2022-03-27 06:48:09,934: ============================================================
2022-03-27 06:49:47,364: time cost, forward:0.27016030582502437, backward:0.042649360794581835, data cost:0.6555090549780989 
2022-03-27 06:49:47,365: ============================================================
2022-03-27 06:49:47,365: Epoch 14/26 Batch 6200/7662 eta: 1 day, 1:16:47.201350	Training Loss 0.7332 (0.8150)	Training Prec@1 23.828 (1.718)	Training Prec@5 33.594 (2.646)	
2022-03-27 06:49:47,365: ============================================================
2022-03-27 06:51:25,032: time cost, forward:0.27009265962943785, backward:0.04267109740554463, data cost:0.6557039973432629 
2022-03-27 06:51:25,032: ============================================================
2022-03-27 06:51:25,032: Epoch 14/26 Batch 6300/7662 eta: 1 day, 1:18:50.648279	Training Loss 0.7246 (0.8136)	Training Prec@1 25.195 (2.115)	Training Prec@5 36.914 (3.204)	
2022-03-27 06:51:25,032: ============================================================
2022-03-27 06:53:02,636: time cost, forward:0.269975971069014, backward:0.04268497540664255, data cost:0.6559030834930654 
2022-03-27 06:53:02,637: ============================================================
2022-03-27 06:53:02,637: Epoch 14/26 Batch 6400/7662 eta: 1 day, 1:16:14.371478	Training Loss 0.7198 (0.8121)	Training Prec@1 29.102 (2.534)	Training Prec@5 40.820 (3.780)	
2022-03-27 06:53:02,637: ============================================================
2022-03-27 06:54:38,787: time cost, forward:0.26993430781536865, backward:0.042685734893674394, data cost:0.6558521683169505 
2022-03-27 06:54:38,788: ============================================================
2022-03-27 06:54:38,788: Epoch 14/26 Batch 6500/7662 eta: 1 day, 0:52:03.115357	Training Loss 0.7135 (0.8107)	Training Prec@1 31.836 (2.965)	Training Prec@5 43.945 (4.368)	
2022-03-27 06:54:38,788: ============================================================
2022-03-27 06:56:16,641: time cost, forward:0.26984961763767246, backward:0.04270352510127683, data cost:0.6560509894937977 
2022-03-27 06:56:16,641: ============================================================
2022-03-27 06:56:16,641: Epoch 14/26 Batch 6600/7662 eta: 1 day, 1:16:50.666731	Training Loss 0.7063 (0.8092)	Training Prec@1 33.008 (3.407)	Training Prec@5 47.266 (4.960)	
2022-03-27 06:56:16,641: ============================================================
2022-03-27 06:57:56,108: time cost, forward:0.26981128427693696, backward:0.04255233709270126, data cost:0.6566337534057006 
2022-03-27 06:57:56,108: ============================================================
2022-03-27 06:57:56,108: Epoch 14/26 Batch 6700/7662 eta: 1 day, 1:40:11.907591	Training Loss 0.7068 (0.8076)	Training Prec@1 34.375 (3.867)	Training Prec@5 45.898 (5.565)	
2022-03-27 06:57:56,108: ============================================================
2022-03-27 06:59:31,047: time cost, forward:0.2696144996030942, backward:0.04254674227698128, data cost:0.6565301492996541 
2022-03-27 06:59:31,047: ============================================================
2022-03-27 06:59:31,047: Epoch 14/26 Batch 6800/7662 eta: 1 day, 0:28:29.719887	Training Loss 0.6954 (0.8061)	Training Prec@1 38.477 (4.331)	Training Prec@5 48.242 (6.168)	
2022-03-27 06:59:31,047: ============================================================
2022-03-27 07:01:09,977: time cost, forward:0.26957058944569445, backward:0.042557046869247266, data cost:0.6568516843438857 
2022-03-27 07:01:09,977: ============================================================
2022-03-27 07:01:09,977: Epoch 14/26 Batch 6900/7662 eta: 1 day, 1:28:35.301283	Training Loss 0.6983 (0.8046)	Training Prec@1 37.305 (4.806)	Training Prec@5 50.195 (6.780)	
2022-03-27 07:01:09,978: ============================================================
2022-03-27 07:02:49,794: time cost, forward:0.2697672011052085, backward:0.04258144509879193, data cost:0.6570199432841777 
2022-03-27 07:02:49,794: ============================================================
2022-03-27 07:02:49,794: Epoch 14/26 Batch 7000/7662 eta: 1 day, 1:40:37.334812	Training Loss 0.6917 (0.8030)	Training Prec@1 38.281 (5.289)	Training Prec@5 52.344 (7.396)	
2022-03-27 07:02:49,794: ============================================================
2022-03-27 07:04:28,570: time cost, forward:0.2697184256120943, backward:0.042591586887441836, data cost:0.6572758544917039 
2022-03-27 07:04:28,571: ============================================================
2022-03-27 07:04:28,571: Epoch 14/26 Batch 7100/7662 eta: 1 day, 1:22:55.865412	Training Loss 0.6809 (0.8015)	Training Prec@1 42.578 (5.774)	Training Prec@5 56.055 (8.009)	
2022-03-27 07:04:28,572: ============================================================
2022-03-27 07:06:03,118: time cost, forward:0.2695359880683455, backward:0.04257938315063935, data cost:0.6572055726899821 
2022-03-27 07:06:03,119: ============================================================
2022-03-27 07:06:03,119: Epoch 14/26 Batch 7200/7662 eta: 1 day, 0:16:08.891577	Training Loss 0.6825 (0.7999)	Training Prec@1 42.188 (6.269)	Training Prec@5 55.078 (8.624)	
2022-03-27 07:06:03,120: ============================================================
2022-03-27 07:07:41,224: time cost, forward:0.2695523207278133, backward:0.042586172063116476, data cost:0.6572554537099851 
2022-03-27 07:07:41,225: ============================================================
2022-03-27 07:07:41,225: Epoch 14/26 Batch 7300/7662 eta: 1 day, 1:09:18.190170	Training Loss 0.6864 (0.7983)	Training Prec@1 42.383 (6.762)	Training Prec@5 53.320 (9.238)	
2022-03-27 07:07:41,225: ============================================================
2022-03-27 07:09:19,831: time cost, forward:0.269587632014407, backward:0.042606514714057096, data cost:0.6574564567851543 
2022-03-27 07:09:19,832: ============================================================
2022-03-27 07:09:19,832: Epoch 14/26 Batch 7400/7662 eta: 1 day, 1:15:22.564728	Training Loss 0.6785 (0.7967)	Training Prec@1 46.680 (7.262)	Training Prec@5 57.227 (9.854)	
2022-03-27 07:09:19,832: ============================================================
2022-03-27 07:10:55,726: time cost, forward:0.2694912457214958, backward:0.042598502479214435, data cost:0.6574612892632612 
2022-03-27 07:10:55,727: ============================================================
2022-03-27 07:10:55,727: Epoch 14/26 Batch 7500/7662 eta: 1 day, 0:32:06.063850	Training Loss 0.6707 (0.7952)	Training Prec@1 47.852 (7.769)	Training Prec@5 56.836 (10.471)	
2022-03-27 07:10:55,727: ============================================================
2022-03-27 07:12:32,079: time cost, forward:0.269560141914188, backward:0.042629839887994264, data cost:0.6572698951630329 
2022-03-27 07:12:32,079: ============================================================
2022-03-27 07:12:32,080: Epoch 14/26 Batch 7600/7662 eta: 1 day, 0:37:31.244917	Training Loss 0.6727 (0.7935)	Training Prec@1 45.898 (8.280)	Training Prec@5 58.594 (11.086)	
2022-03-27 07:12:32,080: ============================================================
2022-03-27 07:13:35,584: Epoch: 14/26 eta: 1 day, 0:36:30.542705	Training Loss 0.6641 (0.7925)	Training Prec@1 50.195 (8.604)	Training Prec@5 61.328 (11.474)
2022-03-27 07:13:35,584: ============================================================
2022-03-27 07:15:13,241: time cost, forward:0.2506985568036937, backward:0.03901464529711791, data cost:0.6873466294221203 
2022-03-27 07:15:13,242: ============================================================
2022-03-27 07:15:13,242: Epoch 15/26 Batch 100/7662 eta: 1 day, 0:49:04.961251	Training Loss 0.6594 (0.6647)	Training Prec@1 51.758 (49.655)	Training Prec@5 63.281 (59.961)	
2022-03-27 07:15:13,242: ============================================================
2022-03-27 07:16:47,220: time cost, forward:0.2499745359372853, backward:0.03986491989250758, data cost:0.6678812372025533 
2022-03-27 07:16:47,221: ============================================================
2022-03-27 07:16:47,221: Epoch 15/26 Batch 200/7662 eta: 23:57:00.941764	Training Loss 0.6622 (0.6630)	Training Prec@1 48.242 (50.104)	Training Prec@5 58.594 (60.513)	
2022-03-27 07:16:47,221: ============================================================
2022-03-27 07:18:25,904: time cost, forward:0.25390480354079437, backward:0.04097840698267704, data cost:0.6728572494608901 
2022-03-27 07:18:25,905: ============================================================
2022-03-27 07:18:25,905: Epoch 15/26 Batch 300/7662 eta: 1 day, 1:07:18.876213	Training Loss 0.6482 (0.6612)	Training Prec@1 57.617 (50.511)	Training Prec@5 66.016 (60.981)	
2022-03-27 07:18:25,905: ============================================================
2022-03-27 07:20:00,766: time cost, forward:0.2559033910134681, backward:0.04218734894181254, data cost:0.662625833860316 
2022-03-27 07:20:00,766: ============================================================
2022-03-27 07:20:00,766: Epoch 15/26 Batch 400/7662 eta: 1 day, 0:07:21.011271	Training Loss 0.6485 (0.6597)	Training Prec@1 51.953 (51.026)	Training Prec@5 63.867 (61.476)	
2022-03-27 07:20:00,766: ============================================================
2022-03-27 07:21:38,797: time cost, forward:0.2583159397025863, backward:0.04250954196066083, data cost:0.66521328150151 
2022-03-27 07:21:38,797: ============================================================
2022-03-27 07:21:38,798: Epoch 15/26 Batch 500/7662 eta: 1 day, 0:54:04.759629	Training Loss 0.6509 (0.6578)	Training Prec@1 54.688 (51.555)	Training Prec@5 63.281 (61.959)	
2022-03-27 07:21:38,798: ============================================================
2022-03-27 07:23:16,427: time cost, forward:0.25971509697839296, backward:0.04275516078547763, data cost:0.6654646328972258 
2022-03-27 07:23:16,428: ============================================================
2022-03-27 07:23:16,428: Epoch 15/26 Batch 600/7662 eta: 1 day, 0:46:20.205273	Training Loss 0.6335 (0.6560)	Training Prec@1 59.180 (52.094)	Training Prec@5 68.945 (62.430)	
2022-03-27 07:23:16,428: ============================================================
2022-03-27 07:24:54,845: time cost, forward:0.2599747337837929, backward:0.04270279288121388, data cost:0.6662925135594752 
2022-03-27 07:24:54,845: ============================================================
2022-03-27 07:24:54,846: Epoch 15/26 Batch 700/7662 eta: 1 day, 0:56:41.346364	Training Loss 0.6404 (0.6548)	Training Prec@1 55.273 (52.577)	Training Prec@5 64.648 (62.834)	
2022-03-27 07:24:54,846: ============================================================
2022-03-27 07:26:34,102: time cost, forward:0.2600126102361572, backward:0.042789371201630975, data cost:0.6701337139358807 
2022-03-27 07:26:34,103: ============================================================
2022-03-27 07:26:34,103: Epoch 15/26 Batch 800/7662 eta: 1 day, 1:07:48.038613	Training Loss 0.6372 (0.6531)	Training Prec@1 58.984 (53.041)	Training Prec@5 69.336 (63.259)	
2022-03-27 07:26:34,103: ============================================================
2022-03-27 07:28:09,872: time cost, forward:0.2607929451977451, backward:0.04225263473587121, data cost:0.667908364594049 
2022-03-27 07:28:09,872: ============================================================
2022-03-27 07:28:09,873: Epoch 15/26 Batch 900/7662 eta: 1 day, 0:13:13.684475	Training Loss 0.6358 (0.6515)	Training Prec@1 57.031 (53.494)	Training Prec@5 67.188 (63.671)	
2022-03-27 07:28:09,873: ============================================================
2022-03-27 07:29:48,179: time cost, forward:0.26090135540928805, backward:0.042286101762238924, data cost:0.6685678806152191 
2022-03-27 07:29:48,179: ============================================================
2022-03-27 07:29:48,179: Epoch 15/26 Batch 1000/7662 eta: 1 day, 0:50:05.028524	Training Loss 0.6361 (0.6499)	Training Prec@1 58.594 (53.987)	Training Prec@5 67.773 (64.127)	
2022-03-27 07:29:48,180: ============================================================
2022-03-27 07:31:26,589: time cost, forward:0.26069715892975714, backward:0.042395696735468856, data cost:0.6695340007299505 
2022-03-27 07:31:26,590: ============================================================
2022-03-27 07:31:26,590: Epoch 15/26 Batch 1100/7662 eta: 1 day, 0:50:00.893580	Training Loss 0.6303 (0.6484)	Training Prec@1 59.375 (54.411)	Training Prec@5 68.555 (64.519)	
2022-03-27 07:31:26,590: ============================================================
2022-03-27 07:33:04,317: time cost, forward:0.26121694033497866, backward:0.042500240788845546, data cost:0.6693589824552433 
2022-03-27 07:33:04,318: ============================================================
2022-03-27 07:33:04,318: Epoch 15/26 Batch 1200/7662 eta: 1 day, 0:38:03.226368	Training Loss 0.6255 (0.6469)	Training Prec@1 58.008 (54.849)	Training Prec@5 69.531 (64.896)	
2022-03-27 07:33:04,318: ============================================================
2022-03-27 07:34:41,111: time cost, forward:0.2612040714633933, backward:0.042470585299602744, data cost:0.6695174299083002 
2022-03-27 07:34:41,111: ============================================================
2022-03-27 07:34:41,111: Epoch 15/26 Batch 1300/7662 eta: 1 day, 0:22:18.506063	Training Loss 0.6228 (0.6453)	Training Prec@1 60.938 (55.279)	Training Prec@5 71.680 (65.275)	
2022-03-27 07:34:41,111: ============================================================
2022-03-27 07:36:18,710: time cost, forward:0.2625361383600351, backward:0.04247510254255272, data cost:0.668153571946183 
2022-03-27 07:36:18,710: ============================================================
2022-03-27 07:36:18,711: Epoch 15/26 Batch 1400/7662 eta: 1 day, 0:32:51.162620	Training Loss 0.6089 (0.6437)	Training Prec@1 66.406 (55.709)	Training Prec@5 75.000 (65.669)	
2022-03-27 07:36:18,711: ============================================================
2022-03-27 07:37:55,662: time cost, forward:0.2629146881307102, backward:0.04262324998663456, data cost:0.6675402230624758 
2022-03-27 07:37:55,662: ============================================================
2022-03-27 07:37:55,662: Epoch 15/26 Batch 1500/7662 eta: 1 day, 0:21:27.825307	Training Loss 0.6129 (0.6422)	Training Prec@1 63.672 (56.144)	Training Prec@5 72.461 (66.037)	
2022-03-27 07:37:55,662: ============================================================
2022-03-27 07:39:33,343: time cost, forward:0.2624357505617028, backward:0.042668678672556734, data cost:0.6681620278456869 
2022-03-27 07:39:33,359: ============================================================
2022-03-27 07:39:33,360: Epoch 15/26 Batch 1600/7662 eta: 1 day, 0:31:04.767595	Training Loss 0.6278 (0.6407)	Training Prec@1 60.547 (56.553)	Training Prec@5 70.508 (66.398)	
2022-03-27 07:39:33,360: ============================================================
2022-03-27 07:41:14,104: time cost, forward:0.26217827114938214, backward:0.04260486753776959, data cost:0.6705328271696328 
2022-03-27 07:41:14,104: ============================================================
2022-03-27 07:41:14,105: Epoch 15/26 Batch 1700/7662 eta: 1 day, 1:15:17.411857	Training Loss 0.6080 (0.6392)	Training Prec@1 66.602 (56.946)	Training Prec@5 75.391 (66.750)	
2022-03-27 07:41:14,105: ============================================================
2022-03-27 07:42:50,969: time cost, forward:0.2620026777690487, backward:0.04262287156856213, data cost:0.6702787152524124 
2022-03-27 07:42:50,969: ============================================================
2022-03-27 07:42:50,969: Epoch 15/26 Batch 1800/7662 eta: 1 day, 0:15:18.671851	Training Loss 0.6067 (0.6378)	Training Prec@1 67.188 (57.356)	Training Prec@5 74.609 (67.107)	
2022-03-27 07:42:50,969: ============================================================
2022-03-27 07:44:27,243: time cost, forward:0.2621706940739829, backward:0.04247413942096986, data cost:0.6696181228249999 
2022-03-27 07:44:27,243: ============================================================
2022-03-27 07:44:27,244: Epoch 15/26 Batch 1900/7662 eta: 1 day, 0:04:50.177852	Training Loss 0.6061 (0.6363)	Training Prec@1 66.992 (57.735)	Training Prec@5 76.758 (67.433)	
2022-03-27 07:44:27,244: ============================================================
2022-03-27 07:46:08,588: time cost, forward:0.2630848182088557, backward:0.04241363974795931, data cost:0.6706734385831526 
2022-03-27 07:46:08,589: ============================================================
2022-03-27 07:46:08,589: Epoch 15/26 Batch 2000/7662 eta: 1 day, 1:19:15.237203	Training Loss 0.5974 (0.6348)	Training Prec@1 66.992 (58.122)	Training Prec@5 74.023 (67.768)	
2022-03-27 07:46:08,589: ============================================================
2022-03-27 07:47:48,468: time cost, forward:0.26283506838238313, backward:0.04246061798957145, data cost:0.6715371085099233 
2022-03-27 07:47:48,469: ============================================================
2022-03-27 07:47:48,469: Epoch 15/26 Batch 2100/7662 eta: 1 day, 0:55:37.263217	Training Loss 0.6091 (0.6334)	Training Prec@1 64.844 (58.503)	Training Prec@5 72.852 (68.101)	
2022-03-27 07:47:48,470: ============================================================
2022-03-27 07:49:25,799: time cost, forward:0.2625029439436083, backward:0.042454733638234335, data cost:0.6720201389092432 
2022-03-27 07:49:25,799: ============================================================
2022-03-27 07:49:25,799: Epoch 15/26 Batch 2200/7662 eta: 1 day, 0:15:48.950079	Training Loss 0.6033 (0.6320)	Training Prec@1 64.453 (58.855)	Training Prec@5 71.680 (68.410)	
2022-03-27 07:49:25,800: ============================================================
2022-03-27 07:51:10,548: time cost, forward:0.26264578676991174, backward:0.04251360457687079, data cost:0.674757598638016 
2022-03-27 07:51:10,549: ============================================================
2022-03-27 07:51:10,549: Epoch 15/26 Batch 2300/7662 eta: 1 day, 2:05:02.661095	Training Loss 0.6008 (0.6306)	Training Prec@1 65.234 (59.189)	Training Prec@5 73.242 (68.696)	
2022-03-27 07:51:10,549: ============================================================
2022-03-27 07:52:46,156: time cost, forward:0.26230980466434783, backward:0.04247836154319187, data cost:0.6743216104137744 
2022-03-27 07:52:46,156: ============================================================
2022-03-27 07:52:46,157: Epoch 15/26 Batch 2400/7662 eta: 23:46:51.970144	Training Loss 0.5940 (0.6292)	Training Prec@1 68.359 (59.515)	Training Prec@5 76.953 (68.982)	
2022-03-27 07:52:46,157: ============================================================
2022-03-27 07:54:23,803: time cost, forward:0.2625852638647622, backward:0.04247214489815091, data cost:0.6738981660626897 
2022-03-27 07:54:23,803: ============================================================
2022-03-27 07:54:23,803: Epoch 15/26 Batch 2500/7662 eta: 1 day, 0:15:40.129116	Training Loss 0.5938 (0.6279)	Training Prec@1 67.773 (59.834)	Training Prec@5 75.586 (69.264)	
2022-03-27 07:54:23,804: ============================================================
2022-03-27 07:56:01,853: time cost, forward:0.2622614699448471, backward:0.04248664580018945, data cost:0.6742284867615826 
2022-03-27 07:56:01,854: ============================================================
2022-03-27 07:56:01,854: Epoch 15/26 Batch 2600/7662 eta: 1 day, 0:20:03.463691	Training Loss 0.5802 (0.6266)	Training Prec@1 69.531 (60.154)	Training Prec@5 76.367 (69.543)	
2022-03-27 07:56:01,854: ============================================================
2022-03-27 07:57:40,266: time cost, forward:0.2620898739149412, backward:0.042461808233978396, data cost:0.6745922131730964 
2022-03-27 07:57:40,266: ============================================================
2022-03-27 07:57:40,266: Epoch 15/26 Batch 2700/7662 eta: 1 day, 0:23:47.799773	Training Loss 0.5947 (0.6253)	Training Prec@1 68.555 (60.459)	Training Prec@5 77.344 (69.807)	
2022-03-27 07:57:40,266: ============================================================
2022-03-27 07:59:21,999: time cost, forward:0.2621975524291774, backward:0.04252406987772536, data cost:0.6757325158454811 
2022-03-27 07:59:22,000: ============================================================
2022-03-27 07:59:22,000: Epoch 15/26 Batch 2800/7662 eta: 1 day, 1:11:30.581711	Training Loss 0.5930 (0.6240)	Training Prec@1 68.945 (60.760)	Training Prec@5 77.539 (70.064)	
2022-03-27 07:59:22,000: ============================================================
2022-03-27 08:01:00,126: time cost, forward:0.26213657481787983, backward:0.042497619261779467, data cost:0.6758611793557543 
2022-03-27 08:01:00,153: ============================================================
2022-03-27 08:01:00,157: Epoch 15/26 Batch 2900/7662 eta: 1 day, 0:16:42.839633	Training Loss 0.5732 (0.6227)	Training Prec@1 72.656 (61.039)	Training Prec@5 80.469 (70.309)	
2022-03-27 08:01:00,158: ============================================================
2022-03-27 08:02:39,992: time cost, forward:0.2623271398363053, backward:0.042491268101991435, data cost:0.6762867206015083 
2022-03-27 08:02:39,992: ============================================================
2022-03-27 08:02:39,992: Epoch 15/26 Batch 3000/7662 eta: 1 day, 0:39:59.243622	Training Loss 0.5805 (0.6215)	Training Prec@1 69.531 (61.319)	Training Prec@5 77.344 (70.560)	
2022-03-27 08:02:39,992: ============================================================
2022-03-27 08:04:17,264: time cost, forward:0.2624252694158563, backward:0.04249596972740939, data cost:0.6757540929775232 
2022-03-27 08:04:17,265: ============================================================
2022-03-27 08:04:17,265: Epoch 15/26 Batch 3100/7662 eta: 1 day, 0:00:21.992866	Training Loss 0.5759 (0.6203)	Training Prec@1 75.000 (61.606)	Training Prec@5 81.836 (70.807)	
2022-03-27 08:04:17,265: ============================================================
2022-03-27 08:05:57,466: time cost, forward:0.2625509113324885, backward:0.04247858062987404, data cost:0.6764763246740763 
2022-03-27 08:05:57,467: ============================================================
2022-03-27 08:05:57,467: Epoch 15/26 Batch 3200/7662 eta: 1 day, 0:42:04.312420	Training Loss 0.5767 (0.6190)	Training Prec@1 70.508 (61.884)	Training Prec@5 79.883 (71.047)	
2022-03-27 08:05:57,467: ============================================================
2022-03-27 08:07:32,873: time cost, forward:0.2625646568060138, backward:0.04249030555801415, data cost:0.675457801555785 
2022-03-27 08:07:32,874: ============================================================
2022-03-27 08:07:32,874: Epoch 15/26 Batch 3300/7662 eta: 23:29:33.467788	Training Loss 0.5835 (0.6178)	Training Prec@1 69.922 (62.161)	Training Prec@5 77.930 (71.285)	
2022-03-27 08:07:32,874: ============================================================
2022-03-27 08:09:14,231: time cost, forward:0.26265290092811683, backward:0.04253498495729856, data cost:0.6764353561064678 
2022-03-27 08:09:14,231: ============================================================
2022-03-27 08:09:14,232: Epoch 15/26 Batch 3400/7662 eta: 1 day, 0:55:47.224328	Training Loss 0.5769 (0.6167)	Training Prec@1 73.438 (62.433)	Training Prec@5 82.617 (71.515)	
2022-03-27 08:09:14,232: ============================================================
2022-03-27 08:10:50,569: time cost, forward:0.2625752445219857, backward:0.04261498234550692, data cost:0.6758727675746188 
2022-03-27 08:10:50,569: ============================================================
2022-03-27 08:10:50,569: Epoch 15/26 Batch 3500/7662 eta: 23:40:06.090591	Training Loss 0.5733 (0.6155)	Training Prec@1 73.047 (62.696)	Training Prec@5 81.250 (71.741)	
2022-03-27 08:10:50,570: ============================================================
2022-03-27 08:12:29,793: time cost, forward:0.26274878834975895, backward:0.042634349692096375, data cost:0.6760032923561429 
2022-03-27 08:12:29,793: ============================================================
2022-03-27 08:12:29,793: Epoch 15/26 Batch 3600/7662 eta: 1 day, 0:20:59.059853	Training Loss 0.5629 (0.6143)	Training Prec@1 73.633 (62.954)	Training Prec@5 81.836 (71.960)	
2022-03-27 08:12:29,793: ============================================================
2022-03-27 08:14:11,649: time cost, forward:0.2627296505118744, backward:0.0425828940548037, data cost:0.676865787433914 
2022-03-27 08:14:11,650: ============================================================
2022-03-27 08:14:11,650: Epoch 15/26 Batch 3700/7662 eta: 1 day, 0:58:03.413306	Training Loss 0.5660 (0.6132)	Training Prec@1 75.000 (63.204)	Training Prec@5 82.227 (72.177)	
2022-03-27 08:14:11,650: ============================================================
2022-03-27 08:15:50,270: time cost, forward:0.26287287177145874, backward:0.042558661948131495, data cost:0.6770302308613013 
2022-03-27 08:15:50,270: ============================================================
2022-03-27 08:15:50,271: Epoch 15/26 Batch 3800/7662 eta: 1 day, 0:08:49.402528	Training Loss 0.5682 (0.6121)	Training Prec@1 73.047 (63.449)	Training Prec@5 79.883 (72.388)	
2022-03-27 08:15:50,271: ============================================================
2022-03-27 08:17:31,041: time cost, forward:0.2629010616800485, backward:0.042552357607849076, data cost:0.6774511318324192 
2022-03-27 08:17:31,042: ============================================================
2022-03-27 08:17:31,043: Epoch 15/26 Batch 3900/7662 eta: 1 day, 0:38:44.497130	Training Loss 0.5591 (0.6109)	Training Prec@1 74.609 (63.685)	Training Prec@5 80.078 (72.586)	
2022-03-27 08:17:31,043: ============================================================
2022-03-27 08:19:06,416: time cost, forward:0.2626411140963685, backward:0.04253959858468188, data cost:0.6771711096461935 
2022-03-27 08:19:06,417: ============================================================
2022-03-27 08:19:06,417: Epoch 15/26 Batch 4000/7662 eta: 23:17:57.099025	Training Loss 0.5746 (0.6098)	Training Prec@1 71.484 (63.920)	Training Prec@5 77.344 (72.785)	
2022-03-27 08:19:06,417: ============================================================
2022-03-27 08:20:46,179: time cost, forward:0.26253248145156266, backward:0.0425661596096734, data cost:0.6775763403587034 
2022-03-27 08:20:46,179: ============================================================
2022-03-27 08:20:46,179: Epoch 15/26 Batch 4100/7662 eta: 1 day, 0:20:36.228890	Training Loss 0.5658 (0.6088)	Training Prec@1 74.414 (64.149)	Training Prec@5 81.445 (72.979)	
2022-03-27 08:20:46,179: ============================================================
2022-03-27 08:22:24,220: time cost, forward:0.2625047000540697, backward:0.042576951905641425, data cost:0.6775808079409071 
2022-03-27 08:22:24,220: ============================================================
2022-03-27 08:22:24,220: Epoch 15/26 Batch 4200/7662 eta: 23:53:46.021170	Training Loss 0.5634 (0.6077)	Training Prec@1 73.438 (64.379)	Training Prec@5 81.445 (73.176)	
2022-03-27 08:22:24,220: ============================================================
2022-03-27 08:24:01,609: time cost, forward:0.26238694809902324, backward:0.04257724656146968, data cost:0.6774825206826692 
2022-03-27 08:24:01,609: ============================================================
2022-03-27 08:24:01,609: Epoch 15/26 Batch 4300/7662 eta: 23:42:36.689089	Training Loss 0.5664 (0.6066)	Training Prec@1 72.266 (64.607)	Training Prec@5 77.734 (73.366)	
2022-03-27 08:24:01,609: ============================================================
2022-03-27 08:25:42,564: time cost, forward:0.2624354386877054, backward:0.04260633592850568, data cost:0.6780268782836574 
2022-03-27 08:25:42,565: ============================================================
2022-03-27 08:25:42,565: Epoch 15/26 Batch 4400/7662 eta: 1 day, 0:33:01.573987	Training Loss 0.5507 (0.6056)	Training Prec@1 76.953 (64.823)	Training Prec@5 84.570 (73.551)	
2022-03-27 08:25:42,565: ============================================================
2022-03-27 08:27:21,054: time cost, forward:0.2625859864263117, backward:0.04236957257947648, data cost:0.6781338121817361 
2022-03-27 08:27:21,055: ============================================================
2022-03-27 08:27:21,055: Epoch 15/26 Batch 4500/7662 eta: 23:55:24.486065	Training Loss 0.5608 (0.6046)	Training Prec@1 75.000 (65.036)	Training Prec@5 81.836 (73.729)	
2022-03-27 08:27:21,055: ============================================================
2022-03-27 08:29:00,662: time cost, forward:0.26256112446860663, backward:0.04244954758660901, data cost:0.6783663257616296 
2022-03-27 08:29:00,662: ============================================================
2022-03-27 08:29:00,662: Epoch 15/26 Batch 4600/7662 eta: 1 day, 0:10:02.324003	Training Loss 0.5591 (0.6035)	Training Prec@1 71.875 (65.248)	Training Prec@5 79.297 (73.910)	
2022-03-27 08:29:00,663: ============================================================
2022-03-27 08:30:41,065: time cost, forward:0.2625983032324792, backward:0.04249501421137499, data cost:0.6787121331445662 
2022-03-27 08:30:41,066: ============================================================
2022-03-27 08:30:41,066: Epoch 15/26 Batch 4700/7662 eta: 1 day, 0:19:57.074415	Training Loss 0.5599 (0.6025)	Training Prec@1 71.484 (65.449)	Training Prec@5 79.297 (74.079)	
2022-03-27 08:30:41,066: ============================================================
2022-03-27 08:32:19,831: time cost, forward:0.26258255601252184, backward:0.042578094078615625, data cost:0.6787100421510455 
2022-03-27 08:32:19,831: ============================================================
2022-03-27 08:32:19,832: Epoch 15/26 Batch 4800/7662 eta: 23:54:29.235342	Training Loss 0.5557 (0.6016)	Training Prec@1 74.023 (65.646)	Training Prec@5 81.641 (74.242)	
2022-03-27 08:32:19,832: ============================================================
2022-03-27 08:33:59,182: time cost, forward:0.26257865495598054, backward:0.042586612905816515, data cost:0.6789006918248995 
2022-03-27 08:33:59,183: ============================================================
2022-03-27 08:33:59,183: Epoch 15/26 Batch 4900/7662 eta: 1 day, 0:01:20.555956	Training Loss 0.5469 (0.6006)	Training Prec@1 75.586 (65.837)	Training Prec@5 82.227 (74.402)	
2022-03-27 08:33:59,183: ============================================================
2022-03-27 08:35:35,455: time cost, forward:0.2623954279514808, backward:0.04260536112006032, data cost:0.6786250108526954 
2022-03-27 08:35:35,455: ============================================================
2022-03-27 08:35:35,455: Epoch 15/26 Batch 5000/7662 eta: 23:15:03.848422	Training Loss 0.5575 (0.5996)	Training Prec@1 74.219 (66.035)	Training Prec@5 81.445 (74.569)	
2022-03-27 08:35:35,455: ============================================================
2022-03-27 08:37:12,577: time cost, forward:0.26251388082412624, backward:0.04264738588245225, data cost:0.6782149059395155 
2022-03-27 08:37:12,578: ============================================================
2022-03-27 08:37:12,578: Epoch 15/26 Batch 5100/7662 eta: 23:25:46.311907	Training Loss 0.5552 (0.5987)	Training Prec@1 76.172 (66.225)	Training Prec@5 84.180 (74.730)	
2022-03-27 08:37:12,578: ============================================================
2022-03-27 08:38:52,740: time cost, forward:0.26263048750181617, backward:0.04267314696087244, data cost:0.678403655023019 
2022-03-27 08:38:52,740: ============================================================
2022-03-27 08:38:52,740: Epoch 15/26 Batch 5200/7662 eta: 1 day, 0:08:05.494999	Training Loss 0.5488 (0.5977)	Training Prec@1 77.344 (66.413)	Training Prec@5 84.570 (74.888)	
2022-03-27 08:38:52,740: ============================================================
2022-03-27 08:40:32,336: time cost, forward:0.26265931417411575, backward:0.04267489466943433, data cost:0.6786111724401425 
2022-03-27 08:40:32,337: ============================================================
2022-03-27 08:40:32,337: Epoch 15/26 Batch 5300/7662 eta: 23:58:15.781919	Training Loss 0.5441 (0.5968)	Training Prec@1 81.055 (66.601)	Training Prec@5 85.547 (75.045)	
2022-03-27 08:40:32,337: ============================================================
2022-03-27 08:42:12,514: time cost, forward:0.2627490639885303, backward:0.04275026279900952, data cost:0.6786318010346805 
2022-03-27 08:42:12,515: ============================================================
2022-03-27 08:42:12,516: Epoch 15/26 Batch 5400/7662 eta: 1 day, 0:04:59.369903	Training Loss 0.5446 (0.5959)	Training Prec@1 78.516 (66.777)	Training Prec@5 85.547 (75.195)	
2022-03-27 08:42:12,516: ============================================================
2022-03-27 08:43:51,544: time cost, forward:0.26260193071922056, backward:0.04282211758783024, data cost:0.6789567782718889 
2022-03-27 08:43:51,545: ============================================================
2022-03-27 08:43:51,545: Epoch 15/26 Batch 5500/7662 eta: 23:46:46.160309	Training Loss 0.5466 (0.5950)	Training Prec@1 75.586 (66.959)	Training Prec@5 82.227 (75.345)	
2022-03-27 08:43:51,545: ============================================================
2022-03-27 08:45:29,246: time cost, forward:0.26257486947201514, backward:0.04283850498339133, data cost:0.6787391966380143 
2022-03-27 08:45:29,246: ============================================================
2022-03-27 08:45:29,247: Epoch 15/26 Batch 5600/7662 eta: 23:26:00.408706	Training Loss 0.5534 (0.5941)	Training Prec@1 73.633 (67.135)	Training Prec@5 82.031 (75.493)	
2022-03-27 08:45:29,247: ============================================================
2022-03-27 08:47:08,433: time cost, forward:0.26260492993689644, backward:0.04284000882016376, data cost:0.67892461790288 
2022-03-27 08:47:08,434: ============================================================
2022-03-27 08:47:08,434: Epoch 15/26 Batch 5700/7662 eta: 23:45:44.017767	Training Loss 0.5576 (0.5932)	Training Prec@1 74.023 (67.304)	Training Prec@5 81.250 (75.635)	
2022-03-27 08:47:08,434: ============================================================
2022-03-27 08:48:47,769: time cost, forward:0.2625223184622738, backward:0.04285038165089015, data cost:0.6790160091812599 
2022-03-27 08:48:47,769: ============================================================
2022-03-27 08:48:47,769: Epoch 15/26 Batch 5800/7662 eta: 23:46:12.643086	Training Loss 0.5511 (0.5924)	Training Prec@1 75.195 (67.469)	Training Prec@5 81.836 (75.771)	
2022-03-27 08:48:47,770: ============================================================
2022-03-27 08:50:27,640: time cost, forward:0.26257872977566366, backward:0.04282488958737389, data cost:0.6793422105656294 
2022-03-27 08:50:27,641: ============================================================
2022-03-27 08:50:27,641: Epoch 15/26 Batch 5900/7662 eta: 23:52:14.431368	Training Loss 0.5298 (0.5915)	Training Prec@1 77.930 (67.635)	Training Prec@5 83.984 (75.909)	
2022-03-27 08:50:27,641: ============================================================
2022-03-27 08:52:03,000: time cost, forward:0.2625516319815408, backward:0.04283620679670621, data cost:0.6788483007408456 
2022-03-27 08:52:03,001: ============================================================
2022-03-27 08:52:03,001: Epoch 15/26 Batch 6000/7662 eta: 22:45:57.114412	Training Loss 0.5425 (0.5906)	Training Prec@1 75.586 (67.804)	Training Prec@5 84.375 (76.051)	
2022-03-27 08:52:03,001: ============================================================
2022-03-27 08:53:44,040: time cost, forward:0.26271141124643405, backward:0.0428577293859464, data cost:0.6790478337415028 
2022-03-27 08:53:44,040: ============================================================
2022-03-27 08:53:44,041: Epoch 15/26 Batch 6100/7662 eta: 1 day, 0:05:37.460699	Training Loss 0.5345 (0.5898)	Training Prec@1 81.055 (67.971)	Training Prec@5 88.672 (76.187)	
2022-03-27 08:53:44,041: ============================================================
2022-03-27 08:55:21,736: time cost, forward:0.262620719176451, backward:0.04286297553392125, data cost:0.6789326606632952 
2022-03-27 08:55:21,737: ============================================================
2022-03-27 08:55:21,738: Epoch 15/26 Batch 6200/7662 eta: 23:16:10.272230	Training Loss 0.5396 (0.5890)	Training Prec@1 75.586 (68.128)	Training Prec@5 83.594 (76.318)	
2022-03-27 08:55:21,738: ============================================================
2022-03-27 08:57:01,399: time cost, forward:0.26268946282313654, backward:0.04286727191418158, data cost:0.6791461195372688 
2022-03-27 08:57:01,400: ============================================================
2022-03-27 08:57:01,400: Epoch 15/26 Batch 6300/7662 eta: 23:42:36.014610	Training Loss 0.5506 (0.5881)	Training Prec@1 75.977 (68.282)	Training Prec@5 84.375 (76.447)	
2022-03-27 08:57:01,400: ============================================================
2022-03-27 08:58:40,408: time cost, forward:0.2626354644067177, backward:0.042856951657077785, data cost:0.6792933437522081 
2022-03-27 08:58:40,409: ============================================================
2022-03-27 08:58:40,409: Epoch 15/26 Batch 6400/7662 eta: 23:31:36.861997	Training Loss 0.5342 (0.5874)	Training Prec@1 78.711 (68.434)	Training Prec@5 83.789 (76.575)	
2022-03-27 08:58:40,409: ============================================================
2022-03-27 09:00:20,692: time cost, forward:0.2627256048296136, backward:0.042861095849028516, data cost:0.6794806114433912 
2022-03-27 09:00:20,693: ============================================================
2022-03-27 09:00:20,693: Epoch 15/26 Batch 6500/7662 eta: 23:48:08.256140	Training Loss 0.5389 (0.5866)	Training Prec@1 73.828 (68.580)	Training Prec@5 78.906 (76.694)	
2022-03-27 09:00:20,694: ============================================================
2022-03-27 09:02:02,887: time cost, forward:0.2627091359723642, backward:0.04286226609888032, data cost:0.6800518065514863 
2022-03-27 09:02:02,887: ============================================================
2022-03-27 09:02:02,887: Epoch 15/26 Batch 6600/7662 eta: 1 day, 0:13:37.335823	Training Loss 0.5246 (0.5858)	Training Prec@1 80.664 (68.724)	Training Prec@5 86.133 (76.817)	
2022-03-27 09:02:02,887: ============================================================
2022-03-27 09:03:37,026: time cost, forward:0.2625813416214661, backward:0.04285844448235947, data cost:0.6795505571230114 
2022-03-27 09:03:37,026: ============================================================
2022-03-27 09:03:37,027: Epoch 15/26 Batch 6700/7662 eta: 22:17:29.111414	Training Loss 0.5353 (0.5850)	Training Prec@1 79.102 (68.872)	Training Prec@5 84.766 (76.938)	
2022-03-27 09:03:37,027: ============================================================
2022-03-27 09:05:17,991: time cost, forward:0.26306297491886876, backward:0.04286115508620258, data cost:0.679387788489244 
2022-03-27 09:05:17,992: ============================================================
2022-03-27 09:05:17,992: Epoch 15/26 Batch 6800/7662 eta: 23:52:46.878569	Training Loss 0.5375 (0.5843)	Training Prec@1 78.125 (69.013)	Training Prec@5 83.789 (77.056)	
2022-03-27 09:05:17,992: ============================================================
2022-03-27 09:06:54,917: time cost, forward:0.2631964112973106, backward:0.0428967000021591, data cost:0.6789761385825738 
2022-03-27 09:06:54,918: ============================================================
2022-03-27 09:06:54,918: Epoch 15/26 Batch 6900/7662 eta: 22:53:50.725722	Training Loss 0.5358 (0.5835)	Training Prec@1 77.930 (69.155)	Training Prec@5 84.570 (77.174)	
2022-03-27 09:06:54,918: ============================================================
2022-03-27 09:08:32,410: time cost, forward:0.26311037270984305, backward:0.04289195162515195, data cost:0.6789062825045018 
2022-03-27 09:08:32,411: ============================================================
2022-03-27 09:08:32,411: Epoch 15/26 Batch 7000/7662 eta: 23:00:15.425433	Training Loss 0.5394 (0.5828)	Training Prec@1 76.758 (69.290)	Training Prec@5 83.008 (77.289)	
2022-03-27 09:08:32,411: ============================================================
2022-03-27 09:10:10,213: time cost, forward:0.2630510189479834, backward:0.042907447710156796, data cost:0.6788682462732831 
2022-03-27 09:10:10,214: ============================================================
2022-03-27 09:10:10,214: Epoch 15/26 Batch 7100/7662 eta: 23:03:00.927007	Training Loss 0.5281 (0.5820)	Training Prec@1 77.734 (69.425)	Training Prec@5 84.961 (77.401)	
2022-03-27 09:10:10,214: ============================================================
2022-03-27 09:11:47,283: time cost, forward:0.26308813153380967, backward:0.04289678448288784, data cost:0.6786360725427207 
2022-03-27 09:11:47,284: ============================================================
2022-03-27 09:11:47,284: Epoch 15/26 Batch 7200/7662 eta: 22:51:01.932448	Training Loss 0.5317 (0.5813)	Training Prec@1 80.469 (69.560)	Training Prec@5 86.523 (77.512)	
2022-03-27 09:11:47,284: ============================================================
2022-03-27 09:13:28,131: time cost, forward:0.26315140600056824, backward:0.04289588593084333, data cost:0.6788283778732975 
2022-03-27 09:13:28,132: ============================================================
2022-03-27 09:13:28,133: Epoch 15/26 Batch 7300/7662 eta: 23:42:43.285689	Training Loss 0.5249 (0.5806)	Training Prec@1 79.688 (69.698)	Training Prec@5 84.961 (77.624)	
2022-03-27 09:13:28,133: ============================================================
2022-03-27 09:15:06,991: time cost, forward:0.26320244918273644, backward:0.042866652552252416, data cost:0.6789118832455308 
2022-03-27 09:15:06,991: ============================================================
2022-03-27 09:15:06,991: Epoch 15/26 Batch 7400/7662 eta: 23:13:00.031708	Training Loss 0.5152 (0.5799)	Training Prec@1 79.102 (69.829)	Training Prec@5 85.547 (77.731)	
2022-03-27 09:15:06,991: ============================================================
2022-03-27 09:16:45,776: time cost, forward:0.2632662812492532, backward:0.042891119111139055, data cost:0.678862169975121 
2022-03-27 09:16:45,776: ============================================================
2022-03-27 09:16:45,777: Epoch 15/26 Batch 7500/7662 eta: 23:10:19.409880	Training Loss 0.5271 (0.5792)	Training Prec@1 79.492 (69.959)	Training Prec@5 85.156 (77.838)	
2022-03-27 09:16:45,777: ============================================================
2022-03-27 09:18:21,579: time cost, forward:0.2632816512422478, backward:0.04289348957836354, data cost:0.678470526263657 
2022-03-27 09:18:21,580: ============================================================
2022-03-27 09:18:21,580: Epoch 15/26 Batch 7600/7662 eta: 22:26:45.338751	Training Loss 0.5228 (0.5785)	Training Prec@1 80.078 (70.084)	Training Prec@5 85.352 (77.941)	
2022-03-27 09:18:21,580: ============================================================
2022-03-27 09:19:27,376: Epoch: 15/26 eta: 22:25:44.982638	Training Loss 0.5304 (0.5780)	Training Prec@1 81.250 (70.165)	Training Prec@5 86.719 (78.006)
2022-03-27 09:19:27,377: ============================================================
2022-03-27 09:19:27,380: Save Checkpoint...
2022-03-27 09:19:27,380: ============================================================
2022-03-27 09:19:31,370: Save done!
2022-03-27 09:19:31,371: ============================================================
2022-03-27 09:21:20,742: time cost, forward:0.2939718082697705, backward:0.03830282856719663, data cost:0.7586056800803753 
2022-03-27 09:21:20,744: ============================================================
2022-03-27 09:21:20,745: Epoch 16/26 Batch 100/7662 eta: 1 day, 1:34:30.392849	Training Loss 0.5131 (0.5138)	Training Prec@1 83.008 (82.004)	Training Prec@5 87.500 (87.776)	
2022-03-27 09:21:20,745: ============================================================
2022-03-27 09:22:58,189: time cost, forward:0.2853543746411501, backward:0.03781134039912391, data cost:0.7090932112842349 
2022-03-27 09:22:58,190: ============================================================
2022-03-27 09:22:58,190: Epoch 16/26 Batch 200/7662 eta: 22:45:35.361291	Training Loss 0.5168 (0.5138)	Training Prec@1 81.445 (81.859)	Training Prec@5 85.938 (87.632)	
2022-03-27 09:22:58,191: ============================================================
2022-03-27 09:24:34,732: time cost, forward:0.275733974865049, backward:0.03831420375351922, data cost:0.6975136823877442 
2022-03-27 09:24:34,756: ============================================================
2022-03-27 09:24:34,757: Epoch 16/26 Batch 300/7662 eta: 22:31:39.472685	Training Loss 0.5155 (0.5138)	Training Prec@1 79.883 (81.841)	Training Prec@5 85.742 (87.575)	
2022-03-27 09:24:34,757: ============================================================
2022-03-27 09:26:14,654: time cost, forward:0.27577079268625204, backward:0.039212863248093685, data cost:0.6940960256676925 
2022-03-27 09:26:14,654: ============================================================
2022-03-27 09:26:14,655: Epoch 16/26 Batch 400/7662 eta: 23:16:37.387743	Training Loss 0.5161 (0.5136)	Training Prec@1 83.398 (81.936)	Training Prec@5 89.844 (87.639)	
2022-03-27 09:26:14,655: ============================================================
2022-03-27 09:27:52,856: time cost, forward:0.27252489865901236, backward:0.03987714283929798, data cost:0.6911745209971029 
2022-03-27 09:27:52,856: ============================================================
2022-03-27 09:27:52,857: Epoch 16/26 Batch 500/7662 eta: 22:51:16.530641	Training Loss 0.5122 (0.5135)	Training Prec@1 83.008 (81.923)	Training Prec@5 87.891 (87.587)	
2022-03-27 09:27:52,857: ============================================================
2022-03-27 09:29:32,884: time cost, forward:0.27111543319460146, backward:0.040387430652752146, data cost:0.6912073185527464 
2022-03-27 09:29:32,884: ============================================================
2022-03-27 09:29:32,885: Epoch 16/26 Batch 600/7662 eta: 23:15:06.466053	Training Loss 0.5173 (0.5135)	Training Prec@1 81.641 (81.941)	Training Prec@5 88.086 (87.555)	
2022-03-27 09:29:32,885: ============================================================
2022-03-27 09:31:14,729: time cost, forward:0.2706495965158138, backward:0.040419089094934205, data cost:0.6932174392012568 
2022-03-27 09:31:14,730: ============================================================
2022-03-27 09:31:14,730: Epoch 16/26 Batch 700/7662 eta: 23:38:45.476631	Training Loss 0.5162 (0.5134)	Training Prec@1 81.445 (81.932)	Training Prec@5 87.305 (87.554)	
2022-03-27 09:31:14,730: ============================================================
2022-03-27 09:32:52,053: time cost, forward:0.26975622523263637, backward:0.04083289580888235, data cost:0.6904748837849375 
2022-03-27 09:32:52,053: ============================================================
2022-03-27 09:32:52,054: Epoch 16/26 Batch 800/7662 eta: 22:34:08.571067	Training Loss 0.5132 (0.5133)	Training Prec@1 81.445 (81.949)	Training Prec@5 86.914 (87.573)	
2022-03-27 09:32:52,054: ============================================================
2022-03-27 09:34:31,363: time cost, forward:0.2695823177214592, backward:0.041124995478798734, data cost:0.6888903075781494 
2022-03-27 09:34:31,364: ============================================================
2022-03-27 09:34:31,364: Epoch 16/26 Batch 900/7662 eta: 23:00:07.746911	Training Loss 0.5224 (0.5131)	Training Prec@1 81.641 (81.961)	Training Prec@5 87.305 (87.601)	
2022-03-27 09:34:31,364: ============================================================
2022-03-27 09:36:08,588: time cost, forward:0.26980275005191656, backward:0.04136398318293574, data cost:0.6859924867227152 
2022-03-27 09:36:08,589: ============================================================
2022-03-27 09:36:08,589: Epoch 16/26 Batch 1000/7662 eta: 22:29:32.418492	Training Loss 0.5146 (0.5127)	Training Prec@1 82.227 (82.009)	Training Prec@5 86.719 (87.627)	
2022-03-27 09:36:08,590: ============================================================
2022-03-27 09:37:52,378: time cost, forward:0.27083308009042645, backward:0.041766730517664205, data cost:0.6882633937283794 
2022-03-27 09:37:52,379: ============================================================
2022-03-27 09:37:52,379: Epoch 16/26 Batch 1100/7662 eta: 23:58:55.510129	Training Loss 0.5188 (0.5126)	Training Prec@1 78.125 (82.020)	Training Prec@5 85.742 (87.646)	
2022-03-27 09:37:52,380: ============================================================
2022-03-27 09:39:33,855: time cost, forward:0.27217735023275824, backward:0.04195334714487058, data cost:0.6873460046642517 
2022-03-27 09:39:33,855: ============================================================
2022-03-27 09:39:33,855: Epoch 16/26 Batch 1200/7662 eta: 23:25:09.403191	Training Loss 0.5113 (0.5124)	Training Prec@1 82.617 (82.032)	Training Prec@5 88.867 (87.655)	
2022-03-27 09:39:33,856: ============================================================
2022-03-27 09:41:16,213: time cost, forward:0.27323818261849137, backward:0.04192098110248897, data cost:0.688486413463801 
2022-03-27 09:41:16,214: ============================================================
2022-03-27 09:41:16,214: Epoch 16/26 Batch 1300/7662 eta: 23:35:40.281669	Training Loss 0.5114 (0.5122)	Training Prec@1 82.422 (82.056)	Training Prec@5 88.867 (87.687)	
2022-03-27 09:41:16,214: ============================================================
2022-03-27 09:42:57,875: time cost, forward:0.27477062370540245, backward:0.04188599511501702, data cost:0.6878278086746139 
2022-03-27 09:42:57,876: ============================================================
2022-03-27 09:42:57,876: Epoch 16/26 Batch 1400/7662 eta: 23:24:20.496638	Training Loss 0.5107 (0.5120)	Training Prec@1 84.180 (82.074)	Training Prec@5 89.648 (87.706)	
2022-03-27 09:42:57,876: ============================================================
2022-03-27 09:44:40,222: time cost, forward:0.27653126990182786, backward:0.04180470031448171, data cost:0.687391806953028 
2022-03-27 09:44:40,223: ============================================================
2022-03-27 09:44:40,223: Epoch 16/26 Batch 1500/7662 eta: 23:32:05.967046	Training Loss 0.4988 (0.5118)	Training Prec@1 85.156 (82.092)	Training Prec@5 89.258 (87.723)	
2022-03-27 09:44:40,223: ============================================================
2022-03-27 09:46:24,040: time cost, forward:0.27999970657964135, backward:0.041595909877297575, data cost:0.686216032303744 
2022-03-27 09:46:24,040: ============================================================
2022-03-27 09:46:24,040: Epoch 16/26 Batch 1600/7662 eta: 23:50:39.282276	Training Loss 0.5179 (0.5115)	Training Prec@1 83.203 (82.124)	Training Prec@5 88.281 (87.752)	
2022-03-27 09:46:24,040: ============================================================
2022-03-27 09:48:05,350: time cost, forward:0.28220436024343076, backward:0.041123094946023224, data cost:0.6847707059118171 
2022-03-27 09:48:05,352: ============================================================
2022-03-27 09:48:05,352: Epoch 16/26 Batch 1700/7662 eta: 23:14:26.021762	Training Loss 0.5168 (0.5113)	Training Prec@1 80.859 (82.140)	Training Prec@5 86.719 (87.764)	
2022-03-27 09:48:05,352: ============================================================
2022-03-27 09:49:49,761: time cost, forward:0.2837535455002925, backward:0.041179033833917744, data cost:0.6851033035286802 
2022-03-27 09:49:49,761: ============================================================
2022-03-27 09:49:49,761: Epoch 16/26 Batch 1800/7662 eta: 23:55:19.976876	Training Loss 0.5089 (0.5111)	Training Prec@1 81.055 (82.167)	Training Prec@5 86.523 (87.783)	
2022-03-27 09:49:49,761: ============================================================
2022-03-27 09:51:29,900: time cost, forward:0.28431860593320696, backward:0.04133344638215799, data cost:0.6837849394781707 
2022-03-27 09:51:29,901: ============================================================
2022-03-27 09:51:29,901: Epoch 16/26 Batch 1900/7662 eta: 22:54:58.097444	Training Loss 0.5007 (0.5109)	Training Prec@1 83.594 (82.202)	Training Prec@5 89.453 (87.813)	
2022-03-27 09:51:29,901: ============================================================
2022-03-27 09:53:12,666: time cost, forward:0.2846859118054663, backward:0.041639363067993346, data cost:0.6841611646305865 
2022-03-27 09:53:12,666: ============================================================
2022-03-27 09:53:12,666: Epoch 16/26 Batch 2000/7662 eta: 23:29:18.356526	Training Loss 0.5000 (0.5107)	Training Prec@1 81.445 (82.219)	Training Prec@5 87.695 (87.828)	
2022-03-27 09:53:12,666: ============================================================
2022-03-27 09:54:52,552: time cost, forward:0.28392604125460424, backward:0.041646882316622065, data cost:0.6843357306539927 
2022-03-27 09:54:52,553: ============================================================
2022-03-27 09:54:52,553: Epoch 16/26 Batch 2100/7662 eta: 22:48:09.776081	Training Loss 0.5049 (0.5104)	Training Prec@1 84.180 (82.261)	Training Prec@5 89.648 (87.856)	
2022-03-27 09:54:52,553: ============================================================
2022-03-27 09:56:34,789: time cost, forward:0.2836222277819541, backward:0.041701719618862786, data cost:0.6848445806030579 
2022-03-27 09:56:34,790: ============================================================
2022-03-27 09:56:34,790: Epoch 16/26 Batch 2200/7662 eta: 23:18:39.360111	Training Loss 0.4943 (0.5102)	Training Prec@1 83.789 (82.279)	Training Prec@5 89.648 (87.874)	
2022-03-27 09:56:34,790: ============================================================
2022-03-27 09:58:13,135: time cost, forward:0.2829743119207036, backward:0.04182222772028302, data cost:0.6841549153636984 
2022-03-27 09:58:13,136: ============================================================
2022-03-27 09:58:13,136: Epoch 16/26 Batch 2300/7662 eta: 22:23:46.917095	Training Loss 0.5147 (0.5100)	Training Prec@1 81.250 (82.315)	Training Prec@5 86.719 (87.907)	
2022-03-27 09:58:13,136: ============================================================
2022-03-27 09:59:54,461: time cost, forward:0.2825388581417858, backward:0.04190692965216118, data cost:0.6847009682665273 
2022-03-27 09:59:54,462: ============================================================
2022-03-27 09:59:54,462: Epoch 16/26 Batch 2400/7662 eta: 23:02:48.740643	Training Loss 0.5066 (0.5097)	Training Prec@1 83.398 (82.340)	Training Prec@5 89.844 (87.931)	
2022-03-27 09:59:54,462: ============================================================
2022-03-27 10:01:34,940: time cost, forward:0.2824264878795451, backward:0.042032544066210466, data cost:0.6847799639074075 
2022-03-27 10:01:34,940: ============================================================
2022-03-27 10:01:34,940: Epoch 16/26 Batch 2500/7662 eta: 22:49:34.141453	Training Loss 0.5043 (0.5095)	Training Prec@1 81.641 (82.361)	Training Prec@5 87.695 (87.944)	
2022-03-27 10:01:34,940: ============================================================
2022-03-27 10:03:17,416: time cost, forward:0.28219420481480373, backward:0.04210471822555912, data cost:0.6855124265884335 
2022-03-27 10:03:17,416: ============================================================
2022-03-27 10:03:17,416: Epoch 16/26 Batch 2600/7662 eta: 23:15:05.676401	Training Loss 0.5089 (0.5093)	Training Prec@1 84.570 (82.384)	Training Prec@5 88.867 (87.964)	
2022-03-27 10:03:17,417: ============================================================
2022-03-27 10:04:55,084: time cost, forward:0.28192747756700776, backward:0.04219090050792376, data cost:0.6843210953878182 
2022-03-27 10:04:55,085: ============================================================
2022-03-27 10:04:55,085: Epoch 16/26 Batch 2700/7662 eta: 22:08:00.759851	Training Loss 0.5093 (0.5092)	Training Prec@1 83.594 (82.407)	Training Prec@5 89.648 (87.981)	
2022-03-27 10:04:55,085: ============================================================
2022-03-27 10:06:36,347: time cost, forward:0.28197902251499474, backward:0.042239030798489216, data cost:0.6844380517736764 
2022-03-27 10:06:36,348: ============================================================
2022-03-27 10:06:36,348: Epoch 16/26 Batch 2800/7662 eta: 22:55:12.320685	Training Loss 0.4991 (0.5090)	Training Prec@1 83.203 (82.432)	Training Prec@5 90.234 (88.003)	
2022-03-27 10:06:36,348: ============================================================
2022-03-27 10:08:20,058: time cost, forward:0.28218317327930337, backward:0.04227901245240879, data cost:0.685018690424403 
2022-03-27 10:08:20,059: ============================================================
2022-03-27 10:08:20,060: Epoch 16/26 Batch 2900/7662 eta: 23:26:43.617884	Training Loss 0.5133 (0.5088)	Training Prec@1 79.297 (82.455)	Training Prec@5 85.938 (88.022)	
2022-03-27 10:08:20,060: ============================================================
2022-03-27 10:10:00,043: time cost, forward:0.2820581258555657, backward:0.04234853407747549, data cost:0.684747897930724 
2022-03-27 10:10:00,044: ============================================================
2022-03-27 10:10:00,044: Epoch 16/26 Batch 3000/7662 eta: 22:34:30.130155	Training Loss 0.5023 (0.5086)	Training Prec@1 83.008 (82.486)	Training Prec@5 88.867 (88.040)	
2022-03-27 10:10:00,044: ============================================================
2022-03-27 10:11:42,752: time cost, forward:0.28212031882668587, backward:0.04239269347681696, data cost:0.6851296911858173 
2022-03-27 10:11:42,753: ============================================================
2022-03-27 10:11:42,754: Epoch 16/26 Batch 3100/7662 eta: 23:09:42.873905	Training Loss 0.5004 (0.5084)	Training Prec@1 84.570 (82.504)	Training Prec@5 89.062 (88.055)	
2022-03-27 10:11:42,754: ============================================================
2022-03-27 10:13:23,679: time cost, forward:0.2819835501709891, backward:0.0424475424660113, data cost:0.6854381279559313 
2022-03-27 10:13:23,679: ============================================================
2022-03-27 10:13:23,679: Epoch 16/26 Batch 3200/7662 eta: 22:43:53.742650	Training Loss 0.5007 (0.5082)	Training Prec@1 83.398 (82.532)	Training Prec@5 88.281 (88.075)	
2022-03-27 10:13:23,680: ============================================================
2022-03-27 10:15:03,703: time cost, forward:0.2815994917894718, backward:0.04246820995900876, data cost:0.6854568022820183 
2022-03-27 10:15:03,705: ============================================================
2022-03-27 10:15:03,705: Epoch 16/26 Batch 3300/7662 eta: 22:30:03.463041	Training Loss 0.5069 (0.5081)	Training Prec@1 81.836 (82.544)	Training Prec@5 87.305 (88.083)	
2022-03-27 10:15:03,705: ============================================================
2022-03-27 10:16:48,319: time cost, forward:0.28179771607677595, backward:0.04254965566122802, data cost:0.6862450129987914 
2022-03-27 10:16:48,320: ============================================================
2022-03-27 10:16:48,321: Epoch 16/26 Batch 3400/7662 eta: 23:30:16.356168	Training Loss 0.5040 (0.5079)	Training Prec@1 81.641 (82.567)	Training Prec@5 87.891 (88.103)	
2022-03-27 10:16:48,321: ============================================================
2022-03-27 10:18:29,033: time cost, forward:0.28187668224715207, backward:0.0425755871333678, data cost:0.6860059870757795 
2022-03-27 10:18:29,034: ============================================================
2022-03-27 10:18:29,034: Epoch 16/26 Batch 3500/7662 eta: 22:35:59.599163	Training Loss 0.5068 (0.5077)	Training Prec@1 84.180 (82.589)	Training Prec@5 89.648 (88.126)	
2022-03-27 10:18:29,035: ============================================================
2022-03-27 10:20:09,418: time cost, forward:0.2820274331033743, backward:0.04262491735228899, data cost:0.6856647601688064 
2022-03-27 10:20:09,419: ============================================================
2022-03-27 10:20:09,419: Epoch 16/26 Batch 3600/7662 eta: 22:29:53.271747	Training Loss 0.5020 (0.5075)	Training Prec@1 83.789 (82.613)	Training Prec@5 89.648 (88.148)	
2022-03-27 10:20:09,419: ============================================================
2022-03-27 10:21:48,400: time cost, forward:0.28157966257462985, backward:0.04266529226341773, data cost:0.6855012171653259 
2022-03-27 10:21:48,401: ============================================================
2022-03-27 10:21:48,401: Epoch 16/26 Batch 3700/7662 eta: 22:09:22.741040	Training Loss 0.4903 (0.5073)	Training Prec@1 87.695 (82.643)	Training Prec@5 90.234 (88.172)	
2022-03-27 10:21:48,401: ============================================================
2022-03-27 10:23:29,958: time cost, forward:0.2817162770790689, backward:0.042640209951097005, data cost:0.6854807206535691 
2022-03-27 10:23:29,958: ============================================================
2022-03-27 10:23:29,958: Epoch 16/26 Batch 3800/7662 eta: 22:42:16.345522	Training Loss 0.5023 (0.5071)	Training Prec@1 84.375 (82.659)	Training Prec@5 90.039 (88.183)	
2022-03-27 10:23:29,958: ============================================================
2022-03-27 10:25:03,642: time cost, forward:0.2809519767149744, backward:0.04263558636019859, data cost:0.6843459463694304 
2022-03-27 10:25:03,643: ============================================================
2022-03-27 10:25:03,643: Epoch 16/26 Batch 3900/7662 eta: 20:55:06.719405	Training Loss 0.4925 (0.5070)	Training Prec@1 84.570 (82.674)	Training Prec@5 88.477 (88.197)	
2022-03-27 10:25:03,644: ============================================================
2022-03-27 10:26:44,604: time cost, forward:0.28068243226101175, backward:0.042692881162299544, data cost:0.6846320793073635 
2022-03-27 10:26:44,605: ============================================================
2022-03-27 10:26:44,605: Epoch 16/26 Batch 4000/7662 eta: 22:30:55.292706	Training Loss 0.5016 (0.5068)	Training Prec@1 81.445 (82.694)	Training Prec@5 87.891 (88.215)	
2022-03-27 10:26:44,605: ============================================================
2022-03-27 10:28:26,684: time cost, forward:0.28052929681404304, backward:0.04273540672949972, data cost:0.6848982766536016 
2022-03-27 10:28:26,685: ============================================================
2022-03-27 10:28:26,686: Epoch 16/26 Batch 4100/7662 eta: 22:44:10.948761	Training Loss 0.4993 (0.5066)	Training Prec@1 84.375 (82.718)	Training Prec@5 89.258 (88.231)	
2022-03-27 10:28:26,686: ============================================================
2022-03-27 10:30:11,935: time cost, forward:0.28025249504821587, backward:0.04274872922704288, data cost:0.6861897893507273 
2022-03-27 10:30:11,936: ============================================================
2022-03-27 10:30:11,936: Epoch 16/26 Batch 4200/7662 eta: 23:24:47.912732	Training Loss 0.5073 (0.5065)	Training Prec@1 84.375 (82.739)	Training Prec@5 88.867 (88.246)	
2022-03-27 10:30:11,936: ============================================================
2022-03-27 10:31:52,668: time cost, forward:0.28016425465727773, backward:0.04277536219623261, data cost:0.6863120040884682 
2022-03-27 10:31:52,668: ============================================================
2022-03-27 10:31:52,668: Epoch 16/26 Batch 4300/7662 eta: 22:22:48.763980	Training Loss 0.4956 (0.5063)	Training Prec@1 85.352 (82.756)	Training Prec@5 90.234 (88.261)	
2022-03-27 10:31:52,669: ============================================================
2022-03-27 10:33:39,547: time cost, forward:0.2806032749977294, backward:0.04281337994503742, data cost:0.6872714782579564 
2022-03-27 10:33:39,548: ============================================================
2022-03-27 10:33:39,548: Epoch 16/26 Batch 4400/7662 eta: 23:42:58.729372	Training Loss 0.4882 (0.5062)	Training Prec@1 84.961 (82.778)	Training Prec@5 90.039 (88.276)	
2022-03-27 10:33:39,548: ============================================================
2022-03-27 10:35:20,316: time cost, forward:0.2803638191269779, backward:0.042842991857111094, data cost:0.6873885663145515 
2022-03-27 10:35:20,316: ============================================================
2022-03-27 10:35:20,317: Epoch 16/26 Batch 4500/7662 eta: 22:19:56.123486	Training Loss 0.4897 (0.5060)	Training Prec@1 81.836 (82.802)	Training Prec@5 89.648 (88.294)	
2022-03-27 10:35:20,317: ============================================================
2022-03-27 10:37:01,920: time cost, forward:0.2802599037852228, backward:0.04283274098773914, data cost:0.6876158046058842 
2022-03-27 10:37:01,920: ============================================================
2022-03-27 10:37:01,920: Epoch 16/26 Batch 4600/7662 eta: 22:29:20.679391	Training Loss 0.4901 (0.5058)	Training Prec@1 85.938 (82.819)	Training Prec@5 90.039 (88.306)	
2022-03-27 10:37:01,920: ============================================================
2022-03-27 10:38:43,976: time cost, forward:0.2802235693544955, backward:0.04260668822566761, data cost:0.6879585719813842 
2022-03-27 10:38:43,977: ============================================================
2022-03-27 10:38:43,978: Epoch 16/26 Batch 4700/7662 eta: 22:33:40.316346	Training Loss 0.4847 (0.5057)	Training Prec@1 87.305 (82.841)	Training Prec@5 91.016 (88.321)	
2022-03-27 10:38:43,978: ============================================================
2022-03-27 10:40:27,613: time cost, forward:0.28023096873725944, backward:0.042376276502313154, data cost:0.6888310767183902 
2022-03-27 10:40:27,613: ============================================================
2022-03-27 10:40:27,613: Epoch 16/26 Batch 4800/7662 eta: 22:52:52.810986	Training Loss 0.4881 (0.5055)	Training Prec@1 85.352 (82.860)	Training Prec@5 90.820 (88.337)	
2022-03-27 10:40:27,613: ============================================================
2022-03-27 10:42:10,805: time cost, forward:0.28034730224274546, backward:0.042200491267288184, data cost:0.6892297422674194 
2022-03-27 10:42:10,805: ============================================================
2022-03-27 10:42:10,805: Epoch 16/26 Batch 4900/7662 eta: 22:45:16.810658	Training Loss 0.4997 (0.5054)	Training Prec@1 82.227 (82.879)	Training Prec@5 88.477 (88.350)	
2022-03-27 10:42:10,805: ============================================================
2022-03-27 10:43:53,036: time cost, forward:0.280430537363271, backward:0.042259075708879566, data cost:0.6891873215741934 
2022-03-27 10:43:53,037: ============================================================
2022-03-27 10:43:53,037: Epoch 16/26 Batch 5000/7662 eta: 22:30:52.411026	Training Loss 0.5038 (0.5052)	Training Prec@1 82.812 (82.901)	Training Prec@5 88.086 (88.368)	
2022-03-27 10:43:53,037: ============================================================
2022-03-27 10:45:35,628: time cost, forward:0.28044765340180744, backward:0.042268681138093435, data cost:0.6895910648066148 
2022-03-27 10:45:35,628: ============================================================
2022-03-27 10:45:35,628: Epoch 16/26 Batch 5100/7662 eta: 22:33:54.825100	Training Loss 0.5079 (0.5051)	Training Prec@1 82.422 (82.921)	Training Prec@5 88.281 (88.382)	
2022-03-27 10:45:35,628: ============================================================
2022-03-27 10:47:19,206: time cost, forward:0.2802677539294214, backward:0.042298848364393994, data cost:0.6900952246171232 
2022-03-27 10:47:19,207: ============================================================
2022-03-27 10:47:19,207: Epoch 16/26 Batch 5200/7662 eta: 22:45:13.043254	Training Loss 0.4951 (0.5049)	Training Prec@1 86.328 (82.940)	Training Prec@5 90.234 (88.395)	
2022-03-27 10:47:19,207: ============================================================
2022-03-27 10:48:59,202: time cost, forward:0.2801123499577845, backward:0.04230715684518204, data cost:0.6900657921337726 
2022-03-27 10:48:59,202: ============================================================
2022-03-27 10:48:59,202: Epoch 16/26 Batch 5300/7662 eta: 21:56:19.495360	Training Loss 0.5023 (0.5048)	Training Prec@1 84.180 (82.957)	Training Prec@5 89.062 (88.410)	
2022-03-27 10:48:59,202: ============================================================
2022-03-27 10:50:43,682: time cost, forward:0.2802089817724, backward:0.04233029352821538, data cost:0.6905534350445898 
2022-03-27 10:50:43,682: ============================================================
2022-03-27 10:50:43,683: Epoch 16/26 Batch 5400/7662 eta: 22:53:37.215697	Training Loss 0.5023 (0.5046)	Training Prec@1 82.422 (82.969)	Training Prec@5 87.891 (88.420)	
2022-03-27 10:50:43,683: ============================================================
2022-03-27 10:52:27,889: time cost, forward:0.28000195045041093, backward:0.04238118954540752, data cost:0.6912368179386498 
2022-03-27 10:52:27,889: ============================================================
2022-03-27 10:52:27,889: Epoch 16/26 Batch 5500/7662 eta: 22:48:17.213366	Training Loss 0.5021 (0.5045)	Training Prec@1 82.031 (82.985)	Training Prec@5 87.109 (88.433)	
2022-03-27 10:52:27,889: ============================================================
2022-03-27 10:54:11,433: time cost, forward:0.28005349267740554, backward:0.0423630801965816, data cost:0.6914331574038877 
2022-03-27 10:54:11,433: ============================================================
2022-03-27 10:54:11,433: Epoch 16/26 Batch 5600/7662 eta: 22:37:51.411017	Training Loss 0.4963 (0.5043)	Training Prec@1 84.375 (83.002)	Training Prec@5 89.844 (88.447)	
2022-03-27 10:54:11,433: ============================================================
2022-03-27 10:55:53,094: time cost, forward:0.27994285422179715, backward:0.042411117224049874, data cost:0.6916720154285849 
2022-03-27 10:55:53,094: ============================================================
2022-03-27 10:55:53,094: Epoch 16/26 Batch 5700/7662 eta: 22:11:28.313290	Training Loss 0.4876 (0.5042)	Training Prec@1 85.742 (83.024)	Training Prec@5 90.234 (88.462)	
2022-03-27 10:55:53,095: ============================================================
2022-03-27 10:57:36,699: time cost, forward:0.28018534900936964, backward:0.04247498080573795, data cost:0.691614358830933 
2022-03-27 10:57:36,700: ============================================================
2022-03-27 10:57:36,700: Epoch 16/26 Batch 5800/7662 eta: 22:35:12.728877	Training Loss 0.4996 (0.5041)	Training Prec@1 83.594 (83.039)	Training Prec@5 88.867 (88.473)	
2022-03-27 10:57:36,700: ============================================================
2022-03-27 10:59:17,645: time cost, forward:0.2800918825805581, backward:0.04252734417065784, data cost:0.6916908544086767 
2022-03-27 10:59:17,645: ============================================================
2022-03-27 10:59:17,646: Epoch 16/26 Batch 5900/7662 eta: 21:58:44.247233	Training Loss 0.4964 (0.5039)	Training Prec@1 83.789 (83.057)	Training Prec@5 89.844 (88.487)	
2022-03-27 10:59:17,646: ============================================================
2022-03-27 11:01:02,833: time cost, forward:0.28004584544538397, backward:0.042576630486311724, data cost:0.6921629151774955 
2022-03-27 11:01:02,834: ============================================================
2022-03-27 11:01:02,834: Epoch 16/26 Batch 6000/7662 eta: 22:52:24.833968	Training Loss 0.4948 (0.5038)	Training Prec@1 83.398 (83.079)	Training Prec@5 89.453 (88.506)	
2022-03-27 11:01:02,835: ============================================================
2022-03-27 11:02:43,406: time cost, forward:0.2800076032861527, backward:0.04258327735097785, data cost:0.6920511021264597 
2022-03-27 11:02:43,407: ============================================================
2022-03-27 11:02:43,408: Epoch 16/26 Batch 6100/7662 eta: 21:50:31.145133	Training Loss 0.4975 (0.5037)	Training Prec@1 85.352 (83.092)	Training Prec@5 88.281 (88.516)	
2022-03-27 11:02:43,408: ============================================================
2022-03-27 11:04:24,275: time cost, forward:0.27991634058286957, backward:0.04260275113542227, data cost:0.6921544275393042 
2022-03-27 11:04:24,276: ============================================================
2022-03-27 11:04:24,276: Epoch 16/26 Batch 6200/7662 eta: 21:52:40.991680	Training Loss 0.4922 (0.5035)	Training Prec@1 85.352 (83.109)	Training Prec@5 90.625 (88.530)	
2022-03-27 11:04:24,276: ============================================================
2022-03-27 11:06:07,054: time cost, forward:0.2798057541920658, backward:0.042650175011333995, data cost:0.6924029552552374 
2022-03-27 11:06:07,055: ============================================================
2022-03-27 11:06:07,056: Epoch 16/26 Batch 6300/7662 eta: 22:15:50.890936	Training Loss 0.4918 (0.5034)	Training Prec@1 83.984 (83.128)	Training Prec@5 89.453 (88.546)	
2022-03-27 11:06:07,056: ============================================================
2022-03-27 11:07:50,081: time cost, forward:0.27983535578668556, backward:0.04268105355328481, data cost:0.692473625984019 
2022-03-27 11:07:50,082: ============================================================
2022-03-27 11:07:50,082: Epoch 16/26 Batch 6400/7662 eta: 22:17:19.974493	Training Loss 0.4938 (0.5032)	Training Prec@1 85.352 (83.150)	Training Prec@5 90.820 (88.560)	
2022-03-27 11:07:50,082: ============================================================
2022-03-27 11:09:35,906: time cost, forward:0.27984812377434287, backward:0.0426989330257117, data cost:0.6931057911796705 
2022-03-27 11:09:35,907: ============================================================
2022-03-27 11:09:35,907: Epoch 16/26 Batch 6500/7662 eta: 22:51:53.908931	Training Loss 0.5117 (0.5031)	Training Prec@1 80.273 (83.167)	Training Prec@5 87.695 (88.576)	
2022-03-27 11:09:35,907: ============================================================
2022-03-27 11:11:21,390: time cost, forward:0.279880325150031, backward:0.04270862463586781, data cost:0.6936686090997429 
2022-03-27 11:11:21,390: ============================================================
2022-03-27 11:11:21,391: Epoch 16/26 Batch 6600/7662 eta: 22:45:42.713785	Training Loss 0.4880 (0.5029)	Training Prec@1 88.086 (83.179)	Training Prec@5 92.969 (88.582)	
2022-03-27 11:11:21,391: ============================================================
2022-03-27 11:13:07,254: time cost, forward:0.2799538606173032, backward:0.042703599427276306, data cost:0.6942984447815219 
2022-03-27 11:13:07,255: ============================================================
2022-03-27 11:13:07,255: Epoch 16/26 Batch 6700/7662 eta: 22:48:52.630514	Training Loss 0.4974 (0.5028)	Training Prec@1 85.156 (83.194)	Training Prec@5 91.211 (88.593)	
2022-03-27 11:13:07,255: ============================================================
2022-03-27 11:14:48,856: time cost, forward:0.2799749813775558, backward:0.04271068526008652, data cost:0.6942566713702593 
2022-03-27 11:14:48,857: ============================================================
2022-03-27 11:14:48,857: Epoch 16/26 Batch 6800/7662 eta: 21:52:04.342685	Training Loss 0.4776 (0.5027)	Training Prec@1 84.180 (83.214)	Training Prec@5 90.234 (88.609)	
2022-03-27 11:14:48,857: ============================================================
2022-03-27 11:16:34,012: time cost, forward:0.28002255801654136, backward:0.042728874714137124, data cost:0.6946248610065646 
2022-03-27 11:16:34,013: ============================================================
2022-03-27 11:16:34,014: Epoch 16/26 Batch 6900/7662 eta: 22:36:13.435279	Training Loss 0.4953 (0.5025)	Training Prec@1 83.008 (83.229)	Training Prec@5 88.672 (88.622)	
2022-03-27 11:16:34,014: ============================================================
2022-03-27 11:18:13,972: time cost, forward:0.2800309595712203, backward:0.04271610319009762, data cost:0.6943913974631155 
2022-03-27 11:18:13,973: ============================================================
2022-03-27 11:18:13,973: Epoch 16/26 Batch 7000/7662 eta: 21:27:31.609235	Training Loss 0.4890 (0.5024)	Training Prec@1 85.156 (83.242)	Training Prec@5 89.844 (88.633)	
2022-03-27 11:18:13,973: ============================================================
2022-03-27 11:19:57,953: time cost, forward:0.2801052966509458, backward:0.04273378766746752, data cost:0.6945602076710874 
2022-03-27 11:19:57,954: ============================================================
2022-03-27 11:19:57,955: Epoch 16/26 Batch 7100/7662 eta: 22:17:36.102722	Training Loss 0.4792 (0.5023)	Training Prec@1 86.523 (83.257)	Training Prec@5 90.820 (88.647)	
2022-03-27 11:19:57,955: ============================================================
2022-03-27 11:21:38,917: time cost, forward:0.2801812779722917, backward:0.042757627218527036, data cost:0.6944259027753179 
2022-03-27 11:21:38,918: ============================================================
2022-03-27 11:21:38,918: Epoch 16/26 Batch 7200/7662 eta: 21:37:05.734235	Training Loss 0.5016 (0.5022)	Training Prec@1 81.445 (83.270)	Training Prec@5 88.477 (88.657)	
2022-03-27 11:21:38,919: ============================================================
2022-03-27 11:23:22,328: time cost, forward:0.28007131887635295, backward:0.042798848164573175, data cost:0.6946395224194801 
2022-03-27 11:23:22,329: ============================================================
2022-03-27 11:23:22,329: Epoch 16/26 Batch 7300/7662 eta: 22:06:49.014949	Training Loss 0.4936 (0.5020)	Training Prec@1 85.742 (83.284)	Training Prec@5 90.820 (88.666)	
2022-03-27 11:23:22,330: ============================================================
2022-03-27 11:25:06,414: time cost, forward:0.2800219072201942, backward:0.04281644580138343, data cost:0.6949986006894906 
2022-03-27 11:25:06,415: ============================================================
2022-03-27 11:25:06,416: Epoch 16/26 Batch 7400/7662 eta: 22:13:44.389128	Training Loss 0.4818 (0.5019)	Training Prec@1 85.938 (83.296)	Training Prec@5 90.234 (88.676)	
2022-03-27 11:25:06,416: ============================================================
2022-03-27 11:26:47,583: time cost, forward:0.27998446791883247, backward:0.04278525522127519, data cost:0.6950829750793046 
2022-03-27 11:26:47,584: ============================================================
2022-03-27 11:26:47,584: Epoch 16/26 Batch 7500/7662 eta: 21:34:40.249771	Training Loss 0.4985 (0.5018)	Training Prec@1 83.594 (83.313)	Training Prec@5 90.625 (88.688)	
2022-03-27 11:26:47,584: ============================================================
2022-03-27 11:28:32,310: time cost, forward:0.28007188362892654, backward:0.04275547179568361, data cost:0.6954135905756639 
2022-03-27 11:28:32,310: ============================================================
2022-03-27 11:28:32,310: Epoch 16/26 Batch 7600/7662 eta: 22:18:27.256381	Training Loss 0.5000 (0.5017)	Training Prec@1 84.961 (83.326)	Training Prec@5 89.648 (88.698)	
2022-03-27 11:28:32,310: ============================================================
2022-03-27 11:29:39,345: Epoch: 16/26 eta: 22:17:21.278822	Training Loss 0.4989 (0.5016)	Training Prec@1 83.008 (83.338)	Training Prec@5 87.500 (88.707)
2022-03-27 11:29:39,346: ============================================================
2022-03-27 11:31:21,475: time cost, forward:0.2574224712872746, backward:0.03924115258033829, data cost:0.7243769433763292 
2022-03-27 11:31:21,476: ============================================================
2022-03-27 11:31:21,477: Epoch 17/26 Batch 100/7662 eta: 21:36:59.132473	Training Loss 0.4702 (0.4783)	Training Prec@1 86.914 (86.731)	Training Prec@5 91.016 (91.195)	
2022-03-27 11:31:21,477: ============================================================
2022-03-27 11:33:02,381: time cost, forward:0.2566067669259843, backward:0.0405100398327238, data cost:0.7171361554208113 
2022-03-27 11:33:02,381: ============================================================
2022-03-27 11:33:02,382: Epoch 17/26 Batch 200/7662 eta: 21:25:12.703133	Training Loss 0.4799 (0.4784)	Training Prec@1 87.305 (86.608)	Training Prec@5 90.820 (91.082)	
2022-03-27 11:33:02,382: ============================================================
2022-03-27 11:34:46,255: time cost, forward:0.2618528305487489, backward:0.041549717702195794, data cost:0.7195361561599782 
2022-03-27 11:34:46,255: ============================================================
2022-03-27 11:34:46,255: Epoch 17/26 Batch 300/7662 eta: 22:01:17.183930	Training Loss 0.4908 (0.4785)	Training Prec@1 86.523 (86.621)	Training Prec@5 91.797 (91.128)	
2022-03-27 11:34:46,255: ============================================================
2022-03-27 11:36:27,650: time cost, forward:0.26556809504229323, backward:0.042241952174289485, data cost:0.7125403958753237 
2022-03-27 11:36:27,651: ============================================================
2022-03-27 11:36:27,651: Epoch 17/26 Batch 400/7662 eta: 21:28:05.006746	Training Loss 0.4845 (0.4785)	Training Prec@1 84.180 (86.550)	Training Prec@5 90.039 (91.111)	
2022-03-27 11:36:27,651: ============================================================
2022-03-27 11:38:11,034: time cost, forward:0.26823054382461825, backward:0.04253342538653968, data cost:0.7113621082000121 
2022-03-27 11:38:11,035: ============================================================
2022-03-27 11:38:11,035: Epoch 17/26 Batch 500/7662 eta: 21:51:37.248841	Training Loss 0.4670 (0.4788)	Training Prec@1 89.062 (86.517)	Training Prec@5 91.797 (91.088)	
2022-03-27 11:38:11,036: ============================================================
2022-03-27 11:39:53,607: time cost, forward:0.26952839852971505, backward:0.04238279315585485, data cost:0.7113232298167997 
2022-03-27 11:39:53,607: ============================================================
2022-03-27 11:39:53,607: Epoch 17/26 Batch 600/7662 eta: 21:39:36.195978	Training Loss 0.4809 (0.4790)	Training Prec@1 86.914 (86.527)	Training Prec@5 91.016 (91.069)	
2022-03-27 11:39:53,607: ============================================================
2022-03-27 11:41:37,305: time cost, forward:0.26949498922869203, backward:0.042833782231517785, data cost:0.7116894916403447 
2022-03-27 11:41:37,306: ============================================================
2022-03-27 11:41:37,306: Epoch 17/26 Batch 700/7662 eta: 21:52:09.192079	Training Loss 0.4800 (0.4792)	Training Prec@1 85.156 (86.520)	Training Prec@5 89.453 (91.063)	
2022-03-27 11:41:37,306: ============================================================
2022-03-27 11:43:21,209: time cost, forward:0.2696047706508517, backward:0.042925967442079244, data cost:0.714099498505288 
2022-03-27 11:43:21,209: ============================================================
2022-03-27 11:43:21,209: Epoch 17/26 Batch 800/7662 eta: 21:53:00.539206	Training Loss 0.4814 (0.4791)	Training Prec@1 86.719 (86.521)	Training Prec@5 90.820 (91.071)	
2022-03-27 11:43:21,210: ============================================================
2022-03-27 11:45:03,766: time cost, forward:0.26886939100747115, backward:0.042878976520627436, data cost:0.7148039974810947 
2022-03-27 11:45:03,766: ============================================================
2022-03-27 11:45:03,767: Epoch 17/26 Batch 900/7662 eta: 21:34:17.245667	Training Loss 0.4746 (0.4791)	Training Prec@1 89.258 (86.510)	Training Prec@5 93.164 (91.076)	
2022-03-27 11:45:03,767: ============================================================
2022-03-27 11:46:46,949: time cost, forward:0.26946080029309094, backward:0.043105655723625236, data cost:0.7142295963890679 
2022-03-27 11:46:46,949: ============================================================
2022-03-27 11:46:46,949: Epoch 17/26 Batch 1000/7662 eta: 21:40:27.799782	Training Loss 0.4769 (0.4792)	Training Prec@1 88.477 (86.484)	Training Prec@5 92.383 (91.068)	
2022-03-27 11:46:46,949: ============================================================
2022-03-27 11:48:23,954: time cost, forward:0.26812119414526514, backward:0.04308061300352338, data cost:0.7107841434860577 
2022-03-27 11:48:23,955: ============================================================
2022-03-27 11:48:23,955: Epoch 17/26 Batch 1100/7662 eta: 20:20:59.509670	Training Loss 0.4785 (0.4792)	Training Prec@1 88.867 (86.504)	Training Prec@5 91.992 (91.083)	
2022-03-27 11:48:23,955: ============================================================
2022-03-27 11:50:08,388: time cost, forward:0.2692023753324482, backward:0.043366699640307454, data cost:0.7110664776904668 
2022-03-27 11:50:08,389: ============================================================
2022-03-27 11:50:08,389: Epoch 17/26 Batch 1200/7662 eta: 21:52:45.414041	Training Loss 0.4691 (0.4791)	Training Prec@1 88.867 (86.508)	Training Prec@5 92.773 (91.090)	
2022-03-27 11:50:08,389: ============================================================
2022-03-27 11:51:52,720: time cost, forward:0.27045311736913713, backward:0.043390758410153524, data cost:0.7114146677139083 
2022-03-27 11:51:52,720: ============================================================
2022-03-27 11:51:52,720: Epoch 17/26 Batch 1300/7662 eta: 21:49:43.328565	Training Loss 0.4677 (0.4791)	Training Prec@1 89.453 (86.512)	Training Prec@5 93.555 (91.085)	
2022-03-27 11:51:52,720: ============================================================
2022-03-27 11:53:34,550: time cost, forward:0.2704842424631289, backward:0.04335145953725797, data cost:0.7108913694985685 
2022-03-27 11:53:34,550: ============================================================
2022-03-27 11:53:34,550: Epoch 17/26 Batch 1400/7662 eta: 21:16:37.467664	Training Loss 0.4756 (0.4793)	Training Prec@1 86.914 (86.491)	Training Prec@5 90.820 (91.063)	
2022-03-27 11:53:34,550: ============================================================
2022-03-27 11:55:18,909: time cost, forward:0.27106543967849495, backward:0.04332120073406278, data cost:0.7115806750729531 
2022-03-27 11:55:18,909: ============================================================
2022-03-27 11:55:18,909: Epoch 17/26 Batch 1500/7662 eta: 21:46:35.562514	Training Loss 0.4910 (0.4793)	Training Prec@1 85.742 (86.475)	Training Prec@5 90.820 (91.054)	
2022-03-27 11:55:18,909: ============================================================
2022-03-27 11:57:04,144: time cost, forward:0.2715677220497823, backward:0.04339597671012568, data cost:0.7125613070637677 
2022-03-27 11:57:04,145: ============================================================
2022-03-27 11:57:04,145: Epoch 17/26 Batch 1600/7662 eta: 21:55:48.874595	Training Loss 0.4746 (0.4794)	Training Prec@1 87.891 (86.473)	Training Prec@5 92.969 (91.051)	
2022-03-27 11:57:04,145: ============================================================
2022-03-27 11:58:46,270: time cost, forward:0.27137228627286286, backward:0.0434447305913951, data cost:0.7123087196226608 
2022-03-27 11:58:46,271: ============================================================
2022-03-27 11:58:46,272: Epoch 17/26 Batch 1700/7662 eta: 21:15:14.148362	Training Loss 0.4712 (0.4794)	Training Prec@1 87.500 (86.469)	Training Prec@5 92.383 (91.049)	
2022-03-27 11:58:46,272: ============================================================
2022-03-27 12:00:26,309: time cost, forward:0.2713867392123839, backward:0.04344911532908297, data cost:0.7108104023554379 
2022-03-27 12:00:26,309: ============================================================
2022-03-27 12:00:26,309: Epoch 17/26 Batch 1800/7662 eta: 20:47:29.082778	Training Loss 0.4811 (0.4793)	Training Prec@1 84.180 (86.481)	Training Prec@5 89.648 (91.057)	
2022-03-27 12:00:26,309: ============================================================
2022-03-27 12:02:11,561: time cost, forward:0.2721647090068172, backward:0.04343881225385058, data cost:0.711521075486258 
2022-03-27 12:02:11,562: ============================================================
2022-03-27 12:02:11,562: Epoch 17/26 Batch 1900/7662 eta: 21:50:45.862374	Training Loss 0.4810 (0.4794)	Training Prec@1 89.062 (86.471)	Training Prec@5 93.555 (91.048)	
2022-03-27 12:02:11,562: ============================================================
2022-03-27 12:03:51,541: time cost, forward:0.2724374207691767, backward:0.04347035728614887, data cost:0.7095429663541258 
2022-03-27 12:03:51,541: ============================================================
2022-03-27 12:03:51,541: Epoch 17/26 Batch 2000/7662 eta: 20:43:25.862678	Training Loss 0.4744 (0.4794)	Training Prec@1 87.500 (86.470)	Training Prec@5 91.602 (91.050)	
2022-03-27 12:03:51,541: ============================================================
2022-03-27 12:05:35,099: time cost, forward:0.27350600859617946, backward:0.04337647621151151, data cost:0.7091353589321898 
2022-03-27 12:05:35,099: ============================================================
2022-03-27 12:05:35,099: Epoch 17/26 Batch 2100/7662 eta: 21:26:12.295564	Training Loss 0.4732 (0.4794)	Training Prec@1 87.109 (86.473)	Training Prec@5 90.820 (91.052)	
2022-03-27 12:05:35,099: ============================================================
2022-03-27 12:07:18,664: time cost, forward:0.27370994272097615, backward:0.043317546298038745, data cost:0.709301361120414 
2022-03-27 12:07:18,665: ============================================================
2022-03-27 12:07:18,665: Epoch 17/26 Batch 2200/7662 eta: 21:24:34.980423	Training Loss 0.4562 (0.4793)	Training Prec@1 90.234 (86.482)	Training Prec@5 93.945 (91.061)	
2022-03-27 12:07:18,666: ============================================================
2022-03-27 12:09:04,756: time cost, forward:0.27398244532982957, backward:0.04306083401683726, data cost:0.7108898405512295 
2022-03-27 12:09:04,757: ============================================================
2022-03-27 12:09:04,758: Epoch 17/26 Batch 2300/7662 eta: 21:54:08.935671	Training Loss 0.4870 (0.4794)	Training Prec@1 85.938 (86.475)	Training Prec@5 91.797 (91.057)	
2022-03-27 12:09:04,758: ============================================================
2022-03-27 12:10:48,416: time cost, forward:0.2743045387291918, backward:0.04296104368342614, data cost:0.7110299229274049 
2022-03-27 12:10:48,417: ============================================================
2022-03-27 12:10:48,417: Epoch 17/26 Batch 2400/7662 eta: 21:22:16.969473	Training Loss 0.4740 (0.4794)	Training Prec@1 86.133 (86.466)	Training Prec@5 89.844 (91.051)	
2022-03-27 12:10:48,417: ============================================================
2022-03-27 12:12:32,182: time cost, forward:0.2746440897754976, backward:0.042994855260219324, data cost:0.711122014513966 
2022-03-27 12:12:32,182: ============================================================
2022-03-27 12:12:32,182: Epoch 17/26 Batch 2500/7662 eta: 21:21:51.913030	Training Loss 0.4790 (0.4794)	Training Prec@1 86.328 (86.461)	Training Prec@5 91.016 (91.049)	
2022-03-27 12:12:32,183: ============================================================
2022-03-27 12:14:16,004: time cost, forward:0.27513018476362183, backward:0.04309813744198959, data cost:0.7108958692172712 
2022-03-27 12:14:16,004: ============================================================
2022-03-27 12:14:16,004: Epoch 17/26 Batch 2600/7662 eta: 21:20:49.944633	Training Loss 0.4664 (0.4794)	Training Prec@1 88.086 (86.467)	Training Prec@5 91.602 (91.054)	
2022-03-27 12:14:16,004: ============================================================
2022-03-27 12:16:01,915: time cost, forward:0.27530700421059473, backward:0.043075084421271614, data cost:0.7118401968200898 
2022-03-27 12:16:01,915: ============================================================
2022-03-27 12:16:01,915: Epoch 17/26 Batch 2700/7662 eta: 21:44:50.367042	Training Loss 0.4793 (0.4795)	Training Prec@1 85.352 (86.445)	Training Prec@5 90.039 (91.038)	
2022-03-27 12:16:01,915: ============================================================
2022-03-27 12:17:46,867: time cost, forward:0.275352236286748, backward:0.04309370910410116, data cost:0.7121793298731535 
2022-03-27 12:17:46,868: ============================================================
2022-03-27 12:17:46,869: Epoch 17/26 Batch 2800/7662 eta: 21:31:17.648986	Training Loss 0.4716 (0.4795)	Training Prec@1 86.914 (86.448)	Training Prec@5 92.188 (91.038)	
2022-03-27 12:17:46,869: ============================================================
2022-03-27 12:19:25,871: time cost, forward:0.2754442135849341, backward:0.043192245500504704, data cost:0.7107640938661804 
2022-03-27 12:19:25,871: ============================================================
2022-03-27 12:19:25,872: Epoch 17/26 Batch 2900/7662 eta: 20:16:26.056132	Training Loss 0.4760 (0.4795)	Training Prec@1 86.914 (86.440)	Training Prec@5 91.797 (91.040)	
2022-03-27 12:19:25,872: ============================================================
2022-03-27 12:21:12,861: time cost, forward:0.2756236438236065, backward:0.04313180390180211, data cost:0.7118341650872201 
2022-03-27 12:21:12,861: ============================================================
2022-03-27 12:21:12,862: Epoch 17/26 Batch 3000/7662 eta: 21:52:47.057707	Training Loss 0.4963 (0.4795)	Training Prec@1 86.328 (86.442)	Training Prec@5 91.211 (91.043)	
2022-03-27 12:21:12,862: ============================================================
2022-03-27 12:22:53,172: time cost, forward:0.27587951156699914, backward:0.043133035633940206, data cost:0.7108837971190323 
2022-03-27 12:22:53,172: ============================================================
2022-03-27 12:22:53,172: Epoch 17/26 Batch 3100/7662 eta: 20:29:09.548022	Training Loss 0.4805 (0.4794)	Training Prec@1 84.375 (86.436)	Training Prec@5 89.648 (91.035)	
2022-03-27 12:22:53,173: ============================================================
2022-03-27 12:24:36,322: time cost, forward:0.2756872683176587, backward:0.043137189931294145, data cost:0.7109529432485758 
2022-03-27 12:24:36,323: ============================================================
2022-03-27 12:24:36,323: Epoch 17/26 Batch 3200/7662 eta: 21:02:14.361289	Training Loss 0.4743 (0.4795)	Training Prec@1 86.719 (86.425)	Training Prec@5 91.797 (91.026)	
2022-03-27 12:24:36,324: ============================================================
2022-03-27 12:26:18,280: time cost, forward:0.2755413399424904, backward:0.04317654512549357, data cost:0.7108791617416331 
2022-03-27 12:26:18,280: ============================================================
2022-03-27 12:26:18,281: Epoch 17/26 Batch 3300/7662 eta: 20:45:56.076058	Training Loss 0.4944 (0.4795)	Training Prec@1 83.203 (86.411)	Training Prec@5 88.867 (91.014)	
2022-03-27 12:26:18,281: ============================================================
2022-03-27 12:28:02,700: time cost, forward:0.2758287792873579, backward:0.043218096693532194, data cost:0.7107141298488786 
2022-03-27 12:28:02,702: ============================================================
2022-03-27 12:28:02,702: Epoch 17/26 Batch 3400/7662 eta: 21:14:18.498089	Training Loss 0.4796 (0.4795)	Training Prec@1 86.523 (86.405)	Training Prec@5 90.430 (91.010)	
2022-03-27 12:28:02,703: ============================================================
2022-03-27 12:29:46,397: time cost, forward:0.2760299498369163, backward:0.04326482942084579, data cost:0.7107414312790584 
2022-03-27 12:29:46,397: ============================================================
2022-03-27 12:29:46,398: Epoch 17/26 Batch 3500/7662 eta: 21:03:43.116223	Training Loss 0.4891 (0.4795)	Training Prec@1 83.594 (86.401)	Training Prec@5 89.648 (91.013)	
2022-03-27 12:29:46,398: ============================================================
2022-03-27 12:31:26,710: time cost, forward:0.2760199316013651, backward:0.04329636190360902, data cost:0.7099696871107504 
2022-03-27 12:31:26,711: ============================================================
2022-03-27 12:31:26,711: Epoch 17/26 Batch 3600/7662 eta: 20:20:50.151807	Training Loss 0.4930 (0.4795)	Training Prec@1 82.422 (86.403)	Training Prec@5 89.844 (91.016)	
2022-03-27 12:31:26,712: ============================================================
2022-03-27 12:33:08,950: time cost, forward:0.2759981832171685, backward:0.043316668128606337, data cost:0.7097168563023939 
2022-03-27 12:33:08,950: ============================================================
2022-03-27 12:33:08,951: Epoch 17/26 Batch 3700/7662 eta: 20:42:33.853375	Training Loss 0.4655 (0.4795)	Training Prec@1 88.086 (86.398)	Training Prec@5 92.969 (91.011)	
2022-03-27 12:33:08,951: ============================================================
2022-03-27 12:34:56,318: time cost, forward:0.27611991687020554, backward:0.04334764695224024, data cost:0.7107338452847514 
2022-03-27 12:34:56,319: ============================================================
2022-03-27 12:34:56,319: Epoch 17/26 Batch 3800/7662 eta: 21:43:06.908961	Training Loss 0.4883 (0.4795)	Training Prec@1 84.375 (86.397)	Training Prec@5 89.648 (91.014)	
2022-03-27 12:34:56,320: ============================================================
2022-03-27 12:36:36,643: time cost, forward:0.2762057746364753, backward:0.043265962025910716, data cost:0.7102483349232895 
2022-03-27 12:36:36,643: ============================================================
2022-03-27 12:36:36,644: Epoch 17/26 Batch 3900/7662 eta: 20:15:56.917116	Training Loss 0.4801 (0.4795)	Training Prec@1 84.766 (86.398)	Training Prec@5 90.430 (91.017)	
2022-03-27 12:36:36,644: ============================================================
2022-03-27 12:38:16,754: time cost, forward:0.27584010608555765, backward:0.043303208698121036, data cost:0.7098553425730929 
2022-03-27 12:38:16,755: ============================================================
2022-03-27 12:38:16,755: Epoch 17/26 Batch 4000/7662 eta: 20:11:41.637403	Training Loss 0.4780 (0.4795)	Training Prec@1 87.109 (86.399)	Training Prec@5 91.406 (91.019)	
2022-03-27 12:38:16,755: ============================================================
2022-03-27 12:39:59,897: time cost, forward:0.2758043817439641, backward:0.04331878284967129, data cost:0.7099129266638847 
2022-03-27 12:39:59,898: ============================================================
2022-03-27 12:39:59,899: Epoch 17/26 Batch 4100/7662 eta: 20:46:41.272258	Training Loss 0.4652 (0.4795)	Training Prec@1 89.453 (86.404)	Training Prec@5 92.383 (91.027)	
2022-03-27 12:39:59,899: ============================================================
2022-03-27 12:41:43,658: time cost, forward:0.2758720610419408, backward:0.043332525649846354, data cost:0.7100098483418816 
2022-03-27 12:41:43,659: ============================================================
2022-03-27 12:41:43,659: Epoch 17/26 Batch 4200/7662 eta: 20:52:24.242317	Training Loss 0.4855 (0.4795)	Training Prec@1 86.328 (86.398)	Training Prec@5 91.406 (91.025)	
2022-03-27 12:41:43,660: ============================================================
2022-03-27 12:43:27,551: time cost, forward:0.2759469005223567, backward:0.043352801402132574, data cost:0.7099647832543496 
2022-03-27 12:43:27,552: ============================================================
2022-03-27 12:43:27,552: Epoch 17/26 Batch 4300/7662 eta: 20:52:16.245226	Training Loss 0.4857 (0.4795)	Training Prec@1 83.789 (86.400)	Training Prec@5 89.258 (91.027)	
2022-03-27 12:43:27,552: ============================================================
2022-03-27 12:45:16,291: time cost, forward:0.27639237179705217, backward:0.04338114037787977, data cost:0.7109987960671479 
2022-03-27 12:45:16,291: ============================================================
2022-03-27 12:45:16,291: Epoch 17/26 Batch 4400/7662 eta: 21:48:52.680804	Training Loss 0.4805 (0.4795)	Training Prec@1 84.961 (86.402)	Training Prec@5 91.406 (91.028)	
2022-03-27 12:45:16,291: ============================================================
2022-03-27 12:46:55,446: time cost, forward:0.2761956143575288, backward:0.04333352523264447, data cost:0.7103650567796024 
2022-03-27 12:46:55,446: ============================================================
2022-03-27 12:46:55,446: Epoch 17/26 Batch 4500/7662 eta: 19:51:51.381678	Training Loss 0.4721 (0.4794)	Training Prec@1 87.695 (86.400)	Training Prec@5 93.555 (91.030)	
2022-03-27 12:46:55,446: ============================================================
2022-03-27 12:48:36,505: time cost, forward:0.2761121866210022, backward:0.043327199295568164, data cost:0.7100114863860812 
2022-03-27 12:48:36,505: ============================================================
2022-03-27 12:48:36,506: Epoch 17/26 Batch 4600/7662 eta: 20:13:03.991735	Training Loss 0.4842 (0.4794)	Training Prec@1 85.547 (86.403)	Training Prec@5 89.258 (91.033)	
2022-03-27 12:48:36,506: ============================================================
2022-03-27 12:50:21,880: time cost, forward:0.2761278043378792, backward:0.043322171117681524, data cost:0.7105140183727445 
2022-03-27 12:50:21,880: ============================================================
2022-03-27 12:50:21,880: Epoch 17/26 Batch 4700/7662 eta: 21:03:06.530321	Training Loss 0.4883 (0.4794)	Training Prec@1 85.156 (86.404)	Training Prec@5 90.820 (91.034)	
2022-03-27 12:50:21,880: ============================================================
2022-03-27 12:52:07,280: time cost, forward:0.2763948776891366, backward:0.04330023439458619, data cost:0.7107324018953343 
2022-03-27 12:52:07,281: ============================================================
2022-03-27 12:52:07,282: Epoch 17/26 Batch 4800/7662 eta: 21:01:40.067295	Training Loss 0.4795 (0.4794)	Training Prec@1 85.352 (86.401)	Training Prec@5 91.016 (91.032)	
2022-03-27 12:52:07,282: ============================================================
2022-03-27 12:53:46,867: time cost, forward:0.2761423014017679, backward:0.04332794104578252, data cost:0.7100959369712373 
2022-03-27 12:53:46,868: ============================================================
2022-03-27 12:53:46,868: Epoch 17/26 Batch 4900/7662 eta: 19:50:24.779198	Training Loss 0.4823 (0.4794)	Training Prec@1 86.133 (86.401)	Training Prec@5 90.625 (91.032)	
2022-03-27 12:53:46,869: ============================================================
2022-03-27 12:55:30,629: time cost, forward:0.27622179842920486, backward:0.04335194860703708, data cost:0.7103293870634784 
2022-03-27 12:55:30,629: ============================================================
2022-03-27 12:55:30,629: Epoch 17/26 Batch 5000/7662 eta: 20:38:34.525730	Training Loss 0.4751 (0.4794)	Training Prec@1 85.352 (86.396)	Training Prec@5 90.430 (91.027)	
2022-03-27 12:55:30,629: ============================================================
2022-03-27 12:57:14,473: time cost, forward:0.2761931882743439, backward:0.043376795425908804, data cost:0.7104962725432673 
2022-03-27 12:57:14,474: ============================================================
2022-03-27 12:57:14,474: Epoch 17/26 Batch 5100/7662 eta: 20:37:50.944104	Training Loss 0.4677 (0.4794)	Training Prec@1 86.133 (86.394)	Training Prec@5 91.211 (91.029)	
2022-03-27 12:57:14,474: ============================================================
2022-03-27 12:58:57,540: time cost, forward:0.27613757600874184, backward:0.04343322974761006, data cost:0.7105029868400884 
2022-03-27 12:58:57,540: ============================================================
2022-03-27 12:58:57,541: Epoch 17/26 Batch 5200/7662 eta: 20:26:51.163582	Training Loss 0.4739 (0.4794)	Training Prec@1 87.695 (86.395)	Training Prec@5 92.188 (91.031)	
2022-03-27 12:58:57,541: ============================================================
2022-03-27 13:00:41,113: time cost, forward:0.27611692173567826, backward:0.04341197018354293, data cost:0.7105073320975864 
2022-03-27 13:00:41,113: ============================================================
2022-03-27 13:00:41,113: Epoch 17/26 Batch 5300/7662 eta: 20:31:09.071270	Training Loss 0.4818 (0.4793)	Training Prec@1 84.766 (86.398)	Training Prec@5 90.625 (91.033)	
2022-03-27 13:00:41,113: ============================================================
2022-03-27 13:02:22,710: time cost, forward:0.27623865497975597, backward:0.04340558256081109, data cost:0.7101488446809557 
2022-03-27 13:02:22,711: ============================================================
2022-03-27 13:02:22,711: Epoch 17/26 Batch 5400/7662 eta: 20:05:58.948434	Training Loss 0.4706 (0.4793)	Training Prec@1 90.430 (86.397)	Training Prec@5 92.383 (91.033)	
2022-03-27 13:02:22,711: ============================================================
2022-03-27 13:04:05,990: time cost, forward:0.27630373910895956, backward:0.04342002967505655, data cost:0.7102276886955438 
2022-03-27 13:04:05,990: ============================================================
2022-03-27 13:04:05,990: Epoch 17/26 Batch 5500/7662 eta: 20:24:13.239396	Training Loss 0.4796 (0.4793)	Training Prec@1 85.547 (86.401)	Training Prec@5 90.820 (91.035)	
2022-03-27 13:04:05,990: ============================================================
2022-03-27 13:05:50,439: time cost, forward:0.2764173538945875, backward:0.04342831643825558, data cost:0.7103508386596609 
2022-03-27 13:05:50,440: ============================================================
2022-03-27 13:05:50,440: Epoch 17/26 Batch 5600/7662 eta: 20:36:21.514795	Training Loss 0.4719 (0.4793)	Training Prec@1 87.500 (86.399)	Training Prec@5 91.406 (91.035)	
2022-03-27 13:05:50,441: ============================================================
2022-03-27 13:07:33,407: time cost, forward:0.27638837567001584, backward:0.043424301428593215, data cost:0.7103343152606627 
2022-03-27 13:07:33,408: ============================================================
2022-03-27 13:07:33,408: Epoch 17/26 Batch 5700/7662 eta: 20:17:05.625971	Training Loss 0.4658 (0.4793)	Training Prec@1 88.672 (86.399)	Training Prec@5 93.359 (91.034)	
2022-03-27 13:07:33,408: ============================================================
2022-03-27 13:09:19,680: time cost, forward:0.27661670769344304, backward:0.043350045897669165, data cost:0.7106616040677279 
2022-03-27 13:09:19,680: ============================================================
2022-03-27 13:09:19,680: Epoch 17/26 Batch 5800/7662 eta: 20:54:23.024032	Training Loss 0.4823 (0.4793)	Training Prec@1 86.719 (86.400)	Training Prec@5 89.453 (91.035)	
2022-03-27 13:09:19,680: ============================================================
2022-03-27 13:11:00,816: time cost, forward:0.2766569576984463, backward:0.043328628638656004, data cost:0.710338541846656 
2022-03-27 13:11:00,816: ============================================================
2022-03-27 13:11:00,817: Epoch 17/26 Batch 5900/7662 eta: 19:52:04.544445	Training Loss 0.4768 (0.4793)	Training Prec@1 85.352 (86.399)	Training Prec@5 89.844 (91.034)	
2022-03-27 13:11:00,817: ============================================================
2022-03-27 13:12:36,331: time cost, forward:0.2762425672731751, backward:0.04332731775212912, data cost:0.7095609959571992 
2022-03-27 13:12:36,331: ============================================================
2022-03-27 13:12:36,332: Epoch 17/26 Batch 6000/7662 eta: 18:44:14.202510	Training Loss 0.4863 (0.4793)	Training Prec@1 88.086 (86.400)	Training Prec@5 92.578 (91.035)	
2022-03-27 13:12:36,332: ============================================================
2022-03-27 13:14:18,413: time cost, forward:0.27607786688653735, backward:0.043358382875361506, data cost:0.7095534372650262 
2022-03-27 13:14:18,415: ============================================================
2022-03-27 13:14:18,415: Epoch 17/26 Batch 6100/7662 eta: 19:59:49.671942	Training Loss 0.4818 (0.4793)	Training Prec@1 85.938 (86.398)	Training Prec@5 90.430 (91.034)	
2022-03-27 13:14:18,415: ============================================================
2022-03-27 13:16:02,673: time cost, forward:0.27599181469687917, backward:0.04338173105517094, data cost:0.7098421741251139 
2022-03-27 13:16:02,674: ============================================================
2022-03-27 13:16:02,674: Epoch 17/26 Batch 6200/7662 eta: 20:23:40.396652	Training Loss 0.4731 (0.4793)	Training Prec@1 88.281 (86.399)	Training Prec@5 93.164 (91.035)	
2022-03-27 13:16:02,674: ============================================================
2022-03-27 13:17:45,886: time cost, forward:0.2759049526565244, backward:0.04342620095330054, data cost:0.7099260633229112 
2022-03-27 13:17:45,887: ============================================================
2022-03-27 13:17:45,888: Epoch 17/26 Batch 6300/7662 eta: 20:09:40.755292	Training Loss 0.4674 (0.4792)	Training Prec@1 86.133 (86.402)	Training Prec@5 91.602 (91.037)	
2022-03-27 13:17:45,888: ============================================================
2022-03-27 13:19:29,270: time cost, forward:0.2760213846190867, backward:0.04343890823373796, data cost:0.7098433519084112 
2022-03-27 13:19:29,271: ============================================================
2022-03-27 13:19:29,272: Epoch 17/26 Batch 6400/7662 eta: 20:09:57.263784	Training Loss 0.4742 (0.4792)	Training Prec@1 85.938 (86.401)	Training Prec@5 90.820 (91.038)	
2022-03-27 13:19:29,272: ============================================================
2022-03-27 13:21:11,974: time cost, forward:0.275899026518254, backward:0.04344997972428826, data cost:0.7099169974951474 
2022-03-27 13:21:11,974: ============================================================
2022-03-27 13:21:11,975: Epoch 17/26 Batch 6500/7662 eta: 20:00:16.360814	Training Loss 0.4648 (0.4792)	Training Prec@1 86.719 (86.407)	Training Prec@5 91.797 (91.043)	
2022-03-27 13:21:11,975: ============================================================
2022-03-27 13:22:53,210: time cost, forward:0.2758353843275643, backward:0.04342492899581833, data cost:0.7097604461539277 
2022-03-27 13:22:53,211: ============================================================
2022-03-27 13:22:53,211: Epoch 17/26 Batch 6600/7662 eta: 19:41:26.613023	Training Loss 0.4635 (0.4792)	Training Prec@1 89.062 (86.406)	Training Prec@5 94.141 (91.045)	
2022-03-27 13:22:53,211: ============================================================
2022-03-27 13:24:38,126: time cost, forward:0.27575258458438323, backward:0.04346463832949183, data cost:0.7100963406392684 
2022-03-27 13:24:38,127: ============================================================
2022-03-27 13:24:38,127: Epoch 17/26 Batch 6700/7662 eta: 20:22:38.711039	Training Loss 0.4810 (0.4792)	Training Prec@1 87.500 (86.404)	Training Prec@5 90.430 (91.045)	
2022-03-27 13:24:38,128: ============================================================
2022-03-27 13:26:23,539: time cost, forward:0.2757549647777146, backward:0.043469617394493475, data cost:0.7104310980963872 
2022-03-27 13:26:23,540: ============================================================
2022-03-27 13:26:23,540: Epoch 17/26 Batch 6800/7662 eta: 20:26:39.990977	Training Loss 0.4851 (0.4791)	Training Prec@1 88.477 (86.408)	Training Prec@5 92.578 (91.049)	
2022-03-27 13:26:23,540: ============================================================
2022-03-27 13:28:05,332: time cost, forward:0.27574976853208794, backward:0.04344412709927452, data cost:0.7103075604107713 
2022-03-27 13:28:05,333: ============================================================
2022-03-27 13:28:05,334: Epoch 17/26 Batch 6900/7662 eta: 19:42:51.594041	Training Loss 0.4703 (0.4791)	Training Prec@1 87.305 (86.409)	Training Prec@5 91.016 (91.049)	
2022-03-27 13:28:05,334: ============================================================
2022-03-27 13:29:51,456: time cost, forward:0.2759897847876649, backward:0.043314144975509894, data cost:0.7105243640348629 
2022-03-27 13:29:51,457: ============================================================
2022-03-27 13:29:51,457: Epoch 17/26 Batch 7000/7662 eta: 20:31:24.435554	Training Loss 0.4754 (0.4791)	Training Prec@1 84.570 (86.408)	Training Prec@5 90.625 (91.051)	
2022-03-27 13:29:51,458: ============================================================
2022-03-27 13:31:36,032: time cost, forward:0.27614200986729726, backward:0.04325732121519311, data cost:0.7107447982086298 
2022-03-27 13:31:36,032: ============================================================
2022-03-27 13:31:36,032: Epoch 17/26 Batch 7100/7662 eta: 20:11:41.641475	Training Loss 0.4847 (0.4791)	Training Prec@1 84.961 (86.412)	Training Prec@5 89.258 (91.055)	
2022-03-27 13:31:36,032: ============================================================
2022-03-27 13:33:18,505: time cost, forward:0.27608488894018934, backward:0.04326031307062021, data cost:0.7107354885903576 
2022-03-27 13:33:18,505: ============================================================
2022-03-27 13:33:18,505: Epoch 17/26 Batch 7200/7662 eta: 19:45:37.836646	Training Loss 0.4625 (0.4791)	Training Prec@1 87.891 (86.412)	Training Prec@5 92.383 (91.053)	
2022-03-27 13:33:18,506: ============================================================
2022-03-27 13:35:05,025: time cost, forward:0.27626445855583487, backward:0.04327711968866827, data cost:0.7110025002084573 
2022-03-27 13:35:05,026: ============================================================
2022-03-27 13:35:05,026: Epoch 17/26 Batch 7300/7662 eta: 20:30:41.387804	Training Loss 0.4724 (0.4790)	Training Prec@1 86.914 (86.416)	Training Prec@5 91.797 (91.055)	
2022-03-27 13:35:05,027: ============================================================
2022-03-27 13:36:47,282: time cost, forward:0.2762859160875304, backward:0.043213388600499586, data cost:0.7109336777625334 
2022-03-27 13:36:47,283: ============================================================
2022-03-27 13:36:47,283: Epoch 17/26 Batch 7400/7662 eta: 19:39:42.901234	Training Loss 0.4751 (0.4790)	Training Prec@1 86.133 (86.419)	Training Prec@5 90.430 (91.057)	
2022-03-27 13:36:47,283: ============================================================
2022-03-27 13:38:31,329: time cost, forward:0.276325883190065, backward:0.04322397980726247, data cost:0.7110335344568159 
2022-03-27 13:38:31,329: ============================================================
2022-03-27 13:38:31,329: Epoch 17/26 Batch 7500/7662 eta: 19:58:37.882035	Training Loss 0.4800 (0.4790)	Training Prec@1 85.547 (86.422)	Training Prec@5 91.016 (91.059)	
2022-03-27 13:38:31,329: ============================================================
2022-03-27 13:40:17,340: time cost, forward:0.2764158343340099, backward:0.04321621257798548, data cost:0.7113219077437469 
2022-03-27 13:40:17,340: ============================================================
2022-03-27 13:40:17,340: Epoch 17/26 Batch 7600/7662 eta: 20:19:30.070294	Training Loss 0.4762 (0.4789)	Training Prec@1 87.109 (86.422)	Training Prec@5 91.992 (91.061)	
2022-03-27 13:40:17,341: ============================================================
2022-03-27 13:41:23,641: Epoch: 17/26 eta: 20:18:23.283165	Training Loss 0.4725 (0.4789)	Training Prec@1 85.938 (86.422)	Training Prec@5 91.211 (91.061)
2022-03-27 13:41:23,641: ============================================================
2022-03-27 13:43:06,461: time cost, forward:0.26260720599781384, backward:0.037413560982906456, data cost:0.7328270709875858 
2022-03-27 13:43:06,462: ============================================================
2022-03-27 13:43:06,462: Epoch 18/26 Batch 100/7662 eta: 19:39:58.714628	Training Loss 0.4533 (0.4626)	Training Prec@1 90.625 (88.607)	Training Prec@5 95.117 (92.657)	
2022-03-27 13:43:06,463: ============================================================
2022-03-27 13:44:51,918: time cost, forward:0.26666284326332895, backward:0.03879054347474371, data cost:0.7351236223575458 
2022-03-27 13:44:51,919: ============================================================
2022-03-27 13:44:51,919: Epoch 18/26 Batch 200/7662 eta: 20:08:30.888478	Training Loss 0.4583 (0.4632)	Training Prec@1 90.039 (88.654)	Training Prec@5 93.750 (92.628)	
2022-03-27 13:44:51,919: ============================================================
2022-03-27 13:46:34,802: time cost, forward:0.27032504671792124, backward:0.04015394596750521, data cost:0.726816565695415 
2022-03-27 13:46:34,803: ============================================================
2022-03-27 13:46:34,803: Epoch 18/26 Batch 300/7662 eta: 19:37:19.003159	Training Loss 0.4661 (0.4636)	Training Prec@1 90.820 (88.652)	Training Prec@5 92.773 (92.666)	
2022-03-27 13:46:34,803: ============================================================
2022-03-27 13:48:20,643: time cost, forward:0.2713123790004797, backward:0.04119109569635606, data cost:0.7298755257350759 
2022-03-27 13:48:20,644: ============================================================
2022-03-27 13:48:20,644: Epoch 18/26 Batch 400/7662 eta: 20:09:23.612156	Training Loss 0.4567 (0.4639)	Training Prec@1 91.016 (88.546)	Training Prec@5 94.727 (92.615)	
2022-03-27 13:48:20,644: ============================================================
2022-03-27 13:50:05,487: time cost, forward:0.272842902219845, backward:0.042202819086506756, data cost:0.7294079225383445 
2022-03-27 13:50:05,488: ============================================================
2022-03-27 13:50:05,488: Epoch 18/26 Batch 500/7662 eta: 19:56:15.307618	Training Loss 0.4615 (0.4637)	Training Prec@1 87.305 (88.520)	Training Prec@5 91.797 (92.601)	
2022-03-27 13:50:05,489: ============================================================
2022-03-27 13:51:48,071: time cost, forward:0.27387587255945983, backward:0.04220467139166066, data cost:0.7251793605855391 
2022-03-27 13:51:48,072: ============================================================
2022-03-27 13:51:48,072: Epoch 18/26 Batch 600/7662 eta: 19:28:45.143038	Training Loss 0.4623 (0.4638)	Training Prec@1 87.305 (88.478)	Training Prec@5 92.773 (92.559)	
2022-03-27 13:51:48,072: ============================================================
2022-03-27 13:53:35,428: time cost, forward:0.27549983946891643, backward:0.042755992286365604, data cost:0.7270299903995149 
2022-03-27 13:53:35,431: ============================================================
2022-03-27 13:53:35,431: Epoch 18/26 Batch 700/7662 eta: 20:21:22.168233	Training Loss 0.4658 (0.4636)	Training Prec@1 90.234 (88.487)	Training Prec@5 93.945 (92.574)	
2022-03-27 13:53:35,431: ============================================================
2022-03-27 13:55:19,151: time cost, forward:0.2762578339391715, backward:0.043037381428800925, data cost:0.7253707630911816 
2022-03-27 13:55:19,151: ============================================================
2022-03-27 13:55:19,152: Epoch 18/26 Batch 800/7662 eta: 19:38:15.028656	Training Loss 0.4634 (0.4636)	Training Prec@1 88.281 (88.470)	Training Prec@5 91.602 (92.577)	
2022-03-27 13:55:19,152: ============================================================
2022-03-27 13:57:04,622: time cost, forward:0.27639898017993625, backward:0.043094042278370416, data cost:0.7261797827528634 
2022-03-27 13:57:04,622: ============================================================
2022-03-27 13:57:04,622: Epoch 18/26 Batch 900/7662 eta: 19:56:22.345108	Training Loss 0.4585 (0.4637)	Training Prec@1 88.281 (88.429)	Training Prec@5 93.164 (92.558)	
2022-03-27 13:57:04,622: ============================================================
2022-03-27 13:58:50,999: time cost, forward:0.2770626416077485, backward:0.04311017517570977, data cost:0.7265398621678472 
2022-03-27 13:58:51,000: ============================================================
2022-03-27 13:58:51,000: Epoch 18/26 Batch 1000/7662 eta: 20:04:53.062256	Training Loss 0.4574 (0.4639)	Training Prec@1 90.820 (88.409)	Training Prec@5 93.555 (92.533)	
2022-03-27 13:58:51,000: ============================================================
2022-03-27 14:00:37,315: time cost, forward:0.27847325270342976, backward:0.0430893199459003, data cost:0.7273044152298876 
2022-03-27 14:00:37,315: ============================================================
2022-03-27 14:00:37,315: Epoch 18/26 Batch 1100/7662 eta: 20:02:24.407361	Training Loss 0.4670 (0.4641)	Training Prec@1 87.891 (88.376)	Training Prec@5 92.578 (92.512)	
2022-03-27 14:00:37,315: ============================================================
2022-03-27 14:02:20,651: time cost, forward:0.27882995597514837, backward:0.04311797278836133, data cost:0.7256661666443788 
2022-03-27 14:02:20,651: ============================================================
2022-03-27 14:02:20,651: Epoch 18/26 Batch 1200/7662 eta: 19:26:59.626807	Training Loss 0.4688 (0.4642)	Training Prec@1 89.844 (88.361)	Training Prec@5 92.969 (92.499)	
2022-03-27 14:02:20,651: ============================================================
2022-03-27 14:04:04,262: time cost, forward:0.27864443769447617, backward:0.043104850117108566, data cost:0.7247564752254236 
2022-03-27 14:04:04,262: ============================================================
2022-03-27 14:04:04,262: Epoch 18/26 Batch 1300/7662 eta: 19:28:22.127978	Training Loss 0.4686 (0.4644)	Training Prec@1 87.891 (88.345)	Training Prec@5 91.797 (92.478)	
2022-03-27 14:04:04,262: ============================================================
2022-03-27 14:05:51,669: time cost, forward:0.2791534485861265, backward:0.043075029981230056, data cost:0.7257651940169209 
2022-03-27 14:05:51,670: ============================================================
2022-03-27 14:05:51,671: Epoch 18/26 Batch 1400/7662 eta: 20:09:23.952566	Training Loss 0.4632 (0.4646)	Training Prec@1 88.477 (88.324)	Training Prec@5 92.578 (92.458)	
2022-03-27 14:05:51,671: ============================================================
2022-03-27 14:07:34,235: time cost, forward:0.27913924389636224, backward:0.043176636686318715, data cost:0.7242016917948249 
2022-03-27 14:07:34,236: ============================================================
2022-03-27 14:07:34,236: Epoch 18/26 Batch 1500/7662 eta: 19:13:09.687840	Training Loss 0.4672 (0.4648)	Training Prec@1 88.086 (88.301)	Training Prec@5 93.555 (92.443)	
2022-03-27 14:07:34,236: ============================================================
2022-03-27 14:09:20,850: time cost, forward:0.2794968166375175, backward:0.0430893902483398, data cost:0.7256549739181586 
2022-03-27 14:09:20,850: ============================================================
2022-03-27 14:09:20,850: Epoch 18/26 Batch 1600/7662 eta: 19:56:54.209271	Training Loss 0.4636 (0.4648)	Training Prec@1 88.867 (88.290)	Training Prec@5 93.164 (92.436)	
2022-03-27 14:09:20,850: ============================================================
2022-03-27 14:11:05,573: time cost, forward:0.27955031619484527, backward:0.04316925202628456, data cost:0.7252660290222437 
2022-03-27 14:11:05,575: ============================================================
2022-03-27 14:11:05,575: Epoch 18/26 Batch 1700/7662 eta: 19:33:56.755327	Training Loss 0.4615 (0.4649)	Training Prec@1 86.914 (88.302)	Training Prec@5 91.602 (92.450)	
2022-03-27 14:11:05,575: ============================================================
2022-03-27 14:12:50,888: time cost, forward:0.27996749596969495, backward:0.04331226558271814, data cost:0.7250948809729211 
2022-03-27 14:12:50,889: ============================================================
2022-03-27 14:12:50,889: Epoch 18/26 Batch 1800/7662 eta: 19:38:47.786275	Training Loss 0.4688 (0.4649)	Training Prec@1 88.477 (88.306)	Training Prec@5 92.773 (92.452)	
2022-03-27 14:12:50,889: ============================================================
2022-03-27 14:14:36,004: time cost, forward:0.2800520218441899, backward:0.04325025944159871, data cost:0.7252428386009261 
2022-03-27 14:14:36,004: ============================================================
2022-03-27 14:14:36,005: Epoch 18/26 Batch 1900/7662 eta: 19:34:49.627121	Training Loss 0.4706 (0.4650)	Training Prec@1 88.281 (88.295)	Training Prec@5 91.016 (92.444)	
2022-03-27 14:14:36,005: ============================================================
2022-03-27 14:16:22,078: time cost, forward:0.28047839410904946, backward:0.04339164575974663, data cost:0.7249736701207736 
2022-03-27 14:16:22,078: ============================================================
2022-03-27 14:16:22,079: Epoch 18/26 Batch 2000/7662 eta: 19:43:46.324096	Training Loss 0.4689 (0.4651)	Training Prec@1 88.867 (88.289)	Training Prec@5 94.336 (92.441)	
2022-03-27 14:16:22,079: ============================================================
2022-03-27 14:18:08,984: time cost, forward:0.28098548020903075, backward:0.04349167861502303, data cost:0.725504081438927 
2022-03-27 14:18:08,984: ============================================================
2022-03-27 14:18:08,984: Epoch 18/26 Batch 2100/7662 eta: 19:51:15.607555	Training Loss 0.4695 (0.4652)	Training Prec@1 88.086 (88.277)	Training Prec@5 91.797 (92.435)	
2022-03-27 14:18:08,984: ============================================================
2022-03-27 14:19:55,512: time cost, forward:0.28201435511087275, backward:0.04348513905489212, data cost:0.7252097102716436 
2022-03-27 14:19:55,513: ============================================================
2022-03-27 14:19:55,513: Epoch 18/26 Batch 2200/7662 eta: 19:45:17.496819	Training Loss 0.4647 (0.4652)	Training Prec@1 88.672 (88.278)	Training Prec@5 91.992 (92.437)	
2022-03-27 14:19:55,513: ============================================================
2022-03-27 14:21:40,873: time cost, forward:0.2826088414393388, backward:0.04352694244268616, data cost:0.7246093549848692 
2022-03-27 14:21:40,874: ============================================================
2022-03-27 14:21:40,875: Epoch 18/26 Batch 2300/7662 eta: 19:30:33.360464	Training Loss 0.4616 (0.4652)	Training Prec@1 89.062 (88.270)	Training Prec@5 92.188 (92.424)	
2022-03-27 14:21:40,875: ============================================================
2022-03-27 14:23:27,261: time cost, forward:0.28302864921048265, backward:0.04358353352437371, data cost:0.7243924461935599 
2022-03-27 14:23:27,262: ============================================================
2022-03-27 14:23:27,263: Epoch 18/26 Batch 2400/7662 eta: 19:40:10.499796	Training Loss 0.4678 (0.4653)	Training Prec@1 88.086 (88.265)	Training Prec@5 92.773 (92.423)	
2022-03-27 14:23:27,263: ============================================================
2022-03-27 14:25:13,110: time cost, forward:0.2832824460694007, backward:0.043624048950482296, data cost:0.7247436071405796 
2022-03-27 14:25:13,111: ============================================================
2022-03-27 14:25:13,111: Epoch 18/26 Batch 2500/7662 eta: 19:32:25.641825	Training Loss 0.4624 (0.4653)	Training Prec@1 86.133 (88.255)	Training Prec@5 91.406 (92.421)	
2022-03-27 14:25:13,111: ============================================================
2022-03-27 14:26:59,545: time cost, forward:0.2841892304811261, backward:0.04362252722707516, data cost:0.7241663579621559 
2022-03-27 14:26:59,545: ============================================================
2022-03-27 14:26:59,545: Epoch 18/26 Batch 2600/7662 eta: 19:37:08.885662	Training Loss 0.4723 (0.4654)	Training Prec@1 87.500 (88.245)	Training Prec@5 91.406 (92.410)	
2022-03-27 14:26:59,545: ============================================================
2022-03-27 14:28:43,629: time cost, forward:0.284500889885907, backward:0.04368963026037566, data cost:0.7234945352009465 
2022-03-27 14:28:43,629: ============================================================
2022-03-27 14:28:43,629: Epoch 18/26 Batch 2700/7662 eta: 19:09:25.061234	Training Loss 0.4645 (0.4654)	Training Prec@1 87.305 (88.243)	Training Prec@5 90.820 (92.405)	
2022-03-27 14:28:43,629: ============================================================
2022-03-27 14:30:33,426: time cost, forward:0.2850383832310727, backward:0.043673463700796375, data cost:0.7245047761100069 
2022-03-27 14:30:33,427: ============================================================
2022-03-27 14:30:33,427: Epoch 18/26 Batch 2800/7662 eta: 20:10:41.093735	Training Loss 0.4620 (0.4655)	Training Prec@1 90.430 (88.232)	Training Prec@5 94.531 (92.398)	
2022-03-27 14:30:33,427: ============================================================
2022-03-27 14:32:19,735: time cost, forward:0.285055531925808, backward:0.04373164619401061, data cost:0.7248711441253209 
2022-03-27 14:32:19,735: ============================================================
2022-03-27 14:32:19,735: Epoch 18/26 Batch 2900/7662 eta: 19:30:26.076746	Training Loss 0.4705 (0.4655)	Training Prec@1 88.086 (88.229)	Training Prec@5 92.773 (92.392)	
2022-03-27 14:32:19,735: ============================================================
2022-03-27 14:34:05,227: time cost, forward:0.2852166747601679, backward:0.04366697625900833, data cost:0.7247662618979887 
2022-03-27 14:34:05,228: ============================================================
2022-03-27 14:34:05,228: Epoch 18/26 Batch 3000/7662 eta: 19:19:41.996737	Training Loss 0.4707 (0.4656)	Training Prec@1 84.570 (88.230)	Training Prec@5 89.844 (92.392)	
2022-03-27 14:34:05,228: ============================================================
2022-03-27 14:35:49,965: time cost, forward:0.2853868001505189, backward:0.043578620340101716, data cost:0.7245064758031204 
2022-03-27 14:35:49,966: ============================================================
2022-03-27 14:35:49,966: Epoch 18/26 Batch 3100/7662 eta: 19:09:39.242188	Training Loss 0.4555 (0.4656)	Training Prec@1 89.258 (88.224)	Training Prec@5 93.164 (92.389)	
2022-03-27 14:35:49,966: ============================================================
2022-03-27 14:37:38,805: time cost, forward:0.2855727645001139, backward:0.04366161004197937, data cost:0.7250295019999412 
2022-03-27 14:37:38,806: ============================================================
2022-03-27 14:37:38,807: Epoch 18/26 Batch 3200/7662 eta: 19:52:52.558833	Training Loss 0.4797 (0.4657)	Training Prec@1 85.938 (88.219)	Training Prec@5 89.453 (92.383)	
2022-03-27 14:37:38,807: ============================================================
2022-03-27 14:39:17,782: time cost, forward:0.2848059393919465, backward:0.0436629316018328, data cost:0.7240950583544382 
2022-03-27 14:39:17,783: ============================================================
2022-03-27 14:39:17,783: Epoch 18/26 Batch 3300/7662 eta: 18:03:06.833946	Training Loss 0.4626 (0.4657)	Training Prec@1 90.039 (88.211)	Training Prec@5 93.359 (92.377)	
2022-03-27 14:39:17,783: ============================================================
2022-03-27 14:41:04,430: time cost, forward:0.2851349408221827, backward:0.04370581419827763, data cost:0.724143066136898 
2022-03-27 14:41:04,431: ============================================================
2022-03-27 14:41:04,431: Epoch 18/26 Batch 3400/7662 eta: 19:25:17.382328	Training Loss 0.4619 (0.4658)	Training Prec@1 87.891 (88.208)	Training Prec@5 91.602 (92.372)	
2022-03-27 14:41:04,431: ============================================================
2022-03-27 14:42:46,937: time cost, forward:0.28487269610600935, backward:0.04376155787040316, data cost:0.7235048034593834 
2022-03-27 14:42:46,937: ============================================================
2022-03-27 14:42:46,938: Epoch 18/26 Batch 3500/7662 eta: 18:38:19.899951	Training Loss 0.4699 (0.4658)	Training Prec@1 84.766 (88.207)	Training Prec@5 90.039 (92.371)	
2022-03-27 14:42:46,938: ============================================================
2022-03-27 14:44:32,963: time cost, forward:0.2845558113904753, backward:0.043843210654379294, data cost:0.7239498829106286 
2022-03-27 14:44:32,963: ============================================================
2022-03-27 14:44:32,963: Epoch 18/26 Batch 3600/7662 eta: 19:14:57.482243	Training Loss 0.4793 (0.4659)	Training Prec@1 85.742 (88.199)	Training Prec@5 90.820 (92.367)	
2022-03-27 14:44:32,964: ============================================================
2022-03-27 14:46:19,061: time cost, forward:0.2847340343513499, backward:0.04390551651384612, data cost:0.7238884607048478 
2022-03-27 14:46:19,061: ============================================================
2022-03-27 14:46:19,061: Epoch 18/26 Batch 3700/7662 eta: 19:13:58.388207	Training Loss 0.4698 (0.4659)	Training Prec@1 89.258 (88.199)	Training Prec@5 92.773 (92.365)	
2022-03-27 14:46:19,061: ============================================================
2022-03-27 14:48:05,279: time cost, forward:0.2848113854642478, backward:0.043947485567049215, data cost:0.7240487756023724 
2022-03-27 14:48:05,280: ============================================================
2022-03-27 14:48:05,281: Epoch 18/26 Batch 3800/7662 eta: 19:13:31.436815	Training Loss 0.4644 (0.4659)	Training Prec@1 88.281 (88.190)	Training Prec@5 91.992 (92.358)	
2022-03-27 14:48:05,281: ============================================================
2022-03-27 14:49:53,776: time cost, forward:0.2849397474021354, backward:0.043978371843982275, data cost:0.724724257472357 
2022-03-27 14:49:53,776: ============================================================
2022-03-27 14:49:53,776: Epoch 18/26 Batch 3900/7662 eta: 19:36:26.168991	Training Loss 0.4533 (0.4659)	Training Prec@1 89.844 (88.186)	Training Prec@5 93.555 (92.354)	
2022-03-27 14:49:53,776: ============================================================
2022-03-27 14:51:38,761: time cost, forward:0.28504889110947706, backward:0.04402418379844442, data cost:0.724456653263486 
2022-03-27 14:51:38,761: ============================================================
2022-03-27 14:51:38,762: Epoch 18/26 Batch 4000/7662 eta: 18:56:37.485320	Training Loss 0.4681 (0.4660)	Training Prec@1 88.672 (88.176)	Training Prec@5 92.383 (92.345)	
2022-03-27 14:51:38,762: ============================================================
2022-03-27 14:53:24,698: time cost, forward:0.2852362367286133, backward:0.04402169572867891, data cost:0.7244249974032325 
2022-03-27 14:53:24,698: ============================================================
2022-03-27 14:53:24,698: Epoch 18/26 Batch 4100/7662 eta: 19:05:09.522362	Training Loss 0.4670 (0.4660)	Training Prec@1 87.109 (88.176)	Training Prec@5 91.211 (92.345)	
2022-03-27 14:53:24,699: ============================================================
2022-03-27 14:55:10,581: time cost, forward:0.28510639882706607, backward:0.04396531479107138, data cost:0.7247250072727263 
2022-03-27 14:55:10,582: ============================================================
2022-03-27 14:55:10,582: Epoch 18/26 Batch 4200/7662 eta: 19:02:48.997941	Training Loss 0.4658 (0.4660)	Training Prec@1 87.695 (88.173)	Training Prec@5 92.188 (92.340)	
2022-03-27 14:55:10,582: ============================================================
2022-03-27 14:56:58,864: time cost, forward:0.28505317658484053, backward:0.04393911200863008, data cost:0.7254896024183551 
2022-03-27 14:56:58,864: ============================================================
2022-03-27 14:56:58,865: Epoch 18/26 Batch 4300/7662 eta: 19:26:54.546644	Training Loss 0.4683 (0.4661)	Training Prec@1 89.453 (88.156)	Training Prec@5 94.531 (92.328)	
2022-03-27 14:56:58,865: ============================================================
2022-03-27 14:58:44,582: time cost, forward:0.28533868969611403, backward:0.04393372608331367, data cost:0.7251797739173315 
2022-03-27 14:58:44,583: ============================================================
2022-03-27 14:58:44,583: Epoch 18/26 Batch 4400/7662 eta: 18:57:30.732622	Training Loss 0.4770 (0.4661)	Training Prec@1 87.695 (88.156)	Training Prec@5 91.016 (92.327)	
2022-03-27 14:58:44,583: ============================================================
2022-03-27 15:00:33,634: time cost, forward:0.28589711318574607, backward:0.04395755059614688, data cost:0.7253770578116887 
2022-03-27 15:00:33,634: ============================================================
2022-03-27 15:00:33,634: Epoch 18/26 Batch 4500/7662 eta: 19:31:33.374271	Training Loss 0.4633 (0.4661)	Training Prec@1 89.258 (88.153)	Training Prec@5 93.359 (92.327)	
2022-03-27 15:00:33,634: ============================================================
2022-03-27 15:02:22,290: time cost, forward:0.2865998082431562, backward:0.04390658241532424, data cost:0.7253171988584913 
2022-03-27 15:02:22,291: ============================================================
2022-03-27 15:02:22,291: Epoch 18/26 Batch 4600/7662 eta: 19:25:30.222630	Training Loss 0.4700 (0.4662)	Training Prec@1 88.867 (88.152)	Training Prec@5 92.773 (92.323)	
2022-03-27 15:02:22,291: ============================================================
2022-03-27 15:04:10,754: time cost, forward:0.28700797196067784, backward:0.04390013514744218, data cost:0.7256638280227606 
2022-03-27 15:04:10,754: ============================================================
2022-03-27 15:04:10,754: Epoch 18/26 Batch 4700/7662 eta: 19:21:37.634172	Training Loss 0.4717 (0.4662)	Training Prec@1 86.914 (88.145)	Training Prec@5 92.188 (92.321)	
2022-03-27 15:04:10,755: ============================================================
2022-03-27 15:06:00,274: time cost, forward:0.2873830811682779, backward:0.04389904846522082, data cost:0.7259413152715767 
2022-03-27 15:06:00,274: ============================================================
2022-03-27 15:06:00,275: Epoch 18/26 Batch 4800/7662 eta: 19:31:07.157519	Training Loss 0.4653 (0.4662)	Training Prec@1 88.672 (88.138)	Training Prec@5 92.578 (92.314)	
2022-03-27 15:06:00,275: ============================================================
2022-03-27 15:07:49,385: time cost, forward:0.28741715752024827, backward:0.04375507510859374, data cost:0.7268726001298775 
2022-03-27 15:07:49,386: ============================================================
2022-03-27 15:07:49,386: Epoch 18/26 Batch 4900/7662 eta: 19:24:55.587043	Training Loss 0.4693 (0.4663)	Training Prec@1 85.352 (88.132)	Training Prec@5 91.016 (92.309)	
2022-03-27 15:07:49,386: ============================================================
2022-03-27 15:09:30,666: time cost, forward:0.28702917168631176, backward:0.04350336634366363, data cost:0.7265999285691641 
2022-03-27 15:09:30,666: ============================================================
2022-03-27 15:09:30,666: Epoch 18/26 Batch 5000/7662 eta: 17:59:37.792142	Training Loss 0.4649 (0.4663)	Training Prec@1 86.914 (88.130)	Training Prec@5 90.820 (92.305)	
2022-03-27 15:09:30,666: ============================================================
2022-03-27 15:11:19,275: time cost, forward:0.28699327230593763, backward:0.04351761813817433, data cost:0.7270628674681642 
2022-03-27 15:11:19,275: ============================================================
2022-03-27 15:11:19,275: Epoch 18/26 Batch 5100/7662 eta: 19:15:56.550797	Training Loss 0.4572 (0.4663)	Training Prec@1 90.430 (88.127)	Training Prec@5 94.531 (92.305)	
2022-03-27 15:11:19,275: ============================================================
2022-03-27 15:13:05,218: time cost, forward:0.2868571202556407, backward:0.043535401395110584, data cost:0.7272257965375516 
2022-03-27 15:13:05,219: ============================================================
2022-03-27 15:13:05,220: Epoch 18/26 Batch 5200/7662 eta: 18:45:49.004915	Training Loss 0.4578 (0.4664)	Training Prec@1 89.258 (88.123)	Training Prec@5 92.773 (92.304)	
2022-03-27 15:13:05,220: ============================================================
2022-03-27 15:14:51,104: time cost, forward:0.28670618119701435, backward:0.04358394480264509, data cost:0.727444597405518 
2022-03-27 15:14:51,105: ============================================================
2022-03-27 15:14:51,105: Epoch 18/26 Batch 5300/7662 eta: 18:43:25.595322	Training Loss 0.4800 (0.4664)	Training Prec@1 86.719 (88.120)	Training Prec@5 91.602 (92.300)	
2022-03-27 15:14:51,105: ============================================================
2022-03-27 15:16:39,313: time cost, forward:0.2864370898508014, backward:0.043602666847792834, data cost:0.7281625503123877 
2022-03-27 15:16:39,313: ============================================================
2022-03-27 15:16:39,313: Epoch 18/26 Batch 5400/7662 eta: 19:06:16.119682	Training Loss 0.4803 (0.4664)	Training Prec@1 88.477 (88.115)	Training Prec@5 93.164 (92.296)	
2022-03-27 15:16:39,313: ============================================================
2022-03-27 15:18:26,385: time cost, forward:0.2862677991682886, backward:0.04359764709410222, data cost:0.7284892011629622 
2022-03-27 15:18:26,385: ============================================================
2022-03-27 15:18:26,385: Epoch 18/26 Batch 5500/7662 eta: 18:52:26.900231	Training Loss 0.4782 (0.4664)	Training Prec@1 88.867 (88.114)	Training Prec@5 92.188 (92.294)	
2022-03-27 15:18:26,385: ============================================================
2022-03-27 15:20:13,761: time cost, forward:0.28643319508415777, backward:0.043616589786197736, data cost:0.7286197579658591 
2022-03-27 15:20:13,761: ============================================================
2022-03-27 15:20:13,761: Epoch 18/26 Batch 5600/7662 eta: 18:53:52.392725	Training Loss 0.4717 (0.4664)	Training Prec@1 88.477 (88.113)	Training Prec@5 93.164 (92.294)	
2022-03-27 15:20:13,761: ============================================================
2022-03-27 15:22:02,389: time cost, forward:0.2863808251782705, backward:0.043628763244703876, data cost:0.7290729322984022 
2022-03-27 15:22:02,390: ============================================================
2022-03-27 15:22:02,390: Epoch 18/26 Batch 5700/7662 eta: 19:05:17.491935	Training Loss 0.4694 (0.4665)	Training Prec@1 87.305 (88.106)	Training Prec@5 92.188 (92.289)	
2022-03-27 15:22:02,390: ============================================================
2022-03-27 15:23:48,013: time cost, forward:0.2863570655043895, backward:0.043645606901876306, data cost:0.7290954081266784 
2022-03-27 15:23:48,015: ============================================================
2022-03-27 15:23:48,015: Epoch 18/26 Batch 5800/7662 eta: 18:31:51.702183	Training Loss 0.4675 (0.4665)	Training Prec@1 88.281 (88.101)	Training Prec@5 92.578 (92.285)	
2022-03-27 15:23:48,016: ============================================================
2022-03-27 15:25:38,269: time cost, forward:0.2864566982590681, backward:0.043678647361583355, data cost:0.7295649703588905 
2022-03-27 15:25:38,270: ============================================================
2022-03-27 15:25:38,271: Epoch 18/26 Batch 5900/7662 eta: 19:18:46.061048	Training Loss 0.4692 (0.4665)	Training Prec@1 87.695 (88.097)	Training Prec@5 92.188 (92.283)	
2022-03-27 15:25:38,271: ============================================================
2022-03-27 15:27:23,964: time cost, forward:0.28650354003683687, backward:0.04370818755729613, data cost:0.7295540396939478 
2022-03-27 15:27:23,965: ============================================================
2022-03-27 15:27:23,965: Epoch 18/26 Batch 6000/7662 eta: 18:29:04.156855	Training Loss 0.4650 (0.4665)	Training Prec@1 88.477 (88.097)	Training Prec@5 94.141 (92.281)	
2022-03-27 15:27:23,965: ============================================================
2022-03-27 15:29:12,163: time cost, forward:0.28631029185319967, backward:0.04368011340447617, data cost:0.7301501266134237 
2022-03-27 15:29:12,164: ============================================================
2022-03-27 15:29:12,164: Epoch 18/26 Batch 6100/7662 eta: 18:53:32.497611	Training Loss 0.4743 (0.4666)	Training Prec@1 88.477 (88.092)	Training Prec@5 91.602 (92.279)	
2022-03-27 15:29:12,164: ============================================================
2022-03-27 15:30:58,241: time cost, forward:0.28617735762118446, backward:0.04365946000805784, data cost:0.730236847682583 
2022-03-27 15:30:58,242: ============================================================
2022-03-27 15:30:58,242: Epoch 18/26 Batch 6200/7662 eta: 18:29:33.624036	Training Loss 0.4724 (0.4666)	Training Prec@1 87.500 (88.087)	Training Prec@5 92.578 (92.276)	
2022-03-27 15:30:58,242: ============================================================
2022-03-27 15:32:43,313: time cost, forward:0.28607184467930363, backward:0.043654916437490913, data cost:0.7301756335659848 
2022-03-27 15:32:43,314: ============================================================
2022-03-27 15:32:43,314: Epoch 18/26 Batch 6300/7662 eta: 18:17:17.330860	Training Loss 0.4691 (0.4666)	Training Prec@1 85.742 (88.087)	Training Prec@5 91.016 (92.274)	
2022-03-27 15:32:43,315: ============================================================
2022-03-27 15:34:28,251: time cost, forward:0.2860384250845941, backward:0.04371455152028426, data cost:0.7300623203557177 
2022-03-27 15:34:28,251: ============================================================
2022-03-27 15:34:28,252: Epoch 18/26 Batch 6400/7662 eta: 18:14:07.677012	Training Loss 0.4708 (0.4666)	Training Prec@1 89.453 (88.082)	Training Prec@5 92.773 (92.272)	
2022-03-27 15:34:28,252: ============================================================
2022-03-27 15:36:14,667: time cost, forward:0.2858922738701697, backward:0.04373192225883403, data cost:0.730253772747335 
2022-03-27 15:36:14,667: ============================================================
2022-03-27 15:36:14,667: Epoch 18/26 Batch 6500/7662 eta: 18:27:46.015552	Training Loss 0.4603 (0.4666)	Training Prec@1 89.258 (88.077)	Training Prec@5 92.578 (92.268)	
2022-03-27 15:36:14,667: ============================================================
2022-03-27 15:38:03,535: time cost, forward:0.28576756379950824, backward:0.043775402681270066, data cost:0.7307405798051154 
2022-03-27 15:38:03,536: ============================================================
2022-03-27 15:38:03,536: Epoch 18/26 Batch 6600/7662 eta: 18:51:29.636187	Training Loss 0.4696 (0.4667)	Training Prec@1 87.695 (88.070)	Training Prec@5 92.383 (92.261)	
2022-03-27 15:38:03,536: ============================================================
2022-03-27 15:39:50,354: time cost, forward:0.28564209015551995, backward:0.043755325920138005, data cost:0.7310161857858383 
2022-03-27 15:39:50,355: ============================================================
2022-03-27 15:39:50,355: Epoch 18/26 Batch 6700/7662 eta: 18:28:24.268581	Training Loss 0.4657 (0.4667)	Training Prec@1 88.867 (88.064)	Training Prec@5 92.969 (92.256)	
2022-03-27 15:39:50,355: ============================================================
2022-03-27 15:41:39,049: time cost, forward:0.2856823345688726, backward:0.043748481604330224, data cost:0.7312619223246103 
2022-03-27 15:41:39,050: ============================================================
2022-03-27 15:41:39,050: Epoch 18/26 Batch 6800/7662 eta: 18:46:03.814224	Training Loss 0.4756 (0.4667)	Training Prec@1 87.305 (88.063)	Training Prec@5 93.555 (92.257)	
2022-03-27 15:41:39,050: ============================================================
2022-03-27 15:43:24,428: time cost, forward:0.2854931816914441, backward:0.04377007169954361, data cost:0.7314288479329054 
2022-03-27 15:43:24,429: ============================================================
2022-03-27 15:43:24,429: Epoch 18/26 Batch 6900/7662 eta: 18:09:57.169854	Training Loss 0.4710 (0.4667)	Training Prec@1 86.133 (88.059)	Training Prec@5 91.016 (92.255)	
2022-03-27 15:43:24,429: ============================================================
2022-03-27 15:45:09,302: time cost, forward:0.28534464526813463, backward:0.0437823827478916, data cost:0.731380275154577 
2022-03-27 15:45:09,303: ============================================================
2022-03-27 15:45:09,304: Epoch 18/26 Batch 7000/7662 eta: 18:02:59.509818	Training Loss 0.4798 (0.4668)	Training Prec@1 87.109 (88.057)	Training Prec@5 91.797 (92.253)	
2022-03-27 15:45:09,305: ============================================================
2022-03-27 15:46:58,360: time cost, forward:0.2850776305415627, backward:0.043805660370588806, data cost:0.7320370846759233 
2022-03-27 15:46:58,361: ============================================================
2022-03-27 15:46:58,361: Epoch 18/26 Batch 7100/7662 eta: 18:44:21.710428	Training Loss 0.4738 (0.4668)	Training Prec@1 86.914 (88.054)	Training Prec@5 91.602 (92.253)	
2022-03-27 15:46:58,361: ============================================================
2022-03-27 15:48:47,024: time cost, forward:0.2851540179927575, backward:0.04380129804079989, data cost:0.7323317831134545 
2022-03-27 15:48:47,024: ============================================================
2022-03-27 15:48:47,024: Epoch 18/26 Batch 7200/7662 eta: 18:38:29.223759	Training Loss 0.4761 (0.4668)	Training Prec@1 85.938 (88.053)	Training Prec@5 90.039 (92.251)	
2022-03-27 15:48:47,024: ============================================================
2022-03-27 15:50:35,398: time cost, forward:0.2850062930105418, backward:0.043805882708310005, data cost:0.7326885752358459 
2022-03-27 15:50:35,398: ============================================================
2022-03-27 15:50:35,398: Epoch 18/26 Batch 7300/7662 eta: 18:33:42.281779	Training Loss 0.4715 (0.4668)	Training Prec@1 87.695 (88.051)	Training Prec@5 92.188 (92.250)	
2022-03-27 15:50:35,398: ============================================================
2022-03-27 15:52:22,035: time cost, forward:0.2848190220808206, backward:0.04379594092401947, data cost:0.73304161717399 
2022-03-27 15:52:22,035: ============================================================
2022-03-27 15:52:22,035: Epoch 18/26 Batch 7400/7662 eta: 18:14:04.634777	Training Loss 0.4726 (0.4668)	Training Prec@1 87.500 (88.048)	Training Prec@5 91.992 (92.249)	
2022-03-27 15:52:22,035: ============================================================
2022-03-27 15:54:07,239: time cost, forward:0.2847455071519098, backward:0.043810448275834565, data cost:0.7329557774654785 
2022-03-27 15:54:07,240: ============================================================
2022-03-27 15:54:07,240: Epoch 18/26 Batch 7500/7662 eta: 17:57:37.751294	Training Loss 0.4660 (0.4668)	Training Prec@1 86.328 (88.046)	Training Prec@5 91.211 (92.248)	
2022-03-27 15:54:07,240: ============================================================
2022-03-27 15:55:51,179: time cost, forward:0.28465155608278464, backward:0.04379769610266793, data cost:0.7327237944020019 
2022-03-27 15:55:51,179: ============================================================
2022-03-27 15:55:51,179: Epoch 18/26 Batch 7600/7662 eta: 17:42:56.145114	Training Loss 0.4753 (0.4668)	Training Prec@1 88.672 (88.040)	Training Prec@5 91.211 (92.245)	
2022-03-27 15:55:51,179: ============================================================
2022-03-27 15:57:03,596: Epoch: 18/26 eta: 17:41:50.663324	Training Loss 0.4698 (0.4669)	Training Prec@1 87.109 (88.038)	Training Prec@5 91.992 (92.242)
2022-03-27 15:57:03,604: ============================================================
2022-03-27 15:58:49,678: time cost, forward:0.27823490807504364, backward:0.040192649822042445, data cost:0.7437961535020308 
2022-03-27 15:58:49,678: ============================================================
2022-03-27 15:58:49,678: Epoch 19/26 Batch 100/7662 eta: 17:58:14.866493	Training Loss 0.4545 (0.4541)	Training Prec@1 89.453 (89.802)	Training Prec@5 92.578 (93.531)	
2022-03-27 15:58:49,678: ============================================================
2022-03-27 16:00:32,697: time cost, forward:0.28045199264833076, backward:0.04189301615384356, data cost:0.7235205413109094 
2022-03-27 16:00:32,698: ============================================================
2022-03-27 16:00:32,698: Epoch 19/26 Batch 200/7662 eta: 17:29:02.002076	Training Loss 0.4550 (0.4534)	Training Prec@1 90.820 (89.829)	Training Prec@5 93.359 (93.508)	
2022-03-27 16:00:32,698: ============================================================
2022-03-27 16:02:20,864: time cost, forward:0.2798801249883645, backward:0.04272205056155406, data cost:0.734819827669839 
2022-03-27 16:02:20,865: ============================================================
2022-03-27 16:02:20,865: Epoch 19/26 Batch 300/7662 eta: 18:19:38.602046	Training Loss 0.4522 (0.4538)	Training Prec@1 88.281 (89.646)	Training Prec@5 91.992 (93.388)	
2022-03-27 16:02:20,865: ============================================================
2022-03-27 16:04:12,577: time cost, forward:0.28235997711506705, backward:0.043368518800663766, data cost:0.7467585279230486 
2022-03-27 16:04:12,578: ============================================================
2022-03-27 16:04:12,578: Epoch 19/26 Batch 400/7662 eta: 18:53:49.770111	Training Loss 0.4492 (0.4538)	Training Prec@1 90.430 (89.682)	Training Prec@5 93.359 (93.402)	
2022-03-27 16:04:12,578: ============================================================
2022-03-27 16:06:00,720: time cost, forward:0.28520228819761106, backward:0.04346490814117248, data cost:0.7444853137633605 
2022-03-27 16:06:00,720: ============================================================
2022-03-27 16:06:00,720: Epoch 19/26 Batch 500/7662 eta: 18:15:47.538456	Training Loss 0.4585 (0.4542)	Training Prec@1 90.039 (89.615)	Training Prec@5 93.945 (93.366)	
2022-03-27 16:06:00,721: ============================================================
2022-03-27 16:07:46,181: time cost, forward:0.28590063300475055, backward:0.043899676238555146, data cost:0.7395447335378554 
2022-03-27 16:07:46,182: ============================================================
2022-03-27 16:07:46,182: Epoch 19/26 Batch 600/7662 eta: 17:46:51.987596	Training Loss 0.4418 (0.4543)	Training Prec@1 91.992 (89.622)	Training Prec@5 94.336 (93.374)	
2022-03-27 16:07:46,183: ============================================================
2022-03-27 16:09:32,326: time cost, forward:0.2878756332124593, backward:0.043671283599133144, data cost:0.7377531944596887 
2022-03-27 16:09:32,326: ============================================================
2022-03-27 16:09:32,327: Epoch 19/26 Batch 700/7662 eta: 17:52:00.463148	Training Loss 0.4591 (0.4545)	Training Prec@1 88.281 (89.596)	Training Prec@5 92.188 (93.349)	
2022-03-27 16:09:32,327: ============================================================
2022-03-27 16:11:19,862: time cost, forward:0.28822956723772986, backward:0.04375500404491592, data cost:0.7377204441457278 
2022-03-27 16:11:19,863: ============================================================
2022-03-27 16:11:19,863: Epoch 19/26 Batch 800/7662 eta: 18:04:16.295668	Training Loss 0.4592 (0.4546)	Training Prec@1 89.844 (89.610)	Training Prec@5 92.773 (93.373)	
2022-03-27 16:11:19,863: ============================================================
2022-03-27 16:13:04,790: time cost, forward:0.28641178318868094, backward:0.04392711020948094, data cost:0.7367087184918736 
2022-03-27 16:13:04,791: ============================================================
2022-03-27 16:13:04,792: Epoch 19/26 Batch 900/7662 eta: 17:36:13.683531	Training Loss 0.4552 (0.4546)	Training Prec@1 90.234 (89.623)	Training Prec@5 93.164 (93.382)	
2022-03-27 16:13:04,792: ============================================================
2022-03-27 16:14:54,446: time cost, forward:0.2870132550820932, backward:0.043992194566163455, data cost:0.739573910429671 
2022-03-27 16:14:54,446: ============================================================
2022-03-27 16:14:54,446: Epoch 19/26 Batch 1000/7662 eta: 18:21:58.398596	Training Loss 0.4626 (0.4546)	Training Prec@1 89.648 (89.624)	Training Prec@5 92.578 (93.395)	
2022-03-27 16:14:54,446: ============================================================
2022-03-27 16:16:46,741: time cost, forward:0.2882308096534236, backward:0.04329616747952462, data cost:0.7430776384768429 
2022-03-27 16:16:46,741: ============================================================
2022-03-27 16:16:46,742: Epoch 19/26 Batch 1100/7662 eta: 18:46:38.380935	Training Loss 0.4618 (0.4547)	Training Prec@1 87.891 (89.627)	Training Prec@5 93.164 (93.398)	
2022-03-27 16:16:46,742: ============================================================
2022-03-27 16:18:33,010: time cost, forward:0.28793339574207755, backward:0.04344061476872105, data cost:0.7428440303977476 
2022-03-27 16:18:33,010: ============================================================
2022-03-27 16:18:33,010: Epoch 19/26 Batch 1200/7662 eta: 17:44:24.461046	Training Loss 0.4522 (0.4548)	Training Prec@1 89.062 (89.610)	Training Prec@5 92.969 (93.373)	
2022-03-27 16:18:33,011: ============================================================
2022-03-27 16:20:20,871: time cost, forward:0.28781327125749007, backward:0.04351699453211455, data cost:0.7425960501493905 
2022-03-27 16:20:20,871: ============================================================
2022-03-27 16:20:20,871: Epoch 19/26 Batch 1300/7662 eta: 17:58:33.272372	Training Loss 0.4612 (0.4549)	Training Prec@1 87.500 (89.608)	Training Prec@5 91.797 (93.376)	
2022-03-27 16:20:20,872: ============================================================
2022-03-27 16:22:12,464: time cost, forward:0.28802727255504246, backward:0.043488296122956564, data cost:0.7453279396395244 
2022-03-27 16:22:12,465: ============================================================
2022-03-27 16:22:12,465: Epoch 19/26 Batch 1400/7662 eta: 18:34:01.313436	Training Loss 0.4564 (0.4551)	Training Prec@1 89.648 (89.586)	Training Prec@5 94.141 (93.360)	
2022-03-27 16:22:12,465: ============================================================
2022-03-27 16:24:01,944: time cost, forward:0.2884047165006061, backward:0.04357591352914476, data cost:0.7461147791866941 
2022-03-27 16:24:01,945: ============================================================
2022-03-27 16:24:01,945: Epoch 19/26 Batch 1500/7662 eta: 18:11:05.798239	Training Loss 0.4663 (0.4552)	Training Prec@1 86.914 (89.574)	Training Prec@5 91.406 (93.355)	
2022-03-27 16:24:01,946: ============================================================
2022-03-27 16:25:52,047: time cost, forward:0.2893853054857761, backward:0.04356673421376642, data cost:0.7469480538681346 
2022-03-27 16:25:52,048: ============================================================
2022-03-27 16:25:52,048: Epoch 19/26 Batch 1600/7662 eta: 18:15:28.022337	Training Loss 0.4500 (0.4553)	Training Prec@1 90.430 (89.558)	Training Prec@5 93.359 (93.346)	
2022-03-27 16:25:52,048: ============================================================
2022-03-27 16:27:41,163: time cost, forward:0.2900887818249483, backward:0.043470380445169376, data cost:0.7469410574948387 
2022-03-27 16:27:41,164: ============================================================
2022-03-27 16:27:41,164: Epoch 19/26 Batch 1700/7662 eta: 18:03:49.972745	Training Loss 0.4511 (0.4554)	Training Prec@1 90.234 (89.534)	Training Prec@5 91.992 (93.334)	
2022-03-27 16:27:41,165: ============================================================
2022-03-27 16:29:29,775: time cost, forward:0.29064657875005906, backward:0.04342444795181249, data cost:0.7468115632702338 
2022-03-27 16:29:29,775: ============================================================
2022-03-27 16:29:29,775: Epoch 19/26 Batch 1800/7662 eta: 17:57:00.292239	Training Loss 0.4600 (0.4555)	Training Prec@1 90.625 (89.528)	Training Prec@5 92.578 (93.326)	
2022-03-27 16:29:29,775: ============================================================
2022-03-27 16:31:20,667: time cost, forward:0.29110544389520837, backward:0.04351176771130796, data cost:0.7477120957668358 
2022-03-27 16:31:20,667: ============================================================
2022-03-27 16:31:20,667: Epoch 19/26 Batch 1900/7662 eta: 18:17:46.656315	Training Loss 0.4600 (0.4556)	Training Prec@1 86.914 (89.514)	Training Prec@5 91.992 (93.311)	
2022-03-27 16:31:20,667: ============================================================
2022-03-27 16:33:09,627: time cost, forward:0.29149051926743097, backward:0.043455522498111236, data cost:0.7473232422905484 
2022-03-27 16:33:09,628: ============================================================
2022-03-27 16:33:09,628: Epoch 19/26 Batch 2000/7662 eta: 17:56:50.435631	Training Loss 0.4485 (0.4557)	Training Prec@1 91.016 (89.501)	Training Prec@5 94.141 (93.306)	
2022-03-27 16:33:09,628: ============================================================
2022-03-27 16:34:56,349: time cost, forward:0.291256468656121, backward:0.0434612806437412, data cost:0.747255399375941 
2022-03-27 16:34:56,349: ============================================================
2022-03-27 16:34:56,349: Epoch 19/26 Batch 2100/7662 eta: 17:32:55.744665	Training Loss 0.4618 (0.4558)	Training Prec@1 90.039 (89.495)	Training Prec@5 93.359 (93.301)	
2022-03-27 16:34:56,349: ============================================================
2022-03-27 16:36:44,810: time cost, forward:0.29106460727849515, backward:0.04357406170382289, data cost:0.7470489787534997 
2022-03-27 16:36:44,810: ============================================================
2022-03-27 16:36:44,810: Epoch 19/26 Batch 2200/7662 eta: 17:48:17.278166	Training Loss 0.4639 (0.4559)	Training Prec@1 89.258 (89.490)	Training Prec@5 92.578 (93.303)	
2022-03-27 16:36:44,811: ============================================================
2022-03-27 16:38:37,147: time cost, forward:0.2910627939225073, backward:0.04366781816320764, data cost:0.7487807071639331 
2022-03-27 16:38:37,147: ============================================================
2022-03-27 16:38:37,148: Epoch 19/26 Batch 2300/7662 eta: 18:24:35.557023	Training Loss 0.4593 (0.4560)	Training Prec@1 89.648 (89.481)	Training Prec@5 93.164 (93.296)	
2022-03-27 16:38:37,148: ============================================================
2022-03-27 16:40:23,583: time cost, forward:0.2903329012243884, backward:0.04378616864505337, data cost:0.7488706643604248 
2022-03-27 16:40:23,583: ============================================================
2022-03-27 16:40:23,583: Epoch 19/26 Batch 2400/7662 eta: 17:24:47.323822	Training Loss 0.4605 (0.4561)	Training Prec@1 90.625 (89.458)	Training Prec@5 94.531 (93.276)	
2022-03-27 16:40:23,583: ============================================================
2022-03-27 16:42:13,414: time cost, forward:0.2908386613617615, backward:0.04369345327623848, data cost:0.7490847006756194 
2022-03-27 16:42:13,415: ============================================================
2022-03-27 16:42:13,415: Epoch 19/26 Batch 2500/7662 eta: 17:56:17.812128	Training Loss 0.4571 (0.4562)	Training Prec@1 91.016 (89.458)	Training Prec@5 94.531 (93.277)	
2022-03-27 16:42:13,415: ============================================================
2022-03-27 16:44:02,596: time cost, forward:0.2909457059767027, backward:0.04377414456419231, data cost:0.7491722672019568 
2022-03-27 16:44:02,596: ============================================================
2022-03-27 16:44:02,596: Epoch 19/26 Batch 2600/7662 eta: 17:48:05.989340	Training Loss 0.4496 (0.4563)	Training Prec@1 88.477 (89.440)	Training Prec@5 93.750 (93.267)	
2022-03-27 16:44:02,596: ============================================================
2022-03-27 16:45:51,348: time cost, forward:0.29100383904829163, backward:0.0437849863850218, data cost:0.7490045280534279 
2022-03-27 16:45:51,349: ============================================================
2022-03-27 16:45:51,349: Epoch 19/26 Batch 2700/7662 eta: 17:42:06.019731	Training Loss 0.4592 (0.4564)	Training Prec@1 89.648 (89.424)	Training Prec@5 92.773 (93.259)	
2022-03-27 16:45:51,349: ============================================================
2022-03-27 16:47:38,161: time cost, forward:0.29093526865423214, backward:0.043850895846558706, data cost:0.7485371623221531 
2022-03-27 16:47:38,162: ============================================================
2022-03-27 16:47:38,162: Epoch 19/26 Batch 2800/7662 eta: 17:21:22.438524	Training Loss 0.4523 (0.4565)	Training Prec@1 90.039 (89.414)	Training Prec@5 91.992 (93.250)	
2022-03-27 16:47:38,162: ============================================================
2022-03-27 16:49:28,036: time cost, forward:0.2911165324767403, backward:0.04353935424933642, data cost:0.7492921568682046 
2022-03-27 16:49:28,037: ============================================================
2022-03-27 16:49:28,037: Epoch 19/26 Batch 2900/7662 eta: 17:49:23.515512	Training Loss 0.4548 (0.4566)	Training Prec@1 91.406 (89.401)	Training Prec@5 94.336 (93.241)	
2022-03-27 16:49:28,037: ============================================================
2022-03-27 16:51:20,521: time cost, forward:0.2915189322649379, backward:0.043458929058709676, data cost:0.7501519842519884 
2022-03-27 16:51:20,521: ============================================================
2022-03-27 16:51:20,522: Epoch 19/26 Batch 3000/7662 eta: 18:12:55.537171	Training Loss 0.4574 (0.4566)	Training Prec@1 90.820 (89.395)	Training Prec@5 94.141 (93.233)	
2022-03-27 16:51:20,522: ============================================================
2022-03-27 16:53:07,908: time cost, forward:0.2918733472630223, backward:0.04343508220018976, data cost:0.7495581118204241 
2022-03-27 16:53:07,909: ============================================================
2022-03-27 16:53:07,909: Epoch 19/26 Batch 3100/7662 eta: 17:21:36.056562	Training Loss 0.4577 (0.4567)	Training Prec@1 91.016 (89.394)	Training Prec@5 93.359 (93.230)	
2022-03-27 16:53:07,910: ============================================================
2022-03-27 16:54:56,053: time cost, forward:0.291705692809386, backward:0.04344306695681134, data cost:0.749658179454559 
2022-03-27 16:54:56,054: ============================================================
2022-03-27 16:54:56,054: Epoch 19/26 Batch 3200/7662 eta: 17:27:08.731368	Training Loss 0.4555 (0.4567)	Training Prec@1 87.891 (89.389)	Training Prec@5 93.164 (93.225)	
2022-03-27 16:54:56,054: ============================================================
2022-03-27 16:56:46,193: time cost, forward:0.29146437942710707, backward:0.0434342346324383, data cost:0.7502671811536573 
2022-03-27 16:56:46,194: ============================================================
2022-03-27 16:56:46,195: Epoch 19/26 Batch 3300/7662 eta: 17:44:38.263951	Training Loss 0.4585 (0.4568)	Training Prec@1 89.648 (89.381)	Training Prec@5 93.945 (93.220)	
2022-03-27 16:56:46,195: ============================================================
2022-03-27 16:58:33,838: time cost, forward:0.291590159063516, backward:0.04347391968862068, data cost:0.7497088151596756 
2022-03-27 16:58:33,838: ============================================================
2022-03-27 16:58:33,839: Epoch 19/26 Batch 3400/7662 eta: 17:18:42.798690	Training Loss 0.4554 (0.4569)	Training Prec@1 87.305 (89.371)	Training Prec@5 92.969 (93.213)	
2022-03-27 16:58:33,839: ============================================================
2022-03-27 17:00:22,845: time cost, forward:0.2915475379402006, backward:0.043486445861123026, data cost:0.75011955816155 
2022-03-27 17:00:22,845: ============================================================
2022-03-27 17:00:22,845: Epoch 19/26 Batch 3500/7662 eta: 17:30:02.562460	Training Loss 0.4567 (0.4569)	Training Prec@1 89.062 (89.361)	Training Prec@5 91.602 (93.206)	
2022-03-27 17:00:22,845: ============================================================
2022-03-27 17:02:10,827: time cost, forward:0.2917265081842862, backward:0.04344893575012767, data cost:0.7497709077674504 
2022-03-27 17:02:10,828: ============================================================
2022-03-27 17:02:10,829: Epoch 19/26 Batch 3600/7662 eta: 17:18:23.179471	Training Loss 0.4617 (0.4570)	Training Prec@1 87.695 (89.348)	Training Prec@5 92.578 (93.201)	
2022-03-27 17:02:10,829: ============================================================
2022-03-27 17:03:59,630: time cost, forward:0.2920295753231497, backward:0.04346206311310714, data cost:0.7495842985476504 
2022-03-27 17:03:59,631: ============================================================
2022-03-27 17:03:59,631: Epoch 19/26 Batch 3700/7662 eta: 17:24:26.696206	Training Loss 0.4451 (0.4571)	Training Prec@1 91.602 (89.335)	Training Prec@5 93.945 (93.190)	
2022-03-27 17:03:59,631: ============================================================
2022-03-27 17:05:46,730: time cost, forward:0.29183179744139065, backward:0.04351036684799897, data cost:0.749361561611785 
2022-03-27 17:05:46,730: ============================================================
2022-03-27 17:05:46,730: Epoch 19/26 Batch 3800/7662 eta: 17:06:19.108737	Training Loss 0.4609 (0.4572)	Training Prec@1 90.625 (89.328)	Training Prec@5 94.531 (93.184)	
2022-03-27 17:05:46,731: ============================================================
2022-03-27 17:07:34,947: time cost, forward:0.29188370099279265, backward:0.04357448086490323, data cost:0.7490024447410527 
2022-03-27 17:07:34,948: ============================================================
2022-03-27 17:07:34,948: Epoch 19/26 Batch 3900/7662 eta: 17:15:13.713819	Training Loss 0.4562 (0.4572)	Training Prec@1 88.477 (89.323)	Training Prec@5 92.578 (93.182)	
2022-03-27 17:07:34,949: ============================================================
2022-03-27 17:09:22,226: time cost, forward:0.29170889268967176, backward:0.04360810468482446, data cost:0.748989200854367 
2022-03-27 17:09:22,226: ============================================================
2022-03-27 17:09:22,226: Epoch 19/26 Batch 4000/7662 eta: 17:04:27.144986	Training Loss 0.4558 (0.4573)	Training Prec@1 90.234 (89.315)	Training Prec@5 93.750 (93.171)	
2022-03-27 17:09:22,226: ============================================================
2022-03-27 17:11:11,364: time cost, forward:0.29148176822117927, backward:0.04367538038245874, data cost:0.7492733084885019 
2022-03-27 17:11:11,364: ============================================================
2022-03-27 17:11:11,364: Epoch 19/26 Batch 4100/7662 eta: 17:20:23.758961	Training Loss 0.4500 (0.4573)	Training Prec@1 90.430 (89.309)	Training Prec@5 94.531 (93.166)	
2022-03-27 17:11:11,365: ============================================================
2022-03-27 17:12:58,483: time cost, forward:0.29126334695709294, backward:0.04367682274593345, data cost:0.7491391475611171 
2022-03-27 17:12:58,484: ============================================================
2022-03-27 17:12:58,484: Epoch 19/26 Batch 4200/7662 eta: 16:59:22.143796	Training Loss 0.4444 (0.4574)	Training Prec@1 91.016 (89.302)	Training Prec@5 95.508 (93.160)	
2022-03-27 17:12:58,484: ============================================================
2022-03-27 17:14:46,307: time cost, forward:0.29124527516601306, backward:0.04368255198847613, data cost:0.7490728939652692 
2022-03-27 17:14:46,308: ============================================================
2022-03-27 17:14:46,309: Epoch 19/26 Batch 4300/7662 eta: 17:04:16.586676	Training Loss 0.4555 (0.4574)	Training Prec@1 88.086 (89.296)	Training Prec@5 91.797 (93.155)	
2022-03-27 17:14:46,309: ============================================================
2022-03-27 17:16:35,398: time cost, forward:0.2912803822469917, backward:0.04375485973917481, data cost:0.7490756158856918 
2022-03-27 17:16:35,398: ============================================================
2022-03-27 17:16:35,398: Epoch 19/26 Batch 4400/7662 eta: 17:14:28.721292	Training Loss 0.4707 (0.4575)	Training Prec@1 88.672 (89.285)	Training Prec@5 92.578 (93.145)	
2022-03-27 17:16:35,398: ============================================================
2022-03-27 17:18:20,473: time cost, forward:0.291298831296142, backward:0.04377979420375548, data cost:0.7482882964131461 
2022-03-27 17:18:20,474: ============================================================
2022-03-27 17:18:20,474: Epoch 19/26 Batch 4500/7662 eta: 16:34:39.817594	Training Loss 0.4673 (0.4575)	Training Prec@1 86.328 (89.277)	Training Prec@5 91.211 (93.139)	
2022-03-27 17:18:20,474: ============================================================
2022-03-27 17:20:12,043: time cost, forward:0.2912758180021488, backward:0.0438091266567382, data cost:0.7488432955446387 
2022-03-27 17:20:12,044: ============================================================
2022-03-27 17:20:12,045: Epoch 19/26 Batch 4600/7662 eta: 17:34:17.363831	Training Loss 0.4505 (0.4576)	Training Prec@1 90.039 (89.268)	Training Prec@5 94.336 (93.134)	
2022-03-27 17:20:12,045: ============================================================
2022-03-27 17:21:59,931: time cost, forward:0.29131278329058946, backward:0.04382432960758668, data cost:0.7486630762655904 
2022-03-27 17:21:59,932: ============================================================
2022-03-27 17:21:59,932: Epoch 19/26 Batch 4700/7662 eta: 16:57:41.230357	Training Loss 0.4648 (0.4577)	Training Prec@1 87.305 (89.259)	Training Prec@5 91.797 (93.128)	
2022-03-27 17:21:59,933: ============================================================
2022-03-27 17:23:48,613: time cost, forward:0.2912040992338574, backward:0.043792113037649905, data cost:0.7488451957404552 
2022-03-27 17:23:48,615: ============================================================
2022-03-27 17:23:48,615: Epoch 19/26 Batch 4800/7662 eta: 17:03:22.426584	Training Loss 0.4574 (0.4577)	Training Prec@1 89.453 (89.254)	Training Prec@5 94.141 (93.123)	
2022-03-27 17:23:48,615: ============================================================
2022-03-27 17:25:37,300: time cost, forward:0.2910032180358644, backward:0.04387306617118553, data cost:0.7492076645434742 
2022-03-27 17:25:37,301: ============================================================
2022-03-27 17:25:37,301: Epoch 19/26 Batch 4900/7662 eta: 17:01:35.536719	Training Loss 0.4563 (0.4578)	Training Prec@1 92.188 (89.246)	Training Prec@5 95.117 (93.116)	
2022-03-27 17:25:37,301: ============================================================
2022-03-27 17:27:25,040: time cost, forward:0.29087108534606704, backward:0.04386901626541129, data cost:0.7491900786849874 
2022-03-27 17:27:25,040: ============================================================
2022-03-27 17:27:25,040: Epoch 19/26 Batch 5000/7662 eta: 16:50:53.987554	Training Loss 0.4699 (0.4578)	Training Prec@1 86.719 (89.237)	Training Prec@5 91.992 (93.110)	
2022-03-27 17:27:25,040: ============================================================
2022-03-27 17:29:13,333: time cost, forward:0.29081687844952175, backward:0.04386876657631473, data cost:0.749231677729608 
2022-03-27 17:29:13,334: ============================================================
2022-03-27 17:29:13,334: Epoch 19/26 Batch 5100/7662 eta: 16:54:17.843002	Training Loss 0.4626 (0.4579)	Training Prec@1 87.500 (89.234)	Training Prec@5 92.188 (93.108)	
2022-03-27 17:29:13,334: ============================================================
2022-03-27 17:31:01,640: time cost, forward:0.2906244229894346, backward:0.04383448830795508, data cost:0.7494141288756591 
2022-03-27 17:31:01,640: ============================================================
2022-03-27 17:31:01,641: Epoch 19/26 Batch 5200/7662 eta: 16:52:36.852025	Training Loss 0.4593 (0.4579)	Training Prec@1 89.062 (89.231)	Training Prec@5 94.531 (93.106)	
2022-03-27 17:31:01,641: ============================================================
2022-03-27 17:32:51,985: time cost, forward:0.2905645262499894, backward:0.04381087884112875, data cost:0.7498809688382384 
2022-03-27 17:32:51,985: ============================================================
2022-03-27 17:32:51,985: Epoch 19/26 Batch 5300/7662 eta: 17:09:49.462977	Training Loss 0.4594 (0.4580)	Training Prec@1 90.234 (89.225)	Training Prec@5 92.773 (93.100)	
2022-03-27 17:32:51,985: ============================================================
2022-03-27 17:34:40,701: time cost, forward:0.29057978793280415, backward:0.043825755673087205, data cost:0.7498794978008069 
2022-03-27 17:34:40,702: ============================================================
2022-03-27 17:34:40,703: Epoch 19/26 Batch 5400/7662 eta: 16:52:49.798437	Training Loss 0.4659 (0.4580)	Training Prec@1 88.281 (89.222)	Training Prec@5 91.992 (93.099)	
2022-03-27 17:34:40,703: ============================================================
2022-03-27 17:36:32,504: time cost, forward:0.2905418735392464, backward:0.04383649416762409, data cost:0.7505377256820409 
2022-03-27 17:36:32,504: ============================================================
2022-03-27 17:36:32,504: Epoch 19/26 Batch 5500/7662 eta: 17:19:42.083079	Training Loss 0.4558 (0.4580)	Training Prec@1 90.039 (89.220)	Training Prec@5 92.578 (93.096)	
2022-03-27 17:36:32,504: ============================================================
2022-03-27 17:38:15,038: time cost, forward:0.29034337177300457, backward:0.04381477656077436, data cost:0.749677115283836 
2022-03-27 17:38:15,039: ============================================================
2022-03-27 17:38:15,039: Epoch 19/26 Batch 5600/7662 eta: 15:51:48.814092	Training Loss 0.4588 (0.4581)	Training Prec@1 89.062 (89.212)	Training Prec@5 93.359 (93.089)	
2022-03-27 17:38:15,040: ============================================================
2022-03-27 17:40:04,724: time cost, forward:0.29058757232435756, backward:0.04381651421516982, data cost:0.7496578747775601 
2022-03-27 17:40:04,724: ============================================================
2022-03-27 17:40:04,724: Epoch 19/26 Batch 5700/7662 eta: 16:56:21.717083	Training Loss 0.4631 (0.4581)	Training Prec@1 88.086 (89.203)	Training Prec@5 92.773 (93.084)	
2022-03-27 17:40:04,724: ============================================================
2022-03-27 17:41:51,847: time cost, forward:0.2904851515964509, backward:0.04383057552198846, data cost:0.7494771087924085 
2022-03-27 17:41:51,847: ============================================================
2022-03-27 17:41:51,847: Epoch 19/26 Batch 5800/7662 eta: 16:30:50.059065	Training Loss 0.4481 (0.4582)	Training Prec@1 90.234 (89.197)	Training Prec@5 93.945 (93.080)	
2022-03-27 17:41:51,847: ============================================================
2022-03-27 17:43:41,830: time cost, forward:0.29043238133490135, backward:0.04384069463765748, data cost:0.7498216959637573 
2022-03-27 17:43:41,830: ============================================================
2022-03-27 17:43:41,830: Epoch 19/26 Batch 5900/7662 eta: 16:55:27.207777	Training Loss 0.4569 (0.4582)	Training Prec@1 89.258 (89.188)	Training Prec@5 92.773 (93.074)	
2022-03-27 17:43:41,830: ============================================================
2022-03-27 17:45:32,575: time cost, forward:0.29055078905172044, backward:0.04386915320415341, data cost:0.750006960797139 
2022-03-27 17:45:32,576: ============================================================
2022-03-27 17:45:32,576: Epoch 19/26 Batch 6000/7662 eta: 17:00:39.034503	Training Loss 0.4628 (0.4582)	Training Prec@1 89.062 (89.182)	Training Prec@5 94.531 (93.070)	
2022-03-27 17:45:32,576: ============================================================
2022-03-27 17:47:20,660: time cost, forward:0.29044988402031857, backward:0.043920164480426696, data cost:0.7500257239925762 
2022-03-27 17:47:20,660: ============================================================
2022-03-27 17:47:20,661: Epoch 19/26 Batch 6100/7662 eta: 16:34:19.494810	Training Loss 0.4631 (0.4583)	Training Prec@1 87.695 (89.178)	Training Prec@5 92.969 (93.067)	
2022-03-27 17:47:20,661: ============================================================
2022-03-27 17:49:10,484: time cost, forward:0.29038129319758504, backward:0.043891593244195386, data cost:0.7503613249527522 
2022-03-27 17:49:10,484: ============================================================
2022-03-27 17:49:10,484: Epoch 19/26 Batch 6200/7662 eta: 16:48:29.377297	Training Loss 0.4685 (0.4583)	Training Prec@1 88.281 (89.171)	Training Prec@5 93.750 (93.062)	
2022-03-27 17:49:10,484: ============================================================
2022-03-27 17:50:56,045: time cost, forward:0.2901865108975684, backward:0.04389291188890621, data cost:0.7500858678573994 
2022-03-27 17:50:56,045: ============================================================
2022-03-27 17:50:56,046: Epoch 19/26 Batch 6300/7662 eta: 16:07:35.714316	Training Loss 0.4617 (0.4584)	Training Prec@1 87.500 (89.164)	Training Prec@5 91.992 (93.058)	
2022-03-27 17:50:56,046: ============================================================
2022-03-27 17:52:47,066: time cost, forward:0.2902047258184224, backward:0.04380886039429856, data cost:0.7505557281856593 
2022-03-27 17:52:47,067: ============================================================
2022-03-27 17:52:47,067: Epoch 19/26 Batch 6400/7662 eta: 16:55:47.289808	Training Loss 0.4679 (0.4584)	Training Prec@1 88.086 (89.165)	Training Prec@5 91.992 (93.059)	
2022-03-27 17:52:47,067: ============================================================
2022-03-27 17:54:39,444: time cost, forward:0.29022892414010254, backward:0.04383641511665012, data cost:0.7510971388352397 
2022-03-27 17:54:39,445: ============================================================
2022-03-27 17:54:39,445: Epoch 19/26 Batch 6500/7662 eta: 17:06:19.882153	Training Loss 0.4552 (0.4584)	Training Prec@1 90.039 (89.161)	Training Prec@5 94.531 (93.056)	
2022-03-27 17:54:39,445: ============================================================
2022-03-27 17:56:27,124: time cost, forward:0.29016598471548904, backward:0.043824746330898265, data cost:0.7510384464827536 
2022-03-27 17:56:27,125: ============================================================
2022-03-27 17:56:27,125: Epoch 19/26 Batch 6600/7662 eta: 16:21:37.610444	Training Loss 0.4626 (0.4585)	Training Prec@1 89.844 (89.159)	Training Prec@5 93.555 (93.055)	
2022-03-27 17:56:27,125: ============================================================
2022-03-27 17:58:16,811: time cost, forward:0.29012948553105544, backward:0.043817151640934596, data cost:0.7512272402570752 
2022-03-27 17:58:16,811: ============================================================
2022-03-27 17:58:16,811: Epoch 19/26 Batch 6700/7662 eta: 16:38:05.592725	Training Loss 0.4553 (0.4585)	Training Prec@1 88.672 (89.154)	Training Prec@5 91.992 (93.053)	
2022-03-27 17:58:16,811: ============================================================
2022-03-27 18:00:05,467: time cost, forward:0.2901242173827909, backward:0.04380081323757472, data cost:0.751269348405147 
2022-03-27 18:00:05,468: ============================================================
2022-03-27 18:00:05,468: Epoch 19/26 Batch 6800/7662 eta: 16:26:54.654086	Training Loss 0.4629 (0.4585)	Training Prec@1 88.086 (89.149)	Training Prec@5 92.188 (93.048)	
2022-03-27 18:00:05,469: ============================================================
2022-03-27 18:01:58,067: time cost, forward:0.290415646356333, backward:0.04380674662149753, data cost:0.7515598795935458 
2022-03-27 18:01:58,068: ============================================================
2022-03-27 18:01:58,068: Epoch 19/26 Batch 6900/7662 eta: 17:00:50.992378	Training Loss 0.4517 (0.4585)	Training Prec@1 89.453 (89.142)	Training Prec@5 94.141 (93.044)	
2022-03-27 18:01:58,068: ============================================================
2022-03-27 18:03:46,545: time cost, forward:0.2905836359128422, backward:0.04378532433376974, data cost:0.7514011612243696 
2022-03-27 18:03:46,546: ============================================================
2022-03-27 18:03:46,546: Epoch 19/26 Batch 7000/7662 eta: 16:21:40.194114	Training Loss 0.4698 (0.4586)	Training Prec@1 87.891 (89.138)	Training Prec@5 91.992 (93.040)	
2022-03-27 18:03:46,546: ============================================================
2022-03-27 18:05:34,571: time cost, forward:0.2905830721701345, backward:0.0437832605101589, data cost:0.7513317285683612 
2022-03-27 18:05:34,571: ============================================================
2022-03-27 18:05:34,571: Epoch 19/26 Batch 7100/7662 eta: 16:15:46.402983	Training Loss 0.4701 (0.4586)	Training Prec@1 87.500 (89.135)	Training Prec@5 93.359 (93.037)	
2022-03-27 18:05:34,571: ============================================================
2022-03-27 18:07:21,609: time cost, forward:0.2904677984863209, backward:0.043773870730436516, data cost:0.7512159251822318 
2022-03-27 18:07:21,610: ============================================================
2022-03-27 18:07:21,610: Epoch 19/26 Batch 7200/7662 eta: 16:05:04.855991	Training Loss 0.4676 (0.4586)	Training Prec@1 87.305 (89.127)	Training Prec@5 92.188 (93.035)	
2022-03-27 18:07:21,610: ============================================================
2022-03-27 18:09:09,155: time cost, forward:0.2905813767364832, backward:0.04370455187238199, data cost:0.7510070736758724 
2022-03-27 18:09:09,156: ============================================================
2022-03-27 18:09:09,157: Epoch 19/26 Batch 7300/7662 eta: 16:07:51.840846	Training Loss 0.4656 (0.4587)	Training Prec@1 89.062 (89.124)	Training Prec@5 92.969 (93.035)	
2022-03-27 18:09:09,157: ============================================================
2022-03-27 18:10:54,528: time cost, forward:0.2904394572611547, backward:0.04362001556337709, data cost:0.7508446896361377 
2022-03-27 18:10:54,529: ============================================================
2022-03-27 18:10:54,529: Epoch 19/26 Batch 7400/7662 eta: 15:46:32.722050	Training Loss 0.4515 (0.4587)	Training Prec@1 88.672 (89.119)	Training Prec@5 91.016 (93.032)	
2022-03-27 18:10:54,529: ============================================================
2022-03-27 18:12:39,549: time cost, forward:0.29017779397589316, backward:0.043657144557191364, data cost:0.7505258548289939 
2022-03-27 18:12:39,550: ============================================================
2022-03-27 18:12:39,550: Epoch 19/26 Batch 7500/7662 eta: 15:41:38.180156	Training Loss 0.4550 (0.4587)	Training Prec@1 88.867 (89.115)	Training Prec@5 93.164 (93.029)	
2022-03-27 18:12:39,550: ============================================================
2022-03-27 18:14:24,290: time cost, forward:0.2901025333911561, backward:0.04368525097943996, data cost:0.7501521700070805 
2022-03-27 18:14:24,291: ============================================================
2022-03-27 18:14:24,291: Epoch 19/26 Batch 7600/7662 eta: 15:37:22.662588	Training Loss 0.4664 (0.4587)	Training Prec@1 87.109 (89.109)	Training Prec@5 91.406 (93.024)	
2022-03-27 18:14:24,291: ============================================================
2022-03-27 18:15:31,867: Epoch: 19/26 eta: 15:36:16.675889	Training Loss 0.4518 (0.4588)	Training Prec@1 91.016 (89.105)	Training Prec@5 94.727 (93.022)
2022-03-27 18:15:31,867: ============================================================
2022-03-27 18:17:18,483: time cost, forward:0.27760438967232753, backward:0.03753555904735218, data cost:0.7505272903827706 
2022-03-27 18:17:18,484: ============================================================
2022-03-27 18:17:18,484: Epoch 20/26 Batch 100/7662 eta: 15:48:31.574685	Training Loss 0.4275 (0.4431)	Training Prec@1 92.383 (90.724)	Training Prec@5 95.898 (94.210)	
2022-03-27 18:17:18,484: ============================================================
2022-03-27 18:19:03,577: time cost, forward:0.28405160879969, backward:0.039255462100158386, data cost:0.7362239840042651 
2022-03-27 18:19:03,577: ============================================================
2022-03-27 18:19:03,578: Epoch 20/26 Batch 200/7662 eta: 15:35:56.683771	Training Loss 0.4492 (0.4432)	Training Prec@1 89.453 (90.732)	Training Prec@5 93.750 (94.123)	
2022-03-27 18:19:03,578: ============================================================
2022-03-27 18:20:49,212: time cost, forward:0.2879656302091669, backward:0.04074030097910393, data cost:0.7295489678016076 
2022-03-27 18:20:49,213: ============================================================
2022-03-27 18:20:49,214: Epoch 20/26 Batch 300/7662 eta: 15:39:00.853869	Training Loss 0.4374 (0.4432)	Training Prec@1 91.406 (90.709)	Training Prec@5 94.531 (94.134)	
2022-03-27 18:20:49,214: ============================================================
2022-03-27 18:22:33,603: time cost, forward:0.2878612856518356, backward:0.04124344082404498, data cost:0.7239418663177872 
2022-03-27 18:22:33,604: ============================================================
2022-03-27 18:22:33,604: Epoch 20/26 Batch 400/7662 eta: 15:26:12.324342	Training Loss 0.4477 (0.4431)	Training Prec@1 92.383 (90.708)	Training Prec@5 95.117 (94.126)	
2022-03-27 18:22:33,604: ============================================================
2022-03-27 18:24:20,169: time cost, forward:0.2867649189217057, backward:0.0413038348387143, data cost:0.7287361096284671 
2022-03-27 18:24:20,170: ============================================================
2022-03-27 18:24:20,170: Epoch 20/26 Batch 500/7662 eta: 15:43:43.918709	Training Loss 0.4454 (0.4430)	Training Prec@1 89.844 (90.697)	Training Prec@5 94.336 (94.123)	
2022-03-27 18:24:20,170: ============================================================
2022-03-27 18:26:04,324: time cost, forward:0.2872060324393449, backward:0.0420112307362246, data cost:0.7248760762318148 
2022-03-27 18:26:04,324: ============================================================
2022-03-27 18:26:04,324: Epoch 20/26 Batch 600/7662 eta: 15:20:38.169642	Training Loss 0.4353 (0.4431)	Training Prec@1 91.602 (90.702)	Training Prec@5 94.141 (94.131)	
2022-03-27 18:26:04,324: ============================================================
2022-03-27 18:27:48,589: time cost, forward:0.286667771605463, backward:0.04244803461394085, data cost:0.7233648555984824 
2022-03-27 18:27:48,589: ============================================================
2022-03-27 18:27:48,589: Epoch 20/26 Batch 700/7662 eta: 15:19:52.561064	Training Loss 0.4519 (0.4432)	Training Prec@1 90.430 (90.709)	Training Prec@5 93.359 (94.127)	
2022-03-27 18:27:48,589: ============================================================
2022-03-27 18:29:35,159: time cost, forward:0.2878096172299343, backward:0.04268120674973584, data cost:0.7227036803774303 
2022-03-27 18:29:35,160: ============================================================
2022-03-27 18:29:35,161: Epoch 20/26 Batch 800/7662 eta: 15:38:27.018173	Training Loss 0.4424 (0.4432)	Training Prec@1 90.625 (90.717)	Training Prec@5 94.531 (94.139)	
2022-03-27 18:29:35,161: ============================================================
2022-03-27 18:31:22,685: time cost, forward:0.28824499955564503, backward:0.0428120822079057, data cost:0.7253495148477352 
2022-03-27 18:31:22,685: ============================================================
2022-03-27 18:31:22,686: Epoch 20/26 Batch 900/7662 eta: 15:45:03.253731	Training Loss 0.4499 (0.4431)	Training Prec@1 91.211 (90.716)	Training Prec@5 94.531 (94.138)	
2022-03-27 18:31:22,686: ============================================================
2022-03-27 18:33:04,990: time cost, forward:0.28850994549236736, backward:0.04280978924519307, data cost:0.7217004122557463 
2022-03-27 18:33:04,991: ============================================================
2022-03-27 18:33:04,991: Epoch 20/26 Batch 1000/7662 eta: 14:57:28.404818	Training Loss 0.4461 (0.4431)	Training Prec@1 90.625 (90.742)	Training Prec@5 94.141 (94.151)	
2022-03-27 18:33:04,991: ============================================================
2022-03-27 18:34:50,496: time cost, forward:0.28881694274777386, backward:0.04300961503123456, data cost:0.7206187107218082 
2022-03-27 18:34:50,497: ============================================================
2022-03-27 18:34:50,497: Epoch 20/26 Batch 1100/7662 eta: 15:23:47.802954	Training Loss 0.4353 (0.4431)	Training Prec@1 91.797 (90.766)	Training Prec@5 95.117 (94.168)	
2022-03-27 18:34:50,498: ============================================================
2022-03-27 18:36:33,186: time cost, forward:0.28911149412319004, backward:0.04325955584210291, data cost:0.718578068189963 
2022-03-27 18:36:33,188: ============================================================
2022-03-27 18:36:33,188: Epoch 20/26 Batch 1200/7662 eta: 14:57:25.919954	Training Loss 0.4559 (0.4430)	Training Prec@1 88.867 (90.774)	Training Prec@5 92.188 (94.183)	
2022-03-27 18:36:33,189: ============================================================
2022-03-27 18:38:18,081: time cost, forward:0.2890176883195344, backward:0.04356967274090985, data cost:0.7177775570573579 
2022-03-27 18:38:18,081: ============================================================
2022-03-27 18:38:18,082: Epoch 20/26 Batch 1300/7662 eta: 15:14:55.929422	Training Loss 0.4357 (0.4430)	Training Prec@1 92.188 (90.785)	Training Prec@5 95.117 (94.185)	
2022-03-27 18:38:18,082: ============================================================
2022-03-27 18:40:05,633: time cost, forward:0.28931439510833545, backward:0.04363059844179951, data cost:0.7195927457693562 
2022-03-27 18:40:05,633: ============================================================
2022-03-27 18:40:05,633: Epoch 20/26 Batch 1400/7662 eta: 15:36:19.575260	Training Loss 0.4332 (0.4430)	Training Prec@1 92.773 (90.792)	Training Prec@5 95.898 (94.186)	
2022-03-27 18:40:05,633: ============================================================
2022-03-27 18:41:49,134: time cost, forward:0.2891611275154404, backward:0.04350416560106233, data cost:0.7186412461365438 
2022-03-27 18:41:49,135: ============================================================
2022-03-27 18:41:49,136: Epoch 20/26 Batch 1500/7662 eta: 14:59:20.861222	Training Loss 0.4484 (0.4431)	Training Prec@1 90.625 (90.801)	Training Prec@5 94.922 (94.192)	
2022-03-27 18:41:49,136: ============================================================
2022-03-27 18:43:34,189: time cost, forward:0.2891385690952704, backward:0.04329610586613696, data cost:0.7188483299949603 
2022-03-27 18:43:34,189: ============================================================
2022-03-27 18:43:34,189: Epoch 20/26 Batch 1600/7662 eta: 15:11:04.768333	Training Loss 0.4504 (0.4430)	Training Prec@1 90.039 (90.827)	Training Prec@5 95.312 (94.203)	
2022-03-27 18:43:34,189: ============================================================
2022-03-27 18:45:22,920: time cost, forward:0.2892536216093695, backward:0.04327961246429857, data cost:0.7208113114647194 
2022-03-27 18:45:22,920: ============================================================
2022-03-27 18:45:22,920: Epoch 20/26 Batch 1700/7662 eta: 15:41:09.571121	Training Loss 0.4497 (0.4430)	Training Prec@1 87.891 (90.830)	Training Prec@5 92.383 (94.211)	
2022-03-27 18:45:22,921: ============================================================
2022-03-27 18:47:08,838: time cost, forward:0.28936154355997507, backward:0.043323525592577065, data cost:0.7206421892400448 
2022-03-27 18:47:08,839: ============================================================
2022-03-27 18:47:08,839: Epoch 20/26 Batch 1800/7662 eta: 15:15:03.112491	Training Loss 0.4417 (0.4429)	Training Prec@1 91.406 (90.834)	Training Prec@5 93.555 (94.209)	
2022-03-27 18:47:08,840: ============================================================
2022-03-27 18:48:55,398: time cost, forward:0.29006532219097825, backward:0.04341915784979444, data cost:0.7207819104759614 
2022-03-27 18:48:55,399: ============================================================
2022-03-27 18:48:55,399: Epoch 20/26 Batch 1900/7662 eta: 15:18:48.552997	Training Loss 0.4482 (0.4430)	Training Prec@1 90.820 (90.819)	Training Prec@5 94.141 (94.202)	
2022-03-27 18:48:55,399: ============================================================
2022-03-27 18:50:41,516: time cost, forward:0.2900962917848848, backward:0.043349313282740005, data cost:0.7211670391317485 
2022-03-27 18:50:41,516: ============================================================
2022-03-27 18:50:41,516: Epoch 20/26 Batch 2000/7662 eta: 15:13:13.752693	Training Loss 0.4545 (0.4429)	Training Prec@1 89.844 (90.822)	Training Prec@5 93.945 (94.204)	
2022-03-27 18:50:41,516: ============================================================
2022-03-27 18:52:29,153: time cost, forward:0.28997103460292806, backward:0.04329890327944308, data cost:0.7223378907731172 
2022-03-27 18:52:29,153: ============================================================
2022-03-27 18:52:29,153: Epoch 20/26 Batch 2100/7662 eta: 15:24:30.733645	Training Loss 0.4364 (0.4428)	Training Prec@1 90.625 (90.831)	Training Prec@5 94.727 (94.209)	
2022-03-27 18:52:29,153: ============================================================
2022-03-27 18:54:17,335: time cost, forward:0.2901692807864145, backward:0.04345016850293252, data cost:0.7228641486157066 
2022-03-27 18:54:17,337: ============================================================
2022-03-27 18:54:17,338: Epoch 20/26 Batch 2200/7662 eta: 15:27:24.527108	Training Loss 0.4359 (0.4428)	Training Prec@1 89.453 (90.832)	Training Prec@5 93.555 (94.210)	
2022-03-27 18:54:17,338: ============================================================
2022-03-27 18:56:05,514: time cost, forward:0.29066387763900725, backward:0.04352518774831539, data cost:0.7236856608455106 
2022-03-27 18:56:05,514: ============================================================
2022-03-27 18:56:05,514: Epoch 20/26 Batch 2300/7662 eta: 15:25:32.441811	Training Loss 0.4408 (0.4428)	Training Prec@1 90.430 (90.826)	Training Prec@5 92.773 (94.210)	
2022-03-27 18:56:05,514: ============================================================
2022-03-27 18:57:51,641: time cost, forward:0.29037009382705087, backward:0.04352595986004122, data cost:0.723737572172673 
2022-03-27 18:57:51,642: ============================================================
2022-03-27 18:57:51,643: Epoch 20/26 Batch 2400/7662 eta: 15:06:14.912903	Training Loss 0.4485 (0.4428)	Training Prec@1 89.844 (90.831)	Training Prec@5 93.359 (94.215)	
2022-03-27 18:57:51,643: ============================================================
2022-03-27 18:59:37,299: time cost, forward:0.2903331059749339, backward:0.043510381104040735, data cost:0.7240024098590547 
2022-03-27 18:59:37,299: ============================================================
2022-03-27 18:59:37,299: Epoch 20/26 Batch 2500/7662 eta: 15:00:27.420604	Training Loss 0.4565 (0.4429)	Training Prec@1 90.430 (90.820)	Training Prec@5 93.750 (94.210)	
2022-03-27 18:59:37,299: ============================================================
2022-03-27 19:01:27,759: time cost, forward:0.29099910614260255, backward:0.04349510410098949, data cost:0.7251625836193676 
2022-03-27 19:01:27,759: ============================================================
2022-03-27 19:01:27,759: Epoch 20/26 Batch 2600/7662 eta: 15:39:33.306527	Training Loss 0.4588 (0.4429)	Training Prec@1 89.258 (90.835)	Training Prec@5 93.164 (94.218)	
2022-03-27 19:01:27,759: ============================================================
2022-03-27 19:03:14,326: time cost, forward:0.2913171646991629, backward:0.04357963078284361, data cost:0.7249804828378085 
2022-03-27 19:03:14,327: ============================================================
2022-03-27 19:03:14,327: Epoch 20/26 Batch 2700/7662 eta: 15:04:40.313325	Training Loss 0.4499 (0.4428)	Training Prec@1 90.625 (90.834)	Training Prec@5 94.336 (94.217)	
2022-03-27 19:03:14,327: ============================================================
2022-03-27 19:05:01,418: time cost, forward:0.2912924661939593, backward:0.043538517848045834, data cost:0.7254613716715614 
2022-03-27 19:05:01,418: ============================================================
2022-03-27 19:05:01,418: Epoch 20/26 Batch 2800/7662 eta: 15:07:19.812790	Training Loss 0.4497 (0.4428)	Training Prec@1 89.062 (90.829)	Training Prec@5 94.531 (94.211)	
2022-03-27 19:05:01,418: ============================================================
2022-03-27 19:06:58,975: time cost, forward:0.2945740144801329, backward:0.043493495640486594, data cost:0.7261864323992695 
2022-03-27 19:06:58,975: ============================================================
2022-03-27 19:06:58,975: Epoch 20/26 Batch 2900/7662 eta: 16:34:02.604270	Training Loss 0.4420 (0.4428)	Training Prec@1 90.039 (90.829)	Training Prec@5 93.750 (94.213)	
2022-03-27 19:06:58,975: ============================================================
2022-03-27 19:08:50,020: time cost, forward:0.2963548808465126, backward:0.04347463622415968, data cost:0.725939515432782 
2022-03-27 19:08:50,021: ============================================================
2022-03-27 19:08:50,021: Epoch 20/26 Batch 3000/7662 eta: 15:37:07.892205	Training Loss 0.4323 (0.4428)	Training Prec@1 90.234 (90.829)	Training Prec@5 95.703 (94.212)	
2022-03-27 19:08:50,021: ============================================================
2022-03-27 19:10:38,260: time cost, forward:0.29745847588779467, backward:0.04343741868687814, data cost:0.7253588233004851 
2022-03-27 19:10:38,261: ============================================================
2022-03-27 19:10:38,261: Epoch 20/26 Batch 3100/7662 eta: 15:11:39.204610	Training Loss 0.4539 (0.4429)	Training Prec@1 90.430 (90.825)	Training Prec@5 93.555 (94.208)	
2022-03-27 19:10:38,261: ============================================================
2022-03-27 19:12:26,591: time cost, forward:0.2981056176561533, backward:0.04342901866933114, data cost:0.7250313044116063 
2022-03-27 19:12:26,591: ============================================================
2022-03-27 19:12:26,592: Epoch 20/26 Batch 3200/7662 eta: 15:10:36.487258	Training Loss 0.4433 (0.4429)	Training Prec@1 91.211 (90.835)	Training Prec@5 95.312 (94.213)	
2022-03-27 19:12:26,592: ============================================================
2022-03-27 19:14:12,087: time cost, forward:0.29878073188166576, backward:0.0434036034459452, data cost:0.7242447837044449 
2022-03-27 19:14:12,088: ============================================================
2022-03-27 19:14:12,088: Epoch 20/26 Batch 3300/7662 eta: 14:45:01.616480	Training Loss 0.4332 (0.4428)	Training Prec@1 90.820 (90.831)	Training Prec@5 94.336 (94.210)	
2022-03-27 19:14:12,088: ============================================================
2022-03-27 19:15:58,814: time cost, forward:0.2982936245653692, backward:0.043409628530010194, data cost:0.724636263130482 
2022-03-27 19:15:58,814: ============================================================
2022-03-27 19:15:58,814: Epoch 20/26 Batch 3400/7662 eta: 14:53:34.007947	Training Loss 0.4414 (0.4429)	Training Prec@1 92.188 (90.824)	Training Prec@5 94.531 (94.205)	
2022-03-27 19:15:58,814: ============================================================
2022-03-27 19:17:43,183: time cost, forward:0.29806965867189994, backward:0.04344115634753589, data cost:0.7242838072415657 
2022-03-27 19:17:43,183: ============================================================
2022-03-27 19:17:43,184: Epoch 20/26 Batch 3500/7662 eta: 14:32:05.512042	Training Loss 0.4444 (0.4429)	Training Prec@1 91.602 (90.821)	Training Prec@5 95.703 (94.203)	
2022-03-27 19:17:43,184: ============================================================
2022-03-27 19:19:30,072: time cost, forward:0.2981549683926204, backward:0.043499373170726, data cost:0.7241795555224979 
2022-03-27 19:19:30,073: ============================================================
2022-03-27 19:19:30,073: Epoch 20/26 Batch 3600/7662 eta: 14:51:22.161396	Training Loss 0.4316 (0.4429)	Training Prec@1 91.992 (90.826)	Training Prec@5 95.117 (94.207)	
2022-03-27 19:19:30,073: ============================================================
2022-03-27 19:21:16,581: time cost, forward:0.29844838608017027, backward:0.04357965690569479, data cost:0.7238059936584282 
2022-03-27 19:21:16,583: ============================================================
2022-03-27 19:21:16,583: Epoch 20/26 Batch 3700/7662 eta: 14:46:25.733493	Training Loss 0.4420 (0.4429)	Training Prec@1 89.062 (90.828)	Training Prec@5 93.164 (94.209)	
2022-03-27 19:21:16,583: ============================================================
2022-03-27 19:23:05,762: time cost, forward:0.2985760871910302, backward:0.043591004040530554, data cost:0.7242945916215254 
2022-03-27 19:23:05,763: ============================================================
2022-03-27 19:23:05,763: Epoch 20/26 Batch 3800/7662 eta: 15:06:49.719009	Training Loss 0.4387 (0.4429)	Training Prec@1 91.016 (90.824)	Training Prec@5 92.969 (94.205)	
2022-03-27 19:23:05,763: ============================================================
2022-03-27 19:24:53,406: time cost, forward:0.2986738468384431, backward:0.04358803409587178, data cost:0.7243852173251719 
2022-03-27 19:24:53,407: ============================================================
2022-03-27 19:24:53,407: Epoch 20/26 Batch 3900/7662 eta: 14:52:16.751846	Training Loss 0.4329 (0.4429)	Training Prec@1 92.383 (90.824)	Training Prec@5 95.117 (94.208)	
2022-03-27 19:24:53,407: ============================================================
2022-03-27 19:26:41,200: time cost, forward:0.29865207604152855, backward:0.043570490353224904, data cost:0.7248084956510391 
2022-03-27 19:26:41,201: ============================================================
2022-03-27 19:26:41,201: Epoch 20/26 Batch 4000/7662 eta: 14:51:43.531975	Training Loss 0.4346 (0.4429)	Training Prec@1 91.016 (90.825)	Training Prec@5 93.945 (94.210)	
2022-03-27 19:26:41,201: ============================================================
2022-03-27 19:28:28,697: time cost, forward:0.2989860375528366, backward:0.04362842826675746, data cost:0.7245518312596146 
2022-03-27 19:28:28,698: ============================================================
2022-03-27 19:28:28,698: Epoch 20/26 Batch 4100/7662 eta: 14:47:28.699761	Training Loss 0.4476 (0.4429)	Training Prec@1 89.258 (90.829)	Training Prec@5 92.188 (94.211)	
2022-03-27 19:28:28,698: ============================================================
2022-03-27 19:30:17,765: time cost, forward:0.29909946232019197, backward:0.04364379612313307, data cost:0.7250043109758436 
2022-03-27 19:30:17,765: ============================================================
2022-03-27 19:30:17,765: Epoch 20/26 Batch 4200/7662 eta: 14:58:37.446196	Training Loss 0.4340 (0.4429)	Training Prec@1 92.383 (90.826)	Training Prec@5 94.336 (94.207)	
2022-03-27 19:30:17,765: ============================================================
2022-03-27 19:32:08,217: time cost, forward:0.299246158065228, backward:0.04367346252278135, data cost:0.725518851980106 
2022-03-27 19:32:08,218: ============================================================
2022-03-27 19:32:08,218: Epoch 20/26 Batch 4300/7662 eta: 15:08:11.918421	Training Loss 0.4456 (0.4429)	Training Prec@1 91.992 (90.829)	Training Prec@5 95.117 (94.207)	
2022-03-27 19:32:08,218: ============================================================
2022-03-27 19:33:56,620: time cost, forward:0.29907072162216264, backward:0.04370157549017585, data cost:0.7261694662406732 
2022-03-27 19:33:56,621: ============================================================
2022-03-27 19:33:56,621: Epoch 20/26 Batch 4400/7662 eta: 14:49:32.182126	Training Loss 0.4439 (0.4429)	Training Prec@1 91.016 (90.826)	Training Prec@5 94.922 (94.204)	
2022-03-27 19:33:56,621: ============================================================
2022-03-27 19:35:42,267: time cost, forward:0.299180112009076, backward:0.043762992291642336, data cost:0.7255923456551102 
2022-03-27 19:35:42,267: ============================================================
2022-03-27 19:35:42,268: Epoch 20/26 Batch 4500/7662 eta: 14:25:09.379714	Training Loss 0.4367 (0.4430)	Training Prec@1 91.797 (90.829)	Training Prec@5 95.508 (94.210)	
2022-03-27 19:35:42,268: ============================================================
2022-03-27 19:37:37,036: time cost, forward:0.2996518891333082, backward:0.04374701729492665, data cost:0.7269219668384842 
2022-03-27 19:37:37,063: ============================================================
2022-03-27 19:37:37,063: Epoch 20/26 Batch 4600/7662 eta: 15:38:09.995423	Training Loss 0.4433 (0.4430)	Training Prec@1 91.211 (90.828)	Training Prec@5 94.531 (94.210)	
2022-03-27 19:37:37,063: ============================================================
2022-03-27 19:39:29,363: time cost, forward:0.30028037046670764, backward:0.04375438655683603, data cost:0.7274302957311136 
2022-03-27 19:39:29,363: ============================================================
2022-03-27 19:39:29,363: Epoch 20/26 Batch 4700/7662 eta: 15:15:54.183599	Training Loss 0.4591 (0.4430)	Training Prec@1 89.258 (90.823)	Training Prec@5 92.578 (94.206)	
2022-03-27 19:39:29,364: ============================================================
2022-03-27 19:41:15,832: time cost, forward:0.2997867176249068, backward:0.04374245848102255, data cost:0.7277545731225146 
2022-03-27 19:41:15,832: ============================================================
2022-03-27 19:41:15,832: Epoch 20/26 Batch 4800/7662 eta: 14:26:34.101037	Training Loss 0.4470 (0.4430)	Training Prec@1 88.867 (90.826)	Training Prec@5 91.406 (94.208)	
2022-03-27 19:41:15,833: ============================================================
2022-03-27 19:43:02,161: time cost, forward:0.2991588993640938, backward:0.04371750522667254, data cost:0.7281362686772375 
2022-03-27 19:43:02,162: ============================================================
2022-03-27 19:43:02,162: Epoch 20/26 Batch 4900/7662 eta: 14:23:39.843198	Training Loss 0.4449 (0.4430)	Training Prec@1 90.625 (90.828)	Training Prec@5 94.336 (94.209)	
2022-03-27 19:43:02,162: ============================================================
2022-03-27 19:44:44,285: time cost, forward:0.2986481883187703, backward:0.04374417607177136, data cost:0.7276838254537504 
2022-03-27 19:44:44,286: ============================================================
2022-03-27 19:44:44,286: Epoch 20/26 Batch 5000/7662 eta: 13:47:47.938094	Training Loss 0.4534 (0.4429)	Training Prec@1 87.891 (90.828)	Training Prec@5 92.773 (94.208)	
2022-03-27 19:44:44,286: ============================================================
2022-03-27 19:46:28,658: time cost, forward:0.29810122023098234, backward:0.04373202129400672, data cost:0.7277924122354942 
2022-03-27 19:46:28,658: ============================================================
2022-03-27 19:46:28,659: Epoch 20/26 Batch 5100/7662 eta: 14:04:17.247118	Training Loss 0.4365 (0.4429)	Training Prec@1 90.039 (90.827)	Training Prec@5 92.969 (94.208)	
2022-03-27 19:46:28,659: ============================================================
2022-03-27 19:48:16,357: time cost, forward:0.297747984049893, backward:0.043736705139844, data cost:0.7282874813032141 
2022-03-27 19:48:16,357: ============================================================
2022-03-27 19:48:16,358: Epoch 20/26 Batch 5200/7662 eta: 14:29:23.909665	Training Loss 0.4420 (0.4429)	Training Prec@1 90.820 (90.830)	Training Prec@5 93.555 (94.208)	
2022-03-27 19:48:16,358: ============================================================
2022-03-27 19:50:04,318: time cost, forward:0.2976843180533152, backward:0.04377097025257751, data cost:0.7283851636943108 
2022-03-27 19:50:04,318: ============================================================
2022-03-27 19:50:04,319: Epoch 20/26 Batch 5300/7662 eta: 14:29:42.958553	Training Loss 0.4313 (0.4429)	Training Prec@1 91.406 (90.835)	Training Prec@5 95.508 (94.211)	
2022-03-27 19:50:04,319: ============================================================
2022-03-27 19:51:52,087: time cost, forward:0.29734468301107847, backward:0.043747586306653034, data cost:0.728958889739914 
2022-03-27 19:51:52,088: ============================================================
2022-03-27 19:51:52,088: Epoch 20/26 Batch 5400/7662 eta: 14:26:22.472167	Training Loss 0.4549 (0.4429)	Training Prec@1 91.797 (90.835)	Training Prec@5 94.922 (94.215)	
2022-03-27 19:51:52,088: ============================================================
2022-03-27 19:53:41,676: time cost, forward:0.29717944001778623, backward:0.04378758206933731, data cost:0.7294318702008903 
2022-03-27 19:53:41,677: ============================================================
2022-03-27 19:53:41,677: Epoch 20/26 Batch 5500/7662 eta: 14:39:10.848764	Training Loss 0.4417 (0.4429)	Training Prec@1 89.453 (90.834)	Training Prec@5 93.750 (94.213)	
2022-03-27 19:53:41,677: ============================================================
2022-03-27 19:55:30,114: time cost, forward:0.2971940425532825, backward:0.04380890419917951, data cost:0.7296782524420931 
2022-03-27 19:55:30,115: ============================================================
2022-03-27 19:55:30,116: Epoch 20/26 Batch 5600/7662 eta: 14:28:08.399197	Training Loss 0.4375 (0.4429)	Training Prec@1 91.406 (90.830)	Training Prec@5 95.312 (94.211)	
2022-03-27 19:55:30,116: ============================================================
2022-03-27 19:57:17,687: time cost, forward:0.29713515972626753, backward:0.04382569749306369, data cost:0.7299019502200333 
2022-03-27 19:57:17,687: ============================================================
2022-03-27 19:57:17,687: Epoch 20/26 Batch 5700/7662 eta: 14:19:24.434670	Training Loss 0.4489 (0.4429)	Training Prec@1 90.039 (90.832)	Training Prec@5 94.141 (94.213)	
2022-03-27 19:57:17,687: ============================================================
2022-03-27 19:59:06,109: time cost, forward:0.2970500553162021, backward:0.043833464913418385, data cost:0.730122537361299 
2022-03-27 19:59:06,110: ============================================================
2022-03-27 19:59:06,110: Epoch 20/26 Batch 5800/7662 eta: 14:24:24.128525	Training Loss 0.4369 (0.4429)	Training Prec@1 91.211 (90.833)	Training Prec@5 95.312 (94.216)	
2022-03-27 19:59:06,110: ============================================================
2022-03-27 20:00:54,758: time cost, forward:0.2970238796107384, backward:0.04388021792288776, data cost:0.7304295394598054 
2022-03-27 20:00:54,759: ============================================================
2022-03-27 20:00:54,759: Epoch 20/26 Batch 5900/7662 eta: 14:24:23.371701	Training Loss 0.4184 (0.4429)	Training Prec@1 93.555 (90.834)	Training Prec@5 96.289 (94.216)	
2022-03-27 20:00:54,759: ============================================================
2022-03-27 20:02:41,165: time cost, forward:0.2969967740280347, backward:0.04390098429020295, data cost:0.7302615027722567 
2022-03-27 20:02:41,165: ============================================================
2022-03-27 20:02:41,166: Epoch 20/26 Batch 6000/7662 eta: 14:04:46.945748	Training Loss 0.4203 (0.4429)	Training Prec@1 92.969 (90.837)	Training Prec@5 95.312 (94.218)	
2022-03-27 20:02:41,166: ============================================================
2022-03-27 20:04:28,475: time cost, forward:0.2972287369822064, backward:0.0439254838065019, data cost:0.7300801637974464 
2022-03-27 20:04:28,476: ============================================================
2022-03-27 20:04:28,476: Epoch 20/26 Batch 6100/7662 eta: 14:10:09.845306	Training Loss 0.4492 (0.4429)	Training Prec@1 89.648 (90.840)	Training Prec@5 93.555 (94.220)	
2022-03-27 20:04:28,476: ============================================================
2022-03-27 20:06:17,958: time cost, forward:0.2976253023453731, backward:0.04388349812768086, data cost:0.7301071001303006 
2022-03-27 20:06:17,959: ============================================================
2022-03-27 20:06:17,959: Epoch 20/26 Batch 6200/7662 eta: 14:25:33.318747	Training Loss 0.4470 (0.4429)	Training Prec@1 90.039 (90.838)	Training Prec@5 94.727 (94.218)	
2022-03-27 20:06:17,959: ============================================================
2022-03-27 20:08:05,070: time cost, forward:0.29757112267471947, backward:0.04387269256265982, data cost:0.7300718687208593 
2022-03-27 20:08:05,071: ============================================================
2022-03-27 20:08:05,071: Epoch 20/26 Batch 6300/7662 eta: 14:05:01.698918	Training Loss 0.4444 (0.4429)	Training Prec@1 91.016 (90.837)	Training Prec@5 94.922 (94.217)	
2022-03-27 20:08:05,072: ============================================================
2022-03-27 20:09:50,393: time cost, forward:0.2975022083782632, backward:0.043866383245092275, data cost:0.7299280367450502 
2022-03-27 20:09:50,394: ============================================================
2022-03-27 20:09:50,394: Epoch 20/26 Batch 6400/7662 eta: 13:49:09.133773	Training Loss 0.4374 (0.4429)	Training Prec@1 91.016 (90.836)	Training Prec@5 93.555 (94.215)	
2022-03-27 20:09:50,394: ============================================================
2022-03-27 20:11:38,581: time cost, forward:0.2973813932480161, backward:0.043890695679020854, data cost:0.730143490525865 
2022-03-27 20:11:38,582: ============================================================
2022-03-27 20:11:38,583: Epoch 20/26 Batch 6500/7662 eta: 14:09:54.676974	Training Loss 0.4442 (0.4429)	Training Prec@1 90.430 (90.833)	Training Prec@5 93.164 (94.213)	
2022-03-27 20:11:38,583: ============================================================
2022-03-27 20:13:27,186: time cost, forward:0.2972652059483662, backward:0.043909440132357314, data cost:0.7305033921942528 
2022-03-27 20:13:27,186: ============================================================
2022-03-27 20:13:27,186: Epoch 20/26 Batch 6600/7662 eta: 14:11:21.742633	Training Loss 0.4407 (0.4430)	Training Prec@1 91.406 (90.837)	Training Prec@5 94.531 (94.215)	
2022-03-27 20:13:27,186: ============================================================
2022-03-27 20:15:11,940: time cost, forward:0.2972356098626048, backward:0.04389565943746286, data cost:0.7301249339306848 
2022-03-27 20:15:11,940: ============================================================
2022-03-27 20:15:11,940: Epoch 20/26 Batch 6700/7662 eta: 13:39:26.181891	Training Loss 0.4403 (0.4430)	Training Prec@1 91.602 (90.838)	Training Prec@5 94.922 (94.216)	
2022-03-27 20:15:11,940: ============================================================
2022-03-27 20:16:58,189: time cost, forward:0.2970504078694627, backward:0.04387773883958164, data cost:0.7301161718080983 
2022-03-27 20:16:58,190: ============================================================
2022-03-27 20:16:58,191: Epoch 20/26 Batch 6800/7662 eta: 13:49:22.334337	Training Loss 0.4419 (0.4430)	Training Prec@1 90.625 (90.837)	Training Prec@5 94.141 (94.215)	
2022-03-27 20:16:58,191: ============================================================
2022-03-27 20:18:41,588: time cost, forward:0.2969380061960614, backward:0.04390435495969609, data cost:0.7297915135765269 
2022-03-27 20:18:41,589: ============================================================
2022-03-27 20:18:41,590: Epoch 20/26 Batch 6900/7662 eta: 13:25:23.604737	Training Loss 0.4360 (0.4430)	Training Prec@1 92.578 (90.838)	Training Prec@5 94.531 (94.215)	
2022-03-27 20:18:41,590: ============================================================
2022-03-27 20:20:31,643: time cost, forward:0.296790617843205, backward:0.04394116287896387, data cost:0.730312434583583 
2022-03-27 20:20:31,644: ============================================================
2022-03-27 20:20:31,644: Epoch 20/26 Batch 7000/7662 eta: 14:15:23.800934	Training Loss 0.4429 (0.4430)	Training Prec@1 89.258 (90.839)	Training Prec@5 92.578 (94.215)	
2022-03-27 20:20:31,644: ============================================================
2022-03-27 20:22:15,700: time cost, forward:0.29662814518484804, backward:0.04394376256093456, data cost:0.7300414383822822 
2022-03-27 20:22:15,701: ============================================================
2022-03-27 20:22:15,701: Epoch 20/26 Batch 7100/7662 eta: 13:27:03.140486	Training Loss 0.4502 (0.4430)	Training Prec@1 90.430 (90.838)	Training Prec@5 94.141 (94.214)	
2022-03-27 20:22:15,702: ============================================================
2022-03-27 20:24:02,870: time cost, forward:0.29637481987782693, backward:0.04395453339401989, data cost:0.7303092085929327 
2022-03-27 20:24:02,871: ============================================================
2022-03-27 20:24:02,871: Epoch 20/26 Batch 7200/7662 eta: 13:49:24.264766	Training Loss 0.4485 (0.4430)	Training Prec@1 90.234 (90.837)	Training Prec@5 94.531 (94.213)	
2022-03-27 20:24:02,871: ============================================================
2022-03-27 20:25:47,173: time cost, forward:0.295984130344059, backward:0.043970710268607285, data cost:0.7302638334286574 
2022-03-27 20:25:47,173: ============================================================
2022-03-27 20:25:47,174: Epoch 20/26 Batch 7300/7662 eta: 13:25:28.597405	Training Loss 0.4489 (0.4430)	Training Prec@1 90.820 (90.841)	Training Prec@5 95.312 (94.215)	
2022-03-27 20:25:47,174: ============================================================
2022-03-27 20:27:33,501: time cost, forward:0.2957388935483522, backward:0.04397006691557473, data cost:0.730437602815088 
2022-03-27 20:27:33,501: ============================================================
2022-03-27 20:27:33,501: Epoch 20/26 Batch 7400/7662 eta: 13:39:20.672677	Training Loss 0.4545 (0.4430)	Training Prec@1 90.039 (90.838)	Training Prec@5 93.945 (94.214)	
2022-03-27 20:27:33,502: ============================================================
2022-03-27 20:29:20,866: time cost, forward:0.2957122987835451, backward:0.043988036161932184, data cost:0.7304988374454464 
2022-03-27 20:29:20,866: ============================================================
2022-03-27 20:29:20,866: Epoch 20/26 Batch 7500/7662 eta: 13:45:32.743539	Training Loss 0.4465 (0.4430)	Training Prec@1 91.797 (90.838)	Training Prec@5 95.312 (94.214)	
2022-03-27 20:29:20,866: ============================================================
2022-03-27 20:31:07,130: time cost, forward:0.29574809194881835, backward:0.04396511131343849, data cost:0.7302667646286346 
2022-03-27 20:31:07,131: ============================================================
2022-03-27 20:31:07,131: Epoch 20/26 Batch 7600/7662 eta: 13:35:18.915323	Training Loss 0.4380 (0.4430)	Training Prec@1 91.992 (90.841)	Training Prec@5 95.703 (94.216)	
2022-03-27 20:31:07,131: ============================================================
2022-03-27 20:32:17,839: Epoch: 20/26 eta: 13:34:11.968616	Training Loss 0.4390 (0.4430)	Training Prec@1 91.406 (90.841)	Training Prec@5 94.727 (94.216)
2022-03-27 20:32:17,840: ============================================================
2022-03-27 20:32:17,980: Save Checkpoint...
2022-03-27 20:32:17,991: ============================================================
2022-03-27 20:32:21,458: Save done!
2022-03-27 20:32:21,458: ============================================================
2022-03-27 20:33:55,998: time cost, forward:0.24179778195390797, backward:0.037479229647703845, data cost:0.6684872357532231 
2022-03-27 20:33:56,000: ============================================================
2022-03-27 20:33:56,001: Epoch 21/26 Batch 100/7662 eta: 12:01:40.823405	Training Loss 0.4505 (0.4410)	Training Prec@1 90.234 (91.170)	Training Prec@5 94.922 (94.405)	
2022-03-27 20:33:56,001: ============================================================
2022-03-27 20:35:40,780: time cost, forward:0.26778586785397934, backward:0.03870539689183834, data cost:0.6911249100862435 
2022-03-27 20:35:40,780: ============================================================
2022-03-27 20:35:40,780: Epoch 21/26 Batch 200/7662 eta: 13:19:20.912610	Training Loss 0.4474 (0.4406)	Training Prec@1 91.016 (91.147)	Training Prec@5 94.922 (94.395)	
2022-03-27 20:35:40,781: ============================================================
2022-03-27 20:37:29,359: time cost, forward:0.27234296176744544, backward:0.039604202959449795, data cost:0.7149077330943334 
2022-03-27 20:37:29,359: ============================================================
2022-03-27 20:37:29,360: Epoch 21/26 Batch 300/7662 eta: 13:46:31.381732	Training Loss 0.4366 (0.4405)	Training Prec@1 92.578 (91.146)	Training Prec@5 95.117 (94.405)	
2022-03-27 20:37:29,360: ============================================================
2022-03-27 20:39:11,892: time cost, forward:0.2732121179575908, backward:0.04031464808566827, data cost:0.7125558130125653 
2022-03-27 20:39:11,892: ============================================================
2022-03-27 20:39:11,893: Epoch 21/26 Batch 400/7662 eta: 12:58:47.342138	Training Loss 0.4353 (0.4405)	Training Prec@1 93.164 (91.146)	Training Prec@5 96.094 (94.433)	
2022-03-27 20:39:11,893: ============================================================
2022-03-27 20:40:56,779: time cost, forward:0.2747642181679338, backward:0.040662004856881734, data cost:0.7154579884064699 
2022-03-27 20:40:56,780: ============================================================
2022-03-27 20:40:56,780: Epoch 21/26 Batch 500/7662 eta: 13:14:55.465576	Training Loss 0.4534 (0.4405)	Training Prec@1 90.820 (91.118)	Training Prec@5 94.141 (94.414)	
2022-03-27 20:40:56,780: ============================================================
2022-03-27 20:42:43,964: time cost, forward:0.27644249115244973, backward:0.04135610782642396, data cost:0.7198822351051293 
2022-03-27 20:42:43,964: ============================================================
2022-03-27 20:42:43,965: Epoch 21/26 Batch 600/7662 eta: 13:30:32.904201	Training Loss 0.4431 (0.4405)	Training Prec@1 91.797 (91.144)	Training Prec@5 96.289 (94.444)	
2022-03-27 20:42:43,965: ============================================================
2022-03-27 20:44:32,082: time cost, forward:0.27797558890903457, backward:0.04155953111225614, data cost:0.724333429541199 
2022-03-27 20:44:32,101: ============================================================
2022-03-27 20:44:32,101: Epoch 21/26 Batch 700/7662 eta: 13:35:56.760210	Training Loss 0.4381 (0.4404)	Training Prec@1 90.820 (91.150)	Training Prec@5 94.141 (94.446)	
2022-03-27 20:44:32,102: ============================================================
2022-03-27 20:46:18,249: time cost, forward:0.27867379743554566, backward:0.04192247169933868, data cost:0.7253602341805889 
2022-03-27 20:46:18,249: ============================================================
2022-03-27 20:46:18,250: Epoch 21/26 Batch 800/7662 eta: 13:19:10.311647	Training Loss 0.4430 (0.4404)	Training Prec@1 89.453 (91.173)	Training Prec@5 94.531 (94.462)	
2022-03-27 20:46:18,250: ============================================================
2022-03-27 20:48:03,441: time cost, forward:0.27975280823246124, backward:0.04222226885455071, data cost:0.7243284969626863 
2022-03-27 20:48:03,441: ============================================================
2022-03-27 20:48:03,442: Epoch 21/26 Batch 900/7662 eta: 13:10:13.169703	Training Loss 0.4393 (0.4406)	Training Prec@1 91.016 (91.140)	Training Prec@5 93.750 (94.440)	
2022-03-27 20:48:03,442: ============================================================
2022-03-27 20:49:46,414: time cost, forward:0.27852195566958254, backward:0.04242004360164608, data cost:0.7239860273576952 
2022-03-27 20:49:46,414: ============================================================
2022-03-27 20:49:46,415: Epoch 21/26 Batch 1000/7662 eta: 12:51:50.011928	Training Loss 0.4475 (0.4407)	Training Prec@1 90.820 (91.138)	Training Prec@5 94.336 (94.440)	
2022-03-27 20:49:46,415: ============================================================
2022-03-27 20:51:30,413: time cost, forward:0.27904313992542823, backward:0.042495804119370435, data cost:0.7227190187348356 
2022-03-27 20:51:30,413: ============================================================
2022-03-27 20:51:30,414: Epoch 21/26 Batch 1100/7662 eta: 12:57:47.584279	Training Loss 0.4423 (0.4406)	Training Prec@1 89.453 (91.145)	Training Prec@5 93.164 (94.443)	
2022-03-27 20:51:30,414: ============================================================
2022-03-27 20:53:21,030: time cost, forward:0.2811724173217341, backward:0.042734121063334234, data cost:0.7250008425979042 
2022-03-27 20:53:21,030: ============================================================
2022-03-27 20:53:21,030: Epoch 21/26 Batch 1200/7662 eta: 13:45:26.409084	Training Loss 0.4377 (0.4406)	Training Prec@1 88.672 (91.126)	Training Prec@5 92.773 (94.427)	
2022-03-27 20:53:21,031: ============================================================
2022-03-27 20:55:11,107: time cost, forward:0.2839277884517843, backward:0.04288334457391588, data cost:0.7260469544200001 
2022-03-27 20:55:11,109: ============================================================
2022-03-27 20:55:11,110: Epoch 21/26 Batch 1300/7662 eta: 13:39:35.601893	Training Loss 0.4370 (0.4407)	Training Prec@1 92.188 (91.111)	Training Prec@5 93.945 (94.406)	
2022-03-27 20:55:11,110: ============================================================
2022-03-27 20:56:57,838: time cost, forward:0.28779353475127584, backward:0.042795615335973015, data cost:0.7235734922873965 
2022-03-27 20:56:57,839: ============================================================
2022-03-27 20:56:57,839: Epoch 21/26 Batch 1400/7662 eta: 13:12:52.463120	Training Loss 0.4391 (0.4407)	Training Prec@1 91.797 (91.122)	Training Prec@5 94.531 (94.416)	
2022-03-27 20:56:57,839: ============================================================
2022-03-27 20:58:50,428: time cost, forward:0.29204485637494293, backward:0.04275374002183096, data cost:0.724169803349633 
2022-03-27 20:58:50,428: ============================================================
2022-03-27 20:58:50,428: Epoch 21/26 Batch 1500/7662 eta: 13:54:31.906788	Training Loss 0.4343 (0.4407)	Training Prec@1 92.969 (91.113)	Training Prec@5 96.094 (94.412)	
2022-03-27 20:58:50,428: ============================================================
2022-03-27 21:00:41,930: time cost, forward:0.2955044285068667, backward:0.042817885015367194, data cost:0.7242286516920785 
2022-03-27 21:00:41,931: ============================================================
2022-03-27 21:00:41,931: Epoch 21/26 Batch 1600/7662 eta: 13:44:37.099247	Training Loss 0.4595 (0.4409)	Training Prec@1 87.500 (91.099)	Training Prec@5 92.383 (94.406)	
2022-03-27 21:00:41,931: ============================================================
2022-03-27 21:02:33,040: time cost, forward:0.2980716025008392, backward:0.0427323062676693, data cost:0.7246952980248068 
2022-03-27 21:02:33,061: ============================================================
2022-03-27 21:02:33,062: Epoch 21/26 Batch 1700/7662 eta: 13:40:00.890427	Training Loss 0.4459 (0.4409)	Training Prec@1 90.820 (91.088)	Training Prec@5 95.508 (94.401)	
2022-03-27 21:02:33,062: ============================================================
2022-03-27 21:04:20,044: time cost, forward:0.29967270088301823, backward:0.04266624281047251, data cost:0.723288859308528 
2022-03-27 21:04:20,045: ============================================================
2022-03-27 21:04:20,046: Epoch 21/26 Batch 1800/7662 eta: 13:07:37.927089	Training Loss 0.4228 (0.4409)	Training Prec@1 93.750 (91.094)	Training Prec@5 95.508 (94.405)	
2022-03-27 21:04:20,046: ============================================================
2022-03-27 21:06:06,205: time cost, forward:0.2995744868916797, backward:0.04267073104480745, data cost:0.7232562546481454 
2022-03-27 21:06:06,205: ============================================================
2022-03-27 21:06:06,206: Epoch 21/26 Batch 1900/7662 eta: 12:59:47.972179	Training Loss 0.4469 (0.4409)	Training Prec@1 91.211 (91.090)	Training Prec@5 95.117 (94.398)	
2022-03-27 21:06:06,206: ============================================================
2022-03-27 21:07:52,270: time cost, forward:0.2994388219653039, backward:0.0428187995030917, data cost:0.7228852621968714 
2022-03-27 21:07:52,270: ============================================================
2022-03-27 21:07:52,271: Epoch 21/26 Batch 2000/7662 eta: 12:57:19.936265	Training Loss 0.4460 (0.4410)	Training Prec@1 89.258 (91.084)	Training Prec@5 91.797 (94.393)	
2022-03-27 21:07:52,271: ============================================================
2022-03-27 21:09:40,712: time cost, forward:0.2996240901401805, backward:0.0428092207097621, data cost:0.7236944446681851 
2022-03-27 21:09:40,712: ============================================================
2022-03-27 21:09:40,712: Epoch 21/26 Batch 2100/7662 eta: 13:12:56.565632	Training Loss 0.4374 (0.4410)	Training Prec@1 92.578 (91.084)	Training Prec@5 95.508 (94.390)	
2022-03-27 21:09:40,712: ============================================================
2022-03-27 21:11:28,298: time cost, forward:0.299151672781354, backward:0.04283726177415072, data cost:0.7244367601655732 
2022-03-27 21:11:28,299: ============================================================
2022-03-27 21:11:28,299: Epoch 21/26 Batch 2200/7662 eta: 13:04:54.085746	Training Loss 0.4363 (0.4410)	Training Prec@1 91.602 (91.084)	Training Prec@5 93.555 (94.383)	
2022-03-27 21:11:28,300: ============================================================
2022-03-27 21:13:12,322: time cost, forward:0.2986964996921959, backward:0.0427900622750739, data cost:0.7238830224800856 
2022-03-27 21:13:12,323: ============================================================
2022-03-27 21:13:12,324: Epoch 21/26 Batch 2300/7662 eta: 12:37:10.542890	Training Loss 0.4434 (0.4411)	Training Prec@1 90.234 (91.071)	Training Prec@5 93.164 (94.374)	
2022-03-27 21:13:12,324: ============================================================
2022-03-27 21:15:00,480: time cost, forward:0.2985781838169392, backward:0.04271960367804619, data cost:0.7244586773642205 
2022-03-27 21:15:00,481: ============================================================
2022-03-27 21:15:00,482: Epoch 21/26 Batch 2400/7662 eta: 13:05:27.635679	Training Loss 0.4406 (0.4411)	Training Prec@1 90.625 (91.072)	Training Prec@5 93.945 (94.381)	
2022-03-27 21:15:00,482: ============================================================
2022-03-27 21:16:46,144: time cost, forward:0.2986702119507471, backward:0.042734927776194705, data cost:0.7241271469487148 
2022-03-27 21:16:46,145: ============================================================
2022-03-27 21:16:46,145: Epoch 21/26 Batch 2500/7662 eta: 12:45:35.071309	Training Loss 0.4291 (0.4411)	Training Prec@1 92.188 (91.066)	Training Prec@5 94.531 (94.379)	
2022-03-27 21:16:46,145: ============================================================
2022-03-27 21:18:32,865: time cost, forward:0.29846527485629143, backward:0.042880507146637915, data cost:0.7243598892671321 
2022-03-27 21:18:32,865: ============================================================
2022-03-27 21:18:32,865: Epoch 21/26 Batch 2600/7662 eta: 12:51:27.807076	Training Loss 0.4552 (0.4411)	Training Prec@1 90.234 (91.064)	Training Prec@5 92.969 (94.376)	
2022-03-27 21:18:32,865: ============================================================
2022-03-27 21:20:18,068: time cost, forward:0.29800206875527246, backward:0.04290457485604613, data cost:0.7240447791340882 
2022-03-27 21:20:18,069: ============================================================
2022-03-27 21:20:18,069: Epoch 21/26 Batch 2700/7662 eta: 12:38:44.922276	Training Loss 0.4395 (0.4410)	Training Prec@1 91.211 (91.065)	Training Prec@5 94.727 (94.382)	
2022-03-27 21:20:18,070: ============================================================
2022-03-27 21:22:03,412: time cost, forward:0.29753785986864556, backward:0.04299543737811504, data cost:0.7240379027018763 
2022-03-27 21:22:03,413: ============================================================
2022-03-27 21:22:03,413: Epoch 21/26 Batch 2800/7662 eta: 12:37:59.950447	Training Loss 0.4428 (0.4410)	Training Prec@1 89.844 (91.067)	Training Prec@5 93.945 (94.381)	
2022-03-27 21:22:03,413: ============================================================
2022-03-27 21:23:48,923: time cost, forward:0.2971700005138196, backward:0.04303498126671782, data cost:0.7238642235960209 
2022-03-27 21:23:48,924: ============================================================
2022-03-27 21:23:48,924: Epoch 21/26 Batch 2900/7662 eta: 12:37:26.892350	Training Loss 0.4425 (0.4410)	Training Prec@1 90.820 (91.070)	Training Prec@5 95.508 (94.384)	
2022-03-27 21:23:48,924: ============================================================
2022-03-27 21:25:35,221: time cost, forward:0.29686371268094003, backward:0.04301921841938442, data cost:0.7244193251032001 
2022-03-27 21:25:35,222: ============================================================
2022-03-27 21:25:35,222: Epoch 21/26 Batch 3000/7662 eta: 12:41:19.318479	Training Loss 0.4451 (0.4411)	Training Prec@1 89.648 (91.064)	Training Prec@5 92.188 (94.377)	
2022-03-27 21:25:35,222: ============================================================
2022-03-27 21:27:20,688: time cost, forward:0.29684526414861984, backward:0.04303692817380252, data cost:0.7240663977275552 
2022-03-27 21:27:20,689: ============================================================
2022-03-27 21:27:20,689: Epoch 21/26 Batch 3100/7662 eta: 12:33:37.022794	Training Loss 0.4400 (0.4411)	Training Prec@1 91.211 (91.064)	Training Prec@5 95.508 (94.378)	
2022-03-27 21:27:20,689: ============================================================
2022-03-27 21:29:09,274: time cost, forward:0.29653925119097735, backward:0.04302310548599305, data cost:0.7251061855833693 
2022-03-27 21:29:09,275: ============================================================
2022-03-27 21:29:09,275: Epoch 21/26 Batch 3200/7662 eta: 12:54:05.493233	Training Loss 0.4229 (0.4411)	Training Prec@1 93.164 (91.058)	Training Prec@5 95.898 (94.371)	
2022-03-27 21:29:09,276: ============================================================
2022-03-27 21:30:55,423: time cost, forward:0.2962557507052715, backward:0.04308911329618039, data cost:0.72501508573143 
2022-03-27 21:30:55,423: ============================================================
2022-03-27 21:30:55,423: Epoch 21/26 Batch 3300/7662 eta: 12:34:56.565546	Training Loss 0.4329 (0.4411)	Training Prec@1 91.406 (91.053)	Training Prec@5 93.945 (94.367)	
2022-03-27 21:30:55,423: ============================================================
2022-03-27 21:32:39,458: time cost, forward:0.2960050396443676, backward:0.04314170026821261, data cost:0.7245802676618082 
2022-03-27 21:32:39,458: ============================================================
2022-03-27 21:32:39,458: Epoch 21/26 Batch 3400/7662 eta: 12:18:10.816120	Training Loss 0.4451 (0.4411)	Training Prec@1 91.992 (91.059)	Training Prec@5 94.531 (94.367)	
2022-03-27 21:32:39,458: ============================================================
2022-03-27 21:34:25,125: time cost, forward:0.29603106861763184, backward:0.04318742991924695, data cost:0.7242078369567994 
2022-03-27 21:34:25,126: ============================================================
2022-03-27 21:34:25,126: Epoch 21/26 Batch 3500/7662 eta: 12:28:00.348975	Training Loss 0.4447 (0.4411)	Training Prec@1 92.578 (91.064)	Training Prec@5 94.531 (94.370)	
2022-03-27 21:34:25,127: ============================================================
2022-03-27 21:36:12,737: time cost, forward:0.2961208622268121, backward:0.04327002681934625, data cost:0.724578542025694 
2022-03-27 21:36:12,738: ============================================================
2022-03-27 21:36:12,738: Epoch 21/26 Batch 3600/7662 eta: 12:39:58.330013	Training Loss 0.4427 (0.4411)	Training Prec@1 90.625 (91.065)	Training Prec@5 93.555 (94.372)	
2022-03-27 21:36:12,738: ============================================================
2022-03-27 21:38:00,483: time cost, forward:0.2960616295065033, backward:0.04328365563121671, data cost:0.7249940921564816 
2022-03-27 21:38:00,484: ============================================================
2022-03-27 21:38:00,484: Epoch 21/26 Batch 3700/7662 eta: 12:39:07.347069	Training Loss 0.4358 (0.4412)	Training Prec@1 91.406 (91.063)	Training Prec@5 94.531 (94.369)	
2022-03-27 21:38:00,484: ============================================================
2022-03-27 21:39:44,825: time cost, forward:0.2956551252210978, backward:0.04320513860085476, data cost:0.7249093508212057 
2022-03-27 21:39:44,826: ============================================================
2022-03-27 21:39:44,826: Epoch 21/26 Batch 3800/7662 eta: 12:13:24.137285	Training Loss 0.4333 (0.4412)	Training Prec@1 91.992 (91.059)	Training Prec@5 95.898 (94.365)	
2022-03-27 21:39:44,826: ============================================================
2022-03-27 21:41:33,737: time cost, forward:0.2958274409232246, backward:0.04322549415631428, data cost:0.7252736773421197 
2022-03-27 21:41:33,738: ============================================================
2022-03-27 21:41:33,738: Epoch 21/26 Batch 3900/7662 eta: 12:43:42.639324	Training Loss 0.4455 (0.4412)	Training Prec@1 87.891 (91.058)	Training Prec@5 92.969 (94.363)	
2022-03-27 21:41:33,738: ============================================================
2022-03-27 21:43:19,440: time cost, forward:0.2954927966963741, backward:0.04329681706506033, data cost:0.7253344927647317 
2022-03-27 21:43:19,441: ============================================================
2022-03-27 21:43:19,441: Epoch 21/26 Batch 4000/7662 eta: 12:19:26.708911	Training Loss 0.4325 (0.4412)	Training Prec@1 91.797 (91.050)	Training Prec@5 94.531 (94.356)	
2022-03-27 21:43:19,441: ============================================================
2022-03-27 21:45:08,428: time cost, forward:0.2959748164826296, backward:0.043320616735833886, data cost:0.7253569995929451 
2022-03-27 21:45:08,429: ============================================================
2022-03-27 21:45:08,429: Epoch 21/26 Batch 4100/7662 eta: 12:40:36.686069	Training Loss 0.4434 (0.4413)	Training Prec@1 91.016 (91.051)	Training Prec@5 95.703 (94.356)	
2022-03-27 21:45:08,430: ============================================================
2022-03-27 21:46:51,700: time cost, forward:0.29578884353692203, backward:0.04336412142049304, data cost:0.7247388925572809 
2022-03-27 21:46:51,701: ============================================================
2022-03-27 21:46:51,701: Epoch 21/26 Batch 4200/7662 eta: 11:58:59.718972	Training Loss 0.4519 (0.4413)	Training Prec@1 90.039 (91.053)	Training Prec@5 93.945 (94.356)	
2022-03-27 21:46:51,701: ============================================================
2022-03-27 21:48:38,377: time cost, forward:0.29580323589100455, backward:0.04342013731976669, data cost:0.724779605532724 
2022-03-27 21:48:38,378: ============================================================
2022-03-27 21:48:38,379: Epoch 21/26 Batch 4300/7662 eta: 12:20:55.668478	Training Loss 0.4384 (0.4413)	Training Prec@1 91.406 (91.054)	Training Prec@5 95.117 (94.355)	
2022-03-27 21:48:38,379: ============================================================
2022-03-27 21:50:27,021: time cost, forward:0.2958263871777624, backward:0.0431916751111467, data cost:0.7256035215612379 
2022-03-27 21:50:27,021: ============================================================
2022-03-27 21:50:27,022: Epoch 21/26 Batch 4400/7662 eta: 12:32:46.193792	Training Loss 0.4478 (0.4413)	Training Prec@1 89.648 (91.055)	Training Prec@5 93.164 (94.356)	
2022-03-27 21:50:27,022: ============================================================
2022-03-27 21:52:13,992: time cost, forward:0.29571992488775445, backward:0.0430816462581013, data cost:0.7259005405394653 
2022-03-27 21:52:13,992: ============================================================
2022-03-27 21:52:13,992: Epoch 21/26 Batch 4500/7662 eta: 12:19:23.997677	Training Loss 0.4375 (0.4413)	Training Prec@1 91.016 (91.052)	Training Prec@5 93.750 (94.355)	
2022-03-27 21:52:13,992: ============================================================
2022-03-27 21:53:59,092: time cost, forward:0.2957190117853625, backward:0.04307398575237197, data cost:0.725618668705724 
2022-03-27 21:53:59,093: ============================================================
2022-03-27 21:53:59,093: Epoch 21/26 Batch 4600/7662 eta: 12:04:43.376095	Training Loss 0.4461 (0.4413)	Training Prec@1 90.820 (91.052)	Training Prec@5 94.141 (94.355)	
2022-03-27 21:53:59,094: ============================================================
2022-03-27 21:55:45,481: time cost, forward:0.2957894197294727, backward:0.043141881464186765, data cost:0.7253355821616397 
2022-03-27 21:55:45,482: ============================================================
2022-03-27 21:55:45,482: Epoch 21/26 Batch 4700/7662 eta: 12:11:49.834231	Training Loss 0.4427 (0.4413)	Training Prec@1 91.602 (91.051)	Training Prec@5 95.898 (94.354)	
2022-03-27 21:55:45,482: ============================================================
2022-03-27 21:57:32,258: time cost, forward:0.2960997954784122, backward:0.04316155809639742, data cost:0.7251827868354099 
2022-03-27 21:57:32,258: ============================================================
2022-03-27 21:57:32,258: Epoch 21/26 Batch 4800/7662 eta: 12:12:43.003820	Training Loss 0.4438 (0.4413)	Training Prec@1 90.820 (91.049)	Training Prec@5 93.555 (94.353)	
2022-03-27 21:57:32,258: ============================================================
2022-03-27 21:59:16,972: time cost, forward:0.29611206716555777, backward:0.04321439525598798, data cost:0.7247287711213379 
2022-03-27 21:59:16,973: ============================================================
2022-03-27 21:59:16,973: Epoch 21/26 Batch 4900/7662 eta: 11:56:49.434842	Training Loss 0.4477 (0.4413)	Training Prec@1 91.406 (91.048)	Training Prec@5 93.750 (94.352)	
2022-03-27 21:59:16,973: ============================================================
2022-03-27 22:00:54,894: time cost, forward:0.2956745964118208, backward:0.04319864984845419, data cost:0.7233586330894566 
2022-03-27 22:00:54,895: ============================================================
2022-03-27 22:00:54,895: Epoch 21/26 Batch 5000/7662 eta: 11:08:41.576148	Training Loss 0.4313 (0.4414)	Training Prec@1 91.797 (91.047)	Training Prec@5 93.555 (94.351)	
2022-03-27 22:00:54,895: ============================================================
2022-03-27 22:02:41,320: time cost, forward:0.2952857990549181, backward:0.04328156756662719, data cost:0.7238433321309244 
2022-03-27 22:02:41,321: ============================================================
2022-03-27 22:02:41,321: Epoch 21/26 Batch 5100/7662 eta: 12:04:59.394271	Training Loss 0.4440 (0.4414)	Training Prec@1 89.648 (91.049)	Training Prec@5 93.945 (94.353)	
2022-03-27 22:02:41,321: ============================================================
2022-03-27 22:04:25,890: time cost, forward:0.2948967998223618, backward:0.043278706672215006, data cost:0.7239047341402688 
2022-03-27 22:04:25,890: ============================================================
2022-03-27 22:04:25,890: Epoch 21/26 Batch 5200/7662 eta: 11:50:36.201157	Training Loss 0.4400 (0.4414)	Training Prec@1 93.164 (91.051)	Training Prec@5 94.922 (94.355)	
2022-03-27 22:04:25,891: ============================================================
2022-03-27 22:06:15,412: time cost, forward:0.2947069873763022, backward:0.04333600810753397, data cost:0.7244947295432766 
2022-03-27 22:06:15,413: ============================================================
2022-03-27 22:06:15,413: Epoch 21/26 Batch 5300/7662 eta: 12:22:26.099629	Training Loss 0.4382 (0.4414)	Training Prec@1 93.359 (91.047)	Training Prec@5 96.875 (94.353)	
2022-03-27 22:06:15,413: ============================================================
2022-03-27 22:08:00,910: time cost, forward:0.29446892597914226, backward:0.04338075055261744, data cost:0.7246965047804862 
2022-03-27 22:08:00,910: ============================================================
2022-03-27 22:08:00,910: Epoch 21/26 Batch 5400/7662 eta: 11:53:23.402177	Training Loss 0.4268 (0.4414)	Training Prec@1 91.406 (91.047)	Training Prec@5 94.336 (94.352)	
2022-03-27 22:08:00,910: ============================================================
2022-03-27 22:09:49,419: time cost, forward:0.2942729927579107, backward:0.04336579285181312, data cost:0.7253227131131302 
2022-03-27 22:09:49,419: ============================================================
2022-03-27 22:09:49,419: Epoch 21/26 Batch 5500/7662 eta: 12:11:56.886580	Training Loss 0.4412 (0.4414)	Training Prec@1 92.578 (91.050)	Training Prec@5 95.312 (94.353)	
2022-03-27 22:09:49,419: ============================================================
2022-03-27 22:11:33,393: time cost, forward:0.29396335877229285, backward:0.04334475679426539, data cost:0.7252293646516577 
2022-03-27 22:11:33,393: ============================================================
2022-03-27 22:11:33,393: Epoch 21/26 Batch 5600/7662 eta: 11:39:37.470080	Training Loss 0.4471 (0.4414)	Training Prec@1 91.406 (91.051)	Training Prec@5 94.531 (94.353)	
2022-03-27 22:11:33,394: ============================================================
2022-03-27 22:13:22,477: time cost, forward:0.293815920365068, backward:0.043370557262262015, data cost:0.7257449518569542 
2022-03-27 22:13:22,478: ============================================================
2022-03-27 22:13:22,478: Epoch 21/26 Batch 5700/7662 eta: 12:12:11.594762	Training Loss 0.4477 (0.4414)	Training Prec@1 90.625 (91.050)	Training Prec@5 92.383 (94.353)	
2022-03-27 22:13:22,478: ============================================================
2022-03-27 22:15:08,876: time cost, forward:0.2940739718649506, backward:0.04338030828280909, data cost:0.7255656354528889 
2022-03-27 22:15:08,877: ============================================================
2022-03-27 22:15:08,878: Epoch 21/26 Batch 5800/7662 eta: 11:52:23.969937	Training Loss 0.4386 (0.4414)	Training Prec@1 88.672 (91.050)	Training Prec@5 94.531 (94.352)	
2022-03-27 22:15:08,878: ============================================================
2022-03-27 22:16:56,111: time cost, forward:0.2941686916723153, backward:0.04337123556245402, data cost:0.7256260485664467 
2022-03-27 22:16:56,112: ============================================================
2022-03-27 22:16:56,112: Epoch 21/26 Batch 5900/7662 eta: 11:56:11.900871	Training Loss 0.4405 (0.4414)	Training Prec@1 90.820 (91.049)	Training Prec@5 93.359 (94.353)	
2022-03-27 22:16:56,112: ============================================================
2022-03-27 22:18:41,461: time cost, forward:0.2941126956167092, backward:0.04340456743839682, data cost:0.7253693413150213 
2022-03-27 22:18:41,461: ============================================================
2022-03-27 22:18:41,462: Epoch 21/26 Batch 6000/7662 eta: 11:41:51.442337	Training Loss 0.4482 (0.4414)	Training Prec@1 90.820 (91.049)	Training Prec@5 94.141 (94.352)	
2022-03-27 22:18:41,462: ============================================================
2022-03-27 22:20:30,750: time cost, forward:0.29409217682016114, backward:0.04336977954926423, data cost:0.7260363780586304 
2022-03-27 22:20:30,751: ============================================================
2022-03-27 22:20:30,751: Epoch 21/26 Batch 6100/7662 eta: 12:06:16.902611	Training Loss 0.4368 (0.4414)	Training Prec@1 92.188 (91.050)	Training Prec@5 94.336 (94.351)	
2022-03-27 22:20:30,751: ============================================================
2022-03-27 22:22:17,728: time cost, forward:0.2939376167221057, backward:0.04337801335607542, data cost:0.7262796872968653 
2022-03-27 22:22:17,729: ============================================================
2022-03-27 22:22:17,729: Epoch 21/26 Batch 6200/7662 eta: 11:49:08.321126	Training Loss 0.4309 (0.4414)	Training Prec@1 91.992 (91.051)	Training Prec@5 94.727 (94.352)	
2022-03-27 22:22:17,729: ============================================================
2022-03-27 22:24:04,795: time cost, forward:0.2936706889298326, backward:0.043405956191701685, data cost:0.7265048154215337 
2022-03-27 22:24:04,795: ============================================================
2022-03-27 22:24:04,796: Epoch 21/26 Batch 6300/7662 eta: 11:47:56.675836	Training Loss 0.4436 (0.4415)	Training Prec@1 92.969 (91.050)	Training Prec@5 95.312 (94.352)	
2022-03-27 22:24:04,796: ============================================================
2022-03-27 22:25:52,620: time cost, forward:0.29357498901898943, backward:0.04341234473776754, data cost:0.7269428891490299 
2022-03-27 22:25:52,621: ============================================================
2022-03-27 22:25:52,621: Epoch 21/26 Batch 6400/7662 eta: 11:51:09.695582	Training Loss 0.4564 (0.4415)	Training Prec@1 89.453 (91.050)	Training Prec@5 93.555 (94.352)	
2022-03-27 22:25:52,621: ============================================================
2022-03-27 22:27:36,788: time cost, forward:0.2934041324441736, backward:0.043404139891314975, data cost:0.7267665180321344 
2022-03-27 22:27:36,788: ============================================================
2022-03-27 22:27:36,788: Epoch 21/26 Batch 6500/7662 eta: 11:25:17.984298	Training Loss 0.4395 (0.4415)	Training Prec@1 91.992 (91.048)	Training Prec@5 94.336 (94.351)	
2022-03-27 22:27:36,788: ============================================================
2022-03-27 22:29:23,248: time cost, forward:0.29333828857295857, backward:0.04344116396787655, data cost:0.7267599849741393 
2022-03-27 22:29:23,249: ============================================================
2022-03-27 22:29:23,249: Epoch 21/26 Batch 6600/7662 eta: 11:38:36.834038	Training Loss 0.4490 (0.4415)	Training Prec@1 90.039 (91.046)	Training Prec@5 94.336 (94.350)	
2022-03-27 22:29:23,250: ============================================================
2022-03-27 22:31:06,786: time cost, forward:0.29319756951754194, backward:0.043431399953705215, data cost:0.7264786428934711 
2022-03-27 22:31:06,788: ============================================================
2022-03-27 22:31:06,788: Epoch 21/26 Batch 6700/7662 eta: 11:17:42.719703	Training Loss 0.4331 (0.4415)	Training Prec@1 92.188 (91.048)	Training Prec@5 96.094 (94.349)	
2022-03-27 22:31:06,788: ============================================================
2022-03-27 22:32:53,545: time cost, forward:0.2932152641154437, backward:0.043403557283525206, data cost:0.7266100109070606 
2022-03-27 22:32:53,545: ============================================================
2022-03-27 22:32:53,545: Epoch 21/26 Batch 6800/7662 eta: 11:37:00.171953	Training Loss 0.4380 (0.4415)	Training Prec@1 92.578 (91.048)	Training Prec@5 95.117 (94.350)	
2022-03-27 22:32:53,546: ============================================================
2022-03-27 22:34:41,315: time cost, forward:0.29292987381000246, backward:0.04342880994103096, data cost:0.7269813631873042 
2022-03-27 22:34:41,317: ============================================================
2022-03-27 22:34:41,317: Epoch 21/26 Batch 6900/7662 eta: 11:41:49.603513	Training Loss 0.4403 (0.4415)	Training Prec@1 89.648 (91.049)	Training Prec@5 93.945 (94.350)	
2022-03-27 22:34:41,318: ============================================================
2022-03-27 22:36:28,009: time cost, forward:0.29270018906504075, backward:0.043443292869058805, data cost:0.7272452441500432 
2022-03-27 22:36:28,010: ============================================================
2022-03-27 22:36:28,010: Epoch 21/26 Batch 7000/7662 eta: 11:33:01.302635	Training Loss 0.4332 (0.4415)	Training Prec@1 91.602 (91.046)	Training Prec@5 94.922 (94.348)	
2022-03-27 22:36:28,010: ============================================================
2022-03-27 22:38:16,777: time cost, forward:0.29258972309830994, backward:0.043439928285335716, data cost:0.7277576294326836 
2022-03-27 22:38:16,778: ============================================================
2022-03-27 22:38:16,778: Epoch 21/26 Batch 7100/7662 eta: 11:44:41.419351	Training Loss 0.4439 (0.4415)	Training Prec@1 90.234 (91.047)	Training Prec@5 93.164 (94.347)	
2022-03-27 22:38:16,778: ============================================================
2022-03-27 22:40:01,101: time cost, forward:0.29232470607373395, backward:0.043452759520314375, data cost:0.7276198224468949 
2022-03-27 22:40:01,102: ============================================================
2022-03-27 22:40:01,102: Epoch 21/26 Batch 7200/7662 eta: 11:14:09.772991	Training Loss 0.4530 (0.4415)	Training Prec@1 89.648 (91.046)	Training Prec@5 94.141 (94.347)	
2022-03-27 22:40:01,103: ============================================================
2022-03-27 22:41:46,804: time cost, forward:0.2921405929231467, backward:0.04350391680744514, data cost:0.7277664177906743 
2022-03-27 22:41:46,804: ============================================================
2022-03-27 22:41:46,804: Epoch 21/26 Batch 7300/7662 eta: 11:21:18.037516	Training Loss 0.4312 (0.4415)	Training Prec@1 92.578 (91.045)	Training Prec@5 95.117 (94.347)	
2022-03-27 22:41:46,804: ============================================================
2022-03-27 22:43:30,871: time cost, forward:0.2920509993280812, backward:0.04348626116157013, data cost:0.7275689804710268 
2022-03-27 22:43:30,871: ============================================================
2022-03-27 22:43:30,872: Epoch 21/26 Batch 7400/7662 eta: 11:09:01.924631	Training Loss 0.4328 (0.4415)	Training Prec@1 91.797 (91.045)	Training Prec@5 94.922 (94.347)	
2022-03-27 22:43:30,872: ============================================================
2022-03-27 22:45:18,365: time cost, forward:0.29182815682110685, backward:0.043493282701161914, data cost:0.7279463680700742 
2022-03-27 22:45:18,365: ============================================================
2022-03-27 22:45:18,366: Epoch 21/26 Batch 7500/7662 eta: 11:29:16.182656	Training Loss 0.4342 (0.4415)	Training Prec@1 93.555 (91.047)	Training Prec@5 96.289 (94.350)	
2022-03-27 22:45:18,366: ============================================================
2022-03-27 22:47:05,467: time cost, forward:0.2917169881723542, backward:0.043516085200881405, data cost:0.7281195808671183 
2022-03-27 22:47:05,467: ============================================================
2022-03-27 22:47:05,467: Epoch 21/26 Batch 7600/7662 eta: 11:24:58.191175	Training Loss 0.4608 (0.4415)	Training Prec@1 90.625 (91.049)	Training Prec@5 93.555 (94.351)	
2022-03-27 22:47:05,468: ============================================================
2022-03-27 22:48:14,401: Epoch: 21/26 eta: 11:23:50.717012	Training Loss 0.4429 (0.4415)	Training Prec@1 90.625 (91.049)	Training Prec@5 93.164 (94.351)
2022-03-27 22:48:14,401: ============================================================
2022-03-27 22:50:02,200: time cost, forward:0.27221397920088336, backward:0.03668569314359414, data cost:0.7708939470426001 
2022-03-27 22:50:02,202: ============================================================
2022-03-27 22:50:02,202: Epoch 22/26 Batch 100/7662 eta: 11:24:55.214328	Training Loss 0.4268 (0.4389)	Training Prec@1 92.578 (91.331)	Training Prec@5 95.312 (94.632)	
2022-03-27 22:50:02,202: ============================================================
2022-03-27 22:51:46,501: time cost, forward:0.2787168133797957, backward:0.03741207194687733, data cost:0.7453281579904221 
2022-03-27 22:51:46,501: ============================================================
2022-03-27 22:51:46,502: Epoch 22/26 Batch 200/7662 eta: 11:02:29.640412	Training Loss 0.4367 (0.4394)	Training Prec@1 91.211 (91.213)	Training Prec@5 95.703 (94.541)	
2022-03-27 22:51:46,502: ============================================================
2022-03-27 22:53:32,035: time cost, forward:0.28320240495994337, backward:0.038296532870136374, data cost:0.734971667611878 
2022-03-27 22:53:32,037: ============================================================
2022-03-27 22:53:32,038: Epoch 22/26 Batch 300/7662 eta: 11:08:35.203052	Training Loss 0.4435 (0.4392)	Training Prec@1 89.258 (91.189)	Training Prec@5 93.555 (94.481)	
2022-03-27 22:53:32,038: ============================================================
2022-03-27 22:55:16,186: time cost, forward:0.28445392682737575, backward:0.03927320167235563, data cost:0.731030303434023 
2022-03-27 22:55:16,186: ============================================================
2022-03-27 22:55:16,187: Epoch 22/26 Batch 400/7662 eta: 10:58:03.999402	Training Loss 0.4371 (0.4393)	Training Prec@1 90.625 (91.169)	Training Prec@5 93.750 (94.474)	
2022-03-27 22:55:16,187: ============================================================
2022-03-27 22:57:01,703: time cost, forward:0.28441870666458036, backward:0.040183429488677064, data cost:0.7301918165478295 
2022-03-27 22:57:01,703: ============================================================
2022-03-27 22:57:01,703: Epoch 22/26 Batch 500/7662 eta: 11:04:56.861302	Training Loss 0.4369 (0.4395)	Training Prec@1 90.430 (91.193)	Training Prec@5 93.555 (94.477)	
2022-03-27 22:57:01,703: ============================================================
2022-03-27 22:58:46,557: time cost, forward:0.2841704580342033, backward:0.040494232623525375, data cost:0.7289261997044584 
2022-03-27 22:58:46,558: ============================================================
2022-03-27 22:58:46,558: Epoch 22/26 Batch 600/7662 eta: 10:59:01.780316	Training Loss 0.4422 (0.4397)	Training Prec@1 91.797 (91.175)	Training Prec@5 94.141 (94.468)	
2022-03-27 22:58:46,558: ============================================================
2022-03-27 23:00:31,939: time cost, forward:0.28384717032633117, backward:0.040981864383462845, data cost:0.7288311128111526 
2022-03-27 23:00:31,939: ============================================================
2022-03-27 23:00:31,940: Epoch 22/26 Batch 700/7662 eta: 11:00:35.264719	Training Loss 0.4371 (0.4397)	Training Prec@1 90.039 (91.175)	Training Prec@5 94.141 (94.459)	
2022-03-27 23:00:31,940: ============================================================
2022-03-27 23:02:18,910: time cost, forward:0.2855461449438102, backward:0.041228064905866064, data cost:0.7287849246038215 
2022-03-27 23:02:18,910: ============================================================
2022-03-27 23:02:18,910: Epoch 22/26 Batch 800/7662 eta: 11:08:45.638966	Training Loss 0.4402 (0.4399)	Training Prec@1 92.188 (91.155)	Training Prec@5 95.312 (94.449)	
2022-03-27 23:02:18,910: ============================================================
2022-03-27 23:04:02,886: time cost, forward:0.2854497586527178, backward:0.04163155354169903, data cost:0.726041853494188 
2022-03-27 23:04:02,887: ============================================================
2022-03-27 23:04:02,887: Epoch 22/26 Batch 900/7662 eta: 10:48:18.689547	Training Loss 0.4357 (0.4400)	Training Prec@1 90.625 (91.158)	Training Prec@5 93.945 (94.443)	
2022-03-27 23:04:02,887: ============================================================
2022-03-27 23:05:47,807: time cost, forward:0.2843522051791171, backward:0.041799532400595175, data cost:0.727027660614258 
2022-03-27 23:05:47,807: ============================================================
2022-03-27 23:05:47,807: Epoch 22/26 Batch 1000/7662 eta: 10:52:26.836086	Training Loss 0.4349 (0.4399)	Training Prec@1 93.750 (91.158)	Training Prec@5 97.070 (94.444)	
2022-03-27 23:05:47,807: ============================================================
2022-03-27 23:07:33,427: time cost, forward:0.2847572362238543, backward:0.042040395129258466, data cost:0.7266224109660071 
2022-03-27 23:07:33,428: ============================================================
2022-03-27 23:07:33,429: Epoch 22/26 Batch 1100/7662 eta: 10:55:02.769971	Training Loss 0.4452 (0.4399)	Training Prec@1 91.992 (91.167)	Training Prec@5 94.141 (94.448)	
2022-03-27 23:07:33,429: ============================================================
2022-03-27 23:09:19,172: time cost, forward:0.2845176077565121, backward:0.04225148470626462, data cost:0.7270826321029982 
2022-03-27 23:09:19,173: ============================================================
2022-03-27 23:09:19,173: Epoch 22/26 Batch 1200/7662 eta: 10:54:02.790756	Training Loss 0.4631 (0.4399)	Training Prec@1 89.258 (91.158)	Training Prec@5 92.383 (94.444)	
2022-03-27 23:09:19,173: ============================================================
2022-03-27 23:11:03,364: time cost, forward:0.28469369409633105, backward:0.042388058516316635, data cost:0.7258353104859339 
2022-03-27 23:11:03,365: ============================================================
2022-03-27 23:11:03,365: Epoch 22/26 Batch 1300/7662 eta: 10:42:42.426877	Training Loss 0.4485 (0.4400)	Training Prec@1 91.797 (91.153)	Training Prec@5 94.727 (94.440)	
2022-03-27 23:11:03,365: ============================================================
2022-03-27 23:12:44,627: time cost, forward:0.2837497961359249, backward:0.042496796417781674, data cost:0.7234672353129629 
2022-03-27 23:12:44,628: ============================================================
2022-03-27 23:12:44,628: Epoch 22/26 Batch 1400/7662 eta: 10:22:57.161381	Training Loss 0.4393 (0.4401)	Training Prec@1 92.969 (91.165)	Training Prec@5 95.703 (94.443)	
2022-03-27 23:12:44,628: ============================================================
2022-03-27 23:14:28,484: time cost, forward:0.28409139373606246, backward:0.042488809423974705, data cost:0.7226364536234504 
2022-03-27 23:14:28,484: ============================================================
2022-03-27 23:14:28,484: Epoch 22/26 Batch 1500/7662 eta: 10:37:10.614163	Training Loss 0.4412 (0.4401)	Training Prec@1 91.602 (91.171)	Training Prec@5 94.727 (94.442)	
2022-03-27 23:14:28,484: ============================================================
2022-03-27 23:16:11,829: time cost, forward:0.28394259669916416, backward:0.0425619630235072, data cost:0.7215467924770524 
2022-03-27 23:16:11,829: ============================================================
2022-03-27 23:16:11,829: Epoch 22/26 Batch 1600/7662 eta: 10:32:18.926769	Training Loss 0.4393 (0.4400)	Training Prec@1 92.578 (91.182)	Training Prec@5 95.703 (94.444)	
2022-03-27 23:16:11,829: ============================================================
2022-03-27 23:17:53,510: time cost, forward:0.2831086072590577, backward:0.0427509281760177, data cost:0.720408873673114 
2022-03-27 23:17:53,512: ============================================================
2022-03-27 23:17:53,512: Epoch 22/26 Batch 1700/7662 eta: 10:20:27.115241	Training Loss 0.4459 (0.4400)	Training Prec@1 91.406 (91.187)	Training Prec@5 95.312 (94.444)	
2022-03-27 23:17:53,512: ============================================================
2022-03-27 23:19:35,686: time cost, forward:0.28343963039921943, backward:0.042712305041403824, data cost:0.7186721798577131 
2022-03-27 23:19:35,687: ============================================================
2022-03-27 23:19:35,688: Epoch 22/26 Batch 1800/7662 eta: 10:21:45.252031	Training Loss 0.4435 (0.4400)	Training Prec@1 90.234 (91.188)	Training Prec@5 93.555 (94.447)	
2022-03-27 23:19:35,688: ============================================================
2022-03-27 23:21:16,041: time cost, forward:0.2830177983087637, backward:0.042724976984057195, data cost:0.7168660593258827 
2022-03-27 23:21:16,042: ============================================================
2022-03-27 23:21:16,042: Epoch 22/26 Batch 1900/7662 eta: 10:09:00.039947	Training Loss 0.4562 (0.4400)	Training Prec@1 89.258 (91.203)	Training Prec@5 92.773 (94.456)	
2022-03-27 23:21:16,042: ============================================================
2022-03-27 23:23:01,573: time cost, forward:0.2832456524816974, backward:0.0428177808272117, data cost:0.7168853536971275 
2022-03-27 23:23:01,574: ============================================================
2022-03-27 23:23:01,574: Epoch 22/26 Batch 2000/7662 eta: 10:38:39.739434	Training Loss 0.4389 (0.4400)	Training Prec@1 91.602 (91.208)	Training Prec@5 94.531 (94.460)	
2022-03-27 23:23:01,574: ============================================================
2022-03-27 23:24:43,603: time cost, forward:0.2828193266315651, backward:0.04289923934155047, data cost:0.7165388399899262 
2022-03-27 23:24:43,603: ============================================================
2022-03-27 23:24:43,603: Epoch 22/26 Batch 2100/7662 eta: 10:15:45.914939	Training Loss 0.4322 (0.4400)	Training Prec@1 92.773 (91.208)	Training Prec@5 94.727 (94.458)	
2022-03-27 23:24:43,604: ============================================================
2022-03-27 23:26:24,302: time cost, forward:0.28219466905476775, backward:0.04286580987820142, data cost:0.7155641878448111 
2022-03-27 23:26:24,302: ============================================================
2022-03-27 23:26:24,302: Epoch 22/26 Batch 2200/7662 eta: 10:06:03.381323	Training Loss 0.4476 (0.4401)	Training Prec@1 90.234 (91.199)	Training Prec@5 94.336 (94.448)	
2022-03-27 23:26:24,303: ============================================================
2022-03-27 23:28:00,500: time cost, forward:0.28086678149027117, backward:0.042911759870578124, data cost:0.7133995667391624 
2022-03-27 23:28:00,501: ============================================================
2022-03-27 23:28:00,501: Epoch 22/26 Batch 2300/7662 eta: 9:37:22.069022	Training Loss 0.4569 (0.4401)	Training Prec@1 89.453 (91.194)	Training Prec@5 93.945 (94.445)	
2022-03-27 23:28:00,501: ============================================================
2022-03-27 23:29:42,303: time cost, forward:0.28065088402484545, backward:0.042942699068235626, data cost:0.7127898182656279 
2022-03-27 23:29:42,304: ============================================================
2022-03-27 23:29:42,304: Epoch 22/26 Batch 2400/7662 eta: 10:09:18.436450	Training Loss 0.4499 (0.4401)	Training Prec@1 89.844 (91.186)	Training Prec@5 95.117 (94.441)	
2022-03-27 23:29:42,304: ============================================================
2022-03-27 23:31:23,616: time cost, forward:0.28019819950380054, backward:0.04295241074258683, data cost:0.7122470839303129 
2022-03-27 23:31:23,617: ============================================================
2022-03-27 23:31:23,617: Epoch 22/26 Batch 2500/7662 eta: 10:04:41.214725	Training Loss 0.4373 (0.4400)	Training Prec@1 92.773 (91.189)	Training Prec@5 95.508 (94.442)	
2022-03-27 23:31:23,617: ============================================================
2022-03-27 23:33:09,662: time cost, forward:0.280597184886837, backward:0.043014488847680436, data cost:0.7127614106614574 
2022-03-27 23:33:09,663: ============================================================
2022-03-27 23:33:09,663: Epoch 22/26 Batch 2600/7662 eta: 10:31:10.109454	Training Loss 0.4425 (0.4401)	Training Prec@1 91.406 (91.186)	Training Prec@5 94.531 (94.436)	
2022-03-27 23:33:09,663: ============================================================
2022-03-27 23:34:50,707: time cost, forward:0.2805614072157304, backward:0.04299109147274304, data cost:0.7115340227548967 
2022-03-27 23:34:50,707: ============================================================
2022-03-27 23:34:50,707: Epoch 22/26 Batch 2700/7662 eta: 9:59:42.917710	Training Loss 0.4463 (0.4401)	Training Prec@1 90.234 (91.188)	Training Prec@5 93.164 (94.437)	
2022-03-27 23:34:50,707: ============================================================
2022-03-27 23:36:32,599: time cost, forward:0.2808512432654443, backward:0.04299011175953605, data cost:0.7106714627707844 
2022-03-27 23:36:32,600: ============================================================
2022-03-27 23:36:32,601: Epoch 22/26 Batch 2800/7662 eta: 10:03:03.221920	Training Loss 0.4384 (0.4400)	Training Prec@1 92.188 (91.199)	Training Prec@5 95.508 (94.442)	
2022-03-27 23:36:32,601: ============================================================
2022-03-27 23:38:14,967: time cost, forward:0.2809502906575619, backward:0.043180607071659736, data cost:0.7102869835834168 
2022-03-27 23:38:14,968: ============================================================
2022-03-27 23:38:14,968: Epoch 22/26 Batch 2900/7662 eta: 10:04:09.342025	Training Loss 0.4418 (0.4400)	Training Prec@1 92.383 (91.201)	Training Prec@5 95.312 (94.444)	
2022-03-27 23:38:14,968: ============================================================
2022-03-27 23:39:58,949: time cost, forward:0.28124366048257643, backward:0.04325462349576527, data cost:0.7100795076147005 
2022-03-27 23:39:58,949: ============================================================
2022-03-27 23:39:58,950: Epoch 22/26 Batch 3000/7662 eta: 10:11:57.016120	Training Loss 0.4491 (0.4400)	Training Prec@1 90.039 (91.197)	Training Prec@5 93.164 (94.442)	
2022-03-27 23:39:58,950: ============================================================
2022-03-27 23:41:40,911: time cost, forward:0.28137722512374735, backward:0.04317197071886632, data cost:0.7094878292576118 
2022-03-27 23:41:40,911: ============================================================
2022-03-27 23:41:40,911: Epoch 22/26 Batch 3100/7662 eta: 9:58:21.629489	Training Loss 0.4420 (0.4401)	Training Prec@1 90.039 (91.190)	Training Prec@5 93.945 (94.439)	
2022-03-27 23:41:40,911: ============================================================
2022-03-27 23:43:23,310: time cost, forward:0.28145883306185504, backward:0.043246901679985524, data cost:0.7087985058433006 
2022-03-27 23:43:23,311: ============================================================
2022-03-27 23:43:23,312: Epoch 22/26 Batch 3200/7662 eta: 9:59:13.850793	Training Loss 0.4374 (0.4401)	Training Prec@1 90.234 (91.190)	Training Prec@5 93.750 (94.440)	
2022-03-27 23:43:23,312: ============================================================
2022-03-27 23:45:04,590: time cost, forward:0.28171689389654636, backward:0.04331169832327323, data cost:0.7080955908637439 
2022-03-27 23:45:04,591: ============================================================
2022-03-27 23:45:04,591: Epoch 22/26 Batch 3300/7662 eta: 9:50:58.976516	Training Loss 0.4381 (0.4401)	Training Prec@1 89.453 (91.186)	Training Prec@5 94.531 (94.434)	
2022-03-27 23:45:04,591: ============================================================
2022-03-27 23:46:46,932: time cost, forward:0.2814683141901971, backward:0.043359277037249906, data cost:0.707969047981839 
2022-03-27 23:46:46,932: ============================================================
2022-03-27 23:46:46,933: Epoch 22/26 Batch 3400/7662 eta: 9:55:28.425349	Training Loss 0.4376 (0.4401)	Training Prec@1 92.969 (91.192)	Training Prec@5 97.070 (94.437)	
2022-03-27 23:46:46,933: ============================================================
2022-03-27 23:48:29,093: time cost, forward:0.2813637729507407, backward:0.04337514601764968, data cost:0.707577809567927 
2022-03-27 23:48:29,094: ============================================================
2022-03-27 23:48:29,095: Epoch 22/26 Batch 3500/7662 eta: 9:52:43.565994	Training Loss 0.4449 (0.4401)	Training Prec@1 88.867 (91.193)	Training Prec@5 92.578 (94.436)	
2022-03-27 23:48:29,095: ============================================================
2022-03-27 23:50:09,611: time cost, forward:0.2813085695543896, backward:0.04331231276238418, data cost:0.707074445431416 
2022-03-27 23:50:09,611: ============================================================
2022-03-27 23:50:09,611: Epoch 22/26 Batch 3600/7662 eta: 9:41:30.383609	Training Loss 0.4467 (0.4401)	Training Prec@1 90.625 (91.195)	Training Prec@5 93.359 (94.440)	
2022-03-27 23:50:09,611: ============================================================
2022-03-27 23:51:53,178: time cost, forward:0.28136549836463237, backward:0.04339504506208343, data cost:0.7070334875509525 
2022-03-27 23:51:53,178: ============================================================
2022-03-27 23:51:53,179: Epoch 22/26 Batch 3700/7662 eta: 9:57:25.698366	Training Loss 0.4357 (0.4402)	Training Prec@1 91.602 (91.189)	Training Prec@5 94.922 (94.439)	
2022-03-27 23:51:53,179: ============================================================
2022-03-27 23:53:34,934: time cost, forward:0.28120775729864955, backward:0.043418008297736725, data cost:0.7067710320928844 
2022-03-27 23:53:34,935: ============================================================
2022-03-27 23:53:34,935: Epoch 22/26 Batch 3800/7662 eta: 9:45:17.121620	Training Loss 0.4396 (0.4401)	Training Prec@1 92.773 (91.191)	Training Prec@5 94.336 (94.437)	
2022-03-27 23:53:34,935: ============================================================
2022-03-27 23:55:15,514: time cost, forward:0.28107051605993616, backward:0.04340625072204324, data cost:0.7062763333106598 
2022-03-27 23:55:15,515: ============================================================
2022-03-27 23:55:15,515: Epoch 22/26 Batch 3900/7662 eta: 9:36:50.601823	Training Loss 0.4399 (0.4401)	Training Prec@1 93.750 (91.185)	Training Prec@5 95.508 (94.433)	
2022-03-27 23:55:15,515: ============================================================
2022-03-27 23:56:57,091: time cost, forward:0.2808184238575971, backward:0.0434167277786129, data cost:0.7059345617387318 
2022-03-27 23:56:57,092: ============================================================
2022-03-27 23:56:57,092: Epoch 22/26 Batch 4000/7662 eta: 9:40:52.201580	Training Loss 0.4358 (0.4402)	Training Prec@1 90.430 (91.181)	Training Prec@5 93.945 (94.429)	
2022-03-27 23:56:57,093: ============================================================
2022-03-27 23:58:39,392: time cost, forward:0.28088825526659766, backward:0.04340649180425089, data cost:0.7058894135772266 
2022-03-27 23:58:39,393: ============================================================
2022-03-27 23:58:39,393: Epoch 22/26 Batch 4100/7662 eta: 9:43:17.999883	Training Loss 0.4460 (0.4402)	Training Prec@1 90.625 (91.180)	Training Prec@5 93.359 (94.427)	
2022-03-27 23:58:39,393: ============================================================
2022-03-28 00:00:21,218: time cost, forward:0.2808700391411015, backward:0.04337978050747949, data cost:0.7056172989924541 
2022-03-28 00:00:21,219: ============================================================
2022-03-28 00:00:21,219: Epoch 22/26 Batch 4200/7662 eta: 9:38:53.965826	Training Loss 0.4407 (0.4402)	Training Prec@1 90.234 (91.181)	Training Prec@5 93.164 (94.428)	
2022-03-28 00:00:21,219: ============================================================
2022-03-28 00:02:03,125: time cost, forward:0.28071015861095955, backward:0.043346598026890566, data cost:0.7055555066554373 
2022-03-28 00:02:03,125: ============================================================
2022-03-28 00:02:03,125: Epoch 22/26 Batch 4300/7662 eta: 9:37:39.302820	Training Loss 0.4454 (0.4402)	Training Prec@1 89.844 (91.180)	Training Prec@5 94.531 (94.428)	
2022-03-28 00:02:03,125: ============================================================
2022-03-28 00:03:46,894: time cost, forward:0.2807237996814413, backward:0.043364474762025325, data cost:0.7055343183286354 
2022-03-28 00:03:46,894: ============================================================
2022-03-28 00:03:46,894: Epoch 22/26 Batch 4400/7662 eta: 9:46:29.053864	Training Loss 0.4399 (0.4402)	Training Prec@1 90.625 (91.182)	Training Prec@5 95.508 (94.430)	
2022-03-28 00:03:46,894: ============================================================
2022-03-28 00:05:27,510: time cost, forward:0.2806705195894769, backward:0.04340581863184562, data cost:0.7051854402813866 
2022-03-28 00:05:27,510: ============================================================
2022-03-28 00:05:27,510: Epoch 22/26 Batch 4500/7662 eta: 9:26:59.266388	Training Loss 0.4499 (0.4403)	Training Prec@1 90.430 (91.174)	Training Prec@5 94.531 (94.423)	
2022-03-28 00:05:27,510: ============================================================
2022-03-28 00:07:06,964: time cost, forward:0.280500129607222, backward:0.04336975361632637, data cost:0.7046236228776979 
2022-03-28 00:07:06,966: ============================================================
2022-03-28 00:07:06,966: Epoch 22/26 Batch 4600/7662 eta: 9:18:47.634936	Training Loss 0.4373 (0.4403)	Training Prec@1 89.453 (91.173)	Training Prec@5 93.945 (94.424)	
2022-03-28 00:07:06,967: ============================================================
2022-03-28 00:08:50,125: time cost, forward:0.28042667722367154, backward:0.043376781555357624, data cost:0.7047716678267059 
2022-03-28 00:08:50,125: ============================================================
2022-03-28 00:08:50,125: Epoch 22/26 Batch 4700/7662 eta: 9:37:52.856085	Training Loss 0.4521 (0.4403)	Training Prec@1 88.672 (91.172)	Training Prec@5 91.992 (94.425)	
2022-03-28 00:08:50,125: ============================================================
2022-03-28 00:10:30,986: time cost, forward:0.28032202108573556, backward:0.043365609871891544, data cost:0.7044510893534561 
2022-03-28 00:10:30,986: ============================================================
2022-03-28 00:10:30,986: Epoch 22/26 Batch 4800/7662 eta: 9:23:19.434973	Training Loss 0.4355 (0.4403)	Training Prec@1 91.797 (91.172)	Training Prec@5 95.117 (94.425)	
2022-03-28 00:10:30,986: ============================================================
2022-03-28 00:12:10,769: time cost, forward:0.28023153890223135, backward:0.043295164550170774, data cost:0.7039829446578858 
2022-03-28 00:12:10,770: ============================================================
2022-03-28 00:12:10,770: Epoch 22/26 Batch 4900/7662 eta: 9:15:38.698547	Training Loss 0.4303 (0.4403)	Training Prec@1 90.820 (91.174)	Training Prec@5 93.750 (94.425)	
2022-03-28 00:12:10,770: ============================================================
2022-03-28 00:13:52,459: time cost, forward:0.28023461991249266, backward:0.04330473629134396, data cost:0.7036706294315198 
2022-03-28 00:13:52,460: ============================================================
2022-03-28 00:13:52,460: Epoch 22/26 Batch 5000/7662 eta: 9:24:34.085532	Training Loss 0.4559 (0.4403)	Training Prec@1 89.062 (91.171)	Training Prec@5 93.164 (94.423)	
2022-03-28 00:13:52,460: ============================================================
2022-03-28 00:15:32,641: time cost, forward:0.280010598293588, backward:0.04328417581631918, data cost:0.7034316173275912 
2022-03-28 00:15:32,642: ============================================================
2022-03-28 00:15:32,643: Epoch 22/26 Batch 5100/7662 eta: 9:14:31.599664	Training Loss 0.4341 (0.4403)	Training Prec@1 92.578 (91.175)	Training Prec@5 94.727 (94.426)	
2022-03-28 00:15:32,643: ============================================================
2022-03-28 00:17:14,357: time cost, forward:0.27995538321750213, backward:0.04329697749641772, data cost:0.7033671497220969 
2022-03-28 00:17:14,358: ============================================================
2022-03-28 00:17:14,358: Epoch 22/26 Batch 5200/7662 eta: 9:21:18.949142	Training Loss 0.4433 (0.4403)	Training Prec@1 91.992 (91.173)	Training Prec@5 94.336 (94.425)	
2022-03-28 00:17:14,358: ============================================================
2022-03-28 00:18:52,877: time cost, forward:0.2797183330429345, backward:0.04329369031701319, data cost:0.702808618140594 
2022-03-28 00:18:52,878: ============================================================
2022-03-28 00:18:52,878: Epoch 22/26 Batch 5300/7662 eta: 9:02:02.595547	Training Loss 0.4312 (0.4403)	Training Prec@1 90.430 (91.177)	Training Prec@5 94.141 (94.428)	
2022-03-28 00:18:52,879: ============================================================
2022-03-28 00:20:36,168: time cost, forward:0.27983565532757104, backward:0.043271683834066745, data cost:0.7026939710923358 
2022-03-28 00:20:36,169: ============================================================
2022-03-28 00:20:36,169: Epoch 22/26 Batch 5400/7662 eta: 9:26:33.968837	Training Loss 0.4464 (0.4404)	Training Prec@1 91.992 (91.174)	Training Prec@5 94.531 (94.427)	
2022-03-28 00:20:36,169: ============================================================
2022-03-28 00:22:17,083: time cost, forward:0.2797801714850504, backward:0.04323009305226627, data cost:0.7026156367638215 
2022-03-28 00:22:17,083: ============================================================
2022-03-28 00:22:17,084: Epoch 22/26 Batch 5500/7662 eta: 9:11:51.045330	Training Loss 0.4325 (0.4404)	Training Prec@1 92.773 (91.174)	Training Prec@5 96.289 (94.427)	
2022-03-28 00:22:17,084: ============================================================
2022-03-28 00:23:57,302: time cost, forward:0.2797504814847662, backward:0.04323187094114576, data cost:0.7022252863785011 
2022-03-28 00:23:57,303: ============================================================
2022-03-28 00:23:57,303: Epoch 22/26 Batch 5600/7662 eta: 9:06:22.807373	Training Loss 0.4455 (0.4404)	Training Prec@1 90.039 (91.172)	Training Prec@5 93.359 (94.429)	
2022-03-28 00:23:57,303: ============================================================
2022-03-28 00:25:38,618: time cost, forward:0.27963989118585086, backward:0.0432706149466562, data cost:0.7020784025967048 
2022-03-28 00:25:38,618: ============================================================
2022-03-28 00:25:38,619: Epoch 22/26 Batch 5700/7662 eta: 9:10:40.017383	Training Loss 0.4527 (0.4404)	Training Prec@1 90.234 (91.174)	Training Prec@5 92.773 (94.429)	
2022-03-28 00:25:38,619: ============================================================
2022-03-28 00:27:21,695: time cost, forward:0.2798308280649463, backward:0.043279052870214794, data cost:0.7019261940118876 
2022-03-28 00:27:21,696: ============================================================
2022-03-28 00:27:21,696: Epoch 22/26 Batch 5800/7662 eta: 9:18:31.416612	Training Loss 0.4387 (0.4404)	Training Prec@1 92.578 (91.174)	Training Prec@5 95.117 (94.429)	
2022-03-28 00:27:21,696: ============================================================
2022-03-28 00:29:00,283: time cost, forward:0.2798123797393892, backward:0.04310878835950671, data cost:0.7014749121273912 
2022-03-28 00:29:00,284: ============================================================
2022-03-28 00:29:00,284: Epoch 22/26 Batch 5900/7662 eta: 8:52:33.438919	Training Loss 0.4458 (0.4404)	Training Prec@1 91.406 (91.173)	Training Prec@5 93.945 (94.427)	
2022-03-28 00:29:00,284: ============================================================
2022-03-28 00:30:39,698: time cost, forward:0.2800437408519757, backward:0.04291788970138415, data cost:0.7009222551194165 
2022-03-28 00:30:39,698: ============================================================
2022-03-28 00:30:39,699: Epoch 22/26 Batch 6000/7662 eta: 8:55:21.817862	Training Loss 0.4524 (0.4404)	Training Prec@1 90.039 (91.176)	Training Prec@5 93.164 (94.429)	
2022-03-28 00:30:39,699: ============================================================
2022-03-28 00:32:21,418: time cost, forward:0.2801036352719571, backward:0.042729897506120926, data cost:0.7009517280248995 
2022-03-28 00:32:21,418: ============================================================
2022-03-28 00:32:21,418: Epoch 22/26 Batch 6100/7662 eta: 9:06:04.955254	Training Loss 0.4413 (0.4404)	Training Prec@1 91.406 (91.178)	Training Prec@5 94.727 (94.430)	
2022-03-28 00:32:21,418: ============================================================
2022-03-28 00:34:02,798: time cost, forward:0.2800505172054428, backward:0.042716461490250185, data cost:0.7008134744151558 
2022-03-28 00:34:02,798: ============================================================
2022-03-28 00:34:02,798: Epoch 22/26 Batch 6200/7662 eta: 9:02:34.085366	Training Loss 0.4503 (0.4404)	Training Prec@1 91.016 (91.175)	Training Prec@5 95.117 (94.427)	
2022-03-28 00:34:02,798: ============================================================
2022-03-28 00:35:44,732: time cost, forward:0.279968350969585, backward:0.04271795295840086, data cost:0.7008626880409566 
2022-03-28 00:35:44,732: ============================================================
2022-03-28 00:35:44,732: Epoch 22/26 Batch 6300/7662 eta: 9:03:50.107933	Training Loss 0.4424 (0.4404)	Training Prec@1 90.820 (91.178)	Training Prec@5 95.117 (94.429)	
2022-03-28 00:35:44,732: ============================================================
2022-03-28 00:37:24,749: time cost, forward:0.27979967087055485, backward:0.04274048345464154, data cost:0.7005698826559299 
2022-03-28 00:37:24,751: ============================================================
2022-03-28 00:37:24,751: Epoch 22/26 Batch 6400/7662 eta: 8:51:56.948984	Training Loss 0.4244 (0.4405)	Training Prec@1 92.188 (91.178)	Training Prec@5 95.117 (94.430)	
2022-03-28 00:37:24,751: ============================================================
2022-03-28 00:39:06,445: time cost, forward:0.27995040123600984, backward:0.04272962863820574, data cost:0.7003658114992521 
2022-03-28 00:39:06,445: ============================================================
2022-03-28 00:39:06,445: Epoch 22/26 Batch 6500/7662 eta: 8:59:09.990666	Training Loss 0.4546 (0.4405)	Training Prec@1 89.258 (91.179)	Training Prec@5 91.406 (94.431)	
2022-03-28 00:39:06,445: ============================================================
2022-03-28 00:40:46,465: time cost, forward:0.2798423602339318, backward:0.042761600022967035, data cost:0.7001202456209402 
2022-03-28 00:40:46,466: ============================================================
2022-03-28 00:40:46,466: Epoch 22/26 Batch 6600/7662 eta: 8:48:37.569614	Training Loss 0.4301 (0.4405)	Training Prec@1 93.945 (91.178)	Training Prec@5 96.289 (94.432)	
2022-03-28 00:40:46,466: ============================================================
2022-03-28 00:42:28,099: time cost, forward:0.2799285001622365, backward:0.04277663281434044, data cost:0.6999012424191675 
2022-03-28 00:42:28,099: ============================================================
2022-03-28 00:42:28,099: Epoch 22/26 Batch 6700/7662 eta: 8:55:27.292912	Training Loss 0.4433 (0.4405)	Training Prec@1 89.648 (91.175)	Training Prec@5 95.117 (94.432)	
2022-03-28 00:42:28,099: ============================================================
2022-03-28 00:44:06,873: time cost, forward:0.2797545381356099, backward:0.042795755912633765, data cost:0.6994319541048594 
2022-03-28 00:44:06,874: ============================================================
2022-03-28 00:44:06,875: Epoch 22/26 Batch 6800/7662 eta: 8:38:45.129192	Training Loss 0.4437 (0.4405)	Training Prec@1 91.016 (91.173)	Training Prec@5 94.141 (94.431)	
2022-03-28 00:44:06,875: ============================================================
2022-03-28 00:45:45,099: time cost, forward:0.2797231287485552, backward:0.042813682991588504, data cost:0.6989928755765031 
2022-03-28 00:45:45,100: ============================================================
2022-03-28 00:45:45,100: Epoch 22/26 Batch 6900/7662 eta: 8:34:13.502125	Training Loss 0.4457 (0.4405)	Training Prec@1 90.430 (91.170)	Training Prec@5 93.359 (94.430)	
2022-03-28 00:45:45,100: ============================================================
2022-03-28 00:47:22,162: time cost, forward:0.2796996020984609, backward:0.042782087294710315, data cost:0.6983092328210714 
2022-03-28 00:47:22,163: ============================================================
2022-03-28 00:47:22,163: Epoch 22/26 Batch 7000/7662 eta: 8:26:31.390320	Training Loss 0.4254 (0.4405)	Training Prec@1 93.359 (91.169)	Training Prec@5 95.117 (94.429)	
2022-03-28 00:47:22,163: ============================================================
2022-03-28 00:49:03,119: time cost, forward:0.27957493514305337, backward:0.04278615418076935, data cost:0.6983088105979949 
2022-03-28 00:49:03,119: ============================================================
2022-03-28 00:49:03,120: Epoch 22/26 Batch 7100/7662 eta: 8:45:09.596185	Training Loss 0.4415 (0.4405)	Training Prec@1 90.625 (91.166)	Training Prec@5 93.359 (94.429)	
2022-03-28 00:49:03,120: ============================================================
2022-03-28 00:50:27,714: time cost, forward:0.27896018242865805, backward:0.04276909816925816, data cost:0.6964142911383503 
2022-03-28 00:50:27,715: ============================================================
2022-03-28 00:50:27,716: Epoch 22/26 Batch 7200/7662 eta: 7:18:38.659321	Training Loss 0.4380 (0.4405)	Training Prec@1 91.016 (91.168)	Training Prec@5 94.141 (94.431)	
2022-03-28 00:50:27,716: ============================================================
2022-03-28 00:52:06,127: time cost, forward:0.2787377327692837, backward:0.04278985087651719, data cost:0.696195170983564 
2022-03-28 00:52:06,128: ============================================================
2022-03-28 00:52:06,128: Epoch 22/26 Batch 7300/7662 eta: 8:28:38.615393	Training Loss 0.4520 (0.4405)	Training Prec@1 89.648 (91.168)	Training Prec@5 93.164 (94.431)	
2022-03-28 00:52:06,128: ============================================================
2022-03-28 00:53:46,416: time cost, forward:0.27865038650843693, backward:0.04278122668234718, data cost:0.6960903231977433 
2022-03-28 00:53:46,417: ============================================================
2022-03-28 00:53:46,417: Epoch 22/26 Batch 7400/7662 eta: 8:36:40.416816	Training Loss 0.4303 (0.4405)	Training Prec@1 91.406 (91.169)	Training Prec@5 96.680 (94.432)	
2022-03-28 00:53:46,417: ============================================================
2022-03-28 00:55:27,475: time cost, forward:0.2784954990318798, backward:0.0427933721991281, data cost:0.6961294253487034 
2022-03-28 00:55:27,476: ============================================================
2022-03-28 00:55:27,476: Epoch 22/26 Batch 7500/7662 eta: 8:38:57.246329	Training Loss 0.4471 (0.4405)	Training Prec@1 89.844 (91.168)	Training Prec@5 95.312 (94.431)	
2022-03-28 00:55:27,476: ============================================================
2022-03-28 00:57:09,402: time cost, forward:0.2785073222416234, backward:0.04282492323131338, data cost:0.6961097054017784 
2022-03-28 00:57:09,402: ============================================================
2022-03-28 00:57:09,402: Epoch 22/26 Batch 7600/7662 eta: 8:41:42.619177	Training Loss 0.4455 (0.4405)	Training Prec@1 91.406 (91.169)	Training Prec@5 95.117 (94.433)	
2022-03-28 00:57:09,402: ============================================================
2022-03-28 00:58:14,791: Epoch: 22/26 eta: 8:40:38.405540	Training Loss 0.4388 (0.4405)	Training Prec@1 92.383 (91.168)	Training Prec@5 95.117 (94.433)
2022-03-28 00:58:14,791: ============================================================
2022-03-28 00:59:54,715: time cost, forward:0.26552614298733795, backward:0.0402754196012863, data cost:0.690224370571098 
2022-03-28 00:59:54,715: ============================================================
2022-03-28 00:59:54,716: Epoch 23/26 Batch 100/7662 eta: 8:28:44.555798	Training Loss 0.4378 (0.4381)	Training Prec@1 92.773 (91.388)	Training Prec@5 95.703 (94.681)	
2022-03-28 00:59:54,716: ============================================================
2022-03-28 01:01:31,650: time cost, forward:0.26777721769246626, backward:0.04212121508229318, data cost:0.6761320919247727 
2022-03-28 01:01:31,651: ============================================================
2022-03-28 01:01:31,651: Epoch 23/26 Batch 200/7662 eta: 8:11:55.807607	Training Loss 0.4408 (0.4379)	Training Prec@1 91.797 (91.422)	Training Prec@5 95.508 (94.656)	
2022-03-28 01:01:31,651: ============================================================
2022-03-28 01:03:16,459: time cost, forward:0.2713483416515848, backward:0.04270703417800342, data cost:0.6929786492350907 
2022-03-28 01:03:16,459: ============================================================
2022-03-28 01:03:16,460: Epoch 23/26 Batch 300/7662 eta: 8:50:08.338410	Training Loss 0.4367 (0.4379)	Training Prec@1 92.969 (91.421)	Training Prec@5 96.289 (94.617)	
2022-03-28 01:03:16,460: ============================================================
2022-03-28 01:04:55,164: time cost, forward:0.27479025833588794, backward:0.04242023788299178, data cost:0.684673377445766 
2022-03-28 01:04:55,164: ============================================================
2022-03-28 01:04:55,164: Epoch 23/26 Batch 400/7662 eta: 8:17:37.243406	Training Loss 0.4372 (0.4383)	Training Prec@1 90.234 (91.407)	Training Prec@5 93.945 (94.624)	
2022-03-28 01:04:55,165: ============================================================
2022-03-28 01:06:35,956: time cost, forward:0.27810307256205524, backward:0.042328177090876086, data cost:0.6812699825348023 
2022-03-28 01:06:35,957: ============================================================
2022-03-28 01:06:35,957: Epoch 23/26 Batch 500/7662 eta: 8:26:28.056407	Training Loss 0.4325 (0.4384)	Training Prec@1 91.992 (91.395)	Training Prec@5 94.922 (94.613)	
2022-03-28 01:06:35,958: ============================================================
2022-03-28 01:08:16,195: time cost, forward:0.27773314405960314, backward:0.042097595179817315, data cost:0.6830092666543187 
2022-03-28 01:08:16,195: ============================================================
2022-03-28 01:08:16,195: Epoch 23/26 Batch 600/7662 eta: 8:22:00.536798	Training Loss 0.4393 (0.4386)	Training Prec@1 92.383 (91.367)	Training Prec@5 95.508 (94.592)	
2022-03-28 01:08:16,196: ============================================================
2022-03-28 01:09:59,629: time cost, forward:0.28168814444917123, backward:0.04234081515256257, data cost:0.6832784770725452 
2022-03-28 01:09:59,630: ============================================================
2022-03-28 01:09:59,630: Epoch 23/26 Batch 700/7662 eta: 8:36:17.529637	Training Loss 0.4416 (0.4386)	Training Prec@1 92.773 (91.365)	Training Prec@5 94.922 (94.572)	
2022-03-28 01:09:59,630: ============================================================
2022-03-28 01:11:43,375: time cost, forward:0.2827480752417382, backward:0.042462369228931186, data cost:0.6858475649908875 
2022-03-28 01:11:43,375: ============================================================
2022-03-28 01:11:43,376: Epoch 23/26 Batch 800/7662 eta: 8:36:07.128468	Training Loss 0.4339 (0.4386)	Training Prec@1 93.164 (91.346)	Training Prec@5 95.312 (94.573)	
2022-03-28 01:11:43,376: ============================================================
2022-03-28 01:13:22,744: time cost, forward:0.2827390009357083, backward:0.042437815427514944, data cost:0.6837771893608424 
2022-03-28 01:13:22,744: ============================================================
2022-03-28 01:13:22,744: Epoch 23/26 Batch 900/7662 eta: 8:12:41.219396	Training Loss 0.4474 (0.4387)	Training Prec@1 91.211 (91.332)	Training Prec@5 94.141 (94.558)	
2022-03-28 01:13:22,745: ============================================================
2022-03-28 01:15:02,032: time cost, forward:0.28251530673052816, backward:0.04256212747132814, data cost:0.6819371074527592 
2022-03-28 01:15:02,033: ============================================================
2022-03-28 01:15:02,033: Epoch 23/26 Batch 1000/7662 eta: 8:10:38.039398	Training Loss 0.4412 (0.4386)	Training Prec@1 91.602 (91.355)	Training Prec@5 94.531 (94.570)	
2022-03-28 01:15:02,033: ============================================================
2022-03-28 01:16:41,319: time cost, forward:0.2818700564352353, backward:0.04275763262609008, data cost:0.6813726553166314 
2022-03-28 01:16:41,320: ============================================================
2022-03-28 01:16:41,320: Epoch 23/26 Batch 1100/7662 eta: 8:08:58.423472	Training Loss 0.4394 (0.4385)	Training Prec@1 91.406 (91.386)	Training Prec@5 95.508 (94.590)	
2022-03-28 01:16:41,321: ============================================================
2022-03-28 01:18:20,779: time cost, forward:0.2819083908182865, backward:0.04277150346598494, data cost:0.6802756040666976 
2022-03-28 01:18:20,779: ============================================================
2022-03-28 01:18:20,779: Epoch 23/26 Batch 1200/7662 eta: 8:08:09.656860	Training Loss 0.4324 (0.4385)	Training Prec@1 90.625 (91.380)	Training Prec@5 94.727 (94.590)	
2022-03-28 01:18:20,779: ============================================================
2022-03-28 01:20:00,221: time cost, forward:0.2813245137899632, backward:0.04273596353215195, data cost:0.6801034943519693 
2022-03-28 01:20:00,221: ============================================================
2022-03-28 01:20:00,222: Epoch 23/26 Batch 1300/7662 eta: 8:06:25.324919	Training Loss 0.4351 (0.4386)	Training Prec@1 92.773 (91.371)	Training Prec@5 94.922 (94.581)	
2022-03-28 01:20:00,222: ============================================================
2022-03-28 01:21:38,774: time cost, forward:0.2810101151210739, backward:0.042680080657860824, data cost:0.6791298720051 
2022-03-28 01:21:38,774: ============================================================
2022-03-28 01:21:38,774: Epoch 23/26 Batch 1400/7662 eta: 8:00:25.696460	Training Loss 0.4369 (0.4386)	Training Prec@1 91.016 (91.377)	Training Prec@5 94.727 (94.586)	
2022-03-28 01:21:38,774: ============================================================
2022-03-28 01:23:22,798: time cost, forward:0.2810003001980976, backward:0.042766694628134656, data cost:0.6815091672939328 
2022-03-28 01:23:22,798: ============================================================
2022-03-28 01:23:22,799: Epoch 23/26 Batch 1500/7662 eta: 8:25:22.051019	Training Loss 0.4313 (0.4387)	Training Prec@1 91.602 (91.364)	Training Prec@5 94.727 (94.581)	
2022-03-28 01:23:22,799: ============================================================
2022-03-28 01:24:59,249: time cost, forward:0.2801349279357166, backward:0.04275170827821466, data cost:0.6797679462158509 
2022-03-28 01:24:59,249: ============================================================
2022-03-28 01:24:59,250: Epoch 23/26 Batch 1600/7662 eta: 7:46:58.040525	Training Loss 0.4426 (0.4387)	Training Prec@1 91.602 (91.351)	Training Prec@5 94.922 (94.583)	
2022-03-28 01:24:59,250: ============================================================
2022-03-28 01:26:38,012: time cost, forward:0.2800555982752503, backward:0.04275131365914707, data cost:0.6790318810427589 
2022-03-28 01:26:38,013: ============================================================
2022-03-28 01:26:38,013: Epoch 23/26 Batch 1700/7662 eta: 7:56:30.928895	Training Loss 0.4344 (0.4387)	Training Prec@1 90.234 (91.356)	Training Prec@5 95.508 (94.585)	
2022-03-28 01:26:38,013: ============================================================
2022-03-28 01:28:18,333: time cost, forward:0.28016230992438595, backward:0.0427897268033412, data cost:0.6788555119288107 
2022-03-28 01:28:18,333: ============================================================
2022-03-28 01:28:18,334: Epoch 23/26 Batch 1800/7662 eta: 8:02:21.596652	Training Loss 0.4379 (0.4387)	Training Prec@1 91.016 (91.351)	Training Prec@5 94.141 (94.584)	
2022-03-28 01:28:18,334: ============================================================
2022-03-28 01:29:58,991: time cost, forward:0.2801044185642445, backward:0.042780376849141856, data cost:0.6792633202026994 
2022-03-28 01:29:58,992: ============================================================
2022-03-28 01:29:58,992: Epoch 23/26 Batch 1900/7662 eta: 8:02:18.191791	Training Loss 0.4291 (0.4388)	Training Prec@1 91.406 (91.349)	Training Prec@5 94.141 (94.581)	
2022-03-28 01:29:58,992: ============================================================
2022-03-28 01:31:40,600: time cost, forward:0.28050299893026653, backward:0.04274670286975305, data cost:0.6793656609188383 
2022-03-28 01:31:40,601: ============================================================
2022-03-28 01:31:40,601: Epoch 23/26 Batch 2000/7662 eta: 8:05:09.966362	Training Loss 0.4420 (0.4387)	Training Prec@1 91.602 (91.357)	Training Prec@5 95.117 (94.583)	
2022-03-28 01:31:40,601: ============================================================
2022-03-28 01:33:19,869: time cost, forward:0.27998551838508157, backward:0.04279492536347613, data cost:0.6794832547884319 
2022-03-28 01:33:19,870: ============================================================
2022-03-28 01:33:19,870: Epoch 23/26 Batch 2100/7662 eta: 7:52:20.277829	Training Loss 0.4331 (0.4388)	Training Prec@1 92.383 (91.354)	Training Prec@5 95.898 (94.578)	
2022-03-28 01:33:19,870: ============================================================
2022-03-28 01:35:00,917: time cost, forward:0.27990579865313814, backward:0.042843625566101766, data cost:0.6799153181139368 
2022-03-28 01:35:00,917: ============================================================
2022-03-28 01:35:00,917: Epoch 23/26 Batch 2200/7662 eta: 7:59:06.963634	Training Loss 0.4361 (0.4388)	Training Prec@1 91.016 (91.348)	Training Prec@5 93.945 (94.573)	
2022-03-28 01:35:00,917: ============================================================
2022-03-28 01:36:40,941: time cost, forward:0.27982126510158833, backward:0.04283035822980764, data cost:0.6798998044334634 
2022-03-28 01:36:40,941: ============================================================
2022-03-28 01:36:40,942: Epoch 23/26 Batch 2300/7662 eta: 7:52:35.953518	Training Loss 0.4493 (0.4389)	Training Prec@1 90.039 (91.350)	Training Prec@5 92.773 (94.574)	
2022-03-28 01:36:40,942: ============================================================
2022-03-28 01:38:21,198: time cost, forward:0.27947307875276656, backward:0.04285787085087511, data cost:0.6800706634028547 
2022-03-28 01:38:21,199: ============================================================
2022-03-28 01:38:21,200: Epoch 23/26 Batch 2400/7662 eta: 7:52:01.930143	Training Loss 0.4342 (0.4389)	Training Prec@1 90.234 (91.339)	Training Prec@5 93.555 (94.569)	
2022-03-28 01:38:21,200: ============================================================
2022-03-28 01:40:03,275: time cost, forward:0.27969865361992574, backward:0.04288523184771345, data cost:0.6806765373538332 
2022-03-28 01:40:03,275: ============================================================
2022-03-28 01:40:03,275: Epoch 23/26 Batch 2500/7662 eta: 7:58:53.272900	Training Loss 0.4299 (0.4390)	Training Prec@1 92.773 (91.332)	Training Prec@5 95.312 (94.560)	
2022-03-28 01:40:03,276: ============================================================
2022-03-28 01:41:40,586: time cost, forward:0.2791912921716177, backward:0.04260247007797846, data cost:0.6800629592666538 
2022-03-28 01:41:40,586: ============================================================
2022-03-28 01:41:40,587: Epoch 23/26 Batch 2600/7662 eta: 7:34:54.808029	Training Loss 0.4446 (0.4390)	Training Prec@1 90.039 (91.334)	Training Prec@5 92.969 (94.561)	
2022-03-28 01:41:40,587: ============================================================
2022-03-28 01:43:19,169: time cost, forward:0.27874495568828433, backward:0.04256054682835865, data cost:0.6801507223884721 
2022-03-28 01:43:19,169: ============================================================
2022-03-28 01:43:19,170: Epoch 23/26 Batch 2700/7662 eta: 7:39:12.959523	Training Loss 0.4304 (0.4389)	Training Prec@1 90.625 (91.333)	Training Prec@5 94.141 (94.559)	
2022-03-28 01:43:19,170: ============================================================
2022-03-28 01:44:59,477: time cost, forward:0.2784939550765713, backward:0.04257448335424752, data cost:0.6804312864939371 
2022-03-28 01:44:59,478: ============================================================
2022-03-28 01:44:59,478: Epoch 23/26 Batch 2800/7662 eta: 7:45:34.845591	Training Loss 0.4253 (0.4389)	Training Prec@1 93.945 (91.330)	Training Prec@5 96.094 (94.559)	
2022-03-28 01:44:59,478: ============================================================
2022-03-28 01:46:38,043: time cost, forward:0.27850328358587373, backward:0.04255303821715045, data cost:0.6797657341906103 
2022-03-28 01:46:38,043: ============================================================
2022-03-28 01:46:38,043: Epoch 23/26 Batch 2900/7662 eta: 7:35:50.886946	Training Loss 0.4541 (0.4390)	Training Prec@1 90.430 (91.328)	Training Prec@5 95.703 (94.560)	
2022-03-28 01:46:38,043: ============================================================
2022-03-28 01:48:17,412: time cost, forward:0.27846423042897744, backward:0.0425315947880861, data cost:0.6795164390022097 
2022-03-28 01:48:17,412: ============================================================
2022-03-28 01:48:17,413: Epoch 23/26 Batch 3000/7662 eta: 7:37:54.637634	Training Loss 0.4428 (0.4390)	Training Prec@1 90.234 (91.330)	Training Prec@5 93.750 (94.560)	
2022-03-28 01:48:17,413: ============================================================
2022-03-28 01:49:54,797: time cost, forward:0.27786682228305026, backward:0.0425243778511877, data cost:0.679427361865319 
2022-03-28 01:49:54,797: ============================================================
2022-03-28 01:49:54,797: Epoch 23/26 Batch 3100/7662 eta: 7:27:08.554304	Training Loss 0.4337 (0.4390)	Training Prec@1 94.141 (91.334)	Training Prec@5 96.875 (94.559)	
2022-03-28 01:49:54,797: ============================================================
2022-03-28 01:51:35,161: time cost, forward:0.2778014443598154, backward:0.042546365588260616, data cost:0.6794549505127039 
2022-03-28 01:51:35,162: ============================================================
2022-03-28 01:51:35,162: Epoch 23/26 Batch 3200/7662 eta: 7:39:09.003975	Training Loss 0.4308 (0.4390)	Training Prec@1 93.359 (91.323)	Training Prec@5 96.289 (94.552)	
2022-03-28 01:51:35,162: ============================================================
2022-03-28 01:53:11,844: time cost, forward:0.27765261400609564, backward:0.04263715680420995, data cost:0.6786396095123245 
2022-03-28 01:53:11,844: ============================================================
2022-03-28 01:53:11,845: Epoch 23/26 Batch 3300/7662 eta: 7:20:41.811263	Training Loss 0.4348 (0.4391)	Training Prec@1 90.820 (91.324)	Training Prec@5 94.727 (94.560)	
2022-03-28 01:53:11,845: ============================================================
2022-03-28 01:54:50,014: time cost, forward:0.2772766998074412, backward:0.04267604458363627, data cost:0.6784421045242179 
2022-03-28 01:54:50,015: ============================================================
2022-03-28 01:54:50,015: Epoch 23/26 Batch 3400/7662 eta: 7:25:50.354170	Training Loss 0.4367 (0.4391)	Training Prec@1 91.211 (91.324)	Training Prec@5 94.922 (94.558)	
2022-03-28 01:54:50,015: ============================================================
2022-03-28 01:56:28,158: time cost, forward:0.2771373903046134, backward:0.04273349341408598, data cost:0.6780263562650809 
2022-03-28 01:56:28,158: ============================================================
2022-03-28 01:56:28,158: Epoch 23/26 Batch 3500/7662 eta: 7:24:04.917283	Training Loss 0.4385 (0.4390)	Training Prec@1 90.625 (91.326)	Training Prec@5 95.508 (94.557)	
2022-03-28 01:56:28,158: ============================================================
2022-03-28 01:58:07,471: time cost, forward:0.27678759908238926, backward:0.04275928420734326, data cost:0.6780536669630182 
2022-03-28 01:58:07,471: ============================================================
2022-03-28 01:58:07,471: Epoch 23/26 Batch 3600/7662 eta: 7:27:43.265903	Training Loss 0.4367 (0.4390)	Training Prec@1 90.820 (91.326)	Training Prec@5 93.359 (94.558)	
2022-03-28 01:58:07,471: ============================================================
2022-03-28 01:59:47,354: time cost, forward:0.27652147132727095, backward:0.04280213866242849, data cost:0.678230833833235 
2022-03-28 01:59:47,355: ============================================================
2022-03-28 01:59:47,355: Epoch 23/26 Batch 3700/7662 eta: 7:28:37.702682	Training Loss 0.4446 (0.4390)	Training Prec@1 92.188 (91.327)	Training Prec@5 95.898 (94.555)	
2022-03-28 01:59:47,356: ============================================================
2022-03-28 02:01:29,212: time cost, forward:0.27654898433379044, backward:0.04282303143878082, data cost:0.6789474818040647 
2022-03-28 02:01:29,213: ============================================================
2022-03-28 02:01:29,213: Epoch 23/26 Batch 3800/7662 eta: 7:35:47.744712	Training Loss 0.4372 (0.4390)	Training Prec@1 92.188 (91.329)	Training Prec@5 94.531 (94.557)	
2022-03-28 02:01:29,213: ============================================================
2022-03-28 02:03:07,921: time cost, forward:0.2765234652223511, backward:0.04266454324137709, data cost:0.6788403187448717 
2022-03-28 02:03:07,921: ============================================================
2022-03-28 02:03:07,921: Epoch 23/26 Batch 3900/7662 eta: 7:20:03.526054	Training Loss 0.4416 (0.4390)	Training Prec@1 93.164 (91.329)	Training Prec@5 95.312 (94.558)	
2022-03-28 02:03:07,921: ============================================================
2022-03-28 02:04:46,941: time cost, forward:0.27630273900529273, backward:0.04237278845048481, data cost:0.6791393820063177 
2022-03-28 02:04:46,942: ============================================================
2022-03-28 02:04:46,942: Epoch 23/26 Batch 4000/7662 eta: 7:19:47.964453	Training Loss 0.4308 (0.4390)	Training Prec@1 93.750 (91.332)	Training Prec@5 96.680 (94.560)	
2022-03-28 02:04:46,942: ============================================================
2022-03-28 02:06:24,522: time cost, forward:0.27594651132422154, backward:0.0420782339808475, data cost:0.6792434020925365 
2022-03-28 02:06:24,523: ============================================================
2022-03-28 02:06:24,523: Epoch 23/26 Batch 4100/7662 eta: 7:11:46.782499	Training Loss 0.4446 (0.4391)	Training Prec@1 91.016 (91.324)	Training Prec@5 94.141 (94.555)	
2022-03-28 02:06:24,523: ============================================================
2022-03-28 02:08:03,979: time cost, forward:0.2758739217743189, backward:0.04192496634971871, data cost:0.6792916234092049 
2022-03-28 02:08:03,980: ============================================================
2022-03-28 02:08:03,980: Epoch 23/26 Batch 4200/7662 eta: 7:18:25.468641	Training Loss 0.4485 (0.4391)	Training Prec@1 91.016 (91.320)	Training Prec@5 94.531 (94.553)	
2022-03-28 02:08:03,981: ============================================================
2022-03-28 02:09:35,032: time cost, forward:0.2752630134381979, backward:0.04195729031843428, data cost:0.6779554069361096 
2022-03-28 02:09:35,032: ============================================================
2022-03-28 02:09:35,032: Epoch 23/26 Batch 4300/7662 eta: 6:39:51.388173	Training Loss 0.4413 (0.4391)	Training Prec@1 91.406 (91.311)	Training Prec@5 94.727 (94.550)	
2022-03-28 02:09:35,033: ============================================================
2022-03-28 02:11:12,196: time cost, forward:0.27498812782788823, backward:0.04192768597933454, data cost:0.67764061254435 
2022-03-28 02:11:12,197: ============================================================
2022-03-28 02:11:12,197: Epoch 23/26 Batch 4400/7662 eta: 7:05:04.792526	Training Loss 0.4368 (0.4391)	Training Prec@1 90.234 (91.310)	Training Prec@5 94.141 (94.548)	
2022-03-28 02:11:12,198: ============================================================
2022-03-28 02:12:50,861: time cost, forward:0.2746615800414517, backward:0.04191747599905082, data cost:0.6778463510757925 
2022-03-28 02:12:50,861: ============================================================
2022-03-28 02:12:50,862: Epoch 23/26 Batch 4500/7662 eta: 7:09:59.745254	Training Loss 0.4320 (0.4391)	Training Prec@1 91.602 (91.308)	Training Prec@5 94.531 (94.546)	
2022-03-28 02:12:50,862: ============================================================
2022-03-28 02:14:28,600: time cost, forward:0.27463732633572036, backward:0.04196165079239996, data cost:0.6774673713863246 
2022-03-28 02:14:28,601: ============================================================
2022-03-28 02:14:28,601: Epoch 23/26 Batch 4600/7662 eta: 7:04:20.056601	Training Loss 0.4434 (0.4392)	Training Prec@1 90.234 (91.306)	Training Prec@5 94.922 (94.547)	
2022-03-28 02:14:28,601: ============================================================
2022-03-28 02:16:07,487: time cost, forward:0.2744881323891311, backward:0.04200670398988986, data cost:0.6774466730833408 
2022-03-28 02:16:07,488: ============================================================
2022-03-28 02:16:07,489: Epoch 23/26 Batch 4700/7662 eta: 7:07:40.388906	Training Loss 0.4411 (0.4392)	Training Prec@1 91.992 (91.310)	Training Prec@5 94.922 (94.548)	
2022-03-28 02:16:07,489: ============================================================
2022-03-28 02:17:47,124: time cost, forward:0.27448860822456234, backward:0.04197262932693345, data cost:0.677483904930571 
2022-03-28 02:17:47,125: ============================================================
2022-03-28 02:17:47,125: Epoch 23/26 Batch 4800/7662 eta: 7:09:15.119896	Training Loss 0.4406 (0.4392)	Training Prec@1 91.602 (91.314)	Training Prec@5 94.531 (94.549)	
2022-03-28 02:17:47,126: ============================================================
2022-03-28 02:19:26,567: time cost, forward:0.27436801895216356, backward:0.04188593802926102, data cost:0.6775660408251284 
2022-03-28 02:19:26,568: ============================================================
2022-03-28 02:19:26,568: Epoch 23/26 Batch 4900/7662 eta: 7:06:45.538186	Training Loss 0.4399 (0.4392)	Training Prec@1 90.430 (91.315)	Training Prec@5 94.336 (94.547)	
2022-03-28 02:19:26,568: ============================================================
2022-03-28 02:21:07,283: time cost, forward:0.2743748378028725, backward:0.041724317907023176, data cost:0.6781365741226859 
2022-03-28 02:21:07,284: ============================================================
2022-03-28 02:21:07,285: Epoch 23/26 Batch 5000/7662 eta: 7:10:32.723790	Training Loss 0.4441 (0.4393)	Training Prec@1 92.188 (91.312)	Training Prec@5 94.141 (94.544)	
2022-03-28 02:21:07,285: ============================================================
2022-03-28 02:22:48,120: time cost, forward:0.2743075816952544, backward:0.04174167466037389, data cost:0.6784735925760099 
2022-03-28 02:22:48,120: ============================================================
2022-03-28 02:22:48,121: Epoch 23/26 Batch 5100/7662 eta: 7:09:22.606809	Training Loss 0.4381 (0.4393)	Training Prec@1 90.234 (91.308)	Training Prec@5 95.117 (94.541)	
2022-03-28 02:22:48,121: ============================================================
2022-03-28 02:24:23,702: time cost, forward:0.2744976969768644, backward:0.041738112675820345, data cost:0.677516000136478 
2022-03-28 02:24:23,702: ============================================================
2022-03-28 02:24:23,703: Epoch 23/26 Batch 5200/7662 eta: 6:45:24.646317	Training Loss 0.4341 (0.4393)	Training Prec@1 91.602 (91.308)	Training Prec@5 95.117 (94.540)	
2022-03-28 02:24:23,703: ============================================================
2022-03-28 02:26:01,856: time cost, forward:0.2744316468938024, backward:0.04185910678445269, data cost:0.6772320666027914 
2022-03-28 02:26:01,857: ============================================================
2022-03-28 02:26:01,857: Epoch 23/26 Batch 5300/7662 eta: 6:54:41.169883	Training Loss 0.4424 (0.4393)	Training Prec@1 90.625 (91.305)	Training Prec@5 94.141 (94.537)	
2022-03-28 02:26:01,857: ============================================================
2022-03-28 02:27:43,161: time cost, forward:0.2747024745715064, backward:0.04187946006928932, data cost:0.6772029175981811 
2022-03-28 02:27:43,162: ============================================================
2022-03-28 02:27:43,162: Epoch 23/26 Batch 5400/7662 eta: 7:06:18.447275	Training Loss 0.4376 (0.4393)	Training Prec@1 91.406 (91.306)	Training Prec@5 94.922 (94.536)	
2022-03-28 02:27:43,162: ============================================================
2022-03-28 02:29:19,494: time cost, forward:0.27479503887049567, backward:0.04188684915104526, data cost:0.6765679793696898 
2022-03-28 02:29:19,494: ============================================================
2022-03-28 02:29:19,495: Epoch 23/26 Batch 5500/7662 eta: 6:43:46.717262	Training Loss 0.4459 (0.4393)	Training Prec@1 91.016 (91.308)	Training Prec@5 93.750 (94.537)	
2022-03-28 02:29:19,495: ============================================================
2022-03-28 02:30:59,109: time cost, forward:0.27461385914291053, backward:0.04190985840076761, data cost:0.676710018070069 
2022-03-28 02:30:59,109: ============================================================
2022-03-28 02:30:59,110: Epoch 23/26 Batch 5600/7662 eta: 6:55:52.563383	Training Loss 0.4483 (0.4393)	Training Prec@1 90.430 (91.307)	Training Prec@5 92.773 (94.536)	
2022-03-28 02:30:59,110: ============================================================
2022-03-28 02:32:37,429: time cost, forward:0.27457918458119634, backward:0.04194254840878274, data cost:0.6766439046456451 
2022-03-28 02:32:37,429: ============================================================
2022-03-28 02:32:37,430: Epoch 23/26 Batch 5700/7662 eta: 6:48:49.843340	Training Loss 0.4405 (0.4394)	Training Prec@1 91.406 (91.301)	Training Prec@5 94.727 (94.533)	
2022-03-28 02:32:37,430: ============================================================
2022-03-28 02:34:19,158: time cost, forward:0.27449806066685084, backward:0.04191360660289193, data cost:0.6770353865718036 
2022-03-28 02:34:19,159: ============================================================
2022-03-28 02:34:19,159: Epoch 23/26 Batch 5800/7662 eta: 7:01:18.745281	Training Loss 0.4498 (0.4394)	Training Prec@1 91.797 (91.300)	Training Prec@5 94.141 (94.533)	
2022-03-28 02:34:19,159: ============================================================
2022-03-28 02:35:57,314: time cost, forward:0.27447925597697037, backward:0.041943577957023984, data cost:0.6769642634681977 
2022-03-28 02:35:57,314: ============================================================
2022-03-28 02:35:57,315: Epoch 23/26 Batch 5900/7662 eta: 6:44:52.545747	Training Loss 0.4490 (0.4394)	Training Prec@1 91.211 (91.297)	Training Prec@5 93.164 (94.529)	
2022-03-28 02:35:57,315: ============================================================
2022-03-28 02:37:36,566: time cost, forward:0.27447049354270886, backward:0.04194466553840821, data cost:0.6769502684759645 
2022-03-28 02:37:36,566: ============================================================
2022-03-28 02:37:36,566: Epoch 23/26 Batch 6000/7662 eta: 6:47:44.503090	Training Loss 0.4519 (0.4394)	Training Prec@1 89.062 (91.296)	Training Prec@5 92.773 (94.528)	
2022-03-28 02:37:36,566: ============================================================
2022-03-28 02:39:12,469: time cost, forward:0.2743964801950325, backward:0.04194959016447478, data cost:0.6764438462308204 
2022-03-28 02:39:12,469: ============================================================
2022-03-28 02:39:12,469: Epoch 23/26 Batch 6100/7662 eta: 6:32:23.252256	Training Loss 0.4353 (0.4394)	Training Prec@1 89.648 (91.295)	Training Prec@5 93.750 (94.528)	
2022-03-28 02:39:12,469: ============================================================
2022-03-28 02:40:53,003: time cost, forward:0.2742904431782609, backward:0.04195016933114399, data cost:0.6766557911938863 
2022-03-28 02:40:53,004: ============================================================
2022-03-28 02:40:53,004: Epoch 23/26 Batch 6200/7662 eta: 6:49:39.764981	Training Loss 0.4360 (0.4395)	Training Prec@1 93.164 (91.292)	Training Prec@5 96.094 (94.526)	
2022-03-28 02:40:53,005: ============================================================
2022-03-28 02:42:35,876: time cost, forward:0.2744057988870672, backward:0.04198412986800186, data cost:0.6771480872869908 
2022-03-28 02:42:35,876: ============================================================
2022-03-28 02:42:35,876: Epoch 23/26 Batch 6300/7662 eta: 6:57:28.316395	Training Loss 0.4366 (0.4395)	Training Prec@1 90.430 (91.286)	Training Prec@5 94.141 (94.522)	
2022-03-28 02:42:35,876: ============================================================
2022-03-28 02:44:14,357: time cost, forward:0.2743358964155495, backward:0.04198273324765234, data cost:0.6770109213000257 
2022-03-28 02:44:14,357: ============================================================
2022-03-28 02:44:14,358: Epoch 23/26 Batch 6400/7662 eta: 6:38:00.785042	Training Loss 0.4360 (0.4395)	Training Prec@1 90.234 (91.286)	Training Prec@5 93.750 (94.520)	
2022-03-28 02:44:14,358: ============================================================
2022-03-28 02:45:51,601: time cost, forward:0.2742095414373137, backward:0.042007543652181276, data cost:0.6768556546937468 
2022-03-28 02:45:51,601: ============================================================
2022-03-28 02:45:51,601: Epoch 23/26 Batch 6500/7662 eta: 6:31:23.305177	Training Loss 0.4348 (0.4395)	Training Prec@1 92.383 (91.285)	Training Prec@5 94.336 (94.520)	
2022-03-28 02:45:51,601: ============================================================
2022-03-28 02:47:30,606: time cost, forward:0.2740391592741699, backward:0.04202413078437594, data cost:0.6769653208094268 
2022-03-28 02:47:30,606: ============================================================
2022-03-28 02:47:30,606: Epoch 23/26 Batch 6600/7662 eta: 6:36:49.678477	Training Loss 0.4378 (0.4395)	Training Prec@1 89.648 (91.286)	Training Prec@5 92.578 (94.520)	
2022-03-28 02:47:30,606: ============================================================
2022-03-28 02:49:08,592: time cost, forward:0.27397176510790494, backward:0.042029196192104615, data cost:0.676778543527526 
2022-03-28 02:49:08,593: ============================================================
2022-03-28 02:49:08,593: Epoch 23/26 Batch 6700/7662 eta: 6:31:06.886471	Training Loss 0.4367 (0.4395)	Training Prec@1 90.430 (91.283)	Training Prec@5 94.141 (94.519)	
2022-03-28 02:49:08,593: ============================================================
2022-03-28 02:50:47,100: time cost, forward:0.27397182479047094, backward:0.04207234909331418, data cost:0.6766404556446101 
2022-03-28 02:50:47,100: ============================================================
2022-03-28 02:50:47,100: Epoch 23/26 Batch 6800/7662 eta: 6:31:32.956883	Training Loss 0.4326 (0.4396)	Training Prec@1 91.797 (91.278)	Training Prec@5 93.945 (94.514)	
2022-03-28 02:50:47,100: ============================================================
2022-03-28 02:52:26,703: time cost, forward:0.2739161857575122, backward:0.04208478300031294, data cost:0.67675968325126 
2022-03-28 02:52:26,703: ============================================================
2022-03-28 02:52:26,703: Epoch 23/26 Batch 6900/7662 eta: 6:34:14.824657	Training Loss 0.4297 (0.4396)	Training Prec@1 92.188 (91.278)	Training Prec@5 95.312 (94.515)	
2022-03-28 02:52:26,704: ============================================================
2022-03-28 02:54:05,170: time cost, forward:0.2738272485298367, backward:0.04209744458471746, data cost:0.676711506802008 
2022-03-28 02:54:05,170: ============================================================
2022-03-28 02:54:05,170: Epoch 23/26 Batch 7000/7662 eta: 6:28:06.339043	Training Loss 0.4390 (0.4396)	Training Prec@1 92.578 (91.273)	Training Prec@5 95.117 (94.510)	
2022-03-28 02:54:05,170: ============================================================
2022-03-28 02:55:42,440: time cost, forward:0.2737873794831328, backward:0.04210615013666364, data cost:0.6764509676543571 
2022-03-28 02:55:42,440: ============================================================
2022-03-28 02:55:42,440: Epoch 23/26 Batch 7100/7662 eta: 6:21:46.142221	Training Loss 0.4427 (0.4396)	Training Prec@1 90.234 (91.275)	Training Prec@5 93.359 (94.511)	
2022-03-28 02:55:42,440: ============================================================
2022-03-28 02:57:20,969: time cost, forward:0.2737184539571837, backward:0.04211144179730866, data cost:0.676422508976032 
2022-03-28 02:57:20,969: ============================================================
2022-03-28 02:57:20,969: Epoch 23/26 Batch 7200/7662 eta: 6:25:04.118891	Training Loss 0.4463 (0.4396)	Training Prec@1 91.211 (91.274)	Training Prec@5 94.922 (94.511)	
2022-03-28 02:57:20,970: ============================================================
2022-03-28 02:58:57,734: time cost, forward:0.27354634760307733, backward:0.042144993883826205, data cost:0.6762043178073346 
2022-03-28 02:58:57,735: ============================================================
2022-03-28 02:58:57,735: Epoch 23/26 Batch 7300/7662 eta: 6:16:33.814243	Training Loss 0.4413 (0.4396)	Training Prec@1 91.016 (91.273)	Training Prec@5 93.359 (94.510)	
2022-03-28 02:58:57,735: ============================================================
2022-03-28 03:00:35,694: time cost, forward:0.2735889392022201, backward:0.04215491225645661, data cost:0.67599852711208 
2022-03-28 03:00:35,694: ============================================================
2022-03-28 03:00:35,695: Epoch 23/26 Batch 7400/7662 eta: 6:19:34.597354	Training Loss 0.4384 (0.4396)	Training Prec@1 90.234 (91.273)	Training Prec@5 94.922 (94.512)	
2022-03-28 03:00:35,695: ============================================================
2022-03-28 03:02:13,746: time cost, forward:0.2735214659111836, backward:0.042144260306027054, data cost:0.6758908627748267 
2022-03-28 03:02:13,747: ============================================================
2022-03-28 03:02:13,747: Epoch 23/26 Batch 7500/7662 eta: 6:18:18.148943	Training Loss 0.4370 (0.4397)	Training Prec@1 91.992 (91.273)	Training Prec@5 95.312 (94.512)	
2022-03-28 03:02:13,747: ============================================================
2022-03-28 03:03:52,938: time cost, forward:0.27350232585164524, backward:0.042158280035150195, data cost:0.6758970025809662 
2022-03-28 03:03:52,938: ============================================================
2022-03-28 03:03:52,938: Epoch 23/26 Batch 7600/7662 eta: 6:21:02.616456	Training Loss 0.4386 (0.4397)	Training Prec@1 93.359 (91.272)	Training Prec@5 96.094 (94.511)	
2022-03-28 03:03:52,938: ============================================================
2022-03-28 03:04:56,082: Epoch: 23/26 eta: 6:20:00.125899	Training Loss 0.4333 (0.4397)	Training Prec@1 92.383 (91.270)	Training Prec@5 95.898 (94.509)
2022-03-28 03:04:56,082: ============================================================
2022-03-28 03:06:33,475: time cost, forward:0.25084450991466795, backward:0.037329731565533264, data cost:0.685744593841861 
2022-03-28 03:06:33,475: ============================================================
2022-03-28 03:06:33,476: Epoch 24/26 Batch 100/7662 eta: 6:09:48.817351	Training Loss 0.4406 (0.4363)	Training Prec@1 91.992 (91.568)	Training Prec@5 94.727 (94.780)	
2022-03-28 03:06:33,476: ============================================================
2022-03-28 03:08:10,401: time cost, forward:0.251736234779933, backward:0.03831954697268692, data cost:0.681455288700123 
2022-03-28 03:08:10,401: ============================================================
2022-03-28 03:08:10,402: Epoch 24/26 Batch 200/7662 eta: 6:08:06.627285	Training Loss 0.4332 (0.4371)	Training Prec@1 91.406 (91.552)	Training Prec@5 94.141 (94.732)	
2022-03-28 03:08:10,402: ============================================================
2022-03-28 03:09:47,946: time cost, forward:0.2554841209016117, backward:0.03965196641392532, data cost:0.677481219122641 
2022-03-28 03:09:47,946: ============================================================
2022-03-28 03:09:47,946: Epoch 24/26 Batch 300/7662 eta: 6:08:49.892992	Training Loss 0.4354 (0.4374)	Training Prec@1 90.820 (91.524)	Training Prec@5 94.141 (94.711)	
2022-03-28 03:09:47,946: ============================================================
2022-03-28 03:11:25,101: time cost, forward:0.25471199664256927, backward:0.04057153125753379, data cost:0.6768288534685484 
2022-03-28 03:11:25,101: ============================================================
2022-03-28 03:11:25,101: Epoch 24/26 Batch 400/7662 eta: 6:05:44.382073	Training Loss 0.4154 (0.4376)	Training Prec@1 93.164 (91.534)	Training Prec@5 95.898 (94.707)	
2022-03-28 03:11:25,101: ============================================================
2022-03-28 03:13:01,522: time cost, forward:0.2551811180993885, backward:0.041362057229082184, data cost:0.6738810023229442 
2022-03-28 03:13:01,522: ============================================================
2022-03-28 03:13:01,522: Epoch 24/26 Batch 500/7662 eta: 6:01:22.162285	Training Loss 0.4474 (0.4375)	Training Prec@1 89.648 (91.533)	Training Prec@5 92.773 (94.703)	
2022-03-28 03:13:01,522: ============================================================
2022-03-28 03:14:37,174: time cost, forward:0.2559859684990324, backward:0.04099982529132314, data cost:0.6696408857686292 
2022-03-28 03:14:37,175: ============================================================
2022-03-28 03:14:37,175: Epoch 24/26 Batch 600/7662 eta: 5:56:53.880209	Training Loss 0.4385 (0.4376)	Training Prec@1 91.602 (91.523)	Training Prec@5 93.555 (94.694)	
2022-03-28 03:14:37,176: ============================================================
2022-03-28 03:16:17,197: time cost, forward:0.25860245238046276, backward:0.03969814132723174, data cost:0.674396876442927 
2022-03-28 03:16:17,198: ============================================================
2022-03-28 03:16:17,198: Epoch 24/26 Batch 700/7662 eta: 6:11:32.025848	Training Loss 0.4458 (0.4376)	Training Prec@1 90.430 (91.523)	Training Prec@5 92.969 (94.700)	
2022-03-28 03:16:17,198: ============================================================
2022-03-28 03:17:54,191: time cost, forward:0.25989694678887854, backward:0.039950938039786825, data cost:0.6723745859907625 
2022-03-28 03:17:54,191: ============================================================
2022-03-28 03:17:54,192: Epoch 24/26 Batch 800/7662 eta: 5:58:39.977784	Training Loss 0.4474 (0.4377)	Training Prec@1 91.797 (91.518)	Training Prec@5 95.312 (94.701)	
2022-03-28 03:17:54,192: ============================================================
2022-03-28 03:19:29,791: time cost, forward:0.26007180723120293, backward:0.04066252204547072, data cost:0.6697625026554367 
2022-03-28 03:19:29,791: ============================================================
2022-03-28 03:19:29,792: Epoch 24/26 Batch 900/7662 eta: 5:51:55.166608	Training Loss 0.4425 (0.4376)	Training Prec@1 90.625 (91.547)	Training Prec@5 93.945 (94.722)	
2022-03-28 03:19:29,792: ============================================================
2022-03-28 03:21:06,715: time cost, forward:0.26042558433295965, backward:0.04139489096564215, data cost:0.6684592111451967 
2022-03-28 03:21:06,715: ============================================================
2022-03-28 03:21:06,715: Epoch 24/26 Batch 1000/7662 eta: 5:55:10.651630	Training Loss 0.4422 (0.4375)	Training Prec@1 89.844 (91.525)	Training Prec@5 93.555 (94.702)	
2022-03-28 03:21:06,716: ============================================================
2022-03-28 03:22:44,527: time cost, forward:0.26095237918503184, backward:0.04190763286073388, data cost:0.668132758769694 
2022-03-28 03:22:44,528: ============================================================
2022-03-28 03:22:44,528: Epoch 24/26 Batch 1100/7662 eta: 5:56:48.203663	Training Loss 0.4349 (0.4376)	Training Prec@1 89.844 (91.500)	Training Prec@5 93.945 (94.685)	
2022-03-28 03:22:44,528: ============================================================
2022-03-28 03:24:23,762: time cost, forward:0.26226214909175716, backward:0.04210789885691944, data cost:0.6683024005953524 
2022-03-28 03:24:23,763: ============================================================
2022-03-28 03:24:23,763: Epoch 24/26 Batch 1200/7662 eta: 6:00:20.342257	Training Loss 0.4406 (0.4376)	Training Prec@1 92.188 (91.491)	Training Prec@5 94.336 (94.680)	
2022-03-28 03:24:23,763: ============================================================
2022-03-28 03:25:59,583: time cost, forward:0.26227035441703295, backward:0.04223792529087786, data cost:0.6670630185580235 
2022-03-28 03:25:59,583: ============================================================
2022-03-28 03:25:59,583: Epoch 24/26 Batch 1300/7662 eta: 5:46:20.596363	Training Loss 0.4473 (0.4376)	Training Prec@1 91.016 (91.496)	Training Prec@5 94.727 (94.681)	
2022-03-28 03:25:59,584: ============================================================
2022-03-28 03:27:37,145: time cost, forward:0.2620213660621234, backward:0.04229709486862521, data cost:0.6675034714563136 
2022-03-28 03:27:37,146: ============================================================
2022-03-28 03:27:37,146: Epoch 24/26 Batch 1400/7662 eta: 5:51:00.822433	Training Loss 0.4342 (0.4377)	Training Prec@1 91.797 (91.486)	Training Prec@5 94.531 (94.676)	
2022-03-28 03:27:37,146: ============================================================
2022-03-28 03:29:08,869: time cost, forward:0.26186075570028255, backward:0.04227135418414115, data cost:0.6640195550721355 
2022-03-28 03:29:08,870: ============================================================
2022-03-28 03:29:08,870: Epoch 24/26 Batch 1500/7662 eta: 5:28:28.729164	Training Loss 0.4304 (0.4376)	Training Prec@1 94.336 (91.496)	Training Prec@5 95.898 (94.679)	
2022-03-28 03:29:08,870: ============================================================
2022-03-28 03:30:44,273: time cost, forward:0.26219244373075806, backward:0.04240082948933996, data cost:0.662633075052086 
2022-03-28 03:30:44,273: ============================================================
2022-03-28 03:30:44,273: Epoch 24/26 Batch 1600/7662 eta: 5:40:03.926064	Training Loss 0.4378 (0.4378)	Training Prec@1 91.016 (91.478)	Training Prec@5 93.945 (94.670)	
2022-03-28 03:30:44,273: ============================================================
2022-03-28 03:32:23,522: time cost, forward:0.2626504082761139, backward:0.04238386979307968, data cost:0.6631967934388985 
2022-03-28 03:32:23,523: ============================================================
2022-03-28 03:32:23,523: Epoch 24/26 Batch 1700/7662 eta: 5:52:07.347348	Training Loss 0.4171 (0.4378)	Training Prec@1 92.578 (91.482)	Training Prec@5 95.312 (94.666)	
2022-03-28 03:32:23,524: ============================================================
2022-03-28 03:33:57,273: time cost, forward:0.26279131421252977, backward:0.04221849444178888, data cost:0.6617400575969669 
2022-03-28 03:33:57,274: ============================================================
2022-03-28 03:33:57,274: Epoch 24/26 Batch 1800/7662 eta: 5:31:02.892564	Training Loss 0.4306 (0.4378)	Training Prec@1 92.578 (91.488)	Training Prec@5 94.727 (94.668)	
2022-03-28 03:33:57,274: ============================================================
2022-03-28 03:35:36,432: time cost, forward:0.2633645159122252, backward:0.042272420228312305, data cost:0.6623476755625326 
2022-03-28 03:35:36,432: ============================================================
2022-03-28 03:35:36,433: Epoch 24/26 Batch 1900/7662 eta: 5:48:29.627494	Training Loss 0.4410 (0.4379)	Training Prec@1 92.773 (91.483)	Training Prec@5 94.922 (94.660)	
2022-03-28 03:35:36,433: ============================================================
2022-03-28 03:37:13,540: time cost, forward:0.26342103539734496, backward:0.0422629287923915, data cost:0.6626982635232793 
2022-03-28 03:37:13,540: ============================================================
2022-03-28 03:37:13,540: Epoch 24/26 Batch 2000/7662 eta: 5:39:40.008483	Training Loss 0.4494 (0.4379)	Training Prec@1 90.625 (91.475)	Training Prec@5 92.773 (94.657)	
2022-03-28 03:37:13,540: ============================================================
2022-03-28 03:38:50,202: time cost, forward:0.26333056863800236, backward:0.042278180751646056, data cost:0.6624706632015307 
2022-03-28 03:38:50,202: ============================================================
2022-03-28 03:38:50,202: Epoch 24/26 Batch 2100/7662 eta: 5:36:29.801041	Training Loss 0.4305 (0.4379)	Training Prec@1 94.531 (91.483)	Training Prec@5 96.484 (94.665)	
2022-03-28 03:38:50,203: ============================================================
2022-03-28 03:40:29,334: time cost, forward:0.2637943496157658, backward:0.042293856283814976, data cost:0.6632524747748763 
2022-03-28 03:40:29,335: ============================================================
2022-03-28 03:40:29,335: Epoch 24/26 Batch 2200/7662 eta: 5:43:26.674644	Training Loss 0.4290 (0.4379)	Training Prec@1 90.430 (91.470)	Training Prec@5 94.336 (94.657)	
2022-03-28 03:40:29,335: ============================================================
2022-03-28 03:42:05,225: time cost, forward:0.26398117493525336, backward:0.04230392326630422, data cost:0.6624205637206301 
2022-03-28 03:42:05,225: ============================================================
2022-03-28 03:42:05,225: Epoch 24/26 Batch 2300/7662 eta: 5:30:36.866122	Training Loss 0.4384 (0.4380)	Training Prec@1 92.969 (91.462)	Training Prec@5 94.922 (94.646)	
2022-03-28 03:42:05,226: ============================================================
2022-03-28 03:43:43,735: time cost, forward:0.26456053538240953, backward:0.042375872462130725, data cost:0.6623153713356709 
2022-03-28 03:43:43,735: ============================================================
2022-03-28 03:43:43,735: Epoch 24/26 Batch 2400/7662 eta: 5:38:00.234261	Training Loss 0.4310 (0.4380)	Training Prec@1 93.164 (91.458)	Training Prec@5 96.875 (94.644)	
2022-03-28 03:43:43,736: ============================================================
2022-03-28 03:45:21,611: time cost, forward:0.265437708038385, backward:0.042377638406589445, data cost:0.6620288299722354 
2022-03-28 03:45:21,612: ============================================================
2022-03-28 03:45:21,612: Epoch 24/26 Batch 2500/7662 eta: 5:34:12.043327	Training Loss 0.4469 (0.4381)	Training Prec@1 91.211 (91.457)	Training Prec@5 94.531 (94.641)	
2022-03-28 03:45:21,613: ============================================================
2022-03-28 03:46:56,957: time cost, forward:0.2656230467839991, backward:0.04238886198386544, data cost:0.6611589792830617 
2022-03-28 03:46:56,957: ============================================================
2022-03-28 03:46:56,957: Epoch 24/26 Batch 2600/7662 eta: 5:23:57.951131	Training Loss 0.4372 (0.4381)	Training Prec@1 91.211 (91.454)	Training Prec@5 94.727 (94.639)	
2022-03-28 03:46:56,957: ============================================================
2022-03-28 03:48:34,651: time cost, forward:0.265789430200634, backward:0.04242747375019041, data cost:0.6612793165209029 
2022-03-28 03:48:34,652: ============================================================
2022-03-28 03:48:34,652: Epoch 24/26 Batch 2700/7662 eta: 5:30:19.339944	Training Loss 0.4427 (0.4381)	Training Prec@1 91.602 (91.458)	Training Prec@5 96.094 (94.645)	
2022-03-28 03:48:34,652: ============================================================
2022-03-28 03:50:09,773: time cost, forward:0.26606549208144625, backward:0.04245883850337523, data cost:0.6602316921461732 
2022-03-28 03:50:09,773: ============================================================
2022-03-28 03:50:09,774: Epoch 24/26 Batch 2800/7662 eta: 5:20:02.237274	Training Loss 0.4363 (0.4382)	Training Prec@1 91.211 (91.454)	Training Prec@5 93.945 (94.639)	
2022-03-28 03:50:09,774: ============================================================
2022-03-28 03:51:46,423: time cost, forward:0.26597407284421154, backward:0.04256605509849777, data cost:0.6602155479656165 
2022-03-28 03:51:46,423: ============================================================
2022-03-28 03:51:46,423: Epoch 24/26 Batch 2900/7662 eta: 5:23:34.004344	Training Loss 0.4330 (0.4382)	Training Prec@1 90.625 (91.451)	Training Prec@5 94.727 (94.640)	
2022-03-28 03:51:46,423: ============================================================
2022-03-28 03:53:21,430: time cost, forward:0.2654615720537115, backward:0.04258858374493565, data cost:0.6600606204589712 
2022-03-28 03:53:21,430: ============================================================
2022-03-28 03:53:21,430: Epoch 24/26 Batch 3000/7662 eta: 5:16:29.080773	Training Loss 0.4451 (0.4382)	Training Prec@1 91.992 (91.450)	Training Prec@5 94.727 (94.638)	
2022-03-28 03:53:21,431: ============================================================
2022-03-28 03:54:57,525: time cost, forward:0.26532129796715315, backward:0.04262953783166374, data cost:0.6599124249584177 
2022-03-28 03:54:57,526: ============================================================
2022-03-28 03:54:57,526: Epoch 24/26 Batch 3100/7662 eta: 5:18:30.511609	Training Loss 0.4413 (0.4382)	Training Prec@1 91.016 (91.442)	Training Prec@5 94.141 (94.631)	
2022-03-28 03:54:57,526: ============================================================
2022-03-28 03:56:34,981: time cost, forward:0.2651784452060939, backward:0.04265478366089821, data cost:0.6602372735617644 
2022-03-28 03:56:34,982: ============================================================
2022-03-28 03:56:34,982: Epoch 24/26 Batch 3200/7662 eta: 5:21:23.611944	Training Loss 0.4399 (0.4382)	Training Prec@1 91.992 (91.446)	Training Prec@5 95.312 (94.630)	
2022-03-28 03:56:34,982: ============================================================
2022-03-28 03:58:11,143: time cost, forward:0.2652776106880375, backward:0.04265746747988504, data cost:0.6598968837578465 
2022-03-28 03:58:11,144: ============================================================
2022-03-28 03:58:11,144: Epoch 24/26 Batch 3300/7662 eta: 5:15:31.502156	Training Loss 0.4362 (0.4383)	Training Prec@1 91.211 (91.447)	Training Prec@5 95.312 (94.630)	
2022-03-28 03:58:11,145: ============================================================
2022-03-28 03:59:47,093: time cost, forward:0.26504141290456484, backward:0.04260514539352197, data cost:0.6599839066154433 
2022-03-28 03:59:47,094: ============================================================
2022-03-28 03:59:47,094: Epoch 24/26 Batch 3400/7662 eta: 5:13:13.590662	Training Loss 0.4398 (0.4383)	Training Prec@1 90.625 (91.438)	Training Prec@5 93.945 (94.625)	
2022-03-28 03:59:47,094: ============================================================
2022-03-28 04:01:26,045: time cost, forward:0.2651481461477266, backward:0.04259689360490763, data cost:0.6604459647554505 
2022-03-28 04:01:26,045: ============================================================
2022-03-28 04:01:26,045: Epoch 24/26 Batch 3500/7662 eta: 5:21:22.693242	Training Loss 0.4360 (0.4383)	Training Prec@1 91.016 (91.434)	Training Prec@5 95.117 (94.622)	
2022-03-28 04:01:26,045: ============================================================
2022-03-28 04:03:02,326: time cost, forward:0.26516810951381303, backward:0.04259910872327715, data cost:0.6603088062913857 
2022-03-28 04:03:02,326: ============================================================
2022-03-28 04:03:02,326: Epoch 24/26 Batch 3600/7662 eta: 5:11:05.936622	Training Loss 0.4455 (0.4383)	Training Prec@1 90.625 (91.436)	Training Prec@5 94.727 (94.625)	
2022-03-28 04:03:02,326: ============================================================
2022-03-28 04:04:37,561: time cost, forward:0.2649120681187242, backward:0.042652168670967806, data cost:0.6599120413751078 
2022-03-28 04:04:37,561: ============================================================
2022-03-28 04:04:37,562: Epoch 24/26 Batch 3700/7662 eta: 5:06:08.074950	Training Loss 0.4344 (0.4383)	Training Prec@1 90.234 (91.431)	Training Prec@5 93.750 (94.622)	
2022-03-28 04:04:37,562: ============================================================
2022-03-28 04:06:14,244: time cost, forward:0.26495506324778106, backward:0.04269600655098092, data cost:0.6599071543603924 
2022-03-28 04:06:14,246: ============================================================
2022-03-28 04:06:14,246: Epoch 24/26 Batch 3800/7662 eta: 5:09:10.838634	Training Loss 0.4389 (0.4383)	Training Prec@1 93.359 (91.426)	Training Prec@5 96.289 (94.618)	
2022-03-28 04:06:14,246: ============================================================
2022-03-28 04:07:53,182: time cost, forward:0.2652211872911906, backward:0.04269508216038029, data cost:0.660254270916078 
2022-03-28 04:07:53,182: ============================================================
2022-03-28 04:07:53,182: Epoch 24/26 Batch 3900/7662 eta: 5:14:44.001942	Training Loss 0.4382 (0.4384)	Training Prec@1 93.555 (91.422)	Training Prec@5 97.266 (94.614)	
2022-03-28 04:07:53,182: ============================================================
2022-03-28 04:09:29,297: time cost, forward:0.265253812439831, backward:0.04276732237048673, data cost:0.6597617593637911 
2022-03-28 04:09:29,297: ============================================================
2022-03-28 04:09:29,297: Epoch 24/26 Batch 4000/7662 eta: 5:04:09.304713	Training Loss 0.4390 (0.4384)	Training Prec@1 91.797 (91.413)	Training Prec@5 94.727 (94.607)	
2022-03-28 04:09:29,297: ============================================================
2022-03-28 04:11:06,839: time cost, forward:0.26520548602027644, backward:0.04280636897462844, data cost:0.6601292021421724 
2022-03-28 04:11:06,839: ============================================================
2022-03-28 04:11:06,839: Epoch 24/26 Batch 4100/7662 eta: 5:07:02.797042	Training Loss 0.4364 (0.4384)	Training Prec@1 92.188 (91.411)	Training Prec@5 95.117 (94.607)	
2022-03-28 04:11:06,839: ============================================================
2022-03-28 04:12:44,290: time cost, forward:0.26512704204451215, backward:0.04279406089446578, data cost:0.6601999595239634 
2022-03-28 04:12:44,291: ============================================================
2022-03-28 04:12:44,291: Epoch 24/26 Batch 4200/7662 eta: 5:05:08.238780	Training Loss 0.4351 (0.4384)	Training Prec@1 91.992 (91.411)	Training Prec@5 95.312 (94.607)	
2022-03-28 04:12:44,291: ============================================================
2022-03-28 04:14:23,255: time cost, forward:0.26524112124197924, backward:0.04279448493022257, data cost:0.6607519207679552 
2022-03-28 04:14:23,255: ============================================================
2022-03-28 04:14:23,255: Epoch 24/26 Batch 4300/7662 eta: 5:08:13.449949	Training Loss 0.4451 (0.4385)	Training Prec@1 88.867 (91.405)	Training Prec@5 92.383 (94.605)	
2022-03-28 04:14:23,255: ============================================================
2022-03-28 04:15:57,868: time cost, forward:0.2648847880323358, backward:0.04276533261242984, data cost:0.6605384437082356 
2022-03-28 04:15:57,868: ============================================================
2022-03-28 04:15:57,868: Epoch 24/26 Batch 4400/7662 eta: 4:53:05.769567	Training Loss 0.4360 (0.4385)	Training Prec@1 92.969 (91.408)	Training Prec@5 96.094 (94.608)	
2022-03-28 04:15:57,869: ============================================================
2022-03-28 04:17:33,013: time cost, forward:0.2645895447723599, backward:0.042772196854292274, data cost:0.6605255274169576 
2022-03-28 04:17:33,014: ============================================================
2022-03-28 04:17:33,014: Epoch 24/26 Batch 4500/7662 eta: 4:53:09.553511	Training Loss 0.4379 (0.4385)	Training Prec@1 91.016 (91.410)	Training Prec@5 94.141 (94.608)	
2022-03-28 04:17:33,014: ============================================================
2022-03-28 04:19:10,269: time cost, forward:0.26459470503380517, backward:0.04279819097848632, data cost:0.660585611481904 
2022-03-28 04:19:10,270: ============================================================
2022-03-28 04:19:10,270: Epoch 24/26 Batch 4600/7662 eta: 4:58:02.436398	Training Loss 0.4478 (0.4384)	Training Prec@1 90.234 (91.412)	Training Prec@5 93.945 (94.609)	
2022-03-28 04:19:10,270: ============================================================
2022-03-28 04:20:48,267: time cost, forward:0.26453940445728874, backward:0.04278775254927637, data cost:0.660896488036671 
2022-03-28 04:20:48,267: ============================================================
2022-03-28 04:20:48,267: Epoch 24/26 Batch 4700/7662 eta: 4:58:40.807916	Training Loss 0.4339 (0.4384)	Training Prec@1 92.383 (91.410)	Training Prec@5 94.922 (94.608)	
2022-03-28 04:20:48,268: ============================================================
2022-03-28 04:22:24,895: time cost, forward:0.2646925910409974, backward:0.042753103947386094, data cost:0.6607265445087621 
2022-03-28 04:22:24,895: ============================================================
2022-03-28 04:22:24,895: Epoch 24/26 Batch 4800/7662 eta: 4:52:53.726429	Training Loss 0.4436 (0.4384)	Training Prec@1 89.844 (91.409)	Training Prec@5 94.531 (94.608)	
2022-03-28 04:22:24,895: ============================================================
2022-03-28 04:24:00,889: time cost, forward:0.2645206845130305, backward:0.042797460680617246, data cost:0.6606126193684884 
2022-03-28 04:24:00,890: ============================================================
2022-03-28 04:24:00,891: Epoch 24/26 Batch 4900/7662 eta: 4:49:22.628135	Training Loss 0.4594 (0.4384)	Training Prec@1 87.500 (91.409)	Training Prec@5 92.383 (94.608)	
2022-03-28 04:24:00,891: ============================================================
2022-03-28 04:25:39,051: time cost, forward:0.2645836885177176, backward:0.042826483931200914, data cost:0.6608613365338931 
2022-03-28 04:25:39,052: ============================================================
2022-03-28 04:25:39,052: Epoch 24/26 Batch 5000/7662 eta: 4:54:16.295192	Training Loss 0.4348 (0.4385)	Training Prec@1 92.188 (91.406)	Training Prec@5 95.898 (94.609)	
2022-03-28 04:25:39,052: ============================================================
2022-03-28 04:27:15,877: time cost, forward:0.26443119585853064, backward:0.04287250842924655, data cost:0.6609527540104042 
2022-03-28 04:27:15,878: ============================================================
2022-03-28 04:27:15,878: Epoch 24/26 Batch 5100/7662 eta: 4:48:39.264569	Training Loss 0.4373 (0.4385)	Training Prec@1 91.602 (91.404)	Training Prec@5 93.945 (94.608)	
2022-03-28 04:27:15,878: ============================================================
2022-03-28 04:28:51,695: time cost, forward:0.2643802831851191, backward:0.04290472752636592, data cost:0.6607641096091266 
2022-03-28 04:28:51,695: ============================================================
2022-03-28 04:28:51,695: Epoch 24/26 Batch 5200/7662 eta: 4:44:03.026007	Training Loss 0.4409 (0.4385)	Training Prec@1 91.211 (91.400)	Training Prec@5 94.336 (94.607)	
2022-03-28 04:28:51,695: ============================================================
2022-03-28 04:30:26,959: time cost, forward:0.26416326532005746, backward:0.042934010896756525, data cost:0.6606678193325051 
2022-03-28 04:30:26,959: ============================================================
2022-03-28 04:30:26,959: Epoch 24/26 Batch 5300/7662 eta: 4:40:49.317145	Training Loss 0.4422 (0.4385)	Training Prec@1 91.406 (91.398)	Training Prec@5 94.336 (94.605)	
2022-03-28 04:30:26,959: ============================================================
2022-03-28 04:32:02,756: time cost, forward:0.2641590000589946, backward:0.04292244914726629, data cost:0.6604408351861453 
2022-03-28 04:32:02,757: ============================================================
2022-03-28 04:32:02,757: Epoch 24/26 Batch 5400/7662 eta: 4:40:47.970125	Training Loss 0.4402 (0.4385)	Training Prec@1 89.844 (91.394)	Training Prec@5 92.578 (94.600)	
2022-03-28 04:32:02,757: ============================================================
2022-03-28 04:33:39,833: time cost, forward:0.264085655365018, backward:0.04290899781232141, data cost:0.6606224632453953 
2022-03-28 04:33:39,833: ============================================================
2022-03-28 04:33:39,833: Epoch 24/26 Batch 5500/7662 eta: 4:42:55.692206	Training Loss 0.4435 (0.4386)	Training Prec@1 91.016 (91.390)	Training Prec@5 93.945 (94.599)	
2022-03-28 04:33:39,833: ============================================================
2022-03-28 04:35:18,500: time cost, forward:0.26408887880362447, backward:0.04292795197796366, data cost:0.6609425614999648 
2022-03-28 04:35:18,501: ============================================================
2022-03-28 04:35:18,501: Epoch 24/26 Batch 5600/7662 eta: 4:45:55.447191	Training Loss 0.4427 (0.4386)	Training Prec@1 91.016 (91.387)	Training Prec@5 94.336 (94.598)	
2022-03-28 04:35:18,502: ============================================================
2022-03-28 04:36:53,501: time cost, forward:0.2639373725998881, backward:0.04293283802895279, data cost:0.6606244111734643 
2022-03-28 04:36:53,501: ============================================================
2022-03-28 04:36:53,502: Epoch 24/26 Batch 5700/7662 eta: 4:33:42.720726	Training Loss 0.4326 (0.4386)	Training Prec@1 92.578 (91.383)	Training Prec@5 94.727 (94.593)	
2022-03-28 04:36:53,502: ============================================================
2022-03-28 04:38:27,263: time cost, forward:0.2639844663843325, backward:0.04295085096877286, data cost:0.6601863465323122 
2022-03-28 04:38:27,263: ============================================================
2022-03-28 04:38:27,263: Epoch 24/26 Batch 5800/7662 eta: 4:28:34.765464	Training Loss 0.4310 (0.4386)	Training Prec@1 90.430 (91.385)	Training Prec@5 94.141 (94.594)	
2022-03-28 04:38:27,263: ============================================================
2022-03-28 04:40:01,736: time cost, forward:0.2639919115054565, backward:0.043000058453655746, data cost:0.6597379993474934 
2022-03-28 04:40:01,737: ============================================================
2022-03-28 04:40:01,737: Epoch 24/26 Batch 5900/7662 eta: 4:29:02.726953	Training Loss 0.4294 (0.4386)	Training Prec@1 93.750 (91.387)	Training Prec@5 96.094 (94.595)	
2022-03-28 04:40:01,737: ============================================================
2022-03-28 04:41:37,683: time cost, forward:0.2639067236593036, backward:0.0429961780723601, data cost:0.6596974594471037 
2022-03-28 04:41:37,684: ============================================================
2022-03-28 04:41:37,684: Epoch 24/26 Batch 6000/7662 eta: 4:31:38.554074	Training Loss 0.4314 (0.4386)	Training Prec@1 93.945 (91.387)	Training Prec@5 95.508 (94.594)	
2022-03-28 04:41:37,684: ============================================================
2022-03-28 04:43:13,816: time cost, forward:0.2640008022207025, backward:0.04301827609451076, data cost:0.6594847873657097 
2022-03-28 04:43:13,816: ============================================================
2022-03-28 04:43:13,817: Epoch 24/26 Batch 6100/7662 eta: 4:30:33.909154	Training Loss 0.4462 (0.4386)	Training Prec@1 90.625 (91.385)	Training Prec@5 94.531 (94.592)	
2022-03-28 04:43:13,817: ============================================================
2022-03-28 04:44:41,636: time cost, forward:0.26362978348637384, backward:0.043016923168125144, data cost:0.658445696039226 
2022-03-28 04:44:41,636: ============================================================
2022-03-28 04:44:41,636: Epoch 24/26 Batch 6200/7662 eta: 4:05:42.251015	Training Loss 0.4422 (0.4387)	Training Prec@1 92.578 (91.382)	Training Prec@5 95.508 (94.590)	
2022-03-28 04:44:41,636: ============================================================
2022-03-28 04:46:13,952: time cost, forward:0.26353436739676755, backward:0.04297356613856835, data cost:0.6578978208307804 
2022-03-28 04:46:13,952: ============================================================
2022-03-28 04:46:13,953: Epoch 24/26 Batch 6300/7662 eta: 4:16:44.845196	Training Loss 0.4354 (0.4387)	Training Prec@1 91.016 (91.383)	Training Prec@5 95.703 (94.588)	
2022-03-28 04:46:13,953: ============================================================
2022-03-28 04:47:48,731: time cost, forward:0.26352511392680716, backward:0.042988985921278804, data cost:0.6575264152762926 
2022-03-28 04:47:48,732: ============================================================
2022-03-28 04:47:48,732: Epoch 24/26 Batch 6400/7662 eta: 4:22:01.053006	Training Loss 0.4388 (0.4387)	Training Prec@1 89.844 (91.380)	Training Prec@5 94.141 (94.586)	
2022-03-28 04:47:48,732: ============================================================
2022-03-28 04:49:21,790: time cost, forward:0.2634981132723915, backward:0.04298793379940204, data cost:0.6571482813051983 
2022-03-28 04:49:21,791: ============================================================
2022-03-28 04:49:21,791: Epoch 24/26 Batch 6500/7662 eta: 4:15:42.629550	Training Loss 0.4240 (0.4387)	Training Prec@1 91.992 (91.378)	Training Prec@5 94.922 (94.585)	
2022-03-28 04:49:21,791: ============================================================
2022-03-28 04:50:57,408: time cost, forward:0.2635553812037672, backward:0.04298562381390027, data cost:0.6569193958025806 
2022-03-28 04:50:57,408: ============================================================
2022-03-28 04:50:57,409: Epoch 24/26 Batch 6600/7662 eta: 4:21:08.875211	Training Loss 0.4273 (0.4387)	Training Prec@1 93.555 (91.378)	Training Prec@5 95.703 (94.584)	
2022-03-28 04:50:57,409: ============================================================
2022-03-28 04:52:30,805: time cost, forward:0.26351728651448497, backward:0.04297827033609361, data cost:0.6565565778917654 
2022-03-28 04:52:30,806: ============================================================
2022-03-28 04:52:30,806: Epoch 24/26 Batch 6700/7662 eta: 4:13:31.599496	Training Loss 0.4399 (0.4387)	Training Prec@1 94.141 (91.380)	Training Prec@5 96.680 (94.584)	
2022-03-28 04:52:30,806: ============================================================
2022-03-28 04:54:04,111: time cost, forward:0.2633744685294646, backward:0.04298637572203091, data cost:0.656247886704564 
2022-03-28 04:54:04,112: ============================================================
2022-03-28 04:54:04,112: Epoch 24/26 Batch 6800/7662 eta: 4:11:43.473788	Training Loss 0.4383 (0.4388)	Training Prec@1 91.602 (91.375)	Training Prec@5 95.312 (94.580)	
2022-03-28 04:54:04,112: ============================================================
2022-03-28 04:55:41,274: time cost, forward:0.2634690791079058, backward:0.04296452734051865, data cost:0.6562799442192837 
2022-03-28 04:55:41,274: ============================================================
2022-03-28 04:55:41,274: Epoch 24/26 Batch 6900/7662 eta: 4:20:30.539951	Training Loss 0.4417 (0.4388)	Training Prec@1 91.602 (91.375)	Training Prec@5 94.336 (94.578)	
2022-03-28 04:55:41,275: ============================================================
2022-03-28 04:57:14,181: time cost, forward:0.2635361242164866, backward:0.042948599218692006, data cost:0.6557761214600067 
2022-03-28 04:57:14,181: ============================================================
2022-03-28 04:57:14,181: Epoch 24/26 Batch 7000/7662 eta: 4:07:33.008139	Training Loss 0.4413 (0.4388)	Training Prec@1 90.625 (91.372)	Training Prec@5 93.750 (94.576)	
2022-03-28 04:57:14,182: ============================================================
2022-03-28 04:58:51,515: time cost, forward:0.26378432823446607, backward:0.04299372618492934, data cost:0.6556263518746528 
2022-03-28 04:58:51,515: ============================================================
2022-03-28 04:58:51,516: Epoch 24/26 Batch 7100/7662 eta: 4:17:43.503278	Training Loss 0.4364 (0.4388)	Training Prec@1 91.211 (91.372)	Training Prec@5 95.117 (94.576)	
2022-03-28 04:58:51,516: ============================================================
2022-03-28 05:00:27,861: time cost, forward:0.264044728142004, backward:0.04299589974596395, data cost:0.6553687528034501 
2022-03-28 05:00:27,862: ============================================================
2022-03-28 05:00:27,862: Epoch 24/26 Batch 7200/7662 eta: 4:13:30.255592	Training Loss 0.4504 (0.4388)	Training Prec@1 91.016 (91.373)	Training Prec@5 94.727 (94.577)	
2022-03-28 05:00:27,863: ============================================================
2022-03-28 05:02:07,072: time cost, forward:0.26444924790690344, backward:0.04298739914110808, data cost:0.6553882125110263 
2022-03-28 05:02:07,073: ============================================================
2022-03-28 05:02:07,073: Epoch 24/26 Batch 7300/7662 eta: 4:19:23.162243	Training Loss 0.4436 (0.4388)	Training Prec@1 89.453 (91.372)	Training Prec@5 92.969 (94.576)	
2022-03-28 05:02:07,073: ============================================================
2022-03-28 05:03:39,037: time cost, forward:0.26459773912157847, backward:0.042961011852569106, data cost:0.6546521476191884 
2022-03-28 05:03:39,038: ============================================================
2022-03-28 05:03:39,039: Epoch 24/26 Batch 7400/7662 eta: 3:58:54.667483	Training Loss 0.4237 (0.4388)	Training Prec@1 93.555 (91.371)	Training Prec@5 97.070 (94.576)	
2022-03-28 05:03:39,039: ============================================================
2022-03-28 05:05:11,585: time cost, forward:0.2645154715633532, backward:0.042965677423880314, data cost:0.6542482099814134 
2022-03-28 05:05:11,585: ============================================================
2022-03-28 05:05:11,586: Epoch 24/26 Batch 7500/7662 eta: 3:58:52.766138	Training Loss 0.4449 (0.4388)	Training Prec@1 90.430 (91.371)	Training Prec@5 94.727 (94.577)	
2022-03-28 05:05:11,586: ============================================================
2022-03-28 05:06:45,414: time cost, forward:0.2645901487852213, backward:0.042971399304489975, data cost:0.65385918793576 
2022-03-28 05:06:45,415: ============================================================
2022-03-28 05:06:45,415: Epoch 24/26 Batch 7600/7662 eta: 4:00:37.541967	Training Loss 0.4323 (0.4389)	Training Prec@1 91.211 (91.368)	Training Prec@5 93.750 (94.573)	
2022-03-28 05:06:45,415: ============================================================
2022-03-28 05:07:46,766: Epoch: 24/26 eta: 3:59:38.429395	Training Loss 0.4410 (0.4389)	Training Prec@1 91.602 (91.367)	Training Prec@5 93.945 (94.573)
2022-03-28 05:07:46,767: ============================================================
2022-03-28 05:09:23,462: time cost, forward:0.240454259544912, backward:0.03767158527566929, data cost:0.6889842784765995 
2022-03-28 05:09:23,463: ============================================================
2022-03-28 05:09:23,463: Epoch 25/26 Batch 100/7662 eta: 4:04:57.849788	Training Loss 0.4357 (0.4375)	Training Prec@1 91.406 (91.582)	Training Prec@5 94.141 (94.618)	
2022-03-28 05:09:23,464: ============================================================
2022-03-28 05:10:58,310: time cost, forward:0.24914093712466445, backward:0.03786141429115181, data cost:0.6682840256235707 
2022-03-28 05:10:58,310: ============================================================
2022-03-28 05:10:58,310: Epoch 25/26 Batch 200/7662 eta: 3:59:05.618000	Training Loss 0.4394 (0.4367)	Training Prec@1 92.773 (91.703)	Training Prec@5 96.094 (94.734)	
2022-03-28 05:10:58,310: ============================================================
2022-03-28 05:12:32,404: time cost, forward:0.25328823953966634, backward:0.037921231725941536, data cost:0.6614201188486156 
2022-03-28 05:12:32,405: ============================================================
2022-03-28 05:12:32,405: Epoch 25/26 Batch 300/7662 eta: 3:55:37.677643	Training Loss 0.4256 (0.4367)	Training Prec@1 93.555 (91.677)	Training Prec@5 96.094 (94.746)	
2022-03-28 05:12:32,405: ============================================================
2022-03-28 05:14:08,919: time cost, forward:0.2585486780133164, backward:0.039282583055042085, data cost:0.6566342034734282 
2022-03-28 05:14:08,919: ============================================================
2022-03-28 05:14:08,919: Epoch 25/26 Batch 400/7662 eta: 4:00:04.827861	Training Loss 0.4366 (0.4370)	Training Prec@1 91.602 (91.686)	Training Prec@5 94.141 (94.752)	
2022-03-28 05:14:08,920: ============================================================
2022-03-28 05:15:44,084: time cost, forward:0.26181508257298286, backward:0.04006303622870742, data cost:0.6522209534425296 
2022-03-28 05:15:44,084: ============================================================
2022-03-28 05:15:44,084: Epoch 25/26 Batch 500/7662 eta: 3:55:08.200323	Training Loss 0.4443 (0.4371)	Training Prec@1 90.820 (91.670)	Training Prec@5 93.164 (94.771)	
2022-03-28 05:15:44,085: ============================================================
2022-03-28 05:17:20,263: time cost, forward:0.26368056394421, backward:0.040591965135628474, data cost:0.651717758337922 
2022-03-28 05:17:20,263: ============================================================
2022-03-28 05:17:20,264: Epoch 25/26 Batch 600/7662 eta: 3:56:02.385716	Training Loss 0.4364 (0.4372)	Training Prec@1 93.164 (91.626)	Training Prec@5 96.680 (94.730)	
2022-03-28 05:17:20,264: ============================================================
2022-03-28 05:18:53,001: time cost, forward:0.2650871505382576, backward:0.04094390671311189, data cost:0.6456569915847887 
2022-03-28 05:18:53,002: ============================================================
2022-03-28 05:18:53,002: Epoch 25/26 Batch 700/7662 eta: 3:46:02.992009	Training Loss 0.4437 (0.4371)	Training Prec@1 91.797 (91.626)	Training Prec@5 96.094 (94.727)	
2022-03-28 05:18:53,002: ============================================================
2022-03-28 05:20:26,892: time cost, forward:0.2654305775562425, backward:0.0411644438479809, data cost:0.6434809797547189 
2022-03-28 05:20:26,893: ============================================================
2022-03-28 05:20:26,893: Epoch 25/26 Batch 800/7662 eta: 3:47:17.651513	Training Loss 0.4277 (0.4371)	Training Prec@1 92.188 (91.611)	Training Prec@5 94.531 (94.718)	
2022-03-28 05:20:26,893: ============================================================
2022-03-28 05:21:59,495: time cost, forward:0.2651431817764435, backward:0.04132792284013963, data cost:0.6409111534793331 
2022-03-28 05:21:59,495: ============================================================
2022-03-28 05:21:59,495: Epoch 25/26 Batch 900/7662 eta: 3:42:37.861095	Training Loss 0.4394 (0.4370)	Training Prec@1 92.188 (91.619)	Training Prec@5 95.117 (94.724)	
2022-03-28 05:21:59,495: ============================================================
2022-03-28 05:23:34,911: time cost, forward:0.265726753899285, backward:0.04148431988927098, data cost:0.6408439264879809 
2022-03-28 05:23:34,912: ============================================================
2022-03-28 05:23:34,912: Epoch 25/26 Batch 1000/7662 eta: 3:47:48.467635	Training Loss 0.4415 (0.4372)	Training Prec@1 91.406 (91.615)	Training Prec@5 95.117 (94.725)	
2022-03-28 05:23:34,912: ============================================================
2022-03-28 05:25:08,747: time cost, forward:0.2662071780360103, backward:0.04158653401590891, data cost:0.6386751827052553 
2022-03-28 05:25:08,909: ============================================================
2022-03-28 05:25:08,909: Epoch 25/26 Batch 1100/7662 eta: 3:42:51.148131	Training Loss 0.4411 (0.4372)	Training Prec@1 93.359 (91.610)	Training Prec@5 96.094 (94.712)	
2022-03-28 05:25:08,910: ============================================================
2022-03-28 05:26:44,091: time cost, forward:0.2668727277416901, backward:0.04186300499624168, data cost:0.6388947138495998 
2022-03-28 05:26:44,091: ============================================================
2022-03-28 05:26:44,091: Epoch 25/26 Batch 1200/7662 eta: 3:44:04.396972	Training Loss 0.4536 (0.4373)	Training Prec@1 88.477 (91.579)	Training Prec@5 91.797 (94.700)	
2022-03-28 05:26:44,091: ============================================================
2022-03-28 05:28:18,000: time cost, forward:0.2671331939007155, backward:0.04198027354556841, data cost:0.6378307329681491 
2022-03-28 05:28:18,000: ============================================================
2022-03-28 05:28:18,000: Epoch 25/26 Batch 1300/7662 eta: 3:39:30.742990	Training Loss 0.4420 (0.4372)	Training Prec@1 89.258 (91.576)	Training Prec@5 93.945 (94.702)	
2022-03-28 05:28:18,000: ============================================================
2022-03-28 05:29:53,436: time cost, forward:0.26868154885003703, backward:0.042128311897534146, data cost:0.6365736882289534 
2022-03-28 05:29:53,436: ============================================================
2022-03-28 05:29:53,437: Epoch 25/26 Batch 1400/7662 eta: 3:41:29.523904	Training Loss 0.4416 (0.4373)	Training Prec@1 91.797 (91.569)	Training Prec@5 93.945 (94.700)	
2022-03-28 05:29:53,437: ============================================================
2022-03-28 05:31:26,120: time cost, forward:0.2683702733534189, backward:0.04209270629984606, data cost:0.6354803122863363 
2022-03-28 05:31:26,121: ============================================================
2022-03-28 05:31:26,121: Epoch 25/26 Batch 1500/7662 eta: 3:33:33.611192	Training Loss 0.4492 (0.4373)	Training Prec@1 87.305 (91.567)	Training Prec@5 92.578 (94.705)	
2022-03-28 05:31:26,121: ============================================================
2022-03-28 05:33:01,963: time cost, forward:0.26950711082711376, backward:0.04226974594063726, data cost:0.6350055215059034 
2022-03-28 05:33:01,964: ============================================================
2022-03-28 05:33:01,964: Epoch 25/26 Batch 1600/7662 eta: 3:39:14.425563	Training Loss 0.4334 (0.4373)	Training Prec@1 91.406 (91.559)	Training Prec@5 94.922 (94.704)	
2022-03-28 05:33:01,964: ============================================================
2022-03-28 05:34:38,571: time cost, forward:0.2701153783253742, backward:0.042298056645699286, data cost:0.6351897330618101 
2022-03-28 05:34:38,571: ============================================================
2022-03-28 05:34:38,571: Epoch 25/26 Batch 1700/7662 eta: 3:39:22.795762	Training Loss 0.4391 (0.4373)	Training Prec@1 91.602 (91.569)	Training Prec@5 95.117 (94.711)	
2022-03-28 05:34:38,572: ============================================================
2022-03-28 05:36:12,509: time cost, forward:0.27021522824137395, backward:0.04242489548641287, data cost:0.634707783247909 
2022-03-28 05:36:12,510: ============================================================
2022-03-28 05:36:12,510: Epoch 25/26 Batch 1800/7662 eta: 3:31:45.206558	Training Loss 0.4465 (0.4373)	Training Prec@1 91.016 (91.574)	Training Prec@5 94.336 (94.723)	
2022-03-28 05:36:12,510: ============================================================
2022-03-28 05:37:46,345: time cost, forward:0.2698873407656171, backward:0.042438984168335414, data cost:0.6345947614903824 
2022-03-28 05:37:46,346: ============================================================
2022-03-28 05:37:46,346: Epoch 25/26 Batch 1900/7662 eta: 3:29:57.448683	Training Loss 0.4369 (0.4373)	Training Prec@1 92.188 (91.568)	Training Prec@5 95.312 (94.716)	
2022-03-28 05:37:46,346: ============================================================
2022-03-28 05:39:22,649: time cost, forward:0.2703226124304065, backward:0.042527613251014854, data cost:0.6348831380469134 
2022-03-28 05:39:22,649: ============================================================
2022-03-28 05:39:22,649: Epoch 25/26 Batch 2000/7662 eta: 3:33:52.418461	Training Loss 0.4243 (0.4374)	Training Prec@1 92.188 (91.562)	Training Prec@5 96.094 (94.709)	
2022-03-28 05:39:22,649: ============================================================
2022-03-28 05:40:54,177: time cost, forward:0.2700416465893764, backward:0.042533786481990875, data cost:0.6335575387499456 
2022-03-28 05:40:54,177: ============================================================
2022-03-28 05:40:54,178: Epoch 25/26 Batch 2100/7662 eta: 3:21:44.629127	Training Loss 0.4295 (0.4374)	Training Prec@1 92.578 (91.556)	Training Prec@5 95.898 (94.701)	
2022-03-28 05:40:54,178: ============================================================
2022-03-28 05:42:28,015: time cost, forward:0.2696585590159584, backward:0.04251039770854067, data cost:0.6332790212991185 
2022-03-28 05:42:28,015: ============================================================
2022-03-28 05:42:28,016: Epoch 25/26 Batch 2200/7662 eta: 3:25:16.243485	Training Loss 0.4300 (0.4374)	Training Prec@1 91.992 (91.558)	Training Prec@5 95.703 (94.704)	
2022-03-28 05:42:28,016: ============================================================
2022-03-28 05:44:00,252: time cost, forward:0.269525613822124, backward:0.04254309370912848, data cost:0.6327120344137928 
2022-03-28 05:44:00,252: ============================================================
2022-03-28 05:44:00,252: Epoch 25/26 Batch 2300/7662 eta: 3:20:13.778105	Training Loss 0.4312 (0.4374)	Training Prec@1 94.531 (91.549)	Training Prec@5 96.289 (94.701)	
2022-03-28 05:44:00,252: ============================================================
2022-03-28 05:45:36,511: time cost, forward:0.26973871421495943, backward:0.042570614327784126, data cost:0.6331774575256118 
2022-03-28 05:45:36,523: ============================================================
2022-03-28 05:45:36,523: Epoch 25/26 Batch 2400/7662 eta: 3:27:22.995676	Training Loss 0.4357 (0.4374)	Training Prec@1 92.188 (91.534)	Training Prec@5 94.531 (94.691)	
2022-03-28 05:45:36,523: ============================================================
2022-03-28 05:47:11,581: time cost, forward:0.2695792908189582, backward:0.04265064342158372, data cost:0.6333442450809975 
2022-03-28 05:47:11,581: ============================================================
2022-03-28 05:47:11,581: Epoch 25/26 Batch 2500/7662 eta: 3:23:11.266422	Training Loss 0.4376 (0.4375)	Training Prec@1 92.383 (91.518)	Training Prec@5 94.922 (94.680)	
2022-03-28 05:47:11,581: ============================================================
2022-03-28 05:48:47,086: time cost, forward:0.26967496172929556, backward:0.042693887411882986, data cost:0.6335463064273719 
2022-03-28 05:48:47,087: ============================================================
2022-03-28 05:48:47,087: Epoch 25/26 Batch 2600/7662 eta: 3:22:33.075886	Training Loss 0.4401 (0.4375)	Training Prec@1 90.430 (91.517)	Training Prec@5 93.750 (94.679)	
2022-03-28 05:48:47,087: ============================================================
2022-03-28 05:50:21,264: time cost, forward:0.26939492792763414, backward:0.04270471100808957, data cost:0.6337271840009657 
2022-03-28 05:50:21,264: ============================================================
2022-03-28 05:50:21,265: Epoch 25/26 Batch 2700/7662 eta: 3:18:09.941132	Training Loss 0.4397 (0.4375)	Training Prec@1 93.164 (91.512)	Training Prec@5 95.117 (94.677)	
2022-03-28 05:50:21,265: ============================================================
2022-03-28 05:51:53,297: time cost, forward:0.26960680960927447, backward:0.04273929890669768, data cost:0.6324736482545963 
2022-03-28 05:51:53,298: ============================================================
2022-03-28 05:51:53,298: Epoch 25/26 Batch 2800/7662 eta: 3:12:07.193451	Training Loss 0.4365 (0.4375)	Training Prec@1 90.234 (91.513)	Training Prec@5 93.164 (94.674)	
2022-03-28 05:51:53,298: ============================================================
2022-03-28 05:53:25,213: time cost, forward:0.2696860682845075, backward:0.04271917994493614, data cost:0.631610922749267 
2022-03-28 05:53:25,213: ============================================================
2022-03-28 05:53:25,213: Epoch 25/26 Batch 2900/7662 eta: 3:10:20.426925	Training Loss 0.4387 (0.4375)	Training Prec@1 90.430 (91.508)	Training Prec@5 93.945 (94.673)	
2022-03-28 05:53:25,213: ============================================================
2022-03-28 05:54:58,993: time cost, forward:0.2696327960423606, backward:0.04273294607533261, data cost:0.6312998547161289 
2022-03-28 05:54:58,994: ============================================================
2022-03-28 05:54:58,995: Epoch 25/26 Batch 3000/7662 eta: 3:12:38.568095	Training Loss 0.4322 (0.4375)	Training Prec@1 91.992 (91.509)	Training Prec@5 93.555 (94.670)	
2022-03-28 05:54:58,995: ============================================================
2022-03-28 05:56:33,763: time cost, forward:0.26924220682459904, backward:0.04274306177285149, data cost:0.6319427307900709 
2022-03-28 05:56:33,764: ============================================================
2022-03-28 05:56:33,764: Epoch 25/26 Batch 3100/7662 eta: 3:13:05.576857	Training Loss 0.4397 (0.4375)	Training Prec@1 92.188 (91.509)	Training Prec@5 94.922 (94.671)	
2022-03-28 05:56:33,764: ============================================================
2022-03-28 05:58:06,539: time cost, forward:0.2692439530781933, backward:0.042798632865922455, data cost:0.6313627097114022 
2022-03-28 05:58:06,539: ============================================================
2022-03-28 05:58:06,540: Epoch 25/26 Batch 3200/7662 eta: 3:07:29.031464	Training Loss 0.4428 (0.4376)	Training Prec@1 91.992 (91.505)	Training Prec@5 95.117 (94.669)	
2022-03-28 05:58:06,540: ============================================================
2022-03-28 05:59:29,218: time cost, forward:0.26790348585174456, backward:0.042766564468356034, data cost:0.6292154491218735 
2022-03-28 05:59:29,219: ============================================================
2022-03-28 05:59:29,219: Epoch 25/26 Batch 3300/7662 eta: 2:45:42.163270	Training Loss 0.4387 (0.4376)	Training Prec@1 92.188 (91.504)	Training Prec@5 95.117 (94.668)	
2022-03-28 05:59:29,219: ============================================================
2022-03-28 06:01:02,160: time cost, forward:0.26715696114026366, backward:0.04277705227357214, data cost:0.6296146553591723 
2022-03-28 06:01:02,160: ============================================================
2022-03-28 06:01:02,161: Epoch 25/26 Batch 3400/7662 eta: 3:04:43.306508	Training Loss 0.4342 (0.4376)	Training Prec@1 91.602 (91.497)	Training Prec@5 95.312 (94.664)	
2022-03-28 06:01:02,161: ============================================================
2022-03-28 06:02:37,330: time cost, forward:0.2669619872727439, backward:0.04280955773075842, data cost:0.6301131309117887 
2022-03-28 06:02:37,330: ============================================================
2022-03-28 06:02:37,331: Epoch 25/26 Batch 3500/7662 eta: 3:07:33.868607	Training Loss 0.4428 (0.4376)	Training Prec@1 89.648 (91.493)	Training Prec@5 94.141 (94.662)	
2022-03-28 06:02:37,331: ============================================================
2022-03-28 06:04:13,834: time cost, forward:0.26654922250046537, backward:0.04282243101422606, data cost:0.6312227547251539 
2022-03-28 06:04:13,835: ============================================================
2022-03-28 06:04:13,835: Epoch 25/26 Batch 3600/7662 eta: 3:08:35.105204	Training Loss 0.4361 (0.4377)	Training Prec@1 91.211 (91.487)	Training Prec@5 94.141 (94.659)	
2022-03-28 06:04:13,835: ============================================================
2022-03-28 06:05:47,456: time cost, forward:0.2664538239362788, backward:0.04284187953966506, data cost:0.6311506587577916 
2022-03-28 06:05:47,457: ============================================================
2022-03-28 06:05:47,458: Epoch 25/26 Batch 3700/7662 eta: 3:01:23.633772	Training Loss 0.4291 (0.4377)	Training Prec@1 93.164 (91.485)	Training Prec@5 94.727 (94.657)	
2022-03-28 06:05:47,458: ============================================================
2022-03-28 06:07:23,884: time cost, forward:0.26639798742496645, backward:0.042924456484664836, data cost:0.6317713786564741 
2022-03-28 06:07:23,884: ============================================================
2022-03-28 06:07:23,884: Epoch 25/26 Batch 3800/7662 eta: 3:05:13.218817	Training Loss 0.4407 (0.4377)	Training Prec@1 91.016 (91.483)	Training Prec@5 94.922 (94.660)	
2022-03-28 06:07:23,885: ============================================================
2022-03-28 06:09:00,104: time cost, forward:0.26634487710753657, backward:0.04293968195057918, data cost:0.6323421880751886 
2022-03-28 06:09:00,104: ============================================================
2022-03-28 06:09:00,104: Epoch 25/26 Batch 3900/7662 eta: 3:03:13.127267	Training Loss 0.4320 (0.4378)	Training Prec@1 90.625 (91.478)	Training Prec@5 95.312 (94.656)	
2022-03-28 06:09:00,104: ============================================================
2022-03-28 06:10:35,114: time cost, forward:0.26607405367300613, backward:0.042923110280820326, data cost:0.6328371161370017 
2022-03-28 06:10:35,114: ============================================================
2022-03-28 06:10:35,114: Epoch 25/26 Batch 4000/7662 eta: 2:59:19.841215	Training Loss 0.4350 (0.4378)	Training Prec@1 92.188 (91.479)	Training Prec@5 94.922 (94.657)	
2022-03-28 06:10:35,114: ============================================================
2022-03-28 06:12:09,069: time cost, forward:0.26594479300970564, backward:0.04294011080430816, data cost:0.6328836476171735 
2022-03-28 06:12:09,069: ============================================================
2022-03-28 06:12:09,070: Epoch 25/26 Batch 4100/7662 eta: 2:55:46.507565	Training Loss 0.4310 (0.4378)	Training Prec@1 91.992 (91.479)	Training Prec@5 95.312 (94.657)	
2022-03-28 06:12:09,070: ============================================================
2022-03-28 06:13:43,335: time cost, forward:0.26584908058882384, backward:0.042920506775563715, data cost:0.6330001232708656 
2022-03-28 06:13:43,335: ============================================================
2022-03-28 06:13:43,336: Epoch 25/26 Batch 4200/7662 eta: 2:54:47.085687	Training Loss 0.4331 (0.4378)	Training Prec@1 93.164 (91.477)	Training Prec@5 95.898 (94.656)	
2022-03-28 06:13:43,336: ============================================================
2022-03-28 06:15:17,460: time cost, forward:0.26578723372179675, backward:0.04290075129091698, data cost:0.6330487910024675 
2022-03-28 06:15:17,460: ============================================================
2022-03-28 06:15:17,461: Epoch 25/26 Batch 4300/7662 eta: 2:52:57.341286	Training Loss 0.4489 (0.4378)	Training Prec@1 90.234 (91.482)	Training Prec@5 92.969 (94.658)	
2022-03-28 06:15:17,461: ============================================================
2022-03-28 06:16:52,620: time cost, forward:0.26586981620753886, backward:0.04293383720599134, data cost:0.6331550793692209 
2022-03-28 06:16:52,620: ============================================================
2022-03-28 06:16:52,621: Epoch 25/26 Batch 4400/7662 eta: 2:53:16.171325	Training Loss 0.4302 (0.4378)	Training Prec@1 91.992 (91.480)	Training Prec@5 95.117 (94.657)	
2022-03-28 06:16:52,621: ============================================================
2022-03-28 06:18:26,408: time cost, forward:0.26575225553239123, backward:0.04284322948078496, data cost:0.6332574305626572 
2022-03-28 06:18:26,408: ============================================================
2022-03-28 06:18:26,408: Epoch 25/26 Batch 4500/7662 eta: 2:49:12.508324	Training Loss 0.4523 (0.4378)	Training Prec@1 90.430 (91.478)	Training Prec@5 94.336 (94.654)	
2022-03-28 06:18:26,408: ============================================================
2022-03-28 06:19:59,314: time cost, forward:0.2655620708701973, backward:0.04288427833371329, data cost:0.6331185475461611 
2022-03-28 06:19:59,314: ============================================================
2022-03-28 06:19:59,314: Epoch 25/26 Batch 4600/7662 eta: 2:46:04.206308	Training Loss 0.4423 (0.4378)	Training Prec@1 90.430 (91.469)	Training Prec@5 94.531 (94.648)	
2022-03-28 06:19:59,315: ============================================================
2022-03-28 06:21:35,214: time cost, forward:0.2654370975433499, backward:0.04289806109840603, data cost:0.6336072205127262 
2022-03-28 06:21:35,229: ============================================================
2022-03-28 06:21:35,229: Epoch 25/26 Batch 4700/7662 eta: 2:49:50.901186	Training Loss 0.4425 (0.4378)	Training Prec@1 89.258 (91.471)	Training Prec@5 92.773 (94.651)	
2022-03-28 06:21:35,229: ============================================================
2022-03-28 06:23:11,752: time cost, forward:0.26515805157404887, backward:0.042851760502183506, data cost:0.6344083966153641 
2022-03-28 06:23:11,753: ============================================================
2022-03-28 06:23:11,753: Epoch 25/26 Batch 4800/7662 eta: 2:49:19.153878	Training Loss 0.4319 (0.4378)	Training Prec@1 92.578 (91.470)	Training Prec@5 94.727 (94.650)	
2022-03-28 06:23:11,753: ============================================================
2022-03-28 06:24:44,722: time cost, forward:0.2650548677878566, backward:0.04260173800722096, data cost:0.6344446235103105 
2022-03-28 06:24:44,723: ============================================================
2022-03-28 06:24:44,724: Epoch 25/26 Batch 4900/7662 eta: 2:41:32.184715	Training Loss 0.4354 (0.4378)	Training Prec@1 88.867 (91.468)	Training Prec@5 92.969 (94.649)	
2022-03-28 06:24:44,724: ============================================================
2022-03-28 06:26:19,765: time cost, forward:0.26497737687452955, backward:0.04236767072156802, data cost:0.6349534374591135 
2022-03-28 06:26:19,765: ============================================================
2022-03-28 06:26:19,765: Epoch 25/26 Batch 5000/7662 eta: 2:43:33.066394	Training Loss 0.4313 (0.4378)	Training Prec@1 92.578 (91.470)	Training Prec@5 96.094 (94.647)	
2022-03-28 06:26:19,766: ============================================================
2022-03-28 06:27:55,597: time cost, forward:0.2650903632393489, backward:0.04213296883151587, data cost:0.6353952432525091 
2022-03-28 06:27:55,598: ============================================================
2022-03-28 06:27:55,598: Epoch 25/26 Batch 5100/7662 eta: 2:43:18.886872	Training Loss 0.4340 (0.4378)	Training Prec@1 93.164 (91.471)	Training Prec@5 96.289 (94.651)	
2022-03-28 06:27:55,598: ============================================================
2022-03-28 06:29:29,882: time cost, forward:0.26513927673967924, backward:0.04190076106005986, data cost:0.6355095567738099 
2022-03-28 06:29:29,883: ============================================================
2022-03-28 06:29:29,883: Epoch 25/26 Batch 5200/7662 eta: 2:39:06.339964	Training Loss 0.4261 (0.4378)	Training Prec@1 91.406 (91.470)	Training Prec@5 95.117 (94.651)	
2022-03-28 06:29:29,883: ============================================================
2022-03-28 06:31:07,547: time cost, forward:0.26512469982601466, backward:0.04172629805235711, data cost:0.6364022220029181 
2022-03-28 06:31:07,547: ============================================================
2022-03-28 06:31:07,547: Epoch 25/26 Batch 5300/7662 eta: 2:43:10.883525	Training Loss 0.4365 (0.4378)	Training Prec@1 91.992 (91.472)	Training Prec@5 94.531 (94.653)	
2022-03-28 06:31:07,548: ============================================================
2022-03-28 06:32:40,678: time cost, forward:0.26514875118236536, backward:0.04162123318534578, data cost:0.6362581038435293 
2022-03-28 06:32:40,679: ============================================================
2022-03-28 06:32:40,679: Epoch 25/26 Batch 5400/7662 eta: 2:34:03.301044	Training Loss 0.4373 (0.4378)	Training Prec@1 89.258 (91.477)	Training Prec@5 92.578 (94.656)	
2022-03-28 06:32:40,679: ============================================================
2022-03-28 06:34:16,826: time cost, forward:0.2651882162525949, backward:0.04159796439554284, data cost:0.6365658322948394 
2022-03-28 06:34:16,826: ============================================================
2022-03-28 06:34:16,827: Epoch 25/26 Batch 5500/7662 eta: 2:37:26.501623	Training Loss 0.4299 (0.4379)	Training Prec@1 93.750 (91.473)	Training Prec@5 97.070 (94.654)	
2022-03-28 06:34:16,827: ============================================================
2022-03-28 06:35:52,288: time cost, forward:0.2651215020748819, backward:0.0414503446368793, data cost:0.6369773978355804 
2022-03-28 06:35:52,288: ============================================================
2022-03-28 06:35:52,288: Epoch 25/26 Batch 5600/7662 eta: 2:34:43.651272	Training Loss 0.4396 (0.4379)	Training Prec@1 89.258 (91.471)	Training Prec@5 92.578 (94.653)	
2022-03-28 06:35:52,288: ============================================================
2022-03-28 06:37:28,750: time cost, forward:0.2651919445503718, backward:0.04136546090268779, data cost:0.6373488326975496 
2022-03-28 06:37:28,751: ============================================================
2022-03-28 06:37:28,751: Epoch 25/26 Batch 5700/7662 eta: 2:34:44.555632	Training Loss 0.4358 (0.4379)	Training Prec@1 90.039 (91.471)	Training Prec@5 93.750 (94.653)	
2022-03-28 06:37:28,751: ============================================================
2022-03-28 06:39:03,031: time cost, forward:0.26518688840811816, backward:0.04140645328277678, data cost:0.6372951102433564 
2022-03-28 06:39:03,031: ============================================================
2022-03-28 06:39:03,031: Epoch 25/26 Batch 5800/7662 eta: 2:29:40.160982	Training Loss 0.4349 (0.4379)	Training Prec@1 91.797 (91.471)	Training Prec@5 94.531 (94.653)	
2022-03-28 06:39:03,031: ============================================================
2022-03-28 06:40:36,838: time cost, forward:0.2650710664617548, backward:0.041429958054121724, data cost:0.6372326522141033 
2022-03-28 06:40:36,839: ============================================================
2022-03-28 06:40:36,839: Epoch 25/26 Batch 5900/7662 eta: 2:27:21.374010	Training Loss 0.4338 (0.4379)	Training Prec@1 90.820 (91.467)	Training Prec@5 93.945 (94.651)	
2022-03-28 06:40:36,839: ============================================================
2022-03-28 06:42:15,039: time cost, forward:0.2651339020008126, backward:0.04145620552415271, data cost:0.6377976426364462 
2022-03-28 06:42:15,040: ============================================================
2022-03-28 06:42:15,040: Epoch 25/26 Batch 6000/7662 eta: 2:32:37.259188	Training Loss 0.4521 (0.4379)	Training Prec@1 89.258 (91.468)	Training Prec@5 93.750 (94.652)	
2022-03-28 06:42:15,040: ============================================================
2022-03-28 06:43:48,460: time cost, forward:0.26512759086401233, backward:0.041506198649133574, data cost:0.6375837371004939 
2022-03-28 06:43:48,461: ============================================================
2022-03-28 06:43:48,462: Epoch 25/26 Batch 6100/7662 eta: 2:23:38.136781	Training Loss 0.4373 (0.4379)	Training Prec@1 92.383 (91.466)	Training Prec@5 94.922 (94.651)	
2022-03-28 06:43:48,462: ============================================================
2022-03-28 06:45:21,880: time cost, forward:0.26517660503599755, backward:0.041515443378503256, data cost:0.6373921979490952 
2022-03-28 06:45:21,880: ============================================================
2022-03-28 06:45:21,880: Epoch 25/26 Batch 6200/7662 eta: 2:22:04.456852	Training Loss 0.4323 (0.4379)	Training Prec@1 92.578 (91.468)	Training Prec@5 94.336 (94.652)	
2022-03-28 06:45:21,880: ============================================================
2022-03-28 06:46:55,873: time cost, forward:0.26515868607542403, backward:0.04157238964959541, data cost:0.6372730195626396 
2022-03-28 06:46:55,873: ============================================================
2022-03-28 06:46:55,873: Epoch 25/26 Batch 6300/7662 eta: 2:21:22.852373	Training Loss 0.4424 (0.4379)	Training Prec@1 89.648 (91.468)	Training Prec@5 93.555 (94.653)	
2022-03-28 06:46:55,873: ============================================================
2022-03-28 06:48:31,923: time cost, forward:0.2651918086060734, backward:0.04160380903715863, data cost:0.6374494346124453 
2022-03-28 06:48:31,923: ============================================================
2022-03-28 06:48:31,924: Epoch 25/26 Batch 6400/7662 eta: 2:22:52.496031	Training Loss 0.4391 (0.4379)	Training Prec@1 91.406 (91.467)	Training Prec@5 94.531 (94.651)	
2022-03-28 06:48:31,924: ============================================================
2022-03-28 06:50:05,824: time cost, forward:0.2651434955385616, backward:0.04160431436913475, data cost:0.6374249662283953 
2022-03-28 06:50:05,824: ============================================================
2022-03-28 06:50:05,825: Epoch 25/26 Batch 6500/7662 eta: 2:18:06.765251	Training Loss 0.4344 (0.4379)	Training Prec@1 90.430 (91.468)	Training Prec@5 92.773 (94.651)	
2022-03-28 06:50:05,825: ============================================================
2022-03-28 06:51:41,955: time cost, forward:0.2650457587562234, backward:0.04163676194122911, data cost:0.6377449362616519 
2022-03-28 06:51:41,956: ============================================================
2022-03-28 06:51:41,956: Epoch 25/26 Batch 6600/7662 eta: 2:19:47.459501	Training Loss 0.4374 (0.4379)	Training Prec@1 91.406 (91.465)	Training Prec@5 94.141 (94.652)	
2022-03-28 06:51:41,956: ============================================================
2022-03-28 06:53:14,613: time cost, forward:0.2647907295446286, backward:0.04165058727495029, data cost:0.637721753864257 
2022-03-28 06:53:14,613: ============================================================
2022-03-28 06:53:14,613: Epoch 25/26 Batch 6700/7662 eta: 2:13:11.718179	Training Loss 0.4331 (0.4380)	Training Prec@1 91.406 (91.466)	Training Prec@5 94.141 (94.652)	
2022-03-28 06:53:14,614: ============================================================
2022-03-28 06:54:49,764: time cost, forward:0.26472367628792975, backward:0.041690491984777374, data cost:0.6378383722738722 
2022-03-28 06:54:49,764: ============================================================
2022-03-28 06:54:49,764: Epoch 25/26 Batch 6800/7662 eta: 2:15:11.601350	Training Loss 0.4338 (0.4380)	Training Prec@1 92.188 (91.463)	Training Prec@5 96.484 (94.651)	
2022-03-28 06:54:49,764: ============================================================
2022-03-28 06:56:24,244: time cost, forward:0.26469248024376085, backward:0.041719354431013, data cost:0.6377384739002294 
2022-03-28 06:56:24,245: ============================================================
2022-03-28 06:56:24,245: Epoch 25/26 Batch 6900/7662 eta: 2:12:40.017798	Training Loss 0.4384 (0.4380)	Training Prec@1 91.016 (91.460)	Training Prec@5 94.141 (94.649)	
2022-03-28 06:56:24,245: ============================================================
2022-03-28 06:57:57,508: time cost, forward:0.26469351281641484, backward:0.04175462850861455, data cost:0.6376460698148594 
2022-03-28 06:57:57,508: ============================================================
2022-03-28 06:57:57,508: Epoch 25/26 Batch 7000/7662 eta: 2:09:24.171169	Training Loss 0.4349 (0.4380)	Training Prec@1 91.016 (91.460)	Training Prec@5 94.141 (94.649)	
2022-03-28 06:57:57,509: ============================================================
2022-03-28 06:59:32,077: time cost, forward:0.2647366946239608, backward:0.04178836906874813, data cost:0.6375926956523891 
2022-03-28 06:59:32,077: ============================================================
2022-03-28 06:59:32,077: Epoch 25/26 Batch 7100/7662 eta: 2:09:38.289524	Training Loss 0.4354 (0.4380)	Training Prec@1 92.383 (91.460)	Training Prec@5 94.336 (94.648)	
2022-03-28 06:59:32,077: ============================================================
2022-03-28 07:01:07,123: time cost, forward:0.26465974497884526, backward:0.04179083060714864, data cost:0.6376993953229521 
2022-03-28 07:01:07,123: ============================================================
2022-03-28 07:01:07,124: Epoch 25/26 Batch 7200/7662 eta: 2:08:42.506988	Training Loss 0.4255 (0.4380)	Training Prec@1 92.383 (91.461)	Training Prec@5 95.508 (94.648)	
2022-03-28 07:01:07,124: ============================================================
2022-03-28 07:02:41,754: time cost, forward:0.2645398873403507, backward:0.04180624266490003, data cost:0.6378825047944143 
2022-03-28 07:02:41,754: ============================================================
2022-03-28 07:02:41,754: Epoch 25/26 Batch 7300/7662 eta: 2:06:34.122466	Training Loss 0.4438 (0.4380)	Training Prec@1 91.016 (91.459)	Training Prec@5 94.336 (94.646)	
2022-03-28 07:02:41,755: ============================================================
2022-03-28 07:04:16,599: time cost, forward:0.2644599679837856, backward:0.04184920556771786, data cost:0.6379686120491218 
2022-03-28 07:04:16,599: ============================================================
2022-03-28 07:04:16,599: Epoch 25/26 Batch 7400/7662 eta: 2:05:16.469124	Training Loss 0.4408 (0.4381)	Training Prec@1 90.430 (91.457)	Training Prec@5 93.945 (94.644)	
2022-03-28 07:04:16,600: ============================================================
2022-03-28 07:05:50,798: time cost, forward:0.26436012747256277, backward:0.04185759631740775, data cost:0.6380248365759579 
2022-03-28 07:05:50,799: ============================================================
2022-03-28 07:05:50,799: Epoch 25/26 Batch 7500/7662 eta: 2:02:51.131124	Training Loss 0.4242 (0.4381)	Training Prec@1 93.945 (91.453)	Training Prec@5 96.484 (94.641)	
2022-03-28 07:05:50,800: ============================================================
2022-03-28 07:07:25,471: time cost, forward:0.2643115420391064, backward:0.041893053970959396, data cost:0.6380647170040102 
2022-03-28 07:07:25,471: ============================================================
2022-03-28 07:07:25,472: Epoch 25/26 Batch 7600/7662 eta: 2:01:53.446362	Training Loss 0.4401 (0.4381)	Training Prec@1 90.234 (91.450)	Training Prec@5 92.969 (94.638)	
2022-03-28 07:07:25,472: ============================================================
2022-03-28 07:08:26,176: Epoch: 25/26 eta: 2:00:53.802722	Training Loss 0.4272 (0.4381)	Training Prec@1 93.750 (91.451)	Training Prec@5 96.289 (94.639)
2022-03-28 07:08:26,177: ============================================================
2022-03-28 07:08:26,429: Save Checkpoint...
2022-03-28 07:08:26,442: ============================================================
2022-03-28 07:08:29,495: Save done!
2022-03-28 07:08:29,495: ============================================================
2022-03-28 07:10:09,523: time cost, forward:0.2605969881770587, backward:0.036955597424747966, data cost:0.7069943505104141 
2022-03-28 07:10:09,524: ============================================================
2022-03-28 07:10:09,524: Epoch 26/26 Batch 100/7662 eta: 2:05:59.429041	Training Loss 0.4319 (0.4361)	Training Prec@1 91.797 (91.570)	Training Prec@5 94.141 (94.778)	
2022-03-28 07:10:09,524: ============================================================
2022-03-28 07:11:42,036: time cost, forward:0.2579519221531087, backward:0.03881659340019801, data cost:0.6647391918316559 
2022-03-28 07:11:42,036: ============================================================
2022-03-28 07:11:42,036: Epoch 26/26 Batch 200/7662 eta: 1:55:04.197612	Training Loss 0.4461 (0.4360)	Training Prec@1 91.797 (91.603)	Training Prec@5 94.336 (94.813)	
2022-03-28 07:11:42,037: ============================================================
2022-03-28 07:13:15,774: time cost, forward:0.25359673085420026, backward:0.039334360173713404, data cost:0.6593838527449796 
2022-03-28 07:13:15,774: ============================================================
2022-03-28 07:13:15,775: Epoch 26/26 Batch 300/7662 eta: 1:55:01.939414	Training Loss 0.4381 (0.4361)	Training Prec@1 90.039 (91.624)	Training Prec@5 93.945 (94.800)	
2022-03-28 07:13:15,775: ============================================================
2022-03-28 07:13:59,587: time cost, forward:0.2203853530692576, backward:0.038643627835993184, data cost:0.5670368731171266 
2022-03-28 07:13:59,587: ============================================================
2022-03-28 07:13:59,587: Epoch 26/26 Batch 400/7662 eta: 0:53:02.110187	Training Loss 0.4365 (0.4363)	Training Prec@1 91.211 (91.627)	Training Prec@5 94.922 (94.771)	
2022-03-28 07:13:59,588: ============================================================
2022-03-28 07:14:38,293: time cost, forward:0.19833474933264966, backward:0.0380671836570174, data cost:0.5016120010483002 
2022-03-28 07:14:38,293: ============================================================
2022-03-28 07:14:38,294: Epoch 26/26 Batch 500/7662 eta: 0:46:12.536062	Training Loss 0.4369 (0.4365)	Training Prec@1 93.359 (91.621)	Training Prec@5 96.094 (94.775)	
2022-03-28 07:14:38,294: ============================================================
2022-03-28 07:15:19,062: time cost, forward:0.1829854542504567, backward:0.03773477360083782, data cost:0.4620527027047337 
2022-03-28 07:15:19,062: ============================================================
2022-03-28 07:15:19,063: Epoch 26/26 Batch 600/7662 eta: 0:47:59.516528	Training Loss 0.4405 (0.4365)	Training Prec@1 92.383 (91.584)	Training Prec@5 95.312 (94.740)	
2022-03-28 07:15:19,063: ============================================================
2022-03-28 07:16:00,246: time cost, forward:0.1719593909677006, backward:0.03747885728598664, data cost:0.43435896926683415 
2022-03-28 07:16:00,246: ============================================================
2022-03-28 07:16:00,247: Epoch 26/26 Batch 700/7662 eta: 0:47:47.636393	Training Loss 0.4393 (0.4365)	Training Prec@1 91.211 (91.586)	Training Prec@5 95.508 (94.745)	
2022-03-28 07:16:00,247: ============================================================
2022-03-28 07:16:39,649: time cost, forward:0.16422858733557938, backward:0.03726953051713888, data cost:0.4112074124499764 
2022-03-28 07:16:39,649: ============================================================
2022-03-28 07:16:39,649: Epoch 26/26 Batch 800/7662 eta: 0:45:04.212173	Training Loss 0.4288 (0.4365)	Training Prec@1 91.992 (91.602)	Training Prec@5 94.141 (94.750)	
2022-03-28 07:16:39,649: ============================================================
2022-03-28 07:17:18,468: time cost, forward:0.15789649589971388, backward:0.03712490747980069, data cost:0.39259547731104627 
2022-03-28 07:17:18,469: ============================================================
2022-03-28 07:17:18,470: Epoch 26/26 Batch 900/7662 eta: 0:43:45.398917	Training Loss 0.4363 (0.4365)	Training Prec@1 91.211 (91.585)	Training Prec@5 94.336 (94.732)	
2022-03-28 07:17:18,470: ============================================================
2022-03-28 07:17:58,399: time cost, forward:0.15285982383980048, backward:0.03710352694308078, data cost:0.37875959130975456 
2022-03-28 07:17:58,399: ============================================================
2022-03-28 07:17:58,400: Epoch 26/26 Batch 1000/7662 eta: 0:44:20.552299	Training Loss 0.4283 (0.4366)	Training Prec@1 92.188 (91.587)	Training Prec@5 96.680 (94.741)	
2022-03-28 07:17:58,400: ============================================================
2022-03-28 07:18:39,481: time cost, forward:0.14869858808578199, backward:0.037135648336922504, data cost:0.36848663741398985 
2022-03-28 07:18:39,481: ============================================================
2022-03-28 07:18:39,481: Epoch 26/26 Batch 1100/7662 eta: 0:44:56.177863	Training Loss 0.4465 (0.4365)	Training Prec@1 90.039 (91.593)	Training Prec@5 93.164 (94.739)	
2022-03-28 07:18:39,481: ============================================================
2022-03-28 07:19:21,656: time cost, forward:0.14536731893366034, backward:0.03701617361805258, data cost:0.36087425198527157 
2022-03-28 07:19:21,656: ============================================================
2022-03-28 07:19:21,657: Epoch 26/26 Batch 1200/7662 eta: 0:45:25.802991	Training Loss 0.4199 (0.4365)	Training Prec@1 94.922 (91.596)	Training Prec@5 96.289 (94.734)	
2022-03-28 07:19:21,657: ============================================================
2022-03-28 07:20:03,917: time cost, forward:0.14251383402606357, backward:0.03696266663267211, data cost:0.35423999955968 
2022-03-28 07:20:03,918: ============================================================
2022-03-28 07:20:03,918: Epoch 26/26 Batch 1300/7662 eta: 0:44:49.074267	Training Loss 0.4436 (0.4366)	Training Prec@1 92.188 (91.584)	Training Prec@5 94.727 (94.728)	
2022-03-28 07:20:03,918: ============================================================
2022-03-28 07:20:44,704: time cost, forward:0.13980660905490355, backward:0.03704682582612546, data cost:0.34801756117154736 
2022-03-28 07:20:44,704: ============================================================
2022-03-28 07:20:44,705: Epoch 26/26 Batch 1400/7662 eta: 0:42:34.477965	Training Loss 0.4337 (0.4367)	Training Prec@1 91.797 (91.585)	Training Prec@5 95.117 (94.726)	
2022-03-28 07:20:44,705: ============================================================
2022-03-28 07:21:26,031: time cost, forward:0.13759236688849288, backward:0.03694467754503979, data cost:0.34286278768568695 
2022-03-28 07:21:26,031: ============================================================
2022-03-28 07:21:26,031: Epoch 26/26 Batch 1500/7662 eta: 0:42:26.972513	Training Loss 0.4415 (0.4367)	Training Prec@1 90.039 (91.578)	Training Prec@5 93.750 (94.724)	
2022-03-28 07:21:26,032: ============================================================
2022-03-28 07:22:08,045: time cost, forward:0.13575967928258384, backward:0.03689818444887201, data cost:0.3386148173336389 
2022-03-28 07:22:08,046: ============================================================
2022-03-28 07:22:08,046: Epoch 26/26 Batch 1600/7662 eta: 0:42:27.334807	Training Loss 0.4323 (0.4366)	Training Prec@1 91.797 (91.582)	Training Prec@5 94.336 (94.730)	
2022-03-28 07:22:08,046: ============================================================
2022-03-28 07:22:49,625: time cost, forward:0.1342083265530214, backward:0.036814037107453054, data cost:0.33461736748680215 
2022-03-28 07:22:49,625: ============================================================
2022-03-28 07:22:49,626: Epoch 26/26 Batch 1700/7662 eta: 0:41:19.407334	Training Loss 0.4342 (0.4366)	Training Prec@1 92.773 (91.582)	Training Prec@5 95.117 (94.726)	
2022-03-28 07:22:49,626: ============================================================
2022-03-28 07:23:29,634: time cost, forward:0.13258532897308842, backward:0.03669692079778378, data cost:0.33047799443854037 
2022-03-28 07:23:29,634: ============================================================
2022-03-28 07:23:29,634: Epoch 26/26 Batch 1800/7662 eta: 0:39:05.710690	Training Loss 0.4333 (0.4367)	Training Prec@1 91.602 (91.581)	Training Prec@5 96.484 (94.733)	
2022-03-28 07:23:29,635: ============================================================
2022-03-28 07:24:10,745: time cost, forward:0.13099051463472147, backward:0.03655130540527376, data cost:0.32752025234128 
2022-03-28 07:24:10,745: ============================================================
2022-03-28 07:24:10,745: Epoch 26/26 Batch 1900/7662 eta: 0:39:29.220256	Training Loss 0.4331 (0.4367)	Training Prec@1 91.602 (91.582)	Training Prec@5 94.141 (94.730)	
2022-03-28 07:24:10,746: ============================================================
2022-03-28 07:24:51,699: time cost, forward:0.12954529539950793, backward:0.03651073993951932, data cost:0.3247202407604101 
2022-03-28 07:24:51,699: ============================================================
2022-03-28 07:24:51,700: Epoch 26/26 Batch 2000/7662 eta: 0:38:39.234376	Training Loss 0.4385 (0.4368)	Training Prec@1 92.773 (91.574)	Training Prec@5 94.727 (94.727)	
2022-03-28 07:24:51,700: ============================================================
2022-03-28 07:25:31,321: time cost, forward:0.12824099344432552, backward:0.036323521465503245, data cost:0.3217167944042611 
2022-03-28 07:25:31,321: ============================================================
2022-03-28 07:25:31,321: Epoch 26/26 Batch 2100/7662 eta: 0:36:44.151778	Training Loss 0.4412 (0.4368)	Training Prec@1 91.797 (91.572)	Training Prec@5 95.117 (94.724)	
2022-03-28 07:25:31,321: ============================================================
2022-03-28 07:26:11,554: time cost, forward:0.12704997444326308, backward:0.03637739613469268, data cost:0.3189893423724901 
2022-03-28 07:26:11,554: ============================================================
2022-03-28 07:26:11,554: Epoch 26/26 Batch 2200/7662 eta: 0:36:37.934705	Training Loss 0.4270 (0.4368)	Training Prec@1 93.359 (91.575)	Training Prec@5 95.898 (94.730)	
2022-03-28 07:26:11,554: ============================================================
2022-03-28 07:26:51,572: time cost, forward:0.12598009211128305, backward:0.03627981056903642, data cost:0.31658013689357234 
2022-03-28 07:26:51,573: ============================================================
2022-03-28 07:26:51,573: Epoch 26/26 Batch 2300/7662 eta: 0:35:46.216965	Training Loss 0.4366 (0.4368)	Training Prec@1 91.797 (91.579)	Training Prec@5 94.531 (94.734)	
2022-03-28 07:26:51,573: ============================================================
2022-03-28 07:27:31,696: time cost, forward:0.12496982380070752, backward:0.036301456028444166, data cost:0.3143227817913849 
2022-03-28 07:27:31,696: ============================================================
2022-03-28 07:27:31,696: Epoch 26/26 Batch 2400/7662 eta: 0:35:11.662543	Training Loss 0.4387 (0.4368)	Training Prec@1 92.773 (91.576)	Training Prec@5 95.312 (94.732)	
2022-03-28 07:27:31,696: ============================================================
2022-03-28 07:28:12,323: time cost, forward:0.12405018636635562, backward:0.03630273596865504, data cost:0.31243856347241655 
2022-03-28 07:28:12,323: ============================================================
2022-03-28 07:28:12,324: Epoch 26/26 Batch 2500/7662 eta: 0:34:57.603503	Training Loss 0.4588 (0.4368)	Training Prec@1 89.258 (91.578)	Training Prec@5 92.188 (94.729)	
2022-03-28 07:28:12,324: ============================================================
2022-03-28 07:28:53,827: time cost, forward:0.1232054265658183, backward:0.036300709542057615, data cost:0.3109162852781559 
2022-03-28 07:28:53,828: ============================================================
2022-03-28 07:28:53,828: Epoch 26/26 Batch 2600/7662 eta: 0:35:01.359082	Training Loss 0.4319 (0.4368)	Training Prec@1 91.211 (91.584)	Training Prec@5 93.750 (94.732)	
2022-03-28 07:28:53,828: ============================================================
2022-03-28 07:29:32,001: time cost, forward:0.12239116648913932, backward:0.03630474197639276, data cost:0.30856307306392144 
2022-03-28 07:29:32,001: ============================================================
2022-03-28 07:29:32,002: Epoch 26/26 Batch 2700/7662 eta: 0:31:34.561540	Training Loss 0.4249 (0.4368)	Training Prec@1 91.211 (91.581)	Training Prec@5 94.336 (94.733)	
2022-03-28 07:29:32,002: ============================================================
2022-03-28 07:30:13,103: time cost, forward:0.12166140334186233, backward:0.0363199568595491, data cost:0.3072486065165747 
2022-03-28 07:30:13,104: ============================================================
2022-03-28 07:30:13,104: Epoch 26/26 Batch 2800/7662 eta: 0:33:18.801379	Training Loss 0.4451 (0.4368)	Training Prec@1 86.523 (91.571)	Training Prec@5 91.602 (94.724)	
2022-03-28 07:30:13,104: ============================================================
2022-03-28 07:30:52,297: time cost, forward:0.12096458157410742, backward:0.036213550455778294, data cost:0.3055299331747939 
2022-03-28 07:30:52,297: ============================================================
2022-03-28 07:30:52,298: Epoch 26/26 Batch 2900/7662 eta: 0:31:06.797956	Training Loss 0.4356 (0.4368)	Training Prec@1 92.773 (91.566)	Training Prec@5 95.898 (94.720)	
2022-03-28 07:30:52,298: ============================================================
2022-03-28 07:31:31,360: time cost, forward:0.12030756779613794, backward:0.03613668380080958, data cost:0.30384043488116136 
2022-03-28 07:31:31,360: ============================================================
2022-03-28 07:31:31,361: Epoch 26/26 Batch 3000/7662 eta: 0:30:21.515115	Training Loss 0.4425 (0.4368)	Training Prec@1 93.555 (91.570)	Training Prec@5 96.094 (94.721)	
2022-03-28 07:31:31,361: ============================================================
2022-03-28 07:32:11,435: time cost, forward:0.11970770624461732, backward:0.03610499299853492, data cost:0.3025312723748797 
2022-03-28 07:32:11,435: ============================================================
2022-03-28 07:32:11,436: Epoch 26/26 Batch 3100/7662 eta: 0:30:28.611406	Training Loss 0.4420 (0.4368)	Training Prec@1 90.820 (91.570)	Training Prec@5 95.117 (94.723)	
2022-03-28 07:32:11,436: ============================================================
2022-03-28 07:32:52,271: time cost, forward:0.11913719300964394, backward:0.036057665781067026, data cost:0.3015925118833007 
2022-03-28 07:32:52,272: ============================================================
2022-03-28 07:32:52,272: Epoch 26/26 Batch 3200/7662 eta: 0:30:22.526182	Training Loss 0.4341 (0.4368)	Training Prec@1 89.648 (91.568)	Training Prec@5 93.750 (94.724)	
2022-03-28 07:32:52,272: ============================================================
2022-03-28 07:33:32,920: time cost, forward:0.11860557417683111, backward:0.036032226527232265, data cost:0.3005963777476782 
2022-03-28 07:33:32,920: ============================================================
2022-03-28 07:33:32,921: Epoch 26/26 Batch 3300/7662 eta: 0:29:33.509355	Training Loss 0.4264 (0.4368)	Training Prec@1 92.383 (91.563)	Training Prec@5 95.898 (94.721)	
2022-03-28 07:33:32,921: ============================================================
2022-03-28 07:34:14,884: time cost, forward:0.11812398461041362, backward:0.03598244655269074, data cost:0.30007651862974694 
2022-03-28 07:34:14,884: ============================================================
2022-03-28 07:34:14,884: Epoch 26/26 Batch 3400/7662 eta: 0:29:48.906994	Training Loss 0.4342 (0.4369)	Training Prec@1 91.992 (91.560)	Training Prec@5 93.555 (94.714)	
2022-03-28 07:34:14,885: ============================================================
2022-03-28 07:34:55,593: time cost, forward:0.1177731373201748, backward:0.035945515184274364, data cost:0.29912330253221675 
2022-03-28 07:34:55,593: ============================================================
2022-03-28 07:34:55,594: Epoch 26/26 Batch 3500/7662 eta: 0:28:14.727833	Training Loss 0.4346 (0.4369)	Training Prec@1 92.969 (91.564)	Training Prec@5 96.680 (94.716)	
2022-03-28 07:34:55,594: ============================================================
2022-03-28 07:35:35,627: time cost, forward:0.11748833343630931, backward:0.035926012503964995, data cost:0.29796554910437734 
2022-03-28 07:35:35,627: ============================================================
2022-03-28 07:35:35,628: Epoch 26/26 Batch 3600/7662 eta: 0:27:06.582560	Training Loss 0.4300 (0.4369)	Training Prec@1 92.578 (91.563)	Training Prec@5 95.508 (94.715)	
2022-03-28 07:35:35,628: ============================================================
2022-03-28 07:36:15,662: time cost, forward:0.1171543384184867, backward:0.03589772295068811, data cost:0.2969274598219872 
2022-03-28 07:36:15,681: ============================================================
2022-03-28 07:36:15,681: Epoch 26/26 Batch 3700/7662 eta: 0:26:27.311774	Training Loss 0.4351 (0.4369)	Training Prec@1 91.992 (91.560)	Training Prec@5 95.312 (94.712)	
2022-03-28 07:36:15,681: ============================================================
2022-03-28 07:36:54,957: time cost, forward:0.11679636644482393, backward:0.03582331788448887, data cost:0.29584144956031955 
2022-03-28 07:36:54,957: ============================================================
2022-03-28 07:36:54,957: Epoch 26/26 Batch 3800/7662 eta: 0:25:17.244582	Training Loss 0.4344 (0.4369)	Training Prec@1 90.820 (91.562)	Training Prec@5 94.531 (94.713)	
2022-03-28 07:36:54,957: ============================================================
2022-03-28 07:37:34,582: time cost, forward:0.11641157697671253, backward:0.03580369616692174, data cost:0.29488501850841414 
2022-03-28 07:37:34,582: ============================================================
2022-03-28 07:37:34,583: Epoch 26/26 Batch 3900/7662 eta: 0:24:51.099193	Training Loss 0.4568 (0.4370)	Training Prec@1 86.523 (91.561)	Training Prec@5 91.211 (94.713)	
2022-03-28 07:37:34,583: ============================================================
2022-03-28 07:38:14,818: time cost, forward:0.1160633784587695, backward:0.035695361804890614, data cost:0.2942263778372686 
2022-03-28 07:38:14,819: ============================================================
2022-03-28 07:38:14,819: Epoch 26/26 Batch 4000/7662 eta: 0:24:33.861372	Training Loss 0.4341 (0.4370)	Training Prec@1 93.555 (91.562)	Training Prec@5 95.508 (94.714)	
2022-03-28 07:38:14,819: ============================================================
2022-03-28 07:38:54,838: time cost, forward:0.1157300094768285, backward:0.03564364911870684, data cost:0.29349389923116176 
2022-03-28 07:38:54,839: ============================================================
2022-03-28 07:38:54,839: Epoch 26/26 Batch 4100/7662 eta: 0:23:45.909635	Training Loss 0.4270 (0.4370)	Training Prec@1 92.383 (91.564)	Training Prec@5 96.094 (94.716)	
2022-03-28 07:38:54,839: ============================================================
2022-03-28 07:39:35,441: time cost, forward:0.11541271919464889, backward:0.03561476651587126, data cost:0.2928977789382589 
2022-03-28 07:39:35,441: ============================================================
2022-03-28 07:39:35,441: Epoch 26/26 Batch 4200/7662 eta: 0:23:26.062402	Training Loss 0.4358 (0.4370)	Training Prec@1 92.969 (91.568)	Training Prec@5 95.117 (94.720)	
2022-03-28 07:39:35,442: ============================================================
2022-03-28 07:40:16,529: time cost, forward:0.11511015281978944, backward:0.03561359612047187, data cost:0.29242804766422265 
2022-03-28 07:40:16,530: ============================================================
2022-03-28 07:40:16,530: Epoch 26/26 Batch 4300/7662 eta: 0:23:01.808052	Training Loss 0.4365 (0.4370)	Training Prec@1 91.992 (91.568)	Training Prec@5 94.531 (94.719)	
2022-03-28 07:40:16,530: ============================================================
2022-03-28 07:40:56,927: time cost, forward:0.11482555098250714, backward:0.03561144277273891, data cost:0.29180614095732527 
2022-03-28 07:40:56,927: ============================================================
2022-03-28 07:40:56,927: Epoch 26/26 Batch 4400/7662 eta: 0:21:58.163705	Training Loss 0.4229 (0.4370)	Training Prec@1 93.359 (91.572)	Training Prec@5 94.922 (94.723)	
2022-03-28 07:40:56,927: ============================================================
2022-03-28 07:41:37,180: time cost, forward:0.11455737370654036, backward:0.035597829984065875, data cost:0.29120717729083906 
2022-03-28 07:41:37,181: ============================================================
2022-03-28 07:41:37,181: Epoch 26/26 Batch 4500/7662 eta: 0:21:13.220588	Training Loss 0.4424 (0.4370)	Training Prec@1 91.797 (91.571)	Training Prec@5 95.508 (94.724)	
2022-03-28 07:41:37,181: ============================================================
2022-03-28 07:42:19,743: time cost, forward:0.11430330094007544, backward:0.03557409419005631, data cost:0.2911328349742819 
2022-03-28 07:42:19,743: ============================================================
2022-03-28 07:42:19,744: Epoch 26/26 Batch 4600/7662 eta: 0:21:43.701585	Training Loss 0.4341 (0.4370)	Training Prec@1 90.820 (91.573)	Training Prec@5 94.922 (94.723)	
2022-03-28 07:42:19,744: ============================================================
2022-03-28 07:42:59,787: time cost, forward:0.11410048109948774, backward:0.03550991669034014, data cost:0.29052623156969487 
2022-03-28 07:42:59,787: ============================================================
2022-03-28 07:42:59,787: Epoch 26/26 Batch 4700/7662 eta: 0:19:46.489772	Training Loss 0.4258 (0.4370)	Training Prec@1 92.188 (91.570)	Training Prec@5 95.508 (94.721)	
2022-03-28 07:42:59,787: ============================================================
2022-03-28 07:43:40,048: time cost, forward:0.11388298943033316, backward:0.03550342570545525, data cost:0.289967814493388 
2022-03-28 07:43:40,048: ============================================================
2022-03-28 07:43:40,049: Epoch 26/26 Batch 4800/7662 eta: 0:19:12.682728	Training Loss 0.4384 (0.4370)	Training Prec@1 90.625 (91.568)	Training Prec@5 93.750 (94.719)	
2022-03-28 07:43:40,049: ============================================================
2022-03-28 07:44:19,752: time cost, forward:0.11365732374812272, backward:0.03549615147892955, data cost:0.2893251150718731 
2022-03-28 07:44:19,752: ============================================================
2022-03-28 07:44:19,752: Epoch 26/26 Batch 4900/7662 eta: 0:18:17.018714	Training Loss 0.4411 (0.4370)	Training Prec@1 92.188 (91.569)	Training Prec@5 93.359 (94.719)	
2022-03-28 07:44:19,753: ============================================================
2022-03-28 07:44:59,934: time cost, forward:0.11345117906256422, backward:0.035490726513680425, data cost:0.28879756554528985 
2022-03-28 07:44:59,935: ============================================================
2022-03-28 07:44:59,935: Epoch 26/26 Batch 5000/7662 eta: 0:17:50.060181	Training Loss 0.4386 (0.4370)	Training Prec@1 91.211 (91.568)	Training Prec@5 94.727 (94.720)	
2022-03-28 07:44:59,935: ============================================================
2022-03-28 07:45:40,739: time cost, forward:0.11323758849304642, backward:0.03546916318655154, data cost:0.2884472923013224 
2022-03-28 07:45:40,739: ============================================================
2022-03-28 07:45:40,739: Epoch 26/26 Batch 5100/7662 eta: 0:17:25.815152	Training Loss 0.4315 (0.4370)	Training Prec@1 93.164 (91.564)	Training Prec@5 95.312 (94.718)	
2022-03-28 07:45:40,740: ============================================================
2022-03-28 07:46:22,062: time cost, forward:0.11309201851742248, backward:0.035464750663388986, data cost:0.28812872356899794 
2022-03-28 07:46:22,063: ============================================================
2022-03-28 07:46:22,063: Epoch 26/26 Batch 5200/7662 eta: 0:16:57.802871	Training Loss 0.4399 (0.4370)	Training Prec@1 92.773 (91.565)	Training Prec@5 95.117 (94.718)	
2022-03-28 07:46:22,063: ============================================================
2022-03-28 07:47:03,711: time cost, forward:0.11292957881640255, backward:0.03543249511070849, data cost:0.28792702677025395 
2022-03-28 07:47:03,711: ============================================================
2022-03-28 07:47:03,712: Epoch 26/26 Batch 5300/7662 eta: 0:16:24.158927	Training Loss 0.4558 (0.4370)	Training Prec@1 90.625 (91.564)	Training Prec@5 93.945 (94.716)	
2022-03-28 07:47:03,712: ============================================================
2022-03-28 07:47:44,095: time cost, forward:0.11276520047061508, backward:0.03543143692800879, data cost:0.28749332813934875 
2022-03-28 07:47:44,096: ============================================================
2022-03-28 07:47:44,096: Epoch 26/26 Batch 5400/7662 eta: 0:15:13.889916	Training Loss 0.4397 (0.4371)	Training Prec@1 89.062 (91.563)	Training Prec@5 93.359 (94.716)	
2022-03-28 07:47:44,096: ============================================================
2022-03-28 07:48:25,694: time cost, forward:0.11262294512962207, backward:0.03539041675942923, data cost:0.28731189413186875 
2022-03-28 07:48:25,694: ============================================================
2022-03-28 07:48:25,695: Epoch 26/26 Batch 5500/7662 eta: 0:14:59.784951	Training Loss 0.4319 (0.4371)	Training Prec@1 92.578 (91.562)	Training Prec@5 95.508 (94.716)	
2022-03-28 07:48:25,695: ============================================================
2022-03-28 07:49:05,280: time cost, forward:0.1124757703531425, backward:0.03535414057174822, data cost:0.2867970679099697 
2022-03-28 07:49:05,281: ============================================================
2022-03-28 07:49:05,281: Epoch 26/26 Batch 5600/7662 eta: 0:13:36.663173	Training Loss 0.4453 (0.4371)	Training Prec@1 90.625 (91.559)	Training Prec@5 94.336 (94.715)	
2022-03-28 07:49:05,281: ============================================================
2022-03-28 07:49:45,621: time cost, forward:0.11229609020719782, backward:0.03533967462918867, data cost:0.28643712513822067 
2022-03-28 07:49:45,621: ============================================================
2022-03-28 07:49:45,621: Epoch 26/26 Batch 5700/7662 eta: 0:13:11.880540	Training Loss 0.4418 (0.4371)	Training Prec@1 91.016 (91.559)	Training Prec@5 94.531 (94.713)	
2022-03-28 07:49:45,621: ============================================================
2022-03-28 07:50:26,168: time cost, forward:0.11211625788412868, backward:0.03533070583675705, data cost:0.28612750294825645 
2022-03-28 07:50:26,168: ============================================================
2022-03-28 07:50:26,169: Epoch 26/26 Batch 5800/7662 eta: 0:12:35.398364	Training Loss 0.4439 (0.4371)	Training Prec@1 92.383 (91.558)	Training Prec@5 95.117 (94.712)	
2022-03-28 07:50:26,169: ============================================================
2022-03-28 07:51:06,581: time cost, forward:0.11198678629380966, backward:0.03529762271946417, data cost:0.28578000534265846 
2022-03-28 07:51:06,582: ============================================================
2022-03-28 07:51:06,582: Epoch 26/26 Batch 5900/7662 eta: 0:11:52.488863	Training Loss 0.4427 (0.4371)	Training Prec@1 93.555 (91.556)	Training Prec@5 96.094 (94.713)	
2022-03-28 07:51:06,582: ============================================================
2022-03-28 07:51:48,740: time cost, forward:0.11182529228014595, backward:0.03525600136866429, data cost:0.2857837786295351 
2022-03-28 07:51:48,740: ============================================================
2022-03-28 07:51:48,740: Epoch 26/26 Batch 6000/7662 eta: 0:11:41.091422	Training Loss 0.4435 (0.4371)	Training Prec@1 92.188 (91.553)	Training Prec@5 95.508 (94.712)	
2022-03-28 07:51:48,740: ============================================================
2022-03-28 07:52:29,200: time cost, forward:0.1117291075613757, backward:0.035215230042044306, data cost:0.28545223636536504 
2022-03-28 07:52:29,200: ============================================================
2022-03-28 07:52:29,200: Epoch 26/26 Batch 6100/7662 eta: 0:10:32.387132	Training Loss 0.4264 (0.4371)	Training Prec@1 91.211 (91.552)	Training Prec@5 95.312 (94.711)	
2022-03-28 07:52:29,200: ============================================================
2022-03-28 07:53:09,046: time cost, forward:0.11175305094521244, backward:0.035178205970410936, data cost:0.28491651171502574 
2022-03-28 07:53:09,047: ============================================================
2022-03-28 07:53:09,047: Epoch 26/26 Batch 6200/7662 eta: 0:09:42.956188	Training Loss 0.4433 (0.4371)	Training Prec@1 93.359 (91.553)	Training Prec@5 95.117 (94.713)	
2022-03-28 07:53:09,047: ============================================================
2022-03-28 07:53:50,770: time cost, forward:0.11177688221038949, backward:0.03514489258522267, data cost:0.28468489537145963 
2022-03-28 07:53:50,770: ============================================================
2022-03-28 07:53:50,770: Epoch 26/26 Batch 6300/7662 eta: 0:09:28.694256	Training Loss 0.4387 (0.4371)	Training Prec@1 91.211 (91.551)	Training Prec@5 94.531 (94.712)	
2022-03-28 07:53:50,771: ============================================================
2022-03-28 07:54:31,352: time cost, forward:0.11177114107251485, backward:0.035154359343275834, data cost:0.2842707788223288 
2022-03-28 07:54:31,352: ============================================================
2022-03-28 07:54:31,353: Epoch 26/26 Batch 6400/7662 eta: 0:08:32.550630	Training Loss 0.4459 (0.4371)	Training Prec@1 92.188 (91.553)	Training Prec@5 95.508 (94.716)	
2022-03-28 07:54:31,353: ============================================================
2022-03-28 07:55:11,929: time cost, forward:0.11175931430006049, backward:0.0351277677292713, data cost:0.28391575879327224 
2022-03-28 07:55:11,930: ============================================================
2022-03-28 07:55:11,930: Epoch 26/26 Batch 6500/7662 eta: 0:07:51.914687	Training Loss 0.4332 (0.4371)	Training Prec@1 90.820 (91.555)	Training Prec@5 94.141 (94.717)	
2022-03-28 07:55:11,930: ============================================================
2022-03-28 07:55:53,013: time cost, forward:0.11175813048441205, backward:0.03509631939486385, data cost:0.2836505742411954 
2022-03-28 07:55:53,014: ============================================================
2022-03-28 07:55:53,014: Epoch 26/26 Batch 6600/7662 eta: 0:07:16.722911	Training Loss 0.4409 (0.4372)	Training Prec@1 90.820 (91.555)	Training Prec@5 94.336 (94.715)	
2022-03-28 07:55:53,014: ============================================================
2022-03-28 07:56:35,050: time cost, forward:0.11179106810997272, backward:0.03506251694035363, data cost:0.28348185568002465 
2022-03-28 07:56:35,051: ============================================================
2022-03-28 07:56:35,051: Epoch 26/26 Batch 6700/7662 eta: 0:06:44.816789	Training Loss 0.4358 (0.4372)	Training Prec@1 91.406 (91.554)	Training Prec@5 95.508 (94.713)	
2022-03-28 07:56:35,051: ============================================================
2022-03-28 07:57:15,039: time cost, forward:0.11178309673034964, backward:0.03505526063792547, data cost:0.28305227420911805 
2022-03-28 07:57:15,039: ============================================================
2022-03-28 07:57:15,039: Epoch 26/26 Batch 6800/7662 eta: 0:05:45.098556	Training Loss 0.4295 (0.4372)	Training Prec@1 93.164 (91.553)	Training Prec@5 95.898 (94.713)	
2022-03-28 07:57:15,039: ============================================================
2022-03-28 07:57:57,422: time cost, forward:0.1117685901062923, backward:0.03504605396258034, data cost:0.2829794724759269 
2022-03-28 07:57:57,422: ============================================================
2022-03-28 07:57:57,422: Epoch 26/26 Batch 6900/7662 eta: 0:05:23.384627	Training Loss 0.4480 (0.4372)	Training Prec@1 91.602 (91.553)	Training Prec@5 95.117 (94.712)	
2022-03-28 07:57:57,423: ============================================================
2022-03-28 07:58:38,463: time cost, forward:0.11179171018659055, backward:0.035029686115557575, data cost:0.28269164772404315 
2022-03-28 07:58:38,463: ============================================================
2022-03-28 07:58:38,463: Epoch 26/26 Batch 7000/7662 eta: 0:04:32.099928	Training Loss 0.4460 (0.4372)	Training Prec@1 91.211 (91.551)	Training Prec@5 95.117 (94.711)	
2022-03-28 07:58:38,463: ============================================================
2022-03-28 07:59:18,762: time cost, forward:0.11183834556190543, backward:0.035003443069232316, data cost:0.2823005507136419 
2022-03-28 07:59:18,762: ============================================================
2022-03-28 07:59:18,763: Epoch 26/26 Batch 7100/7662 eta: 0:03:46.885157	Training Loss 0.4570 (0.4372)	Training Prec@1 90.234 (91.550)	Training Prec@5 94.531 (94.709)	
2022-03-28 07:59:18,763: ============================================================
2022-03-28 08:00:00,636: time cost, forward:0.11188116092154642, backward:0.03497344524533504, data cost:0.28212610925795517 
2022-03-28 08:00:00,636: ============================================================
2022-03-28 08:00:00,636: Epoch 26/26 Batch 7200/7662 eta: 0:03:13.875481	Training Loss 0.4360 (0.4373)	Training Prec@1 90.039 (91.547)	Training Prec@5 93.945 (94.707)	
2022-03-28 08:00:00,636: ============================================================
2022-03-28 08:00:41,758: time cost, forward:0.11190817192460203, backward:0.03496133541306301, data cost:0.28187560911030946 
2022-03-28 08:00:41,759: ============================================================
2022-03-28 08:00:41,759: Epoch 26/26 Batch 7300/7662 eta: 0:02:29.275513	Training Loss 0.4441 (0.4373)	Training Prec@1 88.672 (91.544)	Training Prec@5 93.555 (94.706)	
2022-03-28 08:00:41,759: ============================================================
2022-03-28 08:01:22,165: time cost, forward:0.11192370488975867, backward:0.034959342579919596, data cost:0.28151149752333704 
2022-03-28 08:01:22,166: ============================================================
2022-03-28 08:01:22,166: Epoch 26/26 Batch 7400/7662 eta: 0:01:46.269729	Training Loss 0.4339 (0.4373)	Training Prec@1 92.578 (91.545)	Training Prec@5 95.117 (94.706)	
2022-03-28 08:01:22,166: ============================================================
2022-03-28 08:02:03,052: time cost, forward:0.11192922621412998, backward:0.03495268052952308, data cost:0.2812506066813344 
2022-03-28 08:02:03,052: ============================================================
2022-03-28 08:02:03,052: Epoch 26/26 Batch 7500/7662 eta: 0:01:06.644875	Training Loss 0.4445 (0.4373)	Training Prec@1 91.602 (91.541)	Training Prec@5 94.727 (94.703)	
2022-03-28 08:02:03,052: ============================================================
2022-03-28 08:02:45,651: time cost, forward:0.11193357732581816, backward:0.03494126192126278, data cost:0.2812265043651482 
2022-03-28 08:02:45,651: ============================================================
2022-03-28 08:02:45,652: Epoch 26/26 Batch 7600/7662 eta: 0:00:26.837618	Training Loss 0.4387 (0.4373)	Training Prec@1 92.188 (91.537)	Training Prec@5 95.117 (94.702)	
2022-03-28 08:02:45,652: ============================================================
2022-03-28 08:03:12,719: Epoch: 26/26 eta: 0:00:00	Training Loss 0.4497 (0.4373)	Training Prec@1 92.188 (91.535)	Training Prec@5 95.898 (94.701)
2022-03-28 08:03:12,719: ============================================================
