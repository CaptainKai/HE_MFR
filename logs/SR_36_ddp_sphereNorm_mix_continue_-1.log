2022-06-28 16:07:13,447: [('name', 'amsoft-36'), ('backbone_model_name', 'SimpleResnet_36'), ('classify_model_name', 'MarginCosineProduct'), ('resume_net_model', '/home/ubuntu/data2/lk/recognition/pytorch_new/snapshot/SR_36_ddp_sphereNorm_mix/backbone_10_checkpoint.pth'), ('resume_net_classifier', '/home/ubuntu/data2/lk/recognition/pytorch_new/snapshot/SR_36_ddp_sphereNorm_mix/classifier_status_10_checkpoint.pth'), ('no_cuda', False), ('gpu_num', 1), ('log_interval', 100), ('log_path', './logs/SR_36_ddp_sphereNorm_mix_continue.log'), ('log_pic_path', './logs/pic/SR_36_ddp_sphereNorm_mix_continue/'), ('save_path', 'snapshot/SR_36_ddp_sphereNorm_mix_continue/'), ('lmdb_path', '/home/ubuntu/data4/lk/data/lmdb_mask_augu_full'), ('batch_size', 512), ('datanum', 3923399), ('num_class', 86876), ('lmdb_workers', 4), ('num_workers', 4), ('start_epoch', 1), ('max_epoch', 26), ('lr', 0.1), ('base', 'epoch'), ('step_size', [10, 20, 30]), ('momentum', 0.9), ('gama', 0.1), ('weight_decay', 0.0005), ('rank', -1), ('dist_url', 'env://'), ('world_size', -1), ('gpu', None), ('dist_backend', 'nccl'), ('distributed', False), ('master_port', 22345), ('multiprocessing_distributed', False), ('SEED', 1337), ('local_rank', -1)]
2022-06-28 16:07:13,447: SimpleResidualBackbone(
  (conv1): ConvPrelu(
    (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (prelu): PReLU(num_parameters=64)
  )
  (layer1): Sequential(
    (0): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=64)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=64)
      )
    )
    (1): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=64)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=64)
      )
    )
  )
  (conv2): ConvPrelu(
    (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (prelu): PReLU(num_parameters=128)
  )
  (layer2): Sequential(
    (0): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
    )
    (1): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
    )
    (2): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
    )
    (3): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
    )
  )
  (conv3): ConvPrelu(
    (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (prelu): PReLU(num_parameters=256)
  )
  (layer3): Sequential(
    (0): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
    (1): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
    (2): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
    (3): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
    (4): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
    (5): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
    (6): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
    (7): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
  )
  (conv4): ConvPrelu(
    (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (prelu): PReLU(num_parameters=512)
  )
  (layer4): Sequential(
    (0): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=512)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=512)
      )
    )
    (1): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=512)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=512)
      )
    )
  )
  (fc5): Linear(in_features=25088, out_features=512, bias=True)
)
2022-06-28 16:07:14,119: Loading resume (model) network...
2022-06-28 16:07:19,031: resume net (model) loaded
2022-06-28 16:07:19,031: Loading resume (classifier) network...
2022-06-28 16:07:22,551: start epoch: 10
2022-06-28 16:07:22,845: resume net (classifier) loaded
2022-06-28 16:07:22,936: Use DP
2022-06-28 16:08:39,280: time cost, forward:0.017027394940154723, backward:0.0398420998544404, data cost:0.7076386706997649 
2022-06-28 16:08:39,280: ============================================================
2022-06-28 16:08:39,280: Epoch 10/26 Batch 100/7662 eta: 1 day, 3:32:27.349285	Training Loss 3.4066 (3.4827)	Training Prec@1 98.438 (98.670)	Training Prec@5 99.219 (99.444)	
2022-06-28 16:08:39,280: ============================================================
2022-06-28 16:09:54,982: time cost, forward:0.013677730033146077, backward:0.03452351943931388, data cost:0.7122791244756037 
2022-06-28 16:09:54,982: ============================================================
2022-06-28 16:09:54,983: Epoch 10/26 Batch 200/7662 eta: 1 day, 3:20:54.742947	Training Loss 3.4861 (3.5017)	Training Prec@1 99.023 (98.684)	Training Prec@5 99.805 (99.455)	
2022-06-28 16:09:54,983: ============================================================
2022-06-28 16:11:15,657: time cost, forward:0.012502165542398408, backward:0.03291641828607157, data cost:0.7303989069118946 
2022-06-28 16:11:15,657: ============================================================
2022-06-28 16:11:15,658: Epoch 10/26 Batch 300/7662 eta: 1 day, 5:07:21.119968	Training Loss 3.5274 (3.5170)	Training Prec@1 98.242 (98.618)	Training Prec@5 99.414 (99.431)	
2022-06-28 16:11:15,658: ============================================================
2022-06-28 16:12:33,194: time cost, forward:0.01193601864023615, backward:0.032321821776846595, data cost:0.7313272469025806 
2022-06-28 16:12:33,194: ============================================================
2022-06-28 16:12:33,194: Epoch 10/26 Batch 400/7662 eta: 1 day, 3:58:05.153625	Training Loss 3.4020 (3.5279)	Training Prec@1 98.047 (98.583)	Training Prec@5 99.219 (99.428)	
2022-06-28 16:12:33,194: ============================================================
2022-06-28 16:13:51,557: time cost, forward:0.011562678044688008, backward:0.031556203513441676, data cost:0.733987224842599 
2022-06-28 16:13:51,557: ============================================================
2022-06-28 16:13:51,558: Epoch 10/26 Batch 500/7662 eta: 1 day, 4:14:40.234750	Training Loss 3.4023 (3.5361)	Training Prec@1 99.219 (98.576)	Training Prec@5 99.805 (99.418)	
2022-06-28 16:13:51,558: ============================================================
2022-06-28 16:15:11,158: time cost, forward:0.01134052061676382, backward:0.031088981485128005, data cost:0.7377731179156168 
2022-06-28 16:15:11,158: ============================================================
2022-06-28 16:15:11,158: Epoch 10/26 Batch 600/7662 eta: 1 day, 4:40:06.580505	Training Loss 3.7222 (3.5423)	Training Prec@1 97.461 (98.569)	Training Prec@5 98.633 (99.415)	
2022-06-28 16:15:11,158: ============================================================
2022-06-28 16:16:30,278: time cost, forward:0.011177123360367804, backward:0.03083928289672677, data cost:0.73968553815959 
2022-06-28 16:16:30,279: ============================================================
2022-06-28 16:16:30,279: Epoch 10/26 Batch 700/7662 eta: 1 day, 4:28:24.605588	Training Loss 3.6790 (3.5489)	Training Prec@1 98.242 (98.556)	Training Prec@5 99.023 (99.409)	
2022-06-28 16:16:30,279: ============================================================
2022-06-28 16:17:48,061: time cost, forward:0.011080251020543715, backward:0.030583165912365585, data cost:0.7394878249592118 
2022-06-28 16:17:48,061: ============================================================
2022-06-28 16:17:48,061: Epoch 10/26 Batch 800/7662 eta: 1 day, 3:58:13.119669	Training Loss 3.5405 (3.5573)	Training Prec@1 98.828 (98.552)	Training Prec@5 99.805 (99.403)	
2022-06-28 16:17:48,061: ============================================================
2022-06-28 16:19:05,651: time cost, forward:0.010992748188362503, backward:0.030367186655589816, data cost:0.7391580262359178 
2022-06-28 16:19:05,651: ============================================================
2022-06-28 16:19:05,651: Epoch 10/26 Batch 900/7662 eta: 1 day, 3:52:46.548398	Training Loss 3.7813 (3.5639)	Training Prec@1 97.852 (98.536)	Training Prec@5 99.219 (99.393)	
2022-06-28 16:19:05,651: ============================================================
2022-06-28 16:20:24,562: time cost, forward:0.010883967559020201, backward:0.030106850214548654, data cost:0.7403426578452995 
2022-06-28 16:20:24,562: ============================================================
2022-06-28 16:20:24,562: Epoch 10/26 Batch 1000/7662 eta: 1 day, 4:19:56.531712	Training Loss 3.6857 (3.5702)	Training Prec@1 98.828 (98.526)	Training Prec@5 99.609 (99.386)	
2022-06-28 16:20:24,562: ============================================================
2022-06-28 16:21:42,252: time cost, forward:0.010799806697244965, backward:0.030018596675202888, data cost:0.7400737498650451 
2022-06-28 16:21:42,253: ============================================================
2022-06-28 16:21:42,253: Epoch 10/26 Batch 1100/7662 eta: 1 day, 3:52:21.131738	Training Loss 3.5420 (3.5775)	Training Prec@1 99.414 (98.517)	Training Prec@5 99.414 (99.379)	
2022-06-28 16:21:42,253: ============================================================
2022-06-28 16:23:00,188: time cost, forward:0.010748561369169742, backward:0.029978066707671534, data cost:0.7400008940120057 
2022-06-28 16:23:00,188: ============================================================
2022-06-28 16:23:00,189: Epoch 10/26 Batch 1200/7662 eta: 1 day, 3:56:19.991403	Training Loss 3.6090 (3.5847)	Training Prec@1 98.633 (98.513)	Training Prec@5 99.414 (99.377)	
2022-06-28 16:23:00,189: ============================================================
2022-06-28 16:24:17,755: time cost, forward:0.010718037111195717, backward:0.029895912784168224, data cost:0.7396959050790083 
2022-06-28 16:24:17,755: ============================================================
2022-06-28 16:24:17,756: Epoch 10/26 Batch 1300/7662 eta: 1 day, 3:47:06.526274	Training Loss 3.8343 (3.5932)	Training Prec@1 97.070 (98.502)	Training Prec@5 98.438 (99.372)	
2022-06-28 16:24:17,756: ============================================================
2022-06-28 16:25:35,654: time cost, forward:0.010675991322842558, backward:0.029818921706095347, data cost:0.7396849960493479 
2022-06-28 16:25:35,655: ============================================================
2022-06-28 16:25:35,655: Epoch 10/26 Batch 1400/7662 eta: 1 day, 3:52:57.169255	Training Loss 3.5512 (3.5992)	Training Prec@1 98.633 (98.496)	Training Prec@5 99.023 (99.369)	
2022-06-28 16:25:35,655: ============================================================
2022-06-28 16:26:53,247: time cost, forward:0.010684832324180068, backward:0.029707108759100712, data cost:0.7394738407274976 
2022-06-28 16:26:53,247: ============================================================
2022-06-28 16:26:53,247: Epoch 10/26 Batch 1500/7662 eta: 1 day, 3:45:04.191413	Training Loss 3.7579 (3.6058)	Training Prec@1 97.656 (98.480)	Training Prec@5 99.414 (99.363)	
2022-06-28 16:26:53,248: ============================================================
2022-06-28 16:28:11,583: time cost, forward:0.010698482496727996, backward:0.029598138867653185, data cost:0.7396681210337168 
2022-06-28 16:28:11,584: ============================================================
2022-06-28 16:28:11,584: Epoch 10/26 Batch 1600/7662 eta: 1 day, 3:59:43.577061	Training Loss 3.7613 (3.6115)	Training Prec@1 98.438 (98.469)	Training Prec@5 99.414 (99.359)	
2022-06-28 16:28:11,584: ============================================================
2022-06-28 16:29:31,783: time cost, forward:0.010730142660741598, backward:0.029616188764431815, data cost:0.7407991209754248 
2022-06-28 16:29:31,783: ============================================================
2022-06-28 16:29:31,783: Epoch 10/26 Batch 1700/7662 eta: 1 day, 4:38:20.447410	Training Loss 3.7077 (3.6161)	Training Prec@1 99.219 (98.465)	Training Prec@5 99.219 (99.356)	
2022-06-28 16:29:31,783: ============================================================
2022-06-28 16:30:54,977: time cost, forward:0.010774703871349019, backward:0.029647047881486352, data cost:0.7435357558720638 
2022-06-28 16:30:54,977: ============================================================
2022-06-28 16:30:54,978: Epoch 10/26 Batch 1800/7662 eta: 1 day, 5:41:07.285147	Training Loss 3.5592 (3.6216)	Training Prec@1 98.047 (98.456)	Training Prec@5 99.414 (99.353)	
2022-06-28 16:30:54,978: ============================================================
2022-06-28 16:32:18,674: time cost, forward:0.010789314529153785, backward:0.02962966452403217, data cost:0.7463658747389292 
2022-06-28 16:32:18,674: ============================================================
2022-06-28 16:32:18,674: Epoch 10/26 Batch 1900/7662 eta: 1 day, 5:50:28.961531	Training Loss 3.8317 (3.6273)	Training Prec@1 98.047 (98.449)	Training Prec@5 99.219 (99.349)	
2022-06-28 16:32:18,674: ============================================================
2022-06-28 16:33:38,203: time cost, forward:0.010791429345043615, backward:0.02957991077161658, data cost:0.746898683802732 
2022-06-28 16:33:38,203: ============================================================
2022-06-28 16:33:38,204: Epoch 10/26 Batch 2000/7662 eta: 1 day, 4:20:00.374012	Training Loss 3.6914 (3.6322)	Training Prec@1 98.633 (98.441)	Training Prec@5 99.219 (99.345)	
2022-06-28 16:33:38,204: ============================================================
2022-06-28 16:34:55,575: time cost, forward:0.010779406923291341, backward:0.0293868927230944, data cost:0.7464313429841091 
2022-06-28 16:34:55,575: ============================================================
2022-06-28 16:34:55,575: Epoch 10/26 Batch 2100/7662 eta: 1 day, 3:32:35.484343	Training Loss 3.9943 (3.6376)	Training Prec@1 97.852 (98.428)	Training Prec@5 99.219 (99.343)	
2022-06-28 16:34:55,575: ============================================================
2022-06-28 16:36:14,291: time cost, forward:0.010808781744838574, backward:0.029311992299182677, data cost:0.7464810460738129 
2022-06-28 16:36:14,292: ============================================================
2022-06-28 16:36:14,292: Epoch 10/26 Batch 2200/7662 eta: 1 day, 4:00:00.574417	Training Loss 3.7451 (3.6437)	Training Prec@1 98.633 (98.422)	Training Prec@5 99.609 (99.340)	
2022-06-28 16:36:14,292: ============================================================
2022-06-28 16:37:32,815: time cost, forward:0.01088069220530878, backward:0.02936603754382903, data cost:0.7462779261226912 
2022-06-28 16:37:32,815: ============================================================
2022-06-28 16:37:32,816: Epoch 10/26 Batch 2300/7662 eta: 1 day, 3:54:35.028705	Training Loss 3.9043 (3.6490)	Training Prec@1 98.438 (98.414)	Training Prec@5 99.219 (99.335)	
2022-06-28 16:37:32,816: ============================================================
2022-06-28 16:38:50,166: time cost, forward:0.010897236796606079, backward:0.029441515173997516, data cost:0.745620051042494 
2022-06-28 16:38:50,166: ============================================================
2022-06-28 16:38:50,167: Epoch 10/26 Batch 2400/7662 eta: 1 day, 3:28:17.151014	Training Loss 3.5127 (3.6540)	Training Prec@1 98.828 (98.408)	Training Prec@5 99.609 (99.333)	
2022-06-28 16:38:50,167: ============================================================
2022-06-28 16:40:07,453: time cost, forward:0.010917926225818697, backward:0.029419952032326602, data cost:0.7450799377215486 
2022-06-28 16:40:07,454: ============================================================
2022-06-28 16:40:07,454: Epoch 10/26 Batch 2500/7662 eta: 1 day, 3:25:38.138967	Training Loss 3.8265 (3.6592)	Training Prec@1 97.852 (98.404)	Training Prec@5 99.219 (99.332)	
2022-06-28 16:40:07,454: ============================================================
2022-06-28 16:41:24,339: time cost, forward:0.010916558445853057, backward:0.02940890815635056, data cost:0.7444382141351058 
2022-06-28 16:41:24,340: ============================================================
2022-06-28 16:41:24,340: Epoch 10/26 Batch 2600/7662 eta: 1 day, 3:15:48.956806	Training Loss 3.7679 (3.6642)	Training Prec@1 96.875 (98.395)	Training Prec@5 98.242 (99.328)	
2022-06-28 16:41:24,340: ============================================================
2022-06-28 16:42:41,515: time cost, forward:0.010897927657018197, backward:0.029392007369825512, data cost:0.7439759339434697 
2022-06-28 16:42:41,516: ============================================================
2022-06-28 16:42:41,516: Epoch 10/26 Batch 2700/7662 eta: 1 day, 3:20:41.805287	Training Loss 3.6771 (3.6676)	Training Prec@1 98.047 (98.390)	Training Prec@5 99.219 (99.325)	
2022-06-28 16:42:41,516: ============================================================
2022-06-28 16:44:01,069: time cost, forward:0.010881204611916932, backward:0.029329377525659405, data cost:0.7444414667420491 
2022-06-28 16:44:01,069: ============================================================
2022-06-28 16:44:01,070: Epoch 10/26 Batch 2800/7662 eta: 1 day, 4:09:55.318412	Training Loss 3.7238 (3.6722)	Training Prec@1 98.242 (98.383)	Training Prec@5 98.828 (99.321)	
2022-06-28 16:44:01,070: ============================================================
2022-06-28 16:45:18,964: time cost, forward:0.010862352273183759, backward:0.029293321173287295, data cost:0.7442848619077485 
2022-06-28 16:45:18,964: ============================================================
2022-06-28 16:45:18,964: Epoch 10/26 Batch 2900/7662 eta: 1 day, 3:33:22.665899	Training Loss 3.9835 (3.6763)	Training Prec@1 97.266 (98.375)	Training Prec@5 99.414 (99.319)	
2022-06-28 16:45:18,964: ============================================================
2022-06-28 16:46:37,156: time cost, forward:0.010849453759773765, backward:0.029270429458567285, data cost:0.7442222478668783 
2022-06-28 16:46:37,156: ============================================================
2022-06-28 16:46:37,156: Epoch 10/26 Batch 3000/7662 eta: 1 day, 3:38:23.205823	Training Loss 3.9397 (3.6807)	Training Prec@1 97.656 (98.367)	Training Prec@5 98.633 (99.316)	
2022-06-28 16:46:37,156: ============================================================
2022-06-28 16:47:55,205: time cost, forward:0.010837697798146398, backward:0.029267511124686296, data cost:0.7440986578677615 
2022-06-28 16:47:55,205: ============================================================
2022-06-28 16:47:55,205: Epoch 10/26 Batch 3100/7662 eta: 1 day, 3:34:03.241451	Training Loss 3.4060 (3.6843)	Training Prec@1 97.852 (98.363)	Training Prec@5 99.023 (99.314)	
2022-06-28 16:47:55,205: ============================================================
2022-06-28 16:49:12,413: time cost, forward:0.010823021236156144, backward:0.029256414867781518, data cost:0.7437325530068581 
2022-06-28 16:49:12,414: ============================================================
2022-06-28 16:49:12,414: Epoch 10/26 Batch 3200/7662 eta: 1 day, 3:14:57.389513	Training Loss 3.7560 (3.6887)	Training Prec@1 97.852 (98.356)	Training Prec@5 99.023 (99.312)	
2022-06-28 16:49:12,414: ============================================================
2022-06-28 16:50:31,059: time cost, forward:0.01081458587796806, backward:0.029234181537379566, data cost:0.7438317202336501 
2022-06-28 16:50:31,059: ============================================================
2022-06-28 16:50:31,059: Epoch 10/26 Batch 3300/7662 eta: 1 day, 3:44:04.165020	Training Loss 3.7350 (3.6923)	Training Prec@1 98.828 (98.352)	Training Prec@5 99.609 (99.311)	
2022-06-28 16:50:31,059: ============================================================
2022-06-28 16:51:51,099: time cost, forward:0.010803960638559717, backward:0.029224917340818734, data cost:0.744322941982946 
2022-06-28 16:51:51,099: ============================================================
2022-06-28 16:51:51,100: Epoch 10/26 Batch 3400/7662 eta: 1 day, 4:12:15.250363	Training Loss 3.6694 (3.6963)	Training Prec@1 99.219 (98.345)	Training Prec@5 99.414 (99.308)	
2022-06-28 16:51:51,100: ============================================================
2022-06-28 16:53:10,097: time cost, forward:0.010795525463351729, backward:0.029219892373184505, data cost:0.7444843415976865 
2022-06-28 16:53:10,097: ============================================================
2022-06-28 16:53:10,097: Epoch 10/26 Batch 3500/7662 eta: 1 day, 3:48:53.749776	Training Loss 3.9598 (3.6998)	Training Prec@1 97.070 (98.337)	Training Prec@5 98.438 (99.304)	
2022-06-28 16:53:10,098: ============================================================
2022-06-28 16:54:29,413: time cost, forward:0.010793924729139747, backward:0.029217955667994427, data cost:0.7447167223908895 
2022-06-28 16:54:29,414: ============================================================
2022-06-28 16:54:29,414: Epoch 10/26 Batch 3600/7662 eta: 1 day, 3:54:18.316633	Training Loss 3.8254 (3.7029)	Training Prec@1 97.266 (98.330)	Training Prec@5 99.414 (99.300)	
2022-06-28 16:54:29,414: ============================================================
2022-06-28 16:55:49,131: time cost, forward:0.01078861885761757, backward:0.029205630488832696, data cost:0.745060372655538 
2022-06-28 16:55:49,131: ============================================================
2022-06-28 16:55:49,132: Epoch 10/26 Batch 3700/7662 eta: 1 day, 4:01:26.715025	Training Loss 4.0566 (3.7063)	Training Prec@1 97.461 (98.326)	Training Prec@5 98.633 (99.298)	
2022-06-28 16:55:49,132: ============================================================
2022-06-28 16:57:08,317: time cost, forward:0.01078375341641837, backward:0.02918438749521712, data cost:0.7452528590307514 
2022-06-28 16:57:08,318: ============================================================
2022-06-28 16:57:08,318: Epoch 10/26 Batch 3800/7662 eta: 1 day, 3:48:54.842157	Training Loss 3.9165 (3.7093)	Training Prec@1 99.023 (98.320)	Training Prec@5 99.219 (99.295)	
2022-06-28 16:57:08,318: ============================================================
2022-06-28 16:58:24,455: time cost, forward:0.010807279012973079, backward:0.029191835564385624, data cost:0.7445968874725631 
2022-06-28 16:58:24,455: ============================================================
2022-06-28 16:58:24,455: Epoch 10/26 Batch 3900/7662 eta: 1 day, 2:43:23.166739	Training Loss 3.9897 (3.7126)	Training Prec@1 98.242 (98.313)	Training Prec@5 99.219 (99.293)	
2022-06-28 16:58:24,455: ============================================================
2022-06-28 16:59:41,299: time cost, forward:0.010833451258417785, backward:0.0291961551040493, data cost:0.7441510113813663 
2022-06-28 16:59:41,300: ============================================================
2022-06-28 16:59:41,300: Epoch 10/26 Batch 4000/7662 eta: 1 day, 2:57:00.307715	Training Loss 3.8915 (3.7160)	Training Prec@1 98.242 (98.305)	Training Prec@5 99.414 (99.289)	
2022-06-28 16:59:41,300: ============================================================
2022-06-28 17:00:56,428: time cost, forward:0.010874793249736562, backward:0.029207961563367208, data cost:0.7432854212793265 
2022-06-28 17:00:56,429: ============================================================
2022-06-28 17:00:56,429: Epoch 10/26 Batch 4100/7662 eta: 1 day, 2:19:39.646180	Training Loss 4.0752 (3.7189)	Training Prec@1 97.266 (98.300)	Training Prec@5 99.219 (99.286)	
2022-06-28 17:00:56,430: ============================================================
2022-06-28 17:02:11,678: time cost, forward:0.010897842297300777, backward:0.029257838684594414, data cost:0.7424646867800678 
2022-06-28 17:02:11,679: ============================================================
2022-06-28 17:02:11,679: Epoch 10/26 Batch 4200/7662 eta: 1 day, 2:20:56.070432	Training Loss 3.5754 (3.7221)	Training Prec@1 99.414 (98.294)	Training Prec@5 100.000 (99.283)	
2022-06-28 17:02:11,679: ============================================================
2022-06-28 17:03:28,008: time cost, forward:0.01093317237280779, backward:0.029304102704424614, data cost:0.7419211956533506 
2022-06-28 17:03:28,008: ============================================================
2022-06-28 17:03:28,008: Epoch 10/26 Batch 4300/7662 eta: 1 day, 2:42:20.594347	Training Loss 4.0494 (3.7250)	Training Prec@1 98.633 (98.290)	Training Prec@5 99.414 (99.281)	
2022-06-28 17:03:28,008: ============================================================
2022-06-28 17:04:44,233: time cost, forward:0.010968071895719902, backward:0.029356515253096935, data cost:0.7413713032886585 
2022-06-28 17:04:44,233: ============================================================
2022-06-28 17:04:44,233: Epoch 10/26 Batch 4400/7662 eta: 1 day, 2:38:53.070550	Training Loss 4.1590 (3.7279)	Training Prec@1 97.266 (98.286)	Training Prec@5 98.828 (99.278)	
2022-06-28 17:04:44,234: ============================================================
2022-06-28 17:06:00,208: time cost, forward:0.01098644916257161, backward:0.029377978069036637, data cost:0.7408339503500879 
2022-06-28 17:06:00,209: ============================================================
2022-06-28 17:06:00,209: Epoch 10/26 Batch 4500/7662 eta: 1 day, 2:32:23.039630	Training Loss 3.8461 (3.7303)	Training Prec@1 97.656 (98.281)	Training Prec@5 99.023 (99.275)	
2022-06-28 17:06:00,209: ============================================================
2022-06-28 17:07:17,226: time cost, forward:0.01100388825730309, backward:0.029394524956454556, data cost:0.7405509192882919 
2022-06-28 17:07:17,226: ============================================================
2022-06-28 17:07:17,227: Epoch 10/26 Batch 4600/7662 eta: 1 day, 2:52:56.395552	Training Loss 4.1747 (3.7332)	Training Prec@1 97.852 (98.274)	Training Prec@5 98.242 (99.271)	
2022-06-28 17:07:17,227: ============================================================
2022-06-28 17:08:33,130: time cost, forward:0.011011629668822515, backward:0.02941373754851639, data cost:0.7400469237070029 
2022-06-28 17:08:33,130: ============================================================
2022-06-28 17:08:33,130: Epoch 10/26 Batch 4700/7662 eta: 1 day, 2:28:21.177451	Training Loss 3.7312 (3.7358)	Training Prec@1 98.633 (98.269)	Training Prec@5 99.414 (99.269)	
2022-06-28 17:08:33,131: ============================================================
2022-06-28 17:09:49,160: time cost, forward:0.011032364919399762, backward:0.02945868480600499, data cost:0.7395521784653438 
2022-06-28 17:09:49,174: ============================================================
2022-06-28 17:09:49,175: Epoch 10/26 Batch 4800/7662 eta: 1 day, 2:30:01.141566	Training Loss 3.8136 (3.7391)	Training Prec@1 97.266 (98.261)	Training Prec@5 98.242 (99.264)	
2022-06-28 17:09:49,175: ============================================================
2022-06-28 17:11:05,777: time cost, forward:0.011051369628314461, backward:0.02948334567959052, data cost:0.7392157539831762 
2022-06-28 17:11:05,777: ============================================================
2022-06-28 17:11:05,778: Epoch 10/26 Batch 4900/7662 eta: 1 day, 2:40:25.785000	Training Loss 3.9593 (3.7410)	Training Prec@1 98.047 (98.260)	Training Prec@5 99.023 (99.263)	
2022-06-28 17:11:05,778: ============================================================
2022-06-28 17:12:23,021: time cost, forward:0.011074140182040315, backward:0.02951959081353319, data cost:0.7390008928013172 
2022-06-28 17:12:23,022: ============================================================
2022-06-28 17:12:23,022: Epoch 10/26 Batch 5000/7662 eta: 1 day, 2:52:32.290488	Training Loss 3.8609 (3.7436)	Training Prec@1 98.633 (98.254)	Training Prec@5 99.219 (99.260)	
2022-06-28 17:12:23,022: ============================================================
2022-06-28 17:13:38,282: time cost, forward:0.011079784373859257, backward:0.029556686491516437, data cost:0.7384207041550206 
2022-06-28 17:13:38,282: ============================================================
2022-06-28 17:13:38,283: Epoch 10/26 Batch 5100/7662 eta: 1 day, 2:09:52.497440	Training Loss 3.7952 (3.7456)	Training Prec@1 98.047 (98.249)	Training Prec@5 99.023 (99.259)	
2022-06-28 17:13:38,283: ============================================================
2022-06-28 17:14:54,663: time cost, forward:0.011101355803061, backward:0.029580686064402995, data cost:0.7380723762934106 
2022-06-28 17:14:54,663: ============================================================
2022-06-28 17:14:54,664: Epoch 10/26 Batch 5200/7662 eta: 1 day, 2:31:58.171647	Training Loss 4.0601 (3.7486)	Training Prec@1 98.633 (98.242)	Training Prec@5 100.000 (99.255)	
2022-06-28 17:14:54,664: ============================================================
2022-06-28 17:16:11,654: time cost, forward:0.011126752888668165, backward:0.02962861778286633, data cost:0.7378229610333692 
2022-06-28 17:16:11,655: ============================================================
2022-06-28 17:16:11,655: Epoch 10/26 Batch 5300/7662 eta: 1 day, 2:43:24.407250	Training Loss 3.7591 (3.7515)	Training Prec@1 98.047 (98.237)	Training Prec@5 99.023 (99.251)	
2022-06-28 17:16:11,655: ============================================================
2022-06-28 17:17:27,078: time cost, forward:0.011140545952604929, backward:0.029665167363932186, data cost:0.7373124077311709 
2022-06-28 17:17:27,078: ============================================================
2022-06-28 17:17:27,078: Epoch 10/26 Batch 5400/7662 eta: 1 day, 2:09:29.784766	Training Loss 3.7556 (3.7540)	Training Prec@1 97.852 (98.232)	Training Prec@5 98.828 (99.249)	
2022-06-28 17:17:27,078: ============================================================
2022-06-28 17:18:44,255: time cost, forward:0.01115541419975973, backward:0.029698105763686658, data cost:0.7371426883839026 
2022-06-28 17:18:44,256: ============================================================
2022-06-28 17:18:44,256: Epoch 10/26 Batch 5500/7662 eta: 1 day, 2:44:42.966816	Training Loss 4.0047 (3.7568)	Training Prec@1 97.461 (98.228)	Training Prec@5 99.023 (99.246)	
2022-06-28 17:18:44,256: ============================================================
2022-06-28 17:20:01,197: time cost, forward:0.011174369569462652, backward:0.02972024678119401, data cost:0.7369395806802599 
2022-06-28 17:20:01,198: ============================================================
2022-06-28 17:20:01,198: Epoch 10/26 Batch 5600/7662 eta: 1 day, 2:38:32.212857	Training Loss 3.7503 (3.7592)	Training Prec@1 97.070 (98.222)	Training Prec@5 98.633 (99.244)	
2022-06-28 17:20:01,198: ============================================================
2022-06-28 17:21:17,298: time cost, forward:0.011197558200700302, backward:0.02974207473650462, data cost:0.7365883298664057 
2022-06-28 17:21:17,304: ============================================================
2022-06-28 17:21:17,305: Epoch 10/26 Batch 5700/7662 eta: 1 day, 2:19:54.703678	Training Loss 3.7926 (3.7614)	Training Prec@1 98.242 (98.217)	Training Prec@5 99.023 (99.241)	
2022-06-28 17:21:17,305: ============================================================
2022-06-28 17:22:33,927: time cost, forward:0.011211599557846657, backward:0.029755028306790356, data cost:0.7363613104076093 
2022-06-28 17:22:33,928: ============================================================
2022-06-28 17:22:33,928: Epoch 10/26 Batch 5800/7662 eta: 1 day, 2:29:21.910883	Training Loss 3.7637 (3.7635)	Training Prec@1 98.828 (98.212)	Training Prec@5 99.414 (99.238)	
2022-06-28 17:22:33,929: ============================================================
2022-06-28 17:23:49,089: time cost, forward:0.011215301828276082, backward:0.02978553968398202, data cost:0.7358820292480438 
2022-06-28 17:23:49,089: ============================================================
2022-06-28 17:23:49,089: Epoch 10/26 Batch 5900/7662 eta: 1 day, 1:57:46.619593	Training Loss 4.0914 (3.7663)	Training Prec@1 96.680 (98.207)	Training Prec@5 99.219 (99.237)	
2022-06-28 17:23:49,089: ============================================================
2022-06-28 17:25:04,739: time cost, forward:0.011221691814536432, backward:0.029814592101689595, data cost:0.735499307262359 
2022-06-28 17:25:04,739: ============================================================
2022-06-28 17:25:04,740: Epoch 10/26 Batch 6000/7662 eta: 1 day, 2:06:39.026710	Training Loss 3.9379 (3.7684)	Training Prec@1 97.656 (98.204)	Training Prec@5 99.023 (99.235)	
2022-06-28 17:25:04,740: ============================================================
2022-06-28 17:26:21,157: time cost, forward:0.011228045668244695, backward:0.02982997104640397, data cost:0.7352682112631084 
2022-06-28 17:26:21,158: ============================================================
2022-06-28 17:26:21,158: Epoch 10/26 Batch 6100/7662 eta: 1 day, 2:21:17.375288	Training Loss 4.0159 (3.7712)	Training Prec@1 97.461 (98.198)	Training Prec@5 98.438 (99.233)	
2022-06-28 17:26:21,158: ============================================================
2022-06-28 17:27:36,909: time cost, forward:0.011241564117606406, backward:0.029859950262070625, data cost:0.7349122649797568 
2022-06-28 17:27:36,909: ============================================================
2022-06-28 17:27:36,910: Epoch 10/26 Batch 6200/7662 eta: 1 day, 2:06:13.614287	Training Loss 3.5875 (3.7732)	Training Prec@1 98.047 (98.195)	Training Prec@5 99.805 (99.231)	
2022-06-28 17:27:36,910: ============================================================
2022-06-28 17:28:52,267: time cost, forward:0.011252229640286656, backward:0.029870330199190012, data cost:0.7345271309626862 
2022-06-28 17:28:52,267: ============================================================
2022-06-28 17:28:52,268: Epoch 10/26 Batch 6300/7662 eta: 1 day, 1:56:50.020771	Training Loss 3.8036 (3.7752)	Training Prec@1 98.047 (98.190)	Training Prec@5 99.414 (99.229)	
2022-06-28 17:28:52,268: ============================================================
2022-06-28 17:30:08,702: time cost, forward:0.011263305907287455, backward:0.029884529814233556, data cost:0.7343183023926988 
2022-06-28 17:30:08,702: ============================================================
2022-06-28 17:30:08,703: Epoch 10/26 Batch 6400/7662 eta: 1 day, 2:17:48.437183	Training Loss 3.7994 (3.7776)	Training Prec@1 98.438 (98.187)	Training Prec@5 99.023 (99.226)	
2022-06-28 17:30:08,703: ============================================================
2022-06-28 17:31:26,822: time cost, forward:0.011282443339906485, backward:0.02991849291341124, data cost:0.7343472766406647 
2022-06-28 17:31:26,841: ============================================================
2022-06-28 17:31:26,842: Epoch 10/26 Batch 6500/7662 eta: 1 day, 2:51:41.236263	Training Loss 3.9421 (3.7798)	Training Prec@1 97.852 (98.183)	Training Prec@5 98.633 (99.224)	
2022-06-28 17:31:26,842: ============================================================
2022-06-28 17:32:42,964: time cost, forward:0.011289118889480454, backward:0.029951423420149514, data cost:0.7340861840182352 
2022-06-28 17:32:42,964: ============================================================
2022-06-28 17:32:42,964: Epoch 10/26 Batch 6600/7662 eta: 1 day, 2:08:49.133729	Training Loss 4.0122 (3.7816)	Training Prec@1 97.461 (98.180)	Training Prec@5 99.023 (99.223)	
2022-06-28 17:32:42,964: ============================================================
2022-06-28 17:34:00,537: time cost, forward:0.011303895977935359, backward:0.029967901652954394, data cost:0.7340537735838947 
2022-06-28 17:34:00,538: ============================================================
2022-06-28 17:34:00,538: Epoch 10/26 Batch 6700/7662 eta: 1 day, 2:37:26.455692	Training Loss 3.9459 (3.7836)	Training Prec@1 98.047 (98.177)	Training Prec@5 99.805 (99.221)	
2022-06-28 17:34:00,538: ============================================================
2022-06-28 17:35:16,234: time cost, forward:0.011318314652317394, backward:0.030009743500709674, data cost:0.7337178735807374 
2022-06-28 17:35:16,234: ============================================================
2022-06-28 17:35:16,234: Epoch 10/26 Batch 6800/7662 eta: 1 day, 1:57:30.727685	Training Loss 3.8471 (3.7857)	Training Prec@1 98.242 (98.173)	Training Prec@5 99.609 (99.219)	
2022-06-28 17:35:16,234: ============================================================
2022-06-28 17:36:33,115: time cost, forward:0.011325792015972544, backward:0.030006054709451512, data cost:0.733618364902247 
2022-06-28 17:36:33,115: ============================================================
2022-06-28 17:36:33,115: Epoch 10/26 Batch 6900/7662 eta: 1 day, 2:20:36.806706	Training Loss 3.9291 (3.7879)	Training Prec@1 96.680 (98.169)	Training Prec@5 97.852 (99.217)	
2022-06-28 17:36:33,116: ============================================================
2022-06-28 17:37:49,323: time cost, forward:0.011339368232915632, backward:0.030033563712542868, data cost:0.7333867479723034 
2022-06-28 17:37:49,324: ============================================================
2022-06-28 17:37:49,324: Epoch 10/26 Batch 7000/7662 eta: 1 day, 2:05:30.673131	Training Loss 3.8005 (3.7901)	Training Prec@1 98.242 (98.163)	Training Prec@5 99.805 (99.214)	
2022-06-28 17:37:49,324: ============================================================
2022-06-28 17:39:04,724: time cost, forward:0.011338488487042681, backward:0.030050718409861624, data cost:0.7330721132619933 
2022-06-28 17:39:04,724: ============================================================
2022-06-28 17:39:04,724: Epoch 10/26 Batch 7100/7662 eta: 1 day, 1:47:39.230982	Training Loss 3.8831 (3.7922)	Training Prec@1 97.461 (98.159)	Training Prec@5 98.828 (99.211)	
2022-06-28 17:39:04,724: ============================================================
2022-06-28 17:40:20,457: time cost, forward:0.011344226305145972, backward:0.029995502506896744, data cost:0.7328763512509252 
2022-06-28 17:40:20,457: ============================================================
2022-06-28 17:40:20,457: Epoch 10/26 Batch 7200/7662 eta: 1 day, 1:53:13.513114	Training Loss 3.8092 (3.7939)	Training Prec@1 98.242 (98.157)	Training Prec@5 98.828 (99.210)	
2022-06-28 17:40:20,457: ============================================================
2022-06-28 17:41:37,138: time cost, forward:0.011358990540552146, backward:0.029988304460386753, data cost:0.7327600662504782 
2022-06-28 17:41:37,138: ============================================================
2022-06-28 17:41:37,138: Epoch 10/26 Batch 7300/7662 eta: 1 day, 2:11:22.715482	Training Loss 3.6496 (3.7959)	Training Prec@1 98.438 (98.154)	Training Prec@5 99.219 (99.208)	
2022-06-28 17:41:37,138: ============================================================
2022-06-28 17:42:53,416: time cost, forward:0.011371903072129812, backward:0.029997196660233216, data cost:0.7325781942267791 
2022-06-28 17:42:53,416: ============================================================
2022-06-28 17:42:53,416: Epoch 10/26 Batch 7400/7662 eta: 1 day, 2:01:51.448348	Training Loss 4.0787 (3.7977)	Training Prec@1 98.438 (98.150)	Training Prec@5 99.414 (99.206)	
2022-06-28 17:42:53,416: ============================================================
2022-06-28 17:44:09,375: time cost, forward:0.011378259241684292, backward:0.030004681388701354, data cost:0.7323665280296956 
2022-06-28 17:44:09,376: ============================================================
2022-06-28 17:44:09,376: Epoch 10/26 Batch 7500/7662 eta: 1 day, 1:54:04.493177	Training Loss 4.1529 (3.7994)	Training Prec@1 97.266 (98.148)	Training Prec@5 98.438 (99.205)	
2022-06-28 17:44:09,376: ============================================================
2022-06-28 17:45:25,185: time cost, forward:0.01137830649791446, backward:0.030022966593468654, data cost:0.7321355691441173 
2022-06-28 17:45:25,185: ============================================================
2022-06-28 17:45:25,185: Epoch 10/26 Batch 7600/7662 eta: 1 day, 1:49:43.838947	Training Loss 3.8195 (3.8011)	Training Prec@1 98.438 (98.145)	Training Prec@5 99.414 (99.203)	
2022-06-28 17:45:25,185: ============================================================
2022-06-28 17:46:13,847: Epoch: 10/26 eta: 1 day, 1:48:56.079118	Training Loss 4.2796 (3.8025)	Training Prec@1 97.852 (98.142)	Training Prec@5 99.219 (99.202)
2022-06-28 17:46:13,847: ============================================================
2022-06-28 17:46:13,850: Save Checkpoint...
2022-06-28 17:46:13,851: ============================================================
2022-06-28 17:46:16,136: Save done!
2022-06-28 17:46:16,136: ============================================================
2022-06-28 17:47:34,788: time cost, forward:0.010914525600394817, backward:0.029096981491705382, data cost:0.7493282809402003 
2022-06-28 17:47:34,789: ============================================================
2022-06-28 17:47:34,789: Epoch 11/26 Batch 100/7662 eta: 1 day, 2:45:43.266143	Training Loss 3.5759 (3.4666)	Training Prec@1 98.828 (98.751)	Training Prec@5 99.219 (99.517)	
2022-06-28 17:47:34,789: ============================================================
2022-06-28 17:48:51,069: time cost, forward:0.010848154374702492, backward:0.028748092938907184, data cost:0.7361987571620462 
2022-06-28 17:48:51,069: ============================================================
2022-06-28 17:48:51,070: Epoch 11/26 Batch 200/7662 eta: 1 day, 1:56:02.196843	Training Loss 3.3192 (3.4793)	Training Prec@1 98.828 (98.698)	Training Prec@5 99.414 (99.497)	
2022-06-28 17:48:51,070: ============================================================
2022-06-28 17:50:07,298: time cost, forward:0.010924665425533435, backward:0.028629695292699296, data cost:0.7315849269114211 
2022-06-28 17:50:07,299: ============================================================
2022-06-28 17:50:07,299: Epoch 11/26 Batch 300/7662 eta: 1 day, 1:53:43.180682	Training Loss 3.7042 (3.4938)	Training Prec@1 97.461 (98.701)	Training Prec@5 98.633 (99.492)	
2022-06-28 17:50:07,299: ============================================================
2022-06-28 17:51:25,151: time cost, forward:0.010950935813119836, backward:0.028787241842513692, data cost:0.7331562842940328 
2022-06-28 17:51:25,152: ============================================================
2022-06-28 17:51:25,152: Epoch 11/26 Batch 400/7662 eta: 1 day, 2:25:30.920569	Training Loss 3.3433 (3.5035)	Training Prec@1 99.609 (98.702)	Training Prec@5 99.805 (99.496)	
2022-06-28 17:51:25,152: ============================================================
2022-06-28 17:52:42,580: time cost, forward:0.010924344550153774, backward:0.028849826785987746, data cost:0.7333084676929849 
2022-06-28 17:52:42,580: ============================================================
2022-06-28 17:52:42,581: Epoch 11/26 Batch 500/7662 eta: 1 day, 2:15:34.773771	Training Loss 3.7563 (3.5178)	Training Prec@1 98.633 (98.687)	Training Prec@5 99.023 (99.483)	
2022-06-28 17:52:42,581: ============================================================
2022-06-28 17:54:00,836: time cost, forward:0.010874137655522469, backward:0.0288831264228375, data cost:0.7348430924901183 
2022-06-28 17:54:00,837: ============================================================
2022-06-28 17:54:00,837: Epoch 11/26 Batch 600/7662 eta: 1 day, 2:31:07.138511	Training Loss 3.7311 (3.5298)	Training Prec@1 98.438 (98.672)	Training Prec@5 99.414 (99.472)	
2022-06-28 17:54:00,837: ============================================================
2022-06-28 17:55:15,820: time cost, forward:0.010848318899479376, backward:0.028869165371415952, data cost:0.7312739911850259 
2022-06-28 17:55:15,821: ============================================================
2022-06-28 17:55:15,821: Epoch 11/26 Batch 700/7662 eta: 1 day, 1:23:20.398201	Training Loss 3.6156 (3.5447)	Training Prec@1 98.828 (98.659)	Training Prec@5 99.609 (99.462)	
2022-06-28 17:55:15,821: ============================================================
2022-06-28 17:56:28,436: time cost, forward:0.01090726804673597, backward:0.02904760762955877, data cost:0.725367964134646 
2022-06-28 17:56:28,436: ============================================================
2022-06-28 17:56:28,437: Epoch 11/26 Batch 800/7662 eta: 1 day, 0:34:00.802341	Training Loss 3.6597 (3.5546)	Training Prec@1 97.656 (98.656)	Training Prec@5 98.828 (99.458)	
2022-06-28 17:56:28,437: ============================================================
2022-06-28 17:57:42,286: time cost, forward:0.011026760892687703, backward:0.029138520774374548, data cost:0.722128698372337 
2022-06-28 17:57:42,287: ============================================================
2022-06-28 17:57:42,287: Epoch 11/26 Batch 900/7662 eta: 1 day, 0:57:50.740834	Training Loss 3.4739 (3.5651)	Training Prec@1 98.828 (98.647)	Training Prec@5 99.414 (99.451)	
2022-06-28 17:57:42,287: ============================================================
2022-06-28 17:58:54,123: time cost, forward:0.01112114368854939, backward:0.029330128067367903, data cost:0.7173947364360362 
2022-06-28 17:58:54,123: ============================================================
2022-06-28 17:58:54,124: Epoch 11/26 Batch 1000/7662 eta: 1 day, 0:15:48.404963	Training Loss 3.6956 (3.5731)	Training Prec@1 99.023 (98.643)	Training Prec@5 99.805 (99.446)	
2022-06-28 17:58:54,124: ============================================================
2022-06-28 18:00:08,807: time cost, forward:0.011175458055935306, backward:0.029409029572741132, data cost:0.7162187151522719 
2022-06-28 18:00:08,807: ============================================================
2022-06-28 18:00:08,807: Epoch 11/26 Batch 1100/7662 eta: 1 day, 1:12:15.375052	Training Loss 3.8195 (3.5805)	Training Prec@1 97.852 (98.631)	Training Prec@5 99.219 (99.441)	
2022-06-28 18:00:08,807: ============================================================
2022-06-28 18:01:23,353: time cost, forward:0.011197076627271587, backward:0.02952823169635076, data cost:0.7150883439981112 
2022-06-28 18:01:23,354: ============================================================
2022-06-28 18:01:23,354: Epoch 11/26 Batch 1200/7662 eta: 1 day, 1:08:14.482768	Training Loss 3.8896 (3.5899)	Training Prec@1 97.852 (98.620)	Training Prec@5 99.414 (99.438)	
2022-06-28 18:01:23,354: ============================================================
2022-06-28 18:02:36,075: time cost, forward:0.011171333417239053, backward:0.029524358076898752, data cost:0.7128806901583771 
2022-06-28 18:02:36,075: ============================================================
2022-06-28 18:02:36,075: Epoch 11/26 Batch 1300/7662 eta: 1 day, 0:30:05.865069	Training Loss 3.8041 (3.5999)	Training Prec@1 99.023 (98.611)	Training Prec@5 99.609 (99.436)	
2022-06-28 18:02:36,075: ============================================================
2022-06-28 18:03:49,915: time cost, forward:0.01115830069017717, backward:0.029544162102645426, data cost:0.711758840586817 
2022-06-28 18:03:49,915: ============================================================
2022-06-28 18:03:49,915: Epoch 11/26 Batch 1400/7662 eta: 1 day, 0:51:28.821234	Training Loss 3.6753 (3.6095)	Training Prec@1 99.023 (98.596)	Training Prec@5 99.414 (99.431)	
2022-06-28 18:03:49,915: ============================================================
2022-06-28 18:05:02,403: time cost, forward:0.011159361005227035, backward:0.029562498268244503, data cost:0.7098655247386095 
2022-06-28 18:05:02,403: ============================================================
2022-06-28 18:05:02,403: Epoch 11/26 Batch 1500/7662 eta: 1 day, 0:22:57.940509	Training Loss 3.8920 (3.6177)	Training Prec@1 96.875 (98.587)	Training Prec@5 98.047 (99.424)	
2022-06-28 18:05:02,403: ============================================================
2022-06-28 18:06:16,137: time cost, forward:0.011208014610486153, backward:0.029613672755076186, data cost:0.7089053109856678 
2022-06-28 18:06:16,137: ============================================================
2022-06-28 18:06:16,137: Epoch 11/26 Batch 1600/7662 eta: 1 day, 0:46:52.678284	Training Loss 4.0516 (3.6276)	Training Prec@1 96.484 (98.571)	Training Prec@5 98.242 (99.418)	
2022-06-28 18:06:16,137: ============================================================
2022-06-28 18:07:29,071: time cost, forward:0.011171376164903915, backward:0.029619335075769092, data cost:0.7077116020431653 
2022-06-28 18:07:29,071: ============================================================
2022-06-28 18:07:29,071: Epoch 11/26 Batch 1700/7662 eta: 1 day, 0:29:32.128309	Training Loss 3.8806 (3.6362)	Training Prec@1 97.852 (98.558)	Training Prec@5 99.414 (99.413)	
2022-06-28 18:07:29,071: ============================================================
2022-06-28 18:08:42,869: time cost, forward:0.011231248812121508, backward:0.029699071372065563, data cost:0.7069623564401556 
2022-06-28 18:08:42,869: ============================================================
2022-06-28 18:08:42,869: Epoch 11/26 Batch 1800/7662 eta: 1 day, 0:45:43.234695	Training Loss 3.7396 (3.6440)	Training Prec@1 98.438 (98.542)	Training Prec@5 99.219 (99.404)	
2022-06-28 18:08:42,870: ============================================================
2022-06-28 18:09:55,988: time cost, forward:0.011266974664600728, backward:0.029672936680067083, data cost:0.7060469474963228 
2022-06-28 18:09:55,989: ============================================================
2022-06-28 18:09:55,989: Epoch 11/26 Batch 1900/7662 eta: 1 day, 0:30:50.228251	Training Loss 3.7920 (3.6507)	Training Prec@1 98.047 (98.529)	Training Prec@5 98.438 (99.399)	
2022-06-28 18:09:55,989: ============================================================
2022-06-28 18:11:11,592: time cost, forward:0.011284316641620065, backward:0.02955148290430921, data cost:0.7065829674919705 
2022-06-28 18:11:11,592: ============================================================
2022-06-28 18:11:11,592: Epoch 11/26 Batch 2000/7662 eta: 1 day, 1:19:32.302921	Training Loss 3.7522 (3.6562)	Training Prec@1 98.633 (98.525)	Training Prec@5 99.609 (99.398)	
2022-06-28 18:11:11,592: ============================================================
2022-06-28 18:12:24,079: time cost, forward:0.011261248940680924, backward:0.029522738608932314, data cost:0.7055395825128432 
2022-06-28 18:12:24,080: ============================================================
2022-06-28 18:12:24,080: Epoch 11/26 Batch 2100/7662 eta: 1 day, 0:15:42.622155	Training Loss 4.0481 (3.6631)	Training Prec@1 98.047 (98.512)	Training Prec@5 99.414 (99.393)	
2022-06-28 18:12:24,080: ============================================================
2022-06-28 18:13:37,813: time cost, forward:0.011290118172798659, backward:0.02953731628806551, data cost:0.7050690792971928 
2022-06-28 18:13:37,814: ============================================================
2022-06-28 18:13:37,814: Epoch 11/26 Batch 2200/7662 eta: 1 day, 0:39:30.419293	Training Loss 3.8266 (3.6707)	Training Prec@1 99.023 (98.502)	Training Prec@5 99.805 (99.387)	
2022-06-28 18:13:37,814: ============================================================
2022-06-28 18:14:51,376: time cost, forward:0.011324323120714531, backward:0.02957265125040699, data cost:0.7045327627746993 
2022-06-28 18:14:51,376: ============================================================
2022-06-28 18:14:51,376: Epoch 11/26 Batch 2300/7662 eta: 1 day, 0:34:50.479904	Training Loss 4.0563 (3.6776)	Training Prec@1 97.852 (98.487)	Training Prec@5 99.219 (99.382)	
2022-06-28 18:14:51,376: ============================================================
2022-06-28 18:16:04,620: time cost, forward:0.011349990100550522, backward:0.02963451327458676, data cost:0.7038824867337582 
2022-06-28 18:16:04,620: ============================================================
2022-06-28 18:16:04,620: Epoch 11/26 Batch 2400/7662 eta: 1 day, 0:27:13.824159	Training Loss 3.5355 (3.6835)	Training Prec@1 99.219 (98.481)	Training Prec@5 99.805 (99.379)	
2022-06-28 18:16:04,620: ============================================================
2022-06-28 18:17:17,640: time cost, forward:0.011351631946113406, backward:0.029640512306149266, data cost:0.7032655467506216 
2022-06-28 18:17:17,640: ============================================================
2022-06-28 18:17:17,640: Epoch 11/26 Batch 2500/7662 eta: 1 day, 0:21:31.841291	Training Loss 3.8385 (3.6901)	Training Prec@1 97.656 (98.468)	Training Prec@5 99.609 (99.372)	
2022-06-28 18:17:17,640: ============================================================
2022-06-28 18:18:32,068: time cost, forward:0.011347839308500566, backward:0.02964006024353685, data cost:0.7032547058532586 
2022-06-28 18:18:32,069: ============================================================
2022-06-28 18:18:32,069: Epoch 11/26 Batch 2600/7662 eta: 1 day, 0:48:29.442803	Training Loss 3.7675 (3.6966)	Training Prec@1 98.242 (98.458)	Training Prec@5 99.023 (99.368)	
2022-06-28 18:18:32,069: ============================================================
2022-06-28 18:19:46,121: time cost, forward:0.01135133283586138, backward:0.029684832467993968, data cost:0.7030487736316468 
2022-06-28 18:19:46,121: ============================================================
2022-06-28 18:19:46,121: Epoch 11/26 Batch 2700/7662 eta: 1 day, 0:39:43.692946	Training Loss 3.9293 (3.7020)	Training Prec@1 98.047 (98.451)	Training Prec@5 99.219 (99.366)	
2022-06-28 18:19:46,121: ============================================================
2022-06-28 18:20:59,993: time cost, forward:0.011360049971770968, backward:0.029696974766258682, data cost:0.7028195555613015 
2022-06-28 18:20:59,994: ============================================================
2022-06-28 18:20:59,994: Epoch 11/26 Batch 2800/7662 eta: 1 day, 0:34:54.073860	Training Loss 3.9844 (3.7080)	Training Prec@1 98.242 (98.442)	Training Prec@5 98.828 (99.359)	
2022-06-28 18:20:59,994: ============================================================
2022-06-28 18:22:15,026: time cost, forward:0.011364259239557325, backward:0.029724983644304544, data cost:0.7029987305927047 
2022-06-28 18:22:15,026: ============================================================
2022-06-28 18:22:15,027: Epoch 11/26 Batch 2900/7662 eta: 1 day, 0:56:48.768403	Training Loss 3.7624 (3.7130)	Training Prec@1 97.852 (98.431)	Training Prec@5 99.219 (99.352)	
2022-06-28 18:22:15,027: ============================================================
2022-06-28 18:23:29,705: time cost, forward:0.011400078963979, backward:0.02975024498077423, data cost:0.7030081274351226 
2022-06-28 18:23:29,705: ============================================================
2022-06-28 18:23:29,706: Epoch 11/26 Batch 3000/7662 eta: 1 day, 0:48:30.999488	Training Loss 3.7303 (3.7178)	Training Prec@1 98.242 (98.421)	Training Prec@5 99.609 (99.347)	
2022-06-28 18:23:29,706: ============================================================
2022-06-28 18:24:43,597: time cost, forward:0.011393885952536235, backward:0.029750418839973185, data cost:0.7028307047687296 
2022-06-28 18:24:43,598: ============================================================
2022-06-28 18:24:43,598: Epoch 11/26 Batch 3100/7662 eta: 1 day, 0:31:36.103971	Training Loss 3.8509 (3.7231)	Training Prec@1 98.633 (98.410)	Training Prec@5 99.219 (99.340)	
2022-06-28 18:24:43,598: ============================================================
2022-06-28 18:25:57,631: time cost, forward:0.011421250343024637, backward:0.029853858512503984, data cost:0.7025744761478606 
2022-06-28 18:25:57,632: ============================================================
2022-06-28 18:25:57,632: Epoch 11/26 Batch 3200/7662 eta: 1 day, 0:33:11.235900	Training Loss 3.7900 (3.7281)	Training Prec@1 99.023 (98.399)	Training Prec@5 99.609 (99.335)	
2022-06-28 18:25:57,632: ============================================================
2022-06-28 18:27:11,701: time cost, forward:0.011438262935984168, backward:0.029895502569170278, data cost:0.7024055978463396 
2022-06-28 18:27:11,701: ============================================================
2022-06-28 18:27:11,701: Epoch 11/26 Batch 3300/7662 eta: 1 day, 0:32:39.841512	Training Loss 3.9695 (3.7334)	Training Prec@1 97.461 (98.390)	Training Prec@5 98.828 (99.332)	
2022-06-28 18:27:11,702: ============================================================
2022-06-28 18:28:26,302: time cost, forward:0.011449642972617894, backward:0.029890702169900363, data cost:0.7024488630067534 
2022-06-28 18:28:26,303: ============================================================
2022-06-28 18:28:26,303: Epoch 11/26 Batch 3400/7662 eta: 1 day, 0:41:59.706827	Training Loss 4.1443 (3.7369)	Training Prec@1 98.047 (98.382)	Training Prec@5 99.219 (99.328)	
2022-06-28 18:28:26,303: ============================================================
2022-06-28 18:29:41,424: time cost, forward:0.011469623776087253, backward:0.029900415449968302, data cost:0.7026184091706997 
2022-06-28 18:29:41,424: ============================================================
2022-06-28 18:29:41,424: Epoch 11/26 Batch 3500/7662 eta: 1 day, 0:51:04.455680	Training Loss 3.8536 (3.7413)	Training Prec@1 97.656 (98.372)	Training Prec@5 99.023 (99.323)	
2022-06-28 18:29:41,424: ============================================================
2022-06-28 18:30:56,295: time cost, forward:0.01147108284689778, backward:0.029938462642405756, data cost:0.7026977616570068 
2022-06-28 18:30:56,296: ============================================================
2022-06-28 18:30:56,296: Epoch 11/26 Batch 3600/7662 eta: 1 day, 0:44:52.014801	Training Loss 3.9515 (3.7448)	Training Prec@1 98.242 (98.366)	Training Prec@5 99.414 (99.320)	
2022-06-28 18:30:56,296: ============================================================
2022-06-28 18:32:11,510: time cost, forward:0.011469452920621329, backward:0.029992550120027557, data cost:0.702851306944159 
2022-06-28 18:32:11,510: ============================================================
2022-06-28 18:32:11,511: Epoch 11/26 Batch 3700/7662 eta: 1 day, 0:50:24.800938	Training Loss 3.8839 (3.7491)	Training Prec@1 98.633 (98.361)	Training Prec@5 99.219 (99.317)	
2022-06-28 18:32:11,511: ============================================================
2022-06-28 18:33:25,550: time cost, forward:0.011454780153865468, backward:0.030021595747792805, data cost:0.7027175760984609 
2022-06-28 18:33:25,550: ============================================================
2022-06-28 18:33:25,550: Epoch 11/26 Batch 3800/7662 eta: 1 day, 0:25:54.118789	Training Loss 3.7432 (3.7529)	Training Prec@1 98.828 (98.351)	Training Prec@5 99.805 (99.312)	
2022-06-28 18:33:25,550: ============================================================
2022-06-28 18:34:39,732: time cost, forward:0.011460292947754, backward:0.030062606867291005, data cost:0.7026005794097595 
2022-06-28 18:34:39,732: ============================================================
2022-06-28 18:34:39,732: Epoch 11/26 Batch 3900/7662 eta: 1 day, 0:27:28.742971	Training Loss 4.0330 (3.7567)	Training Prec@1 97.852 (98.340)	Training Prec@5 99.414 (99.306)	
2022-06-28 18:34:39,732: ============================================================
2022-06-28 18:35:54,255: time cost, forward:0.011455778540239003, backward:0.030053704999392854, data cost:0.702631022996323 
2022-06-28 18:35:54,256: ============================================================
2022-06-28 18:35:54,256: Epoch 11/26 Batch 4000/7662 eta: 1 day, 0:32:59.685134	Training Loss 3.8242 (3.7603)	Training Prec@1 98.633 (98.331)	Training Prec@5 99.414 (99.302)	
2022-06-28 18:35:54,256: ============================================================
2022-06-28 18:37:09,298: time cost, forward:0.01145992653635718, backward:0.030059368734273655, data cost:0.7027647770390507 
2022-06-28 18:37:09,299: ============================================================
2022-06-28 18:37:09,299: Epoch 11/26 Batch 4100/7662 eta: 1 day, 0:42:00.809323	Training Loss 3.9701 (3.7638)	Training Prec@1 98.242 (98.322)	Training Prec@5 99.219 (99.297)	
2022-06-28 18:37:09,299: ============================================================
2022-06-28 18:38:23,524: time cost, forward:0.011454211725851387, backward:0.030062364095391248, data cost:0.702707273956139 
2022-06-28 18:38:23,525: ============================================================
2022-06-28 18:38:23,525: Epoch 11/26 Batch 4200/7662 eta: 1 day, 0:24:38.191521	Training Loss 4.0913 (3.7676)	Training Prec@1 97.461 (98.312)	Training Prec@5 99.219 (99.293)	
2022-06-28 18:38:23,525: ============================================================
2022-06-28 18:39:37,939: time cost, forward:0.011457789967464386, backward:0.03008279358960773, data cost:0.7026707496607573 
2022-06-28 18:39:37,939: ============================================================
2022-06-28 18:39:37,940: Epoch 11/26 Batch 4300/7662 eta: 1 day, 0:27:07.372365	Training Loss 3.8401 (3.7717)	Training Prec@1 98.242 (98.304)	Training Prec@5 99.219 (99.289)	
2022-06-28 18:39:37,940: ============================================================
2022-06-28 18:40:52,709: time cost, forward:0.011457599003387055, backward:0.03010478938918516, data cost:0.7027166416548035 
2022-06-28 18:40:52,710: ============================================================
2022-06-28 18:40:52,710: Epoch 11/26 Batch 4400/7662 eta: 1 day, 0:32:53.412180	Training Loss 3.9809 (3.7753)	Training Prec@1 97.461 (98.300)	Training Prec@5 99.023 (99.287)	
2022-06-28 18:40:52,710: ============================================================
2022-06-28 18:42:08,745: time cost, forward:0.01147030867266904, backward:0.030128817633539605, data cost:0.7030273682542789 
2022-06-28 18:42:08,745: ============================================================
2022-06-28 18:42:08,746: Epoch 11/26 Batch 4500/7662 eta: 1 day, 0:56:32.766939	Training Loss 3.9285 (3.7788)	Training Prec@1 97.852 (98.292)	Training Prec@5 98.633 (99.283)	
2022-06-28 18:42:08,746: ============================================================
2022-06-28 18:43:23,335: time cost, forward:0.011477593728629732, backward:0.030152968464532245, data cost:0.7030115122897751 
2022-06-28 18:43:23,336: ============================================================
2022-06-28 18:43:23,336: Epoch 11/26 Batch 4600/7662 eta: 1 day, 0:26:51.231503	Training Loss 3.8964 (3.7820)	Training Prec@1 97.656 (98.287)	Training Prec@5 98.633 (99.282)	
2022-06-28 18:43:23,336: ============================================================
2022-06-28 18:44:37,587: time cost, forward:0.0114803433443643, backward:0.030163597365495218, data cost:0.7029434108916788 
2022-06-28 18:44:37,588: ============================================================
2022-06-28 18:44:37,588: Epoch 11/26 Batch 4700/7662 eta: 1 day, 0:18:57.965281	Training Loss 3.7283 (3.7856)	Training Prec@1 98.047 (98.281)	Training Prec@5 99.219 (99.278)	
2022-06-28 18:44:37,588: ============================================================
2022-06-28 18:45:53,644: time cost, forward:0.011484491996502822, backward:0.030146325720079394, data cost:0.7032802632560976 
2022-06-28 18:45:53,644: ============================================================
2022-06-28 18:45:53,645: Epoch 11/26 Batch 4800/7662 eta: 1 day, 0:53:09.493615	Training Loss 4.0449 (3.7892)	Training Prec@1 98.047 (98.274)	Training Prec@5 99.219 (99.274)	
2022-06-28 18:45:53,645: ============================================================
2022-06-28 18:47:08,783: time cost, forward:0.011479372831236758, backward:0.03015485844531335, data cost:0.7034006852182862 
2022-06-28 18:47:08,783: ============================================================
2022-06-28 18:47:08,783: Epoch 11/26 Batch 4900/7662 eta: 1 day, 0:33:52.949514	Training Loss 4.1388 (3.7923)	Training Prec@1 97.656 (98.267)	Training Prec@5 99.023 (99.271)	
2022-06-28 18:47:08,783: ============================================================
2022-06-28 18:48:23,624: time cost, forward:0.01150131273279192, backward:0.030200833152546645, data cost:0.7033910390304837 
2022-06-28 18:48:23,624: ============================================================
2022-06-28 18:48:23,624: Epoch 11/26 Batch 5000/7662 eta: 1 day, 0:26:48.089269	Training Loss 3.9622 (3.7953)	Training Prec@1 98.047 (98.260)	Training Prec@5 99.609 (99.268)	
2022-06-28 18:48:23,625: ============================================================
2022-06-28 18:49:38,377: time cost, forward:0.011497428917983018, backward:0.030224098180130103, data cost:0.7034096418116275 
2022-06-28 18:49:38,377: ============================================================
2022-06-28 18:49:38,377: Epoch 11/26 Batch 5100/7662 eta: 1 day, 0:23:49.389927	Training Loss 3.6008 (3.7981)	Training Prec@1 98.828 (98.255)	Training Prec@5 99.414 (99.265)	
2022-06-28 18:49:38,377: ============================================================
2022-06-28 18:50:52,645: time cost, forward:0.011483804426140042, backward:0.030237277257119173, data cost:0.7033549659319579 
2022-06-28 18:50:52,646: ============================================================
2022-06-28 18:50:52,646: Epoch 11/26 Batch 5200/7662 eta: 1 day, 0:13:06.245619	Training Loss 3.9075 (3.8013)	Training Prec@1 98.047 (98.248)	Training Prec@5 98.828 (99.262)	
2022-06-28 18:50:52,646: ============================================================
2022-06-28 18:52:07,058: time cost, forward:0.011482933058471449, backward:0.030261241843012463, data cost:0.7033070771058431 
2022-06-28 18:52:07,058: ============================================================
2022-06-28 18:52:07,058: Epoch 11/26 Batch 5300/7662 eta: 1 day, 0:14:40.145672	Training Loss 3.8895 (3.8042)	Training Prec@1 98.242 (98.242)	Training Prec@5 99.219 (99.259)	
2022-06-28 18:52:07,058: ============================================================
2022-06-28 18:53:22,171: time cost, forward:0.011504911850902588, backward:0.03027154370841549, data cost:0.7033775597286348 
2022-06-28 18:53:22,172: ============================================================
2022-06-28 18:53:22,172: Epoch 11/26 Batch 5400/7662 eta: 1 day, 0:27:07.946928	Training Loss 3.9081 (3.8069)	Training Prec@1 96.875 (98.235)	Training Prec@5 98.047 (99.258)	
2022-06-28 18:53:22,172: ============================================================
2022-06-28 18:54:38,013: time cost, forward:0.011509916049217089, backward:0.030276049265191216, data cost:0.7036017048335071 
2022-06-28 18:54:38,013: ============================================================
2022-06-28 18:54:38,014: Epoch 11/26 Batch 5500/7662 eta: 1 day, 0:40:05.507520	Training Loss 3.9400 (3.8094)	Training Prec@1 98.047 (98.231)	Training Prec@5 99.219 (99.255)	
2022-06-28 18:54:38,014: ============================================================
2022-06-28 18:55:52,354: time cost, forward:0.011518180444849924, backward:0.030299718432350655, data cost:0.703525028392276 
2022-06-28 18:55:52,354: ============================================================
2022-06-28 18:55:52,354: Epoch 11/26 Batch 5600/7662 eta: 1 day, 0:09:33.585196	Training Loss 4.2038 (3.8117)	Training Prec@1 97.461 (98.227)	Training Prec@5 98.633 (99.254)	
2022-06-28 18:55:52,355: ============================================================
2022-06-28 18:57:07,773: time cost, forward:0.01153189141534048, backward:0.03030013904213424, data cost:0.703659356905925 
2022-06-28 18:57:07,773: ============================================================
2022-06-28 18:57:07,773: Epoch 11/26 Batch 5700/7662 eta: 1 day, 0:29:19.456875	Training Loss 3.8713 (3.8142)	Training Prec@1 97.656 (98.221)	Training Prec@5 99.023 (99.251)	
2022-06-28 18:57:07,774: ============================================================
2022-06-28 18:58:22,482: time cost, forward:0.011538648630014924, backward:0.030291789275733616, data cost:0.7036799524010903 
2022-06-28 18:58:22,482: ============================================================
2022-06-28 18:58:22,483: Epoch 11/26 Batch 5800/7662 eta: 1 day, 0:14:15.003906	Training Loss 3.8314 (3.8165)	Training Prec@1 98.047 (98.215)	Training Prec@5 98.828 (99.247)	
2022-06-28 18:58:22,483: ============================================================
2022-06-28 18:59:37,425: time cost, forward:0.011555269423693514, backward:0.030312282430012157, data cost:0.7036991970966299 
2022-06-28 18:59:37,425: ============================================================
2022-06-28 18:59:37,425: Epoch 11/26 Batch 5900/7662 eta: 1 day, 0:17:33.050066	Training Loss 3.8841 (3.8189)	Training Prec@1 98.438 (98.210)	Training Prec@5 99.219 (99.244)	
2022-06-28 18:59:37,426: ============================================================
2022-06-28 19:00:53,543: time cost, forward:0.01155272367140078, backward:0.030315408072365903, data cost:0.7039507504879862 
2022-06-28 19:00:53,543: ============================================================
2022-06-28 19:00:53,544: Epoch 11/26 Batch 6000/7662 eta: 1 day, 0:39:08.437404	Training Loss 3.9317 (3.8212)	Training Prec@1 98.047 (98.204)	Training Prec@5 98.633 (99.241)	
2022-06-28 19:00:53,544: ============================================================
2022-06-28 19:02:08,105: time cost, forward:0.011554581275786078, backward:0.03034571319901566, data cost:0.7039088462098424 
2022-06-28 19:02:08,105: ============================================================
2022-06-28 19:02:08,106: Epoch 11/26 Batch 6100/7662 eta: 1 day, 0:07:39.559307	Training Loss 3.9175 (3.8239)	Training Prec@1 98.242 (98.198)	Training Prec@5 99.023 (99.238)	
2022-06-28 19:02:08,106: ============================================================
2022-06-28 19:03:23,803: time cost, forward:0.01155894109175501, backward:0.03033072430388661, data cost:0.7040917107627783 
2022-06-28 19:03:23,804: ============================================================
2022-06-28 19:03:23,804: Epoch 11/26 Batch 6200/7662 eta: 1 day, 0:28:27.335981	Training Loss 3.7234 (3.8261)	Training Prec@1 98.047 (98.192)	Training Prec@5 99.219 (99.235)	
2022-06-28 19:03:23,804: ============================================================
2022-06-28 19:04:38,272: time cost, forward:0.011564536290729703, backward:0.030325999012408247, data cost:0.7040632704852744 
2022-06-28 19:04:38,273: ============================================================
2022-06-28 19:04:38,273: Epoch 11/26 Batch 6300/7662 eta: 1 day, 0:03:22.363215	Training Loss 4.0747 (3.8280)	Training Prec@1 96.289 (98.188)	Training Prec@5 99.023 (99.233)	
2022-06-28 19:04:38,273: ============================================================
2022-06-28 19:05:52,081: time cost, forward:0.011563592784981147, backward:0.03031433476267578, data cost:0.7039460906723101 
2022-06-28 19:05:52,081: ============================================================
2022-06-28 19:05:52,081: Epoch 11/26 Batch 6400/7662 eta: 23:49:20.141202	Training Loss 4.1530 (3.8298)	Training Prec@1 96.484 (98.183)	Training Prec@5 98.242 (99.231)	
2022-06-28 19:05:52,081: ============================================================
2022-06-28 19:07:06,803: time cost, forward:0.011560857983841715, backward:0.03031118797657948, data cost:0.7039667687281808 
2022-06-28 19:07:06,804: ============================================================
2022-06-28 19:07:06,804: Epoch 11/26 Batch 6500/7662 eta: 1 day, 0:05:47.744258	Training Loss 4.0218 (3.8320)	Training Prec@1 97.266 (98.178)	Training Prec@5 98.047 (99.229)	
2022-06-28 19:07:06,804: ============================================================
2022-06-28 19:08:22,005: time cost, forward:0.011579478829353935, backward:0.030300810294072545, data cost:0.7040466525587534 
2022-06-28 19:08:22,005: ============================================================
2022-06-28 19:08:22,005: Epoch 11/26 Batch 6600/7662 eta: 1 day, 0:13:48.413324	Training Loss 3.8641 (3.8336)	Training Prec@1 97.070 (98.175)	Training Prec@5 98.633 (99.227)	
2022-06-28 19:08:22,005: ============================================================
2022-06-28 19:09:37,152: time cost, forward:0.011591209477676457, backward:0.030285910539332387, data cost:0.7041255447255584 
2022-06-28 19:09:37,153: ============================================================
2022-06-28 19:09:37,153: Epoch 11/26 Batch 6700/7662 eta: 1 day, 0:11:30.737258	Training Loss 4.0383 (3.8355)	Training Prec@1 97.070 (98.170)	Training Prec@5 98.828 (99.224)	
2022-06-28 19:09:37,153: ============================================================
2022-06-28 19:10:51,347: time cost, forward:0.011592390818146331, backward:0.03028355165165406, data cost:0.7040606468701156 
2022-06-28 19:10:51,347: ============================================================
2022-06-28 19:10:51,348: Epoch 11/26 Batch 6800/7662 eta: 23:51:52.302655	Training Loss 3.8794 (3.8374)	Training Prec@1 98.047 (98.166)	Training Prec@5 99.414 (99.221)	
2022-06-28 19:10:51,348: ============================================================
2022-06-28 19:12:07,033: time cost, forward:0.011596210280403328, backward:0.03028591278066219, data cost:0.7042053182292008 
2022-06-28 19:12:07,033: ============================================================
2022-06-28 19:12:07,033: Epoch 11/26 Batch 6900/7662 eta: 1 day, 0:19:22.942636	Training Loss 3.8652 (3.8394)	Training Prec@1 97.266 (98.159)	Training Prec@5 99.219 (99.218)	
2022-06-28 19:12:07,033: ============================================================
2022-06-28 19:13:21,908: time cost, forward:0.011601119096627626, backward:0.030286075932960167, data cost:0.704232478758355 
2022-06-28 19:13:21,908: ============================================================
2022-06-28 19:13:21,909: Epoch 11/26 Batch 7000/7662 eta: 1 day, 0:02:30.772735	Training Loss 3.8326 (3.8413)	Training Prec@1 97.461 (98.154)	Training Prec@5 98.828 (99.215)	
2022-06-28 19:13:21,909: ============================================================
2022-06-28 19:14:37,064: time cost, forward:0.01160049022024896, backward:0.030302267642839976, data cost:0.7042855595447494 
2022-06-28 19:14:37,064: ============================================================
2022-06-28 19:14:37,065: Epoch 11/26 Batch 7100/7662 eta: 1 day, 0:06:39.962470	Training Loss 3.9386 (3.8425)	Training Prec@1 98.633 (98.150)	Training Prec@5 99.414 (99.213)	
2022-06-28 19:14:37,065: ============================================================
2022-06-28 19:15:51,764: time cost, forward:0.011599223006680735, backward:0.03028125656298555, data cost:0.7043133293328839 
2022-06-28 19:15:51,764: ============================================================
2022-06-28 19:15:51,764: Epoch 11/26 Batch 7200/7662 eta: 23:56:37.945986	Training Loss 3.9784 (3.8446)	Training Prec@1 98.242 (98.144)	Training Prec@5 98.633 (99.209)	
2022-06-28 19:15:51,764: ============================================================
2022-06-28 19:17:07,065: time cost, forward:0.011609607207348844, backward:0.030300218122497717, data cost:0.7043717712355829 
2022-06-28 19:17:07,066: ============================================================
2022-06-28 19:17:07,066: Epoch 11/26 Batch 7300/7662 eta: 1 day, 0:06:57.536062	Training Loss 3.9983 (3.8463)	Training Prec@1 97.461 (98.139)	Training Prec@5 99.023 (99.207)	
2022-06-28 19:17:07,066: ============================================================
2022-06-28 19:18:23,342: time cost, forward:0.011614149624406525, backward:0.030312056573021492, data cost:0.7045714126952453 
2022-06-28 19:18:23,343: ============================================================
2022-06-28 19:18:23,343: Epoch 11/26 Batch 7400/7662 eta: 1 day, 0:24:26.014751	Training Loss 3.9957 (3.8479)	Training Prec@1 97.656 (98.135)	Training Prec@5 98.242 (99.206)	
2022-06-28 19:18:23,343: ============================================================
2022-06-28 19:19:39,633: time cost, forward:0.011621149655484664, backward:0.03033870642209692, data cost:0.7047503916863395 
2022-06-28 19:19:39,633: ============================================================
2022-06-28 19:19:39,634: Epoch 11/26 Batch 7500/7662 eta: 1 day, 0:23:25.042367	Training Loss 4.0081 (3.8496)	Training Prec@1 98.633 (98.131)	Training Prec@5 99.609 (99.203)	
2022-06-28 19:19:39,634: ============================================================
2022-06-28 19:20:55,505: time cost, forward:0.011626852109316447, backward:0.030349543540473672, data cost:0.7048850709285402 
2022-06-28 19:20:55,506: ============================================================
2022-06-28 19:20:55,506: Epoch 11/26 Batch 7600/7662 eta: 1 day, 0:14:07.773793	Training Loss 4.0599 (3.8518)	Training Prec@1 97.266 (98.126)	Training Prec@5 99.219 (99.201)	
2022-06-28 19:20:55,506: ============================================================
2022-06-28 19:21:43,619: Epoch: 11/26 eta: 1 day, 0:13:19.974277	Training Loss 4.0313 (3.8527)	Training Prec@1 97.656 (98.123)	Training Prec@5 98.828 (99.199)
2022-06-28 19:21:43,620: ============================================================
2022-06-28 19:23:03,576: time cost, forward:0.010938242228344233, backward:0.028331308653860382, data cost:0.7621176820812803 
2022-06-28 19:23:03,576: ============================================================
2022-06-28 19:23:03,576: Epoch 12/26 Batch 100/7662 eta: 1 day, 1:28:09.878028	Training Loss 3.4425 (3.4948)	Training Prec@1 98.242 (98.704)	Training Prec@5 99.609 (99.467)	
2022-06-28 19:23:03,576: ============================================================
2022-06-28 19:24:18,721: time cost, forward:0.010849300940432141, backward:0.028854582177933737, data cost:0.7363713111110668 
2022-06-28 19:24:18,721: ============================================================
2022-06-28 19:24:18,722: Epoch 12/26 Batch 200/7662 eta: 23:56:54.774326	Training Loss 3.6225 (3.4941)	Training Prec@1 98.047 (98.670)	Training Prec@5 99.414 (99.466)	
2022-06-28 19:24:18,722: ============================================================
2022-06-28 19:25:31,674: time cost, forward:0.010912356966713999, backward:0.029511275498763374, data cost:0.7199073882405973 
2022-06-28 19:25:31,675: ============================================================
2022-06-28 19:25:31,675: Epoch 12/26 Batch 300/7662 eta: 23:13:47.211289	Training Loss 3.6254 (3.5107)	Training Prec@1 98.438 (98.666)	Training Prec@5 99.609 (99.466)	
2022-06-28 19:25:31,675: ============================================================
2022-06-28 19:26:46,642: time cost, forward:0.011067449598384082, backward:0.02937510856112143, data cost:0.7171049369008917 
2022-06-28 19:26:46,643: ============================================================
2022-06-28 19:26:46,643: Epoch 12/26 Batch 400/7662 eta: 23:51:01.420057	Training Loss 3.6567 (3.5248)	Training Prec@1 98.828 (98.666)	Training Prec@5 99.805 (99.464)	
2022-06-28 19:26:46,643: ============================================================
2022-06-28 19:28:00,869: time cost, forward:0.011155987072564318, backward:0.02993329589018124, data cost:0.7132888542626329 
2022-06-28 19:28:00,869: ============================================================
2022-06-28 19:28:00,869: Epoch 12/26 Batch 500/7662 eta: 23:35:37.902265	Training Loss 3.6775 (3.5409)	Training Prec@1 98.828 (98.652)	Training Prec@5 99.219 (99.459)	
2022-06-28 19:28:00,869: ============================================================
2022-06-28 19:29:14,191: time cost, forward:0.011265084023069659, backward:0.03036063421946734, data cost:0.7091429866415033 
2022-06-28 19:29:14,191: ============================================================
2022-06-28 19:29:14,191: Epoch 12/26 Batch 600/7662 eta: 23:17:10.286132	Training Loss 3.6899 (3.5500)	Training Prec@1 98.633 (98.658)	Training Prec@5 99.805 (99.448)	
2022-06-28 19:29:14,192: ============================================================
2022-06-28 19:30:28,184: time cost, forward:0.011327122414060928, backward:0.030508555056199496, data cost:0.7073045619397034 
2022-06-28 19:30:28,184: ============================================================
2022-06-28 19:30:28,184: Epoch 12/26 Batch 700/7662 eta: 23:28:42.665798	Training Loss 3.7453 (3.5636)	Training Prec@1 97.656 (98.647)	Training Prec@5 99.023 (99.443)	
2022-06-28 19:30:28,184: ============================================================
2022-06-28 19:31:41,796: time cost, forward:0.011325122417884416, backward:0.030626977638846194, data cost:0.7055049506534772 
2022-06-28 19:31:41,797: ============================================================
2022-06-28 19:31:41,797: Epoch 12/26 Batch 800/7662 eta: 23:20:14.991709	Training Loss 3.6470 (3.5748)	Training Prec@1 98.438 (98.640)	Training Prec@5 99.414 (99.440)	
2022-06-28 19:31:41,797: ============================================================
2022-06-28 19:32:56,641: time cost, forward:0.011369603361781102, backward:0.03049775039791663, data cost:0.7056488935090809 
2022-06-28 19:32:56,642: ============================================================
2022-06-28 19:32:56,642: Epoch 12/26 Batch 900/7662 eta: 23:42:26.137403	Training Loss 3.6766 (3.5878)	Training Prec@1 98.438 (98.623)	Training Prec@5 99.609 (99.434)	
2022-06-28 19:32:56,642: ============================================================
2022-06-28 19:34:10,651: time cost, forward:0.011454604409478448, backward:0.03053332043362332, data cost:0.7047501502929626 
2022-06-28 19:34:10,652: ============================================================
2022-06-28 19:34:10,652: Epoch 12/26 Batch 1000/7662 eta: 23:25:20.449076	Training Loss 3.5622 (3.5972)	Training Prec@1 98.828 (98.613)	Training Prec@5 99.414 (99.432)	
2022-06-28 19:34:10,652: ============================================================
2022-06-28 19:35:24,827: time cost, forward:0.011517533396893572, backward:0.03054586879983612, data cost:0.7041750221061533 
2022-06-28 19:35:24,827: ============================================================
2022-06-28 19:35:24,827: Epoch 12/26 Batch 1100/7662 eta: 23:27:14.542060	Training Loss 3.9467 (3.6074)	Training Prec@1 97.852 (98.591)	Training Prec@5 99.023 (99.426)	
2022-06-28 19:35:24,827: ============================================================
2022-06-28 19:36:37,822: time cost, forward:0.011491265467945192, backward:0.03063247818266779, data cost:0.7027165796281498 
2022-06-28 19:36:37,822: ============================================================
2022-06-28 19:36:37,823: Epoch 12/26 Batch 1200/7662 eta: 23:03:38.453906	Training Loss 3.8369 (3.6179)	Training Prec@1 98.047 (98.576)	Training Prec@5 99.219 (99.421)	
2022-06-28 19:36:37,823: ============================================================
2022-06-28 19:37:52,199: time cost, forward:0.011552832510216222, backward:0.030686342505145934, data cost:0.7024840904805548 
2022-06-28 19:37:52,199: ============================================================
2022-06-28 19:37:52,199: Epoch 12/26 Batch 1300/7662 eta: 23:28:34.874106	Training Loss 3.6677 (3.6287)	Training Prec@1 100.000 (98.563)	Training Prec@5 100.000 (99.416)	
2022-06-28 19:37:52,199: ============================================================
2022-06-28 19:39:05,640: time cost, forward:0.01159230396524338, backward:0.030647344807371912, data cost:0.7017050150720625 
2022-06-28 19:39:05,641: ============================================================
2022-06-28 19:39:05,641: Epoch 12/26 Batch 1400/7662 eta: 23:09:39.004105	Training Loss 3.7096 (3.6383)	Training Prec@1 97.852 (98.551)	Training Prec@5 99.805 (99.409)	
2022-06-28 19:39:05,641: ============================================================
2022-06-28 19:40:18,887: time cost, forward:0.011589421201658854, backward:0.03058814875200003, data cost:0.700975070562738 
2022-06-28 19:40:18,887: ============================================================
2022-06-28 19:40:18,887: Epoch 12/26 Batch 1500/7662 eta: 23:04:43.839344	Training Loss 3.8457 (3.6478)	Training Prec@1 98.438 (98.539)	Training Prec@5 99.219 (99.406)	
2022-06-28 19:40:18,887: ============================================================
2022-06-28 19:41:32,867: time cost, forward:0.011644138255068628, backward:0.030717782037865005, data cost:0.7005559873252902 
2022-06-28 19:41:32,867: ============================================================
2022-06-28 19:41:32,867: Epoch 12/26 Batch 1600/7662 eta: 23:17:22.802877	Training Loss 3.8394 (3.6556)	Training Prec@1 99.023 (98.530)	Training Prec@5 99.414 (99.399)	
2022-06-28 19:41:32,868: ============================================================
2022-06-28 19:42:46,712: time cost, forward:0.011698907792673453, backward:0.03079308952704256, data cost:0.7001314549112123 
2022-06-28 19:42:46,712: ============================================================
2022-06-28 19:42:46,712: Epoch 12/26 Batch 1700/7662 eta: 23:13:35.082379	Training Loss 3.5564 (3.6638)	Training Prec@1 99.023 (98.521)	Training Prec@5 99.805 (99.394)	
2022-06-28 19:42:46,712: ============================================================
2022-06-28 19:43:59,669: time cost, forward:0.011694023912651397, backward:0.03077817016207158, data cost:0.6993994825478724 
2022-06-28 19:43:59,669: ============================================================
2022-06-28 19:43:59,669: Epoch 12/26 Batch 1800/7662 eta: 22:55:36.824551	Training Loss 3.6767 (3.6699)	Training Prec@1 98.438 (98.513)	Training Prec@5 99.023 (99.388)	
2022-06-28 19:43:59,669: ============================================================
2022-06-28 19:45:13,217: time cost, forward:0.011654893243356779, backward:0.03078271226546462, data cost:0.6990778550403629 
2022-06-28 19:45:13,218: ============================================================
2022-06-28 19:45:13,218: Epoch 12/26 Batch 1900/7662 eta: 23:05:32.918248	Training Loss 3.8575 (3.6776)	Training Prec@1 98.047 (98.501)	Training Prec@5 99.219 (99.382)	
2022-06-28 19:45:13,218: ============================================================
2022-06-28 19:46:26,271: time cost, forward:0.011644507241642671, backward:0.030818209283169418, data cost:0.6984814879535257 
2022-06-28 19:46:26,271: ============================================================
2022-06-28 19:46:26,271: Epoch 12/26 Batch 2000/7662 eta: 22:54:59.858194	Training Loss 3.7165 (3.6850)	Training Prec@1 98.438 (98.489)	Training Prec@5 99.414 (99.376)	
2022-06-28 19:46:26,271: ============================================================
2022-06-28 19:47:40,254: time cost, forward:0.011639330828967918, backward:0.030858412193309245, data cost:0.6983696381894675 
2022-06-28 19:47:40,255: ============================================================
2022-06-28 19:47:40,255: Epoch 12/26 Batch 2100/7662 eta: 23:11:16.367814	Training Loss 3.9429 (3.6911)	Training Prec@1 98.633 (98.478)	Training Prec@5 99.609 (99.371)	
2022-06-28 19:47:40,255: ============================================================
2022-06-28 19:48:54,879: time cost, forward:0.01161638982407664, backward:0.03078257706881979, data cost:0.6986980451242986 
2022-06-28 19:48:54,880: ============================================================
2022-06-28 19:48:54,880: Epoch 12/26 Batch 2200/7662 eta: 23:22:05.524876	Training Loss 3.7692 (3.6978)	Training Prec@1 98.828 (98.466)	Training Prec@5 99.805 (99.365)	
2022-06-28 19:48:54,880: ============================================================
2022-06-28 19:50:08,384: time cost, forward:0.011642068196711928, backward:0.030809678322027537, data cost:0.6983554089468632 
2022-06-28 19:50:08,384: ============================================================
2022-06-28 19:50:08,384: Epoch 12/26 Batch 2300/7662 eta: 22:59:48.768440	Training Loss 4.0444 (3.7033)	Training Prec@1 97.656 (98.454)	Training Prec@5 99.414 (99.360)	
2022-06-28 19:50:08,384: ============================================================
2022-06-28 19:51:22,495: time cost, forward:0.011653349468140565, backward:0.030856937604827054, data cost:0.6982955005378612 
2022-06-28 19:51:22,496: ============================================================
2022-06-28 19:51:22,496: Epoch 12/26 Batch 2400/7662 eta: 23:09:58.795754	Training Loss 3.8478 (3.7088)	Training Prec@1 98.633 (98.444)	Training Prec@5 99.023 (99.354)	
2022-06-28 19:51:22,496: ============================================================
2022-06-28 19:52:36,148: time cost, forward:0.011676386767933492, backward:0.030834743908855045, data cost:0.6981006203865519 
2022-06-28 19:52:36,148: ============================================================
2022-06-28 19:52:36,149: Epoch 12/26 Batch 2500/7662 eta: 23:00:08.196341	Training Loss 3.9155 (3.7140)	Training Prec@1 97.461 (98.435)	Training Prec@5 98.633 (99.350)	
2022-06-28 19:52:36,149: ============================================================
2022-06-28 19:53:50,051: time cost, forward:0.011700448186271875, backward:0.030740989543420163, data cost:0.6980908566504637 
2022-06-28 19:53:50,052: ============================================================
2022-06-28 19:53:50,052: Epoch 12/26 Batch 2600/7662 eta: 23:03:36.391233	Training Loss 4.0373 (3.7192)	Training Prec@1 98.047 (98.428)	Training Prec@5 99.219 (99.348)	
2022-06-28 19:53:50,052: ============================================================
2022-06-28 19:55:04,562: time cost, forward:0.011686143366307319, backward:0.030759069998205126, data cost:0.6982361333111384 
2022-06-28 19:55:04,562: ============================================================
2022-06-28 19:55:04,562: Epoch 12/26 Batch 2700/7662 eta: 23:13:43.690292	Training Loss 3.8620 (3.7252)	Training Prec@1 98.047 (98.418)	Training Prec@5 99.609 (99.342)	
2022-06-28 19:55:04,562: ============================================================
2022-06-28 19:56:18,004: time cost, forward:0.01169337209270187, backward:0.0308012897604574, data cost:0.6979505589026219 
2022-06-28 19:56:18,004: ============================================================
2022-06-28 19:56:18,005: Epoch 12/26 Batch 2800/7662 eta: 22:52:31.813813	Training Loss 3.8688 (3.7293)	Training Prec@1 97.656 (98.410)	Training Prec@5 99.414 (99.341)	
2022-06-28 19:56:18,005: ============================================================
2022-06-28 19:57:33,022: time cost, forward:0.011722135313546588, backward:0.03087319625414993, data cost:0.698169065780087 
2022-06-28 19:57:33,023: ============================================================
2022-06-28 19:57:33,023: Epoch 12/26 Batch 2900/7662 eta: 23:20:43.694309	Training Loss 4.0328 (3.7344)	Training Prec@1 98.242 (98.399)	Training Prec@5 98.828 (99.336)	
2022-06-28 19:57:33,023: ============================================================
2022-06-28 19:58:47,306: time cost, forward:0.011733946382065303, backward:0.03094158080388165, data cost:0.6981406067959187 
2022-06-28 19:58:47,307: ============================================================
2022-06-28 19:58:47,307: Epoch 12/26 Batch 3000/7662 eta: 23:05:46.576567	Training Loss 3.6984 (3.7396)	Training Prec@1 99.023 (98.390)	Training Prec@5 99.805 (99.333)	
2022-06-28 19:58:47,307: ============================================================
2022-06-28 20:00:02,503: time cost, forward:0.011733905312783413, backward:0.030934159084072647, data cost:0.6984916607308057 
2022-06-28 20:00:02,503: ============================================================
2022-06-28 20:00:02,503: Epoch 12/26 Batch 3100/7662 eta: 23:21:33.124633	Training Loss 3.7003 (3.7450)	Training Prec@1 98.047 (98.377)	Training Prec@5 99.219 (99.327)	
2022-06-28 20:00:02,503: ============================================================
2022-06-28 20:01:17,229: time cost, forward:0.0117464203430586, backward:0.03098016457469734, data cost:0.6986099000497324 
2022-06-28 20:01:17,230: ============================================================
2022-06-28 20:01:17,230: Epoch 12/26 Batch 3200/7662 eta: 23:11:32.616472	Training Loss 3.8659 (3.7494)	Training Prec@1 97.461 (98.370)	Training Prec@5 99.219 (99.324)	
2022-06-28 20:01:17,230: ============================================================
2022-06-28 20:02:31,565: time cost, forward:0.011757839878749472, backward:0.031026506250502305, data cost:0.6985986607115932 
2022-06-28 20:02:31,565: ============================================================
2022-06-28 20:02:31,566: Epoch 12/26 Batch 3300/7662 eta: 23:03:01.690895	Training Loss 4.0099 (3.7541)	Training Prec@1 97.656 (98.360)	Training Prec@5 99.609 (99.321)	
2022-06-28 20:02:31,566: ============================================================
2022-06-28 20:03:45,175: time cost, forward:0.011739492837244288, backward:0.031019633501619057, data cost:0.6984536024218765 
2022-06-28 20:03:45,176: ============================================================
2022-06-28 20:03:45,176: Epoch 12/26 Batch 3400/7662 eta: 22:48:18.246594	Training Loss 3.8414 (3.7580)	Training Prec@1 99.023 (98.353)	Training Prec@5 99.414 (99.318)	
2022-06-28 20:03:45,176: ============================================================
2022-06-28 20:05:00,397: time cost, forward:0.011750989520369206, backward:0.031022051873633643, data cost:0.6987424656540095 
2022-06-28 20:05:00,397: ============================================================
2022-06-28 20:05:00,397: Epoch 12/26 Batch 3500/7662 eta: 23:16:59.947367	Training Loss 3.7944 (3.7622)	Training Prec@1 97.852 (98.345)	Training Prec@5 98.438 (99.316)	
2022-06-28 20:05:00,397: ============================================================
2022-06-28 20:06:14,178: time cost, forward:0.01175727377867957, backward:0.031050617544476806, data cost:0.6985915472322651 
2022-06-28 20:06:14,179: ============================================================
2022-06-28 20:06:14,179: Epoch 12/26 Batch 3600/7662 eta: 22:49:01.872194	Training Loss 4.0170 (3.7663)	Training Prec@1 98.242 (98.337)	Training Prec@5 99.023 (99.314)	
2022-06-28 20:06:14,179: ============================================================
2022-06-28 20:07:27,919: time cost, forward:0.011772920647709071, backward:0.031044501489998683, data cost:0.6984617249261176 
2022-06-28 20:07:27,919: ============================================================
2022-06-28 20:07:27,920: Epoch 12/26 Batch 3700/7662 eta: 22:47:02.569207	Training Loss 4.1646 (3.7705)	Training Prec@1 98.047 (98.326)	Training Prec@5 99.023 (99.310)	
2022-06-28 20:07:27,920: ============================================================
2022-06-28 20:08:42,420: time cost, forward:0.011785680352151, backward:0.03105487620149609, data cost:0.69852489840203 
2022-06-28 20:08:42,420: ============================================================
2022-06-28 20:08:42,420: Epoch 12/26 Batch 3800/7662 eta: 22:59:53.397555	Training Loss 3.8227 (3.7745)	Training Prec@1 98.828 (98.319)	Training Prec@5 99.414 (99.307)	
2022-06-28 20:08:42,420: ============================================================
2022-06-28 20:09:57,156: time cost, forward:0.01180030541959314, backward:0.031028179487652522, data cost:0.6986754357004569 
2022-06-28 20:09:57,156: ============================================================
2022-06-28 20:09:57,157: Epoch 12/26 Batch 3900/7662 eta: 23:03:00.391358	Training Loss 3.9416 (3.7777)	Training Prec@1 98.242 (98.313)	Training Prec@5 99.219 (99.304)	
2022-06-28 20:09:57,157: ============================================================
2022-06-28 20:11:11,645: time cost, forward:0.01179962856944247, backward:0.031023723776860964, data cost:0.6987546965848747 
2022-06-28 20:11:11,645: ============================================================
2022-06-28 20:11:11,645: Epoch 12/26 Batch 4000/7662 eta: 22:57:11.312015	Training Loss 3.9140 (3.7807)	Training Prec@1 98.633 (98.304)	Training Prec@5 99.219 (99.301)	
2022-06-28 20:11:11,646: ============================================================
2022-06-28 20:12:27,324: time cost, forward:0.011817846277278351, backward:0.031015775703342695, data cost:0.6991032102277263 
2022-06-28 20:12:27,324: ============================================================
2022-06-28 20:12:27,325: Epoch 12/26 Batch 4100/7662 eta: 23:17:55.945376	Training Loss 4.1880 (3.7842)	Training Prec@1 97.266 (98.297)	Training Prec@5 98.438 (99.297)	
2022-06-28 20:12:27,325: ============================================================
2022-06-28 20:13:41,326: time cost, forward:0.011826280299525342, backward:0.031007090362090955, data cost:0.6990483897332493 
2022-06-28 20:13:41,327: ============================================================
2022-06-28 20:13:41,327: Epoch 12/26 Batch 4200/7662 eta: 22:45:43.348502	Training Loss 3.8117 (3.7873)	Training Prec@1 97.656 (98.291)	Training Prec@5 99.219 (99.296)	
2022-06-28 20:13:41,327: ============================================================
2022-06-28 20:14:56,057: time cost, forward:0.011849869459444601, backward:0.03101734422921968, data cost:0.6991317572774486 
2022-06-28 20:14:56,057: ============================================================
2022-06-28 20:14:56,057: Epoch 12/26 Batch 4300/7662 eta: 22:57:55.071741	Training Loss 3.8146 (3.7897)	Training Prec@1 98.828 (98.287)	Training Prec@5 99.609 (99.293)	
2022-06-28 20:14:56,057: ============================================================
2022-06-28 20:16:10,189: time cost, forward:0.011838753403899723, backward:0.030959177353241735, data cost:0.6991740127779403 
2022-06-28 20:16:10,189: ============================================================
2022-06-28 20:16:10,189: Epoch 12/26 Batch 4400/7662 eta: 22:45:38.643241	Training Loss 3.6867 (3.7922)	Training Prec@1 98.438 (98.281)	Training Prec@5 99.609 (99.290)	
2022-06-28 20:16:10,189: ============================================================
2022-06-28 20:17:26,189: time cost, forward:0.01185792280478222, backward:0.030979040120013106, data cost:0.6995257562890427 
2022-06-28 20:17:26,189: ============================================================
2022-06-28 20:17:26,190: Epoch 12/26 Batch 4500/7662 eta: 23:18:48.105533	Training Loss 3.7981 (3.7949)	Training Prec@1 98.438 (98.274)	Training Prec@5 99.219 (99.286)	
2022-06-28 20:17:26,190: ============================================================
2022-06-28 20:18:41,585: time cost, forward:0.01188334684627008, backward:0.031034428286899767, data cost:0.6996853710335477 
2022-06-28 20:18:41,586: ============================================================
2022-06-28 20:18:41,586: Epoch 12/26 Batch 4600/7662 eta: 23:06:25.485788	Training Loss 4.2587 (3.7979)	Training Prec@1 96.680 (98.266)	Training Prec@5 99.219 (99.282)	
2022-06-28 20:18:41,586: ============================================================
2022-06-28 20:19:56,221: time cost, forward:0.011869113834443614, backward:0.03103339502115812, data cost:0.6997703305963101 
2022-06-28 20:19:56,222: ============================================================
2022-06-28 20:19:56,222: Epoch 12/26 Batch 4700/7662 eta: 22:51:11.739951	Training Loss 3.8548 (3.8003)	Training Prec@1 98.047 (98.263)	Training Prec@5 99.219 (99.279)	
2022-06-28 20:19:56,222: ============================================================
2022-06-28 20:21:10,945: time cost, forward:0.01186849574641303, backward:0.03105096862723018, data cost:0.6998384174244382 
2022-06-28 20:21:10,946: ============================================================
2022-06-28 20:21:10,946: Epoch 12/26 Batch 4800/7662 eta: 22:51:34.478255	Training Loss 3.7676 (3.8028)	Training Prec@1 98.242 (98.257)	Training Prec@5 98.633 (99.276)	
2022-06-28 20:21:10,946: ============================================================
2022-06-28 20:22:24,878: time cost, forward:0.011857162229526673, backward:0.031059561760772562, data cost:0.699762265082159 
2022-06-28 20:22:24,878: ============================================================
2022-06-28 20:22:24,879: Epoch 12/26 Batch 4900/7662 eta: 22:35:48.871734	Training Loss 3.9935 (3.8056)	Training Prec@1 99.414 (98.250)	Training Prec@5 99.609 (99.272)	
2022-06-28 20:22:24,879: ============================================================
2022-06-28 20:23:38,886: time cost, forward:0.011870929731753235, backward:0.031074630758671267, data cost:0.6996715967358053 
2022-06-28 20:23:38,886: ============================================================
2022-06-28 20:23:38,887: Epoch 12/26 Batch 5000/7662 eta: 22:35:57.677754	Training Loss 3.7587 (3.8080)	Training Prec@1 98.633 (98.243)	Training Prec@5 99.414 (99.269)	
2022-06-28 20:23:38,887: ============================================================
2022-06-28 20:24:54,043: time cost, forward:0.011866606878612435, backward:0.031087479841056864, data cost:0.6998296200141975 
2022-06-28 20:24:54,043: ============================================================
2022-06-28 20:24:54,044: Epoch 12/26 Batch 5100/7662 eta: 22:55:45.648343	Training Loss 3.7395 (3.8103)	Training Prec@1 99.219 (98.237)	Training Prec@5 99.805 (99.268)	
2022-06-28 20:24:54,044: ============================================================
2022-06-28 20:26:08,963: time cost, forward:0.011876828488443283, backward:0.031114690738082918, data cost:0.6999045178669648 
2022-06-28 20:26:08,963: ============================================================
2022-06-28 20:26:08,963: Epoch 12/26 Batch 5200/7662 eta: 22:50:10.317207	Training Loss 4.0194 (3.8126)	Training Prec@1 98.047 (98.231)	Training Prec@5 98.828 (99.265)	
2022-06-28 20:26:08,964: ============================================================
2022-06-28 20:27:25,321: time cost, forward:0.011891570624866043, backward:0.03112349062061328, data cost:0.7002626434095087 
2022-06-28 20:27:25,322: ============================================================
2022-06-28 20:27:25,322: Epoch 12/26 Batch 5300/7662 eta: 23:15:13.090558	Training Loss 3.9696 (3.8152)	Training Prec@1 97.070 (98.223)	Training Prec@5 98.633 (99.261)	
2022-06-28 20:27:25,323: ============================================================
2022-06-28 20:28:40,829: time cost, forward:0.011905154512422706, backward:0.031145513929864126, data cost:0.7004362871347036 
2022-06-28 20:28:40,830: ============================================================
2022-06-28 20:28:40,830: Epoch 12/26 Batch 5400/7662 eta: 22:58:24.092593	Training Loss 3.7578 (3.8173)	Training Prec@1 98.438 (98.216)	Training Prec@5 99.609 (99.259)	
2022-06-28 20:28:40,830: ============================================================
2022-06-28 20:29:56,346: time cost, forward:0.011911079870134858, backward:0.03115744373108565, data cost:0.7006227102988979 
2022-06-28 20:29:56,347: ============================================================
2022-06-28 20:29:56,347: Epoch 12/26 Batch 5500/7662 eta: 22:57:19.279827	Training Loss 4.1141 (3.8195)	Training Prec@1 97.656 (98.213)	Training Prec@5 98.828 (99.258)	
2022-06-28 20:29:56,347: ============================================================
2022-06-28 20:31:10,339: time cost, forward:0.01190049551622977, backward:0.031146648249938715, data cost:0.700568117484767 
2022-06-28 20:31:10,339: ============================================================
2022-06-28 20:31:10,339: Epoch 12/26 Batch 5600/7662 eta: 22:28:16.626598	Training Loss 4.2060 (3.8212)	Training Prec@1 97.266 (98.206)	Training Prec@5 98.633 (99.254)	
2022-06-28 20:31:10,340: ============================================================
2022-06-28 20:32:25,818: time cost, forward:0.011895602994852891, backward:0.03112593732982126, data cost:0.7007843938537346 
2022-06-28 20:32:25,818: ============================================================
2022-06-28 20:32:25,819: Epoch 12/26 Batch 5700/7662 eta: 22:54:06.657223	Training Loss 3.9976 (3.8235)	Training Prec@1 97.656 (98.202)	Training Prec@5 99.219 (99.253)	
2022-06-28 20:32:25,819: ============================================================
2022-06-28 20:33:39,811: time cost, forward:0.011900679821350551, backward:0.031115199516797646, data cost:0.7007138541616804 
2022-06-28 20:33:39,811: ============================================================
2022-06-28 20:33:39,811: Epoch 12/26 Batch 5800/7662 eta: 22:25:48.990198	Training Loss 4.0560 (3.8256)	Training Prec@1 97.852 (98.197)	Training Prec@5 99.219 (99.251)	
2022-06-28 20:33:39,811: ============================================================
2022-06-28 20:34:53,836: time cost, forward:0.011897164091131894, backward:0.031059279848426293, data cost:0.7007074759438555 
2022-06-28 20:34:53,836: ============================================================
2022-06-28 20:34:53,837: Epoch 12/26 Batch 5900/7662 eta: 22:25:10.417512	Training Loss 3.7708 (3.8270)	Training Prec@1 97.852 (98.193)	Training Prec@5 98.828 (99.248)	
2022-06-28 20:34:53,837: ============================================================
2022-06-28 20:36:10,078: time cost, forward:0.011902478083429147, backward:0.031066879468632652, data cost:0.7009994628767626 
2022-06-28 20:36:10,078: ============================================================
2022-06-28 20:36:10,079: Epoch 12/26 Batch 6000/7662 eta: 23:04:11.164562	Training Loss 4.0568 (3.8289)	Training Prec@1 97.656 (98.188)	Training Prec@5 99.023 (99.245)	
2022-06-28 20:36:10,079: ============================================================
2022-06-28 20:37:24,677: time cost, forward:0.01191925318402567, backward:0.031072125784352797, data cost:0.7010023394927253 
2022-06-28 20:37:24,677: ============================================================
2022-06-28 20:37:24,677: Epoch 12/26 Batch 6100/7662 eta: 22:33:06.564699	Training Loss 3.9016 (3.8308)	Training Prec@1 98.242 (98.182)	Training Prec@5 99.219 (99.242)	
2022-06-28 20:37:24,677: ============================================================
2022-06-28 20:38:39,464: time cost, forward:0.011919321946933166, backward:0.03107518922092261, data cost:0.7010513331202042 
2022-06-28 20:38:39,464: ============================================================
2022-06-28 20:38:39,465: Epoch 12/26 Batch 6200/7662 eta: 22:35:16.912141	Training Loss 4.0398 (3.8326)	Training Prec@1 98.242 (98.178)	Training Prec@5 99.219 (99.240)	
2022-06-28 20:38:39,465: ============================================================
2022-06-28 20:39:54,052: time cost, forward:0.011921509009805023, backward:0.031072271118127725, data cost:0.7010728768610466 
2022-06-28 20:39:54,052: ============================================================
2022-06-28 20:39:54,052: Epoch 12/26 Batch 6300/7662 eta: 22:30:25.179085	Training Loss 4.0596 (3.8344)	Training Prec@1 97.852 (98.171)	Training Prec@5 99.023 (99.237)	
2022-06-28 20:39:54,052: ============================================================
2022-06-28 20:41:10,086: time cost, forward:0.011927774798629769, backward:0.031070626625923053, data cost:0.7013145101538001 
2022-06-28 20:41:10,087: ============================================================
2022-06-28 20:41:10,087: Epoch 12/26 Batch 6400/7662 eta: 22:55:21.160652	Training Loss 4.0278 (3.8358)	Training Prec@1 98.438 (98.166)	Training Prec@5 99.023 (99.234)	
2022-06-28 20:41:10,087: ============================================================
2022-06-28 20:42:25,135: time cost, forward:0.011923204258526814, backward:0.03106186165775147, data cost:0.7014181050433986 
2022-06-28 20:42:25,135: ============================================================
2022-06-28 20:42:25,135: Epoch 12/26 Batch 6500/7662 eta: 22:36:15.801874	Training Loss 3.8804 (3.8371)	Training Prec@1 98.242 (98.163)	Training Prec@5 99.219 (99.233)	
2022-06-28 20:42:25,135: ============================================================
2022-06-28 20:43:41,092: time cost, forward:0.011925334947762083, backward:0.03105596969264586, data cost:0.7016431471311173 
2022-06-28 20:43:41,092: ============================================================
2022-06-28 20:43:41,093: Epoch 12/26 Batch 6600/7662 eta: 22:51:25.447244	Training Loss 4.0435 (3.8390)	Training Prec@1 96.680 (98.157)	Training Prec@5 98.438 (99.231)	
2022-06-28 20:43:41,093: ============================================================
2022-06-28 20:44:55,769: time cost, forward:0.011930684399864605, backward:0.031061751074818716, data cost:0.7016575591993752 
2022-06-28 20:44:55,769: ============================================================
2022-06-28 20:44:55,769: Epoch 12/26 Batch 6700/7662 eta: 22:27:03.159188	Training Loss 3.7732 (3.8404)	Training Prec@1 99.023 (98.154)	Training Prec@5 99.609 (99.229)	
2022-06-28 20:44:55,769: ============================================================
2022-06-28 20:46:12,751: time cost, forward:0.011945548171873635, backward:0.031071830276251364, data cost:0.7019969091150301 
2022-06-28 20:46:12,752: ============================================================
2022-06-28 20:46:12,752: Epoch 12/26 Batch 6800/7662 eta: 23:07:22.139222	Training Loss 4.0367 (3.8420)	Training Prec@1 98.047 (98.149)	Training Prec@5 99.414 (99.227)	
2022-06-28 20:46:12,752: ============================================================
2022-06-28 20:47:28,551: time cost, forward:0.011948861666633904, backward:0.031069911412699255, data cost:0.7021771160860583 
2022-06-28 20:47:28,552: ============================================================
2022-06-28 20:47:28,552: Epoch 12/26 Batch 6900/7662 eta: 22:44:47.345727	Training Loss 3.9191 (3.8435)	Training Prec@1 96.875 (98.144)	Training Prec@5 99.023 (99.224)	
2022-06-28 20:47:28,552: ============================================================
2022-06-28 20:48:43,710: time cost, forward:0.011944812610330266, backward:0.031064180258870686, data cost:0.7022696069043471 
2022-06-28 20:48:43,711: ============================================================
2022-06-28 20:48:43,711: Epoch 12/26 Batch 7000/7662 eta: 22:31:59.882848	Training Loss 3.8075 (3.8451)	Training Prec@1 98.828 (98.140)	Training Prec@5 99.219 (99.222)	
2022-06-28 20:48:43,711: ============================================================
2022-06-28 20:49:59,977: time cost, forward:0.011958889296935098, backward:0.031069288658145313, data cost:0.702489732335799 
2022-06-28 20:49:59,977: ============================================================
2022-06-28 20:49:59,978: Epoch 12/26 Batch 7100/7662 eta: 22:50:39.171275	Training Loss 3.9361 (3.8465)	Training Prec@1 97.266 (98.137)	Training Prec@5 98.633 (99.220)	
2022-06-28 20:49:59,978: ============================================================
2022-06-28 20:51:15,280: time cost, forward:0.011959997510426507, backward:0.03103761501420884, data cost:0.7026177968792094 
2022-06-28 20:51:15,280: ============================================================
2022-06-28 20:51:15,281: Epoch 12/26 Batch 7200/7662 eta: 22:32:04.879868	Training Loss 3.9963 (3.8480)	Training Prec@1 97.266 (98.132)	Training Prec@5 98.828 (99.219)	
2022-06-28 20:51:15,281: ============================================================
2022-06-28 20:52:30,856: time cost, forward:0.011956514732725637, backward:0.031037721230177246, data cost:0.7027548508278915 
2022-06-28 20:52:30,857: ============================================================
2022-06-28 20:52:30,857: Epoch 12/26 Batch 7300/7662 eta: 22:35:43.201967	Training Loss 3.9687 (3.8495)	Training Prec@1 98.047 (98.127)	Training Prec@5 99.609 (99.216)	
2022-06-28 20:52:30,857: ============================================================
2022-06-28 20:53:46,519: time cost, forward:0.011959760700436698, backward:0.03102701096006915, data cost:0.7029007979866169 
2022-06-28 20:53:46,519: ============================================================
2022-06-28 20:53:46,520: Epoch 12/26 Batch 7400/7662 eta: 22:36:01.105015	Training Loss 3.8800 (3.8508)	Training Prec@1 97.461 (98.123)	Training Prec@5 98.438 (99.214)	
2022-06-28 20:53:46,520: ============================================================
2022-06-28 20:55:02,384: time cost, forward:0.011960209965912528, backward:0.03102315742344137, data cost:0.7030688350813311 
2022-06-28 20:55:02,384: ============================================================
2022-06-28 20:55:02,385: Epoch 12/26 Batch 7500/7662 eta: 22:38:22.518427	Training Loss 4.0467 (3.8521)	Training Prec@1 97.266 (98.119)	Training Prec@5 98.633 (99.211)	
2022-06-28 20:55:02,385: ============================================================
2022-06-28 20:56:17,089: time cost, forward:0.011955582573156888, backward:0.03102110533168997, data cost:0.7030832214031679 
2022-06-28 20:56:17,089: ============================================================
2022-06-28 20:56:17,089: Epoch 12/26 Batch 7600/7662 eta: 22:16:21.399046	Training Loss 4.1508 (3.8534)	Training Prec@1 96.680 (98.116)	Training Prec@5 98.633 (99.211)	
2022-06-28 20:56:17,090: ============================================================
2022-06-28 20:57:06,132: Epoch: 12/26 eta: 22:15:34.335028	Training Loss 3.9245 (3.8543)	Training Prec@1 98.633 (98.114)	Training Prec@5 99.023 (99.210)
2022-06-28 20:57:06,133: ============================================================
2022-06-28 20:58:25,611: time cost, forward:0.011694924999969174, backward:0.02899881083555896, data cost:0.7553590837151113 
2022-06-28 20:58:25,612: ============================================================
2022-06-28 20:58:25,612: Epoch 13/26 Batch 100/7662 eta: 23:36:45.737598	Training Loss 3.1534 (3.4526)	Training Prec@1 99.219 (98.789)	Training Prec@5 99.805 (99.525)	
2022-06-28 20:58:25,612: ============================================================
2022-06-28 20:59:42,274: time cost, forward:0.011347486745173009, backward:0.028883581784502347, data cost:0.7407985332623199 
2022-06-28 20:59:42,274: ============================================================
2022-06-28 20:59:42,275: Epoch 13/26 Batch 200/7662 eta: 22:48:01.774320	Training Loss 3.5367 (3.4604)	Training Prec@1 98.047 (98.734)	Training Prec@5 99.219 (99.515)	
2022-06-28 20:59:42,275: ============================================================
2022-06-28 21:00:55,862: time cost, forward:0.01160699467993899, backward:0.0293080168822936, data cost:0.7248590239713024 
2022-06-28 21:00:55,862: ============================================================
2022-06-28 21:00:55,863: Epoch 13/26 Batch 300/7662 eta: 21:51:56.500039	Training Loss 3.3785 (3.4704)	Training Prec@1 99.023 (98.705)	Training Prec@5 99.609 (99.509)	
2022-06-28 21:00:55,863: ============================================================
2022-06-28 21:02:08,420: time cost, forward:0.01155226571219308, backward:0.02940395780673302, data cost:0.7146164002573878 
2022-06-28 21:02:08,421: ============================================================
2022-06-28 21:02:08,421: Epoch 13/26 Batch 400/7662 eta: 21:32:22.245564	Training Loss 3.4477 (3.4790)	Training Prec@1 98.438 (98.719)	Training Prec@5 99.414 (99.517)	
2022-06-28 21:02:08,421: ============================================================
2022-06-28 21:03:21,712: time cost, forward:0.011426628949885855, backward:0.02862293782358418, data cost:0.7108871071993229 
2022-06-28 21:03:21,712: ============================================================
2022-06-28 21:03:21,712: Epoch 13/26 Batch 500/7662 eta: 21:44:12.613188	Training Loss 3.6079 (3.4988)	Training Prec@1 99.219 (98.690)	Training Prec@5 99.609 (99.501)	
2022-06-28 21:03:21,712: ============================================================
2022-06-28 21:04:34,048: time cost, forward:0.011452305496037504, backward:0.02851615047614045, data cost:0.7063021759357994 
2022-06-28 21:04:34,048: ============================================================
2022-06-28 21:04:34,048: Epoch 13/26 Batch 600/7662 eta: 21:25:59.777026	Training Loss 3.5077 (3.5133)	Training Prec@1 97.656 (98.676)	Training Prec@5 99.219 (99.490)	
2022-06-28 21:04:34,048: ============================================================
2022-06-28 21:05:49,764: time cost, forward:0.011527052935271474, backward:0.028720769759411464, data cost:0.7075103823207479 
2022-06-28 21:05:49,765: ============================================================
2022-06-28 21:05:49,765: Epoch 13/26 Batch 700/7662 eta: 22:24:50.736672	Training Loss 3.6543 (3.5260)	Training Prec@1 98.047 (98.664)	Training Prec@5 98.828 (99.492)	
2022-06-28 21:05:49,765: ============================================================
2022-06-28 21:07:03,654: time cost, forward:0.011512488089455233, backward:0.029105565723996883, data cost:0.7059917748347391 
2022-06-28 21:07:03,654: ============================================================
2022-06-28 21:07:03,655: Epoch 13/26 Batch 800/7662 eta: 21:51:09.612187	Training Loss 3.5914 (3.5377)	Training Prec@1 99.023 (98.658)	Training Prec@5 99.805 (99.485)	
2022-06-28 21:07:03,655: ============================================================
2022-06-28 21:08:17,055: time cost, forward:0.011468177642652535, backward:0.029391428785143756, data cost:0.7042834498858426 
2022-06-28 21:08:17,055: ============================================================
2022-06-28 21:08:17,055: Epoch 13/26 Batch 900/7662 eta: 21:41:15.555684	Training Loss 3.6344 (3.5501)	Training Prec@1 99.023 (98.647)	Training Prec@5 100.000 (99.480)	
2022-06-28 21:08:17,056: ============================================================
2022-06-28 21:09:31,301: time cost, forward:0.011429232520026129, backward:0.029612764343246445, data cost:0.703791308331418 
2022-06-28 21:09:31,301: ============================================================
2022-06-28 21:09:31,301: Epoch 13/26 Batch 1000/7662 eta: 21:55:00.601383	Training Loss 3.5034 (3.5609)	Training Prec@1 98.438 (98.636)	Training Prec@5 99.609 (99.475)	
2022-06-28 21:09:31,301: ============================================================
2022-06-28 21:10:44,588: time cost, forward:0.01142615920527617, backward:0.02975047556674947, data cost:0.7025392578340206 
2022-06-28 21:10:44,588: ============================================================
2022-06-28 21:10:44,588: Epoch 13/26 Batch 1100/7662 eta: 21:36:48.158499	Training Loss 4.0169 (3.5724)	Training Prec@1 97.461 (98.619)	Training Prec@5 99.023 (99.464)	
2022-06-28 21:10:44,589: ============================================================
2022-06-28 21:11:58,712: time cost, forward:0.011434019357587418, backward:0.029800196505268977, data cost:0.7022202609478184 
2022-06-28 21:11:58,712: ============================================================
2022-06-28 21:11:58,713: Epoch 13/26 Batch 1200/7662 eta: 21:50:22.607891	Training Loss 3.5459 (3.5823)	Training Prec@1 99.219 (98.610)	Training Prec@5 99.414 (99.459)	
2022-06-28 21:11:58,713: ============================================================
2022-06-28 21:13:11,871: time cost, forward:0.011450584160538249, backward:0.02993759510607055, data cost:0.701119081344487 
2022-06-28 21:13:11,872: ============================================================
2022-06-28 21:13:11,872: Epoch 13/26 Batch 1300/7662 eta: 21:32:06.074114	Training Loss 3.7610 (3.5931)	Training Prec@1 98.633 (98.588)	Training Prec@5 99.805 (99.447)	
2022-06-28 21:13:11,872: ============================================================
2022-06-28 21:14:26,184: time cost, forward:0.011483361842037526, backward:0.030138154128690205, data cost:0.7009046318021478 
2022-06-28 21:14:26,184: ============================================================
2022-06-28 21:14:26,185: Epoch 13/26 Batch 1400/7662 eta: 21:51:14.227498	Training Loss 3.6246 (3.6019)	Training Prec@1 98.047 (98.576)	Training Prec@5 99.414 (99.444)	
2022-06-28 21:14:26,185: ============================================================
2022-06-28 21:15:38,334: time cost, forward:0.011439777995205626, backward:0.030108168572088017, data cost:0.6995403405584598 
2022-06-28 21:15:38,334: ============================================================
2022-06-28 21:15:38,334: Epoch 13/26 Batch 1500/7662 eta: 21:11:52.260471	Training Loss 3.4930 (3.6102)	Training Prec@1 98.633 (98.565)	Training Prec@5 99.023 (99.438)	
2022-06-28 21:15:38,335: ============================================================
2022-06-28 21:16:51,990: time cost, forward:0.011434662409168694, backward:0.030196272484431644, data cost:0.6991495716340695 
2022-06-28 21:16:51,991: ============================================================
2022-06-28 21:16:51,991: Epoch 13/26 Batch 1600/7662 eta: 21:37:12.100696	Training Loss 3.7991 (3.6205)	Training Prec@1 98.242 (98.548)	Training Prec@5 99.023 (99.429)	
2022-06-28 21:16:51,991: ============================================================
2022-06-28 21:18:07,097: time cost, forward:0.01146280519958101, backward:0.03025338283491668, data cost:0.6996394353027973 
2022-06-28 21:18:07,098: ============================================================
2022-06-28 21:18:07,098: Epoch 13/26 Batch 1700/7662 eta: 22:01:29.590400	Training Loss 3.7613 (3.6271)	Training Prec@1 98.047 (98.538)	Training Prec@5 99.023 (99.422)	
2022-06-28 21:18:07,098: ============================================================
2022-06-28 21:19:21,506: time cost, forward:0.011486607435479834, backward:0.030324882901728717, data cost:0.6996666179092942 
2022-06-28 21:19:21,506: ============================================================
2022-06-28 21:19:21,506: Epoch 13/26 Batch 1800/7662 eta: 21:47:57.521621	Training Loss 3.7257 (3.6344)	Training Prec@1 98.438 (98.529)	Training Prec@5 99.219 (99.419)	
2022-06-28 21:19:21,506: ============================================================
2022-06-28 21:20:34,936: time cost, forward:0.01148005370531288, backward:0.030395127648488666, data cost:0.6992079144468303 
2022-06-28 21:20:34,937: ============================================================
2022-06-28 21:20:34,937: Epoch 13/26 Batch 1900/7662 eta: 21:29:33.367440	Training Loss 3.6950 (3.6427)	Training Prec@1 99.023 (98.516)	Training Prec@5 100.000 (99.412)	
2022-06-28 21:20:34,937: ============================================================
2022-06-28 21:21:49,380: time cost, forward:0.011473131752300405, backward:0.03052640736490682, data cost:0.699221468615854 
2022-06-28 21:21:49,381: ============================================================
2022-06-28 21:21:49,381: Epoch 13/26 Batch 2000/7662 eta: 21:46:06.475197	Training Loss 3.9196 (3.6494)	Training Prec@1 96.484 (98.510)	Training Prec@5 98.828 (99.408)	
2022-06-28 21:21:49,381: ============================================================
2022-06-28 21:23:03,203: time cost, forward:0.011479641040658429, backward:0.03064196038212079, data cost:0.6989424952215783 
2022-06-28 21:23:03,203: ============================================================
2022-06-28 21:23:03,204: Epoch 13/26 Batch 2100/7662 eta: 21:33:58.630492	Training Loss 4.0083 (3.6558)	Training Prec@1 97.461 (98.502)	Training Prec@5 99.219 (99.402)	
2022-06-28 21:23:03,204: ============================================================
2022-06-28 21:24:16,931: time cost, forward:0.011470690051118261, backward:0.0307191939395143, data cost:0.6986739325382428 
2022-06-28 21:24:16,931: ============================================================
2022-06-28 21:24:16,931: Epoch 13/26 Batch 2200/7662 eta: 21:31:05.059814	Training Loss 3.6853 (3.6620)	Training Prec@1 97.656 (98.490)	Training Prec@5 98.828 (99.396)	
2022-06-28 21:24:16,932: ============================================================
2022-06-28 21:25:29,703: time cost, forward:0.011481891460344033, backward:0.030795586840284033, data cost:0.6979949313591438 
2022-06-28 21:25:29,703: ============================================================
2022-06-28 21:25:29,703: Epoch 13/26 Batch 2300/7662 eta: 21:13:08.056525	Training Loss 3.7277 (3.6679)	Training Prec@1 98.242 (98.478)	Training Prec@5 99.219 (99.391)	
2022-06-28 21:25:29,704: ============================================================
2022-06-28 21:26:43,787: time cost, forward:0.011482342326079571, backward:0.030808355471351436, data cost:0.6979863447862746 
2022-06-28 21:26:43,787: ============================================================
2022-06-28 21:26:43,787: Epoch 13/26 Batch 2400/7662 eta: 21:34:50.750783	Training Loss 3.9037 (3.6737)	Training Prec@1 97.461 (98.469)	Training Prec@5 98.828 (99.385)	
2022-06-28 21:26:43,787: ============================================================
2022-06-28 21:27:58,287: time cost, forward:0.011501639783263158, backward:0.030781567502183978, data cost:0.6981627411630545 
2022-06-28 21:27:58,287: ============================================================
2022-06-28 21:27:58,288: Epoch 13/26 Batch 2500/7662 eta: 21:40:53.447541	Training Loss 3.8820 (3.6799)	Training Prec@1 97.461 (98.457)	Training Prec@5 99.219 (99.378)	
2022-06-28 21:27:58,288: ============================================================
2022-06-28 21:29:12,310: time cost, forward:0.01150650068079797, backward:0.03072458471229967, data cost:0.6981916538611336 
2022-06-28 21:29:12,311: ============================================================
2022-06-28 21:29:12,311: Epoch 13/26 Batch 2600/7662 eta: 21:31:19.490729	Training Loss 3.8675 (3.6858)	Training Prec@1 98.242 (98.444)	Training Prec@5 99.023 (99.373)	
2022-06-28 21:29:12,311: ============================================================
2022-06-28 21:30:26,409: time cost, forward:0.011487556502040822, backward:0.03072059900948806, data cost:0.6982217087662631 
2022-06-28 21:30:26,409: ============================================================
2022-06-28 21:30:26,409: Epoch 13/26 Batch 2700/7662 eta: 21:31:23.764296	Training Loss 4.0919 (3.6915)	Training Prec@1 97.852 (98.435)	Training Prec@5 99.023 (99.369)	
2022-06-28 21:30:26,409: ============================================================
2022-06-28 21:31:40,956: time cost, forward:0.011476780270286525, backward:0.03061070839138106, data cost:0.698501006412949 
2022-06-28 21:31:40,957: ============================================================
2022-06-28 21:31:40,957: Epoch 13/26 Batch 2800/7662 eta: 21:37:59.218705	Training Loss 3.8019 (3.6965)	Training Prec@1 98.633 (98.424)	Training Prec@5 99.609 (99.363)	
2022-06-28 21:31:40,957: ============================================================
2022-06-28 21:32:55,568: time cost, forward:0.011470340457033313, backward:0.03062826906989138, data cost:0.6986662844782576 
2022-06-28 21:32:55,568: ============================================================
2022-06-28 21:32:55,569: Epoch 13/26 Batch 2900/7662 eta: 21:37:51.378732	Training Loss 3.8719 (3.7003)	Training Prec@1 98.047 (98.417)	Training Prec@5 99.023 (99.360)	
2022-06-28 21:32:55,569: ============================================================
2022-06-28 21:34:10,413: time cost, forward:0.011464899641229693, backward:0.030627395439720345, data cost:0.6989103960728558 
2022-06-28 21:34:10,414: ============================================================
2022-06-28 21:34:10,414: Epoch 13/26 Batch 3000/7662 eta: 21:40:40.368501	Training Loss 3.8815 (3.7050)	Training Prec@1 98.047 (98.408)	Training Prec@5 98.633 (99.356)	
2022-06-28 21:34:10,414: ============================================================
2022-06-28 21:35:24,161: time cost, forward:0.011469323160418312, backward:0.030607747046860544, data cost:0.6987992957085323 
2022-06-28 21:35:24,162: ============================================================
2022-06-28 21:35:24,162: Epoch 13/26 Batch 3100/7662 eta: 21:20:22.567186	Training Loss 3.9854 (3.7093)	Training Prec@1 97.852 (98.398)	Training Prec@5 99.219 (99.351)	
2022-06-28 21:35:24,162: ============================================================
2022-06-28 21:36:38,413: time cost, forward:0.011481179114839889, backward:0.030575340932218236, data cost:0.6988566317532948 
2022-06-28 21:36:38,413: ============================================================
2022-06-28 21:36:38,413: Epoch 13/26 Batch 3200/7662 eta: 21:27:52.563415	Training Loss 3.8221 (3.7138)	Training Prec@1 97.656 (98.390)	Training Prec@5 99.219 (99.347)	
2022-06-28 21:36:38,413: ============================================================
2022-06-28 21:37:53,020: time cost, forward:0.011486279093594072, backward:0.030563670673237384, data cost:0.6990053158667854 
2022-06-28 21:37:53,021: ============================================================
2022-06-28 21:37:53,021: Epoch 13/26 Batch 3300/7662 eta: 21:32:48.853699	Training Loss 3.8277 (3.7184)	Training Prec@1 99.023 (98.383)	Training Prec@5 99.609 (99.343)	
2022-06-28 21:37:53,021: ============================================================
2022-06-28 21:39:06,824: time cost, forward:0.011485759354086616, backward:0.030543767062661646, data cost:0.6989227569464481 
2022-06-28 21:39:06,824: ============================================================
2022-06-28 21:39:06,825: Epoch 13/26 Batch 3400/7662 eta: 21:17:39.381067	Training Loss 3.7790 (3.7223)	Training Prec@1 98.633 (98.374)	Training Prec@5 99.219 (99.339)	
2022-06-28 21:39:06,825: ============================================================
2022-06-28 21:40:21,064: time cost, forward:0.011478177272581857, backward:0.030525259645913936, data cost:0.698979856491634 
2022-06-28 21:40:21,065: ============================================================
2022-06-28 21:40:21,065: Epoch 13/26 Batch 3500/7662 eta: 21:23:58.181811	Training Loss 3.8742 (3.7255)	Training Prec@1 98.242 (98.365)	Training Prec@5 99.219 (99.336)	
2022-06-28 21:40:21,065: ============================================================
2022-06-28 21:41:35,612: time cost, forward:0.011469532496798664, backward:0.030522551461039864, data cost:0.6991036865703925 
2022-06-28 21:41:35,613: ============================================================
2022-06-28 21:41:35,613: Epoch 13/26 Batch 3600/7662 eta: 21:28:03.138044	Training Loss 3.7346 (3.7289)	Training Prec@1 98.633 (98.358)	Training Prec@5 99.414 (99.334)	
2022-06-28 21:41:35,613: ============================================================
2022-06-28 21:42:50,765: time cost, forward:0.011467352723005366, backward:0.030572615368490638, data cost:0.6993232876843909 
2022-06-28 21:42:50,765: ============================================================
2022-06-28 21:42:50,765: Epoch 13/26 Batch 3700/7662 eta: 21:37:14.744985	Training Loss 3.8458 (3.7319)	Training Prec@1 98.438 (98.350)	Training Prec@5 99.023 (99.330)	
2022-06-28 21:42:50,765: ============================================================
2022-06-28 21:44:04,910: time cost, forward:0.011459988523514906, backward:0.030560078574469542, data cost:0.699334744749398 
2022-06-28 21:44:04,910: ============================================================
2022-06-28 21:44:04,910: Epoch 13/26 Batch 3800/7662 eta: 21:18:37.231877	Training Loss 3.9605 (3.7354)	Training Prec@1 98.047 (98.343)	Training Prec@5 99.023 (99.326)	
2022-06-28 21:44:04,910: ============================================================
2022-06-28 21:45:20,203: time cost, forward:0.01146648235277018, backward:0.03056502831413306, data cost:0.6996051323478055 
2022-06-28 21:45:20,203: ============================================================
2022-06-28 21:45:20,203: Epoch 13/26 Batch 3900/7662 eta: 21:37:09.312349	Training Loss 4.0482 (3.7388)	Training Prec@1 97.852 (98.336)	Training Prec@5 98.828 (99.324)	
2022-06-28 21:45:20,203: ============================================================
2022-06-28 21:46:34,215: time cost, forward:0.011467053372134385, backward:0.030582681242362592, data cost:0.6995355200546924 
2022-06-28 21:46:34,215: ============================================================
2022-06-28 21:46:34,215: Epoch 13/26 Batch 4000/7662 eta: 21:13:51.808636	Training Loss 4.0203 (3.7415)	Training Prec@1 98.047 (98.331)	Training Prec@5 99.219 (99.322)	
2022-06-28 21:46:34,216: ============================================================
2022-06-28 21:47:46,701: time cost, forward:0.011462939719102184, backward:0.03055102658231074, data cost:0.699149978192849 
2022-06-28 21:47:46,701: ============================================================
2022-06-28 21:47:46,702: Epoch 13/26 Batch 4100/7662 eta: 20:46:23.143880	Training Loss 3.7336 (3.7441)	Training Prec@1 98.438 (98.324)	Training Prec@5 99.414 (99.318)	
2022-06-28 21:47:46,702: ============================================================
2022-06-28 21:49:00,522: time cost, forward:0.011471490174084796, backward:0.03054293804890941, data cost:0.6990713818807436 
2022-06-28 21:49:00,523: ============================================================
2022-06-28 21:49:00,523: Epoch 13/26 Batch 4200/7662 eta: 21:08:06.805939	Training Loss 3.7823 (3.7471)	Training Prec@1 98.242 (98.317)	Training Prec@5 99.414 (99.315)	
2022-06-28 21:49:00,523: ============================================================
2022-06-28 21:50:14,883: time cost, forward:0.01147367633146085, backward:0.03057655009260619, data cost:0.6990837817914155 
2022-06-28 21:50:14,884: ============================================================
2022-06-28 21:50:14,884: Epoch 13/26 Batch 4300/7662 eta: 21:16:09.023650	Training Loss 3.7631 (3.7502)	Training Prec@1 98.438 (98.310)	Training Prec@5 99.023 (99.311)	
2022-06-28 21:50:14,884: ============================================================
2022-06-28 21:51:29,048: time cost, forward:0.011468170881000371, backward:0.03053623168244636, data cost:0.699128521548317 
2022-06-28 21:51:29,049: ============================================================
2022-06-28 21:51:29,049: Epoch 13/26 Batch 4400/7662 eta: 21:11:32.546590	Training Loss 3.7127 (3.7533)	Training Prec@1 97.852 (98.305)	Training Prec@5 99.219 (99.308)	
2022-06-28 21:51:29,049: ============================================================
2022-06-28 21:52:43,949: time cost, forward:0.011464870460935899, backward:0.030542163855236195, data cost:0.6992894702287323 
2022-06-28 21:52:43,950: ============================================================
2022-06-28 21:52:43,950: Epoch 13/26 Batch 4500/7662 eta: 21:22:55.111622	Training Loss 3.7512 (3.7561)	Training Prec@1 98.828 (98.300)	Training Prec@5 99.609 (99.305)	
2022-06-28 21:52:43,950: ============================================================
2022-06-28 21:53:58,791: time cost, forward:0.011471875830042956, backward:0.03055790207338841, data cost:0.6994122565116642 
2022-06-28 21:53:58,792: ============================================================
2022-06-28 21:53:58,792: Epoch 13/26 Batch 4600/7662 eta: 21:20:39.437033	Training Loss 3.8866 (3.7588)	Training Prec@1 98.633 (98.294)	Training Prec@5 99.414 (99.303)	
2022-06-28 21:53:58,792: ============================================================
2022-06-28 21:55:13,093: time cost, forward:0.011474976719224877, backward:0.03056581488668373, data cost:0.6994240410811446 
2022-06-28 21:55:13,093: ============================================================
2022-06-28 21:55:13,093: Epoch 13/26 Batch 4700/7662 eta: 21:10:10.228832	Training Loss 4.1085 (3.7614)	Training Prec@1 96.484 (98.285)	Training Prec@5 98.633 (99.298)	
2022-06-28 21:55:13,093: ============================================================
2022-06-28 21:56:28,317: time cost, forward:0.011480329930471813, backward:0.030592886004057445, data cost:0.6996089685805318 
2022-06-28 21:56:28,317: ============================================================
2022-06-28 21:56:28,318: Epoch 13/26 Batch 4800/7662 eta: 21:24:41.765971	Training Loss 3.8375 (3.7637)	Training Prec@1 98.242 (98.280)	Training Prec@5 99.219 (99.296)	
2022-06-28 21:56:28,318: ============================================================
2022-06-28 21:57:42,956: time cost, forward:0.011480870016206646, backward:0.030622685045630475, data cost:0.6996646056882847 
2022-06-28 21:57:42,956: ============================================================
2022-06-28 21:57:42,956: Epoch 13/26 Batch 4900/7662 eta: 21:13:26.743151	Training Loss 3.7786 (3.7666)	Training Prec@1 97.852 (98.273)	Training Prec@5 99.219 (99.292)	
2022-06-28 21:57:42,956: ============================================================
2022-06-28 21:58:57,844: time cost, forward:0.011485835079384651, backward:0.03063415112221663, data cost:0.699781981294788 
2022-06-28 21:58:57,844: ============================================================
2022-06-28 21:58:57,844: Epoch 13/26 Batch 5000/7662 eta: 21:16:27.007573	Training Loss 3.9678 (3.7694)	Training Prec@1 98.828 (98.266)	Training Prec@5 99.414 (99.289)	
2022-06-28 21:58:57,844: ============================================================
2022-06-28 22:00:12,214: time cost, forward:0.01148160337630289, backward:0.030651032211593984, data cost:0.699792754114738 
2022-06-28 22:00:12,215: ============================================================
2022-06-28 22:00:12,215: Epoch 13/26 Batch 5100/7662 eta: 21:06:23.791350	Training Loss 3.8020 (3.7716)	Training Prec@1 98.047 (98.262)	Training Prec@5 99.023 (99.287)	
2022-06-28 22:00:12,215: ============================================================
2022-06-28 22:01:26,119: time cost, forward:0.011484002351623288, backward:0.030568949830924164, data cost:0.6998071657691833 
2022-06-28 22:01:26,119: ============================================================
2022-06-28 22:01:26,119: Epoch 13/26 Batch 5200/7662 eta: 20:57:13.771250	Training Loss 3.9861 (3.7739)	Training Prec@1 97.656 (98.257)	Training Prec@5 98.633 (99.285)	
2022-06-28 22:01:26,120: ============================================================
2022-06-28 22:02:40,907: time cost, forward:0.011491923765048236, backward:0.03057066214086875, data cost:0.6999039575724719 
2022-06-28 22:02:40,907: ============================================================
2022-06-28 22:02:40,907: Epoch 13/26 Batch 5300/7662 eta: 21:11:00.511890	Training Loss 3.9959 (3.7764)	Training Prec@1 98.047 (98.253)	Training Prec@5 99.414 (99.282)	
2022-06-28 22:02:40,907: ============================================================
2022-06-28 22:03:55,223: time cost, forward:0.011503374428633386, backward:0.03060965110558363, data cost:0.699866033125904 
2022-06-28 22:03:55,223: ============================================================
2022-06-28 22:03:55,223: Epoch 13/26 Batch 5400/7662 eta: 21:01:44.727522	Training Loss 4.0122 (3.7788)	Training Prec@1 98.242 (98.248)	Training Prec@5 98.633 (99.280)	
2022-06-28 22:03:55,223: ============================================================
2022-06-28 22:05:09,692: time cost, forward:0.011505968376904709, backward:0.03061194484028779, data cost:0.6999032107195565 
2022-06-28 22:05:09,692: ============================================================
2022-06-28 22:05:09,692: Epoch 13/26 Batch 5500/7662 eta: 21:03:06.550094	Training Loss 3.8650 (3.7806)	Training Prec@1 98.242 (98.241)	Training Prec@5 99.414 (99.277)	
2022-06-28 22:05:09,692: ============================================================
2022-06-28 22:06:23,943: time cost, forward:0.011512889885906662, backward:0.03061186213390298, data cost:0.6998974604997534 
2022-06-28 22:06:23,943: ============================================================
2022-06-28 22:06:23,944: Epoch 13/26 Batch 5600/7662 eta: 20:58:10.463638	Training Loss 3.8398 (3.7824)	Training Prec@1 98.828 (98.235)	Training Prec@5 99.219 (99.274)	
2022-06-28 22:06:23,944: ============================================================
2022-06-28 22:07:39,723: time cost, forward:0.011512807888573858, backward:0.030628984404103884, data cost:0.7001511677459031 
2022-06-28 22:07:39,723: ============================================================
2022-06-28 22:07:39,723: Epoch 13/26 Batch 5700/7662 eta: 21:22:48.474067	Training Loss 3.6779 (3.7847)	Training Prec@1 98.242 (98.230)	Training Prec@5 99.414 (99.273)	
2022-06-28 22:07:39,723: ============================================================
2022-06-28 22:08:53,692: time cost, forward:0.011502508007877756, backward:0.030634708703849045, data cost:0.7001005472201975 
2022-06-28 22:08:53,693: ============================================================
2022-06-28 22:08:53,693: Epoch 13/26 Batch 5800/7662 eta: 20:50:56.273866	Training Loss 3.8589 (3.7870)	Training Prec@1 99.219 (98.226)	Training Prec@5 99.805 (99.270)	
2022-06-28 22:08:53,693: ============================================================
2022-06-28 22:10:09,143: time cost, forward:0.011511815242958101, backward:0.03062498393675537, data cost:0.7003014052514405 
2022-06-28 22:10:09,143: ============================================================
2022-06-28 22:10:09,143: Epoch 13/26 Batch 5900/7662 eta: 21:14:43.250837	Training Loss 4.0862 (3.7888)	Training Prec@1 97.266 (98.221)	Training Prec@5 98.828 (99.267)	
2022-06-28 22:10:09,143: ============================================================
2022-06-28 22:11:25,458: time cost, forward:0.01152867793162518, backward:0.030608942676015764, data cost:0.7006359468362474 
2022-06-28 22:11:25,458: ============================================================
2022-06-28 22:11:25,459: Epoch 13/26 Batch 6000/7662 eta: 21:28:03.877078	Training Loss 4.0534 (3.7905)	Training Prec@1 97.852 (98.216)	Training Prec@5 98.828 (99.265)	
2022-06-28 22:11:25,459: ============================================================
2022-06-28 22:12:40,862: time cost, forward:0.011533391770817723, backward:0.030627162168408675, data cost:0.7007888554549447 
2022-06-28 22:12:40,862: ============================================================
2022-06-28 22:12:40,863: Epoch 13/26 Batch 6100/7662 eta: 21:11:25.593648	Training Loss 3.9160 (3.7916)	Training Prec@1 96.484 (98.211)	Training Prec@5 99.219 (99.263)	
2022-06-28 22:12:40,863: ============================================================
2022-06-28 22:13:56,852: time cost, forward:0.011535050542455736, backward:0.030627460936650787, data cost:0.7010571633563694 
2022-06-28 22:13:56,852: ============================================================
2022-06-28 22:13:56,852: Epoch 13/26 Batch 6200/7662 eta: 21:20:02.010454	Training Loss 3.9700 (3.7938)	Training Prec@1 97.852 (98.204)	Training Prec@5 98.828 (99.260)	
2022-06-28 22:13:56,852: ============================================================
2022-06-28 22:15:12,606: time cost, forward:0.011537618458431891, backward:0.030635232375829744, data cost:0.7012631980591983 
2022-06-28 22:15:12,607: ============================================================
2022-06-28 22:15:12,607: Epoch 13/26 Batch 6300/7662 eta: 21:14:48.748303	Training Loss 3.7343 (3.7953)	Training Prec@1 98.828 (98.200)	Training Prec@5 99.609 (99.258)	
2022-06-28 22:15:12,607: ============================================================
2022-06-28 22:16:29,104: time cost, forward:0.011555840883763213, backward:0.030654683189851116, data cost:0.7015562812729466 
2022-06-28 22:16:29,105: ============================================================
2022-06-28 22:16:29,105: Epoch 13/26 Batch 6400/7662 eta: 21:26:02.528238	Training Loss 3.9411 (3.7971)	Training Prec@1 97.852 (98.195)	Training Prec@5 98.633 (99.254)	
2022-06-28 22:16:29,105: ============================================================
2022-06-28 22:17:43,018: time cost, forward:0.01155480210057294, backward:0.030670699238281907, data cost:0.7014610337778171 
2022-06-28 22:17:43,019: ============================================================
2022-06-28 22:17:43,019: Epoch 13/26 Batch 6500/7662 eta: 20:41:22.391968	Training Loss 4.0422 (3.7987)	Training Prec@1 97.656 (98.191)	Training Prec@5 99.414 (99.252)	
2022-06-28 22:17:43,019: ============================================================
2022-06-28 22:18:59,567: time cost, forward:0.011561921878843022, backward:0.030676773776247893, data cost:0.7017751468060721 
2022-06-28 22:18:59,568: ============================================================
2022-06-28 22:18:59,568: Epoch 13/26 Batch 6600/7662 eta: 21:24:21.124116	Training Loss 3.7450 (3.8003)	Training Prec@1 98.438 (98.187)	Training Prec@5 99.023 (99.250)	
2022-06-28 22:18:59,568: ============================================================
2022-06-28 22:20:14,952: time cost, forward:0.011567026843845283, backward:0.030702780246521077, data cost:0.7018804511377609 
2022-06-28 22:20:14,952: ============================================================
2022-06-28 22:20:14,952: Epoch 13/26 Batch 6700/7662 eta: 21:03:33.317944	Training Loss 3.7892 (3.8019)	Training Prec@1 97.461 (98.181)	Training Prec@5 99.414 (99.247)	
2022-06-28 22:20:14,952: ============================================================
2022-06-28 22:21:30,898: time cost, forward:0.011574318521530211, backward:0.030708038415921436, data cost:0.7020893830870123 
2022-06-28 22:21:30,898: ============================================================
2022-06-28 22:21:30,898: Epoch 13/26 Batch 6800/7662 eta: 21:11:42.167198	Training Loss 3.9212 (3.8035)	Training Prec@1 98.047 (98.179)	Training Prec@5 99.414 (99.246)	
2022-06-28 22:21:30,898: ============================================================
2022-06-28 22:22:46,333: time cost, forward:0.011577933987839911, backward:0.030713842543748378, data cost:0.7022125727543884 
2022-06-28 22:22:46,333: ============================================================
2022-06-28 22:22:46,333: Epoch 13/26 Batch 6900/7662 eta: 21:01:53.222521	Training Loss 3.7438 (3.8046)	Training Prec@1 98.828 (98.176)	Training Prec@5 99.609 (99.243)	
2022-06-28 22:22:46,333: ============================================================
2022-06-28 22:24:00,593: time cost, forward:0.011572282473382515, backward:0.030738417225780613, data cost:0.7021616003584531 
2022-06-28 22:24:00,593: ============================================================
2022-06-28 22:24:00,593: Epoch 13/26 Batch 7000/7662 eta: 20:41:00.050565	Training Loss 3.9257 (3.8057)	Training Prec@1 97.266 (98.172)	Training Prec@5 98.828 (99.242)	
2022-06-28 22:24:00,593: ============================================================
2022-06-28 22:25:16,519: time cost, forward:0.011572765219226691, backward:0.030739708506972004, data cost:0.7023618106422903 
2022-06-28 22:25:16,520: ============================================================
2022-06-28 22:25:16,520: Epoch 13/26 Batch 7100/7662 eta: 21:07:34.706487	Training Loss 3.7534 (3.8071)	Training Prec@1 98.242 (98.168)	Training Prec@5 99.023 (99.240)	
2022-06-28 22:25:16,520: ============================================================
2022-06-28 22:26:31,452: time cost, forward:0.011573484033689779, backward:0.030745565303416197, data cost:0.7024115108254718 
2022-06-28 22:26:31,452: ============================================================
2022-06-28 22:26:31,452: Epoch 13/26 Batch 7200/7662 eta: 20:49:44.266296	Training Loss 3.8222 (3.8084)	Training Prec@1 97.852 (98.164)	Training Prec@5 99.414 (99.238)	
2022-06-28 22:26:31,452: ============================================================
2022-06-28 22:27:44,827: time cost, forward:0.01158005146967873, backward:0.030740832054283476, data cost:0.7022536610034839 
2022-06-28 22:27:44,827: ============================================================
2022-06-28 22:27:44,827: Epoch 13/26 Batch 7300/7662 eta: 20:22:32.045913	Training Loss 3.6575 (3.8091)	Training Prec@1 98.633 (98.162)	Training Prec@5 98.828 (99.237)	
2022-06-28 22:27:44,827: ============================================================
2022-06-28 22:29:00,222: time cost, forward:0.011607928861877632, backward:0.03074454768217324, data cost:0.7023419809915001 
2022-06-28 22:29:00,223: ============================================================
2022-06-28 22:29:00,223: Epoch 13/26 Batch 7400/7662 eta: 20:54:56.876132	Training Loss 4.2029 (3.8102)	Training Prec@1 98.047 (98.159)	Training Prec@5 99.219 (99.236)	
2022-06-28 22:29:00,223: ============================================================
2022-06-28 22:30:15,231: time cost, forward:0.011610364195409974, backward:0.03074929882389877, data cost:0.7024031556245565 
2022-06-28 22:30:15,232: ============================================================
2022-06-28 22:30:15,232: Epoch 13/26 Batch 7500/7662 eta: 20:47:15.694782	Training Loss 3.9008 (3.8116)	Training Prec@1 97.070 (98.156)	Training Prec@5 99.023 (99.235)	
2022-06-28 22:30:15,232: ============================================================
2022-06-28 22:31:31,046: time cost, forward:0.011612944829493765, backward:0.030781573191302782, data cost:0.7025374878016032 
2022-06-28 22:31:31,046: ============================================================
2022-06-28 22:31:31,047: Epoch 13/26 Batch 7600/7662 eta: 20:59:23.994425	Training Loss 3.9022 (3.8128)	Training Prec@1 98.242 (98.153)	Training Prec@5 99.805 (99.233)	
2022-06-28 22:31:31,047: ============================================================
2022-06-28 22:32:20,529: Epoch: 13/26 eta: 20:58:36.231012	Training Loss 3.9411 (3.8138)	Training Prec@1 98.438 (98.151)	Training Prec@5 99.609 (99.232)
2022-06-28 22:32:20,530: ============================================================
2022-06-28 22:33:40,006: time cost, forward:0.011436402195631856, backward:0.030709201639348812, data cost:0.7536509687250311 
2022-06-28 22:33:40,006: ============================================================
2022-06-28 22:33:40,007: Epoch 14/26 Batch 100/7662 eta: 21:55:10.240015	Training Loss 3.4079 (3.3905)	Training Prec@1 98.438 (98.761)	Training Prec@5 99.414 (99.544)	
2022-06-28 22:33:40,007: ============================================================
2022-06-28 22:34:55,576: time cost, forward:0.011110683182376114, backward:0.030066469805923538, data cost:0.7342687168313031 
2022-06-28 22:34:55,577: ============================================================
2022-06-28 22:34:55,577: Epoch 14/26 Batch 200/7662 eta: 20:52:02.268713	Training Loss 3.2385 (3.4100)	Training Prec@1 99.414 (98.767)	Training Prec@5 99.609 (99.533)	
2022-06-28 22:34:55,577: ============================================================
2022-06-28 22:36:12,286: time cost, forward:0.010989536011099416, backward:0.029933879208006588, data cost:0.7315442841188565 
2022-06-28 22:36:12,286: ============================================================
2022-06-28 22:36:12,287: Epoch 14/26 Batch 300/7662 eta: 21:09:37.908921	Training Loss 3.4378 (3.4178)	Training Prec@1 98.633 (98.757)	Training Prec@5 99.219 (99.515)	
2022-06-28 22:36:12,287: ============================================================
2022-06-28 22:37:29,686: time cost, forward:0.010880482824225175, backward:0.02994156063051152, data cost:0.7319680455334503 
2022-06-28 22:37:29,686: ============================================================
2022-06-28 22:37:29,686: Epoch 14/26 Batch 400/7662 eta: 21:19:45.918177	Training Loss 3.3809 (3.4374)	Training Prec@1 98.633 (98.741)	Training Prec@5 99.609 (99.508)	
2022-06-28 22:37:29,686: ============================================================
2022-06-28 22:38:44,033: time cost, forward:0.010978943838146264, backward:0.029970960292166365, data cost:0.7258441151980168 
2022-06-28 22:38:44,034: ============================================================
2022-06-28 22:38:44,034: Epoch 14/26 Batch 500/7662 eta: 20:28:03.557062	Training Loss 3.6754 (3.4516)	Training Prec@1 97.266 (98.726)	Training Prec@5 99.219 (99.504)	
2022-06-28 22:38:44,034: ============================================================
2022-06-28 22:39:58,084: time cost, forward:0.011124241133166075, backward:0.0302394606633258, data cost:0.7209599392242941 
2022-06-28 22:39:58,085: ============================================================
2022-06-28 22:39:58,085: Epoch 14/26 Batch 600/7662 eta: 20:21:55.708387	Training Loss 3.5816 (3.4604)	Training Prec@1 98.828 (98.732)	Training Prec@5 99.414 (99.504)	
2022-06-28 22:39:58,085: ============================================================
2022-06-28 22:41:11,693: time cost, forward:0.011161539175991336, backward:0.030439517358171412, data cost:0.7169052343682328 
2022-06-28 22:41:11,693: ============================================================
2022-06-28 22:41:11,693: Epoch 14/26 Batch 700/7662 eta: 20:13:24.036917	Training Loss 3.6270 (3.4719)	Training Prec@1 98.047 (98.726)	Training Prec@5 99.414 (99.501)	
2022-06-28 22:41:11,693: ============================================================
2022-06-28 22:42:24,396: time cost, forward:0.01125223914135681, backward:0.03060287170028209, data cost:0.7126517907549652 
2022-06-28 22:42:24,397: ============================================================
2022-06-28 22:42:24,397: Epoch 14/26 Batch 800/7662 eta: 19:57:16.201224	Training Loss 3.4872 (3.4872)	Training Prec@1 99.023 (98.708)	Training Prec@5 99.609 (99.492)	
2022-06-28 22:42:24,397: ============================================================
2022-06-28 22:43:37,761: time cost, forward:0.011224506959501442, backward:0.03058758301782661, data cost:0.7103486960138442 
2022-06-28 22:43:37,762: ============================================================
2022-06-28 22:43:37,762: Epoch 14/26 Batch 900/7662 eta: 20:06:56.131925	Training Loss 3.4701 (3.4977)	Training Prec@1 99.414 (98.702)	Training Prec@5 99.805 (99.489)	
2022-06-28 22:43:37,762: ============================================================
2022-06-28 22:44:50,911: time cost, forward:0.011255812000583959, backward:0.030590018949231825, data cost:0.708181433730178 
2022-06-28 22:44:50,912: ============================================================
2022-06-28 22:44:50,912: Epoch 14/26 Batch 1000/7662 eta: 20:02:11.137673	Training Loss 3.6973 (3.5103)	Training Prec@1 98.633 (98.690)	Training Prec@5 99.219 (99.482)	
2022-06-28 22:44:50,912: ============================================================
2022-06-28 22:46:02,747: time cost, forward:0.011358814525864578, backward:0.030830229272399846, data cost:0.7049186793753405 
2022-06-28 22:46:02,748: ============================================================
2022-06-28 22:46:02,748: Epoch 14/26 Batch 1100/7662 eta: 19:39:23.399240	Training Loss 3.8212 (3.5227)	Training Prec@1 98.047 (98.673)	Training Prec@5 99.414 (99.477)	
2022-06-28 22:46:02,748: ============================================================
2022-06-28 22:47:16,217: time cost, forward:0.0114230505121659, backward:0.03061620705917142, data cost:0.7039911198158678 
2022-06-28 22:47:16,217: ============================================================
2022-06-28 22:47:16,217: Epoch 14/26 Batch 1200/7662 eta: 20:04:59.151575	Training Loss 3.7485 (3.5323)	Training Prec@1 98.438 (98.661)	Training Prec@5 99.414 (99.470)	
2022-06-28 22:47:16,217: ============================================================
2022-06-28 22:48:29,435: time cost, forward:0.011480771366498211, backward:0.03061118155281942, data cost:0.7028470949726531 
2022-06-28 22:48:29,436: ============================================================
2022-06-28 22:48:29,436: Epoch 14/26 Batch 1300/7662 eta: 19:59:39.165000	Training Loss 3.5564 (3.5419)	Training Prec@1 98.828 (98.653)	Training Prec@5 99.805 (99.468)	
2022-06-28 22:48:29,436: ============================================================
2022-06-28 22:49:44,437: time cost, forward:0.011520516966137399, backward:0.03069534431277555, data cost:0.703047311842825 
2022-06-28 22:49:44,437: ============================================================
2022-06-28 22:49:44,437: Epoch 14/26 Batch 1400/7662 eta: 20:27:36.250964	Training Loss 3.4032 (3.5504)	Training Prec@1 99.219 (98.635)	Training Prec@5 99.609 (99.458)	
2022-06-28 22:49:44,437: ============================================================
2022-06-28 22:50:56,867: time cost, forward:0.011502103538335046, backward:0.030789293870677782, data cost:0.7015426607430976 
2022-06-28 22:50:56,868: ============================================================
2022-06-28 22:50:56,868: Epoch 14/26 Batch 1500/7662 eta: 19:44:19.769825	Training Loss 3.7532 (3.5584)	Training Prec@1 98.438 (98.624)	Training Prec@5 99.414 (99.454)	
2022-06-28 22:50:56,868: ============================================================
2022-06-28 22:52:09,882: time cost, forward:0.011528547888177868, backward:0.03087589262126758, data cost:0.7005361645873298 
2022-06-28 22:52:09,883: ============================================================
2022-06-28 22:52:09,883: Epoch 14/26 Batch 1600/7662 eta: 19:52:39.862326	Training Loss 3.9579 (3.5682)	Training Prec@1 98.438 (98.609)	Training Prec@5 99.414 (99.448)	
2022-06-28 22:52:09,883: ============================================================
2022-06-28 22:53:24,778: time cost, forward:0.011524493445923498, backward:0.030902791261813303, data cost:0.7008542067307174 
2022-06-28 22:53:24,778: ============================================================
2022-06-28 22:53:24,779: Epoch 14/26 Batch 1700/7662 eta: 20:22:07.946001	Training Loss 3.7495 (3.5763)	Training Prec@1 97.461 (98.592)	Training Prec@5 99.219 (99.441)	
2022-06-28 22:53:24,779: ============================================================
2022-06-28 22:54:38,274: time cost, forward:0.011462141633895187, backward:0.030851111801681815, data cost:0.7004737622079218 
2022-06-28 22:54:38,274: ============================================================
2022-06-28 22:54:38,274: Epoch 14/26 Batch 1800/7662 eta: 19:58:03.729080	Training Loss 3.7208 (3.5838)	Training Prec@1 97.070 (98.578)	Training Prec@5 99.023 (99.434)	
2022-06-28 22:54:38,274: ============================================================
2022-06-28 22:55:51,935: time cost, forward:0.011463156243636145, backward:0.030853916181270043, data cost:0.7001205787588384 
2022-06-28 22:55:51,935: ============================================================
2022-06-28 22:55:51,935: Epoch 14/26 Batch 1900/7662 eta: 19:59:32.137315	Training Loss 3.8173 (3.5933)	Training Prec@1 98.242 (98.562)	Training Prec@5 99.414 (99.425)	
2022-06-28 22:55:51,935: ============================================================
2022-06-28 22:57:05,115: time cost, forward:0.011475734080953441, backward:0.030875675316868335, data cost:0.6995327897284137 
2022-06-28 22:57:05,115: ============================================================
2022-06-28 22:57:05,115: Epoch 14/26 Batch 2000/7662 eta: 19:50:28.640697	Training Loss 3.7722 (3.6007)	Training Prec@1 98.438 (98.554)	Training Prec@5 99.805 (99.422)	
2022-06-28 22:57:05,115: ============================================================
2022-06-28 22:58:20,284: time cost, forward:0.011476470266653846, backward:0.03089094366443447, data cost:0.6999626186928788 
2022-06-28 22:58:20,284: ============================================================
2022-06-28 22:58:20,284: Epoch 14/26 Batch 2100/7662 eta: 20:21:35.141356	Training Loss 3.6493 (3.6059)	Training Prec@1 98.242 (98.546)	Training Prec@5 99.023 (99.415)	
2022-06-28 22:58:20,284: ============================================================
2022-06-28 22:59:34,911: time cost, forward:0.011511779471167981, backward:0.030970747983688762, data cost:0.7000047080676195 
2022-06-28 22:59:34,911: ============================================================
2022-06-28 22:59:34,911: Epoch 14/26 Batch 2200/7662 eta: 20:11:31.997226	Training Loss 3.7686 (3.6126)	Training Prec@1 99.023 (98.531)	Training Prec@5 99.805 (99.411)	
2022-06-28 22:59:34,911: ============================================================
2022-06-28 23:00:48,911: time cost, forward:0.011508636030750516, backward:0.030990455813281376, data cost:0.6998620336083756 
2022-06-28 23:00:48,911: ============================================================
2022-06-28 23:00:48,911: Epoch 14/26 Batch 2300/7662 eta: 20:00:07.278599	Training Loss 3.5337 (3.6194)	Training Prec@1 99.023 (98.522)	Training Prec@5 99.219 (99.406)	
2022-06-28 23:00:48,911: ============================================================
2022-06-28 23:02:00,937: time cost, forward:0.01152598216862617, backward:0.03097683402487217, data cost:0.6989145539312772 
2022-06-28 23:02:00,938: ============================================================
2022-06-28 23:02:00,938: Epoch 14/26 Batch 2400/7662 eta: 19:26:54.698100	Training Loss 3.6060 (3.6258)	Training Prec@1 98.633 (98.510)	Training Prec@5 99.414 (99.402)	
2022-06-28 23:02:00,938: ============================================================
2022-06-28 23:03:14,777: time cost, forward:0.01152439955092755, backward:0.030818050887499775, data cost:0.6989399780030726 
2022-06-28 23:03:14,777: ============================================================
2022-06-28 23:03:14,777: Epoch 14/26 Batch 2500/7662 eta: 19:55:03.410500	Training Loss 3.7797 (3.6308)	Training Prec@1 98.438 (98.498)	Training Prec@5 99.609 (99.396)	
2022-06-28 23:03:14,777: ============================================================
2022-06-28 23:04:28,480: time cost, forward:0.011528856252513972, backward:0.03077243822911649, data cost:0.6987959226767528 
2022-06-28 23:04:28,481: ============================================================
2022-06-28 23:04:28,481: Epoch 14/26 Batch 2600/7662 eta: 19:51:37.577636	Training Loss 3.7908 (3.6363)	Training Prec@1 98.242 (98.489)	Training Prec@5 99.609 (99.390)	
2022-06-28 23:04:28,481: ============================================================
2022-06-28 23:05:42,003: time cost, forward:0.011534706139043333, backward:0.030711677702500582, data cost:0.6986170743473727 
2022-06-28 23:05:42,003: ============================================================
2022-06-28 23:05:42,003: Epoch 14/26 Batch 2700/7662 eta: 19:47:28.236551	Training Loss 3.6680 (3.6419)	Training Prec@1 98.242 (98.476)	Training Prec@5 99.609 (99.385)	
2022-06-28 23:05:42,003: ============================================================
2022-06-28 23:06:56,521: time cost, forward:0.011543201437674492, backward:0.03072009107052066, data cost:0.6987377175606758 
2022-06-28 23:06:56,521: ============================================================
2022-06-28 23:06:56,522: Epoch 14/26 Batch 2800/7662 eta: 20:02:19.018211	Training Loss 3.6481 (3.6465)	Training Prec@1 98.242 (98.465)	Training Prec@5 99.219 (99.380)	
2022-06-28 23:06:56,522: ============================================================
2022-06-28 23:08:09,949: time cost, forward:0.011558183516745486, backward:0.0306901342912393, data cost:0.6985061037083995 
2022-06-28 23:08:09,949: ============================================================
2022-06-28 23:08:09,949: Epoch 14/26 Batch 2900/7662 eta: 19:43:29.756546	Training Loss 3.5762 (3.6511)	Training Prec@1 98.242 (98.458)	Training Prec@5 99.219 (99.375)	
2022-06-28 23:08:09,949: ============================================================
2022-06-28 23:09:23,056: time cost, forward:0.01158103787052349, backward:0.030705985803530986, data cost:0.6981269255126464 
2022-06-28 23:09:23,056: ============================================================
2022-06-28 23:09:23,057: Epoch 14/26 Batch 3000/7662 eta: 19:37:06.800447	Training Loss 3.7992 (3.6551)	Training Prec@1 97.461 (98.449)	Training Prec@5 99.023 (99.372)	
2022-06-28 23:09:23,057: ============================================================
2022-06-28 23:10:37,165: time cost, forward:0.011586606021695232, backward:0.030691052914127374, data cost:0.6981456004330788 
2022-06-28 23:10:37,165: ============================================================
2022-06-28 23:10:37,165: Epoch 14/26 Batch 3100/7662 eta: 19:51:59.853744	Training Loss 3.5602 (3.6597)	Training Prec@1 98.828 (98.438)	Training Prec@5 99.609 (99.368)	
2022-06-28 23:10:37,165: ============================================================
2022-06-28 23:11:51,816: time cost, forward:0.011612076131803388, backward:0.030737017422551176, data cost:0.6982491460581354 
2022-06-28 23:11:51,817: ============================================================
2022-06-28 23:11:51,817: Epoch 14/26 Batch 3200/7662 eta: 19:59:29.512937	Training Loss 3.9985 (3.6636)	Training Prec@1 97.070 (98.432)	Training Prec@5 98.633 (99.364)	
2022-06-28 23:11:51,817: ============================================================
2022-06-28 23:13:05,745: time cost, forward:0.011624526457195392, backward:0.030686402906248446, data cost:0.6982316741729441 
2022-06-28 23:13:05,745: ============================================================
2022-06-28 23:13:05,745: Epoch 14/26 Batch 3300/7662 eta: 19:46:38.071533	Training Loss 3.8495 (3.6678)	Training Prec@1 98.438 (98.424)	Training Prec@5 99.609 (99.359)	
2022-06-28 23:13:05,745: ============================================================
2022-06-28 23:14:19,087: time cost, forward:0.01163889871481132, backward:0.030696414785898584, data cost:0.6979899718572757 
2022-06-28 23:14:19,087: ============================================================
2022-06-28 23:14:19,087: Epoch 14/26 Batch 3400/7662 eta: 19:36:00.404023	Training Loss 3.5857 (3.6720)	Training Prec@1 98.438 (98.415)	Training Prec@5 99.219 (99.355)	
2022-06-28 23:14:19,088: ============================================================
2022-06-28 23:15:33,512: time cost, forward:0.011667947695574851, backward:0.03068790520283453, data cost:0.6980637650927259 
2022-06-28 23:15:33,512: ============================================================
2022-06-28 23:15:33,513: Epoch 14/26 Batch 3500/7662 eta: 19:52:07.772874	Training Loss 3.8496 (3.6764)	Training Prec@1 98.242 (98.406)	Training Prec@5 99.609 (99.351)	
2022-06-28 23:15:33,513: ============================================================
2022-06-28 23:16:48,056: time cost, forward:0.011687455160083226, backward:0.030664857409668816, data cost:0.6981954960135428 
2022-06-28 23:16:48,056: ============================================================
2022-06-28 23:16:48,057: Epoch 14/26 Batch 3600/7662 eta: 19:52:47.391156	Training Loss 3.4168 (3.6793)	Training Prec@1 99.023 (98.402)	Training Prec@5 100.000 (99.350)	
2022-06-28 23:16:48,057: ============================================================
2022-06-28 23:18:02,295: time cost, forward:0.01169388730579468, backward:0.030677337200456647, data cost:0.6982115814253329 
2022-06-28 23:18:02,295: ============================================================
2022-06-28 23:18:02,295: Epoch 14/26 Batch 3700/7662 eta: 19:46:40.328525	Training Loss 3.7124 (3.6832)	Training Prec@1 98.047 (98.392)	Training Prec@5 99.609 (99.346)	
2022-06-28 23:18:02,295: ============================================================
2022-06-28 23:19:17,973: time cost, forward:0.011708840535608962, backward:0.030662238331147326, data cost:0.6986245822831184 
2022-06-28 23:19:17,973: ============================================================
2022-06-28 23:19:17,974: Epoch 14/26 Batch 3800/7662 eta: 20:08:24.954604	Training Loss 3.7068 (3.6867)	Training Prec@1 97.461 (98.385)	Training Prec@5 99.023 (99.343)	
2022-06-28 23:19:17,974: ============================================================
2022-06-28 23:20:31,798: time cost, forward:0.011723563560433007, backward:0.030668136430844553, data cost:0.6985223786774034 
2022-06-28 23:20:31,798: ============================================================
2022-06-28 23:20:31,799: Epoch 14/26 Batch 3900/7662 eta: 19:37:35.730674	Training Loss 3.9448 (3.6907)	Training Prec@1 98.242 (98.380)	Training Prec@5 98.633 (99.342)	
2022-06-28 23:20:31,799: ============================================================
2022-06-28 23:21:46,056: time cost, forward:0.011717126082706284, backward:0.030642496165289645, data cost:0.6985882079192894 
2022-06-28 23:21:46,056: ============================================================
2022-06-28 23:21:46,057: Epoch 14/26 Batch 4000/7662 eta: 19:43:15.830233	Training Loss 3.7826 (3.6939)	Training Prec@1 98.438 (98.373)	Training Prec@5 98.828 (99.336)	
2022-06-28 23:21:46,057: ============================================================
2022-06-28 23:23:00,336: time cost, forward:0.011728502768195237, backward:0.030641084358325146, data cost:0.6986077543176306 
2022-06-28 23:23:00,337: ============================================================
2022-06-28 23:23:00,337: Epoch 14/26 Batch 4100/7662 eta: 19:42:22.927242	Training Loss 3.5591 (3.6975)	Training Prec@1 99.219 (98.365)	Training Prec@5 99.414 (99.333)	
2022-06-28 23:23:00,337: ============================================================
2022-06-28 23:24:14,994: time cost, forward:0.011758618253729236, backward:0.03066003950018632, data cost:0.6986830295849823 
2022-06-28 23:24:14,994: ============================================================
2022-06-28 23:24:14,994: Epoch 14/26 Batch 4200/7662 eta: 19:47:08.356855	Training Loss 3.7502 (3.7002)	Training Prec@1 97.852 (98.359)	Training Prec@5 99.023 (99.329)	
2022-06-28 23:24:14,994: ============================================================
2022-06-28 23:25:31,164: time cost, forward:0.01176628841303426, backward:0.030638475145232155, data cost:0.6991657188643575 
2022-06-28 23:25:31,165: ============================================================
2022-06-28 23:25:31,165: Epoch 14/26 Batch 4300/7662 eta: 20:09:56.000711	Training Loss 3.8318 (3.7036)	Training Prec@1 98.242 (98.353)	Training Prec@5 99.023 (99.325)	
2022-06-28 23:25:31,165: ============================================================
2022-06-28 23:26:45,242: time cost, forward:0.011770648288575051, backward:0.03068905761226195, data cost:0.6990815712446841 
2022-06-28 23:26:45,242: ============================================================
2022-06-28 23:26:45,242: Epoch 14/26 Batch 4400/7662 eta: 19:35:26.515174	Training Loss 3.9302 (3.7067)	Training Prec@1 98.633 (98.344)	Training Prec@5 99.414 (99.322)	
2022-06-28 23:26:45,242: ============================================================
2022-06-28 23:27:59,756: time cost, forward:0.01177452696405747, backward:0.030708113096109574, data cost:0.6991274780261567 
2022-06-28 23:27:59,757: ============================================================
2022-06-28 23:27:59,757: Epoch 14/26 Batch 4500/7662 eta: 19:41:08.731948	Training Loss 4.1614 (3.7098)	Training Prec@1 97.461 (98.337)	Training Prec@5 98.633 (99.319)	
2022-06-28 23:27:59,757: ============================================================
2022-06-28 23:29:14,456: time cost, forward:0.011770941065974691, backward:0.03073248320959215, data cost:0.6992129444894544 
2022-06-28 23:29:14,457: ============================================================
2022-06-28 23:29:14,457: Epoch 14/26 Batch 4600/7662 eta: 19:42:50.444913	Training Loss 3.7380 (3.7123)	Training Prec@1 98.242 (98.331)	Training Prec@5 99.219 (99.317)	
2022-06-28 23:29:14,457: ============================================================
2022-06-28 23:30:29,071: time cost, forward:0.011784443984160552, backward:0.030767014595416538, data cost:0.6992512190689506 
2022-06-28 23:30:29,071: ============================================================
2022-06-28 23:30:29,072: Epoch 14/26 Batch 4700/7662 eta: 19:40:14.389215	Training Loss 3.7081 (3.7150)	Training Prec@1 97.852 (98.326)	Training Prec@5 99.414 (99.314)	
2022-06-28 23:30:29,072: ============================================================
2022-06-28 23:31:43,610: time cost, forward:0.011787803552130357, backward:0.03078044074404908, data cost:0.6992999188327174 
2022-06-28 23:31:43,611: ============================================================
2022-06-28 23:31:43,611: Epoch 14/26 Batch 4800/7662 eta: 19:37:48.407437	Training Loss 3.8352 (3.7170)	Training Prec@1 99.219 (98.320)	Training Prec@5 99.609 (99.312)	
2022-06-28 23:31:43,611: ============================================================
2022-06-28 23:32:56,940: time cost, forward:0.011784951622132308, backward:0.030748024111403375, data cost:0.699148840698862 
2022-06-28 23:32:56,940: ============================================================
2022-06-28 23:32:56,940: Epoch 14/26 Batch 4900/7662 eta: 19:17:28.319909	Training Loss 4.0312 (3.7200)	Training Prec@1 98.047 (98.314)	Training Prec@5 99.609 (99.310)	
2022-06-28 23:32:56,941: ============================================================
2022-06-28 23:34:11,020: time cost, forward:0.0117839899843372, backward:0.03075909075629213, data cost:0.6991124999215541 
2022-06-28 23:34:11,020: ============================================================
2022-06-28 23:34:11,021: Epoch 14/26 Batch 5000/7662 eta: 19:28:04.921241	Training Loss 3.9819 (3.7227)	Training Prec@1 98.438 (98.308)	Training Prec@5 99.219 (99.308)	
2022-06-28 23:34:11,021: ============================================================
2022-06-28 23:35:26,373: time cost, forward:0.01180317668873648, backward:0.030791989726911786, data cost:0.6992868482657427 
2022-06-28 23:35:26,373: ============================================================
2022-06-28 23:35:26,373: Epoch 14/26 Batch 5100/7662 eta: 19:46:53.796099	Training Loss 3.8077 (3.7253)	Training Prec@1 97.852 (98.300)	Training Prec@5 98.633 (99.305)	
2022-06-28 23:35:26,374: ============================================================
2022-06-28 23:36:41,969: time cost, forward:0.011809180805054414, backward:0.030817196859398995, data cost:0.6995165127014789 
2022-06-28 23:36:41,969: ============================================================
2022-06-28 23:36:41,970: Epoch 14/26 Batch 5200/7662 eta: 19:49:27.975551	Training Loss 3.9623 (3.7272)	Training Prec@1 97.266 (98.296)	Training Prec@5 98.438 (99.302)	
2022-06-28 23:36:41,970: ============================================================
2022-06-28 23:37:55,224: time cost, forward:0.011815556446816207, backward:0.030851884436260912, data cost:0.6992869818068873 
2022-06-28 23:37:55,225: ============================================================
2022-06-28 23:37:55,225: Epoch 14/26 Batch 5300/7662 eta: 19:11:24.968899	Training Loss 3.6706 (3.7298)	Training Prec@1 98.828 (98.292)	Training Prec@5 99.805 (99.300)	
2022-06-28 23:37:55,225: ============================================================
2022-06-28 23:39:09,423: time cost, forward:0.011811926400668093, backward:0.030866654366558405, data cost:0.6992644592885022 
2022-06-28 23:39:09,423: ============================================================
2022-06-28 23:39:09,423: Epoch 14/26 Batch 5400/7662 eta: 19:25:00.109393	Training Loss 3.8712 (3.7322)	Training Prec@1 97.266 (98.286)	Training Prec@5 98.242 (99.297)	
2022-06-28 23:39:09,423: ============================================================
2022-06-28 23:40:23,426: time cost, forward:0.011809670506748075, backward:0.030885563696226352, data cost:0.6992047883137982 
2022-06-28 23:40:23,426: ============================================================
2022-06-28 23:40:23,426: Epoch 14/26 Batch 5500/7662 eta: 19:20:42.092080	Training Loss 3.7943 (3.7336)	Training Prec@1 98.828 (98.281)	Training Prec@5 99.219 (99.295)	
2022-06-28 23:40:23,427: ============================================================
2022-06-28 23:41:36,734: time cost, forward:0.01182503252290023, backward:0.030915606211372564, data cost:0.6989931550530967 
2022-06-28 23:41:36,734: ============================================================
2022-06-28 23:41:36,735: Epoch 14/26 Batch 5600/7662 eta: 19:08:34.662401	Training Loss 3.8785 (3.7359)	Training Prec@1 99.023 (98.275)	Training Prec@5 99.609 (99.292)	
2022-06-28 23:41:36,735: ============================================================
2022-06-28 23:42:52,229: time cost, forward:0.011840993844745327, backward:0.0308918453848431, data cost:0.6992244800782492 
2022-06-28 23:42:52,230: ============================================================
2022-06-28 23:42:52,230: Epoch 14/26 Batch 5700/7662 eta: 19:41:35.542699	Training Loss 3.9753 (3.7381)	Training Prec@1 98.047 (98.270)	Training Prec@5 99.219 (99.289)	
2022-06-28 23:42:52,230: ============================================================
2022-06-28 23:44:07,286: time cost, forward:0.011844625389150432, backward:0.03090085722615255, data cost:0.6993531786916503 
2022-06-28 23:44:07,287: ============================================================
2022-06-28 23:44:07,287: Epoch 14/26 Batch 5800/7662 eta: 19:33:28.536968	Training Loss 3.8547 (3.7397)	Training Prec@1 97.656 (98.265)	Training Prec@5 99.023 (99.287)	
2022-06-28 23:44:07,287: ============================================================
2022-06-28 23:45:21,788: time cost, forward:0.011843320251945965, backward:0.030905662582857887, data cost:0.6993908923770396 
2022-06-28 23:45:21,789: ============================================================
2022-06-28 23:45:21,789: Epoch 14/26 Batch 5900/7662 eta: 19:23:33.632347	Training Loss 3.9574 (3.7416)	Training Prec@1 97.656 (98.261)	Training Prec@5 99.219 (99.286)	
2022-06-28 23:45:21,789: ============================================================
2022-06-28 23:46:36,386: time cost, forward:0.011846614531783943, backward:0.030898416453668486, data cost:0.6994488153840764 
2022-06-28 23:46:36,386: ============================================================
2022-06-28 23:46:36,386: Epoch 14/26 Batch 6000/7662 eta: 19:23:48.214094	Training Loss 3.5954 (3.7437)	Training Prec@1 98.633 (98.257)	Training Prec@5 99.805 (99.284)	
2022-06-28 23:46:36,386: ============================================================
2022-06-28 23:47:49,865: time cost, forward:0.011843559761128674, backward:0.03087883160571267, data cost:0.6993434165692521 
2022-06-28 23:47:49,865: ============================================================
2022-06-28 23:47:49,865: Epoch 14/26 Batch 6100/7662 eta: 19:05:08.176934	Training Loss 3.8460 (3.7455)	Training Prec@1 98.438 (98.253)	Training Prec@5 98.828 (99.281)	
2022-06-28 23:47:49,865: ============================================================
2022-06-28 23:49:04,903: time cost, forward:0.011836634737615682, backward:0.03088443531953898, data cost:0.6994727148627404 
2022-06-28 23:49:04,903: ============================================================
2022-06-28 23:49:04,903: Epoch 14/26 Batch 6200/7662 eta: 19:28:10.765248	Training Loss 3.6927 (3.7473)	Training Prec@1 98.828 (98.250)	Training Prec@5 99.805 (99.279)	
2022-06-28 23:49:04,903: ============================================================
2022-06-28 23:50:19,925: time cost, forward:0.011835436799030754, backward:0.030906016305432014, data cost:0.6995735175270072 
2022-06-28 23:50:19,925: ============================================================
2022-06-28 23:50:19,925: Epoch 14/26 Batch 6300/7662 eta: 19:26:40.954689	Training Loss 4.0380 (3.7488)	Training Prec@1 98.242 (98.246)	Training Prec@5 99.219 (99.277)	
2022-06-28 23:50:19,926: ============================================================
2022-06-28 23:51:33,763: time cost, forward:0.011832058513550148, backward:0.030907775148933316, data cost:0.699504456607266 
2022-06-28 23:51:33,764: ============================================================
2022-06-28 23:51:33,764: Epoch 14/26 Batch 6400/7662 eta: 19:07:02.473605	Training Loss 3.9859 (3.7506)	Training Prec@1 98.047 (98.242)	Training Prec@5 99.609 (99.275)	
2022-06-28 23:51:33,764: ============================================================
2022-06-28 23:52:48,852: time cost, forward:0.011834242505685313, backward:0.03090944905008861, data cost:0.6996277678396211 
2022-06-28 23:52:48,852: ============================================================
2022-06-28 23:52:48,852: Epoch 14/26 Batch 6500/7662 eta: 19:25:12.778467	Training Loss 3.8071 (3.7519)	Training Prec@1 98.828 (98.238)	Training Prec@5 99.219 (99.272)	
2022-06-28 23:52:48,852: ============================================================
2022-06-28 23:54:03,751: time cost, forward:0.011833672235185114, backward:0.030919696584147456, data cost:0.6997097289314739 
2022-06-28 23:54:03,751: ============================================================
2022-06-28 23:54:03,751: Epoch 14/26 Batch 6600/7662 eta: 19:21:01.260754	Training Loss 3.8069 (3.7535)	Training Prec@1 97.461 (98.235)	Training Prec@5 99.023 (99.271)	
2022-06-28 23:54:03,752: ============================================================
2022-06-28 23:55:18,181: time cost, forward:0.011848856218004604, backward:0.03092376373297849, data cost:0.6997099025229194 
2022-06-28 23:55:18,182: ============================================================
2022-06-28 23:55:18,182: Epoch 14/26 Batch 6700/7662 eta: 19:12:31.002899	Training Loss 3.6090 (3.7546)	Training Prec@1 97.852 (98.230)	Training Prec@5 99.414 (99.269)	
2022-06-28 23:55:18,182: ============================================================
2022-06-28 23:56:32,982: time cost, forward:0.011843100770955087, backward:0.030876925279505377, data cost:0.6998392245860323 
2022-06-28 23:56:32,983: ============================================================
2022-06-28 23:56:32,983: Epoch 14/26 Batch 6800/7662 eta: 19:17:00.762658	Training Loss 3.7952 (3.7562)	Training Prec@1 98.047 (98.226)	Training Prec@5 99.023 (99.268)	
2022-06-28 23:56:32,983: ============================================================
2022-06-28 23:57:47,642: time cost, forward:0.011845806782306805, backward:0.030907489680124203, data cost:0.6998579899182025 
2022-06-28 23:57:47,642: ============================================================
2022-06-28 23:57:47,642: Epoch 14/26 Batch 6900/7662 eta: 19:13:34.237307	Training Loss 3.7634 (3.7579)	Training Prec@1 98.438 (98.222)	Training Prec@5 99.219 (99.266)	
2022-06-28 23:57:47,642: ============================================================
2022-06-28 23:59:02,625: time cost, forward:0.011850561341450442, backward:0.030952142841357097, data cost:0.6999046052416864 
2022-06-28 23:59:02,626: ============================================================
2022-06-28 23:59:02,626: Epoch 14/26 Batch 7000/7662 eta: 19:17:20.283594	Training Loss 3.8759 (3.7597)	Training Prec@1 97.656 (98.217)	Training Prec@5 98.828 (99.263)	
2022-06-28 23:59:02,626: ============================================================
2022-06-29 00:00:18,326: time cost, forward:0.011861363537362939, backward:0.030947717886136306, data cost:0.7000924928672952 
2022-06-29 00:00:18,326: ============================================================
2022-06-29 00:00:18,327: Epoch 14/26 Batch 7100/7662 eta: 19:27:08.431813	Training Loss 3.7030 (3.7611)	Training Prec@1 98.242 (98.214)	Training Prec@5 99.414 (99.261)	
2022-06-29 00:00:18,327: ============================================================
2022-06-29 00:01:35,676: time cost, forward:0.011863932541334426, backward:0.030945835717603024, data cost:0.7005094625433546 
2022-06-29 00:01:35,677: ============================================================
2022-06-29 00:01:35,677: Epoch 14/26 Batch 7200/7662 eta: 19:51:17.126158	Training Loss 3.8440 (3.7623)	Training Prec@1 98.438 (98.209)	Training Prec@5 99.609 (99.259)	
2022-06-29 00:01:35,677: ============================================================
2022-06-29 00:02:50,137: time cost, forward:0.011865824538561592, backward:0.03095612605641453, data cost:0.7005101990284929 
2022-06-29 00:02:50,138: ============================================================
2022-06-29 00:02:50,138: Epoch 14/26 Batch 7300/7662 eta: 19:05:32.781702	Training Loss 4.0042 (3.7638)	Training Prec@1 98.047 (98.206)	Training Prec@5 98.633 (99.257)	
2022-06-29 00:02:50,138: ============================================================
2022-06-29 00:04:04,570: time cost, forward:0.011866343377457872, backward:0.030973655434134266, data cost:0.7005001282849849 
2022-06-29 00:04:04,571: ============================================================
2022-06-29 00:04:04,571: Epoch 14/26 Batch 7400/7662 eta: 19:03:52.420782	Training Loss 4.0198 (3.7652)	Training Prec@1 98.438 (98.202)	Training Prec@5 99.609 (99.256)	
2022-06-29 00:04:04,571: ============================================================
2022-06-29 00:05:20,128: time cost, forward:0.011864219829072506, backward:0.030974990956893617, data cost:0.7006570319681744 
2022-06-29 00:05:20,129: ============================================================
2022-06-29 00:05:20,129: Epoch 14/26 Batch 7500/7662 eta: 19:19:54.038707	Training Loss 3.8581 (3.7665)	Training Prec@1 97.656 (98.198)	Training Prec@5 99.219 (99.254)	
2022-06-29 00:05:20,129: ============================================================
2022-06-29 00:06:34,436: time cost, forward:0.011862007908671134, backward:0.03099113135671032, data cost:0.7006308683236503 
2022-06-29 00:06:34,437: ============================================================
2022-06-29 00:06:34,437: Epoch 14/26 Batch 7600/7662 eta: 18:59:28.428488	Training Loss 3.7481 (3.7675)	Training Prec@1 97.266 (98.194)	Training Prec@5 99.023 (99.252)	
2022-06-29 00:06:34,437: ============================================================
2022-06-29 00:07:23,827: Epoch: 14/26 eta: 18:58:41.614539	Training Loss 3.9947 (3.7680)	Training Prec@1 97.461 (98.192)	Training Prec@5 98.047 (99.251)
2022-06-29 00:07:23,827: ============================================================
2022-06-29 00:08:41,841: time cost, forward:0.01107272475656837, backward:0.029964377181698577, data cost:0.7414108526827109 
2022-06-29 00:08:41,841: ============================================================
2022-06-29 00:08:41,842: Epoch 15/26 Batch 100/7662 eta: 19:53:33.409351	Training Loss 3.3082 (3.3454)	Training Prec@1 98.438 (98.818)	Training Prec@5 99.414 (99.560)	
2022-06-29 00:08:41,842: ============================================================
2022-06-29 00:09:53,420: time cost, forward:0.011221679610822669, backward:0.029516042776443253, data cost:0.7079858660098896 
2022-06-29 00:09:53,421: ============================================================
2022-06-29 00:09:53,421: Epoch 15/26 Batch 200/7662 eta: 18:14:30.633456	Training Loss 3.5510 (3.3508)	Training Prec@1 98.633 (98.865)	Training Prec@5 99.023 (99.561)	
2022-06-29 00:09:53,421: ============================================================
2022-06-29 00:11:06,966: time cost, forward:0.011402299172902187, backward:0.029608740854422784, data cost:0.7030536849363193 
2022-06-29 00:11:06,966: ============================================================
2022-06-29 00:11:06,967: Epoch 15/26 Batch 300/7662 eta: 18:43:20.726753	Training Loss 3.3245 (3.3689)	Training Prec@1 98.047 (98.829)	Training Prec@5 99.414 (99.543)	
2022-06-29 00:11:06,967: ============================================================
2022-06-29 00:12:20,191: time cost, forward:0.01137224355138334, backward:0.029583814448880075, data cost:0.7000214892222469 
2022-06-29 00:12:20,191: ============================================================
2022-06-29 00:12:20,191: Epoch 15/26 Batch 400/7662 eta: 18:37:13.581056	Training Loss 3.4103 (3.3905)	Training Prec@1 98.242 (98.802)	Training Prec@5 99.219 (99.540)	
2022-06-29 00:12:20,192: ============================================================
2022-06-29 00:13:33,830: time cost, forward:0.0113512289547968, backward:0.02969333786285951, data cost:0.6989410100336781 
2022-06-29 00:13:33,831: ============================================================
2022-06-29 00:13:33,831: Epoch 15/26 Batch 500/7662 eta: 18:42:19.652677	Training Loss 3.3554 (3.4067)	Training Prec@1 98.242 (98.758)	Training Prec@5 99.609 (99.512)	
2022-06-29 00:13:33,831: ============================================================
2022-06-29 00:14:46,681: time cost, forward:0.011381125410331509, backward:0.029768564068216315, data cost:0.6968277623139956 
2022-06-29 00:14:46,681: ============================================================
2022-06-29 00:14:46,681: Epoch 15/26 Batch 600/7662 eta: 18:29:05.181520	Training Loss 3.1964 (3.4170)	Training Prec@1 98.633 (98.738)	Training Prec@5 99.414 (99.507)	
2022-06-29 00:14:46,681: ============================================================
2022-06-29 00:16:00,147: time cost, forward:0.011341527466780809, backward:0.02989628591250964, data cost:0.6962016467884374 
2022-06-29 00:16:00,147: ============================================================
2022-06-29 00:16:00,147: Epoch 15/26 Batch 700/7662 eta: 18:37:13.974110	Training Loss 3.4617 (3.4315)	Training Prec@1 99.414 (98.724)	Training Prec@5 99.414 (99.494)	
2022-06-29 00:16:00,147: ============================================================
2022-06-29 00:17:14,438: time cost, forward:0.011367161074030832, backward:0.029744442771462834, data cost:0.6969514710733082 
2022-06-29 00:17:14,439: ============================================================
2022-06-29 00:17:14,439: Epoch 15/26 Batch 800/7662 eta: 18:48:33.114883	Training Loss 3.4706 (3.4451)	Training Prec@1 98.242 (98.725)	Training Prec@5 99.609 (99.497)	
2022-06-29 00:17:14,439: ============================================================
2022-06-29 00:18:27,893: time cost, forward:0.011341474743122784, backward:0.029663615019886326, data cost:0.6966253992447731 
2022-06-29 00:18:27,893: ============================================================
2022-06-29 00:18:27,893: Epoch 15/26 Batch 900/7662 eta: 18:34:36.760627	Training Loss 3.5787 (3.4545)	Training Prec@1 98.828 (98.713)	Training Prec@5 99.805 (99.496)	
2022-06-29 00:18:27,894: ============================================================
2022-06-29 00:19:41,870: time cost, forward:0.011342471306985086, backward:0.02971490415128263, data cost:0.6967383679207619 
2022-06-29 00:19:41,870: ============================================================
2022-06-29 00:19:41,871: Epoch 15/26 Batch 1000/7662 eta: 18:41:18.518384	Training Loss 3.6418 (3.4679)	Training Prec@1 99.023 (98.696)	Training Prec@5 99.414 (99.488)	
2022-06-29 00:19:41,871: ============================================================
2022-06-29 00:20:55,762: time cost, forward:0.011383287466255722, backward:0.029743189590426333, data cost:0.6967420436991031 
2022-06-29 00:20:55,762: ============================================================
2022-06-29 00:20:55,763: Epoch 15/26 Batch 1100/7662 eta: 18:38:47.143829	Training Loss 3.3396 (3.4779)	Training Prec@1 99.023 (98.686)	Training Prec@5 99.609 (99.485)	
2022-06-29 00:20:55,763: ============================================================
2022-06-29 00:22:09,419: time cost, forward:0.01144021486023051, backward:0.029804580305097896, data cost:0.6964807410952049 
2022-06-29 00:22:09,419: ============================================================
2022-06-29 00:22:09,419: Epoch 15/26 Batch 1200/7662 eta: 18:33:59.639480	Training Loss 3.5151 (3.4892)	Training Prec@1 98.242 (98.668)	Training Prec@5 99.219 (99.475)	
2022-06-29 00:22:09,419: ============================================================
2022-06-29 00:23:23,640: time cost, forward:0.0114233838860304, backward:0.029615127645702524, data cost:0.6969931019187616 
2022-06-29 00:23:23,641: ============================================================
2022-06-29 00:23:23,641: Epoch 15/26 Batch 1300/7662 eta: 18:41:18.398452	Training Loss 3.6361 (3.4999)	Training Prec@1 97.852 (98.654)	Training Prec@5 98.828 (99.468)	
2022-06-29 00:23:23,641: ============================================================
2022-06-29 00:24:37,535: time cost, forward:0.011481572424538908, backward:0.02977180020821103, data cost:0.6968098620673092 
2022-06-29 00:24:37,536: ============================================================
2022-06-29 00:24:37,536: Epoch 15/26 Batch 1400/7662 eta: 18:35:08.112671	Training Loss 3.5725 (3.5072)	Training Prec@1 99.219 (98.647)	Training Prec@5 99.805 (99.465)	
2022-06-29 00:24:37,536: ============================================================
2022-06-29 00:25:50,741: time cost, forward:0.011479115470239843, backward:0.02987878206493538, data cost:0.6962702570158772 
2022-06-29 00:25:50,741: ============================================================
2022-06-29 00:25:50,741: Epoch 15/26 Batch 1500/7662 eta: 18:23:30.575287	Training Loss 3.6061 (3.5169)	Training Prec@1 98.438 (98.638)	Training Prec@5 99.219 (99.458)	
2022-06-29 00:25:50,741: ============================================================
2022-06-29 00:27:04,207: time cost, forward:0.011465301656812485, backward:0.029917980149956776, data cost:0.6960310512516482 
2022-06-29 00:27:04,207: ============================================================
2022-06-29 00:27:04,207: Epoch 15/26 Batch 1600/7662 eta: 18:26:13.006398	Training Loss 3.6409 (3.5254)	Training Prec@1 98.438 (98.623)	Training Prec@5 99.414 (99.452)	
2022-06-29 00:27:04,207: ============================================================
2022-06-29 00:28:17,131: time cost, forward:0.011481681523988218, backward:0.030039538349243666, data cost:0.6953836045874224 
2022-06-29 00:28:17,132: ============================================================
2022-06-29 00:28:17,132: Epoch 15/26 Batch 1700/7662 eta: 18:16:50.634329	Training Loss 3.5290 (3.5329)	Training Prec@1 97.656 (98.614)	Training Prec@5 99.414 (99.450)	
2022-06-29 00:28:17,132: ============================================================
2022-06-29 00:29:31,104: time cost, forward:0.011478821922501568, backward:0.02986943171778409, data cost:0.6956861277564887 
2022-06-29 00:29:31,104: ============================================================
2022-06-29 00:29:31,104: Epoch 15/26 Batch 1800/7662 eta: 18:31:22.527396	Training Loss 3.6103 (3.5422)	Training Prec@1 99.219 (98.599)	Training Prec@5 99.609 (99.444)	
2022-06-29 00:29:31,104: ============================================================
2022-06-29 00:30:45,976: time cost, forward:0.01147127164044212, backward:0.02987034877015767, data cost:0.6962723450763656 
2022-06-29 00:30:45,976: ============================================================
2022-06-29 00:30:45,977: Epoch 15/26 Batch 1900/7662 eta: 18:43:38.760307	Training Loss 3.7378 (3.5492)	Training Prec@1 97.852 (98.588)	Training Prec@5 99.414 (99.438)	
2022-06-29 00:30:45,977: ============================================================
2022-06-29 00:31:59,382: time cost, forward:0.011434875648578684, backward:0.029938764128463156, data cost:0.6960483248559399 
2022-06-29 00:31:59,382: ============================================================
2022-06-29 00:31:59,382: Epoch 15/26 Batch 2000/7662 eta: 18:20:24.794365	Training Loss 3.6211 (3.5563)	Training Prec@1 97.656 (98.579)	Training Prec@5 99.023 (99.432)	
2022-06-29 00:31:59,382: ============================================================
2022-06-29 00:33:12,213: time cost, forward:0.011445670198292434, backward:0.03001190208718571, data cost:0.6955021509049676 
2022-06-29 00:33:12,213: ============================================================
2022-06-29 00:33:12,213: Epoch 15/26 Batch 2100/7662 eta: 18:10:34.805106	Training Loss 3.6455 (3.5625)	Training Prec@1 97.656 (98.570)	Training Prec@5 99.414 (99.428)	
2022-06-29 00:33:12,213: ============================================================
2022-06-29 00:34:24,645: time cost, forward:0.011455495122239067, backward:0.030118675869451213, data cost:0.6948001773967803 
2022-06-29 00:34:24,645: ============================================================
2022-06-29 00:34:24,645: Epoch 15/26 Batch 2200/7662 eta: 18:03:24.298177	Training Loss 3.5768 (3.5688)	Training Prec@1 97.852 (98.558)	Training Prec@5 99.023 (99.422)	
2022-06-29 00:34:24,645: ============================================================
2022-06-29 00:35:38,060: time cost, forward:0.01147744706424748, backward:0.030111012017016516, data cost:0.6946598052356283 
2022-06-29 00:35:38,061: ============================================================
2022-06-29 00:35:38,061: Epoch 15/26 Batch 2300/7662 eta: 18:16:53.413820	Training Loss 3.7370 (3.5754)	Training Prec@1 98.633 (98.548)	Training Prec@5 99.609 (99.416)	
2022-06-29 00:35:38,061: ============================================================
2022-06-29 00:36:51,326: time cost, forward:0.011471944930604121, backward:0.03012011606726064, data cost:0.6944874378481026 
2022-06-29 00:36:51,326: ============================================================
2022-06-29 00:36:51,327: Epoch 15/26 Batch 2400/7662 eta: 18:13:25.697715	Training Loss 3.6514 (3.5822)	Training Prec@1 97.852 (98.535)	Training Prec@5 99.023 (99.411)	
2022-06-29 00:36:51,327: ============================================================
2022-06-29 00:38:05,383: time cost, forward:0.011487178012531917, backward:0.03013463600390718, data cost:0.6946155342782865 
2022-06-29 00:38:05,383: ============================================================
2022-06-29 00:38:05,384: Epoch 15/26 Batch 2500/7662 eta: 18:24:00.162879	Training Loss 3.3652 (3.5888)	Training Prec@1 99.219 (98.522)	Training Prec@5 99.609 (99.403)	
2022-06-29 00:38:05,384: ============================================================
2022-06-29 00:39:19,029: time cost, forward:0.01150766149214847, backward:0.030180471683750248, data cost:0.6945372710277503 
2022-06-29 00:39:19,030: ============================================================
2022-06-29 00:39:19,030: Epoch 15/26 Batch 2600/7662 eta: 18:16:39.592694	Training Loss 3.5725 (3.5936)	Training Prec@1 98.633 (98.514)	Training Prec@5 99.219 (99.399)	
2022-06-29 00:39:19,030: ============================================================
2022-06-29 00:40:31,334: time cost, forward:0.011500554952236315, backward:0.030124531361119488, data cost:0.6940963556255045 
2022-06-29 00:40:31,334: ============================================================
2022-06-29 00:40:31,334: Epoch 15/26 Batch 2700/7662 eta: 17:55:27.900679	Training Loss 3.7715 (3.5992)	Training Prec@1 98.828 (98.503)	Training Prec@5 99.023 (99.393)	
2022-06-29 00:40:31,334: ============================================================
2022-06-29 00:41:44,019: time cost, forward:0.011488273766433481, backward:0.03009396538047886, data cost:0.6938096071490648 
2022-06-29 00:41:44,019: ============================================================
2022-06-29 00:41:44,019: Epoch 15/26 Batch 2800/7662 eta: 17:59:54.805794	Training Loss 3.8450 (3.6041)	Training Prec@1 98.047 (98.493)	Training Prec@5 99.414 (99.390)	
2022-06-29 00:41:44,019: ============================================================
2022-06-29 00:42:58,140: time cost, forward:0.011519035416333664, backward:0.030114301528220096, data cost:0.6939407371167028 
2022-06-29 00:42:58,141: ============================================================
2022-06-29 00:42:58,141: Epoch 15/26 Batch 2900/7662 eta: 18:20:01.844017	Training Loss 3.7708 (3.6091)	Training Prec@1 98.438 (98.485)	Training Prec@5 99.219 (99.388)	
2022-06-29 00:42:58,141: ============================================================
2022-06-29 00:44:12,520: time cost, forward:0.01152086790580279, backward:0.03013856166917191, data cost:0.6941734618765388 
2022-06-29 00:44:12,520: ============================================================
2022-06-29 00:44:12,520: Epoch 15/26 Batch 3000/7662 eta: 18:22:36.803148	Training Loss 3.4342 (3.6133)	Training Prec@1 98.828 (98.477)	Training Prec@5 99.414 (99.385)	
2022-06-29 00:44:12,521: ============================================================
2022-06-29 00:45:25,993: time cost, forward:0.011516832312909816, backward:0.030164228558117206, data cost:0.6941006867567852 
2022-06-29 00:45:25,994: ============================================================
2022-06-29 00:45:25,994: Epoch 15/26 Batch 3100/7662 eta: 18:07:57.723846	Training Loss 3.7804 (3.6183)	Training Prec@1 99.023 (98.470)	Training Prec@5 99.805 (99.382)	
2022-06-29 00:45:25,994: ============================================================
2022-06-29 00:46:39,801: time cost, forward:0.011545188131090922, backward:0.030169211838088135, data cost:0.6941307992926237 
2022-06-29 00:46:39,801: ============================================================
2022-06-29 00:46:39,801: Epoch 15/26 Batch 3200/7662 eta: 18:11:40.011713	Training Loss 3.7962 (3.6222)	Training Prec@1 98.438 (98.463)	Training Prec@5 99.609 (99.380)	
2022-06-29 00:46:39,801: ============================================================
2022-06-29 00:47:51,675: time cost, forward:0.011527143777880245, backward:0.030155961460762222, data cost:0.6936243705657006 
2022-06-29 00:47:51,675: ============================================================
2022-06-29 00:47:51,675: Epoch 15/26 Batch 3300/7662 eta: 17:41:52.764850	Training Loss 3.7834 (3.6260)	Training Prec@1 98.633 (98.455)	Training Prec@5 99.805 (99.377)	
2022-06-29 00:47:51,675: ============================================================
2022-06-29 00:49:04,728: time cost, forward:0.011521039061000608, backward:0.0301797638994415, data cost:0.6934535481642892 
2022-06-29 00:49:04,729: ============================================================
2022-06-29 00:49:04,729: Epoch 15/26 Batch 3400/7662 eta: 17:58:05.315251	Training Loss 3.8773 (3.6296)	Training Prec@1 99.023 (98.450)	Training Prec@5 99.414 (99.375)	
2022-06-29 00:49:04,729: ============================================================
2022-06-29 00:50:18,681: time cost, forward:0.011526767714904629, backward:0.030223882753667098, data cost:0.6935169886234455 
2022-06-29 00:50:18,681: ============================================================
2022-06-29 00:50:18,682: Epoch 15/26 Batch 3500/7662 eta: 18:10:07.424728	Training Loss 3.5570 (3.6335)	Training Prec@1 99.219 (98.442)	Training Prec@5 99.805 (99.372)	
2022-06-29 00:50:18,682: ============================================================
2022-06-29 00:51:31,587: time cost, forward:0.011513968778007658, backward:0.030267366537553596, data cost:0.6932988520561573 
2022-06-29 00:51:31,588: ============================================================
2022-06-29 00:51:31,588: Epoch 15/26 Batch 3600/7662 eta: 17:53:29.014346	Training Loss 3.6595 (3.6379)	Training Prec@1 97.852 (98.433)	Training Prec@5 99.023 (99.369)	
2022-06-29 00:51:31,588: ============================================================
2022-06-29 00:52:45,231: time cost, forward:0.011512263783508779, backward:0.030274573968339206, data cost:0.6933172704336223 
2022-06-29 00:52:45,232: ============================================================
2022-06-29 00:52:45,232: Epoch 15/26 Batch 3700/7662 eta: 18:03:07.418833	Training Loss 3.9968 (3.6415)	Training Prec@1 98.047 (98.425)	Training Prec@5 99.219 (99.365)	
2022-06-29 00:52:45,232: ============================================================
2022-06-29 00:53:59,473: time cost, forward:0.01152480825307213, backward:0.030235202352007176, data cost:0.693525506496806 
2022-06-29 00:53:59,473: ============================================================
2022-06-29 00:53:59,473: Epoch 15/26 Batch 3800/7662 eta: 18:10:40.078881	Training Loss 3.6242 (3.6453)	Training Prec@1 99.023 (98.419)	Training Prec@5 99.805 (99.362)	
2022-06-29 00:53:59,474: ============================================================
2022-06-29 00:55:12,685: time cost, forward:0.011536917951847536, backward:0.03025131667079177, data cost:0.6934091301874248 
2022-06-29 00:55:12,685: ============================================================
2022-06-29 00:55:12,685: Epoch 15/26 Batch 3900/7662 eta: 17:54:19.423649	Training Loss 3.6912 (3.6489)	Training Prec@1 98.828 (98.414)	Training Prec@5 99.609 (99.361)	
2022-06-29 00:55:12,685: ============================================================
2022-06-29 00:56:27,410: time cost, forward:0.011546083914395957, backward:0.030212311066219466, data cost:0.6937263540757779 
2022-06-29 00:56:27,411: ============================================================
2022-06-29 00:56:27,411: Epoch 15/26 Batch 4000/7662 eta: 18:15:17.200585	Training Loss 3.4618 (3.6519)	Training Prec@1 99.219 (98.409)	Training Prec@5 99.805 (99.359)	
2022-06-29 00:56:27,411: ============================================================
2022-06-29 00:57:42,058: time cost, forward:0.011545919854340248, backward:0.030234253444331945, data cost:0.6939603955491516 
2022-06-29 00:57:42,059: ============================================================
2022-06-29 00:57:42,059: Epoch 15/26 Batch 4100/7662 eta: 18:12:54.586495	Training Loss 3.6335 (3.6557)	Training Prec@1 98.828 (98.400)	Training Prec@5 99.609 (99.356)	
2022-06-29 00:57:42,059: ============================================================
2022-06-29 00:58:54,255: time cost, forward:0.01157535340394767, backward:0.030296838292055796, data cost:0.693527764267909 
2022-06-29 00:58:54,255: ============================================================
2022-06-29 00:58:54,256: Epoch 15/26 Batch 4200/7662 eta: 17:35:48.951195	Training Loss 4.1017 (3.6589)	Training Prec@1 98.242 (98.392)	Training Prec@5 99.414 (99.351)	
2022-06-29 00:58:54,256: ============================================================
2022-06-29 01:00:08,251: time cost, forward:0.011570584028092726, backward:0.03029610517829705, data cost:0.6936279422988945 
2022-06-29 01:00:08,251: ============================================================
2022-06-29 01:00:08,251: Epoch 15/26 Batch 4300/7662 eta: 18:00:53.621643	Training Loss 3.7241 (3.6622)	Training Prec@1 99.023 (98.384)	Training Prec@5 99.609 (99.348)	
2022-06-29 01:00:08,251: ============================================================
2022-06-29 01:01:23,284: time cost, forward:0.011578254196746265, backward:0.030335525621959205, data cost:0.693908396621378 
2022-06-29 01:01:23,285: ============================================================
2022-06-29 01:01:23,285: Epoch 15/26 Batch 4400/7662 eta: 18:14:48.201101	Training Loss 3.6171 (3.6646)	Training Prec@1 97.656 (98.379)	Training Prec@5 99.414 (99.345)	
2022-06-29 01:01:23,285: ============================================================
2022-06-29 01:02:37,612: time cost, forward:0.011576817337209104, backward:0.030343163143292776, data cost:0.6940563730357302 
2022-06-29 01:02:37,612: ============================================================
2022-06-29 01:02:37,612: Epoch 15/26 Batch 4500/7662 eta: 18:03:15.595737	Training Loss 3.8856 (3.6673)	Training Prec@1 97.656 (98.372)	Training Prec@5 99.023 (99.342)	
2022-06-29 01:02:37,612: ============================================================
2022-06-29 01:03:51,006: time cost, forward:0.01157937046755239, backward:0.030389799711937022, data cost:0.6939541864820241 
2022-06-29 01:03:51,006: ============================================================
2022-06-29 01:03:51,007: Epoch 15/26 Batch 4600/7662 eta: 17:48:26.157818	Training Loss 3.9305 (3.6705)	Training Prec@1 97.266 (98.367)	Training Prec@5 98.633 (99.339)	
2022-06-29 01:03:51,007: ============================================================
2022-06-29 01:05:04,900: time cost, forward:0.01157002653003018, backward:0.030394182836382812, data cost:0.6940127091855286 
2022-06-29 01:05:04,900: ============================================================
2022-06-29 01:05:04,900: Epoch 15/26 Batch 4700/7662 eta: 17:54:28.605890	Training Loss 3.5660 (3.6733)	Training Prec@1 99.023 (98.361)	Training Prec@5 99.414 (99.337)	
2022-06-29 01:05:04,900: ============================================================
2022-06-29 01:06:19,767: time cost, forward:0.011567845446886086, backward:0.030399437421658407, data cost:0.6942649698426361 
2022-06-29 01:06:19,767: ============================================================
2022-06-29 01:06:19,767: Epoch 15/26 Batch 4800/7662 eta: 18:07:22.823970	Training Loss 3.9541 (3.6762)	Training Prec@1 97.656 (98.354)	Training Prec@5 99.023 (99.333)	
2022-06-29 01:06:19,767: ============================================================
2022-06-29 01:07:34,236: time cost, forward:0.011567807922705895, backward:0.03038552294558081, data cost:0.6944416005359813 
2022-06-29 01:07:34,237: ============================================================
2022-06-29 01:07:34,237: Epoch 15/26 Batch 4900/7662 eta: 18:00:21.909714	Training Loss 3.9571 (3.6790)	Training Prec@1 97.852 (98.348)	Training Prec@5 99.023 (99.329)	
2022-06-29 01:07:34,237: ============================================================
2022-06-29 01:08:48,170: time cost, forward:0.01156460144300894, backward:0.030413419586535716, data cost:0.6944687289699456 
2022-06-29 01:08:48,171: ============================================================
2022-06-29 01:08:48,171: Epoch 15/26 Batch 5000/7662 eta: 17:51:21.940152	Training Loss 3.8970 (3.6817)	Training Prec@1 97.461 (98.344)	Training Prec@5 99.023 (99.328)	
2022-06-29 01:08:48,171: ============================================================
2022-06-29 01:10:01,958: time cost, forward:0.011555135705981167, backward:0.030428373011731007, data cost:0.6944813970538489 
2022-06-29 01:10:01,958: ============================================================
2022-06-29 01:10:01,959: Epoch 15/26 Batch 5100/7662 eta: 17:48:01.136308	Training Loss 4.0506 (3.6839)	Training Prec@1 95.703 (98.337)	Training Prec@5 98.438 (99.325)	
2022-06-29 01:10:01,959: ============================================================
2022-06-29 01:11:15,254: time cost, forward:0.01155035049554407, backward:0.030430484446316276, data cost:0.6944096798758297 
2022-06-29 01:11:15,254: ============================================================
2022-06-29 01:11:15,255: Epoch 15/26 Batch 5200/7662 eta: 17:39:40.563292	Training Loss 3.8139 (3.6862)	Training Prec@1 98.438 (98.330)	Training Prec@5 99.609 (99.322)	
2022-06-29 01:11:15,255: ============================================================
2022-06-29 01:12:29,688: time cost, forward:0.011558598359815804, backward:0.030477462838024074, data cost:0.6944909658628177 
2022-06-29 01:12:29,688: ============================================================
2022-06-29 01:12:29,688: Epoch 15/26 Batch 5300/7662 eta: 17:54:53.036057	Training Loss 4.0295 (3.6885)	Training Prec@1 97.461 (98.324)	Training Prec@5 98.633 (99.319)	
2022-06-29 01:12:29,688: ============================================================
2022-06-29 01:13:43,452: time cost, forward:0.011560522377281238, backward:0.03049827324149564, data cost:0.694477711547015 
2022-06-29 01:13:43,453: ============================================================
2022-06-29 01:13:43,453: Epoch 15/26 Batch 5400/7662 eta: 17:43:59.569183	Training Loss 3.6723 (3.6911)	Training Prec@1 98.633 (98.319)	Training Prec@5 99.414 (99.316)	
2022-06-29 01:13:43,453: ============================================================
2022-06-29 01:14:57,246: time cost, forward:0.01156401877013916, backward:0.030504034354179897, data cost:0.6944856440767329 
2022-06-29 01:14:57,246: ============================================================
2022-06-29 01:14:57,247: Epoch 15/26 Batch 5500/7662 eta: 17:43:10.985176	Training Loss 3.6638 (3.6933)	Training Prec@1 97.852 (98.314)	Training Prec@5 99.609 (99.315)	
2022-06-29 01:14:57,247: ============================================================
2022-06-29 01:16:11,567: time cost, forward:0.011576577709666063, backward:0.030505575395350072, data cost:0.6945807327860529 
2022-06-29 01:16:11,567: ============================================================
2022-06-29 01:16:11,567: Epoch 15/26 Batch 5600/7662 eta: 17:49:32.232441	Training Loss 3.7061 (3.6950)	Training Prec@1 98.047 (98.310)	Training Prec@5 98.828 (99.313)	
2022-06-29 01:16:11,567: ============================================================
2022-06-29 01:17:25,661: time cost, forward:0.011587779508136536, backward:0.030512520588789307, data cost:0.6946305035080569 
2022-06-29 01:17:25,661: ============================================================
2022-06-29 01:17:25,661: Epoch 15/26 Batch 5700/7662 eta: 17:45:02.365041	Training Loss 3.9536 (3.6970)	Training Prec@1 98.047 (98.305)	Training Prec@5 99.219 (99.310)	
2022-06-29 01:17:25,661: ============================================================
2022-06-29 01:18:40,105: time cost, forward:0.011593018015575196, backward:0.0305006534894143, data cost:0.6947617531233892 
2022-06-29 01:18:40,106: ============================================================
2022-06-29 01:18:40,106: Epoch 15/26 Batch 5800/7662 eta: 17:48:50.371824	Training Loss 3.8708 (3.6989)	Training Prec@1 98.242 (98.301)	Training Prec@5 99.219 (99.307)	
2022-06-29 01:18:40,106: ============================================================
2022-06-29 01:19:54,358: time cost, forward:0.011609460362177176, backward:0.030471070497030725, data cost:0.6948644775801907 
2022-06-29 01:19:54,358: ============================================================
2022-06-29 01:19:54,358: Epoch 15/26 Batch 5900/7662 eta: 17:44:50.488180	Training Loss 3.7025 (3.7010)	Training Prec@1 98.047 (98.295)	Training Prec@5 99.414 (99.305)	
2022-06-29 01:19:54,359: ============================================================
2022-06-29 01:21:07,396: time cost, forward:0.011625430766374473, backward:0.030446840894482578, data cost:0.6947550011348835 
2022-06-29 01:21:07,396: ============================================================
2022-06-29 01:21:07,396: Epoch 15/26 Batch 6000/7662 eta: 17:26:12.352846	Training Loss 3.8188 (3.7027)	Training Prec@1 98.047 (98.291)	Training Prec@5 99.609 (99.303)	
2022-06-29 01:21:07,396: ============================================================
2022-06-29 01:22:22,760: time cost, forward:0.011643299491195566, backward:0.03045421464460016, data cost:0.6949988226946073 
2022-06-29 01:22:22,760: ============================================================
2022-06-29 01:22:22,760: Epoch 15/26 Batch 6100/7662 eta: 17:58:16.268442	Training Loss 3.7712 (3.7042)	Training Prec@1 98.438 (98.288)	Training Prec@5 99.414 (99.302)	
2022-06-29 01:22:22,760: ============================================================
2022-06-29 01:23:37,300: time cost, forward:0.011643684569972813, backward:0.030467224844157034, data cost:0.6951104823111103 
2022-06-29 01:23:37,301: ============================================================
2022-06-29 01:23:37,301: Epoch 15/26 Batch 6200/7662 eta: 17:45:14.653125	Training Loss 3.9004 (3.7061)	Training Prec@1 97.266 (98.283)	Training Prec@5 99.414 (99.299)	
2022-06-29 01:23:37,301: ============================================================
2022-06-29 01:24:51,744: time cost, forward:0.011640586821233154, backward:0.03045045544106083, data cost:0.6952372870193169 
2022-06-29 01:24:51,744: ============================================================
2022-06-29 01:24:51,744: Epoch 15/26 Batch 6300/7662 eta: 17:42:37.040865	Training Loss 4.0834 (3.7081)	Training Prec@1 97.266 (98.278)	Training Prec@5 98.633 (99.296)	
2022-06-29 01:24:51,744: ============================================================
2022-06-29 01:26:05,204: time cost, forward:0.011639300948624537, backward:0.03046518930291213, data cost:0.6951741961729416 
2022-06-29 01:26:05,205: ============================================================
2022-06-29 01:26:05,205: Epoch 15/26 Batch 6400/7662 eta: 17:27:22.055171	Training Loss 3.8554 (3.7095)	Training Prec@1 97.070 (98.273)	Training Prec@5 98.633 (99.294)	
2022-06-29 01:26:05,205: ============================================================
2022-06-29 01:27:18,438: time cost, forward:0.011638880619765759, backward:0.03045010001755876, data cost:0.6951067883118351 
2022-06-29 01:27:18,438: ============================================================
2022-06-29 01:27:18,438: Epoch 15/26 Batch 6500/7662 eta: 17:22:54.415822	Training Loss 3.8359 (3.7113)	Training Prec@1 98.242 (98.268)	Training Prec@5 99.219 (99.291)	
2022-06-29 01:27:18,439: ============================================================
2022-06-29 01:28:33,425: time cost, forward:0.011644972113158273, backward:0.030413764772098666, data cost:0.6953218704751991 
2022-06-29 01:28:33,425: ============================================================
2022-06-29 01:28:33,425: Epoch 15/26 Batch 6600/7662 eta: 17:46:37.584940	Training Loss 3.8667 (3.7129)	Training Prec@1 97.070 (98.263)	Training Prec@5 98.633 (99.290)	
2022-06-29 01:28:33,426: ============================================================
2022-06-29 01:29:46,653: time cost, forward:0.011647985486561442, backward:0.030412891263800923, data cost:0.6952383515727681 
2022-06-29 01:29:46,654: ============================================================
2022-06-29 01:29:46,654: Epoch 15/26 Batch 6700/7662 eta: 17:20:23.710539	Training Loss 3.9290 (3.7145)	Training Prec@1 98.242 (98.258)	Training Prec@5 99.414 (99.288)	
2022-06-29 01:29:46,654: ============================================================
2022-06-29 01:31:02,697: time cost, forward:0.011657448932868205, backward:0.030415106247516043, data cost:0.6955592084902317 
2022-06-29 01:31:02,698: ============================================================
2022-06-29 01:31:02,698: Epoch 15/26 Batch 6800/7662 eta: 17:59:07.591049	Training Loss 4.0990 (3.7165)	Training Prec@1 98.242 (98.252)	Training Prec@5 99.219 (99.285)	
2022-06-29 01:31:02,698: ============================================================
2022-06-29 01:32:17,318: time cost, forward:0.011658505471413819, backward:0.030434341184608072, data cost:0.6956563905833993 
2022-06-29 01:32:17,318: ============================================================
2022-06-29 01:32:17,318: Epoch 15/26 Batch 6900/7662 eta: 17:37:40.703196	Training Loss 3.7507 (3.7181)	Training Prec@1 98.047 (98.247)	Training Prec@5 99.414 (99.282)	
2022-06-29 01:32:17,318: ============================================================
2022-06-29 01:33:32,099: time cost, forward:0.011649767625909274, backward:0.030428093286016394, data cost:0.6958088356012071 
2022-06-29 01:33:32,099: ============================================================
2022-06-29 01:33:32,100: Epoch 15/26 Batch 7000/7662 eta: 17:38:43.113870	Training Loss 4.1417 (3.7194)	Training Prec@1 97.070 (98.244)	Training Prec@5 98.828 (99.281)	
2022-06-29 01:33:32,100: ============================================================
2022-06-29 01:34:47,247: time cost, forward:0.011648719957939821, backward:0.030433119711934353, data cost:0.6959901386322245 
2022-06-29 01:34:47,248: ============================================================
2022-06-29 01:34:47,248: Epoch 15/26 Batch 7100/7662 eta: 17:42:39.499827	Training Loss 3.8536 (3.7207)	Training Prec@1 98.828 (98.240)	Training Prec@5 99.805 (99.280)	
2022-06-29 01:34:47,248: ============================================================
2022-06-29 01:36:00,696: time cost, forward:0.0116450848190598, backward:0.03042473705597496, data cost:0.6959455668686131 
2022-06-29 01:36:00,696: ============================================================
2022-06-29 01:36:00,696: Epoch 15/26 Batch 7200/7662 eta: 17:17:23.943378	Training Loss 3.7960 (3.7223)	Training Prec@1 97.852 (98.237)	Training Prec@5 99.414 (99.278)	
2022-06-29 01:36:00,696: ============================================================
2022-06-29 01:37:15,592: time cost, forward:0.011650471772898026, backward:0.030431114920101227, data cost:0.6960788096838053 
2022-06-29 01:37:15,593: ============================================================
2022-06-29 01:37:15,593: Epoch 15/26 Batch 7300/7662 eta: 17:36:36.092268	Training Loss 3.8499 (3.7236)	Training Prec@1 98.633 (98.236)	Training Prec@5 99.219 (99.276)	
2022-06-29 01:37:15,593: ============================================================
2022-06-29 01:38:30,543: time cost, forward:0.011659277373189007, backward:0.030435950421919645, data cost:0.6962110817086006 
2022-06-29 01:38:30,543: ============================================================
2022-06-29 01:38:30,543: Epoch 15/26 Batch 7400/7662 eta: 17:36:06.978444	Training Loss 3.7786 (3.7250)	Training Prec@1 97.852 (98.232)	Training Prec@5 99.414 (99.274)	
2022-06-29 01:38:30,543: ============================================================
2022-06-29 01:39:44,729: time cost, forward:0.011649038270562947, backward:0.030431476556900296, data cost:0.6962675698233661 
2022-06-29 01:39:44,729: ============================================================
2022-06-29 01:39:44,729: Epoch 15/26 Batch 7500/7662 eta: 17:24:06.216390	Training Loss 3.8396 (3.7263)	Training Prec@1 98.047 (98.228)	Training Prec@5 99.414 (99.272)	
2022-06-29 01:39:44,729: ============================================================
2022-06-29 01:40:58,774: time cost, forward:0.011643724263318354, backward:0.030407942852106105, data cost:0.6963188101985233 
2022-06-29 01:40:58,775: ============================================================
2022-06-29 01:40:58,776: Epoch 15/26 Batch 7600/7662 eta: 17:20:54.368370	Training Loss 3.8053 (3.7277)	Training Prec@1 98.047 (98.225)	Training Prec@5 99.609 (99.270)	
2022-06-29 01:40:58,776: ============================================================
2022-06-29 01:41:47,266: Epoch: 15/26 eta: 17:20:07.719189	Training Loss 3.6721 (3.7286)	Training Prec@1 97.656 (98.223)	Training Prec@5 98.828 (99.269)
2022-06-29 01:41:47,267: ============================================================
2022-06-29 01:41:47,422: Save Checkpoint...
2022-06-29 01:41:47,422: ============================================================
2022-06-29 01:41:50,285: Save done!
2022-06-29 01:41:50,285: ============================================================
2022-06-29 01:43:10,917: time cost, forward:0.011349829760464754, backward:0.030148470040523644, data cost:0.7673723071512549 
2022-06-29 01:43:10,918: ============================================================
2022-06-29 01:43:10,918: Epoch 16/26 Batch 100/7662 eta: 18:50:44.432800	Training Loss 3.3763 (3.3157)	Training Prec@1 99.609 (98.889)	Training Prec@5 99.805 (99.530)	
2022-06-29 01:43:10,918: ============================================================
2022-06-29 01:44:25,595: time cost, forward:0.01136476310653303, backward:0.029800226939982504, data cost:0.7362509876040358 
2022-06-29 01:44:25,595: ============================================================
2022-06-29 01:44:25,596: Epoch 16/26 Batch 200/7662 eta: 17:26:31.077522	Training Loss 3.2108 (3.3293)	Training Prec@1 99.219 (98.835)	Training Prec@5 99.609 (99.539)	
2022-06-29 01:44:25,596: ============================================================
2022-06-29 01:45:41,444: time cost, forward:0.011499010998269787, backward:0.0291533262833305, data cost:0.7303336854762457 
2022-06-29 01:45:41,444: ============================================================
2022-06-29 01:45:41,444: Epoch 16/26 Batch 300/7662 eta: 17:41:40.085243	Training Loss 3.3666 (3.3340)	Training Prec@1 99.219 (98.864)	Training Prec@5 99.414 (99.552)	
2022-06-29 01:45:41,444: ============================================================
2022-06-29 01:46:58,163: time cost, forward:0.011309864527002014, backward:0.02915215492248535, data cost:0.7294577871050153 
2022-06-29 01:46:58,164: ============================================================
2022-06-29 01:46:58,164: Epoch 16/26 Batch 400/7662 eta: 17:52:34.764834	Training Loss 3.3956 (3.3516)	Training Prec@1 98.438 (98.846)	Training Prec@5 99.414 (99.548)	
2022-06-29 01:46:58,164: ============================================================
2022-06-29 01:48:14,037: time cost, forward:0.011212125808776978, backward:0.029013033142548526, data cost:0.7273641033975299 
2022-06-29 01:48:14,037: ============================================================
2022-06-29 01:48:14,037: Epoch 16/26 Batch 500/7662 eta: 17:39:28.965155	Training Loss 3.3431 (3.3713)	Training Prec@1 99.219 (98.823)	Training Prec@5 99.414 (99.545)	
2022-06-29 01:48:14,037: ============================================================
2022-06-29 01:49:31,227: time cost, forward:0.011145047233976387, backward:0.029014708004730175, data cost:0.7280745438621916 
2022-06-29 01:49:31,227: ============================================================
2022-06-29 01:49:31,227: Epoch 16/26 Batch 600/7662 eta: 17:56:34.657755	Training Loss 3.8477 (3.3881)	Training Prec@1 97.656 (98.807)	Training Prec@5 99.414 (99.537)	
2022-06-29 01:49:31,227: ============================================================
2022-06-29 01:50:46,815: time cost, forward:0.011098881818364789, backward:0.029107280725743808, data cost:0.7261968160391877 
2022-06-29 01:50:46,816: ============================================================
2022-06-29 01:50:46,816: Epoch 16/26 Batch 700/7662 eta: 17:32:59.509619	Training Loss 3.4238 (3.4037)	Training Prec@1 99.023 (98.801)	Training Prec@5 99.805 (99.531)	
2022-06-29 01:50:46,816: ============================================================
2022-06-29 01:52:00,822: time cost, forward:0.011215567439608044, backward:0.029203826405378396, data cost:0.7226386822209937 
2022-06-29 01:52:00,822: ============================================================
2022-06-29 01:52:00,822: Epoch 16/26 Batch 800/7662 eta: 17:09:42.554808	Training Loss 3.3705 (3.4164)	Training Prec@1 98.633 (98.783)	Training Prec@5 99.023 (99.521)	
2022-06-29 01:52:00,822: ============================================================
2022-06-29 01:53:15,291: time cost, forward:0.011260695133909367, backward:0.029357417406839576, data cost:0.7203279575861335 
2022-06-29 01:53:15,291: ============================================================
2022-06-29 01:53:15,291: Epoch 16/26 Batch 900/7662 eta: 17:14:54.402858	Training Loss 3.4448 (3.4290)	Training Prec@1 98.438 (98.760)	Training Prec@5 99.414 (99.511)	
2022-06-29 01:53:15,291: ============================================================
2022-06-29 01:54:29,363: time cost, forward:0.011246442317485332, backward:0.029250252831566917, data cost:0.7183702724712627 
2022-06-29 01:54:29,363: ============================================================
2022-06-29 01:54:29,363: Epoch 16/26 Batch 1000/7662 eta: 17:08:09.342878	Training Loss 3.7223 (3.4362)	Training Prec@1 97.266 (98.741)	Training Prec@5 99.023 (99.504)	
2022-06-29 01:54:29,363: ============================================================
2022-06-29 01:55:42,566: time cost, forward:0.011291976404580559, backward:0.029349077604812746, data cost:0.7157470661472255 
2022-06-29 01:55:42,567: ============================================================
2022-06-29 01:55:42,567: Epoch 16/26 Batch 1100/7662 eta: 16:54:53.033627	Training Loss 3.5030 (3.4491)	Training Prec@1 99.023 (98.723)	Training Prec@5 99.609 (99.497)	
2022-06-29 01:55:42,567: ============================================================
2022-06-29 01:56:57,421: time cost, forward:0.011363562988777574, backward:0.029515515972516056, data cost:0.7148185498123869 
2022-06-29 01:56:57,421: ============================================================
2022-06-29 01:56:57,421: Epoch 16/26 Batch 1200/7662 eta: 17:16:31.259296	Training Loss 3.7011 (3.4584)	Training Prec@1 98.633 (98.716)	Training Prec@5 99.609 (99.494)	
2022-06-29 01:56:57,421: ============================================================
2022-06-29 01:58:10,829: time cost, forward:0.011328262214572546, backward:0.029557347572978593, data cost:0.7131100356165861 
2022-06-29 01:58:10,829: ============================================================
2022-06-29 01:58:10,829: Epoch 16/26 Batch 1300/7662 eta: 16:55:16.460965	Training Loss 3.6799 (3.4684)	Training Prec@1 97.852 (98.702)	Training Prec@5 99.023 (99.488)	
2022-06-29 01:58:10,830: ============================================================
2022-06-29 01:59:24,695: time cost, forward:0.011306195364755082, backward:0.029435764473621295, data cost:0.7121287285216457 
2022-06-29 01:59:24,696: ============================================================
2022-06-29 01:59:24,696: Epoch 16/26 Batch 1400/7662 eta: 17:00:22.673099	Training Loss 3.8312 (3.4777)	Training Prec@1 97.461 (98.685)	Training Prec@5 99.219 (99.483)	
2022-06-29 01:59:24,696: ============================================================
2022-06-29 02:00:37,248: time cost, forward:0.01131888212085645, backward:0.02958680264865501, data cost:0.710111205143639 
2022-06-29 02:00:37,248: ============================================================
2022-06-29 02:00:37,248: Epoch 16/26 Batch 1500/7662 eta: 16:41:00.915028	Training Loss 3.3728 (3.4841)	Training Prec@1 99.414 (98.678)	Training Prec@5 99.609 (99.482)	
2022-06-29 02:00:37,248: ============================================================
2022-06-29 02:01:49,290: time cost, forward:0.0113097264514706, backward:0.02965732273867609, data cost:0.7081086883103571 
2022-06-29 02:01:49,290: ============================================================
2022-06-29 02:01:49,290: Epoch 16/26 Batch 1600/7662 eta: 16:32:46.670830	Training Loss 3.4302 (3.4928)	Training Prec@1 98.047 (98.663)	Training Prec@5 99.023 (99.474)	
2022-06-29 02:01:49,290: ============================================================
2022-06-29 02:03:03,528: time cost, forward:0.011373874508261049, backward:0.029790594410798073, data cost:0.7074895608137466 
2022-06-29 02:03:03,528: ============================================================
2022-06-29 02:03:03,528: Epoch 16/26 Batch 1700/7662 eta: 17:01:47.791842	Training Loss 3.5828 (3.5009)	Training Prec@1 98.242 (98.649)	Training Prec@5 99.414 (99.467)	
2022-06-29 02:03:03,528: ============================================================
2022-06-29 02:04:17,623: time cost, forward:0.011413663807943704, backward:0.029942115854726625, data cost:0.7068456726116628 
2022-06-29 02:04:17,623: ============================================================
2022-06-29 02:04:17,623: Epoch 16/26 Batch 1800/7662 eta: 16:58:35.888017	Training Loss 3.7845 (3.5089)	Training Prec@1 99.023 (98.632)	Training Prec@5 99.805 (99.460)	
2022-06-29 02:04:17,623: ============================================================
2022-06-29 02:05:31,271: time cost, forward:0.011404318832108195, backward:0.029966948219447967, data cost:0.7061943769329406 
2022-06-29 02:05:31,272: ============================================================
2022-06-29 02:05:31,272: Epoch 16/26 Batch 1900/7662 eta: 16:51:13.979450	Training Loss 4.0603 (3.5161)	Training Prec@1 97.852 (98.621)	Training Prec@5 98.828 (99.454)	
2022-06-29 02:05:31,272: ============================================================
2022-06-29 02:06:43,650: time cost, forward:0.011385970141900785, backward:0.030020025743729715, data cost:0.7049415465770452 
2022-06-29 02:06:43,650: ============================================================
2022-06-29 02:06:43,650: Epoch 16/26 Batch 2000/7662 eta: 16:32:35.084220	Training Loss 3.8236 (3.5214)	Training Prec@1 98.242 (98.612)	Training Prec@5 98.633 (99.450)	
2022-06-29 02:06:43,650: ============================================================
2022-06-29 02:07:57,410: time cost, forward:0.011415519051008875, backward:0.029996856159684542, data cost:0.7044950465238224 
2022-06-29 02:07:57,410: ============================================================
2022-06-29 02:07:57,410: Epoch 16/26 Batch 2100/7662 eta: 16:50:17.966042	Training Loss 3.9648 (3.5290)	Training Prec@1 97.656 (98.600)	Training Prec@5 99.023 (99.446)	
2022-06-29 02:07:57,410: ============================================================
2022-06-29 02:09:12,393: time cost, forward:0.011442979827367375, backward:0.029972410245394914, data cost:0.7046501883705837 
2022-06-29 02:09:12,393: ============================================================
2022-06-29 02:09:12,393: Epoch 16/26 Batch 2200/7662 eta: 17:05:48.412169	Training Loss 3.3773 (3.5355)	Training Prec@1 98.828 (98.590)	Training Prec@5 99.609 (99.442)	
2022-06-29 02:09:12,393: ============================================================
2022-06-29 02:10:25,852: time cost, forward:0.011416871426363726, backward:0.030016372596870147, data cost:0.7041150423276419 
2022-06-29 02:10:25,853: ============================================================
2022-06-29 02:10:25,853: Epoch 16/26 Batch 2300/7662 eta: 16:43:44.432515	Training Loss 3.8154 (3.5403)	Training Prec@1 98.438 (98.586)	Training Prec@5 99.609 (99.440)	
2022-06-29 02:10:25,853: ============================================================
2022-06-29 02:11:39,703: time cost, forward:0.011409884445266756, backward:0.03005686736494464, data cost:0.7037672833533722 
2022-06-29 02:11:39,703: ============================================================
2022-06-29 02:11:39,703: Epoch 16/26 Batch 2400/7662 eta: 16:47:50.972790	Training Loss 3.7795 (3.5471)	Training Prec@1 98.242 (98.579)	Training Prec@5 99.609 (99.438)	
2022-06-29 02:11:39,703: ============================================================
2022-06-29 02:12:53,731: time cost, forward:0.011403913352908301, backward:0.030051669868386807, data cost:0.7035640202889017 
2022-06-29 02:12:53,731: ============================================================
2022-06-29 02:12:53,732: Epoch 16/26 Batch 2500/7662 eta: 16:49:02.495602	Training Loss 3.7878 (3.5525)	Training Prec@1 98.438 (98.567)	Training Prec@5 99.609 (99.432)	
2022-06-29 02:12:53,732: ============================================================
2022-06-29 02:14:07,989: time cost, forward:0.011410857494540653, backward:0.030016457497867174, data cost:0.7034825310885058 
2022-06-29 02:14:07,989: ============================================================
2022-06-29 02:14:07,989: Epoch 16/26 Batch 2600/7662 eta: 16:50:55.868377	Training Loss 3.4873 (3.5582)	Training Prec@1 99.414 (98.554)	Training Prec@5 99.609 (99.427)	
2022-06-29 02:14:07,989: ============================================================
2022-06-29 02:15:20,863: time cost, forward:0.011396060037630582, backward:0.030044026355383, data cost:0.7028534792228379 
2022-06-29 02:15:20,864: ============================================================
2022-06-29 02:15:20,864: Epoch 16/26 Batch 2700/7662 eta: 16:30:53.231957	Training Loss 3.5267 (3.5633)	Training Prec@1 99.219 (98.541)	Training Prec@5 99.805 (99.421)	
2022-06-29 02:15:20,864: ============================================================
2022-06-29 02:16:35,576: time cost, forward:0.011434763403780421, backward:0.03012659644262839, data cost:0.7028174442067747 
2022-06-29 02:16:35,576: ============================================================
2022-06-29 02:16:35,576: Epoch 16/26 Batch 2800/7662 eta: 16:54:37.979070	Training Loss 3.6655 (3.5688)	Training Prec@1 98.828 (98.535)	Training Prec@5 99.805 (99.417)	
2022-06-29 02:16:35,576: ============================================================
2022-06-29 02:17:49,618: time cost, forward:0.011444250276558314, backward:0.030132307435529485, data cost:0.7026504137138533 
2022-06-29 02:17:49,618: ============================================================
2022-06-29 02:17:49,619: Epoch 16/26 Batch 2900/7662 eta: 16:44:17.957924	Training Loss 3.7952 (3.5734)	Training Prec@1 96.680 (98.526)	Training Prec@5 98.828 (99.415)	
2022-06-29 02:17:49,619: ============================================================
2022-06-29 02:19:03,355: time cost, forward:0.01147673232589574, backward:0.030192177229700346, data cost:0.7023113209551753 
2022-06-29 02:19:03,356: ============================================================
2022-06-29 02:19:03,356: Epoch 16/26 Batch 3000/7662 eta: 16:38:55.737559	Training Loss 3.8742 (3.5785)	Training Prec@1 98.047 (98.517)	Training Prec@5 99.609 (99.410)	
2022-06-29 02:19:03,356: ============================================================
2022-06-29 02:20:17,042: time cost, forward:0.011441713996609013, backward:0.030197799725084774, data cost:0.7021014819648351 
2022-06-29 02:20:17,042: ============================================================
2022-06-29 02:20:17,042: Epoch 16/26 Batch 3100/7662 eta: 16:37:00.850771	Training Loss 3.5582 (3.5827)	Training Prec@1 97.852 (98.509)	Training Prec@5 99.023 (99.405)	
2022-06-29 02:20:17,042: ============================================================
2022-06-29 02:21:30,913: time cost, forward:0.011458619380973584, backward:0.030250807261608587, data cost:0.7018567392624107 
2022-06-29 02:21:30,914: ============================================================
2022-06-29 02:21:30,914: Epoch 16/26 Batch 3200/7662 eta: 16:38:17.176548	Training Loss 3.8119 (3.5879)	Training Prec@1 97.070 (98.501)	Training Prec@5 99.219 (99.400)	
2022-06-29 02:21:30,914: ============================================================
2022-06-29 02:22:45,055: time cost, forward:0.011475844902138018, backward:0.030310172534559886, data cost:0.7017002214117822 
2022-06-29 02:22:45,055: ============================================================
2022-06-29 02:22:45,055: Epoch 16/26 Batch 3300/7662 eta: 16:40:42.117328	Training Loss 3.6692 (3.5926)	Training Prec@1 97.852 (98.493)	Training Prec@5 99.023 (99.396)	
2022-06-29 02:22:45,055: ============================================================
2022-06-29 02:23:59,128: time cost, forward:0.011476935972778823, backward:0.030322432693364727, data cost:0.70159233693131 
2022-06-29 02:23:59,128: ============================================================
2022-06-29 02:23:59,128: Epoch 16/26 Batch 3400/7662 eta: 16:38:32.482101	Training Loss 3.6459 (3.5969)	Training Prec@1 98.828 (98.485)	Training Prec@5 99.805 (99.393)	
2022-06-29 02:23:59,128: ============================================================
2022-06-29 02:25:12,766: time cost, forward:0.011468163624120528, backward:0.030355845699653723, data cost:0.7013584832253883 
2022-06-29 02:25:12,767: ============================================================
2022-06-29 02:25:12,767: Epoch 16/26 Batch 3500/7662 eta: 16:31:27.316246	Training Loss 3.7503 (3.6004)	Training Prec@1 98.242 (98.479)	Training Prec@5 99.805 (99.390)	
2022-06-29 02:25:12,767: ============================================================
2022-06-29 02:26:28,106: time cost, forward:0.01146876669552764, backward:0.030319223870300987, data cost:0.7016632048810114 
2022-06-29 02:26:28,107: ============================================================
2022-06-29 02:26:28,107: Epoch 16/26 Batch 3600/7662 eta: 16:53:06.741410	Training Loss 3.7513 (3.6042)	Training Prec@1 98.438 (98.475)	Training Prec@5 99.414 (99.388)	
2022-06-29 02:26:28,107: ============================================================
2022-06-29 02:27:42,646: time cost, forward:0.011470061374632337, backward:0.030215721640853697, data cost:0.7018061512449233 
2022-06-29 02:27:42,647: ============================================================
2022-06-29 02:27:42,647: Epoch 16/26 Batch 3700/7662 eta: 16:41:06.416775	Training Loss 3.6577 (3.6080)	Training Prec@1 98.438 (98.468)	Training Prec@5 99.219 (99.385)	
2022-06-29 02:27:42,647: ============================================================
2022-06-29 02:28:57,355: time cost, forward:0.01148220368767136, backward:0.030241374688325478, data cost:0.7018509908988935 
2022-06-29 02:28:57,356: ============================================================
2022-06-29 02:28:57,356: Epoch 16/26 Batch 3800/7662 eta: 16:42:07.988912	Training Loss 3.7321 (3.6121)	Training Prec@1 97.656 (98.461)	Training Prec@5 99.609 (99.381)	
2022-06-29 02:28:57,356: ============================================================
2022-06-29 02:30:10,507: time cost, forward:0.011495619133271509, backward:0.030281766740809225, data cost:0.701475991380921 
2022-06-29 02:30:10,507: ============================================================
2022-06-29 02:30:10,507: Epoch 16/26 Batch 3900/7662 eta: 16:20:01.535435	Training Loss 3.8489 (3.6152)	Training Prec@1 98.242 (98.454)	Training Prec@5 99.609 (99.379)	
2022-06-29 02:30:10,508: ============================================================
2022-06-29 02:31:24,703: time cost, forward:0.011491789463669933, backward:0.03027857539355084, data cost:0.7014389149574496 
2022-06-29 02:31:24,703: ============================================================
2022-06-29 02:31:24,703: Epoch 16/26 Batch 4000/7662 eta: 16:32:46.741263	Training Loss 3.8150 (3.6179)	Training Prec@1 97.852 (98.448)	Training Prec@5 99.609 (99.377)	
2022-06-29 02:31:24,703: ============================================================
2022-06-29 02:32:39,218: time cost, forward:0.011493419664433655, backward:0.030275749386621992, data cost:0.7014773953510628 
2022-06-29 02:32:39,218: ============================================================
2022-06-29 02:32:39,218: Epoch 16/26 Batch 4100/7662 eta: 16:35:48.196024	Training Loss 3.7141 (3.6203)	Training Prec@1 98.633 (98.441)	Training Prec@5 98.828 (99.374)	
2022-06-29 02:32:39,218: ============================================================
2022-06-29 02:33:52,561: time cost, forward:0.011495633419424785, backward:0.030308238890489586, data cost:0.7011975786123256 
2022-06-29 02:33:52,562: ============================================================
2022-06-29 02:33:52,562: Epoch 16/26 Batch 4200/7662 eta: 16:18:55.900134	Training Loss 3.9235 (3.6231)	Training Prec@1 98.438 (98.434)	Training Prec@5 99.414 (99.371)	
2022-06-29 02:33:52,562: ============================================================
2022-06-29 02:35:07,298: time cost, forward:0.011498013549861477, backward:0.030341217533935917, data cost:0.7012537996501084 
2022-06-29 02:35:07,299: ============================================================
2022-06-29 02:35:07,299: Epoch 16/26 Batch 4300/7662 eta: 16:36:16.957821	Training Loss 3.5754 (3.6262)	Training Prec@1 98.242 (98.426)	Training Prec@5 99.023 (99.367)	
2022-06-29 02:35:07,299: ============================================================
2022-06-29 02:36:22,295: time cost, forward:0.011505587313982215, backward:0.030368545375701703, data cost:0.7013659797004203 
2022-06-29 02:36:22,295: ============================================================
2022-06-29 02:36:22,296: Epoch 16/26 Batch 4400/7662 eta: 16:38:29.409160	Training Loss 4.0735 (3.6294)	Training Prec@1 96.875 (98.417)	Training Prec@5 98.438 (99.363)	
2022-06-29 02:36:22,296: ============================================================
2022-06-29 02:37:36,121: time cost, forward:0.011509434067691584, backward:0.030405882332796095, data cost:0.7012032901321312 
2022-06-29 02:37:36,121: ============================================================
2022-06-29 02:37:36,121: Epoch 16/26 Batch 4500/7662 eta: 16:21:40.344761	Training Loss 3.7927 (3.6322)	Training Prec@1 98.828 (98.411)	Training Prec@5 99.609 (99.360)	
2022-06-29 02:37:36,121: ============================================================
2022-06-29 02:38:49,982: time cost, forward:0.011514414079968477, backward:0.030425966135909647, data cost:0.7010695382703204 
2022-06-29 02:38:49,982: ============================================================
2022-06-29 02:38:49,983: Epoch 16/26 Batch 4600/7662 eta: 16:20:54.976614	Training Loss 4.0402 (3.6351)	Training Prec@1 97.266 (98.404)	Training Prec@5 99.023 (99.356)	
2022-06-29 02:38:49,983: ============================================================
2022-06-29 02:40:03,910: time cost, forward:0.011519987447689534, backward:0.030436526666070128, data cost:0.7009632639185777 
2022-06-29 02:40:03,910: ============================================================
2022-06-29 02:40:03,910: Epoch 16/26 Batch 4700/7662 eta: 16:20:33.975636	Training Loss 3.5959 (3.6378)	Training Prec@1 98.633 (98.398)	Training Prec@5 99.219 (99.354)	
2022-06-29 02:40:03,911: ============================================================
2022-06-29 02:41:18,114: time cost, forward:0.01152086322519724, backward:0.03044493974907047, data cost:0.7009271306528552 
2022-06-29 02:41:18,115: ============================================================
2022-06-29 02:41:18,115: Epoch 16/26 Batch 4800/7662 eta: 16:22:59.858287	Training Loss 3.8001 (3.6405)	Training Prec@1 97.070 (98.393)	Training Prec@5 99.219 (99.351)	
2022-06-29 02:41:18,115: ============================================================
2022-06-29 02:42:32,020: time cost, forward:0.011512435633543925, backward:0.0304442092967924, data cost:0.7008483400148234 
2022-06-29 02:42:32,020: ============================================================
2022-06-29 02:42:32,020: Epoch 16/26 Batch 4900/7662 eta: 16:17:48.440866	Training Loss 3.6329 (3.6430)	Training Prec@1 97.656 (98.386)	Training Prec@5 99.414 (99.348)	
2022-06-29 02:42:32,020: ============================================================
2022-06-29 02:43:46,295: time cost, forward:0.011512175682283063, backward:0.030453953415805233, data cost:0.7008279123933918 
2022-06-29 02:43:46,296: ============================================================
2022-06-29 02:43:46,296: Epoch 16/26 Batch 5000/7662 eta: 16:21:27.875901	Training Loss 3.7330 (3.6453)	Training Prec@1 98.828 (98.380)	Training Prec@5 99.219 (99.346)	
2022-06-29 02:43:46,296: ============================================================
2022-06-29 02:45:00,282: time cost, forward:0.011512582595265596, backward:0.030441166162724635, data cost:0.700771303124511 
2022-06-29 02:45:00,283: ============================================================
2022-06-29 02:45:00,283: Epoch 16/26 Batch 5100/7662 eta: 16:16:25.187934	Training Loss 3.4400 (3.6478)	Training Prec@1 99.219 (98.377)	Training Prec@5 99.609 (99.343)	
2022-06-29 02:45:00,283: ============================================================
2022-06-29 02:46:14,149: time cost, forward:0.011511058205708927, backward:0.030458753671662626, data cost:0.7006677146782483 
2022-06-29 02:46:14,149: ============================================================
2022-06-29 02:46:14,149: Epoch 16/26 Batch 5200/7662 eta: 16:13:35.814703	Training Loss 4.0003 (3.6508)	Training Prec@1 97.656 (98.373)	Training Prec@5 98.633 (99.341)	
2022-06-29 02:46:14,150: ============================================================
2022-06-29 02:47:27,573: time cost, forward:0.01150355498325962, backward:0.030460367654489784, data cost:0.7005058211366013 
2022-06-29 02:47:27,573: ============================================================
2022-06-29 02:47:27,573: Epoch 16/26 Batch 5300/7662 eta: 16:06:32.443855	Training Loss 3.9071 (3.6529)	Training Prec@1 96.875 (98.367)	Training Prec@5 99.219 (99.338)	
2022-06-29 02:47:27,574: ============================================================
2022-06-29 02:48:42,001: time cost, forward:0.011510295632989965, backward:0.030472090960123027, data cost:0.7005130713859031 
2022-06-29 02:48:42,001: ============================================================
2022-06-29 02:48:42,001: Epoch 16/26 Batch 5400/7662 eta: 16:18:30.812404	Training Loss 3.6035 (3.6552)	Training Prec@1 98.047 (98.362)	Training Prec@5 99.414 (99.335)	
2022-06-29 02:48:42,001: ============================================================
2022-06-29 02:49:56,806: time cost, forward:0.011507287938544091, backward:0.030465522534761848, data cost:0.700615021245526 
2022-06-29 02:49:56,807: ============================================================
2022-06-29 02:49:56,807: Epoch 16/26 Batch 5500/7662 eta: 16:22:14.356128	Training Loss 3.8956 (3.6577)	Training Prec@1 97.852 (98.355)	Training Prec@5 99.023 (99.332)	
2022-06-29 02:49:56,807: ============================================================
2022-06-29 02:51:10,802: time cost, forward:0.01149745148449077, backward:0.030477679995771688, data cost:0.7005581159126676 
2022-06-29 02:51:10,802: ============================================================
2022-06-29 02:51:10,803: Epoch 16/26 Batch 5600/7662 eta: 16:10:21.893028	Training Loss 3.6537 (3.6594)	Training Prec@1 98.438 (98.350)	Training Prec@5 99.219 (99.330)	
2022-06-29 02:51:10,803: ============================================================
2022-06-29 02:52:24,043: time cost, forward:0.011501429896330411, backward:0.030493783582656253, data cost:0.7003516520423039 
2022-06-29 02:52:24,044: ============================================================
2022-06-29 02:52:24,044: Epoch 16/26 Batch 5700/7662 eta: 15:59:15.289365	Training Loss 3.8998 (3.6617)	Training Prec@1 97.461 (98.344)	Training Prec@5 98.828 (99.327)	
2022-06-29 02:52:24,044: ============================================================
2022-06-29 02:53:38,839: time cost, forward:0.011506664236982767, backward:0.030474177063035644, data cost:0.700454844423647 
2022-06-29 02:53:38,839: ============================================================
2022-06-29 02:53:38,839: Epoch 16/26 Batch 5800/7662 eta: 16:18:21.446546	Training Loss 3.6974 (3.6636)	Training Prec@1 98.438 (98.339)	Training Prec@5 99.219 (99.325)	
2022-06-29 02:53:38,839: ============================================================
2022-06-29 02:54:53,240: time cost, forward:0.011513446827908051, backward:0.030494720415657588, data cost:0.700447471854363 
2022-06-29 02:54:53,241: ============================================================
2022-06-29 02:54:53,241: Epoch 16/26 Batch 5900/7662 eta: 16:11:58.214073	Training Loss 3.8191 (3.6652)	Training Prec@1 97.852 (98.335)	Training Prec@5 99.414 (99.324)	
2022-06-29 02:54:53,241: ============================================================
2022-06-29 02:56:07,165: time cost, forward:0.011520933600182652, backward:0.030522086934698364, data cost:0.700350920425532 
2022-06-29 02:56:07,166: ============================================================
2022-06-29 02:56:07,166: Epoch 16/26 Batch 6000/7662 eta: 16:04:30.799727	Training Loss 4.0774 (3.6667)	Training Prec@1 97.656 (98.333)	Training Prec@5 99.023 (99.322)	
2022-06-29 02:56:07,166: ============================================================
2022-06-29 02:57:21,395: time cost, forward:0.011515695240716892, backward:0.030525828682217253, data cost:0.7003443672297763 
2022-06-29 02:57:21,396: ============================================================
2022-06-29 02:57:21,396: Epoch 16/26 Batch 6100/7662 eta: 16:07:15.247066	Training Loss 3.8381 (3.6686)	Training Prec@1 98.633 (98.327)	Training Prec@5 98.828 (99.319)	
2022-06-29 02:57:21,396: ============================================================
2022-06-29 02:58:35,314: time cost, forward:0.011515673215705784, backward:0.03052849461136566, data cost:0.7002835568352502 
2022-06-29 02:58:35,315: ============================================================
2022-06-29 02:58:35,315: Epoch 16/26 Batch 6200/7662 eta: 16:01:58.227805	Training Loss 3.7118 (3.6704)	Training Prec@1 97.266 (98.322)	Training Prec@5 98.828 (99.316)	
2022-06-29 02:58:35,315: ============================================================
2022-06-29 02:59:49,515: time cost, forward:0.011526662483160827, backward:0.030548027004963216, data cost:0.7002384828033665 
2022-06-29 02:59:49,516: ============================================================
2022-06-29 02:59:49,516: Epoch 16/26 Batch 6300/7662 eta: 16:04:24.128254	Training Loss 3.6307 (3.6716)	Training Prec@1 97.852 (98.318)	Training Prec@5 99.023 (99.314)	
2022-06-29 02:59:49,516: ============================================================
2022-06-29 03:01:03,673: time cost, forward:0.011526839549438266, backward:0.030557680100197902, data cost:0.7002110049061001 
2022-06-29 03:01:03,673: ============================================================
2022-06-29 03:01:03,673: Epoch 16/26 Batch 6400/7662 eta: 16:02:36.074235	Training Loss 3.6092 (3.6730)	Training Prec@1 98.047 (98.314)	Training Prec@5 99.414 (99.312)	
2022-06-29 03:01:03,673: ============================================================
2022-06-29 03:02:18,469: time cost, forward:0.011536236780756234, backward:0.030565271489087168, data cost:0.7002710955273942 
2022-06-29 03:02:18,470: ============================================================
2022-06-29 03:02:18,470: Epoch 16/26 Batch 6500/7662 eta: 16:09:38.934309	Training Loss 3.7322 (3.6746)	Training Prec@1 98.047 (98.310)	Training Prec@5 99.414 (99.310)	
2022-06-29 03:02:18,470: ============================================================
2022-06-29 03:03:33,919: time cost, forward:0.011548996694269714, backward:0.030584990463395575, data cost:0.700415880540263 
2022-06-29 03:03:33,920: ============================================================
2022-06-29 03:03:33,920: Epoch 16/26 Batch 6600/7662 eta: 16:16:51.965223	Training Loss 3.8950 (3.6758)	Training Prec@1 98.438 (98.306)	Training Prec@5 99.609 (99.309)	
2022-06-29 03:03:33,920: ============================================================
2022-06-29 03:04:48,674: time cost, forward:0.011554591031835442, backward:0.030592003906461832, data cost:0.7004685828286794 
2022-06-29 03:04:48,675: ============================================================
2022-06-29 03:04:48,675: Epoch 16/26 Batch 6700/7662 eta: 16:06:36.959021	Training Loss 3.6343 (3.6778)	Training Prec@1 98.047 (98.302)	Training Prec@5 99.023 (99.307)	
2022-06-29 03:04:48,675: ============================================================
2022-06-29 03:06:02,360: time cost, forward:0.011553686109425865, backward:0.030596900887481605, data cost:0.7003725355277081 
2022-06-29 03:06:02,360: ============================================================
2022-06-29 03:06:02,360: Epoch 16/26 Batch 6800/7662 eta: 15:51:33.663292	Training Loss 3.7081 (3.6794)	Training Prec@1 97.266 (98.299)	Training Prec@5 99.219 (99.305)	
2022-06-29 03:06:02,360: ============================================================
2022-06-29 03:07:16,322: time cost, forward:0.011560363412888297, backward:0.030588596519274477, data cost:0.7003251251094081 
2022-06-29 03:07:16,322: ============================================================
2022-06-29 03:07:16,323: Epoch 16/26 Batch 6900/7662 eta: 15:53:54.359937	Training Loss 3.9985 (3.6813)	Training Prec@1 97.266 (98.294)	Training Prec@5 99.219 (99.303)	
2022-06-29 03:07:16,323: ============================================================
2022-06-29 03:08:30,904: time cost, forward:0.011559482778305836, backward:0.030577076998995548, data cost:0.7003790960599395 
2022-06-29 03:08:30,905: ============================================================
2022-06-29 03:08:30,905: Epoch 16/26 Batch 7000/7662 eta: 16:00:39.670295	Training Loss 3.8244 (3.6831)	Training Prec@1 97.461 (98.289)	Training Prec@5 99.414 (99.301)	
2022-06-29 03:08:30,905: ============================================================
2022-06-29 03:09:45,813: time cost, forward:0.011566973988615907, backward:0.030596204770587, data cost:0.7004379918834226 
2022-06-29 03:09:45,813: ============================================================
2022-06-29 03:09:45,813: Epoch 16/26 Batch 7100/7662 eta: 16:03:36.132879	Training Loss 3.8863 (3.6850)	Training Prec@1 99.023 (98.284)	Training Prec@5 99.414 (99.299)	
2022-06-29 03:09:45,813: ============================================================
2022-06-29 03:11:00,514: time cost, forward:0.011560919384506613, backward:0.030601494642475743, data cost:0.7004934175260564 
2022-06-29 03:11:00,514: ============================================================
2022-06-29 03:11:00,514: Epoch 16/26 Batch 7200/7662 eta: 15:59:41.797540	Training Loss 4.0615 (3.6862)	Training Prec@1 97.461 (98.281)	Training Prec@5 99.219 (99.297)	
2022-06-29 03:11:00,514: ============================================================
2022-06-29 03:12:14,730: time cost, forward:0.011565466811680143, backward:0.030609884038659413, data cost:0.7004683126503678 
2022-06-29 03:12:14,730: ============================================================
2022-06-29 03:12:14,731: Epoch 16/26 Batch 7300/7662 eta: 15:52:14.022154	Training Loss 3.8439 (3.6877)	Training Prec@1 97.852 (98.277)	Training Prec@5 99.609 (99.296)	
2022-06-29 03:12:14,731: ============================================================
2022-06-29 03:13:29,489: time cost, forward:0.011565216684167426, backward:0.030617306435135574, data cost:0.7005216795007092 
2022-06-29 03:13:29,489: ============================================================
2022-06-29 03:13:29,490: Epoch 16/26 Batch 7400/7662 eta: 15:57:56.982915	Training Loss 3.7042 (3.6891)	Training Prec@1 98.633 (98.272)	Training Prec@5 99.414 (99.294)	
2022-06-29 03:13:29,490: ============================================================
2022-06-29 03:14:45,235: time cost, forward:0.011572066744671995, backward:0.030624320561416247, data cost:0.7006996052791984 
2022-06-29 03:14:45,235: ============================================================
2022-06-29 03:14:45,236: Epoch 16/26 Batch 7500/7662 eta: 16:09:20.039503	Training Loss 3.7541 (3.6911)	Training Prec@1 98.242 (98.268)	Training Prec@5 98.828 (99.292)	
2022-06-29 03:14:45,236: ============================================================
2022-06-29 03:16:01,175: time cost, forward:0.011572585229513472, backward:0.030623947825772557, data cost:0.700909922100679 
2022-06-29 03:16:01,176: ============================================================
2022-06-29 03:16:01,176: Epoch 16/26 Batch 7600/7662 eta: 16:10:33.185059	Training Loss 3.9000 (3.6927)	Training Prec@1 97.461 (98.264)	Training Prec@5 99.414 (99.290)	
2022-06-29 03:16:01,176: ============================================================
2022-06-29 03:16:49,282: Epoch: 16/26 eta: 16:09:45.342765	Training Loss 3.9195 (3.6935)	Training Prec@1 95.898 (98.261)	Training Prec@5 98.633 (99.289)
2022-06-29 03:16:49,283: ============================================================
2022-06-29 03:18:07,937: time cost, forward:0.011451297336154513, backward:0.027841731755420415, data cost:0.7495405698063398 
2022-06-29 03:18:07,937: ============================================================
2022-06-29 03:18:07,938: Epoch 17/26 Batch 100/7662 eta: 16:42:27.893523	Training Loss 3.2931 (3.2714)	Training Prec@1 99.219 (98.929)	Training Prec@5 99.609 (99.619)	
2022-06-29 03:18:07,938: ============================================================
2022-06-29 03:19:21,070: time cost, forward:0.011773908557604306, backward:0.029118283909169873, data cost:0.7188182931449545 
2022-06-29 03:19:21,070: ============================================================
2022-06-29 03:19:21,070: Epoch 17/26 Batch 200/7662 eta: 15:31:28.905716	Training Loss 3.3840 (3.2975)	Training Prec@1 98.633 (98.879)	Training Prec@5 99.414 (99.603)	
2022-06-29 03:19:21,071: ============================================================
2022-06-29 03:20:34,011: time cost, forward:0.011992891496639188, backward:0.030043412211746674, data cost:0.7073845799551362 
2022-06-29 03:20:34,012: ============================================================
2022-06-29 03:20:34,012: Epoch 17/26 Batch 300/7662 eta: 15:27:49.524049	Training Loss 3.4960 (3.3146)	Training Prec@1 99.805 (98.876)	Training Prec@5 100.000 (99.585)	
2022-06-29 03:20:34,012: ============================================================
2022-06-29 03:21:47,211: time cost, forward:0.011899087662087348, backward:0.02978637523220894, data cost:0.7032339441447628 
2022-06-29 03:21:47,211: ============================================================
2022-06-29 03:21:47,211: Epoch 17/26 Batch 400/7662 eta: 15:29:53.430757	Training Loss 3.4794 (3.3247)	Training Prec@1 98.633 (98.833)	Training Prec@5 99.414 (99.560)	
2022-06-29 03:21:47,211: ============================================================
2022-06-29 03:23:00,086: time cost, forward:0.011605622534283655, backward:0.029607750370889484, data cost:0.7003684311448214 
2022-06-29 03:23:00,087: ============================================================
2022-06-29 03:23:00,087: Epoch 17/26 Batch 500/7662 eta: 15:24:33.604155	Training Loss 3.4593 (3.3376)	Training Prec@1 99.219 (98.826)	Training Prec@5 99.609 (99.560)	
2022-06-29 03:23:00,087: ============================================================
2022-06-29 03:24:13,048: time cost, forward:0.011562973509646815, backward:0.029495409215630992, data cost:0.6984564696807097 
2022-06-29 03:24:13,049: ============================================================
2022-06-29 03:24:13,049: Epoch 17/26 Batch 600/7662 eta: 15:24:26.305640	Training Loss 3.4352 (3.3557)	Training Prec@1 98.242 (98.811)	Training Prec@5 99.414 (99.552)	
2022-06-29 03:24:13,049: ============================================================
2022-06-29 03:25:26,554: time cost, forward:0.01151718329291828, backward:0.02920682645151032, data cost:0.698081669718752 
2022-06-29 03:25:26,555: ============================================================
2022-06-29 03:25:26,555: Epoch 17/26 Batch 700/7662 eta: 15:30:06.793845	Training Loss 3.5092 (3.3696)	Training Prec@1 97.656 (98.785)	Training Prec@5 99.023 (99.541)	
2022-06-29 03:25:26,555: ============================================================
2022-06-29 03:26:40,120: time cost, forward:0.01158415838535199, backward:0.02942842386840133, data cost:0.6973430063011351 
2022-06-29 03:26:40,120: ============================================================
2022-06-29 03:26:40,120: Epoch 17/26 Batch 800/7662 eta: 15:29:37.984066	Training Loss 3.5586 (3.3836)	Training Prec@1 98.438 (98.776)	Training Prec@5 99.219 (99.539)	
2022-06-29 03:26:40,121: ============================================================
2022-06-29 03:27:52,655: time cost, forward:0.011448667895409369, backward:0.029394043963796173, data cost:0.6960182675265099 
2022-06-29 03:27:52,656: ============================================================
2022-06-29 03:27:52,656: Epoch 17/26 Batch 900/7662 eta: 15:15:24.801871	Training Loss 3.4309 (3.3952)	Training Prec@1 99.414 (98.761)	Training Prec@5 99.805 (99.530)	
2022-06-29 03:27:52,656: ============================================================
2022-06-29 03:29:06,316: time cost, forward:0.011521447528231967, backward:0.02948446101970501, data cost:0.6957907667150488 
2022-06-29 03:29:06,317: ============================================================
2022-06-29 03:29:06,317: Epoch 17/26 Batch 1000/7662 eta: 15:28:22.902299	Training Loss 3.3629 (3.4068)	Training Prec@1 97.852 (98.744)	Training Prec@5 99.609 (99.520)	
2022-06-29 03:29:06,317: ============================================================
2022-06-29 03:30:20,249: time cost, forward:0.011590549357920152, backward:0.029627734037612763, data cost:0.6957553240035858 
2022-06-29 03:30:20,249: ============================================================
2022-06-29 03:30:20,250: Epoch 17/26 Batch 1100/7662 eta: 15:30:34.684236	Training Loss 3.3894 (3.4164)	Training Prec@1 99.219 (98.735)	Training Prec@5 99.609 (99.514)	
2022-06-29 03:30:20,250: ============================================================
2022-06-29 03:31:33,298: time cost, forward:0.011574574367914526, backward:0.029444809254255765, data cost:0.6953834067592032 
2022-06-29 03:31:33,298: ============================================================
2022-06-29 03:31:33,298: Epoch 17/26 Batch 1200/7662 eta: 15:18:13.932967	Training Loss 3.4891 (3.4265)	Training Prec@1 99.609 (98.721)	Training Prec@5 99.805 (99.505)	
2022-06-29 03:31:33,298: ============================================================
2022-06-29 03:32:46,830: time cost, forward:0.011549775099368898, backward:0.0295137635921863, data cost:0.6952189879751463 
2022-06-29 03:32:46,830: ============================================================
2022-06-29 03:32:46,830: Epoch 17/26 Batch 1300/7662 eta: 15:23:05.324198	Training Loss 3.3987 (3.4384)	Training Prec@1 98.633 (98.701)	Training Prec@5 99.805 (99.494)	
2022-06-29 03:32:46,831: ============================================================
2022-06-29 03:34:00,347: time cost, forward:0.011551589774949113, backward:0.029522647680428473, data cost:0.6950969767621622 
2022-06-29 03:34:00,347: ============================================================
2022-06-29 03:34:00,347: Epoch 17/26 Batch 1400/7662 eta: 15:21:40.054677	Training Loss 3.3627 (3.4462)	Training Prec@1 98.438 (98.690)	Training Prec@5 99.609 (99.492)	
2022-06-29 03:34:00,347: ============================================================
2022-06-29 03:35:14,396: time cost, forward:0.011568617709403518, backward:0.029595205034710234, data cost:0.6952668825255146 
2022-06-29 03:35:14,396: ============================================================
2022-06-29 03:35:14,397: Epoch 17/26 Batch 1500/7662 eta: 15:27:06.543456	Training Loss 3.8113 (3.4550)	Training Prec@1 97.852 (98.679)	Training Prec@5 99.023 (99.487)	
2022-06-29 03:35:14,397: ============================================================
2022-06-29 03:36:27,431: time cost, forward:0.011568090779994562, backward:0.02966587196073359, data cost:0.6947845683536208 
2022-06-29 03:36:27,431: ============================================================
2022-06-29 03:36:27,431: Epoch 17/26 Batch 1600/7662 eta: 15:13:11.575788	Training Loss 3.6091 (3.4640)	Training Prec@1 98.242 (98.663)	Training Prec@5 99.609 (99.479)	
2022-06-29 03:36:27,432: ============================================================
2022-06-29 03:37:40,982: time cost, forward:0.011562680833265317, backward:0.029650989036268175, data cost:0.6947496292379198 
2022-06-29 03:37:40,983: ============================================================
2022-06-29 03:37:40,983: Epoch 17/26 Batch 1700/7662 eta: 15:18:25.438816	Training Loss 3.6865 (3.4710)	Training Prec@1 98.438 (98.655)	Training Prec@5 99.219 (99.474)	
2022-06-29 03:37:40,983: ============================================================
2022-06-29 03:38:55,313: time cost, forward:0.011573487351244194, backward:0.02965459126509051, data cost:0.6951193988422608 
2022-06-29 03:38:55,313: ============================================================
2022-06-29 03:38:55,314: Epoch 17/26 Batch 1800/7662 eta: 15:26:55.011341	Training Loss 3.7793 (3.4784)	Training Prec@1 98.633 (98.646)	Training Prec@5 99.023 (99.469)	
2022-06-29 03:38:55,314: ============================================================
2022-06-29 03:40:06,572: time cost, forward:0.011572035316921272, backward:0.029670521734638425, data cost:0.6938271793708982 
2022-06-29 03:40:06,573: ============================================================
2022-06-29 03:40:06,573: Epoch 17/26 Batch 1900/7662 eta: 14:47:25.487319	Training Loss 3.6559 (3.4844)	Training Prec@1 97.656 (98.636)	Training Prec@5 99.414 (99.464)	
2022-06-29 03:40:06,573: ============================================================
2022-06-29 03:41:19,301: time cost, forward:0.011575980327199732, backward:0.02971978280590796, data cost:0.6933624069353174 
2022-06-29 03:41:19,302: ============================================================
2022-06-29 03:41:19,302: Epoch 17/26 Batch 2000/7662 eta: 15:04:31.122992	Training Loss 3.2528 (3.4908)	Training Prec@1 98.438 (98.630)	Training Prec@5 99.805 (99.461)	
2022-06-29 03:41:19,302: ============================================================
2022-06-29 03:42:33,890: time cost, forward:0.011594647166273491, backward:0.02968046948022647, data cost:0.6938935839147327 
2022-06-29 03:42:33,891: ============================================================
2022-06-29 03:42:33,891: Epoch 17/26 Batch 2100/7662 eta: 15:26:24.665896	Training Loss 3.5073 (3.4987)	Training Prec@1 98.633 (98.617)	Training Prec@5 99.219 (99.455)	
2022-06-29 03:42:33,891: ============================================================
2022-06-29 03:43:47,419: time cost, forward:0.011572810073720699, backward:0.02974212912333559, data cost:0.6938418820534256 
2022-06-29 03:43:47,419: ============================================================
2022-06-29 03:43:47,420: Epoch 17/26 Batch 2200/7662 eta: 15:12:00.751682	Training Loss 3.5292 (3.5050)	Training Prec@1 98.633 (98.607)	Training Prec@5 99.414 (99.452)	
2022-06-29 03:43:47,420: ============================================================
2022-06-29 03:45:01,302: time cost, forward:0.01158365813376023, backward:0.029823741377722236, data cost:0.6938882959879393 
2022-06-29 03:45:01,302: ============================================================
2022-06-29 03:45:01,303: Epoch 17/26 Batch 2300/7662 eta: 15:15:10.481049	Training Loss 3.8128 (3.5100)	Training Prec@1 98.633 (98.600)	Training Prec@5 100.000 (99.449)	
2022-06-29 03:45:01,303: ============================================================
2022-06-29 03:46:14,606: time cost, forward:0.01161044773930259, backward:0.029929973026671573, data cost:0.6936399631571799 
2022-06-29 03:46:14,607: ============================================================
2022-06-29 03:46:14,607: Epoch 17/26 Batch 2400/7662 eta: 15:06:47.262593	Training Loss 3.7725 (3.5152)	Training Prec@1 97.852 (98.592)	Training Prec@5 98.828 (99.444)	
2022-06-29 03:46:14,607: ============================================================
2022-06-29 03:47:26,800: time cost, forward:0.011604680400602623, backward:0.030041962253804108, data cost:0.6929829313355286 
2022-06-29 03:47:26,800: ============================================================
2022-06-29 03:47:26,800: Epoch 17/26 Batch 2500/7662 eta: 14:51:50.360202	Training Loss 3.5524 (3.5202)	Training Prec@1 98.633 (98.581)	Training Prec@5 99.609 (99.440)	
2022-06-29 03:47:26,800: ============================================================
2022-06-29 03:48:41,094: time cost, forward:0.01158473463230933, backward:0.03006459273205853, data cost:0.6932827493418818 
2022-06-29 03:48:41,094: ============================================================
2022-06-29 03:48:41,094: Epoch 17/26 Batch 2600/7662 eta: 15:16:33.239854	Training Loss 3.7780 (3.5262)	Training Prec@1 98.047 (98.571)	Training Prec@5 99.219 (99.436)	
2022-06-29 03:48:41,094: ============================================================
2022-06-29 03:49:54,415: time cost, forward:0.011558750904503024, backward:0.030119176969213724, data cost:0.693177128156144 
2022-06-29 03:49:54,415: ============================================================
2022-06-29 03:49:54,415: Epoch 17/26 Batch 2700/7662 eta: 15:03:19.651908	Training Loss 3.6817 (3.5315)	Training Prec@1 98.438 (98.560)	Training Prec@5 99.219 (99.432)	
2022-06-29 03:49:54,415: ============================================================
2022-06-29 03:51:08,560: time cost, forward:0.011558548643487656, backward:0.030158610461481387, data cost:0.6933548373808048 
2022-06-29 03:51:08,560: ============================================================
2022-06-29 03:51:08,561: Epoch 17/26 Batch 2800/7662 eta: 15:12:14.704342	Training Loss 3.8188 (3.5366)	Training Prec@1 97.852 (98.553)	Training Prec@5 99.609 (99.429)	
2022-06-29 03:51:08,561: ============================================================
2022-06-29 03:52:21,691: time cost, forward:0.01154676829177209, backward:0.030199253135567986, data cost:0.6931811884050741 
2022-06-29 03:52:21,692: ============================================================
2022-06-29 03:52:21,692: Epoch 17/26 Batch 2900/7662 eta: 14:58:33.070814	Training Loss 4.0757 (3.5424)	Training Prec@1 97.070 (98.542)	Training Prec@5 98.633 (99.424)	
2022-06-29 03:52:21,692: ============================================================
2022-06-29 03:53:35,055: time cost, forward:0.011556991063264578, backward:0.03020323137713894, data cost:0.6931080172641471 
2022-06-29 03:53:35,055: ============================================================
2022-06-29 03:53:35,056: Epoch 17/26 Batch 3000/7662 eta: 15:00:11.184648	Training Loss 3.6118 (3.5478)	Training Prec@1 98.242 (98.532)	Training Prec@5 99.609 (99.419)	
2022-06-29 03:53:35,056: ============================================================
2022-06-29 03:54:47,637: time cost, forward:0.011523066970293427, backward:0.030099769760309092, data cost:0.6929395855069352 
2022-06-29 03:54:47,637: ============================================================
2022-06-29 03:54:47,637: Epoch 17/26 Batch 3100/7662 eta: 14:49:22.736330	Training Loss 3.6975 (3.5526)	Training Prec@1 98.633 (98.525)	Training Prec@5 99.609 (99.416)	
2022-06-29 03:54:47,637: ============================================================
2022-06-29 03:56:02,343: time cost, forward:0.011507476035711653, backward:0.030116731206041903, data cost:0.6933139082266786 
2022-06-29 03:56:02,344: ============================================================
2022-06-29 03:56:02,344: Epoch 17/26 Batch 3200/7662 eta: 15:14:10.429727	Training Loss 3.7853 (3.5569)	Training Prec@1 98.633 (98.512)	Training Prec@5 99.609 (99.411)	
2022-06-29 03:56:02,344: ============================================================
2022-06-29 03:57:16,693: time cost, forward:0.011499036185919931, backward:0.03014534139098381, data cost:0.6935359206695418 
2022-06-29 03:57:16,693: ============================================================
2022-06-29 03:57:16,694: Epoch 17/26 Batch 3300/7662 eta: 15:08:33.853840	Training Loss 3.5244 (3.5611)	Training Prec@1 98.633 (98.503)	Training Prec@5 99.414 (99.407)	
2022-06-29 03:57:16,694: ============================================================
2022-06-29 03:58:30,839: time cost, forward:0.011504337134589936, backward:0.030191567477916192, data cost:0.6936567578816561 
2022-06-29 03:58:30,840: ============================================================
2022-06-29 03:58:30,840: Epoch 17/26 Batch 3400/7662 eta: 15:04:50.683154	Training Loss 3.5711 (3.5644)	Training Prec@1 99.023 (98.497)	Training Prec@5 99.414 (99.405)	
2022-06-29 03:58:30,840: ============================================================
2022-06-29 03:59:45,620: time cost, forward:0.011503404738324546, backward:0.03022338472526051, data cost:0.6939683835415814 
2022-06-29 03:59:45,620: ============================================================
2022-06-29 03:59:45,620: Epoch 17/26 Batch 3500/7662 eta: 15:11:20.029522	Training Loss 3.5641 (3.5680)	Training Prec@1 98.047 (98.491)	Training Prec@5 99.023 (99.404)	
2022-06-29 03:59:45,620: ============================================================
2022-06-29 04:01:00,499: time cost, forward:0.011511017462053906, backward:0.030261533728703157, data cost:0.6942730089729777 
2022-06-29 04:01:00,499: ============================================================
2022-06-29 04:01:00,499: Epoch 17/26 Batch 3600/7662 eta: 15:11:17.424323	Training Loss 3.5335 (3.5724)	Training Prec@1 98.047 (98.482)	Training Prec@5 99.219 (99.399)	
2022-06-29 04:01:00,499: ============================================================
2022-06-29 04:02:15,008: time cost, forward:0.0114919133816709, backward:0.03031647943361091, data cost:0.6944699698636647 
2022-06-29 04:02:15,008: ============================================================
2022-06-29 04:02:15,009: Epoch 17/26 Batch 3700/7662 eta: 15:05:33.027833	Training Loss 3.7073 (3.5758)	Training Prec@1 98.828 (98.473)	Training Prec@5 99.805 (99.396)	
2022-06-29 04:02:15,009: ============================================================
2022-06-29 04:03:29,664: time cost, forward:0.011486930199502863, backward:0.0303496324755575, data cost:0.6946967779005412 
2022-06-29 04:03:29,664: ============================================================
2022-06-29 04:03:29,664: Epoch 17/26 Batch 3800/7662 eta: 15:06:04.875184	Training Loss 3.8119 (3.5800)	Training Prec@1 98.242 (98.466)	Training Prec@5 99.219 (99.392)	
2022-06-29 04:03:29,664: ============================================================
2022-06-29 04:04:43,177: time cost, forward:0.011493360607952422, backward:0.030381752974438528, data cost:0.6946092972727304 
2022-06-29 04:04:43,177: ============================================================
2022-06-29 04:04:43,178: Epoch 17/26 Batch 3900/7662 eta: 14:50:59.783179	Training Loss 3.8374 (3.5838)	Training Prec@1 97.656 (98.459)	Training Prec@5 98.633 (99.390)	
2022-06-29 04:04:43,178: ============================================================
2022-06-29 04:05:56,649: time cost, forward:0.011494153438433614, backward:0.0304356791073455, data cost:0.6944998647904926 
2022-06-29 04:05:56,650: ============================================================
2022-06-29 04:05:56,650: Epoch 17/26 Batch 4000/7662 eta: 14:49:16.203709	Training Loss 3.5185 (3.5870)	Training Prec@1 98.242 (98.454)	Training Prec@5 99.609 (99.388)	
2022-06-29 04:05:56,650: ============================================================
2022-06-29 04:07:11,187: time cost, forward:0.011491501846090123, backward:0.030353660262424965, data cost:0.6947921590998162 
2022-06-29 04:07:11,187: ============================================================
2022-06-29 04:07:11,188: Epoch 17/26 Batch 4100/7662 eta: 15:00:55.523929	Training Loss 3.4281 (3.5903)	Training Prec@1 98.633 (98.448)	Training Prec@5 99.219 (99.385)	
2022-06-29 04:07:11,188: ============================================================
2022-06-29 04:08:25,058: time cost, forward:0.011490857439343206, backward:0.030387058971211522, data cost:0.6947977172672593 
2022-06-29 04:08:25,059: ============================================================
2022-06-29 04:08:25,059: Epoch 17/26 Batch 4200/7662 eta: 14:51:38.470047	Training Loss 3.7048 (3.5933)	Training Prec@1 98.438 (98.438)	Training Prec@5 99.414 (99.380)	
2022-06-29 04:08:25,059: ============================================================
2022-06-29 04:09:38,182: time cost, forward:0.01148628927879928, backward:0.030389537365388304, data cost:0.6946663276404385 
2022-06-29 04:09:38,182: ============================================================
2022-06-29 04:09:38,183: Epoch 17/26 Batch 4300/7662 eta: 14:41:23.636858	Training Loss 3.6476 (3.5966)	Training Prec@1 98.633 (98.433)	Training Prec@5 99.609 (99.377)	
2022-06-29 04:09:38,183: ============================================================
2022-06-29 04:10:51,856: time cost, forward:0.011487948078815436, backward:0.03039492761907211, data cost:0.6946524696801027 
2022-06-29 04:10:51,857: ============================================================
2022-06-29 04:10:51,857: Epoch 17/26 Batch 4400/7662 eta: 14:46:48.207520	Training Loss 3.7620 (3.5992)	Training Prec@1 97.266 (98.428)	Training Prec@5 99.219 (99.375)	
2022-06-29 04:10:51,857: ============================================================
2022-06-29 04:12:05,974: time cost, forward:0.011506070187685886, backward:0.030391785430229884, data cost:0.6947320200226311 
2022-06-29 04:12:05,974: ============================================================
2022-06-29 04:12:05,975: Epoch 17/26 Batch 4500/7662 eta: 14:50:54.578665	Training Loss 3.5695 (3.6015)	Training Prec@1 98.438 (98.422)	Training Prec@5 99.414 (99.373)	
2022-06-29 04:12:05,975: ============================================================
2022-06-29 04:13:18,954: time cost, forward:0.011502462512748505, backward:0.030404786281830385, data cost:0.6945626883953647 
2022-06-29 04:13:18,955: ============================================================
2022-06-29 04:13:18,955: Epoch 17/26 Batch 4600/7662 eta: 14:36:01.260308	Training Loss 3.8648 (3.6046)	Training Prec@1 98.828 (98.415)	Training Prec@5 99.609 (99.371)	
2022-06-29 04:13:18,955: ============================================================
2022-06-29 04:14:31,939: time cost, forward:0.011507979096897512, backward:0.03043117708894998, data cost:0.6943823641780895 
2022-06-29 04:14:31,939: ============================================================
2022-06-29 04:14:31,940: Epoch 17/26 Batch 4700/7662 eta: 14:34:51.130068	Training Loss 3.8643 (3.6074)	Training Prec@1 98.633 (98.410)	Training Prec@5 99.609 (99.369)	
2022-06-29 04:14:31,940: ============================================================
2022-06-29 04:15:47,296: time cost, forward:0.01152675935292547, backward:0.03043157539161003, data cost:0.6947108491010083 
2022-06-29 04:15:47,296: ============================================================
2022-06-29 04:15:47,297: Epoch 17/26 Batch 4800/7662 eta: 15:02:02.205675	Training Loss 3.6509 (3.6109)	Training Prec@1 98.438 (98.403)	Training Prec@5 99.023 (99.366)	
2022-06-29 04:15:47,297: ============================================================
2022-06-29 04:17:01,016: time cost, forward:0.011527474886739855, backward:0.030439004724817535, data cost:0.6947038734803567 
2022-06-29 04:17:01,016: ============================================================
2022-06-29 04:17:01,016: Epoch 17/26 Batch 4900/7662 eta: 14:41:12.437025	Training Loss 3.7238 (3.6134)	Training Prec@1 98.633 (98.398)	Training Prec@5 99.609 (99.364)	
2022-06-29 04:17:01,016: ============================================================
2022-06-29 04:18:14,901: time cost, forward:0.011523698897189107, backward:0.03041853678658095, data cost:0.6947606658191532 
2022-06-29 04:18:14,902: ============================================================
2022-06-29 04:18:14,902: Epoch 17/26 Batch 5000/7662 eta: 14:41:57.613837	Training Loss 3.7136 (3.6157)	Training Prec@1 98.633 (98.393)	Training Prec@5 99.414 (99.362)	
2022-06-29 04:18:14,902: ============================================================
2022-06-29 04:19:28,662: time cost, forward:0.011528531951889335, backward:0.030394989875139593, data cost:0.6947875574631512 
2022-06-29 04:19:28,663: ============================================================
2022-06-29 04:19:28,663: Epoch 17/26 Batch 5100/7662 eta: 14:39:14.744748	Training Loss 3.8652 (3.6185)	Training Prec@1 99.023 (98.388)	Training Prec@5 99.805 (99.359)	
2022-06-29 04:19:28,663: ============================================================
2022-06-29 04:20:40,840: time cost, forward:0.011508077537813974, backward:0.03036952137970012, data cost:0.6945385112512981 
2022-06-29 04:20:40,840: ============================================================
2022-06-29 04:20:40,840: Epoch 17/26 Batch 5200/7662 eta: 14:19:09.594120	Training Loss 3.5753 (3.6212)	Training Prec@1 97.266 (98.382)	Training Prec@5 98.633 (99.356)	
2022-06-29 04:20:40,840: ============================================================
2022-06-29 04:21:55,348: time cost, forward:0.011512248645213038, backward:0.030369749292379775, data cost:0.6946908193481354 
2022-06-29 04:21:55,349: ============================================================
2022-06-29 04:21:55,349: Epoch 17/26 Batch 5300/7662 eta: 14:45:40.302750	Training Loss 3.5025 (3.6233)	Training Prec@1 98.047 (98.378)	Training Prec@5 99.023 (99.355)	
2022-06-29 04:21:55,349: ============================================================
2022-06-29 04:23:10,557: time cost, forward:0.011524955792258373, backward:0.03038048496906968, data cost:0.6949442817803156 
2022-06-29 04:23:10,557: ============================================================
2022-06-29 04:23:10,558: Epoch 17/26 Batch 5400/7662 eta: 14:52:44.491596	Training Loss 3.6415 (3.6262)	Training Prec@1 97.656 (98.373)	Training Prec@5 99.414 (99.354)	
2022-06-29 04:23:10,558: ============================================================
2022-06-29 04:24:25,308: time cost, forward:0.011521454398513686, backward:0.030316805921916334, data cost:0.6951984432225315 
2022-06-29 04:24:25,308: ============================================================
2022-06-29 04:24:25,308: Epoch 17/26 Batch 5500/7662 eta: 14:46:03.378875	Training Loss 3.7235 (3.6287)	Training Prec@1 98.828 (98.369)	Training Prec@5 99.219 (99.351)	
2022-06-29 04:24:25,308: ============================================================
2022-06-29 04:25:38,179: time cost, forward:0.011510679989675258, backward:0.030287785580337505, data cost:0.6950823767608054 
2022-06-29 04:25:38,180: ============================================================
2022-06-29 04:25:38,180: Epoch 17/26 Batch 5600/7662 eta: 14:22:34.110866	Training Loss 3.8338 (3.6307)	Training Prec@1 97.656 (98.363)	Training Prec@5 99.023 (99.349)	
2022-06-29 04:25:38,180: ============================================================
2022-06-29 04:26:53,349: time cost, forward:0.011513582424733446, backward:0.03027878223458682, data cost:0.6953416947503532 
2022-06-29 04:26:53,350: ============================================================
2022-06-29 04:26:53,350: Epoch 17/26 Batch 5700/7662 eta: 14:48:31.276018	Training Loss 3.7454 (3.6324)	Training Prec@1 97.852 (98.358)	Training Prec@5 98.828 (99.347)	
2022-06-29 04:26:53,350: ============================================================
2022-06-29 04:28:07,673: time cost, forward:0.011519407399627007, backward:0.030275829456287904, data cost:0.6954345609385673 
2022-06-29 04:28:07,673: ============================================================
2022-06-29 04:28:07,673: Epoch 17/26 Batch 5800/7662 eta: 14:37:16.721860	Training Loss 3.7826 (3.6349)	Training Prec@1 98.633 (98.353)	Training Prec@5 99.414 (99.345)	
2022-06-29 04:28:07,673: ============================================================
2022-06-29 04:29:22,084: time cost, forward:0.01152875625919459, backward:0.030306174161373954, data cost:0.695502931737439 
2022-06-29 04:29:22,085: ============================================================
2022-06-29 04:29:22,085: Epoch 17/26 Batch 5900/7662 eta: 14:37:04.684369	Training Loss 3.7371 (3.6369)	Training Prec@1 98.438 (98.348)	Training Prec@5 99.805 (99.343)	
2022-06-29 04:29:22,085: ============================================================
2022-06-29 04:30:34,333: time cost, forward:0.011517642199704997, backward:0.030284121267436685, data cost:0.6952814611122398 
2022-06-29 04:30:34,333: ============================================================
2022-06-29 04:30:34,334: Epoch 17/26 Batch 6000/7662 eta: 14:10:22.684821	Training Loss 3.4946 (3.6387)	Training Prec@1 98.438 (98.343)	Training Prec@5 99.609 (99.341)	
2022-06-29 04:30:34,334: ============================================================
2022-06-29 04:31:47,644: time cost, forward:0.011525938483139866, backward:0.030292710196211565, data cost:0.6951923196404503 
2022-06-29 04:31:47,644: ============================================================
2022-06-29 04:31:47,644: Epoch 17/26 Batch 6100/7662 eta: 14:21:39.440890	Training Loss 4.0826 (3.6407)	Training Prec@1 97.266 (98.338)	Training Prec@5 98.242 (99.339)	
2022-06-29 04:31:47,644: ============================================================
2022-06-29 04:33:01,129: time cost, forward:0.011525288765075458, backward:0.030281549116203257, data cost:0.6951625674823577 
2022-06-29 04:33:01,129: ============================================================
2022-06-29 04:33:01,129: Epoch 17/26 Batch 6200/7662 eta: 14:22:28.818385	Training Loss 3.4591 (3.6426)	Training Prec@1 98.438 (98.333)	Training Prec@5 99.609 (99.336)	
2022-06-29 04:33:01,129: ============================================================
2022-06-29 04:34:15,593: time cost, forward:0.011536833141924635, backward:0.030281796911857038, data cost:0.6952647154511753 
2022-06-29 04:34:15,594: ============================================================
2022-06-29 04:34:15,594: Epoch 17/26 Batch 6300/7662 eta: 14:32:44.333747	Training Loss 4.0317 (3.6446)	Training Prec@1 97.266 (98.328)	Training Prec@5 98.633 (99.333)	
2022-06-29 04:34:15,594: ============================================================
2022-06-29 04:35:29,474: time cost, forward:0.011545729685582339, backward:0.030307390481573583, data cost:0.6952512093979337 
2022-06-29 04:35:29,475: ============================================================
2022-06-29 04:35:29,475: Epoch 17/26 Batch 6400/7662 eta: 14:24:39.851307	Training Loss 3.8854 (3.6455)	Training Prec@1 97.461 (98.324)	Training Prec@5 99.414 (99.332)	
2022-06-29 04:35:29,475: ============================================================
2022-06-29 04:36:42,682: time cost, forward:0.011555603457003452, backward:0.030321011819882032, data cost:0.6951416481236418 
2022-06-29 04:36:42,683: ============================================================
2022-06-29 04:36:42,683: Epoch 17/26 Batch 6500/7662 eta: 14:15:34.138174	Training Loss 3.5136 (3.6469)	Training Prec@1 99.023 (98.322)	Training Prec@5 99.414 (99.331)	
2022-06-29 04:36:42,683: ============================================================
2022-06-29 04:37:56,185: time cost, forward:0.01155625178716746, backward:0.030310452390862407, data cost:0.6951134907944597 
2022-06-29 04:37:56,185: ============================================================
2022-06-29 04:37:56,185: Epoch 17/26 Batch 6600/7662 eta: 14:17:47.307600	Training Loss 3.7694 (3.6486)	Training Prec@1 97.070 (98.318)	Training Prec@5 98.633 (99.329)	
2022-06-29 04:37:56,186: ============================================================
2022-06-29 04:39:10,242: time cost, forward:0.011560774326395643, backward:0.030309211035097938, data cost:0.6951552912590664 
2022-06-29 04:39:10,243: ============================================================
2022-06-29 04:39:10,243: Epoch 17/26 Batch 6700/7662 eta: 14:23:01.812510	Training Loss 3.7437 (3.6502)	Training Prec@1 98.047 (98.312)	Training Prec@5 99.219 (99.326)	
2022-06-29 04:39:10,243: ============================================================
2022-06-29 04:40:23,426: time cost, forward:0.011566603949954008, backward:0.030292067392413486, data cost:0.6950837581153125 
2022-06-29 04:40:23,426: ============================================================
2022-06-29 04:40:23,426: Epoch 17/26 Batch 6800/7662 eta: 14:11:37.302750	Training Loss 3.6757 (3.6523)	Training Prec@1 98.047 (98.309)	Training Prec@5 99.609 (99.323)	
2022-06-29 04:40:23,426: ============================================================
2022-06-29 04:41:36,833: time cost, forward:0.011568002138194493, backward:0.030289890904723085, data cost:0.6950357424070704 
2022-06-29 04:41:36,833: ============================================================
2022-06-29 04:41:36,833: Epoch 17/26 Batch 6900/7662 eta: 14:13:00.001428	Training Loss 3.4694 (3.6538)	Training Prec@1 98.633 (98.304)	Training Prec@5 99.805 (99.321)	
2022-06-29 04:41:36,833: ============================================================
2022-06-29 04:42:50,571: time cost, forward:0.011564812842122588, backward:0.03029199500887168, data cost:0.6950375664181361 
2022-06-29 04:42:50,571: ============================================================
2022-06-29 04:42:50,571: Epoch 17/26 Batch 7000/7662 eta: 14:15:37.260567	Training Loss 3.6408 (3.6553)	Training Prec@1 97.852 (98.300)	Training Prec@5 99.023 (99.319)	
2022-06-29 04:42:50,571: ============================================================
2022-06-29 04:44:05,802: time cost, forward:0.011561036261055969, backward:0.03028972368204085, data cost:0.69525488968852 
2022-06-29 04:44:05,802: ============================================================
2022-06-29 04:44:05,803: Epoch 17/26 Batch 7100/7662 eta: 14:31:41.468118	Training Loss 3.6996 (3.6568)	Training Prec@1 97.852 (98.296)	Training Prec@5 98.438 (99.317)	
2022-06-29 04:44:05,803: ============================================================
2022-06-29 04:45:19,909: time cost, forward:0.011559807470994355, backward:0.030299274933671003, data cost:0.6952949072655944 
2022-06-29 04:45:19,909: ============================================================
2022-06-29 04:45:19,909: Epoch 17/26 Batch 7200/7662 eta: 14:17:25.676883	Training Loss 3.8022 (3.6582)	Training Prec@1 98.438 (98.291)	Training Prec@5 98.633 (99.314)	
2022-06-29 04:45:19,909: ============================================================
2022-06-29 04:46:34,604: time cost, forward:0.01155649441401425, backward:0.030327328493667313, data cost:0.6953983104037885 
2022-06-29 04:46:34,604: ============================================================
2022-06-29 04:46:34,604: Epoch 17/26 Batch 7300/7662 eta: 14:22:59.144556	Training Loss 3.8362 (3.6597)	Training Prec@1 98.242 (98.287)	Training Prec@5 98.828 (99.313)	
2022-06-29 04:46:34,604: ============================================================
2022-06-29 04:47:47,561: time cost, forward:0.011556655817022837, backward:0.030345727598559198, data cost:0.695268573044345 
2022-06-29 04:47:47,562: ============================================================
2022-06-29 04:47:47,562: Epoch 17/26 Batch 7400/7662 eta: 14:01:42.086000	Training Loss 3.8826 (3.6609)	Training Prec@1 97.852 (98.283)	Training Prec@5 98.438 (99.311)	
2022-06-29 04:47:47,562: ============================================================
2022-06-29 04:49:02,403: time cost, forward:0.011568269311213337, backward:0.030351237116344517, data cost:0.6953957561874949 
2022-06-29 04:49:02,403: ============================================================
2022-06-29 04:49:02,404: Epoch 17/26 Batch 7500/7662 eta: 14:22:11.406823	Training Loss 3.6881 (3.6625)	Training Prec@1 98.828 (98.280)	Training Prec@5 99.609 (99.309)	
2022-06-29 04:49:02,404: ============================================================
2022-06-29 04:50:17,074: time cost, forward:0.011576985321416402, backward:0.030364168178158256, data cost:0.6954918992975885 
2022-06-29 04:50:17,075: ============================================================
2022-06-29 04:50:17,075: Epoch 17/26 Batch 7600/7662 eta: 14:18:58.707609	Training Loss 3.5410 (3.6638)	Training Prec@1 99.609 (98.277)	Training Prec@5 99.805 (99.307)	
2022-06-29 04:50:17,075: ============================================================
2022-06-29 04:51:05,023: Epoch: 17/26 eta: 14:18:11.664846	Training Loss 3.5628 (3.6647)	Training Prec@1 98.438 (98.275)	Training Prec@5 99.414 (99.306)
2022-06-29 04:51:05,023: ============================================================
2022-06-29 04:52:25,402: time cost, forward:0.011064630566221294, backward:0.02897738687919848, data cost:0.7652519905205929 
2022-06-29 04:52:25,402: ============================================================
2022-06-29 04:52:25,402: Epoch 18/26 Batch 100/7662 eta: 15:20:44.258884	Training Loss 3.2214 (3.2543)	Training Prec@1 98.633 (98.937)	Training Prec@5 99.414 (99.570)	
2022-06-29 04:52:25,403: ============================================================
2022-06-29 04:53:40,402: time cost, forward:0.011004185556766376, backward:0.02964280957552656, data cost:0.7366078654725348 
2022-06-29 04:53:40,402: ============================================================
2022-06-29 04:53:40,402: Epoch 18/26 Batch 200/7662 eta: 14:19:29.201312	Training Loss 3.3533 (3.2610)	Training Prec@1 99.609 (98.914)	Training Prec@5 100.000 (99.594)	
2022-06-29 04:53:40,403: ============================================================
2022-06-29 04:54:56,887: time cost, forward:0.010780662198529196, backward:0.029647520952001464, data cost:0.7325560639933201 
2022-06-29 04:54:56,888: ============================================================
2022-06-29 04:54:56,888: Epoch 18/26 Batch 300/7662 eta: 14:35:14.215525	Training Loss 3.3800 (3.2779)	Training Prec@1 99.023 (98.890)	Training Prec@5 99.609 (99.584)	
2022-06-29 04:54:56,888: ============================================================
2022-06-29 04:56:12,108: time cost, forward:0.010751630429337198, backward:0.02937722086607663, data cost:0.727537667243403 
2022-06-29 04:56:12,108: ============================================================
2022-06-29 04:56:12,108: Epoch 18/26 Batch 400/7662 eta: 14:19:30.341515	Training Loss 3.4058 (3.2967)	Training Prec@1 98.828 (98.870)	Training Prec@5 99.219 (99.579)	
2022-06-29 04:56:12,108: ============================================================
2022-06-29 04:57:26,832: time cost, forward:0.010698102041332421, backward:0.029208512487774622, data cost:0.7235763297530119 
2022-06-29 04:57:26,832: ============================================================
2022-06-29 04:57:26,832: Epoch 18/26 Batch 500/7662 eta: 14:12:35.132417	Training Loss 3.2756 (3.3095)	Training Prec@1 98.828 (98.857)	Training Prec@5 99.219 (99.574)	
2022-06-29 04:57:26,832: ============================================================
2022-06-29 04:58:43,131: time cost, forward:0.010726751588620805, backward:0.028843909949810558, data cost:0.7237562651626256 
2022-06-29 04:58:43,131: ============================================================
2022-06-29 04:58:43,131: Epoch 18/26 Batch 600/7662 eta: 14:29:17.326652	Training Loss 3.4808 (3.3222)	Training Prec@1 99.023 (98.847)	Training Prec@5 99.805 (99.572)	
2022-06-29 04:58:43,131: ============================================================
2022-06-29 04:59:56,844: time cost, forward:0.010784846689226971, backward:0.02894283193716505, data cost:0.7197944483531903 
2022-06-29 04:59:56,844: ============================================================
2022-06-29 04:59:56,844: Epoch 18/26 Batch 700/7662 eta: 13:58:35.917662	Training Loss 3.4283 (3.3355)	Training Prec@1 98.438 (98.822)	Training Prec@5 99.609 (99.553)	
2022-06-29 04:59:56,845: ============================================================
2022-06-29 05:01:10,733: time cost, forward:0.010862399102450909, backward:0.02907778742316369, data cost:0.7169443567345228 
2022-06-29 05:01:10,733: ============================================================
2022-06-29 05:01:10,733: Epoch 18/26 Batch 800/7662 eta: 13:59:21.984618	Training Loss 3.5526 (3.3503)	Training Prec@1 98.633 (98.810)	Training Prec@5 99.414 (99.542)	
2022-06-29 05:01:10,734: ============================================================
2022-06-29 05:02:24,005: time cost, forward:0.010933192075956385, backward:0.02921835917386913, data cost:0.7139849485093945 
2022-06-29 05:02:24,006: ============================================================
2022-06-29 05:02:24,006: Epoch 18/26 Batch 900/7662 eta: 13:51:08.602522	Training Loss 3.3145 (3.3651)	Training Prec@1 99.219 (98.789)	Training Prec@5 99.805 (99.531)	
2022-06-29 05:02:24,006: ============================================================
2022-06-29 05:03:37,681: time cost, forward:0.010945697685142418, backward:0.029219635733374365, data cost:0.7121923764546713 
2022-06-29 05:03:37,682: ============================================================
2022-06-29 05:03:37,682: Epoch 18/26 Batch 1000/7662 eta: 13:54:29.562035	Training Loss 3.1163 (3.3760)	Training Prec@1 99.023 (98.768)	Training Prec@5 99.414 (99.521)	
2022-06-29 05:03:37,682: ============================================================
2022-06-29 05:04:50,540: time cost, forward:0.010903274069274958, backward:0.02911906507039092, data cost:0.7101477192574137 
2022-06-29 05:04:50,541: ============================================================
2022-06-29 05:04:50,541: Epoch 18/26 Batch 1100/7662 eta: 13:44:01.263564	Training Loss 3.4888 (3.3904)	Training Prec@1 98.828 (98.743)	Training Prec@5 99.609 (99.511)	
2022-06-29 05:04:50,541: ============================================================
2022-06-29 05:06:03,470: time cost, forward:0.010956765811974252, backward:0.02926271094989538, data cost:0.708164331811582 
2022-06-29 05:06:03,470: ============================================================
2022-06-29 05:06:03,471: Epoch 18/26 Batch 1200/7662 eta: 13:43:36.410152	Training Loss 3.3988 (3.3999)	Training Prec@1 98.242 (98.734)	Training Prec@5 99.023 (99.505)	
2022-06-29 05:06:03,471: ============================================================
2022-06-29 05:07:16,842: time cost, forward:0.010963498490695498, backward:0.02922418633270851, data cost:0.7070379804151622 
2022-06-29 05:07:16,843: ============================================================
2022-06-29 05:07:16,843: Epoch 18/26 Batch 1300/7662 eta: 13:47:22.869222	Training Loss 3.6627 (3.4128)	Training Prec@1 98.242 (98.717)	Training Prec@5 99.023 (99.494)	
2022-06-29 05:07:16,843: ============================================================
2022-06-29 05:08:29,750: time cost, forward:0.010989066104193599, backward:0.029335465577775194, data cost:0.7055711995030063 
2022-06-29 05:08:29,751: ============================================================
2022-06-29 05:08:29,751: Epoch 18/26 Batch 1400/7662 eta: 13:40:55.874158	Training Loss 3.5159 (3.4205)	Training Prec@1 98.438 (98.711)	Training Prec@5 99.414 (99.492)	
2022-06-29 05:08:29,751: ============================================================
2022-06-29 05:09:42,435: time cost, forward:0.011070443599362465, backward:0.029478468204673883, data cost:0.7040350521461736 
2022-06-29 05:09:42,435: ============================================================
2022-06-29 05:09:42,436: Epoch 18/26 Batch 1500/7662 eta: 13:37:12.494498	Training Loss 3.3942 (3.4274)	Training Prec@1 98.828 (98.698)	Training Prec@5 99.219 (99.488)	
2022-06-29 05:09:42,436: ============================================================
2022-06-29 05:10:55,318: time cost, forward:0.011106731594913523, backward:0.029526970101714956, data cost:0.7029338081304993 
2022-06-29 05:10:55,318: ============================================================
2022-06-29 05:10:55,318: Epoch 18/26 Batch 1600/7662 eta: 13:38:13.119218	Training Loss 3.7549 (3.4353)	Training Prec@1 98.047 (98.689)	Training Prec@5 99.219 (99.485)	
2022-06-29 05:10:55,319: ============================================================
2022-06-29 05:12:08,729: time cost, forward:0.011145587104990456, backward:0.029519900776064346, data cost:0.702320009487527 
2022-06-29 05:12:08,730: ============================================================
2022-06-29 05:12:08,730: Epoch 18/26 Batch 1700/7662 eta: 13:42:55.884708	Training Loss 3.5091 (3.4432)	Training Prec@1 98.438 (98.681)	Training Prec@5 99.805 (99.485)	
2022-06-29 05:12:08,730: ============================================================
2022-06-29 05:13:22,369: time cost, forward:0.011155184273457382, backward:0.029543129055284008, data cost:0.7018936684954623 
2022-06-29 05:13:22,370: ============================================================
2022-06-29 05:13:22,370: Epoch 18/26 Batch 1800/7662 eta: 13:44:15.755412	Training Loss 3.6926 (3.4502)	Training Prec@1 97.852 (98.672)	Training Prec@5 98.828 (99.480)	
2022-06-29 05:13:22,370: ============================================================
2022-06-29 05:14:36,337: time cost, forward:0.011210539643547296, backward:0.029532165888926428, data cost:0.701673055084333 
2022-06-29 05:14:36,338: ============================================================
2022-06-29 05:14:36,338: Epoch 18/26 Batch 1900/7662 eta: 13:46:42.354083	Training Loss 3.5524 (3.4592)	Training Prec@1 98.633 (98.654)	Training Prec@5 99.414 (99.470)	
2022-06-29 05:14:36,338: ============================================================
2022-06-29 05:15:49,415: time cost, forward:0.01122136006300422, backward:0.029546437948092395, data cost:0.7010433918359937 
2022-06-29 05:15:49,415: ============================================================
2022-06-29 05:15:49,415: Epoch 18/26 Batch 2000/7662 eta: 13:35:31.721915	Training Loss 3.6303 (3.4667)	Training Prec@1 98.438 (98.638)	Training Prec@5 99.414 (99.465)	
2022-06-29 05:15:49,415: ============================================================
2022-06-29 05:17:02,407: time cost, forward:0.01120493456316653, backward:0.029490851969762095, data cost:0.7005299237184492 
2022-06-29 05:17:02,407: ============================================================
2022-06-29 05:17:02,408: Epoch 18/26 Batch 2100/7662 eta: 13:33:21.983888	Training Loss 3.5577 (3.4727)	Training Prec@1 98.828 (98.630)	Training Prec@5 99.609 (99.461)	
2022-06-29 05:17:02,408: ============================================================
2022-06-29 05:18:15,667: time cost, forward:0.011220206667911795, backward:0.029533198336245202, data cost:0.7000565589585592 
2022-06-29 05:18:15,668: ============================================================
2022-06-29 05:18:15,668: Epoch 18/26 Batch 2200/7662 eta: 13:35:07.793169	Training Loss 3.7482 (3.4791)	Training Prec@1 98.242 (98.621)	Training Prec@5 99.609 (99.458)	
2022-06-29 05:18:15,668: ============================================================
2022-06-29 05:19:28,988: time cost, forward:0.011228576749757664, backward:0.029531660366182797, data cost:0.6997036912120804 
2022-06-29 05:19:28,989: ============================================================
2022-06-29 05:19:28,989: Epoch 18/26 Batch 2300/7662 eta: 13:34:35.144468	Training Loss 3.8041 (3.4848)	Training Prec@1 98.242 (98.614)	Training Prec@5 99.219 (99.455)	
2022-06-29 05:19:28,989: ============================================================
2022-06-29 05:20:42,226: time cost, forward:0.011226208222911179, backward:0.029400022589400093, data cost:0.6994788048415445 
2022-06-29 05:20:42,227: ============================================================
2022-06-29 05:20:42,227: Epoch 18/26 Batch 2400/7662 eta: 13:32:26.307076	Training Loss 3.6990 (3.4909)	Training Prec@1 98.633 (98.609)	Training Prec@5 99.609 (99.453)	
2022-06-29 05:20:42,227: ============================================================
2022-06-29 05:21:55,285: time cost, forward:0.011220781456808798, backward:0.029390315143238692, data cost:0.6990957053101697 
2022-06-29 05:21:55,285: ============================================================
2022-06-29 05:21:55,285: Epoch 18/26 Batch 2500/7662 eta: 13:29:14.096542	Training Loss 3.5562 (3.4965)	Training Prec@1 99.219 (98.601)	Training Prec@5 99.805 (99.451)	
2022-06-29 05:21:55,286: ============================================================
2022-06-29 05:23:09,111: time cost, forward:0.01122385632675306, backward:0.02936938231887612, data cost:0.699036267410108 
2022-06-29 05:23:09,111: ============================================================
2022-06-29 05:23:09,111: Epoch 18/26 Batch 2600/7662 eta: 13:36:30.056255	Training Loss 3.7175 (3.5025)	Training Prec@1 97.461 (98.591)	Training Prec@5 99.219 (99.445)	
2022-06-29 05:23:09,111: ============================================================
2022-06-29 05:24:22,511: time cost, forward:0.01122251012759016, backward:0.02938651208216811, data cost:0.6987959507351763 
2022-06-29 05:24:22,511: ============================================================
2022-06-29 05:24:22,511: Epoch 18/26 Batch 2700/7662 eta: 13:30:34.030078	Training Loss 3.6450 (3.5064)	Training Prec@1 98.242 (98.582)	Training Prec@5 99.609 (99.442)	
2022-06-29 05:24:22,511: ============================================================
2022-06-29 05:25:37,029: time cost, forward:0.01122955221412607, backward:0.029450485134772122, data cost:0.6989192040999815 
2022-06-29 05:25:37,029: ============================================================
2022-06-29 05:25:37,030: Epoch 18/26 Batch 2800/7662 eta: 13:41:40.641633	Training Loss 3.7825 (3.5118)	Training Prec@1 98.242 (98.575)	Training Prec@5 99.414 (99.438)	
2022-06-29 05:25:37,030: ============================================================
2022-06-29 05:26:50,289: time cost, forward:0.011217812991791982, backward:0.029438769418480233, data cost:0.6986885630044085 
2022-06-29 05:26:50,290: ============================================================
2022-06-29 05:26:50,290: Epoch 18/26 Batch 2900/7662 eta: 13:26:34.916632	Training Loss 3.4492 (3.5166)	Training Prec@1 99.023 (98.565)	Training Prec@5 99.609 (99.432)	
2022-06-29 05:26:50,290: ============================================================
2022-06-29 05:28:03,351: time cost, forward:0.01123761931988906, backward:0.029437394331359355, data cost:0.6983635456572377 
2022-06-29 05:28:03,352: ============================================================
2022-06-29 05:28:03,352: Epoch 18/26 Batch 3000/7662 eta: 13:23:10.980644	Training Loss 3.8001 (3.5219)	Training Prec@1 98.828 (98.556)	Training Prec@5 99.805 (99.427)	
2022-06-29 05:28:03,352: ============================================================
2022-06-29 05:29:16,770: time cost, forward:0.011262373064132842, backward:0.02943868004687181, data cost:0.6981648214019549 
2022-06-29 05:29:16,771: ============================================================
2022-06-29 05:29:16,771: Epoch 18/26 Batch 3100/7662 eta: 13:25:52.992301	Training Loss 3.8292 (3.5266)	Training Prec@1 98.633 (98.548)	Training Prec@5 99.414 (99.423)	
2022-06-29 05:29:16,771: ============================================================
2022-06-29 05:30:30,924: time cost, forward:0.011274371530235318, backward:0.029445847484162912, data cost:0.6982136233294893 
2022-06-29 05:30:30,925: ============================================================
2022-06-29 05:30:30,925: Epoch 18/26 Batch 3200/7662 eta: 13:32:43.123768	Training Loss 3.6070 (3.5305)	Training Prec@1 98.438 (98.540)	Training Prec@5 99.609 (99.421)	
2022-06-29 05:30:30,925: ============================================================
2022-06-29 05:31:44,849: time cost, forward:0.01126538395484168, backward:0.029499032852251483, data cost:0.6981670200987345 
2022-06-29 05:31:44,850: ============================================================
2022-06-29 05:31:44,850: Epoch 18/26 Batch 3300/7662 eta: 13:28:58.246809	Training Loss 3.5753 (3.5345)	Training Prec@1 98.828 (98.535)	Training Prec@5 99.414 (99.418)	
2022-06-29 05:31:44,850: ============================================================
2022-06-29 05:32:58,406: time cost, forward:0.011284002453904181, backward:0.02947862339777328, data cost:0.6980540772051137 
2022-06-29 05:32:58,406: ============================================================
2022-06-29 05:32:58,406: Epoch 18/26 Batch 3400/7662 eta: 13:23:42.786547	Training Loss 3.6490 (3.5384)	Training Prec@1 99.219 (98.530)	Training Prec@5 99.805 (99.416)	
2022-06-29 05:32:58,406: ============================================================
2022-06-29 05:34:12,905: time cost, forward:0.011310791349233849, backward:0.02950269196775512, data cost:0.6981681932480412 
2022-06-29 05:34:12,905: ============================================================
2022-06-29 05:34:12,905: Epoch 18/26 Batch 3500/7662 eta: 13:32:46.306544	Training Loss 3.6648 (3.5416)	Training Prec@1 98.438 (98.522)	Training Prec@5 99.805 (99.414)	
2022-06-29 05:34:12,905: ============================================================
2022-06-29 05:35:26,175: time cost, forward:0.011316146344468142, backward:0.029520380129314655, data cost:0.6979594363805882 
2022-06-29 05:35:26,176: ============================================================
2022-06-29 05:35:26,176: Epoch 18/26 Batch 3600/7662 eta: 13:18:09.039495	Training Loss 3.8024 (3.5460)	Training Prec@1 99.023 (98.513)	Training Prec@5 99.414 (99.410)	
2022-06-29 05:35:26,176: ============================================================
2022-06-29 05:36:40,040: time cost, forward:0.011329513267750158, backward:0.029492732478851046, data cost:0.6979550565052883 
2022-06-29 05:36:40,040: ============================================================
2022-06-29 05:36:40,040: Epoch 18/26 Batch 3700/7662 eta: 13:23:23.260691	Training Loss 3.5785 (3.5500)	Training Prec@1 99.023 (98.505)	Training Prec@5 99.609 (99.407)	
2022-06-29 05:36:40,041: ============================================================
2022-06-29 05:37:53,735: time cost, forward:0.01135961863203217, backward:0.02951722114956608, data cost:0.697842811213948 
2022-06-29 05:37:53,736: ============================================================
2022-06-29 05:37:53,736: Epoch 18/26 Batch 3800/7662 eta: 13:20:19.203396	Training Loss 3.5398 (3.5531)	Training Prec@1 98.242 (98.499)	Training Prec@5 99.219 (99.405)	
2022-06-29 05:37:53,736: ============================================================
2022-06-29 05:39:07,445: time cost, forward:0.01134985304698176, backward:0.029422424792876517, data cost:0.6978927150265503 
2022-06-29 05:39:07,446: ============================================================
2022-06-29 05:39:07,446: Epoch 18/26 Batch 3900/7662 eta: 13:19:15.046006	Training Loss 3.4840 (3.5564)	Training Prec@1 98.438 (98.493)	Training Prec@5 99.023 (99.402)	
2022-06-29 05:39:07,446: ============================================================
2022-06-29 05:40:21,305: time cost, forward:0.011345719361072721, backward:0.02942286488055348, data cost:0.6978814302011859 
2022-06-29 05:40:21,306: ============================================================
2022-06-29 05:40:21,306: Epoch 18/26 Batch 4000/7662 eta: 13:19:38.655847	Training Loss 3.5614 (3.5601)	Training Prec@1 97.852 (98.487)	Training Prec@5 99.414 (99.398)	
2022-06-29 05:40:21,306: ============================================================
2022-06-29 05:41:35,010: time cost, forward:0.011348265035759097, backward:0.029350889924387433, data cost:0.6979040877357813 
2022-06-29 05:41:35,010: ============================================================
2022-06-29 05:41:35,010: Epoch 18/26 Batch 4100/7662 eta: 13:16:43.987712	Training Loss 3.5903 (3.5633)	Training Prec@1 97.852 (98.481)	Training Prec@5 98.438 (99.394)	
2022-06-29 05:41:35,010: ============================================================
2022-06-29 05:42:48,662: time cost, forward:0.011353247618215314, backward:0.029306013546094464, data cost:0.6978848465399164 
2022-06-29 05:42:48,662: ============================================================
2022-06-29 05:42:48,662: Epoch 18/26 Batch 4200/7662 eta: 13:14:56.145177	Training Loss 3.7996 (3.5664)	Training Prec@1 98.242 (98.474)	Training Prec@5 99.219 (99.391)	
2022-06-29 05:42:48,662: ============================================================
2022-06-29 05:44:01,941: time cost, forward:0.011362428747240569, backward:0.02923820994293504, data cost:0.6977979230669993 
2022-06-29 05:44:01,941: ============================================================
2022-06-29 05:44:01,941: Epoch 18/26 Batch 4300/7662 eta: 13:09:41.513344	Training Loss 3.6561 (3.5695)	Training Prec@1 98.047 (98.468)	Training Prec@5 99.414 (99.388)	
2022-06-29 05:44:01,941: ============================================================
2022-06-29 05:45:15,150: time cost, forward:0.011374184477733033, backward:0.029272476633344625, data cost:0.6975987704945412 
2022-06-29 05:45:15,151: ============================================================
2022-06-29 05:45:15,151: Epoch 18/26 Batch 4400/7662 eta: 13:07:43.475382	Training Loss 3.6995 (3.5722)	Training Prec@1 97.852 (98.462)	Training Prec@5 98.633 (99.384)	
2022-06-29 05:45:15,151: ============================================================
2022-06-29 05:46:28,607: time cost, forward:0.011372730821523435, backward:0.029323319854617624, data cost:0.6974573344701024 
2022-06-29 05:46:28,607: ============================================================
2022-06-29 05:46:28,607: Epoch 18/26 Batch 4500/7662 eta: 13:09:09.281570	Training Loss 3.8042 (3.5752)	Training Prec@1 98.828 (98.456)	Training Prec@5 99.609 (99.381)	
2022-06-29 05:46:28,607: ============================================================
2022-06-29 05:47:42,998: time cost, forward:0.011374799135742719, backward:0.029351501004492155, data cost:0.6975459197107204 
2022-06-29 05:47:42,999: ============================================================
2022-06-29 05:47:42,999: Epoch 18/26 Batch 4600/7662 eta: 13:17:57.645584	Training Loss 3.8162 (3.5789)	Training Prec@1 97.266 (98.448)	Training Prec@5 98.828 (99.377)	
2022-06-29 05:47:42,999: ============================================================
2022-06-29 05:48:58,024: time cost, forward:0.011385592330539701, backward:0.02937480865019031, data cost:0.6977538523660819 
2022-06-29 05:48:58,025: ============================================================
2022-06-29 05:48:58,025: Epoch 18/26 Batch 4700/7662 eta: 13:23:30.985391	Training Loss 3.6294 (3.5818)	Training Prec@1 97.656 (98.443)	Training Prec@5 99.414 (99.375)	
2022-06-29 05:48:58,025: ============================================================
2022-06-29 05:50:10,758: time cost, forward:0.011376774591762688, backward:0.02939654459777438, data cost:0.6974980213116 
2022-06-29 05:50:10,758: ============================================================
2022-06-29 05:50:10,758: Epoch 18/26 Batch 4800/7662 eta: 12:57:44.942326	Training Loss 4.0485 (3.5849)	Training Prec@1 97.852 (98.438)	Training Prec@5 99.805 (99.372)	
2022-06-29 05:50:10,758: ============================================================
2022-06-29 05:51:26,045: time cost, forward:0.011377275221249015, backward:0.02939844014669443, data cost:0.6977866193327911 
2022-06-29 05:51:26,045: ============================================================
2022-06-29 05:51:26,045: Epoch 18/26 Batch 4900/7662 eta: 13:23:48.145263	Training Loss 3.4866 (3.5879)	Training Prec@1 99.414 (98.434)	Training Prec@5 99.609 (99.370)	
2022-06-29 05:51:26,045: ============================================================
2022-06-29 05:52:38,461: time cost, forward:0.011382878554012805, backward:0.029412465802334052, data cost:0.6974695138059441 
2022-06-29 05:52:38,461: ============================================================
2022-06-29 05:52:38,461: Epoch 18/26 Batch 5000/7662 eta: 12:51:56.597556	Training Loss 3.8869 (3.5902)	Training Prec@1 98.047 (98.430)	Training Prec@5 98.828 (99.369)	
2022-06-29 05:52:38,462: ============================================================
2022-06-29 05:53:51,498: time cost, forward:0.01140216327831076, backward:0.029425703934487887, data cost:0.6972716798219384 
2022-06-29 05:53:51,498: ============================================================
2022-06-29 05:53:51,498: Epoch 18/26 Batch 5100/7662 eta: 12:57:20.563202	Training Loss 3.6199 (3.5925)	Training Prec@1 98.438 (98.423)	Training Prec@5 99.219 (99.365)	
2022-06-29 05:53:51,498: ============================================================
2022-06-29 05:55:05,832: time cost, forward:0.011420262412489274, backward:0.02942414626774363, data cost:0.6973468502064488 
2022-06-29 05:55:05,832: ============================================================
2022-06-29 05:55:05,832: Epoch 18/26 Batch 5200/7662 eta: 13:09:54.587312	Training Loss 3.5853 (3.5952)	Training Prec@1 98.633 (98.416)	Training Prec@5 99.609 (99.363)	
2022-06-29 05:55:05,832: ============================================================
2022-06-29 05:56:20,300: time cost, forward:0.011433564799982414, backward:0.02944214858296098, data cost:0.6974310191493368 
2022-06-29 05:56:20,300: ============================================================
2022-06-29 05:56:20,300: Epoch 18/26 Batch 5300/7662 eta: 13:10:05.612157	Training Loss 3.6271 (3.5977)	Training Prec@1 98.438 (98.412)	Training Prec@5 99.219 (99.361)	
2022-06-29 05:56:20,300: ============================================================
2022-06-29 05:57:33,309: time cost, forward:0.011443433948834089, backward:0.029459881062727546, data cost:0.6972435876426266 
2022-06-29 05:57:33,309: ============================================================
2022-06-29 05:57:33,309: Epoch 18/26 Batch 5400/7662 eta: 12:53:23.917338	Training Loss 3.8735 (3.6000)	Training Prec@1 96.680 (98.406)	Training Prec@5 99.023 (99.359)	
2022-06-29 05:57:33,310: ============================================================
2022-06-29 05:58:47,292: time cost, forward:0.011450253263086074, backward:0.029478306856171005, data cost:0.6972388770715131 
2022-06-29 05:58:47,293: ============================================================
2022-06-29 05:58:47,293: Epoch 18/26 Batch 5500/7662 eta: 13:02:29.054915	Training Loss 4.0294 (3.6028)	Training Prec@1 97.461 (98.400)	Training Prec@5 98.242 (99.356)	
2022-06-29 05:58:47,293: ============================================================
2022-06-29 06:00:02,337: time cost, forward:0.011448171484106288, backward:0.029516780902326352, data cost:0.6974131281747629 
2022-06-29 06:00:02,337: ============================================================
2022-06-29 06:00:02,337: Epoch 18/26 Batch 5600/7662 eta: 13:12:27.431533	Training Loss 3.8963 (3.6050)	Training Prec@1 97.266 (98.395)	Training Prec@5 98.633 (99.354)	
2022-06-29 06:00:02,337: ============================================================
2022-06-29 06:01:15,537: time cost, forward:0.011465764292542778, backward:0.029580214542764428, data cost:0.6972125492340264 
2022-06-29 06:01:15,538: ============================================================
2022-06-29 06:01:15,538: Epoch 18/26 Batch 5700/7662 eta: 12:51:46.127819	Training Loss 3.6982 (3.6070)	Training Prec@1 98.047 (98.391)	Training Prec@5 99.219 (99.352)	
2022-06-29 06:01:15,538: ============================================================
2022-06-29 06:02:29,826: time cost, forward:0.011476092100924594, backward:0.029588948777881773, data cost:0.6972657051717933 
2022-06-29 06:02:29,827: ============================================================
2022-06-29 06:02:29,827: Epoch 18/26 Batch 5800/7662 eta: 13:02:00.063644	Training Loss 3.7951 (3.6091)	Training Prec@1 98.242 (98.386)	Training Prec@5 99.219 (99.349)	
2022-06-29 06:02:29,827: ============================================================
2022-06-29 06:03:43,731: time cost, forward:0.011473122562952295, backward:0.029620234007187912, data cost:0.6972421148830116 
2022-06-29 06:03:43,731: ============================================================
2022-06-29 06:03:43,732: Epoch 18/26 Batch 5900/7662 eta: 12:56:43.560439	Training Loss 3.8273 (3.6110)	Training Prec@1 98.633 (98.382)	Training Prec@5 99.414 (99.348)	
2022-06-29 06:03:43,732: ============================================================
2022-06-29 06:04:58,850: time cost, forward:0.011491304199821573, backward:0.029614296371210692, data cost:0.697436469100797 
2022-06-29 06:04:58,851: ============================================================
2022-06-29 06:04:58,851: Epoch 18/26 Batch 6000/7662 eta: 13:08:14.336901	Training Loss 3.8569 (3.6137)	Training Prec@1 97.266 (98.375)	Training Prec@5 98.438 (99.346)	
2022-06-29 06:04:58,851: ============================================================
2022-06-29 06:06:13,521: time cost, forward:0.011509340382888877, backward:0.029642174802543414, data cost:0.6975167236243688 
2022-06-29 06:06:13,521: ============================================================
2022-06-29 06:06:13,521: Epoch 18/26 Batch 6100/7662 eta: 13:02:17.163790	Training Loss 3.5849 (3.6153)	Training Prec@1 98.242 (98.372)	Training Prec@5 98.828 (99.345)	
2022-06-29 06:06:13,521: ============================================================
2022-06-29 06:07:28,986: time cost, forward:0.011530084597677891, backward:0.029655249893021096, data cost:0.6977347441114982 
2022-06-29 06:07:28,986: ============================================================
2022-06-29 06:07:28,986: Epoch 18/26 Batch 6200/7662 eta: 13:09:20.897197	Training Loss 3.8108 (3.6171)	Training Prec@1 98.633 (98.368)	Training Prec@5 99.805 (99.343)	
2022-06-29 06:07:28,986: ============================================================
2022-06-29 06:08:43,385: time cost, forward:0.011532606634190583, backward:0.029681038754310735, data cost:0.6977782107133831 
2022-06-29 06:08:43,386: ============================================================
2022-06-29 06:08:43,386: Epoch 18/26 Batch 6300/7662 eta: 12:56:58.084672	Training Loss 3.4278 (3.6186)	Training Prec@1 98.047 (98.363)	Training Prec@5 99.609 (99.342)	
2022-06-29 06:08:43,386: ============================================================
2022-06-29 06:09:57,382: time cost, forward:0.011529805269403781, backward:0.029694234939231817, data cost:0.6977770733151478 
2022-06-29 06:09:57,383: ============================================================
2022-06-29 06:09:57,383: Epoch 18/26 Batch 6400/7662 eta: 12:51:31.831841	Training Loss 3.8982 (3.6199)	Training Prec@1 97.266 (98.359)	Training Prec@5 99.023 (99.341)	
2022-06-29 06:09:57,383: ============================================================
2022-06-29 06:11:11,505: time cost, forward:0.011533412920142856, backward:0.0296738446721812, data cost:0.6978198682955548 
2022-06-29 06:11:11,505: ============================================================
2022-06-29 06:11:11,505: Epoch 18/26 Batch 6500/7662 eta: 12:51:36.038515	Training Loss 3.6730 (3.6212)	Training Prec@1 97.656 (98.356)	Training Prec@5 99.023 (99.339)	
2022-06-29 06:11:11,505: ============================================================
2022-06-29 06:12:26,650: time cost, forward:0.011536528403369889, backward:0.029675725807401517, data cost:0.6979964543588415 
2022-06-29 06:12:26,651: ============================================================
2022-06-29 06:12:26,651: Epoch 18/26 Batch 6600/7662 eta: 13:01:00.179008	Training Loss 3.5850 (3.6230)	Training Prec@1 98.633 (98.351)	Training Prec@5 99.414 (99.337)	
2022-06-29 06:12:26,651: ============================================================
2022-06-29 06:13:39,405: time cost, forward:0.011528622625407612, backward:0.02968678116389114, data cost:0.6978094361401046 
2022-06-29 06:13:39,405: ============================================================
2022-06-29 06:13:39,405: Epoch 18/26 Batch 6700/7662 eta: 12:34:56.175413	Training Loss 3.7638 (3.6245)	Training Prec@1 98.047 (98.347)	Training Prec@5 99.414 (99.334)	
2022-06-29 06:13:39,405: ============================================================
2022-06-29 06:14:53,589: time cost, forward:0.011532056049347485, backward:0.029699288566141624, data cost:0.6978281748471917 
2022-06-29 06:14:53,589: ============================================================
2022-06-29 06:14:53,589: Epoch 18/26 Batch 6800/7662 eta: 12:48:31.916085	Training Loss 3.7642 (3.6260)	Training Prec@1 97.852 (98.343)	Training Prec@5 99.219 (99.332)	
2022-06-29 06:14:53,589: ============================================================
2022-06-29 06:16:07,584: time cost, forward:0.011539726883522892, backward:0.02970582372054689, data cost:0.6978199162298674 
2022-06-29 06:16:07,584: ============================================================
2022-06-29 06:16:07,584: Epoch 18/26 Batch 6900/7662 eta: 12:45:20.532566	Training Loss 3.6958 (3.6275)	Training Prec@1 97.852 (98.338)	Training Prec@5 99.414 (99.329)	
2022-06-29 06:16:07,584: ============================================================
2022-06-29 06:17:22,243: time cost, forward:0.011546214183137525, backward:0.02972349246445171, data cost:0.6978972627871682 
2022-06-29 06:17:22,244: ============================================================
2022-06-29 06:17:22,244: Epoch 18/26 Batch 7000/7662 eta: 12:50:58.522978	Training Loss 3.8349 (3.6287)	Training Prec@1 97.852 (98.334)	Training Prec@5 99.023 (99.328)	
2022-06-29 06:17:22,244: ============================================================
2022-06-29 06:18:36,321: time cost, forward:0.011547885859309829, backward:0.029719971455156105, data cost:0.6979158004248104 
2022-06-29 06:18:36,321: ============================================================
2022-06-29 06:18:36,322: Epoch 18/26 Batch 7100/7662 eta: 12:43:43.602707	Training Loss 3.6064 (3.6302)	Training Prec@1 98.633 (98.331)	Training Prec@5 99.414 (99.327)	
2022-06-29 06:18:36,322: ============================================================
2022-06-29 06:19:51,399: time cost, forward:0.01155163977175624, backward:0.029746432654773846, data cost:0.6980388456623593 
2022-06-29 06:19:51,400: ============================================================
2022-06-29 06:19:51,400: Epoch 18/26 Batch 7200/7662 eta: 12:52:47.781782	Training Loss 3.8050 (3.6312)	Training Prec@1 98.438 (98.328)	Training Prec@5 99.414 (99.325)	
2022-06-29 06:19:51,400: ============================================================
2022-06-29 06:21:06,214: time cost, forward:0.011555580655782742, backward:0.029756182660009945, data cost:0.6981388921198053 
2022-06-29 06:21:06,215: ============================================================
2022-06-29 06:21:06,215: Epoch 18/26 Batch 7300/7662 eta: 12:48:49.993893	Training Loss 3.7721 (3.6328)	Training Prec@1 98.438 (98.325)	Training Prec@5 99.414 (99.324)	
2022-06-29 06:21:06,215: ============================================================
2022-06-29 06:22:20,715: time cost, forward:0.011551558512226119, backward:0.029762348753002016, data cost:0.6982066299097169 
2022-06-29 06:22:20,715: ============================================================
2022-06-29 06:22:20,715: Epoch 18/26 Batch 7400/7662 eta: 12:44:21.777596	Training Loss 3.8688 (3.6344)	Training Prec@1 97.461 (98.322)	Training Prec@5 98.633 (99.323)	
2022-06-29 06:22:20,715: ============================================================
2022-06-29 06:23:36,304: time cost, forward:0.011552709120880017, backward:0.02978808009667402, data cost:0.6983921703997891 
2022-06-29 06:23:36,305: ============================================================
2022-06-29 06:23:36,305: Epoch 18/26 Batch 7500/7662 eta: 12:54:16.418165	Training Loss 3.5148 (3.6357)	Training Prec@1 98.828 (98.319)	Training Prec@5 99.414 (99.321)	
2022-06-29 06:23:36,305: ============================================================
2022-06-29 06:24:51,082: time cost, forward:0.011549578824942482, backward:0.02982347515762315, data cost:0.6984595902610223 
2022-06-29 06:24:51,082: ============================================================
2022-06-29 06:24:51,082: Epoch 18/26 Batch 7600/7662 eta: 12:44:42.847448	Training Loss 3.7068 (3.6369)	Training Prec@1 98.047 (98.315)	Training Prec@5 98.828 (99.320)	
2022-06-29 06:24:51,082: ============================================================
2022-06-29 06:25:39,775: Epoch: 18/26 eta: 12:43:55.737498	Training Loss 3.8586 (3.6379)	Training Prec@1 96.875 (98.312)	Training Prec@5 99.023 (99.319)
2022-06-29 06:25:39,775: ============================================================
2022-06-29 06:27:03,095: time cost, forward:0.011194621673738114, backward:0.030838181274105803, data cost:0.7943664102843313 
2022-06-29 06:27:03,095: ============================================================
2022-06-29 06:27:03,096: Epoch 19/26 Batch 100/7662 eta: 14:09:47.839434	Training Loss 3.2810 (3.2287)	Training Prec@1 99.023 (98.877)	Training Prec@5 99.805 (99.578)	
2022-06-29 06:27:03,096: ============================================================
2022-06-29 06:28:16,037: time cost, forward:0.01142199195210059, backward:0.029616137844833298, data cost:0.7414506751688281 
2022-06-29 06:28:16,037: ============================================================
2022-06-29 06:28:16,037: Epoch 19/26 Batch 200/7662 eta: 12:22:45.221465	Training Loss 3.1783 (3.2437)	Training Prec@1 98.633 (98.850)	Training Prec@5 99.609 (99.572)	
2022-06-29 06:28:16,037: ============================================================
2022-06-29 06:29:29,842: time cost, forward:0.011647269079916454, backward:0.02961640852350854, data cost:0.7261572330691742 
2022-06-29 06:29:29,842: ============================================================
2022-06-29 06:29:29,843: Epoch 19/26 Batch 300/7662 eta: 12:30:18.918785	Training Loss 3.6115 (3.2658)	Training Prec@1 98.828 (98.835)	Training Prec@5 99.609 (99.562)	
2022-06-29 06:29:29,843: ============================================================
2022-06-29 06:30:42,748: time cost, forward:0.011791286014375232, backward:0.029865373047372152, data cost:0.7160252186290005 
2022-06-29 06:30:42,748: ============================================================
2022-06-29 06:30:42,748: Epoch 19/26 Batch 400/7662 eta: 12:19:57.517539	Training Loss 3.1263 (3.2759)	Training Prec@1 99.023 (98.823)	Training Prec@5 99.805 (99.563)	
2022-06-29 06:30:42,749: ============================================================
2022-06-29 06:31:55,544: time cost, forward:0.011669563148208037, backward:0.02959539465053765, data cost:0.7103778202691393 
2022-06-29 06:31:55,545: ============================================================
2022-06-29 06:31:55,545: Epoch 19/26 Batch 500/7662 eta: 12:17:37.962268	Training Loss 3.5060 (3.2856)	Training Prec@1 97.852 (98.828)	Training Prec@5 99.219 (99.561)	
2022-06-29 06:31:55,545: ============================================================
2022-06-29 06:33:07,543: time cost, forward:0.011609311095860247, backward:0.02955529606203006, data cost:0.7051176746221934 
2022-06-29 06:33:07,544: ============================================================
2022-06-29 06:33:07,544: Epoch 19/26 Batch 600/7662 eta: 12:08:21.201092	Training Loss 3.5725 (3.3020)	Training Prec@1 99.219 (98.805)	Training Prec@5 99.609 (99.544)	
2022-06-29 06:33:07,544: ============================================================
2022-06-29 06:34:19,919: time cost, forward:0.011615139220405546, backward:0.02952140561159759, data cost:0.7018505510513022 
2022-06-29 06:34:19,920: ============================================================
2022-06-29 06:34:19,920: Epoch 19/26 Batch 700/7662 eta: 12:10:57.820338	Training Loss 3.3133 (3.3160)	Training Prec@1 98.633 (98.797)	Training Prec@5 99.414 (99.540)	
2022-06-29 06:34:19,920: ============================================================
2022-06-29 06:35:32,507: time cost, forward:0.011581527127491519, backward:0.02934556073032422, data cost:0.6998646459233329 
2022-06-29 06:35:32,507: ============================================================
2022-06-29 06:35:32,507: Epoch 19/26 Batch 800/7662 eta: 12:11:53.072858	Training Loss 3.4519 (3.3276)	Training Prec@1 98.828 (98.781)	Training Prec@5 99.414 (99.529)	
2022-06-29 06:35:32,507: ============================================================
2022-06-29 06:36:46,634: time cost, forward:0.01158232789681406, backward:0.029466237586915692, data cost:0.6997506414292519 
2022-06-29 06:36:46,635: ============================================================
2022-06-29 06:36:46,635: Epoch 19/26 Batch 900/7662 eta: 12:26:11.048861	Training Loss 3.6093 (3.3385)	Training Prec@1 97.656 (98.774)	Training Prec@5 98.633 (99.529)	
2022-06-29 06:36:46,635: ============================================================
2022-06-29 06:37:59,568: time cost, forward:0.011610108930188734, backward:0.029458012070145097, data cost:0.6985277437471651 
2022-06-29 06:37:59,568: ============================================================
2022-06-29 06:37:59,568: Epoch 19/26 Batch 1000/7662 eta: 12:12:56.432483	Training Loss 3.6614 (3.3504)	Training Prec@1 98.242 (98.760)	Training Prec@5 98.828 (99.517)	
2022-06-29 06:37:59,568: ============================================================
2022-06-29 06:39:12,647: time cost, forward:0.01164449573756349, backward:0.029572979768261898, data cost:0.6975312039893361 
2022-06-29 06:39:12,648: ============================================================
2022-06-29 06:39:12,648: Epoch 19/26 Batch 1100/7662 eta: 12:13:11.765907	Training Loss 3.3686 (3.3626)	Training Prec@1 98.633 (98.747)	Training Prec@5 99.609 (99.514)	
2022-06-29 06:39:12,648: ============================================================
2022-06-29 06:40:25,370: time cost, forward:0.011636547290652468, backward:0.029516992616693213, data cost:0.6965906214376009 
2022-06-29 06:40:25,371: ============================================================
2022-06-29 06:40:25,371: Epoch 19/26 Batch 1200/7662 eta: 12:08:24.418426	Training Loss 3.5519 (3.3740)	Training Prec@1 98.633 (98.736)	Training Prec@5 99.023 (99.507)	
2022-06-29 06:40:25,371: ============================================================
2022-06-29 06:41:37,404: time cost, forward:0.011623784888240353, backward:0.029296073480419602, data cost:0.695454516164884 
2022-06-29 06:41:37,404: ============================================================
2022-06-29 06:41:37,404: Epoch 19/26 Batch 1300/7662 eta: 12:00:17.899345	Training Loss 3.2280 (3.3850)	Training Prec@1 98.633 (98.722)	Training Prec@5 99.609 (99.501)	
2022-06-29 06:41:37,404: ============================================================
2022-06-29 06:42:51,167: time cost, forward:0.011600288857384355, backward:0.029400919572722495, data cost:0.6954257007664318 
2022-06-29 06:42:51,168: ============================================================
2022-06-29 06:42:51,168: Epoch 19/26 Batch 1400/7662 eta: 12:16:22.048036	Training Loss 3.5436 (3.3946)	Training Prec@1 98.438 (98.709)	Training Prec@5 99.414 (99.494)	
2022-06-29 06:42:51,168: ============================================================
2022-06-29 06:44:03,913: time cost, forward:0.0115670951069634, backward:0.029469081288262, data cost:0.6947592065046436 
2022-06-29 06:44:03,913: ============================================================
2022-06-29 06:44:03,913: Epoch 19/26 Batch 1500/7662 eta: 12:04:59.614712	Training Loss 3.6042 (3.4038)	Training Prec@1 97.852 (98.697)	Training Prec@5 99.023 (99.490)	
2022-06-29 06:44:03,913: ============================================================
2022-06-29 06:45:16,156: time cost, forward:0.011546320733314309, backward:0.029557170086610757, data cost:0.6938226835812681 
2022-06-29 06:45:16,157: ============================================================
2022-06-29 06:45:16,157: Epoch 19/26 Batch 1600/7662 eta: 11:58:47.292570	Training Loss 3.6317 (3.4131)	Training Prec@1 98.633 (98.689)	Training Prec@5 99.805 (99.483)	
2022-06-29 06:45:16,157: ============================================================
2022-06-29 06:46:28,060: time cost, forward:0.011542620134044914, backward:0.02964210566385414, data cost:0.692775890222362 
2022-06-29 06:46:28,060: ============================================================
2022-06-29 06:46:28,060: Epoch 19/26 Batch 1700/7662 eta: 11:54:12.221807	Training Loss 3.7255 (3.4216)	Training Prec@1 98.242 (98.684)	Training Prec@5 99.219 (99.483)	
2022-06-29 06:46:28,060: ============================================================
2022-06-29 06:47:42,207: time cost, forward:0.011570546943787537, backward:0.029695390263420135, data cost:0.6930942409498417 
2022-06-29 06:47:42,208: ============================================================
2022-06-29 06:47:42,208: Epoch 19/26 Batch 1800/7662 eta: 12:15:15.764919	Training Loss 3.7374 (3.4297)	Training Prec@1 98.242 (98.677)	Training Prec@5 99.219 (99.478)	
2022-06-29 06:47:42,208: ============================================================
2022-06-29 06:48:55,578: time cost, forward:0.011582413493111737, backward:0.029739517610659405, data cost:0.6929737993012358 
2022-06-29 06:48:55,578: ============================================================
2022-06-29 06:48:55,579: Epoch 19/26 Batch 1900/7662 eta: 12:06:19.851013	Training Loss 3.5436 (3.4383)	Training Prec@1 99.219 (98.666)	Training Prec@5 99.414 (99.474)	
2022-06-29 06:48:55,579: ============================================================
2022-06-29 06:50:07,671: time cost, forward:0.011591777734723075, backward:0.029812266911310576, data cost:0.6921994657502167 
2022-06-29 06:50:07,672: ============================================================
2022-06-29 06:50:07,672: Epoch 19/26 Batch 2000/7662 eta: 11:52:29.179149	Training Loss 3.6559 (3.4456)	Training Prec@1 98.438 (98.658)	Training Prec@5 99.414 (99.472)	
2022-06-29 06:50:07,672: ============================================================
2022-06-29 06:51:20,688: time cost, forward:0.011609858930423295, backward:0.029775939821458645, data cost:0.6920283313249621 
2022-06-29 06:51:20,689: ============================================================
2022-06-29 06:51:20,689: Epoch 19/26 Batch 2100/7662 eta: 12:00:23.886451	Training Loss 3.4762 (3.4522)	Training Prec@1 98.633 (98.644)	Training Prec@5 99.805 (99.467)	
2022-06-29 06:51:20,689: ============================================================
2022-06-29 06:52:34,319: time cost, forward:0.011605232615208506, backward:0.0297575414370493, data cost:0.6921656782272568 
2022-06-29 06:52:34,319: ============================================================
2022-06-29 06:52:34,319: Epoch 19/26 Batch 2200/7662 eta: 12:05:13.357454	Training Loss 3.6472 (3.4580)	Training Prec@1 99.023 (98.633)	Training Prec@5 99.609 (99.463)	
2022-06-29 06:52:34,319: ============================================================
2022-06-29 06:53:47,030: time cost, forward:0.011647809220687779, backward:0.029778823379642706, data cost:0.6918018102749579 
2022-06-29 06:53:47,030: ============================================================
2022-06-29 06:53:47,030: Epoch 19/26 Batch 2300/7662 eta: 11:54:57.255199	Training Loss 3.7887 (3.4641)	Training Prec@1 99.219 (98.622)	Training Prec@5 99.414 (99.457)	
2022-06-29 06:53:47,030: ============================================================
2022-06-29 06:54:59,176: time cost, forward:0.011673480980393289, backward:0.029723191072464784, data cost:0.6913198336505453 
2022-06-29 06:54:59,177: ============================================================
2022-06-29 06:54:59,177: Epoch 19/26 Batch 2400/7662 eta: 11:48:12.144250	Training Loss 3.5522 (3.4693)	Training Prec@1 98.438 (98.614)	Training Prec@5 99.805 (99.456)	
2022-06-29 06:54:59,177: ============================================================
2022-06-29 06:56:12,590: time cost, forward:0.01169448396881946, backward:0.02971109899343038, data cost:0.6913491594834345 
2022-06-29 06:56:12,590: ============================================================
2022-06-29 06:56:12,590: Epoch 19/26 Batch 2500/7662 eta: 11:59:24.840873	Training Loss 3.6945 (3.4754)	Training Prec@1 98.828 (98.606)	Training Prec@5 100.000 (99.453)	
2022-06-29 06:56:12,590: ============================================================
2022-06-29 06:57:25,742: time cost, forward:0.011680961068018714, backward:0.029658013648737297, data cost:0.6913499443198039 
2022-06-29 06:57:25,742: ============================================================
2022-06-29 06:57:25,742: Epoch 19/26 Batch 2600/7662 eta: 11:55:38.211759	Training Loss 3.6714 (3.4822)	Training Prec@1 98.242 (98.597)	Training Prec@5 99.023 (99.450)	
2022-06-29 06:57:25,743: ============================================================
2022-06-29 06:58:39,084: time cost, forward:0.01164946374119366, backward:0.029653504584709243, data cost:0.6913994135084572 
2022-06-29 06:58:39,084: ============================================================
2022-06-29 06:58:39,084: Epoch 19/26 Batch 2700/7662 eta: 11:56:16.206017	Training Loss 3.6147 (3.4878)	Training Prec@1 98.242 (98.586)	Training Prec@5 99.609 (99.445)	
2022-06-29 06:58:39,085: ============================================================
2022-06-29 06:59:52,967: time cost, forward:0.011640958591800539, backward:0.02963623339553184, data cost:0.6916276621537448 
2022-06-29 06:59:52,967: ============================================================
2022-06-29 06:59:52,967: Epoch 19/26 Batch 2800/7662 eta: 12:00:19.185733	Training Loss 3.6746 (3.4922)	Training Prec@1 97.656 (98.577)	Training Prec@5 99.609 (99.442)	
2022-06-29 06:59:52,967: ============================================================
2022-06-29 07:01:07,693: time cost, forward:0.011628484841090476, backward:0.02960909272358721, data cost:0.6921479211835542 
2022-06-29 07:01:07,694: ============================================================
2022-06-29 07:01:07,694: Epoch 19/26 Batch 2900/7662 eta: 12:07:18.288597	Training Loss 3.7593 (3.4972)	Training Prec@1 98.633 (98.568)	Training Prec@5 99.414 (99.438)	
2022-06-29 07:01:07,694: ============================================================
2022-06-29 07:02:21,111: time cost, forward:0.01162070860740303, backward:0.029557377547174742, data cost:0.6922191346077253 
2022-06-29 07:02:21,111: ============================================================
2022-06-29 07:02:21,111: Epoch 19/26 Batch 3000/7662 eta: 11:53:19.915333	Training Loss 3.4795 (3.5015)	Training Prec@1 98.828 (98.560)	Training Prec@5 99.609 (99.435)	
2022-06-29 07:02:21,111: ============================================================
2022-06-29 07:03:32,963: time cost, forward:0.011597588817009275, backward:0.02954093307477884, data cost:0.6917658325317176 
2022-06-29 07:03:32,964: ============================================================
2022-06-29 07:03:32,964: Epoch 19/26 Batch 3100/7662 eta: 11:36:56.080157	Training Loss 3.7865 (3.5062)	Training Prec@1 98.242 (98.550)	Training Prec@5 99.414 (99.430)	
2022-06-29 07:03:32,964: ============================================================
2022-06-29 07:04:47,019: time cost, forward:0.011607621602245925, backward:0.02957034841408093, data cost:0.6919534015595894 
2022-06-29 07:04:47,019: ============================================================
2022-06-29 07:04:47,020: Epoch 19/26 Batch 3200/7662 eta: 11:57:04.205722	Training Loss 3.6078 (3.5109)	Training Prec@1 98.828 (98.544)	Training Prec@5 99.805 (99.428)	
2022-06-29 07:04:47,020: ============================================================
2022-06-29 07:06:00,015: time cost, forward:0.011614506950736877, backward:0.029600483245942114, data cost:0.6918033130532433 
2022-06-29 07:06:00,015: ============================================================
2022-06-29 07:06:00,016: Epoch 19/26 Batch 3300/7662 eta: 11:45:35.526240	Training Loss 3.6553 (3.5152)	Training Prec@1 97.461 (98.536)	Training Prec@5 98.438 (99.425)	
2022-06-29 07:06:00,016: ============================================================
2022-06-29 07:07:12,714: time cost, forward:0.01162421180767745, backward:0.029625068520335248, data cost:0.6915803620590115 
2022-06-29 07:07:12,715: ============================================================
2022-06-29 07:07:12,715: Epoch 19/26 Batch 3400/7662 eta: 11:41:30.717339	Training Loss 3.4939 (3.5188)	Training Prec@1 98.242 (98.530)	Training Prec@5 98.828 (99.422)	
2022-06-29 07:07:12,715: ============================================================
2022-06-29 07:08:25,625: time cost, forward:0.011601008902825298, backward:0.029644497669434746, data cost:0.6914662457629932 
2022-06-29 07:08:25,625: ============================================================
2022-06-29 07:08:25,625: Epoch 19/26 Batch 3500/7662 eta: 11:42:19.987321	Training Loss 3.5781 (3.5223)	Training Prec@1 98.242 (98.525)	Training Prec@5 99.023 (99.421)	
2022-06-29 07:08:25,625: ============================================================
2022-06-29 07:09:39,004: time cost, forward:0.011591901379050265, backward:0.02958605918131725, data cost:0.691550691845219 
2022-06-29 07:09:39,004: ============================================================
2022-06-29 07:09:39,005: Epoch 19/26 Batch 3600/7662 eta: 11:45:37.680100	Training Loss 3.6289 (3.5265)	Training Prec@1 98.438 (98.516)	Training Prec@5 99.219 (99.417)	
2022-06-29 07:09:39,005: ============================================================
2022-06-29 07:10:52,462: time cost, forward:0.011570234432772194, backward:0.029538226533690218, data cost:0.6916578539837757 
2022-06-29 07:10:52,463: ============================================================
2022-06-29 07:10:52,463: Epoch 19/26 Batch 3700/7662 eta: 11:45:09.719304	Training Loss 3.6225 (3.5295)	Training Prec@1 99.414 (98.510)	Training Prec@5 99.805 (99.412)	
2022-06-29 07:10:52,463: ============================================================
2022-06-29 07:12:06,063: time cost, forward:0.01155906898406155, backward:0.02955575565439552, data cost:0.6917258721648093 
2022-06-29 07:12:06,064: ============================================================
2022-06-29 07:12:06,064: Epoch 19/26 Batch 3800/7662 eta: 11:45:18.466533	Training Loss 3.8308 (3.5325)	Training Prec@1 98.438 (98.502)	Training Prec@5 99.219 (99.408)	
2022-06-29 07:12:06,064: ============================================================
2022-06-29 07:13:18,992: time cost, forward:0.01154645396122782, backward:0.029561906693745466, data cost:0.6916281520234955 
2022-06-29 07:13:18,992: ============================================================
2022-06-29 07:13:18,992: Epoch 19/26 Batch 3900/7662 eta: 11:37:38.515893	Training Loss 3.3881 (3.5358)	Training Prec@1 99.219 (98.494)	Training Prec@5 100.000 (99.404)	
2022-06-29 07:13:18,992: ============================================================
2022-06-29 07:14:31,836: time cost, forward:0.011532490537833739, backward:0.02951352725657382, data cost:0.6915736421998604 
2022-06-29 07:14:31,837: ============================================================
2022-06-29 07:14:31,837: Epoch 19/26 Batch 4000/7662 eta: 11:35:37.859235	Training Loss 3.6798 (3.5396)	Training Prec@1 99.023 (98.488)	Training Prec@5 99.414 (99.403)	
2022-06-29 07:14:31,837: ============================================================
2022-06-29 07:15:44,626: time cost, forward:0.011536813358121687, backward:0.029495390777792632, data cost:0.6914617007870475 
2022-06-29 07:15:44,626: ============================================================
2022-06-29 07:15:44,627: Epoch 19/26 Batch 4100/7662 eta: 11:33:53.497862	Training Loss 3.4707 (3.5426)	Training Prec@1 98.242 (98.482)	Training Prec@5 99.023 (99.398)	
2022-06-29 07:15:44,627: ============================================================
2022-06-29 07:16:57,931: time cost, forward:0.011541573653251792, backward:0.02949578803503732, data cost:0.6914618655765985 
2022-06-29 07:16:57,931: ============================================================
2022-06-29 07:16:57,931: Epoch 19/26 Batch 4200/7662 eta: 11:37:34.753463	Training Loss 3.7646 (3.5458)	Training Prec@1 97.852 (98.477)	Training Prec@5 99.023 (99.395)	
2022-06-29 07:16:57,931: ============================================================
2022-06-29 07:18:11,837: time cost, forward:0.011537110591994021, backward:0.029486835210870716, data cost:0.6916163287126178 
2022-06-29 07:18:11,838: ============================================================
2022-06-29 07:18:11,838: Epoch 19/26 Batch 4300/7662 eta: 11:42:04.637343	Training Loss 3.3866 (3.5488)	Training Prec@1 98.828 (98.469)	Training Prec@5 99.023 (99.392)	
2022-06-29 07:18:11,838: ============================================================
2022-06-29 07:19:24,208: time cost, forward:0.011532120391384367, backward:0.029489825329582213, data cost:0.6914067428256739 
2022-06-29 07:19:24,208: ============================================================
2022-06-29 07:19:24,208: Epoch 19/26 Batch 4400/7662 eta: 11:26:16.587817	Training Loss 3.7179 (3.5525)	Training Prec@1 98.242 (98.463)	Training Prec@5 99.219 (99.389)	
2022-06-29 07:19:24,208: ============================================================
2022-06-29 07:20:37,292: time cost, forward:0.011532227392593047, backward:0.029491175914186984, data cost:0.6913599802086315 
2022-06-29 07:20:37,292: ============================================================
2022-06-29 07:20:37,292: Epoch 19/26 Batch 4500/7662 eta: 11:31:49.370587	Training Loss 3.6547 (3.5556)	Training Prec@1 98.047 (98.457)	Training Prec@5 98.633 (99.387)	
2022-06-29 07:20:37,292: ============================================================
2022-06-29 07:21:50,417: time cost, forward:0.011539728700090787, backward:0.029534216418580454, data cost:0.691276574036328 
2022-06-29 07:21:50,417: ============================================================
2022-06-29 07:21:50,418: Epoch 19/26 Batch 4600/7662 eta: 11:31:00.014730	Training Loss 3.8681 (3.5584)	Training Prec@1 98.438 (98.450)	Training Prec@5 99.609 (99.383)	
2022-06-29 07:21:50,418: ============================================================
2022-06-29 07:23:04,251: time cost, forward:0.011556344175369188, backward:0.029509198389095964, data cost:0.6914007864649891 
2022-06-29 07:23:04,251: ============================================================
2022-06-29 07:23:04,251: Epoch 19/26 Batch 4700/7662 eta: 11:36:27.627311	Training Loss 3.5795 (3.5603)	Training Prec@1 98.242 (98.446)	Training Prec@5 99.219 (99.382)	
2022-06-29 07:23:04,251: ============================================================
2022-06-29 07:24:17,156: time cost, forward:0.011573706102460642, backward:0.029512467943745173, data cost:0.6913002203046891 
2022-06-29 07:24:17,156: ============================================================
2022-06-29 07:24:17,157: Epoch 19/26 Batch 4800/7662 eta: 11:26:29.291391	Training Loss 3.6333 (3.5628)	Training Prec@1 98.438 (98.441)	Training Prec@5 99.609 (99.379)	
2022-06-29 07:24:17,157: ============================================================
2022-06-29 07:25:31,134: time cost, forward:0.01158233456865674, backward:0.029516199409389866, data cost:0.6914304549121253 
2022-06-29 07:25:31,134: ============================================================
2022-06-29 07:25:31,134: Epoch 19/26 Batch 4900/7662 eta: 11:35:21.231300	Training Loss 3.5930 (3.5652)	Training Prec@1 98.438 (98.435)	Training Prec@5 99.219 (99.376)	
2022-06-29 07:25:31,134: ============================================================
2022-06-29 07:26:45,464: time cost, forward:0.011595909679906563, backward:0.029527062152619122, data cost:0.6916121198883484 
2022-06-29 07:26:45,465: ============================================================
2022-06-29 07:26:45,465: Epoch 19/26 Batch 5000/7662 eta: 11:37:25.865950	Training Loss 3.6649 (3.5677)	Training Prec@1 98.047 (98.431)	Training Prec@5 98.828 (99.373)	
2022-06-29 07:26:45,465: ============================================================
2022-06-29 07:27:59,038: time cost, forward:0.011598033796550947, backward:0.02955188660510359, data cost:0.6916362320962993 
2022-06-29 07:27:59,039: ============================================================
2022-06-29 07:27:59,039: Epoch 19/26 Batch 5100/7662 eta: 11:29:06.271918	Training Loss 3.5998 (3.5701)	Training Prec@1 98.633 (98.427)	Training Prec@5 99.414 (99.372)	
2022-06-29 07:27:59,039: ============================================================
2022-06-29 07:29:14,270: time cost, forward:0.011602925667283076, backward:0.029566942304114833, data cost:0.6919828620546711 
2022-06-29 07:29:14,270: ============================================================
2022-06-29 07:29:14,271: Epoch 19/26 Batch 5200/7662 eta: 11:43:22.835988	Training Loss 3.5562 (3.5719)	Training Prec@1 98.242 (98.423)	Training Prec@5 99.609 (99.370)	
2022-06-29 07:29:14,271: ============================================================
2022-06-29 07:30:28,382: time cost, forward:0.011595548245339466, backward:0.029575654348577503, data cost:0.6921226500924926 
2022-06-29 07:30:28,382: ============================================================
2022-06-29 07:30:28,383: Epoch 19/26 Batch 5300/7662 eta: 11:31:40.443498	Training Loss 3.6342 (3.5738)	Training Prec@1 98.438 (98.418)	Training Prec@5 99.414 (99.368)	
2022-06-29 07:30:28,383: ============================================================
2022-06-29 07:31:42,105: time cost, forward:0.01158132405606966, backward:0.029588479469343124, data cost:0.6921892448318603 
2022-06-29 07:31:42,105: ============================================================
2022-06-29 07:31:42,106: Epoch 19/26 Batch 5400/7662 eta: 11:26:48.907889	Training Loss 3.8581 (3.5760)	Training Prec@1 98.242 (98.413)	Training Prec@5 99.023 (99.365)	
2022-06-29 07:31:42,106: ============================================================
2022-06-29 07:32:55,108: time cost, forward:0.011578136323733555, backward:0.029589013937148727, data cost:0.6921232075317488 
2022-06-29 07:32:55,109: ============================================================
2022-06-29 07:32:55,109: Epoch 19/26 Batch 5500/7662 eta: 11:18:53.745060	Training Loss 3.8671 (3.5782)	Training Prec@1 97.461 (98.408)	Training Prec@5 98.633 (99.362)	
2022-06-29 07:32:55,109: ============================================================
2022-06-29 07:34:09,097: time cost, forward:0.0115757542095944, backward:0.029583704686629003, data cost:0.6922410946910904 
2022-06-29 07:34:09,097: ============================================================
2022-06-29 07:34:09,097: Epoch 19/26 Batch 5600/7662 eta: 11:26:49.213701	Training Loss 3.6363 (3.5804)	Training Prec@1 99.219 (98.403)	Training Prec@5 99.609 (99.360)	
2022-06-29 07:34:09,097: ============================================================
2022-06-29 07:35:23,601: time cost, forward:0.011571384266941856, backward:0.029569786836189396, data cost:0.692454291804043 
2022-06-29 07:35:23,601: ============================================================
2022-06-29 07:35:23,601: Epoch 19/26 Batch 5700/7662 eta: 11:30:22.027027	Training Loss 3.7200 (3.5825)	Training Prec@1 98.438 (98.397)	Training Prec@5 99.219 (99.358)	
2022-06-29 07:35:23,601: ============================================================
2022-06-29 07:36:37,260: time cost, forward:0.011564231778161446, backward:0.029570432341618873, data cost:0.6925059585535109 
2022-06-29 07:36:37,260: ============================================================
2022-06-29 07:36:37,260: Epoch 19/26 Batch 5800/7662 eta: 11:21:18.509913	Training Loss 3.7766 (3.5842)	Training Prec@1 98.047 (98.392)	Training Prec@5 99.219 (99.355)	
2022-06-29 07:36:37,260: ============================================================
2022-06-29 07:37:51,108: time cost, forward:0.011550651079194993, backward:0.029552149558435114, data cost:0.6926119929755172 
2022-06-29 07:37:51,109: ============================================================
2022-06-29 07:37:51,109: Epoch 19/26 Batch 5900/7662 eta: 11:21:49.959214	Training Loss 3.8071 (3.5867)	Training Prec@1 97.852 (98.386)	Training Prec@5 98.633 (99.353)	
2022-06-29 07:37:51,109: ============================================================
2022-06-29 07:39:05,476: time cost, forward:0.011541450474734783, backward:0.0295367685233102, data cost:0.6927962639387856 
2022-06-29 07:39:05,477: ============================================================
2022-06-29 07:39:05,477: Epoch 19/26 Batch 6000/7662 eta: 11:25:23.316088	Training Loss 3.7425 (3.5884)	Training Prec@1 97.852 (98.383)	Training Prec@5 99.219 (99.351)	
2022-06-29 07:39:05,477: ============================================================
2022-06-29 07:40:19,723: time cost, forward:0.011537764889038005, backward:0.029547613006006362, data cost:0.6929226658504153 
2022-06-29 07:40:19,724: ============================================================
2022-06-29 07:40:19,724: Epoch 19/26 Batch 6100/7662 eta: 11:23:02.072098	Training Loss 3.7228 (3.5901)	Training Prec@1 97.656 (98.379)	Training Prec@5 99.023 (99.349)	
2022-06-29 07:40:19,724: ============================================================
2022-06-29 07:41:34,159: time cost, forward:0.01154009848568666, backward:0.029559881615242586, data cost:0.6930669194403185 
2022-06-29 07:41:34,159: ============================================================
2022-06-29 07:41:34,159: Epoch 19/26 Batch 6200/7662 eta: 11:23:31.647778	Training Loss 3.6515 (3.5923)	Training Prec@1 98.047 (98.373)	Training Prec@5 99.023 (99.346)	
2022-06-29 07:41:34,159: ============================================================
2022-06-29 07:42:49,863: time cost, forward:0.011543158217637685, backward:0.029564118457230372, data cost:0.6934174904654491 
2022-06-29 07:42:49,863: ============================================================
2022-06-29 07:42:49,863: Epoch 19/26 Batch 6300/7662 eta: 11:33:54.801951	Training Loss 3.7372 (3.5943)	Training Prec@1 97.461 (98.369)	Training Prec@5 99.219 (99.344)	
2022-06-29 07:42:49,863: ============================================================
2022-06-29 07:44:05,582: time cost, forward:0.011540538352957963, backward:0.02957038425583265, data cost:0.6937598944045655 
2022-06-29 07:44:05,582: ============================================================
2022-06-29 07:44:05,582: Epoch 19/26 Batch 6400/7662 eta: 11:32:47.471920	Training Loss 3.8773 (3.5963)	Training Prec@1 96.875 (98.365)	Training Prec@5 99.023 (99.342)	
2022-06-29 07:44:05,582: ============================================================
2022-06-29 07:45:19,849: time cost, forward:0.011552162290738351, backward:0.029610409665463577, data cost:0.6938214285554547 
2022-06-29 07:45:19,849: ============================================================
2022-06-29 07:45:19,849: Epoch 19/26 Batch 6500/7662 eta: 11:18:16.169753	Training Loss 3.6548 (3.5978)	Training Prec@1 98.828 (98.361)	Training Prec@5 100.000 (99.340)	
2022-06-29 07:45:19,849: ============================================================
2022-06-29 07:46:35,554: time cost, forward:0.011557209905412527, backward:0.029631070899934477, data cost:0.6941231335450491 
2022-06-29 07:46:35,554: ============================================================
2022-06-29 07:46:35,555: Epoch 19/26 Batch 6600/7662 eta: 11:30:08.546640	Training Loss 3.7028 (3.5992)	Training Prec@1 97.852 (98.359)	Training Prec@5 99.023 (99.339)	
2022-06-29 07:46:35,555: ============================================================
2022-06-29 07:47:50,040: time cost, forward:0.011556602979991165, backward:0.02962809424735589, data cost:0.6942622887588185 
2022-06-29 07:47:50,041: ============================================================
2022-06-29 07:47:50,041: Epoch 19/26 Batch 6700/7662 eta: 11:17:47.323997	Training Loss 3.7371 (3.6008)	Training Prec@1 98.438 (98.355)	Training Prec@5 99.023 (99.337)	
2022-06-29 07:47:50,041: ============================================================
2022-06-29 07:49:04,762: time cost, forward:0.011554283120208215, backward:0.029617842654477745, data cost:0.6944420130783397 
2022-06-29 07:49:04,762: ============================================================
2022-06-29 07:49:04,762: Epoch 19/26 Batch 6800/7662 eta: 11:18:40.894604	Training Loss 3.6729 (3.6021)	Training Prec@1 98.242 (98.352)	Training Prec@5 99.219 (99.336)	
2022-06-29 07:49:04,762: ============================================================
2022-06-29 07:50:20,283: time cost, forward:0.011564379516659068, backward:0.029617731770599627, data cost:0.6947077746528839 
2022-06-29 07:50:20,283: ============================================================
2022-06-29 07:50:20,283: Epoch 19/26 Batch 6900/7662 eta: 11:24:41.254941	Training Loss 3.7788 (3.6039)	Training Prec@1 97.266 (98.346)	Training Prec@5 98.828 (99.333)	
2022-06-29 07:50:20,284: ============================================================
2022-06-29 07:51:36,187: time cost, forward:0.01157147551557135, backward:0.029590924921538562, data cost:0.6950530529294734 
2022-06-29 07:51:36,188: ============================================================
2022-06-29 07:51:36,188: Epoch 19/26 Batch 7000/7662 eta: 11:26:53.762676	Training Loss 3.5461 (3.6060)	Training Prec@1 98.242 (98.341)	Training Prec@5 99.023 (99.331)	
2022-06-29 07:51:36,188: ============================================================
2022-06-29 07:52:51,899: time cost, forward:0.011584474832545806, backward:0.029623742170074588, data cost:0.6952956540263158 
2022-06-29 07:52:51,900: ============================================================
2022-06-29 07:52:51,900: Epoch 19/26 Batch 7100/7662 eta: 11:23:53.638397	Training Loss 3.7555 (3.6079)	Training Prec@1 98.047 (98.336)	Training Prec@5 99.219 (99.329)	
2022-06-29 07:52:51,900: ============================================================
2022-06-29 07:54:06,739: time cost, forward:0.011597392658075205, backward:0.0296519428247345, data cost:0.6954132727010828 
2022-06-29 07:54:06,740: ============================================================
2022-06-29 07:54:06,740: Epoch 19/26 Batch 7200/7662 eta: 11:14:46.174504	Training Loss 4.0716 (3.6098)	Training Prec@1 97.461 (98.332)	Training Prec@5 98.828 (99.327)	
2022-06-29 07:54:06,740: ============================================================
2022-06-29 07:55:21,707: time cost, forward:0.011603273191032614, backward:0.029653598877122458, data cost:0.695578759395026 
2022-06-29 07:55:21,707: ============================================================
2022-06-29 07:55:21,708: Epoch 19/26 Batch 7300/7662 eta: 11:14:40.410804	Training Loss 3.9602 (3.6114)	Training Prec@1 97.852 (98.328)	Training Prec@5 99.219 (99.324)	
2022-06-29 07:55:21,708: ============================================================
2022-06-29 07:56:37,050: time cost, forward:0.011607583075991385, backward:0.029665872106231183, data cost:0.6957797986749926 
2022-06-29 07:56:37,051: ============================================================
2022-06-29 07:56:37,051: Epoch 19/26 Batch 7400/7662 eta: 11:16:47.709067	Training Loss 3.9754 (3.6127)	Training Prec@1 96.875 (98.325)	Training Prec@5 98.047 (99.323)	
2022-06-29 07:56:37,051: ============================================================
2022-06-29 07:57:51,963: time cost, forward:0.011613978340015648, backward:0.029686292722584773, data cost:0.6959068851799055 
2022-06-29 07:57:51,963: ============================================================
2022-06-29 07:57:51,964: Epoch 19/26 Batch 7500/7662 eta: 11:11:40.777746	Training Loss 3.5653 (3.6142)	Training Prec@1 97.266 (98.321)	Training Prec@5 99.414 (99.320)	
2022-06-29 07:57:51,964: ============================================================
2022-06-29 07:59:07,446: time cost, forward:0.011618477527303654, backward:0.029685585510418562, data cost:0.6961289782134431 
2022-06-29 07:59:07,446: ============================================================
2022-06-29 07:59:07,446: Epoch 19/26 Batch 7600/7662 eta: 11:15:31.969546	Training Loss 3.4969 (3.6154)	Training Prec@1 98.242 (98.318)	Training Prec@5 99.414 (99.319)	
2022-06-29 07:59:07,446: ============================================================
2022-06-29 07:59:55,250: Epoch: 19/26 eta: 11:14:44.415417	Training Loss 3.6058 (3.6162)	Training Prec@1 98.242 (98.317)	Training Prec@5 99.609 (99.318)
2022-06-29 07:59:55,250: ============================================================
2022-06-29 08:01:22,809: time cost, forward:0.011256901904790088, backward:0.028602494133843318, data cost:0.8371345322541516 
2022-06-29 08:01:22,809: ============================================================
2022-06-29 08:01:22,809: Epoch 20/26 Batch 100/7662 eta: 12:59:11.333297	Training Loss 2.9621 (3.0262)	Training Prec@1 98.828 (99.004)	Training Prec@5 99.414 (99.637)	
2022-06-29 08:01:22,810: ============================================================
2022-06-29 08:02:38,913: time cost, forward:0.010840943111247154, backward:0.0293354341133156, data cost:0.7783223288742143 
2022-06-29 08:02:38,913: ============================================================
2022-06-29 08:02:38,914: Epoch 20/26 Batch 200/7662 eta: 11:17:46.143402	Training Loss 2.9477 (2.9794)	Training Prec@1 98.828 (99.059)	Training Prec@5 99.414 (99.660)	
2022-06-29 08:02:38,914: ============================================================
2022-06-29 08:03:53,972: time cost, forward:0.010684779655175863, backward:0.029548602758043985, data cost:0.7554223066987003 
2022-06-29 08:03:53,973: ============================================================
2022-06-29 08:03:53,973: Epoch 20/26 Batch 300/7662 eta: 11:07:12.909289	Training Loss 2.6989 (2.9523)	Training Prec@1 99.805 (99.104)	Training Prec@5 99.805 (99.689)	
2022-06-29 08:03:53,973: ============================================================
2022-06-29 08:05:10,528: time cost, forward:0.010713541418089903, backward:0.029464139077896464, data cost:0.7478090467907134 
2022-06-29 08:05:10,528: ============================================================
2022-06-29 08:05:10,529: Epoch 20/26 Batch 400/7662 eta: 11:19:14.483536	Training Loss 2.9728 (2.9326)	Training Prec@1 99.609 (99.121)	Training Prec@5 99.805 (99.698)	
2022-06-29 08:05:10,529: ============================================================
2022-06-29 08:06:25,884: time cost, forward:0.010670293548064145, backward:0.029520950240935973, data cost:0.7408098615482002 
2022-06-29 08:06:25,884: ============================================================
2022-06-29 08:06:25,884: Epoch 20/26 Batch 500/7662 eta: 11:07:20.343556	Training Loss 2.9570 (2.9204)	Training Prec@1 98.633 (99.116)	Training Prec@5 99.414 (99.692)	
2022-06-29 08:06:25,885: ============================================================
2022-06-29 08:07:43,361: time cost, forward:0.010640374408142396, backward:0.029669157053672013, data cost:0.7395785603180951 
2022-06-29 08:07:43,361: ============================================================
2022-06-29 08:07:43,361: Epoch 20/26 Batch 600/7662 eta: 11:24:49.846277	Training Loss 2.9060 (2.9089)	Training Prec@1 99.023 (99.123)	Training Prec@5 99.414 (99.690)	
2022-06-29 08:07:43,361: ============================================================
2022-06-29 08:09:00,464: time cost, forward:0.010644717277887041, backward:0.029705251576392266, data cost:0.7382174496657518 
2022-06-29 08:09:00,464: ============================================================
2022-06-29 08:09:00,464: Epoch 20/26 Batch 700/7662 eta: 11:20:14.469351	Training Loss 2.9004 (2.9024)	Training Prec@1 98.633 (99.131)	Training Prec@5 99.414 (99.689)	
2022-06-29 08:09:00,464: ============================================================
2022-06-29 08:10:17,162: time cost, forward:0.010633227523784613, backward:0.029791855245119937, data cost:0.7366408355841798 
2022-06-29 08:10:17,162: ============================================================
2022-06-29 08:10:17,162: Epoch 20/26 Batch 800/7662 eta: 11:15:23.372782	Training Loss 2.6227 (2.8976)	Training Prec@1 99.414 (99.131)	Training Prec@5 100.000 (99.689)	
2022-06-29 08:10:17,162: ============================================================
2022-06-29 08:11:32,355: time cost, forward:0.010755963532359768, backward:0.029862027544863896, data cost:0.7335888567702789 
2022-06-29 08:11:32,355: ============================================================
2022-06-29 08:11:32,356: Epoch 20/26 Batch 900/7662 eta: 11:00:53.193172	Training Loss 3.0342 (2.8894)	Training Prec@1 98.828 (99.142)	Training Prec@5 100.000 (99.690)	
2022-06-29 08:11:32,356: ============================================================
2022-06-29 08:12:46,547: time cost, forward:0.01082527601683104, backward:0.029677421361715108, data cost:0.730448076078245 
2022-06-29 08:12:46,548: ============================================================
2022-06-29 08:12:46,548: Epoch 20/26 Batch 1000/7662 eta: 10:50:51.062559	Training Loss 2.8221 (2.8821)	Training Prec@1 99.609 (99.152)	Training Prec@5 99.805 (99.693)	
2022-06-29 08:12:46,548: ============================================================
2022-06-29 08:14:00,086: time cost, forward:0.010912471733058551, backward:0.0298855825377335, data cost:0.7268655777411421 
2022-06-29 08:14:00,086: ============================================================
2022-06-29 08:14:00,086: Epoch 20/26 Batch 1100/7662 eta: 10:43:53.376737	Training Loss 2.8714 (2.8763)	Training Prec@1 99.414 (99.151)	Training Prec@5 99.805 (99.691)	
2022-06-29 08:14:00,086: ============================================================
2022-06-29 08:15:14,620: time cost, forward:0.010995400956116487, backward:0.03005094802608283, data cost:0.7247224943751192 
2022-06-29 08:15:14,621: ============================================================
2022-06-29 08:15:14,621: Epoch 20/26 Batch 1200/7662 eta: 10:51:22.178891	Training Loss 2.7091 (2.8707)	Training Prec@1 99.609 (99.156)	Training Prec@5 100.000 (99.693)	
2022-06-29 08:15:14,621: ============================================================
2022-06-29 08:16:28,753: time cost, forward:0.011015891111108135, backward:0.030081455665335828, data cost:0.7227519377091006 
2022-06-29 08:16:28,753: ============================================================
2022-06-29 08:16:28,753: Epoch 20/26 Batch 1300/7662 eta: 10:46:37.184447	Training Loss 2.5384 (2.8642)	Training Prec@1 99.609 (99.163)	Training Prec@5 99.609 (99.695)	
2022-06-29 08:16:28,753: ============================================================
2022-06-29 08:17:44,022: time cost, forward:0.01109086725863497, backward:0.03021927728577969, data cost:0.7217089604956496 
2022-06-29 08:17:44,022: ============================================================
2022-06-29 08:17:44,022: Epoch 20/26 Batch 1400/7662 eta: 10:55:16.945124	Training Loss 2.8129 (2.8603)	Training Prec@1 98.828 (99.168)	Training Prec@5 99.414 (99.695)	
2022-06-29 08:17:44,023: ============================================================
2022-06-29 08:18:57,993: time cost, forward:0.011115819951388897, backward:0.03029255122642186, data cost:0.7200246641363917 
2022-06-29 08:18:57,993: ============================================================
2022-06-29 08:18:57,994: Epoch 20/26 Batch 1500/7662 eta: 10:42:44.878154	Training Loss 2.7161 (2.8551)	Training Prec@1 99.414 (99.171)	Training Prec@5 99.414 (99.696)	
2022-06-29 08:18:57,994: ============================================================
2022-06-29 08:20:11,655: time cost, forward:0.011095555593551435, backward:0.030272100626341322, data cost:0.7184878892642099 
2022-06-29 08:20:11,655: ============================================================
2022-06-29 08:20:11,655: Epoch 20/26 Batch 1600/7662 eta: 10:38:49.780246	Training Loss 2.9049 (2.8496)	Training Prec@1 98.633 (99.174)	Training Prec@5 99.805 (99.699)	
2022-06-29 08:20:11,655: ============================================================
2022-06-29 08:21:25,488: time cost, forward:0.011154803056587816, backward:0.030361644375527727, data cost:0.7170468422158316 
2022-06-29 08:21:25,488: ============================================================
2022-06-29 08:21:25,488: Epoch 20/26 Batch 1700/7662 eta: 10:39:05.293954	Training Loss 2.5880 (2.8451)	Training Prec@1 99.609 (99.182)	Training Prec@5 99.805 (99.701)	
2022-06-29 08:21:25,489: ============================================================
2022-06-29 08:22:38,251: time cost, forward:0.011152255661027706, backward:0.03034778606103088, data cost:0.715314450828548 
2022-06-29 08:22:38,252: ============================================================
2022-06-29 08:22:38,252: Epoch 20/26 Batch 1800/7662 eta: 10:28:36.862704	Training Loss 2.6885 (2.8400)	Training Prec@1 99.414 (99.187)	Training Prec@5 99.414 (99.704)	
2022-06-29 08:22:38,252: ============================================================
2022-06-29 08:23:52,359: time cost, forward:0.011166919464183645, backward:0.030381146577108904, data cost:0.7144149414422074 
2022-06-29 08:23:52,360: ============================================================
2022-06-29 08:23:52,360: Epoch 20/26 Batch 1900/7662 eta: 10:38:59.769504	Training Loss 2.7796 (2.8346)	Training Prec@1 99.023 (99.193)	Training Prec@5 99.609 (99.706)	
2022-06-29 08:23:52,360: ============================================================
2022-06-29 08:25:06,909: time cost, forward:0.011167531373680921, backward:0.030399756767917955, data cost:0.7138483044861436 
2022-06-29 08:25:06,910: ============================================================
2022-06-29 08:25:06,910: Epoch 20/26 Batch 2000/7662 eta: 10:41:33.864407	Training Loss 2.8698 (2.8317)	Training Prec@1 100.000 (99.195)	Training Prec@5 100.000 (99.709)	
2022-06-29 08:25:06,910: ============================================================
2022-06-29 08:26:20,187: time cost, forward:0.011141724447910986, backward:0.030430964142325493, data cost:0.7127502739230697 
2022-06-29 08:26:20,187: ============================================================
2022-06-29 08:26:20,187: Epoch 20/26 Batch 2100/7662 eta: 10:29:23.492371	Training Loss 2.8634 (2.8281)	Training Prec@1 99.414 (99.200)	Training Prec@5 100.000 (99.711)	
2022-06-29 08:26:20,187: ============================================================
2022-06-29 08:27:33,804: time cost, forward:0.011165621064911651, backward:0.03041199143770989, data cost:0.7118929720510402 
2022-06-29 08:27:33,804: ============================================================
2022-06-29 08:27:33,805: Epoch 20/26 Batch 2200/7662 eta: 10:31:05.211438	Training Loss 2.7082 (2.8248)	Training Prec@1 99.219 (99.199)	Training Prec@5 99.414 (99.710)	
2022-06-29 08:27:33,805: ============================================================
2022-06-29 08:28:47,392: time cost, forward:0.011180324002730944, backward:0.030457838248459865, data cost:0.7110489016255382 
2022-06-29 08:28:47,393: ============================================================
2022-06-29 08:28:47,393: Epoch 20/26 Batch 2300/7662 eta: 10:29:36.408153	Training Loss 2.8339 (2.8212)	Training Prec@1 99.023 (99.203)	Training Prec@5 99.805 (99.711)	
2022-06-29 08:28:47,393: ============================================================
2022-06-29 08:30:01,257: time cost, forward:0.01121249423517988, backward:0.030425569622553404, data cost:0.7104409669229715 
2022-06-29 08:30:01,257: ============================================================
2022-06-29 08:30:01,257: Epoch 20/26 Batch 2400/7662 eta: 10:30:44.451190	Training Loss 2.5637 (2.8184)	Training Prec@1 99.414 (99.202)	Training Prec@5 99.609 (99.711)	
2022-06-29 08:30:01,257: ============================================================
2022-06-29 08:31:15,656: time cost, forward:0.011227951282594337, backward:0.03045496705915032, data cost:0.7100560427570687 
2022-06-29 08:31:15,656: ============================================================
2022-06-29 08:31:15,656: Epoch 20/26 Batch 2500/7662 eta: 10:34:03.897526	Training Loss 2.7372 (2.8158)	Training Prec@1 98.828 (99.203)	Training Prec@5 99.805 (99.712)	
2022-06-29 08:31:15,656: ============================================================
2022-06-29 08:32:29,795: time cost, forward:0.01125277909649111, backward:0.030482338042661015, data cost:0.709586221835117 
2022-06-29 08:32:29,795: ============================================================
2022-06-29 08:32:29,795: Epoch 20/26 Batch 2600/7662 eta: 10:30:36.889967	Training Loss 2.7526 (2.8132)	Training Prec@1 98.828 (99.204)	Training Prec@5 99.609 (99.714)	
2022-06-29 08:32:29,795: ============================================================
2022-06-29 08:33:44,615: time cost, forward:0.011284624218454888, backward:0.030530335859883136, data cost:0.7093754713956671 
2022-06-29 08:33:44,616: ============================================================
2022-06-29 08:33:44,616: Epoch 20/26 Batch 2700/7662 eta: 10:35:09.914523	Training Loss 2.8060 (2.8102)	Training Prec@1 99.023 (99.206)	Training Prec@5 99.609 (99.713)	
2022-06-29 08:33:44,616: ============================================================
2022-06-29 08:34:59,365: time cost, forward:0.011287213138445397, backward:0.03047875499418694, data cost:0.7092808218843897 
2022-06-29 08:34:59,366: ============================================================
2022-06-29 08:34:59,366: Epoch 20/26 Batch 2800/7662 eta: 10:33:19.195951	Training Loss 2.8225 (2.8072)	Training Prec@1 99.805 (99.209)	Training Prec@5 99.805 (99.714)	
2022-06-29 08:34:59,366: ============================================================
2022-06-29 08:36:14,394: time cost, forward:0.011302914854656955, backward:0.030502526173718267, data cost:0.7091971181433298 
2022-06-29 08:36:14,395: ============================================================
2022-06-29 08:36:14,395: Epoch 20/26 Batch 2900/7662 eta: 10:34:26.048813	Training Loss 2.6365 (2.8044)	Training Prec@1 99.023 (99.209)	Training Prec@5 99.609 (99.713)	
2022-06-29 08:36:14,395: ============================================================
2022-06-29 08:37:27,377: time cost, forward:0.011342317511853316, backward:0.030516832262009293, data cost:0.7084201054002254 
2022-06-29 08:37:27,377: ============================================================
2022-06-29 08:37:27,378: Epoch 20/26 Batch 3000/7662 eta: 10:15:54.759899	Training Loss 2.7425 (2.8022)	Training Prec@1 99.023 (99.211)	Training Prec@5 99.805 (99.714)	
2022-06-29 08:37:27,378: ============================================================
2022-06-29 08:38:41,588: time cost, forward:0.011341223373610036, backward:0.030470615742705875, data cost:0.708184948041386 
2022-06-29 08:38:41,588: ============================================================
2022-06-29 08:38:41,589: Epoch 20/26 Batch 3100/7662 eta: 10:25:02.427023	Training Loss 2.7288 (2.7995)	Training Prec@1 98.828 (99.213)	Training Prec@5 99.609 (99.715)	
2022-06-29 08:38:41,589: ============================================================
2022-06-29 08:39:54,889: time cost, forward:0.011359365629605779, backward:0.030450253309254053, data cost:0.707639999783162 
2022-06-29 08:39:54,890: ============================================================
2022-06-29 08:39:54,890: Epoch 20/26 Batch 3200/7662 eta: 10:16:09.515369	Training Loss 2.6439 (2.7975)	Training Prec@1 99.219 (99.215)	Training Prec@5 99.609 (99.716)	
2022-06-29 08:39:54,890: ============================================================
2022-06-29 08:41:08,643: time cost, forward:0.011359637417407352, backward:0.03047005195767997, data cost:0.7072435896047573 
2022-06-29 08:41:08,643: ============================================================
2022-06-29 08:41:08,643: Epoch 20/26 Batch 3300/7662 eta: 10:18:43.835138	Training Loss 2.5858 (2.7946)	Training Prec@1 99.414 (99.217)	Training Prec@5 99.609 (99.716)	
2022-06-29 08:41:08,644: ============================================================
2022-06-29 08:42:23,476: time cost, forward:0.01134692770342646, backward:0.030466058177785263, data cost:0.7072281077806652 
2022-06-29 08:42:23,476: ============================================================
2022-06-29 08:42:23,476: Epoch 20/26 Batch 3400/7662 eta: 10:26:32.379560	Training Loss 2.7061 (2.7923)	Training Prec@1 100.000 (99.218)	Training Prec@5 100.000 (99.716)	
2022-06-29 08:42:23,477: ============================================================
2022-06-29 08:43:38,302: time cost, forward:0.011352604067165465, backward:0.03043900765361497, data cost:0.7072141139839131 
2022-06-29 08:43:38,302: ============================================================
2022-06-29 08:43:38,303: Epoch 20/26 Batch 3500/7662 eta: 10:25:14.096727	Training Loss 2.6601 (2.7894)	Training Prec@1 99.023 (99.220)	Training Prec@5 99.414 (99.717)	
2022-06-29 08:43:38,303: ============================================================
2022-06-29 08:44:53,379: time cost, forward:0.011361640239629722, backward:0.030411078420471038, data cost:0.7072631931198938 
2022-06-29 08:44:53,379: ============================================================
2022-06-29 08:44:53,379: Epoch 20/26 Batch 3600/7662 eta: 10:26:04.683257	Training Loss 2.8272 (2.7874)	Training Prec@1 98.828 (99.221)	Training Prec@5 99.609 (99.718)	
2022-06-29 08:44:53,380: ============================================================
2022-06-29 08:46:07,696: time cost, forward:0.011379462894667609, backward:0.030456268971080423, data cost:0.7070292853509842 
2022-06-29 08:46:07,696: ============================================================
2022-06-29 08:46:07,697: Epoch 20/26 Batch 3700/7662 eta: 10:18:30.281173	Training Loss 2.7550 (2.7854)	Training Prec@1 99.219 (99.222)	Training Prec@5 99.414 (99.719)	
2022-06-29 08:46:07,697: ============================================================
2022-06-29 08:47:21,621: time cost, forward:0.01139538750644733, backward:0.030482815704586694, data cost:0.7067233993367604 
2022-06-29 08:47:21,621: ============================================================
2022-06-29 08:47:21,621: Epoch 20/26 Batch 3800/7662 eta: 10:14:00.438060	Training Loss 2.8106 (2.7833)	Training Prec@1 98.828 (99.223)	Training Prec@5 99.609 (99.719)	
2022-06-29 08:47:21,622: ============================================================
2022-06-29 08:48:36,705: time cost, forward:0.011405948187394398, backward:0.030470372408162204, data cost:0.7067671102204364 
2022-06-29 08:48:36,706: ============================================================
2022-06-29 08:48:36,706: Epoch 20/26 Batch 3900/7662 eta: 10:22:23.250262	Training Loss 2.7638 (2.7816)	Training Prec@1 98.633 (99.223)	Training Prec@5 99.219 (99.719)	
2022-06-29 08:48:36,706: ============================================================
2022-06-29 08:49:51,901: time cost, forward:0.011448661814215303, backward:0.03045666656007645, data cost:0.7068126260652993 
2022-06-29 08:49:51,901: ============================================================
2022-06-29 08:49:51,901: Epoch 20/26 Batch 4000/7662 eta: 10:22:03.303415	Training Loss 2.7090 (2.7789)	Training Prec@1 99.414 (99.225)	Training Prec@5 99.609 (99.720)	
2022-06-29 08:49:51,902: ============================================================
2022-06-29 08:51:07,014: time cost, forward:0.011458955354357848, backward:0.030472408826539038, data cost:0.7068334256884353 
2022-06-29 08:51:07,014: ============================================================
2022-06-29 08:51:07,014: Epoch 20/26 Batch 4100/7662 eta: 10:20:07.024092	Training Loss 2.7524 (2.7767)	Training Prec@1 99.414 (99.225)	Training Prec@5 100.000 (99.720)	
2022-06-29 08:51:07,014: ============================================================
2022-06-29 08:52:21,367: time cost, forward:0.011475965164195473, backward:0.030422945083905244, data cost:0.7067298091403301 
2022-06-29 08:52:21,368: ============================================================
2022-06-29 08:52:21,368: Epoch 20/26 Batch 4200/7662 eta: 10:12:36.883445	Training Loss 2.5535 (2.7748)	Training Prec@1 99.219 (99.227)	Training Prec@5 99.609 (99.721)	
2022-06-29 08:52:21,368: ============================================================
2022-06-29 08:53:35,335: time cost, forward:0.011500806524521198, backward:0.030455077074383215, data cost:0.706454122474122 
2022-06-29 08:53:35,336: ============================================================
2022-06-29 08:53:35,336: Epoch 20/26 Batch 4300/7662 eta: 10:08:11.936685	Training Loss 2.4214 (2.7726)	Training Prec@1 99.414 (99.228)	Training Prec@5 100.000 (99.721)	
2022-06-29 08:53:35,336: ============================================================
2022-06-29 08:54:51,041: time cost, forward:0.011526269028202515, backward:0.030461225056545277, data cost:0.7066083191795549 
2022-06-29 08:54:51,041: ============================================================
2022-06-29 08:54:51,041: Epoch 20/26 Batch 4400/7662 eta: 10:21:13.736689	Training Loss 2.5024 (2.7704)	Training Prec@1 99.414 (99.228)	Training Prec@5 99.414 (99.722)	
2022-06-29 08:54:51,042: ============================================================
2022-06-29 08:56:06,553: time cost, forward:0.011546249362091723, backward:0.03045243940291921, data cost:0.7067305852000145 
2022-06-29 08:56:06,553: ============================================================
2022-06-29 08:56:06,553: Epoch 20/26 Batch 4500/7662 eta: 10:18:22.700580	Training Loss 2.7043 (2.7685)	Training Prec@1 99.023 (99.229)	Training Prec@5 99.609 (99.723)	
2022-06-29 08:56:06,553: ============================================================
2022-06-29 08:57:20,559: time cost, forward:0.011548892962826312, backward:0.030460504429007024, data cost:0.7065214561260014 
2022-06-29 08:57:20,559: ============================================================
2022-06-29 08:57:20,559: Epoch 20/26 Batch 4600/7662 eta: 10:04:48.836275	Training Loss 2.5348 (2.7668)	Training Prec@1 99.219 (99.229)	Training Prec@5 99.805 (99.723)	
2022-06-29 08:57:20,559: ============================================================
2022-06-29 08:58:34,709: time cost, forward:0.011545573581810022, backward:0.030465324373036198, data cost:0.7063614544297158 
2022-06-29 08:58:34,709: ============================================================
2022-06-29 08:58:34,710: Epoch 20/26 Batch 4700/7662 eta: 10:04:45.449201	Training Loss 2.7966 (2.7650)	Training Prec@1 98.828 (99.230)	Training Prec@5 99.414 (99.724)	
2022-06-29 08:58:34,710: ============================================================
2022-06-29 08:59:50,397: time cost, forward:0.011533932825952154, backward:0.030483252655890962, data cost:0.7065227521064505 
2022-06-29 08:59:50,397: ============================================================
2022-06-29 08:59:50,397: Epoch 20/26 Batch 4800/7662 eta: 10:16:02.113926	Training Loss 2.6147 (2.7638)	Training Prec@1 99.609 (99.231)	Training Prec@5 99.805 (99.724)	
2022-06-29 08:59:50,397: ============================================================
2022-06-29 09:01:04,767: time cost, forward:0.011548131065578893, backward:0.03050250363705182, data cost:0.70638061178098 
2022-06-29 09:01:04,768: ============================================================
2022-06-29 09:01:04,768: Epoch 20/26 Batch 4900/7662 eta: 10:04:04.471932	Training Loss 2.7555 (2.7622)	Training Prec@1 98.242 (99.231)	Training Prec@5 99.805 (99.725)	
2022-06-29 09:01:04,768: ============================================================
2022-06-29 09:02:19,858: time cost, forward:0.011545420789938017, backward:0.030505178355770032, data cost:0.7064217413203863 
2022-06-29 09:02:19,858: ============================================================
2022-06-29 09:02:19,858: Epoch 20/26 Batch 5000/7662 eta: 10:08:40.165822	Training Loss 2.6013 (2.7605)	Training Prec@1 99.609 (99.232)	Training Prec@5 100.000 (99.725)	
2022-06-29 09:02:19,858: ============================================================
2022-06-29 09:03:35,216: time cost, forward:0.011540171024167647, backward:0.03051630191462581, data cost:0.7065074438206189 
2022-06-29 09:03:35,216: ============================================================
2022-06-29 09:03:35,217: Epoch 20/26 Batch 5100/7662 eta: 10:09:35.233859	Training Loss 2.5550 (2.7589)	Training Prec@1 99.414 (99.233)	Training Prec@5 99.805 (99.726)	
2022-06-29 09:03:35,217: ============================================================
2022-06-29 09:04:51,433: time cost, forward:0.011549452952087601, backward:0.0305021945089761, data cost:0.7067598893014622 
2022-06-29 09:04:51,434: ============================================================
2022-06-29 09:04:51,434: Epoch 20/26 Batch 5200/7662 eta: 10:15:15.754764	Training Loss 2.5361 (2.7571)	Training Prec@1 99.609 (99.234)	Training Prec@5 100.000 (99.726)	
2022-06-29 09:04:51,434: ============================================================
2022-06-29 09:06:06,968: time cost, forward:0.011542760059279662, backward:0.030498181048103673, data cost:0.7068843685876516 
2022-06-29 09:06:06,968: ============================================================
2022-06-29 09:06:06,968: Epoch 20/26 Batch 5300/7662 eta: 10:08:29.678651	Training Loss 2.8167 (2.7554)	Training Prec@1 99.414 (99.235)	Training Prec@5 99.609 (99.726)	
2022-06-29 09:06:06,969: ============================================================
2022-06-29 09:07:22,556: time cost, forward:0.011542490266565703, backward:0.030500813355422016, data cost:0.7070029279571437 
2022-06-29 09:07:22,556: ============================================================
2022-06-29 09:07:22,556: Epoch 20/26 Batch 5400/7662 eta: 10:07:39.897819	Training Loss 2.8396 (2.7536)	Training Prec@1 99.219 (99.236)	Training Prec@5 99.805 (99.726)	
2022-06-29 09:07:22,557: ============================================================
2022-06-29 09:08:38,057: time cost, forward:0.011554341204362818, backward:0.030516416381805415, data cost:0.7070739122710893 
2022-06-29 09:08:38,058: ============================================================
2022-06-29 09:08:38,058: Epoch 20/26 Batch 5500/7662 eta: 10:05:42.691271	Training Loss 2.4845 (2.7519)	Training Prec@1 98.633 (99.238)	Training Prec@5 99.805 (99.727)	
2022-06-29 09:08:38,058: ============================================================
2022-06-29 09:09:53,096: time cost, forward:0.01155343786438228, backward:0.03052037842551775, data cost:0.7070869561028621 
2022-06-29 09:09:53,096: ============================================================
2022-06-29 09:09:53,097: Epoch 20/26 Batch 5600/7662 eta: 10:00:44.774545	Training Loss 2.7287 (2.7504)	Training Prec@1 99.414 (99.239)	Training Prec@5 99.609 (99.727)	
2022-06-29 09:09:53,097: ============================================================
2022-06-29 09:11:09,566: time cost, forward:0.011570393443003016, backward:0.03054273277024341, data cost:0.7073101474017631 
2022-06-29 09:11:09,566: ============================================================
2022-06-29 09:11:09,566: Epoch 20/26 Batch 5700/7662 eta: 10:10:55.661142	Training Loss 2.7096 (2.7488)	Training Prec@1 99.414 (99.240)	Training Prec@5 99.609 (99.728)	
2022-06-29 09:11:09,566: ============================================================
2022-06-29 09:12:24,687: time cost, forward:0.011571050779760696, backward:0.030542428420728435, data cost:0.7073337417940658 
2022-06-29 09:12:24,688: ============================================================
2022-06-29 09:12:24,688: Epoch 20/26 Batch 5800/7662 eta: 9:58:54.455182	Training Loss 2.5167 (2.7474)	Training Prec@1 99.414 (99.242)	Training Prec@5 100.000 (99.729)	
2022-06-29 09:12:24,688: ============================================================
2022-06-29 09:13:38,990: time cost, forward:0.011565897824057363, backward:0.03049551917246023, data cost:0.7072684404344393 
2022-06-29 09:13:38,990: ============================================================
2022-06-29 09:13:38,991: Epoch 20/26 Batch 5900/7662 eta: 9:51:08.394207	Training Loss 2.5647 (2.7457)	Training Prec@1 99.219 (99.243)	Training Prec@5 99.805 (99.730)	
2022-06-29 09:13:38,991: ============================================================
2022-06-29 09:14:54,510: time cost, forward:0.011563819335845932, backward:0.030507780826375928, data cost:0.7073477349453796 
2022-06-29 09:14:54,511: ============================================================
2022-06-29 09:14:54,511: Epoch 20/26 Batch 6000/7662 eta: 9:59:34.139723	Training Loss 2.6600 (2.7442)	Training Prec@1 99.805 (99.245)	Training Prec@5 100.000 (99.731)	
2022-06-29 09:14:54,511: ============================================================
2022-06-29 09:16:09,270: time cost, forward:0.011569125043659801, backward:0.03052590190044953, data cost:0.7072845835200214 
2022-06-29 09:16:09,270: ============================================================
2022-06-29 09:16:09,270: Epoch 20/26 Batch 6100/7662 eta: 9:52:16.844812	Training Loss 2.6332 (2.7427)	Training Prec@1 99.609 (99.245)	Training Prec@5 99.805 (99.730)	
2022-06-29 09:16:09,270: ============================================================
2022-06-29 09:17:23,880: time cost, forward:0.011570161072395179, backward:0.030526974716961894, data cost:0.7072218529042322 
2022-06-29 09:17:23,880: ============================================================
2022-06-29 09:17:23,880: Epoch 20/26 Batch 6200/7662 eta: 9:49:51.284777	Training Loss 2.6258 (2.7414)	Training Prec@1 99.219 (99.246)	Training Prec@5 100.000 (99.731)	
2022-06-29 09:17:23,880: ============================================================
2022-06-29 09:18:39,130: time cost, forward:0.011576205591376499, backward:0.030516091784440747, data cost:0.7072705218746163 
2022-06-29 09:18:39,131: ============================================================
2022-06-29 09:18:39,131: Epoch 20/26 Batch 6300/7662 eta: 9:53:39.857789	Training Loss 2.7097 (2.7399)	Training Prec@1 99.414 (99.247)	Training Prec@5 99.805 (99.730)	
2022-06-29 09:18:39,131: ============================================================
2022-06-29 09:19:53,912: time cost, forward:0.011575931980379262, backward:0.030502136693669215, data cost:0.7072539168571118 
2022-06-29 09:19:53,913: ============================================================
2022-06-29 09:19:53,913: Epoch 20/26 Batch 6400/7662 eta: 9:48:43.241806	Training Loss 2.6529 (2.7386)	Training Prec@1 99.805 (99.247)	Training Prec@5 100.000 (99.730)	
2022-06-29 09:19:53,913: ============================================================
2022-06-29 09:21:08,715: time cost, forward:0.011576900116790897, backward:0.030505843264522103, data cost:0.7072225188196467 
2022-06-29 09:21:08,715: ============================================================
2022-06-29 09:21:08,715: Epoch 20/26 Batch 6500/7662 eta: 9:47:38.203668	Training Loss 2.3679 (2.7372)	Training Prec@1 99.023 (99.249)	Training Prec@5 99.414 (99.731)	
2022-06-29 09:21:08,716: ============================================================
2022-06-29 09:22:22,460: time cost, forward:0.011581365150616989, backward:0.030522000954031566, data cost:0.7070153663512124 
2022-06-29 09:22:22,460: ============================================================
2022-06-29 09:22:22,460: Epoch 20/26 Batch 6600/7662 eta: 9:38:05.904402	Training Loss 2.5369 (2.7362)	Training Prec@1 99.414 (99.249)	Training Prec@5 99.609 (99.731)	
2022-06-29 09:22:22,460: ============================================================
2022-06-29 09:23:36,873: time cost, forward:0.011571597440827515, backward:0.03051060205930239, data cost:0.7069550510804534 
2022-06-29 09:23:36,874: ============================================================
2022-06-29 09:23:36,874: Epoch 20/26 Batch 6700/7662 eta: 9:42:06.082453	Training Loss 2.6544 (2.7347)	Training Prec@1 99.609 (99.251)	Training Prec@5 99.805 (99.731)	
2022-06-29 09:23:36,874: ============================================================
2022-06-29 09:24:52,886: time cost, forward:0.011580613452312719, backward:0.030522291161309518, data cost:0.7070885309841304 
2022-06-29 09:24:52,887: ============================================================
2022-06-29 09:24:52,887: Epoch 20/26 Batch 6800/7662 eta: 9:53:20.556123	Training Loss 2.6447 (2.7336)	Training Prec@1 99.023 (99.251)	Training Prec@5 99.414 (99.731)	
2022-06-29 09:24:52,887: ============================================================
2022-06-29 09:26:09,275: time cost, forward:0.011587794647128327, backward:0.0305157934242201, data cost:0.7072931834797459 
2022-06-29 09:26:09,276: ============================================================
2022-06-29 09:26:09,276: Epoch 20/26 Batch 6900/7662 eta: 9:55:00.500964	Training Loss 2.7249 (2.7327)	Training Prec@1 99.023 (99.252)	Training Prec@5 99.805 (99.731)	
2022-06-29 09:26:09,276: ============================================================
2022-06-29 09:27:23,496: time cost, forward:0.011592758095320642, backward:0.0304968099897973, data cost:0.7072001232864482 
2022-06-29 09:27:23,496: ============================================================
2022-06-29 09:27:23,496: Epoch 20/26 Batch 7000/7662 eta: 9:36:52.679026	Training Loss 2.6939 (2.7314)	Training Prec@1 99.414 (99.253)	Training Prec@5 99.805 (99.732)	
2022-06-29 09:27:23,496: ============================================================
2022-06-29 09:28:38,491: time cost, forward:0.01159833420966944, backward:0.030509693821747046, data cost:0.7071829029902184 
2022-06-29 09:28:38,491: ============================================================
2022-06-29 09:28:38,491: Epoch 20/26 Batch 7100/7662 eta: 9:41:38.746124	Training Loss 2.7654 (2.7301)	Training Prec@1 98.828 (99.254)	Training Prec@5 99.414 (99.732)	
2022-06-29 09:28:38,491: ============================================================
2022-06-29 09:29:53,618: time cost, forward:0.011598827839228889, backward:0.03052374041234475, data cost:0.707191428602992 
2022-06-29 09:29:53,619: ============================================================
2022-06-29 09:29:53,619: Epoch 20/26 Batch 7200/7662 eta: 9:41:25.642637	Training Loss 2.8292 (2.7288)	Training Prec@1 99.219 (99.255)	Training Prec@5 100.000 (99.732)	
2022-06-29 09:29:53,619: ============================================================
2022-06-29 09:31:08,654: time cost, forward:0.01160483756184921, backward:0.030538568693998007, data cost:0.7071782675715795 
2022-06-29 09:31:08,655: ============================================================
2022-06-29 09:31:08,655: Epoch 20/26 Batch 7300/7662 eta: 9:39:27.871062	Training Loss 2.4352 (2.7276)	Training Prec@1 99.414 (99.256)	Training Prec@5 100.000 (99.733)	
2022-06-29 09:31:08,655: ============================================================
2022-06-29 09:32:24,644: time cost, forward:0.01160724367027525, backward:0.03053719263686443, data cost:0.7073131089017817 
2022-06-29 09:32:24,644: ============================================================
2022-06-29 09:32:24,645: Epoch 20/26 Batch 7400/7662 eta: 9:45:33.868476	Training Loss 2.6428 (2.7261)	Training Prec@1 99.609 (99.257)	Training Prec@5 99.805 (99.733)	
2022-06-29 09:32:24,645: ============================================================
2022-06-29 09:33:39,609: time cost, forward:0.011592833610165356, backward:0.030543832750952488, data cost:0.7073167459633147 
2022-06-29 09:33:39,609: ============================================================
2022-06-29 09:33:39,610: Epoch 20/26 Batch 7500/7662 eta: 9:36:25.156388	Training Loss 2.4508 (2.7249)	Training Prec@1 99.609 (99.259)	Training Prec@5 99.805 (99.734)	
2022-06-29 09:33:39,610: ============================================================
2022-06-29 09:34:56,223: time cost, forward:0.01159428223008654, backward:0.030542371398227, data cost:0.7075306400686114 
2022-06-29 09:34:56,223: ============================================================
2022-06-29 09:34:56,224: Epoch 20/26 Batch 7600/7662 eta: 9:47:49.237487	Training Loss 2.5092 (2.7237)	Training Prec@1 99.609 (99.259)	Training Prec@5 100.000 (99.734)	
2022-06-29 09:34:56,224: ============================================================
2022-06-29 09:35:44,962: Epoch: 20/26 eta: 9:47:00.970690	Training Loss 2.8201 (2.7227)	Training Prec@1 99.609 (99.260)	Training Prec@5 100.000 (99.735)
2022-06-29 09:35:44,962: ============================================================
2022-06-29 09:35:45,100: Save Checkpoint...
2022-06-29 09:35:45,118: ============================================================
2022-06-29 09:35:48,094: Save done!
2022-06-29 09:35:48,094: ============================================================
2022-06-29 09:37:25,317: time cost, forward:0.011231417607779454, backward:0.028597651105938537, data cost:0.9365789866206622 
2022-06-29 09:37:25,317: ============================================================
2022-06-29 09:37:25,317: Epoch 21/26 Batch 100/7662 eta: 12:23:06.414015	Training Loss 2.3934 (2.4203)	Training Prec@1 99.414 (99.525)	Training Prec@5 99.609 (99.844)	
2022-06-29 09:37:25,317: ============================================================
2022-06-29 09:38:40,506: time cost, forward:0.010972526205244975, backward:0.02865590881462672, data cost:0.8237186640351262 
2022-06-29 09:38:40,507: ============================================================
2022-06-29 09:38:40,507: Epoch 21/26 Batch 200/7662 eta: 9:33:36.461285	Training Loss 2.4727 (2.4343)	Training Prec@1 99.219 (99.529)	Training Prec@5 99.805 (99.838)	
2022-06-29 09:38:40,507: ============================================================
2022-06-29 09:39:54,859: time cost, forward:0.010786133067663697, backward:0.028428294586896097, data cost:0.7839218366106219 
2022-06-29 09:39:54,860: ============================================================
2022-06-29 09:39:54,860: Epoch 21/26 Batch 300/7662 eta: 9:25:59.253605	Training Loss 2.5745 (2.4414)	Training Prec@1 99.219 (99.521)	Training Prec@5 99.609 (99.834)	
2022-06-29 09:39:54,860: ============================================================
2022-06-29 09:41:10,566: time cost, forward:0.010689001633111098, backward:0.02854325418783011, data cost:0.7672346337397296 
2022-06-29 09:41:10,566: ============================================================
2022-06-29 09:41:10,566: Epoch 21/26 Batch 400/7662 eta: 9:35:01.747391	Training Loss 2.4362 (2.4400)	Training Prec@1 99.219 (99.524)	Training Prec@5 99.609 (99.838)	
2022-06-29 09:41:10,567: ============================================================
2022-06-29 09:42:28,093: time cost, forward:0.010574927549801752, backward:0.028726737819358198, data cost:0.7608338477377423 
2022-06-29 09:42:28,093: ============================================================
2022-06-29 09:42:28,094: Epoch 21/26 Batch 500/7662 eta: 9:47:33.912642	Training Loss 2.1748 (2.4464)	Training Prec@1 100.000 (99.525)	Training Prec@5 100.000 (99.838)	
2022-06-29 09:42:28,094: ============================================================
2022-06-29 09:43:45,648: time cost, forward:0.010521685738794393, backward:0.02887274426888544, data cost:0.7565637617955024 
2022-06-29 09:43:45,649: ============================================================
2022-06-29 09:43:45,649: Epoch 21/26 Batch 600/7662 eta: 9:46:29.182927	Training Loss 2.5024 (2.4477)	Training Prec@1 99.414 (99.514)	Training Prec@5 100.000 (99.835)	
2022-06-29 09:43:45,649: ============================================================
2022-06-29 09:45:00,482: time cost, forward:0.010490998689708791, backward:0.02903832284166066, data cost:0.7495533956137509 
2022-06-29 09:45:00,482: ============================================================
2022-06-29 09:45:00,482: Epoch 21/26 Batch 700/7662 eta: 9:24:39.286653	Training Loss 2.6500 (2.4469)	Training Prec@1 99.805 (99.521)	Training Prec@5 99.805 (99.837)	
2022-06-29 09:45:00,482: ============================================================
2022-06-29 09:46:16,935: time cost, forward:0.010435126153041185, backward:0.029137085615022013, data cost:0.7463864193989129 
2022-06-29 09:46:16,935: ============================================================
2022-06-29 09:46:16,935: Epoch 21/26 Batch 800/7662 eta: 9:35:36.239946	Training Loss 2.5968 (2.4482)	Training Prec@1 99.805 (99.520)	Training Prec@5 100.000 (99.835)	
2022-06-29 09:46:16,936: ============================================================
2022-06-29 09:47:33,884: time cost, forward:0.010431170596164113, backward:0.02924052096314902, data cost:0.7444051974872593 
2022-06-29 09:47:33,884: ============================================================
2022-06-29 09:47:33,884: Epoch 21/26 Batch 900/7662 eta: 9:38:03.047768	Training Loss 2.4694 (2.4519)	Training Prec@1 99.023 (99.514)	Training Prec@5 100.000 (99.834)	
2022-06-29 09:47:33,884: ============================================================
2022-06-29 09:48:49,532: time cost, forward:0.0103827945224277, backward:0.029321529008485413, data cost:0.7415685825519733 
2022-06-29 09:48:49,533: ============================================================
2022-06-29 09:48:49,533: Epoch 21/26 Batch 1000/7662 eta: 9:27:01.539817	Training Loss 2.3708 (2.4523)	Training Prec@1 99.414 (99.512)	Training Prec@5 99.805 (99.832)	
2022-06-29 09:48:49,533: ============================================================
2022-06-29 09:50:07,187: time cost, forward:0.010363996191606183, backward:0.029335606629681436, data cost:0.7411102320087075 
2022-06-29 09:50:07,187: ============================================================
2022-06-29 09:50:07,188: Epoch 21/26 Batch 1100/7662 eta: 9:40:46.010774	Training Loss 2.3789 (2.4513)	Training Prec@1 99.414 (99.511)	Training Prec@5 99.609 (99.832)	
2022-06-29 09:50:07,188: ============================================================
2022-06-29 09:51:25,574: time cost, forward:0.010357961941003998, backward:0.029411093804913822, data cost:0.741258702942289 
2022-06-29 09:51:25,574: ============================================================
2022-06-29 09:51:25,575: Epoch 21/26 Batch 1200/7662 eta: 9:44:56.179310	Training Loss 2.5709 (2.4531)	Training Prec@1 99.609 (99.511)	Training Prec@5 99.609 (99.831)	
2022-06-29 09:51:25,575: ============================================================
2022-06-29 09:52:42,116: time cost, forward:0.010359434828196607, backward:0.029449077272892366, data cost:0.7399878711127794 
2022-06-29 09:52:42,116: ============================================================
2022-06-29 09:52:42,116: Epoch 21/26 Batch 1300/7662 eta: 9:29:53.569342	Training Loss 2.6289 (2.4537)	Training Prec@1 99.023 (99.509)	Training Prec@5 99.805 (99.830)	
2022-06-29 09:52:42,117: ============================================================
2022-06-29 09:53:55,319: time cost, forward:0.010423829676510182, backward:0.029542082969932746, data cost:0.7363821499001733 
2022-06-29 09:53:55,320: ============================================================
2022-06-29 09:53:55,320: Epoch 21/26 Batch 1400/7662 eta: 9:03:48.897026	Training Loss 2.5705 (2.4541)	Training Prec@1 98.438 (99.508)	Training Prec@5 99.219 (99.828)	
2022-06-29 09:53:55,320: ============================================================
2022-06-29 09:55:08,691: time cost, forward:0.010520791116756467, backward:0.02965674979277974, data cost:0.733302914515744 
2022-06-29 09:55:08,691: ============================================================
2022-06-29 09:55:08,691: Epoch 21/26 Batch 1500/7662 eta: 9:03:50.510277	Training Loss 2.4744 (2.4549)	Training Prec@1 99.414 (99.508)	Training Prec@5 100.000 (99.829)	
2022-06-29 09:55:08,691: ============================================================
2022-06-29 09:56:21,793: time cost, forward:0.010568628018911813, backward:0.02971954223437187, data cost:0.7305031021063294 
2022-06-29 09:56:21,793: ============================================================
2022-06-29 09:56:21,794: Epoch 21/26 Batch 1600/7662 eta: 9:00:37.712958	Training Loss 2.5235 (2.4551)	Training Prec@1 99.805 (99.507)	Training Prec@5 100.000 (99.829)	
2022-06-29 09:56:21,794: ============================================================
2022-06-29 09:57:35,495: time cost, forward:0.010576299529274889, backward:0.029700607885817628, data cost:0.7285104858798094 
2022-06-29 09:57:35,495: ============================================================
2022-06-29 09:57:35,496: Epoch 21/26 Batch 1700/7662 eta: 9:03:50.070056	Training Loss 2.4949 (2.4554)	Training Prec@1 99.805 (99.507)	Training Prec@5 100.000 (99.828)	
2022-06-29 09:57:35,496: ============================================================
2022-06-29 09:58:47,620: time cost, forward:0.010573930644936003, backward:0.029743034353250923, data cost:0.7257987932074792 
2022-06-29 09:58:47,621: ============================================================
2022-06-29 09:58:47,621: Epoch 21/26 Batch 1800/7662 eta: 8:50:59.897996	Training Loss 2.5031 (2.4562)	Training Prec@1 99.414 (99.506)	Training Prec@5 99.609 (99.827)	
2022-06-29 09:58:47,621: ============================================================
2022-06-29 10:00:01,694: time cost, forward:0.010648975502885976, backward:0.029797132797401916, data cost:0.7243071618112782 
2022-06-29 10:00:01,694: ============================================================
2022-06-29 10:00:01,694: Epoch 21/26 Batch 1900/7662 eta: 9:04:06.324828	Training Loss 2.4415 (2.4568)	Training Prec@1 99.805 (99.505)	Training Prec@5 99.805 (99.826)	
2022-06-29 10:00:01,694: ============================================================
2022-06-29 10:01:14,540: time cost, forward:0.010723542546915854, backward:0.029845466251192002, data cost:0.7223475438585992 
2022-06-29 10:01:14,540: ============================================================
2022-06-29 10:01:14,540: Epoch 21/26 Batch 2000/7662 eta: 8:53:52.550802	Training Loss 2.4263 (2.4570)	Training Prec@1 99.219 (99.503)	Training Prec@5 99.414 (99.827)	
2022-06-29 10:01:14,540: ============================================================
2022-06-29 10:02:28,472: time cost, forward:0.010777652235244671, backward:0.029928192290423768, data cost:0.7210633628648937 
2022-06-29 10:02:28,472: ============================================================
2022-06-29 10:02:28,472: Epoch 21/26 Batch 2100/7662 eta: 9:00:36.182037	Training Loss 2.4684 (2.4585)	Training Prec@1 99.805 (99.503)	Training Prec@5 100.000 (99.826)	
2022-06-29 10:02:28,472: ============================================================
2022-06-29 10:03:43,037: time cost, forward:0.010803091683242472, backward:0.029963196272631026, data cost:0.7202525634340613 
2022-06-29 10:03:43,038: ============================================================
2022-06-29 10:03:43,038: Epoch 21/26 Batch 2200/7662 eta: 9:03:59.632092	Training Loss 2.5177 (2.4598)	Training Prec@1 99.219 (99.502)	Training Prec@5 99.805 (99.825)	
2022-06-29 10:03:43,038: ============================================================
2022-06-29 10:04:57,326: time cost, forward:0.010848272982344725, backward:0.02995058711376746, data cost:0.7194077768446104 
2022-06-29 10:04:57,326: ============================================================
2022-06-29 10:04:57,326: Epoch 21/26 Batch 2300/7662 eta: 9:00:43.990396	Training Loss 2.4991 (2.4609)	Training Prec@1 99.609 (99.499)	Training Prec@5 99.609 (99.824)	
2022-06-29 10:04:57,326: ============================================================
2022-06-29 10:06:09,389: time cost, forward:0.010875745433824864, backward:0.029985016214196608, data cost:0.7176791233239247 
2022-06-29 10:06:09,389: ============================================================
2022-06-29 10:06:09,389: Epoch 21/26 Batch 2400/7662 eta: 8:43:20.026869	Training Loss 2.5153 (2.4614)	Training Prec@1 99.219 (99.500)	Training Prec@5 99.805 (99.824)	
2022-06-29 10:06:09,389: ============================================================
2022-06-29 10:07:23,245: time cost, forward:0.010885965065652725, backward:0.030033738959450967, data cost:0.7168027087658488 
2022-06-29 10:07:23,246: ============================================================
2022-06-29 10:07:23,246: Epoch 21/26 Batch 2500/7662 eta: 8:55:07.639834	Training Loss 2.4925 (2.4614)	Training Prec@1 99.219 (99.501)	Training Prec@5 99.609 (99.824)	
2022-06-29 10:07:23,246: ============================================================
2022-06-29 10:08:36,432: time cost, forward:0.010902626508013383, backward:0.030013964606413892, data cost:0.715791909040603 
2022-06-29 10:08:36,432: ============================================================
2022-06-29 10:08:36,433: Epoch 21/26 Batch 2600/7662 eta: 8:49:03.244066	Training Loss 2.3553 (2.4628)	Training Prec@1 100.000 (99.499)	Training Prec@5 100.000 (99.822)	
2022-06-29 10:08:36,433: ============================================================
2022-06-29 10:09:49,517: time cost, forward:0.010918375738199749, backward:0.02990672870139892, data cost:0.7149122882304522 
2022-06-29 10:09:49,518: ============================================================
2022-06-29 10:09:49,518: Epoch 21/26 Batch 2700/7662 eta: 8:47:06.297495	Training Loss 2.5464 (2.4628)	Training Prec@1 99.219 (99.498)	Training Prec@5 99.805 (99.822)	
2022-06-29 10:09:49,518: ============================================================
2022-06-29 10:11:02,315: time cost, forward:0.010918254893181281, backward:0.029718104069809608, data cost:0.7140894860359293 
2022-06-29 10:11:02,315: ============================================================
2022-06-29 10:11:02,315: Epoch 21/26 Batch 2800/7662 eta: 8:43:48.843014	Training Loss 2.6487 (2.4634)	Training Prec@1 99.219 (99.496)	Training Prec@5 99.609 (99.822)	
2022-06-29 10:11:02,316: ============================================================
2022-06-29 10:12:15,429: time cost, forward:0.010935213533752168, backward:0.029713402702381545, data cost:0.7132488377713548 
2022-06-29 10:12:15,429: ============================================================
2022-06-29 10:12:15,429: Epoch 21/26 Batch 2900/7662 eta: 8:44:52.358237	Training Loss 2.5231 (2.4643)	Training Prec@1 100.000 (99.495)	Training Prec@5 100.000 (99.821)	
2022-06-29 10:12:15,429: ============================================================
2022-06-29 10:13:28,594: time cost, forward:0.010950664553335406, backward:0.029754758636408467, data cost:0.712436243548875 
2022-06-29 10:13:28,594: ============================================================
2022-06-29 10:13:28,594: Epoch 21/26 Batch 3000/7662 eta: 8:44:01.201069	Training Loss 2.3917 (2.4638)	Training Prec@1 99.609 (99.495)	Training Prec@5 99.805 (99.820)	
2022-06-29 10:13:28,595: ============================================================
2022-06-29 10:14:41,787: time cost, forward:0.010990263993373106, backward:0.02980527365426934, data cost:0.7116485344436562 
2022-06-29 10:14:41,787: ============================================================
2022-06-29 10:14:41,788: Epoch 21/26 Batch 3100/7662 eta: 8:43:00.125795	Training Loss 2.5145 (2.4646)	Training Prec@1 99.609 (99.496)	Training Prec@5 100.000 (99.820)	
2022-06-29 10:14:41,788: ============================================================
2022-06-29 10:15:55,819: time cost, forward:0.011022684387059166, backward:0.029839693586988052, data cost:0.7111861220595612 
2022-06-29 10:15:55,819: ============================================================
2022-06-29 10:15:55,819: Epoch 21/26 Batch 3200/7662 eta: 8:47:45.559315	Training Loss 2.4949 (2.4650)	Training Prec@1 99.023 (99.494)	Training Prec@5 99.609 (99.820)	
2022-06-29 10:15:55,819: ============================================================
2022-06-29 10:17:09,445: time cost, forward:0.011001598766334999, backward:0.02985608935464545, data cost:0.7107014614150321 
2022-06-29 10:17:09,445: ============================================================
2022-06-29 10:17:09,446: Epoch 21/26 Batch 3300/7662 eta: 8:43:38.526114	Training Loss 2.6093 (2.4659)	Training Prec@1 99.609 (99.494)	Training Prec@5 100.000 (99.820)	
2022-06-29 10:17:09,446: ============================================================
2022-06-29 10:18:22,537: time cost, forward:0.01100931668428857, backward:0.029881813484768757, data cost:0.7100469059507859 
2022-06-29 10:18:22,538: ============================================================
2022-06-29 10:18:22,538: Epoch 21/26 Batch 3400/7662 eta: 8:38:37.572977	Training Loss 2.1638 (2.4666)	Training Prec@1 100.000 (99.494)	Training Prec@5 100.000 (99.821)	
2022-06-29 10:18:22,538: ============================================================
2022-06-29 10:19:37,097: time cost, forward:0.011015548744212563, backward:0.029838388052692615, data cost:0.7099190122163375 
2022-06-29 10:19:37,098: ============================================================
2022-06-29 10:19:37,098: Epoch 21/26 Batch 3500/7662 eta: 8:47:47.928420	Training Loss 2.4825 (2.4666)	Training Prec@1 99.609 (99.495)	Training Prec@5 100.000 (99.821)	
2022-06-29 10:19:37,098: ============================================================
2022-06-29 10:20:48,997: time cost, forward:0.011037848929161162, backward:0.029843723287049782, data cost:0.7089977867903395 
2022-06-29 10:20:48,997: ============================================================
2022-06-29 10:20:48,997: Epoch 21/26 Batch 3600/7662 eta: 8:27:45.899624	Training Loss 2.2527 (2.4665)	Training Prec@1 99.805 (99.496)	Training Prec@5 99.805 (99.822)	
2022-06-29 10:20:48,997: ============================================================
2022-06-29 10:22:02,069: time cost, forward:0.011051066342673775, backward:0.029871203249033865, data cost:0.7084250754361283 
2022-06-29 10:22:02,069: ============================================================
2022-06-29 10:22:02,069: Epoch 21/26 Batch 3700/7662 eta: 8:34:49.682427	Training Loss 2.3351 (2.4665)	Training Prec@1 99.805 (99.495)	Training Prec@5 100.000 (99.821)	
2022-06-29 10:22:02,069: ============================================================
2022-06-29 10:23:15,483: time cost, forward:0.011053096749149331, backward:0.029856397277840063, data cost:0.7080255600300924 
2022-06-29 10:23:15,483: ============================================================
2022-06-29 10:23:15,483: Epoch 21/26 Batch 3800/7662 eta: 8:36:00.936308	Training Loss 2.5794 (2.4668)	Training Prec@1 98.828 (99.494)	Training Prec@5 99.609 (99.821)	
2022-06-29 10:23:15,483: ============================================================
2022-06-29 10:24:29,504: time cost, forward:0.011049573376839759, backward:0.029864933222310607, data cost:0.7077881172089187 
2022-06-29 10:24:29,504: ============================================================
2022-06-29 10:24:29,504: Epoch 21/26 Batch 3900/7662 eta: 8:39:02.805638	Training Loss 2.4687 (2.4673)	Training Prec@1 99.023 (99.492)	Training Prec@5 99.609 (99.820)	
2022-06-29 10:24:29,504: ============================================================
2022-06-29 10:25:43,056: time cost, forward:0.011058706616007944, backward:0.029897863192986356, data cost:0.7074032145817598 
2022-06-29 10:25:43,057: ============================================================
2022-06-29 10:25:43,057: Epoch 21/26 Batch 4000/7662 eta: 8:34:32.277291	Training Loss 2.3985 (2.4678)	Training Prec@1 99.219 (99.492)	Training Prec@5 100.000 (99.821)	
2022-06-29 10:25:43,057: ============================================================
2022-06-29 10:26:57,960: time cost, forward:0.011065666313199307, backward:0.02997378373500864, data cost:0.7073259433323827 
2022-06-29 10:26:57,961: ============================================================
2022-06-29 10:26:57,961: Epoch 21/26 Batch 4100/7662 eta: 8:42:44.550641	Training Loss 2.2783 (2.4684)	Training Prec@1 100.000 (99.491)	Training Prec@5 100.000 (99.822)	
2022-06-29 10:26:57,961: ============================================================
2022-06-29 10:28:12,519: time cost, forward:0.011087766514701143, backward:0.030002733842904694, data cost:0.7071964586311988 
2022-06-29 10:28:12,519: ============================================================
2022-06-29 10:28:12,520: Epoch 21/26 Batch 4200/7662 eta: 8:39:05.406583	Training Loss 2.4636 (2.4685)	Training Prec@1 99.609 (99.492)	Training Prec@5 99.805 (99.821)	
2022-06-29 10:28:12,520: ============================================================
2022-06-29 10:29:28,121: time cost, forward:0.011101379536506492, backward:0.029991503287592886, data cost:0.7073671135078283 
2022-06-29 10:29:28,122: ============================================================
2022-06-29 10:29:28,122: Epoch 21/26 Batch 4300/7662 eta: 8:45:05.681669	Training Loss 2.3670 (2.4691)	Training Prec@1 99.609 (99.492)	Training Prec@5 100.000 (99.822)	
2022-06-29 10:29:28,122: ============================================================
2022-06-29 10:30:43,393: time cost, forward:0.011116961398756647, backward:0.029967627652153748, data cost:0.7074589150470613 
2022-06-29 10:30:43,393: ============================================================
2022-06-29 10:30:43,393: Epoch 21/26 Batch 4400/7662 eta: 8:41:32.666434	Training Loss 2.4091 (2.4695)	Training Prec@1 99.609 (99.492)	Training Prec@5 99.805 (99.821)	
2022-06-29 10:30:43,393: ============================================================
2022-06-29 10:31:58,347: time cost, forward:0.011144714160451997, backward:0.02998240504378238, data cost:0.707429741297491 
2022-06-29 10:31:58,347: ============================================================
2022-06-29 10:31:58,347: Epoch 21/26 Batch 4500/7662 eta: 8:38:05.587481	Training Loss 2.3645 (2.4704)	Training Prec@1 99.219 (99.492)	Training Prec@5 99.219 (99.821)	
2022-06-29 10:31:58,347: ============================================================
2022-06-29 10:33:13,296: time cost, forward:0.011170960426537932, backward:0.030013697228760378, data cost:0.7073807912330105 
2022-06-29 10:33:13,297: ============================================================
2022-06-29 10:33:13,297: Epoch 21/26 Batch 4600/7662 eta: 8:36:48.970600	Training Loss 2.4897 (2.4710)	Training Prec@1 99.609 (99.492)	Training Prec@5 99.805 (99.821)	
2022-06-29 10:33:13,297: ============================================================
2022-06-29 10:34:27,069: time cost, forward:0.011180567117314766, backward:0.030025693146972916, data cost:0.707117018635716 
2022-06-29 10:34:27,070: ============================================================
2022-06-29 10:34:27,070: Epoch 21/26 Batch 4700/7662 eta: 8:27:28.280302	Training Loss 2.5733 (2.4714)	Training Prec@1 99.414 (99.492)	Training Prec@5 99.609 (99.821)	
2022-06-29 10:34:27,070: ============================================================
2022-06-29 10:35:41,138: time cost, forward:0.011206758248356388, backward:0.03002972452807958, data cost:0.7069179093149658 
2022-06-29 10:35:41,139: ============================================================
2022-06-29 10:35:41,139: Epoch 21/26 Batch 4800/7662 eta: 8:28:16.406304	Training Loss 2.5412 (2.4721)	Training Prec@1 99.414 (99.491)	Training Prec@5 100.000 (99.821)	
2022-06-29 10:35:41,139: ============================================================
2022-06-29 10:36:55,100: time cost, forward:0.011236987617167193, backward:0.03003422706364174, data cost:0.7066985247791677 
2022-06-29 10:36:55,100: ============================================================
2022-06-29 10:36:55,100: Epoch 21/26 Batch 4900/7662 eta: 8:26:18.196780	Training Loss 2.6079 (2.4725)	Training Prec@1 99.414 (99.490)	Training Prec@5 100.000 (99.820)	
2022-06-29 10:36:55,100: ============================================================
2022-06-29 10:38:09,171: time cost, forward:0.011258636290704185, backward:0.029996819533355524, data cost:0.7065587012761592 
2022-06-29 10:38:09,171: ============================================================
2022-06-29 10:38:09,171: Epoch 21/26 Batch 5000/7662 eta: 8:25:49.120346	Training Loss 2.4553 (2.4725)	Training Prec@1 99.805 (99.490)	Training Prec@5 99.805 (99.821)	
2022-06-29 10:38:09,171: ============================================================
2022-06-29 10:39:24,396: time cost, forward:0.011279804188963431, backward:0.029985118786665384, data cost:0.706628340790145 
2022-06-29 10:39:24,396: ============================================================
2022-06-29 10:39:24,396: Epoch 21/26 Batch 5100/7662 eta: 8:32:26.746661	Training Loss 2.5092 (2.4728)	Training Prec@1 99.805 (99.490)	Training Prec@5 100.000 (99.821)	
2022-06-29 10:39:24,397: ============================================================
2022-06-29 10:40:38,713: time cost, forward:0.011302722832587481, backward:0.03002740048655961, data cost:0.7064635530759059 
2022-06-29 10:40:38,714: ============================================================
2022-06-29 10:40:38,714: Epoch 21/26 Batch 5200/7662 eta: 8:25:01.429897	Training Loss 2.6258 (2.4734)	Training Prec@1 99.609 (99.489)	Training Prec@5 99.805 (99.821)	
2022-06-29 10:40:38,714: ============================================================
2022-06-29 10:41:54,497: time cost, forward:0.011308044729468551, backward:0.0300414867728673, data cost:0.7066249582402593 
2022-06-29 10:41:54,497: ============================================================
2022-06-29 10:41:54,498: Epoch 21/26 Batch 5300/7662 eta: 8:33:43.517097	Training Loss 2.3792 (2.4744)	Training Prec@1 99.414 (99.488)	Training Prec@5 100.000 (99.821)	
2022-06-29 10:41:54,498: ============================================================
2022-06-29 10:43:09,473: time cost, forward:0.011313077011998659, backward:0.03004572417564272, data cost:0.7066404116906642 
2022-06-29 10:43:09,473: ============================================================
2022-06-29 10:43:09,473: Epoch 21/26 Batch 5400/7662 eta: 8:26:59.850577	Training Loss 2.6703 (2.4749)	Training Prec@1 99.609 (99.488)	Training Prec@5 99.805 (99.821)	
2022-06-29 10:43:09,473: ============================================================
2022-06-29 10:44:25,178: time cost, forward:0.011326417768623726, backward:0.03008164317201627, data cost:0.7067501172518206 
2022-06-29 10:44:25,179: ============================================================
2022-06-29 10:44:25,179: Epoch 21/26 Batch 5500/7662 eta: 8:30:40.365709	Training Loss 2.5360 (2.4755)	Training Prec@1 99.805 (99.487)	Training Prec@5 99.805 (99.820)	
2022-06-29 10:44:25,179: ============================================================
2022-06-29 10:45:39,965: time cost, forward:0.011328300422250128, backward:0.030106128294737473, data cost:0.7067083934733518 
2022-06-29 10:45:39,965: ============================================================
2022-06-29 10:45:39,965: Epoch 21/26 Batch 5600/7662 eta: 8:23:13.553347	Training Loss 2.5900 (2.4758)	Training Prec@1 99.219 (99.487)	Training Prec@5 99.609 (99.820)	
2022-06-29 10:45:39,965: ============================================================
2022-06-29 10:46:54,427: time cost, forward:0.011343288890184655, backward:0.030136390325583413, data cost:0.7065924320080381 
2022-06-29 10:46:54,427: ============================================================
2022-06-29 10:46:54,427: Epoch 21/26 Batch 5700/7662 eta: 8:19:48.088898	Training Loss 2.4604 (2.4761)	Training Prec@1 99.609 (99.486)	Training Prec@5 100.000 (99.820)	
2022-06-29 10:46:54,427: ============================================================
2022-06-29 10:48:09,691: time cost, forward:0.011357395417485941, backward:0.030165079853250603, data cost:0.706620408905274 
2022-06-29 10:48:09,691: ============================================================
2022-06-29 10:48:09,691: Epoch 21/26 Batch 5800/7662 eta: 8:23:55.683714	Training Loss 2.7339 (2.4768)	Training Prec@1 99.219 (99.485)	Training Prec@5 99.805 (99.820)	
2022-06-29 10:48:09,691: ============================================================
2022-06-29 10:49:24,635: time cost, forward:0.011367519986207131, backward:0.03020430492291836, data cost:0.7065850446377392 
2022-06-29 10:49:24,635: ============================================================
2022-06-29 10:49:24,635: Epoch 21/26 Batch 5900/7662 eta: 8:20:32.279982	Training Loss 2.2313 (2.4769)	Training Prec@1 99.805 (99.485)	Training Prec@5 100.000 (99.820)	
2022-06-29 10:49:24,635: ============================================================
2022-06-29 10:50:38,366: time cost, forward:0.011363855579094521, backward:0.03022263737236744, data cost:0.7063817213646351 
2022-06-29 10:50:38,367: ============================================================
2022-06-29 10:50:38,367: Epoch 21/26 Batch 6000/7662 eta: 8:11:12.825407	Training Loss 2.6968 (2.4771)	Training Prec@1 99.414 (99.484)	Training Prec@5 99.805 (99.820)	
2022-06-29 10:50:38,367: ============================================================
2022-06-29 10:51:51,477: time cost, forward:0.011372240317964343, backward:0.030221343255469126, data cost:0.706090453414179 
2022-06-29 10:51:51,478: ============================================================
2022-06-29 10:51:51,478: Epoch 21/26 Batch 6100/7662 eta: 8:05:51.507416	Training Loss 2.4469 (2.4777)	Training Prec@1 99.805 (99.483)	Training Prec@5 100.000 (99.820)	
2022-06-29 10:51:51,478: ============================================================
2022-06-29 10:53:06,612: time cost, forward:0.011371891774329703, backward:0.030219428865039206, data cost:0.7061444859213166 
2022-06-29 10:53:06,612: ============================================================
2022-06-29 10:53:06,612: Epoch 21/26 Batch 6200/7662 eta: 8:18:03.327100	Training Loss 2.4176 (2.4781)	Training Prec@1 99.023 (99.483)	Training Prec@5 99.414 (99.819)	
2022-06-29 10:53:06,613: ============================================================
2022-06-29 10:54:20,747: time cost, forward:0.011364078234066792, backward:0.03023162961554993, data cost:0.7060313929185202 
2022-06-29 10:54:20,747: ============================================================
2022-06-29 10:54:20,747: Epoch 21/26 Batch 6300/7662 eta: 8:10:11.518294	Training Loss 2.2910 (2.4785)	Training Prec@1 99.219 (99.483)	Training Prec@5 99.609 (99.819)	
2022-06-29 10:54:20,747: ============================================================
2022-06-29 10:55:35,789: time cost, forward:0.01136918007572995, backward:0.030225715295917114, data cost:0.7060696743376312 
2022-06-29 10:55:35,789: ============================================================
2022-06-29 10:55:35,789: Epoch 21/26 Batch 6400/7662 eta: 8:14:56.305770	Training Loss 2.4046 (2.4787)	Training Prec@1 99.609 (99.483)	Training Prec@5 100.000 (99.819)	
2022-06-29 10:55:35,789: ============================================================
2022-06-29 10:56:49,919: time cost, forward:0.011374843580977038, backward:0.030243436819517643, data cost:0.7059423779685564 
2022-06-29 10:56:49,919: ============================================================
2022-06-29 10:56:49,919: Epoch 21/26 Batch 6500/7662 eta: 8:07:41.447596	Training Loss 2.4776 (2.4792)	Training Prec@1 99.805 (99.482)	Training Prec@5 100.000 (99.819)	
2022-06-29 10:56:49,920: ============================================================
2022-06-29 10:58:04,232: time cost, forward:0.011392892788966364, backward:0.030274648055070675, data cost:0.7058188587558109 
2022-06-29 10:58:04,232: ============================================================
2022-06-29 10:58:04,232: Epoch 21/26 Batch 6600/7662 eta: 8:07:39.216078	Training Loss 2.5313 (2.4794)	Training Prec@1 99.414 (99.483)	Training Prec@5 99.805 (99.820)	
2022-06-29 10:58:04,232: ============================================================
2022-06-29 10:59:20,045: time cost, forward:0.011405430866508524, backward:0.030275051870316174, data cost:0.7059573615410556 
2022-06-29 10:59:20,045: ============================================================
2022-06-29 10:59:20,045: Epoch 21/26 Batch 6700/7662 eta: 8:16:14.104739	Training Loss 2.4642 (2.4797)	Training Prec@1 99.414 (99.482)	Training Prec@5 99.805 (99.819)	
2022-06-29 10:59:20,046: ============================================================
2022-06-29 11:00:35,612: time cost, forward:0.011419648755243691, backward:0.030304605004576695, data cost:0.7060253389058069 
2022-06-29 11:00:35,612: ============================================================
2022-06-29 11:00:35,613: Epoch 21/26 Batch 6800/7662 eta: 8:13:21.903557	Training Loss 2.6651 (2.4801)	Training Prec@1 99.414 (99.481)	Training Prec@5 99.805 (99.820)	
2022-06-29 11:00:35,613: ============================================================
2022-06-29 11:01:50,323: time cost, forward:0.01141347672943102, backward:0.030305114202282362, data cost:0.7060159733544606 
2022-06-29 11:01:50,323: ============================================================
2022-06-29 11:01:50,323: Epoch 21/26 Batch 6900/7662 eta: 8:06:31.641677	Training Loss 2.6599 (2.4809)	Training Prec@1 99.414 (99.480)	Training Prec@5 99.414 (99.819)	
2022-06-29 11:01:50,323: ============================================================
2022-06-29 11:03:05,428: time cost, forward:0.011413830419083395, backward:0.030307229986734466, data cost:0.7060540463689703 
2022-06-29 11:03:05,429: ============================================================
2022-06-29 11:03:05,429: Epoch 21/26 Batch 7000/7662 eta: 8:07:50.960263	Training Loss 2.5500 (2.4814)	Training Prec@1 99.609 (99.480)	Training Prec@5 100.000 (99.819)	
2022-06-29 11:03:05,429: ============================================================
2022-06-29 11:04:21,007: time cost, forward:0.011418445561365068, backward:0.030318131730965887, data cost:0.7061445540753128 
2022-06-29 11:04:21,007: ============================================================
2022-06-29 11:04:21,007: Epoch 21/26 Batch 7100/7662 eta: 8:09:39.506497	Training Loss 2.3485 (2.4817)	Training Prec@1 99.805 (99.480)	Training Prec@5 100.000 (99.819)	
2022-06-29 11:04:21,007: ============================================================
2022-06-29 11:05:37,192: time cost, forward:0.011433143353425788, backward:0.03032560155762287, data cost:0.7063101847513895 
2022-06-29 11:05:37,193: ============================================================
2022-06-29 11:05:37,193: Epoch 21/26 Batch 7200/7662 eta: 8:12:19.458604	Training Loss 2.5276 (2.4821)	Training Prec@1 99.023 (99.479)	Training Prec@5 99.609 (99.818)	
2022-06-29 11:05:37,193: ============================================================
2022-06-29 11:06:52,543: time cost, forward:0.011430132207780328, backward:0.030318744412218483, data cost:0.7063887100347772 
2022-06-29 11:06:52,544: ============================================================
2022-06-29 11:06:52,544: Epoch 21/26 Batch 7300/7662 eta: 8:05:40.551821	Training Loss 2.5641 (2.4824)	Training Prec@1 99.414 (99.479)	Training Prec@5 99.609 (99.818)	
2022-06-29 11:06:52,544: ============================================================
2022-06-29 11:08:08,056: time cost, forward:0.011437434347147297, backward:0.030334306771827076, data cost:0.7064541775336989 
2022-06-29 11:08:08,056: ============================================================
2022-06-29 11:08:08,056: Epoch 21/26 Batch 7400/7662 eta: 8:05:27.465245	Training Loss 2.3761 (2.4828)	Training Prec@1 99.805 (99.479)	Training Prec@5 99.805 (99.818)	
2022-06-29 11:08:08,057: ============================================================
2022-06-29 11:09:24,471: time cost, forward:0.011456107851632008, backward:0.030341137026227115, data cost:0.7066350657552986 
2022-06-29 11:09:24,471: ============================================================
2022-06-29 11:09:24,471: Epoch 21/26 Batch 7500/7662 eta: 8:09:59.091568	Training Loss 2.4102 (2.4832)	Training Prec@1 99.805 (99.478)	Training Prec@5 100.000 (99.817)	
2022-06-29 11:09:24,471: ============================================================
2022-06-29 11:10:39,206: time cost, forward:0.011469794003677017, backward:0.030352325090563192, data cost:0.7065893129104532 
2022-06-29 11:10:39,206: ============================================================
2022-06-29 11:10:39,207: Epoch 21/26 Batch 7600/7662 eta: 7:57:58.185385	Training Loss 2.3921 (2.4838)	Training Prec@1 99.609 (99.478)	Training Prec@5 100.000 (99.817)	
2022-06-29 11:10:39,207: ============================================================
2022-06-29 11:11:27,590: Epoch: 21/26 eta: 7:57:11.102132	Training Loss 2.3893 (2.4841)	Training Prec@1 99.414 (99.477)	Training Prec@5 99.805 (99.817)
2022-06-29 11:11:27,591: ============================================================
2022-06-29 11:13:02,102: time cost, forward:0.012154993384775489, backward:0.029624218892569495, data cost:0.9063723255889584 
2022-06-29 11:13:02,102: ============================================================
2022-06-29 11:13:02,103: Epoch 22/26 Batch 100/7662 eta: 10:01:03.671209	Training Loss 2.3335 (2.3228)	Training Prec@1 99.805 (99.661)	Training Prec@5 100.000 (99.876)	
2022-06-29 11:13:02,103: ============================================================
2022-06-29 11:14:15,977: time cost, forward:0.01160275037564225, backward:0.029356400571276794, data cost:0.8017319722391253 
2022-06-29 11:14:15,978: ============================================================
2022-06-29 11:14:15,978: Epoch 22/26 Batch 200/7662 eta: 7:49:14.634274	Training Loss 2.2274 (2.3257)	Training Prec@1 99.609 (99.626)	Training Prec@5 99.805 (99.868)	
2022-06-29 11:14:15,978: ============================================================
2022-06-29 11:15:29,305: time cost, forward:0.011620500015973248, backward:0.03010468738134888, data cost:0.7642554933809517 
2022-06-29 11:15:29,305: ============================================================
2022-06-29 11:15:29,306: Epoch 22/26 Batch 300/7662 eta: 7:44:32.595453	Training Loss 2.2566 (2.3219)	Training Prec@1 99.805 (99.622)	Training Prec@5 100.000 (99.868)	
2022-06-29 11:15:29,306: ============================================================
2022-06-29 11:16:42,196: time cost, forward:0.011679596171940778, backward:0.030493373560128652, data cost:0.7443841884010717 
2022-06-29 11:16:42,197: ============================================================
2022-06-29 11:16:42,197: Epoch 22/26 Batch 400/7662 eta: 7:40:33.803284	Training Loss 2.3182 (2.3208)	Training Prec@1 99.805 (99.617)	Training Prec@5 100.000 (99.868)	
2022-06-29 11:16:42,197: ============================================================
2022-06-29 11:17:56,044: time cost, forward:0.011776640802203774, backward:0.030882314116300227, data cost:0.7341295765014831 
2022-06-29 11:17:56,044: ============================================================
2022-06-29 11:17:56,045: Epoch 22/26 Batch 500/7662 eta: 7:45:22.507556	Training Loss 2.1660 (2.3222)	Training Prec@1 99.805 (99.625)	Training Prec@5 99.805 (99.870)	
2022-06-29 11:17:56,045: ============================================================
2022-06-29 11:19:09,224: time cost, forward:0.011714189398865867, backward:0.03093322648826943, data cost:0.726550181043367 
2022-06-29 11:19:09,224: ============================================================
2022-06-29 11:19:09,224: Epoch 22/26 Batch 600/7662 eta: 7:39:56.899755	Training Loss 2.3399 (2.3245)	Training Prec@1 100.000 (99.628)	Training Prec@5 100.000 (99.872)	
2022-06-29 11:19:09,225: ============================================================
2022-06-29 11:20:22,187: time cost, forward:0.01173893747070487, backward:0.03104126709213584, data cost:0.7206979613106309 
2022-06-29 11:20:22,188: ============================================================
2022-06-29 11:20:22,188: Epoch 22/26 Batch 700/7662 eta: 7:37:22.213936	Training Loss 2.1869 (2.3272)	Training Prec@1 99.609 (99.624)	Training Prec@5 99.805 (99.869)	
2022-06-29 11:20:22,188: ============================================================
2022-06-29 11:21:35,831: time cost, forward:0.011783431558048023, backward:0.030978962536598178, data cost:0.7172692263678406 
2022-06-29 11:21:35,831: ============================================================
2022-06-29 11:21:35,831: Epoch 22/26 Batch 800/7662 eta: 7:40:24.375936	Training Loss 2.3131 (2.3293)	Training Prec@1 99.414 (99.625)	Training Prec@5 99.805 (99.872)	
2022-06-29 11:21:35,831: ============================================================
2022-06-29 11:22:51,144: time cost, forward:0.011823569574663717, backward:0.031030870253039945, data cost:0.7163518724239973 
2022-06-29 11:22:51,144: ============================================================
2022-06-29 11:22:51,145: Epoch 22/26 Batch 900/7662 eta: 7:49:35.509019	Training Loss 2.2676 (2.3310)	Training Prec@1 99.414 (99.621)	Training Prec@5 99.805 (99.872)	
2022-06-29 11:22:51,145: ============================================================
2022-06-29 11:24:05,066: time cost, forward:0.011788462256048774, backward:0.031089542387006758, data cost:0.7142809532784127 
2022-06-29 11:24:05,067: ============================================================
2022-06-29 11:24:05,067: Epoch 22/26 Batch 1000/7662 eta: 7:39:41.133645	Training Loss 1.9813 (2.3326)	Training Prec@1 99.805 (99.620)	Training Prec@5 100.000 (99.870)	
2022-06-29 11:24:05,067: ============================================================
2022-06-29 11:25:17,403: time cost, forward:0.011782401686261414, backward:0.031038240479598595, data cost:0.7112230770798355 
2022-06-29 11:25:17,404: ============================================================
2022-06-29 11:25:17,404: Epoch 22/26 Batch 1100/7662 eta: 7:28:37.355187	Training Loss 2.3693 (2.3359)	Training Prec@1 99.414 (99.617)	Training Prec@5 99.805 (99.868)	
2022-06-29 11:25:17,404: ============================================================
2022-06-29 11:26:30,803: time cost, forward:0.011850724526501577, backward:0.030990967460231448, data cost:0.7094907078571971 
2022-06-29 11:26:30,803: ============================================================
2022-06-29 11:26:30,804: Epoch 22/26 Batch 1200/7662 eta: 7:33:59.346359	Training Loss 2.2124 (2.3392)	Training Prec@1 99.609 (99.610)	Training Prec@5 99.805 (99.866)	
2022-06-29 11:26:30,804: ============================================================
2022-06-29 11:27:44,945: time cost, forward:0.011866828861192523, backward:0.031038588060609554, data cost:0.7085520239221398 
2022-06-29 11:27:44,945: ============================================================
2022-06-29 11:27:44,946: Epoch 22/26 Batch 1300/7662 eta: 7:37:20.660397	Training Loss 2.2692 (2.3415)	Training Prec@1 100.000 (99.606)	Training Prec@5 100.000 (99.866)	
2022-06-29 11:27:44,946: ============================================================
2022-06-29 11:28:58,699: time cost, forward:0.011877773147212172, backward:0.031029565066759548, data cost:0.7075164394774038 
2022-06-29 11:28:58,699: ============================================================
2022-06-29 11:28:58,700: Epoch 22/26 Batch 1400/7662 eta: 7:33:43.338481	Training Loss 2.5083 (2.3426)	Training Prec@1 99.805 (99.608)	Training Prec@5 99.805 (99.867)	
2022-06-29 11:28:58,700: ============================================================
2022-06-29 11:30:13,312: time cost, forward:0.011910498659160633, backward:0.031068171557782093, data cost:0.7071303627823415 
2022-06-29 11:30:13,313: ============================================================
2022-06-29 11:30:13,313: Epoch 22/26 Batch 1500/7662 eta: 7:37:45.966928	Training Loss 2.4177 (2.3452)	Training Prec@1 99.805 (99.605)	Training Prec@5 99.805 (99.866)	
2022-06-29 11:30:13,313: ============================================================
2022-06-29 11:31:27,337: time cost, forward:0.011939896427891715, backward:0.031120916095802826, data cost:0.7064027705738289 
2022-06-29 11:31:27,338: ============================================================
2022-06-29 11:31:27,338: Epoch 22/26 Batch 1600/7662 eta: 7:32:55.308245	Training Loss 2.3878 (2.3462)	Training Prec@1 100.000 (99.605)	Training Prec@5 100.000 (99.865)	
2022-06-29 11:31:27,338: ============================================================
2022-06-29 11:32:42,040: time cost, forward:0.011924856055687988, backward:0.031106290710610877, data cost:0.7062630228185176 
2022-06-29 11:32:42,041: ============================================================
2022-06-29 11:32:42,041: Epoch 22/26 Batch 1700/7662 eta: 7:35:49.411221	Training Loss 2.4842 (2.3469)	Training Prec@1 99.414 (99.604)	Training Prec@5 99.609 (99.864)	
2022-06-29 11:32:42,041: ============================================================
2022-06-29 11:33:55,905: time cost, forward:0.0119258872398474, backward:0.031091522680116137, data cost:0.7056578986839561 
2022-06-29 11:33:55,905: ============================================================
2022-06-29 11:33:55,906: Epoch 22/26 Batch 1800/7662 eta: 7:29:28.807064	Training Loss 2.2923 (2.3472)	Training Prec@1 99.805 (99.603)	Training Prec@5 99.805 (99.862)	
2022-06-29 11:33:55,906: ============================================================
2022-06-29 11:35:10,626: time cost, forward:0.011922248104109521, backward:0.030947286747454842, data cost:0.7057003285647568 
2022-06-29 11:35:10,626: ============================================================
2022-06-29 11:35:10,626: Epoch 22/26 Batch 1900/7662 eta: 7:33:26.422655	Training Loss 2.5585 (2.3495)	Training Prec@1 99.023 (99.604)	Training Prec@5 99.609 (99.862)	
2022-06-29 11:35:10,626: ============================================================
2022-06-29 11:36:24,627: time cost, forward:0.011903068075900438, backward:0.030939839731877656, data cost:0.7052751100319752 
2022-06-29 11:36:24,627: ============================================================
2022-06-29 11:36:24,627: Epoch 22/26 Batch 2000/7662 eta: 7:27:50.566801	Training Loss 2.3651 (2.3510)	Training Prec@1 99.609 (99.604)	Training Prec@5 100.000 (99.862)	
2022-06-29 11:36:24,627: ============================================================
2022-06-29 11:37:38,697: time cost, forward:0.011856098184135768, backward:0.030954308371250832, data cost:0.7049337818033073 
2022-06-29 11:37:38,697: ============================================================
2022-06-29 11:37:38,698: Epoch 22/26 Batch 2100/7662 eta: 7:27:01.630558	Training Loss 2.3942 (2.3516)	Training Prec@1 99.609 (99.604)	Training Prec@5 99.805 (99.863)	
2022-06-29 11:37:38,698: ============================================================
2022-06-29 11:38:54,425: time cost, forward:0.01184575207507735, backward:0.03085291477808794, data cost:0.7054589706531922 
2022-06-29 11:38:54,426: ============================================================
2022-06-29 11:38:54,426: Epoch 22/26 Batch 2200/7662 eta: 7:35:46.261169	Training Loss 2.1881 (2.3524)	Training Prec@1 99.609 (99.601)	Training Prec@5 100.000 (99.862)	
2022-06-29 11:38:54,426: ============================================================
2022-06-29 11:40:07,408: time cost, forward:0.011801197716545779, backward:0.030688286242458084, data cost:0.7048516482983324 
2022-06-29 11:40:07,408: ============================================================
2022-06-29 11:40:07,408: Epoch 22/26 Batch 2300/7662 eta: 7:18:01.628766	Training Loss 2.3180 (2.3526)	Training Prec@1 99.805 (99.601)	Training Prec@5 99.805 (99.862)	
2022-06-29 11:40:07,408: ============================================================
2022-06-29 11:41:21,556: time cost, forward:0.011791909223002361, backward:0.030704830526659618, data cost:0.7045855145496147 
2022-06-29 11:41:21,557: ============================================================
2022-06-29 11:41:21,557: Epoch 22/26 Batch 2400/7662 eta: 7:23:47.599590	Training Loss 2.4819 (2.3540)	Training Prec@1 99.219 (99.601)	Training Prec@5 99.805 (99.863)	
2022-06-29 11:41:21,557: ============================================================
2022-06-29 11:42:34,432: time cost, forward:0.01178479929264186, backward:0.03069764005989969, data cost:0.7038452120579066 
2022-06-29 11:42:34,432: ============================================================
2022-06-29 11:42:34,432: Epoch 22/26 Batch 2500/7662 eta: 7:14:57.398333	Training Loss 2.4211 (2.3556)	Training Prec@1 99.414 (99.599)	Training Prec@5 99.414 (99.862)	
2022-06-29 11:42:34,432: ============================================================
2022-06-29 11:43:48,470: time cost, forward:0.01180717769885531, backward:0.030726284281755237, data cost:0.703548394335651 
2022-06-29 11:43:48,470: ============================================================
2022-06-29 11:43:48,470: Epoch 22/26 Batch 2600/7662 eta: 7:20:39.748362	Training Loss 2.4172 (2.3557)	Training Prec@1 99.023 (99.599)	Training Prec@5 100.000 (99.862)	
2022-06-29 11:43:48,471: ============================================================
2022-06-29 11:45:02,143: time cost, forward:0.011786531986859871, backward:0.03072854870997256, data cost:0.7032016873050505 
2022-06-29 11:45:02,143: ============================================================
2022-06-29 11:45:02,143: Epoch 22/26 Batch 2700/7662 eta: 7:17:15.578040	Training Loss 2.5014 (2.3572)	Training Prec@1 99.219 (99.597)	Training Prec@5 99.805 (99.861)	
2022-06-29 11:45:02,143: ============================================================
2022-06-29 11:46:15,507: time cost, forward:0.011778510438837975, backward:0.030776749938332466, data cost:0.7027170895763533 
2022-06-29 11:46:15,508: ============================================================
2022-06-29 11:46:15,508: Epoch 22/26 Batch 2800/7662 eta: 7:14:12.586481	Training Loss 2.3713 (2.3586)	Training Prec@1 99.805 (99.594)	Training Prec@5 100.000 (99.860)	
2022-06-29 11:46:15,508: ============================================================
2022-06-29 11:47:29,217: time cost, forward:0.011774027335228449, backward:0.030787869789305124, data cost:0.7024128096561755 
2022-06-29 11:47:29,217: ============================================================
2022-06-29 11:47:29,218: Epoch 22/26 Batch 2900/7662 eta: 7:15:01.314551	Training Loss 2.1675 (2.3594)	Training Prec@1 99.609 (99.594)	Training Prec@5 99.805 (99.859)	
2022-06-29 11:47:29,218: ============================================================
2022-06-29 11:48:44,492: time cost, forward:0.011772924202527551, backward:0.030817606879218733, data cost:0.7026272499787883 
2022-06-29 11:48:44,492: ============================================================
2022-06-29 11:48:44,493: Epoch 22/26 Batch 3000/7662 eta: 7:23:00.361261	Training Loss 2.3668 (2.3598)	Training Prec@1 99.414 (99.593)	Training Prec@5 99.805 (99.859)	
2022-06-29 11:48:44,493: ============================================================
2022-06-29 11:49:57,042: time cost, forward:0.011751335103421797, backward:0.030825961901703815, data cost:0.7019872443065908 
2022-06-29 11:49:57,043: ============================================================
2022-06-29 11:49:57,043: Epoch 22/26 Batch 3100/7662 eta: 7:05:45.680131	Training Loss 2.2899 (2.3606)	Training Prec@1 99.805 (99.592)	Training Prec@5 99.805 (99.859)	
2022-06-29 11:49:57,043: ============================================================
2022-06-29 11:51:11,172: time cost, forward:0.011767804976663354, backward:0.03082782300273565, data cost:0.7018541384950657 
2022-06-29 11:51:11,172: ============================================================
2022-06-29 11:51:11,173: Epoch 22/26 Batch 3200/7662 eta: 7:13:47.701634	Training Loss 2.6399 (2.3617)	Training Prec@1 99.609 (99.592)	Training Prec@5 99.805 (99.858)	
2022-06-29 11:51:11,173: ============================================================
2022-06-29 11:52:26,213: time cost, forward:0.011777839576811385, backward:0.03083885377304017, data cost:0.7020013234079806 
2022-06-29 11:52:26,214: ============================================================
2022-06-29 11:52:26,214: Epoch 22/26 Batch 3300/7662 eta: 7:17:52.639947	Training Loss 2.2232 (2.3625)	Training Prec@1 99.805 (99.591)	Training Prec@5 100.000 (99.858)	
2022-06-29 11:52:26,214: ============================================================
2022-06-29 11:53:39,452: time cost, forward:0.01176671211633236, backward:0.03084426313401952, data cost:0.7016304505155451 
2022-06-29 11:53:39,452: ============================================================
2022-06-29 11:53:39,452: Epoch 22/26 Batch 3400/7662 eta: 7:06:08.345380	Training Loss 2.2352 (2.3634)	Training Prec@1 99.414 (99.591)	Training Prec@5 100.000 (99.858)	
2022-06-29 11:53:39,453: ============================================================
2022-06-29 11:54:53,356: time cost, forward:0.011759716703333695, backward:0.03074556584016157, data cost:0.7015742238299034 
2022-06-29 11:54:53,356: ============================================================
2022-06-29 11:54:53,356: Epoch 22/26 Batch 3500/7662 eta: 7:08:46.672903	Training Loss 2.3401 (2.3652)	Training Prec@1 99.609 (99.590)	Training Prec@5 99.805 (99.858)	
2022-06-29 11:54:53,356: ============================================================
2022-06-29 11:56:07,913: time cost, forward:0.011770551156321973, backward:0.030713918574090202, data cost:0.7016276650112118 
2022-06-29 11:56:07,913: ============================================================
2022-06-29 11:56:07,914: Epoch 22/26 Batch 3600/7662 eta: 7:11:19.583276	Training Loss 2.4601 (2.3662)	Training Prec@1 99.609 (99.589)	Training Prec@5 99.805 (99.858)	
2022-06-29 11:56:07,914: ============================================================
2022-06-29 11:57:21,930: time cost, forward:0.011777399939181, backward:0.03066621860577371, data cost:0.7015457370533238 
2022-06-29 11:57:21,930: ============================================================
2022-06-29 11:57:21,931: Epoch 22/26 Batch 3700/7662 eta: 7:06:58.031200	Training Loss 2.2152 (2.3669)	Training Prec@1 99.609 (99.588)	Training Prec@5 100.000 (99.857)	
2022-06-29 11:57:21,931: ============================================================
2022-06-29 11:58:36,487: time cost, forward:0.011784393494303021, backward:0.030643584885764165, data cost:0.7015950084830874 
2022-06-29 11:58:36,487: ============================================================
2022-06-29 11:58:36,487: Epoch 22/26 Batch 3800/7662 eta: 7:08:50.287089	Training Loss 2.4010 (2.3680)	Training Prec@1 99.609 (99.588)	Training Prec@5 100.000 (99.857)	
2022-06-29 11:58:36,488: ============================================================
2022-06-29 11:59:50,782: time cost, forward:0.011804551398274103, backward:0.030649780462753715, data cost:0.7015248195548399 
2022-06-29 11:59:50,782: ============================================================
2022-06-29 11:59:50,783: Epoch 22/26 Batch 3900/7662 eta: 7:06:05.682750	Training Loss 2.2512 (2.3693)	Training Prec@1 99.414 (99.586)	Training Prec@5 99.609 (99.856)	
2022-06-29 11:59:50,783: ============================================================
2022-06-29 12:01:05,265: time cost, forward:0.011791874689291524, backward:0.030633254121559563, data cost:0.7015655192174622 
2022-06-29 12:01:05,265: ============================================================
2022-06-29 12:01:05,266: Epoch 22/26 Batch 4000/7662 eta: 7:05:55.903945	Training Loss 2.3178 (2.3707)	Training Prec@1 99.805 (99.585)	Training Prec@5 99.805 (99.856)	
2022-06-29 12:01:05,266: ============================================================
2022-06-29 12:02:19,002: time cost, forward:0.01178552511698678, backward:0.030587641894453822, data cost:0.7014415817861006 
2022-06-29 12:02:19,003: ============================================================
2022-06-29 12:02:19,003: Epoch 22/26 Batch 4100/7662 eta: 7:00:26.256501	Training Loss 2.3654 (2.3721)	Training Prec@1 99.805 (99.585)	Training Prec@5 99.805 (99.856)	
2022-06-29 12:02:19,003: ============================================================
2022-06-29 12:03:33,883: time cost, forward:0.011790409630950106, backward:0.03057998877305251, data cost:0.7015554987268523 
2022-06-29 12:03:33,884: ============================================================
2022-06-29 12:03:33,884: Epoch 22/26 Batch 4200/7662 eta: 7:05:42.598474	Training Loss 2.2136 (2.3732)	Training Prec@1 99.609 (99.584)	Training Prec@5 100.000 (99.856)	
2022-06-29 12:03:33,884: ============================================================
2022-06-29 12:04:47,764: time cost, forward:0.01178956458834222, backward:0.03058458600218392, data cost:0.7014206854457993 
2022-06-29 12:04:47,764: ============================================================
2022-06-29 12:04:47,764: Epoch 22/26 Batch 4300/7662 eta: 6:58:47.521289	Training Loss 2.5381 (2.3745)	Training Prec@1 99.609 (99.581)	Training Prec@5 99.805 (99.856)	
2022-06-29 12:04:47,764: ============================================================
2022-06-29 12:06:01,470: time cost, forward:0.011815306652023131, backward:0.030632636308073863, data cost:0.7011841556976589 
2022-06-29 12:06:01,470: ============================================================
2022-06-29 12:06:01,470: Epoch 22/26 Batch 4400/7662 eta: 6:56:34.387036	Training Loss 2.3428 (2.3755)	Training Prec@1 99.414 (99.581)	Training Prec@5 99.805 (99.856)	
2022-06-29 12:06:01,470: ============================================================
2022-06-29 12:07:15,903: time cost, forward:0.01183588204317078, backward:0.03067445776202356, data cost:0.7011277830370216 
2022-06-29 12:07:15,903: ============================================================
2022-06-29 12:07:15,904: Epoch 22/26 Batch 4500/7662 eta: 6:59:26.685955	Training Loss 2.4016 (2.3765)	Training Prec@1 99.414 (99.579)	Training Prec@5 99.805 (99.855)	
2022-06-29 12:07:15,904: ============================================================
2022-06-29 12:08:28,926: time cost, forward:0.011832261142535789, backward:0.03070714158010265, data cost:0.7007968028645641 
2022-06-29 12:08:28,926: ============================================================
2022-06-29 12:08:28,927: Epoch 22/26 Batch 4600/7662 eta: 6:50:16.792854	Training Loss 2.4139 (2.3772)	Training Prec@1 99.609 (99.579)	Training Prec@5 100.000 (99.855)	
2022-06-29 12:08:28,927: ============================================================
2022-06-29 12:09:44,332: time cost, forward:0.011840117335395627, backward:0.030668111323397015, data cost:0.7010457803401878 
2022-06-29 12:09:44,332: ============================================================
2022-06-29 12:09:44,332: Epoch 22/26 Batch 4700/7662 eta: 7:02:24.518543	Training Loss 2.3537 (2.3780)	Training Prec@1 99.805 (99.579)	Training Prec@5 99.805 (99.856)	
2022-06-29 12:09:44,332: ============================================================
2022-06-29 12:10:59,667: time cost, forward:0.011842067104052643, backward:0.030659829211448674, data cost:0.7012453007683155 
2022-06-29 12:10:59,667: ============================================================
2022-06-29 12:10:59,667: Epoch 22/26 Batch 4800/7662 eta: 7:00:45.566752	Training Loss 2.6268 (2.3794)	Training Prec@1 99.609 (99.577)	Training Prec@5 100.000 (99.855)	
2022-06-29 12:10:59,667: ============================================================
2022-06-29 12:12:12,289: time cost, forward:0.011846370661981399, backward:0.030669872554912204, data cost:0.7008648165928439 
2022-06-29 12:12:12,290: ============================================================
2022-06-29 12:12:12,290: Epoch 22/26 Batch 4900/7662 eta: 6:44:23.951888	Training Loss 2.5011 (2.3803)	Training Prec@1 99.609 (99.577)	Training Prec@5 100.000 (99.855)	
2022-06-29 12:12:12,290: ============================================================
2022-06-29 12:13:27,454: time cost, forward:0.011840357115612576, backward:0.03065611162431766, data cost:0.7010409640273849 
2022-06-29 12:13:27,455: ============================================================
2022-06-29 12:13:27,455: Epoch 22/26 Batch 5000/7662 eta: 6:57:18.164215	Training Loss 2.5900 (2.3813)	Training Prec@1 99.609 (99.576)	Training Prec@5 100.000 (99.854)	
2022-06-29 12:13:27,455: ============================================================
2022-06-29 12:14:42,136: time cost, forward:0.011829968596655005, backward:0.03064041882081227, data cost:0.7011227828424382 
2022-06-29 12:14:42,136: ============================================================
2022-06-29 12:14:42,136: Epoch 22/26 Batch 5100/7662 eta: 6:53:22.360672	Training Loss 2.4502 (2.3823)	Training Prec@1 99.609 (99.575)	Training Prec@5 99.805 (99.854)	
2022-06-29 12:14:42,136: ============================================================
2022-06-29 12:15:56,718: time cost, forward:0.011823189765312369, backward:0.03062619298988866, data cost:0.701180250696504 
2022-06-29 12:15:56,718: ============================================================
2022-06-29 12:15:56,719: Epoch 22/26 Batch 5200/7662 eta: 6:51:35.084591	Training Loss 2.3146 (2.3832)	Training Prec@1 99.805 (99.574)	Training Prec@5 100.000 (99.854)	
2022-06-29 12:15:56,719: ============================================================
2022-06-29 12:17:10,637: time cost, forward:0.011823053111623292, backward:0.03063381791317276, data cost:0.7010787591594057 
2022-06-29 12:17:10,637: ============================================================
2022-06-29 12:17:10,637: Epoch 22/26 Batch 5300/7662 eta: 6:46:41.256008	Training Loss 2.1905 (2.3842)	Training Prec@1 99.805 (99.572)	Training Prec@5 99.805 (99.853)	
2022-06-29 12:17:10,637: ============================================================
2022-06-29 12:18:23,825: time cost, forward:0.011822997563237238, backward:0.030669474915279948, data cost:0.7008181550057205 
2022-06-29 12:18:23,825: ============================================================
2022-06-29 12:18:23,826: Epoch 22/26 Batch 5400/7662 eta: 6:41:27.021622	Training Loss 2.6043 (2.3852)	Training Prec@1 99.805 (99.571)	Training Prec@5 100.000 (99.853)	
2022-06-29 12:18:23,826: ============================================================
2022-06-29 12:19:38,573: time cost, forward:0.011825800809150914, backward:0.030671153551536292, data cost:0.7008818739824977 
2022-06-29 12:19:38,573: ============================================================
2022-06-29 12:19:38,573: Epoch 22/26 Batch 5500/7662 eta: 6:48:45.405101	Training Loss 2.3861 (2.3864)	Training Prec@1 99.609 (99.570)	Training Prec@5 99.805 (99.853)	
2022-06-29 12:19:38,573: ============================================================
2022-06-29 12:20:53,607: time cost, forward:0.011816888307754346, backward:0.030661831585120508, data cost:0.7010182661123628 
2022-06-29 12:20:53,608: ============================================================
2022-06-29 12:20:53,608: Epoch 22/26 Batch 5600/7662 eta: 6:49:04.612622	Training Loss 2.2572 (2.3870)	Training Prec@1 99.219 (99.569)	Training Prec@5 99.609 (99.852)	
2022-06-29 12:20:53,608: ============================================================
2022-06-29 12:22:07,701: time cost, forward:0.01182541593707932, backward:0.030684565092141344, data cost:0.7009333417507237 
2022-06-29 12:22:07,701: ============================================================
2022-06-29 12:22:07,702: Epoch 22/26 Batch 5700/7662 eta: 6:42:42.702549	Training Loss 2.1837 (2.3878)	Training Prec@1 99.805 (99.568)	Training Prec@5 100.000 (99.852)	
2022-06-29 12:22:07,702: ============================================================
2022-06-29 12:23:20,923: time cost, forward:0.011823259565126774, backward:0.030710447490328363, data cost:0.7007086944695197 
2022-06-29 12:23:20,923: ============================================================
2022-06-29 12:23:20,924: Epoch 22/26 Batch 5800/7662 eta: 6:36:45.219807	Training Loss 2.2802 (2.3885)	Training Prec@1 99.609 (99.567)	Training Prec@5 100.000 (99.852)	
2022-06-29 12:23:20,924: ============================================================
2022-06-29 12:24:35,959: time cost, forward:0.011814600573816347, backward:0.03070245857743171, data cost:0.7008382731685195 
2022-06-29 12:24:35,960: ============================================================
2022-06-29 12:24:35,960: Epoch 22/26 Batch 5900/7662 eta: 6:45:19.946478	Training Loss 2.4448 (2.3893)	Training Prec@1 99.414 (99.567)	Training Prec@5 99.805 (99.852)	
2022-06-29 12:24:35,960: ============================================================
2022-06-29 12:25:49,253: time cost, forward:0.011804368977229543, backward:0.030713899470623543, data cost:0.700653755698607 
2022-06-29 12:25:49,253: ============================================================
2022-06-29 12:25:49,253: Epoch 22/26 Batch 6000/7662 eta: 6:34:41.965071	Training Loss 2.4725 (2.3903)	Training Prec@1 99.609 (99.566)	Training Prec@5 99.805 (99.851)	
2022-06-29 12:25:49,254: ============================================================
2022-06-29 12:27:03,942: time cost, forward:0.01180999746946531, backward:0.030719578315008076, data cost:0.70069661654885 
2022-06-29 12:27:03,942: ============================================================
2022-06-29 12:27:03,942: Epoch 22/26 Batch 6100/7662 eta: 6:40:57.998187	Training Loss 2.4547 (2.3911)	Training Prec@1 99.023 (99.566)	Training Prec@5 99.609 (99.851)	
2022-06-29 12:27:03,942: ============================================================
2022-06-29 12:28:17,617: time cost, forward:0.011796762951344592, backward:0.030709377352817153, data cost:0.7006064472053873 
2022-06-29 12:28:17,617: ============================================================
2022-06-29 12:28:17,617: Epoch 22/26 Batch 6200/7662 eta: 6:34:17.765607	Training Loss 2.5294 (2.3917)	Training Prec@1 99.023 (99.566)	Training Prec@5 99.414 (99.851)	
2022-06-29 12:28:17,617: ============================================================
2022-06-29 12:29:31,722: time cost, forward:0.011792620849488254, backward:0.030692127890616375, data cost:0.7005882251450023 
2022-06-29 12:29:31,723: ============================================================
2022-06-29 12:29:31,723: Epoch 22/26 Batch 6300/7662 eta: 6:35:21.930069	Training Loss 2.3320 (2.3922)	Training Prec@1 99.414 (99.564)	Training Prec@5 100.000 (99.851)	
2022-06-29 12:29:31,723: ============================================================
2022-06-29 12:30:45,691: time cost, forward:0.011783233935580735, backward:0.030687361289642997, data cost:0.7005426868421433 
2022-06-29 12:30:45,691: ============================================================
2022-06-29 12:30:45,691: Epoch 22/26 Batch 6400/7662 eta: 6:33:23.991455	Training Loss 2.4161 (2.3931)	Training Prec@1 98.828 (99.562)	Training Prec@5 99.414 (99.851)	
2022-06-29 12:30:45,691: ============================================================
2022-06-29 12:31:59,767: time cost, forward:0.011779260848151443, backward:0.0306792627904833, data cost:0.7005116589932574 
2022-06-29 12:31:59,767: ============================================================
2022-06-29 12:31:59,767: Epoch 22/26 Batch 6500/7662 eta: 6:32:44.404861	Training Loss 2.3029 (2.3939)	Training Prec@1 99.414 (99.562)	Training Prec@5 99.609 (99.851)	
2022-06-29 12:31:59,767: ============================================================
2022-06-29 12:33:15,188: time cost, forward:0.011778369241093918, backward:0.03066409130966434, data cost:0.7006925110528642 
2022-06-29 12:33:15,188: ============================================================
2022-06-29 12:33:15,189: Epoch 22/26 Batch 6600/7662 eta: 6:38:36.827480	Training Loss 2.4158 (2.3946)	Training Prec@1 99.609 (99.562)	Training Prec@5 100.000 (99.851)	
2022-06-29 12:33:15,189: ============================================================
2022-06-29 12:34:30,061: time cost, forward:0.0117841416783325, backward:0.030681702819826497, data cost:0.7007465661150393 
2022-06-29 12:34:30,061: ============================================================
2022-06-29 12:34:30,061: Epoch 22/26 Batch 6700/7662 eta: 6:34:28.047023	Training Loss 2.2702 (2.3954)	Training Prec@1 99.609 (99.561)	Training Prec@5 99.805 (99.851)	
2022-06-29 12:34:30,062: ============================================================
2022-06-29 12:35:46,057: time cost, forward:0.011782528319978103, backward:0.030685806120120528, data cost:0.700983260235097 
2022-06-29 12:35:46,057: ============================================================
2022-06-29 12:35:46,057: Epoch 22/26 Batch 6800/7662 eta: 6:39:07.049015	Training Loss 2.4668 (2.3959)	Training Prec@1 99.805 (99.560)	Training Prec@5 100.000 (99.851)	
2022-06-29 12:35:46,057: ============================================================
2022-06-29 12:37:00,658: time cost, forward:0.01177745318824026, backward:0.030698110338811823, data cost:0.7010073395358737 
2022-06-29 12:37:00,659: ============================================================
2022-06-29 12:37:00,659: Epoch 22/26 Batch 6900/7662 eta: 6:30:33.098819	Training Loss 2.3619 (2.3965)	Training Prec@1 99.219 (99.559)	Training Prec@5 99.805 (99.850)	
2022-06-29 12:37:00,659: ============================================================
2022-06-29 12:38:15,532: time cost, forward:0.011784536188918364, backward:0.030715513985605646, data cost:0.701051536534987 
2022-06-29 12:38:15,533: ============================================================
2022-06-29 12:38:15,533: Epoch 22/26 Batch 7000/7662 eta: 6:30:43.789055	Training Loss 2.5114 (2.3975)	Training Prec@1 99.609 (99.559)	Training Prec@5 99.609 (99.850)	
2022-06-29 12:38:15,533: ============================================================
2022-06-29 12:39:28,487: time cost, forward:0.011768651253775084, backward:0.030708505093404854, data cost:0.7008707126373471 
2022-06-29 12:39:28,487: ============================================================
2022-06-29 12:39:28,487: Epoch 22/26 Batch 7100/7662 eta: 6:19:29.897740	Training Loss 2.6154 (2.3981)	Training Prec@1 99.219 (99.558)	Training Prec@5 99.805 (99.850)	
2022-06-29 12:39:28,488: ============================================================
2022-06-29 12:40:41,771: time cost, forward:0.011759357761055054, backward:0.03071717991400368, data cost:0.7007188499594814 
2022-06-29 12:40:41,771: ============================================================
2022-06-29 12:40:41,771: Epoch 22/26 Batch 7200/7662 eta: 6:19:59.298060	Training Loss 2.5277 (2.3990)	Training Prec@1 98.828 (99.557)	Training Prec@5 99.805 (99.850)	
2022-06-29 12:40:41,771: ============================================================
2022-06-29 12:41:56,831: time cost, forward:0.011768767761521052, backward:0.030707824653200065, data cost:0.7008142987086783 
2022-06-29 12:41:56,831: ============================================================
2022-06-29 12:41:56,831: Epoch 22/26 Batch 7300/7662 eta: 6:27:56.930001	Training Loss 2.5113 (2.3997)	Training Prec@1 99.414 (99.556)	Training Prec@5 99.609 (99.849)	
2022-06-29 12:41:56,832: ============================================================
2022-06-29 12:43:12,325: time cost, forward:0.011770513705714906, backward:0.03070900356113822, data cost:0.7009609449649279 
2022-06-29 12:43:12,326: ============================================================
2022-06-29 12:43:12,326: Epoch 22/26 Batch 7400/7662 eta: 6:28:56.063821	Training Loss 2.4444 (2.4002)	Training Prec@1 100.000 (99.555)	Training Prec@5 100.000 (99.849)	
2022-06-29 12:43:12,326: ============================================================
2022-06-29 12:44:26,314: time cost, forward:0.011754444939785917, backward:0.03070131895271583, data cost:0.7009318024973215 
2022-06-29 12:44:26,314: ============================================================
2022-06-29 12:44:26,314: Epoch 22/26 Batch 7500/7662 eta: 6:19:56.507812	Training Loss 2.6389 (2.4010)	Training Prec@1 99.023 (99.554)	Training Prec@5 100.000 (99.849)	
2022-06-29 12:44:26,314: ============================================================
2022-06-29 12:45:40,274: time cost, forward:0.01174370460344594, backward:0.030707364459463853, data cost:0.7008810376537397 
2022-06-29 12:45:40,274: ============================================================
2022-06-29 12:45:40,274: Epoch 22/26 Batch 7600/7662 eta: 6:18:33.840089	Training Loss 2.6099 (2.4017)	Training Prec@1 99.219 (99.553)	Training Prec@5 99.609 (99.848)	
2022-06-29 12:45:40,274: ============================================================
2022-06-29 12:46:30,243: Epoch: 22/26 eta: 6:17:47.245321	Training Loss 2.4758 (2.4020)	Training Prec@1 99.609 (99.553)	Training Prec@5 99.805 (99.848)
2022-06-29 12:46:30,243: ============================================================
2022-06-29 12:47:55,223: time cost, forward:0.011165797108351583, backward:0.029599830357715337, data cost:0.8104951309435295 
2022-06-29 12:47:55,223: ============================================================
2022-06-29 12:47:55,223: Epoch 23/26 Batch 100/7662 eta: 7:11:40.909224	Training Loss 2.2516 (2.2764)	Training Prec@1 100.000 (99.694)	Training Prec@5 100.000 (99.917)	
2022-06-29 12:47:55,223: ============================================================
2022-06-29 12:49:08,249: time cost, forward:0.011584204045971434, backward:0.030035927068048984, data cost:0.7485972756716475 
2022-06-29 12:49:08,250: ============================================================
2022-06-29 12:49:08,250: Epoch 23/26 Batch 200/7662 eta: 6:10:35.832229	Training Loss 2.1853 (2.2710)	Training Prec@1 99.609 (99.670)	Training Prec@5 100.000 (99.898)	
2022-06-29 12:49:08,250: ============================================================
2022-06-29 12:50:21,049: time cost, forward:0.011870534124980403, backward:0.029540612147404596, data cost:0.7278401397143718 
2022-06-29 12:50:21,049: ============================================================
2022-06-29 12:50:21,049: Epoch 23/26 Batch 300/7662 eta: 6:08:13.906214	Training Loss 2.1902 (2.2728)	Training Prec@1 100.000 (99.668)	Training Prec@5 100.000 (99.900)	
2022-06-29 12:50:21,049: ============================================================
2022-06-29 12:51:34,043: time cost, forward:0.011668724523749865, backward:0.029553085939029704, data cost:0.7180688596309576 
2022-06-29 12:51:34,044: ============================================================
2022-06-29 12:51:34,044: Epoch 23/26 Batch 400/7662 eta: 6:08:00.191526	Training Loss 2.3073 (2.2743)	Training Prec@1 100.000 (99.667)	Training Prec@5 100.000 (99.891)	
2022-06-29 12:51:34,044: ============================================================
2022-06-29 12:52:47,570: time cost, forward:0.011690252529595324, backward:0.029513750859874045, data cost:0.7131724419718037 
2022-06-29 12:52:47,571: ============================================================
2022-06-29 12:52:47,571: Epoch 23/26 Batch 500/7662 eta: 6:09:27.616903	Training Loss 2.4125 (2.2745)	Training Prec@1 99.805 (99.670)	Training Prec@5 100.000 (99.893)	
2022-06-29 12:52:47,571: ============================================================
2022-06-29 12:54:00,853: time cost, forward:0.011691016625482371, backward:0.029483333055881508, data cost:0.7095443740710989 
2022-06-29 12:54:00,854: ============================================================
2022-06-29 12:54:00,854: Epoch 23/26 Batch 600/7662 eta: 6:07:00.830447	Training Loss 2.0780 (2.2731)	Training Prec@1 99.805 (99.668)	Training Prec@5 100.000 (99.892)	
2022-06-29 12:54:00,854: ============================================================
2022-06-29 12:55:13,376: time cost, forward:0.011627503901251056, backward:0.029631931212156456, data cost:0.705725867690276 
2022-06-29 12:55:13,376: ============================================================
2022-06-29 12:55:13,377: Epoch 23/26 Batch 700/7662 eta: 6:01:59.842438	Training Loss 2.4009 (2.2747)	Training Prec@1 99.609 (99.670)	Training Prec@5 99.805 (99.889)	
2022-06-29 12:55:13,377: ============================================================
2022-06-29 12:56:25,888: time cost, forward:0.011594746378396121, backward:0.029556098658689422, data cost:0.7030386310047441 
2022-06-29 12:56:25,889: ============================================================
2022-06-29 12:56:25,889: Epoch 23/26 Batch 800/7662 eta: 6:00:44.190809	Training Loss 2.4801 (2.2763)	Training Prec@1 99.219 (99.658)	Training Prec@5 99.609 (99.887)	
2022-06-29 12:56:25,889: ============================================================
2022-06-29 12:57:37,976: time cost, forward:0.011545551499482389, backward:0.029458819294930567, data cost:0.7005402145449391 
2022-06-29 12:57:37,976: ============================================================
2022-06-29 12:57:37,977: Epoch 23/26 Batch 900/7662 eta: 5:57:25.319624	Training Loss 2.4057 (2.2771)	Training Prec@1 99.609 (99.657)	Training Prec@5 100.000 (99.887)	
2022-06-29 12:57:37,977: ============================================================
2022-06-29 12:58:50,892: time cost, forward:0.011673226848140254, backward:0.029715435640947956, data cost:0.6988717939283278 
2022-06-29 12:58:50,892: ============================================================
2022-06-29 12:58:50,892: Epoch 23/26 Batch 1000/7662 eta: 6:00:18.798360	Training Loss 2.3071 (2.2777)	Training Prec@1 99.219 (99.652)	Training Prec@5 99.805 (99.885)	
2022-06-29 12:58:50,892: ============================================================
2022-06-29 13:00:05,043: time cost, forward:0.011707262953809437, backward:0.02997032439741251, data cost:0.6986595822855817 
2022-06-29 13:00:05,043: ============================================================
2022-06-29 13:00:05,043: Epoch 23/26 Batch 1100/7662 eta: 6:05:10.910136	Training Loss 2.4319 (2.2802)	Training Prec@1 99.414 (99.650)	Training Prec@5 99.414 (99.884)	
2022-06-29 13:00:05,044: ============================================================
2022-06-29 13:01:17,284: time cost, forward:0.011655104369099086, backward:0.030092617389656684, data cost:0.6970510592154406 
2022-06-29 13:01:17,284: ============================================================
2022-06-29 13:01:17,284: Epoch 23/26 Batch 1200/7662 eta: 5:54:34.152511	Training Loss 2.4307 (2.2821)	Training Prec@1 99.609 (99.647)	Training Prec@5 99.805 (99.880)	
2022-06-29 13:01:17,284: ============================================================
2022-06-29 13:02:30,685: time cost, forward:0.011734034301135244, backward:0.03021428252844924, data cost:0.6964441217579596 
2022-06-29 13:02:30,686: ============================================================
2022-06-29 13:02:30,686: Epoch 23/26 Batch 1300/7662 eta: 5:59:02.725466	Training Loss 2.0913 (2.2843)	Training Prec@1 99.414 (99.646)	Training Prec@5 99.805 (99.880)	
2022-06-29 13:02:30,686: ============================================================
2022-06-29 13:03:44,723: time cost, forward:0.011692576445878788, backward:0.03026238656879068, data cost:0.6965398365808777 
2022-06-29 13:03:44,723: ============================================================
2022-06-29 13:03:44,723: Epoch 23/26 Batch 1400/7662 eta: 6:00:55.198431	Training Loss 2.3791 (2.2859)	Training Prec@1 99.219 (99.646)	Training Prec@5 99.414 (99.881)	
2022-06-29 13:03:44,723: ============================================================
2022-06-29 13:04:58,044: time cost, forward:0.01166608939574829, backward:0.030348913124038666, data cost:0.6960986688027309 
2022-06-29 13:04:58,044: ============================================================
2022-06-29 13:04:58,045: Epoch 23/26 Batch 1500/7662 eta: 5:56:12.381268	Training Loss 2.3941 (2.2876)	Training Prec@1 99.805 (99.646)	Training Prec@5 100.000 (99.883)	
2022-06-29 13:04:58,045: ============================================================
2022-06-29 13:06:10,914: time cost, forward:0.011655869820924607, backward:0.03037990116193341, data cost:0.6954539949406379 
2022-06-29 13:06:10,915: ============================================================
2022-06-29 13:06:10,915: Epoch 23/26 Batch 1600/7662 eta: 5:52:48.162167	Training Loss 2.4802 (2.2889)	Training Prec@1 99.023 (99.644)	Training Prec@5 100.000 (99.883)	
2022-06-29 13:06:10,915: ============================================================
2022-06-29 13:07:25,284: time cost, forward:0.01168894880024246, backward:0.030301282657041767, data cost:0.6958424896264932 
2022-06-29 13:07:25,284: ============================================================
2022-06-29 13:07:25,285: Epoch 23/26 Batch 1700/7662 eta: 5:58:49.245444	Training Loss 2.2281 (2.2905)	Training Prec@1 99.609 (99.643)	Training Prec@5 100.000 (99.882)	
2022-06-29 13:07:25,285: ============================================================
2022-06-29 13:08:38,081: time cost, forward:0.011684881971570239, backward:0.030330168134043652, data cost:0.6952466162924902 
2022-06-29 13:08:38,082: ============================================================
2022-06-29 13:08:38,082: Epoch 23/26 Batch 1800/7662 eta: 5:50:01.219166	Training Loss 2.2912 (2.2919)	Training Prec@1 99.609 (99.640)	Training Prec@5 99.805 (99.881)	
2022-06-29 13:08:38,082: ============================================================
2022-06-29 13:09:51,188: time cost, forward:0.011672420210434048, backward:0.030351411800374477, data cost:0.6948897485798318 
2022-06-29 13:09:51,188: ============================================================
2022-06-29 13:09:51,188: Epoch 23/26 Batch 1900/7662 eta: 5:50:17.336595	Training Loss 2.5349 (2.2936)	Training Prec@1 98.828 (99.638)	Training Prec@5 99.219 (99.881)	
2022-06-29 13:09:51,188: ============================================================
2022-06-29 13:11:05,487: time cost, forward:0.011690409199007157, backward:0.030417070202734424, data cost:0.695087484862579 
2022-06-29 13:11:05,487: ============================================================
2022-06-29 13:11:05,487: Epoch 23/26 Batch 2000/7662 eta: 5:54:46.022018	Training Loss 2.2265 (2.2956)	Training Prec@1 99.414 (99.636)	Training Prec@5 99.609 (99.880)	
2022-06-29 13:11:05,487: ============================================================
2022-06-29 13:12:19,956: time cost, forward:0.01170415864665489, backward:0.030501395307761706, data cost:0.6953281480508399 
2022-06-29 13:12:19,957: ============================================================
2022-06-29 13:12:19,957: Epoch 23/26 Batch 2100/7662 eta: 5:54:20.285526	Training Loss 2.4331 (2.2977)	Training Prec@1 99.609 (99.638)	Training Prec@5 99.805 (99.881)	
2022-06-29 13:12:19,957: ============================================================
2022-06-29 13:13:35,120: time cost, forward:0.01171821862689578, backward:0.030572356826449158, data cost:0.6958591011016138 
2022-06-29 13:13:35,120: ============================================================
2022-06-29 13:13:35,120: Epoch 23/26 Batch 2200/7662 eta: 5:56:23.246500	Training Loss 2.3171 (2.2996)	Training Prec@1 100.000 (99.636)	Training Prec@5 100.000 (99.881)	
2022-06-29 13:13:35,120: ============================================================
2022-06-29 13:14:47,413: time cost, forward:0.011696271659914126, backward:0.03059946334377586, data cost:0.6951758395904767 
2022-06-29 13:14:47,413: ============================================================
2022-06-29 13:14:47,413: Epoch 23/26 Batch 2300/7662 eta: 5:41:34.275855	Training Loss 2.4339 (2.3000)	Training Prec@1 100.000 (99.633)	Training Prec@5 100.000 (99.881)	
2022-06-29 13:14:47,413: ============================================================
2022-06-29 13:16:01,827: time cost, forward:0.011667023901643233, backward:0.030642678013142074, data cost:0.6954210942464354 
2022-06-29 13:16:01,827: ============================================================
2022-06-29 13:16:01,827: Epoch 23/26 Batch 2400/7662 eta: 5:50:21.322672	Training Loss 2.6313 (2.3016)	Training Prec@1 99.023 (99.630)	Training Prec@5 99.609 (99.879)	
2022-06-29 13:16:01,828: ============================================================
2022-06-29 13:17:15,029: time cost, forward:0.011642329260653237, backward:0.030465711732538474, data cost:0.6953704528877286 
2022-06-29 13:17:15,029: ============================================================
2022-06-29 13:17:15,029: Epoch 23/26 Batch 2500/7662 eta: 5:43:25.505251	Training Loss 2.2669 (2.3030)	Training Prec@1 99.219 (99.629)	Training Prec@5 99.805 (99.879)	
2022-06-29 13:17:15,029: ============================================================
2022-06-29 13:18:29,296: time cost, forward:0.011635180022359673, backward:0.03048053958315994, data cost:0.695547238364959 
2022-06-29 13:18:29,296: ============================================================
2022-06-29 13:18:29,296: Epoch 23/26 Batch 2600/7662 eta: 5:47:11.205990	Training Loss 2.3317 (2.3045)	Training Prec@1 99.609 (99.629)	Training Prec@5 99.805 (99.879)	
2022-06-29 13:18:29,296: ============================================================
2022-06-29 13:19:43,832: time cost, forward:0.011626330690500515, backward:0.030469025890665524, data cost:0.6958387872385687 
2022-06-29 13:19:43,832: ============================================================
2022-06-29 13:19:43,832: Epoch 23/26 Batch 2700/7662 eta: 5:47:12.108491	Training Loss 2.1763 (2.3059)	Training Prec@1 100.000 (99.629)	Training Prec@5 100.000 (99.879)	
2022-06-29 13:19:43,832: ============================================================
2022-06-29 13:20:56,981: time cost, forward:0.011617284112421262, backward:0.030486044350501767, data cost:0.6955835504930502 
2022-06-29 13:20:56,982: ============================================================
2022-06-29 13:20:56,982: Epoch 23/26 Batch 2800/7662 eta: 5:39:31.415314	Training Loss 2.3111 (2.3070)	Training Prec@1 99.023 (99.628)	Training Prec@5 99.609 (99.879)	
2022-06-29 13:20:56,982: ============================================================
2022-06-29 13:22:10,980: time cost, forward:0.011612425511686833, backward:0.03053421873847301, data cost:0.6956031826620638 
2022-06-29 13:22:10,981: ============================================================
2022-06-29 13:22:10,981: Epoch 23/26 Batch 2900/7662 eta: 5:42:13.915644	Training Loss 2.4175 (2.3085)	Training Prec@1 99.609 (99.627)	Training Prec@5 99.805 (99.879)	
2022-06-29 13:22:10,981: ============================================================
2022-06-29 13:23:24,743: time cost, forward:0.01159901839965739, backward:0.030549218790576472, data cost:0.6955853798024533 
2022-06-29 13:23:24,744: ============================================================
2022-06-29 13:23:24,744: Epoch 23/26 Batch 3000/7662 eta: 5:39:54.780391	Training Loss 2.3300 (2.3102)	Training Prec@1 99.805 (99.627)	Training Prec@5 99.805 (99.878)	
2022-06-29 13:23:24,744: ============================================================
2022-06-29 13:24:38,526: time cost, forward:0.011581587229824405, backward:0.030504828308735712, data cost:0.6956326598388681 
2022-06-29 13:24:38,526: ============================================================
2022-06-29 13:24:38,526: Epoch 23/26 Batch 3100/7662 eta: 5:38:46.329898	Training Loss 2.2444 (2.3120)	Training Prec@1 99.414 (99.625)	Training Prec@5 99.805 (99.877)	
2022-06-29 13:24:38,526: ============================================================
2022-06-29 13:25:52,030: time cost, forward:0.011573665102558904, backward:0.030410826672014127, data cost:0.695637915349819 
2022-06-29 13:25:52,030: ============================================================
2022-06-29 13:25:52,031: Epoch 23/26 Batch 3200/7662 eta: 5:36:16.203258	Training Loss 2.5877 (2.3134)	Training Prec@1 99.414 (99.626)	Training Prec@5 99.805 (99.877)	
2022-06-29 13:25:52,031: ============================================================
2022-06-29 13:27:05,929: time cost, forward:0.011564038673578952, backward:0.030418896826876766, data cost:0.6956656710528432 
2022-06-29 13:27:05,930: ============================================================
2022-06-29 13:27:05,930: Epoch 23/26 Batch 3300/7662 eta: 5:36:50.725322	Training Loss 2.3857 (2.3143)	Training Prec@1 99.805 (99.628)	Training Prec@5 100.000 (99.879)	
2022-06-29 13:27:05,930: ============================================================
2022-06-29 13:28:19,257: time cost, forward:0.011551266945471095, backward:0.0302693700748319, data cost:0.6956879646506651 
2022-06-29 13:28:19,257: ============================================================
2022-06-29 13:28:19,257: Epoch 23/26 Batch 3400/7662 eta: 5:33:00.966001	Training Loss 2.2271 (2.3156)	Training Prec@1 99.609 (99.626)	Training Prec@5 100.000 (99.878)	
2022-06-29 13:28:19,257: ============================================================
2022-06-29 13:29:33,914: time cost, forward:0.011542918239875874, backward:0.03031309123174161, data cost:0.6958996841450288 
2022-06-29 13:29:33,915: ============================================================
2022-06-29 13:29:33,915: Epoch 23/26 Batch 3500/7662 eta: 5:37:48.721897	Training Loss 2.3691 (2.3171)	Training Prec@1 99.414 (99.625)	Training Prec@5 99.609 (99.877)	
2022-06-29 13:29:33,915: ============================================================
2022-06-29 13:30:48,101: time cost, forward:0.01154072670911411, backward:0.030337170118356818, data cost:0.695979377434432 
2022-06-29 13:30:48,102: ============================================================
2022-06-29 13:30:48,102: Epoch 23/26 Batch 3600/7662 eta: 5:34:26.911805	Training Loss 2.3519 (2.3187)	Training Prec@1 99.219 (99.626)	Training Prec@5 99.414 (99.877)	
2022-06-29 13:30:48,102: ============================================================
2022-06-29 13:32:01,787: time cost, forward:0.011549763306955223, backward:0.03038356361533539, data cost:0.6958881930165369 
2022-06-29 13:32:01,787: ============================================================
2022-06-29 13:32:01,787: Epoch 23/26 Batch 3700/7662 eta: 5:30:57.466369	Training Loss 2.3663 (2.3203)	Training Prec@1 99.609 (99.625)	Training Prec@5 100.000 (99.877)	
2022-06-29 13:32:01,787: ============================================================
2022-06-29 13:33:15,021: time cost, forward:0.011532495196915576, backward:0.030413105601415913, data cost:0.6957199238387809 
2022-06-29 13:33:15,021: ============================================================
2022-06-29 13:33:15,022: Epoch 23/26 Batch 3800/7662 eta: 5:27:42.683837	Training Loss 2.3808 (2.3221)	Training Prec@1 99.609 (99.624)	Training Prec@5 100.000 (99.877)	
2022-06-29 13:33:15,022: ============================================================
2022-06-29 13:34:28,906: time cost, forward:0.011533615802550627, backward:0.03046101629810475, data cost:0.6956891038228867 
2022-06-29 13:34:28,907: ============================================================
2022-06-29 13:34:28,907: Epoch 23/26 Batch 3900/7662 eta: 5:29:23.537040	Training Loss 2.3420 (2.3233)	Training Prec@1 99.609 (99.623)	Training Prec@5 99.805 (99.876)	
2022-06-29 13:34:28,907: ============================================================
2022-06-29 13:35:42,751: time cost, forward:0.011524089547090752, backward:0.0304830997817127, data cost:0.6956816970422645 
2022-06-29 13:35:42,751: ============================================================
2022-06-29 13:35:42,751: Epoch 23/26 Batch 4000/7662 eta: 5:27:58.787466	Training Loss 2.5123 (2.3248)	Training Prec@1 99.414 (99.621)	Training Prec@5 100.000 (99.876)	
2022-06-29 13:35:42,751: ============================================================
2022-06-29 13:36:56,671: time cost, forward:0.01152650953415226, backward:0.030522742949627934, data cost:0.6956676640548948 
2022-06-29 13:36:56,671: ============================================================
2022-06-29 13:36:56,671: Epoch 23/26 Batch 4100/7662 eta: 5:27:05.091967	Training Loss 2.4191 (2.3259)	Training Prec@1 99.805 (99.621)	Training Prec@5 100.000 (99.876)	
2022-06-29 13:36:56,672: ============================================================
2022-06-29 13:38:09,904: time cost, forward:0.011524959699572141, backward:0.030554188975665534, data cost:0.6954961594697208 
2022-06-29 13:38:09,904: ============================================================
2022-06-29 13:38:09,904: Epoch 23/26 Batch 4200/7662 eta: 5:22:49.297871	Training Loss 2.4951 (2.3272)	Training Prec@1 99.609 (99.621)	Training Prec@5 99.805 (99.876)	
2022-06-29 13:38:09,904: ============================================================
2022-06-29 13:39:23,912: time cost, forward:0.011521211749704862, backward:0.03056771241112847, data cost:0.6955352616493135 
2022-06-29 13:39:23,912: ============================================================
2022-06-29 13:39:23,912: Epoch 23/26 Batch 4300/7662 eta: 5:25:00.361674	Training Loss 2.3937 (2.3286)	Training Prec@1 100.000 (99.620)	Training Prec@5 100.000 (99.876)	
2022-06-29 13:39:23,912: ============================================================
2022-06-29 13:40:38,027: time cost, forward:0.011524380269606673, backward:0.030588228828827342, data cost:0.6955816773399219 
2022-06-29 13:40:38,028: ============================================================
2022-06-29 13:40:38,028: Epoch 23/26 Batch 4400/7662 eta: 5:24:14.647430	Training Loss 2.2061 (2.3298)	Training Prec@1 99.414 (99.620)	Training Prec@5 99.805 (99.876)	
2022-06-29 13:40:38,028: ============================================================
2022-06-29 13:41:52,840: time cost, forward:0.011534241735471516, backward:0.030596002151394294, data cost:0.6957853012123116 
2022-06-29 13:41:52,840: ============================================================
2022-06-29 13:41:52,840: Epoch 23/26 Batch 4500/7662 eta: 5:26:02.758468	Training Loss 2.4807 (2.3308)	Training Prec@1 99.023 (99.619)	Training Prec@5 99.805 (99.875)	
2022-06-29 13:41:52,841: ============================================================
2022-06-29 13:43:06,637: time cost, forward:0.011523990844690066, backward:0.030630260427300375, data cost:0.6957551034333058 
2022-06-29 13:43:06,637: ============================================================
2022-06-29 13:43:06,637: Epoch 23/26 Batch 4600/7662 eta: 5:20:23.371010	Training Loss 2.4281 (2.3322)	Training Prec@1 99.609 (99.618)	Training Prec@5 99.805 (99.875)	
2022-06-29 13:43:06,638: ============================================================
2022-06-29 13:44:21,250: time cost, forward:0.011517421314883267, backward:0.03057828926740745, data cost:0.6959797339531736 
2022-06-29 13:44:21,250: ============================================================
2022-06-29 13:44:21,251: Epoch 23/26 Batch 4700/7662 eta: 5:22:41.339103	Training Loss 2.3599 (2.3331)	Training Prec@1 99.805 (99.617)	Training Prec@5 100.000 (99.874)	
2022-06-29 13:44:21,251: ============================================================
2022-06-29 13:45:36,490: time cost, forward:0.011524266365990835, backward:0.030586979542704618, data cost:0.6962496788706921 
2022-06-29 13:45:36,491: ============================================================
2022-06-29 13:45:36,491: Epoch 23/26 Batch 4800/7662 eta: 5:24:08.859277	Training Loss 2.3414 (2.3348)	Training Prec@1 99.609 (99.616)	Training Prec@5 100.000 (99.874)	
2022-06-29 13:45:36,491: ============================================================
2022-06-29 13:46:50,465: time cost, forward:0.011529556705796444, backward:0.030614181692976444, data cost:0.6962379137090966 
2022-06-29 13:46:50,466: ============================================================
2022-06-29 13:46:50,466: Epoch 23/26 Batch 4900/7662 eta: 5:17:27.823032	Training Loss 2.5205 (2.3362)	Training Prec@1 99.414 (99.615)	Training Prec@5 100.000 (99.874)	
2022-06-29 13:46:50,466: ============================================================
2022-06-29 13:48:05,023: time cost, forward:0.011524131618086924, backward:0.030646081399049584, data cost:0.6963450644440259 
2022-06-29 13:48:05,024: ============================================================
2022-06-29 13:48:05,024: Epoch 23/26 Batch 5000/7662 eta: 5:18:43.432994	Training Loss 2.3983 (2.3372)	Training Prec@1 99.414 (99.614)	Training Prec@5 100.000 (99.874)	
2022-06-29 13:48:05,024: ============================================================
2022-06-29 13:49:18,335: time cost, forward:0.011528674657028268, backward:0.030690987499631322, data cost:0.6961850329786451 
2022-06-29 13:49:18,336: ============================================================
2022-06-29 13:49:18,336: Epoch 23/26 Batch 5100/7662 eta: 5:12:10.425204	Training Loss 2.5011 (2.3388)	Training Prec@1 99.414 (99.613)	Training Prec@5 99.805 (99.874)	
2022-06-29 13:49:18,336: ============================================================
2022-06-29 13:50:32,725: time cost, forward:0.011526430219520763, backward:0.030712441679009293, data cost:0.6962555255493674 
2022-06-29 13:50:32,725: ============================================================
2022-06-29 13:50:32,725: Epoch 23/26 Batch 5200/7662 eta: 5:15:31.315025	Training Loss 2.3770 (2.3400)	Training Prec@1 99.414 (99.613)	Training Prec@5 99.805 (99.873)	
2022-06-29 13:50:32,725: ============================================================
2022-06-29 13:51:47,184: time cost, forward:0.011516070181433942, backward:0.03074351277615039, data cost:0.6963417809917063 
2022-06-29 13:51:47,184: ============================================================
2022-06-29 13:51:47,185: Epoch 23/26 Batch 5300/7662 eta: 5:14:34.784545	Training Loss 2.6604 (2.3409)	Training Prec@1 99.414 (99.612)	Training Prec@5 99.609 (99.873)	
2022-06-29 13:51:47,185: ============================================================
2022-06-29 13:53:00,887: time cost, forward:0.011506491534068288, backward:0.03075000550442657, data cost:0.6963094414373441 
2022-06-29 13:53:00,888: ============================================================
2022-06-29 13:53:00,888: Epoch 23/26 Batch 5400/7662 eta: 5:10:09.299563	Training Loss 2.5386 (2.3426)	Training Prec@1 99.414 (99.611)	Training Prec@5 99.805 (99.873)	
2022-06-29 13:53:00,888: ============================================================
2022-06-29 13:54:14,322: time cost, forward:0.011500122677653372, backward:0.030735564938587024, data cost:0.6962428176635004 
2022-06-29 13:54:14,322: ============================================================
2022-06-29 13:54:14,322: Epoch 23/26 Batch 5500/7662 eta: 5:07:48.000188	Training Loss 2.3933 (2.3433)	Training Prec@1 99.805 (99.610)	Training Prec@5 100.000 (99.873)	
2022-06-29 13:54:14,322: ============================================================
2022-06-29 13:55:28,183: time cost, forward:0.011488282014097692, backward:0.030732408764746002, data cost:0.6962524841333803 
2022-06-29 13:55:28,183: ============================================================
2022-06-29 13:55:28,183: Epoch 23/26 Batch 5600/7662 eta: 5:08:21.417897	Training Loss 2.4087 (2.3448)	Training Prec@1 99.805 (99.609)	Training Prec@5 100.000 (99.872)	
2022-06-29 13:55:28,183: ============================================================
2022-06-29 13:56:41,870: time cost, forward:0.011485075318911636, backward:0.03074689015189186, data cost:0.6962057589898927 
2022-06-29 13:56:41,870: ============================================================
2022-06-29 13:56:41,870: Epoch 23/26 Batch 5700/7662 eta: 5:06:24.220378	Training Loss 2.5562 (2.3460)	Training Prec@1 99.805 (99.609)	Training Prec@5 100.000 (99.872)	
2022-06-29 13:56:41,870: ============================================================
2022-06-29 13:57:55,108: time cost, forward:0.011476809782372567, backward:0.030741960432102276, data cost:0.6961056248322296 
2022-06-29 13:57:55,108: ============================================================
2022-06-29 13:57:55,108: Epoch 23/26 Batch 5800/7662 eta: 5:03:18.867765	Training Loss 2.3542 (2.3473)	Training Prec@1 99.805 (99.608)	Training Prec@5 100.000 (99.871)	
2022-06-29 13:57:55,108: ============================================================
2022-06-29 13:59:09,834: time cost, forward:0.011480881695344017, backward:0.030751348087435598, data cost:0.6962370029807717 
2022-06-29 13:59:09,834: ============================================================
2022-06-29 13:59:09,835: Epoch 23/26 Batch 5900/7662 eta: 5:08:14.037714	Training Loss 2.3194 (2.3482)	Training Prec@1 99.219 (99.607)	Training Prec@5 99.414 (99.871)	
2022-06-29 13:59:09,835: ============================================================
2022-06-29 14:00:23,839: time cost, forward:0.01147991900723027, backward:0.030765117099035143, data cost:0.6962430396463934 
2022-06-29 14:00:23,840: ============================================================
2022-06-29 14:00:23,840: Epoch 23/26 Batch 6000/7662 eta: 5:04:01.599083	Training Loss 2.4313 (2.3492)	Training Prec@1 99.805 (99.606)	Training Prec@5 100.000 (99.871)	
2022-06-29 14:00:23,840: ============================================================
2022-06-29 14:01:37,269: time cost, forward:0.011467474017852367, backward:0.030750991125774493, data cost:0.6961924616949229 
2022-06-29 14:01:37,269: ============================================================
2022-06-29 14:01:37,269: Epoch 23/26 Batch 6100/7662 eta: 5:00:26.106783	Training Loss 2.2583 (2.3504)	Training Prec@1 100.000 (99.606)	Training Prec@5 100.000 (99.871)	
2022-06-29 14:01:37,269: ============================================================
2022-06-29 14:02:50,367: time cost, forward:0.0114687107939704, backward:0.03072324874497629, data cost:0.696093443267325 
2022-06-29 14:02:50,368: ============================================================
2022-06-29 14:02:50,368: Epoch 23/26 Batch 6200/7662 eta: 4:57:51.952704	Training Loss 2.3452 (2.3514)	Training Prec@1 99.414 (99.605)	Training Prec@5 100.000 (99.870)	
2022-06-29 14:02:50,368: ============================================================
2022-06-29 14:04:04,164: time cost, forward:0.011462863541194458, backward:0.03072923212737238, data cost:0.6960795810628002 
2022-06-29 14:04:04,164: ============================================================
2022-06-29 14:04:04,165: Epoch 23/26 Batch 6300/7662 eta: 4:59:28.751285	Training Loss 2.3238 (2.3527)	Training Prec@1 99.805 (99.603)	Training Prec@5 99.805 (99.869)	
2022-06-29 14:04:04,165: ============================================================
2022-06-29 14:05:17,353: time cost, forward:0.011476246299809229, backward:0.03072925786857289, data cost:0.6959610935821628 
2022-06-29 14:05:17,353: ============================================================
2022-06-29 14:05:17,353: Epoch 23/26 Batch 6400/7662 eta: 4:55:47.483973	Training Loss 2.3817 (2.3536)	Training Prec@1 99.414 (99.603)	Training Prec@5 99.805 (99.870)	
2022-06-29 14:05:17,353: ============================================================
2022-06-29 14:06:31,620: time cost, forward:0.011464768472974677, backward:0.030691090978683187, data cost:0.6960741686333067 
2022-06-29 14:06:31,620: ============================================================
2022-06-29 14:06:31,621: Epoch 23/26 Batch 6500/7662 eta: 4:58:54.858269	Training Loss 2.4119 (2.3545)	Training Prec@1 99.609 (99.602)	Training Prec@5 99.805 (99.869)	
2022-06-29 14:06:31,621: ============================================================
2022-06-29 14:07:46,176: time cost, forward:0.011471032843406967, backward:0.030689957178367016, data cost:0.6961712037673374 
2022-06-29 14:07:46,176: ============================================================
2022-06-29 14:07:46,177: Epoch 23/26 Batch 6600/7662 eta: 4:58:49.947726	Training Loss 2.5488 (2.3555)	Training Prec@1 99.805 (99.601)	Training Prec@5 99.805 (99.869)	
2022-06-29 14:07:46,177: ============================================================
2022-06-29 14:08:59,255: time cost, forward:0.011472454069621316, backward:0.0306744982296183, data cost:0.696065726111515 
2022-06-29 14:08:59,255: ============================================================
2022-06-29 14:08:59,255: Epoch 23/26 Batch 6700/7662 eta: 4:51:41.654308	Training Loss 2.3520 (2.3563)	Training Prec@1 99.414 (99.600)	Training Prec@5 99.805 (99.869)	
2022-06-29 14:08:59,255: ============================================================
2022-06-29 14:10:13,011: time cost, forward:0.01147777681088409, backward:0.03068244809665335, data cost:0.6960364633631155 
2022-06-29 14:10:13,011: ============================================================
2022-06-29 14:10:13,011: Epoch 23/26 Batch 6800/7662 eta: 4:53:10.031093	Training Loss 2.5350 (2.3573)	Training Prec@1 100.000 (99.599)	Training Prec@5 100.000 (99.868)	
2022-06-29 14:10:13,011: ============================================================
2022-06-29 14:11:26,958: time cost, forward:0.011465536544142918, backward:0.030660566237892407, data cost:0.6960825615299665 
2022-06-29 14:11:26,958: ============================================================
2022-06-29 14:11:26,959: Epoch 23/26 Batch 6900/7662 eta: 4:52:41.736227	Training Loss 2.3095 (2.3586)	Training Prec@1 99.805 (99.598)	Training Prec@5 99.805 (99.868)	
2022-06-29 14:11:26,959: ============================================================
2022-06-29 14:12:41,733: time cost, forward:0.011475371367455483, backward:0.030682826795004354, data cost:0.6961805725424677 
2022-06-29 14:12:41,733: ============================================================
2022-06-29 14:12:41,734: Epoch 23/26 Batch 7000/7662 eta: 4:54:43.534698	Training Loss 2.4387 (2.3594)	Training Prec@1 99.219 (99.597)	Training Prec@5 99.609 (99.868)	
2022-06-29 14:12:41,734: ============================================================
2022-06-29 14:13:54,748: time cost, forward:0.011471073834690213, backward:0.03066169884796293, data cost:0.6960843219977396 
2022-06-29 14:13:54,749: ============================================================
2022-06-29 14:13:54,749: Epoch 23/26 Batch 7100/7662 eta: 4:46:34.401920	Training Loss 2.4072 (2.3604)	Training Prec@1 99.805 (99.596)	Training Prec@5 100.000 (99.868)	
2022-06-29 14:13:54,749: ============================================================
2022-06-29 14:15:08,362: time cost, forward:0.011472815390278323, backward:0.030668108343067955, data cost:0.6960417751736699 
2022-06-29 14:15:08,363: ============================================================
2022-06-29 14:15:08,363: Epoch 23/26 Batch 7200/7662 eta: 4:47:41.735977	Training Loss 2.5888 (2.3610)	Training Prec@1 99.219 (99.597)	Training Prec@5 99.609 (99.868)	
2022-06-29 14:15:08,363: ============================================================
2022-06-29 14:16:21,108: time cost, forward:0.011465715241605312, backward:0.0306658738932392, data cost:0.695897137796998 
2022-06-29 14:16:21,108: ============================================================
2022-06-29 14:16:21,108: Epoch 23/26 Batch 7300/7662 eta: 4:43:05.273612	Training Loss 2.3441 (2.3621)	Training Prec@1 99.219 (99.595)	Training Prec@5 99.414 (99.867)	
2022-06-29 14:16:21,108: ============================================================
2022-06-29 14:17:34,410: time cost, forward:0.01146471650234057, backward:0.030654896174045588, data cost:0.6958352687439736 
2022-06-29 14:17:34,410: ============================================================
2022-06-29 14:17:34,410: Epoch 23/26 Batch 7400/7662 eta: 4:44:01.998564	Training Loss 2.3652 (2.3636)	Training Prec@1 100.000 (99.594)	Training Prec@5 100.000 (99.867)	
2022-06-29 14:17:34,410: ============================================================
2022-06-29 14:18:48,576: time cost, forward:0.011469358666004507, backward:0.030654476585189792, data cost:0.6958769673521573 
2022-06-29 14:18:48,576: ============================================================
2022-06-29 14:18:48,577: Epoch 23/26 Batch 7500/7662 eta: 4:46:08.782409	Training Loss 2.4357 (2.3649)	Training Prec@1 99.414 (99.593)	Training Prec@5 99.805 (99.866)	
2022-06-29 14:18:48,577: ============================================================
2022-06-29 14:20:02,516: time cost, forward:0.01147741392296009, backward:0.030664244769889912, data cost:0.6958702433217527 
2022-06-29 14:20:02,516: ============================================================
2022-06-29 14:20:02,516: Epoch 23/26 Batch 7600/7662 eta: 4:44:02.368022	Training Loss 2.3154 (2.3660)	Training Prec@1 99.805 (99.593)	Training Prec@5 100.000 (99.866)	
2022-06-29 14:20:02,516: ============================================================
2022-06-29 14:20:51,643: Epoch: 23/26 eta: 4:43:15.785993	Training Loss 2.1420 (2.3665)	Training Prec@1 99.609 (99.593)	Training Prec@5 99.805 (99.866)
2022-06-29 14:20:51,644: ============================================================
2022-06-29 14:22:24,274: time cost, forward:0.010455906993210917, backward:0.029401892363423048, data cost:0.8893292359631471 
2022-06-29 14:22:24,275: ============================================================
2022-06-29 14:22:24,275: Epoch 24/26 Batch 100/7662 eta: 5:52:50.180994	Training Loss 2.2089 (2.2212)	Training Prec@1 99.609 (99.663)	Training Prec@5 99.609 (99.895)	
2022-06-29 14:22:24,275: ============================================================
2022-06-29 14:23:37,903: time cost, forward:0.01086563680639219, backward:0.029517881834327277, data cost:0.7916285752052039 
2022-06-29 14:23:37,903: ============================================================
2022-06-29 14:23:37,903: Epoch 24/26 Batch 200/7662 eta: 4:39:37.768342	Training Loss 2.2188 (2.2290)	Training Prec@1 99.805 (99.683)	Training Prec@5 100.000 (99.912)	
2022-06-29 14:23:37,904: ============================================================
2022-06-29 14:24:51,318: time cost, forward:0.01097113870856754, backward:0.029561992473028178, data cost:0.7586070614116248 
2022-06-29 14:24:51,318: ============================================================
2022-06-29 14:24:51,318: Epoch 24/26 Batch 300/7662 eta: 4:37:35.628641	Training Loss 2.1429 (2.2353)	Training Prec@1 99.805 (99.694)	Training Prec@5 100.000 (99.911)	
2022-06-29 14:24:51,318: ============================================================
2022-06-29 14:26:03,033: time cost, forward:0.010944640726075136, backward:0.029784311925558218, data cost:0.7377482625774872 
2022-06-29 14:26:03,033: ============================================================
2022-06-29 14:26:03,033: Epoch 24/26 Batch 400/7662 eta: 4:29:58.275108	Training Loss 2.1069 (2.2353)	Training Prec@1 100.000 (99.695)	Training Prec@5 100.000 (99.906)	
2022-06-29 14:26:03,033: ============================================================
2022-06-29 14:27:16,420: time cost, forward:0.011043887339039651, backward:0.0297130310463762, data cost:0.7286708340616169 
2022-06-29 14:27:16,421: ============================================================
2022-06-29 14:27:16,421: Epoch 24/26 Batch 500/7662 eta: 4:35:02.660003	Training Loss 2.5096 (2.2395)	Training Prec@1 99.219 (99.693)	Training Prec@5 99.805 (99.904)	
2022-06-29 14:27:16,421: ============================================================
2022-06-29 14:28:28,489: time cost, forward:0.011093945256457703, backward:0.029563793156899276, data cost:0.720543096379963 
2022-06-29 14:28:28,489: ============================================================
2022-06-29 14:28:28,489: Epoch 24/26 Batch 600/7662 eta: 4:28:53.998803	Training Loss 2.1922 (2.2424)	Training Prec@1 100.000 (99.690)	Training Prec@5 100.000 (99.904)	
2022-06-29 14:28:28,490: ============================================================
2022-06-29 14:29:41,232: time cost, forward:0.01106314870591498, backward:0.0297166462108301, data cost:0.7155152080055641 
2022-06-29 14:29:41,232: ============================================================
2022-06-29 14:29:41,232: Epoch 24/26 Batch 700/7662 eta: 4:30:12.202023	Training Loss 2.1746 (2.2448)	Training Prec@1 99.805 (99.690)	Training Prec@5 99.805 (99.906)	
2022-06-29 14:29:41,232: ============================================================
2022-06-29 14:30:54,034: time cost, forward:0.01113592877107508, backward:0.029778135285359598, data cost:0.7117880091947668 
2022-06-29 14:30:54,034: ============================================================
2022-06-29 14:30:54,035: Epoch 24/26 Batch 800/7662 eta: 4:29:12.631537	Training Loss 2.1680 (2.2459)	Training Prec@1 99.609 (99.693)	Training Prec@5 99.805 (99.907)	
2022-06-29 14:30:54,035: ============================================================
2022-06-29 14:32:06,111: time cost, forward:0.011189812680372805, backward:0.029860745812947547, data cost:0.7080411476075849 
2022-06-29 14:32:06,112: ============================================================
2022-06-29 14:32:06,112: Epoch 24/26 Batch 900/7662 eta: 4:25:19.708264	Training Loss 2.3200 (2.2460)	Training Prec@1 99.609 (99.690)	Training Prec@5 100.000 (99.904)	
2022-06-29 14:32:06,112: ============================================================
2022-06-29 14:33:19,101: time cost, forward:0.011206347901780565, backward:0.0299779760228979, data cost:0.7059370409380328 
2022-06-29 14:33:19,101: ============================================================
2022-06-29 14:33:19,101: Epoch 24/26 Batch 1000/7662 eta: 4:27:28.202581	Training Loss 2.1326 (2.2484)	Training Prec@1 100.000 (99.692)	Training Prec@5 100.000 (99.903)	
2022-06-29 14:33:19,101: ============================================================
2022-06-29 14:34:32,204: time cost, forward:0.01127998149861413, backward:0.029965274002033544, data cost:0.7043629499648895 
2022-06-29 14:34:32,204: ============================================================
2022-06-29 14:34:32,205: Epoch 24/26 Batch 1100/7662 eta: 4:26:40.091322	Training Loss 2.1009 (2.2500)	Training Prec@1 100.000 (99.689)	Training Prec@5 100.000 (99.902)	
2022-06-29 14:34:32,205: ============================================================
2022-06-29 14:35:44,360: time cost, forward:0.011326978960267894, backward:0.029894794793403377, data cost:0.7023479037726293 
2022-06-29 14:35:44,360: ============================================================
2022-06-29 14:35:44,360: Epoch 24/26 Batch 1200/7662 eta: 4:22:00.580792	Training Loss 2.2771 (2.2527)	Training Prec@1 99.609 (99.688)	Training Prec@5 100.000 (99.900)	
2022-06-29 14:35:44,360: ============================================================
2022-06-29 14:36:57,118: time cost, forward:0.011329459079510436, backward:0.029975925435278397, data cost:0.7009965593398214 
2022-06-29 14:36:57,118: ============================================================
2022-06-29 14:36:57,118: Epoch 24/26 Batch 1300/7662 eta: 4:22:59.021543	Training Loss 2.2952 (2.2544)	Training Prec@1 99.805 (99.687)	Training Prec@5 100.000 (99.900)	
2022-06-29 14:36:57,118: ============================================================
2022-06-29 14:38:10,198: time cost, forward:0.011364041438181116, backward:0.03002296182579275, data cost:0.7000611946359543 
2022-06-29 14:38:10,198: ============================================================
2022-06-29 14:38:10,198: Epoch 24/26 Batch 1400/7662 eta: 4:22:55.810001	Training Loss 2.3180 (2.2555)	Training Prec@1 99.414 (99.687)	Training Prec@5 99.805 (99.900)	
2022-06-29 14:38:10,199: ============================================================
2022-06-29 14:39:24,067: time cost, forward:0.011376052319486591, backward:0.03007649564202266, data cost:0.6997935910317165 
2022-06-29 14:39:24,067: ============================================================
2022-06-29 14:39:24,068: Epoch 24/26 Batch 1500/7662 eta: 4:24:32.242728	Training Loss 2.2488 (2.2565)	Training Prec@1 99.609 (99.689)	Training Prec@5 100.000 (99.899)	
2022-06-29 14:39:24,068: ============================================================
2022-06-29 14:40:36,014: time cost, forward:0.011344667969083995, backward:0.030058723304180746, data cost:0.6984478328435253 
2022-06-29 14:40:36,014: ============================================================
2022-06-29 14:40:36,015: Epoch 24/26 Batch 1600/7662 eta: 4:16:27.331615	Training Loss 2.4078 (2.2585)	Training Prec@1 99.219 (99.690)	Training Prec@5 99.805 (99.899)	
2022-06-29 14:40:36,015: ============================================================
2022-06-29 14:41:48,603: time cost, forward:0.011324522704359642, backward:0.03006927569941116, data cost:0.6975974565116428 
2022-06-29 14:41:48,603: ============================================================
2022-06-29 14:41:48,603: Epoch 24/26 Batch 1700/7662 eta: 4:17:31.912731	Training Loss 2.2472 (2.2608)	Training Prec@1 99.805 (99.689)	Training Prec@5 100.000 (99.899)	
2022-06-29 14:41:48,603: ============================================================
2022-06-29 14:43:01,683: time cost, forward:0.011371063748752495, backward:0.030095417013163032, data cost:0.6970530473370894 
2022-06-29 14:43:01,683: ============================================================
2022-06-29 14:43:01,683: Epoch 24/26 Batch 1800/7662 eta: 4:18:03.449936	Training Loss 2.4567 (2.2629)	Training Prec@1 99.805 (99.688)	Training Prec@5 100.000 (99.899)	
2022-06-29 14:43:01,683: ============================================================
2022-06-29 14:44:15,135: time cost, forward:0.011422650571745782, backward:0.030209142575457322, data cost:0.6966428791867739 
2022-06-29 14:44:15,136: ============================================================
2022-06-29 14:44:15,136: Epoch 24/26 Batch 1900/7662 eta: 4:18:09.019344	Training Loss 2.1710 (2.2652)	Training Prec@1 99.609 (99.689)	Training Prec@5 99.805 (99.898)	
2022-06-29 14:44:15,136: ============================================================
2022-06-29 14:45:29,149: time cost, forward:0.011429145611662337, backward:0.030217789124703038, data cost:0.6966973707161884 
2022-06-29 14:45:29,149: ============================================================
2022-06-29 14:45:29,150: Epoch 24/26 Batch 2000/7662 eta: 4:18:53.211038	Training Loss 2.3288 (2.2685)	Training Prec@1 99.023 (99.684)	Training Prec@5 99.609 (99.897)	
2022-06-29 14:45:29,150: ============================================================
2022-06-29 14:46:41,408: time cost, forward:0.011405342360119867, backward:0.030044666524726246, data cost:0.6961180678772438 
2022-06-29 14:46:41,408: ============================================================
2022-06-29 14:46:41,408: Epoch 24/26 Batch 2100/7662 eta: 4:11:32.635107	Training Loss 2.1805 (2.2702)	Training Prec@1 99.219 (99.682)	Training Prec@5 100.000 (99.897)	
2022-06-29 14:46:41,408: ============================================================
2022-06-29 14:47:54,014: time cost, forward:0.011413187588166519, backward:0.029975667006322176, data cost:0.6956358778850769 
2022-06-29 14:47:54,014: ============================================================
2022-06-29 14:47:54,014: Epoch 24/26 Batch 2200/7662 eta: 4:11:32.654259	Training Loss 2.4808 (2.2721)	Training Prec@1 99.219 (99.679)	Training Prec@5 100.000 (99.897)	
2022-06-29 14:47:54,014: ============================================================
2022-06-29 14:49:08,197: time cost, forward:0.01142244475880308, backward:0.029898031528434735, data cost:0.6958974965399584 
2022-06-29 14:49:08,198: ============================================================
2022-06-29 14:49:08,198: Epoch 24/26 Batch 2300/7662 eta: 4:15:46.379768	Training Loss 2.4784 (2.2732)	Training Prec@1 99.219 (99.679)	Training Prec@5 99.805 (99.896)	
2022-06-29 14:49:08,198: ============================================================
2022-06-29 14:50:21,959: time cost, forward:0.011422403159863058, backward:0.029878933860044175, data cost:0.6959149434001012 
2022-06-29 14:50:21,959: ============================================================
2022-06-29 14:50:21,959: Epoch 24/26 Batch 2400/7662 eta: 4:13:05.262605	Training Loss 2.2040 (2.2751)	Training Prec@1 99.805 (99.678)	Training Prec@5 100.000 (99.896)	
2022-06-29 14:50:21,960: ============================================================
2022-06-29 14:51:35,313: time cost, forward:0.011418977514559291, backward:0.02984959633648992, data cost:0.6957893800907203 
2022-06-29 14:51:35,314: ============================================================
2022-06-29 14:51:35,314: Epoch 24/26 Batch 2500/7662 eta: 4:10:28.153082	Training Loss 2.4434 (2.2766)	Training Prec@1 99.609 (99.676)	Training Prec@5 100.000 (99.894)	
2022-06-29 14:51:35,314: ============================================================
2022-06-29 14:52:49,432: time cost, forward:0.011397791257405475, backward:0.02985186969467932, data cost:0.6959461663126165 
2022-06-29 14:52:49,432: ============================================================
2022-06-29 14:52:49,432: Epoch 24/26 Batch 2600/7662 eta: 4:11:50.481433	Training Loss 2.1590 (2.2783)	Training Prec@1 99.805 (99.675)	Training Prec@5 100.000 (99.894)	
2022-06-29 14:52:49,432: ============================================================
2022-06-29 14:54:04,191: time cost, forward:0.01140583148926618, backward:0.02989512189488448, data cost:0.6962682598385381 
2022-06-29 14:54:04,192: ============================================================
2022-06-29 14:54:04,192: Epoch 24/26 Batch 2700/7662 eta: 4:12:46.504172	Training Loss 2.3185 (2.2798)	Training Prec@1 99.609 (99.675)	Training Prec@5 100.000 (99.894)	
2022-06-29 14:54:04,192: ============================================================
2022-06-29 14:55:19,053: time cost, forward:0.011445026816790254, backward:0.02997782827488394, data cost:0.696522637919555 
2022-06-29 14:55:19,054: ============================================================
2022-06-29 14:55:19,054: Epoch 24/26 Batch 2800/7662 eta: 4:11:52.379039	Training Loss 2.3170 (2.2820)	Training Prec@1 100.000 (99.673)	Training Prec@5 100.000 (99.893)	
2022-06-29 14:55:19,054: ============================================================
2022-06-29 14:56:32,764: time cost, forward:0.011434516975821278, backward:0.029948360058882188, data cost:0.6965159919188737 
2022-06-29 14:56:32,765: ============================================================
2022-06-29 14:56:32,765: Epoch 24/26 Batch 2900/7662 eta: 4:06:46.397574	Training Loss 2.3036 (2.2838)	Training Prec@1 99.805 (99.672)	Training Prec@5 100.000 (99.892)	
2022-06-29 14:56:32,765: ============================================================
2022-06-29 14:57:46,489: time cost, forward:0.011432796845876522, backward:0.02997826528215297, data cost:0.6964501976052615 
2022-06-29 14:57:46,489: ============================================================
2022-06-29 14:57:46,489: Epoch 24/26 Batch 3000/7662 eta: 4:05:35.252377	Training Loss 2.2417 (2.2858)	Training Prec@1 100.000 (99.671)	Training Prec@5 100.000 (99.891)	
2022-06-29 14:57:46,490: ============================================================
2022-06-29 14:58:59,979: time cost, forward:0.011430923228650063, backward:0.03001508231161486, data cost:0.6963079299569784 
2022-06-29 14:58:59,980: ============================================================
2022-06-29 14:58:59,980: Epoch 24/26 Batch 3100/7662 eta: 4:03:35.064501	Training Loss 2.1444 (2.2871)	Training Prec@1 99.609 (99.669)	Training Prec@5 100.000 (99.890)	
2022-06-29 14:58:59,980: ============================================================
2022-06-29 15:00:14,254: time cost, forward:0.011433533185271407, backward:0.02999853357444446, data cost:0.6964616519877895 
2022-06-29 15:00:14,254: ============================================================
2022-06-29 15:00:14,255: Epoch 24/26 Batch 3200/7662 eta: 4:04:56.705861	Training Loss 2.5356 (2.2887)	Training Prec@1 99.414 (99.667)	Training Prec@5 99.805 (99.890)	
2022-06-29 15:00:14,255: ============================================================
2022-06-29 15:01:29,453: time cost, forward:0.011447538856883308, backward:0.030009573754053036, data cost:0.6968470993602807 
2022-06-29 15:01:29,453: ============================================================
2022-06-29 15:01:29,453: Epoch 24/26 Batch 3300/7662 eta: 4:06:44.367496	Training Loss 2.3796 (2.2903)	Training Prec@1 100.000 (99.665)	Training Prec@5 100.000 (99.890)	
2022-06-29 15:01:29,453: ============================================================
2022-06-29 15:02:43,467: time cost, forward:0.011443670022554277, backward:0.030000204758000186, data cost:0.696904233288295 
2022-06-29 15:02:43,468: ============================================================
2022-06-29 15:02:43,468: Epoch 24/26 Batch 3400/7662 eta: 4:01:37.247929	Training Loss 2.3142 (2.2914)	Training Prec@1 99.805 (99.664)	Training Prec@5 100.000 (99.889)	
2022-06-29 15:02:43,468: ============================================================
2022-06-29 15:03:57,500: time cost, forward:0.011459914913651737, backward:0.030056303860494564, data cost:0.6968758737880797 
2022-06-29 15:03:57,500: ============================================================
2022-06-29 15:03:57,500: Epoch 24/26 Batch 3500/7662 eta: 4:00:26.730006	Training Loss 2.2311 (2.2928)	Training Prec@1 99.805 (99.662)	Training Prec@5 100.000 (99.889)	
2022-06-29 15:03:57,501: ============================================================
2022-06-29 15:05:12,635: time cost, forward:0.011483048226774385, backward:0.03008187953284397, data cost:0.6971750220976859 
2022-06-29 15:05:12,635: ============================================================
2022-06-29 15:05:12,635: Epoch 24/26 Batch 3600/7662 eta: 4:02:46.373869	Training Loss 2.3168 (2.2949)	Training Prec@1 99.414 (99.661)	Training Prec@5 100.000 (99.888)	
2022-06-29 15:05:12,635: ============================================================
2022-06-29 15:06:27,649: time cost, forward:0.011489815311065781, backward:0.03014932035851975, data cost:0.6973951412684597 
2022-06-29 15:06:27,649: ============================================================
2022-06-29 15:06:27,649: Epoch 24/26 Batch 3700/7662 eta: 4:01:07.982679	Training Loss 2.2008 (2.2961)	Training Prec@1 99.609 (99.660)	Training Prec@5 99.609 (99.888)	
2022-06-29 15:06:27,650: ============================================================
2022-06-29 15:07:41,454: time cost, forward:0.011507495386596102, backward:0.030199388291654413, data cost:0.6972896546933425 
2022-06-29 15:07:41,454: ============================================================
2022-06-29 15:07:41,455: Epoch 24/26 Batch 3800/7662 eta: 3:56:01.018565	Training Loss 2.2481 (2.2975)	Training Prec@1 99.609 (99.659)	Training Prec@5 100.000 (99.888)	
2022-06-29 15:07:41,455: ============================================================
2022-06-29 15:08:57,356: time cost, forward:0.01152752961645251, backward:0.03022834862706355, data cost:0.6977428477004296 
2022-06-29 15:08:57,356: ============================================================
2022-06-29 15:08:57,357: Epoch 24/26 Batch 3900/7662 eta: 4:01:27.392250	Training Loss 2.3043 (2.2990)	Training Prec@1 100.000 (99.657)	Training Prec@5 100.000 (99.887)	
2022-06-29 15:08:57,357: ============================================================
2022-06-29 15:10:12,323: time cost, forward:0.0115477648875987, backward:0.03026104158209276, data cost:0.697936497380895 
2022-06-29 15:10:12,324: ============================================================
2022-06-29 15:10:12,324: Epoch 24/26 Batch 4000/7662 eta: 3:57:14.079355	Training Loss 2.4211 (2.3007)	Training Prec@1 99.023 (99.657)	Training Prec@5 99.805 (99.887)	
2022-06-29 15:10:12,324: ============================================================
2022-06-29 15:11:29,399: time cost, forward:0.011560352874052295, backward:0.030238412129759758, data cost:0.6986921283785208 
2022-06-29 15:11:29,400: ============================================================
2022-06-29 15:11:29,400: Epoch 24/26 Batch 4100/7662 eta: 4:02:37.276120	Training Loss 2.4689 (2.3022)	Training Prec@1 99.609 (99.655)	Training Prec@5 100.000 (99.886)	
2022-06-29 15:11:29,400: ============================================================
2022-06-29 15:12:44,617: time cost, forward:0.011580294159146314, backward:0.030241710454346198, data cost:0.6989283474265578 
2022-06-29 15:12:44,617: ============================================================
2022-06-29 15:12:44,618: Epoch 24/26 Batch 4200/7662 eta: 3:55:31.198168	Training Loss 2.5338 (2.3036)	Training Prec@1 100.000 (99.655)	Training Prec@5 100.000 (99.886)	
2022-06-29 15:12:44,618: ============================================================
2022-06-29 15:13:59,313: time cost, forward:0.011575925735629806, backward:0.030253958330511574, data cost:0.6990523551835324 
2022-06-29 15:13:59,313: ============================================================
2022-06-29 15:13:59,314: Epoch 24/26 Batch 4300/7662 eta: 3:52:38.419173	Training Loss 2.3643 (2.3050)	Training Prec@1 99.609 (99.655)	Training Prec@5 100.000 (99.886)	
2022-06-29 15:13:59,314: ============================================================
2022-06-29 15:15:13,573: time cost, forward:0.011589716119803091, backward:0.030254479889762376, data cost:0.6990685929057543 
2022-06-29 15:15:13,573: ============================================================
2022-06-29 15:15:13,573: Epoch 24/26 Batch 4400/7662 eta: 3:50:02.622443	Training Loss 2.4837 (2.3067)	Training Prec@1 99.023 (99.652)	Training Prec@5 99.805 (99.885)	
2022-06-29 15:15:13,573: ============================================================
2022-06-29 15:16:27,791: time cost, forward:0.011596461088558281, backward:0.030304903877022584, data cost:0.699029479458163 
2022-06-29 15:16:27,791: ============================================================
2022-06-29 15:16:27,792: Epoch 24/26 Batch 4500/7662 eta: 3:48:40.760324	Training Loss 2.5324 (2.3081)	Training Prec@1 99.023 (99.651)	Training Prec@5 99.805 (99.885)	
2022-06-29 15:16:27,792: ============================================================
2022-06-29 15:17:41,910: time cost, forward:0.011600930319062574, backward:0.030319502520079093, data cost:0.6990074538023323 
2022-06-29 15:17:41,910: ============================================================
2022-06-29 15:17:41,911: Epoch 24/26 Batch 4600/7662 eta: 3:47:08.277444	Training Loss 2.2816 (2.3095)	Training Prec@1 99.805 (99.650)	Training Prec@5 100.000 (99.884)	
2022-06-29 15:17:41,911: ============================================================
2022-06-29 15:18:56,675: time cost, forward:0.011595504338194852, backward:0.030336379091596064, data cost:0.6991281057829856 
2022-06-29 15:18:56,676: ============================================================
2022-06-29 15:18:56,676: Epoch 24/26 Batch 4700/7662 eta: 3:47:52.330548	Training Loss 2.5278 (2.3108)	Training Prec@1 99.414 (99.649)	Training Prec@5 99.805 (99.884)	
2022-06-29 15:18:56,676: ============================================================
2022-06-29 15:20:11,426: time cost, forward:0.011611370027847751, backward:0.030396823859209814, data cost:0.6991788213216754 
2022-06-29 15:20:11,426: ============================================================
2022-06-29 15:20:11,427: Epoch 24/26 Batch 4800/7662 eta: 3:46:34.911066	Training Loss 2.5614 (2.3121)	Training Prec@1 100.000 (99.647)	Training Prec@5 100.000 (99.884)	
2022-06-29 15:20:11,427: ============================================================
2022-06-29 15:21:27,743: time cost, forward:0.011631144774546548, backward:0.030407952639394255, data cost:0.6995851543879699 
2022-06-29 15:21:27,743: ============================================================
2022-06-29 15:21:27,743: Epoch 24/26 Batch 4900/7662 eta: 3:50:03.389624	Training Loss 2.3107 (2.3139)	Training Prec@1 99.609 (99.645)	Training Prec@5 99.805 (99.883)	
2022-06-29 15:21:27,743: ============================================================
2022-06-29 15:22:41,392: time cost, forward:0.011634057081802103, backward:0.030404877295420633, data cost:0.6994754868427452 
2022-06-29 15:22:41,393: ============================================================
2022-06-29 15:22:41,393: Epoch 24/26 Batch 5000/7662 eta: 3:40:47.348754	Training Loss 2.5365 (2.3156)	Training Prec@1 99.219 (99.645)	Training Prec@5 99.609 (99.883)	
2022-06-29 15:22:41,393: ============================================================
2022-06-29 15:23:56,583: time cost, forward:0.011629106437816271, backward:0.030391348602959257, data cost:0.6996876596820006 
2022-06-29 15:23:56,583: ============================================================
2022-06-29 15:23:56,583: Epoch 24/26 Batch 5100/7662 eta: 3:44:09.312883	Training Loss 2.3462 (2.3170)	Training Prec@1 100.000 (99.644)	Training Prec@5 100.000 (99.883)	
2022-06-29 15:23:56,583: ============================================================
2022-06-29 15:25:11,072: time cost, forward:0.01163669851427469, backward:0.030419233281421165, data cost:0.6997043545784045 
2022-06-29 15:25:11,073: ============================================================
2022-06-29 15:25:11,073: Epoch 24/26 Batch 5200/7662 eta: 3:40:49.477567	Training Loss 2.2630 (2.3182)	Training Prec@1 99.609 (99.643)	Training Prec@5 100.000 (99.883)	
2022-06-29 15:25:11,073: ============================================================
2022-06-29 15:26:25,388: time cost, forward:0.011634976172316725, backward:0.030399856533188035, data cost:0.6997422769308586 
2022-06-29 15:26:25,389: ============================================================
2022-06-29 15:26:25,389: Epoch 24/26 Batch 5300/7662 eta: 3:39:04.278550	Training Loss 2.4385 (2.3196)	Training Prec@1 99.414 (99.641)	Training Prec@5 99.805 (99.882)	
2022-06-29 15:26:25,389: ============================================================
2022-06-29 15:27:41,096: time cost, forward:0.011631849761979849, backward:0.030342642787121517, data cost:0.7000797234722631 
2022-06-29 15:27:41,096: ============================================================
2022-06-29 15:27:41,097: Epoch 24/26 Batch 5400/7662 eta: 3:41:54.679321	Training Loss 2.4070 (2.3211)	Training Prec@1 99.805 (99.641)	Training Prec@5 99.805 (99.881)	
2022-06-29 15:27:41,097: ============================================================
2022-06-29 15:28:55,330: time cost, forward:0.01164184823689146, backward:0.030338624061768998, data cost:0.7000698417202953 
2022-06-29 15:28:55,330: ============================================================
2022-06-29 15:28:55,330: Epoch 24/26 Batch 5500/7662 eta: 3:36:21.223194	Training Loss 2.3227 (2.3225)	Training Prec@1 100.000 (99.641)	Training Prec@5 100.000 (99.882)	
2022-06-29 15:28:55,330: ============================================================
2022-06-29 15:30:09,824: time cost, forward:0.011645048127512481, backward:0.030341712379694026, data cost:0.7001062674402317 
2022-06-29 15:30:09,824: ============================================================
2022-06-29 15:30:09,824: Epoch 24/26 Batch 5600/7662 eta: 3:35:52.278115	Training Loss 2.4355 (2.3236)	Training Prec@1 99.805 (99.639)	Training Prec@5 100.000 (99.881)	
2022-06-29 15:30:09,824: ============================================================
2022-06-29 15:31:22,122: time cost, forward:0.011634551928657925, backward:0.030337677982569283, data cost:0.6997783987704945 
2022-06-29 15:31:22,122: ============================================================
2022-06-29 15:31:22,122: Epoch 24/26 Batch 5700/7662 eta: 3:28:18.166158	Training Loss 2.5244 (2.3251)	Training Prec@1 98.633 (99.638)	Training Prec@5 99.219 (99.880)	
2022-06-29 15:31:22,122: ============================================================
2022-06-29 15:32:36,498: time cost, forward:0.011637369462756746, backward:0.03035576945030395, data cost:0.6997843182154783 
2022-06-29 15:32:36,498: ============================================================
2022-06-29 15:32:36,498: Epoch 24/26 Batch 5800/7662 eta: 3:33:02.978194	Training Loss 2.3763 (2.3261)	Training Prec@1 100.000 (99.637)	Training Prec@5 100.000 (99.880)	
2022-06-29 15:32:36,498: ============================================================
2022-06-29 15:33:52,421: time cost, forward:0.011636241530337401, backward:0.030364609872068182, data cost:0.7000668078362892 
2022-06-29 15:33:52,422: ============================================================
2022-06-29 15:33:52,422: Epoch 24/26 Batch 5900/7662 eta: 3:36:13.074121	Training Loss 2.6031 (2.3275)	Training Prec@1 99.414 (99.636)	Training Prec@5 99.805 (99.880)	
2022-06-29 15:33:52,422: ============================================================
2022-06-29 15:35:07,307: time cost, forward:0.011637377528314452, backward:0.030364435977748204, data cost:0.7001700874248491 
2022-06-29 15:35:07,308: ============================================================
2022-06-29 15:35:07,308: Epoch 24/26 Batch 6000/7662 eta: 3:32:00.899629	Training Loss 2.4476 (2.3288)	Training Prec@1 100.000 (99.635)	Training Prec@5 100.000 (99.880)	
2022-06-29 15:35:07,308: ============================================================
2022-06-29 15:36:21,711: time cost, forward:0.011641740838041616, backward:0.030369148232503335, data cost:0.70018425912696 
2022-06-29 15:36:21,712: ============================================================
2022-06-29 15:36:21,712: Epoch 24/26 Batch 6100/7662 eta: 3:29:24.641011	Training Loss 2.4564 (2.3297)	Training Prec@1 99.609 (99.635)	Training Prec@5 100.000 (99.879)	
2022-06-29 15:36:21,712: ============================================================
2022-06-29 15:37:37,189: time cost, forward:0.011638373977850667, backward:0.030365602607437824, data cost:0.7003895070287831 
2022-06-29 15:37:37,189: ============================================================
2022-06-29 15:37:37,189: Epoch 24/26 Batch 6200/7662 eta: 3:31:10.375900	Training Loss 2.3416 (2.3312)	Training Prec@1 99.805 (99.634)	Training Prec@5 100.000 (99.879)	
2022-06-29 15:37:37,189: ============================================================
2022-06-29 15:38:51,701: time cost, forward:0.011635369053907404, backward:0.030355532711735793, data cost:0.7004388574002792 
2022-06-29 15:38:51,702: ============================================================
2022-06-29 15:38:51,702: Epoch 24/26 Batch 6300/7662 eta: 3:27:13.886640	Training Loss 2.4131 (2.3322)	Training Prec@1 99.414 (99.633)	Training Prec@5 99.805 (99.879)	
2022-06-29 15:38:51,702: ============================================================
2022-06-29 15:40:05,034: time cost, forward:0.011640609586810782, backward:0.030397901089419834, data cost:0.7002404297603483 
2022-06-29 15:40:05,034: ============================================================
2022-06-29 15:40:05,035: Epoch 24/26 Batch 6400/7662 eta: 3:22:43.718284	Training Loss 2.3919 (2.3335)	Training Prec@1 99.609 (99.632)	Training Prec@5 99.805 (99.878)	
2022-06-29 15:40:05,035: ============================================================
2022-06-29 15:41:19,825: time cost, forward:0.011636501203080034, backward:0.030420482663085488, data cost:0.7003033296899404 
2022-06-29 15:41:19,826: ============================================================
2022-06-29 15:41:19,826: Epoch 24/26 Batch 6500/7662 eta: 3:25:30.843370	Training Loss 2.5182 (2.3345)	Training Prec@1 100.000 (99.631)	Training Prec@5 100.000 (99.878)	
2022-06-29 15:41:19,826: ============================================================
2022-06-29 15:42:34,575: time cost, forward:0.01162912701454862, backward:0.030414447366766795, data cost:0.7003857709725962 
2022-06-29 15:42:34,576: ============================================================
2022-06-29 15:42:34,576: Epoch 24/26 Batch 6600/7662 eta: 3:24:09.286485	Training Loss 2.3022 (2.3359)	Training Prec@1 99.609 (99.629)	Training Prec@5 99.805 (99.877)	
2022-06-29 15:42:34,576: ============================================================
2022-06-29 15:43:49,507: time cost, forward:0.011627013300012912, backward:0.030421462374349943, data cost:0.7004775728711727 
2022-06-29 15:43:49,508: ============================================================
2022-06-29 15:43:49,508: Epoch 24/26 Batch 6700/7662 eta: 3:23:24.180924	Training Loss 2.4852 (2.3372)	Training Prec@1 99.609 (99.628)	Training Prec@5 99.805 (99.877)	
2022-06-29 15:43:49,508: ============================================================
2022-06-29 15:45:03,200: time cost, forward:0.011625966388945334, backward:0.030429444430172137, data cost:0.7003815897529064 
2022-06-29 15:45:03,200: ============================================================
2022-06-29 15:45:03,201: Epoch 24/26 Batch 6800/7662 eta: 3:18:48.601945	Training Loss 2.3114 (2.3386)	Training Prec@1 100.000 (99.627)	Training Prec@5 100.000 (99.876)	
2022-06-29 15:45:03,201: ============================================================
2022-06-29 15:46:18,271: time cost, forward:0.011627298383578682, backward:0.030426547533879335, data cost:0.7004961410386439 
2022-06-29 15:46:18,272: ============================================================
2022-06-29 15:46:18,272: Epoch 24/26 Batch 6900/7662 eta: 3:21:16.798816	Training Loss 2.3103 (2.3398)	Training Prec@1 99.609 (99.625)	Training Prec@5 100.000 (99.876)	
2022-06-29 15:46:18,273: ============================================================
2022-06-29 15:47:32,808: time cost, forward:0.011626191642696916, backward:0.030415986704645813, data cost:0.7005426930706745 
2022-06-29 15:47:32,809: ============================================================
2022-06-29 15:47:32,809: Epoch 24/26 Batch 7000/7662 eta: 3:18:36.199497	Training Loss 2.3694 (2.3407)	Training Prec@1 99.805 (99.624)	Training Prec@5 100.000 (99.875)	
2022-06-29 15:47:32,809: ============================================================
2022-06-29 15:48:47,609: time cost, forward:0.011622859484915298, backward:0.030391945874528124, data cost:0.700639117820311 
2022-06-29 15:48:47,609: ============================================================
2022-06-29 15:48:47,609: Epoch 24/26 Batch 7100/7662 eta: 3:18:03.506901	Training Loss 2.3882 (2.3417)	Training Prec@1 99.805 (99.623)	Training Prec@5 100.000 (99.875)	
2022-06-29 15:48:47,609: ============================================================
2022-06-29 15:50:02,444: time cost, forward:0.011620649911907253, backward:0.030389078790437084, data cost:0.7007141334180254 
2022-06-29 15:50:02,444: ============================================================
2022-06-29 15:50:02,444: Epoch 24/26 Batch 7200/7662 eta: 3:16:54.171157	Training Loss 2.2048 (2.3428)	Training Prec@1 99.609 (99.623)	Training Prec@5 100.000 (99.874)	
2022-06-29 15:50:02,444: ============================================================
2022-06-29 15:51:16,489: time cost, forward:0.011625646058623637, backward:0.030400405013082714, data cost:0.7006581747494327 
2022-06-29 15:51:16,489: ============================================================
2022-06-29 15:51:16,490: Epoch 24/26 Batch 7300/7662 eta: 3:13:35.504987	Training Loss 2.4426 (2.3438)	Training Prec@1 99.219 (99.622)	Training Prec@5 99.805 (99.874)	
2022-06-29 15:51:16,490: ============================================================
2022-06-29 15:52:31,561: time cost, forward:0.01161936180448835, backward:0.030366257568165522, data cost:0.7008010750445889 
2022-06-29 15:52:31,562: ============================================================
2022-06-29 15:52:31,562: Epoch 24/26 Batch 7400/7662 eta: 3:15:01.500962	Training Loss 2.4932 (2.3450)	Training Prec@1 98.633 (99.620)	Training Prec@5 99.609 (99.874)	
2022-06-29 15:52:31,562: ============================================================
2022-06-29 15:53:45,020: time cost, forward:0.011612084153843396, backward:0.030367528936007384, data cost:0.700692480668209 
2022-06-29 15:53:45,020: ============================================================
2022-06-29 15:53:45,020: Epoch 24/26 Batch 7500/7662 eta: 3:09:36.542324	Training Loss 2.5643 (2.3461)	Training Prec@1 99.414 (99.619)	Training Prec@5 99.805 (99.873)	
2022-06-29 15:53:45,021: ============================================================
2022-06-29 15:55:00,461: time cost, forward:0.011616177395121456, backward:0.03036811487002347, data cost:0.7008370095953406 
2022-06-29 15:55:00,461: ============================================================
2022-06-29 15:55:00,461: Epoch 24/26 Batch 7600/7662 eta: 3:13:28.100651	Training Loss 2.3079 (2.3470)	Training Prec@1 99.414 (99.618)	Training Prec@5 99.805 (99.873)	
2022-06-29 15:55:00,462: ============================================================
2022-06-29 15:55:48,646: Epoch: 24/26 eta: 3:12:40.572846	Training Loss 2.3667 (2.3476)	Training Prec@1 99.609 (99.617)	Training Prec@5 99.805 (99.873)
2022-06-29 15:55:48,646: ============================================================
2022-06-29 15:57:16,088: time cost, forward:0.011129952440358172, backward:0.02960059137055368, data cost:0.8358457738702948 
2022-06-29 15:57:16,088: ============================================================
2022-06-29 15:57:16,088: Epoch 25/26 Batch 100/7662 eta: 3:41:30.314527	Training Loss 2.2282 (2.2369)	Training Prec@1 99.805 (99.682)	Training Prec@5 100.000 (99.895)	
2022-06-29 15:57:16,088: ============================================================
2022-06-29 15:58:29,298: time cost, forward:0.01099249825405715, backward:0.02903964172056572, data cost:0.7636937208511122 
2022-06-29 15:58:29,299: ============================================================
2022-06-29 15:58:29,299: Epoch 25/26 Batch 200/7662 eta: 3:04:33.106444	Training Loss 2.2445 (2.2316)	Training Prec@1 99.609 (99.695)	Training Prec@5 100.000 (99.901)	
2022-06-29 15:58:29,299: ============================================================
2022-06-29 15:59:42,068: time cost, forward:0.011127784499356579, backward:0.028709151673077738, data cost:0.7383517038862043 
2022-06-29 15:59:42,069: ============================================================
2022-06-29 15:59:42,069: Epoch 25/26 Batch 300/7662 eta: 3:02:13.703351	Training Loss 2.3154 (2.2237)	Training Prec@1 99.609 (99.686)	Training Prec@5 99.805 (99.903)	
2022-06-29 15:59:42,069: ============================================================
2022-06-29 16:00:53,768: time cost, forward:0.011278074188041208, backward:0.029351630605253063, data cost:0.7221042452599471 
2022-06-29 16:00:53,769: ============================================================
2022-06-29 16:00:53,769: Epoch 25/26 Batch 400/7662 eta: 2:58:21.241554	Training Loss 2.4051 (2.2251)	Training Prec@1 99.609 (99.699)	Training Prec@5 99.805 (99.909)	
2022-06-29 16:00:53,769: ============================================================
2022-06-29 16:02:06,309: time cost, forward:0.01132159051532019, backward:0.02954367884175333, data cost:0.714272511507084 
2022-06-29 16:02:06,309: ============================================================
2022-06-29 16:02:06,309: Epoch 25/26 Batch 500/7662 eta: 2:59:14.063195	Training Loss 2.1296 (2.2277)	Training Prec@1 99.414 (99.703)	Training Prec@5 99.805 (99.912)	
2022-06-29 16:02:06,309: ============================================================
2022-06-29 16:03:20,629: time cost, forward:0.011480209226401302, backward:0.029777774428684445, data cost:0.711812964265852 
2022-06-29 16:03:20,629: ============================================================
2022-06-29 16:03:20,629: Epoch 25/26 Batch 600/7662 eta: 3:02:23.640423	Training Loss 2.3397 (2.2271)	Training Prec@1 99.609 (99.703)	Training Prec@5 99.805 (99.911)	
2022-06-29 16:03:20,629: ============================================================
2022-06-29 16:04:33,583: time cost, forward:0.011455583640604743, backward:0.029785384094936824, data cost:0.7083995748146068 
2022-06-29 16:04:33,583: ============================================================
2022-06-29 16:04:33,584: Epoch 25/26 Batch 700/7662 eta: 2:57:49.561971	Training Loss 2.5205 (2.2303)	Training Prec@1 99.609 (99.707)	Training Prec@5 99.805 (99.910)	
2022-06-29 16:04:33,584: ============================================================
2022-06-29 16:05:47,100: time cost, forward:0.011442811975491062, backward:0.029848233928370087, data cost:0.7064883410557639 
2022-06-29 16:05:47,100: ============================================================
2022-06-29 16:05:47,101: Epoch 25/26 Batch 800/7662 eta: 2:57:58.353421	Training Loss 1.9898 (2.2338)	Training Prec@1 99.805 (99.701)	Training Prec@5 100.000 (99.906)	
2022-06-29 16:05:47,101: ============================================================
2022-06-29 16:07:00,100: time cost, forward:0.011379054178783175, backward:0.0299481069948835, data cost:0.7044135659634736 
2022-06-29 16:07:00,101: ============================================================
2022-06-29 16:07:00,101: Epoch 25/26 Batch 900/7662 eta: 2:55:30.270532	Training Loss 2.5047 (2.2350)	Training Prec@1 99.805 (99.701)	Training Prec@5 99.805 (99.909)	
2022-06-29 16:07:00,101: ============================================================
2022-06-29 16:08:13,206: time cost, forward:0.011354220880044473, backward:0.030012653396652267, data cost:0.7028625853904136 
2022-06-29 16:08:13,206: ============================================================
2022-06-29 16:08:13,206: Epoch 25/26 Batch 1000/7662 eta: 2:54:32.358672	Training Loss 2.2419 (2.2378)	Training Prec@1 99.414 (99.697)	Training Prec@5 99.805 (99.909)	
2022-06-29 16:08:13,206: ============================================================
2022-06-29 16:09:26,013: time cost, forward:0.011344855649564568, backward:0.0300483046280893, data cost:0.7013233564895754 
2022-06-29 16:09:26,014: ============================================================
2022-06-29 16:09:26,014: Epoch 25/26 Batch 1100/7662 eta: 2:52:36.897891	Training Loss 2.1111 (2.2384)	Training Prec@1 99.609 (99.699)	Training Prec@5 99.805 (99.908)	
2022-06-29 16:09:26,014: ============================================================
2022-06-29 16:10:39,597: time cost, forward:0.011366353420737985, backward:0.030115614343027557, data cost:0.7006204995242032 
2022-06-29 16:10:39,598: ============================================================
2022-06-29 16:10:39,598: Epoch 25/26 Batch 1200/7662 eta: 2:53:13.735335	Training Loss 2.1865 (2.2406)	Training Prec@1 99.805 (99.696)	Training Prec@5 99.805 (99.905)	
2022-06-29 16:10:39,598: ============================================================
2022-06-29 16:11:52,865: time cost, forward:0.01139059242970949, backward:0.030112736403162064, data cost:0.6998402196870941 
2022-06-29 16:11:52,866: ============================================================
2022-06-29 16:11:52,866: Epoch 25/26 Batch 1300/7662 eta: 2:51:15.829093	Training Loss 2.3399 (2.2418)	Training Prec@1 99.414 (99.699)	Training Prec@5 100.000 (99.906)	
2022-06-29 16:11:52,866: ============================================================
2022-06-29 16:13:05,513: time cost, forward:0.011386572931220142, backward:0.030136606708605688, data cost:0.6987199466342667 
2022-06-29 16:13:05,513: ============================================================
2022-06-29 16:13:05,514: Epoch 25/26 Batch 1400/7662 eta: 2:48:36.204784	Training Loss 2.2876 (2.2435)	Training Prec@1 99.609 (99.698)	Training Prec@5 100.000 (99.905)	
2022-06-29 16:13:05,514: ============================================================
2022-06-29 16:14:17,939: time cost, forward:0.0113488985269049, backward:0.029820708770446572, data cost:0.69797926159045 
2022-06-29 16:14:17,940: ============================================================
2022-06-29 16:14:17,940: Epoch 25/26 Batch 1500/7662 eta: 2:46:52.910799	Training Loss 2.0182 (2.2444)	Training Prec@1 100.000 (99.700)	Training Prec@5 100.000 (99.906)	
2022-06-29 16:14:17,940: ============================================================
2022-06-29 16:15:30,262: time cost, forward:0.011343071205754665, backward:0.02983770227342788, data cost:0.6969384483578356 
2022-06-29 16:15:30,262: ============================================================
2022-06-29 16:15:30,262: Epoch 25/26 Batch 1600/7662 eta: 2:45:26.240479	Training Loss 2.3021 (2.2465)	Training Prec@1 99.805 (99.700)	Training Prec@5 100.000 (99.905)	
2022-06-29 16:15:30,262: ============================================================
2022-06-29 16:16:45,321: time cost, forward:0.011351712385719843, backward:0.029909071745487997, data cost:0.6975683746371569 
2022-06-29 16:16:45,321: ============================================================
2022-06-29 16:16:45,322: Epoch 25/26 Batch 1700/7662 eta: 2:50:26.854761	Training Loss 2.2961 (2.2489)	Training Prec@1 99.414 (99.698)	Training Prec@5 99.609 (99.905)	
2022-06-29 16:16:45,322: ============================================================
2022-06-29 16:17:58,836: time cost, forward:0.011369154279665393, backward:0.02998489323690774, data cost:0.6972498250975087 
2022-06-29 16:17:58,836: ============================================================
2022-06-29 16:17:58,837: Epoch 25/26 Batch 1800/7662 eta: 2:45:42.901604	Training Loss 2.2630 (2.2502)	Training Prec@1 99.805 (99.696)	Training Prec@5 100.000 (99.904)	
2022-06-29 16:17:58,837: ============================================================
2022-06-29 16:19:11,197: time cost, forward:0.011363641785093833, backward:0.030083958508781285, data cost:0.6963440375054366 
2022-06-29 16:19:11,197: ============================================================
2022-06-29 16:19:11,197: Epoch 25/26 Batch 1900/7662 eta: 2:41:54.429274	Training Loss 2.3190 (2.2531)	Training Prec@1 99.609 (99.694)	Training Prec@5 100.000 (99.902)	
2022-06-29 16:19:11,197: ============================================================
2022-06-29 16:20:24,830: time cost, forward:0.0113407928625186, backward:0.030140965148292224, data cost:0.6962106082366668 
2022-06-29 16:20:24,830: ============================================================
2022-06-29 16:20:24,830: Epoch 25/26 Batch 2000/7662 eta: 2:43:31.592471	Training Loss 2.3150 (2.2555)	Training Prec@1 99.609 (99.691)	Training Prec@5 99.805 (99.901)	
2022-06-29 16:20:24,830: ============================================================
2022-06-29 16:21:38,746: time cost, forward:0.011308074735811404, backward:0.030103183462825374, data cost:0.6963272148112333 
2022-06-29 16:21:38,746: ============================================================
2022-06-29 16:21:38,746: Epoch 25/26 Batch 2100/7662 eta: 2:42:55.372288	Training Loss 2.4180 (2.2571)	Training Prec@1 99.609 (99.689)	Training Prec@5 99.805 (99.900)	
2022-06-29 16:21:38,746: ============================================================
2022-06-29 16:22:51,226: time cost, forward:0.011332579773629238, backward:0.030098924641177676, data cost:0.6956954862161786 
2022-06-29 16:22:51,227: ============================================================
2022-06-29 16:22:51,227: Epoch 25/26 Batch 2200/7662 eta: 2:38:33.069409	Training Loss 2.2616 (2.2583)	Training Prec@1 99.609 (99.688)	Training Prec@5 99.805 (99.899)	
2022-06-29 16:22:51,227: ============================================================
2022-06-29 16:24:05,348: time cost, forward:0.01135042990327348, backward:0.030063524926522856, data cost:0.6958745131548616 
2022-06-29 16:24:05,348: ============================================================
2022-06-29 16:24:05,349: Epoch 25/26 Batch 2300/7662 eta: 2:40:54.361959	Training Loss 2.5619 (2.2600)	Training Prec@1 99.609 (99.688)	Training Prec@5 99.805 (99.899)	
2022-06-29 16:24:05,349: ============================================================
2022-06-29 16:25:18,199: time cost, forward:0.011370606003030234, backward:0.030084429109230693, data cost:0.6954503906125971 
2022-06-29 16:25:18,199: ============================================================
2022-06-29 16:25:18,199: Epoch 25/26 Batch 2400/7662 eta: 2:36:55.974595	Training Loss 2.2034 (2.2620)	Training Prec@1 99.414 (99.687)	Training Prec@5 99.414 (99.898)	
2022-06-29 16:25:18,199: ============================================================
2022-06-29 16:26:33,226: time cost, forward:0.011385705004505465, backward:0.030108433048359726, data cost:0.6959298768488108 
2022-06-29 16:26:33,227: ============================================================
2022-06-29 16:26:33,227: Epoch 25/26 Batch 2500/7662 eta: 2:40:22.302855	Training Loss 2.2042 (2.2627)	Training Prec@1 99.805 (99.686)	Training Prec@5 100.000 (99.897)	
2022-06-29 16:26:33,227: ============================================================
2022-06-29 16:27:45,048: time cost, forward:0.01137748155377378, backward:0.030142807969683726, data cost:0.6951420751155547 
2022-06-29 16:27:45,048: ============================================================
2022-06-29 16:27:45,048: Epoch 25/26 Batch 2600/7662 eta: 2:32:19.258335	Training Loss 2.3993 (2.2659)	Training Prec@1 99.414 (99.684)	Training Prec@5 99.805 (99.897)	
2022-06-29 16:27:45,048: ============================================================
2022-06-29 16:29:00,013: time cost, forward:0.011362966408151836, backward:0.030151038401300883, data cost:0.6956083443307046 
2022-06-29 16:29:00,013: ============================================================
2022-06-29 16:29:00,014: Epoch 25/26 Batch 2700/7662 eta: 2:37:44.353814	Training Loss 2.4169 (2.2672)	Training Prec@1 99.414 (99.682)	Training Prec@5 99.805 (99.897)	
2022-06-29 16:29:00,014: ============================================================
2022-06-29 16:30:13,369: time cost, forward:0.011375824695572167, backward:0.03017524635421246, data cost:0.6954352751762878 
2022-06-29 16:30:13,369: ============================================================
2022-06-29 16:30:13,369: Epoch 25/26 Batch 2800/7662 eta: 2:33:07.801158	Training Loss 2.2017 (2.2697)	Training Prec@1 100.000 (99.682)	Training Prec@5 100.000 (99.897)	
2022-06-29 16:30:13,369: ============================================================
2022-06-29 16:31:27,057: time cost, forward:0.01136549845692535, backward:0.03015374125756655, data cost:0.6954416627512179 
2022-06-29 16:31:27,057: ============================================================
2022-06-29 16:31:27,057: Epoch 25/26 Batch 2900/7662 eta: 2:32:35.715155	Training Loss 2.1707 (2.2708)	Training Prec@1 99.805 (99.681)	Training Prec@5 99.805 (99.896)	
2022-06-29 16:31:27,057: ============================================================
2022-06-29 16:32:40,725: time cost, forward:0.011364430656191428, backward:0.030131212430383494, data cost:0.6954381388002493 
2022-06-29 16:32:40,726: ============================================================
2022-06-29 16:32:40,726: Epoch 25/26 Batch 3000/7662 eta: 2:31:19.684904	Training Loss 2.3333 (2.2720)	Training Prec@1 99.805 (99.681)	Training Prec@5 100.000 (99.896)	
2022-06-29 16:32:40,726: ============================================================
2022-06-29 16:33:53,538: time cost, forward:0.011352487516695547, backward:0.030134640497021154, data cost:0.6951492715935893 
2022-06-29 16:33:53,538: ============================================================
2022-06-29 16:33:53,538: Epoch 25/26 Batch 3100/7662 eta: 2:28:21.285687	Training Loss 2.3873 (2.2735)	Training Prec@1 99.609 (99.680)	Training Prec@5 99.805 (99.896)	
2022-06-29 16:33:53,538: ============================================================
2022-06-29 16:35:07,245: time cost, forward:0.011344025529299202, backward:0.030135039651196387, data cost:0.6951573659718577 
2022-06-29 16:35:07,245: ============================================================
2022-06-29 16:35:07,246: Epoch 25/26 Batch 3200/7662 eta: 2:28:57.030123	Training Loss 2.1903 (2.2753)	Training Prec@1 99.805 (99.677)	Training Prec@5 99.805 (99.895)	
2022-06-29 16:35:07,246: ============================================================
2022-06-29 16:36:19,512: time cost, forward:0.011326946392677957, backward:0.03013502760127155, data cost:0.6947376960044415 
2022-06-29 16:36:19,513: ============================================================
2022-06-29 16:36:19,513: Epoch 25/26 Batch 3300/7662 eta: 2:24:50.161275	Training Loss 2.3075 (2.2772)	Training Prec@1 99.609 (99.675)	Training Prec@5 100.000 (99.895)	
2022-06-29 16:36:19,513: ============================================================
2022-06-29 16:37:32,023: time cost, forward:0.011318170663082239, backward:0.03013470994265299, data cost:0.6944075666058936 
2022-06-29 16:37:32,023: ============================================================
2022-06-29 16:37:32,024: Epoch 25/26 Batch 3400/7662 eta: 2:24:06.872627	Training Loss 2.4902 (2.2787)	Training Prec@1 99.609 (99.673)	Training Prec@5 99.805 (99.894)	
2022-06-29 16:37:32,024: ============================================================
2022-06-29 16:38:46,276: time cost, forward:0.011350479354923813, backward:0.030195710726484772, data cost:0.6944912103422372 
2022-06-29 16:38:46,276: ============================================================
2022-06-29 16:38:46,277: Epoch 25/26 Batch 3500/7662 eta: 2:26:20.417281	Training Loss 2.1678 (2.2807)	Training Prec@1 99.609 (99.673)	Training Prec@5 100.000 (99.893)	
2022-06-29 16:38:46,277: ============================================================
2022-06-29 16:39:59,167: time cost, forward:0.011354898538613326, backward:0.030210278835121743, data cost:0.6942622645691587 
2022-06-29 16:39:59,167: ============================================================
2022-06-29 16:39:59,168: Epoch 25/26 Batch 3600/7662 eta: 2:22:26.464331	Training Loss 2.3169 (2.2822)	Training Prec@1 100.000 (99.672)	Training Prec@5 100.000 (99.893)	
2022-06-29 16:39:59,168: ============================================================
2022-06-29 16:41:12,075: time cost, forward:0.01137075871511162, backward:0.03020153654108308, data cost:0.6940592961493103 
2022-06-29 16:41:12,075: ============================================================
2022-06-29 16:41:12,075: Epoch 25/26 Batch 3700/7662 eta: 2:21:15.518331	Training Loss 2.2671 (2.2837)	Training Prec@1 99.414 (99.671)	Training Prec@5 99.609 (99.892)	
2022-06-29 16:41:12,075: ============================================================
2022-06-29 16:42:25,822: time cost, forward:0.011383811434057707, backward:0.030220078869724498, data cost:0.6940643849514697 
2022-06-29 16:42:25,823: ============================================================
2022-06-29 16:42:25,823: Epoch 25/26 Batch 3800/7662 eta: 2:21:39.451274	Training Loss 2.3249 (2.2857)	Training Prec@1 99.414 (99.669)	Training Prec@5 99.805 (99.892)	
2022-06-29 16:42:25,823: ============================================================
2022-06-29 16:43:40,753: time cost, forward:0.011384467890275444, backward:0.030226998403763947, data cost:0.6943958897748401 
2022-06-29 16:43:40,754: ============================================================
2022-06-29 16:43:40,754: Epoch 25/26 Batch 3900/7662 eta: 2:22:40.841090	Training Loss 2.4229 (2.2873)	Training Prec@1 99.414 (99.668)	Training Prec@5 99.805 (99.891)	
2022-06-29 16:43:40,754: ============================================================
2022-06-29 16:44:53,668: time cost, forward:0.011397435564373577, backward:0.03025454919199313, data cost:0.6941722706873198 
2022-06-29 16:44:53,668: ============================================================
2022-06-29 16:44:53,669: Epoch 25/26 Batch 4000/7662 eta: 2:17:37.584729	Training Loss 2.3579 (2.2887)	Training Prec@1 99.609 (99.666)	Training Prec@5 100.000 (99.890)	
2022-06-29 16:44:53,669: ============================================================
2022-06-29 16:46:07,324: time cost, forward:0.011396766610481763, backward:0.030254675429400715, data cost:0.694179302019211 
2022-06-29 16:46:07,324: ============================================================
2022-06-29 16:46:07,325: Epoch 25/26 Batch 4100/7662 eta: 2:17:47.896265	Training Loss 2.5906 (2.2903)	Training Prec@1 99.609 (99.665)	Training Prec@5 99.609 (99.890)	
2022-06-29 16:46:07,325: ============================================================
2022-06-29 16:47:21,227: time cost, forward:0.011419541951048003, backward:0.030292307884814088, data cost:0.6941811334351523 
2022-06-29 16:47:21,227: ============================================================
2022-06-29 16:47:21,228: Epoch 25/26 Batch 4200/7662 eta: 2:17:01.686297	Training Loss 2.3210 (2.2916)	Training Prec@1 99.609 (99.665)	Training Prec@5 99.805 (99.889)	
2022-06-29 16:47:21,228: ============================================================
2022-06-29 16:48:35,103: time cost, forward:0.011431738730779108, backward:0.03029489938700912, data cost:0.6942279610586155 
2022-06-29 16:48:35,104: ============================================================
2022-06-29 16:48:35,104: Epoch 25/26 Batch 4300/7662 eta: 2:15:44.882036	Training Loss 2.2772 (2.2932)	Training Prec@1 99.609 (99.663)	Training Prec@5 99.609 (99.889)	
2022-06-29 16:48:35,104: ============================================================
2022-06-29 16:49:49,024: time cost, forward:0.011425499754565551, backward:0.03028733650644575, data cost:0.6942985061624696 
2022-06-29 16:49:49,024: ============================================================
2022-06-29 16:49:49,025: Epoch 25/26 Batch 4400/7662 eta: 2:14:35.823798	Training Loss 2.3829 (2.2946)	Training Prec@1 100.000 (99.663)	Training Prec@5 100.000 (99.889)	
2022-06-29 16:49:49,025: ============================================================
2022-06-29 16:51:02,241: time cost, forward:0.011429095538517293, backward:0.030304490897252206, data cost:0.6941832659853435 
2022-06-29 16:51:02,241: ============================================================
2022-06-29 16:51:02,241: Epoch 25/26 Batch 4500/7662 eta: 2:12:05.725824	Training Loss 2.4130 (2.2960)	Training Prec@1 99.219 (99.663)	Training Prec@5 99.414 (99.889)	
2022-06-29 16:51:02,241: ============================================================
2022-06-29 16:52:16,517: time cost, forward:0.011433196964666206, backward:0.030299771114597373, data cost:0.6943221718986596 
2022-06-29 16:52:16,517: ============================================================
2022-06-29 16:52:16,518: Epoch 25/26 Batch 4600/7662 eta: 2:12:46.124195	Training Loss 2.4874 (2.2975)	Training Prec@1 99.219 (99.663)	Training Prec@5 100.000 (99.889)	
2022-06-29 16:52:16,518: ============================================================
2022-06-29 16:53:30,958: time cost, forward:0.011443680513409965, backward:0.030319174443642925, data cost:0.694459382917912 
2022-06-29 16:53:30,958: ============================================================
2022-06-29 16:53:30,959: Epoch 25/26 Batch 4700/7662 eta: 2:11:49.360124	Training Loss 2.2130 (2.2985)	Training Prec@1 99.805 (99.662)	Training Prec@5 99.805 (99.889)	
2022-06-29 16:53:30,959: ============================================================
2022-06-29 16:54:45,106: time cost, forward:0.011474569431566451, backward:0.030318318915680115, data cost:0.6945306079341461 
2022-06-29 16:54:45,106: ============================================================
2022-06-29 16:54:45,106: Epoch 25/26 Batch 4800/7662 eta: 2:10:04.033488	Training Loss 2.4720 (2.2998)	Training Prec@1 99.609 (99.661)	Training Prec@5 99.609 (99.888)	
2022-06-29 16:54:45,106: ============================================================
2022-06-29 16:56:00,098: time cost, forward:0.011484772995020034, backward:0.030311617955404244, data cost:0.6947950080697161 
2022-06-29 16:56:00,099: ============================================================
2022-06-29 16:56:00,099: Epoch 25/26 Batch 4900/7662 eta: 2:10:17.968107	Training Loss 2.1843 (2.3015)	Training Prec@1 99.609 (99.660)	Training Prec@5 99.609 (99.888)	
2022-06-29 16:56:00,099: ============================================================
2022-06-29 16:57:14,128: time cost, forward:0.01149028352461569, backward:0.030330910351687036, data cost:0.6948360948949891 
2022-06-29 16:57:14,129: ============================================================
2022-06-29 16:57:14,129: Epoch 25/26 Batch 5000/7662 eta: 2:07:23.593435	Training Loss 2.4356 (2.3029)	Training Prec@1 99.414 (99.659)	Training Prec@5 100.000 (99.888)	
2022-06-29 16:57:14,129: ============================================================
2022-06-29 16:58:28,423: time cost, forward:0.011485474136301667, backward:0.030324587800451813, data cost:0.6949614831853741 
2022-06-29 16:58:28,423: ============================================================
2022-06-29 16:58:28,423: Epoch 25/26 Batch 5100/7662 eta: 2:06:36.625825	Training Loss 2.2463 (2.3045)	Training Prec@1 99.805 (99.659)	Training Prec@5 100.000 (99.888)	
2022-06-29 16:58:28,423: ============================================================
2022-06-29 16:59:42,075: time cost, forward:0.011495917456543063, backward:0.0303611683373177, data cost:0.6949002601064428 
2022-06-29 16:59:42,075: ============================================================
2022-06-29 16:59:42,075: Epoch 25/26 Batch 5200/7662 eta: 2:04:17.240662	Training Loss 2.4295 (2.3065)	Training Prec@1 99.023 (99.657)	Training Prec@5 99.609 (99.887)	
2022-06-29 16:59:42,075: ============================================================
2022-06-29 17:00:55,375: time cost, forward:0.011497468717999448, backward:0.030391771763220082, data cost:0.6947889889517153 
2022-06-29 17:00:55,376: ============================================================
2022-06-29 17:00:55,376: Epoch 25/26 Batch 5300/7662 eta: 2:02:28.400763	Training Loss 2.4572 (2.3078)	Training Prec@1 99.023 (99.657)	Training Prec@5 99.414 (99.887)	
2022-06-29 17:00:55,376: ============================================================
2022-06-29 17:02:10,260: time cost, forward:0.011516330859952115, backward:0.030406667559560657, data cost:0.6949734231634789 
2022-06-29 17:02:10,260: ============================================================
2022-06-29 17:02:10,261: Epoch 25/26 Batch 5400/7662 eta: 2:03:52.308327	Training Loss 2.2826 (2.3097)	Training Prec@1 99.805 (99.656)	Training Prec@5 100.000 (99.887)	
2022-06-29 17:02:10,261: ============================================================
2022-06-29 17:03:23,977: time cost, forward:0.01151963779548663, backward:0.03043111503546965, data cost:0.6949426908886721 
2022-06-29 17:03:23,978: ============================================================
2022-06-29 17:03:23,978: Epoch 25/26 Batch 5500/7662 eta: 2:00:42.724813	Training Loss 2.5712 (2.3110)	Training Prec@1 99.609 (99.655)	Training Prec@5 100.000 (99.886)	
2022-06-29 17:03:23,978: ============================================================
2022-06-29 17:04:38,283: time cost, forward:0.01153035899702407, backward:0.03044037257673315, data cost:0.6950229923519455 
2022-06-29 17:04:38,284: ============================================================
2022-06-29 17:04:38,284: Epoch 25/26 Batch 5600/7662 eta: 2:00:26.250802	Training Loss 2.5273 (2.3126)	Training Prec@1 99.219 (99.653)	Training Prec@5 100.000 (99.886)	
2022-06-29 17:04:38,284: ============================================================
2022-06-29 17:05:52,970: time cost, forward:0.011531410394666236, backward:0.03044816731862759, data cost:0.6951788811751428 
2022-06-29 17:05:52,970: ============================================================
2022-06-29 17:05:52,970: Epoch 25/26 Batch 5700/7662 eta: 1:59:48.566407	Training Loss 2.4611 (2.3141)	Training Prec@1 99.414 (99.652)	Training Prec@5 99.805 (99.885)	
2022-06-29 17:05:52,970: ============================================================
2022-06-29 17:07:07,715: time cost, forward:0.011534018729509701, backward:0.03045273262954083, data cost:0.6953389721916634 
2022-06-29 17:07:07,715: ============================================================
2022-06-29 17:07:07,715: Epoch 25/26 Batch 5800/7662 eta: 1:58:39.450725	Training Loss 2.4279 (2.3153)	Training Prec@1 99.805 (99.651)	Training Prec@5 99.805 (99.885)	
2022-06-29 17:07:07,715: ============================================================
2022-06-29 17:08:20,507: time cost, forward:0.011526636399137992, backward:0.03046719820585508, data cost:0.6951660318967952 
2022-06-29 17:08:20,507: ============================================================
2022-06-29 17:08:20,507: Epoch 25/26 Batch 5900/7662 eta: 1:54:20.650162	Training Loss 2.4418 (2.3169)	Training Prec@1 99.219 (99.649)	Training Prec@5 100.000 (99.884)	
2022-06-29 17:08:20,507: ============================================================
2022-06-29 17:09:35,032: time cost, forward:0.011533697320334334, backward:0.030471779422216325, data cost:0.6952790665932548 
2022-06-29 17:09:35,033: ============================================================
2022-06-29 17:09:35,033: Epoch 25/26 Batch 6000/7662 eta: 1:55:49.524224	Training Loss 2.3805 (2.3184)	Training Prec@1 99.414 (99.648)	Training Prec@5 100.000 (99.883)	
2022-06-29 17:09:35,033: ============================================================
2022-06-29 17:10:48,437: time cost, forward:0.011530271259013269, backward:0.030474913474047138, data cost:0.6952184292698985 
2022-06-29 17:10:48,438: ============================================================
2022-06-29 17:10:48,438: Epoch 25/26 Batch 6100/7662 eta: 1:52:51.604891	Training Loss 2.3716 (2.3196)	Training Prec@1 99.805 (99.647)	Training Prec@5 99.805 (99.883)	
2022-06-29 17:10:48,438: ============================================================
2022-06-29 17:12:02,307: time cost, forward:0.011521101267150495, backward:0.030471494763604015, data cost:0.6952511715415909 
2022-06-29 17:12:02,308: ============================================================
2022-06-29 17:12:02,308: Epoch 25/26 Batch 6200/7662 eta: 1:52:20.642754	Training Loss 2.3774 (2.3209)	Training Prec@1 99.805 (99.647)	Training Prec@5 99.805 (99.883)	
2022-06-29 17:12:02,308: ============================================================
2022-06-29 17:13:16,024: time cost, forward:0.011528059686435785, backward:0.030507425028741465, data cost:0.6951970724401673 
2022-06-29 17:13:16,024: ============================================================
2022-06-29 17:13:16,025: Epoch 25/26 Batch 6300/7662 eta: 1:50:52.936830	Training Loss 2.4738 (2.3221)	Training Prec@1 99.414 (99.646)	Training Prec@5 99.805 (99.883)	
2022-06-29 17:13:16,025: ============================================================
2022-06-29 17:14:31,098: time cost, forward:0.011543850653580268, backward:0.030510287747604434, data cost:0.6953818897173393 
2022-06-29 17:14:31,098: ============================================================
2022-06-29 17:14:31,098: Epoch 25/26 Batch 6400/7662 eta: 1:51:40.317443	Training Loss 2.4063 (2.3231)	Training Prec@1 99.219 (99.646)	Training Prec@5 99.609 (99.883)	
2022-06-29 17:14:31,098: ============================================================
2022-06-29 17:15:46,141: time cost, forward:0.011552323926722275, backward:0.030488054978698928, data cost:0.6955890091662591 
2022-06-29 17:15:46,142: ============================================================
2022-06-29 17:15:46,142: Epoch 25/26 Batch 6500/7662 eta: 1:50:22.597097	Training Loss 2.4536 (2.3245)	Training Prec@1 98.633 (99.644)	Training Prec@5 99.414 (99.882)	
2022-06-29 17:15:46,142: ============================================================
2022-06-29 17:16:59,201: time cost, forward:0.011549282876049538, backward:0.03049036542074773, data cost:0.6954779426949298 
2022-06-29 17:16:59,202: ============================================================
2022-06-29 17:16:59,202: Epoch 25/26 Batch 6600/7662 eta: 1:46:14.477922	Training Loss 2.3027 (2.3255)	Training Prec@1 99.805 (99.643)	Training Prec@5 100.000 (99.882)	
2022-06-29 17:16:59,202: ============================================================
2022-06-29 17:18:12,153: time cost, forward:0.0115634162918207, backward:0.030510725272486577, data cost:0.6953151202910087 
2022-06-29 17:18:12,154: ============================================================
2022-06-29 17:18:12,154: Epoch 25/26 Batch 6700/7662 eta: 1:44:52.109930	Training Loss 2.3171 (2.3268)	Training Prec@1 99.609 (99.642)	Training Prec@5 100.000 (99.881)	
2022-06-29 17:18:12,154: ============================================================
2022-06-29 17:19:26,064: time cost, forward:0.011562174147482321, backward:0.030517663828045643, data cost:0.6953285898701516 
2022-06-29 17:19:26,064: ============================================================
2022-06-29 17:19:26,065: Epoch 25/26 Batch 6800/7662 eta: 1:45:00.889926	Training Loss 2.1536 (2.3278)	Training Prec@1 99.805 (99.641)	Training Prec@5 100.000 (99.881)	
2022-06-29 17:19:26,065: ============================================================
2022-06-29 17:20:41,894: time cost, forward:0.01156106159676329, backward:0.030518406663256843, data cost:0.6956253271203816 
2022-06-29 17:20:41,894: ============================================================
2022-06-29 17:20:41,894: Epoch 25/26 Batch 6900/7662 eta: 1:46:28.662569	Training Loss 2.3039 (2.3289)	Training Prec@1 100.000 (99.640)	Training Prec@5 100.000 (99.881)	
2022-06-29 17:20:41,894: ============================================================
2022-06-29 17:21:55,981: time cost, forward:0.01155522016478123, backward:0.030522729928433204, data cost:0.6956642019798082 
2022-06-29 17:21:55,982: ============================================================
2022-06-29 17:21:55,982: Epoch 25/26 Batch 7000/7662 eta: 1:42:47.777674	Training Loss 2.3415 (2.3300)	Training Prec@1 99.805 (99.639)	Training Prec@5 100.000 (99.880)	
2022-06-29 17:21:55,982: ============================================================
2022-06-29 17:23:10,442: time cost, forward:0.011554175555697628, backward:0.03052903581864566, data cost:0.6957505287998478 
2022-06-29 17:23:10,443: ============================================================
2022-06-29 17:23:10,443: Epoch 25/26 Batch 7100/7662 eta: 1:42:04.415678	Training Loss 2.3909 (2.3312)	Training Prec@1 99.023 (99.638)	Training Prec@5 99.805 (99.880)	
2022-06-29 17:23:10,443: ============================================================
2022-06-29 17:24:25,805: time cost, forward:0.011556230000049343, backward:0.03052995270830937, data cost:0.695961022380326 
2022-06-29 17:24:25,806: ============================================================
2022-06-29 17:24:25,806: Epoch 25/26 Batch 7200/7662 eta: 1:42:03.236673	Training Loss 2.3384 (2.3323)	Training Prec@1 99.609 (99.638)	Training Prec@5 99.609 (99.880)	
2022-06-29 17:24:25,806: ============================================================
2022-06-29 17:25:40,605: time cost, forward:0.01155411568320374, backward:0.030524758153262898, data cost:0.6960991869104743 
2022-06-29 17:25:40,606: ============================================================
2022-06-29 17:25:40,606: Epoch 25/26 Batch 7300/7662 eta: 1:40:02.705908	Training Loss 2.3348 (2.3335)	Training Prec@1 100.000 (99.637)	Training Prec@5 100.000 (99.880)	
2022-06-29 17:25:40,606: ============================================================
2022-06-29 17:26:55,054: time cost, forward:0.011552699563760727, backward:0.030497387915563706, data cost:0.6962056353956094 
2022-06-29 17:26:55,055: ============================================================
2022-06-29 17:26:55,055: Epoch 25/26 Batch 7400/7662 eta: 1:38:20.084393	Training Loss 2.3761 (2.3347)	Training Prec@1 99.609 (99.636)	Training Prec@5 99.805 (99.879)	
2022-06-29 17:26:55,055: ============================================================
2022-06-29 17:28:09,054: time cost, forward:0.011550658733817097, backward:0.030503900071146773, data cost:0.6962195498925207 
2022-06-29 17:28:09,055: ============================================================
2022-06-29 17:28:09,055: Epoch 25/26 Batch 7500/7662 eta: 1:36:30.504813	Training Loss 2.5871 (2.3358)	Training Prec@1 100.000 (99.635)	Training Prec@5 100.000 (99.879)	
2022-06-29 17:28:09,055: ============================================================
2022-06-29 17:29:23,495: time cost, forward:0.011550093092468478, backward:0.030524521097413396, data cost:0.6962751216175588 
2022-06-29 17:29:23,496: ============================================================
2022-06-29 17:29:23,496: Epoch 25/26 Batch 7600/7662 eta: 1:35:50.579662	Training Loss 2.3841 (2.3371)	Training Prec@1 100.000 (99.634)	Training Prec@5 100.000 (99.879)	
2022-06-29 17:29:23,496: ============================================================
2022-06-29 17:30:10,702: Epoch: 25/26 eta: 1:35:03.681731	Training Loss 2.3642 (2.3380)	Training Prec@1 99.609 (99.633)	Training Prec@5 100.000 (99.879)
2022-06-29 17:30:10,703: ============================================================
2022-06-29 17:30:10,797: Save Checkpoint...
2022-06-29 17:30:10,807: ============================================================
2022-06-29 17:30:13,990: Save done!
2022-06-29 17:30:13,991: ============================================================
2022-06-29 17:31:44,594: time cost, forward:0.010709726449215052, backward:0.029485204003073952, data cost:0.8697666784729621 
2022-06-29 17:31:44,595: ============================================================
2022-06-29 17:31:44,595: Epoch 26/26 Batch 100/7662 eta: 1:54:12.101524	Training Loss 2.0976 (2.1921)	Training Prec@1 99.609 (99.765)	Training Prec@5 99.805 (99.923)	
2022-06-29 17:31:44,595: ============================================================
2022-06-29 17:32:57,013: time cost, forward:0.010944585704324234, backward:0.02971619217839073, data cost:0.7757367668439396 
2022-06-29 17:32:57,013: ============================================================
2022-06-29 17:32:57,013: Epoch 26/26 Batch 200/7662 eta: 1:30:04.590640	Training Loss 2.1550 (2.1992)	Training Prec@1 99.805 (99.767)	Training Prec@5 100.000 (99.924)	
2022-06-29 17:32:57,013: ============================================================
2022-06-29 17:34:09,500: time cost, forward:0.011095886645109757, backward:0.03029955270697042, data cost:0.7442252915041104 
2022-06-29 17:34:09,500: ============================================================
2022-06-29 17:34:09,501: Epoch 26/26 Batch 300/7662 eta: 1:28:57.239384	Training Loss 2.0659 (2.2001)	Training Prec@1 100.000 (99.751)	Training Prec@5 100.000 (99.912)	
2022-06-29 17:34:09,501: ============================================================
2022-06-29 17:35:21,966: time cost, forward:0.011149402847863678, backward:0.030259550663462857, data cost:0.7288106127191606 
2022-06-29 17:35:21,966: ============================================================
2022-06-29 17:35:21,967: Epoch 26/26 Batch 400/7662 eta: 1:27:43.211629	Training Loss 2.3038 (2.2050)	Training Prec@1 99.609 (99.735)	Training Prec@5 100.000 (99.907)	
2022-06-29 17:35:21,967: ============================================================
2022-06-29 17:36:34,519: time cost, forward:0.011179110807980707, backward:0.030110815483964756, data cost:0.7198851132440662 
2022-06-29 17:36:34,520: ============================================================
2022-06-29 17:36:34,520: Epoch 26/26 Batch 500/7662 eta: 1:26:36.984179	Training Loss 2.1405 (2.2054)	Training Prec@1 99.414 (99.736)	Training Prec@5 100.000 (99.909)	
2022-06-29 17:36:34,520: ============================================================
2022-06-29 17:37:48,487: time cost, forward:0.011237714047822013, backward:0.029671852497107198, data cost:0.7165943947379697 
2022-06-29 17:37:48,487: ============================================================
2022-06-29 17:37:48,487: Epoch 26/26 Batch 600/7662 eta: 1:27:04.331798	Training Loss 2.3480 (2.2077)	Training Prec@1 99.609 (99.733)	Training Prec@5 100.000 (99.907)	
2022-06-29 17:37:48,487: ============================================================
2022-06-29 17:39:00,544: time cost, forward:0.011213250767349003, backward:0.029529507750264222, data cost:0.7114137832357819 
2022-06-29 17:39:00,544: ============================================================
2022-06-29 17:39:00,544: Epoch 26/26 Batch 700/7662 eta: 1:23:37.308303	Training Loss 2.3533 (2.2126)	Training Prec@1 99.805 (99.731)	Training Prec@5 100.000 (99.909)	
2022-06-29 17:39:00,544: ============================================================
2022-06-29 17:40:14,701: time cost, forward:0.01123325577068687, backward:0.029486954286787777, data cost:0.7100563631189034 
2022-06-29 17:40:14,701: ============================================================
2022-06-29 17:40:14,701: Epoch 26/26 Batch 800/7662 eta: 1:24:49.412995	Training Loss 2.3422 (2.2140)	Training Prec@1 99.609 (99.730)	Training Prec@5 99.805 (99.909)	
2022-06-29 17:40:14,701: ============================================================
2022-06-29 17:41:27,640: time cost, forward:0.011288546879379052, backward:0.02977448602406944, data cost:0.7073017930294966 
2022-06-29 17:41:27,640: ============================================================
2022-06-29 17:41:27,640: Epoch 26/26 Batch 900/7662 eta: 1:22:12.857661	Training Loss 2.2515 (2.2160)	Training Prec@1 99.609 (99.730)	Training Prec@5 100.000 (99.909)	
2022-06-29 17:41:27,640: ============================================================
2022-06-29 17:42:41,986: time cost, forward:0.011311364722800804, backward:0.029940642632760323, data cost:0.7065554044626139 
2022-06-29 17:42:41,986: ============================================================
2022-06-29 17:42:41,986: Epoch 26/26 Batch 1000/7662 eta: 1:22:33.664541	Training Loss 2.1959 (2.2180)	Training Prec@1 100.000 (99.728)	Training Prec@5 100.000 (99.909)	
2022-06-29 17:42:41,986: ============================================================
2022-06-29 17:43:55,163: time cost, forward:0.011312420526561789, backward:0.02994434154500085, data cost:0.7050526213711017 
2022-06-29 17:43:55,163: ============================================================
2022-06-29 17:43:55,163: Epoch 26/26 Batch 1100/7662 eta: 1:20:02.608532	Training Loss 2.0379 (2.2203)	Training Prec@1 99.805 (99.730)	Training Prec@5 99.805 (99.909)	
2022-06-29 17:43:55,163: ============================================================
2022-06-29 17:45:07,528: time cost, forward:0.011301963303464965, backward:0.02995968401879445, data cost:0.7031183513230935 
2022-06-29 17:45:07,529: ============================================================
2022-06-29 17:45:07,529: Epoch 26/26 Batch 1200/7662 eta: 1:17:56.988427	Training Loss 2.1444 (2.2241)	Training Prec@1 99.219 (99.728)	Training Prec@5 100.000 (99.908)	
2022-06-29 17:45:07,529: ============================================================
2022-06-29 17:46:20,569: time cost, forward:0.011283387396315412, backward:0.0298705732391099, data cost:0.7021178246645674 
2022-06-29 17:46:20,570: ============================================================
2022-06-29 17:46:20,570: Epoch 26/26 Batch 1300/7662 eta: 1:17:27.612037	Training Loss 2.1558 (2.2259)	Training Prec@1 99.805 (99.725)	Training Prec@5 100.000 (99.908)	
2022-06-29 17:46:20,570: ============================================================
2022-06-29 17:47:33,587: time cost, forward:0.01133696806268917, backward:0.02988890565404558, data cost:0.7010789532760282 
2022-06-29 17:47:33,587: ============================================================
2022-06-29 17:47:33,587: Epoch 26/26 Batch 1400/7662 eta: 1:16:13.061636	Training Loss 2.2568 (2.2270)	Training Prec@1 99.219 (99.721)	Training Prec@5 100.000 (99.908)	
2022-06-29 17:47:33,587: ============================================================
2022-06-29 17:48:46,628: time cost, forward:0.011356104366615504, backward:0.02983532165033647, data cost:0.7002852319319142 
2022-06-29 17:48:46,629: ============================================================
2022-06-29 17:48:46,629: Epoch 26/26 Batch 1500/7662 eta: 1:15:01.570911	Training Loss 2.2169 (2.2289)	Training Prec@1 99.609 (99.722)	Training Prec@5 99.805 (99.908)	
2022-06-29 17:48:46,629: ============================================================
2022-06-29 17:50:00,457: time cost, forward:0.011402619638019536, backward:0.029926383100203083, data cost:0.6999217479806009 
2022-06-29 17:50:00,457: ============================================================
2022-06-29 17:50:00,457: Epoch 26/26 Batch 1600/7662 eta: 1:14:36.196602	Training Loss 2.3026 (2.2321)	Training Prec@1 99.609 (99.721)	Training Prec@5 100.000 (99.907)	
2022-06-29 17:50:00,457: ============================================================
2022-06-29 17:51:14,046: time cost, forward:0.011395186378788849, backward:0.02993417754462356, data cost:0.699574726339366 
2022-06-29 17:51:14,047: ============================================================
2022-06-29 17:51:14,047: Epoch 26/26 Batch 1700/7662 eta: 1:13:08.168724	Training Loss 2.2554 (2.2354)	Training Prec@1 99.219 (99.717)	Training Prec@5 99.805 (99.906)	
2022-06-29 17:51:14,047: ============================================================
2022-06-29 17:52:26,645: time cost, forward:0.011355672033711763, backward:0.02986945305485537, data cost:0.6988295306756538 
2022-06-29 17:52:26,646: ============================================================
2022-06-29 17:52:26,646: Epoch 26/26 Batch 1800/7662 eta: 1:10:56.471862	Training Loss 2.4503 (2.2381)	Training Prec@1 99.414 (99.713)	Training Prec@5 99.805 (99.904)	
2022-06-29 17:52:26,646: ============================================================
2022-06-29 17:53:40,829: time cost, forward:0.011356782260350393, backward:0.029856713838863524, data cost:0.6989158734075015 
2022-06-29 17:53:40,829: ============================================================
2022-06-29 17:53:40,829: Epoch 26/26 Batch 1900/7662 eta: 1:11:15.198076	Training Loss 2.2662 (2.2413)	Training Prec@1 99.805 (99.712)	Training Prec@5 99.805 (99.904)	
2022-06-29 17:53:40,830: ============================================================
2022-06-29 17:54:54,548: time cost, forward:0.011358690595793808, backward:0.029744605412180273, data cost:0.6988510961470573 
2022-06-29 17:54:54,548: ============================================================
2022-06-29 17:54:54,548: Epoch 26/26 Batch 2000/7662 eta: 1:09:34.702237	Training Loss 2.2409 (2.2434)	Training Prec@1 99.805 (99.711)	Training Prec@5 100.000 (99.904)	
2022-06-29 17:54:54,548: ============================================================
2022-06-29 17:56:07,867: time cost, forward:0.011368606362017976, backward:0.029747454310213174, data cost:0.6984946159818958 
2022-06-29 17:56:07,867: ============================================================
2022-06-29 17:56:07,867: Epoch 26/26 Batch 2100/7662 eta: 1:07:58.721368	Training Loss 2.1712 (2.2458)	Training Prec@1 99.609 (99.708)	Training Prec@5 100.000 (99.904)	
2022-06-29 17:56:07,867: ============================================================
2022-06-29 17:57:20,488: time cost, forward:0.011368285097171632, backward:0.02973805703375219, data cost:0.6978759079317767 
2022-06-29 17:57:20,488: ============================================================
2022-06-29 17:57:20,488: Epoch 26/26 Batch 2200/7662 eta: 1:06:07.285441	Training Loss 2.3615 (2.2482)	Training Prec@1 98.828 (99.708)	Training Prec@5 99.805 (99.904)	
2022-06-29 17:57:20,488: ============================================================
2022-06-29 17:58:32,883: time cost, forward:0.011364956428922742, backward:0.02977240318938824, data cost:0.6971732012444655 
2022-06-29 17:58:32,884: ============================================================
2022-06-29 17:58:32,884: Epoch 26/26 Batch 2300/7662 eta: 1:04:42.585047	Training Loss 2.2727 (2.2495)	Training Prec@1 100.000 (99.709)	Training Prec@5 100.000 (99.904)	
2022-06-29 17:58:32,884: ============================================================
2022-06-29 17:59:46,111: time cost, forward:0.011353550974952028, backward:0.029772337797831974, data cost:0.6969147223440395 
2022-06-29 17:59:46,111: ============================================================
2022-06-29 17:59:46,112: Epoch 26/26 Batch 2400/7662 eta: 1:04:13.973274	Training Loss 2.1949 (2.2509)	Training Prec@1 100.000 (99.708)	Training Prec@5 100.000 (99.905)	
2022-06-29 17:59:46,112: ============================================================
2022-06-29 18:01:00,872: time cost, forward:0.011364641166677852, backward:0.029698361106374922, data cost:0.6973426471762105 
2022-06-29 18:01:00,873: ============================================================
2022-06-29 18:01:00,873: Epoch 26/26 Batch 2500/7662 eta: 1:04:19.925074	Training Loss 2.2446 (2.2528)	Training Prec@1 99.805 (99.706)	Training Prec@5 100.000 (99.903)	
2022-06-29 18:01:00,873: ============================================================
2022-06-29 18:02:14,883: time cost, forward:0.01136574189265722, backward:0.029645501122469168, data cost:0.697437494247865 
2022-06-29 18:02:14,883: ============================================================
2022-06-29 18:02:14,883: Epoch 26/26 Batch 2600/7662 eta: 1:02:27.155270	Training Loss 2.3452 (2.2558)	Training Prec@1 99.609 (99.703)	Training Prec@5 100.000 (99.903)	
2022-06-29 18:02:14,884: ============================================================
2022-06-29 18:03:28,469: time cost, forward:0.011372855258191148, backward:0.029448257900688904, data cost:0.6975161113223132 
2022-06-29 18:03:28,469: ============================================================
2022-06-29 18:03:28,469: Epoch 26/26 Batch 2700/7662 eta: 1:00:52.068611	Training Loss 2.1218 (2.2577)	Training Prec@1 100.000 (99.700)	Training Prec@5 100.000 (99.901)	
2022-06-29 18:03:28,469: ============================================================
2022-06-29 18:04:42,437: time cost, forward:0.011394756442523505, backward:0.029359395097689613, data cost:0.6976217920331284 
2022-06-29 18:04:42,438: ============================================================
2022-06-29 18:04:42,438: Epoch 26/26 Batch 2800/7662 eta: 0:59:57.086075	Training Loss 2.2344 (2.2591)	Training Prec@1 99.609 (99.699)	Training Prec@5 100.000 (99.902)	
2022-06-29 18:04:42,438: ============================================================
2022-06-29 18:05:54,042: time cost, forward:0.011375759831376222, backward:0.029428444388982716, data cost:0.6967813184072988 
2022-06-29 18:05:54,043: ============================================================
2022-06-29 18:05:54,043: Epoch 26/26 Batch 2900/7662 eta: 0:56:50.545049	Training Loss 2.2879 (2.2613)	Training Prec@1 99.805 (99.698)	Training Prec@5 100.000 (99.901)	
2022-06-29 18:05:54,043: ============================================================
2022-06-29 18:07:07,479: time cost, forward:0.011383058946106426, backward:0.029419377073521373, data cost:0.6966575067335067 
2022-06-29 18:07:07,479: ============================================================
2022-06-29 18:07:07,479: Epoch 26/26 Batch 3000/7662 eta: 0:57:04.333370	Training Loss 2.3379 (2.2628)	Training Prec@1 99.805 (99.695)	Training Prec@5 99.805 (99.901)	
2022-06-29 18:07:07,479: ============================================================
2022-06-29 18:08:21,476: time cost, forward:0.011401065282953982, backward:0.029463719306125992, data cost:0.6966618133691405 
2022-06-29 18:08:21,476: ============================================================
2022-06-29 18:08:21,476: Epoch 26/26 Batch 3100/7662 eta: 0:56:16.496207	Training Loss 2.3631 (2.2648)	Training Prec@1 99.609 (99.693)	Training Prec@5 100.000 (99.900)	
2022-06-29 18:08:21,476: ============================================================
2022-06-29 18:09:34,181: time cost, forward:0.01139386611716678, backward:0.02944897725903343, data cost:0.6963415535661197 
2022-06-29 18:09:34,182: ============================================================
2022-06-29 18:09:34,182: Epoch 26/26 Batch 3200/7662 eta: 0:54:04.837352	Training Loss 2.1686 (2.2661)	Training Prec@1 99.805 (99.692)	Training Prec@5 100.000 (99.900)	
2022-06-29 18:09:34,182: ============================================================
2022-06-29 18:10:47,045: time cost, forward:0.011386871482430533, backward:0.02942863880919485, data cost:0.6960954864880069 
2022-06-29 18:10:47,045: ============================================================
2022-06-29 18:10:47,046: Epoch 26/26 Batch 3300/7662 eta: 0:52:59.051778	Training Loss 2.3375 (2.2677)	Training Prec@1 99.609 (99.692)	Training Prec@5 99.609 (99.900)	
2022-06-29 18:10:47,046: ============================================================
2022-06-29 18:12:02,070: time cost, forward:0.011388900526203314, backward:0.029411393426803673, data cost:0.6964893583060363 
2022-06-29 18:12:02,070: ============================================================
2022-06-29 18:12:02,070: Epoch 26/26 Batch 3400/7662 eta: 0:53:18.303131	Training Loss 2.4231 (2.2693)	Training Prec@1 99.609 (99.690)	Training Prec@5 99.805 (99.899)	
2022-06-29 18:12:02,070: ============================================================
2022-06-29 18:13:16,223: time cost, forward:0.01138344019540687, backward:0.029405119351640228, data cost:0.6966082206212578 
2022-06-29 18:13:16,223: ============================================================
2022-06-29 18:13:16,223: Epoch 26/26 Batch 3500/7662 eta: 0:51:26.989435	Training Loss 2.5248 (2.2712)	Training Prec@1 99.805 (99.689)	Training Prec@5 100.000 (99.898)	
2022-06-29 18:13:16,223: ============================================================
2022-06-29 18:14:30,170: time cost, forward:0.011391295761358543, backward:0.02942569555922262, data cost:0.6966246511247894 
2022-06-29 18:14:30,170: ============================================================
2022-06-29 18:14:30,170: Epoch 26/26 Batch 3600/7662 eta: 0:50:04.467299	Training Loss 2.4084 (2.2726)	Training Prec@1 100.000 (99.686)	Training Prec@5 100.000 (99.898)	
2022-06-29 18:14:30,170: ============================================================
2022-06-29 18:15:44,326: time cost, forward:0.01140294013135528, backward:0.02943958891955992, data cost:0.6966985991659214 
2022-06-29 18:15:44,326: ============================================================
2022-06-29 18:15:44,326: Epoch 26/26 Batch 3700/7662 eta: 0:48:58.792553	Training Loss 2.5310 (2.2742)	Training Prec@1 99.219 (99.683)	Training Prec@5 99.414 (99.897)	
2022-06-29 18:15:44,326: ============================================================
2022-06-29 18:16:58,896: time cost, forward:0.01139351047004766, backward:0.029453122637779595, data cost:0.6968980618733173 
2022-06-29 18:16:58,896: ============================================================
2022-06-29 18:16:58,896: Epoch 26/26 Batch 3800/7662 eta: 0:48:00.643380	Training Loss 2.3474 (2.2761)	Training Prec@1 99.414 (99.682)	Training Prec@5 99.805 (99.897)	
2022-06-29 18:16:58,896: ============================================================
2022-06-29 18:18:13,772: time cost, forward:0.011402354420194506, backward:0.029489296098402385, data cost:0.6971233773457757 
2022-06-29 18:18:13,772: ============================================================
2022-06-29 18:18:13,772: Epoch 26/26 Batch 3900/7662 eta: 0:46:57.579562	Training Loss 2.4012 (2.2782)	Training Prec@1 99.219 (99.680)	Training Prec@5 100.000 (99.897)	
2022-06-29 18:18:13,772: ============================================================
2022-06-29 18:19:28,055: time cost, forward:0.011403195170588302, backward:0.029517614951757348, data cost:0.6972039773124967 
2022-06-29 18:19:28,055: ============================================================
2022-06-29 18:19:28,055: Epoch 26/26 Batch 4000/7662 eta: 0:45:20.987215	Training Loss 2.1842 (2.2796)	Training Prec@1 99.609 (99.680)	Training Prec@5 99.609 (99.897)	
2022-06-29 18:19:28,055: ============================================================
2022-06-29 18:20:41,980: time cost, forward:0.011420708570459407, backward:0.029524109368790765, data cost:0.6971959163282347 
2022-06-29 18:20:41,980: ============================================================
2022-06-29 18:20:41,980: Epoch 26/26 Batch 4100/7662 eta: 0:43:53.952403	Training Loss 2.5072 (2.2815)	Training Prec@1 99.609 (99.678)	Training Prec@5 100.000 (99.896)	
2022-06-29 18:20:41,980: ============================================================
2022-06-29 18:21:55,325: time cost, forward:0.011426410154945426, backward:0.02953475133155919, data cost:0.6970568087078839 
2022-06-29 18:21:55,326: ============================================================
2022-06-29 18:21:55,326: Epoch 26/26 Batch 4200/7662 eta: 0:42:19.953435	Training Loss 2.2091 (2.2834)	Training Prec@1 99.805 (99.677)	Training Prec@5 100.000 (99.896)	
2022-06-29 18:21:55,326: ============================================================
2022-06-29 18:23:08,505: time cost, forward:0.011421047606893017, backward:0.029513543027588088, data cost:0.6969280408187977 
2022-06-29 18:23:08,505: ============================================================
2022-06-29 18:23:08,505: Epoch 26/26 Batch 4300/7662 eta: 0:41:01.019276	Training Loss 2.3367 (2.2850)	Training Prec@1 99.609 (99.675)	Training Prec@5 100.000 (99.895)	
2022-06-29 18:23:08,505: ============================================================
2022-06-29 18:24:22,228: time cost, forward:0.011415345854693094, backward:0.0295233297792449, data cost:0.6968998279211656 
2022-06-29 18:24:22,228: ============================================================
2022-06-29 18:24:22,228: Epoch 26/26 Batch 4400/7662 eta: 0:40:05.584557	Training Loss 2.3807 (2.2869)	Training Prec@1 99.609 (99.674)	Training Prec@5 100.000 (99.895)	
2022-06-29 18:24:22,228: ============================================================
2022-06-29 18:25:35,814: time cost, forward:0.011409075002083118, backward:0.029511038105496833, data cost:0.6968639742721316 
2022-06-29 18:25:35,814: ============================================================
2022-06-29 18:25:35,814: Epoch 26/26 Batch 4500/7662 eta: 0:38:47.534115	Training Loss 2.2605 (2.2885)	Training Prec@1 99.609 (99.674)	Training Prec@5 100.000 (99.895)	
2022-06-29 18:25:35,814: ============================================================
2022-06-29 18:26:49,876: time cost, forward:0.011411780610139486, backward:0.02949567529579224, data cost:0.6969279231494291 
2022-06-29 18:26:49,877: ============================================================
2022-06-29 18:26:49,877: Epoch 26/26 Batch 4600/7662 eta: 0:37:48.530278	Training Loss 2.4549 (2.2899)	Training Prec@1 99.023 (99.673)	Training Prec@5 99.414 (99.895)	
2022-06-29 18:26:49,877: ============================================================
2022-06-29 18:28:03,127: time cost, forward:0.011419081642262909, backward:0.029449054702187276, data cost:0.6968468151896222 
2022-06-29 18:28:03,127: ============================================================
2022-06-29 18:28:03,127: Epoch 26/26 Batch 4700/7662 eta: 0:36:10.411360	Training Loss 2.2733 (2.2915)	Training Prec@1 99.805 (99.671)	Training Prec@5 100.000 (99.894)	
2022-06-29 18:28:03,127: ============================================================
2022-06-29 18:29:16,848: time cost, forward:0.011416347803337223, backward:0.02945123729320287, data cost:0.6968253491495668 
2022-06-29 18:29:16,848: ============================================================
2022-06-29 18:29:16,848: Epoch 26/26 Batch 4800/7662 eta: 0:35:10.636597	Training Loss 2.3511 (2.2929)	Training Prec@1 99.805 (99.671)	Training Prec@5 99.805 (99.894)	
2022-06-29 18:29:16,848: ============================================================
2022-06-29 18:30:31,113: time cost, forward:0.011419567776641253, backward:0.029403415108778252, data cost:0.6969625583398729 
2022-06-29 18:30:31,113: ============================================================
2022-06-29 18:30:31,114: Epoch 26/26 Batch 4900/7662 eta: 0:34:11.946656	Training Loss 2.1441 (2.2948)	Training Prec@1 100.000 (99.669)	Training Prec@5 100.000 (99.893)	
2022-06-29 18:30:31,114: ============================================================
2022-06-29 18:31:45,947: time cost, forward:0.01142908196660084, backward:0.029414706908361652, data cost:0.6971438440901682 
2022-06-29 18:31:45,948: ============================================================
2022-06-29 18:31:45,948: Epoch 26/26 Batch 5000/7662 eta: 0:33:12.834229	Training Loss 2.5210 (2.2966)	Training Prec@1 99.609 (99.668)	Training Prec@5 100.000 (99.893)	
2022-06-29 18:31:45,948: ============================================================
2022-06-29 18:32:58,990: time cost, forward:0.011421629531076316, backward:0.02940968705944324, data cost:0.6969994280613692 
2022-06-29 18:32:58,990: ============================================================
2022-06-29 18:32:58,991: Epoch 26/26 Batch 5100/7662 eta: 0:31:12.088160	Training Loss 2.3540 (2.2979)	Training Prec@1 99.609 (99.668)	Training Prec@5 99.805 (99.893)	
2022-06-29 18:32:58,991: ============================================================
2022-06-29 18:34:12,471: time cost, forward:0.011416532874543016, backward:0.02941125222044877, data cost:0.696936679725625 
2022-06-29 18:34:12,471: ============================================================
2022-06-29 18:34:12,472: Epoch 26/26 Batch 5200/7662 eta: 0:30:09.834498	Training Loss 2.2726 (2.2995)	Training Prec@1 99.805 (99.667)	Training Prec@5 100.000 (99.893)	
2022-06-29 18:34:12,472: ============================================================
2022-06-29 18:35:27,427: time cost, forward:0.011426996838306341, backward:0.029454970904219082, data cost:0.6970988002042092 
2022-06-29 18:35:27,428: ============================================================
2022-06-29 18:35:27,428: Epoch 26/26 Batch 5300/7662 eta: 0:29:31.220113	Training Loss 2.3481 (2.3009)	Training Prec@1 99.609 (99.667)	Training Prec@5 99.805 (99.892)	
2022-06-29 18:35:27,428: ============================================================
2022-06-29 18:36:40,928: time cost, forward:0.011432430924784588, backward:0.029491291109732642, data cost:0.6969914443847492 
2022-06-29 18:36:40,928: ============================================================
2022-06-29 18:36:40,928: Epoch 26/26 Batch 5400/7662 eta: 0:27:43.306182	Training Loss 2.6074 (2.3022)	Training Prec@1 99.023 (99.665)	Training Prec@5 99.609 (99.892)	
2022-06-29 18:36:40,928: ============================================================
2022-06-29 18:37:55,375: time cost, forward:0.011443642361161058, backward:0.029524747318171396, data cost:0.6970569178676103 
2022-06-29 18:37:55,375: ============================================================
2022-06-29 18:37:55,376: Epoch 26/26 Batch 5500/7662 eta: 0:26:50.302828	Training Loss 2.4380 (2.3032)	Training Prec@1 99.414 (99.664)	Training Prec@5 99.805 (99.892)	
2022-06-29 18:37:55,376: ============================================================
2022-06-29 18:39:10,520: time cost, forward:0.011445141536973591, backward:0.02952593768317905, data cost:0.6972848145232325 
2022-06-29 18:39:10,520: ============================================================
2022-06-29 18:39:10,520: Epoch 26/26 Batch 5600/7662 eta: 0:25:50.232486	Training Loss 2.2807 (2.3045)	Training Prec@1 99.805 (99.663)	Training Prec@5 100.000 (99.892)	
2022-06-29 18:39:10,520: ============================================================
2022-06-29 18:40:24,380: time cost, forward:0.01144329902058548, backward:0.029513838375256885, data cost:0.6972964491461804 
2022-06-29 18:40:24,381: ============================================================
2022-06-29 18:40:24,381: Epoch 26/26 Batch 5700/7662 eta: 0:24:09.881626	Training Loss 2.2173 (2.3058)	Training Prec@1 99.609 (99.663)	Training Prec@5 100.000 (99.892)	
2022-06-29 18:40:24,381: ============================================================
2022-06-29 18:41:38,027: time cost, forward:0.011435285110394695, backward:0.029515386881715656, data cost:0.697264815388229 
2022-06-29 18:41:38,027: ============================================================
2022-06-29 18:41:38,027: Epoch 26/26 Batch 5800/7662 eta: 0:22:52.033693	Training Loss 2.3170 (2.3070)	Training Prec@1 99.219 (99.662)	Training Prec@5 100.000 (99.892)	
2022-06-29 18:41:38,027: ============================================================
2022-06-29 18:42:52,265: time cost, forward:0.011439547900083329, backward:0.02952985538024178, data cost:0.6973090079259541 
2022-06-29 18:42:52,266: ============================================================
2022-06-29 18:42:52,266: Epoch 26/26 Batch 5900/7662 eta: 0:21:48.825173	Training Loss 2.4393 (2.3087)	Training Prec@1 99.023 (99.660)	Training Prec@5 99.609 (99.891)	
2022-06-29 18:42:52,266: ============================================================
2022-06-29 18:44:06,667: time cost, forward:0.011447107698504459, backward:0.029553570892835064, data cost:0.6973660304200989 
2022-06-29 18:44:06,668: ============================================================
2022-06-29 18:44:06,668: Epoch 26/26 Batch 6000/7662 eta: 0:20:37.305235	Training Loss 2.4706 (2.3098)	Training Prec@1 100.000 (99.659)	Training Prec@5 100.000 (99.891)	
2022-06-29 18:44:06,668: ============================================================
2022-06-29 18:45:21,258: time cost, forward:0.011460828554397685, backward:0.029575754959361635, data cost:0.6974473948712465 
2022-06-29 18:45:21,259: ============================================================
2022-06-29 18:45:21,259: Epoch 26/26 Batch 6100/7662 eta: 0:19:25.857667	Training Loss 2.5160 (2.3114)	Training Prec@1 100.000 (99.659)	Training Prec@5 100.000 (99.890)	
2022-06-29 18:45:21,259: ============================================================
2022-06-29 18:46:36,228: time cost, forward:0.011467857386993196, backward:0.0295885784584854, data cost:0.6976001080360542 
2022-06-29 18:46:36,229: ============================================================
2022-06-29 18:46:36,229: Epoch 26/26 Batch 6200/7662 eta: 0:18:16.812649	Training Loss 2.4245 (2.3131)	Training Prec@1 99.609 (99.657)	Training Prec@5 100.000 (99.890)	
2022-06-29 18:46:36,229: ============================================================
2022-06-29 18:47:50,467: time cost, forward:0.01146478943643844, backward:0.029589360584283863, data cost:0.697654235171863 
2022-06-29 18:47:50,468: ============================================================
2022-06-29 18:47:50,468: Epoch 26/26 Batch 6300/7662 eta: 0:16:51.879443	Training Loss 2.3889 (2.3148)	Training Prec@1 99.805 (99.656)	Training Prec@5 100.000 (99.889)	
2022-06-29 18:47:50,468: ============================================================
2022-06-29 18:49:04,147: time cost, forward:0.011471792354604606, backward:0.029618744664610244, data cost:0.6975829726849744 
2022-06-29 18:49:04,147: ============================================================
2022-06-29 18:49:04,147: Epoch 26/26 Batch 6400/7662 eta: 0:15:30.566061	Training Loss 2.5454 (2.3162)	Training Prec@1 99.609 (99.655)	Training Prec@5 99.805 (99.889)	
2022-06-29 18:49:04,147: ============================================================
2022-06-29 18:50:18,792: time cost, forward:0.01147889236171973, backward:0.02964013711289821, data cost:0.6976670154627882 
2022-06-29 18:50:18,793: ============================================================
2022-06-29 18:50:18,793: Epoch 26/26 Batch 6500/7662 eta: 0:14:28.131121	Training Loss 2.1993 (2.3176)	Training Prec@1 100.000 (99.653)	Training Prec@5 100.000 (99.889)	
2022-06-29 18:50:18,793: ============================================================
2022-06-29 18:51:33,821: time cost, forward:0.011477613506903881, backward:0.029646909025550377, data cost:0.6978275761096329 
2022-06-29 18:51:33,821: ============================================================
2022-06-29 18:51:33,822: Epoch 26/26 Batch 6600/7662 eta: 0:13:17.555184	Training Loss 2.2060 (2.3188)	Training Prec@1 100.000 (99.652)	Training Prec@5 100.000 (99.888)	
2022-06-29 18:51:33,822: ============================================================
2022-06-29 18:52:47,221: time cost, forward:0.01148574514911502, backward:0.029666753647344862, data cost:0.6977202243494586 
2022-06-29 18:52:47,221: ============================================================
2022-06-29 18:52:47,221: Epoch 26/26 Batch 6700/7662 eta: 0:11:46.839446	Training Loss 2.4152 (2.3202)	Training Prec@1 100.000 (99.651)	Training Prec@5 100.000 (99.888)	
2022-06-29 18:52:47,221: ============================================================
2022-06-29 18:54:00,815: time cost, forward:0.01148280699054254, backward:0.02967734241471569, data cost:0.6976624591365634 
2022-06-29 18:54:00,815: ============================================================
2022-06-29 18:54:00,816: Epoch 26/26 Batch 6800/7662 eta: 0:10:35.117468	Training Loss 2.4370 (2.3216)	Training Prec@1 99.609 (99.650)	Training Prec@5 100.000 (99.888)	
2022-06-29 18:54:00,816: ============================================================
2022-06-29 18:55:14,376: time cost, forward:0.01148421589162561, backward:0.029629626711618555, data cost:0.6976541395653225 
2022-06-29 18:55:14,376: ============================================================
2022-06-29 18:55:14,376: Epoch 26/26 Batch 6900/7662 eta: 0:09:21.267327	Training Loss 2.3549 (2.3230)	Training Prec@1 100.000 (99.650)	Training Prec@5 100.000 (99.887)	
2022-06-29 18:55:14,376: ============================================================
2022-06-29 18:56:28,247: time cost, forward:0.011498274505436463, backward:0.029652908029241518, data cost:0.6976102619004907 
2022-06-29 18:56:28,247: ============================================================
2022-06-29 18:56:28,248: Epoch 26/26 Batch 7000/7662 eta: 0:08:09.767656	Training Loss 2.1968 (2.3239)	Training Prec@1 100.000 (99.649)	Training Prec@5 100.000 (99.887)	
2022-06-29 18:56:28,248: ============================================================
2022-06-29 18:57:43,681: time cost, forward:0.01150431151389404, backward:0.029653168980681335, data cost:0.6978157842506874 
2022-06-29 18:57:43,681: ============================================================
2022-06-29 18:57:43,682: Epoch 26/26 Batch 7100/7662 eta: 0:07:04.693737	Training Loss 2.4114 (2.3252)	Training Prec@1 99.609 (99.647)	Training Prec@5 100.000 (99.887)	
2022-06-29 18:57:43,682: ============================================================
2022-06-29 18:58:58,768: time cost, forward:0.011510027400452753, backward:0.029644239344585602, data cost:0.6979797345794793 
2022-06-29 18:58:58,768: ============================================================
2022-06-29 18:58:58,768: Epoch 26/26 Batch 7200/7662 eta: 0:05:47.651616	Training Loss 2.3529 (2.3263)	Training Prec@1 99.805 (99.646)	Training Prec@5 99.805 (99.887)	
2022-06-29 18:58:58,768: ============================================================
2022-06-29 19:00:12,802: time cost, forward:0.011508169329677612, backward:0.029621538323463682, data cost:0.6980140473780885 
2022-06-29 19:00:12,803: ============================================================
2022-06-29 19:00:12,803: Epoch 26/26 Batch 7300/7662 eta: 0:04:28.744721	Training Loss 2.4806 (2.3276)	Training Prec@1 99.805 (99.646)	Training Prec@5 100.000 (99.887)	
2022-06-29 19:00:12,803: ============================================================
2022-06-29 19:01:26,862: time cost, forward:0.011511030092740772, backward:0.029638495021840176, data cost:0.6980062234496761 
2022-06-29 19:01:26,862: ============================================================
2022-06-29 19:01:26,862: Epoch 26/26 Batch 7400/7662 eta: 0:03:14.776634	Training Loss 2.4693 (2.3289)	Training Prec@1 99.609 (99.644)	Training Prec@5 100.000 (99.886)	
2022-06-29 19:01:26,862: ============================================================
2022-06-29 19:02:41,247: time cost, forward:0.011508819150485934, backward:0.029632525215754272, data cost:0.6980721754365833 
2022-06-29 19:02:41,247: ============================================================
2022-06-29 19:02:41,247: Epoch 26/26 Batch 7500/7662 eta: 0:02:01.247474	Training Loss 2.4998 (2.3301)	Training Prec@1 99.805 (99.643)	Training Prec@5 100.000 (99.886)	
2022-06-29 19:02:41,247: ============================================================
2022-06-29 19:03:56,884: time cost, forward:0.011516745960513202, backward:0.029635375103584667, data cost:0.6982816858250211 
2022-06-29 19:03:56,884: ============================================================
2022-06-29 19:03:56,884: Epoch 26/26 Batch 7600/7662 eta: 0:00:47.651374	Training Loss 2.3509 (2.3312)	Training Prec@1 99.609 (99.643)	Training Prec@5 100.000 (99.885)	
2022-06-29 19:03:56,884: ============================================================
2022-06-29 19:04:45,377: Epoch: 26/26 eta: 0:00:00	Training Loss 2.3377 (2.3319)	Training Prec@1 99.805 (99.642)	Training Prec@5 100.000 (99.885)
2022-06-29 19:04:45,377: ============================================================
