2022-05-10 14:27:56,064: [('name', 'resnet50'), ('backbone_model_name', 'resnet50'), ('classify_model_name', 'Sphereface2'), ('resume_net_model', None), ('resume_net_classifier', None), ('no_cuda', False), ('gpu_num', 2), ('log_interval', 100), ('log_path', './logs/res_50_sphereface2.log'), ('log_pic_path', './logs/pic/res_50_sphereface2/'), ('save_path', 'snapshot/res_50_sphereface2/'), ('lmdb_path', '/home/ubuntu/data4/lk/data/lmdb_default'), ('batch_size', 512), ('datanum', 3923399), ('num_class', 86876), ('lmdb_workers', 4), ('num_workers', 4), ('start_epoch', 1), ('max_epoch', 38), ('lr', 0.1), ('base', 'epoch'), ('step_size', [10, 20, 30]), ('momentum', 0.9), ('gama', 0.1), ('weight_decay', 0.0005), ('rank', -1), ('dist_url', 'env://'), ('world_size', 1), ('gpu', 0), ('dist_backend', 'nccl'), ('distributed', False), ('master_port', 22345), ('multiprocessing_distributed', False), ('SEED', 1337), ('local_rank', 0)]
2022-05-10 14:27:56,065: ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer2): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer3): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (4): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (5): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer4): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (bn_o1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (dropout): Dropout(p=0, inplace=False)
  (fc): Linear(in_features=32768, out_features=512, bias=True)
)
2022-05-10 14:27:59,784: Use one GPU
2022-05-10 14:28:49,173: time cost, forward:0.18376984499921703, backward:0.11618231041262848, data cost:0.19473117288917002 
2022-05-10 14:28:49,173: ============================================================
2022-05-10 14:28:49,174: Epoch 1/38 Batch 100/7662 eta: 1 day, 15:46:52.674431	Training Loss 0.8360 (0.8435)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.018)	
2022-05-10 14:28:49,174: ============================================================
2022-05-10 14:29:35,429: time cost, forward:0.17803120613098145, backward:0.10968725046320776, data cost:0.19061715519008923 
2022-05-10 14:29:35,430: ============================================================
2022-05-10 14:29:35,430: Epoch 1/38 Batch 200/7662 eta: 1 day, 13:23:06.234063	Training Loss 0.8348 (0.8387)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.021)	
2022-05-10 14:29:35,430: ============================================================
2022-05-10 14:30:21,761: time cost, forward:0.17557372536547608, backward:0.10797563524150529, data cost:0.18965310635774033 
2022-05-10 14:30:21,762: ============================================================
2022-05-10 14:30:21,763: Epoch 1/38 Batch 300/7662 eta: 1 day, 13:26:00.773025	Training Loss 0.8332 (0.8370)	Training Prec@1 0.195 (0.005)	Training Prec@5 0.391 (0.022)	
2022-05-10 14:30:21,763: ============================================================
2022-05-10 14:31:07,942: time cost, forward:0.17404671181413464, backward:0.10698359831233968, data cost:0.18924505190741747 
2022-05-10 14:31:07,943: ============================================================
2022-05-10 14:31:07,943: Epoch 1/38 Batch 400/7662 eta: 1 day, 13:17:53.042713	Training Loss 0.8337 (0.8360)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.028)	
2022-05-10 14:31:07,943: ============================================================
2022-05-10 14:31:54,220: time cost, forward:0.17325984069961822, backward:0.10632616675688412, data cost:0.18913105303395486 
2022-05-10 14:31:54,220: ============================================================
2022-05-10 14:31:54,220: Epoch 1/38 Batch 500/7662 eta: 1 day, 13:21:48.618294	Training Loss 0.8316 (0.8351)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.034)	
2022-05-10 14:31:54,220: ============================================================
2022-05-10 14:32:40,590: time cost, forward:0.17279333861323948, backward:0.1059127614175736, data cost:0.18912268242175273 
2022-05-10 14:32:40,590: ============================================================
2022-05-10 14:32:40,590: Epoch 1/38 Batch 600/7662 eta: 1 day, 13:25:31.643564	Training Loss 0.8282 (0.8342)	Training Prec@1 0.000 (0.011)	Training Prec@5 0.391 (0.048)	
2022-05-10 14:32:40,591: ============================================================
2022-05-10 14:33:27,060: time cost, forward:0.1724117801595314, backward:0.10562758827755209, data cost:0.18927082005829599 
2022-05-10 14:33:27,060: ============================================================
2022-05-10 14:33:27,060: Epoch 1/38 Batch 700/7662 eta: 1 day, 13:29:34.410943	Training Loss 0.8268 (0.8331)	Training Prec@1 0.195 (0.017)	Training Prec@5 0.195 (0.065)	
2022-05-10 14:33:27,060: ============================================================
2022-05-10 14:34:13,436: time cost, forward:0.1721196141797998, backward:0.1054076775442226, data cost:0.1892968134229562 
2022-05-10 14:34:13,436: ============================================================
2022-05-10 14:34:13,436: Epoch 1/38 Batch 800/7662 eta: 1 day, 13:24:16.589302	Training Loss 0.8203 (0.8320)	Training Prec@1 0.195 (0.022)	Training Prec@5 0.391 (0.083)	
2022-05-10 14:34:13,436: ============================================================
2022-05-10 14:34:59,831: time cost, forward:0.1719401935581636, backward:0.10523528649623985, data cost:0.189302212934738 
2022-05-10 14:34:59,831: ============================================================
2022-05-10 14:34:59,831: Epoch 1/38 Batch 900/7662 eta: 1 day, 13:24:24.048604	Training Loss 0.8194 (0.8307)	Training Prec@1 0.195 (0.034)	Training Prec@5 0.586 (0.119)	
2022-05-10 14:34:59,831: ============================================================
2022-05-10 14:35:46,055: time cost, forward:0.17167975188972237, backward:0.10508625858180874, data cost:0.18926303570454303 
2022-05-10 14:35:46,055: ============================================================
2022-05-10 14:35:46,056: Epoch 1/38 Batch 1000/7662 eta: 1 day, 13:15:23.670719	Training Loss 0.8140 (0.8294)	Training Prec@1 0.195 (0.048)	Training Prec@5 0.586 (0.159)	
2022-05-10 14:35:46,056: ============================================================
2022-05-10 14:36:32,250: time cost, forward:0.17148195601681127, backward:0.10496495787505132, data cost:0.18918677630263964 
2022-05-10 14:36:32,250: ============================================================
2022-05-10 14:36:32,251: Epoch 1/38 Batch 1100/7662 eta: 1 day, 13:13:11.772175	Training Loss 0.8156 (0.8281)	Training Prec@1 0.195 (0.067)	Training Prec@5 1.367 (0.204)	
2022-05-10 14:36:32,251: ============================================================
2022-05-10 14:37:18,556: time cost, forward:0.17139176690051514, backward:0.10487019846695875, data cost:0.18913577257145237 
2022-05-10 14:37:18,556: ============================================================
2022-05-10 14:37:18,556: Epoch 1/38 Batch 1200/7662 eta: 1 day, 13:17:46.898715	Training Loss 0.8094 (0.8267)	Training Prec@1 0.391 (0.095)	Training Prec@5 0.977 (0.271)	
2022-05-10 14:37:18,556: ============================================================
2022-05-10 14:38:04,946: time cost, forward:0.17134406751995365, backward:0.10479859648712604, data cost:0.1891208271323212 
2022-05-10 14:38:04,947: ============================================================
2022-05-10 14:38:04,947: Epoch 1/38 Batch 1300/7662 eta: 1 day, 13:21:05.856778	Training Loss 0.8049 (0.8253)	Training Prec@1 0.195 (0.122)	Training Prec@5 0.781 (0.346)	
2022-05-10 14:38:04,947: ============================================================
2022-05-10 14:38:51,304: time cost, forward:0.17128061702883696, backward:0.10473890011441801, data cost:0.18910431759625013 
2022-05-10 14:38:51,304: ============================================================
2022-05-10 14:38:51,305: Epoch 1/38 Batch 1400/7662 eta: 1 day, 13:18:44.800621	Training Loss 0.8033 (0.8238)	Training Prec@1 0.586 (0.161)	Training Prec@5 1.758 (0.443)	
2022-05-10 14:38:51,305: ============================================================
2022-05-10 14:39:37,690: time cost, forward:0.1712339980511605, backward:0.10469054189660376, data cost:0.18909759263820533 
2022-05-10 14:39:37,690: ============================================================
2022-05-10 14:39:37,690: Epoch 1/38 Batch 1500/7662 eta: 1 day, 13:19:19.500216	Training Loss 0.8009 (0.8223)	Training Prec@1 0.781 (0.210)	Training Prec@5 2.344 (0.559)	
2022-05-10 14:39:37,690: ============================================================
2022-05-10 14:40:24,057: time cost, forward:0.1711767864942998, backward:0.10464636141840855, data cost:0.1890983539793624 
2022-05-10 14:40:24,057: ============================================================
2022-05-10 14:40:24,057: Epoch 1/38 Batch 1600/7662 eta: 1 day, 13:17:38.966285	Training Loss 0.7934 (0.8207)	Training Prec@1 1.562 (0.277)	Training Prec@5 3.711 (0.704)	
2022-05-10 14:40:24,057: ============================================================
2022-05-10 14:41:10,482: time cost, forward:0.17115952871770562, backward:0.10460939598195759, data cost:0.1890969028046301 
2022-05-10 14:41:10,482: ============================================================
2022-05-10 14:41:10,482: Epoch 1/38 Batch 1700/7662 eta: 1 day, 13:19:39.963534	Training Loss 0.7909 (0.8191)	Training Prec@1 2.734 (0.359)	Training Prec@5 4.102 (0.882)	
2022-05-10 14:41:10,482: ============================================================
2022-05-10 14:41:56,908: time cost, forward:0.17114682884067878, backward:0.1045804916984045, data cost:0.18909169210865473 
2022-05-10 14:41:56,908: ============================================================
2022-05-10 14:41:56,908: Epoch 1/38 Batch 1800/7662 eta: 1 day, 13:18:57.762140	Training Loss 0.7863 (0.8174)	Training Prec@1 2.930 (0.460)	Training Prec@5 6.055 (1.095)	
2022-05-10 14:41:56,909: ============================================================
2022-05-10 14:42:43,290: time cost, forward:0.17109413357895886, backward:0.1045550841793002, data cost:0.18910355477536459 
2022-05-10 14:42:43,290: ============================================================
2022-05-10 14:42:43,291: Epoch 1/38 Batch 1900/7662 eta: 1 day, 13:16:03.385096	Training Loss 0.7877 (0.8157)	Training Prec@1 1.562 (0.577)	Training Prec@5 4.492 (1.333)	
2022-05-10 14:42:43,291: ============================================================
2022-05-10 14:43:29,654: time cost, forward:0.17104811785279542, backward:0.10453033793145505, data cost:0.1891066082243087 
2022-05-10 14:43:29,654: ============================================================
2022-05-10 14:43:29,654: Epoch 1/38 Batch 2000/7662 eta: 1 day, 13:14:23.683141	Training Loss 0.7754 (0.8139)	Training Prec@1 3.906 (0.723)	Training Prec@5 8.594 (1.611)	
2022-05-10 14:43:29,654: ============================================================
2022-05-10 14:44:16,039: time cost, forward:0.17101779036319728, backward:0.10450828876195492, data cost:0.1891078383312616 
2022-05-10 14:44:16,040: ============================================================
2022-05-10 14:44:16,040: Epoch 1/38 Batch 2100/7662 eta: 1 day, 13:14:41.462220	Training Loss 0.7679 (0.8120)	Training Prec@1 5.469 (0.884)	Training Prec@5 9.375 (1.919)	
2022-05-10 14:44:16,040: ============================================================
2022-05-10 14:45:02,516: time cost, forward:0.1710009256131327, backward:0.10450196472174908, data cost:0.18911535493782186 
2022-05-10 14:45:02,517: ============================================================
2022-05-10 14:45:02,517: Epoch 1/38 Batch 2200/7662 eta: 1 day, 13:18:18.537995	Training Loss 0.7640 (0.8101)	Training Prec@1 5.273 (1.071)	Training Prec@5 10.938 (2.270)	
2022-05-10 14:45:02,517: ============================================================
2022-05-10 14:45:49,079: time cost, forward:0.17096964283163726, backward:0.10455369576001593, data cost:0.18912747519179082 
2022-05-10 14:45:49,079: ============================================================
2022-05-10 14:45:49,079: Epoch 1/38 Batch 2300/7662 eta: 1 day, 13:21:38.398078	Training Loss 0.7635 (0.8081)	Training Prec@1 7.031 (1.285)	Training Prec@5 11.914 (2.660)	
2022-05-10 14:45:49,079: ============================================================
2022-05-10 14:46:35,628: time cost, forward:0.17094222085085348, backward:0.10459945270447693, data cost:0.189133010242521 
2022-05-10 14:46:35,629: ============================================================
2022-05-10 14:46:35,629: Epoch 1/38 Batch 2400/7662 eta: 1 day, 13:20:14.875656	Training Loss 0.7583 (0.8060)	Training Prec@1 7.617 (1.537)	Training Prec@5 14.062 (3.096)	
2022-05-10 14:46:35,629: ============================================================
2022-05-10 14:47:22,294: time cost, forward:0.17093328248505213, backward:0.10464224141805159, data cost:0.18916805652009339 
2022-05-10 14:47:22,294: ============================================================
2022-05-10 14:47:22,294: Epoch 1/38 Batch 2500/7662 eta: 1 day, 13:25:02.920360	Training Loss 0.7531 (0.8038)	Training Prec@1 7.617 (1.829)	Training Prec@5 13.867 (3.601)	
2022-05-10 14:47:22,294: ============================================================
2022-05-10 14:48:08,872: time cost, forward:0.17090699194761, backward:0.10468182640838916, data cost:0.18918430828139982 
2022-05-10 14:48:08,872: ============================================================
2022-05-10 14:48:08,873: Epoch 1/38 Batch 2600/7662 eta: 1 day, 13:20:05.588384	Training Loss 0.7415 (0.8015)	Training Prec@1 11.328 (2.177)	Training Prec@5 19.141 (4.168)	
2022-05-10 14:48:08,873: ============================================================
2022-05-10 14:48:55,440: time cost, forward:0.17087316689733312, backward:0.10472118744102837, data cost:0.1892025006970197 
2022-05-10 14:48:55,441: ============================================================
2022-05-10 14:48:55,441: Epoch 1/38 Batch 2700/7662 eta: 1 day, 13:18:49.473015	Training Loss 0.7293 (0.7991)	Training Prec@1 12.109 (2.570)	Training Prec@5 22.070 (4.794)	
2022-05-10 14:48:55,441: ============================================================
2022-05-10 14:49:42,059: time cost, forward:0.1708565850307278, backward:0.10475676431959124, data cost:0.18922135973879592 
2022-05-10 14:49:42,060: ============================================================
2022-05-10 14:49:42,060: Epoch 1/38 Batch 2800/7662 eta: 1 day, 13:20:28.502775	Training Loss 0.7184 (0.7966)	Training Prec@1 16.992 (3.005)	Training Prec@5 28.125 (5.461)	
2022-05-10 14:49:42,060: ============================================================
2022-05-10 14:50:28,557: time cost, forward:0.17083786495310063, backward:0.10476004119246694, data cost:0.18923231427856213 
2022-05-10 14:50:28,557: ============================================================
2022-05-10 14:50:28,557: Epoch 1/38 Batch 2900/7662 eta: 1 day, 13:13:52.863336	Training Loss 0.7156 (0.7940)	Training Prec@1 20.508 (3.490)	Training Prec@5 29.297 (6.182)	
2022-05-10 14:50:28,558: ============================================================
2022-05-10 14:51:15,074: time cost, forward:0.17083903605558745, backward:0.10473950086493777, data cost:0.1892536971997563 
2022-05-10 14:51:15,074: ============================================================
2022-05-10 14:51:15,075: Epoch 1/38 Batch 3000/7662 eta: 1 day, 13:14:02.734243	Training Loss 0.7082 (0.7913)	Training Prec@1 21.289 (4.039)	Training Prec@5 31.250 (6.981)	
2022-05-10 14:51:15,075: ============================================================
2022-05-10 14:52:01,640: time cost, forward:0.17084652841302725, backward:0.10472031438223736, data cost:0.18928152386239744 
2022-05-10 14:52:01,641: ============================================================
2022-05-10 14:52:01,641: Epoch 1/38 Batch 3100/7662 eta: 1 day, 13:15:37.366360	Training Loss 0.6981 (0.7884)	Training Prec@1 25.000 (4.655)	Training Prec@5 35.547 (7.843)	
2022-05-10 14:52:01,641: ============================================================
2022-05-10 14:52:48,206: time cost, forward:0.17083867209596387, backward:0.10470339841267287, data cost:0.18932475504110516 
2022-05-10 14:52:48,207: ============================================================
2022-05-10 14:52:48,207: Epoch 1/38 Batch 3200/7662 eta: 1 day, 13:14:50.034607	Training Loss 0.6834 (0.7855)	Training Prec@1 28.516 (5.304)	Training Prec@5 41.016 (8.739)	
2022-05-10 14:52:48,207: ============================================================
2022-05-10 14:53:34,787: time cost, forward:0.17084023012252025, backward:0.10468911344118283, data cost:0.18935669014113496 
2022-05-10 14:53:34,787: ============================================================
2022-05-10 14:53:34,787: Epoch 1/38 Batch 3300/7662 eta: 1 day, 13:14:44.890527	Training Loss 0.6857 (0.7824)	Training Prec@1 29.297 (6.001)	Training Prec@5 38.477 (9.679)	
2022-05-10 14:53:34,787: ============================================================
2022-05-10 14:54:21,454: time cost, forward:0.17087040385206717, backward:0.10467544945943844, data cost:0.1893860469603756 
2022-05-10 14:54:21,454: ============================================================
2022-05-10 14:54:21,454: Epoch 1/38 Batch 3400/7662 eta: 1 day, 13:18:07.529848	Training Loss 0.6781 (0.7793)	Training Prec@1 31.445 (6.758)	Training Prec@5 45.508 (10.683)	
2022-05-10 14:54:21,454: ============================================================
2022-05-10 14:55:08,051: time cost, forward:0.1708754152187316, backward:0.10466224883549143, data cost:0.1894128293982912 
2022-05-10 14:55:08,052: ============================================================
2022-05-10 14:55:08,052: Epoch 1/38 Batch 3500/7662 eta: 1 day, 13:14:01.529771	Training Loss 0.6613 (0.7761)	Training Prec@1 34.180 (7.544)	Training Prec@5 47.266 (11.703)	
2022-05-10 14:55:08,052: ============================================================
2022-05-10 14:55:54,617: time cost, forward:0.17088574957734978, backward:0.10465109669589175, data cost:0.18942572004631447 
2022-05-10 14:55:54,617: ============================================================
2022-05-10 14:55:54,617: Epoch 1/38 Batch 3600/7662 eta: 1 day, 13:11:41.121520	Training Loss 0.6467 (0.7728)	Training Prec@1 40.039 (8.373)	Training Prec@5 52.148 (12.751)	
2022-05-10 14:55:54,617: ============================================================
2022-05-10 14:56:41,181: time cost, forward:0.17089038373457802, backward:0.10463853860810242, data cost:0.18943799054438953 
2022-05-10 14:56:41,182: ============================================================
2022-05-10 14:56:41,182: Epoch 1/38 Batch 3700/7662 eta: 1 day, 13:10:53.415340	Training Loss 0.6413 (0.7695)	Training Prec@1 43.359 (9.238)	Training Prec@5 55.273 (13.822)	
2022-05-10 14:56:41,182: ============================================================
2022-05-10 14:57:27,631: time cost, forward:0.1708839630635044, backward:0.10462573842959644, data cost:0.18943788685840066 
2022-05-10 14:57:27,632: ============================================================
2022-05-10 14:57:27,632: Epoch 1/38 Batch 3800/7662 eta: 1 day, 13:04:37.346505	Training Loss 0.6376 (0.7661)	Training Prec@1 44.922 (10.120)	Training Prec@5 58.789 (14.905)	
2022-05-10 14:57:27,632: ============================================================
2022-05-10 14:58:14,112: time cost, forward:0.17087811334037145, backward:0.10461462378715912, data cost:0.1894445581355441 
2022-05-10 14:58:14,112: ============================================================
2022-05-10 14:58:14,112: Epoch 1/38 Batch 3900/7662 eta: 1 day, 13:05:18.046037	Training Loss 0.6294 (0.7627)	Training Prec@1 47.266 (11.026)	Training Prec@5 58.789 (15.994)	
2022-05-10 14:58:14,112: ============================================================
2022-05-10 14:59:00,579: time cost, forward:0.17086917938486162, backward:0.10460227732361481, data cost:0.1894518257111542 
2022-05-10 14:59:00,579: ============================================================
2022-05-10 14:59:00,579: Epoch 1/38 Batch 4000/7662 eta: 1 day, 13:03:53.435595	Training Loss 0.6305 (0.7592)	Training Prec@1 47.461 (11.952)	Training Prec@5 57.812 (17.099)	
2022-05-10 14:59:00,579: ============================================================
2022-05-10 14:59:47,099: time cost, forward:0.1708681862015176, backward:0.10459314354689245, data cost:0.1894622647666326 
2022-05-10 14:59:47,099: ============================================================
2022-05-10 14:59:47,099: Epoch 1/38 Batch 4100/7662 eta: 1 day, 13:05:38.589888	Training Loss 0.6030 (0.7558)	Training Prec@1 55.664 (12.892)	Training Prec@5 65.625 (18.200)	
2022-05-10 14:59:47,099: ============================================================
2022-05-10 15:00:33,789: time cost, forward:0.17086569801288776, backward:0.10461813581929544, data cost:0.1894806999625351 
2022-05-10 15:00:33,789: ============================================================
2022-05-10 15:00:33,789: Epoch 1/38 Batch 4200/7662 eta: 1 day, 13:13:01.093030	Training Loss 0.5995 (0.7524)	Training Prec@1 55.078 (13.832)	Training Prec@5 65.234 (19.288)	
2022-05-10 15:00:33,789: ============================================================
2022-05-10 15:01:20,294: time cost, forward:0.17086241433276053, backward:0.10460997021567076, data cost:0.18948860516740046 
2022-05-10 15:01:20,295: ============================================================
2022-05-10 15:01:20,295: Epoch 1/38 Batch 4300/7662 eta: 1 day, 13:03:24.055982	Training Loss 0.5940 (0.7489)	Training Prec@1 55.664 (14.787)	Training Prec@5 69.336 (20.378)	
2022-05-10 15:01:20,295: ============================================================
2022-05-10 15:02:06,851: time cost, forward:0.17086655260568642, backward:0.10460107254423752, data cost:0.18949760965770904 
2022-05-10 15:02:06,852: ============================================================
2022-05-10 15:02:06,852: Epoch 1/38 Batch 4400/7662 eta: 1 day, 13:05:05.736575	Training Loss 0.6003 (0.7455)	Training Prec@1 54.492 (15.738)	Training Prec@5 66.406 (21.459)	
2022-05-10 15:02:06,852: ============================================================
2022-05-10 15:02:53,358: time cost, forward:0.1708711139041335, backward:0.1045911224133758, data cost:0.18949984937117983 
2022-05-10 15:02:53,358: ============================================================
2022-05-10 15:02:53,359: Epoch 1/38 Batch 4500/7662 eta: 1 day, 13:01:54.763756	Training Loss 0.5824 (0.7421)	Training Prec@1 59.180 (16.683)	Training Prec@5 70.703 (22.523)	
2022-05-10 15:02:53,359: ============================================================
2022-05-10 15:03:39,861: time cost, forward:0.17087786766362464, backward:0.1045840324124815, data cost:0.18949576408144028 
2022-05-10 15:03:39,861: ============================================================
2022-05-10 15:03:39,862: Epoch 1/38 Batch 4600/7662 eta: 1 day, 13:00:57.596988	Training Loss 0.5749 (0.7387)	Training Prec@1 61.523 (17.623)	Training Prec@5 71.680 (23.573)	
2022-05-10 15:03:39,862: ============================================================
2022-05-10 15:04:26,333: time cost, forward:0.1708827543370291, backward:0.10457420354194909, data cost:0.18948984298332622 
2022-05-10 15:04:26,333: ============================================================
2022-05-10 15:04:26,333: Epoch 1/38 Batch 4700/7662 eta: 1 day, 12:58:41.398605	Training Loss 0.5659 (0.7353)	Training Prec@1 66.016 (18.563)	Training Prec@5 76.367 (24.607)	
2022-05-10 15:04:26,333: ============================================================
2022-05-10 15:05:12,786: time cost, forward:0.17088385789835048, backward:0.10456570502891468, data cost:0.1894825419477434 
2022-05-10 15:05:12,786: ============================================================
2022-05-10 15:05:12,786: Epoch 1/38 Batch 4800/7662 eta: 1 day, 12:57:01.581944	Training Loss 0.5651 (0.7320)	Training Prec@1 66.797 (19.488)	Training Prec@5 76.562 (25.623)	
2022-05-10 15:05:12,786: ============================================================
2022-05-10 15:05:59,229: time cost, forward:0.17088016823229193, backward:0.10455885875660635, data cost:0.1894775346532893 
2022-05-10 15:05:59,229: ============================================================
2022-05-10 15:05:59,229: Epoch 1/38 Batch 4900/7662 eta: 1 day, 12:55:46.450662	Training Loss 0.5680 (0.7287)	Training Prec@1 63.086 (20.402)	Training Prec@5 72.852 (26.624)	
2022-05-10 15:05:59,229: ============================================================
2022-05-10 15:06:45,714: time cost, forward:0.17088423850274512, backward:0.10455216019362014, data cost:0.18947391200957478 
2022-05-10 15:06:45,714: ============================================================
2022-05-10 15:06:45,714: Epoch 1/38 Batch 5000/7662 eta: 1 day, 12:56:59.926279	Training Loss 0.5612 (0.7254)	Training Prec@1 68.164 (21.313)	Training Prec@5 78.516 (27.608)	
2022-05-10 15:06:45,714: ============================================================
2022-05-10 15:07:32,174: time cost, forward:0.1708843403176762, backward:0.10454558203982053, data cost:0.18946975398283422 
2022-05-10 15:07:32,174: ============================================================
2022-05-10 15:07:32,174: Epoch 1/38 Batch 5100/7662 eta: 1 day, 12:55:02.114364	Training Loss 0.5548 (0.7222)	Training Prec@1 67.773 (22.207)	Training Prec@5 77.734 (28.570)	
2022-05-10 15:07:32,174: ============================================================
2022-05-10 15:08:18,707: time cost, forward:0.17089975937257984, backward:0.10453905887754175, data cost:0.18946453373485814 
2022-05-10 15:08:18,707: ============================================================
2022-05-10 15:08:18,707: Epoch 1/38 Batch 5200/7662 eta: 1 day, 12:57:43.697877	Training Loss 0.5673 (0.7190)	Training Prec@1 66.797 (23.082)	Training Prec@5 76.758 (29.507)	
2022-05-10 15:08:18,707: ============================================================
2022-05-10 15:09:05,227: time cost, forward:0.17091087112563538, backward:0.10453146015569655, data cost:0.18946192682543034 
2022-05-10 15:09:05,227: ============================================================
2022-05-10 15:09:05,228: Epoch 1/38 Batch 5300/7662 eta: 1 day, 12:56:22.264325	Training Loss 0.5553 (0.7158)	Training Prec@1 68.945 (23.955)	Training Prec@5 76.367 (30.434)	
2022-05-10 15:09:05,228: ============================================================
2022-05-10 15:09:51,766: time cost, forward:0.17092804803652198, backward:0.10452406228438729, data cost:0.1894565567437709 
2022-05-10 15:09:51,767: ============================================================
2022-05-10 15:09:51,767: Epoch 1/38 Batch 5400/7662 eta: 1 day, 12:56:28.604301	Training Loss 0.5549 (0.7127)	Training Prec@1 68.750 (24.808)	Training Prec@5 77.148 (31.339)	
2022-05-10 15:09:51,767: ============================================================
2022-05-10 15:10:38,305: time cost, forward:0.17094339269099398, backward:0.10451740354901119, data cost:0.18945216985155527 
2022-05-10 15:10:38,305: ============================================================
2022-05-10 15:10:38,305: Epoch 1/38 Batch 5500/7662 eta: 1 day, 12:55:39.903565	Training Loss 0.5389 (0.7097)	Training Prec@1 70.703 (25.645)	Training Prec@5 81.445 (32.223)	
2022-05-10 15:10:38,305: ============================================================
2022-05-10 15:11:24,793: time cost, forward:0.17095115572709146, backward:0.10451044630080296, data cost:0.18944648602835343 
2022-05-10 15:11:24,793: ============================================================
2022-05-10 15:11:24,793: Epoch 1/38 Batch 5600/7662 eta: 1 day, 12:52:30.658390	Training Loss 0.5356 (0.7067)	Training Prec@1 70.703 (26.465)	Training Prec@5 79.297 (33.082)	
2022-05-10 15:11:24,793: ============================================================
2022-05-10 15:12:11,285: time cost, forward:0.17095887809495044, backward:0.10450325934253966, data cost:0.18944204374454926 
2022-05-10 15:12:11,286: ============================================================
2022-05-10 15:12:11,286: Epoch 1/38 Batch 5700/7662 eta: 1 day, 12:51:55.810071	Training Loss 0.5430 (0.7037)	Training Prec@1 74.609 (27.271)	Training Prec@5 81.055 (33.924)	
2022-05-10 15:12:11,286: ============================================================
2022-05-10 15:12:57,797: time cost, forward:0.17096923182474824, backward:0.10449664320158823, data cost:0.18943778468239078 
2022-05-10 15:12:57,797: ============================================================
2022-05-10 15:12:57,797: Epoch 1/38 Batch 5800/7662 eta: 1 day, 12:52:03.496193	Training Loss 0.5324 (0.7008)	Training Prec@1 76.953 (28.063)	Training Prec@5 84.766 (34.748)	
2022-05-10 15:12:57,797: ============================================================
2022-05-10 15:13:44,324: time cost, forward:0.17098020428135186, backward:0.10449118552763273, data cost:0.18943412361720555 
2022-05-10 15:13:44,324: ============================================================
2022-05-10 15:13:44,324: Epoch 1/38 Batch 5900/7662 eta: 1 day, 12:52:01.810573	Training Loss 0.5285 (0.6980)	Training Prec@1 74.023 (28.844)	Training Prec@5 82.422 (35.564)	
2022-05-10 15:13:44,324: ============================================================
2022-05-10 15:14:30,852: time cost, forward:0.1709883217414949, backward:0.10448735367160854, data cost:0.18943156741384387 
2022-05-10 15:14:30,852: ============================================================
2022-05-10 15:14:30,852: Epoch 1/38 Batch 6000/7662 eta: 1 day, 12:51:17.257127	Training Loss 0.5388 (0.6951)	Training Prec@1 71.289 (29.606)	Training Prec@5 79.883 (36.351)	
2022-05-10 15:14:30,852: ============================================================
2022-05-10 15:15:17,348: time cost, forward:0.17099204143943855, backward:0.10448252980797813, data cost:0.18942926840462398 
2022-05-10 15:15:17,348: ============================================================
2022-05-10 15:15:17,348: Epoch 1/38 Batch 6100/7662 eta: 1 day, 12:49:00.814438	Training Loss 0.5339 (0.6923)	Training Prec@1 76.367 (30.354)	Training Prec@5 83.789 (37.124)	
2022-05-10 15:15:17,348: ============================================================
2022-05-10 15:16:03,853: time cost, forward:0.170998421536855, backward:0.10447678605978249, data cost:0.18942657134709465 
2022-05-10 15:16:03,853: ============================================================
2022-05-10 15:16:03,853: Epoch 1/38 Batch 6200/7662 eta: 1 day, 12:48:38.448778	Training Loss 0.5249 (0.6896)	Training Prec@1 76.172 (31.092)	Training Prec@5 84.766 (37.885)	
2022-05-10 15:16:03,853: ============================================================
2022-05-10 15:16:50,384: time cost, forward:0.17101097973703788, backward:0.10447125386427197, data cost:0.18942210670122364 
2022-05-10 15:16:50,385: ============================================================
2022-05-10 15:16:50,385: Epoch 1/38 Batch 6300/7662 eta: 1 day, 12:49:09.370106	Training Loss 0.5193 (0.6869)	Training Prec@1 78.320 (31.810)	Training Prec@5 86.133 (38.621)	
2022-05-10 15:16:50,385: ============================================================
2022-05-10 15:17:36,843: time cost, forward:0.17101201617656267, backward:0.1044662193239322, data cost:0.18941735252586636 
2022-05-10 15:17:36,843: ============================================================
2022-05-10 15:17:36,843: Epoch 1/38 Batch 6400/7662 eta: 1 day, 12:44:53.550872	Training Loss 0.5187 (0.6842)	Training Prec@1 77.344 (32.514)	Training Prec@5 83.984 (39.342)	
2022-05-10 15:17:36,843: ============================================================
2022-05-10 15:18:23,358: time cost, forward:0.1710223463025895, backward:0.1044611436694489, data cost:0.18941217236270133 
2022-05-10 15:18:23,358: ============================================================
2022-05-10 15:18:23,358: Epoch 1/38 Batch 6500/7662 eta: 1 day, 12:46:47.664302	Training Loss 0.5085 (0.6816)	Training Prec@1 78.711 (33.213)	Training Prec@5 85.547 (40.052)	
2022-05-10 15:18:23,358: ============================================================
2022-05-10 15:19:09,816: time cost, forward:0.17102037283268312, backward:0.10445706225431477, data cost:0.1894097381296402 
2022-05-10 15:19:09,816: ============================================================
2022-05-10 15:19:09,817: Epoch 1/38 Batch 6600/7662 eta: 1 day, 12:43:20.673418	Training Loss 0.5020 (0.6790)	Training Prec@1 81.836 (33.891)	Training Prec@5 87.500 (40.742)	
2022-05-10 15:19:09,817: ============================================================
2022-05-10 15:19:56,307: time cost, forward:0.17102221589174568, backward:0.10445382310696762, data cost:0.1894078686408524 
2022-05-10 15:19:56,308: ============================================================
2022-05-10 15:19:56,308: Epoch 1/38 Batch 6700/7662 eta: 1 day, 12:44:07.581889	Training Loss 0.5038 (0.6765)	Training Prec@1 82.031 (34.559)	Training Prec@5 87.305 (41.418)	
2022-05-10 15:19:56,308: ============================================================
2022-05-10 15:20:42,754: time cost, forward:0.17101890175706203, backward:0.10444931567355208, data cost:0.18940594740204292 
2022-05-10 15:20:42,754: ============================================================
2022-05-10 15:20:42,754: Epoch 1/38 Batch 6800/7662 eta: 1 day, 12:41:13.823337	Training Loss 0.5039 (0.6740)	Training Prec@1 78.320 (35.214)	Training Prec@5 84.961 (42.081)	
2022-05-10 15:20:42,754: ============================================================
2022-05-10 15:21:29,254: time cost, forward:0.17102530732122362, backward:0.1044445524078847, data cost:0.18940273152345988 
2022-05-10 15:21:29,254: ============================================================
2022-05-10 15:21:29,254: Epoch 1/38 Batch 6900/7662 eta: 1 day, 12:42:59.027206	Training Loss 0.5047 (0.6715)	Training Prec@1 79.297 (35.850)	Training Prec@5 86.133 (42.725)	
2022-05-10 15:21:29,254: ============================================================
2022-05-10 15:22:15,684: time cost, forward:0.17102068171260662, backward:0.10444054141659824, data cost:0.18939975974116602 
2022-05-10 15:22:15,684: ============================================================
2022-05-10 15:22:15,684: Epoch 1/38 Batch 7000/7662 eta: 1 day, 12:38:54.009249	Training Loss 0.5051 (0.6691)	Training Prec@1 79.688 (36.475)	Training Prec@5 86.719 (43.356)	
2022-05-10 15:22:15,684: ============================================================
2022-05-10 15:23:02,072: time cost, forward:0.17101048341786834, backward:0.10443666475325307, data cost:0.18939667645433048 
2022-05-10 15:23:02,072: ============================================================
2022-05-10 15:23:02,072: Epoch 1/38 Batch 7100/7662 eta: 1 day, 12:36:08.907052	Training Loss 0.5104 (0.6667)	Training Prec@1 78.711 (37.087)	Training Prec@5 87.305 (43.973)	
2022-05-10 15:23:02,072: ============================================================
2022-05-10 15:23:48,478: time cost, forward:0.17100276624449326, backward:0.10443376123714752, data cost:0.18939330959041875 
2022-05-10 15:23:48,478: ============================================================
2022-05-10 15:23:48,478: Epoch 1/38 Batch 7200/7662 eta: 1 day, 12:36:13.642986	Training Loss 0.5036 (0.6644)	Training Prec@1 77.930 (37.689)	Training Prec@5 85.938 (44.577)	
2022-05-10 15:23:48,479: ============================================================
2022-05-10 15:24:34,964: time cost, forward:0.17099944002449652, backward:0.10442990860819473, data cost:0.18939745427811205 
2022-05-10 15:24:34,965: ============================================================
2022-05-10 15:24:34,965: Epoch 1/38 Batch 7300/7662 eta: 1 day, 12:39:14.896072	Training Loss 0.4913 (0.6620)	Training Prec@1 82.422 (38.280)	Training Prec@5 89.062 (45.167)	
2022-05-10 15:24:34,965: ============================================================
2022-05-10 15:25:21,422: time cost, forward:0.1709947387565389, backward:0.10442665529051315, data cost:0.18939861785335982 
2022-05-10 15:25:21,423: ============================================================
2022-05-10 15:25:21,423: Epoch 1/38 Batch 7400/7662 eta: 1 day, 12:37:07.264031	Training Loss 0.5010 (0.6598)	Training Prec@1 79.883 (38.860)	Training Prec@5 86.523 (45.747)	
2022-05-10 15:25:21,423: ============================================================
2022-05-10 15:26:07,871: time cost, forward:0.17098399234908568, backward:0.1044230925939865, data cost:0.18940337687623487 
2022-05-10 15:26:07,871: ============================================================
2022-05-10 15:26:07,872: Epoch 1/38 Batch 7500/7662 eta: 1 day, 12:35:55.553523	Training Loss 0.4903 (0.6575)	Training Prec@1 81.055 (39.428)	Training Prec@5 85.938 (46.315)	
2022-05-10 15:26:07,872: ============================================================
2022-05-10 15:26:54,286: time cost, forward:0.17096795614086682, backward:0.10441974452144615, data cost:0.18941104680335055 
2022-05-10 15:26:54,286: ============================================================
2022-05-10 15:26:54,287: Epoch 1/38 Batch 7600/7662 eta: 1 day, 12:33:32.740767	Training Loss 0.4951 (0.6553)	Training Prec@1 81.250 (39.988)	Training Prec@5 86.328 (46.871)	
2022-05-10 15:26:54,287: ============================================================
2022-05-10 15:27:24,452: Epoch: 1/38 eta: 1 day, 12:33:03.499371	Training Loss 0.4729 (0.6539)	Training Prec@1 83.398 (40.337)	Training Prec@5 88.867 (47.217)
2022-05-10 15:27:24,452: ============================================================
2022-05-10 15:28:12,966: time cost, forward:0.17577422508085616, backward:0.1041895355841126, data cost:0.2068864456330887 
2022-05-10 15:28:12,967: ============================================================
2022-05-10 15:28:12,967: Epoch 2/38 Batch 100/7662 eta: 1 day, 14:06:45.691169	Training Loss 0.4620 (0.4675)	Training Prec@1 87.109 (85.168)	Training Prec@5 91.797 (90.917)	
2022-05-10 15:28:12,967: ============================================================
2022-05-10 15:28:59,472: time cost, forward:0.17331662729157873, backward:0.10416625851961836, data cost:0.1982735401421935 
2022-05-10 15:28:59,472: ============================================================
2022-05-10 15:28:59,472: Epoch 2/38 Batch 200/7662 eta: 1 day, 12:35:47.088448	Training Loss 0.4667 (0.4693)	Training Prec@1 85.938 (85.156)	Training Prec@5 91.992 (90.972)	
2022-05-10 15:28:59,472: ============================================================
2022-05-10 15:29:45,861: time cost, forward:0.17212449906263064, backward:0.10415646383993601, data cost:0.19542095653189465 
2022-05-10 15:29:45,861: ============================================================
2022-05-10 15:29:45,861: Epoch 2/38 Batch 300/7662 eta: 1 day, 12:29:31.763199	Training Loss 0.4821 (0.4700)	Training Prec@1 85.156 (85.025)	Training Prec@5 90.039 (90.885)	
2022-05-10 15:29:45,861: ============================================================
2022-05-10 15:30:32,256: time cost, forward:0.1715520963931741, backward:0.10415436450700115, data cost:0.19398699607466696 
2022-05-10 15:30:32,256: ============================================================
2022-05-10 15:30:32,256: Epoch 2/38 Batch 400/7662 eta: 1 day, 12:29:01.814504	Training Loss 0.4635 (0.4707)	Training Prec@1 86.719 (84.941)	Training Prec@5 92.188 (90.817)	
2022-05-10 15:30:32,256: ============================================================
2022-05-10 15:31:18,724: time cost, forward:0.17126516827600513, backward:0.10414843759938089, data cost:0.19322031389974162 
2022-05-10 15:31:18,724: ============================================================
2022-05-10 15:31:18,724: Epoch 2/38 Batch 500/7662 eta: 1 day, 12:31:42.023981	Training Loss 0.4666 (0.4712)	Training Prec@1 85.156 (84.850)	Training Prec@5 90.234 (90.741)	
2022-05-10 15:31:18,724: ============================================================
2022-05-10 15:32:05,112: time cost, forward:0.17105200573279583, backward:0.10415706093203843, data cost:0.19258871779019923 
2022-05-10 15:32:05,113: ============================================================
2022-05-10 15:32:05,113: Epoch 2/38 Batch 600/7662 eta: 1 day, 12:27:11.449133	Training Loss 0.4806 (0.4715)	Training Prec@1 81.055 (84.846)	Training Prec@5 88.477 (90.738)	
2022-05-10 15:32:05,113: ============================================================
2022-05-10 15:32:51,549: time cost, forward:0.1709480497117377, backward:0.10415336945878931, data cost:0.19217015063131657 
2022-05-10 15:32:51,549: ============================================================
2022-05-10 15:32:51,550: Epoch 2/38 Batch 700/7662 eta: 1 day, 12:28:40.368726	Training Loss 0.4649 (0.4716)	Training Prec@1 86.133 (84.828)	Training Prec@5 91.992 (90.723)	
2022-05-10 15:32:51,550: ============================================================
2022-05-10 15:33:37,931: time cost, forward:0.17085051536560059, backward:0.10415188242705803, data cost:0.1918058872819693 
2022-05-10 15:33:37,931: ============================================================
2022-05-10 15:33:37,931: Epoch 2/38 Batch 800/7662 eta: 1 day, 12:25:18.910706	Training Loss 0.4713 (0.4715)	Training Prec@1 84.375 (84.793)	Training Prec@5 90.430 (90.708)	
2022-05-10 15:33:37,931: ============================================================
2022-05-10 15:34:24,331: time cost, forward:0.17078609434728229, backward:0.1041501753852683, data cost:0.19153239464468103 
2022-05-10 15:34:24,331: ============================================================
2022-05-10 15:34:24,332: Epoch 2/38 Batch 900/7662 eta: 1 day, 12:25:25.204773	Training Loss 0.4735 (0.4712)	Training Prec@1 84.961 (84.817)	Training Prec@5 90.625 (90.721)	
2022-05-10 15:34:24,332: ============================================================
2022-05-10 15:35:10,725: time cost, forward:0.17071035913041643, backward:0.10415272645883493, data cost:0.19132765659221537 
2022-05-10 15:35:10,726: ============================================================
2022-05-10 15:35:10,726: Epoch 2/38 Batch 1000/7662 eta: 1 day, 12:24:20.801844	Training Loss 0.4663 (0.4709)	Training Prec@1 84.570 (84.832)	Training Prec@5 91.016 (90.734)	
2022-05-10 15:35:10,726: ============================================================
2022-05-10 15:35:57,161: time cost, forward:0.17065309350115263, backward:0.104157144530889, data cost:0.19119139277360134 
2022-05-10 15:35:57,162: ============================================================
2022-05-10 15:35:57,162: Epoch 2/38 Batch 1100/7662 eta: 1 day, 12:25:33.478440	Training Loss 0.4696 (0.4707)	Training Prec@1 85.742 (84.859)	Training Prec@5 90.039 (90.745)	
2022-05-10 15:35:57,162: ============================================================
2022-05-10 15:36:43,562: time cost, forward:0.1706073900577523, backward:0.10416480339597523, data cost:0.19104306154990813 
2022-05-10 15:36:43,562: ============================================================
2022-05-10 15:36:43,562: Epoch 2/38 Batch 1200/7662 eta: 1 day, 12:23:05.670423	Training Loss 0.4583 (0.4704)	Training Prec@1 86.719 (84.884)	Training Prec@5 91.406 (90.763)	
2022-05-10 15:36:43,562: ============================================================
2022-05-10 15:37:29,980: time cost, forward:0.1705776448429686, backward:0.10417276698869407, data cost:0.1909185450658879 
2022-05-10 15:37:29,980: ============================================================
2022-05-10 15:37:29,981: Epoch 2/38 Batch 1300/7662 eta: 1 day, 12:23:10.129514	Training Loss 0.4496 (0.4700)	Training Prec@1 87.891 (84.910)	Training Prec@5 93.555 (90.792)	
2022-05-10 15:37:29,981: ============================================================
2022-05-10 15:38:16,391: time cost, forward:0.17055049753768517, backward:0.104167762869507, data cost:0.19081374284963765 
2022-05-10 15:38:16,392: ============================================================
2022-05-10 15:38:16,392: Epoch 2/38 Batch 1400/7662 eta: 1 day, 12:22:04.246453	Training Loss 0.4688 (0.4696)	Training Prec@1 83.203 (84.939)	Training Prec@5 90.039 (90.807)	
2022-05-10 15:38:16,392: ============================================================
2022-05-10 15:39:02,792: time cost, forward:0.1705330256385116, backward:0.10416105988027256, data cost:0.19071938325119783 
2022-05-10 15:39:02,792: ============================================================
2022-05-10 15:39:02,792: Epoch 2/38 Batch 1500/7662 eta: 1 day, 12:20:46.279986	Training Loss 0.4614 (0.4691)	Training Prec@1 84.766 (84.980)	Training Prec@5 91.211 (90.836)	
2022-05-10 15:39:02,792: ============================================================
2022-05-10 15:39:49,193: time cost, forward:0.17051531375386403, backward:0.10415871729322938, data cost:0.19063356460967312 
2022-05-10 15:39:49,194: ============================================================
2022-05-10 15:39:49,194: Epoch 2/38 Batch 1600/7662 eta: 1 day, 12:20:04.150233	Training Loss 0.4623 (0.4688)	Training Prec@1 84.570 (85.013)	Training Prec@5 89.844 (90.853)	
2022-05-10 15:39:49,194: ============================================================
2022-05-10 15:40:35,662: time cost, forward:0.17052992446903906, backward:0.10415636363486952, data cost:0.19056924698702232 
2022-05-10 15:40:35,662: ============================================================
2022-05-10 15:40:35,662: Epoch 2/38 Batch 1700/7662 eta: 1 day, 12:22:25.011696	Training Loss 0.4610 (0.4683)	Training Prec@1 85.352 (85.062)	Training Prec@5 90.625 (90.876)	
2022-05-10 15:40:35,662: ============================================================
2022-05-10 15:41:22,170: time cost, forward:0.17055175846453968, backward:0.10415465424894425, data cost:0.19052433172419975 
2022-05-10 15:41:22,170: ============================================================
2022-05-10 15:41:22,170: Epoch 2/38 Batch 1800/7662 eta: 1 day, 12:23:31.702954	Training Loss 0.4613 (0.4679)	Training Prec@1 84.180 (85.102)	Training Prec@5 90.625 (90.908)	
2022-05-10 15:41:22,171: ============================================================
2022-05-10 15:42:08,653: time cost, forward:0.1705703682620755, backward:0.10415478905230337, data cost:0.1904708894696469 
2022-05-10 15:42:08,653: ============================================================
2022-05-10 15:42:08,653: Epoch 2/38 Batch 1900/7662 eta: 1 day, 12:21:33.362870	Training Loss 0.4623 (0.4673)	Training Prec@1 85.938 (85.162)	Training Prec@5 92.578 (90.950)	
2022-05-10 15:42:08,653: ============================================================
2022-05-10 15:42:55,083: time cost, forward:0.1705621396857181, backward:0.10415778868552623, data cost:0.19041855708547328 
2022-05-10 15:42:55,084: ============================================================
2022-05-10 15:42:55,084: Epoch 2/38 Batch 2000/7662 eta: 1 day, 12:18:19.826663	Training Loss 0.4572 (0.4668)	Training Prec@1 87.500 (85.196)	Training Prec@5 93.164 (90.981)	
2022-05-10 15:42:55,084: ============================================================
2022-05-10 15:43:41,517: time cost, forward:0.17054950560542048, backward:0.10416238997424426, data cost:0.19037061875749053 
2022-05-10 15:43:41,518: ============================================================
2022-05-10 15:43:41,518: Epoch 2/38 Batch 2100/7662 eta: 1 day, 12:17:42.671895	Training Loss 0.4501 (0.4664)	Training Prec@1 87.109 (85.243)	Training Prec@5 93.359 (91.018)	
2022-05-10 15:43:41,518: ============================================================
2022-05-10 15:44:27,998: time cost, forward:0.170550354506114, backward:0.10416753414599882, data cost:0.19034041486690673 
2022-05-10 15:44:27,999: ============================================================
2022-05-10 15:44:27,999: Epoch 2/38 Batch 2200/7662 eta: 1 day, 12:19:08.840129	Training Loss 0.4675 (0.4659)	Training Prec@1 86.328 (85.289)	Training Prec@5 92.188 (91.047)	
2022-05-10 15:44:27,999: ============================================================
2022-05-10 15:45:14,466: time cost, forward:0.1705402591633973, backward:0.10417000030942355, data cost:0.19031975838659948 
2022-05-10 15:45:14,466: ============================================================
2022-05-10 15:45:14,466: Epoch 2/38 Batch 2300/7662 eta: 1 day, 12:17:44.458172	Training Loss 0.4508 (0.4654)	Training Prec@1 86.133 (85.336)	Training Prec@5 90.625 (91.087)	
2022-05-10 15:45:14,466: ============================================================
2022-05-10 15:46:00,918: time cost, forward:0.17052948847568347, backward:0.10417302989522434, data cost:0.19029544750418748 
2022-05-10 15:46:00,919: ============================================================
2022-05-10 15:46:00,919: Epoch 2/38 Batch 2400/7662 eta: 1 day, 12:16:15.706104	Training Loss 0.4536 (0.4649)	Training Prec@1 86.523 (85.395)	Training Prec@5 90.039 (91.128)	
2022-05-10 15:46:00,919: ============================================================
2022-05-10 15:46:47,403: time cost, forward:0.1705216539053976, backward:0.1041744210425259, data cost:0.19028064965152322 
2022-05-10 15:46:47,403: ============================================================
2022-05-10 15:46:47,403: Epoch 2/38 Batch 2500/7662 eta: 1 day, 12:16:58.449298	Training Loss 0.4546 (0.4644)	Training Prec@1 83.203 (85.443)	Training Prec@5 91.602 (91.163)	
2022-05-10 15:46:47,403: ============================================================
2022-05-10 15:47:33,870: time cost, forward:0.17051429636618778, backward:0.10417457413976125, data cost:0.19026683825353055 
2022-05-10 15:47:33,870: ============================================================
2022-05-10 15:47:33,870: Epoch 2/38 Batch 2600/7662 eta: 1 day, 12:15:24.020794	Training Loss 0.4479 (0.4640)	Training Prec@1 88.086 (85.484)	Training Prec@5 92.383 (91.190)	
2022-05-10 15:47:33,870: ============================================================
2022-05-10 15:48:20,332: time cost, forward:0.1705050249371806, backward:0.10417652138960543, data cost:0.1902526384285089 
2022-05-10 15:48:20,333: ============================================================
2022-05-10 15:48:20,333: Epoch 2/38 Batch 2700/7662 eta: 1 day, 12:14:24.385176	Training Loss 0.4536 (0.4634)	Training Prec@1 89.258 (85.544)	Training Prec@5 94.336 (91.235)	
2022-05-10 15:48:20,333: ============================================================
2022-05-10 15:49:06,820: time cost, forward:0.17049920997606, backward:0.10417798844010713, data cost:0.19024207695078194 
2022-05-10 15:49:06,820: ============================================================
2022-05-10 15:49:06,820: Epoch 2/38 Batch 2800/7662 eta: 1 day, 12:14:48.476144	Training Loss 0.4472 (0.4629)	Training Prec@1 87.500 (85.591)	Training Prec@5 93.359 (91.266)	
2022-05-10 15:49:06,821: ============================================================
2022-05-10 15:49:53,260: time cost, forward:0.17048884753976948, backward:0.1041802219293495, data cost:0.19022323732418864 
2022-05-10 15:49:53,260: ============================================================
2022-05-10 15:49:53,261: Epoch 2/38 Batch 2900/7662 eta: 1 day, 12:11:48.537589	Training Loss 0.4421 (0.4624)	Training Prec@1 89.453 (85.639)	Training Prec@5 94.531 (91.306)	
2022-05-10 15:49:53,261: ============================================================
2022-05-10 15:50:39,739: time cost, forward:0.17047826565675395, backward:0.1041797829214912, data cost:0.19022209869300813 
2022-05-10 15:50:39,739: ============================================================
2022-05-10 15:50:39,740: Epoch 2/38 Batch 3000/7662 eta: 1 day, 12:12:51.554189	Training Loss 0.4508 (0.4619)	Training Prec@1 86.914 (85.687)	Training Prec@5 91.602 (91.336)	
2022-05-10 15:50:39,740: ============================================================
2022-05-10 15:51:26,202: time cost, forward:0.17046943877196458, backward:0.10418143507818053, data cost:0.1902092551754228 
2022-05-10 15:51:26,203: ============================================================
2022-05-10 15:51:26,203: Epoch 2/38 Batch 3100/7662 eta: 1 day, 12:11:20.665049	Training Loss 0.4494 (0.4615)	Training Prec@1 85.938 (85.735)	Training Prec@5 91.016 (91.368)	
2022-05-10 15:51:26,203: ============================================================
2022-05-10 15:52:12,698: time cost, forward:0.1704754048341809, backward:0.10418364523946959, data cost:0.1901953596739368 
2022-05-10 15:52:12,698: ============================================================
2022-05-10 15:52:12,698: Epoch 2/38 Batch 3200/7662 eta: 1 day, 12:12:04.055418	Training Loss 0.4552 (0.4610)	Training Prec@1 85.938 (85.777)	Training Prec@5 91.602 (91.397)	
2022-05-10 15:52:12,698: ============================================================
2022-05-10 15:52:59,219: time cost, forward:0.17048685237760797, backward:0.10418367104011436, data cost:0.19018708723680508 
2022-05-10 15:52:59,219: ============================================================
2022-05-10 15:52:59,220: Epoch 2/38 Batch 3300/7662 eta: 1 day, 12:12:30.370781	Training Loss 0.4504 (0.4605)	Training Prec@1 86.719 (85.827)	Training Prec@5 92.188 (91.435)	
2022-05-10 15:52:59,220: ============================================================
2022-05-10 15:53:45,734: time cost, forward:0.17049047476265422, backward:0.10418278710145605, data cost:0.19018150673574755 
2022-05-10 15:53:45,734: ============================================================
2022-05-10 15:53:45,735: Epoch 2/38 Batch 3400/7662 eta: 1 day, 12:11:26.153483	Training Loss 0.4341 (0.4600)	Training Prec@1 91.406 (85.871)	Training Prec@5 95.312 (91.464)	
2022-05-10 15:53:45,735: ============================================================
2022-05-10 15:54:32,304: time cost, forward:0.17051071035892632, backward:0.10418034192663359, data cost:0.19017872254349022 
2022-05-10 15:54:32,304: ============================================================
2022-05-10 15:54:32,304: Epoch 2/38 Batch 3500/7662 eta: 1 day, 12:13:12.788799	Training Loss 0.4199 (0.4595)	Training Prec@1 91.406 (85.924)	Training Prec@5 95.508 (91.506)	
2022-05-10 15:54:32,304: ============================================================
2022-05-10 15:55:18,917: time cost, forward:0.17052897661054886, backward:0.10417964233892366, data cost:0.19018978170303213 
2022-05-10 15:55:18,917: ============================================================
2022-05-10 15:55:18,917: Epoch 2/38 Batch 3600/7662 eta: 1 day, 12:14:27.903888	Training Loss 0.4491 (0.4591)	Training Prec@1 85.938 (85.971)	Training Prec@5 91.992 (91.540)	
2022-05-10 15:55:18,917: ============================================================
2022-05-10 15:56:05,532: time cost, forward:0.17054085603885696, backward:0.1041803634563115, data cost:0.19020083112373776 
2022-05-10 15:56:05,533: ============================================================
2022-05-10 15:56:05,533: Epoch 2/38 Batch 3700/7662 eta: 1 day, 12:13:47.789453	Training Loss 0.4382 (0.4586)	Training Prec@1 86.523 (86.015)	Training Prec@5 90.820 (91.573)	
2022-05-10 15:56:05,533: ============================================================
2022-05-10 15:56:52,056: time cost, forward:0.17054007379090544, backward:0.10418007498698725, data cost:0.19019998045587702 
2022-05-10 15:56:52,056: ============================================================
2022-05-10 15:56:52,056: Epoch 2/38 Batch 3800/7662 eta: 1 day, 12:08:43.645827	Training Loss 0.4377 (0.4581)	Training Prec@1 87.695 (86.059)	Training Prec@5 91.016 (91.601)	
2022-05-10 15:56:52,056: ============================================================
2022-05-10 15:57:38,572: time cost, forward:0.17053679895266474, backward:0.10418030530191379, data cost:0.19019894338198337 
2022-05-10 15:57:38,572: ============================================================
2022-05-10 15:57:38,572: Epoch 2/38 Batch 3900/7662 eta: 1 day, 12:07:36.290302	Training Loss 0.4409 (0.4576)	Training Prec@1 87.305 (86.099)	Training Prec@5 92.969 (91.629)	
2022-05-10 15:57:38,572: ============================================================
2022-05-10 15:58:25,078: time cost, forward:0.17054255600719637, backward:0.10417921890703312, data cost:0.1901911278014244 
2022-05-10 15:58:25,079: ============================================================
2022-05-10 15:58:25,079: Epoch 2/38 Batch 4000/7662 eta: 1 day, 12:06:23.128953	Training Loss 0.4404 (0.4571)	Training Prec@1 90.039 (86.147)	Training Prec@5 94.336 (91.660)	
2022-05-10 15:58:25,079: ============================================================
2022-05-10 15:59:11,628: time cost, forward:0.1705573810894741, backward:0.10417858784767034, data cost:0.19018447611441872 
2022-05-10 15:59:11,628: ============================================================
2022-05-10 15:59:11,628: Epoch 2/38 Batch 4100/7662 eta: 1 day, 12:07:37.526382	Training Loss 0.4318 (0.4567)	Training Prec@1 87.109 (86.188)	Training Prec@5 92.773 (91.688)	
2022-05-10 15:59:11,628: ============================================================
2022-05-10 15:59:58,141: time cost, forward:0.17055953437585325, backward:0.1041772200908511, data cost:0.19018272355386942 
2022-05-10 15:59:58,142: ============================================================
2022-05-10 15:59:58,142: Epoch 2/38 Batch 4200/7662 eta: 1 day, 12:05:09.806508	Training Loss 0.4365 (0.4562)	Training Prec@1 87.695 (86.230)	Training Prec@5 91.797 (91.718)	
2022-05-10 15:59:58,142: ============================================================
2022-05-10 16:00:44,652: time cost, forward:0.17055195956819139, backward:0.1041760910497374, data cost:0.19018928819990458 
2022-05-10 16:00:44,652: ============================================================
2022-05-10 16:00:44,652: Epoch 2/38 Batch 4300/7662 eta: 1 day, 12:04:14.509080	Training Loss 0.4365 (0.4558)	Training Prec@1 89.062 (86.268)	Training Prec@5 93.555 (91.745)	
2022-05-10 16:00:44,652: ============================================================
2022-05-10 16:01:31,138: time cost, forward:0.17054375726327378, backward:0.10417436507377442, data cost:0.19018949056435888 
2022-05-10 16:01:31,138: ============================================================
2022-05-10 16:01:31,138: Epoch 2/38 Batch 4400/7662 eta: 1 day, 12:02:20.722037	Training Loss 0.4399 (0.4553)	Training Prec@1 87.500 (86.310)	Training Prec@5 92.773 (91.775)	
2022-05-10 16:01:31,139: ============================================================
2022-05-10 16:02:17,640: time cost, forward:0.17054104322750163, backward:0.10417261704467991, data cost:0.19019013469710458 
2022-05-10 16:02:17,641: ============================================================
2022-05-10 16:02:17,641: Epoch 2/38 Batch 4500/7662 eta: 1 day, 12:02:19.036077	Training Loss 0.4305 (0.4549)	Training Prec@1 88.281 (86.354)	Training Prec@5 93.164 (91.808)	
2022-05-10 16:02:17,641: ============================================================
2022-05-10 16:03:04,149: time cost, forward:0.1705369377530225, backward:0.10417164919505459, data cost:0.19019365715031833 
2022-05-10 16:03:04,149: ============================================================
2022-05-10 16:03:04,149: Epoch 2/38 Batch 4600/7662 eta: 1 day, 12:01:50.050911	Training Loss 0.4456 (0.4544)	Training Prec@1 85.742 (86.397)	Training Prec@5 90.820 (91.837)	
2022-05-10 16:03:04,149: ============================================================
2022-05-10 16:03:50,621: time cost, forward:0.17052978468742946, backward:0.10417032054090124, data cost:0.19019231016926624 
2022-05-10 16:03:50,621: ============================================================
2022-05-10 16:03:50,621: Epoch 2/38 Batch 4700/7662 eta: 1 day, 11:59:21.447895	Training Loss 0.4279 (0.4540)	Training Prec@1 87.500 (86.437)	Training Prec@5 92.578 (91.867)	
2022-05-10 16:03:50,621: ============================================================
2022-05-10 16:04:37,158: time cost, forward:0.17052458077327587, backward:0.10417296976366498, data cost:0.19019926525846476 
2022-05-10 16:04:37,159: ============================================================
2022-05-10 16:04:37,159: Epoch 2/38 Batch 4800/7662 eta: 1 day, 12:01:38.158455	Training Loss 0.4351 (0.4535)	Training Prec@1 89.062 (86.478)	Training Prec@5 93.555 (91.896)	
2022-05-10 16:04:37,159: ============================================================
2022-05-10 16:05:23,615: time cost, forward:0.1705212136584171, backward:0.10417086836220561, data cost:0.1901919392571933 
2022-05-10 16:05:23,615: ============================================================
2022-05-10 16:05:23,615: Epoch 2/38 Batch 4900/7662 eta: 1 day, 11:57:04.620178	Training Loss 0.4268 (0.4531)	Training Prec@1 87.891 (86.521)	Training Prec@5 92.578 (91.926)	
2022-05-10 16:05:23,615: ============================================================
2022-05-10 16:06:10,156: time cost, forward:0.1705176615672103, backward:0.10417025078294467, data cost:0.19020143068416234 
2022-05-10 16:06:10,157: ============================================================
2022-05-10 16:06:10,157: Epoch 2/38 Batch 5000/7662 eta: 1 day, 12:00:16.890740	Training Loss 0.4310 (0.4526)	Training Prec@1 88.086 (86.564)	Training Prec@5 92.969 (91.956)	
2022-05-10 16:06:10,157: ============================================================
2022-05-10 16:06:56,590: time cost, forward:0.17051697651716652, backward:0.10416910152244531, data cost:0.1901870296150592 
2022-05-10 16:06:56,591: ============================================================
2022-05-10 16:06:56,591: Epoch 2/38 Batch 5100/7662 eta: 1 day, 11:54:29.244047	Training Loss 0.4438 (0.4522)	Training Prec@1 86.719 (86.598)	Training Prec@5 92.383 (91.983)	
2022-05-10 16:06:56,591: ============================================================
2022-05-10 16:07:43,067: time cost, forward:0.17051548213999096, backward:0.10416823773458385, data cost:0.1901824877889919 
2022-05-10 16:07:43,067: ============================================================
2022-05-10 16:07:43,068: Epoch 2/38 Batch 5200/7662 eta: 1 day, 11:55:43.283258	Training Loss 0.4295 (0.4518)	Training Prec@1 89.648 (86.642)	Training Prec@5 94.922 (92.011)	
2022-05-10 16:07:43,068: ============================================================
2022-05-10 16:08:29,561: time cost, forward:0.17051892870888438, backward:0.10416819761779808, data cost:0.19017537113944863 
2022-05-10 16:08:29,561: ============================================================
2022-05-10 16:08:29,561: Epoch 2/38 Batch 5300/7662 eta: 1 day, 11:55:43.134200	Training Loss 0.4347 (0.4514)	Training Prec@1 89.258 (86.682)	Training Prec@5 94.336 (92.039)	
2022-05-10 16:08:29,562: ============================================================
2022-05-10 16:09:16,023: time cost, forward:0.17051966341806132, backward:0.10416845194298507, data cost:0.19016289556439353 
2022-05-10 16:09:16,023: ============================================================
2022-05-10 16:09:16,023: Epoch 2/38 Batch 5400/7662 eta: 1 day, 11:53:27.666500	Training Loss 0.4365 (0.4510)	Training Prec@1 87.891 (86.717)	Training Prec@5 93.164 (92.062)	
2022-05-10 16:09:16,023: ============================================================
2022-05-10 16:10:02,487: time cost, forward:0.17051340085980154, backward:0.1041687338715099, data cost:0.19016234682655092 
2022-05-10 16:10:02,487: ============================================================
2022-05-10 16:10:02,488: Epoch 2/38 Batch 5500/7662 eta: 1 day, 11:52:48.742730	Training Loss 0.4318 (0.4507)	Training Prec@1 88.281 (86.750)	Training Prec@5 92.773 (92.084)	
2022-05-10 16:10:02,488: ============================================================
2022-05-10 16:10:48,969: time cost, forward:0.17051239085210224, backward:0.1041697401045731, data cost:0.19015752010887108 
2022-05-10 16:10:48,969: ============================================================
2022-05-10 16:10:48,969: Epoch 2/38 Batch 5600/7662 eta: 1 day, 11:52:50.155082	Training Loss 0.4280 (0.4502)	Training Prec@1 87.500 (86.788)	Training Prec@5 93.750 (92.112)	
2022-05-10 16:10:48,969: ============================================================
2022-05-10 16:11:35,447: time cost, forward:0.1705083764212281, backward:0.10417124220604937, data cost:0.19015216948714544 
2022-05-10 16:11:35,448: ============================================================
2022-05-10 16:11:35,448: Epoch 2/38 Batch 5700/7662 eta: 1 day, 11:51:54.977247	Training Loss 0.4306 (0.4498)	Training Prec@1 87.305 (86.824)	Training Prec@5 92.578 (92.139)	
2022-05-10 16:11:35,448: ============================================================
2022-05-10 16:12:22,024: time cost, forward:0.17050878215111584, backward:0.10417095482976381, data cost:0.19016183699219572 
2022-05-10 16:12:22,025: ============================================================
2022-05-10 16:12:22,025: Epoch 2/38 Batch 5800/7662 eta: 1 day, 11:55:42.197179	Training Loss 0.4227 (0.4495)	Training Prec@1 89.844 (86.855)	Training Prec@5 95.117 (92.163)	
2022-05-10 16:12:22,025: ============================================================
2022-05-10 16:13:08,555: time cost, forward:0.170512137685434, backward:0.10417211110318267, data cost:0.19016060236652618 
2022-05-10 16:13:08,555: ============================================================
2022-05-10 16:13:08,555: Epoch 2/38 Batch 5900/7662 eta: 1 day, 11:52:46.497489	Training Loss 0.4135 (0.4490)	Training Prec@1 90.820 (86.887)	Training Prec@5 94.531 (92.185)	
2022-05-10 16:13:08,555: ============================================================
2022-05-10 16:13:55,229: time cost, forward:0.17053416125435375, backward:0.10417337198220883, data cost:0.1901643742003189 
2022-05-10 16:13:55,241: ============================================================
2022-05-10 16:13:55,241: Epoch 2/38 Batch 6000/7662 eta: 1 day, 11:59:09.841296	Training Loss 0.4251 (0.4486)	Training Prec@1 88.867 (86.925)	Training Prec@5 93.555 (92.211)	
2022-05-10 16:13:55,241: ============================================================
2022-05-10 16:14:43,571: time cost, forward:0.17082712645999015, backward:0.10417583372225858, data cost:0.19016846861481998 
2022-05-10 16:14:43,571: ============================================================
2022-05-10 16:14:43,572: Epoch 2/38 Batch 6100/7662 eta: 1 day, 13:14:27.149406	Training Loss 0.4330 (0.4482)	Training Prec@1 88.867 (86.959)	Training Prec@5 94.141 (92.236)	
2022-05-10 16:14:43,572: ============================================================
2022-05-10 16:15:31,028: time cost, forward:0.1709713676626172, backward:0.10417812257875338, data cost:0.1901671430683459 
2022-05-10 16:15:31,028: ============================================================
2022-05-10 16:15:31,029: Epoch 2/38 Batch 6200/7662 eta: 1 day, 12:33:15.697133	Training Loss 0.4141 (0.4478)	Training Prec@1 91.211 (86.994)	Training Prec@5 95.117 (92.260)	
2022-05-10 16:15:31,029: ============================================================
2022-05-10 16:16:17,491: time cost, forward:0.17096954236845874, backward:0.1041780230090209, data cost:0.1901532223648941 
2022-05-10 16:16:17,491: ============================================================
2022-05-10 16:16:17,491: Epoch 2/38 Batch 6300/7662 eta: 1 day, 11:46:31.844777	Training Loss 0.4273 (0.4475)	Training Prec@1 90.430 (87.028)	Training Prec@5 94.531 (92.284)	
2022-05-10 16:16:17,491: ============================================================
2022-05-10 16:17:04,378: time cost, forward:0.1710191706713894, backward:0.10418985988743922, data cost:0.19014384854974403 
2022-05-10 16:17:04,378: ============================================================
2022-05-10 16:17:04,379: Epoch 2/38 Batch 6400/7662 eta: 1 day, 12:05:22.713457	Training Loss 0.4238 (0.4471)	Training Prec@1 87.891 (87.063)	Training Prec@5 93.359 (92.308)	
2022-05-10 16:17:04,379: ============================================================
2022-05-10 16:17:51,082: time cost, forward:0.1710275450675813, backward:0.10421469362355468, data cost:0.19012984027677654 
2022-05-10 16:17:51,083: ============================================================
2022-05-10 16:17:51,083: Epoch 2/38 Batch 6500/7662 eta: 1 day, 11:56:08.804083	Training Loss 0.4218 (0.4467)	Training Prec@1 89.453 (87.099)	Training Prec@5 93.750 (92.333)	
2022-05-10 16:17:51,083: ============================================================
2022-05-10 16:18:37,690: time cost, forward:0.17101874649931145, backward:0.1042364609749105, data cost:0.1901219093107711 
2022-05-10 16:18:37,690: ============================================================
2022-05-10 16:18:37,690: Epoch 2/38 Batch 6600/7662 eta: 1 day, 11:50:52.965913	Training Loss 0.4168 (0.4464)	Training Prec@1 90.039 (87.130)	Training Prec@5 96.289 (92.356)	
2022-05-10 16:18:37,690: ============================================================
2022-05-10 16:19:24,216: time cost, forward:0.1710016689366023, backward:0.10425693146380619, data cost:0.1901127918386908 
2022-05-10 16:19:24,216: ============================================================
2022-05-10 16:19:24,216: Epoch 2/38 Batch 6700/7662 eta: 1 day, 11:46:21.588969	Training Loss 0.4119 (0.4460)	Training Prec@1 90.039 (87.163)	Training Prec@5 93.945 (92.380)	
2022-05-10 16:19:24,216: ============================================================
2022-05-10 16:20:10,779: time cost, forward:0.1709892150145591, backward:0.10427782763135944, data cost:0.19010395098300625 
2022-05-10 16:20:10,779: ============================================================
2022-05-10 16:20:10,779: Epoch 2/38 Batch 6800/7662 eta: 1 day, 11:47:17.495388	Training Loss 0.4237 (0.4456)	Training Prec@1 88.672 (87.194)	Training Prec@5 94.141 (92.402)	
2022-05-10 16:20:10,779: ============================================================
2022-05-10 16:20:57,331: time cost, forward:0.17097894574165481, backward:0.1042974514621879, data cost:0.1900928659808171 
2022-05-10 16:20:57,332: ============================================================
2022-05-10 16:20:57,344: Epoch 2/38 Batch 6900/7662 eta: 1 day, 11:46:36.392666	Training Loss 0.4197 (0.4453)	Training Prec@1 89.648 (87.222)	Training Prec@5 93.750 (92.423)	
2022-05-10 16:20:57,344: ============================================================
2022-05-10 16:21:44,016: time cost, forward:0.17097407801693926, backward:0.10431739234433786, data cost:0.19009480913769672 
2022-05-10 16:21:44,016: ============================================================
2022-05-10 16:21:44,016: Epoch 2/38 Batch 7000/7662 eta: 1 day, 11:50:46.437727	Training Loss 0.4351 (0.4449)	Training Prec@1 86.328 (87.255)	Training Prec@5 92.578 (92.447)	
2022-05-10 16:21:44,016: ============================================================
2022-05-10 16:22:30,634: time cost, forward:0.17096298791133344, backward:0.10433680706585707, data cost:0.19008881482528556 
2022-05-10 16:22:30,634: ============================================================
2022-05-10 16:22:30,634: Epoch 2/38 Batch 7100/7662 eta: 1 day, 11:47:29.451498	Training Loss 0.4153 (0.4446)	Training Prec@1 91.406 (87.289)	Training Prec@5 95.898 (92.470)	
2022-05-10 16:22:30,634: ============================================================
2022-05-10 16:23:17,227: time cost, forward:0.170951762684916, backward:0.10435459911533487, data cost:0.19008601163887187 
2022-05-10 16:23:17,228: ============================================================
2022-05-10 16:23:17,228: Epoch 2/38 Batch 7200/7662 eta: 1 day, 11:45:35.853090	Training Loss 0.4145 (0.4442)	Training Prec@1 87.695 (87.316)	Training Prec@5 92.383 (92.490)	
2022-05-10 16:23:17,228: ============================================================
2022-05-10 16:24:03,832: time cost, forward:0.17094014954740078, backward:0.10437164657457934, data cost:0.19008502618533843 
2022-05-10 16:24:03,832: ============================================================
2022-05-10 16:24:03,833: Epoch 2/38 Batch 7300/7662 eta: 1 day, 11:45:20.211609	Training Loss 0.4168 (0.4439)	Training Prec@1 91.211 (87.345)	Training Prec@5 93.945 (92.508)	
2022-05-10 16:24:03,833: ============================================================
2022-05-10 16:24:50,359: time cost, forward:0.17092659928086867, backward:0.10438835735272066, data cost:0.19007676423345166 
2022-05-10 16:24:50,359: ============================================================
2022-05-10 16:24:50,360: Epoch 2/38 Batch 7400/7662 eta: 1 day, 11:40:58.758692	Training Loss 0.4254 (0.4436)	Training Prec@1 89.648 (87.375)	Training Prec@5 93.750 (92.528)	
2022-05-10 16:24:50,360: ============================================================
2022-05-10 16:25:36,839: time cost, forward:0.17091458984209165, backward:0.1043943671770677, data cost:0.19006777340641878 
2022-05-10 16:25:36,840: ============================================================
2022-05-10 16:25:36,840: Epoch 2/38 Batch 7500/7662 eta: 1 day, 11:38:02.823489	Training Loss 0.4141 (0.4432)	Training Prec@1 90.234 (87.405)	Training Prec@5 94.141 (92.549)	
2022-05-10 16:25:36,840: ============================================================
2022-05-10 16:26:23,221: time cost, forward:0.17090695825810964, backward:0.1043904800605799, data cost:0.19005490594952495 
2022-05-10 16:26:23,221: ============================================================
2022-05-10 16:26:23,221: Epoch 2/38 Batch 7600/7662 eta: 1 day, 11:32:44.226943	Training Loss 0.4210 (0.4429)	Training Prec@1 88.281 (87.434)	Training Prec@5 92.188 (92.570)	
2022-05-10 16:26:23,221: ============================================================
2022-05-10 16:26:53,252: Epoch: 2/38 eta: 1 day, 11:32:15.006601	Training Loss 0.4285 (0.4427)	Training Prec@1 86.523 (87.452)	Training Prec@5 92.188 (92.583)
2022-05-10 16:26:53,253: ============================================================
2022-05-10 16:27:42,316: time cost, forward:0.18535512866395892, backward:0.1040392740808352, data cost:0.20387406782670456 
2022-05-10 16:27:42,316: ============================================================
2022-05-10 16:27:42,316: Epoch 3/38 Batch 100/7662 eta: 1 day, 13:34:36.825076	Training Loss 0.4011 (0.4005)	Training Prec@1 91.406 (91.679)	Training Prec@5 95.508 (95.460)	
2022-05-10 16:27:42,317: ============================================================
2022-05-10 16:28:29,034: time cost, forward:0.17918847314077407, backward:0.10406486952125128, data cost:0.19677835373423208 
2022-05-10 16:28:29,034: ============================================================
2022-05-10 16:28:29,035: Epoch 3/38 Batch 200/7662 eta: 1 day, 11:46:10.111730	Training Loss 0.4007 (0.4016)	Training Prec@1 91.211 (91.519)	Training Prec@5 95.703 (95.396)	
2022-05-10 16:28:29,035: ============================================================
2022-05-10 16:29:15,416: time cost, forward:0.17605447529949073, backward:0.10406275417493738, data cost:0.1943714491101013 
2022-05-10 16:29:15,417: ============================================================
2022-05-10 16:29:15,417: Epoch 3/38 Batch 300/7662 eta: 1 day, 11:29:58.757197	Training Loss 0.4073 (0.4032)	Training Prec@1 91.602 (91.430)	Training Prec@5 95.508 (95.254)	
2022-05-10 16:29:15,417: ============================================================
2022-05-10 16:30:01,864: time cost, forward:0.17455219923702994, backward:0.10406487149403508, data cost:0.19330751985535585 
2022-05-10 16:30:01,864: ============================================================
2022-05-10 16:30:01,864: Epoch 3/38 Batch 400/7662 eta: 1 day, 11:32:11.560091	Training Loss 0.3987 (0.4046)	Training Prec@1 91.406 (91.334)	Training Prec@5 95.703 (95.209)	
2022-05-10 16:30:01,864: ============================================================
2022-05-10 16:30:48,263: time cost, forward:0.1736161250150753, backward:0.1040764141656115, data cost:0.19259528215519173 
2022-05-10 16:30:48,263: ============================================================
2022-05-10 16:30:48,263: Epoch 3/38 Batch 500/7662 eta: 1 day, 11:29:11.044920	Training Loss 0.4057 (0.4057)	Training Prec@1 90.820 (91.256)	Training Prec@5 95.508 (95.170)	
2022-05-10 16:30:48,263: ============================================================
2022-05-10 16:31:34,641: time cost, forward:0.17299704838276705, backward:0.1040845661609121, data cost:0.19206312104736226 
2022-05-10 16:31:34,641: ============================================================
2022-05-10 16:31:34,641: Epoch 3/38 Batch 600/7662 eta: 1 day, 11:27:28.149415	Training Loss 0.4156 (0.4066)	Training Prec@1 91.602 (91.175)	Training Prec@5 95.508 (95.130)	
2022-05-10 16:31:34,641: ============================================================
2022-05-10 16:32:21,070: time cost, forward:0.17263694416640996, backward:0.10408598875283172, data cost:0.1916747911805247 
2022-05-10 16:32:21,070: ============================================================
2022-05-10 16:32:21,071: Epoch 3/38 Batch 700/7662 eta: 1 day, 11:29:02.289427	Training Loss 0.4243 (0.4073)	Training Prec@1 88.086 (91.076)	Training Prec@5 93.555 (95.073)	
2022-05-10 16:32:21,071: ============================================================
2022-05-10 16:33:07,506: time cost, forward:0.17235438963946173, backward:0.10408708001854124, data cost:0.19141902464053806 
2022-05-10 16:33:07,506: ============================================================
2022-05-10 16:33:07,507: Epoch 3/38 Batch 800/7662 eta: 1 day, 11:28:34.482866	Training Loss 0.4068 (0.4076)	Training Prec@1 90.039 (91.046)	Training Prec@5 95.703 (95.058)	
2022-05-10 16:33:07,507: ============================================================
2022-05-10 16:33:53,890: time cost, forward:0.17209265494638343, backward:0.10409438543775854, data cost:0.1911986054514884 
2022-05-10 16:33:53,890: ============================================================
2022-05-10 16:33:53,890: Epoch 3/38 Batch 900/7662 eta: 1 day, 11:25:23.516864	Training Loss 0.4190 (0.4081)	Training Prec@1 91.016 (90.993)	Training Prec@5 94.336 (95.015)	
2022-05-10 16:33:53,890: ============================================================
2022-05-10 16:34:40,260: time cost, forward:0.17185353612279272, backward:0.10409248149669445, data cost:0.19103348887599148 
2022-05-10 16:34:40,260: ============================================================
2022-05-10 16:34:40,260: Epoch 3/38 Batch 1000/7662 eta: 1 day, 11:24:00.773390	Training Loss 0.4018 (0.4085)	Training Prec@1 89.453 (90.925)	Training Prec@5 93.945 (94.968)	
2022-05-10 16:34:40,260: ============================================================
2022-05-10 16:35:26,615: time cost, forward:0.17165702554287968, backward:0.10409103099382173, data cost:0.19089516257024874 
2022-05-10 16:35:26,615: ============================================================
2022-05-10 16:35:26,615: Epoch 3/38 Batch 1100/7662 eta: 1 day, 11:22:32.093779	Training Loss 0.3969 (0.4088)	Training Prec@1 91.992 (90.873)	Training Prec@5 95.898 (94.936)	
2022-05-10 16:35:26,615: ============================================================
2022-05-10 16:36:13,053: time cost, forward:0.17151271173415134, backward:0.1040981000815957, data cost:0.19081905009450267 
2022-05-10 16:36:13,054: ============================================================
2022-05-10 16:36:13,054: Epoch 3/38 Batch 1200/7662 eta: 1 day, 11:25:36.014506	Training Loss 0.4265 (0.4089)	Training Prec@1 89.062 (90.849)	Training Prec@5 92.969 (94.926)	
2022-05-10 16:36:13,054: ============================================================
2022-05-10 16:36:59,496: time cost, forward:0.17137709133803064, backward:0.10409500747574944, data cost:0.19077815671807716 
2022-05-10 16:36:59,496: ============================================================
2022-05-10 16:36:59,496: Epoch 3/38 Batch 1300/7662 eta: 1 day, 11:24:59.855968	Training Loss 0.4204 (0.4092)	Training Prec@1 88.477 (90.806)	Training Prec@5 93.945 (94.902)	
2022-05-10 16:36:59,496: ============================================================
2022-05-10 16:37:45,901: time cost, forward:0.17126995653148375, backward:0.1040953156605544, data cost:0.1907075533618068 
2022-05-10 16:37:45,901: ============================================================
2022-05-10 16:37:45,901: Epoch 3/38 Batch 1400/7662 eta: 1 day, 11:22:29.928891	Training Loss 0.3981 (0.4094)	Training Prec@1 92.773 (90.785)	Training Prec@5 95.312 (94.891)	
2022-05-10 16:37:45,901: ============================================================
2022-05-10 16:38:32,403: time cost, forward:0.17119277215465217, backward:0.1040915906866683, data cost:0.1906979130139901 
2022-05-10 16:38:32,404: ============================================================
2022-05-10 16:38:32,404: Epoch 3/38 Batch 1500/7662 eta: 1 day, 11:26:11.948101	Training Loss 0.4124 (0.4095)	Training Prec@1 91.406 (90.755)	Training Prec@5 94.531 (94.872)	
2022-05-10 16:38:32,404: ============================================================
2022-05-10 16:39:18,900: time cost, forward:0.17113612859677046, backward:0.10409288126055041, data cost:0.19067515515774172 
2022-05-10 16:39:18,900: ============================================================
2022-05-10 16:39:18,900: Epoch 3/38 Batch 1600/7662 eta: 1 day, 11:25:09.446477	Training Loss 0.4049 (0.4096)	Training Prec@1 90.820 (90.741)	Training Prec@5 94.922 (94.867)	
2022-05-10 16:39:18,901: ============================================================
2022-05-10 16:40:05,366: time cost, forward:0.17106522820569825, backward:0.10409321344340809, data cost:0.19063795405742068 
2022-05-10 16:40:05,367: ============================================================
2022-05-10 16:40:05,367: Epoch 3/38 Batch 1700/7662 eta: 1 day, 11:22:59.764818	Training Loss 0.4067 (0.4096)	Training Prec@1 89.844 (90.709)	Training Prec@5 94.531 (94.844)	
2022-05-10 16:40:05,367: ============================================================
2022-05-10 16:40:51,824: time cost, forward:0.1710128735144182, backward:0.10409143648258908, data cost:0.1906057180730153 
2022-05-10 16:40:51,824: ============================================================
2022-05-10 16:40:51,824: Epoch 3/38 Batch 1800/7662 eta: 1 day, 11:21:48.494795	Training Loss 0.4148 (0.4097)	Training Prec@1 90.625 (90.685)	Training Prec@5 94.336 (94.827)	
2022-05-10 16:40:51,824: ============================================================
2022-05-10 16:41:38,287: time cost, forward:0.17096674260244424, backward:0.1040915527614937, data cost:0.19057464750268824 
2022-05-10 16:41:38,287: ============================================================
2022-05-10 16:41:38,287: Epoch 3/38 Batch 1900/7662 eta: 1 day, 11:21:17.345615	Training Loss 0.4159 (0.4097)	Training Prec@1 89.258 (90.668)	Training Prec@5 94.727 (94.815)	
2022-05-10 16:41:38,287: ============================================================
2022-05-10 16:42:24,758: time cost, forward:0.17094613886762106, backward:0.10409025086827013, data cost:0.19053859767942444 
2022-05-10 16:42:24,758: ============================================================
2022-05-10 16:42:24,758: Epoch 3/38 Batch 2000/7662 eta: 1 day, 11:20:52.527878	Training Loss 0.4024 (0.4097)	Training Prec@1 90.234 (90.642)	Training Prec@5 94.727 (94.799)	
2022-05-10 16:42:24,758: ============================================================
2022-05-10 16:43:11,262: time cost, forward:0.17092380187464873, backward:0.10408993991799102, data cost:0.19052427050157522 
2022-05-10 16:43:11,263: ============================================================
2022-05-10 16:43:11,263: Epoch 3/38 Batch 2100/7662 eta: 1 day, 11:21:38.808849	Training Loss 0.4230 (0.4098)	Training Prec@1 87.891 (90.621)	Training Prec@5 92.773 (94.789)	
2022-05-10 16:43:11,263: ============================================================
2022-05-10 16:43:57,761: time cost, forward:0.17090260001300084, backward:0.10408779359395096, data cost:0.1905076960207604 
2022-05-10 16:43:57,761: ============================================================
2022-05-10 16:43:57,761: Epoch 3/38 Batch 2200/7662 eta: 1 day, 11:20:35.346490	Training Loss 0.4214 (0.4098)	Training Prec@1 87.500 (90.614)	Training Prec@5 92.773 (94.782)	
2022-05-10 16:43:57,761: ============================================================
2022-05-10 16:44:44,308: time cost, forward:0.17089857169471134, backward:0.10408584695113332, data cost:0.19050552192694625 
2022-05-10 16:44:44,308: ============================================================
2022-05-10 16:44:44,309: Epoch 3/38 Batch 2300/7662 eta: 1 day, 11:22:02.137691	Training Loss 0.4012 (0.4098)	Training Prec@1 90.625 (90.602)	Training Prec@5 94.727 (94.773)	
2022-05-10 16:44:44,309: ============================================================
2022-05-10 16:45:30,803: time cost, forward:0.17088100909192944, backward:0.10408536172400121, data cost:0.19049016054892054 
2022-05-10 16:45:30,803: ============================================================
2022-05-10 16:45:30,803: Epoch 3/38 Batch 2400/7662 eta: 1 day, 11:18:51.259033	Training Loss 0.4096 (0.4097)	Training Prec@1 92.969 (90.591)	Training Prec@5 96.289 (94.767)	
2022-05-10 16:45:30,803: ============================================================
2022-05-10 16:46:17,212: time cost, forward:0.17084723493966067, backward:0.10408595382046251, data cost:0.19045833446064583 
2022-05-10 16:46:17,212: ============================================================
2022-05-10 16:46:17,212: Epoch 3/38 Batch 2500/7662 eta: 1 day, 11:14:11.797967	Training Loss 0.3978 (0.4097)	Training Prec@1 90.430 (90.585)	Training Prec@5 94.922 (94.761)	
2022-05-10 16:46:17,212: ============================================================
2022-05-10 16:47:03,670: time cost, forward:0.17082165359946203, backward:0.10408765345915046, data cost:0.19043662117829274 
2022-05-10 16:47:03,671: ============================================================
2022-05-10 16:47:03,671: Epoch 3/38 Batch 2600/7662 eta: 1 day, 11:15:39.817556	Training Loss 0.4089 (0.4097)	Training Prec@1 89.453 (90.571)	Training Prec@5 93.750 (94.752)	
2022-05-10 16:47:03,671: ============================================================
2022-05-10 16:47:50,267: time cost, forward:0.17082173447116034, backward:0.10408732996202479, data cost:0.1904426779116291 
2022-05-10 16:47:50,268: ============================================================
2022-05-10 16:47:50,268: Epoch 3/38 Batch 2700/7662 eta: 1 day, 11:21:11.544702	Training Loss 0.4076 (0.4096)	Training Prec@1 90.234 (90.562)	Training Prec@5 96.680 (94.747)	
2022-05-10 16:47:50,268: ============================================================
2022-05-10 16:48:36,831: time cost, forward:0.1708179653095492, backward:0.10408587718103647, data cost:0.19044578727035277 
2022-05-10 16:48:36,832: ============================================================
2022-05-10 16:48:36,832: Epoch 3/38 Batch 2800/7662 eta: 1 day, 11:18:55.704236	Training Loss 0.4136 (0.4095)	Training Prec@1 89.062 (90.549)	Training Prec@5 94.531 (94.740)	
2022-05-10 16:48:36,832: ============================================================
2022-05-10 16:49:23,440: time cost, forward:0.17082748860480582, backward:0.10408643246848405, data cost:0.19045273819311853 
2022-05-10 16:49:23,441: ============================================================
2022-05-10 16:49:23,441: Epoch 3/38 Batch 2900/7662 eta: 1 day, 11:20:11.034740	Training Loss 0.3919 (0.4094)	Training Prec@1 90.234 (90.549)	Training Prec@5 94.336 (94.740)	
2022-05-10 16:49:23,441: ============================================================
2022-05-10 16:50:09,993: time cost, forward:0.17082769117899121, backward:0.10409028755104037, data cost:0.19044576839193897 
2022-05-10 16:50:09,993: ============================================================
2022-05-10 16:50:09,993: Epoch 3/38 Batch 3000/7662 eta: 1 day, 11:16:49.726313	Training Loss 0.4115 (0.4093)	Training Prec@1 90.625 (90.544)	Training Prec@5 94.141 (94.735)	
2022-05-10 16:50:09,993: ============================================================
2022-05-10 16:50:56,561: time cost, forward:0.17082843291217106, backward:0.10409143487266204, data cost:0.1904433109022487 
2022-05-10 16:50:56,561: ============================================================
2022-05-10 16:50:56,562: Epoch 3/38 Batch 3100/7662 eta: 1 day, 11:16:48.065170	Training Loss 0.3982 (0.4092)	Training Prec@1 91.016 (90.543)	Training Prec@5 94.531 (94.735)	
2022-05-10 16:50:56,562: ============================================================
2022-05-10 16:51:43,174: time cost, forward:0.1708338967186468, backward:0.10409379236472327, data cost:0.19044894149579938 
2022-05-10 16:51:43,174: ============================================================
2022-05-10 16:51:43,174: Epoch 3/38 Batch 3200/7662 eta: 1 day, 11:18:00.805442	Training Loss 0.4225 (0.4092)	Training Prec@1 87.500 (90.534)	Training Prec@5 93.750 (94.729)	
2022-05-10 16:51:43,174: ============================================================
2022-05-10 16:52:29,820: time cost, forward:0.1708451531518044, backward:0.10409743679621322, data cost:0.19045876567744602 
2022-05-10 16:52:29,820: ============================================================
2022-05-10 16:52:29,820: Epoch 3/38 Batch 3300/7662 eta: 1 day, 11:18:46.827395	Training Loss 0.4055 (0.4091)	Training Prec@1 90.234 (90.533)	Training Prec@5 94.727 (94.727)	
2022-05-10 16:52:29,821: ============================================================
2022-05-10 16:53:16,427: time cost, forward:0.170849662066979, backward:0.1040971342273655, data cost:0.1904668588433486 
2022-05-10 16:53:16,427: ============================================================
2022-05-10 16:53:16,428: Epoch 3/38 Batch 3400/7662 eta: 1 day, 11:16:13.355251	Training Loss 0.3914 (0.4090)	Training Prec@1 92.383 (90.532)	Training Prec@5 95.703 (94.729)	
2022-05-10 16:53:16,428: ============================================================
2022-05-10 16:54:02,948: time cost, forward:0.1708414258872417, backward:0.10409774620828031, data cost:0.19046139805682832 
2022-05-10 16:54:02,949: ============================================================
2022-05-10 16:54:02,949: Epoch 3/38 Batch 3500/7662 eta: 1 day, 11:11:32.372313	Training Loss 0.3852 (0.4089)	Training Prec@1 91.602 (90.529)	Training Prec@5 95.898 (94.729)	
2022-05-10 16:54:02,949: ============================================================
2022-05-10 16:54:49,471: time cost, forward:0.17082946821860917, backward:0.10409895782173922, data cost:0.19045971989399793 
2022-05-10 16:54:49,471: ============================================================
2022-05-10 16:54:49,472: Epoch 3/38 Batch 3600/7662 eta: 1 day, 11:10:50.600966	Training Loss 0.4174 (0.4089)	Training Prec@1 91.211 (90.530)	Training Prec@5 95.117 (94.732)	
2022-05-10 16:54:49,472: ============================================================
2022-05-10 16:55:36,010: time cost, forward:0.1708194320025912, backward:0.10410034595292528, data cost:0.19046133787253638 
2022-05-10 16:55:36,011: ============================================================
2022-05-10 16:55:36,011: Epoch 3/38 Batch 3700/7662 eta: 1 day, 11:10:48.425944	Training Loss 0.4061 (0.4088)	Training Prec@1 91.992 (90.532)	Training Prec@5 95.508 (94.737)	
2022-05-10 16:55:36,011: ============================================================
2022-05-10 16:56:22,537: time cost, forward:0.1708083971766115, backward:0.10410119031849395, data cost:0.1904583878503344 
2022-05-10 16:56:22,537: ============================================================
2022-05-10 16:56:22,537: Epoch 3/38 Batch 3800/7662 eta: 1 day, 11:09:27.522564	Training Loss 0.4127 (0.4087)	Training Prec@1 90.820 (90.530)	Training Prec@5 94.531 (94.737)	
2022-05-10 16:56:22,537: ============================================================
2022-05-10 16:57:09,060: time cost, forward:0.17079971851095477, backward:0.10410015079784955, data cost:0.19045452522479378 
2022-05-10 16:57:09,060: ============================================================
2022-05-10 16:57:09,060: Epoch 3/38 Batch 3900/7662 eta: 1 day, 11:08:31.140633	Training Loss 0.4048 (0.4086)	Training Prec@1 90.039 (90.526)	Training Prec@5 95.117 (94.737)	
2022-05-10 16:57:09,060: ============================================================
2022-05-10 16:57:55,579: time cost, forward:0.17077945047213036, backward:0.10410011330375853, data cost:0.19045845864265673 
2022-05-10 16:57:55,579: ============================================================
2022-05-10 16:57:55,579: Epoch 3/38 Batch 4000/7662 eta: 1 day, 11:07:33.401051	Training Loss 0.3815 (0.4085)	Training Prec@1 94.336 (90.523)	Training Prec@5 97.266 (94.735)	
2022-05-10 16:57:55,579: ============================================================
2022-05-10 16:58:42,056: time cost, forward:0.17076580324938426, backward:0.10410042709477153, data cost:0.1904512365494277 
2022-05-10 16:58:42,056: ============================================================
2022-05-10 16:58:42,056: Epoch 3/38 Batch 4100/7662 eta: 1 day, 11:04:54.226201	Training Loss 0.4114 (0.4084)	Training Prec@1 89.062 (90.525)	Training Prec@5 93.555 (94.737)	
2022-05-10 16:58:42,056: ============================================================
2022-05-10 16:59:28,521: time cost, forward:0.1707520611543376, backward:0.10410049229072485, data cost:0.19043976677460567 
2022-05-10 16:59:28,521: ============================================================
2022-05-10 16:59:28,521: Epoch 3/38 Batch 4200/7662 eta: 1 day, 11:03:33.241553	Training Loss 0.3969 (0.4083)	Training Prec@1 89.453 (90.519)	Training Prec@5 93.359 (94.733)	
2022-05-10 16:59:28,521: ============================================================
2022-05-10 17:00:14,976: time cost, forward:0.17073844182932202, backward:0.10410009957823983, data cost:0.19043023826411004 
2022-05-10 17:00:14,976: ============================================================
2022-05-10 17:00:14,976: Epoch 3/38 Batch 4300/7662 eta: 1 day, 11:02:21.464822	Training Loss 0.3957 (0.4083)	Training Prec@1 91.211 (90.518)	Training Prec@5 96.094 (94.734)	
2022-05-10 17:00:14,976: ============================================================
2022-05-10 17:01:01,410: time cost, forward:0.17072345170413236, backward:0.10409871793167243, data cost:0.19041907481102271 
2022-05-10 17:01:01,410: ============================================================
2022-05-10 17:01:01,410: Epoch 3/38 Batch 4400/7662 eta: 1 day, 11:00:36.530112	Training Loss 0.4050 (0.4082)	Training Prec@1 90.430 (90.518)	Training Prec@5 95.117 (94.730)	
2022-05-10 17:01:01,410: ============================================================
2022-05-10 17:01:47,890: time cost, forward:0.17070781286357906, backward:0.10409801020625432, data cost:0.19041957052900252 
2022-05-10 17:01:47,890: ============================================================
2022-05-10 17:01:47,891: Epoch 3/38 Batch 4500/7662 eta: 1 day, 11:01:57.257826	Training Loss 0.4084 (0.4081)	Training Prec@1 88.672 (90.526)	Training Prec@5 93.945 (94.736)	
2022-05-10 17:01:47,891: ============================================================
2022-05-10 17:02:34,358: time cost, forward:0.1706980627810185, backward:0.10409617605456116, data cost:0.19041123030418466 
2022-05-10 17:02:34,358: ============================================================
2022-05-10 17:02:34,358: Epoch 3/38 Batch 4600/7662 eta: 1 day, 11:00:35.746453	Training Loss 0.4032 (0.4080)	Training Prec@1 90.039 (90.530)	Training Prec@5 94.141 (94.739)	
2022-05-10 17:02:34,370: ============================================================
2022-05-10 17:03:20,845: time cost, forward:0.1706858625511434, backward:0.10409598985766573, data cost:0.1904107749043538 
2022-05-10 17:03:20,846: ============================================================
2022-05-10 17:03:20,846: Epoch 3/38 Batch 4700/7662 eta: 1 day, 11:00:42.734752	Training Loss 0.3962 (0.4079)	Training Prec@1 88.867 (90.533)	Training Prec@5 93.555 (94.739)	
2022-05-10 17:03:20,846: ============================================================
2022-05-10 17:04:07,308: time cost, forward:0.17067412794518158, backward:0.1040961091084688, data cost:0.1904046790851705 
2022-05-10 17:04:07,308: ============================================================
2022-05-10 17:04:07,308: Epoch 3/38 Batch 4800/7662 eta: 1 day, 10:58:48.353124	Training Loss 0.3957 (0.4078)	Training Prec@1 90.234 (90.537)	Training Prec@5 94.727 (94.743)	
2022-05-10 17:04:07,308: ============================================================
2022-05-10 17:04:53,812: time cost, forward:0.17066539280461787, backward:0.1040960841578935, data cost:0.19040502872143894 
2022-05-10 17:04:53,812: ============================================================
2022-05-10 17:04:53,813: Epoch 3/38 Batch 4900/7662 eta: 1 day, 10:59:55.749943	Training Loss 0.4055 (0.4076)	Training Prec@1 90.039 (90.539)	Training Prec@5 93.945 (94.742)	
2022-05-10 17:04:53,813: ============================================================
2022-05-10 17:05:40,278: time cost, forward:0.17065736750980262, backward:0.10409624153529437, data cost:0.19039462837941123 
2022-05-10 17:05:40,278: ============================================================
2022-05-10 17:05:40,278: Epoch 3/38 Batch 5000/7662 eta: 1 day, 10:57:24.235308	Training Loss 0.4151 (0.4076)	Training Prec@1 88.086 (90.539)	Training Prec@5 93.359 (94.740)	
2022-05-10 17:05:40,278: ============================================================
2022-05-10 17:06:26,903: time cost, forward:0.17068455906142485, backward:0.10409649654238054, data cost:0.1903835295882733 
2022-05-10 17:06:26,903: ============================================================
2022-05-10 17:06:26,903: Epoch 3/38 Batch 5100/7662 eta: 1 day, 11:03:48.558325	Training Loss 0.3903 (0.4075)	Training Prec@1 91.602 (90.538)	Training Prec@5 94.922 (94.742)	
2022-05-10 17:06:26,903: ============================================================
2022-05-10 17:07:13,376: time cost, forward:0.17067658426578652, backward:0.10409705632923887, data cost:0.19037599516822917 
2022-05-10 17:07:13,376: ============================================================
2022-05-10 17:07:13,376: Epoch 3/38 Batch 5200/7662 eta: 1 day, 10:56:12.420815	Training Loss 0.3990 (0.4074)	Training Prec@1 90.430 (90.540)	Training Prec@5 94.336 (94.744)	
2022-05-10 17:07:13,376: ============================================================
2022-05-10 17:07:59,877: time cost, forward:0.17067144609527962, backward:0.10409832387673312, data cost:0.1903718684074631 
2022-05-10 17:07:59,877: ============================================================
2022-05-10 17:07:59,877: Epoch 3/38 Batch 5300/7662 eta: 1 day, 10:56:40.457899	Training Loss 0.4029 (0.4073)	Training Prec@1 90.625 (90.544)	Training Prec@5 95.312 (94.748)	
2022-05-10 17:07:59,877: ============================================================
2022-05-10 17:08:46,371: time cost, forward:0.1706637063938769, backward:0.10409971708985562, data cost:0.190369269520646 
2022-05-10 17:08:46,371: ============================================================
2022-05-10 17:08:46,371: Epoch 3/38 Batch 5400/7662 eta: 1 day, 10:55:34.280070	Training Loss 0.4035 (0.4072)	Training Prec@1 91.406 (90.547)	Training Prec@5 95.312 (94.749)	
2022-05-10 17:08:46,371: ============================================================
2022-05-10 17:09:32,848: time cost, forward:0.17065412895444046, backward:0.10410145370065786, data cost:0.19036589602726897 
2022-05-10 17:09:32,849: ============================================================
2022-05-10 17:09:32,849: Epoch 3/38 Batch 5500/7662 eta: 1 day, 10:54:04.970645	Training Loss 0.4012 (0.4071)	Training Prec@1 90.234 (90.549)	Training Prec@5 93.359 (94.750)	
2022-05-10 17:09:32,849: ============================================================
2022-05-10 17:10:19,335: time cost, forward:0.1706498951374537, backward:0.10410338130289368, data cost:0.1903583437954875 
2022-05-10 17:10:19,335: ============================================================
2022-05-10 17:10:19,335: Epoch 3/38 Batch 5600/7662 eta: 1 day, 10:53:42.200573	Training Loss 0.3896 (0.4070)	Training Prec@1 92.188 (90.555)	Training Prec@5 96.289 (94.755)	
2022-05-10 17:10:19,336: ============================================================
2022-05-10 17:11:05,888: time cost, forward:0.17064598652956298, backward:0.1041065699846248, data cost:0.19036207953802972 
2022-05-10 17:11:05,888: ============================================================
2022-05-10 17:11:05,888: Epoch 3/38 Batch 5700/7662 eta: 1 day, 10:55:53.761458	Training Loss 0.3969 (0.4069)	Training Prec@1 89.453 (90.560)	Training Prec@5 94.141 (94.758)	
2022-05-10 17:11:05,888: ============================================================
2022-05-10 17:11:52,418: time cost, forward:0.1706430669035618, backward:0.10410799789395819, data cost:0.19036210461060823 
2022-05-10 17:11:52,418: ============================================================
2022-05-10 17:11:52,419: Epoch 3/38 Batch 5800/7662 eta: 1 day, 10:54:07.993316	Training Loss 0.3980 (0.4068)	Training Prec@1 90.234 (90.560)	Training Prec@5 94.922 (94.759)	
2022-05-10 17:11:52,419: ============================================================
2022-05-10 17:12:39,043: time cost, forward:0.17064690375695857, backward:0.10412040502868641, data cost:0.19036024819998282 
2022-05-10 17:12:39,043: ============================================================
2022-05-10 17:12:39,044: Epoch 3/38 Batch 5900/7662 eta: 1 day, 10:57:36.010901	Training Loss 0.4065 (0.4068)	Training Prec@1 90.820 (90.564)	Training Prec@5 95.117 (94.761)	
2022-05-10 17:12:39,044: ============================================================
2022-05-10 17:13:25,577: time cost, forward:0.17065383200050097, backward:0.10411860510038722, data cost:0.1903540711340099 
2022-05-10 17:13:25,578: ============================================================
2022-05-10 17:13:25,578: Epoch 3/38 Batch 6000/7662 eta: 1 day, 10:52:45.251791	Training Loss 0.4113 (0.4067)	Training Prec@1 88.867 (90.568)	Training Prec@5 94.141 (94.764)	
2022-05-10 17:13:25,578: ============================================================
2022-05-10 17:14:12,126: time cost, forward:0.17065987932543264, backward:0.10411745635265796, data cost:0.19034833539839865 
2022-05-10 17:14:12,126: ============================================================
2022-05-10 17:14:12,126: Epoch 3/38 Batch 6100/7662 eta: 1 day, 10:52:35.326106	Training Loss 0.4001 (0.4066)	Training Prec@1 91.211 (90.567)	Training Prec@5 95.508 (94.764)	
2022-05-10 17:14:12,126: ============================================================
2022-05-10 17:14:58,721: time cost, forward:0.17066501013443036, backward:0.10411608597985736, data cost:0.1903484802627625 
2022-05-10 17:14:58,721: ============================================================
2022-05-10 17:14:58,721: Epoch 3/38 Batch 6200/7662 eta: 1 day, 10:53:56.679924	Training Loss 0.3870 (0.4065)	Training Prec@1 91.406 (90.570)	Training Prec@5 94.141 (94.767)	
2022-05-10 17:14:58,721: ============================================================
2022-05-10 17:15:45,262: time cost, forward:0.17066723067602632, backward:0.10411532157223306, data cost:0.19034552899669666 
2022-05-10 17:15:45,263: ============================================================
2022-05-10 17:15:45,263: Epoch 3/38 Batch 6300/7662 eta: 1 day, 10:50:44.590269	Training Loss 0.4108 (0.4064)	Training Prec@1 90.430 (90.570)	Training Prec@5 93.750 (94.767)	
2022-05-10 17:15:45,263: ============================================================
2022-05-10 17:16:31,835: time cost, forward:0.1706741091273207, backward:0.10411496087151927, data cost:0.19034382707906117 
2022-05-10 17:16:31,836: ============================================================
2022-05-10 17:16:31,836: Epoch 3/38 Batch 6400/7662 eta: 1 day, 10:51:22.661599	Training Loss 0.3950 (0.4063)	Training Prec@1 91.797 (90.576)	Training Prec@5 95.117 (94.770)	
2022-05-10 17:16:31,836: ============================================================
2022-05-10 17:17:18,377: time cost, forward:0.17067925176871412, backward:0.10411509489495858, data cost:0.19033888105723212 
2022-05-10 17:17:18,377: ============================================================
2022-05-10 17:17:18,378: Epoch 3/38 Batch 6500/7662 eta: 1 day, 10:49:12.388367	Training Loss 0.4020 (0.4062)	Training Prec@1 89.258 (90.582)	Training Prec@5 93.359 (94.775)	
2022-05-10 17:17:18,378: ============================================================
2022-05-10 17:18:04,822: time cost, forward:0.17067841505133613, backward:0.10411429137854093, data cost:0.19032541598889263 
2022-05-10 17:18:04,822: ============================================================
2022-05-10 17:18:04,822: Epoch 3/38 Batch 6600/7662 eta: 1 day, 10:44:04.430915	Training Loss 0.3971 (0.4061)	Training Prec@1 88.477 (90.588)	Training Prec@5 93.555 (94.779)	
2022-05-10 17:18:04,822: ============================================================
2022-05-10 17:18:51,252: time cost, forward:0.17067297744580143, backward:0.10411445577387704, data cost:0.19031177394193294 
2022-05-10 17:18:51,253: ============================================================
2022-05-10 17:18:51,263: Epoch 3/38 Batch 6700/7662 eta: 1 day, 10:43:07.899281	Training Loss 0.3938 (0.4060)	Training Prec@1 91.797 (90.593)	Training Prec@5 96.094 (94.783)	
2022-05-10 17:18:51,263: ============================================================
2022-05-10 17:19:37,703: time cost, forward:0.17067219801099182, backward:0.10411367943785194, data cost:0.19030095030409674 
2022-05-10 17:19:37,703: ============================================================
2022-05-10 17:19:37,703: Epoch 3/38 Batch 6800/7662 eta: 1 day, 10:42:19.105594	Training Loss 0.4139 (0.4059)	Training Prec@1 90.234 (90.599)	Training Prec@5 94.727 (94.787)	
2022-05-10 17:19:37,703: ============================================================
2022-05-10 17:20:24,154: time cost, forward:0.17067323395922177, backward:0.10411401143331842, data cost:0.1902872110246005 
2022-05-10 17:20:24,155: ============================================================
2022-05-10 17:20:24,155: Epoch 3/38 Batch 6900/7662 eta: 1 day, 10:42:03.490556	Training Loss 0.4096 (0.4058)	Training Prec@1 89.453 (90.602)	Training Prec@5 93.945 (94.789)	
2022-05-10 17:20:24,155: ============================================================
2022-05-10 17:21:10,572: time cost, forward:0.1706691078499975, backward:0.10411464512254497, data cost:0.1902739207631163 
2022-05-10 17:21:10,572: ============================================================
2022-05-10 17:21:10,573: Epoch 3/38 Batch 7000/7662 eta: 1 day, 10:39:46.531426	Training Loss 0.4092 (0.4057)	Training Prec@1 87.891 (90.608)	Training Prec@5 93.750 (94.793)	
2022-05-10 17:21:10,573: ============================================================
2022-05-10 17:21:57,079: time cost, forward:0.17066769822246006, backward:0.10411625795757994, data cost:0.1902687607692789 
2022-05-10 17:21:57,079: ============================================================
2022-05-10 17:21:57,080: Epoch 3/38 Batch 7100/7662 eta: 1 day, 10:42:59.452482	Training Loss 0.4046 (0.4056)	Training Prec@1 90.234 (90.610)	Training Prec@5 95.117 (94.794)	
2022-05-10 17:21:57,080: ============================================================
2022-05-10 17:22:43,539: time cost, forward:0.1706663186491521, backward:0.10411753033843202, data cost:0.19025912088128424 
2022-05-10 17:22:43,539: ============================================================
2022-05-10 17:22:43,539: Epoch 3/38 Batch 7200/7662 eta: 1 day, 10:40:06.443573	Training Loss 0.3977 (0.4055)	Training Prec@1 90.234 (90.614)	Training Prec@5 94.531 (94.797)	
2022-05-10 17:22:43,540: ============================================================
2022-05-10 17:23:29,926: time cost, forward:0.17065989081051794, backward:0.10411813733087433, data cost:0.19024422721089296 
2022-05-10 17:23:29,926: ============================================================
2022-05-10 17:23:29,926: Epoch 3/38 Batch 7300/7662 eta: 1 day, 10:36:04.164129	Training Loss 0.4075 (0.4054)	Training Prec@1 90.430 (90.619)	Training Prec@5 94.922 (94.801)	
2022-05-10 17:23:29,926: ============================================================
2022-05-10 17:24:16,324: time cost, forward:0.1706559711540852, backward:0.10411935185142297, data cost:0.19022983050794276 
2022-05-10 17:24:16,325: ============================================================
2022-05-10 17:24:16,325: Epoch 3/38 Batch 7400/7662 eta: 1 day, 10:35:48.788774	Training Loss 0.4036 (0.4053)	Training Prec@1 89.453 (90.625)	Training Prec@5 96.289 (94.805)	
2022-05-10 17:24:16,325: ============================================================
2022-05-10 17:25:02,732: time cost, forward:0.17065566761491457, backward:0.10412015878672536, data cost:0.19021349316327504 
2022-05-10 17:25:02,733: ============================================================
2022-05-10 17:25:02,733: Epoch 3/38 Batch 7500/7662 eta: 1 day, 10:35:28.090577	Training Loss 0.4047 (0.4053)	Training Prec@1 89.648 (90.628)	Training Prec@5 92.969 (94.807)	
2022-05-10 17:25:02,733: ============================================================
2022-05-10 17:25:49,156: time cost, forward:0.1706513583871907, backward:0.10412020761098559, data cost:0.1902041165730501 
2022-05-10 17:25:49,156: ============================================================
2022-05-10 17:25:49,156: Epoch 3/38 Batch 7600/7662 eta: 1 day, 10:35:22.396765	Training Loss 0.4040 (0.4052)	Training Prec@1 90.430 (90.632)	Training Prec@5 94.141 (94.809)	
2022-05-10 17:25:49,156: ============================================================
2022-05-10 17:26:19,548: Epoch: 3/38 eta: 1 day, 10:34:53.150136	Training Loss 0.3803 (0.4051)	Training Prec@1 91.992 (90.633)	Training Prec@5 96.289 (94.810)
2022-05-10 17:26:19,548: ============================================================
2022-05-10 17:27:07,568: time cost, forward:0.17156368554240525, backward:0.10403586397267352, data cost:0.20723418033484256 
2022-05-10 17:27:07,569: ============================================================
2022-05-10 17:27:07,569: Epoch 4/38 Batch 100/7662 eta: 1 day, 11:45:18.812784	Training Loss 0.3802 (0.3789)	Training Prec@1 91.602 (92.762)	Training Prec@5 95.312 (96.250)	
2022-05-10 17:27:07,569: ============================================================
2022-05-10 17:27:53,953: time cost, forward:0.17074612516853677, backward:0.10408418861465837, data cost:0.19832759885931733 
2022-05-10 17:27:53,953: ============================================================
2022-05-10 17:27:53,953: Epoch 4/38 Batch 200/7662 eta: 1 day, 10:31:36.744065	Training Loss 0.3904 (0.3807)	Training Prec@1 93.945 (92.717)	Training Prec@5 96.484 (96.134)	
2022-05-10 17:27:53,954: ============================================================
2022-05-10 17:28:40,309: time cost, forward:0.1703878661063204, backward:0.10410467517814509, data cost:0.19537041896960408 
2022-05-10 17:28:40,309: ============================================================
2022-05-10 17:28:40,310: Epoch 4/38 Batch 300/7662 eta: 1 day, 10:29:35.191338	Training Loss 0.3776 (0.3824)	Training Prec@1 92.383 (92.636)	Training Prec@5 95.508 (96.111)	
2022-05-10 17:28:40,310: ============================================================
2022-05-10 17:29:26,687: time cost, forward:0.17026320913979284, backward:0.10411088926750317, data cost:0.19389731304388597 
2022-05-10 17:29:26,687: ============================================================
2022-05-10 17:29:26,688: Epoch 4/38 Batch 400/7662 eta: 1 day, 10:29:46.618652	Training Loss 0.3959 (0.3841)	Training Prec@1 90.430 (92.467)	Training Prec@5 94.727 (96.006)	
2022-05-10 17:29:26,688: ============================================================
2022-05-10 17:30:13,088: time cost, forward:0.17021757567334989, backward:0.10411789660941145, data cost:0.1930257299381172 
2022-05-10 17:30:13,088: ============================================================
2022-05-10 17:30:13,088: Epoch 4/38 Batch 500/7662 eta: 1 day, 10:30:01.363449	Training Loss 0.3934 (0.3855)	Training Prec@1 93.359 (92.381)	Training Prec@5 95.312 (95.974)	
2022-05-10 17:30:13,088: ============================================================
2022-05-10 17:30:59,505: time cost, forward:0.17022062860466602, backward:0.10413007982983215, data cost:0.19243436265668407 
2022-05-10 17:30:59,506: ============================================================
2022-05-10 17:30:59,506: Epoch 4/38 Batch 600/7662 eta: 1 day, 10:29:59.938030	Training Loss 0.3984 (0.3865)	Training Prec@1 91.602 (92.313)	Training Prec@5 95.703 (95.931)	
2022-05-10 17:30:59,506: ============================================================
2022-05-10 17:31:45,926: time cost, forward:0.1702606981574892, backward:0.10413210484091305, data cost:0.19198659527114192 
2022-05-10 17:31:45,926: ============================================================
2022-05-10 17:31:45,927: Epoch 4/38 Batch 700/7662 eta: 1 day, 10:29:21.693237	Training Loss 0.3974 (0.3875)	Training Prec@1 90.820 (92.229)	Training Prec@5 96.680 (95.876)	
2022-05-10 17:31:45,927: ============================================================
2022-05-10 17:32:32,396: time cost, forward:0.17033383216666936, backward:0.10413445220870876, data cost:0.1916523397491035 
2022-05-10 17:32:32,396: ============================================================
2022-05-10 17:32:32,397: Epoch 4/38 Batch 800/7662 eta: 1 day, 10:30:47.413420	Training Loss 0.3982 (0.3882)	Training Prec@1 91.406 (92.157)	Training Prec@5 96.094 (95.843)	
2022-05-10 17:32:32,397: ============================================================
2022-05-10 17:33:18,879: time cost, forward:0.17044020176464247, backward:0.1041409682909294, data cost:0.19136666482494724 
2022-05-10 17:33:18,879: ============================================================
2022-05-10 17:33:18,879: Epoch 4/38 Batch 900/7662 eta: 1 day, 10:30:35.187144	Training Loss 0.4003 (0.3886)	Training Prec@1 91.211 (92.111)	Training Prec@5 96.289 (95.810)	
2022-05-10 17:33:18,880: ============================================================
2022-05-10 17:34:05,308: time cost, forward:0.1704262742051133, backward:0.10414262648459312, data cost:0.19118673689253218 
2022-05-10 17:34:05,308: ============================================================
2022-05-10 17:34:05,309: Epoch 4/38 Batch 1000/7662 eta: 1 day, 10:27:25.231633	Training Loss 0.3877 (0.3892)	Training Prec@1 93.555 (92.030)	Training Prec@5 96.680 (95.772)	
2022-05-10 17:34:05,309: ============================================================
2022-05-10 17:34:51,726: time cost, forward:0.17041048361454583, backward:0.10414849507797838, data cost:0.19102932844951653 
2022-05-10 17:34:51,726: ============================================================
2022-05-10 17:34:51,727: Epoch 4/38 Batch 1100/7662 eta: 1 day, 10:26:09.126255	Training Loss 0.3858 (0.3897)	Training Prec@1 91.602 (91.966)	Training Prec@5 96.484 (95.726)	
2022-05-10 17:34:51,727: ============================================================
2022-05-10 17:35:38,172: time cost, forward:0.17039158525220346, backward:0.10414675258416947, data cost:0.19093443613633004 
2022-05-10 17:35:38,173: ============================================================
2022-05-10 17:35:38,173: Epoch 4/38 Batch 1200/7662 eta: 1 day, 10:26:38.270680	Training Loss 0.4003 (0.3901)	Training Prec@1 91.992 (91.931)	Training Prec@5 95.703 (95.703)	
2022-05-10 17:35:38,173: ============================================================
2022-05-10 17:36:24,576: time cost, forward:0.17036832801372478, backward:0.1041485987965009, data cost:0.19082458391842977 
2022-05-10 17:36:24,576: ============================================================
2022-05-10 17:36:24,576: Epoch 4/38 Batch 1300/7662 eta: 1 day, 10:23:56.681090	Training Loss 0.3875 (0.3904)	Training Prec@1 92.383 (91.900)	Training Prec@5 95.898 (95.689)	
2022-05-10 17:36:24,576: ============================================================
2022-05-10 17:37:11,025: time cost, forward:0.1703477822686196, backward:0.10415120155492623, data cost:0.19076359655449782 
2022-05-10 17:37:11,025: ============================================================
2022-05-10 17:37:11,026: Epoch 4/38 Batch 1400/7662 eta: 1 day, 10:25:13.745622	Training Loss 0.3854 (0.3906)	Training Prec@1 90.039 (91.868)	Training Prec@5 94.531 (95.671)	
2022-05-10 17:37:11,026: ============================================================
2022-05-10 17:37:57,500: time cost, forward:0.17036626560040677, backward:0.10415457995276677, data cost:0.19068989505602407 
2022-05-10 17:37:57,500: ============================================================
2022-05-10 17:37:57,500: Epoch 4/38 Batch 1500/7662 eta: 1 day, 10:25:34.821830	Training Loss 0.3810 (0.3908)	Training Prec@1 92.969 (91.839)	Training Prec@5 95.508 (95.652)	
2022-05-10 17:37:57,501: ============================================================
2022-05-10 17:38:44,014: time cost, forward:0.17039581848130217, backward:0.10415382173525087, data cost:0.1906341143590797 
2022-05-10 17:38:44,014: ============================================================
2022-05-10 17:38:44,015: Epoch 4/38 Batch 1600/7662 eta: 1 day, 10:26:33.182426	Training Loss 0.3873 (0.3909)	Training Prec@1 92.578 (91.808)	Training Prec@5 96.484 (95.635)	
2022-05-10 17:38:44,015: ============================================================
2022-05-10 17:39:30,558: time cost, forward:0.17043427273131176, backward:0.1041638020419457, data cost:0.19057763696348337 
2022-05-10 17:39:30,558: ============================================================
2022-05-10 17:39:30,559: Epoch 4/38 Batch 1700/7662 eta: 1 day, 10:27:06.113972	Training Loss 0.3903 (0.3912)	Training Prec@1 92.578 (91.782)	Training Prec@5 95.312 (95.615)	
2022-05-10 17:39:30,559: ============================================================
2022-05-10 17:40:17,095: time cost, forward:0.17045469798267782, backward:0.10416195510558912, data cost:0.19055014626724048 
2022-05-10 17:40:17,095: ============================================================
2022-05-10 17:40:17,095: Epoch 4/38 Batch 1800/7662 eta: 1 day, 10:26:00.540552	Training Loss 0.3928 (0.3913)	Training Prec@1 91.211 (91.760)	Training Prec@5 95.508 (95.592)	
2022-05-10 17:40:17,095: ============================================================
2022-05-10 17:41:03,536: time cost, forward:0.17043294964369, backward:0.10416345096626302, data cost:0.19051054341344847 
2022-05-10 17:41:03,536: ============================================================
2022-05-10 17:41:03,536: Epoch 4/38 Batch 1900/7662 eta: 1 day, 10:20:58.871900	Training Loss 0.3740 (0.3914)	Training Prec@1 91.797 (91.741)	Training Prec@5 97.461 (95.577)	
2022-05-10 17:41:03,536: ============================================================
2022-05-10 17:41:50,049: time cost, forward:0.1704468694909207, backward:0.10415953454403594, data cost:0.19048873981038827 
2022-05-10 17:41:50,049: ============================================================
2022-05-10 17:41:50,049: Epoch 4/38 Batch 2000/7662 eta: 1 day, 10:23:24.014455	Training Loss 0.3982 (0.3915)	Training Prec@1 88.867 (91.726)	Training Prec@5 93.164 (95.564)	
2022-05-10 17:41:50,049: ============================================================
2022-05-10 17:42:36,656: time cost, forward:0.17046489938206194, backward:0.10415899679739173, data cost:0.19050103860448916 
2022-05-10 17:42:36,656: ============================================================
2022-05-10 17:42:36,657: Epoch 4/38 Batch 2100/7662 eta: 1 day, 10:26:48.504857	Training Loss 0.3844 (0.3916)	Training Prec@1 92.578 (91.710)	Training Prec@5 95.898 (95.556)	
2022-05-10 17:42:36,657: ============================================================
2022-05-10 17:43:23,211: time cost, forward:0.17049019290079254, backward:0.10415682450052065, data cost:0.19048556960566904 
2022-05-10 17:43:23,212: ============================================================
2022-05-10 17:43:23,212: Epoch 4/38 Batch 2200/7662 eta: 1 day, 10:23:43.801778	Training Loss 0.3966 (0.3917)	Training Prec@1 91.016 (91.688)	Training Prec@5 94.727 (95.538)	
2022-05-10 17:43:23,212: ============================================================
2022-05-10 17:44:09,733: time cost, forward:0.17050815126386712, backward:0.10415646894022712, data cost:0.19046044868197115 
2022-05-10 17:44:09,733: ============================================================
2022-05-10 17:44:09,733: Epoch 4/38 Batch 2300/7662 eta: 1 day, 10:21:26.127844	Training Loss 0.3980 (0.3917)	Training Prec@1 92.578 (91.671)	Training Prec@5 95.703 (95.528)	
2022-05-10 17:44:09,733: ============================================================
2022-05-10 17:44:56,241: time cost, forward:0.17052205059119888, backward:0.10415432760247394, data cost:0.19043544234211815 
2022-05-10 17:44:56,241: ============================================================
2022-05-10 17:44:56,241: Epoch 4/38 Batch 2400/7662 eta: 1 day, 10:20:04.904403	Training Loss 0.4124 (0.3918)	Training Prec@1 89.648 (91.661)	Training Prec@5 94.141 (95.517)	
2022-05-10 17:44:56,241: ============================================================
2022-05-10 17:45:42,757: time cost, forward:0.17053335416121404, backward:0.10415225775063443, data cost:0.19041748693724928 
2022-05-10 17:45:42,758: ============================================================
2022-05-10 17:45:42,758: Epoch 4/38 Batch 2500/7662 eta: 1 day, 10:19:41.322595	Training Loss 0.3919 (0.3919)	Training Prec@1 93.750 (91.650)	Training Prec@5 95.898 (95.510)	
2022-05-10 17:45:42,758: ============================================================
2022-05-10 17:46:29,293: time cost, forward:0.17054625041854524, backward:0.10414941093471244, data cost:0.1904028257345777 
2022-05-10 17:46:29,293: ============================================================
2022-05-10 17:46:29,294: Epoch 4/38 Batch 2600/7662 eta: 1 day, 10:19:45.329132	Training Loss 0.4014 (0.3920)	Training Prec@1 88.867 (91.635)	Training Prec@5 94.336 (95.497)	
2022-05-10 17:46:29,294: ============================================================
2022-05-10 17:47:15,862: time cost, forward:0.17057377994391776, backward:0.10414709369974606, data cost:0.19038636863739591 
2022-05-10 17:47:15,862: ============================================================
2022-05-10 17:47:15,862: Epoch 4/38 Batch 2700/7662 eta: 1 day, 10:20:26.809613	Training Loss 0.3872 (0.3921)	Training Prec@1 92.578 (91.614)	Training Prec@5 96.094 (95.485)	
2022-05-10 17:47:15,862: ============================================================
2022-05-10 17:48:02,332: time cost, forward:0.1705615962561048, backward:0.10414515618300088, data cost:0.19037647731136365 
2022-05-10 17:48:02,332: ============================================================
2022-05-10 17:48:02,332: Epoch 4/38 Batch 2800/7662 eta: 1 day, 10:15:16.924999	Training Loss 0.3986 (0.3922)	Training Prec@1 91.211 (91.604)	Training Prec@5 95.898 (95.481)	
2022-05-10 17:48:02,332: ============================================================
2022-05-10 17:48:48,796: time cost, forward:0.17055058758930733, backward:0.10414513623809026, data cost:0.1903631692921223 
2022-05-10 17:48:48,797: ============================================================
2022-05-10 17:48:48,797: Epoch 4/38 Batch 2900/7662 eta: 1 day, 10:14:17.760091	Training Loss 0.3930 (0.3922)	Training Prec@1 91.602 (91.586)	Training Prec@5 96.094 (95.472)	
2022-05-10 17:48:48,797: ============================================================
2022-05-10 17:49:35,295: time cost, forward:0.17054564112542112, backward:0.10414637291816999, data cost:0.190355355678379 
2022-05-10 17:49:35,295: ============================================================
2022-05-10 17:49:35,295: Epoch 4/38 Batch 3000/7662 eta: 1 day, 10:15:00.012351	Training Loss 0.3901 (0.3922)	Training Prec@1 91.992 (91.578)	Training Prec@5 96.680 (95.467)	
2022-05-10 17:49:35,295: ============================================================
2022-05-10 17:50:21,864: time cost, forward:0.170554172996553, backward:0.10414708503102749, data cost:0.19035448686428014 
2022-05-10 17:50:21,864: ============================================================
2022-05-10 17:50:21,865: Epoch 4/38 Batch 3100/7662 eta: 1 day, 10:17:21.903052	Training Loss 0.3907 (0.3923)	Training Prec@1 92.188 (91.582)	Training Prec@5 95.312 (95.465)	
2022-05-10 17:50:21,865: ============================================================
2022-05-10 17:51:08,401: time cost, forward:0.17056819937235865, backward:0.10414867857241117, data cost:0.19034030005946015 
2022-05-10 17:51:08,401: ============================================================
2022-05-10 17:51:08,401: Epoch 4/38 Batch 3200/7662 eta: 1 day, 10:15:09.193390	Training Loss 0.3897 (0.3923)	Training Prec@1 90.625 (91.569)	Training Prec@5 95.312 (95.456)	
2022-05-10 17:51:08,401: ============================================================
2022-05-10 17:51:54,952: time cost, forward:0.17058181235124648, backward:0.10414826642314244, data cost:0.19033276879379118 
2022-05-10 17:51:54,953: ============================================================
2022-05-10 17:51:54,953: Epoch 4/38 Batch 3300/7662 eta: 1 day, 10:15:01.009517	Training Loss 0.3976 (0.3923)	Training Prec@1 89.453 (91.557)	Training Prec@5 94.727 (95.451)	
2022-05-10 17:51:54,953: ============================================================
2022-05-10 17:52:41,499: time cost, forward:0.17059262235854156, backward:0.10414549090224667, data cost:0.19032880754181833 
2022-05-10 17:52:41,500: ============================================================
2022-05-10 17:52:41,500: Epoch 4/38 Batch 3400/7662 eta: 1 day, 10:14:02.908581	Training Loss 0.3973 (0.3923)	Training Prec@1 91.797 (91.557)	Training Prec@5 95.703 (95.451)	
2022-05-10 17:52:41,500: ============================================================
2022-05-10 17:53:28,046: time cost, forward:0.17060185691635074, backward:0.10414419742474115, data cost:0.1903214874387503 
2022-05-10 17:53:28,046: ============================================================
2022-05-10 17:53:28,046: Epoch 4/38 Batch 3500/7662 eta: 1 day, 10:13:14.501969	Training Loss 0.3858 (0.3922)	Training Prec@1 91.016 (91.558)	Training Prec@5 96.094 (95.454)	
2022-05-10 17:53:28,046: ============================================================
2022-05-10 17:54:14,577: time cost, forward:0.17061035260123392, backward:0.10414347975874781, data cost:0.190307394734155 
2022-05-10 17:54:14,577: ============================================================
2022-05-10 17:54:14,577: Epoch 4/38 Batch 3600/7662 eta: 1 day, 10:11:48.686082	Training Loss 0.3808 (0.3923)	Training Prec@1 93.164 (91.543)	Training Prec@5 96.484 (95.446)	
2022-05-10 17:54:14,578: ============================================================
2022-05-10 17:55:01,123: time cost, forward:0.17061889980509012, backward:0.10414258858164313, data cost:0.19030331450238297 
2022-05-10 17:55:01,124: ============================================================
2022-05-10 17:55:01,124: Epoch 4/38 Batch 3700/7662 eta: 1 day, 10:11:41.888628	Training Loss 0.3996 (0.3923)	Training Prec@1 90.820 (91.546)	Training Prec@5 94.531 (95.446)	
2022-05-10 17:55:01,124: ============================================================
2022-05-10 17:55:47,685: time cost, forward:0.1706216391779053, backward:0.10414114598381924, data cost:0.19030904951896377 
2022-05-10 17:55:47,685: ============================================================
2022-05-10 17:55:47,685: Epoch 4/38 Batch 3800/7662 eta: 1 day, 10:11:35.154412	Training Loss 0.3888 (0.3923)	Training Prec@1 92.188 (91.537)	Training Prec@5 96.680 (95.439)	
2022-05-10 17:55:47,686: ============================================================
2022-05-10 17:56:34,203: time cost, forward:0.17062019415163449, backward:0.1041412504552786, data cost:0.19030656347399524 
2022-05-10 17:56:34,203: ============================================================
2022-05-10 17:56:34,204: Epoch 4/38 Batch 3900/7662 eta: 1 day, 10:08:54.238757	Training Loss 0.3984 (0.3923)	Training Prec@1 91.797 (91.535)	Training Prec@5 96.484 (95.439)	
2022-05-10 17:56:34,204: ============================================================
2022-05-10 17:57:20,771: time cost, forward:0.17062210529915955, backward:0.10414229532753595, data cost:0.19031269880019597 
2022-05-10 17:57:20,772: ============================================================
2022-05-10 17:57:20,772: Epoch 4/38 Batch 4000/7662 eta: 1 day, 10:10:19.249740	Training Loss 0.3967 (0.3923)	Training Prec@1 91.406 (91.525)	Training Prec@5 94.727 (95.430)	
2022-05-10 17:57:20,772: ============================================================
2022-05-10 17:58:07,303: time cost, forward:0.17062127785032394, backward:0.10414191844202188, data cost:0.19031326088506323 
2022-05-10 17:58:07,304: ============================================================
2022-05-10 17:58:07,304: Epoch 4/38 Batch 4100/7662 eta: 1 day, 10:07:57.892500	Training Loss 0.3898 (0.3923)	Training Prec@1 90.820 (91.519)	Training Prec@5 94.922 (95.427)	
2022-05-10 17:58:07,304: ============================================================
2022-05-10 17:58:53,876: time cost, forward:0.17062341028464695, backward:0.10414721114659883, data cost:0.19031508231793282 
2022-05-10 17:58:53,876: ============================================================
2022-05-10 17:58:53,876: Epoch 4/38 Batch 4200/7662 eta: 1 day, 10:08:56.883204	Training Loss 0.4053 (0.3923)	Training Prec@1 87.891 (91.514)	Training Prec@5 93.945 (95.423)	
2022-05-10 17:58:53,876: ============================================================
2022-05-10 17:59:40,538: time cost, forward:0.17061535095885677, backward:0.1041831933057261, data cost:0.1903073299649317 
2022-05-10 17:59:40,539: ============================================================
2022-05-10 17:59:40,539: Epoch 4/38 Batch 4300/7662 eta: 1 day, 10:12:10.015545	Training Loss 0.3914 (0.3923)	Training Prec@1 92.773 (91.507)	Training Prec@5 95.508 (95.420)	
2022-05-10 17:59:40,539: ============================================================
2022-05-10 18:00:27,202: time cost, forward:0.17060267646140906, backward:0.10420765348878007, data cost:0.19031765363952957 
2022-05-10 18:00:27,203: ============================================================
2022-05-10 18:00:27,203: Epoch 4/38 Batch 4400/7662 eta: 1 day, 10:11:25.612149	Training Loss 0.3838 (0.3923)	Training Prec@1 92.188 (91.503)	Training Prec@5 95.117 (95.418)	
2022-05-10 18:00:27,203: ============================================================
2022-05-10 18:01:13,744: time cost, forward:0.17060451519226968, backward:0.10420612230065611, data cost:0.1903188656796135 
2022-05-10 18:01:13,744: ============================================================
2022-05-10 18:01:13,745: Epoch 4/38 Batch 4500/7662 eta: 1 day, 10:05:17.272913	Training Loss 0.3833 (0.3923)	Training Prec@1 90.820 (91.499)	Training Prec@5 94.922 (95.413)	
2022-05-10 18:01:13,745: ============================================================
2022-05-10 18:02:00,286: time cost, forward:0.17060972706445743, backward:0.10420417142811224, data cost:0.19031365095571115 
2022-05-10 18:02:00,286: ============================================================
2022-05-10 18:02:00,286: Epoch 4/38 Batch 4600/7662 eta: 1 day, 10:04:30.152338	Training Loss 0.3990 (0.3923)	Training Prec@1 90.234 (91.495)	Training Prec@5 95.312 (95.412)	
2022-05-10 18:02:00,286: ============================================================
2022-05-10 18:02:46,798: time cost, forward:0.17061094756734246, backward:0.10420306598056908, data cost:0.1903076132299241 
2022-05-10 18:02:46,798: ============================================================
2022-05-10 18:02:46,798: Epoch 4/38 Batch 4700/7662 eta: 1 day, 10:02:25.567668	Training Loss 0.3764 (0.3923)	Training Prec@1 91.016 (91.491)	Training Prec@5 94.336 (95.408)	
2022-05-10 18:02:46,798: ============================================================
2022-05-10 18:03:33,440: time cost, forward:0.17061694847292938, backward:0.10421561881834628, data cost:0.19030883248136998 
2022-05-10 18:03:33,441: ============================================================
2022-05-10 18:03:33,441: Epoch 4/38 Batch 4800/7662 eta: 1 day, 10:07:23.302605	Training Loss 0.3921 (0.3923)	Training Prec@1 90.625 (91.488)	Training Prec@5 96.094 (95.408)	
2022-05-10 18:03:33,441: ============================================================
2022-05-10 18:04:19,961: time cost, forward:0.17061401391715558, backward:0.10421197018737233, data cost:0.19031194025800044 
2022-05-10 18:04:19,962: ============================================================
2022-05-10 18:04:19,962: Epoch 4/38 Batch 4900/7662 eta: 1 day, 10:01:16.319872	Training Loss 0.3839 (0.3923)	Training Prec@1 90.625 (91.485)	Training Prec@5 94.336 (95.403)	
2022-05-10 18:04:19,962: ============================================================
2022-05-10 18:05:06,423: time cost, forward:0.17060531709498944, backward:0.10420949188655175, data cost:0.1903057363086234 
2022-05-10 18:05:06,424: ============================================================
2022-05-10 18:05:06,424: Epoch 4/38 Batch 5000/7662 eta: 1 day, 9:57:55.293422	Training Loss 0.4052 (0.3923)	Training Prec@1 89.258 (91.476)	Training Prec@5 93.945 (95.399)	
2022-05-10 18:05:06,424: ============================================================
2022-05-10 18:05:52,898: time cost, forward:0.17060209854277097, backward:0.10420644187440964, data cost:0.19029765882826852 
2022-05-10 18:05:52,898: ============================================================
2022-05-10 18:05:52,898: Epoch 4/38 Batch 5100/7662 eta: 1 day, 9:57:40.052391	Training Loss 0.3796 (0.3922)	Training Prec@1 92.969 (91.477)	Training Prec@5 96.680 (95.398)	
2022-05-10 18:05:52,898: ============================================================
2022-05-10 18:06:39,349: time cost, forward:0.1705961994630462, backward:0.10420151219090078, data cost:0.19029231130171106 
2022-05-10 18:06:39,349: ============================================================
2022-05-10 18:06:39,349: Epoch 4/38 Batch 5200/7662 eta: 1 day, 9:55:52.262272	Training Loss 0.3953 (0.3922)	Training Prec@1 90.820 (91.479)	Training Prec@5 94.922 (95.397)	
2022-05-10 18:06:39,349: ============================================================
2022-05-10 18:07:25,824: time cost, forward:0.17059546876660067, backward:0.10419833779357518, data cost:0.19028423637416053 
2022-05-10 18:07:25,824: ============================================================
2022-05-10 18:07:25,825: Epoch 4/38 Batch 5300/7662 eta: 1 day, 9:56:10.237099	Training Loss 0.3964 (0.3922)	Training Prec@1 91.016 (91.474)	Training Prec@5 95.703 (95.395)	
2022-05-10 18:07:25,825: ============================================================
2022-05-10 18:08:12,307: time cost, forward:0.17058925947495623, backward:0.10419415924190967, data cost:0.19028620636889307 
2022-05-10 18:08:12,307: ============================================================
2022-05-10 18:08:12,307: Epoch 4/38 Batch 5400/7662 eta: 1 day, 9:55:43.037736	Training Loss 0.3811 (0.3922)	Training Prec@1 90.625 (91.470)	Training Prec@5 94.141 (95.390)	
2022-05-10 18:08:12,307: ============================================================
2022-05-10 18:08:58,784: time cost, forward:0.17059138237855548, backward:0.1041909838876067, data cost:0.19027727030476432 
2022-05-10 18:08:58,784: ============================================================
2022-05-10 18:08:58,784: Epoch 4/38 Batch 5500/7662 eta: 1 day, 9:54:42.220659	Training Loss 0.3730 (0.3921)	Training Prec@1 93.945 (91.470)	Training Prec@5 97.656 (95.390)	
2022-05-10 18:08:58,785: ============================================================
2022-05-10 18:09:45,265: time cost, forward:0.17059349196151785, backward:0.10418834437598372, data cost:0.19026777679993864 
2022-05-10 18:09:45,266: ============================================================
2022-05-10 18:09:45,266: Epoch 4/38 Batch 5600/7662 eta: 1 day, 9:54:06.559137	Training Loss 0.3734 (0.3921)	Training Prec@1 90.820 (91.468)	Training Prec@5 95.508 (95.389)	
2022-05-10 18:09:45,266: ============================================================
2022-05-10 18:10:31,702: time cost, forward:0.1705893427264295, backward:0.10418551347615071, data cost:0.19025902246922688 
2022-05-10 18:10:31,702: ============================================================
2022-05-10 18:10:31,702: Epoch 4/38 Batch 5700/7662 eta: 1 day, 9:51:22.542600	Training Loss 0.3917 (0.3921)	Training Prec@1 91.406 (91.467)	Training Prec@5 94.141 (95.386)	
2022-05-10 18:10:31,702: ============================================================
2022-05-10 18:11:18,107: time cost, forward:0.17058087575228015, backward:0.10418184696959923, data cost:0.1902498760229967 
2022-05-10 18:11:18,107: ============================================================
2022-05-10 18:11:18,107: Epoch 4/38 Batch 5800/7662 eta: 1 day, 9:49:12.646317	Training Loss 0.3939 (0.3920)	Training Prec@1 88.281 (91.465)	Training Prec@5 92.773 (95.386)	
2022-05-10 18:11:18,107: ============================================================
2022-05-10 18:12:04,508: time cost, forward:0.17057404382327065, backward:0.10417850875595824, data cost:0.19023882447511267 
2022-05-10 18:12:04,509: ============================================================
2022-05-10 18:12:04,509: Epoch 4/38 Batch 5900/7662 eta: 1 day, 9:48:18.088854	Training Loss 0.3902 (0.3920)	Training Prec@1 91.406 (91.464)	Training Prec@5 94.922 (95.383)	
2022-05-10 18:12:04,509: ============================================================
2022-05-10 18:12:50,955: time cost, forward:0.17057138221385898, backward:0.10417567763572574, data cost:0.19023080833118386 
2022-05-10 18:12:50,955: ============================================================
2022-05-10 18:12:50,955: Epoch 4/38 Batch 6000/7662 eta: 1 day, 9:49:28.494227	Training Loss 0.3891 (0.3920)	Training Prec@1 93.164 (91.463)	Training Prec@5 95.703 (95.381)	
2022-05-10 18:12:50,955: ============================================================
2022-05-10 18:13:37,372: time cost, forward:0.1705678537412244, backward:0.10417255766568838, data cost:0.1902190469331205 
2022-05-10 18:13:37,372: ============================================================
2022-05-10 18:13:37,372: Epoch 4/38 Batch 6100/7662 eta: 1 day, 9:47:26.063557	Training Loss 0.3893 (0.3920)	Training Prec@1 91.211 (91.465)	Training Prec@5 94.727 (95.384)	
2022-05-10 18:13:37,372: ============================================================
2022-05-10 18:14:23,763: time cost, forward:0.1705614108965462, backward:0.10417098167500663, data cost:0.19020394022031298 
2022-05-10 18:14:23,764: ============================================================
2022-05-10 18:14:23,764: Epoch 4/38 Batch 6200/7662 eta: 1 day, 9:45:32.657453	Training Loss 0.3820 (0.3919)	Training Prec@1 89.062 (91.463)	Training Prec@5 94.531 (95.382)	
2022-05-10 18:14:23,764: ============================================================
2022-05-10 18:15:10,165: time cost, forward:0.17055191503931444, backward:0.10417004520315123, data cost:0.19019184731021535 
2022-05-10 18:15:10,165: ============================================================
2022-05-10 18:15:10,166: Epoch 4/38 Batch 6300/7662 eta: 1 day, 9:45:12.707617	Training Loss 0.3885 (0.3919)	Training Prec@1 91.992 (91.459)	Training Prec@5 96.094 (95.381)	
2022-05-10 18:15:10,166: ============================================================
2022-05-10 18:15:56,612: time cost, forward:0.17054844040445172, backward:0.10416893400909714, data cost:0.190185364195473 
2022-05-10 18:15:56,613: ============================================================
2022-05-10 18:15:56,613: Epoch 4/38 Batch 6400/7662 eta: 1 day, 9:46:25.050424	Training Loss 0.3809 (0.3919)	Training Prec@1 92.188 (91.461)	Training Prec@5 96.289 (95.383)	
2022-05-10 18:15:56,613: ============================================================
2022-05-10 18:16:43,098: time cost, forward:0.17054578520221184, backward:0.10416751385542186, data cost:0.19018171570597842 
2022-05-10 18:16:43,099: ============================================================
2022-05-10 18:16:43,099: Epoch 4/38 Batch 6500/7662 eta: 1 day, 9:47:20.408670	Training Loss 0.3961 (0.3918)	Training Prec@1 89.844 (91.460)	Training Prec@5 94.141 (95.381)	
2022-05-10 18:16:43,099: ============================================================
2022-05-10 18:17:29,529: time cost, forward:0.17053799015732493, backward:0.10416646021065305, data cost:0.19017914292089397 
2022-05-10 18:17:29,529: ============================================================
2022-05-10 18:17:29,529: Epoch 4/38 Batch 6600/7662 eta: 1 day, 9:44:08.412042	Training Loss 0.3907 (0.3918)	Training Prec@1 90.625 (91.462)	Training Prec@5 93.945 (95.384)	
2022-05-10 18:17:29,529: ============================================================
2022-05-10 18:18:16,064: time cost, forward:0.17053598392399447, backward:0.10416639087840432, data cost:0.19018404621529142 
2022-05-10 18:18:16,064: ============================================================
2022-05-10 18:18:16,065: Epoch 4/38 Batch 6700/7662 eta: 1 day, 9:47:56.522520	Training Loss 0.3951 (0.3918)	Training Prec@1 92.188 (91.461)	Training Prec@5 96.484 (95.385)	
2022-05-10 18:18:16,065: ============================================================
2022-05-10 18:19:02,515: time cost, forward:0.1705292524844693, backward:0.10416679617972528, data cost:0.19018048057662756 
2022-05-10 18:19:02,515: ============================================================
2022-05-10 18:19:02,515: Epoch 4/38 Batch 6800/7662 eta: 1 day, 9:43:28.725891	Training Loss 0.4052 (0.3917)	Training Prec@1 89.062 (91.461)	Training Prec@5 94.727 (95.383)	
2022-05-10 18:19:02,515: ============================================================
2022-05-10 18:19:48,972: time cost, forward:0.1705233490213067, backward:0.10416726534531451, data cost:0.19017648012642585 
2022-05-10 18:19:48,973: ============================================================
2022-05-10 18:19:48,973: Epoch 4/38 Batch 6900/7662 eta: 1 day, 9:43:00.256334	Training Loss 0.3937 (0.3917)	Training Prec@1 91.016 (91.458)	Training Prec@5 93.945 (95.383)	
2022-05-10 18:19:48,973: ============================================================
2022-05-10 18:20:35,404: time cost, forward:0.17051738472491745, backward:0.10416794419373797, data cost:0.1901691267874977 
2022-05-10 18:20:35,405: ============================================================
2022-05-10 18:20:35,405: Epoch 4/38 Batch 7000/7662 eta: 1 day, 9:41:06.925988	Training Loss 0.3898 (0.3917)	Training Prec@1 90.039 (91.454)	Training Prec@5 95.703 (95.382)	
2022-05-10 18:20:35,405: ============================================================
2022-05-10 18:21:21,885: time cost, forward:0.1705136305178567, backward:0.10416898906759887, data cost:0.1901661307228369 
2022-05-10 18:21:21,885: ============================================================
2022-05-10 18:21:21,885: Epoch 4/38 Batch 7100/7662 eta: 1 day, 9:42:26.280130	Training Loss 0.3800 (0.3917)	Training Prec@1 92.773 (91.449)	Training Prec@5 95.703 (95.380)	
2022-05-10 18:21:21,885: ============================================================
2022-05-10 18:22:08,319: time cost, forward:0.17050670411689758, backward:0.10417084581968866, data cost:0.19016040694566216 
2022-05-10 18:22:08,319: ============================================================
2022-05-10 18:22:08,320: Epoch 4/38 Batch 7200/7662 eta: 1 day, 9:39:40.945418	Training Loss 0.3786 (0.3916)	Training Prec@1 93.359 (91.452)	Training Prec@5 96.680 (95.381)	
2022-05-10 18:22:08,320: ============================================================
2022-05-10 18:22:54,803: time cost, forward:0.17050590602024432, backward:0.10417143732476747, data cost:0.1901568612883819 
2022-05-10 18:22:54,804: ============================================================
2022-05-10 18:22:54,804: Epoch 4/38 Batch 7300/7662 eta: 1 day, 9:41:03.855227	Training Loss 0.3804 (0.3916)	Training Prec@1 92.969 (91.450)	Training Prec@5 96.680 (95.379)	
2022-05-10 18:22:54,804: ============================================================
2022-05-10 18:23:41,308: time cost, forward:0.17051151633697645, backward:0.10417124032490897, data cost:0.19015060464890202 
2022-05-10 18:23:41,308: ============================================================
2022-05-10 18:23:41,308: Epoch 4/38 Batch 7400/7662 eta: 1 day, 9:41:09.883269	Training Loss 0.3866 (0.3916)	Training Prec@1 90.039 (91.449)	Training Prec@5 94.922 (95.378)	
2022-05-10 18:23:41,308: ============================================================
2022-05-10 18:24:27,712: time cost, forward:0.17050976345643692, backward:0.10417064337241426, data cost:0.19013885730647265 
2022-05-10 18:24:27,712: ============================================================
2022-05-10 18:24:27,712: Epoch 4/38 Batch 7500/7662 eta: 1 day, 9:36:01.152574	Training Loss 0.3969 (0.3916)	Training Prec@1 89.062 (91.449)	Training Prec@5 93.359 (95.378)	
2022-05-10 18:24:27,712: ============================================================
2022-05-10 18:25:14,122: time cost, forward:0.17050474125204126, backward:0.10417109578043901, data cost:0.19013075251879857 
2022-05-10 18:25:14,122: ============================================================
2022-05-10 18:25:14,122: Epoch 4/38 Batch 7600/7662 eta: 1 day, 9:35:31.847466	Training Loss 0.3771 (0.3915)	Training Prec@1 93.555 (91.450)	Training Prec@5 96.289 (95.380)	
2022-05-10 18:25:14,122: ============================================================
2022-05-10 18:25:44,465: Epoch: 4/38 eta: 1 day, 9:35:02.608961	Training Loss 0.4033 (0.3915)	Training Prec@1 91.406 (91.450)	Training Prec@5 94.336 (95.380)
2022-05-10 18:25:44,466: ============================================================
2022-05-10 18:26:32,630: time cost, forward:0.17183969960068213, backward:0.1041657587494513, data cost:0.2072837617662218 
2022-05-10 18:26:32,630: ============================================================
2022-05-10 18:26:32,631: Epoch 5/38 Batch 100/7662 eta: 1 day, 10:45:55.867003	Training Loss 0.3631 (0.3714)	Training Prec@1 93.555 (93.121)	Training Prec@5 97.266 (96.437)	
2022-05-10 18:26:32,631: ============================================================
2022-05-10 18:27:19,188: time cost, forward:0.17140613848240532, backward:0.10419573735951179, data cost:0.19866861769901448 
2022-05-10 18:27:19,189: ============================================================
2022-05-10 18:27:19,189: Epoch 5/38 Batch 200/7662 eta: 1 day, 9:39:55.948522	Training Loss 0.3794 (0.3734)	Training Prec@1 91.797 (93.002)	Training Prec@5 95.898 (96.383)	
2022-05-10 18:27:19,189: ============================================================
2022-05-10 18:28:05,702: time cost, forward:0.17113319448005396, backward:0.10421162783900233, data cost:0.195787425025251 
2022-05-10 18:28:05,703: ============================================================
2022-05-10 18:28:05,703: Epoch 5/38 Batch 300/7662 eta: 1 day, 9:37:12.517878	Training Loss 0.3722 (0.3742)	Training Prec@1 93.359 (92.961)	Training Prec@5 96.289 (96.332)	
2022-05-10 18:28:05,703: ============================================================
2022-05-10 18:28:52,154: time cost, forward:0.1708699133163108, backward:0.10422106793052272, data cost:0.1943200441231405 
2022-05-10 18:28:52,154: ============================================================
2022-05-10 18:28:52,154: Epoch 5/38 Batch 400/7662 eta: 1 day, 9:33:44.257871	Training Loss 0.3796 (0.3758)	Training Prec@1 91.797 (92.840)	Training Prec@5 95.898 (96.273)	
2022-05-10 18:28:52,154: ============================================================
2022-05-10 18:29:38,623: time cost, forward:0.17072264894932687, backward:0.10422881858382292, data cost:0.19343893035858092 
2022-05-10 18:29:38,624: ============================================================
2022-05-10 18:29:38,624: Epoch 5/38 Batch 500/7662 eta: 1 day, 9:33:45.045460	Training Loss 0.3824 (0.3772)	Training Prec@1 92.773 (92.726)	Training Prec@5 96.094 (96.206)	
2022-05-10 18:29:38,624: ============================================================
2022-05-10 18:30:25,080: time cost, forward:0.17066156167617824, backward:0.10422584051281861, data cost:0.19282139999440595 
2022-05-10 18:30:25,081: ============================================================
2022-05-10 18:30:25,081: Epoch 5/38 Batch 600/7662 eta: 1 day, 9:32:26.048109	Training Loss 0.3886 (0.3782)	Training Prec@1 90.625 (92.608)	Training Prec@5 95.703 (96.132)	
2022-05-10 18:30:25,081: ============================================================
2022-05-10 18:31:11,549: time cost, forward:0.17062425067666945, backward:0.10422808247403867, data cost:0.19238808226687715 
2022-05-10 18:31:11,549: ============================================================
2022-05-10 18:31:11,549: Epoch 5/38 Batch 700/7662 eta: 1 day, 9:32:09.160311	Training Loss 0.3970 (0.3790)	Training Prec@1 91.406 (92.564)	Training Prec@5 95.703 (96.112)	
2022-05-10 18:31:11,549: ============================================================
2022-05-10 18:31:58,006: time cost, forward:0.17059793997467385, backward:0.10422826410085895, data cost:0.1920484625204036 
2022-05-10 18:31:58,007: ============================================================
2022-05-10 18:31:58,007: Epoch 5/38 Batch 800/7662 eta: 1 day, 9:30:54.943919	Training Loss 0.3828 (0.3797)	Training Prec@1 92.773 (92.494)	Training Prec@5 95.898 (96.073)	
2022-05-10 18:31:58,007: ============================================================
2022-05-10 18:32:44,470: time cost, forward:0.17061623158523848, backward:0.10422368070837919, data cost:0.19175752410634075 
2022-05-10 18:32:44,470: ============================================================
2022-05-10 18:32:44,471: Epoch 5/38 Batch 900/7662 eta: 1 day, 9:30:23.978026	Training Loss 0.3723 (0.3802)	Training Prec@1 93.555 (92.449)	Training Prec@5 96.289 (96.051)	
2022-05-10 18:32:44,471: ============================================================
2022-05-10 18:33:30,981: time cost, forward:0.17063787272265246, backward:0.1042252338684357, data cost:0.19156109678136693 
2022-05-10 18:33:30,981: ============================================================
2022-05-10 18:33:30,982: Epoch 5/38 Batch 1000/7662 eta: 1 day, 9:31:39.818092	Training Loss 0.3896 (0.3807)	Training Prec@1 91.211 (92.395)	Training Prec@5 96.484 (96.022)	
2022-05-10 18:33:30,982: ============================================================
2022-05-10 18:34:17,483: time cost, forward:0.1706388766815491, backward:0.10422022002083915, data cost:0.19141565158868293 
2022-05-10 18:34:17,483: ============================================================
2022-05-10 18:34:17,483: Epoch 5/38 Batch 1100/7662 eta: 1 day, 9:30:29.493945	Training Loss 0.3794 (0.3812)	Training Prec@1 91.602 (92.369)	Training Prec@5 95.703 (95.990)	
2022-05-10 18:34:17,483: ============================================================
2022-05-10 18:35:03,964: time cost, forward:0.1706635436979903, backward:0.10421175097703338, data cost:0.19125733562466302 
2022-05-10 18:35:03,964: ============================================================
2022-05-10 18:35:03,964: Epoch 5/38 Batch 1200/7662 eta: 1 day, 9:28:49.755566	Training Loss 0.3812 (0.3817)	Training Prec@1 92.773 (92.311)	Training Prec@5 96.094 (95.955)	
2022-05-10 18:35:03,964: ============================================================
2022-05-10 18:35:50,493: time cost, forward:0.1706836419990193, backward:0.10420969029955904, data cost:0.19113909895370518 
2022-05-10 18:35:50,493: ============================================================
2022-05-10 18:35:50,493: Epoch 5/38 Batch 1300/7662 eta: 1 day, 9:30:06.897784	Training Loss 0.3978 (0.3820)	Training Prec@1 90.625 (92.263)	Training Prec@5 96.094 (95.933)	
2022-05-10 18:35:50,493: ============================================================
2022-05-10 18:36:37,003: time cost, forward:0.17070943240696743, backward:0.10420930223689921, data cost:0.19103171043177858 
2022-05-10 18:36:37,003: ============================================================
2022-05-10 18:36:37,003: Epoch 5/38 Batch 1400/7662 eta: 1 day, 9:28:32.084527	Training Loss 0.3778 (0.3823)	Training Prec@1 92.578 (92.228)	Training Prec@5 95.312 (95.908)	
2022-05-10 18:36:37,003: ============================================================
2022-05-10 18:37:23,510: time cost, forward:0.17071125458048692, backward:0.10421359578794921, data cost:0.19095193107101105 
2022-05-10 18:37:23,510: ============================================================
2022-05-10 18:37:23,510: Epoch 5/38 Batch 1500/7662 eta: 1 day, 9:27:36.988262	Training Loss 0.3917 (0.3826)	Training Prec@1 91.211 (92.187)	Training Prec@5 94.922 (95.887)	
2022-05-10 18:37:23,510: ============================================================
2022-05-10 18:38:09,976: time cost, forward:0.17069988000236352, backward:0.10422075845958144, data cost:0.19086669801994738 
2022-05-10 18:38:09,977: ============================================================
2022-05-10 18:38:09,977: Epoch 5/38 Batch 1600/7662 eta: 1 day, 9:25:06.338255	Training Loss 0.3952 (0.3829)	Training Prec@1 90.625 (92.162)	Training Prec@5 94.336 (95.876)	
2022-05-10 18:38:09,977: ============================================================
2022-05-10 18:38:56,495: time cost, forward:0.17068780977070647, backward:0.10422818628460467, data cost:0.19081397615088092 
2022-05-10 18:38:56,496: ============================================================
2022-05-10 18:38:56,496: Epoch 5/38 Batch 1700/7662 eta: 1 day, 9:26:35.223715	Training Loss 0.3780 (0.3830)	Training Prec@1 93.750 (92.142)	Training Prec@5 96.094 (95.858)	
2022-05-10 18:38:56,496: ============================================================
2022-05-10 18:39:43,016: time cost, forward:0.17068001082899042, backward:0.1042343121624576, data cost:0.1907673510264661 
2022-05-10 18:39:43,017: ============================================================
2022-05-10 18:39:43,017: Epoch 5/38 Batch 1800/7662 eta: 1 day, 9:25:54.389291	Training Loss 0.3822 (0.3833)	Training Prec@1 92.969 (92.116)	Training Prec@5 96.484 (95.846)	
2022-05-10 18:39:43,017: ============================================================
2022-05-10 18:40:29,537: time cost, forward:0.17068154049773415, backward:0.10424441045808315, data cost:0.1907129034109653 
2022-05-10 18:40:29,537: ============================================================
2022-05-10 18:40:29,537: Epoch 5/38 Batch 1900/7662 eta: 1 day, 9:25:05.982669	Training Loss 0.3913 (0.3834)	Training Prec@1 91.602 (92.098)	Training Prec@5 95.312 (95.834)	
2022-05-10 18:40:29,537: ============================================================
2022-05-10 18:41:16,089: time cost, forward:0.1706875185181702, backward:0.10424952390135497, data cost:0.19067776447656812 
2022-05-10 18:41:16,089: ============================================================
2022-05-10 18:41:16,089: Epoch 5/38 Batch 2000/7662 eta: 1 day, 9:25:40.621662	Training Loss 0.3863 (0.3834)	Training Prec@1 94.141 (92.090)	Training Prec@5 96.680 (95.829)	
2022-05-10 18:41:16,089: ============================================================
2022-05-10 18:42:02,660: time cost, forward:0.17068240698205112, backward:0.10425191495803608, data cost:0.19066826078424912 
2022-05-10 18:42:02,660: ============================================================
2022-05-10 18:42:02,660: Epoch 5/38 Batch 2100/7662 eta: 1 day, 9:25:44.242169	Training Loss 0.3768 (0.3835)	Training Prec@1 92.773 (92.065)	Training Prec@5 95.703 (95.812)	
2022-05-10 18:42:02,660: ============================================================
2022-05-10 18:42:49,171: time cost, forward:0.17067860277634742, backward:0.10425578642563692, data cost:0.1906345594249134 
2022-05-10 18:42:49,172: ============================================================
2022-05-10 18:42:49,172: Epoch 5/38 Batch 2200/7662 eta: 1 day, 9:22:22.884611	Training Loss 0.3853 (0.3836)	Training Prec@1 92.578 (92.050)	Training Prec@5 95.508 (95.803)	
2022-05-10 18:42:49,172: ============================================================
2022-05-10 18:43:35,673: time cost, forward:0.17067436251032606, backward:0.10425942843247621, data cost:0.1906005805240812 
2022-05-10 18:43:35,674: ============================================================
2022-05-10 18:43:35,674: Epoch 5/38 Batch 2300/7662 eta: 1 day, 9:21:12.459001	Training Loss 0.3949 (0.3837)	Training Prec@1 91.211 (92.041)	Training Prec@5 94.727 (95.801)	
2022-05-10 18:43:35,674: ============================================================
2022-05-10 18:44:22,233: time cost, forward:0.17067964248927547, backward:0.1042650299501598, data cost:0.19058205386706817 
2022-05-10 18:44:22,234: ============================================================
2022-05-10 18:44:22,234: Epoch 5/38 Batch 2400/7662 eta: 1 day, 9:22:55.706559	Training Loss 0.3876 (0.3838)	Training Prec@1 91.211 (92.023)	Training Prec@5 95.117 (95.793)	
2022-05-10 18:44:22,234: ============================================================
2022-05-10 18:45:08,735: time cost, forward:0.17068026036250683, backward:0.1042676881200173, data cost:0.19054883076887982 
2022-05-10 18:45:08,735: ============================================================
2022-05-10 18:45:08,735: Epoch 5/38 Batch 2500/7662 eta: 1 day, 9:19:37.781117	Training Loss 0.3861 (0.3839)	Training Prec@1 91.406 (92.005)	Training Prec@5 96.094 (95.780)	
2022-05-10 18:45:08,735: ============================================================
2022-05-10 18:45:55,213: time cost, forward:0.17067725688689211, backward:0.10427096413850509, data cost:0.19051181806789633 
2022-05-10 18:45:55,214: ============================================================
2022-05-10 18:45:55,214: Epoch 5/38 Batch 2600/7662 eta: 1 day, 9:17:52.758792	Training Loss 0.3784 (0.3840)	Training Prec@1 92.383 (91.992)	Training Prec@5 95.508 (95.776)	
2022-05-10 18:45:55,214: ============================================================
2022-05-10 18:46:41,707: time cost, forward:0.17067644392043937, backward:0.1042717736312397, data cost:0.19048330155775783 
2022-05-10 18:46:41,707: ============================================================
2022-05-10 18:46:41,708: Epoch 5/38 Batch 2700/7662 eta: 1 day, 9:17:44.765466	Training Loss 0.3800 (0.3840)	Training Prec@1 91.797 (91.975)	Training Prec@5 95.312 (95.766)	
2022-05-10 18:46:41,708: ============================================================
2022-05-10 18:47:28,150: time cost, forward:0.17066586149637508, backward:0.10427099545115273, data cost:0.19044965077570908 
2022-05-10 18:47:28,150: ============================================================
2022-05-10 18:47:28,150: Epoch 5/38 Batch 2800/7662 eta: 1 day, 9:14:47.238088	Training Loss 0.3778 (0.3841)	Training Prec@1 92.773 (91.966)	Training Prec@5 94.531 (95.758)	
2022-05-10 18:47:28,150: ============================================================
2022-05-10 18:48:14,628: time cost, forward:0.17066400772376322, backward:0.10427127298958427, data cost:0.19042119662405582 
2022-05-10 18:48:14,628: ============================================================
2022-05-10 18:48:14,628: Epoch 5/38 Batch 2900/7662 eta: 1 day, 9:15:30.564365	Training Loss 0.3910 (0.3843)	Training Prec@1 93.750 (91.953)	Training Prec@5 97.266 (95.752)	
2022-05-10 18:48:14,628: ============================================================
2022-05-10 18:49:01,143: time cost, forward:0.17065859508737002, backward:0.10427370728075842, data cost:0.19040855124379127 
2022-05-10 18:49:01,143: ============================================================
2022-05-10 18:49:01,143: Epoch 5/38 Batch 3000/7662 eta: 1 day, 9:16:21.199391	Training Loss 0.3965 (0.3844)	Training Prec@1 93.164 (91.940)	Training Prec@5 96.289 (95.743)	
2022-05-10 18:49:01,143: ============================================================
2022-05-10 18:49:47,652: time cost, forward:0.17065590102659497, backward:0.10427761031720438, data cost:0.19039087566340035 
2022-05-10 18:49:47,652: ============================================================
2022-05-10 18:49:47,652: Epoch 5/38 Batch 3100/7662 eta: 1 day, 9:15:17.533895	Training Loss 0.3831 (0.3844)	Training Prec@1 90.430 (91.936)	Training Prec@5 94.727 (95.736)	
2022-05-10 18:49:47,652: ============================================================
2022-05-10 18:50:34,203: time cost, forward:0.17066816629264905, backward:0.10428074025556273, data cost:0.1903735202116756 
2022-05-10 18:50:34,204: ============================================================
2022-05-10 18:50:34,204: Epoch 5/38 Batch 3200/7662 eta: 1 day, 9:16:21.671106	Training Loss 0.3786 (0.3844)	Training Prec@1 92.969 (91.931)	Training Prec@5 96.094 (95.732)	
2022-05-10 18:50:34,204: ============================================================
2022-05-10 18:51:20,789: time cost, forward:0.17068280758876517, backward:0.1042845325782177, data cost:0.19036355167491828 
2022-05-10 18:51:20,790: ============================================================
2022-05-10 18:51:20,790: Epoch 5/38 Batch 3300/7662 eta: 1 day, 9:17:03.541640	Training Loss 0.3956 (0.3844)	Training Prec@1 90.820 (91.929)	Training Prec@5 95.703 (95.727)	
2022-05-10 18:51:20,790: ============================================================
2022-05-10 18:52:07,334: time cost, forward:0.17068989489421524, backward:0.10428832249979511, data cost:0.19034844877159432 
2022-05-10 18:52:07,335: ============================================================
2022-05-10 18:52:07,335: Epoch 5/38 Batch 3400/7662 eta: 1 day, 9:14:32.265734	Training Loss 0.4040 (0.3845)	Training Prec@1 90.039 (91.917)	Training Prec@5 94.727 (95.722)	
2022-05-10 18:52:07,335: ============================================================
2022-05-10 18:52:53,852: time cost, forward:0.17069309253152964, backward:0.10429111158006292, data cost:0.19033104251132213 
2022-05-10 18:52:53,853: ============================================================
2022-05-10 18:52:53,853: Epoch 5/38 Batch 3500/7662 eta: 1 day, 9:12:34.821318	Training Loss 0.3849 (0.3845)	Training Prec@1 92.383 (91.908)	Training Prec@5 96.094 (95.717)	
2022-05-10 18:52:53,853: ============================================================
2022-05-10 18:53:40,378: time cost, forward:0.17069488480608475, backward:0.10429362039759478, data cost:0.19031522425720182 
2022-05-10 18:53:40,378: ============================================================
2022-05-10 18:53:40,378: Epoch 5/38 Batch 3600/7662 eta: 1 day, 9:12:08.280249	Training Loss 0.3937 (0.3845)	Training Prec@1 91.602 (91.905)	Training Prec@5 94.531 (95.712)	
2022-05-10 18:53:40,378: ============================================================
2022-05-10 18:54:26,898: time cost, forward:0.1706977173520862, backward:0.10429416098572751, data cost:0.19030184995873486 
2022-05-10 18:54:26,898: ============================================================
2022-05-10 18:54:26,898: Epoch 5/38 Batch 3700/7662 eta: 1 day, 9:11:07.817991	Training Loss 0.3734 (0.3846)	Training Prec@1 92.578 (91.894)	Training Prec@5 95.117 (95.704)	
2022-05-10 18:54:26,899: ============================================================
2022-05-10 18:55:13,449: time cost, forward:0.17069963437376853, backward:0.10429414299545428, data cost:0.19029851843413945 
2022-05-10 18:55:13,450: ============================================================
2022-05-10 18:55:13,450: Epoch 5/38 Batch 3800/7662 eta: 1 day, 9:11:41.516388	Training Loss 0.3827 (0.3846)	Training Prec@1 92.773 (91.887)	Training Prec@5 96.289 (95.696)	
2022-05-10 18:55:13,450: ============================================================
2022-05-10 18:56:00,057: time cost, forward:0.17071131493195904, backward:0.1042939235871191, data cost:0.19030100102606845 
2022-05-10 18:56:00,057: ============================================================
2022-05-10 18:56:00,058: Epoch 5/38 Batch 3900/7662 eta: 1 day, 9:13:19.743445	Training Loss 0.3783 (0.3846)	Training Prec@1 91.211 (91.885)	Training Prec@5 96.680 (95.693)	
2022-05-10 18:56:00,058: ============================================================
2022-05-10 18:56:46,655: time cost, forward:0.17071974721661984, backward:0.10429404180745656, data cost:0.19030205837992853 
2022-05-10 18:56:46,655: ============================================================
2022-05-10 18:56:46,655: Epoch 5/38 Batch 4000/7662 eta: 1 day, 9:12:07.697620	Training Loss 0.3801 (0.3846)	Training Prec@1 93.555 (91.882)	Training Prec@5 96.484 (95.691)	
2022-05-10 18:56:46,656: ============================================================
2022-05-10 18:57:33,299: time cost, forward:0.17072686563907352, backward:0.1042963285276325, data cost:0.19030959927823435 
2022-05-10 18:57:33,299: ============================================================
2022-05-10 18:57:33,299: Epoch 5/38 Batch 4100/7662 eta: 1 day, 9:13:18.999006	Training Loss 0.3861 (0.3846)	Training Prec@1 91.602 (91.878)	Training Prec@5 96.094 (95.686)	
2022-05-10 18:57:33,299: ============================================================
2022-05-10 18:58:19,987: time cost, forward:0.17075017401933046, backward:0.1042966945422891, data cost:0.19031944971023274 
2022-05-10 18:58:19,987: ============================================================
2022-05-10 18:58:19,987: Epoch 5/38 Batch 4200/7662 eta: 1 day, 9:14:25.100955	Training Loss 0.3828 (0.3847)	Training Prec@1 91.992 (91.872)	Training Prec@5 95.898 (95.681)	
2022-05-10 18:58:19,987: ============================================================
2022-05-10 18:59:06,663: time cost, forward:0.17075204311290101, backward:0.10429731350384304, data cost:0.19034302564631175 
2022-05-10 18:59:06,663: ============================================================
2022-05-10 18:59:06,663: Epoch 5/38 Batch 4300/7662 eta: 1 day, 9:13:07.784506	Training Loss 0.3810 (0.3847)	Training Prec@1 91.992 (91.867)	Training Prec@5 95.898 (95.679)	
2022-05-10 18:59:06,663: ============================================================
2022-05-10 18:59:53,211: time cost, forward:0.17074557558247436, backward:0.10429725535324037, data cost:0.19034294118445472 
2022-05-10 18:59:53,211: ============================================================
2022-05-10 18:59:53,211: Epoch 5/38 Batch 4400/7662 eta: 1 day, 9:06:53.605968	Training Loss 0.3904 (0.3846)	Training Prec@1 92.578 (91.864)	Training Prec@5 95.117 (95.678)	
2022-05-10 18:59:53,211: ============================================================
2022-05-10 19:00:39,706: time cost, forward:0.1707331955658115, backward:0.10429788271727417, data cost:0.19033890449886826 
2022-05-10 19:00:39,706: ============================================================
2022-05-10 19:00:39,706: Epoch 5/38 Batch 4500/7662 eta: 1 day, 9:03:52.573264	Training Loss 0.3818 (0.3847)	Training Prec@1 92.969 (91.858)	Training Prec@5 96.094 (95.673)	
2022-05-10 19:00:39,707: ============================================================
2022-05-10 19:01:26,221: time cost, forward:0.17072468639638377, backward:0.10429858119364899, data cost:0.19033621642661627 
2022-05-10 19:01:26,222: ============================================================
2022-05-10 19:01:26,222: Epoch 5/38 Batch 4600/7662 eta: 1 day, 9:03:57.228434	Training Loss 0.3834 (0.3847)	Training Prec@1 92.383 (91.855)	Training Prec@5 96.680 (95.672)	
2022-05-10 19:01:26,222: ============================================================
2022-05-10 19:02:12,718: time cost, forward:0.17072107315469381, backward:0.10429873007818799, data cost:0.19032565439779928 
2022-05-10 19:02:12,718: ============================================================
2022-05-10 19:02:12,718: Epoch 5/38 Batch 4700/7662 eta: 1 day, 9:02:21.332127	Training Loss 0.3771 (0.3847)	Training Prec@1 91.992 (91.845)	Training Prec@5 94.922 (95.666)	
2022-05-10 19:02:12,718: ============================================================
2022-05-10 19:02:59,262: time cost, forward:0.17072201873094098, backward:0.10430059901970977, data cost:0.1903165708757684 
2022-05-10 19:02:59,262: ============================================================
2022-05-10 19:02:59,262: Epoch 5/38 Batch 4800/7662 eta: 1 day, 9:03:37.733839	Training Loss 0.3913 (0.3847)	Training Prec@1 89.453 (91.843)	Training Prec@5 93.945 (95.662)	
2022-05-10 19:02:59,262: ============================================================
2022-05-10 19:03:45,771: time cost, forward:0.1707200551913889, backward:0.10430189886246927, data cost:0.1903064839814142 
2022-05-10 19:03:45,771: ============================================================
2022-05-10 19:03:45,771: Epoch 5/38 Batch 4900/7662 eta: 1 day, 9:01:20.237448	Training Loss 0.3794 (0.3847)	Training Prec@1 91.211 (91.839)	Training Prec@5 95.312 (95.660)	
2022-05-10 19:03:45,771: ============================================================
2022-05-10 19:04:32,269: time cost, forward:0.1707161673309088, backward:0.1043030254648647, data cost:0.19029712319302544 
2022-05-10 19:04:32,270: ============================================================
2022-05-10 19:04:32,270: Epoch 5/38 Batch 5000/7662 eta: 1 day, 9:00:08.612901	Training Loss 0.3775 (0.3847)	Training Prec@1 93.359 (91.837)	Training Prec@5 95.898 (95.656)	
2022-05-10 19:04:32,270: ============================================================
2022-05-10 19:05:18,774: time cost, forward:0.17071216754946997, backward:0.10430342044332819, data cost:0.19029020790867676 
2022-05-10 19:05:18,774: ============================================================
2022-05-10 19:05:18,774: Epoch 5/38 Batch 5100/7662 eta: 1 day, 8:59:35.765376	Training Loss 0.3965 (0.3847)	Training Prec@1 90.820 (91.833)	Training Prec@5 94.922 (95.653)	
2022-05-10 19:05:18,774: ============================================================
2022-05-10 19:06:05,290: time cost, forward:0.17071002028175997, backward:0.10430609576861247, data cost:0.19028173123077374 
2022-05-10 19:06:05,291: ============================================================
2022-05-10 19:06:05,291: Epoch 5/38 Batch 5200/7662 eta: 1 day, 8:59:21.980905	Training Loss 0.3821 (0.3848)	Training Prec@1 91.602 (91.828)	Training Prec@5 95.703 (95.650)	
2022-05-10 19:06:05,291: ============================================================
2022-05-10 19:06:51,851: time cost, forward:0.1707076887788357, backward:0.10430783585661603, data cost:0.19028117688652885 
2022-05-10 19:06:51,851: ============================================================
2022-05-10 19:06:51,852: Epoch 5/38 Batch 5300/7662 eta: 1 day, 9:00:27.170942	Training Loss 0.3917 (0.3848)	Training Prec@1 93.359 (91.825)	Training Prec@5 96.289 (95.649)	
2022-05-10 19:06:51,852: ============================================================
2022-05-10 19:07:38,395: time cost, forward:0.1707030089393018, backward:0.10431013241545495, data cost:0.19027734491687767 
2022-05-10 19:07:38,395: ============================================================
2022-05-10 19:07:38,395: Epoch 5/38 Batch 5400/7662 eta: 1 day, 8:58:56.429802	Training Loss 0.3819 (0.3848)	Training Prec@1 91.797 (91.822)	Training Prec@5 95.508 (95.649)	
2022-05-10 19:07:38,395: ============================================================
2022-05-10 19:08:24,954: time cost, forward:0.17070702887335829, backward:0.10431179923997357, data cost:0.19027246408276957 
2022-05-10 19:08:24,955: ============================================================
2022-05-10 19:08:24,955: Epoch 5/38 Batch 5500/7662 eta: 1 day, 8:58:51.351837	Training Loss 0.3826 (0.3848)	Training Prec@1 94.141 (91.820)	Training Prec@5 98.047 (95.648)	
2022-05-10 19:08:24,955: ============================================================
2022-05-10 19:09:11,495: time cost, forward:0.17070702698256718, backward:0.1043142967936098, data cost:0.19026746096664676 
2022-05-10 19:09:11,495: ============================================================
2022-05-10 19:09:11,495: Epoch 5/38 Batch 5600/7662 eta: 1 day, 8:57:16.550154	Training Loss 0.3873 (0.3848)	Training Prec@1 92.383 (91.817)	Training Prec@5 95.508 (95.644)	
2022-05-10 19:09:11,496: ============================================================
2022-05-10 19:09:58,090: time cost, forward:0.1707086510816401, backward:0.1043206538039564, data cost:0.1902666410284516 
2022-05-10 19:09:58,090: ============================================================
2022-05-10 19:09:58,091: Epoch 5/38 Batch 5700/7662 eta: 1 day, 8:58:48.715332	Training Loss 0.3834 (0.3848)	Training Prec@1 91.992 (91.815)	Training Prec@5 95.117 (95.643)	
2022-05-10 19:09:58,091: ============================================================
2022-05-10 19:10:44,667: time cost, forward:0.17070822922150253, backward:0.10432110471671194, data cost:0.1902684602558171 
2022-05-10 19:10:44,667: ============================================================
2022-05-10 19:10:44,668: Epoch 5/38 Batch 5800/7662 eta: 1 day, 8:57:15.599958	Training Loss 0.3848 (0.3847)	Training Prec@1 91.211 (91.811)	Training Prec@5 95.312 (95.642)	
2022-05-10 19:10:44,668: ============================================================
2022-05-10 19:11:31,238: time cost, forward:0.17071036662787054, backward:0.10432250747480197, data cost:0.1902676453972736 
2022-05-10 19:11:31,239: ============================================================
2022-05-10 19:11:31,239: Epoch 5/38 Batch 5900/7662 eta: 1 day, 8:56:14.797779	Training Loss 0.3790 (0.3848)	Training Prec@1 90.820 (91.806)	Training Prec@5 95.508 (95.638)	
2022-05-10 19:11:31,239: ============================================================
2022-05-10 19:12:17,905: time cost, forward:0.17072445767226666, backward:0.10432472163825299, data cost:0.19026968339658376 
2022-05-10 19:12:17,905: ============================================================
2022-05-10 19:12:17,906: Epoch 5/38 Batch 6000/7662 eta: 1 day, 8:59:31.209102	Training Loss 0.3890 (0.3848)	Training Prec@1 90.039 (91.804)	Training Prec@5 95.312 (95.638)	
2022-05-10 19:12:17,906: ============================================================
2022-05-10 19:13:04,558: time cost, forward:0.1707358776614165, backward:0.10432702765188798, data cost:0.19026989748407963 
2022-05-10 19:13:04,558: ============================================================
2022-05-10 19:13:04,558: Epoch 5/38 Batch 6100/7662 eta: 1 day, 8:58:07.735129	Training Loss 0.3745 (0.3848)	Training Prec@1 91.797 (91.797)	Training Prec@5 95.312 (95.634)	
2022-05-10 19:13:04,558: ============================================================
2022-05-10 19:13:51,274: time cost, forward:0.17074868032520366, backward:0.10432995467594428, data cost:0.1902795771395589 
2022-05-10 19:13:51,274: ============================================================
2022-05-10 19:13:51,274: Epoch 5/38 Batch 6200/7662 eta: 1 day, 9:00:04.116761	Training Loss 0.3991 (0.3848)	Training Prec@1 91.992 (91.798)	Training Prec@5 96.094 (95.634)	
2022-05-10 19:13:51,275: ============================================================
2022-05-10 19:14:37,887: time cost, forward:0.17075210015799133, backward:0.10433381034147363, data cost:0.1902805098391162 
2022-05-10 19:14:37,887: ============================================================
2022-05-10 19:14:37,887: Epoch 5/38 Batch 6300/7662 eta: 1 day, 8:54:54.606417	Training Loss 0.3808 (0.3848)	Training Prec@1 92.188 (91.796)	Training Prec@5 96.484 (95.632)	
2022-05-10 19:14:37,888: ============================================================
2022-05-10 19:15:24,616: time cost, forward:0.1707586446280106, backward:0.10434669028000639, data cost:0.19028701717396382 
2022-05-10 19:15:24,617: ============================================================
2022-05-10 19:15:24,617: Epoch 5/38 Batch 6400/7662 eta: 1 day, 8:59:03.225525	Training Loss 0.3808 (0.3847)	Training Prec@1 91.797 (91.798)	Training Prec@5 95.898 (95.633)	
2022-05-10 19:15:24,617: ============================================================
2022-05-10 19:16:11,394: time cost, forward:0.17076537384952392, backward:0.10437184606153867, data cost:0.19028598771753413 
2022-05-10 19:16:11,395: ============================================================
2022-05-10 19:16:11,395: Epoch 5/38 Batch 6500/7662 eta: 1 day, 9:00:20.549544	Training Loss 0.3792 (0.3847)	Training Prec@1 92.188 (91.797)	Training Prec@5 95.508 (95.631)	
2022-05-10 19:16:11,395: ============================================================
2022-05-10 19:16:58,043: time cost, forward:0.1707665605930907, backward:0.10437441464716204, data cost:0.19029457790596158 
2022-05-10 19:16:58,043: ============================================================
2022-05-10 19:16:58,043: Epoch 5/38 Batch 6600/7662 eta: 1 day, 8:54:04.829372	Training Loss 0.3826 (0.3847)	Training Prec@1 92.383 (91.797)	Training Prec@5 96.680 (95.631)	
2022-05-10 19:16:58,044: ============================================================
2022-05-10 19:17:44,655: time cost, forward:0.1707709836397514, backward:0.1043757895495148, data cost:0.19029511421683085 
2022-05-10 19:17:44,655: ============================================================
2022-05-10 19:17:44,656: Epoch 5/38 Batch 6700/7662 eta: 1 day, 8:51:46.045286	Training Loss 0.3775 (0.3847)	Training Prec@1 92.188 (91.795)	Training Prec@5 95.117 (95.629)	
2022-05-10 19:17:44,656: ============================================================
2022-05-10 19:18:31,365: time cost, forward:0.1707837880402913, backward:0.10437828724060642, data cost:0.19029691100453677 
2022-05-10 19:18:31,366: ============================================================
2022-05-10 19:18:31,366: Epoch 5/38 Batch 6800/7662 eta: 1 day, 8:55:08.156917	Training Loss 0.3794 (0.3847)	Training Prec@1 92.773 (91.793)	Training Prec@5 97.852 (95.627)	
2022-05-10 19:18:31,366: ============================================================
2022-05-10 19:19:17,972: time cost, forward:0.170790938955059, backward:0.10438009106019111, data cost:0.19029441472844363 
2022-05-10 19:19:17,973: ============================================================
2022-05-10 19:19:17,973: Epoch 5/38 Batch 6900/7662 eta: 1 day, 8:49:59.157520	Training Loss 0.3842 (0.3847)	Training Prec@1 90.625 (91.790)	Training Prec@5 94.727 (95.626)	
2022-05-10 19:19:17,973: ============================================================
2022-05-10 19:20:04,583: time cost, forward:0.1707942442206557, backward:0.10438155163899714, data cost:0.19029414604384315 
2022-05-10 19:20:04,583: ============================================================
2022-05-10 19:20:04,583: Epoch 5/38 Batch 7000/7662 eta: 1 day, 8:49:21.317678	Training Loss 0.3752 (0.3847)	Training Prec@1 92.383 (91.789)	Training Prec@5 95.508 (95.625)	
2022-05-10 19:20:04,583: ============================================================
2022-05-10 19:20:51,192: time cost, forward:0.17079688253696912, backward:0.10438214659539725, data cost:0.19029547191200197 
2022-05-10 19:20:51,192: ============================================================
2022-05-10 19:20:51,192: Epoch 5/38 Batch 7100/7662 eta: 1 day, 8:48:32.170446	Training Loss 0.3918 (0.3847)	Training Prec@1 89.844 (91.787)	Training Prec@5 94.141 (95.625)	
2022-05-10 19:20:51,192: ============================================================
2022-05-10 19:21:37,818: time cost, forward:0.17079787251684034, backward:0.10438291512192711, data cost:0.19030153875566883 
2022-05-10 19:21:37,819: ============================================================
2022-05-10 19:21:37,819: Epoch 5/38 Batch 7200/7662 eta: 1 day, 8:48:28.661015	Training Loss 0.3782 (0.3847)	Training Prec@1 91.211 (91.787)	Training Prec@5 95.312 (95.625)	
2022-05-10 19:21:37,819: ============================================================
2022-05-10 19:22:24,390: time cost, forward:0.17079854187924234, backward:0.1043826078842692, data cost:0.19029896486979803 
2022-05-10 19:22:24,390: ============================================================
2022-05-10 19:22:24,391: Epoch 5/38 Batch 7300/7662 eta: 1 day, 8:45:24.527544	Training Loss 0.3857 (0.3846)	Training Prec@1 91.016 (91.788)	Training Prec@5 94.727 (95.627)	
2022-05-10 19:22:24,391: ============================================================
2022-05-10 19:23:10,915: time cost, forward:0.17079541402533982, backward:0.10438164995721683, data cost:0.19029610110933934 
2022-05-10 19:23:10,915: ============================================================
2022-05-10 19:23:10,916: Epoch 5/38 Batch 7400/7662 eta: 1 day, 8:42:38.786885	Training Loss 0.3724 (0.3846)	Training Prec@1 91.211 (91.787)	Training Prec@5 95.703 (95.627)	
2022-05-10 19:23:10,916: ============================================================
2022-05-10 19:23:57,478: time cost, forward:0.17079822383478238, backward:0.10437983820511192, data cost:0.1902936262231713 
2022-05-10 19:23:57,479: ============================================================
2022-05-10 19:23:57,479: Epoch 5/38 Batch 7500/7662 eta: 1 day, 8:43:28.940098	Training Loss 0.4051 (0.3846)	Training Prec@1 88.672 (91.785)	Training Prec@5 93.945 (95.626)	
2022-05-10 19:23:57,479: ============================================================
2022-05-10 19:24:44,100: time cost, forward:0.17079582875112842, backward:0.1043791633198835, data cost:0.19030285945204092 
2022-05-10 19:24:44,101: ============================================================
2022-05-10 19:24:44,101: Epoch 5/38 Batch 7600/7662 eta: 1 day, 8:45:11.255031	Training Loss 0.3828 (0.3846)	Training Prec@1 92.188 (91.785)	Training Prec@5 95.508 (95.626)	
2022-05-10 19:24:44,101: ============================================================
2022-05-10 19:25:14,828: Epoch: 5/38 eta: 1 day, 8:44:41.883166	Training Loss 0.3756 (0.3846)	Training Prec@1 92.578 (91.787)	Training Prec@5 95.898 (95.627)
2022-05-10 19:25:14,828: ============================================================
2022-05-10 19:25:14,831: Save Checkpoint...
2022-05-10 19:25:14,832: ============================================================
2022-05-10 19:25:17,982: Save done!
2022-05-10 19:25:17,982: ============================================================
2022-05-10 19:26:07,105: time cost, forward:0.18454432005834098, backward:0.10421230576255104, data cost:0.20524178610907662 
2022-05-10 19:26:07,105: ============================================================
2022-05-10 19:26:07,106: Epoch 6/38 Batch 100/7662 eta: 1 day, 10:29:16.108929	Training Loss 0.3675 (0.3646)	Training Prec@1 92.188 (93.381)	Training Prec@5 95.117 (96.646)	
2022-05-10 19:26:07,106: ============================================================
2022-05-10 19:26:53,629: time cost, forward:0.17776705511850327, backward:0.10423969383814827, data cost:0.19740645609908367 
2022-05-10 19:26:53,630: ============================================================
2022-05-10 19:26:53,630: Epoch 6/38 Batch 200/7662 eta: 1 day, 8:39:02.516519	Training Loss 0.3586 (0.3667)	Training Prec@1 93.555 (93.251)	Training Prec@5 97.070 (96.533)	
2022-05-10 19:26:53,630: ============================================================
2022-05-10 19:27:40,158: time cost, forward:0.17556121437047237, backward:0.10426512051585526, data cost:0.1947757424319468 
2022-05-10 19:27:40,159: ============================================================
2022-05-10 19:27:40,159: Epoch 6/38 Batch 300/7662 eta: 1 day, 8:38:27.186106	Training Loss 0.3681 (0.3685)	Training Prec@1 92.969 (93.182)	Training Prec@5 95.898 (96.500)	
2022-05-10 19:27:40,159: ============================================================
2022-05-10 19:28:26,699: time cost, forward:0.1744662783199683, backward:0.10428196505496376, data cost:0.1934829588820761 
2022-05-10 19:28:26,699: ============================================================
2022-05-10 19:28:26,699: Epoch 6/38 Batch 400/7662 eta: 1 day, 8:38:10.560499	Training Loss 0.3715 (0.3699)	Training Prec@1 93.555 (93.125)	Training Prec@5 97.070 (96.454)	
2022-05-10 19:28:26,700: ============================================================
2022-05-10 19:29:13,257: time cost, forward:0.17384016059921356, backward:0.10429686248183012, data cost:0.1927098076424761 
2022-05-10 19:29:13,258: ============================================================
2022-05-10 19:29:13,258: Epoch 6/38 Batch 500/7662 eta: 1 day, 8:38:08.495608	Training Loss 0.3833 (0.3713)	Training Prec@1 92.969 (93.002)	Training Prec@5 95.117 (96.400)	
2022-05-10 19:29:13,258: ============================================================
2022-05-10 19:29:59,795: time cost, forward:0.17340012583788328, backward:0.1042964518169728, data cost:0.19219095758683297 
2022-05-10 19:29:59,795: ============================================================
2022-05-10 19:29:59,795: Epoch 6/38 Batch 600/7662 eta: 1 day, 8:36:29.540001	Training Loss 0.3889 (0.3725)	Training Prec@1 90.625 (92.910)	Training Prec@5 94.922 (96.328)	
2022-05-10 19:29:59,795: ============================================================
2022-05-10 19:30:46,336: time cost, forward:0.17310473062790854, backward:0.10429974823380063, data cost:0.19180540636032606 
2022-05-10 19:30:46,337: ============================================================
2022-05-10 19:30:46,337: Epoch 6/38 Batch 700/7662 eta: 1 day, 8:35:53.067775	Training Loss 0.3902 (0.3734)	Training Prec@1 92.383 (92.856)	Training Prec@5 95.898 (96.313)	
2022-05-10 19:30:46,337: ============================================================
2022-05-10 19:31:32,833: time cost, forward:0.1728634386695222, backward:0.10429382741973457, data cost:0.19149044607398805 
2022-05-10 19:31:32,833: ============================================================
2022-05-10 19:31:32,834: Epoch 6/38 Batch 800/7662 eta: 1 day, 8:33:13.669775	Training Loss 0.3780 (0.3742)	Training Prec@1 91.992 (92.793)	Training Prec@5 94.531 (96.261)	
2022-05-10 19:31:32,834: ============================================================
2022-05-10 19:32:19,344: time cost, forward:0.1726799979225812, backward:0.10429586054088011, data cost:0.19125084882318244 
2022-05-10 19:32:19,345: ============================================================
2022-05-10 19:32:19,345: Epoch 6/38 Batch 900/7662 eta: 1 day, 8:33:03.451001	Training Loss 0.3817 (0.3749)	Training Prec@1 92.383 (92.736)	Training Prec@5 96.094 (96.216)	
2022-05-10 19:32:19,345: ============================================================
2022-05-10 19:33:05,839: time cost, forward:0.17251377850323468, backward:0.1042917734151846, data cost:0.19106707558617578 
2022-05-10 19:33:05,840: ============================================================
2022-05-10 19:33:05,840: Epoch 6/38 Batch 1000/7662 eta: 1 day, 8:31:36.839394	Training Loss 0.3848 (0.3754)	Training Prec@1 92.969 (92.690)	Training Prec@5 96.680 (96.196)	
2022-05-10 19:33:05,840: ============================================================
2022-05-10 19:33:52,342: time cost, forward:0.17239068702093788, backward:0.10429180525344973, data cost:0.19090729675258258 
2022-05-10 19:33:52,342: ============================================================
2022-05-10 19:33:52,342: Epoch 6/38 Batch 1100/7662 eta: 1 day, 8:31:08.606804	Training Loss 0.3899 (0.3759)	Training Prec@1 91.016 (92.633)	Training Prec@5 94.727 (96.156)	
2022-05-10 19:33:52,343: ============================================================
2022-05-10 19:34:38,870: time cost, forward:0.17229941171641347, backward:0.1042926643568839, data cost:0.19078333582651427 
2022-05-10 19:34:38,870: ============================================================
2022-05-10 19:34:38,870: Epoch 6/38 Batch 1200/7662 eta: 1 day, 8:31:25.600085	Training Loss 0.3817 (0.3764)	Training Prec@1 92.578 (92.575)	Training Prec@5 96.094 (96.125)	
2022-05-10 19:34:38,870: ============================================================
2022-05-10 19:35:25,385: time cost, forward:0.17221416685561017, backward:0.10429346056696633, data cost:0.19067706815823857 
2022-05-10 19:35:25,385: ============================================================
2022-05-10 19:35:25,385: Epoch 6/38 Batch 1300/7662 eta: 1 day, 8:30:06.612324	Training Loss 0.3908 (0.3767)	Training Prec@1 91.406 (92.550)	Training Prec@5 95.117 (96.109)	
2022-05-10 19:35:25,385: ============================================================
2022-05-10 19:36:11,896: time cost, forward:0.17213586520262494, backward:0.10429358431234625, data cost:0.19058921338831894 
2022-05-10 19:36:11,896: ============================================================
2022-05-10 19:36:11,896: Epoch 6/38 Batch 1400/7662 eta: 1 day, 8:29:11.666196	Training Loss 0.3860 (0.3771)	Training Prec@1 90.625 (92.521)	Training Prec@5 95.312 (96.092)	
2022-05-10 19:36:11,897: ============================================================
2022-05-10 19:36:58,427: time cost, forward:0.1720805417863109, backward:0.10429712833763362, data cost:0.1905108361819969 
2022-05-10 19:36:58,427: ============================================================
2022-05-10 19:36:58,427: Epoch 6/38 Batch 1500/7662 eta: 1 day, 8:29:14.408947	Training Loss 0.3764 (0.3774)	Training Prec@1 91.797 (92.494)	Training Prec@5 95.703 (96.079)	
2022-05-10 19:36:58,428: ============================================================
2022-05-10 19:37:44,982: time cost, forward:0.17205213218125945, backward:0.10429465465056591, data cost:0.1904417011721422 
2022-05-10 19:37:44,983: ============================================================
2022-05-10 19:37:44,983: Epoch 6/38 Batch 1600/7662 eta: 1 day, 8:29:28.614279	Training Loss 0.3799 (0.3777)	Training Prec@1 92.383 (92.458)	Training Prec@5 95.508 (96.051)	
2022-05-10 19:37:44,983: ============================================================
2022-05-10 19:38:31,504: time cost, forward:0.17200497699667947, backward:0.10429624938628054, data cost:0.19038019073647988 
2022-05-10 19:38:31,504: ============================================================
2022-05-10 19:38:31,504: Epoch 6/38 Batch 1700/7662 eta: 1 day, 8:27:17.393199	Training Loss 0.3764 (0.3779)	Training Prec@1 93.555 (92.428)	Training Prec@5 95.703 (96.036)	
2022-05-10 19:38:31,504: ============================================================
2022-05-10 19:39:18,027: time cost, forward:0.17196141089778136, backward:0.10429842674844858, data cost:0.19032794134427336 
2022-05-10 19:39:18,028: ============================================================
2022-05-10 19:39:18,028: Epoch 6/38 Batch 1800/7662 eta: 1 day, 8:26:36.516538	Training Loss 0.3861 (0.3781)	Training Prec@1 91.211 (92.409)	Training Prec@5 95.508 (96.024)	
2022-05-10 19:39:18,028: ============================================================
2022-05-10 19:40:04,584: time cost, forward:0.17192564731274484, backward:0.10430238936184706, data cost:0.1902923147071971 
2022-05-10 19:40:04,584: ============================================================
2022-05-10 19:40:04,585: Epoch 6/38 Batch 1900/7662 eta: 1 day, 8:27:12.477992	Training Loss 0.3838 (0.3783)	Training Prec@1 93.164 (92.385)	Training Prec@5 96.484 (96.006)	
2022-05-10 19:40:04,585: ============================================================
2022-05-10 19:40:51,149: time cost, forward:0.17189857517259607, backward:0.10430807468591778, data cost:0.19025733066595096 
2022-05-10 19:40:51,150: ============================================================
2022-05-10 19:40:51,150: Epoch 6/38 Batch 2000/7662 eta: 1 day, 8:26:47.248983	Training Loss 0.3866 (0.3786)	Training Prec@1 92.578 (92.363)	Training Prec@5 95.117 (95.992)	
2022-05-10 19:40:51,150: ============================================================
2022-05-10 19:41:37,684: time cost, forward:0.17186466190234545, backward:0.10431033625609537, data cost:0.1902234680372059 
2022-05-10 19:41:37,684: ============================================================
2022-05-10 19:41:37,685: Epoch 6/38 Batch 2100/7662 eta: 1 day, 8:24:44.482370	Training Loss 0.3951 (0.3787)	Training Prec@1 90.039 (92.348)	Training Prec@5 94.141 (95.988)	
2022-05-10 19:41:37,685: ============================================================
2022-05-10 19:42:24,206: time cost, forward:0.17183234671019815, backward:0.10431111634129987, data cost:0.19018985868421887 
2022-05-10 19:42:24,206: ============================================================
2022-05-10 19:42:24,206: Epoch 6/38 Batch 2200/7662 eta: 1 day, 8:23:24.461125	Training Loss 0.3799 (0.3788)	Training Prec@1 92.383 (92.327)	Training Prec@5 95.703 (95.974)	
2022-05-10 19:42:24,206: ============================================================
2022-05-10 19:43:10,735: time cost, forward:0.1718017175540866, backward:0.10430863744645287, data cost:0.19016594832853007 
2022-05-10 19:43:10,735: ============================================================
2022-05-10 19:43:10,735: Epoch 6/38 Batch 2300/7662 eta: 1 day, 8:22:58.247269	Training Loss 0.3716 (0.3790)	Training Prec@1 91.797 (92.307)	Training Prec@5 96.094 (95.960)	
2022-05-10 19:43:10,736: ============================================================
2022-05-10 19:43:57,286: time cost, forward:0.17177382584858458, backward:0.10430953581167192, data cost:0.19014980416339652 
2022-05-10 19:43:57,286: ============================================================
2022-05-10 19:43:57,287: Epoch 6/38 Batch 2400/7662 eta: 1 day, 8:23:05.942131	Training Loss 0.3760 (0.3790)	Training Prec@1 93.164 (92.291)	Training Prec@5 95.898 (95.950)	
2022-05-10 19:43:57,287: ============================================================
2022-05-10 19:44:43,852: time cost, forward:0.171744598298609, backward:0.10431090933458954, data cost:0.19014446083761874 
2022-05-10 19:44:43,853: ============================================================
2022-05-10 19:44:43,853: Epoch 6/38 Batch 2500/7662 eta: 1 day, 8:22:57.602845	Training Loss 0.3977 (0.3792)	Training Prec@1 87.305 (92.271)	Training Prec@5 91.992 (95.938)	
2022-05-10 19:44:43,853: ============================================================
2022-05-10 19:45:30,387: time cost, forward:0.17171725964445295, backward:0.10431234228377069, data cost:0.19012796654064593 
2022-05-10 19:45:30,387: ============================================================
2022-05-10 19:45:30,387: Epoch 6/38 Batch 2600/7662 eta: 1 day, 8:20:50.653549	Training Loss 0.3753 (0.3793)	Training Prec@1 92.383 (92.258)	Training Prec@5 95.898 (95.931)	
2022-05-10 19:45:30,387: ============================================================
2022-05-10 19:46:16,958: time cost, forward:0.17169748592836057, backward:0.10431641620722203, data cost:0.19011828739495576 
2022-05-10 19:46:16,959: ============================================================
2022-05-10 19:46:16,959: Epoch 6/38 Batch 2700/7662 eta: 1 day, 8:21:36.935323	Training Loss 0.3787 (0.3793)	Training Prec@1 90.234 (92.245)	Training Prec@5 94.727 (95.920)	
2022-05-10 19:46:16,959: ============================================================
2022-05-10 19:47:03,537: time cost, forward:0.17167840279950206, backward:0.10431758409399951, data cost:0.19011442309492355 
2022-05-10 19:47:03,538: ============================================================
2022-05-10 19:47:03,538: Epoch 6/38 Batch 2800/7662 eta: 1 day, 8:21:09.607930	Training Loss 0.3921 (0.3794)	Training Prec@1 90.430 (92.230)	Training Prec@5 93.945 (95.906)	
2022-05-10 19:47:03,538: ============================================================
2022-05-10 19:47:50,091: time cost, forward:0.17165971517809592, backward:0.10432024683036159, data cost:0.1901018834188092 
2022-05-10 19:47:50,091: ============================================================
2022-05-10 19:47:50,091: Epoch 6/38 Batch 2900/7662 eta: 1 day, 8:19:19.046692	Training Loss 0.3633 (0.3795)	Training Prec@1 92.383 (92.216)	Training Prec@5 95.312 (95.899)	
2022-05-10 19:47:50,091: ============================================================
2022-05-10 19:48:36,725: time cost, forward:0.1716381256164571, backward:0.10435597918040755, data cost:0.19008742494955186 
2022-05-10 19:48:36,725: ============================================================
2022-05-10 19:48:36,726: Epoch 6/38 Batch 3000/7662 eta: 1 day, 8:21:54.217822	Training Loss 0.3855 (0.3795)	Training Prec@1 92.578 (92.206)	Training Prec@5 96.484 (95.895)	
2022-05-10 19:48:36,726: ============================================================
2022-05-10 19:49:23,444: time cost, forward:0.17162963643155585, backward:0.10440436229662728, data cost:0.19007451844315407 
2022-05-10 19:49:23,445: ============================================================
2022-05-10 19:49:23,445: Epoch 6/38 Batch 3100/7662 eta: 1 day, 8:24:40.372980	Training Loss 0.3701 (0.3796)	Training Prec@1 91.992 (92.199)	Training Prec@5 96.289 (95.893)	
2022-05-10 19:49:23,445: ============================================================
2022-05-10 19:50:10,115: time cost, forward:0.17161193569215547, backward:0.10444172802251665, data cost:0.19006557895377785 
2022-05-10 19:50:10,115: ============================================================
2022-05-10 19:50:10,116: Epoch 6/38 Batch 3200/7662 eta: 1 day, 8:21:51.957971	Training Loss 0.3767 (0.3797)	Training Prec@1 91.602 (92.186)	Training Prec@5 96.875 (95.888)	
2022-05-10 19:50:10,116: ============================================================
2022-05-10 19:50:56,694: time cost, forward:0.17159753577136097, backward:0.10443894868187559, data cost:0.19006494812330862 
2022-05-10 19:50:56,695: ============================================================
2022-05-10 19:50:56,695: Epoch 6/38 Batch 3300/7662 eta: 1 day, 8:17:16.768425	Training Loss 0.3776 (0.3797)	Training Prec@1 92.188 (92.180)	Training Prec@5 95.508 (95.881)	
2022-05-10 19:50:56,695: ============================================================
2022-05-10 19:51:43,319: time cost, forward:0.17158457250165812, backward:0.10443609670598074, data cost:0.19007705456721638 
2022-05-10 19:51:43,320: ============================================================
2022-05-10 19:51:43,320: Epoch 6/38 Batch 3400/7662 eta: 1 day, 8:18:24.746417	Training Loss 0.3763 (0.3798)	Training Prec@1 93.945 (92.167)	Training Prec@5 96.875 (95.872)	
2022-05-10 19:51:43,320: ============================================================
2022-05-10 19:52:29,924: time cost, forward:0.17156356428309352, backward:0.1044327722818179, data cost:0.1900893360861849 
2022-05-10 19:52:29,925: ============================================================
2022-05-10 19:52:29,925: Epoch 6/38 Batch 3500/7662 eta: 1 day, 8:16:48.097464	Training Loss 0.3899 (0.3798)	Training Prec@1 91.797 (92.160)	Training Prec@5 96.094 (95.869)	
2022-05-10 19:52:29,925: ============================================================
2022-05-10 19:53:16,461: time cost, forward:0.17154263714745033, backward:0.10442961444785841, data cost:0.1900861442801223 
2022-05-10 19:53:16,462: ============================================================
2022-05-10 19:53:16,462: Epoch 6/38 Batch 3600/7662 eta: 1 day, 8:13:11.972249	Training Loss 0.3810 (0.3798)	Training Prec@1 91.016 (92.148)	Training Prec@5 94.531 (95.861)	
2022-05-10 19:53:16,462: ============================================================
2022-05-10 19:54:03,073: time cost, forward:0.1715284438028823, backward:0.10442649141844301, data cost:0.1900949217751723 
2022-05-10 19:54:03,074: ============================================================
2022-05-10 19:54:03,074: Epoch 6/38 Batch 3700/7662 eta: 1 day, 8:15:32.915809	Training Loss 0.3851 (0.3799)	Training Prec@1 93.750 (92.140)	Training Prec@5 96.094 (95.858)	
2022-05-10 19:54:03,074: ============================================================
2022-05-10 19:54:49,642: time cost, forward:0.17151119333092996, backward:0.10442196309299775, data cost:0.1901001535487445 
2022-05-10 19:54:49,642: ============================================================
2022-05-10 19:54:49,642: Epoch 6/38 Batch 3800/7662 eta: 1 day, 8:12:56.805085	Training Loss 0.3760 (0.3800)	Training Prec@1 92.969 (92.127)	Training Prec@5 96.680 (95.851)	
2022-05-10 19:54:49,642: ============================================================
2022-05-10 19:55:36,251: time cost, forward:0.1714956416139605, backward:0.10441738521481025, data cost:0.19011268813844276 
2022-05-10 19:55:36,251: ============================================================
2022-05-10 19:55:36,251: Epoch 6/38 Batch 3900/7662 eta: 1 day, 8:13:52.132715	Training Loss 0.3889 (0.3800)	Training Prec@1 92.188 (92.125)	Training Prec@5 95.898 (95.849)	
2022-05-10 19:55:36,251: ============================================================
2022-05-10 19:56:22,801: time cost, forward:0.17147566724282617, backward:0.1044138771022788, data cost:0.19011632046958274 
2022-05-10 19:56:22,801: ============================================================
2022-05-10 19:56:22,802: Epoch 6/38 Batch 4000/7662 eta: 1 day, 8:10:38.982625	Training Loss 0.3775 (0.3800)	Training Prec@1 94.531 (92.121)	Training Prec@5 97.266 (95.844)	
2022-05-10 19:56:22,802: ============================================================
2022-05-10 19:57:09,370: time cost, forward:0.17145974259749946, backward:0.10440934544861331, data cost:0.19012025490886672 
2022-05-10 19:57:09,370: ============================================================
2022-05-10 19:57:09,370: Epoch 6/38 Batch 4100/7662 eta: 1 day, 8:10:37.926496	Training Loss 0.3868 (0.3800)	Training Prec@1 90.625 (92.115)	Training Prec@5 95.898 (95.840)	
2022-05-10 19:57:09,370: ============================================================
2022-05-10 19:57:55,915: time cost, forward:0.17144387465029792, backward:0.10440529718601184, data cost:0.19012040676290462 
2022-05-10 19:57:55,915: ============================================================
2022-05-10 19:57:55,915: Epoch 6/38 Batch 4200/7662 eta: 1 day, 8:08:52.561380	Training Loss 0.3864 (0.3800)	Training Prec@1 91.211 (92.113)	Training Prec@5 95.312 (95.838)	
2022-05-10 19:57:55,915: ============================================================
2022-05-10 19:58:42,478: time cost, forward:0.1714230885919401, backward:0.10440165682098537, data cost:0.1901306433854033 
2022-05-10 19:58:42,478: ============================================================
2022-05-10 19:58:42,478: Epoch 6/38 Batch 4300/7662 eta: 1 day, 8:08:51.543361	Training Loss 0.3838 (0.3800)	Training Prec@1 92.773 (92.102)	Training Prec@5 96.094 (95.834)	
2022-05-10 19:58:42,478: ============================================================
2022-05-10 19:59:29,007: time cost, forward:0.1714089613769455, backward:0.10439995013196025, data cost:0.19012533873150256 
2022-05-10 19:59:29,007: ============================================================
2022-05-10 19:59:29,007: Epoch 6/38 Batch 4400/7662 eta: 1 day, 8:06:38.861622	Training Loss 0.3853 (0.3800)	Training Prec@1 92.578 (92.100)	Training Prec@5 96.680 (95.835)	
2022-05-10 19:59:29,007: ============================================================
2022-05-10 20:00:16,374: time cost, forward:0.17156810621654597, backward:0.10440915323517327, data cost:0.1901206784207017 
2022-05-10 20:00:16,375: ============================================================
2022-05-10 20:00:16,375: Epoch 6/38 Batch 4500/7662 eta: 1 day, 8:40:37.057365	Training Loss 0.3782 (0.3801)	Training Prec@1 91.797 (92.092)	Training Prec@5 95.508 (95.829)	
2022-05-10 20:00:16,375: ============================================================
2022-05-10 20:01:02,943: time cost, forward:0.17155233194683395, backward:0.1044051405086961, data cost:0.1901258017400421 
2022-05-10 20:01:02,943: ============================================================
2022-05-10 20:01:02,943: Epoch 6/38 Batch 4600/7662 eta: 1 day, 8:06:44.365700	Training Loss 0.3985 (0.3801)	Training Prec@1 89.648 (92.087)	Training Prec@5 93.945 (95.825)	
2022-05-10 20:01:02,943: ============================================================
2022-05-10 20:01:49,533: time cost, forward:0.17154973921661149, backward:0.10440253607641765, data cost:0.19012165759618954 
2022-05-10 20:01:49,533: ============================================================
2022-05-10 20:01:49,533: Epoch 6/38 Batch 4700/7662 eta: 1 day, 8:06:51.617275	Training Loss 0.3858 (0.3801)	Training Prec@1 91.992 (92.083)	Training Prec@5 94.922 (95.823)	
2022-05-10 20:01:49,533: ============================================================
2022-05-10 20:02:36,080: time cost, forward:0.17153812552720563, backward:0.10439857335656005, data cost:0.19011720624360523 
2022-05-10 20:02:36,081: ============================================================
2022-05-10 20:02:36,081: Epoch 6/38 Batch 4800/7662 eta: 1 day, 8:04:20.636300	Training Loss 0.3831 (0.3801)	Training Prec@1 90.625 (92.077)	Training Prec@5 97.070 (95.820)	
2022-05-10 20:02:36,081: ============================================================
2022-05-10 20:03:22,627: time cost, forward:0.17152172104391086, backward:0.1043946207676841, data cost:0.19011575057813648 
2022-05-10 20:03:22,627: ============================================================
2022-05-10 20:03:22,627: Epoch 6/38 Batch 4900/7662 eta: 1 day, 8:03:29.762956	Training Loss 0.3828 (0.3802)	Training Prec@1 90.430 (92.072)	Training Prec@5 96.094 (95.816)	
2022-05-10 20:03:22,627: ============================================================
2022-05-10 20:04:09,214: time cost, forward:0.17150822523284565, backward:0.10439049994904986, data cost:0.19012295148162323 
2022-05-10 20:04:09,215: ============================================================
2022-05-10 20:04:09,215: Epoch 6/38 Batch 5000/7662 eta: 1 day, 8:04:25.817680	Training Loss 0.3787 (0.3802)	Training Prec@1 91.992 (92.068)	Training Prec@5 95.508 (95.813)	
2022-05-10 20:04:09,215: ============================================================
2022-05-10 20:04:55,817: time cost, forward:0.1715063770089951, backward:0.10438569163920763, data cost:0.19012462094522592 
2022-05-10 20:04:55,817: ============================================================
2022-05-10 20:04:55,817: Epoch 6/38 Batch 5100/7662 eta: 1 day, 8:04:16.645851	Training Loss 0.3817 (0.3802)	Training Prec@1 91.992 (92.065)	Training Prec@5 96.680 (95.813)	
2022-05-10 20:04:55,818: ============================================================
2022-05-10 20:05:42,432: time cost, forward:0.1714993589404547, backward:0.10438114882753684, data cost:0.1901336411004526 
2022-05-10 20:05:42,432: ============================================================
2022-05-10 20:05:42,433: Epoch 6/38 Batch 5200/7662 eta: 1 day, 8:04:01.082454	Training Loss 0.3725 (0.3802)	Training Prec@1 92.188 (92.059)	Training Prec@5 95.898 (95.809)	
2022-05-10 20:05:42,433: ============================================================
2022-05-10 20:06:29,010: time cost, forward:0.17148635283486532, backward:0.10437787598226403, data cost:0.19013837932033076 
2022-05-10 20:06:29,010: ============================================================
2022-05-10 20:06:29,010: Epoch 6/38 Batch 5300/7662 eta: 1 day, 8:01:41.384785	Training Loss 0.3669 (0.3802)	Training Prec@1 93.164 (92.058)	Training Prec@5 95.703 (95.808)	
2022-05-10 20:06:29,010: ============================================================
2022-05-10 20:07:15,559: time cost, forward:0.17147737199409205, backward:0.1043740135361738, data cost:0.19013696472873112 
2022-05-10 20:07:15,560: ============================================================
2022-05-10 20:07:15,560: Epoch 6/38 Batch 5400/7662 eta: 1 day, 7:59:45.849192	Training Loss 0.3934 (0.3803)	Training Prec@1 91.797 (92.051)	Training Prec@5 96.289 (95.806)	
2022-05-10 20:07:15,560: ============================================================
2022-05-10 20:08:02,162: time cost, forward:0.1714691075656084, backward:0.10437159539136177, data cost:0.19014343176566162 
2022-05-10 20:08:02,162: ============================================================
2022-05-10 20:08:02,163: Epoch 6/38 Batch 5500/7662 eta: 1 day, 8:01:10.260054	Training Loss 0.3723 (0.3803)	Training Prec@1 91.016 (92.048)	Training Prec@5 94.336 (95.803)	
2022-05-10 20:08:02,163: ============================================================
2022-05-10 20:08:48,707: time cost, forward:0.17145933353766776, backward:0.1043678421402727, data cost:0.19014044041334677 
2022-05-10 20:08:48,708: ============================================================
2022-05-10 20:08:48,708: Epoch 6/38 Batch 5600/7662 eta: 1 day, 7:58:01.498913	Training Loss 0.3819 (0.3803)	Training Prec@1 92.773 (92.043)	Training Prec@5 95.703 (95.801)	
2022-05-10 20:08:48,708: ============================================================
2022-05-10 20:09:35,277: time cost, forward:0.17145054171766852, backward:0.10436409961802852, data cost:0.1901421504682523 
2022-05-10 20:09:35,277: ============================================================
2022-05-10 20:09:35,277: Epoch 6/38 Batch 5700/7662 eta: 1 day, 7:58:15.205173	Training Loss 0.3792 (0.3803)	Training Prec@1 90.625 (92.037)	Training Prec@5 94.922 (95.797)	
2022-05-10 20:09:35,277: ============================================================
2022-05-10 20:10:21,807: time cost, forward:0.17144347158130396, backward:0.10436147433927417, data cost:0.1901370533007263 
2022-05-10 20:10:21,808: ============================================================
2022-05-10 20:10:21,808: Epoch 6/38 Batch 5800/7662 eta: 1 day, 7:55:52.566413	Training Loss 0.3551 (0.3803)	Training Prec@1 93.359 (92.035)	Training Prec@5 96.289 (95.796)	
2022-05-10 20:10:21,808: ============================================================
2022-05-10 20:11:08,355: time cost, forward:0.17143749269232303, backward:0.10435852601904448, data cost:0.19013364223286872 
2022-05-10 20:11:08,355: ============================================================
2022-05-10 20:11:08,356: Epoch 6/38 Batch 5900/7662 eta: 1 day, 7:55:47.880653	Training Loss 0.3920 (0.3803)	Training Prec@1 91.797 (92.031)	Training Prec@5 94.727 (95.794)	
2022-05-10 20:11:08,356: ============================================================
2022-05-10 20:11:54,919: time cost, forward:0.17142851894389471, backward:0.10435598574989854, data cost:0.1901361197109003 
2022-05-10 20:11:54,919: ============================================================
2022-05-10 20:11:54,920: Epoch 6/38 Batch 6000/7662 eta: 1 day, 7:55:42.095764	Training Loss 0.3762 (0.3803)	Training Prec@1 92.773 (92.033)	Training Prec@5 95.703 (95.795)	
2022-05-10 20:11:54,920: ============================================================
2022-05-10 20:12:41,440: time cost, forward:0.1714170148752228, backward:0.10435360078831973, data cost:0.19013413282120145 
2022-05-10 20:12:41,441: ============================================================
2022-05-10 20:12:41,441: Epoch 6/38 Batch 6100/7662 eta: 1 day, 7:53:09.352249	Training Loss 0.3856 (0.3803)	Training Prec@1 92.773 (92.032)	Training Prec@5 95.703 (95.797)	
2022-05-10 20:12:41,441: ============================================================
2022-05-10 20:13:27,935: time cost, forward:0.17140609726903516, backward:0.10435164611288417, data cost:0.1901275428154138 
2022-05-10 20:13:27,935: ============================================================
2022-05-10 20:13:27,935: Epoch 6/38 Batch 6200/7662 eta: 1 day, 7:51:17.303335	Training Loss 0.3833 (0.3803)	Training Prec@1 91.992 (92.029)	Training Prec@5 95.898 (95.795)	
2022-05-10 20:13:27,935: ============================================================
2022-05-10 20:14:14,449: time cost, forward:0.17139529727682043, backward:0.10434839630490315, data cost:0.19012584495514154 
2022-05-10 20:14:14,449: ============================================================
2022-05-10 20:14:14,450: Epoch 6/38 Batch 6300/7662 eta: 1 day, 7:51:19.553294	Training Loss 0.3783 (0.3803)	Training Prec@1 91.602 (92.021)	Training Prec@5 94.531 (95.790)	
2022-05-10 20:14:14,450: ============================================================
2022-05-10 20:15:00,985: time cost, forward:0.17138744600304665, backward:0.10434555843446866, data cost:0.19012475803617873 
2022-05-10 20:15:00,985: ============================================================
2022-05-10 20:15:00,985: Epoch 6/38 Batch 6400/7662 eta: 1 day, 7:51:25.139919	Training Loss 0.3883 (0.3804)	Training Prec@1 89.844 (92.018)	Training Prec@5 94.141 (95.788)	
2022-05-10 20:15:00,985: ============================================================
2022-05-10 20:15:47,504: time cost, forward:0.17137677531221093, backward:0.10434313777190463, data cost:0.19012366406531275 
2022-05-10 20:15:47,504: ============================================================
2022-05-10 20:15:47,504: Epoch 6/38 Batch 6500/7662 eta: 1 day, 7:49:59.283463	Training Loss 0.3721 (0.3804)	Training Prec@1 93.164 (92.012)	Training Prec@5 96.680 (95.784)	
2022-05-10 20:15:47,504: ============================================================
2022-05-10 20:16:33,986: time cost, forward:0.17136409629888832, backward:0.10434120827542054, data cost:0.19011562859439401 
2022-05-10 20:16:33,986: ============================================================
2022-05-10 20:16:33,987: Epoch 6/38 Batch 6600/7662 eta: 1 day, 7:47:41.029264	Training Loss 0.3740 (0.3804)	Training Prec@1 91.602 (92.008)	Training Prec@5 95.898 (95.781)	
2022-05-10 20:16:33,987: ============================================================
2022-05-10 20:17:20,496: time cost, forward:0.17135581419990745, backward:0.10433912013854388, data cost:0.19010977525108874 
2022-05-10 20:17:20,497: ============================================================
2022-05-10 20:17:20,497: Epoch 6/38 Batch 6700/7662 eta: 1 day, 7:48:03.914521	Training Loss 0.3849 (0.3803)	Training Prec@1 91.016 (92.007)	Training Prec@5 95.312 (95.781)	
2022-05-10 20:17:20,497: ============================================================
2022-05-10 20:18:07,085: time cost, forward:0.17134954572022004, backward:0.10433726237791219, data cost:0.19011350283992345 
2022-05-10 20:18:07,086: ============================================================
2022-05-10 20:18:07,086: Epoch 6/38 Batch 6800/7662 eta: 1 day, 7:50:30.459013	Training Loss 0.4019 (0.3803)	Training Prec@1 89.844 (92.007)	Training Prec@5 94.727 (95.780)	
2022-05-10 20:18:07,086: ============================================================
2022-05-10 20:18:53,682: time cost, forward:0.17134758534163974, backward:0.10433521124224228, data cost:0.190115946723959 
2022-05-10 20:18:53,682: ============================================================
2022-05-10 20:18:53,695: Epoch 6/38 Batch 6900/7662 eta: 1 day, 7:50:33.555013	Training Loss 0.3624 (0.3803)	Training Prec@1 94.141 (92.006)	Training Prec@5 97.266 (95.778)	
2022-05-10 20:18:53,695: ============================================================
2022-05-10 20:19:40,365: time cost, forward:0.17134908956022735, backward:0.10433350912007729, data cost:0.1901269199201287 
2022-05-10 20:19:40,365: ============================================================
2022-05-10 20:19:40,365: Epoch 6/38 Batch 7000/7662 eta: 1 day, 7:52:17.909935	Training Loss 0.3833 (0.3803)	Training Prec@1 92.969 (92.006)	Training Prec@5 95.312 (95.778)	
2022-05-10 20:19:40,365: ============================================================
2022-05-10 20:20:26,988: time cost, forward:0.17135121651410484, backward:0.10433142355486177, data cost:0.19012882246368618 
2022-05-10 20:20:26,988: ============================================================
2022-05-10 20:20:26,988: Epoch 6/38 Batch 7100/7662 eta: 1 day, 7:49:34.480619	Training Loss 0.3834 (0.3803)	Training Prec@1 90.430 (92.004)	Training Prec@5 94.531 (95.776)	
2022-05-10 20:20:26,988: ============================================================
2022-05-10 20:21:13,533: time cost, forward:0.17134632314471904, backward:0.10433022875573209, data cost:0.1901249191730879 
2022-05-10 20:21:13,533: ============================================================
2022-05-10 20:21:13,533: Epoch 6/38 Batch 7200/7662 eta: 1 day, 7:45:36.395752	Training Loss 0.3789 (0.3803)	Training Prec@1 92.578 (92.003)	Training Prec@5 95.312 (95.776)	
2022-05-10 20:21:13,533: ============================================================
2022-05-10 20:22:00,193: time cost, forward:0.17134894353263197, backward:0.10432920186123401, data cost:0.19013071269233808 
2022-05-10 20:22:00,193: ============================================================
2022-05-10 20:22:00,194: Epoch 6/38 Batch 7300/7662 eta: 1 day, 7:49:32.849210	Training Loss 0.3726 (0.3803)	Training Prec@1 93.164 (92.001)	Training Prec@5 96.875 (95.775)	
2022-05-10 20:22:00,194: ============================================================
2022-05-10 20:22:46,850: time cost, forward:0.1713535826920593, backward:0.10432973528636567, data cost:0.1901319384623225 
2022-05-10 20:22:46,851: ============================================================
2022-05-10 20:22:46,851: Epoch 6/38 Batch 7400/7662 eta: 1 day, 7:48:38.692073	Training Loss 0.3725 (0.3803)	Training Prec@1 91.992 (91.998)	Training Prec@5 96.289 (95.773)	
2022-05-10 20:22:46,851: ============================================================
2022-05-10 20:23:33,557: time cost, forward:0.17135437397436074, backward:0.10433105396133913, data cost:0.19014190409815873 
2022-05-10 20:23:33,558: ============================================================
2022-05-10 20:23:33,558: Epoch 6/38 Batch 7500/7662 eta: 1 day, 7:49:54.708258	Training Loss 0.3816 (0.3803)	Training Prec@1 92.969 (91.997)	Training Prec@5 96.289 (95.771)	
2022-05-10 20:23:33,558: ============================================================
2022-05-10 20:24:20,250: time cost, forward:0.17135255037757782, backward:0.10433215626855794, data cost:0.1901521275805586 
2022-05-10 20:24:20,251: ============================================================
2022-05-10 20:24:20,251: Epoch 6/38 Batch 7600/7662 eta: 1 day, 7:48:33.240958	Training Loss 0.3825 (0.3803)	Training Prec@1 89.844 (91.995)	Training Prec@5 96.094 (95.770)	
2022-05-10 20:24:20,251: ============================================================
2022-05-10 20:24:50,948: Epoch: 6/38 eta: 1 day, 7:48:03.824353	Training Loss 0.3775 (0.3803)	Training Prec@1 90.820 (91.993)	Training Prec@5 93.750 (95.768)
2022-05-10 20:24:50,948: ============================================================
2022-05-10 20:25:38,404: time cost, forward:0.1718245202844793, backward:0.10432478394171205, data cost:0.20097306762078795 
2022-05-10 20:25:38,405: ============================================================
2022-05-10 20:25:38,405: Epoch 7/38 Batch 100/7662 eta: 1 day, 8:18:19.514994	Training Loss 0.3772 (0.3607)	Training Prec@1 91.797 (93.428)	Training Prec@5 95.312 (96.636)	
2022-05-10 20:25:38,405: ============================================================
2022-05-10 20:26:24,949: time cost, forward:0.1716491373340089, backward:0.10428018665792954, data cost:0.19520401355609224 
2022-05-10 20:26:24,949: ============================================================
2022-05-10 20:26:24,949: Epoch 7/38 Batch 200/7662 eta: 1 day, 7:40:26.376570	Training Loss 0.3700 (0.3633)	Training Prec@1 92.773 (93.401)	Training Prec@5 96.094 (96.598)	
2022-05-10 20:26:24,949: ============================================================
2022-05-10 20:27:11,514: time cost, forward:0.1716103649458359, backward:0.10428898549797543, data cost:0.19331117138814766 
2022-05-10 20:27:11,514: ============================================================
2022-05-10 20:27:11,514: Epoch 7/38 Batch 300/7662 eta: 1 day, 7:40:31.295918	Training Loss 0.3654 (0.3654)	Training Prec@1 94.531 (93.269)	Training Prec@5 97.266 (96.544)	
2022-05-10 20:27:11,514: ============================================================
2022-05-10 20:27:57,986: time cost, forward:0.17138673548112837, backward:0.10428764168779951, data cost:0.19234949126279444 
2022-05-10 20:27:57,986: ============================================================
2022-05-10 20:27:57,986: Epoch 7/38 Batch 400/7662 eta: 1 day, 7:35:55.834770	Training Loss 0.3659 (0.3666)	Training Prec@1 92.969 (93.171)	Training Prec@5 96.289 (96.498)	
2022-05-10 20:27:57,986: ============================================================
2022-05-10 20:28:44,457: time cost, forward:0.1712901630478058, backward:0.1042871217211645, data cost:0.1917332274641446 
2022-05-10 20:28:44,458: ============================================================
2022-05-10 20:28:44,458: Epoch 7/38 Batch 500/7662 eta: 1 day, 7:35:09.636639	Training Loss 0.3643 (0.3676)	Training Prec@1 95.117 (93.129)	Training Prec@5 97.852 (96.485)	
2022-05-10 20:28:44,458: ============================================================
2022-05-10 20:29:30,893: time cost, forward:0.1711541694870377, backward:0.10429667272233406, data cost:0.19132380254678616 
2022-05-10 20:29:30,893: ============================================================
2022-05-10 20:29:30,893: Epoch 7/38 Batch 600/7662 eta: 1 day, 7:32:53.058605	Training Loss 0.3832 (0.3686)	Training Prec@1 91.211 (93.038)	Training Prec@5 95.898 (96.443)	
2022-05-10 20:29:30,893: ============================================================
2022-05-10 20:30:17,363: time cost, forward:0.1711024607029425, backward:0.10430765629496867, data cost:0.1910338828150977 
2022-05-10 20:30:17,363: ============================================================
2022-05-10 20:30:17,363: Epoch 7/38 Batch 700/7662 eta: 1 day, 7:33:32.556705	Training Loss 0.3855 (0.3697)	Training Prec@1 93.555 (92.929)	Training Prec@5 97.070 (96.378)	
2022-05-10 20:30:17,363: ============================================================
2022-05-10 20:31:03,822: time cost, forward:0.17105421285903796, backward:0.10430493551738867, data cost:0.1908221170212957 
2022-05-10 20:31:03,822: ============================================================
2022-05-10 20:31:03,823: Epoch 7/38 Batch 800/7662 eta: 1 day, 7:32:20.016628	Training Loss 0.3808 (0.3706)	Training Prec@1 91.602 (92.866)	Training Prec@5 95.898 (96.343)	
2022-05-10 20:31:03,823: ============================================================
2022-05-10 20:31:50,298: time cost, forward:0.17101458421140678, backward:0.10430870358485136, data cost:0.19066946312901176 
2022-05-10 20:31:50,299: ============================================================
2022-05-10 20:31:50,299: Epoch 7/38 Batch 900/7662 eta: 1 day, 7:32:14.203126	Training Loss 0.3648 (0.3713)	Training Prec@1 92.969 (92.816)	Training Prec@5 95.703 (96.319)	
2022-05-10 20:31:50,299: ============================================================
2022-05-10 20:32:36,791: time cost, forward:0.17099436553748878, backward:0.10431440671284993, data cost:0.19055075879330868 
2022-05-10 20:32:36,792: ============================================================
2022-05-10 20:32:36,792: Epoch 7/38 Batch 1000/7662 eta: 1 day, 7:32:09.137635	Training Loss 0.3846 (0.3718)	Training Prec@1 92.578 (92.786)	Training Prec@5 96.289 (96.302)	
2022-05-10 20:32:36,792: ============================================================
2022-05-10 20:33:23,297: time cost, forward:0.1709819714300626, backward:0.10432158002428188, data cost:0.1904590947721306 
2022-05-10 20:33:23,297: ============================================================
2022-05-10 20:33:23,297: Epoch 7/38 Batch 1100/7662 eta: 1 day, 7:31:52.944628	Training Loss 0.3794 (0.3725)	Training Prec@1 92.578 (92.712)	Training Prec@5 96.094 (96.268)	
2022-05-10 20:33:23,297: ============================================================
2022-05-10 20:34:09,780: time cost, forward:0.17096114755173938, backward:0.10432192263153814, data cost:0.19038223941888882 
2022-05-10 20:34:09,781: ============================================================
2022-05-10 20:34:09,781: Epoch 7/38 Batch 1200/7662 eta: 1 day, 7:30:12.508625	Training Loss 0.3828 (0.3729)	Training Prec@1 92.969 (92.668)	Training Prec@5 95.508 (96.240)	
2022-05-10 20:34:09,781: ============================================================
2022-05-10 20:34:56,220: time cost, forward:0.17093752419792568, backward:0.10431961906791376, data cost:0.1902932968389263 
2022-05-10 20:34:56,220: ============================================================
2022-05-10 20:34:56,221: Epoch 7/38 Batch 1300/7662 eta: 1 day, 7:27:39.890032	Training Loss 0.3648 (0.3733)	Training Prec@1 93.359 (92.628)	Training Prec@5 97.266 (96.209)	
2022-05-10 20:34:56,221: ============================================================
2022-05-10 20:35:42,707: time cost, forward:0.17094964210777475, backward:0.10431504028025826, data cost:0.19022062849027077 
2022-05-10 20:35:42,707: ============================================================
2022-05-10 20:35:42,708: Epoch 7/38 Batch 1400/7662 eta: 1 day, 7:28:48.163785	Training Loss 0.3813 (0.3735)	Training Prec@1 91.602 (92.605)	Training Prec@5 95.898 (96.186)	
2022-05-10 20:35:42,708: ============================================================
2022-05-10 20:36:29,199: time cost, forward:0.17096015355680846, backward:0.10431070722207139, data cost:0.19016254783233377 
2022-05-10 20:36:29,199: ============================================================
2022-05-10 20:36:29,199: Epoch 7/38 Batch 1500/7662 eta: 1 day, 7:28:13.225779	Training Loss 0.3859 (0.3739)	Training Prec@1 91.016 (92.567)	Training Prec@5 96.094 (96.163)	
2022-05-10 20:36:29,199: ============================================================
2022-05-10 20:37:15,702: time cost, forward:0.17097015243682956, backward:0.10430653293554748, data cost:0.19011740553297052 
2022-05-10 20:37:15,703: ============================================================
2022-05-10 20:37:15,703: Epoch 7/38 Batch 1600/7662 eta: 1 day, 7:27:55.981936	Training Loss 0.3752 (0.3741)	Training Prec@1 92.383 (92.542)	Training Prec@5 96.094 (96.149)	
2022-05-10 20:37:15,703: ============================================================
2022-05-10 20:38:02,229: time cost, forward:0.17098033336978438, backward:0.10430787043265556, data cost:0.1900863822871899 
2022-05-10 20:38:02,230: ============================================================
2022-05-10 20:38:02,230: Epoch 7/38 Batch 1700/7662 eta: 1 day, 7:28:06.253058	Training Loss 0.3809 (0.3743)	Training Prec@1 91.602 (92.511)	Training Prec@5 94.531 (96.135)	
2022-05-10 20:38:02,230: ============================================================
2022-05-10 20:38:48,752: time cost, forward:0.17098871570881902, backward:0.10430889821436884, data cost:0.1900573000767418 
2022-05-10 20:38:48,752: ============================================================
2022-05-10 20:38:48,753: Epoch 7/38 Batch 1800/7662 eta: 1 day, 7:27:09.505098	Training Loss 0.3834 (0.3746)	Training Prec@1 91.797 (92.487)	Training Prec@5 95.117 (96.117)	
2022-05-10 20:38:48,753: ============================================================
2022-05-10 20:39:35,280: time cost, forward:0.17100097619589533, backward:0.10431281725565593, data cost:0.1900258881597534 
2022-05-10 20:39:35,280: ============================================================
2022-05-10 20:39:35,280: Epoch 7/38 Batch 1900/7662 eta: 1 day, 7:26:34.963540	Training Loss 0.3927 (0.3748)	Training Prec@1 91.992 (92.463)	Training Prec@5 95.508 (96.104)	
2022-05-10 20:39:35,281: ============================================================
2022-05-10 20:40:21,816: time cost, forward:0.17100399813096245, backward:0.10431768776119321, data cost:0.19000774672652793 
2022-05-10 20:40:21,817: ============================================================
2022-05-10 20:40:21,817: Epoch 7/38 Batch 2000/7662 eta: 1 day, 7:26:09.471479	Training Loss 0.3814 (0.3749)	Training Prec@1 91.211 (92.451)	Training Prec@5 94.531 (96.090)	
2022-05-10 20:40:21,817: ============================================================
2022-05-10 20:41:08,291: time cost, forward:0.17099200435454873, backward:0.10431942648976232, data cost:0.18997852242293956 
2022-05-10 20:41:08,291: ============================================================
2022-05-10 20:41:08,291: Epoch 7/38 Batch 2100/7662 eta: 1 day, 7:22:52.385757	Training Loss 0.3740 (0.3751)	Training Prec@1 91.016 (92.440)	Training Prec@5 94.922 (96.082)	
2022-05-10 20:41:08,291: ============================================================
2022-05-10 20:41:54,823: time cost, forward:0.1709987549090071, backward:0.104323949419189, data cost:0.1899582305351351 
2022-05-10 20:41:54,824: ============================================================
2022-05-10 20:41:54,824: Epoch 7/38 Batch 2200/7662 eta: 1 day, 7:24:26.990560	Training Loss 0.3730 (0.3752)	Training Prec@1 92.383 (92.418)	Training Prec@5 97.070 (96.072)	
2022-05-10 20:41:54,824: ============================================================
2022-05-10 20:42:41,355: time cost, forward:0.17100284222988213, backward:0.10433059788206547, data cost:0.18993856005691456 
2022-05-10 20:42:41,356: ============================================================
2022-05-10 20:42:41,356: Epoch 7/38 Batch 2300/7662 eta: 1 day, 7:23:39.277891	Training Loss 0.3716 (0.3754)	Training Prec@1 93.164 (92.400)	Training Prec@5 96.680 (96.060)	
2022-05-10 20:42:41,356: ============================================================
2022-05-10 20:43:27,900: time cost, forward:0.17101053865614807, backward:0.10433599391347322, data cost:0.18992178784951214 
2022-05-10 20:43:27,900: ============================================================
2022-05-10 20:43:27,900: Epoch 7/38 Batch 2400/7662 eta: 1 day, 7:23:23.033341	Training Loss 0.3833 (0.3755)	Training Prec@1 92.188 (92.381)	Training Prec@5 96.484 (96.052)	
2022-05-10 20:43:27,900: ============================================================
2022-05-10 20:44:14,435: time cost, forward:0.1710121906390425, backward:0.10434252493569449, data cost:0.18990765537629847 
2022-05-10 20:44:14,436: ============================================================
2022-05-10 20:44:14,436: Epoch 7/38 Batch 2500/7662 eta: 1 day, 7:22:15.318812	Training Loss 0.3695 (0.3756)	Training Prec@1 92.773 (92.372)	Training Prec@5 96.289 (96.043)	
2022-05-10 20:44:14,436: ============================================================
2022-05-10 20:45:00,987: time cost, forward:0.17101499051853253, backward:0.10434776922976709, data cost:0.1898999025198807 
2022-05-10 20:45:00,987: ============================================================
2022-05-10 20:45:00,987: Epoch 7/38 Batch 2600/7662 eta: 1 day, 7:22:06.627383	Training Loss 0.3806 (0.3757)	Training Prec@1 91.797 (92.361)	Training Prec@5 96.289 (96.032)	
2022-05-10 20:45:00,987: ============================================================
2022-05-10 20:45:47,512: time cost, forward:0.17101495598987015, backward:0.10435168625646805, data cost:0.18988535632995288 
2022-05-10 20:45:47,512: ============================================================
2022-05-10 20:45:47,512: Epoch 7/38 Batch 2700/7662 eta: 1 day, 7:20:15.298366	Training Loss 0.3770 (0.3758)	Training Prec@1 92.969 (92.352)	Training Prec@5 95.898 (96.025)	
2022-05-10 20:45:47,512: ============================================================
2022-05-10 20:46:34,083: time cost, forward:0.17102406381836702, backward:0.1043577291318969, data cost:0.18987773750117098 
2022-05-10 20:46:34,083: ============================================================
2022-05-10 20:46:34,084: Epoch 7/38 Batch 2800/7662 eta: 1 day, 7:21:22.391106	Training Loss 0.3728 (0.3759)	Training Prec@1 92.578 (92.350)	Training Prec@5 95.312 (96.018)	
2022-05-10 20:46:34,084: ============================================================
2022-05-10 20:47:20,659: time cost, forward:0.17103654551234646, backward:0.10436167763035312, data cost:0.18986928870078407 
2022-05-10 20:47:20,659: ============================================================
2022-05-10 20:47:20,659: Epoch 7/38 Batch 2900/7662 eta: 1 day, 7:20:46.313793	Training Loss 0.3677 (0.3760)	Training Prec@1 90.820 (92.334)	Training Prec@5 94.922 (96.006)	
2022-05-10 20:47:20,660: ============================================================
2022-05-10 20:48:07,268: time cost, forward:0.1710587602808063, backward:0.10436766725573869, data cost:0.18986025839179466 
2022-05-10 20:48:07,268: ============================================================
2022-05-10 20:48:07,269: Epoch 7/38 Batch 3000/7662 eta: 1 day, 7:21:20.329346	Training Loss 0.3965 (0.3761)	Training Prec@1 91.406 (92.318)	Training Prec@5 95.117 (95.997)	
2022-05-10 20:48:07,269: ============================================================
2022-05-10 20:48:53,877: time cost, forward:0.17106705959784135, backward:0.10437441956962297, data cost:0.1898627975133974 
2022-05-10 20:48:53,878: ============================================================
2022-05-10 20:48:53,878: Epoch 7/38 Batch 3100/7662 eta: 1 day, 7:20:34.121927	Training Loss 0.3678 (0.3761)	Training Prec@1 92.773 (92.311)	Training Prec@5 95.508 (95.988)	
2022-05-10 20:48:53,878: ============================================================
2022-05-10 20:49:40,457: time cost, forward:0.17108057043857222, backward:0.10437703870467448, data cost:0.1898541835070625 
2022-05-10 20:49:40,457: ============================================================
2022-05-10 20:49:40,457: Epoch 7/38 Batch 3200/7662 eta: 1 day, 7:18:35.457210	Training Loss 0.3764 (0.3762)	Training Prec@1 92.773 (92.303)	Training Prec@5 96.289 (95.981)	
2022-05-10 20:49:40,458: ============================================================
2022-05-10 20:50:27,003: time cost, forward:0.17108501915354987, backward:0.10437730559077035, data cost:0.189846412309483 
2022-05-10 20:50:27,003: ============================================================
2022-05-10 20:50:27,003: Epoch 7/38 Batch 3300/7662 eta: 1 day, 7:16:27.057972	Training Loss 0.3887 (0.3763)	Training Prec@1 90.430 (92.293)	Training Prec@5 95.703 (95.975)	
2022-05-10 20:50:27,003: ============================================================
2022-05-10 20:51:13,534: time cost, forward:0.17109089039395436, backward:0.10437634861725294, data cost:0.1898339228898015 
2022-05-10 20:51:13,534: ============================================================
2022-05-10 20:51:13,534: Epoch 7/38 Batch 3400/7662 eta: 1 day, 7:15:05.146432	Training Loss 0.3877 (0.3763)	Training Prec@1 91.797 (92.284)	Training Prec@5 96.094 (95.969)	
2022-05-10 20:51:13,534: ============================================================
2022-05-10 20:52:00,035: time cost, forward:0.1710860145265765, backward:0.10437482327997906, data cost:0.18982477922649443 
2022-05-10 20:52:00,035: ============================================================
2022-05-10 20:52:00,035: Epoch 7/38 Batch 3500/7662 eta: 1 day, 7:13:06.564571	Training Loss 0.3932 (0.3764)	Training Prec@1 92.188 (92.273)	Training Prec@5 95.312 (95.962)	
2022-05-10 20:52:00,036: ============================================================
2022-05-10 20:52:46,527: time cost, forward:0.17108290577703267, backward:0.10437504302531224, data cost:0.18981067079012512 
2022-05-10 20:52:46,527: ============================================================
2022-05-10 20:52:46,527: Epoch 7/38 Batch 3600/7662 eta: 1 day, 7:11:57.763535	Training Loss 0.3840 (0.3765)	Training Prec@1 92.383 (92.269)	Training Prec@5 96.875 (95.959)	
2022-05-10 20:52:46,528: ============================================================
2022-05-10 20:53:33,027: time cost, forward:0.17107980487861643, backward:0.10437605335249002, data cost:0.18979871546973986 
2022-05-10 20:53:33,027: ============================================================
2022-05-10 20:53:33,028: Epoch 7/38 Batch 3700/7662 eta: 1 day, 7:11:31.144502	Training Loss 0.3833 (0.3765)	Training Prec@1 90.625 (92.264)	Training Prec@5 95.898 (95.957)	
2022-05-10 20:53:33,028: ============================================================
2022-05-10 20:54:19,538: time cost, forward:0.17108112455951946, backward:0.1043755768411691, data cost:0.18978734504677616 
2022-05-10 20:54:19,538: ============================================================
2022-05-10 20:54:19,539: Epoch 7/38 Batch 3800/7662 eta: 1 day, 7:11:10.213432	Training Loss 0.3764 (0.3766)	Training Prec@1 92.578 (92.256)	Training Prec@5 95.312 (95.952)	
2022-05-10 20:54:19,539: ============================================================
2022-05-10 20:55:06,149: time cost, forward:0.17108837186632844, backward:0.10439282730623037, data cost:0.18977825175067894 
2022-05-10 20:55:06,149: ============================================================
2022-05-10 20:55:06,149: Epoch 7/38 Batch 3900/7662 eta: 1 day, 7:14:24.838933	Training Loss 0.3784 (0.3766)	Training Prec@1 93.164 (92.250)	Training Prec@5 96.094 (95.947)	
2022-05-10 20:55:06,150: ============================================================
2022-05-10 20:55:52,710: time cost, forward:0.17110188980941982, backward:0.10439070191017298, data cost:0.18976930905413883 
2022-05-10 20:55:52,710: ============================================================
2022-05-10 20:55:52,711: Epoch 7/38 Batch 4000/7662 eta: 1 day, 7:11:38.854824	Training Loss 0.3797 (0.3767)	Training Prec@1 92.383 (92.245)	Training Prec@5 95.312 (95.941)	
2022-05-10 20:55:52,711: ============================================================
2022-05-10 20:56:39,252: time cost, forward:0.17110704311250796, backward:0.10438941443481221, data cost:0.18976285080119848 
2022-05-10 20:56:39,252: ============================================================
2022-05-10 20:56:39,252: Epoch 7/38 Batch 4100/7662 eta: 1 day, 7:10:05.372731	Training Loss 0.3749 (0.3767)	Training Prec@1 93.164 (92.237)	Training Prec@5 95.703 (95.938)	
2022-05-10 20:56:39,253: ============================================================
2022-05-10 20:57:25,763: time cost, forward:0.17110847694358816, backward:0.1043874887546831, data cost:0.1897536494329334 
2022-05-10 20:57:25,763: ============================================================
2022-05-10 20:57:25,763: Epoch 7/38 Batch 4200/7662 eta: 1 day, 7:08:04.420540	Training Loss 0.3726 (0.3767)	Training Prec@1 92.383 (92.224)	Training Prec@5 95.508 (95.929)	
2022-05-10 20:57:25,764: ============================================================
2022-05-10 20:58:12,298: time cost, forward:0.1711112050905869, backward:0.10438579031133907, data cost:0.18974916689283322 
2022-05-10 20:58:12,298: ============================================================
2022-05-10 20:58:12,298: Epoch 7/38 Batch 4300/7662 eta: 1 day, 7:08:15.914212	Training Loss 0.3831 (0.3768)	Training Prec@1 93.359 (92.220)	Training Prec@5 95.898 (95.926)	
2022-05-10 20:58:12,299: ============================================================
2022-05-10 20:58:58,809: time cost, forward:0.17111154642124615, backward:0.10438394698264193, data cost:0.18974249827425488 
2022-05-10 20:58:58,810: ============================================================
2022-05-10 20:58:58,810: Epoch 7/38 Batch 4400/7662 eta: 1 day, 7:06:32.337822	Training Loss 0.3773 (0.3768)	Training Prec@1 91.406 (92.216)	Training Prec@5 94.727 (95.921)	
2022-05-10 20:58:58,810: ============================================================
2022-05-10 20:59:45,344: time cost, forward:0.1711122807886209, backward:0.10438262692926513, data cost:0.18974062643413625 
2022-05-10 20:59:45,344: ============================================================
2022-05-10 20:59:45,344: Epoch 7/38 Batch 4500/7662 eta: 1 day, 7:06:41.618429	Training Loss 0.3822 (0.3769)	Training Prec@1 91.406 (92.205)	Training Prec@5 96.484 (95.917)	
2022-05-10 20:59:45,344: ============================================================
2022-05-10 21:00:31,848: time cost, forward:0.17111192290796925, backward:0.10438112031638454, data cost:0.18973335568659666 
2022-05-10 21:00:31,849: ============================================================
2022-05-10 21:00:31,849: Epoch 7/38 Batch 4600/7662 eta: 1 day, 7:04:42.735820	Training Loss 0.3647 (0.3769)	Training Prec@1 93.164 (92.199)	Training Prec@5 97.070 (95.913)	
2022-05-10 21:00:31,849: ============================================================
2022-05-10 21:01:18,343: time cost, forward:0.17110971578462855, backward:0.10437916618480304, data cost:0.18972696916020457 
2022-05-10 21:01:18,344: ============================================================
2022-05-10 21:01:18,344: Epoch 7/38 Batch 4700/7662 eta: 1 day, 7:03:33.544050	Training Loss 0.3740 (0.3770)	Training Prec@1 92.773 (92.195)	Training Prec@5 96.875 (95.911)	
2022-05-10 21:01:18,344: ============================================================
2022-05-10 21:02:04,864: time cost, forward:0.17110910279523783, backward:0.10438047162839138, data cost:0.18972126526940886 
2022-05-10 21:02:04,864: ============================================================
2022-05-10 21:02:04,864: Epoch 7/38 Batch 4800/7662 eta: 1 day, 7:03:48.012646	Training Loss 0.3649 (0.3770)	Training Prec@1 94.141 (92.187)	Training Prec@5 96.680 (95.907)	
2022-05-10 21:02:04,864: ============================================================
2022-05-10 21:02:51,338: time cost, forward:0.17110027106690587, backward:0.1043804092878321, data cost:0.189716143227519 
2022-05-10 21:02:51,338: ============================================================
2022-05-10 21:02:51,339: Epoch 7/38 Batch 4900/7662 eta: 1 day, 7:01:10.748618	Training Loss 0.3656 (0.3770)	Training Prec@1 94.141 (92.186)	Training Prec@5 96.680 (95.905)	
2022-05-10 21:02:51,339: ============================================================
2022-05-10 21:03:37,797: time cost, forward:0.1710872991153254, backward:0.10437976510364023, data cost:0.18971302896100156 
2022-05-10 21:03:37,797: ============================================================
2022-05-10 21:03:37,797: Epoch 7/38 Batch 5000/7662 eta: 1 day, 6:59:47.444049	Training Loss 0.3833 (0.3770)	Training Prec@1 90.625 (92.184)	Training Prec@5 96.484 (95.903)	
2022-05-10 21:03:37,798: ============================================================
2022-05-10 21:04:24,267: time cost, forward:0.17107521741851728, backward:0.10437913758307257, data cost:0.18971215699041186 
2022-05-10 21:04:24,268: ============================================================
2022-05-10 21:04:24,268: Epoch 7/38 Batch 5100/7662 eta: 1 day, 6:59:28.821829	Training Loss 0.3778 (0.3770)	Training Prec@1 91.406 (92.186)	Training Prec@5 96.289 (95.903)	
2022-05-10 21:04:24,268: ============================================================
2022-05-10 21:05:10,730: time cost, forward:0.1710657339688562, backward:0.10437859047098924, data cost:0.18970743961851513 
2022-05-10 21:05:10,730: ============================================================
2022-05-10 21:05:10,730: Epoch 7/38 Batch 5200/7662 eta: 1 day, 6:58:22.786538	Training Loss 0.3801 (0.3771)	Training Prec@1 91.406 (92.183)	Training Prec@5 96.484 (95.898)	
2022-05-10 21:05:10,731: ============================================================
2022-05-10 21:05:57,196: time cost, forward:0.17105475275623144, backward:0.10437887590951482, data cost:0.1897046051738082 
2022-05-10 21:05:57,196: ============================================================
2022-05-10 21:05:57,197: Epoch 7/38 Batch 5300/7662 eta: 1 day, 6:57:45.150170	Training Loss 0.3720 (0.3771)	Training Prec@1 92.578 (92.174)	Training Prec@5 96.680 (95.895)	
2022-05-10 21:05:57,197: ============================================================
2022-05-10 21:06:43,632: time cost, forward:0.1710438794572169, backward:0.1043780817104989, data cost:0.1896977893156704 
2022-05-10 21:06:43,632: ============================================================
2022-05-10 21:06:43,632: Epoch 7/38 Batch 5400/7662 eta: 1 day, 6:55:46.035761	Training Loss 0.3781 (0.3771)	Training Prec@1 92.578 (92.167)	Training Prec@5 94.922 (95.891)	
2022-05-10 21:06:43,632: ============================================================
2022-05-10 21:07:30,086: time cost, forward:0.1710354884682319, backward:0.1043767972000297, data cost:0.18969268915024123 
2022-05-10 21:07:30,086: ============================================================
2022-05-10 21:07:30,086: Epoch 7/38 Batch 5500/7662 eta: 1 day, 6:55:43.028737	Training Loss 0.3758 (0.3771)	Training Prec@1 90.625 (92.164)	Training Prec@5 94.727 (95.891)	
2022-05-10 21:07:30,086: ============================================================
2022-05-10 21:08:16,537: time cost, forward:0.17102563306675955, backward:0.1043762351215088, data cost:0.18968851235449835 
2022-05-10 21:08:16,537: ============================================================
2022-05-10 21:08:16,537: Epoch 7/38 Batch 5600/7662 eta: 1 day, 6:54:49.316407	Training Loss 0.3709 (0.3772)	Training Prec@1 93.555 (92.161)	Training Prec@5 96.289 (95.888)	
2022-05-10 21:08:16,537: ============================================================
2022-05-10 21:09:03,026: time cost, forward:0.17102087483236217, backward:0.10437573954021122, data cost:0.18968663129456775 
2022-05-10 21:09:03,027: ============================================================
2022-05-10 21:09:03,027: Epoch 7/38 Batch 5700/7662 eta: 1 day, 6:55:36.356697	Training Loss 0.3836 (0.3772)	Training Prec@1 91.602 (92.155)	Training Prec@5 96.289 (95.886)	
2022-05-10 21:09:03,027: ============================================================
2022-05-10 21:09:49,496: time cost, forward:0.17101628539027336, backward:0.10437453366658013, data cost:0.18968198002977893 
2022-05-10 21:09:49,496: ============================================================
2022-05-10 21:09:49,496: Epoch 7/38 Batch 5800/7662 eta: 1 day, 6:54:00.050465	Training Loss 0.3709 (0.3772)	Training Prec@1 93.945 (92.153)	Training Prec@5 97.266 (95.885)	
2022-05-10 21:09:49,496: ============================================================
2022-05-10 21:10:35,978: time cost, forward:0.17101289709052064, backward:0.10437300440052198, data cost:0.18967878994324952 
2022-05-10 21:10:35,978: ============================================================
2022-05-10 21:10:35,978: Epoch 7/38 Batch 5900/7662 eta: 1 day, 6:53:44.932048	Training Loss 0.3748 (0.3772)	Training Prec@1 91.992 (92.150)	Training Prec@5 96.484 (95.882)	
2022-05-10 21:10:35,978: ============================================================
2022-05-10 21:11:22,444: time cost, forward:0.17100923306585492, backward:0.10437203260397271, data cost:0.1896723982770754 
2022-05-10 21:11:22,444: ============================================================
2022-05-10 21:11:22,444: Epoch 7/38 Batch 6000/7662 eta: 1 day, 6:52:19.343027	Training Loss 0.3821 (0.3772)	Training Prec@1 90.234 (92.146)	Training Prec@5 95.703 (95.881)	
2022-05-10 21:11:22,444: ============================================================
2022-05-10 21:12:08,952: time cost, forward:0.17100511431439935, backward:0.1043721085435974, data cost:0.18967240977471023 
2022-05-10 21:12:08,952: ============================================================
2022-05-10 21:12:08,952: Epoch 7/38 Batch 6100/7662 eta: 1 day, 6:53:14.589242	Training Loss 0.3656 (0.3773)	Training Prec@1 92.188 (92.144)	Training Prec@5 96.289 (95.879)	
2022-05-10 21:12:08,953: ============================================================
2022-05-10 21:12:55,463: time cost, forward:0.17100342186559955, backward:0.1043720191131582, data cost:0.18967113546410536 
2022-05-10 21:12:55,463: ============================================================
2022-05-10 21:12:55,463: Epoch 7/38 Batch 6200/7662 eta: 1 day, 6:52:33.390673	Training Loss 0.3816 (0.3773)	Training Prec@1 91.602 (92.142)	Training Prec@5 95.898 (95.878)	
2022-05-10 21:12:55,463: ============================================================
2022-05-10 21:13:41,941: time cost, forward:0.17099825956269207, backward:0.10437148588955412, data cost:0.18966888200481613 
2022-05-10 21:13:41,942: ============================================================
2022-05-10 21:13:41,942: Epoch 7/38 Batch 6300/7662 eta: 1 day, 6:50:30.761345	Training Loss 0.3835 (0.3773)	Training Prec@1 90.430 (92.141)	Training Prec@5 95.508 (95.876)	
2022-05-10 21:13:41,942: ============================================================
2022-05-10 21:14:28,414: time cost, forward:0.17099462928092374, backward:0.10437079831424552, data cost:0.18966460529761978 
2022-05-10 21:14:28,415: ============================================================
2022-05-10 21:14:28,415: Epoch 7/38 Batch 6400/7662 eta: 1 day, 6:49:30.818466	Training Loss 0.3779 (0.3773)	Training Prec@1 92.383 (92.141)	Training Prec@5 94.141 (95.876)	
2022-05-10 21:14:28,415: ============================================================
2022-05-10 21:15:14,902: time cost, forward:0.1709881566968179, backward:0.1043699613844987, data cost:0.18966521243165688 
2022-05-10 21:15:14,903: ============================================================
2022-05-10 21:15:14,903: Epoch 7/38 Batch 6500/7662 eta: 1 day, 6:49:19.869511	Training Loss 0.3825 (0.3773)	Training Prec@1 91.211 (92.135)	Training Prec@5 95.312 (95.874)	
2022-05-10 21:15:14,903: ============================================================
2022-05-10 21:16:01,433: time cost, forward:0.1709858991825539, backward:0.1043691472187785, data cost:0.18966854303275876 
2022-05-10 21:16:01,434: ============================================================
2022-05-10 21:16:01,434: Epoch 7/38 Batch 6600/7662 eta: 1 day, 6:50:15.460509	Training Loss 0.3693 (0.3773)	Training Prec@1 94.922 (92.135)	Training Prec@5 96.289 (95.874)	
2022-05-10 21:16:01,434: ============================================================
2022-05-10 21:16:47,954: time cost, forward:0.17098456739507376, backward:0.10436929377322234, data cost:0.18966819998363468 
2022-05-10 21:16:47,954: ============================================================
2022-05-10 21:16:47,955: Epoch 7/38 Batch 6700/7662 eta: 1 day, 6:49:05.434917	Training Loss 0.3671 (0.3773)	Training Prec@1 92.578 (92.131)	Training Prec@5 96.484 (95.871)	
2022-05-10 21:16:47,955: ============================================================
2022-05-10 21:17:34,501: time cost, forward:0.17098463281215437, backward:0.10437028119451493, data cost:0.1896692969410152 
2022-05-10 21:17:34,501: ============================================================
2022-05-10 21:17:34,502: Epoch 7/38 Batch 6800/7662 eta: 1 day, 6:49:20.457647	Training Loss 0.3842 (0.3773)	Training Prec@1 92.773 (92.131)	Training Prec@5 97.266 (95.871)	
2022-05-10 21:17:34,502: ============================================================
2022-05-10 21:18:21,021: time cost, forward:0.17097930978011144, backward:0.10437040886061315, data cost:0.18967009250764175 
2022-05-10 21:18:21,021: ============================================================
2022-05-10 21:18:21,022: Epoch 7/38 Batch 6900/7662 eta: 1 day, 6:47:30.655763	Training Loss 0.3738 (0.3774)	Training Prec@1 90.820 (92.128)	Training Prec@5 94.336 (95.868)	
2022-05-10 21:18:21,022: ============================================================
2022-05-10 21:19:07,538: time cost, forward:0.17097485097821635, backward:0.10436981448890108, data cost:0.18967323552575993 
2022-05-10 21:19:07,538: ============================================================
2022-05-10 21:19:07,538: Epoch 7/38 Batch 7000/7662 eta: 1 day, 6:46:35.821273	Training Loss 0.3612 (0.3774)	Training Prec@1 92.773 (92.125)	Training Prec@5 96.289 (95.866)	
2022-05-10 21:19:07,538: ============================================================
2022-05-10 21:19:54,058: time cost, forward:0.1709752031439945, backward:0.1043687838704708, data cost:0.1896710785060957 
2022-05-10 21:19:54,058: ============================================================
2022-05-10 21:19:54,059: Epoch 7/38 Batch 7100/7662 eta: 1 day, 6:45:57.677238	Training Loss 0.3957 (0.3774)	Training Prec@1 90.234 (92.122)	Training Prec@5 94.727 (95.865)	
2022-05-10 21:19:54,059: ============================================================
2022-05-10 21:20:40,557: time cost, forward:0.17097323443230894, backward:0.10436787822541635, data cost:0.18966959741218567 
2022-05-10 21:20:40,557: ============================================================
2022-05-10 21:20:40,557: Epoch 7/38 Batch 7200/7662 eta: 1 day, 6:44:19.661450	Training Loss 0.3795 (0.3774)	Training Prec@1 92.578 (92.122)	Training Prec@5 95.703 (95.865)	
2022-05-10 21:20:40,557: ============================================================
2022-05-10 21:21:27,042: time cost, forward:0.17097023111905998, backward:0.10436693543129578, data cost:0.18966739046065706 
2022-05-10 21:21:27,042: ============================================================
2022-05-10 21:21:27,042: Epoch 7/38 Batch 7300/7662 eta: 1 day, 6:43:00.515315	Training Loss 0.3769 (0.3774)	Training Prec@1 91.797 (92.122)	Training Prec@5 95.117 (95.864)	
2022-05-10 21:21:27,042: ============================================================
2022-05-10 21:22:13,551: time cost, forward:0.17096857129439968, backward:0.10436534617362529, data cost:0.18966816515354776 
2022-05-10 21:22:13,552: ============================================================
2022-05-10 21:22:13,552: Epoch 7/38 Batch 7400/7662 eta: 1 day, 6:43:13.305718	Training Loss 0.3915 (0.3774)	Training Prec@1 91.602 (92.122)	Training Prec@5 95.898 (95.862)	
2022-05-10 21:22:13,552: ============================================================
2022-05-10 21:23:00,118: time cost, forward:0.17096927977034307, backward:0.10436384537042276, data cost:0.18967386401006422 
2022-05-10 21:23:00,119: ============================================================
2022-05-10 21:23:00,119: Epoch 7/38 Batch 7500/7662 eta: 1 day, 6:44:42.527233	Training Loss 0.3718 (0.3774)	Training Prec@1 91.016 (92.119)	Training Prec@5 95.703 (95.860)	
2022-05-10 21:23:00,119: ============================================================
2022-05-10 21:23:46,690: time cost, forward:0.17096929409610925, backward:0.10436228046700867, data cost:0.18968115243210198 
2022-05-10 21:23:46,690: ============================================================
2022-05-10 21:23:46,690: Epoch 7/38 Batch 7600/7662 eta: 1 day, 6:44:07.163522	Training Loss 0.3819 (0.3774)	Training Prec@1 92.188 (92.118)	Training Prec@5 95.312 (95.860)	
2022-05-10 21:23:46,690: ============================================================
2022-05-10 21:24:17,353: Epoch: 7/38 eta: 1 day, 6:43:37.823406	Training Loss 0.3742 (0.3774)	Training Prec@1 92.188 (92.117)	Training Prec@5 96.094 (95.859)
2022-05-10 21:24:17,353: ============================================================
2022-05-10 21:25:08,452: time cost, forward:0.18077699102536596, backward:0.10537449759666366, data cost:0.22778668788948445 
2022-05-10 21:25:08,452: ============================================================
2022-05-10 21:25:08,453: Epoch 8/38 Batch 100/7662 eta: 1 day, 9:41:52.363660	Training Loss 0.3544 (0.3598)	Training Prec@1 93.945 (93.450)	Training Prec@5 97.461 (96.713)	
2022-05-10 21:25:08,453: ============================================================
2022-05-10 21:25:55,074: time cost, forward:0.17577889936054172, backward:0.10554800800342656, data cost:0.20850591563699233 
2022-05-10 21:25:55,075: ============================================================
2022-05-10 21:25:55,075: Epoch 8/38 Batch 200/7662 eta: 1 day, 6:44:05.799546	Training Loss 0.3542 (0.3609)	Training Prec@1 94.531 (93.456)	Training Prec@5 97.656 (96.724)	
2022-05-10 21:25:55,075: ============================================================
2022-05-10 21:26:41,715: time cost, forward:0.174137373034372, backward:0.1056625587884399, data cost:0.20211103369161038 
2022-05-10 21:26:41,716: ============================================================
2022-05-10 21:26:41,716: Epoch 8/38 Batch 300/7662 eta: 1 day, 6:44:03.285837	Training Loss 0.3583 (0.3623)	Training Prec@1 93.945 (93.399)	Training Prec@5 97.266 (96.682)	
2022-05-10 21:26:41,716: ============================================================
2022-05-10 21:27:28,364: time cost, forward:0.17329432611776174, backward:0.10570564724150158, data cost:0.1989801886087671 
2022-05-10 21:27:28,364: ============================================================
2022-05-10 21:27:28,365: Epoch 8/38 Batch 400/7662 eta: 1 day, 6:43:34.839865	Training Loss 0.3675 (0.3640)	Training Prec@1 92.773 (93.301)	Training Prec@5 95.898 (96.642)	
2022-05-10 21:27:28,365: ============================================================
2022-05-10 21:28:14,991: time cost, forward:0.1727934361459736, backward:0.10573242279236207, data cost:0.19705472441617855 
2022-05-10 21:28:14,991: ============================================================
2022-05-10 21:28:14,992: Epoch 8/38 Batch 500/7662 eta: 1 day, 6:41:56.427357	Training Loss 0.3688 (0.3652)	Training Prec@1 91.406 (93.193)	Training Prec@5 95.508 (96.579)	
2022-05-10 21:28:14,992: ============================================================
2022-05-10 21:29:01,612: time cost, forward:0.17245373264179006, backward:0.10574121069231494, data cost:0.19577884196439052 
2022-05-10 21:29:01,612: ============================================================
2022-05-10 21:29:01,613: Epoch 8/38 Batch 600/7662 eta: 1 day, 6:40:56.076999	Training Loss 0.3553 (0.3662)	Training Prec@1 94.141 (93.124)	Training Prec@5 97.461 (96.537)	
2022-05-10 21:29:01,613: ============================================================
2022-05-10 21:29:48,108: time cost, forward:0.17219151140794223, backward:0.10560526902412994, data cost:0.1948500733518805 
2022-05-10 21:29:48,108: ============================================================
2022-05-10 21:29:48,108: Epoch 8/38 Batch 700/7662 eta: 1 day, 6:35:12.472373	Training Loss 0.3820 (0.3671)	Training Prec@1 92.578 (93.098)	Training Prec@5 95.898 (96.507)	
2022-05-10 21:29:48,108: ============================================================
2022-05-10 21:30:34,561: time cost, forward:0.17199472282944395, backward:0.10544319803335789, data cost:0.1941619346079152 
2022-05-10 21:30:34,561: ============================================================
2022-05-10 21:30:34,561: Epoch 8/38 Batch 800/7662 eta: 1 day, 6:32:44.466343	Training Loss 0.3714 (0.3679)	Training Prec@1 91.992 (93.034)	Training Prec@5 94.727 (96.458)	
2022-05-10 21:30:34,561: ============================================================
2022-05-10 21:31:21,030: time cost, forward:0.17185188957528358, backward:0.10531698397720218, data cost:0.1936354836049149 
2022-05-10 21:31:21,030: ============================================================
2022-05-10 21:31:21,030: Epoch 8/38 Batch 900/7662 eta: 1 day, 6:32:36.831794	Training Loss 0.3847 (0.3687)	Training Prec@1 91.406 (92.971)	Training Prec@5 95.703 (96.421)	
2022-05-10 21:31:21,030: ============================================================
2022-05-10 21:32:07,503: time cost, forward:0.17175054669499518, backward:0.10520859547444172, data cost:0.19321149152081768 
2022-05-10 21:32:07,503: ============================================================
2022-05-10 21:32:07,503: Epoch 8/38 Batch 1000/7662 eta: 1 day, 6:31:59.049130	Training Loss 0.3837 (0.3694)	Training Prec@1 92.773 (92.923)	Training Prec@5 96.680 (96.390)	
2022-05-10 21:32:07,503: ============================================================
2022-05-10 21:32:53,979: time cost, forward:0.1716699155489893, backward:0.105125184488687, data cost:0.19285992213657924 
2022-05-10 21:32:53,979: ============================================================
2022-05-10 21:32:53,980: Epoch 8/38 Batch 1100/7662 eta: 1 day, 6:31:20.888222	Training Loss 0.3811 (0.3700)	Training Prec@1 92.188 (92.871)	Training Prec@5 95.703 (96.354)	
2022-05-10 21:32:53,980: ============================================================
2022-05-10 21:33:40,457: time cost, forward:0.1715979647696068, backward:0.10505740716121315, data cost:0.19257183249937285 
2022-05-10 21:33:40,457: ============================================================
2022-05-10 21:33:40,458: Epoch 8/38 Batch 1200/7662 eta: 1 day, 6:30:38.078681	Training Loss 0.3652 (0.3704)	Training Prec@1 94.336 (92.819)	Training Prec@5 97.266 (96.320)	
2022-05-10 21:33:40,458: ============================================================
2022-05-10 21:34:26,935: time cost, forward:0.1715431266605533, backward:0.10499482507243167, data cost:0.19232612302250088 
2022-05-10 21:34:26,935: ============================================================
2022-05-10 21:34:26,935: Epoch 8/38 Batch 1300/7662 eta: 1 day, 6:29:50.736223	Training Loss 0.3764 (0.3708)	Training Prec@1 91.797 (92.773)	Training Prec@5 95.508 (96.291)	
2022-05-10 21:34:26,935: ============================================================
2022-05-10 21:35:13,419: time cost, forward:0.17149606016893912, backward:0.10494325022939446, data cost:0.19211945949578985 
2022-05-10 21:35:13,419: ============================================================
2022-05-10 21:35:13,419: Epoch 8/38 Batch 1400/7662 eta: 1 day, 6:29:19.222711	Training Loss 0.3791 (0.3711)	Training Prec@1 91.211 (92.732)	Training Prec@5 95.508 (96.268)	
2022-05-10 21:35:13,419: ============================================================
2022-05-10 21:35:59,905: time cost, forward:0.17146369852647533, backward:0.10490107838514251, data cost:0.19193095680552374 
2022-05-10 21:35:59,906: ============================================================
2022-05-10 21:35:59,906: Epoch 8/38 Batch 1500/7662 eta: 1 day, 6:28:39.277630	Training Loss 0.3728 (0.3715)	Training Prec@1 92.188 (92.697)	Training Prec@5 95.898 (96.247)	
2022-05-10 21:35:59,906: ============================================================
2022-05-10 21:36:46,415: time cost, forward:0.17144714779522807, backward:0.104861563783351, data cost:0.19177128569344717 
2022-05-10 21:36:46,416: ============================================================
2022-05-10 21:36:46,416: Epoch 8/38 Batch 1600/7662 eta: 1 day, 6:28:48.003834	Training Loss 0.3955 (0.3718)	Training Prec@1 91.992 (92.665)	Training Prec@5 95.703 (96.219)	
2022-05-10 21:36:46,416: ============================================================
2022-05-10 21:37:32,890: time cost, forward:0.17141500608299395, backward:0.10482600115550975, data cost:0.19162730275356749 
2022-05-10 21:37:32,890: ============================================================
2022-05-10 21:37:32,890: Epoch 8/38 Batch 1700/7662 eta: 1 day, 6:26:37.070842	Training Loss 0.3917 (0.3720)	Training Prec@1 90.234 (92.640)	Training Prec@5 94.141 (96.203)	
2022-05-10 21:37:32,890: ============================================================
2022-05-10 21:38:19,403: time cost, forward:0.17138374521044508, backward:0.10478967729709492, data cost:0.19152957615155256 
2022-05-10 21:38:19,404: ============================================================
2022-05-10 21:38:19,404: Epoch 8/38 Batch 1800/7662 eta: 1 day, 6:27:23.309228	Training Loss 0.3758 (0.3723)	Training Prec@1 91.602 (92.606)	Training Prec@5 96.289 (96.184)	
2022-05-10 21:38:19,404: ============================================================
2022-05-10 21:39:05,895: time cost, forward:0.17134233962365863, backward:0.10476008862680733, data cost:0.1914408029914844 
2022-05-10 21:39:05,895: ============================================================
2022-05-10 21:39:05,895: Epoch 8/38 Batch 1900/7662 eta: 1 day, 6:25:45.084206	Training Loss 0.3817 (0.3724)	Training Prec@1 91.211 (92.576)	Training Prec@5 94.727 (96.165)	
2022-05-10 21:39:05,895: ============================================================
2022-05-10 21:39:52,422: time cost, forward:0.17130729900472697, backward:0.10473269364307856, data cost:0.19137062210628783 
2022-05-10 21:39:52,422: ============================================================
2022-05-10 21:39:52,422: Epoch 8/38 Batch 2000/7662 eta: 1 day, 6:26:21.359330	Training Loss 0.3598 (0.3726)	Training Prec@1 93.359 (92.557)	Training Prec@5 97.266 (96.158)	
2022-05-10 21:39:52,422: ============================================================
2022-05-10 21:40:38,993: time cost, forward:0.17129301570494326, backward:0.10470820393319241, data cost:0.1913043095305626 
2022-05-10 21:40:38,993: ============================================================
2022-05-10 21:40:38,993: Epoch 8/38 Batch 2100/7662 eta: 1 day, 6:27:18.506543	Training Loss 0.3619 (0.3727)	Training Prec@1 93.945 (92.546)	Training Prec@5 96.484 (96.152)	
2022-05-10 21:40:38,993: ============================================================
2022-05-10 21:41:25,501: time cost, forward:0.1712621661303747, backward:0.10468410480667538, data cost:0.1912469904007506 
2022-05-10 21:41:25,502: ============================================================
2022-05-10 21:41:25,502: Epoch 8/38 Batch 2200/7662 eta: 1 day, 6:24:05.487753	Training Loss 0.3724 (0.3729)	Training Prec@1 92.773 (92.527)	Training Prec@5 97.070 (96.143)	
2022-05-10 21:41:25,502: ============================================================
2022-05-10 21:42:12,034: time cost, forward:0.17123098329856842, backward:0.10466268571784777, data cost:0.1911975255786154 
2022-05-10 21:42:12,034: ============================================================
2022-05-10 21:42:12,035: Epoch 8/38 Batch 2300/7662 eta: 1 day, 6:24:15.905251	Training Loss 0.3886 (0.3731)	Training Prec@1 92.188 (92.504)	Training Prec@5 95.312 (96.131)	
2022-05-10 21:42:12,035: ============================================================
2022-05-10 21:42:58,553: time cost, forward:0.17121034873033772, backward:0.10464261680307264, data cost:0.19114769165989953 
2022-05-10 21:42:58,553: ============================================================
2022-05-10 21:42:58,553: Epoch 8/38 Batch 2400/7662 eta: 1 day, 6:22:55.692405	Training Loss 0.3680 (0.3732)	Training Prec@1 94.531 (92.488)	Training Prec@5 97.656 (96.122)	
2022-05-10 21:42:58,553: ============================================================
2022-05-10 21:43:45,091: time cost, forward:0.17118988699224197, backward:0.10462550288822804, data cost:0.19110939473140331 
2022-05-10 21:43:45,091: ============================================================
2022-05-10 21:43:45,091: Epoch 8/38 Batch 2500/7662 eta: 1 day, 6:22:54.943474	Training Loss 0.3835 (0.3733)	Training Prec@1 92.383 (92.478)	Training Prec@5 96.289 (96.114)	
2022-05-10 21:43:45,091: ============================================================
2022-05-10 21:44:31,588: time cost, forward:0.17116868188629797, backward:0.10460948934918324, data cost:0.1910562683133356 
2022-05-10 21:44:31,588: ============================================================
2022-05-10 21:44:31,588: Epoch 8/38 Batch 2600/7662 eta: 1 day, 6:20:31.928262	Training Loss 0.3797 (0.3734)	Training Prec@1 91.602 (92.463)	Training Prec@5 95.312 (96.103)	
2022-05-10 21:44:31,588: ============================================================
2022-05-10 21:45:18,099: time cost, forward:0.17115491900279725, backward:0.10459399841678897, data cost:0.19101137123800463 
2022-05-10 21:45:18,099: ============================================================
2022-05-10 21:45:18,099: Epoch 8/38 Batch 2700/7662 eta: 1 day, 6:20:19.316422	Training Loss 0.3847 (0.3735)	Training Prec@1 93.164 (92.451)	Training Prec@5 96.680 (96.100)	
2022-05-10 21:45:18,099: ============================================================
2022-05-10 21:46:04,621: time cost, forward:0.17114564937197682, backward:0.10457965108742667, data cost:0.1909700115479159 
2022-05-10 21:46:04,621: ============================================================
2022-05-10 21:46:04,621: Epoch 8/38 Batch 2800/7662 eta: 1 day, 6:19:56.957305	Training Loss 0.3862 (0.3736)	Training Prec@1 93.164 (92.441)	Training Prec@5 96.094 (96.094)	
2022-05-10 21:46:04,621: ============================================================
2022-05-10 21:46:51,120: time cost, forward:0.17113559917977614, backward:0.10456595144505416, data cost:0.19092537962843442 
2022-05-10 21:46:51,120: ============================================================
2022-05-10 21:46:51,120: Epoch 8/38 Batch 2900/7662 eta: 1 day, 6:18:17.668908	Training Loss 0.3815 (0.3738)	Training Prec@1 90.430 (92.424)	Training Prec@5 95.703 (96.084)	
2022-05-10 21:46:51,120: ============================================================
2022-05-10 21:47:37,621: time cost, forward:0.17112118627835052, backward:0.10455329873713703, data cost:0.19088640535780094 
2022-05-10 21:47:37,621: ============================================================
2022-05-10 21:47:37,622: Epoch 8/38 Batch 3000/7662 eta: 1 day, 6:17:36.576717	Training Loss 0.3795 (0.3738)	Training Prec@1 91.797 (92.416)	Training Prec@5 95.117 (96.075)	
2022-05-10 21:47:37,622: ============================================================
2022-05-10 21:48:24,113: time cost, forward:0.1711073084853087, backward:0.10454172755718692, data cost:0.19085054483749128 
2022-05-10 21:48:24,113: ============================================================
2022-05-10 21:48:24,114: Epoch 8/38 Batch 3100/7662 eta: 1 day, 6:16:28.248801	Training Loss 0.3809 (0.3739)	Training Prec@1 91.602 (92.404)	Training Prec@5 94.531 (96.066)	
2022-05-10 21:48:24,114: ============================================================
2022-05-10 21:49:10,616: time cost, forward:0.17110146504336873, backward:0.10453204834375504, data cost:0.1908118463971161 
2022-05-10 21:49:10,617: ============================================================
2022-05-10 21:49:10,617: Epoch 8/38 Batch 3200/7662 eta: 1 day, 6:16:07.597372	Training Loss 0.3809 (0.3740)	Training Prec@1 91.602 (92.394)	Training Prec@5 96.680 (96.059)	
2022-05-10 21:49:10,617: ============================================================
2022-05-10 21:49:57,138: time cost, forward:0.1711065806775933, backward:0.10452367963845818, data cost:0.19076996118453604 
2022-05-10 21:49:57,138: ============================================================
2022-05-10 21:49:57,138: Epoch 8/38 Batch 3300/7662 eta: 1 day, 6:16:03.665653	Training Loss 0.3731 (0.3741)	Training Prec@1 92.578 (92.383)	Training Prec@5 97.070 (96.051)	
2022-05-10 21:49:57,138: ============================================================
2022-05-10 21:50:43,683: time cost, forward:0.17111422904065932, backward:0.10451764918734446, data cost:0.19073307650970972 
2022-05-10 21:50:43,683: ============================================================
2022-05-10 21:50:43,683: Epoch 8/38 Batch 3400/7662 eta: 1 day, 6:16:12.771015	Training Loss 0.3695 (0.3742)	Training Prec@1 92.773 (92.369)	Training Prec@5 96.289 (96.039)	
2022-05-10 21:50:43,683: ============================================================
2022-05-10 21:51:30,206: time cost, forward:0.17111353255503858, backward:0.10450942320767795, data cost:0.19070218085697563 
2022-05-10 21:51:30,206: ============================================================
2022-05-10 21:51:30,206: Epoch 8/38 Batch 3500/7662 eta: 1 day, 6:14:34.148139	Training Loss 0.3694 (0.3742)	Training Prec@1 91.016 (92.355)	Training Prec@5 96.289 (96.030)	
2022-05-10 21:51:30,206: ============================================================
2022-05-10 21:52:16,725: time cost, forward:0.17111690212004912, backward:0.10450231694419969, data cost:0.19066763573403026 
2022-05-10 21:52:16,725: ============================================================
2022-05-10 21:52:16,725: Epoch 8/38 Batch 3600/7662 eta: 1 day, 6:13:38.636033	Training Loss 0.3666 (0.3743)	Training Prec@1 92.969 (92.348)	Training Prec@5 96.289 (96.027)	
2022-05-10 21:52:16,725: ============================================================
2022-05-10 21:53:03,252: time cost, forward:0.17111786554619635, backward:0.10449509196553433, data cost:0.1906397396823979 
2022-05-10 21:53:03,252: ============================================================
2022-05-10 21:53:03,252: Epoch 8/38 Batch 3700/7662 eta: 1 day, 6:13:11.503872	Training Loss 0.3673 (0.3744)	Training Prec@1 92.773 (92.339)	Training Prec@5 96.094 (96.021)	
2022-05-10 21:53:03,253: ============================================================
2022-05-10 21:53:49,819: time cost, forward:0.17112306790403328, backward:0.1044887683052049, data cost:0.19061950697149532 
2022-05-10 21:53:49,820: ============================================================
2022-05-10 21:53:49,820: Epoch 8/38 Batch 3800/7662 eta: 1 day, 6:13:58.980025	Training Loss 0.3760 (0.3744)	Training Prec@1 92.969 (92.334)	Training Prec@5 96.094 (96.017)	
2022-05-10 21:53:49,820: ============================================================
2022-05-10 21:54:36,442: time cost, forward:0.17114345518006027, backward:0.1044833296291276, data cost:0.190598897977987 
2022-05-10 21:54:36,443: ============================================================
2022-05-10 21:54:36,443: Epoch 8/38 Batch 3900/7662 eta: 1 day, 6:15:21.599901	Training Loss 0.3752 (0.3745)	Training Prec@1 93.555 (92.326)	Training Prec@5 96.875 (96.014)	
2022-05-10 21:54:36,443: ============================================================
2022-05-10 21:55:23,060: time cost, forward:0.17116677197673136, backward:0.10447862500636451, data cost:0.19057277895027652 
2022-05-10 21:55:23,060: ============================================================
2022-05-10 21:55:23,060: Epoch 8/38 Batch 4000/7662 eta: 1 day, 6:14:22.123682	Training Loss 0.3799 (0.3745)	Training Prec@1 91.406 (92.319)	Training Prec@5 95.117 (96.010)	
2022-05-10 21:55:23,060: ============================================================
2022-05-10 21:56:09,635: time cost, forward:0.17117580322848205, backward:0.10447459536140853, data cost:0.19055030793206057 
2022-05-10 21:56:09,636: ============================================================
2022-05-10 21:56:09,636: Epoch 8/38 Batch 4100/7662 eta: 1 day, 6:11:58.847099	Training Loss 0.3843 (0.3746)	Training Prec@1 91.211 (92.313)	Training Prec@5 94.531 (96.006)	
2022-05-10 21:56:09,636: ============================================================
2022-05-10 21:56:56,150: time cost, forward:0.17116949938115236, backward:0.10447079864505587, data cost:0.1905292656115618 
2022-05-10 21:56:56,150: ============================================================
2022-05-10 21:56:56,150: Epoch 8/38 Batch 4200/7662 eta: 1 day, 6:08:48.554878	Training Loss 0.3644 (0.3746)	Training Prec@1 92.578 (92.312)	Training Prec@5 96.289 (96.005)	
2022-05-10 21:56:56,150: ============================================================
2022-05-10 21:57:42,660: time cost, forward:0.17116470579824827, backward:0.10446786270443299, data cost:0.19050670967847422 
2022-05-10 21:57:42,660: ============================================================
2022-05-10 21:57:42,660: Epoch 8/38 Batch 4300/7662 eta: 1 day, 6:07:52.260826	Training Loss 0.3783 (0.3746)	Training Prec@1 92.969 (92.304)	Training Prec@5 96.289 (96.002)	
2022-05-10 21:57:42,660: ============================================================
2022-05-10 21:58:29,184: time cost, forward:0.17116224665510624, backward:0.10446206215539557, data cost:0.1904871013929259 
2022-05-10 21:58:29,184: ============================================================
2022-05-10 21:58:29,184: Epoch 8/38 Batch 4400/7662 eta: 1 day, 6:07:38.609567	Training Loss 0.3774 (0.3747)	Training Prec@1 92.578 (92.295)	Training Prec@5 96.289 (95.995)	
2022-05-10 21:58:29,185: ============================================================
2022-05-10 21:59:15,727: time cost, forward:0.17116080042679432, backward:0.10445836693161088, data cost:0.19047141843542678 
2022-05-10 21:59:15,728: ============================================================
2022-05-10 21:59:15,728: Epoch 8/38 Batch 4500/7662 eta: 1 day, 6:07:36.322083	Training Loss 0.3678 (0.3748)	Training Prec@1 91.406 (92.285)	Training Prec@5 94.922 (95.989)	
2022-05-10 21:59:15,728: ============================================================
2022-05-10 22:00:02,268: time cost, forward:0.17116010767087958, backward:0.10445521432022656, data cost:0.1904547319227676 
2022-05-10 22:00:02,268: ============================================================
2022-05-10 22:00:02,268: Epoch 8/38 Batch 4600/7662 eta: 1 day, 6:06:43.772432	Training Loss 0.3940 (0.3748)	Training Prec@1 90.820 (92.278)	Training Prec@5 95.703 (95.986)	
2022-05-10 22:00:02,268: ============================================================
2022-05-10 22:00:48,830: time cost, forward:0.17115850244641026, backward:0.10445256983125227, data cost:0.19044420495391476 
2022-05-10 22:00:48,830: ============================================================
2022-05-10 22:00:48,831: Epoch 8/38 Batch 4700/7662 eta: 1 day, 6:06:47.657612	Training Loss 0.3668 (0.3748)	Training Prec@1 93.945 (92.278)	Training Prec@5 96.289 (95.987)	
2022-05-10 22:00:48,831: ============================================================
2022-05-10 22:01:35,383: time cost, forward:0.17115655251407802, backward:0.10444905182102567, data cost:0.19043346046532011 
2022-05-10 22:01:35,383: ============================================================
2022-05-10 22:01:35,383: Epoch 8/38 Batch 4800/7662 eta: 1 day, 6:05:39.011571	Training Loss 0.3715 (0.3749)	Training Prec@1 92.578 (92.271)	Training Prec@5 96.875 (95.981)	
2022-05-10 22:01:35,383: ============================================================
2022-05-10 22:02:21,940: time cost, forward:0.1711553384099938, backward:0.10444610190406141, data cost:0.19042064000402428 
2022-05-10 22:02:21,940: ============================================================
2022-05-10 22:02:21,940: Epoch 8/38 Batch 4900/7662 eta: 1 day, 6:05:02.197307	Training Loss 0.3889 (0.3749)	Training Prec@1 93.359 (92.267)	Training Prec@5 96.484 (95.978)	
2022-05-10 22:02:21,940: ============================================================
2022-05-10 22:03:08,544: time cost, forward:0.1711563375812217, backward:0.10444389707828956, data cost:0.19041728854155535 
2022-05-10 22:03:08,544: ============================================================
2022-05-10 22:03:08,544: Epoch 8/38 Batch 5000/7662 eta: 1 day, 6:06:04.996958	Training Loss 0.3805 (0.3749)	Training Prec@1 92.383 (92.263)	Training Prec@5 96.094 (95.975)	
2022-05-10 22:03:08,544: ============================================================
2022-05-10 22:03:55,121: time cost, forward:0.17115604603938156, backward:0.10444086882431709, data cost:0.19041104133420422 
2022-05-10 22:03:55,121: ============================================================
2022-05-10 22:03:55,121: Epoch 8/38 Batch 5100/7662 eta: 1 day, 6:04:16.047828	Training Loss 0.3796 (0.3750)	Training Prec@1 91.211 (92.262)	Training Prec@5 96.094 (95.974)	
2022-05-10 22:03:55,122: ============================================================
2022-05-10 22:04:41,653: time cost, forward:0.17115234553664893, backward:0.10443697752551773, data cost:0.19040046625124488 
2022-05-10 22:04:41,653: ============================================================
2022-05-10 22:04:41,653: Epoch 8/38 Batch 5200/7662 eta: 1 day, 6:01:44.613841	Training Loss 0.3697 (0.3750)	Training Prec@1 91.992 (92.255)	Training Prec@5 96.094 (95.969)	
2022-05-10 22:04:41,654: ============================================================
2022-05-10 22:05:28,182: time cost, forward:0.17114923742272356, backward:0.10443364356818975, data cost:0.19038889191694633 
2022-05-10 22:05:28,182: ============================================================
2022-05-10 22:05:28,182: Epoch 8/38 Batch 5300/7662 eta: 1 day, 6:00:50.397523	Training Loss 0.3753 (0.3751)	Training Prec@1 91.211 (92.250)	Training Prec@5 95.312 (95.964)	
2022-05-10 22:05:28,182: ============================================================
2022-05-10 22:06:14,790: time cost, forward:0.17115057351567564, backward:0.10443143894063431, data cost:0.19038663866078773 
2022-05-10 22:06:14,790: ============================================================
2022-05-10 22:06:14,790: Epoch 8/38 Batch 5400/7662 eta: 1 day, 6:03:08.100448	Training Loss 0.3769 (0.3751)	Training Prec@1 92.969 (92.246)	Training Prec@5 95.508 (95.961)	
2022-05-10 22:06:14,791: ============================================================
2022-05-10 22:07:01,694: time cost, forward:0.17120035233595607, backward:0.10443747245218346, data cost:0.19038181639645485 
2022-05-10 22:07:01,695: ============================================================
2022-05-10 22:07:01,695: Epoch 8/38 Batch 5500/7662 eta: 1 day, 6:13:49.163883	Training Loss 0.3817 (0.3751)	Training Prec@1 91.016 (92.244)	Training Prec@5 95.703 (95.959)	
2022-05-10 22:07:01,695: ============================================================
2022-05-10 22:07:48,234: time cost, forward:0.17119820655765522, backward:0.1044344288426907, data cost:0.19037097452963903 
2022-05-10 22:07:48,234: ============================================================
2022-05-10 22:07:48,234: Epoch 8/38 Batch 5600/7662 eta: 1 day, 5:58:55.399270	Training Loss 0.3891 (0.3751)	Training Prec@1 91.211 (92.241)	Training Prec@5 95.312 (95.957)	
2022-05-10 22:07:48,234: ============================================================
2022-05-10 22:08:34,814: time cost, forward:0.1712000012753365, backward:0.10443159964528496, data cost:0.19036365124317067 
2022-05-10 22:08:34,814: ============================================================
2022-05-10 22:08:34,814: Epoch 8/38 Batch 5700/7662 eta: 1 day, 5:59:42.990727	Training Loss 0.3593 (0.3751)	Training Prec@1 93.555 (92.235)	Training Prec@5 97.070 (95.951)	
2022-05-10 22:08:34,814: ============================================================
2022-05-10 22:09:21,360: time cost, forward:0.1711985014454828, backward:0.10442841449756625, data cost:0.19035480371486074 
2022-05-10 22:09:21,360: ============================================================
2022-05-10 22:09:21,361: Epoch 8/38 Batch 5800/7662 eta: 1 day, 5:57:39.008549	Training Loss 0.3954 (0.3751)	Training Prec@1 91.406 (92.231)	Training Prec@5 95.117 (95.949)	
2022-05-10 22:09:21,361: ============================================================
2022-05-10 22:10:07,892: time cost, forward:0.17119514059062568, backward:0.10442517890548642, data cost:0.19034374800955448 
2022-05-10 22:10:07,892: ============================================================
2022-05-10 22:10:07,893: Epoch 8/38 Batch 5900/7662 eta: 1 day, 5:56:18.969687	Training Loss 0.3921 (0.3751)	Training Prec@1 90.430 (92.229)	Training Prec@5 95.508 (95.947)	
2022-05-10 22:10:07,893: ============================================================
2022-05-10 22:10:54,432: time cost, forward:0.17119088397858281, backward:0.10442282720732081, data cost:0.1903346132926095 
2022-05-10 22:10:54,432: ============================================================
2022-05-10 22:10:54,432: Epoch 8/38 Batch 6000/7662 eta: 1 day, 5:55:49.967289	Training Loss 0.3681 (0.3752)	Training Prec@1 91.602 (92.224)	Training Prec@5 96.875 (95.945)	
2022-05-10 22:10:54,432: ============================================================
2022-05-10 22:11:40,963: time cost, forward:0.1711896782840817, backward:0.10441993103396367, data cost:0.19032369505911503 
2022-05-10 22:11:40,963: ============================================================
2022-05-10 22:11:40,963: Epoch 8/38 Batch 6100/7662 eta: 1 day, 5:54:43.404446	Training Loss 0.3675 (0.3752)	Training Prec@1 93.164 (92.219)	Training Prec@5 97.266 (95.943)	
2022-05-10 22:11:40,963: ============================================================
2022-05-10 22:12:27,527: time cost, forward:0.17118701482515294, backward:0.10441830104773113, data cost:0.19031730869697513 
2022-05-10 22:12:27,527: ============================================================
2022-05-10 22:12:27,527: Epoch 8/38 Batch 6200/7662 eta: 1 day, 5:55:13.083735	Training Loss 0.3799 (0.3752)	Training Prec@1 91.797 (92.214)	Training Prec@5 95.312 (95.942)	
2022-05-10 22:12:27,527: ============================================================
2022-05-10 22:13:14,070: time cost, forward:0.17118607019314522, backward:0.10441650252698774, data cost:0.19030815564482756 
2022-05-10 22:13:14,070: ============================================================
2022-05-10 22:13:14,071: Epoch 8/38 Batch 6300/7662 eta: 1 day, 5:53:38.991319	Training Loss 0.3807 (0.3752)	Training Prec@1 91.211 (92.211)	Training Prec@5 95.312 (95.940)	
2022-05-10 22:13:14,071: ============================================================
2022-05-10 22:14:00,632: time cost, forward:0.1711836355629331, backward:0.10441486804554995, data cost:0.19030181566874185 
2022-05-10 22:14:00,632: ============================================================
2022-05-10 22:14:00,632: Epoch 8/38 Batch 6400/7662 eta: 1 day, 5:53:34.474675	Training Loss 0.3836 (0.3752)	Training Prec@1 91.406 (92.208)	Training Prec@5 95.508 (95.937)	
2022-05-10 22:14:00,632: ============================================================
2022-05-10 22:14:47,175: time cost, forward:0.17118027496748767, backward:0.10441265305769885, data cost:0.19029593530077626 
2022-05-10 22:14:47,175: ============================================================
2022-05-10 22:14:47,175: Epoch 8/38 Batch 6500/7662 eta: 1 day, 5:52:05.488711	Training Loss 0.3750 (0.3753)	Training Prec@1 93.945 (92.202)	Training Prec@5 96.094 (95.934)	
2022-05-10 22:14:47,175: ============================================================
2022-05-10 22:15:33,695: time cost, forward:0.17117471126990527, backward:0.10441047250366442, data cost:0.19028931690862927 
2022-05-10 22:15:33,695: ============================================================
2022-05-10 22:15:33,695: Epoch 8/38 Batch 6600/7662 eta: 1 day, 5:50:25.387264	Training Loss 0.3672 (0.3753)	Training Prec@1 91.992 (92.199)	Training Prec@5 95.703 (95.932)	
2022-05-10 22:15:33,695: ============================================================
2022-05-10 22:16:20,249: time cost, forward:0.17117307577262728, backward:0.10440828971390155, data cost:0.1902832830107057 
2022-05-10 22:16:20,249: ============================================================
2022-05-10 22:16:20,250: Epoch 8/38 Batch 6700/7662 eta: 1 day, 5:50:57.652326	Training Loss 0.3813 (0.3753)	Training Prec@1 93.750 (92.197)	Training Prec@5 95.703 (95.931)	
2022-05-10 22:16:20,250: ============================================================
2022-05-10 22:17:06,822: time cost, forward:0.17117121581172817, backward:0.10440712242306006, data cost:0.19028089270554566 
2022-05-10 22:17:06,823: ============================================================
2022-05-10 22:17:06,823: Epoch 8/38 Batch 6800/7662 eta: 1 day, 5:50:55.283888	Training Loss 0.3857 (0.3753)	Training Prec@1 92.578 (92.195)	Training Prec@5 96.289 (95.929)	
2022-05-10 22:17:06,823: ============================================================
2022-05-10 22:17:53,344: time cost, forward:0.17116886219229796, backward:0.10440556936323478, data cost:0.19027137072090827 
2022-05-10 22:17:53,344: ============================================================
2022-05-10 22:17:53,344: Epoch 8/38 Batch 6900/7662 eta: 1 day, 5:48:09.441405	Training Loss 0.3674 (0.3753)	Training Prec@1 92.578 (92.192)	Training Prec@5 95.898 (95.928)	
2022-05-10 22:17:53,344: ============================================================
2022-05-10 22:18:39,876: time cost, forward:0.17116804823975576, backward:0.10440417146117266, data cost:0.19026234794095645 
2022-05-10 22:18:39,877: ============================================================
2022-05-10 22:18:39,877: Epoch 8/38 Batch 7000/7662 eta: 1 day, 5:47:47.673704	Training Loss 0.3768 (0.3753)	Training Prec@1 91.602 (92.189)	Training Prec@5 96.094 (95.926)	
2022-05-10 22:18:39,877: ============================================================
2022-05-10 22:19:26,393: time cost, forward:0.17116345726515075, backward:0.10440253818483483, data cost:0.19025394298238038 
2022-05-10 22:19:26,393: ============================================================
2022-05-10 22:19:26,393: Epoch 8/38 Batch 7100/7662 eta: 1 day, 5:46:24.933436	Training Loss 0.3709 (0.3753)	Training Prec@1 93.750 (92.187)	Training Prec@5 97.461 (95.924)	
2022-05-10 22:19:26,393: ============================================================
2022-05-10 22:20:12,927: time cost, forward:0.1711634759986412, backward:0.10440140416976859, data cost:0.19024374402551325 
2022-05-10 22:20:12,927: ============================================================
2022-05-10 22:20:12,927: Epoch 8/38 Batch 7200/7662 eta: 1 day, 5:46:17.727613	Training Loss 0.3748 (0.3753)	Training Prec@1 90.234 (92.184)	Training Prec@5 94.336 (95.921)	
2022-05-10 22:20:12,927: ============================================================
2022-05-10 22:20:59,475: time cost, forward:0.1711608654735088, backward:0.10439985568334932, data cost:0.19024057903752326 
2022-05-10 22:20:59,475: ============================================================
2022-05-10 22:20:59,475: Epoch 8/38 Batch 7300/7662 eta: 1 day, 5:46:04.405355	Training Loss 0.3794 (0.3753)	Training Prec@1 92.578 (92.182)	Training Prec@5 95.703 (95.919)	
2022-05-10 22:20:59,475: ============================================================
2022-05-10 22:21:46,009: time cost, forward:0.1711594375311837, backward:0.10439881538600435, data cost:0.1902319339984719 
2022-05-10 22:21:46,009: ============================================================
2022-05-10 22:21:46,009: Epoch 8/38 Batch 7400/7662 eta: 1 day, 5:44:46.414889	Training Loss 0.3851 (0.3754)	Training Prec@1 92.578 (92.180)	Training Prec@5 96.680 (95.918)	
2022-05-10 22:21:46,010: ============================================================
2022-05-10 22:22:32,565: time cost, forward:0.17115803695802834, backward:0.10439781062300006, data cost:0.19022609100514754 
2022-05-10 22:22:32,565: ============================================================
2022-05-10 22:22:32,565: Epoch 8/38 Batch 7500/7662 eta: 1 day, 5:44:49.150299	Training Loss 0.3737 (0.3754)	Training Prec@1 92.188 (92.183)	Training Prec@5 95.703 (95.919)	
2022-05-10 22:22:32,565: ============================================================
2022-05-10 22:23:19,072: time cost, forward:0.17115593960542774, backward:0.10439621729197542, data cost:0.19021542283449852 
2022-05-10 22:23:19,072: ============================================================
2022-05-10 22:23:19,086: Epoch 8/38 Batch 7600/7662 eta: 1 day, 5:42:40.743084	Training Loss 0.3605 (0.3754)	Training Prec@1 92.188 (92.180)	Training Prec@5 97.266 (95.917)	
2022-05-10 22:23:19,086: ============================================================
2022-05-10 22:23:49,776: Epoch: 8/38 eta: 1 day, 5:42:11.435330	Training Loss 0.3841 (0.3754)	Training Prec@1 92.188 (92.179)	Training Prec@5 95.117 (95.916)
2022-05-10 22:23:49,777: ============================================================
2022-05-10 22:24:40,577: time cost, forward:0.1971672520493016, backward:0.10556004023311114, data cost:0.2077416049109565 
2022-05-10 22:24:40,578: ============================================================
2022-05-10 22:24:40,578: Epoch 9/38 Batch 100/7662 eta: 1 day, 8:23:26.861144	Training Loss 0.3576 (0.3571)	Training Prec@1 92.969 (93.568)	Training Prec@5 97.070 (96.699)	
2022-05-10 22:24:40,578: ============================================================
2022-05-10 22:25:29,504: time cost, forward:0.19574780080785703, backward:0.10552463100184148, data cost:0.1984041072615427 
2022-05-10 22:25:29,505: ============================================================
2022-05-10 22:25:29,505: Epoch 9/38 Batch 200/7662 eta: 1 day, 7:12:45.873999	Training Loss 0.3741 (0.3601)	Training Prec@1 92.383 (93.395)	Training Prec@5 95.703 (96.642)	
2022-05-10 22:25:29,505: ============================================================
2022-05-10 22:26:17,532: time cost, forward:0.1924384485519052, backward:0.10526099890769525, data cost:0.1954042193881644 
2022-05-10 22:26:17,533: ============================================================
2022-05-10 22:26:17,533: Epoch 9/38 Batch 300/7662 eta: 1 day, 6:37:34.434147	Training Loss 0.3621 (0.3613)	Training Prec@1 93.164 (93.340)	Training Prec@5 97.266 (96.654)	
2022-05-10 22:26:17,533: ============================================================
2022-05-10 22:27:05,555: time cost, forward:0.1907144722185637, backward:0.10515258366003968, data cost:0.1939480884332107 
2022-05-10 22:27:05,555: ============================================================
2022-05-10 22:27:05,556: Epoch 9/38 Batch 400/7662 eta: 1 day, 6:36:32.272014	Training Loss 0.3592 (0.3628)	Training Prec@1 93.164 (93.315)	Training Prec@5 96.484 (96.614)	
2022-05-10 22:27:05,556: ============================================================
2022-05-10 22:27:53,275: time cost, forward:0.18909688129692612, backward:0.10507704738624588, data cost:0.19306162746253616 
2022-05-10 22:27:53,276: ============================================================
2022-05-10 22:27:53,276: Epoch 9/38 Batch 500/7662 eta: 1 day, 6:24:12.275046	Training Loss 0.3764 (0.3640)	Training Prec@1 91.992 (93.220)	Training Prec@5 96.680 (96.565)	
2022-05-10 22:27:53,276: ============================================================
2022-05-10 22:28:40,778: time cost, forward:0.1876860608242589, backward:0.1049991704784769, data cost:0.19247199219335898 
2022-05-10 22:28:40,778: ============================================================
2022-05-10 22:28:40,779: Epoch 9/38 Batch 600/7662 eta: 1 day, 6:15:04.791379	Training Loss 0.3704 (0.3652)	Training Prec@1 91.211 (93.149)	Training Prec@5 96.484 (96.522)	
2022-05-10 22:28:40,779: ============================================================
2022-05-10 22:29:28,189: time cost, forward:0.18651399967155402, backward:0.10496430983700296, data cost:0.1920611906119853 
2022-05-10 22:29:28,190: ============================================================
2022-05-10 22:29:28,190: Epoch 9/38 Batch 700/7662 eta: 1 day, 6:10:48.211796	Training Loss 0.3893 (0.3661)	Training Prec@1 91.016 (93.106)	Training Prec@5 95.312 (96.485)	
2022-05-10 22:29:28,190: ============================================================
2022-05-10 22:30:15,550: time cost, forward:0.18555740361219653, backward:0.10493433520253817, data cost:0.1917739878309534 
2022-05-10 22:30:15,550: ============================================================
2022-05-10 22:30:15,550: Epoch 9/38 Batch 800/7662 eta: 1 day, 6:08:04.322080	Training Loss 0.3726 (0.3667)	Training Prec@1 91.797 (93.059)	Training Prec@5 96.289 (96.474)	
2022-05-10 22:30:15,550: ============================================================
2022-05-10 22:31:02,778: time cost, forward:0.18468762504908612, backward:0.1049128544078653, data cost:0.19152629919126382 
2022-05-10 22:31:02,778: ============================================================
2022-05-10 22:31:02,779: Epoch 9/38 Batch 900/7662 eta: 1 day, 6:02:14.157816	Training Loss 0.3649 (0.3674)	Training Prec@1 93.945 (93.004)	Training Prec@5 97.070 (96.437)	
2022-05-10 22:31:02,779: ============================================================
2022-05-10 22:31:49,882: time cost, forward:0.18388912007138059, backward:0.10488858690729609, data cost:0.19131300876567792 
2022-05-10 22:31:49,883: ============================================================
2022-05-10 22:31:49,883: Epoch 9/38 Batch 1000/7662 eta: 1 day, 5:56:43.990292	Training Loss 0.3753 (0.3678)	Training Prec@1 92.383 (92.957)	Training Prec@5 96.289 (96.409)	
2022-05-10 22:31:49,883: ============================================================
2022-05-10 22:32:36,828: time cost, forward:0.18306636463196524, backward:0.10487926711376631, data cost:0.19115559028646315 
2022-05-10 22:32:36,828: ============================================================
2022-05-10 22:32:36,829: Epoch 9/38 Batch 1100/7662 eta: 1 day, 5:49:53.119918	Training Loss 0.3700 (0.3682)	Training Prec@1 92.578 (92.925)	Training Prec@5 95.703 (96.387)	
2022-05-10 22:32:36,829: ============================================================
2022-05-10 22:33:23,712: time cost, forward:0.1823114108005298, backward:0.10487363535329836, data cost:0.19103942342953845 
2022-05-10 22:33:23,712: ============================================================
2022-05-10 22:33:23,712: Epoch 9/38 Batch 1200/7662 eta: 1 day, 5:46:44.287249	Training Loss 0.3788 (0.3684)	Training Prec@1 91.016 (92.896)	Training Prec@5 96.094 (96.367)	
2022-05-10 22:33:23,712: ============================================================
2022-05-10 22:34:10,487: time cost, forward:0.18161424882050384, backward:0.10486754460734896, data cost:0.19091710023828615 
2022-05-10 22:34:10,487: ============================================================
2022-05-10 22:34:10,487: Epoch 9/38 Batch 1300/7662 eta: 1 day, 5:41:49.850453	Training Loss 0.3664 (0.3688)	Training Prec@1 92.578 (92.846)	Training Prec@5 95.703 (96.331)	
2022-05-10 22:34:10,487: ============================================================
2022-05-10 22:34:57,346: time cost, forward:0.18104043000080144, backward:0.10486116300232501, data cost:0.1908503054209144 
2022-05-10 22:34:57,346: ============================================================
2022-05-10 22:34:57,346: Epoch 9/38 Batch 1400/7662 eta: 1 day, 5:44:14.576410	Training Loss 0.3611 (0.3691)	Training Prec@1 93.164 (92.798)	Training Prec@5 95.703 (96.301)	
2022-05-10 22:34:57,346: ============================================================
2022-05-10 22:35:44,145: time cost, forward:0.1804705792224113, backward:0.10491933689028363, data cost:0.190760317764893 
2022-05-10 22:35:44,145: ============================================================
2022-05-10 22:35:44,145: Epoch 9/38 Batch 1500/7662 eta: 1 day, 5:41:10.197304	Training Loss 0.3824 (0.3694)	Training Prec@1 91.797 (92.772)	Training Prec@5 95.117 (96.282)	
2022-05-10 22:35:44,145: ============================================================
2022-05-10 22:36:30,698: time cost, forward:0.17988730192631763, backward:0.10489280571260626, data cost:0.1906896060969846 
2022-05-10 22:36:30,699: ============================================================
2022-05-10 22:36:30,699: Epoch 9/38 Batch 1600/7662 eta: 1 day, 5:31:04.195782	Training Loss 0.3629 (0.3697)	Training Prec@1 93.359 (92.747)	Training Prec@5 97.852 (96.264)	
2022-05-10 22:36:30,699: ============================================================
2022-05-10 22:37:17,217: time cost, forward:0.17936826987151472, backward:0.10485759996680248, data cost:0.19062339410562948 
2022-05-10 22:37:17,218: ============================================================
2022-05-10 22:37:17,218: Epoch 9/38 Batch 1700/7662 eta: 1 day, 5:28:57.877901	Training Loss 0.3595 (0.3698)	Training Prec@1 92.578 (92.728)	Training Prec@5 95.898 (96.254)	
2022-05-10 22:37:17,218: ============================================================
2022-05-10 22:38:03,798: time cost, forward:0.1789262330551953, backward:0.10482657161138004, data cost:0.19057310879926273 
2022-05-10 22:38:03,799: ============================================================
2022-05-10 22:38:03,799: Epoch 9/38 Batch 1800/7662 eta: 1 day, 5:30:33.412702	Training Loss 0.3642 (0.3701)	Training Prec@1 93.945 (92.695)	Training Prec@5 96.484 (96.232)	
2022-05-10 22:38:03,799: ============================================================
2022-05-10 22:38:50,327: time cost, forward:0.17850078527019675, backward:0.10480103648418247, data cost:0.19052447828259703 
2022-05-10 22:38:50,327: ============================================================
2022-05-10 22:38:50,327: Epoch 9/38 Batch 1900/7662 eta: 1 day, 5:27:46.518293	Training Loss 0.3784 (0.3703)	Training Prec@1 93.555 (92.666)	Training Prec@5 96.680 (96.225)	
2022-05-10 22:38:50,327: ============================================================
2022-05-10 22:39:36,867: time cost, forward:0.1781361886654692, backward:0.10477860812368006, data cost:0.1904768541850347 
2022-05-10 22:39:36,867: ============================================================
2022-05-10 22:39:36,867: Epoch 9/38 Batch 2000/7662 eta: 1 day, 5:27:25.924762	Training Loss 0.3694 (0.3705)	Training Prec@1 93.945 (92.637)	Training Prec@5 96.094 (96.210)	
2022-05-10 22:39:36,867: ============================================================
2022-05-10 22:40:23,399: time cost, forward:0.17780559468462445, backward:0.10475511117001952, data cost:0.19043411079504877 
2022-05-10 22:40:23,400: ============================================================
2022-05-10 22:40:23,400: Epoch 9/38 Batch 2100/7662 eta: 1 day, 5:26:23.466254	Training Loss 0.3708 (0.3707)	Training Prec@1 92.188 (92.614)	Training Prec@5 95.898 (96.191)	
2022-05-10 22:40:23,400: ============================================================
2022-05-10 22:41:09,940: time cost, forward:0.17750797048380507, backward:0.10473315625800063, data cost:0.19039744016743618 
2022-05-10 22:41:09,941: ============================================================
2022-05-10 22:41:09,941: Epoch 9/38 Batch 2200/7662 eta: 1 day, 5:25:55.539666	Training Loss 0.3874 (0.3709)	Training Prec@1 91.406 (92.588)	Training Prec@5 96.289 (96.172)	
2022-05-10 22:41:09,941: ============================================================
2022-05-10 22:41:56,426: time cost, forward:0.17722623345124924, backward:0.10471207331242173, data cost:0.190350738905367 
2022-05-10 22:41:56,427: ============================================================
2022-05-10 22:41:56,427: Epoch 9/38 Batch 2300/7662 eta: 1 day, 5:23:04.376074	Training Loss 0.3670 (0.3711)	Training Prec@1 93.359 (92.570)	Training Prec@5 95.703 (96.162)	
2022-05-10 22:41:56,427: ============================================================
2022-05-10 22:42:42,948: time cost, forward:0.1769735572635258, backward:0.10469235157459764, data cost:0.19031667282005904 
2022-05-10 22:42:42,949: ============================================================
2022-05-10 22:42:42,949: Epoch 9/38 Batch 2400/7662 eta: 1 day, 5:23:38.999315	Training Loss 0.3776 (0.3712)	Training Prec@1 90.039 (92.549)	Training Prec@5 94.922 (96.146)	
2022-05-10 22:42:42,949: ============================================================
2022-05-10 22:43:29,509: time cost, forward:0.17674307472088566, backward:0.10467476537581585, data cost:0.19029912341828822 
2022-05-10 22:43:29,509: ============================================================
2022-05-10 22:43:29,509: Epoch 9/38 Batch 2500/7662 eta: 1 day, 5:24:20.623637	Training Loss 0.3674 (0.3714)	Training Prec@1 94.141 (92.535)	Training Prec@5 97.266 (96.138)	
2022-05-10 22:43:29,509: ============================================================
2022-05-10 22:44:16,051: time cost, forward:0.17652791433492135, backward:0.10465885043465298, data cost:0.1902776707498419 
2022-05-10 22:44:16,052: ============================================================
2022-05-10 22:44:16,052: Epoch 9/38 Batch 2600/7662 eta: 1 day, 5:22:53.140068	Training Loss 0.3787 (0.3715)	Training Prec@1 93.555 (92.520)	Training Prec@5 95.312 (96.130)	
2022-05-10 22:44:16,052: ============================================================
2022-05-10 22:45:02,623: time cost, forward:0.17633024256686097, backward:0.10464506495568698, data cost:0.19026522876687207 
2022-05-10 22:45:02,623: ============================================================
2022-05-10 22:45:02,623: Epoch 9/38 Batch 2700/7662 eta: 1 day, 5:23:12.206185	Training Loss 0.3673 (0.3716)	Training Prec@1 92.773 (92.500)	Training Prec@5 95.312 (96.120)	
2022-05-10 22:45:02,623: ============================================================
2022-05-10 22:45:49,154: time cost, forward:0.17613796346227625, backward:0.10463138894125068, data cost:0.19025124060592297 
2022-05-10 22:45:49,154: ============================================================
2022-05-10 22:45:49,154: Epoch 9/38 Batch 2800/7662 eta: 1 day, 5:20:53.733650	Training Loss 0.3645 (0.3717)	Training Prec@1 91.602 (92.484)	Training Prec@5 95.508 (96.110)	
2022-05-10 22:45:49,154: ============================================================
2022-05-10 22:46:35,653: time cost, forward:0.1759494124054292, backward:0.10461906393300505, data cost:0.19022772459376883 
2022-05-10 22:46:35,653: ============================================================
2022-05-10 22:46:35,653: Epoch 9/38 Batch 2900/7662 eta: 1 day, 5:18:53.670244	Training Loss 0.3696 (0.3719)	Training Prec@1 89.844 (92.467)	Training Prec@5 94.141 (96.097)	
2022-05-10 22:46:35,653: ============================================================
2022-05-10 22:47:22,157: time cost, forward:0.1757793854220226, backward:0.10460829933550644, data cost:0.19020816507876892 
2022-05-10 22:47:22,157: ============================================================
2022-05-10 22:47:22,157: Epoch 9/38 Batch 3000/7662 eta: 1 day, 5:18:19.895284	Training Loss 0.3528 (0.3720)	Training Prec@1 93.945 (92.450)	Training Prec@5 97.070 (96.088)	
2022-05-10 22:47:22,157: ============================================================
2022-05-10 22:48:08,676: time cost, forward:0.17561847150383475, backward:0.1045981182825877, data cost:0.1901966016805722 
2022-05-10 22:48:08,676: ============================================================
2022-05-10 22:48:08,677: Epoch 9/38 Batch 3100/7662 eta: 1 day, 5:18:07.862853	Training Loss 0.3796 (0.3721)	Training Prec@1 90.820 (92.436)	Training Prec@5 94.727 (96.077)	
2022-05-10 22:48:08,677: ============================================================
2022-05-10 22:48:55,198: time cost, forward:0.17547474439608451, backward:0.10458700043516407, data cost:0.19018101736917165 
2022-05-10 22:48:55,198: ============================================================
2022-05-10 22:48:55,198: Epoch 9/38 Batch 3200/7662 eta: 1 day, 5:17:26.760979	Training Loss 0.3766 (0.3722)	Training Prec@1 92.773 (92.433)	Training Prec@5 96.289 (96.076)	
2022-05-10 22:48:55,198: ============================================================
2022-05-10 22:49:41,732: time cost, forward:0.17533504287197071, backward:0.1045768201694448, data cost:0.1901749252152826 
2022-05-10 22:49:41,733: ============================================================
2022-05-10 22:49:41,733: Epoch 9/38 Batch 3300/7662 eta: 1 day, 5:17:09.114167	Training Loss 0.3749 (0.3723)	Training Prec@1 92.773 (92.428)	Training Prec@5 95.508 (96.075)	
2022-05-10 22:49:41,733: ============================================================
2022-05-10 22:50:28,299: time cost, forward:0.17520981951649311, backward:0.10457012400131921, data cost:0.19016982170019686 
2022-05-10 22:50:28,300: ============================================================
2022-05-10 22:50:28,300: Epoch 9/38 Batch 3400/7662 eta: 1 day, 5:17:35.828028	Training Loss 0.3741 (0.3723)	Training Prec@1 91.992 (92.416)	Training Prec@5 96.484 (96.069)	
2022-05-10 22:50:28,300: ============================================================
2022-05-10 22:51:14,815: time cost, forward:0.17508535175263523, backward:0.10456061199686466, data cost:0.19016013413914684 
2022-05-10 22:51:14,815: ============================================================
2022-05-10 22:51:14,815: Epoch 9/38 Batch 3500/7662 eta: 1 day, 5:14:53.240922	Training Loss 0.3579 (0.3724)	Training Prec@1 93.359 (92.407)	Training Prec@5 96.094 (96.062)	
2022-05-10 22:51:14,816: ============================================================
2022-05-10 22:52:01,311: time cost, forward:0.17496628759966587, backward:0.10455194298642713, data cost:0.19014711385304545 
2022-05-10 22:52:01,311: ============================================================
2022-05-10 22:52:01,312: Epoch 9/38 Batch 3600/7662 eta: 1 day, 5:13:22.738143	Training Loss 0.3940 (0.3725)	Training Prec@1 90.820 (92.398)	Training Prec@5 94.727 (96.059)	
2022-05-10 22:52:01,312: ============================================================
2022-05-10 22:52:47,833: time cost, forward:0.17485256574063018, backward:0.10454402043388224, data cost:0.19013923069824235 
2022-05-10 22:52:47,834: ============================================================
2022-05-10 22:52:47,834: Epoch 9/38 Batch 3700/7662 eta: 1 day, 5:13:35.158720	Training Loss 0.3774 (0.3725)	Training Prec@1 92.383 (92.392)	Training Prec@5 95.898 (96.055)	
2022-05-10 22:52:47,834: ============================================================
2022-05-10 22:53:34,375: time cost, forward:0.17476315584958432, backward:0.10453808536715306, data cost:0.1901203684193048 
2022-05-10 22:53:34,376: ============================================================
2022-05-10 22:53:34,376: Epoch 9/38 Batch 3800/7662 eta: 1 day, 5:13:33.206185	Training Loss 0.3604 (0.3726)	Training Prec@1 94.336 (92.387)	Training Prec@5 96.875 (96.049)	
2022-05-10 22:53:34,376: ============================================================
2022-05-10 22:54:20,959: time cost, forward:0.17467866600645174, backward:0.10453125500440537, data cost:0.19011403200228297 
2022-05-10 22:54:20,959: ============================================================
2022-05-10 22:54:20,959: Epoch 9/38 Batch 3900/7662 eta: 1 day, 5:14:20.085921	Training Loss 0.3787 (0.3727)	Training Prec@1 92.773 (92.383)	Training Prec@5 95.508 (96.045)	
2022-05-10 22:54:20,959: ============================================================
2022-05-10 22:55:07,460: time cost, forward:0.17459006254659293, backward:0.10452476779530423, data cost:0.19009579506836166 
2022-05-10 22:55:07,460: ============================================================
2022-05-10 22:55:07,461: Epoch 9/38 Batch 4000/7662 eta: 1 day, 5:10:28.712821	Training Loss 0.3683 (0.3727)	Training Prec@1 92.773 (92.374)	Training Prec@5 96.484 (96.040)	
2022-05-10 22:55:07,461: ============================================================
2022-05-10 22:55:53,961: time cost, forward:0.17449878500449598, backward:0.10451891934705904, data cost:0.19008493923681427 
2022-05-10 22:55:53,961: ============================================================
2022-05-10 22:55:53,961: Epoch 9/38 Batch 4100/7662 eta: 1 day, 5:09:40.547589	Training Loss 0.3873 (0.3728)	Training Prec@1 90.820 (92.362)	Training Prec@5 95.898 (96.035)	
2022-05-10 22:55:53,961: ============================================================
2022-05-10 22:56:40,421: time cost, forward:0.1744069619302552, backward:0.1045133773415791, data cost:0.19006956631469 
2022-05-10 22:56:40,421: ============================================================
2022-05-10 22:56:40,421: Epoch 9/38 Batch 4200/7662 eta: 1 day, 5:07:21.296350	Training Loss 0.3777 (0.3728)	Training Prec@1 93.164 (92.360)	Training Prec@5 97.656 (96.036)	
2022-05-10 22:56:40,421: ============================================================
2022-05-10 22:57:26,902: time cost, forward:0.17432265909474015, backward:0.10450591678313251, data cost:0.19005852728340342 
2022-05-10 22:57:26,903: ============================================================
2022-05-10 22:57:26,903: Epoch 9/38 Batch 4300/7662 eta: 1 day, 5:07:25.073900	Training Loss 0.3673 (0.3729)	Training Prec@1 93.359 (92.358)	Training Prec@5 95.898 (96.034)	
2022-05-10 22:57:26,903: ============================================================
2022-05-10 22:58:13,364: time cost, forward:0.17423976706114377, backward:0.10450057550895536, data cost:0.19004416823468442 
2022-05-10 22:58:13,364: ============================================================
2022-05-10 22:58:13,365: Epoch 9/38 Batch 4400/7662 eta: 1 day, 5:05:53.076245	Training Loss 0.3777 (0.3729)	Training Prec@1 92.578 (92.354)	Training Prec@5 96.484 (96.033)	
2022-05-10 22:58:13,365: ============================================================
2022-05-10 22:58:59,831: time cost, forward:0.17415720639056062, backward:0.10449653292899928, data cost:0.19003357413504543 
2022-05-10 22:58:59,831: ============================================================
2022-05-10 22:58:59,831: Epoch 9/38 Batch 4500/7662 eta: 1 day, 5:05:17.736679	Training Loss 0.3794 (0.3729)	Training Prec@1 91.016 (92.348)	Training Prec@5 96.484 (96.030)	
2022-05-10 22:58:59,831: ============================================================
2022-05-10 22:59:46,283: time cost, forward:0.17407705675495477, backward:0.1044927866828522, data cost:0.19002134080917116 
2022-05-10 22:59:46,284: ============================================================
2022-05-10 22:59:46,284: Epoch 9/38 Batch 4600/7662 eta: 1 day, 5:03:59.107933	Training Loss 0.3611 (0.3730)	Training Prec@1 93.750 (92.343)	Training Prec@5 96.484 (96.025)	
2022-05-10 22:59:46,284: ============================================================
2022-05-10 23:00:32,764: time cost, forward:0.1740013233370719, backward:0.1044895914316837, data cost:0.1900143677641874 
2022-05-10 23:00:32,764: ============================================================
2022-05-10 23:00:32,764: Epoch 9/38 Batch 4700/7662 eta: 1 day, 5:04:15.527495	Training Loss 0.3723 (0.3731)	Training Prec@1 92.969 (92.334)	Training Prec@5 96.875 (96.017)	
2022-05-10 23:00:32,764: ============================================================
2022-05-10 23:01:19,290: time cost, forward:0.17393112868213434, backward:0.10448563702530254, data cost:0.19001520571795125 
2022-05-10 23:01:19,290: ============================================================
2022-05-10 23:01:19,290: Epoch 9/38 Batch 4800/7662 eta: 1 day, 5:05:11.699545	Training Loss 0.3863 (0.3731)	Training Prec@1 90.625 (92.325)	Training Prec@5 96.094 (96.014)	
2022-05-10 23:01:19,290: ============================================================
2022-05-10 23:02:05,870: time cost, forward:0.17386575187072628, backward:0.10448242323961665, data cost:0.19002130543073603 
2022-05-10 23:02:05,870: ============================================================
2022-05-10 23:02:05,870: Epoch 9/38 Batch 4900/7662 eta: 1 day, 5:06:26.948407	Training Loss 0.3824 (0.3732)	Training Prec@1 92.188 (92.318)	Training Prec@5 95.312 (96.012)	
2022-05-10 23:02:05,870: ============================================================
2022-05-10 23:02:52,506: time cost, forward:0.17380458952355657, backward:0.10447783039960654, data cost:0.19004304162452973 
2022-05-10 23:02:52,506: ============================================================
2022-05-10 23:02:52,506: Epoch 9/38 Batch 5000/7662 eta: 1 day, 5:07:46.508164	Training Loss 0.3685 (0.3733)	Training Prec@1 93.164 (92.311)	Training Prec@5 95.508 (96.007)	
2022-05-10 23:02:52,506: ============================================================
2022-05-10 23:03:39,073: time cost, forward:0.17374859302271625, backward:0.10447394490171867, data cost:0.19004329851408241 
2022-05-10 23:03:39,073: ============================================================
2022-05-10 23:03:39,073: Epoch 9/38 Batch 5100/7662 eta: 1 day, 5:04:24.898375	Training Loss 0.3692 (0.3733)	Training Prec@1 92.773 (92.307)	Training Prec@5 96.094 (96.004)	
2022-05-10 23:03:39,073: ============================================================
2022-05-10 23:04:25,692: time cost, forward:0.17368946985273, backward:0.10447030251795202, data cost:0.19005699372332838 
2022-05-10 23:04:25,693: ============================================================
2022-05-10 23:04:25,693: Epoch 9/38 Batch 5200/7662 eta: 1 day, 5:05:35.495128	Training Loss 0.3732 (0.3733)	Training Prec@1 92.578 (92.302)	Training Prec@5 96.875 (96.000)	
2022-05-10 23:04:25,693: ============================================================
2022-05-10 23:05:12,287: time cost, forward:0.17363583791883605, backward:0.10446676512353037, data cost:0.19006633475088222 
2022-05-10 23:05:12,287: ============================================================
2022-05-10 23:05:12,287: Epoch 9/38 Batch 5300/7662 eta: 1 day, 5:03:52.718182	Training Loss 0.3828 (0.3734)	Training Prec@1 90.234 (92.297)	Training Prec@5 94.922 (95.996)	
2022-05-10 23:05:12,287: ============================================================
2022-05-10 23:05:58,834: time cost, forward:0.17358081392456723, backward:0.10446313090358847, data cost:0.1900682429910523 
2022-05-10 23:05:58,835: ============================================================
2022-05-10 23:05:58,835: Epoch 9/38 Batch 5400/7662 eta: 1 day, 5:01:21.288244	Training Loss 0.3707 (0.3734)	Training Prec@1 92.969 (92.294)	Training Prec@5 97.461 (95.995)	
2022-05-10 23:05:58,835: ============================================================
2022-05-10 23:06:45,431: time cost, forward:0.17352721265802212, backward:0.10445905833011064, data cost:0.19007668869780245 
2022-05-10 23:06:45,431: ============================================================
2022-05-10 23:06:45,431: Epoch 9/38 Batch 5500/7662 eta: 1 day, 5:02:24.333601	Training Loss 0.3859 (0.3734)	Training Prec@1 91.406 (92.287)	Training Prec@5 95.898 (95.990)	
2022-05-10 23:06:45,431: ============================================================
2022-05-10 23:07:32,036: time cost, forward:0.17347876538887985, backward:0.10445517189780779, data cost:0.19008932268647216 
2022-05-10 23:07:32,036: ============================================================
2022-05-10 23:07:32,036: Epoch 9/38 Batch 5600/7662 eta: 1 day, 5:01:57.421359	Training Loss 0.3665 (0.3735)	Training Prec@1 92.578 (92.283)	Training Prec@5 95.703 (95.987)	
2022-05-10 23:07:32,036: ============================================================
2022-05-10 23:08:18,635: time cost, forward:0.17343651974362267, backward:0.10445124844873886, data cost:0.19009488058583865 
2022-05-10 23:08:18,635: ============================================================
2022-05-10 23:08:18,635: Epoch 9/38 Batch 5700/7662 eta: 1 day, 5:00:56.433211	Training Loss 0.3815 (0.3735)	Training Prec@1 91.406 (92.279)	Training Prec@5 95.117 (95.985)	
2022-05-10 23:08:18,635: ============================================================
2022-05-10 23:09:05,215: time cost, forward:0.17339891938428095, backward:0.10444634674869543, data cost:0.19009513640366746 
2022-05-10 23:09:05,215: ============================================================
2022-05-10 23:09:05,215: Epoch 9/38 Batch 5800/7662 eta: 1 day, 4:59:28.159585	Training Loss 0.3793 (0.3735)	Training Prec@1 91.016 (92.276)	Training Prec@5 94.922 (95.984)	
2022-05-10 23:09:05,216: ============================================================
2022-05-10 23:09:51,790: time cost, forward:0.1733603799195588, backward:0.10444267524826585, data cost:0.19009571068164433 
2022-05-10 23:09:51,791: ============================================================
2022-05-10 23:09:51,791: Epoch 9/38 Batch 5900/7662 eta: 1 day, 4:58:30.361812	Training Loss 0.3685 (0.3736)	Training Prec@1 92.773 (92.271)	Training Prec@5 96.680 (95.982)	
2022-05-10 23:09:51,791: ============================================================
2022-05-10 23:10:38,397: time cost, forward:0.17332009081642594, backward:0.1044388624564233, data cost:0.19010482726245745 
2022-05-10 23:10:38,397: ============================================================
2022-05-10 23:10:38,397: Epoch 9/38 Batch 6000/7662 eta: 1 day, 4:58:54.119950	Training Loss 0.3800 (0.3736)	Training Prec@1 91.016 (92.266)	Training Prec@5 94.727 (95.979)	
2022-05-10 23:10:38,397: ============================================================
2022-05-10 23:11:24,969: time cost, forward:0.17327990616358857, backward:0.10443557143348185, data cost:0.19010666441303684 
2022-05-10 23:11:24,970: ============================================================
2022-05-10 23:11:24,970: Epoch 9/38 Batch 6100/7662 eta: 1 day, 4:56:51.140251	Training Loss 0.3733 (0.3736)	Training Prec@1 91.992 (92.259)	Training Prec@5 97.266 (95.974)	
2022-05-10 23:11:24,970: ============================================================
2022-05-10 23:12:11,563: time cost, forward:0.17324482481178496, backward:0.10443238847427627, data cost:0.19011031421735838 
2022-05-10 23:12:11,564: ============================================================
2022-05-10 23:12:11,564: Epoch 9/38 Batch 6200/7662 eta: 1 day, 4:56:52.639094	Training Loss 0.3688 (0.3736)	Training Prec@1 93.945 (92.260)	Training Prec@5 97.070 (95.974)	
2022-05-10 23:12:11,564: ============================================================
2022-05-10 23:12:58,168: time cost, forward:0.1732061235540196, backward:0.10442865464512859, data cost:0.1901208767343616 
2022-05-10 23:12:58,168: ============================================================
2022-05-10 23:12:58,168: Epoch 9/38 Batch 6300/7662 eta: 1 day, 4:56:29.276362	Training Loss 0.3800 (0.3737)	Training Prec@1 92.969 (92.257)	Training Prec@5 96.484 (95.971)	
2022-05-10 23:12:58,168: ============================================================
2022-05-10 23:13:44,712: time cost, forward:0.17316746033622168, backward:0.10442479265203773, data cost:0.19012103950368145 
2022-05-10 23:13:44,712: ============================================================
2022-05-10 23:13:44,713: Epoch 9/38 Batch 6400/7662 eta: 1 day, 4:53:28.280083	Training Loss 0.3757 (0.3737)	Training Prec@1 93.945 (92.255)	Training Prec@5 96.680 (95.970)	
2022-05-10 23:13:44,713: ============================================================
2022-05-10 23:14:31,345: time cost, forward:0.17313836974205465, backward:0.10442163405335488, data cost:0.1901279457680426 
2022-05-10 23:14:31,346: ============================================================
2022-05-10 23:14:31,346: Epoch 9/38 Batch 6500/7662 eta: 1 day, 4:56:00.516427	Training Loss 0.3713 (0.3737)	Training Prec@1 92.383 (92.251)	Training Prec@5 95.508 (95.967)	
2022-05-10 23:14:31,346: ============================================================
2022-05-10 23:15:17,957: time cost, forward:0.1731139668046859, backward:0.10441840914347475, data cost:0.19012557934551352 
2022-05-10 23:15:17,957: ============================================================
2022-05-10 23:15:17,957: Epoch 9/38 Batch 6600/7662 eta: 1 day, 4:54:24.548404	Training Loss 0.3810 (0.3737)	Training Prec@1 90.430 (92.247)	Training Prec@5 95.508 (95.964)	
2022-05-10 23:15:17,957: ============================================================
2022-05-10 23:16:04,554: time cost, forward:0.17308449531637177, backward:0.10441638412965307, data cost:0.19012707912275945 
2022-05-10 23:16:04,555: ============================================================
2022-05-10 23:16:04,555: Epoch 9/38 Batch 6700/7662 eta: 1 day, 4:53:08.260150	Training Loss 0.3650 (0.3737)	Training Prec@1 93.359 (92.246)	Training Prec@5 96.680 (95.963)	
2022-05-10 23:16:04,555: ============================================================
2022-05-10 23:16:51,198: time cost, forward:0.17305524129344357, backward:0.10441289373768974, data cost:0.19013882830031112 
2022-05-10 23:16:51,199: ============================================================
2022-05-10 23:16:51,199: Epoch 9/38 Batch 6800/7662 eta: 1 day, 4:54:04.391609	Training Loss 0.3673 (0.3738)	Training Prec@1 92.773 (92.242)	Training Prec@5 95.898 (95.960)	
2022-05-10 23:16:51,199: ============================================================
2022-05-10 23:17:37,786: time cost, forward:0.17302210743245153, backward:0.1044099892822102, data cost:0.19014358361539055 
2022-05-10 23:17:37,787: ============================================================
2022-05-10 23:17:37,787: Epoch 9/38 Batch 6900/7662 eta: 1 day, 4:51:12.954396	Training Loss 0.3708 (0.3738)	Training Prec@1 93.945 (92.237)	Training Prec@5 96.289 (95.959)	
2022-05-10 23:17:37,787: ============================================================
2022-05-10 23:18:24,350: time cost, forward:0.17299288513831096, backward:0.10440678633286418, data cost:0.19014302831596094 
2022-05-10 23:18:24,351: ============================================================
2022-05-10 23:18:24,351: Epoch 9/38 Batch 7000/7662 eta: 1 day, 4:49:33.659975	Training Loss 0.3733 (0.3738)	Training Prec@1 94.336 (92.239)	Training Prec@5 96.484 (95.959)	
2022-05-10 23:18:24,351: ============================================================
2022-05-10 23:19:10,929: time cost, forward:0.1729643767376083, backward:0.10440429634973354, data cost:0.1901454325040674 
2022-05-10 23:19:10,929: ============================================================
2022-05-10 23:19:10,929: Epoch 9/38 Batch 7100/7662 eta: 1 day, 4:49:17.386110	Training Loss 0.3724 (0.3738)	Training Prec@1 92.969 (92.238)	Training Prec@5 96.094 (95.957)	
2022-05-10 23:19:10,929: ============================================================
2022-05-10 23:19:57,578: time cost, forward:0.17293627107453058, backward:0.10440186159960808, data cost:0.19015679407126374 
2022-05-10 23:19:57,578: ============================================================
2022-05-10 23:19:57,578: Epoch 9/38 Batch 7200/7662 eta: 1 day, 4:51:09.733327	Training Loss 0.3738 (0.3738)	Training Prec@1 92.578 (92.238)	Training Prec@5 96.289 (95.956)	
2022-05-10 23:19:57,578: ============================================================
2022-05-10 23:20:44,215: time cost, forward:0.17290856789556133, backward:0.10440469591695, data cost:0.19016134534768658 
2022-05-10 23:20:44,215: ============================================================
2022-05-10 23:20:44,215: Epoch 9/38 Batch 7300/7662 eta: 1 day, 4:49:56.117603	Training Loss 0.3892 (0.3738)	Training Prec@1 90.039 (92.234)	Training Prec@5 95.898 (95.954)	
2022-05-10 23:20:44,216: ============================================================
2022-05-10 23:21:30,878: time cost, forward:0.17289126955314107, backward:0.10440208796214889, data cost:0.19016503546588856 
2022-05-10 23:21:30,878: ============================================================
2022-05-10 23:21:30,879: Epoch 9/38 Batch 7400/7662 eta: 1 day, 4:50:07.228072	Training Loss 0.3750 (0.3738)	Training Prec@1 92.188 (92.231)	Training Prec@5 96.680 (95.953)	
2022-05-10 23:21:30,879: ============================================================
2022-05-10 23:22:17,413: time cost, forward:0.17286407383207736, backward:0.10440041389699331, data cost:0.19016205328180721 
2022-05-10 23:22:17,413: ============================================================
2022-05-10 23:22:17,413: Epoch 9/38 Batch 7500/7662 eta: 1 day, 4:44:35.358607	Training Loss 0.3785 (0.3739)	Training Prec@1 91.406 (92.231)	Training Prec@5 95.312 (95.952)	
2022-05-10 23:22:17,413: ============================================================
2022-05-10 23:23:03,950: time cost, forward:0.17283966168241605, backward:0.10439862312651227, data cost:0.19015782995433583 
2022-05-10 23:23:03,951: ============================================================
2022-05-10 23:23:03,951: Epoch 9/38 Batch 7600/7662 eta: 1 day, 4:43:54.538322	Training Loss 0.3810 (0.3739)	Training Prec@1 91.992 (92.231)	Training Prec@5 95.117 (95.950)	
2022-05-10 23:23:03,951: ============================================================
2022-05-10 23:23:34,588: Epoch: 9/38 eta: 1 day, 4:43:25.219747	Training Loss 0.3706 (0.3739)	Training Prec@1 93.359 (92.227)	Training Prec@5 96.484 (95.949)
2022-05-10 23:23:34,589: ============================================================
2022-05-10 23:24:24,404: time cost, forward:0.18977385337906655, backward:0.10431321221168595, data cost:0.20681066705723 
2022-05-10 23:24:24,404: ============================================================
2022-05-10 23:24:24,404: Epoch 10/38 Batch 100/7662 eta: 1 day, 6:43:34.380605	Training Loss 0.3061 (0.3205)	Training Prec@1 95.117 (95.188)	Training Prec@5 98.047 (97.660)	
2022-05-10 23:24:24,404: ============================================================
2022-05-10 23:25:12,219: time cost, forward:0.18702503544601365, backward:0.10431541749580421, data cost:0.19800479328213025 
2022-05-10 23:25:12,219: ============================================================
2022-05-10 23:25:12,219: Epoch 10/38 Batch 200/7662 eta: 1 day, 5:29:08.623494	Training Loss 0.3046 (0.3124)	Training Prec@1 95.312 (95.481)	Training Prec@5 97.852 (97.817)	
2022-05-10 23:25:12,219: ============================================================
2022-05-10 23:26:00,012: time cost, forward:0.18597450782622782, backward:0.10431960833112532, data cost:0.19514494596117715 
2022-05-10 23:26:00,012: ============================================================
2022-05-10 23:26:00,012: Epoch 10/38 Batch 300/7662 eta: 1 day, 5:27:32.257279	Training Loss 0.2860 (0.3058)	Training Prec@1 96.094 (95.703)	Training Prec@5 97.266 (97.962)	
2022-05-10 23:26:00,012: ============================================================
2022-05-10 23:26:47,449: time cost, forward:0.18458029261806555, backward:0.1043219494640379, data cost:0.19370519308219278 
2022-05-10 23:26:47,450: ============================================================
2022-05-10 23:26:47,450: Epoch 10/38 Batch 400/7662 eta: 1 day, 5:13:36.319443	Training Loss 0.3002 (0.3010)	Training Prec@1 94.141 (95.905)	Training Prec@5 98.242 (98.070)	
2022-05-10 23:26:47,450: ============================================================
2022-05-10 23:27:34,054: time cost, forward:0.18207926023938134, backward:0.10431467985103508, data cost:0.19284700057310666 
2022-05-10 23:27:34,055: ============================================================
2022-05-10 23:27:34,055: Epoch 10/38 Batch 500/7662 eta: 1 day, 4:42:02.669935	Training Loss 0.2775 (0.2970)	Training Prec@1 96.875 (96.045)	Training Prec@5 97.852 (98.156)	
2022-05-10 23:27:34,055: ============================================================
2022-05-10 23:28:20,586: time cost, forward:0.1801928355419178, backward:0.10431266030007491, data cost:0.19237000993973824 
2022-05-10 23:28:20,587: ============================================================
2022-05-10 23:28:20,587: Epoch 10/38 Batch 600/7662 eta: 1 day, 4:38:34.317910	Training Loss 0.2813 (0.2937)	Training Prec@1 96.875 (96.145)	Training Prec@5 98.438 (98.215)	
2022-05-10 23:28:20,587: ============================================================
2022-05-10 23:29:07,043: time cost, forward:0.17881872213961228, backward:0.10430836575225699, data cost:0.19195028401921918 
2022-05-10 23:29:07,043: ============================================================
2022-05-10 23:29:07,043: Epoch 10/38 Batch 700/7662 eta: 1 day, 4:35:00.403163	Training Loss 0.2628 (0.2907)	Training Prec@1 96.680 (96.268)	Training Prec@5 98.438 (98.280)	
2022-05-10 23:29:07,043: ============================================================
2022-05-10 23:29:53,550: time cost, forward:0.1778030216470081, backward:0.10430244599773231, data cost:0.19169172417088057 
2022-05-10 23:29:53,550: ============================================================
2022-05-10 23:29:53,551: Epoch 10/38 Batch 800/7662 eta: 1 day, 4:36:07.250627	Training Loss 0.2578 (0.2878)	Training Prec@1 96.680 (96.358)	Training Prec@5 98.633 (98.332)	
2022-05-10 23:29:53,551: ============================================================
2022-05-10 23:30:40,024: time cost, forward:0.17702453208049226, backward:0.10430465842513274, data cost:0.19143207903300827 
2022-05-10 23:30:40,024: ============================================================
2022-05-10 23:30:40,024: Epoch 10/38 Batch 900/7662 eta: 1 day, 4:34:05.945849	Training Loss 0.2615 (0.2853)	Training Prec@1 96.289 (96.448)	Training Prec@5 98.633 (98.380)	
2022-05-10 23:30:40,024: ============================================================
2022-05-10 23:31:26,533: time cost, forward:0.17641510882296482, backward:0.1043004428779518, data cost:0.19125191967289248 
2022-05-10 23:31:26,533: ============================================================
2022-05-10 23:31:26,533: Epoch 10/38 Batch 1000/7662 eta: 1 day, 4:34:37.201509	Training Loss 0.2689 (0.2828)	Training Prec@1 98.438 (96.546)	Training Prec@5 99.219 (98.428)	
2022-05-10 23:31:26,533: ============================================================
2022-05-10 23:32:13,019: time cost, forward:0.17591415262959892, backward:0.10429520407408557, data cost:0.19108915827944672 
2022-05-10 23:32:13,019: ============================================================
2022-05-10 23:32:13,019: Epoch 10/38 Batch 1100/7662 eta: 1 day, 4:32:59.202531	Training Loss 0.2500 (0.2804)	Training Prec@1 96.484 (96.627)	Training Prec@5 98.633 (98.471)	
2022-05-10 23:32:13,019: ============================================================
2022-05-10 23:32:59,545: time cost, forward:0.17549354996255678, backward:0.10429095883882473, data cost:0.1909909697748205 
2022-05-10 23:32:59,546: ============================================================
2022-05-10 23:32:59,546: Epoch 10/38 Batch 1200/7662 eta: 1 day, 4:33:43.866876	Training Loss 0.2441 (0.2781)	Training Prec@1 97.852 (96.699)	Training Prec@5 99.023 (98.501)	
2022-05-10 23:32:59,546: ============================================================
2022-05-10 23:33:46,056: time cost, forward:0.17514679430079882, backward:0.10429067993457726, data cost:0.19088373301669762 
2022-05-10 23:33:46,057: ============================================================
2022-05-10 23:33:46,057: Epoch 10/38 Batch 1300/7662 eta: 1 day, 4:32:22.476962	Training Loss 0.2586 (0.2760)	Training Prec@1 96.484 (96.767)	Training Prec@5 98.438 (98.534)	
2022-05-10 23:33:46,057: ============================================================
2022-05-10 23:34:32,535: time cost, forward:0.1748422956023581, backward:0.10429072005140347, data cost:0.19077465975599855 
2022-05-10 23:34:32,535: ============================================================
2022-05-10 23:34:32,535: Epoch 10/38 Batch 1400/7662 eta: 1 day, 4:30:23.554443	Training Loss 0.2536 (0.2740)	Training Prec@1 97.266 (96.829)	Training Prec@5 98.828 (98.570)	
2022-05-10 23:34:32,535: ============================================================
2022-05-10 23:35:19,010: time cost, forward:0.17457308381139794, backward:0.10428713829697094, data cost:0.19068694687271373 
2022-05-10 23:35:19,010: ============================================================
2022-05-10 23:35:19,010: Epoch 10/38 Batch 1500/7662 eta: 1 day, 4:29:29.549063	Training Loss 0.2500 (0.2721)	Training Prec@1 96.875 (96.889)	Training Prec@5 98.633 (98.602)	
2022-05-10 23:35:19,010: ============================================================
2022-05-10 23:36:05,478: time cost, forward:0.1743372142724949, backward:0.1042834530031778, data cost:0.1906058803210041 
2022-05-10 23:36:05,478: ============================================================
2022-05-10 23:36:05,478: Epoch 10/38 Batch 1600/7662 eta: 1 day, 4:28:28.222982	Training Loss 0.2459 (0.2704)	Training Prec@1 96.680 (96.943)	Training Prec@5 98.828 (98.632)	
2022-05-10 23:36:05,478: ============================================================
2022-05-10 23:36:52,016: time cost, forward:0.174132059713614, backward:0.10428334966415935, data cost:0.19056957212878087 
2022-05-10 23:36:52,017: ============================================================
2022-05-10 23:36:52,017: Epoch 10/38 Batch 1700/7662 eta: 1 day, 4:30:17.647494	Training Loss 0.2394 (0.2687)	Training Prec@1 97.266 (97.002)	Training Prec@5 98.047 (98.665)	
2022-05-10 23:36:52,017: ============================================================
2022-05-10 23:37:38,557: time cost, forward:0.17393739638294095, backward:0.104281036637769, data cost:0.19055397554262934 
2022-05-10 23:37:38,557: ============================================================
2022-05-10 23:37:38,557: Epoch 10/38 Batch 1800/7662 eta: 1 day, 4:29:34.107537	Training Loss 0.2412 (0.2671)	Training Prec@1 98.242 (97.059)	Training Prec@5 98.633 (98.693)	
2022-05-10 23:37:38,557: ============================================================
2022-05-10 23:38:25,088: time cost, forward:0.1737647733291618, backward:0.10427734310718635, data cost:0.19053424114048512 
2022-05-10 23:38:25,088: ============================================================
2022-05-10 23:38:25,088: Epoch 10/38 Batch 1900/7662 eta: 1 day, 4:28:27.881064	Training Loss 0.2297 (0.2654)	Training Prec@1 98.438 (97.114)	Training Prec@5 99.805 (98.723)	
2022-05-10 23:38:25,088: ============================================================
2022-05-10 23:39:11,603: time cost, forward:0.17360184000634504, backward:0.10427717604358057, data cost:0.19051370613571403 
2022-05-10 23:39:11,604: ============================================================
2022-05-10 23:39:11,604: Epoch 10/38 Batch 2000/7662 eta: 1 day, 4:27:06.860769	Training Loss 0.2448 (0.2640)	Training Prec@1 97.656 (97.159)	Training Prec@5 99.023 (98.746)	
2022-05-10 23:39:11,604: ============================================================
2022-05-10 23:39:58,117: time cost, forward:0.1734515333698158, backward:0.10427712655851193, data cost:0.19049653489002447 
2022-05-10 23:39:58,117: ============================================================
2022-05-10 23:39:58,117: Epoch 10/38 Batch 2100/7662 eta: 1 day, 4:26:15.849064	Training Loss 0.2326 (0.2626)	Training Prec@1 97.852 (97.203)	Training Prec@5 98.828 (98.767)	
2022-05-10 23:39:58,118: ============================================================
2022-05-10 23:40:44,622: time cost, forward:0.17331913310107777, backward:0.10427678894487062, data cost:0.19047317346587622 
2022-05-10 23:40:44,622: ============================================================
2022-05-10 23:40:44,622: Epoch 10/38 Batch 2200/7662 eta: 1 day, 4:25:10.415087	Training Loss 0.2410 (0.2612)	Training Prec@1 97.461 (97.244)	Training Prec@5 99.023 (98.790)	
2022-05-10 23:40:44,622: ============================================================
2022-05-10 23:41:31,139: time cost, forward:0.17320459186641898, backward:0.1042779924144637, data cost:0.19044881646868558 
2022-05-10 23:41:31,139: ============================================================
2022-05-10 23:41:31,139: Epoch 10/38 Batch 2300/7662 eta: 1 day, 4:24:50.346440	Training Loss 0.2246 (0.2598)	Training Prec@1 98.438 (97.287)	Training Prec@5 99.805 (98.813)	
2022-05-10 23:41:31,140: ============================================================
2022-05-10 23:42:17,622: time cost, forward:0.17309772406781201, backward:0.10427683112322166, data cost:0.1904168198535024 
2022-05-10 23:42:17,622: ============================================================
2022-05-10 23:42:17,622: Epoch 10/38 Batch 2400/7662 eta: 1 day, 4:22:48.962786	Training Loss 0.2415 (0.2586)	Training Prec@1 98.438 (97.325)	Training Prec@5 99.805 (98.832)	
2022-05-10 23:42:17,622: ============================================================
2022-05-10 23:43:04,178: time cost, forward:0.1730053520240799, backward:0.10427597524071273, data cost:0.1904100123859969 
2022-05-10 23:43:04,179: ============================================================
2022-05-10 23:43:04,179: Epoch 10/38 Batch 2500/7662 eta: 1 day, 4:24:44.187366	Training Loss 0.2317 (0.2573)	Training Prec@1 98.047 (97.361)	Training Prec@5 99.609 (98.853)	
2022-05-10 23:43:04,179: ============================================================
2022-05-10 23:43:50,681: time cost, forward:0.17291316558600114, backward:0.10427654867403413, data cost:0.19038892737165145 
2022-05-10 23:43:50,681: ============================================================
2022-05-10 23:43:50,682: Epoch 10/38 Batch 2600/7662 eta: 1 day, 4:21:59.455994	Training Loss 0.2228 (0.2561)	Training Prec@1 98.242 (97.397)	Training Prec@5 99.414 (98.871)	
2022-05-10 23:43:50,682: ============================================================
2022-05-10 23:44:37,170: time cost, forward:0.17281686840078575, backward:0.10427872875788867, data cost:0.19037380347476265 
2022-05-10 23:44:37,170: ============================================================
2022-05-10 23:44:37,170: Epoch 10/38 Batch 2700/7662 eta: 1 day, 4:20:42.643803	Training Loss 0.2179 (0.2550)	Training Prec@1 97.656 (97.431)	Training Prec@5 99.414 (98.887)	
2022-05-10 23:44:37,170: ============================================================
2022-05-10 23:45:23,663: time cost, forward:0.17273357358307614, backward:0.10427831981641218, data cost:0.19035800263983046 
2022-05-10 23:45:23,663: ============================================================
2022-05-10 23:45:23,663: Epoch 10/38 Batch 2800/7662 eta: 1 day, 4:20:04.774882	Training Loss 0.2214 (0.2539)	Training Prec@1 98.047 (97.462)	Training Prec@5 99.219 (98.903)	
2022-05-10 23:45:23,663: ============================================================
2022-05-10 23:46:10,159: time cost, forward:0.17266189702505405, backward:0.10427825950104107, data cost:0.19033416775680073 
2022-05-10 23:46:10,159: ============================================================
2022-05-10 23:46:10,159: Epoch 10/38 Batch 2900/7662 eta: 1 day, 4:19:25.448765	Training Loss 0.2194 (0.2528)	Training Prec@1 98.438 (97.493)	Training Prec@5 99.219 (98.918)	
2022-05-10 23:46:10,159: ============================================================
2022-05-10 23:46:56,704: time cost, forward:0.17259634483174588, backward:0.10427704649235496, data cost:0.1903320121224541 
2022-05-10 23:46:56,704: ============================================================
2022-05-10 23:46:56,705: Epoch 10/38 Batch 3000/7662 eta: 1 day, 4:20:26.881287	Training Loss 0.2256 (0.2518)	Training Prec@1 98.047 (97.520)	Training Prec@5 99.414 (98.933)	
2022-05-10 23:46:56,705: ============================================================
2022-05-10 23:47:43,212: time cost, forward:0.17252996822602135, backward:0.10427691791087591, data cost:0.19032155548076007 
2022-05-10 23:47:43,212: ============================================================
2022-05-10 23:47:43,212: Epoch 10/38 Batch 3100/7662 eta: 1 day, 4:18:17.256763	Training Loss 0.2235 (0.2508)	Training Prec@1 98.047 (97.548)	Training Prec@5 99.609 (98.947)	
2022-05-10 23:47:43,212: ============================================================
2022-05-10 23:48:29,713: time cost, forward:0.17246330339635077, backward:0.10427638894880366, data cost:0.19031056742177752 
2022-05-10 23:48:29,713: ============================================================
2022-05-10 23:48:29,713: Epoch 10/38 Batch 3200/7662 eta: 1 day, 4:17:17.656319	Training Loss 0.2067 (0.2498)	Training Prec@1 98.633 (97.574)	Training Prec@5 99.609 (98.961)	
2022-05-10 23:48:29,714: ============================================================
2022-05-10 23:49:16,209: time cost, forward:0.17240036130132153, backward:0.1042772265194618, data cost:0.19029823842645593 
2022-05-10 23:49:16,209: ============================================================
2022-05-10 23:49:16,209: Epoch 10/38 Batch 3300/7662 eta: 1 day, 4:16:18.276069	Training Loss 0.2276 (0.2489)	Training Prec@1 98.047 (97.600)	Training Prec@5 99.414 (98.975)	
2022-05-10 23:49:16,209: ============================================================
2022-05-10 23:50:02,729: time cost, forward:0.17234385949999279, backward:0.1042770271127313, data cost:0.19029190064037713 
2022-05-10 23:50:02,729: ============================================================
2022-05-10 23:50:02,729: Epoch 10/38 Batch 3400/7662 eta: 1 day, 4:16:25.453342	Training Loss 0.2195 (0.2480)	Training Prec@1 99.414 (97.629)	Training Prec@5 99.609 (98.989)	
2022-05-10 23:50:02,729: ============================================================
2022-05-10 23:50:49,222: time cost, forward:0.17229153354292634, backward:0.10427753562142283, data cost:0.19027653596305139 
2022-05-10 23:50:49,222: ============================================================
2022-05-10 23:50:49,222: Epoch 10/38 Batch 3500/7662 eta: 1 day, 4:14:40.206885	Training Loss 0.2173 (0.2471)	Training Prec@1 98.047 (97.653)	Training Prec@5 99.023 (99.001)	
2022-05-10 23:50:49,222: ============================================================
2022-05-10 23:51:35,693: time cost, forward:0.17224027203599357, backward:0.10427627731740856, data cost:0.1902598953141077 
2022-05-10 23:51:35,694: ============================================================
2022-05-10 23:51:35,694: Epoch 10/38 Batch 3600/7662 eta: 1 day, 4:13:06.095476	Training Loss 0.2144 (0.2462)	Training Prec@1 98.828 (97.680)	Training Prec@5 100.000 (99.014)	
2022-05-10 23:51:35,694: ============================================================
2022-05-10 23:52:22,255: time cost, forward:0.1721970349848351, backward:0.10427710519477656, data cost:0.19026434695472522 
2022-05-10 23:52:22,256: ============================================================
2022-05-10 23:52:22,256: Epoch 10/38 Batch 3700/7662 eta: 1 day, 4:15:37.510710	Training Loss 0.2054 (0.2453)	Training Prec@1 99.805 (97.703)	Training Prec@5 99.805 (99.026)	
2022-05-10 23:52:22,256: ============================================================
2022-05-10 23:53:08,764: time cost, forward:0.17216236342188873, backward:0.10427729064899233, data cost:0.190248660145072 
2022-05-10 23:53:08,765: ============================================================
2022-05-10 23:53:08,765: Epoch 10/38 Batch 3800/7662 eta: 1 day, 4:12:55.174385	Training Loss 0.2109 (0.2445)	Training Prec@1 98.438 (97.727)	Training Prec@5 99.609 (99.038)	
2022-05-10 23:53:08,765: ============================================================
2022-05-10 23:53:55,311: time cost, forward:0.1721206766790413, backward:0.10427788466360362, data cost:0.19024893784406827 
2022-05-10 23:53:55,311: ============================================================
2022-05-10 23:53:55,311: Epoch 10/38 Batch 3900/7662 eta: 1 day, 4:13:30.119785	Training Loss 0.2145 (0.2437)	Training Prec@1 98.633 (97.751)	Training Prec@5 99.609 (99.051)	
2022-05-10 23:53:55,311: ============================================================
2022-05-10 23:54:41,872: time cost, forward:0.17208185318739125, backward:0.10427892938438849, data cost:0.1902545978200826 
2022-05-10 23:54:41,872: ============================================================
2022-05-10 23:54:41,872: Epoch 10/38 Batch 4000/7662 eta: 1 day, 4:13:15.752118	Training Loss 0.2147 (0.2429)	Training Prec@1 98.438 (97.773)	Training Prec@5 99.023 (99.062)	
2022-05-10 23:54:41,872: ============================================================
2022-05-10 23:55:28,391: time cost, forward:0.17204156076655094, backward:0.10427887703215503, data cost:0.1902544645601204 
2022-05-10 23:55:28,392: ============================================================
2022-05-10 23:55:28,392: Epoch 10/38 Batch 4100/7662 eta: 1 day, 4:10:58.892975	Training Loss 0.2166 (0.2422)	Training Prec@1 99.023 (97.794)	Training Prec@5 99.609 (99.074)	
2022-05-10 23:55:28,392: ============================================================
2022-05-10 23:56:14,886: time cost, forward:0.17200507439724402, backward:0.10427818981969206, data cost:0.19024685991182302 
2022-05-10 23:56:14,887: ============================================================
2022-05-10 23:56:14,887: Epoch 10/38 Batch 4200/7662 eta: 1 day, 4:09:18.794884	Training Loss 0.2124 (0.2414)	Training Prec@1 98.438 (97.814)	Training Prec@5 99.414 (99.085)	
2022-05-10 23:56:14,887: ============================================================
2022-05-10 23:57:01,431: time cost, forward:0.17197243239497495, backward:0.10427879028249325, data cost:0.19024518030303722 
2022-05-10 23:57:01,432: ============================================================
2022-05-10 23:57:01,432: Epoch 10/38 Batch 4300/7662 eta: 1 day, 4:10:20.862690	Training Loss 0.2113 (0.2407)	Training Prec@1 98.633 (97.835)	Training Prec@5 99.609 (99.095)	
2022-05-10 23:57:01,432: ============================================================
2022-05-10 23:57:47,993: time cost, forward:0.17194890618242983, backward:0.10427890839590813, data cost:0.19024267183647667 
2022-05-10 23:57:47,993: ============================================================
2022-05-10 23:57:47,994: Epoch 10/38 Batch 4400/7662 eta: 1 day, 4:10:11.317573	Training Loss 0.2133 (0.2400)	Training Prec@1 98.828 (97.855)	Training Prec@5 99.805 (99.104)	
2022-05-10 23:57:47,994: ============================================================
2022-05-10 23:58:34,533: time cost, forward:0.1719233916054357, backward:0.10427862751560758, data cost:0.19023871331724704 
2022-05-10 23:58:34,533: ============================================================
2022-05-10 23:58:34,534: Epoch 10/38 Batch 4500/7662 eta: 1 day, 4:08:36.985796	Training Loss 0.2093 (0.2393)	Training Prec@1 98.633 (97.873)	Training Prec@5 99.219 (99.114)	
2022-05-10 23:58:34,534: ============================================================
2022-05-10 23:59:21,050: time cost, forward:0.1718980304882251, backward:0.10427865522740898, data cost:0.19023077838911806 
2022-05-10 23:59:21,050: ============================================================
2022-05-10 23:59:21,050: Epoch 10/38 Batch 4600/7662 eta: 1 day, 4:07:00.079540	Training Loss 0.2085 (0.2386)	Training Prec@1 99.414 (97.891)	Training Prec@5 99.805 (99.123)	
2022-05-10 23:59:21,050: ============================================================
2022-05-11 00:00:07,549: time cost, forward:0.17187602288115655, backward:0.10427779465387364, data cost:0.19021785114643092 
2022-05-11 00:00:07,550: ============================================================
2022-05-11 00:00:07,550: Epoch 10/38 Batch 4700/7662 eta: 1 day, 4:05:35.521329	Training Loss 0.2126 (0.2380)	Training Prec@1 98.828 (97.907)	Training Prec@5 99.414 (99.131)	
2022-05-11 00:00:07,550: ============================================================
2022-05-11 00:00:54,095: time cost, forward:0.1718632416765897, backward:0.10427880252393788, data cost:0.19020538708646487 
2022-05-11 00:00:54,095: ============================================================
2022-05-11 00:00:54,095: Epoch 10/38 Batch 4800/7662 eta: 1 day, 4:06:29.050971	Training Loss 0.2059 (0.2374)	Training Prec@1 98.438 (97.925)	Training Prec@5 99.805 (99.140)	
2022-05-11 00:00:54,095: ============================================================
2022-05-11 00:01:40,588: time cost, forward:0.17183727399503293, backward:0.10427987646097844, data cost:0.1901931854675536 
2022-05-11 00:01:40,589: ============================================================
2022-05-11 00:01:40,589: Epoch 10/38 Batch 4900/7662 eta: 1 day, 4:03:50.700626	Training Loss 0.2187 (0.2367)	Training Prec@1 99.219 (97.943)	Training Prec@5 99.609 (99.149)	
2022-05-11 00:01:40,589: ============================================================
2022-05-11 00:02:27,115: time cost, forward:0.1718184027487718, backward:0.10428235248986138, data cost:0.1901834502318402 
2022-05-11 00:02:27,116: ============================================================
2022-05-11 00:02:27,116: Epoch 10/38 Batch 5000/7662 eta: 1 day, 4:04:15.943522	Training Loss 0.1990 (0.2362)	Training Prec@1 98.633 (97.959)	Training Prec@5 100.000 (99.157)	
2022-05-11 00:02:27,116: ============================================================
2022-05-11 00:03:13,624: time cost, forward:0.17179578938982631, backward:0.10428349217566164, data cost:0.1901742837363118 
2022-05-11 00:03:13,624: ============================================================
2022-05-11 00:03:13,624: Epoch 10/38 Batch 5100/7662 eta: 1 day, 4:02:49.684802	Training Loss 0.2061 (0.2356)	Training Prec@1 98.438 (97.976)	Training Prec@5 99.414 (99.165)	
2022-05-11 00:03:13,624: ============================================================
2022-05-11 00:04:00,209: time cost, forward:0.17177382623445395, backward:0.10428540838248547, data cost:0.19018334850803617 
2022-05-11 00:04:00,209: ============================================================
2022-05-11 00:04:00,209: Epoch 10/38 Batch 5200/7662 eta: 1 day, 4:04:48.032797	Training Loss 0.2113 (0.2350)	Training Prec@1 99.609 (97.990)	Training Prec@5 99.805 (99.173)	
2022-05-11 00:04:00,209: ============================================================
2022-05-11 00:04:46,751: time cost, forward:0.1717511519640656, backward:0.1042871888256631, data cost:0.1901839001265578 
2022-05-11 00:04:46,752: ============================================================
2022-05-11 00:04:46,752: Epoch 10/38 Batch 5300/7662 eta: 1 day, 4:02:31.131398	Training Loss 0.2048 (0.2345)	Training Prec@1 98.828 (98.004)	Training Prec@5 99.805 (99.181)	
2022-05-11 00:04:46,752: ============================================================
2022-05-11 00:05:33,340: time cost, forward:0.17173409590038421, backward:0.10428919967047968, data cost:0.19018796223758613 
2022-05-11 00:05:33,341: ============================================================
2022-05-11 00:05:33,341: Epoch 10/38 Batch 5400/7662 eta: 1 day, 4:03:24.324812	Training Loss 0.2028 (0.2339)	Training Prec@1 99.219 (98.019)	Training Prec@5 99.414 (99.187)	
2022-05-11 00:05:33,341: ============================================================
2022-05-11 00:06:19,966: time cost, forward:0.17172190843440985, backward:0.10429087962469506, data cost:0.19019493832981008 
2022-05-11 00:06:19,967: ============================================================
2022-05-11 00:06:19,967: Epoch 10/38 Batch 5500/7662 eta: 1 day, 4:03:58.326159	Training Loss 0.2125 (0.2334)	Training Prec@1 99.609 (98.035)	Training Prec@5 99.805 (99.194)	
2022-05-11 00:06:19,967: ============================================================
2022-05-11 00:07:06,524: time cost, forward:0.17170858711062809, backward:0.1042915319285024, data cost:0.1901916645535147 
2022-05-11 00:07:06,524: ============================================================
2022-05-11 00:07:06,524: Epoch 10/38 Batch 5600/7662 eta: 1 day, 4:00:42.156348	Training Loss 0.2061 (0.2329)	Training Prec@1 98.828 (98.049)	Training Prec@5 99.609 (99.201)	
2022-05-11 00:07:06,524: ============================================================
2022-05-11 00:07:53,119: time cost, forward:0.17169299308072686, backward:0.10429265947169558, data cost:0.19019743312260712 
2022-05-11 00:07:53,119: ============================================================
2022-05-11 00:07:53,119: Epoch 10/38 Batch 5700/7662 eta: 1 day, 4:01:17.816992	Training Loss 0.2054 (0.2324)	Training Prec@1 99.609 (98.063)	Training Prec@5 99.609 (99.207)	
2022-05-11 00:07:53,119: ============================================================
2022-05-11 00:08:39,658: time cost, forward:0.17167338520766415, backward:0.10429313265469428, data cost:0.19019783264728513 
2022-05-11 00:08:39,658: ============================================================
2022-05-11 00:08:39,659: Epoch 10/38 Batch 5800/7662 eta: 1 day, 3:58:31.035818	Training Loss 0.2130 (0.2319)	Training Prec@1 99.023 (98.077)	Training Prec@5 99.805 (99.214)	
2022-05-11 00:08:39,659: ============================================================
2022-05-11 00:09:26,198: time cost, forward:0.17165234444969527, backward:0.10429272576497155, data cost:0.19020256726979037 
2022-05-11 00:09:26,198: ============================================================
2022-05-11 00:09:26,198: Epoch 10/38 Batch 5900/7662 eta: 1 day, 3:57:45.035726	Training Loss 0.1984 (0.2314)	Training Prec@1 99.219 (98.091)	Training Prec@5 100.000 (99.220)	
2022-05-11 00:09:26,198: ============================================================
2022-05-11 00:10:12,726: time cost, forward:0.17163374674759382, backward:0.10429345510228115, data cost:0.19020200832861028 
2022-05-11 00:10:12,727: ============================================================
2022-05-11 00:10:12,727: Epoch 10/38 Batch 6000/7662 eta: 1 day, 3:56:33.919416	Training Loss 0.1991 (0.2310)	Training Prec@1 99.805 (98.104)	Training Prec@5 100.000 (99.227)	
2022-05-11 00:10:12,727: ============================================================
2022-05-11 00:10:59,311: time cost, forward:0.171618226473987, backward:0.10429417737137393, data cost:0.19020797010522766 
2022-05-11 00:10:59,311: ============================================================
2022-05-11 00:10:59,312: Epoch 10/38 Batch 6100/7662 eta: 1 day, 3:57:49.358063	Training Loss 0.1973 (0.2305)	Training Prec@1 99.219 (98.117)	Training Prec@5 99.609 (99.233)	
2022-05-11 00:10:59,312: ============================================================
2022-05-11 00:11:45,833: time cost, forward:0.17159966288660589, backward:0.10429406750681017, data cost:0.19020486043372217 
2022-05-11 00:11:45,834: ============================================================
2022-05-11 00:11:45,834: Epoch 10/38 Batch 6200/7662 eta: 1 day, 3:54:47.494220	Training Loss 0.2060 (0.2301)	Training Prec@1 98.438 (98.128)	Training Prec@5 99.219 (99.239)	
2022-05-11 00:11:45,834: ============================================================
2022-05-11 00:12:32,430: time cost, forward:0.17158241032759222, backward:0.10429400639943535, data cost:0.19021409283480695 
2022-05-11 00:12:32,430: ============================================================
2022-05-11 00:12:32,430: Epoch 10/38 Batch 6300/7662 eta: 1 day, 3:56:41.774744	Training Loss 0.2084 (0.2297)	Training Prec@1 98.633 (98.141)	Training Prec@5 99.609 (99.245)	
2022-05-11 00:12:32,431: ============================================================
2022-05-11 00:13:19,030: time cost, forward:0.17156935256055453, backward:0.10429412887550589, data cost:0.1902198280314204 
2022-05-11 00:13:19,031: ============================================================
2022-05-11 00:13:19,031: Epoch 10/38 Batch 6400/7662 eta: 1 day, 3:56:03.035579	Training Loss 0.2046 (0.2293)	Training Prec@1 99.219 (98.153)	Training Prec@5 99.805 (99.250)	
2022-05-11 00:13:19,031: ============================================================
2022-05-11 00:14:05,618: time cost, forward:0.17155518002061776, backward:0.10429392632823263, data cost:0.19022756936935703 
2022-05-11 00:14:05,618: ============================================================
2022-05-11 00:14:05,619: Epoch 10/38 Batch 6500/7662 eta: 1 day, 3:54:49.463519	Training Loss 0.2113 (0.2289)	Training Prec@1 98.828 (98.164)	Training Prec@5 99.414 (99.256)	
2022-05-11 00:14:05,619: ============================================================
2022-05-11 00:14:52,258: time cost, forward:0.1715402356746215, backward:0.10429415819879409, data cost:0.19024197981924446 
2022-05-11 00:14:52,259: ============================================================
2022-05-11 00:14:52,259: Epoch 10/38 Batch 6600/7662 eta: 1 day, 3:55:55.581494	Training Loss 0.2037 (0.2285)	Training Prec@1 99.023 (98.174)	Training Prec@5 100.000 (99.262)	
2022-05-11 00:14:52,259: ============================================================
2022-05-11 00:15:38,907: time cost, forward:0.17152266083128115, backward:0.10429478086701328, data cost:0.19025833102407197 
2022-05-11 00:15:38,908: ============================================================
2022-05-11 00:15:38,908: Epoch 10/38 Batch 6700/7662 eta: 1 day, 3:55:28.617486	Training Loss 0.1905 (0.2281)	Training Prec@1 99.219 (98.186)	Training Prec@5 99.609 (99.268)	
2022-05-11 00:15:38,908: ============================================================
2022-05-11 00:16:25,545: time cost, forward:0.17151771389152884, backward:0.10429456013408649, data cost:0.1902643916431219 
2022-05-11 00:16:25,545: ============================================================
2022-05-11 00:16:25,545: Epoch 10/38 Batch 6800/7662 eta: 1 day, 3:54:16.289670	Training Loss 0.2100 (0.2277)	Training Prec@1 98.633 (98.197)	Training Prec@5 99.414 (99.273)	
2022-05-11 00:16:25,545: ============================================================
2022-05-11 00:17:12,197: time cost, forward:0.17150692715819701, backward:0.10429471153196243, data cost:0.19027802307962732 
2022-05-11 00:17:12,198: ============================================================
2022-05-11 00:17:12,198: Epoch 10/38 Batch 6900/7662 eta: 1 day, 3:54:02.599348	Training Loss 0.2013 (0.2273)	Training Prec@1 98.828 (98.208)	Training Prec@5 99.805 (99.278)	
2022-05-11 00:17:12,198: ============================================================
2022-05-11 00:17:58,798: time cost, forward:0.1714980101854499, backward:0.10429410846561411, data cost:0.19028122054796454 
2022-05-11 00:17:58,798: ============================================================
2022-05-11 00:17:58,798: Epoch 10/38 Batch 7000/7662 eta: 1 day, 3:51:23.823052	Training Loss 0.2128 (0.2270)	Training Prec@1 98.828 (98.217)	Training Prec@5 99.609 (99.283)	
2022-05-11 00:17:58,798: ============================================================
2022-05-11 00:18:45,413: time cost, forward:0.1714905940540946, backward:0.10429260864746807, data cost:0.19028574517955746 
2022-05-11 00:18:45,413: ============================================================
2022-05-11 00:18:45,413: Epoch 10/38 Batch 7100/7662 eta: 1 day, 3:51:07.437303	Training Loss 0.2100 (0.2266)	Training Prec@1 99.219 (98.225)	Training Prec@5 99.609 (99.287)	
2022-05-11 00:18:45,413: ============================================================
2022-05-11 00:19:32,012: time cost, forward:0.1714827645767197, backward:0.10429065696794733, data cost:0.19029096812568683 
2022-05-11 00:19:32,012: ============================================================
2022-05-11 00:19:32,012: Epoch 10/38 Batch 7200/7662 eta: 1 day, 3:49:48.215907	Training Loss 0.1937 (0.2263)	Training Prec@1 99.805 (98.235)	Training Prec@5 100.000 (99.292)	
2022-05-11 00:19:32,012: ============================================================
2022-05-11 00:20:18,724: time cost, forward:0.17148079567044414, backward:0.10429066059474733, data cost:0.19030389447361823 
2022-05-11 00:20:18,724: ============================================================
2022-05-11 00:20:18,724: Epoch 10/38 Batch 7300/7662 eta: 1 day, 3:53:03.094970	Training Loss 0.2092 (0.2259)	Training Prec@1 99.609 (98.243)	Training Prec@5 100.000 (99.296)	
2022-05-11 00:20:18,724: ============================================================
2022-05-11 00:21:05,341: time cost, forward:0.17147308082931154, backward:0.10428941538243991, data cost:0.19030919189726378 
2022-05-11 00:21:05,341: ============================================================
2022-05-11 00:21:05,341: Epoch 10/38 Batch 7400/7662 eta: 1 day, 3:48:52.967839	Training Loss 0.2068 (0.2256)	Training Prec@1 99.023 (98.252)	Training Prec@5 99.414 (99.301)	
2022-05-11 00:21:05,341: ============================================================
2022-05-11 00:21:52,037: time cost, forward:0.17146961487743248, backward:0.10428833443254673, data cost:0.19032208409877216 
2022-05-11 00:21:52,037: ============================================================
2022-05-11 00:21:52,037: Epoch 10/38 Batch 7500/7662 eta: 1 day, 3:50:55.540171	Training Loss 0.1995 (0.2253)	Training Prec@1 99.414 (98.261)	Training Prec@5 100.000 (99.306)	
2022-05-11 00:21:52,037: ============================================================
2022-05-11 00:22:38,657: time cost, forward:0.17146730906148538, backward:0.10428672173192963, data cost:0.1903240843217049 
2022-05-11 00:22:38,657: ============================================================
2022-05-11 00:22:38,657: Epoch 10/38 Batch 7600/7662 eta: 1 day, 3:47:26.862463	Training Loss 0.2095 (0.2250)	Training Prec@1 98.438 (98.268)	Training Prec@5 99.023 (99.309)	
2022-05-11 00:22:38,657: ============================================================
2022-05-11 00:23:09,316: Epoch: 10/38 eta: 1 day, 3:46:57.491626	Training Loss 0.2056 (0.2248)	Training Prec@1 98.633 (98.274)	Training Prec@5 99.023 (99.312)
2022-05-11 00:23:09,316: ============================================================
2022-05-11 00:23:09,318: Save Checkpoint...
2022-05-11 00:23:09,319: ============================================================
2022-05-11 00:23:12,986: Save done!
2022-05-11 00:23:12,986: ============================================================
2022-05-11 00:24:01,237: time cost, forward:0.18243748491460626, backward:0.10397680600484212, data cost:0.19879834579698968 
2022-05-11 00:24:01,238: ============================================================
2022-05-11 00:24:01,238: Epoch 11/38 Batch 100/7662 eta: 1 day, 4:44:28.741106	Training Loss 0.1755 (0.1790)	Training Prec@1 99.609 (99.400)	Training Prec@5 100.000 (99.775)	
2022-05-11 00:24:01,238: ============================================================
2022-05-11 00:24:47,769: time cost, forward:0.17679964477692417, backward:0.10408356800750272, data cost:0.19420234641837114 
2022-05-11 00:24:47,770: ============================================================
2022-05-11 00:24:47,770: Epoch 11/38 Batch 200/7662 eta: 1 day, 3:42:14.800867	Training Loss 0.1898 (0.1792)	Training Prec@1 99.023 (99.401)	Training Prec@5 99.609 (99.800)	
2022-05-11 00:24:47,770: ============================================================
2022-05-11 00:25:34,324: time cost, forward:0.1749026049738345, backward:0.10412154548542954, data cost:0.19278365313807458 
2022-05-11 00:25:34,325: ============================================================
2022-05-11 00:25:34,325: Epoch 11/38 Batch 300/7662 eta: 1 day, 3:42:18.075334	Training Loss 0.1868 (0.1796)	Training Prec@1 99.219 (99.397)	Training Prec@5 99.414 (99.801)	
2022-05-11 00:25:34,325: ============================================================
2022-05-11 00:26:20,907: time cost, forward:0.1739722296110072, backward:0.1041535871070728, data cost:0.1920887981739857 
2022-05-11 00:26:20,908: ============================================================
2022-05-11 00:26:20,908: Epoch 11/38 Batch 400/7662 eta: 1 day, 3:42:31.665272	Training Loss 0.1871 (0.1804)	Training Prec@1 99.219 (99.376)	Training Prec@5 99.414 (99.792)	
2022-05-11 00:26:20,908: ============================================================
2022-05-11 00:27:07,492: time cost, forward:0.17340595593194447, backward:0.10416951494847605, data cost:0.19166610713951096 
2022-05-11 00:27:07,493: ============================================================
2022-05-11 00:27:07,493: Epoch 11/38 Batch 500/7662 eta: 1 day, 3:41:48.895668	Training Loss 0.1786 (0.1811)	Training Prec@1 98.828 (99.358)	Training Prec@5 99.609 (99.783)	
2022-05-11 00:27:07,493: ============================================================
2022-05-11 00:27:54,076: time cost, forward:0.1730325202113997, backward:0.10417446907056194, data cost:0.19140463201748906 
2022-05-11 00:27:54,077: ============================================================
2022-05-11 00:27:54,077: Epoch 11/38 Batch 600/7662 eta: 1 day, 3:41:00.251646	Training Loss 0.1789 (0.1816)	Training Prec@1 99.023 (99.352)	Training Prec@5 99.805 (99.783)	
2022-05-11 00:27:54,077: ============================================================
2022-05-11 00:28:40,657: time cost, forward:0.172747130046075, backward:0.10417428071236236, data cost:0.19121986090369492 
2022-05-11 00:28:40,658: ============================================================
2022-05-11 00:28:40,658: Epoch 11/38 Batch 700/7662 eta: 1 day, 3:40:07.575287	Training Loss 0.1916 (0.1821)	Training Prec@1 99.219 (99.342)	Training Prec@5 99.609 (99.776)	
2022-05-11 00:28:40,658: ============================================================
2022-05-11 00:29:27,232: time cost, forward:0.17255345512838924, backward:0.10417387124444726, data cost:0.19108201087789334 
2022-05-11 00:29:27,232: ============================================================
2022-05-11 00:29:27,232: Epoch 11/38 Batch 800/7662 eta: 1 day, 3:39:06.363409	Training Loss 0.1839 (0.1826)	Training Prec@1 99.609 (99.339)	Training Prec@5 99.805 (99.777)	
2022-05-11 00:29:27,232: ============================================================
2022-05-11 00:30:13,764: time cost, forward:0.1723933657496604, backward:0.10417490302521872, data cost:0.19093400273094985 
2022-05-11 00:30:13,764: ============================================================
2022-05-11 00:30:13,765: Epoch 11/38 Batch 900/7662 eta: 1 day, 3:36:50.752199	Training Loss 0.1921 (0.1829)	Training Prec@1 99.414 (99.339)	Training Prec@5 99.609 (99.779)	
2022-05-11 00:30:13,765: ============================================================
2022-05-11 00:31:00,376: time cost, forward:0.17226679332263478, backward:0.10417818163966273, data cost:0.190881118640766 
2022-05-11 00:31:00,376: ============================================================
2022-05-11 00:31:00,376: Epoch 11/38 Batch 1000/7662 eta: 1 day, 3:38:53.283992	Training Loss 0.1896 (0.1833)	Training Prec@1 98.633 (99.334)	Training Prec@5 99.609 (99.778)	
2022-05-11 00:31:00,376: ============================================================
2022-05-11 00:31:46,992: time cost, forward:0.17216264800227046, backward:0.10418054296061383, data cost:0.19084375093371572 
2022-05-11 00:31:46,992: ============================================================
2022-05-11 00:31:46,992: Epoch 11/38 Batch 1100/7662 eta: 1 day, 3:38:15.105315	Training Loss 0.1816 (0.1837)	Training Prec@1 99.219 (99.331)	Training Prec@5 99.609 (99.777)	
2022-05-11 00:31:46,992: ============================================================
2022-05-11 00:32:33,601: time cost, forward:0.17210796497780845, backward:0.10417878776912992, data cost:0.19078700118904018 
2022-05-11 00:32:33,602: ============================================================
2022-05-11 00:32:33,602: Epoch 11/38 Batch 1200/7662 eta: 1 day, 3:37:15.869893	Training Loss 0.1961 (0.1840)	Training Prec@1 99.023 (99.325)	Training Prec@5 99.805 (99.775)	
2022-05-11 00:32:33,602: ============================================================
2022-05-11 00:33:20,186: time cost, forward:0.1720425618254652, backward:0.10417992541935005, data cost:0.19072774614711466 
2022-05-11 00:33:20,186: ============================================================
2022-05-11 00:33:20,186: Epoch 11/38 Batch 1300/7662 eta: 1 day, 3:35:35.328399	Training Loss 0.1876 (0.1844)	Training Prec@1 98.242 (99.322)	Training Prec@5 99.609 (99.775)	
2022-05-11 00:33:20,186: ============================================================
2022-05-11 00:34:06,768: time cost, forward:0.17199242771140502, backward:0.1041807531884434, data cost:0.19067764179974134 
2022-05-11 00:34:06,768: ============================================================
2022-05-11 00:34:06,768: Epoch 11/38 Batch 1400/7662 eta: 1 day, 3:34:43.597302	Training Loss 0.1784 (0.1848)	Training Prec@1 98.828 (99.316)	Training Prec@5 100.000 (99.775)	
2022-05-11 00:34:06,768: ============================================================
2022-05-11 00:34:53,341: time cost, forward:0.1719439190335875, backward:0.10417817066795751, data cost:0.19063648197792465 
2022-05-11 00:34:53,342: ============================================================
2022-05-11 00:34:53,342: Epoch 11/38 Batch 1500/7662 eta: 1 day, 3:33:38.763148	Training Loss 0.1890 (0.1851)	Training Prec@1 99.023 (99.315)	Training Prec@5 99.414 (99.773)	
2022-05-11 00:34:53,342: ============================================================
2022-05-11 00:35:40,041: time cost, forward:0.1719021379686729, backward:0.10425340182487483, data cost:0.19060171000878465 
2022-05-11 00:35:40,041: ============================================================
2022-05-11 00:35:40,041: Epoch 11/38 Batch 1600/7662 eta: 1 day, 3:37:20.744981	Training Loss 0.2015 (0.1854)	Training Prec@1 99.414 (99.308)	Training Prec@5 100.000 (99.771)	
2022-05-11 00:35:40,041: ============================================================
2022-05-11 00:36:26,793: time cost, forward:0.17186705851428574, backward:0.10435060026226077, data cost:0.19056893321189408 
2022-05-11 00:36:26,793: ============================================================
2022-05-11 00:36:26,794: Epoch 11/38 Batch 1700/7662 eta: 1 day, 3:38:25.920813	Training Loss 0.1872 (0.1857)	Training Prec@1 99.609 (99.303)	Training Prec@5 100.000 (99.771)	
2022-05-11 00:36:26,794: ============================================================
2022-05-11 00:37:13,487: time cost, forward:0.17184034342763158, backward:0.10442316485750072, data cost:0.19051667993237006 
2022-05-11 00:37:13,487: ============================================================
2022-05-11 00:37:13,487: Epoch 11/38 Batch 1800/7662 eta: 1 day, 3:35:34.640798	Training Loss 0.1895 (0.1861)	Training Prec@1 99.414 (99.298)	Training Prec@5 99.805 (99.768)	
2022-05-11 00:37:13,487: ============================================================
2022-05-11 00:38:00,086: time cost, forward:0.17181251688088914, backward:0.10442143669248946, data cost:0.19048435327691615 
2022-05-11 00:38:00,086: ============================================================
2022-05-11 00:38:00,086: Epoch 11/38 Batch 1900/7662 eta: 1 day, 3:31:27.195171	Training Loss 0.2011 (0.1864)	Training Prec@1 98.828 (99.295)	Training Prec@5 99.805 (99.767)	
2022-05-11 00:38:00,086: ============================================================
2022-05-11 00:38:46,714: time cost, forward:0.17180870269882256, backward:0.10442027215542586, data cost:0.19044826721298272 
2022-05-11 00:38:46,714: ============================================================
2022-05-11 00:38:46,714: Epoch 11/38 Batch 2000/7662 eta: 1 day, 3:31:41.228955	Training Loss 0.1911 (0.1867)	Training Prec@1 99.414 (99.291)	Training Prec@5 100.000 (99.765)	
2022-05-11 00:38:46,714: ============================================================
2022-05-11 00:39:33,326: time cost, forward:0.1717940054943926, backward:0.10441823298730073, data cost:0.1904198900752547 
2022-05-11 00:39:33,326: ============================================================
2022-05-11 00:39:33,326: Epoch 11/38 Batch 2100/7662 eta: 1 day, 3:30:20.767717	Training Loss 0.1923 (0.1870)	Training Prec@1 99.219 (99.285)	Training Prec@5 99.414 (99.765)	
2022-05-11 00:39:33,326: ============================================================
2022-05-11 00:40:19,929: time cost, forward:0.171780460257051, backward:0.10441339032223898, data cost:0.19039942731419277 
2022-05-11 00:40:19,930: ============================================================
2022-05-11 00:40:19,930: Epoch 11/38 Batch 2200/7662 eta: 1 day, 3:29:16.980317	Training Loss 0.2053 (0.1873)	Training Prec@1 99.023 (99.282)	Training Prec@5 99.609 (99.762)	
2022-05-11 00:40:19,930: ============================================================
2022-05-11 00:41:06,547: time cost, forward:0.17176651850945537, backward:0.10441170105886438, data cost:0.1903800851316647 
2022-05-11 00:41:06,547: ============================================================
2022-05-11 00:41:06,547: Epoch 11/38 Batch 2300/7662 eta: 1 day, 3:28:59.049774	Training Loss 0.1878 (0.1875)	Training Prec@1 99.219 (99.282)	Training Prec@5 99.609 (99.764)	
2022-05-11 00:41:06,547: ============================================================
2022-05-11 00:41:53,131: time cost, forward:0.17175043439209187, backward:0.10440687757573956, data cost:0.19035620180553772 
2022-05-11 00:41:53,132: ============================================================
2022-05-11 00:41:53,132: Epoch 11/38 Batch 2400/7662 eta: 1 day, 3:27:03.598198	Training Loss 0.1912 (0.1878)	Training Prec@1 99.219 (99.278)	Training Prec@5 100.000 (99.763)	
2022-05-11 00:41:53,132: ============================================================
2022-05-11 00:42:39,734: time cost, forward:0.17174833428625966, backward:0.10439885545129918, data cost:0.19033675739506617 
2022-05-11 00:42:39,734: ============================================================
2022-05-11 00:42:39,734: Epoch 11/38 Batch 2500/7662 eta: 1 day, 3:26:54.709165	Training Loss 0.1901 (0.1880)	Training Prec@1 99.609 (99.275)	Training Prec@5 99.805 (99.761)	
2022-05-11 00:42:39,734: ============================================================
2022-05-11 00:43:26,315: time cost, forward:0.17172915919921453, backward:0.10439150862713968, data cost:0.19032795230165359 
2022-05-11 00:43:26,315: ============================================================
2022-05-11 00:43:26,315: Epoch 11/38 Batch 2600/7662 eta: 1 day, 3:25:22.088667	Training Loss 0.1964 (0.1882)	Training Prec@1 98.828 (99.270)	Training Prec@5 99.609 (99.758)	
2022-05-11 00:43:26,315: ============================================================
2022-05-11 00:44:12,888: time cost, forward:0.17170864372352354, backward:0.10438587525103789, data cost:0.1903184296776516 
2022-05-11 00:44:12,889: ============================================================
2022-05-11 00:44:12,889: Epoch 11/38 Batch 2700/7662 eta: 1 day, 3:24:19.884819	Training Loss 0.2014 (0.1884)	Training Prec@1 99.219 (99.268)	Training Prec@5 99.805 (99.758)	
2022-05-11 00:44:12,889: ============================================================
2022-05-11 00:44:59,440: time cost, forward:0.17168348940324255, backward:0.10437969183572576, data cost:0.19030035713307558 
2022-05-11 00:44:59,440: ============================================================
2022-05-11 00:44:59,440: Epoch 11/38 Batch 2800/7662 eta: 1 day, 3:22:47.023341	Training Loss 0.1995 (0.1886)	Training Prec@1 99.414 (99.262)	Training Prec@5 100.000 (99.756)	
2022-05-11 00:44:59,440: ============================================================
2022-05-11 00:45:45,973: time cost, forward:0.1716635116177125, backward:0.10437389997500064, data cost:0.19028184330845832 
2022-05-11 00:45:45,973: ============================================================
2022-05-11 00:45:45,973: Epoch 11/38 Batch 2900/7662 eta: 1 day, 3:21:21.325741	Training Loss 0.1995 (0.1889)	Training Prec@1 99.219 (99.255)	Training Prec@5 100.000 (99.753)	
2022-05-11 00:45:45,974: ============================================================
2022-05-11 00:46:32,550: time cost, forward:0.17164907395024823, backward:0.10436920874831915, data cost:0.19027052930531083 
2022-05-11 00:46:32,550: ============================================================
2022-05-11 00:46:32,550: Epoch 11/38 Batch 3000/7662 eta: 1 day, 3:22:06.702153	Training Loss 0.2022 (0.1891)	Training Prec@1 98.242 (99.252)	Training Prec@5 99.219 (99.751)	
2022-05-11 00:46:32,550: ============================================================
2022-05-11 00:47:19,147: time cost, forward:0.1716393740494892, backward:0.10436434513447784, data cost:0.19026698909216674 
2022-05-11 00:47:19,148: ============================================================
2022-05-11 00:47:19,148: Epoch 11/38 Batch 3100/7662 eta: 1 day, 3:22:04.598731	Training Loss 0.1964 (0.1893)	Training Prec@1 98.633 (99.248)	Training Prec@5 99.414 (99.749)	
2022-05-11 00:47:19,148: ============================================================
2022-05-11 00:48:05,702: time cost, forward:0.17163135596236873, backward:0.10435854669435578, data cost:0.19024946541292811 
2022-05-11 00:48:05,702: ============================================================
2022-05-11 00:48:05,702: Epoch 11/38 Batch 3200/7662 eta: 1 day, 3:19:47.019423	Training Loss 0.1957 (0.1896)	Training Prec@1 99.219 (99.243)	Training Prec@5 99.609 (99.748)	
2022-05-11 00:48:05,702: ============================================================
2022-05-11 00:48:52,302: time cost, forward:0.17162761178006544, backward:0.10435511950978224, data cost:0.19024181546641683 
2022-05-11 00:48:52,303: ============================================================
2022-05-11 00:48:52,303: Epoch 11/38 Batch 3300/7662 eta: 1 day, 3:20:37.294945	Training Loss 0.1983 (0.1898)	Training Prec@1 98.828 (99.240)	Training Prec@5 99.805 (99.747)	
2022-05-11 00:48:52,303: ============================================================
2022-05-11 00:49:38,898: time cost, forward:0.17161889327347507, backward:0.10435235595029745, data cost:0.19023776938193473 
2022-05-11 00:49:38,899: ============================================================
2022-05-11 00:49:38,899: Epoch 11/38 Batch 3400/7662 eta: 1 day, 3:19:41.786051	Training Loss 0.2038 (0.1900)	Training Prec@1 98.438 (99.235)	Training Prec@5 99.609 (99.746)	
2022-05-11 00:49:38,899: ============================================================
2022-05-11 00:50:25,571: time cost, forward:0.17160809983795594, backward:0.10438557896282918, data cost:0.19022273349571173 
2022-05-11 00:50:25,572: ============================================================
2022-05-11 00:50:25,572: Epoch 11/38 Batch 3500/7662 eta: 1 day, 3:21:37.098458	Training Loss 0.1958 (0.1902)	Training Prec@1 99.414 (99.232)	Training Prec@5 99.609 (99.744)	
2022-05-11 00:50:25,572: ============================================================
2022-05-11 00:51:12,307: time cost, forward:0.17159552639078585, backward:0.1044253176137718, data cost:0.19022040825547296 
2022-05-11 00:51:12,308: ============================================================
2022-05-11 00:51:12,308: Epoch 11/38 Batch 3600/7662 eta: 1 day, 3:23:03.963035	Training Loss 0.1919 (0.1904)	Training Prec@1 98.633 (99.228)	Training Prec@5 99.609 (99.743)	
2022-05-11 00:51:12,308: ============================================================
2022-05-11 00:51:59,046: time cost, forward:0.17158853920706868, backward:0.10446366460686214, data cost:0.19021301605985694 
2022-05-11 00:51:59,046: ============================================================
2022-05-11 00:51:59,046: Epoch 11/38 Batch 3700/7662 eta: 1 day, 3:22:21.048659	Training Loss 0.1905 (0.1906)	Training Prec@1 99.219 (99.223)	Training Prec@5 99.805 (99.742)	
2022-05-11 00:51:59,046: ============================================================
2022-05-11 00:52:45,799: time cost, forward:0.17159237444918543, backward:0.10449971754822678, data cost:0.19019966490741277 
2022-05-11 00:52:45,800: ============================================================
2022-05-11 00:52:45,800: Epoch 11/38 Batch 3800/7662 eta: 1 day, 3:22:07.318178	Training Loss 0.1858 (0.1908)	Training Prec@1 99.219 (99.217)	Training Prec@5 99.805 (99.740)	
2022-05-11 00:52:45,800: ============================================================
2022-05-11 00:53:32,581: time cost, forward:0.17159784148980117, backward:0.10453455568613472, data cost:0.1901915309428557 
2022-05-11 00:53:32,581: ============================================================
2022-05-11 00:53:32,581: Epoch 11/38 Batch 3900/7662 eta: 1 day, 3:22:19.608883	Training Loss 0.1968 (0.1910)	Training Prec@1 99.609 (99.214)	Training Prec@5 100.000 (99.739)	
2022-05-11 00:53:32,582: ============================================================
2022-05-11 00:54:19,376: time cost, forward:0.1716019889657931, backward:0.10456740787608172, data cost:0.1901890730732648 
2022-05-11 00:54:19,376: ============================================================
2022-05-11 00:54:19,377: Epoch 11/38 Batch 4000/7662 eta: 1 day, 3:22:01.199913	Training Loss 0.1994 (0.1911)	Training Prec@1 98.828 (99.211)	Training Prec@5 99.219 (99.738)	
2022-05-11 00:54:19,377: ============================================================
2022-05-11 00:55:06,156: time cost, forward:0.17160763301975002, backward:0.10459721893995498, data cost:0.19018229451753013 
2022-05-11 00:55:06,156: ============================================================
2022-05-11 00:55:06,156: Epoch 11/38 Batch 4100/7662 eta: 1 day, 3:20:42.060277	Training Loss 0.2081 (0.1913)	Training Prec@1 99.219 (99.209)	Training Prec@5 99.414 (99.737)	
2022-05-11 00:55:06,157: ============================================================
2022-05-11 00:55:52,894: time cost, forward:0.17160615486086878, backward:0.10462688701327115, data cost:0.19017158175797996 
2022-05-11 00:55:52,894: ============================================================
2022-05-11 00:55:52,894: Epoch 11/38 Batch 4200/7662 eta: 1 day, 3:18:27.035581	Training Loss 0.2102 (0.1914)	Training Prec@1 99.414 (99.206)	Training Prec@5 99.805 (99.735)	
2022-05-11 00:55:52,894: ============================================================
2022-05-11 00:56:39,662: time cost, forward:0.17160365320300192, backward:0.1046559939858081, data cost:0.19016838500765373 
2022-05-11 00:56:39,662: ============================================================
2022-05-11 00:56:39,663: Epoch 11/38 Batch 4300/7662 eta: 1 day, 3:18:44.258960	Training Loss 0.2018 (0.1916)	Training Prec@1 98.633 (99.203)	Training Prec@5 99.805 (99.735)	
2022-05-11 00:56:39,663: ============================================================
2022-05-11 00:57:26,385: time cost, forward:0.17159979580261134, backward:0.10468419456135064, data cost:0.19015637813142333 
2022-05-11 00:57:26,385: ============================================================
2022-05-11 00:57:26,385: Epoch 11/38 Batch 4400/7662 eta: 1 day, 3:16:21.414315	Training Loss 0.1996 (0.1918)	Training Prec@1 98.242 (99.200)	Training Prec@5 99.414 (99.734)	
2022-05-11 00:57:26,385: ============================================================
2022-05-11 00:58:13,086: time cost, forward:0.1715943682429578, backward:0.10471169878096283, data cost:0.19014146270209298 
2022-05-11 00:58:13,087: ============================================================
2022-05-11 00:58:13,087: Epoch 11/38 Batch 4500/7662 eta: 1 day, 3:14:50.929193	Training Loss 0.2089 (0.1919)	Training Prec@1 99.414 (99.197)	Training Prec@5 99.805 (99.732)	
2022-05-11 00:58:13,087: ============================================================
2022-05-11 00:58:59,760: time cost, forward:0.1715810003942136, backward:0.10473671869807566, data cost:0.19013060748927046 
2022-05-11 00:58:59,761: ============================================================
2022-05-11 00:58:59,761: Epoch 11/38 Batch 4600/7662 eta: 1 day, 3:13:05.905337	Training Loss 0.2008 (0.1921)	Training Prec@1 99.219 (99.195)	Training Prec@5 99.414 (99.731)	
2022-05-11 00:58:59,761: ============================================================
2022-05-11 00:59:46,463: time cost, forward:0.1715753095711665, backward:0.10476009377420493, data cost:0.19011961437078403 
2022-05-11 00:59:46,463: ============================================================
2022-05-11 00:59:46,463: Epoch 11/38 Batch 4700/7662 eta: 1 day, 3:13:18.798956	Training Loss 0.2013 (0.1922)	Training Prec@1 99.609 (99.191)	Training Prec@5 99.805 (99.730)	
2022-05-11 00:59:46,463: ============================================================
2022-05-11 01:00:33,163: time cost, forward:0.1715678879061598, backward:0.10478354970920481, data cost:0.19010722540298783 
2022-05-11 01:00:33,163: ============================================================
2022-05-11 01:00:33,164: Epoch 11/38 Batch 4800/7662 eta: 1 day, 3:12:27.847670	Training Loss 0.2063 (0.1924)	Training Prec@1 99.023 (99.187)	Training Prec@5 99.609 (99.729)	
2022-05-11 01:00:33,164: ============================================================
2022-05-11 01:01:19,839: time cost, forward:0.17155766453054833, backward:0.1048057962617331, data cost:0.19009402553070123 
2022-05-11 01:01:19,839: ============================================================
2022-05-11 01:01:19,839: Epoch 11/38 Batch 4900/7662 eta: 1 day, 3:10:49.326681	Training Loss 0.2100 (0.1925)	Training Prec@1 99.414 (99.183)	Training Prec@5 99.609 (99.727)	
2022-05-11 01:01:19,839: ============================================================
2022-05-11 01:02:06,535: time cost, forward:0.1715525287846418, backward:0.10482604981994934, data cost:0.19008376388984768 
2022-05-11 01:02:06,535: ============================================================
2022-05-11 01:02:06,535: Epoch 11/38 Batch 5000/7662 eta: 1 day, 3:10:45.442190	Training Loss 0.2072 (0.1927)	Training Prec@1 98.242 (99.181)	Training Prec@5 99.805 (99.726)	
2022-05-11 01:02:06,535: ============================================================
2022-05-11 01:02:53,232: time cost, forward:0.1715489923077299, backward:0.10484536167779934, data cost:0.19007288631118263 
2022-05-11 01:02:53,232: ============================================================
2022-05-11 01:02:53,233: Epoch 11/38 Batch 5100/7662 eta: 1 day, 3:10:01.561928	Training Loss 0.2061 (0.1928)	Training Prec@1 99.023 (99.179)	Training Prec@5 99.609 (99.724)	
2022-05-11 01:02:53,233: ============================================================
2022-05-11 01:03:39,904: time cost, forward:0.1715406717119549, backward:0.1048646399231456, data cost:0.1900617926825604 
2022-05-11 01:03:39,904: ============================================================
2022-05-11 01:03:39,904: Epoch 11/38 Batch 5200/7662 eta: 1 day, 3:08:21.057274	Training Loss 0.2074 (0.1930)	Training Prec@1 99.023 (99.175)	Training Prec@5 99.219 (99.723)	
2022-05-11 01:03:39,904: ============================================================
2022-05-11 01:04:26,609: time cost, forward:0.1715379772287064, backward:0.10488286237038179, data cost:0.19005215467203562 
2022-05-11 01:04:26,609: ============================================================
2022-05-11 01:04:26,609: Epoch 11/38 Batch 5300/7662 eta: 1 day, 3:08:43.723145	Training Loss 0.1973 (0.1931)	Training Prec@1 98.828 (99.171)	Training Prec@5 99.609 (99.722)	
2022-05-11 01:04:26,609: ============================================================
2022-05-11 01:05:13,329: time cost, forward:0.1715354758250446, backward:0.10490067346512466, data cost:0.1900456613645573 
2022-05-11 01:05:13,330: ============================================================
2022-05-11 01:05:13,330: Epoch 11/38 Batch 5400/7662 eta: 1 day, 3:08:30.842331	Training Loss 0.2017 (0.1932)	Training Prec@1 98.047 (99.169)	Training Prec@5 99.023 (99.721)	
2022-05-11 01:05:13,330: ============================================================
2022-05-11 01:06:00,056: time cost, forward:0.17153134244553586, backward:0.10491799666548147, data cost:0.1900420657156337 
2022-05-11 01:06:00,056: ============================================================
2022-05-11 01:06:00,056: Epoch 11/38 Batch 5500/7662 eta: 1 day, 3:07:54.974147	Training Loss 0.1935 (0.1933)	Training Prec@1 99.414 (99.168)	Training Prec@5 100.000 (99.721)	
2022-05-11 01:06:00,056: ============================================================
2022-05-11 01:06:46,769: time cost, forward:0.17152513451055876, backward:0.10493505007455468, data cost:0.19003422074199552 
2022-05-11 01:06:46,769: ============================================================
2022-05-11 01:06:46,769: Epoch 11/38 Batch 5600/7662 eta: 1 day, 3:06:40.616896	Training Loss 0.1954 (0.1935)	Training Prec@1 99.414 (99.165)	Training Prec@5 100.000 (99.720)	
2022-05-11 01:06:46,769: ============================================================
2022-05-11 01:07:33,482: time cost, forward:0.171520611385982, backward:0.10495160311685359, data cost:0.19002866556736894 
2022-05-11 01:07:33,482: ============================================================
2022-05-11 01:07:33,482: Epoch 11/38 Batch 5700/7662 eta: 1 day, 3:05:54.007519	Training Loss 0.2010 (0.1936)	Training Prec@1 98.828 (99.161)	Training Prec@5 99.609 (99.719)	
2022-05-11 01:07:33,482: ============================================================
2022-05-11 01:08:20,218: time cost, forward:0.1715185694045744, backward:0.10496739133264837, data cost:0.19002530562053324 
2022-05-11 01:08:20,218: ============================================================
2022-05-11 01:08:20,218: Epoch 11/38 Batch 5800/7662 eta: 1 day, 3:05:55.921151	Training Loss 0.2035 (0.1937)	Training Prec@1 99.023 (99.158)	Training Prec@5 99.414 (99.718)	
2022-05-11 01:08:20,218: ============================================================
2022-05-11 01:09:06,940: time cost, forward:0.1715144028318476, backward:0.10498232044472817, data cost:0.19002030711797238 
2022-05-11 01:09:06,940: ============================================================
2022-05-11 01:09:06,940: Epoch 11/38 Batch 5900/7662 eta: 1 day, 3:04:38.555652	Training Loss 0.1923 (0.1939)	Training Prec@1 99.805 (99.155)	Training Prec@5 99.805 (99.717)	
2022-05-11 01:09:06,940: ============================================================
2022-05-11 01:09:53,704: time cost, forward:0.17151148972222757, backward:0.10499629832879963, data cost:0.19002366375974822 
2022-05-11 01:09:53,704: ============================================================
2022-05-11 01:09:53,704: Epoch 11/38 Batch 6000/7662 eta: 1 day, 3:05:20.326081	Training Loss 0.2013 (0.1940)	Training Prec@1 99.023 (99.153)	Training Prec@5 100.000 (99.716)	
2022-05-11 01:09:53,704: ============================================================
2022-05-11 01:10:40,425: time cost, forward:0.17150945576669194, backward:0.10500838049397467, data cost:0.19002046685157045 
2022-05-11 01:10:40,425: ============================================================
2022-05-11 01:10:40,425: Epoch 11/38 Batch 6100/7662 eta: 1 day, 3:03:04.270603	Training Loss 0.1953 (0.1941)	Training Prec@1 99.414 (99.150)	Training Prec@5 99.805 (99.716)	
2022-05-11 01:10:40,425: ============================================================
2022-05-11 01:11:27,171: time cost, forward:0.17150857752802912, backward:0.10502038884305208, data cost:0.19002018214848987 
2022-05-11 01:11:27,172: ============================================================
2022-05-11 01:11:27,172: Epoch 11/38 Batch 6200/7662 eta: 1 day, 3:03:10.230901	Training Loss 0.2135 (0.1942)	Training Prec@1 98.828 (99.147)	Training Prec@5 99.414 (99.714)	
2022-05-11 01:11:27,172: ============================================================
2022-05-11 01:12:13,905: time cost, forward:0.17150711532546747, backward:0.10503374302003057, data cost:0.19001648497592838 
2022-05-11 01:12:13,905: ============================================================
2022-05-11 01:12:13,905: Epoch 11/38 Batch 6300/7662 eta: 1 day, 3:01:56.532733	Training Loss 0.1962 (0.1943)	Training Prec@1 99.805 (99.144)	Training Prec@5 100.000 (99.713)	
2022-05-11 01:12:13,905: ============================================================
2022-05-11 01:13:00,642: time cost, forward:0.17150610744031003, backward:0.10504625905098477, data cost:0.19001357371703892 
2022-05-11 01:13:00,642: ============================================================
2022-05-11 01:13:00,642: Epoch 11/38 Batch 6400/7662 eta: 1 day, 3:01:16.917712	Training Loss 0.2025 (0.1944)	Training Prec@1 98.438 (99.142)	Training Prec@5 99.414 (99.713)	
2022-05-11 01:13:00,642: ============================================================
2022-05-11 01:13:47,364: time cost, forward:0.17150105515119204, backward:0.10505693276894425, data cost:0.1900141380038293 
2022-05-11 01:13:47,365: ============================================================
2022-05-11 01:13:47,365: Epoch 11/38 Batch 6500/7662 eta: 1 day, 3:00:00.323103	Training Loss 0.2100 (0.1945)	Training Prec@1 99.219 (99.140)	Training Prec@5 99.414 (99.713)	
2022-05-11 01:13:47,365: ============================================================
2022-05-11 01:14:34,042: time cost, forward:0.17149682416394182, backward:0.10506795821614041, data cost:0.19000633959879315 
2022-05-11 01:14:34,043: ============================================================
2022-05-11 01:14:34,043: Epoch 11/38 Batch 6600/7662 eta: 1 day, 2:57:41.041024	Training Loss 0.2133 (0.1946)	Training Prec@1 98.438 (99.137)	Training Prec@5 99.414 (99.712)	
2022-05-11 01:14:34,043: ============================================================
2022-05-11 01:15:20,750: time cost, forward:0.1714923961569363, backward:0.10507862008068167, data cost:0.1900021207387776 
2022-05-11 01:15:20,750: ============================================================
2022-05-11 01:15:20,750: Epoch 11/38 Batch 6700/7662 eta: 1 day, 2:57:55.321547	Training Loss 0.1959 (0.1947)	Training Prec@1 99.023 (99.134)	Training Prec@5 99.414 (99.710)	
2022-05-11 01:15:20,750: ============================================================
2022-05-11 01:16:07,490: time cost, forward:0.17148868261601824, backward:0.1050900378495845, data cost:0.19000268999417577 
2022-05-11 01:16:07,490: ============================================================
2022-05-11 01:16:07,491: Epoch 11/38 Batch 6800/7662 eta: 1 day, 2:58:16.424386	Training Loss 0.2017 (0.1948)	Training Prec@1 98.633 (99.132)	Training Prec@5 99.805 (99.710)	
2022-05-11 01:16:07,491: ============================================================
2022-05-11 01:16:54,208: time cost, forward:0.17148770634930002, backward:0.10510023505225667, data cost:0.18999844524269088 
2022-05-11 01:16:54,208: ============================================================
2022-05-11 01:16:54,208: Epoch 11/38 Batch 6900/7662 eta: 1 day, 2:56:43.810951	Training Loss 0.1999 (0.1949)	Training Prec@1 99.023 (99.129)	Training Prec@5 99.414 (99.708)	
2022-05-11 01:16:54,209: ============================================================
2022-05-11 01:17:40,788: time cost, forward:0.17148907424075413, backward:0.10508850026529233, data cost:0.18999408704755238 
2022-05-11 01:17:40,788: ============================================================
2022-05-11 01:17:40,788: Epoch 11/38 Batch 7000/7662 eta: 1 day, 2:51:10.745327	Training Loss 0.2004 (0.1950)	Training Prec@1 98.828 (99.127)	Training Prec@5 99.805 (99.708)	
2022-05-11 01:17:40,789: ============================================================
2022-05-11 01:18:27,377: time cost, forward:0.1714880561842047, backward:0.10507737631394101, data cost:0.18999304387213092 
2022-05-11 01:18:27,377: ============================================================
2022-05-11 01:18:27,377: Epoch 11/38 Batch 7100/7662 eta: 1 day, 2:50:42.316475	Training Loss 0.2111 (0.1951)	Training Prec@1 99.023 (99.125)	Training Prec@5 99.609 (99.708)	
2022-05-11 01:18:27,377: ============================================================
2022-05-11 01:19:13,946: time cost, forward:0.17148617234954008, backward:0.1050667620678878, data cost:0.18998842422192852 
2022-05-11 01:19:13,946: ============================================================
2022-05-11 01:19:13,946: Epoch 11/38 Batch 7200/7662 eta: 1 day, 2:49:14.994439	Training Loss 0.2095 (0.1952)	Training Prec@1 99.023 (99.124)	Training Prec@5 99.609 (99.706)	
2022-05-11 01:19:13,946: ============================================================
2022-05-11 01:20:00,531: time cost, forward:0.1714867216738173, backward:0.10505634553629432, data cost:0.18998543333233114 
2022-05-11 01:20:00,531: ============================================================
2022-05-11 01:20:00,532: Epoch 11/38 Batch 7300/7662 eta: 1 day, 2:49:01.947957	Training Loss 0.1944 (0.1953)	Training Prec@1 99.219 (99.122)	Training Prec@5 99.609 (99.706)	
2022-05-11 01:20:00,532: ============================================================
2022-05-11 01:20:47,138: time cost, forward:0.171486216375096, backward:0.10504590947815882, data cost:0.189986912362204 
2022-05-11 01:20:47,138: ============================================================
2022-05-11 01:20:47,138: Epoch 11/38 Batch 7400/7662 eta: 1 day, 2:48:59.172873	Training Loss 0.1917 (0.1954)	Training Prec@1 99.414 (99.120)	Training Prec@5 99.805 (99.705)	
2022-05-11 01:20:47,138: ============================================================
2022-05-11 01:21:33,745: time cost, forward:0.17148717938621674, backward:0.1050354328643864, data cost:0.1899871628099099 
2022-05-11 01:21:33,745: ============================================================
2022-05-11 01:21:33,745: Epoch 11/38 Batch 7500/7662 eta: 1 day, 2:48:13.565513	Training Loss 0.2026 (0.1955)	Training Prec@1 99.414 (99.117)	Training Prec@5 99.805 (99.704)	
2022-05-11 01:21:33,745: ============================================================
2022-05-11 01:22:20,325: time cost, forward:0.17148376424181758, backward:0.10502646056927102, data cost:0.189985730739342 
2022-05-11 01:22:20,325: ============================================================
2022-05-11 01:22:20,325: Epoch 11/38 Batch 7600/7662 eta: 1 day, 2:46:31.695520	Training Loss 0.2074 (0.1956)	Training Prec@1 98.633 (99.116)	Training Prec@5 99.609 (99.703)	
2022-05-11 01:22:20,325: ============================================================
2022-05-11 01:22:51,102: Epoch: 11/38 eta: 1 day, 2:46:02.349986	Training Loss 0.2123 (0.1957)	Training Prec@1 98.633 (99.114)	Training Prec@5 99.219 (99.703)
2022-05-11 01:22:51,102: ============================================================
2022-05-11 01:23:43,959: time cost, forward:0.19968998793399695, backward:0.10423667743952587, data cost:0.22779540341309826 
2022-05-11 01:23:43,959: ============================================================
2022-05-11 01:23:43,959: Epoch 12/38 Batch 100/7662 eta: 1 day, 6:21:29.030250	Training Loss 0.1753 (0.1791)	Training Prec@1 99.219 (99.422)	Training Prec@5 99.805 (99.828)	
2022-05-11 01:23:43,959: ============================================================
2022-05-11 01:24:32,980: time cost, forward:0.19813136718980032, backward:0.10425576972002959, data cost:0.2083516660048135 
2022-05-11 01:24:32,981: ============================================================
2022-05-11 01:24:32,981: Epoch 12/38 Batch 200/7662 eta: 1 day, 4:08:35.693873	Training Loss 0.1819 (0.1793)	Training Prec@1 99.414 (99.417)	Training Prec@5 99.609 (99.830)	
2022-05-11 01:24:32,981: ============================================================
2022-05-11 01:25:21,532: time cost, forward:0.19566782661106275, backward:0.10437394464295045, data cost:0.20217772152112878 
2022-05-11 01:25:21,532: ============================================================
2022-05-11 01:25:21,532: Epoch 12/38 Batch 300/7662 eta: 1 day, 3:51:35.432196	Training Loss 0.1828 (0.1797)	Training Prec@1 100.000 (99.421)	Training Prec@5 100.000 (99.821)	
2022-05-11 01:25:21,533: ============================================================
2022-05-11 01:26:10,020: time cost, forward:0.1941518819421754, backward:0.10446577024340331, data cost:0.19916649808859765 
2022-05-11 01:26:10,021: ============================================================
2022-05-11 01:26:10,022: Epoch 12/38 Batch 400/7662 eta: 1 day, 3:48:37.367062	Training Loss 0.1777 (0.1803)	Training Prec@1 99.414 (99.425)	Training Prec@5 100.000 (99.823)	
2022-05-11 01:26:10,022: ============================================================
2022-05-11 01:26:58,338: time cost, forward:0.1928647477067783, backward:0.10453568575138558, data cost:0.19740270230478657 
2022-05-11 01:26:58,339: ============================================================
2022-05-11 01:26:58,339: Epoch 12/38 Batch 500/7662 eta: 1 day, 3:41:55.359442	Training Loss 0.1926 (0.1812)	Training Prec@1 98.438 (99.413)	Training Prec@5 99.414 (99.812)	
2022-05-11 01:26:58,339: ============================================================
2022-05-11 01:27:46,470: time cost, forward:0.19173137612255267, backward:0.10459554135699901, data cost:0.19618172956030436 
2022-05-11 01:27:46,470: ============================================================
2022-05-11 01:27:46,470: Epoch 12/38 Batch 600/7662 eta: 1 day, 3:34:43.419832	Training Loss 0.1873 (0.1817)	Training Prec@1 99.414 (99.407)	Training Prec@5 99.805 (99.809)	
2022-05-11 01:27:46,471: ============================================================
2022-05-11 01:28:34,494: time cost, forward:0.1908307740616696, backward:0.10460545917778397, data cost:0.19526267119913823 
2022-05-11 01:28:34,494: ============================================================
2022-05-11 01:28:34,494: Epoch 12/38 Batch 700/7662 eta: 1 day, 3:30:12.939173	Training Loss 0.1854 (0.1824)	Training Prec@1 99.219 (99.388)	Training Prec@5 99.805 (99.801)	
2022-05-11 01:28:34,494: ============================================================
2022-05-11 01:29:22,115: time cost, forward:0.18961830013833744, backward:0.10463750496674538, data cost:0.19458608424409907 
2022-05-11 01:29:22,116: ============================================================
2022-05-11 01:29:22,116: Epoch 12/38 Batch 800/7662 eta: 1 day, 3:15:36.529413	Training Loss 0.1830 (0.1829)	Training Prec@1 99.805 (99.387)	Training Prec@5 99.805 (99.801)	
2022-05-11 01:29:22,116: ============================================================
2022-05-11 01:30:09,584: time cost, forward:0.18852411785698572, backward:0.1046658551467539, data cost:0.1940481508931806 
2022-05-11 01:30:09,585: ============================================================
2022-05-11 01:30:09,585: Epoch 12/38 Batch 900/7662 eta: 1 day, 3:09:34.387380	Training Loss 0.1958 (0.1834)	Training Prec@1 98.633 (99.380)	Training Prec@5 99.805 (99.798)	
2022-05-11 01:30:09,585: ============================================================
2022-05-11 01:30:56,814: time cost, forward:0.1873797055359956, backward:0.10468545857373181, data cost:0.19364245279176576 
2022-05-11 01:30:56,814: ============================================================
2022-05-11 01:30:56,814: Epoch 12/38 Batch 1000/7662 eta: 1 day, 3:00:33.365106	Training Loss 0.1749 (0.1838)	Training Prec@1 99.609 (99.378)	Training Prec@5 100.000 (99.795)	
2022-05-11 01:30:56,814: ============================================================
2022-05-11 01:31:43,967: time cost, forward:0.1863976574898634, backward:0.10469314355650634, data cost:0.19330433697132113 
2022-05-11 01:31:43,969: ============================================================
2022-05-11 01:31:43,969: Epoch 12/38 Batch 1100/7662 eta: 1 day, 2:57:12.586462	Training Loss 0.1827 (0.1843)	Training Prec@1 99.414 (99.374)	Training Prec@5 100.000 (99.791)	
2022-05-11 01:31:43,970: ============================================================
2022-05-11 01:32:31,018: time cost, forward:0.18547619492735237, backward:0.10470454567566427, data cost:0.19303525239850602 
2022-05-11 01:32:31,018: ============================================================
2022-05-11 01:32:31,018: Epoch 12/38 Batch 1200/7662 eta: 1 day, 2:52:48.312762	Training Loss 0.1906 (0.1848)	Training Prec@1 100.000 (99.366)	Training Prec@5 100.000 (99.791)	
2022-05-11 01:32:31,018: ============================================================
2022-05-11 01:33:17,942: time cost, forward:0.18459379682181154, backward:0.10471611577240296, data cost:0.19280886760209504 
2022-05-11 01:33:17,943: ============================================================
2022-05-11 01:33:17,943: Epoch 12/38 Batch 1300/7662 eta: 1 day, 2:47:45.564799	Training Loss 0.1969 (0.1853)	Training Prec@1 99.414 (99.357)	Training Prec@5 100.000 (99.785)	
2022-05-11 01:33:17,943: ============================================================
2022-05-11 01:34:04,863: time cost, forward:0.18384548985506485, backward:0.10472016337942106, data cost:0.1926057560261528 
2022-05-11 01:34:04,863: ============================================================
2022-05-11 01:34:04,863: Epoch 12/38 Batch 1400/7662 eta: 1 day, 2:46:49.417365	Training Loss 0.1947 (0.1857)	Training Prec@1 99.805 (99.349)	Training Prec@5 100.000 (99.784)	
2022-05-11 01:34:04,863: ============================================================
2022-05-11 01:34:51,781: time cost, forward:0.18319649009246522, backward:0.10473412287243213, data cost:0.19242383162922824 
2022-05-11 01:34:51,782: ============================================================
2022-05-11 01:34:51,782: Epoch 12/38 Batch 1500/7662 eta: 1 day, 2:45:59.633123	Training Loss 0.1829 (0.1862)	Training Prec@1 99.414 (99.341)	Training Prec@5 99.805 (99.783)	
2022-05-11 01:34:51,782: ============================================================
2022-05-11 01:35:38,715: time cost, forward:0.1826507293708329, backward:0.10474587068325136, data cost:0.19225426731145404 
2022-05-11 01:35:38,716: ============================================================
2022-05-11 01:35:38,716: Epoch 12/38 Batch 1600/7662 eta: 1 day, 2:45:43.316313	Training Loss 0.1964 (0.1867)	Training Prec@1 99.805 (99.338)	Training Prec@5 100.000 (99.781)	
2022-05-11 01:35:38,716: ============================================================
2022-05-11 01:36:25,647: time cost, forward:0.18216609084795615, backward:0.10474995881968066, data cost:0.19211277939278354 
2022-05-11 01:36:25,648: ============================================================
2022-05-11 01:36:25,648: Epoch 12/38 Batch 1700/7662 eta: 1 day, 2:44:53.186262	Training Loss 0.1922 (0.1871)	Training Prec@1 98.828 (99.332)	Training Prec@5 99.414 (99.780)	
2022-05-11 01:36:25,648: ============================================================
2022-05-11 01:37:12,596: time cost, forward:0.1817533900964386, backward:0.10475404491816845, data cost:0.1919767655154743 
2022-05-11 01:37:12,597: ============================================================
2022-05-11 01:37:12,597: Epoch 12/38 Batch 1800/7662 eta: 1 day, 2:44:40.740715	Training Loss 0.1829 (0.1874)	Training Prec@1 99.023 (99.327)	Training Prec@5 99.609 (99.777)	
2022-05-11 01:37:12,597: ============================================================
2022-05-11 01:37:59,555: time cost, forward:0.18137079317234514, backward:0.10475858090236477, data cost:0.19187313271171486 
2022-05-11 01:37:59,555: ============================================================
2022-05-11 01:37:59,555: Epoch 12/38 Batch 1900/7662 eta: 1 day, 2:44:12.218542	Training Loss 0.1970 (0.1878)	Training Prec@1 99.219 (99.319)	Training Prec@5 100.000 (99.774)	
2022-05-11 01:37:59,555: ============================================================
2022-05-11 01:38:46,572: time cost, forward:0.1810617341942761, backward:0.10476369497595936, data cost:0.1917730399881261 
2022-05-11 01:38:46,573: ============================================================
2022-05-11 01:38:46,573: Epoch 12/38 Batch 2000/7662 eta: 1 day, 2:45:27.935793	Training Loss 0.1980 (0.1882)	Training Prec@1 99.414 (99.309)	Training Prec@5 99.805 (99.771)	
2022-05-11 01:38:46,573: ============================================================
2022-05-11 01:39:33,548: time cost, forward:0.18077265972066572, backward:0.1047634984153177, data cost:0.19167627068347395 
2022-05-11 01:39:33,549: ============================================================
2022-05-11 01:39:33,549: Epoch 12/38 Batch 2100/7662 eta: 1 day, 2:43:14.651075	Training Loss 0.2005 (0.1885)	Training Prec@1 98.633 (99.305)	Training Prec@5 99.805 (99.770)	
2022-05-11 01:39:33,549: ============================================================
2022-05-11 01:40:20,558: time cost, forward:0.18048844526116553, backward:0.10476997214157292, data cost:0.1916189682705937 
2022-05-11 01:40:20,559: ============================================================
2022-05-11 01:40:20,559: Epoch 12/38 Batch 2200/7662 eta: 1 day, 2:43:37.396876	Training Loss 0.1967 (0.1888)	Training Prec@1 98.828 (99.300)	Training Prec@5 99.609 (99.768)	
2022-05-11 01:40:20,559: ============================================================
2022-05-11 01:41:07,522: time cost, forward:0.18023319708984695, backward:0.10477069731949204, data cost:0.1915475937427257 
2022-05-11 01:41:07,523: ============================================================
2022-05-11 01:41:07,523: Epoch 12/38 Batch 2300/7662 eta: 1 day, 2:41:17.523835	Training Loss 0.1963 (0.1891)	Training Prec@1 100.000 (99.298)	Training Prec@5 100.000 (99.768)	
2022-05-11 01:41:07,523: ============================================================
2022-05-11 01:41:54,722: time cost, forward:0.1800928815497414, backward:0.10477375189132022, data cost:0.1914845078425787 
2022-05-11 01:41:54,722: ============================================================
2022-05-11 01:41:54,722: Epoch 12/38 Batch 2400/7662 eta: 1 day, 2:48:30.227159	Training Loss 0.1984 (0.1894)	Training Prec@1 99.023 (99.293)	Training Prec@5 99.219 (99.766)	
2022-05-11 01:41:54,722: ============================================================
2022-05-11 01:42:41,839: time cost, forward:0.17992812054020826, backward:0.10477653175604348, data cost:0.19142440224991364 
2022-05-11 01:42:41,839: ============================================================
2022-05-11 01:42:41,839: Epoch 12/38 Batch 2500/7662 eta: 1 day, 2:44:55.240809	Training Loss 0.2020 (0.1897)	Training Prec@1 99.219 (99.288)	Training Prec@5 100.000 (99.764)	
2022-05-11 01:42:41,839: ============================================================
2022-05-11 01:43:29,037: time cost, forward:0.1798104977506819, backward:0.10477714788092701, data cost:0.1913725232656023 
2022-05-11 01:43:29,037: ============================================================
2022-05-11 01:43:29,037: Epoch 12/38 Batch 2600/7662 eta: 1 day, 2:46:54.054353	Training Loss 0.1954 (0.1900)	Training Prec@1 99.219 (99.284)	Training Prec@5 99.805 (99.763)	
2022-05-11 01:43:29,037: ============================================================
2022-05-11 01:44:16,204: time cost, forward:0.17969032418688125, backward:0.1047810394263082, data cost:0.19132154797924675 
2022-05-11 01:44:16,205: ============================================================
2022-05-11 01:44:16,205: Epoch 12/38 Batch 2700/7662 eta: 1 day, 2:45:04.110270	Training Loss 0.1892 (0.1902)	Training Prec@1 99.414 (99.279)	Training Prec@5 100.000 (99.762)	
2022-05-11 01:44:16,205: ============================================================
2022-05-11 01:45:03,497: time cost, forward:0.1796212767055521, backward:0.10478246224782602, data cost:0.19127036793481542 
2022-05-11 01:45:03,498: ============================================================
2022-05-11 01:45:03,498: Epoch 12/38 Batch 2800/7662 eta: 1 day, 2:48:33.922950	Training Loss 0.1932 (0.1905)	Training Prec@1 99.414 (99.275)	Training Prec@5 99.805 (99.761)	
2022-05-11 01:45:03,498: ============================================================
2022-05-11 01:45:50,770: time cost, forward:0.1795653102726063, backward:0.10478516585582616, data cost:0.19121365861343326 
2022-05-11 01:45:50,770: ============================================================
2022-05-11 01:45:50,771: Epoch 12/38 Batch 2900/7662 eta: 1 day, 2:47:03.871865	Training Loss 0.1977 (0.1907)	Training Prec@1 98.828 (99.269)	Training Prec@5 99.805 (99.760)	
2022-05-11 01:45:50,771: ============================================================
2022-05-11 01:46:38,390: time cost, forward:0.17960614258148305, backward:0.10482079563795944, data cost:0.19115023232969136 
2022-05-11 01:46:38,390: ============================================================
2022-05-11 01:46:38,391: Epoch 12/38 Batch 3000/7662 eta: 1 day, 2:58:05.307334	Training Loss 0.1975 (0.1910)	Training Prec@1 98.633 (99.261)	Training Prec@5 99.805 (99.758)	
2022-05-11 01:46:38,391: ============================================================
2022-05-11 01:47:25,932: time cost, forward:0.1796628294086487, backward:0.10480989868235457, data cost:0.1910914260751011 
2022-05-11 01:47:25,933: ============================================================
2022-05-11 01:47:25,934: Epoch 12/38 Batch 3100/7662 eta: 1 day, 2:54:40.302216	Training Loss 0.1963 (0.1912)	Training Prec@1 98.633 (99.256)	Training Prec@5 99.609 (99.757)	
2022-05-11 01:47:25,934: ============================================================
2022-05-11 01:48:12,624: time cost, forward:0.1794539277499152, backward:0.10479481595126716, data cost:0.19103705715335656 
2022-05-11 01:48:12,624: ============================================================
2022-05-11 01:48:12,625: Epoch 12/38 Batch 3200/7662 eta: 1 day, 2:24:58.398756	Training Loss 0.1971 (0.1914)	Training Prec@1 98.633 (99.252)	Training Prec@5 99.805 (99.755)	
2022-05-11 01:48:12,625: ============================================================
2022-05-11 01:48:59,151: time cost, forward:0.1792040331575429, backward:0.10478019945619323, data cost:0.19099009821146826 
2022-05-11 01:48:59,151: ============================================================
2022-05-11 01:48:59,151: Epoch 12/38 Batch 3300/7662 eta: 1 day, 2:18:36.599974	Training Loss 0.1931 (0.1916)	Training Prec@1 99.609 (99.247)	Training Prec@5 100.000 (99.753)	
2022-05-11 01:48:59,151: ============================================================
2022-05-11 01:49:45,699: time cost, forward:0.1789723256995798, backward:0.1047678222443013, data cost:0.19094809331273851 
2022-05-11 01:49:45,700: ============================================================
2022-05-11 01:49:45,700: Epoch 12/38 Batch 3400/7662 eta: 1 day, 2:18:34.810337	Training Loss 0.1981 (0.1919)	Training Prec@1 98.633 (99.242)	Training Prec@5 99.219 (99.751)	
2022-05-11 01:49:45,700: ============================================================
2022-05-11 01:50:32,234: time cost, forward:0.17874852137144515, backward:0.10475688431732448, data cost:0.19090866190803224 
2022-05-11 01:50:32,235: ============================================================
2022-05-11 01:50:32,235: Epoch 12/38 Batch 3500/7662 eta: 1 day, 2:17:20.625763	Training Loss 0.1953 (0.1921)	Training Prec@1 99.023 (99.239)	Training Prec@5 99.805 (99.749)	
2022-05-11 01:50:32,235: ============================================================
2022-05-11 01:51:18,767: time cost, forward:0.17853817054714619, backward:0.10474542691728148, data cost:0.19087097571273087 
2022-05-11 01:51:18,767: ============================================================
2022-05-11 01:51:18,768: Epoch 12/38 Batch 3600/7662 eta: 1 day, 2:16:29.173032	Training Loss 0.2006 (0.1923)	Training Prec@1 98.633 (99.233)	Training Prec@5 99.219 (99.747)	
2022-05-11 01:51:18,768: ============================================================
2022-05-11 01:52:05,353: time cost, forward:0.17835093247113792, backward:0.10473379259916472, data cost:0.1908388110101787 
2022-05-11 01:52:05,354: ============================================================
2022-05-11 01:52:05,354: Epoch 12/38 Batch 3700/7662 eta: 1 day, 2:17:31.920203	Training Loss 0.2000 (0.1925)	Training Prec@1 98.438 (99.226)	Training Prec@5 99.414 (99.745)	
2022-05-11 01:52:05,354: ============================================================
2022-05-11 01:52:51,931: time cost, forward:0.1781709074942681, backward:0.1047214010760294, data cost:0.19081050228150023 
2022-05-11 01:52:51,931: ============================================================
2022-05-11 01:52:51,932: Epoch 12/38 Batch 3800/7662 eta: 1 day, 2:16:27.691185	Training Loss 0.2100 (0.1927)	Training Prec@1 98.242 (99.222)	Training Prec@5 99.414 (99.744)	
2022-05-11 01:52:51,932: ============================================================
2022-05-11 01:53:38,523: time cost, forward:0.1780049797203884, backward:0.10471003298332643, data cost:0.19077816386197158 
2022-05-11 01:53:38,523: ============================================================
2022-05-11 01:53:38,523: Epoch 12/38 Batch 3900/7662 eta: 1 day, 2:16:09.305304	Training Loss 0.1990 (0.1929)	Training Prec@1 99.219 (99.216)	Training Prec@5 99.805 (99.741)	
2022-05-11 01:53:38,523: ============================================================
2022-05-11 01:54:25,132: time cost, forward:0.1778568341512029, backward:0.10469906560836299, data cost:0.19074556892530475 
2022-05-11 01:54:25,133: ============================================================
2022-05-11 01:54:25,133: Epoch 12/38 Batch 4000/7662 eta: 1 day, 2:15:58.850791	Training Loss 0.1898 (0.1931)	Training Prec@1 99.609 (99.210)	Training Prec@5 99.805 (99.739)	
2022-05-11 01:54:25,133: ============================================================
2022-05-11 01:55:11,753: time cost, forward:0.17771229542706413, backward:0.10468872240852455, data cost:0.19072098573785667 
2022-05-11 01:55:11,753: ============================================================
2022-05-11 01:55:11,754: Epoch 12/38 Batch 4100/7662 eta: 1 day, 2:15:35.622144	Training Loss 0.2002 (0.1932)	Training Prec@1 98.633 (99.206)	Training Prec@5 99.805 (99.737)	
2022-05-11 01:55:11,754: ============================================================
2022-05-11 01:55:58,376: time cost, forward:0.1775766288305811, backward:0.10468007207172318, data cost:0.1906922892974541 
2022-05-11 01:55:58,376: ============================================================
2022-05-11 01:55:58,376: Epoch 12/38 Batch 4200/7662 eta: 1 day, 2:14:52.062847	Training Loss 0.1955 (0.1934)	Training Prec@1 99.023 (99.200)	Training Prec@5 100.000 (99.735)	
2022-05-11 01:55:58,376: ============================================================
2022-05-11 01:56:44,917: time cost, forward:0.17742787141748903, backward:0.10467087526492225, data cost:0.19066908071694968 
2022-05-11 01:56:44,917: ============================================================
2022-05-11 01:56:44,917: Epoch 12/38 Batch 4300/7662 eta: 1 day, 2:11:21.069021	Training Loss 0.2016 (0.1935)	Training Prec@1 98.633 (99.198)	Training Prec@5 99.609 (99.735)	
2022-05-11 01:56:44,917: ============================================================
2022-05-11 01:57:31,462: time cost, forward:0.17729066295714832, backward:0.10466323079887263, data cost:0.19064177261425383 
2022-05-11 01:57:31,463: ============================================================
2022-05-11 01:57:31,463: Epoch 12/38 Batch 4400/7662 eta: 1 day, 2:10:42.606809	Training Loss 0.2037 (0.1937)	Training Prec@1 99.219 (99.196)	Training Prec@5 99.414 (99.735)	
2022-05-11 01:57:31,463: ============================================================
2022-05-11 01:58:17,988: time cost, forward:0.17715127316017262, backward:0.10465651916169834, data cost:0.1906189910569014 
2022-05-11 01:58:17,988: ============================================================
2022-05-11 01:58:17,988: Epoch 12/38 Batch 4500/7662 eta: 1 day, 2:09:15.801737	Training Loss 0.2159 (0.1938)	Training Prec@1 98.828 (99.193)	Training Prec@5 99.023 (99.733)	
2022-05-11 01:58:17,988: ============================================================
2022-05-11 01:59:04,533: time cost, forward:0.1770163938568374, backward:0.10464945941625613, data cost:0.19060151254023955 
2022-05-11 01:59:04,533: ============================================================
2022-05-11 01:59:04,534: Epoch 12/38 Batch 4600/7662 eta: 1 day, 2:09:09.936730	Training Loss 0.2105 (0.1940)	Training Prec@1 99.023 (99.189)	Training Prec@5 99.805 (99.732)	
2022-05-11 01:59:04,534: ============================================================
2022-05-11 01:59:51,067: time cost, forward:0.17688866898617253, backward:0.10464219220979946, data cost:0.19058383903901205 
2022-05-11 01:59:51,067: ============================================================
2022-05-11 01:59:51,068: Epoch 12/38 Batch 4700/7662 eta: 1 day, 2:07:59.856938	Training Loss 0.2024 (0.1942)	Training Prec@1 98.828 (99.186)	Training Prec@5 99.805 (99.730)	
2022-05-11 01:59:51,068: ============================================================
2022-05-11 02:00:37,587: time cost, forward:0.17677165046536095, backward:0.10463495601289197, data cost:0.19055861109220676 
2022-05-11 02:00:37,587: ============================================================
2022-05-11 02:00:37,587: Epoch 12/38 Batch 4800/7662 eta: 1 day, 2:06:44.403960	Training Loss 0.2126 (0.1943)	Training Prec@1 99.609 (99.182)	Training Prec@5 99.805 (99.729)	
2022-05-11 02:00:37,587: ============================================================
2022-05-11 02:01:24,158: time cost, forward:0.17666067505739347, backward:0.10462726440009207, data cost:0.19054199345478307 
2022-05-11 02:01:24,158: ============================================================
2022-05-11 02:01:24,158: Epoch 12/38 Batch 4900/7662 eta: 1 day, 2:07:41.887724	Training Loss 0.2065 (0.1945)	Training Prec@1 99.023 (99.176)	Training Prec@5 99.805 (99.728)	
2022-05-11 02:01:24,158: ============================================================
2022-05-11 02:02:10,693: time cost, forward:0.17655482600273717, backward:0.10462009928230763, data cost:0.1905223917880042 
2022-05-11 02:02:10,693: ============================================================
2022-05-11 02:02:10,693: Epoch 12/38 Batch 5000/7662 eta: 1 day, 2:05:42.927539	Training Loss 0.1983 (0.1947)	Training Prec@1 98.828 (99.173)	Training Prec@5 99.219 (99.727)	
2022-05-11 02:02:10,693: ============================================================
2022-05-11 02:02:57,253: time cost, forward:0.17645049188669626, backward:0.10461412464597455, data cost:0.19050755938447486 
2022-05-11 02:02:57,254: ============================================================
2022-05-11 02:02:57,254: Epoch 12/38 Batch 5100/7662 eta: 1 day, 2:05:47.431368	Training Loss 0.2030 (0.1948)	Training Prec@1 98.633 (99.170)	Training Prec@5 99.609 (99.726)	
2022-05-11 02:02:57,254: ============================================================
2022-05-11 02:03:43,791: time cost, forward:0.17635261436956942, backward:0.10460786540638049, data cost:0.19048789630236132 
2022-05-11 02:03:43,791: ============================================================
2022-05-11 02:03:43,792: Epoch 12/38 Batch 5200/7662 eta: 1 day, 2:04:14.757292	Training Loss 0.2086 (0.1949)	Training Prec@1 98.047 (99.165)	Training Prec@5 99.414 (99.724)	
2022-05-11 02:03:43,792: ============================================================
2022-05-11 02:04:30,412: time cost, forward:0.17625713357387296, backward:0.10460204199859165, data cost:0.19048539295041758 
2022-05-11 02:04:30,413: ============================================================
2022-05-11 02:04:30,413: Epoch 12/38 Batch 5300/7662 eta: 1 day, 2:06:17.196863	Training Loss 0.2068 (0.1950)	Training Prec@1 99.023 (99.162)	Training Prec@5 99.609 (99.723)	
2022-05-11 02:04:30,413: ============================================================
2022-05-11 02:05:17,028: time cost, forward:0.17616746663649804, backward:0.10459708884857963, data cost:0.19047891389310173 
2022-05-11 02:05:17,029: ============================================================
2022-05-11 02:05:17,029: Epoch 12/38 Batch 5400/7662 eta: 1 day, 2:05:19.344255	Training Loss 0.2063 (0.1952)	Training Prec@1 99.219 (99.158)	Training Prec@5 99.609 (99.722)	
2022-05-11 02:05:17,029: ============================================================
2022-05-11 02:06:03,692: time cost, forward:0.17608260960985606, backward:0.10459232681511663, data cost:0.19047757161055984 
2022-05-11 02:06:03,692: ============================================================
2022-05-11 02:06:03,693: Epoch 12/38 Batch 5500/7662 eta: 1 day, 2:06:09.202766	Training Loss 0.1981 (0.1953)	Training Prec@1 98.633 (99.154)	Training Prec@5 99.609 (99.720)	
2022-05-11 02:06:03,693: ============================================================
2022-05-11 02:06:50,379: time cost, forward:0.17600645012335173, backward:0.10458875247507697, data cost:0.19047593712742827 
2022-05-11 02:06:50,380: ============================================================
2022-05-11 02:06:50,380: Epoch 12/38 Batch 5600/7662 eta: 1 day, 2:06:10.088071	Training Loss 0.1999 (0.1954)	Training Prec@1 99.023 (99.150)	Training Prec@5 99.805 (99.718)	
2022-05-11 02:06:50,380: ============================================================
2022-05-11 02:07:37,107: time cost, forward:0.1759339875768289, backward:0.10458604928421794, data cost:0.19047991973012138 
2022-05-11 02:07:37,107: ============================================================
2022-05-11 02:07:37,107: Epoch 12/38 Batch 5700/7662 eta: 1 day, 2:06:43.386147	Training Loss 0.2249 (0.1956)	Training Prec@1 98.047 (99.146)	Training Prec@5 99.414 (99.717)	
2022-05-11 02:07:37,107: ============================================================
2022-05-11 02:08:23,782: time cost, forward:0.17586253651011954, backward:0.10458232682621629, data cost:0.19047508726532777 
2022-05-11 02:08:23,782: ============================================================
2022-05-11 02:08:23,782: Epoch 12/38 Batch 5800/7662 eta: 1 day, 2:04:11.623360	Training Loss 0.2026 (0.1957)	Training Prec@1 98.828 (99.143)	Training Prec@5 99.609 (99.715)	
2022-05-11 02:08:23,782: ============================================================
2022-05-11 02:09:10,480: time cost, forward:0.17579684436957824, backward:0.1045786119513763, data cost:0.19047133359571172 
2022-05-11 02:09:10,481: ============================================================
2022-05-11 02:09:10,481: Epoch 12/38 Batch 5900/7662 eta: 1 day, 2:04:12.464021	Training Loss 0.2113 (0.1958)	Training Prec@1 98.828 (99.140)	Training Prec@5 99.609 (99.714)	
2022-05-11 02:09:10,481: ============================================================
2022-05-11 02:09:57,126: time cost, forward:0.17572605691367058, backward:0.10457442827792263, data cost:0.19046851165454812 
2022-05-11 02:09:57,126: ============================================================
2022-05-11 02:09:57,126: Epoch 12/38 Batch 6000/7662 eta: 1 day, 2:01:39.010084	Training Loss 0.2085 (0.1959)	Training Prec@1 99.219 (99.137)	Training Prec@5 99.414 (99.714)	
2022-05-11 02:09:57,126: ============================================================
2022-05-11 02:10:43,807: time cost, forward:0.1756590194908551, backward:0.10457031811665543, data cost:0.19047069447922851 
2022-05-11 02:10:43,807: ============================================================
2022-05-11 02:10:43,807: Epoch 12/38 Batch 6100/7662 eta: 1 day, 2:02:04.406252	Training Loss 0.2047 (0.1960)	Training Prec@1 98.633 (99.134)	Training Prec@5 99.609 (99.712)	
2022-05-11 02:10:43,808: ============================================================
2022-05-11 02:11:30,441: time cost, forward:0.1755927329410332, backward:0.10456652628988927, data cost:0.1904646117642226 
2022-05-11 02:11:30,441: ============================================================
2022-05-11 02:11:30,441: Epoch 12/38 Batch 6200/7662 eta: 1 day, 1:59:42.456675	Training Loss 0.2031 (0.1961)	Training Prec@1 99.219 (99.130)	Training Prec@5 99.609 (99.710)	
2022-05-11 02:11:30,441: ============================================================
2022-05-11 02:12:17,120: time cost, forward:0.17552791600909418, backward:0.10456303551681913, data cost:0.1904681618392685 
2022-05-11 02:12:17,120: ============================================================
2022-05-11 02:12:17,120: Epoch 12/38 Batch 6300/7662 eta: 1 day, 2:00:26.220897	Training Loss 0.1966 (0.1962)	Training Prec@1 98.633 (99.128)	Training Prec@5 99.414 (99.709)	
2022-05-11 02:12:17,120: ============================================================
2022-05-11 02:13:03,756: time cost, forward:0.17546833956832159, backward:0.10455860728713791, data cost:0.19046247458156151 
2022-05-11 02:13:03,756: ============================================================
2022-05-11 02:13:03,756: Epoch 12/38 Batch 6400/7662 eta: 1 day, 1:58:13.378401	Training Loss 0.2057 (0.1963)	Training Prec@1 99.023 (99.124)	Training Prec@5 100.000 (99.707)	
2022-05-11 02:13:03,756: ============================================================
2022-05-11 02:13:50,460: time cost, forward:0.17540734921038784, backward:0.10455583054976457, data cost:0.1904676049686355 
2022-05-11 02:13:50,460: ============================================================
2022-05-11 02:13:50,460: Epoch 12/38 Batch 6500/7662 eta: 1 day, 1:59:43.431408	Training Loss 0.2031 (0.1964)	Training Prec@1 99.219 (99.121)	Training Prec@5 99.805 (99.706)	
2022-05-11 02:13:50,460: ============================================================
2022-05-11 02:14:37,156: time cost, forward:0.17534951705574212, backward:0.10455286569677712, data cost:0.19046823424558817 
2022-05-11 02:14:37,156: ============================================================
2022-05-11 02:14:37,156: Epoch 12/38 Batch 6600/7662 eta: 1 day, 1:58:40.475795	Training Loss 0.1985 (0.1966)	Training Prec@1 99.023 (99.117)	Training Prec@5 99.805 (99.705)	
2022-05-11 02:14:37,156: ============================================================
2022-05-11 02:15:23,839: time cost, forward:0.17529481064830188, backward:0.10454953284490676, data cost:0.19046957668287928 
2022-05-11 02:15:23,840: ============================================================
2022-05-11 02:15:23,840: Epoch 12/38 Batch 6700/7662 eta: 1 day, 1:57:28.677138	Training Loss 0.1977 (0.1966)	Training Prec@1 98.633 (99.115)	Training Prec@5 99.609 (99.705)	
2022-05-11 02:15:23,840: ============================================================
2022-05-11 02:16:10,560: time cost, forward:0.1752388929335365, backward:0.10454650075317463, data cost:0.19047718483624274 
2022-05-11 02:16:10,560: ============================================================
2022-05-11 02:16:10,560: Epoch 12/38 Batch 6800/7662 eta: 1 day, 1:57:56.224488	Training Loss 0.1977 (0.1967)	Training Prec@1 98.828 (99.112)	Training Prec@5 99.219 (99.703)	
2022-05-11 02:16:10,561: ============================================================
2022-05-11 02:16:57,262: time cost, forward:0.17518713730351615, backward:0.10454301838253456, data cost:0.1904783264798243 
2022-05-11 02:16:57,262: ============================================================
2022-05-11 02:16:57,262: Epoch 12/38 Batch 6900/7662 eta: 1 day, 1:56:32.004865	Training Loss 0.2070 (0.1968)	Training Prec@1 98.633 (99.109)	Training Prec@5 99.805 (99.703)	
2022-05-11 02:16:57,262: ============================================================
2022-05-11 02:17:43,871: time cost, forward:0.17513248950758226, backward:0.10453918883248318, data cost:0.19047430900696907 
2022-05-11 02:17:43,871: ============================================================
2022-05-11 02:17:43,872: Epoch 12/38 Batch 7000/7662 eta: 1 day, 1:52:40.569769	Training Loss 0.2061 (0.1969)	Training Prec@1 99.023 (99.105)	Training Prec@5 99.805 (99.702)	
2022-05-11 02:17:43,872: ============================================================
2022-05-11 02:18:30,533: time cost, forward:0.1750827837803109, backward:0.10453569071278436, data cost:0.1904741823379381 
2022-05-11 02:18:30,533: ============================================================
2022-05-11 02:18:30,533: Epoch 12/38 Batch 7100/7662 eta: 1 day, 1:53:38.259732	Training Loss 0.2112 (0.1970)	Training Prec@1 98.828 (99.103)	Training Prec@5 99.414 (99.701)	
2022-05-11 02:18:30,533: ============================================================
2022-05-11 02:19:17,157: time cost, forward:0.17503004392694643, backward:0.10453236111337434, data cost:0.19047302718890477 
2022-05-11 02:19:17,158: ============================================================
2022-05-11 02:19:17,158: Epoch 12/38 Batch 7200/7662 eta: 1 day, 1:51:37.740375	Training Loss 0.1956 (0.1971)	Training Prec@1 99.414 (99.102)	Training Prec@5 100.000 (99.700)	
2022-05-11 02:19:17,158: ============================================================
2022-05-11 02:20:03,839: time cost, forward:0.17498735157263282, backward:0.10452821542504945, data cost:0.19047216138279197 
2022-05-11 02:20:03,839: ============================================================
2022-05-11 02:20:03,839: Epoch 12/38 Batch 7300/7662 eta: 1 day, 1:52:44.181010	Training Loss 0.2091 (0.1972)	Training Prec@1 98.828 (99.099)	Training Prec@5 99.414 (99.699)	
2022-05-11 02:20:03,839: ============================================================
2022-05-11 02:20:50,513: time cost, forward:0.1749400140659473, backward:0.10452429486829085, data cost:0.19047549805587685 
2022-05-11 02:20:50,513: ============================================================
2022-05-11 02:20:50,513: Epoch 12/38 Batch 7400/7662 eta: 1 day, 1:51:42.800802	Training Loss 0.1961 (0.1973)	Training Prec@1 98.828 (99.096)	Training Prec@5 100.000 (99.698)	
2022-05-11 02:20:50,513: ============================================================
2022-05-11 02:21:37,155: time cost, forward:0.1748913663405548, backward:0.1045211346757652, data cost:0.1904774739084474 
2022-05-11 02:21:37,155: ============================================================
2022-05-11 02:21:37,155: Epoch 12/38 Batch 7500/7662 eta: 1 day, 1:49:53.105847	Training Loss 0.2041 (0.1974)	Training Prec@1 99.414 (99.093)	Training Prec@5 99.609 (99.697)	
2022-05-11 02:21:37,156: ============================================================
2022-05-11 02:22:23,775: time cost, forward:0.17484581525395743, backward:0.10451745362576097, data cost:0.19047503346502037 
2022-05-11 02:22:23,775: ============================================================
2022-05-11 02:22:23,775: Epoch 12/38 Batch 7600/7662 eta: 1 day, 1:48:21.754390	Training Loss 0.2007 (0.1975)	Training Prec@1 99.219 (99.091)	Training Prec@5 99.805 (99.696)	
2022-05-11 02:22:23,775: ============================================================
2022-05-11 02:22:54,443: Epoch: 12/38 eta: 1 day, 1:47:52.383869	Training Loss 0.2111 (0.1975)	Training Prec@1 98.438 (99.089)	Training Prec@5 99.805 (99.696)
2022-05-11 02:22:54,443: ============================================================
2022-05-11 02:23:44,123: time cost, forward:0.19574593775200122, backward:0.1052211005278308, data cost:0.19868521497707176 
2022-05-11 02:23:44,123: ============================================================
2022-05-11 02:23:44,123: Epoch 13/38 Batch 100/7662 eta: 1 day, 3:28:35.338522	Training Loss 0.1948 (0.1763)	Training Prec@1 99.609 (99.436)	Training Prec@5 100.000 (99.824)	
2022-05-11 02:23:44,124: ============================================================
2022-05-11 02:24:33,637: time cost, forward:0.19771446534736672, backward:0.10555805033774832, data cost:0.1939819769643659 
2022-05-11 02:24:33,637: ============================================================
2022-05-11 02:24:33,637: Epoch 13/38 Batch 200/7662 eta: 1 day, 3:22:18.859224	Training Loss 0.1715 (0.1776)	Training Prec@1 99.609 (99.449)	Training Prec@5 99.609 (99.821)	
2022-05-11 02:24:33,637: ============================================================
2022-05-11 02:25:22,499: time cost, forward:0.19634477749317386, backward:0.10545545597140207, data cost:0.19248131126863102 
2022-05-11 02:25:22,499: ============================================================
2022-05-11 02:25:22,499: Epoch 13/38 Batch 300/7662 eta: 1 day, 2:59:53.175926	Training Loss 0.1763 (0.1785)	Training Prec@1 99.023 (99.429)	Training Prec@5 100.000 (99.814)	
2022-05-11 02:25:22,499: ============================================================
2022-05-11 02:26:10,693: time cost, forward:0.19404521860873192, backward:0.10530386891281396, data cost:0.19177044423899256 
2022-05-11 02:26:10,693: ============================================================
2022-05-11 02:26:10,694: Epoch 13/38 Batch 400/7662 eta: 1 day, 2:36:56.372844	Training Loss 0.1793 (0.1795)	Training Prec@1 99.609 (99.413)	Training Prec@5 100.000 (99.807)	
2022-05-11 02:26:10,694: ============================================================
2022-05-11 02:26:58,742: time cost, forward:0.19241249585199452, backward:0.10519986926673171, data cost:0.1913254452133943 
2022-05-11 02:26:58,742: ============================================================
2022-05-11 02:26:58,743: Epoch 13/38 Batch 500/7662 eta: 1 day, 2:31:19.550198	Training Loss 0.1785 (0.1801)	Training Prec@1 99.805 (99.415)	Training Prec@5 100.000 (99.808)	
2022-05-11 02:26:58,743: ============================================================
2022-05-11 02:27:46,664: time cost, forward:0.1910959006549918, backward:0.1051239613101558, data cost:0.19105339129898505 
2022-05-11 02:27:46,666: ============================================================
2022-05-11 02:27:46,667: Epoch 13/38 Batch 600/7662 eta: 1 day, 2:26:22.414350	Training Loss 0.1900 (0.1808)	Training Prec@1 99.023 (99.405)	Training Prec@5 100.000 (99.805)	
2022-05-11 02:27:46,667: ============================================================
2022-05-11 02:28:34,618: time cost, forward:0.1902265709016115, backward:0.10507386027487563, data cost:0.1908327254102977 
2022-05-11 02:28:34,618: ============================================================
2022-05-11 02:28:34,619: Epoch 13/38 Batch 700/7662 eta: 1 day, 2:26:31.777568	Training Loss 0.1922 (0.1815)	Training Prec@1 99.023 (99.398)	Training Prec@5 99.414 (99.802)	
2022-05-11 02:28:34,619: ============================================================
2022-05-11 02:29:22,419: time cost, forward:0.18939001061889496, backward:0.10502513806721445, data cost:0.19066970518443999 
2022-05-11 02:29:22,420: ============================================================
2022-05-11 02:29:22,420: Epoch 13/38 Batch 800/7662 eta: 1 day, 2:20:44.125921	Training Loss 0.1839 (0.1821)	Training Prec@1 99.414 (99.387)	Training Prec@5 99.805 (99.801)	
2022-05-11 02:29:22,420: ============================================================
2022-05-11 02:30:10,391: time cost, forward:0.18892094290694086, backward:0.1049938506889131, data cost:0.1905344914276157 
2022-05-11 02:30:10,391: ============================================================
2022-05-11 02:30:10,392: Epoch 13/38 Batch 900/7662 eta: 1 day, 2:25:34.024183	Training Loss 0.1860 (0.1828)	Training Prec@1 99.414 (99.380)	Training Prec@5 99.609 (99.801)	
2022-05-11 02:30:10,392: ============================================================
2022-05-11 02:30:58,190: time cost, forward:0.1883905377831903, backward:0.10496026188045651, data cost:0.19042776177475998 
2022-05-11 02:30:58,190: ============================================================
2022-05-11 02:30:58,191: Epoch 13/38 Batch 1000/7662 eta: 1 day, 2:19:03.959987	Training Loss 0.1896 (0.1833)	Training Prec@1 99.219 (99.370)	Training Prec@5 99.609 (99.798)	
2022-05-11 02:30:58,191: ============================================================
2022-05-11 02:31:46,069: time cost, forward:0.18804118067053255, backward:0.10492615660718618, data cost:0.19033681728061055 
2022-05-11 02:31:46,070: ============================================================
2022-05-11 02:31:46,070: Epoch 13/38 Batch 1100/7662 eta: 1 day, 2:20:55.392743	Training Loss 0.1877 (0.1839)	Training Prec@1 99.414 (99.363)	Training Prec@5 99.805 (99.797)	
2022-05-11 02:31:46,070: ============================================================
2022-05-11 02:32:33,898: time cost, forward:0.1876686367022186, backward:0.10491661015304553, data cost:0.19028161246146233 
2022-05-11 02:32:33,899: ============================================================
2022-05-11 02:32:33,899: Epoch 13/38 Batch 1200/7662 eta: 1 day, 2:18:27.965400	Training Loss 0.1830 (0.1844)	Training Prec@1 98.828 (99.352)	Training Prec@5 99.609 (99.792)	
2022-05-11 02:32:33,900: ============================================================
2022-05-11 02:33:21,774: time cost, forward:0.18739532910465184, backward:0.104909634755335, data cost:0.19022816433366949 
2022-05-11 02:33:21,775: ============================================================
2022-05-11 02:33:21,775: Epoch 13/38 Batch 1300/7662 eta: 1 day, 2:19:12.592278	Training Loss 0.1973 (0.1849)	Training Prec@1 98.828 (99.337)	Training Prec@5 99.805 (99.788)	
2022-05-11 02:33:21,775: ============================================================
2022-05-11 02:34:09,628: time cost, forward:0.18714888475893907, backward:0.10490141467080107, data cost:0.19018048929946604 
2022-05-11 02:34:09,629: ============================================================
2022-05-11 02:34:09,629: Epoch 13/38 Batch 1400/7662 eta: 1 day, 2:17:40.681434	Training Loss 0.1935 (0.1853)	Training Prec@1 99.023 (99.332)	Training Prec@5 99.219 (99.787)	
2022-05-11 02:34:09,629: ============================================================
2022-05-11 02:34:57,414: time cost, forward:0.1869108218841349, backward:0.104887713902469, data cost:0.19012638296263468 
2022-05-11 02:34:57,414: ============================================================
2022-05-11 02:34:57,415: Epoch 13/38 Batch 1500/7662 eta: 1 day, 2:14:38.672721	Training Loss 0.1880 (0.1858)	Training Prec@1 99.609 (99.325)	Training Prec@5 100.000 (99.785)	
2022-05-11 02:34:57,415: ============================================================
2022-05-11 02:35:44,947: time cost, forward:0.18654551052763882, backward:0.10487468351491769, data cost:0.19007967754480912 
2022-05-11 02:35:44,948: ============================================================
2022-05-11 02:35:44,948: Epoch 13/38 Batch 1600/7662 eta: 1 day, 2:05:31.699645	Training Loss 0.1901 (0.1862)	Training Prec@1 99.414 (99.319)	Training Prec@5 99.805 (99.783)	
2022-05-11 02:35:44,948: ============================================================
2022-05-11 02:36:32,385: time cost, forward:0.18615636929404814, backward:0.10486626456666512, data cost:0.1900437696321071 
2022-05-11 02:36:32,386: ============================================================
2022-05-11 02:36:32,386: Epoch 13/38 Batch 1700/7662 eta: 1 day, 2:01:36.353903	Training Loss 0.1775 (0.1867)	Training Prec@1 99.609 (99.314)	Training Prec@5 99.609 (99.782)	
2022-05-11 02:36:32,386: ============================================================
2022-05-11 02:37:19,931: time cost, forward:0.18585523212532523, backward:0.10486104489698087, data cost:0.19002699507415924 
2022-05-11 02:37:19,931: ============================================================
2022-05-11 02:37:19,932: Epoch 13/38 Batch 1800/7662 eta: 1 day, 2:04:21.644223	Training Loss 0.1964 (0.1870)	Training Prec@1 99.414 (99.309)	Training Prec@5 100.000 (99.780)	
2022-05-11 02:37:19,932: ============================================================
2022-05-11 02:38:07,439: time cost, forward:0.1855858193377936, backward:0.10485399252744397, data cost:0.1899934462838075 
2022-05-11 02:38:07,440: ============================================================
2022-05-11 02:38:07,440: Epoch 13/38 Batch 1900/7662 eta: 1 day, 2:02:20.495255	Training Loss 0.2001 (0.1874)	Training Prec@1 99.219 (99.300)	Training Prec@5 99.414 (99.776)	
2022-05-11 02:38:07,440: ============================================================
2022-05-11 02:38:54,813: time cost, forward:0.185272461655976, backward:0.10484417836149673, data cost:0.1899690733008411 
2022-05-11 02:38:54,813: ============================================================
2022-05-11 02:38:54,813: Epoch 13/38 Batch 2000/7662 eta: 1 day, 1:57:06.242802	Training Loss 0.1899 (0.1877)	Training Prec@1 99.219 (99.292)	Training Prec@5 99.609 (99.773)	
2022-05-11 02:38:54,813: ============================================================
2022-05-11 02:39:42,248: time cost, forward:0.18501470417224436, backward:0.10484291929015095, data cost:0.1899431746820429 
2022-05-11 02:39:42,248: ============================================================
2022-05-11 02:39:42,248: Epoch 13/38 Batch 2100/7662 eta: 1 day, 1:58:20.269935	Training Loss 0.1935 (0.1881)	Training Prec@1 98.047 (99.284)	Training Prec@5 99.609 (99.770)	
2022-05-11 02:39:42,248: ============================================================
2022-05-11 02:40:29,679: time cost, forward:0.1847819417864152, backward:0.10483683364507337, data cost:0.18992168115127514 
2022-05-11 02:40:29,680: ============================================================
2022-05-11 02:40:29,680: Epoch 13/38 Batch 2200/7662 eta: 1 day, 1:57:26.909615	Training Loss 0.1846 (0.1884)	Training Prec@1 99.414 (99.277)	Training Prec@5 99.609 (99.769)	
2022-05-11 02:40:29,680: ============================================================
2022-05-11 02:41:17,001: time cost, forward:0.18451736117508577, backward:0.10483162648888347, data cost:0.18990357277858977 
2022-05-11 02:41:17,002: ============================================================
2022-05-11 02:41:17,002: Epoch 13/38 Batch 2300/7662 eta: 1 day, 1:53:02.915925	Training Loss 0.1950 (0.1887)	Training Prec@1 99.805 (99.269)	Training Prec@5 100.000 (99.766)	
2022-05-11 02:41:17,002: ============================================================
2022-05-11 02:42:04,351: time cost, forward:0.18428393421992006, backward:0.10482826845106258, data cost:0.18988992522884876 
2022-05-11 02:42:04,352: ============================================================
2022-05-11 02:42:04,352: Epoch 13/38 Batch 2400/7662 eta: 1 day, 1:53:10.745093	Training Loss 0.1911 (0.1891)	Training Prec@1 98.438 (99.263)	Training Prec@5 99.805 (99.763)	
2022-05-11 02:42:04,352: ============================================================
2022-05-11 02:42:51,681: time cost, forward:0.18406644693705118, backward:0.10482386752766291, data cost:0.18987388895148513 
2022-05-11 02:42:51,681: ============================================================
2022-05-11 02:42:51,682: Epoch 13/38 Batch 2500/7662 eta: 1 day, 1:51:43.632413	Training Loss 0.1897 (0.1894)	Training Prec@1 99.023 (99.258)	Training Prec@5 99.414 (99.763)	
2022-05-11 02:42:51,682: ============================================================
2022-05-11 02:43:38,883: time cost, forward:0.18381474925353464, backward:0.10482200268095573, data cost:0.18985887278314278 
2022-05-11 02:43:38,884: ============================================================
2022-05-11 02:43:38,884: Epoch 13/38 Batch 2600/7662 eta: 1 day, 1:46:46.533257	Training Loss 0.1988 (0.1896)	Training Prec@1 99.414 (99.253)	Training Prec@5 100.000 (99.761)	
2022-05-11 02:43:38,884: ============================================================
2022-05-11 02:44:25,985: time cost, forward:0.1835445671357151, backward:0.10482136926725204, data cost:0.18984399348905945 
2022-05-11 02:44:25,986: ============================================================
2022-05-11 02:44:25,986: Epoch 13/38 Batch 2700/7662 eta: 1 day, 1:42:40.731935	Training Loss 0.2015 (0.1899)	Training Prec@1 99.219 (99.250)	Training Prec@5 100.000 (99.760)	
2022-05-11 02:44:25,986: ============================================================
2022-05-11 02:45:13,067: time cost, forward:0.1832828578799058, backward:0.1048192822026031, data cost:0.18983521773245302 
2022-05-11 02:45:13,068: ============================================================
2022-05-11 02:45:13,068: Epoch 13/38 Batch 2800/7662 eta: 1 day, 1:41:16.075294	Training Loss 0.1965 (0.1901)	Training Prec@1 99.023 (99.247)	Training Prec@5 99.805 (99.758)	
2022-05-11 02:45:13,069: ============================================================
2022-05-11 02:46:00,026: time cost, forward:0.18298430161543575, backward:0.10483246714791662, data cost:0.18982371645740248 
2022-05-11 02:46:00,027: ============================================================
2022-05-11 02:46:00,027: Epoch 13/38 Batch 2900/7662 eta: 1 day, 1:36:26.002193	Training Loss 0.2041 (0.1904)	Training Prec@1 98.828 (99.240)	Training Prec@5 99.414 (99.755)	
2022-05-11 02:46:00,027: ============================================================
2022-05-11 02:46:46,963: time cost, forward:0.18268920048430348, backward:0.10485441536059098, data cost:0.1898122368831959 
2022-05-11 02:46:46,964: ============================================================
2022-05-11 02:46:46,964: Epoch 13/38 Batch 3000/7662 eta: 1 day, 1:34:56.559503	Training Loss 0.1938 (0.1907)	Training Prec@1 99.023 (99.235)	Training Prec@5 99.414 (99.752)	
2022-05-11 02:46:46,964: ============================================================
2022-05-11 02:47:33,714: time cost, forward:0.18235120553284084, backward:0.10487176964997706, data cost:0.18980693355534453 
2022-05-11 02:47:33,715: ============================================================
2022-05-11 02:47:33,715: Epoch 13/38 Batch 3100/7662 eta: 1 day, 1:28:05.555302	Training Loss 0.2013 (0.1909)	Training Prec@1 98.633 (99.228)	Training Prec@5 99.805 (99.749)	
2022-05-11 02:47:33,716: ============================================================
2022-05-11 02:48:20,436: time cost, forward:0.18203499586219227, backward:0.1048865052229466, data cost:0.1897937715631159 
2022-05-11 02:48:20,437: ============================================================
2022-05-11 02:48:20,437: Epoch 13/38 Batch 3200/7662 eta: 1 day, 1:26:19.966887	Training Loss 0.1970 (0.1911)	Training Prec@1 99.609 (99.223)	Training Prec@5 100.000 (99.748)	
2022-05-11 02:48:20,437: ============================================================
2022-05-11 02:49:07,242: time cost, forward:0.18174239858492608, backward:0.10488703229926723, data cost:0.1898153597168866 
2022-05-11 02:49:07,243: ============================================================
2022-05-11 02:49:07,243: Epoch 13/38 Batch 3300/7662 eta: 1 day, 1:28:18.954692	Training Loss 0.1968 (0.1913)	Training Prec@1 99.414 (99.216)	Training Prec@5 99.805 (99.745)	
2022-05-11 02:49:07,243: ============================================================
2022-05-11 02:49:54,010: time cost, forward:0.1814568326837282, backward:0.10489558156499725, data cost:0.18982697304784288 
2022-05-11 02:49:54,011: ============================================================
2022-05-11 02:49:54,011: Epoch 13/38 Batch 3400/7662 eta: 1 day, 1:26:18.099064	Training Loss 0.1987 (0.1915)	Training Prec@1 99.219 (99.212)	Training Prec@5 99.805 (99.744)	
2022-05-11 02:49:54,011: ============================================================
2022-05-11 02:50:40,712: time cost, forward:0.18117744767962268, backward:0.10488293994730219, data cost:0.18984344013080012 
2022-05-11 02:50:40,712: ============================================================
2022-05-11 02:50:40,713: Epoch 13/38 Batch 3500/7662 eta: 1 day, 1:23:21.243006	Training Loss 0.2126 (0.1917)	Training Prec@1 98.438 (99.209)	Training Prec@5 99.414 (99.742)	
2022-05-11 02:50:40,713: ============================================================
2022-05-11 02:51:27,447: time cost, forward:0.18092381268549243, backward:0.1048831366671228, data cost:0.18985242371957942 
2022-05-11 02:51:27,447: ============================================================
2022-05-11 02:51:27,447: Epoch 13/38 Batch 3600/7662 eta: 1 day, 1:23:38.731700	Training Loss 0.1978 (0.1919)	Training Prec@1 98.633 (99.205)	Training Prec@5 99.609 (99.741)	
2022-05-11 02:51:27,447: ============================================================
2022-05-11 02:52:14,205: time cost, forward:0.18068430442428485, backward:0.1048946388994368, data cost:0.18985542009636724 
2022-05-11 02:52:14,206: ============================================================
2022-05-11 02:52:14,206: Epoch 13/38 Batch 3700/7662 eta: 1 day, 1:23:39.799800	Training Loss 0.2038 (0.1921)	Training Prec@1 99.414 (99.199)	Training Prec@5 100.000 (99.740)	
2022-05-11 02:52:14,206: ============================================================
2022-05-11 02:53:01,102: time cost, forward:0.18046769709234395, backward:0.10492512005572258, data cost:0.18986178599209746 
2022-05-11 02:53:01,103: ============================================================
2022-05-11 02:53:01,103: Epoch 13/38 Batch 3800/7662 eta: 1 day, 1:27:22.703371	Training Loss 0.1993 (0.1923)	Training Prec@1 98.633 (99.194)	Training Prec@5 100.000 (99.739)	
2022-05-11 02:53:01,103: ============================================================
2022-05-11 02:53:47,987: time cost, forward:0.1802489949544597, backward:0.10495446699954021, data cost:0.1898735081975232 
2022-05-11 02:53:47,987: ============================================================
2022-05-11 02:53:47,988: Epoch 13/38 Batch 3900/7662 eta: 1 day, 1:26:11.745192	Training Loss 0.1935 (0.1924)	Training Prec@1 99.219 (99.190)	Training Prec@5 99.609 (99.738)	
2022-05-11 02:53:47,988: ============================================================
2022-05-11 02:54:34,796: time cost, forward:0.18003847283642124, backward:0.10497726747828086, data cost:0.18988023724786102 
2022-05-11 02:54:34,796: ============================================================
2022-05-11 02:54:34,797: Epoch 13/38 Batch 4000/7662 eta: 1 day, 1:22:57.329064	Training Loss 0.1938 (0.1926)	Training Prec@1 98.828 (99.186)	Training Prec@5 100.000 (99.736)	
2022-05-11 02:54:34,797: ============================================================
2022-05-11 02:55:21,530: time cost, forward:0.17983982248345826, backward:0.104992039932452, data cost:0.189873561419403 
2022-05-11 02:55:21,530: ============================================================
2022-05-11 02:55:21,530: Epoch 13/38 Batch 4100/7662 eta: 1 day, 1:19:43.127815	Training Loss 0.1992 (0.1927)	Training Prec@1 98.633 (99.182)	Training Prec@5 100.000 (99.735)	
2022-05-11 02:55:21,530: ============================================================
2022-05-11 02:56:08,347: time cost, forward:0.1796547048118575, backward:0.10501693867308437, data cost:0.1898718836421653 
2022-05-11 02:56:08,347: ============================================================
2022-05-11 02:56:08,347: Epoch 13/38 Batch 4200/7662 eta: 1 day, 1:21:39.296017	Training Loss 0.1997 (0.1929)	Training Prec@1 98.047 (99.179)	Training Prec@5 98.828 (99.734)	
2022-05-11 02:56:08,347: ============================================================
2022-05-11 02:56:55,119: time cost, forward:0.17946939014728525, backward:0.10504014515882316, data cost:0.18986943051492816 
2022-05-11 02:56:55,120: ============================================================
2022-05-11 02:56:55,120: Epoch 13/38 Batch 4300/7662 eta: 1 day, 1:19:25.890724	Training Loss 0.1943 (0.1930)	Training Prec@1 99.805 (99.175)	Training Prec@5 100.000 (99.733)	
2022-05-11 02:56:55,120: ============================================================
2022-05-11 02:57:41,893: time cost, forward:0.17929535417238077, backward:0.10504600686847039, data cost:0.1898784962641323 
2022-05-11 02:57:41,894: ============================================================
2022-05-11 02:57:41,894: Epoch 13/38 Batch 4400/7662 eta: 1 day, 1:18:42.163650	Training Loss 0.1933 (0.1932)	Training Prec@1 99.023 (99.169)	Training Prec@5 100.000 (99.732)	
2022-05-11 02:57:41,894: ============================================================
2022-05-11 02:58:28,705: time cost, forward:0.17913483317413975, backward:0.10506621215788092, data cost:0.1898779319005162 
2022-05-11 02:58:28,706: ============================================================
2022-05-11 02:58:28,706: Epoch 13/38 Batch 4500/7662 eta: 1 day, 1:19:08.815193	Training Loss 0.1909 (0.1934)	Training Prec@1 98.633 (99.165)	Training Prec@5 99.414 (99.730)	
2022-05-11 02:58:28,706: ============================================================
2022-05-11 02:59:15,470: time cost, forward:0.17897995810686027, backward:0.10507881835793173, data cost:0.18987528052789332 
2022-05-11 02:59:15,471: ============================================================
2022-05-11 02:59:15,471: Epoch 13/38 Batch 4600/7662 eta: 1 day, 1:16:51.226224	Training Loss 0.1942 (0.1935)	Training Prec@1 98.828 (99.161)	Training Prec@5 99.805 (99.729)	
2022-05-11 02:59:15,471: ============================================================
2022-05-11 03:00:02,166: time cost, forward:0.1788248512993013, backward:0.10508308179278555, data cost:0.18987265194342678 
2022-05-11 03:00:02,167: ============================================================
2022-05-11 03:00:02,167: Epoch 13/38 Batch 4700/7662 eta: 1 day, 1:13:49.548593	Training Loss 0.1884 (0.1936)	Training Prec@1 98.633 (99.158)	Training Prec@5 99.609 (99.729)	
2022-05-11 03:00:02,167: ============================================================
2022-05-11 03:00:48,830: time cost, forward:0.17867443407046396, backward:0.10508412717655068, data cost:0.18986789741524063 
2022-05-11 03:00:48,830: ============================================================
2022-05-11 03:00:48,830: Epoch 13/38 Batch 4800/7662 eta: 1 day, 1:11:59.389863	Training Loss 0.1970 (0.1937)	Training Prec@1 98.828 (99.156)	Training Prec@5 99.609 (99.728)	
2022-05-11 03:00:48,830: ============================================================
2022-05-11 03:01:35,518: time cost, forward:0.1785409952285558, backward:0.10508033756724083, data cost:0.18986195543635304 
2022-05-11 03:01:35,518: ============================================================
2022-05-11 03:01:35,519: Epoch 13/38 Batch 4900/7662 eta: 1 day, 1:12:01.532999	Training Loss 0.1973 (0.1938)	Training Prec@1 98.633 (99.152)	Training Prec@5 99.414 (99.726)	
2022-05-11 03:01:35,519: ============================================================
2022-05-11 03:02:22,208: time cost, forward:0.1784080678783767, backward:0.10508182883906493, data cost:0.18985670622550718 
2022-05-11 03:02:22,208: ============================================================
2022-05-11 03:02:22,208: Epoch 13/38 Batch 5000/7662 eta: 1 day, 1:11:17.620110	Training Loss 0.1851 (0.1939)	Training Prec@1 99.219 (99.149)	Training Prec@5 99.805 (99.725)	
2022-05-11 03:02:22,208: ============================================================
2022-05-11 03:03:08,864: time cost, forward:0.17827291992697722, backward:0.10508564131520359, data cost:0.18984988437584507 
2022-05-11 03:03:08,864: ============================================================
2022-05-11 03:03:08,864: Epoch 13/38 Batch 5100/7662 eta: 1 day, 1:09:25.273614	Training Loss 0.2049 (0.1940)	Training Prec@1 98.438 (99.147)	Training Prec@5 99.219 (99.724)	
2022-05-11 03:03:08,864: ============================================================
2022-05-11 03:03:55,590: time cost, forward:0.17814458707452485, backward:0.10509598665591455, data cost:0.18984517942921292 
2022-05-11 03:03:55,590: ============================================================
2022-05-11 03:03:55,590: Epoch 13/38 Batch 5200/7662 eta: 1 day, 1:10:54.103298	Training Loss 0.2042 (0.1941)	Training Prec@1 99.219 (99.144)	Training Prec@5 99.805 (99.722)	
2022-05-11 03:03:55,590: ============================================================
2022-05-11 03:04:42,351: time cost, forward:0.17802107480364626, backward:0.10511195346935219, data cost:0.1898448142854194 
2022-05-11 03:04:42,351: ============================================================
2022-05-11 03:04:42,351: Epoch 13/38 Batch 5300/7662 eta: 1 day, 1:11:15.747000	Training Loss 0.1997 (0.1942)	Training Prec@1 98.828 (99.142)	Training Prec@5 99.414 (99.721)	
2022-05-11 03:04:42,351: ============================================================
2022-05-11 03:05:29,073: time cost, forward:0.17790528089166857, backward:0.10511672556411339, data cost:0.1898445041339957 
2022-05-11 03:05:29,073: ============================================================
2022-05-11 03:05:29,073: Epoch 13/38 Batch 5400/7662 eta: 1 day, 1:09:13.752775	Training Loss 0.2119 (0.1943)	Training Prec@1 99.023 (99.138)	Training Prec@5 99.414 (99.721)	
2022-05-11 03:05:29,073: ============================================================
2022-05-11 03:06:15,854: time cost, forward:0.17778866081633207, backward:0.10513270796591812, data cost:0.18984655194508854 
2022-05-11 03:06:15,854: ============================================================
2022-05-11 03:06:15,855: Epoch 13/38 Batch 5500/7662 eta: 1 day, 1:10:21.651929	Training Loss 0.2041 (0.1944)	Training Prec@1 98.633 (99.135)	Training Prec@5 99.023 (99.719)	
2022-05-11 03:06:15,855: ============================================================
2022-05-11 03:07:02,639: time cost, forward:0.17768449612144147, backward:0.10514244877412758, data cost:0.1898484649477654 
2022-05-11 03:07:02,639: ============================================================
2022-05-11 03:07:02,639: Epoch 13/38 Batch 5600/7662 eta: 1 day, 1:09:41.323367	Training Loss 0.2137 (0.1945)	Training Prec@1 99.023 (99.132)	Training Prec@5 99.805 (99.718)	
2022-05-11 03:07:02,640: ============================================================
2022-05-11 03:07:49,376: time cost, forward:0.177574206034454, backward:0.10515700011613976, data cost:0.1898467980846854 
2022-05-11 03:07:49,377: ============================================================
2022-05-11 03:07:49,377: Epoch 13/38 Batch 5700/7662 eta: 1 day, 1:07:22.813016	Training Loss 0.1884 (0.1946)	Training Prec@1 98.633 (99.129)	Training Prec@5 99.609 (99.717)	
2022-05-11 03:07:49,377: ============================================================
2022-05-11 03:08:36,178: time cost, forward:0.17747057908813507, backward:0.10517086606947466, data cost:0.18985159044780492 
2022-05-11 03:08:36,179: ============================================================
2022-05-11 03:08:36,179: Epoch 13/38 Batch 5800/7662 eta: 1 day, 1:08:41.476986	Training Loss 0.1966 (0.1947)	Training Prec@1 99.414 (99.126)	Training Prec@5 99.805 (99.716)	
2022-05-11 03:08:36,179: ============================================================
2022-05-11 03:09:22,946: time cost, forward:0.17737446738251347, backward:0.10517659092741631, data cost:0.1898564140884366 
2022-05-11 03:09:22,946: ============================================================
2022-05-11 03:09:22,946: Epoch 13/38 Batch 5900/7662 eta: 1 day, 1:06:47.548817	Training Loss 0.1987 (0.1948)	Training Prec@1 98.633 (99.124)	Training Prec@5 99.805 (99.716)	
2022-05-11 03:09:22,946: ============================================================
2022-05-11 03:10:09,667: time cost, forward:0.17728292725447475, backward:0.10517262975301996, data cost:0.18985905900043654 
2022-05-11 03:10:09,667: ============================================================
2022-05-11 03:10:09,667: Epoch 13/38 Batch 6000/7662 eta: 1 day, 1:04:30.386447	Training Loss 0.2103 (0.1949)	Training Prec@1 98.633 (99.119)	Training Prec@5 99.219 (99.714)	
2022-05-11 03:10:09,667: ============================================================
2022-05-11 03:10:56,502: time cost, forward:0.17719613284160904, backward:0.1051850857197564, data cost:0.18986420108365473 
2022-05-11 03:10:56,502: ============================================================
2022-05-11 03:10:56,502: Epoch 13/38 Batch 6100/7662 eta: 1 day, 1:07:24.613130	Training Loss 0.2000 (0.1950)	Training Prec@1 99.023 (99.117)	Training Prec@5 99.414 (99.713)	
2022-05-11 03:10:56,502: ============================================================
2022-05-11 03:11:43,317: time cost, forward:0.1771164320422519, backward:0.10519191468410058, data cost:0.18986510838168458 
2022-05-11 03:11:43,318: ============================================================
2022-05-11 03:11:43,318: Epoch 13/38 Batch 6200/7662 eta: 1 day, 1:06:00.212738	Training Loss 0.1971 (0.1951)	Training Prec@1 98.438 (99.114)	Training Prec@5 99.219 (99.711)	
2022-05-11 03:11:43,318: ============================================================
2022-05-11 03:12:30,062: time cost, forward:0.17703643615784428, backward:0.10519715119286328, data cost:0.1898589726193857 
2022-05-11 03:12:30,062: ============================================================
2022-05-11 03:12:30,062: Epoch 13/38 Batch 6300/7662 eta: 1 day, 1:02:56.594745	Training Loss 0.1950 (0.1952)	Training Prec@1 98.633 (99.111)	Training Prec@5 99.609 (99.710)	
2022-05-11 03:12:30,063: ============================================================
2022-05-11 03:13:16,879: time cost, forward:0.17696034939964594, backward:0.10520849970844243, data cost:0.18985876338074664 
2022-05-11 03:13:16,880: ============================================================
2022-05-11 03:13:16,880: Epoch 13/38 Batch 6400/7662 eta: 1 day, 1:04:30.038478	Training Loss 0.2116 (0.1952)	Training Prec@1 99.219 (99.108)	Training Prec@5 99.805 (99.709)	
2022-05-11 03:13:16,880: ============================================================
2022-05-11 03:14:03,737: time cost, forward:0.17689143428253676, backward:0.10521946622511298, data cost:0.18985983943513657 
2022-05-11 03:14:03,738: ============================================================
2022-05-11 03:14:03,738: Epoch 13/38 Batch 6500/7662 eta: 1 day, 1:05:01.937297	Training Loss 0.2038 (0.1953)	Training Prec@1 99.023 (99.106)	Training Prec@5 100.000 (99.709)	
2022-05-11 03:14:03,738: ============================================================
2022-05-11 03:14:50,570: time cost, forward:0.17682036751598132, backward:0.10523027083172475, data cost:0.18986096257855628 
2022-05-11 03:14:50,571: ============================================================
2022-05-11 03:14:50,571: Epoch 13/38 Batch 6600/7662 eta: 1 day, 1:03:25.844598	Training Loss 0.1896 (0.1954)	Training Prec@1 99.609 (99.104)	Training Prec@5 99.805 (99.708)	
2022-05-11 03:14:50,571: ============================================================
2022-05-11 03:15:37,411: time cost, forward:0.1767575630484668, backward:0.10523175171799296, data cost:0.18986617331897027 
2022-05-11 03:15:37,412: ============================================================
2022-05-11 03:15:37,412: Epoch 13/38 Batch 6700/7662 eta: 1 day, 1:02:55.475766	Training Loss 0.2136 (0.1955)	Training Prec@1 99.219 (99.101)	Training Prec@5 99.609 (99.707)	
2022-05-11 03:15:37,412: ============================================================
2022-05-11 03:16:24,197: time cost, forward:0.17669097569641393, backward:0.10523732512606332, data cost:0.18986469052226812 
2022-05-11 03:16:24,197: ============================================================
2022-05-11 03:16:24,197: Epoch 13/38 Batch 6800/7662 eta: 1 day, 1:00:20.902525	Training Loss 0.1960 (0.1956)	Training Prec@1 98.633 (99.097)	Training Prec@5 99.414 (99.706)	
2022-05-11 03:16:24,197: ============================================================
2022-05-11 03:17:11,024: time cost, forward:0.17662745673581473, backward:0.10524307211027023, data cost:0.189867782426893 
2022-05-11 03:17:11,024: ============================================================
2022-05-11 03:17:11,025: Epoch 13/38 Batch 6900/7662 eta: 1 day, 1:00:55.084167	Training Loss 0.2039 (0.1957)	Training Prec@1 98.828 (99.093)	Training Prec@5 99.805 (99.705)	
2022-05-11 03:17:11,025: ============================================================
2022-05-11 03:17:57,856: time cost, forward:0.1765654581685563, backward:0.10524269726842211, data cost:0.18987641448309667 
2022-05-11 03:17:57,856: ============================================================
2022-05-11 03:17:57,857: Epoch 13/38 Batch 7000/7662 eta: 1 day, 1:00:16.980930	Training Loss 0.2039 (0.1957)	Training Prec@1 98.828 (99.091)	Training Prec@5 99.609 (99.703)	
2022-05-11 03:17:57,857: ============================================================
2022-05-11 03:18:44,682: time cost, forward:0.17650388784686652, backward:0.10524659409357101, data cost:0.18988224126399614 
2022-05-11 03:18:44,682: ============================================================
2022-05-11 03:18:44,682: Epoch 13/38 Batch 7100/7662 eta: 1 day, 0:59:18.328580	Training Loss 0.1867 (0.1958)	Training Prec@1 99.219 (99.090)	Training Prec@5 99.609 (99.703)	
2022-05-11 03:18:44,682: ============================================================
2022-05-11 03:19:31,456: time cost, forward:0.17643846940921404, backward:0.1052535044549157, data cost:0.18988335385953806 
2022-05-11 03:19:31,456: ============================================================
2022-05-11 03:19:31,457: Epoch 13/38 Batch 7200/7662 eta: 1 day, 0:56:52.767520	Training Loss 0.2031 (0.1958)	Training Prec@1 98.828 (99.088)	Training Prec@5 100.000 (99.702)	
2022-05-11 03:19:31,457: ============================================================
2022-05-11 03:20:18,298: time cost, forward:0.1763840163631102, backward:0.10525834597958524, data cost:0.18988498799979547 
2022-05-11 03:20:18,298: ============================================================
2022-05-11 03:20:18,298: Epoch 13/38 Batch 7300/7662 eta: 1 day, 0:58:14.794830	Training Loss 0.2006 (0.1959)	Training Prec@1 99.805 (99.085)	Training Prec@5 100.000 (99.702)	
2022-05-11 03:20:18,298: ============================================================
2022-05-11 03:21:05,183: time cost, forward:0.17633056009052606, backward:0.10526873485705936, data cost:0.1898887537350315 
2022-05-11 03:21:05,184: ============================================================
2022-05-11 03:21:05,184: Epoch 13/38 Batch 7400/7662 eta: 1 day, 0:58:53.169547	Training Loss 0.1891 (0.1960)	Training Prec@1 99.805 (99.083)	Training Prec@5 100.000 (99.701)	
2022-05-11 03:21:05,184: ============================================================
2022-05-11 03:21:52,101: time cost, forward:0.1762908609219592, backward:0.10526753511567452, data cost:0.1898928686910859 
2022-05-11 03:21:52,101: ============================================================
2022-05-11 03:21:52,101: Epoch 13/38 Batch 7500/7662 eta: 1 day, 0:59:06.405630	Training Loss 0.2046 (0.1960)	Training Prec@1 98.633 (99.079)	Training Prec@5 99.414 (99.700)	
2022-05-11 03:21:52,101: ============================================================
2022-05-11 03:22:38,897: time cost, forward:0.17623823259140037, backward:0.10526733267290025, data cost:0.1898948798635819 
2022-05-11 03:22:38,898: ============================================================
2022-05-11 03:22:38,898: Epoch 13/38 Batch 7600/7662 eta: 1 day, 0:54:28.371640	Training Loss 0.2109 (0.1961)	Training Prec@1 98.047 (99.077)	Training Prec@5 99.414 (99.699)	
2022-05-11 03:22:38,898: ============================================================
2022-05-11 03:23:09,997: Epoch: 13/38 eta: 1 day, 0:53:58.889781	Training Loss 0.2019 (0.1961)	Training Prec@1 98.633 (99.076)	Training Prec@5 99.609 (99.698)
2022-05-11 03:23:09,997: ============================================================
2022-05-11 03:23:57,926: time cost, forward:0.17487935827235984, backward:0.10412171151902941, data cost:0.20283742384477096 
2022-05-11 03:23:57,926: ============================================================
2022-05-11 03:23:57,927: Epoch 14/38 Batch 100/7662 eta: 1 day, 1:28:57.072306	Training Loss 0.1820 (0.1760)	Training Prec@1 99.219 (99.406)	Training Prec@5 99.609 (99.807)	
2022-05-11 03:23:57,927: ============================================================
2022-05-11 03:24:44,441: time cost, forward:0.17309650464273577, backward:0.1041740951825626, data cost:0.19605312874568767 
2022-05-11 03:24:44,441: ============================================================
2022-05-11 03:24:44,441: Epoch 14/38 Batch 200/7662 eta: 1 day, 0:43:26.864930	Training Loss 0.1710 (0.1760)	Training Prec@1 99.609 (99.423)	Training Prec@5 100.000 (99.824)	
2022-05-11 03:24:44,442: ============================================================
2022-05-11 03:25:30,933: time cost, forward:0.17243161568274865, backward:0.10417547353533997, data cost:0.1938186377585931 
2022-05-11 03:25:30,933: ============================================================
2022-05-11 03:25:30,933: Epoch 14/38 Batch 300/7662 eta: 1 day, 0:41:55.677801	Training Loss 0.1879 (0.1763)	Training Prec@1 99.023 (99.422)	Training Prec@5 99.609 (99.820)	
2022-05-11 03:25:30,933: ============================================================
2022-05-11 03:26:17,474: time cost, forward:0.17211732051725076, backward:0.10418143188744261, data cost:0.19280881690500973 
2022-05-11 03:26:17,474: ============================================================
2022-05-11 03:26:17,474: Epoch 14/38 Batch 400/7662 eta: 1 day, 0:42:44.273954	Training Loss 0.1789 (0.1771)	Training Prec@1 98.828 (99.411)	Training Prec@5 99.609 (99.813)	
2022-05-11 03:26:17,475: ============================================================
2022-05-11 03:27:03,990: time cost, forward:0.17192067077499115, backward:0.10419479878488667, data cost:0.19215119625619037 
2022-05-11 03:27:03,990: ============================================================
2022-05-11 03:27:03,991: Epoch 14/38 Batch 500/7662 eta: 1 day, 0:41:09.551512	Training Loss 0.1800 (0.1777)	Training Prec@1 99.609 (99.394)	Training Prec@5 99.609 (99.807)	
2022-05-11 03:27:03,991: ============================================================
2022-05-11 03:27:50,516: time cost, forward:0.17177275465008413, backward:0.10420149395581278, data cost:0.1917479949721908 
2022-05-11 03:27:50,516: ============================================================
2022-05-11 03:27:50,517: Epoch 14/38 Batch 600/7662 eta: 1 day, 0:40:41.832256	Training Loss 0.1893 (0.1785)	Training Prec@1 99.414 (99.389)	Training Prec@5 99.805 (99.804)	
2022-05-11 03:27:50,517: ============================================================
2022-05-11 03:28:36,990: time cost, forward:0.17166852848724234, backward:0.10420185301948515, data cost:0.19138795077715479 
2022-05-11 03:28:36,990: ============================================================
2022-05-11 03:28:36,990: Epoch 14/38 Batch 700/7662 eta: 1 day, 0:38:15.262367	Training Loss 0.1815 (0.1792)	Training Prec@1 98.828 (99.379)	Training Prec@5 99.609 (99.800)	
2022-05-11 03:28:36,990: ============================================================
2022-05-11 03:29:23,504: time cost, forward:0.1715869229188998, backward:0.1042009462253919, data cost:0.19117238435041023 
2022-05-11 03:29:23,504: ============================================================
2022-05-11 03:29:23,504: Epoch 14/38 Batch 800/7662 eta: 1 day, 0:38:45.757665	Training Loss 0.1914 (0.1800)	Training Prec@1 98.828 (99.371)	Training Prec@5 99.609 (99.798)	
2022-05-11 03:29:23,504: ============================================================
2022-05-11 03:30:10,019: time cost, forward:0.17154403151871764, backward:0.10419948055958987, data cost:0.19098781452030442 
2022-05-11 03:30:10,019: ============================================================
2022-05-11 03:30:10,019: Epoch 14/38 Batch 900/7662 eta: 1 day, 0:38:01.688306	Training Loss 0.1888 (0.1805)	Training Prec@1 98.242 (99.368)	Training Prec@5 99.414 (99.799)	
2022-05-11 03:30:10,019: ============================================================
2022-05-11 03:30:56,535: time cost, forward:0.17151025584987453, backward:0.10419949802669796, data cost:0.1908397734224856 
2022-05-11 03:30:56,536: ============================================================
2022-05-11 03:30:56,536: Epoch 14/38 Batch 1000/7662 eta: 1 day, 0:37:18.031167	Training Loss 0.1888 (0.1810)	Training Prec@1 99.023 (99.363)	Training Prec@5 99.609 (99.801)	
2022-05-11 03:30:56,536: ============================================================
2022-05-11 03:31:43,101: time cost, forward:0.17148435864261977, backward:0.10420313089733453, data cost:0.19075752280862684 
2022-05-11 03:31:43,101: ============================================================
2022-05-11 03:31:43,102: Epoch 14/38 Batch 1100/7662 eta: 1 day, 0:38:04.883639	Training Loss 0.1934 (0.1816)	Training Prec@1 99.414 (99.357)	Training Prec@5 100.000 (99.803)	
2022-05-11 03:31:43,102: ============================================================
2022-05-11 03:32:29,636: time cost, forward:0.17144170634641162, backward:0.10420237192021896, data cost:0.19068808213584715 
2022-05-11 03:32:29,636: ============================================================
2022-05-11 03:32:29,636: Epoch 14/38 Batch 1200/7662 eta: 1 day, 0:36:19.251662	Training Loss 0.1846 (0.1820)	Training Prec@1 99.414 (99.349)	Training Prec@5 99.609 (99.800)	
2022-05-11 03:32:29,636: ============================================================
2022-05-11 03:33:16,196: time cost, forward:0.1714259974308616, backward:0.10420256453903938, data cost:0.19061719224120766 
2022-05-11 03:33:16,196: ============================================================
2022-05-11 03:33:16,196: Epoch 14/38 Batch 1300/7662 eta: 1 day, 0:36:20.656838	Training Loss 0.1934 (0.1825)	Training Prec@1 99.414 (99.338)	Training Prec@5 99.805 (99.794)	
2022-05-11 03:33:16,196: ============================================================
2022-05-11 03:34:02,713: time cost, forward:0.17140388863695102, backward:0.10420047478474746, data cost:0.19054585358685813 
2022-05-11 03:34:02,713: ============================================================
2022-05-11 03:34:02,714: Epoch 14/38 Batch 1400/7662 eta: 1 day, 0:34:13.131769	Training Loss 0.1765 (0.1828)	Training Prec@1 99.609 (99.330)	Training Prec@5 100.000 (99.792)	
2022-05-11 03:34:02,714: ============================================================
2022-05-11 03:34:49,224: time cost, forward:0.17138330852134456, backward:0.10420161187449958, data cost:0.1904789004984341 
2022-05-11 03:34:49,224: ============================================================
2022-05-11 03:34:49,224: Epoch 14/38 Batch 1500/7662 eta: 1 day, 0:33:13.461834	Training Loss 0.1896 (0.1833)	Training Prec@1 99.023 (99.324)	Training Prec@5 99.805 (99.790)	
2022-05-11 03:34:49,224: ============================================================
2022-05-11 03:35:35,753: time cost, forward:0.17136998322697414, backward:0.10420180380978086, data cost:0.19042804108477146 
2022-05-11 03:35:35,753: ============================================================
2022-05-11 03:35:35,753: Epoch 14/38 Batch 1600/7662 eta: 1 day, 0:33:02.463457	Training Loss 0.1852 (0.1837)	Training Prec@1 99.805 (99.317)	Training Prec@5 99.805 (99.788)	
2022-05-11 03:35:35,753: ============================================================
2022-05-11 03:36:22,238: time cost, forward:0.1713479903952524, backward:0.10420061855753988, data cost:0.19037136279392972 
2022-05-11 03:36:22,239: ============================================================
2022-05-11 03:36:22,239: Epoch 14/38 Batch 1700/7662 eta: 1 day, 0:30:53.680167	Training Loss 0.1837 (0.1841)	Training Prec@1 99.609 (99.311)	Training Prec@5 100.000 (99.786)	
2022-05-11 03:36:22,239: ============================================================
2022-05-11 03:37:08,722: time cost, forward:0.17133119293157759, backward:0.10419926118559146, data cost:0.1903172811579214 
2022-05-11 03:37:08,723: ============================================================
2022-05-11 03:37:08,723: Epoch 14/38 Batch 1800/7662 eta: 1 day, 0:30:03.694628	Training Loss 0.1908 (0.1844)	Training Prec@1 99.219 (99.303)	Training Prec@5 99.414 (99.781)	
2022-05-11 03:37:08,723: ============================================================
2022-05-11 03:37:55,181: time cost, forward:0.1713080339647708, backward:0.10419828719751278, data cost:0.1902634857704038 
2022-05-11 03:37:55,181: ============================================================
2022-05-11 03:37:55,181: Epoch 14/38 Batch 1900/7662 eta: 1 day, 0:28:28.590506	Training Loss 0.1844 (0.1847)	Training Prec@1 99.414 (99.300)	Training Prec@5 99.805 (99.779)	
2022-05-11 03:37:55,181: ============================================================
2022-05-11 03:38:41,687: time cost, forward:0.17128952089818256, backward:0.10419592611666856, data cost:0.1902329319414346 
2022-05-11 03:38:41,687: ============================================================
2022-05-11 03:38:41,687: Epoch 14/38 Batch 2000/7662 eta: 1 day, 0:29:12.656380	Training Loss 0.1865 (0.1850)	Training Prec@1 98.633 (99.296)	Training Prec@5 99.414 (99.777)	
2022-05-11 03:38:41,687: ============================================================
2022-05-11 03:39:28,158: time cost, forward:0.17127346924340628, backward:0.10419428104329756, data cost:0.19019101675832312 
2022-05-11 03:39:28,158: ============================================================
2022-05-11 03:39:28,159: Epoch 14/38 Batch 2100/7662 eta: 1 day, 0:27:20.621942	Training Loss 0.1920 (0.1853)	Training Prec@1 99.414 (99.290)	Training Prec@5 99.609 (99.774)	
2022-05-11 03:39:28,159: ============================================================
2022-05-11 03:40:14,612: time cost, forward:0.17125820690743107, backward:0.1041946313553585, data cost:0.19014491640258344 
2022-05-11 03:40:14,613: ============================================================
2022-05-11 03:40:14,613: Epoch 14/38 Batch 2200/7662 eta: 1 day, 0:26:01.849393	Training Loss 0.1934 (0.1856)	Training Prec@1 99.609 (99.283)	Training Prec@5 99.805 (99.774)	
2022-05-11 03:40:14,613: ============================================================
2022-05-11 03:41:01,079: time cost, forward:0.17124199068717408, backward:0.10419258204373447, data cost:0.1901123654380888 
2022-05-11 03:41:01,080: ============================================================
2022-05-11 03:41:01,080: Epoch 14/38 Batch 2300/7662 eta: 1 day, 0:25:39.351073	Training Loss 0.2029 (0.1859)	Training Prec@1 99.023 (99.273)	Training Prec@5 100.000 (99.772)	
2022-05-11 03:41:01,080: ============================================================
2022-05-11 03:41:47,559: time cost, forward:0.17122750483040217, backward:0.10419394513774584, data cost:0.190079964812272 
2022-05-11 03:41:47,560: ============================================================
2022-05-11 03:41:47,560: Epoch 14/38 Batch 2400/7662 eta: 1 day, 0:25:17.057882	Training Loss 0.1933 (0.1862)	Training Prec@1 99.414 (99.266)	Training Prec@5 99.805 (99.769)	
2022-05-11 03:41:47,560: ============================================================
2022-05-11 03:42:34,042: time cost, forward:0.17121753543794227, backward:0.1041945812939739, data cost:0.19005183927437552 
2022-05-11 03:42:34,042: ============================================================
2022-05-11 03:42:34,042: Epoch 14/38 Batch 2500/7662 eta: 1 day, 0:24:35.684856	Training Loss 0.2053 (0.1865)	Training Prec@1 98.828 (99.260)	Training Prec@5 100.000 (99.766)	
2022-05-11 03:42:34,042: ============================================================
2022-05-11 03:43:20,522: time cost, forward:0.17120936743430606, backward:0.10419660478704203, data cost:0.1900232249197936 
2022-05-11 03:43:20,523: ============================================================
2022-05-11 03:43:20,523: Epoch 14/38 Batch 2600/7662 eta: 1 day, 0:23:45.475389	Training Loss 0.1984 (0.1868)	Training Prec@1 99.023 (99.256)	Training Prec@5 99.609 (99.764)	
2022-05-11 03:43:20,523: ============================================================
2022-05-11 03:44:07,005: time cost, forward:0.17120451951919108, backward:0.10419757545502285, data cost:0.18999631787371132 
2022-05-11 03:44:07,005: ============================================================
2022-05-11 03:44:07,005: Epoch 14/38 Batch 2700/7662 eta: 1 day, 0:23:01.971925	Training Loss 0.1931 (0.1870)	Training Prec@1 99.805 (99.250)	Training Prec@5 100.000 (99.763)	
2022-05-11 03:44:07,005: ============================================================
2022-05-11 03:44:53,475: time cost, forward:0.17119699488711723, backward:0.10419812088312529, data cost:0.18997026861203745 
2022-05-11 03:44:53,475: ============================================================
2022-05-11 03:44:53,476: Epoch 14/38 Batch 2800/7662 eta: 1 day, 0:21:53.715698	Training Loss 0.1998 (0.1873)	Training Prec@1 99.023 (99.244)	Training Prec@5 99.805 (99.760)	
2022-05-11 03:44:53,476: ============================================================
2022-05-11 03:45:39,985: time cost, forward:0.17119491318251684, backward:0.1041994622840105, data cost:0.18995353936244389 
2022-05-11 03:45:39,985: ============================================================
2022-05-11 03:45:39,985: Epoch 14/38 Batch 2900/7662 eta: 1 day, 0:22:20.724153	Training Loss 0.1912 (0.1875)	Training Prec@1 98.438 (99.240)	Training Prec@5 99.609 (99.759)	
2022-05-11 03:45:39,985: ============================================================
2022-05-11 03:46:26,490: time cost, forward:0.1711912826920955, backward:0.10420031895753581, data cost:0.18993818636694207 
2022-05-11 03:46:26,490: ============================================================
2022-05-11 03:46:26,490: Epoch 14/38 Batch 3000/7662 eta: 1 day, 0:21:25.346069	Training Loss 0.1855 (0.1878)	Training Prec@1 99.609 (99.234)	Training Prec@5 100.000 (99.756)	
2022-05-11 03:46:26,490: ============================================================
2022-05-11 03:47:12,990: time cost, forward:0.1711889951219094, backward:0.10420047686768563, data cost:0.18992247924607736 
2022-05-11 03:47:12,991: ============================================================
2022-05-11 03:47:12,991: Epoch 14/38 Batch 3100/7662 eta: 1 day, 0:20:31.501426	Training Loss 0.1917 (0.1880)	Training Prec@1 99.219 (99.228)	Training Prec@5 99.805 (99.754)	
2022-05-11 03:47:12,991: ============================================================
2022-05-11 03:47:59,542: time cost, forward:0.17119230677016492, backward:0.10420120503985163, data cost:0.1899139843124194 
2022-05-11 03:47:59,542: ============================================================
2022-05-11 03:47:59,542: Epoch 14/38 Batch 3200/7662 eta: 1 day, 0:21:19.840951	Training Loss 0.1903 (0.1882)	Training Prec@1 99.219 (99.223)	Training Prec@5 99.805 (99.752)	
2022-05-11 03:47:59,542: ============================================================
2022-05-11 03:48:46,049: time cost, forward:0.17119579612937758, backward:0.10420121897997803, data cost:0.18989579668186693 
2022-05-11 03:48:46,050: ============================================================
2022-05-11 03:48:46,050: Epoch 14/38 Batch 3300/7662 eta: 1 day, 0:19:11.012781	Training Loss 0.1948 (0.1884)	Training Prec@1 99.219 (99.219)	Training Prec@5 99.609 (99.751)	
2022-05-11 03:48:46,050: ============================================================
2022-05-11 03:49:32,559: time cost, forward:0.1711934986237955, backward:0.10420138795925049, data cost:0.18988510306072992 
2022-05-11 03:49:32,559: ============================================================
2022-05-11 03:49:32,560: Epoch 14/38 Batch 3400/7662 eta: 1 day, 0:18:28.499404	Training Loss 0.2087 (0.1886)	Training Prec@1 98.438 (99.215)	Training Prec@5 99.609 (99.751)	
2022-05-11 03:49:32,560: ============================================================
2022-05-11 03:50:19,094: time cost, forward:0.171195955745286, backward:0.1042019514125836, data cost:0.18987650222592983 
2022-05-11 03:50:19,095: ============================================================
2022-05-11 03:50:19,095: Epoch 14/38 Batch 3500/7662 eta: 1 day, 0:18:30.060718	Training Loss 0.1964 (0.1888)	Training Prec@1 99.023 (99.210)	Training Prec@5 99.609 (99.750)	
2022-05-11 03:50:19,095: ============================================================
2022-05-11 03:51:05,647: time cost, forward:0.1712018399478396, backward:0.10420219452389747, data cost:0.18987040580660478 
2022-05-11 03:51:05,647: ============================================================
2022-05-11 03:51:05,647: Epoch 14/38 Batch 3600/7662 eta: 1 day, 0:18:15.492267	Training Loss 0.1936 (0.1890)	Training Prec@1 99.219 (99.206)	Training Prec@5 99.805 (99.748)	
2022-05-11 03:51:05,647: ============================================================
2022-05-11 03:51:52,156: time cost, forward:0.17120419169928972, backward:0.10420145824748975, data cost:0.18985715928223365 
2022-05-11 03:51:52,156: ============================================================
2022-05-11 03:51:52,156: Epoch 14/38 Batch 3700/7662 eta: 1 day, 0:16:08.406827	Training Loss 0.1858 (0.1891)	Training Prec@1 98.633 (99.202)	Training Prec@5 99.609 (99.745)	
2022-05-11 03:51:52,157: ============================================================
2022-05-11 03:52:38,751: time cost, forward:0.17121978507728505, backward:0.10420231255583777, data cost:0.18985260377026886 
2022-05-11 03:52:38,751: ============================================================
2022-05-11 03:52:38,751: Epoch 14/38 Batch 3800/7662 eta: 1 day, 0:18:02.261132	Training Loss 0.1932 (0.1893)	Training Prec@1 99.023 (99.198)	Training Prec@5 99.414 (99.744)	
2022-05-11 03:52:38,751: ============================================================
2022-05-11 03:53:25,297: time cost, forward:0.17122846635435446, backward:0.10420304581152227, data cost:0.1898419054754883 
2022-05-11 03:53:25,297: ============================================================
2022-05-11 03:53:25,297: Epoch 14/38 Batch 3900/7662 eta: 1 day, 0:15:43.685499	Training Loss 0.1918 (0.1895)	Training Prec@1 98.633 (99.193)	Training Prec@5 99.805 (99.742)	
2022-05-11 03:53:25,297: ============================================================
2022-05-11 03:54:11,874: time cost, forward:0.1712447724720334, backward:0.1042015272905064, data cost:0.18983396878091058 
2022-05-11 03:54:11,875: ============================================================
2022-05-11 03:54:11,875: Epoch 14/38 Batch 4000/7662 eta: 1 day, 0:15:56.801532	Training Loss 0.2033 (0.1896)	Training Prec@1 99.414 (99.189)	Training Prec@5 100.000 (99.741)	
2022-05-11 03:54:11,875: ============================================================
2022-05-11 03:54:58,512: time cost, forward:0.1712748772285426, backward:0.10420093079199585, data cost:0.18982510684204845 
2022-05-11 03:54:58,513: ============================================================
2022-05-11 03:54:58,513: Epoch 14/38 Batch 4100/7662 eta: 1 day, 0:17:03.353157	Training Loss 0.1894 (0.1898)	Training Prec@1 98.633 (99.185)	Training Prec@5 99.414 (99.740)	
2022-05-11 03:54:58,513: ============================================================
2022-05-11 03:55:45,185: time cost, forward:0.17130462315344305, backward:0.10420093896361185, data cost:0.18982098011154025 
2022-05-11 03:55:45,186: ============================================================
2022-05-11 03:55:45,186: Epoch 14/38 Batch 4200/7662 eta: 1 day, 0:17:22.175181	Training Loss 0.1870 (0.1899)	Training Prec@1 99.609 (99.183)	Training Prec@5 100.000 (99.739)	
2022-05-11 03:55:45,186: ============================================================
2022-05-11 03:56:31,933: time cost, forward:0.17134196299623683, backward:0.10420053824349097, data cost:0.18982338267555068 
2022-05-11 03:56:31,933: ============================================================
2022-05-11 03:56:31,934: Epoch 14/38 Batch 4300/7662 eta: 1 day, 0:18:56.070072	Training Loss 0.1964 (0.1901)	Training Prec@1 99.023 (99.179)	Training Prec@5 100.000 (99.738)	
2022-05-11 03:56:31,934: ============================================================
2022-05-11 03:57:18,647: time cost, forward:0.17137851859255523, backward:0.10420122973673396, data cost:0.18982057171427247 
2022-05-11 03:57:18,647: ============================================================
2022-05-11 03:57:18,647: Epoch 14/38 Batch 4400/7662 eta: 1 day, 0:17:04.701219	Training Loss 0.1988 (0.1902)	Training Prec@1 99.414 (99.176)	Training Prec@5 99.805 (99.738)	
2022-05-11 03:57:18,647: ============================================================
2022-05-11 03:58:05,355: time cost, forward:0.17141955824633867, backward:0.10420037243307419, data cost:0.18981209710641128 
2022-05-11 03:58:05,356: ============================================================
2022-05-11 03:58:05,356: Epoch 14/38 Batch 4500/7662 eta: 1 day, 0:16:09.129127	Training Loss 0.1938 (0.1903)	Training Prec@1 99.609 (99.173)	Training Prec@5 100.000 (99.737)	
2022-05-11 03:58:05,356: ============================================================
2022-05-11 03:58:52,089: time cost, forward:0.17146478157557724, backward:0.10419940907013212, data cost:0.1898035882322341 
2022-05-11 03:58:52,089: ============================================================
2022-05-11 03:58:52,089: Epoch 14/38 Batch 4600/7662 eta: 1 day, 0:16:08.240139	Training Loss 0.1974 (0.1905)	Training Prec@1 99.219 (99.168)	Training Prec@5 99.805 (99.735)	
2022-05-11 03:58:52,089: ============================================================
2022-05-11 03:59:38,754: time cost, forward:0.17148998098744817, backward:0.10419962710079982, data cost:0.18979591596732878 
2022-05-11 03:59:38,754: ============================================================
2022-05-11 03:59:38,754: Epoch 14/38 Batch 4700/7662 eta: 1 day, 0:13:14.174554	Training Loss 0.1838 (0.1906)	Training Prec@1 99.609 (99.164)	Training Prec@5 99.805 (99.734)	
2022-05-11 03:59:38,754: ============================================================
2022-05-11 04:00:25,250: time cost, forward:0.1714804168541398, backward:0.10419900493339639, data cost:0.18978988103355857 
2022-05-11 04:00:25,250: ============================================================
2022-05-11 04:00:25,250: Epoch 14/38 Batch 4800/7662 eta: 1 day, 0:07:11.422696	Training Loss 0.1802 (0.1907)	Training Prec@1 99.805 (99.160)	Training Prec@5 99.805 (99.732)	
2022-05-11 04:00:25,250: ============================================================
2022-05-11 04:01:11,747: time cost, forward:0.17147345717134804, backward:0.10419801883148548, data cost:0.1897826942771667 
2022-05-11 04:01:11,747: ============================================================
2022-05-11 04:01:11,748: Epoch 14/38 Batch 4900/7662 eta: 1 day, 0:06:28.328975	Training Loss 0.1894 (0.1908)	Training Prec@1 99.414 (99.158)	Training Prec@5 99.805 (99.732)	
2022-05-11 04:01:11,748: ============================================================
2022-05-11 04:01:58,216: time cost, forward:0.17146130093671627, backward:0.10419798336116809, data cost:0.18977443855699241 
2022-05-11 04:01:58,216: ============================================================
2022-05-11 04:01:58,216: Epoch 14/38 Batch 5000/7662 eta: 1 day, 0:04:47.064295	Training Loss 0.1922 (0.1909)	Training Prec@1 99.023 (99.154)	Training Prec@5 99.805 (99.732)	
2022-05-11 04:01:58,216: ============================================================
2022-05-11 04:02:44,734: time cost, forward:0.1714511353914867, backward:0.10419770637477793, data cost:0.189775254871827 
2022-05-11 04:02:44,735: ============================================================
2022-05-11 04:02:44,735: Epoch 14/38 Batch 5100/7662 eta: 1 day, 0:05:34.974089	Training Loss 0.1967 (0.1910)	Training Prec@1 98.828 (99.151)	Training Prec@5 99.609 (99.730)	
2022-05-11 04:02:44,735: ============================================================
2022-05-11 04:03:31,206: time cost, forward:0.17144110528843567, backward:0.10419784451613268, data cost:0.18976658815419498 
2022-05-11 04:03:31,206: ============================================================
2022-05-11 04:03:31,206: Epoch 14/38 Batch 5200/7662 eta: 1 day, 0:03:20.277202	Training Loss 0.1906 (0.1911)	Training Prec@1 98.828 (99.147)	Training Prec@5 99.609 (99.729)	
2022-05-11 04:03:31,207: ============================================================
2022-05-11 04:04:17,749: time cost, forward:0.17143431135473847, backward:0.10419809096128137, data cost:0.18976907537531956 
2022-05-11 04:04:17,750: ============================================================
2022-05-11 04:04:17,750: Epoch 14/38 Batch 5300/7662 eta: 1 day, 0:04:47.571117	Training Loss 0.1901 (0.1912)	Training Prec@1 99.609 (99.144)	Training Prec@5 100.000 (99.728)	
2022-05-11 04:04:17,750: ============================================================
2022-05-11 04:05:04,279: time cost, forward:0.1714261439712561, backward:0.10419887846367164, data cost:0.1897704841958569 
2022-05-11 04:05:04,280: ============================================================
2022-05-11 04:05:04,280: Epoch 14/38 Batch 5400/7662 eta: 1 day, 0:03:35.960831	Training Loss 0.1931 (0.1913)	Training Prec@1 98.828 (99.142)	Training Prec@5 99.219 (99.727)	
2022-05-11 04:05:04,280: ============================================================
2022-05-11 04:05:50,834: time cost, forward:0.17141965676013027, backward:0.10419905374301176, data cost:0.18977505273224116 
2022-05-11 04:05:50,835: ============================================================
2022-05-11 04:05:50,835: Epoch 14/38 Batch 5500/7662 eta: 1 day, 0:03:35.959781	Training Loss 0.1964 (0.1915)	Training Prec@1 98.828 (99.139)	Training Prec@5 99.805 (99.725)	
2022-05-11 04:05:50,835: ============================================================
2022-05-11 04:06:37,384: time cost, forward:0.17141544974303752, backward:0.10419913951276263, data cost:0.1897751745911108 
2022-05-11 04:06:37,385: ============================================================
2022-05-11 04:06:37,385: Epoch 14/38 Batch 5600/7662 eta: 1 day, 0:02:40.338487	Training Loss 0.1914 (0.1915)	Training Prec@1 99.219 (99.136)	Training Prec@5 99.609 (99.724)	
2022-05-11 04:06:37,385: ============================================================
2022-05-11 04:07:23,910: time cost, forward:0.17141379931868744, backward:0.10419916625524073, data cost:0.18976964103817878 
2022-05-11 04:07:23,910: ============================================================
2022-05-11 04:07:23,910: Epoch 14/38 Batch 5700/7662 eta: 1 day, 0:01:08.327780	Training Loss 0.1920 (0.1917)	Training Prec@1 99.023 (99.133)	Training Prec@5 99.414 (99.723)	
2022-05-11 04:07:23,911: ============================================================
2022-05-11 04:08:10,433: time cost, forward:0.17141052693575698, backward:0.10419897515931238, data cost:0.1897658664083703 
2022-05-11 04:08:10,433: ============================================================
2022-05-11 04:08:10,433: Epoch 14/38 Batch 5800/7662 eta: 1 day, 0:00:16.121976	Training Loss 0.1872 (0.1917)	Training Prec@1 99.023 (99.131)	Training Prec@5 99.219 (99.722)	
2022-05-11 04:08:10,433: ============================================================
2022-05-11 04:08:56,942: time cost, forward:0.17140370826637125, backward:0.10419930371415273, data cost:0.18976303588982293 
2022-05-11 04:08:56,942: ============================================================
2022-05-11 04:08:56,942: Epoch 14/38 Batch 5900/7662 eta: 23:59:04.327657	Training Loss 0.2047 (0.1918)	Training Prec@1 98.633 (99.128)	Training Prec@5 99.609 (99.720)	
2022-05-11 04:08:56,942: ============================================================
2022-05-11 04:09:43,472: time cost, forward:0.17140039385785896, backward:0.10419835406832942, data cost:0.18976186199731918 
2022-05-11 04:09:43,472: ============================================================
2022-05-11 04:09:43,473: Epoch 14/38 Batch 6000/7662 eta: 23:58:57.960116	Training Loss 0.2149 (0.1919)	Training Prec@1 98.047 (99.125)	Training Prec@5 99.219 (99.719)	
2022-05-11 04:09:43,473: ============================================================
2022-05-11 04:10:30,021: time cost, forward:0.17140415110027502, backward:0.10419826375439355, data cost:0.18975603453427733 
2022-05-11 04:10:30,021: ============================================================
2022-05-11 04:10:30,021: Epoch 14/38 Batch 6100/7662 eta: 23:58:44.316182	Training Loss 0.1953 (0.1920)	Training Prec@1 98.438 (99.121)	Training Prec@5 99.805 (99.718)	
2022-05-11 04:10:30,021: ============================================================
2022-05-11 04:11:16,551: time cost, forward:0.17140356423989825, backward:0.10419829523665307, data cost:0.1897516281379002 
2022-05-11 04:11:16,551: ============================================================
2022-05-11 04:11:16,552: Epoch 14/38 Batch 6200/7662 eta: 23:57:25.191939	Training Loss 0.2014 (0.1921)	Training Prec@1 98.438 (99.118)	Training Prec@5 99.609 (99.717)	
2022-05-11 04:11:16,552: ============================================================
2022-05-11 04:12:03,116: time cost, forward:0.1714034400339788, backward:0.10419856727946503, data cost:0.18974990507102538 
2022-05-11 04:12:03,116: ============================================================
2022-05-11 04:12:03,117: Epoch 14/38 Batch 6300/7662 eta: 23:57:41.978087	Training Loss 0.2017 (0.1922)	Training Prec@1 98.438 (99.115)	Training Prec@5 99.609 (99.716)	
2022-05-11 04:12:03,117: ============================================================
2022-05-11 04:12:49,640: time cost, forward:0.17140022041760752, backward:0.10419757732433683, data cost:0.1897484686136581 
2022-05-11 04:12:49,640: ============================================================
2022-05-11 04:12:49,641: Epoch 14/38 Batch 6400/7662 eta: 23:55:39.647578	Training Loss 0.2050 (0.1922)	Training Prec@1 98.242 (99.112)	Training Prec@5 99.609 (99.715)	
2022-05-11 04:12:49,641: ============================================================
2022-05-11 04:13:36,184: time cost, forward:0.17139814468251136, backward:0.10419729647773616, data cost:0.18974793127893136 
2022-05-11 04:13:36,184: ============================================================
2022-05-11 04:13:36,184: Epoch 14/38 Batch 6500/7662 eta: 23:55:29.264588	Training Loss 0.2214 (0.1923)	Training Prec@1 97.266 (99.109)	Training Prec@5 98.828 (99.714)	
2022-05-11 04:13:36,184: ============================================================
2022-05-11 04:14:22,761: time cost, forward:0.17139667968963887, backward:0.10419658441076786, data cost:0.1897527738707881 
2022-05-11 04:14:22,762: ============================================================
2022-05-11 04:14:22,762: Epoch 14/38 Batch 6600/7662 eta: 23:55:45.963191	Training Loss 0.1977 (0.1924)	Training Prec@1 98.242 (99.108)	Training Prec@5 99.414 (99.713)	
2022-05-11 04:14:22,762: ============================================================
2022-05-11 04:15:09,425: time cost, forward:0.17140013955567981, backward:0.10419607486346175, data cost:0.18976541205402062 
2022-05-11 04:15:09,425: ============================================================
2022-05-11 04:15:09,426: Epoch 14/38 Batch 6700/7662 eta: 23:57:38.476701	Training Loss 0.1896 (0.1925)	Training Prec@1 98.828 (99.105)	Training Prec@5 99.609 (99.712)	
2022-05-11 04:15:09,426: ============================================================
2022-05-11 04:15:56,011: time cost, forward:0.17139952462251476, backward:0.10419520898362541, data cost:0.18976847935045515 
2022-05-11 04:15:56,011: ============================================================
2022-05-11 04:15:56,011: Epoch 14/38 Batch 6800/7662 eta: 23:54:27.478838	Training Loss 0.1857 (0.1926)	Training Prec@1 99.219 (99.102)	Training Prec@5 100.000 (99.710)	
2022-05-11 04:15:56,011: ============================================================
2022-05-11 04:16:42,580: time cost, forward:0.17139808988896016, backward:0.10419455426795739, data cost:0.1897700381358476 
2022-05-11 04:16:42,580: ============================================================
2022-05-11 04:16:42,580: Epoch 14/38 Batch 6900/7662 eta: 23:53:10.415641	Training Loss 0.1962 (0.1926)	Training Prec@1 98.242 (99.099)	Training Prec@5 99.219 (99.709)	
2022-05-11 04:16:42,580: ============================================================
2022-05-11 04:17:29,197: time cost, forward:0.17139958306574313, backward:0.10419417984367421, data cost:0.18977671099451715 
2022-05-11 04:17:29,197: ============================================================
2022-05-11 04:17:29,197: Epoch 14/38 Batch 7000/7662 eta: 23:53:52.278461	Training Loss 0.2028 (0.1927)	Training Prec@1 99.609 (99.097)	Training Prec@5 99.609 (99.709)	
2022-05-11 04:17:29,198: ============================================================
2022-05-11 04:18:15,859: time cost, forward:0.1713979515261609, backward:0.10419376176215339, data cost:0.18978941989693948 
2022-05-11 04:18:15,859: ============================================================
2022-05-11 04:18:15,869: Epoch 14/38 Batch 7100/7662 eta: 23:54:46.735319	Training Loss 0.1973 (0.1928)	Training Prec@1 98.828 (99.094)	Training Prec@5 99.609 (99.708)	
2022-05-11 04:18:15,870: ============================================================
2022-05-11 04:19:02,518: time cost, forward:0.1713972734169656, backward:0.10419328760183393, data cost:0.18980225054219887 
2022-05-11 04:19:02,518: ============================================================
2022-05-11 04:19:02,519: Epoch 14/38 Batch 7200/7662 eta: 23:53:18.315411	Training Loss 0.1881 (0.1928)	Training Prec@1 98.242 (99.090)	Training Prec@5 99.805 (99.707)	
2022-05-11 04:19:02,519: ============================================================
2022-05-11 04:19:49,165: time cost, forward:0.17139480894339348, backward:0.10419316222560228, data cost:0.18981438856416247 
2022-05-11 04:19:49,166: ============================================================
2022-05-11 04:19:49,166: Epoch 14/38 Batch 7300/7662 eta: 23:52:27.691501	Training Loss 0.1945 (0.1929)	Training Prec@1 98.633 (99.089)	Training Prec@5 99.609 (99.707)	
2022-05-11 04:19:49,166: ============================================================
2022-05-11 04:20:35,800: time cost, forward:0.17139618092895376, backward:0.10419305290204639, data cost:0.1898223553046711 
2022-05-11 04:20:35,800: ============================================================
2022-05-11 04:20:35,800: Epoch 14/38 Batch 7400/7662 eta: 23:51:17.649642	Training Loss 0.1998 (0.1930)	Training Prec@1 99.219 (99.087)	Training Prec@5 100.000 (99.706)	
2022-05-11 04:20:35,800: ============================================================
2022-05-11 04:21:22,485: time cost, forward:0.1713971673909752, backward:0.10419297405903713, data cost:0.18983707740825403 
2022-05-11 04:21:22,485: ============================================================
2022-05-11 04:21:22,486: Epoch 14/38 Batch 7500/7662 eta: 23:52:05.098277	Training Loss 0.2012 (0.1930)	Training Prec@1 97.852 (99.086)	Training Prec@5 99.414 (99.706)	
2022-05-11 04:21:22,486: ============================================================
2022-05-11 04:22:09,091: time cost, forward:0.17139817642716926, backward:0.10419304023558944, data cost:0.18984080706949155 
2022-05-11 04:22:09,091: ============================================================
2022-05-11 04:22:09,091: Epoch 14/38 Batch 7600/7662 eta: 23:48:51.834122	Training Loss 0.1903 (0.1931)	Training Prec@1 99.414 (99.084)	Training Prec@5 99.609 (99.704)	
2022-05-11 04:22:09,091: ============================================================
2022-05-11 04:22:39,729: Epoch: 14/38 eta: 23:48:22.472468	Training Loss 0.2020 (0.1931)	Training Prec@1 99.609 (99.082)	Training Prec@5 99.805 (99.703)
2022-05-11 04:22:39,729: ============================================================
2022-05-11 04:23:30,370: time cost, forward:0.18557068555041997, backward:0.10402809971510762, data cost:0.21971373847036652 
2022-05-11 04:23:30,370: ============================================================
2022-05-11 04:23:30,370: Epoch 15/38 Batch 100/7662 eta: 1 day, 1:51:06.885859	Training Loss 0.1751 (0.1729)	Training Prec@1 99.414 (99.416)	Training Prec@5 100.000 (99.828)	
2022-05-11 04:23:30,370: ============================================================
2022-05-11 04:24:16,898: time cost, forward:0.17842604646730661, backward:0.10411359796571971, data cost:0.20452010691465444 
2022-05-11 04:24:16,898: ============================================================
2022-05-11 04:24:16,898: Epoch 15/38 Batch 200/7662 eta: 23:44:26.965722	Training Loss 0.1668 (0.1733)	Training Prec@1 99.219 (99.406)	Training Prec@5 99.805 (99.815)	
2022-05-11 04:24:16,899: ============================================================
2022-05-11 04:25:03,442: time cost, forward:0.1761058899869887, backward:0.1041794349517312, data cost:0.1994572714419668 
2022-05-11 04:25:03,442: ============================================================
2022-05-11 04:25:03,442: Epoch 15/38 Batch 300/7662 eta: 23:44:09.548878	Training Loss 0.1833 (0.1734)	Training Prec@1 98.633 (99.407)	Training Prec@5 99.414 (99.819)	
2022-05-11 04:25:03,443: ============================================================
2022-05-11 04:25:50,196: time cost, forward:0.17508393361753688, backward:0.10457736985725269, data cost:0.19693157905922795 
2022-05-11 04:25:50,196: ============================================================
2022-05-11 04:25:50,197: Epoch 15/38 Batch 400/7662 eta: 23:49:48.894937	Training Loss 0.1709 (0.1741)	Training Prec@1 98.828 (99.407)	Training Prec@5 99.414 (99.815)	
2022-05-11 04:25:50,197: ============================================================
2022-05-11 04:26:36,821: time cost, forward:0.1744370121277406, backward:0.10453847653880148, data cost:0.1954929537190225 
2022-05-11 04:26:36,821: ============================================================
2022-05-11 04:26:36,821: Epoch 15/38 Batch 500/7662 eta: 23:45:04.687952	Training Loss 0.1824 (0.1746)	Training Prec@1 98.633 (99.397)	Training Prec@5 99.023 (99.813)	
2022-05-11 04:26:36,821: ============================================================
2022-05-11 04:27:23,396: time cost, forward:0.17395383806180875, backward:0.10450081833216901, data cost:0.1945193824863593 
2022-05-11 04:27:23,396: ============================================================
2022-05-11 04:27:23,396: Epoch 15/38 Batch 600/7662 eta: 23:42:46.711125	Training Loss 0.1663 (0.1750)	Training Prec@1 99.414 (99.393)	Training Prec@5 99.805 (99.810)	
2022-05-11 04:27:23,396: ============================================================
2022-05-11 04:28:09,917: time cost, forward:0.17356088301313452, backward:0.1044697137349665, data cost:0.19379863275137751 
2022-05-11 04:28:09,917: ============================================================
2022-05-11 04:28:09,917: Epoch 15/38 Batch 700/7662 eta: 23:40:21.323076	Training Loss 0.1894 (0.1757)	Training Prec@1 99.414 (99.386)	Training Prec@5 99.805 (99.804)	
2022-05-11 04:28:09,917: ============================================================
2022-05-11 04:28:56,452: time cost, forward:0.17328144253717645, backward:0.10444622463517553, data cost:0.19325811006548407 
2022-05-11 04:28:56,452: ============================================================
2022-05-11 04:28:56,453: Epoch 15/38 Batch 800/7662 eta: 23:40:00.933818	Training Loss 0.1742 (0.1763)	Training Prec@1 98.633 (99.378)	Training Prec@5 99.414 (99.801)	
2022-05-11 04:28:56,453: ============================================================
2022-05-11 04:29:43,011: time cost, forward:0.17306236350894372, backward:0.10442877797051452, data cost:0.19286596310947576 
2022-05-11 04:29:43,011: ============================================================
2022-05-11 04:29:43,012: Epoch 15/38 Batch 900/7662 eta: 23:39:57.832832	Training Loss 0.1822 (0.1770)	Training Prec@1 99.805 (99.372)	Training Prec@5 99.805 (99.800)	
2022-05-11 04:29:43,012: ============================================================
2022-05-11 04:30:29,600: time cost, forward:0.17290132301109093, backward:0.10441050467429099, data cost:0.19257252567165248 
2022-05-11 04:30:29,600: ============================================================
2022-05-11 04:30:29,600: Epoch 15/38 Batch 1000/7662 eta: 23:40:05.828282	Training Loss 0.1989 (0.1774)	Training Prec@1 99.219 (99.367)	Training Prec@5 99.805 (99.796)	
2022-05-11 04:30:29,600: ============================================================
2022-05-11 04:31:16,190: time cost, forward:0.17277669754757244, backward:0.1043992884274067, data cost:0.1923214974893669 
2022-05-11 04:31:16,190: ============================================================
2022-05-11 04:31:16,190: Epoch 15/38 Batch 1100/7662 eta: 23:39:21.266817	Training Loss 0.1862 (0.1779)	Training Prec@1 99.219 (99.359)	Training Prec@5 99.609 (99.794)	
2022-05-11 04:31:16,190: ============================================================
2022-05-11 04:32:02,773: time cost, forward:0.17266475587611005, backward:0.10438782299827595, data cost:0.19211016922219779 
2022-05-11 04:32:02,774: ============================================================
2022-05-11 04:32:02,774: Epoch 15/38 Batch 1200/7662 eta: 23:38:22.936681	Training Loss 0.1875 (0.1784)	Training Prec@1 99.609 (99.355)	Training Prec@5 100.000 (99.793)	
2022-05-11 04:32:02,774: ============================================================
2022-05-11 04:32:49,355: time cost, forward:0.1725864186481479, backward:0.10437998980903185, data cost:0.1919191100213783 
2022-05-11 04:32:49,355: ============================================================
2022-05-11 04:32:49,356: Epoch 15/38 Batch 1300/7662 eta: 23:37:33.156143	Training Loss 0.1750 (0.1789)	Training Prec@1 99.609 (99.348)	Training Prec@5 99.805 (99.791)	
2022-05-11 04:32:49,356: ============================================================
2022-05-11 04:33:35,978: time cost, forward:0.1725073194742373, backward:0.10437338330048676, data cost:0.19178685143302387 
2022-05-11 04:33:35,978: ============================================================
2022-05-11 04:33:35,978: Epoch 15/38 Batch 1400/7662 eta: 23:38:01.085331	Training Loss 0.1849 (0.1794)	Training Prec@1 99.219 (99.343)	Training Prec@5 99.609 (99.789)	
2022-05-11 04:33:35,978: ============================================================
2022-05-11 04:34:22,557: time cost, forward:0.17244253403509036, backward:0.10436910816317324, data cost:0.19164695065366658 
2022-05-11 04:34:22,557: ============================================================
2022-05-11 04:34:22,557: Epoch 15/38 Batch 1500/7662 eta: 23:35:55.430199	Training Loss 0.1893 (0.1799)	Training Prec@1 99.414 (99.335)	Training Prec@5 99.805 (99.788)	
2022-05-11 04:34:22,557: ============================================================
2022-05-11 04:35:09,153: time cost, forward:0.17241002754392737, backward:0.10436240175949774, data cost:0.19151423125061265 
2022-05-11 04:35:09,154: ============================================================
2022-05-11 04:35:09,154: Epoch 15/38 Batch 1600/7662 eta: 23:35:39.924754	Training Loss 0.1844 (0.1804)	Training Prec@1 99.219 (99.329)	Training Prec@5 99.805 (99.787)	
2022-05-11 04:35:09,154: ============================================================
2022-05-11 04:35:55,698: time cost, forward:0.1723456541322974, backward:0.10435614661654, data cost:0.19140251879835213 
2022-05-11 04:35:55,698: ============================================================
2022-05-11 04:35:55,698: Epoch 15/38 Batch 1700/7662 eta: 23:33:18.701293	Training Loss 0.1971 (0.1808)	Training Prec@1 99.219 (99.326)	Training Prec@5 99.609 (99.785)	
2022-05-11 04:35:55,698: ============================================================
2022-05-11 04:36:42,280: time cost, forward:0.17228773251184162, backward:0.1043536812812504, data cost:0.1913105866324577 
2022-05-11 04:36:42,281: ============================================================
2022-05-11 04:36:42,281: Epoch 15/38 Batch 1800/7662 eta: 23:33:42.216178	Training Loss 0.1883 (0.1811)	Training Prec@1 99.219 (99.319)	Training Prec@5 99.414 (99.783)	
2022-05-11 04:36:42,281: ============================================================
2022-05-11 04:37:28,838: time cost, forward:0.17222994763704272, backward:0.10434622523532283, data cost:0.19123206633276033 
2022-05-11 04:37:28,838: ============================================================
2022-05-11 04:37:28,839: Epoch 15/38 Batch 1900/7662 eta: 23:32:10.051311	Training Loss 0.1944 (0.1816)	Training Prec@1 99.219 (99.310)	Training Prec@5 100.000 (99.778)	
2022-05-11 04:37:28,839: ============================================================
2022-05-11 04:38:15,379: time cost, forward:0.17218664767087372, backward:0.10433736987684059, data cost:0.19115079862586018 
2022-05-11 04:38:15,379: ============================================================
2022-05-11 04:38:15,379: Epoch 15/38 Batch 2000/7662 eta: 23:30:52.411580	Training Loss 0.1841 (0.1819)	Training Prec@1 99.219 (99.302)	Training Prec@5 99.609 (99.777)	
2022-05-11 04:38:15,380: ============================================================
2022-05-11 04:39:01,943: time cost, forward:0.17215192051033795, backward:0.10432955138509531, data cost:0.19108423475653516 
2022-05-11 04:39:01,944: ============================================================
2022-05-11 04:39:01,944: Epoch 15/38 Batch 2100/7662 eta: 23:30:48.883358	Training Loss 0.1956 (0.1822)	Training Prec@1 99.414 (99.300)	Training Prec@5 99.609 (99.775)	
2022-05-11 04:39:01,944: ============================================================
2022-05-11 04:39:48,480: time cost, forward:0.1721089328620151, backward:0.10432152316590881, data cost:0.1910128678013488 
2022-05-11 04:39:48,480: ============================================================
2022-05-11 04:39:48,480: Epoch 15/38 Batch 2200/7662 eta: 23:29:11.970882	Training Loss 0.1781 (0.1825)	Training Prec@1 99.805 (99.295)	Training Prec@5 99.805 (99.774)	
2022-05-11 04:39:48,480: ============================================================
2022-05-11 04:40:35,102: time cost, forward:0.17209057996666083, backward:0.10431353710899668, data cost:0.19097489385617303 
2022-05-11 04:40:35,103: ============================================================
2022-05-11 04:40:35,103: Epoch 15/38 Batch 2300/7662 eta: 23:31:01.308475	Training Loss 0.1965 (0.1828)	Training Prec@1 99.023 (99.291)	Training Prec@5 100.000 (99.771)	
2022-05-11 04:40:35,103: ============================================================
2022-05-11 04:41:21,734: time cost, forward:0.17207110280938923, backward:0.10430885563795146, data cost:0.19094380829522092 
2022-05-11 04:41:21,734: ============================================================
2022-05-11 04:41:21,734: Epoch 15/38 Batch 2400/7662 eta: 23:30:30.694286	Training Loss 0.1921 (0.1832)	Training Prec@1 98.633 (99.285)	Training Prec@5 99.414 (99.771)	
2022-05-11 04:41:21,734: ============================================================
2022-05-11 04:42:08,330: time cost, forward:0.17205471876097853, backward:0.10430615613249694, data cost:0.19089256672441315 
2022-05-11 04:42:08,330: ============================================================
2022-05-11 04:42:08,330: Epoch 15/38 Batch 2500/7662 eta: 23:28:39.782234	Training Loss 0.2034 (0.1834)	Training Prec@1 98.242 (99.279)	Training Prec@5 98.828 (99.769)	
2022-05-11 04:42:08,330: ============================================================
2022-05-11 04:42:54,906: time cost, forward:0.17203709913153242, backward:0.10430228852363402, data cost:0.19084699523591134 
2022-05-11 04:42:54,907: ============================================================
2022-05-11 04:42:54,907: Epoch 15/38 Batch 2600/7662 eta: 23:27:18.364024	Training Loss 0.1901 (0.1837)	Training Prec@1 98.633 (99.274)	Training Prec@5 99.609 (99.768)	
2022-05-11 04:42:54,907: ============================================================
2022-05-11 04:43:41,431: time cost, forward:0.1720128058503848, backward:0.10429650308821721, data cost:0.1907957714104838 
2022-05-11 04:43:41,431: ============================================================
2022-05-11 04:43:41,431: Epoch 15/38 Batch 2700/7662 eta: 23:24:57.524937	Training Loss 0.1903 (0.1839)	Training Prec@1 99.219 (99.270)	Training Prec@5 99.609 (99.767)	
2022-05-11 04:43:41,431: ============================================================
2022-05-11 04:44:28,006: time cost, forward:0.17199409225234905, backward:0.10429344589516877, data cost:0.19076012628084424 
2022-05-11 04:44:28,006: ============================================================
2022-05-11 04:44:28,006: Epoch 15/38 Batch 2800/7662 eta: 23:25:42.396556	Training Loss 0.1887 (0.1842)	Training Prec@1 99.219 (99.263)	Training Prec@5 99.414 (99.765)	
2022-05-11 04:44:28,007: ============================================================
2022-05-11 04:45:14,549: time cost, forward:0.1719702247423565, backward:0.10428933038017428, data cost:0.19071863436953862 
2022-05-11 04:45:14,549: ============================================================
2022-05-11 04:45:14,549: Epoch 15/38 Batch 2900/7662 eta: 23:23:57.699020	Training Loss 0.1952 (0.1844)	Training Prec@1 99.219 (99.259)	Training Prec@5 99.805 (99.764)	
2022-05-11 04:45:14,550: ============================================================
2022-05-11 04:46:01,067: time cost, forward:0.17194730625744062, backward:0.10428516663643232, data cost:0.190677306539975 
2022-05-11 04:46:01,067: ============================================================
2022-05-11 04:46:01,067: Epoch 15/38 Batch 3000/7662 eta: 23:22:25.818453	Training Loss 0.1863 (0.1847)	Training Prec@1 99.219 (99.255)	Training Prec@5 99.609 (99.761)	
2022-05-11 04:46:01,067: ============================================================
2022-05-11 04:46:47,638: time cost, forward:0.1719297522612255, backward:0.10428309225197491, data cost:0.19064971976758743 
2022-05-11 04:46:47,638: ============================================================
2022-05-11 04:46:47,638: Epoch 15/38 Batch 3100/7662 eta: 23:23:14.659162	Training Loss 0.1870 (0.1849)	Training Prec@1 99.023 (99.250)	Training Prec@5 99.609 (99.759)	
2022-05-11 04:46:47,638: ============================================================
2022-05-11 04:47:34,214: time cost, forward:0.17191184725974568, backward:0.10428037200729785, data cost:0.1906279147733335 
2022-05-11 04:47:34,214: ============================================================
2022-05-11 04:47:34,214: Epoch 15/38 Batch 3200/7662 eta: 23:22:37.778815	Training Loss 0.1928 (0.1851)	Training Prec@1 99.609 (99.244)	Training Prec@5 100.000 (99.757)	
2022-05-11 04:47:34,214: ============================================================
2022-05-11 04:48:20,751: time cost, forward:0.17188972565360994, backward:0.10427777945688184, data cost:0.19060109672708272 
2022-05-11 04:48:20,752: ============================================================
2022-05-11 04:48:20,752: Epoch 15/38 Batch 3300/7662 eta: 23:20:41.947996	Training Loss 0.1913 (0.1853)	Training Prec@1 99.414 (99.239)	Training Prec@5 99.609 (99.755)	
2022-05-11 04:48:20,752: ============================================================
2022-05-11 04:49:07,283: time cost, forward:0.1718641994770361, backward:0.10427509766881976, data cost:0.19057936491633767 
2022-05-11 04:49:07,284: ============================================================
2022-05-11 04:49:07,284: Epoch 15/38 Batch 3400/7662 eta: 23:19:45.029284	Training Loss 0.1978 (0.1855)	Training Prec@1 99.219 (99.235)	Training Prec@5 99.414 (99.753)	
2022-05-11 04:49:07,284: ============================================================
2022-05-11 04:49:53,847: time cost, forward:0.17184345699712597, backward:0.10427374599933216, data cost:0.19056315413881417 
2022-05-11 04:49:53,848: ============================================================
2022-05-11 04:49:53,848: Epoch 15/38 Batch 3500/7662 eta: 23:19:56.889858	Training Loss 0.1979 (0.1857)	Training Prec@1 99.609 (99.231)	Training Prec@5 99.805 (99.752)	
2022-05-11 04:49:53,848: ============================================================
2022-05-11 04:50:40,400: time cost, forward:0.17182525206552873, backward:0.10427223480088937, data cost:0.19054371676666268 
2022-05-11 04:50:40,400: ============================================================
2022-05-11 04:50:40,401: Epoch 15/38 Batch 3600/7662 eta: 23:18:48.938308	Training Loss 0.2026 (0.1859)	Training Prec@1 99.414 (99.225)	Training Prec@5 99.609 (99.749)	
2022-05-11 04:50:40,401: ============================================================
2022-05-11 04:51:27,049: time cost, forward:0.17181423142910907, backward:0.1042714788643661, data cost:0.19054127519405928 
2022-05-11 04:51:27,049: ============================================================
2022-05-11 04:51:27,049: Epoch 15/38 Batch 3700/7662 eta: 23:20:55.951056	Training Loss 0.1907 (0.1861)	Training Prec@1 98.242 (99.220)	Training Prec@5 99.609 (99.748)	
2022-05-11 04:51:27,049: ============================================================
2022-05-11 04:52:13,633: time cost, forward:0.17179839552688297, backward:0.10426884508346312, data cost:0.19053226867830417 
2022-05-11 04:52:13,633: ============================================================
2022-05-11 04:52:13,633: Epoch 15/38 Batch 3800/7662 eta: 23:18:12.486925	Training Loss 0.1928 (0.1863)	Training Prec@1 99.023 (99.217)	Training Prec@5 99.805 (99.746)	
2022-05-11 04:52:13,633: ============================================================
2022-05-11 04:53:00,236: time cost, forward:0.17179042414293194, backward:0.10426700063227506, data cost:0.1905208413617432 
2022-05-11 04:53:00,236: ============================================================
2022-05-11 04:53:00,236: Epoch 15/38 Batch 3900/7662 eta: 23:18:00.569634	Training Loss 0.1842 (0.1864)	Training Prec@1 99.219 (99.213)	Training Prec@5 99.609 (99.745)	
2022-05-11 04:53:00,236: ============================================================
2022-05-11 04:53:46,886: time cost, forward:0.17179574278421061, backward:0.10426387562695727, data cost:0.19051045303077632 
2022-05-11 04:53:46,886: ============================================================
2022-05-11 04:53:46,886: Epoch 15/38 Batch 4000/7662 eta: 23:18:38.167205	Training Loss 0.1964 (0.1866)	Training Prec@1 99.219 (99.210)	Training Prec@5 100.000 (99.745)	
2022-05-11 04:53:46,886: ============================================================
2022-05-11 04:54:33,470: time cost, forward:0.17178481588947625, backward:0.10426071161873662, data cost:0.19049761044627198 
2022-05-11 04:54:33,470: ============================================================
2022-05-11 04:54:33,470: Epoch 15/38 Batch 4100/7662 eta: 23:15:53.042555	Training Loss 0.1737 (0.1867)	Training Prec@1 99.219 (99.206)	Training Prec@5 100.000 (99.744)	
2022-05-11 04:54:33,470: ============================================================
2022-05-11 04:55:20,032: time cost, forward:0.17176702880495984, backward:0.10425904303058098, data cost:0.190486304332427 
2022-05-11 04:55:20,032: ============================================================
2022-05-11 04:55:20,032: Epoch 15/38 Batch 4200/7662 eta: 23:14:26.190755	Training Loss 0.1848 (0.1869)	Training Prec@1 99.805 (99.201)	Training Prec@5 99.805 (99.743)	
2022-05-11 04:55:20,032: ============================================================
2022-05-11 04:56:06,606: time cost, forward:0.1717491050076002, backward:0.10425741823919153, data cost:0.19048185341855653 
2022-05-11 04:56:06,606: ============================================================
2022-05-11 04:56:06,606: Epoch 15/38 Batch 4300/7662 eta: 23:14:01.722416	Training Loss 0.1932 (0.1871)	Training Prec@1 98.828 (99.196)	Training Prec@5 99.805 (99.742)	
2022-05-11 04:56:06,606: ============================================================
2022-05-11 04:56:53,151: time cost, forward:0.17173246893998736, backward:0.10425632930555298, data cost:0.19046707883914185 
2022-05-11 04:56:53,151: ============================================================
2022-05-11 04:56:53,151: Epoch 15/38 Batch 4400/7662 eta: 23:12:23.450462	Training Loss 0.1891 (0.1872)	Training Prec@1 99.805 (99.192)	Training Prec@5 100.000 (99.740)	
2022-05-11 04:56:53,151: ============================================================
2022-05-11 04:57:39,698: time cost, forward:0.17172018128730213, backward:0.10425577595064868, data cost:0.1904529164329744 
2022-05-11 04:57:39,698: ============================================================
2022-05-11 04:57:39,699: Epoch 15/38 Batch 4500/7662 eta: 23:11:40.702817	Training Loss 0.1806 (0.1874)	Training Prec@1 99.414 (99.188)	Training Prec@5 99.609 (99.737)	
2022-05-11 04:57:39,699: ============================================================
2022-05-11 04:58:26,298: time cost, forward:0.17170978027935987, backward:0.10425454845996648, data cost:0.1904502067910145 
2022-05-11 04:58:26,299: ============================================================
2022-05-11 04:58:26,299: Epoch 15/38 Batch 4600/7662 eta: 23:12:28.984164	Training Loss 0.1864 (0.1875)	Training Prec@1 98.828 (99.184)	Training Prec@5 99.414 (99.736)	
2022-05-11 04:58:26,299: ============================================================
2022-05-11 04:59:12,894: time cost, forward:0.17170349580984365, backward:0.10425396233473617, data cost:0.19044165607208038 
2022-05-11 04:59:12,894: ============================================================
2022-05-11 04:59:12,894: Epoch 15/38 Batch 4700/7662 eta: 23:11:34.309962	Training Loss 0.1992 (0.1876)	Training Prec@1 99.023 (99.180)	Training Prec@5 99.805 (99.735)	
2022-05-11 04:59:12,894: ============================================================
2022-05-11 04:59:59,524: time cost, forward:0.17169437673743204, backward:0.10425396704827777, data cost:0.1904367643437005 
2022-05-11 04:59:59,524: ============================================================
2022-05-11 04:59:59,525: Epoch 15/38 Batch 4800/7662 eta: 23:11:49.949830	Training Loss 0.1892 (0.1878)	Training Prec@1 98.438 (99.177)	Training Prec@5 99.023 (99.733)	
2022-05-11 04:59:59,525: ============================================================
2022-05-11 05:00:46,189: time cost, forward:0.17169431137245367, backward:0.10425558316997179, data cost:0.1904338198453705 
2022-05-11 05:00:46,189: ============================================================
2022-05-11 05:00:46,190: Epoch 15/38 Batch 4900/7662 eta: 23:12:04.869840	Training Loss 0.1993 (0.1879)	Training Prec@1 98.828 (99.173)	Training Prec@5 99.414 (99.732)	
2022-05-11 05:00:46,190: ============================================================
2022-05-11 05:01:32,816: time cost, forward:0.17169340397506075, backward:0.10425611127970529, data cost:0.1904283708323238 
2022-05-11 05:01:32,816: ============================================================
2022-05-11 05:01:32,817: Epoch 15/38 Batch 5000/7662 eta: 23:10:10.670587	Training Loss 0.1986 (0.1880)	Training Prec@1 99.023 (99.170)	Training Prec@5 99.609 (99.731)	
2022-05-11 05:01:32,817: ============================================================
2022-05-11 05:02:19,423: time cost, forward:0.17169012642767084, backward:0.1042566179738229, data cost:0.19041775245015632 
2022-05-11 05:02:19,423: ============================================================
2022-05-11 05:02:19,423: Epoch 15/38 Batch 5100/7662 eta: 23:08:46.968179	Training Loss 0.1900 (0.1881)	Training Prec@1 99.023 (99.168)	Training Prec@5 99.805 (99.730)	
2022-05-11 05:02:19,423: ============================================================
2022-05-11 05:03:05,991: time cost, forward:0.1716827518964277, backward:0.10425657330854371, data cost:0.19040743216433692 
2022-05-11 05:03:05,992: ============================================================
2022-05-11 05:03:05,992: Epoch 15/38 Batch 5200/7662 eta: 23:06:53.398816	Training Loss 0.1887 (0.1882)	Training Prec@1 99.609 (99.163)	Training Prec@5 100.000 (99.728)	
2022-05-11 05:03:05,992: ============================================================
2022-05-11 05:03:52,563: time cost, forward:0.1716742696886266, backward:0.1042570154899515, data cost:0.19039896889258429 
2022-05-11 05:03:52,563: ============================================================
2022-05-11 05:03:52,563: Epoch 15/38 Batch 5300/7662 eta: 23:06:11.631600	Training Loss 0.1981 (0.1883)	Training Prec@1 98.047 (99.159)	Training Prec@5 99.219 (99.726)	
2022-05-11 05:03:52,563: ============================================================
2022-05-11 05:04:39,196: time cost, forward:0.17167123968368506, backward:0.10425750541121767, data cost:0.19039749096755432 
2022-05-11 05:04:39,197: ============================================================
2022-05-11 05:04:39,197: Epoch 15/38 Batch 5400/7662 eta: 23:07:15.688844	Training Loss 0.1952 (0.1884)	Training Prec@1 99.609 (99.156)	Training Prec@5 99.805 (99.725)	
2022-05-11 05:04:39,197: ============================================================
2022-05-11 05:05:25,836: time cost, forward:0.1716702877120292, backward:0.10425823331854737, data cost:0.19039444551400259 
2022-05-11 05:05:25,836: ============================================================
2022-05-11 05:05:25,836: Epoch 15/38 Batch 5500/7662 eta: 23:06:39.106743	Training Loss 0.1873 (0.1885)	Training Prec@1 98.828 (99.153)	Training Prec@5 99.805 (99.724)	
2022-05-11 05:05:25,836: ============================================================
2022-05-11 05:06:12,484: time cost, forward:0.17167124328368008, backward:0.10425869689112924, data cost:0.19038951607724772 
2022-05-11 05:06:12,484: ============================================================
2022-05-11 05:06:12,485: Epoch 15/38 Batch 5600/7662 eta: 23:06:09.411050	Training Loss 0.1941 (0.1886)	Training Prec@1 99.414 (99.150)	Training Prec@5 100.000 (99.722)	
2022-05-11 05:06:12,485: ============================================================
2022-05-11 05:06:59,168: time cost, forward:0.17167361988730964, backward:0.10425978360374386, data cost:0.19039042386324243 
2022-05-11 05:06:59,168: ============================================================
2022-05-11 05:06:59,168: Epoch 15/38 Batch 5700/7662 eta: 23:06:25.098115	Training Loss 0.1858 (0.1887)	Training Prec@1 99.219 (99.149)	Training Prec@5 99.805 (99.722)	
2022-05-11 05:06:59,168: ============================================================
2022-05-11 05:07:45,813: time cost, forward:0.17167012344908975, backward:0.10426002606212487, data cost:0.19039024523896048 
2022-05-11 05:07:45,813: ============================================================
2022-05-11 05:07:45,813: Epoch 15/38 Batch 5800/7662 eta: 23:04:29.974924	Training Loss 0.2005 (0.1888)	Training Prec@1 98.438 (99.146)	Training Prec@5 99.805 (99.722)	
2022-05-11 05:07:45,814: ============================================================
2022-05-11 05:08:32,442: time cost, forward:0.1716662716271413, backward:0.10425970452905692, data cost:0.19038783580413368 
2022-05-11 05:08:32,443: ============================================================
2022-05-11 05:08:32,443: Epoch 15/38 Batch 5900/7662 eta: 23:03:15.033049	Training Loss 0.2006 (0.1889)	Training Prec@1 99.219 (99.142)	Training Prec@5 99.805 (99.720)	
2022-05-11 05:08:32,443: ============================================================
2022-05-11 05:09:19,111: time cost, forward:0.17166473802317578, backward:0.1042604346656068, data cost:0.1903904063003344 
2022-05-11 05:09:19,111: ============================================================
2022-05-11 05:09:19,111: Epoch 15/38 Batch 6000/7662 eta: 23:03:37.759309	Training Loss 0.1976 (0.1890)	Training Prec@1 99.023 (99.139)	Training Prec@5 99.609 (99.719)	
2022-05-11 05:09:19,111: ============================================================
2022-05-11 05:10:05,771: time cost, forward:0.17166120784363603, backward:0.1042613566830659, data cost:0.19039363672663334 
2022-05-11 05:10:05,772: ============================================================
2022-05-11 05:10:05,772: Epoch 15/38 Batch 6100/7662 eta: 23:02:37.754417	Training Loss 0.1794 (0.1891)	Training Prec@1 99.414 (99.137)	Training Prec@5 99.609 (99.718)	
2022-05-11 05:10:05,772: ============================================================
2022-05-11 05:10:52,485: time cost, forward:0.17166043447090515, backward:0.10426203495726545, data cost:0.19040115076912126 
2022-05-11 05:10:52,486: ============================================================
2022-05-11 05:10:52,486: Epoch 15/38 Batch 6200/7662 eta: 23:03:25.472944	Training Loss 0.1932 (0.1892)	Training Prec@1 99.609 (99.135)	Training Prec@5 99.805 (99.717)	
2022-05-11 05:10:52,486: ============================================================
2022-05-11 05:11:39,151: time cost, forward:0.17166119663464416, backward:0.10426383772470171, data cost:0.19039827756492614 
2022-05-11 05:11:39,152: ============================================================
2022-05-11 05:11:39,152: Epoch 15/38 Batch 6300/7662 eta: 23:01:13.754946	Training Loss 0.1876 (0.1892)	Training Prec@1 99.023 (99.132)	Training Prec@5 99.805 (99.717)	
2022-05-11 05:11:39,152: ============================================================
2022-05-11 05:12:25,783: time cost, forward:0.17165499390019237, backward:0.10426480532773008, data cost:0.1903938465070717 
2022-05-11 05:12:25,784: ============================================================
2022-05-11 05:12:25,784: Epoch 15/38 Batch 6400/7662 eta: 22:59:26.881163	Training Loss 0.1914 (0.1893)	Training Prec@1 98.828 (99.129)	Training Prec@5 99.609 (99.716)	
2022-05-11 05:12:25,784: ============================================================
2022-05-11 05:13:12,459: time cost, forward:0.17164901275417588, backward:0.1042658975260462, data cost:0.19039868989308478 
2022-05-11 05:13:12,460: ============================================================
2022-05-11 05:13:12,460: Epoch 15/38 Batch 6500/7662 eta: 22:59:57.886421	Training Loss 0.1966 (0.1894)	Training Prec@1 98.828 (99.127)	Training Prec@5 99.805 (99.715)	
2022-05-11 05:13:12,460: ============================================================
2022-05-11 05:13:59,104: time cost, forward:0.17165173771056574, backward:0.10426615519783031, data cost:0.19039376689947307 
2022-05-11 05:13:59,104: ============================================================
2022-05-11 05:13:59,104: Epoch 15/38 Batch 6600/7662 eta: 22:58:15.252731	Training Loss 0.1899 (0.1895)	Training Prec@1 98.633 (99.124)	Training Prec@5 99.805 (99.714)	
2022-05-11 05:13:59,104: ============================================================
2022-05-11 05:14:45,798: time cost, forward:0.17165167428856734, backward:0.10426650981188426, data cost:0.1903977201205258 
2022-05-11 05:14:45,799: ============================================================
2022-05-11 05:14:45,799: Epoch 15/38 Batch 6700/7662 eta: 22:58:57.722440	Training Loss 0.1882 (0.1895)	Training Prec@1 99.023 (99.122)	Training Prec@5 99.414 (99.713)	
2022-05-11 05:14:45,799: ============================================================
2022-05-11 05:15:32,515: time cost, forward:0.1716508361097118, backward:0.10426659225663608, data cost:0.19040745843033666 
2022-05-11 05:15:32,515: ============================================================
2022-05-11 05:15:32,515: Epoch 15/38 Batch 6800/7662 eta: 22:58:49.322973	Training Loss 0.1940 (0.1897)	Training Prec@1 99.414 (99.119)	Training Prec@5 100.000 (99.712)	
2022-05-11 05:15:32,515: ============================================================
2022-05-11 05:16:19,209: time cost, forward:0.17164864165486762, backward:0.1042662804187908, data cost:0.19041232852628912 
2022-05-11 05:16:19,209: ============================================================
2022-05-11 05:16:19,209: Epoch 15/38 Batch 6900/7662 eta: 22:57:23.858487	Training Loss 0.1931 (0.1897)	Training Prec@1 99.609 (99.116)	Training Prec@5 99.805 (99.712)	
2022-05-11 05:16:19,209: ============================================================
2022-05-11 05:17:05,887: time cost, forward:0.17164475002498655, backward:0.10426591927536148, data cost:0.19041465013124956 
2022-05-11 05:17:05,887: ============================================================
2022-05-11 05:17:05,887: Epoch 15/38 Batch 7000/7662 eta: 22:56:07.629951	Training Loss 0.1989 (0.1898)	Training Prec@1 98.828 (99.112)	Training Prec@5 99.805 (99.710)	
2022-05-11 05:17:05,887: ============================================================
2022-05-11 05:17:52,613: time cost, forward:0.17164268861741883, backward:0.10426530866223938, data cost:0.1904219113062563 
2022-05-11 05:17:52,613: ============================================================
2022-05-11 05:17:52,614: Epoch 15/38 Batch 7100/7662 eta: 22:56:47.514886	Training Loss 0.1916 (0.1899)	Training Prec@1 99.023 (99.110)	Training Prec@5 100.000 (99.710)	
2022-05-11 05:17:52,626: ============================================================
2022-05-11 05:18:39,235: time cost, forward:0.171640989001815, backward:0.10426486964225107, data cost:0.19041727019409485 
2022-05-11 05:18:39,235: ============================================================
2022-05-11 05:18:39,236: Epoch 15/38 Batch 7200/7662 eta: 22:52:55.809055	Training Loss 0.1913 (0.1899)	Training Prec@1 99.609 (99.108)	Training Prec@5 99.805 (99.710)	
2022-05-11 05:18:39,236: ============================================================
2022-05-11 05:19:25,879: time cost, forward:0.1716411443977654, backward:0.10426498828056431, data cost:0.19041335006203777 
2022-05-11 05:19:25,880: ============================================================
2022-05-11 05:19:25,880: Epoch 15/38 Batch 7300/7662 eta: 22:52:48.426288	Training Loss 0.1884 (0.1900)	Training Prec@1 99.023 (99.105)	Training Prec@5 99.414 (99.709)	
2022-05-11 05:19:25,880: ============================================================
2022-05-11 05:20:12,574: time cost, forward:0.1716387887019727, backward:0.10426465068770222, data cost:0.19041843536109887 
2022-05-11 05:20:12,575: ============================================================
2022-05-11 05:20:12,575: Epoch 15/38 Batch 7400/7662 eta: 22:53:31.562838	Training Loss 0.2003 (0.1901)	Training Prec@1 98.828 (99.101)	Training Prec@5 99.414 (99.707)	
2022-05-11 05:20:12,575: ============================================================
2022-05-11 05:20:59,300: time cost, forward:0.17163969135424315, backward:0.10426428798421698, data cost:0.1904237507533862 
2022-05-11 05:20:59,300: ============================================================
2022-05-11 05:20:59,300: Epoch 15/38 Batch 7500/7662 eta: 22:53:38.438419	Training Loss 0.1934 (0.1902)	Training Prec@1 98.633 (99.099)	Training Prec@5 99.805 (99.706)	
2022-05-11 05:20:59,300: ============================================================
2022-05-11 05:21:46,028: time cost, forward:0.171641559910815, backward:0.10426494008162286, data cost:0.19043051846671502 
2022-05-11 05:21:46,028: ============================================================
2022-05-11 05:21:46,028: Epoch 15/38 Batch 7600/7662 eta: 22:52:56.674744	Training Loss 0.1952 (0.1902)	Training Prec@1 99.023 (99.097)	Training Prec@5 99.609 (99.705)	
2022-05-11 05:21:46,028: ============================================================
2022-05-11 05:22:17,123: Epoch: 15/38 eta: 22:52:27.235979	Training Loss 0.1970 (0.1902)	Training Prec@1 99.414 (99.096)	Training Prec@5 100.000 (99.705)
2022-05-11 05:22:17,123: ============================================================
2022-05-11 05:22:17,136: Save Checkpoint...
2022-05-11 05:22:17,137: ============================================================
2022-05-11 05:22:19,713: Save done!
2022-05-11 05:22:19,714: ============================================================
2022-05-11 05:23:08,774: time cost, forward:0.19066517280809808, backward:0.10412106369480942, data cost:0.198599899658049 
2022-05-11 05:23:08,775: ============================================================
2022-05-11 05:23:08,775: Epoch 16/38 Batch 100/7662 eta: 1 day, 0:00:08.472151	Training Loss 0.1714 (0.1690)	Training Prec@1 100.000 (99.426)	Training Prec@5 100.000 (99.799)	
2022-05-11 05:23:08,775: ============================================================
2022-05-11 05:23:55,281: time cost, forward:0.18102666361248074, backward:0.10417367225915343, data cost:0.19382804482426474 
2022-05-11 05:23:55,281: ============================================================
2022-05-11 05:23:55,282: Epoch 16/38 Batch 200/7662 eta: 22:44:23.889327	Training Loss 0.1728 (0.1696)	Training Prec@1 99.805 (99.444)	Training Prec@5 99.805 (99.825)	
2022-05-11 05:23:55,282: ============================================================
2022-05-11 05:24:41,794: time cost, forward:0.1777511145358899, backward:0.10420795188699677, data cost:0.19233773304865912 
2022-05-11 05:24:41,794: ============================================================
2022-05-11 05:24:41,795: Epoch 16/38 Batch 300/7662 eta: 22:43:48.936855	Training Loss 0.1842 (0.1704)	Training Prec@1 99.219 (99.430)	Training Prec@5 99.414 (99.819)	
2022-05-11 05:24:41,795: ============================================================
2022-05-11 05:25:28,330: time cost, forward:0.17612557901176892, backward:0.10424998708834923, data cost:0.19161648081060043 
2022-05-11 05:25:28,330: ============================================================
2022-05-11 05:25:28,330: Epoch 16/38 Batch 400/7662 eta: 22:43:42.402099	Training Loss 0.1689 (0.1712)	Training Prec@1 99.609 (99.423)	Training Prec@5 99.805 (99.814)	
2022-05-11 05:25:28,330: ============================================================
2022-05-11 05:26:14,914: time cost, forward:0.17517907442693004, backward:0.10426631002483483, data cost:0.19126197713649346 
2022-05-11 05:26:14,914: ============================================================
2022-05-11 05:26:14,914: Epoch 16/38 Batch 500/7662 eta: 22:44:20.952866	Training Loss 0.1756 (0.1720)	Training Prec@1 99.805 (99.429)	Training Prec@5 100.000 (99.816)	
2022-05-11 05:26:14,915: ============================================================
2022-05-11 05:27:01,451: time cost, forward:0.17452403818426626, backward:0.10426785034408952, data cost:0.19096438315555528 
2022-05-11 05:27:01,451: ============================================================
2022-05-11 05:27:01,451: Epoch 16/38 Batch 600/7662 eta: 22:42:11.128208	Training Loss 0.1792 (0.1726)	Training Prec@1 98.633 (99.422)	Training Prec@5 99.805 (99.813)	
2022-05-11 05:27:01,451: ============================================================
2022-05-11 05:27:47,998: time cost, forward:0.17410527858270256, backward:0.1042749844225009, data cost:0.19072708142161882 
2022-05-11 05:27:47,998: ============================================================
2022-05-11 05:27:47,998: Epoch 16/38 Batch 700/7662 eta: 22:41:42.405261	Training Loss 0.1807 (0.1735)	Training Prec@1 99.414 (99.406)	Training Prec@5 99.805 (99.812)	
2022-05-11 05:27:47,998: ============================================================
2022-05-11 05:28:34,486: time cost, forward:0.17374999024841156, backward:0.10427718496740386, data cost:0.19052152639634917 
2022-05-11 05:28:34,486: ============================================================
2022-05-11 05:28:34,486: Epoch 16/38 Batch 800/7662 eta: 22:39:13.109240	Training Loss 0.1779 (0.1741)	Training Prec@1 98.828 (99.398)	Training Prec@5 99.609 (99.810)	
2022-05-11 05:28:34,487: ============================================================
2022-05-11 05:29:20,991: time cost, forward:0.17347685168927185, backward:0.10427568619190254, data cost:0.19038002111755303 
2022-05-11 05:29:20,991: ============================================================
2022-05-11 05:29:20,991: Epoch 16/38 Batch 900/7662 eta: 22:38:55.432799	Training Loss 0.1764 (0.1746)	Training Prec@1 99.219 (99.392)	Training Prec@5 100.000 (99.809)	
2022-05-11 05:29:20,991: ============================================================
2022-05-11 05:30:07,556: time cost, forward:0.17327897231261413, backward:0.10427605330168425, data cost:0.19030526641372209 
2022-05-11 05:30:07,557: ============================================================
2022-05-11 05:30:07,557: Epoch 16/38 Batch 1000/7662 eta: 22:39:55.312429	Training Loss 0.1813 (0.1751)	Training Prec@1 99.219 (99.390)	Training Prec@5 99.805 (99.809)	
2022-05-11 05:30:07,557: ============================================================
2022-05-11 05:30:54,105: time cost, forward:0.1731006122915391, backward:0.10427784247220484, data cost:0.19024182971333026 
2022-05-11 05:30:54,105: ============================================================
2022-05-11 05:30:54,105: Epoch 16/38 Batch 1100/7662 eta: 22:38:38.558718	Training Loss 0.1902 (0.1756)	Training Prec@1 99.023 (99.382)	Training Prec@5 100.000 (99.807)	
2022-05-11 05:30:54,105: ============================================================
2022-05-11 05:31:40,704: time cost, forward:0.17298266647058888, backward:0.1042793998129672, data cost:0.1902021669764833 
2022-05-11 05:31:40,705: ============================================================
2022-05-11 05:31:40,705: Epoch 16/38 Batch 1200/7662 eta: 22:39:22.014309	Training Loss 0.1827 (0.1761)	Training Prec@1 99.219 (99.375)	Training Prec@5 99.805 (99.805)	
2022-05-11 05:31:40,705: ============================================================
2022-05-11 05:32:27,338: time cost, forward:0.1728841553659417, backward:0.10428189478808866, data cost:0.19018187570608608 
2022-05-11 05:32:27,338: ============================================================
2022-05-11 05:32:27,338: Epoch 16/38 Batch 1300/7662 eta: 22:39:34.284105	Training Loss 0.1860 (0.1767)	Training Prec@1 99.414 (99.365)	Training Prec@5 99.805 (99.801)	
2022-05-11 05:32:27,338: ============================================================
2022-05-11 05:33:14,015: time cost, forward:0.17281163190414942, backward:0.10428848856257233, data cost:0.1901869110928168 
2022-05-11 05:33:14,015: ============================================================
2022-05-11 05:33:14,016: Epoch 16/38 Batch 1400/7662 eta: 22:40:05.102610	Training Loss 0.1835 (0.1771)	Training Prec@1 99.414 (99.357)	Training Prec@5 99.805 (99.796)	
2022-05-11 05:33:14,016: ============================================================
2022-05-11 05:34:00,646: time cost, forward:0.17273640298620713, backward:0.10429200989314125, data cost:0.19016229319047578 
2022-05-11 05:34:00,646: ============================================================
2022-05-11 05:34:00,647: Epoch 16/38 Batch 1500/7662 eta: 22:37:56.785810	Training Loss 0.1879 (0.1776)	Training Prec@1 99.219 (99.347)	Training Prec@5 99.609 (99.793)	
2022-05-11 05:34:00,647: ============================================================
2022-05-11 05:34:47,225: time cost, forward:0.17264665283956998, backward:0.10429445455192103, data cost:0.19014609210412156 
2022-05-11 05:34:47,225: ============================================================
2022-05-11 05:34:47,225: Epoch 16/38 Batch 1600/7662 eta: 22:35:39.304233	Training Loss 0.1846 (0.1780)	Training Prec@1 99.414 (99.338)	Training Prec@5 99.805 (99.790)	
2022-05-11 05:34:47,226: ============================================================
2022-05-11 05:35:33,730: time cost, forward:0.17255678802746194, backward:0.10429325785757584, data cost:0.19009681348592972 
2022-05-11 05:35:33,730: ============================================================
2022-05-11 05:35:33,730: Epoch 16/38 Batch 1700/7662 eta: 22:32:43.819415	Training Loss 0.1866 (0.1783)	Training Prec@1 98.828 (99.331)	Training Prec@5 99.805 (99.787)	
2022-05-11 05:35:33,731: ============================================================
2022-05-11 05:36:20,253: time cost, forward:0.17247258125907386, backward:0.10429208672265333, data cost:0.19006013737710864 
2022-05-11 05:36:20,253: ============================================================
2022-05-11 05:36:20,253: Epoch 16/38 Batch 1800/7662 eta: 22:32:28.310578	Training Loss 0.1791 (0.1787)	Training Prec@1 99.414 (99.325)	Training Prec@5 99.805 (99.784)	
2022-05-11 05:36:20,253: ============================================================
2022-05-11 05:37:06,746: time cost, forward:0.17239254383490926, backward:0.10429096184258965, data cost:0.19002825388976183 
2022-05-11 05:37:06,746: ============================================================
2022-05-11 05:37:06,746: Epoch 16/38 Batch 1900/7662 eta: 22:30:49.591564	Training Loss 0.1892 (0.1790)	Training Prec@1 99.609 (99.320)	Training Prec@5 100.000 (99.782)	
2022-05-11 05:37:06,746: ============================================================
2022-05-11 05:37:53,264: time cost, forward:0.17233768470767977, backward:0.1042905481175341, data cost:0.18999436451471585 
2022-05-11 05:37:53,265: ============================================================
2022-05-11 05:37:53,265: Epoch 16/38 Batch 2000/7662 eta: 22:30:48.405251	Training Loss 0.1855 (0.1794)	Training Prec@1 98.828 (99.314)	Training Prec@5 99.219 (99.780)	
2022-05-11 05:37:53,265: ============================================================
2022-05-11 05:38:39,768: time cost, forward:0.1722749926579345, backward:0.10428759937004682, data cost:0.18997269462778094 
2022-05-11 05:38:39,768: ============================================================
2022-05-11 05:38:39,768: Epoch 16/38 Batch 2100/7662 eta: 22:29:35.042309	Training Loss 0.1875 (0.1797)	Training Prec@1 98.438 (99.308)	Training Prec@5 99.805 (99.778)	
2022-05-11 05:38:39,769: ============================================================
2022-05-11 05:39:26,249: time cost, forward:0.1722161600729616, backward:0.10428511310350141, data cost:0.18994504974993212 
2022-05-11 05:39:26,250: ============================================================
2022-05-11 05:39:26,250: Epoch 16/38 Batch 2200/7662 eta: 22:28:09.932904	Training Loss 0.1897 (0.1800)	Training Prec@1 99.219 (99.301)	Training Prec@5 100.000 (99.776)	
2022-05-11 05:39:26,250: ============================================================
2022-05-11 05:40:12,779: time cost, forward:0.1721610811390323, backward:0.10428415520806165, data cost:0.18993996557540196 
2022-05-11 05:40:12,779: ============================================================
2022-05-11 05:40:12,779: Epoch 16/38 Batch 2300/7662 eta: 22:28:47.059107	Training Loss 0.1872 (0.1803)	Training Prec@1 99.609 (99.295)	Training Prec@5 100.000 (99.776)	
2022-05-11 05:40:12,779: ============================================================
2022-05-11 05:40:59,254: time cost, forward:0.172110503889611, backward:0.10428189694657829, data cost:0.18991430265896517 
2022-05-11 05:40:59,254: ============================================================
2022-05-11 05:40:59,255: Epoch 16/38 Batch 2400/7662 eta: 22:26:27.095631	Training Loss 0.1948 (0.1806)	Training Prec@1 98.828 (99.289)	Training Prec@5 99.805 (99.774)	
2022-05-11 05:40:59,255: ============================================================
2022-05-11 05:41:45,743: time cost, forward:0.172067524767628, backward:0.10428157573988457, data cost:0.18989113875988628 
2022-05-11 05:41:45,743: ============================================================
2022-05-11 05:41:45,743: Epoch 16/38 Batch 2500/7662 eta: 22:26:03.498253	Training Loss 0.1803 (0.1809)	Training Prec@1 99.609 (99.284)	Training Prec@5 99.609 (99.770)	
2022-05-11 05:41:45,743: ============================================================
2022-05-11 05:42:32,222: time cost, forward:0.17202716270012322, backward:0.10427991772395181, data cost:0.18986829962809298 
2022-05-11 05:42:32,222: ============================================================
2022-05-11 05:42:32,222: Epoch 16/38 Batch 2600/7662 eta: 22:25:00.018976	Training Loss 0.1949 (0.1812)	Training Prec@1 99.023 (99.278)	Training Prec@5 99.609 (99.765)	
2022-05-11 05:42:32,222: ============================================================
2022-05-11 05:43:18,701: time cost, forward:0.17199070942141295, backward:0.10427815801967467, data cost:0.18984584015093278 
2022-05-11 05:43:18,701: ============================================================
2022-05-11 05:43:18,701: Epoch 16/38 Batch 2700/7662 eta: 22:24:13.516023	Training Loss 0.1976 (0.1814)	Training Prec@1 98.828 (99.278)	Training Prec@5 99.805 (99.765)	
2022-05-11 05:43:18,701: ============================================================
2022-05-11 05:44:05,178: time cost, forward:0.17195923697228685, backward:0.10427661664403307, data cost:0.1898218673141823 
2022-05-11 05:44:05,178: ============================================================
2022-05-11 05:44:05,178: Epoch 16/38 Batch 2800/7662 eta: 22:23:23.909087	Training Loss 0.1861 (0.1817)	Training Prec@1 98.828 (99.272)	Training Prec@5 99.805 (99.764)	
2022-05-11 05:44:05,178: ============================================================
2022-05-11 05:44:51,662: time cost, forward:0.1719285818411178, backward:0.10427437703664569, data cost:0.18980430865871697 
2022-05-11 05:44:51,663: ============================================================
2022-05-11 05:44:51,663: Epoch 16/38 Batch 2900/7662 eta: 22:22:49.853642	Training Loss 0.1803 (0.1820)	Training Prec@1 99.414 (99.269)	Training Prec@5 99.805 (99.762)	
2022-05-11 05:44:51,663: ============================================================
2022-05-11 05:45:38,171: time cost, forward:0.17190163530640382, backward:0.10427456722532999, data cost:0.18979170617360835 
2022-05-11 05:45:38,171: ============================================================
2022-05-11 05:45:38,171: Epoch 16/38 Batch 3000/7662 eta: 22:22:44.755363	Training Loss 0.1859 (0.1822)	Training Prec@1 99.023 (99.264)	Training Prec@5 100.000 (99.760)	
2022-05-11 05:45:38,171: ============================================================
2022-05-11 05:46:24,740: time cost, forward:0.1718931258898006, backward:0.10427407435195298, data cost:0.18978364392994834 
2022-05-11 05:46:24,740: ============================================================
2022-05-11 05:46:24,741: Epoch 16/38 Batch 3100/7662 eta: 22:23:44.579230	Training Loss 0.1796 (0.1824)	Training Prec@1 99.609 (99.261)	Training Prec@5 100.000 (99.759)	
2022-05-11 05:46:24,741: ============================================================
2022-05-11 05:47:11,213: time cost, forward:0.17186198073575257, backward:0.10427418825364776, data cost:0.18976860495051878 
2022-05-11 05:47:11,213: ============================================================
2022-05-11 05:47:11,213: Epoch 16/38 Batch 3200/7662 eta: 22:20:10.598117	Training Loss 0.1932 (0.1826)	Training Prec@1 99.414 (99.254)	Training Prec@5 99.805 (99.756)	
2022-05-11 05:47:11,213: ============================================================
2022-05-11 05:47:57,702: time cost, forward:0.17183826178556214, backward:0.10427304859340607, data cost:0.1897550074394344 
2022-05-11 05:47:57,703: ============================================================
2022-05-11 05:47:57,703: Epoch 16/38 Batch 3300/7662 eta: 22:19:52.783952	Training Loss 0.1949 (0.1828)	Training Prec@1 98.828 (99.250)	Training Prec@5 99.609 (99.755)	
2022-05-11 05:47:57,703: ============================================================
2022-05-11 05:48:44,180: time cost, forward:0.17181193853133073, backward:0.1042713522034275, data cost:0.1897445002104402 
2022-05-11 05:48:44,180: ============================================================
2022-05-11 05:48:44,180: Epoch 16/38 Batch 3400/7662 eta: 22:18:45.559253	Training Loss 0.1906 (0.1831)	Training Prec@1 98.828 (99.247)	Training Prec@5 99.805 (99.754)	
2022-05-11 05:48:44,180: ============================================================
2022-05-11 05:49:30,670: time cost, forward:0.17179227508998454, backward:0.10426872455927262, data cost:0.18973317361620706 
2022-05-11 05:49:30,670: ============================================================
2022-05-11 05:49:30,670: Epoch 16/38 Batch 3500/7662 eta: 22:18:20.493635	Training Loss 0.1832 (0.1832)	Training Prec@1 98.633 (99.242)	Training Prec@5 100.000 (99.752)	
2022-05-11 05:49:30,670: ============================================================
2022-05-11 05:50:17,153: time cost, forward:0.17177286993367502, backward:0.10426679747937355, data cost:0.1897215992916157 
2022-05-11 05:50:17,153: ============================================================
2022-05-11 05:50:17,153: Epoch 16/38 Batch 3600/7662 eta: 22:17:22.935732	Training Loss 0.1944 (0.1834)	Training Prec@1 98.242 (99.237)	Training Prec@5 99.609 (99.752)	
2022-05-11 05:50:17,154: ============================================================
2022-05-11 05:51:03,636: time cost, forward:0.1717498811008673, backward:0.10426592704379001, data cost:0.189713665845427 
2022-05-11 05:51:03,636: ============================================================
2022-05-11 05:51:03,636: Epoch 16/38 Batch 3700/7662 eta: 22:16:35.075156	Training Loss 0.1921 (0.1836)	Training Prec@1 99.609 (99.232)	Training Prec@5 99.805 (99.750)	
2022-05-11 05:51:03,636: ============================================================
2022-05-11 05:51:50,093: time cost, forward:0.1717264625266151, backward:0.10426510550781877, data cost:0.18970149145153956 
2022-05-11 05:51:50,094: ============================================================
2022-05-11 05:51:50,094: Epoch 16/38 Batch 3800/7662 eta: 22:15:05.732689	Training Loss 0.1801 (0.1838)	Training Prec@1 99.023 (99.229)	Training Prec@5 100.000 (99.749)	
2022-05-11 05:51:50,094: ============================================================
2022-05-11 05:52:36,549: time cost, forward:0.17170384719635345, backward:0.10426208770528883, data cost:0.18969146053923738 
2022-05-11 05:52:36,549: ============================================================
2022-05-11 05:52:36,550: Epoch 16/38 Batch 3900/7662 eta: 22:14:15.638815	Training Loss 0.1961 (0.1839)	Training Prec@1 99.023 (99.226)	Training Prec@5 99.609 (99.748)	
2022-05-11 05:52:36,550: ============================================================
2022-05-11 05:53:22,995: time cost, forward:0.17168067651678545, backward:0.1042609612445111, data cost:0.1896793266390824 
2022-05-11 05:53:22,995: ============================================================
2022-05-11 05:53:22,995: Epoch 16/38 Batch 4000/7662 eta: 22:13:12.194940	Training Loss 0.1989 (0.1841)	Training Prec@1 99.023 (99.222)	Training Prec@5 99.805 (99.748)	
2022-05-11 05:53:22,995: ============================================================
2022-05-11 05:54:09,446: time cost, forward:0.17165920076558694, backward:0.1042608540068024, data cost:0.1896680416959645 
2022-05-11 05:54:09,447: ============================================================
2022-05-11 05:54:09,447: Epoch 16/38 Batch 4100/7662 eta: 22:12:35.475629	Training Loss 0.1888 (0.1842)	Training Prec@1 98.047 (99.217)	Training Prec@5 99.414 (99.746)	
2022-05-11 05:54:09,447: ============================================================
2022-05-11 05:54:55,883: time cost, forward:0.171636914150804, backward:0.10425949664478161, data cost:0.18965627596928522 
2022-05-11 05:54:55,883: ============================================================
2022-05-11 05:54:55,883: Epoch 16/38 Batch 4200/7662 eta: 22:11:22.840162	Training Loss 0.1951 (0.1844)	Training Prec@1 99.219 (99.213)	Training Prec@5 100.000 (99.745)	
2022-05-11 05:54:55,883: ============================================================
2022-05-11 05:55:42,333: time cost, forward:0.17161967527536381, backward:0.10425875325013272, data cost:0.18964443236735012 
2022-05-11 05:55:42,333: ============================================================
2022-05-11 05:55:42,334: Epoch 16/38 Batch 4300/7662 eta: 22:11:01.191360	Training Loss 0.1863 (0.1845)	Training Prec@1 99.609 (99.210)	Training Prec@5 100.000 (99.743)	
2022-05-11 05:55:42,334: ============================================================
2022-05-11 05:56:28,782: time cost, forward:0.1716026242523471, backward:0.10425751473205039, data cost:0.18963391755380044 
2022-05-11 05:56:28,783: ============================================================
2022-05-11 05:56:28,783: Epoch 16/38 Batch 4400/7662 eta: 22:10:12.270015	Training Loss 0.1830 (0.1846)	Training Prec@1 99.023 (99.207)	Training Prec@5 99.805 (99.742)	
2022-05-11 05:56:28,783: ============================================================
2022-05-11 05:57:15,249: time cost, forward:0.17158736920828394, backward:0.10425614664146014, data cost:0.1896269263678536 
2022-05-11 05:57:15,249: ============================================================
2022-05-11 05:57:15,250: Epoch 16/38 Batch 4500/7662 eta: 22:09:55.799210	Training Loss 0.1882 (0.1848)	Training Prec@1 99.023 (99.200)	Training Prec@5 99.414 (99.739)	
2022-05-11 05:57:15,250: ============================================================
2022-05-11 05:58:01,696: time cost, forward:0.17157174473509734, backward:0.10425353651592124, data cost:0.18961832102912227 
2022-05-11 05:58:01,696: ============================================================
2022-05-11 05:58:01,697: Epoch 16/38 Batch 4600/7662 eta: 22:08:35.630381	Training Loss 0.1928 (0.1849)	Training Prec@1 99.414 (99.198)	Training Prec@5 99.609 (99.738)	
2022-05-11 05:58:01,697: ============================================================
2022-05-11 05:58:48,168: time cost, forward:0.1715630033874187, backward:0.10425192083442787, data cost:0.18960780294734536 
2022-05-11 05:58:48,168: ============================================================
2022-05-11 05:58:48,169: Epoch 16/38 Batch 4700/7662 eta: 22:08:32.134795	Training Loss 0.1913 (0.1851)	Training Prec@1 99.609 (99.193)	Training Prec@5 99.805 (99.737)	
2022-05-11 05:58:48,169: ============================================================
2022-05-11 05:59:34,704: time cost, forward:0.17156322828604048, backward:0.10425125665777946, data cost:0.18960159702781937 
2022-05-11 05:59:34,705: ============================================================
2022-05-11 05:59:34,705: Epoch 16/38 Batch 4800/7662 eta: 22:09:35.439585	Training Loss 0.1964 (0.1852)	Training Prec@1 98.047 (99.189)	Training Prec@5 99.609 (99.735)	
2022-05-11 05:59:34,705: ============================================================
2022-05-11 06:00:21,276: time cost, forward:0.17156485378267716, backward:0.10425011336401935, data cost:0.18960223827685208 
2022-05-11 06:00:21,276: ============================================================
2022-05-11 06:00:21,276: Epoch 16/38 Batch 4900/7662 eta: 22:09:49.933386	Training Loss 0.1937 (0.1853)	Training Prec@1 99.414 (99.186)	Training Prec@5 99.805 (99.734)	
2022-05-11 06:00:21,277: ============================================================
2022-05-11 06:01:07,787: time cost, forward:0.17155476535981024, backward:0.10424925146352818, data cost:0.18960137309062763 
2022-05-11 06:01:07,787: ============================================================
2022-05-11 06:01:07,787: Epoch 16/38 Batch 5000/7662 eta: 22:07:18.781965	Training Loss 0.1889 (0.1855)	Training Prec@1 99.414 (99.181)	Training Prec@5 99.609 (99.734)	
2022-05-11 06:01:07,787: ============================================================
2022-05-11 06:01:54,326: time cost, forward:0.17154952305675744, backward:0.10424951376412799, data cost:0.18960120888826168 
2022-05-11 06:01:54,326: ============================================================
2022-05-11 06:01:54,326: Epoch 16/38 Batch 5100/7662 eta: 22:07:20.534286	Training Loss 0.1909 (0.1856)	Training Prec@1 99.023 (99.178)	Training Prec@5 99.805 (99.733)	
2022-05-11 06:01:54,326: ============================================================
2022-05-11 06:02:40,806: time cost, forward:0.17154291369039568, backward:0.10424882431492527, data cost:0.18959207694377778 
2022-05-11 06:02:40,806: ============================================================
2022-05-11 06:02:40,806: Epoch 16/38 Batch 5200/7662 eta: 22:04:53.979214	Training Loss 0.1906 (0.1857)	Training Prec@1 99.414 (99.174)	Training Prec@5 99.609 (99.732)	
2022-05-11 06:02:40,806: ============================================================
2022-05-11 06:03:27,307: time cost, forward:0.17153619235136483, backward:0.10424761620078993, data cost:0.1895881738498945 
2022-05-11 06:03:27,307: ============================================================
2022-05-11 06:03:27,307: Epoch 16/38 Batch 5300/7662 eta: 22:04:42.860729	Training Loss 0.1952 (0.1858)	Training Prec@1 99.414 (99.170)	Training Prec@5 100.000 (99.732)	
2022-05-11 06:03:27,307: ============================================================
2022-05-11 06:04:13,853: time cost, forward:0.17153360777860396, backward:0.10424743058129933, data cost:0.18958805649120247 
2022-05-11 06:04:13,853: ============================================================
2022-05-11 06:04:13,853: Epoch 16/38 Batch 5400/7662 eta: 22:05:13.331330	Training Loss 0.1989 (0.1860)	Training Prec@1 99.414 (99.168)	Training Prec@5 100.000 (99.732)	
2022-05-11 06:04:13,854: ============================================================
2022-05-11 06:05:00,412: time cost, forward:0.17153479940654104, backward:0.1042471468762975, data cost:0.18958708181622289 
2022-05-11 06:05:00,412: ============================================================
2022-05-11 06:05:00,412: Epoch 16/38 Batch 5500/7662 eta: 22:04:47.855894	Training Loss 0.1864 (0.1861)	Training Prec@1 98.242 (99.165)	Training Prec@5 99.414 (99.731)	
2022-05-11 06:05:00,412: ============================================================
2022-05-11 06:05:46,957: time cost, forward:0.17153384903112168, backward:0.1042460909824879, data cost:0.18958644237576222 
2022-05-11 06:05:46,957: ============================================================
2022-05-11 06:05:46,958: Epoch 16/38 Batch 5600/7662 eta: 22:03:39.463727	Training Loss 0.1828 (0.1862)	Training Prec@1 99.023 (99.163)	Training Prec@5 99.805 (99.731)	
2022-05-11 06:05:46,958: ============================================================
2022-05-11 06:06:33,522: time cost, forward:0.17153725671776557, backward:0.1042459564557053, data cost:0.1895839779768979 
2022-05-11 06:06:33,522: ============================================================
2022-05-11 06:06:33,522: Epoch 16/38 Batch 5700/7662 eta: 22:03:25.606545	Training Loss 0.2009 (0.1863)	Training Prec@1 99.023 (99.159)	Training Prec@5 99.805 (99.729)	
2022-05-11 06:06:33,523: ============================================================
2022-05-11 06:07:20,085: time cost, forward:0.17153641210997755, backward:0.10424561840971085, data cost:0.1895835636442829 
2022-05-11 06:07:20,086: ============================================================
2022-05-11 06:07:20,086: Epoch 16/38 Batch 5800/7662 eta: 22:02:36.387164	Training Loss 0.1824 (0.1864)	Training Prec@1 98.633 (99.157)	Training Prec@5 99.805 (99.729)	
2022-05-11 06:07:20,086: ============================================================
2022-05-11 06:08:06,667: time cost, forward:0.171535164163282, backward:0.10424484724027663, data cost:0.189589197826822 
2022-05-11 06:08:06,667: ============================================================
2022-05-11 06:08:06,667: Epoch 16/38 Batch 5900/7662 eta: 22:02:21.060428	Training Loss 0.1863 (0.1865)	Training Prec@1 98.828 (99.154)	Training Prec@5 99.805 (99.728)	
2022-05-11 06:08:06,667: ============================================================
2022-05-11 06:08:53,229: time cost, forward:0.17153224282949084, backward:0.10424475515657791, data cost:0.18959224412870082 
2022-05-11 06:08:53,229: ============================================================
2022-05-11 06:08:53,229: Epoch 16/38 Batch 6000/7662 eta: 22:01:00.364455	Training Loss 0.1987 (0.1866)	Training Prec@1 99.414 (99.150)	Training Prec@5 99.805 (99.727)	
2022-05-11 06:08:53,229: ============================================================
2022-05-11 06:09:39,799: time cost, forward:0.17153146884972628, backward:0.10424483180104718, data cost:0.18959427075339919 
2022-05-11 06:09:39,799: ============================================================
2022-05-11 06:09:39,799: Epoch 16/38 Batch 6100/7662 eta: 22:00:28.510056	Training Loss 0.1852 (0.1867)	Training Prec@1 99.609 (99.145)	Training Prec@5 99.805 (99.724)	
2022-05-11 06:09:39,799: ============================================================
2022-05-11 06:10:26,400: time cost, forward:0.17152659445736634, backward:0.10424409521877967, data cost:0.18960578404312883 
2022-05-11 06:10:26,400: ============================================================
2022-05-11 06:10:26,401: Epoch 16/38 Batch 6200/7662 eta: 22:00:35.048145	Training Loss 0.2001 (0.1868)	Training Prec@1 98.828 (99.143)	Training Prec@5 99.805 (99.724)	
2022-05-11 06:10:26,401: ============================================================
2022-05-11 06:11:13,057: time cost, forward:0.1715270860135735, backward:0.10424419012613231, data cost:0.18962002924688848 
2022-05-11 06:11:13,057: ============================================================
2022-05-11 06:11:13,057: Epoch 16/38 Batch 6300/7662 eta: 22:01:22.042784	Training Loss 0.1919 (0.1868)	Training Prec@1 98.438 (99.141)	Training Prec@5 99.414 (99.723)	
2022-05-11 06:11:13,057: ============================================================
2022-05-11 06:11:59,626: time cost, forward:0.171522155480937, backward:0.10424408198781526, data cost:0.18962389481293074 
2022-05-11 06:11:59,627: ============================================================
2022-05-11 06:11:59,627: Epoch 16/38 Batch 6400/7662 eta: 21:58:07.739385	Training Loss 0.1893 (0.1869)	Training Prec@1 98.828 (99.138)	Training Prec@5 99.414 (99.722)	
2022-05-11 06:11:59,627: ============================================================
2022-05-11 06:12:46,248: time cost, forward:0.171520403521412, backward:0.10424449069992654, data cost:0.18963175946922556 
2022-05-11 06:12:46,248: ============================================================
2022-05-11 06:12:46,248: Epoch 16/38 Batch 6500/7662 eta: 21:58:49.065740	Training Loss 0.1887 (0.1870)	Training Prec@1 98.828 (99.134)	Training Prec@5 99.219 (99.720)	
2022-05-11 06:12:46,248: ============================================================
2022-05-11 06:13:32,949: time cost, forward:0.17151959727507393, backward:0.10424539504186332, data cost:0.1896503052217958 
2022-05-11 06:13:32,950: ============================================================
2022-05-11 06:13:32,950: Epoch 16/38 Batch 6600/7662 eta: 22:00:18.920706	Training Loss 0.1841 (0.1871)	Training Prec@1 97.852 (99.131)	Training Prec@5 98.828 (99.719)	
2022-05-11 06:13:32,950: ============================================================
2022-05-11 06:14:19,622: time cost, forward:0.17152083815167352, backward:0.10424498793509028, data cost:0.18966500274030676 
2022-05-11 06:14:19,622: ============================================================
2022-05-11 06:14:19,622: Epoch 16/38 Batch 6700/7662 eta: 21:58:41.729436	Training Loss 0.1950 (0.1872)	Training Prec@1 98.828 (99.128)	Training Prec@5 99.609 (99.718)	
2022-05-11 06:14:19,622: ============================================================
2022-05-11 06:15:06,245: time cost, forward:0.1715192282124466, backward:0.10424461685957181, data cost:0.18967250992855897 
2022-05-11 06:15:06,246: ============================================================
2022-05-11 06:15:06,246: Epoch 16/38 Batch 6800/7662 eta: 21:56:33.474946	Training Loss 0.1907 (0.1873)	Training Prec@1 99.414 (99.125)	Training Prec@5 99.805 (99.717)	
2022-05-11 06:15:06,246: ============================================================
2022-05-11 06:15:52,879: time cost, forward:0.17151827324229854, backward:0.10424606532942715, data cost:0.18967810885286587 
2022-05-11 06:15:52,879: ============================================================
2022-05-11 06:15:52,879: Epoch 16/38 Batch 6900/7662 eta: 21:56:02.815236	Training Loss 0.1854 (0.1874)	Training Prec@1 99.219 (99.122)	Training Prec@5 99.609 (99.716)	
2022-05-11 06:15:52,879: ============================================================
2022-05-11 06:16:39,439: time cost, forward:0.17151502936818733, backward:0.10424626318109531, data cost:0.1896810884185477 
2022-05-11 06:16:39,439: ============================================================
2022-05-11 06:16:39,439: Epoch 16/38 Batch 7000/7662 eta: 21:53:12.444945	Training Loss 0.1853 (0.1875)	Training Prec@1 99.023 (99.118)	Training Prec@5 99.609 (99.715)	
2022-05-11 06:16:39,439: ============================================================
2022-05-11 06:17:26,092: time cost, forward:0.17151003018922076, backward:0.10424695926445406, data cost:0.18969407197807453 
2022-05-11 06:17:26,092: ============================================================
2022-05-11 06:17:26,092: Epoch 16/38 Batch 7100/7662 eta: 21:55:02.307808	Training Loss 0.1966 (0.1875)	Training Prec@1 99.219 (99.116)	Training Prec@5 100.000 (99.714)	
2022-05-11 06:17:26,092: ============================================================
2022-05-11 06:18:12,680: time cost, forward:0.17150712331180226, backward:0.1042471297301589, data cost:0.18969685061969166 
2022-05-11 06:18:12,681: ============================================================
2022-05-11 06:18:12,681: Epoch 16/38 Batch 7200/7662 eta: 21:52:27.621479	Training Loss 0.1942 (0.1876)	Training Prec@1 98.633 (99.115)	Training Prec@5 99.219 (99.713)	
2022-05-11 06:18:12,681: ============================================================
2022-05-11 06:18:59,303: time cost, forward:0.1715061156974131, backward:0.10424739547846562, data cost:0.18970415699659987 
2022-05-11 06:18:59,304: ============================================================
2022-05-11 06:18:59,304: Epoch 16/38 Batch 7300/7662 eta: 21:52:38.846329	Training Loss 0.1992 (0.1877)	Training Prec@1 99.414 (99.114)	Training Prec@5 99.805 (99.712)	
2022-05-11 06:18:59,304: ============================================================
2022-05-11 06:19:46,007: time cost, forward:0.1715053106775347, backward:0.10424833743052477, data cost:0.18972069808866127 
2022-05-11 06:19:46,008: ============================================================
2022-05-11 06:19:46,008: Epoch 16/38 Batch 7400/7662 eta: 21:54:08.840917	Training Loss 0.1895 (0.1878)	Training Prec@1 99.805 (99.111)	Training Prec@5 100.000 (99.710)	
2022-05-11 06:19:46,008: ============================================================
2022-05-11 06:20:32,700: time cost, forward:0.17150797082799515, backward:0.10424911840738718, data cost:0.18973339244610057 
2022-05-11 06:20:32,700: ============================================================
2022-05-11 06:20:32,701: Epoch 16/38 Batch 7500/7662 eta: 21:53:03.350675	Training Loss 0.1897 (0.1878)	Training Prec@1 99.609 (99.109)	Training Prec@5 100.000 (99.710)	
2022-05-11 06:20:32,701: ============================================================
2022-05-11 06:21:19,374: time cost, forward:0.17150899494521035, backward:0.10424947832772442, data cost:0.18974516774215328 
2022-05-11 06:21:19,374: ============================================================
2022-05-11 06:21:19,374: Epoch 16/38 Batch 7600/7662 eta: 21:51:43.784030	Training Loss 0.1981 (0.1879)	Training Prec@1 99.023 (99.106)	Training Prec@5 99.609 (99.709)	
2022-05-11 06:21:19,374: ============================================================
2022-05-11 06:21:50,401: Epoch: 16/38 eta: 21:51:14.379851	Training Loss 0.1946 (0.1880)	Training Prec@1 98.828 (99.105)	Training Prec@5 99.609 (99.708)
2022-05-11 06:21:50,401: ============================================================
2022-05-11 06:22:38,969: time cost, forward:0.18458925353156197, backward:0.1042294887581257, data cost:0.1993802966493549 
2022-05-11 06:22:38,969: ============================================================
2022-05-11 06:22:38,969: Epoch 17/38 Batch 100/7662 eta: 22:43:03.794898	Training Loss 0.1548 (0.1669)	Training Prec@1 99.609 (99.475)	Training Prec@5 99.805 (99.854)	
2022-05-11 06:22:38,969: ============================================================
2022-05-11 06:23:26,377: time cost, forward:0.1824709925819282, backward:0.10425607283510754, data cost:0.19425195785024058 
2022-05-11 06:23:26,377: ============================================================
2022-05-11 06:23:26,377: Epoch 17/38 Batch 200/7662 eta: 22:10:18.622090	Training Loss 0.1643 (0.1682)	Training Prec@1 99.609 (99.453)	Training Prec@5 99.805 (99.823)	
2022-05-11 06:23:26,377: ============================================================
2022-05-11 06:24:13,836: time cost, forward:0.1818412418748224, backward:0.10428051406324508, data cost:0.19263186821570763 
2022-05-11 06:24:13,836: ============================================================
2022-05-11 06:24:13,836: Epoch 17/38 Batch 300/7662 eta: 22:10:56.850430	Training Loss 0.1659 (0.1686)	Training Prec@1 99.414 (99.438)	Training Prec@5 99.805 (99.819)	
2022-05-11 06:24:13,836: ============================================================
2022-05-11 06:25:01,174: time cost, forward:0.1812438534614735, backward:0.10429368162513676, data cost:0.19180808987533837 
2022-05-11 06:25:01,175: ============================================================
2022-05-11 06:25:01,175: Epoch 17/38 Batch 400/7662 eta: 22:06:46.732031	Training Loss 0.1655 (0.1692)	Training Prec@1 99.609 (99.422)	Training Prec@5 99.805 (99.811)	
2022-05-11 06:25:01,175: ============================================================
2022-05-11 06:25:48,518: time cost, forward:0.18087496403940695, backward:0.10429584382770057, data cost:0.19134073267002144 
2022-05-11 06:25:48,519: ============================================================
2022-05-11 06:25:48,519: Epoch 17/38 Batch 500/7662 eta: 22:06:08.680948	Training Loss 0.1631 (0.1698)	Training Prec@1 99.805 (99.411)	Training Prec@5 100.000 (99.815)	
2022-05-11 06:25:48,519: ============================================================
2022-05-11 06:26:35,959: time cost, forward:0.18077274515155162, backward:0.10428688960003733, data cost:0.19106089332465934 
2022-05-11 06:26:35,960: ============================================================
2022-05-11 06:26:35,960: Epoch 17/38 Batch 600/7662 eta: 22:08:04.340098	Training Loss 0.1770 (0.1706)	Training Prec@1 98.438 (99.417)	Training Prec@5 100.000 (99.820)	
2022-05-11 06:26:35,960: ============================================================
2022-05-11 06:27:23,269: time cost, forward:0.18056306511547432, backward:0.10427892975541143, data cost:0.19081059341266943 
2022-05-11 06:27:23,270: ============================================================
2022-05-11 06:27:23,270: Epoch 17/38 Batch 700/7662 eta: 22:03:36.791326	Training Loss 0.1809 (0.1714)	Training Prec@1 99.023 (99.398)	Training Prec@5 99.609 (99.810)	
2022-05-11 06:27:23,270: ============================================================
2022-05-11 06:28:10,330: time cost, forward:0.1800698314948434, backward:0.10427727776862802, data cost:0.1906418364695524 
2022-05-11 06:28:10,330: ============================================================
2022-05-11 06:28:10,330: Epoch 17/38 Batch 800/7662 eta: 21:55:50.659285	Training Loss 0.1688 (0.1720)	Training Prec@1 100.000 (99.389)	Training Prec@5 100.000 (99.808)	
2022-05-11 06:28:10,330: ============================================================
2022-05-11 06:28:56,853: time cost, forward:0.17907429430986008, backward:0.10428781159329865, data cost:0.1905126380708247 
2022-05-11 06:28:56,853: ============================================================
2022-05-11 06:28:56,853: Epoch 17/38 Batch 900/7662 eta: 21:40:02.854711	Training Loss 0.1708 (0.1724)	Training Prec@1 99.805 (99.381)	Training Prec@5 99.805 (99.809)	
2022-05-11 06:28:56,853: ============================================================
2022-05-11 06:29:43,425: time cost, forward:0.17830321905729887, backward:0.10429796633181032, data cost:0.19043188338523154 
2022-05-11 06:29:43,425: ============================================================
2022-05-11 06:29:43,425: Epoch 17/38 Batch 1000/7662 eta: 21:40:38.348673	Training Loss 0.1751 (0.1729)	Training Prec@1 100.000 (99.373)	Training Prec@5 100.000 (99.804)	
2022-05-11 06:29:43,425: ============================================================
2022-05-11 06:30:29,959: time cost, forward:0.1776582925725352, backward:0.10430176459842644, data cost:0.1903509210737539 
2022-05-11 06:30:29,960: ============================================================
2022-05-11 06:30:29,960: Epoch 17/38 Batch 1100/7662 eta: 21:38:49.246578	Training Loss 0.1826 (0.1735)	Training Prec@1 99.805 (99.369)	Training Prec@5 100.000 (99.802)	
2022-05-11 06:30:29,960: ============================================================
2022-05-11 06:31:16,456: time cost, forward:0.17710624445071313, backward:0.10430414046318556, data cost:0.19026716775552147 
2022-05-11 06:31:16,456: ============================================================
2022-05-11 06:31:16,456: Epoch 17/38 Batch 1200/7662 eta: 21:36:59.355662	Training Loss 0.1811 (0.1741)	Training Prec@1 99.805 (99.365)	Training Prec@5 99.805 (99.801)	
2022-05-11 06:31:16,457: ============================================================
2022-05-11 06:32:02,955: time cost, forward:0.17664343490336287, backward:0.10430591669882876, data cost:0.19019348278148437 
2022-05-11 06:32:02,955: ============================================================
2022-05-11 06:32:02,956: Epoch 17/38 Batch 1300/7662 eta: 21:36:16.866320	Training Loss 0.1782 (0.1744)	Training Prec@1 99.609 (99.357)	Training Prec@5 100.000 (99.800)	
2022-05-11 06:32:02,956: ============================================================
2022-05-11 06:32:49,451: time cost, forward:0.17624622741028442, backward:0.10430538373133215, data cost:0.1901308472792194 
2022-05-11 06:32:49,452: ============================================================
2022-05-11 06:32:49,452: Epoch 17/38 Batch 1400/7662 eta: 21:35:25.108631	Training Loss 0.1879 (0.1748)	Training Prec@1 99.414 (99.358)	Training Prec@5 100.000 (99.802)	
2022-05-11 06:32:49,452: ============================================================
2022-05-11 06:33:35,985: time cost, forward:0.1759107710919116, backward:0.10430710565415599, data cost:0.19009142656816172 
2022-05-11 06:33:35,985: ============================================================
2022-05-11 06:33:35,985: Epoch 17/38 Batch 1500/7662 eta: 21:35:41.544210	Training Loss 0.1826 (0.1752)	Training Prec@1 99.023 (99.350)	Training Prec@5 99.414 (99.801)	
2022-05-11 06:33:35,985: ============================================================
2022-05-11 06:34:22,535: time cost, forward:0.1756381342901596, backward:0.10430908739902289, data cost:0.1900458599791965 
2022-05-11 06:34:22,535: ============================================================
2022-05-11 06:34:22,536: Epoch 17/38 Batch 1600/7662 eta: 21:35:22.409245	Training Loss 0.1895 (0.1756)	Training Prec@1 99.609 (99.347)	Training Prec@5 100.000 (99.797)	
2022-05-11 06:34:22,536: ============================================================
2022-05-11 06:35:09,057: time cost, forward:0.1753950488083218, backward:0.10431197869770663, data cost:0.18999000729498547 
2022-05-11 06:35:09,057: ============================================================
2022-05-11 06:35:09,058: Epoch 17/38 Batch 1700/7662 eta: 21:33:49.117236	Training Loss 0.1790 (0.1760)	Training Prec@1 98.828 (99.340)	Training Prec@5 99.609 (99.795)	
2022-05-11 06:35:09,058: ============================================================
2022-05-11 06:35:55,550: time cost, forward:0.1751527001686796, backward:0.10431388684814012, data cost:0.1899508428016989 
2022-05-11 06:35:55,550: ============================================================
2022-05-11 06:35:55,550: Epoch 17/38 Batch 1800/7662 eta: 21:32:12.963273	Training Loss 0.1868 (0.1764)	Training Prec@1 99.609 (99.335)	Training Prec@5 100.000 (99.792)	
2022-05-11 06:35:55,550: ============================================================
2022-05-11 06:36:42,039: time cost, forward:0.17493829958184007, backward:0.10431486810741454, data cost:0.18991303029595205 
2022-05-11 06:36:42,040: ============================================================
2022-05-11 06:36:42,040: Epoch 17/38 Batch 1900/7662 eta: 21:31:22.020490	Training Loss 0.1841 (0.1768)	Training Prec@1 99.805 (99.329)	Training Prec@5 100.000 (99.791)	
2022-05-11 06:36:42,040: ============================================================
2022-05-11 06:37:28,728: time cost, forward:0.17482733786135926, backward:0.10431795456577624, data cost:0.1898934340226525 
2022-05-11 06:37:28,728: ============================================================
2022-05-11 06:37:28,728: Epoch 17/38 Batch 2000/7662 eta: 21:36:06.846839	Training Loss 0.1817 (0.1771)	Training Prec@1 99.023 (99.319)	Training Prec@5 99.609 (99.788)	
2022-05-11 06:37:28,728: ============================================================
2022-05-11 06:38:15,258: time cost, forward:0.17466040552656328, backward:0.10431888286359768, data cost:0.18986909874511254 
2022-05-11 06:38:15,258: ============================================================
2022-05-11 06:38:15,258: Epoch 17/38 Batch 2100/7662 eta: 21:30:56.083488	Training Loss 0.1734 (0.1775)	Training Prec@1 99.414 (99.316)	Training Prec@5 99.609 (99.787)	
2022-05-11 06:38:15,258: ============================================================
2022-05-11 06:39:01,773: time cost, forward:0.17450580677155636, backward:0.10431869380199785, data cost:0.18984406533269463 
2022-05-11 06:39:01,773: ============================================================
2022-05-11 06:39:01,773: Epoch 17/38 Batch 2200/7662 eta: 21:29:44.482792	Training Loss 0.1794 (0.1778)	Training Prec@1 99.414 (99.312)	Training Prec@5 99.805 (99.786)	
2022-05-11 06:39:01,773: ============================================================
2022-05-11 06:39:48,351: time cost, forward:0.17437800297067185, backward:0.10432096655963037, data cost:0.18983286782522313 
2022-05-11 06:39:48,351: ============================================================
2022-05-11 06:39:48,351: Epoch 17/38 Batch 2300/7662 eta: 21:30:43.150055	Training Loss 0.1867 (0.1781)	Training Prec@1 98.633 (99.306)	Training Prec@5 99.805 (99.784)	
2022-05-11 06:39:48,351: ============================================================
2022-05-11 06:40:34,912: time cost, forward:0.17426386799798405, backward:0.10431915623488751, data cost:0.1898158978998487 
2022-05-11 06:40:34,912: ============================================================
2022-05-11 06:40:34,912: Epoch 17/38 Batch 2400/7662 eta: 21:29:28.306893	Training Loss 0.1821 (0.1783)	Training Prec@1 99.414 (99.302)	Training Prec@5 99.805 (99.783)	
2022-05-11 06:40:34,912: ============================================================
2022-05-11 06:41:21,481: time cost, forward:0.17415461229199933, backward:0.10431927421084401, data cost:0.18980225289807695 
2022-05-11 06:41:21,481: ============================================================
2022-05-11 06:41:21,481: Epoch 17/38 Batch 2500/7662 eta: 21:28:54.188250	Training Loss 0.1944 (0.1786)	Training Prec@1 99.609 (99.296)	Training Prec@5 99.805 (99.782)	
2022-05-11 06:41:21,481: ============================================================
2022-05-11 06:42:08,018: time cost, forward:0.17405459815697194, backward:0.1043191257005657, data cost:0.1897810779658131 
2022-05-11 06:42:08,019: ============================================================
2022-05-11 06:42:08,019: Epoch 17/38 Batch 2600/7662 eta: 21:27:16.388272	Training Loss 0.1809 (0.1789)	Training Prec@1 99.609 (99.291)	Training Prec@5 100.000 (99.779)	
2022-05-11 06:42:08,019: ============================================================
2022-05-11 06:42:54,574: time cost, forward:0.17396448355509025, backward:0.104317847248712, data cost:0.18976695425380552 
2022-05-11 06:42:54,574: ============================================================
2022-05-11 06:42:54,574: Epoch 17/38 Batch 2700/7662 eta: 21:26:59.025058	Training Loss 0.1924 (0.1791)	Training Prec@1 99.219 (99.286)	Training Prec@5 99.805 (99.778)	
2022-05-11 06:42:54,574: ============================================================
2022-05-11 06:43:41,139: time cost, forward:0.17388733159903758, backward:0.10431594889519172, data cost:0.1897513104064331 
2022-05-11 06:43:41,139: ============================================================
2022-05-11 06:43:41,139: Epoch 17/38 Batch 2800/7662 eta: 21:26:28.138784	Training Loss 0.1963 (0.1794)	Training Prec@1 99.414 (99.281)	Training Prec@5 100.000 (99.777)	
2022-05-11 06:43:41,139: ============================================================
2022-05-11 06:44:27,703: time cost, forward:0.17381304845846124, backward:0.10431613219775344, data cost:0.18973784793776124 
2022-05-11 06:44:27,703: ============================================================
2022-05-11 06:44:27,704: Epoch 17/38 Batch 2900/7662 eta: 21:25:41.428634	Training Loss 0.1886 (0.1797)	Training Prec@1 99.414 (99.274)	Training Prec@5 99.609 (99.774)	
2022-05-11 06:44:27,704: ============================================================
2022-05-11 06:45:14,281: time cost, forward:0.1737455265169821, backward:0.10431533155539863, data cost:0.1897286919603033 
2022-05-11 06:45:14,281: ============================================================
2022-05-11 06:45:14,281: Epoch 17/38 Batch 3000/7662 eta: 21:25:15.837522	Training Loss 0.1771 (0.1799)	Training Prec@1 99.805 (99.268)	Training Prec@5 100.000 (99.773)	
2022-05-11 06:45:14,281: ============================================================
2022-05-11 06:46:00,870: time cost, forward:0.17368058021240135, backward:0.1043163306023006, data cost:0.1897240275911994 
2022-05-11 06:46:00,870: ============================================================
2022-05-11 06:46:00,870: Epoch 17/38 Batch 3100/7662 eta: 21:24:48.868336	Training Loss 0.1890 (0.1802)	Training Prec@1 99.219 (99.263)	Training Prec@5 99.805 (99.771)	
2022-05-11 06:46:00,870: ============================================================
2022-05-11 06:46:47,407: time cost, forward:0.17360794823704082, backward:0.10431830627391322, data cost:0.18971327596546972 
2022-05-11 06:46:47,407: ============================================================
2022-05-11 06:46:47,407: Epoch 17/38 Batch 3200/7662 eta: 21:22:35.311858	Training Loss 0.1963 (0.1804)	Training Prec@1 98.633 (99.257)	Training Prec@5 99.219 (99.769)	
2022-05-11 06:46:47,407: ============================================================
2022-05-11 06:47:33,958: time cost, forward:0.17353661561164035, backward:0.1043186796979855, data cost:0.18971220910025208 
2022-05-11 06:47:33,958: ============================================================
2022-05-11 06:47:33,958: Epoch 17/38 Batch 3300/7662 eta: 21:22:12.900822	Training Loss 0.1915 (0.1806)	Training Prec@1 99.023 (99.253)	Training Prec@5 99.609 (99.768)	
2022-05-11 06:47:33,958: ============================================================
2022-05-11 06:48:20,488: time cost, forward:0.17346324504000468, backward:0.10431779290199561, data cost:0.18970880728674203 
2022-05-11 06:48:20,488: ============================================================
2022-05-11 06:48:20,488: Epoch 17/38 Batch 3400/7662 eta: 21:20:51.593024	Training Loss 0.1867 (0.1808)	Training Prec@1 98.828 (99.248)	Training Prec@5 99.414 (99.766)	
2022-05-11 06:48:20,488: ============================================================
2022-05-11 06:49:07,056: time cost, forward:0.17339570844606114, backward:0.10431823419754625, data cost:0.1897166361976399 
2022-05-11 06:49:07,056: ============================================================
2022-05-11 06:49:07,056: Epoch 17/38 Batch 3500/7662 eta: 21:21:07.443749	Training Loss 0.1753 (0.1810)	Training Prec@1 99.805 (99.244)	Training Prec@5 100.000 (99.763)	
2022-05-11 06:49:07,056: ============================================================
2022-05-11 06:49:53,664: time cost, forward:0.17334216361113408, backward:0.10432063132135297, data cost:0.1897232604046668 
2022-05-11 06:49:53,665: ============================================================
2022-05-11 06:49:53,665: Epoch 17/38 Batch 3600/7662 eta: 21:21:27.944083	Training Loss 0.1896 (0.1812)	Training Prec@1 98.828 (99.240)	Training Prec@5 99.805 (99.762)	
2022-05-11 06:49:53,665: ============================================================
2022-05-11 06:50:40,213: time cost, forward:0.17328210623401602, backward:0.10432156700480787, data cost:0.18972398545749125 
2022-05-11 06:50:40,213: ============================================================
2022-05-11 06:50:40,213: Epoch 17/38 Batch 3700/7662 eta: 21:19:01.301793	Training Loss 0.1887 (0.1814)	Training Prec@1 98.633 (99.235)	Training Prec@5 99.414 (99.759)	
2022-05-11 06:50:40,213: ============================================================
2022-05-11 06:51:26,789: time cost, forward:0.17322232466554854, backward:0.10432221777158589, data cost:0.1897349377060037 
2022-05-11 06:51:26,789: ============================================================
2022-05-11 06:51:26,789: Epoch 17/38 Batch 3800/7662 eta: 21:19:01.432683	Training Loss 0.1950 (0.1816)	Training Prec@1 98.828 (99.231)	Training Prec@5 99.805 (99.757)	
2022-05-11 06:51:26,789: ============================================================
2022-05-11 06:52:13,310: time cost, forward:0.17317207387301456, backward:0.10432281130917655, data cost:0.1897249857136212 
2022-05-11 06:52:13,311: ============================================================
2022-05-11 06:52:13,311: Epoch 17/38 Batch 3900/7662 eta: 21:16:44.712957	Training Loss 0.1943 (0.1818)	Training Prec@1 99.219 (99.225)	Training Prec@5 100.000 (99.755)	
2022-05-11 06:52:13,311: ============================================================
2022-05-11 06:52:59,841: time cost, forward:0.1731180727377508, backward:0.10432393987884102, data cost:0.18972344629822388 
2022-05-11 06:52:59,841: ============================================================
2022-05-11 06:52:59,841: Epoch 17/38 Batch 4000/7662 eta: 21:16:13.300940	Training Loss 0.1971 (0.1819)	Training Prec@1 99.023 (99.220)	Training Prec@5 100.000 (99.754)	
2022-05-11 06:52:59,842: ============================================================
2022-05-11 06:53:46,433: time cost, forward:0.173069767324946, backward:0.1043245348007861, data cost:0.18973138815718588 
2022-05-11 06:53:46,434: ============================================================
2022-05-11 06:53:46,434: Epoch 17/38 Batch 4100/7662 eta: 21:17:07.954336	Training Loss 0.1907 (0.1821)	Training Prec@1 99.414 (99.218)	Training Prec@5 99.805 (99.753)	
2022-05-11 06:53:46,434: ============================================================
2022-05-11 06:54:32,999: time cost, forward:0.17302616507304683, backward:0.1043252817759431, data cost:0.18973097519580454 
2022-05-11 06:54:32,999: ============================================================
2022-05-11 06:54:32,999: Epoch 17/38 Batch 4200/7662 eta: 21:15:37.491484	Training Loss 0.1904 (0.1822)	Training Prec@1 99.023 (99.217)	Training Prec@5 99.805 (99.752)	
2022-05-11 06:54:32,999: ============================================================
2022-05-11 06:55:19,582: time cost, forward:0.1729879495736526, backward:0.10432646617858347, data cost:0.18973470987567073 
2022-05-11 06:55:19,583: ============================================================
2022-05-11 06:55:19,583: Epoch 17/38 Batch 4300/7662 eta: 21:15:20.477768	Training Loss 0.1874 (0.1824)	Training Prec@1 99.219 (99.212)	Training Prec@5 99.805 (99.751)	
2022-05-11 06:55:19,583: ============================================================
2022-05-11 06:56:06,132: time cost, forward:0.1729482259227894, backward:0.10432708526259256, data cost:0.18973280381386756 
2022-05-11 06:56:06,132: ============================================================
2022-05-11 06:56:06,132: Epoch 17/38 Batch 4400/7662 eta: 21:13:37.561205	Training Loss 0.1945 (0.1826)	Training Prec@1 98.828 (99.209)	Training Prec@5 99.414 (99.749)	
2022-05-11 06:56:06,132: ============================================================
2022-05-11 06:56:52,676: time cost, forward:0.17290948401241468, backward:0.10432693056859925, data cost:0.18972867985623867 
2022-05-11 06:56:52,676: ============================================================
2022-05-11 06:56:52,676: Epoch 17/38 Batch 4500/7662 eta: 21:12:42.773713	Training Loss 0.2058 (0.1827)	Training Prec@1 98.438 (99.203)	Training Prec@5 99.219 (99.748)	
2022-05-11 06:56:52,676: ============================================================
2022-05-11 06:57:39,211: time cost, forward:0.17287097290355918, backward:0.10432690836912031, data cost:0.1897265858742485 
2022-05-11 06:57:39,211: ============================================================
2022-05-11 06:57:39,211: Epoch 17/38 Batch 4600/7662 eta: 21:11:41.348226	Training Loss 0.2047 (0.1829)	Training Prec@1 98.828 (99.200)	Training Prec@5 99.805 (99.746)	
2022-05-11 06:57:39,212: ============================================================
2022-05-11 06:58:25,790: time cost, forward:0.1728409710628577, backward:0.10432717033486895, data cost:0.18972696809470335 
2022-05-11 06:58:25,791: ============================================================
2022-05-11 06:58:25,791: Epoch 17/38 Batch 4700/7662 eta: 21:12:07.222567	Training Loss 0.1855 (0.1830)	Training Prec@1 99.414 (99.196)	Training Prec@5 99.805 (99.745)	
2022-05-11 06:58:25,791: ============================================================
2022-05-11 06:59:12,409: time cost, forward:0.17281739993452105, backward:0.10432829179225253, data cost:0.18972904569383808 
2022-05-11 06:59:12,409: ============================================================
2022-05-11 06:59:12,409: Epoch 17/38 Batch 4800/7662 eta: 21:12:24.183276	Training Loss 0.1974 (0.1831)	Training Prec@1 98.633 (99.193)	Training Prec@5 99.414 (99.744)	
2022-05-11 06:59:12,409: ============================================================
2022-05-11 06:59:59,032: time cost, forward:0.1727900762026542, backward:0.10432872545429579, data cost:0.18973773098595412 
2022-05-11 06:59:59,032: ============================================================
2022-05-11 06:59:59,033: Epoch 17/38 Batch 4900/7662 eta: 21:11:46.572311	Training Loss 0.1803 (0.1833)	Training Prec@1 99.414 (99.190)	Training Prec@5 100.000 (99.743)	
2022-05-11 06:59:59,033: ============================================================
2022-05-11 07:00:45,634: time cost, forward:0.17275996846326663, backward:0.1043290747573648, data cost:0.18974618898389053 
2022-05-11 07:00:45,634: ============================================================
2022-05-11 07:00:45,634: Epoch 17/38 Batch 5000/7662 eta: 21:10:24.100743	Training Loss 0.1873 (0.1834)	Training Prec@1 98.438 (99.185)	Training Prec@5 99.023 (99.742)	
2022-05-11 07:00:45,634: ============================================================
2022-05-11 07:01:32,274: time cost, forward:0.1727347255197313, backward:0.10432971105970198, data cost:0.18975370129923608 
2022-05-11 07:01:32,274: ============================================================
2022-05-11 07:01:32,274: Epoch 17/38 Batch 5100/7662 eta: 21:10:40.210629	Training Loss 0.1992 (0.1836)	Training Prec@1 98.047 (99.181)	Training Prec@5 99.023 (99.740)	
2022-05-11 07:01:32,274: ============================================================
2022-05-11 07:02:18,895: time cost, forward:0.17270829191939788, backward:0.10433130815501945, data cost:0.18975828661095936 
2022-05-11 07:02:18,896: ============================================================
2022-05-11 07:02:18,896: Epoch 17/38 Batch 5200/7662 eta: 21:09:23.087304	Training Loss 0.1942 (0.1836)	Training Prec@1 99.414 (99.178)	Training Prec@5 100.000 (99.739)	
2022-05-11 07:02:18,896: ============================================================
2022-05-11 07:03:05,520: time cost, forward:0.17268997764875357, backward:0.10433244210275801, data cost:0.1897610658788528 
2022-05-11 07:03:05,521: ============================================================
2022-05-11 07:03:05,521: Epoch 17/38 Batch 5300/7662 eta: 21:08:42.303136	Training Loss 0.1924 (0.1838)	Training Prec@1 99.414 (99.176)	Training Prec@5 99.805 (99.738)	
2022-05-11 07:03:05,521: ============================================================
2022-05-11 07:03:52,147: time cost, forward:0.17267124174612278, backward:0.10433366405100575, data cost:0.18976490646407523 
2022-05-11 07:03:52,148: ============================================================
2022-05-11 07:03:52,148: Epoch 17/38 Batch 5400/7662 eta: 21:07:58.942368	Training Loss 0.1955 (0.1839)	Training Prec@1 98.633 (99.173)	Training Prec@5 99.609 (99.737)	
2022-05-11 07:03:52,148: ============================================================
2022-05-11 07:04:38,803: time cost, forward:0.1726551019488562, backward:0.10433429842711492, data cost:0.18977254762457033 
2022-05-11 07:04:38,804: ============================================================
2022-05-11 07:04:38,804: Epoch 17/38 Batch 5500/7662 eta: 21:07:59.457333	Training Loss 0.1885 (0.1840)	Training Prec@1 99.609 (99.170)	Training Prec@5 99.805 (99.735)	
2022-05-11 07:04:38,804: ============================================================
2022-05-11 07:05:25,393: time cost, forward:0.17263654973554193, backward:0.10433384703193142, data cost:0.18977060554751032 
2022-05-11 07:05:25,393: ============================================================
2022-05-11 07:05:25,394: Epoch 17/38 Batch 5600/7662 eta: 21:05:25.243384	Training Loss 0.1871 (0.1841)	Training Prec@1 99.219 (99.167)	Training Prec@5 99.414 (99.735)	
2022-05-11 07:05:25,394: ============================================================
2022-05-11 07:06:11,997: time cost, forward:0.17261888922714605, backward:0.1043335952598142, data cost:0.18977243131787175 
2022-05-11 07:06:11,998: ============================================================
2022-05-11 07:06:11,998: Epoch 17/38 Batch 5700/7662 eta: 21:05:01.930533	Training Loss 0.1822 (0.1842)	Training Prec@1 99.219 (99.165)	Training Prec@5 99.414 (99.734)	
2022-05-11 07:06:11,998: ============================================================
2022-05-11 07:06:58,616: time cost, forward:0.17260391594192287, backward:0.10433398725493527, data cost:0.1897721892082397 
2022-05-11 07:06:58,616: ============================================================
2022-05-11 07:06:58,616: Epoch 17/38 Batch 5800/7662 eta: 21:04:38.622471	Training Loss 0.1734 (0.1843)	Training Prec@1 99.219 (99.162)	Training Prec@5 99.609 (99.732)	
2022-05-11 07:06:58,616: ============================================================
2022-05-11 07:07:45,215: time cost, forward:0.17259076846456262, backward:0.10433401481885791, data cost:0.18976930930142 
2022-05-11 07:07:45,215: ============================================================
2022-05-11 07:07:45,216: Epoch 17/38 Batch 5900/7662 eta: 21:03:20.706983	Training Loss 0.1876 (0.1844)	Training Prec@1 98.242 (99.160)	Training Prec@5 99.609 (99.732)	
2022-05-11 07:07:45,216: ============================================================
2022-05-11 07:08:31,843: time cost, forward:0.17257957240704158, backward:0.10433568479935712, data cost:0.18976644075479204 
2022-05-11 07:08:31,843: ============================================================
2022-05-11 07:08:31,843: Epoch 17/38 Batch 6000/7662 eta: 21:03:20.021049	Training Loss 0.1943 (0.1845)	Training Prec@1 99.414 (99.157)	Training Prec@5 100.000 (99.730)	
2022-05-11 07:08:31,843: ============================================================
2022-05-11 07:09:18,459: time cost, forward:0.17256751660930073, backward:0.10433633410748859, data cost:0.18976549735556353 
2022-05-11 07:09:18,459: ============================================================
2022-05-11 07:09:18,459: Epoch 17/38 Batch 6100/7662 eta: 21:02:14.793917	Training Loss 0.1732 (0.1846)	Training Prec@1 99.414 (99.153)	Training Prec@5 100.000 (99.729)	
2022-05-11 07:09:18,459: ============================================================
2022-05-11 07:10:05,103: time cost, forward:0.17255656491135143, backward:0.10433718542414994, data cost:0.18976790710002459 
2022-05-11 07:10:05,103: ============================================================
2022-05-11 07:10:05,103: Epoch 17/38 Batch 6200/7662 eta: 21:02:13.205903	Training Loss 0.1865 (0.1848)	Training Prec@1 99.023 (99.150)	Training Prec@5 99.219 (99.728)	
2022-05-11 07:10:05,103: ============================================================
2022-05-11 07:10:51,695: time cost, forward:0.17254068181900434, backward:0.10433771364612038, data cost:0.18976748922662634 
2022-05-11 07:10:51,695: ============================================================
2022-05-11 07:10:51,695: Epoch 17/38 Batch 6300/7662 eta: 21:00:02.542857	Training Loss 0.1974 (0.1848)	Training Prec@1 99.414 (99.147)	Training Prec@5 99.609 (99.727)	
2022-05-11 07:10:51,695: ============================================================
2022-05-11 07:11:38,276: time cost, forward:0.17252374764698933, backward:0.10433769676904787, data cost:0.18976727324102907 
2022-05-11 07:11:38,277: ============================================================
2022-05-11 07:11:38,277: Epoch 17/38 Batch 6400/7662 eta: 20:58:59.189201	Training Loss 0.1948 (0.1849)	Training Prec@1 98.828 (99.143)	Training Prec@5 99.805 (99.725)	
2022-05-11 07:11:38,277: ============================================================
2022-05-11 07:12:24,917: time cost, forward:0.1725130855239232, backward:0.10433832889961304, data cost:0.18976994451513143 
2022-05-11 07:12:24,917: ============================================================
2022-05-11 07:12:24,918: Epoch 17/38 Batch 6500/7662 eta: 20:59:48.521482	Training Loss 0.1725 (0.1851)	Training Prec@1 99.219 (99.140)	Training Prec@5 100.000 (99.724)	
2022-05-11 07:12:24,918: ============================================================
2022-05-11 07:13:11,540: time cost, forward:0.17250224911348264, backward:0.10433842615930217, data cost:0.18977069746347824 
2022-05-11 07:13:11,541: ============================================================
2022-05-11 07:13:11,541: Epoch 17/38 Batch 6600/7662 eta: 20:58:33.046833	Training Loss 0.2091 (0.1851)	Training Prec@1 98.828 (99.138)	Training Prec@5 99.609 (99.724)	
2022-05-11 07:13:11,541: ============================================================
2022-05-11 07:13:58,171: time cost, forward:0.1724922736023127, backward:0.10433897503740237, data cost:0.18977175240802097 
2022-05-11 07:13:58,172: ============================================================
2022-05-11 07:13:58,172: Epoch 17/38 Batch 6700/7662 eta: 20:57:59.482401	Training Loss 0.1863 (0.1852)	Training Prec@1 99.023 (99.136)	Training Prec@5 99.609 (99.723)	
2022-05-11 07:13:58,172: ============================================================
2022-05-11 07:14:44,797: time cost, forward:0.17248277517605712, backward:0.10433995129343586, data cost:0.18977129580361263 
2022-05-11 07:14:44,797: ============================================================
2022-05-11 07:14:44,797: Epoch 17/38 Batch 6800/7662 eta: 20:57:03.949825	Training Loss 0.2079 (0.1853)	Training Prec@1 99.219 (99.134)	Training Prec@5 100.000 (99.722)	
2022-05-11 07:14:44,798: ============================================================
2022-05-11 07:15:31,468: time cost, forward:0.17247617225713324, backward:0.10434086821462507, data cost:0.189774699791011 
2022-05-11 07:15:31,468: ============================================================
2022-05-11 07:15:31,468: Epoch 17/38 Batch 6900/7662 eta: 20:57:30.014597	Training Loss 0.1963 (0.1854)	Training Prec@1 99.219 (99.131)	Training Prec@5 99.805 (99.721)	
2022-05-11 07:15:31,468: ============================================================
2022-05-11 07:16:18,138: time cost, forward:0.17247101504013426, backward:0.10434109119879108, data cost:0.18977761517287767 
2022-05-11 07:16:18,138: ============================================================
2022-05-11 07:16:18,138: Epoch 17/38 Batch 7000/7662 eta: 20:56:42.875984	Training Loss 0.1924 (0.1854)	Training Prec@1 99.023 (99.129)	Training Prec@5 99.805 (99.720)	
2022-05-11 07:16:18,138: ============================================================
2022-05-11 07:17:04,817: time cost, forward:0.17246368526152983, backward:0.10434266613778774, data cost:0.189782372359273 
2022-05-11 07:17:04,817: ============================================================
2022-05-11 07:17:04,817: Epoch 17/38 Batch 7100/7662 eta: 20:56:09.681295	Training Loss 0.1906 (0.1855)	Training Prec@1 99.219 (99.127)	Training Prec@5 99.609 (99.719)	
2022-05-11 07:17:04,817: ============================================================
2022-05-11 07:17:51,521: time cost, forward:0.17245739561797083, backward:0.10434387306121178, data cost:0.18978880835765102 
2022-05-11 07:17:51,521: ============================================================
2022-05-11 07:17:51,522: Epoch 17/38 Batch 7200/7662 eta: 20:56:04.990284	Training Loss 0.1734 (0.1856)	Training Prec@1 99.414 (99.124)	Training Prec@5 99.805 (99.719)	
2022-05-11 07:17:51,522: ============================================================
2022-05-11 07:18:38,249: time cost, forward:0.1724501106245483, backward:0.10435346012687761, data cost:0.1897908694320451 
2022-05-11 07:18:38,249: ============================================================
2022-05-11 07:18:38,249: Epoch 17/38 Batch 7300/7662 eta: 20:55:55.551893	Training Loss 0.2019 (0.1857)	Training Prec@1 97.852 (99.121)	Training Prec@5 99.805 (99.718)	
2022-05-11 07:18:38,250: ============================================================
2022-05-11 07:19:25,033: time cost, forward:0.17244201116359528, backward:0.10437501274358423, data cost:0.18979064814705093 
2022-05-11 07:19:25,033: ============================================================
2022-05-11 07:19:25,033: Epoch 17/38 Batch 7400/7662 eta: 20:56:38.641153	Training Loss 0.1801 (0.1858)	Training Prec@1 98.828 (99.118)	Training Prec@5 99.609 (99.717)	
2022-05-11 07:19:25,033: ============================================================
2022-05-11 07:20:11,835: time cost, forward:0.1724380640558186, backward:0.10439605559646518, data cost:0.18978928390988223 
2022-05-11 07:20:11,835: ============================================================
2022-05-11 07:20:11,836: Epoch 17/38 Batch 7500/7662 eta: 20:56:22.746935	Training Loss 0.2005 (0.1859)	Training Prec@1 99.414 (99.115)	Training Prec@5 99.609 (99.716)	
2022-05-11 07:20:11,836: ============================================================
2022-05-11 07:20:58,649: time cost, forward:0.17243408024162035, backward:0.10441634149547627, data cost:0.1897896935334565 
2022-05-11 07:20:58,650: ============================================================
2022-05-11 07:20:58,650: Epoch 17/38 Batch 7600/7662 eta: 20:55:54.420110	Training Loss 0.1894 (0.1859)	Training Prec@1 98.828 (99.113)	Training Prec@5 99.023 (99.716)	
2022-05-11 07:20:58,650: ============================================================
2022-05-11 07:21:29,505: Epoch: 17/38 eta: 20:55:24.927187	Training Loss 0.1884 (0.1860)	Training Prec@1 98.828 (99.112)	Training Prec@5 99.219 (99.715)
2022-05-11 07:21:29,505: ============================================================
2022-05-11 07:22:20,425: time cost, forward:0.18900622021068225, backward:0.10570324550975453, data cost:0.2172487143314246 
2022-05-11 07:22:20,426: ============================================================
2022-05-11 07:22:20,426: Epoch 18/38 Batch 100/7662 eta: 22:44:09.187214	Training Loss 0.1614 (0.1654)	Training Prec@1 99.414 (99.446)	Training Prec@5 100.000 (99.815)	
2022-05-11 07:22:20,426: ============================================================
2022-05-11 07:23:07,603: time cost, forward:0.1826153616210324, backward:0.10577740621327156, data cost:0.20325119651142676 
2022-05-11 07:23:07,603: ============================================================
2022-05-11 07:23:07,603: Epoch 18/38 Batch 200/7662 eta: 21:03:35.198449	Training Loss 0.1721 (0.1657)	Training Prec@1 99.023 (99.444)	Training Prec@5 99.805 (99.832)	
2022-05-11 07:23:07,603: ============================================================
2022-05-11 07:23:54,819: time cost, forward:0.18046465047625793, backward:0.10581158714549597, data cost:0.1987696571094934 
2022-05-11 07:23:54,819: ============================================================
2022-05-11 07:23:54,819: Epoch 18/38 Batch 300/7662 eta: 21:03:50.712364	Training Loss 0.1762 (0.1668)	Training Prec@1 99.219 (99.430)	Training Prec@5 100.000 (99.835)	
2022-05-11 07:23:54,819: ============================================================
2022-05-11 07:24:41,989: time cost, forward:0.17924276927957558, backward:0.10583294125129107, data cost:0.19656092003174594 
2022-05-11 07:24:41,989: ============================================================
2022-05-11 07:24:41,989: Epoch 18/38 Batch 400/7662 eta: 21:01:49.312673	Training Loss 0.1730 (0.1676)	Training Prec@1 99.219 (99.412)	Training Prec@5 99.805 (99.820)	
2022-05-11 07:24:41,989: ============================================================
2022-05-11 07:25:29,190: time cost, forward:0.1786400631577792, backward:0.10584362379773585, data cost:0.1951735502254509 
2022-05-11 07:25:29,190: ============================================================
2022-05-11 07:25:29,190: Epoch 18/38 Batch 500/7662 eta: 21:01:51.367575	Training Loss 0.1755 (0.1683)	Training Prec@1 99.023 (99.414)	Training Prec@5 99.805 (99.819)	
2022-05-11 07:25:29,190: ============================================================
2022-05-11 07:26:16,114: time cost, forward:0.17780654219434736, backward:0.10584769981333329, data cost:0.19422026150214652 
2022-05-11 07:26:16,114: ============================================================
2022-05-11 07:26:16,114: Epoch 18/38 Batch 600/7662 eta: 20:53:41.108331	Training Loss 0.1651 (0.1689)	Training Prec@1 99.805 (99.414)	Training Prec@5 100.000 (99.819)	
2022-05-11 07:26:16,114: ============================================================
2022-05-11 07:27:02,818: time cost, forward:0.17686813651918512, backward:0.10584133206860019, data cost:0.1935634647145633 
2022-05-11 07:27:02,819: ============================================================
2022-05-11 07:27:02,819: Epoch 18/38 Batch 700/7662 eta: 20:47:01.666694	Training Loss 0.1626 (0.1697)	Training Prec@1 100.000 (99.406)	Training Prec@5 100.000 (99.818)	
2022-05-11 07:27:02,819: ============================================================
2022-05-11 07:27:49,530: time cost, forward:0.17617292487725747, backward:0.10583644098274698, data cost:0.1930842196687739 
2022-05-11 07:27:49,530: ============================================================
2022-05-11 07:27:49,530: Epoch 18/38 Batch 800/7662 eta: 20:46:26.336761	Training Loss 0.1830 (0.1702)	Training Prec@1 99.219 (99.407)	Training Prec@5 99.805 (99.818)	
2022-05-11 07:27:49,530: ============================================================
2022-05-11 07:28:36,248: time cost, forward:0.17562260113250427, backward:0.10583256481751982, data cost:0.19272965106603435 
2022-05-11 07:28:36,249: ============================================================
2022-05-11 07:28:36,249: Epoch 18/38 Batch 900/7662 eta: 20:45:51.189843	Training Loss 0.1761 (0.1708)	Training Prec@1 99.219 (99.401)	Training Prec@5 100.000 (99.814)	
2022-05-11 07:28:36,249: ============================================================
2022-05-11 07:29:22,974: time cost, forward:0.17520449684188888, backward:0.10584269581852972, data cost:0.19241926094910522 
2022-05-11 07:29:22,974: ============================================================
2022-05-11 07:29:22,974: Epoch 18/38 Batch 1000/7662 eta: 20:45:15.922866	Training Loss 0.1734 (0.1712)	Training Prec@1 99.609 (99.395)	Training Prec@5 99.805 (99.813)	
2022-05-11 07:29:22,975: ============================================================
2022-05-11 07:30:09,759: time cost, forward:0.17484361459386685, backward:0.1058372733156935, data cost:0.19223339499073533 
2022-05-11 07:30:09,759: ============================================================
2022-05-11 07:30:09,759: Epoch 18/38 Batch 1100/7662 eta: 20:46:03.375344	Training Loss 0.1832 (0.1718)	Training Prec@1 99.414 (99.388)	Training Prec@5 99.609 (99.813)	
2022-05-11 07:30:09,759: ============================================================
2022-05-11 07:30:56,538: time cost, forward:0.17457783033293023, backward:0.1058360239781371, data cost:0.19205164849708437 
2022-05-11 07:30:56,538: ============================================================
2022-05-11 07:30:56,538: Epoch 18/38 Batch 1200/7662 eta: 20:45:07.399045	Training Loss 0.1701 (0.1722)	Training Prec@1 99.609 (99.382)	Training Prec@5 99.805 (99.807)	
2022-05-11 07:30:56,538: ============================================================
2022-05-11 07:31:43,300: time cost, forward:0.1743287463845245, backward:0.1058335058316531, data cost:0.19190953326647422 
2022-05-11 07:31:43,300: ============================================================
2022-05-11 07:31:43,300: Epoch 18/38 Batch 1300/7662 eta: 20:43:54.015808	Training Loss 0.1770 (0.1727)	Training Prec@1 99.023 (99.375)	Training Prec@5 99.805 (99.804)	
2022-05-11 07:31:43,301: ============================================================
2022-05-11 07:32:29,950: time cost, forward:0.1741086107394455, backward:0.10577178393371452, data cost:0.19177430131079215 
2022-05-11 07:32:29,951: ============================================================
2022-05-11 07:32:29,951: Epoch 18/38 Batch 1400/7662 eta: 20:40:08.588120	Training Loss 0.1830 (0.1732)	Training Prec@1 99.023 (99.369)	Training Prec@5 99.414 (99.802)	
2022-05-11 07:32:29,951: ============================================================
2022-05-11 07:33:16,557: time cost, forward:0.17391868795531046, backward:0.10567430626002051, data cost:0.19166183058145128 
2022-05-11 07:33:16,557: ============================================================
2022-05-11 07:33:16,557: Epoch 18/38 Batch 1500/7662 eta: 20:38:11.813970	Training Loss 0.1727 (0.1736)	Training Prec@1 99.023 (99.356)	Training Prec@5 100.000 (99.797)	
2022-05-11 07:33:16,557: ============================================================
2022-05-11 07:34:03,288: time cost, forward:0.17375299123915527, backward:0.10568762004487287, data cost:0.19155158379288148 
2022-05-11 07:34:03,288: ============================================================
2022-05-11 07:34:03,288: Epoch 18/38 Batch 1600/7662 eta: 20:40:43.927004	Training Loss 0.1783 (0.1740)	Training Prec@1 98.828 (99.354)	Training Prec@5 100.000 (99.796)	
2022-05-11 07:34:03,288: ============================================================
2022-05-11 07:34:49,991: time cost, forward:0.17359825496886883, backward:0.10569579773892228, data cost:0.1914496256226017 
2022-05-11 07:34:49,991: ============================================================
2022-05-11 07:34:49,991: Epoch 18/38 Batch 1700/7662 eta: 20:39:13.014463	Training Loss 0.1924 (0.1744)	Training Prec@1 99.805 (99.343)	Training Prec@5 100.000 (99.792)	
2022-05-11 07:34:49,991: ============================================================
2022-05-11 07:35:37,416: time cost, forward:0.1738632609275661, backward:0.10570755052593034, data cost:0.19134852381266773 
2022-05-11 07:35:37,416: ============================================================
2022-05-11 07:35:37,417: Epoch 18/38 Batch 1800/7662 eta: 20:57:35.091184	Training Loss 0.1932 (0.1747)	Training Prec@1 98.438 (99.331)	Training Prec@5 99.805 (99.788)	
2022-05-11 07:35:37,417: ============================================================
2022-05-11 07:36:24,213: time cost, forward:0.17374042274450993, backward:0.10571657638288662, data cost:0.1912820388167202 
2022-05-11 07:36:24,214: ============================================================
2022-05-11 07:36:24,214: Epoch 18/38 Batch 1900/7662 eta: 20:40:08.793778	Training Loss 0.1899 (0.1751)	Training Prec@1 98.828 (99.323)	Training Prec@5 99.805 (99.786)	
2022-05-11 07:36:24,214: ============================================================
2022-05-11 07:37:11,073: time cost, forward:0.17367598639541176, backward:0.10568662748866346, data cost:0.19125666887894935 
2022-05-11 07:37:11,073: ============================================================
2022-05-11 07:37:11,073: Epoch 18/38 Batch 2000/7662 eta: 20:41:01.128823	Training Loss 0.1802 (0.1755)	Training Prec@1 99.414 (99.317)	Training Prec@5 100.000 (99.783)	
2022-05-11 07:37:11,073: ============================================================
2022-05-11 07:37:58,535: time cost, forward:0.17394535288235982, backward:0.1056295303346544, data cost:0.19121473490936294 
2022-05-11 07:37:58,539: ============================================================
2022-05-11 07:37:58,540: Epoch 18/38 Batch 2100/7662 eta: 20:56:17.901969	Training Loss 0.1767 (0.1758)	Training Prec@1 99.219 (99.310)	Training Prec@5 99.609 (99.781)	
2022-05-11 07:37:58,540: ============================================================
2022-05-11 07:38:46,239: time cost, forward:0.17431003888014393, backward:0.10560326773559793, data cost:0.19114938948901472 
2022-05-11 07:38:46,240: ============================================================
2022-05-11 07:38:46,240: Epoch 18/38 Batch 2200/7662 eta: 21:01:41.897885	Training Loss 0.1839 (0.1762)	Training Prec@1 99.414 (99.304)	Training Prec@5 99.805 (99.779)	
2022-05-11 07:38:46,240: ============================================================
2022-05-11 07:39:33,272: time cost, forward:0.1743253417095966, backward:0.1055867766338413, data cost:0.19109367339079045 
2022-05-11 07:39:33,273: ============================================================
2022-05-11 07:39:33,273: Epoch 18/38 Batch 2300/7662 eta: 20:43:15.930863	Training Loss 0.1794 (0.1765)	Training Prec@1 99.023 (99.297)	Training Prec@5 99.609 (99.777)	
2022-05-11 07:39:33,273: ============================================================
2022-05-11 07:40:20,959: time cost, forward:0.17461740379285792, backward:0.10553905267226492, data cost:0.19107726108237771 
2022-05-11 07:40:20,959: ============================================================
2022-05-11 07:40:20,960: Epoch 18/38 Batch 2400/7662 eta: 20:59:44.600854	Training Loss 0.1869 (0.1768)	Training Prec@1 98.828 (99.293)	Training Prec@5 100.000 (99.775)	
2022-05-11 07:40:20,960: ============================================================
2022-05-11 07:41:08,805: time cost, forward:0.17492268170390715, backward:0.10553664920710716, data cost:0.19104260680865365 
2022-05-11 07:41:08,805: ============================================================
2022-05-11 07:41:08,806: Epoch 18/38 Batch 2500/7662 eta: 21:03:09.632248	Training Loss 0.1880 (0.1771)	Training Prec@1 98.828 (99.287)	Training Prec@5 99.609 (99.772)	
2022-05-11 07:41:08,806: ============================================================
2022-05-11 07:41:56,248: time cost, forward:0.1751013471787597, backward:0.10550706429681488, data cost:0.19099981191296814 
2022-05-11 07:41:56,248: ============================================================
2022-05-11 07:41:56,248: Epoch 18/38 Batch 2600/7662 eta: 20:51:43.036074	Training Loss 0.1957 (0.1774)	Training Prec@1 99.023 (99.281)	Training Prec@5 100.000 (99.770)	
2022-05-11 07:41:56,248: ============================================================
2022-05-11 07:42:43,143: time cost, forward:0.17507314257994544, backward:0.10546940474564961, data cost:0.1909551196471105 
2022-05-11 07:42:43,143: ============================================================
2022-05-11 07:42:43,143: Epoch 18/38 Batch 2700/7662 eta: 20:36:29.603094	Training Loss 0.1841 (0.1776)	Training Prec@1 99.414 (99.275)	Training Prec@5 99.805 (99.768)	
2022-05-11 07:42:43,144: ============================================================
2022-05-11 07:43:30,243: time cost, forward:0.17512727150026072, backward:0.10543212894032196, data cost:0.19091171611841767 
2022-05-11 07:43:30,244: ============================================================
2022-05-11 07:43:30,244: Epoch 18/38 Batch 2800/7662 eta: 20:41:07.251288	Training Loss 0.1948 (0.1779)	Training Prec@1 99.023 (99.268)	Training Prec@5 100.000 (99.766)	
2022-05-11 07:43:30,244: ============================================================
2022-05-11 07:44:17,247: time cost, forward:0.17515239817555833, backward:0.10539711397571702, data cost:0.19086372650833366 
2022-05-11 07:44:17,247: ============================================================
2022-05-11 07:44:17,247: Epoch 18/38 Batch 2900/7662 eta: 20:37:46.298923	Training Loss 0.1795 (0.1782)	Training Prec@1 99.609 (99.264)	Training Prec@5 99.805 (99.764)	
2022-05-11 07:44:17,247: ============================================================
2022-05-11 07:45:04,057: time cost, forward:0.17511707745062666, backward:0.10536512433389458, data cost:0.19081251984558412 
2022-05-11 07:45:04,095: ============================================================
2022-05-11 07:45:04,095: Epoch 18/38 Batch 3000/7662 eta: 20:32:54.273283	Training Loss 0.1963 (0.1784)	Training Prec@1 99.023 (99.259)	Training Prec@5 99.609 (99.761)	
2022-05-11 07:45:04,095: ============================================================
2022-05-11 07:45:50,899: time cost, forward:0.17507990639838297, backward:0.10533754454000645, data cost:0.19077654144924738 
2022-05-11 07:45:50,899: ============================================================
2022-05-11 07:45:50,899: Epoch 18/38 Batch 3100/7662 eta: 20:30:58.078340	Training Loss 0.1973 (0.1786)	Training Prec@1 98.633 (99.255)	Training Prec@5 99.414 (99.761)	
2022-05-11 07:45:50,899: ============================================================
2022-05-11 07:46:37,795: time cost, forward:0.17506770306581554, backward:0.10530982437861193, data cost:0.19073881257806358 
2022-05-11 07:46:37,795: ============================================================
2022-05-11 07:46:37,795: Epoch 18/38 Batch 3200/7662 eta: 20:32:37.275176	Training Loss 0.1921 (0.1789)	Training Prec@1 98.047 (99.250)	Training Prec@5 99.414 (99.759)	
2022-05-11 07:46:37,796: ============================================================
2022-05-11 07:47:24,709: time cost, forward:0.1750535619515439, backward:0.10528316581635881, data cost:0.1907117569869343 
2022-05-11 07:47:24,709: ============================================================
2022-05-11 07:47:24,709: Epoch 18/38 Batch 3300/7662 eta: 20:32:17.384120	Training Loss 0.1904 (0.1791)	Training Prec@1 99.219 (99.245)	Training Prec@5 99.805 (99.758)	
2022-05-11 07:47:24,709: ============================================================
2022-05-11 07:48:11,584: time cost, forward:0.17503460150110123, backward:0.10525703724779498, data cost:0.19068106864262552 
2022-05-11 07:48:11,584: ============================================================
2022-05-11 07:48:11,584: Epoch 18/38 Batch 3400/7662 eta: 20:30:29.650664	Training Loss 0.1959 (0.1793)	Training Prec@1 99.414 (99.240)	Training Prec@5 99.609 (99.757)	
2022-05-11 07:48:11,584: ============================================================
2022-05-11 07:48:58,554: time cost, forward:0.17504622575793138, backward:0.1052345226546225, data cost:0.19064826684599095 
2022-05-11 07:48:58,554: ============================================================
2022-05-11 07:48:58,554: Epoch 18/38 Batch 3500/7662 eta: 20:32:11.897179	Training Loss 0.2005 (0.1795)	Training Prec@1 98.438 (99.236)	Training Prec@5 99.609 (99.757)	
2022-05-11 07:48:58,554: ============================================================
2022-05-11 07:49:45,359: time cost, forward:0.17501526436695758, backward:0.10521052432875065, data cost:0.19061650889355064 
2022-05-11 07:49:45,360: ============================================================
2022-05-11 07:49:45,360: Epoch 18/38 Batch 3600/7662 eta: 20:27:06.751244	Training Loss 0.1825 (0.1797)	Training Prec@1 99.023 (99.232)	Training Prec@5 99.805 (99.756)	
2022-05-11 07:49:45,360: ============================================================
2022-05-11 07:50:31,907: time cost, forward:0.17491792188718144, backward:0.10518836330548915, data cost:0.19058382030950105 
2022-05-11 07:50:31,907: ============================================================
2022-05-11 07:50:31,908: Epoch 18/38 Batch 3700/7662 eta: 20:19:34.461675	Training Loss 0.1885 (0.1799)	Training Prec@1 98.047 (99.227)	Training Prec@5 99.414 (99.755)	
2022-05-11 07:50:31,908: ============================================================
2022-05-11 07:51:18,473: time cost, forward:0.17482625317906167, backward:0.10516868700758976, data cost:0.19055562064534082 
2022-05-11 07:51:18,473: ============================================================
2022-05-11 07:51:18,474: Epoch 18/38 Batch 3800/7662 eta: 20:19:16.835037	Training Loss 0.1899 (0.1800)	Training Prec@1 100.000 (99.224)	Training Prec@5 100.000 (99.755)	
2022-05-11 07:51:18,474: ============================================================
2022-05-11 07:52:05,046: time cost, forward:0.17474367472415522, backward:0.10514897283880366, data cost:0.19052764708398398 
2022-05-11 07:52:05,046: ============================================================
2022-05-11 07:52:05,047: Epoch 18/38 Batch 3900/7662 eta: 20:18:40.895569	Training Loss 0.1865 (0.1802)	Training Prec@1 99.023 (99.220)	Training Prec@5 99.805 (99.754)	
2022-05-11 07:52:05,047: ============================================================
2022-05-11 07:52:51,602: time cost, forward:0.17466130087333312, backward:0.10512948888753408, data cost:0.19050121003313344 
2022-05-11 07:52:51,603: ============================================================
2022-05-11 07:52:51,603: Epoch 18/38 Batch 4000/7662 eta: 20:17:28.107075	Training Loss 0.1928 (0.1804)	Training Prec@1 98.438 (99.217)	Training Prec@5 99.609 (99.753)	
2022-05-11 07:52:51,603: ============================================================
2022-05-11 07:53:38,134: time cost, forward:0.17457520941403704, backward:0.10511219731247347, data cost:0.19047662553975686 
2022-05-11 07:53:38,134: ============================================================
2022-05-11 07:53:38,134: Epoch 18/38 Batch 4100/7662 eta: 20:16:02.487904	Training Loss 0.1878 (0.1805)	Training Prec@1 99.219 (99.214)	Training Prec@5 99.805 (99.752)	
2022-05-11 07:53:38,134: ============================================================
2022-05-11 07:54:24,648: time cost, forward:0.17449367696485454, backward:0.1050946775519527, data cost:0.1904496696910054 
2022-05-11 07:54:24,649: ============================================================
2022-05-11 07:54:24,649: Epoch 18/38 Batch 4200/7662 eta: 20:14:49.753897	Training Loss 0.1829 (0.1807)	Training Prec@1 99.414 (99.210)	Training Prec@5 99.805 (99.751)	
2022-05-11 07:54:24,649: ============================================================
2022-05-11 07:55:11,175: time cost, forward:0.17441821880300645, backward:0.10507776221998294, data cost:0.19042482351696638 
2022-05-11 07:55:11,175: ============================================================
2022-05-11 07:55:11,175: Epoch 18/38 Batch 4300/7662 eta: 20:14:21.968328	Training Loss 0.1848 (0.1809)	Training Prec@1 99.414 (99.206)	Training Prec@5 99.414 (99.749)	
2022-05-11 07:55:11,175: ============================================================
2022-05-11 07:55:57,696: time cost, forward:0.17434541554200592, backward:0.10506171046346122, data cost:0.1904005093801073 
2022-05-11 07:55:57,697: ============================================================
2022-05-11 07:55:57,697: Epoch 18/38 Batch 4400/7662 eta: 20:13:27.404513	Training Loss 0.1883 (0.1810)	Training Prec@1 99.609 (99.203)	Training Prec@5 99.805 (99.748)	
2022-05-11 07:55:57,697: ============================================================
2022-05-11 07:56:44,221: time cost, forward:0.17427481325712965, backward:0.10504654100879772, data cost:0.19037868574370964 
2022-05-11 07:56:44,221: ============================================================
2022-05-11 07:56:44,222: Epoch 18/38 Batch 4500/7662 eta: 20:12:46.356810	Training Loss 0.1964 (0.1811)	Training Prec@1 98.828 (99.200)	Training Prec@5 100.000 (99.747)	
2022-05-11 07:56:44,222: ============================================================
2022-05-11 07:57:30,759: time cost, forward:0.1742101890363235, backward:0.10503159198690482, data cost:0.19035866426939446 
2022-05-11 07:57:30,759: ============================================================
2022-05-11 07:57:30,760: Epoch 18/38 Batch 4600/7662 eta: 20:12:20.349932	Training Loss 0.1901 (0.1813)	Training Prec@1 99.219 (99.198)	Training Prec@5 99.805 (99.746)	
2022-05-11 07:57:30,760: ============================================================
2022-05-11 07:58:17,324: time cost, forward:0.17415298074071625, backward:0.10501807013530126, data cost:0.1903395672051494 
2022-05-11 07:58:17,324: ============================================================
2022-05-11 07:58:17,324: Epoch 18/38 Batch 4700/7662 eta: 20:12:15.549781	Training Loss 0.1769 (0.1814)	Training Prec@1 98.047 (99.195)	Training Prec@5 99.805 (99.744)	
2022-05-11 07:58:17,324: ============================================================
2022-05-11 07:59:03,844: time cost, forward:0.17409072192566274, backward:0.10500423921647482, data cost:0.19032065722812685 
2022-05-11 07:59:03,844: ============================================================
2022-05-11 07:59:03,845: Epoch 18/38 Batch 4800/7662 eta: 20:10:19.337016	Training Loss 0.1801 (0.1815)	Training Prec@1 99.219 (99.192)	Training Prec@5 99.609 (99.743)	
2022-05-11 07:59:03,845: ============================================================
2022-05-11 07:59:50,393: time cost, forward:0.17403277720108545, backward:0.10499195678790361, data cost:0.19030520136829882 
2022-05-11 07:59:50,394: ============================================================
2022-05-11 07:59:50,394: Epoch 18/38 Batch 4900/7662 eta: 20:10:18.081617	Training Loss 0.1921 (0.1817)	Training Prec@1 99.414 (99.188)	Training Prec@5 100.000 (99.742)	
2022-05-11 07:59:50,394: ============================================================
2022-05-11 08:00:36,955: time cost, forward:0.17398001633064344, backward:0.104980199426192, data cost:0.19029061349302942 
2022-05-11 08:00:36,956: ============================================================
2022-05-11 08:00:36,956: Epoch 18/38 Batch 5000/7662 eta: 20:09:51.661223	Training Loss 0.1913 (0.1818)	Training Prec@1 99.219 (99.183)	Training Prec@5 99.609 (99.740)	
2022-05-11 08:00:36,956: ============================================================
2022-05-11 08:01:23,482: time cost, forward:0.17392673579401352, backward:0.10496781339456483, data cost:0.19027355372332946 
2022-05-11 08:01:23,482: ============================================================
2022-05-11 08:01:23,482: Epoch 18/38 Batch 5100/7662 eta: 20:08:09.214730	Training Loss 0.1959 (0.1820)	Training Prec@1 99.023 (99.181)	Training Prec@5 99.805 (99.739)	
2022-05-11 08:01:23,482: ============================================================
2022-05-11 08:02:10,007: time cost, forward:0.17387662614439744, backward:0.10495570554804816, data cost:0.19025588934410992 
2022-05-11 08:02:10,007: ============================================================
2022-05-11 08:02:10,007: Epoch 18/38 Batch 5200/7662 eta: 20:07:21.393327	Training Loss 0.1868 (0.1821)	Training Prec@1 99.023 (99.178)	Training Prec@5 99.805 (99.738)	
2022-05-11 08:02:10,007: ============================================================
2022-05-11 08:02:56,540: time cost, forward:0.17382841907507698, backward:0.1049446389683689, data cost:0.19023996336232 
2022-05-11 08:02:56,540: ============================================================
2022-05-11 08:02:56,541: Epoch 18/38 Batch 5300/7662 eta: 20:06:46.998104	Training Loss 0.1949 (0.1822)	Training Prec@1 99.414 (99.175)	Training Prec@5 100.000 (99.737)	
2022-05-11 08:02:56,541: ============================================================
2022-05-11 08:03:43,069: time cost, forward:0.1737791962437242, backward:0.1049344182831421, data cost:0.19022638719597224 
2022-05-11 08:03:43,069: ============================================================
2022-05-11 08:03:43,070: Epoch 18/38 Batch 5400/7662 eta: 20:05:54.219690	Training Loss 0.1849 (0.1823)	Training Prec@1 99.414 (99.171)	Training Prec@5 99.805 (99.736)	
2022-05-11 08:03:43,070: ============================================================
2022-05-11 08:04:29,671: time cost, forward:0.17374246002089047, backward:0.10492450567912483, data cost:0.19021521414121859 
2022-05-11 08:04:29,671: ============================================================
2022-05-11 08:04:29,671: Epoch 18/38 Batch 5500/7662 eta: 20:06:59.991639	Training Loss 0.1874 (0.1824)	Training Prec@1 99.023 (99.167)	Training Prec@5 99.805 (99.734)	
2022-05-11 08:04:29,671: ============================================================
2022-05-11 08:05:16,218: time cost, forward:0.17369858484903516, backward:0.10491647326875998, data cost:0.19020159782352436 
2022-05-11 08:05:16,218: ============================================================
2022-05-11 08:05:16,219: Epoch 18/38 Batch 5600/7662 eta: 20:04:49.658949	Training Loss 0.1950 (0.1825)	Training Prec@1 99.219 (99.163)	Training Prec@5 99.805 (99.733)	
2022-05-11 08:05:16,219: ============================================================
2022-05-11 08:06:02,769: time cost, forward:0.1736566420081708, backward:0.10490844052681736, data cost:0.1901889651422857 
2022-05-11 08:06:02,769: ============================================================
2022-05-11 08:06:02,769: Epoch 18/38 Batch 5700/7662 eta: 20:04:08.146488	Training Loss 0.1913 (0.1826)	Training Prec@1 99.219 (99.160)	Training Prec@5 99.805 (99.732)	
2022-05-11 08:06:02,769: ============================================================
2022-05-11 08:06:49,376: time cost, forward:0.17362534496204096, backward:0.1049005264536145, data cost:0.19017754684010135 
2022-05-11 08:06:49,377: ============================================================
2022-05-11 08:06:49,377: Epoch 18/38 Batch 5800/7662 eta: 20:04:49.418212	Training Loss 0.1994 (0.1828)	Training Prec@1 98.242 (99.157)	Training Prec@5 99.805 (99.731)	
2022-05-11 08:06:49,377: ============================================================
2022-05-11 08:07:35,960: time cost, forward:0.1735920928296123, backward:0.10489293097803039, data cost:0.19016584612026238 
2022-05-11 08:07:35,960: ============================================================
2022-05-11 08:07:35,961: Epoch 18/38 Batch 5900/7662 eta: 20:03:26.437674	Training Loss 0.1937 (0.1829)	Training Prec@1 98.438 (99.155)	Training Prec@5 100.000 (99.730)	
2022-05-11 08:07:35,961: ============================================================
2022-05-11 08:08:22,555: time cost, forward:0.1735609951248207, backward:0.10488559007843369, data cost:0.19015522519038666 
2022-05-11 08:08:22,555: ============================================================
2022-05-11 08:08:22,556: Epoch 18/38 Batch 6000/7662 eta: 20:02:56.923264	Training Loss 0.1841 (0.1830)	Training Prec@1 99.609 (99.152)	Training Prec@5 100.000 (99.729)	
2022-05-11 08:08:22,556: ============================================================
2022-05-11 08:09:09,122: time cost, forward:0.17352780230144219, backward:0.10487799918891993, data cost:0.19014450674624614 
2022-05-11 08:09:09,122: ============================================================
2022-05-11 08:09:09,122: Epoch 18/38 Batch 6100/7662 eta: 20:01:26.827576	Training Loss 0.1964 (0.1831)	Training Prec@1 99.219 (99.150)	Training Prec@5 99.609 (99.729)	
2022-05-11 08:09:09,122: ============================================================
2022-05-11 08:09:55,707: time cost, forward:0.17350002365124612, backward:0.10487025686763413, data cost:0.19013260448915495 
2022-05-11 08:09:55,707: ============================================================
2022-05-11 08:09:55,707: Epoch 18/38 Batch 6200/7662 eta: 20:01:08.270892	Training Loss 0.1798 (0.1831)	Training Prec@1 99.219 (99.148)	Training Prec@5 99.805 (99.728)	
2022-05-11 08:09:55,707: ============================================================
2022-05-11 08:10:42,274: time cost, forward:0.17346902312996237, backward:0.10486636367709433, data cost:0.19011871136073216 
2022-05-11 08:10:42,274: ============================================================
2022-05-11 08:10:42,275: Epoch 18/38 Batch 6300/7662 eta: 19:59:54.423040	Training Loss 0.1813 (0.1832)	Training Prec@1 99.805 (99.146)	Training Prec@5 99.805 (99.727)	
2022-05-11 08:10:42,275: ============================================================
2022-05-11 08:11:28,958: time cost, forward:0.17343557199513024, backward:0.104882997020108, data cost:0.19010682574732823 
2022-05-11 08:11:28,958: ============================================================
2022-05-11 08:11:28,958: Epoch 18/38 Batch 6400/7662 eta: 20:02:07.732981	Training Loss 0.1863 (0.1833)	Training Prec@1 98.438 (99.142)	Training Prec@5 99.414 (99.726)	
2022-05-11 08:11:28,958: ============================================================
2022-05-11 08:12:15,675: time cost, forward:0.17340526960137845, backward:0.1049006246460238, data cost:0.19009657723479206 
2022-05-11 08:12:15,675: ============================================================
2022-05-11 08:12:15,676: Epoch 18/38 Batch 6500/7662 eta: 20:02:13.055088	Training Loss 0.1939 (0.1834)	Training Prec@1 98.242 (99.141)	Training Prec@5 99.414 (99.725)	
2022-05-11 08:12:15,676: ============================================================
2022-05-11 08:13:02,349: time cost, forward:0.17337194495642613, backward:0.10491607441723681, data cost:0.19008559121347085 
2022-05-11 08:13:02,350: ============================================================
2022-05-11 08:13:02,350: Epoch 18/38 Batch 6600/7662 eta: 20:00:19.725865	Training Loss 0.2000 (0.1835)	Training Prec@1 98.438 (99.137)	Training Prec@5 99.609 (99.723)	
2022-05-11 08:13:02,350: ============================================================
2022-05-11 08:13:48,899: time cost, forward:0.17333601634704207, backward:0.10491659702125068, data cost:0.1900743650204923 
2022-05-11 08:13:48,899: ============================================================
2022-05-11 08:13:48,899: Epoch 18/38 Batch 6700/7662 eta: 19:56:20.905615	Training Loss 0.1877 (0.1836)	Training Prec@1 98.828 (99.134)	Training Prec@5 100.000 (99.722)	
2022-05-11 08:13:48,900: ============================================================
2022-05-11 08:14:35,426: time cost, forward:0.17330325100418048, backward:0.10490895390668359, data cost:0.19006608096724625 
2022-05-11 08:14:35,427: ============================================================
2022-05-11 08:14:35,427: Epoch 18/38 Batch 6800/7662 eta: 19:54:59.980734	Training Loss 0.2010 (0.1837)	Training Prec@1 99.414 (99.131)	Training Prec@5 100.000 (99.721)	
2022-05-11 08:14:35,427: ============================================================
2022-05-11 08:15:21,974: time cost, forward:0.17327476394471958, backward:0.1049018626386557, data cost:0.19005717614678858 
2022-05-11 08:15:21,974: ============================================================
2022-05-11 08:15:21,974: Epoch 18/38 Batch 6900/7662 eta: 19:54:44.440885	Training Loss 0.1958 (0.1838)	Training Prec@1 99.023 (99.129)	Training Prec@5 100.000 (99.720)	
2022-05-11 08:15:21,974: ============================================================
2022-05-11 08:16:08,524: time cost, forward:0.17324659503822856, backward:0.10489526529417052, data cost:0.19004914518389843 
2022-05-11 08:16:08,525: ============================================================
2022-05-11 08:16:08,525: Epoch 18/38 Batch 7000/7662 eta: 19:54:02.776970	Training Loss 0.1881 (0.1839)	Training Prec@1 99.805 (99.127)	Training Prec@5 99.805 (99.719)	
2022-05-11 08:16:08,525: ============================================================
2022-05-11 08:16:55,051: time cost, forward:0.17321707171644185, backward:0.10488874359120112, data cost:0.1900403205736168 
2022-05-11 08:16:55,051: ============================================================
2022-05-11 08:16:55,052: Epoch 18/38 Batch 7100/7662 eta: 19:52:39.504068	Training Loss 0.1859 (0.1840)	Training Prec@1 99.414 (99.125)	Training Prec@5 99.609 (99.718)	
2022-05-11 08:16:55,052: ============================================================
2022-05-11 08:17:41,571: time cost, forward:0.17318657150300348, backward:0.1048827760168903, data cost:0.19003237706287848 
2022-05-11 08:17:41,571: ============================================================
2022-05-11 08:17:41,572: Epoch 18/38 Batch 7200/7662 eta: 19:51:42.733415	Training Loss 0.1760 (0.1840)	Training Prec@1 100.000 (99.123)	Training Prec@5 100.000 (99.718)	
2022-05-11 08:17:41,572: ============================================================
2022-05-11 08:18:28,121: time cost, forward:0.17316125595238066, backward:0.1048764856502869, data cost:0.1900247304239311 
2022-05-11 08:18:28,121: ============================================================
2022-05-11 08:18:28,121: Epoch 18/38 Batch 7300/7662 eta: 19:51:41.304319	Training Loss 0.2018 (0.1841)	Training Prec@1 99.023 (99.120)	Training Prec@5 99.805 (99.717)	
2022-05-11 08:18:28,121: ============================================================
2022-05-11 08:19:14,624: time cost, forward:0.17313151398870263, backward:0.10487047287721475, data cost:0.19001588858145446 
2022-05-11 08:19:14,624: ============================================================
2022-05-11 08:19:14,624: Epoch 18/38 Batch 7400/7662 eta: 19:49:43.324818	Training Loss 0.1945 (0.1842)	Training Prec@1 98.828 (99.118)	Training Prec@5 99.805 (99.716)	
2022-05-11 08:19:14,624: ============================================================
2022-05-11 08:20:01,149: time cost, forward:0.17310450461438887, backward:0.1048654652481191, data cost:0.19000755975939207 
2022-05-11 08:20:01,149: ============================================================
2022-05-11 08:20:01,150: Epoch 18/38 Batch 7500/7662 eta: 19:49:31.676708	Training Loss 0.1964 (0.1843)	Training Prec@1 97.656 (99.115)	Training Prec@5 99.414 (99.715)	
2022-05-11 08:20:01,150: ============================================================
2022-05-11 08:20:47,675: time cost, forward:0.17307706979846213, backward:0.10486077245779298, data cost:0.19000044947063346 
2022-05-11 08:20:47,675: ============================================================
2022-05-11 08:20:47,675: Epoch 18/38 Batch 7600/7662 eta: 19:48:44.728945	Training Loss 0.1942 (0.1844)	Training Prec@1 98.828 (99.113)	Training Prec@5 99.805 (99.714)	
2022-05-11 08:20:47,675: ============================================================
2022-05-11 08:21:18,241: Epoch: 18/38 eta: 19:48:15.417986	Training Loss 0.1930 (0.1844)	Training Prec@1 99.219 (99.111)	Training Prec@5 99.805 (99.713)
2022-05-11 08:21:18,242: ============================================================
2022-05-11 08:22:07,689: time cost, forward:0.17438034577803177, backward:0.10419943115927956, data cost:0.21714288778979368 
2022-05-11 08:22:07,690: ============================================================
2022-05-11 08:22:07,690: Epoch 19/38 Batch 100/7662 eta: 20:58:00.129306	Training Loss 0.1574 (0.1656)	Training Prec@1 99.805 (99.432)	Training Prec@5 100.000 (99.836)	
2022-05-11 08:22:07,690: ============================================================
2022-05-11 08:22:54,414: time cost, forward:0.17333193879630698, backward:0.10430034321157178, data cost:0.2036057548906336 
2022-05-11 08:22:54,415: ============================================================
2022-05-11 08:22:54,415: Epoch 19/38 Batch 200/7662 eta: 19:51:48.560353	Training Loss 0.1690 (0.1657)	Training Prec@1 99.609 (99.432)	Training Prec@5 100.000 (99.829)	
2022-05-11 08:22:54,415: ============================================================
2022-05-11 08:23:41,028: time cost, forward:0.1726165144738545, backward:0.1043528306444353, data cost:0.19910448291229962 
2022-05-11 08:23:41,029: ============================================================
2022-05-11 08:23:41,029: Epoch 19/38 Batch 300/7662 eta: 19:48:11.992252	Training Loss 0.1738 (0.1661)	Training Prec@1 99.414 (99.424)	Training Prec@5 99.414 (99.822)	
2022-05-11 08:23:41,029: ============================================================
2022-05-11 08:24:27,621: time cost, forward:0.17228517735512333, backward:0.10438207695657448, data cost:0.1968061081448892 
2022-05-11 08:24:27,621: ============================================================
2022-05-11 08:24:27,621: Epoch 19/38 Batch 400/7662 eta: 19:46:52.532524	Training Loss 0.1771 (0.1666)	Training Prec@1 99.219 (99.422)	Training Prec@5 99.805 (99.824)	
2022-05-11 08:24:27,621: ============================================================
2022-05-11 08:25:14,248: time cost, forward:0.17206031382681133, backward:0.1043964201558329, data cost:0.1955036290422948 
2022-05-11 08:25:14,249: ============================================================
2022-05-11 08:25:14,249: Epoch 19/38 Batch 500/7662 eta: 19:46:59.395805	Training Loss 0.1739 (0.1672)	Training Prec@1 99.805 (99.414)	Training Prec@5 100.000 (99.822)	
2022-05-11 08:25:14,249: ============================================================
2022-05-11 08:26:00,840: time cost, forward:0.17193491829058563, backward:0.10440136355430335, data cost:0.19457553702722208 
2022-05-11 08:26:00,840: ============================================================
2022-05-11 08:26:00,840: Epoch 19/38 Batch 600/7662 eta: 19:45:17.246835	Training Loss 0.1716 (0.1676)	Training Prec@1 99.023 (99.412)	Training Prec@5 99.414 (99.821)	
2022-05-11 08:26:00,840: ============================================================
2022-05-11 08:26:47,422: time cost, forward:0.1718543373975631, backward:0.10439594382039126, data cost:0.19389698740750425 
2022-05-11 08:26:47,422: ============================================================
2022-05-11 08:26:47,422: Epoch 19/38 Batch 700/7662 eta: 19:44:17.189811	Training Loss 0.1793 (0.1682)	Training Prec@1 99.219 (99.407)	Training Prec@5 99.609 (99.816)	
2022-05-11 08:26:47,423: ============================================================
2022-05-11 08:27:34,017: time cost, forward:0.1718108251187321, backward:0.10439385967946918, data cost:0.1933861187611414 
2022-05-11 08:27:34,018: ============================================================
2022-05-11 08:27:34,018: Epoch 19/38 Batch 800/7662 eta: 19:43:50.499674	Training Loss 0.1834 (0.1687)	Training Prec@1 99.023 (99.407)	Training Prec@5 99.805 (99.815)	
2022-05-11 08:27:34,018: ============================================================
2022-05-11 08:28:20,565: time cost, forward:0.17176278865377154, backward:0.10439203578452512, data cost:0.19295134586805232 
2022-05-11 08:28:20,565: ============================================================
2022-05-11 08:28:20,565: Epoch 19/38 Batch 900/7662 eta: 19:41:50.945702	Training Loss 0.1809 (0.1692)	Training Prec@1 99.219 (99.405)	Training Prec@5 99.805 (99.813)	
2022-05-11 08:28:20,565: ============================================================
2022-05-11 08:29:07,147: time cost, forward:0.17171260305830427, backward:0.1043869141224507, data cost:0.19265209160767519 
2022-05-11 08:29:07,147: ============================================================
2022-05-11 08:29:07,147: Epoch 19/38 Batch 1000/7662 eta: 19:41:56.191949	Training Loss 0.1714 (0.1697)	Training Prec@1 99.414 (99.400)	Training Prec@5 99.609 (99.813)	
2022-05-11 08:29:07,147: ============================================================
2022-05-11 08:29:53,752: time cost, forward:0.1716817152077117, backward:0.10438220320884697, data cost:0.19242018152085946 
2022-05-11 08:29:53,752: ============================================================
2022-05-11 08:29:53,752: Epoch 19/38 Batch 1100/7662 eta: 19:41:46.111816	Training Loss 0.1819 (0.1702)	Training Prec@1 99.219 (99.391)	Training Prec@5 99.609 (99.810)	
2022-05-11 08:29:53,753: ============================================================
2022-05-11 08:30:40,405: time cost, forward:0.17165256123228606, backward:0.10438240359881404, data cost:0.19225608576726078 
2022-05-11 08:30:40,406: ============================================================
2022-05-11 08:30:40,406: Epoch 19/38 Batch 1200/7662 eta: 19:42:12.340759	Training Loss 0.1695 (0.1707)	Training Prec@1 99.609 (99.385)	Training Prec@5 100.000 (99.810)	
2022-05-11 08:30:40,406: ============================================================
2022-05-11 08:31:27,043: time cost, forward:0.17162627656245066, backward:0.10438143592141426, data cost:0.1921158378357333 
2022-05-11 08:31:27,044: ============================================================
2022-05-11 08:31:27,044: Epoch 19/38 Batch 1300/7662 eta: 19:41:02.166437	Training Loss 0.1804 (0.1713)	Training Prec@1 99.414 (99.381)	Training Prec@5 99.805 (99.807)	
2022-05-11 08:31:27,044: ============================================================
2022-05-11 08:32:13,671: time cost, forward:0.1715922241469977, backward:0.10438323174313702, data cost:0.19198983852312854 
2022-05-11 08:32:13,671: ============================================================
2022-05-11 08:32:13,671: Epoch 19/38 Batch 1400/7662 eta: 19:39:59.761193	Training Loss 0.1723 (0.1717)	Training Prec@1 99.219 (99.379)	Training Prec@5 99.805 (99.808)	
2022-05-11 08:32:13,671: ============================================================
2022-05-11 08:33:00,343: time cost, forward:0.1715865267205827, backward:0.10438363086071867, data cost:0.1918879126293648 
2022-05-11 08:33:00,343: ============================================================
2022-05-11 08:33:00,343: Epoch 19/38 Batch 1500/7662 eta: 19:40:20.624536	Training Loss 0.1747 (0.1721)	Training Prec@1 99.414 (99.370)	Training Prec@5 100.000 (99.805)	
2022-05-11 08:33:00,344: ============================================================
2022-05-11 08:33:46,986: time cost, forward:0.17159214505857046, backward:0.10438882074481327, data cost:0.191770126552713 
2022-05-11 08:33:46,986: ============================================================
2022-05-11 08:33:46,986: Epoch 19/38 Batch 1600/7662 eta: 19:38:49.438926	Training Loss 0.1809 (0.1725)	Training Prec@1 98.828 (99.360)	Training Prec@5 99.805 (99.802)	
2022-05-11 08:33:46,986: ============================================================
2022-05-11 08:34:33,594: time cost, forward:0.17157966631731614, backward:0.10439121407435317, data cost:0.19166506747065606 
2022-05-11 08:34:33,595: ============================================================
2022-05-11 08:34:33,595: Epoch 19/38 Batch 1700/7662 eta: 19:37:10.997107	Training Loss 0.1712 (0.1729)	Training Prec@1 99.219 (99.353)	Training Prec@5 99.805 (99.798)	
2022-05-11 08:34:33,595: ============================================================
2022-05-11 08:35:20,209: time cost, forward:0.17156854505470026, backward:0.10439284646955048, data cost:0.19157636742117407 
2022-05-11 08:35:20,209: ============================================================
2022-05-11 08:35:20,209: Epoch 19/38 Batch 1800/7662 eta: 19:36:33.171109	Training Loss 0.1832 (0.1733)	Training Prec@1 99.219 (99.348)	Training Prec@5 99.609 (99.797)	
2022-05-11 08:35:20,209: ============================================================
2022-05-11 08:36:06,839: time cost, forward:0.1715633915624473, backward:0.10439759910326371, data cost:0.191497637385629 
2022-05-11 08:36:06,840: ============================================================
2022-05-11 08:36:06,840: Epoch 19/38 Batch 1900/7662 eta: 19:36:11.436412	Training Loss 0.1754 (0.1736)	Training Prec@1 99.414 (99.340)	Training Prec@5 99.609 (99.794)	
2022-05-11 08:36:06,840: ============================================================
2022-05-11 08:36:53,469: time cost, forward:0.17155606929155037, backward:0.10440124089029683, data cost:0.1914298292277395 
2022-05-11 08:36:53,470: ============================================================
2022-05-11 08:36:53,470: Epoch 19/38 Batch 2000/7662 eta: 19:35:23.761769	Training Loss 0.1724 (0.1740)	Training Prec@1 99.023 (99.332)	Training Prec@5 99.609 (99.790)	
2022-05-11 08:36:53,470: ============================================================
2022-05-11 08:37:40,045: time cost, forward:0.171539202140819, backward:0.1044035604194325, data cost:0.19135338184434836 
2022-05-11 08:37:40,045: ============================================================
2022-05-11 08:37:40,046: Epoch 19/38 Batch 2100/7662 eta: 19:33:15.072135	Training Loss 0.1780 (0.1743)	Training Prec@1 99.219 (99.327)	Training Prec@5 99.609 (99.788)	
2022-05-11 08:37:40,046: ============================================================
2022-05-11 08:38:26,655: time cost, forward:0.17153157576369718, backward:0.10440578781620596, data cost:0.19129222574533253 
2022-05-11 08:38:26,655: ============================================================
2022-05-11 08:38:26,655: Epoch 19/38 Batch 2200/7662 eta: 19:33:20.085344	Training Loss 0.1903 (0.1747)	Training Prec@1 99.023 (99.318)	Training Prec@5 99.805 (99.785)	
2022-05-11 08:38:26,656: ============================================================
2022-05-11 08:39:13,294: time cost, forward:0.17151939148174883, backward:0.10440753563013529, data cost:0.19124913143043468 
2022-05-11 08:39:13,295: ============================================================
2022-05-11 08:39:13,295: Epoch 19/38 Batch 2300/7662 eta: 19:33:18.000873	Training Loss 0.1875 (0.1749)	Training Prec@1 99.414 (99.312)	Training Prec@5 99.805 (99.783)	
2022-05-11 08:39:13,295: ============================================================
2022-05-11 08:39:59,911: time cost, forward:0.17151244842494315, backward:0.10440747724964798, data cost:0.19120272739373828 
2022-05-11 08:39:59,911: ============================================================
2022-05-11 08:39:59,911: Epoch 19/38 Batch 2400/7662 eta: 19:31:56.485331	Training Loss 0.1789 (0.1752)	Training Prec@1 99.805 (99.308)	Training Prec@5 100.000 (99.782)	
2022-05-11 08:39:59,911: ============================================================
2022-05-11 08:40:46,524: time cost, forward:0.17151756198847948, backward:0.10440787872155698, data cost:0.19114744801576636 
2022-05-11 08:40:46,524: ============================================================
2022-05-11 08:40:46,524: Epoch 19/38 Batch 2500/7662 eta: 19:31:05.298975	Training Loss 0.1812 (0.1755)	Training Prec@1 99.023 (99.302)	Training Prec@5 99.609 (99.779)	
2022-05-11 08:40:46,524: ============================================================
2022-05-11 08:41:33,150: time cost, forward:0.1715310500557031, backward:0.10440963651180818, data cost:0.19109068984662445 
2022-05-11 08:41:33,151: ============================================================
2022-05-11 08:41:33,151: Epoch 19/38 Batch 2600/7662 eta: 19:30:38.489581	Training Loss 0.1935 (0.1758)	Training Prec@1 99.219 (99.295)	Training Prec@5 99.609 (99.777)	
2022-05-11 08:41:33,151: ============================================================
2022-05-11 08:42:19,814: time cost, forward:0.17153248604954327, backward:0.1044124852908722, data cost:0.1910616878934947 
2022-05-11 08:42:19,815: ============================================================
2022-05-11 08:42:19,815: Epoch 19/38 Batch 2700/7662 eta: 19:30:48.356461	Training Loss 0.1749 (0.1760)	Training Prec@1 99.609 (99.291)	Training Prec@5 99.805 (99.777)	
2022-05-11 08:42:19,815: ============================================================
2022-05-11 08:43:06,474: time cost, forward:0.17153822289658002, backward:0.10441423433514398, data cost:0.19102950844010017 
2022-05-11 08:43:06,474: ============================================================
2022-05-11 08:43:06,474: Epoch 19/38 Batch 2800/7662 eta: 19:29:54.604663	Training Loss 0.1747 (0.1763)	Training Prec@1 98.828 (99.284)	Training Prec@5 99.414 (99.774)	
2022-05-11 08:43:06,474: ============================================================
2022-05-11 08:43:53,108: time cost, forward:0.17153931289099134, backward:0.10441580637852543, data cost:0.1909925912980089 
2022-05-11 08:43:53,109: ============================================================
2022-05-11 08:43:53,109: Epoch 19/38 Batch 2900/7662 eta: 19:28:31.121014	Training Loss 0.1779 (0.1765)	Training Prec@1 99.219 (99.277)	Training Prec@5 99.805 (99.771)	
2022-05-11 08:43:53,109: ============================================================
2022-05-11 08:44:39,804: time cost, forward:0.17153813489956551, backward:0.10441714185363017, data cost:0.1909839086987329 
2022-05-11 08:44:39,805: ============================================================
2022-05-11 08:44:39,805: Epoch 19/38 Batch 3000/7662 eta: 19:29:16.596971	Training Loss 0.1811 (0.1768)	Training Prec@1 98.828 (99.272)	Training Prec@5 99.609 (99.768)	
2022-05-11 08:44:39,805: ============================================================
2022-05-11 08:45:26,457: time cost, forward:0.1715370211612028, backward:0.10441691377694548, data cost:0.19096386113371452 
2022-05-11 08:45:26,457: ============================================================
2022-05-11 08:45:26,457: Epoch 19/38 Batch 3100/7662 eta: 19:27:24.767226	Training Loss 0.1824 (0.1770)	Training Prec@1 99.414 (99.266)	Training Prec@5 99.609 (99.767)	
2022-05-11 08:45:26,458: ============================================================
2022-05-11 08:46:13,164: time cost, forward:0.17153223822660169, backward:0.10441611870708746, data cost:0.1909650949136508 
2022-05-11 08:46:13,164: ============================================================
2022-05-11 08:46:13,164: Epoch 19/38 Batch 3200/7662 eta: 19:27:58.945892	Training Loss 0.1806 (0.1772)	Training Prec@1 99.219 (99.263)	Training Prec@5 99.805 (99.765)	
2022-05-11 08:46:13,164: ============================================================
2022-05-11 08:46:59,813: time cost, forward:0.17152660360622493, backward:0.10441495397301218, data cost:0.19095073905486923 
2022-05-11 08:46:59,813: ============================================================
2022-05-11 08:46:59,813: Epoch 19/38 Batch 3300/7662 eta: 19:25:46.091380	Training Loss 0.1721 (0.1774)	Training Prec@1 99.609 (99.259)	Training Prec@5 99.805 (99.764)	
2022-05-11 08:46:59,813: ============================================================
2022-05-11 08:47:46,462: time cost, forward:0.17152304248130823, backward:0.10441403656926146, data cost:0.1909353365509536 
2022-05-11 08:47:46,462: ============================================================
2022-05-11 08:47:46,463: Epoch 19/38 Batch 3400/7662 eta: 19:25:00.144298	Training Loss 0.1865 (0.1776)	Training Prec@1 98.633 (99.255)	Training Prec@5 100.000 (99.762)	
2022-05-11 08:47:46,463: ============================================================
2022-05-11 08:48:34,324: time cost, forward:0.17186102495087185, backward:0.1044244760102836, data cost:0.190914146012325 
2022-05-11 08:48:34,325: ============================================================
2022-05-11 08:48:34,325: Epoch 19/38 Batch 3500/7662 eta: 19:54:29.168783	Training Loss 0.1922 (0.1779)	Training Prec@1 98.242 (99.251)	Training Prec@5 99.609 (99.761)	
2022-05-11 08:48:34,325: ============================================================
2022-05-11 08:49:20,970: time cost, forward:0.17185125850445365, backward:0.10442509675032564, data cost:0.19089496847853854 
2022-05-11 08:49:20,970: ============================================================
2022-05-11 08:49:20,970: Epoch 19/38 Batch 3600/7662 eta: 19:23:20.758322	Training Loss 0.1957 (0.1781)	Training Prec@1 98.828 (99.246)	Training Prec@5 99.609 (99.760)	
2022-05-11 08:49:20,970: ============================================================
2022-05-11 08:50:07,600: time cost, forward:0.17184394834878863, backward:0.10442475055674985, data cost:0.19087149414316196 
2022-05-11 08:50:07,600: ============================================================
2022-05-11 08:50:07,600: Epoch 19/38 Batch 3700/7662 eta: 19:22:10.713193	Training Loss 0.1735 (0.1783)	Training Prec@1 99.609 (99.242)	Training Prec@5 99.609 (99.759)	
2022-05-11 08:50:07,600: ============================================================
2022-05-11 08:50:54,223: time cost, forward:0.17183953368309204, backward:0.10442620893941801, data cost:0.1908434721381139 
2022-05-11 08:50:54,224: ============================================================
2022-05-11 08:50:54,224: Epoch 19/38 Batch 3800/7662 eta: 19:21:15.030974	Training Loss 0.1883 (0.1785)	Training Prec@1 99.414 (99.237)	Training Prec@5 100.000 (99.757)	
2022-05-11 08:50:54,224: ============================================================
2022-05-11 08:51:40,906: time cost, forward:0.17184253447053982, backward:0.1044269337596634, data cost:0.19082517604333799 
2022-05-11 08:51:40,907: ============================================================
2022-05-11 08:51:40,907: Epoch 19/38 Batch 3900/7662 eta: 19:21:56.934645	Training Loss 0.1902 (0.1787)	Training Prec@1 99.414 (99.232)	Training Prec@5 99.805 (99.754)	
2022-05-11 08:51:40,907: ============================================================
2022-05-11 08:52:27,644: time cost, forward:0.17183792874287832, backward:0.10442940322540199, data cost:0.19082750383392816 
2022-05-11 08:52:27,644: ============================================================
2022-05-11 08:52:27,644: Epoch 19/38 Batch 4000/7662 eta: 19:22:31.091015	Training Loss 0.1862 (0.1788)	Training Prec@1 99.414 (99.226)	Training Prec@5 100.000 (99.751)	
2022-05-11 08:52:27,644: ============================================================
2022-05-11 08:53:14,451: time cost, forward:0.17183552383940287, backward:0.10443003854102464, data cost:0.1908433729336011 
2022-05-11 08:53:14,452: ============================================================
2022-05-11 08:53:14,452: Epoch 19/38 Batch 4100/7662 eta: 19:23:29.617524	Training Loss 0.1776 (0.1790)	Training Prec@1 99.609 (99.224)	Training Prec@5 100.000 (99.751)	
2022-05-11 08:53:14,452: ============================================================
2022-05-11 08:54:01,198: time cost, forward:0.17182821891341332, backward:0.1044306508073582, data cost:0.19085207806510227 
2022-05-11 08:54:01,199: ============================================================
2022-05-11 08:54:01,199: Epoch 19/38 Batch 4200/7662 eta: 19:21:12.169943	Training Loss 0.2048 (0.1792)	Training Prec@1 99.219 (99.220)	Training Prec@5 99.805 (99.749)	
2022-05-11 08:54:01,199: ============================================================
2022-05-11 08:54:48,000: time cost, forward:0.17182045821451425, backward:0.10442985643145927, data cost:0.1908732327951279 
2022-05-11 08:54:48,001: ============================================================
2022-05-11 08:54:48,001: Epoch 19/38 Batch 4300/7662 eta: 19:21:47.155957	Training Loss 0.1790 (0.1793)	Training Prec@1 98.828 (99.216)	Training Prec@5 99.609 (99.748)	
2022-05-11 08:54:48,001: ============================================================
2022-05-11 08:55:34,745: time cost, forward:0.17181166146771154, backward:0.10442778673408303, data cost:0.19088378828421157 
2022-05-11 08:55:34,745: ============================================================
2022-05-11 08:55:34,745: Epoch 19/38 Batch 4400/7662 eta: 19:19:35.197951	Training Loss 0.1794 (0.1795)	Training Prec@1 99.414 (99.211)	Training Prec@5 100.000 (99.746)	
2022-05-11 08:55:34,745: ============================================================
2022-05-11 08:56:21,437: time cost, forward:0.17180073465286666, backward:0.10442728401687734, data cost:0.19088234809219215 
2022-05-11 08:56:21,438: ============================================================
2022-05-11 08:56:21,438: Epoch 19/38 Batch 4500/7662 eta: 19:17:30.837692	Training Loss 0.1819 (0.1797)	Training Prec@1 98.633 (99.208)	Training Prec@5 99.805 (99.745)	
2022-05-11 08:56:21,438: ============================================================
2022-05-11 08:57:08,223: time cost, forward:0.17180205101706614, backward:0.10442590832736187, data cost:0.19089205225127293 
2022-05-11 08:57:08,223: ============================================================
2022-05-11 08:57:08,223: Epoch 19/38 Batch 4600/7662 eta: 19:19:02.166857	Training Loss 0.1873 (0.1798)	Training Prec@1 98.828 (99.205)	Training Prec@5 99.414 (99.743)	
2022-05-11 08:57:08,223: ============================================================
2022-05-11 08:57:55,037: time cost, forward:0.1718022771073443, backward:0.10442536697663711, data cost:0.190905537496706 
2022-05-11 08:57:55,037: ============================================================
2022-05-11 08:57:55,037: Epoch 19/38 Batch 4700/7662 eta: 19:18:57.623409	Training Loss 0.1848 (0.1800)	Training Prec@1 98.828 (99.200)	Training Prec@5 99.805 (99.742)	
2022-05-11 08:57:55,037: ============================================================
2022-05-11 08:58:41,796: time cost, forward:0.17180172953413883, backward:0.10442356974861478, data cost:0.19090928020862818 
2022-05-11 08:58:41,797: ============================================================
2022-05-11 08:58:41,797: Epoch 19/38 Batch 4800/7662 eta: 19:16:50.720317	Training Loss 0.1930 (0.1801)	Training Prec@1 99.219 (99.197)	Training Prec@5 99.805 (99.742)	
2022-05-11 08:58:41,797: ============================================================
2022-05-11 08:59:28,633: time cost, forward:0.17180472350797013, backward:0.10442512248043723, data cost:0.19092400459932732 
2022-05-11 08:59:28,633: ============================================================
2022-05-11 08:59:28,633: Epoch 19/38 Batch 4900/7662 eta: 19:17:57.654199	Training Loss 0.1900 (0.1802)	Training Prec@1 98.633 (99.194)	Training Prec@5 99.805 (99.741)	
2022-05-11 08:59:28,633: ============================================================
2022-05-11 09:00:15,471: time cost, forward:0.17180461729972643, backward:0.10442610463277653, data cost:0.19094214121755015 
2022-05-11 09:00:15,471: ============================================================
2022-05-11 09:00:15,471: Epoch 19/38 Batch 5000/7662 eta: 19:17:13.450835	Training Loss 0.1865 (0.1804)	Training Prec@1 98.828 (99.191)	Training Prec@5 99.609 (99.740)	
2022-05-11 09:00:15,471: ============================================================
2022-05-11 09:01:03,151: time cost, forward:0.17193179374630485, backward:0.10445362700039462, data cost:0.19097057780370358 
2022-05-11 09:01:03,151: ============================================================
2022-05-11 09:01:03,152: Epoch 19/38 Batch 5100/7662 eta: 19:37:13.785718	Training Loss 0.1878 (0.1805)	Training Prec@1 99.219 (99.188)	Training Prec@5 99.805 (99.739)	
2022-05-11 09:01:03,152: ============================================================
2022-05-11 09:01:50,693: time cost, forward:0.17207299766459816, backward:0.1044853752588946, data cost:0.19094486088907747 
2022-05-11 09:01:50,694: ============================================================
2022-05-11 09:01:50,694: Epoch 19/38 Batch 5200/7662 eta: 19:33:02.016554	Training Loss 0.1899 (0.1806)	Training Prec@1 98.828 (99.187)	Training Prec@5 99.414 (99.739)	
2022-05-11 09:01:50,694: ============================================================
2022-05-11 09:02:37,410: time cost, forward:0.17206504151919672, backward:0.10450784798769888, data cost:0.1909183091230045 
2022-05-11 09:02:37,410: ============================================================
2022-05-11 09:02:37,410: Epoch 19/38 Batch 5300/7662 eta: 19:11:53.080954	Training Loss 0.1851 (0.1807)	Training Prec@1 99.219 (99.184)	Training Prec@5 99.609 (99.738)	
2022-05-11 09:02:37,410: ============================================================
2022-05-11 09:03:23,987: time cost, forward:0.17205329483627146, backward:0.10450919497165444, data cost:0.1908913720292192 
2022-05-11 09:03:23,987: ============================================================
2022-05-11 09:03:23,987: Epoch 19/38 Batch 5400/7662 eta: 19:07:39.710324	Training Loss 0.1741 (0.1808)	Training Prec@1 99.414 (99.181)	Training Prec@5 100.000 (99.736)	
2022-05-11 09:03:23,987: ============================================================
2022-05-11 09:04:10,491: time cost, forward:0.1720268832139263, backward:0.10451152550565002, data cost:0.1908667471695432 
2022-05-11 09:04:10,491: ============================================================
2022-05-11 09:04:10,491: Epoch 19/38 Batch 5500/7662 eta: 19:05:05.303727	Training Loss 0.1841 (0.1810)	Training Prec@1 99.219 (99.176)	Training Prec@5 99.219 (99.735)	
2022-05-11 09:04:10,491: ============================================================
2022-05-11 09:04:57,021: time cost, forward:0.17200649604347693, backward:0.10451163077145778, data cost:0.19084443818630759 
2022-05-11 09:04:57,022: ============================================================
2022-05-11 09:04:57,022: Epoch 19/38 Batch 5600/7662 eta: 19:04:58.180946	Training Loss 0.2009 (0.1811)	Training Prec@1 99.219 (99.174)	Training Prec@5 99.805 (99.734)	
2022-05-11 09:04:57,022: ============================================================
2022-05-11 09:05:43,579: time cost, forward:0.17199060744958125, backward:0.1045127978009453, data cost:0.19082296080789266 
2022-05-11 09:05:43,600: ============================================================
2022-05-11 09:05:43,600: Epoch 19/38 Batch 5700/7662 eta: 19:05:21.679444	Training Loss 0.1901 (0.1812)	Training Prec@1 98.828 (99.171)	Training Prec@5 99.805 (99.733)	
2022-05-11 09:05:43,600: ============================================================
2022-05-11 09:06:30,172: time cost, forward:0.17197623917266694, backward:0.10451395225064429, data cost:0.19080724825549072 
2022-05-11 09:06:30,172: ============================================================
2022-05-11 09:06:30,172: Epoch 19/38 Batch 5800/7662 eta: 19:04:26.794493	Training Loss 0.1986 (0.1813)	Training Prec@1 98.438 (99.168)	Training Prec@5 99.609 (99.731)	
2022-05-11 09:06:30,172: ============================================================
2022-05-11 09:07:16,727: time cost, forward:0.17196053863683178, backward:0.10451520186477767, data cost:0.19078729629193267 
2022-05-11 09:07:16,727: ============================================================
2022-05-11 09:07:16,727: Epoch 19/38 Batch 5900/7662 eta: 19:03:14.448082	Training Loss 0.1915 (0.1814)	Training Prec@1 97.852 (99.165)	Training Prec@5 99.219 (99.731)	
2022-05-11 09:07:16,727: ============================================================
2022-05-11 09:08:03,506: time cost, forward:0.1719624229541797, backward:0.10453171908090385, data cost:0.19077276615207048 
2022-05-11 09:08:03,507: ============================================================
2022-05-11 09:08:03,507: Epoch 19/38 Batch 6000/7662 eta: 19:07:59.130181	Training Loss 0.1929 (0.1815)	Training Prec@1 99.414 (99.162)	Training Prec@5 99.609 (99.730)	
2022-05-11 09:08:03,507: ============================================================
2022-05-11 09:08:50,233: time cost, forward:0.17195540714467192, backward:0.10455187552677724, data cost:0.19075475471647943 
2022-05-11 09:08:50,234: ============================================================
2022-05-11 09:08:50,234: Epoch 19/38 Batch 6100/7662 eta: 19:05:54.296523	Training Loss 0.1873 (0.1816)	Training Prec@1 99.219 (99.158)	Training Prec@5 99.805 (99.729)	
2022-05-11 09:08:50,234: ============================================================
2022-05-11 09:09:36,847: time cost, forward:0.17194666110963508, backward:0.10455476001186281, data cost:0.19073784930184112 
2022-05-11 09:09:36,847: ============================================================
2022-05-11 09:09:36,847: Epoch 19/38 Batch 6200/7662 eta: 19:02:21.129892	Training Loss 0.1907 (0.1817)	Training Prec@1 98.438 (99.155)	Training Prec@5 99.609 (99.728)	
2022-05-11 09:09:36,847: ============================================================
2022-05-11 09:10:23,460: time cost, forward:0.1719408455794341, backward:0.10455627554199926, data cost:0.1907210059725381 
2022-05-11 09:10:23,460: ============================================================
2022-05-11 09:10:23,461: Epoch 19/38 Batch 6300/7662 eta: 19:01:34.070298	Training Loss 0.1868 (0.1818)	Training Prec@1 98.828 (99.153)	Training Prec@5 99.609 (99.727)	
2022-05-11 09:10:23,461: ============================================================
2022-05-11 09:11:10,065: time cost, forward:0.17193396353390017, backward:0.10455753531637071, data cost:0.19070443232965983 
2022-05-11 09:11:10,066: ============================================================
2022-05-11 09:11:10,066: Epoch 19/38 Batch 6400/7662 eta: 19:00:35.450434	Training Loss 0.1884 (0.1819)	Training Prec@1 99.414 (99.151)	Training Prec@5 99.414 (99.727)	
2022-05-11 09:11:10,066: ============================================================
2022-05-11 09:11:56,660: time cost, forward:0.17192747076028383, backward:0.10455864505559449, data cost:0.19068659003064492 
2022-05-11 09:11:56,660: ============================================================
2022-05-11 09:11:56,660: Epoch 19/38 Batch 6500/7662 eta: 18:59:32.937611	Training Loss 0.1929 (0.1820)	Training Prec@1 98.242 (99.147)	Training Prec@5 99.609 (99.725)	
2022-05-11 09:11:56,660: ============================================================
2022-05-11 09:12:43,242: time cost, forward:0.1719205931906159, backward:0.10455833078966228, data cost:0.19066924498937116 
2022-05-11 09:12:43,242: ============================================================
2022-05-11 09:12:43,242: Epoch 19/38 Batch 6600/7662 eta: 18:58:28.323581	Training Loss 0.1774 (0.1821)	Training Prec@1 99.414 (99.144)	Training Prec@5 99.609 (99.724)	
2022-05-11 09:12:43,242: ============================================================
2022-05-11 09:13:29,847: time cost, forward:0.17191727404488363, backward:0.10455781300577908, data cost:0.19065323657536795 
2022-05-11 09:13:29,847: ============================================================
2022-05-11 09:13:29,847: Epoch 19/38 Batch 6700/7662 eta: 18:58:15.986847	Training Loss 0.1998 (0.1822)	Training Prec@1 98.828 (99.142)	Training Prec@5 99.609 (99.724)	
2022-05-11 09:13:29,848: ============================================================
2022-05-11 09:14:16,508: time cost, forward:0.17191015595740336, backward:0.10456841608096018, data cost:0.19063797107881125 
2022-05-11 09:14:16,508: ============================================================
2022-05-11 09:14:16,508: Epoch 19/38 Batch 6800/7662 eta: 18:58:50.487982	Training Loss 0.2007 (0.1823)	Training Prec@1 99.023 (99.139)	Training Prec@5 99.609 (99.723)	
2022-05-11 09:14:16,508: ============================================================
2022-05-11 09:15:03,013: time cost, forward:0.1718902706080441, backward:0.10456927069063929, data cost:0.19062303335602032 
2022-05-11 09:15:03,013: ============================================================
2022-05-11 09:15:03,013: Epoch 19/38 Batch 6900/7662 eta: 18:54:15.523893	Training Loss 0.1873 (0.1824)	Training Prec@1 99.219 (99.137)	Training Prec@5 99.609 (99.722)	
2022-05-11 09:15:03,013: ============================================================
2022-05-11 09:15:49,532: time cost, forward:0.17187320973161527, backward:0.10457040075064217, data cost:0.19060799206541443 
2022-05-11 09:15:49,532: ============================================================
2022-05-11 09:15:49,532: Epoch 19/38 Batch 7000/7662 eta: 18:53:50.434883	Training Loss 0.1885 (0.1825)	Training Prec@1 99.219 (99.134)	Training Prec@5 99.805 (99.721)	
2022-05-11 09:15:49,533: ============================================================
2022-05-11 09:16:36,137: time cost, forward:0.17186451844890985, backward:0.1045738709344043, data cost:0.1905951696074266 
2022-05-11 09:16:36,137: ============================================================
2022-05-11 09:16:36,137: Epoch 19/38 Batch 7100/7662 eta: 18:55:08.706113	Training Loss 0.1819 (0.1826)	Training Prec@1 99.609 (99.132)	Training Prec@5 100.000 (99.721)	
2022-05-11 09:16:36,137: ============================================================
2022-05-11 09:17:22,715: time cost, forward:0.1718544566576672, backward:0.10457568116313236, data cost:0.1905822845312734 
2022-05-11 09:17:22,715: ============================================================
2022-05-11 09:17:22,715: Epoch 19/38 Batch 7200/7662 eta: 18:53:42.951314	Training Loss 0.1843 (0.1826)	Training Prec@1 98.633 (99.130)	Training Prec@5 99.609 (99.720)	
2022-05-11 09:17:22,715: ============================================================
2022-05-11 09:18:09,313: time cost, forward:0.17184632463738728, backward:0.10457708212035473, data cost:0.19057102055725356 
2022-05-11 09:18:09,313: ============================================================
2022-05-11 09:18:09,313: Epoch 19/38 Batch 7300/7662 eta: 18:53:25.815160	Training Loss 0.1937 (0.1827)	Training Prec@1 99.609 (99.127)	Training Prec@5 100.000 (99.718)	
2022-05-11 09:18:09,313: ============================================================
2022-05-11 09:18:55,900: time cost, forward:0.17183822018824038, backward:0.1045782269618208, data cost:0.19055894433300083 
2022-05-11 09:18:55,900: ============================================================
2022-05-11 09:18:55,900: Epoch 19/38 Batch 7400/7662 eta: 18:52:22.462151	Training Loss 0.1838 (0.1828)	Training Prec@1 97.070 (99.123)	Training Prec@5 98.438 (99.718)	
2022-05-11 09:18:55,900: ============================================================
2022-05-11 09:19:42,539: time cost, forward:0.17183947289748294, backward:0.10457805411499935, data cost:0.19054634587925934 
2022-05-11 09:19:42,539: ============================================================
2022-05-11 09:19:42,539: Epoch 19/38 Batch 7500/7662 eta: 18:52:52.494460	Training Loss 0.1901 (0.1829)	Training Prec@1 99.219 (99.121)	Training Prec@5 99.805 (99.717)	
2022-05-11 09:19:42,539: ============================================================
2022-05-11 09:20:29,160: time cost, forward:0.17183709944654632, backward:0.10457893659729976, data cost:0.19053439771459202 
2022-05-11 09:20:29,161: ============================================================
2022-05-11 09:20:29,161: Epoch 19/38 Batch 7600/7662 eta: 18:51:40.092104	Training Loss 0.1851 (0.1830)	Training Prec@1 98.242 (99.118)	Training Prec@5 99.414 (99.716)	
2022-05-11 09:20:29,161: ============================================================
2022-05-11 09:21:00,092: Epoch: 19/38 eta: 18:51:10.720527	Training Loss 0.1939 (0.1830)	Training Prec@1 98.828 (99.117)	Training Prec@5 99.414 (99.715)
2022-05-11 09:21:00,092: ============================================================
2022-05-11 09:21:50,313: time cost, forward:0.17474258066427828, backward:0.10422417130133119, data cost:0.22555991856738775 
2022-05-11 09:21:50,313: ============================================================
2022-05-11 09:21:50,313: Epoch 20/38 Batch 100/7662 eta: 20:16:20.017212	Training Loss 0.1476 (0.1521)	Training Prec@1 99.805 (99.527)	Training Prec@5 99.805 (99.848)	
2022-05-11 09:21:50,314: ============================================================
2022-05-11 09:22:36,896: time cost, forward:0.17287986482208098, backward:0.10426967826919939, data cost:0.20773847258869726 
2022-05-11 09:22:36,896: ============================================================
2022-05-11 09:22:36,896: Epoch 20/38 Batch 200/7662 eta: 18:48:41.978517	Training Loss 0.1453 (0.1485)	Training Prec@1 99.609 (99.544)	Training Prec@5 100.000 (99.857)	
2022-05-11 09:22:36,897: ============================================================
2022-05-11 09:23:23,491: time cost, forward:0.17233266240378287, backward:0.10429520670785553, data cost:0.20183300732768897 
2022-05-11 09:23:23,491: ============================================================
2022-05-11 09:23:23,491: Epoch 20/38 Batch 300/7662 eta: 18:48:12.144979	Training Loss 0.1378 (0.1462)	Training Prec@1 100.000 (99.571)	Training Prec@5 100.000 (99.863)	
2022-05-11 09:23:23,491: ============================================================
2022-05-11 09:24:10,110: time cost, forward:0.17210510081814645, backward:0.1043225493944976, data cost:0.19889123995501296 
2022-05-11 09:24:10,110: ============================================================
2022-05-11 09:24:10,110: Epoch 20/38 Batch 400/7662 eta: 18:48:01.310508	Training Loss 0.1395 (0.1448)	Training Prec@1 99.414 (99.585)	Training Prec@5 100.000 (99.869)	
2022-05-11 09:24:10,110: ============================================================
2022-05-11 09:24:56,718: time cost, forward:0.17198188510352003, backward:0.10434175302127081, data cost:0.19708903757985943 
2022-05-11 09:24:56,718: ============================================================
2022-05-11 09:24:56,718: Epoch 20/38 Batch 500/7662 eta: 18:46:58.784260	Training Loss 0.1338 (0.1436)	Training Prec@1 100.000 (99.602)	Training Prec@5 100.000 (99.876)	
2022-05-11 09:24:56,719: ============================================================
2022-05-11 09:25:43,391: time cost, forward:0.17192458509403796, backward:0.10438433314404623, data cost:0.1959407998245825 
2022-05-11 09:25:43,392: ============================================================
2022-05-11 09:25:43,392: Epoch 20/38 Batch 600/7662 eta: 18:47:46.744273	Training Loss 0.1331 (0.1426)	Training Prec@1 99.805 (99.610)	Training Prec@5 100.000 (99.880)	
2022-05-11 09:25:43,392: ============================================================
2022-05-11 09:26:30,369: time cost, forward:0.17196574504453907, backward:0.10460169086811028, data cost:0.1952727956321618 
2022-05-11 09:26:30,369: ============================================================
2022-05-11 09:26:30,369: Epoch 20/38 Batch 700/7662 eta: 18:54:20.377422	Training Loss 0.1427 (0.1416)	Training Prec@1 99.609 (99.616)	Training Prec@5 100.000 (99.883)	
2022-05-11 09:26:30,369: ============================================================
2022-05-11 09:27:17,180: time cost, forward:0.17196746851237157, backward:0.10461647907395535, data cost:0.1947396135747955 
2022-05-11 09:27:17,180: ============================================================
2022-05-11 09:27:17,180: Epoch 20/38 Batch 800/7662 eta: 18:49:32.462639	Training Loss 0.1251 (0.1409)	Training Prec@1 100.000 (99.617)	Training Prec@5 100.000 (99.884)	
2022-05-11 09:27:17,180: ============================================================
2022-05-11 09:28:03,846: time cost, forward:0.17191259190025796, backward:0.10460486162756388, data cost:0.19425790169347779 
2022-05-11 09:28:03,847: ============================================================
2022-05-11 09:28:03,847: Epoch 20/38 Batch 900/7662 eta: 18:45:16.638430	Training Loss 0.1285 (0.1403)	Training Prec@1 100.000 (99.621)	Training Prec@5 100.000 (99.886)	
2022-05-11 09:28:03,847: ============================================================
2022-05-11 09:28:50,542: time cost, forward:0.17187428927875018, backward:0.10459492872427176, data cost:0.19389138971124445 
2022-05-11 09:28:50,542: ============================================================
2022-05-11 09:28:50,542: Epoch 20/38 Batch 1000/7662 eta: 18:45:11.930573	Training Loss 0.1332 (0.1396)	Training Prec@1 99.805 (99.623)	Training Prec@5 99.805 (99.886)	
2022-05-11 09:28:50,542: ============================================================
2022-05-11 09:29:37,283: time cost, forward:0.17187248564937962, backward:0.10458985689664776, data cost:0.1936097787227058 
2022-05-11 09:29:37,283: ============================================================
2022-05-11 09:29:37,284: Epoch 20/38 Batch 1100/7662 eta: 18:45:31.279275	Training Loss 0.1302 (0.1391)	Training Prec@1 99.414 (99.628)	Training Prec@5 100.000 (99.888)	
2022-05-11 09:29:37,284: ============================================================
2022-05-11 09:30:24,062: time cost, forward:0.1718599165947463, backward:0.1045833838990174, data cost:0.19341602476563824 
2022-05-11 09:30:24,063: ============================================================
2022-05-11 09:30:24,063: Epoch 20/38 Batch 1200/7662 eta: 18:45:39.152299	Training Loss 0.1406 (0.1385)	Training Prec@1 99.805 (99.635)	Training Prec@5 100.000 (99.890)	
2022-05-11 09:30:24,063: ============================================================
2022-05-11 09:31:10,763: time cost, forward:0.17186157073857145, backward:0.10457179397688728, data cost:0.19317718245966606 
2022-05-11 09:31:10,763: ============================================================
2022-05-11 09:31:10,763: Epoch 20/38 Batch 1300/7662 eta: 18:42:59.036771	Training Loss 0.1280 (0.1380)	Training Prec@1 99.414 (99.637)	Training Prec@5 100.000 (99.891)	
2022-05-11 09:31:10,763: ============================================================
2022-05-11 09:31:57,445: time cost, forward:0.17183778284276016, backward:0.10456750391209611, data cost:0.19298470659371866 
2022-05-11 09:31:57,445: ============================================================
2022-05-11 09:31:57,445: Epoch 20/38 Batch 1400/7662 eta: 18:41:45.524480	Training Loss 0.1285 (0.1375)	Training Prec@1 99.609 (99.640)	Training Prec@5 100.000 (99.892)	
2022-05-11 09:31:57,445: ============================================================
2022-05-11 09:32:44,161: time cost, forward:0.17186075262104059, backward:0.10456165160394812, data cost:0.19279319513154236 
2022-05-11 09:32:44,162: ============================================================
2022-05-11 09:32:44,162: Epoch 20/38 Batch 1500/7662 eta: 18:41:49.017167	Training Loss 0.1211 (0.1371)	Training Prec@1 99.414 (99.643)	Training Prec@5 100.000 (99.893)	
2022-05-11 09:32:44,162: ============================================================
2022-05-11 09:33:30,934: time cost, forward:0.17186567841506586, backward:0.10460250895048694, data cost:0.19263860163948102 
2022-05-11 09:33:30,935: ============================================================
2022-05-11 09:33:30,935: Epoch 20/38 Batch 1600/7662 eta: 18:42:23.464503	Training Loss 0.1272 (0.1367)	Training Prec@1 99.414 (99.644)	Training Prec@5 100.000 (99.893)	
2022-05-11 09:33:30,935: ============================================================
2022-05-11 09:34:17,713: time cost, forward:0.17185268744501805, backward:0.10469067903600629, data cost:0.1924692590914452 
2022-05-11 09:34:17,713: ============================================================
2022-05-11 09:34:17,713: Epoch 20/38 Batch 1700/7662 eta: 18:41:44.275189	Training Loss 0.1219 (0.1363)	Training Prec@1 100.000 (99.648)	Training Prec@5 100.000 (99.894)	
2022-05-11 09:34:17,714: ============================================================
2022-05-11 09:35:04,308: time cost, forward:0.17181822046297932, backward:0.1046850463958367, data cost:0.19232496650700043 
2022-05-11 09:35:04,308: ============================================================
2022-05-11 09:35:04,308: Epoch 20/38 Batch 1800/7662 eta: 18:36:33.752076	Training Loss 0.1354 (0.1359)	Training Prec@1 99.414 (99.649)	Training Prec@5 99.805 (99.894)	
2022-05-11 09:35:04,308: ============================================================
2022-05-11 09:35:50,852: time cost, forward:0.17177738272057766, backward:0.10468057559125357, data cost:0.1921781651153886 
2022-05-11 09:35:50,852: ============================================================
2022-05-11 09:35:50,852: Epoch 20/38 Batch 1900/7662 eta: 18:34:33.679243	Training Loss 0.1306 (0.1355)	Training Prec@1 99.609 (99.651)	Training Prec@5 99.609 (99.894)	
2022-05-11 09:35:50,852: ============================================================
2022-05-11 09:36:37,400: time cost, forward:0.17174481343722092, backward:0.1046720913137538, data cost:0.19204922483347844 
2022-05-11 09:36:37,400: ============================================================
2022-05-11 09:36:37,400: Epoch 20/38 Batch 2000/7662 eta: 18:33:53.233505	Training Loss 0.1254 (0.1352)	Training Prec@1 99.805 (99.654)	Training Prec@5 100.000 (99.894)	
2022-05-11 09:36:37,400: ============================================================
2022-05-11 09:37:23,988: time cost, forward:0.17172535264304617, backward:0.10467416993659584, data cost:0.1919295107426673 
2022-05-11 09:37:23,988: ============================================================
2022-05-11 09:37:23,988: Epoch 20/38 Batch 2100/7662 eta: 18:34:04.116333	Training Loss 0.1242 (0.1348)	Training Prec@1 99.805 (99.655)	Training Prec@5 100.000 (99.895)	
2022-05-11 09:37:23,988: ============================================================
2022-05-11 09:38:10,772: time cost, forward:0.1717983185567331, backward:0.10467117761904242, data cost:0.19182508823382632 
2022-05-11 09:38:10,772: ============================================================
2022-05-11 09:38:10,773: Epoch 20/38 Batch 2200/7662 eta: 18:37:58.761807	Training Loss 0.1334 (0.1345)	Training Prec@1 99.805 (99.659)	Training Prec@5 100.000 (99.895)	
2022-05-11 09:38:10,773: ============================================================
2022-05-11 09:38:57,389: time cost, forward:0.17179875821847407, backward:0.10466680178283452, data cost:0.19172529823731319 
2022-05-11 09:38:57,390: ============================================================
2022-05-11 09:38:57,390: Epoch 20/38 Batch 2300/7662 eta: 18:33:12.878518	Training Loss 0.1229 (0.1342)	Training Prec@1 100.000 (99.660)	Training Prec@5 100.000 (99.895)	
2022-05-11 09:38:57,390: ============================================================
2022-05-11 09:39:43,904: time cost, forward:0.17175289788510512, backward:0.10466207966997307, data cost:0.19163741972010154 
2022-05-11 09:39:43,904: ============================================================
2022-05-11 09:39:43,904: Epoch 20/38 Batch 2400/7662 eta: 18:29:58.317864	Training Loss 0.1152 (0.1338)	Training Prec@1 99.805 (99.661)	Training Prec@5 100.000 (99.897)	
2022-05-11 09:39:43,904: ============================================================
2022-05-11 09:40:30,421: time cost, forward:0.17171340200508914, backward:0.10465902192633646, data cost:0.19155401828623905 
2022-05-11 09:40:30,421: ============================================================
2022-05-11 09:40:30,421: Epoch 20/38 Batch 2500/7662 eta: 18:29:16.693210	Training Loss 0.1298 (0.1336)	Training Prec@1 99.609 (99.661)	Training Prec@5 100.000 (99.898)	
2022-05-11 09:40:30,421: ============================================================
2022-05-11 09:41:16,951: time cost, forward:0.17168606267887246, backward:0.10465434791033613, data cost:0.19147425222598666 
2022-05-11 09:41:16,951: ============================================================
2022-05-11 09:41:16,951: Epoch 20/38 Batch 2600/7662 eta: 18:28:47.484380	Training Loss 0.1301 (0.1333)	Training Prec@1 100.000 (99.663)	Training Prec@5 100.000 (99.898)	
2022-05-11 09:41:16,951: ============================================================
2022-05-11 09:42:03,500: time cost, forward:0.1716636342002357, backward:0.1046487971472272, data cost:0.1914057702477573 
2022-05-11 09:42:03,500: ============================================================
2022-05-11 09:42:03,500: Epoch 20/38 Batch 2700/7662 eta: 18:28:28.772316	Training Loss 0.1314 (0.1331)	Training Prec@1 99.219 (99.664)	Training Prec@5 99.805 (99.898)	
2022-05-11 09:42:03,500: ============================================================
2022-05-11 09:42:50,047: time cost, forward:0.1716456731841921, backward:0.10464521304502279, data cost:0.19133731900644796 
2022-05-11 09:42:50,047: ============================================================
2022-05-11 09:42:50,047: Epoch 20/38 Batch 2800/7662 eta: 18:27:39.810800	Training Loss 0.1290 (0.1328)	Training Prec@1 98.438 (99.665)	Training Prec@5 100.000 (99.899)	
2022-05-11 09:42:50,047: ============================================================
2022-05-11 09:43:36,658: time cost, forward:0.17163580514184767, backward:0.10464405256865476, data cost:0.19128699967185972 
2022-05-11 09:43:36,658: ============================================================
2022-05-11 09:43:36,658: Epoch 20/38 Batch 2900/7662 eta: 18:28:24.422077	Training Loss 0.1309 (0.1326)	Training Prec@1 100.000 (99.668)	Training Prec@5 100.000 (99.901)	
2022-05-11 09:43:36,659: ============================================================
2022-05-11 09:44:23,332: time cost, forward:0.17163922382060906, backward:0.10465702640092067, data cost:0.1912338069853444 
2022-05-11 09:44:23,332: ============================================================
2022-05-11 09:44:23,332: Epoch 20/38 Batch 3000/7662 eta: 18:29:06.905055	Training Loss 0.1201 (0.1323)	Training Prec@1 99.414 (99.669)	Training Prec@5 99.609 (99.901)	
2022-05-11 09:44:23,332: ============================================================
2022-05-11 09:45:10,016: time cost, forward:0.17165757025699918, backward:0.10465828331488491, data cost:0.19118471567228404 
2022-05-11 09:45:10,016: ============================================================
2022-05-11 09:45:10,016: Epoch 20/38 Batch 3100/7662 eta: 18:28:35.175952	Training Loss 0.1216 (0.1321)	Training Prec@1 99.805 (99.670)	Training Prec@5 100.000 (99.901)	
2022-05-11 09:45:10,016: ============================================================
2022-05-11 09:45:56,330: time cost, forward:0.17156931801712785, backward:0.10465085070443995, data cost:0.19113577146312527 
2022-05-11 09:45:56,330: ============================================================
2022-05-11 09:45:56,330: Epoch 20/38 Batch 3200/7662 eta: 18:19:01.279893	Training Loss 0.1222 (0.1319)	Training Prec@1 99.805 (99.671)	Training Prec@5 100.000 (99.902)	
2022-05-11 09:45:56,330: ============================================================
2022-05-11 09:46:42,721: time cost, forward:0.17150668759677004, backward:0.1046455363209734, data cost:0.19109134942916495 
2022-05-11 09:46:42,721: ============================================================
2022-05-11 09:46:42,721: Epoch 20/38 Batch 3300/7662 eta: 18:20:04.858539	Training Loss 0.1320 (0.1317)	Training Prec@1 99.805 (99.671)	Training Prec@5 99.805 (99.902)	
2022-05-11 09:46:42,722: ============================================================
2022-05-11 09:47:29,151: time cost, forward:0.17146165022326765, backward:0.10463930004026722, data cost:0.19104836168763356 
2022-05-11 09:47:29,152: ============================================================
2022-05-11 09:47:29,152: Epoch 20/38 Batch 3400/7662 eta: 18:20:14.049454	Training Loss 0.1226 (0.1314)	Training Prec@1 100.000 (99.672)	Training Prec@5 100.000 (99.902)	
2022-05-11 09:47:29,152: ============================================================
2022-05-11 09:48:15,627: time cost, forward:0.17143650074010577, backward:0.10463191959373472, data cost:0.1910047888858007 
2022-05-11 09:48:15,627: ============================================================
2022-05-11 09:48:15,627: Epoch 20/38 Batch 3500/7662 eta: 18:20:31.965091	Training Loss 0.1312 (0.1312)	Training Prec@1 99.609 (99.674)	Training Prec@5 100.000 (99.903)	
2022-05-11 09:48:15,627: ============================================================
2022-05-11 09:49:02,170: time cost, forward:0.17142553738866723, backward:0.1046263145453137, data cost:0.1909685837093013 
2022-05-11 09:49:02,170: ============================================================
2022-05-11 09:49:02,170: Epoch 20/38 Batch 3600/7662 eta: 18:21:21.498865	Training Loss 0.1337 (0.1310)	Training Prec@1 99.414 (99.675)	Training Prec@5 100.000 (99.904)	
2022-05-11 09:49:02,170: ============================================================
2022-05-11 09:49:48,723: time cost, forward:0.17141630888694234, backward:0.10462555269126346, data cost:0.19093103613779977 
2022-05-11 09:49:48,723: ============================================================
2022-05-11 09:49:48,723: Epoch 20/38 Batch 3700/7662 eta: 18:20:48.521869	Training Loss 0.1185 (0.1308)	Training Prec@1 99.805 (99.677)	Training Prec@5 99.805 (99.904)	
2022-05-11 09:49:48,723: ============================================================
2022-05-11 09:50:35,215: time cost, forward:0.17139358594562543, backward:0.1046234912450579, data cost:0.19089501241095036 
2022-05-11 09:50:35,216: ============================================================
2022-05-11 09:50:35,216: Epoch 20/38 Batch 3800/7662 eta: 18:18:36.719641	Training Loss 0.1141 (0.1306)	Training Prec@1 99.805 (99.678)	Training Prec@5 100.000 (99.905)	
2022-05-11 09:50:35,216: ============================================================
2022-05-11 09:51:21,760: time cost, forward:0.171383013080774, backward:0.10462129076311728, data cost:0.19086350163119548 
2022-05-11 09:51:21,760: ============================================================
2022-05-11 09:51:21,760: Epoch 20/38 Batch 3900/7662 eta: 18:19:03.631661	Training Loss 0.1178 (0.1304)	Training Prec@1 99.805 (99.680)	Training Prec@5 99.805 (99.905)	
2022-05-11 09:51:21,760: ============================================================
2022-05-11 09:52:08,279: time cost, forward:0.1713707226459668, backward:0.10461834181127146, data cost:0.19083046495810124 
2022-05-11 09:52:08,279: ============================================================
2022-05-11 09:52:08,279: Epoch 20/38 Batch 4000/7662 eta: 18:17:41.574914	Training Loss 0.1291 (0.1302)	Training Prec@1 99.805 (99.680)	Training Prec@5 99.805 (99.905)	
2022-05-11 09:52:08,279: ============================================================
2022-05-11 09:52:54,811: time cost, forward:0.1713646362106461, backward:0.10461427817027084, data cost:0.19079830385353774 
2022-05-11 09:52:54,812: ============================================================
2022-05-11 09:52:54,812: Epoch 20/38 Batch 4100/7662 eta: 18:17:13.602716	Training Loss 0.1231 (0.1300)	Training Prec@1 99.219 (99.680)	Training Prec@5 99.805 (99.905)	
2022-05-11 09:52:54,812: ============================================================
2022-05-11 09:53:41,356: time cost, forward:0.17136234316152457, backward:0.10461078322652012, data cost:0.19076658652265402 
2022-05-11 09:53:41,357: ============================================================
2022-05-11 09:53:41,357: Epoch 20/38 Batch 4200/7662 eta: 18:16:44.808130	Training Loss 0.1230 (0.1298)	Training Prec@1 99.414 (99.681)	Training Prec@5 99.805 (99.905)	
2022-05-11 09:53:41,357: ============================================================
2022-05-11 09:54:27,900: time cost, forward:0.17136011891210876, backward:0.1046065979154755, data cost:0.19073735051000915 
2022-05-11 09:54:27,900: ============================================================
2022-05-11 09:54:27,901: Epoch 20/38 Batch 4300/7662 eta: 18:15:56.701932	Training Loss 0.1221 (0.1297)	Training Prec@1 99.609 (99.682)	Training Prec@5 99.805 (99.905)	
2022-05-11 09:54:27,901: ============================================================
2022-05-11 09:55:14,470: time cost, forward:0.17136286014479707, backward:0.10460289312129835, data cost:0.1907096272789638 
2022-05-11 09:55:14,470: ============================================================
2022-05-11 09:55:14,470: Epoch 20/38 Batch 4400/7662 eta: 18:15:46.746497	Training Loss 0.1291 (0.1295)	Training Prec@1 99.609 (99.683)	Training Prec@5 100.000 (99.906)	
2022-05-11 09:55:14,471: ============================================================
2022-05-11 09:56:01,014: time cost, forward:0.1713599844438867, backward:0.10460040160724125, data cost:0.1906825657764205 
2022-05-11 09:56:01,014: ============================================================
2022-05-11 09:56:01,014: Epoch 20/38 Batch 4500/7662 eta: 18:14:23.793825	Training Loss 0.1234 (0.1293)	Training Prec@1 99.805 (99.684)	Training Prec@5 99.805 (99.906)	
2022-05-11 09:56:01,014: ============================================================
2022-05-11 09:56:47,582: time cost, forward:0.17136517766507509, backward:0.10459686222478705, data cost:0.1906550843499489 
2022-05-11 09:56:47,582: ============================================================
2022-05-11 09:56:47,583: Epoch 20/38 Batch 4600/7662 eta: 18:14:11.325358	Training Loss 0.1214 (0.1292)	Training Prec@1 99.609 (99.684)	Training Prec@5 99.805 (99.906)	
2022-05-11 09:56:47,583: ============================================================
2022-05-11 09:57:34,141: time cost, forward:0.17136807151489192, backward:0.10459416225682576, data cost:0.19062787589937558 
2022-05-11 09:57:34,141: ============================================================
2022-05-11 09:57:34,141: Epoch 20/38 Batch 4700/7662 eta: 18:13:11.205380	Training Loss 0.1167 (0.1290)	Training Prec@1 99.609 (99.686)	Training Prec@5 99.805 (99.907)	
2022-05-11 09:57:34,141: ============================================================
2022-05-11 09:58:20,706: time cost, forward:0.17137040612995189, backward:0.10459127930905278, data cost:0.19060403740786094 
2022-05-11 09:58:20,706: ============================================================
2022-05-11 09:58:20,706: Epoch 20/38 Batch 4800/7662 eta: 18:12:33.378265	Training Loss 0.1196 (0.1289)	Training Prec@1 99.609 (99.686)	Training Prec@5 99.805 (99.907)	
2022-05-11 09:58:20,706: ============================================================
2022-05-11 09:59:07,305: time cost, forward:0.17137921326110303, backward:0.10458804914284103, data cost:0.19058209410685134 
2022-05-11 09:59:07,306: ============================================================
2022-05-11 09:59:07,306: Epoch 20/38 Batch 4900/7662 eta: 18:12:36.308549	Training Loss 0.1175 (0.1287)	Training Prec@1 100.000 (99.687)	Training Prec@5 100.000 (99.907)	
2022-05-11 09:59:07,306: ============================================================
2022-05-11 09:59:53,876: time cost, forward:0.17138236802824738, backward:0.1045853835054578, data cost:0.19056018196742375 
2022-05-11 09:59:53,876: ============================================================
2022-05-11 09:59:53,876: Epoch 20/38 Batch 5000/7662 eta: 18:11:08.350089	Training Loss 0.1202 (0.1285)	Training Prec@1 100.000 (99.688)	Training Prec@5 100.000 (99.907)	
2022-05-11 09:59:53,876: ============================================================
2022-05-11 10:00:40,486: time cost, forward:0.17138803161857502, backward:0.10458493499247133, data cost:0.19054196310595078 
2022-05-11 10:00:40,486: ============================================================
2022-05-11 10:00:40,486: Epoch 20/38 Batch 5100/7662 eta: 18:11:16.689696	Training Loss 0.1141 (0.1284)	Training Prec@1 99.219 (99.688)	Training Prec@5 100.000 (99.907)	
2022-05-11 10:00:40,486: ============================================================
2022-05-11 10:01:27,156: time cost, forward:0.17140543802492111, backward:0.10458452712116069, data cost:0.1905242035677397 
2022-05-11 10:01:27,157: ============================================================
2022-05-11 10:01:27,157: Epoch 20/38 Batch 5200/7662 eta: 18:11:56.281757	Training Loss 0.1282 (0.1283)	Training Prec@1 99.414 (99.689)	Training Prec@5 99.609 (99.908)	
2022-05-11 10:01:27,157: ============================================================
2022-05-11 10:02:13,780: time cost, forward:0.171410155444803, backward:0.10458670798102107, data cost:0.1905072809817949 
2022-05-11 10:02:13,780: ============================================================
2022-05-11 10:02:13,780: Epoch 20/38 Batch 5300/7662 eta: 18:10:03.093765	Training Loss 0.1215 (0.1281)	Training Prec@1 100.000 (99.690)	Training Prec@5 100.000 (99.907)	
2022-05-11 10:02:13,781: ============================================================
2022-05-11 10:03:00,417: time cost, forward:0.17141765500687078, backward:0.10458750790148935, data cost:0.1904920752698966 
2022-05-11 10:03:00,417: ============================================================
2022-05-11 10:03:00,417: Epoch 20/38 Batch 5400/7662 eta: 18:09:35.044059	Training Loss 0.1132 (0.1279)	Training Prec@1 99.805 (99.691)	Training Prec@5 100.000 (99.908)	
2022-05-11 10:03:00,417: ============================================================
2022-05-11 10:03:47,027: time cost, forward:0.1714195409543429, backward:0.10458721401778584, data cost:0.19047832476006657 
2022-05-11 10:03:47,028: ============================================================
2022-05-11 10:03:47,028: Epoch 20/38 Batch 5500/7662 eta: 18:08:11.640992	Training Loss 0.1191 (0.1278)	Training Prec@1 100.000 (99.693)	Training Prec@5 100.000 (99.908)	
2022-05-11 10:03:47,028: ============================================================
2022-05-11 10:04:33,563: time cost, forward:0.1714144032817799, backward:0.10458464489640626, data cost:0.1904613534389468 
2022-05-11 10:04:33,563: ============================================================
2022-05-11 10:04:33,563: Epoch 20/38 Batch 5600/7662 eta: 18:05:39.198735	Training Loss 0.1240 (0.1277)	Training Prec@1 99.414 (99.692)	Training Prec@5 99.609 (99.908)	
2022-05-11 10:04:33,563: ============================================================
2022-05-11 10:05:20,114: time cost, forward:0.17141328805119221, backward:0.10458224241012731, data cost:0.19044400047975624 
2022-05-11 10:05:20,115: ============================================================
2022-05-11 10:05:20,115: Epoch 20/38 Batch 5700/7662 eta: 18:05:16.434125	Training Loss 0.1279 (0.1276)	Training Prec@1 100.000 (99.693)	Training Prec@5 100.000 (99.908)	
2022-05-11 10:05:20,115: ============================================================
2022-05-11 10:06:06,680: time cost, forward:0.17141138358164665, backward:0.10458092575217963, data cost:0.1904294459156629 
2022-05-11 10:06:06,680: ============================================================
2022-05-11 10:06:06,681: Epoch 20/38 Batch 5800/7662 eta: 18:04:49.043551	Training Loss 0.1162 (0.1274)	Training Prec@1 99.609 (99.694)	Training Prec@5 100.000 (99.908)	
2022-05-11 10:06:06,681: ============================================================
2022-05-11 10:06:53,220: time cost, forward:0.171407978420319, backward:0.10457857270668393, data cost:0.19041385115516613 
2022-05-11 10:06:53,221: ============================================================
2022-05-11 10:06:53,221: Epoch 20/38 Batch 5900/7662 eta: 18:03:26.845323	Training Loss 0.1217 (0.1273)	Training Prec@1 99.805 (99.695)	Training Prec@5 100.000 (99.909)	
2022-05-11 10:06:53,221: ============================================================
2022-05-11 10:07:39,762: time cost, forward:0.1714031367644526, backward:0.10457715254502409, data cost:0.19039920747906075 
2022-05-11 10:07:39,762: ============================================================
2022-05-11 10:07:39,762: Epoch 20/38 Batch 6000/7662 eta: 18:02:41.844935	Training Loss 0.1200 (0.1271)	Training Prec@1 99.805 (99.696)	Training Prec@5 100.000 (99.909)	
2022-05-11 10:07:39,762: ============================================================
2022-05-11 10:08:26,332: time cost, forward:0.17140229640778684, backward:0.10457571460919647, data cost:0.1903860989233024 
2022-05-11 10:08:26,333: ============================================================
2022-05-11 10:08:26,333: Epoch 20/38 Batch 6100/7662 eta: 18:02:36.372494	Training Loss 0.1178 (0.1270)	Training Prec@1 99.609 (99.696)	Training Prec@5 100.000 (99.909)	
2022-05-11 10:08:26,333: ============================================================
2022-05-11 10:09:12,942: time cost, forward:0.17140477856314362, backward:0.10457580749941249, data cost:0.19037483457327467 
2022-05-11 10:09:12,942: ============================================================
2022-05-11 10:09:12,942: Epoch 20/38 Batch 6200/7662 eta: 18:02:43.928016	Training Loss 0.1282 (0.1269)	Training Prec@1 99.609 (99.697)	Training Prec@5 99.805 (99.910)	
2022-05-11 10:09:12,942: ============================================================
2022-05-11 10:09:59,573: time cost, forward:0.17140999380076266, backward:0.10457729165337165, data cost:0.1903633402915091 
2022-05-11 10:09:59,574: ============================================================
2022-05-11 10:09:59,574: Epoch 20/38 Batch 6300/7662 eta: 18:02:28.157196	Training Loss 0.1184 (0.1268)	Training Prec@1 100.000 (99.698)	Training Prec@5 100.000 (99.910)	
2022-05-11 10:09:59,574: ============================================================
2022-05-11 10:10:46,203: time cost, forward:0.1714131669302176, backward:0.1045791292063872, data cost:0.190353440985044 
2022-05-11 10:10:46,204: ============================================================
2022-05-11 10:10:46,204: Epoch 20/38 Batch 6400/7662 eta: 18:01:38.831385	Training Loss 0.1198 (0.1267)	Training Prec@1 99.219 (99.698)	Training Prec@5 99.805 (99.910)	
2022-05-11 10:10:46,204: ============================================================
2022-05-11 10:11:32,882: time cost, forward:0.17141817272360607, backward:0.10458758552728534, data cost:0.19034261849499204 
2022-05-11 10:11:32,882: ============================================================
2022-05-11 10:11:32,882: Epoch 20/38 Batch 6500/7662 eta: 18:01:59.865918	Training Loss 0.1240 (0.1266)	Training Prec@1 99.805 (99.698)	Training Prec@5 100.000 (99.910)	
2022-05-11 10:11:32,882: ============================================================
2022-05-11 10:12:19,574: time cost, forward:0.17141781324400182, backward:0.10460426146594985, data cost:0.19033111780227036 
2022-05-11 10:12:19,575: ============================================================
2022-05-11 10:12:19,575: Epoch 20/38 Batch 6600/7662 eta: 18:01:33.175640	Training Loss 0.1139 (0.1264)	Training Prec@1 99.805 (99.699)	Training Prec@5 100.000 (99.911)	
2022-05-11 10:12:19,575: ============================================================
2022-05-11 10:13:06,129: time cost, forward:0.17141505134054077, backward:0.10460343103228015, data cost:0.1903186542700611 
2022-05-11 10:13:06,129: ============================================================
2022-05-11 10:13:06,129: Epoch 20/38 Batch 6700/7662 eta: 17:57:34.403007	Training Loss 0.1160 (0.1263)	Training Prec@1 99.609 (99.701)	Training Prec@5 99.805 (99.911)	
2022-05-11 10:13:06,130: ============================================================
2022-05-11 10:13:52,750: time cost, forward:0.1714206669396873, backward:0.10460257915946242, data cost:0.1903082662723506 
2022-05-11 10:13:52,751: ============================================================
2022-05-11 10:13:52,751: Epoch 20/38 Batch 6800/7662 eta: 17:58:20.772427	Training Loss 0.1242 (0.1262)	Training Prec@1 99.805 (99.701)	Training Prec@5 100.000 (99.912)	
2022-05-11 10:13:52,751: ============================================================
2022-05-11 10:14:39,313: time cost, forward:0.1714176841362056, backward:0.10460221330261452, data cost:0.1902978832194003 
2022-05-11 10:14:39,314: ============================================================
2022-05-11 10:14:39,314: Epoch 20/38 Batch 6900/7662 eta: 17:56:13.014109	Training Loss 0.1250 (0.1261)	Training Prec@1 99.805 (99.702)	Training Prec@5 99.805 (99.912)	
2022-05-11 10:14:39,314: ============================================================
2022-05-11 10:15:25,906: time cost, forward:0.17141915631474794, backward:0.10460154011106812, data cost:0.19028775598989553 
2022-05-11 10:15:25,906: ============================================================
2022-05-11 10:15:25,906: Epoch 20/38 Batch 7000/7662 eta: 17:56:07.202803	Training Loss 0.1195 (0.1260)	Training Prec@1 99.805 (99.703)	Training Prec@5 100.000 (99.912)	
2022-05-11 10:15:25,906: ============================================================
2022-05-11 10:16:12,829: time cost, forward:0.17146346692989234, backward:0.10460275602199642, data cost:0.19027996422589907 
2022-05-11 10:16:12,829: ============================================================
2022-05-11 10:16:12,829: Epoch 20/38 Batch 7100/7662 eta: 18:02:58.629407	Training Loss 0.1234 (0.1259)	Training Prec@1 99.609 (99.703)	Training Prec@5 100.000 (99.912)	
2022-05-11 10:16:12,829: ============================================================
2022-05-11 10:16:59,493: time cost, forward:0.1714753049465497, backward:0.10460301693453856, data cost:0.19026832177185618 
2022-05-11 10:16:59,493: ============================================================
2022-05-11 10:16:59,494: Epoch 20/38 Batch 7200/7662 eta: 17:56:13.713389	Training Loss 0.1193 (0.1258)	Training Prec@1 99.805 (99.704)	Training Prec@5 100.000 (99.913)	
2022-05-11 10:16:59,494: ============================================================
2022-05-11 10:17:46,123: time cost, forward:0.17148335565686437, backward:0.10460197130185739, data cost:0.19025706421726288 
2022-05-11 10:17:46,123: ============================================================
2022-05-11 10:17:46,124: Epoch 20/38 Batch 7300/7662 eta: 17:54:39.390711	Training Loss 0.1106 (0.1257)	Training Prec@1 99.805 (99.704)	Training Prec@5 100.000 (99.913)	
2022-05-11 10:17:46,124: ============================================================
2022-05-11 10:18:32,749: time cost, forward:0.17149037070363934, backward:0.10460123611086203, data cost:0.19024623292638637 
2022-05-11 10:18:32,750: ============================================================
2022-05-11 10:18:32,750: Epoch 20/38 Batch 7400/7662 eta: 17:53:47.602678	Training Loss 0.1247 (0.1256)	Training Prec@1 99.805 (99.705)	Training Prec@5 100.000 (99.913)	
2022-05-11 10:18:32,750: ============================================================
2022-05-11 10:19:19,412: time cost, forward:0.1714999612799834, backward:0.10460110546223464, data cost:0.1902372877126313 
2022-05-11 10:19:19,413: ============================================================
2022-05-11 10:19:19,413: Epoch 20/38 Batch 7500/7662 eta: 17:53:51.830254	Training Loss 0.1234 (0.1255)	Training Prec@1 99.609 (99.705)	Training Prec@5 100.000 (99.913)	
2022-05-11 10:19:19,413: ============================================================
2022-05-11 10:20:06,024: time cost, forward:0.1715052579324298, backward:0.10460132450661482, data cost:0.19022544686269377 
2022-05-11 10:20:06,024: ============================================================
2022-05-11 10:20:06,024: Epoch 20/38 Batch 7600/7662 eta: 17:51:53.903648	Training Loss 0.1315 (0.1254)	Training Prec@1 99.219 (99.705)	Training Prec@5 99.805 (99.913)	
2022-05-11 10:20:06,024: ============================================================
2022-05-11 10:20:36,573: Epoch: 20/38 eta: 17:51:24.538484	Training Loss 0.1249 (0.1253)	Training Prec@1 99.609 (99.706)	Training Prec@5 99.805 (99.913)
2022-05-11 10:20:36,573: ============================================================
2022-05-11 10:20:36,684: Save Checkpoint...
2022-05-11 10:20:36,686: ============================================================
2022-05-11 10:20:39,359: Save done!
2022-05-11 10:20:39,359: ============================================================
2022-05-11 10:21:29,796: time cost, forward:0.18826640013492468, backward:0.10602026997190533, data cost:0.21269124926942767 
2022-05-11 10:21:29,797: ============================================================
2022-05-11 10:21:29,797: Epoch 21/38 Batch 100/7662 eta: 19:17:47.421776	Training Loss 0.1066 (0.1078)	Training Prec@1 100.000 (99.836)	Training Prec@5 100.000 (99.955)	
2022-05-11 10:21:29,797: ============================================================
2022-05-11 10:22:16,625: time cost, forward:0.18003017578891772, backward:0.10602758398008107, data cost:0.20129142813946135 
2022-05-11 10:22:16,626: ============================================================
2022-05-11 10:22:16,626: Epoch 21/38 Batch 200/7662 eta: 17:54:51.378020	Training Loss 0.1041 (0.1074)	Training Prec@1 99.805 (99.832)	Training Prec@5 100.000 (99.950)	
2022-05-11 10:22:16,626: ============================================================
2022-05-11 10:23:03,486: time cost, forward:0.17721447019672712, backward:0.10606011897823882, data cost:0.1976796799280173 
2022-05-11 10:23:03,486: ============================================================
2022-05-11 10:23:03,486: Epoch 21/38 Batch 300/7662 eta: 17:54:47.756857	Training Loss 0.1059 (0.1072)	Training Prec@1 99.805 (99.830)	Training Prec@5 99.805 (99.949)	
2022-05-11 10:23:03,486: ============================================================
2022-05-11 10:23:50,360: time cost, forward:0.17586268936482288, backward:0.10607533586353886, data cost:0.19588771918064968 
2022-05-11 10:23:50,360: ============================================================
2022-05-11 10:23:50,360: Epoch 21/38 Batch 400/7662 eta: 17:54:19.745565	Training Loss 0.1027 (0.1072)	Training Prec@1 99.805 (99.830)	Training Prec@5 99.805 (99.949)	
2022-05-11 10:23:50,360: ============================================================
2022-05-11 10:24:37,318: time cost, forward:0.17512805332879505, backward:0.10607811205372782, data cost:0.1949174141358278 
2022-05-11 10:24:37,318: ============================================================
2022-05-11 10:24:37,319: Epoch 21/38 Batch 500/7662 eta: 17:55:29.139721	Training Loss 0.1067 (0.1073)	Training Prec@1 99.805 (99.826)	Training Prec@5 100.000 (99.947)	
2022-05-11 10:24:37,319: ============================================================
2022-05-11 10:25:24,200: time cost, forward:0.1745751214544841, backward:0.10607280237646852, data cost:0.19417436373651725 
2022-05-11 10:25:24,200: ============================================================
2022-05-11 10:25:24,200: Epoch 21/38 Batch 600/7662 eta: 17:52:56.376092	Training Loss 0.1061 (0.1073)	Training Prec@1 99.805 (99.829)	Training Prec@5 99.805 (99.948)	
2022-05-11 10:25:24,200: ============================================================
2022-05-11 10:26:11,004: time cost, forward:0.17420798889727723, backward:0.10595886321879593, data cost:0.1936453333569528 
2022-05-11 10:26:11,004: ============================================================
2022-05-11 10:26:11,005: Epoch 21/38 Batch 700/7662 eta: 17:50:23.581071	Training Loss 0.1078 (0.1073)	Training Prec@1 99.805 (99.828)	Training Prec@5 99.805 (99.947)	
2022-05-11 10:26:11,005: ============================================================
2022-05-11 10:26:57,707: time cost, forward:0.17390878209482893, backward:0.10578334256913396, data cost:0.19324383926630317 
2022-05-11 10:26:57,707: ============================================================
2022-05-11 10:26:57,707: Epoch 21/38 Batch 800/7662 eta: 17:47:17.454787	Training Loss 0.1012 (0.1073)	Training Prec@1 100.000 (99.830)	Training Prec@5 100.000 (99.947)	
2022-05-11 10:26:57,708: ============================================================
2022-05-11 10:27:44,412: time cost, forward:0.1736964211448016, backward:0.10564531765472107, data cost:0.19291422841811473 
2022-05-11 10:27:44,412: ============================================================
2022-05-11 10:27:44,412: Epoch 21/38 Batch 900/7662 eta: 17:46:33.220026	Training Loss 0.1016 (0.1074)	Training Prec@1 100.000 (99.831)	Training Prec@5 100.000 (99.947)	
2022-05-11 10:27:44,412: ============================================================
2022-05-11 10:28:31,158: time cost, forward:0.17351389313125992, backward:0.1055653677569018, data cost:0.19267299822023562 
2022-05-11 10:28:31,158: ============================================================
2022-05-11 10:28:31,158: Epoch 21/38 Batch 1000/7662 eta: 17:46:43.579970	Training Loss 0.1038 (0.1074)	Training Prec@1 100.000 (99.831)	Training Prec@5 100.000 (99.948)	
2022-05-11 10:28:31,158: ============================================================
2022-05-11 10:29:17,986: time cost, forward:0.17335551711404398, backward:0.10552649936207432, data cost:0.1924990846201764 
2022-05-11 10:29:17,987: ============================================================
2022-05-11 10:29:17,987: Epoch 21/38 Batch 1100/7662 eta: 17:47:49.300938	Training Loss 0.1061 (0.1074)	Training Prec@1 99.805 (99.828)	Training Prec@5 100.000 (99.947)	
2022-05-11 10:29:17,987: ============================================================
2022-05-11 10:30:04,745: time cost, forward:0.17323095048836015, backward:0.10544230343402675, data cost:0.19236360359828208 
2022-05-11 10:30:04,745: ============================================================
2022-05-11 10:30:04,746: Epoch 21/38 Batch 1200/7662 eta: 17:45:27.356413	Training Loss 0.1039 (0.1075)	Training Prec@1 100.000 (99.828)	Training Prec@5 100.000 (99.947)	
2022-05-11 10:30:04,746: ============================================================
2022-05-11 10:30:51,513: time cost, forward:0.1731412965027161, backward:0.10537331686100655, data cost:0.19224832661799782 
2022-05-11 10:30:51,513: ============================================================
2022-05-11 10:30:51,513: Epoch 21/38 Batch 1300/7662 eta: 17:44:52.214008	Training Loss 0.1031 (0.1075)	Training Prec@1 99.805 (99.828)	Training Prec@5 100.000 (99.947)	
2022-05-11 10:30:51,513: ============================================================
2022-05-11 10:31:38,392: time cost, forward:0.17308486215211052, backward:0.10539178118865945, data cost:0.19213191213737307 
2022-05-11 10:31:38,393: ============================================================
2022-05-11 10:31:38,393: Epoch 21/38 Batch 1400/7662 eta: 17:46:38.790895	Training Loss 0.1062 (0.1076)	Training Prec@1 99.805 (99.827)	Training Prec@5 99.805 (99.947)	
2022-05-11 10:31:38,393: ============================================================
2022-05-11 10:32:25,374: time cost, forward:0.17306666043378896, backward:0.10543472882984001, data cost:0.19203670570419343 
2022-05-11 10:32:25,374: ============================================================
2022-05-11 10:32:25,374: Epoch 21/38 Batch 1500/7662 eta: 17:48:11.014879	Training Loss 0.1098 (0.1077)	Training Prec@1 100.000 (99.823)	Training Prec@5 100.000 (99.947)	
2022-05-11 10:32:25,375: ============================================================
2022-05-11 10:33:12,330: time cost, forward:0.17303025342286416, backward:0.10547320823359295, data cost:0.19195645507087256 
2022-05-11 10:33:12,330: ============================================================
2022-05-11 10:33:12,331: Epoch 21/38 Batch 1600/7662 eta: 17:46:49.109769	Training Loss 0.1077 (0.1078)	Training Prec@1 99.805 (99.824)	Training Prec@5 100.000 (99.947)	
2022-05-11 10:33:12,331: ============================================================
2022-05-11 10:33:59,165: time cost, forward:0.1730145514186794, backward:0.10547123213527201, data cost:0.19183477069996188 
2022-05-11 10:33:59,165: ============================================================
2022-05-11 10:33:59,166: Epoch 21/38 Batch 1700/7662 eta: 17:43:17.268701	Training Loss 0.1004 (0.1078)	Training Prec@1 100.000 (99.825)	Training Prec@5 100.000 (99.947)	
2022-05-11 10:33:59,166: ============================================================
2022-05-11 10:34:45,898: time cost, forward:0.17299032105280995, backward:0.10542048156890954, data cost:0.19172926966914738 
2022-05-11 10:34:45,898: ============================================================
2022-05-11 10:34:45,899: Epoch 21/38 Batch 1800/7662 eta: 17:40:11.626140	Training Loss 0.1070 (0.1078)	Training Prec@1 100.000 (99.826)	Training Prec@5 100.000 (99.947)	
2022-05-11 10:34:45,899: ============================================================
2022-05-11 10:35:32,603: time cost, forward:0.17295095153455045, backward:0.10537391062973046, data cost:0.19163222423410842 
2022-05-11 10:35:32,603: ============================================================
2022-05-11 10:35:32,604: Epoch 21/38 Batch 1900/7662 eta: 17:38:46.783525	Training Loss 0.1054 (0.1079)	Training Prec@1 99.805 (99.826)	Training Prec@5 100.000 (99.947)	
2022-05-11 10:35:32,604: ============================================================
2022-05-11 10:36:19,335: time cost, forward:0.17291915661218824, backward:0.10533399567596909, data cost:0.19155846553304423 
2022-05-11 10:36:19,335: ============================================================
2022-05-11 10:36:19,336: Epoch 21/38 Batch 2000/7662 eta: 17:38:36.698244	Training Loss 0.1053 (0.1079)	Training Prec@1 99.609 (99.826)	Training Prec@5 100.000 (99.946)	
2022-05-11 10:36:19,336: ============================================================
2022-05-11 10:37:06,074: time cost, forward:0.17288271605031386, backward:0.10529384038288177, data cost:0.1915050139025088 
2022-05-11 10:37:06,074: ============================================================
2022-05-11 10:37:06,074: Epoch 21/38 Batch 2100/7662 eta: 17:37:59.071242	Training Loss 0.1075 (0.1079)	Training Prec@1 100.000 (99.825)	Training Prec@5 100.000 (99.946)	
2022-05-11 10:37:06,074: ============================================================
2022-05-11 10:37:52,697: time cost, forward:0.17283419881857975, backward:0.10525720961910315, data cost:0.19142255711522954 
2022-05-11 10:37:52,698: ============================================================
2022-05-11 10:37:52,698: Epoch 21/38 Batch 2200/7662 eta: 17:34:36.052854	Training Loss 0.0989 (0.1079)	Training Prec@1 100.000 (99.824)	Training Prec@5 100.000 (99.946)	
2022-05-11 10:37:52,698: ============================================================
2022-05-11 10:38:39,336: time cost, forward:0.17280042477409027, backward:0.10522647845636196, data cost:0.19133970280116722 
2022-05-11 10:38:39,336: ============================================================
2022-05-11 10:38:39,337: Epoch 21/38 Batch 2300/7662 eta: 17:34:09.972163	Training Loss 0.1053 (0.1079)	Training Prec@1 100.000 (99.825)	Training Prec@5 100.000 (99.946)	
2022-05-11 10:38:39,337: ============================================================
2022-05-11 10:39:26,040: time cost, forward:0.17276654406456513, backward:0.1051971981951772, data cost:0.1912863968113354 
2022-05-11 10:39:26,041: ============================================================
2022-05-11 10:39:26,041: Epoch 21/38 Batch 2400/7662 eta: 17:34:52.155309	Training Loss 0.1076 (0.1079)	Training Prec@1 100.000 (99.825)	Training Prec@5 100.000 (99.946)	
2022-05-11 10:39:26,041: ============================================================
2022-05-11 10:40:12,719: time cost, forward:0.17270946197387646, backward:0.10516690912128401, data cost:0.19124852766652925 
2022-05-11 10:40:12,719: ============================================================
2022-05-11 10:40:12,719: Epoch 21/38 Batch 2500/7662 eta: 17:33:30.440230	Training Loss 0.1035 (0.1079)	Training Prec@1 99.805 (99.824)	Training Prec@5 99.805 (99.945)	
2022-05-11 10:40:12,719: ============================================================
2022-05-11 10:40:59,423: time cost, forward:0.17266907266306392, backward:0.10514039129144918, data cost:0.19122718040096434 
2022-05-11 10:40:59,424: ============================================================
2022-05-11 10:40:59,424: Epoch 21/38 Batch 2600/7662 eta: 17:33:19.405342	Training Loss 0.1071 (0.1079)	Training Prec@1 100.000 (99.823)	Training Prec@5 100.000 (99.945)	
2022-05-11 10:40:59,424: ============================================================
2022-05-11 10:41:46,180: time cost, forward:0.17264592519465444, backward:0.1051175276320614, data cost:0.19119836949295094 
2022-05-11 10:41:46,180: ============================================================
2022-05-11 10:41:46,181: Epoch 21/38 Batch 2700/7662 eta: 17:33:43.058028	Training Loss 0.1093 (0.1080)	Training Prec@1 99.805 (99.822)	Training Prec@5 100.000 (99.944)	
2022-05-11 10:41:46,181: ============================================================
2022-05-11 10:42:32,876: time cost, forward:0.172621093677086, backward:0.10509623685620775, data cost:0.19116040347686364 
2022-05-11 10:42:32,876: ============================================================
2022-05-11 10:42:32,877: Epoch 21/38 Batch 2800/7662 eta: 17:31:34.163904	Training Loss 0.1100 (0.1080)	Training Prec@1 99.805 (99.822)	Training Prec@5 99.805 (99.944)	
2022-05-11 10:42:32,877: ============================================================
2022-05-11 10:43:19,567: time cost, forward:0.17260841510755598, backward:0.10507522808678935, data cost:0.19111677834641402 
2022-05-11 10:43:19,567: ============================================================
2022-05-11 10:43:19,567: Epoch 21/38 Batch 2900/7662 eta: 17:30:39.992986	Training Loss 0.1096 (0.1080)	Training Prec@1 99.805 (99.821)	Training Prec@5 99.805 (99.943)	
2022-05-11 10:43:19,567: ============================================================
2022-05-11 10:44:06,214: time cost, forward:0.17258851915329607, backward:0.1050551072801499, data cost:0.19106909409090853 
2022-05-11 10:44:06,215: ============================================================
2022-05-11 10:44:06,215: Epoch 21/38 Batch 3000/7662 eta: 17:28:56.122693	Training Loss 0.1071 (0.1080)	Training Prec@1 99.805 (99.820)	Training Prec@5 100.000 (99.943)	
2022-05-11 10:44:06,215: ============================================================
2022-05-11 10:44:52,911: time cost, forward:0.17256923912801678, backward:0.10504075372246012, data cost:0.19104050243620183 
2022-05-11 10:44:52,911: ============================================================
2022-05-11 10:44:52,911: Epoch 21/38 Batch 3100/7662 eta: 17:29:14.478490	Training Loss 0.1010 (0.1081)	Training Prec@1 99.609 (99.821)	Training Prec@5 100.000 (99.944)	
2022-05-11 10:44:52,911: ============================================================
2022-05-11 10:45:39,547: time cost, forward:0.17253889661909977, backward:0.10502405649574521, data cost:0.1910076561701525 
2022-05-11 10:45:39,547: ============================================================
2022-05-11 10:45:39,547: Epoch 21/38 Batch 3200/7662 eta: 17:27:06.791204	Training Loss 0.1066 (0.1081)	Training Prec@1 99.805 (99.821)	Training Prec@5 99.805 (99.944)	
2022-05-11 10:45:39,547: ============================================================
2022-05-11 10:46:26,152: time cost, forward:0.17251469807828618, backward:0.10500952900449737, data cost:0.19096248104341754 
2022-05-11 10:46:26,153: ============================================================
2022-05-11 10:46:26,153: Epoch 21/38 Batch 3300/7662 eta: 17:25:38.974055	Training Loss 0.1051 (0.1081)	Training Prec@1 99.805 (99.821)	Training Prec@5 99.805 (99.944)	
2022-05-11 10:46:26,153: ============================================================
2022-05-11 10:47:12,825: time cost, forward:0.17249307649280787, backward:0.10499653826043269, data cost:0.19093741420859203 
2022-05-11 10:47:12,826: ============================================================
2022-05-11 10:47:12,826: Epoch 21/38 Batch 3400/7662 eta: 17:26:23.099657	Training Loss 0.1110 (0.1081)	Training Prec@1 100.000 (99.821)	Training Prec@5 100.000 (99.944)	
2022-05-11 10:47:12,826: ============================================================
2022-05-11 10:47:59,453: time cost, forward:0.17247631087170973, backward:0.10498395719743518, data cost:0.19089773758100284 
2022-05-11 10:47:59,453: ============================================================
2022-05-11 10:47:59,453: Epoch 21/38 Batch 3500/7662 eta: 17:24:35.407892	Training Loss 0.1106 (0.1081)	Training Prec@1 100.000 (99.821)	Training Prec@5 100.000 (99.944)	
2022-05-11 10:47:59,454: ============================================================
2022-05-11 10:48:46,102: time cost, forward:0.17245781120243056, backward:0.10497268586398562, data cost:0.19086867300925503 
2022-05-11 10:48:46,103: ============================================================
2022-05-11 10:48:46,103: Epoch 21/38 Batch 3600/7662 eta: 17:24:17.951942	Training Loss 0.1101 (0.1081)	Training Prec@1 99.609 (99.821)	Training Prec@5 99.805 (99.944)	
2022-05-11 10:48:46,103: ============================================================
2022-05-11 10:49:32,678: time cost, forward:0.17243177293280906, backward:0.1049608234844842, data cost:0.19083093281983363 
2022-05-11 10:49:32,679: ============================================================
2022-05-11 10:49:32,679: Epoch 21/38 Batch 3700/7662 eta: 17:21:52.935487	Training Loss 0.1079 (0.1082)	Training Prec@1 99.609 (99.821)	Training Prec@5 100.000 (99.944)	
2022-05-11 10:49:32,679: ============================================================
2022-05-11 10:50:19,274: time cost, forward:0.17241328344372706, backward:0.1049490842294555, data cost:0.19079467885649246 
2022-05-11 10:50:19,274: ============================================================
2022-05-11 10:50:19,275: Epoch 21/38 Batch 3800/7662 eta: 17:21:32.960929	Training Loss 0.1041 (0.1082)	Training Prec@1 100.000 (99.821)	Training Prec@5 100.000 (99.945)	
2022-05-11 10:50:19,275: ============================================================
2022-05-11 10:51:05,769: time cost, forward:0.17237047710061593, backward:0.10493741949022228, data cost:0.19076051899150995 
2022-05-11 10:51:05,770: ============================================================
2022-05-11 10:51:05,770: Epoch 21/38 Batch 3900/7662 eta: 17:18:31.236907	Training Loss 0.1122 (0.1082)	Training Prec@1 100.000 (99.820)	Training Prec@5 100.000 (99.945)	
2022-05-11 10:51:05,770: ============================================================
2022-05-11 10:51:52,297: time cost, forward:0.17233332159162074, backward:0.10492853511420153, data cost:0.19073029529097438 
2022-05-11 10:51:52,297: ============================================================
2022-05-11 10:51:52,297: Epoch 21/38 Batch 4000/7662 eta: 17:18:28.271970	Training Loss 0.1115 (0.1082)	Training Prec@1 100.000 (99.820)	Training Prec@5 100.000 (99.944)	
2022-05-11 10:51:52,297: ============================================================
2022-05-11 10:52:38,866: time cost, forward:0.17231040234739067, backward:0.10491863859371606, data cost:0.19070032824246178 
2022-05-11 10:52:38,867: ============================================================
2022-05-11 10:52:38,867: Epoch 21/38 Batch 4100/7662 eta: 17:18:37.952759	Training Loss 0.1114 (0.1082)	Training Prec@1 99.609 (99.820)	Training Prec@5 99.805 (99.945)	
2022-05-11 10:52:38,867: ============================================================
2022-05-11 10:53:25,430: time cost, forward:0.17229081960370582, backward:0.10491022889913335, data cost:0.19066773831603015 
2022-05-11 10:53:25,430: ============================================================
2022-05-11 10:53:25,430: Epoch 21/38 Batch 4200/7662 eta: 17:17:43.238685	Training Loss 0.1089 (0.1082)	Training Prec@1 99.609 (99.821)	Training Prec@5 99.805 (99.945)	
2022-05-11 10:53:25,430: ============================================================
2022-05-11 10:54:12,014: time cost, forward:0.17227317949149962, backward:0.10490244952820989, data cost:0.19064015148683713 
2022-05-11 10:54:12,014: ============================================================
2022-05-11 10:54:12,015: Epoch 21/38 Batch 4300/7662 eta: 17:17:24.601528	Training Loss 0.1036 (0.1082)	Training Prec@1 100.000 (99.821)	Training Prec@5 100.000 (99.945)	
2022-05-11 10:54:12,015: ============================================================
2022-05-11 10:54:58,615: time cost, forward:0.1722604573165918, backward:0.10489421238761568, data cost:0.19061375455602675 
2022-05-11 10:54:58,615: ============================================================
2022-05-11 10:54:58,615: Epoch 21/38 Batch 4400/7662 eta: 17:16:59.494547	Training Loss 0.1078 (0.1082)	Training Prec@1 100.000 (99.821)	Training Prec@5 100.000 (99.946)	
2022-05-11 10:54:58,615: ============================================================
2022-05-11 10:55:45,271: time cost, forward:0.1722530045226352, backward:0.10488732175367041, data cost:0.1905953975803827 
2022-05-11 10:55:45,271: ============================================================
2022-05-11 10:55:45,271: Epoch 21/38 Batch 4500/7662 eta: 17:17:27.068148	Training Loss 0.1086 (0.1082)	Training Prec@1 100.000 (99.821)	Training Prec@5 100.000 (99.945)	
2022-05-11 10:55:45,271: ============================================================
2022-05-11 10:56:31,887: time cost, forward:0.17224360678760506, backward:0.1048793211582563, data cost:0.19057290941301858 
2022-05-11 10:56:31,887: ============================================================
2022-05-11 10:56:31,887: Epoch 21/38 Batch 4600/7662 eta: 17:15:47.481419	Training Loss 0.1098 (0.1083)	Training Prec@1 99.805 (99.820)	Training Prec@5 100.000 (99.945)	
2022-05-11 10:56:31,887: ============================================================
2022-05-11 10:57:18,490: time cost, forward:0.1722333295773029, backward:0.10487208008182686, data cost:0.1905499485407162 
2022-05-11 10:57:18,491: ============================================================
2022-05-11 10:57:18,491: Epoch 21/38 Batch 4700/7662 eta: 17:14:43.659308	Training Loss 0.1128 (0.1083)	Training Prec@1 99.023 (99.820)	Training Prec@5 99.805 (99.945)	
2022-05-11 10:57:18,491: ============================================================
2022-05-11 10:58:05,061: time cost, forward:0.1722199522373353, backward:0.1048641870061068, data cost:0.19052556724095251 
2022-05-11 10:58:05,062: ============================================================
2022-05-11 10:58:05,062: Epoch 21/38 Batch 4800/7662 eta: 17:13:14.104819	Training Loss 0.1098 (0.1083)	Training Prec@1 100.000 (99.819)	Training Prec@5 100.000 (99.945)	
2022-05-11 10:58:05,062: ============================================================
2022-05-11 10:58:51,675: time cost, forward:0.1722124427356241, backward:0.10485755246277852, data cost:0.1905046332780379 
2022-05-11 10:58:51,675: ============================================================
2022-05-11 10:58:51,676: Epoch 21/38 Batch 4900/7662 eta: 17:13:24.150288	Training Loss 0.1127 (0.1083)	Training Prec@1 99.609 (99.820)	Training Prec@5 100.000 (99.945)	
2022-05-11 10:58:51,676: ============================================================
2022-05-11 10:59:38,219: time cost, forward:0.17219401545752572, backward:0.10485014511981376, data cost:0.1904823139539407 
2022-05-11 10:59:38,219: ============================================================
2022-05-11 10:59:38,219: Epoch 21/38 Batch 5000/7662 eta: 17:11:04.086607	Training Loss 0.1113 (0.1083)	Training Prec@1 100.000 (99.819)	Training Prec@5 100.000 (99.945)	
2022-05-11 10:59:38,219: ============================================================
2022-05-11 11:00:24,800: time cost, forward:0.1721829459535816, backward:0.10484308092050353, data cost:0.19046170221962025 
2022-05-11 11:00:24,800: ============================================================
2022-05-11 11:00:24,800: Epoch 21/38 Batch 5100/7662 eta: 17:11:07.867198	Training Loss 0.1054 (0.1083)	Training Prec@1 99.414 (99.820)	Training Prec@5 100.000 (99.945)	
2022-05-11 11:00:24,800: ============================================================
2022-05-11 11:01:11,406: time cost, forward:0.17217636145085274, backward:0.10483690591288612, data cost:0.19044185051621784 
2022-05-11 11:01:11,406: ============================================================
2022-05-11 11:01:11,406: Epoch 21/38 Batch 5200/7662 eta: 17:10:54.245691	Training Loss 0.1126 (0.1084)	Training Prec@1 100.000 (99.820)	Training Prec@5 100.000 (99.945)	
2022-05-11 11:01:11,407: ============================================================
2022-05-11 11:01:57,987: time cost, forward:0.17216548602026258, backward:0.1048309859700373, data cost:0.1904227670621683 
2022-05-11 11:01:57,988: ============================================================
2022-05-11 11:01:57,988: Epoch 21/38 Batch 5300/7662 eta: 17:09:34.921527	Training Loss 0.1106 (0.1084)	Training Prec@1 100.000 (99.819)	Training Prec@5 100.000 (99.945)	
2022-05-11 11:01:57,988: ============================================================
2022-05-11 11:02:44,595: time cost, forward:0.1721603245972748, backward:0.104824728602766, data cost:0.19040425739192945 
2022-05-11 11:02:44,596: ============================================================
2022-05-11 11:02:44,596: Epoch 21/38 Batch 5400/7662 eta: 17:09:23.378078	Training Loss 0.1082 (0.1084)	Training Prec@1 100.000 (99.819)	Training Prec@5 100.000 (99.946)	
2022-05-11 11:02:44,596: ============================================================
2022-05-11 11:03:31,175: time cost, forward:0.1721507802749248, backward:0.1048189161647166, data cost:0.19038594473620116 
2022-05-11 11:03:31,175: ============================================================
2022-05-11 11:03:31,175: Epoch 21/38 Batch 5500/7662 eta: 17:07:59.321371	Training Loss 0.1091 (0.1084)	Training Prec@1 100.000 (99.819)	Training Prec@5 100.000 (99.946)	
2022-05-11 11:03:31,175: ============================================================
2022-05-11 11:04:17,771: time cost, forward:0.17214247336833047, backward:0.10481303149961024, data cost:0.19037027600876538 
2022-05-11 11:04:17,771: ============================================================
2022-05-11 11:04:17,771: Epoch 21/38 Batch 5600/7662 eta: 17:07:33.861734	Training Loss 0.1085 (0.1084)	Training Prec@1 99.805 (99.819)	Training Prec@5 100.000 (99.946)	
2022-05-11 11:04:17,771: ============================================================
2022-05-11 11:05:04,407: time cost, forward:0.1721329755543784, backward:0.10481706270524799, data cost:0.19035453088535806 
2022-05-11 11:05:04,407: ============================================================
2022-05-11 11:05:04,407: Epoch 21/38 Batch 5700/7662 eta: 17:07:41.289317	Training Loss 0.1070 (0.1084)	Training Prec@1 100.000 (99.818)	Training Prec@5 100.000 (99.945)	
2022-05-11 11:05:04,407: ============================================================
2022-05-11 11:05:51,156: time cost, forward:0.17212303952320543, backward:0.10483979866368583, data cost:0.19034034425913413 
2022-05-11 11:05:51,156: ============================================================
2022-05-11 11:05:51,156: Epoch 21/38 Batch 5800/7662 eta: 17:09:23.166326	Training Loss 0.1029 (0.1084)	Training Prec@1 100.000 (99.819)	Training Prec@5 100.000 (99.946)	
2022-05-11 11:05:51,156: ============================================================
2022-05-11 11:06:37,922: time cost, forward:0.17211776144283467, backward:0.10486079559707706, data cost:0.19032636915835147 
2022-05-11 11:06:37,922: ============================================================
2022-05-11 11:06:37,922: Epoch 21/38 Batch 5900/7662 eta: 17:08:59.198367	Training Loss 0.1086 (0.1084)	Training Prec@1 99.805 (99.819)	Training Prec@5 99.805 (99.946)	
2022-05-11 11:06:37,922: ============================================================
2022-05-11 11:07:24,646: time cost, forward:0.17210729795011764, backward:0.10488066599356728, data cost:0.1903116138682085 
2022-05-11 11:07:24,646: ============================================================
2022-05-11 11:07:24,646: Epoch 21/38 Batch 6000/7662 eta: 17:07:16.800292	Training Loss 0.1208 (0.1084)	Training Prec@1 99.805 (99.819)	Training Prec@5 99.805 (99.945)	
2022-05-11 11:07:24,646: ============================================================
2022-05-11 11:08:11,366: time cost, forward:0.1720981677255976, backward:0.10489947273215616, data cost:0.19029612454415776 
2022-05-11 11:08:11,367: ============================================================
2022-05-11 11:08:11,367: Epoch 21/38 Batch 6100/7662 eta: 17:06:25.618987	Training Loss 0.1084 (0.1084)	Training Prec@1 100.000 (99.818)	Training Prec@5 100.000 (99.945)	
2022-05-11 11:08:11,367: ============================================================
2022-05-11 11:08:58,080: time cost, forward:0.17208820224712118, backward:0.10491584900752789, data cost:0.1902830134208865 
2022-05-11 11:08:58,080: ============================================================
2022-05-11 11:08:58,081: Epoch 21/38 Batch 6200/7662 eta: 17:05:29.954019	Training Loss 0.1080 (0.1085)	Training Prec@1 99.414 (99.818)	Training Prec@5 100.000 (99.945)	
2022-05-11 11:08:58,081: ============================================================
2022-05-11 11:09:44,664: time cost, forward:0.1720839979384017, backward:0.10490857326600225, data cost:0.19026817320111933 
2022-05-11 11:09:44,665: ============================================================
2022-05-11 11:09:44,665: Epoch 21/38 Batch 6300/7662 eta: 17:01:52.899293	Training Loss 0.1132 (0.1085)	Training Prec@1 99.805 (99.818)	Training Prec@5 99.805 (99.945)	
2022-05-11 11:09:44,665: ============================================================
2022-05-11 11:10:31,232: time cost, forward:0.17207419907679725, backward:0.10490161155346577, data cost:0.19025619929051804 
2022-05-11 11:10:31,232: ============================================================
2022-05-11 11:10:31,232: Epoch 21/38 Batch 6400/7662 eta: 17:00:43.981269	Training Loss 0.1084 (0.1085)	Training Prec@1 99.609 (99.818)	Training Prec@5 100.000 (99.946)	
2022-05-11 11:10:31,232: ============================================================
2022-05-11 11:11:17,818: time cost, forward:0.17206733966721152, backward:0.10489582083632092, data cost:0.19024374092848673 
2022-05-11 11:11:17,818: ============================================================
2022-05-11 11:11:17,818: Epoch 21/38 Batch 6500/7662 eta: 17:00:21.646284	Training Loss 0.1056 (0.1085)	Training Prec@1 99.805 (99.818)	Training Prec@5 99.805 (99.946)	
2022-05-11 11:11:17,818: ============================================================
2022-05-11 11:12:04,426: time cost, forward:0.17206349494258893, backward:0.10489040184136611, data cost:0.1902320971722349 
2022-05-11 11:12:04,427: ============================================================
2022-05-11 11:12:04,427: Epoch 21/38 Batch 6600/7662 eta: 17:00:05.639422	Training Loss 0.1108 (0.1085)	Training Prec@1 99.805 (99.818)	Training Prec@5 99.805 (99.945)	
2022-05-11 11:12:04,427: ============================================================
2022-05-11 11:12:50,991: time cost, forward:0.17205300557469233, backward:0.10488485652913904, data cost:0.19022186177224254 
2022-05-11 11:12:50,991: ============================================================
2022-05-11 11:12:50,992: Epoch 21/38 Batch 6700/7662 eta: 16:58:20.519440	Training Loss 0.1060 (0.1085)	Training Prec@1 99.805 (99.818)	Training Prec@5 99.805 (99.945)	
2022-05-11 11:12:50,992: ============================================================
2022-05-11 11:13:37,518: time cost, forward:0.17204004355188082, backward:0.10487914611388872, data cost:0.19020953632870358 
2022-05-11 11:13:37,518: ============================================================
2022-05-11 11:13:37,518: Epoch 21/38 Batch 6800/7662 eta: 16:56:44.100033	Training Loss 0.1011 (0.1085)	Training Prec@1 100.000 (99.818)	Training Prec@5 100.000 (99.945)	
2022-05-11 11:13:37,518: ============================================================
2022-05-11 11:14:24,118: time cost, forward:0.1720367859266585, backward:0.10487371366047171, data cost:0.19019858017056243 
2022-05-11 11:14:24,118: ============================================================
2022-05-11 11:14:24,118: Epoch 21/38 Batch 6900/7662 eta: 16:57:33.972791	Training Loss 0.1002 (0.1085)	Training Prec@1 100.000 (99.818)	Training Prec@5 100.000 (99.945)	
2022-05-11 11:14:24,118: ============================================================
2022-05-11 11:15:10,714: time cost, forward:0.17203111910176186, backward:0.10486821393180462, data cost:0.19019025083030355 
2022-05-11 11:15:10,715: ============================================================
2022-05-11 11:15:10,715: Epoch 21/38 Batch 7000/7662 eta: 16:56:42.900859	Training Loss 0.1179 (0.1085)	Training Prec@1 99.023 (99.817)	Training Prec@5 99.805 (99.945)	
2022-05-11 11:15:10,715: ============================================================
2022-05-11 11:15:57,297: time cost, forward:0.1720258254604552, backward:0.10486256554019605, data cost:0.19018041672782507 
2022-05-11 11:15:57,297: ============================================================
2022-05-11 11:15:57,297: Epoch 21/38 Batch 7100/7662 eta: 16:55:38.087870	Training Loss 0.1138 (0.1085)	Training Prec@1 99.805 (99.817)	Training Prec@5 99.805 (99.945)	
2022-05-11 11:15:57,297: ============================================================
2022-05-11 11:16:43,869: time cost, forward:0.1720184245230771, backward:0.10485713692866591, data cost:0.1901712760708037 
2022-05-11 11:16:43,869: ============================================================
2022-05-11 11:16:43,869: Epoch 21/38 Batch 7200/7662 eta: 16:54:37.185936	Training Loss 0.1074 (0.1085)	Training Prec@1 100.000 (99.817)	Training Prec@5 100.000 (99.945)	
2022-05-11 11:16:43,869: ============================================================
2022-05-11 11:17:30,476: time cost, forward:0.17201525316710078, backward:0.10485297174449816, data cost:0.19016195290838958 
2022-05-11 11:17:30,477: ============================================================
2022-05-11 11:17:30,477: Epoch 21/38 Batch 7300/7662 eta: 16:54:37.620759	Training Loss 0.1023 (0.1085)	Training Prec@1 99.609 (99.817)	Training Prec@5 100.000 (99.945)	
2022-05-11 11:17:30,477: ============================================================
2022-05-11 11:18:17,116: time cost, forward:0.17201247584547508, backward:0.1048534225492739, data cost:0.19015229329948152 
2022-05-11 11:18:17,116: ============================================================
2022-05-11 11:18:17,116: Epoch 21/38 Batch 7400/7662 eta: 16:54:32.555127	Training Loss 0.1113 (0.1085)	Training Prec@1 100.000 (99.817)	Training Prec@5 100.000 (99.945)	
2022-05-11 11:18:17,117: ============================================================
2022-05-11 11:19:03,900: time cost, forward:0.17201080359145948, backward:0.10487017117749692, data cost:0.19014462211447122 
2022-05-11 11:19:03,900: ============================================================
2022-05-11 11:19:03,900: Epoch 21/38 Batch 7500/7662 eta: 16:56:53.783590	Training Loss 0.1109 (0.1085)	Training Prec@1 100.000 (99.817)	Training Prec@5 100.000 (99.945)	
2022-05-11 11:19:03,900: ============================================================
2022-05-11 11:19:50,478: time cost, forward:0.17200231025024124, backward:0.10486782116393602, data cost:0.19013569969647118 
2022-05-11 11:19:50,478: ============================================================
2022-05-11 11:19:50,478: Epoch 21/38 Batch 7600/7662 eta: 16:51:38.890164	Training Loss 0.1172 (0.1085)	Training Prec@1 100.000 (99.817)	Training Prec@5 100.000 (99.945)	
2022-05-11 11:19:50,478: ============================================================
2022-05-11 11:20:21,098: Epoch: 21/38 eta: 16:51:09.546102	Training Loss 0.1170 (0.1085)	Training Prec@1 100.000 (99.817)	Training Prec@5 100.000 (99.944)
2022-05-11 11:20:21,098: ============================================================
2022-05-11 11:21:11,730: time cost, forward:0.19453317227989736, backward:0.10538154419022377, data cost:0.20875929822825423 
2022-05-11 11:21:11,731: ============================================================
2022-05-11 11:21:11,731: Epoch 22/38 Batch 100/7662 eta: 18:17:05.967029	Training Loss 0.1046 (0.0977)	Training Prec@1 99.609 (99.866)	Training Prec@5 100.000 (99.951)	
2022-05-11 11:21:11,731: ============================================================
2022-05-11 11:22:00,862: time cost, forward:0.1953553674209058, backward:0.10538034103623586, data cost:0.19908475995662822 
2022-05-11 11:22:00,863: ============================================================
2022-05-11 11:22:00,863: Epoch 22/38 Batch 200/7662 eta: 17:44:58.927364	Training Loss 0.0957 (0.0984)	Training Prec@1 99.805 (99.851)	Training Prec@5 99.805 (99.949)	
2022-05-11 11:22:00,863: ============================================================
2022-05-11 11:22:49,127: time cost, forward:0.19275243944148954, backward:0.10523610928385553, data cost:0.1960016197982839 
2022-05-11 11:22:49,128: ============================================================
2022-05-11 11:22:49,128: Epoch 22/38 Batch 300/7662 eta: 17:25:22.664078	Training Loss 0.0956 (0.0984)	Training Prec@1 100.000 (99.865)	Training Prec@5 100.000 (99.954)	
2022-05-11 11:22:49,128: ============================================================
2022-05-11 11:23:36,960: time cost, forward:0.19048367885121129, backward:0.10509722573416573, data cost:0.19441815545983182 
2022-05-11 11:23:36,960: ============================================================
2022-05-11 11:23:36,960: Epoch 22/38 Batch 400/7662 eta: 17:15:12.920095	Training Loss 0.1003 (0.0983)	Training Prec@1 100.000 (99.871)	Training Prec@5 100.000 (99.956)	
2022-05-11 11:23:36,961: ============================================================
2022-05-11 11:24:24,891: time cost, forward:0.18928138574282966, backward:0.10503717940412685, data cost:0.19349024721042427 
2022-05-11 11:24:24,891: ============================================================
2022-05-11 11:24:24,891: Epoch 22/38 Batch 500/7662 eta: 17:16:32.910187	Training Loss 0.0997 (0.0983)	Training Prec@1 99.805 (99.873)	Training Prec@5 100.000 (99.955)	
2022-05-11 11:24:24,892: ============================================================
2022-05-11 11:25:12,860: time cost, forward:0.1884365432051466, backward:0.10501591510486125, data cost:0.19294238846767725 
2022-05-11 11:25:12,860: ============================================================
2022-05-11 11:25:12,861: Epoch 22/38 Batch 600/7662 eta: 17:16:34.406774	Training Loss 0.1052 (0.0984)	Training Prec@1 99.805 (99.869)	Training Prec@5 100.000 (99.955)	
2022-05-11 11:25:12,861: ============================================================
2022-05-11 11:26:00,864: time cost, forward:0.18784611078461522, backward:0.10498972375676015, data cost:0.19261629182381693 
2022-05-11 11:26:00,865: ============================================================
2022-05-11 11:26:00,865: Epoch 22/38 Batch 700/7662 eta: 17:16:31.724528	Training Loss 0.0981 (0.0985)	Training Prec@1 99.805 (99.868)	Training Prec@5 99.805 (99.953)	
2022-05-11 11:26:00,865: ============================================================
2022-05-11 11:26:48,689: time cost, forward:0.18725868638078025, backward:0.10495503435146823, data cost:0.19230644514921758 
2022-05-11 11:26:48,689: ============================================================
2022-05-11 11:26:48,689: Epoch 22/38 Batch 800/7662 eta: 17:11:51.326338	Training Loss 0.1024 (0.0985)	Training Prec@1 99.609 (99.871)	Training Prec@5 100.000 (99.954)	
2022-05-11 11:26:48,689: ============================================================
2022-05-11 11:27:36,394: time cost, forward:0.18670127309601883, backward:0.10491413189651438, data cost:0.19204710110673914 
2022-05-11 11:27:36,394: ============================================================
2022-05-11 11:27:36,394: Epoch 22/38 Batch 900/7662 eta: 17:08:28.976592	Training Loss 0.0933 (0.0987)	Training Prec@1 100.000 (99.871)	Training Prec@5 100.000 (99.955)	
2022-05-11 11:27:36,395: ============================================================
2022-05-11 11:28:24,120: time cost, forward:0.18623167473274665, backward:0.10488470467003258, data cost:0.19188064712661881 
2022-05-11 11:28:24,120: ============================================================
2022-05-11 11:28:24,120: Epoch 22/38 Batch 1000/7662 eta: 17:08:08.006259	Training Loss 0.0999 (0.0988)	Training Prec@1 99.805 (99.871)	Training Prec@5 100.000 (99.955)	
2022-05-11 11:28:24,120: ============================================================
2022-05-11 11:29:11,830: time cost, forward:0.18587498929524443, backward:0.1048672095117404, data cost:0.19169687313638675 
2022-05-11 11:29:11,831: ============================================================
2022-05-11 11:29:11,831: Epoch 22/38 Batch 1100/7662 eta: 17:07:00.638541	Training Loss 0.0912 (0.0988)	Training Prec@1 99.805 (99.868)	Training Prec@5 100.000 (99.955)	
2022-05-11 11:29:11,831: ============================================================
2022-05-11 11:29:59,554: time cost, forward:0.18554801240973517, backward:0.10484945744251191, data cost:0.1915784261940518 
2022-05-11 11:29:59,554: ============================================================
2022-05-11 11:29:59,554: Epoch 22/38 Batch 1200/7662 eta: 17:06:29.196482	Training Loss 0.1082 (0.0989)	Training Prec@1 100.000 (99.868)	Training Prec@5 100.000 (99.956)	
2022-05-11 11:29:59,554: ============================================================
2022-05-11 11:30:47,181: time cost, forward:0.18520948646433819, backward:0.10483699692864891, data cost:0.19146748686681075 
2022-05-11 11:30:47,182: ============================================================
2022-05-11 11:30:47,182: Epoch 22/38 Batch 1300/7662 eta: 17:03:38.276670	Training Loss 0.1094 (0.0990)	Training Prec@1 100.000 (99.871)	Training Prec@5 100.000 (99.957)	
2022-05-11 11:30:47,182: ============================================================
2022-05-11 11:31:34,838: time cost, forward:0.18493012090168995, backward:0.10482729273749046, data cost:0.1913875994978844 
2022-05-11 11:31:34,839: ============================================================
2022-05-11 11:31:34,839: Epoch 22/38 Batch 1400/7662 eta: 17:03:28.329432	Training Loss 0.1093 (0.0991)	Training Prec@1 100.000 (99.872)	Training Prec@5 100.000 (99.958)	
2022-05-11 11:31:34,839: ============================================================
2022-05-11 11:32:22,521: time cost, forward:0.18469542865358726, backward:0.10481796700450244, data cost:0.19131161595599663 
2022-05-11 11:32:22,521: ============================================================
2022-05-11 11:32:22,521: Epoch 22/38 Batch 1500/7662 eta: 17:03:13.589835	Training Loss 0.1014 (0.0991)	Training Prec@1 99.805 (99.872)	Training Prec@5 100.000 (99.959)	
2022-05-11 11:32:22,521: ============================================================
2022-05-11 11:33:10,198: time cost, forward:0.18448282734463556, backward:0.10480717691203219, data cost:0.19125548327543201 
2022-05-11 11:33:10,198: ============================================================
2022-05-11 11:33:10,198: Epoch 22/38 Batch 1600/7662 eta: 17:02:18.981827	Training Loss 0.1039 (0.0992)	Training Prec@1 100.000 (99.873)	Training Prec@5 100.000 (99.960)	
2022-05-11 11:33:10,199: ============================================================
2022-05-11 11:33:58,049: time cost, forward:0.18435495344591954, backward:0.10480137822766947, data cost:0.19125821774254273 
2022-05-11 11:33:58,050: ============================================================
2022-05-11 11:33:58,050: Epoch 22/38 Batch 1700/7662 eta: 17:05:15.624292	Training Loss 0.0987 (0.0993)	Training Prec@1 100.000 (99.873)	Training Prec@5 100.000 (99.959)	
2022-05-11 11:33:58,050: ============================================================
2022-05-11 11:34:45,882: time cost, forward:0.18423401202805642, backward:0.10480048657788907, data cost:0.19124264634934446 
2022-05-11 11:34:45,882: ============================================================
2022-05-11 11:34:45,882: Epoch 22/38 Batch 1800/7662 eta: 17:04:03.266333	Training Loss 0.0963 (0.0993)	Training Prec@1 100.000 (99.873)	Training Prec@5 100.000 (99.960)	
2022-05-11 11:34:45,883: ============================================================
2022-05-11 11:35:33,662: time cost, forward:0.18412659744515802, backward:0.10479137607472014, data cost:0.1912094754504806 
2022-05-11 11:35:33,663: ============================================================
2022-05-11 11:35:33,663: Epoch 22/38 Batch 1900/7662 eta: 17:02:08.526348	Training Loss 0.0944 (0.0993)	Training Prec@1 99.805 (99.873)	Training Prec@5 99.805 (99.960)	
2022-05-11 11:35:33,663: ============================================================
2022-05-11 11:36:21,462: time cost, forward:0.18402694832867178, backward:0.10478306043261346, data cost:0.1911986821171282 
2022-05-11 11:36:21,462: ============================================================
2022-05-11 11:36:21,463: Epoch 22/38 Batch 2000/7662 eta: 17:01:45.545321	Training Loss 0.0950 (0.0994)	Training Prec@1 100.000 (99.874)	Training Prec@5 100.000 (99.960)	
2022-05-11 11:36:21,463: ============================================================
2022-05-11 11:37:09,098: time cost, forward:0.18388852521088533, backward:0.10477798742700498, data cost:0.19115588311753767 
2022-05-11 11:37:09,098: ============================================================
2022-05-11 11:37:09,098: Epoch 22/38 Batch 2100/7662 eta: 16:57:27.126166	Training Loss 0.0978 (0.0994)	Training Prec@1 100.000 (99.874)	Training Prec@5 100.000 (99.961)	
2022-05-11 11:37:09,098: ============================================================
2022-05-11 11:37:56,793: time cost, forward:0.18376960218792993, backward:0.10477102632249362, data cost:0.191134398825985 
2022-05-11 11:37:56,793: ============================================================
2022-05-11 11:37:56,794: Epoch 22/38 Batch 2200/7662 eta: 16:57:56.545972	Training Loss 0.0988 (0.0995)	Training Prec@1 99.609 (99.874)	Training Prec@5 100.000 (99.960)	
2022-05-11 11:37:56,794: ============================================================
2022-05-11 11:38:44,459: time cost, forward:0.18364924843179603, backward:0.10476437907158784, data cost:0.1911190279985107 
2022-05-11 11:38:44,459: ============================================================
2022-05-11 11:38:44,459: Epoch 22/38 Batch 2300/7662 eta: 16:56:30.274504	Training Loss 0.0949 (0.0996)	Training Prec@1 100.000 (99.873)	Training Prec@5 100.000 (99.960)	
2022-05-11 11:38:44,459: ============================================================
2022-05-11 11:39:32,231: time cost, forward:0.1835717617247988, backward:0.10475746340034106, data cost:0.19111245142613514 
2022-05-11 11:39:32,232: ============================================================
2022-05-11 11:39:32,232: Epoch 22/38 Batch 2400/7662 eta: 16:57:59.985340	Training Loss 0.1004 (0.0996)	Training Prec@1 100.000 (99.872)	Training Prec@5 100.000 (99.960)	
2022-05-11 11:39:32,232: ============================================================
2022-05-11 11:40:20,053: time cost, forward:0.1835051503549723, backward:0.10475307724484446, data cost:0.19110943642364783 
2022-05-11 11:40:20,054: ============================================================
2022-05-11 11:40:20,054: Epoch 22/38 Batch 2500/7662 eta: 16:58:14.902624	Training Loss 0.1022 (0.0997)	Training Prec@1 100.000 (99.871)	Training Prec@5 100.000 (99.960)	
2022-05-11 11:40:20,054: ============================================================
2022-05-11 11:41:07,862: time cost, forward:0.18345645970223087, backward:0.10474814741186748, data cost:0.19109888304284373 
2022-05-11 11:41:07,862: ============================================================
2022-05-11 11:41:07,862: Epoch 22/38 Batch 2600/7662 eta: 16:57:09.927654	Training Loss 0.1017 (0.0998)	Training Prec@1 99.609 (99.871)	Training Prec@5 100.000 (99.960)	
2022-05-11 11:41:07,862: ============================================================
2022-05-11 11:41:55,706: time cost, forward:0.18342942712747773, backward:0.10474382422066654, data cost:0.1910840845761718 
2022-05-11 11:41:55,706: ============================================================
2022-05-11 11:41:55,706: Epoch 22/38 Batch 2700/7662 eta: 16:57:07.520465	Training Loss 0.1011 (0.0998)	Training Prec@1 99.805 (99.871)	Training Prec@5 100.000 (99.960)	
2022-05-11 11:41:55,706: ============================================================
2022-05-11 11:42:43,620: time cost, forward:0.18340319256647947, backward:0.10474293936402, data cost:0.19109764368289622 
2022-05-11 11:42:43,620: ============================================================
2022-05-11 11:42:43,620: Epoch 22/38 Batch 2800/7662 eta: 16:57:48.490033	Training Loss 0.0918 (0.0999)	Training Prec@1 100.000 (99.872)	Training Prec@5 100.000 (99.960)	
2022-05-11 11:42:43,620: ============================================================
2022-05-11 11:43:31,532: time cost, forward:0.18338662363324096, backward:0.10474017983101368, data cost:0.19109552948587555 
2022-05-11 11:43:31,532: ============================================================
2022-05-11 11:43:31,533: Epoch 22/38 Batch 2900/7662 eta: 16:56:58.902615	Training Loss 0.0994 (0.1000)	Training Prec@1 99.609 (99.871)	Training Prec@5 100.000 (99.960)	
2022-05-11 11:43:31,533: ============================================================
2022-05-11 11:44:19,425: time cost, forward:0.1833757672877501, backward:0.10473933725525594, data cost:0.1910880183569389 
2022-05-11 11:44:19,425: ============================================================
2022-05-11 11:44:19,426: Epoch 22/38 Batch 3000/7662 eta: 16:55:46.278573	Training Loss 0.1052 (0.1000)	Training Prec@1 99.805 (99.871)	Training Prec@5 100.000 (99.960)	
2022-05-11 11:44:19,426: ============================================================
2022-05-11 11:45:07,362: time cost, forward:0.1833635974445817, backward:0.10474077121947573, data cost:0.19109561144055456 
2022-05-11 11:45:07,362: ============================================================
2022-05-11 11:45:07,362: Epoch 22/38 Batch 3100/7662 eta: 16:55:54.072301	Training Loss 0.0968 (0.1001)	Training Prec@1 99.609 (99.870)	Training Prec@5 99.805 (99.960)	
2022-05-11 11:45:07,363: ============================================================
2022-05-11 11:45:55,279: time cost, forward:0.18334937147812458, backward:0.10474013290989581, data cost:0.19110163341055963 
2022-05-11 11:45:55,279: ============================================================
2022-05-11 11:45:55,279: Epoch 22/38 Batch 3200/7662 eta: 16:54:40.941391	Training Loss 0.1087 (0.1002)	Training Prec@1 100.000 (99.870)	Training Prec@5 100.000 (99.960)	
2022-05-11 11:45:55,280: ============================================================
2022-05-11 11:46:43,102: time cost, forward:0.183305508586702, backward:0.10474149860660753, data cost:0.1911029531652908 
2022-05-11 11:46:43,102: ============================================================
2022-05-11 11:46:43,102: Epoch 22/38 Batch 3300/7662 eta: 16:51:53.510403	Training Loss 0.1019 (0.1002)	Training Prec@1 99.609 (99.869)	Training Prec@5 99.805 (99.959)	
2022-05-11 11:46:43,102: ============================================================
2022-05-11 11:47:30,983: time cost, forward:0.18329720421376106, backward:0.10474068840029101, data cost:0.19109048875649912 
2022-05-11 11:47:30,983: ============================================================
2022-05-11 11:47:30,984: Epoch 22/38 Batch 3400/7662 eta: 16:52:19.660364	Training Loss 0.1038 (0.1003)	Training Prec@1 100.000 (99.869)	Training Prec@5 100.000 (99.959)	
2022-05-11 11:47:30,984: ============================================================
2022-05-11 11:48:18,819: time cost, forward:0.18327762556607535, backward:0.10473929776161457, data cost:0.19107559450219855 
2022-05-11 11:48:18,819: ============================================================
2022-05-11 11:48:18,819: Epoch 22/38 Batch 3500/7662 eta: 16:50:34.071770	Training Loss 0.0948 (0.1003)	Training Prec@1 99.805 (99.868)	Training Prec@5 99.805 (99.959)	
2022-05-11 11:48:18,819: ============================================================
2022-05-11 11:49:06,710: time cost, forward:0.18326819449803936, backward:0.10473991473802893, data cost:0.19107210500335056 
2022-05-11 11:49:06,711: ============================================================
2022-05-11 11:49:06,711: Epoch 22/38 Batch 3600/7662 eta: 16:50:57.407814	Training Loss 0.1037 (0.1004)	Training Prec@1 99.805 (99.869)	Training Prec@5 99.805 (99.958)	
2022-05-11 11:49:06,711: ============================================================
2022-05-11 11:49:54,637: time cost, forward:0.18325976153649842, backward:0.10474187311335943, data cost:0.1910768942305706 
2022-05-11 11:49:54,638: ============================================================
2022-05-11 11:49:54,638: Epoch 22/38 Batch 3700/7662 eta: 16:50:53.923182	Training Loss 0.1019 (0.1004)	Training Prec@1 99.609 (99.869)	Training Prec@5 100.000 (99.958)	
2022-05-11 11:49:54,638: ============================================================
2022-05-11 11:50:42,584: time cost, forward:0.18325020037503204, backward:0.10474287343357826, data cost:0.1910854782923864 
2022-05-11 11:50:42,584: ============================================================
2022-05-11 11:50:42,585: Epoch 22/38 Batch 3800/7662 eta: 16:50:30.916998	Training Loss 0.1025 (0.1005)	Training Prec@1 99.805 (99.869)	Training Prec@5 100.000 (99.959)	
2022-05-11 11:50:42,585: ============================================================
2022-05-11 11:51:30,459: time cost, forward:0.18323331253441152, backward:0.10474626808234991, data cost:0.19108383561990663 
2022-05-11 11:51:30,460: ============================================================
2022-05-11 11:51:30,460: Epoch 22/38 Batch 3900/7662 eta: 16:48:13.215711	Training Loss 0.1000 (0.1006)	Training Prec@1 99.805 (99.869)	Training Prec@5 100.000 (99.959)	
2022-05-11 11:51:30,460: ============================================================
2022-05-11 11:52:18,338: time cost, forward:0.1832129614267924, backward:0.10474626580963554, data cost:0.19108786395741392 
2022-05-11 11:52:18,339: ============================================================
2022-05-11 11:52:18,339: Epoch 22/38 Batch 4000/7662 eta: 16:47:29.867381	Training Loss 0.1054 (0.1006)	Training Prec@1 99.609 (99.869)	Training Prec@5 100.000 (99.959)	
2022-05-11 11:52:18,340: ============================================================
2022-05-11 11:53:06,258: time cost, forward:0.18320518122791923, backward:0.10474535127068822, data cost:0.1910934686137281 
2022-05-11 11:53:06,258: ============================================================
2022-05-11 11:53:06,258: Epoch 22/38 Batch 4100/7662 eta: 16:47:32.129518	Training Loss 0.0957 (0.1006)	Training Prec@1 100.000 (99.869)	Training Prec@5 100.000 (99.959)	
2022-05-11 11:53:06,258: ============================================================
2022-05-11 11:53:54,191: time cost, forward:0.18319160304032045, backward:0.10474868569098135, data cost:0.1910985664800111 
2022-05-11 11:53:54,191: ============================================================
2022-05-11 11:53:54,192: Epoch 22/38 Batch 4200/7662 eta: 16:47:02.206532	Training Loss 0.1019 (0.1007)	Training Prec@1 99.805 (99.869)	Training Prec@5 99.805 (99.959)	
2022-05-11 11:53:54,192: ============================================================
2022-05-11 11:54:42,088: time cost, forward:0.1831876370873, backward:0.10475083283697015, data cost:0.19108812158455485 
2022-05-11 11:54:42,089: ============================================================
2022-05-11 11:54:42,089: Epoch 22/38 Batch 4300/7662 eta: 16:45:29.142119	Training Loss 0.1036 (0.1007)	Training Prec@1 99.414 (99.869)	Training Prec@5 99.805 (99.959)	
2022-05-11 11:54:42,089: ============================================================
2022-05-11 11:55:30,090: time cost, forward:0.18320807486020535, backward:0.1047540314768249, data cost:0.1910806833329215 
2022-05-11 11:55:30,090: ============================================================
2022-05-11 11:55:30,091: Epoch 22/38 Batch 4400/7662 eta: 16:46:52.488129	Training Loss 0.1048 (0.1007)	Training Prec@1 100.000 (99.869)	Training Prec@5 100.000 (99.958)	
2022-05-11 11:55:30,091: ============================================================
2022-05-11 11:56:18,102: time cost, forward:0.1832277737185276, backward:0.10475704648224983, data cost:0.19106744628239802 
2022-05-11 11:56:18,102: ============================================================
2022-05-11 11:56:18,103: Epoch 22/38 Batch 4500/7662 eta: 16:46:17.500000	Training Loss 0.1076 (0.1008)	Training Prec@1 99.609 (99.868)	Training Prec@5 99.805 (99.959)	
2022-05-11 11:56:18,103: ============================================================
2022-05-11 11:57:05,971: time cost, forward:0.18322187606395132, backward:0.10475926021825596, data cost:0.19105707834429989 
2022-05-11 11:57:05,971: ============================================================
2022-05-11 11:57:05,971: Epoch 22/38 Batch 4600/7662 eta: 16:42:29.180445	Training Loss 0.0974 (0.1008)	Training Prec@1 100.000 (99.868)	Training Prec@5 100.000 (99.959)	
2022-05-11 11:57:05,971: ============================================================
2022-05-11 11:57:53,870: time cost, forward:0.1832260825223531, backward:0.10476046740996074, data cost:0.191044761211625 
2022-05-11 11:57:53,870: ============================================================
2022-05-11 11:57:53,870: Epoch 22/38 Batch 4700/7662 eta: 16:42:19.549848	Training Loss 0.1025 (0.1009)	Training Prec@1 99.805 (99.868)	Training Prec@5 99.805 (99.958)	
2022-05-11 11:57:53,870: ============================================================
2022-05-11 11:58:41,793: time cost, forward:0.18322709491536576, backward:0.10476197195838059, data cost:0.19103812833556683 
2022-05-11 11:58:41,794: ============================================================
2022-05-11 11:58:41,794: Epoch 22/38 Batch 4800/7662 eta: 16:42:02.628600	Training Loss 0.1020 (0.1009)	Training Prec@1 99.805 (99.867)	Training Prec@5 100.000 (99.958)	
2022-05-11 11:58:41,794: ============================================================
2022-05-11 11:59:29,743: time cost, forward:0.1832277629783772, backward:0.1047629801004024, data cost:0.19103839057249594 
2022-05-11 11:59:29,744: ============================================================
2022-05-11 11:59:29,744: Epoch 22/38 Batch 4900/7662 eta: 16:41:48.278158	Training Loss 0.0977 (0.1010)	Training Prec@1 100.000 (99.867)	Training Prec@5 100.000 (99.958)	
2022-05-11 11:59:29,744: ============================================================
2022-05-11 12:00:17,684: time cost, forward:0.1832210515398673, backward:0.1047643033188089, data cost:0.1910391631281884 
2022-05-11 12:00:17,684: ============================================================
2022-05-11 12:00:17,684: Epoch 22/38 Batch 5000/7662 eta: 16:40:47.108507	Training Loss 0.0995 (0.1010)	Training Prec@1 99.609 (99.866)	Training Prec@5 100.000 (99.957)	
2022-05-11 12:00:17,684: ============================================================
2022-05-11 12:01:05,644: time cost, forward:0.1832220698833746, backward:0.10476654832282238, data cost:0.19104353725547812 
2022-05-11 12:01:05,645: ============================================================
2022-05-11 12:01:05,645: Epoch 22/38 Batch 5100/7662 eta: 16:40:25.525054	Training Loss 0.1034 (0.1010)	Training Prec@1 99.805 (99.866)	Training Prec@5 100.000 (99.958)	
2022-05-11 12:01:05,645: ============================================================
2022-05-11 12:01:53,555: time cost, forward:0.1832113757594821, backward:0.10476772884699811, data cost:0.1910474637903418 
2022-05-11 12:01:53,555: ============================================================
2022-05-11 12:01:53,556: Epoch 22/38 Batch 5200/7662 eta: 16:38:34.507740	Training Loss 0.1040 (0.1011)	Training Prec@1 100.000 (99.866)	Training Prec@5 100.000 (99.957)	
2022-05-11 12:01:53,556: ============================================================
2022-05-11 12:02:41,491: time cost, forward:0.18320823233180236, backward:0.10476979243798085, data cost:0.19104338448145272 
2022-05-11 12:02:41,491: ============================================================
2022-05-11 12:02:41,491: Epoch 22/38 Batch 5300/7662 eta: 16:38:18.251080	Training Loss 0.1035 (0.1011)	Training Prec@1 99.414 (99.865)	Training Prec@5 99.805 (99.957)	
2022-05-11 12:02:41,492: ============================================================
2022-05-11 12:03:29,334: time cost, forward:0.18320496591468016, backward:0.10477021672721704, data cost:0.191024197982757 
2022-05-11 12:03:29,335: ============================================================
2022-05-11 12:03:29,335: Epoch 22/38 Batch 5400/7662 eta: 16:35:35.063120	Training Loss 0.1043 (0.1012)	Training Prec@1 100.000 (99.865)	Training Prec@5 100.000 (99.957)	
2022-05-11 12:03:29,335: ============================================================
2022-05-11 12:04:17,180: time cost, forward:0.18320865491494892, backward:0.10477191605423121, data cost:0.19100224271560284 
2022-05-11 12:04:17,181: ============================================================
2022-05-11 12:04:17,181: Epoch 22/38 Batch 5500/7662 eta: 16:34:50.239173	Training Loss 0.1015 (0.1012)	Training Prec@1 99.609 (99.865)	Training Prec@5 99.805 (99.957)	
2022-05-11 12:04:17,181: ============================================================
2022-05-11 12:05:04,959: time cost, forward:0.18320017104532957, backward:0.10477334070384535, data cost:0.19098294068711383 
2022-05-11 12:05:04,960: ============================================================
2022-05-11 12:05:04,960: Epoch 22/38 Batch 5600/7662 eta: 16:32:38.762121	Training Loss 0.1005 (0.1013)	Training Prec@1 99.805 (99.864)	Training Prec@5 100.000 (99.957)	
2022-05-11 12:05:04,960: ============================================================
2022-05-11 12:05:52,680: time cost, forward:0.18318519296928923, backward:0.10477539266822923, data cost:0.19096045712459128 
2022-05-11 12:05:52,680: ============================================================
2022-05-11 12:05:52,680: Epoch 22/38 Batch 5700/7662 eta: 16:30:37.872915	Training Loss 0.1033 (0.1013)	Training Prec@1 100.000 (99.864)	Training Prec@5 100.000 (99.957)	
2022-05-11 12:05:52,680: ============================================================
2022-05-11 12:06:40,487: time cost, forward:0.1831795400454065, backward:0.10477666761119071, data cost:0.19094241292420328 
2022-05-11 12:06:40,487: ============================================================
2022-05-11 12:06:40,487: Epoch 22/38 Batch 5800/7662 eta: 16:31:38.394326	Training Loss 0.1045 (0.1014)	Training Prec@1 100.000 (99.863)	Training Prec@5 100.000 (99.957)	
2022-05-11 12:06:40,487: ============================================================
2022-05-11 12:07:28,188: time cost, forward:0.18315721689836315, backward:0.10477859150617683, data cost:0.19092614643855466 
2022-05-11 12:07:28,189: ============================================================
2022-05-11 12:07:28,189: Epoch 22/38 Batch 5900/7662 eta: 16:28:39.629264	Training Loss 0.0978 (0.1014)	Training Prec@1 100.000 (99.863)	Training Prec@5 100.000 (99.957)	
2022-05-11 12:07:28,189: ============================================================
2022-05-11 12:08:16,090: time cost, forward:0.18316208984399163, backward:0.10478091999021524, data cost:0.19091475306003963 
2022-05-11 12:08:16,090: ============================================================
2022-05-11 12:08:16,090: Epoch 22/38 Batch 6000/7662 eta: 16:31:59.967630	Training Loss 0.1012 (0.1014)	Training Prec@1 100.000 (99.862)	Training Prec@5 100.000 (99.956)	
2022-05-11 12:08:16,091: ============================================================
2022-05-11 12:09:03,900: time cost, forward:0.1831538099835282, backward:0.10478275747529052, data cost:0.19090065035121834 
2022-05-11 12:09:03,900: ============================================================
2022-05-11 12:09:03,901: Epoch 22/38 Batch 6100/7662 eta: 16:29:18.623536	Training Loss 0.1027 (0.1015)	Training Prec@1 99.805 (99.862)	Training Prec@5 100.000 (99.956)	
2022-05-11 12:09:03,901: ============================================================
2022-05-11 12:09:51,673: time cost, forward:0.18314238532279112, backward:0.10478371126956758, data cost:0.19088869503302466 
2022-05-11 12:09:51,674: ============================================================
2022-05-11 12:09:51,674: Epoch 22/38 Batch 6200/7662 eta: 16:27:45.066965	Training Loss 0.1000 (0.1015)	Training Prec@1 99.805 (99.862)	Training Prec@5 100.000 (99.956)	
2022-05-11 12:09:51,674: ============================================================
2022-05-11 12:10:39,422: time cost, forward:0.18313344805406037, backward:0.10478611820594605, data cost:0.1908699077809684 
2022-05-11 12:10:39,422: ============================================================
2022-05-11 12:10:39,422: Epoch 22/38 Batch 6300/7662 eta: 16:26:26.352458	Training Loss 0.1002 (0.1016)	Training Prec@1 99.609 (99.862)	Training Prec@5 99.805 (99.957)	
2022-05-11 12:10:39,422: ============================================================
2022-05-11 12:11:27,249: time cost, forward:0.18313062625073664, backward:0.1047867809464958, data cost:0.19085776431427504 
2022-05-11 12:11:27,249: ============================================================
2022-05-11 12:11:27,249: Epoch 22/38 Batch 6400/7662 eta: 16:27:16.115079	Training Loss 0.1044 (0.1016)	Training Prec@1 100.000 (99.862)	Training Prec@5 100.000 (99.957)	
2022-05-11 12:11:27,249: ============================================================
2022-05-11 12:12:15,035: time cost, forward:0.18312367873478713, backward:0.10478837127996639, data cost:0.19084514223771712 
2022-05-11 12:12:15,035: ============================================================
2022-05-11 12:12:15,036: Epoch 22/38 Batch 6500/7662 eta: 16:25:38.331754	Training Loss 0.1087 (0.1016)	Training Prec@1 99.805 (99.861)	Training Prec@5 100.000 (99.956)	
2022-05-11 12:12:15,036: ============================================================
2022-05-11 12:13:02,831: time cost, forward:0.18312015546453886, backward:0.10479230890853565, data cost:0.19082852113714796 
2022-05-11 12:13:02,831: ============================================================
2022-05-11 12:13:02,832: Epoch 22/38 Batch 6600/7662 eta: 16:25:02.085136	Training Loss 0.1038 (0.1017)	Training Prec@1 100.000 (99.861)	Training Prec@5 100.000 (99.956)	
2022-05-11 12:13:02,832: ============================================================
2022-05-11 12:13:50,575: time cost, forward:0.18311020957478696, backward:0.10479446282438741, data cost:0.19081265553731958 
2022-05-11 12:13:50,576: ============================================================
2022-05-11 12:13:50,576: Epoch 22/38 Batch 6700/7662 eta: 16:23:10.181630	Training Loss 0.1127 (0.1017)	Training Prec@1 99.609 (99.861)	Training Prec@5 100.000 (99.956)	
2022-05-11 12:13:50,576: ============================================================
2022-05-11 12:14:38,277: time cost, forward:0.18309365509011882, backward:0.10479630970186934, data cost:0.1907981692175424 
2022-05-11 12:14:38,277: ============================================================
2022-05-11 12:14:38,277: Epoch 22/38 Batch 6800/7662 eta: 16:21:29.599180	Training Loss 0.1008 (0.1017)	Training Prec@1 100.000 (99.861)	Training Prec@5 100.000 (99.956)	
2022-05-11 12:14:38,277: ============================================================
2022-05-11 12:15:25,846: time cost, forward:0.18306203616980385, backward:0.104795729151531, data cost:0.19078304360164802 
2022-05-11 12:15:25,846: ============================================================
2022-05-11 12:15:25,846: Epoch 22/38 Batch 6900/7662 eta: 16:17:59.037588	Training Loss 0.0988 (0.1018)	Training Prec@1 99.609 (99.860)	Training Prec@5 100.000 (99.956)	
2022-05-11 12:15:25,846: ============================================================
2022-05-11 12:16:13,445: time cost, forward:0.18303378075595447, backward:0.10479548291183059, data cost:0.19076983239552278 
2022-05-11 12:16:13,446: ============================================================
2022-05-11 12:16:13,446: Epoch 22/38 Batch 7000/7662 eta: 16:17:48.803911	Training Loss 0.1127 (0.1018)	Training Prec@1 99.805 (99.860)	Training Prec@5 99.805 (99.956)	
2022-05-11 12:16:13,446: ============================================================
2022-05-11 12:17:01,127: time cost, forward:0.18301841869776073, backward:0.10479538822563655, data cost:0.19075626207919402 
2022-05-11 12:17:01,127: ============================================================
2022-05-11 12:17:01,128: Epoch 22/38 Batch 7100/7662 eta: 16:18:42.404378	Training Loss 0.1018 (0.1019)	Training Prec@1 99.609 (99.860)	Training Prec@5 100.000 (99.956)	
2022-05-11 12:17:01,128: ============================================================
2022-05-11 12:17:48,795: time cost, forward:0.18299983534353909, backward:0.1047964156675809, data cost:0.19074353778969994 
2022-05-11 12:17:48,795: ============================================================
2022-05-11 12:17:48,796: Epoch 22/38 Batch 7200/7662 eta: 16:17:38.094435	Training Loss 0.1085 (0.1019)	Training Prec@1 99.805 (99.859)	Training Prec@5 100.000 (99.956)	
2022-05-11 12:17:48,796: ============================================================
2022-05-11 12:18:36,542: time cost, forward:0.18298563083110891, backward:0.1047994298042541, data cost:0.19073647220651815 
2022-05-11 12:18:36,542: ============================================================
2022-05-11 12:18:36,543: Epoch 22/38 Batch 7300/7662 eta: 16:18:27.175492	Training Loss 0.0971 (0.1019)	Training Prec@1 99.805 (99.859)	Training Prec@5 99.805 (99.956)	
2022-05-11 12:18:36,543: ============================================================
2022-05-11 12:19:24,330: time cost, forward:0.1829753831071231, backward:0.10480277285992834, data cost:0.19072933196377023 
2022-05-11 12:19:24,331: ============================================================
2022-05-11 12:19:24,331: Epoch 22/38 Batch 7400/7662 eta: 16:18:30.104238	Training Loss 0.1025 (0.1020)	Training Prec@1 99.805 (99.859)	Training Prec@5 100.000 (99.955)	
2022-05-11 12:19:24,331: ============================================================
2022-05-11 12:20:11,992: time cost, forward:0.1829587578026354, backward:0.10480431926013598, data cost:0.19071576455097577 
2022-05-11 12:20:11,993: ============================================================
2022-05-11 12:20:11,993: Epoch 22/38 Batch 7500/7662 eta: 16:15:08.132488	Training Loss 0.0996 (0.1020)	Training Prec@1 99.805 (99.859)	Training Prec@5 100.000 (99.955)	
2022-05-11 12:20:11,994: ============================================================
2022-05-11 12:20:59,684: time cost, forward:0.1829443223571476, backward:0.10480713756449334, data cost:0.19070342092517803 
2022-05-11 12:20:59,684: ============================================================
2022-05-11 12:20:59,684: Epoch 22/38 Batch 7600/7662 eta: 16:14:55.382872	Training Loss 0.1073 (0.1020)	Training Prec@1 100.000 (99.859)	Training Prec@5 100.000 (99.955)	
2022-05-11 12:20:59,684: ============================================================
2022-05-11 12:21:31,135: Epoch: 22/38 eta: 16:14:25.337549	Training Loss 0.1034 (0.1020)	Training Prec@1 100.000 (99.858)	Training Prec@5 100.000 (99.955)
2022-05-11 12:21:31,135: ============================================================
2022-05-11 12:22:20,547: time cost, forward:0.1819054815504286, backward:0.10450079224326393, data cost:0.20911171701219347 
2022-05-11 12:22:20,548: ============================================================
2022-05-11 12:22:20,548: Epoch 23/38 Batch 100/7662 eta: 16:45:54.844214	Training Loss 0.0887 (0.0928)	Training Prec@1 99.414 (99.917)	Training Prec@5 99.609 (99.978)	
2022-05-11 12:22:20,548: ============================================================
2022-05-11 12:23:08,237: time cost, forward:0.1821422876425125, backward:0.10457061642977461, data cost:0.19932143652259404 
2022-05-11 12:23:08,237: ============================================================
2022-05-11 12:23:08,238: Epoch 23/38 Batch 200/7662 eta: 16:12:48.910411	Training Loss 0.0910 (0.0932)	Training Prec@1 100.000 (99.905)	Training Prec@5 100.000 (99.974)	
2022-05-11 12:23:08,238: ============================================================
2022-05-11 12:23:55,855: time cost, forward:0.18199002862375316, backward:0.10457748473687316, data cost:0.1960844953721981 
2022-05-11 12:23:55,855: ============================================================
2022-05-11 12:23:55,855: Epoch 23/38 Batch 300/7662 eta: 16:10:32.855070	Training Loss 0.1046 (0.0931)	Training Prec@1 99.805 (99.903)	Training Prec@5 99.805 (99.975)	
2022-05-11 12:23:55,855: ============================================================
2022-05-11 12:24:43,431: time cost, forward:0.18177542650609985, backward:0.1045876045274854, data cost:0.19450042002780693 
2022-05-11 12:24:43,431: ============================================================
2022-05-11 12:24:43,431: Epoch 23/38 Batch 400/7662 eta: 16:08:54.712370	Training Loss 0.0956 (0.0932)	Training Prec@1 100.000 (99.902)	Training Prec@5 100.000 (99.976)	
2022-05-11 12:24:43,431: ============================================================
2022-05-11 12:25:31,009: time cost, forward:0.18166360730876427, backward:0.10459106670830676, data cost:0.1935403456907712 
2022-05-11 12:25:31,009: ============================================================
2022-05-11 12:25:31,009: Epoch 23/38 Batch 500/7662 eta: 16:08:09.375021	Training Loss 0.0951 (0.0934)	Training Prec@1 99.609 (99.905)	Training Prec@5 100.000 (99.976)	
2022-05-11 12:25:31,009: ============================================================
2022-05-11 12:26:18,615: time cost, forward:0.18162261583968276, backward:0.10459506571392384, data cost:0.1929116770500731 
2022-05-11 12:26:18,616: ============================================================
2022-05-11 12:26:18,616: Epoch 23/38 Batch 600/7662 eta: 16:07:56.691091	Training Loss 0.0934 (0.0936)	Training Prec@1 99.805 (99.907)	Training Prec@5 100.000 (99.975)	
2022-05-11 12:26:18,616: ============================================================
2022-05-11 12:27:06,229: time cost, forward:0.18160687836795747, backward:0.10460391508492618, data cost:0.19245613456966199 
2022-05-11 12:27:06,230: ============================================================
2022-05-11 12:27:06,230: Epoch 23/38 Batch 700/7662 eta: 16:07:18.104930	Training Loss 0.0881 (0.0938)	Training Prec@1 100.000 (99.904)	Training Prec@5 100.000 (99.973)	
2022-05-11 12:27:06,230: ============================================================
2022-05-11 12:27:53,935: time cost, forward:0.1816895020023007, backward:0.10464019321828372, data cost:0.19210340263548123 
2022-05-11 12:27:53,935: ============================================================
2022-05-11 12:27:53,935: Epoch 23/38 Batch 800/7662 eta: 16:08:21.707721	Training Loss 0.0930 (0.0940)	Training Prec@1 100.000 (99.905)	Training Prec@5 100.000 (99.973)	
2022-05-11 12:27:53,935: ============================================================
2022-05-11 12:28:41,626: time cost, forward:0.18174596596612813, backward:0.1046558458096989, data cost:0.19183525333680354 
2022-05-11 12:28:41,627: ============================================================
2022-05-11 12:28:41,627: Epoch 23/38 Batch 900/7662 eta: 16:07:17.696051	Training Loss 0.1023 (0.0942)	Training Prec@1 99.414 (99.906)	Training Prec@5 99.805 (99.973)	
2022-05-11 12:28:41,627: ============================================================
2022-05-11 12:29:29,307: time cost, forward:0.18178202845790126, backward:0.10466258996003144, data cost:0.19162590582449515 
2022-05-11 12:29:29,307: ============================================================
2022-05-11 12:29:29,307: Epoch 23/38 Batch 1000/7662 eta: 16:06:16.203164	Training Loss 0.0968 (0.0942)	Training Prec@1 99.805 (99.906)	Training Prec@5 100.000 (99.973)	
2022-05-11 12:29:29,308: ============================================================
2022-05-11 12:30:17,025: time cost, forward:0.1818163303812598, backward:0.10467551099483917, data cost:0.1914751217298013 
2022-05-11 12:30:17,026: ============================================================
2022-05-11 12:30:17,026: Epoch 23/38 Batch 1100/7662 eta: 16:06:14.416070	Training Loss 0.0957 (0.0942)	Training Prec@1 100.000 (99.906)	Training Prec@5 100.000 (99.972)	
2022-05-11 12:30:17,026: ============================================================
2022-05-11 12:31:04,756: time cost, forward:0.18186745313528282, backward:0.1046827764089551, data cost:0.19133959599988873 
2022-05-11 12:31:04,756: ============================================================
2022-05-11 12:31:04,756: Epoch 23/38 Batch 1200/7662 eta: 16:05:41.529837	Training Loss 0.0977 (0.0943)	Training Prec@1 100.000 (99.907)	Training Prec@5 100.000 (99.973)	
2022-05-11 12:31:04,756: ============================================================
2022-05-11 12:31:52,462: time cost, forward:0.18188890353636708, backward:0.10469367120521081, data cost:0.19122432377633908 
2022-05-11 12:31:52,462: ============================================================
2022-05-11 12:31:52,462: Epoch 23/38 Batch 1300/7662 eta: 16:04:23.694559	Training Loss 0.0988 (0.0944)	Training Prec@1 99.805 (99.905)	Training Prec@5 100.000 (99.972)	
2022-05-11 12:31:52,462: ============================================================
2022-05-11 12:32:40,184: time cost, forward:0.18191819705649562, backward:0.10470292208619081, data cost:0.191126212296612 
2022-05-11 12:32:40,184: ============================================================
2022-05-11 12:32:40,184: Epoch 23/38 Batch 1400/7662 eta: 16:03:55.791799	Training Loss 0.0938 (0.0946)	Training Prec@1 99.805 (99.904)	Training Prec@5 100.000 (99.972)	
2022-05-11 12:32:40,184: ============================================================
2022-05-11 12:33:27,932: time cost, forward:0.18195360131546845, backward:0.10471292175079203, data cost:0.191047667343669 
2022-05-11 12:33:27,933: ============================================================
2022-05-11 12:33:27,933: Epoch 23/38 Batch 1500/7662 eta: 16:03:40.194017	Training Loss 0.0949 (0.0946)	Training Prec@1 99.805 (99.903)	Training Prec@5 100.000 (99.971)	
2022-05-11 12:33:27,933: ============================================================
2022-05-11 12:34:15,789: time cost, forward:0.18197906606267436, backward:0.10472255322693139, data cost:0.19105073479729343 
2022-05-11 12:34:15,790: ============================================================
2022-05-11 12:34:15,790: Epoch 23/38 Batch 1600/7662 eta: 16:05:03.621300	Training Loss 0.0963 (0.0946)	Training Prec@1 100.000 (99.903)	Training Prec@5 100.000 (99.971)	
2022-05-11 12:34:15,790: ============================================================
2022-05-11 12:35:03,614: time cost, forward:0.18199472303878847, backward:0.10472568432817465, data cost:0.1910468403769634 
2022-05-11 12:35:03,614: ============================================================
2022-05-11 12:35:03,614: Epoch 23/38 Batch 1700/7662 eta: 16:03:36.756794	Training Loss 0.0962 (0.0948)	Training Prec@1 100.000 (99.903)	Training Prec@5 100.000 (99.971)	
2022-05-11 12:35:03,615: ============================================================
2022-05-11 12:35:51,419: time cost, forward:0.1819999208710073, backward:0.10472959329712185, data cost:0.19104031869740934 
2022-05-11 12:35:51,419: ============================================================
2022-05-11 12:35:51,419: Epoch 23/38 Batch 1800/7662 eta: 16:02:24.981413	Training Loss 0.0934 (0.0948)	Training Prec@1 99.805 (99.902)	Training Prec@5 100.000 (99.971)	
2022-05-11 12:35:51,419: ============================================================
2022-05-11 12:36:39,148: time cost, forward:0.18200028451133113, backward:0.10472867299281277, data cost:0.19100301274505022 
2022-05-11 12:36:39,148: ============================================================
2022-05-11 12:36:39,149: Epoch 23/38 Batch 1900/7662 eta: 16:00:05.774731	Training Loss 0.1044 (0.0949)	Training Prec@1 99.805 (99.901)	Training Prec@5 99.805 (99.971)	
2022-05-11 12:36:39,149: ============================================================
2022-05-11 12:37:26,794: time cost, forward:0.1819280634646776, backward:0.10473315891115113, data cost:0.1909949013804006 
2022-05-11 12:37:26,794: ============================================================
2022-05-11 12:37:26,795: Epoch 23/38 Batch 2000/7662 eta: 15:57:37.924105	Training Loss 0.0951 (0.0950)	Training Prec@1 99.609 (99.900)	Training Prec@5 100.000 (99.971)	
2022-05-11 12:37:26,795: ============================================================
2022-05-11 12:38:14,406: time cost, forward:0.18184029414234643, backward:0.10473849115739725, data cost:0.19099207751349984 
2022-05-11 12:38:14,406: ============================================================
2022-05-11 12:38:14,406: Epoch 23/38 Batch 2100/7662 eta: 15:56:08.308405	Training Loss 0.0969 (0.0951)	Training Prec@1 99.805 (99.899)	Training Prec@5 99.805 (99.971)	
2022-05-11 12:38:14,406: ============================================================
2022-05-11 12:39:02,125: time cost, forward:0.18179167341567973, backward:0.10474186054193307, data cost:0.19100385679337803 
2022-05-11 12:39:02,126: ============================================================
2022-05-11 12:39:02,126: Epoch 23/38 Batch 2200/7662 eta: 15:57:31.477347	Training Loss 0.0917 (0.0952)	Training Prec@1 100.000 (99.900)	Training Prec@5 100.000 (99.971)	
2022-05-11 12:39:02,126: ============================================================
2022-05-11 12:39:49,819: time cost, forward:0.18174425940660874, backward:0.10474374585693014, data cost:0.19101233552880473 
2022-05-11 12:39:49,819: ============================================================
2022-05-11 12:39:49,820: Epoch 23/38 Batch 2300/7662 eta: 15:56:12.120969	Training Loss 0.1002 (0.0952)	Training Prec@1 100.000 (99.900)	Training Prec@5 100.000 (99.971)	
2022-05-11 12:39:49,820: ============================================================
2022-05-11 12:40:37,565: time cost, forward:0.18171816092821497, backward:0.1047452921269088, data cost:0.19102504463084494 
2022-05-11 12:40:37,566: ============================================================
2022-05-11 12:40:37,566: Epoch 23/38 Batch 2400/7662 eta: 15:56:27.700021	Training Loss 0.0937 (0.0953)	Training Prec@1 100.000 (99.900)	Training Prec@5 100.000 (99.971)	
2022-05-11 12:40:37,566: ============================================================
2022-05-11 12:41:25,398: time cost, forward:0.1817027636173488, backward:0.10474431633996982, data cost:0.19105471997988038 
2022-05-11 12:41:25,398: ============================================================
2022-05-11 12:41:25,398: Epoch 23/38 Batch 2500/7662 eta: 15:57:23.039255	Training Loss 0.0916 (0.0953)	Training Prec@1 100.000 (99.900)	Training Prec@5 100.000 (99.971)	
2022-05-11 12:41:25,398: ============================================================
2022-05-11 12:42:13,179: time cost, forward:0.18169011469756974, backward:0.10474383954866064, data cost:0.19106564341989468 
2022-05-11 12:42:13,180: ============================================================
2022-05-11 12:42:13,180: Epoch 23/38 Batch 2600/7662 eta: 15:55:34.653101	Training Loss 0.0954 (0.0954)	Training Prec@1 99.805 (99.900)	Training Prec@5 100.000 (99.971)	
2022-05-11 12:42:13,180: ============================================================
2022-05-11 12:43:01,076: time cost, forward:0.18169729159292622, backward:0.1047424323119778, data cost:0.19110047689143178 
2022-05-11 12:43:01,076: ============================================================
2022-05-11 12:43:01,076: Epoch 23/38 Batch 2700/7662 eta: 15:57:04.648352	Training Loss 0.0949 (0.0955)	Training Prec@1 99.805 (99.898)	Training Prec@5 100.000 (99.970)	
2022-05-11 12:43:01,076: ============================================================
2022-05-11 12:43:48,978: time cost, forward:0.1817034959537551, backward:0.10474308834368946, data cost:0.19113799928554087 
2022-05-11 12:43:48,978: ============================================================
2022-05-11 12:43:48,979: Epoch 23/38 Batch 2800/7662 eta: 15:56:23.543547	Training Loss 0.0881 (0.0955)	Training Prec@1 100.000 (99.897)	Training Prec@5 100.000 (99.970)	
2022-05-11 12:43:48,979: ============================================================
2022-05-11 12:44:36,842: time cost, forward:0.18171064160371, backward:0.10474084738658683, data cost:0.1911563888094515 
2022-05-11 12:44:36,842: ============================================================
2022-05-11 12:44:36,842: Epoch 23/38 Batch 2900/7662 eta: 15:54:49.748036	Training Loss 0.0899 (0.0956)	Training Prec@1 100.000 (99.896)	Training Prec@5 100.000 (99.970)	
2022-05-11 12:44:36,843: ============================================================
2022-05-11 12:45:24,696: time cost, forward:0.18172114513126283, backward:0.1047420205971367, data cost:0.19116029392762676 
2022-05-11 12:45:24,697: ============================================================
2022-05-11 12:45:24,697: Epoch 23/38 Batch 3000/7662 eta: 15:53:50.414410	Training Loss 0.0971 (0.0957)	Training Prec@1 99.805 (99.896)	Training Prec@5 99.805 (99.969)	
2022-05-11 12:45:24,697: ============================================================
2022-05-11 12:46:12,644: time cost, forward:0.18175502837415894, backward:0.1047414450847014, data cost:0.1911702538429056 
2022-05-11 12:46:12,644: ============================================================
2022-05-11 12:46:12,645: Epoch 23/38 Batch 3100/7662 eta: 15:54:54.283363	Training Loss 0.0908 (0.0958)	Training Prec@1 100.000 (99.895)	Training Prec@5 100.000 (99.969)	
2022-05-11 12:46:12,645: ============================================================
2022-05-11 12:47:00,568: time cost, forward:0.18177380454506714, backward:0.10473896071626902, data cost:0.19118762791398988 
2022-05-11 12:47:00,569: ============================================================
2022-05-11 12:47:00,569: Epoch 23/38 Batch 3200/7662 eta: 15:53:38.476068	Training Loss 0.0977 (0.0958)	Training Prec@1 99.805 (99.895)	Training Prec@5 99.805 (99.968)	
2022-05-11 12:47:00,569: ============================================================
2022-05-11 12:47:48,506: time cost, forward:0.18179900915776645, backward:0.10473883813278138, data cost:0.19120199480140596 
2022-05-11 12:47:48,507: ============================================================
2022-05-11 12:47:48,507: Epoch 23/38 Batch 3300/7662 eta: 15:53:06.520446	Training Loss 0.0954 (0.0959)	Training Prec@1 100.000 (99.894)	Training Prec@5 100.000 (99.968)	
2022-05-11 12:47:48,507: ============================================================
2022-05-11 12:48:36,370: time cost, forward:0.1818151509772332, backward:0.10473974405509229, data cost:0.19120385864967107 
2022-05-11 12:48:36,370: ============================================================
2022-05-11 12:48:36,371: Epoch 23/38 Batch 3400/7662 eta: 15:50:50.101404	Training Loss 0.0975 (0.0960)	Training Prec@1 100.000 (99.893)	Training Prec@5 100.000 (99.968)	
2022-05-11 12:48:36,371: ============================================================
2022-05-11 12:49:24,227: time cost, forward:0.18182944706352344, backward:0.10473960159369351, data cost:0.19119892722710638 
2022-05-11 12:49:24,228: ============================================================
2022-05-11 12:49:24,228: Epoch 23/38 Batch 3500/7662 eta: 15:49:54.786905	Training Loss 0.1058 (0.0960)	Training Prec@1 99.805 (99.892)	Training Prec@5 100.000 (99.967)	
2022-05-11 12:49:24,228: ============================================================
2022-05-11 12:50:12,171: time cost, forward:0.18185619116823154, backward:0.10473823090267367, data cost:0.19121277170003737 
2022-05-11 12:50:12,171: ============================================================
2022-05-11 12:50:12,171: Epoch 23/38 Batch 3600/7662 eta: 15:50:49.346874	Training Loss 0.0921 (0.0961)	Training Prec@1 100.000 (99.892)	Training Prec@5 100.000 (99.967)	
2022-05-11 12:50:12,171: ============================================================
2022-05-11 12:51:00,143: time cost, forward:0.18187579402217158, backward:0.10474007939866956, data cost:0.19123283983340422 
2022-05-11 12:51:00,143: ============================================================
2022-05-11 12:51:00,143: Epoch 23/38 Batch 3700/7662 eta: 15:50:34.929730	Training Loss 0.1041 (0.0962)	Training Prec@1 99.609 (99.891)	Training Prec@5 99.805 (99.967)	
2022-05-11 12:51:00,143: ============================================================
2022-05-11 12:51:48,027: time cost, forward:0.18188769373651492, backward:0.1047402178183704, data cost:0.19124036031071842 
2022-05-11 12:51:48,028: ============================================================
2022-05-11 12:51:48,028: Epoch 23/38 Batch 3800/7662 eta: 15:48:03.733485	Training Loss 0.1041 (0.0962)	Training Prec@1 100.000 (99.890)	Training Prec@5 100.000 (99.966)	
2022-05-11 12:51:48,028: ============================================================
2022-05-11 12:52:35,980: time cost, forward:0.1819027680316073, backward:0.10474186030434596, data cost:0.19125968304986554 
2022-05-11 12:52:35,981: ============================================================
2022-05-11 12:52:35,981: Epoch 23/38 Batch 3900/7662 eta: 15:48:36.896253	Training Loss 0.1008 (0.0963)	Training Prec@1 100.000 (99.890)	Training Prec@5 100.000 (99.966)	
2022-05-11 12:52:35,981: ============================================================
2022-05-11 12:53:23,871: time cost, forward:0.18192375883754416, backward:0.10474073001521025, data cost:0.191255666339776 
2022-05-11 12:53:23,871: ============================================================
2022-05-11 12:53:23,871: Epoch 23/38 Batch 4000/7662 eta: 15:46:34.619297	Training Loss 0.0993 (0.0963)	Training Prec@1 99.609 (99.889)	Training Prec@5 100.000 (99.966)	
2022-05-11 12:53:23,871: ============================================================
2022-05-11 12:54:11,740: time cost, forward:0.18193526348273154, backward:0.10473766312944682, data cost:0.19125403552905731 
2022-05-11 12:54:11,741: ============================================================
2022-05-11 12:54:11,741: Epoch 23/38 Batch 4100/7662 eta: 15:45:22.104573	Training Loss 0.1055 (0.0964)	Training Prec@1 99.805 (99.888)	Training Prec@5 99.805 (99.966)	
2022-05-11 12:54:11,753: ============================================================
2022-05-11 12:54:59,615: time cost, forward:0.18194814567538664, backward:0.10473642096005045, data cost:0.19125272228934134 
2022-05-11 12:54:59,615: ============================================================
2022-05-11 12:54:59,615: Epoch 23/38 Batch 4200/7662 eta: 15:44:39.813228	Training Loss 0.0935 (0.0964)	Training Prec@1 100.000 (99.889)	Training Prec@5 100.000 (99.966)	
2022-05-11 12:54:59,615: ============================================================
2022-05-11 12:55:47,510: time cost, forward:0.1819604453055574, backward:0.10473622602483622, data cost:0.19125004085337569 
2022-05-11 12:55:47,510: ============================================================
2022-05-11 12:55:47,510: Epoch 23/38 Batch 4300/7662 eta: 15:44:16.484785	Training Loss 0.1000 (0.0965)	Training Prec@1 99.805 (99.888)	Training Prec@5 100.000 (99.966)	
2022-05-11 12:55:47,510: ============================================================
2022-05-11 12:56:35,411: time cost, forward:0.18196941939612143, backward:0.10473575443537514, data cost:0.1912608128782022 
2022-05-11 12:56:35,411: ============================================================
2022-05-11 12:56:35,411: Epoch 23/38 Batch 4400/7662 eta: 15:43:35.925968	Training Loss 0.0938 (0.0966)	Training Prec@1 100.000 (99.888)	Training Prec@5 100.000 (99.966)	
2022-05-11 12:56:35,412: ============================================================
2022-05-11 12:57:23,251: time cost, forward:0.1819780484441387, backward:0.10473424658613169, data cost:0.19125887112342985 
2022-05-11 12:57:23,251: ============================================================
2022-05-11 12:57:23,251: Epoch 23/38 Batch 4500/7662 eta: 15:41:35.539059	Training Loss 0.1000 (0.0966)	Training Prec@1 100.000 (99.888)	Training Prec@5 100.000 (99.965)	
2022-05-11 12:57:23,251: ============================================================
2022-05-11 12:58:11,115: time cost, forward:0.1819836905169005, backward:0.10473231352731233, data cost:0.1912639690601559 
2022-05-11 12:58:11,115: ============================================================
2022-05-11 12:58:11,115: Epoch 23/38 Batch 4600/7662 eta: 15:41:16.374978	Training Loss 0.1032 (0.0967)	Training Prec@1 100.000 (99.887)	Training Prec@5 100.000 (99.965)	
2022-05-11 12:58:11,116: ============================================================
2022-05-11 12:58:58,987: time cost, forward:0.1819975073729761, backward:0.10473244315539301, data cost:0.19126006592383002 
2022-05-11 12:58:58,988: ============================================================
2022-05-11 12:58:58,988: Epoch 23/38 Batch 4700/7662 eta: 15:40:38.267331	Training Loss 0.0961 (0.0967)	Training Prec@1 99.805 (99.887)	Training Prec@5 100.000 (99.965)	
2022-05-11 12:58:58,988: ============================================================
2022-05-11 12:59:46,856: time cost, forward:0.18201034653805326, backward:0.10473249554261488, data cost:0.1912534610508233 
2022-05-11 12:59:46,857: ============================================================
2022-05-11 12:59:46,857: Epoch 23/38 Batch 4800/7662 eta: 15:39:46.144923	Training Loss 0.1124 (0.0968)	Training Prec@1 99.805 (99.886)	Training Prec@5 100.000 (99.965)	
2022-05-11 12:59:46,857: ============================================================
2022-05-11 13:00:34,703: time cost, forward:0.18201841045628034, backward:0.10473298627421622, data cost:0.19124406409472877 
2022-05-11 13:00:34,704: ============================================================
2022-05-11 13:00:34,704: Epoch 23/38 Batch 4900/7662 eta: 15:38:32.961855	Training Loss 0.1011 (0.0968)	Training Prec@1 99.805 (99.886)	Training Prec@5 100.000 (99.965)	
2022-05-11 13:00:34,704: ============================================================
2022-05-11 13:01:22,563: time cost, forward:0.18202477723366023, backward:0.10473237192184835, data cost:0.19124058275896208 
2022-05-11 13:01:22,564: ============================================================
2022-05-11 13:01:22,564: Epoch 23/38 Batch 5000/7662 eta: 15:37:59.553245	Training Loss 0.1007 (0.0969)	Training Prec@1 99.805 (99.886)	Training Prec@5 99.805 (99.964)	
2022-05-11 13:01:22,564: ============================================================
2022-05-11 13:02:10,432: time cost, forward:0.18203245880417226, backward:0.10473201508193793, data cost:0.19124158973155198 
2022-05-11 13:02:10,432: ============================================================
2022-05-11 13:02:10,432: Epoch 23/38 Batch 5100/7662 eta: 15:37:22.328304	Training Loss 0.1041 (0.0970)	Training Prec@1 100.000 (99.886)	Training Prec@5 100.000 (99.964)	
2022-05-11 13:02:10,432: ============================================================
2022-05-11 13:02:58,318: time cost, forward:0.1820419518895781, backward:0.10473217632156492, data cost:0.1912386640261448 
2022-05-11 13:02:58,318: ============================================================
2022-05-11 13:02:58,318: Epoch 23/38 Batch 5200/7662 eta: 15:36:54.859744	Training Loss 0.1045 (0.0970)	Training Prec@1 99.805 (99.886)	Training Prec@5 99.805 (99.964)	
2022-05-11 13:02:58,318: ============================================================
2022-05-11 13:03:46,166: time cost, forward:0.18204497067202574, backward:0.10473112260019764, data cost:0.19123359805436646 
2022-05-11 13:03:46,166: ============================================================
2022-05-11 13:03:46,166: Epoch 23/38 Batch 5300/7662 eta: 15:35:21.934666	Training Loss 0.0964 (0.0971)	Training Prec@1 99.805 (99.886)	Training Prec@5 100.000 (99.964)	
2022-05-11 13:03:46,166: ============================================================
2022-05-11 13:04:33,997: time cost, forward:0.18205552989629756, backward:0.10473179512497319, data cost:0.1912229698352139 
2022-05-11 13:04:33,997: ============================================================
2022-05-11 13:04:33,997: Epoch 23/38 Batch 5400/7662 eta: 15:34:14.872845	Training Loss 0.0994 (0.0971)	Training Prec@1 100.000 (99.887)	Training Prec@5 100.000 (99.964)	
2022-05-11 13:04:33,997: ============================================================
2022-05-11 13:05:21,865: time cost, forward:0.18205981090689252, backward:0.10473113815271544, data cost:0.19122262039191507 
2022-05-11 13:05:21,865: ============================================================
2022-05-11 13:05:21,865: Epoch 23/38 Batch 5500/7662 eta: 15:34:10.126410	Training Loss 0.0965 (0.0972)	Training Prec@1 99.805 (99.887)	Training Prec@5 99.805 (99.964)	
2022-05-11 13:05:21,865: ============================================================
2022-05-11 13:06:09,751: time cost, forward:0.1820707159354061, backward:0.10473105770750842, data cost:0.19121636320680652 
2022-05-11 13:06:09,752: ============================================================
2022-05-11 13:06:09,752: Epoch 23/38 Batch 5600/7662 eta: 15:33:43.819335	Training Loss 0.1032 (0.0972)	Training Prec@1 100.000 (99.886)	Training Prec@5 100.000 (99.964)	
2022-05-11 13:06:09,752: ============================================================
2022-05-11 13:06:57,526: time cost, forward:0.18207438277830093, backward:0.10472765009033824, data cost:0.1912005406594063 
2022-05-11 13:06:57,526: ============================================================
2022-05-11 13:06:57,527: Epoch 23/38 Batch 5700/7662 eta: 15:30:45.330429	Training Loss 0.0939 (0.0973)	Training Prec@1 100.000 (99.886)	Training Prec@5 100.000 (99.964)	
2022-05-11 13:06:57,527: ============================================================
2022-05-11 13:07:45,353: time cost, forward:0.18208385989838252, backward:0.1047267006026977, data cost:0.19119188028649023 
2022-05-11 13:07:45,353: ============================================================
2022-05-11 13:07:45,354: Epoch 23/38 Batch 5800/7662 eta: 15:30:58.560151	Training Loss 0.0983 (0.0973)	Training Prec@1 99.805 (99.886)	Training Prec@5 99.805 (99.964)	
2022-05-11 13:07:45,354: ============================================================
2022-05-11 13:08:33,188: time cost, forward:0.18209412910712333, backward:0.1047242671923226, data cost:0.19118101157501888 
2022-05-11 13:08:33,188: ============================================================
2022-05-11 13:08:33,188: Epoch 23/38 Batch 5900/7662 eta: 15:30:19.819768	Training Loss 0.1026 (0.0974)	Training Prec@1 99.609 (99.886)	Training Prec@5 99.805 (99.964)	
2022-05-11 13:08:33,188: ============================================================
2022-05-11 13:09:21,015: time cost, forward:0.18210671941207476, backward:0.10472492314036796, data cost:0.1911652962909895 
2022-05-11 13:09:21,015: ============================================================
2022-05-11 13:09:21,016: Epoch 23/38 Batch 6000/7662 eta: 15:29:23.345962	Training Loss 0.1051 (0.0974)	Training Prec@1 99.609 (99.885)	Training Prec@5 100.000 (99.963)	
2022-05-11 13:09:21,016: ============================================================
2022-05-11 13:10:08,772: time cost, forward:0.18210716321050466, backward:0.10472527850473644, data cost:0.19115121686315903 
2022-05-11 13:10:08,772: ============================================================
2022-05-11 13:10:08,772: Epoch 23/38 Batch 6100/7662 eta: 15:27:13.187302	Training Loss 0.0929 (0.0975)	Training Prec@1 100.000 (99.885)	Training Prec@5 100.000 (99.963)	
2022-05-11 13:10:08,772: ============================================================
2022-05-11 13:10:56,372: time cost, forward:0.182082486818021, backward:0.1047244065422111, data cost:0.19113666189353415 
2022-05-11 13:10:56,372: ============================================================
2022-05-11 13:10:56,373: Epoch 23/38 Batch 6200/7662 eta: 15:23:23.337066	Training Loss 0.0944 (0.0975)	Training Prec@1 99.805 (99.885)	Training Prec@5 100.000 (99.963)	
2022-05-11 13:10:56,373: ============================================================
2022-05-11 13:11:44,012: time cost, forward:0.18207193412635417, backward:0.10472430038270468, data cost:0.19111860390787447 
2022-05-11 13:11:44,012: ============================================================
2022-05-11 13:11:44,012: Epoch 23/38 Batch 6300/7662 eta: 15:23:21.614343	Training Loss 0.0985 (0.0976)	Training Prec@1 100.000 (99.885)	Training Prec@5 100.000 (99.963)	
2022-05-11 13:11:44,012: ============================================================
2022-05-11 13:12:31,794: time cost, forward:0.182079811248207, backward:0.10472373061486381, data cost:0.19110327766246768 
2022-05-11 13:12:31,795: ============================================================
2022-05-11 13:12:31,795: Epoch 23/38 Batch 6400/7662 eta: 15:25:19.848232	Training Loss 0.0934 (0.0976)	Training Prec@1 100.000 (99.884)	Training Prec@5 100.000 (99.963)	
2022-05-11 13:12:31,795: ============================================================
2022-05-11 13:13:19,701: time cost, forward:0.18211100655054016, backward:0.10472287917470983, data cost:0.1910862238485275 
2022-05-11 13:13:19,702: ============================================================
2022-05-11 13:13:19,702: Epoch 23/38 Batch 6500/7662 eta: 15:26:56.895845	Training Loss 0.1032 (0.0977)	Training Prec@1 99.414 (99.884)	Training Prec@5 99.805 (99.963)	
2022-05-11 13:13:19,702: ============================================================
2022-05-11 13:14:07,585: time cost, forward:0.18213468541664, backward:0.10472255086226795, data cost:0.1910725073446594 
2022-05-11 13:14:07,585: ============================================================
2022-05-11 13:14:07,586: Epoch 23/38 Batch 6600/7662 eta: 15:25:41.741677	Training Loss 0.1015 (0.0977)	Training Prec@1 99.609 (99.884)	Training Prec@5 100.000 (99.963)	
2022-05-11 13:14:07,586: ============================================================
2022-05-11 13:14:55,284: time cost, forward:0.18213578597309518, backward:0.10472199820390227, data cost:0.19105381114320233 
2022-05-11 13:14:55,284: ============================================================
2022-05-11 13:14:55,285: Epoch 23/38 Batch 6700/7662 eta: 15:21:19.825419	Training Loss 0.0983 (0.0978)	Training Prec@1 99.609 (99.883)	Training Prec@5 99.805 (99.963)	
2022-05-11 13:14:55,285: ============================================================
2022-05-11 13:15:43,002: time cost, forward:0.1821360709755223, backward:0.10472216345243796, data cost:0.19103827376912 
2022-05-11 13:15:43,003: ============================================================
2022-05-11 13:15:43,003: Epoch 23/38 Batch 6800/7662 eta: 15:20:54.334737	Training Loss 0.1043 (0.0978)	Training Prec@1 100.000 (99.883)	Training Prec@5 100.000 (99.962)	
2022-05-11 13:15:43,003: ============================================================
2022-05-11 13:16:30,761: time cost, forward:0.1821388474995372, backward:0.10472218885613897, data cost:0.19102536344687168 
2022-05-11 13:16:30,762: ============================================================
2022-05-11 13:16:30,762: Epoch 23/38 Batch 6900/7662 eta: 15:20:53.747123	Training Loss 0.0957 (0.0979)	Training Prec@1 100.000 (99.883)	Training Prec@5 100.000 (99.962)	
2022-05-11 13:16:30,762: ============================================================
2022-05-11 13:17:18,681: time cost, forward:0.18216637693689386, backward:0.10472347712854024, data cost:0.191012481805818 
2022-05-11 13:17:18,681: ============================================================
2022-05-11 13:17:18,681: Epoch 23/38 Batch 7000/7662 eta: 15:23:11.728870	Training Loss 0.0995 (0.0979)	Training Prec@1 100.000 (99.883)	Training Prec@5 100.000 (99.963)	
2022-05-11 13:17:18,682: ============================================================
2022-05-11 13:18:06,650: time cost, forward:0.18220083689014582, backward:0.10472466334740467, data cost:0.1909977732149375 
2022-05-11 13:18:06,651: ============================================================
2022-05-11 13:18:06,651: Epoch 23/38 Batch 7100/7662 eta: 15:23:21.351929	Training Loss 0.0999 (0.0980)	Training Prec@1 100.000 (99.882)	Training Prec@5 100.000 (99.962)	
2022-05-11 13:18:06,651: ============================================================
2022-05-11 13:18:54,832: time cost, forward:0.182254460010616, backward:0.10472893870560754, data cost:0.1909898270632032 
2022-05-11 13:18:54,832: ============================================================
2022-05-11 13:18:54,833: Epoch 23/38 Batch 7200/7662 eta: 15:26:38.331080	Training Loss 0.0998 (0.0980)	Training Prec@1 100.000 (99.882)	Training Prec@5 100.000 (99.962)	
2022-05-11 13:18:54,833: ============================================================
2022-05-11 13:19:42,701: time cost, forward:0.18227160899732878, backward:0.10473219060394794, data cost:0.19097540355378723 
2022-05-11 13:19:42,702: ============================================================
2022-05-11 13:19:42,702: Epoch 23/38 Batch 7300/7662 eta: 15:19:50.004972	Training Loss 0.1000 (0.0981)	Training Prec@1 100.000 (99.882)	Training Prec@5 100.000 (99.962)	
2022-05-11 13:19:42,702: ============================================================
2022-05-11 13:20:30,374: time cost, forward:0.18226812700755468, backward:0.10473294347697842, data cost:0.1909575075664332 
2022-05-11 13:20:30,374: ============================================================
2022-05-11 13:20:30,375: Epoch 23/38 Batch 7400/7662 eta: 15:15:15.666234	Training Loss 0.0971 (0.0981)	Training Prec@1 99.609 (99.882)	Training Prec@5 100.000 (99.962)	
2022-05-11 13:20:30,375: ============================================================
2022-05-11 13:21:18,076: time cost, forward:0.18226750718226256, backward:0.10473411187185798, data cost:0.19094075627574317 
2022-05-11 13:21:18,077: ============================================================
2022-05-11 13:21:18,077: Epoch 23/38 Batch 7500/7662 eta: 15:15:01.669059	Training Loss 0.1030 (0.0981)	Training Prec@1 100.000 (99.881)	Training Prec@5 100.000 (99.962)	
2022-05-11 13:21:18,077: ============================================================
2022-05-11 13:22:05,819: time cost, forward:0.18226803128759175, backward:0.10473800467917724, data cost:0.1909260997051847 
2022-05-11 13:22:05,819: ============================================================
2022-05-11 13:22:05,819: Epoch 23/38 Batch 7600/7662 eta: 15:15:00.360104	Training Loss 0.1064 (0.0982)	Training Prec@1 100.000 (99.881)	Training Prec@5 100.000 (99.962)	
2022-05-11 13:22:05,819: ============================================================
2022-05-11 13:22:37,425: Epoch: 23/38 eta: 15:14:30.282424	Training Loss 0.0987 (0.0982)	Training Prec@1 99.805 (99.881)	Training Prec@5 100.000 (99.962)
2022-05-11 13:22:37,425: ============================================================
2022-05-11 13:23:26,815: time cost, forward:0.18168247107303503, backward:0.10462001839069406, data cost:0.20904104155723494 
2022-05-11 13:23:26,816: ============================================================
2022-05-11 13:23:26,816: Epoch 24/38 Batch 100/7662 eta: 15:42:39.579075	Training Loss 0.0953 (0.0903)	Training Prec@1 99.609 (99.911)	Training Prec@5 99.805 (99.968)	
2022-05-11 13:23:26,816: ============================================================
2022-05-11 13:24:14,454: time cost, forward:0.18167779313859028, backward:0.10470318434825494, data cost:0.19929662062295117 
2022-05-11 13:24:14,454: ============================================================
2022-05-11 13:24:14,454: Epoch 24/38 Batch 200/7662 eta: 15:10:56.083093	Training Loss 0.0869 (0.0903)	Training Prec@1 100.000 (99.913)	Training Prec@5 100.000 (99.970)	
2022-05-11 13:24:14,454: ============================================================
2022-05-11 13:25:02,100: time cost, forward:0.18164685737329184, backward:0.10476975536665391, data cost:0.19608629906057912 
2022-05-11 13:25:02,100: ============================================================
2022-05-11 13:25:02,101: Epoch 24/38 Batch 300/7662 eta: 15:10:17.314362	Training Loss 0.1008 (0.0903)	Training Prec@1 99.805 (99.919)	Training Prec@5 99.805 (99.972)	
2022-05-11 13:25:02,101: ============================================================
2022-05-11 13:25:49,727: time cost, forward:0.18159016033163047, backward:0.10480729858379316, data cost:0.19448064562670866 
2022-05-11 13:25:49,727: ============================================================
2022-05-11 13:25:49,727: Epoch 24/38 Batch 400/7662 eta: 15:09:07.521373	Training Loss 0.0935 (0.0903)	Training Prec@1 100.000 (99.913)	Training Prec@5 100.000 (99.970)	
2022-05-11 13:25:49,728: ============================================================
2022-05-11 13:26:37,346: time cost, forward:0.1815219412824673, backward:0.10484571925146069, data cost:0.19351483872514927 
2022-05-11 13:26:37,346: ============================================================
2022-05-11 13:26:37,346: Epoch 24/38 Batch 500/7662 eta: 15:08:10.680401	Training Loss 0.0881 (0.0904)	Training Prec@1 100.000 (99.914)	Training Prec@5 100.000 (99.972)	
2022-05-11 13:26:37,346: ============================================================
2022-05-11 13:27:24,983: time cost, forward:0.18151955851330384, backward:0.10487160579191027, data cost:0.1928625835202174 
2022-05-11 13:27:24,983: ============================================================
2022-05-11 13:27:24,983: Epoch 24/38 Batch 600/7662 eta: 15:07:44.002492	Training Loss 0.0880 (0.0904)	Training Prec@1 100.000 (99.915)	Training Prec@5 100.000 (99.971)	
2022-05-11 13:27:24,983: ============================================================
2022-05-11 13:28:12,595: time cost, forward:0.18148206845885181, backward:0.10489487886769919, data cost:0.1923930883748678 
2022-05-11 13:28:12,595: ============================================================
2022-05-11 13:28:12,595: Epoch 24/38 Batch 700/7662 eta: 15:06:27.498119	Training Loss 0.0945 (0.0905)	Training Prec@1 99.805 (99.917)	Training Prec@5 99.805 (99.972)	
2022-05-11 13:28:12,595: ============================================================
2022-05-11 13:29:00,239: time cost, forward:0.18149760130499124, backward:0.10490466327929825, data cost:0.19204569220990503 
2022-05-11 13:29:00,239: ============================================================
2022-05-11 13:29:00,239: Epoch 24/38 Batch 800/7662 eta: 15:06:16.289074	Training Loss 0.0874 (0.0906)	Training Prec@1 100.000 (99.920)	Training Prec@5 100.000 (99.973)	
2022-05-11 13:29:00,239: ============================================================
2022-05-11 13:29:47,946: time cost, forward:0.18155021556094703, backward:0.10491143105690419, data cost:0.19180544597553598 
2022-05-11 13:29:47,947: ============================================================
2022-05-11 13:29:47,947: Epoch 24/38 Batch 900/7662 eta: 15:06:41.580181	Training Loss 0.0987 (0.0907)	Training Prec@1 100.000 (99.922)	Training Prec@5 100.000 (99.973)	
2022-05-11 13:29:47,947: ============================================================
2022-05-11 13:30:35,644: time cost, forward:0.18159376775418912, backward:0.10492080849808855, data cost:0.19159567678296888 
2022-05-11 13:30:35,644: ============================================================
2022-05-11 13:30:35,644: Epoch 24/38 Batch 1000/7662 eta: 15:05:42.526373	Training Loss 0.0945 (0.0908)	Training Prec@1 99.609 (99.922)	Training Prec@5 100.000 (99.974)	
2022-05-11 13:30:35,645: ============================================================
2022-05-11 13:31:23,341: time cost, forward:0.18163543120636735, backward:0.10492427030186745, data cost:0.19142462298260482 
2022-05-11 13:31:23,341: ============================================================
2022-05-11 13:31:23,342: Epoch 24/38 Batch 1100/7662 eta: 15:04:54.149321	Training Loss 0.0954 (0.0909)	Training Prec@1 100.000 (99.922)	Training Prec@5 100.000 (99.974)	
2022-05-11 13:31:23,342: ============================================================
2022-05-11 13:32:11,039: time cost, forward:0.1816791171725339, backward:0.10492487765034603, data cost:0.19127675013506382 
2022-05-11 13:32:11,040: ============================================================
2022-05-11 13:32:11,040: Epoch 24/38 Batch 1200/7662 eta: 15:04:07.642810	Training Loss 0.0953 (0.0910)	Training Prec@1 99.805 (99.921)	Training Prec@5 99.805 (99.974)	
2022-05-11 13:32:11,040: ============================================================
2022-05-11 13:32:58,722: time cost, forward:0.18169115101768019, backward:0.10492315945761124, data cost:0.19116604722766714 
2022-05-11 13:32:58,722: ============================================================
2022-05-11 13:32:58,722: Epoch 24/38 Batch 1300/7662 eta: 15:03:01.952982	Training Loss 0.0990 (0.0911)	Training Prec@1 100.000 (99.922)	Training Prec@5 100.000 (99.974)	
2022-05-11 13:32:58,722: ============================================================
2022-05-11 13:33:46,442: time cost, forward:0.18170957602800175, backward:0.10493958038973587, data cost:0.19107451875180836 
2022-05-11 13:33:46,443: ============================================================
2022-05-11 13:33:46,443: Epoch 24/38 Batch 1400/7662 eta: 15:02:57.790923	Training Loss 0.0919 (0.0912)	Training Prec@1 100.000 (99.921)	Training Prec@5 100.000 (99.974)	
2022-05-11 13:33:46,443: ============================================================
2022-05-11 13:34:34,189: time cost, forward:0.18174531509114394, backward:0.10495020295080143, data cost:0.19099534154335923 
2022-05-11 13:34:34,190: ============================================================
2022-05-11 13:34:34,190: Epoch 24/38 Batch 1500/7662 eta: 15:02:39.918207	Training Loss 0.0886 (0.0913)	Training Prec@1 100.000 (99.920)	Training Prec@5 100.000 (99.973)	
2022-05-11 13:34:34,190: ============================================================
2022-05-11 13:35:21,928: time cost, forward:0.18176749141757528, backward:0.10495841331672788, data cost:0.19093067188274868 
2022-05-11 13:35:21,929: ============================================================
2022-05-11 13:35:21,929: Epoch 24/38 Batch 1600/7662 eta: 15:01:43.018092	Training Loss 0.0907 (0.0913)	Training Prec@1 99.805 (99.919)	Training Prec@5 99.805 (99.973)	
2022-05-11 13:35:21,929: ============================================================
2022-05-11 13:36:09,659: time cost, forward:0.18178097692358278, backward:0.1049636201763097, data cost:0.19087736013007206 
2022-05-11 13:36:09,659: ============================================================
2022-05-11 13:36:09,659: Epoch 24/38 Batch 1700/7662 eta: 15:00:45.623089	Training Loss 0.0876 (0.0914)	Training Prec@1 100.000 (99.919)	Training Prec@5 100.000 (99.973)	
2022-05-11 13:36:09,659: ============================================================
2022-05-11 13:36:57,358: time cost, forward:0.1817889342114553, backward:0.104968645626999, data cost:0.19081509544029046 
2022-05-11 13:36:57,358: ============================================================
2022-05-11 13:36:57,358: Epoch 24/38 Batch 1800/7662 eta: 14:59:22.485294	Training Loss 0.0882 (0.0914)	Training Prec@1 100.000 (99.918)	Training Prec@5 100.000 (99.973)	
2022-05-11 13:36:57,359: ============================================================
2022-05-11 13:37:45,068: time cost, forward:0.18180245496901543, backward:0.10496839025637048, data cost:0.19076489749364064 
2022-05-11 13:37:45,068: ============================================================
2022-05-11 13:37:45,069: Epoch 24/38 Batch 1900/7662 eta: 14:58:47.394124	Training Loss 0.0923 (0.0915)	Training Prec@1 100.000 (99.917)	Training Prec@5 100.000 (99.973)	
2022-05-11 13:37:45,069: ============================================================
2022-05-11 13:38:32,794: time cost, forward:0.181816398888722, backward:0.10497368187114797, data cost:0.19072018628599882 
2022-05-11 13:38:32,795: ============================================================
2022-05-11 13:38:32,795: Epoch 24/38 Batch 2000/7662 eta: 14:58:17.731043	Training Loss 0.0920 (0.0916)	Training Prec@1 99.805 (99.917)	Training Prec@5 99.805 (99.973)	
2022-05-11 13:38:32,795: ============================================================
2022-05-11 13:39:20,497: time cost, forward:0.18181828239408204, backward:0.10496947491606284, data cost:0.1906877104698788 
2022-05-11 13:39:20,498: ============================================================
2022-05-11 13:39:20,498: Epoch 24/38 Batch 2100/7662 eta: 14:57:03.740264	Training Loss 0.0905 (0.0917)	Training Prec@1 99.805 (99.917)	Training Prec@5 100.000 (99.972)	
2022-05-11 13:39:20,498: ============================================================
2022-05-11 13:40:08,216: time cost, forward:0.18182730522953744, backward:0.10497068014400772, data cost:0.1906529908399248 
2022-05-11 13:40:08,217: ============================================================
2022-05-11 13:40:08,217: Epoch 24/38 Batch 2200/7662 eta: 14:56:34.010052	Training Loss 0.0909 (0.0918)	Training Prec@1 99.805 (99.917)	Training Prec@5 99.805 (99.972)	
2022-05-11 13:40:08,217: ============================================================
2022-05-11 13:40:55,940: time cost, forward:0.18184027395957758, backward:0.10497896885965222, data cost:0.190612564920705 
2022-05-11 13:40:55,940: ============================================================
2022-05-11 13:40:55,941: Epoch 24/38 Batch 2300/7662 eta: 14:55:51.745316	Training Loss 0.0937 (0.0919)	Training Prec@1 99.805 (99.917)	Training Prec@5 99.805 (99.972)	
2022-05-11 13:40:55,941: ============================================================
2022-05-11 13:41:43,728: time cost, forward:0.18186024528287162, backward:0.10498669486385726, data cost:0.19059334033824543 
2022-05-11 13:41:43,729: ============================================================
2022-05-11 13:41:43,729: Epoch 24/38 Batch 2400/7662 eta: 14:56:16.668013	Training Loss 0.0970 (0.0920)	Training Prec@1 100.000 (99.917)	Training Prec@5 100.000 (99.972)	
2022-05-11 13:41:43,729: ============================================================
2022-05-11 13:42:31,507: time cost, forward:0.18187648604134646, backward:0.10499090822089334, data cost:0.19057160236683784 
2022-05-11 13:42:31,507: ============================================================
2022-05-11 13:42:31,507: Epoch 24/38 Batch 2500/7662 eta: 14:55:17.577905	Training Loss 0.0969 (0.0921)	Training Prec@1 100.000 (99.916)	Training Prec@5 100.000 (99.972)	
2022-05-11 13:42:31,507: ============================================================
2022-05-11 13:43:19,100: time cost, forward:0.1818157273469039, backward:0.10499454315188482, data cost:0.19056131125138603 
2022-05-11 13:43:19,100: ============================================================
2022-05-11 13:43:19,100: Epoch 24/38 Batch 2600/7662 eta: 14:51:02.036903	Training Loss 0.0961 (0.0921)	Training Prec@1 99.609 (99.915)	Training Prec@5 99.805 (99.971)	
2022-05-11 13:43:19,101: ============================================================
2022-05-11 13:44:06,799: time cost, forward:0.18178054888012588, backward:0.1049973871055114, data cost:0.1905701782315605 
2022-05-11 13:44:06,799: ============================================================
2022-05-11 13:44:06,799: Epoch 24/38 Batch 2700/7662 eta: 14:52:12.551072	Training Loss 0.0976 (0.0922)	Training Prec@1 99.805 (99.915)	Training Prec@5 100.000 (99.971)	
2022-05-11 13:44:06,799: ============================================================
2022-05-11 13:44:54,470: time cost, forward:0.18175492486003128, backward:0.10499503826319895, data cost:0.19056290028222164 
2022-05-11 13:44:54,471: ============================================================
2022-05-11 13:44:54,471: Epoch 24/38 Batch 2800/7662 eta: 14:50:54.735481	Training Loss 0.0992 (0.0923)	Training Prec@1 99.805 (99.914)	Training Prec@5 100.000 (99.972)	
2022-05-11 13:44:54,471: ============================================================
2022-05-11 13:45:42,186: time cost, forward:0.18174090735786494, backward:0.10498896423147727, data cost:0.19056451818210252 
2022-05-11 13:45:42,186: ============================================================
2022-05-11 13:45:42,186: Epoch 24/38 Batch 2900/7662 eta: 14:50:56.389657	Training Loss 0.1016 (0.0924)	Training Prec@1 99.805 (99.914)	Training Prec@5 100.000 (99.972)	
2022-05-11 13:45:42,187: ============================================================
2022-05-11 13:46:29,926: time cost, forward:0.18174335971678365, backward:0.10497989349263476, data cost:0.1905668690507513 
2022-05-11 13:46:29,926: ============================================================
2022-05-11 13:46:29,927: Epoch 24/38 Batch 3000/7662 eta: 14:50:35.943473	Training Loss 0.0905 (0.0925)	Training Prec@1 99.805 (99.914)	Training Prec@5 100.000 (99.972)	
2022-05-11 13:46:29,927: ============================================================
2022-05-11 13:47:17,668: time cost, forward:0.1817475811594261, backward:0.10497649302979599, data cost:0.19055870926430166 
2022-05-11 13:47:17,668: ============================================================
2022-05-11 13:47:17,668: Epoch 24/38 Batch 3100/7662 eta: 14:49:50.220423	Training Loss 0.0996 (0.0926)	Training Prec@1 99.805 (99.913)	Training Prec@5 99.805 (99.971)	
2022-05-11 13:47:17,668: ============================================================
2022-05-11 13:48:05,396: time cost, forward:0.18175117453026302, backward:0.10497065803787789, data cost:0.1905533923846403 
2022-05-11 13:48:05,397: ============================================================
2022-05-11 13:48:05,397: Epoch 24/38 Batch 3200/7662 eta: 14:48:47.408472	Training Loss 0.0946 (0.0927)	Training Prec@1 99.805 (99.913)	Training Prec@5 100.000 (99.971)	
2022-05-11 13:48:05,397: ============================================================
2022-05-11 13:48:53,183: time cost, forward:0.18175552049598104, backward:0.10496969770828714, data cost:0.1905605800226263 
2022-05-11 13:48:53,183: ============================================================
2022-05-11 13:48:53,183: Epoch 24/38 Batch 3300/7662 eta: 14:49:04.413916	Training Loss 0.0998 (0.0927)	Training Prec@1 100.000 (99.912)	Training Prec@5 100.000 (99.971)	
2022-05-11 13:48:53,183: ============================================================
2022-05-11 13:49:40,999: time cost, forward:0.18176552119343448, backward:0.1049690191168475, data cost:0.1905698096552257 
2022-05-11 13:49:41,000: ============================================================
2022-05-11 13:49:41,000: Epoch 24/38 Batch 3400/7662 eta: 14:48:50.246617	Training Loss 0.1012 (0.0928)	Training Prec@1 100.000 (99.912)	Training Prec@5 100.000 (99.971)	
2022-05-11 13:49:41,000: ============================================================
2022-05-11 13:50:28,774: time cost, forward:0.1817743157481902, backward:0.10497052371757444, data cost:0.19056539386979304 
2022-05-11 13:50:28,775: ============================================================
2022-05-11 13:50:28,775: Epoch 24/38 Batch 3500/7662 eta: 14:47:16.184267	Training Loss 0.0944 (0.0929)	Training Prec@1 99.805 (99.912)	Training Prec@5 100.000 (99.971)	
2022-05-11 13:50:28,775: ============================================================
2022-05-11 13:51:16,624: time cost, forward:0.18178578501577078, backward:0.10497125959224124, data cost:0.19057559728556192 
2022-05-11 13:51:16,624: ============================================================
2022-05-11 13:51:16,624: Epoch 24/38 Batch 3600/7662 eta: 14:47:51.474891	Training Loss 0.0946 (0.0930)	Training Prec@1 99.609 (99.911)	Training Prec@5 99.805 (99.970)	
2022-05-11 13:51:16,624: ============================================================
2022-05-11 13:52:04,495: time cost, forward:0.18180448237416807, backward:0.10497378568192951, data cost:0.19058529980667993 
2022-05-11 13:52:04,495: ============================================================
2022-05-11 13:52:04,495: Epoch 24/38 Batch 3700/7662 eta: 14:47:27.422300	Training Loss 0.0977 (0.0931)	Training Prec@1 99.219 (99.910)	Training Prec@5 99.805 (99.970)	
2022-05-11 13:52:04,495: ============================================================
2022-05-11 13:52:52,299: time cost, forward:0.18181559022209084, backward:0.10497726111325442, data cost:0.19057896269657448 
2022-05-11 13:52:52,300: ============================================================
2022-05-11 13:52:52,300: Epoch 24/38 Batch 3800/7662 eta: 14:45:25.398830	Training Loss 0.1017 (0.0931)	Training Prec@1 100.000 (99.910)	Training Prec@5 100.000 (99.970)	
2022-05-11 13:52:52,300: ============================================================
2022-05-11 13:53:40,169: time cost, forward:0.18182426411300232, backward:0.10498137368884383, data cost:0.19059390726992032 
2022-05-11 13:53:40,169: ============================================================
2022-05-11 13:53:40,170: Epoch 24/38 Batch 3900/7662 eta: 14:45:50.526337	Training Loss 0.1008 (0.0932)	Training Prec@1 99.805 (99.909)	Training Prec@5 100.000 (99.970)	
2022-05-11 13:53:40,170: ============================================================
2022-05-11 13:54:28,063: time cost, forward:0.1818393770233635, backward:0.10498287755866503, data cost:0.19060693045919255 
2022-05-11 13:54:28,063: ============================================================
2022-05-11 13:54:28,064: Epoch 24/38 Batch 4000/7662 eta: 14:45:29.255643	Training Loss 0.0957 (0.0933)	Training Prec@1 99.805 (99.909)	Training Prec@5 99.805 (99.970)	
2022-05-11 13:54:28,064: ============================================================
2022-05-11 13:55:15,972: time cost, forward:0.1818492777262062, backward:0.10498849587720846, data cost:0.19062313843890208 
2022-05-11 13:55:15,972: ============================================================
2022-05-11 13:55:15,972: Epoch 24/38 Batch 4100/7662 eta: 14:44:57.627339	Training Loss 0.0914 (0.0934)	Training Prec@1 99.805 (99.909)	Training Prec@5 99.805 (99.970)	
2022-05-11 13:55:15,972: ============================================================
2022-05-11 13:56:03,845: time cost, forward:0.18185783204762077, backward:0.10499203185235696, data cost:0.19063548645424713 
2022-05-11 13:56:03,845: ============================================================
2022-05-11 13:56:03,845: Epoch 24/38 Batch 4200/7662 eta: 14:43:30.460881	Training Loss 0.0963 (0.0934)	Training Prec@1 100.000 (99.909)	Training Prec@5 100.000 (99.970)	
2022-05-11 13:56:03,846: ============================================================
2022-05-11 13:56:51,773: time cost, forward:0.18186899234206488, backward:0.10499352664552641, data cost:0.19065592499160855 
2022-05-11 13:56:51,774: ============================================================
2022-05-11 13:56:51,774: Epoch 24/38 Batch 4300/7662 eta: 14:43:43.621562	Training Loss 0.0900 (0.0935)	Training Prec@1 99.805 (99.909)	Training Prec@5 100.000 (99.970)	
2022-05-11 13:56:51,774: ============================================================
2022-05-11 13:57:39,678: time cost, forward:0.1818879988822755, backward:0.10499197040045362, data cost:0.19066764902434422 
2022-05-11 13:57:39,679: ============================================================
2022-05-11 13:57:39,679: Epoch 24/38 Batch 4400/7662 eta: 14:42:29.990679	Training Loss 0.1043 (0.0936)	Training Prec@1 100.000 (99.908)	Training Prec@5 100.000 (99.970)	
2022-05-11 13:57:39,679: ============================================================
2022-05-11 13:58:27,536: time cost, forward:0.1818959248757516, backward:0.1049929248091644, data cost:0.19067604781839947 
2022-05-11 13:58:27,536: ============================================================
2022-05-11 13:58:27,536: Epoch 24/38 Batch 4500/7662 eta: 14:40:49.387688	Training Loss 0.1017 (0.0936)	Training Prec@1 100.000 (99.908)	Training Prec@5 100.000 (99.969)	
2022-05-11 13:58:27,536: ============================================================
2022-05-11 13:59:15,380: time cost, forward:0.1819076839802861, backward:0.10499199672117522, data cost:0.19067859825918948 
2022-05-11 13:59:15,381: ============================================================
2022-05-11 13:59:15,381: Epoch 24/38 Batch 4600/7662 eta: 14:39:47.510023	Training Loss 0.0864 (0.0937)	Training Prec@1 100.000 (99.907)	Training Prec@5 100.000 (99.969)	
2022-05-11 13:59:15,381: ============================================================
2022-05-11 14:00:03,252: time cost, forward:0.18192193396016876, backward:0.1049912128582435, data cost:0.1906816060808421 
2022-05-11 14:00:03,252: ============================================================
2022-05-11 14:00:03,252: Epoch 24/38 Batch 4700/7662 eta: 14:39:28.819780	Training Loss 0.0959 (0.0938)	Training Prec@1 99.609 (99.906)	Training Prec@5 99.805 (99.969)	
2022-05-11 14:00:03,252: ============================================================
2022-05-11 14:00:51,117: time cost, forward:0.1819312335004606, backward:0.10499000400273743, data cost:0.19069028168972593 
2022-05-11 14:00:51,118: ============================================================
2022-05-11 14:00:51,118: Epoch 24/38 Batch 4800/7662 eta: 14:38:35.204613	Training Loss 0.0936 (0.0938)	Training Prec@1 99.805 (99.906)	Training Prec@5 99.805 (99.969)	
2022-05-11 14:00:51,118: ============================================================
2022-05-11 14:01:39,001: time cost, forward:0.18194260098881126, backward:0.10498831432238967, data cost:0.19069557833316303 
2022-05-11 14:01:39,001: ============================================================
2022-05-11 14:01:39,001: Epoch 24/38 Batch 4900/7662 eta: 14:38:06.301017	Training Loss 0.1059 (0.0939)	Training Prec@1 99.805 (99.906)	Training Prec@5 100.000 (99.968)	
2022-05-11 14:01:39,001: ============================================================
2022-05-11 14:02:26,928: time cost, forward:0.18195852748773936, backward:0.10499215202346805, data cost:0.1907012129240118 
2022-05-11 14:02:26,929: ============================================================
2022-05-11 14:02:26,929: Epoch 24/38 Batch 5000/7662 eta: 14:38:07.213322	Training Loss 0.0968 (0.0940)	Training Prec@1 99.805 (99.905)	Training Prec@5 100.000 (99.968)	
2022-05-11 14:02:26,929: ============================================================
2022-05-11 14:03:14,811: time cost, forward:0.1819686815770941, backward:0.10499562219349304, data cost:0.19070574063183068 
2022-05-11 14:03:14,811: ============================================================
2022-05-11 14:03:14,812: Epoch 24/38 Batch 5100/7662 eta: 14:36:30.134351	Training Loss 0.0949 (0.0940)	Training Prec@1 100.000 (99.905)	Training Prec@5 100.000 (99.968)	
2022-05-11 14:03:14,812: ============================================================
2022-05-11 14:04:02,665: time cost, forward:0.18197651605556553, backward:0.10499584658784714, data cost:0.19070721819071065 
2022-05-11 14:04:02,666: ============================================================
2022-05-11 14:04:02,666: Epoch 24/38 Batch 5200/7662 eta: 14:35:11.137214	Training Loss 0.0972 (0.0941)	Training Prec@1 100.000 (99.905)	Training Prec@5 100.000 (99.968)	
2022-05-11 14:04:02,666: ============================================================
2022-05-11 14:04:50,550: time cost, forward:0.18198598396285431, backward:0.1049969360544493, data cost:0.19071409917818102 
2022-05-11 14:04:50,550: ============================================================
2022-05-11 14:04:50,551: Epoch 24/38 Batch 5300/7662 eta: 14:34:56.519957	Training Loss 0.0951 (0.0942)	Training Prec@1 100.000 (99.905)	Training Prec@5 100.000 (99.968)	
2022-05-11 14:04:50,551: ============================================================
2022-05-11 14:05:38,462: time cost, forward:0.18199858358114335, backward:0.1049984935301943, data cost:0.19072152155596894 
2022-05-11 14:05:38,463: ============================================================
2022-05-11 14:05:38,463: Epoch 24/38 Batch 5400/7662 eta: 14:34:38.736040	Training Loss 0.0913 (0.0942)	Training Prec@1 100.000 (99.905)	Training Prec@5 100.000 (99.968)	
2022-05-11 14:05:38,463: ============================================================
2022-05-11 14:06:26,362: time cost, forward:0.1819998354754853, backward:0.10499983957668373, data cost:0.19073317596794886 
2022-05-11 14:06:26,362: ============================================================
2022-05-11 14:06:26,362: Epoch 24/38 Batch 5500/7662 eta: 14:33:36.822674	Training Loss 0.0902 (0.0943)	Training Prec@1 100.000 (99.904)	Training Prec@5 100.000 (99.968)	
2022-05-11 14:06:26,362: ============================================================
2022-05-11 14:07:14,284: time cost, forward:0.18200837626885594, backward:0.10500129445745894, data cost:0.19074508917717065 
2022-05-11 14:07:14,284: ============================================================
2022-05-11 14:07:14,284: Epoch 24/38 Batch 5600/7662 eta: 14:33:13.508948	Training Loss 0.0987 (0.0943)	Training Prec@1 100.000 (99.904)	Training Prec@5 100.000 (99.968)	
2022-05-11 14:07:14,284: ============================================================
2022-05-11 14:08:02,183: time cost, forward:0.18201974354871303, backward:0.1050053012226732, data cost:0.19074720904625891 
2022-05-11 14:08:02,183: ============================================================
2022-05-11 14:08:02,183: Epoch 24/38 Batch 5700/7662 eta: 14:32:00.822509	Training Loss 0.0977 (0.0944)	Training Prec@1 99.805 (99.903)	Training Prec@5 100.000 (99.967)	
2022-05-11 14:08:02,184: ============================================================
2022-05-11 14:08:50,108: time cost, forward:0.18203307049174539, backward:0.10500861953344606, data cost:0.19075182944171323 
2022-05-11 14:08:50,109: ============================================================
2022-05-11 14:08:50,109: Epoch 24/38 Batch 5800/7662 eta: 14:31:41.314783	Training Loss 0.0970 (0.0945)	Training Prec@1 99.805 (99.903)	Training Prec@5 100.000 (99.967)	
2022-05-11 14:08:50,109: ============================================================
2022-05-11 14:09:37,932: time cost, forward:0.1820381798366709, backward:0.10500890369192183, data cost:0.19074983361576103 
2022-05-11 14:09:37,933: ============================================================
2022-05-11 14:09:37,933: Epoch 24/38 Batch 5900/7662 eta: 14:29:03.135822	Training Loss 0.0970 (0.0945)	Training Prec@1 100.000 (99.902)	Training Prec@5 100.000 (99.967)	
2022-05-11 14:09:37,933: ============================================================
2022-05-11 14:10:25,769: time cost, forward:0.18204653368411133, backward:0.10500925015282445, data cost:0.19074658374624226 
2022-05-11 14:10:25,770: ============================================================
2022-05-11 14:10:25,770: Epoch 24/38 Batch 6000/7662 eta: 14:28:29.327548	Training Loss 0.0946 (0.0946)	Training Prec@1 100.000 (99.902)	Training Prec@5 100.000 (99.967)	
2022-05-11 14:10:25,770: ============================================================
2022-05-11 14:11:13,650: time cost, forward:0.18205405860909635, backward:0.10501046039214153, data cost:0.19074823931018375 
2022-05-11 14:11:13,650: ============================================================
2022-05-11 14:11:13,651: Epoch 24/38 Batch 6100/7662 eta: 14:28:29.028391	Training Loss 0.0989 (0.0947)	Training Prec@1 100.000 (99.901)	Training Prec@5 100.000 (99.967)	
2022-05-11 14:11:13,651: ============================================================
2022-05-11 14:12:01,550: time cost, forward:0.1820622458152568, backward:0.10500976431271707, data cost:0.19075002499522076 
2022-05-11 14:12:01,550: ============================================================
2022-05-11 14:12:01,550: Epoch 24/38 Batch 6200/7662 eta: 14:28:01.709182	Training Loss 0.0957 (0.0947)	Training Prec@1 99.805 (99.901)	Training Prec@5 100.000 (99.967)	
2022-05-11 14:12:01,550: ============================================================
2022-05-11 14:12:49,460: time cost, forward:0.18207481963840016, backward:0.10501154647363256, data cost:0.19075028645384784 
2022-05-11 14:12:49,460: ============================================================
2022-05-11 14:12:49,460: Epoch 24/38 Batch 6300/7662 eta: 14:27:25.280541	Training Loss 0.0960 (0.0947)	Training Prec@1 100.000 (99.901)	Training Prec@5 100.000 (99.967)	
2022-05-11 14:12:49,460: ============================================================
2022-05-11 14:13:37,324: time cost, forward:0.1820828076321029, backward:0.10501301566182235, data cost:0.19074764298654978 
2022-05-11 14:13:37,324: ============================================================
2022-05-11 14:13:37,325: Epoch 24/38 Batch 6400/7662 eta: 14:25:47.619490	Training Loss 0.0959 (0.0948)	Training Prec@1 99.805 (99.900)	Training Prec@5 100.000 (99.967)	
2022-05-11 14:13:37,325: ============================================================
2022-05-11 14:14:25,164: time cost, forward:0.18208767293251227, backward:0.10501116667367583, data cost:0.190747084113557 
2022-05-11 14:14:25,164: ============================================================
2022-05-11 14:14:25,165: Epoch 24/38 Batch 6500/7662 eta: 14:24:33.322316	Training Loss 0.1028 (0.0949)	Training Prec@1 99.414 (99.899)	Training Prec@5 100.000 (99.967)	
2022-05-11 14:14:25,165: ============================================================
2022-05-11 14:15:13,033: time cost, forward:0.1820961853503675, backward:0.10501146009427559, data cost:0.19074724930527537 
2022-05-11 14:15:13,034: ============================================================
2022-05-11 14:15:13,034: Epoch 24/38 Batch 6600/7662 eta: 14:24:17.199056	Training Loss 0.0972 (0.0949)	Training Prec@1 100.000 (99.899)	Training Prec@5 100.000 (99.967)	
2022-05-11 14:15:13,034: ============================================================
2022-05-11 14:16:00,882: time cost, forward:0.18210063651170744, backward:0.10501229163336565, data cost:0.19074725051267163 
2022-05-11 14:16:00,882: ============================================================
2022-05-11 14:16:00,882: Epoch 24/38 Batch 6700/7662 eta: 14:23:07.035200	Training Loss 0.0948 (0.0950)	Training Prec@1 100.000 (99.899)	Training Prec@5 100.000 (99.966)	
2022-05-11 14:16:00,883: ============================================================
2022-05-11 14:16:48,692: time cost, forward:0.18210071650545884, backward:0.10501389882900834, data cost:0.19074516367221478 
2022-05-11 14:16:48,692: ============================================================
2022-05-11 14:16:48,692: Epoch 24/38 Batch 6800/7662 eta: 14:21:37.332041	Training Loss 0.1019 (0.0950)	Training Prec@1 100.000 (99.898)	Training Prec@5 100.000 (99.966)	
2022-05-11 14:16:48,692: ============================================================
2022-05-11 14:17:36,578: time cost, forward:0.18210957018875318, backward:0.10501649380075809, data cost:0.19074417090205148 
2022-05-11 14:17:36,578: ============================================================
2022-05-11 14:17:36,578: Epoch 24/38 Batch 6900/7662 eta: 14:22:11.350843	Training Loss 0.0984 (0.0951)	Training Prec@1 99.609 (99.898)	Training Prec@5 100.000 (99.966)	
2022-05-11 14:17:36,578: ============================================================
2022-05-11 14:18:24,421: time cost, forward:0.18211625293078193, backward:0.10501756527063114, data cost:0.1907390210437407 
2022-05-11 14:18:24,421: ============================================================
2022-05-11 14:18:24,421: Epoch 24/38 Batch 7000/7662 eta: 14:20:37.918469	Training Loss 0.0984 (0.0951)	Training Prec@1 99.805 (99.898)	Training Prec@5 99.805 (99.966)	
2022-05-11 14:18:24,422: ============================================================
2022-05-11 14:19:12,154: time cost, forward:0.18211644329576698, backward:0.10501620372864105, data cost:0.19072861214022616 
2022-05-11 14:19:12,155: ============================================================
2022-05-11 14:19:12,155: Epoch 24/38 Batch 7100/7662 eta: 14:17:51.472083	Training Loss 0.0948 (0.0952)	Training Prec@1 99.805 (99.898)	Training Prec@5 100.000 (99.966)	
2022-05-11 14:19:12,155: ============================================================
2022-05-11 14:19:59,951: time cost, forward:0.182123240074659, backward:0.10501611866972847, data cost:0.19071925694883854 
2022-05-11 14:19:59,951: ============================================================
2022-05-11 14:19:59,951: Epoch 24/38 Batch 7200/7662 eta: 14:18:11.313474	Training Loss 0.1011 (0.0953)	Training Prec@1 100.000 (99.898)	Training Prec@5 100.000 (99.966)	
2022-05-11 14:19:59,951: ============================================================
2022-05-11 14:20:47,749: time cost, forward:0.18213034139984127, backward:0.10501498734400622, data cost:0.19070966378648505 
2022-05-11 14:20:47,749: ============================================================
2022-05-11 14:20:47,749: Epoch 24/38 Batch 7300/7662 eta: 14:17:25.611497	Training Loss 0.1018 (0.0953)	Training Prec@1 100.000 (99.897)	Training Prec@5 100.000 (99.966)	
2022-05-11 14:20:47,749: ============================================================
2022-05-11 14:21:35,511: time cost, forward:0.1821307564993326, backward:0.1050129175862842, data cost:0.1907039826778902 
2022-05-11 14:21:35,512: ============================================================
2022-05-11 14:21:35,512: Epoch 24/38 Batch 7400/7662 eta: 14:15:59.433422	Training Loss 0.0984 (0.0954)	Training Prec@1 100.000 (99.897)	Training Prec@5 100.000 (99.966)	
2022-05-11 14:21:35,512: ============================================================
2022-05-11 14:22:23,229: time cost, forward:0.18213233265467907, backward:0.10501060140563705, data cost:0.19069044894259013 
2022-05-11 14:22:23,229: ============================================================
2022-05-11 14:22:23,230: Epoch 24/38 Batch 7500/7662 eta: 14:14:23.762377	Training Loss 0.0969 (0.0954)	Training Prec@1 100.000 (99.897)	Training Prec@5 100.000 (99.966)	
2022-05-11 14:22:23,230: ============================================================
2022-05-11 14:23:10,962: time cost, forward:0.18213586101941112, backward:0.1050088436356625, data cost:0.1906771828021042 
2022-05-11 14:23:10,962: ============================================================
2022-05-11 14:23:10,963: Epoch 24/38 Batch 7600/7662 eta: 14:13:52.406841	Training Loss 0.0977 (0.0955)	Training Prec@1 100.000 (99.896)	Training Prec@5 100.000 (99.966)	
2022-05-11 14:23:10,963: ============================================================
2022-05-11 14:23:42,614: Epoch: 24/38 eta: 14:13:22.334991	Training Loss 0.0977 (0.0955)	Training Prec@1 99.805 (99.896)	Training Prec@5 100.000 (99.966)
2022-05-11 14:23:42,614: ============================================================
2022-05-11 14:24:31,395: time cost, forward:0.17907575886658947, backward:0.10471704993585143, data cost:0.20673161564451276 
2022-05-11 14:24:31,396: ============================================================
2022-05-11 14:24:31,396: Epoch 25/38 Batch 100/7662 eta: 14:31:15.476232	Training Loss 0.0885 (0.0876)	Training Prec@1 100.000 (99.925)	Training Prec@5 100.000 (99.978)	
2022-05-11 14:24:31,396: ============================================================
2022-05-11 14:25:18,309: time cost, forward:0.1767326743159462, backward:0.10473101821976091, data cost:0.19818502814326455 
2022-05-11 14:25:18,309: ============================================================
2022-05-11 14:25:18,309: Epoch 25/38 Batch 200/7662 eta: 13:57:09.462094	Training Loss 0.0814 (0.0877)	Training Prec@1 99.805 (99.927)	Training Prec@5 99.805 (99.975)	
2022-05-11 14:25:18,309: ============================================================
2022-05-11 14:26:05,163: time cost, forward:0.17568169788373353, backward:0.10477528603977981, data cost:0.1953855573532972 
2022-05-11 14:26:05,163: ============================================================
2022-05-11 14:26:05,163: Epoch 25/38 Batch 300/7662 eta: 13:55:19.283667	Training Loss 0.0926 (0.0877)	Training Prec@1 100.000 (99.930)	Training Prec@5 100.000 (99.977)	
2022-05-11 14:26:05,163: ============================================================
2022-05-11 14:26:52,110: time cost, forward:0.17526917828055552, backward:0.10482216299625866, data cost:0.1940604068880392 
2022-05-11 14:26:52,111: ============================================================
2022-05-11 14:26:52,111: Epoch 25/38 Batch 400/7662 eta: 13:56:12.635125	Training Loss 0.0864 (0.0878)	Training Prec@1 100.000 (99.930)	Training Prec@5 100.000 (99.977)	
2022-05-11 14:26:52,111: ============================================================
2022-05-11 14:27:39,189: time cost, forward:0.17519076075964796, backward:0.10485802241461072, data cost:0.19334895434026012 
2022-05-11 14:27:39,189: ============================================================
2022-05-11 14:27:39,190: Epoch 25/38 Batch 500/7662 eta: 13:57:45.124312	Training Loss 0.0935 (0.0879)	Training Prec@1 100.000 (99.927)	Training Prec@5 100.000 (99.978)	
2022-05-11 14:27:39,190: ============================================================
2022-05-11 14:28:26,282: time cost, forward:0.17513443671403225, backward:0.10491022920369704, data cost:0.19289766488369797 
2022-05-11 14:28:26,283: ============================================================
2022-05-11 14:28:26,283: Epoch 25/38 Batch 600/7662 eta: 13:57:13.995014	Training Loss 0.0847 (0.0880)	Training Prec@1 99.805 (99.925)	Training Prec@5 99.805 (99.977)	
2022-05-11 14:28:26,283: ============================================================
2022-05-11 14:29:13,135: time cost, forward:0.17474686809534337, backward:0.10505352545534934, data cost:0.19246979264571773 
2022-05-11 14:29:13,136: ============================================================
2022-05-11 14:29:13,136: Epoch 25/38 Batch 700/7662 eta: 13:52:11.181290	Training Loss 0.0939 (0.0881)	Training Prec@1 100.000 (99.924)	Training Prec@5 100.000 (99.977)	
2022-05-11 14:29:13,137: ============================================================
2022-05-11 14:29:59,936: time cost, forward:0.1743486052908199, backward:0.10519885658770241, data cost:0.1921576609151981 
2022-05-11 14:29:59,936: ============================================================
2022-05-11 14:29:59,937: Epoch 25/38 Batch 800/7662 eta: 13:50:27.883881	Training Loss 0.0912 (0.0881)	Training Prec@1 99.805 (99.926)	Training Prec@5 99.805 (99.977)	
2022-05-11 14:29:59,937: ============================================================
2022-05-11 14:30:46,750: time cost, forward:0.17407836452607187, backward:0.10531736056717139, data cost:0.1918825424287688 
2022-05-11 14:30:46,750: ============================================================
2022-05-11 14:30:46,750: Epoch 25/38 Batch 900/7662 eta: 13:49:55.223935	Training Loss 0.0892 (0.0881)	Training Prec@1 100.000 (99.928)	Training Prec@5 100.000 (99.976)	
2022-05-11 14:30:46,750: ============================================================
2022-05-11 14:31:33,547: time cost, forward:0.17383238980481336, backward:0.10540907781522672, data cost:0.19167931254084283 
2022-05-11 14:31:33,548: ============================================================
2022-05-11 14:31:33,548: Epoch 25/38 Batch 1000/7662 eta: 13:48:51.224269	Training Loss 0.0830 (0.0882)	Training Prec@1 100.000 (99.929)	Training Prec@5 100.000 (99.977)	
2022-05-11 14:31:33,548: ============================================================
2022-05-11 14:32:20,351: time cost, forward:0.1736318576975884, backward:0.10549060011907964, data cost:0.19149925081810157 
2022-05-11 14:32:20,351: ============================================================
2022-05-11 14:32:20,351: Epoch 25/38 Batch 1100/7662 eta: 13:48:10.747604	Training Loss 0.0940 (0.0883)	Training Prec@1 99.805 (99.929)	Training Prec@5 100.000 (99.976)	
2022-05-11 14:32:20,351: ============================================================
2022-05-11 14:33:07,135: time cost, forward:0.1734620413251277, backward:0.10556164137814023, data cost:0.1913441617455057 
2022-05-11 14:33:07,136: ============================================================
2022-05-11 14:33:07,136: Epoch 25/38 Batch 1200/7662 eta: 13:47:03.980660	Training Loss 0.0890 (0.0884)	Training Prec@1 99.609 (99.928)	Training Prec@5 100.000 (99.975)	
2022-05-11 14:33:07,136: ============================================================
2022-05-11 14:33:53,930: time cost, forward:0.1733161331232554, backward:0.10562808665979634, data cost:0.19121684488468302 
2022-05-11 14:33:53,931: ============================================================
2022-05-11 14:33:53,931: Epoch 25/38 Batch 1300/7662 eta: 13:46:28.114299	Training Loss 0.0961 (0.0885)	Training Prec@1 99.805 (99.929)	Training Prec@5 100.000 (99.976)	
2022-05-11 14:33:53,931: ============================================================
2022-05-11 14:34:40,557: time cost, forward:0.17307013098557902, backward:0.10568462805376469, data cost:0.1911083729970958 
2022-05-11 14:34:40,558: ============================================================
2022-05-11 14:34:40,558: Epoch 25/38 Batch 1400/7662 eta: 13:42:43.652566	Training Loss 0.0907 (0.0887)	Training Prec@1 100.000 (99.929)	Training Prec@5 100.000 (99.976)	
2022-05-11 14:34:40,558: ============================================================
2022-05-11 14:35:27,244: time cost, forward:0.1728971004486084, backward:0.10572568729291207, data cost:0.1910210438296348 
2022-05-11 14:35:27,244: ============================================================
2022-05-11 14:35:27,244: Epoch 25/38 Batch 1500/7662 eta: 13:42:59.621341	Training Loss 0.0843 (0.0888)	Training Prec@1 99.805 (99.929)	Training Prec@5 99.805 (99.976)	
2022-05-11 14:35:27,244: ============================================================
2022-05-11 14:36:13,949: time cost, forward:0.17274619520567894, backward:0.1057713349362028, data cost:0.19094821286991734 
2022-05-11 14:36:13,949: ============================================================
2022-05-11 14:36:13,950: Epoch 25/38 Batch 1600/7662 eta: 13:42:33.053283	Training Loss 0.0923 (0.0889)	Training Prec@1 100.000 (99.929)	Training Prec@5 100.000 (99.976)	
2022-05-11 14:36:13,950: ============================================================
2022-05-11 14:37:00,477: time cost, forward:0.17261862530295746, backward:0.10572523043533155, data cost:0.19086077972465995 
2022-05-11 14:37:00,477: ============================================================
2022-05-11 14:37:00,477: Epoch 25/38 Batch 1700/7662 eta: 13:38:39.027908	Training Loss 0.0824 (0.0890)	Training Prec@1 100.000 (99.928)	Training Prec@5 100.000 (99.976)	
2022-05-11 14:37:00,477: ============================================================
2022-05-11 14:37:47,012: time cost, forward:0.1725078247996951, backward:0.10568697085441517, data cost:0.19078121296626585 
2022-05-11 14:37:47,012: ============================================================
2022-05-11 14:37:47,012: Epoch 25/38 Batch 1800/7662 eta: 13:37:59.631861	Training Loss 0.0918 (0.0891)	Training Prec@1 99.805 (99.927)	Training Prec@5 99.805 (99.975)	
2022-05-11 14:37:47,012: ============================================================
2022-05-11 14:38:33,592: time cost, forward:0.1724267147791392, backward:0.1056557886847827, data cost:0.19071265356737793 
2022-05-11 14:38:33,592: ============================================================
2022-05-11 14:38:33,593: Epoch 25/38 Batch 1900/7662 eta: 13:38:01.520729	Training Loss 0.0925 (0.0892)	Training Prec@1 100.000 (99.928)	Training Prec@5 100.000 (99.976)	
2022-05-11 14:38:33,593: ============================================================
2022-05-11 14:39:20,153: time cost, forward:0.17235097508242037, backward:0.10562142781939371, data cost:0.19064979806072777 
2022-05-11 14:39:20,154: ============================================================
2022-05-11 14:39:20,154: Epoch 25/38 Batch 2000/7662 eta: 13:36:54.313510	Training Loss 0.0964 (0.0893)	Training Prec@1 99.609 (99.928)	Training Prec@5 100.000 (99.976)	
2022-05-11 14:39:20,154: ============================================================
2022-05-11 14:40:06,702: time cost, forward:0.17227675620574734, backward:0.10558910458470709, data cost:0.19059375764756842 
2022-05-11 14:40:06,702: ============================================================
2022-05-11 14:40:06,702: Epoch 25/38 Batch 2100/7662 eta: 13:35:54.587265	Training Loss 0.0873 (0.0894)	Training Prec@1 100.000 (99.927)	Training Prec@5 100.000 (99.975)	
2022-05-11 14:40:06,702: ============================================================
2022-05-11 14:40:53,263: time cost, forward:0.1722117769224853, backward:0.10556430066374553, data cost:0.19054227744844515 
2022-05-11 14:40:53,263: ============================================================
2022-05-11 14:40:53,263: Epoch 25/38 Batch 2200/7662 eta: 13:35:21.162424	Training Loss 0.0938 (0.0895)	Training Prec@1 100.000 (99.927)	Training Prec@5 100.000 (99.975)	
2022-05-11 14:40:53,263: ============================================================
2022-05-11 14:41:39,901: time cost, forward:0.1721570664978691, backward:0.105542939660237, data cost:0.19051813094083928 
2022-05-11 14:41:39,901: ============================================================
2022-05-11 14:41:39,902: Epoch 25/38 Batch 2300/7662 eta: 13:35:55.844659	Training Loss 0.0971 (0.0896)	Training Prec@1 100.000 (99.926)	Training Prec@5 100.000 (99.975)	
2022-05-11 14:41:39,902: ============================================================
2022-05-11 14:42:26,549: time cost, forward:0.17212064229433316, backward:0.10552919969403679, data cost:0.19048469590365563 
2022-05-11 14:42:26,549: ============================================================
2022-05-11 14:42:26,549: Epoch 25/38 Batch 2400/7662 eta: 13:35:19.169609	Training Loss 0.0875 (0.0897)	Training Prec@1 99.805 (99.926)	Training Prec@5 100.000 (99.975)	
2022-05-11 14:42:26,550: ============================================================
2022-05-11 14:43:13,213: time cost, forward:0.17208628933064316, backward:0.10551313678471266, data cost:0.1904650612228534 
2022-05-11 14:43:13,213: ============================================================
2022-05-11 14:43:13,213: Epoch 25/38 Batch 2500/7662 eta: 13:34:48.955077	Training Loss 0.0947 (0.0898)	Training Prec@1 100.000 (99.926)	Training Prec@5 100.000 (99.975)	
2022-05-11 14:43:13,213: ============================================================
2022-05-11 14:43:59,903: time cost, forward:0.17205317536882825, backward:0.10549653223176422, data cost:0.19045607508857143 
2022-05-11 14:43:59,904: ============================================================
2022-05-11 14:43:59,904: Epoch 25/38 Batch 2600/7662 eta: 13:34:30.793401	Training Loss 0.0966 (0.0899)	Training Prec@1 100.000 (99.925)	Training Prec@5 100.000 (99.975)	
2022-05-11 14:43:59,904: ============================================================
2022-05-11 14:44:46,601: time cost, forward:0.17203447508697114, backward:0.10547930569770646, data cost:0.19044398068940036 
2022-05-11 14:44:46,601: ============================================================
2022-05-11 14:44:46,601: Epoch 25/38 Batch 2700/7662 eta: 13:33:51.008043	Training Loss 0.0960 (0.0899)	Training Prec@1 99.805 (99.925)	Training Prec@5 100.000 (99.975)	
2022-05-11 14:44:46,601: ============================================================
2022-05-11 14:45:33,316: time cost, forward:0.17200571948096086, backward:0.10546176541741722, data cost:0.1904481208592749 
2022-05-11 14:45:33,316: ============================================================
2022-05-11 14:45:33,317: Epoch 25/38 Batch 2800/7662 eta: 13:33:23.077581	Training Loss 0.0943 (0.0900)	Training Prec@1 100.000 (99.924)	Training Prec@5 100.000 (99.975)	
2022-05-11 14:45:33,317: ============================================================
2022-05-11 14:46:20,013: time cost, forward:0.17198454729233498, backward:0.1054444604184801, data cost:0.19044114746443772 
2022-05-11 14:46:20,013: ============================================================
2022-05-11 14:46:20,014: Epoch 25/38 Batch 2900/7662 eta: 13:32:17.268350	Training Loss 0.0986 (0.0901)	Training Prec@1 99.805 (99.924)	Training Prec@5 100.000 (99.974)	
2022-05-11 14:46:20,014: ============================================================
2022-05-11 14:47:06,698: time cost, forward:0.17195824314332397, backward:0.10543041731683998, data cost:0.19043091878607973 
2022-05-11 14:47:06,698: ============================================================
2022-05-11 14:47:06,698: Epoch 25/38 Batch 3000/7662 eta: 13:31:17.508516	Training Loss 0.0919 (0.0902)	Training Prec@1 99.805 (99.923)	Training Prec@5 100.000 (99.974)	
2022-05-11 14:47:06,698: ============================================================
2022-05-11 14:47:53,458: time cost, forward:0.17195317105886898, backward:0.10541677136465825, data cost:0.19043148937206877 
2022-05-11 14:47:53,458: ============================================================
2022-05-11 14:47:53,459: Epoch 25/38 Batch 3100/7662 eta: 13:31:49.710499	Training Loss 0.0892 (0.0903)	Training Prec@1 100.000 (99.923)	Training Prec@5 100.000 (99.974)	
2022-05-11 14:47:53,459: ============================================================
2022-05-11 14:48:40,221: time cost, forward:0.17194886817228575, backward:0.10540259454577519, data cost:0.19043663390989266 
2022-05-11 14:48:40,222: ============================================================
2022-05-11 14:48:40,222: Epoch 25/38 Batch 3200/7662 eta: 13:31:06.000361	Training Loss 0.0891 (0.0904)	Training Prec@1 100.000 (99.922)	Training Prec@5 100.000 (99.974)	
2022-05-11 14:48:40,222: ============================================================
2022-05-11 14:49:26,980: time cost, forward:0.17194671759499894, backward:0.10538696982564981, data cost:0.19044032751628578 
2022-05-11 14:49:26,981: ============================================================
2022-05-11 14:49:26,981: Epoch 25/38 Batch 3300/7662 eta: 13:30:14.887085	Training Loss 0.0875 (0.0905)	Training Prec@1 100.000 (99.921)	Training Prec@5 100.000 (99.974)	
2022-05-11 14:49:26,981: ============================================================
2022-05-11 14:50:13,760: time cost, forward:0.1719464024013195, backward:0.10537378701717583, data cost:0.19044338516994025 
2022-05-11 14:50:13,760: ============================================================
2022-05-11 14:50:13,760: Epoch 25/38 Batch 3400/7662 eta: 13:29:49.566270	Training Loss 0.0978 (0.0906)	Training Prec@1 99.609 (99.920)	Training Prec@5 99.805 (99.974)	
2022-05-11 14:50:13,760: ============================================================
2022-05-11 14:51:00,529: time cost, forward:0.1719499033633284, backward:0.10536236264222552, data cost:0.19044168099705647 
2022-05-11 14:51:00,529: ============================================================
2022-05-11 14:51:00,530: Epoch 25/38 Batch 3500/7662 eta: 13:28:51.920105	Training Loss 0.0971 (0.0907)	Training Prec@1 99.609 (99.920)	Training Prec@5 99.805 (99.973)	
2022-05-11 14:51:00,530: ============================================================
2022-05-11 14:51:47,323: time cost, forward:0.17195390224059312, backward:0.10535034447055487, data cost:0.19044450098489782 
2022-05-11 14:51:47,324: ============================================================
2022-05-11 14:51:47,324: Epoch 25/38 Batch 3600/7662 eta: 13:28:31.134752	Training Loss 0.0982 (0.0907)	Training Prec@1 99.805 (99.920)	Training Prec@5 100.000 (99.973)	
2022-05-11 14:51:47,324: ============================================================
2022-05-11 14:52:34,141: time cost, forward:0.17196222207584264, backward:0.10533621253822906, data cost:0.19045435612057957 
2022-05-11 14:52:34,141: ============================================================
2022-05-11 14:52:34,141: Epoch 25/38 Batch 3700/7662 eta: 13:28:08.447066	Training Loss 0.0934 (0.0908)	Training Prec@1 100.000 (99.919)	Training Prec@5 100.000 (99.973)	
2022-05-11 14:52:34,141: ============================================================
2022-05-11 14:53:20,943: time cost, forward:0.17197148044914531, backward:0.10532389474122203, data cost:0.19045760475293244 
2022-05-11 14:53:20,943: ============================================================
2022-05-11 14:53:20,944: Epoch 25/38 Batch 3800/7662 eta: 13:27:05.802936	Training Loss 0.0939 (0.0909)	Training Prec@1 99.805 (99.919)	Training Prec@5 100.000 (99.973)	
2022-05-11 14:53:20,944: ============================================================
2022-05-11 14:54:07,756: time cost, forward:0.17196974885191604, backward:0.1053103401465855, data cost:0.19047549364657915 
2022-05-11 14:54:07,756: ============================================================
2022-05-11 14:54:07,757: Epoch 25/38 Batch 3900/7662 eta: 13:26:30.061173	Training Loss 0.1030 (0.0910)	Training Prec@1 99.805 (99.918)	Training Prec@5 100.000 (99.973)	
2022-05-11 14:54:07,757: ============================================================
2022-05-11 14:54:54,544: time cost, forward:0.17196324677072664, backward:0.10529228769919073, data cost:0.19049166392970007 
2022-05-11 14:54:54,544: ============================================================
2022-05-11 14:54:54,544: Epoch 25/38 Batch 4000/7662 eta: 13:25:17.347179	Training Loss 0.0965 (0.0911)	Training Prec@1 100.000 (99.918)	Training Prec@5 100.000 (99.973)	
2022-05-11 14:54:54,544: ============================================================
2022-05-11 14:55:41,282: time cost, forward:0.17196145712616792, backward:0.10527885992604367, data cost:0.19049375247420203 
2022-05-11 14:55:41,283: ============================================================
2022-05-11 14:55:41,283: Epoch 25/38 Batch 4100/7662 eta: 13:23:39.513805	Training Loss 0.0975 (0.0912)	Training Prec@1 99.414 (99.917)	Training Prec@5 99.609 (99.973)	
2022-05-11 14:55:41,283: ============================================================
2022-05-11 14:56:28,058: time cost, forward:0.17196757187585543, backward:0.1052656136799154, data cost:0.19049271778652685 
2022-05-11 14:56:28,058: ============================================================
2022-05-11 14:56:28,059: Epoch 25/38 Batch 4200/7662 eta: 13:23:31.343639	Training Loss 0.0989 (0.0912)	Training Prec@1 99.805 (99.917)	Training Prec@5 99.805 (99.973)	
2022-05-11 14:56:28,059: ============================================================
2022-05-11 14:57:14,843: time cost, forward:0.17197231864840465, backward:0.10525330456780067, data cost:0.19049686796583667 
2022-05-11 14:57:14,843: ============================================================
2022-05-11 14:57:14,843: Epoch 25/38 Batch 4300/7662 eta: 13:22:53.677511	Training Loss 0.0921 (0.0913)	Training Prec@1 100.000 (99.917)	Training Prec@5 100.000 (99.973)	
2022-05-11 14:57:14,843: ============================================================
2022-05-11 14:58:01,606: time cost, forward:0.17198145413946145, backward:0.10524309665188245, data cost:0.190488712330736 
2022-05-11 14:58:01,606: ============================================================
2022-05-11 14:58:01,607: Epoch 25/38 Batch 4400/7662 eta: 13:21:44.991257	Training Loss 0.0961 (0.0914)	Training Prec@1 100.000 (99.916)	Training Prec@5 100.000 (99.973)	
2022-05-11 14:58:01,607: ============================================================
2022-05-11 14:58:48,404: time cost, forward:0.1719841319048344, backward:0.10523511584956637, data cost:0.19049481117187486 
2022-05-11 14:58:48,404: ============================================================
2022-05-11 14:58:48,404: Epoch 25/38 Batch 4500/7662 eta: 13:21:33.556907	Training Loss 0.0912 (0.0915)	Training Prec@1 99.805 (99.915)	Training Prec@5 99.805 (99.972)	
2022-05-11 14:58:48,404: ============================================================
2022-05-11 14:59:35,171: time cost, forward:0.17198795908351233, backward:0.10522421843903457, data cost:0.19049524576618868 
2022-05-11 14:59:35,171: ============================================================
2022-05-11 14:59:35,171: Epoch 25/38 Batch 4600/7662 eta: 13:20:15.223428	Training Loss 0.1005 (0.0915)	Training Prec@1 99.609 (99.915)	Training Prec@5 100.000 (99.972)	
2022-05-11 14:59:35,171: ============================================================
2022-05-11 15:00:22,008: time cost, forward:0.17199306458608982, backward:0.10522915429575795, data cost:0.19049365932978476 
2022-05-11 15:00:22,008: ============================================================
2022-05-11 15:00:22,009: Epoch 25/38 Batch 4700/7662 eta: 13:20:40.514353	Training Loss 0.0944 (0.0916)	Training Prec@1 100.000 (99.915)	Training Prec@5 100.000 (99.972)	
2022-05-11 15:00:22,009: ============================================================
2022-05-11 15:01:08,976: time cost, forward:0.17200182084864343, backward:0.10525714032077173, data cost:0.19049237042224565 
2022-05-11 15:01:08,977: ============================================================
2022-05-11 15:01:08,977: Epoch 25/38 Batch 4800/7662 eta: 13:22:07.841405	Training Loss 0.1009 (0.0917)	Training Prec@1 100.000 (99.915)	Training Prec@5 100.000 (99.972)	
2022-05-11 15:01:08,977: ============================================================
2022-05-11 15:01:55,760: time cost, forward:0.17200247573229605, backward:0.10525827267676574, data cost:0.19048430506466213 
2022-05-11 15:01:55,760: ============================================================
2022-05-11 15:01:55,760: Epoch 25/38 Batch 4900/7662 eta: 13:18:11.908459	Training Loss 0.1021 (0.0918)	Training Prec@1 100.000 (99.915)	Training Prec@5 100.000 (99.972)	
2022-05-11 15:01:55,760: ============================================================
2022-05-11 15:02:42,489: time cost, forward:0.1720033032962336, backward:0.1052496383657072, data cost:0.19047751687101946 
2022-05-11 15:02:42,489: ============================================================
2022-05-11 15:02:42,490: Epoch 25/38 Batch 5000/7662 eta: 13:16:29.464950	Training Loss 0.0927 (0.0918)	Training Prec@1 99.805 (99.915)	Training Prec@5 100.000 (99.972)	
2022-05-11 15:02:42,490: ============================================================
2022-05-11 15:03:29,209: time cost, forward:0.17200424007678364, backward:0.10523936098102121, data cost:0.19047116265387645 
2022-05-11 15:03:29,209: ============================================================
2022-05-11 15:03:29,209: Epoch 25/38 Batch 5100/7662 eta: 13:15:32.767829	Training Loss 0.0921 (0.0919)	Training Prec@1 99.805 (99.915)	Training Prec@5 100.000 (99.972)	
2022-05-11 15:03:29,209: ============================================================
2022-05-11 15:04:15,920: time cost, forward:0.172004990450211, backward:0.10522887761328262, data cost:0.19046209880676973 
2022-05-11 15:04:15,920: ============================================================
2022-05-11 15:04:15,921: Epoch 25/38 Batch 5200/7662 eta: 13:14:37.942612	Training Loss 0.0928 (0.0920)	Training Prec@1 100.000 (99.914)	Training Prec@5 100.000 (99.972)	
2022-05-11 15:04:15,921: ============================================================
2022-05-11 15:05:02,619: time cost, forward:0.17200576217472835, backward:0.1052207591781573, data cost:0.1904490550614051 
2022-05-11 15:05:02,619: ============================================================
2022-05-11 15:05:02,619: Epoch 25/38 Batch 5300/7662 eta: 13:13:38.089897	Training Loss 0.1003 (0.0921)	Training Prec@1 99.805 (99.914)	Training Prec@5 99.805 (99.972)	
2022-05-11 15:05:02,619: ============================================================
2022-05-11 15:05:49,313: time cost, forward:0.17200371136729817, backward:0.1052117542903453, data cost:0.19044142450352777 
2022-05-11 15:05:49,313: ============================================================
2022-05-11 15:05:49,314: Epoch 25/38 Batch 5400/7662 eta: 13:12:47.261948	Training Loss 0.0900 (0.0921)	Training Prec@1 100.000 (99.914)	Training Prec@5 100.000 (99.972)	
2022-05-11 15:05:49,314: ============================================================
2022-05-11 15:06:36,128: time cost, forward:0.17200918322499176, backward:0.10521677360250248, data cost:0.19043286415983882 
2022-05-11 15:06:36,128: ============================================================
2022-05-11 15:06:36,128: Epoch 25/38 Batch 5500/7662 eta: 13:14:02.926661	Training Loss 0.0974 (0.0922)	Training Prec@1 99.805 (99.914)	Training Prec@5 100.000 (99.972)	
2022-05-11 15:06:36,129: ============================================================
2022-05-11 15:07:22,996: time cost, forward:0.17201810394957526, backward:0.10522727200677937, data cost:0.19042743093351272 
2022-05-11 15:07:22,996: ============================================================
2022-05-11 15:07:22,996: Epoch 25/38 Batch 5600/7662 eta: 13:14:09.912561	Training Loss 0.0968 (0.0923)	Training Prec@1 100.000 (99.914)	Training Prec@5 100.000 (99.972)	
2022-05-11 15:07:22,996: ============================================================
2022-05-11 15:08:09,807: time cost, forward:0.1720261579230075, backward:0.10521928660387239, data cost:0.1904316432519134 
2022-05-11 15:08:09,807: ============================================================
2022-05-11 15:08:09,807: Epoch 25/38 Batch 5700/7662 eta: 13:12:25.400044	Training Loss 0.1024 (0.0923)	Training Prec@1 100.000 (99.914)	Training Prec@5 100.000 (99.972)	
2022-05-11 15:08:09,807: ============================================================
2022-05-11 15:08:56,514: time cost, forward:0.17202327781390436, backward:0.1052103357944926, data cost:0.19042809631602892 
2022-05-11 15:08:56,515: ============================================================
2022-05-11 15:08:56,515: Epoch 25/38 Batch 5800/7662 eta: 13:09:54.000875	Training Loss 0.0958 (0.0924)	Training Prec@1 99.609 (99.914)	Training Prec@5 99.609 (99.972)	
2022-05-11 15:08:56,515: ============================================================
2022-05-11 15:09:43,221: time cost, forward:0.1720264643445866, backward:0.10520190189482499, data cost:0.1904185738962047 
2022-05-11 15:09:43,222: ============================================================
2022-05-11 15:09:43,222: Epoch 25/38 Batch 5900/7662 eta: 13:09:06.403863	Training Loss 0.0965 (0.0925)	Training Prec@1 99.805 (99.913)	Training Prec@5 99.805 (99.971)	
2022-05-11 15:09:43,222: ============================================================
2022-05-11 15:10:29,935: time cost, forward:0.17202408871346264, backward:0.10519471373592224, data cost:0.1904128179647144 
2022-05-11 15:10:29,936: ============================================================
2022-05-11 15:10:29,936: Epoch 25/38 Batch 6000/7662 eta: 13:08:26.647571	Training Loss 0.0909 (0.0925)	Training Prec@1 99.805 (99.913)	Training Prec@5 100.000 (99.971)	
2022-05-11 15:10:29,936: ============================================================
2022-05-11 15:11:16,556: time cost, forward:0.17201713750276004, backward:0.10518899345460496, data cost:0.19039767299407542 
2022-05-11 15:11:16,557: ============================================================
2022-05-11 15:11:16,557: Epoch 25/38 Batch 6100/7662 eta: 13:06:06.034517	Training Loss 0.0933 (0.0926)	Training Prec@1 100.000 (99.913)	Training Prec@5 100.000 (99.971)	
2022-05-11 15:11:16,557: ============================================================
2022-05-11 15:12:03,223: time cost, forward:0.1720130899333631, backward:0.10518383399039088, data cost:0.19038722580104975 
2022-05-11 15:12:03,223: ============================================================
2022-05-11 15:12:03,223: Epoch 25/38 Batch 6200/7662 eta: 13:06:05.293169	Training Loss 0.1073 (0.0926)	Training Prec@1 100.000 (99.912)	Training Prec@5 100.000 (99.971)	
2022-05-11 15:12:03,223: ============================================================
2022-05-11 15:12:49,903: time cost, forward:0.1720096116066736, backward:0.10517710711316734, data cost:0.1903788115717453 
2022-05-11 15:12:49,903: ============================================================
2022-05-11 15:12:49,903: Epoch 25/38 Batch 6300/7662 eta: 13:05:32.469612	Training Loss 0.1007 (0.0927)	Training Prec@1 99.805 (99.912)	Training Prec@5 100.000 (99.971)	
2022-05-11 15:12:49,903: ============================================================
2022-05-11 15:13:36,537: time cost, forward:0.1720064443840722, backward:0.10517071272958385, data cost:0.19036495337208317 
2022-05-11 15:13:36,537: ============================================================
2022-05-11 15:13:36,537: Epoch 25/38 Batch 6400/7662 eta: 13:03:58.798604	Training Loss 0.0947 (0.0928)	Training Prec@1 100.000 (99.912)	Training Prec@5 100.000 (99.971)	
2022-05-11 15:13:36,537: ============================================================
2022-05-11 15:14:23,195: time cost, forward:0.1720025847555766, backward:0.1051657308448478, data cost:0.19035466987731953 
2022-05-11 15:14:23,195: ============================================================
2022-05-11 15:14:23,195: Epoch 25/38 Batch 6500/7662 eta: 13:03:36.836050	Training Loss 0.0947 (0.0928)	Training Prec@1 99.805 (99.912)	Training Prec@5 99.805 (99.971)	
2022-05-11 15:14:23,195: ============================================================
2022-05-11 15:15:09,855: time cost, forward:0.1720006481086256, backward:0.10516203347616691, data cost:0.1903423806684887 
2022-05-11 15:15:09,856: ============================================================
2022-05-11 15:15:09,856: Epoch 25/38 Batch 6600/7662 eta: 13:02:53.039216	Training Loss 0.0971 (0.0929)	Training Prec@1 99.414 (99.912)	Training Prec@5 100.000 (99.971)	
2022-05-11 15:15:09,856: ============================================================
2022-05-11 15:15:56,581: time cost, forward:0.17199548555320904, backward:0.1051581578568605, data cost:0.19034365949959592 
2022-05-11 15:15:56,582: ============================================================
2022-05-11 15:15:56,582: Epoch 25/38 Batch 6700/7662 eta: 13:03:11.731222	Training Loss 0.0881 (0.0929)	Training Prec@1 100.000 (99.912)	Training Prec@5 100.000 (99.971)	
2022-05-11 15:15:56,582: ============================================================
2022-05-11 15:16:43,284: time cost, forward:0.17198910722313146, backward:0.10515502267487699, data cost:0.19034040961340606 
2022-05-11 15:16:43,285: ============================================================
2022-05-11 15:16:43,285: Epoch 25/38 Batch 6800/7662 eta: 13:02:02.375365	Training Loss 0.0928 (0.0930)	Training Prec@1 99.805 (99.911)	Training Prec@5 100.000 (99.971)	
2022-05-11 15:16:43,285: ============================================================
2022-05-11 15:17:29,908: time cost, forward:0.1719830817529336, backward:0.10515168370120956, data cost:0.19032793740359472 
2022-05-11 15:17:29,909: ============================================================
2022-05-11 15:17:29,909: Epoch 25/38 Batch 6900/7662 eta: 12:59:56.017985	Training Loss 0.0930 (0.0931)	Training Prec@1 100.000 (99.911)	Training Prec@5 100.000 (99.971)	
2022-05-11 15:17:29,909: ============================================================
2022-05-11 15:18:16,629: time cost, forward:0.17198207106210792, backward:0.10514860058498478, data cost:0.19032424755616945 
2022-05-11 15:18:16,629: ============================================================
2022-05-11 15:18:16,630: Epoch 25/38 Batch 7000/7662 eta: 13:00:46.220929	Training Loss 0.1082 (0.0931)	Training Prec@1 100.000 (99.911)	Training Prec@5 100.000 (99.971)	
2022-05-11 15:18:16,630: ============================================================
2022-05-11 15:19:03,329: time cost, forward:0.17198225638785486, backward:0.10514336207296197, data cost:0.19031922137809482 
2022-05-11 15:19:03,329: ============================================================
2022-05-11 15:19:03,329: Epoch 25/38 Batch 7100/7662 eta: 12:59:38.359429	Training Loss 0.0925 (0.0932)	Training Prec@1 99.609 (99.911)	Training Prec@5 99.805 (99.971)	
2022-05-11 15:19:03,329: ============================================================
2022-05-11 15:19:49,857: time cost, forward:0.17196378854930955, backward:0.10513957892379623, data cost:0.1903075924812547 
2022-05-11 15:19:49,857: ============================================================
2022-05-11 15:19:49,857: Epoch 25/38 Batch 7200/7662 eta: 12:56:00.437498	Training Loss 0.1007 (0.0932)	Training Prec@1 99.805 (99.910)	Training Prec@5 99.805 (99.971)	
2022-05-11 15:19:49,857: ============================================================
2022-05-11 15:20:36,366: time cost, forward:0.17194495052160474, backward:0.10513541756925363, data cost:0.1902950334620812 
2022-05-11 15:20:36,366: ============================================================
2022-05-11 15:20:36,367: Epoch 25/38 Batch 7300/7662 eta: 12:54:54.776762	Training Loss 0.0953 (0.0933)	Training Prec@1 100.000 (99.910)	Training Prec@5 100.000 (99.971)	
2022-05-11 15:20:36,367: ============================================================
2022-05-11 15:21:22,935: time cost, forward:0.17193398048368913, backward:0.10513223301866503, data cost:0.1902828452103459 
2022-05-11 15:21:22,935: ============================================================
2022-05-11 15:21:22,935: Epoch 25/38 Batch 7400/7662 eta: 12:55:07.803416	Training Loss 0.0952 (0.0933)	Training Prec@1 99.609 (99.910)	Training Prec@5 99.805 (99.971)	
2022-05-11 15:21:22,935: ============================================================
2022-05-11 15:22:09,532: time cost, forward:0.17192680184913328, backward:0.1051296858107794, data cost:0.1902702551616766 
2022-05-11 15:22:09,532: ============================================================
2022-05-11 15:22:09,532: Epoch 25/38 Batch 7500/7662 eta: 12:54:49.054916	Training Loss 0.0964 (0.0934)	Training Prec@1 100.000 (99.910)	Training Prec@5 100.000 (99.971)	
2022-05-11 15:22:09,532: ============================================================
2022-05-11 15:22:56,153: time cost, forward:0.17192273102931122, backward:0.10512685085506969, data cost:0.19025898252698775 
2022-05-11 15:22:56,153: ============================================================
2022-05-11 15:22:56,153: Epoch 25/38 Batch 7600/7662 eta: 12:54:26.533647	Training Loss 0.1032 (0.0934)	Training Prec@1 100.000 (99.909)	Training Prec@5 100.000 (99.971)	
2022-05-11 15:22:56,153: ============================================================
2022-05-11 15:23:26,750: Epoch: 25/38 eta: 12:53:57.162512	Training Loss 0.1001 (0.0935)	Training Prec@1 99.805 (99.909)	Training Prec@5 100.000 (99.971)
2022-05-11 15:23:26,750: ============================================================
2022-05-11 15:23:26,814: Save Checkpoint...
2022-05-11 15:23:26,815: ============================================================
2022-05-11 15:23:29,300: Save done!
2022-05-11 15:23:29,301: ============================================================
2022-05-11 15:24:19,123: time cost, forward:0.18981087087380766, backward:0.10449906551476681, data cost:0.20651441150241429 
2022-05-11 15:24:19,124: ============================================================
2022-05-11 15:24:19,124: Epoch 26/38 Batch 100/7662 eta: 13:45:50.206560	Training Loss 0.0926 (0.0851)	Training Prec@1 100.000 (99.953)	Training Prec@5 100.000 (99.984)	
2022-05-11 15:24:19,124: ============================================================
2022-05-11 15:25:05,905: time cost, forward:0.18141391888335723, backward:0.10466246868497762, data cost:0.19803552531716812 
2022-05-11 15:25:05,906: ============================================================
2022-05-11 15:25:05,906: Epoch 26/38 Batch 200/7662 eta: 12:55:04.168994	Training Loss 0.0891 (0.0848)	Training Prec@1 100.000 (99.958)	Training Prec@5 100.000 (99.988)	
2022-05-11 15:25:05,906: ============================================================
2022-05-11 15:25:52,629: time cost, forward:0.1783883300513328, backward:0.10471051592491941, data cost:0.19528914614265977 
2022-05-11 15:25:52,630: ============================================================
2022-05-11 15:25:52,630: Epoch 26/38 Batch 300/7662 eta: 12:53:20.178270	Training Loss 0.0879 (0.0850)	Training Prec@1 100.000 (99.950)	Training Prec@5 100.000 (99.986)	
2022-05-11 15:25:52,630: ============================================================
2022-05-11 15:26:39,337: time cost, forward:0.17682055721904402, backward:0.10475352593233113, data cost:0.19391788575882302 
2022-05-11 15:26:39,338: ============================================================
2022-05-11 15:26:39,338: Epoch 26/38 Batch 400/7662 eta: 12:52:17.586346	Training Loss 0.0805 (0.0852)	Training Prec@1 100.000 (99.949)	Training Prec@5 100.000 (99.985)	
2022-05-11 15:26:39,338: ============================================================
2022-05-11 15:27:26,056: time cost, forward:0.17588520002269553, backward:0.10478307727821365, data cost:0.19310734840576538 
2022-05-11 15:27:26,056: ============================================================
2022-05-11 15:27:26,056: Epoch 26/38 Batch 500/7662 eta: 12:51:41.388286	Training Loss 0.0869 (0.0854)	Training Prec@1 100.000 (99.948)	Training Prec@5 100.000 (99.982)	
2022-05-11 15:27:26,056: ============================================================
2022-05-11 15:28:12,810: time cost, forward:0.1752397791173104, backward:0.10480651712178786, data cost:0.192631568255926 
2022-05-11 15:28:12,811: ============================================================
2022-05-11 15:28:12,811: Epoch 26/38 Batch 600/7662 eta: 12:51:30.159745	Training Loss 0.0813 (0.0855)	Training Prec@1 100.000 (99.947)	Training Prec@5 100.000 (99.981)	
2022-05-11 15:28:12,811: ============================================================
2022-05-11 15:28:59,493: time cost, forward:0.17477732461921136, backward:0.10481399255078579, data cost:0.19221555794428005 
2022-05-11 15:28:59,493: ============================================================
2022-05-11 15:28:59,493: Epoch 26/38 Batch 700/7662 eta: 12:49:32.037083	Training Loss 0.0872 (0.0857)	Training Prec@1 100.000 (99.944)	Training Prec@5 100.000 (99.981)	
2022-05-11 15:28:59,493: ============================================================
2022-05-11 15:29:46,225: time cost, forward:0.1744167980771787, backward:0.10483498776212652, data cost:0.19194716625428468 
2022-05-11 15:29:46,225: ============================================================
2022-05-11 15:29:46,225: Epoch 26/38 Batch 800/7662 eta: 12:49:34.780877	Training Loss 0.0794 (0.0859)	Training Prec@1 100.000 (99.943)	Training Prec@5 100.000 (99.980)	
2022-05-11 15:29:46,225: ============================================================
2022-05-11 15:30:32,958: time cost, forward:0.17416461901086588, backward:0.10484128905350427, data cost:0.1917357614493874 
2022-05-11 15:30:32,959: ============================================================
2022-05-11 15:30:32,959: Epoch 26/38 Batch 900/7662 eta: 12:48:49.460124	Training Loss 0.0905 (0.0860)	Training Prec@1 100.000 (99.942)	Training Prec@5 100.000 (99.980)	
2022-05-11 15:30:32,959: ============================================================
2022-05-11 15:31:19,682: time cost, forward:0.17395083730046576, backward:0.10485157952294336, data cost:0.1915515464347404 
2022-05-11 15:31:19,682: ============================================================
2022-05-11 15:31:19,682: Epoch 26/38 Batch 1000/7662 eta: 12:47:52.559844	Training Loss 0.0886 (0.0862)	Training Prec@1 100.000 (99.942)	Training Prec@5 100.000 (99.981)	
2022-05-11 15:31:19,682: ============================================================
2022-05-11 15:32:06,434: time cost, forward:0.17379186953925566, backward:0.10485818062835221, data cost:0.1914148645253481 
2022-05-11 15:32:06,434: ============================================================
2022-05-11 15:32:06,434: Epoch 26/38 Batch 1100/7662 eta: 12:47:33.802496	Training Loss 0.0833 (0.0863)	Training Prec@1 100.000 (99.943)	Training Prec@5 100.000 (99.981)	
2022-05-11 15:32:06,434: ============================================================
2022-05-11 15:32:53,151: time cost, forward:0.17364601814518182, backward:0.10486217952947799, data cost:0.19129440702926725 
2022-05-11 15:32:53,152: ============================================================
2022-05-11 15:32:53,152: Epoch 26/38 Batch 1200/7662 eta: 12:46:13.521063	Training Loss 0.0939 (0.0864)	Training Prec@1 100.000 (99.942)	Training Prec@5 100.000 (99.980)	
2022-05-11 15:32:53,152: ============================================================
2022-05-11 15:33:39,896: time cost, forward:0.17352173748706468, backward:0.10486674363838883, data cost:0.19120471563772387 
2022-05-11 15:33:39,896: ============================================================
2022-05-11 15:33:39,896: Epoch 26/38 Batch 1300/7662 eta: 12:45:53.122101	Training Loss 0.0924 (0.0866)	Training Prec@1 100.000 (99.941)	Training Prec@5 100.000 (99.979)	
2022-05-11 15:33:39,897: ============================================================
2022-05-11 15:34:26,617: time cost, forward:0.17341795983358824, backward:0.10486617763183899, data cost:0.19112149044988494 
2022-05-11 15:34:26,617: ============================================================
2022-05-11 15:34:26,618: Epoch 26/38 Batch 1400/7662 eta: 12:44:43.374143	Training Loss 0.0930 (0.0867)	Training Prec@1 100.000 (99.939)	Training Prec@5 100.000 (99.980)	
2022-05-11 15:34:26,618: ============================================================
2022-05-11 15:35:13,516: time cost, forward:0.17334135346924806, backward:0.10493297080662825, data cost:0.19108616757027064 
2022-05-11 15:35:13,516: ============================================================
2022-05-11 15:35:13,516: Epoch 26/38 Batch 1500/7662 eta: 12:46:50.962342	Training Loss 0.0885 (0.0868)	Training Prec@1 100.000 (99.938)	Training Prec@5 100.000 (99.979)	
2022-05-11 15:35:13,516: ============================================================
2022-05-11 15:36:00,424: time cost, forward:0.17325799863289265, backward:0.10502935663620482, data cost:0.19103925402571514 
2022-05-11 15:36:00,425: ============================================================
2022-05-11 15:36:00,425: Epoch 26/38 Batch 1600/7662 eta: 12:46:13.465174	Training Loss 0.0882 (0.0869)	Training Prec@1 99.805 (99.938)	Training Prec@5 99.805 (99.979)	
2022-05-11 15:36:00,425: ============================================================
2022-05-11 15:36:47,341: time cost, forward:0.17319340029486913, backward:0.10511560647750055, data cost:0.19099339574417554 
2022-05-11 15:36:47,341: ============================================================
2022-05-11 15:36:47,342: Epoch 26/38 Batch 1700/7662 eta: 12:45:34.934340	Training Loss 0.0914 (0.0870)	Training Prec@1 100.000 (99.938)	Training Prec@5 100.000 (99.979)	
2022-05-11 15:36:47,342: ============================================================
2022-05-11 15:37:34,252: time cost, forward:0.17312042841717826, backward:0.10518926365498771, data cost:0.19095504131497376 
2022-05-11 15:37:34,253: ============================================================
2022-05-11 15:37:34,253: Epoch 26/38 Batch 1800/7662 eta: 12:44:42.443726	Training Loss 0.0936 (0.0870)	Training Prec@1 99.805 (99.937)	Training Prec@5 100.000 (99.979)	
2022-05-11 15:37:34,253: ============================================================
2022-05-11 15:38:21,243: time cost, forward:0.1730741500352294, backward:0.1052555024718033, data cost:0.19094289384935328 
2022-05-11 15:38:21,244: ============================================================
2022-05-11 15:38:21,244: Epoch 26/38 Batch 1900/7662 eta: 12:45:13.442730	Training Loss 0.0888 (0.0871)	Training Prec@1 100.000 (99.938)	Training Prec@5 100.000 (99.979)	
2022-05-11 15:38:21,244: ============================================================
2022-05-11 15:39:08,163: time cost, forward:0.17304836338075655, backward:0.10527140883101768, data cost:0.19092977565786373 
2022-05-11 15:39:08,163: ============================================================
2022-05-11 15:39:08,163: Epoch 26/38 Batch 2000/7662 eta: 12:43:16.941974	Training Loss 0.0824 (0.0872)	Training Prec@1 100.000 (99.937)	Training Prec@5 100.000 (99.979)	
2022-05-11 15:39:08,164: ============================================================
2022-05-11 15:39:54,991: time cost, forward:0.17301178103461046, backward:0.1052502720284428, data cost:0.1909283734094875 
2022-05-11 15:39:54,991: ============================================================
2022-05-11 15:39:54,991: Epoch 26/38 Batch 2100/7662 eta: 12:41:00.395534	Training Loss 0.0841 (0.0874)	Training Prec@1 100.000 (99.936)	Training Prec@5 100.000 (99.979)	
2022-05-11 15:39:54,991: ============================================================
2022-05-11 15:40:41,748: time cost, forward:0.17297718838270604, backward:0.10523581808401596, data cost:0.19089152217724475 
2022-05-11 15:40:41,748: ============================================================
2022-05-11 15:40:41,748: Epoch 26/38 Batch 2200/7662 eta: 12:39:04.354776	Training Loss 0.0935 (0.0875)	Training Prec@1 100.000 (99.934)	Training Prec@5 100.000 (99.978)	
2022-05-11 15:40:41,748: ============================================================
2022-05-11 15:41:28,505: time cost, forward:0.17294623137246323, backward:0.10522037767855796, data cost:0.1908593922399759 
2022-05-11 15:41:28,505: ============================================================
2022-05-11 15:41:28,505: Epoch 26/38 Batch 2300/7662 eta: 12:38:18.268029	Training Loss 0.0922 (0.0876)	Training Prec@1 99.805 (99.933)	Training Prec@5 99.805 (99.977)	
2022-05-11 15:41:28,506: ============================================================
2022-05-11 15:42:15,301: time cost, forward:0.17291131929935838, backward:0.10521486164282241, data cost:0.19084387881003503 
2022-05-11 15:42:15,301: ============================================================
2022-05-11 15:42:15,301: Epoch 26/38 Batch 2400/7662 eta: 12:38:08.838702	Training Loss 0.0927 (0.0878)	Training Prec@1 100.000 (99.933)	Training Prec@5 100.000 (99.977)	
2022-05-11 15:42:15,301: ============================================================
2022-05-11 15:43:02,132: time cost, forward:0.1729002467342833, backward:0.10520813139785333, data cost:0.19081427536758722 
2022-05-11 15:43:02,132: ============================================================
2022-05-11 15:43:02,133: Epoch 26/38 Batch 2500/7662 eta: 12:37:56.364937	Training Loss 0.0995 (0.0879)	Training Prec@1 99.805 (99.933)	Training Prec@5 99.805 (99.977)	
2022-05-11 15:43:02,133: ============================================================
2022-05-11 15:43:48,941: time cost, forward:0.17287033106006536, backward:0.10519730159529084, data cost:0.19081226813421656 
2022-05-11 15:43:48,941: ============================================================
2022-05-11 15:43:48,942: Epoch 26/38 Batch 2600/7662 eta: 12:36:48.104940	Training Loss 0.0886 (0.0879)	Training Prec@1 100.000 (99.933)	Training Prec@5 100.000 (99.977)	
2022-05-11 15:43:48,942: ============================================================
2022-05-11 15:44:35,752: time cost, forward:0.17284629467727078, backward:0.10518600632412074, data cost:0.1908046414826525 
2022-05-11 15:44:35,752: ============================================================
2022-05-11 15:44:35,752: Epoch 26/38 Batch 2700/7662 eta: 12:36:02.884268	Training Loss 0.0983 (0.0880)	Training Prec@1 99.805 (99.932)	Training Prec@5 99.805 (99.978)	
2022-05-11 15:44:35,752: ============================================================
2022-05-11 15:45:22,582: time cost, forward:0.1728423824903155, backward:0.10517134424531915, data cost:0.19079380931493084 
2022-05-11 15:45:22,582: ============================================================
2022-05-11 15:45:22,582: Epoch 26/38 Batch 2800/7662 eta: 12:35:34.755878	Training Loss 0.0844 (0.0881)	Training Prec@1 100.000 (99.932)	Training Prec@5 100.000 (99.978)	
2022-05-11 15:45:22,583: ============================================================
2022-05-11 15:46:09,341: time cost, forward:0.17281506899596494, backward:0.10516177707394471, data cost:0.19077650642921365 
2022-05-11 15:46:09,341: ============================================================
2022-05-11 15:46:09,341: Epoch 26/38 Batch 2900/7662 eta: 12:33:39.241639	Training Loss 0.0958 (0.0882)	Training Prec@1 100.000 (99.932)	Training Prec@5 100.000 (99.977)	
2022-05-11 15:46:09,342: ============================================================
2022-05-11 15:46:56,097: time cost, forward:0.1727853062233157, backward:0.10515458029721252, data cost:0.19076436811703448 
2022-05-11 15:46:56,097: ============================================================
2022-05-11 15:46:56,097: Epoch 26/38 Batch 3000/7662 eta: 12:32:49.356367	Training Loss 0.0856 (0.0883)	Training Prec@1 100.000 (99.931)	Training Prec@5 100.000 (99.977)	
2022-05-11 15:46:56,097: ============================================================
2022-05-11 15:47:42,880: time cost, forward:0.17277057096241905, backward:0.10514609942170026, data cost:0.19074669027374652 
2022-05-11 15:47:42,880: ============================================================
2022-05-11 15:47:42,880: Epoch 26/38 Batch 3100/7662 eta: 12:32:29.049964	Training Loss 0.0984 (0.0884)	Training Prec@1 99.805 (99.931)	Training Prec@5 99.805 (99.977)	
2022-05-11 15:47:42,881: ============================================================
2022-05-11 15:48:29,632: time cost, forward:0.17275165274352647, backward:0.10513793643320601, data cost:0.1907305244953791 
2022-05-11 15:48:29,633: ============================================================
2022-05-11 15:48:29,633: Epoch 26/38 Batch 3200/7662 eta: 12:31:12.531947	Training Loss 0.0926 (0.0885)	Training Prec@1 99.609 (99.929)	Training Prec@5 99.609 (99.976)	
2022-05-11 15:48:29,633: ============================================================
2022-05-11 15:49:16,454: time cost, forward:0.17273949355419999, backward:0.10512973511352725, data cost:0.19073110061835144 
2022-05-11 15:49:16,455: ============================================================
2022-05-11 15:49:16,455: Epoch 26/38 Batch 3300/7662 eta: 12:31:32.883542	Training Loss 0.0915 (0.0886)	Training Prec@1 100.000 (99.930)	Training Prec@5 100.000 (99.976)	
2022-05-11 15:49:16,455: ============================================================
2022-05-11 15:50:03,239: time cost, forward:0.17271885545017368, backward:0.10512366263997594, data cost:0.19072490048499696 
2022-05-11 15:50:03,239: ============================================================
2022-05-11 15:50:03,239: Epoch 26/38 Batch 3400/7662 eta: 12:30:10.028716	Training Loss 0.0981 (0.0887)	Training Prec@1 100.000 (99.929)	Training Prec@5 100.000 (99.976)	
2022-05-11 15:50:03,239: ============================================================
2022-05-11 15:50:50,012: time cost, forward:0.17270479654713883, backward:0.10511631507742708, data cost:0.19070795584692551 
2022-05-11 15:50:50,013: ============================================================
2022-05-11 15:50:50,013: Epoch 26/38 Batch 3500/7662 eta: 12:29:12.423615	Training Loss 0.1013 (0.0888)	Training Prec@1 99.805 (99.929)	Training Prec@5 100.000 (99.976)	
2022-05-11 15:50:50,013: ============================================================
2022-05-11 15:51:36,845: time cost, forward:0.17269817416155858, backward:0.1051069804448888, data cost:0.19070773510245292 
2022-05-11 15:51:36,845: ============================================================
2022-05-11 15:51:36,845: Epoch 26/38 Batch 3600/7662 eta: 12:29:22.345724	Training Loss 0.0943 (0.0889)	Training Prec@1 99.805 (99.929)	Training Prec@5 100.000 (99.976)	
2022-05-11 15:51:36,845: ============================================================
2022-05-11 15:52:23,640: time cost, forward:0.17268801779642592, backward:0.10509862291326262, data cost:0.19070383476933842 
2022-05-11 15:52:23,641: ============================================================
2022-05-11 15:52:23,641: Epoch 26/38 Batch 3700/7662 eta: 12:28:00.333776	Training Loss 0.0921 (0.0890)	Training Prec@1 99.805 (99.928)	Training Prec@5 99.805 (99.976)	
2022-05-11 15:52:23,641: ============================================================
2022-05-11 15:53:10,366: time cost, forward:0.17267629409281948, backward:0.10509075400514896, data cost:0.19068418737774492 
2022-05-11 15:53:10,367: ============================================================
2022-05-11 15:53:10,367: Epoch 26/38 Batch 3800/7662 eta: 12:26:06.779344	Training Loss 0.0903 (0.0890)	Training Prec@1 100.000 (99.928)	Training Prec@5 100.000 (99.976)	
2022-05-11 15:53:10,367: ============================================================
2022-05-11 15:53:57,106: time cost, forward:0.1726673663228131, backward:0.10508702412175044, data cost:0.19066306284434614 
2022-05-11 15:53:57,106: ============================================================
2022-05-11 15:53:57,106: Epoch 26/38 Batch 3900/7662 eta: 12:25:33.102004	Training Loss 0.0968 (0.0891)	Training Prec@1 100.000 (99.927)	Training Prec@5 100.000 (99.975)	
2022-05-11 15:53:57,106: ============================================================
2022-05-11 15:54:43,846: time cost, forward:0.17265924736093538, backward:0.10508498635164468, data cost:0.19064123942333927 
2022-05-11 15:54:43,846: ============================================================
2022-05-11 15:54:43,846: Epoch 26/38 Batch 4000/7662 eta: 12:24:46.416393	Training Loss 0.0947 (0.0893)	Training Prec@1 100.000 (99.927)	Training Prec@5 100.000 (99.975)	
2022-05-11 15:54:43,846: ============================================================
2022-05-11 15:55:30,577: time cost, forward:0.17265054213474307, backward:0.10508555341098448, data cost:0.19061707542942455 
2022-05-11 15:55:30,577: ============================================================
2022-05-11 15:55:30,577: Epoch 26/38 Batch 4100/7662 eta: 12:23:51.625913	Training Loss 0.0932 (0.0893)	Training Prec@1 99.805 (99.927)	Training Prec@5 100.000 (99.975)	
2022-05-11 15:55:30,577: ============================================================
2022-05-11 15:56:17,321: time cost, forward:0.17264133954394514, backward:0.10508387757074439, data cost:0.190599902183222 
2022-05-11 15:56:17,321: ============================================================
2022-05-11 15:56:17,322: Epoch 26/38 Batch 4200/7662 eta: 12:23:17.255491	Training Loss 0.0855 (0.0894)	Training Prec@1 100.000 (99.927)	Training Prec@5 100.000 (99.975)	
2022-05-11 15:56:17,322: ============================================================
2022-05-11 15:57:04,096: time cost, forward:0.17263732058526637, backward:0.10508477185931031, data cost:0.19058099400861286 
2022-05-11 15:57:04,096: ============================================================
2022-05-11 15:57:04,096: Epoch 26/38 Batch 4300/7662 eta: 12:22:59.555306	Training Loss 0.0998 (0.0895)	Training Prec@1 100.000 (99.926)	Training Prec@5 100.000 (99.976)	
2022-05-11 15:57:04,096: ============================================================
2022-05-11 15:57:50,875: time cost, forward:0.17263585915753016, backward:0.10508579296208317, data cost:0.19056400479877988 
2022-05-11 15:57:50,875: ============================================================
2022-05-11 15:57:50,875: Epoch 26/38 Batch 4400/7662 eta: 12:22:16.594293	Training Loss 0.0904 (0.0896)	Training Prec@1 100.000 (99.926)	Training Prec@5 100.000 (99.975)	
2022-05-11 15:57:50,875: ============================================================
2022-05-11 15:58:37,685: time cost, forward:0.17263752912303876, backward:0.10508424829286743, data cost:0.19055438677611206 
2022-05-11 15:58:37,686: ============================================================
2022-05-11 15:58:37,686: Epoch 26/38 Batch 4500/7662 eta: 12:22:00.485267	Training Loss 0.0956 (0.0897)	Training Prec@1 99.805 (99.926)	Training Prec@5 99.805 (99.975)	
2022-05-11 15:58:37,686: ============================================================
2022-05-11 15:59:24,531: time cost, forward:0.17263731139461536, backward:0.10508279293406189, data cost:0.1905488451036792 
2022-05-11 15:59:24,531: ============================================================
2022-05-11 15:59:24,531: Epoch 26/38 Batch 4600/7662 eta: 12:21:46.467482	Training Loss 0.0910 (0.0898)	Training Prec@1 100.000 (99.926)	Training Prec@5 100.000 (99.975)	
2022-05-11 15:59:24,531: ============================================================
2022-05-11 16:00:11,357: time cost, forward:0.17263394534575174, backward:0.10508558293001832, data cost:0.1905437011012475 
2022-05-11 16:00:11,358: ============================================================
2022-05-11 16:00:11,358: Epoch 26/38 Batch 4700/7662 eta: 12:20:41.652093	Training Loss 0.0922 (0.0898)	Training Prec@1 100.000 (99.925)	Training Prec@5 100.000 (99.975)	
2022-05-11 16:00:11,358: ============================================================
2022-05-11 16:00:58,226: time cost, forward:0.17263086946538697, backward:0.10508720152923082, data cost:0.19054830250677454 
2022-05-11 16:00:58,226: ============================================================
2022-05-11 16:00:58,226: Epoch 26/38 Batch 4800/7662 eta: 12:20:34.288549	Training Loss 0.0843 (0.0899)	Training Prec@1 100.000 (99.925)	Training Prec@5 100.000 (99.975)	
2022-05-11 16:00:58,226: ============================================================
2022-05-11 16:01:45,008: time cost, forward:0.17262655877414881, backward:0.10508658779375551, data cost:0.19053843776214655 
2022-05-11 16:01:45,008: ============================================================
2022-05-11 16:01:45,008: Epoch 26/38 Batch 4900/7662 eta: 12:18:25.886154	Training Loss 0.0937 (0.0900)	Training Prec@1 99.805 (99.925)	Training Prec@5 99.805 (99.975)	
2022-05-11 16:01:45,008: ============================================================
2022-05-11 16:02:31,747: time cost, forward:0.17261183540876876, backward:0.10508578914383646, data cost:0.19053145136015728 
2022-05-11 16:02:31,748: ============================================================
2022-05-11 16:02:31,748: Epoch 26/38 Batch 5000/7662 eta: 12:16:59.028730	Training Loss 0.0957 (0.0900)	Training Prec@1 100.000 (99.925)	Training Prec@5 100.000 (99.975)	
2022-05-11 16:02:31,748: ============================================================
2022-05-11 16:03:18,513: time cost, forward:0.17260384662498748, backward:0.10508355235885139, data cost:0.19052494949255533 
2022-05-11 16:03:18,513: ============================================================
2022-05-11 16:03:18,513: Epoch 26/38 Batch 5100/7662 eta: 12:16:36.404143	Training Loss 0.0945 (0.0901)	Training Prec@1 99.805 (99.924)	Training Prec@5 99.805 (99.975)	
2022-05-11 16:03:18,513: ============================================================
2022-05-11 16:04:05,286: time cost, forward:0.17259271820363323, backward:0.1050802669426092, data cost:0.19052281685117622 
2022-05-11 16:04:05,286: ============================================================
2022-05-11 16:04:05,286: Epoch 26/38 Batch 5200/7662 eta: 12:15:57.342870	Training Loss 0.0978 (0.0902)	Training Prec@1 99.805 (99.924)	Training Prec@5 100.000 (99.975)	
2022-05-11 16:04:05,286: ============================================================
2022-05-11 16:04:52,018: time cost, forward:0.17258235836371, backward:0.10507804142976622, data cost:0.19051363414628344 
2022-05-11 16:04:52,018: ============================================================
2022-05-11 16:04:52,018: Epoch 26/38 Batch 5300/7662 eta: 12:14:31.607830	Training Loss 0.0870 (0.0903)	Training Prec@1 100.000 (99.924)	Training Prec@5 100.000 (99.974)	
2022-05-11 16:04:52,019: ============================================================
2022-05-11 16:05:38,750: time cost, forward:0.17257652836478315, backward:0.10507313952134216, data cost:0.19050320984589036 
2022-05-11 16:05:38,750: ============================================================
2022-05-11 16:05:38,750: Epoch 26/38 Batch 5400/7662 eta: 12:13:44.644645	Training Loss 0.0986 (0.0903)	Training Prec@1 99.805 (99.923)	Training Prec@5 100.000 (99.974)	
2022-05-11 16:05:38,750: ============================================================
2022-05-11 16:06:25,532: time cost, forward:0.172572447226511, backward:0.10506790289988971, data cost:0.19050165847726985 
2022-05-11 16:06:25,532: ============================================================
2022-05-11 16:06:25,532: Epoch 26/38 Batch 5500/7662 eta: 12:13:44.777138	Training Loss 0.0957 (0.0904)	Training Prec@1 100.000 (99.923)	Training Prec@5 100.000 (99.974)	
2022-05-11 16:06:25,532: ============================================================
2022-05-11 16:07:12,367: time cost, forward:0.1725728562909123, backward:0.10506305777189838, data cost:0.19050526938325146 
2022-05-11 16:07:12,368: ============================================================
2022-05-11 16:07:12,368: Epoch 26/38 Batch 5600/7662 eta: 12:13:48.874410	Training Loss 0.0924 (0.0905)	Training Prec@1 99.805 (99.923)	Training Prec@5 100.000 (99.974)	
2022-05-11 16:07:12,368: ============================================================
2022-05-11 16:07:59,130: time cost, forward:0.17257223315020573, backward:0.10505888775412002, data cost:0.1904962717974305 
2022-05-11 16:07:59,130: ============================================================
2022-05-11 16:07:59,130: Epoch 26/38 Batch 5700/7662 eta: 12:11:53.347342	Training Loss 0.1017 (0.0905)	Training Prec@1 99.805 (99.922)	Training Prec@5 100.000 (99.974)	
2022-05-11 16:07:59,130: ============================================================
2022-05-11 16:08:45,891: time cost, forward:0.1725677893395711, backward:0.10505419394994198, data cost:0.19049192819333854 
2022-05-11 16:08:45,891: ============================================================
2022-05-11 16:08:45,892: Epoch 26/38 Batch 5800/7662 eta: 12:11:05.311044	Training Loss 0.0956 (0.0906)	Training Prec@1 100.000 (99.922)	Training Prec@5 100.000 (99.974)	
2022-05-11 16:08:45,892: ============================================================
2022-05-11 16:09:32,625: time cost, forward:0.1725595477153172, backward:0.10505355760432397, data cost:0.19048293304960695 
2022-05-11 16:09:32,625: ============================================================
2022-05-11 16:09:32,625: Epoch 26/38 Batch 5900/7662 eta: 12:09:52.972155	Training Loss 0.0979 (0.0907)	Training Prec@1 99.805 (99.922)	Training Prec@5 100.000 (99.974)	
2022-05-11 16:09:32,626: ============================================================
2022-05-11 16:10:19,463: time cost, forward:0.17255435786379994, backward:0.1050523552701441, data cost:0.19048837443792258 
2022-05-11 16:10:19,463: ============================================================
2022-05-11 16:10:19,463: Epoch 26/38 Batch 6000/7662 eta: 12:10:43.540037	Training Loss 0.1052 (0.0908)	Training Prec@1 99.805 (99.921)	Training Prec@5 100.000 (99.974)	
2022-05-11 16:10:19,463: ============================================================
2022-05-11 16:11:06,352: time cost, forward:0.1725582742245398, backward:0.1050479778365476, data cost:0.19049691403375374 
2022-05-11 16:11:06,352: ============================================================
2022-05-11 16:11:06,353: Epoch 26/38 Batch 6100/7662 eta: 12:10:44.775846	Training Loss 0.1084 (0.0908)	Training Prec@1 99.609 (99.921)	Training Prec@5 99.805 (99.974)	
2022-05-11 16:11:06,353: ============================================================
2022-05-11 16:11:53,161: time cost, forward:0.1725519466523221, backward:0.10504354044475331, data cost:0.19050299330937667 
2022-05-11 16:11:53,161: ============================================================
2022-05-11 16:11:53,162: Epoch 26/38 Batch 6200/7662 eta: 12:08:42.776417	Training Loss 0.0957 (0.0909)	Training Prec@1 100.000 (99.921)	Training Prec@5 100.000 (99.974)	
2022-05-11 16:11:53,162: ============================================================
2022-05-11 16:12:39,941: time cost, forward:0.17254433357104326, backward:0.10504015102559072, data cost:0.1905044747413312 
2022-05-11 16:12:39,942: ============================================================
2022-05-11 16:12:39,942: Epoch 26/38 Batch 6300/7662 eta: 12:07:29.377630	Training Loss 0.0886 (0.0910)	Training Prec@1 100.000 (99.920)	Training Prec@5 100.000 (99.974)	
2022-05-11 16:12:39,942: ============================================================
2022-05-11 16:13:26,795: time cost, forward:0.17253815738423428, backward:0.10503591297380364, data cost:0.19051765754718783 
2022-05-11 16:13:26,796: ============================================================
2022-05-11 16:13:26,796: Epoch 26/38 Batch 6400/7662 eta: 12:07:51.113643	Training Loss 0.0971 (0.0910)	Training Prec@1 100.000 (99.921)	Training Prec@5 100.000 (99.973)	
2022-05-11 16:13:26,796: ============================================================
2022-05-11 16:14:13,554: time cost, forward:0.17252450958547785, backward:0.10503520384479034, data cost:0.19052004803142322 
2022-05-11 16:14:13,555: ============================================================
2022-05-11 16:14:13,555: Epoch 26/38 Batch 6500/7662 eta: 12:05:35.978995	Training Loss 0.1006 (0.0911)	Training Prec@1 100.000 (99.920)	Training Prec@5 100.000 (99.973)	
2022-05-11 16:14:13,555: ============================================================
2022-05-11 16:15:00,318: time cost, forward:0.17251259168904376, backward:0.10503290598817731, data cost:0.19052333220475948 
2022-05-11 16:15:00,318: ============================================================
2022-05-11 16:15:00,318: Epoch 26/38 Batch 6600/7662 eta: 12:04:53.011325	Training Loss 0.0960 (0.0912)	Training Prec@1 99.805 (99.920)	Training Prec@5 100.000 (99.973)	
2022-05-11 16:15:00,318: ============================================================
2022-05-11 16:15:47,117: time cost, forward:0.17250758524278434, backward:0.10503152491957736, data cost:0.19052448840724265 
2022-05-11 16:15:47,117: ============================================================
2022-05-11 16:15:47,117: Epoch 26/38 Batch 6700/7662 eta: 12:04:39.883423	Training Loss 0.0895 (0.0912)	Training Prec@1 100.000 (99.920)	Training Prec@5 100.000 (99.973)	
2022-05-11 16:15:47,118: ============================================================
2022-05-11 16:16:33,964: time cost, forward:0.17249833809871817, backward:0.1050309025376908, data cost:0.19052898050985156 
2022-05-11 16:16:33,964: ============================================================
2022-05-11 16:16:33,964: Epoch 26/38 Batch 6800/7662 eta: 12:04:36.909289	Training Loss 0.0962 (0.0913)	Training Prec@1 99.805 (99.920)	Training Prec@5 99.805 (99.973)	
2022-05-11 16:16:33,964: ============================================================
2022-05-11 16:17:20,819: time cost, forward:0.1724972375874451, backward:0.10503020406132212, data cost:0.1905321536469864 
2022-05-11 16:17:20,820: ============================================================
2022-05-11 16:17:20,820: Epoch 26/38 Batch 6900/7662 eta: 12:03:58.688428	Training Loss 0.0927 (0.0914)	Training Prec@1 100.000 (99.920)	Training Prec@5 100.000 (99.973)	
2022-05-11 16:17:20,820: ============================================================
2022-05-11 16:18:07,659: time cost, forward:0.17249319835771304, backward:0.10502706529208806, data cost:0.1905368116007888 
2022-05-11 16:18:07,660: ============================================================
2022-05-11 16:18:07,660: Epoch 26/38 Batch 7000/7662 eta: 12:02:57.026209	Training Loss 0.0978 (0.0914)	Training Prec@1 99.805 (99.919)	Training Prec@5 100.000 (99.973)	
2022-05-11 16:18:07,660: ============================================================
2022-05-11 16:18:54,555: time cost, forward:0.1724975575929226, backward:0.10502242148636193, data cost:0.1905462379471687 
2022-05-11 16:18:54,555: ============================================================
2022-05-11 16:18:54,556: Epoch 26/38 Batch 7100/7662 eta: 12:03:01.888768	Training Loss 0.0957 (0.0915)	Training Prec@1 99.805 (99.919)	Training Prec@5 99.805 (99.973)	
2022-05-11 16:18:54,556: ============================================================
2022-05-11 16:19:41,377: time cost, forward:0.17249601754004268, backward:0.10502024461269577, data cost:0.19054667147220317 
2022-05-11 16:19:41,377: ============================================================
2022-05-11 16:19:41,378: Epoch 26/38 Batch 7200/7662 eta: 12:01:06.785075	Training Loss 0.0917 (0.0916)	Training Prec@1 100.000 (99.918)	Training Prec@5 100.000 (99.973)	
2022-05-11 16:19:41,378: ============================================================
2022-05-11 16:20:28,309: time cost, forward:0.17249942289703366, backward:0.10501809181587585, data cost:0.19055871983753 
2022-05-11 16:20:28,309: ============================================================
2022-05-11 16:20:28,309: Epoch 26/38 Batch 7300/7662 eta: 12:02:01.314736	Training Loss 0.0924 (0.0916)	Training Prec@1 100.000 (99.918)	Training Prec@5 100.000 (99.973)	
2022-05-11 16:20:28,309: ============================================================
2022-05-11 16:21:15,187: time cost, forward:0.1725005229625658, backward:0.10501592010078374, data cost:0.19056529182890877 
2022-05-11 16:21:15,187: ============================================================
2022-05-11 16:21:15,187: Epoch 26/38 Batch 7400/7662 eta: 12:00:24.914214	Training Loss 0.0959 (0.0917)	Training Prec@1 100.000 (99.917)	Training Prec@5 100.000 (99.973)	
2022-05-11 16:21:15,188: ============================================================
2022-05-11 16:22:02,004: time cost, forward:0.1724965835606389, backward:0.10501401626931808, data cost:0.1905684510554166 
2022-05-11 16:22:02,004: ============================================================
2022-05-11 16:22:02,004: Epoch 26/38 Batch 7500/7662 eta: 11:58:41.497600	Training Loss 0.0942 (0.0918)	Training Prec@1 99.805 (99.917)	Training Prec@5 99.805 (99.973)	
2022-05-11 16:22:02,004: ============================================================
2022-05-11 16:22:48,930: time cost, forward:0.17250420636512023, backward:0.10501300571686124, data cost:0.19057359405529625 
2022-05-11 16:22:48,931: ============================================================
2022-05-11 16:22:48,931: Epoch 26/38 Batch 7600/7662 eta: 11:59:35.702222	Training Loss 0.0937 (0.0918)	Training Prec@1 99.609 (99.917)	Training Prec@5 99.805 (99.972)	
2022-05-11 16:22:48,931: ============================================================
2022-05-11 16:23:19,739: Epoch: 26/38 eta: 11:59:06.138501	Training Loss 0.1029 (0.0918)	Training Prec@1 99.805 (99.916)	Training Prec@5 100.000 (99.972)
2022-05-11 16:23:19,739: ============================================================
2022-05-11 16:24:10,593: time cost, forward:0.19386294153001574, backward:0.10534671099499018, data cost:0.21205379023696436 
2022-05-11 16:24:10,594: ============================================================
2022-05-11 16:24:10,594: Epoch 27/38 Batch 100/7662 eta: 12:58:25.161951	Training Loss 0.0835 (0.0829)	Training Prec@1 100.000 (99.941)	Training Prec@5 100.000 (99.980)	
2022-05-11 16:24:10,594: ============================================================
2022-05-11 16:24:58,825: time cost, forward:0.19070205496783232, backward:0.10503700869766312, data cost:0.20085052030170383 
2022-05-11 16:24:58,825: ============================================================
2022-05-11 16:24:58,825: Epoch 27/38 Batch 200/7662 eta: 12:17:29.737389	Training Loss 0.0827 (0.0833)	Training Prec@1 100.000 (99.945)	Training Prec@5 100.000 (99.979)	
2022-05-11 16:24:58,825: ============================================================
2022-05-11 16:25:46,884: time cost, forward:0.1890413577740009, backward:0.10496119830919348, data cost:0.1971557722442525 
2022-05-11 16:25:46,884: ============================================================
2022-05-11 16:25:46,884: Epoch 27/38 Batch 300/7662 eta: 12:14:03.757089	Training Loss 0.0872 (0.0835)	Training Prec@1 100.000 (99.945)	Training Prec@5 100.000 (99.979)	
2022-05-11 16:25:46,884: ============================================================
2022-05-11 16:26:34,856: time cost, forward:0.1878776430784909, backward:0.10492614576392305, data cost:0.19542112864348524 
2022-05-11 16:26:34,856: ============================================================
2022-05-11 16:26:34,856: Epoch 27/38 Batch 400/7662 eta: 12:11:56.159581	Training Loss 0.0861 (0.0836)	Training Prec@1 100.000 (99.946)	Training Prec@5 100.000 (99.979)	
2022-05-11 16:26:34,857: ============================================================
2022-05-11 16:27:22,159: time cost, forward:0.18588907971888602, backward:0.10491146162182152, data cost:0.19431199912795563 
2022-05-11 16:27:22,159: ============================================================
2022-05-11 16:27:22,159: Epoch 27/38 Batch 500/7662 eta: 12:00:55.928327	Training Loss 0.0849 (0.0837)	Training Prec@1 100.000 (99.942)	Training Prec@5 100.000 (99.980)	
2022-05-11 16:27:22,159: ============================================================
2022-05-11 16:28:08,853: time cost, forward:0.18344713252454448, backward:0.1049174538040798, data cost:0.19367076041105394 
2022-05-11 16:28:08,853: ============================================================
2022-05-11 16:28:08,854: Epoch 27/38 Batch 600/7662 eta: 11:50:53.112122	Training Loss 0.0842 (0.0840)	Training Prec@1 100.000 (99.940)	Training Prec@5 100.000 (99.979)	
2022-05-11 16:28:08,854: ============================================================
2022-05-11 16:28:55,558: time cost, forward:0.18173232678862258, backward:0.10493003349959083, data cost:0.19319091334363422 
2022-05-11 16:28:55,558: ============================================================
2022-05-11 16:28:55,558: Epoch 27/38 Batch 700/7662 eta: 11:50:15.589298	Training Loss 0.0865 (0.0840)	Training Prec@1 100.000 (99.940)	Training Prec@5 100.000 (99.978)	
2022-05-11 16:28:55,558: ============================================================
2022-05-11 16:29:42,308: time cost, forward:0.18048445930767418, backward:0.10494596429999092, data cost:0.19284462630375754 
2022-05-11 16:29:42,308: ============================================================
2022-05-11 16:29:42,308: Epoch 27/38 Batch 800/7662 eta: 11:50:10.236868	Training Loss 0.0821 (0.0842)	Training Prec@1 100.000 (99.940)	Training Prec@5 100.000 (99.978)	
2022-05-11 16:29:42,308: ============================================================
2022-05-11 16:30:28,988: time cost, forward:0.17949405793220766, backward:0.10495209853031214, data cost:0.1925241493674884 
2022-05-11 16:30:28,988: ============================================================
2022-05-11 16:30:28,988: Epoch 27/38 Batch 900/7662 eta: 11:48:19.884205	Training Loss 0.0842 (0.0843)	Training Prec@1 100.000 (99.940)	Training Prec@5 100.000 (99.978)	
2022-05-11 16:30:28,988: ============================================================
2022-05-11 16:31:15,772: time cost, forward:0.17872901674028155, backward:0.10495810919218473, data cost:0.19233223434921737 
2022-05-11 16:31:15,772: ============================================================
2022-05-11 16:31:15,772: Epoch 27/38 Batch 1000/7662 eta: 11:49:07.845764	Training Loss 0.0837 (0.0844)	Training Prec@1 100.000 (99.940)	Training Prec@5 100.000 (99.978)	
2022-05-11 16:31:15,772: ============================================================
2022-05-11 16:32:02,553: time cost, forward:0.17809916215120825, backward:0.10497083308156563, data cost:0.19217858062862156 
2022-05-11 16:32:02,553: ============================================================
2022-05-11 16:32:02,554: Epoch 27/38 Batch 1100/7662 eta: 11:48:18.439775	Training Loss 0.0824 (0.0846)	Training Prec@1 100.000 (99.941)	Training Prec@5 100.000 (99.978)	
2022-05-11 16:32:02,554: ============================================================
2022-05-11 16:32:49,309: time cost, forward:0.17758408797791445, backward:0.10498194201376361, data cost:0.19202079665571375 
2022-05-11 16:32:49,309: ============================================================
2022-05-11 16:32:49,309: Epoch 27/38 Batch 1200/7662 eta: 11:47:08.367900	Training Loss 0.0844 (0.0847)	Training Prec@1 100.000 (99.941)	Training Prec@5 100.000 (99.979)	
2022-05-11 16:32:49,309: ============================================================
2022-05-11 16:33:36,059: time cost, forward:0.17714310298065114, backward:0.10499552068937917, data cost:0.1918813477487542 
2022-05-11 16:33:36,059: ============================================================
2022-05-11 16:33:36,059: Epoch 27/38 Batch 1300/7662 eta: 11:46:16.315118	Training Loss 0.0878 (0.0849)	Training Prec@1 99.805 (99.943)	Training Prec@5 99.805 (99.979)	
2022-05-11 16:33:36,059: ============================================================
2022-05-11 16:34:22,805: time cost, forward:0.1767628022480897, backward:0.10500025885543114, data cost:0.19176285329931886 
2022-05-11 16:34:22,805: ============================================================
2022-05-11 16:34:22,806: Epoch 27/38 Batch 1400/7662 eta: 11:45:26.723355	Training Loss 0.0865 (0.0850)	Training Prec@1 100.000 (99.944)	Training Prec@5 100.000 (99.979)	
2022-05-11 16:34:22,806: ============================================================
2022-05-11 16:35:09,555: time cost, forward:0.17641628575849883, backward:0.10500428452342252, data cost:0.19168597972734996 
2022-05-11 16:35:09,555: ============================================================
2022-05-11 16:35:09,555: Epoch 27/38 Batch 1500/7662 eta: 11:44:42.741861	Training Loss 0.0842 (0.0851)	Training Prec@1 100.000 (99.942)	Training Prec@5 100.000 (99.978)	
2022-05-11 16:35:09,555: ============================================================
2022-05-11 16:35:56,247: time cost, forward:0.17607572885361816, backward:0.10500735860828163, data cost:0.1916169517855856 
2022-05-11 16:35:56,247: ============================================================
2022-05-11 16:35:56,247: Epoch 27/38 Batch 1600/7662 eta: 11:43:03.789960	Training Loss 0.0832 (0.0853)	Training Prec@1 100.000 (99.941)	Training Prec@5 100.000 (99.977)	
2022-05-11 16:35:56,247: ============================================================
2022-05-11 16:36:42,880: time cost, forward:0.17572930702537282, backward:0.10500533781450169, data cost:0.19157191512863941 
2022-05-11 16:36:42,880: ============================================================
2022-05-11 16:36:42,880: Epoch 27/38 Batch 1700/7662 eta: 11:41:24.217772	Training Loss 0.0851 (0.0854)	Training Prec@1 99.805 (99.940)	Training Prec@5 99.805 (99.977)	
2022-05-11 16:36:42,881: ============================================================
2022-05-11 16:37:29,530: time cost, forward:0.17543095863813027, backward:0.10500149292174546, data cost:0.19153142916354424 
2022-05-11 16:37:29,531: ============================================================
2022-05-11 16:37:29,531: Epoch 27/38 Batch 1800/7662 eta: 11:40:52.905436	Training Loss 0.0893 (0.0855)	Training Prec@1 99.609 (99.939)	Training Prec@5 99.805 (99.977)	
2022-05-11 16:37:29,531: ============================================================
2022-05-11 16:38:16,166: time cost, forward:0.17515922182795246, backward:0.10499585333970297, data cost:0.1914996812066133 
2022-05-11 16:38:16,166: ============================================================
2022-05-11 16:38:16,166: Epoch 27/38 Batch 1900/7662 eta: 11:39:53.081060	Training Loss 0.0834 (0.0856)	Training Prec@1 100.000 (99.939)	Training Prec@5 100.000 (99.977)	
2022-05-11 16:38:16,166: ============================================================
2022-05-11 16:39:02,688: time cost, forward:0.17485151355298773, backward:0.10499467212835391, data cost:0.19146563638264444 
2022-05-11 16:39:02,688: ============================================================
2022-05-11 16:39:02,688: Epoch 27/38 Batch 2000/7662 eta: 11:37:24.113250	Training Loss 0.0968 (0.0857)	Training Prec@1 99.805 (99.939)	Training Prec@5 100.000 (99.976)	
2022-05-11 16:39:02,688: ============================================================
2022-05-11 16:39:49,145: time cost, forward:0.1745504570779714, backward:0.10499166261019623, data cost:0.19143479787036882 
2022-05-11 16:39:49,146: ============================================================
2022-05-11 16:39:49,146: Epoch 27/38 Batch 2100/7662 eta: 11:35:40.033036	Training Loss 0.0912 (0.0858)	Training Prec@1 100.000 (99.938)	Training Prec@5 100.000 (99.976)	
2022-05-11 16:39:49,146: ============================================================
2022-05-11 16:40:35,618: time cost, forward:0.17427508383243936, backward:0.10499118479233864, data cost:0.19141077637509793 
2022-05-11 16:40:35,619: ============================================================
2022-05-11 16:40:35,619: Epoch 27/38 Batch 2200/7662 eta: 11:35:07.013091	Training Loss 0.0891 (0.0859)	Training Prec@1 100.000 (99.938)	Training Prec@5 100.000 (99.977)	
2022-05-11 16:40:35,619: ============================================================
2022-05-11 16:41:22,093: time cost, forward:0.17403710484763962, backward:0.1049924445390805, data cost:0.19137845562042594 
2022-05-11 16:41:22,093: ============================================================
2022-05-11 16:41:22,093: Epoch 27/38 Batch 2300/7662 eta: 11:34:21.702558	Training Loss 0.0934 (0.0860)	Training Prec@1 100.000 (99.938)	Training Prec@5 100.000 (99.976)	
2022-05-11 16:41:22,093: ============================================================
2022-05-11 16:42:08,609: time cost, forward:0.17383451946778514, backward:0.10498979738624258, data cost:0.1913514400631649 
2022-05-11 16:42:08,609: ============================================================
2022-05-11 16:42:08,609: Epoch 27/38 Batch 2400/7662 eta: 11:34:13.092749	Training Loss 0.0873 (0.0861)	Training Prec@1 100.000 (99.937)	Training Prec@5 100.000 (99.976)	
2022-05-11 16:42:08,610: ============================================================
2022-05-11 16:42:55,173: time cost, forward:0.1736654899462837, backward:0.1049862988904363, data cost:0.19133264525216215 
2022-05-11 16:42:55,173: ============================================================
2022-05-11 16:42:55,173: Epoch 27/38 Batch 2500/7662 eta: 11:34:09.127692	Training Loss 0.0870 (0.0862)	Training Prec@1 100.000 (99.937)	Training Prec@5 100.000 (99.976)	
2022-05-11 16:42:55,174: ============================================================
2022-05-11 16:43:41,787: time cost, forward:0.1735202364391343, backward:0.10498083596414857, data cost:0.19132598063816425 
2022-05-11 16:43:41,788: ============================================================
2022-05-11 16:43:41,788: Epoch 27/38 Batch 2600/7662 eta: 11:34:07.699078	Training Loss 0.0922 (0.0864)	Training Prec@1 100.000 (99.937)	Training Prec@5 100.000 (99.976)	
2022-05-11 16:43:41,788: ============================================================
2022-05-11 16:44:28,357: time cost, forward:0.17338226697497033, backward:0.10497892614027535, data cost:0.19129536822355425 
2022-05-11 16:44:28,358: ============================================================
2022-05-11 16:44:28,358: Epoch 27/38 Batch 2700/7662 eta: 11:32:41.390483	Training Loss 0.0967 (0.0865)	Training Prec@1 99.805 (99.936)	Training Prec@5 99.805 (99.976)	
2022-05-11 16:44:28,358: ============================================================
2022-05-11 16:45:14,899: time cost, forward:0.17324234639461145, backward:0.10498053399781407, data cost:0.1912709192192184 
2022-05-11 16:45:14,900: ============================================================
2022-05-11 16:45:14,900: Epoch 27/38 Batch 2800/7662 eta: 11:31:29.778384	Training Loss 0.0937 (0.0866)	Training Prec@1 100.000 (99.936)	Training Prec@5 100.000 (99.976)	
2022-05-11 16:45:14,900: ============================================================
2022-05-11 16:46:01,439: time cost, forward:0.173125581849892, backward:0.10498065461615687, data cost:0.19123993572920675 
2022-05-11 16:46:01,440: ============================================================
2022-05-11 16:46:01,440: Epoch 27/38 Batch 2900/7662 eta: 11:30:41.580119	Training Loss 0.0873 (0.0867)	Training Prec@1 99.414 (99.935)	Training Prec@5 99.414 (99.976)	
2022-05-11 16:46:01,440: ============================================================
2022-05-11 16:46:48,028: time cost, forward:0.17301689358145525, backward:0.1049826060902798, data cost:0.1912144675736588 
2022-05-11 16:46:48,028: ============================================================
2022-05-11 16:46:48,028: Epoch 27/38 Batch 3000/7662 eta: 11:30:38.042525	Training Loss 0.0891 (0.0868)	Training Prec@1 99.805 (99.936)	Training Prec@5 100.000 (99.976)	
2022-05-11 16:46:48,028: ============================================================
2022-05-11 16:47:34,705: time cost, forward:0.17295150366011033, backward:0.10497881451434726, data cost:0.19119245531328957 
2022-05-11 16:47:34,706: ============================================================
2022-05-11 16:47:34,706: Epoch 27/38 Batch 3100/7662 eta: 11:31:10.897711	Training Loss 0.0978 (0.0869)	Training Prec@1 99.805 (99.936)	Training Prec@5 99.805 (99.977)	
2022-05-11 16:47:34,706: ============================================================
2022-05-11 16:48:21,458: time cost, forward:0.17289536533671715, backward:0.10497066877006776, data cost:0.19119547396460412 
2022-05-11 16:48:21,459: ============================================================
2022-05-11 16:48:21,459: Epoch 27/38 Batch 3200/7662 eta: 11:31:30.659998	Training Loss 0.0841 (0.0870)	Training Prec@1 99.805 (99.937)	Training Prec@5 100.000 (99.977)	
2022-05-11 16:48:21,459: ============================================================
2022-05-11 16:49:08,138: time cost, forward:0.17283301311538016, backward:0.10496504829304983, data cost:0.19118260043648092 
2022-05-11 16:49:08,138: ============================================================
2022-05-11 16:49:08,138: Epoch 27/38 Batch 3300/7662 eta: 11:29:39.083022	Training Loss 0.0823 (0.0871)	Training Prec@1 100.000 (99.936)	Training Prec@5 100.000 (99.977)	
2022-05-11 16:49:08,138: ============================================================
2022-05-11 16:49:54,820: time cost, forward:0.17276877450676448, backward:0.1049583297717147, data cost:0.19118231266658073 
2022-05-11 16:49:54,821: ============================================================
2022-05-11 16:49:54,821: Epoch 27/38 Batch 3400/7662 eta: 11:28:55.090456	Training Loss 0.0840 (0.0872)	Training Prec@1 100.000 (99.936)	Training Prec@5 100.000 (99.977)	
2022-05-11 16:49:54,821: ============================================================
2022-05-11 16:50:41,474: time cost, forward:0.17270528653513606, backward:0.10495417933697086, data cost:0.19116864834011674 
2022-05-11 16:50:41,474: ============================================================
2022-05-11 16:50:41,474: Epoch 27/38 Batch 3500/7662 eta: 11:27:42.632687	Training Loss 0.0876 (0.0873)	Training Prec@1 99.805 (99.935)	Training Prec@5 100.000 (99.976)	
2022-05-11 16:50:41,474: ============================================================
2022-05-11 16:51:28,193: time cost, forward:0.1726520848492842, backward:0.10495195285450522, data cost:0.19116763705576614 
2022-05-11 16:51:28,193: ============================================================
2022-05-11 16:51:28,193: Epoch 27/38 Batch 3600/7662 eta: 11:27:53.849877	Training Loss 0.0856 (0.0874)	Training Prec@1 100.000 (99.935)	Training Prec@5 100.000 (99.976)	
2022-05-11 16:51:28,193: ============================================================
2022-05-11 16:52:14,834: time cost, forward:0.17259718366944168, backward:0.10495330417887783, data cost:0.1911446678216279 
2022-05-11 16:52:14,834: ============================================================
2022-05-11 16:52:14,835: Epoch 27/38 Batch 3700/7662 eta: 11:25:58.637244	Training Loss 0.0830 (0.0874)	Training Prec@1 100.000 (99.934)	Training Prec@5 100.000 (99.976)	
2022-05-11 16:52:14,835: ============================================================
2022-05-11 16:53:01,500: time cost, forward:0.1725563351560122, backward:0.10494933193625511, data cost:0.19112774572048605 
2022-05-11 16:53:01,501: ============================================================
2022-05-11 16:53:01,501: Epoch 27/38 Batch 3800/7662 eta: 11:25:33.929697	Training Loss 0.0921 (0.0875)	Training Prec@1 99.805 (99.934)	Training Prec@5 100.000 (99.976)	
2022-05-11 16:53:01,501: ============================================================
2022-05-11 16:53:48,236: time cost, forward:0.1725319994202208, backward:0.10495165825868515, data cost:0.19111032209570025 
2022-05-11 16:53:48,237: ============================================================
2022-05-11 16:53:48,237: Epoch 27/38 Batch 3900/7662 eta: 11:25:48.888423	Training Loss 0.0896 (0.0876)	Training Prec@1 100.000 (99.934)	Training Prec@5 100.000 (99.977)	
2022-05-11 16:53:48,237: ============================================================
2022-05-11 16:54:35,123: time cost, forward:0.17251677988886566, backward:0.10496194865233184, data cost:0.19110655587862418 
2022-05-11 16:54:35,124: ============================================================
2022-05-11 16:54:35,124: Epoch 27/38 Batch 4000/7662 eta: 11:27:14.807240	Training Loss 0.0929 (0.0877)	Training Prec@1 99.805 (99.934)	Training Prec@5 99.805 (99.977)	
2022-05-11 16:54:35,124: ============================================================
2022-05-11 16:55:22,146: time cost, forward:0.17250695075020903, backward:0.10499835153939405, data cost:0.19111009160609732 
2022-05-11 16:55:22,146: ============================================================
2022-05-11 16:55:22,146: Epoch 27/38 Batch 4100/7662 eta: 11:28:26.584036	Training Loss 0.0903 (0.0878)	Training Prec@1 100.000 (99.934)	Training Prec@5 100.000 (99.977)	
2022-05-11 16:55:22,146: ============================================================
2022-05-11 16:56:09,129: time cost, forward:0.1725169909968493, backward:0.10502441697644177, data cost:0.19109663602198043 
2022-05-11 16:56:09,130: ============================================================
2022-05-11 16:56:09,130: Epoch 27/38 Batch 4200/7662 eta: 11:27:05.760570	Training Loss 0.0908 (0.0879)	Training Prec@1 100.000 (99.934)	Training Prec@5 100.000 (99.977)	
2022-05-11 16:56:09,130: ============================================================
2022-05-11 16:56:56,075: time cost, forward:0.1725163168617669, backward:0.10505922596574967, data cost:0.19106973551350656 
2022-05-11 16:56:56,075: ============================================================
2022-05-11 16:56:56,076: Epoch 27/38 Batch 4300/7662 eta: 11:25:45.626825	Training Loss 0.0859 (0.0880)	Training Prec@1 100.000 (99.934)	Training Prec@5 100.000 (99.977)	
2022-05-11 16:56:56,076: ============================================================
2022-05-11 16:57:43,041: time cost, forward:0.17250833952527178, backward:0.10509197255052417, data cost:0.1910595758363967 
2022-05-11 16:57:43,041: ============================================================
2022-05-11 16:57:43,041: Epoch 27/38 Batch 4400/7662 eta: 11:25:16.176673	Training Loss 0.0930 (0.0880)	Training Prec@1 99.609 (99.933)	Training Prec@5 99.805 (99.977)	
2022-05-11 16:57:43,041: ============================================================
2022-05-11 16:58:30,044: time cost, forward:0.17251287913105173, backward:0.1051255172823609, data cost:0.19104364787930778 
2022-05-11 16:58:30,045: ============================================================
2022-05-11 16:58:30,045: Epoch 27/38 Batch 4500/7662 eta: 11:25:02.320016	Training Loss 0.0896 (0.0881)	Training Prec@1 99.805 (99.933)	Training Prec@5 100.000 (99.977)	
2022-05-11 16:58:30,045: ============================================================
2022-05-11 16:59:16,986: time cost, forward:0.17250748804585522, backward:0.10515593824036149, data cost:0.1910265165973057 
2022-05-11 16:59:16,986: ============================================================
2022-05-11 16:59:16,986: Epoch 27/38 Batch 4600/7662 eta: 11:23:20.869248	Training Loss 0.0978 (0.0882)	Training Prec@1 99.609 (99.932)	Training Prec@5 100.000 (99.976)	
2022-05-11 16:59:16,986: ============================================================
2022-05-11 17:00:03,916: time cost, forward:0.17251774071886022, backward:0.10515747107858733, data cost:0.19101920653515914 
2022-05-11 17:00:03,916: ============================================================
2022-05-11 17:00:03,916: Epoch 27/38 Batch 4700/7662 eta: 11:22:24.241637	Training Loss 0.0916 (0.0883)	Training Prec@1 99.805 (99.932)	Training Prec@5 99.805 (99.976)	
2022-05-11 17:00:03,916: ============================================================
2022-05-11 17:00:50,747: time cost, forward:0.17251250152166597, backward:0.10515259096686555, data cost:0.19101384282733133 
2022-05-11 17:00:50,747: ============================================================
2022-05-11 17:00:50,747: Epoch 27/38 Batch 4800/7662 eta: 11:20:10.707981	Training Loss 0.0955 (0.0884)	Training Prec@1 100.000 (99.932)	Training Prec@5 100.000 (99.976)	
2022-05-11 17:00:50,747: ============================================================
2022-05-11 17:01:37,494: time cost, forward:0.17250292270517903, backward:0.1051488997231067, data cost:0.1909968985857149 
2022-05-11 17:01:37,494: ============================================================
2022-05-11 17:01:37,494: Epoch 27/38 Batch 4900/7662 eta: 11:18:10.755126	Training Loss 0.0893 (0.0885)	Training Prec@1 100.000 (99.932)	Training Prec@5 100.000 (99.976)	
2022-05-11 17:01:37,494: ============================================================
2022-05-11 17:02:24,274: time cost, forward:0.1724989282104773, backward:0.10514705895089846, data cost:0.1909804844956418 
2022-05-11 17:02:24,275: ============================================================
2022-05-11 17:02:24,275: Epoch 27/38 Batch 5000/7662 eta: 11:17:53.614121	Training Loss 0.0918 (0.0886)	Training Prec@1 100.000 (99.931)	Training Prec@5 100.000 (99.976)	
2022-05-11 17:02:24,275: ============================================================
2022-05-11 17:03:11,115: time cost, forward:0.1724958421202542, backward:0.10514358282790602, data cost:0.1909776108946186 
2022-05-11 17:03:11,115: ============================================================
2022-05-11 17:03:11,115: Epoch 27/38 Batch 5100/7662 eta: 11:17:58.654895	Training Loss 0.0914 (0.0886)	Training Prec@1 100.000 (99.931)	Training Prec@5 100.000 (99.976)	
2022-05-11 17:03:11,115: ============================================================
2022-05-11 17:03:57,932: time cost, forward:0.1724966203829352, backward:0.10513924048207865, data cost:0.19096782923340913 
2022-05-11 17:03:57,933: ============================================================
2022-05-11 17:03:57,933: Epoch 27/38 Batch 5200/7662 eta: 11:16:51.865085	Training Loss 0.1014 (0.0887)	Training Prec@1 100.000 (99.930)	Training Prec@5 100.000 (99.976)	
2022-05-11 17:03:57,933: ============================================================
2022-05-11 17:04:44,700: time cost, forward:0.17249847160327839, backward:0.10513409071765906, data cost:0.19094844200989508 
2022-05-11 17:04:44,700: ============================================================
2022-05-11 17:04:44,701: Epoch 27/38 Batch 5300/7662 eta: 11:15:21.837477	Training Loss 0.0959 (0.0888)	Training Prec@1 100.000 (99.929)	Training Prec@5 100.000 (99.976)	
2022-05-11 17:04:44,701: ============================================================
2022-05-11 17:05:31,633: time cost, forward:0.17249794791508305, backward:0.10515514093983017, data cost:0.1909372409111174 
2022-05-11 17:05:31,634: ============================================================
2022-05-11 17:05:31,634: Epoch 27/38 Batch 5400/7662 eta: 11:16:58.472578	Training Loss 0.0887 (0.0888)	Training Prec@1 100.000 (99.930)	Training Prec@5 100.000 (99.976)	
2022-05-11 17:05:31,634: ============================================================
2022-05-11 17:06:18,576: time cost, forward:0.17249708271911088, backward:0.1051790642291768, data cost:0.1909243387186564 
2022-05-11 17:06:18,576: ============================================================
2022-05-11 17:06:18,576: Epoch 27/38 Batch 5500/7662 eta: 11:16:19.073448	Training Loss 0.1005 (0.0889)	Training Prec@1 100.000 (99.929)	Training Prec@5 100.000 (99.976)	
2022-05-11 17:06:18,576: ============================================================
2022-05-11 17:07:05,379: time cost, forward:0.17249554645846968, backward:0.1051744637180171, data cost:0.19091571452554199 
2022-05-11 17:07:05,379: ============================================================
2022-05-11 17:07:05,379: Epoch 27/38 Batch 5600/7662 eta: 11:13:32.260513	Training Loss 0.0984 (0.0890)	Training Prec@1 100.000 (99.929)	Training Prec@5 100.000 (99.976)	
2022-05-11 17:07:05,379: ============================================================
2022-05-11 17:07:52,145: time cost, forward:0.1724903016660188, backward:0.10517051826968363, data cost:0.19090377102611064 
2022-05-11 17:07:52,145: ============================================================
2022-05-11 17:07:52,145: Epoch 27/38 Batch 5700/7662 eta: 11:12:13.310614	Training Loss 0.0946 (0.0891)	Training Prec@1 99.805 (99.929)	Training Prec@5 100.000 (99.976)	
2022-05-11 17:07:52,145: ============================================================
2022-05-11 17:08:38,992: time cost, forward:0.17249485705922155, backward:0.10516624833863653, data cost:0.19089305213780872 
2022-05-11 17:08:38,992: ============================================================
2022-05-11 17:08:38,993: Epoch 27/38 Batch 5800/7662 eta: 11:12:36.684677	Training Loss 0.0976 (0.0892)	Training Prec@1 100.000 (99.929)	Training Prec@5 100.000 (99.976)	
2022-05-11 17:08:38,993: ============================================================
2022-05-11 17:09:25,745: time cost, forward:0.1724921145829574, backward:0.10516254338880256, data cost:0.1908783508490902 
2022-05-11 17:09:25,745: ============================================================
2022-05-11 17:09:25,745: Epoch 27/38 Batch 5900/7662 eta: 11:10:28.319353	Training Loss 0.0993 (0.0892)	Training Prec@1 100.000 (99.929)	Training Prec@5 100.000 (99.976)	
2022-05-11 17:09:25,745: ============================================================
2022-05-11 17:10:12,476: time cost, forward:0.17248953002793607, backward:0.10516008922985781, data cost:0.19085904724857453 
2022-05-11 17:10:12,476: ============================================================
2022-05-11 17:10:12,477: Epoch 27/38 Batch 6000/7662 eta: 11:09:23.151748	Training Loss 0.0917 (0.0893)	Training Prec@1 100.000 (99.928)	Training Prec@5 100.000 (99.975)	
2022-05-11 17:10:12,477: ============================================================
2022-05-11 17:10:59,185: time cost, forward:0.172481309274979, backward:0.10515587187962643, data cost:0.19084192342612757 
2022-05-11 17:10:59,186: ============================================================
2022-05-11 17:10:59,186: Epoch 27/38 Batch 6100/7662 eta: 11:08:17.615608	Training Loss 0.0973 (0.0894)	Training Prec@1 99.805 (99.928)	Training Prec@5 100.000 (99.975)	
2022-05-11 17:10:59,186: ============================================================
2022-05-11 17:11:45,922: time cost, forward:0.17247659534307272, backward:0.10515173701898459, data cost:0.1908268585072773 
2022-05-11 17:11:45,923: ============================================================
2022-05-11 17:11:45,923: Epoch 27/38 Batch 6200/7662 eta: 11:07:54.652906	Training Loss 0.0950 (0.0895)	Training Prec@1 100.000 (99.928)	Training Prec@5 100.000 (99.975)	
2022-05-11 17:11:45,923: ============================================================
2022-05-11 17:12:32,682: time cost, forward:0.17247541746765419, backward:0.10514794597362295, data cost:0.19081385950566018 
2022-05-11 17:12:32,682: ============================================================
2022-05-11 17:12:32,682: Epoch 27/38 Batch 6300/7662 eta: 11:07:27.234239	Training Loss 0.0914 (0.0896)	Training Prec@1 100.000 (99.927)	Training Prec@5 100.000 (99.975)	
2022-05-11 17:12:32,683: ============================================================
2022-05-11 17:13:19,394: time cost, forward:0.17247083399850588, backward:0.10514461049662473, data cost:0.190797244185376 
2022-05-11 17:13:19,394: ============================================================
2022-05-11 17:13:19,395: Epoch 27/38 Batch 6400/7662 eta: 11:05:59.895951	Training Loss 0.0895 (0.0896)	Training Prec@1 100.000 (99.927)	Training Prec@5 100.000 (99.975)	
2022-05-11 17:13:19,395: ============================================================
2022-05-11 17:14:06,122: time cost, forward:0.17247015748652775, backward:0.10514175497507898, data cost:0.19077762957260525 
2022-05-11 17:14:06,122: ============================================================
2022-05-11 17:14:06,123: Epoch 27/38 Batch 6500/7662 eta: 11:05:26.711016	Training Loss 0.1007 (0.0897)	Training Prec@1 99.805 (99.927)	Training Prec@5 99.805 (99.975)	
2022-05-11 17:14:06,123: ============================================================
2022-05-11 17:14:52,892: time cost, forward:0.1724688292525179, backward:0.10514011970522331, data cost:0.1907666336859622 
2022-05-11 17:14:52,892: ============================================================
2022-05-11 17:14:52,892: Epoch 27/38 Batch 6600/7662 eta: 11:05:15.703671	Training Loss 0.0948 (0.0898)	Training Prec@1 99.805 (99.927)	Training Prec@5 100.000 (99.975)	
2022-05-11 17:14:52,892: ============================================================
2022-05-11 17:15:39,685: time cost, forward:0.17246760566086178, backward:0.10513775838740033, data cost:0.19076060522739738 
2022-05-11 17:15:39,685: ============================================================
2022-05-11 17:15:39,686: Epoch 27/38 Batch 6700/7662 eta: 11:04:48.854411	Training Loss 0.0932 (0.0898)	Training Prec@1 99.805 (99.927)	Training Prec@5 100.000 (99.975)	
2022-05-11 17:15:39,686: ============================================================
2022-05-11 17:16:26,541: time cost, forward:0.17246757316000236, backward:0.10513557706059454, data cost:0.19076189589440815 
2022-05-11 17:16:26,541: ============================================================
2022-05-11 17:16:26,542: Epoch 27/38 Batch 6800/7662 eta: 11:04:55.621949	Training Loss 0.0929 (0.0899)	Training Prec@1 100.000 (99.926)	Training Prec@5 100.000 (99.975)	
2022-05-11 17:16:26,542: ============================================================
2022-05-11 17:17:13,328: time cost, forward:0.17246837497776982, backward:0.10513324968399113, data cost:0.19075120879456797 
2022-05-11 17:17:13,328: ============================================================
2022-05-11 17:17:13,329: Epoch 27/38 Batch 6900/7662 eta: 11:03:09.995178	Training Loss 0.0974 (0.0900)	Training Prec@1 100.000 (99.926)	Training Prec@5 100.000 (99.975)	
2022-05-11 17:17:13,329: ============================================================
2022-05-11 17:18:00,109: time cost, forward:0.1724630292270299, backward:0.10512915885964536, data cost:0.19074962860959857 
2022-05-11 17:18:00,109: ============================================================
2022-05-11 17:18:00,109: Epoch 27/38 Batch 7000/7662 eta: 11:02:17.729086	Training Loss 0.0922 (0.0900)	Training Prec@1 100.000 (99.926)	Training Prec@5 100.000 (99.975)	
2022-05-11 17:18:00,109: ============================================================
2022-05-11 17:18:46,940: time cost, forward:0.1724631546550879, backward:0.10512522899494958, data cost:0.19074760596338067 
2022-05-11 17:18:46,940: ============================================================
2022-05-11 17:18:46,941: Epoch 27/38 Batch 7100/7662 eta: 11:02:14.108138	Training Loss 0.0907 (0.0901)	Training Prec@1 100.000 (99.925)	Training Prec@5 100.000 (99.975)	
2022-05-11 17:18:46,941: ============================================================
2022-05-11 17:19:33,765: time cost, forward:0.1724612699281608, backward:0.10512125785192826, data cost:0.19074818080854938 
2022-05-11 17:19:33,765: ============================================================
2022-05-11 17:19:33,765: Epoch 27/38 Batch 7200/7662 eta: 11:01:21.569687	Training Loss 0.0939 (0.0902)	Training Prec@1 100.000 (99.925)	Training Prec@5 100.000 (99.975)	
2022-05-11 17:19:33,765: ============================================================
2022-05-11 17:20:20,584: time cost, forward:0.17246090256852603, backward:0.10511917838626961, data cost:0.1907449533946221 
2022-05-11 17:20:20,585: ============================================================
2022-05-11 17:20:20,585: Epoch 27/38 Batch 7300/7662 eta: 11:00:30.442639	Training Loss 0.1029 (0.0902)	Training Prec@1 100.000 (99.924)	Training Prec@5 100.000 (99.975)	
2022-05-11 17:20:20,585: ============================================================
2022-05-11 17:21:07,415: time cost, forward:0.17245966248422687, backward:0.10512779399919774, data cost:0.19073360741887646 
2022-05-11 17:21:07,415: ============================================================
2022-05-11 17:21:07,415: Epoch 27/38 Batch 7400/7662 eta: 10:59:52.762276	Training Loss 0.0955 (0.0903)	Training Prec@1 100.000 (99.924)	Training Prec@5 100.000 (99.975)	
2022-05-11 17:21:07,415: ============================================================
2022-05-11 17:21:54,073: time cost, forward:0.17245232310195274, backward:0.10512620586604338, data cost:0.19071608375654106 
2022-05-11 17:21:54,074: ============================================================
2022-05-11 17:21:54,074: Epoch 27/38 Batch 7500/7662 eta: 10:56:40.751765	Training Loss 0.0961 (0.0904)	Training Prec@1 99.609 (99.924)	Training Prec@5 99.805 (99.975)	
2022-05-11 17:21:54,074: ============================================================
2022-05-11 17:22:40,776: time cost, forward:0.1724442616467853, backward:0.10512343352210257, data cost:0.19070681955864877 
2022-05-11 17:22:40,776: ============================================================
2022-05-11 17:22:40,776: Epoch 27/38 Batch 7600/7662 eta: 10:56:31.060023	Training Loss 0.0982 (0.0905)	Training Prec@1 99.609 (99.924)	Training Prec@5 99.805 (99.975)	
2022-05-11 17:22:40,776: ============================================================
2022-05-11 17:23:11,505: Epoch: 27/38 eta: 10:56:01.637570	Training Loss 0.1014 (0.0905)	Training Prec@1 100.000 (99.924)	Training Prec@5 100.000 (99.975)
2022-05-11 17:23:11,505: ============================================================
2022-05-11 17:24:00,127: time cost, forward:0.17344674919590805, backward:0.10457175669043955, data cost:0.21006254957179832 
2022-05-11 17:24:00,128: ============================================================
2022-05-11 17:24:00,128: Epoch 28/38 Batch 100/7662 eta: 11:20:56.884013	Training Loss 0.0803 (0.0822)	Training Prec@1 100.000 (99.951)	Training Prec@5 100.000 (99.982)	
2022-05-11 17:24:00,128: ============================================================
2022-05-11 17:24:46,877: time cost, forward:0.17256901611634834, backward:0.10466084528208977, data cost:0.20038697827401472 
2022-05-11 17:24:46,877: ============================================================
2022-05-11 17:24:46,878: Epoch 28/38 Batch 200/7662 eta: 10:55:08.514826	Training Loss 0.0777 (0.0818)	Training Prec@1 100.000 (99.950)	Training Prec@5 100.000 (99.980)	
2022-05-11 17:24:46,878: ============================================================
2022-05-11 17:25:33,639: time cost, forward:0.17225732532233298, backward:0.10470947134853606, data cost:0.19710341504584986 
2022-05-11 17:25:33,640: ============================================================
2022-05-11 17:25:33,640: Epoch 28/38 Batch 300/7662 eta: 10:54:32.853565	Training Loss 0.0827 (0.0821)	Training Prec@1 99.805 (99.945)	Training Prec@5 100.000 (99.981)	
2022-05-11 17:25:33,641: ============================================================
2022-05-11 17:26:20,540: time cost, forward:0.17208574648787803, backward:0.10512377564470869, data cost:0.19552812420933469 
2022-05-11 17:26:20,541: ============================================================
2022-05-11 17:26:20,541: Epoch 28/38 Batch 400/7662 eta: 10:55:41.537065	Training Loss 0.0830 (0.0822)	Training Prec@1 100.000 (99.945)	Training Prec@5 100.000 (99.980)	
2022-05-11 17:26:20,541: ============================================================
2022-05-11 17:27:07,373: time cost, forward:0.17197218399965214, backward:0.10538050836933878, data cost:0.1944501920787987 
2022-05-11 17:27:07,374: ============================================================
2022-05-11 17:27:07,374: Epoch 28/38 Batch 500/7662 eta: 10:53:57.975487	Training Loss 0.0832 (0.0824)	Training Prec@1 99.805 (99.942)	Training Prec@5 100.000 (99.980)	
2022-05-11 17:27:07,374: ============================================================
2022-05-11 17:27:54,236: time cost, forward:0.17193400760325844, backward:0.10554617593602864, data cost:0.19375605057794382 
2022-05-11 17:27:54,237: ============================================================
2022-05-11 17:27:54,237: Epoch 28/38 Batch 600/7662 eta: 10:53:36.615809	Training Loss 0.0793 (0.0824)	Training Prec@1 100.000 (99.944)	Training Prec@5 100.000 (99.980)	
2022-05-11 17:27:54,237: ============================================================
2022-05-11 17:28:41,136: time cost, forward:0.17193865434976777, backward:0.1056807228765092, data cost:0.1932461080974093 
2022-05-11 17:28:41,136: ============================================================
2022-05-11 17:28:41,136: Epoch 28/38 Batch 700/7662 eta: 10:53:19.649499	Training Loss 0.0809 (0.0826)	Training Prec@1 99.805 (99.944)	Training Prec@5 100.000 (99.980)	
2022-05-11 17:28:41,136: ============================================================
2022-05-11 17:29:28,043: time cost, forward:0.17195535989219465, backward:0.10577548818385347, data cost:0.19288015216402477 
2022-05-11 17:29:28,043: ============================================================
2022-05-11 17:29:28,043: Epoch 28/38 Batch 800/7662 eta: 10:52:39.531290	Training Loss 0.0805 (0.0826)	Training Prec@1 100.000 (99.945)	Training Prec@5 100.000 (99.981)	
2022-05-11 17:29:28,043: ============================================================
2022-05-11 17:30:14,918: time cost, forward:0.17198756406781937, backward:0.10582040732641507, data cost:0.1925710231496707 
2022-05-11 17:30:14,919: ============================================================
2022-05-11 17:30:14,919: Epoch 28/38 Batch 900/7662 eta: 10:51:26.140483	Training Loss 0.0812 (0.0828)	Training Prec@1 100.000 (99.944)	Training Prec@5 100.000 (99.982)	
2022-05-11 17:30:14,919: ============================================================
2022-05-11 17:31:01,652: time cost, forward:0.1719730048327594, backward:0.10572339297534229, data cost:0.19235486526031037 
2022-05-11 17:31:01,652: ============================================================
2022-05-11 17:31:01,652: Epoch 28/38 Batch 1000/7662 eta: 10:48:41.060212	Training Loss 0.0843 (0.0830)	Training Prec@1 99.805 (99.945)	Training Prec@5 100.000 (99.982)	
2022-05-11 17:31:01,652: ============================================================
2022-05-11 17:31:48,389: time cost, forward:0.17195292621227262, backward:0.10563799812101689, data cost:0.19219679025436553 
2022-05-11 17:31:48,389: ============================================================
2022-05-11 17:31:48,389: Epoch 28/38 Batch 1100/7662 eta: 10:47:57.251592	Training Loss 0.0903 (0.0832)	Training Prec@1 99.609 (99.943)	Training Prec@5 99.609 (99.982)	
2022-05-11 17:31:48,389: ============================================================
2022-05-11 17:32:35,101: time cost, forward:0.17192955868158666, backward:0.10556054711838977, data cost:0.1920547608637233 
2022-05-11 17:32:35,101: ============================================================
2022-05-11 17:32:35,102: Epoch 28/38 Batch 1200/7662 eta: 10:46:49.912515	Training Loss 0.0899 (0.0833)	Training Prec@1 100.000 (99.942)	Training Prec@5 100.000 (99.982)	
2022-05-11 17:32:35,102: ============================================================
2022-05-11 17:33:21,807: time cost, forward:0.171910103694396, backward:0.10549695111862782, data cost:0.19192923207389473 
2022-05-11 17:33:21,808: ============================================================
2022-05-11 17:33:21,808: Epoch 28/38 Batch 1300/7662 eta: 10:45:58.234736	Training Loss 0.0916 (0.0834)	Training Prec@1 99.805 (99.942)	Training Prec@5 99.805 (99.982)	
2022-05-11 17:33:21,808: ============================================================
2022-05-11 17:34:08,559: time cost, forward:0.171891306024351, backward:0.10543857292246188, data cost:0.19185854879083422 
2022-05-11 17:34:08,560: ============================================================
2022-05-11 17:34:08,560: Epoch 28/38 Batch 1400/7662 eta: 10:45:49.611210	Training Loss 0.0837 (0.0835)	Training Prec@1 100.000 (99.943)	Training Prec@5 100.000 (99.982)	
2022-05-11 17:34:08,560: ============================================================
2022-05-11 17:34:55,435: time cost, forward:0.17189597558625305, backward:0.10539674202229994, data cost:0.19183526252252886 
2022-05-11 17:34:55,435: ============================================================
2022-05-11 17:34:55,435: Epoch 28/38 Batch 1500/7662 eta: 10:46:44.905266	Training Loss 0.0901 (0.0837)	Training Prec@1 100.000 (99.944)	Training Prec@5 100.000 (99.982)	
2022-05-11 17:34:55,435: ============================================================
2022-05-11 17:35:42,264: time cost, forward:0.17189101340846766, backward:0.10535592791287134, data cost:0.19179832570026487 
2022-05-11 17:35:42,264: ============================================================
2022-05-11 17:35:42,265: Epoch 28/38 Batch 1600/7662 eta: 10:45:19.845417	Training Loss 0.0837 (0.0839)	Training Prec@1 100.000 (99.943)	Training Prec@5 100.000 (99.982)	
2022-05-11 17:35:42,265: ============================================================
2022-05-11 17:36:29,061: time cost, forward:0.1718860055643927, backward:0.10531566450355893, data cost:0.19176016771631987 
2022-05-11 17:36:29,061: ============================================================
2022-05-11 17:36:29,062: Epoch 28/38 Batch 1700/7662 eta: 10:44:06.309945	Training Loss 0.0898 (0.0840)	Training Prec@1 100.000 (99.942)	Training Prec@5 100.000 (99.982)	
2022-05-11 17:36:29,062: ============================================================
2022-05-11 17:37:15,880: time cost, forward:0.17187059197311869, backward:0.10528100457968084, data cost:0.19174042789720044 
2022-05-11 17:37:15,880: ============================================================
2022-05-11 17:37:15,880: Epoch 28/38 Batch 1800/7662 eta: 10:43:37.520497	Training Loss 0.0826 (0.0841)	Training Prec@1 100.000 (99.942)	Training Prec@5 100.000 (99.981)	
2022-05-11 17:37:15,880: ============================================================
2022-05-11 17:38:02,718: time cost, forward:0.17187193797223502, backward:0.10526128465593207, data cost:0.19170604836884267 
2022-05-11 17:38:02,719: ============================================================
2022-05-11 17:38:02,719: Epoch 28/38 Batch 1900/7662 eta: 10:43:06.949100	Training Loss 0.0930 (0.0842)	Training Prec@1 99.805 (99.942)	Training Prec@5 100.000 (99.981)	
2022-05-11 17:38:02,719: ============================================================
2022-05-11 17:38:49,556: time cost, forward:0.1718726840360335, backward:0.10524085535294656, data cost:0.19168180427055112 
2022-05-11 17:38:49,556: ============================================================
2022-05-11 17:38:49,556: Epoch 28/38 Batch 2000/7662 eta: 10:42:19.187009	Training Loss 0.0884 (0.0843)	Training Prec@1 99.805 (99.942)	Training Prec@5 100.000 (99.981)	
2022-05-11 17:38:49,556: ============================================================
2022-05-11 17:39:36,384: time cost, forward:0.17186123555816316, backward:0.10522303313173073, data cost:0.19166110991977295 
2022-05-11 17:39:36,385: ============================================================
2022-05-11 17:39:36,385: Epoch 28/38 Batch 2100/7662 eta: 10:41:25.182178	Training Loss 0.0826 (0.0844)	Training Prec@1 100.000 (99.942)	Training Prec@5 100.000 (99.981)	
2022-05-11 17:39:36,385: ============================================================
2022-05-11 17:40:23,168: time cost, forward:0.17185458577508653, backward:0.1052057295292277, data cost:0.1916268842227896 
2022-05-11 17:40:23,169: ============================================================
2022-05-11 17:40:23,169: Epoch 28/38 Batch 2200/7662 eta: 10:40:01.728854	Training Loss 0.0914 (0.0845)	Training Prec@1 100.000 (99.942)	Training Prec@5 100.000 (99.980)	
2022-05-11 17:40:23,169: ============================================================
2022-05-11 17:41:09,904: time cost, forward:0.1718301502400349, backward:0.10519168635148907, data cost:0.19159741451450926 
2022-05-11 17:41:09,905: ============================================================
2022-05-11 17:41:09,905: Epoch 28/38 Batch 2300/7662 eta: 10:38:35.512773	Training Loss 0.0864 (0.0846)	Training Prec@1 100.000 (99.941)	Training Prec@5 100.000 (99.980)	
2022-05-11 17:41:09,905: ============================================================
2022-05-11 17:41:56,617: time cost, forward:0.1717884742304304, backward:0.10517669121589994, data cost:0.1915811786754969 
2022-05-11 17:41:56,617: ============================================================
2022-05-11 17:41:56,617: Epoch 28/38 Batch 2400/7662 eta: 10:37:29.538667	Training Loss 0.0918 (0.0847)	Training Prec@1 100.000 (99.941)	Training Prec@5 100.000 (99.980)	
2022-05-11 17:41:56,617: ============================================================
2022-05-11 17:42:43,398: time cost, forward:0.1717666098002006, backward:0.10516226258264537, data cost:0.19157787531363865 
2022-05-11 17:42:43,398: ============================================================
2022-05-11 17:42:43,398: Epoch 28/38 Batch 2500/7662 eta: 10:37:39.084534	Training Loss 0.0870 (0.0848)	Training Prec@1 100.000 (99.940)	Training Prec@5 100.000 (99.980)	
2022-05-11 17:42:43,399: ============================================================
2022-05-11 17:43:30,177: time cost, forward:0.1717452986417435, backward:0.10515290445986047, data cost:0.19156677386264426 
2022-05-11 17:43:30,177: ============================================================
2022-05-11 17:43:30,177: Epoch 28/38 Batch 2600/7662 eta: 10:36:50.380768	Training Loss 0.0920 (0.0850)	Training Prec@1 99.609 (99.940)	Training Prec@5 99.805 (99.980)	
2022-05-11 17:43:30,177: ============================================================
2022-05-11 17:44:16,898: time cost, forward:0.171728676802673, backward:0.10514386966079198, data cost:0.19153656929499488 
2022-05-11 17:44:16,898: ============================================================
2022-05-11 17:44:16,898: Epoch 28/38 Batch 2700/7662 eta: 10:35:16.074010	Training Loss 0.0905 (0.0851)	Training Prec@1 100.000 (99.940)	Training Prec@5 100.000 (99.980)	
2022-05-11 17:44:16,898: ============================================================
2022-05-11 17:45:03,631: time cost, forward:0.1717177632452122, backward:0.10513368024277492, data cost:0.19151088619879544 
2022-05-11 17:45:03,631: ============================================================
2022-05-11 17:45:03,631: Epoch 28/38 Batch 2800/7662 eta: 10:34:39.652076	Training Loss 0.0890 (0.0852)	Training Prec@1 100.000 (99.940)	Training Prec@5 100.000 (99.980)	
2022-05-11 17:45:03,631: ============================================================
2022-05-11 17:45:50,418: time cost, forward:0.171712962789098, backward:0.10512672839143351, data cost:0.1914973520500654 
2022-05-11 17:45:50,419: ============================================================
2022-05-11 17:45:50,419: Epoch 28/38 Batch 2900/7662 eta: 10:34:37.215601	Training Loss 0.0900 (0.0853)	Training Prec@1 99.805 (99.940)	Training Prec@5 100.000 (99.980)	
2022-05-11 17:45:50,419: ============================================================
2022-05-11 17:46:37,179: time cost, forward:0.17171345483704223, backward:0.10511865350316865, data cost:0.1914692576943576 
2022-05-11 17:46:37,179: ============================================================
2022-05-11 17:46:37,179: Epoch 28/38 Batch 3000/7662 eta: 10:33:28.072455	Training Loss 0.0939 (0.0854)	Training Prec@1 100.000 (99.939)	Training Prec@5 100.000 (99.980)	
2022-05-11 17:46:37,179: ============================================================
2022-05-11 17:47:23,929: time cost, forward:0.17171081099520963, backward:0.10510809131497989, data cost:0.19144891815517903 
2022-05-11 17:47:23,930: ============================================================
2022-05-11 17:47:23,930: Epoch 28/38 Batch 3100/7662 eta: 10:32:33.607423	Training Loss 0.0929 (0.0855)	Training Prec@1 99.805 (99.939)	Training Prec@5 100.000 (99.980)	
2022-05-11 17:47:23,930: ============================================================
2022-05-11 17:48:10,718: time cost, forward:0.17170099565184613, backward:0.10509985049987965, data cost:0.19144445503082227 
2022-05-11 17:48:10,718: ============================================================
2022-05-11 17:48:10,718: Epoch 28/38 Batch 3200/7662 eta: 10:32:17.433873	Training Loss 0.0819 (0.0856)	Training Prec@1 100.000 (99.939)	Training Prec@5 100.000 (99.980)	
2022-05-11 17:48:10,718: ============================================================
2022-05-11 17:48:57,526: time cost, forward:0.17169814096793654, backward:0.10509227253733783, data cost:0.19144243542155776 
2022-05-11 17:48:57,526: ============================================================
2022-05-11 17:48:57,526: Epoch 28/38 Batch 3300/7662 eta: 10:31:46.498962	Training Loss 0.0860 (0.0857)	Training Prec@1 99.805 (99.938)	Training Prec@5 100.000 (99.981)	
2022-05-11 17:48:57,526: ============================================================
2022-05-11 17:49:44,357: time cost, forward:0.17169570277529136, backward:0.10508160129579666, data cost:0.19144715425301104 
2022-05-11 17:49:44,358: ============================================================
2022-05-11 17:49:44,358: Epoch 28/38 Batch 3400/7662 eta: 10:31:18.827093	Training Loss 0.0896 (0.0858)	Training Prec@1 100.000 (99.938)	Training Prec@5 100.000 (99.981)	
2022-05-11 17:49:44,358: ============================================================
2022-05-11 17:50:31,187: time cost, forward:0.1716994380705627, backward:0.10507113976490842, data cost:0.19144590761566815 
2022-05-11 17:50:31,187: ============================================================
2022-05-11 17:50:31,187: Epoch 28/38 Batch 3500/7662 eta: 10:30:30.369135	Training Loss 0.0857 (0.0859)	Training Prec@1 100.000 (99.938)	Training Prec@5 100.000 (99.980)	
2022-05-11 17:50:31,200: ============================================================
2022-05-11 17:51:18,032: time cost, forward:0.1717060317129319, backward:0.10506194112830176, data cost:0.1914444937577477 
2022-05-11 17:51:18,033: ============================================================
2022-05-11 17:51:18,033: Epoch 28/38 Batch 3600/7662 eta: 10:29:56.455942	Training Loss 0.0864 (0.0860)	Training Prec@1 100.000 (99.938)	Training Prec@5 100.000 (99.980)	
2022-05-11 17:51:18,033: ============================================================
2022-05-11 17:52:04,812: time cost, forward:0.17170022487253653, backward:0.10505528152230689, data cost:0.19143476992821365 
2022-05-11 17:52:04,812: ============================================================
2022-05-11 17:52:04,812: Epoch 28/38 Batch 3700/7662 eta: 10:28:16.315461	Training Loss 0.0895 (0.0861)	Training Prec@1 100.000 (99.937)	Training Prec@5 100.000 (99.980)	
2022-05-11 17:52:04,813: ============================================================
2022-05-11 17:52:51,564: time cost, forward:0.17170592118765562, backward:0.10504751181596202, data cost:0.1914130893309639 
2022-05-11 17:52:51,564: ============================================================
2022-05-11 17:52:51,564: Epoch 28/38 Batch 3800/7662 eta: 10:27:07.025968	Training Loss 0.0849 (0.0862)	Training Prec@1 100.000 (99.936)	Training Prec@5 100.000 (99.979)	
2022-05-11 17:52:51,564: ============================================================
2022-05-11 17:53:38,366: time cost, forward:0.1717171439698917, backward:0.10504314605319583, data cost:0.19139587521461315 
2022-05-11 17:53:38,367: ============================================================
2022-05-11 17:53:38,367: Epoch 28/38 Batch 3900/7662 eta: 10:27:01.574018	Training Loss 0.0900 (0.0863)	Training Prec@1 100.000 (99.936)	Training Prec@5 100.000 (99.979)	
2022-05-11 17:53:38,367: ============================================================
2022-05-11 17:54:25,142: time cost, forward:0.1717194693480232, backward:0.10503783956948863, data cost:0.19137954866924892 
2022-05-11 17:54:25,142: ============================================================
2022-05-11 17:54:25,143: Epoch 28/38 Batch 4000/7662 eta: 10:25:52.928223	Training Loss 0.0846 (0.0864)	Training Prec@1 100.000 (99.936)	Training Prec@5 100.000 (99.979)	
2022-05-11 17:54:25,143: ============================================================
2022-05-11 17:55:11,966: time cost, forward:0.1717304844889998, backward:0.10503503409034597, data cost:0.19136421777586088 
2022-05-11 17:55:11,966: ============================================================
2022-05-11 17:55:11,967: Epoch 28/38 Batch 4100/7662 eta: 10:25:44.933706	Training Loss 0.0903 (0.0865)	Training Prec@1 100.000 (99.936)	Training Prec@5 100.000 (99.979)	
2022-05-11 17:55:11,967: ============================================================
2022-05-11 17:55:58,777: time cost, forward:0.17173277783831065, backward:0.10503096937082812, data cost:0.19135027608578475 
2022-05-11 17:55:58,777: ============================================================
2022-05-11 17:55:58,777: Epoch 28/38 Batch 4200/7662 eta: 10:24:47.376937	Training Loss 0.0888 (0.0866)	Training Prec@1 100.000 (99.935)	Training Prec@5 100.000 (99.979)	
2022-05-11 17:55:58,777: ============================================================
2022-05-11 17:56:45,603: time cost, forward:0.17173639888900966, backward:0.10502706751986475, data cost:0.1913390930488127 
2022-05-11 17:56:45,603: ============================================================
2022-05-11 17:56:45,603: Epoch 28/38 Batch 4300/7662 eta: 10:24:12.535021	Training Loss 0.0916 (0.0867)	Training Prec@1 100.000 (99.935)	Training Prec@5 100.000 (99.979)	
2022-05-11 17:56:45,603: ============================================================
2022-05-11 17:57:32,448: time cost, forward:0.17174618144988146, backward:0.10502329211962388, data cost:0.19132735236554452 
2022-05-11 17:57:32,448: ============================================================
2022-05-11 17:57:32,448: Epoch 28/38 Batch 4400/7662 eta: 10:23:41.433252	Training Loss 0.0993 (0.0868)	Training Prec@1 99.805 (99.935)	Training Prec@5 100.000 (99.979)	
2022-05-11 17:57:32,448: ============================================================
2022-05-11 17:58:19,230: time cost, forward:0.17175600162530694, backward:0.10502145199755558, data cost:0.19130730289807715 
2022-05-11 17:58:19,230: ============================================================
2022-05-11 17:58:19,230: Epoch 28/38 Batch 4500/7662 eta: 10:22:04.074172	Training Loss 0.0968 (0.0869)	Training Prec@1 100.000 (99.935)	Training Prec@5 100.000 (99.979)	
2022-05-11 17:58:19,230: ============================================================
2022-05-11 17:59:05,940: time cost, forward:0.17176054653641348, backward:0.10501737972009853, data cost:0.1912768470331181 
2022-05-11 17:59:05,940: ============================================================
2022-05-11 17:59:05,940: Epoch 28/38 Batch 4600/7662 eta: 10:20:20.070865	Training Loss 0.0862 (0.0870)	Training Prec@1 100.000 (99.935)	Training Prec@5 100.000 (99.979)	
2022-05-11 17:59:05,941: ============================================================
2022-05-11 17:59:52,726: time cost, forward:0.1717640415458736, backward:0.10501579995813916, data cost:0.19126529291757347 
2022-05-11 17:59:52,727: ============================================================
2022-05-11 17:59:52,727: Epoch 28/38 Batch 4700/7662 eta: 10:20:34.050754	Training Loss 0.0924 (0.0871)	Training Prec@1 100.000 (99.934)	Training Prec@5 100.000 (99.978)	
2022-05-11 17:59:52,727: ============================================================
2022-05-11 18:00:39,487: time cost, forward:0.17176943601332845, backward:0.10501202684463275, data cost:0.19124880749177228 
2022-05-11 18:00:39,487: ============================================================
2022-05-11 18:00:39,488: Epoch 28/38 Batch 4800/7662 eta: 10:19:26.863264	Training Loss 0.0915 (0.0872)	Training Prec@1 100.000 (99.934)	Training Prec@5 100.000 (99.978)	
2022-05-11 18:00:39,488: ============================================================
2022-05-11 18:01:26,178: time cost, forward:0.17176931642663554, backward:0.10500879598213814, data cost:0.19122385360630562 
2022-05-11 18:01:26,179: ============================================================
2022-05-11 18:01:26,179: Epoch 28/38 Batch 4900/7662 eta: 10:17:44.788249	Training Loss 0.0973 (0.0873)	Training Prec@1 100.000 (99.934)	Training Prec@5 100.000 (99.978)	
2022-05-11 18:01:26,179: ============================================================
2022-05-11 18:02:12,814: time cost, forward:0.17175360588246188, backward:0.10500492041386182, data cost:0.19120504842278577 
2022-05-11 18:02:12,815: ============================================================
2022-05-11 18:02:12,815: Epoch 28/38 Batch 5000/7662 eta: 10:16:14.557804	Training Loss 0.0923 (0.0873)	Training Prec@1 100.000 (99.934)	Training Prec@5 100.000 (99.978)	
2022-05-11 18:02:12,815: ============================================================
2022-05-11 18:02:59,463: time cost, forward:0.17173787350045813, backward:0.10500125745671196, data cost:0.19118979342382642 
2022-05-11 18:02:59,463: ============================================================
2022-05-11 18:02:59,463: Epoch 28/38 Batch 5100/7662 eta: 10:15:37.687580	Training Loss 0.0878 (0.0874)	Training Prec@1 100.000 (99.934)	Training Prec@5 100.000 (99.978)	
2022-05-11 18:02:59,464: ============================================================
2022-05-11 18:03:46,217: time cost, forward:0.17173254427989645, backward:0.10499873471319687, data cost:0.1911851839277235 
2022-05-11 18:03:46,217: ============================================================
2022-05-11 18:03:46,217: Epoch 28/38 Batch 5200/7662 eta: 10:16:14.484257	Training Loss 0.0865 (0.0875)	Training Prec@1 100.000 (99.933)	Training Prec@5 100.000 (99.978)	
2022-05-11 18:03:46,218: ============================================================
2022-05-11 18:04:32,930: time cost, forward:0.17173411252701545, backward:0.10499612923769888, data cost:0.19116612451664566 
2022-05-11 18:04:32,931: ============================================================
2022-05-11 18:04:32,931: Epoch 28/38 Batch 5300/7662 eta: 10:14:55.529010	Training Loss 0.0868 (0.0876)	Training Prec@1 100.000 (99.933)	Training Prec@5 100.000 (99.978)	
2022-05-11 18:04:32,931: ============================================================
2022-05-11 18:05:19,653: time cost, forward:0.17173349250133532, backward:0.1049930305254859, data cost:0.1911491713583039 
2022-05-11 18:05:19,654: ============================================================
2022-05-11 18:05:19,654: Epoch 28/38 Batch 5400/7662 eta: 10:14:16.622802	Training Loss 0.1001 (0.0877)	Training Prec@1 100.000 (99.933)	Training Prec@5 100.000 (99.978)	
2022-05-11 18:05:19,654: ============================================================
2022-05-11 18:06:06,356: time cost, forward:0.17173326117360693, backward:0.10499129921420094, data cost:0.19113180528534263 
2022-05-11 18:06:06,356: ============================================================
2022-05-11 18:06:06,357: Epoch 28/38 Batch 5500/7662 eta: 10:13:13.812480	Training Loss 0.0892 (0.0878)	Training Prec@1 100.000 (99.933)	Training Prec@5 100.000 (99.978)	
2022-05-11 18:06:06,357: ============================================================
2022-05-11 18:06:53,087: time cost, forward:0.17173387906789397, backward:0.10499001630908103, data cost:0.19111548936628917 
2022-05-11 18:06:53,087: ============================================================
2022-05-11 18:06:53,097: Epoch 28/38 Batch 5600/7662 eta: 10:12:56.904695	Training Loss 0.0956 (0.0879)	Training Prec@1 100.000 (99.932)	Training Prec@5 100.000 (99.978)	
2022-05-11 18:06:53,097: ============================================================
2022-05-11 18:07:39,837: time cost, forward:0.1717365768253228, backward:0.10499143642299028, data cost:0.19110067611536366 
2022-05-11 18:07:39,837: ============================================================
2022-05-11 18:07:39,837: Epoch 28/38 Batch 5700/7662 eta: 10:12:09.827418	Training Loss 0.0984 (0.0880)	Training Prec@1 100.000 (99.932)	Training Prec@5 100.000 (99.978)	
2022-05-11 18:07:39,837: ============================================================
2022-05-11 18:08:26,576: time cost, forward:0.17173952821164856, backward:0.1049916042009496, data cost:0.19108312313752784 
2022-05-11 18:08:26,576: ============================================================
2022-05-11 18:08:26,576: Epoch 28/38 Batch 5800/7662 eta: 10:11:22.142864	Training Loss 0.0897 (0.0880)	Training Prec@1 100.000 (99.932)	Training Prec@5 100.000 (99.978)	
2022-05-11 18:08:26,576: ============================================================
2022-05-11 18:09:13,314: time cost, forward:0.17174416005480064, backward:0.10499058248310053, data cost:0.1910658366479274 
2022-05-11 18:09:13,314: ============================================================
2022-05-11 18:09:13,314: Epoch 28/38 Batch 5900/7662 eta: 10:10:34.599381	Training Loss 0.0953 (0.0881)	Training Prec@1 99.414 (99.931)	Training Prec@5 99.609 (99.978)	
2022-05-11 18:09:13,314: ============================================================
2022-05-11 18:10:00,051: time cost, forward:0.1717491147915191, backward:0.1049911269229101, data cost:0.1910501401570265 
2022-05-11 18:10:00,051: ============================================================
2022-05-11 18:10:00,051: Epoch 28/38 Batch 6000/7662 eta: 10:09:46.963137	Training Loss 0.0891 (0.0882)	Training Prec@1 100.000 (99.931)	Training Prec@5 100.000 (99.978)	
2022-05-11 18:10:00,051: ============================================================
2022-05-11 18:10:46,800: time cost, forward:0.17175624608641707, backward:0.10499324570290083, data cost:0.19103172486444872 
2022-05-11 18:10:46,801: ============================================================
2022-05-11 18:10:46,801: Epoch 28/38 Batch 6100/7662 eta: 10:09:10.362928	Training Loss 0.0911 (0.0883)	Training Prec@1 100.000 (99.931)	Training Prec@5 100.000 (99.978)	
2022-05-11 18:10:46,801: ============================================================
2022-05-11 18:11:33,559: time cost, forward:0.17176150302576199, backward:0.10499504770573387, data cost:0.19101685392296994 
2022-05-11 18:11:33,559: ============================================================
2022-05-11 18:11:33,559: Epoch 28/38 Batch 6200/7662 eta: 10:08:30.456387	Training Loss 0.0910 (0.0884)	Training Prec@1 99.805 (99.931)	Training Prec@5 99.805 (99.978)	
2022-05-11 18:11:33,559: ============================================================
2022-05-11 18:12:20,356: time cost, forward:0.17176547052747088, backward:0.10499877690474066, data cost:0.191006405577998 
2022-05-11 18:12:20,356: ============================================================
2022-05-11 18:12:20,356: Epoch 28/38 Batch 6300/7662 eta: 10:08:13.452155	Training Loss 0.0969 (0.0884)	Training Prec@1 100.000 (99.930)	Training Prec@5 100.000 (99.977)	
2022-05-11 18:12:20,356: ============================================================
2022-05-11 18:13:07,123: time cost, forward:0.17177098895408416, backward:0.10499917821858819, data cost:0.19099469865964974 
2022-05-11 18:13:07,123: ============================================================
2022-05-11 18:13:07,124: Epoch 28/38 Batch 6400/7662 eta: 10:07:04.023324	Training Loss 0.0935 (0.0885)	Training Prec@1 99.805 (99.930)	Training Prec@5 99.805 (99.977)	
2022-05-11 18:13:07,124: ============================================================
2022-05-11 18:13:53,873: time cost, forward:0.1717760568032688, backward:0.10500177828637174, data cost:0.19097862949479927 
2022-05-11 18:13:53,874: ============================================================
2022-05-11 18:13:53,874: Epoch 28/38 Batch 6500/7662 eta: 10:06:03.674340	Training Loss 0.0940 (0.0886)	Training Prec@1 99.805 (99.929)	Training Prec@5 100.000 (99.977)	
2022-05-11 18:13:53,874: ============================================================
2022-05-11 18:14:40,638: time cost, forward:0.17178066330690206, backward:0.10500319503729841, data cost:0.19096694022963528 
2022-05-11 18:14:40,639: ============================================================
2022-05-11 18:14:40,639: Epoch 28/38 Batch 6600/7662 eta: 10:05:28.591902	Training Loss 0.0920 (0.0886)	Training Prec@1 99.805 (99.929)	Training Prec@5 100.000 (99.977)	
2022-05-11 18:14:40,639: ============================================================
2022-05-11 18:15:27,358: time cost, forward:0.17178287255548688, backward:0.10500473156849437, data cost:0.19094908296181062 
2022-05-11 18:15:27,359: ============================================================
2022-05-11 18:15:27,359: Epoch 28/38 Batch 6700/7662 eta: 10:04:06.723980	Training Loss 0.0895 (0.0887)	Training Prec@1 99.805 (99.929)	Training Prec@5 99.805 (99.977)	
2022-05-11 18:15:27,359: ============================================================
2022-05-11 18:16:14,049: time cost, forward:0.17178423065598492, backward:0.105006704577314, data cost:0.19092954276396712 
2022-05-11 18:16:14,049: ============================================================
2022-05-11 18:16:14,049: Epoch 28/38 Batch 6800/7662 eta: 10:02:57.102407	Training Loss 0.0929 (0.0888)	Training Prec@1 99.805 (99.929)	Training Prec@5 100.000 (99.977)	
2022-05-11 18:16:14,049: ============================================================
2022-05-11 18:17:00,719: time cost, forward:0.1717838075026548, backward:0.1050071495134669, data cost:0.19091076653216918 
2022-05-11 18:17:00,719: ============================================================
2022-05-11 18:17:00,719: Epoch 28/38 Batch 6900/7662 eta: 10:01:54.588781	Training Loss 0.0904 (0.0888)	Training Prec@1 100.000 (99.929)	Training Prec@5 100.000 (99.977)	
2022-05-11 18:17:00,719: ============================================================
2022-05-11 18:17:47,476: time cost, forward:0.17179210319878765, backward:0.10500828912214205, data cost:0.19089547571650164 
2022-05-11 18:17:47,476: ============================================================
2022-05-11 18:17:47,476: Epoch 28/38 Batch 7000/7662 eta: 10:02:15.036874	Training Loss 0.0867 (0.0889)	Training Prec@1 100.000 (99.928)	Training Prec@5 100.000 (99.977)	
2022-05-11 18:17:47,476: ============================================================
2022-05-11 18:18:34,317: time cost, forward:0.17179830925013587, backward:0.10501924506844493, data cost:0.19088449460013615 
2022-05-11 18:18:34,317: ============================================================
2022-05-11 18:18:34,317: Epoch 28/38 Batch 7100/7662 eta: 10:02:33.462253	Training Loss 0.0960 (0.0890)	Training Prec@1 100.000 (99.928)	Training Prec@5 100.000 (99.977)	
2022-05-11 18:18:34,317: ============================================================
2022-05-11 18:19:21,321: time cost, forward:0.17181105464013818, backward:0.10504199240104674, data cost:0.19087757191934226 
2022-05-11 18:19:21,321: ============================================================
2022-05-11 18:19:21,322: Epoch 28/38 Batch 7200/7662 eta: 10:03:52.365826	Training Loss 0.0949 (0.0891)	Training Prec@1 100.000 (99.928)	Training Prec@5 100.000 (99.976)	
2022-05-11 18:19:21,322: ============================================================
2022-05-11 18:20:08,272: time cost, forward:0.17182461541553837, backward:0.10504537743237724, data cost:0.19088149746896013 
2022-05-11 18:20:08,273: ============================================================
2022-05-11 18:20:08,273: Epoch 28/38 Batch 7300/7662 eta: 10:02:24.471669	Training Loss 0.0905 (0.0891)	Training Prec@1 100.000 (99.927)	Training Prec@5 100.000 (99.976)	
2022-05-11 18:20:08,273: ============================================================
2022-05-11 18:20:55,163: time cost, forward:0.17183681323183825, backward:0.10504561457251807, data cost:0.1908791844370172 
2022-05-11 18:20:55,164: ============================================================
2022-05-11 18:20:55,164: Epoch 28/38 Batch 7400/7662 eta: 10:00:51.154397	Training Loss 0.0974 (0.0892)	Training Prec@1 100.000 (99.927)	Training Prec@5 100.000 (99.976)	
2022-05-11 18:20:55,164: ============================================================
2022-05-11 18:21:41,826: time cost, forward:0.17183521509583846, backward:0.1050449642980555, data cost:0.19086249536920474 
2022-05-11 18:21:41,826: ============================================================
2022-05-11 18:21:41,827: Epoch 28/38 Batch 7500/7662 eta: 9:57:09.050184	Training Loss 0.0959 (0.0893)	Training Prec@1 100.000 (99.927)	Training Prec@5 100.000 (99.976)	
2022-05-11 18:21:41,827: ============================================================
2022-05-11 18:22:28,493: time cost, forward:0.17183469254525968, backward:0.10504401261939204, data cost:0.19084633201466594 
2022-05-11 18:22:28,494: ============================================================
2022-05-11 18:22:28,494: Epoch 28/38 Batch 7600/7662 eta: 9:56:25.806119	Training Loss 0.0972 (0.0893)	Training Prec@1 100.000 (99.927)	Training Prec@5 100.000 (99.976)	
2022-05-11 18:22:28,494: ============================================================
2022-05-11 18:22:59,231: Epoch: 28/38 eta: 9:55:56.405785	Training Loss 0.0950 (0.0894)	Training Prec@1 100.000 (99.927)	Training Prec@5 100.000 (99.976)
2022-05-11 18:22:59,231: ============================================================
2022-05-11 18:23:47,283: time cost, forward:0.1778915265593866, backward:0.10466992253004903, data cost:0.19980492977180866 
2022-05-11 18:23:47,284: ============================================================
2022-05-11 18:23:47,284: Epoch 29/38 Batch 100/7662 eta: 10:11:46.890381	Training Loss 0.0816 (0.0807)	Training Prec@1 100.000 (99.964)	Training Prec@5 100.000 (99.988)	
2022-05-11 18:23:47,284: ============================================================
2022-05-11 18:24:34,029: time cost, forward:0.1750217742057302, backward:0.10485890163249106, data cost:0.1948790670040265 
2022-05-11 18:24:34,030: ============================================================
2022-05-11 18:24:34,030: Epoch 29/38 Batch 200/7662 eta: 9:55:23.803152	Training Loss 0.0833 (0.0808)	Training Prec@1 100.000 (99.949)	Training Prec@5 100.000 (99.979)	
2022-05-11 18:24:34,030: ============================================================
2022-05-11 18:25:20,725: time cost, forward:0.17400666543073878, backward:0.10491393720824584, data cost:0.19315221237897076 
2022-05-11 18:25:20,725: ============================================================
2022-05-11 18:25:20,726: Epoch 29/38 Batch 300/7662 eta: 9:53:58.739963	Training Loss 0.0774 (0.0808)	Training Prec@1 100.000 (99.946)	Training Prec@5 100.000 (99.979)	
2022-05-11 18:25:20,726: ============================================================
2022-05-11 18:26:07,431: time cost, forward:0.1734926288289235, backward:0.10495638130302716, data cost:0.19230838288041882 
2022-05-11 18:26:07,431: ============================================================
2022-05-11 18:26:07,431: Epoch 29/38 Batch 400/7662 eta: 9:53:19.459765	Training Loss 0.0789 (0.0809)	Training Prec@1 99.805 (99.947)	Training Prec@5 100.000 (99.978)	
2022-05-11 18:26:07,431: ============================================================
2022-05-11 18:26:54,151: time cost, forward:0.17318013053618833, backward:0.10499400652959973, data cost:0.19182567749329224 
2022-05-11 18:26:54,152: ============================================================
2022-05-11 18:26:54,152: Epoch 29/38 Batch 500/7662 eta: 9:52:44.085665	Training Loss 0.0863 (0.0811)	Training Prec@1 100.000 (99.946)	Training Prec@5 100.000 (99.978)	
2022-05-11 18:26:54,152: ============================================================
2022-05-11 18:27:40,814: time cost, forward:0.17292851279295346, backward:0.10500760826722211, data cost:0.1914611829939191 
2022-05-11 18:27:40,814: ============================================================
2022-05-11 18:27:40,814: Epoch 29/38 Batch 600/7662 eta: 9:51:13.433720	Training Loss 0.0779 (0.0812)	Training Prec@1 99.805 (99.950)	Training Prec@5 100.000 (99.980)	
2022-05-11 18:27:40,814: ============================================================
2022-05-11 18:28:27,531: time cost, forward:0.17275670601404106, backward:0.10501965262176995, data cost:0.19127065702228246 
2022-05-11 18:28:27,532: ============================================================
2022-05-11 18:28:27,532: Epoch 29/38 Batch 700/7662 eta: 9:51:08.346996	Training Loss 0.0846 (0.0813)	Training Prec@1 100.000 (99.949)	Training Prec@5 100.000 (99.980)	
2022-05-11 18:28:27,532: ============================================================
2022-05-11 18:29:14,209: time cost, forward:0.17263304635192336, backward:0.10500747330943694, data cost:0.1910922757078321 
2022-05-11 18:29:14,209: ============================================================
2022-05-11 18:29:14,209: Epoch 29/38 Batch 800/7662 eta: 9:49:51.273708	Training Loss 0.0802 (0.0814)	Training Prec@1 100.000 (99.947)	Training Prec@5 100.000 (99.980)	
2022-05-11 18:29:14,209: ============================================================
2022-05-11 18:30:00,921: time cost, forward:0.17252155883161058, backward:0.10502127598602329, data cost:0.19097267268629572 
2022-05-11 18:30:00,921: ============================================================
2022-05-11 18:30:00,921: Epoch 29/38 Batch 900/7662 eta: 9:49:30.896704	Training Loss 0.0837 (0.0816)	Training Prec@1 100.000 (99.949)	Training Prec@5 100.000 (99.982)	
2022-05-11 18:30:00,922: ============================================================
2022-05-11 18:30:47,624: time cost, forward:0.1724398076474607, backward:0.10500901955384034, data cost:0.19089392880658368 
2022-05-11 18:30:47,624: ============================================================
2022-05-11 18:30:47,624: Epoch 29/38 Batch 1000/7662 eta: 9:48:37.197795	Training Loss 0.0876 (0.0818)	Training Prec@1 100.000 (99.950)	Training Prec@5 100.000 (99.982)	
2022-05-11 18:30:47,624: ============================================================
2022-05-11 18:31:34,319: time cost, forward:0.1723811839036881, backward:0.10500037854535672, data cost:0.19081317087647262 
2022-05-11 18:31:34,319: ============================================================
2022-05-11 18:31:34,320: Epoch 29/38 Batch 1100/7662 eta: 9:47:44.747507	Training Loss 0.0816 (0.0819)	Training Prec@1 100.000 (99.950)	Training Prec@5 100.000 (99.982)	
2022-05-11 18:31:34,320: ============================================================
2022-05-11 18:32:20,976: time cost, forward:0.17229575132508393, backward:0.10499176211512218, data cost:0.19075278424540593 
2022-05-11 18:32:20,976: ============================================================
2022-05-11 18:32:20,977: Epoch 29/38 Batch 1200/7662 eta: 9:46:29.164511	Training Loss 0.0857 (0.0820)	Training Prec@1 100.000 (99.950)	Training Prec@5 100.000 (99.981)	
2022-05-11 18:32:20,977: ============================================================
2022-05-11 18:33:07,622: time cost, forward:0.1722000074716969, backward:0.10499692991020314, data cost:0.19070354216460358 
2022-05-11 18:33:07,622: ============================================================
2022-05-11 18:33:07,622: Epoch 29/38 Batch 1300/7662 eta: 9:45:34.051139	Training Loss 0.0838 (0.0821)	Training Prec@1 100.000 (99.951)	Training Prec@5 100.000 (99.982)	
2022-05-11 18:33:07,622: ============================================================
2022-05-11 18:33:54,255: time cost, forward:0.17211314369048963, backward:0.10499002117186977, data cost:0.1906688579752924 
2022-05-11 18:33:54,256: ============================================================
2022-05-11 18:33:54,256: Epoch 29/38 Batch 1400/7662 eta: 9:44:38.235863	Training Loss 0.0832 (0.0823)	Training Prec@1 99.805 (99.952)	Training Prec@5 100.000 (99.982)	
2022-05-11 18:33:54,256: ============================================================
2022-05-11 18:34:40,899: time cost, forward:0.172061253580115, backward:0.10498769001773073, data cost:0.19061810990983125 
2022-05-11 18:34:40,899: ============================================================
2022-05-11 18:34:40,899: Epoch 29/38 Batch 1500/7662 eta: 9:43:59.082866	Training Loss 0.0879 (0.0824)	Training Prec@1 99.805 (99.952)	Training Prec@5 99.805 (99.983)	
2022-05-11 18:34:40,900: ============================================================
2022-05-11 18:35:27,550: time cost, forward:0.17200019584736875, backward:0.10499833299638034, data cost:0.19058199701195885 
2022-05-11 18:35:27,551: ============================================================
2022-05-11 18:35:27,551: Epoch 29/38 Batch 1600/7662 eta: 9:43:18.335414	Training Loss 0.0900 (0.0825)	Training Prec@1 100.000 (99.951)	Training Prec@5 100.000 (99.983)	
2022-05-11 18:35:27,551: ============================================================
2022-05-11 18:36:14,225: time cost, forward:0.17195536782981508, backward:0.10500417154209975, data cost:0.19055810235681922 
2022-05-11 18:36:14,225: ============================================================
2022-05-11 18:36:14,225: Epoch 29/38 Batch 1700/7662 eta: 9:42:49.039469	Training Loss 0.0861 (0.0827)	Training Prec@1 99.805 (99.949)	Training Prec@5 100.000 (99.982)	
2022-05-11 18:36:14,225: ============================================================
2022-05-11 18:37:00,871: time cost, forward:0.1719159540565495, backward:0.10500925259168709, data cost:0.19052126037869074 
2022-05-11 18:37:00,871: ============================================================
2022-05-11 18:37:00,872: Epoch 29/38 Batch 1800/7662 eta: 9:41:41.090288	Training Loss 0.0849 (0.0828)	Training Prec@1 99.609 (99.948)	Training Prec@5 99.805 (99.982)	
2022-05-11 18:37:00,872: ============================================================
2022-05-11 18:37:47,580: time cost, forward:0.17188668263592552, backward:0.10500962424115044, data cost:0.19051950677185703 
2022-05-11 18:37:47,580: ============================================================
2022-05-11 18:37:47,581: Epoch 29/38 Batch 1900/7662 eta: 9:41:41.510180	Training Loss 0.0809 (0.0829)	Training Prec@1 100.000 (99.947)	Training Prec@5 100.000 (99.981)	
2022-05-11 18:37:47,581: ============================================================
2022-05-11 18:38:34,237: time cost, forward:0.17185632379845775, backward:0.1050167096859816, data cost:0.19048851820872748 
2022-05-11 18:38:34,237: ============================================================
2022-05-11 18:38:34,237: Epoch 29/38 Batch 2000/7662 eta: 9:40:15.624331	Training Loss 0.0849 (0.0830)	Training Prec@1 100.000 (99.947)	Training Prec@5 100.000 (99.981)	
2022-05-11 18:38:34,237: ============================================================
2022-05-11 18:39:20,916: time cost, forward:0.17182933358478228, backward:0.10501959620344463, data cost:0.19047437263932213 
2022-05-11 18:39:20,916: ============================================================
2022-05-11 18:39:20,916: Epoch 29/38 Batch 2100/7662 eta: 9:39:45.484997	Training Loss 0.0910 (0.0832)	Training Prec@1 100.000 (99.947)	Training Prec@5 100.000 (99.981)	
2022-05-11 18:39:20,916: ============================================================
2022-05-11 18:40:07,630: time cost, forward:0.17181904264990444, backward:0.10502025700526219, data cost:0.19046004114502285 
2022-05-11 18:40:07,630: ============================================================
2022-05-11 18:40:07,630: Epoch 29/38 Batch 2200/7662 eta: 9:39:25.060352	Training Loss 0.0851 (0.0833)	Training Prec@1 100.000 (99.946)	Training Prec@5 100.000 (99.981)	
2022-05-11 18:40:07,630: ============================================================
2022-05-11 18:40:54,348: time cost, forward:0.17181221875692254, backward:0.10502235388538017, data cost:0.19044931103945711 
2022-05-11 18:40:54,349: ============================================================
2022-05-11 18:40:54,349: Epoch 29/38 Batch 2300/7662 eta: 9:38:41.791510	Training Loss 0.0929 (0.0835)	Training Prec@1 100.000 (99.946)	Training Prec@5 100.000 (99.981)	
2022-05-11 18:40:54,349: ============================================================
2022-05-11 18:41:40,995: time cost, forward:0.17179660968057014, backward:0.10501956780685291, data cost:0.19042392103013123 
2022-05-11 18:41:40,995: ============================================================
2022-05-11 18:41:40,996: Epoch 29/38 Batch 2400/7662 eta: 9:37:01.731191	Training Loss 0.0827 (0.0836)	Training Prec@1 100.000 (99.946)	Training Prec@5 100.000 (99.981)	
2022-05-11 18:41:40,996: ============================================================
2022-05-11 18:42:27,718: time cost, forward:0.17179508550780542, backward:0.10501995569422228, data cost:0.1904149385584312 
2022-05-11 18:42:27,719: ============================================================
2022-05-11 18:42:27,719: Epoch 29/38 Batch 2500/7662 eta: 9:37:11.676802	Training Loss 0.0856 (0.0837)	Training Prec@1 99.805 (99.946)	Training Prec@5 100.000 (99.981)	
2022-05-11 18:42:27,719: ============================================================
2022-05-11 18:43:14,455: time cost, forward:0.17180179687315061, backward:0.10501386936741088, data cost:0.19041040696837253 
2022-05-11 18:43:14,455: ============================================================
2022-05-11 18:43:14,456: Epoch 29/38 Batch 2600/7662 eta: 9:36:35.074402	Training Loss 0.0846 (0.0838)	Training Prec@1 100.000 (99.945)	Training Prec@5 100.000 (99.981)	
2022-05-11 18:43:14,456: ============================================================
2022-05-11 18:44:01,238: time cost, forward:0.17179739568002933, backward:0.10501422065856414, data cost:0.19042503325839358 
2022-05-11 18:44:01,238: ============================================================
2022-05-11 18:44:01,238: Epoch 29/38 Batch 2700/7662 eta: 9:36:22.353917	Training Loss 0.0917 (0.0839)	Training Prec@1 100.000 (99.945)	Training Prec@5 100.000 (99.980)	
2022-05-11 18:44:01,238: ============================================================
2022-05-11 18:44:48,033: time cost, forward:0.17178623767442558, backward:0.10502118500440025, data cost:0.19044544186580176 
2022-05-11 18:44:48,034: ============================================================
2022-05-11 18:44:48,034: Epoch 29/38 Batch 2800/7662 eta: 9:35:44.915237	Training Loss 0.0908 (0.0840)	Training Prec@1 99.805 (99.945)	Training Prec@5 99.805 (99.980)	
2022-05-11 18:44:48,034: ============================================================
2022-05-11 18:45:34,823: time cost, forward:0.17177667507594024, backward:0.10502631658519207, data cost:0.19046129461566758 
2022-05-11 18:45:34,824: ============================================================
2022-05-11 18:45:34,824: Epoch 29/38 Batch 2900/7662 eta: 9:34:53.987675	Training Loss 0.0886 (0.0842)	Training Prec@1 99.805 (99.945)	Training Prec@5 100.000 (99.980)	
2022-05-11 18:45:34,824: ============================================================
2022-05-11 18:46:21,581: time cost, forward:0.17177768284656797, backward:0.10502554862329903, data cost:0.19046607149486028 
2022-05-11 18:46:21,582: ============================================================
2022-05-11 18:46:21,582: Epoch 29/38 Batch 3000/7662 eta: 9:33:43.712194	Training Loss 0.0844 (0.0843)	Training Prec@1 100.000 (99.945)	Training Prec@5 100.000 (99.980)	
2022-05-11 18:46:21,582: ============================================================
2022-05-11 18:47:08,472: time cost, forward:0.17177524994403634, backward:0.10506685344047337, data cost:0.19047210946626222 
2022-05-11 18:47:08,472: ============================================================
2022-05-11 18:47:08,473: Epoch 29/38 Batch 3100/7662 eta: 9:34:34.568240	Training Loss 0.0868 (0.0844)	Training Prec@1 100.000 (99.945)	Training Prec@5 100.000 (99.980)	
2022-05-11 18:47:08,473: ============================================================
2022-05-11 18:47:55,377: time cost, forward:0.17177141864212575, backward:0.10511331142355182, data cost:0.19047621854881674 
2022-05-11 18:47:55,378: ============================================================
2022-05-11 18:47:55,378: Epoch 29/38 Batch 3200/7662 eta: 9:33:58.303306	Training Loss 0.0921 (0.0845)	Training Prec@1 100.000 (99.945)	Training Prec@5 100.000 (99.980)	
2022-05-11 18:47:55,378: ============================================================
2022-05-11 18:48:42,311: time cost, forward:0.17176823248896464, backward:0.1051564080023556, data cost:0.19048575828855202 
2022-05-11 18:48:42,312: ============================================================
2022-05-11 18:48:42,312: Epoch 29/38 Batch 3300/7662 eta: 9:33:32.448433	Training Loss 0.0813 (0.0846)	Training Prec@1 100.000 (99.944)	Training Prec@5 100.000 (99.980)	
2022-05-11 18:48:42,312: ============================================================
2022-05-11 18:49:29,233: time cost, forward:0.1717659968353433, backward:0.1051953928931456, data cost:0.19049498451987096 
2022-05-11 18:49:29,233: ============================================================
2022-05-11 18:49:29,233: Epoch 29/38 Batch 3400/7662 eta: 9:32:36.378747	Training Loss 0.0922 (0.0848)	Training Prec@1 100.000 (99.944)	Training Prec@5 100.000 (99.980)	
2022-05-11 18:49:29,233: ============================================================
2022-05-11 18:50:16,187: time cost, forward:0.17176826486045138, backward:0.1052312475505915, data cost:0.19050947595712422 
2022-05-11 18:50:16,187: ============================================================
2022-05-11 18:50:16,187: Epoch 29/38 Batch 3500/7662 eta: 9:32:13.341553	Training Loss 0.0897 (0.0849)	Training Prec@1 100.000 (99.943)	Training Prec@5 100.000 (99.979)	
2022-05-11 18:50:16,188: ============================================================
2022-05-11 18:51:03,163: time cost, forward:0.1717791118102459, backward:0.10526634441809245, data cost:0.19051945020702687 
2022-05-11 18:51:03,164: ============================================================
2022-05-11 18:51:03,164: Epoch 29/38 Batch 3600/7662 eta: 9:31:42.833176	Training Loss 0.0925 (0.0849)	Training Prec@1 100.000 (99.943)	Training Prec@5 100.000 (99.979)	
2022-05-11 18:51:03,164: ============================================================
2022-05-11 18:51:50,122: time cost, forward:0.1717776545771846, backward:0.10529968853930133, data cost:0.19053560600115757 
2022-05-11 18:51:50,122: ============================================================
2022-05-11 18:51:50,122: Epoch 29/38 Batch 3700/7662 eta: 9:30:42.475587	Training Loss 0.0912 (0.0850)	Training Prec@1 100.000 (99.942)	Training Prec@5 100.000 (99.979)	
2022-05-11 18:51:50,123: ============================================================
2022-05-11 18:52:37,084: time cost, forward:0.17177737998661163, backward:0.10532952566214629, data cost:0.1905494382049448 
2022-05-11 18:52:37,084: ============================================================
2022-05-11 18:52:37,085: Epoch 29/38 Batch 3800/7662 eta: 9:29:58.347428	Training Loss 0.0961 (0.0851)	Training Prec@1 99.609 (99.942)	Training Prec@5 100.000 (99.979)	
2022-05-11 18:52:37,085: ============================================================
2022-05-11 18:53:23,874: time cost, forward:0.17177729809641928, backward:0.1053317318393133, data cost:0.19054206085987782 
2022-05-11 18:53:23,875: ============================================================
2022-05-11 18:53:23,875: Epoch 29/38 Batch 3900/7662 eta: 9:27:06.516677	Training Loss 0.0861 (0.0852)	Training Prec@1 100.000 (99.942)	Training Prec@5 100.000 (99.978)	
2022-05-11 18:53:23,875: ============================================================
2022-05-11 18:54:10,640: time cost, forward:0.17178508680324073, backward:0.10532572335617398, data cost:0.1905353406752071 
2022-05-11 18:54:10,641: ============================================================
2022-05-11 18:54:10,641: Epoch 29/38 Batch 4000/7662 eta: 9:26:01.701930	Training Loss 0.0902 (0.0854)	Training Prec@1 99.805 (99.941)	Training Prec@5 100.000 (99.978)	
2022-05-11 18:54:10,641: ============================================================
2022-05-11 18:54:57,463: time cost, forward:0.17179510872024942, backward:0.10531740724880481, data cost:0.19054166163779318 
2022-05-11 18:54:57,463: ============================================================
2022-05-11 18:54:57,463: Epoch 29/38 Batch 4100/7662 eta: 9:25:56.173574	Training Loss 0.0923 (0.0854)	Training Prec@1 100.000 (99.941)	Training Prec@5 100.000 (99.978)	
2022-05-11 18:54:57,463: ============================================================
2022-05-11 18:55:44,334: time cost, forward:0.17180267797535048, backward:0.10530911306166371, data cost:0.1905602978990032 
2022-05-11 18:55:44,335: ============================================================
2022-05-11 18:55:44,335: Epoch 29/38 Batch 4200/7662 eta: 9:25:44.841314	Training Loss 0.0914 (0.0856)	Training Prec@1 100.000 (99.941)	Training Prec@5 100.000 (99.978)	
2022-05-11 18:55:44,335: ============================================================
2022-05-11 18:56:31,185: time cost, forward:0.17180499333951552, backward:0.10530174502274912, data cost:0.1905778077181674 
2022-05-11 18:56:31,186: ============================================================
2022-05-11 18:56:31,186: Epoch 29/38 Batch 4300/7662 eta: 9:24:43.050894	Training Loss 0.0955 (0.0856)	Training Prec@1 100.000 (99.940)	Training Prec@5 100.000 (99.978)	
2022-05-11 18:56:31,186: ============================================================
2022-05-11 18:57:17,990: time cost, forward:0.17181456324782635, backward:0.10529305583158659, data cost:0.1905796826495504 
2022-05-11 18:57:17,990: ============================================================
2022-05-11 18:57:17,991: Epoch 29/38 Batch 4400/7662 eta: 9:23:22.790803	Training Loss 0.0789 (0.0857)	Training Prec@1 100.000 (99.940)	Training Prec@5 100.000 (99.978)	
2022-05-11 18:57:17,991: ============================================================
2022-05-11 18:58:04,803: time cost, forward:0.17181859235812305, backward:0.10528320756375087, data cost:0.19058769341176499 
2022-05-11 18:58:04,803: ============================================================
2022-05-11 18:58:04,803: Epoch 29/38 Batch 4500/7662 eta: 9:22:41.667542	Training Loss 0.0876 (0.0858)	Training Prec@1 100.000 (99.940)	Training Prec@5 100.000 (99.979)	
2022-05-11 18:58:04,803: ============================================================
2022-05-11 18:58:51,628: time cost, forward:0.17182415691399786, backward:0.10527257718166907, data cost:0.1905954970201997 
2022-05-11 18:58:51,628: ============================================================
2022-05-11 18:58:51,628: Epoch 29/38 Batch 4600/7662 eta: 9:22:04.175334	Training Loss 0.0919 (0.0859)	Training Prec@1 100.000 (99.940)	Training Prec@5 100.000 (99.979)	
2022-05-11 18:58:51,629: ============================================================
2022-05-11 18:59:38,447: time cost, forward:0.1718305605831337, backward:0.10526249387919281, data cost:0.19060639980930702 
2022-05-11 18:59:38,447: ============================================================
2022-05-11 18:59:38,447: Epoch 29/38 Batch 4700/7662 eta: 9:21:12.651498	Training Loss 0.0851 (0.0860)	Training Prec@1 99.805 (99.940)	Training Prec@5 100.000 (99.979)	
2022-05-11 18:59:38,448: ============================================================
2022-05-11 19:00:25,298: time cost, forward:0.1718321307596253, backward:0.10525402284508124, data cost:0.19062317617487526 
2022-05-11 19:00:25,298: ============================================================
2022-05-11 19:00:25,298: Epoch 29/38 Batch 4800/7662 eta: 9:20:48.806246	Training Loss 0.0901 (0.0861)	Training Prec@1 100.000 (99.939)	Training Prec@5 100.000 (99.979)	
2022-05-11 19:00:25,298: ============================================================
2022-05-11 19:01:12,100: time cost, forward:0.1718325509808944, backward:0.10524594401748698, data cost:0.19062998830651623 
2022-05-11 19:01:12,100: ============================================================
2022-05-11 19:01:12,100: Epoch 29/38 Batch 4900/7662 eta: 9:19:26.743952	Training Loss 0.0890 (0.0862)	Training Prec@1 100.000 (99.939)	Training Prec@5 100.000 (99.978)	
2022-05-11 19:01:12,100: ============================================================
2022-05-11 19:01:58,845: time cost, forward:0.17183207816947912, backward:0.10524087520713066, data cost:0.19062497053510738 
2022-05-11 19:01:58,845: ============================================================
2022-05-11 19:01:58,845: Epoch 29/38 Batch 5000/7662 eta: 9:17:59.351459	Training Loss 0.0866 (0.0863)	Training Prec@1 100.000 (99.939)	Training Prec@5 100.000 (99.978)	
2022-05-11 19:01:58,845: ============================================================
2022-05-11 19:02:45,547: time cost, forward:0.17182823900476019, backward:0.1052349427326634, data cost:0.190614541574281 
2022-05-11 19:02:45,548: ============================================================
2022-05-11 19:02:45,548: Epoch 29/38 Batch 5100/7662 eta: 9:16:41.953739	Training Loss 0.0933 (0.0864)	Training Prec@1 100.000 (99.939)	Training Prec@5 100.000 (99.978)	
2022-05-11 19:02:45,548: ============================================================
2022-05-11 19:03:32,182: time cost, forward:0.17181475897618592, backward:0.1052288696797542, data cost:0.19060311539399208 
2022-05-11 19:03:32,182: ============================================================
2022-05-11 19:03:32,182: Epoch 29/38 Batch 5200/7662 eta: 9:15:06.943928	Training Loss 0.0942 (0.0865)	Training Prec@1 99.609 (99.939)	Training Prec@5 100.000 (99.978)	
2022-05-11 19:03:32,183: ============================================================
2022-05-11 19:04:18,741: time cost, forward:0.17178118195167508, backward:0.10522459853165643, data cost:0.19059729234163075 
2022-05-11 19:04:18,741: ============================================================
2022-05-11 19:04:18,742: Epoch 29/38 Batch 5300/7662 eta: 9:13:26.525666	Training Loss 0.0986 (0.0865)	Training Prec@1 100.000 (99.939)	Training Prec@5 100.000 (99.978)	
2022-05-11 19:04:18,742: ============================================================
2022-05-11 19:05:05,397: time cost, forward:0.17176340840264237, backward:0.10522138540293027, data cost:0.19059397132557 
2022-05-11 19:05:05,398: ============================================================
2022-05-11 19:05:05,398: Epoch 29/38 Batch 5400/7662 eta: 9:13:48.969872	Training Loss 0.0867 (0.0866)	Training Prec@1 100.000 (99.938)	Training Prec@5 100.000 (99.978)	
2022-05-11 19:05:05,398: ============================================================
2022-05-11 19:05:52,092: time cost, forward:0.17174442171248377, backward:0.10522012763466482, data cost:0.19059379583359806 
2022-05-11 19:05:52,092: ============================================================
2022-05-11 19:05:52,092: Epoch 29/38 Batch 5500/7662 eta: 9:13:29.645854	Training Loss 0.0899 (0.0867)	Training Prec@1 99.805 (99.938)	Training Prec@5 100.000 (99.978)	
2022-05-11 19:05:52,092: ============================================================
2022-05-11 19:06:38,789: time cost, forward:0.17173110589233334, backward:0.10521644391126134, data cost:0.19059045362906873 
2022-05-11 19:06:38,790: ============================================================
2022-05-11 19:06:38,790: Epoch 29/38 Batch 5600/7662 eta: 9:12:44.985750	Training Loss 0.0937 (0.0868)	Training Prec@1 100.000 (99.937)	Training Prec@5 100.000 (99.978)	
2022-05-11 19:06:38,790: ============================================================
2022-05-11 19:07:25,464: time cost, forward:0.17172252297255006, backward:0.10521222717156639, data cost:0.19058443358287955 
2022-05-11 19:07:25,464: ============================================================
2022-05-11 19:07:25,464: Epoch 29/38 Batch 5700/7662 eta: 9:11:42.162481	Training Loss 0.0933 (0.0869)	Training Prec@1 100.000 (99.937)	Training Prec@5 100.000 (99.978)	
2022-05-11 19:07:25,465: ============================================================
2022-05-11 19:08:12,242: time cost, forward:0.17172064520527852, backward:0.10520865835389467, data cost:0.19058762128691484 
2022-05-11 19:08:12,243: ============================================================
2022-05-11 19:08:12,243: Epoch 29/38 Batch 5800/7662 eta: 9:12:08.841640	Training Loss 0.0884 (0.0869)	Training Prec@1 100.000 (99.937)	Training Prec@5 100.000 (99.978)	
2022-05-11 19:08:12,243: ============================================================
2022-05-11 19:08:58,982: time cost, forward:0.1717177914207033, backward:0.10520620025968447, data cost:0.19058526635351858 
2022-05-11 19:08:58,982: ============================================================
2022-05-11 19:08:58,982: Epoch 29/38 Batch 5900/7662 eta: 9:10:54.591750	Training Loss 0.0968 (0.0870)	Training Prec@1 100.000 (99.936)	Training Prec@5 100.000 (99.978)	
2022-05-11 19:08:58,982: ============================================================
2022-05-11 19:09:45,772: time cost, forward:0.17172266113934945, backward:0.10520426359429401, data cost:0.19058518009119021 
2022-05-11 19:09:45,772: ============================================================
2022-05-11 19:09:45,772: Epoch 29/38 Batch 6000/7662 eta: 9:10:43.577828	Training Loss 0.0962 (0.0871)	Training Prec@1 99.805 (99.936)	Training Prec@5 100.000 (99.978)	
2022-05-11 19:09:45,772: ============================================================
2022-05-11 19:10:32,520: time cost, forward:0.17172804756777504, backward:0.10520245646195131, data cost:0.19057644701606036 
2022-05-11 19:10:32,520: ============================================================
2022-05-11 19:10:32,520: Epoch 29/38 Batch 6100/7662 eta: 9:09:27.234356	Training Loss 0.0908 (0.0872)	Training Prec@1 100.000 (99.936)	Training Prec@5 100.000 (99.978)	
2022-05-11 19:10:32,520: ============================================================
2022-05-11 19:11:19,333: time cost, forward:0.17173406581260212, backward:0.10520038410124614, data cost:0.19057811931518417 
2022-05-11 19:11:19,333: ============================================================
2022-05-11 19:11:19,333: Epoch 29/38 Batch 6200/7662 eta: 9:09:26.225686	Training Loss 0.0928 (0.0873)	Training Prec@1 100.000 (99.936)	Training Prec@5 100.000 (99.978)	
2022-05-11 19:11:19,333: ============================================================
2022-05-11 19:12:06,071: time cost, forward:0.17173667782203492, backward:0.10519784547957489, data cost:0.19056972826751645 
2022-05-11 19:12:06,072: ============================================================
2022-05-11 19:12:06,072: Epoch 29/38 Batch 6300/7662 eta: 9:07:46.926347	Training Loss 0.0989 (0.0874)	Training Prec@1 100.000 (99.936)	Training Prec@5 100.000 (99.978)	
2022-05-11 19:12:06,072: ============================================================
2022-05-11 19:12:52,852: time cost, forward:0.1717423529788132, backward:0.10519492106430976, data cost:0.19056763755546768 
2022-05-11 19:12:52,853: ============================================================
2022-05-11 19:12:52,853: Epoch 29/38 Batch 6400/7662 eta: 9:07:30.084767	Training Loss 0.0904 (0.0874)	Training Prec@1 100.000 (99.936)	Training Prec@5 100.000 (99.978)	
2022-05-11 19:12:52,853: ============================================================
2022-05-11 19:13:39,679: time cost, forward:0.17175106548092736, backward:0.10519369276950388, data cost:0.19056752352076947 
2022-05-11 19:13:39,680: ============================================================
2022-05-11 19:13:39,680: Epoch 29/38 Batch 6500/7662 eta: 9:07:15.493562	Training Loss 0.0902 (0.0875)	Training Prec@1 100.000 (99.935)	Training Prec@5 100.000 (99.977)	
2022-05-11 19:13:39,680: ============================================================
2022-05-11 19:14:26,477: time cost, forward:0.1717571928241358, backward:0.10518971752589319, data cost:0.19056641291372522 
2022-05-11 19:14:26,477: ============================================================
2022-05-11 19:14:26,477: Epoch 29/38 Batch 6600/7662 eta: 9:06:07.891594	Training Loss 0.0931 (0.0876)	Training Prec@1 100.000 (99.935)	Training Prec@5 100.000 (99.978)	
2022-05-11 19:14:26,477: ============================================================
2022-05-11 19:15:13,238: time cost, forward:0.1717624106608606, backward:0.10518599004954754, data cost:0.19056235375484792 
2022-05-11 19:15:13,239: ============================================================
2022-05-11 19:15:13,239: Epoch 29/38 Batch 6700/7662 eta: 9:04:56.350721	Training Loss 0.0934 (0.0877)	Training Prec@1 100.000 (99.935)	Training Prec@5 100.000 (99.977)	
2022-05-11 19:15:13,239: ============================================================
2022-05-11 19:15:59,994: time cost, forward:0.17176954917021228, backward:0.10518258255112607, data cost:0.19055352622681743 
2022-05-11 19:15:59,995: ============================================================
2022-05-11 19:15:59,995: Epoch 29/38 Batch 6800/7662 eta: 9:04:05.444864	Training Loss 0.0915 (0.0877)	Training Prec@1 100.000 (99.935)	Training Prec@5 100.000 (99.977)	
2022-05-11 19:15:59,995: ============================================================
2022-05-11 19:16:46,793: time cost, forward:0.17177809499488186, backward:0.10517971231239674, data cost:0.19055097838176613 
2022-05-11 19:16:46,794: ============================================================
2022-05-11 19:16:46,794: Epoch 29/38 Batch 6900/7662 eta: 9:03:48.790151	Training Loss 0.0923 (0.0878)	Training Prec@1 100.000 (99.935)	Training Prec@5 100.000 (99.977)	
2022-05-11 19:16:46,794: ============================================================
2022-05-11 19:17:33,602: time cost, forward:0.17178396838684562, backward:0.10518281792620111, data cost:0.19054664348019654 
2022-05-11 19:17:33,603: ============================================================
2022-05-11 19:17:33,603: Epoch 29/38 Batch 7000/7662 eta: 9:03:08.971584	Training Loss 0.0942 (0.0879)	Training Prec@1 99.805 (99.934)	Training Prec@5 100.000 (99.977)	
2022-05-11 19:17:33,603: ============================================================
2022-05-11 19:18:20,461: time cost, forward:0.17179190012615722, backward:0.10518771588827526, data cost:0.19054496521714004 
2022-05-11 19:18:20,461: ============================================================
2022-05-11 19:18:20,461: Epoch 29/38 Batch 7100/7662 eta: 9:02:56.385077	Training Loss 0.0870 (0.0880)	Training Prec@1 100.000 (99.934)	Training Prec@5 100.000 (99.977)	
2022-05-11 19:18:20,461: ============================================================
2022-05-11 19:19:07,325: time cost, forward:0.17179782630039728, backward:0.10518347827870575, data cost:0.19055528868600916 
2022-05-11 19:19:07,325: ============================================================
2022-05-11 19:19:07,325: Epoch 29/38 Batch 7200/7662 eta: 9:02:13.583949	Training Loss 0.0927 (0.0881)	Training Prec@1 99.805 (99.934)	Training Prec@5 100.000 (99.977)	
2022-05-11 19:19:07,326: ============================================================
2022-05-11 19:19:54,059: time cost, forward:0.17180237673393486, backward:0.10518098622254271, data cost:0.1905471706965277 
2022-05-11 19:19:54,060: ============================================================
2022-05-11 19:19:54,060: Epoch 29/38 Batch 7300/7662 eta: 8:59:56.780387	Training Loss 0.0934 (0.0881)	Training Prec@1 100.000 (99.933)	Training Prec@5 100.000 (99.977)	
2022-05-11 19:19:54,060: ============================================================
2022-05-11 19:20:40,760: time cost, forward:0.17180597989973884, backward:0.10517858949798654, data cost:0.1905354413652375 
2022-05-11 19:20:40,761: ============================================================
2022-05-11 19:20:40,761: Epoch 29/38 Batch 7400/7662 eta: 8:58:46.817830	Training Loss 0.0959 (0.0882)	Training Prec@1 99.805 (99.933)	Training Prec@5 100.000 (99.977)	
2022-05-11 19:20:40,761: ============================================================
2022-05-11 19:21:27,500: time cost, forward:0.17180848213843877, backward:0.10517511146515907, data cost:0.1905312245647849 
2022-05-11 19:21:27,500: ============================================================
2022-05-11 19:21:27,500: Epoch 29/38 Batch 7500/7662 eta: 8:58:26.826966	Training Loss 0.0876 (0.0883)	Training Prec@1 99.805 (99.933)	Training Prec@5 100.000 (99.977)	
2022-05-11 19:21:27,500: ============================================================
2022-05-11 19:22:14,238: time cost, forward:0.17181225340057948, backward:0.10517154836171488, data cost:0.19052561259078327 
2022-05-11 19:22:14,239: ============================================================
2022-05-11 19:22:14,239: Epoch 29/38 Batch 7600/7662 eta: 8:57:39.325533	Training Loss 0.0960 (0.0884)	Training Prec@1 100.000 (99.933)	Training Prec@5 100.000 (99.977)	
2022-05-11 19:22:14,239: ============================================================
2022-05-11 19:22:44,966: Epoch: 29/38 eta: 8:57:09.880328	Training Loss 0.0966 (0.0884)	Training Prec@1 99.609 (99.932)	Training Prec@5 99.805 (99.977)
2022-05-11 19:22:44,967: ============================================================
2022-05-11 19:23:34,492: time cost, forward:0.1843159126512932, backward:0.10587864211111357, data cost:0.207289507894805 
2022-05-11 19:23:34,492: ============================================================
2022-05-11 19:23:34,492: Epoch 30/38 Batch 100/7662 eta: 9:27:42.882773	Training Loss 0.0830 (0.0780)	Training Prec@1 99.805 (99.972)	Training Prec@5 100.000 (99.994)	
2022-05-11 19:23:34,493: ============================================================
2022-05-11 19:24:21,399: time cost, forward:0.17830885355197004, backward:0.10612874055028561, data cost:0.19859365242809507 
2022-05-11 19:24:21,399: ============================================================
2022-05-11 19:24:21,399: Epoch 30/38 Batch 200/7662 eta: 8:57:32.740896	Training Loss 0.0766 (0.0772)	Training Prec@1 100.000 (99.971)	Training Prec@5 100.000 (99.991)	
2022-05-11 19:24:21,399: ============================================================
2022-05-11 19:25:07,974: time cost, forward:0.1755604169839202, backward:0.10596295662946924, data cost:0.19563893809366387 
2022-05-11 19:25:07,974: ============================================================
2022-05-11 19:25:07,974: Epoch 30/38 Batch 300/7662 eta: 8:52:57.785230	Training Loss 0.0775 (0.0768)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.991)	
2022-05-11 19:25:07,974: ============================================================
2022-05-11 19:25:54,379: time cost, forward:0.17394729365681047, backward:0.10571811551737008, data cost:0.1941428668516919 
2022-05-11 19:25:54,379: ============================================================
2022-05-11 19:25:54,379: Epoch 30/38 Batch 400/7662 eta: 8:50:14.941562	Training Loss 0.0757 (0.0766)	Training Prec@1 100.000 (99.965)	Training Prec@5 100.000 (99.990)	
2022-05-11 19:25:54,379: ============================================================
2022-05-11 19:26:40,818: time cost, forward:0.17301828732232533, backward:0.1055955194041342, data cost:0.19325691234611558 
2022-05-11 19:26:40,819: ============================================================
2022-05-11 19:26:40,819: Epoch 30/38 Batch 500/7662 eta: 8:49:52.107466	Training Loss 0.0777 (0.0764)	Training Prec@1 100.000 (99.966)	Training Prec@5 100.000 (99.989)	
2022-05-11 19:26:40,819: ============================================================
2022-05-11 19:27:27,256: time cost, forward:0.17237860213138026, backward:0.10551934807447838, data cost:0.19267876000953635 
2022-05-11 19:27:27,256: ============================================================
2022-05-11 19:27:27,256: Epoch 30/38 Batch 600/7662 eta: 8:49:03.893465	Training Loss 0.0766 (0.0762)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.990)	
2022-05-11 19:27:27,256: ============================================================
2022-05-11 19:28:13,735: time cost, forward:0.17198376048446895, backward:0.10545998172186986, data cost:0.19226730534958736 
2022-05-11 19:28:13,735: ============================================================
2022-05-11 19:28:13,735: Epoch 30/38 Batch 700/7662 eta: 8:48:46.258532	Training Loss 0.0724 (0.0760)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.990)	
2022-05-11 19:28:13,735: ============================================================
2022-05-11 19:29:00,284: time cost, forward:0.17175796154294354, backward:0.10541828344103989, data cost:0.19197756298194094 
2022-05-11 19:29:00,284: ============================================================
2022-05-11 19:29:00,284: Epoch 30/38 Batch 800/7662 eta: 8:48:47.308064	Training Loss 0.0764 (0.0759)	Training Prec@1 99.805 (99.968)	Training Prec@5 99.805 (99.989)	
2022-05-11 19:29:00,284: ============================================================
2022-05-11 19:29:46,818: time cost, forward:0.17159265432262313, backward:0.1053896470117622, data cost:0.19171964605074704 
2022-05-11 19:29:46,818: ============================================================
2022-05-11 19:29:46,819: Epoch 30/38 Batch 900/7662 eta: 8:47:50.796498	Training Loss 0.0801 (0.0758)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.989)	
2022-05-11 19:29:46,819: ============================================================
2022-05-11 19:30:33,389: time cost, forward:0.1715015448607482, backward:0.10536967049370538, data cost:0.19150644069438702 
2022-05-11 19:30:33,390: ============================================================
2022-05-11 19:30:33,390: Epoch 30/38 Batch 1000/7662 eta: 8:47:29.285442	Training Loss 0.0689 (0.0757)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.988)	
2022-05-11 19:30:33,390: ============================================================
2022-05-11 19:31:19,975: time cost, forward:0.17144492737698055, backward:0.1053164970668692, data cost:0.1913647046405907 
2022-05-11 19:31:19,975: ============================================================
2022-05-11 19:31:19,975: Epoch 30/38 Batch 1100/7662 eta: 8:46:52.644386	Training Loss 0.0743 (0.0756)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.988)	
2022-05-11 19:31:19,976: ============================================================
2022-05-11 19:32:06,588: time cost, forward:0.171392613793533, backward:0.10527881947629546, data cost:0.1912566969253502 
2022-05-11 19:32:06,589: ============================================================
2022-05-11 19:32:06,589: Epoch 30/38 Batch 1200/7662 eta: 8:46:24.646393	Training Loss 0.0746 (0.0755)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.987)	
2022-05-11 19:32:06,589: ============================================================
2022-05-11 19:32:53,218: time cost, forward:0.17135581849078382, backward:0.10524722610279814, data cost:0.19118271193383196 
2022-05-11 19:32:53,219: ============================================================
2022-05-11 19:32:53,219: Epoch 30/38 Batch 1300/7662 eta: 8:45:49.589223	Training Loss 0.0760 (0.0754)	Training Prec@1 100.000 (99.966)	Training Prec@5 100.000 (99.987)	
2022-05-11 19:32:53,219: ============================================================
2022-05-11 19:33:39,846: time cost, forward:0.17133007158629804, backward:0.10521925731247199, data cost:0.19111259244355752 
2022-05-11 19:33:39,846: ============================================================
2022-05-11 19:33:39,846: Epoch 30/38 Batch 1400/7662 eta: 8:45:00.851127	Training Loss 0.0775 (0.0753)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.988)	
2022-05-11 19:33:39,846: ============================================================
2022-05-11 19:34:26,530: time cost, forward:0.1713404927435042, backward:0.10521155567945362, data cost:0.19104122161229029 
2022-05-11 19:34:26,530: ============================================================
2022-05-11 19:34:26,530: Epoch 30/38 Batch 1500/7662 eta: 8:44:52.582409	Training Loss 0.0774 (0.0752)	Training Prec@1 99.609 (99.967)	Training Prec@5 99.805 (99.987)	
2022-05-11 19:34:26,530: ============================================================
2022-05-11 19:35:13,216: time cost, forward:0.17135157087134004, backward:0.10519042366963018, data cost:0.1909901077408877 
2022-05-11 19:35:13,216: ============================================================
2022-05-11 19:35:13,216: Epoch 30/38 Batch 1600/7662 eta: 8:44:07.269226	Training Loss 0.0771 (0.0752)	Training Prec@1 100.000 (99.966)	Training Prec@5 100.000 (99.987)	
2022-05-11 19:35:13,216: ============================================================
2022-05-11 19:35:59,894: time cost, forward:0.1713562574437115, backward:0.10517275550914133, data cost:0.19094430046126448 
2022-05-11 19:35:59,895: ============================================================
2022-05-11 19:35:59,895: Epoch 30/38 Batch 1700/7662 eta: 8:43:15.534607	Training Loss 0.0766 (0.0751)	Training Prec@1 100.000 (99.966)	Training Prec@5 100.000 (99.987)	
2022-05-11 19:35:59,895: ============================================================
2022-05-11 19:36:46,568: time cost, forward:0.1713698443072978, backward:0.10516168489397865, data cost:0.19088684790262983 
2022-05-11 19:36:46,568: ============================================================
2022-05-11 19:36:46,568: Epoch 30/38 Batch 1800/7662 eta: 8:42:25.516912	Training Loss 0.0682 (0.0751)	Training Prec@1 100.000 (99.966)	Training Prec@5 100.000 (99.988)	
2022-05-11 19:36:46,568: ============================================================
2022-05-11 19:37:33,265: time cost, forward:0.17138332728023842, backward:0.10515051016122055, data cost:0.19084104379269246 
2022-05-11 19:37:33,265: ============================================================
2022-05-11 19:37:33,265: Epoch 30/38 Batch 1900/7662 eta: 8:41:54.409666	Training Loss 0.0703 (0.0750)	Training Prec@1 100.000 (99.965)	Training Prec@5 100.000 (99.987)	
2022-05-11 19:37:33,265: ============================================================
2022-05-11 19:38:19,937: time cost, forward:0.1714019367490905, backward:0.1051396924057503, data cost:0.19078763930304996 
2022-05-11 19:38:19,938: ============================================================
2022-05-11 19:38:19,938: Epoch 30/38 Batch 2000/7662 eta: 8:40:51.602040	Training Loss 0.0755 (0.0750)	Training Prec@1 100.000 (99.966)	Training Prec@5 100.000 (99.987)	
2022-05-11 19:38:19,938: ============================================================
2022-05-11 19:39:06,608: time cost, forward:0.17142293327135266, backward:0.10513272121896512, data cost:0.19073258200505053 
2022-05-11 19:39:06,608: ============================================================
2022-05-11 19:39:06,608: Epoch 30/38 Batch 2100/7662 eta: 8:40:03.433926	Training Loss 0.0760 (0.0749)	Training Prec@1 100.000 (99.966)	Training Prec@5 100.000 (99.987)	
2022-05-11 19:39:06,609: ============================================================
2022-05-11 19:39:53,326: time cost, forward:0.1714259709700393, backward:0.10512974762060036, data cost:0.1907161589696658 
2022-05-11 19:39:53,326: ============================================================
2022-05-11 19:39:53,326: Epoch 30/38 Batch 2200/7662 eta: 8:39:48.323781	Training Loss 0.0763 (0.0749)	Training Prec@1 99.805 (99.966)	Training Prec@5 100.000 (99.987)	
2022-05-11 19:39:53,326: ============================================================
2022-05-11 19:40:40,058: time cost, forward:0.17143446697054246, backward:0.10512339576216768, data cost:0.19070454492108518 
2022-05-11 19:40:40,058: ============================================================
2022-05-11 19:40:40,058: Epoch 30/38 Batch 2300/7662 eta: 8:39:11.055507	Training Loss 0.0754 (0.0749)	Training Prec@1 100.000 (99.966)	Training Prec@5 100.000 (99.987)	
2022-05-11 19:40:40,058: ============================================================
2022-05-11 19:41:26,775: time cost, forward:0.17145462570810577, backward:0.10511582878640713, data cost:0.19067738989384386 
2022-05-11 19:41:26,775: ============================================================
2022-05-11 19:41:26,775: Epoch 30/38 Batch 2400/7662 eta: 8:38:14.498795	Training Loss 0.0742 (0.0749)	Training Prec@1 100.000 (99.966)	Training Prec@5 100.000 (99.987)	
2022-05-11 19:41:26,775: ============================================================
2022-05-11 19:42:13,463: time cost, forward:0.17145936209566834, backward:0.10510819575556662, data cost:0.19065463318735087 
2022-05-11 19:42:13,463: ============================================================
2022-05-11 19:42:13,464: Epoch 30/38 Batch 2500/7662 eta: 8:37:08.489762	Training Loss 0.0751 (0.0748)	Training Prec@1 100.000 (99.966)	Training Prec@5 100.000 (99.987)	
2022-05-11 19:42:13,464: ============================================================
2022-05-11 19:43:00,165: time cost, forward:0.17145926533134317, backward:0.10510451255187754, data cost:0.19064067280627342 
2022-05-11 19:43:00,165: ============================================================
2022-05-11 19:43:00,165: Epoch 30/38 Batch 2600/7662 eta: 8:36:30.823011	Training Loss 0.0722 (0.0748)	Training Prec@1 100.000 (99.965)	Training Prec@5 100.000 (99.987)	
2022-05-11 19:43:00,165: ============================================================
2022-05-11 19:43:46,874: time cost, forward:0.1714643369387061, backward:0.1051010495426479, data cost:0.190624656214366 
2022-05-11 19:43:46,874: ============================================================
2022-05-11 19:43:46,874: Epoch 30/38 Batch 2700/7662 eta: 8:35:48.682108	Training Loss 0.0726 (0.0748)	Training Prec@1 100.000 (99.965)	Training Prec@5 100.000 (99.987)	
2022-05-11 19:43:46,874: ============================================================
2022-05-11 19:44:33,589: time cost, forward:0.1714756135303406, backward:0.10509641667100607, data cost:0.19060718046422087 
2022-05-11 19:44:33,589: ============================================================
2022-05-11 19:44:33,589: Epoch 30/38 Batch 2800/7662 eta: 8:35:06.303770	Training Loss 0.0690 (0.0747)	Training Prec@1 100.000 (99.965)	Training Prec@5 100.000 (99.987)	
2022-05-11 19:44:33,589: ============================================================
2022-05-11 19:45:20,281: time cost, forward:0.17147099556450845, backward:0.10509494988414163, data cost:0.19059101759708927 
2022-05-11 19:45:20,281: ============================================================
2022-05-11 19:45:20,281: Epoch 30/38 Batch 2900/7662 eta: 8:34:04.337521	Training Loss 0.0711 (0.0747)	Training Prec@1 100.000 (99.965)	Training Prec@5 100.000 (99.987)	
2022-05-11 19:45:20,281: ============================================================
2022-05-11 19:46:06,983: time cost, forward:0.17146945643639636, backward:0.10509561760976498, data cost:0.19057835734419204 
2022-05-11 19:46:06,983: ============================================================
2022-05-11 19:46:06,983: Epoch 30/38 Batch 3000/7662 eta: 8:33:24.129971	Training Loss 0.0721 (0.0747)	Training Prec@1 100.000 (99.965)	Training Prec@5 100.000 (99.987)	
2022-05-11 19:46:06,983: ============================================================
2022-05-11 19:46:53,681: time cost, forward:0.17147093143875503, backward:0.1050959490468018, data cost:0.1905628140798189 
2022-05-11 19:46:53,682: ============================================================
2022-05-11 19:46:53,682: Epoch 30/38 Batch 3100/7662 eta: 8:32:35.251893	Training Loss 0.0728 (0.0746)	Training Prec@1 100.000 (99.964)	Training Prec@5 100.000 (99.987)	
2022-05-11 19:46:53,682: ============================================================
2022-05-11 19:47:40,404: time cost, forward:0.17147650022587205, backward:0.10509508592928153, data cost:0.19055280166702293 
2022-05-11 19:47:40,404: ============================================================
2022-05-11 19:47:40,404: Epoch 30/38 Batch 3200/7662 eta: 8:32:04.039998	Training Loss 0.0708 (0.0746)	Training Prec@1 100.000 (99.963)	Training Prec@5 100.000 (99.986)	
2022-05-11 19:47:40,404: ============================================================
2022-05-11 19:48:27,173: time cost, forward:0.17148089813586256, backward:0.10509535897027437, data cost:0.19054993848867147 
2022-05-11 19:48:27,173: ============================================================
2022-05-11 19:48:27,173: Epoch 30/38 Batch 3300/7662 eta: 8:31:48.257964	Training Loss 0.0734 (0.0746)	Training Prec@1 100.000 (99.963)	Training Prec@5 100.000 (99.986)	
2022-05-11 19:48:27,173: ============================================================
2022-05-11 19:49:13,943: time cost, forward:0.17149273764915277, backward:0.10509632032876437, data cost:0.19054631009877657 
2022-05-11 19:49:13,943: ============================================================
2022-05-11 19:49:13,943: Epoch 30/38 Batch 3400/7662 eta: 8:31:01.942256	Training Loss 0.0749 (0.0745)	Training Prec@1 100.000 (99.963)	Training Prec@5 100.000 (99.986)	
2022-05-11 19:49:13,943: ============================================================
2022-05-11 19:50:00,636: time cost, forward:0.17149431278242933, backward:0.10509739517654546, data cost:0.19052634017063433 
2022-05-11 19:50:00,637: ============================================================
2022-05-11 19:50:00,637: Epoch 30/38 Batch 3500/7662 eta: 8:29:25.105059	Training Loss 0.0772 (0.0745)	Training Prec@1 100.000 (99.963)	Training Prec@5 100.000 (99.986)	
2022-05-11 19:50:00,637: ============================================================
2022-05-11 19:50:47,390: time cost, forward:0.1714958250274192, backward:0.10509850866895942, data cost:0.19052430509560372 
2022-05-11 19:50:47,391: ============================================================
2022-05-11 19:50:47,391: Epoch 30/38 Batch 3600/7662 eta: 8:29:17.964591	Training Loss 0.0764 (0.0745)	Training Prec@1 100.000 (99.963)	Training Prec@5 100.000 (99.986)	
2022-05-11 19:50:47,391: ============================================================
2022-05-11 19:51:34,170: time cost, forward:0.17149949821468044, backward:0.1050996196434349, data cost:0.19052823500621638 
2022-05-11 19:51:34,171: ============================================================
2022-05-11 19:51:34,171: Epoch 30/38 Batch 3700/7662 eta: 8:28:48.072273	Training Loss 0.0759 (0.0745)	Training Prec@1 100.000 (99.963)	Training Prec@5 100.000 (99.986)	
2022-05-11 19:51:34,171: ============================================================
2022-05-11 19:52:20,940: time cost, forward:0.17150995711898703, backward:0.1051023111245481, data cost:0.1905233023448441 
2022-05-11 19:52:20,940: ============================================================
2022-05-11 19:52:20,940: Epoch 30/38 Batch 3800/7662 eta: 8:27:54.562751	Training Loss 0.0717 (0.0744)	Training Prec@1 100.000 (99.963)	Training Prec@5 100.000 (99.986)	
2022-05-11 19:52:20,940: ============================================================
2022-05-11 19:53:07,746: time cost, forward:0.171518100411747, backward:0.10510464104727985, data cost:0.19052445757049694 
2022-05-11 19:53:07,746: ============================================================
2022-05-11 19:53:07,746: Epoch 30/38 Batch 3900/7662 eta: 8:27:31.376710	Training Loss 0.0724 (0.0744)	Training Prec@1 99.805 (99.963)	Training Prec@5 100.000 (99.986)	
2022-05-11 19:53:07,746: ============================================================
2022-05-11 19:53:54,569: time cost, forward:0.17152911855388087, backward:0.10510605107131199, data cost:0.1905306732991422 
2022-05-11 19:53:54,570: ============================================================
2022-05-11 19:53:54,570: Epoch 30/38 Batch 4000/7662 eta: 8:26:56.147780	Training Loss 0.0757 (0.0744)	Training Prec@1 100.000 (99.963)	Training Prec@5 100.000 (99.986)	
2022-05-11 19:53:54,570: ============================================================
2022-05-11 19:54:41,412: time cost, forward:0.1715427362851964, backward:0.10510779037857149, data cost:0.1905415254152237 
2022-05-11 19:54:41,412: ============================================================
2022-05-11 19:54:41,413: Epoch 30/38 Batch 4100/7662 eta: 8:26:21.834680	Training Loss 0.0723 (0.0744)	Training Prec@1 100.000 (99.963)	Training Prec@5 100.000 (99.986)	
2022-05-11 19:54:41,413: ============================================================
2022-05-11 19:55:28,055: time cost, forward:0.17149996876745005, backward:0.10510777036017763, data cost:0.1905601738350367 
2022-05-11 19:55:28,056: ============================================================
2022-05-11 19:55:28,056: Epoch 30/38 Batch 4200/7662 eta: 8:23:25.619812	Training Loss 0.0717 (0.0744)	Training Prec@1 100.000 (99.963)	Training Prec@5 100.000 (99.986)	
2022-05-11 19:55:28,056: ============================================================
2022-05-11 19:56:14,682: time cost, forward:0.17146175987472587, backward:0.1051056245283405, data cost:0.19057335030563932 
2022-05-11 19:56:14,682: ============================================================
2022-05-11 19:56:14,682: Epoch 30/38 Batch 4300/7662 eta: 8:22:28.282520	Training Loss 0.0741 (0.0744)	Training Prec@1 100.000 (99.963)	Training Prec@5 100.000 (99.986)	
2022-05-11 19:56:14,682: ============================================================
2022-05-11 19:57:01,314: time cost, forward:0.17143743562275618, backward:0.10510403672574081, data cost:0.19057473937986547 
2022-05-11 19:57:01,314: ============================================================
2022-05-11 19:57:01,314: Epoch 30/38 Batch 4400/7662 eta: 8:21:45.071128	Training Loss 0.0770 (0.0744)	Training Prec@1 100.000 (99.962)	Training Prec@5 100.000 (99.986)	
2022-05-11 19:57:01,314: ============================================================
2022-05-11 19:57:47,943: time cost, forward:0.17141031551212702, backward:0.10510427020713736, data cost:0.19057516363838775 
2022-05-11 19:57:47,944: ============================================================
2022-05-11 19:57:47,944: Epoch 30/38 Batch 4500/7662 eta: 8:20:57.076401	Training Loss 0.0711 (0.0743)	Training Prec@1 100.000 (99.962)	Training Prec@5 100.000 (99.986)	
2022-05-11 19:57:47,944: ============================================================
2022-05-11 19:58:34,631: time cost, forward:0.17138956847152495, backward:0.10510440934453484, data cost:0.19057392348256103 
2022-05-11 19:58:34,631: ============================================================
2022-05-11 19:58:34,631: Epoch 30/38 Batch 4600/7662 eta: 8:20:47.334688	Training Loss 0.0775 (0.0743)	Training Prec@1 100.000 (99.962)	Training Prec@5 100.000 (99.986)	
2022-05-11 19:58:34,631: ============================================================
2022-05-11 19:59:21,325: time cost, forward:0.17138772468461358, backward:0.10510207567095224, data cost:0.19056700548990707 
2022-05-11 19:59:21,325: ============================================================
2022-05-11 19:59:21,326: Epoch 30/38 Batch 4700/7662 eta: 8:20:05.475268	Training Loss 0.0764 (0.0743)	Training Prec@1 99.805 (99.962)	Training Prec@5 100.000 (99.986)	
2022-05-11 19:59:21,326: ============================================================
2022-05-11 20:00:08,038: time cost, forward:0.1713852961874674, backward:0.10510235618715312, data cost:0.19056506791843128 
2022-05-11 20:00:08,039: ============================================================
2022-05-11 20:00:08,039: Epoch 30/38 Batch 4800/7662 eta: 8:19:30.678758	Training Loss 0.0737 (0.0743)	Training Prec@1 100.000 (99.962)	Training Prec@5 100.000 (99.986)	
2022-05-11 20:00:08,039: ============================================================
2022-05-11 20:00:54,826: time cost, forward:0.17139383558595295, backward:0.10509946994037865, data cost:0.19057076837267528 
2022-05-11 20:00:54,827: ============================================================
2022-05-11 20:00:54,827: Epoch 30/38 Batch 4900/7662 eta: 8:19:31.948356	Training Loss 0.0742 (0.0743)	Training Prec@1 99.805 (99.962)	Training Prec@5 99.805 (99.986)	
2022-05-11 20:00:54,827: ============================================================
2022-05-11 20:01:41,538: time cost, forward:0.17139343624950576, backward:0.10509497839394845, data cost:0.19057142884761338 
2022-05-11 20:01:41,538: ============================================================
2022-05-11 20:01:41,538: Epoch 30/38 Batch 5000/7662 eta: 8:17:56.311933	Training Loss 0.0710 (0.0743)	Training Prec@1 100.000 (99.962)	Training Prec@5 100.000 (99.986)	
2022-05-11 20:01:41,539: ============================================================
2022-05-11 20:02:28,351: time cost, forward:0.17139449599304019, backward:0.1050931832256867, data cost:0.19058567637390986 
2022-05-11 20:02:28,351: ============================================================
2022-05-11 20:02:28,351: Epoch 30/38 Batch 5100/7662 eta: 8:18:14.259445	Training Loss 0.0756 (0.0742)	Training Prec@1 100.000 (99.962)	Training Prec@5 100.000 (99.986)	
2022-05-11 20:02:28,351: ============================================================
2022-05-11 20:03:15,073: time cost, forward:0.1713957645315738, backward:0.10509000844417982, data cost:0.19058296079244905 
2022-05-11 20:03:15,074: ============================================================
2022-05-11 20:03:15,074: Epoch 30/38 Batch 5200/7662 eta: 8:16:29.847018	Training Loss 0.0679 (0.0742)	Training Prec@1 100.000 (99.962)	Training Prec@5 100.000 (99.986)	
2022-05-11 20:03:15,074: ============================================================
2022-05-11 20:04:01,832: time cost, forward:0.171400880156699, backward:0.10508777326312824, data cost:0.19058487261887158 
2022-05-11 20:04:01,832: ============================================================
2022-05-11 20:04:01,832: Epoch 30/38 Batch 5300/7662 eta: 8:16:05.966714	Training Loss 0.0714 (0.0742)	Training Prec@1 99.805 (99.962)	Training Prec@5 100.000 (99.986)	
2022-05-11 20:04:01,833: ============================================================
2022-05-11 20:04:48,643: time cost, forward:0.17140637479196721, backward:0.10508495654236677, data cost:0.19059413922100205 
2022-05-11 20:04:48,643: ============================================================
2022-05-11 20:04:48,643: Epoch 30/38 Batch 5400/7662 eta: 8:15:52.355494	Training Loss 0.0757 (0.0742)	Training Prec@1 100.000 (99.962)	Training Prec@5 100.000 (99.986)	
2022-05-11 20:04:48,643: ============================================================
2022-05-11 20:05:35,474: time cost, forward:0.1714182363507704, backward:0.10508226945110181, data cost:0.19060010120074822 
2022-05-11 20:05:35,474: ============================================================
2022-05-11 20:05:35,474: Epoch 30/38 Batch 5500/7662 eta: 8:15:18.472394	Training Loss 0.0768 (0.0742)	Training Prec@1 100.000 (99.962)	Training Prec@5 100.000 (99.986)	
2022-05-11 20:05:35,474: ============================================================
2022-05-11 20:06:22,278: time cost, forward:0.1714306957999773, backward:0.10508121654676059, data cost:0.19060080199182874 
2022-05-11 20:06:22,279: ============================================================
2022-05-11 20:06:22,279: Epoch 30/38 Batch 5600/7662 eta: 8:14:15.031199	Training Loss 0.0751 (0.0742)	Training Prec@1 100.000 (99.962)	Training Prec@5 100.000 (99.986)	
2022-05-11 20:06:22,279: ============================================================
2022-05-11 20:07:09,075: time cost, forward:0.17144220497424528, backward:0.10507731823403284, data cost:0.19060338365548452 
2022-05-11 20:07:09,075: ============================================================
2022-05-11 20:07:09,075: Epoch 30/38 Batch 5700/7662 eta: 8:13:22.808483	Training Loss 0.0779 (0.0742)	Training Prec@1 100.000 (99.962)	Training Prec@5 100.000 (99.986)	
2022-05-11 20:07:09,075: ============================================================
2022-05-11 20:07:55,936: time cost, forward:0.17145333197183044, backward:0.10508603025128213, data cost:0.19060463123351135 
2022-05-11 20:07:55,936: ============================================================
2022-05-11 20:07:55,936: Epoch 30/38 Batch 5800/7662 eta: 8:13:17.185533	Training Loss 0.0712 (0.0742)	Training Prec@1 100.000 (99.962)	Training Prec@5 100.000 (99.986)	
2022-05-11 20:07:55,936: ============================================================
2022-05-11 20:08:42,947: time cost, forward:0.1714644917877554, backward:0.10510831393312854, data cost:0.19061694744987637 
2022-05-11 20:08:42,947: ============================================================
2022-05-11 20:08:42,947: Epoch 30/38 Batch 5900/7662 eta: 8:14:04.534586	Training Loss 0.0748 (0.0741)	Training Prec@1 100.000 (99.963)	Training Prec@5 100.000 (99.986)	
2022-05-11 20:08:42,947: ============================================================
2022-05-11 20:09:29,880: time cost, forward:0.17147293737042366, backward:0.10513161432546345, data cost:0.19061435475153096 
2022-05-11 20:09:29,880: ============================================================
2022-05-11 20:09:29,880: Epoch 30/38 Batch 6000/7662 eta: 8:12:28.660555	Training Loss 0.0725 (0.0741)	Training Prec@1 100.000 (99.962)	Training Prec@5 100.000 (99.986)	
2022-05-11 20:09:29,880: ============================================================
2022-05-11 20:10:16,709: time cost, forward:0.1714820579967258, backward:0.1051406024576973, data cost:0.19060948043988366 
2022-05-11 20:10:16,709: ============================================================
2022-05-11 20:10:16,709: Epoch 30/38 Batch 6100/7662 eta: 8:10:36.114919	Training Loss 0.0722 (0.0741)	Training Prec@1 100.000 (99.962)	Training Prec@5 100.000 (99.986)	
2022-05-11 20:10:16,709: ============================================================
2022-05-11 20:11:03,475: time cost, forward:0.17148718993151105, backward:0.10513732309859883, data cost:0.1906081714790124 
2022-05-11 20:11:03,476: ============================================================
2022-05-11 20:11:03,476: Epoch 30/38 Batch 6200/7662 eta: 8:09:10.260452	Training Loss 0.0792 (0.0741)	Training Prec@1 100.000 (99.962)	Training Prec@5 100.000 (99.986)	
2022-05-11 20:11:03,476: ============================================================
2022-05-11 20:11:50,256: time cost, forward:0.17149615605722668, backward:0.10513436784818449, data cost:0.19060721157429464 
2022-05-11 20:11:50,256: ============================================================
2022-05-11 20:11:50,256: Epoch 30/38 Batch 6300/7662 eta: 8:08:32.252165	Training Loss 0.0698 (0.0741)	Training Prec@1 100.000 (99.962)	Training Prec@5 100.000 (99.986)	
2022-05-11 20:11:50,256: ============================================================
2022-05-11 20:12:37,046: time cost, forward:0.17150293832496658, backward:0.10513191007789102, data cost:0.1906088518526316 
2022-05-11 20:12:37,046: ============================================================
2022-05-11 20:12:37,047: Epoch 30/38 Batch 6400/7662 eta: 8:07:51.491656	Training Loss 0.0753 (0.0741)	Training Prec@1 100.000 (99.962)	Training Prec@5 100.000 (99.986)	
2022-05-11 20:12:37,047: ============================================================
2022-05-11 20:13:23,790: time cost, forward:0.1715083354105306, backward:0.10512746024230825, data cost:0.19060670318814824 
2022-05-11 20:13:23,790: ============================================================
2022-05-11 20:13:23,791: Epoch 30/38 Batch 6500/7662 eta: 8:06:35.831807	Training Loss 0.0742 (0.0741)	Training Prec@1 100.000 (99.962)	Training Prec@5 100.000 (99.986)	
2022-05-11 20:13:23,791: ============================================================
2022-05-11 20:14:10,608: time cost, forward:0.17151769426198127, backward:0.10512449636949267, data cost:0.19061038638266817 
2022-05-11 20:14:10,608: ============================================================
2022-05-11 20:14:10,608: Epoch 30/38 Batch 6600/7662 eta: 8:06:35.008155	Training Loss 0.0733 (0.0741)	Training Prec@1 100.000 (99.962)	Training Prec@5 100.000 (99.986)	
2022-05-11 20:14:10,608: ============================================================
2022-05-11 20:14:57,393: time cost, forward:0.1715300025148416, backward:0.10512279599331123, data cost:0.19060439233513693 
2022-05-11 20:14:57,393: ============================================================
2022-05-11 20:14:57,393: Epoch 30/38 Batch 6700/7662 eta: 8:05:27.917438	Training Loss 0.0758 (0.0741)	Training Prec@1 100.000 (99.962)	Training Prec@5 100.000 (99.986)	
2022-05-11 20:14:57,393: ============================================================
2022-05-11 20:15:44,204: time cost, forward:0.171541008603522, backward:0.10512050773698033, data cost:0.19060423276339897 
2022-05-11 20:15:44,204: ============================================================
2022-05-11 20:15:44,204: Epoch 30/38 Batch 6800/7662 eta: 8:04:57.368709	Training Loss 0.0748 (0.0741)	Training Prec@1 100.000 (99.962)	Training Prec@5 100.000 (99.986)	
2022-05-11 20:15:44,205: ============================================================
2022-05-11 20:16:30,945: time cost, forward:0.17154524816708525, backward:0.10511899409146909, data cost:0.19059810308049185 
2022-05-11 20:16:30,946: ============================================================
2022-05-11 20:16:30,946: Epoch 30/38 Batch 6900/7662 eta: 8:03:27.235663	Training Loss 0.0693 (0.0741)	Training Prec@1 100.000 (99.962)	Training Prec@5 100.000 (99.986)	
2022-05-11 20:16:30,946: ============================================================
2022-05-11 20:17:17,644: time cost, forward:0.17155109379764694, backward:0.10511696469802519, data cost:0.1905867643297732 
2022-05-11 20:17:17,644: ============================================================
2022-05-11 20:17:17,645: Epoch 30/38 Batch 7000/7662 eta: 8:02:14.073797	Training Loss 0.0743 (0.0741)	Training Prec@1 99.805 (99.962)	Training Prec@5 99.805 (99.986)	
2022-05-11 20:17:17,645: ============================================================
2022-05-11 20:18:04,370: time cost, forward:0.1715558131726162, backward:0.10511441807760993, data cost:0.1905794826455982 
2022-05-11 20:18:04,370: ============================================================
2022-05-11 20:18:04,370: Epoch 30/38 Batch 7100/7662 eta: 8:01:43.987874	Training Loss 0.0723 (0.0740)	Training Prec@1 99.805 (99.962)	Training Prec@5 99.805 (99.986)	
2022-05-11 20:18:04,370: ============================================================
2022-05-11 20:18:51,057: time cost, forward:0.17156200585124856, backward:0.10511372993184157, data cost:0.1905646533134133 
2022-05-11 20:18:51,057: ============================================================
2022-05-11 20:18:51,057: Epoch 30/38 Batch 7200/7662 eta: 8:00:33.351319	Training Loss 0.0706 (0.0740)	Training Prec@1 99.805 (99.962)	Training Prec@5 100.000 (99.986)	
2022-05-11 20:18:51,057: ============================================================
2022-05-11 20:19:37,815: time cost, forward:0.17156914884643304, backward:0.10511215273068855, data cost:0.1905594454479309 
2022-05-11 20:19:37,815: ============================================================
2022-05-11 20:19:37,816: Epoch 30/38 Batch 7300/7662 eta: 8:00:30.786972	Training Loss 0.0726 (0.0740)	Training Prec@1 100.000 (99.962)	Training Prec@5 100.000 (99.986)	
2022-05-11 20:19:37,816: ============================================================
2022-05-11 20:20:24,608: time cost, forward:0.17157848707194714, backward:0.10511109148719727, data cost:0.19055568906065096 
2022-05-11 20:20:24,608: ============================================================
2022-05-11 20:20:24,608: Epoch 30/38 Batch 7400/7662 eta: 8:00:05.221110	Training Loss 0.0679 (0.0740)	Training Prec@1 100.000 (99.962)	Training Prec@5 100.000 (99.986)	
2022-05-11 20:20:24,609: ============================================================
2022-05-11 20:21:11,431: time cost, forward:0.17158910369440658, backward:0.1051124082054833, data cost:0.19055323963849477 
2022-05-11 20:21:11,431: ============================================================
2022-05-11 20:21:11,432: Epoch 30/38 Batch 7500/7662 eta: 7:59:37.079565	Training Loss 0.0715 (0.0740)	Training Prec@1 100.000 (99.962)	Training Prec@5 100.000 (99.986)	
2022-05-11 20:21:11,432: ============================================================
2022-05-11 20:21:58,227: time cost, forward:0.17160299213673977, backward:0.10511178790871949, data cost:0.19054573362540972 
2022-05-11 20:21:58,227: ============================================================
2022-05-11 20:21:58,227: Epoch 30/38 Batch 7600/7662 eta: 7:58:33.175676	Training Loss 0.0741 (0.0740)	Training Prec@1 100.000 (99.962)	Training Prec@5 100.000 (99.986)	
2022-05-11 20:21:58,227: ============================================================
2022-05-11 20:22:28,893: Epoch: 30/38 eta: 7:58:03.694588	Training Loss 0.0778 (0.0740)	Training Prec@1 99.805 (99.962)	Training Prec@5 100.000 (99.986)
2022-05-11 20:22:28,893: ============================================================
2022-05-11 20:22:28,972: Save Checkpoint...
2022-05-11 20:22:28,981: ============================================================
2022-05-11 20:22:31,859: Save done!
2022-05-11 20:22:31,860: ============================================================
2022-05-11 20:23:21,041: time cost, forward:0.18941581128823637, backward:0.10604315333896214, data cost:0.19910553248241694 
2022-05-11 20:23:21,041: ============================================================
2022-05-11 20:23:21,042: Epoch 31/38 Batch 100/7662 eta: 8:21:35.515358	Training Loss 0.0762 (0.0719)	Training Prec@1 99.805 (99.959)	Training Prec@5 100.000 (99.984)	
2022-05-11 20:23:21,042: ============================================================
2022-05-11 20:24:08,112: time cost, forward:0.1819678586931085, backward:0.10610621179168547, data cost:0.19437514956872068 
2022-05-11 20:24:08,113: ============================================================
2022-05-11 20:24:08,113: Epoch 31/38 Batch 200/7662 eta: 7:59:19.218603	Training Loss 0.0708 (0.0713)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.986)	
2022-05-11 20:24:08,113: ============================================================
2022-05-11 20:24:54,976: time cost, forward:0.17884018827840237, backward:0.10611816792185091, data cost:0.19278632199086473 
2022-05-11 20:24:54,977: ============================================================
2022-05-11 20:24:54,977: Epoch 31/38 Batch 300/7662 eta: 7:56:25.563888	Training Loss 0.0648 (0.0711)	Training Prec@1 99.805 (99.965)	Training Prec@5 100.000 (99.985)	
2022-05-11 20:24:54,977: ============================================================
2022-05-11 20:25:41,777: time cost, forward:0.1771346996900133, backward:0.10577784684068876, data cost:0.1923265982988783 
2022-05-11 20:25:41,777: ============================================================
2022-05-11 20:25:41,778: Epoch 31/38 Batch 400/7662 eta: 7:55:00.362501	Training Loss 0.0736 (0.0711)	Training Prec@1 99.805 (99.966)	Training Prec@5 99.805 (99.985)	
2022-05-11 20:25:41,778: ============================================================
2022-05-11 20:26:28,324: time cost, forward:0.17580434936798647, backward:0.105596272883291, data cost:0.1918281223587617 
2022-05-11 20:26:28,325: ============================================================
2022-05-11 20:26:28,325: Epoch 31/38 Batch 500/7662 eta: 7:51:39.360882	Training Loss 0.0704 (0.0711)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.986)	
2022-05-11 20:26:28,325: ============================================================
2022-05-11 20:27:14,902: time cost, forward:0.17490379957603494, backward:0.1054810426868063, data cost:0.19155562540923612 
2022-05-11 20:27:14,902: ============================================================
2022-05-11 20:27:14,902: Epoch 31/38 Batch 600/7662 eta: 7:51:11.025416	Training Loss 0.0704 (0.0710)	Training Prec@1 100.000 (99.966)	Training Prec@5 100.000 (99.985)	
2022-05-11 20:27:14,902: ============================================================
2022-05-11 20:28:01,446: time cost, forward:0.17429661170948557, backward:0.10537427041322547, data cost:0.1913047501969235 
2022-05-11 20:28:01,446: ============================================================
2022-05-11 20:28:01,446: Epoch 31/38 Batch 700/7662 eta: 7:50:04.079086	Training Loss 0.0739 (0.0710)	Training Prec@1 100.000 (99.966)	Training Prec@5 100.000 (99.985)	
2022-05-11 20:28:01,446: ============================================================
2022-05-11 20:28:47,997: time cost, forward:0.17384654768417415, backward:0.10528330958083515, data cost:0.191129993288329 
2022-05-11 20:28:47,998: ============================================================
2022-05-11 20:28:47,998: Epoch 31/38 Batch 800/7662 eta: 7:49:22.417789	Training Loss 0.0753 (0.0711)	Training Prec@1 99.805 (99.965)	Training Prec@5 100.000 (99.984)	
2022-05-11 20:28:47,998: ============================================================
2022-05-11 20:29:34,581: time cost, forward:0.17352149643012227, backward:0.10523970559388565, data cost:0.1909779651013842 
2022-05-11 20:29:34,581: ============================================================
2022-05-11 20:29:34,582: Epoch 31/38 Batch 900/7662 eta: 7:48:55.266260	Training Loss 0.0700 (0.0711)	Training Prec@1 99.805 (99.965)	Training Prec@5 100.000 (99.985)	
2022-05-11 20:29:34,582: ============================================================
2022-05-11 20:30:21,189: time cost, forward:0.1732693202980049, backward:0.10520237081640356, data cost:0.19087552904963373 
2022-05-11 20:30:21,189: ============================================================
2022-05-11 20:30:21,189: Epoch 31/38 Batch 1000/7662 eta: 7:48:23.096832	Training Loss 0.0699 (0.0711)	Training Prec@1 100.000 (99.965)	Training Prec@5 100.000 (99.986)	
2022-05-11 20:30:21,189: ============================================================
2022-05-11 20:31:07,782: time cost, forward:0.17306454079708694, backward:0.1051823435532602, data cost:0.19076500988961134 
2022-05-11 20:31:07,782: ============================================================
2022-05-11 20:31:07,783: Epoch 31/38 Batch 1100/7662 eta: 7:47:27.703131	Training Loss 0.0673 (0.0711)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.987)	
2022-05-11 20:31:07,783: ============================================================
2022-05-11 20:31:54,382: time cost, forward:0.1728857645300451, backward:0.10516382536359187, data cost:0.19069041660967423 
2022-05-11 20:31:54,382: ============================================================
2022-05-11 20:31:54,382: Epoch 31/38 Batch 1200/7662 eta: 7:46:45.054219	Training Loss 0.0773 (0.0711)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.987)	
2022-05-11 20:31:54,382: ============================================================
2022-05-11 20:32:40,993: time cost, forward:0.17274668457142842, backward:0.10514589453587815, data cost:0.19062594398339958 
2022-05-11 20:32:40,993: ============================================================
2022-05-11 20:32:40,994: Epoch 31/38 Batch 1300/7662 eta: 7:46:05.393815	Training Loss 0.0670 (0.0711)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.987)	
2022-05-11 20:32:40,994: ============================================================
2022-05-11 20:33:27,587: time cost, forward:0.1726366681145974, backward:0.10513013494790155, data cost:0.19054944810056107 
2022-05-11 20:33:27,587: ============================================================
2022-05-11 20:33:27,588: Epoch 31/38 Batch 1400/7662 eta: 7:45:08.327984	Training Loss 0.0752 (0.0711)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.986)	
2022-05-11 20:33:27,588: ============================================================
2022-05-11 20:34:14,247: time cost, forward:0.17256118234910514, backward:0.10511042023595768, data cost:0.19051350984198 
2022-05-11 20:34:14,247: ============================================================
2022-05-11 20:34:14,247: Epoch 31/38 Batch 1500/7662 eta: 7:45:01.129558	Training Loss 0.0675 (0.0712)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.986)	
2022-05-11 20:34:14,247: ============================================================
2022-05-11 20:35:00,891: time cost, forward:0.17249240496517942, backward:0.1050831005676155, data cost:0.19048489459683704 
2022-05-11 20:35:00,891: ============================================================
2022-05-11 20:35:00,891: Epoch 31/38 Batch 1600/7662 eta: 7:44:04.913716	Training Loss 0.0707 (0.0712)	Training Prec@1 99.805 (99.967)	Training Prec@5 100.000 (99.987)	
2022-05-11 20:35:00,891: ============================================================
2022-05-11 20:35:47,542: time cost, forward:0.17244401702184828, backward:0.10506539922942128, data cost:0.19044504943070797 
2022-05-11 20:35:47,542: ============================================================
2022-05-11 20:35:47,542: Epoch 31/38 Batch 1700/7662 eta: 7:43:22.690974	Training Loss 0.0702 (0.0712)	Training Prec@1 100.000 (99.966)	Training Prec@5 100.000 (99.986)	
2022-05-11 20:35:47,542: ============================================================
2022-05-11 20:36:34,238: time cost, forward:0.1724050516814507, backward:0.10505379631229081, data cost:0.19042687657278334 
2022-05-11 20:36:34,238: ============================================================
2022-05-11 20:36:34,239: Epoch 31/38 Batch 1800/7662 eta: 7:43:02.895643	Training Loss 0.0754 (0.0712)	Training Prec@1 99.609 (99.966)	Training Prec@5 99.805 (99.986)	
2022-05-11 20:36:34,239: ============================================================
2022-05-11 20:37:20,965: time cost, forward:0.17237486645948139, backward:0.10503996655211567, data cost:0.19042413959131546 
2022-05-11 20:37:20,965: ============================================================
2022-05-11 20:37:20,965: Epoch 31/38 Batch 1900/7662 eta: 7:42:34.340883	Training Loss 0.0718 (0.0712)	Training Prec@1 100.000 (99.966)	Training Prec@5 100.000 (99.986)	
2022-05-11 20:37:20,965: ============================================================
2022-05-11 20:38:07,661: time cost, forward:0.1723385650316079, backward:0.10502331062458109, data cost:0.19042050546261596 
2022-05-11 20:38:07,661: ============================================================
2022-05-11 20:38:07,662: Epoch 31/38 Batch 2000/7662 eta: 7:41:29.490750	Training Loss 0.0698 (0.0712)	Training Prec@1 100.000 (99.966)	Training Prec@5 100.000 (99.987)	
2022-05-11 20:38:07,662: ============================================================
2022-05-11 20:38:54,404: time cost, forward:0.17231433422239467, backward:0.10500870664213997, data cost:0.19042952881931635 
2022-05-11 20:38:54,404: ============================================================
2022-05-11 20:38:54,404: Epoch 31/38 Batch 2100/7662 eta: 7:41:10.303559	Training Loss 0.0783 (0.0712)	Training Prec@1 100.000 (99.966)	Training Prec@5 100.000 (99.987)	
2022-05-11 20:38:54,404: ============================================================
2022-05-11 20:39:41,213: time cost, forward:0.172297919647647, backward:0.10500631965578226, data cost:0.19045166277571016 
2022-05-11 20:39:41,213: ============================================================
2022-05-11 20:39:41,213: Epoch 31/38 Batch 2200/7662 eta: 7:41:02.794628	Training Loss 0.0772 (0.0713)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.987)	
2022-05-11 20:39:41,214: ============================================================
2022-05-11 20:40:27,997: time cost, forward:0.17227145742986347, backward:0.10500466258383773, data cost:0.19047120157766986 
2022-05-11 20:40:27,997: ============================================================
2022-05-11 20:40:27,997: Epoch 31/38 Batch 2300/7662 eta: 7:40:00.950225	Training Loss 0.0713 (0.0713)	Training Prec@1 99.805 (99.967)	Training Prec@5 100.000 (99.986)	
2022-05-11 20:40:27,997: ============================================================
2022-05-11 20:41:14,789: time cost, forward:0.172250046437857, backward:0.10499828653864286, data cost:0.19049113390096878 
2022-05-11 20:41:14,790: ============================================================
2022-05-11 20:41:14,790: Epoch 31/38 Batch 2400/7662 eta: 7:39:19.423531	Training Loss 0.0693 (0.0713)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.987)	
2022-05-11 20:41:14,790: ============================================================
2022-05-11 20:42:01,647: time cost, forward:0.17224781949217674, backward:0.1049964350669467, data cost:0.1905119410511397 
2022-05-11 20:42:01,647: ============================================================
2022-05-11 20:42:01,647: Epoch 31/38 Batch 2500/7662 eta: 7:39:10.800395	Training Loss 0.0713 (0.0713)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.987)	
2022-05-11 20:42:01,647: ============================================================
2022-05-11 20:42:48,438: time cost, forward:0.17223462924538965, backward:0.1049914566449543, data cost:0.19052641691726738 
2022-05-11 20:42:48,438: ============================================================
2022-05-11 20:42:48,438: Epoch 31/38 Batch 2600/7662 eta: 7:37:44.882277	Training Loss 0.0730 (0.0713)	Training Prec@1 100.000 (99.966)	Training Prec@5 100.000 (99.987)	
2022-05-11 20:42:48,438: ============================================================
2022-05-11 20:43:35,222: time cost, forward:0.1722212738794678, backward:0.1049857017683868, data cost:0.19052949928716184 
2022-05-11 20:43:35,223: ============================================================
2022-05-11 20:43:35,223: Epoch 31/38 Batch 2700/7662 eta: 7:36:54.458831	Training Loss 0.0755 (0.0713)	Training Prec@1 99.609 (99.966)	Training Prec@5 100.000 (99.987)	
2022-05-11 20:43:35,223: ============================================================
2022-05-11 20:44:21,992: time cost, forward:0.17221252702738227, backward:0.10498081824318688, data cost:0.1905328086036663 
2022-05-11 20:44:21,992: ============================================================
2022-05-11 20:44:21,992: Epoch 31/38 Batch 2800/7662 eta: 7:35:58.694454	Training Loss 0.0723 (0.0713)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.988)	
2022-05-11 20:44:21,992: ============================================================
2022-05-11 20:45:08,759: time cost, forward:0.17219875137655435, backward:0.10497475821793428, data cost:0.19054086103896595 
2022-05-11 20:45:08,759: ============================================================
2022-05-11 20:45:08,760: Epoch 31/38 Batch 2900/7662 eta: 7:35:10.695105	Training Loss 0.0764 (0.0713)	Training Prec@1 99.805 (99.966)	Training Prec@5 99.805 (99.988)	
2022-05-11 20:45:08,760: ============================================================
2022-05-11 20:45:55,534: time cost, forward:0.17218688147272337, backward:0.10496964896667317, data cost:0.19055065022742362 
2022-05-11 20:45:55,535: ============================================================
2022-05-11 20:45:55,535: Epoch 31/38 Batch 3000/7662 eta: 7:34:28.543006	Training Loss 0.0745 (0.0714)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.987)	
2022-05-11 20:45:55,535: ============================================================
2022-05-11 20:46:42,334: time cost, forward:0.17218274483953072, backward:0.10496830763298298, data cost:0.19055680960907248 
2022-05-11 20:46:42,334: ============================================================
2022-05-11 20:46:42,334: Epoch 31/38 Batch 3100/7662 eta: 7:33:55.880727	Training Loss 0.0676 (0.0714)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.988)	
2022-05-11 20:46:42,334: ============================================================
2022-05-11 20:47:29,089: time cost, forward:0.1721729294662738, backward:0.10496268327551433, data cost:0.19055195263155775 
2022-05-11 20:47:29,090: ============================================================
2022-05-11 20:47:29,090: Epoch 31/38 Batch 3200/7662 eta: 7:32:43.519472	Training Loss 0.0681 (0.0714)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.988)	
2022-05-11 20:47:29,090: ============================================================
2022-05-11 20:48:15,851: time cost, forward:0.1721711753534165, backward:0.10496044903316076, data cost:0.19054566784026442 
2022-05-11 20:48:15,851: ============================================================
2022-05-11 20:48:15,851: Epoch 31/38 Batch 3300/7662 eta: 7:32:00.381026	Training Loss 0.0679 (0.0714)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.988)	
2022-05-11 20:48:15,852: ============================================================
2022-05-11 20:49:02,698: time cost, forward:0.17216950986412702, backward:0.10495913382942938, data cost:0.1905633949398749 
2022-05-11 20:49:02,698: ============================================================
2022-05-11 20:49:02,698: Epoch 31/38 Batch 3400/7662 eta: 7:32:02.845881	Training Loss 0.0732 (0.0714)	Training Prec@1 99.805 (99.967)	Training Prec@5 99.805 (99.988)	
2022-05-11 20:49:02,698: ============================================================
2022-05-11 20:49:49,474: time cost, forward:0.17215739273622943, backward:0.10495825500684522, data cost:0.19056833011826707 
2022-05-11 20:49:49,474: ============================================================
2022-05-11 20:49:49,475: Epoch 31/38 Batch 3500/7662 eta: 7:30:35.377732	Training Loss 0.0691 (0.0714)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.988)	
2022-05-11 20:49:49,475: ============================================================
2022-05-11 20:50:36,244: time cost, forward:0.17214650483752794, backward:0.10495874099381668, data cost:0.19056845645369275 
2022-05-11 20:50:36,244: ============================================================
2022-05-11 20:50:36,244: Epoch 31/38 Batch 3600/7662 eta: 7:29:44.640106	Training Loss 0.0725 (0.0714)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.988)	
2022-05-11 20:50:36,244: ============================================================
2022-05-11 20:51:23,010: time cost, forward:0.1721350806376263, backward:0.10495932001009217, data cost:0.190569831410367 
2022-05-11 20:51:23,011: ============================================================
2022-05-11 20:51:23,011: Epoch 31/38 Batch 3700/7662 eta: 7:28:56.221571	Training Loss 0.0721 (0.0714)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.988)	
2022-05-11 20:51:23,011: ============================================================
2022-05-11 20:52:09,798: time cost, forward:0.17213249150060547, backward:0.10495886572978157, data cost:0.19057123539917845 
2022-05-11 20:52:09,798: ============================================================
2022-05-11 20:52:09,799: Epoch 31/38 Batch 3800/7662 eta: 7:28:21.482434	Training Loss 0.0763 (0.0714)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.988)	
2022-05-11 20:52:09,799: ============================================================
2022-05-11 20:52:56,571: time cost, forward:0.17212642238946657, backward:0.1049593878758507, data cost:0.19056827057688994 
2022-05-11 20:52:56,571: ============================================================
2022-05-11 20:52:56,571: Epoch 31/38 Batch 3900/7662 eta: 7:27:26.091217	Training Loss 0.0783 (0.0714)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.988)	
2022-05-11 20:52:56,571: ============================================================
2022-05-11 20:53:43,368: time cost, forward:0.17213035702973672, backward:0.10496043723712835, data cost:0.1905640744364062 
2022-05-11 20:53:43,368: ============================================================
2022-05-11 20:53:43,368: Epoch 31/38 Batch 4000/7662 eta: 7:26:53.300274	Training Loss 0.0675 (0.0715)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.988)	
2022-05-11 20:53:43,368: ============================================================
2022-05-11 20:54:30,146: time cost, forward:0.17213098663735837, backward:0.10495943190208672, data cost:0.19056086378523301 
2022-05-11 20:54:30,146: ============================================================
2022-05-11 20:54:30,147: Epoch 31/38 Batch 4100/7662 eta: 7:25:55.805824	Training Loss 0.0696 (0.0715)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.988)	
2022-05-11 20:54:30,147: ============================================================
2022-05-11 20:55:16,991: time cost, forward:0.17213795224267206, backward:0.10496018977073239, data cost:0.19056312996423025 
2022-05-11 20:55:16,991: ============================================================
2022-05-11 20:55:16,991: Epoch 31/38 Batch 4200/7662 eta: 7:25:46.940876	Training Loss 0.0745 (0.0715)	Training Prec@1 100.000 (99.966)	Training Prec@5 100.000 (99.988)	
2022-05-11 20:55:16,991: ============================================================
2022-05-11 20:56:03,789: time cost, forward:0.17213468347546332, backward:0.1049563002935757, data cost:0.19056864521286604 
2022-05-11 20:56:03,789: ============================================================
2022-05-11 20:56:03,789: Epoch 31/38 Batch 4300/7662 eta: 7:24:33.424860	Training Loss 0.0724 (0.0715)	Training Prec@1 100.000 (99.966)	Training Prec@5 100.000 (99.988)	
2022-05-11 20:56:03,789: ============================================================
2022-05-11 20:56:50,695: time cost, forward:0.17212993336092425, backward:0.1049809519825645, data cost:0.19057442053092233 
2022-05-11 20:56:50,695: ============================================================
2022-05-11 20:56:50,695: Epoch 31/38 Batch 4400/7662 eta: 7:24:48.179201	Training Loss 0.0733 (0.0715)	Training Prec@1 99.805 (99.966)	Training Prec@5 100.000 (99.988)	
2022-05-11 20:56:50,695: ============================================================
2022-05-11 20:57:37,601: time cost, forward:0.172127573085801, backward:0.10501407787359458, data cost:0.1905683650258224 
2022-05-11 20:57:37,602: ============================================================
2022-05-11 20:57:37,602: Epoch 31/38 Batch 4500/7662 eta: 7:24:01.490279	Training Loss 0.0662 (0.0715)	Training Prec@1 100.000 (99.966)	Training Prec@5 100.000 (99.988)	
2022-05-11 20:57:37,602: ============================================================
2022-05-11 20:58:24,214: time cost, forward:0.172086992064723, backward:0.10501166358411922, data cost:0.19057081621298197 
2022-05-11 20:58:24,214: ============================================================
2022-05-11 20:58:24,214: Epoch 31/38 Batch 4600/7662 eta: 7:20:27.756896	Training Loss 0.0730 (0.0716)	Training Prec@1 100.000 (99.966)	Training Prec@5 100.000 (99.988)	
2022-05-11 20:58:24,214: ============================================================
2022-05-11 20:59:10,924: time cost, forward:0.17205721638410187, backward:0.1050062614898779, data cost:0.19058573796511152 
2022-05-11 20:59:10,925: ============================================================
2022-05-11 20:59:10,925: Epoch 31/38 Batch 4700/7662 eta: 7:20:36.967977	Training Loss 0.0753 (0.0716)	Training Prec@1 100.000 (99.966)	Training Prec@5 100.000 (99.988)	
2022-05-11 20:59:10,925: ============================================================
2022-05-11 20:59:57,632: time cost, forward:0.1720262177414287, backward:0.10500213011375788, data cost:0.19059482821078816 
2022-05-11 20:59:57,632: ============================================================
2022-05-11 20:59:57,633: Epoch 31/38 Batch 4800/7662 eta: 7:19:48.283462	Training Loss 0.0694 (0.0716)	Training Prec@1 100.000 (99.966)	Training Prec@5 100.000 (99.988)	
2022-05-11 20:59:57,633: ============================================================
2022-05-11 21:00:44,328: time cost, forward:0.1720027374135983, backward:0.10499713989782634, data cost:0.19060376201948115 
2022-05-11 21:00:44,329: ============================================================
2022-05-11 21:00:44,329: Epoch 31/38 Batch 4900/7662 eta: 7:18:55.459294	Training Loss 0.0713 (0.0716)	Training Prec@1 100.000 (99.966)	Training Prec@5 100.000 (99.988)	
2022-05-11 21:00:44,329: ============================================================
2022-05-11 21:01:31,056: time cost, forward:0.1719853488367351, backward:0.10499330157398057, data cost:0.19061308432684157 
2022-05-11 21:01:31,056: ============================================================
2022-05-11 21:01:31,056: Epoch 31/38 Batch 5000/7662 eta: 7:18:26.021734	Training Loss 0.0663 (0.0716)	Training Prec@1 100.000 (99.966)	Training Prec@5 100.000 (99.988)	
2022-05-11 21:01:31,056: ============================================================
2022-05-11 21:02:17,696: time cost, forward:0.1719614776309085, backward:0.10498878651447076, data cost:0.19061086495312132 
2022-05-11 21:02:17,696: ============================================================
2022-05-11 21:02:17,696: Epoch 31/38 Batch 5100/7662 eta: 7:16:50.177557	Training Loss 0.0731 (0.0716)	Training Prec@1 99.805 (99.966)	Training Prec@5 99.805 (99.988)	
2022-05-11 21:02:17,696: ============================================================
2022-05-11 21:03:04,434: time cost, forward:0.17194836844524802, backward:0.10498517516668679, data cost:0.19061452605490914 
2022-05-11 21:03:04,435: ============================================================
2022-05-11 21:03:04,435: Epoch 31/38 Batch 5200/7662 eta: 7:16:59.002873	Training Loss 0.0719 (0.0716)	Training Prec@1 100.000 (99.965)	Training Prec@5 100.000 (99.988)	
2022-05-11 21:03:04,435: ============================================================
2022-05-11 21:03:51,231: time cost, forward:0.17195172713913767, backward:0.10498184221018979, data cost:0.19061374137887058 
2022-05-11 21:03:51,232: ============================================================
2022-05-11 21:03:51,232: Epoch 31/38 Batch 5300/7662 eta: 7:16:45.036075	Training Loss 0.0729 (0.0716)	Training Prec@1 100.000 (99.965)	Training Prec@5 100.000 (99.988)	
2022-05-11 21:03:51,232: ============================================================
2022-05-11 21:04:37,888: time cost, forward:0.17193471040741606, backward:0.10497943443995005, data cost:0.19060905625763194 
2022-05-11 21:04:37,888: ============================================================
2022-05-11 21:04:37,888: Epoch 31/38 Batch 5400/7662 eta: 7:14:39.412345	Training Loss 0.0713 (0.0716)	Training Prec@1 100.000 (99.965)	Training Prec@5 100.000 (99.988)	
2022-05-11 21:04:37,888: ============================================================
2022-05-11 21:05:24,516: time cost, forward:0.17191487178951637, backward:0.1049775263898523, data cost:0.1906035804471052 
2022-05-11 21:05:24,516: ============================================================
2022-05-11 21:05:24,517: Epoch 31/38 Batch 5500/7662 eta: 7:13:37.298682	Training Loss 0.0699 (0.0716)	Training Prec@1 100.000 (99.965)	Training Prec@5 100.000 (99.988)	
2022-05-11 21:05:24,517: ============================================================
2022-05-11 21:06:11,225: time cost, forward:0.1719078653134242, backward:0.10497404090164601, data cost:0.19060204177695655 
2022-05-11 21:06:11,226: ============================================================
2022-05-11 21:06:11,226: Epoch 31/38 Batch 5600/7662 eta: 7:13:35.657730	Training Loss 0.0701 (0.0716)	Training Prec@1 100.000 (99.965)	Training Prec@5 100.000 (99.988)	
2022-05-11 21:06:11,226: ============================================================
2022-05-11 21:06:57,910: time cost, forward:0.17190117977401378, backward:0.10497123380568305, data cost:0.1905958537031295 
2022-05-11 21:06:57,910: ============================================================
2022-05-11 21:06:57,910: Epoch 31/38 Batch 5700/7662 eta: 7:12:35.172970	Training Loss 0.0746 (0.0716)	Training Prec@1 100.000 (99.965)	Training Prec@5 100.000 (99.988)	
2022-05-11 21:06:57,910: ============================================================
2022-05-11 21:07:44,615: time cost, forward:0.1718962685900282, backward:0.1049684195872894, data cost:0.1905904171856997 
2022-05-11 21:07:44,615: ============================================================
2022-05-11 21:07:44,615: Epoch 31/38 Batch 5800/7662 eta: 7:11:59.796403	Training Loss 0.0718 (0.0716)	Training Prec@1 100.000 (99.966)	Training Prec@5 100.000 (99.988)	
2022-05-11 21:07:44,615: ============================================================
2022-05-11 21:08:31,320: time cost, forward:0.1718941709311822, backward:0.1049667890040748, data cost:0.1905838123598954 
2022-05-11 21:08:31,321: ============================================================
2022-05-11 21:08:31,321: Epoch 31/38 Batch 5900/7662 eta: 7:11:13.542453	Training Loss 0.0747 (0.0717)	Training Prec@1 100.000 (99.965)	Training Prec@5 100.000 (99.988)	
2022-05-11 21:08:31,321: ============================================================
2022-05-11 21:09:18,027: time cost, forward:0.1718913411116437, backward:0.1049644480071121, data cost:0.1905786982375913 
2022-05-11 21:09:18,027: ============================================================
2022-05-11 21:09:18,027: Epoch 31/38 Batch 6000/7662 eta: 7:10:27.030713	Training Loss 0.0717 (0.0717)	Training Prec@1 100.000 (99.965)	Training Prec@5 100.000 (99.987)	
2022-05-11 21:09:18,027: ============================================================
2022-05-11 21:10:04,764: time cost, forward:0.17189370704334395, backward:0.10496383507655555, data cost:0.19057136071394812 
2022-05-11 21:10:04,764: ============================================================
2022-05-11 21:10:04,764: Epoch 31/38 Batch 6100/7662 eta: 7:09:57.549799	Training Loss 0.0701 (0.0717)	Training Prec@1 100.000 (99.965)	Training Prec@5 100.000 (99.987)	
2022-05-11 21:10:04,765: ============================================================
2022-05-11 21:10:51,487: time cost, forward:0.17189452317015244, backward:0.1049612688045191, data cost:0.1905658343930959 
2022-05-11 21:10:51,488: ============================================================
2022-05-11 21:10:51,488: Epoch 31/38 Batch 6200/7662 eta: 7:09:03.249298	Training Loss 0.0745 (0.0717)	Training Prec@1 100.000 (99.965)	Training Prec@5 100.000 (99.987)	
2022-05-11 21:10:51,488: ============================================================
2022-05-11 21:11:38,240: time cost, forward:0.1718992350839172, backward:0.10496193315324603, data cost:0.19055762785278552 
2022-05-11 21:11:38,240: ============================================================
2022-05-11 21:11:38,241: Epoch 31/38 Batch 6300/7662 eta: 7:08:32.695366	Training Loss 0.0695 (0.0717)	Training Prec@1 99.805 (99.965)	Training Prec@5 100.000 (99.987)	
2022-05-11 21:11:38,241: ============================================================
2022-05-11 21:12:25,023: time cost, forward:0.17190306241446351, backward:0.10496261082956392, data cost:0.19055396419965695 
2022-05-11 21:12:25,024: ============================================================
2022-05-11 21:12:25,024: Epoch 31/38 Batch 6400/7662 eta: 7:08:02.541120	Training Loss 0.0756 (0.0717)	Training Prec@1 99.805 (99.965)	Training Prec@5 100.000 (99.987)	
2022-05-11 21:12:25,024: ============================================================
2022-05-11 21:13:11,751: time cost, forward:0.17190692585823186, backward:0.10496084311133551, data cost:0.19054541736038708 
2022-05-11 21:13:11,751: ============================================================
2022-05-11 21:13:11,751: Epoch 31/38 Batch 6500/7662 eta: 7:06:45.173436	Training Loss 0.0724 (0.0717)	Training Prec@1 100.000 (99.965)	Training Prec@5 100.000 (99.987)	
2022-05-11 21:13:11,751: ============================================================
2022-05-11 21:13:58,484: time cost, forward:0.17191041200553708, backward:0.10495906559729833, data cost:0.19053850663143643 
2022-05-11 21:13:58,484: ============================================================
2022-05-11 21:13:58,484: Epoch 31/38 Batch 6600/7662 eta: 7:06:01.631189	Training Loss 0.0696 (0.0717)	Training Prec@1 99.805 (99.965)	Training Prec@5 99.805 (99.987)	
2022-05-11 21:13:58,484: ============================================================
2022-05-11 21:14:45,267: time cost, forward:0.17191764485891195, backward:0.10495759106550773, data cost:0.19053577152468015 
2022-05-11 21:14:45,267: ============================================================
2022-05-11 21:14:45,267: Epoch 31/38 Batch 6700/7662 eta: 7:05:42.155770	Training Loss 0.0739 (0.0717)	Training Prec@1 100.000 (99.965)	Training Prec@5 100.000 (99.987)	
2022-05-11 21:14:45,267: ============================================================
2022-05-11 21:15:32,071: time cost, forward:0.17192902237479346, backward:0.1049567845870965, data cost:0.19053089841356485 
2022-05-11 21:15:32,072: ============================================================
2022-05-11 21:15:32,072: Epoch 31/38 Batch 6800/7662 eta: 7:05:07.039326	Training Loss 0.0771 (0.0717)	Training Prec@1 100.000 (99.965)	Training Prec@5 100.000 (99.987)	
2022-05-11 21:15:32,072: ============================================================
2022-05-11 21:16:18,935: time cost, forward:0.17193420998755357, backward:0.1049676405932527, data cost:0.19052915691309932 
2022-05-11 21:16:18,935: ============================================================
2022-05-11 21:16:18,936: Epoch 31/38 Batch 6900/7662 eta: 7:04:52.507667	Training Loss 0.0751 (0.0717)	Training Prec@1 100.000 (99.965)	Training Prec@5 100.000 (99.987)	
2022-05-11 21:16:18,936: ============================================================
2022-05-11 21:17:05,806: time cost, forward:0.17193852160416054, backward:0.10498633931783084, data cost:0.19052096965875365 
2022-05-11 21:17:05,806: ============================================================
2022-05-11 21:17:05,806: Epoch 31/38 Batch 7000/7662 eta: 7:04:09.473239	Training Loss 0.0746 (0.0718)	Training Prec@1 100.000 (99.965)	Training Prec@5 100.000 (99.987)	
2022-05-11 21:17:05,807: ============================================================
2022-05-11 21:17:52,736: time cost, forward:0.17194409336165856, backward:0.10500478086244525, data cost:0.19051919206462622 
2022-05-11 21:17:52,736: ============================================================
2022-05-11 21:17:52,736: Epoch 31/38 Batch 7100/7662 eta: 7:03:54.609495	Training Loss 0.0718 (0.0718)	Training Prec@1 100.000 (99.965)	Training Prec@5 100.000 (99.987)	
2022-05-11 21:17:52,737: ============================================================
2022-05-11 21:18:39,668: time cost, forward:0.1719477800946051, backward:0.10502643428886743, data cost:0.19051607656286795 
2022-05-11 21:18:39,668: ============================================================
2022-05-11 21:18:39,668: Epoch 31/38 Batch 7200/7662 eta: 7:03:08.709844	Training Loss 0.0680 (0.0718)	Training Prec@1 100.000 (99.965)	Training Prec@5 100.000 (99.987)	
2022-05-11 21:18:39,668: ============================================================
2022-05-11 21:19:26,636: time cost, forward:0.17195119144394228, backward:0.10504622484889974, data cost:0.19051766291042274 
2022-05-11 21:19:26,636: ============================================================
2022-05-11 21:19:26,636: Epoch 31/38 Batch 7300/7662 eta: 7:02:41.382246	Training Loss 0.0723 (0.0718)	Training Prec@1 100.000 (99.965)	Training Prec@5 100.000 (99.987)	
2022-05-11 21:19:26,636: ============================================================
2022-05-11 21:20:13,417: time cost, forward:0.1719565826552126, backward:0.10504907188358814, data cost:0.1905097776465294 
2022-05-11 21:20:13,418: ============================================================
2022-05-11 21:20:13,418: Epoch 31/38 Batch 7400/7662 eta: 7:00:13.995244	Training Loss 0.0710 (0.0718)	Training Prec@1 99.805 (99.965)	Training Prec@5 100.000 (99.987)	
2022-05-11 21:20:13,418: ============================================================
2022-05-11 21:21:00,054: time cost, forward:0.1719506499067531, backward:0.10504801636744315, data cost:0.19049788026877093 
2022-05-11 21:21:00,054: ============================================================
2022-05-11 21:21:00,054: Epoch 31/38 Batch 7500/7662 eta: 6:58:08.799787	Training Loss 0.0742 (0.0718)	Training Prec@1 100.000 (99.965)	Training Prec@5 100.000 (99.987)	
2022-05-11 21:21:00,054: ============================================================
2022-05-11 21:21:46,628: time cost, forward:0.17193261490540843, backward:0.10504557082709207, data cost:0.1904919408845155 
2022-05-11 21:21:46,628: ============================================================
2022-05-11 21:21:46,629: Epoch 31/38 Batch 7600/7662 eta: 6:56:49.065526	Training Loss 0.0717 (0.0718)	Training Prec@1 100.000 (99.965)	Training Prec@5 100.000 (99.987)	
2022-05-11 21:21:46,629: ============================================================
2022-05-11 21:22:17,448: Epoch: 31/38 eta: 6:56:19.723642	Training Loss 0.0766 (0.0718)	Training Prec@1 99.805 (99.965)	Training Prec@5 100.000 (99.987)
2022-05-11 21:22:17,448: ============================================================
2022-05-11 21:22:17,505: Save Checkpoint...
2022-05-11 21:22:17,507: ============================================================
2022-05-11 21:22:20,058: Save done!
2022-05-11 21:22:20,058: ============================================================
2022-05-11 21:23:09,265: time cost, forward:0.1858128249043166, backward:0.10488750477029819, data cost:0.20416251095858487 
2022-05-11 21:23:09,266: ============================================================
2022-05-11 21:23:09,266: Epoch 32/38 Batch 100/7662 eta: 7:19:02.512304	Training Loss 0.0730 (0.0695)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.990)	
2022-05-11 21:23:09,266: ============================================================
2022-05-11 21:23:56,184: time cost, forward:0.17942481663957913, backward:0.10550737380981445, data cost:0.19690746398427378 
2022-05-11 21:23:56,184: ============================================================
2022-05-11 21:23:56,184: Epoch 32/38 Batch 200/7662 eta: 6:57:50.551755	Training Loss 0.0645 (0.0699)	Training Prec@1 100.000 (99.971)	Training Prec@5 100.000 (99.992)	
2022-05-11 21:23:56,184: ============================================================
2022-05-11 21:24:43,082: time cost, forward:0.1771029469161528, backward:0.1057660970400807, data cost:0.1945812151982234 
2022-05-11 21:24:43,082: ============================================================
2022-05-11 21:24:43,082: Epoch 32/38 Batch 300/7662 eta: 6:56:53.174317	Training Loss 0.0637 (0.0697)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.992)	
2022-05-11 21:24:43,082: ============================================================
2022-05-11 21:25:29,944: time cost, forward:0.1758775394363212, backward:0.10591073143751101, data cost:0.19337675625220277 
2022-05-11 21:25:29,944: ============================================================
2022-05-11 21:25:29,944: Epoch 32/38 Batch 400/7662 eta: 6:55:46.853695	Training Loss 0.0705 (0.0699)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.992)	
2022-05-11 21:25:29,944: ============================================================
2022-05-11 21:26:16,797: time cost, forward:0.1751358107717816, backward:0.1060038945956794, data cost:0.19264338059511357 
2022-05-11 21:26:16,797: ============================================================
2022-05-11 21:26:16,797: Epoch 32/38 Batch 500/7662 eta: 6:54:55.390284	Training Loss 0.0743 (0.0701)	Training Prec@1 99.805 (99.970)	Training Prec@5 100.000 (99.991)	
2022-05-11 21:26:16,797: ============================================================
2022-05-11 21:27:03,670: time cost, forward:0.1746789211024824, backward:0.10606004001700221, data cost:0.192156801239676 
2022-05-11 21:27:03,670: ============================================================
2022-05-11 21:27:03,670: Epoch 32/38 Batch 600/7662 eta: 6:54:19.002942	Training Loss 0.0718 (0.0700)	Training Prec@1 99.805 (99.972)	Training Prec@5 100.000 (99.992)	
2022-05-11 21:27:03,670: ============================================================
2022-05-11 21:27:50,402: time cost, forward:0.17429194532238873, backward:0.10593517723683805, data cost:0.19183358921001908 
2022-05-11 21:27:50,402: ============================================================
2022-05-11 21:27:50,402: Epoch 32/38 Batch 700/7662 eta: 6:52:17.618209	Training Loss 0.0674 (0.0701)	Training Prec@1 100.000 (99.971)	Training Prec@5 100.000 (99.992)	
2022-05-11 21:27:50,402: ============================================================
2022-05-11 21:28:37,056: time cost, forward:0.1738966731762558, backward:0.10581377062839321, data cost:0.19162567685333748 
2022-05-11 21:28:37,056: ============================================================
2022-05-11 21:28:37,056: Epoch 32/38 Batch 800/7662 eta: 6:50:49.589654	Training Loss 0.0711 (0.0701)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.991)	
2022-05-11 21:28:37,056: ============================================================
2022-05-11 21:29:23,552: time cost, forward:0.17347256890658674, backward:0.10571604310736905, data cost:0.19140984882104384 
2022-05-11 21:29:23,553: ============================================================
2022-05-11 21:29:23,553: Epoch 32/38 Batch 900/7662 eta: 6:48:40.088834	Training Loss 0.0658 (0.0702)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.991)	
2022-05-11 21:29:23,553: ============================================================
2022-05-11 21:30:10,058: time cost, forward:0.1730954527735591, backward:0.10564047080260497, data cost:0.19127111439709668 
2022-05-11 21:30:10,059: ============================================================
2022-05-11 21:30:10,059: Epoch 32/38 Batch 1000/7662 eta: 6:47:58.508417	Training Loss 0.0626 (0.0702)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.991)	
2022-05-11 21:30:10,059: ============================================================
2022-05-11 21:30:56,550: time cost, forward:0.17277591243671003, backward:0.10557677183940911, data cost:0.1911676127439851 
2022-05-11 21:30:56,550: ============================================================
2022-05-11 21:30:56,550: Epoch 32/38 Batch 1100/7662 eta: 6:47:04.291311	Training Loss 0.0699 (0.0702)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.990)	
2022-05-11 21:30:56,550: ============================================================
2022-05-11 21:31:43,110: time cost, forward:0.1725584983427988, backward:0.10551741204727083, data cost:0.19108638373685938 
2022-05-11 21:31:43,110: ============================================================
2022-05-11 21:31:43,110: Epoch 32/38 Batch 1200/7662 eta: 6:46:53.547198	Training Loss 0.0718 (0.0702)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.990)	
2022-05-11 21:31:43,110: ============================================================
2022-05-11 21:32:29,712: time cost, forward:0.17238424428157204, backward:0.10547503698230065, data cost:0.19104083012029519 
2022-05-11 21:32:29,713: ============================================================
2022-05-11 21:32:29,713: Epoch 32/38 Batch 1300/7662 eta: 6:46:29.543506	Training Loss 0.0708 (0.0702)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.990)	
2022-05-11 21:32:29,713: ============================================================
2022-05-11 21:33:16,336: time cost, forward:0.17224075438040679, backward:0.10543025264235545, data cost:0.19101847146902023 
2022-05-11 21:33:16,336: ============================================================
2022-05-11 21:33:16,336: Epoch 32/38 Batch 1400/7662 eta: 6:45:53.730859	Training Loss 0.0729 (0.0702)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.990)	
2022-05-11 21:33:16,336: ============================================================
2022-05-11 21:34:02,980: time cost, forward:0.17211998725748603, backward:0.1054070061091346, data cost:0.19099580995077448 
2022-05-11 21:34:02,980: ============================================================
2022-05-11 21:34:02,981: Epoch 32/38 Batch 1500/7662 eta: 6:45:18.029662	Training Loss 0.0741 (0.0703)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.990)	
2022-05-11 21:34:02,981: ============================================================
2022-05-11 21:34:49,574: time cost, forward:0.17201469792955887, backward:0.10537352660359853, data cost:0.1909485106322078 
2022-05-11 21:34:49,574: ============================================================
2022-05-11 21:34:49,574: Epoch 32/38 Batch 1600/7662 eta: 6:44:05.018609	Training Loss 0.0741 (0.0703)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.990)	
2022-05-11 21:34:49,574: ============================================================
2022-05-11 21:35:36,166: time cost, forward:0.1719078881520254, backward:0.10534043056674394, data cost:0.1909317589984914 
2022-05-11 21:35:36,167: ============================================================
2022-05-11 21:35:36,167: Epoch 32/38 Batch 1700/7662 eta: 6:43:17.810526	Training Loss 0.0694 (0.0703)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.990)	
2022-05-11 21:35:36,167: ============================================================
2022-05-11 21:36:22,735: time cost, forward:0.17180772461183472, backward:0.10531270205808918, data cost:0.19089528598541547 
2022-05-11 21:36:22,736: ============================================================
2022-05-11 21:36:22,736: Epoch 32/38 Batch 1800/7662 eta: 6:42:19.128280	Training Loss 0.0655 (0.0703)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.990)	
2022-05-11 21:36:22,736: ============================================================
2022-05-11 21:37:09,307: time cost, forward:0.17172963447229306, backward:0.10528937887680913, data cost:0.1908569114970307 
2022-05-11 21:37:09,307: ============================================================
2022-05-11 21:37:09,307: Epoch 32/38 Batch 1900/7662 eta: 6:41:33.595094	Training Loss 0.0758 (0.0703)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.990)	
2022-05-11 21:37:09,307: ============================================================
2022-05-11 21:37:55,949: time cost, forward:0.17168330466407367, backward:0.10526644330790426, data cost:0.19084060114583354 
2022-05-11 21:37:55,949: ============================================================
2022-05-11 21:37:55,949: Epoch 32/38 Batch 2000/7662 eta: 6:41:23.695904	Training Loss 0.0705 (0.0703)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.990)	
2022-05-11 21:37:55,949: ============================================================
2022-05-11 21:38:42,625: time cost, forward:0.17163935623150772, backward:0.10524967388064024, data cost:0.1908409916939992 
2022-05-11 21:38:42,626: ============================================================
2022-05-11 21:38:42,626: Epoch 32/38 Batch 2100/7662 eta: 6:40:54.811356	Training Loss 0.0714 (0.0703)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.990)	
2022-05-11 21:38:42,626: ============================================================
2022-05-11 21:39:29,213: time cost, forward:0.17158892340094137, backward:0.10523423068682787, data cost:0.19081196659204364 
2022-05-11 21:39:29,214: ============================================================
2022-05-11 21:39:29,214: Epoch 32/38 Batch 2200/7662 eta: 6:39:22.562847	Training Loss 0.0712 (0.0703)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.990)	
2022-05-11 21:39:29,214: ============================================================
2022-05-11 21:40:15,870: time cost, forward:0.1715521529323384, backward:0.10522202213415119, data cost:0.1908035789587644 
2022-05-11 21:40:15,871: ============================================================
2022-05-11 21:40:15,871: Epoch 32/38 Batch 2300/7662 eta: 6:39:11.319334	Training Loss 0.0679 (0.0703)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.990)	
2022-05-11 21:40:15,871: ============================================================
2022-05-11 21:41:02,546: time cost, forward:0.17151553246218645, backward:0.10521120903838818, data cost:0.1908070579972452 
2022-05-11 21:41:02,547: ============================================================
2022-05-11 21:41:02,547: Epoch 32/38 Batch 2400/7662 eta: 6:38:34.376223	Training Loss 0.0733 (0.0703)	Training Prec@1 99.805 (99.969)	Training Prec@5 100.000 (99.989)	
2022-05-11 21:41:02,547: ============================================================
2022-05-11 21:41:49,218: time cost, forward:0.17148248946108594, backward:0.10519881418296079, data cost:0.19081034589739215 
2022-05-11 21:41:49,219: ============================================================
2022-05-11 21:41:49,219: Epoch 32/38 Batch 2500/7662 eta: 6:37:45.831646	Training Loss 0.0681 (0.0703)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.990)	
2022-05-11 21:41:49,219: ============================================================
2022-05-11 21:42:35,961: time cost, forward:0.1714489157266826, backward:0.10518685484354474, data cost:0.19083505375837537 
2022-05-11 21:42:35,962: ============================================================
2022-05-11 21:42:35,962: Epoch 32/38 Batch 2600/7662 eta: 6:37:35.205500	Training Loss 0.0767 (0.0704)	Training Prec@1 99.805 (99.969)	Training Prec@5 100.000 (99.989)	
2022-05-11 21:42:35,962: ============================================================
2022-05-11 21:43:22,647: time cost, forward:0.17141821358812523, backward:0.10517614786162911, data cost:0.1908430849105705 
2022-05-11 21:43:22,647: ============================================================
2022-05-11 21:43:22,647: Epoch 32/38 Batch 2700/7662 eta: 6:36:19.367336	Training Loss 0.0726 (0.0704)	Training Prec@1 99.805 (99.969)	Training Prec@5 100.000 (99.989)	
2022-05-11 21:43:22,648: ============================================================
2022-05-11 21:44:09,321: time cost, forward:0.1713857064719028, backward:0.105163329752397, data cost:0.19084707197439418 
2022-05-11 21:44:09,321: ============================================================
2022-05-11 21:44:09,321: Epoch 32/38 Batch 2800/7662 eta: 6:35:26.527448	Training Loss 0.0684 (0.0704)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.989)	
2022-05-11 21:44:09,321: ============================================================
2022-05-11 21:44:55,997: time cost, forward:0.1713662303781131, backward:0.1051531168624178, data cost:0.19084633050519215 
2022-05-11 21:44:55,997: ============================================================
2022-05-11 21:44:55,998: Epoch 32/38 Batch 2900/7662 eta: 6:34:41.297882	Training Loss 0.0723 (0.0704)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.989)	
2022-05-11 21:44:55,998: ============================================================
2022-05-11 21:45:42,745: time cost, forward:0.17136705450393153, backward:0.10514417883951531, data cost:0.19084641439750138 
2022-05-11 21:45:42,745: ============================================================
2022-05-11 21:45:42,745: Epoch 32/38 Batch 3000/7662 eta: 6:34:30.600338	Training Loss 0.0698 (0.0704)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.989)	
2022-05-11 21:45:42,745: ============================================================
2022-05-11 21:46:29,472: time cost, forward:0.17137549545888786, backward:0.10513458224256872, data cost:0.190833374545358 
2022-05-11 21:46:29,472: ============================================================
2022-05-11 21:46:29,472: Epoch 32/38 Batch 3100/7662 eta: 6:33:33.636802	Training Loss 0.0664 (0.0704)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.989)	
2022-05-11 21:46:29,472: ============================================================
2022-05-11 21:47:16,150: time cost, forward:0.17135660675921713, backward:0.10512442453163197, data cost:0.19083350783178454 
2022-05-11 21:47:16,150: ============================================================
2022-05-11 21:47:16,150: Epoch 32/38 Batch 3200/7662 eta: 6:32:21.992410	Training Loss 0.0669 (0.0704)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.989)	
2022-05-11 21:47:16,150: ============================================================
2022-05-11 21:48:02,817: time cost, forward:0.17134168025904548, backward:0.10511371951350373, data cost:0.1908322408293984 
2022-05-11 21:48:02,818: ============================================================
2022-05-11 21:48:02,818: Epoch 32/38 Batch 3300/7662 eta: 6:31:30.058893	Training Loss 0.0711 (0.0704)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.989)	
2022-05-11 21:48:02,818: ============================================================
2022-05-11 21:48:49,550: time cost, forward:0.1713445501560392, backward:0.10510353082486831, data cost:0.19083339784313 
2022-05-11 21:48:49,550: ============================================================
2022-05-11 21:48:49,550: Epoch 32/38 Batch 3400/7662 eta: 6:31:16.071892	Training Loss 0.0702 (0.0704)	Training Prec@1 99.805 (99.969)	Training Prec@5 100.000 (99.989)	
2022-05-11 21:48:49,550: ============================================================
2022-05-11 21:49:36,240: time cost, forward:0.17133988765826666, backward:0.10509421430883764, data cost:0.19082600765822444 
2022-05-11 21:49:36,240: ============================================================
2022-05-11 21:49:36,240: Epoch 32/38 Batch 3500/7662 eta: 6:30:07.961603	Training Loss 0.0690 (0.0705)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.989)	
2022-05-11 21:49:36,240: ============================================================
2022-05-11 21:50:22,906: time cost, forward:0.17133291743470086, backward:0.10508437744939814, data cost:0.19081576806566855 
2022-05-11 21:50:22,906: ============================================================
2022-05-11 21:50:22,906: Epoch 32/38 Batch 3600/7662 eta: 6:29:09.537035	Training Loss 0.0697 (0.0705)	Training Prec@1 99.805 (99.969)	Training Prec@5 100.000 (99.989)	
2022-05-11 21:50:22,907: ============================================================
2022-05-11 21:51:09,594: time cost, forward:0.17132967721774597, backward:0.10507493374894909, data cost:0.19081259650389998 
2022-05-11 21:51:09,595: ============================================================
2022-05-11 21:51:09,595: Epoch 32/38 Batch 3700/7662 eta: 6:28:33.896248	Training Loss 0.0683 (0.0705)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.989)	
2022-05-11 21:51:09,595: ============================================================
2022-05-11 21:51:56,332: time cost, forward:0.17132572156248924, backward:0.10506868280841038, data cost:0.1908146686759802 
2022-05-11 21:51:56,332: ============================================================
2022-05-11 21:51:56,332: Epoch 32/38 Batch 3800/7662 eta: 6:28:11.396776	Training Loss 0.0657 (0.0705)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.989)	
2022-05-11 21:51:56,332: ============================================================
2022-05-11 21:52:43,057: time cost, forward:0.1713275107765051, backward:0.10505958366589718, data cost:0.19081411431403794 
2022-05-11 21:52:43,058: ============================================================
2022-05-11 21:52:43,058: Epoch 32/38 Batch 3900/7662 eta: 6:27:19.147084	Training Loss 0.0701 (0.0705)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.989)	
2022-05-11 21:52:43,058: ============================================================
2022-05-11 21:53:29,805: time cost, forward:0.17132840743211544, backward:0.10505131495896206, data cost:0.19081956894882443 
2022-05-11 21:53:29,806: ============================================================
2022-05-11 21:53:29,806: Epoch 32/38 Batch 4000/7662 eta: 6:26:43.375789	Training Loss 0.0708 (0.0705)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.989)	
2022-05-11 21:53:29,806: ============================================================
2022-05-11 21:54:16,559: time cost, forward:0.17132854106863057, backward:0.10504371092126963, data cost:0.19082913523215903 
2022-05-11 21:54:16,560: ============================================================
2022-05-11 21:54:16,560: Epoch 32/38 Batch 4100/7662 eta: 6:25:59.472939	Training Loss 0.0644 (0.0705)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.989)	
2022-05-11 21:54:16,560: ============================================================
2022-05-11 21:55:03,310: time cost, forward:0.17132880739383285, backward:0.10503382641918803, data cost:0.1908399308684554 
2022-05-11 21:55:03,310: ============================================================
2022-05-11 21:55:03,310: Epoch 32/38 Batch 4200/7662 eta: 6:25:11.044126	Training Loss 0.0692 (0.0705)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.989)	
2022-05-11 21:55:03,310: ============================================================
2022-05-11 21:55:49,990: time cost, forward:0.1713149273054465, backward:0.1050275769669612, data cost:0.19084480530329986 
2022-05-11 21:55:49,990: ============================================================
2022-05-11 21:55:49,990: Epoch 32/38 Batch 4300/7662 eta: 6:23:49.574975	Training Loss 0.0708 (0.0705)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.989)	
2022-05-11 21:55:49,990: ============================================================
2022-05-11 21:56:36,547: time cost, forward:0.17127161688304918, backward:0.10502445066373547, data cost:0.19084619256305976 
2022-05-11 21:56:36,547: ============================================================
2022-05-11 21:56:36,547: Epoch 32/38 Batch 4400/7662 eta: 6:22:02.403004	Training Loss 0.0706 (0.0705)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.989)	
2022-05-11 21:56:36,547: ============================================================
2022-05-11 21:57:23,155: time cost, forward:0.17123743962595053, backward:0.10502039228287981, data cost:0.19085517897291113 
2022-05-11 21:57:23,155: ============================================================
2022-05-11 21:57:23,156: Epoch 32/38 Batch 4500/7662 eta: 6:21:41.045944	Training Loss 0.0737 (0.0705)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.989)	
2022-05-11 21:57:23,156: ============================================================
2022-05-11 21:58:09,743: time cost, forward:0.17121103121472794, backward:0.10501569922941356, data cost:0.19085139231879858 
2022-05-11 21:58:09,743: ============================================================
2022-05-11 21:58:09,743: Epoch 32/38 Batch 4600/7662 eta: 6:20:44.189674	Training Loss 0.0726 (0.0706)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.989)	
2022-05-11 21:58:09,743: ============================================================
2022-05-11 21:58:56,437: time cost, forward:0.17120398062547487, backward:0.10501151527336593, data cost:0.19085230515799287 
2022-05-11 21:58:56,437: ============================================================
2022-05-11 21:58:56,437: Epoch 32/38 Batch 4700/7662 eta: 6:20:49.675535	Training Loss 0.0746 (0.0706)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.989)	
2022-05-11 21:58:56,437: ============================================================
2022-05-11 21:59:43,140: time cost, forward:0.17118710889297617, backward:0.10500578916080297, data cost:0.19086654302005246 
2022-05-11 21:59:43,140: ============================================================
2022-05-11 21:59:43,140: Epoch 32/38 Batch 4800/7662 eta: 6:20:07.516153	Training Loss 0.0744 (0.0706)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.988)	
2022-05-11 21:59:43,140: ============================================================
2022-05-11 22:00:29,821: time cost, forward:0.17117965618039327, backward:0.1050028159049463, data cost:0.19086671951085263 
2022-05-11 22:00:29,821: ============================================================
2022-05-11 22:00:29,822: Epoch 32/38 Batch 4900/7662 eta: 6:19:10.139187	Training Loss 0.0698 (0.0706)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.988)	
2022-05-11 22:00:29,822: ============================================================
2022-05-11 22:01:16,526: time cost, forward:0.17116846077726897, backward:0.10500166997548985, data cost:0.19086980581235877 
2022-05-11 22:01:16,526: ============================================================
2022-05-11 22:01:16,527: Epoch 32/38 Batch 5000/7662 eta: 6:18:34.964538	Training Loss 0.0751 (0.0706)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.988)	
2022-05-11 22:01:16,527: ============================================================
2022-05-11 22:02:03,269: time cost, forward:0.17116446639070512, backward:0.10499896968572975, data cost:0.19087700765257748 
2022-05-11 22:02:03,269: ============================================================
2022-05-11 22:02:03,269: Epoch 32/38 Batch 5100/7662 eta: 6:18:06.531770	Training Loss 0.0725 (0.0706)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.988)	
2022-05-11 22:02:03,269: ============================================================
2022-05-11 22:02:50,062: time cost, forward:0.17116822263648312, backward:0.10499759251439908, data cost:0.19088440708161133 
2022-05-11 22:02:50,063: ============================================================
2022-05-11 22:02:50,063: Epoch 32/38 Batch 5200/7662 eta: 6:17:44.446596	Training Loss 0.0695 (0.0707)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.988)	
2022-05-11 22:02:50,063: ============================================================
2022-05-11 22:03:36,894: time cost, forward:0.17117479518351184, backward:0.10499321588774316, data cost:0.1908967693384289 
2022-05-11 22:03:36,895: ============================================================
2022-05-11 22:03:36,895: Epoch 32/38 Batch 5300/7662 eta: 6:17:16.238565	Training Loss 0.0689 (0.0707)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.988)	
2022-05-11 22:03:36,895: ============================================================
2022-05-11 22:04:23,665: time cost, forward:0.17118366569650462, backward:0.10498851514520591, data cost:0.19089753743917284 
2022-05-11 22:04:23,665: ============================================================
2022-05-11 22:04:23,665: Epoch 32/38 Batch 5400/7662 eta: 6:15:59.748693	Training Loss 0.0707 (0.0707)	Training Prec@1 99.805 (99.968)	Training Prec@5 100.000 (99.988)	
2022-05-11 22:04:23,665: ============================================================
2022-05-11 22:05:10,329: time cost, forward:0.17118656177871075, backward:0.10498246706102214, data cost:0.19088844668542196 
2022-05-11 22:05:10,330: ============================================================
2022-05-11 22:05:10,330: Epoch 32/38 Batch 5500/7662 eta: 6:14:22.014455	Training Loss 0.0706 (0.0707)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.988)	
2022-05-11 22:05:10,330: ============================================================
2022-05-11 22:05:57,093: time cost, forward:0.1711954413449941, backward:0.10497909968485682, data cost:0.19088856678686944 
2022-05-11 22:05:57,093: ============================================================
2022-05-11 22:05:57,094: Epoch 32/38 Batch 5600/7662 eta: 6:14:22.976740	Training Loss 0.0700 (0.0707)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.988)	
2022-05-11 22:05:57,094: ============================================================
2022-05-11 22:06:43,840: time cost, forward:0.17120299893191956, backward:0.10497592277413063, data cost:0.19088661170754648 
2022-05-11 22:06:43,840: ============================================================
2022-05-11 22:06:43,840: Epoch 32/38 Batch 5700/7662 eta: 6:13:27.899925	Training Loss 0.0656 (0.0707)	Training Prec@1 99.805 (99.967)	Training Prec@5 99.805 (99.987)	
2022-05-11 22:06:43,840: ============================================================
2022-05-11 22:07:30,626: time cost, forward:0.17121313538792257, backward:0.10496951863979097, data cost:0.19088832113861648 
2022-05-11 22:07:30,626: ============================================================
2022-05-11 22:07:30,626: Epoch 32/38 Batch 5800/7662 eta: 6:13:00.054709	Training Loss 0.0766 (0.0707)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.987)	
2022-05-11 22:07:30,626: ============================================================
2022-05-11 22:08:17,393: time cost, forward:0.17122603772272194, backward:0.10496328195933063, data cost:0.19088355103353866 
2022-05-11 22:08:17,393: ============================================================
2022-05-11 22:08:17,393: Epoch 32/38 Batch 5900/7662 eta: 6:12:04.466089	Training Loss 0.0720 (0.0707)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.987)	
2022-05-11 22:08:17,394: ============================================================
2022-05-11 22:09:04,140: time cost, forward:0.1712391368944181, backward:0.10495710361001889, data cost:0.1908745697327983 
2022-05-11 22:09:04,140: ============================================================
2022-05-11 22:09:04,141: Epoch 32/38 Batch 6000/7662 eta: 6:11:07.959448	Training Loss 0.0660 (0.0707)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.987)	
2022-05-11 22:09:04,141: ============================================================
2022-05-11 22:09:50,928: time cost, forward:0.171250310955057, backward:0.10495316116394303, data cost:0.19087431958159926 
2022-05-11 22:09:50,928: ============================================================
2022-05-11 22:09:50,929: Epoch 32/38 Batch 6100/7662 eta: 6:10:40.665311	Training Loss 0.0654 (0.0707)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.987)	
2022-05-11 22:09:50,929: ============================================================
2022-05-11 22:10:37,728: time cost, forward:0.1712652854639439, backward:0.10495153871884863, data cost:0.1908714792424199 
2022-05-11 22:10:37,728: ============================================================
2022-05-11 22:10:37,728: Epoch 32/38 Batch 6200/7662 eta: 6:09:59.417688	Training Loss 0.0734 (0.0708)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.988)	
2022-05-11 22:10:37,728: ============================================================
2022-05-11 22:11:24,493: time cost, forward:0.17127533582756113, backward:0.10494788481443908, data cost:0.1908677020589971 
2022-05-11 22:11:24,493: ============================================================
2022-05-11 22:11:24,493: Epoch 32/38 Batch 6300/7662 eta: 6:08:56.175219	Training Loss 0.0703 (0.0708)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.988)	
2022-05-11 22:11:24,493: ============================================================
2022-05-11 22:12:11,317: time cost, forward:0.17128612652740025, backward:0.10494299783690271, data cost:0.19087198593221916 
2022-05-11 22:12:11,318: ============================================================
2022-05-11 22:12:11,318: Epoch 32/38 Batch 6400/7662 eta: 6:08:37.623338	Training Loss 0.0742 (0.0708)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.988)	
2022-05-11 22:12:11,318: ============================================================
2022-05-11 22:12:58,174: time cost, forward:0.17130244594479474, backward:0.10493757405965617, data cost:0.1908774761112493 
2022-05-11 22:12:58,174: ============================================================
2022-05-11 22:12:58,175: Epoch 32/38 Batch 6500/7662 eta: 6:08:05.919116	Training Loss 0.0697 (0.0708)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.988)	
2022-05-11 22:12:58,175: ============================================================
2022-05-11 22:13:44,940: time cost, forward:0.17131219952192103, backward:0.10493302912509049, data cost:0.19087607055961192 
2022-05-11 22:13:44,940: ============================================================
2022-05-11 22:13:44,940: Epoch 32/38 Batch 6600/7662 eta: 6:06:36.277657	Training Loss 0.0655 (0.0708)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.987)	
2022-05-11 22:13:44,940: ============================================================
2022-05-11 22:14:31,709: time cost, forward:0.1713238206260648, backward:0.10492962690445358, data cost:0.19087238407149246 
2022-05-11 22:14:31,709: ============================================================
2022-05-11 22:14:31,710: Epoch 32/38 Batch 6700/7662 eta: 6:05:51.147448	Training Loss 0.0753 (0.0708)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.987)	
2022-05-11 22:14:31,710: ============================================================
2022-05-11 22:15:18,498: time cost, forward:0.1713323875426685, backward:0.10492561441744964, data cost:0.1908741258210795 
2022-05-11 22:15:18,498: ============================================================
2022-05-11 22:15:18,498: Epoch 32/38 Batch 6800/7662 eta: 6:05:13.487247	Training Loss 0.0719 (0.0708)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.987)	
2022-05-11 22:15:18,498: ============================================================
2022-05-11 22:16:05,258: time cost, forward:0.17134477280416183, backward:0.10492221167647747, data cost:0.19086716157454547 
2022-05-11 22:16:05,259: ============================================================
2022-05-11 22:16:05,259: Epoch 32/38 Batch 6900/7662 eta: 6:04:13.496477	Training Loss 0.0714 (0.0708)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.987)	
2022-05-11 22:16:05,259: ============================================================
2022-05-11 22:16:51,952: time cost, forward:0.17134978682982238, backward:0.10491991189568872, data cost:0.19085748935873328 
2022-05-11 22:16:51,952: ============================================================
2022-05-11 22:16:51,952: Epoch 32/38 Batch 7000/7662 eta: 6:02:55.512633	Training Loss 0.0742 (0.0708)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.987)	
2022-05-11 22:16:51,952: ============================================================
2022-05-11 22:17:38,635: time cost, forward:0.17135542062726353, backward:0.10491670177157185, data cost:0.1908470430010086 
2022-05-11 22:17:38,635: ============================================================
2022-05-11 22:17:38,635: Epoch 32/38 Batch 7100/7662 eta: 6:02:03.834570	Training Loss 0.0721 (0.0708)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.987)	
2022-05-11 22:17:38,635: ============================================================
2022-05-11 22:18:25,288: time cost, forward:0.17136079017479133, backward:0.10491403190108335, data cost:0.19083246738981216 
2022-05-11 22:18:25,289: ============================================================
2022-05-11 22:18:25,289: Epoch 32/38 Batch 7200/7662 eta: 6:01:03.675096	Training Loss 0.0712 (0.0708)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.987)	
2022-05-11 22:18:25,289: ============================================================
2022-05-11 22:19:11,973: time cost, forward:0.17136755968254058, backward:0.10491087972701356, data cost:0.19082180489120557 
2022-05-11 22:19:11,974: ============================================================
2022-05-11 22:19:11,974: Epoch 32/38 Batch 7300/7662 eta: 6:00:31.511184	Training Loss 0.0803 (0.0709)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.987)	
2022-05-11 22:19:11,974: ============================================================
2022-05-11 22:19:58,619: time cost, forward:0.17137248349489434, backward:0.10490709315249849, data cost:0.19080856716750458 
2022-05-11 22:19:58,620: ============================================================
2022-05-11 22:19:58,620: Epoch 32/38 Batch 7400/7662 eta: 5:59:26.829095	Training Loss 0.0731 (0.0709)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.987)	
2022-05-11 22:19:58,620: ============================================================
2022-05-11 22:20:45,238: time cost, forward:0.17137713256812537, backward:0.10490292793179308, data cost:0.1907927494300876 
2022-05-11 22:20:45,239: ============================================================
2022-05-11 22:20:45,239: Epoch 32/38 Batch 7500/7662 eta: 5:58:27.694990	Training Loss 0.0736 (0.0709)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.987)	
2022-05-11 22:20:45,239: ============================================================
2022-05-11 22:21:31,885: time cost, forward:0.17138094735123607, backward:0.10489941935960298, data cost:0.19077998996643758 
2022-05-11 22:21:31,886: ============================================================
2022-05-11 22:21:31,886: Epoch 32/38 Batch 7600/7662 eta: 5:57:53.861204	Training Loss 0.0803 (0.0709)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.987)	
2022-05-11 22:21:31,886: ============================================================
2022-05-11 22:22:02,607: Epoch: 32/38 eta: 5:57:24.473710	Training Loss 0.0687 (0.0709)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.987)
2022-05-11 22:22:02,608: ============================================================
2022-05-11 22:22:02,633: Save Checkpoint...
2022-05-11 22:22:02,634: ============================================================
2022-05-11 22:22:04,941: Save done!
2022-05-11 22:22:04,941: ============================================================
2022-05-11 22:22:54,520: time cost, forward:0.18880510089373348, backward:0.10437516010168826, data cost:0.2054422383356576 
2022-05-11 22:22:54,521: ============================================================
2022-05-11 22:22:54,521: Epoch 33/38 Batch 100/7662 eta: 6:19:03.042731	Training Loss 0.0648 (0.0694)	Training Prec@1 100.000 (99.963)	Training Prec@5 100.000 (99.986)	
2022-05-11 22:22:54,521: ============================================================
2022-05-11 22:23:41,415: time cost, forward:0.18165247284587305, backward:0.1044610349377196, data cost:0.1974701234443703 
2022-05-11 22:23:41,416: ============================================================
2022-05-11 22:23:41,416: Epoch 33/38 Batch 200/7662 eta: 5:57:45.190065	Training Loss 0.0683 (0.0694)	Training Prec@1 100.000 (99.963)	Training Prec@5 100.000 (99.982)	
2022-05-11 22:23:41,416: ============================================================
2022-05-11 22:24:27,993: time cost, forward:0.17811873206326795, backward:0.10455544975689024, data cost:0.19487013625460722 
2022-05-11 22:24:27,994: ============================================================
2022-05-11 22:24:27,994: Epoch 33/38 Batch 300/7662 eta: 5:54:33.530008	Training Loss 0.0702 (0.0692)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.986)	
2022-05-11 22:24:27,994: ============================================================
2022-05-11 22:25:14,572: time cost, forward:0.17628243214504463, backward:0.10455702121992756, data cost:0.19369517292892724 
2022-05-11 22:25:14,573: ============================================================
2022-05-11 22:25:14,573: Epoch 33/38 Batch 400/7662 eta: 5:53:47.389321	Training Loss 0.0714 (0.0694)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.986)	
2022-05-11 22:25:14,573: ============================================================
2022-05-11 22:26:01,141: time cost, forward:0.1751716977847602, backward:0.10456378044250733, data cost:0.19297385741331297 
2022-05-11 22:26:01,141: ============================================================
2022-05-11 22:26:01,141: Epoch 33/38 Batch 500/7662 eta: 5:52:56.002738	Training Loss 0.0653 (0.0693)	Training Prec@1 100.000 (99.971)	Training Prec@5 100.000 (99.988)	
2022-05-11 22:26:01,141: ============================================================
2022-05-11 22:26:47,787: time cost, forward:0.17448831161791972, backward:0.10455675395780892, data cost:0.19257954842658195 
2022-05-11 22:26:47,787: ============================================================
2022-05-11 22:26:47,787: Epoch 33/38 Batch 600/7662 eta: 5:52:44.749253	Training Loss 0.0715 (0.0694)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.990)	
2022-05-11 22:26:47,787: ============================================================
2022-05-11 22:27:34,406: time cost, forward:0.17401360783283631, backward:0.10455691524500157, data cost:0.1922410588407721 
2022-05-11 22:27:34,406: ============================================================
2022-05-11 22:27:34,406: Epoch 33/38 Batch 700/7662 eta: 5:51:45.733068	Training Loss 0.0640 (0.0694)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.990)	
2022-05-11 22:27:34,406: ============================================================
2022-05-11 22:28:21,095: time cost, forward:0.1737196367882071, backward:0.10455791523519237, data cost:0.19201186064337014 
2022-05-11 22:28:21,095: ============================================================
2022-05-11 22:28:21,095: Epoch 33/38 Batch 800/7662 eta: 5:51:30.912497	Training Loss 0.0681 (0.0694)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.990)	
2022-05-11 22:28:21,095: ============================================================
2022-05-11 22:29:07,747: time cost, forward:0.1734550168967751, backward:0.10455381247039897, data cost:0.19183351280161484 
2022-05-11 22:29:07,748: ============================================================
2022-05-11 22:29:07,748: Epoch 33/38 Batch 900/7662 eta: 5:50:27.711376	Training Loss 0.0691 (0.0694)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.990)	
2022-05-11 22:29:07,748: ============================================================
2022-05-11 22:29:54,405: time cost, forward:0.17326225723709548, backward:0.10455102963490528, data cost:0.1916775481478946 
2022-05-11 22:29:54,405: ============================================================
2022-05-11 22:29:54,405: Epoch 33/38 Batch 1000/7662 eta: 5:49:43.386535	Training Loss 0.0720 (0.0694)	Training Prec@1 99.805 (99.969)	Training Prec@5 100.000 (99.989)	
2022-05-11 22:29:54,406: ============================================================
2022-05-11 22:30:41,054: time cost, forward:0.17310745679214937, backward:0.10454934569680767, data cost:0.19153871462494812 
2022-05-11 22:30:41,055: ============================================================
2022-05-11 22:30:41,055: Epoch 33/38 Batch 1100/7662 eta: 5:48:52.882982	Training Loss 0.0700 (0.0694)	Training Prec@1 99.805 (99.968)	Training Prec@5 100.000 (99.989)	
2022-05-11 22:30:41,055: ============================================================
2022-05-11 22:31:27,756: time cost, forward:0.17301395478300297, backward:0.10454994683667358, data cost:0.19142818391273378 
2022-05-11 22:31:27,756: ============================================================
2022-05-11 22:31:27,756: Epoch 33/38 Batch 1200/7662 eta: 5:48:29.734515	Training Loss 0.0738 (0.0694)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.989)	
2022-05-11 22:31:27,756: ============================================================
2022-05-11 22:32:14,504: time cost, forward:0.1729119396650213, backward:0.10454838821023496, data cost:0.19138762838937762 
2022-05-11 22:32:14,505: ============================================================
2022-05-11 22:32:14,505: Epoch 33/38 Batch 1300/7662 eta: 5:48:03.924755	Training Loss 0.0728 (0.0694)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.990)	
2022-05-11 22:32:14,505: ============================================================
2022-05-11 22:33:01,191: time cost, forward:0.1728188872252131, backward:0.10455107637777594, data cost:0.1913094295613505 
2022-05-11 22:33:01,192: ============================================================
2022-05-11 22:33:01,192: Epoch 33/38 Batch 1400/7662 eta: 5:46:49.848705	Training Loss 0.0637 (0.0694)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.990)	
2022-05-11 22:33:01,192: ============================================================
2022-05-11 22:33:47,950: time cost, forward:0.17276370215209189, backward:0.10456534542188078, data cost:0.19126001129633907 
2022-05-11 22:33:47,950: ============================================================
2022-05-11 22:33:47,950: Epoch 33/38 Batch 1500/7662 eta: 5:46:34.778708	Training Loss 0.0678 (0.0694)	Training Prec@1 99.805 (99.969)	Training Prec@5 99.805 (99.990)	
2022-05-11 22:33:47,950: ============================================================
2022-05-11 22:34:34,733: time cost, forward:0.17271638035848783, backward:0.10456351237866639, data cost:0.1912461567700394 
2022-05-11 22:34:34,733: ============================================================
2022-05-11 22:34:34,734: Epoch 33/38 Batch 1600/7662 eta: 5:45:59.207101	Training Loss 0.0736 (0.0695)	Training Prec@1 99.805 (99.969)	Training Prec@5 99.805 (99.990)	
2022-05-11 22:34:34,734: ============================================================
2022-05-11 22:35:21,514: time cost, forward:0.17266798650888643, backward:0.10456516014399986, data cost:0.1912231504250583 
2022-05-11 22:35:21,514: ============================================================
2022-05-11 22:35:21,514: Epoch 33/38 Batch 1700/7662 eta: 5:45:11.295719	Training Loss 0.0690 (0.0695)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.990)	
2022-05-11 22:35:21,514: ============================================================
2022-05-11 22:36:08,289: time cost, forward:0.1725993050410391, backward:0.10456830544760652, data cost:0.19119742156532885 
2022-05-11 22:36:08,289: ============================================================
2022-05-11 22:36:08,290: Epoch 33/38 Batch 1800/7662 eta: 5:44:22.005256	Training Loss 0.0715 (0.0695)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.990)	
2022-05-11 22:36:08,290: ============================================================
2022-05-11 22:36:55,008: time cost, forward:0.17256189196156224, backward:0.10456602569628289, data cost:0.19116158934879957 
2022-05-11 22:36:55,008: ============================================================
2022-05-11 22:36:55,009: Epoch 33/38 Batch 1900/7662 eta: 5:43:10.488347	Training Loss 0.0635 (0.0695)	Training Prec@1 99.805 (99.969)	Training Prec@5 100.000 (99.989)	
2022-05-11 22:36:55,009: ============================================================
2022-05-11 22:37:41,739: time cost, forward:0.17251780356330357, backward:0.10456984230373549, data cost:0.19113349842989427 
2022-05-11 22:37:41,739: ============================================================
2022-05-11 22:37:41,740: Epoch 33/38 Batch 2000/7662 eta: 5:42:28.988953	Training Loss 0.0741 (0.0695)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.989)	
2022-05-11 22:37:41,740: ============================================================
2022-05-11 22:38:28,511: time cost, forward:0.1724937197252249, backward:0.10457787438765657, data cost:0.19111282079205053 
2022-05-11 22:38:28,511: ============================================================
2022-05-11 22:38:28,511: Epoch 33/38 Batch 2100/7662 eta: 5:42:00.123527	Training Loss 0.0699 (0.0695)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.989)	
2022-05-11 22:38:28,511: ============================================================
2022-05-11 22:39:15,274: time cost, forward:0.17246463126407638, backward:0.10458229682075809, data cost:0.1911000553831939 
2022-05-11 22:39:15,274: ============================================================
2022-05-11 22:39:15,275: Epoch 33/38 Batch 2200/7662 eta: 5:41:09.728088	Training Loss 0.0729 (0.0695)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.989)	
2022-05-11 22:39:15,275: ============================================================
2022-05-11 22:40:02,017: time cost, forward:0.17244348032363552, backward:0.10458258941620524, data cost:0.19107302835372386 
2022-05-11 22:40:02,017: ============================================================
2022-05-11 22:40:02,017: Epoch 33/38 Batch 2300/7662 eta: 5:40:13.940352	Training Loss 0.0662 (0.0696)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.989)	
2022-05-11 22:40:02,017: ============================================================
2022-05-11 22:40:48,706: time cost, forward:0.17242069252335365, backward:0.10458250331997922, data cost:0.1910344597298486 
2022-05-11 22:40:48,706: ============================================================
2022-05-11 22:40:48,707: Epoch 33/38 Batch 2400/7662 eta: 5:39:03.932351	Training Loss 0.0698 (0.0696)	Training Prec@1 99.805 (99.969)	Training Prec@5 99.805 (99.989)	
2022-05-11 22:40:48,707: ============================================================
2022-05-11 22:41:35,476: time cost, forward:0.17241430053619347, backward:0.10458210135708336, data cost:0.19101644010723184 
2022-05-11 22:41:35,476: ============================================================
2022-05-11 22:41:35,476: Epoch 33/38 Batch 2500/7662 eta: 5:38:52.125679	Training Loss 0.0685 (0.0696)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.989)	
2022-05-11 22:41:35,476: ============================================================
2022-05-11 22:42:22,207: time cost, forward:0.17239344913531102, backward:0.10458102910598456, data cost:0.19100104189230965 
2022-05-11 22:42:22,207: ============================================================
2022-05-11 22:42:22,207: Epoch 33/38 Batch 2600/7662 eta: 5:37:48.742705	Training Loss 0.0663 (0.0696)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.989)	
2022-05-11 22:42:22,207: ============================================================
2022-05-11 22:43:08,899: time cost, forward:0.1723676480466059, backward:0.10458286394230212, data cost:0.19097637087824434 
2022-05-11 22:43:08,899: ============================================================
2022-05-11 22:43:08,899: Epoch 33/38 Batch 2700/7662 eta: 5:36:44.940705	Training Loss 0.0706 (0.0696)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.989)	
2022-05-11 22:43:08,899: ============================================================
2022-05-11 22:43:55,597: time cost, forward:0.17234832391265292, backward:0.10458337881600017, data cost:0.19095208475358916 
2022-05-11 22:43:55,597: ============================================================
2022-05-11 22:43:55,597: Epoch 33/38 Batch 2800/7662 eta: 5:36:00.891700	Training Loss 0.0642 (0.0696)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.989)	
2022-05-11 22:43:55,597: ============================================================
2022-05-11 22:44:42,339: time cost, forward:0.1723454413063652, backward:0.10457934976323138, data cost:0.19093347985648254 
2022-05-11 22:44:42,339: ============================================================
2022-05-11 22:44:42,339: Epoch 33/38 Batch 2900/7662 eta: 5:35:33.236543	Training Loss 0.0692 (0.0696)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.989)	
2022-05-11 22:44:42,339: ============================================================
2022-05-11 22:45:29,036: time cost, forward:0.17233387427792704, backward:0.10457582098517906, data cost:0.19091054454331557 
2022-05-11 22:45:29,036: ============================================================
2022-05-11 22:45:29,036: Epoch 33/38 Batch 3000/7662 eta: 5:34:26.969244	Training Loss 0.0664 (0.0696)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.989)	
2022-05-11 22:45:29,036: ============================================================
2022-05-11 22:46:15,727: time cost, forward:0.17232048692300111, backward:0.10457726862015898, data cost:0.19088106233868224 
2022-05-11 22:46:15,727: ============================================================
2022-05-11 22:46:15,727: Epoch 33/38 Batch 3100/7662 eta: 5:33:38.069056	Training Loss 0.0724 (0.0696)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.989)	
2022-05-11 22:46:15,728: ============================================================
2022-05-11 22:47:02,438: time cost, forward:0.17230739150803026, backward:0.10457869975706234, data cost:0.19086353471033943 
2022-05-11 22:47:02,438: ============================================================
2022-05-11 22:47:02,438: Epoch 33/38 Batch 3200/7662 eta: 5:32:59.624120	Training Loss 0.0718 (0.0697)	Training Prec@1 99.805 (99.968)	Training Prec@5 100.000 (99.989)	
2022-05-11 22:47:02,438: ============================================================
2022-05-11 22:47:49,231: time cost, forward:0.17231306909755997, backward:0.10457954301224148, data cost:0.1908546828905645 
2022-05-11 22:47:49,232: ============================================================
2022-05-11 22:47:49,232: Epoch 33/38 Batch 3300/7662 eta: 5:32:48.248021	Training Loss 0.0711 (0.0697)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.989)	
2022-05-11 22:47:49,232: ============================================================
2022-05-11 22:48:35,988: time cost, forward:0.17230366503150718, backward:0.10458243436832995, data cost:0.19084405870990354 
2022-05-11 22:48:35,988: ============================================================
2022-05-11 22:48:35,988: Epoch 33/38 Batch 3400/7662 eta: 5:31:45.579989	Training Loss 0.0705 (0.0697)	Training Prec@1 99.805 (99.969)	Training Prec@5 100.000 (99.989)	
2022-05-11 22:48:35,988: ============================================================
2022-05-11 22:49:22,755: time cost, forward:0.1722922013057372, backward:0.10458381798104512, data cost:0.1908415914024752 
2022-05-11 22:49:22,755: ============================================================
2022-05-11 22:49:22,755: Epoch 33/38 Batch 3500/7662 eta: 5:31:03.347387	Training Loss 0.0715 (0.0697)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.989)	
2022-05-11 22:49:22,755: ============================================================
2022-05-11 22:50:09,512: time cost, forward:0.17228171831371056, backward:0.10460283525058314, data cost:0.19081926107340372 
2022-05-11 22:50:09,513: ============================================================
2022-05-11 22:50:09,513: Epoch 33/38 Batch 3600/7662 eta: 5:30:12.582926	Training Loss 0.0732 (0.0697)	Training Prec@1 99.805 (99.969)	Training Prec@5 100.000 (99.989)	
2022-05-11 22:50:09,513: ============================================================
2022-05-11 22:50:56,351: time cost, forward:0.17226650760637227, backward:0.10464425826917052, data cost:0.19080467177713584 
2022-05-11 22:50:56,352: ============================================================
2022-05-11 22:50:56,352: Epoch 33/38 Batch 3700/7662 eta: 5:30:00.282716	Training Loss 0.0704 (0.0697)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.989)	
2022-05-11 22:50:56,352: ============================================================
2022-05-11 22:51:43,261: time cost, forward:0.1722530062872035, backward:0.10468316693216853, data cost:0.1908026575006664 
2022-05-11 22:51:43,262: ============================================================
2022-05-11 22:51:43,262: Epoch 33/38 Batch 3800/7662 eta: 5:29:43.280835	Training Loss 0.0733 (0.0697)	Training Prec@1 99.805 (99.969)	Training Prec@5 99.805 (99.989)	
2022-05-11 22:51:43,262: ============================================================
2022-05-11 22:52:29,944: time cost, forward:0.17223828864360535, backward:0.10468844365816785, data cost:0.1907829059396349 
2022-05-11 22:52:29,945: ============================================================
2022-05-11 22:52:29,945: Epoch 33/38 Batch 3900/7662 eta: 5:27:21.033520	Training Loss 0.0745 (0.0698)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.989)	
2022-05-11 22:52:29,945: ============================================================
2022-05-11 22:53:16,649: time cost, forward:0.17221273282492985, backward:0.10468564810947228, data cost:0.1907855371559641 
2022-05-11 22:53:16,649: ============================================================
2022-05-11 22:53:16,649: Epoch 33/38 Batch 4000/7662 eta: 5:26:43.272163	Training Loss 0.0741 (0.0698)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.989)	
2022-05-11 22:53:16,650: ============================================================
2022-05-11 22:54:03,310: time cost, forward:0.1721911251792154, backward:0.10468469220971328, data cost:0.19077572696934272 
2022-05-11 22:54:03,310: ============================================================
2022-05-11 22:54:03,310: Epoch 33/38 Batch 4100/7662 eta: 5:25:38.222167	Training Loss 0.0694 (0.0698)	Training Prec@1 99.805 (99.969)	Training Prec@5 100.000 (99.989)	
2022-05-11 22:54:03,310: ============================================================
2022-05-11 22:54:50,005: time cost, forward:0.17217397053885045, backward:0.10468171204405474, data cost:0.19077084194509494 
2022-05-11 22:54:50,006: ============================================================
2022-05-11 22:54:50,006: Epoch 33/38 Batch 4200/7662 eta: 5:25:06.235366	Training Loss 0.0659 (0.0698)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.989)	
2022-05-11 22:54:50,006: ============================================================
2022-05-11 22:55:36,671: time cost, forward:0.17215974948161644, backward:0.10467958832985025, data cost:0.1907560475955705 
2022-05-11 22:55:36,671: ============================================================
2022-05-11 22:55:36,671: Epoch 33/38 Batch 4300/7662 eta: 5:24:06.906432	Training Loss 0.0723 (0.0698)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.989)	
2022-05-11 22:55:36,672: ============================================================
2022-05-11 22:56:23,318: time cost, forward:0.1721423527521826, backward:0.10467695252248768, data cost:0.19074505999782568 
2022-05-11 22:56:23,318: ============================================================
2022-05-11 22:56:23,318: Epoch 33/38 Batch 4400/7662 eta: 5:23:12.496978	Training Loss 0.0624 (0.0699)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.989)	
2022-05-11 22:56:23,318: ============================================================
2022-05-11 22:57:10,005: time cost, forward:0.17212645136851631, backward:0.10467453256239491, data cost:0.1907371882201036 
2022-05-11 22:57:10,005: ============================================================
2022-05-11 22:57:10,006: Epoch 33/38 Batch 4500/7662 eta: 5:22:42.612643	Training Loss 0.0707 (0.0699)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.989)	
2022-05-11 22:57:10,006: ============================================================
2022-05-11 22:57:56,723: time cost, forward:0.17211870080259836, backward:0.10467374482914842, data cost:0.19073010087142847 
2022-05-11 22:57:56,724: ============================================================
2022-05-11 22:57:56,724: Epoch 33/38 Batch 4600/7662 eta: 5:22:08.702920	Training Loss 0.0673 (0.0699)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.989)	
2022-05-11 22:57:56,724: ============================================================
2022-05-11 22:58:43,491: time cost, forward:0.1721126027603458, backward:0.1046751937249235, data cost:0.19073030197206875 
2022-05-11 22:58:43,491: ============================================================
2022-05-11 22:58:43,492: Epoch 33/38 Batch 4700/7662 eta: 5:21:42.498634	Training Loss 0.0688 (0.0699)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.989)	
2022-05-11 22:58:43,492: ============================================================
2022-05-11 22:59:30,221: time cost, forward:0.1721067488205932, backward:0.10467429487972017, data cost:0.1907260447746765 
2022-05-11 22:59:30,222: ============================================================
2022-05-11 22:59:30,222: Epoch 33/38 Batch 4800/7662 eta: 5:20:40.271405	Training Loss 0.0657 (0.0699)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.988)	
2022-05-11 22:59:30,222: ============================================================
2022-05-11 23:00:16,935: time cost, forward:0.17209721808775175, backward:0.10468011209978866, data cost:0.19071809518918817 
2022-05-11 23:00:16,935: ============================================================
2022-05-11 23:00:16,935: Epoch 33/38 Batch 4900/7662 eta: 5:19:46.529615	Training Loss 0.0710 (0.0700)	Training Prec@1 99.609 (99.968)	Training Prec@5 99.805 (99.988)	
2022-05-11 23:00:16,935: ============================================================
2022-05-11 23:01:03,682: time cost, forward:0.17209074325050253, backward:0.10468062516998639, data cost:0.1907183387609071 
2022-05-11 23:01:03,682: ============================================================
2022-05-11 23:01:03,682: Epoch 33/38 Batch 5000/7662 eta: 5:19:13.629741	Training Loss 0.0715 (0.0700)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.988)	
2022-05-11 23:01:03,682: ============================================================
2022-05-11 23:01:50,440: time cost, forward:0.17208723709568788, backward:0.10467754506344748, data cost:0.1907168363772039 
2022-05-11 23:01:50,440: ============================================================
2022-05-11 23:01:50,440: Epoch 33/38 Batch 5100/7662 eta: 5:18:31.482371	Training Loss 0.0701 (0.0700)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.988)	
2022-05-11 23:01:50,440: ============================================================
2022-05-11 23:02:37,188: time cost, forward:0.1720845088474474, backward:0.10467410248090359, data cost:0.1907114655174964 
2022-05-11 23:02:37,189: ============================================================
2022-05-11 23:02:37,189: Epoch 33/38 Batch 5200/7662 eta: 5:17:40.735911	Training Loss 0.0719 (0.0700)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.988)	
2022-05-11 23:02:37,189: ============================================================
2022-05-11 23:03:23,924: time cost, forward:0.17208123922483, backward:0.10467185369413469, data cost:0.19070988548186663 
2022-05-11 23:03:23,924: ============================================================
2022-05-11 23:03:23,924: Epoch 33/38 Batch 5300/7662 eta: 5:16:48.806272	Training Loss 0.0763 (0.0700)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.988)	
2022-05-11 23:03:23,925: ============================================================
2022-05-11 23:04:10,707: time cost, forward:0.17208209905961772, backward:0.10467094137704379, data cost:0.19071174030017798 
2022-05-11 23:04:10,707: ============================================================
2022-05-11 23:04:10,707: Epoch 33/38 Batch 5400/7662 eta: 5:16:21.183976	Training Loss 0.0726 (0.0700)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.988)	
2022-05-11 23:04:10,707: ============================================================
2022-05-11 23:04:57,506: time cost, forward:0.17208258657807501, backward:0.10466956897179935, data cost:0.1907175315209011 
2022-05-11 23:04:57,506: ============================================================
2022-05-11 23:04:57,506: Epoch 33/38 Batch 5500/7662 eta: 5:15:40.982825	Training Loss 0.0715 (0.0700)	Training Prec@1 99.805 (99.968)	Training Prec@5 99.805 (99.988)	
2022-05-11 23:04:57,506: ============================================================
2022-05-11 23:05:44,315: time cost, forward:0.17208327163775322, backward:0.10466862721280512, data cost:0.1907240875620228 
2022-05-11 23:05:44,316: ============================================================
2022-05-11 23:05:44,316: Epoch 33/38 Batch 5600/7662 eta: 5:14:58.408860	Training Loss 0.0657 (0.0700)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.988)	
2022-05-11 23:05:44,316: ============================================================
2022-05-11 23:06:31,045: time cost, forward:0.17207883571110016, backward:0.10466677286181875, data cost:0.1907208496320664 
2022-05-11 23:06:31,045: ============================================================
2022-05-11 23:06:31,046: Epoch 33/38 Batch 5700/7662 eta: 5:13:39.482939	Training Loss 0.0732 (0.0700)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.988)	
2022-05-11 23:06:31,046: ============================================================
2022-05-11 23:07:17,818: time cost, forward:0.17207461382771674, backward:0.10466575248423558, data cost:0.1907223419683476 
2022-05-11 23:07:17,819: ============================================================
2022-05-11 23:07:17,819: Epoch 33/38 Batch 5800/7662 eta: 5:13:10.152825	Training Loss 0.0701 (0.0700)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.988)	
2022-05-11 23:07:17,819: ============================================================
2022-05-11 23:08:04,546: time cost, forward:0.17207299355511585, backward:0.10466302845675696, data cost:0.19071901226512536 
2022-05-11 23:08:04,546: ============================================================
2022-05-11 23:08:04,546: Epoch 33/38 Batch 5900/7662 eta: 5:12:05.182907	Training Loss 0.0702 (0.0701)	Training Prec@1 99.805 (99.968)	Training Prec@5 99.805 (99.988)	
2022-05-11 23:08:04,547: ============================================================
2022-05-11 23:08:51,280: time cost, forward:0.17206874933416078, backward:0.10466066029175537, data cost:0.19071927832094585 
2022-05-11 23:08:51,280: ============================================================
2022-05-11 23:08:51,280: Epoch 33/38 Batch 6000/7662 eta: 5:11:20.899179	Training Loss 0.0692 (0.0701)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.988)	
2022-05-11 23:08:51,280: ============================================================
2022-05-11 23:09:38,032: time cost, forward:0.17206505291343496, backward:0.10465864803697618, data cost:0.19071967305854062 
2022-05-11 23:09:38,032: ============================================================
2022-05-11 23:09:38,032: Epoch 33/38 Batch 6100/7662 eta: 5:10:41.402942	Training Loss 0.0688 (0.0701)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.988)	
2022-05-11 23:09:38,032: ============================================================
2022-05-11 23:10:24,832: time cost, forward:0.17206528044877697, backward:0.1046581119467201, data cost:0.1907230362736 
2022-05-11 23:10:24,832: ============================================================
2022-05-11 23:10:24,832: Epoch 33/38 Batch 6200/7662 eta: 5:10:13.875023	Training Loss 0.0682 (0.0701)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.988)	
2022-05-11 23:10:24,832: ============================================================
2022-05-11 23:11:11,570: time cost, forward:0.17206205873569622, backward:0.1046569422325041, data cost:0.19072204692947767 
2022-05-11 23:11:11,570: ============================================================
2022-05-11 23:11:11,570: Epoch 33/38 Batch 6300/7662 eta: 5:09:02.213096	Training Loss 0.0692 (0.0701)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.988)	
2022-05-11 23:11:11,570: ============================================================
2022-05-11 23:11:58,326: time cost, forward:0.17206159534445403, backward:0.10465484206462991, data cost:0.1907223504974537 
2022-05-11 23:11:58,326: ============================================================
2022-05-11 23:11:58,326: Epoch 33/38 Batch 6400/7662 eta: 5:08:22.792750	Training Loss 0.0709 (0.0701)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.988)	
2022-05-11 23:11:58,326: ============================================================
2022-05-11 23:12:45,075: time cost, forward:0.1720623633259534, backward:0.10465498637522087, data cost:0.19071615452142032 
2022-05-11 23:12:45,075: ============================================================
2022-05-11 23:12:45,075: Epoch 33/38 Batch 6500/7662 eta: 5:07:33.262538	Training Loss 0.0697 (0.0701)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.988)	
2022-05-11 23:12:45,075: ============================================================
2022-05-11 23:13:31,838: time cost, forward:0.17206289302509722, backward:0.10465272117119917, data cost:0.19071688144780377 
2022-05-11 23:13:31,838: ============================================================
2022-05-11 23:13:31,838: Epoch 33/38 Batch 6600/7662 eta: 5:06:52.056636	Training Loss 0.0667 (0.0702)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.988)	
2022-05-11 23:13:31,839: ============================================================
2022-05-11 23:14:18,667: time cost, forward:0.172063604933697, backward:0.10465176651096643, data cost:0.19072618308681608 
2022-05-11 23:14:18,667: ============================================================
2022-05-11 23:14:18,667: Epoch 33/38 Batch 6700/7662 eta: 5:06:31.181446	Training Loss 0.0673 (0.0702)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.988)	
2022-05-11 23:14:18,668: ============================================================
2022-05-11 23:15:05,438: time cost, forward:0.17206418442364949, backward:0.1046508966359799, data cost:0.19072624191955218 
2022-05-11 23:15:05,438: ============================================================
2022-05-11 23:15:05,438: Epoch 33/38 Batch 6800/7662 eta: 5:05:21.508437	Training Loss 0.0717 (0.0702)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.988)	
2022-05-11 23:15:05,438: ============================================================
2022-05-11 23:15:52,145: time cost, forward:0.17206358384318862, backward:0.10464880379719534, data cost:0.19071810911454778 
2022-05-11 23:15:52,146: ============================================================
2022-05-11 23:15:52,146: Epoch 33/38 Batch 6900/7662 eta: 5:04:10.061432	Training Loss 0.0746 (0.0702)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.988)	
2022-05-11 23:15:52,146: ============================================================
2022-05-11 23:16:38,865: time cost, forward:0.17206380721210907, backward:0.10464842313697532, data cost:0.19071090114101338 
2022-05-11 23:16:38,865: ============================================================
2022-05-11 23:16:38,865: Epoch 33/38 Batch 7000/7662 eta: 5:03:27.908899	Training Loss 0.0711 (0.0702)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.988)	
2022-05-11 23:16:38,865: ============================================================
2022-05-11 23:17:25,579: time cost, forward:0.17206115379419473, backward:0.10464669946449409, data cost:0.19070581356091035 
2022-05-11 23:17:25,579: ============================================================
2022-05-11 23:17:25,579: Epoch 33/38 Batch 7100/7662 eta: 5:02:39.115976	Training Loss 0.0727 (0.0702)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.988)	
2022-05-11 23:17:25,579: ============================================================
2022-05-11 23:18:12,346: time cost, forward:0.17206200753206807, backward:0.10464539615987721, data cost:0.19070595194025328 
2022-05-11 23:18:12,347: ============================================================
2022-05-11 23:18:12,347: Epoch 33/38 Batch 7200/7662 eta: 5:02:13.228009	Training Loss 0.0733 (0.0702)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.988)	
2022-05-11 23:18:12,347: ============================================================
2022-05-11 23:18:59,110: time cost, forward:0.17206611462138519, backward:0.10464423426962467, data cost:0.190702210780545 
2022-05-11 23:18:59,110: ============================================================
2022-05-11 23:18:59,110: Epoch 33/38 Batch 7300/7662 eta: 5:01:24.908462	Training Loss 0.0669 (0.0702)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.988)	
2022-05-11 23:18:59,111: ============================================================
2022-05-11 23:19:45,805: time cost, forward:0.17206776891307005, backward:0.10464305616034127, data cost:0.19069188564979542 
2022-05-11 23:19:45,805: ============================================================
2022-05-11 23:19:45,805: Epoch 33/38 Batch 7400/7662 eta: 5:00:11.600616	Training Loss 0.0737 (0.0702)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.988)	
2022-05-11 23:19:45,805: ============================================================
2022-05-11 23:20:32,560: time cost, forward:0.17206758876723724, backward:0.10464183437552416, data cost:0.19069032161009122 
2022-05-11 23:20:32,560: ============================================================
2022-05-11 23:20:32,560: Epoch 33/38 Batch 7500/7662 eta: 4:59:48.109807	Training Loss 0.0766 (0.0702)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.988)	
2022-05-11 23:20:32,560: ============================================================
2022-05-11 23:21:19,268: time cost, forward:0.1720650390600402, backward:0.1046406016379285, data cost:0.1906863499164644 
2022-05-11 23:21:19,268: ============================================================
2022-05-11 23:21:19,268: Epoch 33/38 Batch 7600/7662 eta: 4:58:43.224864	Training Loss 0.0685 (0.0702)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.988)	
2022-05-11 23:21:19,268: ============================================================
2022-05-11 23:21:49,834: Epoch: 33/38 eta: 4:58:13.798883	Training Loss 0.0745 (0.0702)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.988)
2022-05-11 23:21:49,834: ============================================================
2022-05-11 23:21:49,836: Save Checkpoint...
2022-05-11 23:21:49,836: ============================================================
2022-05-11 23:21:52,162: Save done!
2022-05-11 23:21:52,163: ============================================================
2022-05-11 23:22:42,461: time cost, forward:0.18976186501859416, backward:0.10435547973170425, data cost:0.2117564846770932 
2022-05-11 23:22:42,462: ============================================================
2022-05-11 23:22:42,462: Epoch 34/38 Batch 100/7662 eta: 5:20:19.083941	Training Loss 0.0682 (0.0687)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.994)	
2022-05-11 23:22:42,462: ============================================================
2022-05-11 23:23:29,448: time cost, forward:0.18259848901374856, backward:0.10440597342486357, data cost:0.20064811970121296 
2022-05-11 23:23:29,449: ============================================================
2022-05-11 23:23:29,449: Epoch 34/38 Batch 200/7662 eta: 4:58:27.311699	Training Loss 0.0613 (0.0687)	Training Prec@1 100.000 (99.967)	Training Prec@5 100.000 (99.984)	
2022-05-11 23:23:29,449: ============================================================
2022-05-11 23:24:16,057: time cost, forward:0.17893008085397574, backward:0.10445826109436443, data cost:0.19695572310865522 
2022-05-11 23:24:16,057: ============================================================
2022-05-11 23:24:16,057: Epoch 34/38 Batch 300/7662 eta: 4:55:16.341077	Training Loss 0.0684 (0.0685)	Training Prec@1 99.805 (99.971)	Training Prec@5 100.000 (99.986)	
2022-05-11 23:24:16,058: ============================================================
2022-05-11 23:25:02,686: time cost, forward:0.17711333463664042, backward:0.10449235540882387, data cost:0.19514734105657516 
2022-05-11 23:25:02,687: ============================================================
2022-05-11 23:25:02,687: Epoch 34/38 Batch 400/7662 eta: 4:54:37.728964	Training Loss 0.0745 (0.0686)	Training Prec@1 99.805 (99.972)	Training Prec@5 99.805 (99.988)	
2022-05-11 23:25:02,687: ============================================================
2022-05-11 23:25:49,353: time cost, forward:0.17610406158921235, backward:0.10451619658537045, data cost:0.19405338186061455 
2022-05-11 23:25:49,353: ============================================================
2022-05-11 23:25:49,353: Epoch 34/38 Batch 500/7662 eta: 4:54:04.914934	Training Loss 0.0700 (0.0686)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.989)	
2022-05-11 23:25:49,353: ============================================================
2022-05-11 23:26:35,976: time cost, forward:0.17537099650387772, backward:0.10452343386680335, data cost:0.19332609033345777 
2022-05-11 23:26:35,976: ============================================================
2022-05-11 23:26:35,976: Epoch 34/38 Batch 600/7662 eta: 4:53:02.036268	Training Loss 0.0645 (0.0687)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.990)	
2022-05-11 23:26:35,976: ============================================================
2022-05-11 23:27:22,581: time cost, forward:0.17484128014724143, backward:0.10451838557471192, data cost:0.19279754826950923 
2022-05-11 23:27:22,581: ============================================================
2022-05-11 23:27:22,581: Epoch 34/38 Batch 700/7662 eta: 4:52:08.573648	Training Loss 0.0683 (0.0687)	Training Prec@1 99.609 (99.970)	Training Prec@5 99.805 (99.989)	
2022-05-11 23:27:22,581: ============================================================
2022-05-11 23:28:09,236: time cost, forward:0.17449309888560424, backward:0.10452165203786762, data cost:0.1924073890094017 
2022-05-11 23:28:09,236: ============================================================
2022-05-11 23:28:09,237: Epoch 34/38 Batch 800/7662 eta: 4:51:40.951646	Training Loss 0.0694 (0.0687)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.989)	
2022-05-11 23:28:09,237: ============================================================
2022-05-11 23:28:55,863: time cost, forward:0.17417692713795832, backward:0.10452813884705404, data cost:0.19211455579594325 
2022-05-11 23:28:55,864: ============================================================
2022-05-11 23:28:55,864: Epoch 34/38 Batch 900/7662 eta: 4:50:43.713078	Training Loss 0.0609 (0.0688)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.990)	
2022-05-11 23:28:55,864: ============================================================
2022-05-11 23:29:42,477: time cost, forward:0.1739247446661597, backward:0.10452892973616316, data cost:0.1918709249467821 
2022-05-11 23:29:42,477: ============================================================
2022-05-11 23:29:42,477: Epoch 34/38 Batch 1000/7662 eta: 4:49:51.973259	Training Loss 0.0675 (0.0688)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.990)	
2022-05-11 23:29:42,477: ============================================================
2022-05-11 23:30:29,097: time cost, forward:0.17371925860778975, backward:0.10453273774928891, data cost:0.19167353588413172 
2022-05-11 23:30:29,098: ============================================================
2022-05-11 23:30:29,098: Epoch 34/38 Batch 1100/7662 eta: 4:49:07.921107	Training Loss 0.0665 (0.0688)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.990)	
2022-05-11 23:30:29,098: ============================================================
2022-05-11 23:31:15,762: time cost, forward:0.17358913692063943, backward:0.10453707322764139, data cost:0.19150463276052596 
2022-05-11 23:31:15,763: ============================================================
2022-05-11 23:31:15,763: Epoch 34/38 Batch 1200/7662 eta: 4:48:37.901577	Training Loss 0.0698 (0.0688)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.990)	
2022-05-11 23:31:15,763: ============================================================
2022-05-11 23:32:02,449: time cost, forward:0.17344672887301427, backward:0.10454018855663884, data cost:0.19141162295264405 
2022-05-11 23:32:02,450: ============================================================
2022-05-11 23:32:02,450: Epoch 34/38 Batch 1300/7662 eta: 4:47:59.302817	Training Loss 0.0661 (0.0688)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.989)	
2022-05-11 23:32:02,450: ============================================================
2022-05-11 23:32:49,116: time cost, forward:0.17332020957952232, backward:0.10454186837616948, data cost:0.19131510797954612 
2022-05-11 23:32:49,116: ============================================================
2022-05-11 23:32:49,116: Epoch 34/38 Batch 1400/7662 eta: 4:47:05.070617	Training Loss 0.0637 (0.0688)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.989)	
2022-05-11 23:32:49,116: ============================================================
2022-05-11 23:33:35,818: time cost, forward:0.1732416086152365, backward:0.1045461699833784, data cost:0.19122007021989879 
2022-05-11 23:33:35,818: ============================================================
2022-05-11 23:33:35,818: Epoch 34/38 Batch 1500/7662 eta: 4:46:31.429565	Training Loss 0.0724 (0.0688)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.990)	
2022-05-11 23:33:35,818: ============================================================
2022-05-11 23:34:22,466: time cost, forward:0.17315183482071697, backward:0.10454757188244714, data cost:0.1911340599286698 
2022-05-11 23:34:22,466: ============================================================
2022-05-11 23:34:22,466: Epoch 34/38 Batch 1600/7662 eta: 4:45:24.866757	Training Loss 0.0645 (0.0688)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.989)	
2022-05-11 23:34:22,466: ============================================================
2022-05-11 23:35:09,095: time cost, forward:0.17306981625593432, backward:0.10454684401203984, data cost:0.1910526143445065 
2022-05-11 23:35:09,095: ============================================================
2022-05-11 23:35:09,095: Epoch 34/38 Batch 1700/7662 eta: 4:44:31.461969	Training Loss 0.0705 (0.0689)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.989)	
2022-05-11 23:35:09,095: ============================================================
2022-05-11 23:35:55,736: time cost, forward:0.17300276268582135, backward:0.10454621773550682, data cost:0.19098052957311082 
2022-05-11 23:35:55,736: ============================================================
2022-05-11 23:35:55,736: Epoch 34/38 Batch 1800/7662 eta: 4:43:49.050343	Training Loss 0.0728 (0.0689)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.989)	
2022-05-11 23:35:55,736: ============================================================
2022-05-11 23:36:42,448: time cost, forward:0.1729432583608522, backward:0.10454933928338524, data cost:0.19094976894223986 
2022-05-11 23:36:42,448: ============================================================
2022-05-11 23:36:42,448: Epoch 34/38 Batch 1900/7662 eta: 4:43:28.315570	Training Loss 0.0717 (0.0689)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.989)	
2022-05-11 23:36:42,448: ============================================================
2022-05-11 23:37:29,121: time cost, forward:0.1729003487377539, backward:0.1045492710382596, data cost:0.1908943084193922 
2022-05-11 23:37:29,121: ============================================================
2022-05-11 23:37:29,121: Epoch 34/38 Batch 2000/7662 eta: 4:42:27.466915	Training Loss 0.0689 (0.0689)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.989)	
2022-05-11 23:37:29,122: ============================================================
2022-05-11 23:38:15,766: time cost, forward:0.1728508733692142, backward:0.10454872632492378, data cost:0.19084210847888236 
2022-05-11 23:38:15,766: ============================================================
2022-05-11 23:38:15,767: Epoch 34/38 Batch 2100/7662 eta: 4:41:30.684744	Training Loss 0.0660 (0.0689)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.989)	
2022-05-11 23:38:15,767: ============================================================
2022-05-11 23:39:02,408: time cost, forward:0.17280297617632565, backward:0.10454855511653635, data cost:0.19079574588864107 
2022-05-11 23:39:02,408: ============================================================
2022-05-11 23:39:02,409: Epoch 34/38 Batch 2200/7662 eta: 4:40:42.930143	Training Loss 0.0670 (0.0689)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.989)	
2022-05-11 23:39:02,409: ============================================================
2022-05-11 23:39:49,061: time cost, forward:0.17276320617164723, backward:0.10454908118345468, data cost:0.19075340247766098 
2022-05-11 23:39:49,061: ============================================================
2022-05-11 23:39:49,062: Epoch 34/38 Batch 2300/7662 eta: 4:40:00.192125	Training Loss 0.0658 (0.0689)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.989)	
2022-05-11 23:39:49,062: ============================================================
2022-05-11 23:40:35,707: time cost, forward:0.17272365247274052, backward:0.104549857366577, data cost:0.19071461877111298 
2022-05-11 23:40:35,707: ============================================================
2022-05-11 23:40:35,707: Epoch 34/38 Batch 2400/7662 eta: 4:39:10.829697	Training Loss 0.0686 (0.0689)	Training Prec@1 99.805 (99.970)	Training Prec@5 99.805 (99.989)	
2022-05-11 23:40:35,707: ============================================================
2022-05-11 23:41:22,342: time cost, forward:0.17268769089438143, backward:0.1045498376657792, data cost:0.1906751076094195 
2022-05-11 23:41:22,342: ============================================================
2022-05-11 23:41:22,342: Epoch 34/38 Batch 2500/7662 eta: 4:38:20.628216	Training Loss 0.0684 (0.0690)	Training Prec@1 99.805 (99.970)	Training Prec@5 100.000 (99.989)	
2022-05-11 23:41:22,343: ============================================================
2022-05-11 23:42:08,979: time cost, forward:0.17265494734840056, backward:0.10455091461028994, data cost:0.1906379523209399 
2022-05-11 23:42:08,979: ============================================================
2022-05-11 23:42:08,980: Epoch 34/38 Batch 2600/7662 eta: 4:37:34.595208	Training Loss 0.0681 (0.0690)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.989)	
2022-05-11 23:42:08,980: ============================================================
2022-05-11 23:42:55,614: time cost, forward:0.17262065936212587, backward:0.1045507587031463, data cost:0.19060738142352052 
2022-05-11 23:42:55,614: ============================================================
2022-05-11 23:42:55,614: Epoch 34/38 Batch 2700/7662 eta: 4:36:46.936920	Training Loss 0.0682 (0.0690)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.988)	
2022-05-11 23:42:55,614: ============================================================
2022-05-11 23:43:42,298: time cost, forward:0.17260728814253512, backward:0.10455114699210726, data cost:0.19057782346242325 
2022-05-11 23:43:42,299: ============================================================
2022-05-11 23:43:42,299: Epoch 34/38 Batch 2800/7662 eta: 4:36:18.224564	Training Loss 0.0728 (0.0690)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.988)	
2022-05-11 23:43:42,299: ============================================================
2022-05-11 23:44:28,909: time cost, forward:0.1725762927478739, backward:0.10455051756349257, data cost:0.19054447597123378 
2022-05-11 23:44:28,910: ============================================================
2022-05-11 23:44:28,910: Epoch 34/38 Batch 2900/7662 eta: 4:35:05.409243	Training Loss 0.0711 (0.0690)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.988)	
2022-05-11 23:44:28,910: ============================================================
2022-05-11 23:45:15,522: time cost, forward:0.17254873258584974, backward:0.10455011677527357, data cost:0.1905129106094854 
2022-05-11 23:45:15,522: ============================================================
2022-05-11 23:45:15,522: Epoch 34/38 Batch 3000/7662 eta: 4:34:19.455448	Training Loss 0.0667 (0.0690)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.988)	
2022-05-11 23:45:15,523: ============================================================
2022-05-11 23:46:02,149: time cost, forward:0.17252324580684636, backward:0.10454856999345886, data cost:0.19048836262774643 
2022-05-11 23:46:02,149: ============================================================
2022-05-11 23:46:02,149: Epoch 34/38 Batch 3100/7662 eta: 4:33:37.716229	Training Loss 0.0696 (0.0691)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.988)	
2022-05-11 23:46:02,149: ============================================================
2022-05-11 23:46:48,839: time cost, forward:0.17250795482135856, backward:0.10454881903006531, data cost:0.19047507273849004 
2022-05-11 23:46:48,840: ============================================================
2022-05-11 23:46:48,840: Epoch 34/38 Batch 3200/7662 eta: 4:33:13.581574	Training Loss 0.0637 (0.0691)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.988)	
2022-05-11 23:46:48,840: ============================================================
2022-05-11 23:47:35,495: time cost, forward:0.17248214595640887, backward:0.10454856225597964, data cost:0.19046395805684968 
2022-05-11 23:47:35,495: ============================================================
2022-05-11 23:47:35,495: Epoch 34/38 Batch 3300/7662 eta: 4:32:14.543059	Training Loss 0.0641 (0.0691)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.988)	
2022-05-11 23:47:35,495: ============================================================
2022-05-11 23:48:22,248: time cost, forward:0.17245652578128862, backward:0.10457807521533882, data cost:0.19045380116491045 
2022-05-11 23:48:22,248: ============================================================
2022-05-11 23:48:22,248: Epoch 34/38 Batch 3400/7662 eta: 4:32:01.888399	Training Loss 0.0671 (0.0691)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.988)	
2022-05-11 23:48:22,248: ============================================================
2022-05-11 23:49:09,064: time cost, forward:0.17243428119900364, backward:0.10461931741043444, data cost:0.19044666748177702 
2022-05-11 23:49:09,064: ============================================================
2022-05-11 23:49:09,064: Epoch 34/38 Batch 3500/7662 eta: 4:31:37.020401	Training Loss 0.0712 (0.0691)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.988)	
2022-05-11 23:49:09,064: ============================================================
2022-05-11 23:49:55,844: time cost, forward:0.17240297300810944, backward:0.10465898478021221, data cost:0.19043971280582617 
2022-05-11 23:49:55,844: ============================================================
2022-05-11 23:49:55,845: Epoch 34/38 Batch 3600/7662 eta: 4:30:38.022449	Training Loss 0.0703 (0.0692)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.988)	
2022-05-11 23:49:55,845: ============================================================
2022-05-11 23:50:42,539: time cost, forward:0.17235965572778972, backward:0.10469750089560305, data cost:0.19042245295602717 
2022-05-11 23:50:42,540: ============================================================
2022-05-11 23:50:42,540: Epoch 34/38 Batch 3700/7662 eta: 4:29:21.714692	Training Loss 0.0658 (0.0692)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.988)	
2022-05-11 23:50:42,540: ============================================================
2022-05-11 23:51:29,179: time cost, forward:0.17230596910121723, backward:0.10473365286646093, data cost:0.19040486768033196 
2022-05-11 23:51:29,179: ============================================================
2022-05-11 23:51:29,179: Epoch 34/38 Batch 3800/7662 eta: 4:28:15.632004	Training Loss 0.0675 (0.0692)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.988)	
2022-05-11 23:51:29,179: ============================================================
2022-05-11 23:52:15,831: time cost, forward:0.17225513772556006, backward:0.10476921637506478, data cost:0.19038979277668258 
2022-05-11 23:52:15,831: ============================================================
2022-05-11 23:52:15,831: Epoch 34/38 Batch 3900/7662 eta: 4:27:33.490834	Training Loss 0.0733 (0.0692)	Training Prec@1 99.805 (99.969)	Training Prec@5 100.000 (99.988)	
2022-05-11 23:52:15,831: ============================================================
2022-05-11 23:53:02,525: time cost, forward:0.17222097665853994, backward:0.1048016961916413, data cost:0.1903727550034405 
2022-05-11 23:53:02,526: ============================================================
2022-05-11 23:53:02,526: Epoch 34/38 Batch 4000/7662 eta: 4:27:01.386696	Training Loss 0.0714 (0.0692)	Training Prec@1 99.805 (99.969)	Training Prec@5 100.000 (99.988)	
2022-05-11 23:53:02,526: ============================================================
2022-05-11 23:53:49,160: time cost, forward:0.1721759717852408, backward:0.10483216250573871, data cost:0.19035570893121306 
2022-05-11 23:53:49,160: ============================================================
2022-05-11 23:53:49,161: Epoch 34/38 Batch 4100/7662 eta: 4:25:54.221462	Training Loss 0.0691 (0.0692)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.988)	
2022-05-11 23:53:49,161: ============================================================
2022-05-11 23:54:35,810: time cost, forward:0.17213605199152016, backward:0.10486121102723941, data cost:0.1903401515290237 
2022-05-11 23:54:35,810: ============================================================
2022-05-11 23:54:35,810: Epoch 34/38 Batch 4200/7662 eta: 4:25:12.634575	Training Loss 0.0691 (0.0693)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.988)	
2022-05-11 23:54:35,810: ============================================================
2022-05-11 23:55:22,434: time cost, forward:0.17209358913007242, backward:0.1048880062094398, data cost:0.19032397805937337 
2022-05-11 23:55:22,434: ============================================================
2022-05-11 23:55:22,434: Epoch 34/38 Batch 4300/7662 eta: 4:24:17.259878	Training Loss 0.0694 (0.0693)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.988)	
2022-05-11 23:55:22,434: ============================================================
2022-05-11 23:56:09,074: time cost, forward:0.17205727894378267, backward:0.104913794308745, data cost:0.19030804589651584 
2022-05-11 23:56:09,075: ============================================================
2022-05-11 23:56:09,075: Epoch 34/38 Batch 4400/7662 eta: 4:23:36.334441	Training Loss 0.0650 (0.0693)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.988)	
2022-05-11 23:56:09,075: ============================================================
2022-05-11 23:56:55,651: time cost, forward:0.1720203484236121, backward:0.10492647242667967, data cost:0.19029270518909802 
2022-05-11 23:56:55,652: ============================================================
2022-05-11 23:56:55,652: Epoch 34/38 Batch 4500/7662 eta: 4:22:28.126382	Training Loss 0.0689 (0.0693)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.988)	
2022-05-11 23:56:55,652: ============================================================
2022-05-11 23:57:42,158: time cost, forward:0.17198861928368733, backward:0.10491784123343782, data cost:0.19028041512584085 
2022-05-11 23:57:42,158: ============================================================
2022-05-11 23:57:42,159: Epoch 34/38 Batch 4600/7662 eta: 4:21:17.904996	Training Loss 0.0721 (0.0693)	Training Prec@1 99.805 (99.969)	Training Prec@5 99.805 (99.988)	
2022-05-11 23:57:42,159: ============================================================
2022-05-11 23:58:28,684: time cost, forward:0.17196666410461997, backward:0.10490928844939802, data cost:0.1902642562608055 
2022-05-11 23:58:28,684: ============================================================
2022-05-11 23:58:28,684: Epoch 34/38 Batch 4700/7662 eta: 4:20:37.642071	Training Loss 0.0733 (0.0693)	Training Prec@1 99.805 (99.969)	Training Prec@5 99.805 (99.988)	
2022-05-11 23:58:28,684: ============================================================
2022-05-11 23:59:15,254: time cost, forward:0.17195367837950795, backward:0.10490169706978533, data cost:0.1902496071998515 
2022-05-11 23:59:15,255: ============================================================
2022-05-11 23:59:15,255: Epoch 34/38 Batch 4800/7662 eta: 4:20:06.332421	Training Loss 0.0730 (0.0693)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.988)	
2022-05-11 23:59:15,255: ============================================================
2022-05-12 00:00:01,728: time cost, forward:0.17191382553363777, backward:0.10489487132142335, data cost:0.19024267501309347 
2022-05-12 00:00:01,729: ============================================================
2022-05-12 00:00:01,729: Epoch 34/38 Batch 4900/7662 eta: 4:18:47.432115	Training Loss 0.0690 (0.0693)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.989)	
2022-05-12 00:00:01,729: ============================================================
2022-05-12 00:00:48,247: time cost, forward:0.17187216530372726, backward:0.10488757006429057, data cost:0.19024971256878023 
2022-05-12 00:00:48,247: ============================================================
2022-05-12 00:00:48,247: Epoch 34/38 Batch 5000/7662 eta: 4:18:15.836891	Training Loss 0.0692 (0.0693)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.988)	
2022-05-12 00:00:48,247: ============================================================
2022-05-12 00:01:34,775: time cost, forward:0.17183680435236026, backward:0.10488033173107171, data cost:0.19025361886279774 
2022-05-12 00:01:34,775: ============================================================
2022-05-12 00:01:34,775: Epoch 34/38 Batch 5100/7662 eta: 4:17:32.429005	Training Loss 0.0706 (0.0694)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.989)	
2022-05-12 00:01:34,776: ============================================================
2022-05-12 00:02:21,373: time cost, forward:0.17181419991465527, backward:0.10487483381926956, data cost:0.19025775798813016 
2022-05-12 00:02:21,373: ============================================================
2022-05-12 00:02:21,373: Epoch 34/38 Batch 5200/7662 eta: 4:17:08.906700	Training Loss 0.0706 (0.0694)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.988)	
2022-05-12 00:02:21,373: ============================================================
2022-05-12 00:03:07,885: time cost, forward:0.17178503682780297, backward:0.10486936996648571, data cost:0.19025336150561534 
2022-05-12 00:03:07,886: ============================================================
2022-05-12 00:03:07,886: Epoch 34/38 Batch 5300/7662 eta: 4:15:54.437994	Training Loss 0.0729 (0.0694)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.989)	
2022-05-12 00:03:07,886: ============================================================
2022-05-12 00:03:54,393: time cost, forward:0.17176108290518097, backward:0.1048628868361627, data cost:0.19024523423101797 
2022-05-12 00:03:54,393: ============================================================
2022-05-12 00:03:54,393: Epoch 34/38 Batch 5400/7662 eta: 4:15:05.979963	Training Loss 0.0642 (0.0694)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.988)	
2022-05-12 00:03:54,393: ============================================================
2022-05-12 00:04:40,922: time cost, forward:0.17174245106304617, backward:0.10485737491551475, data cost:0.19023646240040137 
2022-05-12 00:04:40,922: ============================================================
2022-05-12 00:04:40,922: Epoch 34/38 Batch 5500/7662 eta: 4:14:26.640922	Training Loss 0.0684 (0.0694)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.988)	
2022-05-12 00:04:40,922: ============================================================
2022-05-12 00:05:27,452: time cost, forward:0.17172671850503907, backward:0.10485200052453825, data cost:0.1902259629333545 
2022-05-12 00:05:27,453: ============================================================
2022-05-12 00:05:27,453: Epoch 34/38 Batch 5600/7662 eta: 4:13:40.572025	Training Loss 0.0701 (0.0694)	Training Prec@1 99.805 (99.969)	Training Prec@5 99.805 (99.988)	
2022-05-12 00:05:27,453: ============================================================
2022-05-12 00:06:14,016: time cost, forward:0.1717145010387088, backward:0.10484755509860642, data cost:0.1902177686920541 
2022-05-12 00:06:14,017: ============================================================
2022-05-12 00:06:14,017: Epoch 34/38 Batch 5700/7662 eta: 4:13:04.976286	Training Loss 0.0695 (0.0694)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.988)	
2022-05-12 00:06:14,017: ============================================================
2022-05-12 00:07:00,568: time cost, forward:0.17170298520933658, backward:0.10484228875847146, data cost:0.19020871915453816 
2022-05-12 00:07:00,568: ============================================================
2022-05-12 00:07:00,568: Epoch 34/38 Batch 5800/7662 eta: 4:12:14.278742	Training Loss 0.0683 (0.0694)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.989)	
2022-05-12 00:07:00,568: ============================================================
2022-05-12 00:07:47,124: time cost, forward:0.17169433586636648, backward:0.10483883279605445, data cost:0.19019676855326223 
2022-05-12 00:07:47,124: ============================================================
2022-05-12 00:07:47,124: Epoch 34/38 Batch 5900/7662 eta: 4:11:29.431992	Training Loss 0.0714 (0.0695)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.989)	
2022-05-12 00:07:47,125: ============================================================
2022-05-12 00:08:33,712: time cost, forward:0.17169035738916233, backward:0.10483388082844791, data cost:0.19018744555964712 
2022-05-12 00:08:33,712: ============================================================
2022-05-12 00:08:33,712: Epoch 34/38 Batch 6000/7662 eta: 4:10:52.927368	Training Loss 0.0697 (0.0695)	Training Prec@1 99.805 (99.969)	Training Prec@5 99.805 (99.989)	
2022-05-12 00:08:33,712: ============================================================
2022-05-12 00:09:20,349: time cost, forward:0.17168983628973059, backward:0.10482915598244956, data cost:0.1901831596009867 
2022-05-12 00:09:20,349: ============================================================
2022-05-12 00:09:20,349: Epoch 34/38 Batch 6100/7662 eta: 4:10:22.242868	Training Loss 0.0728 (0.0695)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.988)	
2022-05-12 00:09:20,349: ============================================================
2022-05-12 00:10:06,938: time cost, forward:0.1716878727994286, backward:0.10482410666134535, data cost:0.19017334768206368 
2022-05-12 00:10:06,938: ============================================================
2022-05-12 00:10:06,938: Epoch 34/38 Batch 6200/7662 eta: 4:09:20.211318	Training Loss 0.0721 (0.0695)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.988)	
2022-05-12 00:10:06,938: ============================================================
2022-05-12 00:10:53,545: time cost, forward:0.17168628558182947, backward:0.10482008640000434, data cost:0.19016530025874004 
2022-05-12 00:10:53,545: ============================================================
2022-05-12 00:10:53,545: Epoch 34/38 Batch 6300/7662 eta: 4:08:39.321472	Training Loss 0.0741 (0.0695)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.989)	
2022-05-12 00:10:53,545: ============================================================
2022-05-12 00:11:40,207: time cost, forward:0.17168770135985928, backward:0.10481619276019033, data cost:0.1901629345177449 
2022-05-12 00:11:40,207: ============================================================
2022-05-12 00:11:40,207: Epoch 34/38 Batch 6400/7662 eta: 4:08:10.291324	Training Loss 0.0681 (0.0695)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.989)	
2022-05-12 00:11:40,207: ============================================================
2022-05-12 00:12:26,871: time cost, forward:0.17168603836343663, backward:0.10481218874206871, data cost:0.1901606347564918 
2022-05-12 00:12:26,872: ============================================================
2022-05-12 00:12:26,872: Epoch 34/38 Batch 6500/7662 eta: 4:07:24.568098	Training Loss 0.0733 (0.0695)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.989)	
2022-05-12 00:12:26,872: ============================================================
2022-05-12 00:13:13,593: time cost, forward:0.1716877397831181, backward:0.10480873374112322, data cost:0.1901671893308697 
2022-05-12 00:13:13,593: ============================================================
2022-05-12 00:13:13,593: Epoch 34/38 Batch 6600/7662 eta: 4:06:55.837602	Training Loss 0.0727 (0.0696)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.989)	
2022-05-12 00:13:13,593: ============================================================
2022-05-12 00:14:00,309: time cost, forward:0.17168984030196696, backward:0.10480412288750618, data cost:0.1901732794401058 
2022-05-12 00:14:00,309: ============================================================
2022-05-12 00:14:00,309: Epoch 34/38 Batch 6700/7662 eta: 4:06:07.349942	Training Loss 0.0684 (0.0696)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.989)	
2022-05-12 00:14:00,309: ============================================================
2022-05-12 00:14:46,990: time cost, forward:0.17168997981860754, backward:0.1048002987157634, data cost:0.1901733789010545 
2022-05-12 00:14:46,990: ============================================================
2022-05-12 00:14:46,990: Epoch 34/38 Batch 6800/7662 eta: 4:05:09.733826	Training Loss 0.0675 (0.0696)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.989)	
2022-05-12 00:14:46,991: ============================================================
2022-05-12 00:15:33,683: time cost, forward:0.1716922164775441, backward:0.10479598070231187, data cost:0.19017557079056965 
2022-05-12 00:15:33,683: ============================================================
2022-05-12 00:15:33,683: Epoch 34/38 Batch 6900/7662 eta: 4:04:26.706426	Training Loss 0.0715 (0.0696)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.989)	
2022-05-12 00:15:33,683: ============================================================
2022-05-12 00:16:20,378: time cost, forward:0.17169351416973577, backward:0.10479225562562056, data cost:0.19017859839902534 
2022-05-12 00:16:20,378: ============================================================
2022-05-12 00:16:20,378: Epoch 34/38 Batch 7000/7662 eta: 4:03:40.583789	Training Loss 0.0727 (0.0696)	Training Prec@1 99.805 (99.970)	Training Prec@5 100.000 (99.989)	
2022-05-12 00:16:20,378: ============================================================
2022-05-12 00:17:07,077: time cost, forward:0.17169454047706434, backward:0.10478768339961797, data cost:0.19018331660840154 
2022-05-12 00:17:07,078: ============================================================
2022-05-12 00:17:07,078: Epoch 34/38 Batch 7100/7662 eta: 4:02:55.432614	Training Loss 0.0665 (0.0696)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.989)	
2022-05-12 00:17:07,078: ============================================================
2022-05-12 00:17:53,728: time cost, forward:0.17169597957312754, backward:0.10478425969811243, data cost:0.19017975485015204 
2022-05-12 00:17:53,729: ============================================================
2022-05-12 00:17:53,729: Epoch 34/38 Batch 7200/7662 eta: 4:01:53.608045	Training Loss 0.0714 (0.0696)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.989)	
2022-05-12 00:17:53,729: ============================================================
2022-05-12 00:18:40,406: time cost, forward:0.1716997514670639, backward:0.10478092255796827, data cost:0.19017747572504146 
2022-05-12 00:18:40,406: ============================================================
2022-05-12 00:18:40,406: Epoch 34/38 Batch 7300/7662 eta: 4:01:15.199601	Training Loss 0.0708 (0.0697)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.988)	
2022-05-12 00:18:40,407: ============================================================
2022-05-12 00:19:27,124: time cost, forward:0.17170505350321463, backward:0.1047777634308876, data cost:0.1901789731408377 
2022-05-12 00:19:27,124: ============================================================
2022-05-12 00:19:27,124: Epoch 34/38 Batch 7400/7662 eta: 4:00:40.938317	Training Loss 0.0730 (0.0697)	Training Prec@1 99.805 (99.969)	Training Prec@5 100.000 (99.988)	
2022-05-12 00:19:27,124: ============================================================
2022-05-12 00:20:13,829: time cost, forward:0.1717102904052063, backward:0.10477471777654868, data cost:0.1901787415013693 
2022-05-12 00:20:13,830: ============================================================
2022-05-12 00:20:13,830: Epoch 34/38 Batch 7500/7662 eta: 3:59:50.423931	Training Loss 0.0694 (0.0697)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.988)	
2022-05-12 00:20:13,830: ============================================================
2022-05-12 00:21:00,525: time cost, forward:0.17171478029896922, backward:0.10477128620602015, data cost:0.19017817441029428 
2022-05-12 00:21:00,525: ============================================================
2022-05-12 00:21:00,525: Epoch 34/38 Batch 7600/7662 eta: 3:59:00.649628	Training Loss 0.0740 (0.0697)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.988)	
2022-05-12 00:21:00,525: ============================================================
2022-05-12 00:21:31,563: Epoch: 34/38 eta: 3:58:31.231474	Training Loss 0.0761 (0.0697)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.988)
2022-05-12 00:21:31,563: ============================================================
2022-05-12 00:21:31,604: Save Checkpoint...
2022-05-12 00:21:31,604: ============================================================
2022-05-12 00:21:33,733: Save done!
2022-05-12 00:21:33,733: ============================================================
2022-05-12 00:22:22,575: time cost, forward:0.18816791399560792, backward:0.10575615275989879, data cost:0.197214080829813 
2022-05-12 00:22:22,576: ============================================================
2022-05-12 00:22:22,576: Epoch 35/38 Batch 100/7662 eta: 4:08:40.113219	Training Loss 0.0638 (0.0680)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.986)	
2022-05-12 00:22:22,576: ============================================================
2022-05-12 00:23:09,500: time cost, forward:0.1809546731824252, backward:0.10568248926095627, data cost:0.19336606030488135 
2022-05-12 00:23:09,500: ============================================================
2022-05-12 00:23:09,501: Epoch 35/38 Batch 200/7662 eta: 3:58:08.103289	Training Loss 0.0663 (0.0682)	Training Prec@1 100.000 (99.968)	Training Prec@5 100.000 (99.982)	
2022-05-12 00:23:09,501: ============================================================
2022-05-12 00:23:56,130: time cost, forward:0.177892525459213, backward:0.10529803990520363, data cost:0.1921435439068338 
2022-05-12 00:23:56,131: ============================================================
2022-05-12 00:23:56,131: Epoch 35/38 Batch 300/7662 eta: 3:55:51.831570	Training Loss 0.0678 (0.0682)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.985)	
2022-05-12 00:23:56,131: ============================================================
2022-05-12 00:24:42,815: time cost, forward:0.1764098486505953, backward:0.10510866803334172, data cost:0.19161990172880933 
2022-05-12 00:24:42,815: ============================================================
2022-05-12 00:24:42,815: Epoch 35/38 Batch 400/7662 eta: 3:55:21.566921	Training Loss 0.0673 (0.0683)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.987)	
2022-05-12 00:24:42,815: ============================================================
2022-05-12 00:25:29,476: time cost, forward:0.1754964324897659, backward:0.10499329079606967, data cost:0.19128741386658205 
2022-05-12 00:25:29,477: ============================================================
2022-05-12 00:25:29,477: Epoch 35/38 Batch 500/7662 eta: 3:54:27.992376	Training Loss 0.0621 (0.0683)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.988)	
2022-05-12 00:25:29,477: ============================================================
2022-05-12 00:26:16,154: time cost, forward:0.1749125000630476, backward:0.10491838120856946, data cost:0.19106382002217542 
2022-05-12 00:26:16,154: ============================================================
2022-05-12 00:26:16,154: Epoch 35/38 Batch 600/7662 eta: 3:53:46.038658	Training Loss 0.0640 (0.0684)	Training Prec@1 100.000 (99.971)	Training Prec@5 100.000 (99.987)	
2022-05-12 00:26:16,154: ============================================================
2022-05-12 00:27:02,826: time cost, forward:0.174494675130121, backward:0.10485976960014376, data cost:0.19090722968138338 
2022-05-12 00:27:02,826: ============================================================
2022-05-12 00:27:02,826: Epoch 35/38 Batch 700/7662 eta: 3:52:57.818395	Training Loss 0.0713 (0.0684)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.987)	
2022-05-12 00:27:02,826: ============================================================
2022-05-12 00:27:49,463: time cost, forward:0.17417825178449534, backward:0.10481975314315777, data cost:0.19074262755087232 
2022-05-12 00:27:49,463: ============================================================
2022-05-12 00:27:49,463: Epoch 35/38 Batch 800/7662 eta: 3:52:00.641007	Training Loss 0.0750 (0.0684)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.987)	
2022-05-12 00:27:49,463: ============================================================
2022-05-12 00:28:36,094: time cost, forward:0.17393283849298224, backward:0.10478336209052132, data cost:0.19061363578770926 
2022-05-12 00:28:36,095: ============================================================
2022-05-12 00:28:36,095: Epoch 35/38 Batch 900/7662 eta: 3:51:12.459692	Training Loss 0.0665 (0.0684)	Training Prec@1 100.000 (99.971)	Training Prec@5 100.000 (99.987)	
2022-05-12 00:28:36,095: ============================================================
2022-05-12 00:29:22,741: time cost, forward:0.17374232151844837, backward:0.10475888767757931, data cost:0.19051606733877738 
2022-05-12 00:29:22,741: ============================================================
2022-05-12 00:29:22,741: Epoch 35/38 Batch 1000/7662 eta: 3:50:30.209861	Training Loss 0.0680 (0.0684)	Training Prec@1 100.000 (99.971)	Training Prec@5 100.000 (99.988)	
2022-05-12 00:29:22,741: ============================================================
2022-05-12 00:30:09,392: time cost, forward:0.1735872894769587, backward:0.10473786558857606, data cost:0.19044110772824482 
2022-05-12 00:30:09,392: ============================================================
2022-05-12 00:30:09,393: Epoch 35/38 Batch 1100/7662 eta: 3:49:45.037711	Training Loss 0.0650 (0.0684)	Training Prec@1 100.000 (99.971)	Training Prec@5 100.000 (99.988)	
2022-05-12 00:30:09,393: ============================================================
2022-05-12 00:30:56,034: time cost, forward:0.17345896196723282, backward:0.10471896115097033, data cost:0.19037169372170443 
2022-05-12 00:30:56,034: ============================================================
2022-05-12 00:30:56,034: Epoch 35/38 Batch 1200/7662 eta: 3:48:55.548294	Training Loss 0.0678 (0.0685)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.988)	
2022-05-12 00:30:56,035: ============================================================
2022-05-12 00:31:42,714: time cost, forward:0.17333935608397638, backward:0.10469950117268316, data cost:0.19034783100512873 
2022-05-12 00:31:42,715: ============================================================
2022-05-12 00:31:42,715: Epoch 35/38 Batch 1300/7662 eta: 3:48:20.224547	Training Loss 0.0663 (0.0685)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.988)	
2022-05-12 00:31:42,715: ============================================================
2022-05-12 00:32:29,367: time cost, forward:0.17324111783734555, backward:0.10468623142228797, data cost:0.1903081361185746 
2022-05-12 00:32:29,367: ============================================================
2022-05-12 00:32:29,368: Epoch 35/38 Batch 1400/7662 eta: 3:47:25.470523	Training Loss 0.0692 (0.0685)	Training Prec@1 99.805 (99.971)	Training Prec@5 100.000 (99.988)	
2022-05-12 00:32:29,368: ============================================================
2022-05-12 00:33:16,050: time cost, forward:0.17316762235182137, backward:0.10467748454286704, data cost:0.19027102367332413 
2022-05-12 00:33:16,050: ============================================================
2022-05-12 00:33:16,050: Epoch 35/38 Batch 1500/7662 eta: 3:46:47.572446	Training Loss 0.0653 (0.0685)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.989)	
2022-05-12 00:33:16,051: ============================================================
2022-05-12 00:34:02,752: time cost, forward:0.17309730033564374, backward:0.10466437670795377, data cost:0.1902690325922486 
2022-05-12 00:34:02,752: ============================================================
2022-05-12 00:34:02,752: Epoch 35/38 Batch 1600/7662 eta: 3:46:06.474964	Training Loss 0.0744 (0.0685)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.989)	
2022-05-12 00:34:02,753: ============================================================
2022-05-12 00:34:49,443: time cost, forward:0.1730372119890093, backward:0.10465359772002437, data cost:0.19025817038102175 
2022-05-12 00:34:49,444: ============================================================
2022-05-12 00:34:49,444: Epoch 35/38 Batch 1700/7662 eta: 3:45:16.664205	Training Loss 0.0702 (0.0685)	Training Prec@1 100.000 (99.971)	Training Prec@5 100.000 (99.988)	
2022-05-12 00:34:49,444: ============================================================
2022-05-12 00:35:36,072: time cost, forward:0.17297101564179398, backward:0.10464268502028139, data cost:0.19022855021809126 
2022-05-12 00:35:36,073: ============================================================
2022-05-12 00:35:36,073: Epoch 35/38 Batch 1800/7662 eta: 3:44:12.063405	Training Loss 0.0684 (0.0685)	Training Prec@1 99.805 (99.972)	Training Prec@5 99.805 (99.988)	
2022-05-12 00:35:36,073: ============================================================
2022-05-12 00:36:22,791: time cost, forward:0.17292470201308505, backward:0.10464051423919019, data cost:0.19022838375077492 
2022-05-12 00:36:22,791: ============================================================
2022-05-12 00:36:22,791: Epoch 35/38 Batch 1900/7662 eta: 3:43:51.042246	Training Loss 0.0692 (0.0685)	Training Prec@1 99.805 (99.972)	Training Prec@5 99.805 (99.988)	
2022-05-12 00:36:22,791: ============================================================
2022-05-12 00:37:09,468: time cost, forward:0.17288417777996054, backward:0.10463510661676205, data cost:0.19020994440682712 
2022-05-12 00:37:09,469: ============================================================
2022-05-12 00:37:09,469: Epoch 35/38 Batch 2000/7662 eta: 3:42:52.690392	Training Loss 0.0709 (0.0685)	Training Prec@1 99.805 (99.972)	Training Prec@5 100.000 (99.988)	
2022-05-12 00:37:09,469: ============================================================
2022-05-12 00:37:56,160: time cost, forward:0.17284524707694232, backward:0.10463004943698631, data cost:0.19020333546806142 
2022-05-12 00:37:56,160: ============================================================
2022-05-12 00:37:56,161: Epoch 35/38 Batch 2100/7662 eta: 3:42:09.962514	Training Loss 0.0735 (0.0686)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.988)	
2022-05-12 00:37:56,161: ============================================================
2022-05-12 00:38:42,827: time cost, forward:0.17281331567126765, backward:0.10462444356594805, data cost:0.19018280500712964 
2022-05-12 00:38:42,827: ============================================================
2022-05-12 00:38:42,828: Epoch 35/38 Batch 2200/7662 eta: 3:41:16.297559	Training Loss 0.0669 (0.0686)	Training Prec@1 100.000 (99.971)	Training Prec@5 100.000 (99.988)	
2022-05-12 00:38:42,828: ============================================================
2022-05-12 00:39:29,481: time cost, forward:0.17277694899603407, backward:0.10461806276146357, data cost:0.1901624567771072 
2022-05-12 00:39:29,481: ============================================================
2022-05-12 00:39:29,482: Epoch 35/38 Batch 2300/7662 eta: 3:40:25.934835	Training Loss 0.0657 (0.0686)	Training Prec@1 100.000 (99.971)	Training Prec@5 100.000 (99.989)	
2022-05-12 00:39:29,482: ============================================================
2022-05-12 00:40:16,135: time cost, forward:0.17274736910872085, backward:0.10461266013968731, data cost:0.19014407565763664 
2022-05-12 00:40:16,135: ============================================================
2022-05-12 00:40:16,135: Epoch 35/38 Batch 2400/7662 eta: 3:39:39.207786	Training Loss 0.0648 (0.0686)	Training Prec@1 100.000 (99.971)	Training Prec@5 100.000 (99.989)	
2022-05-12 00:40:16,135: ============================================================
2022-05-12 00:41:02,765: time cost, forward:0.17271464574141424, backward:0.10460808821896068, data cost:0.19012344374853213 
2022-05-12 00:41:02,766: ============================================================
2022-05-12 00:41:02,766: Epoch 35/38 Batch 2500/7662 eta: 3:38:46.000273	Training Loss 0.0671 (0.0686)	Training Prec@1 99.805 (99.971)	Training Prec@5 100.000 (99.988)	
2022-05-12 00:41:02,766: ============================================================
2022-05-12 00:41:49,434: time cost, forward:0.1726914665798996, backward:0.10460467180778266, data cost:0.19011090066901717 
2022-05-12 00:41:49,434: ============================================================
2022-05-12 00:41:49,434: Epoch 35/38 Batch 2600/7662 eta: 3:38:10.112217	Training Loss 0.0708 (0.0686)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.988)	
2022-05-12 00:41:49,434: ============================================================
2022-05-12 00:42:36,129: time cost, forward:0.17267088821173687, backward:0.10460217381548378, data cost:0.19010722385419215 
2022-05-12 00:42:36,129: ============================================================
2022-05-12 00:42:36,129: Epoch 35/38 Batch 2700/7662 eta: 3:37:30.754479	Training Loss 0.0679 (0.0686)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.988)	
2022-05-12 00:42:36,129: ============================================================
2022-05-12 00:43:22,794: time cost, forward:0.17264934248820335, backward:0.10459796255424475, data cost:0.19009771897308142 
2022-05-12 00:43:22,794: ============================================================
2022-05-12 00:43:22,794: Epoch 35/38 Batch 2800/7662 eta: 3:36:35.718908	Training Loss 0.0706 (0.0687)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.988)	
2022-05-12 00:43:22,794: ============================================================
2022-05-12 00:44:09,436: time cost, forward:0.17262860181702544, backward:0.10459270128590274, data cost:0.1900832450731165 
2022-05-12 00:44:09,437: ============================================================
2022-05-12 00:44:09,437: Epoch 35/38 Batch 2900/7662 eta: 3:35:42.906628	Training Loss 0.0714 (0.0687)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.988)	
2022-05-12 00:44:09,437: ============================================================
2022-05-12 00:44:56,103: time cost, forward:0.1726111484869753, backward:0.10458834801725087, data cost:0.1900753717336626 
2022-05-12 00:44:56,104: ============================================================
2022-05-12 00:44:56,104: Epoch 35/38 Batch 3000/7662 eta: 3:35:02.887256	Training Loss 0.0723 (0.0687)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.988)	
2022-05-12 00:44:56,104: ============================================================
2022-05-12 00:45:42,803: time cost, forward:0.17260588388667641, backward:0.10458501433895341, data cost:0.19006632104463136 
2022-05-12 00:45:42,803: ============================================================
2022-05-12 00:45:42,804: Epoch 35/38 Batch 3100/7662 eta: 3:34:25.313259	Training Loss 0.0693 (0.0687)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.988)	
2022-05-12 00:45:42,804: ============================================================
2022-05-12 00:46:29,473: time cost, forward:0.1725918055698625, backward:0.1045825016353234, data cost:0.19005804994993936 
2022-05-12 00:46:29,474: ============================================================
2022-05-12 00:46:29,474: Epoch 35/38 Batch 3200/7662 eta: 3:33:30.565988	Training Loss 0.0688 (0.0687)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.988)	
2022-05-12 00:46:29,474: ============================================================
2022-05-12 00:47:16,190: time cost, forward:0.17258238185351818, backward:0.10457946481615098, data cost:0.19006034734575053 
2022-05-12 00:47:16,190: ============================================================
2022-05-12 00:47:16,190: Epoch 35/38 Batch 3300/7662 eta: 3:32:56.449367	Training Loss 0.0652 (0.0687)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.988)	
2022-05-12 00:47:16,190: ============================================================
2022-05-12 00:48:02,931: time cost, forward:0.17259627063332603, backward:0.10457490254374384, data cost:0.19004932885031098 
2022-05-12 00:48:02,931: ============================================================
2022-05-12 00:48:02,932: Epoch 35/38 Batch 3400/7662 eta: 3:32:16.538230	Training Loss 0.0704 (0.0687)	Training Prec@1 99.609 (99.970)	Training Prec@5 100.000 (99.988)	
2022-05-12 00:48:02,932: ============================================================
2022-05-12 00:48:49,645: time cost, forward:0.17259948844397263, backward:0.10457225348752511, data cost:0.1900392397024455 
2022-05-12 00:48:49,645: ============================================================
2022-05-12 00:48:49,645: Epoch 35/38 Batch 3500/7662 eta: 3:31:22.246244	Training Loss 0.0677 (0.0688)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.988)	
2022-05-12 00:48:49,645: ============================================================
2022-05-12 00:49:36,346: time cost, forward:0.1725879813870247, backward:0.10457001404154131, data cost:0.1900407196780515 
2022-05-12 00:49:36,347: ============================================================
2022-05-12 00:49:36,347: Epoch 35/38 Batch 3600/7662 eta: 3:30:32.338634	Training Loss 0.0698 (0.0688)	Training Prec@1 99.805 (99.970)	Training Prec@5 99.805 (99.988)	
2022-05-12 00:49:36,347: ============================================================
2022-05-12 00:50:23,101: time cost, forward:0.1725769909242257, backward:0.10456936525054544, data cost:0.19004746384477578 
2022-05-12 00:50:23,101: ============================================================
2022-05-12 00:50:23,101: Epoch 35/38 Batch 3700/7662 eta: 3:29:59.884445	Training Loss 0.0678 (0.0688)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.988)	
2022-05-12 00:50:23,101: ============================================================
2022-05-12 00:51:09,782: time cost, forward:0.17256535671672937, backward:0.10456728125660317, data cost:0.19004503360827618 
2022-05-12 00:51:09,782: ============================================================
2022-05-12 00:51:09,782: Epoch 35/38 Batch 3800/7662 eta: 3:28:53.353203	Training Loss 0.0724 (0.0688)	Training Prec@1 99.805 (99.970)	Training Prec@5 99.805 (99.988)	
2022-05-12 00:51:09,782: ============================================================
2022-05-12 00:51:56,512: time cost, forward:0.17256018448316246, backward:0.10456578197709167, data cost:0.19004611505487387 
2022-05-12 00:51:56,512: ============================================================
2022-05-12 00:51:56,512: Epoch 35/38 Batch 3900/7662 eta: 3:28:19.874796	Training Loss 0.0663 (0.0688)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.988)	
2022-05-12 00:51:56,513: ============================================================
2022-05-12 00:52:43,299: time cost, forward:0.17255337168556895, backward:0.10456550714521892, data cost:0.1900616727134054 
2022-05-12 00:52:43,299: ============================================================
2022-05-12 00:52:43,299: Epoch 35/38 Batch 4000/7662 eta: 3:27:48.254208	Training Loss 0.0693 (0.0688)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.988)	
2022-05-12 00:52:43,300: ============================================================
2022-05-12 00:53:30,007: time cost, forward:0.1725471088961294, backward:0.10456502178757038, data cost:0.19006023153382762 
2022-05-12 00:53:30,008: ============================================================
2022-05-12 00:53:30,008: Epoch 35/38 Batch 4100/7662 eta: 3:26:40.642806	Training Loss 0.0716 (0.0688)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.988)	
2022-05-12 00:53:30,008: ============================================================
2022-05-12 00:54:16,702: time cost, forward:0.17253457270624753, backward:0.10456393945498192, data cost:0.19006279225177952 
2022-05-12 00:54:16,703: ============================================================
2022-05-12 00:54:16,703: Epoch 35/38 Batch 4200/7662 eta: 3:25:50.309454	Training Loss 0.0659 (0.0688)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.988)	
2022-05-12 00:54:16,703: ============================================================
2022-05-12 00:55:03,468: time cost, forward:0.17253118754819705, backward:0.1045637755761121, data cost:0.19007012605057064 
2022-05-12 00:55:03,469: ============================================================
2022-05-12 00:55:03,469: Epoch 35/38 Batch 4300/7662 eta: 3:25:22.379191	Training Loss 0.0717 (0.0689)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.988)	
2022-05-12 00:55:03,469: ============================================================
2022-05-12 00:55:50,201: time cost, forward:0.1725273147499759, backward:0.10456222917687272, data cost:0.19007355138696738 
2022-05-12 00:55:50,201: ============================================================
2022-05-12 00:55:50,202: Epoch 35/38 Batch 4400/7662 eta: 3:24:26.901498	Training Loss 0.0700 (0.0689)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.988)	
2022-05-12 00:55:50,202: ============================================================
2022-05-12 00:56:36,966: time cost, forward:0.17251732667887787, backward:0.10456053398269684, data cost:0.19009043572080958 
2022-05-12 00:56:36,967: ============================================================
2022-05-12 00:56:36,967: Epoch 35/38 Batch 4500/7662 eta: 3:23:48.684428	Training Loss 0.0641 (0.0689)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.988)	
2022-05-12 00:56:36,967: ============================================================
2022-05-12 00:57:23,753: time cost, forward:0.17251079744503636, backward:0.10455993414702792, data cost:0.19010752707778125 
2022-05-12 00:57:23,753: ============================================================
2022-05-12 00:57:23,753: Epoch 35/38 Batch 4600/7662 eta: 3:23:07.323587	Training Loss 0.0643 (0.0689)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.988)	
2022-05-12 00:57:23,753: ============================================================
2022-05-12 00:58:10,522: time cost, forward:0.1725039853012595, backward:0.1045587338343862, data cost:0.19011862791962106 
2022-05-12 00:58:10,523: ============================================================
2022-05-12 00:58:10,523: Epoch 35/38 Batch 4700/7662 eta: 3:22:16.287346	Training Loss 0.0605 (0.0689)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.988)	
2022-05-12 00:58:10,523: ============================================================
2022-05-12 00:58:57,319: time cost, forward:0.17249713119901103, backward:0.10455822790630362, data cost:0.19013735422816816 
2022-05-12 00:58:57,319: ============================================================
2022-05-12 00:58:57,320: Epoch 35/38 Batch 4800/7662 eta: 3:21:36.462405	Training Loss 0.0694 (0.0689)	Training Prec@1 99.805 (99.970)	Training Prec@5 100.000 (99.988)	
2022-05-12 00:58:57,320: ============================================================
2022-05-12 00:59:44,100: time cost, forward:0.17249537614151564, backward:0.10455606460181954, data cost:0.1901464312386576 
2022-05-12 00:59:44,101: ============================================================
2022-05-12 00:59:44,101: Epoch 35/38 Batch 4900/7662 eta: 3:20:45.681778	Training Loss 0.0695 (0.0689)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.988)	
2022-05-12 00:59:44,101: ============================================================
2022-05-12 01:00:30,840: time cost, forward:0.17248587098973445, backward:0.10455402466601718, data cost:0.19015447185811674 
2022-05-12 01:00:30,841: ============================================================
2022-05-12 01:00:30,841: Epoch 35/38 Batch 5000/7662 eta: 3:19:48.333797	Training Loss 0.0745 (0.0689)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.988)	
2022-05-12 01:00:30,841: ============================================================
2022-05-12 01:01:17,584: time cost, forward:0.17248011486369924, backward:0.10455274703479743, data cost:0.19016194689575422 
2022-05-12 01:01:17,585: ============================================================
2022-05-12 01:01:17,585: Epoch 35/38 Batch 5100/7662 eta: 3:19:02.612001	Training Loss 0.0681 (0.0689)	Training Prec@1 99.805 (99.970)	Training Prec@5 100.000 (99.988)	
2022-05-12 01:01:17,585: ============================================================
2022-05-12 01:02:04,350: time cost, forward:0.17247201530124895, backward:0.10455196356401922, data cost:0.19017112949853404 
2022-05-12 01:02:04,350: ============================================================
2022-05-12 01:02:04,350: Epoch 35/38 Batch 5200/7662 eta: 3:18:21.364430	Training Loss 0.0691 (0.0690)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.988)	
2022-05-12 01:02:04,350: ============================================================
2022-05-12 01:02:51,083: time cost, forward:0.1724668989813222, backward:0.10455192019521437, data cost:0.19017298038466107 
2022-05-12 01:02:51,083: ============================================================
2022-05-12 01:02:51,083: Epoch 35/38 Batch 5300/7662 eta: 3:17:26.349208	Training Loss 0.0718 (0.0690)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.988)	
2022-05-12 01:02:51,083: ============================================================
2022-05-12 01:03:37,893: time cost, forward:0.17246159669932976, backward:0.10455192780357794, data cost:0.19018596166768634 
2022-05-12 01:03:37,894: ============================================================
2022-05-12 01:03:37,894: Epoch 35/38 Batch 5400/7662 eta: 3:16:59.207502	Training Loss 0.0680 (0.0690)	Training Prec@1 99.805 (99.969)	Training Prec@5 100.000 (99.988)	
2022-05-12 01:03:37,894: ============================================================
2022-05-12 01:04:24,722: time cost, forward:0.1724559466044108, backward:0.10455003355303381, data cost:0.19020673803338833 
2022-05-12 01:04:24,722: ============================================================
2022-05-12 01:04:24,722: Epoch 35/38 Batch 5500/7662 eta: 3:16:16.874290	Training Loss 0.0692 (0.0690)	Training Prec@1 99.805 (99.969)	Training Prec@5 99.805 (99.988)	
2022-05-12 01:04:24,722: ============================================================
2022-05-12 01:05:11,505: time cost, forward:0.17245229364910558, backward:0.10454827854730844, data cost:0.19021654218451256 
2022-05-12 01:05:11,505: ============================================================
2022-05-12 01:05:11,505: Epoch 35/38 Batch 5600/7662 eta: 3:15:18.652586	Training Loss 0.0655 (0.0690)	Training Prec@1 99.805 (99.969)	Training Prec@5 99.805 (99.988)	
2022-05-12 01:05:11,505: ============================================================
2022-05-12 01:05:58,243: time cost, forward:0.17244369641879836, backward:0.10454654032607981, data cost:0.19022351935320223 
2022-05-12 01:05:58,243: ============================================================
2022-05-12 01:05:58,244: Epoch 35/38 Batch 5700/7662 eta: 3:14:20.788335	Training Loss 0.0636 (0.0690)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.988)	
2022-05-12 01:05:58,244: ============================================================
2022-05-12 01:06:44,960: time cost, forward:0.17243749253769172, backward:0.10454569732059506, data cost:0.19022540339808522 
2022-05-12 01:06:44,960: ============================================================
2022-05-12 01:06:44,960: Epoch 35/38 Batch 5800/7662 eta: 3:13:28.635764	Training Loss 0.0742 (0.0690)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.988)	
2022-05-12 01:06:44,960: ============================================================
2022-05-12 01:07:31,689: time cost, forward:0.1724335664327841, backward:0.10454435165826902, data cost:0.1902250969969715 
2022-05-12 01:07:31,690: ============================================================
2022-05-12 01:07:31,690: Epoch 35/38 Batch 5900/7662 eta: 3:12:45.034344	Training Loss 0.0704 (0.0690)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.988)	
2022-05-12 01:07:31,690: ============================================================
2022-05-12 01:08:18,488: time cost, forward:0.17243283521057984, backward:0.10454437748196324, data cost:0.1902271035234617 
2022-05-12 01:08:18,488: ============================================================
2022-05-12 01:08:18,489: Epoch 35/38 Batch 6000/7662 eta: 3:12:15.451078	Training Loss 0.0732 (0.0690)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.988)	
2022-05-12 01:08:18,489: ============================================================
2022-05-12 01:09:05,244: time cost, forward:0.1724274136195673, backward:0.10454352047819059, data cost:0.19023481445794108 
2022-05-12 01:09:05,245: ============================================================
2022-05-12 01:09:05,245: Epoch 35/38 Batch 6100/7662 eta: 3:11:18.186639	Training Loss 0.0665 (0.0690)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.988)	
2022-05-12 01:09:05,245: ============================================================
2022-05-12 01:09:52,020: time cost, forward:0.1724242400230756, backward:0.10454272962343425, data cost:0.19024119717129817 
2022-05-12 01:09:52,020: ============================================================
2022-05-12 01:09:52,020: Epoch 35/38 Batch 6200/7662 eta: 3:10:36.144050	Training Loss 0.0720 (0.0691)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.988)	
2022-05-12 01:09:52,020: ============================================================
2022-05-12 01:10:38,773: time cost, forward:0.17242064156557269, backward:0.10454279734115976, data cost:0.19024415038127448 
2022-05-12 01:10:38,773: ============================================================
2022-05-12 01:10:38,773: Epoch 35/38 Batch 6300/7662 eta: 3:09:43.931515	Training Loss 0.0679 (0.0691)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.988)	
2022-05-12 01:10:38,774: ============================================================
2022-05-12 01:11:25,589: time cost, forward:0.17242129442561024, backward:0.1045414881326944, data cost:0.19025293986002603 
2022-05-12 01:11:25,589: ============================================================
2022-05-12 01:11:25,589: Epoch 35/38 Batch 6400/7662 eta: 3:09:12.399002	Training Loss 0.0717 (0.0691)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.988)	
2022-05-12 01:11:25,590: ============================================================
2022-05-12 01:12:12,316: time cost, forward:0.17241364714732113, backward:0.10454077320037246, data cost:0.19025460296932561 
2022-05-12 01:12:12,316: ============================================================
2022-05-12 01:12:12,316: Epoch 35/38 Batch 6500/7662 eta: 3:08:04.044042	Training Loss 0.0687 (0.0691)	Training Prec@1 99.805 (99.969)	Training Prec@5 100.000 (99.988)	
2022-05-12 01:12:12,316: ============================================================
2022-05-12 01:12:59,094: time cost, forward:0.1724036194407808, backward:0.10454007361328661, data cost:0.19026342159438303 
2022-05-12 01:12:59,095: ============================================================
2022-05-12 01:12:59,095: Epoch 35/38 Batch 6600/7662 eta: 3:07:29.765498	Training Loss 0.0649 (0.0691)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.988)	
2022-05-12 01:12:59,095: ============================================================
2022-05-12 01:13:45,888: time cost, forward:0.17239746305013276, backward:0.10453958165416043, data cost:0.19027565710401156 
2022-05-12 01:13:45,889: ============================================================
2022-05-12 01:13:45,889: Epoch 35/38 Batch 6700/7662 eta: 3:06:46.740661	Training Loss 0.0675 (0.0691)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.988)	
2022-05-12 01:13:45,889: ============================================================
2022-05-12 01:14:32,595: time cost, forward:0.17239079680192435, backward:0.1045387730315812, data cost:0.19027591011141623 
2022-05-12 01:14:32,595: ============================================================
2022-05-12 01:14:32,596: Epoch 35/38 Batch 6800/7662 eta: 3:05:39.095346	Training Loss 0.0704 (0.0691)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.988)	
2022-05-12 01:14:32,596: ============================================================
2022-05-12 01:15:19,388: time cost, forward:0.17238805310970493, backward:0.10453818949914909, data cost:0.19028730903229588 
2022-05-12 01:15:19,388: ============================================================
2022-05-12 01:15:19,388: Epoch 35/38 Batch 6900/7662 eta: 3:05:12.773535	Training Loss 0.0729 (0.0691)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.988)	
2022-05-12 01:15:19,388: ============================================================
2022-05-12 01:16:06,205: time cost, forward:0.1723877900258901, backward:0.10453831187178875, data cost:0.19029583023486604 
2022-05-12 01:16:06,206: ============================================================
2022-05-12 01:16:06,206: Epoch 35/38 Batch 7000/7662 eta: 3:04:31.920050	Training Loss 0.0722 (0.0692)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.988)	
2022-05-12 01:16:06,206: ============================================================
2022-05-12 01:16:52,999: time cost, forward:0.17238896107032176, backward:0.1045372659412131, data cost:0.19030013593557368 
2022-05-12 01:16:53,000: ============================================================
2022-05-12 01:16:53,000: Epoch 35/38 Batch 7100/7662 eta: 3:03:39.464185	Training Loss 0.0684 (0.0692)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.988)	
2022-05-12 01:16:53,000: ============================================================
2022-05-12 01:17:39,779: time cost, forward:0.1723908660378385, backward:0.10453640714190474, data cost:0.190301372104427 
2022-05-12 01:17:39,779: ============================================================
2022-05-12 01:17:39,780: Epoch 35/38 Batch 7200/7662 eta: 3:02:49.399760	Training Loss 0.0691 (0.0692)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.988)	
2022-05-12 01:17:39,780: ============================================================
2022-05-12 01:18:26,577: time cost, forward:0.17239270871396684, backward:0.1045356151877666, data cost:0.19030683611268653 
2022-05-12 01:18:26,577: ============================================================
2022-05-12 01:18:26,577: Epoch 35/38 Batch 7300/7662 eta: 3:02:06.814774	Training Loss 0.0694 (0.0692)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.989)	
2022-05-12 01:18:26,577: ============================================================
2022-05-12 01:19:13,343: time cost, forward:0.17239206567747012, backward:0.10453526305739888, data cost:0.19030794805409956 
2022-05-12 01:19:13,344: ============================================================
2022-05-12 01:19:13,344: Epoch 35/38 Batch 7400/7662 eta: 3:01:12.709384	Training Loss 0.0762 (0.0692)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.989)	
2022-05-12 01:19:13,344: ============================================================
2022-05-12 01:20:00,094: time cost, forward:0.17239303054102487, backward:0.10453470835194205, data cost:0.1903074195598313 
2022-05-12 01:20:00,094: ============================================================
2022-05-12 01:20:00,094: Epoch 35/38 Batch 7500/7662 eta: 3:00:22.282950	Training Loss 0.0691 (0.0692)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.989)	
2022-05-12 01:20:00,094: ============================================================
2022-05-12 01:20:46,885: time cost, forward:0.17239844402148075, backward:0.1045343033152672, data cost:0.1903079012566953 
2022-05-12 01:20:46,886: ============================================================
2022-05-12 01:20:46,886: Epoch 35/38 Batch 7600/7662 eta: 2:59:45.002421	Training Loss 0.0670 (0.0692)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.989)	
2022-05-12 01:20:46,886: ============================================================
2022-05-12 01:21:17,887: Epoch: 35/38 eta: 2:59:15.523695	Training Loss 0.0711 (0.0692)	Training Prec@1 99.805 (99.970)	Training Prec@5 100.000 (99.989)
2022-05-12 01:21:17,887: ============================================================
2022-05-12 01:21:17,889: Save Checkpoint...
2022-05-12 01:21:17,901: ============================================================
2022-05-12 01:21:20,137: Save done!
2022-05-12 01:21:20,138: ============================================================
2022-05-12 01:22:10,893: time cost, forward:0.1857624270699241, backward:0.10427531810721966, data cost:0.22022580137156478 
2022-05-12 01:22:10,893: ============================================================
2022-05-12 01:22:10,893: Epoch 36/38 Batch 100/7662 eta: 3:13:31.038377	Training Loss 0.0678 (0.0682)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.986)	
2022-05-12 01:22:10,893: ============================================================
2022-05-12 01:22:57,539: time cost, forward:0.17887660846039277, backward:0.10442080330010035, data cost:0.20483593605271536 
2022-05-12 01:22:57,539: ============================================================
2022-05-12 01:22:57,539: Epoch 36/38 Batch 200/7662 eta: 2:57:09.167063	Training Loss 0.0694 (0.0680)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.984)	
2022-05-12 01:22:57,539: ============================================================
2022-05-12 01:23:44,209: time cost, forward:0.17652425319454743, backward:0.10452241403203345, data cost:0.19983690080036687 
2022-05-12 01:23:44,210: ============================================================
2022-05-12 01:23:44,210: Epoch 36/38 Batch 300/7662 eta: 2:56:28.199846	Training Loss 0.0694 (0.0680)	Training Prec@1 99.805 (99.972)	Training Prec@5 99.805 (99.986)	
2022-05-12 01:23:44,210: ============================================================
2022-05-12 01:24:30,863: time cost, forward:0.17528512663112247, backward:0.10451626419124746, data cost:0.1973927935263268 
2022-05-12 01:24:30,864: ============================================================
2022-05-12 01:24:30,864: Epoch 36/38 Batch 400/7662 eta: 2:55:37.710987	Training Loss 0.0744 (0.0680)	Training Prec@1 100.000 (99.971)	Training Prec@5 100.000 (99.986)	
2022-05-12 01:24:30,864: ============================================================
2022-05-12 01:25:17,531: time cost, forward:0.17461646104862313, backward:0.10451927261505432, data cost:0.19590026821067671 
2022-05-12 01:25:17,531: ============================================================
2022-05-12 01:25:17,531: Epoch 36/38 Batch 500/7662 eta: 2:54:54.071030	Training Loss 0.0677 (0.0680)	Training Prec@1 99.805 (99.971)	Training Prec@5 99.805 (99.987)	
2022-05-12 01:25:17,531: ============================================================
2022-05-12 01:26:04,203: time cost, forward:0.17416035790674275, backward:0.10452277791719007, data cost:0.19492301001572648 
2022-05-12 01:26:04,203: ============================================================
2022-05-12 01:26:04,203: Epoch 36/38 Batch 600/7662 eta: 2:54:08.517309	Training Loss 0.0677 (0.0680)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.987)	
2022-05-12 01:26:04,203: ============================================================
2022-05-12 01:26:50,858: time cost, forward:0.1738174094662646, backward:0.10451552898587076, data cost:0.19421315227284794 
2022-05-12 01:26:50,858: ============================================================
2022-05-12 01:26:50,858: Epoch 36/38 Batch 700/7662 eta: 2:53:18.033851	Training Loss 0.0685 (0.0681)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.988)	
2022-05-12 01:26:50,859: ============================================================
2022-05-12 01:27:37,473: time cost, forward:0.17356591051600603, backward:0.10451216811083434, data cost:0.19363707535257924 
2022-05-12 01:27:37,473: ============================================================
2022-05-12 01:27:37,474: Epoch 36/38 Batch 800/7662 eta: 2:52:22.488990	Training Loss 0.0653 (0.0681)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.988)	
2022-05-12 01:27:37,474: ============================================================
2022-05-12 01:28:24,117: time cost, forward:0.17337467752653976, backward:0.10451054626099923, data cost:0.19321444488075604 
2022-05-12 01:28:24,117: ============================================================
2022-05-12 01:28:24,118: Epoch 36/38 Batch 900/7662 eta: 2:51:42.271245	Training Loss 0.0691 (0.0680)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.988)	
2022-05-12 01:28:24,118: ============================================================
2022-05-12 01:29:10,755: time cost, forward:0.17322266209232914, backward:0.10450992068728886, data cost:0.19286884512151922 
2022-05-12 01:29:10,755: ============================================================
2022-05-12 01:29:10,755: Epoch 36/38 Batch 1000/7662 eta: 2:50:54.275150	Training Loss 0.0665 (0.0680)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.988)	
2022-05-12 01:29:10,756: ============================================================
2022-05-12 01:29:57,392: time cost, forward:0.17309866046992295, backward:0.10450986344994362, data cost:0.1925858759250936 
2022-05-12 01:29:57,392: ============================================================
2022-05-12 01:29:57,392: Epoch 36/38 Batch 1100/7662 eta: 2:50:07.410308	Training Loss 0.0672 (0.0681)	Training Prec@1 99.805 (99.974)	Training Prec@5 100.000 (99.989)	
2022-05-12 01:29:57,392: ============================================================
2022-05-12 01:30:44,077: time cost, forward:0.17300905199027042, backward:0.10450880263028689, data cost:0.19236747079138164 
2022-05-12 01:30:44,077: ============================================================
2022-05-12 01:30:44,077: Epoch 36/38 Batch 1200/7662 eta: 2:49:31.221304	Training Loss 0.0735 (0.0680)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.989)	
2022-05-12 01:30:44,077: ============================================================
2022-05-12 01:31:30,845: time cost, forward:0.17294034065880898, backward:0.10450381531542866, data cost:0.19224469564436397 
2022-05-12 01:31:30,845: ============================================================
2022-05-12 01:31:30,845: Epoch 36/38 Batch 1300/7662 eta: 2:49:02.609382	Training Loss 0.0674 (0.0680)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.989)	
2022-05-12 01:31:30,845: ============================================================
2022-05-12 01:32:17,510: time cost, forward:0.17287726552252944, backward:0.10449805576687118, data cost:0.1920799097902354 
2022-05-12 01:32:17,510: ============================================================
2022-05-12 01:32:17,510: Epoch 36/38 Batch 1400/7662 eta: 2:47:53.500509	Training Loss 0.0659 (0.0680)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.989)	
2022-05-12 01:32:17,510: ============================================================
2022-05-12 01:33:04,243: time cost, forward:0.17285151080817998, backward:0.10449804935239011, data cost:0.19194844279629616 
2022-05-12 01:33:04,243: ============================================================
2022-05-12 01:33:04,243: Epoch 36/38 Batch 1500/7662 eta: 2:47:21.609779	Training Loss 0.0669 (0.0680)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.989)	
2022-05-12 01:33:04,243: ============================================================
2022-05-12 01:33:51,034: time cost, forward:0.17281916694688826, backward:0.10449893329947199, data cost:0.19187875044502417 
2022-05-12 01:33:51,035: ============================================================
2022-05-12 01:33:51,035: Epoch 36/38 Batch 1600/7662 eta: 2:46:47.264522	Training Loss 0.0751 (0.0680)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.989)	
2022-05-12 01:33:51,035: ============================================================
2022-05-12 01:34:37,770: time cost, forward:0.17278353167394106, backward:0.10449996255579382, data cost:0.1917834162641933 
2022-05-12 01:34:37,770: ============================================================
2022-05-12 01:34:37,771: Epoch 36/38 Batch 1700/7662 eta: 2:45:48.669292	Training Loss 0.0680 (0.0681)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.989)	
2022-05-12 01:34:37,771: ============================================================
2022-05-12 01:35:24,528: time cost, forward:0.1727443789693632, backward:0.10450121069564099, data cost:0.19172391313655698 
2022-05-12 01:35:24,529: ============================================================
2022-05-12 01:35:24,529: Epoch 36/38 Batch 1800/7662 eta: 2:45:06.641836	Training Loss 0.0658 (0.0681)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.989)	
2022-05-12 01:35:24,529: ============================================================
2022-05-12 01:36:11,229: time cost, forward:0.1727098327614622, backward:0.10450147615727028, data cost:0.19164149543999245 
2022-05-12 01:36:11,230: ============================================================
2022-05-12 01:36:11,230: Epoch 36/38 Batch 1900/7662 eta: 2:44:07.843334	Training Loss 0.0689 (0.0681)	Training Prec@1 99.805 (99.972)	Training Prec@5 100.000 (99.989)	
2022-05-12 01:36:11,230: ============================================================
2022-05-12 01:36:57,902: time cost, forward:0.1726759505784768, backward:0.10449980926132012, data cost:0.19155867628123296 
2022-05-12 01:36:57,902: ============================================================
2022-05-12 01:36:57,902: Epoch 36/38 Batch 2000/7662 eta: 2:43:15.199234	Training Loss 0.0780 (0.0681)	Training Prec@1 99.805 (99.972)	Training Prec@5 100.000 (99.989)	
2022-05-12 01:36:57,903: ============================================================
2022-05-12 01:37:44,700: time cost, forward:0.1726657533259435, backward:0.10449770202291415, data cost:0.19151719948858123 
2022-05-12 01:37:44,700: ============================================================
2022-05-12 01:37:44,700: Epoch 36/38 Batch 2100/7662 eta: 2:42:54.587030	Training Loss 0.0738 (0.0681)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.989)	
2022-05-12 01:37:44,700: ============================================================
2022-05-12 01:38:31,469: time cost, forward:0.17263806229453024, backward:0.10449553750330018, data cost:0.19148513922749894 
2022-05-12 01:38:31,469: ============================================================
2022-05-12 01:38:31,470: Epoch 36/38 Batch 2200/7662 eta: 2:42:01.975969	Training Loss 0.0666 (0.0681)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.989)	
2022-05-12 01:38:31,470: ============================================================
2022-05-12 01:39:18,233: time cost, forward:0.1726143578956209, backward:0.10449576865283755, data cost:0.19145028992495675 
2022-05-12 01:39:18,233: ============================================================
2022-05-12 01:39:18,233: Epoch 36/38 Batch 2300/7662 eta: 2:41:13.998384	Training Loss 0.0757 (0.0681)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.989)	
2022-05-12 01:39:18,233: ============================================================
2022-05-12 01:40:05,045: time cost, forward:0.17259299243276643, backward:0.10449284571019149, data cost:0.1914360248928221 
2022-05-12 01:40:05,045: ============================================================
2022-05-12 01:40:05,045: Epoch 36/38 Batch 2400/7662 eta: 2:40:37.169514	Training Loss 0.0729 (0.0682)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.989)	
2022-05-12 01:40:05,045: ============================================================
2022-05-12 01:40:51,797: time cost, forward:0.17257241546368304, backward:0.10449143188769648, data cost:0.19140822088875833 
2022-05-12 01:40:51,797: ============================================================
2022-05-12 01:40:51,797: Epoch 36/38 Batch 2500/7662 eta: 2:39:38.104825	Training Loss 0.0655 (0.0682)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.989)	
2022-05-12 01:40:51,797: ============================================================
2022-05-12 01:41:38,587: time cost, forward:0.17256762431923725, backward:0.10449184138484073, data cost:0.19138122779124056 
2022-05-12 01:41:38,588: ============================================================
2022-05-12 01:41:38,588: Epoch 36/38 Batch 2600/7662 eta: 2:38:59.208724	Training Loss 0.0726 (0.0682)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.989)	
2022-05-12 01:41:38,588: ============================================================
2022-05-12 01:42:25,398: time cost, forward:0.17254925215849395, backward:0.10449131527137827, data cost:0.19137076211443826 
2022-05-12 01:42:25,399: ============================================================
2022-05-12 01:42:25,399: Epoch 36/38 Batch 2700/7662 eta: 2:38:16.523069	Training Loss 0.0700 (0.0682)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.989)	
2022-05-12 01:42:25,399: ============================================================
2022-05-12 01:43:12,184: time cost, forward:0.17253621385198867, backward:0.10449200368174573, data cost:0.19134991975629614 
2022-05-12 01:43:12,184: ============================================================
2022-05-12 01:43:12,184: Epoch 36/38 Batch 2800/7662 eta: 2:37:24.614115	Training Loss 0.0690 (0.0682)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.989)	
2022-05-12 01:43:12,184: ============================================================
2022-05-12 01:43:58,946: time cost, forward:0.17252028962997537, backward:0.10449072787497693, data cost:0.19132443056636203 
2022-05-12 01:43:58,946: ============================================================
2022-05-12 01:43:58,946: Epoch 36/38 Batch 2900/7662 eta: 2:36:33.005421	Training Loss 0.0679 (0.0682)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.989)	
2022-05-12 01:43:58,946: ============================================================
2022-05-12 01:44:45,768: time cost, forward:0.17250460567137288, backward:0.10449335844606589, data cost:0.19131058532025425 
2022-05-12 01:44:45,768: ============================================================
2022-05-12 01:44:45,768: Epoch 36/38 Batch 3000/7662 eta: 2:35:58.397777	Training Loss 0.0715 (0.0682)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.989)	
2022-05-12 01:44:45,768: ============================================================
2022-05-12 01:45:32,517: time cost, forward:0.17249221469402776, backward:0.10449334597272156, data cost:0.1912887924215262 
2022-05-12 01:45:32,517: ============================================================
2022-05-12 01:45:32,517: Epoch 36/38 Batch 3100/7662 eta: 2:34:56.891238	Training Loss 0.0686 (0.0683)	Training Prec@1 99.805 (99.973)	Training Prec@5 99.805 (99.989)	
2022-05-12 01:45:32,517: ============================================================
2022-05-12 01:46:19,216: time cost, forward:0.17247349905125534, backward:0.10448943484235682, data cost:0.1912638546340575 
2022-05-12 01:46:19,216: ============================================================
2022-05-12 01:46:19,216: Epoch 36/38 Batch 3200/7662 eta: 2:34:00.380688	Training Loss 0.0725 (0.0683)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.989)	
2022-05-12 01:46:19,216: ============================================================
2022-05-12 01:47:05,915: time cost, forward:0.1724585861681302, backward:0.10448576299014616, data cost:0.19123786902854065 
2022-05-12 01:47:05,916: ============================================================
2022-05-12 01:47:05,916: Epoch 36/38 Batch 3300/7662 eta: 2:33:13.731473	Training Loss 0.0719 (0.0683)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.989)	
2022-05-12 01:47:05,916: ============================================================
2022-05-12 01:47:52,687: time cost, forward:0.17245792030902357, backward:0.1044826835841072, data cost:0.19122065709387073 
2022-05-12 01:47:52,687: ============================================================
2022-05-12 01:47:52,688: Epoch 36/38 Batch 3400/7662 eta: 2:32:41.201347	Training Loss 0.0699 (0.0683)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.989)	
2022-05-12 01:47:52,688: ============================================================
2022-05-12 01:48:39,426: time cost, forward:0.17244390338855187, backward:0.1044791486815883, data cost:0.1912058626252878 
2022-05-12 01:48:39,426: ============================================================
2022-05-12 01:48:39,426: Epoch 36/38 Batch 3500/7662 eta: 2:31:47.928637	Training Loss 0.0663 (0.0683)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.990)	
2022-05-12 01:48:39,426: ============================================================
2022-05-12 01:49:26,126: time cost, forward:0.1724312221318293, backward:0.10447826826694973, data cost:0.19117806467224274 
2022-05-12 01:49:26,126: ============================================================
2022-05-12 01:49:26,126: Epoch 36/38 Batch 3600/7662 eta: 2:30:53.712647	Training Loss 0.0684 (0.0683)	Training Prec@1 99.805 (99.973)	Training Prec@5 100.000 (99.990)	
2022-05-12 01:49:26,126: ============================================================
2022-05-12 01:50:12,801: time cost, forward:0.17241944767842907, backward:0.10447549085160725, data cost:0.19114998728238303 
2022-05-12 01:50:12,801: ============================================================
2022-05-12 01:50:12,802: Epoch 36/38 Batch 3700/7662 eta: 2:30:02.334248	Training Loss 0.0689 (0.0683)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.990)	
2022-05-12 01:50:12,802: ============================================================
2022-05-12 01:50:59,493: time cost, forward:0.1724045441068452, backward:0.1044734642046883, data cost:0.19112775030183804 
2022-05-12 01:50:59,493: ============================================================
2022-05-12 01:50:59,494: Epoch 36/38 Batch 3800/7662 eta: 2:29:18.771150	Training Loss 0.0659 (0.0683)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.989)	
2022-05-12 01:50:59,494: ============================================================
2022-05-12 01:51:46,170: time cost, forward:0.1723886054734384, backward:0.10447068879713796, data cost:0.1911088140477398 
2022-05-12 01:51:46,170: ============================================================
2022-05-12 01:51:46,170: Epoch 36/38 Batch 3900/7662 eta: 2:28:29.202184	Training Loss 0.0687 (0.0684)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.989)	
2022-05-12 01:51:46,170: ============================================================
2022-05-12 01:52:32,812: time cost, forward:0.1723784602084855, backward:0.10446853976334354, data cost:0.19107660170524352 
2022-05-12 01:52:32,812: ============================================================
2022-05-12 01:52:32,812: Epoch 36/38 Batch 4000/7662 eta: 2:27:35.912775	Training Loss 0.0683 (0.0684)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.989)	
2022-05-12 01:52:32,812: ============================================================
2022-05-12 01:53:19,503: time cost, forward:0.172366605034163, backward:0.10446567249228297, data cost:0.19106072825785234 
2022-05-12 01:53:19,503: ============================================================
2022-05-12 01:53:19,504: Epoch 36/38 Batch 4100/7662 eta: 2:26:58.596982	Training Loss 0.0728 (0.0684)	Training Prec@1 99.805 (99.972)	Training Prec@5 100.000 (99.990)	
2022-05-12 01:53:19,504: ============================================================
2022-05-12 01:54:06,194: time cost, forward:0.17235802235731654, backward:0.10446412036974789, data cost:0.1910414927969322 
2022-05-12 01:54:06,194: ============================================================
2022-05-12 01:54:06,194: Epoch 36/38 Batch 4200/7662 eta: 2:26:11.721126	Training Loss 0.0679 (0.0684)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.990)	
2022-05-12 01:54:06,194: ============================================================
2022-05-12 01:54:52,909: time cost, forward:0.17234301772276228, backward:0.10446237652599603, data cost:0.19103065089420762 
2022-05-12 01:54:52,909: ============================================================
2022-05-12 01:54:52,909: Epoch 36/38 Batch 4300/7662 eta: 2:25:29.709913	Training Loss 0.0672 (0.0684)	Training Prec@1 99.805 (99.973)	Training Prec@5 100.000 (99.990)	
2022-05-12 01:54:52,910: ============================================================
2022-05-12 01:55:39,613: time cost, forward:0.1723296402746722, backward:0.10446018298990918, data cost:0.19101740680355514 
2022-05-12 01:55:39,613: ============================================================
2022-05-12 01:55:39,613: Epoch 36/38 Batch 4400/7662 eta: 2:24:40.835920	Training Loss 0.0691 (0.0684)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.990)	
2022-05-12 01:55:39,613: ============================================================
2022-05-12 01:56:26,329: time cost, forward:0.17232149912267558, backward:0.10445869194186776, data cost:0.19100720576642222 
2022-05-12 01:56:26,329: ============================================================
2022-05-12 01:56:26,329: Epoch 36/38 Batch 4500/7662 eta: 2:23:56.358109	Training Loss 0.0663 (0.0684)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.989)	
2022-05-12 01:56:26,329: ============================================================
2022-05-12 01:57:13,082: time cost, forward:0.17232254334806643, backward:0.10445703747843266, data cost:0.19099682791125752 
2022-05-12 01:57:13,082: ============================================================
2022-05-12 01:57:13,082: Epoch 36/38 Batch 4600/7662 eta: 2:23:16.459121	Training Loss 0.0708 (0.0684)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.989)	
2022-05-12 01:57:13,082: ============================================================
2022-05-12 01:57:59,839: time cost, forward:0.17231205053140722, backward:0.1044558843518095, data cost:0.19099710088609304 
2022-05-12 01:57:59,839: ============================================================
2022-05-12 01:57:59,839: Epoch 36/38 Batch 4700/7662 eta: 2:22:30.535642	Training Loss 0.0699 (0.0685)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.989)	
2022-05-12 01:57:59,840: ============================================================
2022-05-12 01:58:46,525: time cost, forward:0.1722989022719361, backward:0.10445465885566954, data cost:0.19098812020006317 
2022-05-12 01:58:46,525: ============================================================
2022-05-12 01:58:46,525: Epoch 36/38 Batch 4800/7662 eta: 2:21:30.783837	Training Loss 0.0692 (0.0685)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.989)	
2022-05-12 01:58:46,526: ============================================================
2022-05-12 01:59:33,223: time cost, forward:0.17228788136219245, backward:0.1044529746760882, data cost:0.19098109974134064 
2022-05-12 01:59:33,223: ============================================================
2022-05-12 01:59:33,224: Epoch 36/38 Batch 4900/7662 eta: 2:20:46.269839	Training Loss 0.0667 (0.0685)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.990)	
2022-05-12 01:59:33,224: ============================================================
2022-05-12 02:00:20,027: time cost, forward:0.17228288673405456, backward:0.10445240169173362, data cost:0.19098175323159725 
2022-05-12 02:00:20,027: ============================================================
2022-05-12 02:00:20,028: Epoch 36/38 Batch 5000/7662 eta: 2:20:18.648671	Training Loss 0.0737 (0.0685)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.990)	
2022-05-12 02:00:20,028: ============================================================
2022-05-12 02:01:06,808: time cost, forward:0.17227450345726336, backward:0.10445112531197774, data cost:0.1909840963101429 
2022-05-12 02:01:06,808: ============================================================
2022-05-12 02:01:06,808: Epoch 36/38 Batch 5100/7662 eta: 2:19:27.683676	Training Loss 0.0631 (0.0685)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.990)	
2022-05-12 02:01:06,809: ============================================================
2022-05-12 02:01:53,595: time cost, forward:0.1722642146846289, backward:0.10444972239496342, data cost:0.19098983133818284 
2022-05-12 02:01:53,595: ============================================================
2022-05-12 02:01:53,595: Epoch 36/38 Batch 5200/7662 eta: 2:18:41.985020	Training Loss 0.0722 (0.0685)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.990)	
2022-05-12 02:01:53,595: ============================================================
2022-05-12 02:02:40,439: time cost, forward:0.172256003777741, backward:0.10444785491725952, data cost:0.19100709788460488 
2022-05-12 02:02:40,439: ============================================================
2022-05-12 02:02:40,440: Epoch 36/38 Batch 5300/7662 eta: 2:18:05.352274	Training Loss 0.0655 (0.0685)	Training Prec@1 99.805 (99.973)	Training Prec@5 99.805 (99.990)	
2022-05-12 02:02:40,440: ============================================================
2022-05-12 02:03:27,228: time cost, forward:0.17224967212539224, backward:0.10444668911854235, data cost:0.19101139169464423 
2022-05-12 02:03:27,228: ============================================================
2022-05-12 02:03:27,228: Epoch 36/38 Batch 5400/7662 eta: 2:17:08.695185	Training Loss 0.0675 (0.0686)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.990)	
2022-05-12 02:03:27,228: ============================================================
2022-05-12 02:04:14,024: time cost, forward:0.17224290978368748, backward:0.10444526924699365, data cost:0.19102015489230353 
2022-05-12 02:04:14,024: ============================================================
2022-05-12 02:04:14,024: Epoch 36/38 Batch 5500/7662 eta: 2:16:23.226277	Training Loss 0.0636 (0.0686)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.990)	
2022-05-12 02:04:14,024: ============================================================
2022-05-12 02:05:00,881: time cost, forward:0.17223923916177125, backward:0.10444639529217821, data cost:0.1910295073401398 
2022-05-12 02:05:00,882: ============================================================
2022-05-12 02:05:00,882: Epoch 36/38 Batch 5600/7662 eta: 2:15:47.119466	Training Loss 0.0769 (0.0686)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.990)	
2022-05-12 02:05:00,882: ============================================================
2022-05-12 02:05:47,677: time cost, forward:0.17223436641241296, backward:0.10444485118335162, data cost:0.19103375642545226 
2022-05-12 02:05:47,677: ============================================================
2022-05-12 02:05:47,678: Epoch 36/38 Batch 5700/7662 eta: 2:14:49.601193	Training Loss 0.0716 (0.0686)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.990)	
2022-05-12 02:05:47,678: ============================================================
2022-05-12 02:06:34,537: time cost, forward:0.17223454709915606, backward:0.10444411016123153, data cost:0.19104312871895818 
2022-05-12 02:06:34,538: ============================================================
2022-05-12 02:06:34,538: Epoch 36/38 Batch 5800/7662 eta: 2:14:13.873175	Training Loss 0.0668 (0.0686)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.989)	
2022-05-12 02:06:34,538: ============================================================
2022-05-12 02:07:21,375: time cost, forward:0.1722314346845038, backward:0.10444338832149709, data cost:0.1910436672767475 
2022-05-12 02:07:21,375: ============================================================
2022-05-12 02:07:21,375: Epoch 36/38 Batch 5900/7662 eta: 2:13:23.125678	Training Loss 0.0680 (0.0686)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.989)	
2022-05-12 02:07:21,375: ============================================================
2022-05-12 02:08:08,218: time cost, forward:0.1722321048898088, backward:0.10444220087293347, data cost:0.19104576989161332 
2022-05-12 02:08:08,218: ============================================================
2022-05-12 02:08:08,218: Epoch 36/38 Batch 6000/7662 eta: 2:12:37.230038	Training Loss 0.0655 (0.0686)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.989)	
2022-05-12 02:08:08,218: ============================================================
2022-05-12 02:08:55,071: time cost, forward:0.17223735198874535, backward:0.10444088434856394, data cost:0.19104510089338245 
2022-05-12 02:08:55,072: ============================================================
2022-05-12 02:08:55,072: Epoch 36/38 Batch 6100/7662 eta: 2:11:52.110828	Training Loss 0.0673 (0.0686)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.989)	
2022-05-12 02:08:55,072: ============================================================
2022-05-12 02:09:41,925: time cost, forward:0.17224219303435714, backward:0.10444059243489127, data cost:0.1910455441124921 
2022-05-12 02:09:41,926: ============================================================
2022-05-12 02:09:41,926: Epoch 36/38 Batch 6200/7662 eta: 2:11:05.397045	Training Loss 0.0707 (0.0687)	Training Prec@1 99.805 (99.972)	Training Prec@5 99.805 (99.989)	
2022-05-12 02:09:41,926: ============================================================
2022-05-12 02:10:28,763: time cost, forward:0.17224526534025245, backward:0.10444190748571724, data cost:0.1910474844670784 
2022-05-12 02:10:28,764: ============================================================
2022-05-12 02:10:28,764: Epoch 36/38 Batch 6300/7662 eta: 2:10:15.881577	Training Loss 0.0652 (0.0687)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.989)	
2022-05-12 02:10:28,764: ============================================================
2022-05-12 02:11:15,563: time cost, forward:0.17224280184778426, backward:0.10444032492013923, data cost:0.19104990729653737 
2022-05-12 02:11:15,563: ============================================================
2022-05-12 02:11:15,564: Epoch 36/38 Batch 6400/7662 eta: 2:09:22.667745	Training Loss 0.0720 (0.0687)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.989)	
2022-05-12 02:11:15,564: ============================================================
2022-05-12 02:12:02,366: time cost, forward:0.1722406519616745, backward:0.10443947681703464, data cost:0.19105005865923202 
2022-05-12 02:12:02,366: ============================================================
2022-05-12 02:12:02,366: Epoch 36/38 Batch 6500/7662 eta: 2:08:36.325661	Training Loss 0.0705 (0.0687)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.989)	
2022-05-12 02:12:02,366: ============================================================
2022-05-12 02:12:49,166: time cost, forward:0.17224057487762956, backward:0.10443806174957927, data cost:0.19104675163480617 
2022-05-12 02:12:49,166: ============================================================
2022-05-12 02:12:49,166: Epoch 36/38 Batch 6600/7662 eta: 2:07:49.139747	Training Loss 0.0725 (0.0687)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.989)	
2022-05-12 02:12:49,166: ============================================================
2022-05-12 02:13:35,984: time cost, forward:0.17223972689840292, backward:0.10443796497936622, data cost:0.19104448665983909 
2022-05-12 02:13:35,985: ============================================================
2022-05-12 02:13:35,985: Epoch 36/38 Batch 6700/7662 eta: 2:07:05.329335	Training Loss 0.0699 (0.0687)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.989)	
2022-05-12 02:13:35,985: ============================================================
2022-05-12 02:14:22,864: time cost, forward:0.17224402093838237, backward:0.10443859869004138, data cost:0.1910471542387574 
2022-05-12 02:14:22,865: ============================================================
2022-05-12 02:14:22,865: Epoch 36/38 Batch 6800/7662 eta: 2:06:28.457823	Training Loss 0.0691 (0.0687)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.989)	
2022-05-12 02:14:22,865: ============================================================
2022-05-12 02:15:09,816: time cost, forward:0.17224689161696283, backward:0.1044557648545539, data cost:0.1910464085950629 
2022-05-12 02:15:09,816: ============================================================
2022-05-12 02:15:09,816: Epoch 36/38 Batch 6900/7662 eta: 2:05:53.082809	Training Loss 0.0706 (0.0687)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.989)	
2022-05-12 02:15:09,816: ============================================================
2022-05-12 02:15:56,760: time cost, forward:0.1722457648379613, backward:0.1044773875960181, data cost:0.19104484132842212 
2022-05-12 02:15:56,760: ============================================================
2022-05-12 02:15:56,761: Epoch 36/38 Batch 7000/7662 eta: 2:05:05.003031	Training Loss 0.0674 (0.0687)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.989)	
2022-05-12 02:15:56,761: ============================================================
2022-05-12 02:16:43,702: time cost, forward:0.17224899593046442, backward:0.10449814071015819, data cost:0.1910390777308465 
2022-05-12 02:16:43,702: ============================================================
2022-05-12 02:16:43,703: Epoch 36/38 Batch 7100/7662 eta: 2:04:17.678443	Training Loss 0.0717 (0.0687)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.989)	
2022-05-12 02:16:43,703: ============================================================
2022-05-12 02:17:30,599: time cost, forward:0.17225153871105187, backward:0.10450836028766593, data cost:0.1910359424292205 
2022-05-12 02:17:30,599: ============================================================
2022-05-12 02:17:30,599: Epoch 36/38 Batch 7200/7662 eta: 2:03:23.582014	Training Loss 0.0731 (0.0688)	Training Prec@1 99.805 (99.972)	Training Prec@5 99.805 (99.989)	
2022-05-12 02:17:30,599: ============================================================
2022-05-12 02:18:17,394: time cost, forward:0.17225540068104164, backward:0.10450738906076402, data cost:0.19102999624740197 
2022-05-12 02:18:17,395: ============================================================
2022-05-12 02:18:17,395: Epoch 36/38 Batch 7300/7662 eta: 2:02:20.783200	Training Loss 0.0721 (0.0688)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.989)	
2022-05-12 02:18:17,395: ============================================================
2022-05-12 02:19:04,237: time cost, forward:0.1722610782716609, backward:0.10450639613884045, data cost:0.19102732876472045 
2022-05-12 02:19:04,238: ============================================================
2022-05-12 02:19:04,238: Epoch 36/38 Batch 7400/7662 eta: 2:01:41.454447	Training Loss 0.0692 (0.0688)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.989)	
2022-05-12 02:19:04,238: ============================================================
2022-05-12 02:19:51,000: time cost, forward:0.1722611332753608, backward:0.10450495648565317, data cost:0.19102293930938838 
2022-05-12 02:19:51,001: ============================================================
2022-05-12 02:19:51,001: Epoch 36/38 Batch 7500/7662 eta: 2:00:42.185627	Training Loss 0.0741 (0.0688)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.989)	
2022-05-12 02:19:51,001: ============================================================
2022-05-12 02:20:37,819: time cost, forward:0.17226141580611032, backward:0.10450370438178286, data cost:0.1910210361071583 
2022-05-12 02:20:37,819: ============================================================
2022-05-12 02:20:37,819: Epoch 36/38 Batch 7600/7662 eta: 2:00:03.930905	Training Loss 0.0698 (0.0688)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.989)	
2022-05-12 02:20:37,819: ============================================================
2022-05-12 02:21:08,922: Epoch: 36/38 eta: 1:59:34.435380	Training Loss 0.0665 (0.0688)	Training Prec@1 99.805 (99.972)	Training Prec@5 100.000 (99.989)
2022-05-12 02:21:08,922: ============================================================
2022-05-12 02:21:08,924: Save Checkpoint...
2022-05-12 02:21:08,929: ============================================================
2022-05-12 02:21:11,425: Save done!
2022-05-12 02:21:11,425: ============================================================
2022-05-12 02:22:01,021: time cost, forward:0.18715159579960985, backward:0.10434349377950032, data cost:0.20728560649987424 
2022-05-12 02:22:01,021: ============================================================
2022-05-12 02:22:01,022: Epoch 37/38 Batch 100/7662 eta: 2:05:50.963660	Training Loss 0.0709 (0.0674)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.988)	
2022-05-12 02:22:01,022: ============================================================
2022-05-12 02:22:48,057: time cost, forward:0.18163781429654988, backward:0.10440135121944562, data cost:0.19833296148022214 
2022-05-12 02:22:48,057: ============================================================
2022-05-12 02:22:48,057: Epoch 37/38 Batch 200/7662 eta: 1:58:34.112279	Training Loss 0.0669 (0.0674)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.991)	
2022-05-12 02:22:48,057: ============================================================
2022-05-12 02:23:34,647: time cost, forward:0.17829732432413262, backward:0.10444096817220733, data cost:0.19537626859735088 
2022-05-12 02:23:34,648: ============================================================
2022-05-12 02:23:34,648: Epoch 37/38 Batch 300/7662 eta: 1:56:40.272543	Training Loss 0.0673 (0.0673)	Training Prec@1 100.000 (99.977)	Training Prec@5 100.000 (99.990)	
2022-05-12 02:23:34,648: ============================================================
2022-05-12 02:24:21,303: time cost, forward:0.17678704058616085, backward:0.10444374729816179, data cost:0.19391728224312155 
2022-05-12 02:24:21,303: ============================================================
2022-05-12 02:24:21,303: Epoch 37/38 Batch 400/7662 eta: 1:56:03.288636	Training Loss 0.0670 (0.0673)	Training Prec@1 100.000 (99.979)	Training Prec@5 100.000 (99.991)	
2022-05-12 02:24:21,303: ============================================================
2022-05-12 02:25:07,967: time cost, forward:0.17578917801499605, backward:0.10446607039304438, data cost:0.19311066285402836 
2022-05-12 02:25:07,967: ============================================================
2022-05-12 02:25:07,967: Epoch 37/38 Batch 500/7662 eta: 1:55:17.989362	Training Loss 0.0629 (0.0673)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.991)	
2022-05-12 02:25:07,968: ============================================================
2022-05-12 02:25:54,566: time cost, forward:0.1751204344983491, backward:0.10446306500888627, data cost:0.19250311198736073 
2022-05-12 02:25:54,566: ============================================================
2022-05-12 02:25:54,566: Epoch 37/38 Batch 600/7662 eta: 1:54:21.648331	Training Loss 0.0634 (0.0673)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.992)	
2022-05-12 02:25:54,566: ============================================================
2022-05-12 02:26:41,188: time cost, forward:0.1746545864618217, backward:0.10447183937814955, data cost:0.19208120037728282 
2022-05-12 02:26:41,188: ============================================================
2022-05-12 02:26:41,188: Epoch 37/38 Batch 700/7662 eta: 1:53:38.509305	Training Loss 0.0657 (0.0674)	Training Prec@1 100.000 (99.978)	Training Prec@5 100.000 (99.992)	
2022-05-12 02:26:41,188: ============================================================
2022-05-12 02:27:27,844: time cost, forward:0.17435146691056158, backward:0.104470554370904, data cost:0.19177005884793583 
2022-05-12 02:27:27,844: ============================================================
2022-05-12 02:27:27,844: Epoch 37/38 Batch 800/7662 eta: 1:52:56.782877	Training Loss 0.0679 (0.0674)	Training Prec@1 99.805 (99.977)	Training Prec@5 99.805 (99.991)	
2022-05-12 02:27:27,844: ============================================================
2022-05-12 02:28:14,478: time cost, forward:0.17408795934895652, backward:0.1044772832889578, data cost:0.19152179602388544 
2022-05-12 02:28:14,479: ============================================================
2022-05-12 02:28:14,479: Epoch 37/38 Batch 900/7662 eta: 1:52:06.998015	Training Loss 0.0678 (0.0673)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.990)	
2022-05-12 02:28:14,479: ============================================================
2022-05-12 02:29:01,110: time cost, forward:0.17385364963008357, backward:0.10447670389582087, data cost:0.19134133952754634 
2022-05-12 02:29:01,110: ============================================================
2022-05-12 02:29:01,110: Epoch 37/38 Batch 1000/7662 eta: 1:51:19.985395	Training Loss 0.0690 (0.0673)	Training Prec@1 99.805 (99.975)	Training Prec@5 99.805 (99.990)	
2022-05-12 02:29:01,110: ============================================================
2022-05-12 02:29:47,792: time cost, forward:0.1736988257667604, backward:0.10447641217350634, data cost:0.1911944034861043 
2022-05-12 02:29:47,793: ============================================================
2022-05-12 02:29:47,793: Epoch 37/38 Batch 1100/7662 eta: 1:50:40.585778	Training Loss 0.0663 (0.0674)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.988)	
2022-05-12 02:29:47,793: ============================================================
2022-05-12 02:30:34,384: time cost, forward:0.17352614808420622, backward:0.1044756542950297, data cost:0.19104937457163398 
2022-05-12 02:30:34,384: ============================================================
2022-05-12 02:30:34,384: Epoch 37/38 Batch 1200/7662 eta: 1:49:41.034698	Training Loss 0.0655 (0.0674)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.988)	
2022-05-12 02:30:34,384: ============================================================
2022-05-12 02:31:20,995: time cost, forward:0.17337474775277623, backward:0.10447162733892922, data cost:0.19094879265653802 
2022-05-12 02:31:20,995: ============================================================
2022-05-12 02:31:20,995: Epoch 37/38 Batch 1300/7662 eta: 1:48:57.228337	Training Loss 0.0662 (0.0674)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.988)	
2022-05-12 02:31:20,996: ============================================================
2022-05-12 02:32:07,627: time cost, forward:0.17326878632197132, backward:0.10447064887804164, data cost:0.19085948428057875 
2022-05-12 02:32:07,627: ============================================================
2022-05-12 02:32:07,628: Epoch 37/38 Batch 1400/7662 eta: 1:48:13.526945	Training Loss 0.0614 (0.0674)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.987)	
2022-05-12 02:32:07,628: ============================================================
2022-05-12 02:32:54,303: time cost, forward:0.17318954540937245, backward:0.10447029545754095, data cost:0.19080026122710958 
2022-05-12 02:32:54,303: ============================================================
2022-05-12 02:32:54,303: Epoch 37/38 Batch 1500/7662 eta: 1:47:32.895313	Training Loss 0.0649 (0.0674)	Training Prec@1 99.805 (99.973)	Training Prec@5 100.000 (99.987)	
2022-05-12 02:32:54,303: ============================================================
2022-05-12 02:33:40,927: time cost, forward:0.17311318163725642, backward:0.10446917108627615, data cost:0.1907227149674712 
2022-05-12 02:33:40,927: ============================================================
2022-05-12 02:33:40,927: Epoch 37/38 Batch 1600/7662 eta: 1:46:39.164527	Training Loss 0.0685 (0.0675)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.987)	
2022-05-12 02:33:40,927: ============================================================
2022-05-12 02:34:28,608: time cost, forward:0.17344622081556763, backward:0.10453382080060163, data cost:0.19080030714644622 
2022-05-12 02:34:28,781: ============================================================
2022-05-12 02:34:28,781: Epoch 37/38 Batch 1700/7662 eta: 1:48:40.103095	Training Loss 0.0681 (0.0675)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.987)	
2022-05-12 02:34:28,781: ============================================================
2022-05-12 02:35:15,442: time cost, forward:0.1733709066824624, backward:0.10452569054523529, data cost:0.19084635756292762 
2022-05-12 02:35:15,443: ============================================================
2022-05-12 02:35:15,443: Epoch 37/38 Batch 1800/7662 eta: 1:45:10.956231	Training Loss 0.0752 (0.0676)	Training Prec@1 100.000 (99.971)	Training Prec@5 100.000 (99.987)	
2022-05-12 02:35:15,443: ============================================================
2022-05-12 02:36:02,112: time cost, forward:0.17328570515560815, backward:0.10451982949142898, data cost:0.19081143531879668 
2022-05-12 02:36:02,112: ============================================================
2022-05-12 02:36:02,112: Epoch 37/38 Batch 1900/7662 eta: 1:44:25.387816	Training Loss 0.0708 (0.0676)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.987)	
2022-05-12 02:36:02,112: ============================================================
2022-05-12 02:36:48,785: time cost, forward:0.17321695608756374, backward:0.10451398079487131, data cost:0.19077647036466078 
2022-05-12 02:36:48,785: ============================================================
2022-05-12 02:36:48,785: Epoch 37/38 Batch 2000/7662 eta: 1:43:39.142952	Training Loss 0.0722 (0.0676)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.988)	
2022-05-12 02:36:48,785: ============================================================
2022-05-12 02:37:35,464: time cost, forward:0.17315678144421334, backward:0.10451008559068423, data cost:0.19074944566124222 
2022-05-12 02:37:35,465: ============================================================
2022-05-12 02:37:35,465: Epoch 37/38 Batch 2100/7662 eta: 1:42:53.379969	Training Loss 0.0648 (0.0676)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.988)	
2022-05-12 02:37:35,465: ============================================================
2022-05-12 02:38:22,151: time cost, forward:0.1731112057537098, backward:0.10450631155106847, data cost:0.1907168732496108 
2022-05-12 02:38:22,151: ============================================================
2022-05-12 02:38:22,151: Epoch 37/38 Batch 2200/7662 eta: 1:42:07.577037	Training Loss 0.0658 (0.0676)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.988)	
2022-05-12 02:38:22,151: ============================================================
2022-05-12 02:39:08,835: time cost, forward:0.17307162969306325, backward:0.10450104082496646, data cost:0.19068604648087326 
2022-05-12 02:39:08,835: ============================================================
2022-05-12 02:39:08,835: Epoch 37/38 Batch 2300/7662 eta: 1:41:20.604759	Training Loss 0.0660 (0.0676)	Training Prec@1 99.805 (99.973)	Training Prec@5 99.805 (99.988)	
2022-05-12 02:39:08,835: ============================================================
2022-05-12 02:39:55,494: time cost, forward:0.17303172445833906, backward:0.10449602296820477, data cost:0.19064610726935707 
2022-05-12 02:39:55,494: ============================================================
2022-05-12 02:39:55,494: Epoch 37/38 Batch 2400/7662 eta: 1:40:30.671333	Training Loss 0.0671 (0.0677)	Training Prec@1 99.805 (99.973)	Training Prec@5 100.000 (99.988)	
2022-05-12 02:39:55,494: ============================================================
2022-05-12 02:40:42,171: time cost, forward:0.17299885280421373, backward:0.10449336804881865, data cost:0.19061595575959264 
2022-05-12 02:40:42,172: ============================================================
2022-05-12 02:40:42,172: Epoch 37/38 Batch 2500/7662 eta: 1:39:46.418027	Training Loss 0.0669 (0.0677)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.989)	
2022-05-12 02:40:42,172: ============================================================
2022-05-12 02:41:28,827: time cost, forward:0.17296777288929321, backward:0.10448967277567953, data cost:0.1905816537043185 
2022-05-12 02:41:28,827: ============================================================
2022-05-12 02:41:28,827: Epoch 37/38 Batch 2600/7662 eta: 1:38:56.889522	Training Loss 0.0704 (0.0677)	Training Prec@1 99.805 (99.974)	Training Prec@5 100.000 (99.989)	
2022-05-12 02:41:28,827: ============================================================
2022-05-12 02:42:15,522: time cost, forward:0.17293444126789195, backward:0.10448769314636253, data cost:0.1905670833834987 
2022-05-12 02:42:15,523: ============================================================
2022-05-12 02:42:15,523: Epoch 37/38 Batch 2700/7662 eta: 1:38:15.334464	Training Loss 0.0665 (0.0677)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.989)	
2022-05-12 02:42:15,523: ============================================================
2022-05-12 02:43:02,210: time cost, forward:0.17290526238796156, backward:0.10448663121421407, data cost:0.1905480368131397 
2022-05-12 02:43:02,210: ============================================================
2022-05-12 02:43:02,210: Epoch 37/38 Batch 2800/7662 eta: 1:37:27.630458	Training Loss 0.0659 (0.0677)	Training Prec@1 99.805 (99.974)	Training Prec@5 100.000 (99.989)	
2022-05-12 02:43:02,211: ============================================================
2022-05-12 02:43:48,894: time cost, forward:0.17286696315593003, backward:0.1044830650080891, data cost:0.1905399057198163 
2022-05-12 02:43:48,895: ============================================================
2022-05-12 02:43:48,895: Epoch 37/38 Batch 2900/7662 eta: 1:36:40.547641	Training Loss 0.0667 (0.0677)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.989)	
2022-05-12 02:43:48,895: ============================================================
2022-05-12 02:44:35,533: time cost, forward:0.17283602109071453, backward:0.1044813239125261, data cost:0.19051338148419164 
2022-05-12 02:44:35,533: ============================================================
2022-05-12 02:44:35,533: Epoch 37/38 Batch 3000/7662 eta: 1:35:48.160066	Training Loss 0.0681 (0.0678)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.989)	
2022-05-12 02:44:35,533: ============================================================
2022-05-12 02:45:22,232: time cost, forward:0.17281108534924636, backward:0.10448385262035408, data cost:0.1904999972851517 
2022-05-12 02:45:22,232: ============================================================
2022-05-12 02:45:22,232: Epoch 37/38 Batch 3100/7662 eta: 1:35:08.945478	Training Loss 0.0674 (0.0678)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.989)	
2022-05-12 02:45:22,232: ============================================================
2022-05-12 02:46:08,941: time cost, forward:0.1727873933952501, backward:0.10448186820132466, data cost:0.1904917129988818 
2022-05-12 02:46:08,942: ============================================================
2022-05-12 02:46:08,942: Epoch 37/38 Batch 3200/7662 eta: 1:34:23.528387	Training Loss 0.0656 (0.0678)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.989)	
2022-05-12 02:46:08,942: ============================================================
2022-05-12 02:46:55,575: time cost, forward:0.17275848580909953, backward:0.10448010230143889, data cost:0.1904709282048582 
2022-05-12 02:46:55,575: ============================================================
2022-05-12 02:46:55,575: Epoch 37/38 Batch 3300/7662 eta: 1:33:27.688851	Training Loss 0.0632 (0.0678)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.989)	
2022-05-12 02:46:55,575: ============================================================
2022-05-12 02:47:42,267: time cost, forward:0.1727388077674455, backward:0.10447886874655408, data cost:0.1904608193268738 
2022-05-12 02:47:42,267: ============================================================
2022-05-12 02:47:42,267: Epoch 37/38 Batch 3400/7662 eta: 1:32:48.028097	Training Loss 0.0726 (0.0679)	Training Prec@1 99.609 (99.974)	Training Prec@5 99.805 (99.989)	
2022-05-12 02:47:42,267: ============================================================
2022-05-12 02:48:28,991: time cost, forward:0.17272028155788827, backward:0.10447789001682889, data cost:0.19045723196641826 
2022-05-12 02:48:28,992: ============================================================
2022-05-12 02:48:28,992: Epoch 37/38 Batch 3500/7662 eta: 1:32:05.183705	Training Loss 0.0705 (0.0679)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.989)	
2022-05-12 02:48:28,992: ============================================================
2022-05-12 02:49:15,694: time cost, forward:0.17269873592581275, backward:0.10447621623752315, data cost:0.19045173515707758 
2022-05-12 02:49:15,694: ============================================================
2022-05-12 02:49:15,694: Epoch 37/38 Batch 3600/7662 eta: 1:31:15.823857	Training Loss 0.0677 (0.0679)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.989)	
2022-05-12 02:49:15,694: ============================================================
2022-05-12 02:50:02,445: time cost, forward:0.17268911365819448, backward:0.10447383358788574, data cost:0.19045315706655766 
2022-05-12 02:50:02,446: ============================================================
2022-05-12 02:50:02,446: Epoch 37/38 Batch 3700/7662 eta: 1:30:34.899113	Training Loss 0.0662 (0.0679)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.989)	
2022-05-12 02:50:02,446: ============================================================
2022-05-12 02:50:49,158: time cost, forward:0.17267438442213154, backward:0.10447149918122679, data cost:0.19045086068898698 
2022-05-12 02:50:49,159: ============================================================
2022-05-12 02:50:49,159: Epoch 37/38 Batch 3800/7662 eta: 1:29:43.676087	Training Loss 0.0694 (0.0679)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.989)	
2022-05-12 02:50:49,159: ============================================================
2022-05-12 02:51:35,876: time cost, forward:0.172660240365102, backward:0.10447051629680155, data cost:0.19044817891234647 
2022-05-12 02:51:35,876: ============================================================
2022-05-12 02:51:35,876: Epoch 37/38 Batch 3900/7662 eta: 1:28:57.470558	Training Loss 0.0738 (0.0679)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.989)	
2022-05-12 02:51:35,876: ============================================================
2022-05-12 02:52:22,564: time cost, forward:0.17264561588748092, backward:0.10446998953193269, data cost:0.19043979909486192 
2022-05-12 02:52:22,564: ============================================================
2022-05-12 02:52:22,564: Epoch 37/38 Batch 4000/7662 eta: 1:28:07.396528	Training Loss 0.0718 (0.0679)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.989)	
2022-05-12 02:52:22,564: ============================================================
2022-05-12 02:53:09,255: time cost, forward:0.17263811598408074, backward:0.10446763527221754, data cost:0.1904275688958709 
2022-05-12 02:53:09,256: ============================================================
2022-05-12 02:53:09,256: Epoch 37/38 Batch 4100/7662 eta: 1:27:21.138532	Training Loss 0.0676 (0.0679)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.989)	
2022-05-12 02:53:09,256: ============================================================
2022-05-12 02:53:55,966: time cost, forward:0.17262831765374959, backward:0.10446529673462568, data cost:0.1904209477187736 
2022-05-12 02:53:55,966: ============================================================
2022-05-12 02:53:55,966: Epoch 37/38 Batch 4200/7662 eta: 1:26:36.524293	Training Loss 0.0697 (0.0680)	Training Prec@1 99.805 (99.973)	Training Prec@5 100.000 (99.989)	
2022-05-12 02:53:55,966: ============================================================
2022-05-12 02:54:42,625: time cost, forward:0.1726081285345801, backward:0.10446298413566169, data cost:0.19041604356838954 
2022-05-12 02:54:42,626: ============================================================
2022-05-12 02:54:42,626: Epoch 37/38 Batch 4300/7662 eta: 1:25:44.212070	Training Loss 0.0615 (0.0680)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.989)	
2022-05-12 02:54:42,626: ============================================================
2022-05-12 02:55:29,355: time cost, forward:0.17259512963309073, backward:0.10446199467843921, data cost:0.19041783469838158 
2022-05-12 02:55:29,355: ============================================================
2022-05-12 02:55:29,356: Epoch 37/38 Batch 4400/7662 eta: 1:25:05.238437	Training Loss 0.0714 (0.0680)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.989)	
2022-05-12 02:55:29,356: ============================================================
2022-05-12 02:56:16,041: time cost, forward:0.17257977231499036, backward:0.10446109674220139, data cost:0.19041590829456242 
2022-05-12 02:56:16,041: ============================================================
2022-05-12 02:56:16,041: Epoch 37/38 Batch 4500/7662 eta: 1:24:13.721186	Training Loss 0.0712 (0.0680)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.989)	
2022-05-12 02:56:16,041: ============================================================
2022-05-12 02:57:02,621: time cost, forward:0.17256274459724402, backward:0.10445977454860461, data cost:0.1903928238610958 
2022-05-12 02:57:02,622: ============================================================
2022-05-12 02:57:02,622: Epoch 37/38 Batch 4600/7662 eta: 1:23:15.774518	Training Loss 0.0697 (0.0680)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.990)	
2022-05-12 02:57:02,622: ============================================================
2022-05-12 02:57:49,292: time cost, forward:0.17254937905203815, backward:0.10445858717319889, data cost:0.19038627339972158 
2022-05-12 02:57:49,292: ============================================================
2022-05-12 02:57:49,293: Epoch 37/38 Batch 4700/7662 eta: 1:22:38.769989	Training Loss 0.0667 (0.0680)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.990)	
2022-05-12 02:57:49,293: ============================================================
2022-05-12 02:58:36,163: time cost, forward:0.17257152281346036, backward:0.10445859949398498, data cost:0.1903856958193341 
2022-05-12 02:58:36,163: ============================================================
2022-05-12 02:58:36,163: Epoch 37/38 Batch 4800/7662 eta: 1:22:13.117801	Training Loss 0.0707 (0.0680)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.990)	
2022-05-12 02:58:36,163: ============================================================
2022-05-12 02:59:22,852: time cost, forward:0.17256145488001615, backward:0.10445616570850566, data cost:0.19038210102041586 
2022-05-12 02:59:22,852: ============================================================
2022-05-12 02:59:22,852: Epoch 37/38 Batch 4900/7662 eta: 1:21:07.312058	Training Loss 0.0620 (0.0680)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.990)	
2022-05-12 02:59:22,852: ============================================================
2022-05-12 03:00:09,560: time cost, forward:0.17255254086553395, backward:0.10445496491800191, data cost:0.1903784381410889 
2022-05-12 03:00:09,560: ============================================================
2022-05-12 03:00:09,560: Epoch 37/38 Batch 5000/7662 eta: 1:20:22.626670	Training Loss 0.0690 (0.0681)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.989)	
2022-05-12 03:00:09,560: ============================================================
2022-05-12 03:00:56,279: time cost, forward:0.17254398312842667, backward:0.10445433533596137, data cost:0.19037884954238177 
2022-05-12 03:00:56,279: ============================================================
2022-05-12 03:00:56,279: Epoch 37/38 Batch 5100/7662 eta: 1:19:37.032972	Training Loss 0.0699 (0.0681)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.989)	
2022-05-12 03:00:56,279: ============================================================
2022-05-12 03:01:43,042: time cost, forward:0.17253933087704984, backward:0.10445353429485775, data cost:0.1903841367109988 
2022-05-12 03:01:43,042: ============================================================
2022-05-12 03:01:43,042: Epoch 37/38 Batch 5200/7662 eta: 1:18:54.714645	Training Loss 0.0708 (0.0681)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.989)	
2022-05-12 03:01:43,042: ============================================================
2022-05-12 03:02:29,822: time cost, forward:0.17253543206218686, backward:0.10445283606133836, data cost:0.19039139762917293 
2022-05-12 03:02:29,822: ============================================================
2022-05-12 03:02:29,823: Epoch 37/38 Batch 5300/7662 eta: 1:18:09.759937	Training Loss 0.0717 (0.0681)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.989)	
2022-05-12 03:02:29,823: ============================================================
2022-05-12 03:03:16,518: time cost, forward:0.17253261933748004, backward:0.1044524139023463, data cost:0.19038155794717754 
2022-05-12 03:03:16,518: ============================================================
2022-05-12 03:03:16,519: Epoch 37/38 Batch 5400/7662 eta: 1:17:14.572946	Training Loss 0.0689 (0.0681)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.989)	
2022-05-12 03:03:16,519: ============================================================
2022-05-12 03:04:03,210: time cost, forward:0.1725278620850847, backward:0.10445163813173218, data cost:0.19037154146185092 
2022-05-12 03:04:03,211: ============================================================
2022-05-12 03:04:03,211: Epoch 37/38 Batch 5500/7662 eta: 1:16:27.508902	Training Loss 0.0699 (0.0681)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.989)	
2022-05-12 03:04:03,211: ============================================================
2022-05-12 03:04:49,872: time cost, forward:0.17252093942107036, backward:0.10445128012648819, data cost:0.19036036270987797 
2022-05-12 03:04:49,872: ============================================================
2022-05-12 03:04:49,873: Epoch 37/38 Batch 5600/7662 eta: 1:15:37.855682	Training Loss 0.0704 (0.0682)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.989)	
2022-05-12 03:04:49,873: ============================================================
2022-05-12 03:05:36,592: time cost, forward:0.17252119375249966, backward:0.10445069802353353, data cost:0.19035310049938892 
2022-05-12 03:05:36,592: ============================================================
2022-05-12 03:05:36,592: Epoch 37/38 Batch 5700/7662 eta: 1:14:56.746603	Training Loss 0.0666 (0.0682)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.989)	
2022-05-12 03:05:36,592: ============================================================
2022-05-12 03:06:23,315: time cost, forward:0.17251961114879805, backward:0.1044512225915942, data cost:0.19034590168561705 
2022-05-12 03:06:23,315: ============================================================
2022-05-12 03:06:23,316: Epoch 37/38 Batch 5800/7662 eta: 1:14:10.424776	Training Loss 0.0727 (0.0682)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.989)	
2022-05-12 03:06:23,316: ============================================================
2022-05-12 03:07:10,056: time cost, forward:0.17251540762142603, backward:0.10445198343454488, data cost:0.19034117265239897 
2022-05-12 03:07:10,056: ============================================================
2022-05-12 03:07:10,056: Epoch 37/38 Batch 5900/7662 eta: 1:13:25.274101	Training Loss 0.0673 (0.0682)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.989)	
2022-05-12 03:07:10,056: ============================================================
2022-05-12 03:07:56,729: time cost, forward:0.17250853444083689, backward:0.10445267984441448, data cost:0.1903306372385459 
2022-05-12 03:07:56,729: ============================================================
2022-05-12 03:07:56,729: Epoch 37/38 Batch 6000/7662 eta: 1:12:32.266085	Training Loss 0.0658 (0.0682)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.989)	
2022-05-12 03:07:56,729: ============================================================
2022-05-12 03:08:43,362: time cost, forward:0.17249960503747844, backward:0.10445388986900568, data cost:0.19031803544221657 
2022-05-12 03:08:43,362: ============================================================
2022-05-12 03:08:43,362: Epoch 37/38 Batch 6100/7662 eta: 1:11:41.905721	Training Loss 0.0708 (0.0682)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.989)	
2022-05-12 03:08:43,362: ============================================================
2022-05-12 03:09:29,980: time cost, forward:0.1724913050655704, backward:0.10445386587679242, data cost:0.1903043390954958 
2022-05-12 03:09:29,980: ============================================================
2022-05-12 03:09:29,980: Epoch 37/38 Batch 6200/7662 eta: 1:10:53.879471	Training Loss 0.0764 (0.0682)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.989)	
2022-05-12 03:09:29,980: ============================================================
2022-05-12 03:10:16,596: time cost, forward:0.17248289440147158, backward:0.10445445192145968, data cost:0.19029028042098192 
2022-05-12 03:10:16,596: ============================================================
2022-05-12 03:10:16,596: Epoch 37/38 Batch 6300/7662 eta: 1:10:07.091111	Training Loss 0.0697 (0.0682)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.989)	
2022-05-12 03:10:16,596: ============================================================
2022-05-12 03:11:03,188: time cost, forward:0.17247081864791133, backward:0.10445531883692812, data cost:0.19027681424480283 
2022-05-12 03:11:03,188: ============================================================
2022-05-12 03:11:03,189: Epoch 37/38 Batch 6400/7662 eta: 1:09:18.382282	Training Loss 0.0699 (0.0683)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.989)	
2022-05-12 03:11:03,189: ============================================================
2022-05-12 03:11:49,827: time cost, forward:0.17245868767824774, backward:0.10445456923769335, data cost:0.19027294245366408 
2022-05-12 03:11:49,827: ============================================================
2022-05-12 03:11:49,827: Epoch 37/38 Batch 6500/7662 eta: 1:08:35.877227	Training Loss 0.0691 (0.0683)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.989)	
2022-05-12 03:11:49,827: ============================================================
2022-05-12 03:12:36,493: time cost, forward:0.17244835553123727, backward:0.10445606070840913, data cost:0.19026796795017956 
2022-05-12 03:12:36,493: ============================================================
2022-05-12 03:12:36,493: Epoch 37/38 Batch 6600/7662 eta: 1:07:51.593409	Training Loss 0.0698 (0.0683)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.989)	
2022-05-12 03:12:36,493: ============================================================
2022-05-12 03:13:23,122: time cost, forward:0.17243612867840227, backward:0.10445630121522918, data cost:0.19026275794351968 
2022-05-12 03:13:23,122: ============================================================
2022-05-12 03:13:23,122: Epoch 37/38 Batch 6700/7662 eta: 1:07:01.775367	Training Loss 0.0694 (0.0683)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.989)	
2022-05-12 03:13:23,123: ============================================================
2022-05-12 03:14:09,728: time cost, forward:0.17242460504036158, backward:0.1044562711560002, data cost:0.19025403465448293 
2022-05-12 03:14:09,728: ============================================================
2022-05-12 03:14:09,728: Epoch 37/38 Batch 6800/7662 eta: 1:06:13.136272	Training Loss 0.0717 (0.0683)	Training Prec@1 99.805 (99.973)	Training Prec@5 99.805 (99.989)	
2022-05-12 03:14:09,728: ============================================================
2022-05-12 03:14:56,353: time cost, forward:0.17241767071730713, backward:0.10445658772522892, data cost:0.19024395579824518 
2022-05-12 03:14:56,353: ============================================================
2022-05-12 03:14:56,354: Epoch 37/38 Batch 6900/7662 eta: 1:05:28.187043	Training Loss 0.0646 (0.0683)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.989)	
2022-05-12 03:14:56,354: ============================================================
2022-05-12 03:15:42,955: time cost, forward:0.17240788259068834, backward:0.10445632602780491, data cost:0.1902343626958436 
2022-05-12 03:15:42,955: ============================================================
2022-05-12 03:15:42,955: Epoch 37/38 Batch 7000/7662 eta: 1:04:39.592920	Training Loss 0.0682 (0.0683)	Training Prec@1 99.805 (99.973)	Training Prec@5 99.805 (99.989)	
2022-05-12 03:15:42,955: ============================================================
2022-05-12 03:16:29,554: time cost, forward:0.17240002726581605, backward:0.10445681607694689, data cost:0.19022241151237138 
2022-05-12 03:16:29,554: ============================================================
2022-05-12 03:16:29,555: Epoch 37/38 Batch 7100/7662 eta: 1:03:52.794829	Training Loss 0.0771 (0.0684)	Training Prec@1 99.609 (99.972)	Training Prec@5 99.609 (99.989)	
2022-05-12 03:16:29,555: ============================================================
2022-05-12 03:17:16,140: time cost, forward:0.17239167707167427, backward:0.10445647545035705, data cost:0.19021036850444012 
2022-05-12 03:17:16,140: ============================================================
2022-05-12 03:17:16,141: Epoch 37/38 Batch 7200/7662 eta: 1:03:05.107461	Training Loss 0.0704 (0.0684)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.989)	
2022-05-12 03:17:16,141: ============================================================
2022-05-12 03:18:02,722: time cost, forward:0.17238354392207833, backward:0.10445642840422936, data cost:0.1901978433809961 
2022-05-12 03:18:02,722: ============================================================
2022-05-12 03:18:02,723: Epoch 37/38 Batch 7300/7662 eta: 1:02:18.212581	Training Loss 0.0728 (0.0684)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.989)	
2022-05-12 03:18:02,723: ============================================================
2022-05-12 03:18:49,318: time cost, forward:0.17237521007361, backward:0.10445718704679396, data cost:0.19018726494525282 
2022-05-12 03:18:49,319: ============================================================
2022-05-12 03:18:49,319: Epoch 37/38 Batch 7400/7662 eta: 1:01:32.749851	Training Loss 0.0729 (0.0684)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.989)	
2022-05-12 03:18:49,319: ============================================================
2022-05-12 03:19:35,915: time cost, forward:0.17236916801741575, backward:0.10445669009250265, data cost:0.19017597754361837 
2022-05-12 03:19:35,915: ============================================================
2022-05-12 03:19:35,916: Epoch 37/38 Batch 7500/7662 eta: 1:00:46.191473	Training Loss 0.0665 (0.0684)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.989)	
2022-05-12 03:19:35,916: ============================================================
2022-05-12 03:20:22,520: time cost, forward:0.1723624434435363, backward:0.10445738208970046, data cost:0.19016614633573484 
2022-05-12 03:20:22,520: ============================================================
2022-05-12 03:20:22,521: Epoch 37/38 Batch 7600/7662 eta: 1:00:00.240119	Training Loss 0.0686 (0.0684)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.989)	
2022-05-12 03:20:22,521: ============================================================
2022-05-12 03:20:53,292: Epoch: 37/38 eta: 0:59:30.878938	Training Loss 0.0685 (0.0684)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.989)
2022-05-12 03:20:53,293: ============================================================
2022-05-12 03:20:53,408: Save Checkpoint...
2022-05-12 03:20:53,432: ============================================================
2022-05-12 03:20:56,408: Save done!
2022-05-12 03:20:56,408: ============================================================
2022-05-12 03:21:46,216: time cost, forward:0.18505537871158484, backward:0.10417615524446121, data cost:0.21133830812242296 
2022-05-12 03:21:46,217: ============================================================
2022-05-12 03:21:46,217: Epoch 38/38 Batch 100/7662 eta: 1:02:44.268789	Training Loss 0.0634 (0.0671)	Training Prec@1 100.000 (99.961)	Training Prec@5 100.000 (99.986)	
2022-05-12 03:21:46,217: ============================================================
2022-05-12 03:22:32,853: time cost, forward:0.17844781564108692, backward:0.10421551531882742, data cost:0.20058841441743938 
2022-05-12 03:22:32,853: ============================================================
2022-05-12 03:22:32,853: Epoch 38/38 Batch 200/7662 eta: 0:58:00.461720	Training Loss 0.0626 (0.0671)	Training Prec@1 100.000 (99.971)	Training Prec@5 100.000 (99.989)	
2022-05-12 03:22:32,853: ============================================================
2022-05-12 03:23:19,534: time cost, forward:0.17631154714220743, backward:0.10426895753994435, data cost:0.19708477772996577 
2022-05-12 03:23:19,534: ============================================================
2022-05-12 03:23:19,534: Epoch 38/38 Batch 300/7662 eta: 0:57:17.129385	Training Loss 0.0643 (0.0670)	Training Prec@1 100.000 (99.969)	Training Prec@5 100.000 (99.988)	
2022-05-12 03:23:19,534: ============================================================
2022-05-12 03:24:06,218: time cost, forward:0.17517006905156568, backward:0.10430755352316644, data cost:0.1953558856084532 
2022-05-12 03:24:06,218: ============================================================
2022-05-12 03:24:06,218: Epoch 38/38 Batch 400/7662 eta: 0:56:30.643700	Training Loss 0.0664 (0.0670)	Training Prec@1 100.000 (99.970)	Training Prec@5 100.000 (99.988)	
2022-05-12 03:24:06,218: ============================================================
2022-05-12 03:24:52,886: time cost, forward:0.17446477857524742, backward:0.10432029917149362, data cost:0.19434041107345917 
2022-05-12 03:24:52,886: ============================================================
2022-05-12 03:24:52,886: Epoch 38/38 Batch 500/7662 eta: 0:55:42.829539	Training Loss 0.0669 (0.0669)	Training Prec@1 100.000 (99.971)	Training Prec@5 100.000 (99.990)	
2022-05-12 03:24:52,886: ============================================================
2022-05-12 03:25:39,549: time cost, forward:0.17403031470182542, backward:0.10433488974786163, data cost:0.193631238650798 
2022-05-12 03:25:39,549: ============================================================
2022-05-12 03:25:39,549: Epoch 38/38 Batch 600/7662 eta: 0:54:55.810476	Training Loss 0.0680 (0.0671)	Training Prec@1 99.805 (99.971)	Training Prec@5 100.000 (99.990)	
2022-05-12 03:25:39,549: ============================================================
2022-05-12 03:26:26,252: time cost, forward:0.17369485378947552, backward:0.1043390119195155, data cost:0.19319823678470988 
2022-05-12 03:26:26,253: ============================================================
2022-05-12 03:26:26,253: Epoch 38/38 Batch 700/7662 eta: 0:54:11.969771	Training Loss 0.0635 (0.0671)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.990)	
2022-05-12 03:26:26,253: ============================================================
2022-05-12 03:27:12,938: time cost, forward:0.17346416158282266, backward:0.10433862982166275, data cost:0.19284893365318098 
2022-05-12 03:27:12,938: ============================================================
2022-05-12 03:27:12,939: Epoch 38/38 Batch 800/7662 eta: 0:53:24.043498	Training Loss 0.0723 (0.0670)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.991)	
2022-05-12 03:27:12,939: ============================================================
2022-05-12 03:27:59,609: time cost, forward:0.17331107519359823, backward:0.10434524156360393, data cost:0.19252642800200634 
2022-05-12 03:27:59,609: ============================================================
2022-05-12 03:27:59,609: Epoch 38/38 Batch 900/7662 eta: 0:52:36.327030	Training Loss 0.0721 (0.0671)	Training Prec@1 100.000 (99.972)	Training Prec@5 100.000 (99.991)	
2022-05-12 03:27:59,609: ============================================================
2022-05-12 03:28:46,268: time cost, forward:0.173155205385821, backward:0.1043387516602143, data cost:0.19229439739231113 
2022-05-12 03:28:46,268: ============================================================
2022-05-12 03:28:46,268: Epoch 38/38 Batch 1000/7662 eta: 0:51:48.916186	Training Loss 0.0652 (0.0671)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.991)	
2022-05-12 03:28:46,269: ============================================================
2022-05-12 03:29:32,902: time cost, forward:0.17302157577327212, backward:0.10434026887353927, data cost:0.19208905456063963 
2022-05-12 03:29:32,903: ============================================================
2022-05-12 03:29:32,903: Epoch 38/38 Batch 1100/7662 eta: 0:51:00.599438	Training Loss 0.0630 (0.0671)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.991)	
2022-05-12 03:29:32,903: ============================================================
2022-05-12 03:30:19,643: time cost, forward:0.17293319073789212, backward:0.1043434373729919, data cost:0.1919624077667287 
2022-05-12 03:30:19,644: ============================================================
2022-05-12 03:30:19,644: Epoch 38/38 Batch 1200/7662 eta: 0:50:20.885172	Training Loss 0.0625 (0.0671)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.991)	
2022-05-12 03:30:19,644: ============================================================
2022-05-12 03:31:06,379: time cost, forward:0.17284872056522033, backward:0.10434468256867419, data cost:0.1918639230030697 
2022-05-12 03:31:06,379: ============================================================
2022-05-12 03:31:06,380: Epoch 38/38 Batch 1300/7662 eta: 0:49:33.790111	Training Loss 0.0663 (0.0671)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.991)	
2022-05-12 03:31:06,380: ============================================================
2022-05-12 03:31:53,192: time cost, forward:0.17280253961820785, backward:0.10434671262914236, data cost:0.19182182380861687 
2022-05-12 03:31:53,192: ============================================================
2022-05-12 03:31:53,193: Epoch 38/38 Batch 1400/7662 eta: 0:48:51.896724	Training Loss 0.0696 (0.0671)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.991)	
2022-05-12 03:31:53,193: ============================================================
2022-05-12 03:32:40,036: time cost, forward:0.17277753170209378, backward:0.10435382822022747, data cost:0.19178647816857153 
2022-05-12 03:32:40,036: ============================================================
2022-05-12 03:32:40,036: Epoch 38/38 Batch 1500/7662 eta: 0:48:06.976757	Training Loss 0.0652 (0.0671)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.991)	
2022-05-12 03:32:40,036: ============================================================
2022-05-12 03:33:26,751: time cost, forward:0.17273047881397774, backward:0.10436094247079626, data cost:0.19169123251785555 
2022-05-12 03:33:26,752: ============================================================
2022-05-12 03:33:26,752: Epoch 38/38 Batch 1600/7662 eta: 0:47:12.376846	Training Loss 0.0646 (0.0672)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.991)	
2022-05-12 03:33:26,752: ============================================================
2022-05-12 03:34:13,556: time cost, forward:0.17272477096638447, backward:0.1043664808481002, data cost:0.19163165322607442 
2022-05-12 03:34:13,556: ============================================================
2022-05-12 03:34:13,556: Epoch 38/38 Batch 1700/7662 eta: 0:46:30.930433	Training Loss 0.0684 (0.0672)	Training Prec@1 99.805 (99.975)	Training Prec@5 99.805 (99.991)	
2022-05-12 03:34:13,556: ============================================================
2022-05-12 03:35:00,408: time cost, forward:0.1727104350021642, backward:0.10443100298425102, data cost:0.19155612370913527 
2022-05-12 03:35:00,408: ============================================================
2022-05-12 03:35:00,408: Epoch 38/38 Batch 1800/7662 eta: 0:45:46.951785	Training Loss 0.0696 (0.0672)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.991)	
2022-05-12 03:35:00,409: ============================================================
2022-05-12 03:35:47,196: time cost, forward:0.17269402758079558, backward:0.10445418428156865, data cost:0.19149157070623943 
2022-05-12 03:35:47,196: ============================================================
2022-05-12 03:35:47,196: Epoch 38/38 Batch 1900/7662 eta: 0:44:56.376425	Training Loss 0.0710 (0.0672)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.991)	
2022-05-12 03:35:47,196: ============================================================
2022-05-12 03:36:33,971: time cost, forward:0.17266953450670952, backward:0.10445776720414346, data cost:0.19143849196822837 
2022-05-12 03:36:33,971: ============================================================
2022-05-12 03:36:33,971: Epoch 38/38 Batch 2000/7662 eta: 0:44:08.884633	Training Loss 0.0696 (0.0673)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.991)	
2022-05-12 03:36:33,972: ============================================================
2022-05-12 03:37:20,735: time cost, forward:0.17265270334473673, backward:0.10446055245547138, data cost:0.19139560169694309 
2022-05-12 03:37:20,736: ============================================================
2022-05-12 03:37:20,736: Epoch 38/38 Batch 2100/7662 eta: 0:43:21.498187	Training Loss 0.0674 (0.0673)	Training Prec@1 99.805 (99.975)	Training Prec@5 99.805 (99.991)	
2022-05-12 03:37:20,736: ============================================================
2022-05-12 03:38:07,480: time cost, forward:0.17262346867053494, backward:0.1044618567318849, data cost:0.19135704849350718 
2022-05-12 03:38:07,481: ============================================================
2022-05-12 03:38:07,481: Epoch 38/38 Batch 2200/7662 eta: 0:42:33.677677	Training Loss 0.0687 (0.0673)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.991)	
2022-05-12 03:38:07,481: ============================================================
2022-05-12 03:38:54,257: time cost, forward:0.17261223618804813, backward:0.10446359832269204, data cost:0.1913255150808672 
2022-05-12 03:38:54,258: ============================================================
2022-05-12 03:38:54,258: Epoch 38/38 Batch 2300/7662 eta: 0:41:48.659854	Training Loss 0.0645 (0.0673)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.991)	
2022-05-12 03:38:54,258: ============================================================
2022-05-12 03:39:40,993: time cost, forward:0.17258217375494134, backward:0.10446188250100827, data cost:0.1912977210478566 
2022-05-12 03:39:40,993: ============================================================
2022-05-12 03:39:40,993: Epoch 38/38 Batch 2400/7662 eta: 0:40:59.674513	Training Loss 0.0664 (0.0673)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.991)	
2022-05-12 03:39:40,993: ============================================================
2022-05-12 03:40:27,749: time cost, forward:0.17256991736361293, backward:0.10446027108505755, data cost:0.19126089261311824 
2022-05-12 03:40:27,749: ============================================================
2022-05-12 03:40:27,749: Epoch 38/38 Batch 2500/7662 eta: 0:40:14.024973	Training Loss 0.0663 (0.0673)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.991)	
2022-05-12 03:40:27,749: ============================================================
2022-05-12 03:41:14,476: time cost, forward:0.1725515692726655, backward:0.10445957479223741, data cost:0.19123013444293596 
2022-05-12 03:41:14,477: ============================================================
2022-05-12 03:41:14,477: Epoch 38/38 Batch 2600/7662 eta: 0:39:25.811645	Training Loss 0.0686 (0.0674)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.991)	
2022-05-12 03:41:14,477: ============================================================
2022-05-12 03:42:01,277: time cost, forward:0.17254130069129156, backward:0.10445936780012992, data cost:0.19121674927750001 
2022-05-12 03:42:01,277: ============================================================
2022-05-12 03:42:01,277: Epoch 38/38 Batch 2700/7662 eta: 0:38:42.709036	Training Loss 0.0694 (0.0674)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.991)	
2022-05-12 03:42:01,277: ============================================================
2022-05-12 03:42:48,055: time cost, forward:0.17253414823907579, backward:0.1044621650727147, data cost:0.19119440491346854 
2022-05-12 03:42:48,056: ============================================================
2022-05-12 03:42:48,056: Epoch 38/38 Batch 2800/7662 eta: 0:37:54.836801	Training Loss 0.0692 (0.0674)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.991)	
2022-05-12 03:42:48,056: ============================================================
2022-05-12 03:43:34,797: time cost, forward:0.17252383169613036, backward:0.10446541422027766, data cost:0.19116186955831263 
2022-05-12 03:43:34,798: ============================================================
2022-05-12 03:43:34,798: Epoch 38/38 Batch 2900/7662 eta: 0:37:06.320363	Training Loss 0.0725 (0.0674)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.991)	
2022-05-12 03:43:34,798: ============================================================
2022-05-12 03:44:21,566: time cost, forward:0.17250621521540505, backward:0.10446776823824189, data cost:0.19114860434180778 
2022-05-12 03:44:21,566: ============================================================
2022-05-12 03:44:21,566: Epoch 38/38 Batch 3000/7662 eta: 0:36:20.800084	Training Loss 0.0673 (0.0674)	Training Prec@1 100.000 (99.976)	Training Prec@5 100.000 (99.991)	
2022-05-12 03:44:21,566: ============================================================
2022-05-12 03:45:08,320: time cost, forward:0.17249529013213669, backward:0.10447632147058744, data cost:0.19112064854565572 
2022-05-12 03:45:08,320: ============================================================
2022-05-12 03:45:08,321: Epoch 38/38 Batch 3100/7662 eta: 0:35:33.411171	Training Loss 0.0657 (0.0674)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.991)	
2022-05-12 03:45:08,321: ============================================================
2022-05-12 03:45:55,099: time cost, forward:0.17249811921651828, backward:0.10447774845646783, data cost:0.19109319805838088 
2022-05-12 03:45:55,100: ============================================================
2022-05-12 03:45:55,100: Epoch 38/38 Batch 3200/7662 eta: 0:34:47.752752	Training Loss 0.0652 (0.0675)	Training Prec@1 100.000 (99.975)	Training Prec@5 100.000 (99.991)	
2022-05-12 03:45:55,100: ============================================================
2022-05-12 03:46:41,901: time cost, forward:0.17249378705610105, backward:0.10447926606579816, data cost:0.19107894790501406 
2022-05-12 03:46:41,901: ============================================================
2022-05-12 03:46:41,901: Epoch 38/38 Batch 3300/7662 eta: 0:34:01.946682	Training Loss 0.0699 (0.0675)	Training Prec@1 99.805 (99.975)	Training Prec@5 99.805 (99.990)	
2022-05-12 03:46:41,901: ============================================================
2022-05-12 03:47:28,710: time cost, forward:0.17248752272174653, backward:0.10448045455627351, data cost:0.19107357043664433 
2022-05-12 03:47:28,710: ============================================================
2022-05-12 03:47:28,711: Epoch 38/38 Batch 3400/7662 eta: 0:33:15.487602	Training Loss 0.0692 (0.0675)	Training Prec@1 99.805 (99.975)	Training Prec@5 100.000 (99.990)	
2022-05-12 03:47:28,711: ============================================================
2022-05-12 03:48:15,482: time cost, forward:0.17248894916871305, backward:0.10448236525416477, data cost:0.19105388348904567 
2022-05-12 03:48:15,483: ============================================================
2022-05-12 03:48:15,483: Epoch 38/38 Batch 3500/7662 eta: 0:32:27.125490	Training Loss 0.0681 (0.0675)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.990)	
2022-05-12 03:48:15,483: ============================================================
2022-05-12 03:49:02,224: time cost, forward:0.17248396132846247, backward:0.10448386292220421, data cost:0.19103289915807184 
2022-05-12 03:49:02,225: ============================================================
2022-05-12 03:49:02,225: Epoch 38/38 Batch 3600/7662 eta: 0:31:39.129867	Training Loss 0.0644 (0.0675)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.990)	
2022-05-12 03:49:02,225: ============================================================
2022-05-12 03:49:48,886: time cost, forward:0.17247288160692778, backward:0.10448374777879223, data cost:0.1909966568071541 
2022-05-12 03:49:48,886: ============================================================
2022-05-12 03:49:48,886: Epoch 38/38 Batch 3700/7662 eta: 0:30:49.200242	Training Loss 0.0678 (0.0675)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.990)	
2022-05-12 03:49:48,887: ============================================================
2022-05-12 03:50:35,540: time cost, forward:0.17245959200084632, backward:0.10448276572994383, data cost:0.19096634500307233 
2022-05-12 03:50:35,540: ============================================================
2022-05-12 03:50:35,540: Epoch 38/38 Batch 3800/7662 eta: 0:30:02.244851	Training Loss 0.0676 (0.0675)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.990)	
2022-05-12 03:50:35,541: ============================================================
2022-05-12 03:51:22,296: time cost, forward:0.17245503186140038, backward:0.10448144374367029, data cost:0.19095646897839655 
2022-05-12 03:51:22,296: ============================================================
2022-05-12 03:51:22,296: Epoch 38/38 Batch 3900/7662 eta: 0:29:19.411630	Training Loss 0.0659 (0.0676)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.990)	
2022-05-12 03:51:22,296: ============================================================
2022-05-12 03:52:09,044: time cost, forward:0.17244633026914793, backward:0.10447916092649642, data cost:0.19095056776584282 
2022-05-12 03:52:09,044: ============================================================
2022-05-12 03:52:09,044: Epoch 38/38 Batch 4000/7662 eta: 0:28:32.389000	Training Loss 0.0708 (0.0676)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.990)	
2022-05-12 03:52:09,044: ============================================================
2022-05-12 03:52:55,728: time cost, forward:0.17243644893969173, backward:0.10447779478867422, data cost:0.19092978073579853 
2022-05-12 03:52:55,728: ============================================================
2022-05-12 03:52:55,728: Epoch 38/38 Batch 4100/7662 eta: 0:27:43.356884	Training Loss 0.0646 (0.0676)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.990)	
2022-05-12 03:52:55,729: ============================================================
2022-05-12 03:53:42,383: time cost, forward:0.1724285084056014, backward:0.10447546407477462, data cost:0.19090264574293012 
2022-05-12 03:53:42,383: ============================================================
2022-05-12 03:53:42,383: Epoch 38/38 Batch 4200/7662 eta: 0:26:55.654599	Training Loss 0.0679 (0.0676)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.990)	
2022-05-12 03:53:42,383: ============================================================
2022-05-12 03:54:29,045: time cost, forward:0.17242020550204532, backward:0.10447432718101726, data cost:0.19087673803073468 
2022-05-12 03:54:29,045: ============================================================
2022-05-12 03:54:29,045: Epoch 38/38 Batch 4300/7662 eta: 0:26:09.245840	Training Loss 0.0784 (0.0676)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.990)	
2022-05-12 03:54:29,045: ============================================================
2022-05-12 03:55:15,773: time cost, forward:0.17241271275448566, backward:0.10447370038571263, data cost:0.1908627445249564 
2022-05-12 03:55:15,774: ============================================================
2022-05-12 03:55:15,774: Epoch 38/38 Batch 4400/7662 eta: 0:25:24.748921	Training Loss 0.0715 (0.0676)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.990)	
2022-05-12 03:55:15,774: ============================================================
2022-05-12 03:56:02,467: time cost, forward:0.1724091283637541, backward:0.10447460366609654, data cost:0.19083907784925988 
2022-05-12 03:56:02,467: ============================================================
2022-05-12 03:56:02,468: Epoch 38/38 Batch 4500/7662 eta: 0:24:36.923973	Training Loss 0.0649 (0.0677)	Training Prec@1 99.805 (99.974)	Training Prec@5 100.000 (99.990)	
2022-05-12 03:56:02,468: ============================================================
2022-05-12 03:56:49,112: time cost, forward:0.17239924424833566, backward:0.10447406908770597, data cost:0.19081551345904824 
2022-05-12 03:56:49,112: ============================================================
2022-05-12 03:56:49,112: Epoch 38/38 Batch 4600/7662 eta: 0:23:48.722861	Training Loss 0.0667 (0.0677)	Training Prec@1 100.000 (99.974)	Training Prec@5 100.000 (99.990)	
2022-05-12 03:56:49,112: ============================================================
2022-05-12 03:57:35,861: time cost, forward:0.17238151674499966, backward:0.10447561170071028, data cost:0.1908167193458039 
2022-05-12 03:57:35,861: ============================================================
2022-05-12 03:57:35,861: Epoch 38/38 Batch 4700/7662 eta: 0:23:05.184083	Training Loss 0.0706 (0.0677)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.990)	
2022-05-12 03:57:35,862: ============================================================
2022-05-12 03:58:22,538: time cost, forward:0.1723713125629111, backward:0.10447742234023567, data cost:0.19080042729752342 
2022-05-12 03:58:22,550: ============================================================
2022-05-12 03:58:22,551: Epoch 38/38 Batch 4800/7662 eta: 0:22:16.710606	Training Loss 0.0684 (0.0677)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.990)	
2022-05-12 03:58:22,551: ============================================================
2022-05-12 03:59:09,258: time cost, forward:0.1723678348063936, backward:0.10447761651860814, data cost:0.19078886078240603 
2022-05-12 03:59:09,258: ============================================================
2022-05-12 03:59:09,258: Epoch 38/38 Batch 4900/7662 eta: 0:21:30.524522	Training Loss 0.0655 (0.0677)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.990)	
2022-05-12 03:59:09,258: ============================================================
2022-05-12 03:59:55,914: time cost, forward:0.1723620486178382, backward:0.10447614344150263, data cost:0.19076903735811554 
2022-05-12 03:59:55,914: ============================================================
2022-05-12 03:59:55,914: Epoch 38/38 Batch 5000/7662 eta: 0:20:42.455633	Training Loss 0.0642 (0.0677)	Training Prec@1 99.805 (99.973)	Training Prec@5 100.000 (99.990)	
2022-05-12 03:59:55,914: ============================================================
2022-05-12 04:00:42,488: time cost, forward:0.17234993663622505, backward:0.1044739470525825, data cost:0.19074152586249235 
2022-05-12 04:00:42,488: ============================================================
2022-05-12 04:00:42,488: Epoch 38/38 Batch 5100/7662 eta: 0:19:53.690126	Training Loss 0.0717 (0.0678)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.990)	
2022-05-12 04:00:42,488: ============================================================
2022-05-12 04:01:29,083: time cost, forward:0.17233742881587066, backward:0.10447254866952047, data cost:0.19071951300438883 
2022-05-12 04:01:29,083: ============================================================
2022-05-12 04:01:29,083: Epoch 38/38 Batch 5200/7662 eta: 0:19:07.641111	Training Loss 0.0720 (0.0678)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.990)	
2022-05-12 04:01:29,084: ============================================================
2022-05-12 04:02:15,730: time cost, forward:0.17232952533656415, backward:0.10447026423900437, data cost:0.1907047251301636 
2022-05-12 04:02:15,730: ============================================================
2022-05-12 04:02:15,730: Epoch 38/38 Batch 5300/7662 eta: 0:18:22.267620	Training Loss 0.0648 (0.0678)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.990)	
2022-05-12 04:02:15,731: ============================================================
2022-05-12 04:03:02,396: time cost, forward:0.17231885524431098, backward:0.10446897646435369, data cost:0.19069179823540344 
2022-05-12 04:03:02,396: ============================================================
2022-05-12 04:03:02,396: Epoch 38/38 Batch 5400/7662 eta: 0:17:36.040970	Training Loss 0.0715 (0.0678)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.990)	
2022-05-12 04:03:02,396: ============================================================
2022-05-12 04:03:49,065: time cost, forward:0.17232284486933305, backward:0.10446931414440298, data cost:0.19066874147176874 
2022-05-12 04:03:49,065: ============================================================
2022-05-12 04:03:49,065: Epoch 38/38 Batch 5500/7662 eta: 0:16:49.459441	Training Loss 0.0625 (0.0678)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.990)	
2022-05-12 04:03:49,065: ============================================================
2022-05-12 04:04:35,654: time cost, forward:0.17231328769717222, backward:0.10446856281207617, data cost:0.19064665121741753 
2022-05-12 04:04:35,654: ============================================================
2022-05-12 04:04:35,654: Epoch 38/38 Batch 5600/7662 eta: 0:16:01.126028	Training Loss 0.0711 (0.0678)	Training Prec@1 99.805 (99.973)	Training Prec@5 100.000 (99.990)	
2022-05-12 04:04:35,654: ============================================================
2022-05-12 04:05:22,214: time cost, forward:0.17230192626394877, backward:0.10446660366784608, data cost:0.19062381109494372 
2022-05-12 04:05:22,214: ============================================================
2022-05-12 04:05:22,214: Epoch 38/38 Batch 5700/7662 eta: 0:15:13.974034	Training Loss 0.0710 (0.0678)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.990)	
2022-05-12 04:05:22,214: ============================================================
2022-05-12 04:06:08,804: time cost, forward:0.1722953641470146, backward:0.1044654250864449, data cost:0.19060154256378295 
2022-05-12 04:06:08,804: ============================================================
2022-05-12 04:06:08,804: Epoch 38/38 Batch 5800/7662 eta: 0:14:27.969020	Training Loss 0.0653 (0.0678)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.990)	
2022-05-12 04:06:08,804: ============================================================
2022-05-12 04:06:55,389: time cost, forward:0.1722882363044078, backward:0.10446470170571534, data cost:0.19057969550679024 
2022-05-12 04:06:55,389: ============================================================
2022-05-12 04:06:55,389: Epoch 38/38 Batch 5900/7662 eta: 0:13:41.296337	Training Loss 0.0713 (0.0678)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.990)	
2022-05-12 04:06:55,389: ============================================================
2022-05-12 04:07:41,985: time cost, forward:0.1722812014711879, backward:0.10446427662902363, data cost:0.1905603065830923 
2022-05-12 04:07:41,985: ============================================================
2022-05-12 04:07:41,986: Epoch 38/38 Batch 6000/7662 eta: 0:12:54.898164	Training Loss 0.0680 (0.0678)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.990)	
2022-05-12 04:07:41,986: ============================================================
2022-05-12 04:08:28,591: time cost, forward:0.1722758415195273, backward:0.10446286776120946, data cost:0.190541959938641 
2022-05-12 04:08:28,591: ============================================================
2022-05-12 04:08:28,592: Epoch 38/38 Batch 6100/7662 eta: 0:12:08.449517	Training Loss 0.0679 (0.0678)	Training Prec@1 99.805 (99.973)	Training Prec@5 100.000 (99.990)	
2022-05-12 04:08:28,592: ============================================================
2022-05-12 04:09:15,169: time cost, forward:0.17226744586564896, backward:0.10446136519685448, data cost:0.19052355022925796 
2022-05-12 04:09:15,169: ============================================================
2022-05-12 04:09:15,169: Epoch 38/38 Batch 6200/7662 eta: 0:11:21.436190	Training Loss 0.0710 (0.0679)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.990)	
2022-05-12 04:09:15,170: ============================================================
2022-05-12 04:10:01,763: time cost, forward:0.1722609162576654, backward:0.10446060125856935, data cost:0.19050582338276506 
2022-05-12 04:10:01,764: ============================================================
2022-05-12 04:10:01,764: Epoch 38/38 Batch 6300/7662 eta: 0:10:35.080781	Training Loss 0.0710 (0.0679)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.990)	
2022-05-12 04:10:01,764: ============================================================
2022-05-12 04:10:48,357: time cost, forward:0.17225531548853124, backward:0.10445986671137761, data cost:0.19048785854082664 
2022-05-12 04:10:48,357: ============================================================
2022-05-12 04:10:48,357: Epoch 38/38 Batch 6400/7662 eta: 0:09:48.476696	Training Loss 0.0711 (0.0679)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.990)	
2022-05-12 04:10:48,357: ============================================================
2022-05-12 04:11:34,954: time cost, forward:0.1722492827582605, backward:0.10445904133778056, data cost:0.1904716577909968 
2022-05-12 04:11:34,954: ============================================================
2022-05-12 04:11:34,954: Epoch 38/38 Batch 6500/7662 eta: 0:09:01.921273	Training Loss 0.0676 (0.0679)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.990)	
2022-05-12 04:11:34,954: ============================================================
2022-05-12 04:12:21,530: time cost, forward:0.17224146832406728, backward:0.1044579502813273, data cost:0.19045514243175485 
2022-05-12 04:12:21,530: ============================================================
2022-05-12 04:12:21,531: Epoch 38/38 Batch 6600/7662 eta: 0:08:15.106367	Training Loss 0.0678 (0.0679)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.990)	
2022-05-12 04:12:21,531: ============================================================
2022-05-12 04:13:08,094: time cost, forward:0.17223204742849613, backward:0.10445695824544098, data cost:0.19043900023860563 
2022-05-12 04:13:08,094: ============================================================
2022-05-12 04:13:08,094: Epoch 38/38 Batch 6700/7662 eta: 0:07:28.407292	Training Loss 0.0707 (0.0679)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.990)	
2022-05-12 04:13:08,094: ============================================================
2022-05-12 04:13:54,696: time cost, forward:0.1722290715078586, backward:0.10445636516985674, data cost:0.1904225244927466 
2022-05-12 04:13:54,696: ============================================================
2022-05-12 04:13:54,697: Epoch 38/38 Batch 6800/7662 eta: 0:06:42.178256	Training Loss 0.0672 (0.0679)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.990)	
2022-05-12 04:13:54,697: ============================================================
2022-05-12 04:14:41,284: time cost, forward:0.17222195007538757, backward:0.10445658147015387, data cost:0.19040784851021136 
2022-05-12 04:14:41,284: ============================================================
2022-05-12 04:14:41,284: Epoch 38/38 Batch 6900/7662 eta: 0:05:55.462406	Training Loss 0.0742 (0.0679)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.990)	
2022-05-12 04:14:41,284: ============================================================
2022-05-12 04:15:27,866: time cost, forward:0.17221517184067153, backward:0.10445625776221946, data cost:0.19039319092622056 
2022-05-12 04:15:27,866: ============================================================
2022-05-12 04:15:27,866: Epoch 38/38 Batch 7000/7662 eta: 0:05:08.841855	Training Loss 0.0722 (0.0680)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.990)	
2022-05-12 04:15:27,867: ============================================================
2022-05-12 04:16:14,447: time cost, forward:0.1722082674612477, backward:0.10445639361359903, data cost:0.19037867529423477 
2022-05-12 04:16:14,447: ============================================================
2022-05-12 04:16:14,447: Epoch 38/38 Batch 7100/7662 eta: 0:04:22.248597	Training Loss 0.0689 (0.0680)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.990)	
2022-05-12 04:16:14,447: ============================================================
2022-05-12 04:17:01,025: time cost, forward:0.17220182232698444, backward:0.1044551653901079, data cost:0.1903653151460084 
2022-05-12 04:17:01,025: ============================================================
2022-05-12 04:17:01,025: Epoch 38/38 Batch 7200/7662 eta: 0:03:35.658136	Training Loss 0.0696 (0.0680)	Training Prec@1 99.805 (99.973)	Training Prec@5 100.000 (99.990)	
2022-05-12 04:17:01,026: ============================================================
2022-05-12 04:17:47,673: time cost, forward:0.17220237778055944, backward:0.1044546350222252, data cost:0.19035458871805108 
2022-05-12 04:17:47,673: ============================================================
2022-05-12 04:17:47,674: Epoch 38/38 Batch 7300/7662 eta: 0:02:49.332672	Training Loss 0.0692 (0.0680)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.990)	
2022-05-12 04:17:47,674: ============================================================
2022-05-12 04:18:34,264: time cost, forward:0.17219723593723066, backward:0.10445386417041938, data cost:0.19034245252963708 
2022-05-12 04:18:34,265: ============================================================
2022-05-12 04:18:34,265: Epoch 38/38 Batch 7400/7662 eta: 0:02:02.534566	Training Loss 0.0706 (0.0680)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.990)	
2022-05-12 04:18:34,265: ============================================================
2022-05-12 04:19:20,836: time cost, forward:0.17219129160636742, backward:0.10445253625522058, data cost:0.1903296461867116 
2022-05-12 04:19:20,837: ============================================================
2022-05-12 04:19:20,837: Epoch 38/38 Batch 7500/7662 eta: 0:01:15.912623	Training Loss 0.0705 (0.0680)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.990)	
2022-05-12 04:19:20,837: ============================================================
2022-05-12 04:20:07,412: time cost, forward:0.1721857306925556, backward:0.10445117818664479, data cost:0.19031747100635302 
2022-05-12 04:20:07,412: ============================================================
2022-05-12 04:20:07,412: Epoch 38/38 Batch 7600/7662 eta: 0:00:29.342376	Training Loss 0.0742 (0.0680)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.990)	
2022-05-12 04:20:07,412: ============================================================
2022-05-12 04:20:38,105: Epoch: 38/38 eta: 0:00:00	Training Loss 0.0693 (0.0681)	Training Prec@1 100.000 (99.973)	Training Prec@5 100.000 (99.990)
2022-05-12 04:20:38,106: ============================================================
2022-05-12 04:20:38,161: Save Checkpoint...
2022-05-12 04:20:38,178: ============================================================
2022-05-12 04:20:40,555: Save done!
2022-05-12 04:20:40,555: ============================================================
