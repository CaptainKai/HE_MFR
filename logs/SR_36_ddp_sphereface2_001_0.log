2022-03-29 08:10:50,359: [('name', 'amsoft-36'), ('backbone_model_name', 'SimpleResnet_36'), ('classify_model_name', 'Sphereface2'), ('resume_net_model', None), ('resume_net_classifier', None), ('no_cuda', False), ('gpu_num', 1), ('log_interval', 100), ('log_path', './logs/SR_36_ddp_sphereface2_001.log'), ('log_pic_path', './logs/pic/SR_36_ddp_sphereface2_001/'), ('save_path', 'snapshot/SR_36_ddp_sphereface2_001/'), ('lmdb_path', '/home/ubuntu/data4/lk/data/lmdb_default'), ('batch_size', 512), ('datanum', 3923399), ('num_class', 86876), ('lmdb_workers', 4), ('num_workers', 4), ('start_epoch', 1), ('max_epoch', 31), ('lr', 0.001), ('base', 'epoch'), ('step_size', [10, 20, 30, 40]), ('momentum', 0.9), ('gama', 0.1), ('weight_decay', 0.0005), ('rank', 0), ('dist_url', 'env://'), ('world_size', 2), ('gpu', 0), ('dist_backend', 'nccl'), ('distributed', True), ('master_port', 22000), ('multiprocessing_distributed', False), ('SEED', 1337), ('local_rank', 0)]
2022-03-29 08:10:50,359: SimpleResidualBackbone(
  (conv1): ConvPrelu(
    (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (prelu): PReLU(num_parameters=64)
  )
  (layer1): Sequential(
    (0): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=64)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=64)
      )
    )
    (1): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=64)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=64)
      )
    )
  )
  (conv2): ConvPrelu(
    (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (prelu): PReLU(num_parameters=128)
  )
  (layer2): Sequential(
    (0): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
    )
    (1): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
    )
    (2): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
    )
    (3): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=128)
      )
    )
  )
  (conv3): ConvPrelu(
    (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (prelu): PReLU(num_parameters=256)
  )
  (layer3): Sequential(
    (0): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
    (1): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
    (2): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
    (3): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
    (4): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
    (5): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
    (6): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
    (7): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=256)
      )
    )
  )
  (conv4): ConvPrelu(
    (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (prelu): PReLU(num_parameters=512)
  )
  (layer4): Sequential(
    (0): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=512)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=512)
      )
    )
    (1): SimpleResidualUnit(
      (conv1): ConvPrelu(
        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=512)
      )
      (conv2): ConvPrelu(
        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (prelu): PReLU(num_parameters=512)
      )
    )
  )
  (fc5): Linear(in_features=25088, out_features=512, bias=True)
)
2022-03-29 08:10:50,973: data balance
2022-03-29 08:11:25,660: time cost, forward:0.11740163119152339, backward:0.043522355532405355, data cost:0.1850144863128662 
2022-03-29 08:11:25,661: ============================================================
2022-03-29 08:11:25,661: Epoch 1/31 Batch 100/7662 eta: 22:43:47.575792	Training Loss 0.8627 (0.8654)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.004)	
2022-03-29 08:11:25,661: ============================================================
2022-03-29 08:11:57,515: time cost, forward:0.11338228556379001, backward:0.038392846907802564, data cost:0.18020853924391858 
2022-03-29 08:11:57,516: ============================================================
2022-03-29 08:11:57,516: Epoch 1/31 Batch 200/7662 eta: 20:59:59.352031	Training Loss 0.8576 (0.8624)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.003)	
2022-03-29 08:11:57,516: ============================================================
2022-03-29 08:12:29,421: time cost, forward:0.11193790722850175, backward:0.036572136607855854, data cost:0.17902937541438585 
2022-03-29 08:12:29,422: ============================================================
2022-03-29 08:12:29,422: Epoch 1/31 Batch 300/7662 eta: 21:01:28.457240	Training Loss 0.8522 (0.8601)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.006)	
2022-03-29 08:12:29,422: ============================================================
2022-03-29 08:13:01,386: time cost, forward:0.11115962162352445, backward:0.03568352971758161, data cost:0.17861423934611462 
2022-03-29 08:13:01,387: ============================================================
2022-03-29 08:13:01,387: Epoch 1/31 Batch 400/7662 eta: 21:03:16.241240	Training Loss 0.8513 (0.8581)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.006)	
2022-03-29 08:13:01,387: ============================================================
2022-03-29 08:13:33,498: time cost, forward:0.1106833900382858, backward:0.035122713727320364, data cost:0.17869681251311828 
2022-03-29 08:13:33,498: ============================================================
2022-03-29 08:13:33,498: Epoch 1/31 Batch 500/7662 eta: 21:08:30.877244	Training Loss 0.8487 (0.8565)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.006)	
2022-03-29 08:13:33,498: ============================================================
2022-03-29 08:14:05,810: time cost, forward:0.1104158419798531, backward:0.03489964673037521, data cost:0.1788992834011581 
2022-03-29 08:14:05,811: ============================================================
2022-03-29 08:14:05,811: Epoch 1/31 Batch 600/7662 eta: 21:15:56.583770	Training Loss 0.8470 (0.8550)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.006)	
2022-03-29 08:14:05,811: ============================================================
2022-03-29 08:14:38,393: time cost, forward:0.11030101844340094, backward:0.03467662242349125, data cost:0.17941200852564645 
2022-03-29 08:14:38,393: ============================================================
2022-03-29 08:14:38,393: Epoch 1/31 Batch 700/7662 eta: 21:26:02.552417	Training Loss 0.8468 (0.8538)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.006)	
2022-03-29 08:14:38,394: ============================================================
2022-03-29 08:15:11,158: time cost, forward:0.11018957035413224, backward:0.03443153748971798, data cost:0.1801222325564923 
2022-03-29 08:15:11,159: ============================================================
2022-03-29 08:15:11,159: Epoch 1/31 Batch 800/7662 eta: 21:32:43.640659	Training Loss 0.8443 (0.8526)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.006)	
2022-03-29 08:15:11,159: ============================================================
2022-03-29 08:15:44,164: time cost, forward:0.11007996475338538, backward:0.03424802505399812, data cost:0.18095334512373232 
2022-03-29 08:15:44,165: ============================================================
2022-03-29 08:15:44,165: Epoch 1/31 Batch 900/7662 eta: 21:41:40.201004	Training Loss 0.8424 (0.8516)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.007)	
2022-03-29 08:15:44,165: ============================================================
2022-03-29 08:16:19,546: time cost, forward:0.11002475482684833, backward:0.034007650237899645, data cost:0.18406918003513767 
2022-03-29 08:16:19,547: ============================================================
2022-03-29 08:16:19,547: Epoch 1/31 Batch 1000/7662 eta: 23:14:45.794097	Training Loss 0.8416 (0.8506)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.007)	
2022-03-29 08:16:19,547: ============================================================
2022-03-29 08:16:54,449: time cost, forward:0.10994913558508723, backward:0.033768306980358674, data cost:0.1862617673604894 
2022-03-29 08:16:54,450: ============================================================
2022-03-29 08:16:54,450: Epoch 1/31 Batch 1100/7662 eta: 22:55:18.983766	Training Loss 0.8410 (0.8498)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.007)	
2022-03-29 08:16:54,450: ============================================================
2022-03-29 08:17:30,143: time cost, forward:0.10986526475736158, backward:0.03378299577122832, data cost:0.1885273156313224 
2022-03-29 08:17:30,144: ============================================================
2022-03-29 08:17:30,145: Epoch 1/31 Batch 1200/7662 eta: 23:25:54.513183	Training Loss 0.8391 (0.8490)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.007)	
2022-03-29 08:17:30,145: ============================================================
2022-03-29 08:18:07,360: time cost, forward:0.10986346423947141, backward:0.0339168217477659, data cost:0.1914489157297136 
2022-03-29 08:18:07,360: ============================================================
2022-03-29 08:18:07,360: Epoch 1/31 Batch 1300/7662 eta: 1 day, 0:25:12.006193	Training Loss 0.8394 (0.8483)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.007)	
2022-03-29 08:18:07,361: ============================================================
2022-03-29 08:18:45,418: time cost, forward:0.10982157861956364, backward:0.03384940806587225, data cost:0.19478442414987931 
2022-03-29 08:18:45,419: ============================================================
2022-03-29 08:18:45,419: Epoch 1/31 Batch 1400/7662 eta: 1 day, 0:57:44.811277	Training Loss 0.8384 (0.8476)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.007)	
2022-03-29 08:18:45,419: ============================================================
2022-03-29 08:19:21,844: time cost, forward:0.10981592661225852, backward:0.033862183776356684, data cost:0.19646806936410366 
2022-03-29 08:19:21,845: ============================================================
2022-03-29 08:19:21,845: Epoch 1/31 Batch 1500/7662 eta: 23:52:53.772585	Training Loss 0.8379 (0.8470)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.007)	
2022-03-29 08:19:21,845: ============================================================
2022-03-29 08:19:59,641: time cost, forward:0.1098253576363378, backward:0.033908509253859145, data cost:0.1987282810843386 
2022-03-29 08:19:59,641: ============================================================
2022-03-29 08:19:59,641: Epoch 1/31 Batch 1600/7662 eta: 1 day, 0:46:11.086043	Training Loss 0.8382 (0.8464)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.008)	
2022-03-29 08:19:59,642: ============================================================
2022-03-29 08:20:37,289: time cost, forward:0.10982050300696936, backward:0.033887130502674986, data cost:0.20075063048705696 
2022-03-29 08:20:37,290: ============================================================
2022-03-29 08:20:37,290: Epoch 1/31 Batch 1700/7662 eta: 1 day, 0:39:43.838941	Training Loss 0.8366 (0.8458)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.008)	
2022-03-29 08:20:37,290: ============================================================
2022-03-29 08:21:16,451: time cost, forward:0.10984065374975538, backward:0.033814490272178456, data cost:0.20341066243318534 
2022-03-29 08:21:16,452: ============================================================
2022-03-29 08:21:16,452: Epoch 1/31 Batch 1800/7662 eta: 1 day, 1:38:33.680949	Training Loss 0.8355 (0.8453)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.007)	
2022-03-29 08:21:16,452: ============================================================
2022-03-29 08:21:53,962: time cost, forward:0.1098389967044069, backward:0.033814181899823534, data cost:0.20482407901838243 
2022-03-29 08:21:53,963: ============================================================
2022-03-29 08:21:53,963: Epoch 1/31 Batch 1900/7662 eta: 1 day, 0:33:04.905678	Training Loss 0.8366 (0.8448)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.008)	
2022-03-29 08:21:53,963: ============================================================
2022-03-29 08:22:33,343: time cost, forward:0.10981387624506833, backward:0.033756472815150554, data cost:0.2071980095434451 
2022-03-29 08:22:33,344: ============================================================
2022-03-29 08:22:33,345: Epoch 1/31 Batch 2000/7662 eta: 1 day, 1:45:52.745193	Training Loss 0.8365 (0.8444)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.008)	
2022-03-29 08:22:33,345: ============================================================
2022-03-29 08:23:16,082: time cost, forward:0.10980205424573661, backward:0.033703717690186596, data cost:0.21083042734063426 
2022-03-29 08:23:16,082: ============================================================
2022-03-29 08:23:16,082: Epoch 1/31 Batch 2100/7662 eta: 1 day, 3:56:54.419779	Training Loss 0.8352 (0.8439)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.007)	
2022-03-29 08:23:16,083: ============================================================
2022-03-29 08:23:55,153: time cost, forward:0.10981752971130482, backward:0.03364801558650261, data cost:0.21256826443258012 
2022-03-29 08:23:55,154: ============================================================
2022-03-29 08:23:55,154: Epoch 1/31 Batch 2200/7662 eta: 1 day, 1:32:25.152954	Training Loss 0.8354 (0.8435)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.007)	
2022-03-29 08:23:55,155: ============================================================
2022-03-29 08:24:34,859: time cost, forward:0.10981831098442857, backward:0.033614977902565485, data cost:0.21435199130250351 
2022-03-29 08:24:34,860: ============================================================
2022-03-29 08:24:34,860: Epoch 1/31 Batch 2300/7662 eta: 1 day, 1:56:37.342311	Training Loss 0.8344 (0.8431)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.008)	
2022-03-29 08:24:34,860: ============================================================
2022-03-29 08:25:15,248: time cost, forward:0.10981397958734027, backward:0.0335461375811737, data cost:0.21635267107424114 
2022-03-29 08:25:15,248: ============================================================
2022-03-29 08:25:15,249: Epoch 1/31 Batch 2400/7662 eta: 1 day, 2:22:42.422400	Training Loss 0.8349 (0.8428)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.008)	
2022-03-29 08:25:15,249: ============================================================
2022-03-29 08:25:55,763: time cost, forward:0.10981616834584786, backward:0.033573655139546056, data cost:0.21811111873032904 
2022-03-29 08:25:55,764: ============================================================
2022-03-29 08:25:55,764: Epoch 1/31 Batch 2500/7662 eta: 1 day, 2:27:00.884932	Training Loss 0.8343 (0.8424)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.008)	
2022-03-29 08:25:55,764: ============================================================
2022-03-29 08:26:36,448: time cost, forward:0.10980473935214223, backward:0.0335784945500819, data cost:0.21985472363203754 
2022-03-29 08:26:36,448: ============================================================
2022-03-29 08:26:36,448: Epoch 1/31 Batch 2600/7662 eta: 1 day, 2:32:56.787483	Training Loss 0.8334 (0.8421)	Training Prec@1 0.195 (0.002)	Training Prec@5 0.195 (0.009)	
2022-03-29 08:26:36,449: ============================================================
2022-03-29 08:27:27,760: time cost, forward:0.10977389548345158, backward:0.033566465109266495, data cost:0.22538980319350682 
2022-03-29 08:27:27,761: ============================================================
2022-03-29 08:27:27,761: Epoch 1/31 Batch 2700/7662 eta: 1 day, 9:28:13.485251	Training Loss 0.8332 (0.8417)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.009)	
2022-03-29 08:27:27,761: ============================================================
2022-03-29 08:28:13,154: time cost, forward:0.10975117400613331, backward:0.0336432005516671, data cost:0.22838424094535062 
2022-03-29 08:28:13,155: ============================================================
2022-03-29 08:28:13,155: Epoch 1/31 Batch 2800/7662 eta: 1 day, 5:35:50.656250	Training Loss 0.8329 (0.8414)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.009)	
2022-03-29 08:28:13,155: ============================================================
2022-03-29 08:28:58,156: time cost, forward:0.10973205587789082, backward:0.03373534328240944, data cost:0.2309976957221819 
2022-03-29 08:28:58,156: ============================================================
2022-03-29 08:28:58,157: Epoch 1/31 Batch 2900/7662 eta: 1 day, 5:19:43.845596	Training Loss 0.8330 (0.8411)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.009)	
2022-03-29 08:28:58,157: ============================================================
2022-03-29 08:29:43,287: time cost, forward:0.10971856101348663, backward:0.03382157110778361, data cost:0.2334735118456386 
2022-03-29 08:29:43,287: ============================================================
2022-03-29 08:29:43,288: Epoch 1/31 Batch 3000/7662 eta: 1 day, 5:24:02.196686	Training Loss 0.8326 (0.8408)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.009)	
2022-03-29 08:29:43,288: ============================================================
2022-03-29 08:30:28,382: time cost, forward:0.10970432876040374, backward:0.03389359120593297, data cost:0.23578961521012046 
2022-03-29 08:30:28,383: ============================================================
2022-03-29 08:30:28,383: Epoch 1/31 Batch 3100/7662 eta: 1 day, 5:21:54.829803	Training Loss 0.8322 (0.8406)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.009)	
2022-03-29 08:30:28,384: ============================================================
2022-03-29 08:31:13,556: time cost, forward:0.10970347961361387, backward:0.03398620705933972, data cost:0.2379477813341499 
2022-03-29 08:31:13,556: ============================================================
2022-03-29 08:31:13,557: Epoch 1/31 Batch 3200/7662 eta: 1 day, 5:24:11.446350	Training Loss 0.8318 (0.8403)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.009)	
2022-03-29 08:31:13,557: ============================================================
2022-03-29 08:31:58,766: time cost, forward:0.10969267537572883, backward:0.03406707385555474, data cost:0.2400045701322067 
2022-03-29 08:31:58,767: ============================================================
2022-03-29 08:31:58,767: Epoch 1/31 Batch 3300/7662 eta: 1 day, 5:24:53.030348	Training Loss 0.8318 (0.8400)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.009)	
2022-03-29 08:31:58,767: ============================================================
2022-03-29 08:32:43,976: time cost, forward:0.1096763871774564, backward:0.0341420454921425, data cost:0.24194364745534844 
2022-03-29 08:32:43,977: ============================================================
2022-03-29 08:32:43,977: Epoch 1/31 Batch 3400/7662 eta: 1 day, 5:24:06.830326	Training Loss 0.8319 (0.8398)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.195 (0.009)	
2022-03-29 08:32:43,977: ============================================================
2022-03-29 08:33:29,193: time cost, forward:0.10966011748105399, backward:0.03425383949388808, data cost:0.24373454725991048 
2022-03-29 08:33:29,193: ============================================================
2022-03-29 08:33:29,194: Epoch 1/31 Batch 3500/7662 eta: 1 day, 5:23:37.572316	Training Loss 0.8311 (0.8396)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.009)	
2022-03-29 08:33:29,194: ============================================================
2022-03-29 08:34:14,411: time cost, forward:0.10965150930908661, backward:0.03436712266074581, data cost:0.24541292809287388 
2022-03-29 08:34:14,411: ============================================================
2022-03-29 08:34:14,412: Epoch 1/31 Batch 3600/7662 eta: 1 day, 5:22:55.496631	Training Loss 0.8308 (0.8393)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.010)	
2022-03-29 08:34:14,412: ============================================================
2022-03-29 08:34:59,687: time cost, forward:0.10963034455793617, backward:0.03444843860728317, data cost:0.24705544005345254 
2022-03-29 08:34:59,688: ============================================================
2022-03-29 08:34:59,688: Epoch 1/31 Batch 3700/7662 eta: 1 day, 5:24:27.204493	Training Loss 0.8311 (0.8391)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.010)	
2022-03-29 08:34:59,689: ============================================================
2022-03-29 08:35:45,042: time cost, forward:0.10961884566124065, backward:0.03451423338759287, data cost:0.24863438381587685 
2022-03-29 08:35:45,043: ============================================================
2022-03-29 08:35:45,043: Epoch 1/31 Batch 3800/7662 eta: 1 day, 5:26:44.171211	Training Loss 0.8308 (0.8389)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.010)	
2022-03-29 08:35:45,043: ============================================================
2022-03-29 08:36:30,414: time cost, forward:0.10960889999974718, backward:0.03451822408806761, data cost:0.25018998151193617 
2022-03-29 08:36:30,415: ============================================================
2022-03-29 08:36:30,415: Epoch 1/31 Batch 3900/7662 eta: 1 day, 5:26:40.300331	Training Loss 0.8305 (0.8387)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.010)	
2022-03-29 08:36:30,416: ============================================================
2022-03-29 08:37:15,786: time cost, forward:0.10960008758817741, backward:0.034456578157162125, data cost:0.2517364810901631 
2022-03-29 08:37:15,786: ============================================================
2022-03-29 08:37:15,787: Epoch 1/31 Batch 4000/7662 eta: 1 day, 5:25:52.577864	Training Loss 0.8303 (0.8385)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.010)	
2022-03-29 08:37:15,787: ============================================================
2022-03-29 08:38:01,215: time cost, forward:0.10958944276705926, backward:0.034388128738049674, data cost:0.25323331207727684 
2022-03-29 08:38:01,216: ============================================================
2022-03-29 08:38:01,216: Epoch 1/31 Batch 4100/7662 eta: 1 day, 5:27:21.988213	Training Loss 0.8304 (0.8383)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.010)	
2022-03-29 08:38:01,216: ============================================================
2022-03-29 08:38:46,661: time cost, forward:0.10957784486912807, backward:0.03434776709062141, data cost:0.25464148031981054 
2022-03-29 08:38:46,662: ============================================================
2022-03-29 08:38:46,662: Epoch 1/31 Batch 4200/7662 eta: 1 day, 5:27:15.714364	Training Loss 0.8289 (0.8381)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.010)	
2022-03-29 08:38:46,662: ============================================================
2022-03-29 08:39:32,151: time cost, forward:0.10954151959939457, backward:0.03430823082978239, data cost:0.2560189689251123 
2022-03-29 08:39:32,151: ============================================================
2022-03-29 08:39:32,152: Epoch 1/31 Batch 4300/7662 eta: 1 day, 5:28:12.754045	Training Loss 0.8308 (0.8379)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.010)	
2022-03-29 08:39:32,152: ============================================================
2022-03-29 08:40:17,684: time cost, forward:0.10949338222259987, backward:0.03425554070426107, data cost:0.2573708151925502 
2022-03-29 08:40:17,684: ============================================================
2022-03-29 08:40:17,685: Epoch 1/31 Batch 4400/7662 eta: 1 day, 5:29:08.055645	Training Loss 0.8302 (0.8377)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.010)	
2022-03-29 08:40:17,685: ============================================================
2022-03-29 08:41:03,223: time cost, forward:0.10944660532922315, backward:0.03415520076196335, data cost:0.2587159706449795 
2022-03-29 08:41:03,224: ============================================================
2022-03-29 08:41:03,224: Epoch 1/31 Batch 4500/7662 eta: 1 day, 5:28:36.694059	Training Loss 0.8304 (0.8376)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.010)	
2022-03-29 08:41:03,224: ============================================================
2022-03-29 08:41:48,736: time cost, forward:0.1094117219563696, backward:0.03409898319978459, data cost:0.2599477975828333 
2022-03-29 08:41:48,736: ============================================================
2022-03-29 08:41:48,737: Epoch 1/31 Batch 4600/7662 eta: 1 day, 5:26:49.666916	Training Loss 0.8293 (0.8374)	Training Prec@1 0.195 (0.002)	Training Prec@5 0.195 (0.010)	
2022-03-29 08:41:48,737: ============================================================
2022-03-29 08:42:34,236: time cost, forward:0.10938581093039049, backward:0.03395586466378266, data cost:0.2612032456001238 
2022-03-29 08:42:34,236: ============================================================
2022-03-29 08:42:34,237: Epoch 1/31 Batch 4700/7662 eta: 1 day, 5:25:35.212711	Training Loss 0.8298 (0.8372)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.011)	
2022-03-29 08:42:34,237: ============================================================
2022-03-29 08:43:19,713: time cost, forward:0.10937793410353473, backward:0.03383213774714278, data cost:0.26237643711466074 
2022-03-29 08:43:19,713: ============================================================
2022-03-29 08:43:19,714: Epoch 1/31 Batch 4800/7662 eta: 1 day, 5:23:54.707407	Training Loss 0.8292 (0.8371)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.011)	
2022-03-29 08:43:19,714: ============================================================
2022-03-29 08:44:05,205: time cost, forward:0.10937105472975056, backward:0.033769772524346035, data cost:0.26344402071455836 
2022-03-29 08:44:05,205: ============================================================
2022-03-29 08:44:05,206: Epoch 1/31 Batch 4900/7662 eta: 1 day, 5:23:44.843198	Training Loss 0.8294 (0.8369)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.010)	
2022-03-29 08:44:05,206: ============================================================
2022-03-29 08:44:50,719: time cost, forward:0.10936786151213702, backward:0.033736208482464926, data cost:0.26444505376562066 
2022-03-29 08:44:50,720: ============================================================
2022-03-29 08:44:50,720: Epoch 1/31 Batch 5000/7662 eta: 1 day, 5:23:51.634041	Training Loss 0.8292 (0.8368)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.011)	
2022-03-29 08:44:50,720: ============================================================
2022-03-29 08:45:36,300: time cost, forward:0.10936309384654423, backward:0.033691609787178826, data cost:0.2654341431453336 
2022-03-29 08:45:36,301: ============================================================
2022-03-29 08:45:36,301: Epoch 1/31 Batch 5100/7662 eta: 1 day, 5:25:40.906271	Training Loss 0.8290 (0.8366)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.011)	
2022-03-29 08:45:36,301: ============================================================
2022-03-29 08:46:21,919: time cost, forward:0.1093603109575093, backward:0.0336578231656705, data cost:0.26638099261718795 
2022-03-29 08:46:21,920: ============================================================
2022-03-29 08:46:21,920: Epoch 1/31 Batch 5200/7662 eta: 1 day, 5:26:23.543930	Training Loss 0.8287 (0.8365)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.011)	
2022-03-29 08:46:21,920: ============================================================
2022-03-29 08:47:07,570: time cost, forward:0.10936096781356129, backward:0.0336294836493163, data cost:0.2672913478081756 
2022-03-29 08:47:07,571: ============================================================
2022-03-29 08:47:07,571: Epoch 1/31 Batch 5300/7662 eta: 1 day, 5:26:52.143376	Training Loss 0.8286 (0.8363)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.011)	
2022-03-29 08:47:07,571: ============================================================
2022-03-29 08:47:53,248: time cost, forward:0.10935498410009592, backward:0.03364854738610302, data cost:0.2681334798568751 
2022-03-29 08:47:53,248: ============================================================
2022-03-29 08:47:53,249: Epoch 1/31 Batch 5400/7662 eta: 1 day, 5:27:07.837243	Training Loss 0.8295 (0.8362)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.011)	
2022-03-29 08:47:53,249: ============================================================
2022-03-29 08:48:38,899: time cost, forward:0.10934908330646466, backward:0.03368619494621137, data cost:0.2689209257088741 
2022-03-29 08:48:38,899: ============================================================
2022-03-29 08:48:38,900: Epoch 1/31 Batch 5500/7662 eta: 1 day, 5:25:20.449702	Training Loss 0.8291 (0.8361)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.011)	
2022-03-29 08:48:38,900: ============================================================
2022-03-29 08:49:24,600: time cost, forward:0.10934073023549956, backward:0.03370010207691114, data cost:0.2697122392111068 
2022-03-29 08:49:24,601: ============================================================
2022-03-29 08:49:24,601: Epoch 1/31 Batch 5600/7662 eta: 1 day, 5:26:32.388128	Training Loss 0.8283 (0.8359)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.011)	
2022-03-29 08:49:24,601: ============================================================
2022-03-29 08:50:10,328: time cost, forward:0.10933684235937785, backward:0.03367657631316673, data cost:0.2705150327048274 
2022-03-29 08:50:10,328: ============================================================
2022-03-29 08:50:10,329: Epoch 1/31 Batch 5700/7662 eta: 1 day, 5:26:47.539858	Training Loss 0.8284 (0.8358)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.011)	
2022-03-29 08:50:10,329: ============================================================
2022-03-29 08:50:56,085: time cost, forward:0.10933350665669211, backward:0.03365689883007636, data cost:0.2712910815053283 
2022-03-29 08:50:56,086: ============================================================
2022-03-29 08:50:56,086: Epoch 1/31 Batch 5800/7662 eta: 1 day, 5:27:09.931149	Training Loss 0.8291 (0.8357)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.011)	
2022-03-29 08:50:56,086: ============================================================
2022-03-29 08:51:41,782: time cost, forward:0.10933034883593883, backward:0.03364173301823525, data cost:0.2720268555951737 
2022-03-29 08:51:41,782: ============================================================
2022-03-29 08:51:41,782: Epoch 1/31 Batch 5900/7662 eta: 1 day, 5:24:03.248703	Training Loss 0.8277 (0.8356)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.011)	
2022-03-29 08:51:41,783: ============================================================
2022-03-29 08:52:27,503: time cost, forward:0.10932985030128313, backward:0.033618750860739156, data cost:0.27274859899440435 
2022-03-29 08:52:27,503: ============================================================
2022-03-29 08:52:27,504: Epoch 1/31 Batch 6000/7662 eta: 1 day, 5:24:14.921077	Training Loss 0.8288 (0.8354)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.011)	
2022-03-29 08:52:27,504: ============================================================
2022-03-29 08:53:13,232: time cost, forward:0.10932601199890477, backward:0.03360941680186419, data cost:0.2734369217987861 
2022-03-29 08:53:13,232: ============================================================
2022-03-29 08:53:13,233: Epoch 1/31 Batch 6100/7662 eta: 1 day, 5:23:47.771488	Training Loss 0.8275 (0.8353)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.011)	
2022-03-29 08:53:13,233: ============================================================
2022-03-29 08:53:59,022: time cost, forward:0.1093194000104451, backward:0.03358866372672295, data cost:0.27412736175482955 
2022-03-29 08:53:59,022: ============================================================
2022-03-29 08:53:59,022: Epoch 1/31 Batch 6200/7662 eta: 1 day, 5:25:22.271052	Training Loss 0.8277 (0.8352)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.011)	
2022-03-29 08:53:59,023: ============================================================
2022-03-29 08:54:44,797: time cost, forward:0.10931589459971712, backward:0.03357314794739952, data cost:0.2747884697527294 
2022-03-29 08:54:44,798: ============================================================
2022-03-29 08:54:44,798: Epoch 1/31 Batch 6300/7662 eta: 1 day, 5:24:03.900717	Training Loss 0.8285 (0.8351)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.011)	
2022-03-29 08:54:44,798: ============================================================
2022-03-29 08:55:30,570: time cost, forward:0.10931336780994605, backward:0.03354886685112227, data cost:0.2754351362471917 
2022-03-29 08:55:30,570: ============================================================
2022-03-29 08:55:30,571: Epoch 1/31 Batch 6400/7662 eta: 1 day, 5:23:10.784080	Training Loss 0.8280 (0.8350)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.011)	
2022-03-29 08:55:30,571: ============================================================
2022-03-29 08:56:16,342: time cost, forward:0.10930858488944259, backward:0.033523157644792786, data cost:0.27606423797378504 
2022-03-29 08:56:16,343: ============================================================
2022-03-29 08:56:16,343: Epoch 1/31 Batch 6500/7662 eta: 1 day, 5:22:24.749945	Training Loss 0.8275 (0.8349)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.011)	
2022-03-29 08:56:16,343: ============================================================
2022-03-29 08:57:02,135: time cost, forward:0.10930370558281888, backward:0.03349932596021971, data cost:0.2766797150205637 
2022-03-29 08:57:02,136: ============================================================
2022-03-29 08:57:02,136: Epoch 1/31 Batch 6600/7662 eta: 1 day, 5:22:25.977495	Training Loss 0.8284 (0.8348)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.012)	
2022-03-29 08:57:02,136: ============================================================
2022-03-29 08:57:47,962: time cost, forward:0.10930252292295377, backward:0.03350357038438418, data cost:0.27725123319897765 
2022-03-29 08:57:47,962: ============================================================
2022-03-29 08:57:47,963: Epoch 1/31 Batch 6700/7662 eta: 1 day, 5:22:59.060620	Training Loss 0.8285 (0.8347)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.012)	
2022-03-29 08:57:47,963: ============================================================
2022-03-29 08:58:33,787: time cost, forward:0.10929575620775521, backward:0.033499551215650826, data cost:0.27781855030820063 
2022-03-29 08:58:33,787: ============================================================
2022-03-29 08:58:33,787: Epoch 1/31 Batch 6800/7662 eta: 1 day, 5:22:07.499603	Training Loss 0.8276 (0.8346)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.012)	
2022-03-29 08:58:33,787: ============================================================
2022-03-29 08:59:19,658: time cost, forward:0.10929213760382611, backward:0.03347591680622668, data cost:0.2783919357704 
2022-03-29 08:59:19,659: ============================================================
2022-03-29 08:59:19,659: Epoch 1/31 Batch 6900/7662 eta: 1 day, 5:23:10.938784	Training Loss 0.8277 (0.8345)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.012)	
2022-03-29 08:59:19,659: ============================================================
2022-03-29 09:00:05,550: time cost, forward:0.10930190390902837, backward:0.03345146174430166, data cost:0.27894043356950904 
2022-03-29 09:00:05,551: ============================================================
2022-03-29 09:00:05,551: Epoch 1/31 Batch 7000/7662 eta: 1 day, 5:23:12.157532	Training Loss 0.8289 (0.8344)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.012)	
2022-03-29 09:00:05,551: ============================================================
2022-03-29 09:00:51,636: time cost, forward:0.1094518361385145, backward:0.03343608409926192, data cost:0.27935153666575674 
2022-03-29 09:00:51,637: ============================================================
2022-03-29 09:00:51,637: Epoch 1/31 Batch 7100/7662 eta: 1 day, 5:29:52.856322	Training Loss 0.8278 (0.8343)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.012)	
2022-03-29 09:00:51,637: ============================================================
2022-03-29 09:01:38,052: time cost, forward:0.10977313369160677, backward:0.03344738501644015, data cost:0.2795944105901558 
2022-03-29 09:01:38,052: ============================================================
2022-03-29 09:01:38,053: Epoch 1/31 Batch 7200/7662 eta: 1 day, 5:41:45.066142	Training Loss 0.8277 (0.8342)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.012)	
2022-03-29 09:01:38,053: ============================================================
2022-03-29 09:02:24,493: time cost, forward:0.10999557285672068, backward:0.03345273161346022, data cost:0.2799442069859419 
2022-03-29 09:02:24,494: ============================================================
2022-03-29 09:02:24,495: Epoch 1/31 Batch 7300/7662 eta: 1 day, 5:41:59.650046	Training Loss 0.8277 (0.8341)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.012)	
2022-03-29 09:02:24,495: ============================================================
2022-03-29 09:03:11,001: time cost, forward:0.11029670782742718, backward:0.0334588228198125, data cost:0.2801840855698599 
2022-03-29 09:03:11,003: ============================================================
2022-03-29 09:03:11,003: Epoch 1/31 Batch 7400/7662 eta: 1 day, 5:43:47.051409	Training Loss 0.8282 (0.8340)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.012)	
2022-03-29 09:03:11,004: ============================================================
2022-03-29 09:03:57,649: time cost, forward:0.11061383409648914, backward:0.0334605069013576, data cost:0.2804216868655811 
2022-03-29 09:03:57,650: ============================================================
2022-03-29 09:03:57,650: Epoch 1/31 Batch 7500/7662 eta: 1 day, 5:48:18.993506	Training Loss 0.8268 (0.8339)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.012)	
2022-03-29 09:03:57,650: ============================================================
2022-03-29 09:04:44,381: time cost, forward:0.11095721502965462, backward:0.033480497987227374, data cost:0.2806144215304815 
2022-03-29 09:04:44,381: ============================================================
2022-03-29 09:04:44,382: Epoch 1/31 Batch 7600/7662 eta: 1 day, 5:50:46.650179	Training Loss 0.8278 (0.8339)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.012)	
2022-03-29 09:04:44,382: ============================================================
2022-03-29 09:05:14,476: Epoch: 1/31 eta: 1 day, 5:50:17.209284	Training Loss 0.8273 (0.8338)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.012)
2022-03-29 09:05:14,476: ============================================================
2022-03-29 09:06:03,649: time cost, forward:0.15406290690104166, backward:0.03897858388496168, data cost:0.2982516505501487 
2022-03-29 09:06:03,649: ============================================================
2022-03-29 09:06:03,650: Epoch 2/31 Batch 100/7662 eta: 1 day, 7:16:23.080084	Training Loss 0.8275 (0.8271)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.032)	
2022-03-29 09:06:03,650: ============================================================
2022-03-29 09:06:53,782: time cost, forward:0.1680877232671383, backward:0.041553242122707654, data cost:0.28656504142224487 
2022-03-29 09:06:53,782: ============================================================
2022-03-29 09:06:53,783: Epoch 2/31 Batch 200/7662 eta: 1 day, 7:58:56.137252	Training Loss 0.8275 (0.8271)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.026)	
2022-03-29 09:06:53,783: ============================================================
2022-03-29 09:07:43,630: time cost, forward:0.16640469780733752, backward:0.04106155685756518, data cost:0.28917704298344743 
2022-03-29 09:07:43,631: ============================================================
2022-03-29 09:07:43,632: Epoch 2/31 Batch 300/7662 eta: 1 day, 7:47:13.726556	Training Loss 0.8264 (0.8271)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.024)	
2022-03-29 09:07:43,632: ============================================================
2022-03-29 09:08:34,033: time cost, forward:0.16770582987849875, backward:0.04116024767844599, data cost:0.28948674942915303 
2022-03-29 09:08:34,033: ============================================================
2022-03-29 09:08:34,034: Epoch 2/31 Batch 400/7662 eta: 1 day, 8:07:32.744911	Training Loss 0.8266 (0.8271)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.022)	
2022-03-29 09:08:34,034: ============================================================
2022-03-29 09:09:25,208: time cost, forward:0.17007646006429364, backward:0.041625043911064315, data cost:0.2893823736416314 
2022-03-29 09:09:25,210: ============================================================
2022-03-29 09:09:25,210: Epoch 2/31 Batch 500/7662 eta: 1 day, 8:36:19.219444	Training Loss 0.8272 (0.8271)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.021)	
2022-03-29 09:09:25,211: ============================================================
2022-03-29 09:10:16,125: time cost, forward:0.17032524699559792, backward:0.04189884602924022, data cost:0.28999320493516617 
2022-03-29 09:10:16,125: ============================================================
2022-03-29 09:10:16,125: Epoch 2/31 Batch 600/7662 eta: 1 day, 8:25:28.852442	Training Loss 0.8272 (0.8271)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.021)	
2022-03-29 09:10:16,126: ============================================================
2022-03-29 09:11:05,624: time cost, forward:0.16836833817423327, backward:0.041697460182746594, data cost:0.2910671919712181 
2022-03-29 09:11:05,625: ============================================================
2022-03-29 09:11:05,625: Epoch 2/31 Batch 700/7662 eta: 1 day, 7:30:34.021335	Training Loss 0.8257 (0.8270)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.021)	
2022-03-29 09:11:05,626: ============================================================
2022-03-29 09:12:00,181: time cost, forward:0.17177429067924413, backward:0.04218573504604296, data cost:0.29266622875151554 
2022-03-29 09:12:00,181: ============================================================
2022-03-29 09:12:00,182: Epoch 2/31 Batch 800/7662 eta: 1 day, 10:42:47.773048	Training Loss 0.8273 (0.8270)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.020)	
2022-03-29 09:12:00,182: ============================================================
2022-03-29 09:12:53,605: time cost, forward:0.1738148380041918, backward:0.04238850945758077, data cost:0.29333213226946364 
2022-03-29 09:12:53,606: ============================================================
2022-03-29 09:12:53,606: Epoch 2/31 Batch 900/7662 eta: 1 day, 9:58:41.295621	Training Loss 0.8266 (0.8270)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.019)	
2022-03-29 09:12:53,607: ============================================================
2022-03-29 09:13:47,104: time cost, forward:0.17538262177277375, backward:0.04262671360859761, data cost:0.2941241634261978 
2022-03-29 09:13:47,104: ============================================================
2022-03-29 09:13:47,104: Epoch 2/31 Batch 1000/7662 eta: 1 day, 10:00:36.184156	Training Loss 0.8280 (0.8270)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.019)	
2022-03-29 09:13:47,104: ============================================================
2022-03-29 09:14:40,704: time cost, forward:0.1765836343860713, backward:0.04287397199809497, data cost:0.2948682787637476 
2022-03-29 09:14:40,704: ============================================================
2022-03-29 09:14:40,704: Epoch 2/31 Batch 1100/7662 eta: 1 day, 10:03:36.007591	Training Loss 0.8266 (0.8270)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.195 (0.018)	
2022-03-29 09:14:40,705: ============================================================
2022-03-29 09:15:32,908: time cost, forward:0.1765082389538839, backward:0.04279481698514224, data cost:0.29558635752234885 
2022-03-29 09:15:32,909: ============================================================
2022-03-29 09:15:32,909: Epoch 2/31 Batch 1200/7662 eta: 1 day, 9:09:31.985858	Training Loss 0.8271 (0.8269)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.018)	
2022-03-29 09:15:32,909: ============================================================
2022-03-29 09:16:25,373: time cost, forward:0.17737472800679902, backward:0.042834215479873525, data cost:0.29541454891501434 
2022-03-29 09:16:25,374: ============================================================
2022-03-29 09:16:25,374: Epoch 2/31 Batch 1300/7662 eta: 1 day, 9:18:34.021667	Training Loss 0.8265 (0.8269)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.018)	
2022-03-29 09:16:25,374: ============================================================
2022-03-29 09:17:21,741: time cost, forward:0.1796949710736878, backward:0.04310058678278674, data cost:0.29621544252386084 
2022-03-29 09:17:21,742: ============================================================
2022-03-29 09:17:21,742: Epoch 2/31 Batch 1400/7662 eta: 1 day, 11:46:19.131313	Training Loss 0.8271 (0.8269)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.195 (0.019)	
2022-03-29 09:17:21,743: ============================================================
2022-03-29 09:18:17,302: time cost, forward:0.18155478826755678, backward:0.04335783496548765, data cost:0.2965251508754758 
2022-03-29 09:18:17,303: ============================================================
2022-03-29 09:18:17,303: Epoch 2/31 Batch 1500/7662 eta: 1 day, 11:14:40.060533	Training Loss 0.8271 (0.8269)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.019)	
2022-03-29 09:18:17,303: ============================================================
2022-03-29 09:19:12,438: time cost, forward:0.18294983330631792, backward:0.04348068270107744, data cost:0.29683607246370297 
2022-03-29 09:19:12,439: ============================================================
2022-03-29 09:19:12,439: Epoch 2/31 Batch 1600/7662 eta: 1 day, 10:57:33.914025	Training Loss 0.8266 (0.8269)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.018)	
2022-03-29 09:19:12,439: ============================================================
2022-03-29 09:20:03,666: time cost, forward:0.18160303990373616, backward:0.04319948866621335, data cost:0.29778209302339786 
2022-03-29 09:20:03,667: ============================================================
2022-03-29 09:20:03,667: Epoch 2/31 Batch 1700/7662 eta: 1 day, 8:28:01.385620	Training Loss 0.8262 (0.8269)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.018)	
2022-03-29 09:20:03,667: ============================================================
2022-03-29 09:20:57,484: time cost, forward:0.1822745792066607, backward:0.043231201675482896, data cost:0.2979361133617848 
2022-03-29 09:20:57,485: ============================================================
2022-03-29 09:20:57,485: Epoch 2/31 Batch 1800/7662 eta: 1 day, 10:05:37.995306	Training Loss 0.8259 (0.8268)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.018)	
2022-03-29 09:20:57,485: ============================================================
2022-03-29 09:21:52,836: time cost, forward:0.18309532409595652, backward:0.043319242260467385, data cost:0.2985735822188471 
2022-03-29 09:21:52,837: ============================================================
2022-03-29 09:21:52,838: Epoch 2/31 Batch 1900/7662 eta: 1 day, 11:03:02.721703	Training Loss 0.8266 (0.8268)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.018)	
2022-03-29 09:21:52,838: ============================================================
2022-03-29 09:22:45,567: time cost, forward:0.18322147853139523, backward:0.043264855975923444, data cost:0.29864966076215904 
2022-03-29 09:22:45,567: ============================================================
2022-03-29 09:22:45,567: Epoch 2/31 Batch 2000/7662 eta: 1 day, 9:22:30.553388	Training Loss 0.8262 (0.8268)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.018)	
2022-03-29 09:22:45,568: ============================================================
2022-03-29 09:23:43,102: time cost, forward:0.18481889084556546, backward:0.043462880626640304, data cost:0.29918215898402023 
2022-03-29 09:23:43,103: ============================================================
2022-03-29 09:23:43,103: Epoch 2/31 Batch 2100/7662 eta: 1 day, 12:24:04.125339	Training Loss 0.8263 (0.8268)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.018)	
2022-03-29 09:23:43,103: ============================================================
2022-03-29 09:24:36,869: time cost, forward:0.18515976877199514, backward:0.04345064078639344, data cost:0.2993236132348977 
2022-03-29 09:24:36,870: ============================================================
2022-03-29 09:24:36,870: Epoch 2/31 Batch 2200/7662 eta: 1 day, 10:00:05.543703	Training Loss 0.8260 (0.8268)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.017)	
2022-03-29 09:24:36,870: ============================================================
2022-03-29 09:25:34,517: time cost, forward:0.18650344518435005, backward:0.0435312193546569, data cost:0.299957454178633 
2022-03-29 09:25:34,518: ============================================================
2022-03-29 09:25:34,518: Epoch 2/31 Batch 2300/7662 eta: 1 day, 12:26:25.016342	Training Loss 0.8262 (0.8268)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.017)	
2022-03-29 09:25:34,518: ============================================================
2022-03-29 09:26:32,396: time cost, forward:0.18776736213744508, backward:0.043634934343860364, data cost:0.30056701773849814 
2022-03-29 09:26:32,397: ============================================================
2022-03-29 09:26:32,397: Epoch 2/31 Batch 2400/7662 eta: 1 day, 12:34:12.646117	Training Loss 0.8266 (0.8267)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.017)	
2022-03-29 09:26:32,398: ============================================================
2022-03-29 09:27:28,604: time cost, forward:0.18856493374403593, backward:0.04373760440913426, data cost:0.3008908935430862 
2022-03-29 09:27:28,604: ============================================================
2022-03-29 09:27:28,604: Epoch 2/31 Batch 2500/7662 eta: 1 day, 11:29:52.592406	Training Loss 0.8264 (0.8267)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.017)	
2022-03-29 09:27:28,605: ============================================================
2022-03-29 09:28:21,685: time cost, forward:0.18869298841000154, backward:0.04377807814967591, data cost:0.30061072191397653 
2022-03-29 09:28:21,686: ============================================================
2022-03-29 09:28:21,686: Epoch 2/31 Batch 2600/7662 eta: 1 day, 9:30:34.190991	Training Loss 0.8263 (0.8267)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.016)	
2022-03-29 09:28:21,686: ============================================================
2022-03-29 09:29:16,907: time cost, forward:0.18896854237390032, backward:0.04382070155883993, data cost:0.300989840197625 
2022-03-29 09:29:16,908: ============================================================
2022-03-29 09:29:16,908: Epoch 2/31 Batch 2700/7662 eta: 1 day, 10:50:42.997177	Training Loss 0.8258 (0.8267)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.016)	
2022-03-29 09:29:16,908: ============================================================
2022-03-29 09:30:10,183: time cost, forward:0.18899970380013736, backward:0.04379876454671224, data cost:0.3009324699863871 
2022-03-29 09:30:10,184: ============================================================
2022-03-29 09:30:10,184: Epoch 2/31 Batch 2800/7662 eta: 1 day, 9:36:09.512128	Training Loss 0.8256 (0.8267)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.016)	
2022-03-29 09:30:10,184: ============================================================
2022-03-29 09:31:06,586: time cost, forward:0.18953854612499815, backward:0.04386155060053941, data cost:0.3013512791333917 
2022-03-29 09:31:06,587: ============================================================
2022-03-29 09:31:06,587: Epoch 2/31 Batch 2900/7662 eta: 1 day, 11:33:32.175658	Training Loss 0.8256 (0.8267)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.016)	
2022-03-29 09:31:06,587: ============================================================
2022-03-29 09:32:00,026: time cost, forward:0.18951149215774563, backward:0.04381352776326748, data cost:0.3014067561279022 
2022-03-29 09:32:00,026: ============================================================
2022-03-29 09:32:00,026: Epoch 2/31 Batch 3000/7662 eta: 1 day, 9:40:33.271804	Training Loss 0.8265 (0.8267)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.195 (0.016)	
2022-03-29 09:32:00,027: ============================================================
2022-03-29 09:32:54,608: time cost, forward:0.1895788166745319, backward:0.043781123649077706, data cost:0.3017176643191864 
2022-03-29 09:32:54,609: ============================================================
2022-03-29 09:32:54,609: Epoch 2/31 Batch 3100/7662 eta: 1 day, 10:22:52.189336	Training Loss 0.8260 (0.8267)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-29 09:32:54,609: ============================================================
2022-03-29 09:33:50,263: time cost, forward:0.19006526011830382, backward:0.04378332507427725, data cost:0.30188779787705744 
2022-03-29 09:33:50,263: ============================================================
2022-03-29 09:33:50,263: Epoch 2/31 Batch 3200/7662 eta: 1 day, 11:02:26.378326	Training Loss 0.8263 (0.8266)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.016)	
2022-03-29 09:33:50,264: ============================================================
2022-03-29 09:34:47,615: time cost, forward:0.19068558095404148, backward:0.043812981371664214, data cost:0.3023689954560538 
2022-03-29 09:34:47,616: ============================================================
2022-03-29 09:34:47,616: Epoch 2/31 Batch 3300/7662 eta: 1 day, 12:05:39.147726	Training Loss 0.8253 (0.8266)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-29 09:34:47,617: ============================================================
2022-03-29 09:35:41,454: time cost, forward:0.190799984100041, backward:0.043771958554552105, data cost:0.3023304165584545 
2022-03-29 09:35:41,454: ============================================================
2022-03-29 09:35:41,455: Epoch 2/31 Batch 3400/7662 eta: 1 day, 9:52:03.268168	Training Loss 0.8266 (0.8266)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.195 (0.017)	
2022-03-29 09:35:41,455: ============================================================
2022-03-29 09:36:37,672: time cost, forward:0.19155066331545603, backward:0.04383376156408196, data cost:0.3022390029947565 
2022-03-29 09:36:37,673: ============================================================
2022-03-29 09:36:37,673: Epoch 2/31 Batch 3500/7662 eta: 1 day, 11:20:56.580460	Training Loss 0.8259 (0.8266)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-29 09:36:37,673: ============================================================
2022-03-29 09:37:35,390: time cost, forward:0.19226358830514767, backward:0.043895207831978166, data cost:0.30254047279326113 
2022-03-29 09:37:35,390: ============================================================
2022-03-29 09:37:35,391: Epoch 2/31 Batch 3600/7662 eta: 1 day, 12:16:32.415942	Training Loss 0.8260 (0.8266)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.016)	
2022-03-29 09:37:35,391: ============================================================
2022-03-29 09:38:29,796: time cost, forward:0.19237030793216042, backward:0.04388664477127376, data cost:0.30257725850992445 
2022-03-29 09:38:29,797: ============================================================
2022-03-29 09:38:29,798: Epoch 2/31 Batch 3700/7662 eta: 1 day, 10:10:46.712826	Training Loss 0.8270 (0.8266)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-29 09:38:29,798: ============================================================
2022-03-29 09:39:25,505: time cost, forward:0.19270814635559708, backward:0.04392993371716986, data cost:0.3026687326981037 
2022-03-29 09:39:25,506: ============================================================
2022-03-29 09:39:25,506: Epoch 2/31 Batch 3800/7662 eta: 1 day, 10:58:54.829250	Training Loss 0.8262 (0.8266)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.016)	
2022-03-29 09:39:25,506: ============================================================
2022-03-29 09:40:24,286: time cost, forward:0.19341436047589483, backward:0.04402841443005327, data cost:0.3030899067541427 
2022-03-29 09:40:24,287: ============================================================
2022-03-29 09:40:24,287: Epoch 2/31 Batch 3900/7662 eta: 1 day, 12:53:42.242389	Training Loss 0.8248 (0.8266)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-29 09:40:24,287: ============================================================
2022-03-29 09:41:18,645: time cost, forward:0.19354810515592383, backward:0.04400848901161524, data cost:0.3030467803074617 
2022-03-29 09:41:18,646: ============================================================
2022-03-29 09:41:18,646: Epoch 2/31 Batch 4000/7662 eta: 1 day, 10:06:16.617737	Training Loss 0.8267 (0.8265)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-29 09:41:18,647: ============================================================
2022-03-29 09:42:17,601: time cost, forward:0.19426215541278424, backward:0.044075793829101505, data cost:0.30347167209579645 
2022-03-29 09:42:17,602: ============================================================
2022-03-29 09:42:17,602: Epoch 2/31 Batch 4100/7662 eta: 1 day, 12:58:19.493886	Training Loss 0.8260 (0.8265)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.016)	
2022-03-29 09:42:17,602: ============================================================
2022-03-29 09:43:13,098: time cost, forward:0.19446815590428068, backward:0.04409422400906757, data cost:0.3035157521187223 
2022-03-29 09:43:13,099: ============================================================
2022-03-29 09:43:13,099: Epoch 2/31 Batch 4200/7662 eta: 1 day, 10:47:14.929636	Training Loss 0.8251 (0.8265)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-29 09:43:13,099: ============================================================
2022-03-29 09:44:10,158: time cost, forward:0.1949289400207633, backward:0.04413393947462005, data cost:0.30368007663017815 
2022-03-29 09:44:10,159: ============================================================
2022-03-29 09:44:10,159: Epoch 2/31 Batch 4300/7662 eta: 1 day, 11:45:04.928466	Training Loss 0.8254 (0.8265)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.195 (0.017)	
2022-03-29 09:44:10,159: ============================================================
2022-03-29 09:45:06,604: time cost, forward:0.19516333560288887, backward:0.04418128147589182, data cost:0.30388004000985264 
2022-03-29 09:45:06,604: ============================================================
2022-03-29 09:45:06,605: Epoch 2/31 Batch 4400/7662 eta: 1 day, 11:21:02.799776	Training Loss 0.8262 (0.8265)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-29 09:45:06,605: ============================================================
2022-03-29 09:46:01,843: time cost, forward:0.19524151586272712, backward:0.044201988833669714, data cost:0.3039780677385027 
2022-03-29 09:46:01,844: ============================================================
2022-03-29 09:46:01,844: Epoch 2/31 Batch 4500/7662 eta: 1 day, 10:34:48.162895	Training Loss 0.8265 (0.8265)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.016)	
2022-03-29 09:46:01,845: ============================================================
2022-03-29 09:46:56,383: time cost, forward:0.19515472978424783, backward:0.04418973094303988, data cost:0.30410544108660176 
2022-03-29 09:46:56,383: ============================================================
2022-03-29 09:46:56,384: Epoch 2/31 Batch 4600/7662 eta: 1 day, 10:07:36.093658	Training Loss 0.8264 (0.8265)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.016)	
2022-03-29 09:46:56,384: ============================================================
2022-03-29 09:47:55,552: time cost, forward:0.1956764970796873, backward:0.04425196313786999, data cost:0.30454492827734303 
2022-03-29 09:47:55,552: ============================================================
2022-03-29 09:47:55,552: Epoch 2/31 Batch 4700/7662 eta: 1 day, 13:00:25.087259	Training Loss 0.8252 (0.8265)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.195 (0.016)	
2022-03-29 09:47:55,553: ============================================================
2022-03-29 09:48:50,661: time cost, forward:0.19581583808625483, backward:0.04426115571173262, data cost:0.3045176314075531 
2022-03-29 09:48:50,661: ============================================================
2022-03-29 09:48:50,662: Epoch 2/31 Batch 4800/7662 eta: 1 day, 10:27:09.694908	Training Loss 0.8257 (0.8265)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.016)	
2022-03-29 09:48:50,662: ============================================================
2022-03-29 09:49:49,706: time cost, forward:0.1963233424099301, backward:0.04436303187594362, data cost:0.3048378580758756 
2022-03-29 09:49:49,706: ============================================================
2022-03-29 09:49:49,707: Epoch 2/31 Batch 4900/7662 eta: 1 day, 12:53:47.780134	Training Loss 0.8264 (0.8264)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.016)	
2022-03-29 09:49:49,707: ============================================================
2022-03-29 09:50:45,723: time cost, forward:0.19648497532453268, backward:0.044381224267314404, data cost:0.304946152823857 
2022-03-29 09:50:45,723: ============================================================
2022-03-29 09:50:45,724: Epoch 2/31 Batch 5000/7662 eta: 1 day, 10:59:20.494038	Training Loss 0.8268 (0.8264)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.016)	
2022-03-29 09:50:45,724: ============================================================
2022-03-29 09:51:41,894: time cost, forward:0.1966618460097671, backward:0.044517365453944156, data cost:0.30493393522263695 
2022-03-29 09:51:41,894: ============================================================
2022-03-29 09:51:41,895: Epoch 2/31 Batch 5100/7662 eta: 1 day, 11:04:10.579556	Training Loss 0.8263 (0.8264)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.016)	
2022-03-29 09:51:41,895: ============================================================
2022-03-29 09:52:37,807: time cost, forward:0.1967060998853158, backward:0.044583998315264155, data cost:0.30506530915986896 
2022-03-29 09:52:37,807: ============================================================
2022-03-29 09:52:37,807: Epoch 2/31 Batch 5200/7662 eta: 1 day, 10:53:33.733531	Training Loss 0.8265 (0.8264)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.016)	
2022-03-29 09:52:37,807: ============================================================
2022-03-29 09:53:35,972: time cost, forward:0.19711802176291773, backward:0.04471344681455631, data cost:0.30517917890597296 
2022-03-29 09:53:35,973: ============================================================
2022-03-29 09:53:35,973: Epoch 2/31 Batch 5300/7662 eta: 1 day, 12:16:57.670762	Training Loss 0.8267 (0.8264)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.016)	
2022-03-29 09:53:35,973: ============================================================
2022-03-29 09:54:31,498: time cost, forward:0.19711383922737294, backward:0.04473286148441524, data cost:0.305310536411255 
2022-03-29 09:54:31,498: ============================================================
2022-03-29 09:54:31,499: Epoch 2/31 Batch 5400/7662 eta: 1 day, 10:37:13.181524	Training Loss 0.8252 (0.8264)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.016)	
2022-03-29 09:54:31,499: ============================================================
2022-03-29 09:55:27,073: time cost, forward:0.19722299186462358, backward:0.044744337964305055, data cost:0.3053372560533356 
2022-03-29 09:55:27,074: ============================================================
2022-03-29 09:55:27,074: Epoch 2/31 Batch 5500/7662 eta: 1 day, 10:38:10.375575	Training Loss 0.8252 (0.8264)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.016)	
2022-03-29 09:55:27,075: ============================================================
2022-03-29 09:56:26,324: time cost, forward:0.19757090021103785, backward:0.04479810305420129, data cost:0.30573402393884075 
2022-03-29 09:56:26,324: ============================================================
2022-03-29 09:56:26,325: Epoch 2/31 Batch 5600/7662 eta: 1 day, 12:54:35.071848	Training Loss 0.8258 (0.8264)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.016)	
2022-03-29 09:56:26,325: ============================================================
2022-03-29 09:57:23,648: time cost, forward:0.19766900141545818, backward:0.04482251779094749, data cost:0.3060463049638102 
2022-03-29 09:57:23,649: ============================================================
2022-03-29 09:57:23,649: Epoch 2/31 Batch 5700/7662 eta: 1 day, 11:41:39.249593	Training Loss 0.8259 (0.8264)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.016)	
2022-03-29 09:57:23,649: ============================================================
2022-03-29 09:58:21,350: time cost, forward:0.19793425668702289, backward:0.044846359872267066, data cost:0.3062402543414768 
2022-03-29 09:58:21,351: ============================================================
2022-03-29 09:58:21,351: Epoch 2/31 Batch 5800/7662 eta: 1 day, 11:54:47.075421	Training Loss 0.8248 (0.8264)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.016)	
2022-03-29 09:58:21,351: ============================================================
2022-03-29 09:59:18,669: time cost, forward:0.19816936167807353, backward:0.04487266441910403, data cost:0.3063819352641593 
2022-03-29 09:59:18,670: ============================================================
2022-03-29 09:59:18,671: Epoch 2/31 Batch 5900/7662 eta: 1 day, 11:39:34.448254	Training Loss 0.8264 (0.8263)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.016)	
2022-03-29 09:59:18,671: ============================================================
2022-03-29 10:00:13,318: time cost, forward:0.1980127567330049, backward:0.044851232596408684, data cost:0.3064962107850266 
2022-03-29 10:00:13,318: ============================================================
2022-03-29 10:00:13,319: Epoch 2/31 Batch 6000/7662 eta: 1 day, 9:58:55.397565	Training Loss 0.8249 (0.8263)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.016)	
2022-03-29 10:00:13,319: ============================================================
2022-03-29 10:01:13,604: time cost, forward:0.19856148908364615, backward:0.0449069624045654, data cost:0.30676442209785737 
2022-03-29 10:01:13,604: ============================================================
2022-03-29 10:01:13,604: Epoch 2/31 Batch 6100/7662 eta: 1 day, 13:28:15.620219	Training Loss 0.8260 (0.8263)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.016)	
2022-03-29 10:01:13,605: ============================================================
2022-03-29 10:02:10,775: time cost, forward:0.1987209957748637, backward:0.04491988569137492, data cost:0.3069317443541201 
2022-03-29 10:02:10,775: ============================================================
2022-03-29 10:02:10,775: Epoch 2/31 Batch 6200/7662 eta: 1 day, 11:31:09.052213	Training Loss 0.8257 (0.8263)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.016)	
2022-03-29 10:02:10,776: ============================================================
2022-03-29 10:03:06,202: time cost, forward:0.19871415939004028, backward:0.04494114216593906, data cost:0.3069718876118167 
2022-03-29 10:03:06,203: ============================================================
2022-03-29 10:03:06,203: Epoch 2/31 Batch 6300/7662 eta: 1 day, 10:25:15.007785	Training Loss 0.8265 (0.8263)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.016)	
2022-03-29 10:03:06,203: ============================================================
2022-03-29 10:04:06,535: time cost, forward:0.19912099130341068, backward:0.045011764355871266, data cost:0.30732573235588234 
2022-03-29 10:04:06,535: ============================================================
2022-03-29 10:04:06,536: Epoch 2/31 Batch 6400/7662 eta: 1 day, 13:26:59.373362	Training Loss 0.8261 (0.8263)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.016)	
2022-03-29 10:04:06,536: ============================================================
2022-03-29 10:05:00,391: time cost, forward:0.19892017810890208, backward:0.0450038364399835, data cost:0.30731963612406343 
2022-03-29 10:05:00,391: ============================================================
2022-03-29 10:05:00,391: Epoch 2/31 Batch 6500/7662 eta: 1 day, 9:24:53.270219	Training Loss 0.8253 (0.8263)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.016)	
2022-03-29 10:05:00,392: ============================================================
2022-03-29 10:05:57,842: time cost, forward:0.19913222031406172, backward:0.04503216984091717, data cost:0.3074196788610374 
2022-03-29 10:05:57,842: ============================================================
2022-03-29 10:05:57,842: Epoch 2/31 Batch 6600/7662 eta: 1 day, 11:37:45.521092	Training Loss 0.8252 (0.8263)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.016)	
2022-03-29 10:05:57,843: ============================================================
2022-03-29 10:06:55,808: time cost, forward:0.19942264963324557, backward:0.04510338051245451, data cost:0.307468087482068 
2022-03-29 10:06:55,809: ============================================================
2022-03-29 10:06:55,809: Epoch 2/31 Batch 6700/7662 eta: 1 day, 11:55:59.267613	Training Loss 0.8262 (0.8263)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.016)	
2022-03-29 10:06:55,809: ============================================================
2022-03-29 10:07:52,089: time cost, forward:0.1995058883058795, backward:0.04511533458191851, data cost:0.3075248209373585 
2022-03-29 10:07:52,090: ============================================================
2022-03-29 10:07:52,090: Epoch 2/31 Batch 6800/7662 eta: 1 day, 10:52:19.921479	Training Loss 0.8249 (0.8263)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.016)	
2022-03-29 10:07:52,090: ============================================================
2022-03-29 10:08:53,268: time cost, forward:0.2000764940662442, backward:0.045171921348931186, data cost:0.3077534090040179 
2022-03-29 10:08:53,269: ============================================================
2022-03-29 10:08:53,269: Epoch 2/31 Batch 6900/7662 eta: 1 day, 13:53:26.426288	Training Loss 0.8258 (0.8262)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.016)	
2022-03-29 10:08:53,269: ============================================================
2022-03-29 10:09:51,251: time cost, forward:0.2003631954926187, backward:0.045165196540168664, data cost:0.3078513611110726 
2022-03-29 10:09:51,251: ============================================================
2022-03-29 10:09:51,251: Epoch 2/31 Batch 7000/7662 eta: 1 day, 11:53:39.605861	Training Loss 0.8263 (0.8262)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.016)	
2022-03-29 10:09:51,252: ============================================================
2022-03-29 10:10:49,272: time cost, forward:0.2005073891876281, backward:0.04519745204999155, data cost:0.30804458976312493 
2022-03-29 10:10:49,273: ============================================================
2022-03-29 10:10:49,274: Epoch 2/31 Batch 7100/7662 eta: 1 day, 11:54:10.366873	Training Loss 0.8264 (0.8262)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.016)	
2022-03-29 10:10:49,274: ============================================================
2022-03-29 10:11:47,862: time cost, forward:0.20077512952780985, backward:0.045232870923527284, data cost:0.3081740130482655 
2022-03-29 10:11:47,863: ============================================================
2022-03-29 10:11:47,863: Epoch 2/31 Batch 7200/7662 eta: 1 day, 12:14:16.082744	Training Loss 0.8265 (0.8262)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.016)	
2022-03-29 10:11:47,863: ============================================================
2022-03-29 10:12:43,171: time cost, forward:0.2007185922516325, backward:0.04522847962683236, data cost:0.3082123433160266 
2022-03-29 10:12:43,171: ============================================================
2022-03-29 10:12:43,171: Epoch 2/31 Batch 7300/7662 eta: 1 day, 10:11:34.856832	Training Loss 0.8259 (0.8262)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.016)	
2022-03-29 10:12:43,172: ============================================================
2022-03-29 10:13:41,382: time cost, forward:0.20081416908704455, backward:0.045273472351195894, data cost:0.3084563097932529 
2022-03-29 10:13:41,382: ============================================================
2022-03-29 10:13:41,383: Epoch 2/31 Batch 7400/7662 eta: 1 day, 11:58:17.340149	Training Loss 0.8255 (0.8262)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.016)	
2022-03-29 10:13:41,383: ============================================================
2022-03-29 10:14:36,552: time cost, forward:0.20074311185318686, backward:0.045270878436613406, data cost:0.30847320666009864 
2022-03-29 10:14:36,552: ============================================================
2022-03-29 10:14:36,553: Epoch 2/31 Batch 7500/7662 eta: 1 day, 10:04:36.528880	Training Loss 0.8258 (0.8262)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.016)	
2022-03-29 10:14:36,553: ============================================================
2022-03-29 10:15:31,849: time cost, forward:0.20077530144547018, backward:0.045268069946353316, data cost:0.3084159247231085 
2022-03-29 10:15:31,850: ============================================================
2022-03-29 10:15:31,850: Epoch 2/31 Batch 7600/7662 eta: 1 day, 10:08:24.734909	Training Loss 0.8254 (0.8262)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-29 10:15:31,850: ============================================================
2022-03-29 10:16:10,825: Epoch: 2/31 eta: 1 day, 10:07:49.897496	Training Loss 0.8255 (0.8262)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.016)
2022-03-29 10:16:10,826: ============================================================
2022-03-29 10:17:11,910: time cost, forward:0.21019188322202123, backward:0.045353210333621864, data cost:0.3578218041044293 
2022-03-29 10:17:11,911: ============================================================
2022-03-29 10:17:11,912: Epoch 3/31 Batch 100/7662 eta: 1 day, 13:37:04.033154	Training Loss 0.8261 (0.8253)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.006)	
2022-03-29 10:17:11,912: ============================================================
2022-03-29 10:18:08,186: time cost, forward:0.20634055856484265, backward:0.04643275510126622, data cost:0.33414764859568535 
2022-03-29 10:18:08,188: ============================================================
2022-03-29 10:18:08,188: Epoch 3/31 Batch 200/7662 eta: 1 day, 10:42:12.443106	Training Loss 0.8259 (0.8253)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.012)	
2022-03-29 10:18:08,189: ============================================================
2022-03-29 10:19:06,340: time cost, forward:0.20758994765903638, backward:0.046847019705884035, data cost:0.3310280021616448 
2022-03-29 10:19:06,340: ============================================================
2022-03-29 10:19:06,341: Epoch 3/31 Batch 300/7662 eta: 1 day, 11:50:40.770717	Training Loss 0.8255 (0.8253)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.012)	
2022-03-29 10:19:06,341: ============================================================
2022-03-29 10:20:00,142: time cost, forward:0.2030904179527646, backward:0.04610377684571689, data cost:0.3240049972868802 
2022-03-29 10:20:00,142: ============================================================
2022-03-29 10:20:00,142: Epoch 3/31 Batch 400/7662 eta: 1 day, 9:08:51.436121	Training Loss 0.8254 (0.8253)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.013)	
2022-03-29 10:20:00,143: ============================================================
2022-03-29 10:21:00,000: time cost, forward:0.2061223988542576, backward:0.04655034986430992, data cost:0.3255531276634079 
2022-03-29 10:21:00,000: ============================================================
2022-03-29 10:21:00,001: Epoch 3/31 Batch 500/7662 eta: 1 day, 12:51:44.781495	Training Loss 0.8256 (0.8253)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.014)	
2022-03-29 10:21:00,001: ============================================================
2022-03-29 10:21:58,203: time cost, forward:0.20710412409150342, backward:0.0467778943814897, data cost:0.32471635664046705 
2022-03-29 10:21:58,203: ============================================================
2022-03-29 10:21:58,204: Epoch 3/31 Batch 600/7662 eta: 1 day, 11:49:37.607954	Training Loss 0.8250 (0.8253)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-29 10:21:58,204: ============================================================
2022-03-29 10:22:54,658: time cost, forward:0.20677453526782033, backward:0.04685263060704833, data cost:0.3230935503996493 
2022-03-29 10:22:54,659: ============================================================
2022-03-29 10:22:54,659: Epoch 3/31 Batch 700/7662 eta: 1 day, 10:44:08.402022	Training Loss 0.8253 (0.8253)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.018)	
2022-03-29 10:22:54,659: ============================================================
2022-03-29 10:23:53,411: time cost, forward:0.207220799931895, backward:0.04705760565508292, data cost:0.3237399204502416 
2022-03-29 10:23:53,412: ============================================================
2022-03-29 10:23:53,412: Epoch 3/31 Batch 800/7662 eta: 1 day, 12:07:57.685665	Training Loss 0.8244 (0.8253)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.019)	
2022-03-29 10:23:53,412: ============================================================
2022-03-29 10:24:52,249: time cost, forward:0.20806114188290808, backward:0.04725034032700722, data cost:0.32379589701388384 
2022-03-29 10:24:52,250: ============================================================
2022-03-29 10:24:52,250: Epoch 3/31 Batch 900/7662 eta: 1 day, 12:10:07.988587	Training Loss 0.8250 (0.8253)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-29 10:24:52,250: ============================================================
2022-03-29 10:25:50,974: time cost, forward:0.20861045304719392, backward:0.04749209458405549, data cost:0.3238034055039689 
2022-03-29 10:25:50,974: ============================================================
2022-03-29 10:25:50,975: Epoch 3/31 Batch 1000/7662 eta: 1 day, 12:04:58.211247	Training Loss 0.8249 (0.8253)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-29 10:25:50,975: ============================================================
2022-03-29 10:26:50,872: time cost, forward:0.2092644450228468, backward:0.04766661693444569, data cost:0.32468133476021294 
2022-03-29 10:26:50,873: ============================================================
2022-03-29 10:26:50,873: Epoch 3/31 Batch 1100/7662 eta: 1 day, 12:47:15.510526	Training Loss 0.8254 (0.8253)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.020)	
2022-03-29 10:26:50,873: ============================================================
2022-03-29 10:27:49,042: time cost, forward:0.2094164246614025, backward:0.0479367204861804, data cost:0.32421838173377104 
2022-03-29 10:27:49,043: ============================================================
2022-03-29 10:27:49,043: Epoch 3/31 Batch 1200/7662 eta: 1 day, 11:42:34.546252	Training Loss 0.8250 (0.8253)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.020)	
2022-03-29 10:27:49,043: ============================================================
2022-03-29 10:28:47,077: time cost, forward:0.20893206607386916, backward:0.04832353657993378, data cost:0.3242124716440837 
2022-03-29 10:28:47,077: ============================================================
2022-03-29 10:28:47,077: Epoch 3/31 Batch 1300/7662 eta: 1 day, 11:36:36.942601	Training Loss 0.8253 (0.8253)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.020)	
2022-03-29 10:28:47,077: ============================================================
2022-03-29 10:29:48,107: time cost, forward:0.20983674255245663, backward:0.04894222303149187, data cost:0.32469637978494464 
2022-03-29 10:29:48,107: ============================================================
2022-03-29 10:29:48,108: Epoch 3/31 Batch 1400/7662 eta: 1 day, 13:25:54.880951	Training Loss 0.8257 (0.8253)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.020)	
2022-03-29 10:29:48,108: ============================================================
2022-03-29 10:30:43,545: time cost, forward:0.20922380069480728, backward:0.04911769096496663, data cost:0.323175111399085 
2022-03-29 10:30:43,545: ============================================================
2022-03-29 10:30:43,545: Epoch 3/31 Batch 1500/7662 eta: 1 day, 9:59:10.463277	Training Loss 0.8252 (0.8253)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.020)	
2022-03-29 10:30:43,546: ============================================================
2022-03-29 10:31:44,210: time cost, forward:0.20992980471546013, backward:0.04925322413369967, data cost:0.3238855265616774 
2022-03-29 10:31:44,211: ============================================================
2022-03-29 10:31:44,212: Epoch 3/31 Batch 1600/7662 eta: 1 day, 13:10:28.474965	Training Loss 0.8260 (0.8253)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.020)	
2022-03-29 10:31:44,212: ============================================================
2022-03-29 10:32:41,819: time cost, forward:0.2098993704977142, backward:0.049221684892013395, data cost:0.3235097381912869 
2022-03-29 10:32:41,819: ============================================================
2022-03-29 10:32:41,820: Epoch 3/31 Batch 1700/7662 eta: 1 day, 11:17:05.380486	Training Loss 0.8261 (0.8253)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.020)	
2022-03-29 10:32:41,820: ============================================================
2022-03-29 10:33:40,852: time cost, forward:0.21012123735034513, backward:0.04917345860721404, data cost:0.32375121885302865 
2022-03-29 10:33:40,853: ============================================================
2022-03-29 10:33:40,853: Epoch 3/31 Batch 1800/7662 eta: 1 day, 12:08:29.276148	Training Loss 0.8249 (0.8253)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.019)	
2022-03-29 10:33:40,853: ============================================================
2022-03-29 10:34:38,180: time cost, forward:0.2099083216959957, backward:0.049176686559619875, data cost:0.32339187092753446 
2022-03-29 10:34:38,182: ============================================================
2022-03-29 10:34:38,183: Epoch 3/31 Batch 1900/7662 eta: 1 day, 11:04:56.258392	Training Loss 0.8252 (0.8253)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.020)	
2022-03-29 10:34:38,183: ============================================================
2022-03-29 10:35:37,099: time cost, forward:0.20993855453956836, backward:0.0492053445784553, data cost:0.3236889700820411 
2022-03-29 10:35:37,099: ============================================================
2022-03-29 10:35:37,100: Epoch 3/31 Batch 2000/7662 eta: 1 day, 12:02:15.300146	Training Loss 0.8255 (0.8253)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.019)	
2022-03-29 10:35:37,100: ============================================================
2022-03-29 10:36:36,021: time cost, forward:0.20990836614651473, backward:0.04924579595826591, data cost:0.3239501878839268 
2022-03-29 10:36:36,021: ============================================================
2022-03-29 10:36:36,021: Epoch 3/31 Batch 2100/7662 eta: 1 day, 12:01:25.551926	Training Loss 0.8253 (0.8253)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.019)	
2022-03-29 10:36:36,022: ============================================================
2022-03-29 10:37:33,294: time cost, forward:0.20976518923285442, backward:0.04951882904472542, data cost:0.3233650557937379 
2022-03-29 10:37:33,295: ============================================================
2022-03-29 10:37:33,295: Epoch 3/31 Batch 2200/7662 eta: 1 day, 11:00:01.462881	Training Loss 0.8247 (0.8253)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.019)	
2022-03-29 10:37:33,295: ============================================================
2022-03-29 10:38:32,016: time cost, forward:0.20994447313634765, backward:0.04994336487470165, data cost:0.32291950252378643 
2022-03-29 10:38:32,016: ============================================================
2022-03-29 10:38:32,017: Epoch 3/31 Batch 2300/7662 eta: 1 day, 11:52:07.864757	Training Loss 0.8246 (0.8253)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.019)	
2022-03-29 10:38:32,017: ============================================================
2022-03-29 10:39:33,001: time cost, forward:0.21048112152118692, backward:0.05047685625951655, data cost:0.3229553551413507 
2022-03-29 10:39:33,001: ============================================================
2022-03-29 10:39:33,002: Epoch 3/31 Batch 2400/7662 eta: 1 day, 13:14:04.836533	Training Loss 0.8246 (0.8253)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.019)	
2022-03-29 10:39:33,002: ============================================================
2022-03-29 10:40:31,790: time cost, forward:0.210594874660985, backward:0.050597176355283324, data cost:0.3228551241434684 
2022-03-29 10:40:31,790: ============================================================
2022-03-29 10:40:31,791: Epoch 3/31 Batch 2500/7662 eta: 1 day, 11:52:38.902280	Training Loss 0.8249 (0.8253)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.019)	
2022-03-29 10:40:31,791: ============================================================
2022-03-29 10:41:33,001: time cost, forward:0.21111981343103858, backward:0.05052276270441846, data cost:0.32348086385371 
2022-03-29 10:41:33,001: ============================================================
2022-03-29 10:41:33,002: Epoch 3/31 Batch 2600/7662 eta: 1 day, 13:20:18.844863	Training Loss 0.8255 (0.8253)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.019)	
2022-03-29 10:41:33,002: ============================================================
2022-03-29 10:42:30,522: time cost, forward:0.21101087833078053, backward:0.05037672778508009, data cost:0.3233583592714845 
2022-03-29 10:42:30,522: ============================================================
2022-03-29 10:42:30,523: Epoch 3/31 Batch 2700/7662 eta: 1 day, 11:04:17.999703	Training Loss 0.8256 (0.8253)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.019)	
2022-03-29 10:42:30,523: ============================================================
2022-03-29 10:43:27,399: time cost, forward:0.2105698623841215, backward:0.05019535325007082, data cost:0.323445421578672 
2022-03-29 10:43:27,400: ============================================================
2022-03-29 10:43:27,400: Epoch 3/31 Batch 2800/7662 eta: 1 day, 10:39:48.048584	Training Loss 0.8254 (0.8253)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.019)	
2022-03-29 10:43:27,400: ============================================================
2022-03-29 10:44:28,415: time cost, forward:0.21107283408331765, backward:0.05010863072545663, data cost:0.3238594545994022 
2022-03-29 10:44:28,415: ============================================================
2022-03-29 10:44:28,415: Epoch 3/31 Batch 2900/7662 eta: 1 day, 13:10:06.443192	Training Loss 0.8249 (0.8253)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.019)	
2022-03-29 10:44:28,416: ============================================================
2022-03-29 10:45:28,447: time cost, forward:0.2114162479253084, backward:0.050035145092741894, data cost:0.32409742841246764 
2022-03-29 10:45:28,447: ============================================================
2022-03-29 10:45:28,447: Epoch 3/31 Batch 3000/7662 eta: 1 day, 12:33:09.311260	Training Loss 0.8243 (0.8253)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.019)	
2022-03-29 10:45:28,448: ============================================================
2022-03-29 10:46:28,491: time cost, forward:0.2116307646815105, backward:0.04994597808896976, data cost:0.3244634667070653 
2022-03-29 10:46:28,492: ============================================================
2022-03-29 10:46:28,492: Epoch 3/31 Batch 3100/7662 eta: 1 day, 12:32:37.638459	Training Loss 0.8253 (0.8253)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.019)	
2022-03-29 10:46:28,492: ============================================================
2022-03-29 10:47:26,530: time cost, forward:0.21158289491999854, backward:0.04983469298870424, data cost:0.3244053348596113 
2022-03-29 10:47:26,530: ============================================================
2022-03-29 10:47:26,531: Epoch 3/31 Batch 3200/7662 eta: 1 day, 11:18:23.357789	Training Loss 0.8254 (0.8253)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.019)	
2022-03-29 10:47:26,531: ============================================================
2022-03-29 10:48:26,963: time cost, forward:0.21187523438302486, backward:0.04973255334098471, data cost:0.32477098408884336 
2022-03-29 10:48:26,963: ============================================================
2022-03-29 10:48:26,963: Epoch 3/31 Batch 3300/7662 eta: 1 day, 12:44:47.028801	Training Loss 0.8254 (0.8253)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.019)	
2022-03-29 10:48:26,964: ============================================================
2022-03-29 10:49:27,870: time cost, forward:0.21222392563681, backward:0.04965129569194779, data cost:0.32515550831129497 
2022-03-29 10:49:27,870: ============================================================
2022-03-29 10:49:27,870: Epoch 3/31 Batch 3400/7662 eta: 1 day, 13:01:03.539303	Training Loss 0.8259 (0.8253)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.019)	
2022-03-29 10:49:27,870: ============================================================
2022-03-29 10:50:26,472: time cost, forward:0.21231766965396748, backward:0.04955856416456425, data cost:0.3250331588389704 
2022-03-29 10:50:26,472: ============================================================
2022-03-29 10:50:26,472: Epoch 3/31 Batch 3500/7662 eta: 1 day, 11:36:02.180379	Training Loss 0.8250 (0.8253)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.019)	
2022-03-29 10:50:26,473: ============================================================
2022-03-29 10:51:24,802: time cost, forward:0.21238202331926664, backward:0.049474442127712175, data cost:0.3250221295898641 
2022-03-29 10:51:24,803: ============================================================
2022-03-29 10:51:24,803: Epoch 3/31 Batch 3600/7662 eta: 1 day, 11:25:10.365808	Training Loss 0.8251 (0.8253)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.019)	
2022-03-29 10:51:24,803: ============================================================
2022-03-29 10:52:24,042: time cost, forward:0.2125019445133132, backward:0.04941791880933231, data cost:0.3250925127123781 
2022-03-29 10:52:24,042: ============================================================
2022-03-29 10:52:24,043: Epoch 3/31 Batch 3700/7662 eta: 1 day, 11:57:17.860548	Training Loss 0.8254 (0.8253)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.019)	
2022-03-29 10:52:24,043: ============================================================
2022-03-29 10:53:23,365: time cost, forward:0.21255081928099542, backward:0.04935581434962309, data cost:0.32525900565627125 
2022-03-29 10:53:23,365: ============================================================
2022-03-29 10:53:23,365: Epoch 3/31 Batch 3800/7662 eta: 1 day, 11:59:20.402320	Training Loss 0.8255 (0.8253)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.019)	
2022-03-29 10:53:23,366: ============================================================
2022-03-29 10:54:20,594: time cost, forward:0.21230405524743767, backward:0.04928897796272773, data cost:0.32518365934097515 
2022-03-29 10:54:20,594: ============================================================
2022-03-29 10:54:20,594: Epoch 3/31 Batch 3900/7662 eta: 1 day, 10:42:09.969543	Training Loss 0.8252 (0.8253)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.019)	
2022-03-29 10:54:20,594: ============================================================
2022-03-29 10:55:18,142: time cost, forward:0.21224330144692852, backward:0.0492254467897637, data cost:0.3250256971467522 
2022-03-29 10:55:18,142: ============================================================
2022-03-29 10:55:18,143: Epoch 3/31 Batch 4000/7662 eta: 1 day, 10:52:49.809455	Training Loss 0.8247 (0.8253)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.195 (0.019)	
2022-03-29 10:55:18,143: ============================================================
2022-03-29 10:56:19,710: time cost, forward:0.2125666760967894, backward:0.049242363292492146, data cost:0.3253701663825767 
2022-03-29 10:56:19,710: ============================================================
2022-03-29 10:56:19,710: Epoch 3/31 Batch 4100/7662 eta: 1 day, 13:17:58.753620	Training Loss 0.8240 (0.8253)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.019)	
2022-03-29 10:56:19,711: ============================================================
2022-03-29 10:57:14,686: time cost, forward:0.212145797069029, backward:0.04912727382757119, data cost:0.32500405571636176 
2022-03-29 10:57:14,687: ============================================================
2022-03-29 10:57:14,687: Epoch 3/31 Batch 4200/7662 eta: 1 day, 9:17:28.065944	Training Loss 0.8248 (0.8253)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.019)	
2022-03-29 10:57:14,687: ============================================================
2022-03-29 10:58:17,289: time cost, forward:0.21261951956091218, backward:0.049156790695847066, data cost:0.3254223108901676 
2022-03-29 10:58:17,289: ============================================================
2022-03-29 10:58:17,290: Epoch 3/31 Batch 4300/7662 eta: 1 day, 13:53:30.651548	Training Loss 0.8255 (0.8253)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.019)	
2022-03-29 10:58:17,290: ============================================================
2022-03-29 10:59:17,741: time cost, forward:0.21283541768484426, backward:0.04915516672960382, data cost:0.3255892720756869 
2022-03-29 10:59:17,742: ============================================================
2022-03-29 10:59:17,742: Epoch 3/31 Batch 4400/7662 eta: 1 day, 12:34:25.038846	Training Loss 0.8249 (0.8252)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-29 10:59:17,742: ============================================================
2022-03-29 11:00:17,312: time cost, forward:0.21300495500219058, backward:0.049119088511436246, data cost:0.3256294639885863 
2022-03-29 11:00:17,313: ============================================================
2022-03-29 11:00:17,313: Epoch 3/31 Batch 4500/7662 eta: 1 day, 12:01:25.385865	Training Loss 0.8252 (0.8252)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.195 (0.018)	
2022-03-29 11:00:17,313: ============================================================
2022-03-29 11:01:17,245: time cost, forward:0.21310634980074192, backward:0.049087855214008845, data cost:0.325799085907792 
2022-03-29 11:01:17,245: ============================================================
2022-03-29 11:01:17,245: Epoch 3/31 Batch 4600/7662 eta: 1 day, 12:13:31.602156	Training Loss 0.8249 (0.8252)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-29 11:01:17,245: ============================================================
2022-03-29 11:02:16,855: time cost, forward:0.2132590792741794, backward:0.049057373317613784, data cost:0.3258422728065837 
2022-03-29 11:02:16,855: ============================================================
2022-03-29 11:02:16,855: Epoch 3/31 Batch 4700/7662 eta: 1 day, 12:00:51.327907	Training Loss 0.8248 (0.8252)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-29 11:02:16,855: ============================================================
2022-03-29 11:03:16,634: time cost, forward:0.2133231113344015, backward:0.04902292058030176, data cost:0.32601018338482635 
2022-03-29 11:03:16,634: ============================================================
2022-03-29 11:03:16,635: Epoch 3/31 Batch 4800/7662 eta: 1 day, 12:05:59.541263	Training Loss 0.8260 (0.8252)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-29 11:03:16,635: ============================================================
2022-03-29 11:04:14,103: time cost, forward:0.21326877852317436, backward:0.04896483291872036, data cost:0.32584709657846994 
2022-03-29 11:04:14,104: ============================================================
2022-03-29 11:04:14,104: Epoch 3/31 Batch 4900/7662 eta: 1 day, 10:41:20.566053	Training Loss 0.8244 (0.8252)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-29 11:04:14,104: ============================================================
2022-03-29 11:05:12,892: time cost, forward:0.2133860280452239, backward:0.0489398421562059, data cost:0.3257306564996471 
2022-03-29 11:05:12,892: ============================================================
2022-03-29 11:05:12,893: Epoch 3/31 Batch 5000/7662 eta: 1 day, 11:28:08.252798	Training Loss 0.8254 (0.8252)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-29 11:05:12,893: ============================================================
2022-03-29 11:06:11,487: time cost, forward:0.21329795301930768, backward:0.04888674772868182, data cost:0.32585176628555684 
2022-03-29 11:06:11,487: ============================================================
2022-03-29 11:06:11,488: Epoch 3/31 Batch 5100/7662 eta: 1 day, 11:20:09.515224	Training Loss 0.8243 (0.8252)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.195 (0.018)	
2022-03-29 11:06:11,488: ============================================================
2022-03-29 11:07:11,098: time cost, forward:0.21344675493139467, backward:0.04886428817782775, data cost:0.32584256175665427 
2022-03-29 11:07:11,099: ============================================================
2022-03-29 11:07:11,099: Epoch 3/31 Batch 5200/7662 eta: 1 day, 11:55:55.774833	Training Loss 0.8254 (0.8252)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-29 11:07:11,099: ============================================================
2022-03-29 11:08:10,137: time cost, forward:0.21347528944647207, backward:0.04882194307935218, data cost:0.3258938201307508 
2022-03-29 11:08:10,138: ============================================================
2022-03-29 11:08:10,138: Epoch 3/31 Batch 5300/7662 eta: 1 day, 11:34:14.654726	Training Loss 0.8256 (0.8252)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.195 (0.018)	
2022-03-29 11:08:10,138: ============================================================
2022-03-29 11:09:09,601: time cost, forward:0.21349810573608263, backward:0.048816425664753006, data cost:0.3259864790966432 
2022-03-29 11:09:09,601: ============================================================
2022-03-29 11:09:09,602: Epoch 3/31 Batch 5400/7662 eta: 1 day, 11:48:36.893165	Training Loss 0.8249 (0.8252)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-29 11:09:09,602: ============================================================
2022-03-29 11:10:10,119: time cost, forward:0.2136346141865826, backward:0.04880766375191885, data cost:0.3261739531740923 
2022-03-29 11:10:10,120: ============================================================
2022-03-29 11:10:10,120: Epoch 3/31 Batch 5500/7662 eta: 1 day, 12:25:42.430660	Training Loss 0.8258 (0.8252)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-29 11:10:10,120: ============================================================
2022-03-29 11:11:08,171: time cost, forward:0.2135755111754292, backward:0.04878176704307266, data cost:0.3260925227051272 
2022-03-29 11:11:08,171: ============================================================
2022-03-29 11:11:08,172: Epoch 3/31 Batch 5600/7662 eta: 1 day, 10:55:39.935903	Training Loss 0.8251 (0.8252)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-29 11:11:08,172: ============================================================
2022-03-29 11:12:09,406: time cost, forward:0.21374733319594622, backward:0.04876419991270495, data cost:0.3263518873443309 
2022-03-29 11:12:09,406: ============================================================
2022-03-29 11:12:09,407: Epoch 3/31 Batch 5700/7662 eta: 1 day, 12:49:32.491397	Training Loss 0.8253 (0.8252)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-29 11:12:09,407: ============================================================
2022-03-29 11:13:11,988: time cost, forward:0.2140751917786918, backward:0.04872059012141838, data cost:0.3266962766030633 
2022-03-29 11:13:11,989: ============================================================
2022-03-29 11:13:11,989: Epoch 3/31 Batch 5800/7662 eta: 1 day, 13:37:07.757608	Training Loss 0.8255 (0.8252)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-29 11:13:11,989: ============================================================
2022-03-29 11:14:11,405: time cost, forward:0.21419464577899422, backward:0.04865863598449935, data cost:0.3267135663767309 
2022-03-29 11:14:11,406: ============================================================
2022-03-29 11:14:11,406: Epoch 3/31 Batch 5900/7662 eta: 1 day, 11:41:58.614170	Training Loss 0.8248 (0.8252)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-29 11:14:11,406: ============================================================
2022-03-29 11:15:11,501: time cost, forward:0.2143086637928399, backward:0.048569032084367574, data cost:0.3268730963522403 
2022-03-29 11:15:11,501: ============================================================
2022-03-29 11:15:11,502: Epoch 3/31 Batch 6000/7662 eta: 1 day, 12:05:25.905080	Training Loss 0.8256 (0.8252)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-29 11:15:11,502: ============================================================
2022-03-29 11:16:12,044: time cost, forward:0.21439179367150493, backward:0.04850665610976875, data cost:0.3270983597864419 
2022-03-29 11:16:12,044: ============================================================
2022-03-29 11:16:12,045: Epoch 3/31 Batch 6100/7662 eta: 1 day, 12:20:32.759828	Training Loss 0.8251 (0.8252)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-29 11:16:12,045: ============================================================
2022-03-29 11:17:11,051: time cost, forward:0.21425788924470604, backward:0.0483867581726409, data cost:0.3273529479880163 
2022-03-29 11:17:11,052: ============================================================
2022-03-29 11:17:11,052: Epoch 3/31 Batch 6200/7662 eta: 1 day, 11:24:15.470221	Training Loss 0.8251 (0.8252)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-29 11:17:11,052: ============================================================
2022-03-29 11:18:10,423: time cost, forward:0.21425823393956614, backward:0.04833418222661434, data cost:0.3274564803980857 
2022-03-29 11:18:10,423: ============================================================
2022-03-29 11:18:10,424: Epoch 3/31 Batch 6300/7662 eta: 1 day, 11:36:22.884554	Training Loss 0.8250 (0.8252)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-29 11:18:10,424: ============================================================
2022-03-29 11:19:10,540: time cost, forward:0.21423707565007163, backward:0.048274964648385515, data cost:0.3276979690381262 
2022-03-29 11:19:10,541: ============================================================
2022-03-29 11:19:10,542: Epoch 3/31 Batch 6400/7662 eta: 1 day, 12:02:13.918890	Training Loss 0.8247 (0.8252)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-29 11:19:10,542: ============================================================
2022-03-29 11:20:11,208: time cost, forward:0.2142973779293001, backward:0.048228698320472434, data cost:0.3279413401777881 
2022-03-29 11:20:11,208: ============================================================
2022-03-29 11:20:11,209: Epoch 3/31 Batch 6500/7662 eta: 1 day, 12:20:57.981826	Training Loss 0.8254 (0.8252)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-29 11:20:11,209: ============================================================
2022-03-29 11:21:09,887: time cost, forward:0.21419019763407193, backward:0.048168584205360375, data cost:0.32804624657501574 
2022-03-29 11:21:09,887: ============================================================
2022-03-29 11:21:09,887: Epoch 3/31 Batch 6600/7662 eta: 1 day, 11:08:30.583431	Training Loss 0.8251 (0.8252)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-29 11:21:09,888: ============================================================
2022-03-29 11:22:09,660: time cost, forward:0.21414350858284903, backward:0.048114480785797525, data cost:0.32825097110239776 
2022-03-29 11:22:09,660: ============================================================
2022-03-29 11:22:09,661: Epoch 3/31 Batch 6700/7662 eta: 1 day, 11:46:51.177547	Training Loss 0.8256 (0.8252)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-29 11:22:09,661: ============================================================
2022-03-29 11:23:06,942: time cost, forward:0.21403790088344415, backward:0.048038838172348164, data cost:0.32816906262187506 
2022-03-29 11:23:06,942: ============================================================
2022-03-29 11:23:06,942: Epoch 3/31 Batch 6800/7662 eta: 1 day, 10:16:23.726534	Training Loss 0.8256 (0.8252)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-29 11:23:06,943: ============================================================
2022-03-29 11:24:07,606: time cost, forward:0.21405204483902546, backward:0.04799858237163004, data cost:0.32842088136176717 
2022-03-29 11:24:07,607: ============================================================
2022-03-29 11:24:07,608: Epoch 3/31 Batch 6900/7662 eta: 1 day, 12:16:52.357386	Training Loss 0.8255 (0.8252)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-29 11:24:07,609: ============================================================
2022-03-29 11:25:08,631: time cost, forward:0.21407515318977235, backward:0.047986024923879156, data cost:0.3286923915935527 
2022-03-29 11:25:08,632: ============================================================
2022-03-29 11:25:08,632: Epoch 3/31 Batch 7000/7662 eta: 1 day, 12:28:43.412666	Training Loss 0.8254 (0.8252)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-29 11:25:08,632: ============================================================
2022-03-29 11:26:08,578: time cost, forward:0.214063829427908, backward:0.04793358127875032, data cost:0.32887199882521295 
2022-03-29 11:26:08,578: ============================================================
2022-03-29 11:26:08,579: Epoch 3/31 Batch 7100/7662 eta: 1 day, 11:49:04.877059	Training Loss 0.8258 (0.8252)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-29 11:26:08,579: ============================================================
2022-03-29 11:27:09,049: time cost, forward:0.214061294368347, backward:0.04788619959614379, data cost:0.32910258992875113 
2022-03-29 11:27:09,050: ============================================================
2022-03-29 11:27:09,050: Epoch 3/31 Batch 7200/7662 eta: 1 day, 12:06:52.488593	Training Loss 0.8256 (0.8252)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-29 11:27:09,050: ============================================================
2022-03-29 11:28:10,085: time cost, forward:0.21410713945125648, backward:0.04784581415913565, data cost:0.32936424574699774 
2022-03-29 11:28:10,085: ============================================================
2022-03-29 11:28:10,086: Epoch 3/31 Batch 7300/7662 eta: 1 day, 12:26:04.762766	Training Loss 0.8248 (0.8252)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-29 11:28:10,086: ============================================================
2022-03-29 11:29:09,970: time cost, forward:0.21409936868946267, backward:0.04778745880415672, data cost:0.3295253301765616 
2022-03-29 11:29:09,971: ============================================================
2022-03-29 11:29:09,971: Epoch 3/31 Batch 7400/7662 eta: 1 day, 11:43:53.906737	Training Loss 0.8251 (0.8252)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-29 11:29:09,971: ============================================================
2022-03-29 11:30:10,226: time cost, forward:0.21412696172625467, backward:0.04773541173389362, data cost:0.32971015185066055 
2022-03-29 11:30:10,226: ============================================================
2022-03-29 11:30:10,227: Epoch 3/31 Batch 7500/7662 eta: 1 day, 11:56:07.536369	Training Loss 0.8253 (0.8252)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-29 11:30:10,227: ============================================================
2022-03-29 11:31:10,826: time cost, forward:0.21413781194565154, backward:0.047706022029143286, data cost:0.32989799877517645 
2022-03-29 11:31:10,826: ============================================================
2022-03-29 11:31:10,827: Epoch 3/31 Batch 7600/7662 eta: 1 day, 12:07:27.017331	Training Loss 0.8249 (0.8252)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-29 11:31:10,827: ============================================================
2022-03-29 11:31:50,695: Epoch: 3/31 eta: 1 day, 12:06:48.839324	Training Loss 0.8253 (0.8252)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)
2022-03-29 11:31:50,696: ============================================================
2022-03-29 11:32:50,568: time cost, forward:0.19736972722140225, backward:0.041932339620108554, data cost:0.3602730505394213 
2022-03-29 11:32:50,569: ============================================================
2022-03-29 11:32:50,569: Epoch 4/31 Batch 100/7662 eta: 1 day, 11:36:18.131033	Training Loss 0.8239 (0.8248)	Training Prec@1 0.000 (0.010)	Training Prec@5 0.000 (0.024)	
2022-03-29 11:32:50,569: ============================================================
2022-03-29 11:33:51,399: time cost, forward:0.20510540176276584, backward:0.04314595131418813, data cost:0.3555888542577849 
2022-03-29 11:33:51,399: ============================================================
2022-03-29 11:33:51,400: Epoch 4/31 Batch 200/7662 eta: 1 day, 12:13:02.006902	Training Loss 0.8244 (0.8248)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.195 (0.021)	
2022-03-29 11:33:51,400: ============================================================
2022-03-29 11:34:51,394: time cost, forward:0.20645340788723235, backward:0.044373571274671265, data cost:0.35142451624407817 
2022-03-29 11:34:51,394: ============================================================
2022-03-29 11:34:51,394: Epoch 4/31 Batch 300/7662 eta: 1 day, 11:42:10.763618	Training Loss 0.8250 (0.8248)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.026)	
2022-03-29 11:34:51,394: ============================================================
2022-03-29 11:35:51,606: time cost, forward:0.2065910223432651, backward:0.04415775719740636, data cost:0.3514349042323598 
2022-03-29 11:35:51,607: ============================================================
2022-03-29 11:35:51,608: Epoch 4/31 Batch 400/7662 eta: 1 day, 11:48:58.988405	Training Loss 0.8247 (0.8248)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.195 (0.023)	
2022-03-29 11:35:51,608: ============================================================
2022-03-29 11:36:50,294: time cost, forward:0.20553024880632847, backward:0.044107183903634904, data cost:0.3493027252281357 
2022-03-29 11:36:50,295: ============================================================
2022-03-29 11:36:50,295: Epoch 4/31 Batch 500/7662 eta: 1 day, 10:53:33.114404	Training Loss 0.8246 (0.8248)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.024)	
2022-03-29 11:36:50,295: ============================================================
2022-03-29 11:37:49,552: time cost, forward:0.20539880276522374, backward:0.044283696526478046, data cost:0.3481201046894309 
2022-03-29 11:37:49,553: ============================================================
2022-03-29 11:37:49,553: Epoch 4/31 Batch 600/7662 eta: 1 day, 11:12:54.471509	Training Loss 0.8250 (0.8248)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.024)	
2022-03-29 11:37:49,553: ============================================================
2022-03-29 11:38:48,871: time cost, forward:0.20529681520912268, backward:0.04446761393240081, data cost:0.3473727532551865 
2022-03-29 11:38:48,871: ============================================================
2022-03-29 11:38:48,871: Epoch 4/31 Batch 700/7662 eta: 1 day, 11:14:04.673042	Training Loss 0.8249 (0.8248)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.024)	
2022-03-29 11:38:48,872: ============================================================
2022-03-29 11:39:48,069: time cost, forward:0.205323421611953, backward:0.04465166200535169, data cost:0.3464496720568259 
2022-03-29 11:39:48,069: ============================================================
2022-03-29 11:39:48,070: Epoch 4/31 Batch 800/7662 eta: 1 day, 11:08:48.483206	Training Loss 0.8242 (0.8248)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.023)	
2022-03-29 11:39:48,070: ============================================================
2022-03-29 11:40:47,788: time cost, forward:0.2053871918573263, backward:0.04467247643645799, data cost:0.34635748163081115 
2022-03-29 11:40:47,788: ============================================================
2022-03-29 11:40:47,788: Epoch 4/31 Batch 900/7662 eta: 1 day, 11:26:21.659188	Training Loss 0.8253 (0.8248)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.022)	
2022-03-29 11:40:47,789: ============================================================
2022-03-29 11:41:47,458: time cost, forward:0.20552954349193248, backward:0.044599926149522934, data cost:0.34630822562598607 
2022-03-29 11:41:47,458: ============================================================
2022-03-29 11:41:47,459: Epoch 4/31 Batch 1000/7662 eta: 1 day, 11:23:37.851349	Training Loss 0.8246 (0.8248)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.195 (0.022)	
2022-03-29 11:41:47,459: ============================================================
2022-03-29 11:42:46,669: time cost, forward:0.20555612496401202, backward:0.044572693961007256, data cost:0.3458550811573199 
2022-03-29 11:42:46,670: ============================================================
2022-03-29 11:42:46,670: Epoch 4/31 Batch 1100/7662 eta: 1 day, 11:06:18.696977	Training Loss 0.8252 (0.8248)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.021)	
2022-03-29 11:42:46,670: ============================================================
2022-03-29 11:43:46,055: time cost, forward:0.20565233238544733, backward:0.044518967684951796, data cost:0.34558049612387304 
2022-03-29 11:43:46,055: ============================================================
2022-03-29 11:43:46,056: Epoch 4/31 Batch 1200/7662 eta: 1 day, 11:11:31.914927	Training Loss 0.8251 (0.8248)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.021)	
2022-03-29 11:43:46,056: ============================================================
2022-03-29 11:44:45,818: time cost, forward:0.2057768193642115, backward:0.04459668949441418, data cost:0.3455201425031114 
2022-03-29 11:44:45,819: ============================================================
2022-03-29 11:44:45,819: Epoch 4/31 Batch 1300/7662 eta: 1 day, 11:23:57.065247	Training Loss 0.8246 (0.8248)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.021)	
2022-03-29 11:44:45,819: ============================================================
2022-03-29 11:45:46,114: time cost, forward:0.20590892870823257, backward:0.04466162382320816, data cost:0.3457724799250943 
2022-03-29 11:45:46,114: ============================================================
2022-03-29 11:45:46,115: Epoch 4/31 Batch 1400/7662 eta: 1 day, 11:41:52.509277	Training Loss 0.8239 (0.8248)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.021)	
2022-03-29 11:45:46,115: ============================================================
2022-03-29 11:46:46,235: time cost, forward:0.2059069988805505, backward:0.0446931418774524, data cost:0.34603379009722707 
2022-03-29 11:46:46,236: ============================================================
2022-03-29 11:46:46,236: Epoch 4/31 Batch 1500/7662 eta: 1 day, 11:34:40.960244	Training Loss 0.8245 (0.8248)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.021)	
2022-03-29 11:46:46,236: ============================================================
2022-03-29 11:47:46,248: time cost, forward:0.2060557867006036, backward:0.04459023729125137, data cost:0.3460718598344909 
2022-03-29 11:47:46,248: ============================================================
2022-03-29 11:47:46,249: Epoch 4/31 Batch 1600/7662 eta: 1 day, 11:29:49.156358	Training Loss 0.8249 (0.8248)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.021)	
2022-03-29 11:47:46,249: ============================================================
2022-03-29 11:48:47,365: time cost, forward:0.2061847228734475, backward:0.044710801586535065, data cost:0.3467331425171168 
2022-03-29 11:48:47,365: ============================================================
2022-03-29 11:48:47,366: Epoch 4/31 Batch 1700/7662 eta: 1 day, 12:07:59.411904	Training Loss 0.8251 (0.8248)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.021)	
2022-03-29 11:48:47,366: ============================================================
2022-03-29 11:49:48,142: time cost, forward:0.20649470972842546, backward:0.04473316331516709, data cost:0.3469384237419837 
2022-03-29 11:49:48,142: ============================================================
2022-03-29 11:49:48,143: Epoch 4/31 Batch 1800/7662 eta: 1 day, 11:54:55.337820	Training Loss 0.8248 (0.8248)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.020)	
2022-03-29 11:49:48,143: ============================================================
2022-03-29 11:50:48,442: time cost, forward:0.206580867762312, backward:0.04477987834313721, data cost:0.3470447278135761 
2022-03-29 11:50:48,442: ============================================================
2022-03-29 11:50:48,443: Epoch 4/31 Batch 1900/7662 eta: 1 day, 11:36:59.780864	Training Loss 0.8245 (0.8248)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.020)	
2022-03-29 11:50:48,443: ============================================================
2022-03-29 11:51:48,865: time cost, forward:0.2066606279013454, backward:0.04481578720039341, data cost:0.34720031734464646 
2022-03-29 11:51:48,866: ============================================================
2022-03-29 11:51:48,866: Epoch 4/31 Batch 2000/7662 eta: 1 day, 11:40:22.283177	Training Loss 0.8256 (0.8248)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.020)	
2022-03-29 11:51:48,866: ============================================================
2022-03-29 11:52:49,586: time cost, forward:0.20676369403531972, backward:0.04482406522615459, data cost:0.3474566919454908 
2022-03-29 11:52:49,587: ============================================================
2022-03-29 11:52:49,587: Epoch 4/31 Batch 2100/7662 eta: 1 day, 11:49:53.402681	Training Loss 0.8251 (0.8248)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.019)	
2022-03-29 11:52:49,587: ============================================================
2022-03-29 11:53:51,188: time cost, forward:0.2070311474333898, backward:0.044823572710461376, data cost:0.347949494443844 
2022-03-29 11:53:51,189: ============================================================
2022-03-29 11:53:51,189: Epoch 4/31 Batch 2200/7662 eta: 1 day, 12:20:04.419406	Training Loss 0.8246 (0.8248)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.020)	
2022-03-29 11:53:51,189: ============================================================
2022-03-29 11:54:51,395: time cost, forward:0.20716988039618214, backward:0.044845642137133386, data cost:0.3478598437033409 
2022-03-29 11:54:51,395: ============================================================
2022-03-29 11:54:51,395: Epoch 4/31 Batch 2300/7662 eta: 1 day, 11:29:39.793486	Training Loss 0.8249 (0.8248)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.019)	
2022-03-29 11:54:51,396: ============================================================
2022-03-29 11:55:53,381: time cost, forward:0.2073508947777122, backward:0.04446360596819389, data cost:0.34886309503266694 
2022-03-29 11:55:53,381: ============================================================
2022-03-29 11:55:53,382: Epoch 4/31 Batch 2400/7662 eta: 1 day, 12:31:35.710308	Training Loss 0.8246 (0.8248)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.019)	
2022-03-29 11:55:53,382: ============================================================
2022-03-29 11:56:53,737: time cost, forward:0.20745914962206807, backward:0.044515782139119074, data cost:0.3488067778266397 
2022-03-29 11:56:53,738: ============================================================
2022-03-29 11:56:53,738: Epoch 4/31 Batch 2500/7662 eta: 1 day, 11:32:58.518671	Training Loss 0.8257 (0.8248)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.019)	
2022-03-29 11:56:53,739: ============================================================
2022-03-29 11:57:54,748: time cost, forward:0.20759952054568648, backward:0.04452890531518634, data cost:0.3489892677235209 
2022-03-29 11:57:54,748: ============================================================
2022-03-29 11:57:54,748: Epoch 4/31 Batch 2600/7662 eta: 1 day, 11:55:02.787934	Training Loss 0.8252 (0.8248)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.019)	
2022-03-29 11:57:54,749: ============================================================
2022-03-29 11:58:55,645: time cost, forward:0.2077430815730284, backward:0.04457635480238359, data cost:0.3490252940908279 
2022-03-29 11:58:55,645: ============================================================
2022-03-29 11:58:55,645: Epoch 4/31 Batch 2700/7662 eta: 1 day, 11:50:02.520979	Training Loss 0.8252 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.020)	
2022-03-29 11:58:55,646: ============================================================
2022-03-29 11:59:56,260: time cost, forward:0.20788700974979926, backward:0.044564771243358094, data cost:0.34913061030552445 
2022-03-29 11:59:56,261: ============================================================
2022-03-29 11:59:56,261: Epoch 4/31 Batch 2800/7662 eta: 1 day, 11:39:05.941960	Training Loss 0.8244 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.020)	
2022-03-29 11:59:56,261: ============================================================
2022-03-29 12:00:53,782: time cost, forward:0.2075197063424991, backward:0.04451938520920363, data cost:0.3485905155308208 
2022-03-29 12:00:53,782: ============================================================
2022-03-29 12:00:53,783: Epoch 4/31 Batch 2900/7662 eta: 1 day, 9:48:57.013838	Training Loss 0.8249 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.019)	
2022-03-29 12:00:53,783: ============================================================
2022-03-29 12:01:55,766: time cost, forward:0.207761571422423, backward:0.04455301856231435, data cost:0.3489374843348102 
2022-03-29 12:01:55,766: ============================================================
2022-03-29 12:01:55,766: Epoch 4/31 Batch 3000/7662 eta: 1 day, 12:25:18.723823	Training Loss 0.8249 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.020)	
2022-03-29 12:01:55,767: ============================================================
2022-03-29 12:02:53,855: time cost, forward:0.20760613350992857, backward:0.044524464848811646, data cost:0.34846047064149405 
2022-03-29 12:02:53,855: ============================================================
2022-03-29 12:02:53,856: Epoch 4/31 Batch 3100/7662 eta: 1 day, 10:07:01.723087	Training Loss 0.8252 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.195 (0.020)	
2022-03-29 12:02:53,856: ============================================================
2022-03-29 12:03:53,805: time cost, forward:0.20767866354057216, backward:0.04453348539590314, data cost:0.34833327909304446 
2022-03-29 12:03:53,806: ============================================================
2022-03-29 12:03:53,806: Epoch 4/31 Batch 3200/7662 eta: 1 day, 11:11:37.398755	Training Loss 0.8254 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.020)	
2022-03-29 12:03:53,806: ============================================================
2022-03-29 12:04:54,007: time cost, forward:0.20778371493503447, backward:0.04454376929526836, data cost:0.34825578780924416 
2022-03-29 12:04:54,007: ============================================================
2022-03-29 12:04:54,008: Epoch 4/31 Batch 3300/7662 eta: 1 day, 11:19:27.958764	Training Loss 0.8253 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.020)	
2022-03-29 12:04:54,008: ============================================================
2022-03-29 12:05:54,030: time cost, forward:0.207894658228691, backward:0.04458459393702454, data cost:0.34807925990273864 
2022-03-29 12:05:54,030: ============================================================
2022-03-29 12:05:54,030: Epoch 4/31 Batch 3400/7662 eta: 1 day, 11:12:10.327089	Training Loss 0.8247 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.020)	
2022-03-29 12:05:54,030: ============================================================
2022-03-29 12:06:52,368: time cost, forward:0.20773393346705277, backward:0.044570364792641995, data cost:0.347751803723837 
2022-03-29 12:06:52,369: ============================================================
2022-03-29 12:06:52,369: Epoch 4/31 Batch 3500/7662 eta: 1 day, 10:11:55.758909	Training Loss 0.8245 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.019)	
2022-03-29 12:06:52,369: ============================================================
2022-03-29 12:07:51,566: time cost, forward:0.2077273330147911, backward:0.04457028695827525, data cost:0.3475224149661052 
2022-03-29 12:07:51,566: ============================================================
2022-03-29 12:07:51,566: Epoch 4/31 Batch 3600/7662 eta: 1 day, 10:41:09.427537	Training Loss 0.8248 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.019)	
2022-03-29 12:07:51,566: ============================================================
2022-03-29 12:08:51,919: time cost, forward:0.20775615327839725, backward:0.044588768536994894, data cost:0.3475565198757546 
2022-03-29 12:08:51,919: ============================================================
2022-03-29 12:08:51,919: Epoch 4/31 Batch 3700/7662 eta: 1 day, 11:20:46.173458	Training Loss 0.8256 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.019)	
2022-03-29 12:08:51,919: ============================================================
2022-03-29 12:09:51,693: time cost, forward:0.20774913028718045, backward:0.044586308035733796, data cost:0.3474981598428564 
2022-03-29 12:09:51,693: ============================================================
2022-03-29 12:09:51,694: Epoch 4/31 Batch 3800/7662 eta: 1 day, 10:59:27.089332	Training Loss 0.8242 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.019)	
2022-03-29 12:09:51,694: ============================================================
2022-03-29 12:10:50,152: time cost, forward:0.20757809697924348, backward:0.04452361305972557, data cost:0.34735154011030017 
2022-03-29 12:10:50,152: ============================================================
2022-03-29 12:10:50,153: Epoch 4/31 Batch 3900/7662 eta: 1 day, 10:12:16.301640	Training Loss 0.8247 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.019)	
2022-03-29 12:10:50,153: ============================================================
2022-03-29 12:11:46,953: time cost, forward:0.2073820626386913, backward:0.04446445849276268, data cost:0.3468112105517186 
2022-03-29 12:11:46,953: ============================================================
2022-03-29 12:11:46,953: Epoch 4/31 Batch 4000/7662 eta: 1 day, 9:13:06.518766	Training Loss 0.8242 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-29 12:11:46,954: ============================================================
2022-03-29 12:12:50,693: time cost, forward:0.20806126392129048, backward:0.044503406595386916, data cost:0.3470036981745038 
2022-03-29 12:12:50,694: ============================================================
2022-03-29 12:12:50,695: Epoch 4/31 Batch 4100/7662 eta: 1 day, 13:15:34.944053	Training Loss 0.8246 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-29 12:12:50,695: ============================================================
2022-03-29 12:13:51,832: time cost, forward:0.20850591586867695, backward:0.04451596836272692, data cost:0.34682331042052394 
2022-03-29 12:13:51,832: ============================================================
2022-03-29 12:13:51,833: Epoch 4/31 Batch 4200/7662 eta: 1 day, 11:43:15.939392	Training Loss 0.8249 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-29 12:13:51,833: ============================================================
2022-03-29 12:14:54,223: time cost, forward:0.2089514386296189, backward:0.04452359956429431, data cost:0.34692366929019874 
2022-03-29 12:14:54,224: ============================================================
2022-03-29 12:14:54,224: Epoch 4/31 Batch 4300/7662 eta: 1 day, 12:26:10.075490	Training Loss 0.8250 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-29 12:14:54,224: ============================================================
2022-03-29 12:15:52,973: time cost, forward:0.20897310651088472, backward:0.04449301357837286, data cost:0.3466393967654711 
2022-03-29 12:15:52,973: ============================================================
2022-03-29 12:15:52,973: Epoch 4/31 Batch 4400/7662 eta: 1 day, 10:17:34.014042	Training Loss 0.8248 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-29 12:15:52,974: ============================================================
2022-03-29 12:16:51,952: time cost, forward:0.20911222347870856, backward:0.04447276440162769, data cost:0.3462747535485113 
2022-03-29 12:16:51,952: ============================================================
2022-03-29 12:16:51,952: Epoch 4/31 Batch 4500/7662 eta: 1 day, 10:24:37.166571	Training Loss 0.8254 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-29 12:16:51,953: ============================================================
2022-03-29 12:17:54,982: time cost, forward:0.2096420827443819, backward:0.04448523161644053, data cost:0.34638276621683134 
2022-03-29 12:17:54,983: ============================================================
2022-03-29 12:17:54,983: Epoch 4/31 Batch 4600/7662 eta: 1 day, 12:45:25.440811	Training Loss 0.8243 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-29 12:17:54,983: ============================================================
2022-03-29 12:18:52,419: time cost, forward:0.2096211107062847, backward:0.04444997562807046, data cost:0.34587193961142476 
2022-03-29 12:18:52,420: ============================================================
2022-03-29 12:18:52,420: Epoch 4/31 Batch 4700/7662 eta: 1 day, 9:28:44.237359	Training Loss 0.8247 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.195 (0.018)	
2022-03-29 12:18:52,421: ============================================================
2022-03-29 12:19:53,918: time cost, forward:0.20995051261161013, backward:0.044455649281919286, data cost:0.34584720732396185 
2022-03-29 12:19:53,919: ============================================================
2022-03-29 12:19:53,919: Epoch 4/31 Batch 4800/7662 eta: 1 day, 11:49:45.166679	Training Loss 0.8257 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-29 12:19:53,919: ============================================================
2022-03-29 12:20:55,572: time cost, forward:0.21028245198626888, backward:0.04447215074031882, data cost:0.34584119563736365 
2022-03-29 12:20:55,572: ============================================================
2022-03-29 12:20:55,573: Epoch 4/31 Batch 4900/7662 eta: 1 day, 11:54:09.261197	Training Loss 0.8248 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-29 12:20:55,573: ============================================================
2022-03-29 12:21:56,285: time cost, forward:0.21050729267977314, backward:0.044458135840272306, data cost:0.3457308476580265 
2022-03-29 12:21:56,285: ============================================================
2022-03-29 12:21:56,285: Epoch 4/31 Batch 5000/7662 eta: 1 day, 11:20:15.506523	Training Loss 0.8252 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-29 12:21:56,286: ============================================================
2022-03-29 12:22:58,284: time cost, forward:0.2107930084283877, backward:0.04445836375240813, data cost:0.34581697559936486 
2022-03-29 12:22:58,285: ============================================================
2022-03-29 12:22:58,286: Epoch 4/31 Batch 5100/7662 eta: 1 day, 12:04:11.041365	Training Loss 0.8255 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-29 12:22:58,286: ============================================================
2022-03-29 12:23:58,212: time cost, forward:0.21088079792601624, backward:0.0444194572112679, data cost:0.3457561197315736 
2022-03-29 12:23:58,213: ============================================================
2022-03-29 12:23:58,213: Epoch 4/31 Batch 5200/7662 eta: 1 day, 10:50:50.973215	Training Loss 0.8254 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-29 12:23:58,213: ============================================================
2022-03-29 12:24:51,569: time cost, forward:0.21027019325799146, backward:0.04437461842408966, data cost:0.3451226527881208 
2022-03-29 12:24:51,569: ============================================================
2022-03-29 12:24:51,569: Epoch 4/31 Batch 5300/7662 eta: 1 day, 7:00:40.668708	Training Loss 0.8246 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-29 12:24:51,570: ============================================================
2022-03-29 12:25:51,205: time cost, forward:0.21013303985638096, backward:0.04437194013622077, data cost:0.34517363844855803 
2022-03-29 12:25:51,206: ============================================================
2022-03-29 12:25:51,206: Epoch 4/31 Batch 5400/7662 eta: 1 day, 10:38:42.090970	Training Loss 0.8243 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-29 12:25:51,206: ============================================================
2022-03-29 12:26:50,361: time cost, forward:0.21000088707146417, backward:0.04438545912433742, data cost:0.34514364166072464 
2022-03-29 12:26:50,361: ============================================================
2022-03-29 12:26:50,362: Epoch 4/31 Batch 5500/7662 eta: 1 day, 10:20:57.486440	Training Loss 0.8250 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-29 12:26:50,362: ============================================================
2022-03-29 12:27:48,347: time cost, forward:0.20983290625461662, backward:0.044389578972060376, data cost:0.34494748352297416 
2022-03-29 12:27:48,348: ============================================================
2022-03-29 12:27:48,348: Epoch 4/31 Batch 5600/7662 eta: 1 day, 9:39:15.394532	Training Loss 0.8251 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-29 12:27:48,348: ============================================================
2022-03-29 12:28:46,257: time cost, forward:0.20960183866527293, backward:0.04438427243866112, data cost:0.3448251847489547 
2022-03-29 12:28:46,257: ============================================================
2022-03-29 12:28:46,257: Epoch 4/31 Batch 5700/7662 eta: 1 day, 9:35:35.630769	Training Loss 0.8247 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-29 12:28:46,257: ============================================================
2022-03-29 12:29:46,310: time cost, forward:0.20950374892712215, backward:0.04440212734897993, data cost:0.3449320976930274 
2022-03-29 12:29:46,310: ============================================================
2022-03-29 12:29:46,310: Epoch 4/31 Batch 5800/7662 eta: 1 day, 10:49:12.562809	Training Loss 0.8251 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-29 12:29:46,310: ============================================================
2022-03-29 12:30:46,134: time cost, forward:0.2094000704633238, backward:0.044411009217666594, data cost:0.3450104417104118 
2022-03-29 12:30:46,135: ============================================================
2022-03-29 12:30:46,135: Epoch 4/31 Batch 5900/7662 eta: 1 day, 10:40:16.989843	Training Loss 0.8252 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-29 12:30:46,135: ============================================================
2022-03-29 12:31:43,424: time cost, forward:0.209167134783669, backward:0.044406170287834126, data cost:0.3448032264531424 
2022-03-29 12:31:43,424: ============================================================
2022-03-29 12:31:43,425: Epoch 4/31 Batch 6000/7662 eta: 1 day, 9:11:09.890128	Training Loss 0.8251 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-29 12:31:43,425: ============================================================
2022-03-29 12:32:41,773: time cost, forward:0.20890816256030112, backward:0.04438937752144046, data cost:0.3448567940067279 
2022-03-29 12:32:41,774: ============================================================
2022-03-29 12:32:41,774: Epoch 4/31 Batch 6100/7662 eta: 1 day, 9:47:01.386132	Training Loss 0.8251 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-29 12:32:41,774: ============================================================
2022-03-29 12:33:39,559: time cost, forward:0.20870952153132796, backward:0.044380764977396216, data cost:0.3447112255585657 
2022-03-29 12:33:39,559: ============================================================
2022-03-29 12:33:39,560: Epoch 4/31 Batch 6200/7662 eta: 1 day, 9:26:29.200615	Training Loss 0.8241 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-29 12:33:39,560: ============================================================
2022-03-29 12:34:37,393: time cost, forward:0.20847934627366418, backward:0.044373626235099536, data cost:0.3446301107350598 
2022-03-29 12:34:37,394: ============================================================
2022-03-29 12:34:37,394: Epoch 4/31 Batch 6300/7662 eta: 1 day, 9:27:12.135833	Training Loss 0.8249 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-29 12:34:37,394: ============================================================
2022-03-29 12:35:37,589: time cost, forward:0.20845462255392955, backward:0.04438891830360876, data cost:0.3447065162256297 
2022-03-29 12:35:37,589: ============================================================
2022-03-29 12:35:37,589: Epoch 4/31 Batch 6400/7662 eta: 1 day, 10:48:09.104643	Training Loss 0.8250 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.195 (0.018)	
2022-03-29 12:35:37,590: ============================================================
2022-03-29 12:36:35,740: time cost, forward:0.20829619325331714, backward:0.0443821642321428, data cost:0.3446181314984621 
2022-03-29 12:36:35,740: ============================================================
2022-03-29 12:36:35,740: Epoch 4/31 Batch 6500/7662 eta: 1 day, 9:36:15.767533	Training Loss 0.8239 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-29 12:36:35,741: ============================================================
2022-03-29 12:37:35,337: time cost, forward:0.20826605757649586, backward:0.044315570411329504, data cost:0.3446873073994093 
2022-03-29 12:37:35,338: ============================================================
2022-03-29 12:37:35,338: Epoch 4/31 Batch 6600/7662 eta: 1 day, 10:25:25.515515	Training Loss 0.8254 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.195 (0.018)	
2022-03-29 12:37:35,338: ============================================================
2022-03-29 12:38:34,905: time cost, forward:0.20830633701148504, backward:0.044296793233709456, data cost:0.34463852369032577 
2022-03-29 12:38:34,905: ============================================================
2022-03-29 12:38:34,906: Epoch 4/31 Batch 6700/7662 eta: 1 day, 10:23:23.271022	Training Loss 0.8246 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-29 12:38:34,906: ============================================================
2022-03-29 12:39:34,117: time cost, forward:0.208220879248546, backward:0.04427224338922558, data cost:0.3446688906622908 
2022-03-29 12:39:34,117: ============================================================
2022-03-29 12:39:34,117: Epoch 4/31 Batch 6800/7662 eta: 1 day, 10:10:04.560118	Training Loss 0.8258 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-29 12:39:34,117: ============================================================
2022-03-29 12:40:31,610: time cost, forward:0.20808466874545753, backward:0.044264042579638715, data cost:0.3444878368347274 
2022-03-29 12:40:31,611: ============================================================
2022-03-29 12:40:31,611: Epoch 4/31 Batch 6900/7662 eta: 1 day, 9:09:37.795415	Training Loss 0.8246 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-29 12:40:31,611: ============================================================
2022-03-29 12:41:31,896: time cost, forward:0.20810779194641768, backward:0.04428592244630746, data cost:0.3445298718050354 
2022-03-29 12:41:31,896: ============================================================
2022-03-29 12:41:31,897: Epoch 4/31 Batch 7000/7662 eta: 1 day, 10:45:15.261041	Training Loss 0.8255 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-29 12:41:31,897: ============================================================
2022-03-29 12:42:27,862: time cost, forward:0.2079030822273509, backward:0.04425877912865002, data cost:0.344225450105475 
2022-03-29 12:42:27,862: ============================================================
2022-03-29 12:42:27,862: Epoch 4/31 Batch 7100/7662 eta: 1 day, 8:14:53.252401	Training Loss 0.8255 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-29 12:42:27,862: ============================================================
2022-03-29 12:43:24,880: time cost, forward:0.2077012019681341, backward:0.044256787479611, data cost:0.3440764341143738 
2022-03-29 12:43:24,880: ============================================================
2022-03-29 12:43:24,880: Epoch 4/31 Batch 7200/7662 eta: 1 day, 8:50:19.472712	Training Loss 0.8261 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-29 12:43:24,880: ============================================================
2022-03-29 12:44:20,014: time cost, forward:0.20742712913922928, backward:0.044228416940156265, data cost:0.34374773203469183 
2022-03-29 12:44:20,014: ============================================================
2022-03-29 12:44:20,015: Epoch 4/31 Batch 7300/7662 eta: 1 day, 7:44:18.894089	Training Loss 0.8250 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-29 12:44:20,015: ============================================================
2022-03-29 12:45:17,838: time cost, forward:0.20728364173166333, backward:0.04422444268680453, data cost:0.34365386337118387 
2022-03-29 12:45:17,839: ============================================================
2022-03-29 12:45:17,839: Epoch 4/31 Batch 7400/7662 eta: 1 day, 9:16:15.689788	Training Loss 0.8248 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-29 12:45:17,839: ============================================================
2022-03-29 12:46:14,653: time cost, forward:0.20707221262644793, backward:0.04421348965379425, data cost:0.3435077698711777 
2022-03-29 12:46:14,654: ============================================================
2022-03-29 12:46:14,654: Epoch 4/31 Batch 7500/7662 eta: 1 day, 8:40:27.960605	Training Loss 0.8256 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-29 12:46:14,654: ============================================================
2022-03-29 12:47:12,915: time cost, forward:0.206955478165962, backward:0.04421072323740525, data cost:0.34346467345180376 
2022-03-29 12:47:12,916: ============================================================
2022-03-29 12:47:12,916: Epoch 4/31 Batch 7600/7662 eta: 1 day, 9:29:26.517270	Training Loss 0.8250 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)	
2022-03-29 12:47:12,916: ============================================================
2022-03-29 12:47:50,146: Epoch: 4/31 eta: 1 day, 9:28:49.811942	Training Loss 0.8247 (0.8249)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.018)
2022-03-29 12:47:50,146: ============================================================
2022-03-29 12:48:52,777: time cost, forward:0.27747617345867737, backward:0.04534773633937643, data cost:0.3065241948522703 
2022-03-29 12:48:52,777: ============================================================
2022-03-29 12:48:52,778: Epoch 5/31 Batch 100/7662 eta: 1 day, 11:57:01.455345	Training Loss 0.8240 (0.8245)	Training Prec@1 0.195 (0.006)	Training Prec@5 0.195 (0.024)	
2022-03-29 12:48:52,778: ============================================================
2022-03-29 12:50:03,389: time cost, forward:0.326534423396815, backward:0.04668806186273469, data cost:0.29419169114462695 
2022-03-29 12:50:03,390: ============================================================
2022-03-29 12:50:03,390: Epoch 5/31 Batch 200/7662 eta: 1 day, 16:32:17.825989	Training Loss 0.8254 (0.8245)	Training Prec@1 0.000 (0.009)	Training Prec@5 0.000 (0.026)	
2022-03-29 12:50:03,390: ============================================================
2022-03-29 12:51:08,506: time cost, forward:0.3264043147747333, backward:0.04639148393203582, data cost:0.28897960847835474 
2022-03-29 12:51:08,506: ============================================================
2022-03-29 12:51:08,507: Epoch 5/31 Batch 300/7662 eta: 1 day, 13:21:54.745072	Training Loss 0.8249 (0.8245)	Training Prec@1 0.000 (0.010)	Training Prec@5 0.000 (0.025)	
2022-03-29 12:51:08,507: ============================================================
2022-03-29 12:52:05,751: time cost, forward:0.3025094763676923, backward:0.04512932844329299, data cost:0.2918020173123008 
2022-03-29 12:52:05,751: ============================================================
2022-03-29 12:52:05,752: Epoch 5/31 Batch 400/7662 eta: 1 day, 8:49:56.242831	Training Loss 0.8246 (0.8245)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.022)	
2022-03-29 12:52:05,752: ============================================================
2022-03-29 12:53:03,092: time cost, forward:0.2864036039264503, backward:0.044362268849221884, data cost:0.29532364088452173 
2022-03-29 12:53:03,093: ============================================================
2022-03-29 12:53:03,093: Epoch 5/31 Batch 500/7662 eta: 1 day, 8:52:17.981936	Training Loss 0.8241 (0.8245)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.022)	
2022-03-29 12:53:03,093: ============================================================
2022-03-29 12:54:00,499: time cost, forward:0.2769712546034926, backward:0.04374220733451525, data cost:0.29645478745334736 
2022-03-29 12:54:00,500: ============================================================
2022-03-29 12:54:00,500: Epoch 5/31 Batch 600/7662 eta: 1 day, 8:53:36.576594	Training Loss 0.8246 (0.8246)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.022)	
2022-03-29 12:54:00,500: ============================================================
2022-03-29 12:54:59,755: time cost, forward:0.2719068953578223, backward:0.04374468411839912, data cost:0.29793394993303157 
2022-03-29 12:54:59,755: ============================================================
2022-03-29 12:54:59,756: Epoch 5/31 Batch 700/7662 eta: 1 day, 9:56:10.370395	Training Loss 0.8256 (0.8246)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.022)	
2022-03-29 12:54:59,756: ============================================================
2022-03-29 12:55:59,621: time cost, forward:0.26932692826167215, backward:0.04368640514130288, data cost:0.29862357051262123 
2022-03-29 12:55:59,622: ============================================================
2022-03-29 12:55:59,622: Epoch 5/31 Batch 800/7662 eta: 1 day, 10:16:09.194943	Training Loss 0.8243 (0.8246)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.021)	
2022-03-29 12:55:59,622: ============================================================
2022-03-29 12:56:59,744: time cost, forward:0.2660957958064435, backward:0.04391911403753601, data cost:0.3004339823335641 
2022-03-29 12:56:59,745: ============================================================
2022-03-29 12:56:59,745: Epoch 5/31 Batch 900/7662 eta: 1 day, 10:23:58.720316	Training Loss 0.8246 (0.8246)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.021)	
2022-03-29 12:56:59,745: ============================================================
2022-03-29 12:57:59,384: time cost, forward:0.26343471676976354, backward:0.04398711283763011, data cost:0.3014839726525384 
2022-03-29 12:57:59,384: ============================================================
2022-03-29 12:57:59,385: Epoch 5/31 Batch 1000/7662 eta: 1 day, 10:06:23.024125	Training Loss 0.8240 (0.8246)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.020)	
2022-03-29 12:57:59,385: ============================================================
2022-03-29 12:59:00,222: time cost, forward:0.2616753697503795, backward:0.04379270877265409, data cost:0.30338702601015405 
2022-03-29 12:59:00,223: ============================================================
2022-03-29 12:59:00,223: Epoch 5/31 Batch 1100/7662 eta: 1 day, 10:46:29.930363	Training Loss 0.8254 (0.8246)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.020)	
2022-03-29 12:59:00,223: ============================================================
2022-03-29 13:00:02,481: time cost, forward:0.26045907249641576, backward:0.042789643361630096, data cost:0.3064615332752193 
2022-03-29 13:00:02,481: ============================================================
2022-03-29 13:00:02,482: Epoch 5/31 Batch 1200/7662 eta: 1 day, 11:34:10.772741	Training Loss 0.8250 (0.8246)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.019)	
2022-03-29 13:00:02,482: ============================================================
2022-03-29 13:01:02,838: time cost, forward:0.2576573462188932, backward:0.0418914918994977, data cost:0.3098823161562009 
2022-03-29 13:01:02,839: ============================================================
2022-03-29 13:01:02,839: Epoch 5/31 Batch 1300/7662 eta: 1 day, 10:27:59.959209	Training Loss 0.8252 (0.8246)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.020)	
2022-03-29 13:01:02,839: ============================================================
2022-03-29 13:02:03,727: time cost, forward:0.2563964306583909, backward:0.041342432623339004, data cost:0.31162257617162414 
2022-03-29 13:02:03,728: ============================================================
2022-03-29 13:02:03,728: Epoch 5/31 Batch 1400/7662 eta: 1 day, 10:45:11.201350	Training Loss 0.8243 (0.8246)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.020)	
2022-03-29 13:02:03,728: ============================================================
2022-03-29 13:03:03,605: time cost, forward:0.2541958476162657, backward:0.04167332277049853, data cost:0.31275530780769334 
2022-03-29 13:03:03,606: ============================================================
2022-03-29 13:03:03,606: Epoch 5/31 Batch 1500/7662 eta: 1 day, 10:09:34.368606	Training Loss 0.8243 (0.8246)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.019)	
2022-03-29 13:03:03,606: ============================================================
2022-03-29 13:04:02,388: time cost, forward:0.2520541782450721, backward:0.04170694717994103, data cost:0.31354504350276946 
2022-03-29 13:04:02,389: ============================================================
2022-03-29 13:04:02,389: Epoch 5/31 Batch 1600/7662 eta: 1 day, 9:31:06.595234	Training Loss 0.8242 (0.8246)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.018)	
2022-03-29 13:04:02,389: ============================================================
2022-03-29 13:04:59,247: time cost, forward:0.2498124358652619, backward:0.04187121076959943, data cost:0.3133000028070244 
2022-03-29 13:04:59,248: ============================================================
2022-03-29 13:04:59,248: Epoch 5/31 Batch 1700/7662 eta: 1 day, 8:24:21.089601	Training Loss 0.8251 (0.8246)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.019)	
2022-03-29 13:04:59,248: ============================================================
2022-03-29 13:05:57,770: time cost, forward:0.2476868101992562, backward:0.0420869527226226, data cost:0.3140743979485317 
2022-03-29 13:05:57,771: ============================================================
2022-03-29 13:05:57,771: Epoch 5/31 Batch 1800/7662 eta: 1 day, 9:20:15.576786	Training Loss 0.8244 (0.8246)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.018)	
2022-03-29 13:05:57,771: ============================================================
2022-03-29 13:06:56,403: time cost, forward:0.24586068824318097, backward:0.04223596704451896, data cost:0.3148037488363868 
2022-03-29 13:06:56,404: ============================================================
2022-03-29 13:06:56,404: Epoch 5/31 Batch 1900/7662 eta: 1 day, 9:23:03.948899	Training Loss 0.8256 (0.8246)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.018)	
2022-03-29 13:06:56,405: ============================================================
2022-03-29 13:07:54,455: time cost, forward:0.24414239089568893, backward:0.04237403936419504, data cost:0.31524325132727804 
2022-03-29 13:07:54,455: ============================================================
2022-03-29 13:07:54,455: Epoch 5/31 Batch 2000/7662 eta: 1 day, 9:02:12.162826	Training Loss 0.8245 (0.8246)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.018)	
2022-03-29 13:07:54,456: ============================================================
2022-03-29 13:08:52,468: time cost, forward:0.24252269925703146, backward:0.042528220731454444, data cost:0.3156437922682633 
2022-03-29 13:08:52,468: ============================================================
2022-03-29 13:08:52,469: Epoch 5/31 Batch 2100/7662 eta: 1 day, 8:59:56.339497	Training Loss 0.8243 (0.8246)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.018)	
2022-03-29 13:08:52,469: ============================================================
2022-03-29 13:09:50,375: time cost, forward:0.24095366422888256, backward:0.04262641463945431, data cost:0.31611627294237693 
2022-03-29 13:09:50,375: ============================================================
2022-03-29 13:09:50,375: Epoch 5/31 Batch 2200/7662 eta: 1 day, 8:55:20.626825	Training Loss 0.8250 (0.8246)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.018)	
2022-03-29 13:09:50,376: ============================================================
2022-03-29 13:10:47,930: time cost, forward:0.23973133253916393, backward:0.04276511605898677, data cost:0.31611367825478665 
2022-03-29 13:10:47,931: ============================================================
2022-03-29 13:10:47,931: Epoch 5/31 Batch 2300/7662 eta: 1 day, 8:42:25.081635	Training Loss 0.8248 (0.8246)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.018)	
2022-03-29 13:10:47,932: ============================================================
2022-03-29 13:11:46,486: time cost, forward:0.2384604299600147, backward:0.04291628091819289, data cost:0.316683280065488 
2022-03-29 13:11:46,487: ============================================================
2022-03-29 13:11:46,487: Epoch 5/31 Batch 2400/7662 eta: 1 day, 9:15:32.410726	Training Loss 0.8249 (0.8246)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.017)	
2022-03-29 13:11:46,488: ============================================================
2022-03-29 13:12:43,670: time cost, forward:0.23721460964070076, backward:0.04300012994928806, data cost:0.31677977358545956 
2022-03-29 13:12:43,670: ============================================================
2022-03-29 13:12:43,671: Epoch 5/31 Batch 2500/7662 eta: 1 day, 8:27:47.929897	Training Loss 0.8245 (0.8246)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.018)	
2022-03-29 13:12:43,671: ============================================================
2022-03-29 13:13:40,636: time cost, forward:0.2361921391701781, backward:0.04305275718539254, data cost:0.31667641824646703 
2022-03-29 13:13:40,636: ============================================================
2022-03-29 13:13:40,637: Epoch 5/31 Batch 2600/7662 eta: 1 day, 8:19:28.313581	Training Loss 0.8249 (0.8246)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.018)	
2022-03-29 13:13:40,637: ============================================================
2022-03-29 13:14:42,457: time cost, forward:0.23619300659253184, backward:0.04315243327383555, data cost:0.3173905091181469 
2022-03-29 13:14:42,458: ============================================================
2022-03-29 13:14:42,458: Epoch 5/31 Batch 2700/7662 eta: 1 day, 11:03:43.042530	Training Loss 0.8252 (0.8247)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.017)	
2022-03-29 13:14:42,458: ============================================================
2022-03-29 13:15:42,376: time cost, forward:0.23586971421631883, backward:0.043222867577959276, data cost:0.31770791850715246 
2022-03-29 13:15:42,376: ============================================================
2022-03-29 13:15:42,377: Epoch 5/31 Batch 2800/7662 eta: 1 day, 9:57:58.738125	Training Loss 0.8249 (0.8247)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.195 (0.017)	
2022-03-29 13:15:42,377: ============================================================
2022-03-29 13:16:40,137: time cost, forward:0.23505161046241638, backward:0.04330254604422499, data cost:0.31777005312400836 
2022-03-29 13:16:40,137: ============================================================
2022-03-29 13:16:40,137: Epoch 5/31 Batch 2900/7662 eta: 1 day, 8:43:37.787550	Training Loss 0.8247 (0.8247)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.017)	
2022-03-29 13:16:40,138: ============================================================
2022-03-29 13:17:38,328: time cost, forward:0.23414115478055164, backward:0.04339721617042005, data cost:0.31809498739862646 
2022-03-29 13:17:38,329: ============================================================
2022-03-29 13:17:38,329: Epoch 5/31 Batch 3000/7662 eta: 1 day, 8:57:17.544297	Training Loss 0.8237 (0.8247)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.017)	
2022-03-29 13:17:38,329: ============================================================
2022-03-29 13:18:36,773: time cost, forward:0.23331339507766138, backward:0.04348011561538682, data cost:0.3184471518887978 
2022-03-29 13:18:36,773: ============================================================
2022-03-29 13:18:36,774: Epoch 5/31 Batch 3100/7662 eta: 1 day, 9:04:56.102336	Training Loss 0.8248 (0.8247)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.017)	
2022-03-29 13:18:36,774: ============================================================
2022-03-29 13:19:34,594: time cost, forward:0.23254180081228273, backward:0.04353949158368315, data cost:0.31863014352958846 
2022-03-29 13:19:34,595: ============================================================
2022-03-29 13:19:34,595: Epoch 5/31 Batch 3200/7662 eta: 1 day, 8:42:47.054521	Training Loss 0.8247 (0.8247)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.017)	
2022-03-29 13:19:34,595: ============================================================
2022-03-29 13:20:34,687: time cost, forward:0.2321874046007696, backward:0.043593313738084914, data cost:0.3191065166024737 
2022-03-29 13:20:34,688: ============================================================
2022-03-29 13:20:34,688: Epoch 5/31 Batch 3300/7662 eta: 1 day, 9:58:54.738145	Training Loss 0.8249 (0.8247)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.017)	
2022-03-29 13:20:34,688: ============================================================
2022-03-29 13:21:31,955: time cost, forward:0.23150687113899665, backward:0.04360452502150506, data cost:0.3191083816613615 
2022-03-29 13:21:31,956: ============================================================
2022-03-29 13:21:31,956: Epoch 5/31 Batch 3400/7662 eta: 1 day, 8:22:06.091393	Training Loss 0.8259 (0.8247)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.017)	
2022-03-29 13:21:31,956: ============================================================
2022-03-29 13:22:29,064: time cost, forward:0.2307900783503931, backward:0.04367398861375118, data cost:0.31908206906990516 
2022-03-29 13:22:29,065: ============================================================
2022-03-29 13:22:29,065: Epoch 5/31 Batch 3500/7662 eta: 1 day, 8:15:45.295826	Training Loss 0.8253 (0.8247)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.018)	
2022-03-29 13:22:29,065: ============================================================
2022-03-29 13:23:26,295: time cost, forward:0.23022978588686152, backward:0.043737033699313345, data cost:0.3189806739434033 
2022-03-29 13:23:26,296: ============================================================
2022-03-29 13:23:26,296: Epoch 5/31 Batch 3600/7662 eta: 1 day, 8:18:56.651970	Training Loss 0.8241 (0.8247)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.017)	
2022-03-29 13:23:26,296: ============================================================
2022-03-29 13:24:24,092: time cost, forward:0.2299686616483525, backward:0.04379380461524454, data cost:0.3187689331293944 
2022-03-29 13:24:24,093: ============================================================
2022-03-29 13:24:24,093: Epoch 5/31 Batch 3700/7662 eta: 1 day, 8:37:08.878286	Training Loss 0.8246 (0.8247)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.017)	
2022-03-29 13:24:24,093: ============================================================
2022-03-29 13:25:21,862: time cost, forward:0.22957187020235797, backward:0.043769490376809106, data cost:0.31878427500221473 
2022-03-29 13:25:21,863: ============================================================
2022-03-29 13:25:21,863: Epoch 5/31 Batch 3800/7662 eta: 1 day, 8:35:16.063851	Training Loss 0.8255 (0.8247)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.017)	
2022-03-29 13:25:21,863: ============================================================
2022-03-29 13:26:20,127: time cost, forward:0.2291283793986287, backward:0.04385391196461022, data cost:0.31887488360281446 
2022-03-29 13:26:20,128: ============================================================
2022-03-29 13:26:20,128: Epoch 5/31 Batch 3900/7662 eta: 1 day, 8:51:03.983068	Training Loss 0.8246 (0.8247)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.017)	
2022-03-29 13:26:20,128: ============================================================
2022-03-29 13:27:18,760: time cost, forward:0.22886686600515563, backward:0.04385946547576683, data cost:0.31898021793389325 
2022-03-29 13:27:18,761: ============================================================
2022-03-29 13:27:18,761: Epoch 5/31 Batch 4000/7662 eta: 1 day, 9:02:30.929471	Training Loss 0.8248 (0.8247)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.017)	
2022-03-29 13:27:18,761: ============================================================
2022-03-29 13:28:17,618: time cost, forward:0.2286799724697049, backward:0.043902793085322085, data cost:0.31904023401502807 
2022-03-29 13:28:17,619: ============================================================
2022-03-29 13:28:17,619: Epoch 5/31 Batch 4100/7662 eta: 1 day, 9:09:09.515049	Training Loss 0.8249 (0.8247)	Training Prec@1 0.195 (0.005)	Training Prec@5 0.195 (0.017)	
2022-03-29 13:28:17,619: ============================================================
2022-03-29 13:29:19,064: time cost, forward:0.22877811068266624, backward:0.043938750509819435, data cost:0.3193155328101503 
2022-03-29 13:29:19,065: ============================================================
2022-03-29 13:29:19,065: Epoch 5/31 Batch 4200/7662 eta: 1 day, 10:35:36.360584	Training Loss 0.8243 (0.8247)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.017)	
2022-03-29 13:29:19,065: ============================================================
2022-03-29 13:30:20,633: time cost, forward:0.22910249629778262, backward:0.04398070825868275, data cost:0.31960600552156265 
2022-03-29 13:30:20,633: ============================================================
2022-03-29 13:30:20,633: Epoch 5/31 Batch 4300/7662 eta: 1 day, 10:38:41.462611	Training Loss 0.8248 (0.8247)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.017)	
2022-03-29 13:30:20,633: ============================================================
2022-03-29 13:31:22,352: time cost, forward:0.22954954242511186, backward:0.04400996713102826, data cost:0.3196781399196374 
2022-03-29 13:31:22,353: ============================================================
2022-03-29 13:31:22,353: Epoch 5/31 Batch 4400/7662 eta: 1 day, 10:42:47.425237	Training Loss 0.8248 (0.8247)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.017)	
2022-03-29 13:31:22,353: ============================================================
2022-03-29 13:32:25,483: time cost, forward:0.23012919504395007, backward:0.04405582828186808, data cost:0.3198886396726467 
2022-03-29 13:32:25,484: ============================================================
2022-03-29 13:32:25,484: Epoch 5/31 Batch 4500/7662 eta: 1 day, 11:29:21.489680	Training Loss 0.8249 (0.8247)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.017)	
2022-03-29 13:32:25,485: ============================================================
2022-03-29 13:33:27,445: time cost, forward:0.23060016389462346, backward:0.04405286214123034, data cost:0.319959638844005 
2022-03-29 13:33:27,446: ============================================================
2022-03-29 13:33:27,446: Epoch 5/31 Batch 4600/7662 eta: 1 day, 10:48:53.182923	Training Loss 0.8262 (0.8247)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.017)	
2022-03-29 13:33:27,446: ============================================================
2022-03-29 13:34:28,153: time cost, forward:0.2306463258726644, backward:0.0440730622890884, data cost:0.32013920886284697 
2022-03-29 13:34:28,153: ============================================================
2022-03-29 13:34:28,154: Epoch 5/31 Batch 4700/7662 eta: 1 day, 10:05:35.176478	Training Loss 0.8240 (0.8247)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.017)	
2022-03-29 13:34:28,154: ============================================================
2022-03-29 13:35:27,696: time cost, forward:0.23047974234348687, backward:0.04411403813394911, data cost:0.32026454756025924 
2022-03-29 13:35:27,696: ============================================================
2022-03-29 13:35:27,697: Epoch 5/31 Batch 4800/7662 eta: 1 day, 9:25:21.538896	Training Loss 0.8238 (0.8247)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.017)	
2022-03-29 13:35:27,697: ============================================================
2022-03-29 13:36:26,983: time cost, forward:0.2302246183783552, backward:0.04415303119520042, data cost:0.3204326104524063 
2022-03-29 13:36:26,984: ============================================================
2022-03-29 13:36:26,984: Epoch 5/31 Batch 4900/7662 eta: 1 day, 9:15:45.355856	Training Loss 0.8253 (0.8247)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.018)	
2022-03-29 13:36:26,984: ============================================================
2022-03-29 13:37:25,613: time cost, forward:0.22985757944893423, backward:0.0441561515008385, data cost:0.3206157759681514 
2022-03-29 13:37:25,613: ============================================================
2022-03-29 13:37:25,614: Epoch 5/31 Batch 5000/7662 eta: 1 day, 8:52:39.278077	Training Loss 0.8254 (0.8247)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.018)	
2022-03-29 13:37:25,614: ============================================================
2022-03-29 13:38:23,405: time cost, forward:0.22956358855741824, backward:0.04417641903050017, data cost:0.3205529057902433 
2022-03-29 13:38:23,406: ============================================================
2022-03-29 13:38:23,407: Epoch 5/31 Batch 5100/7662 eta: 1 day, 8:23:31.325404	Training Loss 0.8249 (0.8247)	Training Prec@1 0.195 (0.005)	Training Prec@5 0.195 (0.018)	
2022-03-29 13:38:23,407: ============================================================
2022-03-29 13:39:21,377: time cost, forward:0.2292087809996872, backward:0.04417089921599467, data cost:0.3206227714452727 
2022-03-29 13:39:21,378: ============================================================
2022-03-29 13:39:21,378: Epoch 5/31 Batch 5200/7662 eta: 1 day, 8:28:33.957070	Training Loss 0.8248 (0.8247)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.018)	
2022-03-29 13:39:21,378: ============================================================
2022-03-29 13:40:20,143: time cost, forward:0.22909683608900805, backward:0.044146899120563333, data cost:0.32062946038103074 
2022-03-29 13:40:20,144: ============================================================
2022-03-29 13:40:20,144: Epoch 5/31 Batch 5300/7662 eta: 1 day, 8:54:17.644824	Training Loss 0.8249 (0.8247)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.018)	
2022-03-29 13:40:20,145: ============================================================
2022-03-29 13:41:18,447: time cost, forward:0.22880197710672073, backward:0.04411810405785606, data cost:0.32074691953869255 
2022-03-29 13:41:18,448: ============================================================
2022-03-29 13:41:18,448: Epoch 5/31 Batch 5400/7662 eta: 1 day, 8:37:48.545814	Training Loss 0.8245 (0.8247)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.195 (0.018)	
2022-03-29 13:41:18,449: ============================================================
2022-03-29 13:42:15,126: time cost, forward:0.22839344486493937, backward:0.04410437328812425, data cost:0.32067221714206384 
2022-03-29 13:42:15,127: ============================================================
2022-03-29 13:42:15,127: Epoch 5/31 Batch 5500/7662 eta: 1 day, 7:42:17.130081	Training Loss 0.8248 (0.8247)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.018)	
2022-03-29 13:42:15,127: ============================================================
2022-03-29 13:43:12,749: time cost, forward:0.22809238973782092, backward:0.04409269648676452, data cost:0.3206774769861542 
2022-03-29 13:43:12,749: ============================================================
2022-03-29 13:43:12,750: Epoch 5/31 Batch 5600/7662 eta: 1 day, 8:12:59.519283	Training Loss 0.8249 (0.8247)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.018)	
2022-03-29 13:43:12,750: ============================================================
2022-03-29 13:44:11,920: time cost, forward:0.22783159736918449, backward:0.04409507743767174, data cost:0.3209070362821339 
2022-03-29 13:44:11,921: ============================================================
2022-03-29 13:44:11,921: Epoch 5/31 Batch 5700/7662 eta: 1 day, 9:03:57.926435	Training Loss 0.8250 (0.8247)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.018)	
2022-03-29 13:44:11,921: ============================================================
2022-03-29 13:45:09,917: time cost, forward:0.22747173846271618, backward:0.04409396609348929, data cost:0.3210371473078523 
2022-03-29 13:45:09,918: ============================================================
2022-03-29 13:45:09,918: Epoch 5/31 Batch 5800/7662 eta: 1 day, 8:23:37.114390	Training Loss 0.8251 (0.8247)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.018)	
2022-03-29 13:45:09,918: ============================================================
2022-03-29 13:46:08,889: time cost, forward:0.22727108312918182, backward:0.0441024790054298, data cost:0.3211531169860317 
2022-03-29 13:46:08,889: ============================================================
2022-03-29 13:46:08,890: Epoch 5/31 Batch 5900/7662 eta: 1 day, 8:55:18.668665	Training Loss 0.8246 (0.8247)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.019)	
2022-03-29 13:46:08,890: ============================================================
2022-03-29 13:47:07,862: time cost, forward:0.22712632119009785, backward:0.04408182925354502, data cost:0.32128228781958146 
2022-03-29 13:47:07,863: ============================================================
2022-03-29 13:47:07,863: Epoch 5/31 Batch 6000/7662 eta: 1 day, 8:54:22.403214	Training Loss 0.8253 (0.8247)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.018)	
2022-03-29 13:47:07,863: ============================================================
2022-03-29 13:48:05,348: time cost, forward:0.2269488601024707, backward:0.04409190083472606, data cost:0.3211561313397104 
2022-03-29 13:48:05,348: ============================================================
2022-03-29 13:48:05,349: Epoch 5/31 Batch 6100/7662 eta: 1 day, 8:03:36.627226	Training Loss 0.8251 (0.8247)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.018)	
2022-03-29 13:48:05,349: ============================================================
2022-03-29 13:49:02,622: time cost, forward:0.22663985580989557, backward:0.04408685048369943, data cost:0.32115102187339906 
2022-03-29 13:49:02,623: ============================================================
2022-03-29 13:49:02,623: Epoch 5/31 Batch 6200/7662 eta: 1 day, 7:55:35.535678	Training Loss 0.8251 (0.8247)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.018)	
2022-03-29 13:49:02,623: ============================================================
2022-03-29 13:49:59,814: time cost, forward:0.22631457158924567, backward:0.04405304912083261, data cost:0.32118441510113444 
2022-03-29 13:49:59,814: ============================================================
2022-03-29 13:49:59,815: Epoch 5/31 Batch 6300/7662 eta: 1 day, 7:51:52.064781	Training Loss 0.8248 (0.8247)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.018)	
2022-03-29 13:49:59,815: ============================================================
2022-03-29 13:50:57,641: time cost, forward:0.2260730842590928, backward:0.04404438430582253, data cost:0.3212204746276741 
2022-03-29 13:50:57,641: ============================================================
2022-03-29 13:50:57,641: Epoch 5/31 Batch 6400/7662 eta: 1 day, 8:12:08.120264	Training Loss 0.8243 (0.8247)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.018)	
2022-03-29 13:50:57,642: ============================================================
2022-03-29 13:51:54,737: time cost, forward:0.22585826460114442, backward:0.044041621756564654, data cost:0.32111748693025666 
2022-03-29 13:51:54,738: ============================================================
2022-03-29 13:51:54,738: Epoch 5/31 Batch 6500/7662 eta: 1 day, 7:46:47.264588	Training Loss 0.8253 (0.8247)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.018)	
2022-03-29 13:51:54,738: ============================================================
2022-03-29 13:52:53,916: time cost, forward:0.22579597841520926, backward:0.04404229878620553, data cost:0.32118458190746857 
2022-03-29 13:52:53,917: ============================================================
2022-03-29 13:52:53,917: Epoch 5/31 Batch 6600/7662 eta: 1 day, 8:55:21.314088	Training Loss 0.8253 (0.8247)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.018)	
2022-03-29 13:52:53,918: ============================================================
2022-03-29 13:53:50,923: time cost, forward:0.22562022962967376, backward:0.04403462170095368, data cost:0.3210489284033063 
2022-03-29 13:53:50,923: ============================================================
2022-03-29 13:53:50,923: Epoch 5/31 Batch 6700/7662 eta: 1 day, 7:41:52.378151	Training Loss 0.8245 (0.8247)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.018)	
2022-03-29 13:53:50,924: ============================================================
2022-03-29 13:54:50,501: time cost, forward:0.22566335852452282, backward:0.0440286307637175, data cost:0.32107958128775266 
2022-03-29 13:54:50,502: ============================================================
2022-03-29 13:54:50,502: Epoch 5/31 Batch 6800/7662 eta: 1 day, 9:06:42.004972	Training Loss 0.8246 (0.8247)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.018)	
2022-03-29 13:54:50,503: ============================================================
2022-03-29 13:55:49,480: time cost, forward:0.22561174210369941, backward:0.04401893525179581, data cost:0.32112241202566066 
2022-03-29 13:55:49,481: ============================================================
2022-03-29 13:55:49,481: Epoch 5/31 Batch 6900/7662 eta: 1 day, 8:45:42.478762	Training Loss 0.8243 (0.8247)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.018)	
2022-03-29 13:55:49,481: ============================================================
2022-03-29 13:56:48,812: time cost, forward:0.22565021285296746, backward:0.04400727285250781, data cost:0.3211250709182689 
2022-03-29 13:56:48,813: ============================================================
2022-03-29 13:56:48,813: Epoch 5/31 Batch 7000/7662 eta: 1 day, 8:56:30.103802	Training Loss 0.8245 (0.8247)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.018)	
2022-03-29 13:56:48,813: ============================================================
2022-03-29 13:57:48,984: time cost, forward:0.22563865084365348, backward:0.04397718055699305, data cost:0.32131256481546266 
2022-03-29 13:57:48,984: ============================================================
2022-03-29 13:57:48,985: Epoch 5/31 Batch 7100/7662 eta: 1 day, 9:23:28.216104	Training Loss 0.8241 (0.8247)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.018)	
2022-03-29 13:57:48,985: ============================================================
2022-03-29 13:58:48,804: time cost, forward:0.22571148390835533, backward:0.04397801542169502, data cost:0.3213354151254562 
2022-03-29 13:58:48,805: ============================================================
2022-03-29 13:58:48,805: Epoch 5/31 Batch 7200/7662 eta: 1 day, 9:10:45.716260	Training Loss 0.8247 (0.8247)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.018)	
2022-03-29 13:58:48,805: ============================================================
2022-03-29 13:59:49,124: time cost, forward:0.22583115723120348, backward:0.043969680420551126, data cost:0.32138212165827296 
2022-03-29 13:59:49,125: ============================================================
2022-03-29 13:59:49,125: Epoch 5/31 Batch 7300/7662 eta: 1 day, 9:26:24.086190	Training Loss 0.8243 (0.8247)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.019)	
2022-03-29 13:59:49,125: ============================================================
2022-03-29 14:00:48,091: time cost, forward:0.22581498850711473, backward:0.04395670004028906, data cost:0.32138635236067553 
2022-03-29 14:00:48,092: ============================================================
2022-03-29 14:00:48,092: Epoch 5/31 Batch 7400/7662 eta: 1 day, 8:40:24.795173	Training Loss 0.8245 (0.8247)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.019)	
2022-03-29 14:00:48,092: ============================================================
2022-03-29 14:01:47,771: time cost, forward:0.22591112467237656, backward:0.04395839690780589, data cost:0.3213580982067344 
2022-03-29 14:01:47,772: ============================================================
2022-03-29 14:01:47,772: Epoch 5/31 Batch 7500/7662 eta: 1 day, 9:03:06.135001	Training Loss 0.8256 (0.8247)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.019)	
2022-03-29 14:01:47,772: ============================================================
2022-03-29 14:02:46,725: time cost, forward:0.2258557876735506, backward:0.04394301650931701, data cost:0.32139712814469606 
2022-03-29 14:02:46,725: ============================================================
2022-03-29 14:02:46,726: Epoch 5/31 Batch 7600/7662 eta: 1 day, 8:38:00.116461	Training Loss 0.8248 (0.8247)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.019)	
2022-03-29 14:02:46,726: ============================================================
2022-03-29 14:03:25,861: Epoch: 5/31 eta: 1 day, 8:37:22.975588	Training Loss 0.8244 (0.8247)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.019)
2022-03-29 14:03:25,861: ============================================================
2022-03-29 14:03:25,987: Save Checkpoint...
2022-03-29 14:03:25,990: ============================================================
2022-03-29 14:03:28,445: Save done!
2022-03-29 14:03:28,446: ============================================================
2022-03-29 14:04:29,422: time cost, forward:0.26461436290933626, backward:0.04435716975818981, data cost:0.30361328702984436 
2022-03-29 14:04:29,423: ============================================================
2022-03-29 14:04:29,424: Epoch 6/31 Batch 100/7662 eta: 1 day, 9:43:29.870290	Training Loss 0.8259 (0.8243)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.024)	
2022-03-29 14:04:29,424: ============================================================
2022-03-29 14:05:26,971: time cost, forward:0.25065304645940883, backward:0.044229294187459516, data cost:0.2988646102311024 
2022-03-29 14:05:26,972: ============================================================
2022-03-29 14:05:26,972: Epoch 6/31 Batch 200/7662 eta: 1 day, 7:48:48.283277	Training Loss 0.8238 (0.8244)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.025)	
2022-03-29 14:05:26,972: ============================================================
2022-03-29 14:06:24,433: time cost, forward:0.24448177487555156, backward:0.04408246617652102, data cost:0.29854886747124204 
2022-03-29 14:06:24,434: ============================================================
2022-03-29 14:06:24,434: Epoch 6/31 Batch 300/7662 eta: 1 day, 7:44:59.992985	Training Loss 0.8241 (0.8244)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.024)	
2022-03-29 14:06:24,434: ============================================================
2022-03-29 14:07:22,598: time cost, forward:0.2406731356953021, backward:0.04376712060512457, data cost:0.3009706523484156 
2022-03-29 14:07:22,599: ============================================================
2022-03-29 14:07:22,599: Epoch 6/31 Batch 400/7662 eta: 1 day, 8:07:18.948101	Training Loss 0.8247 (0.8244)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.023)	
2022-03-29 14:07:22,599: ============================================================
2022-03-29 14:08:21,810: time cost, forward:0.24264066921685168, backward:0.043922825184518205, data cost:0.3001824256652343 
2022-03-29 14:08:21,811: ============================================================
2022-03-29 14:08:21,811: Epoch 6/31 Batch 500/7662 eta: 1 day, 8:41:02.186760	Training Loss 0.8236 (0.8244)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.024)	
2022-03-29 14:08:21,811: ============================================================
2022-03-29 14:09:19,136: time cost, forward:0.23960915949189404, backward:0.043729702498956594, data cost:0.30094391316523733 
2022-03-29 14:09:19,137: ============================================================
2022-03-29 14:09:19,137: Epoch 6/31 Batch 600/7662 eta: 1 day, 7:37:37.499185	Training Loss 0.8256 (0.8244)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.027)	
2022-03-29 14:09:19,138: ============================================================
2022-03-29 14:10:16,758: time cost, forward:0.237390200638123, backward:0.04345158173120414, data cost:0.30163343849782437 
2022-03-29 14:10:16,758: ============================================================
2022-03-29 14:10:16,758: Epoch 6/31 Batch 700/7662 eta: 1 day, 7:46:25.202337	Training Loss 0.8233 (0.8244)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.195 (0.027)	
2022-03-29 14:10:16,759: ============================================================
2022-03-29 14:11:15,365: time cost, forward:0.23679953373418433, backward:0.043573330281225404, data cost:0.30294373724726176 
2022-03-29 14:11:15,383: ============================================================
2022-03-29 14:11:15,383: Epoch 6/31 Batch 800/7662 eta: 1 day, 8:18:39.114610	Training Loss 0.8249 (0.8244)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.026)	
2022-03-29 14:11:15,383: ============================================================
2022-03-29 14:12:12,778: time cost, forward:0.23505130705234073, backward:0.04366501260785027, data cost:0.3034462963248519 
2022-03-29 14:12:12,779: ============================================================
2022-03-29 14:12:12,779: Epoch 6/31 Batch 900/7662 eta: 1 day, 7:37:03.119840	Training Loss 0.8240 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.026)	
2022-03-29 14:12:12,779: ============================================================
2022-03-29 14:13:11,261: time cost, forward:0.2339911250858097, backward:0.04363781983429963, data cost:0.3047406716389699 
2022-03-29 14:13:11,262: ============================================================
2022-03-29 14:13:11,263: Epoch 6/31 Batch 1000/7662 eta: 1 day, 8:12:02.315730	Training Loss 0.8246 (0.8244)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.026)	
2022-03-29 14:13:11,263: ============================================================
2022-03-29 14:14:10,799: time cost, forward:0.23356395205982822, backward:0.04370017546323129, data cost:0.30626458618400093 
2022-03-29 14:14:10,809: ============================================================
2022-03-29 14:14:10,809: Epoch 6/31 Batch 1100/7662 eta: 1 day, 8:46:10.042371	Training Loss 0.8244 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.025)	
2022-03-29 14:14:10,809: ============================================================
2022-03-29 14:15:07,914: time cost, forward:0.23280819363152613, backward:0.043634007631290744, data cost:0.30602037638202123 
2022-03-29 14:15:07,927: ============================================================
2022-03-29 14:15:07,927: Epoch 6/31 Batch 1200/7662 eta: 1 day, 7:25:00.267552	Training Loss 0.8247 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.195 (0.025)	
2022-03-29 14:15:07,927: ============================================================
2022-03-29 14:16:05,892: time cost, forward:0.23236227567788728, backward:0.04359204297436486, data cost:0.30624023008750345 
2022-03-29 14:16:05,894: ============================================================
2022-03-29 14:16:05,894: Epoch 6/31 Batch 1300/7662 eta: 1 day, 7:52:04.394348	Training Loss 0.8256 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.025)	
2022-03-29 14:16:05,894: ============================================================
2022-03-29 14:17:06,222: time cost, forward:0.2322508665048028, backward:0.04358056309054459, data cost:0.30782004575204475 
2022-03-29 14:17:06,222: ============================================================
2022-03-29 14:17:06,223: Epoch 6/31 Batch 1400/7662 eta: 1 day, 9:08:57.695473	Training Loss 0.8254 (0.8245)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.025)	
2022-03-29 14:17:06,223: ============================================================
2022-03-29 14:18:05,503: time cost, forward:0.23230537038552435, backward:0.04314805938053958, data cost:0.3087990961526536 
2022-03-29 14:18:05,503: ============================================================
2022-03-29 14:18:05,504: Epoch 6/31 Batch 1500/7662 eta: 1 day, 8:33:26.145754	Training Loss 0.8244 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.025)	
2022-03-29 14:18:05,504: ============================================================
2022-03-29 14:19:04,641: time cost, forward:0.23215880552033025, backward:0.0431056024135091, data cost:0.30937891725154876 
2022-03-29 14:19:04,642: ============================================================
2022-03-29 14:19:04,642: Epoch 6/31 Batch 1600/7662 eta: 1 day, 8:27:45.729094	Training Loss 0.8251 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.024)	
2022-03-29 14:19:04,642: ============================================================
2022-03-29 14:20:03,043: time cost, forward:0.23197750318324026, backward:0.043169595831769436, data cost:0.30943174036619875 
2022-03-29 14:20:03,044: ============================================================
2022-03-29 14:20:03,044: Epoch 6/31 Batch 1700/7662 eta: 1 day, 8:02:30.634723	Training Loss 0.8245 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.024)	
2022-03-29 14:20:03,044: ============================================================
2022-03-29 14:21:01,824: time cost, forward:0.2319560518789583, backward:0.04321001343358683, data cost:0.30956949148660506 
2022-03-29 14:21:01,825: ============================================================
2022-03-29 14:21:01,825: Epoch 6/31 Batch 1800/7662 eta: 1 day, 8:14:02.329855	Training Loss 0.8249 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.024)	
2022-03-29 14:21:01,826: ============================================================
2022-03-29 14:21:59,648: time cost, forward:0.2315611491522204, backward:0.043207905554909526, data cost:0.3095985131868882 
2022-03-29 14:21:59,649: ============================================================
2022-03-29 14:21:59,650: Epoch 6/31 Batch 1900/7662 eta: 1 day, 7:41:35.005581	Training Loss 0.8247 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.195 (0.024)	
2022-03-29 14:21:59,650: ============================================================
2022-03-29 14:22:57,304: time cost, forward:0.23083767323210097, backward:0.0432414567249903, data cost:0.3098748123842576 
2022-03-29 14:22:57,304: ============================================================
2022-03-29 14:22:57,305: Epoch 6/31 Batch 2000/7662 eta: 1 day, 7:35:03.199292	Training Loss 0.8252 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.023)	
2022-03-29 14:22:57,305: ============================================================
2022-03-29 14:23:53,199: time cost, forward:0.22985178212315313, backward:0.04323466156936362, data cost:0.3096535937339706 
2022-03-29 14:23:53,201: ============================================================
2022-03-29 14:23:53,201: Epoch 6/31 Batch 2100/7662 eta: 1 day, 6:36:18.790320	Training Loss 0.8245 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.023)	
2022-03-29 14:23:53,201: ============================================================
2022-03-29 14:24:47,776: time cost, forward:0.22849019119120448, backward:0.04323470142550119, data cost:0.30930983993127814 
2022-03-29 14:24:47,776: ============================================================
2022-03-29 14:24:47,777: Epoch 6/31 Batch 2200/7662 eta: 1 day, 5:52:01.254460	Training Loss 0.8244 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.023)	
2022-03-29 14:24:47,777: ============================================================
2022-03-29 14:25:44,195: time cost, forward:0.2274339779816072, backward:0.04331701109854228, data cost:0.30953271765457957 
2022-03-29 14:25:44,196: ============================================================
2022-03-29 14:25:44,196: Epoch 6/31 Batch 2300/7662 eta: 1 day, 6:51:36.723692	Training Loss 0.8245 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.023)	
2022-03-29 14:25:44,196: ============================================================
2022-03-29 14:26:40,281: time cost, forward:0.22623489915753167, backward:0.043302513450918324, data cost:0.30991353020662066 
2022-03-29 14:26:40,282: ============================================================
2022-03-29 14:26:40,283: Epoch 6/31 Batch 2400/7662 eta: 1 day, 6:39:45.939321	Training Loss 0.8240 (0.8245)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.024)	
2022-03-29 14:26:40,283: ============================================================
2022-03-29 14:27:35,106: time cost, forward:0.22497771052467008, backward:0.043313378188647285, data cost:0.30989188573607546 
2022-03-29 14:27:35,106: ============================================================
2022-03-29 14:27:35,107: Epoch 6/31 Batch 2500/7662 eta: 1 day, 5:57:25.713988	Training Loss 0.8250 (0.8245)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.024)	
2022-03-29 14:27:35,107: ============================================================
2022-03-29 14:28:30,957: time cost, forward:0.2241797038067667, backward:0.04335701525234268, data cost:0.30986368055295926 
2022-03-29 14:28:30,957: ============================================================
2022-03-29 14:28:30,958: Epoch 6/31 Batch 2600/7662 eta: 1 day, 6:30:11.009755	Training Loss 0.8251 (0.8245)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.024)	
2022-03-29 14:28:30,958: ============================================================
2022-03-29 14:29:28,360: time cost, forward:0.22413754198188118, backward:0.043390737016274335, data cost:0.30964614656864603 
2022-03-29 14:29:28,360: ============================================================
2022-03-29 14:29:28,360: Epoch 6/31 Batch 2700/7662 eta: 1 day, 7:20:03.376062	Training Loss 0.8242 (0.8245)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.024)	
2022-03-29 14:29:28,361: ============================================================
2022-03-29 14:30:29,835: time cost, forward:0.22457462125439523, backward:0.04343762752114555, data cost:0.3105718981329566 
2022-03-29 14:30:29,836: ============================================================
2022-03-29 14:30:29,836: Epoch 6/31 Batch 2800/7662 eta: 1 day, 9:32:26.288457	Training Loss 0.8244 (0.8245)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.023)	
2022-03-29 14:30:29,837: ============================================================
2022-03-29 14:31:28,638: time cost, forward:0.22486779902794723, backward:0.0434658329994278, data cost:0.31055096076578464 
2022-03-29 14:31:28,639: ============================================================
2022-03-29 14:31:28,639: Epoch 6/31 Batch 2900/7662 eta: 1 day, 8:03:57.898702	Training Loss 0.8260 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.023)	
2022-03-29 14:31:28,639: ============================================================
2022-03-29 14:32:26,606: time cost, forward:0.224663443150382, backward:0.04351789262065016, data cost:0.31070916268697535 
2022-03-29 14:32:26,607: ============================================================
2022-03-29 14:32:26,607: Epoch 6/31 Batch 3000/7662 eta: 1 day, 7:35:40.557105	Training Loss 0.8250 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.024)	
2022-03-29 14:32:26,607: ============================================================
2022-03-29 14:33:21,451: time cost, forward:0.22397885164086687, backward:0.04351750555712394, data cost:0.31039788446798755 
2022-03-29 14:33:21,451: ============================================================
2022-03-29 14:33:21,452: Epoch 6/31 Batch 3100/7662 eta: 1 day, 5:52:37.520308	Training Loss 0.8250 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.024)	
2022-03-29 14:33:21,452: ============================================================
2022-03-29 14:34:16,650: time cost, forward:0.2232134434609683, backward:0.043535583725047136, data cost:0.31031320519132816 
2022-03-29 14:34:16,651: ============================================================
2022-03-29 14:34:16,652: Epoch 6/31 Batch 3200/7662 eta: 1 day, 6:03:18.780731	Training Loss 0.8243 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.195 (0.024)	
2022-03-29 14:34:16,652: ============================================================
2022-03-29 14:35:12,370: time cost, forward:0.22245995049478068, backward:0.04355347196273133, data cost:0.3104354069788697 
2022-03-29 14:35:12,370: ============================================================
2022-03-29 14:35:12,371: Epoch 6/31 Batch 3300/7662 eta: 1 day, 6:19:20.715623	Training Loss 0.8248 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.023)	
2022-03-29 14:35:12,371: ============================================================
2022-03-29 14:36:08,132: time cost, forward:0.2218194646883025, backward:0.04355877088988378, data cost:0.3102968516999324 
2022-03-29 14:36:08,133: ============================================================
2022-03-29 14:36:08,133: Epoch 6/31 Batch 3400/7662 eta: 1 day, 6:19:49.941305	Training Loss 0.8254 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.023)	
2022-03-29 14:36:08,133: ============================================================
2022-03-29 14:37:03,666: time cost, forward:0.22116046941222448, backward:0.04354372737270725, data cost:0.31057945419359495 
2022-03-29 14:37:03,666: ============================================================
2022-03-29 14:37:03,667: Epoch 6/31 Batch 3500/7662 eta: 1 day, 6:11:26.695457	Training Loss 0.8243 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.195 (0.023)	
2022-03-29 14:37:03,667: ============================================================
2022-03-29 14:38:01,818: time cost, forward:0.22079287618026033, backward:0.043549687440410594, data cost:0.31110116831956225 
2022-03-29 14:38:01,818: ============================================================
2022-03-29 14:38:01,818: Epoch 6/31 Batch 3600/7662 eta: 1 day, 7:35:51.947769	Training Loss 0.8253 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.195 (0.023)	
2022-03-29 14:38:01,818: ============================================================
2022-03-29 14:38:58,895: time cost, forward:0.22072265489129125, backward:0.04356697818078554, data cost:0.31100486684212914 
2022-03-29 14:38:58,896: ============================================================
2022-03-29 14:38:58,896: Epoch 6/31 Batch 3700/7662 eta: 1 day, 6:59:54.594698	Training Loss 0.8250 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.023)	
2022-03-29 14:38:58,896: ============================================================
2022-03-29 14:39:55,339: time cost, forward:0.2204754028109445, backward:0.04360476033440951, data cost:0.31092164961404944 
2022-03-29 14:39:55,339: ============================================================
2022-03-29 14:39:55,340: Epoch 6/31 Batch 3800/7662 eta: 1 day, 6:38:18.083962	Training Loss 0.8250 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.023)	
2022-03-29 14:39:55,340: ============================================================
2022-03-29 14:40:50,259: time cost, forward:0.22000167852305363, backward:0.04359587738837423, data cost:0.3107286543991664 
2022-03-29 14:40:50,259: ============================================================
2022-03-29 14:40:50,260: Epoch 6/31 Batch 3900/7662 eta: 1 day, 5:47:46.271813	Training Loss 0.8240 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.023)	
2022-03-29 14:40:50,260: ============================================================
2022-03-29 14:41:45,465: time cost, forward:0.21943177399440955, backward:0.04357718950392277, data cost:0.3107541099909873 
2022-03-29 14:41:45,465: ============================================================
2022-03-29 14:41:45,466: Epoch 6/31 Batch 4000/7662 eta: 1 day, 5:56:08.849595	Training Loss 0.8242 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.023)	
2022-03-29 14:41:45,466: ============================================================
2022-03-29 14:42:40,693: time cost, forward:0.2189594660482339, backward:0.04355094118157839, data cost:0.310707098857808 
2022-03-29 14:42:40,694: ============================================================
2022-03-29 14:42:40,694: Epoch 6/31 Batch 4100/7662 eta: 1 day, 5:55:58.641692	Training Loss 0.8245 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.023)	
2022-03-29 14:42:40,695: ============================================================
2022-03-29 14:43:37,840: time cost, forward:0.21855871624593423, backward:0.0435589054250297, data cost:0.31104929414809557 
2022-03-29 14:43:37,840: ============================================================
2022-03-29 14:43:37,840: Epoch 6/31 Batch 4200/7662 eta: 1 day, 6:57:22.067428	Training Loss 0.8254 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.023)	
2022-03-29 14:43:37,840: ============================================================
2022-03-29 14:44:34,919: time cost, forward:0.21837454569786197, backward:0.04356185606286314, data cost:0.31116456429773665 
2022-03-29 14:44:34,919: ============================================================
2022-03-29 14:44:34,920: Epoch 6/31 Batch 4300/7662 eta: 1 day, 6:54:14.590623	Training Loss 0.8245 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.195 (0.023)	
2022-03-29 14:44:34,920: ============================================================
2022-03-29 14:45:30,979: time cost, forward:0.2180596323657182, backward:0.04353967323225177, data cost:0.31120379465930864 
2022-03-29 14:45:30,979: ============================================================
2022-03-29 14:45:30,979: Epoch 6/31 Batch 4400/7662 eta: 1 day, 6:20:11.842559	Training Loss 0.8239 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.023)	
2022-03-29 14:45:30,980: ============================================================
2022-03-29 14:46:27,421: time cost, forward:0.21758621781368895, backward:0.04337829604470007, data cost:0.3116433376152003 
2022-03-29 14:46:27,421: ============================================================
2022-03-29 14:46:27,422: Epoch 6/31 Batch 4500/7662 eta: 1 day, 6:31:40.507827	Training Loss 0.8250 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.023)	
2022-03-29 14:46:27,422: ============================================================
2022-03-29 14:47:22,349: time cost, forward:0.2171686138892127, backward:0.0433488429746153, data cost:0.31150184296659605 
2022-03-29 14:47:22,349: ============================================================
2022-03-29 14:47:22,350: Epoch 6/31 Batch 4600/7662 eta: 1 day, 5:41:37.567749	Training Loss 0.8249 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.023)	
2022-03-29 14:47:22,351: ============================================================
2022-03-29 14:48:18,975: time cost, forward:0.21689643462076164, backward:0.04332894902453572, data cost:0.3117294040074321 
2022-03-29 14:48:18,976: ============================================================
2022-03-29 14:48:18,976: Epoch 6/31 Batch 4700/7662 eta: 1 day, 6:35:44.929384	Training Loss 0.8243 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.023)	
2022-03-29 14:48:18,976: ============================================================
2022-03-29 14:49:13,542: time cost, forward:0.2165558028653354, backward:0.04334884590098052, data cost:0.31149167437234454 
2022-03-29 14:49:13,542: ============================================================
2022-03-29 14:49:13,543: Epoch 6/31 Batch 4800/7662 eta: 1 day, 5:28:05.173283	Training Loss 0.8244 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.023)	
2022-03-29 14:49:13,543: ============================================================
2022-03-29 14:50:11,065: time cost, forward:0.21631729804780878, backward:0.04333855989490828, data cost:0.3118073205895316 
2022-03-29 14:50:11,066: ============================================================
2022-03-29 14:50:11,066: Epoch 6/31 Batch 4900/7662 eta: 1 day, 7:02:54.963955	Training Loss 0.8245 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.023)	
2022-03-29 14:50:11,066: ============================================================
2022-03-29 14:51:07,608: time cost, forward:0.21600334194570237, backward:0.04333514870584285, data cost:0.31199385309534133 
2022-03-29 14:51:07,609: ============================================================
2022-03-29 14:51:07,609: Epoch 6/31 Batch 5000/7662 eta: 1 day, 6:30:14.036679	Training Loss 0.8254 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.023)	
2022-03-29 14:51:07,609: ============================================================
2022-03-29 14:52:03,954: time cost, forward:0.21576683028909968, backward:0.04334484911310974, data cost:0.31205335718249544 
2022-03-29 14:52:03,955: ============================================================
2022-03-29 14:52:03,955: Epoch 6/31 Batch 5100/7662 eta: 1 day, 6:22:54.556389	Training Loss 0.8242 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.023)	
2022-03-29 14:52:03,955: ============================================================
2022-03-29 14:52:58,597: time cost, forward:0.21560122508639487, backward:0.043355581782877184, data cost:0.31172023917372627 
2022-03-29 14:52:58,598: ============================================================
2022-03-29 14:52:58,598: Epoch 6/31 Batch 5200/7662 eta: 1 day, 5:26:55.157083	Training Loss 0.8252 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.023)	
2022-03-29 14:52:58,599: ============================================================
2022-03-29 14:53:55,279: time cost, forward:0.21542658385611363, backward:0.043335996949238516, data cost:0.311833666144373 
2022-03-29 14:53:55,279: ============================================================
2022-03-29 14:53:55,280: Epoch 6/31 Batch 5300/7662 eta: 1 day, 6:31:52.316196	Training Loss 0.8245 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.023)	
2022-03-29 14:53:55,280: ============================================================
2022-03-29 14:54:50,949: time cost, forward:0.2152974944707309, backward:0.043346131592022975, data cost:0.3116866214824266 
2022-03-29 14:54:50,949: ============================================================
2022-03-29 14:54:50,950: Epoch 6/31 Batch 5400/7662 eta: 1 day, 5:58:16.031336	Training Loss 0.8242 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.023)	
2022-03-29 14:54:50,950: ============================================================
2022-03-29 14:55:48,776: time cost, forward:0.2154736198453735, backward:0.043340318266706784, data cost:0.3116552734791225 
2022-03-29 14:55:48,777: ============================================================
2022-03-29 14:55:48,777: Epoch 6/31 Batch 5500/7662 eta: 1 day, 7:06:59.371885	Training Loss 0.8240 (0.8245)	Training Prec@1 0.195 (0.006)	Training Prec@5 0.391 (0.023)	
2022-03-29 14:55:48,778: ============================================================
2022-03-29 14:56:46,298: time cost, forward:0.21558138237912478, backward:0.043339057700253744, data cost:0.3116220116806916 
2022-03-29 14:56:46,299: ============================================================
2022-03-29 14:56:46,299: Epoch 6/31 Batch 5600/7662 eta: 1 day, 6:56:10.046924	Training Loss 0.8244 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.023)	
2022-03-29 14:56:46,299: ============================================================
2022-03-29 14:57:43,081: time cost, forward:0.21547958365154382, backward:0.043344837800518086, data cost:0.31165995587798917 
2022-03-29 14:57:43,082: ============================================================
2022-03-29 14:57:43,082: Epoch 6/31 Batch 5700/7662 eta: 1 day, 6:31:22.015254	Training Loss 0.8249 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.023)	
2022-03-29 14:57:43,082: ============================================================
2022-03-29 14:58:38,571: time cost, forward:0.21533289677645753, backward:0.04332353119439843, data cost:0.3115557715242783 
2022-03-29 14:58:38,572: ============================================================
2022-03-29 14:58:38,572: Epoch 6/31 Batch 5800/7662 eta: 1 day, 5:48:45.260609	Training Loss 0.8244 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.023)	
2022-03-29 14:58:38,572: ============================================================
2022-03-29 14:59:34,058: time cost, forward:0.21503094411094342, backward:0.043300280592808944, data cost:0.3116097748128009 
2022-03-29 14:59:34,058: ============================================================
2022-03-29 14:59:34,058: Epoch 6/31 Batch 5900/7662 eta: 1 day, 5:47:42.139385	Training Loss 0.8256 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.023)	
2022-03-29 14:59:34,059: ============================================================
2022-03-29 15:00:29,116: time cost, forward:0.2147999656341497, backward:0.04326262234012014, data cost:0.31154462937057603 
2022-03-29 15:00:29,117: ============================================================
2022-03-29 15:00:29,117: Epoch 6/31 Batch 6000/7662 eta: 1 day, 5:33:00.427077	Training Loss 0.8245 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.023)	
2022-03-29 15:00:29,117: ============================================================
2022-03-29 15:01:25,039: time cost, forward:0.21442671227912508, backward:0.043221150173244176, data cost:0.3117800426201696 
2022-03-29 15:01:25,039: ============================================================
2022-03-29 15:01:25,039: Epoch 6/31 Batch 6100/7662 eta: 1 day, 5:59:53.096030	Training Loss 0.8255 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.023)	
2022-03-29 15:01:25,040: ============================================================
2022-03-29 15:02:21,780: time cost, forward:0.21421646779536202, backward:0.04319806455854332, data cost:0.311977555317578 
2022-03-29 15:02:21,780: ============================================================
2022-03-29 15:02:21,780: Epoch 6/31 Batch 6200/7662 eta: 1 day, 6:25:17.474456	Training Loss 0.8243 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.023)	
2022-03-29 15:02:21,780: ============================================================
2022-03-29 15:03:19,740: time cost, forward:0.21440180113702034, backward:0.043209553597597566, data cost:0.3119279503689851 
2022-03-29 15:03:19,741: ============================================================
2022-03-29 15:03:19,741: Epoch 6/31 Batch 6300/7662 eta: 1 day, 7:03:33.964888	Training Loss 0.8251 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.023)	
2022-03-29 15:03:19,741: ============================================================
2022-03-29 15:04:18,676: time cost, forward:0.2147474419345966, backward:0.04323326663908353, data cost:0.311831947676296 
2022-03-29 15:04:18,676: ============================================================
2022-03-29 15:04:18,676: Epoch 6/31 Batch 6400/7662 eta: 1 day, 7:33:54.602091	Training Loss 0.8243 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.023)	
2022-03-29 15:04:18,677: ============================================================
2022-03-29 15:05:16,404: time cost, forward:0.21495525733124826, backward:0.04323769951072138, data cost:0.31172430473101065 
2022-03-29 15:05:16,404: ============================================================
2022-03-29 15:05:16,405: Epoch 6/31 Batch 6500/7662 eta: 1 day, 6:54:09.781825	Training Loss 0.8245 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.023)	
2022-03-29 15:05:16,405: ============================================================
2022-03-29 15:06:14,853: time cost, forward:0.21497165006044183, backward:0.04325568251473233, data cost:0.31193444786297225 
2022-03-29 15:06:14,853: ============================================================
2022-03-29 15:06:14,854: Epoch 6/31 Batch 6600/7662 eta: 1 day, 7:16:20.394644	Training Loss 0.8253 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.023)	
2022-03-29 15:06:14,854: ============================================================
2022-03-29 15:07:10,740: time cost, forward:0.21487271897845134, backward:0.043247217170372526, data cost:0.3118652925862894 
2022-03-29 15:07:10,741: ============================================================
2022-03-29 15:07:10,741: Epoch 6/31 Batch 6700/7662 eta: 1 day, 5:53:11.116514	Training Loss 0.8252 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.023)	
2022-03-29 15:07:10,742: ============================================================
2022-03-29 15:08:07,780: time cost, forward:0.21479464569658474, backward:0.04323701070220808, data cost:0.3119518512802135 
2022-03-29 15:08:07,781: ============================================================
2022-03-29 15:08:07,781: Epoch 6/31 Batch 6800/7662 eta: 1 day, 6:29:12.091620	Training Loss 0.8240 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.023)	
2022-03-29 15:08:07,781: ============================================================
2022-03-29 15:09:04,822: time cost, forward:0.21463577210652618, backward:0.0432228384406381, data cost:0.3121216650336769 
2022-03-29 15:09:04,823: ============================================================
2022-03-29 15:09:04,823: Epoch 6/31 Batch 6900/7662 eta: 1 day, 6:28:18.900500	Training Loss 0.8248 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.023)	
2022-03-29 15:09:04,823: ============================================================
2022-03-29 15:10:01,608: time cost, forward:0.2146215282826615, backward:0.04320316570863535, data cost:0.31210757926764326 
2022-03-29 15:10:01,609: ============================================================
2022-03-29 15:10:01,609: Epoch 6/31 Batch 7000/7662 eta: 1 day, 6:19:10.319381	Training Loss 0.8246 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.024)	
2022-03-29 15:10:01,609: ============================================================
2022-03-29 15:10:59,971: time cost, forward:0.21481062530010314, backward:0.04320191326133297, data cost:0.31211287815111727 
2022-03-29 15:10:59,972: ============================================================
2022-03-29 15:10:59,972: Epoch 6/31 Batch 7100/7662 eta: 1 day, 7:08:42.633835	Training Loss 0.8253 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.024)	
2022-03-29 15:10:59,972: ============================================================
2022-03-29 15:11:58,852: time cost, forward:0.21493548296411627, backward:0.04320808708179261, data cost:0.3122365836683852 
2022-03-29 15:11:58,853: ============================================================
2022-03-29 15:11:58,853: Epoch 6/31 Batch 7200/7662 eta: 1 day, 7:24:19.696039	Training Loss 0.8248 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.024)	
2022-03-29 15:11:58,854: ============================================================
2022-03-29 15:12:55,338: time cost, forward:0.21498039242730987, backward:0.04317743057322054, data cost:0.3121395691859753 
2022-03-29 15:12:55,338: ============================================================
2022-03-29 15:12:55,338: Epoch 6/31 Batch 7300/7662 eta: 1 day, 6:06:42.241786	Training Loss 0.8256 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.024)	
2022-03-29 15:12:55,339: ============================================================
2022-03-29 15:13:51,973: time cost, forward:0.21502143238860058, backward:0.04317484438169613, data cost:0.31204501602001683 
2022-03-29 15:13:51,973: ============================================================
2022-03-29 15:13:51,974: Epoch 6/31 Batch 7400/7662 eta: 1 day, 6:10:33.773173	Training Loss 0.8250 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.024)	
2022-03-29 15:13:51,974: ============================================================
2022-03-29 15:14:48,824: time cost, forward:0.21508150664086756, backward:0.043174106767295536, data cost:0.31195272698626864 
2022-03-29 15:14:48,824: ============================================================
2022-03-29 15:14:48,825: Epoch 6/31 Batch 7500/7662 eta: 1 day, 6:16:30.770106	Training Loss 0.8244 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.024)	
2022-03-29 15:14:48,825: ============================================================
2022-03-29 15:15:47,094: time cost, forward:0.21518871250521557, backward:0.04318026700040544, data cost:0.3119958882144226 
2022-03-29 15:15:47,094: ============================================================
2022-03-29 15:15:47,094: Epoch 6/31 Batch 7600/7662 eta: 1 day, 7:00:52.327667	Training Loss 0.8243 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.024)	
2022-03-29 15:15:47,095: ============================================================
2022-03-29 15:16:25,184: Epoch: 6/31 eta: 1 day, 7:00:15.617754	Training Loss 0.8239 (0.8245)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.024)
2022-03-29 15:16:25,185: ============================================================
2022-03-29 15:17:26,032: time cost, forward:0.22667929620453806, backward:0.04915473918722133, data cost:0.33440019385983244 
2022-03-29 15:17:26,033: ============================================================
2022-03-29 15:17:26,033: Epoch 7/31 Batch 100/7662 eta: 1 day, 8:17:59.484571	Training Loss 0.8228 (0.8242)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.026)	
2022-03-29 15:17:26,034: ============================================================
2022-03-29 15:18:24,156: time cost, forward:0.22390731854654436, backward:0.047617498953737805, data cost:0.3238196097426678 
2022-03-29 15:18:24,157: ============================================================
2022-03-29 15:18:24,157: Epoch 7/31 Batch 200/7662 eta: 1 day, 6:53:39.947964	Training Loss 0.8244 (0.8242)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.023)	
2022-03-29 15:18:24,157: ============================================================
2022-03-29 15:19:25,085: time cost, forward:0.2319560425736035, backward:0.04734774497041734, data cost:0.3206313621240316 
2022-03-29 15:19:25,085: ============================================================
2022-03-29 15:19:25,086: Epoch 7/31 Batch 300/7662 eta: 1 day, 8:22:06.839632	Training Loss 0.8240 (0.8242)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.195 (0.025)	
2022-03-29 15:19:25,086: ============================================================
2022-03-29 15:20:25,072: time cost, forward:0.23006191648038707, backward:0.046523040996159525, data cost:0.3232089851733138 
2022-03-29 15:20:25,073: ============================================================
2022-03-29 15:20:25,073: Epoch 7/31 Batch 400/7662 eta: 1 day, 7:51:06.551538	Training Loss 0.8231 (0.8242)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.027)	
2022-03-29 15:20:25,073: ============================================================
2022-03-29 15:21:23,188: time cost, forward:0.22829090903899474, backward:0.046679477175634226, data cost:0.3209877033271866 
2022-03-29 15:21:23,189: ============================================================
2022-03-29 15:21:23,189: Epoch 7/31 Batch 500/7662 eta: 1 day, 6:50:30.681135	Training Loss 0.8246 (0.8242)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.028)	
2022-03-29 15:21:23,189: ============================================================
2022-03-29 15:22:21,534: time cost, forward:0.22778453094533369, backward:0.0464229336963074, data cost:0.3195759971472178 
2022-03-29 15:22:21,534: ============================================================
2022-03-29 15:22:21,534: Epoch 7/31 Batch 600/7662 eta: 1 day, 6:56:51.068938	Training Loss 0.8249 (0.8242)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.030)	
2022-03-29 15:22:21,534: ============================================================
2022-03-29 15:23:19,221: time cost, forward:0.2264370979669268, backward:0.046344717173105655, data cost:0.3185493543594862 
2022-03-29 15:23:19,222: ============================================================
2022-03-29 15:23:19,222: Epoch 7/31 Batch 700/7662 eta: 1 day, 6:34:57.518719	Training Loss 0.8241 (0.8242)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.030)	
2022-03-29 15:23:19,222: ============================================================
2022-03-29 15:24:17,472: time cost, forward:0.22557982276467717, backward:0.04624202045540935, data cost:0.3183417541064667 
2022-03-29 15:24:17,472: ============================================================
2022-03-29 15:24:17,472: Epoch 7/31 Batch 800/7662 eta: 1 day, 6:51:52.844978	Training Loss 0.8231 (0.8242)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.029)	
2022-03-29 15:24:17,472: ============================================================
2022-03-29 15:25:15,426: time cost, forward:0.2246843689143061, backward:0.04614067634565547, data cost:0.3181280116483287 
2022-03-29 15:25:15,427: ============================================================
2022-03-29 15:25:15,427: Epoch 7/31 Batch 900/7662 eta: 1 day, 6:41:31.398721	Training Loss 0.8251 (0.8242)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.030)	
2022-03-29 15:25:15,427: ============================================================
2022-03-29 15:26:14,609: time cost, forward:0.22415391556374184, backward:0.046180502669111986, data cost:0.31851421987210904 
2022-03-29 15:26:14,610: ============================================================
2022-03-29 15:26:14,610: Epoch 7/31 Batch 1000/7662 eta: 1 day, 7:19:33.906623	Training Loss 0.8241 (0.8242)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.030)	
2022-03-29 15:26:14,610: ============================================================
2022-03-29 15:27:12,335: time cost, forward:0.22382776361904544, backward:0.04620518675709552, data cost:0.3180275024122493 
2022-03-29 15:27:12,335: ============================================================
2022-03-29 15:27:12,336: Epoch 7/31 Batch 1100/7662 eta: 1 day, 6:32:19.021060	Training Loss 0.8243 (0.8242)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.029)	
2022-03-29 15:27:12,336: ============================================================
2022-03-29 15:28:10,953: time cost, forward:0.22384617903314102, backward:0.04611064514783743, data cost:0.3179282772232832 
2022-03-29 15:28:10,953: ============================================================
2022-03-29 15:28:10,953: Epoch 7/31 Batch 1200/7662 eta: 1 day, 6:59:39.810365	Training Loss 0.8240 (0.8242)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.030)	
2022-03-29 15:28:10,954: ============================================================
2022-03-29 15:29:09,906: time cost, forward:0.2243325350558051, backward:0.04616866376053103, data cost:0.31744012197592886 
2022-03-29 15:29:09,906: ============================================================
2022-03-29 15:29:09,907: Epoch 7/31 Batch 1300/7662 eta: 1 day, 7:09:18.774219	Training Loss 0.8244 (0.8242)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.030)	
2022-03-29 15:29:09,907: ============================================================
2022-03-29 15:30:08,716: time cost, forward:0.22436630990012701, backward:0.04628152980218196, data cost:0.31729837380791664 
2022-03-29 15:30:08,717: ============================================================
2022-03-29 15:30:08,717: Epoch 7/31 Batch 1400/7662 eta: 1 day, 7:03:48.335684	Training Loss 0.8236 (0.8242)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.030)	
2022-03-29 15:30:08,717: ============================================================
2022-03-29 15:31:06,397: time cost, forward:0.22389004467486381, backward:0.04615164630169706, data cost:0.3171369076729457 
2022-03-29 15:31:06,397: ============================================================
2022-03-29 15:31:06,398: Epoch 7/31 Batch 1500/7662 eta: 1 day, 6:27:02.739575	Training Loss 0.8230 (0.8242)	Training Prec@1 0.195 (0.008)	Training Prec@5 0.195 (0.030)	
2022-03-29 15:31:06,398: ============================================================
2022-03-29 15:32:06,312: time cost, forward:0.22364147384886893, backward:0.046089596268234584, data cost:0.3181809183207805 
2022-03-29 15:32:06,312: ============================================================
2022-03-29 15:32:06,312: Epoch 7/31 Batch 1600/7662 eta: 1 day, 7:36:48.676471	Training Loss 0.8240 (0.8242)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.030)	
2022-03-29 15:32:06,313: ============================================================
2022-03-29 15:33:03,823: time cost, forward:0.22346037019344553, backward:0.04608609355008202, data cost:0.31759357129636406 
2022-03-29 15:33:03,824: ============================================================
2022-03-29 15:33:03,824: Epoch 7/31 Batch 1700/7662 eta: 1 day, 6:19:46.150398	Training Loss 0.8247 (0.8242)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.029)	
2022-03-29 15:33:03,824: ============================================================
2022-03-29 15:34:02,884: time cost, forward:0.2233094380523444, backward:0.04603013255451705, data cost:0.31795939079187124 
2022-03-29 15:34:02,885: ============================================================
2022-03-29 15:34:02,885: Epoch 7/31 Batch 1800/7662 eta: 1 day, 7:07:48.632926	Training Loss 0.8240 (0.8242)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.029)	
2022-03-29 15:34:02,885: ============================================================
2022-03-29 15:35:01,132: time cost, forward:0.22330171613708302, backward:0.0460803405807921, data cost:0.3176502443226216 
2022-03-29 15:35:01,132: ============================================================
2022-03-29 15:35:01,132: Epoch 7/31 Batch 1900/7662 eta: 1 day, 6:41:07.461235	Training Loss 0.8253 (0.8242)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.029)	
2022-03-29 15:35:01,133: ============================================================
2022-03-29 15:35:59,516: time cost, forward:0.22342842277614638, backward:0.04607133295250988, data cost:0.3173396149654875 
2022-03-29 15:35:59,517: ============================================================
2022-03-29 15:35:59,517: Epoch 7/31 Batch 2000/7662 eta: 1 day, 6:44:28.471886	Training Loss 0.8243 (0.8242)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.028)	
2022-03-29 15:35:59,517: ============================================================
2022-03-29 15:36:58,885: time cost, forward:0.22328808831282604, backward:0.045931027922646216, data cost:0.31793169000706484 
2022-03-29 15:36:58,885: ============================================================
2022-03-29 15:36:58,885: Epoch 7/31 Batch 2100/7662 eta: 1 day, 7:14:33.765238	Training Loss 0.8246 (0.8242)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.027)	
2022-03-29 15:36:58,885: ============================================================
2022-03-29 15:37:56,695: time cost, forward:0.22305218389544937, backward:0.04580486411666697, data cost:0.3178657674420796 
2022-03-29 15:37:56,696: ============================================================
2022-03-29 15:37:56,696: Epoch 7/31 Batch 2200/7662 eta: 1 day, 6:24:24.762387	Training Loss 0.8250 (0.8242)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.027)	
2022-03-29 15:37:56,696: ============================================================
2022-03-29 15:38:55,875: time cost, forward:0.22270214386533893, backward:0.04590134861262895, data cost:0.31832485906245034 
2022-03-29 15:38:55,876: ============================================================
2022-03-29 15:38:55,876: Epoch 7/31 Batch 2300/7662 eta: 1 day, 7:06:39.131320	Training Loss 0.8242 (0.8242)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.027)	
2022-03-29 15:38:55,876: ============================================================
2022-03-29 15:39:53,325: time cost, forward:0.22227230545082108, backward:0.04585998770891502, data cost:0.31825970013273813 
2022-03-29 15:39:53,326: ============================================================
2022-03-29 15:39:53,326: Epoch 7/31 Batch 2400/7662 eta: 1 day, 6:11:07.399764	Training Loss 0.8248 (0.8242)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.195 (0.027)	
2022-03-29 15:39:53,326: ============================================================
2022-03-29 15:40:50,941: time cost, forward:0.22196902528482707, backward:0.04580822139799523, data cost:0.31819362323634287 
2022-03-29 15:40:50,941: ============================================================
2022-03-29 15:40:50,942: Epoch 7/31 Batch 2500/7662 eta: 1 day, 6:15:22.962365	Training Loss 0.8243 (0.8242)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.027)	
2022-03-29 15:40:50,942: ============================================================
2022-03-29 15:41:48,738: time cost, forward:0.2214308795033624, backward:0.045762154816572094, data cost:0.3183807682743344 
2022-03-29 15:41:48,739: ============================================================
2022-03-29 15:41:48,739: Epoch 7/31 Batch 2600/7662 eta: 1 day, 6:20:08.772928	Training Loss 0.8236 (0.8243)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.195 (0.027)	
2022-03-29 15:41:48,739: ============================================================
2022-03-29 15:42:48,517: time cost, forward:0.22109684638510638, backward:0.04581963004514702, data cost:0.31894528720059984 
2022-03-29 15:42:48,518: ============================================================
2022-03-29 15:42:48,518: Epoch 7/31 Batch 2700/7662 eta: 1 day, 7:21:32.845849	Training Loss 0.8237 (0.8243)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.027)	
2022-03-29 15:42:48,518: ============================================================
2022-03-29 15:43:46,148: time cost, forward:0.2210068947164107, backward:0.045849759308684505, data cost:0.31885922913382675 
2022-03-29 15:43:46,148: ============================================================
2022-03-29 15:43:46,149: Epoch 7/31 Batch 2800/7662 eta: 1 day, 6:12:58.305409	Training Loss 0.8249 (0.8243)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.028)	
2022-03-29 15:43:46,149: ============================================================
2022-03-29 15:44:44,781: time cost, forward:0.220952350626982, backward:0.04576715957546859, data cost:0.3190010890914638 
2022-03-29 15:44:44,782: ============================================================
2022-03-29 15:44:44,782: Epoch 7/31 Batch 2900/7662 eta: 1 day, 6:43:31.959228	Training Loss 0.8250 (0.8243)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.028)	
2022-03-29 15:44:44,782: ============================================================
2022-03-29 15:45:42,819: time cost, forward:0.220882231253471, backward:0.045695601641714434, data cost:0.31895270408014725 
2022-03-29 15:45:42,819: ============================================================
2022-03-29 15:45:42,820: Epoch 7/31 Batch 3000/7662 eta: 1 day, 6:23:50.766105	Training Loss 0.8248 (0.8243)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.028)	
2022-03-29 15:45:42,820: ============================================================
2022-03-29 15:46:41,667: time cost, forward:0.22078141492195535, backward:0.0457012237907033, data cost:0.31913471006508526 
2022-03-29 15:46:41,667: ============================================================
2022-03-29 15:46:41,668: Epoch 7/31 Batch 3100/7662 eta: 1 day, 6:48:20.093426	Training Loss 0.8233 (0.8243)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.028)	
2022-03-29 15:46:41,668: ============================================================
2022-03-29 15:47:40,539: time cost, forward:0.220847724638495, backward:0.04569861679458737, data cost:0.3191576743356956 
2022-03-29 15:47:40,540: ============================================================
2022-03-29 15:47:40,540: Epoch 7/31 Batch 3200/7662 eta: 1 day, 6:48:06.465461	Training Loss 0.8257 (0.8243)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.028)	
2022-03-29 15:47:40,540: ============================================================
2022-03-29 15:48:38,822: time cost, forward:0.22086186075109393, backward:0.04575444359098575, data cost:0.3189759721319471 
2022-03-29 15:48:38,823: ============================================================
2022-03-29 15:48:38,824: Epoch 7/31 Batch 3300/7662 eta: 1 day, 6:28:39.511624	Training Loss 0.8241 (0.8243)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.028)	
2022-03-29 15:48:38,824: ============================================================
2022-03-29 15:49:36,920: time cost, forward:0.22074055959281236, backward:0.04572686275056826, data cost:0.3189791074462693 
2022-03-29 15:49:36,920: ============================================================
2022-03-29 15:49:36,920: Epoch 7/31 Batch 3400/7662 eta: 1 day, 6:21:49.416511	Training Loss 0.8237 (0.8243)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.195 (0.028)	
2022-03-29 15:49:36,920: ============================================================
2022-03-29 15:50:35,692: time cost, forward:0.2206618049956281, backward:0.04570269523330606, data cost:0.31913374062434846 
2022-03-29 15:50:35,695: ============================================================
2022-03-29 15:50:35,696: Epoch 7/31 Batch 3500/7662 eta: 1 day, 6:42:07.148940	Training Loss 0.8243 (0.8243)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.028)	
2022-03-29 15:50:35,696: ============================================================
2022-03-29 15:51:34,269: time cost, forward:0.22060478485501717, backward:0.04571148083255701, data cost:0.31917742074413674 
2022-03-29 15:51:34,271: ============================================================
2022-03-29 15:51:34,272: Epoch 7/31 Batch 3600/7662 eta: 1 day, 6:34:54.611484	Training Loss 0.8243 (0.8243)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.028)	
2022-03-29 15:51:34,272: ============================================================
2022-03-29 15:52:32,342: time cost, forward:0.2206872480886954, backward:0.04574129477679069, data cost:0.31889443186109984 
2022-03-29 15:52:32,342: ============================================================
2022-03-29 15:52:32,342: Epoch 7/31 Batch 3700/7662 eta: 1 day, 6:18:05.955195	Training Loss 0.8248 (0.8243)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.028)	
2022-03-29 15:52:32,342: ============================================================
2022-03-29 15:53:30,769: time cost, forward:0.22071138668386645, backward:0.045744578880396417, data cost:0.31885863316940866 
2022-03-29 15:53:30,769: ============================================================
2022-03-29 15:53:30,769: Epoch 7/31 Batch 3800/7662 eta: 1 day, 6:28:17.539617	Training Loss 0.8256 (0.8243)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.028)	
2022-03-29 15:53:30,769: ============================================================
2022-03-29 15:54:29,822: time cost, forward:0.22067747650528052, backward:0.045730225824031745, data cost:0.3190366816416738 
2022-03-29 15:54:29,823: ============================================================
2022-03-29 15:54:29,823: Epoch 7/31 Batch 3900/7662 eta: 1 day, 6:46:54.487641	Training Loss 0.8236 (0.8243)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.028)	
2022-03-29 15:54:29,823: ============================================================
2022-03-29 15:55:29,264: time cost, forward:0.22054007453422422, backward:0.04567159423532412, data cost:0.3194416579856787 
2022-03-29 15:55:29,265: ============================================================
2022-03-29 15:55:29,265: Epoch 7/31 Batch 4000/7662 eta: 1 day, 6:58:04.128305	Training Loss 0.8239 (0.8243)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.028)	
2022-03-29 15:55:29,265: ============================================================
2022-03-29 15:56:27,099: time cost, forward:0.22059890758005343, backward:0.045651347848315676, data cost:0.31921315443286025 
2022-03-29 15:56:27,099: ============================================================
2022-03-29 15:56:27,100: Epoch 7/31 Batch 4100/7662 eta: 1 day, 6:06:51.634315	Training Loss 0.8238 (0.8243)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.028)	
2022-03-29 15:56:27,100: ============================================================
2022-03-29 15:57:25,768: time cost, forward:0.2205818151399958, backward:0.04564612625496363, data cost:0.31925856541894565 
2022-03-29 15:57:25,768: ============================================================
2022-03-29 15:57:25,768: Epoch 7/31 Batch 4200/7662 eta: 1 day, 6:31:56.532783	Training Loss 0.8241 (0.8243)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.029)	
2022-03-29 15:57:25,768: ============================================================
2022-03-29 15:58:23,424: time cost, forward:0.22056038897102392, backward:0.0456718624844388, data cost:0.3190370500018414 
2022-03-29 15:58:23,424: ============================================================
2022-03-29 15:58:23,424: Epoch 7/31 Batch 4300/7662 eta: 1 day, 5:59:21.580125	Training Loss 0.8234 (0.8243)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.195 (0.029)	
2022-03-29 15:58:23,425: ============================================================
2022-03-29 15:59:21,526: time cost, forward:0.22056556387526471, backward:0.045683286113613275, data cost:0.3189146962591832 
2022-03-29 15:59:21,527: ============================================================
2022-03-29 15:59:21,527: Epoch 7/31 Batch 4400/7662 eta: 1 day, 6:12:19.477973	Training Loss 0.8243 (0.8243)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.028)	
2022-03-29 15:59:21,527: ============================================================
2022-03-29 16:00:20,094: time cost, forward:0.22052219137135387, backward:0.04568458642130774, data cost:0.3189592763672248 
2022-03-29 16:00:20,095: ============================================================
2022-03-29 16:00:20,095: Epoch 7/31 Batch 4500/7662 eta: 1 day, 6:25:52.523063	Training Loss 0.8242 (0.8243)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.028)	
2022-03-29 16:00:20,096: ============================================================
2022-03-29 16:01:19,870: time cost, forward:0.22054306427585896, backward:0.0456577144671741, data cost:0.31922843353103936 
2022-03-29 16:01:19,870: ============================================================
2022-03-29 16:01:19,870: Epoch 7/31 Batch 4600/7662 eta: 1 day, 7:02:30.543438	Training Loss 0.8239 (0.8243)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.029)	
2022-03-29 16:01:19,871: ============================================================
2022-03-29 16:02:17,729: time cost, forward:0.22058561406863145, backward:0.04567951414275103, data cost:0.3190085536293538 
2022-03-29 16:02:17,730: ============================================================
2022-03-29 16:02:17,730: Epoch 7/31 Batch 4700/7662 eta: 1 day, 6:01:50.763759	Training Loss 0.8239 (0.8242)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.029)	
2022-03-29 16:02:17,730: ============================================================
2022-03-29 16:03:16,032: time cost, forward:0.220582069916436, backward:0.04567507461449285, data cost:0.31896445999097817 
2022-03-29 16:03:16,033: ============================================================
2022-03-29 16:03:16,033: Epoch 7/31 Batch 4800/7662 eta: 1 day, 6:14:41.969334	Training Loss 0.8252 (0.8242)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.029)	
2022-03-29 16:03:16,033: ============================================================
2022-03-29 16:04:13,575: time cost, forward:0.22051815802672853, backward:0.04567880425119332, data cost:0.3188149135778037 
2022-03-29 16:04:13,576: ============================================================
2022-03-29 16:04:13,576: Epoch 7/31 Batch 4900/7662 eta: 1 day, 5:50:04.082481	Training Loss 0.8233 (0.8242)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.029)	
2022-03-29 16:04:13,576: ============================================================
2022-03-29 16:05:12,538: time cost, forward:0.22049404235095066, backward:0.045629159668298405, data cost:0.3189706474715506 
2022-03-29 16:05:12,540: ============================================================
2022-03-29 16:05:12,541: Epoch 7/31 Batch 5000/7662 eta: 1 day, 6:33:19.001737	Training Loss 0.8237 (0.8242)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.029)	
2022-03-29 16:05:12,541: ============================================================
2022-03-29 16:06:11,698: time cost, forward:0.22056737341677868, backward:0.045520828293454156, data cost:0.3191293608232862 
2022-03-29 16:06:11,698: ============================================================
2022-03-29 16:06:11,699: Epoch 7/31 Batch 5100/7662 eta: 1 day, 6:38:20.709238	Training Loss 0.8250 (0.8242)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.029)	
2022-03-29 16:06:11,699: ============================================================
2022-03-29 16:07:11,137: time cost, forward:0.22054347778242536, backward:0.04551114703994871, data cost:0.31932617169340016 
2022-03-29 16:07:11,137: ============================================================
2022-03-29 16:07:11,138: Epoch 7/31 Batch 5200/7662 eta: 1 day, 6:46:05.448372	Training Loss 0.8255 (0.8242)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.030)	
2022-03-29 16:07:11,138: ============================================================
2022-03-29 16:08:09,311: time cost, forward:0.22060874755212914, backward:0.04549196036857667, data cost:0.3192062990736075 
2022-03-29 16:08:09,312: ============================================================
2022-03-29 16:08:09,312: Epoch 7/31 Batch 5300/7662 eta: 1 day, 6:05:50.262480	Training Loss 0.8238 (0.8242)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.030)	
2022-03-29 16:08:09,312: ============================================================
2022-03-29 16:09:07,102: time cost, forward:0.22064131307345802, backward:0.04545546253647356, data cost:0.3190474282770074 
2022-03-29 16:09:07,103: ============================================================
2022-03-29 16:09:07,103: Epoch 7/31 Batch 5400/7662 eta: 1 day, 5:52:57.981414	Training Loss 0.8246 (0.8242)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.030)	
2022-03-29 16:09:07,103: ============================================================
2022-03-29 16:10:05,339: time cost, forward:0.22062295262304993, backward:0.04546646938299695, data cost:0.3190167669513742 
2022-03-29 16:10:05,350: ============================================================
2022-03-29 16:10:05,351: Epoch 7/31 Batch 5500/7662 eta: 1 day, 6:06:10.600391	Training Loss 0.8245 (0.8242)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.195 (0.030)	
2022-03-29 16:10:05,351: ============================================================
2022-03-29 16:11:03,521: time cost, forward:0.2206615675217468, backward:0.045454765264637494, data cost:0.31892271892665475 
2022-03-29 16:11:03,521: ============================================================
2022-03-29 16:11:03,522: Epoch 7/31 Batch 5600/7662 eta: 1 day, 6:02:49.741977	Training Loss 0.8247 (0.8242)	Training Prec@1 0.195 (0.007)	Training Prec@5 0.195 (0.030)	
2022-03-29 16:11:03,522: ============================================================
2022-03-29 16:12:02,445: time cost, forward:0.22066907251816212, backward:0.04546535372796823, data cost:0.3189719606437355 
2022-03-29 16:12:02,446: ============================================================
2022-03-29 16:12:02,446: Epoch 7/31 Batch 5700/7662 eta: 1 day, 6:25:11.213720	Training Loss 0.8246 (0.8242)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.030)	
2022-03-29 16:12:02,446: ============================================================
2022-03-29 16:13:00,588: time cost, forward:0.22067334405675718, backward:0.04539919536799105, data cost:0.3189600488814347 
2022-03-29 16:13:00,588: ============================================================
2022-03-29 16:13:00,589: Epoch 7/31 Batch 5800/7662 eta: 1 day, 6:00:00.764399	Training Loss 0.8248 (0.8242)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.030)	
2022-03-29 16:13:00,589: ============================================================
2022-03-29 16:14:00,192: time cost, forward:0.22069709877742308, backward:0.045358854504960494, data cost:0.31915788546237406 
2022-03-29 16:14:00,193: ============================================================
2022-03-29 16:14:00,193: Epoch 7/31 Batch 5900/7662 eta: 1 day, 6:44:16.065789	Training Loss 0.8243 (0.8242)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.030)	
2022-03-29 16:14:00,193: ============================================================
2022-03-29 16:14:57,548: time cost, forward:0.22071720580495105, backward:0.04536907926045332, data cost:0.31892459574173365 
2022-03-29 16:14:57,548: ============================================================
2022-03-29 16:14:57,548: Epoch 7/31 Batch 6000/7662 eta: 1 day, 5:33:43.103453	Training Loss 0.8241 (0.8242)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.030)	
2022-03-29 16:14:57,548: ============================================================
2022-03-29 16:15:57,238: time cost, forward:0.22077118312556113, backward:0.045349245209012935, data cost:0.3190805842044178 
2022-03-29 16:15:57,238: ============================================================
2022-03-29 16:15:57,238: Epoch 7/31 Batch 6100/7662 eta: 1 day, 6:44:55.864717	Training Loss 0.8247 (0.8242)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.195 (0.030)	
2022-03-29 16:15:57,238: ============================================================
2022-03-29 16:16:54,586: time cost, forward:0.22079312434060322, backward:0.04534006857222021, data cost:0.3188738972934182 
2022-03-29 16:16:54,586: ============================================================
2022-03-29 16:16:54,586: Epoch 7/31 Batch 6200/7662 eta: 1 day, 5:31:35.342136	Training Loss 0.8246 (0.8242)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.030)	
2022-03-29 16:16:54,587: ============================================================
2022-03-29 16:17:54,738: time cost, forward:0.22072832613525778, backward:0.045345502195708015, data cost:0.3191881777464653 
2022-03-29 16:17:54,738: ============================================================
2022-03-29 16:17:54,739: Epoch 7/31 Batch 6300/7662 eta: 1 day, 6:57:12.651810	Training Loss 0.8247 (0.8242)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.031)	
2022-03-29 16:17:54,739: ============================================================
2022-03-29 16:18:54,108: time cost, forward:0.2207866948663229, backward:0.04533907409235172, data cost:0.31926705237756875 
2022-03-29 16:18:54,108: ============================================================
2022-03-29 16:18:54,109: Epoch 7/31 Batch 6400/7662 eta: 1 day, 6:32:04.027535	Training Loss 0.8243 (0.8242)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.031)	
2022-03-29 16:18:54,109: ============================================================
2022-03-29 16:19:53,083: time cost, forward:0.2207905260814779, backward:0.04531356660672969, data cost:0.3193432702561822 
2022-03-29 16:19:53,084: ============================================================
2022-03-29 16:19:53,084: Epoch 7/31 Batch 6500/7662 eta: 1 day, 6:18:54.617255	Training Loss 0.8236 (0.8242)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.031)	
2022-03-29 16:19:53,084: ============================================================
2022-03-29 16:20:51,943: time cost, forward:0.22084567557322038, backward:0.04530392666444, data cost:0.3193386453699932 
2022-03-29 16:20:51,944: ============================================================
2022-03-29 16:20:51,944: Epoch 7/31 Batch 6600/7662 eta: 1 day, 6:14:22.386381	Training Loss 0.8243 (0.8242)	Training Prec@1 0.195 (0.008)	Training Prec@5 0.195 (0.031)	
2022-03-29 16:20:51,944: ============================================================
2022-03-29 16:21:50,060: time cost, forward:0.22090731633031593, backward:0.04530975053089379, data cost:0.3192030863186053 
2022-03-29 16:21:50,061: ============================================================
2022-03-29 16:21:50,061: Epoch 7/31 Batch 6700/7662 eta: 1 day, 5:50:29.344185	Training Loss 0.8226 (0.8242)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.031)	
2022-03-29 16:21:50,061: ============================================================
2022-03-29 16:22:48,531: time cost, forward:0.22094273251599295, backward:0.045291184888094346, data cost:0.3191684491670488 
2022-03-29 16:22:48,531: ============================================================
2022-03-29 16:22:48,531: Epoch 7/31 Batch 6800/7662 eta: 1 day, 6:00:24.608796	Training Loss 0.8239 (0.8242)	Training Prec@1 0.391 (0.008)	Training Prec@5 0.391 (0.031)	
2022-03-29 16:22:48,532: ============================================================
2022-03-29 16:23:48,025: time cost, forward:0.22099821044666418, backward:0.04525086723871725, data cost:0.31928431854712513 
2022-03-29 16:23:48,026: ============================================================
2022-03-29 16:23:48,026: Epoch 7/31 Batch 6900/7662 eta: 1 day, 6:30:58.146137	Training Loss 0.8244 (0.8242)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.031)	
2022-03-29 16:23:48,027: ============================================================
2022-03-29 16:24:47,300: time cost, forward:0.2210318521697754, backward:0.04525802458741185, data cost:0.31934244218153995 
2022-03-29 16:24:47,300: ============================================================
2022-03-29 16:24:47,301: Epoch 7/31 Batch 7000/7662 eta: 1 day, 6:23:11.086533	Training Loss 0.8232 (0.8242)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.031)	
2022-03-29 16:24:47,301: ============================================================
2022-03-29 16:25:46,162: time cost, forward:0.22108177588613692, backward:0.04525814672341933, data cost:0.31932714499626585 
2022-03-29 16:25:46,162: ============================================================
2022-03-29 16:25:46,163: Epoch 7/31 Batch 7100/7662 eta: 1 day, 6:09:31.718668	Training Loss 0.8250 (0.8242)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.032)	
2022-03-29 16:25:46,163: ============================================================
2022-03-29 16:26:44,531: time cost, forward:0.22112091545728135, backward:0.0452737842670562, data cost:0.3192406039152531 
2022-03-29 16:26:44,532: ============================================================
2022-03-29 16:26:44,532: Epoch 7/31 Batch 7200/7662 eta: 1 day, 5:53:24.478580	Training Loss 0.8238 (0.8242)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.032)	
2022-03-29 16:26:44,532: ============================================================
2022-03-29 16:27:43,357: time cost, forward:0.2211867812104806, backward:0.04526999490296029, data cost:0.3192080639701851 
2022-03-29 16:27:43,357: ============================================================
2022-03-29 16:27:43,358: Epoch 7/31 Batch 7300/7662 eta: 1 day, 6:06:27.118501	Training Loss 0.8237 (0.8242)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.032)	
2022-03-29 16:27:43,358: ============================================================
2022-03-29 16:28:43,165: time cost, forward:0.2212120867980656, backward:0.04526175903555412, data cost:0.3193492116372575 
2022-03-29 16:28:43,165: ============================================================
2022-03-29 16:28:43,165: Epoch 7/31 Batch 7400/7662 eta: 1 day, 6:35:36.100772	Training Loss 0.8241 (0.8242)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.195 (0.032)	
2022-03-29 16:28:43,165: ============================================================
2022-03-29 16:29:41,254: time cost, forward:0.2212419351238714, backward:0.04525291495266589, data cost:0.3192586313169596 
2022-03-29 16:29:41,254: ============================================================
2022-03-29 16:29:41,254: Epoch 7/31 Batch 7500/7662 eta: 1 day, 5:41:53.248456	Training Loss 0.8234 (0.8242)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.032)	
2022-03-29 16:29:41,255: ============================================================
2022-03-29 16:30:40,288: time cost, forward:0.2212869856510998, backward:0.04524489188919037, data cost:0.3192762030568746 
2022-03-29 16:30:40,288: ============================================================
2022-03-29 16:30:40,289: Epoch 7/31 Batch 7600/7662 eta: 1 day, 6:09:54.631824	Training Loss 0.8247 (0.8242)	Training Prec@1 0.000 (0.009)	Training Prec@5 0.000 (0.032)	
2022-03-29 16:30:40,289: ============================================================
2022-03-29 16:31:18,775: Epoch: 7/31 eta: 1 day, 6:09:17.440062	Training Loss 0.8234 (0.8242)	Training Prec@1 0.000 (0.009)	Training Prec@5 0.000 (0.032)
2022-03-29 16:31:18,775: ============================================================
2022-03-29 16:32:20,089: time cost, forward:0.2225482078513714, backward:0.041361018864795415, data cost:0.3505097037613994 
2022-03-29 16:32:20,089: ============================================================
2022-03-29 16:32:20,090: Epoch 8/31 Batch 100/7662 eta: 1 day, 7:13:29.542065	Training Loss 0.8246 (0.8237)	Training Prec@1 0.000 (0.010)	Training Prec@5 0.000 (0.057)	
2022-03-29 16:32:20,090: ============================================================
2022-03-29 16:33:13,159: time cost, forward:0.20061410491790005, backward:0.041971907543776624, data cost:0.32874310196344575 
2022-03-29 16:33:13,160: ============================================================
2022-03-29 16:33:13,160: Epoch 8/31 Batch 200/7662 eta: 1 day, 3:04:44.734058	Training Loss 0.8233 (0.8236)	Training Prec@1 0.000 (0.010)	Training Prec@5 0.000 (0.055)	
2022-03-29 16:33:13,160: ============================================================
2022-03-29 16:34:07,890: time cost, forward:0.19583744269150954, backward:0.04276335438757038, data cost:0.32497045666876445 
2022-03-29 16:34:07,890: ============================================================
2022-03-29 16:34:07,891: Epoch 8/31 Batch 300/7662 eta: 1 day, 3:54:39.318994	Training Loss 0.8241 (0.8236)	Training Prec@1 0.000 (0.010)	Training Prec@5 0.000 (0.050)	
2022-03-29 16:34:07,891: ============================================================
2022-03-29 16:35:02,985: time cost, forward:0.1936301246920325, backward:0.04343508897269877, data cost:0.3232866863260293 
2022-03-29 16:35:02,986: ============================================================
2022-03-29 16:35:02,987: Epoch 8/31 Batch 400/7662 eta: 1 day, 4:04:54.923496	Training Loss 0.8235 (0.8236)	Training Prec@1 0.195 (0.009)	Training Prec@5 0.195 (0.045)	
2022-03-29 16:35:02,987: ============================================================
2022-03-29 16:35:57,251: time cost, forward:0.1915843424672832, backward:0.043872924988159916, data cost:0.32126377293007646 
2022-03-29 16:35:57,251: ============================================================
2022-03-29 16:35:57,251: Epoch 8/31 Batch 500/7662 eta: 1 day, 3:38:35.301243	Training Loss 0.8237 (0.8236)	Training Prec@1 0.000 (0.010)	Training Prec@5 0.000 (0.045)	
2022-03-29 16:35:57,251: ============================================================
2022-03-29 16:36:52,005: time cost, forward:0.19100559494133187, backward:0.04391727980866854, data cost:0.32018774140856304 
2022-03-29 16:36:52,005: ============================================================
2022-03-29 16:36:52,006: Epoch 8/31 Batch 600/7662 eta: 1 day, 3:52:38.731064	Training Loss 0.8243 (0.8236)	Training Prec@1 0.000 (0.009)	Training Prec@5 0.000 (0.046)	
2022-03-29 16:36:52,006: ============================================================
2022-03-29 16:37:48,455: time cost, forward:0.19079646225139307, backward:0.04432244396346151, data cost:0.32127409329230183 
2022-03-29 16:37:48,455: ============================================================
2022-03-29 16:37:48,455: Epoch 8/31 Batch 700/7662 eta: 1 day, 4:43:29.376036	Training Loss 0.8241 (0.8236)	Training Prec@1 0.000 (0.010)	Training Prec@5 0.000 (0.048)	
2022-03-29 16:37:48,456: ============================================================
2022-03-29 16:38:43,582: time cost, forward:0.1910124102581726, backward:0.04452578594747264, data cost:0.32016677969835877 
2022-03-29 16:38:43,583: ============================================================
2022-03-29 16:38:43,583: Epoch 8/31 Batch 800/7662 eta: 1 day, 4:02:12.519099	Training Loss 0.8244 (0.8236)	Training Prec@1 0.000 (0.011)	Training Prec@5 0.000 (0.047)	
2022-03-29 16:38:43,583: ============================================================
2022-03-29 16:39:39,965: time cost, forward:0.19133747035059437, backward:0.04463883899608099, data cost:0.32057954419043755 
2022-03-29 16:39:39,966: ============================================================
2022-03-29 16:39:39,966: Epoch 8/31 Batch 900/7662 eta: 1 day, 4:39:35.061573	Training Loss 0.8237 (0.8236)	Training Prec@1 0.000 (0.011)	Training Prec@5 0.000 (0.048)	
2022-03-29 16:39:39,966: ============================================================
2022-03-29 16:40:35,171: time cost, forward:0.19159152629497173, backward:0.0448115339746943, data cost:0.319674841037861 
2022-03-29 16:40:35,172: ============================================================
2022-03-29 16:40:35,172: Epoch 8/31 Batch 1000/7662 eta: 1 day, 4:02:45.878537	Training Loss 0.8230 (0.8236)	Training Prec@1 0.000 (0.010)	Training Prec@5 0.000 (0.047)	
2022-03-29 16:40:35,172: ============================================================
2022-03-29 16:41:33,429: time cost, forward:0.19186298732219553, backward:0.044901832870400095, data cost:0.32166852725430767 
2022-03-29 16:41:33,430: ============================================================
2022-03-29 16:41:33,430: Epoch 8/31 Batch 1100/7662 eta: 1 day, 5:34:48.899910	Training Loss 0.8231 (0.8236)	Training Prec@1 0.000 (0.010)	Training Prec@5 0.000 (0.046)	
2022-03-29 16:41:33,430: ============================================================
2022-03-29 16:42:30,461: time cost, forward:0.192987547604813, backward:0.045112543249249556, data cost:0.3213112887190818 
2022-03-29 16:42:30,462: ============================================================
2022-03-29 16:42:30,462: Epoch 8/31 Batch 1200/7662 eta: 1 day, 4:56:30.851729	Training Loss 0.8226 (0.8236)	Training Prec@1 0.000 (0.011)	Training Prec@5 0.000 (0.046)	
2022-03-29 16:42:30,462: ============================================================
2022-03-29 16:43:28,295: time cost, forward:0.1942975444000808, backward:0.04519632158139929, data cost:0.3213330003460891 
2022-03-29 16:43:28,296: ============================================================
2022-03-29 16:43:28,296: Epoch 8/31 Batch 1300/7662 eta: 1 day, 5:19:58.722277	Training Loss 0.8237 (0.8236)	Training Prec@1 0.000 (0.011)	Training Prec@5 0.000 (0.047)	
2022-03-29 16:43:28,296: ============================================================
2022-03-29 16:44:25,086: time cost, forward:0.19509002189281754, backward:0.04531584235921428, data cost:0.32088459398680025 
2022-03-29 16:44:25,087: ============================================================
2022-03-29 16:44:25,087: Epoch 8/31 Batch 1400/7662 eta: 1 day, 4:47:17.420027	Training Loss 0.8231 (0.8236)	Training Prec@1 0.000 (0.011)	Training Prec@5 0.000 (0.047)	
2022-03-29 16:44:25,087: ============================================================
2022-03-29 16:45:22,808: time cost, forward:0.19597070514559348, backward:0.045396483525027426, data cost:0.32097273432786977 
2022-03-29 16:45:22,808: ============================================================
2022-03-29 16:45:22,809: Epoch 8/31 Batch 1500/7662 eta: 1 day, 5:14:38.154390	Training Loss 0.8237 (0.8236)	Training Prec@1 0.000 (0.011)	Training Prec@5 0.000 (0.047)	
2022-03-29 16:45:22,809: ============================================================
2022-03-29 16:46:20,532: time cost, forward:0.19684020439634628, backward:0.04545487919175826, data cost:0.3209533069639224 
2022-03-29 16:46:20,532: ============================================================
2022-03-29 16:46:20,533: Epoch 8/31 Batch 1600/7662 eta: 1 day, 5:13:43.986435	Training Loss 0.8231 (0.8236)	Training Prec@1 0.000 (0.011)	Training Prec@5 0.000 (0.047)	
2022-03-29 16:46:20,533: ============================================================
2022-03-29 16:47:16,561: time cost, forward:0.1967318236231453, backward:0.04557358285411096, data cost:0.3207206093191469 
2022-03-29 16:47:16,562: ============================================================
2022-03-29 16:47:16,562: Epoch 8/31 Batch 1700/7662 eta: 1 day, 4:21:20.281199	Training Loss 0.8232 (0.8236)	Training Prec@1 0.000 (0.011)	Training Prec@5 0.000 (0.048)	
2022-03-29 16:47:16,563: ============================================================
2022-03-29 16:48:13,841: time cost, forward:0.19686912509585303, backward:0.04562977501390509, data cost:0.32107020391895746 
2022-03-29 16:48:13,842: ============================================================
2022-03-29 16:48:13,842: Epoch 8/31 Batch 1800/7662 eta: 1 day, 4:58:20.072514	Training Loss 0.8230 (0.8236)	Training Prec@1 0.000 (0.011)	Training Prec@5 0.000 (0.049)	
2022-03-29 16:48:13,842: ============================================================
2022-03-29 16:49:11,329: time cost, forward:0.19727360568214805, backward:0.04565722431365662, data cost:0.32120705278626616 
2022-03-29 16:49:11,329: ============================================================
2022-03-29 16:49:11,330: Epoch 8/31 Batch 1900/7662 eta: 1 day, 5:03:41.130219	Training Loss 0.8238 (0.8236)	Training Prec@1 0.000 (0.011)	Training Prec@5 0.000 (0.049)	
2022-03-29 16:49:11,330: ============================================================
2022-03-29 16:50:07,334: time cost, forward:0.1972032269577553, backward:0.045764311246122936, data cost:0.3209452726889873 
2022-03-29 16:50:07,334: ============================================================
2022-03-29 16:50:07,335: Epoch 8/31 Batch 2000/7662 eta: 1 day, 4:17:46.862237	Training Loss 0.8245 (0.8236)	Training Prec@1 0.000 (0.011)	Training Prec@5 0.195 (0.049)	
2022-03-29 16:50:07,335: ============================================================
2022-03-29 16:51:03,990: time cost, forward:0.19752713758187843, backward:0.045810609388601334, data cost:0.3206897235132502 
2022-03-29 16:51:03,990: ============================================================
2022-03-29 16:51:03,991: Epoch 8/31 Batch 2100/7662 eta: 1 day, 4:36:34.608402	Training Loss 0.8233 (0.8236)	Training Prec@1 0.000 (0.011)	Training Prec@5 0.195 (0.050)	
2022-03-29 16:51:03,991: ============================================================
2022-03-29 16:51:59,840: time cost, forward:0.1974137322693426, backward:0.04588916075126644, data cost:0.32045317910486265 
2022-03-29 16:51:59,840: ============================================================
2022-03-29 16:51:59,840: Epoch 8/31 Batch 2200/7662 eta: 1 day, 4:11:12.280556	Training Loss 0.8238 (0.8236)	Training Prec@1 0.000 (0.011)	Training Prec@5 0.000 (0.050)	
2022-03-29 16:51:59,841: ============================================================
2022-03-29 16:52:56,656: time cost, forward:0.19742352613006897, backward:0.04592040758020933, data cost:0.3205893124741749 
2022-03-29 16:52:56,656: ============================================================
2022-03-29 16:52:56,656: Epoch 8/31 Batch 2300/7662 eta: 1 day, 4:39:31.340386	Training Loss 0.8228 (0.8236)	Training Prec@1 0.000 (0.012)	Training Prec@5 0.000 (0.050)	
2022-03-29 16:52:56,657: ============================================================
2022-03-29 16:53:53,744: time cost, forward:0.19759003566473213, backward:0.04596413081265728, data cost:0.3206492247507939 
2022-03-29 16:53:53,745: ============================================================
2022-03-29 16:53:53,745: Epoch 8/31 Batch 2400/7662 eta: 1 day, 4:46:50.319226	Training Loss 0.8238 (0.8236)	Training Prec@1 0.000 (0.012)	Training Prec@5 0.000 (0.051)	
2022-03-29 16:53:53,745: ============================================================
2022-03-29 16:54:52,146: time cost, forward:0.19830776014629484, backward:0.0460715485649521, data cost:0.3206002908785279 
2022-03-29 16:54:52,147: ============================================================
2022-03-29 16:54:52,147: Epoch 8/31 Batch 2500/7662 eta: 1 day, 5:25:34.649300	Training Loss 0.8232 (0.8236)	Training Prec@1 0.000 (0.012)	Training Prec@5 0.000 (0.050)	
2022-03-29 16:54:52,147: ============================================================
2022-03-29 16:55:51,083: time cost, forward:0.1991506842018412, backward:0.04612659784223814, data cost:0.320380219866469 
2022-03-29 16:55:51,084: ============================================================
2022-03-29 16:55:51,084: Epoch 8/31 Batch 2600/7662 eta: 1 day, 5:40:46.021371	Training Loss 0.8227 (0.8236)	Training Prec@1 0.000 (0.012)	Training Prec@5 0.000 (0.050)	
2022-03-29 16:55:51,084: ============================================================
2022-03-29 16:56:50,252: time cost, forward:0.19972380994646227, backward:0.04610513907620182, data cost:0.32101012760288145 
2022-03-29 16:56:50,253: ============================================================
2022-03-29 16:56:50,253: Epoch 8/31 Batch 2700/7662 eta: 1 day, 5:46:48.149940	Training Loss 0.8234 (0.8236)	Training Prec@1 0.195 (0.012)	Training Prec@5 0.195 (0.051)	
2022-03-29 16:56:50,253: ============================================================
2022-03-29 16:57:47,952: time cost, forward:0.19999813028385316, backward:0.046179804813866104, data cost:0.32101100212593253 
2022-03-29 16:57:47,953: ============================================================
2022-03-29 16:57:47,953: Epoch 8/31 Batch 2800/7662 eta: 1 day, 5:01:28.011572	Training Loss 0.8237 (0.8236)	Training Prec@1 0.000 (0.012)	Training Prec@5 0.000 (0.052)	
2022-03-29 16:57:47,953: ============================================================
2022-03-29 16:58:46,062: time cost, forward:0.20006138869670803, backward:0.04618670530013275, data cost:0.3214057290418348 
2022-03-29 16:58:46,063: ============================================================
2022-03-29 16:58:46,063: Epoch 8/31 Batch 2900/7662 eta: 1 day, 5:12:52.800917	Training Loss 0.8236 (0.8236)	Training Prec@1 0.000 (0.012)	Training Prec@5 0.195 (0.052)	
2022-03-29 16:58:46,063: ============================================================
2022-03-29 16:59:42,378: time cost, forward:0.19970684124653082, backward:0.04615568605889158, data cost:0.3216224770897347 
2022-03-29 16:59:42,379: ============================================================
2022-03-29 16:59:42,379: Epoch 8/31 Batch 3000/7662 eta: 1 day, 4:17:49.454819	Training Loss 0.8230 (0.8236)	Training Prec@1 0.000 (0.013)	Training Prec@5 0.000 (0.051)	
2022-03-29 16:59:42,379: ============================================================
2022-03-29 17:00:38,047: time cost, forward:0.19946772946815947, backward:0.046145837050785975, data cost:0.32151126376887834 
2022-03-29 17:00:38,047: ============================================================
2022-03-29 17:00:38,048: Epoch 8/31 Batch 3100/7662 eta: 1 day, 3:57:22.423937	Training Loss 0.8237 (0.8236)	Training Prec@1 0.000 (0.013)	Training Prec@5 0.000 (0.051)	
2022-03-29 17:00:38,048: ============================================================
2022-03-29 17:01:35,463: time cost, forward:0.1994383502058701, backward:0.04617664790891342, data cost:0.3217148002738988 
2022-03-29 17:01:35,463: ============================================================
2022-03-29 17:01:35,464: Epoch 8/31 Batch 3200/7662 eta: 1 day, 4:49:04.274986	Training Loss 0.8229 (0.8236)	Training Prec@1 0.000 (0.013)	Training Prec@5 0.000 (0.050)	
2022-03-29 17:01:35,464: ============================================================
2022-03-29 17:02:34,456: time cost, forward:0.19974447301244258, backward:0.04618048559502783, data cost:0.32207609176924823 
2022-03-29 17:02:34,457: ============================================================
2022-03-29 17:02:34,457: Epoch 8/31 Batch 3300/7662 eta: 1 day, 5:35:35.559440	Training Loss 0.8234 (0.8236)	Training Prec@1 0.000 (0.013)	Training Prec@5 0.195 (0.051)	
2022-03-29 17:02:34,457: ============================================================
2022-03-29 17:03:30,464: time cost, forward:0.19968155749793193, backward:0.04615477549044235, data cost:0.32192529983890866 
2022-03-29 17:03:30,464: ============================================================
2022-03-29 17:03:30,464: Epoch 8/31 Batch 3400/7662 eta: 1 day, 4:04:47.171292	Training Loss 0.8238 (0.8236)	Training Prec@1 0.000 (0.013)	Training Prec@5 0.000 (0.051)	
2022-03-29 17:03:30,465: ============================================================
2022-03-29 17:04:28,165: time cost, forward:0.1998458384241026, backward:0.04615888366633805, data cost:0.32201032844329774 
2022-03-29 17:04:28,166: ============================================================
2022-03-29 17:04:28,166: Epoch 8/31 Batch 3500/7662 eta: 1 day, 4:54:47.971578	Training Loss 0.8233 (0.8236)	Training Prec@1 0.000 (0.013)	Training Prec@5 0.000 (0.051)	
2022-03-29 17:04:28,167: ============================================================
2022-03-29 17:05:26,240: time cost, forward:0.20008327868886377, backward:0.04613929028046002, data cost:0.3221318672086902 
2022-03-29 17:05:26,241: ============================================================
2022-03-29 17:05:26,241: Epoch 8/31 Batch 3600/7662 eta: 1 day, 5:05:02.590536	Training Loss 0.8236 (0.8236)	Training Prec@1 0.000 (0.013)	Training Prec@5 0.000 (0.052)	
2022-03-29 17:05:26,242: ============================================================
2022-03-29 17:06:25,316: time cost, forward:0.20042699148410653, backward:0.04613268984495288, data cost:0.3223887491496907 
2022-03-29 17:06:25,316: ============================================================
2022-03-29 17:06:25,316: Epoch 8/31 Batch 3700/7662 eta: 1 day, 5:34:06.816804	Training Loss 0.8234 (0.8236)	Training Prec@1 0.000 (0.013)	Training Prec@5 0.195 (0.052)	
2022-03-29 17:06:25,317: ============================================================
2022-03-29 17:07:22,401: time cost, forward:0.20053376138571158, backward:0.04612788372084981, data cost:0.3223207252971371 
2022-03-29 17:07:22,401: ============================================================
2022-03-29 17:07:22,401: Epoch 8/31 Batch 3800/7662 eta: 1 day, 4:33:23.724569	Training Loss 0.8228 (0.8235)	Training Prec@1 0.000 (0.013)	Training Prec@5 0.000 (0.052)	
2022-03-29 17:07:22,402: ============================================================
2022-03-29 17:08:19,824: time cost, forward:0.20032166003814017, backward:0.04609022791124546, data cost:0.32269486704677397 
2022-03-29 17:08:19,825: ============================================================
2022-03-29 17:08:19,825: Epoch 8/31 Batch 3900/7662 eta: 1 day, 4:42:36.049610	Training Loss 0.8235 (0.8235)	Training Prec@1 0.000 (0.013)	Training Prec@5 0.000 (0.052)	
2022-03-29 17:08:19,825: ============================================================
2022-03-29 17:09:17,290: time cost, forward:0.2002920989961617, backward:0.046094763544268176, data cost:0.3228398645839324 
2022-03-29 17:09:17,292: ============================================================
2022-03-29 17:09:17,293: Epoch 8/31 Batch 4000/7662 eta: 1 day, 4:42:58.290881	Training Loss 0.8242 (0.8235)	Training Prec@1 0.000 (0.013)	Training Prec@5 0.000 (0.052)	
2022-03-29 17:09:17,294: ============================================================
2022-03-29 17:10:14,351: time cost, forward:0.200276516914135, backward:0.046084233277249434, data cost:0.3228154047491144 
2022-03-29 17:10:14,352: ============================================================
2022-03-29 17:10:14,352: Epoch 8/31 Batch 4100/7662 eta: 1 day, 4:29:46.033579	Training Loss 0.8235 (0.8235)	Training Prec@1 0.000 (0.013)	Training Prec@5 0.000 (0.052)	
2022-03-29 17:10:14,352: ============================================================
2022-03-29 17:11:12,094: time cost, forward:0.20041418751241707, backward:0.046060518129407355, data cost:0.32296782824277137 
2022-03-29 17:11:12,095: ============================================================
2022-03-29 17:11:12,095: Epoch 8/31 Batch 4200/7662 eta: 1 day, 4:49:18.124354	Training Loss 0.8231 (0.8235)	Training Prec@1 0.000 (0.014)	Training Prec@5 0.000 (0.053)	
2022-03-29 17:11:12,095: ============================================================
2022-03-29 17:12:09,929: time cost, forward:0.20043421545869447, backward:0.04602422201791512, data cost:0.3231908440950389 
2022-03-29 17:12:09,930: ============================================================
2022-03-29 17:12:09,930: Epoch 8/31 Batch 4300/7662 eta: 1 day, 4:51:04.790833	Training Loss 0.8221 (0.8235)	Training Prec@1 0.000 (0.014)	Training Prec@5 0.000 (0.053)	
2022-03-29 17:12:09,930: ============================================================
2022-03-29 17:13:06,865: time cost, forward:0.2005264812178112, backward:0.046041956541889986, data cost:0.3230604771511965 
2022-03-29 17:13:06,866: ============================================================
2022-03-29 17:13:06,866: Epoch 8/31 Batch 4400/7662 eta: 1 day, 4:23:14.575738	Training Loss 0.8229 (0.8235)	Training Prec@1 0.000 (0.014)	Training Prec@5 0.000 (0.053)	
2022-03-29 17:13:06,866: ============================================================
2022-03-29 17:14:04,305: time cost, forward:0.2005158931738961, backward:0.04603820886842991, data cost:0.32316928546835144 
2022-03-29 17:14:04,306: ============================================================
2022-03-29 17:14:04,306: Epoch 8/31 Batch 4500/7662 eta: 1 day, 4:37:21.080623	Training Loss 0.8225 (0.8235)	Training Prec@1 0.000 (0.014)	Training Prec@5 0.000 (0.053)	
2022-03-29 17:14:04,306: ============================================================
2022-03-29 17:15:01,595: time cost, forward:0.20071686592068871, backward:0.04602499126377093, data cost:0.32304160997747833 
2022-03-29 17:15:01,596: ============================================================
2022-03-29 17:15:01,596: Epoch 8/31 Batch 4600/7662 eta: 1 day, 4:31:54.519704	Training Loss 0.8224 (0.8235)	Training Prec@1 0.000 (0.014)	Training Prec@5 0.000 (0.053)	
2022-03-29 17:15:01,596: ============================================================
2022-03-29 17:15:58,080: time cost, forward:0.2006800423837464, backward:0.0459947638827249, data cost:0.32299059957969845 
2022-03-29 17:15:58,080: ============================================================
2022-03-29 17:15:58,081: Epoch 8/31 Batch 4700/7662 eta: 1 day, 4:06:54.297674	Training Loss 0.8235 (0.8235)	Training Prec@1 0.000 (0.014)	Training Prec@5 0.195 (0.053)	
2022-03-29 17:15:58,081: ============================================================
2022-03-29 17:16:56,408: time cost, forward:0.2009424941195476, backward:0.04600256108870032, data cost:0.32300425167008223 
2022-03-29 17:16:56,409: ============================================================
2022-03-29 17:16:56,409: Epoch 8/31 Batch 4800/7662 eta: 1 day, 5:00:59.216926	Training Loss 0.8229 (0.8235)	Training Prec@1 0.000 (0.014)	Training Prec@5 0.195 (0.053)	
2022-03-29 17:16:56,409: ============================================================
2022-03-29 17:17:55,014: time cost, forward:0.20118249998114066, backward:0.04600092230292821, data cost:0.32308359164611544 
2022-03-29 17:17:55,015: ============================================================
2022-03-29 17:17:55,015: Epoch 8/31 Batch 4900/7662 eta: 1 day, 5:08:18.647868	Training Loss 0.8233 (0.8235)	Training Prec@1 0.000 (0.014)	Training Prec@5 0.000 (0.053)	
2022-03-29 17:17:55,015: ============================================================
2022-03-29 17:18:52,171: time cost, forward:0.20122838578335783, backward:0.045980607397343116, data cost:0.32306775772039786 
2022-03-29 17:18:52,172: ============================================================
2022-03-29 17:18:52,172: Epoch 8/31 Batch 5000/7662 eta: 1 day, 4:24:07.796539	Training Loss 0.8237 (0.8235)	Training Prec@1 0.000 (0.014)	Training Prec@5 0.195 (0.054)	
2022-03-29 17:18:52,173: ============================================================
2022-03-29 17:19:50,091: time cost, forward:0.20146657490547928, backward:0.045960664515355965, data cost:0.32301975993881926 
2022-03-29 17:19:50,092: ============================================================
2022-03-29 17:19:50,092: Epoch 8/31 Batch 5100/7662 eta: 1 day, 4:45:54.345538	Training Loss 0.8230 (0.8235)	Training Prec@1 0.000 (0.014)	Training Prec@5 0.000 (0.054)	
2022-03-29 17:19:50,092: ============================================================
2022-03-29 17:20:49,660: time cost, forward:0.20164942833111135, backward:0.04593661350111568, data cost:0.323337523197527 
2022-03-29 17:20:49,660: ============================================================
2022-03-29 17:20:49,660: Epoch 8/31 Batch 5200/7662 eta: 1 day, 5:34:01.974041	Training Loss 0.8220 (0.8235)	Training Prec@1 0.000 (0.014)	Training Prec@5 0.586 (0.054)	
2022-03-29 17:20:49,661: ============================================================
2022-03-29 17:21:47,106: time cost, forward:0.2016558032549649, backward:0.04589167543797476, data cost:0.3234353937907452 
2022-03-29 17:21:47,107: ============================================================
2022-03-29 17:21:47,107: Epoch 8/31 Batch 5300/7662 eta: 1 day, 4:29:53.354814	Training Loss 0.8234 (0.8235)	Training Prec@1 0.000 (0.014)	Training Prec@5 0.195 (0.054)	
2022-03-29 17:21:47,107: ============================================================
2022-03-29 17:22:43,289: time cost, forward:0.20168725913002394, backward:0.04588294126387326, data cost:0.3232385996514547 
2022-03-29 17:22:43,290: ============================================================
2022-03-29 17:22:43,290: Epoch 8/31 Batch 5400/7662 eta: 1 day, 3:51:20.467792	Training Loss 0.8239 (0.8235)	Training Prec@1 0.000 (0.014)	Training Prec@5 0.000 (0.054)	
2022-03-29 17:22:43,290: ============================================================
2022-03-29 17:23:42,019: time cost, forward:0.2018951881926891, backward:0.045855870440258156, data cost:0.32335231637581846 
2022-03-29 17:23:42,019: ============================================================
2022-03-29 17:23:42,019: Epoch 8/31 Batch 5500/7662 eta: 1 day, 5:06:06.668008	Training Loss 0.8231 (0.8234)	Training Prec@1 0.000 (0.015)	Training Prec@5 0.000 (0.054)	
2022-03-29 17:23:42,020: ============================================================
2022-03-29 17:24:40,532: time cost, forward:0.20220172309432632, backward:0.04582446237657087, data cost:0.3233192828877267 
2022-03-29 17:24:40,533: ============================================================
2022-03-29 17:24:40,534: Epoch 8/31 Batch 5600/7662 eta: 1 day, 4:58:44.375187	Training Loss 0.8232 (0.8234)	Training Prec@1 0.000 (0.015)	Training Prec@5 0.000 (0.055)	
2022-03-29 17:24:40,534: ============================================================
2022-03-29 17:25:38,718: time cost, forward:0.20230748846271954, backward:0.04582296628495187, data cost:0.32338831286238756 
2022-03-29 17:25:38,718: ============================================================
2022-03-29 17:25:38,718: Epoch 8/31 Batch 5700/7662 eta: 1 day, 4:47:58.737229	Training Loss 0.8229 (0.8234)	Training Prec@1 0.000 (0.015)	Training Prec@5 0.000 (0.055)	
2022-03-29 17:25:38,719: ============================================================
2022-03-29 17:26:35,394: time cost, forward:0.2023552796988266, backward:0.04584180792768899, data cost:0.32323203240618414 
2022-03-29 17:26:35,394: ============================================================
2022-03-29 17:26:35,395: Epoch 8/31 Batch 5800/7662 eta: 1 day, 4:02:14.604588	Training Loss 0.8214 (0.8234)	Training Prec@1 0.000 (0.015)	Training Prec@5 0.000 (0.056)	
2022-03-29 17:26:35,395: ============================================================
2022-03-29 17:27:32,051: time cost, forward:0.20241812213555618, backward:0.045838206920568815, data cost:0.32308525630105733 
2022-03-29 17:27:32,051: ============================================================
2022-03-29 17:27:32,052: Epoch 8/31 Batch 5900/7662 eta: 1 day, 4:00:42.475882	Training Loss 0.8219 (0.8234)	Training Prec@1 0.195 (0.015)	Training Prec@5 0.195 (0.056)	
2022-03-29 17:27:32,052: ============================================================
2022-03-29 17:28:28,940: time cost, forward:0.20252027589493066, backward:0.04583817641920677, data cost:0.32293769172239867 
2022-03-29 17:28:28,941: ============================================================
2022-03-29 17:28:28,941: Epoch 8/31 Batch 6000/7662 eta: 1 day, 4:06:39.983079	Training Loss 0.8232 (0.8234)	Training Prec@1 0.000 (0.015)	Training Prec@5 0.000 (0.056)	
2022-03-29 17:28:28,941: ============================================================
2022-03-29 17:29:25,903: time cost, forward:0.20249826229093582, backward:0.045817284764647775, data cost:0.3229474105841216 
2022-03-29 17:29:25,903: ============================================================
2022-03-29 17:29:25,904: Epoch 8/31 Batch 6100/7662 eta: 1 day, 4:07:53.405606	Training Loss 0.8226 (0.8234)	Training Prec@1 0.000 (0.015)	Training Prec@5 0.000 (0.057)	
2022-03-29 17:29:25,904: ============================================================
2022-03-29 17:30:22,124: time cost, forward:0.20243078298117964, backward:0.04581790963456138, data cost:0.3228615589114154 
2022-03-29 17:30:22,124: ============================================================
2022-03-29 17:30:22,125: Epoch 8/31 Batch 6200/7662 eta: 1 day, 3:44:58.793577	Training Loss 0.8228 (0.8234)	Training Prec@1 0.000 (0.015)	Training Prec@5 0.000 (0.057)	
2022-03-29 17:30:22,125: ============================================================
2022-03-29 17:31:18,963: time cost, forward:0.20236200978972077, backward:0.045809357596647365, data cost:0.3228885587349186 
2022-03-29 17:31:18,964: ============================================================
2022-03-29 17:31:18,964: Epoch 8/31 Batch 6300/7662 eta: 1 day, 4:02:20.418426	Training Loss 0.8217 (0.8234)	Training Prec@1 0.000 (0.016)	Training Prec@5 0.195 (0.057)	
2022-03-29 17:31:18,964: ============================================================
2022-03-29 17:32:16,802: time cost, forward:0.20246102404158495, backward:0.0457664753314312, data cost:0.322941201201527 
2022-03-29 17:32:16,803: ============================================================
2022-03-29 17:32:16,803: Epoch 8/31 Batch 6400/7662 eta: 1 day, 4:30:57.896963	Training Loss 0.8221 (0.8234)	Training Prec@1 0.000 (0.015)	Training Prec@5 0.000 (0.057)	
2022-03-29 17:32:16,803: ============================================================
2022-03-29 17:33:15,312: time cost, forward:0.20252904614625958, backward:0.04578194230827006, data cost:0.32306423405900997 
2022-03-29 17:33:15,313: ============================================================
2022-03-29 17:33:15,313: Epoch 8/31 Batch 6500/7662 eta: 1 day, 4:49:50.563138	Training Loss 0.8225 (0.8234)	Training Prec@1 0.000 (0.015)	Training Prec@5 0.195 (0.057)	
2022-03-29 17:33:15,314: ============================================================
2022-03-29 17:34:15,836: time cost, forward:0.2025534704176291, backward:0.04574702667239797, data cost:0.3235819100574899 
2022-03-29 17:34:15,837: ============================================================
2022-03-29 17:34:15,837: Epoch 8/31 Batch 6600/7662 eta: 1 day, 5:48:21.915327	Training Loss 0.8230 (0.8234)	Training Prec@1 0.000 (0.015)	Training Prec@5 0.000 (0.057)	
2022-03-29 17:34:15,837: ============================================================
2022-03-29 17:35:14,528: time cost, forward:0.202696001303696, backward:0.04571966445878435, data cost:0.3236817938834095 
2022-03-29 17:35:14,528: ============================================================
2022-03-29 17:35:14,529: Epoch 8/31 Batch 6700/7662 eta: 1 day, 4:53:15.295846	Training Loss 0.8234 (0.8233)	Training Prec@1 0.195 (0.015)	Training Prec@5 0.195 (0.057)	
2022-03-29 17:35:14,529: ============================================================
2022-03-29 17:36:11,194: time cost, forward:0.20264588364574343, backward:0.04571253170878033, data cost:0.3236567960414558 
2022-03-29 17:36:11,195: ============================================================
2022-03-29 17:36:11,195: Epoch 8/31 Batch 6800/7662 eta: 1 day, 3:52:29.207367	Training Loss 0.8220 (0.8233)	Training Prec@1 0.000 (0.015)	Training Prec@5 0.000 (0.057)	
2022-03-29 17:36:11,195: ============================================================
2022-03-29 17:37:07,915: time cost, forward:0.2026557064968739, backward:0.04568045024233187, data cost:0.32360396303634986 
2022-03-29 17:37:07,915: ============================================================
2022-03-29 17:37:07,916: Epoch 8/31 Batch 6900/7662 eta: 1 day, 3:53:09.624681	Training Loss 0.8233 (0.8233)	Training Prec@1 0.000 (0.016)	Training Prec@5 0.000 (0.057)	
2022-03-29 17:37:07,916: ============================================================
2022-03-29 17:38:05,874: time cost, forward:0.20262606843298955, backward:0.045659305504652956, data cost:0.3237584546423415 
2022-03-29 17:38:05,875: ============================================================
2022-03-29 17:38:05,875: Epoch 8/31 Batch 7000/7662 eta: 1 day, 4:28:43.717345	Training Loss 0.8242 (0.8233)	Training Prec@1 0.000 (0.016)	Training Prec@5 0.195 (0.058)	
2022-03-29 17:38:05,875: ============================================================
2022-03-29 17:39:01,913: time cost, forward:0.2025736913427129, backward:0.04563005347707974, data cost:0.32367035022401897 
2022-03-29 17:39:01,914: ============================================================
2022-03-29 17:39:01,914: Epoch 8/31 Batch 7100/7662 eta: 1 day, 3:31:10.678181	Training Loss 0.8233 (0.8233)	Training Prec@1 0.000 (0.016)	Training Prec@5 0.195 (0.058)	
2022-03-29 17:39:01,914: ============================================================
2022-03-29 17:39:58,317: time cost, forward:0.20253414736139821, backward:0.045576010235218, data cost:0.32364856824227084 
2022-03-29 17:39:58,318: ============================================================
2022-03-29 17:39:58,318: Epoch 8/31 Batch 7200/7662 eta: 1 day, 3:40:59.904177	Training Loss 0.8230 (0.8233)	Training Prec@1 0.195 (0.016)	Training Prec@5 0.195 (0.058)	
2022-03-29 17:39:58,318: ============================================================
2022-03-29 17:40:54,895: time cost, forward:0.2024537369165866, backward:0.045558326259706586, data cost:0.3236601511768028 
2022-03-29 17:40:54,896: ============================================================
2022-03-29 17:40:54,896: Epoch 8/31 Batch 7300/7662 eta: 1 day, 3:45:10.164568	Training Loss 0.8223 (0.8233)	Training Prec@1 0.000 (0.016)	Training Prec@5 0.195 (0.058)	
2022-03-29 17:40:54,896: ============================================================
2022-03-29 17:41:53,635: time cost, forward:0.2025539942054527, backward:0.04554688310217158, data cost:0.323779031414811 
2022-03-29 17:41:53,636: ============================================================
2022-03-29 17:41:53,636: Epoch 8/31 Batch 7400/7662 eta: 1 day, 4:47:49.434117	Training Loss 0.8224 (0.8233)	Training Prec@1 0.000 (0.016)	Training Prec@5 0.000 (0.058)	
2022-03-29 17:41:53,636: ============================================================
2022-03-29 17:42:50,478: time cost, forward:0.20255880795219514, backward:0.04552231185959886, data cost:0.3237484803691294 
2022-03-29 17:42:50,479: ============================================================
2022-03-29 17:42:50,479: Epoch 8/31 Batch 7500/7662 eta: 1 day, 3:51:05.176384	Training Loss 0.8220 (0.8233)	Training Prec@1 0.000 (0.016)	Training Prec@5 0.000 (0.058)	
2022-03-29 17:42:50,479: ============================================================
2022-03-29 17:43:47,904: time cost, forward:0.20249660536872352, backward:0.045496392805398425, data cost:0.323861234422451 
2022-03-29 17:43:47,904: ============================================================
2022-03-29 17:43:47,905: Epoch 8/31 Batch 7600/7662 eta: 1 day, 4:07:15.130819	Training Loss 0.8233 (0.8233)	Training Prec@1 0.000 (0.016)	Training Prec@5 0.000 (0.059)	
2022-03-29 17:43:47,905: ============================================================
2022-03-29 17:44:26,160: Epoch: 8/31 eta: 1 day, 4:06:38.952650	Training Loss 0.8223 (0.8233)	Training Prec@1 0.000 (0.016)	Training Prec@5 0.000 (0.059)
2022-03-29 17:44:26,160: ============================================================
2022-03-29 17:45:24,183: time cost, forward:0.21167707202410457, backward:0.04585889613989628, data cost:0.3244787298067652 
2022-03-29 17:45:24,184: ============================================================
2022-03-29 17:45:24,185: Epoch 9/31 Batch 100/7662 eta: 1 day, 4:21:56.753696	Training Loss 0.8227 (0.8221)	Training Prec@1 0.000 (0.020)	Training Prec@5 0.195 (0.081)	
2022-03-29 17:45:24,185: ============================================================
2022-03-29 17:46:28,040: time cost, forward:0.24471283677834363, backward:0.04784969948044973, data cost:0.3178249795233185 
2022-03-29 17:46:28,066: ============================================================
2022-03-29 17:46:28,067: Epoch 9/31 Batch 200/7662 eta: 1 day, 7:14:09.091748	Training Loss 0.8215 (0.8221)	Training Prec@1 0.000 (0.017)	Training Prec@5 0.000 (0.079)	
2022-03-29 17:46:28,067: ============================================================
2022-03-29 17:47:40,753: time cost, forward:0.28637172147183115, backward:0.04909479099771251, data cost:0.31367388696574844 
2022-03-29 17:47:40,754: ============================================================
2022-03-29 17:47:40,754: Epoch 9/31 Batch 300/7662 eta: 1 day, 11:31:17.743874	Training Loss 0.8230 (0.8222)	Training Prec@1 0.000 (0.022)	Training Prec@5 0.195 (0.083)	
2022-03-29 17:47:40,755: ============================================================
2022-03-29 17:48:46,793: time cost, forward:0.29039773008877173, backward:0.048715341658819286, data cost:0.31265642409934136 
2022-03-29 17:48:46,794: ============================================================
2022-03-29 17:48:46,794: Epoch 9/31 Batch 400/7662 eta: 1 day, 8:15:15.405388	Training Loss 0.8214 (0.8221)	Training Prec@1 0.000 (0.021)	Training Prec@5 0.000 (0.081)	
2022-03-29 17:48:46,794: ============================================================
2022-03-29 17:49:48,776: time cost, forward:0.28340712052308964, backward:0.047596951047022024, data cost:0.3143120777153061 
2022-03-29 17:49:48,777: ============================================================
2022-03-29 17:49:48,777: Epoch 9/31 Batch 500/7662 eta: 1 day, 6:15:21.188665	Training Loss 0.8234 (0.8221)	Training Prec@1 0.000 (0.022)	Training Prec@5 0.000 (0.078)	
2022-03-29 17:49:48,777: ============================================================
2022-03-29 17:50:52,455: time cost, forward:0.28201156745171907, backward:0.047689753502159565, data cost:0.31410411602268634 
2022-03-29 17:50:52,456: ============================================================
2022-03-29 17:50:52,456: Epoch 9/31 Batch 600/7662 eta: 1 day, 7:03:57.829108	Training Loss 0.8215 (0.8221)	Training Prec@1 0.000 (0.022)	Training Prec@5 0.000 (0.075)	
2022-03-29 17:50:52,456: ============================================================
2022-03-29 17:51:53,430: time cost, forward:0.2767472335367926, backward:0.04726086529198293, data cost:0.3148793430628524 
2022-03-29 17:51:53,430: ============================================================
2022-03-29 17:51:53,431: Epoch 9/31 Batch 700/7662 eta: 1 day, 5:43:46.466951	Training Loss 0.8224 (0.8221)	Training Prec@1 0.000 (0.022)	Training Prec@5 0.195 (0.077)	
2022-03-29 17:51:53,431: ============================================================
2022-03-29 17:52:55,299: time cost, forward:0.27209971813445394, backward:0.04689607453137375, data cost:0.31729095629667015 
2022-03-29 17:52:55,300: ============================================================
2022-03-29 17:52:55,300: Epoch 9/31 Batch 800/7662 eta: 1 day, 6:08:55.718959	Training Loss 0.8219 (0.8221)	Training Prec@1 0.000 (0.022)	Training Prec@5 0.000 (0.079)	
2022-03-29 17:52:55,300: ============================================================
2022-03-29 17:53:56,404: time cost, forward:0.2690788795208109, backward:0.04670769274566277, data cost:0.31763306820352827 
2022-03-29 17:53:56,404: ============================================================
2022-03-29 17:53:56,405: Epoch 9/31 Batch 900/7662 eta: 1 day, 5:45:32.424718	Training Loss 0.8226 (0.8221)	Training Prec@1 0.000 (0.022)	Training Prec@5 0.000 (0.079)	
2022-03-29 17:53:56,405: ============================================================
2022-03-29 17:54:56,992: time cost, forward:0.266068997922483, backward:0.04652714896369148, data cost:0.317947929447239 
2022-03-29 17:54:56,993: ============================================================
2022-03-29 17:54:56,993: Epoch 9/31 Batch 1000/7662 eta: 1 day, 5:29:27.640711	Training Loss 0.8229 (0.8221)	Training Prec@1 0.000 (0.022)	Training Prec@5 0.000 (0.079)	
2022-03-29 17:54:56,993: ============================================================
2022-03-29 17:55:58,588: time cost, forward:0.26366911333620385, backward:0.04655539067470561, data cost:0.3190443151316066 
2022-03-29 17:55:58,589: ============================================================
2022-03-29 17:55:58,589: Epoch 9/31 Batch 1100/7662 eta: 1 day, 5:57:50.788014	Training Loss 0.8214 (0.8221)	Training Prec@1 0.000 (0.022)	Training Prec@5 0.000 (0.078)	
2022-03-29 17:55:58,589: ============================================================
2022-03-29 17:56:58,720: time cost, forward:0.2615698487486215, backward:0.04644815418698372, data cost:0.3188926557186149 
2022-03-29 17:56:58,720: ============================================================
2022-03-29 17:56:58,721: Epoch 9/31 Batch 1200/7662 eta: 1 day, 5:14:07.247688	Training Loss 0.8223 (0.8221)	Training Prec@1 0.000 (0.021)	Training Prec@5 0.000 (0.079)	
2022-03-29 17:56:58,722: ============================================================
2022-03-29 17:57:59,457: time cost, forward:0.26008281549919193, backward:0.04634419636509802, data cost:0.31890985817061285 
2022-03-29 17:57:59,457: ============================================================
2022-03-29 17:57:59,458: Epoch 9/31 Batch 1300/7662 eta: 1 day, 5:30:44.896486	Training Loss 0.8223 (0.8221)	Training Prec@1 0.000 (0.022)	Training Prec@5 0.391 (0.081)	
2022-03-29 17:57:59,458: ============================================================
2022-03-29 17:59:00,081: time cost, forward:0.258574354384438, backward:0.04620247333709302, data cost:0.3191696031337299 
2022-03-29 17:59:00,082: ============================================================
2022-03-29 17:59:00,082: Epoch 9/31 Batch 1400/7662 eta: 1 day, 5:26:27.319430	Training Loss 0.8226 (0.8220)	Training Prec@1 0.000 (0.022)	Training Prec@5 0.000 (0.081)	
2022-03-29 17:59:00,082: ============================================================
2022-03-29 18:00:01,585: time cost, forward:0.2569534773823418, backward:0.046151981741846045, data cost:0.32022115085187 
2022-03-29 18:00:01,585: ============================================================
2022-03-29 18:00:01,585: Epoch 9/31 Batch 1500/7662 eta: 1 day, 5:51:03.180010	Training Loss 0.8214 (0.8220)	Training Prec@1 0.000 (0.022)	Training Prec@5 0.000 (0.081)	
2022-03-29 18:00:01,585: ============================================================
2022-03-29 18:01:02,639: time cost, forward:0.25575853795689146, backward:0.04603837906680605, data cost:0.3207158820192243 
2022-03-29 18:01:02,640: ============================================================
2022-03-29 18:01:02,640: Epoch 9/31 Batch 1600/7662 eta: 1 day, 5:36:58.780177	Training Loss 0.8211 (0.8220)	Training Prec@1 0.000 (0.022)	Training Prec@5 0.391 (0.082)	
2022-03-29 18:01:02,641: ============================================================
2022-03-29 18:02:02,981: time cost, forward:0.25453683683070943, backward:0.046063458098601844, data cost:0.32075874604780297 
2022-03-29 18:02:02,981: ============================================================
2022-03-29 18:02:02,982: Epoch 9/31 Batch 1700/7662 eta: 1 day, 5:15:11.583960	Training Loss 0.8219 (0.8220)	Training Prec@1 0.000 (0.023)	Training Prec@5 0.000 (0.084)	
2022-03-29 18:02:02,982: ============================================================
2022-03-29 18:03:05,004: time cost, forward:0.2534062080478721, backward:0.046056966903542336, data cost:0.32178740212491913 
2022-03-29 18:03:05,004: ============================================================
2022-03-29 18:03:05,004: Epoch 9/31 Batch 1800/7662 eta: 1 day, 6:03:04.672737	Training Loss 0.8220 (0.8220)	Training Prec@1 0.000 (0.024)	Training Prec@5 0.000 (0.086)	
2022-03-29 18:03:05,005: ============================================================
2022-03-29 18:04:05,617: time cost, forward:0.252460221606471, backward:0.04612670276213973, data cost:0.32186789623117873 
2022-03-29 18:04:05,617: ============================================================
2022-03-29 18:04:05,618: Epoch 9/31 Batch 1900/7662 eta: 1 day, 5:21:05.156450	Training Loss 0.8219 (0.8220)	Training Prec@1 0.000 (0.024)	Training Prec@5 0.000 (0.087)	
2022-03-29 18:04:05,618: ============================================================
2022-03-29 18:05:07,255: time cost, forward:0.2516035236913959, backward:0.04607783382448213, data cost:0.3225293842895798 
2022-03-29 18:05:07,256: ============================================================
2022-03-29 18:05:07,256: Epoch 9/31 Batch 2000/7662 eta: 1 day, 5:49:50.741950	Training Loss 0.8215 (0.8220)	Training Prec@1 0.000 (0.024)	Training Prec@5 0.000 (0.087)	
2022-03-29 18:05:07,256: ============================================================
2022-03-29 18:06:07,606: time cost, forward:0.2509093596970484, backward:0.04602828327958614, data cost:0.32244285087803537 
2022-03-29 18:06:07,607: ============================================================
2022-03-29 18:06:07,607: Epoch 9/31 Batch 2100/7662 eta: 1 day, 5:11:27.138878	Training Loss 0.8213 (0.8220)	Training Prec@1 0.000 (0.024)	Training Prec@5 0.000 (0.087)	
2022-03-29 18:06:07,607: ============================================================
2022-03-29 18:07:08,243: time cost, forward:0.2501646618021245, backward:0.04593588027589806, data cost:0.3226866483579933 
2022-03-29 18:07:08,244: ============================================================
2022-03-29 18:07:08,244: Epoch 9/31 Batch 2200/7662 eta: 1 day, 5:18:44.589490	Training Loss 0.8214 (0.8220)	Training Prec@1 0.000 (0.024)	Training Prec@5 0.195 (0.087)	
2022-03-29 18:07:08,244: ============================================================
2022-03-29 18:08:08,223: time cost, forward:0.24940831208032024, backward:0.04604160490114827, data cost:0.32250855216880425 
2022-03-29 18:08:08,223: ============================================================
2022-03-29 18:08:08,224: Epoch 9/31 Batch 2300/7662 eta: 1 day, 4:58:41.082479	Training Loss 0.8205 (0.8219)	Training Prec@1 0.000 (0.024)	Training Prec@5 0.195 (0.088)	
2022-03-29 18:08:08,224: ============================================================
2022-03-29 18:09:07,784: time cost, forward:0.24863267123773725, backward:0.04623382684835646, data cost:0.3221307968586472 
2022-03-29 18:09:07,784: ============================================================
2022-03-29 18:09:07,785: Epoch 9/31 Batch 2400/7662 eta: 1 day, 4:45:33.131156	Training Loss 0.8210 (0.8219)	Training Prec@1 0.000 (0.024)	Training Prec@5 0.195 (0.089)	
2022-03-29 18:09:07,785: ============================================================
2022-03-29 18:10:07,433: time cost, forward:0.24782529073793824, backward:0.04622744378589448, data cost:0.32210652873057183 
2022-03-29 18:10:07,434: ============================================================
2022-03-29 18:10:07,435: Epoch 9/31 Batch 2500/7662 eta: 1 day, 4:47:07.876082	Training Loss 0.8221 (0.8219)	Training Prec@1 0.000 (0.024)	Training Prec@5 0.000 (0.089)	
2022-03-29 18:10:07,435: ============================================================
2022-03-29 18:11:06,825: time cost, forward:0.24696365610000123, backward:0.04625659082522068, data cost:0.32207824643550814 
2022-03-29 18:11:06,825: ============================================================
2022-03-29 18:11:06,825: Epoch 9/31 Batch 2600/7662 eta: 1 day, 4:38:37.994885	Training Loss 0.8210 (0.8219)	Training Prec@1 0.000 (0.024)	Training Prec@5 0.195 (0.090)	
2022-03-29 18:11:06,825: ============================================================
2022-03-29 18:12:05,023: time cost, forward:0.24611491351359063, backward:0.046333118119298106, data cost:0.32160076966061335 
2022-03-29 18:12:05,023: ============================================================
2022-03-29 18:12:05,023: Epoch 9/31 Batch 2700/7662 eta: 1 day, 4:03:09.166015	Training Loss 0.8217 (0.8219)	Training Prec@1 0.000 (0.024)	Training Prec@5 0.000 (0.090)	
2022-03-29 18:12:05,023: ============================================================
2022-03-29 18:13:05,619: time cost, forward:0.24549264045816185, backward:0.04637735841443769, data cost:0.3218612184521129 
2022-03-29 18:13:05,620: ============================================================
2022-03-29 18:13:05,620: Epoch 9/31 Batch 2800/7662 eta: 1 day, 5:11:31.447762	Training Loss 0.8212 (0.8219)	Training Prec@1 0.000 (0.024)	Training Prec@5 0.195 (0.090)	
2022-03-29 18:13:05,620: ============================================================
2022-03-29 18:14:05,834: time cost, forward:0.24528437377913898, backward:0.046442846710741954, data cost:0.32158872866556537 
2022-03-29 18:14:05,835: ============================================================
2022-03-29 18:14:05,835: Epoch 9/31 Batch 2900/7662 eta: 1 day, 4:59:29.250442	Training Loss 0.8231 (0.8219)	Training Prec@1 0.000 (0.024)	Training Prec@5 0.195 (0.091)	
2022-03-29 18:14:05,835: ============================================================
2022-03-29 18:15:07,141: time cost, forward:0.24502520467409017, backward:0.046369198124660733, data cost:0.321905212745781 
2022-03-29 18:15:07,141: ============================================================
2022-03-29 18:15:07,142: Epoch 9/31 Batch 3000/7662 eta: 1 day, 5:29:59.032782	Training Loss 0.8213 (0.8218)	Training Prec@1 0.195 (0.025)	Training Prec@5 0.391 (0.092)	
2022-03-29 18:15:07,142: ============================================================
2022-03-29 18:16:08,243: time cost, forward:0.24481450622794934, backward:0.04635571710291737, data cost:0.3220256225029551 
2022-03-29 18:16:08,244: ============================================================
2022-03-29 18:16:08,244: Epoch 9/31 Batch 3100/7662 eta: 1 day, 5:23:04.566827	Training Loss 0.8221 (0.8218)	Training Prec@1 0.000 (0.025)	Training Prec@5 0.000 (0.092)	
2022-03-29 18:16:08,244: ============================================================
2022-03-29 18:17:08,836: time cost, forward:0.24458712658013132, backward:0.04632956737948791, data cost:0.3220467334913067 
2022-03-29 18:17:08,837: ============================================================
2022-03-29 18:17:08,837: Epoch 9/31 Batch 3200/7662 eta: 1 day, 5:07:22.442236	Training Loss 0.8213 (0.8218)	Training Prec@1 0.000 (0.025)	Training Prec@5 0.195 (0.093)	
2022-03-29 18:17:08,837: ============================================================
2022-03-29 18:18:09,771: time cost, forward:0.24422368283487153, backward:0.04625172852096719, data cost:0.32237296792441117 
2022-03-29 18:18:09,771: ============================================================
2022-03-29 18:18:09,772: Epoch 9/31 Batch 3300/7662 eta: 1 day, 5:16:12.606823	Training Loss 0.8209 (0.8218)	Training Prec@1 0.000 (0.025)	Training Prec@5 0.195 (0.094)	
2022-03-29 18:18:09,772: ============================================================
2022-03-29 18:19:09,685: time cost, forward:0.2438674017975491, backward:0.04619913551519113, data cost:0.32237084419035006 
2022-03-29 18:19:09,686: ============================================================
2022-03-29 18:19:09,686: Epoch 9/31 Batch 3400/7662 eta: 1 day, 4:45:48.467524	Training Loss 0.8224 (0.8218)	Training Prec@1 0.000 (0.026)	Training Prec@5 0.000 (0.094)	
2022-03-29 18:19:09,687: ============================================================
2022-03-29 18:20:10,326: time cost, forward:0.2435983449058827, backward:0.046174714550967895, data cost:0.3224682606912129 
2022-03-29 18:20:10,326: ============================================================
2022-03-29 18:20:10,327: Epoch 9/31 Batch 3500/7662 eta: 1 day, 5:05:42.367477	Training Loss 0.8210 (0.8218)	Training Prec@1 0.000 (0.026)	Training Prec@5 0.195 (0.095)	
2022-03-29 18:20:10,327: ============================================================
2022-03-29 18:21:11,227: time cost, forward:0.24340996175184618, backward:0.0461461597033493, data cost:0.32258938338631354 
2022-03-29 18:21:11,228: ============================================================
2022-03-29 18:21:11,228: Epoch 9/31 Batch 3600/7662 eta: 1 day, 5:12:12.060318	Training Loss 0.8220 (0.8218)	Training Prec@1 0.000 (0.026)	Training Prec@5 0.586 (0.096)	
2022-03-29 18:21:11,228: ============================================================
2022-03-29 18:22:11,586: time cost, forward:0.2432504665145812, backward:0.04613584355748515, data cost:0.32251611030498173 
2022-03-29 18:22:11,587: ============================================================
2022-03-29 18:22:11,587: Epoch 9/31 Batch 3700/7662 eta: 1 day, 4:55:36.243998	Training Loss 0.8208 (0.8217)	Training Prec@1 0.000 (0.027)	Training Prec@5 0.000 (0.097)	
2022-03-29 18:22:11,588: ============================================================
2022-03-29 18:23:12,212: time cost, forward:0.24301645899484206, backward:0.04611053771801954, data cost:0.32261441098479543 
2022-03-29 18:23:12,212: ============================================================
2022-03-29 18:23:12,213: Epoch 9/31 Batch 3800/7662 eta: 1 day, 5:02:14.220239	Training Loss 0.8214 (0.8217)	Training Prec@1 0.000 (0.027)	Training Prec@5 0.195 (0.097)	
2022-03-29 18:23:12,213: ============================================================
2022-03-29 18:24:12,801: time cost, forward:0.24282946486325105, backward:0.04609997298785374, data cost:0.3226522900991545 
2022-03-29 18:24:12,802: ============================================================
2022-03-29 18:24:12,802: Epoch 9/31 Batch 3900/7662 eta: 1 day, 5:00:11.570850	Training Loss 0.8222 (0.8217)	Training Prec@1 0.195 (0.027)	Training Prec@5 0.391 (0.097)	
2022-03-29 18:24:12,802: ============================================================
2022-03-29 18:25:12,639: time cost, forward:0.24257066006003453, backward:0.04610078166085024, data cost:0.3225673370046537 
2022-03-29 18:25:12,639: ============================================================
2022-03-29 18:25:12,639: Epoch 9/31 Batch 4000/7662 eta: 1 day, 4:37:36.134602	Training Loss 0.8216 (0.8217)	Training Prec@1 0.000 (0.027)	Training Prec@5 0.000 (0.098)	
2022-03-29 18:25:12,639: ============================================================
2022-03-29 18:26:12,550: time cost, forward:0.2423503969494498, backward:0.04615234985500465, data cost:0.32241692121914756 
2022-03-29 18:26:12,550: ============================================================
2022-03-29 18:26:12,551: Epoch 9/31 Batch 4100/7662 eta: 1 day, 4:38:43.672634	Training Loss 0.8206 (0.8217)	Training Prec@1 0.000 (0.027)	Training Prec@5 0.000 (0.098)	
2022-03-29 18:26:12,551: ============================================================
2022-03-29 18:27:12,373: time cost, forward:0.2422646751117638, backward:0.04611140706761163, data cost:0.32224112307636416 
2022-03-29 18:27:12,374: ============================================================
2022-03-29 18:27:12,374: Epoch 9/31 Batch 4200/7662 eta: 1 day, 4:35:12.990141	Training Loss 0.8207 (0.8217)	Training Prec@1 0.000 (0.027)	Training Prec@5 0.586 (0.099)	
2022-03-29 18:27:12,375: ============================================================
2022-03-29 18:28:12,384: time cost, forward:0.24214797669938898, backward:0.04613287334082764, data cost:0.3220923610775103 
2022-03-29 18:28:12,384: ============================================================
2022-03-29 18:28:12,384: Epoch 9/31 Batch 4300/7662 eta: 1 day, 4:39:33.015160	Training Loss 0.8202 (0.8216)	Training Prec@1 0.000 (0.027)	Training Prec@5 0.000 (0.100)	
2022-03-29 18:28:12,384: ============================================================
2022-03-29 18:29:12,858: time cost, forward:0.24199377279114687, backward:0.046129347221719644, data cost:0.3220821396549552 
2022-03-29 18:29:12,858: ============================================================
2022-03-29 18:29:12,859: Epoch 9/31 Batch 4400/7662 eta: 1 day, 4:51:51.476818	Training Loss 0.8213 (0.8216)	Training Prec@1 0.000 (0.027)	Training Prec@5 0.391 (0.100)	
2022-03-29 18:29:12,859: ============================================================
2022-03-29 18:30:14,489: time cost, forward:0.24184228023122908, backward:0.046099705016726944, data cost:0.32239787645884743 
2022-03-29 18:30:14,489: ============================================================
2022-03-29 18:30:14,490: Epoch 9/31 Batch 4500/7662 eta: 1 day, 5:23:57.031412	Training Loss 0.8198 (0.8216)	Training Prec@1 0.000 (0.027)	Training Prec@5 0.000 (0.100)	
2022-03-29 18:30:14,490: ============================================================
2022-03-29 18:31:14,842: time cost, forward:0.24172166337861162, backward:0.046063329064604974, data cost:0.3223954241388283 
2022-03-29 18:31:14,842: ============================================================
2022-03-29 18:31:14,842: Epoch 9/31 Batch 4600/7662 eta: 1 day, 4:46:21.325053	Training Loss 0.8201 (0.8216)	Training Prec@1 0.000 (0.028)	Training Prec@5 0.000 (0.101)	
2022-03-29 18:31:14,842: ============================================================
2022-03-29 18:32:14,636: time cost, forward:0.24160088744917482, backward:0.046052298766040986, data cost:0.3222699878215282 
2022-03-29 18:32:14,636: ============================================================
2022-03-29 18:32:14,636: Epoch 9/31 Batch 4700/7662 eta: 1 day, 4:29:22.557736	Training Loss 0.8201 (0.8216)	Training Prec@1 0.195 (0.028)	Training Prec@5 0.195 (0.102)	
2022-03-29 18:32:14,636: ============================================================
2022-03-29 18:33:14,926: time cost, forward:0.24145806727495808, backward:0.04604473544250157, data cost:0.3222662545562064 
2022-03-29 18:33:14,926: ============================================================
2022-03-29 18:33:14,926: Epoch 9/31 Batch 4800/7662 eta: 1 day, 4:42:33.795177	Training Loss 0.8200 (0.8216)	Training Prec@1 0.000 (0.028)	Training Prec@5 0.195 (0.102)	
2022-03-29 18:33:14,926: ============================================================
2022-03-29 18:34:15,200: time cost, forward:0.2413881168143558, backward:0.04601759719809699, data cost:0.3222062057270082 
2022-03-29 18:34:15,200: ============================================================
2022-03-29 18:34:15,201: Epoch 9/31 Batch 4900/7662 eta: 1 day, 4:41:05.895649	Training Loss 0.8227 (0.8215)	Training Prec@1 0.000 (0.028)	Training Prec@5 0.000 (0.103)	
2022-03-29 18:34:15,201: ============================================================
2022-03-29 18:35:15,101: time cost, forward:0.2412286107600701, backward:0.046032050724720136, data cost:0.32213443497415306 
2022-03-29 18:35:15,102: ============================================================
2022-03-29 18:35:15,102: Epoch 9/31 Batch 5000/7662 eta: 1 day, 4:29:27.416462	Training Loss 0.8210 (0.8215)	Training Prec@1 0.000 (0.028)	Training Prec@5 0.391 (0.103)	
2022-03-29 18:35:15,102: ============================================================
2022-03-29 18:36:13,795: time cost, forward:0.24095613354677126, backward:0.04600436268051037, data cost:0.3219860349128844 
2022-03-29 18:36:13,795: ============================================================
2022-03-29 18:36:13,795: Epoch 9/31 Batch 5100/7662 eta: 1 day, 3:54:00.007210	Training Loss 0.8218 (0.8215)	Training Prec@1 0.000 (0.028)	Training Prec@5 0.000 (0.103)	
2022-03-29 18:36:13,795: ============================================================
2022-03-29 18:37:12,396: time cost, forward:0.24050435751166382, backward:0.04594561920232052, data cost:0.3220503238972207 
2022-03-29 18:37:12,397: ============================================================
2022-03-29 18:37:12,397: Epoch 9/31 Batch 5200/7662 eta: 1 day, 3:50:24.908989	Training Loss 0.8207 (0.8215)	Training Prec@1 0.195 (0.028)	Training Prec@5 0.195 (0.104)	
2022-03-29 18:37:12,397: ============================================================
2022-03-29 18:38:11,131: time cost, forward:0.24021754365616146, backward:0.04590975210157784, data cost:0.3219609865716638 
2022-03-29 18:38:11,131: ============================================================
2022-03-29 18:38:11,131: Epoch 9/31 Batch 5300/7662 eta: 1 day, 3:53:12.864812	Training Loss 0.8193 (0.8215)	Training Prec@1 0.000 (0.029)	Training Prec@5 0.000 (0.104)	
2022-03-29 18:38:11,132: ============================================================
2022-03-29 18:39:10,259: time cost, forward:0.24006246129414133, backward:0.04594727206349395, data cost:0.32176121483689923 
2022-03-29 18:39:10,260: ============================================================
2022-03-29 18:39:10,260: Epoch 9/31 Batch 5400/7662 eta: 1 day, 4:03:27.656900	Training Loss 0.8199 (0.8215)	Training Prec@1 0.000 (0.029)	Training Prec@5 0.195 (0.105)	
2022-03-29 18:39:10,260: ============================================================
2022-03-29 18:40:08,078: time cost, forward:0.23972048042340374, backward:0.04592838315968948, data cost:0.32158527506071993 
2022-03-29 18:40:08,079: ============================================================
2022-03-29 18:40:08,079: Epoch 9/31 Batch 5500/7662 eta: 1 day, 3:25:12.682809	Training Loss 0.8201 (0.8214)	Training Prec@1 0.000 (0.029)	Training Prec@5 0.000 (0.105)	
2022-03-29 18:40:08,079: ============================================================
2022-03-29 18:41:06,492: time cost, forward:0.23938438219137545, backward:0.04591939291329783, data cost:0.32150352620763384 
2022-03-29 18:41:06,492: ============================================================
2022-03-29 18:41:06,493: Epoch 9/31 Batch 5600/7662 eta: 1 day, 3:41:09.227174	Training Loss 0.8205 (0.8214)	Training Prec@1 0.000 (0.029)	Training Prec@5 0.391 (0.105)	
2022-03-29 18:41:06,493: ============================================================
2022-03-29 18:42:06,213: time cost, forward:0.23916432137530316, backward:0.04592722523607775, data cost:0.3215402204711346 
2022-03-29 18:42:06,214: ============================================================
2022-03-29 18:42:06,214: Epoch 9/31 Batch 5700/7662 eta: 1 day, 4:17:20.621495	Training Loss 0.8206 (0.8214)	Training Prec@1 0.000 (0.029)	Training Prec@5 0.000 (0.107)	
2022-03-29 18:42:06,214: ============================================================
2022-03-29 18:43:04,566: time cost, forward:0.23894786600368478, backward:0.04592037891638569, data cost:0.32135722213293855 
2022-03-29 18:43:04,566: ============================================================
2022-03-29 18:43:04,567: Epoch 9/31 Batch 5800/7662 eta: 1 day, 3:37:29.109934	Training Loss 0.8205 (0.8214)	Training Prec@1 0.000 (0.029)	Training Prec@5 0.000 (0.107)	
2022-03-29 18:43:04,567: ============================================================
2022-03-29 18:44:03,735: time cost, forward:0.2387665996593547, backward:0.045901949071423406, data cost:0.3212828393264592 
2022-03-29 18:44:03,736: ============================================================
2022-03-29 18:44:03,736: Epoch 9/31 Batch 5900/7662 eta: 1 day, 3:59:41.869990	Training Loss 0.8197 (0.8214)	Training Prec@1 0.000 (0.030)	Training Prec@5 0.195 (0.108)	
2022-03-29 18:44:03,737: ============================================================
2022-03-29 18:45:02,497: time cost, forward:0.23860091872166783, backward:0.045866857232362314, data cost:0.3211854979443061 
2022-03-29 18:45:02,497: ============================================================
2022-03-29 18:45:02,498: Epoch 9/31 Batch 6000/7662 eta: 1 day, 3:47:07.545132	Training Loss 0.8194 (0.8213)	Training Prec@1 0.000 (0.030)	Training Prec@5 0.195 (0.108)	
2022-03-29 18:45:02,498: ============================================================
2022-03-29 18:46:00,383: time cost, forward:0.23842041182467186, backward:0.0458732620773403, data cost:0.3209146643333854 
2022-03-29 18:46:00,383: ============================================================
2022-03-29 18:46:00,384: Epoch 9/31 Batch 6100/7662 eta: 1 day, 3:21:19.795392	Training Loss 0.8211 (0.8213)	Training Prec@1 0.000 (0.030)	Training Prec@5 0.195 (0.109)	
2022-03-29 18:46:00,384: ============================================================
2022-03-29 18:46:59,263: time cost, forward:0.2382999728006362, backward:0.04588679125817058, data cost:0.32074874573166207 
2022-03-29 18:46:59,264: ============================================================
2022-03-29 18:46:59,264: Epoch 9/31 Batch 6200/7662 eta: 1 day, 3:48:32.553288	Training Loss 0.8190 (0.8213)	Training Prec@1 0.000 (0.030)	Training Prec@5 0.000 (0.110)	
2022-03-29 18:46:59,264: ============================================================
2022-03-29 18:47:59,831: time cost, forward:0.23816779345288167, backward:0.04588151004583538, data cost:0.32088932197687076 
2022-03-29 18:47:59,831: ============================================================
2022-03-29 18:47:59,832: Epoch 9/31 Batch 6300/7662 eta: 1 day, 4:35:20.420455	Training Loss 0.8213 (0.8213)	Training Prec@1 0.000 (0.030)	Training Prec@5 0.000 (0.111)	
2022-03-29 18:47:59,832: ============================================================
2022-03-29 18:48:58,667: time cost, forward:0.23804541441924423, backward:0.04589526395086833, data cost:0.3207501877023012 
2022-03-29 18:48:58,668: ============================================================
2022-03-29 18:48:58,668: Epoch 9/31 Batch 6400/7662 eta: 1 day, 3:45:20.548189	Training Loss 0.8209 (0.8213)	Training Prec@1 0.000 (0.030)	Training Prec@5 0.391 (0.112)	
2022-03-29 18:48:58,668: ============================================================
2022-03-29 18:49:57,677: time cost, forward:0.23782318785550466, backward:0.04586731145741078, data cost:0.3207603835164446 
2022-03-29 18:49:57,677: ============================================================
2022-03-29 18:49:57,678: Epoch 9/31 Batch 6500/7662 eta: 1 day, 3:49:14.952945	Training Loss 0.8202 (0.8212)	Training Prec@1 0.000 (0.030)	Training Prec@5 0.000 (0.112)	
2022-03-29 18:49:57,678: ============================================================
2022-03-29 18:50:57,988: time cost, forward:0.2377253977308347, backward:0.04588109382193528, data cost:0.3208156038475933 
2022-03-29 18:50:57,989: ============================================================
2022-03-29 18:50:57,989: Epoch 9/31 Batch 6600/7662 eta: 1 day, 4:25:03.903541	Training Loss 0.8199 (0.8212)	Training Prec@1 0.000 (0.031)	Training Prec@5 0.000 (0.113)	
2022-03-29 18:50:57,989: ============================================================
2022-03-29 18:51:54,191: time cost, forward:0.23737609448726898, backward:0.04583651757201146, data cost:0.3205712167589251 
2022-03-29 18:51:54,191: ============================================================
2022-03-29 18:51:54,191: Epoch 9/31 Batch 6700/7662 eta: 1 day, 2:27:58.002915	Training Loss 0.8201 (0.8212)	Training Prec@1 0.195 (0.031)	Training Prec@5 0.195 (0.114)	
2022-03-29 18:51:54,191: ============================================================
2022-03-29 18:52:53,677: time cost, forward:0.23733817813922103, backward:0.045832868708742244, data cost:0.32047226001522366 
2022-03-29 18:52:53,677: ============================================================
2022-03-29 18:52:53,678: Epoch 9/31 Batch 6800/7662 eta: 1 day, 3:59:46.053440	Training Loss 0.8207 (0.8212)	Training Prec@1 0.195 (0.031)	Training Prec@5 0.195 (0.114)	
2022-03-29 18:52:53,678: ============================================================
2022-03-29 18:53:50,913: time cost, forward:0.23716548090828452, backward:0.045814158450280223, data cost:0.3202053086103469 
2022-03-29 18:53:50,914: ============================================================
2022-03-29 18:53:50,914: Epoch 9/31 Batch 6900/7662 eta: 1 day, 2:55:17.365546	Training Loss 0.8194 (0.8212)	Training Prec@1 0.195 (0.031)	Training Prec@5 0.391 (0.115)	
2022-03-29 18:53:50,915: ============================================================
2022-03-29 18:54:47,927: time cost, forward:0.23681603807911802, backward:0.04577328464204472, data cost:0.3201068848401312 
2022-03-29 18:54:47,927: ============================================================
2022-03-29 18:54:47,928: Epoch 9/31 Batch 7000/7662 eta: 1 day, 2:48:02.191625	Training Loss 0.8197 (0.8211)	Training Prec@1 0.000 (0.031)	Training Prec@5 0.195 (0.116)	
2022-03-29 18:54:47,928: ============================================================
2022-03-29 18:55:47,589: time cost, forward:0.23678557300822872, backward:0.0457581098792687, data cost:0.3200718734881998 
2022-03-29 18:55:47,589: ============================================================
2022-03-29 18:55:47,589: Epoch 9/31 Batch 7100/7662 eta: 1 day, 4:01:43.353853	Training Loss 0.8205 (0.8211)	Training Prec@1 0.000 (0.031)	Training Prec@5 0.195 (0.117)	
2022-03-29 18:55:47,589: ============================================================
2022-03-29 18:56:45,640: time cost, forward:0.23669593114623727, backward:0.04575112164393119, data cost:0.31985658780620035 
2022-03-29 18:56:45,640: ============================================================
2022-03-29 18:56:45,641: Epoch 9/31 Batch 7200/7662 eta: 1 day, 3:15:22.806971	Training Loss 0.8179 (0.8211)	Training Prec@1 0.391 (0.032)	Training Prec@5 0.391 (0.118)	
2022-03-29 18:56:45,641: ============================================================
2022-03-29 18:57:44,272: time cost, forward:0.23653988120228905, backward:0.045715759022298914, data cost:0.31982515040840703 
2022-03-29 18:57:44,272: ============================================================
2022-03-29 18:57:44,272: Epoch 9/31 Batch 7300/7662 eta: 1 day, 3:30:44.307953	Training Loss 0.8184 (0.8211)	Training Prec@1 0.000 (0.032)	Training Prec@5 0.195 (0.118)	
2022-03-29 18:57:44,272: ============================================================
2022-03-29 18:58:42,831: time cost, forward:0.23639106624818265, backward:0.0457065647752692, data cost:0.31975707851208324 
2022-03-29 18:58:42,831: ============================================================
2022-03-29 18:58:42,831: Epoch 9/31 Batch 7400/7662 eta: 1 day, 3:27:44.031684	Training Loss 0.8202 (0.8211)	Training Prec@1 0.000 (0.032)	Training Prec@5 0.391 (0.119)	
2022-03-29 18:58:42,832: ============================================================
2022-03-29 18:59:42,189: time cost, forward:0.2363895973152662, backward:0.0457037808275458, data cost:0.31963943646643733 
2022-03-29 18:59:42,190: ============================================================
2022-03-29 18:59:42,190: Epoch 9/31 Batch 7500/7662 eta: 1 day, 3:49:13.540340	Training Loss 0.8203 (0.8210)	Training Prec@1 0.000 (0.032)	Training Prec@5 0.195 (0.119)	
2022-03-29 18:59:42,190: ============================================================
2022-03-29 19:00:42,669: time cost, forward:0.2364911725606114, backward:0.04572237785089359, data cost:0.3195541285577456 
2022-03-29 19:00:42,670: ============================================================
2022-03-29 19:00:42,670: Epoch 9/31 Batch 7600/7662 eta: 1 day, 4:19:45.653052	Training Loss 0.8188 (0.8210)	Training Prec@1 0.195 (0.032)	Training Prec@5 0.391 (0.120)	
2022-03-29 19:00:42,670: ============================================================
2022-03-29 19:01:20,273: Epoch: 9/31 eta: 1 day, 4:19:07.550636	Training Loss 0.8187 (0.8210)	Training Prec@1 0.000 (0.032)	Training Prec@5 0.000 (0.120)
2022-03-29 19:01:20,273: ============================================================
2022-03-29 19:02:14,648: time cost, forward:0.20917081832885742, backward:0.0409953160719438, data cost:0.29322212874287307 
2022-03-29 19:02:14,648: ============================================================
2022-03-29 19:02:14,649: Epoch 10/31 Batch 100/7662 eta: 1 day, 1:19:23.668369	Training Loss 0.8192 (0.8188)	Training Prec@1 0.000 (0.067)	Training Prec@5 0.000 (0.183)	
2022-03-29 19:02:14,649: ============================================================
2022-03-29 19:03:15,157: time cost, forward:0.23511182123692193, backward:0.04420452022073257, data cost:0.2948287395975698 
2022-03-29 19:03:15,157: ============================================================
2022-03-29 19:03:15,158: Epoch 10/31 Batch 200/7662 eta: 1 day, 4:17:56.074295	Training Loss 0.8173 (0.8188)	Training Prec@1 0.000 (0.057)	Training Prec@5 0.195 (0.185)	
2022-03-29 19:03:15,158: ============================================================
2022-03-29 19:04:14,884: time cost, forward:0.2507264638026821, backward:0.04470888986236674, data cost:0.2862706144517879 
2022-03-29 19:04:14,884: ============================================================
2022-03-29 19:04:14,884: Epoch 10/31 Batch 300/7662 eta: 1 day, 3:54:59.228552	Training Loss 0.8175 (0.8187)	Training Prec@1 0.000 (0.057)	Training Prec@5 0.195 (0.192)	
2022-03-29 19:04:14,884: ============================================================
2022-03-29 19:05:12,059: time cost, forward:0.2484627660354576, backward:0.04469840329392512, data cost:0.2859438433683008 
2022-03-29 19:05:12,060: ============================================================
2022-03-29 19:05:12,061: Epoch 10/31 Batch 400/7662 eta: 1 day, 2:42:30.766341	Training Loss 0.8180 (0.8187)	Training Prec@1 0.000 (0.055)	Training Prec@5 0.000 (0.192)	
2022-03-29 19:05:12,061: ============================================================
2022-03-29 19:06:11,030: time cost, forward:0.25040415102589825, backward:0.04563778101322885, data cost:0.28522900445666727 
2022-03-29 19:06:11,031: ============================================================
2022-03-29 19:06:11,032: Epoch 10/31 Batch 500/7662 eta: 1 day, 3:31:49.256058	Training Loss 0.8181 (0.8187)	Training Prec@1 0.000 (0.054)	Training Prec@5 0.195 (0.192)	
2022-03-29 19:06:11,032: ============================================================
2022-03-29 19:07:04,800: time cost, forward:0.24357225779499952, backward:0.045112764696047976, data cost:0.28500592171250283 
2022-03-29 19:07:04,800: ============================================================
2022-03-29 19:07:04,800: Epoch 10/31 Batch 600/7662 eta: 1 day, 1:05:12.378911	Training Loss 0.8205 (0.8188)	Training Prec@1 0.000 (0.052)	Training Prec@5 0.000 (0.193)	
2022-03-29 19:07:04,800: ============================================================
2022-03-29 19:08:03,063: time cost, forward:0.24441201969959875, backward:0.045209889759833206, data cost:0.2854640330367845 
2022-03-29 19:08:03,064: ============================================================
2022-03-29 19:08:03,064: Epoch 10/31 Batch 700/7662 eta: 1 day, 3:10:04.528512	Training Loss 0.8189 (0.8188)	Training Prec@1 0.000 (0.053)	Training Prec@5 0.000 (0.192)	
2022-03-29 19:08:03,064: ============================================================
2022-03-29 19:09:00,189: time cost, forward:0.24224023616060297, backward:0.04542555588207794, data cost:0.2867041171268468 
2022-03-29 19:09:00,189: ============================================================
2022-03-29 19:09:00,190: Epoch 10/31 Batch 800/7662 eta: 1 day, 2:37:16.710209	Training Loss 0.8191 (0.8188)	Training Prec@1 0.000 (0.054)	Training Prec@5 0.391 (0.194)	
2022-03-29 19:09:00,190: ============================================================
2022-03-29 19:09:57,857: time cost, forward:0.24169484288063942, backward:0.04564758614783027, data cost:0.28729111731914314 
2022-03-29 19:09:57,857: ============================================================
2022-03-29 19:09:57,857: Epoch 10/31 Batch 900/7662 eta: 1 day, 2:51:28.668816	Training Loss 0.8186 (0.8188)	Training Prec@1 0.000 (0.052)	Training Prec@5 0.000 (0.192)	
2022-03-29 19:09:57,857: ============================================================
2022-03-29 19:10:51,490: time cost, forward:0.238215065813876, backward:0.04543565844630336, data cost:0.2870820554288419 
2022-03-29 19:10:51,490: ============================================================
2022-03-29 19:10:51,491: Epoch 10/31 Batch 1000/7662 eta: 1 day, 0:57:50.441101	Training Loss 0.8183 (0.8188)	Training Prec@1 0.000 (0.051)	Training Prec@5 0.000 (0.190)	
2022-03-29 19:10:51,491: ============================================================
2022-03-29 19:11:46,859: time cost, forward:0.23483122750994723, backward:0.045528503848380454, data cost:0.28875495500191434 
2022-03-29 19:11:46,859: ============================================================
2022-03-29 19:11:46,875: Epoch 10/31 Batch 1100/7662 eta: 1 day, 1:45:49.338347	Training Loss 0.8182 (0.8188)	Training Prec@1 0.000 (0.053)	Training Prec@5 0.000 (0.195)	
2022-03-29 19:11:46,875: ============================================================
2022-03-29 19:12:42,239: time cost, forward:0.2327627101672302, backward:0.045655204217766004, data cost:0.28934731734007774 
2022-03-29 19:12:42,240: ============================================================
2022-03-29 19:12:42,240: Epoch 10/31 Batch 1200/7662 eta: 1 day, 1:44:22.222430	Training Loss 0.8201 (0.8188)	Training Prec@1 0.000 (0.053)	Training Prec@5 0.195 (0.196)	
2022-03-29 19:12:42,240: ============================================================
2022-03-29 19:13:36,247: time cost, forward:0.22951957278292026, backward:0.04554583569321841, data cost:0.2901944875533623 
2022-03-29 19:13:36,248: ============================================================
2022-03-29 19:13:36,248: Epoch 10/31 Batch 1300/7662 eta: 1 day, 1:05:36.372158	Training Loss 0.8203 (0.8188)	Training Prec@1 0.000 (0.052)	Training Prec@5 0.000 (0.196)	
2022-03-29 19:13:36,249: ============================================================
2022-03-29 19:14:31,762: time cost, forward:0.22808736882267722, backward:0.0455449218831802, data cost:0.29118722536633745 
2022-03-29 19:14:31,763: ============================================================
2022-03-29 19:14:31,763: Epoch 10/31 Batch 1400/7662 eta: 1 day, 1:46:41.466193	Training Loss 0.8183 (0.8188)	Training Prec@1 0.000 (0.054)	Training Prec@5 0.195 (0.197)	
2022-03-29 19:14:31,763: ============================================================
2022-03-29 19:15:26,943: time cost, forward:0.22706761194754632, backward:0.04543082772929959, data cost:0.2914086639920897 
2022-03-29 19:15:26,944: ============================================================
2022-03-29 19:15:26,945: Epoch 10/31 Batch 1500/7662 eta: 1 day, 1:36:28.843453	Training Loss 0.8184 (0.8187)	Training Prec@1 0.000 (0.054)	Training Prec@5 0.195 (0.197)	
2022-03-29 19:15:26,945: ============================================================
2022-03-29 19:16:21,107: time cost, forward:0.2251343952260068, backward:0.04528330265543772, data cost:0.29209346678795256 
2022-03-29 19:16:21,107: ============================================================
2022-03-29 19:16:21,107: Epoch 10/31 Batch 1600/7662 eta: 1 day, 1:07:12.798924	Training Loss 0.8185 (0.8187)	Training Prec@1 0.195 (0.054)	Training Prec@5 0.391 (0.196)	
2022-03-29 19:16:21,107: ============================================================
2022-03-29 19:17:15,135: time cost, forward:0.22321226528071178, backward:0.04509701695141896, data cost:0.2928712435369284 
2022-03-29 19:17:15,136: ============================================================
2022-03-29 19:17:15,137: Epoch 10/31 Batch 1700/7662 eta: 1 day, 1:02:36.022434	Training Loss 0.8190 (0.8187)	Training Prec@1 0.391 (0.054)	Training Prec@5 0.586 (0.197)	
2022-03-29 19:17:15,137: ============================================================
2022-03-29 19:18:08,417: time cost, forward:0.22176152921637407, backward:0.04492416124730855, data cost:0.29288447970082326 
2022-03-29 19:18:08,417: ============================================================
2022-03-29 19:18:08,418: Epoch 10/31 Batch 1800/7662 eta: 1 day, 0:40:54.232437	Training Loss 0.8183 (0.8187)	Training Prec@1 0.000 (0.054)	Training Prec@5 0.000 (0.197)	
2022-03-29 19:18:08,418: ============================================================
2022-03-29 19:19:03,506: time cost, forward:0.22089401341037038, backward:0.04492728430199083, data cost:0.29324196312790357 
2022-03-29 19:19:03,507: ============================================================
2022-03-29 19:19:03,507: Epoch 10/31 Batch 1900/7662 eta: 1 day, 1:30:14.317065	Training Loss 0.8186 (0.8187)	Training Prec@1 0.000 (0.054)	Training Prec@5 0.000 (0.199)	
2022-03-29 19:19:03,507: ============================================================
2022-03-29 19:19:57,865: time cost, forward:0.21979170360822806, backward:0.044835293871453546, data cost:0.29370109017578705 
2022-03-29 19:19:57,865: ============================================================
2022-03-29 19:19:57,866: Epoch 10/31 Batch 2000/7662 eta: 1 day, 1:09:02.686265	Training Loss 0.8200 (0.8187)	Training Prec@1 0.000 (0.054)	Training Prec@5 0.195 (0.200)	
2022-03-29 19:19:57,866: ============================================================
2022-03-29 19:20:51,769: time cost, forward:0.21860058152033865, backward:0.04481337716773671, data cost:0.2938214351359636 
2022-03-29 19:20:51,770: ============================================================
2022-03-29 19:20:51,770: Epoch 10/31 Batch 2100/7662 eta: 1 day, 0:55:32.034258	Training Loss 0.8180 (0.8187)	Training Prec@1 0.195 (0.055)	Training Prec@5 0.781 (0.201)	
2022-03-29 19:20:51,770: ============================================================
2022-03-29 19:21:44,250: time cost, forward:0.21662245635934285, backward:0.044652365402180046, data cost:0.29457933710834666 
2022-03-29 19:21:44,251: ============================================================
2022-03-29 19:21:44,251: Epoch 10/31 Batch 2200/7662 eta: 1 day, 0:15:10.343587	Training Loss 0.8193 (0.8187)	Training Prec@1 0.195 (0.054)	Training Prec@5 0.195 (0.201)	
2022-03-29 19:21:44,251: ============================================================
2022-03-29 19:22:38,862: time cost, forward:0.21586672748467775, backward:0.04455281600271841, data cost:0.2950043616060487 
2022-03-29 19:22:38,862: ============================================================
2022-03-29 19:22:38,862: Epoch 10/31 Batch 2300/7662 eta: 1 day, 1:13:19.041487	Training Loss 0.8180 (0.8187)	Training Prec@1 0.000 (0.055)	Training Prec@5 0.195 (0.201)	
2022-03-29 19:22:38,863: ============================================================
2022-03-29 19:23:33,442: time cost, forward:0.21548587682595993, backward:0.04454647933209424, data cost:0.29497507891589375 
2022-03-29 19:23:33,443: ============================================================
2022-03-29 19:23:33,443: Epoch 10/31 Batch 2400/7662 eta: 1 day, 1:11:34.131346	Training Loss 0.8180 (0.8187)	Training Prec@1 0.000 (0.055)	Training Prec@5 0.391 (0.201)	
2022-03-29 19:23:33,443: ============================================================
2022-03-29 19:24:28,626: time cost, forward:0.21503028968850724, backward:0.04453095744828693, data cost:0.2952977187540971 
2022-03-29 19:24:28,627: ============================================================
2022-03-29 19:24:28,627: Epoch 10/31 Batch 2500/7662 eta: 1 day, 1:27:21.019409	Training Loss 0.8199 (0.8187)	Training Prec@1 0.000 (0.055)	Training Prec@5 0.000 (0.200)	
2022-03-29 19:24:28,627: ============================================================
2022-03-29 19:25:23,318: time cost, forward:0.2143715599400578, backward:0.04456179799736349, data cost:0.29561107687970317 
2022-03-29 19:25:23,329: ============================================================
2022-03-29 19:25:23,329: Epoch 10/31 Batch 2600/7662 eta: 1 day, 1:13:06.755805	Training Loss 0.8176 (0.8187)	Training Prec@1 0.000 (0.055)	Training Prec@5 0.195 (0.199)	
2022-03-29 19:25:23,329: ============================================================
2022-03-29 19:26:17,304: time cost, forward:0.21358816523868182, backward:0.04448068464363271, data cost:0.29591847552595957 
2022-03-29 19:26:17,304: ============================================================
2022-03-29 19:26:17,304: Epoch 10/31 Batch 2700/7662 eta: 1 day, 0:52:05.939277	Training Loss 0.8171 (0.8187)	Training Prec@1 0.000 (0.055)	Training Prec@5 0.000 (0.199)	
2022-03-29 19:26:17,305: ============================================================
2022-03-29 19:27:12,288: time cost, forward:0.21305649116150863, backward:0.04455155089481595, data cost:0.29621087052473727 
2022-03-29 19:27:12,289: ============================================================
2022-03-29 19:27:12,289: Epoch 10/31 Batch 2800/7662 eta: 1 day, 1:19:05.649528	Training Loss 0.8189 (0.8187)	Training Prec@1 0.000 (0.055)	Training Prec@5 0.000 (0.199)	
2022-03-29 19:27:12,290: ============================================================
2022-03-29 19:28:07,675: time cost, forward:0.21263234316788693, backward:0.044513167739531304, data cost:0.2966665617964851 
2022-03-29 19:28:07,676: ============================================================
2022-03-29 19:28:07,676: Epoch 10/31 Batch 2900/7662 eta: 1 day, 1:29:15.984598	Training Loss 0.8185 (0.8187)	Training Prec@1 0.000 (0.055)	Training Prec@5 0.195 (0.199)	
2022-03-29 19:28:07,676: ============================================================
2022-03-29 19:29:02,790: time cost, forward:0.21203863608833154, backward:0.044479441030616164, data cost:0.297189510596041 
2022-03-29 19:29:02,791: ============================================================
2022-03-29 19:29:02,791: Epoch 10/31 Batch 3000/7662 eta: 1 day, 1:20:51.259503	Training Loss 0.8169 (0.8187)	Training Prec@1 0.000 (0.055)	Training Prec@5 0.000 (0.200)	
2022-03-29 19:29:02,791: ============================================================
2022-03-29 19:29:56,897: time cost, forward:0.21125689357586466, backward:0.04442867004859828, data cost:0.29760934230241903 
2022-03-29 19:29:56,897: ============================================================
2022-03-29 19:29:56,897: Epoch 10/31 Batch 3100/7662 eta: 1 day, 0:52:07.139001	Training Loss 0.8199 (0.8187)	Training Prec@1 0.000 (0.055)	Training Prec@5 0.000 (0.201)	
2022-03-29 19:29:56,897: ============================================================
2022-03-29 19:30:49,417: time cost, forward:0.21076602256085658, backward:0.04444704826416988, data cost:0.29717820210172147 
2022-03-29 19:30:49,417: ============================================================
2022-03-29 19:30:49,418: Epoch 10/31 Batch 3200/7662 eta: 1 day, 0:07:29.961729	Training Loss 0.8187 (0.8187)	Training Prec@1 0.195 (0.055)	Training Prec@5 0.195 (0.202)	
2022-03-29 19:30:49,418: ============================================================
2022-03-29 19:31:45,917: time cost, forward:0.2104300624423043, backward:0.044419152406390126, data cost:0.29791210383565253 
2022-03-29 19:31:45,918: ============================================================
2022-03-29 19:31:45,919: Epoch 10/31 Batch 3300/7662 eta: 1 day, 1:56:16.557993	Training Loss 0.8189 (0.8187)	Training Prec@1 0.000 (0.055)	Training Prec@5 0.195 (0.201)	
2022-03-29 19:31:45,919: ============================================================
2022-03-29 19:32:38,137: time cost, forward:0.20962445895157691, backward:0.0444118384579835, data cost:0.29782596073560275 
2022-03-29 19:32:38,138: ============================================================
2022-03-29 19:32:38,138: Epoch 10/31 Batch 3400/7662 eta: 23:57:27.919477	Training Loss 0.8202 (0.8187)	Training Prec@1 0.195 (0.055)	Training Prec@5 0.586 (0.202)	
2022-03-29 19:32:38,138: ============================================================
2022-03-29 19:33:32,600: time cost, forward:0.20945801609548442, backward:0.04441336394378409, data cost:0.29776084371960887 
2022-03-29 19:33:32,601: ============================================================
2022-03-29 19:33:32,601: Epoch 10/31 Batch 3500/7662 eta: 1 day, 0:58:20.139319	Training Loss 0.8185 (0.8187)	Training Prec@1 0.000 (0.055)	Training Prec@5 0.000 (0.202)	
2022-03-29 19:33:32,602: ============================================================
2022-03-29 19:34:27,601: time cost, forward:0.20924649002751433, backward:0.044462537792001246, data cost:0.2978624525782995 
2022-03-29 19:34:27,604: ============================================================
2022-03-29 19:34:27,605: Epoch 10/31 Batch 3600/7662 eta: 1 day, 1:12:15.522390	Training Loss 0.8184 (0.8187)	Training Prec@1 0.000 (0.055)	Training Prec@5 0.195 (0.201)	
2022-03-29 19:34:27,605: ============================================================
2022-03-29 19:35:23,857: time cost, forward:0.2092383525345125, backward:0.044433853051958294, data cost:0.29805196520765914 
2022-03-29 19:35:23,858: ============================================================
2022-03-29 19:35:23,859: Epoch 10/31 Batch 3700/7662 eta: 1 day, 1:45:43.430198	Training Loss 0.8173 (0.8187)	Training Prec@1 0.000 (0.055)	Training Prec@5 0.391 (0.202)	
2022-03-29 19:35:23,859: ============================================================
2022-03-29 19:36:18,815: time cost, forward:0.2092546259424943, backward:0.04442845566958683, data cost:0.2981047227402115 
2022-03-29 19:36:18,816: ============================================================
2022-03-29 19:36:18,816: Epoch 10/31 Batch 3800/7662 eta: 1 day, 1:09:10.693417	Training Loss 0.8190 (0.8187)	Training Prec@1 0.195 (0.055)	Training Prec@5 0.195 (0.202)	
2022-03-29 19:36:18,816: ============================================================
2022-03-29 19:37:14,057: time cost, forward:0.20925466639471532, backward:0.0444106628235012, data cost:0.2981320991061167 
2022-03-29 19:37:14,057: ============================================================
2022-03-29 19:37:14,058: Epoch 10/31 Batch 3900/7662 eta: 1 day, 1:16:03.374982	Training Loss 0.8187 (0.8187)	Training Prec@1 0.000 (0.055)	Training Prec@5 0.391 (0.202)	
2022-03-29 19:37:14,058: ============================================================
2022-03-29 19:38:07,459: time cost, forward:0.2087198998159574, backward:0.04435960189435863, data cost:0.29825390860807244 
2022-03-29 19:38:07,460: ============================================================
2022-03-29 19:38:07,460: Epoch 10/31 Batch 4000/7662 eta: 1 day, 0:24:41.778078	Training Loss 0.8184 (0.8187)	Training Prec@1 0.000 (0.055)	Training Prec@5 0.195 (0.202)	
2022-03-29 19:38:07,460: ============================================================
2022-03-29 19:39:03,055: time cost, forward:0.208687810962972, backward:0.0443950896438781, data cost:0.29835486563277497 
2022-03-29 19:39:03,056: ============================================================
2022-03-29 19:39:03,056: Epoch 10/31 Batch 4100/7662 eta: 1 day, 1:23:56.390694	Training Loss 0.8187 (0.8187)	Training Prec@1 0.000 (0.055)	Training Prec@5 0.000 (0.203)	
2022-03-29 19:39:03,056: ============================================================
2022-03-29 19:39:56,630: time cost, forward:0.2083473479813069, backward:0.04435612565422376, data cost:0.2983540719280529 
2022-03-29 19:39:56,631: ============================================================
2022-03-29 19:39:56,631: Epoch 10/31 Batch 4200/7662 eta: 1 day, 0:27:38.549612	Training Loss 0.8174 (0.8187)	Training Prec@1 0.000 (0.055)	Training Prec@5 0.000 (0.202)	
2022-03-29 19:39:56,631: ============================================================
2022-03-29 19:40:52,169: time cost, forward:0.20834445099299329, backward:0.04442488245976251, data cost:0.29838158857492436 
2022-03-29 19:40:52,170: ============================================================
2022-03-29 19:40:52,170: Epoch 10/31 Batch 4300/7662 eta: 1 day, 1:20:30.890108	Training Loss 0.8170 (0.8187)	Training Prec@1 0.000 (0.054)	Training Prec@5 0.391 (0.202)	
2022-03-29 19:40:52,170: ============================================================
2022-03-29 19:41:45,513: time cost, forward:0.20808316572440377, backward:0.044412754643746576, data cost:0.29823646233227613 
2022-03-29 19:41:45,522: ============================================================
2022-03-29 19:41:45,523: Epoch 10/31 Batch 4400/7662 eta: 1 day, 0:19:46.348006	Training Loss 0.8155 (0.8187)	Training Prec@1 0.391 (0.054)	Training Prec@5 0.586 (0.202)	
2022-03-29 19:41:45,523: ============================================================
2022-03-29 19:42:41,578: time cost, forward:0.20818548383753044, backward:0.0444148345692048, data cost:0.2983396148172901 
2022-03-29 19:42:41,578: ============================================================
2022-03-29 19:42:41,578: Epoch 10/31 Batch 4500/7662 eta: 1 day, 1:32:47.769445	Training Loss 0.8181 (0.8186)	Training Prec@1 0.000 (0.055)	Training Prec@5 0.000 (0.202)	
2022-03-29 19:42:41,579: ============================================================
2022-03-29 19:43:35,328: time cost, forward:0.20789078806607353, backward:0.04435127147982291, data cost:0.2983991617118568 
2022-03-29 19:43:35,329: ============================================================
2022-03-29 19:43:35,330: Epoch 10/31 Batch 4600/7662 eta: 1 day, 0:28:52.850877	Training Loss 0.8182 (0.8186)	Training Prec@1 0.000 (0.054)	Training Prec@5 0.195 (0.202)	
2022-03-29 19:43:35,330: ============================================================
2022-03-29 19:44:28,701: time cost, forward:0.20762424297499185, backward:0.04433611312504143, data cost:0.2983143564538008 
2022-03-29 19:44:28,702: ============================================================
2022-03-29 19:44:28,702: Epoch 10/31 Batch 4700/7662 eta: 1 day, 0:17:39.003696	Training Loss 0.8185 (0.8186)	Training Prec@1 0.000 (0.055)	Training Prec@5 0.195 (0.203)	
2022-03-29 19:44:28,702: ============================================================
2022-03-29 19:45:24,422: time cost, forward:0.20762789902723836, backward:0.044372180025387266, data cost:0.2984055733526714 
2022-03-29 19:45:24,423: ============================================================
2022-03-29 19:45:24,423: Epoch 10/31 Batch 4800/7662 eta: 1 day, 1:20:51.269900	Training Loss 0.8181 (0.8186)	Training Prec@1 0.000 (0.055)	Training Prec@5 0.195 (0.203)	
2022-03-29 19:45:24,423: ============================================================
2022-03-29 19:46:19,727: time cost, forward:0.20766439294785863, backward:0.04441501179819911, data cost:0.29837373865699496 
2022-03-29 19:46:19,727: ============================================================
2022-03-29 19:46:19,728: Epoch 10/31 Batch 4900/7662 eta: 1 day, 1:08:34.315343	Training Loss 0.8177 (0.8186)	Training Prec@1 0.000 (0.055)	Training Prec@5 0.195 (0.203)	
2022-03-29 19:46:19,728: ============================================================
2022-03-29 19:47:13,897: time cost, forward:0.20762624008986064, backward:0.044417569627283, data cost:0.2982225306488605 
2022-03-29 19:47:13,898: ============================================================
2022-03-29 19:47:13,898: Epoch 10/31 Batch 5000/7662 eta: 1 day, 0:36:43.985800	Training Loss 0.8194 (0.8186)	Training Prec@1 0.000 (0.055)	Training Prec@5 0.781 (0.204)	
2022-03-29 19:47:13,898: ============================================================
2022-03-29 19:48:08,348: time cost, forward:0.20744746295721725, backward:0.04445811023102435, data cost:0.2982396690909548 
2022-03-29 19:48:08,348: ============================================================
2022-03-29 19:48:08,348: Epoch 10/31 Batch 5100/7662 eta: 1 day, 0:43:27.096339	Training Loss 0.8187 (0.8186)	Training Prec@1 0.195 (0.055)	Training Prec@5 0.195 (0.203)	
2022-03-29 19:48:08,349: ============================================================
2022-03-29 19:49:02,327: time cost, forward:0.20729115605927542, backward:0.0443961807433677, data cost:0.2982532143890915 
2022-03-29 19:49:02,327: ============================================================
2022-03-29 19:49:02,328: Epoch 10/31 Batch 5200/7662 eta: 1 day, 0:29:43.475111	Training Loss 0.8184 (0.8186)	Training Prec@1 0.195 (0.056)	Training Prec@5 0.195 (0.204)	
2022-03-29 19:49:02,328: ============================================================
2022-03-29 19:49:57,697: time cost, forward:0.20747476817302196, backward:0.04438499221938537, data cost:0.2981390112142424 
2022-03-29 19:49:57,697: ============================================================
2022-03-29 19:49:57,697: Epoch 10/31 Batch 5300/7662 eta: 1 day, 1:06:38.871580	Training Loss 0.8192 (0.8186)	Training Prec@1 0.391 (0.056)	Training Prec@5 0.586 (0.204)	
2022-03-29 19:49:57,697: ============================================================
2022-03-29 19:50:52,662: time cost, forward:0.20735480242646342, backward:0.04437352193905526, data cost:0.2982581810810805 
2022-03-29 19:50:52,662: ============================================================
2022-03-29 19:50:52,662: Epoch 10/31 Batch 5400/7662 eta: 1 day, 0:54:43.634719	Training Loss 0.8189 (0.8186)	Training Prec@1 0.195 (0.056)	Training Prec@5 0.195 (0.204)	
2022-03-29 19:50:52,662: ============================================================
2022-03-29 19:51:44,206: time cost, forward:0.20676222491814975, backward:0.044331529179927026, data cost:0.2982581721411811 
2022-03-29 19:51:44,207: ============================================================
2022-03-29 19:51:44,208: Epoch 10/31 Batch 5500/7662 eta: 23:20:52.319741	Training Loss 0.8190 (0.8186)	Training Prec@1 0.000 (0.056)	Training Prec@5 0.586 (0.204)	
2022-03-29 19:51:44,208: ============================================================
2022-03-29 19:52:40,574: time cost, forward:0.20675525530722977, backward:0.0443451783980274, data cost:0.2984915006201189 
2022-03-29 19:52:40,575: ============================================================
2022-03-29 19:52:40,576: Epoch 10/31 Batch 5600/7662 eta: 1 day, 1:31:00.355252	Training Loss 0.8183 (0.8186)	Training Prec@1 0.000 (0.056)	Training Prec@5 0.195 (0.204)	
2022-03-29 19:52:40,576: ============================================================
2022-03-29 19:53:33,374: time cost, forward:0.20642061835110115, backward:0.04428829379532709, data cost:0.29850425521916185 
2022-03-29 19:53:33,374: ============================================================
2022-03-29 19:53:33,375: Epoch 10/31 Batch 5700/7662 eta: 23:53:11.018778	Training Loss 0.8192 (0.8186)	Training Prec@1 0.000 (0.056)	Training Prec@5 0.000 (0.204)	
2022-03-29 19:53:33,375: ============================================================
2022-03-29 19:54:25,832: time cost, forward:0.20607907037361672, backward:0.04424683590103047, data cost:0.298454368169975 
2022-03-29 19:54:25,833: ============================================================
2022-03-29 19:54:25,833: Epoch 10/31 Batch 5800/7662 eta: 23:43:04.386273	Training Loss 0.8183 (0.8186)	Training Prec@1 0.391 (0.057)	Training Prec@5 0.781 (0.204)	
2022-03-29 19:54:25,834: ============================================================
2022-03-29 19:55:21,084: time cost, forward:0.20612130287967106, backward:0.04425513992917439, data cost:0.2983787089692352 
2022-03-29 19:55:21,085: ============================================================
2022-03-29 19:55:21,086: Epoch 10/31 Batch 5900/7662 eta: 1 day, 0:57:55.998705	Training Loss 0.8174 (0.8186)	Training Prec@1 0.195 (0.056)	Training Prec@5 0.391 (0.204)	
2022-03-29 19:55:21,086: ============================================================
2022-03-29 19:56:13,387: time cost, forward:0.2059591163852092, backward:0.044225294165937956, data cost:0.29821538956965343 
2022-03-29 19:56:13,387: ============================================================
2022-03-29 19:56:13,388: Epoch 10/31 Batch 6000/7662 eta: 23:37:04.913036	Training Loss 0.8181 (0.8186)	Training Prec@1 0.000 (0.056)	Training Prec@5 0.195 (0.204)	
2022-03-29 19:56:13,388: ============================================================
2022-03-29 19:57:08,802: time cost, forward:0.20588456761506682, backward:0.04420436466496623, data cost:0.2984039087259568 
2022-03-29 19:57:08,802: ============================================================
2022-03-29 19:57:08,803: Epoch 10/31 Batch 6100/7662 eta: 1 day, 1:00:30.110224	Training Loss 0.8182 (0.8186)	Training Prec@1 0.000 (0.057)	Training Prec@5 0.195 (0.204)	
2022-03-29 19:57:08,803: ============================================================
2022-03-29 19:58:00,520: time cost, forward:0.20551829988830683, backward:0.04414490258084091, data cost:0.29831099667882205 
2022-03-29 19:58:00,521: ============================================================
2022-03-29 19:58:00,521: Epoch 10/31 Batch 6200/7662 eta: 23:19:32.188796	Training Loss 0.8186 (0.8186)	Training Prec@1 0.000 (0.057)	Training Prec@5 0.000 (0.204)	
2022-03-29 19:58:00,521: ============================================================
2022-03-29 19:58:54,970: time cost, forward:0.2055548162455785, backward:0.04415063022299217, data cost:0.2981980063079141 
2022-03-29 19:58:54,971: ============================================================
2022-03-29 19:58:54,971: Epoch 10/31 Batch 6300/7662 eta: 1 day, 0:32:33.778486	Training Loss 0.8175 (0.8186)	Training Prec@1 0.000 (0.057)	Training Prec@5 0.000 (0.205)	
2022-03-29 19:58:54,972: ============================================================
2022-03-29 19:59:48,337: time cost, forward:0.20558062589323173, backward:0.04410313468255891, data cost:0.2979979970004712 
2022-03-29 19:59:48,338: ============================================================
2022-03-29 19:59:48,338: Epoch 10/31 Batch 6400/7662 eta: 1 day, 0:02:21.766006	Training Loss 0.8208 (0.8186)	Training Prec@1 0.000 (0.057)	Training Prec@5 0.000 (0.205)	
2022-03-29 19:59:48,338: ============================================================
2022-03-29 20:00:41,970: time cost, forward:0.2056048158903015, backward:0.044105086515162206, data cost:0.29779204931198994 
2022-03-29 20:00:41,970: ============================================================
2022-03-29 20:00:41,971: Epoch 10/31 Batch 6500/7662 eta: 1 day, 0:08:40.072060	Training Loss 0.8186 (0.8186)	Training Prec@1 0.000 (0.057)	Training Prec@5 0.195 (0.205)	
2022-03-29 20:00:41,971: ============================================================
2022-03-29 20:01:35,824: time cost, forward:0.20542211394578078, backward:0.04410405241371845, data cost:0.2978364969315105 
2022-03-29 20:01:35,824: ============================================================
2022-03-29 20:01:35,825: Epoch 10/31 Batch 6600/7662 eta: 1 day, 0:13:44.588771	Training Loss 0.8200 (0.8186)	Training Prec@1 0.000 (0.057)	Training Prec@5 0.195 (0.205)	
2022-03-29 20:01:35,825: ============================================================
2022-03-29 20:02:29,679: time cost, forward:0.20535074712483095, backward:0.044074568824637096, data cost:0.29779905314800686 
2022-03-29 20:02:29,680: ============================================================
2022-03-29 20:02:29,680: Epoch 10/31 Batch 6700/7662 eta: 1 day, 0:12:53.269495	Training Loss 0.8178 (0.8186)	Training Prec@1 0.000 (0.057)	Training Prec@5 0.391 (0.205)	
2022-03-29 20:02:29,680: ============================================================
2022-03-29 20:03:24,591: time cost, forward:0.20543095700476763, backward:0.04407950712838827, data cost:0.2977324159447981 
2022-03-29 20:03:24,592: ============================================================
2022-03-29 20:03:24,592: Epoch 10/31 Batch 6800/7662 eta: 1 day, 0:40:28.722988	Training Loss 0.8190 (0.8186)	Training Prec@1 0.000 (0.057)	Training Prec@5 0.195 (0.205)	
2022-03-29 20:03:24,593: ============================================================
2022-03-29 20:04:17,875: time cost, forward:0.20538363948838056, backward:0.044074059673142894, data cost:0.29757126121697935 
2022-03-29 20:04:17,876: ============================================================
2022-03-29 20:04:17,876: Epoch 10/31 Batch 6900/7662 eta: 23:55:40.847292	Training Loss 0.8187 (0.8186)	Training Prec@1 0.195 (0.057)	Training Prec@5 0.391 (0.205)	
2022-03-29 20:04:17,876: ============================================================
2022-03-29 20:05:12,561: time cost, forward:0.2054413289815328, backward:0.044049661182338704, data cost:0.2975291141971109 
2022-03-29 20:05:12,562: ============================================================
2022-03-29 20:05:12,562: Epoch 10/31 Batch 7000/7662 eta: 1 day, 0:32:34.081672	Training Loss 0.8174 (0.8186)	Training Prec@1 0.000 (0.057)	Training Prec@5 0.000 (0.205)	
2022-03-29 20:05:12,563: ============================================================
2022-03-29 20:06:06,014: time cost, forward:0.2053735584990376, backward:0.04402711821670414, data cost:0.297439207643132 
2022-03-29 20:06:06,015: ============================================================
2022-03-29 20:06:06,016: Epoch 10/31 Batch 7100/7662 eta: 23:58:27.916203	Training Loss 0.8183 (0.8186)	Training Prec@1 0.000 (0.057)	Training Prec@5 0.000 (0.206)	
2022-03-29 20:06:06,016: ============================================================
2022-03-29 20:07:01,445: time cost, forward:0.205374875587297, backward:0.04403499411715287, data cost:0.29752466082158957 
2022-03-29 20:07:01,445: ============================================================
2022-03-29 20:07:01,446: Epoch 10/31 Batch 7200/7662 eta: 1 day, 0:50:44.768111	Training Loss 0.8198 (0.8186)	Training Prec@1 0.391 (0.057)	Training Prec@5 0.391 (0.206)	
2022-03-29 20:07:01,446: ============================================================
2022-03-29 20:07:55,380: time cost, forward:0.20541149120589514, backward:0.04405735260591979, data cost:0.29735358654105315 
2022-03-29 20:07:55,381: ============================================================
2022-03-29 20:07:55,381: Epoch 10/31 Batch 7300/7662 eta: 1 day, 0:09:38.779412	Training Loss 0.8172 (0.8186)	Training Prec@1 0.391 (0.057)	Training Prec@5 0.391 (0.207)	
2022-03-29 20:07:55,381: ============================================================
2022-03-29 20:08:50,396: time cost, forward:0.20547519259911032, backward:0.04404515784436713, data cost:0.2973387383467314 
2022-03-29 20:08:50,397: ============================================================
2022-03-29 20:08:50,397: Epoch 10/31 Batch 7400/7662 eta: 1 day, 0:37:47.148558	Training Loss 0.8176 (0.8186)	Training Prec@1 0.000 (0.058)	Training Prec@5 0.195 (0.207)	
2022-03-29 20:08:50,397: ============================================================
2022-03-29 20:09:46,451: time cost, forward:0.20551512152024118, backward:0.044038077293515034, data cost:0.2974815172487171 
2022-03-29 20:09:46,451: ============================================================
2022-03-29 20:09:46,451: Epoch 10/31 Batch 7500/7662 eta: 1 day, 1:04:43.850343	Training Loss 0.8189 (0.8186)	Training Prec@1 0.000 (0.058)	Training Prec@5 0.000 (0.208)	
2022-03-29 20:09:46,452: ============================================================
2022-03-29 20:10:42,018: time cost, forward:0.20553894961628574, backward:0.04403676831701866, data cost:0.29756566994691275 
2022-03-29 20:10:42,018: ============================================================
2022-03-29 20:10:42,018: Epoch 10/31 Batch 7600/7662 eta: 1 day, 0:50:43.443667	Training Loss 0.8178 (0.8186)	Training Prec@1 0.195 (0.058)	Training Prec@5 0.195 (0.208)	
2022-03-29 20:10:42,019: ============================================================
2022-03-29 20:11:18,182: Epoch: 10/31 eta: 1 day, 0:50:08.436449	Training Loss 0.8182 (0.8186)	Training Prec@1 0.000 (0.058)	Training Prec@5 0.195 (0.208)
2022-03-29 20:11:18,183: ============================================================
2022-03-29 20:11:18,185: Save Checkpoint...
2022-03-29 20:11:18,186: ============================================================
2022-03-29 20:11:20,395: Save done!
2022-03-29 20:11:20,395: ============================================================
2022-03-29 20:12:12,190: time cost, forward:0.18860830441869872, backward:0.04201147532222247, data cost:0.2890495868644329 
2022-03-29 20:12:12,190: ============================================================
2022-03-29 20:12:12,191: Epoch 11/31 Batch 100/7662 eta: 23:07:38.108533	Training Loss 0.8180 (0.8182)	Training Prec@1 0.000 (0.079)	Training Prec@5 0.000 (0.241)	
2022-03-29 20:12:12,191: ============================================================
2022-03-29 20:13:06,138: time cost, forward:0.19580914746576816, backward:0.04282434861264636, data cost:0.2903273524950497 
2022-03-29 20:13:06,139: ============================================================
2022-03-29 20:13:06,139: Epoch 11/31 Batch 200/7662 eta: 1 day, 0:04:56.781960	Training Loss 0.8192 (0.8183)	Training Prec@1 0.000 (0.073)	Training Prec@5 0.195 (0.241)	
2022-03-29 20:13:06,139: ============================================================
2022-03-29 20:14:02,622: time cost, forward:0.20157225315387434, backward:0.04345429701151258, data cost:0.29604445811498126 
2022-03-29 20:14:02,623: ============================================================
2022-03-29 20:14:02,623: Epoch 11/31 Batch 300/7662 eta: 1 day, 1:11:54.740771	Training Loss 0.8172 (0.8183)	Training Prec@1 0.000 (0.067)	Training Prec@5 0.000 (0.241)	
2022-03-29 20:14:02,623: ============================================================
2022-03-29 20:14:57,403: time cost, forward:0.20416007304848885, backward:0.04357446763748513, data cost:0.2946042357232039 
2022-03-29 20:14:57,403: ============================================================
2022-03-29 20:14:57,404: Epoch 11/31 Batch 400/7662 eta: 1 day, 0:25:24.524517	Training Loss 0.8177 (0.8182)	Training Prec@1 0.000 (0.067)	Training Prec@5 0.195 (0.236)	
2022-03-29 20:14:57,404: ============================================================
2022-03-29 20:15:52,178: time cost, forward:0.20356705575763342, backward:0.04399501297899143, data cost:0.29567487206392157 
2022-03-29 20:15:52,179: ============================================================
2022-03-29 20:15:52,179: Epoch 11/31 Batch 500/7662 eta: 1 day, 0:24:21.277276	Training Loss 0.8184 (0.8182)	Training Prec@1 0.000 (0.061)	Training Prec@5 0.000 (0.231)	
2022-03-29 20:15:52,179: ============================================================
2022-03-29 20:16:45,056: time cost, forward:0.20168251147453295, backward:0.043998406208019224, data cost:0.2950002339129058 
2022-03-29 20:16:45,058: ============================================================
2022-03-29 20:16:45,058: Epoch 11/31 Batch 600/7662 eta: 23:32:46.833493	Training Loss 0.8194 (0.8182)	Training Prec@1 0.000 (0.061)	Training Prec@5 0.000 (0.229)	
2022-03-29 20:16:45,059: ============================================================
2022-03-29 20:17:39,510: time cost, forward:0.2029578273047364, backward:0.04400099330023464, data cost:0.2942458856770921 
2022-03-29 20:17:39,510: ============================================================
2022-03-29 20:17:39,510: Epoch 11/31 Batch 700/7662 eta: 1 day, 0:13:54.359989	Training Loss 0.8188 (0.8182)	Training Prec@1 0.195 (0.065)	Training Prec@5 0.195 (0.234)	
2022-03-29 20:17:39,510: ============================================================
2022-03-29 20:18:33,721: time cost, forward:0.20316524410128445, backward:0.044140013645826204, data cost:0.29395836435062567 
2022-03-29 20:18:33,733: ============================================================
2022-03-29 20:18:33,734: Epoch 11/31 Batch 800/7662 eta: 1 day, 0:06:52.888723	Training Loss 0.8195 (0.8182)	Training Prec@1 0.000 (0.066)	Training Prec@5 0.195 (0.234)	
2022-03-29 20:18:33,734: ============================================================
2022-03-29 20:19:27,225: time cost, forward:0.20223498768748113, backward:0.043994934593344956, data cost:0.29426608944893945 
2022-03-29 20:19:27,225: ============================================================
2022-03-29 20:19:27,226: Epoch 11/31 Batch 900/7662 eta: 23:46:28.724052	Training Loss 0.8170 (0.8182)	Training Prec@1 0.000 (0.066)	Training Prec@5 0.000 (0.231)	
2022-03-29 20:19:27,226: ============================================================
2022-03-29 20:20:20,529: time cost, forward:0.20202426533321957, backward:0.04377383679837674, data cost:0.2938930828411419 
2022-03-29 20:20:20,529: ============================================================
2022-03-29 20:20:20,530: Epoch 11/31 Batch 1000/7662 eta: 23:40:34.959160	Training Loss 0.8166 (0.8182)	Training Prec@1 0.000 (0.065)	Training Prec@5 0.000 (0.228)	
2022-03-29 20:20:20,530: ============================================================
2022-03-29 20:21:13,699: time cost, forward:0.20123705351970975, backward:0.04373423070447677, data cost:0.2939350405424915 
2022-03-29 20:21:13,710: ============================================================
2022-03-29 20:21:13,711: Epoch 11/31 Batch 1100/7662 eta: 23:36:24.804846	Training Loss 0.8187 (0.8182)	Training Prec@1 0.000 (0.063)	Training Prec@5 0.391 (0.226)	
2022-03-29 20:21:13,711: ============================================================
2022-03-29 20:22:06,511: time cost, forward:0.2001405951378244, backward:0.043756388146445786, data cost:0.2940156435946607 
2022-03-29 20:22:06,512: ============================================================
2022-03-29 20:22:06,513: Epoch 11/31 Batch 1200/7662 eta: 23:25:26.367472	Training Loss 0.8172 (0.8182)	Training Prec@1 0.000 (0.064)	Training Prec@5 0.977 (0.226)	
2022-03-29 20:22:06,513: ============================================================
2022-03-29 20:22:59,343: time cost, forward:0.19896591746687797, backward:0.04361466741084685, data cost:0.29455114090048046 
2022-03-29 20:22:59,344: ============================================================
2022-03-29 20:22:59,344: Epoch 11/31 Batch 1300/7662 eta: 23:25:20.886583	Training Loss 0.8186 (0.8182)	Training Prec@1 0.000 (0.065)	Training Prec@5 0.000 (0.226)	
2022-03-29 20:22:59,345: ============================================================
2022-03-29 20:23:53,511: time cost, forward:0.1989064761960055, backward:0.04364296945186067, data cost:0.29486853450941475 
2022-03-29 20:23:53,521: ============================================================
2022-03-29 20:23:53,522: Epoch 11/31 Batch 1400/7662 eta: 1 day, 0:00:14.590290	Training Loss 0.8181 (0.8182)	Training Prec@1 0.195 (0.064)	Training Prec@5 0.391 (0.224)	
2022-03-29 20:23:53,522: ============================================================
2022-03-29 20:24:45,976: time cost, forward:0.19782016609731398, backward:0.043536021122541166, data cost:0.2951725741240722 
2022-03-29 20:24:45,976: ============================================================
2022-03-29 20:24:45,976: Epoch 11/31 Batch 1500/7662 eta: 23:13:34.201250	Training Loss 0.8186 (0.8182)	Training Prec@1 0.000 (0.063)	Training Prec@5 0.195 (0.224)	
2022-03-29 20:24:45,977: ============================================================
2022-03-29 20:25:39,744: time cost, forward:0.19689693787904589, backward:0.04334333138289938, data cost:0.29632293067178256 
2022-03-29 20:25:39,756: ============================================================
2022-03-29 20:25:39,756: Epoch 11/31 Batch 1600/7662 eta: 23:47:52.805830	Training Loss 0.8182 (0.8182)	Training Prec@1 0.000 (0.063)	Training Prec@5 0.391 (0.224)	
2022-03-29 20:25:39,756: ============================================================
2022-03-29 20:26:33,505: time cost, forward:0.1972497460981058, backward:0.043393829277222684, data cost:0.2959334590703056 
2022-03-29 20:26:33,519: ============================================================
2022-03-29 20:26:33,519: Epoch 11/31 Batch 1700/7662 eta: 23:46:31.965398	Training Loss 0.8180 (0.8182)	Training Prec@1 0.000 (0.063)	Training Prec@5 0.195 (0.224)	
2022-03-29 20:26:33,519: ============================================================
2022-03-29 20:27:27,237: time cost, forward:0.19712327002418778, backward:0.043434143994105, data cost:0.29605024241287886 
2022-03-29 20:27:27,237: ============================================================
2022-03-29 20:27:27,238: Epoch 11/31 Batch 1800/7662 eta: 23:44:28.170883	Training Loss 0.8181 (0.8182)	Training Prec@1 0.000 (0.064)	Training Prec@5 0.000 (0.225)	
2022-03-29 20:27:27,238: ============================================================
2022-03-29 20:28:20,225: time cost, forward:0.1961411794528891, backward:0.04329332732852978, data cost:0.2967838387290951 
2022-03-29 20:28:20,226: ============================================================
2022-03-29 20:28:20,227: Epoch 11/31 Batch 1900/7662 eta: 23:24:13.939065	Training Loss 0.8198 (0.8182)	Training Prec@1 0.195 (0.063)	Training Prec@5 0.781 (0.225)	
2022-03-29 20:28:20,227: ============================================================
2022-03-29 20:29:13,180: time cost, forward:0.19555277965139187, backward:0.04313942502295154, data cost:0.297155431176854 
2022-03-29 20:29:13,180: ============================================================
2022-03-29 20:29:13,181: Epoch 11/31 Batch 2000/7662 eta: 23:22:25.562429	Training Loss 0.8186 (0.8182)	Training Prec@1 0.391 (0.065)	Training Prec@5 0.391 (0.225)	
2022-03-29 20:29:13,181: ============================================================
2022-03-29 20:30:05,157: time cost, forward:0.19470846704098654, backward:0.0430214493657476, data cost:0.2973286578517803 
2022-03-29 20:30:05,158: ============================================================
2022-03-29 20:30:05,158: Epoch 11/31 Batch 2100/7662 eta: 22:55:41.351073	Training Loss 0.8200 (0.8182)	Training Prec@1 0.195 (0.065)	Training Prec@5 0.195 (0.223)	
2022-03-29 20:30:05,158: ============================================================
2022-03-29 20:30:58,895: time cost, forward:0.19467227553280445, backward:0.04310629247480655, data cost:0.29733135603730815 
2022-03-29 20:30:58,895: ============================================================
2022-03-29 20:30:58,895: Epoch 11/31 Batch 2200/7662 eta: 23:41:23.109306	Training Loss 0.8181 (0.8182)	Training Prec@1 0.000 (0.065)	Training Prec@5 0.195 (0.224)	
2022-03-29 20:30:58,896: ============================================================
2022-03-29 20:31:50,478: time cost, forward:0.19384818390277533, backward:0.04303863412559214, data cost:0.2974010823653438 
2022-03-29 20:31:50,478: ============================================================
2022-03-29 20:31:50,479: Epoch 11/31 Batch 2300/7662 eta: 22:43:32.441781	Training Loss 0.8180 (0.8182)	Training Prec@1 0.000 (0.064)	Training Prec@5 0.000 (0.223)	
2022-03-29 20:31:50,479: ============================================================
2022-03-29 20:32:45,312: time cost, forward:0.193643309564181, backward:0.04339608056886139, data cost:0.29774026326111525 
2022-03-29 20:32:45,313: ============================================================
2022-03-29 20:32:45,313: Epoch 11/31 Batch 2400/7662 eta: 1 day, 0:08:33.965246	Training Loss 0.8189 (0.8182)	Training Prec@1 0.195 (0.065)	Training Prec@5 0.195 (0.223)	
2022-03-29 20:32:45,313: ============================================================
2022-03-29 20:33:38,576: time cost, forward:0.19352738291514116, backward:0.04363473800240922, data cost:0.2975405592496703 
2022-03-29 20:33:38,577: ============================================================
2022-03-29 20:33:38,577: Epoch 11/31 Batch 2500/7662 eta: 23:26:12.222108	Training Loss 0.8164 (0.8182)	Training Prec@1 0.195 (0.064)	Training Prec@5 0.195 (0.223)	
2022-03-29 20:33:38,577: ============================================================
2022-03-29 20:34:32,863: time cost, forward:0.19330081172794872, backward:0.04373218014222835, data cost:0.29793193781545596 
2022-03-29 20:34:32,863: ============================================================
2022-03-29 20:34:32,864: Epoch 11/31 Batch 2600/7662 eta: 23:52:17.160701	Training Loss 0.8171 (0.8182)	Training Prec@1 0.000 (0.063)	Training Prec@5 0.000 (0.222)	
2022-03-29 20:34:32,864: ============================================================
2022-03-29 20:35:25,478: time cost, forward:0.1926567205547094, backward:0.04372120839924934, data cost:0.298275253604014 
2022-03-29 20:35:25,479: ============================================================
2022-03-29 20:35:25,479: Epoch 11/31 Batch 2700/7662 eta: 23:07:19.116865	Training Loss 0.8173 (0.8182)	Training Prec@1 0.195 (0.063)	Training Prec@5 0.391 (0.223)	
2022-03-29 20:35:25,479: ============================================================
2022-03-29 20:36:16,599: time cost, forward:0.19212328736038453, backward:0.04364622231252111, data cost:0.2980275254626068 
2022-03-29 20:36:16,599: ============================================================
2022-03-29 20:36:16,599: Epoch 11/31 Batch 2800/7662 eta: 22:27:02.704248	Training Loss 0.8189 (0.8182)	Training Prec@1 0.195 (0.063)	Training Prec@5 0.781 (0.224)	
2022-03-29 20:36:16,600: ============================================================
2022-03-29 20:37:09,385: time cost, forward:0.1915805331589066, backward:0.04358525932472548, data cost:0.2984017291205552 
2022-03-29 20:37:09,395: ============================================================
2022-03-29 20:37:09,395: Epoch 11/31 Batch 2900/7662 eta: 23:10:19.139196	Training Loss 0.8196 (0.8182)	Training Prec@1 0.000 (0.063)	Training Prec@5 0.000 (0.224)	
2022-03-29 20:37:09,395: ============================================================
2022-03-29 20:38:03,445: time cost, forward:0.19174582173562757, backward:0.04360857698352148, data cost:0.29841252723190137 
2022-03-29 20:38:03,445: ============================================================
2022-03-29 20:38:03,446: Epoch 11/31 Batch 3000/7662 eta: 23:42:27.133495	Training Loss 0.8173 (0.8182)	Training Prec@1 0.391 (0.063)	Training Prec@5 0.781 (0.224)	
2022-03-29 20:38:03,446: ============================================================
2022-03-29 20:38:57,572: time cost, forward:0.19195064616687993, backward:0.043589668452412744, data cost:0.29845644266769245 
2022-03-29 20:38:57,573: ============================================================
2022-03-29 20:38:57,573: Epoch 11/31 Batch 3100/7662 eta: 23:43:34.540880	Training Loss 0.8183 (0.8182)	Training Prec@1 0.195 (0.064)	Training Prec@5 0.391 (0.225)	
2022-03-29 20:38:57,573: ============================================================
2022-03-29 20:39:49,884: time cost, forward:0.1918567145902986, backward:0.043536702034137294, data cost:0.2982630350322193 
2022-03-29 20:39:49,885: ============================================================
2022-03-29 20:39:49,885: Epoch 11/31 Batch 3200/7662 eta: 22:54:57.486635	Training Loss 0.8188 (0.8182)	Training Prec@1 0.195 (0.063)	Training Prec@5 0.391 (0.224)	
2022-03-29 20:39:49,885: ============================================================
2022-03-29 20:40:42,994: time cost, forward:0.1915066318824169, backward:0.04359364458993552, data cost:0.29845546360773256 
2022-03-29 20:40:42,995: ============================================================
2022-03-29 20:40:42,996: Epoch 11/31 Batch 3300/7662 eta: 23:15:04.039818	Training Loss 0.8175 (0.8182)	Training Prec@1 0.000 (0.063)	Training Prec@5 0.195 (0.224)	
2022-03-29 20:40:42,996: ============================================================
2022-03-29 20:41:37,101: time cost, forward:0.1916956087181448, backward:0.043637458911254916, data cost:0.29842602305287436 
2022-03-29 20:41:37,115: ============================================================
2022-03-29 20:41:37,115: Epoch 11/31 Batch 3400/7662 eta: 23:40:40.124358	Training Loss 0.8184 (0.8182)	Training Prec@1 0.195 (0.063)	Training Prec@5 0.195 (0.224)	
2022-03-29 20:41:37,115: ============================================================
2022-03-29 20:42:30,984: time cost, forward:0.191730372324505, backward:0.04363485335213486, data cost:0.29852128069753064 
2022-03-29 20:42:30,985: ============================================================
2022-03-29 20:42:30,985: Epoch 11/31 Batch 3500/7662 eta: 23:33:12.930621	Training Loss 0.8174 (0.8182)	Training Prec@1 0.000 (0.063)	Training Prec@5 0.000 (0.224)	
2022-03-29 20:42:30,986: ============================================================
2022-03-29 20:43:24,989: time cost, forward:0.19216766116287218, backward:0.04370286359360365, data cost:0.2981690566849132 
2022-03-29 20:43:24,990: ============================================================
2022-03-29 20:43:24,990: Epoch 11/31 Batch 3600/7662 eta: 23:35:51.487205	Training Loss 0.8183 (0.8182)	Training Prec@1 0.000 (0.063)	Training Prec@5 0.391 (0.224)	
2022-03-29 20:43:24,991: ============================================================
2022-03-29 20:44:17,166: time cost, forward:0.19203335293308083, backward:0.04362165086750856, data cost:0.29801729280389816 
2022-03-29 20:44:17,167: ============================================================
2022-03-29 20:44:17,167: Epoch 11/31 Batch 3700/7662 eta: 22:47:03.653090	Training Loss 0.8183 (0.8182)	Training Prec@1 0.000 (0.063)	Training Prec@5 0.000 (0.224)	
2022-03-29 20:44:17,167: ============================================================
2022-03-29 20:45:09,569: time cost, forward:0.1922692867227842, backward:0.04362028484188842, data cost:0.29753970773510635 
2022-03-29 20:45:09,580: ============================================================
2022-03-29 20:45:09,580: Epoch 11/31 Batch 3800/7662 eta: 22:52:22.123625	Training Loss 0.8205 (0.8182)	Training Prec@1 0.000 (0.063)	Training Prec@5 0.195 (0.223)	
2022-03-29 20:45:09,580: ============================================================
2022-03-29 20:46:01,810: time cost, forward:0.1922834593383249, backward:0.04360791443861212, data cost:0.2972441402023405 
2022-03-29 20:46:01,819: ============================================================
2022-03-29 20:46:01,819: Epoch 11/31 Batch 3900/7662 eta: 22:46:56.789064	Training Loss 0.8178 (0.8182)	Training Prec@1 0.000 (0.063)	Training Prec@5 0.000 (0.223)	
2022-03-29 20:46:01,819: ============================================================
2022-03-29 20:46:56,526: time cost, forward:0.19250211270936401, backward:0.043632726247205114, data cost:0.29733387659000854 
2022-03-29 20:46:56,537: ============================================================
2022-03-29 20:46:56,537: Epoch 11/31 Batch 4000/7662 eta: 23:50:53.938786	Training Loss 0.8191 (0.8182)	Training Prec@1 0.000 (0.063)	Training Prec@5 0.391 (0.223)	
2022-03-29 20:46:56,537: ============================================================
2022-03-29 20:47:50,729: time cost, forward:0.19269112081869721, backward:0.04380911261490363, data cost:0.29716227519334776 
2022-03-29 20:47:50,730: ============================================================
2022-03-29 20:47:50,731: Epoch 11/31 Batch 4100/7662 eta: 23:36:17.166587	Training Loss 0.8187 (0.8182)	Training Prec@1 0.000 (0.064)	Training Prec@5 0.000 (0.224)	
2022-03-29 20:47:50,731: ============================================================
2022-03-29 20:48:45,657: time cost, forward:0.19277666029006874, backward:0.043835364798472935, data cost:0.2974132322419056 
2022-03-29 20:48:45,658: ============================================================
2022-03-29 20:48:45,658: Epoch 11/31 Batch 4200/7662 eta: 23:54:33.337733	Training Loss 0.8192 (0.8182)	Training Prec@1 0.000 (0.064)	Training Prec@5 0.000 (0.224)	
2022-03-29 20:48:45,658: ============================================================
2022-03-29 20:49:36,236: time cost, forward:0.1923759470542771, backward:0.04378887497288983, data cost:0.29719529891740615 
2022-03-29 20:49:36,250: ============================================================
2022-03-29 20:49:36,250: Epoch 11/31 Batch 4300/7662 eta: 22:00:28.181678	Training Loss 0.8188 (0.8182)	Training Prec@1 0.000 (0.064)	Training Prec@5 0.000 (0.225)	
2022-03-29 20:49:36,250: ============================================================
2022-03-29 20:50:29,605: time cost, forward:0.1924860080173542, backward:0.04378976543319851, data cost:0.29706699107283485 
2022-03-29 20:50:29,606: ============================================================
2022-03-29 20:50:29,606: Epoch 11/31 Batch 4400/7662 eta: 23:11:43.755149	Training Loss 0.8180 (0.8182)	Training Prec@1 0.000 (0.065)	Training Prec@5 0.000 (0.225)	
2022-03-29 20:50:29,606: ============================================================
2022-03-29 20:51:23,607: time cost, forward:0.1926097944064203, backward:0.04378352670781902, data cost:0.2970964752798426 
2022-03-29 20:51:23,622: ============================================================
2022-03-29 20:51:23,623: Epoch 11/31 Batch 4500/7662 eta: 23:28:03.867995	Training Loss 0.8183 (0.8182)	Training Prec@1 0.000 (0.065)	Training Prec@5 0.195 (0.225)	
2022-03-29 20:51:23,623: ============================================================
2022-03-29 20:52:15,158: time cost, forward:0.19238865160377006, backward:0.04372867990457693, data cost:0.2969721341864081 
2022-03-29 20:52:15,158: ============================================================
2022-03-29 20:52:15,159: Epoch 11/31 Batch 4600/7662 eta: 22:22:32.408755	Training Loss 0.8173 (0.8181)	Training Prec@1 0.000 (0.065)	Training Prec@5 0.000 (0.225)	
2022-03-29 20:52:15,159: ============================================================
2022-03-29 20:53:08,860: time cost, forward:0.1923678747819672, backward:0.04371079385826044, data cost:0.29707726455034156 
2022-03-29 20:53:08,861: ============================================================
2022-03-29 20:53:08,861: Epoch 11/31 Batch 4700/7662 eta: 23:18:04.388896	Training Loss 0.8179 (0.8181)	Training Prec@1 0.000 (0.065)	Training Prec@5 0.000 (0.225)	
2022-03-29 20:53:08,861: ============================================================
2022-03-29 20:54:01,536: time cost, forward:0.19214655762291075, backward:0.04364942555428545, data cost:0.2972258429498468 
2022-03-29 20:54:01,536: ============================================================
2022-03-29 20:54:01,537: Epoch 11/31 Batch 4800/7662 eta: 22:50:28.266385	Training Loss 0.8183 (0.8181)	Training Prec@1 0.000 (0.065)	Training Prec@5 0.000 (0.226)	
2022-03-29 20:54:01,537: ============================================================
2022-03-29 20:54:56,109: time cost, forward:0.19233383269036491, backward:0.043704042339305485, data cost:0.29723249033631827 
2022-03-29 20:54:56,110: ============================================================
2022-03-29 20:54:56,110: Epoch 11/31 Batch 4900/7662 eta: 23:38:55.854840	Training Loss 0.8185 (0.8181)	Training Prec@1 0.000 (0.065)	Training Prec@5 0.195 (0.226)	
2022-03-29 20:54:56,110: ============================================================
2022-03-29 20:55:50,933: time cost, forward:0.1924054111855391, backward:0.043710261398516886, data cost:0.29744635936998803 
2022-03-29 20:55:50,934: ============================================================
2022-03-29 20:55:50,934: Epoch 11/31 Batch 5000/7662 eta: 23:44:32.700259	Training Loss 0.8168 (0.8181)	Training Prec@1 0.000 (0.065)	Training Prec@5 0.195 (0.227)	
2022-03-29 20:55:50,934: ============================================================
2022-03-29 20:56:43,794: time cost, forward:0.1925530933964414, backward:0.04370046732682391, data cost:0.29720574553093737 
2022-03-29 20:56:43,794: ============================================================
2022-03-29 20:56:43,795: Epoch 11/31 Batch 5100/7662 eta: 22:52:38.018374	Training Loss 0.8180 (0.8181)	Training Prec@1 0.000 (0.066)	Training Prec@5 0.195 (0.228)	
2022-03-29 20:56:43,795: ============================================================
2022-03-29 20:57:36,680: time cost, forward:0.1924556619640863, backward:0.04365011700576809, data cost:0.29724506603614437 
2022-03-29 20:57:36,680: ============================================================
2022-03-29 20:57:36,680: Epoch 11/31 Batch 5200/7662 eta: 22:52:25.071747	Training Loss 0.8185 (0.8181)	Training Prec@1 0.195 (0.066)	Training Prec@5 0.195 (0.228)	
2022-03-29 20:57:36,681: ============================================================
2022-03-29 20:58:30,069: time cost, forward:0.1926579185647095, backward:0.04358278344005521, data cost:0.29711626047997186 
2022-03-29 20:58:30,082: ============================================================
2022-03-29 20:58:30,082: Epoch 11/31 Batch 5300/7662 eta: 23:04:54.458821	Training Loss 0.8187 (0.8181)	Training Prec@1 0.000 (0.066)	Training Prec@5 0.586 (0.229)	
2022-03-29 20:58:30,082: ============================================================
2022-03-29 20:59:23,074: time cost, forward:0.19244889467595838, backward:0.04351494369252476, data cost:0.29732398338551036 
2022-03-29 20:59:23,089: ============================================================
2022-03-29 20:59:23,089: Epoch 11/31 Batch 5400/7662 eta: 22:53:47.150387	Training Loss 0.8186 (0.8181)	Training Prec@1 0.000 (0.066)	Training Prec@5 0.391 (0.229)	
2022-03-29 20:59:23,089: ============================================================
2022-03-29 21:00:16,456: time cost, forward:0.1926595659164065, backward:0.04348182955705636, data cost:0.2971350374081326 
2022-03-29 21:00:16,457: ============================================================
2022-03-29 21:00:16,457: Epoch 11/31 Batch 5500/7662 eta: 23:02:15.374161	Training Loss 0.8186 (0.8181)	Training Prec@1 0.195 (0.066)	Training Prec@5 0.781 (0.229)	
2022-03-29 21:00:16,457: ============================================================
2022-03-29 21:01:10,684: time cost, forward:0.1926749969171741, backward:0.04347275959463881, data cost:0.29729403885672573 
2022-03-29 21:01:10,684: ============================================================
2022-03-29 21:01:10,685: Epoch 11/31 Batch 5600/7662 eta: 23:23:37.293429	Training Loss 0.8193 (0.8181)	Training Prec@1 0.000 (0.067)	Training Prec@5 0.195 (0.229)	
2022-03-29 21:01:10,685: ============================================================
2022-03-29 21:02:04,585: time cost, forward:0.19272664798563208, backward:0.04340254685234074, data cost:0.29739907972225704 
2022-03-29 21:02:04,586: ============================================================
2022-03-29 21:02:04,586: Epoch 11/31 Batch 5700/7662 eta: 23:14:16.648446	Training Loss 0.8196 (0.8181)	Training Prec@1 0.000 (0.067)	Training Prec@5 0.586 (0.230)	
2022-03-29 21:02:04,586: ============================================================
2022-03-29 21:02:57,244: time cost, forward:0.1928722330939669, backward:0.04340755304276357, data cost:0.29711031810972977 
2022-03-29 21:02:57,245: ============================================================
2022-03-29 21:02:57,246: Epoch 11/31 Batch 5800/7662 eta: 22:41:16.459297	Training Loss 0.8168 (0.8181)	Training Prec@1 0.195 (0.067)	Training Prec@5 0.391 (0.230)	
2022-03-29 21:02:57,246: ============================================================
2022-03-29 21:03:51,807: time cost, forward:0.19307229975195817, backward:0.04342707316134618, data cost:0.2970900518608449 
2022-03-29 21:03:51,808: ============================================================
2022-03-29 21:03:51,808: Epoch 11/31 Batch 5900/7662 eta: 23:29:33.211056	Training Loss 0.8186 (0.8181)	Training Prec@1 0.000 (0.067)	Training Prec@5 0.195 (0.231)	
2022-03-29 21:03:51,808: ============================================================
2022-03-29 21:04:46,278: time cost, forward:0.19318027515414557, backward:0.04344123755917785, data cost:0.2971364032588297 
2022-03-29 21:04:46,278: ============================================================
2022-03-29 21:04:46,279: Epoch 11/31 Batch 6000/7662 eta: 23:26:16.954909	Training Loss 0.8172 (0.8181)	Training Prec@1 0.195 (0.068)	Training Prec@5 0.195 (0.231)	
2022-03-29 21:04:46,279: ============================================================
2022-03-29 21:05:39,804: time cost, forward:0.1931059385131746, backward:0.04340145290435426, data cost:0.2972345449901405 
2022-03-29 21:05:39,805: ============================================================
2022-03-29 21:05:39,805: Epoch 11/31 Batch 6100/7662 eta: 23:01:00.553589	Training Loss 0.8184 (0.8181)	Training Prec@1 0.391 (0.068)	Training Prec@5 0.391 (0.232)	
2022-03-29 21:05:39,805: ============================================================
2022-03-29 21:06:32,903: time cost, forward:0.1933207301905817, backward:0.04340777917915168, data cost:0.2969957273378355 
2022-03-29 21:06:32,918: ============================================================
2022-03-29 21:06:32,919: Epoch 11/31 Batch 6200/7662 eta: 22:49:28.343329	Training Loss 0.8187 (0.8181)	Training Prec@1 0.000 (0.068)	Training Prec@5 0.000 (0.232)	
2022-03-29 21:06:32,919: ============================================================
2022-03-29 21:07:27,539: time cost, forward:0.1935320573489729, backward:0.04344271636989537, data cost:0.29693931658166917 
2022-03-29 21:07:27,540: ============================================================
2022-03-29 21:07:27,541: Epoch 11/31 Batch 6300/7662 eta: 23:27:26.993712	Training Loss 0.8168 (0.8181)	Training Prec@1 0.195 (0.068)	Training Prec@5 0.195 (0.232)	
2022-03-29 21:07:27,541: ============================================================
2022-03-29 21:08:22,660: time cost, forward:0.19373356083218501, backward:0.04347220039457097, data cost:0.2969704850946931 
2022-03-29 21:08:22,660: ============================================================
2022-03-29 21:08:22,661: Epoch 11/31 Batch 6400/7662 eta: 23:39:22.074052	Training Loss 0.8184 (0.8181)	Training Prec@1 0.195 (0.068)	Training Prec@5 0.391 (0.233)	
2022-03-29 21:08:22,661: ============================================================
2022-03-29 21:09:17,873: time cost, forward:0.19382777186903077, backward:0.043454459638371065, data cost:0.2971636038373885 
2022-03-29 21:09:17,885: ============================================================
2022-03-29 21:09:17,885: Epoch 11/31 Batch 6500/7662 eta: 23:41:08.096532	Training Loss 0.8188 (0.8181)	Training Prec@1 0.000 (0.068)	Training Prec@5 0.195 (0.233)	
2022-03-29 21:09:17,885: ============================================================
2022-03-29 21:10:10,046: time cost, forward:0.19387010408723188, backward:0.04335287983335497, data cost:0.29701758229492253 
2022-03-29 21:10:10,046: ============================================================
2022-03-29 21:10:10,047: Epoch 11/31 Batch 6600/7662 eta: 22:21:26.865261	Training Loss 0.8190 (0.8181)	Training Prec@1 0.000 (0.068)	Training Prec@5 0.195 (0.233)	
2022-03-29 21:10:10,047: ============================================================
2022-03-29 21:11:03,574: time cost, forward:0.19399626508793344, backward:0.043355743855500437, data cost:0.29689732251335993 
2022-03-29 21:11:03,575: ============================================================
2022-03-29 21:11:03,575: Epoch 11/31 Batch 6700/7662 eta: 22:55:42.337904	Training Loss 0.8183 (0.8181)	Training Prec@1 0.391 (0.069)	Training Prec@5 0.391 (0.233)	
2022-03-29 21:11:03,575: ============================================================
2022-03-29 21:11:57,188: time cost, forward:0.19409510615573664, backward:0.04336517168188958, data cost:0.29681461981980833 
2022-03-29 21:11:57,188: ============================================================
2022-03-29 21:11:57,189: Epoch 11/31 Batch 6800/7662 eta: 22:57:00.621621	Training Loss 0.8166 (0.8181)	Training Prec@1 0.000 (0.069)	Training Prec@5 0.195 (0.234)	
2022-03-29 21:11:57,192: ============================================================
2022-03-29 21:12:51,657: time cost, forward:0.19420568921251874, backward:0.04335343093003963, data cost:0.2968578740537538 
2022-03-29 21:12:51,672: ============================================================
2022-03-29 21:12:51,672: Epoch 11/31 Batch 6900/7662 eta: 23:18:25.570945	Training Loss 0.8191 (0.8181)	Training Prec@1 0.000 (0.068)	Training Prec@5 0.000 (0.234)	
2022-03-29 21:12:51,672: ============================================================
2022-03-29 21:13:44,665: time cost, forward:0.19430698069662244, backward:0.04335482223729846, data cost:0.2966894842519268 
2022-03-29 21:13:44,678: ============================================================
2022-03-29 21:13:44,678: Epoch 11/31 Batch 7000/7662 eta: 22:39:37.928454	Training Loss 0.8189 (0.8181)	Training Prec@1 0.000 (0.068)	Training Prec@5 0.391 (0.234)	
2022-03-29 21:13:44,678: ============================================================
2022-03-29 21:14:38,791: time cost, forward:0.19444448740688206, backward:0.04336525685586699, data cost:0.2966289162585426 
2022-03-29 21:14:38,792: ============================================================
2022-03-29 21:14:38,792: Epoch 11/31 Batch 7100/7662 eta: 23:07:08.785400	Training Loss 0.8184 (0.8181)	Training Prec@1 0.391 (0.069)	Training Prec@5 0.391 (0.234)	
2022-03-29 21:14:38,792: ============================================================
2022-03-29 21:15:32,681: time cost, forward:0.19452772244494365, backward:0.04337291678449713, data cost:0.2965913543205722 
2022-03-29 21:15:32,682: ============================================================
2022-03-29 21:15:32,682: Epoch 11/31 Batch 7200/7662 eta: 23:00:30.386353	Training Loss 0.8190 (0.8181)	Training Prec@1 0.000 (0.069)	Training Prec@5 0.195 (0.234)	
2022-03-29 21:15:32,682: ============================================================
2022-03-29 21:16:26,750: time cost, forward:0.19461158442650778, backward:0.04336533031654384, data cost:0.2965836411617377 
2022-03-29 21:16:26,751: ============================================================
2022-03-29 21:16:26,751: Epoch 11/31 Batch 7300/7662 eta: 23:04:12.044442	Training Loss 0.8194 (0.8181)	Training Prec@1 0.000 (0.069)	Training Prec@5 0.000 (0.234)	
2022-03-29 21:16:26,751: ============================================================
2022-03-29 21:17:20,402: time cost, forward:0.19474351907166326, backward:0.04334426741452455, data cost:0.29650700693276144 
2022-03-29 21:17:20,417: ============================================================
2022-03-29 21:17:20,417: Epoch 11/31 Batch 7400/7662 eta: 22:52:59.171604	Training Loss 0.8185 (0.8181)	Training Prec@1 0.000 (0.069)	Training Prec@5 0.195 (0.234)	
2022-03-29 21:17:20,417: ============================================================
2022-03-29 21:18:15,636: time cost, forward:0.19489290422082725, backward:0.04335419755567629, data cost:0.2965609633711151 
2022-03-29 21:18:15,637: ============================================================
2022-03-29 21:18:15,637: Epoch 11/31 Batch 7500/7662 eta: 23:31:48.959259	Training Loss 0.8182 (0.8181)	Training Prec@1 0.195 (0.069)	Training Prec@5 0.195 (0.234)	
2022-03-29 21:18:15,637: ============================================================
2022-03-29 21:19:09,664: time cost, forward:0.19505890888169433, backward:0.0433965238525234, data cost:0.2964362675837113 
2022-03-29 21:19:09,665: ============================================================
2022-03-29 21:19:09,665: Epoch 11/31 Batch 7600/7662 eta: 23:00:27.076094	Training Loss 0.8191 (0.8181)	Training Prec@1 0.000 (0.069)	Training Prec@5 0.000 (0.233)	
2022-03-29 21:19:09,666: ============================================================
2022-03-29 21:19:45,344: Epoch: 11/31 eta: 22:59:53.038236	Training Loss 0.8179 (0.8181)	Training Prec@1 0.000 (0.069)	Training Prec@5 0.391 (0.234)
2022-03-29 21:19:45,345: ============================================================
2022-03-29 21:20:41,722: time cost, forward:0.2040187301057758, backward:0.044518412965716736, data cost:0.3171118028236158 
2022-03-29 21:20:41,723: ============================================================
2022-03-29 21:20:41,724: Epoch 12/31 Batch 100/7662 eta: 23:58:54.131460	Training Loss 0.8182 (0.8178)	Training Prec@1 0.000 (0.079)	Training Prec@5 0.000 (0.239)	
2022-03-29 21:20:41,724: ============================================================
2022-03-29 21:21:36,448: time cost, forward:0.2028814763879057, backward:0.04429725666141989, data cost:0.3084636345580595 
2022-03-29 21:21:36,448: ============================================================
2022-03-29 21:21:36,449: Epoch 12/31 Batch 200/7662 eta: 23:15:51.854218	Training Loss 0.8180 (0.8178)	Training Prec@1 0.000 (0.073)	Training Prec@5 0.391 (0.235)	
2022-03-29 21:21:36,449: ============================================================
2022-03-29 21:22:31,710: time cost, forward:0.2065087361479284, backward:0.04467572655566161, data cost:0.3031538194637235 
2022-03-29 21:22:31,710: ============================================================
2022-03-29 21:22:31,711: Epoch 12/31 Batch 300/7662 eta: 23:28:38.490741	Training Loss 0.8172 (0.8178)	Training Prec@1 0.391 (0.080)	Training Prec@5 0.586 (0.233)	
2022-03-29 21:22:31,711: ============================================================
2022-03-29 21:23:27,908: time cost, forward:0.20856332420406484, backward:0.04476782552580487, data cost:0.302752901736955 
2022-03-29 21:23:27,909: ============================================================
2022-03-29 21:23:27,909: Epoch 12/31 Batch 400/7662 eta: 23:51:33.725405	Training Loss 0.8187 (0.8178)	Training Prec@1 0.000 (0.075)	Training Prec@5 0.000 (0.232)	
2022-03-29 21:23:27,909: ============================================================
2022-03-29 21:24:24,520: time cost, forward:0.20906511576237802, backward:0.04434795035627896, data cost:0.3044435911044807 
2022-03-29 21:24:24,521: ============================================================
2022-03-29 21:24:24,521: Epoch 12/31 Batch 500/7662 eta: 1 day, 0:01:10.248736	Training Loss 0.8180 (0.8178)	Training Prec@1 0.000 (0.079)	Training Prec@5 0.000 (0.243)	
2022-03-29 21:24:24,522: ============================================================
2022-03-29 21:25:20,309: time cost, forward:0.21043621279759478, backward:0.04445817673544653, data cost:0.30282252897603285 
2022-03-29 21:25:20,323: ============================================================
2022-03-29 21:25:20,323: Epoch 12/31 Batch 600/7662 eta: 23:39:36.287630	Training Loss 0.8185 (0.8178)	Training Prec@1 0.000 (0.079)	Training Prec@5 0.195 (0.245)	
2022-03-29 21:25:20,324: ============================================================
2022-03-29 21:26:16,410: time cost, forward:0.21079605604616528, backward:0.04451660161707364, data cost:0.3026280362206979 
2022-03-29 21:26:16,410: ============================================================
2022-03-29 21:26:16,411: Epoch 12/31 Batch 700/7662 eta: 23:45:56.900493	Training Loss 0.8176 (0.8178)	Training Prec@1 0.000 (0.078)	Training Prec@5 0.195 (0.247)	
2022-03-29 21:26:16,411: ============================================================
2022-03-29 21:27:12,141: time cost, forward:0.21057786541677387, backward:0.044620049611498624, data cost:0.3025922453000638 
2022-03-29 21:27:12,141: ============================================================
2022-03-29 21:27:12,141: Epoch 12/31 Batch 800/7662 eta: 23:35:56.245601	Training Loss 0.8168 (0.8178)	Training Prec@1 0.195 (0.075)	Training Prec@5 0.391 (0.245)	
2022-03-29 21:27:12,141: ============================================================
2022-03-29 21:28:08,546: time cost, forward:0.21191317857438915, backward:0.044682314716801626, data cost:0.3018170737053316 
2022-03-29 21:28:08,559: ============================================================
2022-03-29 21:28:08,560: Epoch 12/31 Batch 900/7662 eta: 23:52:28.327578	Training Loss 0.8171 (0.8178)	Training Prec@1 0.000 (0.075)	Training Prec@5 0.000 (0.244)	
2022-03-29 21:28:08,560: ============================================================
2022-03-29 21:29:05,211: time cost, forward:0.2122980333543993, backward:0.044626135964532035, data cost:0.3022309621652445 
2022-03-29 21:29:05,212: ============================================================
2022-03-29 21:29:05,212: Epoch 12/31 Batch 1000/7662 eta: 23:57:27.683402	Training Loss 0.8180 (0.8178)	Training Prec@1 0.000 (0.075)	Training Prec@5 0.195 (0.249)	
2022-03-29 21:29:05,212: ============================================================
2022-03-29 21:30:02,049: time cost, forward:0.2124547094947322, backward:0.04447025402336364, data cost:0.30300891648866135 
2022-03-29 21:30:02,062: ============================================================
2022-03-29 21:30:02,062: Epoch 12/31 Batch 1100/7662 eta: 1 day, 0:01:32.090887	Training Loss 0.8173 (0.8177)	Training Prec@1 0.000 (0.075)	Training Prec@5 0.391 (0.245)	
2022-03-29 21:30:02,062: ============================================================
2022-03-29 21:30:58,040: time cost, forward:0.2129649292736674, backward:0.04460302087244538, data cost:0.30230250112010204 
2022-03-29 21:30:58,041: ============================================================
2022-03-29 21:30:58,041: Epoch 12/31 Batch 1200/7662 eta: 23:38:31.790954	Training Loss 0.8174 (0.8177)	Training Prec@1 0.000 (0.074)	Training Prec@5 0.391 (0.244)	
2022-03-29 21:30:58,042: ============================================================
2022-03-29 21:31:54,012: time cost, forward:0.21270110755814692, backward:0.04468264902803511, data cost:0.3024357176451063 
2022-03-29 21:31:54,013: ============================================================
2022-03-29 21:31:54,013: Epoch 12/31 Batch 1300/7662 eta: 23:37:24.109513	Training Loss 0.8181 (0.8178)	Training Prec@1 0.000 (0.074)	Training Prec@5 0.195 (0.243)	
2022-03-29 21:31:54,013: ============================================================
2022-03-29 21:32:49,871: time cost, forward:0.2119372197779014, backward:0.04463590069103446, data cost:0.3030751796174339 
2022-03-29 21:32:49,872: ============================================================
2022-03-29 21:32:49,872: Epoch 12/31 Batch 1400/7662 eta: 23:33:36.931476	Training Loss 0.8197 (0.8178)	Training Prec@1 0.195 (0.074)	Training Prec@5 0.391 (0.244)	
2022-03-29 21:32:49,872: ============================================================
2022-03-29 21:33:44,453: time cost, forward:0.211546670762279, backward:0.044568277979946835, data cost:0.3026264235526423 
2022-03-29 21:33:44,454: ============================================================
2022-03-29 21:33:44,454: Epoch 12/31 Batch 1500/7662 eta: 23:00:23.384436	Training Loss 0.8170 (0.8177)	Training Prec@1 0.000 (0.074)	Training Prec@5 0.000 (0.242)	
2022-03-29 21:33:44,455: ============================================================
2022-03-29 21:34:41,014: time cost, forward:0.21150844018111906, backward:0.044683737185241434, data cost:0.30293322459394445 
2022-03-29 21:34:41,015: ============================================================
2022-03-29 21:34:41,015: Epoch 12/31 Batch 1600/7662 eta: 23:49:29.077949	Training Loss 0.8179 (0.8177)	Training Prec@1 0.000 (0.073)	Training Prec@5 0.391 (0.242)	
2022-03-29 21:34:41,015: ============================================================
2022-03-29 21:35:35,119: time cost, forward:0.2107854704775482, backward:0.0446690457789178, data cost:0.30253294315528984 
2022-03-29 21:35:35,119: ============================================================
2022-03-29 21:35:35,119: Epoch 12/31 Batch 1700/7662 eta: 22:46:30.703480	Training Loss 0.8162 (0.8177)	Training Prec@1 0.000 (0.073)	Training Prec@5 0.391 (0.243)	
2022-03-29 21:35:35,120: ============================================================
2022-03-29 21:36:30,176: time cost, forward:0.21031543133721345, backward:0.04470179251924762, data cost:0.30256939517451104 
2022-03-29 21:36:30,177: ============================================================
2022-03-29 21:36:30,177: Epoch 12/31 Batch 1800/7662 eta: 23:09:39.758385	Training Loss 0.8179 (0.8177)	Training Prec@1 0.000 (0.072)	Training Prec@5 0.195 (0.243)	
2022-03-29 21:36:30,177: ============================================================
2022-03-29 21:37:25,495: time cost, forward:0.21021694142671557, backward:0.044754469375851404, data cost:0.30235475499483083 
2022-03-29 21:37:25,496: ============================================================
2022-03-29 21:37:25,496: Epoch 12/31 Batch 1900/7662 eta: 23:15:20.083520	Training Loss 0.8177 (0.8177)	Training Prec@1 0.195 (0.073)	Training Prec@5 0.195 (0.243)	
2022-03-29 21:37:25,496: ============================================================
2022-03-29 21:38:19,699: time cost, forward:0.20932441642726882, backward:0.04467523068174712, data cost:0.3025114444448329 
2022-03-29 21:38:19,700: ============================================================
2022-03-29 21:38:19,700: Epoch 12/31 Batch 2000/7662 eta: 22:46:18.795315	Training Loss 0.8161 (0.8177)	Training Prec@1 0.000 (0.074)	Training Prec@5 0.195 (0.243)	
2022-03-29 21:38:19,700: ============================================================
2022-03-29 21:39:14,633: time cost, forward:0.20926701653395566, backward:0.04470940190533788, data cost:0.30219646849593645 
2022-03-29 21:39:14,634: ============================================================
2022-03-29 21:39:14,634: Epoch 12/31 Batch 2100/7662 eta: 23:03:47.665436	Training Loss 0.8185 (0.8177)	Training Prec@1 0.000 (0.074)	Training Prec@5 0.195 (0.244)	
2022-03-29 21:39:14,634: ============================================================
2022-03-29 21:40:08,732: time cost, forward:0.20929244270428793, backward:0.04470531958891837, data cost:0.3014208999423885 
2022-03-29 21:40:08,733: ============================================================
2022-03-29 21:40:08,734: Epoch 12/31 Batch 2200/7662 eta: 22:41:52.410221	Training Loss 0.8175 (0.8177)	Training Prec@1 0.000 (0.075)	Training Prec@5 0.195 (0.245)	
2022-03-29 21:40:08,734: ============================================================
2022-03-29 21:41:03,308: time cost, forward:0.2092765134642984, backward:0.04469848965084413, data cost:0.30099202654267354 
2022-03-29 21:41:03,309: ============================================================
2022-03-29 21:41:03,309: Epoch 12/31 Batch 2300/7662 eta: 22:52:57.073217	Training Loss 0.8162 (0.8177)	Training Prec@1 0.000 (0.074)	Training Prec@5 0.391 (0.245)	
2022-03-29 21:41:03,309: ============================================================
2022-03-29 21:41:59,937: time cost, forward:0.209119325978103, backward:0.0446997802920419, data cost:0.30163006436680695 
2022-03-29 21:41:59,938: ============================================================
2022-03-29 21:41:59,938: Epoch 12/31 Batch 2400/7662 eta: 23:43:39.376513	Training Loss 0.8170 (0.8177)	Training Prec@1 0.195 (0.074)	Training Prec@5 0.391 (0.244)	
2022-03-29 21:41:59,938: ============================================================
2022-03-29 21:42:54,589: time cost, forward:0.20894684997641025, backward:0.0447178037703729, data cost:0.3013949384685515 
2022-03-29 21:42:54,590: ============================================================
2022-03-29 21:42:54,590: Epoch 12/31 Batch 2500/7662 eta: 22:53:03.387424	Training Loss 0.8181 (0.8177)	Training Prec@1 0.000 (0.074)	Training Prec@5 0.391 (0.244)	
2022-03-29 21:42:54,590: ============================================================
2022-03-29 21:43:48,872: time cost, forward:0.20853271187154454, backward:0.044654704644708464, data cost:0.30138078310160327 
2022-03-29 21:43:48,872: ============================================================
2022-03-29 21:43:48,873: Epoch 12/31 Batch 2600/7662 eta: 22:42:51.792094	Training Loss 0.8179 (0.8177)	Training Prec@1 0.000 (0.073)	Training Prec@5 0.195 (0.244)	
2022-03-29 21:43:48,873: ============================================================
2022-03-29 21:44:43,570: time cost, forward:0.20790419714589523, backward:0.044551008760862855, data cost:0.30182769802951426 
2022-03-29 21:44:43,570: ============================================================
2022-03-29 21:44:43,571: Epoch 12/31 Batch 2700/7662 eta: 22:52:22.702914	Training Loss 0.8173 (0.8177)	Training Prec@1 0.000 (0.073)	Training Prec@5 0.000 (0.243)	
2022-03-29 21:44:43,571: ============================================================
2022-03-29 21:45:37,786: time cost, forward:0.20774091929782923, backward:0.04448312331455526, data cost:0.3016078727677193 
2022-03-29 21:45:37,787: ============================================================
2022-03-29 21:45:37,788: Epoch 12/31 Batch 2800/7662 eta: 22:39:24.345547	Training Loss 0.8168 (0.8177)	Training Prec@1 0.000 (0.073)	Training Prec@5 0.195 (0.243)	
2022-03-29 21:45:37,788: ============================================================
2022-03-29 21:46:32,235: time cost, forward:0.20758728341177934, backward:0.044558230578056406, data cost:0.30134018489762643 
2022-03-29 21:46:32,236: ============================================================
2022-03-29 21:46:32,236: Epoch 12/31 Batch 2900/7662 eta: 22:44:18.421771	Training Loss 0.8177 (0.8177)	Training Prec@1 0.000 (0.073)	Training Prec@5 0.195 (0.244)	
2022-03-29 21:46:32,236: ============================================================
2022-03-29 21:47:26,115: time cost, forward:0.207039362989135, backward:0.04465603995378831, data cost:0.3012819668578084 
2022-03-29 21:47:26,115: ============================================================
2022-03-29 21:47:26,115: Epoch 12/31 Batch 3000/7662 eta: 22:29:08.865915	Training Loss 0.8171 (0.8177)	Training Prec@1 0.000 (0.073)	Training Prec@5 0.195 (0.243)	
2022-03-29 21:47:26,116: ============================================================
2022-03-29 21:48:19,672: time cost, forward:0.2066883215330308, backward:0.04466997257699194, data cost:0.30103780631674376 
2022-03-29 21:48:19,673: ============================================================
2022-03-29 21:48:19,673: Epoch 12/31 Batch 3100/7662 eta: 22:20:11.754090	Training Loss 0.8184 (0.8177)	Training Prec@1 0.000 (0.073)	Training Prec@5 0.391 (0.245)	
2022-03-29 21:48:19,673: ============================================================
2022-03-29 21:49:13,300: time cost, forward:0.2064921422167173, backward:0.044699279469749116, data cost:0.30068752593493303 
2022-03-29 21:49:13,301: ============================================================
2022-03-29 21:49:13,301: Epoch 12/31 Batch 3200/7662 eta: 22:21:03.871608	Training Loss 0.8175 (0.8177)	Training Prec@1 0.000 (0.073)	Training Prec@5 0.000 (0.246)	
2022-03-29 21:49:13,301: ============================================================
2022-03-29 21:50:08,411: time cost, forward:0.206238210110926, backward:0.044718521585895205, data cost:0.3008825288248192 
2022-03-29 21:50:08,412: ============================================================
2022-03-29 21:50:08,412: Epoch 12/31 Batch 3300/7662 eta: 22:57:14.401074	Training Loss 0.8166 (0.8177)	Training Prec@1 0.391 (0.074)	Training Prec@5 0.586 (0.247)	
2022-03-29 21:50:08,412: ============================================================
2022-03-29 21:51:03,351: time cost, forward:0.20602343123812786, backward:0.04468195169734478, data cost:0.3010490479347249 
2022-03-29 21:51:03,351: ============================================================
2022-03-29 21:51:03,351: Epoch 12/31 Batch 3400/7662 eta: 22:52:01.588744	Training Loss 0.8173 (0.8177)	Training Prec@1 0.000 (0.074)	Training Prec@5 0.000 (0.246)	
2022-03-29 21:51:03,352: ============================================================
2022-03-29 21:51:55,682: time cost, forward:0.20563297170882702, backward:0.04469888576203396, data cost:0.30059207627077583 
2022-03-29 21:51:55,682: ============================================================
2022-03-29 21:51:55,683: Epoch 12/31 Batch 3500/7662 eta: 21:46:01.320212	Training Loss 0.8172 (0.8177)	Training Prec@1 0.000 (0.074)	Training Prec@5 0.195 (0.247)	
2022-03-29 21:51:55,683: ============================================================
2022-03-29 21:52:50,029: time cost, forward:0.20535596730676617, backward:0.04471393014431397, data cost:0.3006401878159786 
2022-03-29 21:52:50,029: ============================================================
2022-03-29 21:52:50,029: Epoch 12/31 Batch 3600/7662 eta: 22:35:25.212499	Training Loss 0.8184 (0.8177)	Training Prec@1 0.391 (0.074)	Training Prec@5 0.586 (0.248)	
2022-03-29 21:52:50,030: ============================================================
2022-03-29 21:53:44,386: time cost, forward:0.2052509283239566, backward:0.044734628370047325, data cost:0.3005031319881459 
2022-03-29 21:53:44,387: ============================================================
2022-03-29 21:53:44,387: Epoch 12/31 Batch 3700/7662 eta: 22:34:46.779494	Training Loss 0.8198 (0.8177)	Training Prec@1 0.000 (0.074)	Training Prec@5 0.586 (0.247)	
2022-03-29 21:53:44,388: ============================================================
2022-03-29 21:54:38,525: time cost, forward:0.20523389335304978, backward:0.044735016337066114, data cost:0.30028025838506006 
2022-03-29 21:54:38,526: ============================================================
2022-03-29 21:54:38,526: Epoch 12/31 Batch 3800/7662 eta: 22:28:25.781664	Training Loss 0.8167 (0.8177)	Training Prec@1 0.000 (0.074)	Training Prec@5 0.195 (0.247)	
2022-03-29 21:54:38,526: ============================================================
2022-03-29 21:55:33,167: time cost, forward:0.20519283173114222, backward:0.044720057494581036, data cost:0.30022122151242003 
2022-03-29 21:55:33,168: ============================================================
2022-03-29 21:55:33,168: Epoch 12/31 Batch 3900/7662 eta: 22:40:03.060128	Training Loss 0.8169 (0.8177)	Training Prec@1 0.000 (0.075)	Training Prec@5 0.195 (0.248)	
2022-03-29 21:55:33,168: ============================================================
2022-03-29 21:56:27,271: time cost, forward:0.20525773348406454, backward:0.04472486255585655, data cost:0.29991523871930964 
2022-03-29 21:56:27,272: ============================================================
2022-03-29 21:56:27,273: Epoch 12/31 Batch 4000/7662 eta: 22:25:46.060990	Training Loss 0.8179 (0.8177)	Training Prec@1 0.391 (0.075)	Training Prec@5 0.391 (0.249)	
2022-03-29 21:56:27,273: ============================================================
2022-03-29 21:57:22,357: time cost, forward:0.20524972565263094, backward:0.04470415643495186, data cost:0.29995828885862263 
2022-03-29 21:57:22,358: ============================================================
2022-03-29 21:57:22,358: Epoch 12/31 Batch 4100/7662 eta: 22:49:15.374201	Training Loss 0.8181 (0.8177)	Training Prec@1 0.000 (0.075)	Training Prec@5 0.391 (0.249)	
2022-03-29 21:57:22,359: ============================================================
2022-03-29 21:58:15,892: time cost, forward:0.204965222418436, backward:0.044685878592407344, data cost:0.29990965583603224 
2022-03-29 21:58:15,892: ============================================================
2022-03-29 21:58:15,892: Epoch 12/31 Batch 4200/7662 eta: 22:09:47.266627	Training Loss 0.8185 (0.8176)	Training Prec@1 0.000 (0.075)	Training Prec@5 0.781 (0.250)	
2022-03-29 21:58:15,892: ============================================================
2022-03-29 21:59:11,788: time cost, forward:0.20511928362246307, backward:0.04470341691973043, data cost:0.2999447945468119 
2022-03-29 21:59:11,789: ============================================================
2022-03-29 21:59:11,789: Epoch 12/31 Batch 4300/7662 eta: 23:07:33.375460	Training Loss 0.8173 (0.8176)	Training Prec@1 0.195 (0.075)	Training Prec@5 0.195 (0.250)	
2022-03-29 21:59:11,790: ============================================================
2022-03-29 22:00:04,289: time cost, forward:0.20494715179413875, backward:0.04465520796544933, data cost:0.29956412992848136 
2022-03-29 22:00:04,290: ============================================================
2022-03-29 22:00:04,290: Epoch 12/31 Batch 4400/7662 eta: 21:42:23.036013	Training Loss 0.8186 (0.8176)	Training Prec@1 0.000 (0.075)	Training Prec@5 0.195 (0.250)	
2022-03-29 22:00:04,290: ============================================================
2022-03-29 22:00:58,197: time cost, forward:0.2044846412207609, backward:0.04456948052249662, data cost:0.29989153985368805 
2022-03-29 22:00:58,197: ============================================================
2022-03-29 22:00:58,197: Epoch 12/31 Batch 4500/7662 eta: 22:16:22.223042	Training Loss 0.8176 (0.8176)	Training Prec@1 0.000 (0.075)	Training Prec@5 0.391 (0.250)	
2022-03-29 22:00:58,197: ============================================================
2022-03-29 22:01:51,143: time cost, forward:0.20408313563140118, backward:0.04452317428215609, data cost:0.29991626993524795 
2022-03-29 22:01:51,152: ============================================================
2022-03-29 22:01:51,153: Epoch 12/31 Batch 4600/7662 eta: 21:51:53.448503	Training Loss 0.8174 (0.8176)	Training Prec@1 0.195 (0.075)	Training Prec@5 0.195 (0.251)	
2022-03-29 22:01:51,153: ============================================================
2022-03-29 22:02:44,401: time cost, forward:0.20371319441420901, backward:0.04449048659273299, data cost:0.2998968366106207 
2022-03-29 22:02:44,402: ============================================================
2022-03-29 22:02:44,402: Epoch 12/31 Batch 4700/7662 eta: 21:58:16.651383	Training Loss 0.8170 (0.8176)	Training Prec@1 0.000 (0.075)	Training Prec@5 0.195 (0.250)	
2022-03-29 22:02:44,402: ============================================================
2022-03-29 22:03:36,417: time cost, forward:0.20342053242290137, backward:0.04444431577977798, data cost:0.29969946248602386 
2022-03-29 22:03:36,418: ============================================================
2022-03-29 22:03:36,418: Epoch 12/31 Batch 4800/7662 eta: 21:26:53.164395	Training Loss 0.8180 (0.8176)	Training Prec@1 0.000 (0.074)	Training Prec@5 0.391 (0.250)	
2022-03-29 22:03:36,418: ============================================================
2022-03-29 22:04:30,323: time cost, forward:0.20334895841197886, backward:0.04435916588388674, data cost:0.2996717238090408 
2022-03-29 22:04:30,323: ============================================================
2022-03-29 22:04:30,324: Epoch 12/31 Batch 4900/7662 eta: 22:12:44.443251	Training Loss 0.8164 (0.8176)	Training Prec@1 0.195 (0.074)	Training Prec@5 0.195 (0.250)	
2022-03-29 22:04:30,324: ============================================================
2022-03-29 22:05:22,670: time cost, forward:0.20306622235625715, backward:0.04434131712740864, data cost:0.2994696463458799 
2022-03-29 22:05:22,670: ============================================================
2022-03-29 22:05:22,671: Epoch 12/31 Batch 5000/7662 eta: 21:33:19.726347	Training Loss 0.8181 (0.8176)	Training Prec@1 0.000 (0.074)	Training Prec@5 0.000 (0.250)	
2022-03-29 22:05:22,671: ============================================================
2022-03-29 22:06:18,143: time cost, forward:0.2030888417347386, backward:0.044336150781527105, data cost:0.299600154658256 
2022-03-29 22:06:18,143: ============================================================
2022-03-29 22:06:18,143: Epoch 12/31 Batch 5100/7662 eta: 22:49:37.932063	Training Loss 0.8161 (0.8176)	Training Prec@1 0.391 (0.074)	Training Prec@5 0.391 (0.251)	
2022-03-29 22:06:18,144: ============================================================
2022-03-29 22:07:11,029: time cost, forward:0.2031581543986443, backward:0.04435193256635715, data cost:0.2991724530649451 
2022-03-29 22:07:11,029: ============================================================
2022-03-29 22:07:11,030: Epoch 12/31 Batch 5200/7662 eta: 21:44:53.201032	Training Loss 0.8178 (0.8176)	Training Prec@1 0.000 (0.075)	Training Prec@5 0.195 (0.252)	
2022-03-29 22:07:11,030: ============================================================
2022-03-29 22:08:05,032: time cost, forward:0.2030736721558579, backward:0.044343959027628874, data cost:0.29913553145049226 
2022-03-29 22:08:05,032: ============================================================
2022-03-29 22:08:05,033: Epoch 12/31 Batch 5300/7662 eta: 22:11:32.441406	Training Loss 0.8199 (0.8176)	Training Prec@1 0.000 (0.075)	Training Prec@5 0.000 (0.252)	
2022-03-29 22:08:05,033: ============================================================
2022-03-29 22:08:57,881: time cost, forward:0.20279140325801684, backward:0.044310940572742534, data cost:0.29910880341576657 
2022-03-29 22:08:57,882: ============================================================
2022-03-29 22:08:57,882: Epoch 12/31 Batch 5400/7662 eta: 21:42:13.194665	Training Loss 0.8171 (0.8176)	Training Prec@1 0.000 (0.075)	Training Prec@5 0.000 (0.253)	
2022-03-29 22:08:57,882: ============================================================
2022-03-29 22:09:48,682: time cost, forward:0.2023076145708355, backward:0.044234256784272945, data cost:0.2989567889150955 
2022-03-29 22:09:48,683: ============================================================
2022-03-29 22:09:48,683: Epoch 12/31 Batch 5500/7662 eta: 20:50:53.802730	Training Loss 0.8184 (0.8176)	Training Prec@1 0.000 (0.075)	Training Prec@5 0.195 (0.253)	
2022-03-29 22:09:48,683: ============================================================
2022-03-29 22:10:42,033: time cost, forward:0.20237145885481836, backward:0.044239619136346324, data cost:0.2986650825036511 
2022-03-29 22:10:42,034: ============================================================
2022-03-29 22:10:42,034: Epoch 12/31 Batch 5600/7662 eta: 21:52:48.416771	Training Loss 0.8169 (0.8176)	Training Prec@1 0.000 (0.075)	Training Prec@5 0.000 (0.254)	
2022-03-29 22:10:42,035: ============================================================
2022-03-29 22:11:33,200: time cost, forward:0.2019536416140287, backward:0.0441806797480077, data cost:0.29854336419133143 
2022-03-29 22:11:33,201: ============================================================
2022-03-29 22:11:33,201: Epoch 12/31 Batch 5700/7662 eta: 20:58:11.675299	Training Loss 0.8169 (0.8176)	Training Prec@1 0.000 (0.075)	Training Prec@5 0.586 (0.255)	
2022-03-29 22:11:33,201: ============================================================
2022-03-29 22:12:24,210: time cost, forward:0.20148086490292327, backward:0.04411912914143901, data cost:0.2984742427575298 
2022-03-29 22:12:24,211: ============================================================
2022-03-29 22:12:24,211: Epoch 12/31 Batch 5800/7662 eta: 20:53:29.948314	Training Loss 0.8174 (0.8176)	Training Prec@1 0.391 (0.075)	Training Prec@5 0.586 (0.256)	
2022-03-29 22:12:24,211: ============================================================
2022-03-29 22:13:15,396: time cost, forward:0.20121814590689488, backward:0.044057934703332205, data cost:0.2982487921028506 
2022-03-29 22:13:15,396: ============================================================
2022-03-29 22:13:15,396: Epoch 12/31 Batch 5900/7662 eta: 20:56:57.092523	Training Loss 0.8162 (0.8176)	Training Prec@1 0.195 (0.075)	Training Prec@5 0.195 (0.256)	
2022-03-29 22:13:15,397: ============================================================
2022-03-29 22:14:08,793: time cost, forward:0.20110457900127265, backward:0.04406915018609771, data cost:0.2981811317727454 
2022-03-29 22:14:08,794: ============================================================
2022-03-29 22:14:08,794: Epoch 12/31 Batch 6000/7662 eta: 21:50:23.138005	Training Loss 0.8189 (0.8176)	Training Prec@1 0.000 (0.076)	Training Prec@5 0.391 (0.257)	
2022-03-29 22:14:08,794: ============================================================
2022-03-29 22:15:02,519: time cost, forward:0.20100031901351897, backward:0.04407660498699608, data cost:0.2981608563670371 
2022-03-29 22:15:02,520: ============================================================
2022-03-29 22:15:02,520: Epoch 12/31 Batch 6100/7662 eta: 21:57:33.133734	Training Loss 0.8177 (0.8176)	Training Prec@1 0.195 (0.075)	Training Prec@5 0.391 (0.257)	
2022-03-29 22:15:02,520: ============================================================
2022-03-29 22:15:53,100: time cost, forward:0.20047654280990992, backward:0.0439926643759267, data cost:0.29816404275883396 
2022-03-29 22:15:53,100: ============================================================
2022-03-29 22:15:53,100: Epoch 12/31 Batch 6200/7662 eta: 20:39:33.650750	Training Loss 0.8160 (0.8176)	Training Prec@1 0.195 (0.075)	Training Prec@5 0.195 (0.257)	
2022-03-29 22:15:53,101: ============================================================
2022-03-29 22:16:45,968: time cost, forward:0.20033398006128533, backward:0.0439436378167118, data cost:0.29812665102235436 
2022-03-29 22:16:45,968: ============================================================
2022-03-29 22:16:45,968: Epoch 12/31 Batch 6300/7662 eta: 21:34:44.273603	Training Loss 0.8175 (0.8176)	Training Prec@1 0.000 (0.076)	Training Prec@5 0.391 (0.257)	
2022-03-29 22:16:45,968: ============================================================
2022-03-29 22:17:38,386: time cost, forward:0.20024873078065022, backward:0.04397200733297485, data cost:0.2978926936356905 
2022-03-29 22:17:38,386: ============================================================
2022-03-29 22:17:38,387: Epoch 12/31 Batch 6400/7662 eta: 21:22:51.725573	Training Loss 0.8171 (0.8176)	Training Prec@1 0.000 (0.076)	Training Prec@5 0.195 (0.258)	
2022-03-29 22:17:38,387: ============================================================
2022-03-29 22:18:28,562: time cost, forward:0.19993604357599534, backward:0.043947671152735, data cost:0.29760385095238556 
2022-03-29 22:18:28,562: ============================================================
2022-03-29 22:18:28,563: Epoch 12/31 Batch 6500/7662 eta: 20:27:08.812964	Training Loss 0.8177 (0.8176)	Training Prec@1 0.000 (0.076)	Training Prec@5 0.391 (0.258)	
2022-03-29 22:18:28,563: ============================================================
2022-03-29 22:19:21,804: time cost, forward:0.19983705984388161, backward:0.04394498018084701, data cost:0.2975569577411479 
2022-03-29 22:19:21,805: ============================================================
2022-03-29 22:19:21,805: Epoch 12/31 Batch 6600/7662 eta: 21:41:15.262851	Training Loss 0.8182 (0.8176)	Training Prec@1 0.000 (0.076)	Training Prec@5 0.195 (0.258)	
2022-03-29 22:19:21,805: ============================================================
2022-03-29 22:20:11,397: time cost, forward:0.19940402230534524, backward:0.043884238408099074, data cost:0.2973610301358715 
2022-03-29 22:20:11,398: ============================================================
2022-03-29 22:20:11,398: Epoch 12/31 Batch 6700/7662 eta: 20:11:14.376406	Training Loss 0.8165 (0.8176)	Training Prec@1 0.000 (0.076)	Training Prec@5 0.195 (0.258)	
2022-03-29 22:20:11,399: ============================================================
2022-03-29 22:21:02,548: time cost, forward:0.19900514704635133, backward:0.043828268860487185, data cost:0.2973871587006235 
2022-03-29 22:21:02,549: ============================================================
2022-03-29 22:21:02,549: Epoch 12/31 Batch 6800/7662 eta: 20:48:25.593580	Training Loss 0.8165 (0.8176)	Training Prec@1 0.000 (0.076)	Training Prec@5 0.000 (0.258)	
2022-03-29 22:21:02,549: ============================================================
2022-03-29 22:21:53,084: time cost, forward:0.19870506747768726, backward:0.04372938696345241, data cost:0.29727435464495455 
2022-03-29 22:21:53,084: ============================================================
2022-03-29 22:21:53,085: Epoch 12/31 Batch 6900/7662 eta: 20:32:34.396523	Training Loss 0.8169 (0.8176)	Training Prec@1 0.000 (0.076)	Training Prec@5 0.195 (0.259)	
2022-03-29 22:21:53,085: ============================================================
2022-03-29 22:22:44,213: time cost, forward:0.19840396290285994, backward:0.04368967024798665, data cost:0.2972031305953253 
2022-03-29 22:22:44,214: ============================================================
2022-03-29 22:22:44,214: Epoch 12/31 Batch 7000/7662 eta: 20:46:12.180742	Training Loss 0.8182 (0.8176)	Training Prec@1 0.195 (0.076)	Training Prec@5 0.586 (0.259)	
2022-03-29 22:22:44,214: ============================================================
2022-03-29 22:23:37,553: time cost, forward:0.19857411213971676, backward:0.04371838284841909, data cost:0.29691448814853144 
2022-03-29 22:23:37,554: ============================================================
2022-03-29 22:23:37,554: Epoch 12/31 Batch 7100/7662 eta: 21:39:11.758053	Training Loss 0.8168 (0.8176)	Training Prec@1 0.391 (0.077)	Training Prec@5 0.586 (0.259)	
2022-03-29 22:23:37,554: ============================================================
2022-03-29 22:24:25,759: time cost, forward:0.1979868371282324, backward:0.04370313721376089, data cost:0.29671921861189937 
2022-03-29 22:24:25,772: ============================================================
2022-03-29 22:24:25,772: Epoch 12/31 Batch 7200/7662 eta: 19:33:37.774912	Training Loss 0.8186 (0.8176)	Training Prec@1 0.000 (0.077)	Training Prec@5 0.195 (0.259)	
2022-03-29 22:24:25,772: ============================================================
2022-03-29 22:25:19,489: time cost, forward:0.19793629260859533, backward:0.04367913911074445, data cost:0.29677787737121875 
2022-03-29 22:25:19,489: ============================================================
2022-03-29 22:25:19,489: Epoch 12/31 Batch 7300/7662 eta: 21:46:35.718845	Training Loss 0.8178 (0.8176)	Training Prec@1 0.000 (0.076)	Training Prec@5 0.000 (0.259)	
2022-03-29 22:25:19,490: ============================================================
2022-03-29 22:26:09,149: time cost, forward:0.1975625823810143, backward:0.043615601581244036, data cost:0.29664294966847077 
2022-03-29 22:26:09,150: ============================================================
2022-03-29 22:26:09,150: Epoch 12/31 Batch 7400/7662 eta: 20:07:05.214798	Training Loss 0.8184 (0.8175)	Training Prec@1 0.000 (0.076)	Training Prec@5 0.000 (0.259)	
2022-03-29 22:26:09,150: ============================================================
2022-03-29 22:27:00,707: time cost, forward:0.19739495580840832, backward:0.04357905196482252, data cost:0.296536577623802 
2022-03-29 22:27:00,708: ============================================================
2022-03-29 22:27:00,709: Epoch 12/31 Batch 7500/7662 eta: 20:52:22.475037	Training Loss 0.8156 (0.8175)	Training Prec@1 0.195 (0.076)	Training Prec@5 0.391 (0.259)	
2022-03-29 22:27:00,709: ============================================================
2022-03-29 22:27:48,976: time cost, forward:0.19691839301597133, backward:0.04351161689974161, data cost:0.2963547004745389 
2022-03-29 22:27:48,977: ============================================================
2022-03-29 22:27:48,977: Epoch 12/31 Batch 7600/7662 eta: 19:31:38.146333	Training Loss 0.8169 (0.8175)	Training Prec@1 0.195 (0.076)	Training Prec@5 0.195 (0.259)	
2022-03-29 22:27:48,977: ============================================================
2022-03-29 22:28:25,346: Epoch: 12/31 eta: 19:31:07.737429	Training Loss 0.8171 (0.8175)	Training Prec@1 0.000 (0.077)	Training Prec@5 0.195 (0.259)
2022-03-29 22:28:25,347: ============================================================
2022-03-29 22:29:13,545: time cost, forward:0.15283670810737995, backward:0.038647873233063054, data cost:0.289502218516186 
2022-03-29 22:29:13,546: ============================================================
2022-03-29 22:29:13,546: Epoch 13/31 Batch 100/7662 eta: 19:22:46.369639	Training Loss 0.8160 (0.8174)	Training Prec@1 0.000 (0.079)	Training Prec@5 0.000 (0.280)	
2022-03-29 22:29:13,547: ============================================================
2022-03-29 22:30:01,406: time cost, forward:0.14909494462324746, backward:0.0369089656139738, data cost:0.2937020057409852 
2022-03-29 22:30:01,407: ============================================================
2022-03-29 22:30:01,408: Epoch 13/31 Batch 200/7662 eta: 19:19:40.661973	Training Loss 0.8164 (0.8173)	Training Prec@1 0.000 (0.086)	Training Prec@5 0.000 (0.291)	
2022-03-29 22:30:01,408: ============================================================
2022-03-29 22:30:50,636: time cost, forward:0.147692485796568, backward:0.03776707617335495, data cost:0.29822531272735087 
2022-03-29 22:30:50,636: ============================================================
2022-03-29 22:30:50,636: Epoch 13/31 Batch 300/7662 eta: 19:51:58.497783	Training Loss 0.8177 (0.8173)	Training Prec@1 0.000 (0.082)	Training Prec@5 0.000 (0.281)	
2022-03-29 22:30:50,637: ============================================================
2022-03-29 22:31:40,981: time cost, forward:0.15057571669270223, backward:0.038675546646118164, data cost:0.2993348427583699 
2022-03-29 22:31:40,982: ============================================================
2022-03-29 22:31:40,982: Epoch 13/31 Batch 400/7662 eta: 20:18:11.123894	Training Loss 0.8160 (0.8173)	Training Prec@1 0.195 (0.090)	Training Prec@5 0.586 (0.292)	
2022-03-29 22:31:40,982: ============================================================
2022-03-29 22:32:31,193: time cost, forward:0.15225606690905616, backward:0.038616189497984, data cost:0.30023821131260936 
2022-03-29 22:32:31,194: ============================================================
2022-03-29 22:32:31,194: Epoch 13/31 Batch 500/7662 eta: 20:14:07.699968	Training Loss 0.8176 (0.8173)	Training Prec@1 0.000 (0.088)	Training Prec@5 0.000 (0.283)	
2022-03-29 22:32:31,195: ============================================================
2022-03-29 22:33:22,710: time cost, forward:0.15666530287524497, backward:0.03911582735026619, data cost:0.29940194836841005 
2022-03-29 22:33:22,710: ============================================================
2022-03-29 22:33:22,711: Epoch 13/31 Batch 600/7662 eta: 20:44:47.824473	Training Loss 0.8188 (0.8173)	Training Prec@1 0.195 (0.082)	Training Prec@5 0.195 (0.274)	
2022-03-29 22:33:22,711: ============================================================
2022-03-29 22:34:17,737: time cost, forward:0.16311802270586398, backward:0.03975229372452939, data cost:0.3001333064105207 
2022-03-29 22:34:17,737: ============================================================
2022-03-29 22:34:17,738: Epoch 13/31 Batch 700/7662 eta: 22:08:42.767946	Training Loss 0.8182 (0.8173)	Training Prec@1 0.000 (0.083)	Training Prec@5 0.000 (0.273)	
2022-03-29 22:34:17,738: ============================================================
2022-03-29 22:35:12,025: time cost, forward:0.16658439982370082, backward:0.040395688652544656, data cost:0.30096202499427843 
2022-03-29 22:35:12,039: ============================================================
2022-03-29 22:35:12,040: Epoch 13/31 Batch 800/7662 eta: 21:50:17.643426	Training Loss 0.8163 (0.8173)	Training Prec@1 0.391 (0.082)	Training Prec@5 0.586 (0.273)	
2022-03-29 22:35:12,040: ============================================================
2022-03-29 22:36:07,415: time cost, forward:0.17073450576476712, backward:0.04037996208309729, data cost:0.3018823903182457 
2022-03-29 22:36:07,415: ============================================================
2022-03-29 22:36:07,416: Epoch 13/31 Batch 900/7662 eta: 22:15:17.387744	Training Loss 0.8176 (0.8173)	Training Prec@1 0.000 (0.082)	Training Prec@5 0.000 (0.275)	
2022-03-29 22:36:07,416: ============================================================
2022-03-29 22:37:01,540: time cost, forward:0.172559221466263, backward:0.04028237450707543, data cost:0.3029606256399069 
2022-03-29 22:37:01,540: ============================================================
2022-03-29 22:37:01,541: Epoch 13/31 Batch 1000/7662 eta: 21:44:13.301366	Training Loss 0.8159 (0.8172)	Training Prec@1 0.000 (0.082)	Training Prec@5 0.000 (0.274)	
2022-03-29 22:37:01,541: ============================================================
2022-03-29 22:37:55,329: time cost, forward:0.17507187814686492, backward:0.04009542842687966, data cost:0.3026177327778255 
2022-03-29 22:37:55,330: ============================================================
2022-03-29 22:37:55,330: Epoch 13/31 Batch 1100/7662 eta: 21:35:14.479688	Training Loss 0.8176 (0.8172)	Training Prec@1 0.000 (0.084)	Training Prec@5 0.195 (0.275)	
2022-03-29 22:37:55,330: ============================================================
