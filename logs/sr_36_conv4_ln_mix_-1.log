2022-07-06 17:32:22,912: ('name', 'amsoft-36')
2022-07-06 17:32:22,912: ('description', '测试在conv4之前加ln进行直接混合训练的效果')
2022-07-06 17:32:22,913: ('data_settings', {'training': {'batch_size': 512, 'num_workers': 4, 'num_class': 86876, 'loader_settings': {'lmdb_path': '/home/ubuntu/data4/lk/data/lmdb_mask_augu_full', 'num': 3923399, 'max_reader': 4, 'augu_paral': False, 'ldm68': True, 'augu_rate': 0.5, 'shuffle': False}}})
2022-07-06 17:32:22,913: ('common_settings', {'backbone': {'num': 1, 'settings': [{'backbone_model_name': 'SimpleResnet_36', 'args': {'input_size': [112, 112], 'ln': True}, 'resume_net_model': None}]}, 'classifier': {'num': 1, 'settings': [{'classifier_model_name': 'MarginCosineProduct', 'args': {'in_features': 512, 'out_features': 86876}, 'resume_net_classifier': None, 'alpha': 1}]}})
2022-07-06 17:32:22,913: ('gpu_settings', {'no_cuda': False, 'gpu_num': 1})
2022-07-06 17:32:22,913: ('log_settings', {'training': {'log_path': './logs/sr_36_conv4_ln_mix.log', 'log_pic_path': './logs/pic/sr_36_conv4_ln_mix/', 'save_path': 'snapshot/sr_36_conv4_ln_mix/', 'log_interval': 100}, 'testing': {'result_path': './result/result.txt'}})
2022-07-06 17:32:22,913: ('other_settings', {'resume': False, 'resume_net_optimizer': None, 'start_epoch': 1, 'max_epoch': 36, 'lr': 0.1, 'base': 'epoch', 'step_size': [10, 20, 30], 'momentum': 0.9, 'gama': 0.1, 'weight_decay': 0.0005})
2022-07-06 17:32:22,913: ('environ_settings', {'rank': -1, 'dist_url': 'env://', 'world_size': -1, 'gpu': None, 'dist_backend': 'nccl', 'distributed': False, 'master_port': 22345, 'multiprocessing_distributed': False, 'SEED': 1337})
2022-07-06 17:32:22,913: ('local_rank', -1)
2022-07-06 17:32:27,200: Use DP
2022-07-06 17:32:27,364: CrossEntropyLoss()
2022-07-06 17:32:27,364: <bound method Trainer.loss_func of <trainner.Trainer object at 0x7f5a36554d68>>
2022-07-06 17:33:42,945: time cost, forward:0.017251794988458805, backward:0.04473587960907907, data cost:0.6963494137080029 
2022-07-06 17:33:42,945: ============================================================
2022-07-06 17:33:42,945: Epoch 1/36 Batch 100/7662 eta: 2 days, 9:53:18.635019	Training Loss1 21.8722 (28.7787)	Training Total_Loss 21.8722 (28.7787)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.000)	
2022-07-06 17:33:42,945: ============================================================
2022-07-06 17:35:01,244: time cost, forward:0.014000172591089603, backward:0.039047585060848065, data cost:0.7173836530752518 
2022-07-06 17:35:01,244: ============================================================
2022-07-06 17:35:01,245: Epoch 1/36 Batch 200/7662 eta: 2 days, 11:56:59.256860	Training Loss1 21.8722 (25.3081)	Training Total_Loss 21.8722 (25.3081)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.000)	
2022-07-06 17:35:01,245: ============================================================
2022-07-06 17:36:20,201: time cost, forward:0.012918634956895707, backward:0.037173873206046114, data cost:0.7265676439406481 
2022-07-06 17:36:20,202: ============================================================
2022-07-06 17:36:20,202: Epoch 1/36 Batch 300/7662 eta: 2 days, 12:25:52.691366	Training Loss1 21.8722 (24.1590)	Training Total_Loss 21.8722 (24.1590)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.000)	
2022-07-06 17:36:20,202: ============================================================
2022-07-06 17:37:38,561: time cost, forward:0.01238532831196797, backward:0.03624389464395088, data cost:0.7296138508875567 
2022-07-06 17:37:38,561: ============================================================
2022-07-06 17:37:38,562: Epoch 1/36 Batch 400/7662 eta: 2 days, 11:57:08.683199	Training Loss1 21.8722 (23.5859)	Training Total_Loss 21.8722 (23.5859)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.000)	
2022-07-06 17:37:38,562: ============================================================
2022-07-06 17:38:57,050: time cost, forward:0.012037649422227022, backward:0.03562698431148797, data cost:0.7317927132149736 
2022-07-06 17:38:57,051: ============================================================
2022-07-06 17:38:57,051: Epoch 1/36 Batch 500/7662 eta: 2 days, 12:01:47.327111	Training Loss1 21.8722 (23.2424)	Training Total_Loss 21.8722 (23.2424)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.000)	
2022-07-06 17:38:57,051: ============================================================
2022-07-06 17:40:14,265: time cost, forward:0.011806832729078494, backward:0.03531014421746408, data cost:0.7310179135636217 
2022-07-06 17:40:14,265: ============================================================
2022-07-06 17:40:14,266: Epoch 1/36 Batch 600/7662 eta: 2 days, 11:02:00.518944	Training Loss1 21.8722 (23.0144)	Training Total_Loss 21.8722 (23.0144)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.000)	
2022-07-06 17:40:14,266: ============================================================
2022-07-06 17:41:31,477: time cost, forward:0.01178147182273592, backward:0.034879786773812614, data cost:0.7305408683798685 
2022-07-06 17:41:31,477: ============================================================
2022-07-06 17:41:31,477: Epoch 1/36 Batch 700/7662 eta: 2 days, 11:00:34.580456	Training Loss1 21.9528 (22.8530)	Training Total_Loss 21.9528 (22.8530)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.000)	
2022-07-06 17:41:31,477: ============================================================
2022-07-06 17:42:50,231: time cost, forward:0.011709298001362176, backward:0.034588956713527255, data cost:0.732125418953066 
2022-07-06 17:42:50,231: ============================================================
2022-07-06 17:42:50,231: Epoch 1/36 Batch 800/7662 eta: 2 days, 12:09:59.771954	Training Loss1 21.8722 (22.7342)	Training Total_Loss 21.8722 (22.7342)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.000)	
2022-07-06 17:42:50,232: ============================================================
2022-07-06 17:44:08,291: time cost, forward:0.011596318744578801, backward:0.034426181281899185, data cost:0.7325237126185976 
2022-07-06 17:44:08,291: ============================================================
2022-07-06 17:44:08,291: Epoch 1/36 Batch 900/7662 eta: 2 days, 11:36:52.063816	Training Loss1 21.9628 (22.6485)	Training Total_Loss 21.9628 (22.6485)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.000)	
2022-07-06 17:44:08,291: ============================================================
2022-07-06 17:45:25,954: time cost, forward:0.011481027584056835, backward:0.03423173577935846, data cost:0.7326169309912024 
2022-07-06 17:45:25,954: ============================================================
2022-07-06 17:45:25,954: Epoch 1/36 Batch 1000/7662 eta: 2 days, 11:17:24.085804	Training Loss1 22.9582 (22.6246)	Training Total_Loss 22.9582 (22.6246)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.000)	
2022-07-06 17:45:25,954: ============================================================
2022-07-06 17:46:44,461: time cost, forward:0.011419360262356204, backward:0.03416090167794475, data cost:0.7333182019467133 
2022-07-06 17:46:44,461: ============================================================
2022-07-06 17:46:44,461: Epoch 1/36 Batch 1100/7662 eta: 2 days, 11:54:44.744304	Training Loss1 29.5520 (22.9085)	Training Total_Loss 29.5520 (22.9085)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.000)	
2022-07-06 17:46:44,462: ============================================================
2022-07-06 17:48:02,608: time cost, forward:0.011343420695224536, backward:0.03410626352579023, data cost:0.7335758149574159 
2022-07-06 17:48:02,608: ============================================================
2022-07-06 17:48:02,608: Epoch 1/36 Batch 1200/7662 eta: 2 days, 11:36:56.530099	Training Loss1 33.7505 (23.7691)	Training Total_Loss 33.7505 (23.7691)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.000)	
2022-07-06 17:48:02,608: ============================================================
2022-07-06 17:49:20,435: time cost, forward:0.011275929428229798, backward:0.034074767173667246, data cost:0.7335594520833145 
2022-07-06 17:49:20,436: ============================================================
2022-07-06 17:49:20,436: Epoch 1/36 Batch 1300/7662 eta: 2 days, 11:21:02.864018	Training Loss1 32.4271 (24.5798)	Training Total_Loss 32.4271 (24.5798)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.000)	
2022-07-06 17:49:20,436: ============================================================
2022-07-06 17:50:37,632: time cost, forward:0.011234519820796157, backward:0.033957892609460597, data cost:0.7332203074639997 
2022-07-06 17:50:37,632: ============================================================
2022-07-06 17:50:37,632: Epoch 1/36 Batch 1400/7662 eta: 2 days, 10:50:52.430236	Training Loss1 28.1195 (24.9470)	Training Total_Loss 28.1195 (24.9470)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.000)	
2022-07-06 17:50:37,632: ============================================================
2022-07-06 17:51:56,042: time cost, forward:0.011212665291926795, backward:0.03385187483692742, data cost:0.7336853180351537 
2022-07-06 17:51:56,043: ============================================================
2022-07-06 17:51:56,043: Epoch 1/36 Batch 1500/7662 eta: 2 days, 11:45:06.395117	Training Loss1 26.6562 (25.0843)	Training Total_Loss 26.6562 (25.0843)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.000)	
2022-07-06 17:51:56,043: ============================================================
2022-07-06 17:53:13,742: time cost, forward:0.011170838757408194, backward:0.03379326674847248, data cost:0.7335687596176176 
2022-07-06 17:53:13,743: ============================================================
2022-07-06 17:53:13,743: Epoch 1/36 Batch 1600/7662 eta: 2 days, 11:11:18.486036	Training Loss1 25.2878 (25.0973)	Training Total_Loss 25.2878 (25.0973)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.000)	
2022-07-06 17:53:13,743: ============================================================
2022-07-06 17:54:31,598: time cost, forward:0.011158364039438482, backward:0.03374849002876304, data cost:0.7336662108930438 
2022-07-06 17:54:31,599: ============================================================
2022-07-06 17:54:31,599: Epoch 1/36 Batch 1700/7662 eta: 2 days, 11:17:09.462182	Training Loss1 23.8145 (25.0511)	Training Total_Loss 23.8145 (25.0511)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.000)	
2022-07-06 17:54:31,599: ============================================================
2022-07-06 17:55:48,719: time cost, forward:0.011166263249531396, backward:0.03372294588709222, data cost:0.733233137353385 
2022-07-06 17:55:48,720: ============================================================
2022-07-06 17:55:48,720: Epoch 1/36 Batch 1800/7662 eta: 2 days, 10:42:16.372660	Training Loss1 23.6828 (24.9764)	Training Total_Loss 23.6828 (24.9764)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.000)	
2022-07-06 17:55:48,720: ============================================================
2022-07-06 17:57:04,569: time cost, forward:0.011260544268189763, backward:0.033755349635826784, data cost:0.7320481651139422 
2022-07-06 17:57:04,569: ============================================================
2022-07-06 17:57:04,569: Epoch 1/36 Batch 1900/7662 eta: 2 days, 9:42:57.009218	Training Loss1 22.9045 (24.8830)	Training Total_Loss 22.9045 (24.8830)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.000)	
2022-07-06 17:57:04,569: ============================================================
2022-07-06 17:58:20,376: time cost, forward:0.011311109093441374, backward:0.03372537058076005, data cost:0.73104680878571 
2022-07-06 17:58:20,377: ============================================================
2022-07-06 17:58:20,377: Epoch 1/36 Batch 2000/7662 eta: 2 days, 9:39:46.244953	Training Loss1 23.2323 (24.7834)	Training Total_Loss 23.2323 (24.7834)	Training Prec@1 0.000 (0.000)	Training Prec@5 0.000 (0.000)	
2022-07-06 17:58:20,377: ============================================================
2022-07-06 17:59:36,120: time cost, forward:0.011389069582179025, backward:0.033721695859526495, data cost:0.7300489959744058 
2022-07-06 17:59:36,120: ============================================================
2022-07-06 17:59:36,121: Epoch 1/36 Batch 2100/7662 eta: 2 days, 9:35:35.675343	Training Loss1 22.6614 (24.6824)	Training Total_Loss 22.6614 (24.6824)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.000)	
2022-07-06 17:59:36,121: ============================================================
2022-07-06 18:00:53,525: time cost, forward:0.011472064617169125, backward:0.033754058077206335, data cost:0.729851757520543 
2022-07-06 18:00:53,525: ============================================================
2022-07-06 18:00:53,525: Epoch 1/36 Batch 2200/7662 eta: 2 days, 10:50:04.154385	Training Loss1 22.5730 (24.5827)	Training Total_Loss 22.5730 (24.5827)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.000)	
2022-07-06 18:00:53,525: ============================================================
2022-07-06 18:02:09,239: time cost, forward:0.011525801753624464, backward:0.03375381301309088, data cost:0.7289876352968088 
2022-07-06 18:02:09,239: ============================================================
2022-07-06 18:02:09,240: Epoch 1/36 Batch 2300/7662 eta: 2 days, 9:31:43.801421	Training Loss1 22.3854 (24.4873)	Training Total_Loss 22.3854 (24.4873)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.000)	
2022-07-06 18:02:09,240: ============================================================
2022-07-06 18:03:25,487: time cost, forward:0.01153825699860675, backward:0.033737221276973775, data cost:0.7284790497613282 
2022-07-06 18:03:25,488: ============================================================
2022-07-06 18:03:25,488: Epoch 1/36 Batch 2400/7662 eta: 2 days, 9:54:47.822682	Training Loss1 22.2038 (24.3961)	Training Total_Loss 22.2038 (24.3961)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.000)	
2022-07-06 18:03:25,488: ============================================================
2022-07-06 18:04:41,690: time cost, forward:0.011554853588927026, backward:0.03371999825702376, data cost:0.7279893583944198 
2022-07-06 18:04:41,691: ============================================================
2022-07-06 18:04:41,691: Epoch 1/36 Batch 2500/7662 eta: 2 days, 9:51:28.497496	Training Loss1 22.2052 (24.3094)	Training Total_Loss 22.2052 (24.3094)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.000)	
2022-07-06 18:04:41,691: ============================================================
2022-07-06 18:05:58,201: time cost, forward:0.011581089185631794, backward:0.03371750459894853, data cost:0.7276225434032115 
2022-07-06 18:05:58,202: ============================================================
2022-07-06 18:05:58,202: Epoch 1/36 Batch 2600/7662 eta: 2 days, 10:04:12.786421	Training Loss1 22.3025 (24.2268)	Training Total_Loss 22.3025 (24.2268)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.000)	
2022-07-06 18:05:58,202: ============================================================
2022-07-06 18:07:15,019: time cost, forward:0.011607342801654106, backward:0.03371337309021471, data cost:0.7273885934341391 
2022-07-06 18:07:15,020: ============================================================
2022-07-06 18:07:15,020: Epoch 1/36 Batch 2700/7662 eta: 2 days, 10:16:56.063545	Training Loss1 22.2755 (24.1485)	Training Total_Loss 22.2755 (24.1485)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.000)	
2022-07-06 18:07:15,020: ============================================================
2022-07-06 18:08:32,528: time cost, forward:0.011618692391938336, backward:0.03368734401990448, data cost:0.727480582826348 
2022-07-06 18:08:32,528: ============================================================
2022-07-06 18:08:32,528: Epoch 1/36 Batch 2800/7662 eta: 2 days, 10:47:03.216088	Training Loss1 22.0615 (24.0735)	Training Total_Loss 22.0615 (24.0735)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.000)	
2022-07-06 18:08:32,528: ============================================================
2022-07-06 18:09:48,100: time cost, forward:0.011644747060675094, backward:0.033679564519765746, data cost:0.7268498993281786 
2022-07-06 18:09:48,117: ============================================================
2022-07-06 18:09:48,117: Epoch 1/36 Batch 2900/7662 eta: 2 days, 9:18:26.082453	Training Loss1 21.9049 (24.0040)	Training Total_Loss 21.9049 (24.0040)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.000)	
2022-07-06 18:09:48,117: ============================================================
2022-07-06 18:11:04,222: time cost, forward:0.011664655853327452, backward:0.03368765801419891, data cost:0.7264296983869603 
2022-07-06 18:11:04,223: ============================================================
2022-07-06 18:11:04,223: Epoch 1/36 Batch 3000/7662 eta: 2 days, 9:40:42.010281	Training Loss1 22.1824 (23.9384)	Training Total_Loss 22.1824 (23.9384)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.000)	
2022-07-06 18:11:04,223: ============================================================
2022-07-06 18:12:20,299: time cost, forward:0.011710965275649065, backward:0.03370033552201189, data cost:0.7260023521276857 
2022-07-06 18:12:20,299: ============================================================
2022-07-06 18:12:20,300: Epoch 1/36 Batch 3100/7662 eta: 2 days, 9:38:06.531435	Training Loss1 21.9826 (23.8760)	Training Total_Loss 21.9826 (23.8760)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.000)	
2022-07-06 18:12:20,300: ============================================================
2022-07-06 18:13:36,003: time cost, forward:0.011726434620591617, backward:0.03370561052687878, data cost:0.7255129852157788 
2022-07-06 18:13:36,004: ============================================================
2022-07-06 18:13:36,004: Epoch 1/36 Batch 3200/7662 eta: 2 days, 9:19:55.164022	Training Loss1 22.0357 (23.8174)	Training Total_Loss 22.0357 (23.8174)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.000)	
2022-07-06 18:13:36,004: ============================================================
2022-07-06 18:14:51,720: time cost, forward:0.011756848840866713, backward:0.033703512768197615, data cost:0.7250413951746584 
2022-07-06 18:14:51,720: ============================================================
2022-07-06 18:14:51,720: Epoch 1/36 Batch 3300/7662 eta: 2 days, 9:19:12.235290	Training Loss1 21.9723 (23.7618)	Training Total_Loss 21.9723 (23.7618)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.000)	
2022-07-06 18:14:51,721: ============================================================
2022-07-06 18:16:09,056: time cost, forward:0.011796873714966646, backward:0.03370981056502932, data cost:0.7250590990065967 
2022-07-06 18:16:09,057: ============================================================
2022-07-06 18:16:09,057: Epoch 1/36 Batch 3400/7662 eta: 2 days, 10:31:30.682716	Training Loss1 21.8831 (23.7089)	Training Total_Loss 21.8831 (23.7089)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.000)	
2022-07-06 18:16:09,057: ============================================================
2022-07-06 18:17:26,177: time cost, forward:0.01181438017586498, backward:0.03369996042788523, data cost:0.7250442416302032 
2022-07-06 18:17:26,177: ============================================================
2022-07-06 18:17:26,178: Epoch 1/36 Batch 3500/7662 eta: 2 days, 10:20:24.226730	Training Loss1 21.9525 (23.6589)	Training Total_Loss 21.9525 (23.6589)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.000)	
2022-07-06 18:17:26,178: ============================================================
2022-07-06 18:18:42,958: time cost, forward:0.011828679580031318, backward:0.0337004962978379, data cost:0.7249409719850328 
2022-07-06 18:18:42,990: ============================================================
2022-07-06 18:18:42,990: Epoch 1/36 Batch 3600/7662 eta: 2 days, 10:05:09.505998	Training Loss1 21.9657 (23.6116)	Training Total_Loss 21.9657 (23.6116)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.000)	
2022-07-06 18:18:42,990: ============================================================
2022-07-06 18:20:00,815: time cost, forward:0.011851165126419996, backward:0.033676895975389816, data cost:0.7251416802180719 
2022-07-06 18:20:00,815: ============================================================
2022-07-06 18:20:00,815: Epoch 1/36 Batch 3700/7662 eta: 2 days, 10:49:47.450284	Training Loss1 21.8587 (23.5661)	Training Total_Loss 21.8587 (23.5661)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.000)	
2022-07-06 18:20:00,815: ============================================================
2022-07-06 18:21:16,589: time cost, forward:0.011852799104558508, backward:0.03367216827430735, data cost:0.724793098198172 
2022-07-06 18:21:16,590: ============================================================
2022-07-06 18:21:16,590: Epoch 1/36 Batch 3800/7662 eta: 2 days, 9:15:32.371701	Training Loss1 21.9590 (23.5220)	Training Total_Loss 21.9590 (23.5220)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.000)	
2022-07-06 18:21:16,590: ============================================================
2022-07-06 18:22:32,400: time cost, forward:0.011872213967306915, backward:0.03367240357380642, data cost:0.7244407594372108 
2022-07-06 18:22:32,401: ============================================================
2022-07-06 18:22:32,401: Epoch 1/36 Batch 3900/7662 eta: 2 days, 9:15:54.697725	Training Loss1 21.8915 (23.4790)	Training Total_Loss 21.8915 (23.4790)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.000)	
2022-07-06 18:22:32,401: ============================================================
2022-07-06 18:23:49,178: time cost, forward:0.011886577720670708, backward:0.03367489181360205, data cost:0.7243570664966962 
2022-07-06 18:23:49,178: ============================================================
2022-07-06 18:23:49,178: Epoch 1/36 Batch 4000/7662 eta: 2 days, 9:58:26.970202	Training Loss1 21.7420 (23.4374)	Training Total_Loss 21.7420 (23.4374)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.000)	
2022-07-06 18:23:49,179: ============================================================
2022-07-06 18:25:04,347: time cost, forward:0.011877952828352613, backward:0.033675062740741925, data cost:0.7239026972130177 
2022-07-06 18:25:04,347: ============================================================
2022-07-06 18:25:04,348: Epoch 1/36 Batch 4100/7662 eta: 2 days, 8:44:19.627036	Training Loss1 21.8159 (23.3970)	Training Total_Loss 21.8159 (23.3970)	Training Prec@1 0.000 (0.001)	Training Prec@5 0.000 (0.000)	
2022-07-06 18:25:04,348: ============================================================
2022-07-06 18:26:19,344: time cost, forward:0.011886036376153665, backward:0.03366655791251538, data cost:0.7234212928625707 
2022-07-06 18:26:19,344: ============================================================
2022-07-06 18:26:19,344: Epoch 1/36 Batch 4200/7662 eta: 2 days, 8:35:16.000606	Training Loss1 21.7065 (23.3576)	Training Total_Loss 21.7065 (23.3576)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.000)	
2022-07-06 18:26:19,345: ============================================================
2022-07-06 18:27:35,859: time cost, forward:0.011887193031160186, backward:0.033672494926017836, data cost:0.7233150495598831 
2022-07-06 18:27:35,859: ============================================================
2022-07-06 18:27:35,860: Epoch 1/36 Batch 4300/7662 eta: 2 days, 9:42:43.693404	Training Loss1 21.6126 (23.3192)	Training Total_Loss 21.6126 (23.3192)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.000)	
2022-07-06 18:27:35,860: ============================================================
2022-07-06 18:28:51,761: time cost, forward:0.011883328464470768, backward:0.0336530743525445, data cost:0.7230937095576184 
2022-07-06 18:28:51,783: ============================================================
2022-07-06 18:28:51,783: Epoch 1/36 Batch 4400/7662 eta: 2 days, 9:14:41.890159	Training Loss1 21.6160 (23.2816)	Training Total_Loss 21.6160 (23.2816)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.000)	
2022-07-06 18:28:51,783: ============================================================
2022-07-06 18:30:07,599: time cost, forward:0.011910196833410219, backward:0.033655970699126306, data cost:0.7228229681262177 
2022-07-06 18:30:07,599: ============================================================
2022-07-06 18:30:07,599: Epoch 1/36 Batch 4500/7662 eta: 2 days, 9:08:33.573651	Training Loss1 21.7626 (23.2450)	Training Total_Loss 21.7626 (23.2450)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.000)	
2022-07-06 18:30:07,599: ============================================================
2022-07-06 18:31:24,424: time cost, forward:0.011919950500574546, backward:0.033652063348184956, data cost:0.7227954727640669 
2022-07-06 18:31:24,424: ============================================================
2022-07-06 18:31:24,424: Epoch 1/36 Batch 4600/7662 eta: 2 days, 9:52:55.112574	Training Loss1 21.5560 (23.2092)	Training Total_Loss 21.5560 (23.2092)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.000)	
2022-07-06 18:31:24,424: ============================================================
2022-07-06 18:32:40,615: time cost, forward:0.011917203607699241, backward:0.033648371924793856, data cost:0.722661638442545 
2022-07-06 18:32:40,615: ============================================================
2022-07-06 18:32:40,616: Epoch 1/36 Batch 4700/7662 eta: 2 days, 9:22:59.907171	Training Loss1 21.6627 (23.1742)	Training Total_Loss 21.6627 (23.1742)	Training Prec@1 0.000 (0.002)	Training Prec@5 0.000 (0.000)	
2022-07-06 18:32:40,616: ============================================================
2022-07-06 18:33:56,898: time cost, forward:0.011939843015438269, backward:0.03365419635824373, data cost:0.7225078473763805 
2022-07-06 18:33:56,898: ============================================================
2022-07-06 18:33:56,899: Epoch 1/36 Batch 4800/7662 eta: 2 days, 9:25:52.056843	Training Loss1 21.5123 (23.1400)	Training Total_Loss 21.5123 (23.1400)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.000)	
2022-07-06 18:33:56,899: ============================================================
2022-07-06 18:35:13,175: time cost, forward:0.011944160288172027, backward:0.033637468219655076, data cost:0.7224000663410817 
2022-07-06 18:35:13,175: ============================================================
2022-07-06 18:35:13,176: Epoch 1/36 Batch 4900/7662 eta: 2 days, 9:24:19.634039	Training Loss1 21.5171 (23.1060)	Training Total_Loss 21.5171 (23.1060)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.000)	
2022-07-06 18:35:13,176: ============================================================
2022-07-06 18:36:30,345: time cost, forward:0.011933119350920965, backward:0.03363212405931809, data cost:0.7224786467112453 
2022-07-06 18:36:30,346: ============================================================
2022-07-06 18:36:30,346: Epoch 1/36 Batch 5000/7662 eta: 2 days, 10:03:22.326091	Training Loss1 21.4404 (23.0727)	Training Total_Loss 21.4404 (23.0727)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.000)	
2022-07-06 18:36:30,346: ============================================================
2022-07-06 18:37:45,655: time cost, forward:0.011916872145358571, backward:0.03362598973738257, data cost:0.7221928556939391 
2022-07-06 18:37:45,655: ============================================================
2022-07-06 18:37:45,655: Epoch 1/36 Batch 5100/7662 eta: 2 days, 8:38:06.895296	Training Loss1 21.2828 (23.0401)	Training Total_Loss 21.2828 (23.0401)	Training Prec@1 0.000 (0.003)	Training Prec@5 0.000 (0.000)	
2022-07-06 18:37:45,655: ============================================================
2022-07-06 18:39:02,494: time cost, forward:0.011918781857968385, backward:0.03360689812198146, data cost:0.7222152494609206 
2022-07-06 18:39:02,495: ============================================================
2022-07-06 18:39:02,495: Epoch 1/36 Batch 5200/7662 eta: 2 days, 9:45:54.099512	Training Loss1 21.2904 (23.0076)	Training Total_Loss 21.2904 (23.0076)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.000)	
2022-07-06 18:39:02,495: ============================================================
2022-07-06 18:40:19,485: time cost, forward:0.011932558058612548, backward:0.03360877209821947, data cost:0.7222245371235971 
2022-07-06 18:40:19,485: ============================================================
2022-07-06 18:40:19,485: Epoch 1/36 Batch 5300/7662 eta: 2 days, 9:51:24.595773	Training Loss1 21.1840 (22.9761)	Training Total_Loss 21.1840 (22.9761)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.000)	
2022-07-06 18:40:19,486: ============================================================
2022-07-06 18:41:35,065: time cost, forward:0.01193704908038537, backward:0.033604579714630066, data cost:0.7219913088407621 
2022-07-06 18:41:35,065: ============================================================
2022-07-06 18:41:35,066: Epoch 1/36 Batch 5400/7662 eta: 2 days, 8:46:33.478479	Training Loss1 21.1456 (22.9447)	Training Total_Loss 21.1456 (22.9447)	Training Prec@1 0.000 (0.004)	Training Prec@5 0.000 (0.000)	
2022-07-06 18:41:35,066: ============================================================
2022-07-06 18:42:52,615: time cost, forward:0.01194557477656571, backward:0.03359161309490075, data cost:0.7221306466388581 
2022-07-06 18:42:52,616: ============================================================
2022-07-06 18:42:52,616: Epoch 1/36 Batch 5500/7662 eta: 2 days, 10:14:04.333195	Training Loss1 21.2629 (22.9138)	Training Total_Loss 21.2629 (22.9138)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.000)	
2022-07-06 18:42:52,616: ============================================================
2022-07-06 18:44:09,891: time cost, forward:0.011943319776820846, backward:0.03358746524537583, data cost:0.7222145575458481 
2022-07-06 18:44:09,891: ============================================================
2022-07-06 18:44:09,892: Epoch 1/36 Batch 5600/7662 eta: 2 days, 10:00:24.088918	Training Loss1 21.1699 (22.8828)	Training Total_Loss 21.1699 (22.8828)	Training Prec@1 0.000 (0.005)	Training Prec@5 0.000 (0.000)	
2022-07-06 18:44:09,892: ============================================================
2022-07-06 18:45:26,117: time cost, forward:0.011944626063333309, backward:0.033584388353716264, data cost:0.7221058572587433 
2022-07-06 18:45:26,118: ============================================================
2022-07-06 18:45:26,118: Epoch 1/36 Batch 5700/7662 eta: 2 days, 9:11:52.455387	Training Loss1 21.0462 (22.8525)	Training Total_Loss 21.0462 (22.8525)	Training Prec@1 0.000 (0.006)	Training Prec@5 0.000 (0.000)	
2022-07-06 18:45:26,118: ============================================================
2022-07-06 18:46:42,763: time cost, forward:0.011964898784523649, backward:0.033584935518354564, data cost:0.7220548493920945 
2022-07-06 18:46:42,764: ============================================================
2022-07-06 18:46:42,764: Epoch 1/36 Batch 5800/7662 eta: 2 days, 9:29:30.010555	Training Loss1 21.1169 (22.8218)	Training Total_Loss 21.1169 (22.8218)	Training Prec@1 0.000 (0.007)	Training Prec@5 0.000 (0.000)	
2022-07-06 18:46:42,764: ============================================================
2022-07-06 18:47:58,099: time cost, forward:0.011967024372318757, backward:0.03358296673870588, data cost:0.7218079051641635 
2022-07-06 18:47:58,100: ============================================================
2022-07-06 18:47:58,100: Epoch 1/36 Batch 5900/7662 eta: 2 days, 8:29:15.897156	Training Loss1 21.0757 (22.7912)	Training Total_Loss 21.0757 (22.7912)	Training Prec@1 0.000 (0.008)	Training Prec@5 0.000 (0.000)	
2022-07-06 18:47:58,100: ============================================================
2022-07-06 18:49:14,024: time cost, forward:0.011961755563386542, backward:0.033579803820669024, data cost:0.7216685681089517 
2022-07-06 18:49:14,024: ============================================================
2022-07-06 18:49:14,024: Epoch 1/36 Batch 6000/7662 eta: 2 days, 8:54:29.779367	Training Loss1 20.9144 (22.7603)	Training Total_Loss 20.9144 (22.7603)	Training Prec@1 0.195 (0.010)	Training Prec@5 0.000 (0.000)	
2022-07-06 18:49:14,025: ============================================================
2022-07-06 18:50:31,030: time cost, forward:0.011985587104263219, backward:0.03356259919557635, data cost:0.7216982968538819 
2022-07-06 18:50:31,030: ============================================================
2022-07-06 18:50:31,031: Epoch 1/36 Batch 6100/7662 eta: 2 days, 9:41:51.639763	Training Loss1 20.6111 (22.7292)	Training Total_Loss 20.6111 (22.7292)	Training Prec@1 0.586 (0.011)	Training Prec@5 0.000 (0.000)	
2022-07-06 18:50:31,031: ============================================================
2022-07-06 18:51:47,939: time cost, forward:0.011989345933606805, backward:0.03356673683268656, data cost:0.7217093964779948 
2022-07-06 18:51:47,939: ============================================================
2022-07-06 18:51:47,940: Epoch 1/36 Batch 6200/7662 eta: 2 days, 9:36:11.489613	Training Loss1 20.6615 (22.6972)	Training Total_Loss 20.6615 (22.6972)	Training Prec@1 0.195 (0.014)	Training Prec@5 0.000 (0.000)	
2022-07-06 18:51:47,940: ============================================================
2022-07-06 18:53:03,731: time cost, forward:0.011989539304334487, backward:0.03355471549251379, data cost:0.7215613804084571 
2022-07-06 18:53:03,732: ============================================================
2022-07-06 18:53:03,732: Epoch 1/36 Batch 6300/7662 eta: 2 days, 8:44:45.022795	Training Loss1 20.6278 (22.6647)	Training Total_Loss 20.6278 (22.6647)	Training Prec@1 0.391 (0.017)	Training Prec@5 0.000 (0.000)	
2022-07-06 18:53:03,732: ============================================================
2022-07-06 18:54:18,707: time cost, forward:0.011990620989709334, backward:0.033533104026032566, data cost:0.7213077678924837 
2022-07-06 18:54:18,707: ============================================================
2022-07-06 18:54:18,707: Epoch 1/36 Batch 6400/7662 eta: 2 days, 8:06:48.144360	Training Loss1 20.5002 (22.6317)	Training Total_Loss 20.5002 (22.6317)	Training Prec@1 0.195 (0.021)	Training Prec@5 0.000 (0.000)	
2022-07-06 18:54:18,707: ============================================================
2022-07-06 18:55:35,377: time cost, forward:0.011999917004654675, backward:0.0335185712329203, data cost:0.7212930058750634 
2022-07-06 18:55:35,377: ============================================================
2022-07-06 18:55:35,377: Epoch 1/36 Batch 6500/7662 eta: 2 days, 9:21:38.643224	Training Loss1 20.3102 (22.5980)	Training Total_Loss 20.3102 (22.5980)	Training Prec@1 0.000 (0.026)	Training Prec@5 0.000 (0.000)	
2022-07-06 18:55:35,378: ============================================================
2022-07-06 18:56:52,582: time cost, forward:0.012005651515620209, backward:0.0335166468044396, data cost:0.7213622720553344 
2022-07-06 18:56:52,583: ============================================================
2022-07-06 18:56:52,583: Epoch 1/36 Batch 6600/7662 eta: 2 days, 9:44:22.628308	Training Loss1 20.1698 (22.5631)	Training Total_Loss 20.1698 (22.5631)	Training Prec@1 0.586 (0.033)	Training Prec@5 0.000 (0.000)	
2022-07-06 18:56:52,583: ============================================================
2022-07-06 18:58:09,134: time cost, forward:0.012009434423120649, backward:0.033508498520259625, data cost:0.7213178833734991 
2022-07-06 18:58:09,135: ============================================================
2022-07-06 18:58:09,135: Epoch 1/36 Batch 6700/7662 eta: 2 days, 9:13:46.248969	Training Loss1 20.0303 (22.5271)	Training Total_Loss 20.0303 (22.5271)	Training Prec@1 0.781 (0.041)	Training Prec@5 0.000 (0.000)	
2022-07-06 18:58:09,135: ============================================================
2022-07-06 18:59:25,710: time cost, forward:0.012021751469734013, backward:0.03349835459914939, data cost:0.7213078380805777 
2022-07-06 18:59:25,710: ============================================================
2022-07-06 18:59:25,710: Epoch 1/36 Batch 6800/7662 eta: 2 days, 9:13:33.663208	Training Loss1 20.0361 (22.4913)	Training Total_Loss 20.0361 (22.4913)	Training Prec@1 0.195 (0.050)	Training Prec@5 0.000 (0.000)	
2022-07-06 18:59:25,711: ============================================================
2022-07-06 19:00:43,037: time cost, forward:0.012027347860240923, backward:0.03349502882519949, data cost:0.7213678577012265 
2022-07-06 19:00:43,037: ============================================================
2022-07-06 19:00:43,037: Epoch 1/36 Batch 6900/7662 eta: 2 days, 9:45:57.795001	Training Loss1 20.0902 (22.4545)	Training Total_Loss 20.0902 (22.4545)	Training Prec@1 0.586 (0.061)	Training Prec@5 0.000 (0.000)	
2022-07-06 19:00:43,038: ============================================================
2022-07-06 19:01:59,451: time cost, forward:0.012040946122185982, backward:0.033488450620596466, data cost:0.7213387798625991 
2022-07-06 19:01:59,452: ============================================================
2022-07-06 19:01:59,452: Epoch 1/36 Batch 7000/7662 eta: 2 days, 9:03:47.601729	Training Loss1 19.7497 (22.4168)	Training Total_Loss 19.7497 (22.4168)	Training Prec@1 1.172 (0.075)	Training Prec@5 0.000 (0.000)	
2022-07-06 19:01:59,452: ============================================================
2022-07-06 19:03:16,387: time cost, forward:0.012060868301799994, backward:0.0334813537388087, data cost:0.7213484219958 
2022-07-06 19:03:16,387: ============================================================
2022-07-06 19:03:16,387: Epoch 1/36 Batch 7100/7662 eta: 2 days, 9:25:49.907028	Training Loss1 19.5342 (22.3785)	Training Total_Loss 19.5342 (22.3785)	Training Prec@1 1.562 (0.092)	Training Prec@5 0.000 (0.000)	
2022-07-06 19:03:16,387: ============================================================
2022-07-06 19:04:32,762: time cost, forward:0.012064604647276484, backward:0.03348101574706607, data cost:0.721294065435192 
2022-07-06 19:04:32,762: ============================================================
2022-07-06 19:04:32,762: Epoch 1/36 Batch 7200/7662 eta: 2 days, 8:59:28.705455	Training Loss1 19.3330 (22.3392)	Training Total_Loss 19.3330 (22.3392)	Training Prec@1 2.539 (0.111)	Training Prec@5 0.000 (0.000)	
2022-07-06 19:04:32,762: ============================================================
2022-07-06 19:05:49,704: time cost, forward:0.012071581699534923, backward:0.03347816149132401, data cost:0.7213135323862226 
2022-07-06 19:05:49,704: ============================================================
2022-07-06 19:05:49,705: Epoch 1/36 Batch 7300/7662 eta: 2 days, 9:23:35.797037	Training Loss1 19.2901 (22.2991)	Training Total_Loss 19.2901 (22.2991)	Training Prec@1 2.734 (0.135)	Training Prec@5 0.000 (0.000)	
2022-07-06 19:05:49,705: ============================================================
2022-07-06 19:07:06,146: time cost, forward:0.012070478112460117, backward:0.03346792687143985, data cost:0.7212850516801719 
2022-07-06 19:07:06,146: ============================================================
2022-07-06 19:07:06,147: Epoch 1/36 Batch 7400/7662 eta: 2 days, 8:59:55.317467	Training Loss1 19.2863 (22.2580)	Training Total_Loss 19.2863 (22.2580)	Training Prec@1 1.953 (0.164)	Training Prec@5 0.000 (0.000)	
2022-07-06 19:07:06,147: ============================================================
2022-07-06 19:08:22,831: time cost, forward:0.0120830429062905, backward:0.03347047199677079, data cost:0.721261813109963 
2022-07-06 19:08:22,831: ============================================================
2022-07-06 19:08:22,831: Epoch 1/36 Batch 7500/7662 eta: 2 days, 9:09:30.459724	Training Loss1 19.2348 (22.2156)	Training Total_Loss 19.2348 (22.2156)	Training Prec@1 3.516 (0.201)	Training Prec@5 0.000 (0.000)	
2022-07-06 19:08:22,831: ============================================================
2022-07-06 19:09:39,489: time cost, forward:0.01208368952861976, backward:0.03346236499771819, data cost:0.7212405163357957 
2022-07-06 19:09:39,490: ============================================================
2022-07-06 19:09:39,490: Epoch 1/36 Batch 7600/7662 eta: 2 days, 9:07:03.755515	Training Loss1 18.7049 (22.1725)	Training Total_Loss 18.7049 (22.1725)	Training Prec@1 4.102 (0.242)	Training Prec@5 0.000 (0.000)	
2022-07-06 19:09:39,490: ============================================================
2022-07-06 19:10:28,541: Epoch 1/36 Batch 7663/7662 eta: 2 days, 9:06:15.460575	Training Loss1 18.9991 (22.1453)	Training Total_Loss 18.9991 (22.1453)	Training Prec@1 4.297 (0.269)	Training Prec@5 0.000 (0.000)	
2022-07-06 19:10:28,541: ============================================================
2022-07-06 19:11:46,397: time cost, forward:0.011188738273851799, backward:0.033572040422998294, data cost:0.7328756409462052 
2022-07-06 19:11:46,398: ============================================================
2022-07-06 19:11:46,398: Epoch 2/36 Batch 100/7662 eta: 2 days, 9:52:44.836571	Training Loss1 18.3838 (18.5137)	Training Total_Loss 18.3838 (18.5137)	Training Prec@1 4.688 (5.056)	Training Prec@5 0.000 (0.000)	
2022-07-06 19:11:46,398: ============================================================
2022-07-06 19:13:01,168: time cost, forward:0.011305508302084764, backward:0.03268201147491608, data cost:0.719231635481868 
2022-07-06 19:13:01,169: ============================================================
2022-07-06 19:13:01,169: Epoch 2/36 Batch 200/7662 eta: 2 days, 7:39:24.618526	Training Loss1 18.3028 (18.4829)	Training Total_Loss 18.3028 (18.4829)	Training Prec@1 6.836 (5.191)	Training Prec@5 0.000 (0.000)	
2022-07-06 19:13:01,169: ============================================================
2022-07-06 19:14:17,453: time cost, forward:0.011226047241568166, backward:0.032782982823043365, data cost:0.7189699327666624 
2022-07-06 19:14:17,454: ============================================================
2022-07-06 19:14:17,454: Epoch 2/36 Batch 300/7662 eta: 2 days, 8:45:45.250160	Training Loss1 18.4968 (18.4300)	Training Total_Loss 18.4968 (18.4300)	Training Prec@1 5.859 (5.433)	Training Prec@5 0.000 (0.000)	
2022-07-06 19:14:17,454: ============================================================
2022-07-06 19:15:33,524: time cost, forward:0.011071622819828809, backward:0.033095529503690865, data cost:0.7180631268293338 
2022-07-06 19:15:33,524: ============================================================
2022-07-06 19:15:33,525: Epoch 2/36 Batch 400/7662 eta: 2 days, 8:34:55.815287	Training Loss1 18.0747 (18.3800)	Training Total_Loss 18.0747 (18.3800)	Training Prec@1 8.008 (5.714)	Training Prec@5 0.000 (0.000)	
2022-07-06 19:15:33,525: ============================================================
2022-07-06 19:16:49,022: time cost, forward:0.011074155987145189, backward:0.03311649878660519, data cost:0.7165097698181091 
2022-07-06 19:16:49,022: ============================================================
2022-07-06 19:16:49,023: Epoch 2/36 Batch 500/7662 eta: 2 days, 8:08:06.135182	Training Loss1 18.1344 (18.3183)	Training Total_Loss 18.1344 (18.3183)	Training Prec@1 6.445 (6.002)	Training Prec@5 0.000 (0.000)	
2022-07-06 19:16:49,023: ============================================================
2022-07-06 19:18:04,670: time cost, forward:0.011141001282629863, backward:0.03296838578875355, data cost:0.7157932904009429 
2022-07-06 19:18:04,670: ============================================================
2022-07-06 19:18:04,670: Epoch 2/36 Batch 600/7662 eta: 2 days, 8:13:31.336903	Training Loss1 18.1537 (18.2529)	Training Total_Loss 18.1537 (18.2529)	Training Prec@1 8.398 (6.396)	Training Prec@5 0.000 (0.000)	
2022-07-06 19:18:04,670: ============================================================
2022-07-06 19:19:19,305: time cost, forward:0.011105333104495156, backward:0.03299340430929596, data cost:0.7137668381774204 
2022-07-06 19:19:19,305: ============================================================
2022-07-06 19:19:19,306: Epoch 2/36 Batch 700/7662 eta: 2 days, 7:27:07.758819	Training Loss1 17.5017 (18.1809)	Training Total_Loss 17.5017 (18.1809)	Training Prec@1 9.961 (6.822)	Training Prec@5 0.000 (0.000)	
2022-07-06 19:19:19,306: ============================================================
2022-07-06 19:20:33,974: time cost, forward:0.01104098834442406, backward:0.03301478476637744, data cost:0.7122647908512731 
2022-07-06 19:20:33,974: ============================================================
2022-07-06 19:20:33,974: Epoch 2/36 Batch 800/7662 eta: 2 days, 7:27:22.275796	Training Loss1 17.5851 (18.1110)	Training Total_Loss 17.5851 (18.1110)	Training Prec@1 10.156 (7.265)	Training Prec@5 0.000 (0.000)	
2022-07-06 19:20:33,974: ============================================================
2022-07-06 19:21:51,026: time cost, forward:0.01100077963246652, backward:0.03305041750227914, data cost:0.7138467948879628 
2022-07-06 19:21:51,026: ============================================================
2022-07-06 19:21:51,026: Epoch 2/36 Batch 900/7662 eta: 2 days, 9:12:18.332235	Training Loss1 17.2494 (18.0426)	Training Total_Loss 17.2494 (18.0426)	Training Prec@1 9.375 (7.675)	Training Prec@5 0.000 (0.000)	
2022-07-06 19:21:51,027: ============================================================
2022-07-06 19:23:07,494: time cost, forward:0.01098778202488377, backward:0.03307448206721125, data cost:0.7143955533807581 
2022-07-06 19:23:07,494: ============================================================
2022-07-06 19:23:07,495: Epoch 2/36 Batch 1000/7662 eta: 2 days, 8:45:00.801031	Training Loss1 17.3029 (17.9667)	Training Total_Loss 17.3029 (17.9667)	Training Prec@1 12.500 (8.157)	Training Prec@5 0.000 (0.000)	
2022-07-06 19:23:07,495: ============================================================
2022-07-06 19:24:23,615: time cost, forward:0.010972668844748889, backward:0.033163407588677585, data cost:0.7145494922276949 
2022-07-06 19:24:23,616: ============================================================
2022-07-06 19:24:23,616: Epoch 2/36 Batch 1100/7662 eta: 2 days, 8:28:17.808191	Training Loss1 17.1915 (17.8902)	Training Total_Loss 17.1915 (17.8902)	Training Prec@1 12.695 (8.654)	Training Prec@5 0.000 (0.000)	
2022-07-06 19:24:23,616: ============================================================
2022-07-06 19:25:39,618: time cost, forward:0.010976832742189944, backward:0.0332169707761992, data cost:0.7145422371951017 
2022-07-06 19:25:39,618: ============================================================
2022-07-06 19:25:39,619: Epoch 2/36 Batch 1200/7662 eta: 2 days, 8:21:45.033519	Training Loss1 17.2034 (17.8135)	Training Total_Loss 17.2034 (17.8135)	Training Prec@1 17.188 (9.167)	Training Prec@5 0.000 (0.000)	
2022-07-06 19:25:39,619: ============================================================
2022-07-06 19:26:54,457: time cost, forward:0.011074050010581307, backward:0.033246794877555205, data cost:0.7135818700225102 
2022-07-06 19:26:54,457: ============================================================
2022-07-06 19:26:54,457: Epoch 2/36 Batch 1300/7662 eta: 2 days, 7:28:42.430915	Training Loss1 16.9363 (17.7405)	Training Total_Loss 16.9363 (17.7405)	Training Prec@1 14.648 (9.673)	Training Prec@5 0.000 (0.000)	
2022-07-06 19:26:54,457: ============================================================
2022-07-06 19:28:10,431: time cost, forward:0.01114137995831024, backward:0.033273338504652195, data cost:0.7135850070969729 
2022-07-06 19:28:10,432: ============================================================
2022-07-06 19:28:10,432: Epoch 2/36 Batch 1400/7662 eta: 2 days, 8:17:59.025304	Training Loss1 16.7635 (17.6665)	Training Total_Loss 16.7635 (17.6665)	Training Prec@1 16.406 (10.202)	Training Prec@5 0.000 (0.000)	
2022-07-06 19:28:10,432: ============================================================
2022-07-06 19:29:26,685: time cost, forward:0.011255581431423847, backward:0.0332529839076067, data cost:0.7137612243586178 
2022-07-06 19:29:26,685: ============================================================
2022-07-06 19:29:26,685: Epoch 2/36 Batch 1500/7662 eta: 2 days, 8:29:04.946681	Training Loss1 16.5742 (17.5949)	Training Total_Loss 16.5742 (17.5949)	Training Prec@1 17.383 (10.715)	Training Prec@5 0.000 (0.000)	
2022-07-06 19:29:26,685: ============================================================
2022-07-06 19:30:41,789: time cost, forward:0.011353698650548576, backward:0.03328498025623391, data cost:0.7131234244155168 
2022-07-06 19:30:41,790: ============================================================
2022-07-06 19:30:41,790: Epoch 2/36 Batch 1600/7662 eta: 2 days, 7:36:47.761912	Training Loss1 16.3027 (17.5189)	Training Total_Loss 16.3027 (17.5189)	Training Prec@1 19.922 (11.273)	Training Prec@5 0.000 (0.000)	
2022-07-06 19:30:41,790: ============================================================
2022-07-06 19:31:56,580: time cost, forward:0.011427196213046968, backward:0.033302318916522876, data cost:0.7124057655267115 
2022-07-06 19:31:56,580: ============================================================
2022-07-06 19:31:56,581: Epoch 2/36 Batch 1700/7662 eta: 2 days, 7:21:35.200805	Training Loss1 16.2928 (17.4418)	Training Total_Loss 16.2928 (17.4418)	Training Prec@1 19.141 (11.846)	Training Prec@5 0.000 (0.000)	
2022-07-06 19:31:56,581: ============================================================
2022-07-06 19:33:10,563: time cost, forward:0.011479099436956621, backward:0.03329865159824068, data cost:0.7113458596049844 
2022-07-06 19:33:10,563: ============================================================
2022-07-06 19:33:10,563: Epoch 2/36 Batch 1800/7662 eta: 2 days, 6:44:27.976084	Training Loss1 16.1869 (17.3672)	Training Total_Loss 16.1869 (17.3672)	Training Prec@1 19.727 (12.423)	Training Prec@5 0.000 (0.000)	
2022-07-06 19:33:10,563: ============================================================
2022-07-06 19:34:24,908: time cost, forward:0.011529522233413608, backward:0.033291649228337564, data cost:0.7106085460144573 
2022-07-06 19:34:24,908: ============================================================
2022-07-06 19:34:24,909: Epoch 2/36 Batch 1900/7662 eta: 2 days, 6:59:20.265681	Training Loss1 15.7247 (17.2905)	Training Total_Loss 15.7247 (17.2905)	Training Prec@1 26.562 (13.027)	Training Prec@5 0.000 (0.000)	
2022-07-06 19:34:24,909: ============================================================
2022-07-06 19:35:39,235: time cost, forward:0.011584923468928983, backward:0.033244582997255766, data cost:0.7099678275464713 
2022-07-06 19:35:39,235: ============================================================
2022-07-06 19:35:39,236: Epoch 2/36 Batch 2000/7662 eta: 2 days, 6:57:16.885912	Training Loss1 15.9042 (17.2163)	Training Total_Loss 15.9042 (17.2163)	Training Prec@1 23.828 (13.585)	Training Prec@5 0.000 (0.000)	
2022-07-06 19:35:39,236: ============================================================
2022-07-06 19:36:53,973: time cost, forward:0.011625978593431011, backward:0.03323715149987136, data cost:0.70947394591391 
2022-07-06 19:36:53,974: ============================================================
2022-07-06 19:36:53,974: Epoch 2/36 Batch 2100/7662 eta: 2 days, 7:14:17.170790	Training Loss1 15.7317 (17.1422)	Training Total_Loss 15.7317 (17.1422)	Training Prec@1 27.148 (14.159)	Training Prec@5 0.000 (0.000)	
2022-07-06 19:36:53,974: ============================================================
2022-07-06 19:38:08,698: time cost, forward:0.01166002421879996, backward:0.033236957886588744, data cost:0.7091453685821214 
2022-07-06 19:38:08,699: ============================================================
2022-07-06 19:38:08,699: Epoch 2/36 Batch 2200/7662 eta: 2 days, 7:12:26.813009	Training Loss1 15.5990 (17.0687)	Training Total_Loss 15.5990 (17.0687)	Training Prec@1 27.344 (14.739)	Training Prec@5 0.000 (0.000)	
2022-07-06 19:38:08,699: ============================================================
2022-07-06 19:39:22,731: time cost, forward:0.0116813519873169, backward:0.033211457827859676, data cost:0.7085103416193979 
2022-07-06 19:39:22,732: ============================================================
2022-07-06 19:39:22,732: Epoch 2/36 Batch 2300/7662 eta: 2 days, 6:40:32.712889	Training Loss1 15.7521 (16.9957)	Training Total_Loss 15.7521 (16.9957)	Training Prec@1 23.633 (15.333)	Training Prec@5 0.000 (0.000)	
2022-07-06 19:39:22,732: ============================================================
2022-07-06 19:40:37,675: time cost, forward:0.011742533619774535, backward:0.03316781748429394, data cost:0.7083170015447187 
2022-07-06 19:40:37,675: ============================================================
2022-07-06 19:40:37,676: Epoch 2/36 Batch 2400/7662 eta: 2 days, 7:19:37.817662	Training Loss1 15.0371 (16.9239)	Training Total_Loss 15.0371 (16.9239)	Training Prec@1 26.953 (15.912)	Training Prec@5 0.000 (0.000)	
2022-07-06 19:40:37,676: ============================================================
2022-07-06 19:41:53,666: time cost, forward:0.01177449749202049, backward:0.03314942729716398, data cost:0.708538507833248 
2022-07-06 19:41:53,667: ============================================================
2022-07-06 19:41:53,667: Epoch 2/36 Batch 2500/7662 eta: 2 days, 8:04:47.465112	Training Loss1 14.8249 (16.8510)	Training Total_Loss 14.8249 (16.8510)	Training Prec@1 33.398 (16.522)	Training Prec@5 0.000 (0.000)	
2022-07-06 19:41:53,667: ============================================================
2022-07-06 19:43:08,224: time cost, forward:0.011790773601612708, backward:0.03313129413306782, data cost:0.7081929951183793 
2022-07-06 19:43:08,225: ============================================================
2022-07-06 19:43:08,225: Epoch 2/36 Batch 2600/7662 eta: 2 days, 7:00:04.480233	Training Loss1 14.9398 (16.7789)	Training Total_Loss 14.9398 (16.7789)	Training Prec@1 30.469 (17.114)	Training Prec@5 0.000 (0.000)	
2022-07-06 19:43:08,225: ============================================================
2022-07-06 19:44:23,605: time cost, forward:0.011818504103822769, backward:0.033110035927748846, data cost:0.708190765677668 
2022-07-06 19:44:23,605: ============================================================
2022-07-06 19:44:23,606: Epoch 2/36 Batch 2700/7662 eta: 2 days, 7:35:13.161660	Training Loss1 14.9745 (16.7083)	Training Total_Loss 14.9745 (16.7083)	Training Prec@1 30.859 (17.699)	Training Prec@5 0.000 (0.000)	
2022-07-06 19:44:23,606: ============================================================
2022-07-06 19:45:38,200: time cost, forward:0.011822993860111871, backward:0.03312925689345643, data cost:0.7079068749834274 
2022-07-06 19:45:38,200: ============================================================
2022-07-06 19:45:38,200: Epoch 2/36 Batch 2800/7662 eta: 2 days, 6:59:13.312779	Training Loss1 14.7082 (16.6392)	Training Total_Loss 14.7082 (16.6392)	Training Prec@1 32.617 (18.275)	Training Prec@5 0.000 (0.000)	
2022-07-06 19:45:38,201: ============================================================
2022-07-06 19:46:53,228: time cost, forward:0.01184152166939637, backward:0.03312084558874461, data cost:0.7077767997825914 
2022-07-06 19:46:53,229: ============================================================
2022-07-06 19:46:53,229: Epoch 2/36 Batch 2900/7662 eta: 2 days, 7:17:08.431865	Training Loss1 14.4775 (16.5691)	Training Total_Loss 14.4775 (16.5691)	Training Prec@1 37.500 (18.867)	Training Prec@5 0.000 (0.000)	
2022-07-06 19:46:53,229: ============================================================
2022-07-06 19:48:07,804: time cost, forward:0.011875552072172047, backward:0.03311509750572273, data cost:0.7075024300632814 
2022-07-06 19:48:07,805: ============================================================
2022-07-06 19:48:07,805: Epoch 2/36 Batch 3000/7662 eta: 2 days, 6:55:54.627919	Training Loss1 13.9556 (16.4969)	Training Total_Loss 13.9556 (16.4969)	Training Prec@1 44.141 (19.484)	Training Prec@5 0.000 (0.000)	
2022-07-06 19:48:07,805: ============================================================
2022-07-06 19:49:23,172: time cost, forward:0.011918777802483656, backward:0.03306117924077544, data cost:0.7075228927288566 
2022-07-06 19:49:23,172: ============================================================
2022-07-06 19:49:23,173: Epoch 2/36 Batch 3100/7662 eta: 2 days, 7:29:37.496698	Training Loss1 14.4610 (16.4279)	Training Total_Loss 14.4610 (16.4279)	Training Prec@1 36.523 (20.088)	Training Prec@5 0.000 (0.000)	
2022-07-06 19:49:23,173: ============================================================
2022-07-06 19:50:39,195: time cost, forward:0.011935672077323243, backward:0.03306007616294105, data cost:0.7077403193751363 
2022-07-06 19:50:39,196: ============================================================
2022-07-06 19:50:39,196: Epoch 2/36 Batch 3200/7662 eta: 2 days, 7:57:19.380299	Training Loss1 14.1739 (16.3592)	Training Total_Loss 14.1739 (16.3592)	Training Prec@1 38.281 (20.679)	Training Prec@5 0.000 (0.000)	
2022-07-06 19:50:39,196: ============================================================
2022-07-06 19:51:54,247: time cost, forward:0.011955526244391019, backward:0.03304780935222144, data cost:0.7076391866619784 
2022-07-06 19:51:54,248: ============================================================
2022-07-06 19:51:54,248: Epoch 2/36 Batch 3300/7662 eta: 2 days, 7:13:11.185753	Training Loss1 14.1837 (16.2917)	Training Total_Loss 14.1837 (16.2917)	Training Prec@1 37.891 (21.263)	Training Prec@5 0.000 (0.000)	
2022-07-06 19:51:54,248: ============================================================
2022-07-06 19:53:09,921: time cost, forward:0.011973390091023188, backward:0.03306200750507513, data cost:0.7077210430679478 
2022-07-06 19:53:09,922: ============================================================
2022-07-06 19:53:09,922: Epoch 2/36 Batch 3400/7662 eta: 2 days, 7:39:23.038279	Training Loss1 14.2946 (16.2237)	Training Total_Loss 14.2946 (16.2237)	Training Prec@1 36.133 (21.850)	Training Prec@5 0.000 (0.000)	
2022-07-06 19:53:09,922: ============================================================
2022-07-06 19:54:25,581: time cost, forward:0.011998817695144518, backward:0.033063206068956366, data cost:0.7077806494719099 
2022-07-06 19:54:25,581: ============================================================
2022-07-06 19:54:25,581: Epoch 2/36 Batch 3500/7662 eta: 2 days, 7:37:27.592589	Training Loss1 13.9384 (16.1582)	Training Total_Loss 13.9384 (16.1582)	Training Prec@1 41.016 (22.426)	Training Prec@5 0.000 (0.000)	
2022-07-06 19:54:25,581: ============================================================
2022-07-06 19:55:40,831: time cost, forward:0.012015291040690285, backward:0.033061924693517535, data cost:0.7077425454318043 
2022-07-06 19:55:40,831: ============================================================
2022-07-06 19:55:40,831: Epoch 2/36 Batch 3600/7662 eta: 2 days, 7:18:10.141759	Training Loss1 13.8379 (16.0921)	Training Total_Loss 13.8379 (16.0921)	Training Prec@1 45.117 (23.005)	Training Prec@5 0.000 (0.000)	
2022-07-06 19:55:40,831: ============================================================
2022-07-06 19:56:56,142: time cost, forward:0.012026991577334067, backward:0.03305011860387781, data cost:0.707728773299086 
2022-07-06 19:56:56,143: ============================================================
2022-07-06 19:56:56,143: Epoch 2/36 Batch 3700/7662 eta: 2 days, 7:19:36.990972	Training Loss1 13.7383 (16.0276)	Training Total_Loss 13.7383 (16.0276)	Training Prec@1 45.312 (23.566)	Training Prec@5 0.000 (0.000)	
2022-07-06 19:56:56,143: ============================================================
2022-07-06 19:58:10,795: time cost, forward:0.012033991011609275, backward:0.03305001081871842, data cost:0.707533592611716 
2022-07-06 19:58:10,795: ============================================================
2022-07-06 19:58:10,795: Epoch 2/36 Batch 3800/7662 eta: 2 days, 6:49:19.658246	Training Loss1 13.5813 (15.9648)	Training Total_Loss 13.5813 (15.9648)	Training Prec@1 46.680 (24.120)	Training Prec@5 0.000 (0.000)	
2022-07-06 19:58:10,795: ============================================================
2022-07-06 19:59:25,134: time cost, forward:0.012053194642831314, backward:0.03305366143840311, data cost:0.7072479514532684 
2022-07-06 19:59:25,134: ============================================================
2022-07-06 19:59:25,135: Epoch 2/36 Batch 3900/7662 eta: 2 days, 6:34:17.673126	Training Loss1 13.5541 (15.9024)	Training Total_Loss 13.5541 (15.9024)	Training Prec@1 44.141 (24.674)	Training Prec@5 0.000 (0.000)	
2022-07-06 19:59:25,135: ============================================================
2022-07-06 20:00:40,648: time cost, forward:0.01207649859824041, backward:0.03302126027369803, data cost:0.707332748149329 
2022-07-06 20:00:40,648: ============================================================
2022-07-06 20:00:40,648: Epoch 2/36 Batch 4000/7662 eta: 2 days, 7:24:44.497191	Training Loss1 13.5674 (15.8402)	Training Total_Loss 13.5674 (15.8402)	Training Prec@1 47.461 (25.219)	Training Prec@5 0.000 (0.000)	
2022-07-06 20:00:40,648: ============================================================
2022-07-06 20:01:55,875: time cost, forward:0.01208997051958399, backward:0.033018890256618805, data cost:0.7072882291077695 
2022-07-06 20:01:55,876: ============================================================
2022-07-06 20:01:55,876: Epoch 2/36 Batch 4100/7662 eta: 2 days, 7:10:55.291390	Training Loss1 13.6077 (15.7790)	Training Total_Loss 13.6077 (15.7790)	Training Prec@1 45.703 (25.762)	Training Prec@5 0.000 (0.000)	
2022-07-06 20:01:55,876: ============================================================
2022-07-06 20:03:12,708: time cost, forward:0.01209816083251706, backward:0.03302389486939261, data cost:0.7076367847009283 
2022-07-06 20:03:12,709: ============================================================
2022-07-06 20:03:12,709: Epoch 2/36 Batch 4200/7662 eta: 2 days, 8:20:16.338575	Training Loss1 13.6112 (15.7198)	Training Total_Loss 13.6112 (15.7198)	Training Prec@1 45.898 (26.288)	Training Prec@5 0.000 (0.000)	
2022-07-06 20:03:12,709: ============================================================
2022-07-06 20:04:27,804: time cost, forward:0.012103817634289695, backward:0.0330340867265487, data cost:0.7075731107650122 
2022-07-06 20:04:27,805: ============================================================
2022-07-06 20:04:27,805: Epoch 2/36 Batch 4300/7662 eta: 2 days, 7:02:37.129104	Training Loss1 12.9096 (15.6616)	Training Total_Loss 12.9096 (15.6616)	Training Prec@1 49.023 (26.803)	Training Prec@5 0.000 (0.000)	
2022-07-06 20:04:27,805: ============================================================
2022-07-06 20:05:42,012: time cost, forward:0.01212666348506982, backward:0.033012568232524825, data cost:0.7073126857620555 
2022-07-06 20:05:42,012: ============================================================
2022-07-06 20:05:42,012: Epoch 2/36 Batch 4400/7662 eta: 2 days, 6:22:16.478725	Training Loss1 13.1570 (15.6030)	Training Total_Loss 13.1570 (15.6030)	Training Prec@1 52.734 (27.330)	Training Prec@5 0.000 (0.000)	
2022-07-06 20:05:42,012: ============================================================
2022-07-06 20:06:57,948: time cost, forward:0.01214864524795522, backward:0.03299946052600448, data cost:0.7074522149644976 
2022-07-06 20:06:57,949: ============================================================
2022-07-06 20:06:57,949: Epoch 2/36 Batch 4500/7662 eta: 2 days, 7:37:03.615397	Training Loss1 13.2650 (15.5457)	Training Total_Loss 13.2650 (15.5457)	Training Prec@1 45.898 (27.840)	Training Prec@5 0.000 (0.000)	
2022-07-06 20:06:57,949: ============================================================
2022-07-06 20:08:12,721: time cost, forward:0.012164629965042077, backward:0.03300577128651506, data cost:0.7073022498076675 
2022-07-06 20:08:12,722: ============================================================
2022-07-06 20:08:12,722: Epoch 2/36 Batch 4600/7662 eta: 2 days, 6:44:39.669223	Training Loss1 13.0067 (15.4901)	Training Total_Loss 13.0067 (15.4901)	Training Prec@1 52.344 (28.335)	Training Prec@5 0.000 (0.000)	
2022-07-06 20:08:12,722: ============================================================
2022-07-06 20:09:27,202: time cost, forward:0.012169165518923651, backward:0.033006883727968894, data cost:0.7071306757735151 
2022-07-06 20:09:27,202: ============================================================
2022-07-06 20:09:27,202: Epoch 2/36 Batch 4700/7662 eta: 2 days, 6:30:34.013066	Training Loss1 12.8376 (15.4349)	Training Total_Loss 12.8376 (15.4349)	Training Prec@1 52.148 (28.830)	Training Prec@5 0.000 (0.000)	
2022-07-06 20:09:27,202: ============================================================
2022-07-06 20:10:43,221: time cost, forward:0.012170198684584277, backward:0.03301033230467771, data cost:0.7072800169092438 
2022-07-06 20:10:43,222: ============================================================
2022-07-06 20:10:43,222: Epoch 2/36 Batch 4800/7662 eta: 2 days, 7:36:53.724286	Training Loss1 13.0882 (15.3803)	Training Total_Loss 13.0882 (15.3803)	Training Prec@1 49.023 (29.312)	Training Prec@5 0.000 (0.000)	
2022-07-06 20:10:43,222: ============================================================
2022-07-06 20:11:58,830: time cost, forward:0.012164372963719427, backward:0.0330128716458883, data cost:0.7073428798729265 
2022-07-06 20:11:58,831: ============================================================
2022-07-06 20:11:58,831: Epoch 2/36 Batch 4900/7662 eta: 2 days, 7:17:36.311070	Training Loss1 12.9019 (15.3271)	Training Total_Loss 12.9019 (15.3271)	Training Prec@1 51.953 (29.793)	Training Prec@5 0.000 (0.000)	
2022-07-06 20:11:58,831: ============================================================
2022-07-06 20:13:14,355: time cost, forward:0.01216323133897104, backward:0.03300841557166414, data cost:0.7073880506768468 
2022-07-06 20:13:14,355: ============================================================
2022-07-06 20:13:14,356: Epoch 2/36 Batch 5000/7662 eta: 2 days, 7:12:39.369689	Training Loss1 12.5146 (15.2751)	Training Total_Loss 12.5146 (15.2751)	Training Prec@1 54.883 (30.263)	Training Prec@5 0.000 (0.000)	
2022-07-06 20:13:14,356: ============================================================
2022-07-06 20:14:30,199: time cost, forward:0.012178396986942475, backward:0.03300110427368667, data cost:0.7074808616641924 
2022-07-06 20:14:30,200: ============================================================
2022-07-06 20:14:30,200: Epoch 2/36 Batch 5100/7662 eta: 2 days, 7:25:24.571161	Training Loss1 12.0601 (15.2233)	Training Total_Loss 12.0601 (15.2233)	Training Prec@1 58.984 (30.727)	Training Prec@5 0.000 (0.000)	
2022-07-06 20:14:30,200: ============================================================
2022-07-06 20:15:45,259: time cost, forward:0.012185461728887894, backward:0.03299442706921624, data cost:0.7074296601943544 
2022-07-06 20:15:45,259: ============================================================
2022-07-06 20:15:45,259: Epoch 2/36 Batch 5200/7662 eta: 2 days, 6:49:44.336491	Training Loss1 12.4891 (15.1727)	Training Total_Loss 12.4891 (15.1727)	Training Prec@1 54.297 (31.182)	Training Prec@5 0.000 (0.000)	
2022-07-06 20:15:45,259: ============================================================
2022-07-06 20:16:59,857: time cost, forward:0.012186029673207591, backward:0.032986518053946395, data cost:0.7072997413101816 
2022-07-06 20:16:59,857: ============================================================
2022-07-06 20:16:59,858: Epoch 2/36 Batch 5300/7662 eta: 2 days, 6:28:16.662260	Training Loss1 12.4599 (15.1234)	Training Total_Loss 12.4599 (15.1234)	Training Prec@1 53.516 (31.629)	Training Prec@5 0.000 (0.000)	
2022-07-06 20:16:59,858: ============================================================
2022-07-06 20:18:15,193: time cost, forward:0.012207179229377398, backward:0.03299264846896437, data cost:0.7072740370839983 
2022-07-06 20:18:15,193: ============================================================
2022-07-06 20:18:15,193: Epoch 2/36 Batch 5400/7662 eta: 2 days, 6:59:20.896715	Training Loss1 12.4483 (15.0741)	Training Total_Loss 12.4483 (15.0741)	Training Prec@1 56.055 (32.071)	Training Prec@5 0.000 (0.000)	
2022-07-06 20:18:15,193: ============================================================
2022-07-06 20:19:30,976: time cost, forward:0.012201789553153729, backward:0.0329803438441583, data cost:0.7073797935961723 
2022-07-06 20:19:30,976: ============================================================
2022-07-06 20:19:30,977: Epoch 2/36 Batch 5500/7662 eta: 2 days, 7:17:40.824386	Training Loss1 12.2909 (15.0255)	Training Total_Loss 12.2909 (15.0255)	Training Prec@1 56.055 (32.506)	Training Prec@5 0.000 (0.000)	
2022-07-06 20:19:30,977: ============================================================
2022-07-06 20:20:47,045: time cost, forward:0.012212331943542622, backward:0.03298183687458423, data cost:0.7075044150692286 
2022-07-06 20:20:47,046: ============================================================
2022-07-06 20:20:47,046: Epoch 2/36 Batch 5600/7662 eta: 2 days, 7:28:55.171566	Training Loss1 12.7206 (14.9775)	Training Total_Loss 12.7206 (14.9775)	Training Prec@1 52.148 (32.934)	Training Prec@5 0.000 (0.000)	
2022-07-06 20:20:47,046: ============================================================
2022-07-06 20:22:02,953: time cost, forward:0.012203066448178871, backward:0.03297503594035202, data cost:0.7076191967841846 
2022-07-06 20:22:02,953: ============================================================
2022-07-06 20:22:02,954: Epoch 2/36 Batch 5700/7662 eta: 2 days, 7:20:36.371517	Training Loss1 12.3047 (14.9311)	Training Total_Loss 12.3047 (14.9311)	Training Prec@1 56.641 (33.350)	Training Prec@5 0.000 (0.000)	
2022-07-06 20:22:02,954: ============================================================
2022-07-06 20:23:18,233: time cost, forward:0.012208734633367952, backward:0.03298475948319926, data cost:0.7075947603905565 
2022-07-06 20:23:18,233: ============================================================
2022-07-06 20:23:18,233: Epoch 2/36 Batch 5800/7662 eta: 2 days, 6:51:52.352636	Training Loss1 11.9416 (14.8850)	Training Total_Loss 11.9416 (14.8850)	Training Prec@1 59.961 (33.762)	Training Prec@5 0.000 (0.000)	
2022-07-06 20:23:18,234: ============================================================
2022-07-06 20:24:33,868: time cost, forward:0.012207824510120703, backward:0.03298357321581895, data cost:0.7076464650347629 
2022-07-06 20:24:33,869: ============================================================
2022-07-06 20:24:33,869: Epoch 2/36 Batch 5900/7662 eta: 2 days, 7:06:09.898920	Training Loss1 12.3084 (14.8394)	Training Total_Loss 12.3084 (14.8394)	Training Prec@1 58.789 (34.170)	Training Prec@5 0.000 (0.000)	
2022-07-06 20:24:33,869: ============================================================
2022-07-06 20:25:50,244: time cost, forward:0.01220188500146346, backward:0.03299310561477552, data cost:0.7078157435021494 
2022-07-06 20:25:50,244: ============================================================
2022-07-06 20:25:50,245: Epoch 2/36 Batch 6000/7662 eta: 2 days, 7:37:14.648909	Training Loss1 12.1494 (14.7947)	Training Total_Loss 12.1494 (14.7947)	Training Prec@1 58.984 (34.569)	Training Prec@5 0.000 (0.000)	
2022-07-06 20:25:50,245: ============================================================
2022-07-06 20:27:05,210: time cost, forward:0.012195507919891952, backward:0.03298535646425151, data cost:0.7077596539023431 
2022-07-06 20:27:05,211: ============================================================
2022-07-06 20:27:05,211: Epoch 2/36 Batch 6100/7662 eta: 2 days, 6:34:24.609691	Training Loss1 12.0486 (14.7508)	Training Total_Loss 12.0486 (14.7508)	Training Prec@1 60.547 (34.962)	Training Prec@5 0.000 (0.000)	
2022-07-06 20:27:05,211: ============================================================
2022-07-06 20:28:19,904: time cost, forward:0.01220361381447071, backward:0.03298189855810326, data cost:0.7076532425736589 
2022-07-06 20:28:19,904: ============================================================
2022-07-06 20:28:19,905: Epoch 2/36 Batch 6200/7662 eta: 2 days, 6:21:16.551300	Training Loss1 11.9246 (14.7073)	Training Total_Loss 11.9246 (14.7073)	Training Prec@1 61.914 (35.349)	Training Prec@5 0.000 (0.000)	
2022-07-06 20:28:19,905: ============================================================
2022-07-06 20:29:34,239: time cost, forward:0.01220407132440795, backward:0.03297839018632011, data cost:0.7074953909052006 
2022-07-06 20:29:34,239: ============================================================
2022-07-06 20:29:34,239: Epoch 2/36 Batch 6300/7662 eta: 2 days, 6:04:20.416276	Training Loss1 12.2248 (14.6642)	Training Total_Loss 12.2248 (14.6642)	Training Prec@1 60.352 (35.731)	Training Prec@5 0.000 (0.000)	
2022-07-06 20:29:34,239: ============================================================
2022-07-06 20:30:49,799: time cost, forward:0.01220045884822864, backward:0.03297558455266772, data cost:0.7075393162289343 
2022-07-06 20:30:49,799: ============================================================
2022-07-06 20:30:49,799: Epoch 2/36 Batch 6400/7662 eta: 2 days, 6:56:33.950884	Training Loss1 12.2172 (14.6218)	Training Total_Loss 12.2172 (14.6218)	Training Prec@1 58.008 (36.108)	Training Prec@5 0.000 (0.000)	
2022-07-06 20:30:49,799: ============================================================
2022-07-06 20:32:05,171: time cost, forward:0.012200438475531787, backward:0.03297163490369368, data cost:0.7075504697200096 
2022-07-06 20:32:05,172: ============================================================
2022-07-06 20:32:05,172: Epoch 2/36 Batch 6500/7662 eta: 2 days, 6:47:09.135352	Training Loss1 11.8963 (14.5802)	Training Total_Loss 11.8963 (14.5802)	Training Prec@1 60.547 (36.476)	Training Prec@5 0.000 (0.000)	
2022-07-06 20:32:05,172: ============================================================
2022-07-06 20:33:21,534: time cost, forward:0.012194676297345764, backward:0.03297704016553541, data cost:0.7077051888344631 
2022-07-06 20:33:21,534: ============================================================
2022-07-06 20:33:21,534: Epoch 2/36 Batch 6600/7662 eta: 2 days, 7:29:01.375832	Training Loss1 11.7174 (14.5388)	Training Total_Loss 11.7174 (14.5388)	Training Prec@1 60.938 (36.845)	Training Prec@5 0.000 (0.000)	
2022-07-06 20:33:21,534: ============================================================
2022-07-06 20:34:37,048: time cost, forward:0.012200144230919039, backward:0.03297561363491269, data cost:0.7077230515275754 
2022-07-06 20:34:37,049: ============================================================
2022-07-06 20:34:37,049: Epoch 2/36 Batch 6700/7662 eta: 2 days, 6:50:48.576016	Training Loss1 11.6370 (14.4986)	Training Total_Loss 11.6370 (14.4986)	Training Prec@1 63.086 (37.200)	Training Prec@5 0.000 (0.000)	
2022-07-06 20:34:37,049: ============================================================
2022-07-06 20:35:51,881: time cost, forward:0.012205018525895766, backward:0.03297505699232898, data cost:0.7076427062691477 
2022-07-06 20:35:51,881: ============================================================
2022-07-06 20:35:51,881: Epoch 2/36 Batch 6800/7662 eta: 2 days, 6:19:50.429222	Training Loss1 11.8220 (14.4592)	Training Total_Loss 11.8220 (14.4592)	Training Prec@1 61.328 (37.551)	Training Prec@5 0.000 (0.000)	
2022-07-06 20:35:51,881: ============================================================
2022-07-06 20:37:08,273: time cost, forward:0.012212341843281713, backward:0.032971037697284045, data cost:0.707794833898648 
2022-07-06 20:37:08,273: ============================================================
2022-07-06 20:37:08,274: Epoch 2/36 Batch 6900/7662 eta: 2 days, 7:26:31.116460	Training Loss1 11.8917 (14.4200)	Training Total_Loss 11.8917 (14.4200)	Training Prec@1 60.156 (37.899)	Training Prec@5 0.000 (0.000)	
2022-07-06 20:37:08,274: ============================================================
2022-07-06 20:38:23,617: time cost, forward:0.01221406263936535, backward:0.03297250763759185, data cost:0.7077868056648168 
2022-07-06 20:38:23,617: ============================================================
2022-07-06 20:38:23,617: Epoch 2/36 Batch 7000/7662 eta: 2 days, 6:39:35.902022	Training Loss1 11.5653 (14.3815)	Training Total_Loss 11.5653 (14.3815)	Training Prec@1 59.766 (38.240)	Training Prec@5 0.000 (0.000)	
2022-07-06 20:38:23,617: ============================================================
2022-07-06 20:39:38,551: time cost, forward:0.012215620699961903, backward:0.03297054114384053, data cost:0.7077293646874638 
2022-07-06 20:39:38,552: ============================================================
2022-07-06 20:39:38,552: Epoch 2/36 Batch 7100/7662 eta: 2 days, 6:20:32.598252	Training Loss1 11.3622 (14.3424)	Training Total_Loss 11.3622 (14.3424)	Training Prec@1 64.453 (38.588)	Training Prec@5 0.000 (0.000)	
2022-07-06 20:39:38,552: ============================================================
2022-07-06 20:40:52,742: time cost, forward:0.012210921589442965, backward:0.032967034371830815, data cost:0.7075742747588594 
2022-07-06 20:40:52,743: ============================================================
2022-07-06 20:40:52,743: Epoch 2/36 Batch 7200/7662 eta: 2 days, 5:46:56.794221	Training Loss1 11.7687 (14.3054)	Training Total_Loss 11.7687 (14.3054)	Training Prec@1 61.914 (38.911)	Training Prec@5 0.000 (0.000)	
2022-07-06 20:40:52,743: ============================================================
2022-07-06 20:42:07,511: time cost, forward:0.012209028360826999, backward:0.03297158093758847, data cost:0.7074966492726715 
2022-07-06 20:42:07,511: ============================================================
2022-07-06 20:42:07,511: Epoch 2/36 Batch 7300/7662 eta: 2 days, 6:10:49.337601	Training Loss1 11.5838 (14.2682)	Training Total_Loss 11.5838 (14.2682)	Training Prec@1 61.719 (39.238)	Training Prec@5 0.000 (0.000)	
2022-07-06 20:42:07,512: ============================================================
2022-07-06 20:43:23,326: time cost, forward:0.01222269933664214, backward:0.032981952246273996, data cost:0.7075380926148959 
2022-07-06 20:43:23,326: ============================================================
2022-07-06 20:43:23,326: Epoch 2/36 Batch 7400/7662 eta: 2 days, 6:55:03.137759	Training Loss1 11.5118 (14.2312)	Training Total_Loss 11.5118 (14.2312)	Training Prec@1 65.625 (39.564)	Training Prec@5 0.000 (0.000)	
2022-07-06 20:43:23,326: ============================================================
2022-07-06 20:44:39,403: time cost, forward:0.012228484852566116, backward:0.032985036699656474, data cost:0.70762559537459 
2022-07-06 20:44:39,403: ============================================================
2022-07-06 20:44:39,403: Epoch 2/36 Batch 7500/7662 eta: 2 days, 7:05:10.915689	Training Loss1 11.3309 (14.1955)	Training Total_Loss 11.3309 (14.1955)	Training Prec@1 65.039 (39.879)	Training Prec@5 0.000 (0.000)	
2022-07-06 20:44:39,403: ============================================================
2022-07-06 20:45:55,054: time cost, forward:0.01222889767554045, backward:0.03299377265455284, data cost:0.7076587027539578 
2022-07-06 20:45:55,054: ============================================================
2022-07-06 20:45:55,054: Epoch 2/36 Batch 7600/7662 eta: 2 days, 6:45:24.538071	Training Loss1 11.6339 (14.1602)	Training Total_Loss 11.6339 (14.1602)	Training Prec@1 62.891 (40.188)	Training Prec@5 0.000 (0.000)	
2022-07-06 20:45:55,055: ============================================================
2022-07-06 20:46:42,790: Epoch 2/36 Batch 7663/7662 eta: 2 days, 6:44:36.877948	Training Loss1 11.2273 (14.1378)	Training Total_Loss 11.2273 (14.1378)	Training Prec@1 65.234 (40.386)	Training Prec@5 0.000 (0.000)	
2022-07-06 20:46:42,790: ============================================================
2022-07-06 20:48:01,461: time cost, forward:0.011020448472764757, backward:0.03271114946615816, data cost:0.7428759733835856 
2022-07-06 20:48:01,461: ============================================================
2022-07-06 20:48:01,461: Epoch 3/36 Batch 100/7662 eta: 2 days, 8:51:40.952721	Training Loss1 10.9235 (10.9756)	Training Total_Loss 10.9235 (10.9756)	Training Prec@1 66.797 (67.823)	Training Prec@5 0.000 (0.000)	
2022-07-06 20:48:01,461: ============================================================
2022-07-06 20:49:18,065: time cost, forward:0.010955260626634761, backward:0.033232920133887824, data cost:0.7327345196326175 
2022-07-06 20:49:18,065: ============================================================
2022-07-06 20:49:18,065: Epoch 3/36 Batch 200/7662 eta: 2 days, 7:23:27.032744	Training Loss1 11.2700 (10.9957)	Training Total_Loss 11.2700 (10.9957)	Training Prec@1 64.062 (67.762)	Training Prec@5 0.000 (0.000)	
2022-07-06 20:49:18,065: ============================================================
2022-07-06 20:50:34,063: time cost, forward:0.011062909129471284, backward:0.0334923115861057, data cost:0.7265249414986192 
2022-07-06 20:50:34,064: ============================================================
2022-07-06 20:50:34,064: Epoch 3/36 Batch 300/7662 eta: 2 days, 6:55:55.411744	Training Loss1 11.2733 (11.0247)	Training Total_Loss 11.2733 (11.0247)	Training Prec@1 64.844 (67.600)	Training Prec@5 0.000 (0.000)	
2022-07-06 20:50:34,064: ============================================================
2022-07-06 20:51:48,345: time cost, forward:0.011434018462522883, backward:0.033576189724723794, data cost:0.7188359239047631 
2022-07-06 20:51:48,345: ============================================================
2022-07-06 20:51:48,346: Epoch 3/36 Batch 400/7662 eta: 2 days, 5:40:13.673291	Training Loss1 11.3510 (11.0425)	Training Total_Loss 11.3510 (11.0425)	Training Prec@1 65.039 (67.420)	Training Prec@5 0.000 (0.000)	
2022-07-06 20:51:48,346: ============================================================
2022-07-06 20:53:03,708: time cost, forward:0.011569920904889614, backward:0.03352549463092445, data cost:0.7165742001695958 
2022-07-06 20:53:03,709: ============================================================
2022-07-06 20:53:03,709: Epoch 3/36 Batch 500/7662 eta: 2 days, 6:25:52.079534	Training Loss1 11.1971 (11.0559)	Training Total_Loss 11.1971 (11.0559)	Training Prec@1 64.258 (67.308)	Training Prec@5 0.000 (0.000)	
2022-07-06 20:53:03,709: ============================================================
2022-07-06 20:54:18,733: time cost, forward:0.011725412983329148, backward:0.03341059971333346, data cost:0.7145192129584107 
2022-07-06 20:54:18,733: ============================================================
2022-07-06 20:54:18,733: Epoch 3/36 Batch 600/7662 eta: 2 days, 6:09:54.593350	Training Loss1 11.2581 (11.0580)	Training Total_Loss 11.2581 (11.0580)	Training Prec@1 67.969 (67.319)	Training Prec@5 0.000 (0.000)	
2022-07-06 20:54:18,734: ============================================================
2022-07-06 20:55:33,543: time cost, forward:0.011753529097048169, backward:0.03347081926588678, data cost:0.712690374199754 
2022-07-06 20:55:33,543: ============================================================
2022-07-06 20:55:33,544: Epoch 3/36 Batch 700/7662 eta: 2 days, 5:59:23.754484	Training Loss1 11.2846 (11.0645)	Training Total_Loss 11.2846 (11.0645)	Training Prec@1 66.992 (67.230)	Training Prec@5 0.000 (0.000)	
2022-07-06 20:55:33,544: ============================================================
2022-07-06 20:56:47,782: time cost, forward:0.01182466215723298, backward:0.033600588763908985, data cost:0.7104793266301161 
2022-07-06 20:56:47,783: ============================================================
2022-07-06 20:56:47,783: Epoch 3/36 Batch 800/7662 eta: 2 days, 5:33:25.753577	Training Loss1 11.1434 (11.0686)	Training Total_Loss 11.1434 (11.0686)	Training Prec@1 66.797 (67.208)	Training Prec@5 0.000 (0.000)	
2022-07-06 20:56:47,783: ============================================================
2022-07-06 20:58:01,394: time cost, forward:0.011813284955645298, backward:0.03357677624143403, data cost:0.7082456452430157 
2022-07-06 20:58:01,394: ============================================================
2022-07-06 20:58:01,395: Epoch 3/36 Batch 900/7662 eta: 2 days, 5:05:02.762427	Training Loss1 11.2274 (11.0726)	Training Total_Loss 11.2274 (11.0726)	Training Prec@1 65.430 (67.178)	Training Prec@5 0.000 (0.000)	
2022-07-06 20:58:01,395: ============================================================
2022-07-06 20:59:16,578: time cost, forward:0.01189550933417854, backward:0.033568642399571205, data cost:0.7079092904970095 
2022-07-06 20:59:16,579: ============================================================
2022-07-06 20:59:16,579: Epoch 3/36 Batch 1000/7662 eta: 2 days, 6:11:50.093624	Training Loss1 10.9528 (11.0728)	Training Total_Loss 10.9528 (11.0728)	Training Prec@1 67.383 (67.153)	Training Prec@5 0.000 (0.000)	
2022-07-06 20:59:16,579: ============================================================
2022-07-06 21:00:31,067: time cost, forward:0.011936643537984749, backward:0.03356905630005827, data cost:0.707040619264417 
2022-07-06 21:00:31,068: ============================================================
2022-07-06 21:00:31,068: Epoch 3/36 Batch 1100/7662 eta: 2 days, 5:40:31.749738	Training Loss1 11.3235 (11.0708)	Training Total_Loss 11.3235 (11.0708)	Training Prec@1 64.648 (67.160)	Training Prec@5 0.000 (0.000)	
2022-07-06 21:00:31,068: ============================================================
2022-07-06 21:01:44,633: time cost, forward:0.011889201984294162, backward:0.033541811616148325, data cost:0.705622347520728 
2022-07-06 21:01:44,633: ============================================================
2022-07-06 21:01:44,634: Epoch 3/36 Batch 1200/7662 eta: 2 days, 4:59:21.821490	Training Loss1 11.1401 (11.0713)	Training Total_Loss 11.1401 (11.0713)	Training Prec@1 68.359 (67.151)	Training Prec@5 0.000 (0.000)	
2022-07-06 21:01:44,634: ============================================================
2022-07-06 21:02:58,896: time cost, forward:0.011888149979483448, backward:0.03345371063531959, data cost:0.7050260730299975 
2022-07-06 21:02:58,896: ============================================================
2022-07-06 21:02:58,896: Epoch 3/36 Batch 1300/7662 eta: 2 days, 5:28:15.931648	Training Loss1 10.9716 (11.0683)	Training Total_Loss 10.9716 (11.0683)	Training Prec@1 67.578 (67.182)	Training Prec@5 0.000 (0.000)	
2022-07-06 21:02:58,897: ============================================================
2022-07-06 21:04:13,185: time cost, forward:0.011938541424623807, backward:0.033366237562669016, data cost:0.7045159651774692 
2022-07-06 21:04:13,185: ============================================================
2022-07-06 21:04:13,185: Epoch 3/36 Batch 1400/7662 eta: 2 days, 5:28:09.420234	Training Loss1 10.8311 (11.0641)	Training Total_Loss 10.8311 (11.0641)	Training Prec@1 71.289 (67.188)	Training Prec@5 0.000 (0.000)	
2022-07-06 21:04:13,186: ============================================================
2022-07-06 21:05:27,225: time cost, forward:0.011924205898363802, backward:0.033347834261995384, data cost:0.7038661173934376 
2022-07-06 21:05:27,226: ============================================================
2022-07-06 21:05:27,226: Epoch 3/36 Batch 1500/7662 eta: 2 days, 5:16:11.110746	Training Loss1 10.9318 (11.0574)	Training Total_Loss 10.9318 (11.0574)	Training Prec@1 67.383 (67.227)	Training Prec@5 0.000 (0.000)	
2022-07-06 21:05:27,226: ============================================================
2022-07-06 21:06:41,824: time cost, forward:0.01190651991428473, backward:0.03332235695348075, data cost:0.7036876386221385 
2022-07-06 21:06:41,824: ============================================================
2022-07-06 21:06:41,825: Epoch 3/36 Batch 1600/7662 eta: 2 days, 5:39:02.955712	Training Loss1 11.2013 (11.0504)	Training Total_Loss 11.2013 (11.0504)	Training Prec@1 65.234 (67.273)	Training Prec@5 0.000 (0.000)	
2022-07-06 21:06:41,825: ============================================================
2022-07-06 21:07:57,299: time cost, forward:0.011918522316684015, backward:0.033270998657837274, data cost:0.7040369070018299 
2022-07-06 21:07:57,299: ============================================================
2022-07-06 21:07:57,299: Epoch 3/36 Batch 1700/7662 eta: 2 days, 6:15:35.928985	Training Loss1 10.5546 (11.0456)	Training Total_Loss 10.5546 (11.0456)	Training Prec@1 71.094 (67.302)	Training Prec@5 0.000 (0.000)	
2022-07-06 21:07:57,300: ============================================================
2022-07-06 21:09:11,201: time cost, forward:0.01189551027434743, backward:0.03328473081583444, data cost:0.7034427992432166 
2022-07-06 21:09:11,201: ============================================================
2022-07-06 21:09:11,201: Epoch 3/36 Batch 1800/7662 eta: 2 days, 5:06:30.409552	Training Loss1 10.7935 (11.0365)	Training Total_Loss 10.7935 (11.0365)	Training Prec@1 67.969 (67.359)	Training Prec@5 0.000 (0.000)	
2022-07-06 21:09:11,201: ============================================================
2022-07-06 21:10:25,743: time cost, forward:0.011899166448672487, backward:0.03329280729730735, data cost:0.7032365846659021 
2022-07-06 21:10:25,744: ============================================================
2022-07-06 21:10:25,744: Epoch 3/36 Batch 1900/7662 eta: 2 days, 5:32:54.293337	Training Loss1 10.8939 (11.0287)	Training Total_Loss 10.8939 (11.0287)	Training Prec@1 69.336 (67.407)	Training Prec@5 0.000 (0.000)	
2022-07-06 21:10:25,744: ============================================================
2022-07-06 21:11:40,933: time cost, forward:0.011918446610962646, backward:0.033302591943096795, data cost:0.7033169474704317 
2022-07-06 21:11:40,933: ============================================================
2022-07-06 21:11:40,933: Epoch 3/36 Batch 2000/7662 eta: 2 days, 5:59:30.520327	Training Loss1 10.6984 (11.0206)	Training Total_Loss 10.6984 (11.0206)	Training Prec@1 71.484 (67.455)	Training Prec@5 0.000 (0.000)	
2022-07-06 21:11:40,933: ============================================================
2022-07-06 21:12:55,286: time cost, forward:0.01193830250217098, backward:0.03328779278737468, data cost:0.7030660967533789 
2022-07-06 21:12:55,287: ============================================================
2022-07-06 21:12:55,287: Epoch 3/36 Batch 2100/7662 eta: 2 days, 5:22:17.304878	Training Loss1 10.8137 (11.0108)	Training Total_Loss 10.8137 (11.0108)	Training Prec@1 68.555 (67.526)	Training Prec@5 0.000 (0.000)	
2022-07-06 21:12:55,287: ============================================================
2022-07-06 21:14:09,460: time cost, forward:0.011910444717615395, backward:0.03325912214073608, data cost:0.7028043532490784 
2022-07-06 21:14:09,461: ============================================================
2022-07-06 21:14:09,461: Epoch 3/36 Batch 2200/7662 eta: 2 days, 5:13:18.023498	Training Loss1 10.5287 (11.0025)	Training Total_Loss 10.5287 (11.0025)	Training Prec@1 71.289 (67.578)	Training Prec@5 0.000 (0.000)	
2022-07-06 21:14:09,461: ============================================================
2022-07-06 21:15:23,948: time cost, forward:0.011935890732043824, backward:0.033244840577147536, data cost:0.7026234469552722 
2022-07-06 21:15:23,949: ============================================================
2022-07-06 21:15:23,949: Epoch 3/36 Batch 2300/7662 eta: 2 days, 5:25:34.582420	Training Loss1 10.8654 (10.9930)	Training Total_Loss 10.8654 (10.9930)	Training Prec@1 67.969 (67.636)	Training Prec@5 0.000 (0.000)	
2022-07-06 21:15:23,949: ============================================================
2022-07-06 21:16:39,345: time cost, forward:0.011935181695255153, backward:0.03319065458529092, data cost:0.7029196516381249 
2022-07-06 21:16:39,346: ============================================================
2022-07-06 21:16:39,346: Epoch 3/36 Batch 2400/7662 eta: 2 days, 6:03:26.780766	Training Loss1 10.6877 (10.9831)	Training Total_Loss 10.6877 (10.9831)	Training Prec@1 68.359 (67.704)	Training Prec@5 0.000 (0.000)	
2022-07-06 21:16:39,346: ============================================================
2022-07-06 21:17:54,944: time cost, forward:0.011972938360524875, backward:0.03317104009877877, data cost:0.7031814582636949 
2022-07-06 21:17:54,944: ============================================================
2022-07-06 21:17:54,945: Epoch 3/36 Batch 2500/7662 eta: 2 days, 6:10:51.179956	Training Loss1 10.7891 (10.9728)	Training Total_Loss 10.7891 (10.9728)	Training Prec@1 68.750 (67.777)	Training Prec@5 0.000 (0.000)	
2022-07-06 21:17:54,945: ============================================================
2022-07-06 21:19:08,667: time cost, forward:0.011999710196025007, backward:0.033153369638634536, data cost:0.7027249238086508 
2022-07-06 21:19:08,667: ============================================================
2022-07-06 21:19:08,667: Epoch 3/36 Batch 2600/7662 eta: 2 days, 4:48:57.123851	Training Loss1 10.7570 (10.9632)	Training Total_Loss 10.7570 (10.9632)	Training Prec@1 69.336 (67.839)	Training Prec@5 0.000 (0.000)	
2022-07-06 21:19:08,667: ============================================================
2022-07-06 21:20:24,059: time cost, forward:0.012036977762997525, backward:0.03313271493194456, data cost:0.7029170385772716 
2022-07-06 21:20:24,059: ============================================================
2022-07-06 21:20:24,059: Epoch 3/36 Batch 2700/7662 eta: 2 days, 5:59:26.945049	Training Loss1 10.6969 (10.9549)	Training Total_Loss 10.6969 (10.9549)	Training Prec@1 69.531 (67.888)	Training Prec@5 0.000 (0.000)	
2022-07-06 21:20:24,059: ============================================================
2022-07-06 21:21:37,622: time cost, forward:0.012032788580935016, backward:0.03312785423581368, data cost:0.7024503843662525 
2022-07-06 21:21:37,622: ============================================================
2022-07-06 21:21:37,622: Epoch 3/36 Batch 2800/7662 eta: 2 days, 4:39:38.803367	Training Loss1 10.5180 (10.9435)	Training Total_Loss 10.5180 (10.9435)	Training Prec@1 71.484 (67.966)	Training Prec@5 0.000 (0.000)	
2022-07-06 21:21:37,622: ============================================================
2022-07-06 21:22:52,814: time cost, forward:0.012062883985663497, backward:0.03312104313321754, data cost:0.7025595003261612 
2022-07-06 21:22:52,814: ============================================================
2022-07-06 21:22:52,814: Epoch 3/36 Batch 2900/7662 eta: 2 days, 5:48:21.747221	Training Loss1 10.7096 (10.9325)	Training Total_Loss 10.7096 (10.9325)	Training Prec@1 68.750 (68.050)	Training Prec@5 0.000 (0.000)	
2022-07-06 21:22:52,815: ============================================================
2022-07-06 21:24:07,402: time cost, forward:0.012069130627542148, backward:0.033132842001258316, data cost:0.7024562048013706 
2022-07-06 21:24:07,403: ============================================================
2022-07-06 21:24:07,403: Epoch 3/36 Batch 3000/7662 eta: 2 days, 5:21:11.942125	Training Loss1 10.4640 (10.9234)	Training Total_Loss 10.4640 (10.9234)	Training Prec@1 71.094 (68.115)	Training Prec@5 0.000 (0.000)	
2022-07-06 21:24:07,403: ============================================================
2022-07-06 21:25:22,714: time cost, forward:0.012096394874004058, backward:0.03308742959563214, data cost:0.702627768244194 
2022-07-06 21:25:22,715: ============================================================
2022-07-06 21:25:22,715: Epoch 3/36 Batch 3100/7662 eta: 2 days, 5:50:59.985847	Training Loss1 10.5707 (10.9147)	Training Total_Loss 10.5707 (10.9147)	Training Prec@1 71.289 (68.176)	Training Prec@5 0.000 (0.000)	
2022-07-06 21:25:22,715: ============================================================
2022-07-06 21:26:37,294: time cost, forward:0.012127194787681607, backward:0.03302470726234982, data cost:0.702582230155041 
2022-07-06 21:26:37,294: ============================================================
2022-07-06 21:26:37,294: Epoch 3/36 Batch 3200/7662 eta: 2 days, 5:18:19.717701	Training Loss1 10.4349 (10.9050)	Training Total_Loss 10.4349 (10.9050)	Training Prec@1 70.508 (68.243)	Training Prec@5 0.000 (0.000)	
2022-07-06 21:26:37,294: ============================================================
2022-07-06 21:27:51,857: time cost, forward:0.01214340586631939, backward:0.032994528617523555, data cost:0.7025049452566313 
2022-07-06 21:27:51,857: ============================================================
2022-07-06 21:27:51,857: Epoch 3/36 Batch 3300/7662 eta: 2 days, 5:16:22.490858	Training Loss1 10.7714 (10.8958)	Training Total_Loss 10.7714 (10.8958)	Training Prec@1 68.945 (68.304)	Training Prec@5 0.000 (0.000)	
2022-07-06 21:27:51,857: ============================================================
2022-07-06 21:29:05,852: time cost, forward:0.012142479016381736, backward:0.03298170575677525, data cost:0.7022807042575577 
2022-07-06 21:29:05,852: ============================================================
2022-07-06 21:29:05,853: Epoch 3/36 Batch 3400/7662 eta: 2 days, 4:50:48.615249	Training Loss1 10.5046 (10.8853)	Training Total_Loss 10.5046 (10.8853)	Training Prec@1 71.680 (68.381)	Training Prec@5 0.000 (0.000)	
2022-07-06 21:29:05,853: ============================================================
2022-07-06 21:30:20,961: time cost, forward:0.0121673176240226, backward:0.03294871534133305, data cost:0.7023715237679908 
2022-07-06 21:30:20,962: ============================================================
2022-07-06 21:30:20,962: Epoch 3/36 Batch 3500/7662 eta: 2 days, 5:37:17.731655	Training Loss1 10.4615 (10.8757)	Training Total_Loss 10.4615 (10.8757)	Training Prec@1 74.805 (68.452)	Training Prec@5 0.000 (0.000)	
2022-07-06 21:30:20,962: ============================================================
2022-07-06 21:31:35,116: time cost, forward:0.01218918794789358, backward:0.0329288489025611, data cost:0.7021801788365056 
2022-07-06 21:31:35,116: ============================================================
2022-07-06 21:31:35,117: Epoch 3/36 Batch 3600/7662 eta: 2 days, 4:55:09.981337	Training Loss1 10.4743 (10.8654)	Training Total_Loss 10.4743 (10.8654)	Training Prec@1 70.898 (68.521)	Training Prec@5 0.000 (0.000)	
2022-07-06 21:31:35,117: ============================================================
2022-07-06 21:32:50,417: time cost, forward:0.012205925848910086, backward:0.03291362709340356, data cost:0.7023240375853964 
2022-07-06 21:32:50,418: ============================================================
2022-07-06 21:32:50,418: Epoch 3/36 Batch 3700/7662 eta: 2 days, 5:43:00.493600	Training Loss1 10.8515 (10.8559)	Training Total_Loss 10.8515 (10.8559)	Training Prec@1 67.969 (68.584)	Training Prec@5 0.000 (0.000)	
2022-07-06 21:32:50,418: ============================================================
2022-07-06 21:34:06,161: time cost, forward:0.012215768264826739, backward:0.03293958216097581, data cost:0.7025339903408492 
2022-07-06 21:34:06,162: ============================================================
2022-07-06 21:34:06,162: Epoch 3/36 Batch 3800/7662 eta: 2 days, 6:00:41.495317	Training Loss1 10.2452 (10.8473)	Training Total_Loss 10.2452 (10.8473)	Training Prec@1 72.656 (68.645)	Training Prec@5 0.000 (0.000)	
2022-07-06 21:34:06,162: ============================================================
2022-07-06 21:35:20,230: time cost, forward:0.01220350713111034, backward:0.03294499093491348, data cost:0.7023372634859323 
2022-07-06 21:35:20,231: ============================================================
2022-07-06 21:35:20,231: Epoch 3/36 Batch 3900/7662 eta: 2 days, 4:47:48.038363	Training Loss1 10.5751 (10.8376)	Training Total_Loss 10.5751 (10.8376)	Training Prec@1 67.773 (68.713)	Training Prec@5 0.000 (0.000)	
2022-07-06 21:35:20,231: ============================================================
2022-07-06 21:36:36,134: time cost, forward:0.012205320765120174, backward:0.03294878007173836, data cost:0.7026134698681308 
2022-07-06 21:36:36,146: ============================================================
2022-07-06 21:36:36,147: Epoch 3/36 Batch 4000/7662 eta: 2 days, 6:05:30.329438	Training Loss1 10.5206 (10.8268)	Training Total_Loss 10.5206 (10.8268)	Training Prec@1 71.289 (68.789)	Training Prec@5 0.000 (0.000)	
2022-07-06 21:36:36,147: ============================================================
2022-07-06 21:37:49,815: time cost, forward:0.012178922345156086, backward:0.032948693347343676, data cost:0.7023561510931546 
2022-07-06 21:37:49,815: ============================================================
2022-07-06 21:37:49,815: Epoch 3/36 Batch 4100/7662 eta: 2 days, 4:28:13.680664	Training Loss1 10.7392 (10.8171)	Training Total_Loss 10.7392 (10.8171)	Training Prec@1 67.188 (68.846)	Training Prec@5 0.000 (0.000)	
2022-07-06 21:37:49,816: ============================================================
2022-07-06 21:39:04,892: time cost, forward:0.012191168493701039, backward:0.0329260261719157, data cost:0.7024347490286594 
2022-07-06 21:39:04,893: ============================================================
2022-07-06 21:39:04,893: Epoch 3/36 Batch 4200/7662 eta: 2 days, 5:27:10.447797	Training Loss1 10.2145 (10.8072)	Training Total_Loss 10.2145 (10.8072)	Training Prec@1 73.633 (68.917)	Training Prec@5 0.000 (0.000)	
2022-07-06 21:39:04,893: ============================================================
2022-07-06 21:40:19,152: time cost, forward:0.012175791594671023, backward:0.03293106289180552, data cost:0.7023073167239657 
2022-07-06 21:40:19,152: ============================================================
2022-07-06 21:40:19,152: Epoch 3/36 Batch 4300/7662 eta: 2 days, 4:50:58.785128	Training Loss1 10.1732 (10.7962)	Training Total_Loss 10.1732 (10.7962)	Training Prec@1 71.875 (68.993)	Training Prec@5 0.000 (0.000)	
2022-07-06 21:40:19,152: ============================================================
2022-07-06 21:41:33,677: time cost, forward:0.012196144425725362, backward:0.03293177679902615, data cost:0.7022212182535152 
2022-07-06 21:41:33,677: ============================================================
2022-07-06 21:41:33,677: Epoch 3/36 Batch 4400/7662 eta: 2 days, 5:01:05.951795	Training Loss1 9.9725 (10.7866)	Training Total_Loss 9.9725 (10.7866)	Training Prec@1 73.828 (69.060)	Training Prec@5 0.000 (0.000)	
2022-07-06 21:41:33,678: ============================================================
2022-07-06 21:42:48,515: time cost, forward:0.012197457464251632, backward:0.032926759128439134, data cost:0.7022360861367665 
2022-07-06 21:42:48,516: ============================================================
2022-07-06 21:42:48,516: Epoch 3/36 Batch 4500/7662 eta: 2 days, 5:13:12.862769	Training Loss1 10.2669 (10.7769)	Training Total_Loss 10.2669 (10.7769)	Training Prec@1 74.414 (69.126)	Training Prec@5 0.000 (0.000)	
2022-07-06 21:42:48,516: ============================================================
2022-07-06 21:44:03,227: time cost, forward:0.012195559163849415, backward:0.03293537855096474, data cost:0.7022107677061575 
2022-07-06 21:44:03,228: ============================================================
2022-07-06 21:44:03,228: Epoch 3/36 Batch 4600/7662 eta: 2 days, 5:06:35.606130	Training Loss1 10.4827 (10.7674)	Training Total_Loss 10.4827 (10.7674)	Training Prec@1 68.945 (69.189)	Training Prec@5 0.000 (0.000)	
2022-07-06 21:44:03,228: ============================================================
2022-07-06 21:45:17,417: time cost, forward:0.012194856985448954, backward:0.03291982081271811, data cost:0.7020984672693324 
2022-07-06 21:45:17,417: ============================================================
2022-07-06 21:45:17,417: Epoch 3/36 Batch 4700/7662 eta: 2 days, 4:43:02.455878	Training Loss1 10.2412 (10.7573)	Training Total_Loss 10.2412 (10.7573)	Training Prec@1 73.633 (69.257)	Training Prec@5 0.000 (0.000)	
2022-07-06 21:45:17,417: ============================================================
2022-07-06 21:46:32,125: time cost, forward:0.012192855603646725, backward:0.032901787266032746, data cost:0.7020917087824401 
2022-07-06 21:46:32,126: ============================================================
2022-07-06 21:46:32,126: Epoch 3/36 Batch 4800/7662 eta: 2 days, 5:03:56.701268	Training Loss1 10.1343 (10.7472)	Training Total_Loss 10.1343 (10.7472)	Training Prec@1 74.219 (69.329)	Training Prec@5 0.000 (0.000)	
2022-07-06 21:46:32,126: ============================================================
2022-07-06 21:47:46,886: time cost, forward:0.012181862248866308, backward:0.03290282738259871, data cost:0.7020759251098726 
2022-07-06 21:47:46,887: ============================================================
2022-07-06 21:47:46,887: Epoch 3/36 Batch 4900/7662 eta: 2 days, 5:04:55.697410	Training Loss1 10.2821 (10.7383)	Training Total_Loss 10.2821 (10.7383)	Training Prec@1 73.633 (69.390)	Training Prec@5 0.000 (0.000)	
2022-07-06 21:47:46,887: ============================================================
2022-07-06 21:49:00,701: time cost, forward:0.01217881630220087, backward:0.03289803153730722, data cost:0.7019046081211787 
2022-07-06 21:49:00,702: ============================================================
2022-07-06 21:49:00,702: Epoch 3/36 Batch 5000/7662 eta: 2 days, 4:23:24.768351	Training Loss1 10.3278 (10.7294)	Training Total_Loss 10.3278 (10.7294)	Training Prec@1 73.047 (69.456)	Training Prec@5 0.000 (0.000)	
2022-07-06 21:49:00,702: ============================================================
2022-07-06 21:50:14,811: time cost, forward:0.012198085807355905, backward:0.032896475689998914, data cost:0.7017694328971694 
2022-07-06 21:50:14,811: ============================================================
2022-07-06 21:50:14,812: Epoch 3/36 Batch 5100/7662 eta: 2 days, 4:34:42.153042	Training Loss1 10.1971 (10.7198)	Training Total_Loss 10.1971 (10.7198)	Training Prec@1 72.070 (69.522)	Training Prec@5 0.000 (0.000)	
2022-07-06 21:50:14,812: ============================================================
2022-07-06 21:51:28,814: time cost, forward:0.012202350101371892, backward:0.03288934065255093, data cost:0.7016322616889721 
2022-07-06 21:51:28,814: ============================================================
2022-07-06 21:51:28,815: Epoch 3/36 Batch 5200/7662 eta: 2 days, 4:28:56.521413	Training Loss1 10.2051 (10.7107)	Training Total_Loss 10.2051 (10.7107)	Training Prec@1 73.438 (69.578)	Training Prec@5 0.000 (0.000)	
2022-07-06 21:51:28,815: ============================================================
2022-07-06 21:52:44,624: time cost, forward:0.01220319783559361, backward:0.032890046041041954, data cost:0.7018273516991697 
2022-07-06 21:52:44,624: ============================================================
2022-07-06 21:52:44,624: Epoch 3/36 Batch 5300/7662 eta: 2 days, 5:44:32.884024	Training Loss1 10.3761 (10.7019)	Training Total_Loss 10.3761 (10.7019)	Training Prec@1 72.070 (69.639)	Training Prec@5 0.000 (0.000)	
2022-07-06 21:52:44,624: ============================================================
2022-07-06 21:54:00,256: time cost, forward:0.012208868561243211, backward:0.0328967842399511, data cost:0.7019794436378994 
2022-07-06 21:54:00,256: ============================================================
2022-07-06 21:54:00,256: Epoch 3/36 Batch 5400/7662 eta: 2 days, 5:35:44.260805	Training Loss1 10.1484 (10.6922)	Training Total_Loss 10.1484 (10.6922)	Training Prec@1 75.000 (69.702)	Training Prec@5 0.000 (0.000)	
2022-07-06 21:54:00,256: ============================================================
2022-07-06 21:55:15,164: time cost, forward:0.012211788955829993, backward:0.03289398723872147, data cost:0.7020066776022431 
2022-07-06 21:55:15,164: ============================================================
2022-07-06 21:55:15,164: Epoch 3/36 Batch 5500/7662 eta: 2 days, 5:03:41.861418	Training Loss1 10.4689 (10.6832)	Training Total_Loss 10.4689 (10.6832)	Training Prec@1 70.898 (69.763)	Training Prec@5 0.000 (0.000)	
2022-07-06 21:55:15,164: ============================================================
2022-07-06 21:56:28,976: time cost, forward:0.012212164424576703, backward:0.032912873651198264, data cost:0.7018167959789993 
2022-07-06 21:56:28,977: ============================================================
2022-07-06 21:56:28,977: Epoch 3/36 Batch 5600/7662 eta: 2 days, 4:15:55.475645	Training Loss1 10.3946 (10.6742)	Training Total_Loss 10.3946 (10.6742)	Training Prec@1 73.438 (69.827)	Training Prec@5 0.000 (0.000)	
2022-07-06 21:56:28,977: ============================================================
2022-07-06 21:57:43,016: time cost, forward:0.012213989232042042, backward:0.03290806663394037, data cost:0.7016859824332381 
2022-07-06 21:57:43,016: ============================================================
2022-07-06 21:57:43,016: Epoch 3/36 Batch 5700/7662 eta: 2 days, 4:24:18.832046	Training Loss1 10.3251 (10.6657)	Training Total_Loss 10.3251 (10.6657)	Training Prec@1 72.852 (69.883)	Training Prec@5 0.000 (0.000)	
2022-07-06 21:57:43,016: ============================================================
2022-07-06 21:58:57,466: time cost, forward:0.012225861877465088, backward:0.03291171525013531, data cost:0.7016260482500619 
2022-07-06 21:58:57,466: ============================================================
2022-07-06 21:58:57,466: Epoch 3/36 Batch 5800/7662 eta: 2 days, 4:40:30.331403	Training Loss1 10.3025 (10.6570)	Training Total_Loss 10.3025 (10.6570)	Training Prec@1 70.898 (69.940)	Training Prec@5 0.000 (0.000)	
2022-07-06 21:58:57,466: ============================================================
2022-07-06 22:00:11,771: time cost, forward:0.01222773296668542, backward:0.03293060274280963, data cost:0.7015289219178715 
2022-07-06 22:00:11,772: ============================================================
2022-07-06 22:00:11,772: Epoch 3/36 Batch 5900/7662 eta: 2 days, 4:33:09.214159	Training Loss1 9.7923 (10.6476)	Training Total_Loss 9.7923 (10.6476)	Training Prec@1 76.953 (70.004)	Training Prec@5 0.000 (0.000)	
2022-07-06 22:00:11,772: ============================================================
2022-07-06 22:01:26,547: time cost, forward:0.012224912603689563, backward:0.03294477722688126, data cost:0.7015272214981413 
2022-07-06 22:01:26,548: ============================================================
2022-07-06 22:01:26,548: Epoch 3/36 Batch 6000/7662 eta: 2 days, 4:51:51.683879	Training Loss1 10.2841 (10.6389)	Training Total_Loss 10.2841 (10.6389)	Training Prec@1 72.070 (70.060)	Training Prec@5 0.000 (0.000)	
2022-07-06 22:01:26,548: ============================================================
2022-07-06 22:02:41,821: time cost, forward:0.012242026554988943, backward:0.032948606618996, data cost:0.7015915753548605 
2022-07-06 22:02:41,821: ============================================================
2022-07-06 22:02:41,821: Epoch 3/36 Batch 6100/7662 eta: 2 days, 5:11:42.309839	Training Loss1 10.1768 (10.6300)	Training Total_Loss 10.1768 (10.6300)	Training Prec@1 73.242 (70.119)	Training Prec@5 0.000 (0.000)	
2022-07-06 22:02:41,821: ============================================================
2022-07-06 22:03:57,703: time cost, forward:0.01224149244603543, backward:0.03295186274012052, data cost:0.7017693731511364 
2022-07-06 22:03:57,704: ============================================================
2022-07-06 22:03:57,704: Epoch 3/36 Batch 6200/7662 eta: 2 days, 5:36:15.842434	Training Loss1 10.1898 (10.6218)	Training Total_Loss 10.1898 (10.6218)	Training Prec@1 74.023 (70.173)	Training Prec@5 0.000 (0.000)	
2022-07-06 22:03:57,704: ============================================================
2022-07-06 22:05:13,365: time cost, forward:0.012232330530896075, backward:0.032956873808499085, data cost:0.701921932431209 
2022-07-06 22:05:13,366: ============================================================
2022-07-06 22:05:13,366: Epoch 3/36 Batch 6300/7662 eta: 2 days, 5:25:39.694645	Training Loss1 10.1667 (10.6134)	Training Total_Loss 10.1667 (10.6134)	Training Prec@1 74.023 (70.228)	Training Prec@5 0.000 (0.000)	
2022-07-06 22:05:13,366: ============================================================
2022-07-06 22:06:28,871: time cost, forward:0.012238289047207827, backward:0.032975145272303975, data cost:0.7020124971056231 
2022-07-06 22:06:28,871: ============================================================
2022-07-06 22:06:28,872: Epoch 3/36 Batch 6400/7662 eta: 2 days, 5:17:47.103016	Training Loss1 10.2398 (10.6051)	Training Total_Loss 10.2398 (10.6051)	Training Prec@1 71.094 (70.281)	Training Prec@5 0.000 (0.000)	
2022-07-06 22:06:28,872: ============================================================
2022-07-06 22:07:43,214: time cost, forward:0.012234616818877803, backward:0.0329743667939458, data cost:0.7019481593635489 
2022-07-06 22:07:43,214: ============================================================
2022-07-06 22:07:43,214: Epoch 3/36 Batch 6500/7662 eta: 2 days, 4:27:17.391702	Training Loss1 10.1457 (10.5967)	Training Total_Loss 10.1457 (10.5967)	Training Prec@1 74.023 (70.335)	Training Prec@5 0.000 (0.000)	
2022-07-06 22:07:43,215: ============================================================
2022-07-06 22:08:56,918: time cost, forward:0.012234077866934777, backward:0.032977864098812634, data cost:0.7017452324099713 
2022-07-06 22:08:56,918: ============================================================
2022-07-06 22:08:56,919: Epoch 3/36 Batch 6600/7662 eta: 2 days, 3:59:01.671713	Training Loss1 10.1675 (10.5892)	Training Total_Loss 10.1675 (10.5892)	Training Prec@1 73.047 (70.386)	Training Prec@5 0.000 (0.000)	
2022-07-06 22:08:56,919: ============================================================
2022-07-06 22:10:12,556: time cost, forward:0.012253669077361728, backward:0.032978386394229106, data cost:0.7018974280780884 
2022-07-06 22:10:12,556: ============================================================
2022-07-06 22:10:12,557: Epoch 3/36 Batch 6700/7662 eta: 2 days, 5:19:35.826342	Training Loss1 10.1041 (10.5811)	Training Total_Loss 10.1041 (10.5811)	Training Prec@1 72.070 (70.438)	Training Prec@5 0.000 (0.000)	
2022-07-06 22:10:12,557: ============================================================
2022-07-06 22:11:27,448: time cost, forward:0.012257325577374713, backward:0.03300194158889315, data cost:0.7018793260793438 
2022-07-06 22:11:27,448: ============================================================
2022-07-06 22:11:27,449: Epoch 3/36 Batch 6800/7662 eta: 2 days, 4:46:47.519764	Training Loss1 10.1495 (10.5733)	Training Total_Loss 10.1495 (10.5733)	Training Prec@1 69.922 (70.486)	Training Prec@5 0.000 (0.000)	
2022-07-06 22:11:27,449: ============================================================
2022-07-06 22:12:40,736: time cost, forward:0.012252228590764417, backward:0.033011072182036735, data cost:0.7016601822033777 
2022-07-06 22:12:40,736: ============================================================
2022-07-06 22:12:40,737: Epoch 3/36 Batch 6900/7662 eta: 2 days, 3:37:44.959958	Training Loss1 10.0043 (10.5649)	Training Total_Loss 10.0043 (10.5649)	Training Prec@1 71.875 (70.540)	Training Prec@5 0.000 (0.000)	
2022-07-06 22:12:40,737: ============================================================
2022-07-06 22:13:56,096: time cost, forward:0.012245914189708898, backward:0.033006484959189904, data cost:0.7017640302412543 
2022-07-06 22:13:56,096: ============================================================
2022-07-06 22:13:56,097: Epoch 3/36 Batch 7000/7662 eta: 2 days, 5:04:04.576755	Training Loss1 9.6902 (10.5572)	Training Total_Loss 9.6902 (10.5572)	Training Prec@1 78.711 (70.591)	Training Prec@5 0.000 (0.000)	
2022-07-06 22:13:56,097: ============================================================
2022-07-06 22:15:09,661: time cost, forward:0.012234070415580117, backward:0.03300854356746671, data cost:0.7016051853017112 
2022-07-06 22:15:09,661: ============================================================
2022-07-06 22:15:09,662: Epoch 3/36 Batch 7100/7662 eta: 2 days, 3:47:00.251244	Training Loss1 10.0464 (10.5493)	Training Total_Loss 10.0464 (10.5493)	Training Prec@1 73.047 (70.641)	Training Prec@5 0.000 (0.000)	
2022-07-06 22:15:09,662: ============================================================
2022-07-06 22:16:25,363: time cost, forward:0.012238052656690616, backward:0.03301087967768893, data cost:0.7017306508844404 
2022-07-06 22:16:25,363: ============================================================
2022-07-06 22:16:25,364: Epoch 3/36 Batch 7200/7662 eta: 2 days, 5:16:00.076167	Training Loss1 10.0274 (10.5412)	Training Total_Loss 10.0274 (10.5412)	Training Prec@1 74.805 (70.695)	Training Prec@5 0.000 (0.000)	
2022-07-06 22:16:25,364: ============================================================
2022-07-06 22:17:38,966: time cost, forward:0.012235387087946217, backward:0.0330070224359013, data cost:0.7015746067706682 
2022-07-06 22:17:38,966: ============================================================
2022-07-06 22:17:38,966: Epoch 3/36 Batch 7300/7662 eta: 2 days, 3:46:08.812762	Training Loss1 9.9455 (10.5334)	Training Total_Loss 9.9455 (10.5334)	Training Prec@1 76.562 (70.744)	Training Prec@5 0.000 (0.000)	
2022-07-06 22:17:38,966: ============================================================
2022-07-06 22:18:53,358: time cost, forward:0.012236149379700837, backward:0.033002121542930474, data cost:0.7015299431326132 
2022-07-06 22:18:53,358: ============================================================
2022-07-06 22:18:53,358: Epoch 3/36 Batch 7400/7662 eta: 2 days, 4:18:13.080717	Training Loss1 9.7782 (10.5259)	Training Total_Loss 9.7782 (10.5259)	Training Prec@1 77.148 (70.794)	Training Prec@5 0.000 (0.000)	
2022-07-06 22:18:53,359: ============================================================
2022-07-06 22:20:07,910: time cost, forward:0.012229832542278017, backward:0.03299974718003579, data cost:0.701515781639385 
2022-07-06 22:20:07,910: ============================================================
2022-07-06 22:20:07,911: Epoch 3/36 Batch 7500/7662 eta: 2 days, 4:23:43.354850	Training Loss1 10.1660 (10.5181)	Training Total_Loss 10.1660 (10.5181)	Training Prec@1 71.680 (70.844)	Training Prec@5 0.000 (0.000)	
2022-07-06 22:20:07,911: ============================================================
2022-07-06 22:21:23,360: time cost, forward:0.012232560643335286, backward:0.03301117523420263, data cost:0.7015960605885891 
2022-07-06 22:21:23,361: ============================================================
2022-07-06 22:21:23,361: Epoch 3/36 Batch 7600/7662 eta: 2 days, 5:00:20.558169	Training Loss1 9.9696 (10.5108)	Training Total_Loss 9.9696 (10.5108)	Training Prec@1 74.609 (70.890)	Training Prec@5 0.000 (0.000)	
2022-07-06 22:21:23,361: ============================================================
2022-07-06 22:22:11,547: Epoch 3/36 Batch 7663/7662 eta: 2 days, 4:59:33.024490	Training Loss1 9.9722 (10.5064)	Training Total_Loss 9.9722 (10.5064)	Training Prec@1 73.828 (70.918)	Training Prec@5 0.000 (0.000)	
2022-07-06 22:22:11,547: ============================================================
2022-07-06 22:23:29,634: time cost, forward:0.010947788604582199, backward:0.03338837141942496, data cost:0.7371853192647299 
2022-07-06 22:23:29,634: ============================================================
2022-07-06 22:23:29,634: Epoch 4/36 Batch 100/7662 eta: 2 days, 6:43:21.879157	Training Loss1 9.0420 (9.4887)	Training Total_Loss 9.0420 (9.4887)	Training Prec@1 79.688 (77.231)	Training Prec@5 0.000 (0.000)	
2022-07-06 22:23:29,634: ============================================================
2022-07-06 22:24:44,246: time cost, forward:0.010834279371865431, backward:0.0334036134595248, data cost:0.7191661985675294 
2022-07-06 22:24:44,246: ============================================================
2022-07-06 22:24:44,246: Epoch 4/36 Batch 200/7662 eta: 2 days, 4:21:44.818179	Training Loss1 9.7759 (9.5010)	Training Total_Loss 9.7759 (9.5010)	Training Prec@1 76.367 (77.357)	Training Prec@5 0.000 (0.000)	
2022-07-06 22:24:44,246: ============================================================
2022-07-06 22:25:58,052: time cost, forward:0.010675849723178008, backward:0.033472750099207645, data cost:0.7106354699086983 
2022-07-06 22:25:58,052: ============================================================
2022-07-06 22:25:58,053: Epoch 4/36 Batch 300/7662 eta: 2 days, 3:46:36.400100	Training Loss1 9.4061 (9.5341)	Training Total_Loss 9.4061 (9.5341)	Training Prec@1 77.344 (77.340)	Training Prec@5 0.000 (0.000)	
2022-07-06 22:25:58,053: ============================================================
2022-07-06 22:27:13,517: time cost, forward:0.0109470452282363, backward:0.03355709592202552, data cost:0.7100707612240822 
2022-07-06 22:27:13,517: ============================================================
2022-07-06 22:27:13,517: Epoch 4/36 Batch 400/7662 eta: 2 days, 4:55:07.860171	Training Loss1 9.4319 (9.5506)	Training Total_Loss 9.4319 (9.5506)	Training Prec@1 79.688 (77.241)	Training Prec@5 0.000 (0.000)	
2022-07-06 22:27:13,517: ============================================================
2022-07-06 22:28:28,088: time cost, forward:0.01123812394533941, backward:0.033567789800181415, data cost:0.7078456348312164 
2022-07-06 22:28:28,088: ============================================================
2022-07-06 22:28:28,089: Epoch 4/36 Batch 500/7662 eta: 2 days, 4:16:18.472780	Training Loss1 9.6480 (9.5812)	Training Total_Loss 9.6480 (9.5812)	Training Prec@1 77.539 (77.103)	Training Prec@5 0.000 (0.000)	
2022-07-06 22:28:28,089: ============================================================
2022-07-06 22:29:40,555: time cost, forward:0.011407544099428816, backward:0.03355430641238001, data cost:0.7028163569996473 
2022-07-06 22:29:40,555: ============================================================
2022-07-06 22:29:40,555: Epoch 4/36 Batch 600/7662 eta: 2 days, 2:46:35.547842	Training Loss1 9.3546 (9.6061)	Training Total_Loss 9.3546 (9.6061)	Training Prec@1 78.711 (76.948)	Training Prec@5 0.000 (0.000)	
2022-07-06 22:29:40,556: ============================================================
2022-07-06 22:30:53,278: time cost, forward:0.01162807897095687, backward:0.03353722787892528, data cost:0.6996266899872917 
2022-07-06 22:30:53,279: ============================================================
2022-07-06 22:30:53,279: Epoch 4/36 Batch 700/7662 eta: 2 days, 2:56:09.879506	Training Loss1 9.8535 (9.6193)	Training Total_Loss 9.8535 (9.6193)	Training Prec@1 75.781 (76.880)	Training Prec@5 0.000 (0.000)	
2022-07-06 22:30:53,279: ============================================================
2022-07-06 22:32:06,844: time cost, forward:0.01165136109305562, backward:0.03347985347609347, data cost:0.6984651894384392 
2022-07-06 22:32:06,844: ============================================================
2022-07-06 22:32:06,844: Epoch 4/36 Batch 800/7662 eta: 2 days, 3:30:19.718165	Training Loss1 9.8104 (9.6347)	Training Total_Loss 9.8104 (9.6347)	Training Prec@1 75.586 (76.777)	Training Prec@5 0.000 (0.000)	
2022-07-06 22:32:06,844: ============================================================
2022-07-06 22:33:21,344: time cost, forward:0.01177289011215872, backward:0.033318570511492264, data cost:0.698586245665163 
2022-07-06 22:33:21,344: ============================================================
2022-07-06 22:33:21,344: Epoch 4/36 Batch 900/7662 eta: 2 days, 4:08:20.122750	Training Loss1 9.8000 (9.6482)	Training Total_Loss 9.8000 (9.6482)	Training Prec@1 74.414 (76.666)	Training Prec@5 0.000 (0.000)	
2022-07-06 22:33:21,344: ============================================================
2022-07-06 22:34:35,237: time cost, forward:0.011799113528506534, backward:0.033249664831686544, data cost:0.6980862085287038 
2022-07-06 22:34:35,238: ============================================================
2022-07-06 22:34:35,238: Epoch 4/36 Batch 1000/7662 eta: 2 days, 3:41:38.858592	Training Loss1 9.6893 (9.6572)	Training Total_Loss 9.6893 (9.6572)	Training Prec@1 76.758 (76.606)	Training Prec@5 0.000 (0.000)	
2022-07-06 22:34:35,238: ============================================================
2022-07-06 22:35:48,932: time cost, forward:0.011789684625405198, backward:0.033190143878509826, data cost:0.6975407335734346 
2022-07-06 22:35:48,932: ============================================================
2022-07-06 22:35:48,932: Epoch 4/36 Batch 1100/7662 eta: 2 days, 3:32:03.223473	Training Loss1 10.3348 (9.6703)	Training Total_Loss 10.3348 (9.6703)	Training Prec@1 70.508 (76.522)	Training Prec@5 0.000 (0.000)	
2022-07-06 22:35:48,932: ============================================================
2022-07-06 22:37:02,273: time cost, forward:0.011773725665540274, backward:0.033134075479769924, data cost:0.6968023411128001 
2022-07-06 22:37:02,274: ============================================================
2022-07-06 22:37:02,274: Epoch 4/36 Batch 1200/7662 eta: 2 days, 3:16:02.345786	Training Loss1 9.5553 (9.6797)	Training Total_Loss 9.5553 (9.6797)	Training Prec@1 77.539 (76.439)	Training Prec@5 0.000 (0.000)	
2022-07-06 22:37:02,274: ============================================================
2022-07-06 22:38:15,875: time cost, forward:0.011822627084451606, backward:0.03311600017033695, data cost:0.6962946050436888 
2022-07-06 22:38:15,876: ============================================================
2022-07-06 22:38:15,876: Epoch 4/36 Batch 1300/7662 eta: 2 days, 3:25:43.162939	Training Loss1 10.0097 (9.6872)	Training Total_Loss 10.0097 (9.6872)	Training Prec@1 75.195 (76.390)	Training Prec@5 0.000 (0.000)	
2022-07-06 22:38:15,876: ============================================================
2022-07-06 22:39:29,846: time cost, forward:0.011881809391406198, backward:0.03311627383228708, data cost:0.6960506480109956 
2022-07-06 22:39:29,847: ============================================================
2022-07-06 22:39:29,847: Epoch 4/36 Batch 1400/7662 eta: 2 days, 3:39:58.505917	Training Loss1 9.6893 (9.6922)	Training Total_Loss 9.6893 (9.6922)	Training Prec@1 76.562 (76.344)	Training Prec@5 0.000 (0.000)	
2022-07-06 22:39:29,847: ============================================================
2022-07-06 22:40:43,672: time cost, forward:0.011889326803043256, backward:0.03307304547738043, data cost:0.6958962078488931 
2022-07-06 22:40:43,672: ============================================================
2022-07-06 22:40:43,672: Epoch 4/36 Batch 1500/7662 eta: 2 days, 3:32:38.071647	Training Loss1 9.4100 (9.6948)	Training Total_Loss 9.4100 (9.6948)	Training Prec@1 79.102 (76.303)	Training Prec@5 0.000 (0.000)	
2022-07-06 22:40:43,673: ============================================================
2022-07-06 22:41:57,868: time cost, forward:0.011886989123527522, backward:0.03312815271965633, data cost:0.6958272908910355 
2022-07-06 22:41:57,869: ============================================================
2022-07-06 22:41:57,869: Epoch 4/36 Batch 1600/7662 eta: 2 days, 3:46:55.905454	Training Loss1 9.6617 (9.7013)	Training Total_Loss 9.6617 (9.7013)	Training Prec@1 78.125 (76.253)	Training Prec@5 0.000 (0.000)	
2022-07-06 22:41:57,869: ============================================================
2022-07-06 22:43:12,119: time cost, forward:0.011928974284081687, backward:0.03311934563747359, data cost:0.6958282383979946 
2022-07-06 22:43:12,119: ============================================================
2022-07-06 22:43:12,119: Epoch 4/36 Batch 1700/7662 eta: 2 days, 3:47:57.766622	Training Loss1 9.8344 (9.7024)	Training Total_Loss 9.8344 (9.7024)	Training Prec@1 73.438 (76.233)	Training Prec@5 0.000 (0.000)	
2022-07-06 22:43:12,119: ============================================================
2022-07-06 22:44:26,664: time cost, forward:0.011942200292276633, backward:0.03312918144573829, data cost:0.6961071295099434 
2022-07-06 22:44:26,664: ============================================================
2022-07-06 22:44:26,664: Epoch 4/36 Batch 1800/7662 eta: 2 days, 3:59:03.318533	Training Loss1 9.6518 (9.7062)	Training Total_Loss 9.6518 (9.7062)	Training Prec@1 77.344 (76.199)	Training Prec@5 0.000 (0.000)	
2022-07-06 22:44:26,664: ============================================================
2022-07-06 22:45:40,422: time cost, forward:0.01196964895681308, backward:0.03314670667703557, data cost:0.6958261192817949 
2022-07-06 22:45:40,422: ============================================================
2022-07-06 22:45:40,422: Epoch 4/36 Batch 1900/7662 eta: 2 days, 3:24:53.418000	Training Loss1 9.6708 (9.7095)	Training Total_Loss 9.6708 (9.7095)	Training Prec@1 77.344 (76.164)	Training Prec@5 0.000 (0.000)	
2022-07-06 22:45:40,422: ============================================================
2022-07-06 22:46:53,548: time cost, forward:0.011949933964708795, backward:0.033116817712903084, data cost:0.6953527967950116 
2022-07-06 22:46:53,548: ============================================================
2022-07-06 22:46:53,548: Epoch 4/36 Batch 2000/7662 eta: 2 days, 2:57:13.777776	Training Loss1 9.7891 (9.7086)	Training Total_Loss 9.7891 (9.7086)	Training Prec@1 75.586 (76.166)	Training Prec@5 0.000 (0.000)	
2022-07-06 22:46:53,548: ============================================================
2022-07-06 22:48:07,622: time cost, forward:0.011947670909778, backward:0.03308410290140604, data cost:0.6953738051519444 
2022-07-06 22:48:07,623: ============================================================
2022-07-06 22:48:07,623: Epoch 4/36 Batch 2100/7662 eta: 2 days, 3:35:41.020913	Training Loss1 10.0432 (9.7084)	Training Total_Loss 10.0432 (9.7084)	Training Prec@1 70.312 (76.148)	Training Prec@5 0.000 (0.000)	
2022-07-06 22:48:07,623: ============================================================
2022-07-06 22:49:22,204: time cost, forward:0.011975043033566894, backward:0.03302076492812645, data cost:0.6956231957297262 
2022-07-06 22:49:22,205: ============================================================
2022-07-06 22:49:22,205: Epoch 4/36 Batch 2200/7662 eta: 2 days, 3:55:37.044206	Training Loss1 9.5975 (9.7085)	Training Total_Loss 9.5975 (9.7085)	Training Prec@1 77.539 (76.147)	Training Prec@5 0.000 (0.000)	
2022-07-06 22:49:22,205: ============================================================
2022-07-06 22:50:35,411: time cost, forward:0.011971328817486193, backward:0.033059384212021, data cost:0.6951956884816399 
2022-07-06 22:50:35,411: ============================================================
2022-07-06 22:50:35,411: Epoch 4/36 Batch 2300/7662 eta: 2 days, 2:56:56.582763	Training Loss1 9.7333 (9.7081)	Training Total_Loss 9.7333 (9.7081)	Training Prec@1 75.391 (76.146)	Training Prec@5 0.000 (0.000)	
2022-07-06 22:50:35,411: ============================================================
2022-07-06 22:51:50,278: time cost, forward:0.01198134466030539, backward:0.0330842498343604, data cost:0.6954804568948623 
2022-07-06 22:51:50,278: ============================================================
2022-07-06 22:51:50,278: Epoch 4/36 Batch 2400/7662 eta: 2 days, 4:05:02.073346	Training Loss1 9.6565 (9.7064)	Training Total_Loss 9.6565 (9.7064)	Training Prec@1 75.586 (76.147)	Training Prec@5 0.000 (0.000)	
2022-07-06 22:51:50,278: ============================================================
2022-07-06 22:53:04,029: time cost, forward:0.01197828126459324, backward:0.03312833521928058, data cost:0.6952911128326147 
2022-07-06 22:53:04,029: ============================================================
2022-07-06 22:53:04,030: Epoch 4/36 Batch 2500/7662 eta: 2 days, 3:17:13.758394	Training Loss1 9.8926 (9.7079)	Training Total_Loss 9.8926 (9.7079)	Training Prec@1 76.758 (76.131)	Training Prec@5 0.000 (0.000)	
2022-07-06 22:53:04,030: ============================================================
2022-07-06 22:54:17,306: time cost, forward:0.011960337922498784, backward:0.033165356066191184, data cost:0.6949811727553893 
2022-07-06 22:54:17,306: ============================================================
2022-07-06 22:54:17,306: Epoch 4/36 Batch 2600/7662 eta: 2 days, 2:56:12.551382	Training Loss1 9.4885 (9.7064)	Training Total_Loss 9.4885 (9.7064)	Training Prec@1 77.539 (76.129)	Training Prec@5 0.000 (0.000)	
2022-07-06 22:54:17,306: ============================================================
2022-07-06 22:55:33,102: time cost, forward:0.011980850549042778, backward:0.033171839517944605, data cost:0.6955818423256692 
2022-07-06 22:55:33,102: ============================================================
2022-07-06 22:55:33,103: Epoch 4/36 Batch 2700/7662 eta: 2 days, 4:40:02.426848	Training Loss1 10.2093 (9.7058)	Training Total_Loss 10.2093 (9.7058)	Training Prec@1 73.438 (76.120)	Training Prec@5 0.000 (0.000)	
2022-07-06 22:55:33,103: ============================================================
2022-07-06 22:56:47,197: time cost, forward:0.011948408506392751, backward:0.03317439867028512, data cost:0.6955999167913537 
2022-07-06 22:56:47,198: ============================================================
2022-07-06 22:56:47,198: Epoch 4/36 Batch 2800/7662 eta: 2 days, 3:27:53.325672	Training Loss1 9.8320 (9.7059)	Training Total_Loss 9.8320 (9.7059)	Training Prec@1 72.656 (76.115)	Training Prec@5 0.000 (0.000)	
2022-07-06 22:56:47,198: ============================================================
2022-07-06 22:58:01,512: time cost, forward:0.011953227887609245, backward:0.0331889402048059, data cost:0.6956412179505426 
2022-07-06 22:58:01,512: ============================================================
2022-07-06 22:58:01,513: Epoch 4/36 Batch 2900/7662 eta: 2 days, 3:35:47.131713	Training Loss1 9.8610 (9.7042)	Training Total_Loss 9.8610 (9.7042)	Training Prec@1 73.242 (76.118)	Training Prec@5 0.000 (0.000)	
2022-07-06 22:58:01,513: ============================================================
2022-07-06 22:59:16,680: time cost, forward:0.011942095818540261, backward:0.03319108720698648, data cost:0.6960002034852886 
2022-07-06 22:59:16,681: ============================================================
2022-07-06 22:59:16,681: Epoch 4/36 Batch 3000/7662 eta: 2 days, 4:10:05.941242	Training Loss1 9.7605 (9.7022)	Training Total_Loss 9.7605 (9.7022)	Training Prec@1 76.953 (76.122)	Training Prec@5 0.000 (0.000)	
2022-07-06 22:59:16,681: ============================================================
2022-07-06 23:00:31,572: time cost, forward:0.011959602002675936, backward:0.03320341419504319, data cost:0.6961793453318721 
2022-07-06 23:00:31,573: ============================================================
2022-07-06 23:00:31,573: Epoch 4/36 Batch 3100/7662 eta: 2 days, 3:57:20.392738	Training Loss1 9.5868 (9.7006)	Training Total_Loss 9.5868 (9.7006)	Training Prec@1 76.953 (76.122)	Training Prec@5 0.000 (0.000)	
2022-07-06 23:00:31,573: ============================================================
2022-07-06 23:01:45,883: time cost, forward:0.011947115349300059, backward:0.033192130542241176, data cost:0.696251079789472 
2022-07-06 23:01:45,884: ============================================================
2022-07-06 23:01:45,884: Epoch 4/36 Batch 3200/7662 eta: 2 days, 3:31:55.614560	Training Loss1 9.6280 (9.6989)	Training Total_Loss 9.6280 (9.6989)	Training Prec@1 75.391 (76.125)	Training Prec@5 0.000 (0.000)	
2022-07-06 23:01:45,884: ============================================================
2022-07-06 23:03:00,206: time cost, forward:0.011948472118695673, backward:0.03319423868642427, data cost:0.6962562028694673 
2022-07-06 23:03:00,207: ============================================================
2022-07-06 23:03:00,207: Epoch 4/36 Batch 3300/7662 eta: 2 days, 3:31:10.081912	Training Loss1 9.5435 (9.6975)	Training Total_Loss 9.5435 (9.6975)	Training Prec@1 78.125 (76.125)	Training Prec@5 0.000 (0.000)	
2022-07-06 23:03:00,207: ============================================================
2022-07-06 23:04:13,679: time cost, forward:0.011949851745084722, backward:0.033194710977570596, data cost:0.6960714138336271 
2022-07-06 23:04:13,680: ============================================================
2022-07-06 23:04:13,680: Epoch 4/36 Batch 3400/7662 eta: 2 days, 2:54:36.264612	Training Loss1 9.5534 (9.6956)	Training Total_Loss 9.5534 (9.6956)	Training Prec@1 76.758 (76.128)	Training Prec@5 0.000 (0.000)	
2022-07-06 23:04:13,680: ============================================================
2022-07-06 23:05:28,068: time cost, forward:0.011959287908357291, backward:0.03323069672204318, data cost:0.6960985998522727 
2022-07-06 23:05:28,069: ============================================================
2022-07-06 23:05:28,069: Epoch 4/36 Batch 3500/7662 eta: 2 days, 3:31:27.220025	Training Loss1 9.7238 (9.6930)	Training Total_Loss 9.7238 (9.6930)	Training Prec@1 74.219 (76.138)	Training Prec@5 0.000 (0.000)	
2022-07-06 23:05:28,069: ============================================================
2022-07-06 23:06:41,708: time cost, forward:0.011978368555118257, backward:0.03325191124441492, data cost:0.6958644072126434 
2022-07-06 23:06:41,708: ============================================================
2022-07-06 23:06:41,708: Epoch 4/36 Batch 3600/7662 eta: 2 days, 2:59:03.483087	Training Loss1 9.5392 (9.6911)	Training Total_Loss 9.5392 (9.6911)	Training Prec@1 75.977 (76.142)	Training Prec@5 0.000 (0.000)	
2022-07-06 23:06:41,708: ============================================================
2022-07-06 23:07:55,888: time cost, forward:0.01198761828624419, backward:0.033258359604314974, data cost:0.6958783121488004 
2022-07-06 23:07:55,888: ============================================================
2022-07-06 23:07:55,888: Epoch 4/36 Batch 3700/7662 eta: 2 days, 3:20:17.110519	Training Loss1 9.8030 (9.6889)	Training Total_Loss 9.8030 (9.6889)	Training Prec@1 75.391 (76.147)	Training Prec@5 0.000 (0.000)	
2022-07-06 23:07:55,888: ============================================================
2022-07-06 23:09:09,929: time cost, forward:0.011996668368523044, backward:0.03322292183787925, data cost:0.6958538535771542 
2022-07-06 23:09:09,930: ============================================================
2022-07-06 23:09:09,930: Epoch 4/36 Batch 3800/7662 eta: 2 days, 3:13:18.937516	Training Loss1 9.5486 (9.6862)	Training Total_Loss 9.5486 (9.6862)	Training Prec@1 75.586 (76.161)	Training Prec@5 0.000 (0.000)	
2022-07-06 23:09:09,930: ============================================================
2022-07-06 23:10:24,848: time cost, forward:0.012015157187403884, backward:0.03321973535763236, data cost:0.6960476404215991 
2022-07-06 23:10:24,848: ============================================================
2022-07-06 23:10:24,848: Epoch 4/36 Batch 3900/7662 eta: 2 days, 3:48:26.829222	Training Loss1 9.7902 (9.6834)	Training Total_Loss 9.7902 (9.6834)	Training Prec@1 75.977 (76.179)	Training Prec@5 0.000 (0.000)	
2022-07-06 23:10:24,848: ============================================================
2022-07-06 23:11:39,715: time cost, forward:0.012030949739254424, backward:0.03321566805895581, data cost:0.6962063143210997 
2022-07-06 23:11:39,715: ============================================================
2022-07-06 23:11:39,715: Epoch 4/36 Batch 4000/7662 eta: 2 days, 3:45:03.914715	Training Loss1 9.6869 (9.6801)	Training Total_Loss 9.6869 (9.6801)	Training Prec@1 76.953 (76.197)	Training Prec@5 0.000 (0.000)	
2022-07-06 23:11:39,715: ============================================================
2022-07-06 23:12:54,013: time cost, forward:0.01204334232509936, backward:0.03322988063656839, data cost:0.6961940658124489 
2022-07-06 23:12:54,013: ============================================================
2022-07-06 23:12:54,013: Epoch 4/36 Batch 4100/7662 eta: 2 days, 3:20:14.404510	Training Loss1 9.5927 (9.6773)	Training Total_Loss 9.5927 (9.6773)	Training Prec@1 75.000 (76.208)	Training Prec@5 0.000 (0.000)	
2022-07-06 23:12:54,013: ============================================================
2022-07-06 23:14:07,940: time cost, forward:0.012058927718160492, backward:0.0332701613318781, data cost:0.6960758520722758 
2022-07-06 23:14:07,940: ============================================================
2022-07-06 23:14:07,940: Epoch 4/36 Batch 4200/7662 eta: 2 days, 3:03:37.492483	Training Loss1 9.3182 (9.6741)	Training Total_Loss 9.3182 (9.6741)	Training Prec@1 77.148 (76.226)	Training Prec@5 0.000 (0.000)	
2022-07-06 23:14:07,940: ============================================================
2022-07-06 23:15:22,264: time cost, forward:0.012078053342877334, backward:0.03328468240008961, data cost:0.6960731840433146 
2022-07-06 23:15:22,264: ============================================================
2022-07-06 23:15:22,265: Epoch 4/36 Batch 4300/7662 eta: 2 days, 3:18:50.623680	Training Loss1 9.3801 (9.6710)	Training Total_Loss 9.3801 (9.6710)	Training Prec@1 80.273 (76.243)	Training Prec@5 0.000 (0.000)	
2022-07-06 23:15:22,265: ============================================================
2022-07-06 23:16:36,863: time cost, forward:0.01209994840957978, backward:0.03329394887484971, data cost:0.6961289704672503 
2022-07-06 23:16:36,864: ============================================================
2022-07-06 23:16:36,864: Epoch 4/36 Batch 4400/7662 eta: 2 days, 3:28:59.502882	Training Loss1 9.5672 (9.6692)	Training Total_Loss 9.5672 (9.6692)	Training Prec@1 77.930 (76.242)	Training Prec@5 0.000 (0.000)	
2022-07-06 23:16:36,864: ============================================================
2022-07-06 23:17:51,505: time cost, forward:0.012105837533886788, backward:0.03327388322520293, data cost:0.6962452024373778 
2022-07-06 23:17:51,505: ============================================================
2022-07-06 23:17:51,505: Epoch 4/36 Batch 4500/7662 eta: 2 days, 3:29:29.812903	Training Loss1 9.3651 (9.6671)	Training Total_Loss 9.3651 (9.6671)	Training Prec@1 78.516 (76.249)	Training Prec@5 0.000 (0.000)	
2022-07-06 23:17:51,505: ============================================================
2022-07-06 23:19:06,918: time cost, forward:0.012104424634014012, backward:0.033256360514575076, data cost:0.6965200499779091 
2022-07-06 23:19:06,918: ============================================================
2022-07-06 23:19:06,919: Epoch 4/36 Batch 4600/7662 eta: 2 days, 4:00:11.340765	Training Loss1 9.4913 (9.6645)	Training Total_Loss 9.4913 (9.6645)	Training Prec@1 77.344 (76.259)	Training Prec@5 0.000 (0.000)	
2022-07-06 23:19:06,919: ============================================================
2022-07-06 23:20:21,728: time cost, forward:0.012092710277024014, backward:0.03324465336609861, data cost:0.6966558419584999 
2022-07-06 23:20:21,728: ============================================================
2022-07-06 23:20:21,728: Epoch 4/36 Batch 4700/7662 eta: 2 days, 3:33:57.367807	Training Loss1 10.0036 (9.6617)	Training Total_Loss 10.0036 (9.6617)	Training Prec@1 72.852 (76.273)	Training Prec@5 0.000 (0.000)	
2022-07-06 23:20:21,728: ============================================================
2022-07-06 23:21:37,825: time cost, forward:0.012087344874886578, backward:0.033253031538088736, data cost:0.6970414136146152 
2022-07-06 23:21:37,825: ============================================================
2022-07-06 23:21:37,825: Epoch 4/36 Batch 4800/7662 eta: 2 days, 4:25:57.047980	Training Loss1 9.5274 (9.6591)	Training Total_Loss 9.5274 (9.6591)	Training Prec@1 79.688 (76.286)	Training Prec@5 0.000 (0.000)	
2022-07-06 23:21:37,825: ============================================================
2022-07-06 23:22:52,328: time cost, forward:0.012087066651947961, backward:0.033258708308341184, data cost:0.697078004956951 
2022-07-06 23:22:52,328: ============================================================
2022-07-06 23:22:52,328: Epoch 4/36 Batch 4900/7662 eta: 2 days, 3:18:47.254130	Training Loss1 9.2707 (9.6565)	Training Total_Loss 9.2707 (9.6565)	Training Prec@1 79.297 (76.296)	Training Prec@5 0.000 (0.000)	
2022-07-06 23:22:52,328: ============================================================
2022-07-06 23:24:07,638: time cost, forward:0.012084408220373934, backward:0.03327194741545355, data cost:0.6972635251613921 
2022-07-06 23:24:07,638: ============================================================
2022-07-06 23:24:07,639: Epoch 4/36 Batch 5000/7662 eta: 2 days, 3:50:54.995523	Training Loss1 9.6762 (9.6538)	Training Total_Loss 9.6762 (9.6538)	Training Prec@1 77.148 (76.306)	Training Prec@5 0.000 (0.000)	
2022-07-06 23:24:07,639: ============================================================
2022-07-06 23:25:22,392: time cost, forward:0.012071216683874973, backward:0.033274051371123846, data cost:0.6973602609976667 
2022-07-06 23:25:22,392: ============================================================
2022-07-06 23:25:22,392: Epoch 4/36 Batch 5100/7662 eta: 2 days, 3:26:39.415389	Training Loss1 9.4226 (9.6515)	Training Total_Loss 9.4226 (9.6515)	Training Prec@1 77.734 (76.318)	Training Prec@5 0.000 (0.000)	
2022-07-06 23:25:22,392: ============================================================
2022-07-06 23:26:36,940: time cost, forward:0.012061267386126642, backward:0.03327901974667217, data cost:0.6974073322627792 
2022-07-06 23:26:36,940: ============================================================
2022-07-06 23:26:36,940: Epoch 4/36 Batch 5200/7662 eta: 2 days, 3:16:56.719497	Training Loss1 9.7060 (9.6494)	Training Total_Loss 9.7060 (9.6494)	Training Prec@1 73.828 (76.327)	Training Prec@5 0.000 (0.000)	
2022-07-06 23:26:36,941: ============================================================
2022-07-06 23:27:52,127: time cost, forward:0.01207442161249066, backward:0.033272903805567335, data cost:0.6975472178137917 
2022-07-06 23:27:52,128: ============================================================
2022-07-06 23:27:52,128: Epoch 4/36 Batch 5300/7662 eta: 2 days, 3:42:04.182252	Training Loss1 9.6508 (9.6469)	Training Total_Loss 9.6508 (9.6469)	Training Prec@1 76.562 (76.337)	Training Prec@5 0.000 (0.000)	
2022-07-06 23:27:52,128: ============================================================
2022-07-06 23:29:06,919: time cost, forward:0.0120832051010259, backward:0.033268771672341574, data cost:0.6976294850040131 
2022-07-06 23:29:06,919: ============================================================
2022-07-06 23:29:06,919: Epoch 4/36 Batch 5400/7662 eta: 2 days, 3:24:29.025892	Training Loss1 9.4993 (9.6437)	Training Total_Loss 9.4993 (9.6437)	Training Prec@1 76.367 (76.350)	Training Prec@5 0.000 (0.000)	
2022-07-06 23:29:06,919: ============================================================
2022-07-06 23:30:21,979: time cost, forward:0.012089708151004817, backward:0.03326807570123612, data cost:0.6977561543390607 
2022-07-06 23:30:21,979: ============================================================
2022-07-06 23:30:21,980: Epoch 4/36 Batch 5500/7662 eta: 2 days, 3:34:19.599843	Training Loss1 9.5189 (9.6411)	Training Total_Loss 9.5189 (9.6411)	Training Prec@1 75.000 (76.364)	Training Prec@5 0.000 (0.000)	
2022-07-06 23:30:21,980: ============================================================
2022-07-06 23:31:36,970: time cost, forward:0.012092828963522102, backward:0.0332864412432761, data cost:0.6978454563868516 
2022-07-06 23:31:36,970: ============================================================
2022-07-06 23:31:36,971: Epoch 4/36 Batch 5600/7662 eta: 2 days, 3:30:13.008815	Training Loss1 9.5055 (9.6380)	Training Total_Loss 9.5055 (9.6380)	Training Prec@1 75.586 (76.379)	Training Prec@5 0.000 (0.000)	
2022-07-06 23:31:36,971: ============================================================
2022-07-06 23:32:53,134: time cost, forward:0.01209455332142739, backward:0.033283463610454825, data cost:0.6981583378737088 
2022-07-06 23:32:53,134: ============================================================
2022-07-06 23:32:53,134: Epoch 4/36 Batch 5700/7662 eta: 2 days, 4:17:16.651085	Training Loss1 9.1215 (9.6355)	Training Total_Loss 9.1215 (9.6355)	Training Prec@1 82.031 (76.390)	Training Prec@5 0.000 (0.000)	
2022-07-06 23:32:53,135: ============================================================
2022-07-06 23:34:06,967: time cost, forward:0.012095286365541266, backward:0.03327218584612251, data cost:0.6980682990328569 
2022-07-06 23:34:06,967: ============================================================
2022-07-06 23:34:06,967: Epoch 4/36 Batch 5800/7662 eta: 2 days, 2:40:01.787289	Training Loss1 9.4759 (9.6332)	Training Total_Loss 9.4759 (9.6332)	Training Prec@1 77.344 (76.402)	Training Prec@5 0.000 (0.000)	
2022-07-06 23:34:06,967: ============================================================
2022-07-06 23:35:22,701: time cost, forward:0.012099815760856766, backward:0.03326730446040297, data cost:0.6982912515700722 
2022-07-06 23:35:22,701: ============================================================
2022-07-06 23:35:22,701: Epoch 4/36 Batch 5900/7662 eta: 2 days, 3:57:02.303355	Training Loss1 10.0857 (9.6299)	Training Total_Loss 10.0857 (9.6299)	Training Prec@1 72.852 (76.418)	Training Prec@5 0.000 (0.000)	
2022-07-06 23:35:22,701: ============================================================
2022-07-06 23:36:38,337: time cost, forward:0.01210804274925134, backward:0.033265978281727275, data cost:0.6984918717643304 
2022-07-06 23:36:38,337: ============================================================
2022-07-06 23:36:38,337: Epoch 4/36 Batch 6000/7662 eta: 2 days, 3:51:46.014184	Training Loss1 9.7034 (9.6275)	Training Total_Loss 9.7034 (9.6275)	Training Prec@1 76.562 (76.432)	Training Prec@5 0.000 (0.000)	
2022-07-06 23:36:38,338: ============================================================
2022-07-06 23:37:53,747: time cost, forward:0.0121127634991347, backward:0.03327682999865621, data cost:0.6986296059636136 
2022-07-06 23:37:53,747: ============================================================
2022-07-06 23:37:53,747: Epoch 4/36 Batch 6100/7662 eta: 2 days, 3:41:11.362860	Training Loss1 9.4617 (9.6241)	Training Total_Loss 9.4617 (9.6241)	Training Prec@1 75.781 (76.451)	Training Prec@5 0.000 (0.000)	
2022-07-06 23:37:53,747: ============================================================
2022-07-06 23:39:09,301: time cost, forward:0.012112412573464706, backward:0.03327410385327525, data cost:0.6988006963097563 
2022-07-06 23:39:09,301: ============================================================
2022-07-06 23:39:09,301: Epoch 4/36 Batch 6200/7662 eta: 2 days, 3:45:51.214278	Training Loss1 9.7639 (9.6214)	Training Total_Loss 9.7639 (9.6214)	Training Prec@1 74.414 (76.465)	Training Prec@5 0.000 (0.000)	
2022-07-06 23:39:09,301: ============================================================
2022-07-06 23:40:24,373: time cost, forward:0.012118075836043563, backward:0.03327255897019322, data cost:0.6988796851316659 
2022-07-06 23:40:24,373: ============================================================
2022-07-06 23:40:24,374: Epoch 4/36 Batch 6300/7662 eta: 2 days, 3:24:49.120580	Training Loss1 9.2665 (9.6186)	Training Total_Loss 9.2665 (9.6186)	Training Prec@1 78.516 (76.480)	Training Prec@5 0.000 (0.000)	
2022-07-06 23:40:24,374: ============================================================
2022-07-06 23:41:40,610: time cost, forward:0.012120311270283244, backward:0.033267971164901884, data cost:0.699176911358387 
2022-07-06 23:41:40,610: ============================================================
2022-07-06 23:41:40,610: Epoch 4/36 Batch 6400/7662 eta: 2 days, 4:11:23.035514	Training Loss1 9.3592 (9.6161)	Training Total_Loss 9.3592 (9.6161)	Training Prec@1 77.734 (76.489)	Training Prec@5 0.000 (0.000)	
2022-07-06 23:41:40,610: ============================================================
2022-07-06 23:42:54,274: time cost, forward:0.012123882706338835, backward:0.03326765484655063, data cost:0.6990419093380159 
2022-07-06 23:42:54,274: ============================================================
2022-07-06 23:42:54,274: Epoch 4/36 Batch 6500/7662 eta: 2 days, 2:24:28.863280	Training Loss1 9.5685 (9.6137)	Training Total_Loss 9.5685 (9.6137)	Training Prec@1 76.172 (76.500)	Training Prec@5 0.000 (0.000)	
2022-07-06 23:42:54,274: ============================================================
2022-07-06 23:44:10,736: time cost, forward:0.01212917181339602, backward:0.033260174096759694, data cost:0.6993407989960942 
2022-07-06 23:44:10,736: ============================================================
2022-07-06 23:44:10,736: Epoch 4/36 Batch 6600/7662 eta: 2 days, 4:18:05.103766	Training Loss1 9.1002 (9.6112)	Training Total_Loss 9.1002 (9.6112)	Training Prec@1 81.445 (76.510)	Training Prec@5 0.000 (0.000)	
2022-07-06 23:44:10,736: ============================================================
2022-07-06 23:45:25,915: time cost, forward:0.012132688536005494, backward:0.03325932266854905, data cost:0.6994329241963176 
2022-07-06 23:45:25,916: ============================================================
2022-07-06 23:45:25,916: Epoch 4/36 Batch 6700/7662 eta: 2 days, 3:24:12.952085	Training Loss1 9.1881 (9.6085)	Training Total_Loss 9.1881 (9.6085)	Training Prec@1 79.688 (76.522)	Training Prec@5 0.000 (0.000)	
2022-07-06 23:45:25,916: ============================================================
2022-07-06 23:46:42,008: time cost, forward:0.012130806315977936, backward:0.03326919671805015, data cost:0.6996475921201082 
2022-07-06 23:46:42,008: ============================================================
2022-07-06 23:46:42,008: Epoch 4/36 Batch 6800/7662 eta: 2 days, 4:00:22.886931	Training Loss1 9.3680 (9.6053)	Training Total_Loss 9.3680 (9.6053)	Training Prec@1 78.125 (76.537)	Training Prec@5 0.000 (0.000)	
2022-07-06 23:46:42,008: ============================================================
2022-07-06 23:47:57,289: time cost, forward:0.012141384479187074, backward:0.033278983612823596, data cost:0.6997330138987088 
2022-07-06 23:47:57,289: ============================================================
2022-07-06 23:47:57,289: Epoch 4/36 Batch 6900/7662 eta: 2 days, 3:25:51.396004	Training Loss1 9.1748 (9.6025)	Training Total_Loss 9.1748 (9.6025)	Training Prec@1 78.516 (76.553)	Training Prec@5 0.000 (0.000)	
2022-07-06 23:47:57,289: ============================================================
2022-07-06 23:49:11,756: time cost, forward:0.012148016026095334, backward:0.033284047208933985, data cost:0.6996977781292234 
2022-07-06 23:49:11,757: ============================================================
2022-07-06 23:49:11,757: Epoch 4/36 Batch 7000/7662 eta: 2 days, 2:51:16.682043	Training Loss1 9.4617 (9.5993)	Training Total_Loss 9.4617 (9.5993)	Training Prec@1 79.102 (76.572)	Training Prec@5 0.000 (0.000)	
2022-07-06 23:49:11,757: ============================================================
2022-07-06 23:50:27,913: time cost, forward:0.012161501160237568, backward:0.03327577358266807, data cost:0.6999218069276166 
2022-07-06 23:50:27,913: ============================================================
2022-07-06 23:50:27,913: Epoch 4/36 Batch 7100/7662 eta: 2 days, 3:59:11.515713	Training Loss1 9.3046 (9.5967)	Training Total_Loss 9.3046 (9.5967)	Training Prec@1 76.953 (76.584)	Training Prec@5 0.000 (0.000)	
2022-07-06 23:50:27,913: ============================================================
2022-07-06 23:51:42,773: time cost, forward:0.012167363419170461, backward:0.03327897380235908, data cost:0.6999492075297878 
2022-07-06 23:51:42,773: ============================================================
2022-07-06 23:51:42,773: Epoch 4/36 Batch 7200/7662 eta: 2 days, 3:04:51.852888	Training Loss1 9.3459 (9.5935)	Training Total_Loss 9.3459 (9.5935)	Training Prec@1 78.320 (76.598)	Training Prec@5 0.000 (0.000)	
2022-07-06 23:51:42,774: ============================================================
2022-07-06 23:52:56,318: time cost, forward:0.012178134389047118, backward:0.03328469155961348, data cost:0.6997834713365267 
2022-07-06 23:52:56,318: ============================================================
2022-07-06 23:52:56,319: Epoch 4/36 Batch 7300/7662 eta: 2 days, 2:09:48.021975	Training Loss1 9.1862 (9.5900)	Training Total_Loss 9.1862 (9.5900)	Training Prec@1 76.758 (76.615)	Training Prec@5 0.000 (0.000)	
2022-07-06 23:52:56,319: ============================================================
2022-07-06 23:54:11,665: time cost, forward:0.012182289046973115, backward:0.033274037014037985, data cost:0.6998923499610943 
2022-07-06 23:54:11,665: ============================================================
2022-07-06 23:54:11,666: Epoch 4/36 Batch 7400/7662 eta: 2 days, 3:22:16.706194	Training Loss1 9.7320 (9.5868)	Training Total_Loss 9.7320 (9.5868)	Training Prec@1 75.586 (76.630)	Training Prec@5 0.000 (0.000)	
2022-07-06 23:54:11,666: ============================================================
2022-07-06 23:55:27,048: time cost, forward:0.012178351075065217, backward:0.033270286741153704, data cost:0.7000102335523806 
2022-07-06 23:55:27,048: ============================================================
2022-07-06 23:55:27,049: Epoch 4/36 Batch 7500/7662 eta: 2 days, 3:22:29.825806	Training Loss1 9.4652 (9.5839)	Training Total_Loss 9.4652 (9.5839)	Training Prec@1 76.562 (76.644)	Training Prec@5 0.000 (0.000)	
2022-07-06 23:55:27,049: ============================================================
2022-07-06 23:56:42,810: time cost, forward:0.012176196251061108, backward:0.033271428361850784, data cost:0.7001598916378189 
2022-07-06 23:56:42,811: ============================================================
2022-07-06 23:56:42,811: Epoch 4/36 Batch 7600/7662 eta: 2 days, 3:36:45.194173	Training Loss1 9.4135 (9.5809)	Training Total_Loss 9.4135 (9.5809)	Training Prec@1 79.297 (76.660)	Training Prec@5 0.000 (0.000)	
2022-07-06 23:56:42,811: ============================================================
2022-07-06 23:57:32,273: Epoch 4/36 Batch 7663/7662 eta: 2 days, 3:35:57.463815	Training Loss1 9.5575 (9.5795)	Training Total_Loss 9.5575 (9.5795)	Training Prec@1 76.562 (76.666)	Training Prec@5 0.000 (0.000)	
2022-07-06 23:57:32,274: ============================================================
2022-07-06 23:58:48,444: time cost, forward:0.01209435077628704, backward:0.03256645347132827, data cost:0.7187264567673809 
2022-07-06 23:58:48,445: ============================================================
2022-07-06 23:58:48,445: Epoch 5/36 Batch 100/7662 eta: 2 days, 3:51:19.674597	Training Loss1 8.8779 (8.8900)	Training Total_Loss 8.8779 (8.8900)	Training Prec@1 83.008 (80.747)	Training Prec@5 0.000 (0.000)	
2022-07-06 23:58:48,445: ============================================================
2022-07-07 00:00:01,355: time cost, forward:0.012167107519791952, backward:0.03256822590851904, data cost:0.7013068570563542 
2022-07-07 00:00:01,356: ============================================================
2022-07-07 00:00:01,356: Epoch 5/36 Batch 200/7662 eta: 2 days, 1:37:01.197955	Training Loss1 8.9600 (8.9385)	Training Total_Loss 8.9600 (8.9385)	Training Prec@1 79.688 (80.470)	Training Prec@5 0.000 (0.000)	
2022-07-07 00:00:01,356: ============================================================
2022-07-07 00:01:15,415: time cost, forward:0.012268334328131533, backward:0.03242616031480872, data cost:0.6991057029137244 
2022-07-07 00:01:15,415: ============================================================
2022-07-07 00:01:15,416: Epoch 5/36 Batch 300/7662 eta: 2 days, 2:22:40.883853	Training Loss1 9.0649 (8.9672)	Training Total_Loss 9.0649 (8.9672)	Training Prec@1 80.078 (80.316)	Training Prec@5 0.000 (0.000)	
2022-07-07 00:01:15,416: ============================================================
2022-07-07 00:02:29,497: time cost, forward:0.01236817711278012, backward:0.03234941021242835, data cost:0.6983685792239388 
2022-07-07 00:02:29,497: ============================================================
2022-07-07 00:02:29,497: Epoch 5/36 Batch 400/7662 eta: 2 days, 2:22:20.816022	Training Loss1 8.8431 (9.0046)	Training Total_Loss 8.8431 (9.0046)	Training Prec@1 80.273 (80.058)	Training Prec@5 0.000 (0.000)	
2022-07-07 00:02:29,497: ============================================================
2022-07-07 00:03:43,728: time cost, forward:0.012418373314316621, backward:0.03251438819334836, data cost:0.6978342494888152 
2022-07-07 00:03:43,728: ============================================================
2022-07-07 00:03:43,729: Epoch 5/36 Batch 500/7662 eta: 2 days, 2:27:12.497329	Training Loss1 9.2475 (9.0316)	Training Total_Loss 9.2475 (9.0316)	Training Prec@1 76.758 (79.942)	Training Prec@5 0.000 (0.000)	
2022-07-07 00:03:43,729: ============================================================
2022-07-07 00:04:57,451: time cost, forward:0.012462402225933807, backward:0.032513657475950725, data cost:0.6967904917982862 
2022-07-07 00:04:57,451: ============================================================
2022-07-07 00:04:57,451: Epoch 5/36 Batch 600/7662 eta: 2 days, 2:05:14.959987	Training Loss1 9.1841 (9.0475)	Training Total_Loss 9.1841 (9.0475)	Training Prec@1 78.516 (79.856)	Training Prec@5 0.000 (0.000)	
2022-07-07 00:04:57,451: ============================================================
2022-07-07 00:06:11,736: time cost, forward:0.012378754022295383, backward:0.03253454234296501, data cost:0.6968717182825223 
2022-07-07 00:06:11,736: ============================================================
2022-07-07 00:06:11,736: Epoch 5/36 Batch 700/7662 eta: 2 days, 2:26:56.165682	Training Loss1 9.3591 (9.0660)	Training Total_Loss 9.3591 (9.0660)	Training Prec@1 78.320 (79.760)	Training Prec@5 0.000 (0.000)	
2022-07-07 00:06:11,737: ============================================================
2022-07-07 00:07:24,226: time cost, forward:0.012281121240837852, backward:0.032569961941734574, data cost:0.694779781585044 
2022-07-07 00:07:24,227: ============================================================
2022-07-07 00:07:24,227: Epoch 5/36 Batch 800/7662 eta: 2 days, 1:12:35.427083	Training Loss1 9.1078 (9.0880)	Training Total_Loss 9.1078 (9.0880)	Training Prec@1 81.055 (79.599)	Training Prec@5 0.000 (0.000)	
2022-07-07 00:07:24,227: ============================================================
2022-07-07 00:08:37,993: time cost, forward:0.01233646230517293, backward:0.0325445993591071, data cost:0.694473086262704 
2022-07-07 00:08:37,994: ============================================================
2022-07-07 00:08:37,994: Epoch 5/36 Batch 900/7662 eta: 2 days, 2:03:22.097920	Training Loss1 9.0852 (9.1030)	Training Total_Loss 9.0852 (9.1030)	Training Prec@1 79.883 (79.525)	Training Prec@5 0.000 (0.000)	
2022-07-07 00:08:37,994: ============================================================
2022-07-07 00:09:51,697: time cost, forward:0.012343884469033242, backward:0.032445977042029214, data cost:0.6942507268430235 
2022-07-07 00:09:51,697: ============================================================
2022-07-07 00:09:51,698: Epoch 5/36 Batch 1000/7662 eta: 2 days, 1:59:33.372437	Training Loss1 9.2962 (9.1167)	Training Total_Loss 9.2962 (9.1167)	Training Prec@1 77.930 (79.438)	Training Prec@5 0.000 (0.000)	
2022-07-07 00:09:51,698: ============================================================
2022-07-07 00:11:04,692: time cost, forward:0.012363350315458455, backward:0.03239450593554399, data cost:0.6934047997052069 
2022-07-07 00:11:04,693: ============================================================
2022-07-07 00:11:04,693: Epoch 5/36 Batch 1100/7662 eta: 2 days, 1:29:30.310444	Training Loss1 9.4316 (9.1283)	Training Total_Loss 9.4316 (9.1283)	Training Prec@1 76.953 (79.360)	Training Prec@5 0.000 (0.000)	
2022-07-07 00:11:04,693: ============================================================
2022-07-07 00:12:18,778: time cost, forward:0.012407563545984263, backward:0.03230793800226741, data cost:0.6935884232715928 
2022-07-07 00:12:18,779: ============================================================
2022-07-07 00:12:18,779: Epoch 5/36 Batch 1200/7662 eta: 2 days, 2:12:38.813109	Training Loss1 9.4788 (9.1407)	Training Total_Loss 9.4788 (9.1407)	Training Prec@1 76.758 (79.293)	Training Prec@5 0.000 (0.000)	
2022-07-07 00:12:18,779: ============================================================
2022-07-07 00:13:32,896: time cost, forward:0.012415943740421851, backward:0.03239490180129359, data cost:0.6936886297729586 
2022-07-07 00:13:32,896: ============================================================
2022-07-07 00:13:32,896: Epoch 5/36 Batch 1300/7662 eta: 2 days, 2:12:41.216170	Training Loss1 9.0963 (9.1487)	Training Total_Loss 9.0963 (9.1487)	Training Prec@1 80.078 (79.256)	Training Prec@5 0.000 (0.000)	
2022-07-07 00:13:32,896: ============================================================
2022-07-07 00:14:48,277: time cost, forward:0.012381391750223897, backward:0.03243734088431434, data cost:0.694734138621016 
2022-07-07 00:14:48,277: ============================================================
2022-07-07 00:14:48,278: Epoch 5/36 Batch 1400/7662 eta: 2 days, 3:02:48.188798	Training Loss1 8.9567 (9.1549)	Training Total_Loss 8.9567 (9.1549)	Training Prec@1 80.664 (79.207)	Training Prec@5 0.000 (0.000)	
2022-07-07 00:14:48,278: ============================================================
2022-07-07 00:16:01,536: time cost, forward:0.012326524765035008, backward:0.03248294756522252, data cost:0.6941664285704324 
2022-07-07 00:16:01,536: ============================================================
2022-07-07 00:16:01,537: Epoch 5/36 Batch 1500/7662 eta: 2 days, 1:35:21.512686	Training Loss1 9.5056 (9.1615)	Training Total_Loss 9.5056 (9.1615)	Training Prec@1 75.000 (79.148)	Training Prec@5 0.000 (0.000)	
2022-07-07 00:16:01,537: ============================================================
2022-07-07 00:17:14,681: time cost, forward:0.012300617326565875, backward:0.03254875531414287, data cost:0.6936615967169041 
2022-07-07 00:17:14,682: ============================================================
2022-07-07 00:17:14,682: Epoch 5/36 Batch 1600/7662 eta: 2 days, 1:29:30.726743	Training Loss1 9.5978 (9.1690)	Training Total_Loss 9.5978 (9.1690)	Training Prec@1 77.148 (79.087)	Training Prec@5 0.000 (0.000)	
2022-07-07 00:17:14,682: ============================================================
2022-07-07 00:18:30,117: time cost, forward:0.012301669533355156, backward:0.03256027189123413, data cost:0.69457576904948 
2022-07-07 00:18:30,117: ============================================================
2022-07-07 00:18:30,117: Epoch 5/36 Batch 1700/7662 eta: 2 days, 3:01:13.834949	Training Loss1 9.3053 (9.1740)	Training Total_Loss 9.3053 (9.1740)	Training Prec@1 79.883 (79.034)	Training Prec@5 0.000 (0.000)	
2022-07-07 00:18:30,117: ============================================================
2022-07-07 00:19:43,861: time cost, forward:0.012284338374877387, backward:0.032576158220334606, data cost:0.6944258300511952 
2022-07-07 00:19:43,861: ============================================================
2022-07-07 00:19:43,861: Epoch 5/36 Batch 1800/7662 eta: 2 days, 1:51:21.754800	Training Loss1 8.9434 (9.1785)	Training Total_Loss 8.9434 (9.1785)	Training Prec@1 80.273 (78.998)	Training Prec@5 0.000 (0.000)	
2022-07-07 00:19:43,861: ============================================================
2022-07-07 00:20:57,954: time cost, forward:0.012283810820938601, backward:0.032623244562294686, data cost:0.694444500941738 
2022-07-07 00:20:57,954: ============================================================
2022-07-07 00:20:57,955: Epoch 5/36 Batch 1900/7662 eta: 2 days, 2:04:17.944902	Training Loss1 9.5153 (9.1850)	Training Total_Loss 9.5153 (9.1850)	Training Prec@1 74.219 (78.944)	Training Prec@5 0.000 (0.000)	
2022-07-07 00:20:57,955: ============================================================
2022-07-07 00:22:11,475: time cost, forward:0.012314465834296543, backward:0.032642555332231545, data cost:0.6941559965936108 
2022-07-07 00:22:11,475: ============================================================
2022-07-07 00:22:11,476: Epoch 5/36 Batch 2000/7662 eta: 2 days, 1:39:51.921290	Training Loss1 9.4853 (9.1903)	Training Total_Loss 9.4853 (9.1903)	Training Prec@1 76.367 (78.910)	Training Prec@5 0.000 (0.000)	
2022-07-07 00:22:11,476: ============================================================
2022-07-07 00:23:27,308: time cost, forward:0.012304626799243129, backward:0.032677083653799406, data cost:0.6950037031868856 
2022-07-07 00:23:27,309: ============================================================
2022-07-07 00:23:27,309: Epoch 5/36 Batch 2100/7662 eta: 2 days, 3:12:19.873105	Training Loss1 9.1051 (9.1919)	Training Total_Loss 9.1051 (9.1919)	Training Prec@1 78.516 (78.897)	Training Prec@5 0.000 (0.000)	
2022-07-07 00:23:27,309: ============================================================
2022-07-07 00:24:42,038: time cost, forward:0.012316278134112253, backward:0.03267657198435396, data cost:0.6952790183986302 
2022-07-07 00:24:42,038: ============================================================
2022-07-07 00:24:42,039: Epoch 5/36 Batch 2200/7662 eta: 2 days, 2:26:21.522055	Training Loss1 9.3546 (9.1956)	Training Total_Loss 9.3546 (9.1956)	Training Prec@1 79.688 (78.882)	Training Prec@5 0.000 (0.000)	
2022-07-07 00:24:42,039: ============================================================
2022-07-07 00:25:55,880: time cost, forward:0.01229118989726262, backward:0.03270319380310112, data cost:0.6951969368865356 
2022-07-07 00:25:55,881: ============================================================
2022-07-07 00:25:55,881: Epoch 5/36 Batch 2300/7662 eta: 2 days, 1:49:12.032348	Training Loss1 9.0859 (9.1993)	Training Total_Loss 9.0859 (9.1993)	Training Prec@1 79.688 (78.849)	Training Prec@5 0.000 (0.000)	
2022-07-07 00:25:55,881: ============================================================
2022-07-07 00:27:08,165: time cost, forward:0.012270879526841933, backward:0.03268387855316709, data cost:0.6944799611050668 
2022-07-07 00:27:08,165: ============================================================
2022-07-07 00:27:08,165: Epoch 5/36 Batch 2400/7662 eta: 2 days, 0:44:55.339567	Training Loss1 9.1199 (9.2018)	Training Total_Loss 9.1199 (9.2018)	Training Prec@1 79.492 (78.821)	Training Prec@5 0.000 (0.000)	
2022-07-07 00:27:08,165: ============================================================
2022-07-07 00:28:22,009: time cost, forward:0.012264309810991046, backward:0.032677656080590194, data cost:0.6944379443977298 
2022-07-07 00:28:22,009: ============================================================
2022-07-07 00:28:22,009: Epoch 5/36 Batch 2500/7662 eta: 2 days, 1:46:48.849749	Training Loss1 9.4810 (9.2022)	Training Total_Loss 9.4810 (9.2022)	Training Prec@1 77.344 (78.805)	Training Prec@5 0.000 (0.000)	
2022-07-07 00:28:22,010: ============================================================
2022-07-07 00:29:35,535: time cost, forward:0.012275010267098438, backward:0.03266422333007319, data cost:0.6942535947496591 
2022-07-07 00:29:35,536: ============================================================
2022-07-07 00:29:35,536: Epoch 5/36 Batch 2600/7662 eta: 2 days, 1:32:44.731941	Training Loss1 9.1371 (9.2033)	Training Total_Loss 9.1371 (9.2033)	Training Prec@1 77.734 (78.791)	Training Prec@5 0.000 (0.000)	
2022-07-07 00:29:35,536: ============================================================
2022-07-07 00:30:48,995: time cost, forward:0.012302299833774743, backward:0.032657273745881316, data cost:0.6940250565450073 
2022-07-07 00:30:48,995: ============================================================
2022-07-07 00:30:48,995: Epoch 5/36 Batch 2700/7662 eta: 2 days, 1:28:46.818229	Training Loss1 9.0513 (9.2042)	Training Total_Loss 9.0513 (9.2042)	Training Prec@1 80.273 (78.776)	Training Prec@5 0.000 (0.000)	
2022-07-07 00:30:48,995: ============================================================
2022-07-07 00:32:02,974: time cost, forward:0.012312739012112741, backward:0.03262945403793788, data cost:0.6940516965565574 
2022-07-07 00:32:02,975: ============================================================
2022-07-07 00:32:02,975: Epoch 5/36 Batch 2800/7662 eta: 2 days, 1:48:36.273950	Training Loss1 9.1417 (9.2046)	Training Total_Loss 9.1417 (9.2046)	Training Prec@1 80.078 (78.768)	Training Prec@5 0.000 (0.000)	
2022-07-07 00:32:02,975: ============================================================
2022-07-07 00:33:17,144: time cost, forward:0.01232870491096257, backward:0.03260736689151423, data cost:0.6941328603837276 
2022-07-07 00:33:17,145: ============================================================
2022-07-07 00:33:17,145: Epoch 5/36 Batch 2900/7662 eta: 2 days, 1:55:02.282705	Training Loss1 8.8682 (9.2053)	Training Total_Loss 8.8682 (9.2053)	Training Prec@1 80.273 (78.755)	Training Prec@5 0.000 (0.000)	
2022-07-07 00:33:17,145: ============================================================
2022-07-07 00:34:29,462: time cost, forward:0.012359308377628764, backward:0.03259359029341873, data cost:0.6935447039863355 
2022-07-07 00:34:29,462: ============================================================
2022-07-07 00:34:29,463: Epoch 5/36 Batch 3000/7662 eta: 2 days, 0:39:03.411428	Training Loss1 9.1799 (9.2053)	Training Total_Loss 9.1799 (9.2053)	Training Prec@1 78.516 (78.749)	Training Prec@5 0.000 (0.000)	
2022-07-07 00:34:29,463: ============================================================
2022-07-07 00:35:43,139: time cost, forward:0.012358262716627537, backward:0.0325785808772493, data cost:0.6935135283443996 
2022-07-07 00:35:43,139: ============================================================
2022-07-07 00:35:43,139: Epoch 5/36 Batch 3100/7662 eta: 2 days, 1:32:40.005141	Training Loss1 9.1860 (9.2053)	Training Total_Loss 9.1860 (9.2053)	Training Prec@1 79.297 (78.739)	Training Prec@5 0.000 (0.000)	
2022-07-07 00:35:43,140: ============================================================
2022-07-07 00:36:57,744: time cost, forward:0.012365448359363934, backward:0.03254112820209433, data cost:0.6937549896782806 
2022-07-07 00:36:57,744: ============================================================
2022-07-07 00:36:57,744: Epoch 5/36 Batch 3200/7662 eta: 2 days, 2:08:52.737369	Training Loss1 9.3404 (9.2057)	Training Total_Loss 9.3404 (9.2057)	Training Prec@1 78.320 (78.738)	Training Prec@5 0.000 (0.000)	
2022-07-07 00:36:57,744: ============================================================
2022-07-07 00:38:11,588: time cost, forward:0.012384607127739755, backward:0.03247809092107416, data cost:0.6937818824973891 
2022-07-07 00:38:11,589: ============================================================
2022-07-07 00:38:11,589: Epoch 5/36 Batch 3300/7662 eta: 2 days, 1:36:58.506007	Training Loss1 9.2235 (9.2057)	Training Total_Loss 9.2235 (9.2057)	Training Prec@1 77.930 (78.732)	Training Prec@5 0.000 (0.000)	
2022-07-07 00:38:11,589: ============================================================
2022-07-07 00:39:25,154: time cost, forward:0.012378204847371168, backward:0.03248146429732464, data cost:0.693671732728851 
2022-07-07 00:39:25,154: ============================================================
2022-07-07 00:39:25,154: Epoch 5/36 Batch 3400/7662 eta: 2 days, 1:24:30.714890	Training Loss1 9.0512 (9.2056)	Training Total_Loss 9.0512 (9.2056)	Training Prec@1 81.836 (78.732)	Training Prec@5 0.000 (0.000)	
2022-07-07 00:39:25,154: ============================================================
2022-07-07 00:40:39,098: time cost, forward:0.012383352044174487, backward:0.0324495252318708, data cost:0.6936874311969906 
2022-07-07 00:40:39,098: ============================================================
2022-07-07 00:40:39,098: Epoch 5/36 Batch 3500/7662 eta: 2 days, 1:38:31.436560	Training Loss1 9.4364 (9.2064)	Training Total_Loss 9.4364 (9.2064)	Training Prec@1 76.953 (78.719)	Training Prec@5 0.000 (0.000)	
2022-07-07 00:40:39,098: ============================================================
2022-07-07 00:41:53,173: time cost, forward:0.01240042025064488, backward:0.03245306491984298, data cost:0.6937226986149743 
2022-07-07 00:41:53,173: ============================================================
2022-07-07 00:41:53,173: Epoch 5/36 Batch 3600/7662 eta: 2 days, 1:42:33.456435	Training Loss1 8.7222 (9.2054)	Training Total_Loss 8.7222 (9.2054)	Training Prec@1 82.422 (78.724)	Training Prec@5 0.000 (0.000)	
2022-07-07 00:41:53,173: ============================================================
2022-07-07 00:43:07,295: time cost, forward:0.012380417568292383, backward:0.032473489444750196, data cost:0.6937744398315586 
2022-07-07 00:43:07,295: ============================================================
2022-07-07 00:43:07,295: Epoch 5/36 Batch 3700/7662 eta: 2 days, 1:43:13.600890	Training Loss1 9.0145 (9.2054)	Training Total_Loss 9.0145 (9.2054)	Training Prec@1 79.883 (78.715)	Training Prec@5 0.000 (0.000)	
2022-07-07 00:43:07,295: ============================================================
2022-07-07 00:44:22,197: time cost, forward:0.012382848666322391, backward:0.032468868011109105, data cost:0.6940461591407794 
2022-07-07 00:44:22,198: ============================================================
2022-07-07 00:44:22,198: Epoch 5/36 Batch 3800/7662 eta: 2 days, 2:13:23.782130	Training Loss1 9.1527 (9.2047)	Training Total_Loss 9.1527 (9.2047)	Training Prec@1 79.102 (78.711)	Training Prec@5 0.000 (0.000)	
2022-07-07 00:44:22,198: ============================================================
2022-07-07 00:45:35,588: time cost, forward:0.012380779569165527, backward:0.032457799476120645, data cost:0.6939153369190326 
2022-07-07 00:45:35,589: ============================================================
2022-07-07 00:45:35,589: Epoch 5/36 Batch 3900/7662 eta: 2 days, 1:11:21.566471	Training Loss1 9.2080 (9.2057)	Training Total_Loss 9.2080 (9.2057)	Training Prec@1 78.711 (78.700)	Training Prec@5 0.000 (0.000)	
2022-07-07 00:45:35,589: ============================================================
2022-07-07 00:46:49,828: time cost, forward:0.012378947619767032, backward:0.03244295660392378, data cost:0.694009781420365 
2022-07-07 00:46:49,828: ============================================================
2022-07-07 00:46:49,829: Epoch 5/36 Batch 4000/7662 eta: 2 days, 1:44:14.921730	Training Loss1 9.1228 (9.2051)	Training Total_Loss 9.1228 (9.2051)	Training Prec@1 78.711 (78.698)	Training Prec@5 0.000 (0.000)	
2022-07-07 00:46:49,829: ============================================================
2022-07-07 00:48:03,704: time cost, forward:0.012375685086218896, backward:0.032441653807473256, data cost:0.6939957055791932 
2022-07-07 00:48:03,705: ============================================================
2022-07-07 00:48:03,705: Epoch 5/36 Batch 4100/7662 eta: 2 days, 1:28:24.748212	Training Loss1 8.7986 (9.2046)	Training Total_Loss 8.7986 (9.2046)	Training Prec@1 82.031 (78.692)	Training Prec@5 0.000 (0.000)	
2022-07-07 00:48:03,705: ============================================================
2022-07-07 00:49:18,421: time cost, forward:0.012392937157602077, backward:0.03243712085461327, data cost:0.6941626417719202 
2022-07-07 00:49:18,421: ============================================================
2022-07-07 00:49:18,421: Epoch 5/36 Batch 4200/7662 eta: 2 days, 2:00:55.592104	Training Loss1 9.0211 (9.2039)	Training Total_Loss 9.0211 (9.2039)	Training Prec@1 79.883 (78.691)	Training Prec@5 0.000 (0.000)	
2022-07-07 00:49:18,421: ============================================================
2022-07-07 00:50:34,066: time cost, forward:0.012405156922856162, backward:0.032452267528994466, data cost:0.6945343515046061 
2022-07-07 00:50:34,066: ============================================================
2022-07-07 00:50:34,067: Epoch 5/36 Batch 4300/7662 eta: 2 days, 2:36:58.105457	Training Loss1 9.5269 (9.2034)	Training Total_Loss 9.5269 (9.2034)	Training Prec@1 76.562 (78.688)	Training Prec@5 0.000 (0.000)	
2022-07-07 00:50:34,067: ============================================================
2022-07-07 00:51:48,138: time cost, forward:0.012396407848218539, backward:0.032468008870399925, data cost:0.6945430095912815 
2022-07-07 00:51:48,138: ============================================================
2022-07-07 00:51:48,138: Epoch 5/36 Batch 4400/7662 eta: 2 days, 1:32:32.835241	Training Loss1 9.4299 (9.2032)	Training Total_Loss 9.4299 (9.2032)	Training Prec@1 77.148 (78.685)	Training Prec@5 0.000 (0.000)	
2022-07-07 00:51:48,138: ============================================================
2022-07-07 00:53:02,842: time cost, forward:0.012393352799374254, backward:0.032468143583112466, data cost:0.6946990610785314 
2022-07-07 00:53:02,842: ============================================================
2022-07-07 00:53:02,842: Epoch 5/36 Batch 4500/7662 eta: 2 days, 1:56:41.838271	Training Loss1 9.5243 (9.2031)	Training Total_Loss 9.5243 (9.2031)	Training Prec@1 76.367 (78.684)	Training Prec@5 0.000 (0.000)	
2022-07-07 00:53:02,842: ============================================================
2022-07-07 00:54:17,116: time cost, forward:0.012387289381929262, backward:0.032484689570686356, data cost:0.6947457828737389 
2022-07-07 00:54:17,116: ============================================================
2022-07-07 00:54:17,116: Epoch 5/36 Batch 4600/7662 eta: 2 days, 1:38:11.572151	Training Loss1 9.0641 (9.2022)	Training Total_Loss 9.0641 (9.2022)	Training Prec@1 77.148 (78.684)	Training Prec@5 0.000 (0.000)	
2022-07-07 00:54:17,116: ============================================================
2022-07-07 00:55:31,387: time cost, forward:0.012367178161338584, backward:0.03250034029470096, data cost:0.6948062453175585 
2022-07-07 00:55:31,388: ============================================================
2022-07-07 00:55:31,388: Epoch 5/36 Batch 4700/7662 eta: 2 days, 1:36:52.732698	Training Loss1 9.2560 (9.2016)	Training Total_Loss 9.2560 (9.2016)	Training Prec@1 78.125 (78.686)	Training Prec@5 0.000 (0.000)	
2022-07-07 00:55:31,388: ============================================================
2022-07-07 00:56:45,480: time cost, forward:0.012362371163707048, backward:0.03250582219660593, data cost:0.694817160685675 
2022-07-07 00:56:45,480: ============================================================
2022-07-07 00:56:45,480: Epoch 5/36 Batch 4800/7662 eta: 2 days, 1:28:26.511570	Training Loss1 9.1688 (9.1999)	Training Total_Loss 9.1688 (9.1999)	Training Prec@1 78.906 (78.693)	Training Prec@5 0.000 (0.000)	
2022-07-07 00:56:45,480: ============================================================
2022-07-07 00:57:58,395: time cost, forward:0.012358135387687737, backward:0.03252284204164167, data cost:0.6945734948716764 
2022-07-07 00:57:58,395: ============================================================
2022-07-07 00:57:58,395: Epoch 5/36 Batch 4900/7662 eta: 2 days, 0:40:04.500275	Training Loss1 9.3759 (9.2002)	Training Total_Loss 9.3759 (9.2002)	Training Prec@1 76.953 (78.689)	Training Prec@5 0.000 (0.000)	
2022-07-07 00:57:58,396: ============================================================
2022-07-07 00:59:12,196: time cost, forward:0.012366975205114875, backward:0.0325337575182578, data cost:0.6945169003492929 
2022-07-07 00:59:12,197: ============================================================
2022-07-07 00:59:12,197: Epoch 5/36 Batch 5000/7662 eta: 2 days, 1:14:19.749872	Training Loss1 9.2089 (9.1998)	Training Total_Loss 9.2089 (9.1998)	Training Prec@1 77.344 (78.686)	Training Prec@5 0.000 (0.000)	
2022-07-07 00:59:12,197: ============================================================
2022-07-07 01:00:27,539: time cost, forward:0.012368945847260856, backward:0.032542146872389335, data cost:0.6947659727497928 
2022-07-07 01:00:27,539: ============================================================
2022-07-07 01:00:27,539: Epoch 5/36 Batch 5100/7662 eta: 2 days, 2:14:46.379921	Training Loss1 9.1841 (9.1991)	Training Total_Loss 9.1841 (9.1991)	Training Prec@1 79.102 (78.687)	Training Prec@5 0.000 (0.000)	
2022-07-07 01:00:27,540: ============================================================
2022-07-07 01:01:43,122: time cost, forward:0.012366476323105184, backward:0.032548712500931554, data cost:0.6950643029114815 
2022-07-07 01:01:43,122: ============================================================
2022-07-07 01:01:43,122: Epoch 5/36 Batch 5200/7662 eta: 2 days, 2:23:07.825798	Training Loss1 9.0845 (9.1980)	Training Total_Loss 9.0845 (9.1980)	Training Prec@1 80.078 (78.690)	Training Prec@5 0.000 (0.000)	
2022-07-07 01:01:43,123: ============================================================
2022-07-07 01:02:56,734: time cost, forward:0.01235705700701735, backward:0.0325580513866516, data cost:0.6949756311501933 
2022-07-07 01:02:56,735: ============================================================
2022-07-07 01:02:56,735: Epoch 5/36 Batch 5300/7662 eta: 2 days, 1:03:05.670367	Training Loss1 8.8704 (9.1978)	Training Total_Loss 8.8704 (9.1978)	Training Prec@1 81.055 (78.681)	Training Prec@5 0.000 (0.000)	
2022-07-07 01:02:56,735: ============================================================
2022-07-07 01:04:10,389: time cost, forward:0.01235425284580514, backward:0.03257251258337138, data cost:0.6948944922618722 
2022-07-07 01:04:10,389: ============================================================
2022-07-07 01:04:10,389: Epoch 5/36 Batch 5400/7662 eta: 2 days, 1:03:31.119376	Training Loss1 9.1172 (9.1976)	Training Total_Loss 9.1172 (9.1976)	Training Prec@1 77.734 (78.679)	Training Prec@5 0.000 (0.000)	
2022-07-07 01:04:10,389: ============================================================
2022-07-07 01:05:24,155: time cost, forward:0.012351445575956216, backward:0.03257697485732824, data cost:0.6948421751071939 
2022-07-07 01:05:24,155: ============================================================
2022-07-07 01:05:24,156: Epoch 5/36 Batch 5500/7662 eta: 2 days, 1:06:47.548101	Training Loss1 9.1277 (9.1955)	Training Total_Loss 9.1277 (9.1955)	Training Prec@1 80.273 (78.688)	Training Prec@5 0.000 (0.000)	
2022-07-07 01:05:24,156: ============================================================
2022-07-07 01:06:37,135: time cost, forward:0.01235024050572745, backward:0.0325772595375771, data cost:0.694645512676767 
2022-07-07 01:06:37,135: ============================================================
2022-07-07 01:06:37,135: Epoch 5/36 Batch 5600/7662 eta: 2 days, 0:34:07.791261	Training Loss1 9.1585 (9.1944)	Training Total_Loss 9.1585 (9.1944)	Training Prec@1 79.102 (78.688)	Training Prec@5 0.000 (0.000)	
2022-07-07 01:06:37,135: ============================================================
2022-07-07 01:07:52,060: time cost, forward:0.012356362984585834, backward:0.03255578818541281, data cost:0.6948288240899619 
2022-07-07 01:07:52,061: ============================================================
2022-07-07 01:07:52,061: Epoch 5/36 Batch 5700/7662 eta: 2 days, 1:50:35.899883	Training Loss1 9.4968 (9.1933)	Training Total_Loss 9.4968 (9.1933)	Training Prec@1 76.953 (78.689)	Training Prec@5 0.000 (0.000)	
2022-07-07 01:07:52,061: ============================================================
2022-07-07 01:09:06,624: time cost, forward:0.012356641149085069, backward:0.03253945142446993, data cost:0.6949356093573599 
2022-07-07 01:09:06,624: ============================================================
2022-07-07 01:09:06,625: Epoch 5/36 Batch 5800/7662 eta: 2 days, 1:34:54.610506	Training Loss1 9.0002 (9.1917)	Training Total_Loss 9.0002 (9.1917)	Training Prec@1 78.516 (78.695)	Training Prec@5 0.000 (0.000)	
2022-07-07 01:09:06,625: ============================================================
2022-07-07 01:10:20,966: time cost, forward:0.012349796327499439, backward:0.03252891868549922, data cost:0.6950040946756102 
2022-07-07 01:10:20,966: ============================================================
2022-07-07 01:10:20,966: Epoch 5/36 Batch 5900/7662 eta: 2 days, 1:24:48.110866	Training Loss1 9.1622 (9.1910)	Training Total_Loss 9.1622 (9.1910)	Training Prec@1 78.320 (78.698)	Training Prec@5 0.000 (0.000)	
2022-07-07 01:10:20,966: ============================================================
2022-07-07 01:11:35,164: time cost, forward:0.012336946642583639, backward:0.03253430635815045, data cost:0.6950374715903298 
2022-07-07 01:11:35,164: ============================================================
2022-07-07 01:11:35,165: Epoch 5/36 Batch 6000/7662 eta: 2 days, 1:17:51.408303	Training Loss1 8.9138 (9.1903)	Training Total_Loss 8.9138 (9.1903)	Training Prec@1 80.273 (78.697)	Training Prec@5 0.000 (0.000)	
2022-07-07 01:11:35,165: ============================================================
2022-07-07 01:12:48,476: time cost, forward:0.012333802305923014, backward:0.03253788020810566, data cost:0.6949135916685351 
2022-07-07 01:12:48,477: ============================================================
2022-07-07 01:12:48,477: Epoch 5/36 Batch 6100/7662 eta: 2 days, 0:41:18.986557	Training Loss1 9.0097 (9.1892)	Training Total_Loss 9.0097 (9.1892)	Training Prec@1 79.492 (78.699)	Training Prec@5 0.000 (0.000)	
2022-07-07 01:12:48,477: ============================================================
2022-07-07 01:14:03,136: time cost, forward:0.012317096365903881, backward:0.03254349871323289, data cost:0.6950261651325426 
2022-07-07 01:14:03,136: ============================================================
2022-07-07 01:14:03,136: Epoch 5/36 Batch 6200/7662 eta: 2 days, 1:33:44.074199	Training Loss1 8.9536 (9.1882)	Training Total_Loss 8.9536 (9.1882)	Training Prec@1 79.492 (78.704)	Training Prec@5 0.000 (0.000)	
2022-07-07 01:14:03,136: ============================================================
2022-07-07 01:15:18,765: time cost, forward:0.01231585477794763, backward:0.03254958398191867, data cost:0.695274073465568 
2022-07-07 01:15:18,765: ============================================================
2022-07-07 01:15:18,765: Epoch 5/36 Batch 6300/7662 eta: 2 days, 2:11:06.824628	Training Loss1 9.2431 (9.1868)	Training Total_Loss 9.2431 (9.1868)	Training Prec@1 76.367 (78.712)	Training Prec@5 0.000 (0.000)	
2022-07-07 01:15:18,765: ============================================================
2022-07-07 01:16:32,877: time cost, forward:0.012318623216846321, backward:0.0325451926302772, data cost:0.6952811617239469 
2022-07-07 01:16:32,878: ============================================================
2022-07-07 01:16:32,878: Epoch 5/36 Batch 6400/7662 eta: 2 days, 1:09:29.613284	Training Loss1 9.2837 (9.1861)	Training Total_Loss 9.2837 (9.1861)	Training Prec@1 77.344 (78.711)	Training Prec@5 0.000 (0.000)	
2022-07-07 01:16:32,878: ============================================================
2022-07-07 01:17:48,313: time cost, forward:0.012329258539434909, backward:0.03253528752277807, data cost:0.6954886076871863 
2022-07-07 01:17:48,314: ============================================================
2022-07-07 01:17:48,314: Epoch 5/36 Batch 6500/7662 eta: 2 days, 2:00:54.494253	Training Loss1 9.2671 (9.1839)	Training Total_Loss 9.2671 (9.1839)	Training Prec@1 78.320 (78.718)	Training Prec@5 0.000 (0.000)	
2022-07-07 01:17:48,314: ============================================================
2022-07-07 01:19:03,169: time cost, forward:0.012326030193594193, backward:0.032540190091619424, data cost:0.6955996792430967 
2022-07-07 01:19:03,169: ============================================================
2022-07-07 01:19:03,169: Epoch 5/36 Batch 6600/7662 eta: 2 days, 1:36:33.305211	Training Loss1 8.9249 (9.1830)	Training Total_Loss 8.9249 (9.1830)	Training Prec@1 81.445 (78.722)	Training Prec@5 0.000 (0.000)	
2022-07-07 01:19:03,169: ============================================================
2022-07-07 01:20:17,789: time cost, forward:0.01233375579639235, backward:0.03252981018354544, data cost:0.6956730762298898 
2022-07-07 01:20:17,789: ============================================================
2022-07-07 01:20:17,789: Epoch 5/36 Batch 6700/7662 eta: 2 days, 1:25:58.333461	Training Loss1 8.7488 (9.1810)	Training Total_Loss 8.7488 (9.1810)	Training Prec@1 81.250 (78.731)	Training Prec@5 0.000 (0.000)	
2022-07-07 01:20:17,790: ============================================================
2022-07-07 01:21:32,584: time cost, forward:0.012333754424330661, backward:0.03253639131841422, data cost:0.6957727786214374 
2022-07-07 01:21:32,585: ============================================================
2022-07-07 01:21:32,585: Epoch 5/36 Batch 6800/7662 eta: 2 days, 1:31:41.364168	Training Loss1 9.0811 (9.1797)	Training Total_Loss 9.0811 (9.1797)	Training Prec@1 80.273 (78.736)	Training Prec@5 0.000 (0.000)	
2022-07-07 01:21:32,585: ============================================================
2022-07-07 01:22:47,860: time cost, forward:0.012340335089808911, backward:0.03252834557692095, data cost:0.6959371542581563 
2022-07-07 01:22:47,860: ============================================================
2022-07-07 01:22:47,860: Epoch 5/36 Batch 6900/7662 eta: 2 days, 1:49:29.252134	Training Loss1 8.8967 (9.1787)	Training Total_Loss 8.8967 (9.1787)	Training Prec@1 81.250 (78.738)	Training Prec@5 0.000 (0.000)	
2022-07-07 01:22:47,860: ============================================================
2022-07-07 01:24:03,059: time cost, forward:0.012346395033907083, backward:0.03251750848347467, data cost:0.6960948216674975 
2022-07-07 01:24:03,059: ============================================================
2022-07-07 01:24:03,059: Epoch 5/36 Batch 7000/7662 eta: 2 days, 1:45:12.867912	Training Loss1 9.1748 (9.1776)	Training Total_Loss 9.1748 (9.1776)	Training Prec@1 80.469 (78.739)	Training Prec@5 0.000 (0.000)	
2022-07-07 01:24:03,059: ============================================================
2022-07-07 01:25:18,593: time cost, forward:0.012344473263699834, backward:0.0325221812528596, data cost:0.6962830043373048 
2022-07-07 01:25:18,593: ============================================================
2022-07-07 01:25:18,593: Epoch 5/36 Batch 7100/7662 eta: 2 days, 1:57:15.436478	Training Loss1 8.9981 (9.1763)	Training Total_Loss 8.9981 (9.1763)	Training Prec@1 80.469 (78.745)	Training Prec@5 0.000 (0.000)	
2022-07-07 01:25:18,593: ============================================================
2022-07-07 01:26:35,929: time cost, forward:0.012352038463100259, backward:0.032522196702815406, data cost:0.696716832359527 
2022-07-07 01:26:35,929: ============================================================
2022-07-07 01:26:35,930: Epoch 5/36 Batch 7200/7662 eta: 2 days, 3:07:28.931186	Training Loss1 9.2351 (9.1750)	Training Total_Loss 9.2351 (9.1750)	Training Prec@1 78.516 (78.751)	Training Prec@5 0.000 (0.000)	
2022-07-07 01:26:35,930: ============================================================
2022-07-07 01:27:50,487: time cost, forward:0.012352880443150189, backward:0.03252260739516846, data cost:0.6967609635868013 
2022-07-07 01:27:50,488: ============================================================
2022-07-07 01:27:50,488: Epoch 5/36 Batch 7300/7662 eta: 2 days, 1:16:02.756208	Training Loss1 9.1983 (9.1739)	Training Total_Loss 9.1983 (9.1739)	Training Prec@1 74.609 (78.752)	Training Prec@5 0.000 (0.000)	
2022-07-07 01:27:50,488: ============================================================
2022-07-07 01:29:04,239: time cost, forward:0.012351707149670082, backward:0.03252289675106663, data cost:0.6966975933636406 
2022-07-07 01:29:04,239: ============================================================
2022-07-07 01:29:04,239: Epoch 5/36 Batch 7400/7662 eta: 2 days, 0:42:49.628146	Training Loss1 9.2968 (9.1728)	Training Total_Loss 9.2968 (9.1728)	Training Prec@1 80.078 (78.754)	Training Prec@5 0.000 (0.000)	
2022-07-07 01:29:04,239: ============================================================
2022-07-07 01:30:19,750: time cost, forward:0.012349711972755629, backward:0.03252923041919912, data cost:0.6968617617312964 
2022-07-07 01:30:19,750: ============================================================
2022-07-07 01:30:19,750: Epoch 5/36 Batch 7500/7662 eta: 2 days, 1:51:18.209651	Training Loss1 9.2817 (9.1717)	Training Total_Loss 9.2817 (9.1717)	Training Prec@1 79.883 (78.761)	Training Prec@5 0.000 (0.000)	
2022-07-07 01:30:19,750: ============================================================
2022-07-07 01:31:33,586: time cost, forward:0.01234789452500713, backward:0.03252852052461946, data cost:0.6968147112109313 
2022-07-07 01:31:33,587: ============================================================
2022-07-07 01:31:33,587: Epoch 5/36 Batch 7600/7662 eta: 2 days, 0:43:45.145653	Training Loss1 8.9474 (9.1699)	Training Total_Loss 8.9474 (9.1699)	Training Prec@1 80.078 (78.766)	Training Prec@5 0.000 (0.000)	
2022-07-07 01:31:33,587: ============================================================
2022-07-07 01:32:22,311: Epoch 5/36 Batch 7663/7662 eta: 2 days, 0:42:58.628473	Training Loss1 9.1412 (9.1687)	Training Total_Loss 9.1412 (9.1687)	Training Prec@1 80.273 (78.774)	Training Prec@5 0.000 (0.000)	
2022-07-07 01:32:22,311: ============================================================
2022-07-07 01:32:22,418: Save Checkpoint...
2022-07-07 01:32:22,418: ============================================================
2022-07-07 01:32:25,640: Save done!
2022-07-07 01:32:25,641: ============================================================
2022-07-07 01:33:46,178: time cost, forward:0.0123742517798838, backward:0.032695714873496935, data cost:0.762477371427748 
2022-07-07 01:33:46,179: ============================================================
2022-07-07 01:33:46,179: Epoch 6/36 Batch 100/7662 eta: 2 days, 5:05:47.389278	Training Loss1 8.6564 (8.6034)	Training Total_Loss 8.6564 (8.6034)	Training Prec@1 81.836 (81.698)	Training Prec@5 0.000 (0.000)	
2022-07-07 01:33:46,179: ============================================================
2022-07-07 01:35:00,971: time cost, forward:0.012100683384804271, backward:0.033562472118205164, data cost:0.7316420689300077 
2022-07-07 01:35:00,972: ============================================================
2022-07-07 01:35:00,972: Epoch 6/36 Batch 200/7662 eta: 2 days, 1:18:20.215607	Training Loss1 8.8752 (8.6130)	Training Total_Loss 8.8752 (8.6130)	Training Prec@1 79.297 (81.755)	Training Prec@5 0.000 (0.000)	
2022-07-07 01:35:00,972: ============================================================
2022-07-07 01:36:15,058: time cost, forward:0.012135674722218593, backward:0.03368991115021466, data cost:0.7190685184504276 
2022-07-07 01:36:15,058: ============================================================
2022-07-07 01:36:15,059: Epoch 6/36 Batch 300/7662 eta: 2 days, 0:49:10.988618	Training Loss1 8.6631 (8.6588)	Training Total_Loss 8.6631 (8.6588)	Training Prec@1 81.445 (81.662)	Training Prec@5 0.000 (0.000)	
2022-07-07 01:36:15,059: ============================================================
2022-07-07 01:37:28,394: time cost, forward:0.012152157331767836, backward:0.03370227192278793, data cost:0.7110022261626738 
2022-07-07 01:37:28,395: ============================================================
2022-07-07 01:37:28,395: Epoch 6/36 Batch 400/7662 eta: 2 days, 0:18:17.143382	Training Loss1 8.7122 (8.6947)	Training Total_Loss 8.7122 (8.6947)	Training Prec@1 79.883 (81.506)	Training Prec@5 0.000 (0.000)	
2022-07-07 01:37:28,395: ============================================================
2022-07-07 01:38:41,978: time cost, forward:0.011973104400481872, backward:0.03366668859799066, data cost:0.7068051106944113 
2022-07-07 01:38:41,978: ============================================================
2022-07-07 01:38:41,978: Epoch 6/36 Batch 500/7662 eta: 2 days, 0:26:49.452234	Training Loss1 8.8788 (8.7250)	Training Total_Loss 8.8788 (8.7250)	Training Prec@1 78.516 (81.357)	Training Prec@5 0.000 (0.000)	
2022-07-07 01:38:41,978: ============================================================
2022-07-07 01:39:54,397: time cost, forward:0.011841000619038118, backward:0.0336300459051371, data cost:0.7022039516143289 
2022-07-07 01:39:54,397: ============================================================
2022-07-07 01:39:54,398: Epoch 6/36 Batch 600/7662 eta: 1 day, 23:39:38.304821	Training Loss1 8.5236 (8.7469)	Training Total_Loss 8.5236 (8.7469)	Training Prec@1 83.008 (81.252)	Training Prec@5 0.000 (0.000)	
2022-07-07 01:39:54,398: ============================================================
2022-07-07 01:41:06,963: time cost, forward:0.011691030002970552, backward:0.03361355832035791, data cost:0.6991403525820447 
2022-07-07 01:41:06,963: ============================================================
2022-07-07 01:41:06,963: Epoch 6/36 Batch 700/7662 eta: 1 day, 23:44:11.947129	Training Loss1 8.7873 (8.7691)	Training Total_Loss 8.7873 (8.7691)	Training Prec@1 83.594 (81.141)	Training Prec@5 0.000 (0.000)	
2022-07-07 01:41:06,963: ============================================================
2022-07-07 01:42:19,497: time cost, forward:0.011667309774176796, backward:0.033708587605902486, data cost:0.6965764347692306 
2022-07-07 01:42:19,498: ============================================================
2022-07-07 01:42:19,498: Epoch 6/36 Batch 800/7662 eta: 1 day, 23:41:46.102087	Training Loss1 8.9374 (8.7858)	Training Total_Loss 8.9374 (8.7858)	Training Prec@1 80.273 (81.039)	Training Prec@5 0.000 (0.000)	
2022-07-07 01:42:19,498: ============================================================
2022-07-07 01:43:33,586: time cost, forward:0.011739946445978523, backward:0.03371705282251615, data cost:0.6963399716293454 
2022-07-07 01:43:33,586: ============================================================
2022-07-07 01:43:33,586: Epoch 6/36 Batch 900/7662 eta: 2 days, 0:41:50.272318	Training Loss1 9.3325 (8.7977)	Training Total_Loss 9.3325 (8.7977)	Training Prec@1 76.172 (80.975)	Training Prec@5 0.000 (0.000)	
2022-07-07 01:43:33,586: ============================================================
2022-07-07 01:44:47,361: time cost, forward:0.011727754776184266, backward:0.03365886772239769, data cost:0.6959347443299012 
2022-07-07 01:44:47,362: ============================================================
2022-07-07 01:44:47,362: Epoch 6/36 Batch 1000/7662 eta: 2 days, 0:28:16.913607	Training Loss1 8.9982 (8.8149)	Training Total_Loss 8.9982 (8.8149)	Training Prec@1 79.688 (80.863)	Training Prec@5 0.000 (0.000)	
2022-07-07 01:44:47,363: ============================================================
2022-07-07 01:46:02,279: time cost, forward:0.011674129279555788, backward:0.03369918858820574, data cost:0.6966181719053649 
2022-07-07 01:46:02,280: ============================================================
2022-07-07 01:46:02,280: Epoch 6/36 Batch 1100/7662 eta: 2 days, 1:12:02.883682	Training Loss1 8.7988 (8.8252)	Training Total_Loss 8.7988 (8.8252)	Training Prec@1 79.492 (80.808)	Training Prec@5 0.000 (0.000)	
2022-07-07 01:46:02,280: ============================================================
2022-07-07 01:47:16,767: time cost, forward:0.0116667709716466, backward:0.03370697703134825, data cost:0.6968021651324479 
2022-07-07 01:47:16,768: ============================================================
2022-07-07 01:47:16,768: Epoch 6/36 Batch 1200/7662 eta: 2 days, 0:53:52.567903	Training Loss1 8.9139 (8.8393)	Training Total_Loss 8.9139 (8.8393)	Training Prec@1 78.906 (80.711)	Training Prec@5 0.000 (0.000)	
2022-07-07 01:47:16,768: ============================================================
2022-07-07 01:48:29,540: time cost, forward:0.011622815796556244, backward:0.03365501080043872, data cost:0.6957075025046028 
2022-07-07 01:48:29,541: ============================================================
2022-07-07 01:48:29,541: Epoch 6/36 Batch 1300/7662 eta: 1 day, 23:45:06.266988	Training Loss1 9.0074 (8.8496)	Training Total_Loss 9.0074 (8.8496)	Training Prec@1 81.250 (80.658)	Training Prec@5 0.000 (0.000)	
2022-07-07 01:48:29,541: ============================================================
2022-07-07 01:49:42,550: time cost, forward:0.011616941517467921, backward:0.0336229168917129, data cost:0.6949594559372962 
2022-07-07 01:49:42,551: ============================================================
2022-07-07 01:49:42,551: Epoch 6/36 Batch 1400/7662 eta: 1 day, 23:53:13.217063	Training Loss1 9.0856 (8.8581)	Training Total_Loss 9.0856 (8.8581)	Training Prec@1 79.492 (80.602)	Training Prec@5 0.000 (0.000)	
2022-07-07 01:49:42,551: ============================================================
2022-07-07 01:50:56,636: time cost, forward:0.011647694742305825, backward:0.033683386860568175, data cost:0.6948529315678734 
2022-07-07 01:50:56,637: ============================================================
2022-07-07 01:50:56,637: Epoch 6/36 Batch 1500/7662 eta: 2 days, 0:34:19.929921	Training Loss1 9.1159 (8.8675)	Training Total_Loss 9.1159 (8.8675)	Training Prec@1 78.516 (80.530)	Training Prec@5 0.000 (0.000)	
2022-07-07 01:50:56,637: ============================================================
2022-07-07 01:52:09,822: time cost, forward:0.011633463842261948, backward:0.03369647044551007, data cost:0.694304235731534 
2022-07-07 01:52:09,822: ============================================================
2022-07-07 01:52:09,822: Epoch 6/36 Batch 1600/7662 eta: 1 day, 23:57:40.818899	Training Loss1 9.0343 (8.8754)	Training Total_Loss 9.0343 (8.8754)	Training Prec@1 79.102 (80.479)	Training Prec@5 0.000 (0.000)	
2022-07-07 01:52:09,822: ============================================================
2022-07-07 01:53:24,403: time cost, forward:0.011602543184797929, backward:0.03372110486942716, data cost:0.694646585541939 
2022-07-07 01:53:24,403: ============================================================
2022-07-07 01:53:24,403: Epoch 6/36 Batch 1700/7662 eta: 2 days, 0:51:20.068302	Training Loss1 8.7646 (8.8818)	Training Total_Loss 8.7646 (8.8818)	Training Prec@1 82.031 (80.429)	Training Prec@5 0.000 (0.000)	
2022-07-07 01:53:24,404: ============================================================
2022-07-07 01:54:37,783: time cost, forward:0.011612031113909243, backward:0.033709925370059984, data cost:0.694286622624718 
2022-07-07 01:54:37,784: ============================================================
2022-07-07 01:54:37,784: Epoch 6/36 Batch 1800/7662 eta: 2 days, 0:02:54.196904	Training Loss1 9.1760 (8.8911)	Training Total_Loss 9.1760 (8.8911)	Training Prec@1 83.203 (80.365)	Training Prec@5 0.000 (0.000)	
2022-07-07 01:54:37,784: ============================================================
2022-07-07 01:55:51,069: time cost, forward:0.011633093574286888, backward:0.03372375873467243, data cost:0.6938561455333402 
2022-07-07 01:55:51,069: ============================================================
2022-07-07 01:55:51,070: Epoch 6/36 Batch 1900/7662 eta: 1 day, 23:57:58.385871	Training Loss1 9.1361 (8.8961)	Training Total_Loss 9.1361 (8.8961)	Training Prec@1 78.125 (80.327)	Training Prec@5 0.000 (0.000)	
2022-07-07 01:55:51,070: ============================================================
2022-07-07 01:57:05,703: time cost, forward:0.01162432670116186, backward:0.03372798209312023, data cost:0.6941883067836637 
2022-07-07 01:57:05,703: ============================================================
2022-07-07 01:57:05,703: Epoch 6/36 Batch 2000/7662 eta: 2 days, 0:49:38.810804	Training Loss1 8.7668 (8.8989)	Training Total_Loss 8.7668 (8.8989)	Training Prec@1 80.859 (80.307)	Training Prec@5 0.000 (0.000)	
2022-07-07 01:57:05,703: ============================================================
2022-07-07 01:58:19,100: time cost, forward:0.011595370032322753, backward:0.03374220542307977, data cost:0.6939061806848243 
2022-07-07 01:58:19,100: ============================================================
2022-07-07 01:58:19,101: Epoch 6/36 Batch 2100/7662 eta: 1 day, 23:59:54.674534	Training Loss1 8.8119 (8.9029)	Training Total_Loss 8.8119 (8.9029)	Training Prec@1 82.227 (80.271)	Training Prec@5 0.000 (0.000)	
2022-07-07 01:58:19,101: ============================================================
2022-07-07 01:59:32,330: time cost, forward:0.01162382254225387, backward:0.03373612453309771, data cost:0.6935221761830995 
2022-07-07 01:59:32,331: ============================================================
2022-07-07 01:59:32,331: Epoch 6/36 Batch 2200/7662 eta: 1 day, 23:52:08.177495	Training Loss1 8.6638 (8.9061)	Training Total_Loss 8.6638 (8.9061)	Training Prec@1 78.906 (80.240)	Training Prec@5 0.000 (0.000)	
2022-07-07 01:59:32,331: ============================================================
2022-07-07 02:00:46,288: time cost, forward:0.011610318702840452, backward:0.033714030192384725, data cost:0.6935808538301658 
2022-07-07 02:00:46,288: ============================================================
2022-07-07 02:00:46,289: Epoch 6/36 Batch 2300/7662 eta: 2 days, 0:19:24.994099	Training Loss1 9.0118 (8.9090)	Training Total_Loss 9.0118 (8.9090)	Training Prec@1 78.320 (80.221)	Training Prec@5 0.000 (0.000)	
2022-07-07 02:00:46,289: ============================================================
2022-07-07 02:02:00,090: time cost, forward:0.01158404012380316, backward:0.03368434343501, data cost:0.6935721228847209 
2022-07-07 02:02:00,090: ============================================================
2022-07-07 02:02:00,090: Epoch 6/36 Batch 2400/7662 eta: 2 days, 0:12:05.015773	Training Loss1 8.8546 (8.9134)	Training Total_Loss 8.8546 (8.9134)	Training Prec@1 79.688 (80.182)	Training Prec@5 0.000 (0.000)	
2022-07-07 02:02:00,090: ============================================================
2022-07-07 02:03:13,199: time cost, forward:0.011581254224864996, backward:0.03369872204634417, data cost:0.6932200724337282 
2022-07-07 02:03:13,200: ============================================================
2022-07-07 02:03:13,200: Epoch 6/36 Batch 2500/7662 eta: 1 day, 23:43:44.059335	Training Loss1 8.5825 (8.9181)	Training Total_Loss 8.5825 (8.9181)	Training Prec@1 84.570 (80.142)	Training Prec@5 0.000 (0.000)	
2022-07-07 02:03:13,200: ============================================================
2022-07-07 02:04:27,748: time cost, forward:0.011583012220904477, backward:0.03366841339707237, data cost:0.6935058191401448 
2022-07-07 02:04:27,748: ============================================================
2022-07-07 02:04:27,748: Epoch 6/36 Batch 2600/7662 eta: 2 days, 0:38:51.823163	Training Loss1 8.6795 (8.9203)	Training Total_Loss 8.6795 (8.9203)	Training Prec@1 82.422 (80.125)	Training Prec@5 0.000 (0.000)	
2022-07-07 02:04:27,748: ============================================================
2022-07-07 02:05:42,611: time cost, forward:0.011605589952500673, backward:0.03365260753511455, data cost:0.6938418658321193 
2022-07-07 02:05:42,611: ============================================================
2022-07-07 02:05:42,611: Epoch 6/36 Batch 2700/7662 eta: 2 days, 0:49:55.650346	Training Loss1 9.2535 (8.9235)	Training Total_Loss 9.2535 (8.9235)	Training Prec@1 79.102 (80.096)	Training Prec@5 0.000 (0.000)	
2022-07-07 02:05:42,612: ============================================================
2022-07-07 02:06:56,684: time cost, forward:0.011606933134459905, backward:0.03364303376939562, data cost:0.6938762484213504 
2022-07-07 02:06:56,684: ============================================================
2022-07-07 02:06:56,684: Epoch 6/36 Batch 2800/7662 eta: 2 days, 0:17:46.345298	Training Loss1 9.0817 (8.9248)	Training Total_Loss 9.0817 (8.9248)	Training Prec@1 79.688 (80.077)	Training Prec@5 0.000 (0.000)	
2022-07-07 02:06:56,685: ============================================================
2022-07-07 02:08:09,796: time cost, forward:0.011614625805120873, backward:0.0336250827903787, data cost:0.693596774933872 
2022-07-07 02:08:09,797: ============================================================
2022-07-07 02:08:09,797: Epoch 6/36 Batch 2900/7662 eta: 1 day, 23:38:58.807330	Training Loss1 8.9290 (8.9266)	Training Total_Loss 8.9290 (8.9266)	Training Prec@1 79.688 (80.060)	Training Prec@5 0.000 (0.000)	
2022-07-07 02:08:09,797: ============================================================
2022-07-07 02:09:23,781: time cost, forward:0.011617138529666546, backward:0.033603364286839306, data cost:0.6936257562068113 
2022-07-07 02:09:23,781: ============================================================
2022-07-07 02:09:23,782: Epoch 6/36 Batch 3000/7662 eta: 2 days, 0:11:50.912003	Training Loss1 8.9105 (8.9271)	Training Total_Loss 8.9105 (8.9271)	Training Prec@1 81.641 (80.051)	Training Prec@5 0.000 (0.000)	
2022-07-07 02:09:23,782: ============================================================
2022-07-07 02:10:37,448: time cost, forward:0.011615401816083447, backward:0.03360561479788205, data cost:0.6935367701937591 
2022-07-07 02:10:37,448: ============================================================
2022-07-07 02:10:37,448: Epoch 6/36 Batch 3100/7662 eta: 1 day, 23:58:11.363149	Training Loss1 8.9705 (8.9289)	Training Total_Loss 8.9705 (8.9289)	Training Prec@1 80.273 (80.030)	Training Prec@5 0.000 (0.000)	
2022-07-07 02:10:37,448: ============================================================
2022-07-07 02:11:50,348: time cost, forward:0.011634415035957319, backward:0.033578504730515574, data cost:0.6932173851468706 
2022-07-07 02:11:50,349: ============================================================
2022-07-07 02:11:50,349: Epoch 6/36 Batch 3200/7662 eta: 1 day, 23:27:02.945463	Training Loss1 8.9858 (8.9295)	Training Total_Loss 8.9858 (8.9295)	Training Prec@1 80.469 (80.028)	Training Prec@5 0.000 (0.000)	
2022-07-07 02:11:50,349: ============================================================
2022-07-07 02:13:05,176: time cost, forward:0.011661094186811168, backward:0.033570681893128125, data cost:0.6934715674551518 
2022-07-07 02:13:05,176: ============================================================
2022-07-07 02:13:05,176: Epoch 6/36 Batch 3300/7662 eta: 2 days, 0:41:02.649880	Training Loss1 9.1497 (8.9306)	Training Total_Loss 9.1497 (8.9306)	Training Prec@1 78.906 (80.017)	Training Prec@5 0.000 (0.000)	
2022-07-07 02:13:05,176: ============================================================
2022-07-07 02:14:19,259: time cost, forward:0.011679786484042979, backward:0.03358908069943919, data cost:0.6934929173215062 
2022-07-07 02:14:19,259: ============================================================
2022-07-07 02:14:19,260: Epoch 6/36 Batch 3400/7662 eta: 2 days, 0:10:46.796611	Training Loss1 9.3059 (8.9314)	Training Total_Loss 9.3059 (8.9314)	Training Prec@1 78.711 (80.013)	Training Prec@5 0.000 (0.000)	
2022-07-07 02:14:19,260: ============================================================
2022-07-07 02:15:33,230: time cost, forward:0.011710247335245895, backward:0.03358453742161108, data cost:0.693475336713701 
2022-07-07 02:15:33,230: ============================================================
2022-07-07 02:15:33,231: Epoch 6/36 Batch 3500/7662 eta: 2 days, 0:05:08.911075	Training Loss1 8.9191 (8.9331)	Training Total_Loss 8.9191 (8.9331)	Training Prec@1 82.422 (79.996)	Training Prec@5 0.000 (0.000)	
2022-07-07 02:15:33,231: ============================================================
2022-07-07 02:16:47,030: time cost, forward:0.011713522346392708, backward:0.03360924590922422, data cost:0.6934135460992693 
2022-07-07 02:16:47,030: ============================================================
2022-07-07 02:16:47,030: Epoch 6/36 Batch 3600/7662 eta: 1 day, 23:57:13.957510	Training Loss1 8.9659 (8.9340)	Training Total_Loss 8.9659 (8.9340)	Training Prec@1 79.492 (79.985)	Training Prec@5 0.000 (0.000)	
2022-07-07 02:16:47,030: ============================================================
2022-07-07 02:18:00,816: time cost, forward:0.011731623443083752, backward:0.033596639666695245, data cost:0.6933129463494871 
2022-07-07 02:18:00,817: ============================================================
2022-07-07 02:18:00,817: Epoch 6/36 Batch 3700/7662 eta: 1 day, 23:55:30.705380	Training Loss1 8.9614 (8.9348)	Training Total_Loss 8.9614 (8.9348)	Training Prec@1 77.734 (79.980)	Training Prec@5 0.000 (0.000)	
2022-07-07 02:18:00,817: ============================================================
2022-07-07 02:19:13,603: time cost, forward:0.011751310421812374, backward:0.03356360604682073, data cost:0.6930460575914095 
2022-07-07 02:19:13,603: ============================================================
2022-07-07 02:19:13,604: Epoch 6/36 Batch 3800/7662 eta: 1 day, 23:15:19.270567	Training Loss1 8.7489 (8.9356)	Training Total_Loss 8.7489 (8.9356)	Training Prec@1 80.664 (79.973)	Training Prec@5 0.000 (0.000)	
2022-07-07 02:19:13,604: ============================================================
2022-07-07 02:20:28,037: time cost, forward:0.011763504267533824, backward:0.033551351264000676, data cost:0.693217025777871 
2022-07-07 02:20:28,038: ============================================================
2022-07-07 02:20:28,038: Epoch 6/36 Batch 3900/7662 eta: 2 days, 0:18:15.813334	Training Loss1 8.9564 (8.9372)	Training Total_Loss 8.9564 (8.9372)	Training Prec@1 78.711 (79.954)	Training Prec@5 0.000 (0.000)	
2022-07-07 02:20:28,038: ============================================================
2022-07-07 02:21:41,576: time cost, forward:0.011775630627551298, backward:0.033546766658877396, data cost:0.6931000275145652 
2022-07-07 02:21:41,577: ============================================================
2022-07-07 02:21:41,577: Epoch 6/36 Batch 4000/7662 eta: 1 day, 23:42:10.281400	Training Loss1 8.6489 (8.9376)	Training Total_Loss 8.6489 (8.9376)	Training Prec@1 81.055 (79.950)	Training Prec@5 0.000 (0.000)	
2022-07-07 02:21:41,577: ============================================================
2022-07-07 02:22:56,823: time cost, forward:0.011776278617469878, backward:0.03354073164084389, data cost:0.6934429349245517 
2022-07-07 02:22:56,823: ============================================================
2022-07-07 02:22:56,824: Epoch 6/36 Batch 4100/7662 eta: 2 days, 0:47:23.067367	Training Loss1 8.8205 (8.9391)	Training Total_Loss 8.8205 (8.9391)	Training Prec@1 80.273 (79.938)	Training Prec@5 0.000 (0.000)	
2022-07-07 02:22:56,824: ============================================================
2022-07-07 02:24:13,583: time cost, forward:0.01179498631376742, backward:0.03354799761662003, data cost:0.6940917844402135 
2022-07-07 02:24:13,583: ============================================================
2022-07-07 02:24:13,583: Epoch 6/36 Batch 4200/7662 eta: 2 days, 1:44:57.854734	Training Loss1 9.4584 (8.9396)	Training Total_Loss 9.4584 (8.9396)	Training Prec@1 76.953 (79.928)	Training Prec@5 0.000 (0.000)	
2022-07-07 02:24:13,583: ============================================================
2022-07-07 02:25:29,497: time cost, forward:0.011814599759247615, backward:0.033558093051240453, data cost:0.6945008515590677 
2022-07-07 02:25:29,497: ============================================================
2022-07-07 02:25:29,497: Epoch 6/36 Batch 4300/7662 eta: 2 days, 1:10:48.782077	Training Loss1 8.7917 (8.9403)	Training Total_Loss 8.7917 (8.9403)	Training Prec@1 80.469 (79.920)	Training Prec@5 0.000 (0.000)	
2022-07-07 02:25:29,497: ============================================================
2022-07-07 02:26:43,571: time cost, forward:0.011816554677624625, backward:0.03355619966455361, data cost:0.6945105477012431 
2022-07-07 02:26:43,571: ============================================================
2022-07-07 02:26:43,571: Epoch 6/36 Batch 4400/7662 eta: 1 day, 23:58:04.111564	Training Loss1 8.7054 (8.9394)	Training Total_Loss 8.7054 (8.9394)	Training Prec@1 82.031 (79.921)	Training Prec@5 0.000 (0.000)	
2022-07-07 02:26:43,572: ============================================================
2022-07-07 02:27:57,291: time cost, forward:0.011825399680730103, backward:0.03354911238226686, data cost:0.694436001072833 
2022-07-07 02:27:57,291: ============================================================
2022-07-07 02:27:57,291: Epoch 6/36 Batch 4500/7662 eta: 1 day, 23:43:04.378995	Training Loss1 8.8716 (8.9394)	Training Total_Loss 8.8716 (8.9394)	Training Prec@1 80.273 (79.917)	Training Prec@5 0.000 (0.000)	
2022-07-07 02:27:57,291: ============================================================
2022-07-07 02:29:10,551: time cost, forward:0.011832657625530565, backward:0.03354549843426709, data cost:0.6942562144018821 
2022-07-07 02:29:10,551: ============================================================
2022-07-07 02:29:10,552: Epoch 6/36 Batch 4600/7662 eta: 1 day, 23:23:59.788506	Training Loss1 9.0169 (8.9404)	Training Total_Loss 9.0169 (8.9404)	Training Prec@1 79.102 (79.910)	Training Prec@5 0.000 (0.000)	
2022-07-07 02:29:10,552: ============================================================
2022-07-07 02:30:24,869: time cost, forward:0.011832831235204917, backward:0.03354984492691407, data cost:0.6943126115476256 
2022-07-07 02:30:24,869: ============================================================
2022-07-07 02:30:24,870: Epoch 6/36 Batch 4700/7662 eta: 2 days, 0:03:49.305732	Training Loss1 8.8460 (8.9403)	Training Total_Loss 8.8460 (8.9403)	Training Prec@1 82.031 (79.908)	Training Prec@5 0.000 (0.000)	
2022-07-07 02:30:24,870: ============================================================
2022-07-07 02:31:39,812: time cost, forward:0.011847725757138633, backward:0.03353641832538087, data cost:0.6945062948033371 
2022-07-07 02:31:39,812: ============================================================
2022-07-07 02:31:39,812: Epoch 6/36 Batch 4800/7662 eta: 2 days, 0:26:49.343394	Training Loss1 9.0656 (8.9411)	Training Total_Loss 9.0656 (8.9411)	Training Prec@1 77.930 (79.900)	Training Prec@5 0.000 (0.000)	
2022-07-07 02:31:39,813: ============================================================
2022-07-07 02:32:55,093: time cost, forward:0.011854577682582327, backward:0.03352286621462839, data cost:0.6947700693598083 
2022-07-07 02:32:55,094: ============================================================
2022-07-07 02:32:55,094: Epoch 6/36 Batch 4900/7662 eta: 2 days, 0:38:42.115593	Training Loss1 9.1111 (8.9412)	Training Total_Loss 9.1111 (8.9412)	Training Prec@1 79.297 (79.895)	Training Prec@5 0.000 (0.000)	
2022-07-07 02:32:55,094: ============================================================
2022-07-07 02:34:09,334: time cost, forward:0.01186465740108471, backward:0.03352237558527025, data cost:0.6947909607651663 
2022-07-07 02:34:09,335: ============================================================
2022-07-07 02:34:09,335: Epoch 6/36 Batch 5000/7662 eta: 1 day, 23:57:07.479560	Training Loss1 9.0757 (8.9413)	Training Total_Loss 9.0757 (8.9413)	Training Prec@1 77.930 (79.888)	Training Prec@5 0.000 (0.000)	
2022-07-07 02:34:09,335: ============================================================
2022-07-07 02:35:23,333: time cost, forward:0.011861950024643887, backward:0.0335096302956407, data cost:0.6947920754461294 
2022-07-07 02:35:23,334: ============================================================
2022-07-07 02:35:23,334: Epoch 6/36 Batch 5100/7662 eta: 1 day, 23:46:30.268697	Training Loss1 9.2942 (8.9409)	Training Total_Loss 9.2942 (8.9409)	Training Prec@1 78.320 (79.890)	Training Prec@5 0.000 (0.000)	
2022-07-07 02:35:23,334: ============================================================
2022-07-07 02:36:37,115: time cost, forward:0.011871725899780179, backward:0.03351117083833272, data cost:0.6946956219409929 
2022-07-07 02:36:37,115: ============================================================
2022-07-07 02:36:37,116: Epoch 6/36 Batch 5200/7662 eta: 1 day, 23:36:52.194867	Training Loss1 8.8874 (8.9407)	Training Total_Loss 8.8874 (8.9407)	Training Prec@1 82.227 (79.890)	Training Prec@5 0.000 (0.000)	
2022-07-07 02:36:37,116: ============================================================
2022-07-07 02:37:50,651: time cost, forward:0.011900036081680151, backward:0.033517461651832475, data cost:0.6945865679786078 
2022-07-07 02:37:50,651: ============================================================
2022-07-07 02:37:50,651: Epoch 6/36 Batch 5300/7662 eta: 1 day, 23:26:06.751222	Training Loss1 9.0263 (8.9399)	Training Total_Loss 9.0263 (8.9399)	Training Prec@1 77.930 (79.893)	Training Prec@5 0.000 (0.000)	
2022-07-07 02:37:50,651: ============================================================
2022-07-07 02:39:04,549: time cost, forward:0.011915819272661147, backward:0.03350389482887128, data cost:0.6945559984225878 
2022-07-07 02:39:04,550: ============================================================
2022-07-07 02:39:04,550: Epoch 6/36 Batch 5400/7662 eta: 1 day, 23:38:55.566714	Training Loss1 8.6454 (8.9398)	Training Total_Loss 8.6454 (8.9398)	Training Prec@1 80.664 (79.887)	Training Prec@5 0.000 (0.000)	
2022-07-07 02:39:04,550: ============================================================
2022-07-07 02:40:18,662: time cost, forward:0.01192497873245575, backward:0.03348263984898, data cost:0.6945754376990857 
2022-07-07 02:40:18,662: ============================================================
2022-07-07 02:40:18,663: Epoch 6/36 Batch 5500/7662 eta: 1 day, 23:45:58.439633	Training Loss1 8.6332 (8.9392)	Training Total_Loss 8.6332 (8.9392)	Training Prec@1 81.445 (79.889)	Training Prec@5 0.000 (0.000)	
2022-07-07 02:40:18,663: ============================================================
2022-07-07 02:41:33,797: time cost, forward:0.011921001856061769, backward:0.033473861368666126, data cost:0.6947389794026215 
2022-07-07 02:41:33,797: ============================================================
2022-07-07 02:41:33,798: Epoch 6/36 Batch 5600/7662 eta: 2 days, 0:24:15.336075	Training Loss1 8.6701 (8.9390)	Training Total_Loss 8.6701 (8.9390)	Training Prec@1 83.008 (79.887)	Training Prec@5 0.000 (0.000)	
2022-07-07 02:41:33,798: ============================================================
2022-07-07 02:42:48,362: time cost, forward:0.011923440361591908, backward:0.033471733671590974, data cost:0.6948660854122726 
2022-07-07 02:42:48,362: ============================================================
2022-07-07 02:42:48,362: Epoch 6/36 Batch 5700/7662 eta: 2 days, 0:00:57.957856	Training Loss1 9.0828 (8.9389)	Training Total_Loss 9.0828 (8.9389)	Training Prec@1 76.758 (79.884)	Training Prec@5 0.000 (0.000)	
2022-07-07 02:42:48,362: ============================================================
2022-07-07 02:44:02,917: time cost, forward:0.01192718601407707, backward:0.03347231881703605, data cost:0.6949424394596689 
2022-07-07 02:44:02,917: ============================================================
2022-07-07 02:44:02,917: Epoch 6/36 Batch 5800/7662 eta: 1 day, 23:59:21.066231	Training Loss1 8.7399 (8.9382)	Training Total_Loss 8.7399 (8.9382)	Training Prec@1 80.273 (79.884)	Training Prec@5 0.000 (0.000)	
2022-07-07 02:44:02,917: ============================================================
2022-07-07 02:45:17,124: time cost, forward:0.01191551035835614, backward:0.03347570642735478, data cost:0.6949697526193591 
2022-07-07 02:45:17,125: ============================================================
2022-07-07 02:45:17,125: Epoch 6/36 Batch 5900/7662 eta: 1 day, 23:44:42.318583	Training Loss1 8.8532 (8.9377)	Training Total_Loss 8.8532 (8.9377)	Training Prec@1 80.078 (79.885)	Training Prec@5 0.000 (0.000)	
2022-07-07 02:45:17,125: ============================================================
2022-07-07 02:46:32,971: time cost, forward:0.011916443196350901, backward:0.03348372204738133, data cost:0.6952527473123497 
2022-07-07 02:46:32,971: ============================================================
2022-07-07 02:46:32,971: Epoch 6/36 Batch 6000/7662 eta: 2 days, 0:46:41.298242	Training Loss1 9.0966 (8.9365)	Training Total_Loss 9.0966 (8.9365)	Training Prec@1 78.711 (79.890)	Training Prec@5 0.000 (0.000)	
2022-07-07 02:46:32,971: ============================================================
2022-07-07 02:47:46,894: time cost, forward:0.011914431374470588, backward:0.03348874048945122, data cost:0.6952095244395614 
2022-07-07 02:47:46,895: ============================================================
2022-07-07 02:47:46,895: Epoch 6/36 Batch 6100/7662 eta: 1 day, 23:31:17.187132	Training Loss1 8.9837 (8.9357)	Training Total_Loss 8.9837 (8.9357)	Training Prec@1 79.492 (79.891)	Training Prec@5 0.000 (0.000)	
2022-07-07 02:47:46,896: ============================================================
2022-07-07 02:49:00,547: time cost, forward:0.011925507791774237, backward:0.03348617254485813, data cost:0.6951313644171646 
2022-07-07 02:49:00,547: ============================================================
2022-07-07 02:49:00,548: Epoch 6/36 Batch 6200/7662 eta: 1 day, 23:19:34.751017	Training Loss1 8.9943 (8.9356)	Training Total_Loss 8.9943 (8.9356)	Training Prec@1 80.078 (79.889)	Training Prec@5 0.000 (0.000)	
2022-07-07 02:49:00,548: ============================================================
2022-07-07 02:50:14,929: time cost, forward:0.011928348129449297, backward:0.03348961472984419, data cost:0.6951659296519946 
2022-07-07 02:50:14,929: ============================================================
2022-07-07 02:50:14,930: Epoch 6/36 Batch 6300/7662 eta: 1 day, 23:46:28.295648	Training Loss1 9.1311 (8.9358)	Training Total_Loss 9.1311 (8.9358)	Training Prec@1 77.344 (79.885)	Training Prec@5 0.000 (0.000)	
2022-07-07 02:50:14,930: ============================================================
2022-07-07 02:51:29,266: time cost, forward:0.011927497183872324, backward:0.03348988733322923, data cost:0.6952053679024955 
2022-07-07 02:51:29,266: ============================================================
2022-07-07 02:51:29,266: Epoch 6/36 Batch 6400/7662 eta: 1 day, 23:43:29.181298	Training Loss1 8.6692 (8.9346)	Training Total_Loss 8.6692 (8.9346)	Training Prec@1 80.664 (79.889)	Training Prec@5 0.000 (0.000)	
2022-07-07 02:51:29,266: ============================================================
2022-07-07 02:52:44,148: time cost, forward:0.01193874783654601, backward:0.03350025394326413, data cost:0.695296305732592 
2022-07-07 02:52:44,148: ============================================================
2022-07-07 02:52:44,148: Epoch 6/36 Batch 6500/7662 eta: 2 days, 0:03:14.501784	Training Loss1 9.0194 (8.9345)	Training Total_Loss 9.0194 (8.9345)	Training Prec@1 81.445 (79.888)	Training Prec@5 0.000 (0.000)	
2022-07-07 02:52:44,148: ============================================================
2022-07-07 02:53:59,338: time cost, forward:0.011930455437463818, backward:0.03349677864973031, data cost:0.6954661481830997 
2022-07-07 02:53:59,339: ============================================================
2022-07-07 02:53:59,339: Epoch 6/36 Batch 6600/7662 eta: 2 days, 0:13:52.300959	Training Loss1 8.9543 (8.9336)	Training Total_Loss 8.9543 (8.9336)	Training Prec@1 80.664 (79.892)	Training Prec@5 0.000 (0.000)	
2022-07-07 02:53:59,339: ============================================================
2022-07-07 02:55:14,387: time cost, forward:0.011935555769411695, backward:0.03349351665834506, data cost:0.6955991591387924 
2022-07-07 02:55:14,387: ============================================================
2022-07-07 02:55:14,387: Epoch 6/36 Batch 6700/7662 eta: 2 days, 0:07:09.384755	Training Loss1 9.1368 (8.9331)	Training Total_Loss 9.1368 (8.9331)	Training Prec@1 77.539 (79.895)	Training Prec@5 0.000 (0.000)	
2022-07-07 02:55:14,387: ============================================================
2022-07-07 02:56:29,384: time cost, forward:0.01193917735672502, backward:0.03349830708375379, data cost:0.6957189432574223 
2022-07-07 02:56:29,384: ============================================================
2022-07-07 02:56:29,385: Epoch 6/36 Batch 6800/7662 eta: 2 days, 0:03:55.866246	Training Loss1 9.2946 (8.9330)	Training Total_Loss 9.2946 (8.9330)	Training Prec@1 76.367 (79.889)	Training Prec@5 0.000 (0.000)	
2022-07-07 02:56:29,385: ============================================================
2022-07-07 02:57:43,606: time cost, forward:0.011941091515634661, backward:0.03349499101828174, data cost:0.695720823282158 
2022-07-07 02:57:43,606: ============================================================
2022-07-07 02:57:43,606: Epoch 6/36 Batch 6900/7662 eta: 1 day, 23:32:52.464490	Training Loss1 8.6839 (8.9325)	Training Total_Loss 8.6839 (8.9325)	Training Prec@1 81.055 (79.890)	Training Prec@5 0.000 (0.000)	
2022-07-07 02:57:43,606: ============================================================
2022-07-07 02:58:58,096: time cost, forward:0.011939264396409134, backward:0.03349042793804789, data cost:0.6957745604181923 
2022-07-07 02:58:58,096: ============================================================
2022-07-07 02:58:58,096: Epoch 6/36 Batch 7000/7662 eta: 1 day, 23:41:56.752551	Training Loss1 9.3002 (8.9317)	Training Total_Loss 9.3002 (8.9317)	Training Prec@1 75.000 (79.893)	Training Prec@5 0.000 (0.000)	
2022-07-07 02:58:58,097: ============================================================
2022-07-07 03:00:12,562: time cost, forward:0.01194274440619757, backward:0.033485865320919565, data cost:0.695820345376844 
2022-07-07 03:00:12,562: ============================================================
2022-07-07 03:00:12,563: Epoch 6/36 Batch 7100/7662 eta: 1 day, 23:39:47.161091	Training Loss1 8.9375 (8.9308)	Training Total_Loss 8.9375 (8.9308)	Training Prec@1 80.273 (79.896)	Training Prec@5 0.000 (0.000)	
2022-07-07 03:00:12,563: ============================================================
2022-07-07 03:01:27,241: time cost, forward:0.011943870790303788, backward:0.03348726248605365, data cost:0.6958813425202653 
2022-07-07 03:01:27,241: ============================================================
2022-07-07 03:01:27,242: Epoch 6/36 Batch 7200/7662 eta: 1 day, 23:46:42.920080	Training Loss1 8.7300 (8.9305)	Training Total_Loss 8.7300 (8.9305)	Training Prec@1 79.492 (79.896)	Training Prec@5 0.000 (0.000)	
2022-07-07 03:01:27,242: ============================================================
2022-07-07 03:02:40,438: time cost, forward:0.011958627672060856, backward:0.03349400817702806, data cost:0.6957279434431447 
2022-07-07 03:02:40,438: ============================================================
2022-07-07 03:02:40,438: Epoch 6/36 Batch 7300/7662 eta: 1 day, 22:48:35.235974	Training Loss1 8.8495 (8.9299)	Training Total_Loss 8.8495 (8.9299)	Training Prec@1 80.469 (79.896)	Training Prec@5 0.000 (0.000)	
2022-07-07 03:02:40,438: ============================================================
2022-07-07 03:03:55,020: time cost, forward:0.01196393710179077, backward:0.033492055772558905, data cost:0.6957744392032059 
2022-07-07 03:03:55,020: ============================================================
2022-07-07 03:03:55,020: Epoch 6/36 Batch 7400/7662 eta: 1 day, 23:40:30.545486	Training Loss1 8.7684 (8.9291)	Training Total_Loss 8.7684 (8.9291)	Training Prec@1 81.250 (79.897)	Training Prec@5 0.000 (0.000)	
2022-07-07 03:03:55,020: ============================================================
2022-07-07 03:05:10,509: time cost, forward:0.011968339470358335, backward:0.03348275797734945, data cost:0.6959484306744439 
2022-07-07 03:05:10,509: ============================================================
2022-07-07 03:05:10,509: Epoch 6/36 Batch 7500/7662 eta: 2 days, 0:14:02.658240	Training Loss1 8.9379 (8.9283)	Training Total_Loss 8.9379 (8.9283)	Training Prec@1 77.734 (79.898)	Training Prec@5 0.000 (0.000)	
2022-07-07 03:05:10,510: ============================================================
2022-07-07 03:06:25,949: time cost, forward:0.011976972851789003, backward:0.03348452487357715, data cost:0.6961096768819088 
2022-07-07 03:06:25,949: ============================================================
2022-07-07 03:06:25,950: Epoch 6/36 Batch 7600/7662 eta: 2 days, 0:10:54.068111	Training Loss1 8.8319 (8.9276)	Training Total_Loss 8.8319 (8.9276)	Training Prec@1 81.836 (79.899)	Training Prec@5 0.000 (0.000)	
2022-07-07 03:06:25,950: ============================================================
2022-07-07 03:07:14,289: Epoch 6/36 Batch 7663/7662 eta: 2 days, 0:10:06.540868	Training Loss1 8.6354 (8.9270)	Training Total_Loss 8.6354 (8.9270)	Training Prec@1 81.641 (79.903)	Training Prec@5 0.000 (0.000)	
2022-07-07 03:07:14,289: ============================================================
2022-07-07 03:08:30,356: time cost, forward:0.012029881429190587, backward:0.03176753930371217, data cost:0.7189186534496269 
2022-07-07 03:08:30,357: ============================================================
2022-07-07 03:08:30,357: Epoch 7/36 Batch 100/7662 eta: 2 days, 0:32:44.323256	Training Loss1 8.4338 (8.3574)	Training Total_Loss 8.4338 (8.3574)	Training Prec@1 82.227 (83.120)	Training Prec@5 0.000 (0.000)	
2022-07-07 03:08:30,357: ============================================================
2022-07-07 03:09:42,561: time cost, forward:0.011503207623659067, backward:0.03213686559667539, data cost:0.6984477797944342 
2022-07-07 03:09:42,561: ============================================================
2022-07-07 03:09:42,561: Epoch 7/36 Batch 200/7662 eta: 1 day, 22:03:45.293020	Training Loss1 8.3768 (8.4204)	Training Total_Loss 8.3768 (8.4204)	Training Prec@1 81.250 (82.831)	Training Prec@5 0.000 (0.000)	
2022-07-07 03:09:42,561: ============================================================
2022-07-07 03:10:56,234: time cost, forward:0.01148298193379788, backward:0.032472639976935246, data cost:0.6961462545554374 
2022-07-07 03:10:56,234: ============================================================
2022-07-07 03:10:56,234: Epoch 7/36 Batch 300/7662 eta: 1 day, 22:58:44.625171	Training Loss1 8.4325 (8.4384)	Training Total_Loss 8.4325 (8.4384)	Training Prec@1 82.031 (82.728)	Training Prec@5 0.000 (0.000)	
2022-07-07 03:10:56,234: ============================================================
2022-07-07 03:12:09,840: time cost, forward:0.011629346020538407, backward:0.03257518424127335, data cost:0.6947160579805685 
2022-07-07 03:12:09,841: ============================================================
2022-07-07 03:12:09,841: Epoch 7/36 Batch 400/7662 eta: 1 day, 22:54:58.418102	Training Loss1 8.3699 (8.4777)	Training Total_Loss 8.3699 (8.4777)	Training Prec@1 82.227 (82.553)	Training Prec@5 0.000 (0.000)	
2022-07-07 03:12:09,841: ============================================================
2022-07-07 03:13:22,605: time cost, forward:0.01164071354455126, backward:0.032660366776949896, data cost:0.6922601783920624 
2022-07-07 03:13:22,605: ============================================================
2022-07-07 03:13:22,606: Epoch 7/36 Batch 500/7662 eta: 1 day, 22:21:34.292922	Training Loss1 8.4110 (8.5190)	Training Total_Loss 8.4110 (8.5190)	Training Prec@1 82.031 (82.343)	Training Prec@5 0.000 (0.000)	
2022-07-07 03:13:22,606: ============================================================
2022-07-07 03:14:36,454: time cost, forward:0.011591519258655172, backward:0.03273222800686284, data cost:0.6924642541372716 
2022-07-07 03:14:36,454: ============================================================
2022-07-07 03:14:36,454: Epoch 7/36 Batch 600/7662 eta: 1 day, 23:01:46.502705	Training Loss1 9.0983 (8.5458)	Training Total_Loss 9.0983 (8.5458)	Training Prec@1 76.758 (82.203)	Training Prec@5 0.000 (0.000)	
2022-07-07 03:14:36,455: ============================================================
2022-07-07 03:15:50,427: time cost, forward:0.01158385181290568, backward:0.032851913967869316, data cost:0.6926785886543503 
2022-07-07 03:15:50,427: ============================================================
2022-07-07 03:15:50,427: Epoch 7/36 Batch 700/7662 eta: 1 day, 23:05:16.780381	Training Loss1 8.6658 (8.5771)	Training Total_Loss 8.6658 (8.5771)	Training Prec@1 81.055 (82.028)	Training Prec@5 0.000 (0.000)	
2022-07-07 03:15:50,427: ============================================================
2022-07-07 03:17:03,859: time cost, forward:0.011572973599869557, backward:0.03286655704130667, data cost:0.6922498922025755 
2022-07-07 03:17:03,859: ============================================================
2022-07-07 03:17:03,860: Epoch 7/36 Batch 800/7662 eta: 1 day, 22:43:24.906726	Training Loss1 8.5259 (8.5935)	Training Total_Loss 8.5259 (8.5935)	Training Prec@1 84.180 (81.940)	Training Prec@5 0.000 (0.000)	
2022-07-07 03:17:03,860: ============================================================
2022-07-07 03:18:18,244: time cost, forward:0.011589212332737193, backward:0.03290817787968144, data cost:0.6929200241907818 
2022-07-07 03:18:18,245: ============================================================
2022-07-07 03:18:18,245: Epoch 7/36 Batch 900/7662 eta: 1 day, 23:18:33.239756	Training Loss1 8.8360 (8.6103)	Training Total_Loss 8.8360 (8.6103)	Training Prec@1 82.812 (81.852)	Training Prec@5 0.000 (0.000)	
2022-07-07 03:18:18,245: ============================================================
2022-07-07 03:19:31,915: time cost, forward:0.011609117786686222, backward:0.03295364298739352, data cost:0.6927324222014831 
2022-07-07 03:19:31,915: ============================================================
2022-07-07 03:19:31,915: Epoch 7/36 Batch 1000/7662 eta: 1 day, 22:50:02.730441	Training Loss1 9.0232 (8.6208)	Training Total_Loss 9.0232 (8.6208)	Training Prec@1 78.711 (81.786)	Training Prec@5 0.000 (0.000)	
2022-07-07 03:19:31,915: ============================================================
2022-07-07 03:20:45,215: time cost, forward:0.011560334413023402, backward:0.03306161240082204, data cost:0.6922287498418584 
2022-07-07 03:20:45,216: ============================================================
2022-07-07 03:20:45,216: Epoch 7/36 Batch 1100/7662 eta: 1 day, 22:34:43.253861	Training Loss1 8.6514 (8.6376)	Training Total_Loss 8.6514 (8.6376)	Training Prec@1 81.445 (81.698)	Training Prec@5 0.000 (0.000)	
2022-07-07 03:20:45,216: ============================================================
2022-07-07 03:22:00,005: time cost, forward:0.01153342757650571, backward:0.0331195739033423, data cost:0.6930757227095095 
2022-07-07 03:22:00,005: ============================================================
2022-07-07 03:22:00,005: Epoch 7/36 Batch 1200/7662 eta: 1 day, 23:30:13.970461	Training Loss1 9.0019 (8.6502)	Training Total_Loss 9.0019 (8.6502)	Training Prec@1 77.539 (81.608)	Training Prec@5 0.000 (0.000)	
2022-07-07 03:22:00,005: ============================================================
2022-07-07 03:23:13,225: time cost, forward:0.011590672236758989, backward:0.033191313460939564, data cost:0.6924563452681731 
2022-07-07 03:23:13,225: ============================================================
2022-07-07 03:23:13,226: Epoch 7/36 Batch 1300/7662 eta: 1 day, 22:29:13.191472	Training Loss1 9.0076 (8.6589)	Training Total_Loss 9.0076 (8.6589)	Training Prec@1 80.469 (81.532)	Training Prec@5 0.000 (0.000)	
2022-07-07 03:23:13,226: ============================================================
2022-07-07 03:24:26,913: time cost, forward:0.011595572975382284, backward:0.03322763763384107, data cost:0.6923569065064 
2022-07-07 03:24:26,914: ============================================================
2022-07-07 03:24:26,914: Epoch 7/36 Batch 1400/7662 eta: 1 day, 22:45:49.285006	Training Loss1 9.2052 (8.6692)	Training Total_Loss 9.2052 (8.6692)	Training Prec@1 78.711 (81.452)	Training Prec@5 0.000 (0.000)	
2022-07-07 03:24:26,914: ============================================================
2022-07-07 03:25:39,425: time cost, forward:0.01157491886273792, backward:0.03328155230648761, data cost:0.6914785499967202 
2022-07-07 03:25:39,426: ============================================================
2022-07-07 03:25:39,426: Epoch 7/36 Batch 1500/7662 eta: 1 day, 21:59:48.505111	Training Loss1 8.5838 (8.6742)	Training Total_Loss 8.5838 (8.6742)	Training Prec@1 83.398 (81.423)	Training Prec@5 0.000 (0.000)	
2022-07-07 03:25:39,426: ============================================================
2022-07-07 03:26:51,494: time cost, forward:0.01159527601488983, backward:0.03331887013767569, data cost:0.6903821174020391 
2022-07-07 03:26:51,494: ============================================================
2022-07-07 03:26:51,495: Epoch 7/36 Batch 1600/7662 eta: 1 day, 21:41:44.755615	Training Loss1 8.4691 (8.6812)	Training Total_Loss 8.4691 (8.6812)	Training Prec@1 82.031 (81.379)	Training Prec@5 0.000 (0.000)	
2022-07-07 03:26:51,495: ============================================================
2022-07-07 03:28:05,792: time cost, forward:0.011614602197262033, backward:0.0333341644257921, data cost:0.6907847441246118 
2022-07-07 03:28:05,793: ============================================================
2022-07-07 03:28:05,793: Epoch 7/36 Batch 1700/7662 eta: 1 day, 23:05:19.972797	Training Loss1 8.8955 (8.6892)	Training Total_Loss 8.8955 (8.6892)	Training Prec@1 80.273 (81.323)	Training Prec@5 0.000 (0.000)	
2022-07-07 03:28:05,793: ============================================================
2022-07-07 03:29:19,159: time cost, forward:0.011612650684146764, backward:0.033382552540786, data cost:0.6905866252375418 
2022-07-07 03:29:19,160: ============================================================
2022-07-07 03:29:19,160: Epoch 7/36 Batch 1800/7662 eta: 1 day, 22:28:41.862642	Training Loss1 8.8893 (8.6970)	Training Total_Loss 8.8893 (8.6970)	Training Prec@1 80.664 (81.273)	Training Prec@5 0.000 (0.000)	
2022-07-07 03:29:19,160: ============================================================
2022-07-07 03:30:33,030: time cost, forward:0.011635057545762868, backward:0.033421812464275634, data cost:0.6906620007304533 
2022-07-07 03:30:33,030: ============================================================
2022-07-07 03:30:33,031: Epoch 7/36 Batch 1900/7662 eta: 1 day, 22:46:36.193760	Training Loss1 9.2838 (8.7015)	Training Total_Loss 9.2838 (8.7015)	Training Prec@1 76.172 (81.229)	Training Prec@5 0.000 (0.000)	
2022-07-07 03:30:33,031: ============================================================
2022-07-07 03:31:45,699: time cost, forward:0.01165419307096175, backward:0.03344147010944437, data cost:0.6901017846674726 
2022-07-07 03:31:45,700: ============================================================
2022-07-07 03:31:45,700: Epoch 7/36 Batch 2000/7662 eta: 1 day, 21:59:45.106309	Training Loss1 9.1123 (8.7043)	Training Total_Loss 9.1123 (8.7043)	Training Prec@1 78.320 (81.203)	Training Prec@5 0.000 (0.000)	
2022-07-07 03:31:45,700: ============================================================
2022-07-07 03:32:59,489: time cost, forward:0.011682254692212124, backward:0.033413183354036535, data cost:0.6902404612958744 
2022-07-07 03:32:59,489: ============================================================
2022-07-07 03:32:59,490: Epoch 7/36 Batch 2100/7662 eta: 1 day, 22:41:04.101128	Training Loss1 8.9587 (8.7086)	Training Total_Loss 8.9587 (8.7086)	Training Prec@1 78.906 (81.165)	Training Prec@5 0.000 (0.000)	
2022-07-07 03:32:59,490: ============================================================
2022-07-07 03:34:14,447: time cost, forward:0.011706568534507595, backward:0.033393561704530665, data cost:0.6908555304044591 
2022-07-07 03:34:14,447: ============================================================
2022-07-07 03:34:14,448: Epoch 7/36 Batch 2200/7662 eta: 1 day, 23:24:10.143653	Training Loss1 8.5553 (8.7127)	Training Total_Loss 8.5553 (8.7127)	Training Prec@1 82.031 (81.128)	Training Prec@5 0.000 (0.000)	
2022-07-07 03:34:14,448: ============================================================
2022-07-07 03:35:28,451: time cost, forward:0.011674870818321888, backward:0.03340788860329341, data cost:0.690955941705094 
2022-07-07 03:35:28,451: ============================================================
2022-07-07 03:35:28,452: Epoch 7/36 Batch 2300/7662 eta: 1 day, 22:46:44.285727	Training Loss1 9.0107 (8.7139)	Training Total_Loss 9.0107 (8.7139)	Training Prec@1 78.711 (81.108)	Training Prec@5 0.000 (0.000)	
2022-07-07 03:35:28,452: ============================================================
2022-07-07 03:36:42,620: time cost, forward:0.011659638192962736, backward:0.033431424156433846, data cost:0.6912261746038045 
2022-07-07 03:36:42,621: ============================================================
2022-07-07 03:36:42,621: Epoch 7/36 Batch 2400/7662 eta: 1 day, 22:51:46.232738	Training Loss1 8.9719 (8.7191)	Training Total_Loss 8.9719 (8.7191)	Training Prec@1 78.125 (81.070)	Training Prec@5 0.000 (0.000)	
2022-07-07 03:36:42,621: ============================================================
2022-07-07 03:37:57,064: time cost, forward:0.011668525919431494, backward:0.03343784413179334, data cost:0.6915102457227398 
2022-07-07 03:37:57,064: ============================================================
2022-07-07 03:37:57,064: Epoch 7/36 Batch 2500/7662 eta: 1 day, 23:00:54.974958	Training Loss1 8.9908 (8.7213)	Training Total_Loss 8.9908 (8.7213)	Training Prec@1 81.250 (81.042)	Training Prec@5 0.000 (0.000)	
2022-07-07 03:37:57,064: ============================================================
2022-07-07 03:39:11,800: time cost, forward:0.011667076648772336, backward:0.033421060038144976, data cost:0.691915888839522 
2022-07-07 03:39:11,800: ============================================================
2022-07-07 03:39:11,800: Epoch 7/36 Batch 2600/7662 eta: 1 day, 23:10:45.513975	Training Loss1 8.5551 (8.7247)	Training Total_Loss 8.5551 (8.7247)	Training Prec@1 81.445 (81.018)	Training Prec@5 0.000 (0.000)	
2022-07-07 03:39:11,800: ============================================================
2022-07-07 03:40:25,031: time cost, forward:0.01167160274806664, backward:0.03344383766228025, data cost:0.6916931980227753 
2022-07-07 03:40:25,031: ============================================================
2022-07-07 03:40:25,031: Epoch 7/36 Batch 2700/7662 eta: 1 day, 22:12:32.790636	Training Loss1 8.6689 (8.7280)	Training Total_Loss 8.6689 (8.7280)	Training Prec@1 80.859 (80.995)	Training Prec@5 0.000 (0.000)	
2022-07-07 03:40:25,032: ============================================================
2022-07-07 03:41:40,048: time cost, forward:0.011686079073650745, backward:0.03344072031523339, data cost:0.6921340408134392 
2022-07-07 03:41:40,049: ============================================================
2022-07-07 03:41:40,049: Epoch 7/36 Batch 2800/7662 eta: 1 day, 23:18:55.540720	Training Loss1 8.9176 (8.7307)	Training Total_Loss 8.9176 (8.7307)	Training Prec@1 80.078 (80.964)	Training Prec@5 0.000 (0.000)	
2022-07-07 03:41:40,049: ============================================================
2022-07-07 03:42:54,676: time cost, forward:0.011676624669170084, backward:0.03343098457207471, data cost:0.6924461936819097 
2022-07-07 03:42:54,676: ============================================================
2022-07-07 03:42:54,676: Epoch 7/36 Batch 2900/7662 eta: 1 day, 23:02:55.049305	Training Loss1 8.9624 (8.7323)	Training Total_Loss 8.9624 (8.7323)	Training Prec@1 81.641 (80.952)	Training Prec@5 0.000 (0.000)	
2022-07-07 03:42:54,676: ============================================================
2022-07-07 03:44:09,082: time cost, forward:0.011677647400156742, backward:0.03342628820851152, data cost:0.6926451970355119 
2022-07-07 03:44:09,082: ============================================================
2022-07-07 03:44:09,082: Epoch 7/36 Batch 3000/7662 eta: 1 day, 22:53:17.598301	Training Loss1 8.8806 (8.7342)	Training Total_Loss 8.8806 (8.7342)	Training Prec@1 78.516 (80.924)	Training Prec@5 0.000 (0.000)	
2022-07-07 03:44:09,082: ============================================================
2022-07-07 03:45:22,928: time cost, forward:0.0116849761887803, backward:0.0334489790229268, data cost:0.6926235477937426 
2022-07-07 03:45:22,928: ============================================================
2022-07-07 03:45:22,928: Epoch 7/36 Batch 3100/7662 eta: 1 day, 22:30:54.083124	Training Loss1 8.4842 (8.7360)	Training Total_Loss 8.4842 (8.7360)	Training Prec@1 82.617 (80.912)	Training Prec@5 0.000 (0.000)	
2022-07-07 03:45:22,928: ============================================================
2022-07-07 03:46:37,394: time cost, forward:0.011713678220466883, backward:0.03344940066002205, data cost:0.6927897429309736 
2022-07-07 03:46:37,394: ============================================================
2022-07-07 03:46:37,395: Epoch 7/36 Batch 3200/7662 eta: 1 day, 22:53:06.567164	Training Loss1 8.8051 (8.7377)	Training Total_Loss 8.8051 (8.7377)	Training Prec@1 79.102 (80.897)	Training Prec@5 0.000 (0.000)	
2022-07-07 03:46:37,395: ============================================================
2022-07-07 03:47:51,717: time cost, forward:0.011745902399974868, backward:0.03341886389432585, data cost:0.6929284155314602 
2022-07-07 03:47:51,717: ============================================================
2022-07-07 03:47:51,717: Epoch 7/36 Batch 3300/7662 eta: 1 day, 22:46:26.122221	Training Loss1 8.5997 (8.7398)	Training Total_Loss 8.5997 (8.7398)	Training Prec@1 79.492 (80.875)	Training Prec@5 0.000 (0.000)	
2022-07-07 03:47:51,717: ============================================================
2022-07-07 03:49:06,191: time cost, forward:0.01172789877812699, backward:0.03340618439932787, data cost:0.6931344393107006 
2022-07-07 03:49:06,192: ============================================================
2022-07-07 03:49:06,192: Epoch 7/36 Batch 3400/7662 eta: 1 day, 22:50:55.991030	Training Loss1 8.7051 (8.7409)	Training Total_Loss 8.7051 (8.7409)	Training Prec@1 80.273 (80.867)	Training Prec@5 0.000 (0.000)	
2022-07-07 03:49:06,192: ============================================================
2022-07-07 03:50:19,645: time cost, forward:0.011719418580479608, backward:0.033389306334162754, data cost:0.6930376036094236 
2022-07-07 03:50:19,646: ============================================================
2022-07-07 03:50:19,646: Epoch 7/36 Batch 3500/7662 eta: 1 day, 22:11:11.237535	Training Loss1 8.7899 (8.7406)	Training Total_Loss 8.7899 (8.7406)	Training Prec@1 81.836 (80.865)	Training Prec@5 0.000 (0.000)	
2022-07-07 03:50:19,646: ============================================================
2022-07-07 03:51:35,209: time cost, forward:0.011735987815634348, backward:0.033380664895395, data cost:0.6935003204589487 
2022-07-07 03:51:35,209: ============================================================
2022-07-07 03:51:35,210: Epoch 7/36 Batch 3600/7662 eta: 1 day, 23:29:31.209601	Training Loss1 8.6533 (8.7417)	Training Total_Loss 8.6533 (8.7417)	Training Prec@1 81.055 (80.860)	Training Prec@5 0.000 (0.000)	
2022-07-07 03:51:35,210: ============================================================
2022-07-07 03:52:50,489: time cost, forward:0.011725120719750851, backward:0.03338257761767311, data cost:0.6938762858159544 
2022-07-07 03:52:50,489: ============================================================
2022-07-07 03:52:50,489: Epoch 7/36 Batch 3700/7662 eta: 1 day, 23:17:33.245842	Training Loss1 8.6336 (8.7430)	Training Total_Loss 8.6336 (8.7430)	Training Prec@1 82.422 (80.849)	Training Prec@5 0.000 (0.000)	
2022-07-07 03:52:50,489: ============================================================
2022-07-07 03:54:05,301: time cost, forward:0.01172601916219536, backward:0.03338688754759264, data cost:0.6940974145539343 
2022-07-07 03:54:05,301: ============================================================
2022-07-07 03:54:05,302: Epoch 7/36 Batch 3800/7662 eta: 1 day, 22:58:41.107350	Training Loss1 8.7081 (8.7449)	Training Total_Loss 8.7081 (8.7449)	Training Prec@1 82.031 (80.842)	Training Prec@5 0.000 (0.000)	
2022-07-07 03:54:05,302: ============================================================
2022-07-07 03:55:18,547: time cost, forward:0.011738671067740007, backward:0.03339223074099748, data cost:0.6938868141321073 
2022-07-07 03:55:18,547: ============================================================
2022-07-07 03:55:18,547: Epoch 7/36 Batch 3900/7662 eta: 1 day, 21:58:27.250873	Training Loss1 8.7907 (8.7456)	Training Total_Loss 8.7907 (8.7456)	Training Prec@1 80.859 (80.831)	Training Prec@5 0.000 (0.000)	
2022-07-07 03:55:18,548: ============================================================
2022-07-07 03:56:32,572: time cost, forward:0.011745695293948304, backward:0.03339806804957465, data cost:0.6938900228559032 
2022-07-07 03:56:32,572: ============================================================
2022-07-07 03:56:32,572: Epoch 7/36 Batch 4000/7662 eta: 1 day, 22:26:33.152053	Training Loss1 8.9630 (8.7456)	Training Total_Loss 8.9630 (8.7456)	Training Prec@1 79.102 (80.824)	Training Prec@5 0.000 (0.000)	
2022-07-07 03:56:32,572: ============================================================
2022-07-07 03:57:47,713: time cost, forward:0.011767603647828131, backward:0.03342036765853089, data cost:0.6941324032990344 
2022-07-07 03:57:47,714: ============================================================
2022-07-07 03:57:47,714: Epoch 7/36 Batch 4100/7662 eta: 1 day, 23:07:20.586121	Training Loss1 8.6763 (8.7450)	Training Total_Loss 8.6763 (8.7450)	Training Prec@1 79.688 (80.829)	Training Prec@5 0.000 (0.000)	
2022-07-07 03:57:47,714: ============================================================
2022-07-07 03:59:00,700: time cost, forward:0.011785595210911859, backward:0.03341945667271388, data cost:0.6938704598316212 
2022-07-07 03:59:00,700: ============================================================
2022-07-07 03:59:00,700: Epoch 7/36 Batch 4200/7662 eta: 1 day, 21:45:02.230992	Training Loss1 9.0398 (8.7451)	Training Total_Loss 9.0398 (8.7451)	Training Prec@1 76.758 (80.827)	Training Prec@5 0.000 (0.000)	
2022-07-07 03:59:00,701: ============================================================
2022-07-07 04:00:15,473: time cost, forward:0.011790258880547796, backward:0.033431301396457114, data cost:0.6940420981090162 
2022-07-07 04:00:15,474: ============================================================
2022-07-07 04:00:15,474: Epoch 7/36 Batch 4300/7662 eta: 1 day, 22:50:59.745626	Training Loss1 8.5571 (8.7456)	Training Total_Loss 8.5571 (8.7456)	Training Prec@1 82.812 (80.821)	Training Prec@5 0.000 (0.000)	
2022-07-07 04:00:15,474: ============================================================
2022-07-07 04:01:30,663: time cost, forward:0.011795344583607176, backward:0.03343545959656497, data cost:0.6943093891386607 
2022-07-07 04:01:30,664: ============================================================
2022-07-07 04:01:30,664: Epoch 7/36 Batch 4400/7662 eta: 1 day, 23:05:23.833069	Training Loss1 9.2055 (8.7463)	Training Total_Loss 9.2055 (8.7463)	Training Prec@1 77.734 (80.813)	Training Prec@5 0.000 (0.000)	
2022-07-07 04:01:30,664: ============================================================
2022-07-07 04:02:44,819: time cost, forward:0.011790137843148765, backward:0.03345390716428941, data cost:0.6943295351741949 
2022-07-07 04:02:44,820: ============================================================
2022-07-07 04:02:44,820: Epoch 7/36 Batch 4500/7662 eta: 1 day, 22:25:18.749140	Training Loss1 8.8464 (8.7467)	Training Total_Loss 8.8464 (8.7467)	Training Prec@1 76.758 (80.808)	Training Prec@5 0.000 (0.000)	
2022-07-07 04:02:44,820: ============================================================
2022-07-07 04:03:59,088: time cost, forward:0.01178986104992997, backward:0.03345687935263677, data cost:0.6943792997170697 
2022-07-07 04:03:59,088: ============================================================
2022-07-07 04:03:59,088: Epoch 7/36 Batch 4600/7662 eta: 1 day, 22:28:18.210888	Training Loss1 9.1808 (8.7470)	Training Total_Loss 9.1808 (8.7470)	Training Prec@1 78.516 (80.805)	Training Prec@5 0.000 (0.000)	
2022-07-07 04:03:59,089: ============================================================
2022-07-07 04:05:13,471: time cost, forward:0.011793821663216192, backward:0.03347033976392306, data cost:0.6944345959604332 
2022-07-07 04:05:13,471: ============================================================
2022-07-07 04:05:13,471: Epoch 7/36 Batch 4700/7662 eta: 1 day, 22:31:20.750011	Training Loss1 8.7086 (8.7470)	Training Total_Loss 8.7086 (8.7470)	Training Prec@1 82.031 (80.801)	Training Prec@5 0.000 (0.000)	
2022-07-07 04:05:13,471: ============================================================
2022-07-07 04:06:27,441: time cost, forward:0.011795223044911929, backward:0.033487612914482635, data cost:0.6944082313886556 
2022-07-07 04:06:27,441: ============================================================
2022-07-07 04:06:27,442: Epoch 7/36 Batch 4800/7662 eta: 1 day, 22:14:38.897232	Training Loss1 8.7696 (8.7474)	Training Total_Loss 8.7696 (8.7474)	Training Prec@1 79.102 (80.796)	Training Prec@5 0.000 (0.000)	
2022-07-07 04:06:27,442: ============================================================
2022-07-07 04:07:41,607: time cost, forward:0.011799312071012803, backward:0.03350765390234545, data cost:0.694401947131666 
2022-07-07 04:07:41,607: ============================================================
2022-07-07 04:07:41,608: Epoch 7/36 Batch 4900/7662 eta: 1 day, 22:20:44.182404	Training Loss1 8.4189 (8.7480)	Training Total_Loss 8.4189 (8.7480)	Training Prec@1 82.031 (80.789)	Training Prec@5 0.000 (0.000)	
2022-07-07 04:07:41,608: ============================================================
2022-07-07 04:08:55,922: time cost, forward:0.011806299648754215, backward:0.03350587281305138, data cost:0.6944636828805428 
2022-07-07 04:08:55,922: ============================================================
2022-07-07 04:08:55,922: Epoch 7/36 Batch 5000/7662 eta: 1 day, 22:25:05.249093	Training Loss1 8.8562 (8.7476)	Training Total_Loss 8.8562 (8.7476)	Training Prec@1 78.516 (80.791)	Training Prec@5 0.000 (0.000)	
2022-07-07 04:08:55,923: ============================================================
2022-07-07 04:10:09,930: time cost, forward:0.011809802003925186, backward:0.03350669717199547, data cost:0.6944487637738477 
2022-07-07 04:10:09,931: ============================================================
2022-07-07 04:10:09,931: Epoch 7/36 Batch 5100/7662 eta: 1 day, 22:12:22.422817	Training Loss1 8.5068 (8.7478)	Training Total_Loss 8.5068 (8.7478)	Training Prec@1 82.227 (80.789)	Training Prec@5 0.000 (0.000)	
2022-07-07 04:10:09,931: ============================================================
2022-07-07 04:11:23,705: time cost, forward:0.011805260954143497, backward:0.03350218169206288, data cost:0.6944082773839265 
2022-07-07 04:11:23,705: ============================================================
2022-07-07 04:11:23,705: Epoch 7/36 Batch 5200/7662 eta: 1 day, 22:02:21.559708	Training Loss1 8.9847 (8.7484)	Training Total_Loss 8.9847 (8.7484)	Training Prec@1 77.344 (80.783)	Training Prec@5 0.000 (0.000)	
2022-07-07 04:11:23,705: ============================================================
2022-07-07 04:12:37,051: time cost, forward:0.011801030595789857, backward:0.03350320715435407, data cost:0.6942821342240056 
2022-07-07 04:12:37,051: ============================================================
2022-07-07 04:12:37,052: Epoch 7/36 Batch 5300/7662 eta: 1 day, 21:45:07.607986	Training Loss1 8.9635 (8.7488)	Training Total_Loss 8.9635 (8.7488)	Training Prec@1 79.492 (80.781)	Training Prec@5 0.000 (0.000)	
2022-07-07 04:12:37,052: ============================================================
2022-07-07 04:13:50,996: time cost, forward:0.011801079128114884, backward:0.03350723260065917, data cost:0.6942634677021432 
2022-07-07 04:13:50,996: ============================================================
2022-07-07 04:13:50,997: Epoch 7/36 Batch 5400/7662 eta: 1 day, 22:06:17.645628	Training Loss1 8.3963 (8.7487)	Training Total_Loss 8.3963 (8.7487)	Training Prec@1 82.031 (80.778)	Training Prec@5 0.000 (0.000)	
2022-07-07 04:13:50,997: ============================================================
2022-07-07 04:15:05,008: time cost, forward:0.011802484261207004, backward:0.03351921778545529, data cost:0.6942492202534027 
2022-07-07 04:15:05,008: ============================================================
2022-07-07 04:15:05,008: Epoch 7/36 Batch 5500/7662 eta: 1 day, 22:07:33.260061	Training Loss1 8.9241 (8.7484)	Training Total_Loss 8.9241 (8.7484)	Training Prec@1 79.297 (80.776)	Training Prec@5 0.000 (0.000)	
2022-07-07 04:15:05,008: ============================================================
2022-07-07 04:16:19,309: time cost, forward:0.011798431839681477, backward:0.03352995786651541, data cost:0.6942965647092268 
2022-07-07 04:16:19,310: ============================================================
2022-07-07 04:16:19,310: Epoch 7/36 Batch 5600/7662 eta: 1 day, 22:17:09.291911	Training Loss1 8.8899 (8.7482)	Training Total_Loss 8.8899 (8.7482)	Training Prec@1 81.641 (80.779)	Training Prec@5 0.000 (0.000)	
2022-07-07 04:16:19,310: ============================================================
2022-07-07 04:17:32,796: time cost, forward:0.011797950652256872, backward:0.033530656235911255, data cost:0.6942009494521781 
2022-07-07 04:17:32,796: ============================================================
2022-07-07 04:17:32,796: Epoch 7/36 Batch 5700/7662 eta: 1 day, 21:45:27.998499	Training Loss1 8.6882 (8.7481)	Training Total_Loss 8.6882 (8.7481)	Training Prec@1 78.906 (80.778)	Training Prec@5 0.000 (0.000)	
2022-07-07 04:17:32,796: ============================================================
2022-07-07 04:18:47,627: time cost, forward:0.01179676328081163, backward:0.03353870768118653, data cost:0.6943322913279553 
2022-07-07 04:18:47,627: ============================================================
2022-07-07 04:18:47,627: Epoch 7/36 Batch 5800/7662 eta: 1 day, 22:34:27.534239	Training Loss1 8.5862 (8.7470)	Training Total_Loss 8.5862 (8.7470)	Training Prec@1 78.906 (80.780)	Training Prec@5 0.000 (0.000)	
2022-07-07 04:18:47,627: ============================================================
2022-07-07 04:20:01,768: time cost, forward:0.011803970354697445, backward:0.0335398588893494, data cost:0.694344459984096 
2022-07-07 04:20:01,769: ============================================================
2022-07-07 04:20:01,769: Epoch 7/36 Batch 5900/7662 eta: 1 day, 22:07:27.881413	Training Loss1 8.5852 (8.7462)	Training Total_Loss 8.5852 (8.7462)	Training Prec@1 82.617 (80.787)	Training Prec@5 0.000 (0.000)	
2022-07-07 04:20:01,769: ============================================================
2022-07-07 04:21:15,528: time cost, forward:0.01181031414063141, backward:0.03354615361556587, data cost:0.6942845073257372 
2022-07-07 04:21:15,528: ============================================================
2022-07-07 04:21:15,528: Epoch 7/36 Batch 6000/7662 eta: 1 day, 21:51:58.310828	Training Loss1 8.8782 (8.7450)	Training Total_Loss 8.8782 (8.7450)	Training Prec@1 79.102 (80.791)	Training Prec@5 0.000 (0.000)	
2022-07-07 04:21:15,528: ============================================================
2022-07-07 04:22:29,386: time cost, forward:0.011821015699317483, backward:0.03354811398665188, data cost:0.6942442820333695 
2022-07-07 04:22:29,387: ============================================================
2022-07-07 04:22:29,387: Epoch 7/36 Batch 6100/7662 eta: 1 day, 21:54:26.790806	Training Loss1 8.7928 (8.7446)	Training Total_Loss 8.7928 (8.7446)	Training Prec@1 79.102 (80.792)	Training Prec@5 0.000 (0.000)	
2022-07-07 04:22:29,387: ============================================================
2022-07-07 04:23:42,933: time cost, forward:0.011835965404088968, backward:0.033528693665764296, data cost:0.6941720003234819 
2022-07-07 04:23:42,934: ============================================================
2022-07-07 04:23:42,934: Epoch 7/36 Batch 6200/7662 eta: 1 day, 21:41:36.200278	Training Loss1 8.7085 (8.7439)	Training Total_Loss 8.7085 (8.7439)	Training Prec@1 79.297 (80.794)	Training Prec@5 0.000 (0.000)	
2022-07-07 04:23:42,934: ============================================================
2022-07-07 04:24:57,414: time cost, forward:0.011835496602389221, backward:0.03351355151612336, data cost:0.694261509987225 
2022-07-07 04:24:57,415: ============================================================
2022-07-07 04:24:57,415: Epoch 7/36 Batch 6300/7662 eta: 1 day, 22:15:10.352627	Training Loss1 8.5912 (8.7429)	Training Total_Loss 8.5912 (8.7429)	Training Prec@1 80.273 (80.797)	Training Prec@5 0.000 (0.000)	
2022-07-07 04:24:57,415: ============================================================
2022-07-07 04:26:11,728: time cost, forward:0.011849908944982572, backward:0.03350180397743097, data cost:0.6943031063413673 
2022-07-07 04:26:11,729: ============================================================
2022-07-07 04:26:11,729: Epoch 7/36 Batch 6400/7662 eta: 1 day, 22:07:42.674104	Training Loss1 8.5940 (8.7420)	Training Total_Loss 8.5940 (8.7420)	Training Prec@1 82.617 (80.801)	Training Prec@5 0.000 (0.000)	
2022-07-07 04:26:11,729: ============================================================
2022-07-07 04:27:26,748: time cost, forward:0.011857770299669375, backward:0.03349261570754538, data cost:0.6944604811805599 
2022-07-07 04:27:26,748: ============================================================
2022-07-07 04:27:26,748: Epoch 7/36 Batch 6500/7662 eta: 1 day, 22:32:44.664894	Training Loss1 8.6543 (8.7414)	Training Total_Loss 8.6543 (8.7414)	Training Prec@1 79.883 (80.804)	Training Prec@5 0.000 (0.000)	
2022-07-07 04:27:26,749: ============================================================
2022-07-07 04:28:41,635: time cost, forward:0.011869868648324993, backward:0.033474294755256144, data cost:0.69458932247211 
2022-07-07 04:28:41,636: ============================================================
2022-07-07 04:28:41,636: Epoch 7/36 Batch 6600/7662 eta: 1 day, 22:26:34.065687	Training Loss1 8.8756 (8.7405)	Training Total_Loss 8.8756 (8.7405)	Training Prec@1 81.445 (80.805)	Training Prec@5 0.000 (0.000)	
2022-07-07 04:28:41,636: ============================================================
2022-07-07 04:29:56,713: time cost, forward:0.011880636001668913, backward:0.0334749076237944, data cost:0.6947321014486866 
2022-07-07 04:29:56,714: ============================================================
2022-07-07 04:29:56,714: Epoch 7/36 Batch 6700/7662 eta: 1 day, 22:32:25.275963	Training Loss1 8.6081 (8.7406)	Training Total_Loss 8.6081 (8.7406)	Training Prec@1 82.227 (80.806)	Training Prec@5 0.000 (0.000)	
2022-07-07 04:29:56,714: ============================================================
2022-07-07 04:31:11,396: time cost, forward:0.011882209518338358, backward:0.033470645794571804, data cost:0.6948286318607165 
2022-07-07 04:31:11,396: ============================================================
2022-07-07 04:31:11,397: Epoch 7/36 Batch 6800/7662 eta: 1 day, 22:16:27.819847	Training Loss1 8.6026 (8.7401)	Training Total_Loss 8.6026 (8.7401)	Training Prec@1 81.445 (80.808)	Training Prec@5 0.000 (0.000)	
2022-07-07 04:31:11,397: ============================================================
2022-07-07 04:32:24,725: time cost, forward:0.01189072969461251, backward:0.03345728539128047, data cost:0.6947214275464612 
2022-07-07 04:32:24,726: ============================================================
2022-07-07 04:32:24,726: Epoch 7/36 Batch 6900/7662 eta: 1 day, 21:24:55.868521	Training Loss1 8.8749 (8.7396)	Training Total_Loss 8.8749 (8.7396)	Training Prec@1 79.297 (80.806)	Training Prec@5 0.000 (0.000)	
2022-07-07 04:32:24,726: ============================================================
2022-07-07 04:33:39,263: time cost, forward:0.011908260919925468, backward:0.03344392364306831, data cost:0.6947869029210659 
2022-07-07 04:33:39,263: ============================================================
2022-07-07 04:33:39,263: Epoch 7/36 Batch 7000/7662 eta: 1 day, 22:08:34.500135	Training Loss1 8.7249 (8.7393)	Training Total_Loss 8.7249 (8.7393)	Training Prec@1 77.930 (80.807)	Training Prec@5 0.000 (0.000)	
2022-07-07 04:33:39,263: ============================================================
2022-07-07 04:34:55,566: time cost, forward:0.011924492807384276, backward:0.03343264357038477, data cost:0.6950965421370073 
2022-07-07 04:34:55,567: ============================================================
2022-07-07 04:34:55,567: Epoch 7/36 Batch 7100/7662 eta: 1 day, 23:12:55.175073	Training Loss1 8.8265 (8.7392)	Training Total_Loss 8.8265 (8.7392)	Training Prec@1 81.055 (80.804)	Training Prec@5 0.000 (0.000)	
2022-07-07 04:34:55,567: ============================================================
2022-07-07 04:36:10,533: time cost, forward:0.011928771631405377, backward:0.03342891213032484, data cost:0.695215565775116 
2022-07-07 04:36:10,533: ============================================================
2022-07-07 04:36:10,533: Epoch 7/36 Batch 7200/7662 eta: 1 day, 22:22:01.057267	Training Loss1 8.9510 (8.7387)	Training Total_Loss 8.9510 (8.7387)	Training Prec@1 78.320 (80.805)	Training Prec@5 0.000 (0.000)	
2022-07-07 04:36:10,534: ============================================================
2022-07-07 04:37:24,420: time cost, forward:0.01192892037086053, backward:0.033422413419772375, data cost:0.6951910026891049 
2022-07-07 04:37:24,420: ============================================================
2022-07-07 04:37:24,420: Epoch 7/36 Batch 7300/7662 eta: 1 day, 21:40:42.854562	Training Loss1 8.8644 (8.7380)	Training Total_Loss 8.8644 (8.7380)	Training Prec@1 81.250 (80.807)	Training Prec@5 0.000 (0.000)	
2022-07-07 04:37:24,420: ============================================================
2022-07-07 04:38:38,418: time cost, forward:0.011926230554210767, backward:0.0334242413633336, data cost:0.6951752787168678 
2022-07-07 04:38:38,419: ============================================================
2022-07-07 04:38:38,419: Epoch 7/36 Batch 7400/7662 eta: 1 day, 21:43:38.048897	Training Loss1 8.5802 (8.7373)	Training Total_Loss 8.5802 (8.7373)	Training Prec@1 83.008 (80.809)	Training Prec@5 0.000 (0.000)	
2022-07-07 04:38:38,419: ============================================================
2022-07-07 04:39:53,535: time cost, forward:0.01193795949399495, backward:0.03342731855188724, data cost:0.695295745046127 
2022-07-07 04:39:53,535: ============================================================
2022-07-07 04:39:53,536: Epoch 7/36 Batch 7500/7662 eta: 1 day, 22:23:50.593979	Training Loss1 8.6876 (8.7372)	Training Total_Loss 8.6876 (8.7372)	Training Prec@1 81.250 (80.804)	Training Prec@5 0.000 (0.000)	
2022-07-07 04:39:53,536: ============================================================
2022-07-07 04:41:09,737: time cost, forward:0.01193893170698738, backward:0.03342578683750992, data cost:0.6955694534509084 
2022-07-07 04:41:09,738: ============================================================
2022-07-07 04:41:09,738: Epoch 7/36 Batch 7600/7662 eta: 1 day, 23:02:48.202418	Training Loss1 8.8270 (8.7372)	Training Total_Loss 8.8270 (8.7372)	Training Prec@1 81.641 (80.805)	Training Prec@5 0.000 (0.000)	
2022-07-07 04:41:09,738: ============================================================
2022-07-07 04:41:57,475: Epoch 7/36 Batch 7663/7662 eta: 1 day, 23:02:00.194910	Training Loss1 8.9233 (8.7370)	Training Total_Loss 8.9233 (8.7370)	Training Prec@1 79.297 (80.805)	Training Prec@5 0.000 (0.000)	
2022-07-07 04:41:57,475: ============================================================
2022-07-07 04:43:14,324: time cost, forward:0.011684318985601868, backward:0.03203211890326606, data cost:0.7251807776364413 
2022-07-07 04:43:14,324: ============================================================
2022-07-07 04:43:14,325: Epoch 8/36 Batch 100/7662 eta: 1 day, 23:18:30.518951	Training Loss1 8.1989 (8.1965)	Training Total_Loss 8.1989 (8.1965)	Training Prec@1 82.617 (83.722)	Training Prec@5 0.000 (0.000)	
2022-07-07 04:43:14,325: ============================================================
2022-07-07 04:44:26,148: time cost, forward:0.011747796331817781, backward:0.03204074576871479, data cost:0.6993772779876862 
2022-07-07 04:44:26,149: ============================================================
2022-07-07 04:44:26,149: Epoch 8/36 Batch 200/7662 eta: 1 day, 20:17:29.418942	Training Loss1 8.3689 (8.2450)	Training Total_Loss 8.3689 (8.2450)	Training Prec@1 84.570 (83.485)	Training Prec@5 0.000 (0.000)	
2022-07-07 04:44:26,149: ============================================================
2022-07-07 04:45:39,747: time cost, forward:0.011904078582457475, backward:0.03205505023433213, data cost:0.6966621979423191 
2022-07-07 04:45:39,748: ============================================================
2022-07-07 04:45:39,748: Epoch 8/36 Batch 300/7662 eta: 1 day, 21:21:55.046057	Training Loss1 8.6793 (8.2879)	Training Total_Loss 8.6793 (8.2879)	Training Prec@1 81.641 (83.379)	Training Prec@5 0.000 (0.000)	
2022-07-07 04:45:39,748: ============================================================
2022-07-07 04:46:52,790: time cost, forward:0.01181643409537791, backward:0.03219223739509296, data cost:0.6938777232827399 
2022-07-07 04:46:52,790: ============================================================
2022-07-07 04:46:52,790: Epoch 8/36 Batch 400/7662 eta: 1 day, 21:00:07.418279	Training Loss1 8.4623 (8.3174)	Training Total_Loss 8.4623 (8.3174)	Training Prec@1 81.836 (83.275)	Training Prec@5 0.000 (0.000)	
2022-07-07 04:46:52,790: ============================================================
2022-07-07 04:48:06,914: time cost, forward:0.011909305213209622, backward:0.0320345399852745, data cost:0.6944962598995599 
2022-07-07 04:48:06,915: ============================================================
2022-07-07 04:48:06,915: Epoch 8/36 Batch 500/7662 eta: 1 day, 21:38:53.086107	Training Loss1 8.4134 (8.3393)	Training Total_Loss 8.4134 (8.3393)	Training Prec@1 83.203 (83.196)	Training Prec@5 0.000 (0.000)	
2022-07-07 04:48:06,915: ============================================================
2022-07-07 04:49:19,629: time cost, forward:0.011823977771306874, backward:0.032152161574323906, data cost:0.6924238256699653 
2022-07-07 04:49:19,630: ============================================================
2022-07-07 04:49:19,630: Epoch 8/36 Batch 600/7662 eta: 1 day, 20:45:35.833120	Training Loss1 8.4631 (8.3673)	Training Total_Loss 8.4631 (8.3673)	Training Prec@1 82.031 (83.057)	Training Prec@5 0.000 (0.000)	
2022-07-07 04:49:19,630: ============================================================
2022-07-07 04:50:32,270: time cost, forward:0.011890327128900138, backward:0.03232503107859512, data cost:0.6907346316843755 
2022-07-07 04:50:32,271: ============================================================
2022-07-07 04:50:32,271: Epoch 8/36 Batch 700/7662 eta: 1 day, 20:41:39.224382	Training Loss1 8.4092 (8.3876)	Training Total_Loss 8.4092 (8.3876)	Training Prec@1 84.375 (82.957)	Training Prec@5 0.000 (0.000)	
2022-07-07 04:50:32,271: ============================================================
2022-07-07 04:51:45,635: time cost, forward:0.01203632414415572, backward:0.032370945389787006, data cost:0.6902918594799591 
2022-07-07 04:51:45,636: ============================================================
2022-07-07 04:51:45,636: Epoch 8/36 Batch 800/7662 eta: 1 day, 21:07:09.643466	Training Loss1 8.8105 (8.4103)	Training Total_Loss 8.8105 (8.4103)	Training Prec@1 82.422 (82.811)	Training Prec@5 0.000 (0.000)	
2022-07-07 04:51:45,636: ============================================================
2022-07-07 04:52:58,543: time cost, forward:0.012122875060865426, backward:0.032264129471062816, data cost:0.6895982863773096 
2022-07-07 04:52:58,543: ============================================================
2022-07-07 04:52:58,544: Epoch 8/36 Batch 900/7662 eta: 1 day, 20:49:03.713056	Training Loss1 8.5413 (8.4278)	Training Total_Loss 8.5413 (8.4278)	Training Prec@1 81.836 (82.709)	Training Prec@5 0.000 (0.000)	
2022-07-07 04:52:58,544: ============================================================
2022-07-07 04:54:12,415: time cost, forward:0.012174686273416361, backward:0.032276179100777416, data cost:0.6898982398383491 
2022-07-07 04:54:12,416: ============================================================
2022-07-07 04:54:12,416: Epoch 8/36 Batch 1000/7662 eta: 1 day, 21:23:25.241169	Training Loss1 8.3383 (8.4442)	Training Total_Loss 8.3383 (8.4442)	Training Prec@1 83.398 (82.621)	Training Prec@5 0.000 (0.000)	
2022-07-07 04:54:12,416: ============================================================
2022-07-07 04:55:25,759: time cost, forward:0.012275161691098132, backward:0.03221183760367924, data cost:0.6897730471547676 
2022-07-07 04:55:25,759: ============================================================
2022-07-07 04:55:25,760: Epoch 8/36 Batch 1100/7662 eta: 1 day, 21:02:42.103825	Training Loss1 8.5452 (8.4574)	Training Total_Loss 8.5452 (8.4574)	Training Prec@1 82.812 (82.528)	Training Prec@5 0.000 (0.000)	
2022-07-07 04:55:25,760: ============================================================
2022-07-07 04:56:38,685: time cost, forward:0.012325540396250518, backward:0.03227190756618827, data cost:0.6891904123829642 
2022-07-07 04:56:38,685: ============================================================
2022-07-07 04:56:38,685: Epoch 8/36 Batch 1200/7662 eta: 1 day, 20:46:04.475919	Training Loss1 8.6004 (8.4694)	Training Total_Loss 8.6004 (8.4694)	Training Prec@1 83.789 (82.431)	Training Prec@5 0.000 (0.000)	
2022-07-07 04:56:38,685: ============================================================
2022-07-07 04:57:51,632: time cost, forward:0.01232852065810981, backward:0.03221892870050655, data cost:0.6888723107279953 
2022-07-07 04:57:51,632: ============================================================
2022-07-07 04:57:51,632: Epoch 8/36 Batch 1300/7662 eta: 1 day, 20:45:39.813999	Training Loss1 8.3365 (8.4816)	Training Total_Loss 8.3365 (8.4816)	Training Prec@1 82.031 (82.369)	Training Prec@5 0.000 (0.000)	
2022-07-07 04:57:51,633: ============================================================
2022-07-07 04:59:04,846: time cost, forward:0.01233788248979679, backward:0.03221666139734908, data cost:0.6887216775906435 
2022-07-07 04:59:04,846: ============================================================
2022-07-07 04:59:04,846: Epoch 8/36 Batch 1400/7662 eta: 1 day, 20:54:15.231821	Training Loss1 8.4266 (8.4912)	Training Total_Loss 8.4266 (8.4912)	Training Prec@1 83.398 (82.305)	Training Prec@5 0.000 (0.000)	
2022-07-07 04:59:04,846: ============================================================
2022-07-07 05:00:18,124: time cost, forward:0.012304824379939409, backward:0.03223617686041997, data cost:0.6886664601148487 
2022-07-07 05:00:18,124: ============================================================
2022-07-07 05:00:18,125: Epoch 8/36 Batch 1500/7662 eta: 1 day, 20:55:24.563820	Training Loss1 8.9410 (8.5005)	Training Total_Loss 8.9410 (8.5005)	Training Prec@1 80.664 (82.238)	Training Prec@5 0.000 (0.000)	
2022-07-07 05:00:18,125: ============================================================
2022-07-07 05:01:32,401: time cost, forward:0.012300695755691957, backward:0.03226464774326804, data cost:0.6892081286625388 
2022-07-07 05:01:32,402: ============================================================
2022-07-07 05:01:32,402: Epoch 8/36 Batch 1600/7662 eta: 1 day, 21:30:55.165373	Training Loss1 8.7061 (8.5091)	Training Total_Loss 8.7061 (8.5091)	Training Prec@1 79.883 (82.182)	Training Prec@5 0.000 (0.000)	
2022-07-07 05:01:32,402: ============================================================
2022-07-07 05:02:46,419: time cost, forward:0.012321385865775608, backward:0.03230941821856664, data cost:0.6894854452414959 
2022-07-07 05:02:46,419: ============================================================
2022-07-07 05:02:46,419: Epoch 8/36 Batch 1700/7662 eta: 1 day, 21:20:07.858722	Training Loss1 8.7540 (8.5148)	Training Total_Loss 8.7540 (8.5148)	Training Prec@1 80.273 (82.140)	Training Prec@5 0.000 (0.000)	
2022-07-07 05:02:46,420: ============================================================
2022-07-07 05:04:00,014: time cost, forward:0.012307831948170601, backward:0.03236527904130937, data cost:0.6895015498145942 
2022-07-07 05:04:00,014: ============================================================
2022-07-07 05:04:00,014: Epoch 8/36 Batch 1800/7662 eta: 1 day, 21:03:22.102351	Training Loss1 8.9115 (8.5220)	Training Total_Loss 8.9115 (8.5220)	Training Prec@1 78.711 (82.092)	Training Prec@5 0.000 (0.000)	
2022-07-07 05:04:00,014: ============================================================
2022-07-07 05:05:14,958: time cost, forward:0.012296365147329995, backward:0.032377745993455, data cost:0.6902729891173899 
2022-07-07 05:05:14,958: ============================================================
2022-07-07 05:05:14,959: Epoch 8/36 Batch 1900/7662 eta: 1 day, 21:51:41.655717	Training Loss1 8.6048 (8.5268)	Training Total_Loss 8.6048 (8.5268)	Training Prec@1 82.227 (82.061)	Training Prec@5 0.000 (0.000)	
2022-07-07 05:05:14,959: ============================================================
2022-07-07 05:06:28,113: time cost, forward:0.012276240382688292, backward:0.03239862533615135, data cost:0.6900685111423204 
2022-07-07 05:06:28,114: ============================================================
2022-07-07 05:06:28,114: Epoch 8/36 Batch 2000/7662 eta: 1 day, 20:44:46.902309	Training Loss1 8.2085 (8.5312)	Training Total_Loss 8.2085 (8.5312)	Training Prec@1 85.352 (82.034)	Training Prec@5 0.000 (0.000)	
2022-07-07 05:06:28,114: ============================================================
2022-07-07 05:07:43,162: time cost, forward:0.012248699184597646, backward:0.032400720740795814, data cost:0.6907686383000665 
2022-07-07 05:07:43,162: ============================================================
2022-07-07 05:07:43,162: Epoch 8/36 Batch 2100/7662 eta: 1 day, 21:53:01.455213	Training Loss1 8.4906 (8.5377)	Training Total_Loss 8.4906 (8.5377)	Training Prec@1 81.445 (81.987)	Training Prec@5 0.000 (0.000)	
2022-07-07 05:07:43,163: ============================================================
2022-07-07 05:08:56,709: time cost, forward:0.012220852371777877, backward:0.032413014394145165, data cost:0.6908112748637423 
2022-07-07 05:08:56,709: ============================================================
2022-07-07 05:08:56,709: Epoch 8/36 Batch 2200/7662 eta: 1 day, 20:56:42.013976	Training Loss1 8.4622 (8.5422)	Training Total_Loss 8.4622 (8.5422)	Training Prec@1 83.203 (81.951)	Training Prec@5 0.000 (0.000)	
2022-07-07 05:08:56,709: ============================================================
2022-07-07 05:10:10,807: time cost, forward:0.012208283906814688, backward:0.032453227115745595, data cost:0.6909898839446968 
2022-07-07 05:10:10,808: ============================================================
2022-07-07 05:10:10,808: Epoch 8/36 Batch 2300/7662 eta: 1 day, 21:15:42.474476	Training Loss1 8.8473 (8.5446)	Training Total_Loss 8.8473 (8.5446)	Training Prec@1 79.297 (81.925)	Training Prec@5 0.000 (0.000)	
2022-07-07 05:10:10,808: ============================================================
2022-07-07 05:11:24,267: time cost, forward:0.012188952184806718, backward:0.03247379849184648, data cost:0.6909234800056498 
2022-07-07 05:11:24,268: ============================================================
2022-07-07 05:11:24,268: Epoch 8/36 Batch 2400/7662 eta: 1 day, 20:51:04.577634	Training Loss1 8.6495 (8.5465)	Training Total_Loss 8.6495 (8.5465)	Training Prec@1 80.078 (81.908)	Training Prec@5 0.000 (0.000)	
2022-07-07 05:11:24,268: ============================================================
2022-07-07 05:12:36,598: time cost, forward:0.012198359740166819, backward:0.032433206627682815, data cost:0.690427592011536 
2022-07-07 05:12:36,599: ============================================================
2022-07-07 05:12:36,599: Epoch 8/36 Batch 2500/7662 eta: 1 day, 20:08:30.461363	Training Loss1 8.4207 (8.5478)	Training Total_Loss 8.4207 (8.5478)	Training Prec@1 83.203 (81.899)	Training Prec@5 0.000 (0.000)	
2022-07-07 05:12:36,599: ============================================================
2022-07-07 05:13:51,403: time cost, forward:0.012186080412297764, backward:0.032423466340813924, data cost:0.6909344991659742 
2022-07-07 05:13:51,404: ============================================================
2022-07-07 05:13:51,404: Epoch 8/36 Batch 2600/7662 eta: 1 day, 21:37:50.973457	Training Loss1 8.9221 (8.5514)	Training Total_Loss 8.9221 (8.5514)	Training Prec@1 79.492 (81.872)	Training Prec@5 0.000 (0.000)	
2022-07-07 05:13:51,404: ============================================================
2022-07-07 05:15:05,517: time cost, forward:0.012159088621673074, backward:0.03243537327235343, data cost:0.6911300729495059 
2022-07-07 05:15:05,518: ============================================================
2022-07-07 05:15:05,518: Epoch 8/36 Batch 2700/7662 eta: 1 day, 21:11:19.214294	Training Loss1 8.6626 (8.5542)	Training Total_Loss 8.6626 (8.5542)	Training Prec@1 80.859 (81.848)	Training Prec@5 0.000 (0.000)	
2022-07-07 05:15:05,518: ============================================================
2022-07-07 05:16:20,067: time cost, forward:0.012148571082548227, backward:0.03245759189192761, data cost:0.6914489920031134 
2022-07-07 05:16:20,067: ============================================================
2022-07-07 05:16:20,068: Epoch 8/36 Batch 2800/7662 eta: 1 day, 21:26:01.328259	Training Loss1 8.8099 (8.5558)	Training Total_Loss 8.8099 (8.5558)	Training Prec@1 78.320 (81.829)	Training Prec@5 0.000 (0.000)	
2022-07-07 05:16:20,068: ============================================================
2022-07-07 05:17:33,471: time cost, forward:0.012137085703086262, backward:0.03250408172607422, data cost:0.6913270472493325 
2022-07-07 05:17:33,471: ============================================================
2022-07-07 05:17:33,471: Epoch 8/36 Batch 2900/7662 eta: 1 day, 20:42:53.577697	Training Loss1 9.1155 (8.5599)	Training Total_Loss 9.1155 (8.5599)	Training Prec@1 76.562 (81.803)	Training Prec@5 0.000 (0.000)	
2022-07-07 05:17:33,471: ============================================================
2022-07-07 05:18:46,601: time cost, forward:0.012108000726372291, backward:0.032523372086655025, data cost:0.6911542266160101 
2022-07-07 05:18:46,601: ============================================================
2022-07-07 05:18:46,602: Epoch 8/36 Batch 3000/7662 eta: 1 day, 20:31:40.727522	Training Loss1 8.5118 (8.5627)	Training Total_Loss 8.5118 (8.5627)	Training Prec@1 83.984 (81.784)	Training Prec@5 0.000 (0.000)	
2022-07-07 05:18:46,602: ============================================================
2022-07-07 05:19:59,104: time cost, forward:0.012091987015317046, backward:0.03253126544466169, data cost:0.6907941907326919 
2022-07-07 05:19:59,104: ============================================================
2022-07-07 05:19:59,104: Epoch 8/36 Batch 3100/7662 eta: 1 day, 20:07:33.206975	Training Loss1 8.6108 (8.5654)	Training Total_Loss 8.6108 (8.5654)	Training Prec@1 80.469 (81.770)	Training Prec@5 0.000 (0.000)	
2022-07-07 05:19:59,105: ============================================================
2022-07-07 05:21:13,160: time cost, forward:0.012052830251614426, backward:0.03253816477616678, data cost:0.690968807133409 
2022-07-07 05:21:13,161: ============================================================
2022-07-07 05:21:13,161: Epoch 8/36 Batch 3200/7662 eta: 1 day, 21:03:02.940563	Training Loss1 8.7797 (8.5665)	Training Total_Loss 8.7797 (8.5665)	Training Prec@1 80.469 (81.766)	Training Prec@5 0.000 (0.000)	
2022-07-07 05:21:13,161: ============================================================
2022-07-07 05:22:27,035: time cost, forward:0.012036244050413597, backward:0.03252903010925404, data cost:0.6910780159839539 
2022-07-07 05:22:27,036: ============================================================
2022-07-07 05:22:27,036: Epoch 8/36 Batch 3300/7662 eta: 1 day, 20:55:11.483856	Training Loss1 8.5718 (8.5683)	Training Total_Loss 8.5718 (8.5683)	Training Prec@1 82.422 (81.753)	Training Prec@5 0.000 (0.000)	
2022-07-07 05:22:27,036: ============================================================
2022-07-07 05:23:40,783: time cost, forward:0.01204323852788213, backward:0.03255085511641069, data cost:0.691087721515733 
2022-07-07 05:23:40,784: ============================================================
2022-07-07 05:23:40,784: Epoch 8/36 Batch 3400/7662 eta: 1 day, 20:49:20.098108	Training Loss1 8.4139 (8.5687)	Training Total_Loss 8.4139 (8.5687)	Training Prec@1 81.445 (81.745)	Training Prec@5 0.000 (0.000)	
2022-07-07 05:23:40,784: ============================================================
2022-07-07 05:24:54,884: time cost, forward:0.012043315909800784, backward:0.032568260954938366, data cost:0.6912017567698088 
2022-07-07 05:24:54,885: ============================================================
2022-07-07 05:24:54,885: Epoch 8/36 Batch 3500/7662 eta: 1 day, 21:00:58.210800	Training Loss1 8.5212 (8.5696)	Training Total_Loss 8.5212 (8.5696)	Training Prec@1 82.617 (81.737)	Training Prec@5 0.000 (0.000)	
2022-07-07 05:24:54,885: ============================================================
2022-07-07 05:26:10,244: time cost, forward:0.012039393906992123, backward:0.03258996706732315, data cost:0.6916404042716953 
2022-07-07 05:26:10,245: ============================================================
2022-07-07 05:26:10,245: Epoch 8/36 Batch 3600/7662 eta: 1 day, 21:45:35.576063	Training Loss1 8.4613 (8.5710)	Training Total_Loss 8.4613 (8.5710)	Training Prec@1 83.008 (81.723)	Training Prec@5 0.000 (0.000)	
2022-07-07 05:26:10,245: ============================================================
2022-07-07 05:27:24,768: time cost, forward:0.01203211064788579, backward:0.03261052940174772, data cost:0.6918748033533356 
2022-07-07 05:27:24,768: ============================================================
2022-07-07 05:27:24,768: Epoch 8/36 Batch 3700/7662 eta: 1 day, 21:13:53.185020	Training Loss1 8.6583 (8.5712)	Training Total_Loss 8.6583 (8.5712)	Training Prec@1 80.078 (81.714)	Training Prec@5 0.000 (0.000)	
2022-07-07 05:27:24,768: ============================================================
2022-07-07 05:28:39,578: time cost, forward:0.012051529180190852, backward:0.032620968395673966, data cost:0.6921323979330803 
2022-07-07 05:28:39,578: ============================================================
2022-07-07 05:28:39,578: Epoch 8/36 Batch 3800/7662 eta: 1 day, 21:23:03.951235	Training Loss1 8.5700 (8.5726)	Training Total_Loss 8.5700 (8.5726)	Training Prec@1 82.227 (81.702)	Training Prec@5 0.000 (0.000)	
2022-07-07 05:28:39,578: ============================================================
2022-07-07 05:29:53,348: time cost, forward:0.012062507398497235, backward:0.03261552275251382, data cost:0.6921393330141837 
2022-07-07 05:29:53,348: ============================================================
2022-07-07 05:29:53,348: Epoch 8/36 Batch 3900/7662 eta: 1 day, 20:43:59.868121	Training Loss1 8.5214 (8.5728)	Training Total_Loss 8.5214 (8.5728)	Training Prec@1 82.617 (81.697)	Training Prec@5 0.000 (0.000)	
2022-07-07 05:29:53,349: ============================================================
2022-07-07 05:31:06,947: time cost, forward:0.012059264076921636, backward:0.032631695345062765, data cost:0.6920816730815013 
2022-07-07 05:31:06,948: ============================================================
2022-07-07 05:31:06,948: Epoch 8/36 Batch 4000/7662 eta: 1 day, 20:36:32.895308	Training Loss1 8.4488 (8.5735)	Training Total_Loss 8.4488 (8.5735)	Training Prec@1 82.227 (81.695)	Training Prec@5 0.000 (0.000)	
2022-07-07 05:31:06,948: ============================================================
2022-07-07 05:32:21,429: time cost, forward:0.012050970032843883, backward:0.03264135981687949, data cost:0.6922663483685998 
2022-07-07 05:32:21,429: ============================================================
2022-07-07 05:32:21,430: Epoch 8/36 Batch 4100/7662 eta: 1 day, 21:07:24.106914	Training Loss1 8.2880 (8.5748)	Training Total_Loss 8.2880 (8.5748)	Training Prec@1 84.375 (81.687)	Training Prec@5 0.000 (0.000)	
2022-07-07 05:32:21,430: ============================================================
2022-07-07 05:33:35,716: time cost, forward:0.012049733130356675, backward:0.03265954029222249, data cost:0.6923800538511156 
2022-07-07 05:33:35,716: ============================================================
2022-07-07 05:33:35,717: Epoch 8/36 Batch 4200/7662 eta: 1 day, 20:59:05.053176	Training Loss1 8.4313 (8.5744)	Training Total_Loss 8.4313 (8.5744)	Training Prec@1 82.227 (81.685)	Training Prec@5 0.000 (0.000)	
2022-07-07 05:33:35,717: ============================================================
2022-07-07 05:34:48,381: time cost, forward:0.012028338050088041, backward:0.03266524425576692, data cost:0.6921059870115406 
2022-07-07 05:34:48,381: ============================================================
2022-07-07 05:34:48,381: Epoch 8/36 Batch 4300/7662 eta: 1 day, 19:58:55.324312	Training Loss1 8.5254 (8.5749)	Training Total_Loss 8.5254 (8.5749)	Training Prec@1 82.422 (81.675)	Training Prec@5 0.000 (0.000)	
2022-07-07 05:34:48,381: ============================================================
2022-07-07 05:36:01,789: time cost, forward:0.012030288993729654, backward:0.03267816024142033, data cost:0.6920487984225652 
2022-07-07 05:36:01,789: ============================================================
2022-07-07 05:36:01,790: Epoch 8/36 Batch 4400/7662 eta: 1 day, 20:24:42.799670	Training Loss1 8.8512 (8.5753)	Training Total_Loss 8.8512 (8.5753)	Training Prec@1 80.273 (81.669)	Training Prec@5 0.000 (0.000)	
2022-07-07 05:36:01,790: ============================================================
2022-07-07 05:37:15,566: time cost, forward:0.012043904452674732, backward:0.032677289299711594, data cost:0.6920458943506271 
2022-07-07 05:37:15,566: ============================================================
2022-07-07 05:37:15,567: Epoch 8/36 Batch 4500/7662 eta: 1 day, 20:36:51.881953	Training Loss1 8.3972 (8.5749)	Training Total_Loss 8.3972 (8.5749)	Training Prec@1 83.984 (81.672)	Training Prec@5 0.000 (0.000)	
2022-07-07 05:37:15,567: ============================================================
2022-07-07 05:38:28,995: time cost, forward:0.01205180380286847, backward:0.032678552958518944, data cost:0.6919692131352699 
2022-07-07 05:38:28,995: ============================================================
2022-07-07 05:38:28,995: Epoch 8/36 Batch 4600/7662 eta: 1 day, 20:23:00.368465	Training Loss1 8.7687 (8.5749)	Training Total_Loss 8.7687 (8.5749)	Training Prec@1 80.273 (81.668)	Training Prec@5 0.000 (0.000)	
2022-07-07 05:38:28,996: ============================================================
2022-07-07 05:39:43,516: time cost, forward:0.012051027210298106, backward:0.03268552704247091, data cost:0.6921263648287036 
2022-07-07 05:39:43,517: ============================================================
2022-07-07 05:39:43,517: Epoch 8/36 Batch 4700/7662 eta: 1 day, 21:01:23.010894	Training Loss1 8.7795 (8.5761)	Training Total_Loss 8.7795 (8.5761)	Training Prec@1 81.055 (81.658)	Training Prec@5 0.000 (0.000)	
2022-07-07 05:39:43,517: ============================================================
2022-07-07 05:40:56,937: time cost, forward:0.012035589015441628, backward:0.03269796710283614, data cost:0.6920673104469218 
2022-07-07 05:40:56,938: ============================================================
2022-07-07 05:40:56,938: Epoch 8/36 Batch 4800/7662 eta: 1 day, 20:20:16.578887	Training Loss1 8.5043 (8.5773)	Training Total_Loss 8.5043 (8.5773)	Training Prec@1 83.008 (81.648)	Training Prec@5 0.000 (0.000)	
2022-07-07 05:40:56,938: ============================================================
2022-07-07 05:42:09,765: time cost, forward:0.012023163367398152, backward:0.03269802874315756, data cost:0.6918878380097426 
2022-07-07 05:42:09,765: ============================================================
2022-07-07 05:42:09,765: Epoch 8/36 Batch 4900/7662 eta: 1 day, 19:57:33.237763	Training Loss1 8.6466 (8.5772)	Training Total_Loss 8.6466 (8.5772)	Training Prec@1 80.469 (81.647)	Training Prec@5 0.000 (0.000)	
2022-07-07 05:42:09,765: ============================================================
2022-07-07 05:43:23,068: time cost, forward:0.012024865576829354, backward:0.03268952259041591, data cost:0.6918120853994865 
2022-07-07 05:43:23,068: ============================================================
2022-07-07 05:43:23,068: Epoch 8/36 Batch 5000/7662 eta: 1 day, 20:13:33.900755	Training Loss1 8.5773 (8.5763)	Training Total_Loss 8.5773 (8.5763)	Training Prec@1 83.203 (81.654)	Training Prec@5 0.000 (0.000)	
2022-07-07 05:43:23,069: ============================================================
2022-07-07 05:44:37,815: time cost, forward:0.012027127809631144, backward:0.03268261880681991, data cost:0.6920250280391097 
2022-07-07 05:44:37,815: ============================================================
2022-07-07 05:44:37,815: Epoch 8/36 Batch 5100/7662 eta: 1 day, 21:04:34.645278	Training Loss1 8.6076 (8.5765)	Training Total_Loss 8.6076 (8.5765)	Training Prec@1 80.859 (81.651)	Training Prec@5 0.000 (0.000)	
2022-07-07 05:44:37,815: ============================================================
2022-07-07 05:45:51,694: time cost, forward:0.012025681475672179, backward:0.03269194813732185, data cost:0.6920440857812611 
2022-07-07 05:45:51,695: ============================================================
2022-07-07 05:45:51,695: Epoch 8/36 Batch 5200/7662 eta: 1 day, 20:31:58.213189	Training Loss1 8.1694 (8.5765)	Training Total_Loss 8.1694 (8.5765)	Training Prec@1 84.180 (81.650)	Training Prec@5 0.000 (0.000)	
2022-07-07 05:45:51,695: ============================================================
2022-07-07 05:47:05,684: time cost, forward:0.012013583796094962, backward:0.03271317864436207, data cost:0.6920856323123405 
2022-07-07 05:47:05,684: ============================================================
2022-07-07 05:47:05,685: Epoch 8/36 Batch 5300/7662 eta: 1 day, 20:34:42.469156	Training Loss1 8.4403 (8.5769)	Training Total_Loss 8.4403 (8.5769)	Training Prec@1 83.594 (81.651)	Training Prec@5 0.000 (0.000)	
2022-07-07 05:47:05,685: ============================================================
2022-07-07 05:48:19,048: time cost, forward:0.012002942252543308, backward:0.032724061394691646, data cost:0.6920145556846798 
2022-07-07 05:48:19,049: ============================================================
2022-07-07 05:48:19,049: Epoch 8/36 Batch 5400/7662 eta: 1 day, 20:10:53.444563	Training Loss1 8.2417 (8.5774)	Training Total_Loss 8.2417 (8.5774)	Training Prec@1 84.180 (81.648)	Training Prec@5 0.000 (0.000)	
2022-07-07 05:48:19,049: ============================================================
2022-07-07 05:49:32,905: time cost, forward:0.011999009327143621, backward:0.03273429565374191, data cost:0.6920288843466035 
2022-07-07 05:49:32,905: ============================================================
2022-07-07 05:49:32,905: Epoch 8/36 Batch 5500/7662 eta: 1 day, 20:27:26.024982	Training Loss1 8.6406 (8.5777)	Training Total_Loss 8.6406 (8.5777)	Training Prec@1 81.250 (81.645)	Training Prec@5 0.000 (0.000)	
2022-07-07 05:49:32,905: ============================================================
2022-07-07 05:50:48,174: time cost, forward:0.012010772306166668, backward:0.03272901204765471, data cost:0.6922985204395854 
2022-07-07 05:50:48,175: ============================================================
2022-07-07 05:50:48,175: Epoch 8/36 Batch 5600/7662 eta: 1 day, 21:17:13.484229	Training Loss1 8.6468 (8.5777)	Training Total_Loss 8.6468 (8.5777)	Training Prec@1 80.273 (81.646)	Training Prec@5 0.000 (0.000)	
2022-07-07 05:50:48,175: ============================================================
2022-07-07 05:52:02,493: time cost, forward:0.012006121992039919, backward:0.032742454663015785, data cost:0.692386896197347 
2022-07-07 05:52:02,493: ============================================================
2022-07-07 05:52:02,494: Epoch 8/36 Batch 5700/7662 eta: 1 day, 20:41:38.815600	Training Loss1 8.5832 (8.5774)	Training Total_Loss 8.5832 (8.5774)	Training Prec@1 81.641 (81.643)	Training Prec@5 0.000 (0.000)	
2022-07-07 05:52:02,494: ============================================================
2022-07-07 05:53:15,902: time cost, forward:0.011999676486175006, backward:0.03275075187393665, data cost:0.6923229525800121 
2022-07-07 05:53:15,902: ============================================================
2022-07-07 05:53:15,903: Epoch 8/36 Batch 5800/7662 eta: 1 day, 20:07:36.479491	Training Loss1 8.6336 (8.5780)	Training Total_Loss 8.6336 (8.5780)	Training Prec@1 77.734 (81.638)	Training Prec@5 0.000 (0.000)	
2022-07-07 05:53:15,903: ============================================================
2022-07-07 05:54:30,143: time cost, forward:0.011999693820589295, backward:0.032750981159989444, data cost:0.6924017105370907 
2022-07-07 05:54:30,143: ============================================================
2022-07-07 05:54:30,144: Epoch 8/36 Batch 5900/7662 eta: 1 day, 20:36:22.434736	Training Loss1 8.5517 (8.5776)	Training Total_Loss 8.5517 (8.5776)	Training Prec@1 80.273 (81.638)	Training Prec@5 0.000 (0.000)	
2022-07-07 05:54:30,144: ============================================================
2022-07-07 05:55:44,153: time cost, forward:0.012025357882446757, backward:0.03274388181346519, data cost:0.6924215010512489 
2022-07-07 05:55:44,153: ============================================================
2022-07-07 05:55:44,153: Epoch 8/36 Batch 6000/7662 eta: 1 day, 20:26:48.398441	Training Loss1 8.2325 (8.5772)	Training Total_Loss 8.2325 (8.5772)	Training Prec@1 83.203 (81.640)	Training Prec@5 0.000 (0.000)	
2022-07-07 05:55:44,154: ============================================================
2022-07-07 05:56:58,220: time cost, forward:0.01204223729759225, backward:0.03272925151881868, data cost:0.6924611873207649 
2022-07-07 05:56:58,220: ============================================================
2022-07-07 05:56:58,221: Epoch 8/36 Batch 6100/7662 eta: 1 day, 20:27:38.424312	Training Loss1 9.0812 (8.5769)	Training Total_Loss 9.0812 (8.5769)	Training Prec@1 80.273 (81.640)	Training Prec@5 0.000 (0.000)	
2022-07-07 05:56:58,221: ============================================================
2022-07-07 05:58:12,243: time cost, forward:0.012050441742558732, backward:0.03271813599558333, data cost:0.692504162749161 
2022-07-07 05:58:12,244: ============================================================
2022-07-07 05:58:12,244: Epoch 8/36 Batch 6200/7662 eta: 1 day, 20:24:49.618005	Training Loss1 8.0503 (8.5762)	Training Total_Loss 8.0503 (8.5762)	Training Prec@1 84.766 (81.643)	Training Prec@5 0.000 (0.000)	
2022-07-07 05:58:12,244: ============================================================
2022-07-07 05:59:27,008: time cost, forward:0.012064504366031544, backward:0.03270587029391233, data cost:0.6926600194995527 
2022-07-07 05:59:27,008: ============================================================
2022-07-07 05:59:27,009: Epoch 8/36 Batch 6300/7662 eta: 1 day, 20:50:16.224072	Training Loss1 8.8438 (8.5762)	Training Total_Loss 8.8438 (8.5762)	Training Prec@1 78.125 (81.642)	Training Prec@5 0.000 (0.000)	
2022-07-07 05:59:27,009: ============================================================
2022-07-07 06:00:40,158: time cost, forward:0.012077616348660053, backward:0.03269745711517215, data cost:0.6925545965699335 
2022-07-07 06:00:40,158: ============================================================
2022-07-07 06:00:40,159: Epoch 8/36 Batch 6400/7662 eta: 1 day, 19:50:56.931661	Training Loss1 8.5667 (8.5748)	Training Total_Loss 8.5667 (8.5748)	Training Prec@1 78.906 (81.649)	Training Prec@5 0.000 (0.000)	
2022-07-07 06:00:40,159: ============================================================
2022-07-07 06:01:55,072: time cost, forward:0.012084999016971474, backward:0.03270965026770946, data cost:0.6927065499325242 
2022-07-07 06:01:55,072: ============================================================
2022-07-07 06:01:55,072: Epoch 8/36 Batch 6500/7662 eta: 1 day, 20:53:07.789827	Training Loss1 8.3853 (8.5738)	Training Total_Loss 8.3853 (8.5738)	Training Prec@1 83.203 (81.653)	Training Prec@5 0.000 (0.000)	
2022-07-07 06:01:55,072: ============================================================
2022-07-07 06:03:08,614: time cost, forward:0.012085046130864073, backward:0.0327092669085673, data cost:0.6926677779801633 
2022-07-07 06:03:08,615: ============================================================
2022-07-07 06:03:08,615: Epoch 8/36 Batch 6600/7662 eta: 1 day, 20:02:37.887718	Training Loss1 8.4467 (8.5734)	Training Total_Loss 8.4467 (8.5734)	Training Prec@1 82.227 (81.653)	Training Prec@5 0.000 (0.000)	
2022-07-07 06:03:08,615: ============================================================
2022-07-07 06:04:22,962: time cost, forward:0.012087287218077074, backward:0.032722953611887255, data cost:0.6927304274289532 
2022-07-07 06:04:22,963: ============================================================
2022-07-07 06:04:22,963: Epoch 8/36 Batch 6700/7662 eta: 1 day, 20:30:18.508149	Training Loss1 8.5882 (8.5727)	Training Total_Loss 8.5882 (8.5727)	Training Prec@1 81.250 (81.658)	Training Prec@5 0.000 (0.000)	
2022-07-07 06:04:22,963: ============================================================
2022-07-07 06:05:36,920: time cost, forward:0.012085562051087727, backward:0.03272463784776798, data cost:0.6927497766704871 
2022-07-07 06:05:36,921: ============================================================
2022-07-07 06:05:36,921: Epoch 8/36 Batch 6800/7662 eta: 1 day, 20:15:05.393669	Training Loss1 8.4977 (8.5729)	Training Total_Loss 8.4977 (8.5729)	Training Prec@1 84.180 (81.654)	Training Prec@5 0.000 (0.000)	
2022-07-07 06:05:36,921: ============================================================
2022-07-07 06:06:51,478: time cost, forward:0.01208088414913365, backward:0.03272320747651956, data cost:0.6928609622563291 
2022-07-07 06:06:51,479: ============================================================
2022-07-07 06:06:51,479: Epoch 8/36 Batch 6900/7662 eta: 1 day, 20:35:22.517733	Training Loss1 8.0441 (8.5726)	Training Total_Loss 8.0441 (8.5726)	Training Prec@1 83.594 (81.655)	Training Prec@5 0.000 (0.000)	
2022-07-07 06:06:51,479: ============================================================
2022-07-07 06:08:05,866: time cost, forward:0.012087558538407185, backward:0.03271853608699471, data cost:0.6929431850355955 
2022-07-07 06:08:05,867: ============================================================
2022-07-07 06:08:05,867: Epoch 8/36 Batch 7000/7662 eta: 1 day, 20:28:02.018706	Training Loss1 8.4901 (8.5722)	Training Total_Loss 8.4901 (8.5722)	Training Prec@1 81.445 (81.657)	Training Prec@5 0.000 (0.000)	
2022-07-07 06:08:05,867: ============================================================
2022-07-07 06:09:21,584: time cost, forward:0.012104946855995618, backward:0.03269962170272163, data cost:0.693213246140384 
2022-07-07 06:09:21,585: ============================================================
2022-07-07 06:09:21,585: Epoch 8/36 Batch 7100/7662 eta: 1 day, 21:14:28.321183	Training Loss1 8.4388 (8.5718)	Training Total_Loss 8.4388 (8.5718)	Training Prec@1 79.492 (81.655)	Training Prec@5 0.000 (0.000)	
2022-07-07 06:09:21,585: ============================================================
2022-07-07 06:10:35,549: time cost, forward:0.01211853099541625, backward:0.032684530876033555, data cost:0.693228955897445 
2022-07-07 06:10:35,549: ============================================================
2022-07-07 06:10:35,549: Epoch 8/36 Batch 7200/7662 eta: 1 day, 20:10:22.590270	Training Loss1 8.5943 (8.5710)	Training Total_Loss 8.5943 (8.5710)	Training Prec@1 80.859 (81.660)	Training Prec@5 0.000 (0.000)	
2022-07-07 06:10:35,549: ============================================================
2022-07-07 06:11:49,815: time cost, forward:0.012124839817469929, backward:0.03266554277945029, data cost:0.6932940932557524 
2022-07-07 06:11:49,815: ============================================================
2022-07-07 06:11:49,815: Epoch 8/36 Batch 7300/7662 eta: 1 day, 20:19:56.850933	Training Loss1 8.6586 (8.5707)	Training Total_Loss 8.6586 (8.5707)	Training Prec@1 80.664 (81.658)	Training Prec@5 0.000 (0.000)	
2022-07-07 06:11:49,815: ============================================================
2022-07-07 06:13:03,358: time cost, forward:0.012116904934768274, backward:0.03267488174783908, data cost:0.6932448429229341 
2022-07-07 06:13:03,358: ============================================================
2022-07-07 06:13:03,359: Epoch 8/36 Batch 7400/7662 eta: 1 day, 19:52:50.703475	Training Loss1 8.6158 (8.5704)	Training Total_Loss 8.6158 (8.5704)	Training Prec@1 82.422 (81.658)	Training Prec@5 0.000 (0.000)	
2022-07-07 06:13:03,359: ============================================================
2022-07-07 06:14:17,405: time cost, forward:0.012113533014932589, backward:0.03268222930288614, data cost:0.6932675104679179 
2022-07-07 06:14:17,405: ============================================================
2022-07-07 06:14:17,406: Epoch 8/36 Batch 7500/7662 eta: 1 day, 20:09:38.102350	Training Loss1 8.4512 (8.5699)	Training Total_Loss 8.4512 (8.5699)	Training Prec@1 80.859 (81.659)	Training Prec@5 0.000 (0.000)	
2022-07-07 06:14:17,406: ============================================================
2022-07-07 06:15:31,233: time cost, forward:0.012111729109721806, backward:0.03268909128045766, data cost:0.6932592121515325 
2022-07-07 06:15:31,233: ============================================================
2022-07-07 06:15:31,233: Epoch 8/36 Batch 7600/7662 eta: 1 day, 20:00:33.572221	Training Loss1 8.2539 (8.5694)	Training Total_Loss 8.2539 (8.5694)	Training Prec@1 82.422 (81.664)	Training Prec@5 0.000 (0.000)	
2022-07-07 06:15:31,233: ============================================================
2022-07-07 06:16:19,348: Epoch 8/36 Batch 7663/7662 eta: 1 day, 19:59:47.060751	Training Loss1 8.2721 (8.5690)	Training Total_Loss 8.2721 (8.5690)	Training Prec@1 83.789 (81.666)	Training Prec@5 0.000 (0.000)	
2022-07-07 06:16:19,349: ============================================================
2022-07-07 06:17:37,023: time cost, forward:0.010977942534167357, backward:0.03262373654529302, data cost:0.7354756846572413 
2022-07-07 06:17:37,023: ============================================================
2022-07-07 06:17:37,023: Epoch 9/36 Batch 100/7662 eta: 1 day, 22:15:56.707908	Training Loss1 7.9378 (8.0281)	Training Total_Loss 7.9378 (8.0281)	Training Prec@1 85.352 (84.730)	Training Prec@5 0.000 (0.000)	
2022-07-07 06:17:37,023: ============================================================
2022-07-07 06:18:52,804: time cost, forward:0.010930903592900415, backward:0.032957619758107556, data cost:0.7242572978513324 
2022-07-07 06:18:52,804: ============================================================
2022-07-07 06:18:52,805: Epoch 9/36 Batch 200/7662 eta: 1 day, 21:07:07.445868	Training Loss1 8.2317 (8.0530)	Training Total_Loss 8.2317 (8.0530)	Training Prec@1 83.594 (84.645)	Training Prec@5 0.000 (0.000)	
2022-07-07 06:18:52,805: ============================================================
2022-07-07 06:20:07,947: time cost, forward:0.0108608545666953, backward:0.033031560106819687, data cost:0.7185125980887525 
2022-07-07 06:20:07,948: ============================================================
2022-07-07 06:20:07,948: Epoch 9/36 Batch 300/7662 eta: 1 day, 20:43:04.507078	Training Loss1 8.2880 (8.0984)	Training Total_Loss 8.2880 (8.0984)	Training Prec@1 83.398 (84.378)	Training Prec@5 0.000 (0.000)	
2022-07-07 06:20:07,948: ============================================================
2022-07-07 06:21:21,415: time cost, forward:0.011185610802251295, backward:0.033318236358183664, data cost:0.7107631879342827 
2022-07-07 06:21:21,415: ============================================================
2022-07-07 06:21:21,415: Epoch 9/36 Batch 400/7662 eta: 1 day, 19:42:00.938061	Training Loss1 8.5442 (8.1380)	Training Total_Loss 8.5442 (8.1380)	Training Prec@1 80.078 (84.208)	Training Prec@5 0.000 (0.000)	
2022-07-07 06:21:21,415: ============================================================
2022-07-07 06:22:34,316: time cost, forward:0.011181406124321397, backward:0.03348960714015311, data cost:0.7052149318740937 
2022-07-07 06:22:34,316: ============================================================
2022-07-07 06:22:34,316: Epoch 9/36 Batch 500/7662 eta: 1 day, 19:20:34.992987	Training Loss1 8.3075 (8.1656)	Training Total_Loss 8.3075 (8.1656)	Training Prec@1 82.617 (84.092)	Training Prec@5 0.000 (0.000)	
2022-07-07 06:22:34,316: ============================================================
2022-07-07 06:23:49,472: time cost, forward:0.011300518437100572, backward:0.0334941926902045, data cost:0.7052809682632727 
2022-07-07 06:23:49,472: ============================================================
2022-07-07 06:23:49,473: Epoch 9/36 Batch 600/7662 eta: 1 day, 20:39:47.279045	Training Loss1 8.5037 (8.1936)	Training Total_Loss 8.5037 (8.1936)	Training Prec@1 83.398 (83.943)	Training Prec@5 0.000 (0.000)	
2022-07-07 06:23:49,473: ============================================================
2022-07-07 06:25:04,060: time cost, forward:0.011345325109784695, backward:0.03353392412734134, data cost:0.7044938050626174 
2022-07-07 06:25:04,061: ============================================================
2022-07-07 06:25:04,061: Epoch 9/36 Batch 700/7662 eta: 1 day, 20:18:17.824049	Training Loss1 8.4020 (8.2181)	Training Total_Loss 8.4020 (8.2181)	Training Prec@1 82.422 (83.828)	Training Prec@5 0.000 (0.000)	
2022-07-07 06:25:04,061: ============================================================
2022-07-07 06:26:17,930: time cost, forward:0.011445913505792916, backward:0.03363746247989812, data cost:0.7028849420320704 
2022-07-07 06:26:17,930: ============================================================
2022-07-07 06:26:17,931: Epoch 9/36 Batch 800/7662 eta: 1 day, 19:51:26.743513	Training Loss1 8.6775 (8.2396)	Training Total_Loss 8.6775 (8.2396)	Training Prec@1 81.641 (83.721)	Training Prec@5 0.000 (0.000)	
2022-07-07 06:26:17,931: ============================================================
2022-07-07 06:27:31,685: time cost, forward:0.01143601898091521, backward:0.03357025168761528, data cost:0.701744201053369 
2022-07-07 06:27:31,685: ============================================================
2022-07-07 06:27:31,686: Epoch 9/36 Batch 900/7662 eta: 1 day, 19:46:07.954314	Training Loss1 8.2536 (8.2619)	Training Total_Loss 8.2536 (8.2619)	Training Prec@1 84.570 (83.592)	Training Prec@5 0.000 (0.000)	
2022-07-07 06:27:31,686: ============================================================
2022-07-07 06:28:45,757: time cost, forward:0.011502793124010851, backward:0.03359846429185228, data cost:0.70098401738836 
2022-07-07 06:28:45,758: ============================================================
2022-07-07 06:28:45,758: Epoch 9/36 Batch 1000/7662 eta: 1 day, 19:56:11.358852	Training Loss1 7.8490 (8.2754)	Training Total_Loss 7.8490 (8.2754)	Training Prec@1 86.914 (83.503)	Training Prec@5 0.000 (0.000)	
2022-07-07 06:28:45,758: ============================================================
2022-07-07 06:29:58,751: time cost, forward:0.011550426700095678, backward:0.033696020159317865, data cost:0.6993044433645816 
2022-07-07 06:29:58,751: ============================================================
2022-07-07 06:29:58,751: Epoch 9/36 Batch 1100/7662 eta: 1 day, 19:16:34.835330	Training Loss1 8.4193 (8.2935)	Training Total_Loss 8.4193 (8.2935)	Training Prec@1 84.375 (83.413)	Training Prec@5 0.000 (0.000)	
2022-07-07 06:29:58,751: ============================================================
2022-07-07 06:31:11,665: time cost, forward:0.011593029835106832, backward:0.03369982825208446, data cost:0.6979240816369268 
2022-07-07 06:31:11,666: ============================================================
2022-07-07 06:31:11,666: Epoch 9/36 Batch 1200/7662 eta: 1 day, 19:12:34.450686	Training Loss1 8.2735 (8.3051)	Training Total_Loss 8.2735 (8.3051)	Training Prec@1 84.375 (83.351)	Training Prec@5 0.000 (0.000)	
2022-07-07 06:31:11,666: ============================================================
2022-07-07 06:32:25,108: time cost, forward:0.011669764067229168, backward:0.033714564788148806, data cost:0.697108146867172 
2022-07-07 06:32:25,109: ============================================================
2022-07-07 06:32:25,109: Epoch 9/36 Batch 1300/7662 eta: 1 day, 19:30:06.906801	Training Loss1 8.7916 (8.3193)	Training Total_Loss 8.7916 (8.3193)	Training Prec@1 79.492 (83.263)	Training Prec@5 0.000 (0.000)	
2022-07-07 06:32:25,109: ============================================================
2022-07-07 06:33:38,495: time cost, forward:0.01169445959477019, backward:0.0337563798289541, data cost:0.6963799822918426 
2022-07-07 06:33:38,496: ============================================================
2022-07-07 06:33:38,496: Epoch 9/36 Batch 1400/7662 eta: 1 day, 19:26:55.452028	Training Loss1 8.4062 (8.3263)	Training Total_Loss 8.4062 (8.3263)	Training Prec@1 83.398 (83.202)	Training Prec@5 0.000 (0.000)	
2022-07-07 06:33:38,496: ============================================================
2022-07-07 06:34:51,453: time cost, forward:0.011743271008899325, backward:0.03376702024906456, data cost:0.6954621102827402 
2022-07-07 06:34:51,453: ============================================================
2022-07-07 06:34:51,453: Epoch 9/36 Batch 1500/7662 eta: 1 day, 19:10:26.444346	Training Loss1 8.2449 (8.3323)	Training Total_Loss 8.2449 (8.3323)	Training Prec@1 83.008 (83.161)	Training Prec@5 0.000 (0.000)	
2022-07-07 06:34:51,454: ============================================================
2022-07-07 06:36:04,285: time cost, forward:0.01177056019122784, backward:0.03379146108931493, data cost:0.6945799065053724 
2022-07-07 06:36:04,286: ============================================================
2022-07-07 06:36:04,286: Epoch 9/36 Batch 1600/7662 eta: 1 day, 19:04:47.160765	Training Loss1 8.6129 (8.3390)	Training Total_Loss 8.6129 (8.3390)	Training Prec@1 80.078 (83.118)	Training Prec@5 0.000 (0.000)	
2022-07-07 06:36:04,286: ============================================================
2022-07-07 06:37:17,843: time cost, forward:0.01177854072072353, backward:0.033795651300575116, data cost:0.6942650888722528 
2022-07-07 06:37:17,844: ============================================================
2022-07-07 06:37:17,844: Epoch 9/36 Batch 1700/7662 eta: 1 day, 19:29:18.302690	Training Loss1 8.2660 (8.3468)	Training Total_Loss 8.2660 (8.3468)	Training Prec@1 84.180 (83.060)	Training Prec@5 0.000 (0.000)	
2022-07-07 06:37:17,844: ============================================================
2022-07-07 06:38:31,833: time cost, forward:0.011792468388521916, backward:0.03383316948653725, data cost:0.6941789164020989 
2022-07-07 06:38:31,833: ============================================================
2022-07-07 06:38:31,833: Epoch 9/36 Batch 1800/7662 eta: 1 day, 19:43:23.207047	Training Loss1 8.4747 (8.3527)	Training Total_Loss 8.4747 (8.3527)	Training Prec@1 83.398 (83.026)	Training Prec@5 0.000 (0.000)	
2022-07-07 06:38:31,833: ============================================================
2022-07-07 06:39:45,911: time cost, forward:0.011810573168087157, backward:0.03383780856581975, data cost:0.6941767861304502 
2022-07-07 06:39:45,911: ============================================================
2022-07-07 06:39:45,911: Epoch 9/36 Batch 1900/7662 eta: 1 day, 19:45:17.165524	Training Loss1 8.2377 (8.3601)	Training Total_Loss 8.2377 (8.3601)	Training Prec@1 83.203 (82.967)	Training Prec@5 0.000 (0.000)	
2022-07-07 06:39:45,911: ============================================================
2022-07-07 06:40:59,535: time cost, forward:0.011792621474196876, backward:0.033832988719930644, data cost:0.6939837897998682 
2022-07-07 06:40:59,535: ============================================================
2022-07-07 06:40:59,535: Epoch 9/36 Batch 2000/7662 eta: 1 day, 19:27:58.523281	Training Loss1 8.4635 (8.3662)	Training Total_Loss 8.4635 (8.3662)	Training Prec@1 80.469 (82.918)	Training Prec@5 0.000 (0.000)	
2022-07-07 06:40:59,536: ============================================================
2022-07-07 06:42:12,815: time cost, forward:0.011799532211979779, backward:0.03381742869972785, data cost:0.6936437683823337 
2022-07-07 06:42:12,816: ============================================================
2022-07-07 06:42:12,816: Epoch 9/36 Batch 2100/7662 eta: 1 day, 19:14:34.748765	Training Loss1 8.4064 (8.3697)	Training Total_Loss 8.4064 (8.3697)	Training Prec@1 82.617 (82.900)	Training Prec@5 0.000 (0.000)	
2022-07-07 06:42:12,816: ============================================================
2022-07-07 06:43:25,905: time cost, forward:0.0118289912164401, backward:0.033819196006285704, data cost:0.6931968095249456 
2022-07-07 06:43:25,905: ============================================================
2022-07-07 06:43:25,906: Epoch 9/36 Batch 2200/7662 eta: 1 day, 19:06:36.379054	Training Loss1 8.6246 (8.3743)	Training Total_Loss 8.6246 (8.3743)	Training Prec@1 80.859 (82.860)	Training Prec@5 0.000 (0.000)	
2022-07-07 06:43:25,906: ============================================================
2022-07-07 06:44:39,687: time cost, forward:0.01185894313196661, backward:0.03375572637663348, data cost:0.6931624165717909 
2022-07-07 06:44:39,687: ============================================================
2022-07-07 06:44:39,687: Epoch 9/36 Batch 2300/7662 eta: 1 day, 19:29:52.238452	Training Loss1 8.7217 (8.3776)	Training Total_Loss 8.7217 (8.3776)	Training Prec@1 80.273 (82.836)	Training Prec@5 0.000 (0.000)	
2022-07-07 06:44:39,687: ============================================================
2022-07-07 06:45:53,408: time cost, forward:0.011869545726291137, backward:0.03377697248168665, data cost:0.693041964141763 
2022-07-07 06:45:53,409: ============================================================
2022-07-07 06:45:53,409: Epoch 9/36 Batch 2400/7662 eta: 1 day, 19:26:30.483705	Training Loss1 8.5020 (8.3811)	Training Total_Loss 8.5020 (8.3811)	Training Prec@1 81.836 (82.805)	Training Prec@5 0.000 (0.000)	
2022-07-07 06:45:53,409: ============================================================
2022-07-07 06:47:06,898: time cost, forward:0.011866233595946924, backward:0.03376205571416189, data cost:0.6928715255557178 
2022-07-07 06:47:06,899: ============================================================
2022-07-07 06:47:06,899: Epoch 9/36 Batch 2500/7662 eta: 1 day, 19:17:06.055018	Training Loss1 8.3445 (8.3847)	Training Total_Loss 8.3445 (8.3847)	Training Prec@1 84.180 (82.780)	Training Prec@5 0.000 (0.000)	
2022-07-07 06:47:06,899: ============================================================
2022-07-07 06:48:20,753: time cost, forward:0.011877755102353537, backward:0.0337694941598115, data cost:0.6928429403594936 
2022-07-07 06:48:20,754: ============================================================
2022-07-07 06:48:20,754: Epoch 9/36 Batch 2600/7662 eta: 1 day, 19:28:46.712107	Training Loss1 8.5539 (8.3873)	Training Total_Loss 8.5539 (8.3873)	Training Prec@1 82.227 (82.761)	Training Prec@5 0.000 (0.000)	
2022-07-07 06:48:20,754: ============================================================
2022-07-07 06:49:34,430: time cost, forward:0.011875991867223728, backward:0.03376453397184798, data cost:0.6927670148974571 
2022-07-07 06:49:34,430: ============================================================
2022-07-07 06:49:34,430: Epoch 9/36 Batch 2700/7662 eta: 1 day, 19:21:13.460701	Training Loss1 8.5294 (8.3885)	Training Total_Loss 8.5294 (8.3885)	Training Prec@1 80.664 (82.748)	Training Prec@5 0.000 (0.000)	
2022-07-07 06:49:34,430: ============================================================
2022-07-07 06:50:48,949: time cost, forward:0.011881590059886196, backward:0.03377780423670337, data cost:0.6929676219283278 
2022-07-07 06:50:48,950: ============================================================
2022-07-07 06:50:48,950: Epoch 9/36 Batch 2800/7662 eta: 1 day, 19:49:45.115476	Training Loss1 8.5892 (8.3909)	Training Total_Loss 8.5892 (8.3909)	Training Prec@1 81.055 (82.734)	Training Prec@5 0.000 (0.000)	
2022-07-07 06:50:48,950: ============================================================
2022-07-07 06:52:02,648: time cost, forward:0.011889196914325462, backward:0.03377991933253519, data cost:0.6928728933620552 
2022-07-07 06:52:02,649: ============================================================
2022-07-07 06:52:02,649: Epoch 9/36 Batch 2900/7662 eta: 1 day, 19:19:34.477011	Training Loss1 8.2106 (8.3921)	Training Total_Loss 8.2106 (8.3921)	Training Prec@1 85.547 (82.722)	Training Prec@5 0.000 (0.000)	
2022-07-07 06:52:02,649: ============================================================
2022-07-07 06:53:15,894: time cost, forward:0.011909076316072846, backward:0.0337934261880425, data cost:0.6926055945885822 
2022-07-07 06:53:15,894: ============================================================
2022-07-07 06:53:15,894: Epoch 9/36 Batch 3000/7662 eta: 1 day, 19:02:21.592249	Training Loss1 8.7948 (8.3948)	Training Total_Loss 8.7948 (8.3948)	Training Prec@1 79.297 (82.705)	Training Prec@5 0.000 (0.000)	
2022-07-07 06:53:15,894: ============================================================
2022-07-07 06:54:29,501: time cost, forward:0.01191414521947604, backward:0.03377475520032727, data cost:0.6925432771280836 
2022-07-07 06:54:29,502: ============================================================
2022-07-07 06:54:29,502: Epoch 9/36 Batch 3100/7662 eta: 1 day, 19:13:53.435493	Training Loss1 8.5815 (8.3965)	Training Total_Loss 8.5815 (8.3965)	Training Prec@1 82.227 (82.700)	Training Prec@5 0.000 (0.000)	
2022-07-07 06:54:29,502: ============================================================
2022-07-07 06:55:43,394: time cost, forward:0.011935530546569347, backward:0.03376887529557405, data cost:0.692524419720749 
2022-07-07 06:55:43,394: ============================================================
2022-07-07 06:55:43,394: Epoch 9/36 Batch 3200/7662 eta: 1 day, 19:22:41.952723	Training Loss1 8.5445 (8.3974)	Training Total_Loss 8.5445 (8.3974)	Training Prec@1 81.250 (82.690)	Training Prec@5 0.000 (0.000)	
2022-07-07 06:55:43,394: ============================================================
2022-07-07 06:56:57,687: time cost, forward:0.011928344864164492, backward:0.03374273446734366, data cost:0.6926878811771778 
2022-07-07 06:56:57,687: ============================================================
2022-07-07 06:56:57,687: Epoch 9/36 Batch 3300/7662 eta: 1 day, 19:35:34.458988	Training Loss1 8.2137 (8.3992)	Training Total_Loss 8.2137 (8.3992)	Training Prec@1 84.180 (82.682)	Training Prec@5 0.000 (0.000)	
2022-07-07 06:56:57,687: ============================================================
2022-07-07 06:58:11,226: time cost, forward:0.01191900133490387, backward:0.03372671892447274, data cost:0.6926096604479941 
2022-07-07 06:58:11,227: ============================================================
2022-07-07 06:58:11,227: Epoch 9/36 Batch 3400/7662 eta: 1 day, 19:07:49.351343	Training Loss1 8.2150 (8.4005)	Training Total_Loss 8.2150 (8.4005)	Training Prec@1 84.570 (82.671)	Training Prec@5 0.000 (0.000)	
2022-07-07 06:58:11,227: ============================================================
2022-07-07 06:59:25,955: time cost, forward:0.011912395491467847, backward:0.033731364563350234, data cost:0.6928511260066178 
2022-07-07 06:59:25,956: ============================================================
2022-07-07 06:59:25,956: Epoch 9/36 Batch 3500/7662 eta: 1 day, 19:48:25.673883	Training Loss1 8.4184 (8.4014)	Training Total_Loss 8.4184 (8.4014)	Training Prec@1 83.398 (82.667)	Training Prec@5 0.000 (0.000)	
2022-07-07 06:59:25,956: ============================================================
2022-07-07 07:00:39,592: time cost, forward:0.01189374883958584, backward:0.033742316665501024, data cost:0.6927845517805332 
2022-07-07 07:00:39,592: ============================================================
2022-07-07 07:00:39,593: Epoch 9/36 Batch 3600/7662 eta: 1 day, 19:08:47.109067	Training Loss1 8.3882 (8.4027)	Training Total_Loss 8.3882 (8.4027)	Training Prec@1 83.398 (82.650)	Training Prec@5 0.000 (0.000)	
2022-07-07 07:00:39,593: ============================================================
2022-07-07 07:01:53,779: time cost, forward:0.011898676425452231, backward:0.03375079335957548, data cost:0.6928453423519914 
2022-07-07 07:01:53,779: ============================================================
2022-07-07 07:01:53,780: Epoch 9/36 Batch 3700/7662 eta: 1 day, 19:26:53.612593	Training Loss1 8.2450 (8.4035)	Training Total_Loss 8.2450 (8.4035)	Training Prec@1 83.594 (82.638)	Training Prec@5 0.000 (0.000)	
2022-07-07 07:01:53,780: ============================================================
2022-07-07 07:03:07,567: time cost, forward:0.01189337463308617, backward:0.03373932850991591, data cost:0.6928263564083443 
2022-07-07 07:03:07,568: ============================================================
2022-07-07 07:03:07,568: Epoch 9/36 Batch 3800/7662 eta: 1 day, 19:11:39.457356	Training Loss1 8.3785 (8.4038)	Training Total_Loss 8.3785 (8.4038)	Training Prec@1 83.398 (82.635)	Training Prec@5 0.000 (0.000)	
2022-07-07 07:03:07,568: ============================================================
2022-07-07 07:04:21,303: time cost, forward:0.01188700882157597, backward:0.033754737660284986, data cost:0.692775844212953 
2022-07-07 07:04:21,304: ============================================================
2022-07-07 07:04:21,304: Epoch 9/36 Batch 3900/7662 eta: 1 day, 19:08:35.030777	Training Loss1 8.1883 (8.4044)	Training Total_Loss 8.1883 (8.4044)	Training Prec@1 83.398 (82.629)	Training Prec@5 0.000 (0.000)	
2022-07-07 07:04:21,304: ============================================================
2022-07-07 07:05:35,407: time cost, forward:0.011872939510207141, backward:0.03374945321480135, data cost:0.6928470527031744 
2022-07-07 07:05:35,408: ============================================================
2022-07-07 07:05:35,408: Epoch 9/36 Batch 4000/7662 eta: 1 day, 19:20:16.074140	Training Loss1 8.2386 (8.4054)	Training Total_Loss 8.2386 (8.4054)	Training Prec@1 83.789 (82.622)	Training Prec@5 0.000 (0.000)	
2022-07-07 07:05:35,408: ============================================================
2022-07-07 07:06:49,545: time cost, forward:0.011871383666526868, backward:0.03376161775870508, data cost:0.692893383415131 
2022-07-07 07:06:49,545: ============================================================
2022-07-07 07:06:49,546: Epoch 9/36 Batch 4100/7662 eta: 1 day, 19:20:13.568849	Training Loss1 8.1635 (8.4061)	Training Total_Loss 8.1635 (8.4061)	Training Prec@1 83.008 (82.618)	Training Prec@5 0.000 (0.000)	
2022-07-07 07:06:49,546: ============================================================
2022-07-07 07:08:03,676: time cost, forward:0.0118767457168481, backward:0.03377616544597686, data cost:0.6929254072511386 
2022-07-07 07:08:03,676: ============================================================
2022-07-07 07:08:03,676: Epoch 9/36 Batch 4200/7662 eta: 1 day, 19:18:43.878475	Training Loss1 8.5374 (8.4066)	Training Total_Loss 8.5374 (8.4066)	Training Prec@1 80.859 (82.612)	Training Prec@5 0.000 (0.000)	
2022-07-07 07:08:03,676: ============================================================
2022-07-07 07:09:17,456: time cost, forward:0.011873209911824714, backward:0.03377467783475149, data cost:0.6929007346864688 
2022-07-07 07:09:17,456: ============================================================
2022-07-07 07:09:17,456: Epoch 9/36 Batch 4300/7662 eta: 1 day, 19:05:12.867061	Training Loss1 8.2363 (8.4069)	Training Total_Loss 8.2363 (8.4069)	Training Prec@1 84.961 (82.609)	Training Prec@5 0.000 (0.000)	
2022-07-07 07:09:17,456: ============================================================
2022-07-07 07:10:31,270: time cost, forward:0.011870506216813608, backward:0.03378362437762247, data cost:0.6928692250447968 
2022-07-07 07:10:31,271: ============================================================
2022-07-07 07:10:31,271: Epoch 9/36 Batch 4400/7662 eta: 1 day, 19:05:11.913238	Training Loss1 8.5020 (8.4068)	Training Total_Loss 8.5020 (8.4068)	Training Prec@1 83.008 (82.607)	Training Prec@5 0.000 (0.000)	
2022-07-07 07:10:31,271: ============================================================
2022-07-07 07:11:45,088: time cost, forward:0.01186397372947637, backward:0.03377159332322873, data cost:0.692866101480108 
2022-07-07 07:11:45,089: ============================================================
2022-07-07 07:11:45,089: Epoch 9/36 Batch 4500/7662 eta: 1 day, 19:04:05.210975	Training Loss1 8.5650 (8.4072)	Training Total_Loss 8.5650 (8.4072)	Training Prec@1 81.250 (82.597)	Training Prec@5 0.000 (0.000)	
2022-07-07 07:11:45,089: ============================================================
2022-07-07 07:12:59,448: time cost, forward:0.011890173995201939, backward:0.033765902543073115, data cost:0.6929421956240029 
2022-07-07 07:12:59,448: ============================================================
2022-07-07 07:12:59,448: Epoch 9/36 Batch 4600/7662 eta: 1 day, 19:21:47.554291	Training Loss1 8.6292 (8.4086)	Training Total_Loss 8.6292 (8.4086)	Training Prec@1 81.641 (82.588)	Training Prec@5 0.000 (0.000)	
2022-07-07 07:12:59,448: ============================================================
2022-07-07 07:14:14,323: time cost, forward:0.011906417488265377, backward:0.03376298753422203, data cost:0.6931335893076109 
2022-07-07 07:14:14,323: ============================================================
2022-07-07 07:14:14,323: Epoch 9/36 Batch 4700/7662 eta: 1 day, 19:38:36.056100	Training Loss1 8.3632 (8.4088)	Training Total_Loss 8.3632 (8.4088)	Training Prec@1 82.227 (82.590)	Training Prec@5 0.000 (0.000)	
2022-07-07 07:14:14,324: ============================================================
2022-07-07 07:15:27,428: time cost, forward:0.011906674763241717, backward:0.03375937521867539, data cost:0.6929624568027465 
2022-07-07 07:15:27,428: ============================================================
2022-07-07 07:15:27,428: Epoch 9/36 Batch 4800/7662 eta: 1 day, 18:35:28.107877	Training Loss1 8.7707 (8.4101)	Training Total_Loss 8.7707 (8.4101)	Training Prec@1 79.883 (82.581)	Training Prec@5 0.000 (0.000)	
2022-07-07 07:15:27,428: ============================================================
2022-07-07 07:16:41,972: time cost, forward:0.011908770240212148, backward:0.03376691150139682, data cost:0.6930816071839886 
2022-07-07 07:16:41,973: ============================================================
2022-07-07 07:16:41,973: Epoch 9/36 Batch 4900/7662 eta: 1 day, 19:24:32.487837	Training Loss1 8.1522 (8.4114)	Training Total_Loss 8.1522 (8.4114)	Training Prec@1 83.398 (82.569)	Training Prec@5 0.000 (0.000)	
2022-07-07 07:16:41,973: ============================================================
2022-07-07 07:17:54,618: time cost, forward:0.011905555463738622, backward:0.033771332513573026, data cost:0.6928220703306616 
2022-07-07 07:17:54,618: ============================================================
2022-07-07 07:17:54,618: Epoch 9/36 Batch 5000/7662 eta: 1 day, 18:16:59.319618	Training Loss1 8.6726 (8.4114)	Training Total_Loss 8.6726 (8.4114)	Training Prec@1 80.859 (82.570)	Training Prec@5 0.000 (0.000)	
2022-07-07 07:17:54,618: ============================================================
2022-07-07 07:19:07,658: time cost, forward:0.011912003337787538, backward:0.03376890481932768, data cost:0.6926445893667146 
2022-07-07 07:19:07,658: ============================================================
2022-07-07 07:19:07,659: Epoch 9/36 Batch 5100/7662 eta: 1 day, 18:29:33.357959	Training Loss1 8.3245 (8.4109)	Training Total_Loss 8.3245 (8.4109)	Training Prec@1 83.398 (82.568)	Training Prec@5 0.000 (0.000)	
2022-07-07 07:19:07,659: ============================================================
2022-07-07 07:20:21,764: time cost, forward:0.011925816421303343, backward:0.03376066677844119, data cost:0.6926811692530799 
2022-07-07 07:20:21,765: ============================================================
2022-07-07 07:20:21,765: Epoch 9/36 Batch 5200/7662 eta: 1 day, 19:05:31.810644	Training Loss1 8.2479 (8.4108)	Training Total_Loss 8.2479 (8.4108)	Training Prec@1 82.227 (82.566)	Training Prec@5 0.000 (0.000)	
2022-07-07 07:20:21,765: ============================================================
2022-07-07 07:21:36,326: time cost, forward:0.01193215833967374, backward:0.03377859123159431, data cost:0.6927826167907686 
2022-07-07 07:21:36,326: ============================================================
2022-07-07 07:21:36,327: Epoch 9/36 Batch 5300/7662 eta: 1 day, 19:20:10.940818	Training Loss1 8.3073 (8.4106)	Training Total_Loss 8.3073 (8.4106)	Training Prec@1 82.422 (82.564)	Training Prec@5 0.000 (0.000)	
2022-07-07 07:21:36,327: ============================================================
2022-07-07 07:22:49,640: time cost, forward:0.011942337565696732, backward:0.03377307412977196, data cost:0.6926676206046464 
2022-07-07 07:22:49,640: ============================================================
2022-07-07 07:22:49,641: Epoch 9/36 Batch 5400/7662 eta: 1 day, 18:35:26.522942	Training Loss1 8.4513 (8.4109)	Training Total_Loss 8.4513 (8.4109)	Training Prec@1 80.273 (82.561)	Training Prec@5 0.000 (0.000)	
2022-07-07 07:22:49,641: ============================================================
2022-07-07 07:24:04,216: time cost, forward:0.011940674123644374, backward:0.03376021725976656, data cost:0.6928014181206109 
2022-07-07 07:24:04,216: ============================================================
2022-07-07 07:24:04,216: Epoch 9/36 Batch 5500/7662 eta: 1 day, 19:18:10.857436	Training Loss1 8.6676 (8.4109)	Training Total_Loss 8.6676 (8.4109)	Training Prec@1 78.516 (82.558)	Training Prec@5 0.000 (0.000)	
2022-07-07 07:24:04,216: ============================================================
2022-07-07 07:25:17,775: time cost, forward:0.011931996576316358, backward:0.03376192837064661, data cost:0.692749974514293 
2022-07-07 07:25:17,776: ============================================================
2022-07-07 07:25:17,776: Epoch 9/36 Batch 5600/7662 eta: 1 day, 18:41:32.821682	Training Loss1 8.4103 (8.4106)	Training Total_Loss 8.4103 (8.4106)	Training Prec@1 82.227 (82.556)	Training Prec@5 0.000 (0.000)	
2022-07-07 07:25:17,776: ============================================================
2022-07-07 07:26:32,277: time cost, forward:0.01195780204710029, backward:0.03374660552688012, data cost:0.6928399973405958 
2022-07-07 07:26:32,278: ============================================================
2022-07-07 07:26:32,278: Epoch 9/36 Batch 5700/7662 eta: 1 day, 19:13:08.269716	Training Loss1 8.4179 (8.4107)	Training Total_Loss 8.4179 (8.4107)	Training Prec@1 82.617 (82.559)	Training Prec@5 0.000 (0.000)	
2022-07-07 07:26:32,278: ============================================================
2022-07-07 07:27:47,749: time cost, forward:0.011957049390368882, backward:0.03375008353325268, data cost:0.6931018244297181 
2022-07-07 07:27:47,749: ============================================================
2022-07-07 07:27:47,750: Epoch 9/36 Batch 5800/7662 eta: 1 day, 19:45:37.087121	Training Loss1 8.5285 (8.4105)	Training Total_Loss 8.5285 (8.4105)	Training Prec@1 81.836 (82.556)	Training Prec@5 0.000 (0.000)	
2022-07-07 07:27:47,750: ============================================================
2022-07-07 07:29:02,948: time cost, forward:0.01194846494700226, backward:0.03374195098876953, data cost:0.693340187740439 
2022-07-07 07:29:02,948: ============================================================
2022-07-07 07:29:02,948: Epoch 9/36 Batch 5900/7662 eta: 1 day, 19:34:52.658823	Training Loss1 8.5813 (8.4105)	Training Total_Loss 8.5813 (8.4105)	Training Prec@1 81.836 (82.554)	Training Prec@5 0.000 (0.000)	
2022-07-07 07:29:02,948: ============================================================
2022-07-07 07:30:18,365: time cost, forward:0.011939914251570106, backward:0.033731366419994864, data cost:0.6935677003773039 
2022-07-07 07:30:18,366: ============================================================
2022-07-07 07:30:18,366: Epoch 9/36 Batch 6000/7662 eta: 1 day, 19:41:13.651051	Training Loss1 8.5601 (8.4112)	Training Total_Loss 8.5601 (8.4112)	Training Prec@1 81.250 (82.546)	Training Prec@5 0.000 (0.000)	
2022-07-07 07:30:18,366: ============================================================
2022-07-07 07:31:31,840: time cost, forward:0.011939316934240628, backward:0.033719900886159115, data cost:0.6935302731169504 
2022-07-07 07:31:31,841: ============================================================
2022-07-07 07:31:31,841: Epoch 9/36 Batch 6100/7662 eta: 1 day, 18:32:29.209789	Training Loss1 8.2592 (8.4113)	Training Total_Loss 8.2592 (8.4113)	Training Prec@1 83.008 (82.547)	Training Prec@5 0.000 (0.000)	
2022-07-07 07:31:31,841: ============================================================
2022-07-07 07:32:45,983: time cost, forward:0.011936803463294171, backward:0.03371779355988962, data cost:0.6935596006073131 
2022-07-07 07:32:45,984: ============================================================
2022-07-07 07:32:45,984: Epoch 9/36 Batch 6200/7662 eta: 1 day, 18:54:26.520841	Training Loss1 8.3347 (8.4111)	Training Total_Loss 8.3347 (8.4111)	Training Prec@1 83.594 (82.546)	Training Prec@5 0.000 (0.000)	
2022-07-07 07:32:45,984: ============================================================
2022-07-07 07:34:00,498: time cost, forward:0.011939068903410543, backward:0.03370164844569261, data cost:0.6936603489897141 
2022-07-07 07:34:00,498: ============================================================
2022-07-07 07:34:00,498: Epoch 9/36 Batch 6300/7662 eta: 1 day, 19:06:06.738807	Training Loss1 7.9894 (8.4100)	Training Total_Loss 7.9894 (8.4100)	Training Prec@1 85.938 (82.551)	Training Prec@5 0.000 (0.000)	
2022-07-07 07:34:00,498: ============================================================
2022-07-07 07:35:15,613: time cost, forward:0.011955348974765325, backward:0.03369989028515751, data cost:0.6938161442737726 
2022-07-07 07:35:15,614: ============================================================
2022-07-07 07:35:15,614: Epoch 9/36 Batch 6400/7662 eta: 1 day, 19:25:43.413170	Training Loss1 8.6720 (8.4091)	Training Total_Loss 8.6720 (8.4091)	Training Prec@1 79.883 (82.555)	Training Prec@5 0.000 (0.000)	
2022-07-07 07:35:15,614: ============================================================
2022-07-07 07:36:30,527: time cost, forward:0.01195588136089822, backward:0.033691796142700216, data cost:0.6939625694194488 
2022-07-07 07:36:30,528: ============================================================
2022-07-07 07:36:30,528: Epoch 9/36 Batch 6500/7662 eta: 1 day, 19:17:29.059467	Training Loss1 8.2172 (8.4082)	Training Total_Loss 8.2172 (8.4082)	Training Prec@1 83.789 (82.560)	Training Prec@5 0.000 (0.000)	
2022-07-07 07:36:30,528: ============================================================
2022-07-07 07:37:46,355: time cost, forward:0.011950670688292135, backward:0.033691170577263, data cost:0.6942411944584009 
2022-07-07 07:37:46,355: ============================================================
2022-07-07 07:37:46,355: Epoch 9/36 Batch 6600/7662 eta: 1 day, 19:47:53.294542	Training Loss1 8.3107 (8.4077)	Training Total_Loss 8.3107 (8.4077)	Training Prec@1 82.227 (82.559)	Training Prec@5 0.000 (0.000)	
2022-07-07 07:37:46,356: ============================================================
2022-07-07 07:39:01,197: time cost, forward:0.011956320002570511, backward:0.033697141677804056, data cost:0.6943491729164608 
2022-07-07 07:39:01,197: ============================================================
2022-07-07 07:39:01,197: Epoch 9/36 Batch 6700/7662 eta: 1 day, 19:12:28.914153	Training Loss1 8.4766 (8.4071)	Training Total_Loss 8.4766 (8.4071)	Training Prec@1 83.203 (82.563)	Training Prec@5 0.000 (0.000)	
2022-07-07 07:39:01,197: ============================================================
2022-07-07 07:40:16,479: time cost, forward:0.011961192309041115, backward:0.033711010611290476, data cost:0.6945052941523329 
2022-07-07 07:40:16,497: ============================================================
2022-07-07 07:40:16,497: Epoch 9/36 Batch 6800/7662 eta: 1 day, 19:27:05.828165	Training Loss1 8.2329 (8.4067)	Training Total_Loss 8.2329 (8.4067)	Training Prec@1 83.594 (82.562)	Training Prec@5 0.000 (0.000)	
2022-07-07 07:40:16,497: ============================================================
2022-07-07 07:41:31,648: time cost, forward:0.011960423533545662, backward:0.03372009430506693, data cost:0.6946597320478124 
2022-07-07 07:41:31,648: ============================================================
2022-07-07 07:41:31,649: Epoch 9/36 Batch 6900/7662 eta: 1 day, 19:20:42.276958	Training Loss1 8.3467 (8.4061)	Training Total_Loss 8.3467 (8.4061)	Training Prec@1 81.641 (82.566)	Training Prec@5 0.000 (0.000)	
2022-07-07 07:41:31,649: ============================================================
2022-07-07 07:42:45,605: time cost, forward:0.01196023358125519, backward:0.03371036187259278, data cost:0.694651788533594 
2022-07-07 07:42:45,606: ============================================================
2022-07-07 07:42:45,606: Epoch 9/36 Batch 7000/7662 eta: 1 day, 18:38:08.729925	Training Loss1 8.4249 (8.4053)	Training Total_Loss 8.4249 (8.4053)	Training Prec@1 82.031 (82.568)	Training Prec@5 0.000 (0.000)	
2022-07-07 07:42:45,606: ============================================================
2022-07-07 07:44:00,601: time cost, forward:0.01196990457785467, backward:0.03370786606551795, data cost:0.6947729019971612 
2022-07-07 07:44:00,602: ============================================================
2022-07-07 07:44:00,602: Epoch 9/36 Batch 7100/7662 eta: 1 day, 19:12:49.159842	Training Loss1 8.1793 (8.4048)	Training Total_Loss 8.1793 (8.4048)	Training Prec@1 82.812 (82.572)	Training Prec@5 0.000 (0.000)	
2022-07-07 07:44:00,602: ============================================================
2022-07-07 07:45:16,334: time cost, forward:0.011971243687314547, backward:0.033710045456174245, data cost:0.694994987986422 
2022-07-07 07:45:16,334: ============================================================
2022-07-07 07:45:16,334: Epoch 9/36 Batch 7200/7662 eta: 1 day, 19:37:01.103657	Training Loss1 8.5949 (8.4038)	Training Total_Loss 8.5949 (8.4038)	Training Prec@1 82.422 (82.578)	Training Prec@5 0.000 (0.000)	
2022-07-07 07:45:16,334: ============================================================
2022-07-07 07:46:32,202: time cost, forward:0.011976724684213935, backward:0.033717514146009625, data cost:0.6952177216082603 
2022-07-07 07:46:32,202: ============================================================
2022-07-07 07:46:32,202: Epoch 9/36 Batch 7300/7662 eta: 1 day, 19:40:26.535601	Training Loss1 8.3158 (8.4037)	Training Total_Loss 8.3158 (8.4037)	Training Prec@1 81.836 (82.579)	Training Prec@5 0.000 (0.000)	
2022-07-07 07:46:32,202: ============================================================
2022-07-07 07:47:48,886: time cost, forward:0.011979063292873406, backward:0.03371447043606422, data cost:0.6955489821330263 
2022-07-07 07:47:48,887: ============================================================
2022-07-07 07:47:48,887: Epoch 9/36 Batch 7400/7662 eta: 1 day, 20:07:22.594483	Training Loss1 8.3730 (8.4040)	Training Total_Loss 8.3730 (8.4040)	Training Prec@1 83.008 (82.576)	Training Prec@5 0.000 (0.000)	
2022-07-07 07:47:48,887: ============================================================
2022-07-07 07:49:03,796: time cost, forward:0.011983502020850502, backward:0.033720492680782733, data cost:0.6956450280419572 
2022-07-07 07:49:03,797: ============================================================
2022-07-07 07:49:03,797: Epoch 9/36 Batch 7500/7662 eta: 1 day, 19:04:51.502273	Training Loss1 8.1084 (8.4035)	Training Total_Loss 8.1084 (8.4035)	Training Prec@1 85.742 (82.581)	Training Prec@5 0.000 (0.000)	
2022-07-07 07:49:03,797: ============================================================
2022-07-07 07:50:19,213: time cost, forward:0.01200083896256949, backward:0.03372892779352665, data cost:0.6957833658693526 
2022-07-07 07:50:19,213: ============================================================
2022-07-07 07:50:19,213: Epoch 9/36 Batch 7600/7662 eta: 1 day, 19:21:04.391173	Training Loss1 8.3462 (8.4029)	Training Total_Loss 8.3462 (8.4029)	Training Prec@1 82.422 (82.583)	Training Prec@5 0.000 (0.000)	
2022-07-07 07:50:19,213: ============================================================
2022-07-07 07:51:08,192: Epoch 9/36 Batch 7663/7662 eta: 1 day, 19:20:16.878854	Training Loss1 8.5855 (8.4030)	Training Total_Loss 8.5855 (8.4030)	Training Prec@1 81.641 (82.581)	Training Prec@5 0.000 (0.000)	
2022-07-07 07:51:08,193: ============================================================
2022-07-07 07:52:31,429: time cost, forward:0.010865062174170909, backward:0.03266070828293309, data cost:0.7887943537548335 
2022-07-07 07:52:31,430: ============================================================
2022-07-07 07:52:31,430: Epoch 10/36 Batch 100/7662 eta: 1 day, 23:39:37.118459	Training Loss1 7.2578 (7.2350)	Training Total_Loss 7.2578 (7.2350)	Training Prec@1 85.938 (87.591)	Training Prec@5 0.000 (0.000)	
2022-07-07 07:52:31,430: ============================================================
2022-07-07 07:53:46,277: time cost, forward:0.011017521422113007, backward:0.03252878380780244, data cost:0.746443978506117 
2022-07-07 07:53:46,277: ============================================================
2022-07-07 07:53:46,277: Epoch 10/36 Batch 200/7662 eta: 1 day, 18:58:10.822948	Training Loss1 6.5885 (7.0608)	Training Total_Loss 6.5885 (7.0608)	Training Prec@1 89.258 (88.302)	Training Prec@5 0.000 (0.000)	
2022-07-07 07:53:46,278: ============================================================
2022-07-07 07:55:01,683: time cost, forward:0.01098592225524494, backward:0.032709317861193396, data cost:0.7341068771770567 
2022-07-07 07:55:01,683: ============================================================
2022-07-07 07:55:01,683: Epoch 10/36 Batch 300/7662 eta: 1 day, 19:16:10.098448	Training Loss1 6.9830 (6.9600)	Training Total_Loss 6.9830 (6.9600)	Training Prec@1 89.258 (88.663)	Training Prec@5 0.000 (0.000)	
2022-07-07 07:55:01,683: ============================================================
2022-07-07 07:56:17,727: time cost, forward:0.010965576745513687, backward:0.0328151618030137, data cost:0.7295696568070796 
2022-07-07 07:56:17,727: ============================================================
2022-07-07 07:56:17,728: Epoch 10/36 Batch 400/7662 eta: 1 day, 19:36:52.289893	Training Loss1 6.2497 (6.8702)	Training Total_Loss 6.2497 (6.8702)	Training Prec@1 91.797 (88.988)	Training Prec@5 0.000 (0.000)	
2022-07-07 07:56:17,728: ============================================================
2022-07-07 07:57:33,913: time cost, forward:0.010887247288155412, backward:0.03297146384367245, data cost:0.7270499011557662 
2022-07-07 07:57:33,913: ============================================================
2022-07-07 07:57:33,913: Epoch 10/36 Batch 500/7662 eta: 1 day, 19:40:28.138859	Training Loss1 6.6766 (6.7954)	Training Total_Loss 6.6766 (6.7954)	Training Prec@1 90.039 (89.222)	Training Prec@5 0.000 (0.000)	
2022-07-07 07:57:33,913: ============================================================
2022-07-07 07:58:50,078: time cost, forward:0.01088740033577997, backward:0.03309593734040682, data cost:0.7252628066901969 
2022-07-07 07:58:50,078: ============================================================
2022-07-07 07:58:50,078: Epoch 10/36 Batch 600/7662 eta: 1 day, 19:38:28.836792	Training Loss1 6.5760 (6.7353)	Training Total_Loss 6.5760 (6.7353)	Training Prec@1 90.820 (89.442)	Training Prec@5 0.000 (0.000)	
2022-07-07 07:58:50,078: ============================================================
2022-07-07 08:00:05,650: time cost, forward:0.010913596132794164, backward:0.03313385843377939, data cost:0.7232234065283693 
2022-07-07 08:00:05,650: ============================================================
2022-07-07 08:00:05,650: Epoch 10/36 Batch 700/7662 eta: 1 day, 19:16:51.605788	Training Loss1 6.1114 (6.6785)	Training Total_Loss 6.1114 (6.6785)	Training Prec@1 91.797 (89.641)	Training Prec@5 0.000 (0.000)	
2022-07-07 08:00:05,650: ============================================================
2022-07-07 08:01:19,365: time cost, forward:0.011049015799511657, backward:0.03318143696599968, data cost:0.7191968402814806 
2022-07-07 08:01:19,365: ============================================================
2022-07-07 08:01:19,365: Epoch 10/36 Batch 800/7662 eta: 1 day, 18:11:47.834779	Training Loss1 6.2833 (6.6258)	Training Total_Loss 6.2833 (6.6258)	Training Prec@1 90.820 (89.818)	Training Prec@5 0.000 (0.000)	
2022-07-07 08:01:19,365: ============================================================
2022-07-07 08:02:33,466: time cost, forward:0.011167816113311801, backward:0.033101173343594796, data cost:0.7165970926953105 
2022-07-07 08:02:33,467: ============================================================
2022-07-07 08:02:33,467: Epoch 10/36 Batch 900/7662 eta: 1 day, 18:23:50.768495	Training Loss1 6.2473 (6.5771)	Training Total_Loss 6.2473 (6.5771)	Training Prec@1 89.844 (89.963)	Training Prec@5 0.000 (0.000)	
2022-07-07 08:02:33,467: ============================================================
2022-07-07 08:03:47,450: time cost, forward:0.011261926637636172, backward:0.03303746656851248, data cost:0.71438090388362 
2022-07-07 08:03:47,450: ============================================================
2022-07-07 08:03:47,451: Epoch 10/36 Batch 1000/7662 eta: 1 day, 18:18:33.842319	Training Loss1 6.4329 (6.5322)	Training Total_Loss 6.4329 (6.5322)	Training Prec@1 92.383 (90.130)	Training Prec@5 0.000 (0.000)	
2022-07-07 08:03:47,451: ============================================================
2022-07-07 08:05:01,854: time cost, forward:0.011367889183884431, backward:0.033078129449901635, data cost:0.7128523294224969 
2022-07-07 08:05:01,854: ============================================================
2022-07-07 08:05:01,854: Epoch 10/36 Batch 1100/7662 eta: 1 day, 18:31:44.399848	Training Loss1 5.9592 (6.4924)	Training Total_Loss 5.9592 (6.4924)	Training Prec@1 92.188 (90.270)	Training Prec@5 0.000 (0.000)	
2022-07-07 08:05:01,854: ============================================================
2022-07-07 08:06:16,485: time cost, forward:0.011467614702824456, backward:0.03309441567262677, data cost:0.7117545745887788 
2022-07-07 08:06:16,485: ============================================================
2022-07-07 08:06:16,485: Epoch 10/36 Batch 1200/7662 eta: 1 day, 18:38:17.461841	Training Loss1 5.9359 (6.4514)	Training Total_Loss 5.9359 (6.4514)	Training Prec@1 91.797 (90.415)	Training Prec@5 0.000 (0.000)	
2022-07-07 08:06:16,486: ============================================================
2022-07-07 08:07:30,462: time cost, forward:0.011530576989318518, backward:0.03312944723515441, data cost:0.7103285905120004 
2022-07-07 08:07:30,463: ============================================================
2022-07-07 08:07:30,463: Epoch 10/36 Batch 1300/7662 eta: 1 day, 18:14:39.108310	Training Loss1 5.4505 (6.4154)	Training Total_Loss 5.4505 (6.4154)	Training Prec@1 95.703 (90.523)	Training Prec@5 0.000 (0.000)	
2022-07-07 08:07:30,463: ============================================================
2022-07-07 08:08:45,401: time cost, forward:0.011680640179059435, backward:0.0330494992472258, data cost:0.7098236065238096 
2022-07-07 08:08:45,402: ============================================================
2022-07-07 08:08:45,402: Epoch 10/36 Batch 1400/7662 eta: 1 day, 18:46:20.662142	Training Loss1 5.9315 (6.3794)	Training Total_Loss 5.9315 (6.3794)	Training Prec@1 92.383 (90.635)	Training Prec@5 0.000 (0.000)	
2022-07-07 08:08:45,402: ============================================================
2022-07-07 08:10:01,369: time cost, forward:0.011744426360839682, backward:0.033026915538144, data cost:0.7100810183931622 
2022-07-07 08:10:01,369: ============================================================
2022-07-07 08:10:01,369: Epoch 10/36 Batch 1500/7662 eta: 1 day, 19:20:18.293218	Training Loss1 5.8725 (6.3444)	Training Total_Loss 5.8725 (6.3444)	Training Prec@1 89.844 (90.737)	Training Prec@5 0.000 (0.000)	
2022-07-07 08:10:01,369: ============================================================
2022-07-07 08:11:16,160: time cost, forward:0.011784555018880056, backward:0.033038434272560945, data cost:0.7095666219473928 
2022-07-07 08:11:16,160: ============================================================
2022-07-07 08:11:16,161: Epoch 10/36 Batch 1600/7662 eta: 1 day, 18:38:47.658154	Training Loss1 5.7129 (6.3129)	Training Total_Loss 5.7129 (6.3129)	Training Prec@1 94.141 (90.838)	Training Prec@5 0.000 (0.000)	
2022-07-07 08:11:16,161: ============================================================
2022-07-07 08:12:29,902: time cost, forward:0.011767001486021045, backward:0.033074246496926904, data cost:0.708515150256547 
2022-07-07 08:12:29,902: ============================================================
2022-07-07 08:12:29,902: Epoch 10/36 Batch 1700/7662 eta: 1 day, 18:01:39.699159	Training Loss1 6.0229 (6.2814)	Training Total_Loss 6.0229 (6.2814)	Training Prec@1 91.797 (90.929)	Training Prec@5 0.000 (0.000)	
2022-07-07 08:12:29,902: ============================================================
2022-07-07 08:13:45,180: time cost, forward:0.011753007661905337, backward:0.03307291386589996, data cost:0.7084540177080749 
2022-07-07 08:13:45,181: ============================================================
2022-07-07 08:13:45,181: Epoch 10/36 Batch 1800/7662 eta: 1 day, 18:52:57.772255	Training Loss1 5.9379 (6.2511)	Training Total_Loss 5.9379 (6.2511)	Training Prec@1 93.164 (91.032)	Training Prec@5 0.000 (0.000)	
2022-07-07 08:13:45,181: ============================================================
2022-07-07 08:15:00,097: time cost, forward:0.011755977071166478, backward:0.0330616548979138, data cost:0.7082235516843951 
2022-07-07 08:15:00,097: ============================================================
2022-07-07 08:15:00,098: Epoch 10/36 Batch 1900/7662 eta: 1 day, 18:39:20.505592	Training Loss1 5.6497 (6.2228)	Training Total_Loss 5.6497 (6.2228)	Training Prec@1 92.969 (91.123)	Training Prec@5 0.000 (0.000)	
2022-07-07 08:15:00,098: ============================================================
2022-07-07 08:16:14,409: time cost, forward:0.01181855805221947, backward:0.03307256333645491, data cost:0.7076245437209877 
2022-07-07 08:16:14,409: ============================================================
2022-07-07 08:16:14,409: Epoch 10/36 Batch 2000/7662 eta: 1 day, 18:17:25.791769	Training Loss1 5.6669 (6.1947)	Training Total_Loss 5.6669 (6.1947)	Training Prec@1 91.406 (91.201)	Training Prec@5 0.000 (0.000)	
2022-07-07 08:16:14,409: ============================================================
2022-07-07 08:17:28,565: time cost, forward:0.011878310526592951, backward:0.03305556286852265, data cost:0.7070300267843362 
2022-07-07 08:17:28,565: ============================================================
2022-07-07 08:17:28,565: Epoch 10/36 Batch 2100/7662 eta: 1 day, 18:10:52.850172	Training Loss1 5.4654 (6.1669)	Training Total_Loss 5.4654 (6.1669)	Training Prec@1 94.141 (91.284)	Training Prec@5 0.000 (0.000)	
2022-07-07 08:17:28,565: ============================================================
2022-07-07 08:18:42,296: time cost, forward:0.01185675760245746, backward:0.033069536543911614, data cost:0.7063449610900532 
2022-07-07 08:18:42,296: ============================================================
2022-07-07 08:18:42,297: Epoch 10/36 Batch 2200/7662 eta: 1 day, 17:55:09.790311	Training Loss1 5.6786 (6.1382)	Training Total_Loss 5.6786 (6.1382)	Training Prec@1 93.945 (91.377)	Training Prec@5 0.000 (0.000)	
2022-07-07 08:18:42,297: ============================================================
2022-07-07 08:19:56,635: time cost, forward:0.011894034530453809, backward:0.0330531836696789, data cost:0.7059536050744242 
2022-07-07 08:19:56,635: ============================================================
2022-07-07 08:19:56,635: Epoch 10/36 Batch 2300/7662 eta: 1 day, 18:14:38.607809	Training Loss1 5.8240 (6.1118)	Training Total_Loss 5.8240 (6.1118)	Training Prec@1 92.578 (91.456)	Training Prec@5 0.000 (0.000)	
2022-07-07 08:19:56,636: ============================================================
2022-07-07 08:21:10,862: time cost, forward:0.011899035490766671, backward:0.033028547244054074, data cost:0.7055737762562481 
2022-07-07 08:21:10,862: ============================================================
2022-07-07 08:21:10,863: Epoch 10/36 Batch 2400/7662 eta: 1 day, 18:09:36.040939	Training Loss1 5.3258 (6.0848)	Training Total_Loss 5.3258 (6.0848)	Training Prec@1 94.531 (91.540)	Training Prec@5 0.000 (0.000)	
2022-07-07 08:21:10,863: ============================================================
2022-07-07 08:22:25,606: time cost, forward:0.011905475634009708, backward:0.032980381846189406, data cost:0.7054815105363434 
2022-07-07 08:22:25,606: ============================================================
2022-07-07 08:22:25,607: Epoch 10/36 Batch 2500/7662 eta: 1 day, 18:25:57.857443	Training Loss1 5.6238 (6.0608)	Training Total_Loss 5.6238 (6.0608)	Training Prec@1 92.383 (91.613)	Training Prec@5 0.000 (0.000)	
2022-07-07 08:22:25,607: ============================================================
2022-07-07 08:23:40,616: time cost, forward:0.011934185083117013, backward:0.032957816591809554, data cost:0.705442749476974 
2022-07-07 08:23:40,616: ============================================================
2022-07-07 08:23:40,617: Epoch 10/36 Batch 2600/7662 eta: 1 day, 18:33:46.753944	Training Loss1 5.4637 (6.0382)	Training Total_Loss 5.4637 (6.0382)	Training Prec@1 94.141 (91.678)	Training Prec@5 0.000 (0.000)	
2022-07-07 08:23:40,617: ============================================================
2022-07-07 08:24:55,722: time cost, forward:0.01195436135271206, backward:0.032969589629143245, data cost:0.7054021933556663 
2022-07-07 08:24:55,723: ============================================================
2022-07-07 08:24:55,723: Epoch 10/36 Batch 2700/7662 eta: 1 day, 18:35:48.122752	Training Loss1 5.3449 (6.0150)	Training Total_Loss 5.3449 (6.0150)	Training Prec@1 93.750 (91.750)	Training Prec@5 0.000 (0.000)	
2022-07-07 08:24:55,723: ============================================================
2022-07-07 08:26:11,426: time cost, forward:0.01195518737948337, backward:0.032985612808614596, data cost:0.7055976962395846 
2022-07-07 08:26:11,426: ============================================================
2022-07-07 08:26:11,427: Epoch 10/36 Batch 2800/7662 eta: 1 day, 18:54:52.578430	Training Loss1 5.4927 (5.9926)	Training Total_Loss 5.4927 (5.9926)	Training Prec@1 92.773 (91.814)	Training Prec@5 0.000 (0.000)	
2022-07-07 08:26:11,427: ============================================================
2022-07-07 08:27:25,876: time cost, forward:0.011956821354803195, backward:0.03299731548673821, data cost:0.7053604417934464 
2022-07-07 08:27:25,877: ============================================================
2022-07-07 08:27:25,877: Epoch 10/36 Batch 2900/7662 eta: 1 day, 18:11:00.050930	Training Loss1 5.3787 (5.9705)	Training Total_Loss 5.3787 (5.9705)	Training Prec@1 93.555 (91.883)	Training Prec@5 0.000 (0.000)	
2022-07-07 08:27:25,877: ============================================================
2022-07-07 08:28:39,632: time cost, forward:0.011972604572236359, backward:0.0330193625485432, data cost:0.7048281198662494 
2022-07-07 08:28:39,633: ============================================================
2022-07-07 08:28:39,633: Epoch 10/36 Batch 3000/7662 eta: 1 day, 17:46:10.370756	Training Loss1 5.2523 (5.9485)	Training Total_Loss 5.2523 (5.9485)	Training Prec@1 94.727 (91.945)	Training Prec@5 0.000 (0.000)	
2022-07-07 08:28:39,633: ============================================================
2022-07-07 08:29:53,787: time cost, forward:0.011996383319250343, backward:0.033018238431371076, data cost:0.7045714015074414 
2022-07-07 08:29:53,787: ============================================================
2022-07-07 08:29:53,788: Epoch 10/36 Batch 3100/7662 eta: 1 day, 17:58:28.377573	Training Loss1 5.3569 (5.9280)	Training Total_Loss 5.3569 (5.9280)	Training Prec@1 92.578 (92.004)	Training Prec@5 0.000 (0.000)	
2022-07-07 08:29:53,788: ============================================================
2022-07-07 08:31:07,493: time cost, forward:0.012014718680278924, backward:0.03301538613186139, data cost:0.7041398730640227 
2022-07-07 08:31:07,493: ============================================================
2022-07-07 08:31:07,494: Epoch 10/36 Batch 3200/7662 eta: 1 day, 17:42:00.350907	Training Loss1 5.2182 (5.9080)	Training Total_Loss 5.2182 (5.9080)	Training Prec@1 96.094 (92.063)	Training Prec@5 0.000 (0.000)	
2022-07-07 08:31:07,494: ============================================================
2022-07-07 08:32:22,460: time cost, forward:0.011988160320396459, backward:0.03301992182227184, data cost:0.7041471751757411 
2022-07-07 08:32:22,461: ============================================================
2022-07-07 08:32:22,461: Epoch 10/36 Batch 3300/7662 eta: 1 day, 18:23:34.641050	Training Loss1 5.3117 (5.8888)	Training Total_Loss 5.3117 (5.8888)	Training Prec@1 94.727 (92.121)	Training Prec@5 0.000 (0.000)	
2022-07-07 08:32:22,461: ============================================================
2022-07-07 08:33:36,942: time cost, forward:0.011987133705114469, backward:0.033013305652839504, data cost:0.7040194159712851 
2022-07-07 08:33:36,942: ============================================================
2022-07-07 08:33:36,943: Epoch 10/36 Batch 3400/7662 eta: 1 day, 18:05:51.792259	Training Loss1 5.0996 (5.8696)	Training Total_Loss 5.0996 (5.8696)	Training Prec@1 93.555 (92.181)	Training Prec@5 0.000 (0.000)	
2022-07-07 08:33:36,943: ============================================================
2022-07-07 08:34:52,527: time cost, forward:0.011985268992129377, backward:0.032976836196079565, data cost:0.7042426989398094 
2022-07-07 08:34:52,527: ============================================================
2022-07-07 08:34:52,527: Epoch 10/36 Batch 3500/7662 eta: 1 day, 18:42:00.234015	Training Loss1 5.0372 (5.8504)	Training Total_Loss 5.0372 (5.8504)	Training Prec@1 94.922 (92.239)	Training Prec@5 0.000 (0.000)	
2022-07-07 08:34:52,527: ============================================================
2022-07-07 08:36:06,602: time cost, forward:0.012001179496127057, backward:0.032968042823598595, data cost:0.7039747318979037 
2022-07-07 08:36:06,602: ============================================================
2022-07-07 08:36:06,602: Epoch 10/36 Batch 3600/7662 eta: 1 day, 17:49:35.746495	Training Loss1 5.1878 (5.8326)	Training Total_Loss 5.1878 (5.8326)	Training Prec@1 93.164 (92.289)	Training Prec@5 0.000 (0.000)	
2022-07-07 08:36:06,602: ============================================================
2022-07-07 08:37:21,198: time cost, forward:0.012019800024762222, backward:0.03293595477741259, data cost:0.7038936496393267 
2022-07-07 08:37:21,199: ============================================================
2022-07-07 08:37:21,199: Epoch 10/36 Batch 3700/7662 eta: 1 day, 18:06:02.293691	Training Loss1 5.0295 (5.8142)	Training Total_Loss 5.0295 (5.8142)	Training Prec@1 95.312 (92.344)	Training Prec@5 0.000 (0.000)	
2022-07-07 08:37:21,199: ============================================================
2022-07-07 08:38:35,736: time cost, forward:0.012057521400341206, backward:0.032906238076937266, data cost:0.7037778741656306 
2022-07-07 08:38:35,736: ============================================================
2022-07-07 08:38:35,736: Epoch 10/36 Batch 3800/7662 eta: 1 day, 18:02:46.237284	Training Loss1 5.2511 (5.7960)	Training Total_Loss 5.2511 (5.7960)	Training Prec@1 93.164 (92.395)	Training Prec@5 0.000 (0.000)	
2022-07-07 08:38:35,736: ============================================================
2022-07-07 08:39:50,133: time cost, forward:0.012069334889656766, backward:0.03288267532597141, data cost:0.7036520899121778 
2022-07-07 08:39:50,134: ============================================================
2022-07-07 08:39:50,134: Epoch 10/36 Batch 3900/7662 eta: 1 day, 17:56:49.252913	Training Loss1 4.8742 (5.7792)	Training Total_Loss 4.8742 (5.7792)	Training Prec@1 95.703 (92.443)	Training Prec@5 0.000 (0.000)	
2022-07-07 08:39:50,134: ============================================================
2022-07-07 08:41:05,572: time cost, forward:0.012103016241158983, backward:0.03288666162827099, data cost:0.7037412336868892 
2022-07-07 08:41:05,572: ============================================================
2022-07-07 08:41:05,572: Epoch 10/36 Batch 4000/7662 eta: 1 day, 18:30:45.375938	Training Loss1 5.0587 (5.7632)	Training Total_Loss 5.0587 (5.7632)	Training Prec@1 94.531 (92.492)	Training Prec@5 0.000 (0.000)	
2022-07-07 08:41:05,572: ============================================================
2022-07-07 08:42:20,290: time cost, forward:0.012087642579405563, backward:0.03286788812001236, data cost:0.7037122598593629 
2022-07-07 08:42:20,291: ============================================================
2022-07-07 08:42:20,291: Epoch 10/36 Batch 4100/7662 eta: 1 day, 18:05:10.242371	Training Loss1 4.8688 (5.7464)	Training Total_Loss 4.8688 (5.7464)	Training Prec@1 93.164 (92.538)	Training Prec@5 0.000 (0.000)	
2022-07-07 08:42:20,291: ============================================================
2022-07-07 08:43:34,003: time cost, forward:0.012063794716337404, backward:0.03288135621683403, data cost:0.7034390750002878 
2022-07-07 08:43:34,004: ============================================================
2022-07-07 08:43:34,004: Epoch 10/36 Batch 4200/7662 eta: 1 day, 17:29:58.321548	Training Loss1 5.1149 (5.7309)	Training Total_Loss 5.1149 (5.7309)	Training Prec@1 93.945 (92.583)	Training Prec@5 0.000 (0.000)	
2022-07-07 08:43:34,004: ============================================================
2022-07-07 08:44:47,146: time cost, forward:0.012051817871132794, backward:0.032869417574772256, data cost:0.7030611658240508 
2022-07-07 08:44:47,146: ============================================================
2022-07-07 08:44:47,146: Epoch 10/36 Batch 4300/7662 eta: 1 day, 17:09:28.354019	Training Loss1 4.7295 (5.7157)	Training Total_Loss 4.7295 (5.7157)	Training Prec@1 95.117 (92.626)	Training Prec@5 0.000 (0.000)	
2022-07-07 08:44:47,147: ============================================================
2022-07-07 08:46:02,190: time cost, forward:0.012041213919450327, backward:0.03284138900416904, data cost:0.7031394923700748 
2022-07-07 08:46:02,190: ============================================================
2022-07-07 08:46:02,190: Epoch 10/36 Batch 4400/7662 eta: 1 day, 18:12:24.620504	Training Loss1 5.0230 (5.7018)	Training Total_Loss 5.0230 (5.7018)	Training Prec@1 94.336 (92.666)	Training Prec@5 0.000 (0.000)	
2022-07-07 08:46:02,190: ============================================================
2022-07-07 08:47:17,516: time cost, forward:0.01203569286954379, backward:0.032822495912228404, data cost:0.7032715467167685 
2022-07-07 08:47:17,516: ============================================================
2022-07-07 08:47:17,516: Epoch 10/36 Batch 4500/7662 eta: 1 day, 18:20:41.330200	Training Loss1 4.9252 (5.6873)	Training Total_Loss 4.9252 (5.6873)	Training Prec@1 95.312 (92.707)	Training Prec@5 0.000 (0.000)	
2022-07-07 08:47:17,517: ============================================================
2022-07-07 08:48:31,565: time cost, forward:0.012020316635118565, backward:0.03281626107252585, data cost:0.703115396588801 
2022-07-07 08:48:31,565: ============================================================
2022-07-07 08:48:31,565: Epoch 10/36 Batch 4600/7662 eta: 1 day, 17:36:22.834229	Training Loss1 5.1683 (5.6730)	Training Total_Loss 5.1683 (5.6730)	Training Prec@1 93.945 (92.749)	Training Prec@5 0.000 (0.000)	
2022-07-07 08:48:31,566: ============================================================
2022-07-07 08:49:46,059: time cost, forward:0.012025940542551882, backward:0.03280215959494153, data cost:0.7030437023088155 
2022-07-07 08:49:46,059: ============================================================
2022-07-07 08:49:46,059: Epoch 10/36 Batch 4700/7662 eta: 1 day, 17:50:07.924834	Training Loss1 4.9084 (5.6583)	Training Total_Loss 4.9084 (5.6583)	Training Prec@1 95.117 (92.793)	Training Prec@5 0.000 (0.000)	
2022-07-07 08:49:46,059: ============================================================
2022-07-07 08:51:02,706: time cost, forward:0.012019133364118419, backward:0.032819908046305094, data cost:0.7034099803017586 
2022-07-07 08:51:02,706: ============================================================
2022-07-07 08:51:02,707: Epoch 10/36 Batch 4800/7662 eta: 1 day, 19:01:25.103753	Training Loss1 4.8497 (5.6447)	Training Total_Loss 4.8497 (5.6447)	Training Prec@1 94.922 (92.834)	Training Prec@5 0.000 (0.000)	
2022-07-07 08:51:02,707: ============================================================
2022-07-07 08:52:18,267: time cost, forward:0.01201433706195969, backward:0.03282549698076873, data cost:0.7035465325645389 
2022-07-07 08:52:18,267: ============================================================
2022-07-07 08:52:18,268: Epoch 10/36 Batch 4900/7662 eta: 1 day, 18:23:34.187914	Training Loss1 5.0074 (5.6311)	Training Total_Loss 5.0074 (5.6311)	Training Prec@1 94.727 (92.871)	Training Prec@5 0.000 (0.000)	
2022-07-07 08:52:18,268: ============================================================
2022-07-07 08:53:34,874: time cost, forward:0.012014982771410849, backward:0.032833986221301265, data cost:0.7038797918713839 
2022-07-07 08:53:34,875: ============================================================
2022-07-07 08:53:34,875: Epoch 10/36 Batch 5000/7662 eta: 1 day, 18:57:30.852677	Training Loss1 4.9823 (5.6184)	Training Total_Loss 4.9823 (5.6184)	Training Prec@1 94.727 (92.909)	Training Prec@5 0.000 (0.000)	
2022-07-07 08:53:34,875: ============================================================
2022-07-07 08:54:49,653: time cost, forward:0.012006709378802279, backward:0.03284416294116604, data cost:0.7038473600405154 
2022-07-07 08:54:49,653: ============================================================
2022-07-07 08:54:49,654: Epoch 10/36 Batch 5100/7662 eta: 1 day, 17:54:44.755828	Training Loss1 4.9273 (5.6059)	Training Total_Loss 4.9273 (5.6059)	Training Prec@1 95.117 (92.945)	Training Prec@5 0.000 (0.000)	
2022-07-07 08:54:49,654: ============================================================
2022-07-07 08:56:03,429: time cost, forward:0.011994793819083367, backward:0.03285146562107069, data cost:0.7036298015159377 
2022-07-07 08:56:03,429: ============================================================
2022-07-07 08:56:03,430: Epoch 10/36 Batch 5200/7662 eta: 1 day, 17:19:48.010099	Training Loss1 4.8051 (5.5929)	Training Total_Loss 4.8051 (5.5929)	Training Prec@1 95.117 (92.982)	Training Prec@5 0.000 (0.000)	
2022-07-07 08:56:03,430: ============================================================
2022-07-07 08:57:18,149: time cost, forward:0.011982337779246495, backward:0.03286894925879316, data cost:0.7035903915366399 
2022-07-07 08:57:18,150: ============================================================
2022-07-07 08:57:18,150: Epoch 10/36 Batch 5300/7662 eta: 1 day, 17:50:16.945307	Training Loss1 4.9451 (5.5805)	Training Total_Loss 4.9451 (5.5805)	Training Prec@1 93.945 (93.018)	Training Prec@5 0.000 (0.000)	
2022-07-07 08:57:18,150: ============================================================
2022-07-07 08:58:33,009: time cost, forward:0.011976335684134577, backward:0.03289398464323702, data cost:0.7035624371080139 
2022-07-07 08:58:33,010: ============================================================
2022-07-07 08:58:33,010: Epoch 10/36 Batch 5400/7662 eta: 1 day, 17:53:44.344266	Training Loss1 5.0314 (5.5687)	Training Total_Loss 5.0314 (5.5687)	Training Prec@1 95.508 (93.054)	Training Prec@5 0.000 (0.000)	
2022-07-07 08:58:33,010: ============================================================
2022-07-07 08:59:48,678: time cost, forward:0.011964667990199435, backward:0.0329181652412477, data cost:0.7036876847991554 
2022-07-07 08:59:48,679: ============================================================
2022-07-07 08:59:48,679: Epoch 10/36 Batch 5500/7662 eta: 1 day, 18:19:38.423123	Training Loss1 5.0816 (5.5571)	Training Total_Loss 5.0816 (5.5571)	Training Prec@1 95.508 (93.085)	Training Prec@5 0.000 (0.000)	
2022-07-07 08:59:48,679: ============================================================
2022-07-07 09:01:03,629: time cost, forward:0.01196899233513335, backward:0.03293369403586342, data cost:0.7036746737573334 
2022-07-07 09:01:03,629: ============================================================
2022-07-07 09:01:03,630: Epoch 10/36 Batch 5600/7662 eta: 1 day, 17:54:17.069503	Training Loss1 4.8880 (5.5457)	Training Total_Loss 4.8880 (5.5457)	Training Prec@1 95.508 (93.117)	Training Prec@5 0.000 (0.000)	
2022-07-07 09:01:03,630: ============================================================
2022-07-07 09:02:19,666: time cost, forward:0.011956223062641434, backward:0.03294398571696485, data cost:0.7038726758948542 
2022-07-07 09:02:19,666: ============================================================
2022-07-07 09:02:19,667: Epoch 10/36 Batch 5700/7662 eta: 1 day, 18:29:27.476839	Training Loss1 4.7856 (5.5346)	Training Total_Loss 4.7856 (5.5346)	Training Prec@1 93.750 (93.148)	Training Prec@5 0.000 (0.000)	
2022-07-07 09:02:19,667: ============================================================
2022-07-07 09:03:35,592: time cost, forward:0.011959466138242092, backward:0.0329495612702137, data cost:0.7040334558215587 
2022-07-07 09:03:35,592: ============================================================
2022-07-07 09:03:35,593: Epoch 10/36 Batch 5800/7662 eta: 1 day, 18:24:28.446355	Training Loss1 4.9429 (5.5237)	Training Total_Loss 4.9429 (5.5237)	Training Prec@1 95.508 (93.180)	Training Prec@5 0.000 (0.000)	
2022-07-07 09:03:35,593: ============================================================
2022-07-07 09:04:50,503: time cost, forward:0.011942490457902421, backward:0.03296722357789224, data cost:0.7040270892497462 
2022-07-07 09:04:50,504: ============================================================
2022-07-07 09:04:50,504: Epoch 10/36 Batch 5900/7662 eta: 1 day, 17:49:12.779981	Training Loss1 5.0006 (5.5136)	Training Total_Loss 5.0006 (5.5136)	Training Prec@1 94.727 (93.210)	Training Prec@5 0.000 (0.000)	
2022-07-07 09:04:50,504: ============================================================
2022-07-07 09:06:05,264: time cost, forward:0.011937575651061676, backward:0.032982198451634026, data cost:0.7039854994295517 
2022-07-07 09:06:05,264: ============================================================
2022-07-07 09:06:05,264: Epoch 10/36 Batch 6000/7662 eta: 1 day, 17:42:54.547966	Training Loss1 4.9130 (5.5030)	Training Total_Loss 4.9130 (5.5030)	Training Prec@1 93.359 (93.242)	Training Prec@5 0.000 (0.000)	
2022-07-07 09:06:05,264: ============================================================
2022-07-07 09:07:19,859: time cost, forward:0.011938264045896716, backward:0.033001467759031844, data cost:0.703905819400175 
2022-07-07 09:07:19,859: ============================================================
2022-07-07 09:07:19,859: Epoch 10/36 Batch 6100/7662 eta: 1 day, 17:36:08.351607	Training Loss1 4.8210 (5.4925)	Training Total_Loss 4.8210 (5.4925)	Training Prec@1 94.141 (93.272)	Training Prec@5 0.000 (0.000)	
2022-07-07 09:07:19,859: ============================================================
2022-07-07 09:08:36,462: time cost, forward:0.011926198355669666, backward:0.03300498981478907, data cost:0.7041789706166011 
2022-07-07 09:08:36,463: ============================================================
2022-07-07 09:08:36,463: Epoch 10/36 Batch 6200/7662 eta: 1 day, 18:42:04.521707	Training Loss1 4.7364 (5.4831)	Training Total_Loss 4.7364 (5.4831)	Training Prec@1 95.117 (93.298)	Training Prec@5 0.000 (0.000)	
2022-07-07 09:08:36,463: ============================================================
2022-07-07 09:09:51,897: time cost, forward:0.011921215746247176, backward:0.033013143696885655, data cost:0.7042381750967677 
2022-07-07 09:09:51,897: ============================================================
2022-07-07 09:09:51,897: Epoch 10/36 Batch 6300/7662 eta: 1 day, 18:01:42.357637	Training Loss1 4.8083 (5.4736)	Training Total_Loss 4.8083 (5.4736)	Training Prec@1 95.117 (93.327)	Training Prec@5 0.000 (0.000)	
2022-07-07 09:09:51,897: ============================================================
2022-07-07 09:11:07,221: time cost, forward:0.011906329794477012, backward:0.03301007640717607, data cost:0.7043193085228284 
2022-07-07 09:11:07,221: ============================================================
2022-07-07 09:11:07,221: Epoch 10/36 Batch 6400/7662 eta: 1 day, 17:56:45.891048	Training Loss1 5.0541 (5.4642)	Training Total_Loss 5.0541 (5.4642)	Training Prec@1 93.164 (93.354)	Training Prec@5 0.000 (0.000)	
2022-07-07 09:11:07,221: ============================================================
2022-07-07 09:12:22,333: time cost, forward:0.01190164592160062, backward:0.033006376515059936, data cost:0.7043483219507713 
2022-07-07 09:12:22,334: ============================================================
2022-07-07 09:12:22,334: Epoch 10/36 Batch 6500/7662 eta: 1 day, 17:48:27.416085	Training Loss1 4.8274 (5.4548)	Training Total_Loss 4.8274 (5.4548)	Training Prec@1 96.680 (93.381)	Training Prec@5 0.000 (0.000)	
2022-07-07 09:12:22,334: ============================================================
2022-07-07 09:13:37,382: time cost, forward:0.011899350538165628, backward:0.033014046276929, data cost:0.7043380104677119 
2022-07-07 09:13:37,383: ============================================================
2022-07-07 09:13:37,383: Epoch 10/36 Batch 6600/7662 eta: 1 day, 17:45:03.977021	Training Loss1 4.8583 (5.4453)	Training Total_Loss 4.8583 (5.4453)	Training Prec@1 96.094 (93.409)	Training Prec@5 0.000 (0.000)	
2022-07-07 09:13:37,383: ============================================================
2022-07-07 09:14:52,738: time cost, forward:0.011895404073405148, backward:0.03301377480804858, data cost:0.7044102138397427 
2022-07-07 09:14:52,738: ============================================================
2022-07-07 09:14:52,738: Epoch 10/36 Batch 6700/7662 eta: 1 day, 17:54:02.569034	Training Loss1 4.7940 (5.4365)	Training Total_Loss 4.7940 (5.4365)	Training Prec@1 94.336 (93.434)	Training Prec@5 0.000 (0.000)	
2022-07-07 09:14:52,738: ============================================================
2022-07-07 09:16:07,367: time cost, forward:0.01188584400776783, backward:0.03301662717747117, data cost:0.7043654767533123 
2022-07-07 09:16:07,368: ============================================================
2022-07-07 09:16:07,368: Epoch 10/36 Batch 6800/7662 eta: 1 day, 17:28:35.300613	Training Loss1 4.7325 (5.4277)	Training Total_Loss 4.7325 (5.4277)	Training Prec@1 94.922 (93.461)	Training Prec@5 0.000 (0.000)	
2022-07-07 09:16:07,368: ============================================================
2022-07-07 09:17:21,840: time cost, forward:0.011871187043096695, backward:0.033019663648581846, data cost:0.7042868803991651 
2022-07-07 09:17:21,841: ============================================================
2022-07-07 09:17:21,841: Epoch 10/36 Batch 6900/7662 eta: 1 day, 17:22:06.899350	Training Loss1 4.8720 (5.4195)	Training Total_Loss 4.8720 (5.4195)	Training Prec@1 94.336 (93.484)	Training Prec@5 0.000 (0.000)	
2022-07-07 09:17:21,841: ============================================================
2022-07-07 09:18:38,149: time cost, forward:0.011868837101491184, backward:0.033022301761503475, data cost:0.7044741103505727 
2022-07-07 09:18:38,149: ============================================================
2022-07-07 09:18:38,149: Epoch 10/36 Batch 7000/7662 eta: 1 day, 18:22:01.887058	Training Loss1 4.7067 (5.4117)	Training Total_Loss 4.7067 (5.4117)	Training Prec@1 95.898 (93.505)	Training Prec@5 0.000 (0.000)	
2022-07-07 09:18:38,150: ============================================================
2022-07-07 09:19:53,017: time cost, forward:0.011864500459541249, backward:0.03302786766366063, data cost:0.7044702292932794 
2022-07-07 09:19:53,017: ============================================================
2022-07-07 09:19:53,017: Epoch 10/36 Batch 7100/7662 eta: 1 day, 17:32:47.164115	Training Loss1 4.9231 (5.4039)	Training Total_Loss 4.9231 (5.4039)	Training Prec@1 94.336 (93.525)	Training Prec@5 0.000 (0.000)	
2022-07-07 09:19:53,017: ============================================================
2022-07-07 09:21:09,064: time cost, forward:0.011857917564149398, backward:0.03303612929480757, data cost:0.7046150984342172 
2022-07-07 09:21:09,065: ============================================================
2022-07-07 09:21:09,065: Epoch 10/36 Batch 7200/7662 eta: 1 day, 18:10:48.135814	Training Loss1 5.2533 (5.3964)	Training Total_Loss 5.2533 (5.3964)	Training Prec@1 94.336 (93.546)	Training Prec@5 0.000 (0.000)	
2022-07-07 09:21:09,065: ============================================================
2022-07-07 09:22:24,405: time cost, forward:0.011849582056457628, backward:0.03304252648683489, data cost:0.7046607371992829 
2022-07-07 09:22:24,406: ============================================================
2022-07-07 09:22:24,406: Epoch 10/36 Batch 7300/7662 eta: 1 day, 17:46:02.015506	Training Loss1 4.9694 (5.3888)	Training Total_Loss 4.9694 (5.3888)	Training Prec@1 94.727 (93.569)	Training Prec@5 0.000 (0.000)	
2022-07-07 09:22:24,406: ============================================================
2022-07-07 09:23:41,800: time cost, forward:0.011847935909998709, backward:0.03305512129382389, data cost:0.704969627983845 
2022-07-07 09:23:41,800: ============================================================
2022-07-07 09:23:41,801: Epoch 10/36 Batch 7400/7662 eta: 1 day, 18:53:02.779258	Training Loss1 5.1963 (5.3811)	Training Total_Loss 5.1963 (5.3811)	Training Prec@1 93.164 (93.592)	Training Prec@5 0.000 (0.000)	
2022-07-07 09:23:41,801: ============================================================
2022-07-07 09:24:56,759: time cost, forward:0.011847555454547666, backward:0.033076226894085146, data cost:0.7049349839726453 
2022-07-07 09:24:56,760: ============================================================
2022-07-07 09:24:56,760: Epoch 10/36 Batch 7500/7662 eta: 1 day, 17:30:50.614029	Training Loss1 4.5138 (5.3737)	Training Total_Loss 4.5138 (5.3737)	Training Prec@1 95.898 (93.613)	Training Prec@5 0.000 (0.000)	
2022-07-07 09:24:56,760: ============================================================
2022-07-07 09:26:13,536: time cost, forward:0.011860832977897322, backward:0.03307456903699857, data cost:0.7051493377022907 
2022-07-07 09:26:13,537: ============================================================
2022-07-07 09:26:13,537: Epoch 10/36 Batch 7600/7662 eta: 1 day, 18:29:57.135748	Training Loss1 4.6789 (5.3663)	Training Total_Loss 4.6789 (5.3663)	Training Prec@1 95.508 (93.635)	Training Prec@5 0.000 (0.000)	
2022-07-07 09:26:13,537: ============================================================
2022-07-07 09:27:02,192: Epoch 10/36 Batch 7663/7662 eta: 1 day, 18:29:08.766311	Training Loss1 4.6592 (5.3618)	Training Total_Loss 4.6592 (5.3618)	Training Prec@1 95.312 (93.649)	Training Prec@5 0.000 (0.000)	
2022-07-07 09:27:02,193: ============================================================
2022-07-07 09:27:02,336: Save Checkpoint...
2022-07-07 09:27:02,344: ============================================================
2022-07-07 09:27:05,478: Save done!
2022-07-07 09:27:05,478: ============================================================
2022-07-07 09:28:44,538: time cost, forward:0.010908839678523517, backward:0.03200073194022131, data cost:0.9516695244143708 
2022-07-07 09:28:44,538: ============================================================
2022-07-07 09:28:44,538: Epoch 11/36 Batch 100/7662 eta: 2 days, 6:45:31.704349	Training Loss1 4.4295 (4.3190)	Training Total_Loss 4.4295 (4.3190)	Training Prec@1 96.484 (96.871)	Training Prec@5 0.000 (0.000)	
2022-07-07 09:28:44,539: ============================================================
2022-07-07 09:30:00,590: time cost, forward:0.010769793735676674, backward:0.03235303936292179, data cost:0.8334929811295553 
2022-07-07 09:30:00,591: ============================================================
2022-07-07 09:30:00,591: Epoch 11/36 Batch 200/7662 eta: 1 day, 18:02:34.769426	Training Loss1 4.4939 (4.3327)	Training Total_Loss 4.4939 (4.3327)	Training Prec@1 96.094 (96.869)	Training Prec@5 0.000 (0.000)	
2022-07-07 09:30:00,591: ============================================================
2022-07-07 09:31:16,346: time cost, forward:0.010736554761395407, backward:0.03254245356173818, data cost:0.7933419556123357 
2022-07-07 09:31:16,347: ============================================================
2022-07-07 09:31:16,347: Epoch 11/36 Batch 300/7662 eta: 1 day, 17:51:28.395781	Training Loss1 4.2065 (4.3425)	Training Total_Loss 4.2065 (4.3425)	Training Prec@1 97.461 (96.850)	Training Prec@5 0.000 (0.000)	
2022-07-07 09:31:16,347: ============================================================
2022-07-07 09:32:31,138: time cost, forward:0.010732913077026979, backward:0.032607281118407286, data cost:0.7708672258190643 
2022-07-07 09:32:31,139: ============================================================
2022-07-07 09:32:31,139: Epoch 11/36 Batch 400/7662 eta: 1 day, 17:18:15.623243	Training Loss1 4.5704 (4.3517)	Training Total_Loss 4.5704 (4.3517)	Training Prec@1 96.875 (96.803)	Training Prec@5 0.000 (0.000)	
2022-07-07 09:32:31,139: ============================================================
2022-07-07 09:33:47,015: time cost, forward:0.01074144309890533, backward:0.03269697907931341, data cost:0.759606011167079 
2022-07-07 09:33:47,016: ============================================================
2022-07-07 09:33:47,016: Epoch 11/36 Batch 500/7662 eta: 1 day, 17:52:57.619066	Training Loss1 4.4682 (4.3657)	Training Total_Loss 4.4682 (4.3657)	Training Prec@1 95.312 (96.766)	Training Prec@5 0.000 (0.000)	
2022-07-07 09:33:47,016: ============================================================
2022-07-07 09:35:01,914: time cost, forward:0.010839951854317336, backward:0.03287668857033145, data cost:0.7501346639082308 
2022-07-07 09:35:01,915: ============================================================
2022-07-07 09:35:01,915: Epoch 11/36 Batch 600/7662 eta: 1 day, 17:19:19.011985	Training Loss1 4.5673 (4.3749)	Training Total_Loss 4.5673 (4.3749)	Training Prec@1 95.117 (96.746)	Training Prec@5 0.000 (0.000)	
2022-07-07 09:35:01,915: ============================================================
2022-07-07 09:36:17,873: time cost, forward:0.011014757238232527, backward:0.03313181669756408, data cost:0.7447893650235025 
2022-07-07 09:36:17,874: ============================================================
2022-07-07 09:36:17,874: Epoch 11/36 Batch 700/7662 eta: 1 day, 17:53:08.841545	Training Loss1 4.4137 (4.3873)	Training Total_Loss 4.4137 (4.3873)	Training Prec@1 95.898 (96.720)	Training Prec@5 0.000 (0.000)	
2022-07-07 09:36:17,874: ============================================================
2022-07-07 09:37:31,670: time cost, forward:0.01113814615337959, backward:0.033194519253039685, data cost:0.7381191328261164 
2022-07-07 09:37:31,671: ============================================================
2022-07-07 09:37:31,671: Epoch 11/36 Batch 800/7662 eta: 1 day, 16:40:22.400588	Training Loss1 4.2107 (4.4023)	Training Total_Loss 4.2107 (4.4023)	Training Prec@1 97.656 (96.686)	Training Prec@5 0.000 (0.000)	
2022-07-07 09:37:31,671: ============================================================
2022-07-07 09:38:46,026: time cost, forward:0.011219912827081225, backward:0.03326632077489732, data cost:0.733503272986916 
2022-07-07 09:38:46,026: ============================================================
2022-07-07 09:38:46,027: Epoch 11/36 Batch 900/7662 eta: 1 day, 16:57:37.373511	Training Loss1 4.6598 (4.4083)	Training Total_Loss 4.6598 (4.4083)	Training Prec@1 97.070 (96.670)	Training Prec@5 0.000 (0.000)	
2022-07-07 09:38:46,027: ============================================================
2022-07-07 09:40:00,038: time cost, forward:0.011343483213667158, backward:0.03331365504183688, data cost:0.7294605993055128 
2022-07-07 09:40:00,038: ============================================================
2022-07-07 09:40:00,038: Epoch 11/36 Batch 1000/7662 eta: 1 day, 16:45:00.637317	Training Loss1 4.4488 (4.4170)	Training Total_Loss 4.4488 (4.4170)	Training Prec@1 96.289 (96.655)	Training Prec@5 0.000 (0.000)	
2022-07-07 09:40:00,038: ============================================================
2022-07-07 09:41:13,575: time cost, forward:0.011378129034068391, backward:0.03337258051697833, data cost:0.725828029330586 
2022-07-07 09:41:13,575: ============================================================
2022-07-07 09:41:13,575: Epoch 11/36 Batch 1100/7662 eta: 1 day, 16:28:06.380310	Training Loss1 4.6022 (4.4249)	Training Total_Loss 4.6022 (4.4249)	Training Prec@1 96.680 (96.641)	Training Prec@5 0.000 (0.000)	
2022-07-07 09:41:13,575: ============================================================
2022-07-07 09:42:27,743: time cost, forward:0.011442710400820772, backward:0.033471307722700946, data cost:0.72320661711832 
2022-07-07 09:42:27,743: ============================================================
2022-07-07 09:42:27,744: Epoch 11/36 Batch 1200/7662 eta: 1 day, 16:47:42.662791	Training Loss1 4.5947 (4.4324)	Training Total_Loss 4.5947 (4.4324)	Training Prec@1 97.070 (96.624)	Training Prec@5 0.000 (0.000)	
2022-07-07 09:42:27,744: ============================================================
2022-07-07 09:43:43,475: time cost, forward:0.011504417387130537, backward:0.03350460979000617, data cost:0.7222089649990396 
2022-07-07 09:43:43,475: ============================================================
2022-07-07 09:43:43,475: Epoch 11/36 Batch 1300/7662 eta: 1 day, 17:38:03.094006	Training Loss1 4.2340 (4.4387)	Training Total_Loss 4.2340 (4.4387)	Training Prec@1 96.680 (96.612)	Training Prec@5 0.000 (0.000)	
2022-07-07 09:43:43,475: ============================================================
2022-07-07 09:44:57,677: time cost, forward:0.01154368498054379, backward:0.03349232009004234, data cost:0.7203823843540849 
2022-07-07 09:44:57,677: ============================================================
2022-07-07 09:44:57,677: Epoch 11/36 Batch 1400/7662 eta: 1 day, 16:46:21.685953	Training Loss1 4.7393 (4.4478)	Training Total_Loss 4.7393 (4.4478)	Training Prec@1 95.898 (96.595)	Training Prec@5 0.000 (0.000)	
2022-07-07 09:44:57,678: ============================================================
2022-07-07 09:46:11,921: time cost, forward:0.011594254466356478, backward:0.033453655370161324, data cost:0.7188023751063535 
2022-07-07 09:46:11,922: ============================================================
2022-07-07 09:46:11,922: Epoch 11/36 Batch 1500/7662 eta: 1 day, 16:46:30.591157	Training Loss1 4.6212 (4.4545)	Training Total_Loss 4.6212 (4.4545)	Training Prec@1 96.484 (96.565)	Training Prec@5 0.000 (0.000)	
2022-07-07 09:46:11,922: ============================================================
2022-07-07 09:47:25,826: time cost, forward:0.01159398118878544, backward:0.03345775917368132, data cost:0.7171993073707376 
2022-07-07 09:47:25,826: ============================================================
2022-07-07 09:47:25,827: Epoch 11/36 Batch 1600/7662 eta: 1 day, 16:34:05.589358	Training Loss1 4.6937 (4.4598)	Training Total_Loss 4.6937 (4.4598)	Training Prec@1 95.312 (96.550)	Training Prec@5 0.000 (0.000)	
2022-07-07 09:47:25,827: ============================================================
2022-07-07 09:48:38,833: time cost, forward:0.011628796031294042, backward:0.033418974643458055, data cost:0.715265076605273 
2022-07-07 09:48:38,834: ============================================================
2022-07-07 09:48:38,834: Epoch 11/36 Batch 1700/7662 eta: 1 day, 16:03:18.387428	Training Loss1 4.2084 (4.4658)	Training Total_Loss 4.2084 (4.4658)	Training Prec@1 98.633 (96.540)	Training Prec@5 0.000 (0.000)	
2022-07-07 09:48:38,834: ============================================================
2022-07-07 09:49:51,689: time cost, forward:0.01162827485398891, backward:0.033407174725874456, data cost:0.713489765058033 
2022-07-07 09:49:51,690: ============================================================
2022-07-07 09:49:51,690: Epoch 11/36 Batch 1800/7662 eta: 1 day, 15:57:07.768211	Training Loss1 4.5851 (4.4713)	Training Total_Loss 4.5851 (4.4713)	Training Prec@1 95.703 (96.532)	Training Prec@5 0.000 (0.000)	
2022-07-07 09:49:51,690: ============================================================
2022-07-07 09:51:05,722: time cost, forward:0.011653230339681055, backward:0.033394564196208454, data cost:0.7124596171908908 
2022-07-07 09:51:05,722: ============================================================
2022-07-07 09:51:05,723: Epoch 11/36 Batch 1900/7662 eta: 1 day, 16:34:35.983408	Training Loss1 4.5192 (4.4755)	Training Total_Loss 4.5192 (4.4755)	Training Prec@1 96.484 (96.517)	Training Prec@5 0.000 (0.000)	
2022-07-07 09:51:05,723: ============================================================
2022-07-07 09:52:20,393: time cost, forward:0.011700777008033741, backward:0.03335586901364653, data cost:0.7119157330998186 
2022-07-07 09:52:20,394: ============================================================
2022-07-07 09:52:20,394: Epoch 11/36 Batch 2000/7662 eta: 1 day, 16:54:21.531428	Training Loss1 4.6808 (4.4825)	Training Total_Loss 4.6808 (4.4825)	Training Prec@1 97.852 (96.495)	Training Prec@5 0.000 (0.000)	
2022-07-07 09:52:20,394: ============================================================
2022-07-07 09:53:34,157: time cost, forward:0.011726871452313369, backward:0.03338618980469506, data cost:0.7109095301725797 
2022-07-07 09:53:34,157: ============================================================
2022-07-07 09:53:34,157: Epoch 11/36 Batch 2100/7662 eta: 1 day, 16:23:16.938276	Training Loss1 4.7066 (4.4881)	Training Total_Loss 4.7066 (4.4881)	Training Prec@1 95.312 (96.478)	Training Prec@5 0.000 (0.000)	
2022-07-07 09:53:34,157: ============================================================
2022-07-07 09:54:48,176: time cost, forward:0.011759987848896826, backward:0.03336911409646069, data cost:0.7101171345209848 
2022-07-07 09:54:48,176: ============================================================
2022-07-07 09:54:48,176: Epoch 11/36 Batch 2200/7662 eta: 1 day, 16:30:27.207112	Training Loss1 4.5568 (4.4936)	Training Total_Loss 4.5568 (4.4936)	Training Prec@1 95.898 (96.464)	Training Prec@5 0.000 (0.000)	
2022-07-07 09:54:48,176: ============================================================
2022-07-07 09:56:01,830: time cost, forward:0.01182041639035139, backward:0.033377738245781115, data cost:0.7092324233459566 
2022-07-07 09:56:01,830: ============================================================
2022-07-07 09:56:01,830: Epoch 11/36 Batch 2300/7662 eta: 1 day, 16:17:14.364955	Training Loss1 4.5381 (4.4982)	Training Total_Loss 4.5381 (4.4982)	Training Prec@1 96.680 (96.451)	Training Prec@5 0.000 (0.000)	
2022-07-07 09:56:01,830: ============================================================
2022-07-07 09:57:17,267: time cost, forward:0.011890685771991432, backward:0.03335120828015549, data cost:0.7091474649358561 
2022-07-07 09:57:17,268: ============================================================
2022-07-07 09:57:17,268: Epoch 11/36 Batch 2400/7662 eta: 1 day, 17:14:30.768397	Training Loss1 4.4321 (4.5041)	Training Total_Loss 4.4321 (4.5041)	Training Prec@1 97.461 (96.436)	Training Prec@5 0.000 (0.000)	
2022-07-07 09:57:17,268: ============================================================
2022-07-07 09:58:32,076: time cost, forward:0.011923452051413827, backward:0.033379629737331946, data cost:0.7088004408382615 
2022-07-07 09:58:32,076: ============================================================
2022-07-07 09:58:32,076: Epoch 11/36 Batch 2500/7662 eta: 1 day, 16:52:37.894626	Training Loss1 4.6994 (4.5097)	Training Total_Loss 4.6994 (4.5097)	Training Prec@1 94.336 (96.422)	Training Prec@5 0.000 (0.000)	
2022-07-07 09:58:32,076: ============================================================
2022-07-07 09:59:46,278: time cost, forward:0.011913239015621054, backward:0.033388469438453784, data cost:0.7083230558933318 
2022-07-07 09:59:46,278: ============================================================
2022-07-07 09:59:46,279: Epoch 11/36 Batch 2600/7662 eta: 1 day, 16:31:31.394959	Training Loss1 4.6672 (4.5153)	Training Total_Loss 4.6672 (4.5153)	Training Prec@1 93.750 (96.404)	Training Prec@5 0.000 (0.000)	
2022-07-07 09:59:46,279: ============================================================
2022-07-07 10:01:01,432: time cost, forward:0.011922605393682863, backward:0.03339936787130745, data cost:0.708198303202869 
2022-07-07 10:01:01,432: ============================================================
2022-07-07 10:01:01,433: Epoch 11/36 Batch 2700/7662 eta: 1 day, 17:01:27.548306	Training Loss1 4.7703 (4.5199)	Training Total_Loss 4.7703 (4.5199)	Training Prec@1 94.336 (96.390)	Training Prec@5 0.000 (0.000)	
2022-07-07 10:01:01,433: ============================================================
2022-07-07 10:02:16,107: time cost, forward:0.011926226464285514, backward:0.03342646707505488, data cost:0.7079135221683711 
2022-07-07 10:02:16,107: ============================================================
2022-07-07 10:02:16,108: Epoch 11/36 Batch 2800/7662 eta: 1 day, 16:44:31.405315	Training Loss1 4.9255 (4.5243)	Training Total_Loss 4.9255 (4.5243)	Training Prec@1 96.094 (96.378)	Training Prec@5 0.000 (0.000)	
2022-07-07 10:02:16,108: ============================================================
2022-07-07 10:03:31,478: time cost, forward:0.011977827026746157, backward:0.0334370357491058, data cost:0.7078524626053873 
2022-07-07 10:03:31,479: ============================================================
2022-07-07 10:03:31,479: Epoch 11/36 Batch 2900/7662 eta: 1 day, 17:06:03.662474	Training Loss1 4.6265 (4.5283)	Training Total_Loss 4.6265 (4.5283)	Training Prec@1 97.266 (96.364)	Training Prec@5 0.000 (0.000)	
2022-07-07 10:03:31,479: ============================================================
2022-07-07 10:04:44,934: time cost, forward:0.011992390690822925, backward:0.033458605652135306, data cost:0.7071634528238641 
2022-07-07 10:04:44,934: ============================================================
2022-07-07 10:04:44,935: Epoch 11/36 Batch 3000/7662 eta: 1 day, 16:02:09.452379	Training Loss1 4.7739 (4.5335)	Training Total_Loss 4.7739 (4.5335)	Training Prec@1 95.312 (96.351)	Training Prec@5 0.000 (0.000)	
2022-07-07 10:04:44,935: ============================================================
2022-07-07 10:05:59,879: time cost, forward:0.012007232018538774, backward:0.03347282088083696, data cost:0.7070067562799986 
2022-07-07 10:05:59,880: ============================================================
2022-07-07 10:05:59,880: Epoch 11/36 Batch 3100/7662 eta: 1 day, 16:49:37.605906	Training Loss1 4.6297 (4.5373)	Training Total_Loss 4.6297 (4.5373)	Training Prec@1 96.680 (96.337)	Training Prec@5 0.000 (0.000)	
2022-07-07 10:05:59,880: ============================================================
2022-07-07 10:07:13,818: time cost, forward:0.012005228666858249, backward:0.03346486492580308, data cost:0.7065972405398179 
2022-07-07 10:07:13,818: ============================================================
2022-07-07 10:07:13,818: Epoch 11/36 Batch 3200/7662 eta: 1 day, 16:15:28.762490	Training Loss1 4.5227 (4.5424)	Training Total_Loss 4.5227 (4.5424)	Training Prec@1 96.680 (96.318)	Training Prec@5 0.000 (0.000)	
2022-07-07 10:07:13,818: ============================================================
2022-07-07 10:08:28,178: time cost, forward:0.012009567837167343, backward:0.03348136822647599, data cost:0.706298989214728 
2022-07-07 10:08:28,179: ============================================================
2022-07-07 10:08:28,179: Epoch 11/36 Batch 3300/7662 eta: 1 day, 16:28:02.369530	Training Loss1 4.5484 (4.5458)	Training Total_Loss 4.5484 (4.5458)	Training Prec@1 96.680 (96.304)	Training Prec@5 0.000 (0.000)	
2022-07-07 10:08:28,179: ============================================================
2022-07-07 10:09:43,023: time cost, forward:0.012008095881840031, backward:0.03349326245396864, data cost:0.7061812288447596 
2022-07-07 10:09:43,023: ============================================================
2022-07-07 10:09:43,024: Epoch 11/36 Batch 3400/7662 eta: 1 day, 16:42:35.294059	Training Loss1 4.6748 (4.5498)	Training Total_Loss 4.6748 (4.5498)	Training Prec@1 96.680 (96.292)	Training Prec@5 0.000 (0.000)	
2022-07-07 10:09:43,024: ============================================================
2022-07-07 10:10:58,126: time cost, forward:0.012005972092272247, backward:0.033509509772632964, data cost:0.7061216865276807 
2022-07-07 10:10:58,126: ============================================================
2022-07-07 10:10:58,126: Epoch 11/36 Batch 3500/7662 eta: 1 day, 16:49:45.437408	Training Loss1 4.5669 (4.5531)	Training Total_Loss 4.5669 (4.5531)	Training Prec@1 96.094 (96.279)	Training Prec@5 0.000 (0.000)	
2022-07-07 10:10:58,126: ============================================================
2022-07-07 10:12:13,474: time cost, forward:0.011993110097093891, backward:0.033514460446802105, data cost:0.7061696141983079 
2022-07-07 10:12:13,475: ============================================================
2022-07-07 10:12:13,475: Epoch 11/36 Batch 3600/7662 eta: 1 day, 16:56:31.722036	Training Loss1 4.8271 (4.5576)	Training Total_Loss 4.8271 (4.5576)	Training Prec@1 95.312 (96.267)	Training Prec@5 0.000 (0.000)	
2022-07-07 10:12:13,475: ============================================================
2022-07-07 10:13:28,375: time cost, forward:0.011977620755185563, backward:0.033538265723284916, data cost:0.7060751838921276 
2022-07-07 10:13:28,376: ============================================================
2022-07-07 10:13:28,376: Epoch 11/36 Batch 3700/7662 eta: 1 day, 16:40:41.478384	Training Loss1 4.7878 (4.5613)	Training Total_Loss 4.7878 (4.5613)	Training Prec@1 95.898 (96.253)	Training Prec@5 0.000 (0.000)	
2022-07-07 10:13:28,376: ============================================================
2022-07-07 10:14:41,693: time cost, forward:0.011964523218028888, backward:0.03353508060371979, data cost:0.7055216361485396 
2022-07-07 10:14:41,693: ============================================================
2022-07-07 10:14:41,693: Epoch 11/36 Batch 3800/7662 eta: 1 day, 15:47:51.686560	Training Loss1 4.8245 (4.5649)	Training Total_Loss 4.8245 (4.5649)	Training Prec@1 95.117 (96.244)	Training Prec@5 0.000 (0.000)	
2022-07-07 10:14:41,693: ============================================================
2022-07-07 10:15:56,273: time cost, forward:0.0119726070228923, backward:0.033509120173135086, data cost:0.7054559508786198 
2022-07-07 10:15:56,273: ============================================================
2022-07-07 10:15:56,274: Epoch 11/36 Batch 3900/7662 eta: 1 day, 16:27:44.962381	Training Loss1 4.7297 (4.5691)	Training Total_Loss 4.7297 (4.5691)	Training Prec@1 95.898 (96.229)	Training Prec@5 0.000 (0.000)	
2022-07-07 10:15:56,274: ============================================================
2022-07-07 10:17:11,557: time cost, forward:0.011990845814500042, backward:0.03349844608702759, data cost:0.7054780409556086 
2022-07-07 10:17:11,557: ============================================================
2022-07-07 10:17:11,557: Epoch 11/36 Batch 4000/7662 eta: 1 day, 16:49:23.758688	Training Loss1 4.6051 (4.5716)	Training Total_Loss 4.6051 (4.5716)	Training Prec@1 97.070 (96.224)	Training Prec@5 0.000 (0.000)	
2022-07-07 10:17:11,557: ============================================================
2022-07-07 10:18:26,572: time cost, forward:0.011972046968674595, backward:0.033499069404648585, data cost:0.7054232302221563 
2022-07-07 10:18:26,572: ============================================================
2022-07-07 10:18:26,573: Epoch 11/36 Batch 4100/7662 eta: 1 day, 16:39:24.351623	Training Loss1 4.8190 (4.5747)	Training Total_Loss 4.8190 (4.5747)	Training Prec@1 97.266 (96.213)	Training Prec@5 0.000 (0.000)	
2022-07-07 10:18:26,573: ============================================================
2022-07-07 10:19:40,806: time cost, forward:0.012004680138424652, backward:0.03349089435124062, data cost:0.7052209777586742 
2022-07-07 10:19:40,806: ============================================================
2022-07-07 10:19:40,807: Epoch 11/36 Batch 4200/7662 eta: 1 day, 16:12:46.164697	Training Loss1 4.4135 (4.5780)	Training Total_Loss 4.4135 (4.5780)	Training Prec@1 96.680 (96.202)	Training Prec@5 0.000 (0.000)	
2022-07-07 10:19:40,807: ============================================================
2022-07-07 10:20:55,585: time cost, forward:0.012007782419883088, backward:0.033486091804992436, data cost:0.7051424872572961 
2022-07-07 10:20:55,585: ============================================================
2022-07-07 10:20:55,585: Epoch 11/36 Batch 4300/7662 eta: 1 day, 16:29:12.933749	Training Loss1 4.6207 (4.5808)	Training Total_Loss 4.6207 (4.5808)	Training Prec@1 95.898 (96.193)	Training Prec@5 0.000 (0.000)	
2022-07-07 10:20:55,585: ============================================================
2022-07-07 10:22:10,054: time cost, forward:0.012031892614761355, backward:0.03348247520921988, data cost:0.7049732468404074 
2022-07-07 10:22:10,054: ============================================================
2022-07-07 10:22:10,055: Epoch 11/36 Batch 4400/7662 eta: 1 day, 16:17:56.047931	Training Loss1 4.3286 (4.5833)	Training Total_Loss 4.3286 (4.5833)	Training Prec@1 97.852 (96.184)	Training Prec@5 0.000 (0.000)	
2022-07-07 10:22:10,055: ============================================================
2022-07-07 10:23:25,964: time cost, forward:0.012065730059933838, backward:0.03346102612366754, data cost:0.7051369981729712 
2022-07-07 10:23:25,965: ============================================================
2022-07-07 10:23:25,965: Epoch 11/36 Batch 4500/7662 eta: 1 day, 17:03:27.176048	Training Loss1 4.7279 (4.5862)	Training Total_Loss 4.7279 (4.5862)	Training Prec@1 95.312 (96.176)	Training Prec@5 0.000 (0.000)	
2022-07-07 10:23:25,965: ============================================================
2022-07-07 10:24:40,702: time cost, forward:0.012084969906061466, backward:0.03345972943705148, data cost:0.7050276262963899 
2022-07-07 10:24:40,702: ============================================================
2022-07-07 10:24:40,703: Epoch 11/36 Batch 4600/7662 eta: 1 day, 16:24:09.701843	Training Loss1 4.6645 (4.5894)	Training Total_Loss 4.6645 (4.5894)	Training Prec@1 97.266 (96.166)	Training Prec@5 0.000 (0.000)	
2022-07-07 10:24:40,703: ============================================================
2022-07-07 10:25:54,789: time cost, forward:0.01209633506138443, backward:0.033463601432827894, data cost:0.7047936678896765 
2022-07-07 10:25:54,789: ============================================================
2022-07-07 10:25:54,790: Epoch 11/36 Batch 4700/7662 eta: 1 day, 16:01:48.681933	Training Loss1 4.8927 (4.5921)	Training Total_Loss 4.8927 (4.5921)	Training Prec@1 94.922 (96.155)	Training Prec@5 0.000 (0.000)	
2022-07-07 10:25:54,790: ============================================================
2022-07-07 10:27:10,426: time cost, forward:0.012115034567214321, backward:0.0334339511968315, data cost:0.704919032341094 
2022-07-07 10:27:10,426: ============================================================
2022-07-07 10:27:10,426: Epoch 11/36 Batch 4800/7662 eta: 1 day, 16:50:47.283536	Training Loss1 4.6621 (4.5957)	Training Total_Loss 4.6621 (4.5957)	Training Prec@1 96.680 (96.144)	Training Prec@5 0.000 (0.000)	
2022-07-07 10:27:10,426: ============================================================
2022-07-07 10:28:24,483: time cost, forward:0.012110142348663835, backward:0.03342405205528258, data cost:0.7047207741426872 
2022-07-07 10:28:24,483: ============================================================
2022-07-07 10:28:24,483: Epoch 11/36 Batch 4900/7662 eta: 1 day, 15:58:22.444044	Training Loss1 4.8570 (4.5985)	Training Total_Loss 4.8570 (4.5985)	Training Prec@1 95.898 (96.133)	Training Prec@5 0.000 (0.000)	
2022-07-07 10:28:24,483: ============================================================
2022-07-07 10:29:38,305: time cost, forward:0.012099509526310169, backward:0.03341023004825269, data cost:0.7044952580584934 
2022-07-07 10:29:38,305: ============================================================
2022-07-07 10:29:38,305: Epoch 11/36 Batch 5000/7662 eta: 1 day, 15:49:32.320052	Training Loss1 4.6062 (4.6012)	Training Total_Loss 4.6062 (4.6012)	Training Prec@1 96.680 (96.125)	Training Prec@5 0.000 (0.000)	
2022-07-07 10:29:38,306: ============================================================
2022-07-07 10:30:53,401: time cost, forward:0.012115490625923488, backward:0.0334125124349106, data cost:0.7044807493184029 
2022-07-07 10:30:53,402: ============================================================
2022-07-07 10:30:53,402: Epoch 11/36 Batch 5100/7662 eta: 1 day, 16:29:31.735210	Training Loss1 4.5685 (4.6039)	Training Total_Loss 4.5685 (4.6039)	Training Prec@1 96.094 (96.117)	Training Prec@5 0.000 (0.000)	
2022-07-07 10:30:53,402: ============================================================
2022-07-07 10:32:08,893: time cost, forward:0.012115141317738458, backward:0.033408362949369136, data cost:0.7045744256024912 
2022-07-07 10:32:08,893: ============================================================
2022-07-07 10:32:08,893: Epoch 11/36 Batch 5200/7662 eta: 1 day, 16:41:03.561460	Training Loss1 4.5523 (4.6062)	Training Total_Loss 4.5523 (4.6062)	Training Prec@1 96.094 (96.110)	Training Prec@5 0.000 (0.000)	
2022-07-07 10:32:08,893: ============================================================
2022-07-07 10:33:23,830: time cost, forward:0.012123672213953022, backward:0.03341878907008764, data cost:0.7045301412901669 
2022-07-07 10:33:23,830: ============================================================
2022-07-07 10:33:23,831: Epoch 11/36 Batch 5300/7662 eta: 1 day, 16:21:52.968147	Training Loss1 4.9098 (4.6089)	Training Total_Loss 4.9098 (4.6089)	Training Prec@1 94.922 (96.105)	Training Prec@5 0.000 (0.000)	
2022-07-07 10:33:23,831: ============================================================
2022-07-07 10:34:38,970: time cost, forward:0.012129873009738402, backward:0.03341830017434643, data cost:0.7045353358929898 
2022-07-07 10:34:38,971: ============================================================
2022-07-07 10:34:38,971: Epoch 11/36 Batch 5400/7662 eta: 1 day, 16:27:12.080964	Training Loss1 5.1087 (4.6112)	Training Total_Loss 5.1087 (4.6112)	Training Prec@1 94.141 (96.097)	Training Prec@5 0.000 (0.000)	
2022-07-07 10:34:38,971: ============================================================
2022-07-07 10:35:53,875: time cost, forward:0.012133078784113646, backward:0.033419560076735584, data cost:0.7045034167766138 
2022-07-07 10:35:53,875: ============================================================
2022-07-07 10:35:53,876: Epoch 11/36 Batch 5500/7662 eta: 1 day, 16:18:19.888036	Training Loss1 4.5146 (4.6133)	Training Total_Loss 4.5146 (4.6133)	Training Prec@1 96.484 (96.093)	Training Prec@5 0.000 (0.000)	
2022-07-07 10:35:53,876: ============================================================
2022-07-07 10:37:08,484: time cost, forward:0.012136008957067245, backward:0.033418582281612416, data cost:0.7044184319056194 
2022-07-07 10:37:08,484: ============================================================
2022-07-07 10:37:08,485: Epoch 11/36 Batch 5600/7662 eta: 1 day, 16:07:32.653866	Training Loss1 4.8954 (4.6160)	Training Total_Loss 4.8954 (4.6160)	Training Prec@1 94.141 (96.085)	Training Prec@5 0.000 (0.000)	
2022-07-07 10:37:08,485: ============================================================
2022-07-07 10:38:24,337: time cost, forward:0.01214266802307011, backward:0.03341400625413291, data cost:0.7045565594035421 
2022-07-07 10:38:24,337: ============================================================
2022-07-07 10:38:24,337: Epoch 11/36 Batch 5700/7662 eta: 1 day, 16:46:24.775825	Training Loss1 4.8056 (4.6185)	Training Total_Loss 4.8056 (4.6185)	Training Prec@1 95.898 (96.078)	Training Prec@5 0.000 (0.000)	
2022-07-07 10:38:24,337: ============================================================
2022-07-07 10:39:38,782: time cost, forward:0.012150831151818546, backward:0.03342068394744657, data cost:0.7044334870039296 
2022-07-07 10:39:38,782: ============================================================
2022-07-07 10:39:38,783: Epoch 11/36 Batch 5800/7662 eta: 1 day, 15:59:46.846324	Training Loss1 4.5484 (4.6209)	Training Total_Loss 4.5484 (4.6209)	Training Prec@1 96.680 (96.068)	Training Prec@5 0.000 (0.000)	
2022-07-07 10:39:38,783: ============================================================
2022-07-07 10:40:52,970: time cost, forward:0.012157617898123975, backward:0.033421106430651236, data cost:0.7042749491075799 
2022-07-07 10:40:52,971: ============================================================
2022-07-07 10:40:52,971: Epoch 11/36 Batch 5900/7662 eta: 1 day, 15:50:15.941583	Training Loss1 4.5970 (4.6231)	Training Total_Loss 4.5970 (4.6231)	Training Prec@1 95.508 (96.062)	Training Prec@5 0.000 (0.000)	
2022-07-07 10:40:52,971: ============================================================
2022-07-07 10:42:08,210: time cost, forward:0.01216258993147214, backward:0.03342779546325297, data cost:0.7043006378802722 
2022-07-07 10:42:08,211: ============================================================
2022-07-07 10:42:08,211: Epoch 11/36 Batch 6000/7662 eta: 1 day, 16:22:53.370930	Training Loss1 4.6809 (4.6254)	Training Total_Loss 4.6809 (4.6254)	Training Prec@1 94.922 (96.057)	Training Prec@5 0.000 (0.000)	
2022-07-07 10:42:08,211: ============================================================
2022-07-07 10:43:22,378: time cost, forward:0.012163742387230269, backward:0.03343577388076044, data cost:0.7041474175582187 
2022-07-07 10:43:22,378: ============================================================
2022-07-07 10:43:22,378: Epoch 11/36 Batch 6100/7662 eta: 1 day, 15:47:06.324623	Training Loss1 4.8159 (4.6275)	Training Total_Loss 4.8159 (4.6275)	Training Prec@1 96.289 (96.051)	Training Prec@5 0.000 (0.000)	
2022-07-07 10:43:22,378: ============================================================
2022-07-07 10:44:36,276: time cost, forward:0.01216629609540117, backward:0.033445634540386175, data cost:0.7039484894646812 
2022-07-07 10:44:36,277: ============================================================
2022-07-07 10:44:36,277: Epoch 11/36 Batch 6200/7662 eta: 1 day, 15:37:14.041227	Training Loss1 4.7823 (4.6299)	Training Total_Loss 4.7823 (4.6299)	Training Prec@1 95.508 (96.044)	Training Prec@5 0.000 (0.000)	
2022-07-07 10:44:36,277: ============================================================
2022-07-07 10:45:50,579: time cost, forward:0.012170324667727574, backward:0.033451119535100673, data cost:0.703826332569198 
2022-07-07 10:45:50,580: ============================================================
2022-07-07 10:45:50,580: Epoch 11/36 Batch 6300/7662 eta: 1 day, 15:49:00.018475	Training Loss1 4.9104 (4.6317)	Training Total_Loss 4.9104 (4.6317)	Training Prec@1 96.094 (96.040)	Training Prec@5 0.000 (0.000)	
2022-07-07 10:45:50,580: ============================================================
2022-07-07 10:47:04,670: time cost, forward:0.01217093000487995, backward:0.03345624039482001, data cost:0.7036709930025278 
2022-07-07 10:47:04,670: ============================================================
2022-07-07 10:47:04,671: Epoch 11/36 Batch 6400/7662 eta: 1 day, 15:40:57.035393	Training Loss1 4.7213 (4.6338)	Training Total_Loss 4.7213 (4.6338)	Training Prec@1 95.703 (96.032)	Training Prec@5 0.000 (0.000)	
2022-07-07 10:47:04,671: ============================================================
2022-07-07 10:48:18,844: time cost, forward:0.012170829705448036, backward:0.03346331780975572, data cost:0.7035446899233276 
2022-07-07 10:48:18,844: ============================================================
2022-07-07 10:48:18,844: Epoch 11/36 Batch 6500/7662 eta: 1 day, 15:42:22.038741	Training Loss1 4.4993 (4.6356)	Training Total_Loss 4.4993 (4.6356)	Training Prec@1 98.047 (96.027)	Training Prec@5 0.000 (0.000)	
2022-07-07 10:48:18,844: ============================================================
2022-07-07 10:49:31,759: time cost, forward:0.012163946711307114, backward:0.03346200913511491, data cost:0.703239850084571 
2022-07-07 10:49:31,759: ============================================================
2022-07-07 10:49:31,759: Epoch 11/36 Batch 6600/7662 eta: 1 day, 15:00:44.088497	Training Loss1 4.7100 (4.6381)	Training Total_Loss 4.7100 (4.6381)	Training Prec@1 96.289 (96.020)	Training Prec@5 0.000 (0.000)	
2022-07-07 10:49:31,759: ============================================================
2022-07-07 10:50:46,035: time cost, forward:0.012171212800101819, backward:0.033460533143798175, data cost:0.7031362267426011 
2022-07-07 10:50:46,035: ============================================================
2022-07-07 10:50:46,035: Epoch 11/36 Batch 6700/7662 eta: 1 day, 15:43:10.742954	Training Loss1 4.7745 (4.6397)	Training Total_Loss 4.7745 (4.6397)	Training Prec@1 96.875 (96.017)	Training Prec@5 0.000 (0.000)	
2022-07-07 10:50:46,035: ============================================================
2022-07-07 10:52:01,658: time cost, forward:0.01217406303466357, backward:0.033467420814212306, data cost:0.7032260582330981 
2022-07-07 10:52:01,659: ============================================================
2022-07-07 10:52:01,659: Epoch 11/36 Batch 6800/7662 eta: 1 day, 16:25:09.441594	Training Loss1 4.8099 (4.6419)	Training Total_Loss 4.8099 (4.6419)	Training Prec@1 95.508 (96.010)	Training Prec@5 0.000 (0.000)	
2022-07-07 10:52:01,659: ============================================================
2022-07-07 10:53:17,194: time cost, forward:0.012169416995476356, backward:0.0334663877004747, data cost:0.7033177476151126 
2022-07-07 10:53:17,194: ============================================================
2022-07-07 10:53:17,195: Epoch 11/36 Batch 6900/7662 eta: 1 day, 16:21:05.029131	Training Loss1 4.8786 (4.6445)	Training Total_Loss 4.8786 (4.6445)	Training Prec@1 95.508 (96.002)	Training Prec@5 0.000 (0.000)	
2022-07-07 10:53:17,195: ============================================================
2022-07-07 10:54:30,900: time cost, forward:0.01216347617138316, backward:0.033469963829966, data cost:0.7031372938007606 
2022-07-07 10:54:30,900: ============================================================
2022-07-07 10:54:30,901: Epoch 11/36 Batch 7000/7662 eta: 1 day, 15:21:12.305897	Training Loss1 4.7261 (4.6465)	Training Total_Loss 4.7261 (4.6465)	Training Prec@1 95.508 (95.994)	Training Prec@5 0.000 (0.000)	
2022-07-07 10:54:30,901: ============================================================
2022-07-07 10:55:45,746: time cost, forward:0.012174061107407121, backward:0.033484903250400204, data cost:0.7031009077673177 
2022-07-07 10:55:45,746: ============================================================
2022-07-07 10:55:45,746: Epoch 11/36 Batch 7100/7662 eta: 1 day, 15:56:28.254191	Training Loss1 4.8298 (4.6483)	Training Total_Loss 4.8298 (4.6483)	Training Prec@1 94.727 (95.988)	Training Prec@5 0.000 (0.000)	
2022-07-07 10:55:45,746: ============================================================
2022-07-07 10:56:59,639: time cost, forward:0.012176864195870168, backward:0.03348531486557861, data cost:0.7029568746298912 
2022-07-07 10:56:59,639: ============================================================
2022-07-07 10:56:59,639: Epoch 11/36 Batch 7200/7662 eta: 1 day, 15:24:44.376002	Training Loss1 4.9339 (4.6499)	Training Total_Loss 4.9339 (4.6499)	Training Prec@1 95.508 (95.983)	Training Prec@5 0.000 (0.000)	
2022-07-07 10:56:59,639: ============================================================
2022-07-07 10:58:14,856: time cost, forward:0.012180588607641749, backward:0.033491574896412496, data cost:0.7029839920203871 
2022-07-07 10:58:14,856: ============================================================
2022-07-07 10:58:14,856: Epoch 11/36 Batch 7300/7662 eta: 1 day, 16:05:51.434121	Training Loss1 4.5743 (4.6518)	Training Total_Loss 4.5743 (4.6518)	Training Prec@1 95.703 (95.976)	Training Prec@5 0.000 (0.000)	
2022-07-07 10:58:14,856: ============================================================
2022-07-07 10:59:30,862: time cost, forward:0.012180930940762358, backward:0.03348842146010282, data cost:0.7031372244703816 
2022-07-07 10:59:30,863: ============================================================
2022-07-07 10:59:30,863: Epoch 11/36 Batch 7400/7662 eta: 1 day, 16:29:50.383984	Training Loss1 4.7895 (4.6532)	Training Total_Loss 4.7895 (4.6532)	Training Prec@1 96.289 (95.973)	Training Prec@5 0.000 (0.000)	
2022-07-07 10:59:30,863: ============================================================
2022-07-07 11:00:45,385: time cost, forward:0.012176172369908518, backward:0.03349989734501628, data cost:0.7030722898139145 
2022-07-07 11:00:45,386: ============================================================
2022-07-07 11:00:45,386: Epoch 11/36 Batch 7500/7662 eta: 1 day, 15:41:10.564668	Training Loss1 4.4611 (4.6549)	Training Total_Loss 4.4611 (4.6549)	Training Prec@1 97.070 (95.968)	Training Prec@5 0.000 (0.000)	
2022-07-07 11:00:45,386: ============================================================
2022-07-07 11:02:01,117: time cost, forward:0.012178253258415109, backward:0.033502880280418514, data cost:0.7031708548046725 
2022-07-07 11:02:01,118: ============================================================
2022-07-07 11:02:01,118: Epoch 11/36 Batch 7600/7662 eta: 1 day, 16:18:32.463820	Training Loss1 4.7483 (4.6566)	Training Total_Loss 4.7483 (4.6566)	Training Prec@1 95.312 (95.962)	Training Prec@5 0.000 (0.000)	
2022-07-07 11:02:01,118: ============================================================
2022-07-07 11:02:49,347: Epoch 11/36 Batch 7663/7662 eta: 1 day, 16:17:44.752625	Training Loss1 4.9641 (4.6573)	Training Total_Loss 4.9641 (4.6573)	Training Prec@1 94.727 (95.960)	Training Prec@5 0.000 (0.000)	
2022-07-07 11:02:49,348: ============================================================
2022-07-07 11:04:20,104: time cost, forward:0.0126907994048764, backward:0.03338488424667204, data cost:0.8642028823043361 
2022-07-07 11:04:20,105: ============================================================
2022-07-07 11:04:20,105: Epoch 12/36 Batch 100/7662 eta: 2 days, 0:12:51.798293	Training Loss1 4.1487 (4.2283)	Training Total_Loss 4.1487 (4.2283)	Training Prec@1 97.656 (97.226)	Training Prec@5 0.000 (0.000)	
2022-07-07 11:04:20,105: ============================================================
2022-07-07 11:05:33,056: time cost, forward:0.012208285643227736, backward:0.033181069484308136, data cost:0.7736605783203738 
2022-07-07 11:05:33,056: ============================================================
2022-07-07 11:05:33,057: Epoch 12/36 Batch 200/7662 eta: 1 day, 14:46:33.311050	Training Loss1 4.3001 (4.2593)	Training Total_Loss 4.3001 (4.2593)	Training Prec@1 95.898 (97.140)	Training Prec@5 0.000 (0.000)	
2022-07-07 11:05:33,057: ============================================================
2022-07-07 11:06:46,451: time cost, forward:0.012276236428863628, backward:0.03322839577461166, data cost:0.7449315056752999 
2022-07-07 11:06:46,451: ============================================================
2022-07-07 11:06:46,451: Epoch 12/36 Batch 300/7662 eta: 1 day, 14:59:28.389619	Training Loss1 4.4034 (4.2799)	Training Total_Loss 4.4034 (4.2799)	Training Prec@1 96.680 (97.089)	Training Prec@5 0.000 (0.000)	
2022-07-07 11:06:46,451: ============================================================
2022-07-07 11:07:59,257: time cost, forward:0.012363074716171226, backward:0.03326326623596344, data cost:0.7289932156565195 
2022-07-07 11:07:59,257: ============================================================
2022-07-07 11:07:59,257: Epoch 12/36 Batch 400/7662 eta: 1 day, 14:39:28.963185	Training Loss1 4.2868 (4.2935)	Training Total_Loss 4.2868 (4.2935)	Training Prec@1 95.898 (97.054)	Training Prec@5 0.000 (0.000)	
2022-07-07 11:07:59,257: ============================================================
2022-07-07 11:09:13,310: time cost, forward:0.01245611989665366, backward:0.033286241347899655, data cost:0.7219485166316519 
2022-07-07 11:09:13,310: ============================================================
2022-07-07 11:09:13,310: Epoch 12/36 Batch 500/7662 eta: 1 day, 15:17:58.899502	Training Loss1 4.1257 (4.3161)	Training Total_Loss 4.1257 (4.3161)	Training Prec@1 97.656 (97.025)	Training Prec@5 0.000 (0.000)	
2022-07-07 11:09:13,310: ============================================================
2022-07-07 11:10:26,986: time cost, forward:0.012445709741175275, backward:0.0333083324718953, data cost:0.7166609505381131 
2022-07-07 11:10:26,986: ============================================================
2022-07-07 11:10:26,987: Epoch 12/36 Batch 600/7662 eta: 1 day, 15:04:45.968145	Training Loss1 4.3993 (4.3321)	Training Total_Loss 4.3993 (4.3321)	Training Prec@1 97.266 (96.995)	Training Prec@5 0.000 (0.000)	
2022-07-07 11:10:26,987: ============================================================
2022-07-07 11:11:39,173: time cost, forward:0.012308008851582059, backward:0.033328441761764506, data cost:0.7108997875699329 
2022-07-07 11:11:39,174: ============================================================
2022-07-07 11:11:39,174: Epoch 12/36 Batch 700/7662 eta: 1 day, 14:16:10.050083	Training Loss1 4.7784 (4.3442)	Training Total_Loss 4.7784 (4.3442)	Training Prec@1 96.680 (96.959)	Training Prec@5 0.000 (0.000)	
2022-07-07 11:11:39,174: ============================================================
2022-07-07 11:12:52,983: time cost, forward:0.012240166359759391, backward:0.03336467939861427, data cost:0.7085539799309493 
2022-07-07 11:12:52,983: ============================================================
2022-07-07 11:12:52,984: Epoch 12/36 Batch 800/7662 eta: 1 day, 15:06:32.674926	Training Loss1 4.4974 (4.3584)	Training Total_Loss 4.4974 (4.3584)	Training Prec@1 96.680 (96.930)	Training Prec@5 0.000 (0.000)	
2022-07-07 11:12:52,984: ============================================================
2022-07-07 11:14:06,115: time cost, forward:0.01215237478525673, backward:0.033474850575040786, data cost:0.7059188636974976 
2022-07-07 11:14:06,115: ============================================================
2022-07-07 11:14:06,116: Epoch 12/36 Batch 900/7662 eta: 1 day, 14:43:46.888353	Training Loss1 4.4855 (4.3739)	Training Total_Loss 4.4855 (4.3739)	Training Prec@1 96.680 (96.902)	Training Prec@5 0.000 (0.000)	
2022-07-07 11:14:06,116: ============================================================
2022-07-07 11:15:18,859: time cost, forward:0.012116636719192948, backward:0.033420936720029965, data cost:0.7035398468956933 
2022-07-07 11:15:18,860: ============================================================
2022-07-07 11:15:18,860: Epoch 12/36 Batch 1000/7662 eta: 1 day, 14:30:15.460636	Training Loss1 4.4236 (4.3868)	Training Total_Loss 4.4236 (4.3868)	Training Prec@1 98.047 (96.867)	Training Prec@5 0.000 (0.000)	
2022-07-07 11:15:18,860: ============================================================
2022-07-07 11:16:31,554: time cost, forward:0.012152997659920995, backward:0.033322567284595324, data cost:0.7015293685819367 
2022-07-07 11:16:31,554: ============================================================
2022-07-07 11:16:31,554: Epoch 12/36 Batch 1100/7662 eta: 1 day, 14:27:26.854074	Training Loss1 4.3600 (4.3961)	Training Total_Loss 4.3600 (4.3961)	Training Prec@1 96.875 (96.847)	Training Prec@5 0.000 (0.000)	
2022-07-07 11:16:31,554: ============================================================
2022-07-07 11:17:44,569: time cost, forward:0.012193649385848375, backward:0.03332073972859514, data cost:0.7000221020982502 
2022-07-07 11:17:44,569: ============================================================
2022-07-07 11:17:44,569: Epoch 12/36 Batch 1200/7662 eta: 1 day, 14:36:24.844117	Training Loss1 4.6755 (4.4082)	Training Total_Loss 4.6755 (4.4082)	Training Prec@1 97.461 (96.816)	Training Prec@5 0.000 (0.000)	
2022-07-07 11:17:44,569: ============================================================
2022-07-07 11:18:58,865: time cost, forward:0.01218157111910144, backward:0.0333188101362503, data cost:0.6997957288347088 
2022-07-07 11:18:58,866: ============================================================
2022-07-07 11:18:58,866: Epoch 12/36 Batch 1300/7662 eta: 1 day, 15:15:50.401599	Training Loss1 4.7603 (4.4178)	Training Total_Loss 4.7603 (4.4178)	Training Prec@1 95.508 (96.789)	Training Prec@5 0.000 (0.000)	
2022-07-07 11:18:58,866: ============================================================
2022-07-07 11:20:11,714: time cost, forward:0.012103620471913445, backward:0.03331711805233195, data cost:0.698644469004175 
2022-07-07 11:20:11,715: ============================================================
2022-07-07 11:20:11,715: Epoch 12/36 Batch 1400/7662 eta: 1 day, 14:28:43.022609	Training Loss1 4.7394 (4.4273)	Training Total_Loss 4.7394 (4.4273)	Training Prec@1 95.312 (96.769)	Training Prec@5 0.000 (0.000)	
2022-07-07 11:20:11,715: ============================================================
2022-07-07 11:21:25,620: time cost, forward:0.012057129425394924, backward:0.03328709494200764, data cost:0.6982535064180666 
2022-07-07 11:21:25,621: ============================================================
2022-07-07 11:21:25,621: Epoch 12/36 Batch 1500/7662 eta: 1 day, 15:00:58.870747	Training Loss1 4.5433 (4.4372)	Training Total_Loss 4.5433 (4.4372)	Training Prec@1 97.656 (96.747)	Training Prec@5 0.000 (0.000)	
2022-07-07 11:21:25,621: ============================================================
2022-07-07 11:22:39,227: time cost, forward:0.012065191131744481, backward:0.03326992574075075, data cost:0.6978434554631446 
2022-07-07 11:22:39,227: ============================================================
2022-07-07 11:22:39,228: Epoch 12/36 Batch 1600/7662 eta: 1 day, 14:50:16.602377	Training Loss1 4.7512 (4.4464)	Training Total_Loss 4.7512 (4.4464)	Training Prec@1 96.484 (96.735)	Training Prec@5 0.000 (0.000)	
2022-07-07 11:22:39,228: ============================================================
2022-07-07 11:23:51,966: time cost, forward:0.012089149610935905, backward:0.0332931286450903, data cost:0.696814426890256 
2022-07-07 11:23:51,967: ============================================================
2022-07-07 11:23:51,967: Epoch 12/36 Batch 1700/7662 eta: 1 day, 14:21:36.410227	Training Loss1 4.5856 (4.4546)	Training Total_Loss 4.5856 (4.4546)	Training Prec@1 97.266 (96.713)	Training Prec@5 0.000 (0.000)	
2022-07-07 11:23:51,967: ============================================================
2022-07-07 11:25:05,990: time cost, forward:0.0120696334987299, backward:0.03327154569853803, data cost:0.696713500582158 
2022-07-07 11:25:05,990: ============================================================
2022-07-07 11:25:05,991: Epoch 12/36 Batch 1800/7662 eta: 1 day, 15:01:00.571193	Training Loss1 4.6605 (4.4635)	Training Total_Loss 4.6605 (4.4635)	Training Prec@1 96.680 (96.696)	Training Prec@5 0.000 (0.000)	
2022-07-07 11:25:05,991: ============================================================
2022-07-07 11:26:19,642: time cost, forward:0.012027239410295933, backward:0.03325826058330004, data cost:0.6964479477045221 
2022-07-07 11:26:19,642: ============================================================
2022-07-07 11:26:19,642: Epoch 12/36 Batch 1900/7662 eta: 1 day, 14:48:00.829300	Training Loss1 4.4504 (4.4714)	Training Total_Loss 4.4504 (4.4714)	Training Prec@1 96.484 (96.676)	Training Prec@5 0.000 (0.000)	
2022-07-07 11:26:19,642: ============================================================
2022-07-07 11:27:32,801: time cost, forward:0.012030135398509802, backward:0.0332493330014235, data cost:0.6959172834927825 
2022-07-07 11:27:32,802: ============================================================
2022-07-07 11:27:32,802: Epoch 12/36 Batch 2000/7662 eta: 1 day, 14:31:15.158357	Training Loss1 4.5603 (4.4785)	Training Total_Loss 4.5603 (4.4785)	Training Prec@1 95.508 (96.654)	Training Prec@5 0.000 (0.000)	
2022-07-07 11:27:32,802: ============================================================
2022-07-07 11:28:46,512: time cost, forward:0.012033605643713571, backward:0.03325542158714756, data cost:0.6956864767497127 
2022-07-07 11:28:46,512: ============================================================
2022-07-07 11:28:46,513: Epoch 12/36 Batch 2100/7662 eta: 1 day, 14:47:25.380085	Training Loss1 4.7284 (4.4872)	Training Total_Loss 4.7284 (4.4872)	Training Prec@1 96.680 (96.633)	Training Prec@5 0.000 (0.000)	
2022-07-07 11:28:46,513: ============================================================
2022-07-07 11:29:59,362: time cost, forward:0.012003602088175344, backward:0.033235160910904324, data cost:0.6951229370632406 
2022-07-07 11:29:59,362: ============================================================
2022-07-07 11:29:59,362: Epoch 12/36 Batch 2200/7662 eta: 1 day, 14:19:01.750066	Training Loss1 4.6826 (4.4950)	Training Total_Loss 4.6826 (4.4950)	Training Prec@1 95.703 (96.611)	Training Prec@5 0.000 (0.000)	
2022-07-07 11:29:59,362: ============================================================
2022-07-07 11:31:13,686: time cost, forward:0.012012766256908999, backward:0.03328010194868873, data cost:0.695178872453176 
2022-07-07 11:31:13,686: ============================================================
2022-07-07 11:31:13,686: Epoch 12/36 Batch 2300/7662 eta: 1 day, 15:04:18.684253	Training Loss1 4.7863 (4.5026)	Training Total_Loss 4.7863 (4.5026)	Training Prec@1 93.945 (96.592)	Training Prec@5 0.000 (0.000)	
2022-07-07 11:31:13,686: ============================================================
2022-07-07 11:32:28,427: time cost, forward:0.011999906128075978, backward:0.03327865747672014, data cost:0.6954577382577862 
2022-07-07 11:32:28,427: ============================================================
2022-07-07 11:32:28,427: Epoch 12/36 Batch 2400/7662 eta: 1 day, 15:16:13.644177	Training Loss1 4.6319 (4.5090)	Training Total_Loss 4.6319 (4.5090)	Training Prec@1 96.680 (96.574)	Training Prec@5 0.000 (0.000)	
2022-07-07 11:32:28,427: ============================================================
2022-07-07 11:33:42,180: time cost, forward:0.011988170054398712, backward:0.0332616713105225, data cost:0.6953287538694066 
2022-07-07 11:33:42,181: ============================================================
2022-07-07 11:33:42,181: Epoch 12/36 Batch 2500/7662 eta: 1 day, 14:43:52.027641	Training Loss1 4.5542 (4.5148)	Training Total_Loss 4.5542 (4.5148)	Training Prec@1 95.508 (96.561)	Training Prec@5 0.000 (0.000)	
2022-07-07 11:33:42,181: ============================================================
2022-07-07 11:34:56,416: time cost, forward:0.011986245554930983, backward:0.033260401508908126, data cost:0.6953808394428765 
2022-07-07 11:34:56,416: ============================================================
2022-07-07 11:34:56,416: Epoch 12/36 Batch 2600/7662 eta: 1 day, 14:57:48.188656	Training Loss1 4.5113 (4.5222)	Training Total_Loss 4.5113 (4.5222)	Training Prec@1 96.875 (96.541)	Training Prec@5 0.000 (0.000)	
2022-07-07 11:34:56,416: ============================================================
2022-07-07 11:36:10,218: time cost, forward:0.011993878150083436, backward:0.03325588582135342, data cost:0.6952583908195538 
2022-07-07 11:36:10,218: ============================================================
2022-07-07 11:36:10,219: Epoch 12/36 Batch 2700/7662 eta: 1 day, 14:42:56.581892	Training Loss1 4.7836 (4.5276)	Training Total_Loss 4.7836 (4.5276)	Training Prec@1 94.727 (96.521)	Training Prec@5 0.000 (0.000)	
2022-07-07 11:36:10,219: ============================================================
2022-07-07 11:37:26,006: time cost, forward:0.011983662683991885, backward:0.03326310937683171, data cost:0.6958648810091935 
2022-07-07 11:37:26,007: ============================================================
2022-07-07 11:37:26,007: Epoch 12/36 Batch 2800/7662 eta: 1 day, 15:44:10.824540	Training Loss1 4.9774 (4.5334)	Training Total_Loss 4.9774 (4.5334)	Training Prec@1 95.117 (96.507)	Training Prec@5 0.000 (0.000)	
2022-07-07 11:37:26,007: ============================================================
2022-07-07 11:38:39,767: time cost, forward:0.011969556065007053, backward:0.03326326100815572, data cost:0.6957346010553545 
2022-07-07 11:38:39,767: ============================================================
2022-07-07 11:38:39,767: Epoch 12/36 Batch 2900/7662 eta: 1 day, 14:39:10.233365	Training Loss1 4.7698 (4.5393)	Training Total_Loss 4.7698 (4.5393)	Training Prec@1 95.703 (96.488)	Training Prec@5 0.000 (0.000)	
2022-07-07 11:38:39,768: ============================================================
2022-07-07 11:39:54,127: time cost, forward:0.011986323856202394, backward:0.03326314685741398, data cost:0.6957849557895031 
2022-07-07 11:39:54,127: ============================================================
2022-07-07 11:39:54,127: Epoch 12/36 Batch 3000/7662 eta: 1 day, 14:56:46.375503	Training Loss1 4.5008 (4.5430)	Training Total_Loss 4.5008 (4.5430)	Training Prec@1 97.070 (96.475)	Training Prec@5 0.000 (0.000)	
2022-07-07 11:39:54,127: ============================================================
2022-07-07 11:41:07,927: time cost, forward:0.011968502116687993, backward:0.03325533728401058, data cost:0.6956885934991581 
2022-07-07 11:41:07,927: ============================================================
2022-07-07 11:41:07,928: Epoch 12/36 Batch 3100/7662 eta: 1 day, 14:37:57.496138	Training Loss1 4.7257 (4.5488)	Training Total_Loss 4.7257 (4.5488)	Training Prec@1 96.289 (96.462)	Training Prec@5 0.000 (0.000)	
2022-07-07 11:41:07,928: ============================================================
2022-07-07 11:42:21,709: time cost, forward:0.011958092069133962, backward:0.03326446341514289, data cost:0.6955840554077873 
2022-07-07 11:42:21,709: ============================================================
2022-07-07 11:42:21,709: Epoch 12/36 Batch 3200/7662 eta: 1 day, 14:36:08.750993	Training Loss1 4.5915 (4.5539)	Training Total_Loss 4.5915 (4.5539)	Training Prec@1 95.312 (96.450)	Training Prec@5 0.000 (0.000)	
2022-07-07 11:42:21,710: ============================================================
2022-07-07 11:43:36,949: time cost, forward:0.01195295805929646, backward:0.03325265803167986, data cost:0.6959357122899402 
2022-07-07 11:43:36,949: ============================================================
2022-07-07 11:43:36,949: Epoch 12/36 Batch 3300/7662 eta: 1 day, 15:20:39.913282	Training Loss1 4.8940 (4.5592)	Training Total_Loss 4.8940 (4.5592)	Training Prec@1 94.922 (96.431)	Training Prec@5 0.000 (0.000)	
2022-07-07 11:43:36,950: ============================================================
2022-07-07 11:44:52,066: time cost, forward:0.011958376454339023, backward:0.03324119986488946, data cost:0.6962181517361683 
2022-07-07 11:44:52,066: ============================================================
2022-07-07 11:44:52,066: Epoch 12/36 Batch 3400/7662 eta: 1 day, 15:15:33.447423	Training Loss1 4.3513 (4.5642)	Training Total_Loss 4.3513 (4.5642)	Training Prec@1 96.484 (96.415)	Training Prec@5 0.000 (0.000)	
2022-07-07 11:44:52,067: ============================================================
2022-07-07 11:46:05,741: time cost, forward:0.011971761376968823, backward:0.03324190001039377, data cost:0.6960529612622693 
2022-07-07 11:46:05,742: ============================================================
2022-07-07 11:46:05,742: Epoch 12/36 Batch 3500/7662 eta: 1 day, 14:29:07.625538	Training Loss1 4.7581 (4.5681)	Training Total_Loss 4.7581 (4.5681)	Training Prec@1 96.680 (96.405)	Training Prec@5 0.000 (0.000)	
2022-07-07 11:46:05,742: ============================================================
2022-07-07 11:47:19,283: time cost, forward:0.011975153117220944, backward:0.03324241073769508, data cost:0.6958703925192903 
2022-07-07 11:47:19,284: ============================================================
2022-07-07 11:47:19,284: Epoch 12/36 Batch 3600/7662 eta: 1 day, 14:23:42.550800	Training Loss1 4.4642 (4.5721)	Training Total_Loss 4.4642 (4.5721)	Training Prec@1 96.094 (96.393)	Training Prec@5 0.000 (0.000)	
2022-07-07 11:47:19,284: ============================================================
2022-07-07 11:48:32,538: time cost, forward:0.011949863972680637, backward:0.0332518617795525, data cost:0.6956368968692397 
2022-07-07 11:48:32,538: ============================================================
2022-07-07 11:48:32,538: Epoch 12/36 Batch 3700/7662 eta: 1 day, 14:13:28.870372	Training Loss1 4.5883 (4.5754)	Training Total_Loss 4.5883 (4.5754)	Training Prec@1 97.266 (96.380)	Training Prec@5 0.000 (0.000)	
2022-07-07 11:48:32,538: ============================================================
2022-07-07 11:49:46,389: time cost, forward:0.01195835427065591, backward:0.0332573809476864, data cost:0.6955442847813955 
2022-07-07 11:49:46,389: ============================================================
2022-07-07 11:49:46,389: Epoch 12/36 Batch 3800/7662 eta: 1 day, 14:30:56.738690	Training Loss1 4.9422 (4.5794)	Training Total_Loss 4.9422 (4.5794)	Training Prec@1 94.727 (96.365)	Training Prec@5 0.000 (0.000)	
2022-07-07 11:49:46,390: ============================================================
2022-07-07 11:50:59,784: time cost, forward:0.011951027542666063, backward:0.033269720830866, data cost:0.6953544836222866 
2022-07-07 11:50:59,784: ============================================================
2022-07-07 11:50:59,785: Epoch 12/36 Batch 3900/7662 eta: 1 day, 14:15:26.539104	Training Loss1 4.7185 (4.5833)	Training Total_Loss 4.7185 (4.5833)	Training Prec@1 96.484 (96.350)	Training Prec@5 0.000 (0.000)	
2022-07-07 11:50:59,785: ============================================================
2022-07-07 11:52:14,984: time cost, forward:0.011953168584275585, backward:0.03327584964211329, data cost:0.6956154411212896 
2022-07-07 11:52:14,985: ============================================================
2022-07-07 11:52:14,985: Epoch 12/36 Batch 4000/7662 eta: 1 day, 15:10:39.270996	Training Loss1 4.6944 (4.5870)	Training Total_Loss 4.6944 (4.5870)	Training Prec@1 95.703 (96.340)	Training Prec@5 0.000 (0.000)	
2022-07-07 11:52:14,985: ============================================================
2022-07-07 11:53:29,919: time cost, forward:0.011952852033702128, backward:0.033281635499401885, data cost:0.6958064448400136 
2022-07-07 11:53:29,919: ============================================================
2022-07-07 11:53:29,919: Epoch 12/36 Batch 4100/7662 eta: 1 day, 15:01:04.840295	Training Loss1 4.5629 (4.5907)	Training Total_Loss 4.5629 (4.5907)	Training Prec@1 96.680 (96.329)	Training Prec@5 0.000 (0.000)	
2022-07-07 11:53:29,919: ============================================================
2022-07-07 11:54:44,876: time cost, forward:0.011937015934994346, backward:0.03327701693064941, data cost:0.6960166222880527 
2022-07-07 11:54:44,876: ============================================================
2022-07-07 11:54:44,877: Epoch 12/36 Batch 4200/7662 eta: 1 day, 15:00:33.317580	Training Loss1 4.8199 (4.5939)	Training Total_Loss 4.8199 (4.5939)	Training Prec@1 94.336 (96.318)	Training Prec@5 0.000 (0.000)	
2022-07-07 11:54:44,877: ============================================================
2022-07-07 11:55:59,618: time cost, forward:0.011915180122444701, backward:0.0332779585413945, data cost:0.6961675833258193 
2022-07-07 11:55:59,618: ============================================================
2022-07-07 11:55:59,618: Epoch 12/36 Batch 4300/7662 eta: 1 day, 14:52:34.411789	Training Loss1 4.4902 (4.5977)	Training Total_Loss 4.4902 (4.5977)	Training Prec@1 96.875 (96.308)	Training Prec@5 0.000 (0.000)	
2022-07-07 11:55:59,618: ============================================================
2022-07-07 11:57:14,044: time cost, forward:0.011898924421521581, backward:0.03330262137098891, data cost:0.6962023201951333 
2022-07-07 11:57:14,044: ============================================================
2022-07-07 11:57:14,045: Epoch 12/36 Batch 4400/7662 eta: 1 day, 14:41:29.919089	Training Loss1 4.5781 (4.6013)	Training Total_Loss 4.5781 (4.6013)	Training Prec@1 95.703 (96.296)	Training Prec@5 0.000 (0.000)	
2022-07-07 11:57:14,045: ============================================================
2022-07-07 11:58:28,231: time cost, forward:0.011892813103653161, backward:0.03330780495853259, data cost:0.6962084530141254 
2022-07-07 11:58:28,232: ============================================================
2022-07-07 11:58:28,232: Epoch 12/36 Batch 4500/7662 eta: 1 day, 14:32:48.387933	Training Loss1 4.5505 (4.6053)	Training Total_Loss 4.5505 (4.6053)	Training Prec@1 95.703 (96.282)	Training Prec@5 0.000 (0.000)	
2022-07-07 11:58:28,232: ============================================================
2022-07-07 11:59:42,853: time cost, forward:0.011910932897147626, backward:0.03330323643776665, data cost:0.6962873175186187 
2022-07-07 11:59:42,854: ============================================================
2022-07-07 11:59:42,854: Epoch 12/36 Batch 4600/7662 eta: 1 day, 14:45:06.435223	Training Loss1 4.7624 (4.6089)	Training Total_Loss 4.7624 (4.6089)	Training Prec@1 94.531 (96.269)	Training Prec@5 0.000 (0.000)	
2022-07-07 11:59:42,854: ============================================================
2022-07-07 12:00:57,217: time cost, forward:0.011930100840186789, backward:0.03330729849466899, data cost:0.6962961613256694 
2022-07-07 12:00:57,217: ============================================================
2022-07-07 12:00:57,217: Epoch 12/36 Batch 4700/7662 eta: 1 day, 14:35:48.733336	Training Loss1 4.9947 (4.6121)	Training Total_Loss 4.9947 (4.6121)	Training Prec@1 95.312 (96.257)	Training Prec@5 0.000 (0.000)	
2022-07-07 12:00:57,218: ============================================================
2022-07-07 12:02:10,969: time cost, forward:0.011922667537736107, backward:0.03328631331111322, data cost:0.6962300139830793 
2022-07-07 12:02:10,970: ============================================================
2022-07-07 12:02:10,970: Epoch 12/36 Batch 4800/7662 eta: 1 day, 14:15:33.423186	Training Loss1 4.8206 (4.6153)	Training Total_Loss 4.8206 (4.6153)	Training Prec@1 94.336 (96.245)	Training Prec@5 0.000 (0.000)	
2022-07-07 12:02:10,970: ============================================================
2022-07-07 12:03:26,098: time cost, forward:0.011930740908910654, backward:0.03328223266414682, data cost:0.6964159126694432 
2022-07-07 12:03:26,099: ============================================================
2022-07-07 12:03:26,099: Epoch 12/36 Batch 4900/7662 eta: 1 day, 14:57:08.856585	Training Loss1 4.9853 (4.6182)	Training Total_Loss 4.9853 (4.6182)	Training Prec@1 96.094 (96.236)	Training Prec@5 0.000 (0.000)	
2022-07-07 12:03:26,099: ============================================================
2022-07-07 12:04:40,395: time cost, forward:0.011918319657126005, backward:0.03328603509665251, data cost:0.6964355746992447 
2022-07-07 12:04:40,395: ============================================================
2022-07-07 12:04:40,395: Epoch 12/36 Batch 5000/7662 eta: 1 day, 14:30:00.606576	Training Loss1 4.6808 (4.6206)	Training Total_Loss 4.6808 (4.6206)	Training Prec@1 96.289 (96.228)	Training Prec@5 0.000 (0.000)	
2022-07-07 12:04:40,395: ============================================================
2022-07-07 12:05:54,274: time cost, forward:0.01193734233719294, backward:0.033291038098721484, data cost:0.6963431469060132 
2022-07-07 12:05:54,275: ============================================================
2022-07-07 12:05:54,275: Epoch 12/36 Batch 5100/7662 eta: 1 day, 14:15:49.363775	Training Loss1 4.7050 (4.6229)	Training Total_Loss 4.7050 (4.6229)	Training Prec@1 96.094 (96.221)	Training Prec@5 0.000 (0.000)	
2022-07-07 12:05:54,275: ============================================================
2022-07-07 12:07:08,889: time cost, forward:0.011925716266239532, backward:0.03329150973432086, data cost:0.6964348687371695 
2022-07-07 12:07:08,890: ============================================================
2022-07-07 12:07:08,890: Epoch 12/36 Batch 5200/7662 eta: 1 day, 14:37:25.995935	Training Loss1 4.9474 (4.6259)	Training Total_Loss 4.9474 (4.6259)	Training Prec@1 95.508 (96.210)	Training Prec@5 0.000 (0.000)	
2022-07-07 12:07:08,890: ============================================================
2022-07-07 12:08:22,475: time cost, forward:0.011939382301139076, backward:0.033299484350114844, data cost:0.6962912276142564 
2022-07-07 12:08:22,476: ============================================================
2022-07-07 12:08:22,476: Epoch 12/36 Batch 5300/7662 eta: 1 day, 14:04:14.832202	Training Loss1 4.6409 (4.6290)	Training Total_Loss 4.6409 (4.6290)	Training Prec@1 95.898 (96.199)	Training Prec@5 0.000 (0.000)	
2022-07-07 12:08:22,476: ============================================================
2022-07-07 12:09:37,076: time cost, forward:0.01194826451291153, backward:0.03329052817360033, data cost:0.696366232575079 
2022-07-07 12:09:37,076: ============================================================
2022-07-07 12:09:37,077: Epoch 12/36 Batch 5400/7662 eta: 1 day, 14:34:29.837032	Training Loss1 5.1406 (4.6320)	Training Total_Loss 5.1406 (4.6320)	Training Prec@1 95.898 (96.188)	Training Prec@5 0.000 (0.000)	
2022-07-07 12:09:37,077: ============================================================
2022-07-07 12:10:52,096: time cost, forward:0.011972911099040046, backward:0.03330010521474763, data cost:0.6964770591265507 
2022-07-07 12:10:52,096: ============================================================
2022-07-07 12:10:52,096: Epoch 12/36 Batch 5500/7662 eta: 1 day, 14:46:15.014366	Training Loss1 4.8592 (4.6349)	Training Total_Loss 4.8592 (4.6349)	Training Prec@1 95.898 (96.177)	Training Prec@5 0.000 (0.000)	
2022-07-07 12:10:52,097: ============================================================
2022-07-07 12:12:07,519: time cost, forward:0.01197410536825838, backward:0.033301036812233314, data cost:0.6966860945426177 
2022-07-07 12:12:07,519: ============================================================
2022-07-07 12:12:07,520: Epoch 12/36 Batch 5600/7662 eta: 1 day, 14:57:30.032612	Training Loss1 5.0049 (4.6373)	Training Total_Loss 5.0049 (4.6373)	Training Prec@1 94.727 (96.169)	Training Prec@5 0.000 (0.000)	
2022-07-07 12:12:07,520: ============================================================
2022-07-07 12:13:22,999: time cost, forward:0.011979186256677776, backward:0.03330536239250519, data cost:0.6968921795082126 
2022-07-07 12:13:23,000: ============================================================
2022-07-07 12:13:23,000: Epoch 12/36 Batch 5700/7662 eta: 1 day, 14:58:00.948534	Training Loss1 4.7880 (4.6394)	Training Total_Loss 4.7880 (4.6394)	Training Prec@1 95.703 (96.162)	Training Prec@5 0.000 (0.000)	
2022-07-07 12:13:23,000: ============================================================
2022-07-07 12:14:37,425: time cost, forward:0.011972213617829047, backward:0.03330690997657046, data cost:0.6969232589217131 
2022-07-07 12:14:37,426: ============================================================
2022-07-07 12:14:37,426: Epoch 12/36 Batch 5800/7662 eta: 1 day, 14:24:06.928763	Training Loss1 5.0848 (4.6424)	Training Total_Loss 5.0848 (4.6424)	Training Prec@1 93.164 (96.150)	Training Prec@5 0.000 (0.000)	
2022-07-07 12:14:37,426: ============================================================
2022-07-07 12:15:51,695: time cost, forward:0.01197291924036404, backward:0.03331617594452344, data cost:0.6969115760775416 
2022-07-07 12:15:51,695: ============================================================
2022-07-07 12:15:51,695: Epoch 12/36 Batch 5900/7662 eta: 1 day, 14:18:02.368250	Training Loss1 4.4655 (4.6442)	Training Total_Loss 4.4655 (4.6442)	Training Prec@1 95.898 (96.140)	Training Prec@5 0.000 (0.000)	
2022-07-07 12:15:51,696: ============================================================
2022-07-07 12:17:05,440: time cost, forward:0.011979458748966401, backward:0.033323852156257404, data cost:0.6968069810592288 
2022-07-07 12:17:05,441: ============================================================
2022-07-07 12:17:05,441: Epoch 12/36 Batch 6000/7662 eta: 1 day, 14:00:35.639391	Training Loss1 5.0738 (4.6462)	Training Total_Loss 5.0738 (4.6462)	Training Prec@1 95.703 (96.134)	Training Prec@5 0.000 (0.000)	
2022-07-07 12:17:05,441: ============================================================
2022-07-07 12:18:19,888: time cost, forward:0.011980325516217418, backward:0.03331648398469874, data cost:0.6968436637536916 
2022-07-07 12:18:19,888: ============================================================
2022-07-07 12:18:19,888: Epoch 12/36 Batch 6100/7662 eta: 1 day, 14:21:02.965561	Training Loss1 4.7644 (4.6485)	Training Total_Loss 4.7644 (4.6485)	Training Prec@1 95.898 (96.126)	Training Prec@5 0.000 (0.000)	
2022-07-07 12:18:19,888: ============================================================
2022-07-07 12:19:35,629: time cost, forward:0.011988306799364159, backward:0.03330086392536339, data cost:0.6970880592728953 
2022-07-07 12:19:35,630: ============================================================
2022-07-07 12:19:35,630: Epoch 12/36 Batch 6200/7662 eta: 1 day, 14:59:47.963334	Training Loss1 4.7004 (4.6506)	Training Total_Loss 4.7004 (4.6506)	Training Prec@1 96.680 (96.118)	Training Prec@5 0.000 (0.000)	
2022-07-07 12:19:35,630: ============================================================
2022-07-07 12:20:49,926: time cost, forward:0.011987365490104457, backward:0.033308504308702684, data cost:0.6970822870930068 
2022-07-07 12:20:49,927: ============================================================
2022-07-07 12:20:49,927: Epoch 12/36 Batch 6300/7662 eta: 1 day, 14:13:56.102737	Training Loss1 4.4078 (4.6527)	Training Total_Loss 4.4078 (4.6527)	Training Prec@1 96.484 (96.110)	Training Prec@5 0.000 (0.000)	
2022-07-07 12:20:49,927: ============================================================
2022-07-07 12:22:05,169: time cost, forward:0.011998736163492705, backward:0.03329644979657857, data cost:0.6972199107803653 
2022-07-07 12:22:05,169: ============================================================
2022-07-07 12:22:05,169: Epoch 12/36 Batch 6400/7662 eta: 1 day, 14:41:51.711136	Training Loss1 4.5701 (4.6547)	Training Total_Loss 4.5701 (4.6547)	Training Prec@1 97.461 (96.104)	Training Prec@5 0.000 (0.000)	
2022-07-07 12:22:05,169: ============================================================
2022-07-07 12:23:20,096: time cost, forward:0.011996836749603793, backward:0.03329718892510845, data cost:0.6973265532182352 
2022-07-07 12:23:20,097: ============================================================
2022-07-07 12:23:20,097: Epoch 12/36 Batch 6500/7662 eta: 1 day, 14:30:54.170546	Training Loss1 4.8442 (4.6570)	Training Total_Loss 4.8442 (4.6570)	Training Prec@1 95.703 (96.094)	Training Prec@5 0.000 (0.000)	
2022-07-07 12:23:20,097: ============================================================
2022-07-07 12:24:35,447: time cost, forward:0.012005022717779524, backward:0.033314540975472116, data cost:0.6974543263865594 
2022-07-07 12:24:35,448: ============================================================
2022-07-07 12:24:35,448: Epoch 12/36 Batch 6600/7662 eta: 1 day, 14:42:42.895115	Training Loss1 4.7852 (4.6585)	Training Total_Loss 4.7852 (4.6585)	Training Prec@1 95.508 (96.090)	Training Prec@5 0.000 (0.000)	
2022-07-07 12:24:35,448: ============================================================
2022-07-07 12:25:50,644: time cost, forward:0.012001528706474435, backward:0.033315328470467274, data cost:0.6975855431212901 
2022-07-07 12:25:50,645: ============================================================
2022-07-07 12:25:50,645: Epoch 12/36 Batch 6700/7662 eta: 1 day, 14:36:42.239046	Training Loss1 4.7777 (4.6603)	Training Total_Loss 4.7777 (4.6603)	Training Prec@1 96.094 (96.083)	Training Prec@5 0.000 (0.000)	
2022-07-07 12:25:50,645: ============================================================
2022-07-07 12:27:04,420: time cost, forward:0.011997643700942062, backward:0.03332178482923074, data cost:0.6974979399723031 
2022-07-07 12:27:04,420: ============================================================
2022-07-07 12:27:04,420: Epoch 12/36 Batch 6800/7662 eta: 1 day, 13:51:40.849018	Training Loss1 4.9457 (4.6624)	Training Total_Loss 4.9457 (4.6624)	Training Prec@1 94.727 (96.075)	Training Prec@5 0.000 (0.000)	
2022-07-07 12:27:04,420: ============================================================
2022-07-07 12:28:19,773: time cost, forward:0.011999239799232998, backward:0.03332040700070632, data cost:0.6976447040092291 
2022-07-07 12:28:19,774: ============================================================
2022-07-07 12:28:19,774: Epoch 12/36 Batch 6900/7662 eta: 1 day, 14:39:01.242019	Training Loss1 4.9877 (4.6647)	Training Total_Loss 4.9877 (4.6647)	Training Prec@1 93.359 (96.064)	Training Prec@5 0.000 (0.000)	
2022-07-07 12:28:19,774: ============================================================
2022-07-07 12:29:34,389: time cost, forward:0.012005676148806084, backward:0.03332770908027057, data cost:0.697668594672929 
2022-07-07 12:29:34,389: ============================================================
2022-07-07 12:29:34,389: Epoch 12/36 Batch 7000/7662 eta: 1 day, 14:15:03.087711	Training Loss1 4.7071 (4.6665)	Training Total_Loss 4.7071 (4.6665)	Training Prec@1 96.094 (96.059)	Training Prec@5 0.000 (0.000)	
2022-07-07 12:29:34,389: ============================================================
2022-07-07 12:30:49,027: time cost, forward:0.012014725054128185, backward:0.03333632239725812, data cost:0.6976870628020548 
2022-07-07 12:30:49,027: ============================================================
2022-07-07 12:30:49,028: Epoch 12/36 Batch 7100/7662 eta: 1 day, 14:14:31.274888	Training Loss1 4.6659 (4.6680)	Training Total_Loss 4.6659 (4.6680)	Training Prec@1 96.289 (96.051)	Training Prec@5 0.000 (0.000)	
2022-07-07 12:30:49,028: ============================================================
2022-07-07 12:32:03,468: time cost, forward:0.012003849605534338, backward:0.03332586281166124, data cost:0.6977196672688359 
2022-07-07 12:32:03,468: ============================================================
2022-07-07 12:32:03,468: Epoch 12/36 Batch 7200/7662 eta: 1 day, 14:07:12.449222	Training Loss1 4.6677 (4.6699)	Training Total_Loss 4.6677 (4.6699)	Training Prec@1 97.070 (96.043)	Training Prec@5 0.000 (0.000)	
2022-07-07 12:32:03,469: ============================================================
2022-07-07 12:33:18,785: time cost, forward:0.011995321790687612, backward:0.033322910426952915, data cost:0.6978620731237736 
2022-07-07 12:33:18,785: ============================================================
2022-07-07 12:33:18,785: Epoch 12/36 Batch 7300/7662 eta: 1 day, 14:32:51.979788	Training Loss1 4.7488 (4.6715)	Training Total_Loss 4.7488 (4.6715)	Training Prec@1 95.703 (96.035)	Training Prec@5 0.000 (0.000)	
2022-07-07 12:33:18,785: ============================================================
2022-07-07 12:34:32,271: time cost, forward:0.011987579273265637, backward:0.03332257489929941, data cost:0.6977510506083053 
2022-07-07 12:34:32,271: ============================================================
2022-07-07 12:34:32,271: Epoch 12/36 Batch 7400/7662 eta: 1 day, 13:35:24.845707	Training Loss1 4.6668 (4.6732)	Training Total_Loss 4.6668 (4.6732)	Training Prec@1 95.117 (96.029)	Training Prec@5 0.000 (0.000)	
2022-07-07 12:34:32,271: ============================================================
2022-07-07 12:35:46,514: time cost, forward:0.011993207332531218, backward:0.03331695748799832, data cost:0.6977348898645878 
2022-07-07 12:35:46,514: ============================================================
2022-07-07 12:35:46,514: Epoch 12/36 Batch 7500/7662 eta: 1 day, 13:57:25.669410	Training Loss1 4.7890 (4.6749)	Training Total_Loss 4.7890 (4.6749)	Training Prec@1 96.484 (96.020)	Training Prec@5 0.000 (0.000)	
2022-07-07 12:35:46,515: ============================================================
2022-07-07 12:37:00,232: time cost, forward:0.011999820844015489, backward:0.033327367152331894, data cost:0.6976324581350052 
2022-07-07 12:37:00,232: ============================================================
2022-07-07 12:37:00,232: Epoch 12/36 Batch 7600/7662 eta: 1 day, 13:40:04.552470	Training Loss1 4.6115 (4.6765)	Training Total_Loss 4.6115 (4.6765)	Training Prec@1 97.070 (96.013)	Training Prec@5 0.000 (0.000)	
2022-07-07 12:37:00,232: ============================================================
2022-07-07 12:37:48,385: Epoch 12/36 Batch 7663/7662 eta: 1 day, 13:39:18.110283	Training Loss1 4.6252 (4.6776)	Training Total_Loss 4.6252 (4.6776)	Training Prec@1 96.289 (96.008)	Training Prec@5 0.000 (0.000)	
2022-07-07 12:37:48,386: ============================================================
2022-07-07 12:39:13,763: time cost, forward:0.012639977715232155, backward:0.03223065896467729, data cost:0.8113883649459993 
2022-07-07 12:39:13,764: ============================================================
2022-07-07 12:39:13,764: Epoch 13/36 Batch 100/7662 eta: 1 day, 19:33:12.031109	Training Loss1 4.3049 (4.2523)	Training Total_Loss 4.3049 (4.2523)	Training Prec@1 97.656 (97.086)	Training Prec@5 0.000 (0.000)	
2022-07-07 12:39:13,764: ============================================================
2022-07-07 12:40:26,901: time cost, forward:0.012012910603278845, backward:0.03266213287660225, data cost:0.748327188156358 
2022-07-07 12:40:26,902: ============================================================
2022-07-07 12:40:26,902: Epoch 13/36 Batch 200/7662 eta: 1 day, 13:19:06.182306	Training Loss1 4.1742 (4.2661)	Training Total_Loss 4.1742 (4.2661)	Training Prec@1 96.875 (97.090)	Training Prec@5 0.000 (0.000)	
2022-07-07 12:40:26,902: ============================================================
2022-07-07 12:41:40,349: time cost, forward:0.012200140235416069, backward:0.03302969103274138, data cost:0.7280585957211395 
2022-07-07 12:41:40,350: ============================================================
2022-07-07 12:41:40,350: Epoch 13/36 Batch 300/7662 eta: 1 day, 13:27:22.428064	Training Loss1 4.2243 (4.2778)	Training Total_Loss 4.2243 (4.2778)	Training Prec@1 95.898 (97.098)	Training Prec@5 0.000 (0.000)	
2022-07-07 12:41:40,350: ============================================================
2022-07-07 12:42:53,743: time cost, forward:0.01210645864481914, backward:0.03319886573275229, data cost:0.7180046491455614 
2022-07-07 12:42:53,743: ============================================================
2022-07-07 12:42:53,743: Epoch 13/36 Batch 400/7662 eta: 1 day, 13:24:28.978818	Training Loss1 4.2500 (4.2938)	Training Total_Loss 4.2500 (4.2938)	Training Prec@1 98.242 (97.074)	Training Prec@5 0.000 (0.000)	
2022-07-07 12:42:53,743: ============================================================
2022-07-07 12:44:07,282: time cost, forward:0.012155648462758035, backward:0.03336305608730278, data cost:0.7120326640371808 
2022-07-07 12:44:07,282: ============================================================
2022-07-07 12:44:07,282: Epoch 13/36 Batch 500/7662 eta: 1 day, 13:27:42.403980	Training Loss1 4.2422 (4.3089)	Training Total_Loss 4.2422 (4.3089)	Training Prec@1 97.656 (97.070)	Training Prec@5 0.000 (0.000)	
2022-07-07 12:44:07,282: ============================================================
2022-07-07 12:45:21,313: time cost, forward:0.012231043065728647, backward:0.0335273909847406, data cost:0.7088126407839818 
2022-07-07 12:45:21,313: ============================================================
2022-07-07 12:45:21,314: Epoch 13/36 Batch 600/7662 eta: 1 day, 13:41:31.438902	Training Loss1 4.4085 (4.3247)	Training Total_Loss 4.4085 (4.3247)	Training Prec@1 97.070 (97.042)	Training Prec@5 0.000 (0.000)	
2022-07-07 12:45:21,314: ============================================================
2022-07-07 12:46:33,858: time cost, forward:0.012303095859860487, backward:0.03359301407449747, data cost:0.7044397420296512 
2022-07-07 12:46:33,858: ============================================================
2022-07-07 12:46:33,858: Epoch 13/36 Batch 700/7662 eta: 1 day, 12:54:53.532519	Training Loss1 4.1908 (4.3393)	Training Total_Loss 4.1908 (4.3393)	Training Prec@1 96.680 (97.013)	Training Prec@5 0.000 (0.000)	
2022-07-07 12:46:33,858: ============================================================
2022-07-07 12:47:46,703: time cost, forward:0.0122321016051444, backward:0.033567612102541965, data cost:0.7017006754725985 
2022-07-07 12:47:46,703: ============================================================
2022-07-07 12:47:46,703: Epoch 13/36 Batch 800/7662 eta: 1 day, 13:02:51.369805	Training Loss1 4.3906 (4.3533)	Training Total_Loss 4.3906 (4.3533)	Training Prec@1 97.070 (96.976)	Training Prec@5 0.000 (0.000)	
2022-07-07 12:47:46,703: ============================================================
2022-07-07 12:49:00,206: time cost, forward:0.012153844546953483, backward:0.033524838915391014, data cost:0.7003779721604836 
2022-07-07 12:49:00,207: ============================================================
2022-07-07 12:49:00,207: Epoch 13/36 Batch 900/7662 eta: 1 day, 13:21:43.751504	Training Loss1 4.4477 (4.3665)	Training Total_Loss 4.4477 (4.3665)	Training Prec@1 96.680 (96.946)	Training Prec@5 0.000 (0.000)	
2022-07-07 12:49:00,207: ============================================================
2022-07-07 12:50:13,881: time cost, forward:0.01207822173446029, backward:0.033518161859598244, data cost:0.6994679606593288 
2022-07-07 12:50:13,881: ============================================================
2022-07-07 12:50:13,881: Epoch 13/36 Batch 1000/7662 eta: 1 day, 13:25:42.304252	Training Loss1 4.0598 (4.3780)	Training Total_Loss 4.0598 (4.3780)	Training Prec@1 97.852 (96.925)	Training Prec@5 0.000 (0.000)	
2022-07-07 12:50:13,881: ============================================================
2022-07-07 12:51:27,118: time cost, forward:0.011998582688974618, backward:0.03350096447452618, data cost:0.698334133549101 
2022-07-07 12:51:27,119: ============================================================
2022-07-07 12:51:27,119: Epoch 13/36 Batch 1100/7662 eta: 1 day, 13:11:10.197073	Training Loss1 4.5527 (4.3931)	Training Total_Loss 4.5527 (4.3931)	Training Prec@1 96.484 (96.897)	Training Prec@5 0.000 (0.000)	
2022-07-07 12:51:27,119: ============================================================
2022-07-07 12:52:39,108: time cost, forward:0.011947136505928707, backward:0.03350450915033565, data cost:0.6963440737593065 
2022-07-07 12:52:39,108: ============================================================
2022-07-07 12:52:39,108: Epoch 13/36 Batch 1200/7662 eta: 1 day, 12:31:56.622897	Training Loss1 4.3692 (4.4059)	Training Total_Loss 4.3692 (4.4059)	Training Prec@1 96.680 (96.863)	Training Prec@5 0.000 (0.000)	
2022-07-07 12:52:39,108: ============================================================
2022-07-07 12:53:52,307: time cost, forward:0.011919689692379054, backward:0.03348892482085077, data cost:0.695601767443803 
2022-07-07 12:53:52,307: ============================================================
2022-07-07 12:53:52,307: Epoch 13/36 Batch 1300/7662 eta: 1 day, 13:07:33.111632	Training Loss1 4.5660 (4.4187)	Training Total_Loss 4.5660 (4.4187)	Training Prec@1 96.484 (96.826)	Training Prec@5 0.000 (0.000)	
2022-07-07 12:53:52,307: ============================================================
2022-07-07 12:55:05,865: time cost, forward:0.01192280767303096, backward:0.03347942742217516, data cost:0.6951746761671043 
2022-07-07 12:55:05,866: ============================================================
2022-07-07 12:55:05,866: Epoch 13/36 Batch 1400/7662 eta: 1 day, 13:17:16.713713	Training Loss1 4.7583 (4.4284)	Training Total_Loss 4.7583 (4.4284)	Training Prec@1 96.289 (96.802)	Training Prec@5 0.000 (0.000)	
2022-07-07 12:55:05,866: ============================================================
2022-07-07 12:56:19,609: time cost, forward:0.011970104735401808, backward:0.03342451995177775, data cost:0.6949418416573574 
2022-07-07 12:56:19,609: ============================================================
2022-07-07 12:56:19,609: Epoch 13/36 Batch 1500/7662 eta: 1 day, 13:21:39.230343	Training Loss1 4.6026 (4.4395)	Training Total_Loss 4.6026 (4.4395)	Training Prec@1 96.484 (96.774)	Training Prec@5 0.000 (0.000)	
2022-07-07 12:56:19,609: ============================================================
2022-07-07 12:57:33,675: time cost, forward:0.012004470139313222, backward:0.03335177831309821, data cost:0.6949601325487778 
2022-07-07 12:57:33,675: ============================================================
2022-07-07 12:57:33,675: Epoch 13/36 Batch 1600/7662 eta: 1 day, 13:30:14.569250	Training Loss1 4.5145 (4.4481)	Training Total_Loss 4.5145 (4.4481)	Training Prec@1 95.508 (96.752)	Training Prec@5 0.000 (0.000)	
2022-07-07 12:57:33,675: ============================================================
2022-07-07 12:58:47,924: time cost, forward:0.012008295541935068, backward:0.03331551389037475, data cost:0.6950826772596641 
2022-07-07 12:58:47,924: ============================================================
2022-07-07 12:58:47,925: Epoch 13/36 Batch 1700/7662 eta: 1 day, 13:34:34.221810	Training Loss1 4.7926 (4.4557)	Training Total_Loss 4.7926 (4.4557)	Training Prec@1 96.094 (96.735)	Training Prec@5 0.000 (0.000)	
2022-07-07 12:58:47,925: ============================================================
2022-07-07 13:00:01,432: time cost, forward:0.012005730560582635, backward:0.0333269597955251, data cost:0.6947508017310439 
2022-07-07 13:00:01,432: ============================================================
2022-07-07 13:00:01,432: Epoch 13/36 Batch 1800/7662 eta: 1 day, 13:10:49.111494	Training Loss1 4.5245 (4.4628)	Training Total_Loss 4.5245 (4.4628)	Training Prec@1 96.484 (96.716)	Training Prec@5 0.000 (0.000)	
2022-07-07 13:00:01,432: ============================================================
2022-07-07 13:01:15,494: time cost, forward:0.012047938386536448, backward:0.03327240160479553, data cost:0.6947487072294295 
2022-07-07 13:01:15,494: ============================================================
2022-07-07 13:01:15,494: Epoch 13/36 Batch 1900/7662 eta: 1 day, 13:26:24.973109	Training Loss1 4.8746 (4.4718)	Training Total_Loss 4.8746 (4.4718)	Training Prec@1 94.727 (96.691)	Training Prec@5 0.000 (0.000)	
2022-07-07 13:01:15,494: ============================================================
2022-07-07 13:02:29,282: time cost, forward:0.01207122867139594, backward:0.033247120562883065, data cost:0.694617024775205 
2022-07-07 13:02:29,283: ============================================================
2022-07-07 13:02:29,283: Epoch 13/36 Batch 2000/7662 eta: 1 day, 13:16:53.510952	Training Loss1 4.6947 (4.4808)	Training Total_Loss 4.6947 (4.4808)	Training Prec@1 97.070 (96.668)	Training Prec@5 0.000 (0.000)	
2022-07-07 13:02:29,283: ============================================================
2022-07-07 13:03:43,008: time cost, forward:0.01204521250531695, backward:0.033237441146072744, data cost:0.694498663689194 
2022-07-07 13:03:43,008: ============================================================
2022-07-07 13:03:43,009: Epoch 13/36 Batch 2100/7662 eta: 1 day, 13:13:45.157550	Training Loss1 4.6087 (4.4873)	Training Total_Loss 4.6087 (4.4873)	Training Prec@1 96.484 (96.653)	Training Prec@5 0.000 (0.000)	
2022-07-07 13:03:43,009: ============================================================
2022-07-07 13:04:57,532: time cost, forward:0.012076856874237823, backward:0.03327151426893844, data cost:0.6946580377477253 
2022-07-07 13:04:57,533: ============================================================
2022-07-07 13:04:57,533: Epoch 13/36 Batch 2200/7662 eta: 1 day, 13:36:42.067476	Training Loss1 4.3413 (4.4941)	Training Total_Loss 4.3413 (4.4941)	Training Prec@1 96.484 (96.631)	Training Prec@5 0.000 (0.000)	
2022-07-07 13:04:57,533: ============================================================
2022-07-07 13:06:10,851: time cost, forward:0.012102882568604948, backward:0.03324292845806903, data cost:0.694337403686112 
2022-07-07 13:06:10,852: ============================================================
2022-07-07 13:06:10,852: Epoch 13/36 Batch 2300/7662 eta: 1 day, 12:58:59.697406	Training Loss1 4.5671 (4.4989)	Training Total_Loss 4.5671 (4.4989)	Training Prec@1 96.289 (96.613)	Training Prec@5 0.000 (0.000)	
2022-07-07 13:06:10,852: ============================================================
2022-07-07 13:07:24,718: time cost, forward:0.012092860652387714, backward:0.03323346239768152, data cost:0.6942890590804475 
2022-07-07 13:07:24,718: ============================================================
2022-07-07 13:07:24,718: Epoch 13/36 Batch 2400/7662 eta: 1 day, 13:14:19.207236	Training Loss1 4.8161 (4.5064)	Training Total_Loss 4.8161 (4.5064)	Training Prec@1 95.508 (96.594)	Training Prec@5 0.000 (0.000)	
2022-07-07 13:07:24,718: ============================================================
2022-07-07 13:08:37,410: time cost, forward:0.012067369004639209, backward:0.03325529363738293, data cost:0.6937633415564102 
2022-07-07 13:08:37,410: ============================================================
2022-07-07 13:08:37,411: Epoch 13/36 Batch 2500/7662 eta: 1 day, 12:37:35.595744	Training Loss1 4.7478 (4.5129)	Training Total_Loss 4.7478 (4.5129)	Training Prec@1 95.703 (96.576)	Training Prec@5 0.000 (0.000)	
2022-07-07 13:08:37,411: ============================================================
2022-07-07 13:09:50,967: time cost, forward:0.012070899011539285, backward:0.0332847240568354, data cost:0.6935775435947831 
2022-07-07 13:09:50,967: ============================================================
2022-07-07 13:09:50,968: Epoch 13/36 Batch 2600/7662 eta: 1 day, 13:02:31.040477	Training Loss1 4.8170 (4.5177)	Training Total_Loss 4.8170 (4.5177)	Training Prec@1 94.141 (96.563)	Training Prec@5 0.000 (0.000)	
2022-07-07 13:09:50,968: ============================================================
2022-07-07 13:11:04,490: time cost, forward:0.012106196356508721, backward:0.033321910453929245, data cost:0.6933391969616478 
2022-07-07 13:11:04,490: ============================================================
2022-07-07 13:11:04,490: Epoch 13/36 Batch 2700/7662 eta: 1 day, 13:00:14.527510	Training Loss1 4.7223 (4.5239)	Training Total_Loss 4.7223 (4.5239)	Training Prec@1 96.289 (96.545)	Training Prec@5 0.000 (0.000)	
2022-07-07 13:11:04,490: ============================================================
2022-07-07 13:12:16,847: time cost, forward:0.012095673504196009, backward:0.033339650940154016, data cost:0.6927708540272823 
2022-07-07 13:12:16,848: ============================================================
2022-07-07 13:12:16,848: Epoch 13/36 Batch 2800/7662 eta: 1 day, 12:23:51.952987	Training Loss1 4.5918 (4.5294)	Training Total_Loss 4.5918 (4.5294)	Training Prec@1 97.656 (96.529)	Training Prec@5 0.000 (0.000)	
2022-07-07 13:12:16,848: ============================================================
2022-07-07 13:13:30,872: time cost, forward:0.012100820337422514, backward:0.033341115489010975, data cost:0.6928116220077509 
2022-07-07 13:13:30,872: ============================================================
2022-07-07 13:13:30,872: Epoch 13/36 Batch 2900/7662 eta: 1 day, 13:12:55.631654	Training Loss1 4.4617 (4.5338)	Training Total_Loss 4.4617 (4.5338)	Training Prec@1 96.289 (96.511)	Training Prec@5 0.000 (0.000)	
2022-07-07 13:13:30,872: ============================================================
2022-07-07 13:14:45,708: time cost, forward:0.012109234158934733, backward:0.0333400355374348, data cost:0.6931208593521805 
2022-07-07 13:14:45,708: ============================================================
2022-07-07 13:14:45,708: Epoch 13/36 Batch 3000/7662 eta: 1 day, 13:36:10.702229	Training Loss1 4.7044 (4.5379)	Training Total_Loss 4.7044 (4.5379)	Training Prec@1 96.875 (96.499)	Training Prec@5 0.000 (0.000)	
2022-07-07 13:14:45,708: ============================================================
2022-07-07 13:15:58,563: time cost, forward:0.012097153905208128, backward:0.03336032977908917, data cost:0.6927737925813521 
2022-07-07 13:15:58,563: ============================================================
2022-07-07 13:15:58,564: Epoch 13/36 Batch 3100/7662 eta: 1 day, 12:35:14.200122	Training Loss1 4.4729 (4.5424)	Training Total_Loss 4.4729 (4.5424)	Training Prec@1 96.094 (96.483)	Training Prec@5 0.000 (0.000)	
2022-07-07 13:15:58,564: ============================================================
2022-07-07 13:17:12,157: time cost, forward:0.012097936229580601, backward:0.03336710876209656, data cost:0.6926741254221614 
2022-07-07 13:17:12,157: ============================================================
2022-07-07 13:17:12,157: Epoch 13/36 Batch 3200/7662 eta: 1 day, 12:56:15.690745	Training Loss1 5.1095 (4.5472)	Training Total_Loss 5.1095 (4.5472)	Training Prec@1 95.117 (96.467)	Training Prec@5 0.000 (0.000)	
2022-07-07 13:17:12,157: ============================================================
2022-07-07 13:18:27,082: time cost, forward:0.012105491964265627, backward:0.03338705188905011, data cost:0.6929644459339661 
2022-07-07 13:18:27,082: ============================================================
2022-07-07 13:18:27,082: Epoch 13/36 Batch 3300/7662 eta: 1 day, 13:35:06.175983	Training Loss1 4.4930 (4.5512)	Training Total_Loss 4.4930 (4.5512)	Training Prec@1 96.484 (96.452)	Training Prec@5 0.000 (0.000)	
2022-07-07 13:18:27,082: ============================================================
2022-07-07 13:19:40,043: time cost, forward:0.012094963715685995, backward:0.03339441259596831, data cost:0.6926878698084697 
2022-07-07 13:19:40,044: ============================================================
2022-07-07 13:19:40,044: Epoch 13/36 Batch 3400/7662 eta: 1 day, 12:34:47.825002	Training Loss1 4.5639 (4.5550)	Training Total_Loss 4.5639 (4.5550)	Training Prec@1 97.656 (96.439)	Training Prec@5 0.000 (0.000)	
2022-07-07 13:19:40,044: ============================================================
2022-07-07 13:20:53,540: time cost, forward:0.01208239815922661, backward:0.03340091716224516, data cost:0.692586704198549 
2022-07-07 13:20:53,540: ============================================================
2022-07-07 13:20:53,541: Epoch 13/36 Batch 3500/7662 eta: 1 day, 12:49:40.024182	Training Loss1 4.6050 (4.5601)	Training Total_Loss 4.6050 (4.5601)	Training Prec@1 97.461 (96.425)	Training Prec@5 0.000 (0.000)	
2022-07-07 13:20:53,541: ============================================================
2022-07-07 13:22:08,033: time cost, forward:0.012102484139974796, backward:0.03338174801397469, data cost:0.6927609477449901 
2022-07-07 13:22:08,033: ============================================================
2022-07-07 13:22:08,033: Epoch 13/36 Batch 3600/7662 eta: 1 day, 13:18:21.908959	Training Loss1 4.7693 (4.5639)	Training Total_Loss 4.7693 (4.5639)	Training Prec@1 96.289 (96.413)	Training Prec@5 0.000 (0.000)	
2022-07-07 13:22:08,033: ============================================================
2022-07-07 13:23:21,483: time cost, forward:0.012114924590437436, backward:0.03338702706653835, data cost:0.6926249881537098 
2022-07-07 13:23:21,483: ============================================================
2022-07-07 13:23:21,483: Epoch 13/36 Batch 3700/7662 eta: 1 day, 12:45:48.751849	Training Loss1 4.4336 (4.5673)	Training Total_Loss 4.4336 (4.5673)	Training Prec@1 96.875 (96.404)	Training Prec@5 0.000 (0.000)	
2022-07-07 13:23:21,483: ============================================================
2022-07-07 13:24:35,715: time cost, forward:0.012116037503328094, backward:0.033376340898723156, data cost:0.6927296301351469 
2022-07-07 13:24:35,716: ============================================================
2022-07-07 13:24:35,716: Epoch 13/36 Batch 3800/7662 eta: 1 day, 13:08:04.743532	Training Loss1 4.6403 (4.5712)	Training Total_Loss 4.6403 (4.5712)	Training Prec@1 96.094 (96.388)	Training Prec@5 0.000 (0.000)	
2022-07-07 13:24:35,716: ============================================================
2022-07-07 13:25:49,796: time cost, forward:0.012125693764188834, backward:0.03333684119483574, data cost:0.6928102554312484 
2022-07-07 13:25:49,797: ============================================================
2022-07-07 13:25:49,797: Epoch 13/36 Batch 3900/7662 eta: 1 day, 13:02:18.038753	Training Loss1 4.5077 (4.5752)	Training Total_Loss 4.5077 (4.5752)	Training Prec@1 96.289 (96.373)	Training Prec@5 0.000 (0.000)	
2022-07-07 13:25:49,797: ============================================================
2022-07-07 13:27:04,408: time cost, forward:0.012119836227748954, backward:0.03335188650792764, data cost:0.692983583618206 
2022-07-07 13:27:04,409: ============================================================
2022-07-07 13:27:04,409: Epoch 13/36 Batch 4000/7662 eta: 1 day, 13:16:58.706033	Training Loss1 4.5722 (4.5791)	Training Total_Loss 4.5722 (4.5791)	Training Prec@1 96.094 (96.358)	Training Prec@5 0.000 (0.000)	
2022-07-07 13:27:04,409: ============================================================
2022-07-07 13:28:18,074: time cost, forward:0.012134110238325831, backward:0.033366843065595474, data cost:0.6928943995587213 
2022-07-07 13:28:18,074: ============================================================
2022-07-07 13:28:18,075: Epoch 13/36 Batch 4100/7662 eta: 1 day, 12:47:22.687702	Training Loss1 4.6448 (4.5827)	Training Total_Loss 4.6448 (4.5827)	Training Prec@1 95.312 (96.342)	Training Prec@5 0.000 (0.000)	
2022-07-07 13:28:18,075: ============================================================
2022-07-07 13:29:32,898: time cost, forward:0.012137657632484809, backward:0.03334381552530658, data cost:0.6931338666251342 
2022-07-07 13:29:32,899: ============================================================
2022-07-07 13:29:32,899: Epoch 13/36 Batch 4200/7662 eta: 1 day, 13:20:51.210025	Training Loss1 4.4388 (4.5859)	Training Total_Loss 4.4388 (4.5859)	Training Prec@1 96.094 (96.329)	Training Prec@5 0.000 (0.000)	
2022-07-07 13:29:32,899: ============================================================
2022-07-07 13:30:46,585: time cost, forward:0.012140075171595537, backward:0.03332808362131591, data cost:0.6930788347515346 
2022-07-07 13:30:46,585: ============================================================
2022-07-07 13:30:46,585: Epoch 13/36 Batch 4300/7662 eta: 1 day, 12:45:32.259020	Training Loss1 4.9469 (4.5897)	Training Total_Loss 4.9469 (4.5897)	Training Prec@1 95.508 (96.316)	Training Prec@5 0.000 (0.000)	
2022-07-07 13:30:46,585: ============================================================
2022-07-07 13:32:00,983: time cost, forward:0.012155231927627595, backward:0.03333613709391017, data cost:0.6931770147586795 
2022-07-07 13:32:00,983: ============================================================
2022-07-07 13:32:00,983: Epoch 13/36 Batch 4400/7662 eta: 1 day, 13:05:36.032797	Training Loss1 4.6103 (4.5932)	Training Total_Loss 4.6103 (4.5932)	Training Prec@1 96.094 (96.305)	Training Prec@5 0.000 (0.000)	
2022-07-07 13:32:00,983: ============================================================
2022-07-07 13:33:14,984: time cost, forward:0.01215684114495604, backward:0.03333166234359181, data cost:0.6932007159940877 
2022-07-07 13:33:14,984: ============================================================
2022-07-07 13:33:14,984: Epoch 13/36 Batch 4500/7662 eta: 1 day, 12:52:30.033555	Training Loss1 4.6141 (4.5958)	Training Total_Loss 4.6141 (4.5958)	Training Prec@1 95.508 (96.293)	Training Prec@5 0.000 (0.000)	
2022-07-07 13:33:14,984: ============================================================
2022-07-07 13:34:29,163: time cost, forward:0.012163422267886446, backward:0.03334484859299831, data cost:0.6932316842507372 
2022-07-07 13:34:29,163: ============================================================
2022-07-07 13:34:29,163: Epoch 13/36 Batch 4600/7662 eta: 1 day, 12:56:34.699076	Training Loss1 4.7936 (4.5984)	Training Total_Loss 4.7936 (4.5984)	Training Prec@1 96.289 (96.283)	Training Prec@5 0.000 (0.000)	
2022-07-07 13:34:29,163: ============================================================
2022-07-07 13:35:43,248: time cost, forward:0.012163339814979439, backward:0.033340743156817905, data cost:0.6932674391418346 
2022-07-07 13:35:43,248: ============================================================
2022-07-07 13:35:43,248: Epoch 13/36 Batch 4700/7662 eta: 1 day, 12:52:31.934466	Training Loss1 4.6286 (4.6008)	Training Total_Loss 4.6286 (4.6008)	Training Prec@1 94.727 (96.274)	Training Prec@5 0.000 (0.000)	
2022-07-07 13:35:43,248: ============================================================
2022-07-07 13:36:58,426: time cost, forward:0.01216448776720464, backward:0.03332901562370591, data cost:0.6935404538859872 
2022-07-07 13:36:58,426: ============================================================
2022-07-07 13:36:58,426: Epoch 13/36 Batch 4800/7662 eta: 1 day, 13:23:55.620600	Training Loss1 5.0654 (4.6036)	Training Total_Loss 5.0654 (4.6036)	Training Prec@1 95.898 (96.263)	Training Prec@5 0.000 (0.000)	
2022-07-07 13:36:58,426: ============================================================
2022-07-07 13:38:11,802: time cost, forward:0.012173678636988905, backward:0.03331694293445557, data cost:0.6934165743862665 
2022-07-07 13:38:11,802: ============================================================
2022-07-07 13:38:11,803: Epoch 13/36 Batch 4900/7662 eta: 1 day, 12:28:55.804927	Training Loss1 4.9412 (4.6064)	Training Total_Loss 4.9412 (4.6064)	Training Prec@1 95.117 (96.253)	Training Prec@5 0.000 (0.000)	
2022-07-07 13:38:11,803: ============================================================
2022-07-07 13:39:26,956: time cost, forward:0.012179553830688012, backward:0.03332594414428845, data cost:0.6936421110096348 
2022-07-07 13:39:26,957: ============================================================
2022-07-07 13:39:26,957: Epoch 13/36 Batch 5000/7662 eta: 1 day, 13:20:42.448126	Training Loss1 4.8352 (4.6092)	Training Total_Loss 4.8352 (4.6092)	Training Prec@1 94.531 (96.241)	Training Prec@5 0.000 (0.000)	
2022-07-07 13:39:26,957: ============================================================
2022-07-07 13:40:42,175: time cost, forward:0.012193127879209906, backward:0.03334197490255981, data cost:0.6938592237359194 
2022-07-07 13:40:42,175: ============================================================
2022-07-07 13:40:42,175: Epoch 13/36 Batch 5100/7662 eta: 1 day, 13:21:22.740108	Training Loss1 4.7243 (4.6116)	Training Total_Loss 4.7243 (4.6116)	Training Prec@1 96.289 (96.234)	Training Prec@5 0.000 (0.000)	
2022-07-07 13:40:42,176: ============================================================
2022-07-07 13:41:56,134: time cost, forward:0.012201900274897108, backward:0.03333898144608439, data cost:0.6938459465516992 
2022-07-07 13:41:56,135: ============================================================
2022-07-07 13:41:56,135: Epoch 13/36 Batch 5200/7662 eta: 1 day, 12:42:37.570755	Training Loss1 4.4977 (4.6138)	Training Total_Loss 4.4977 (4.6138)	Training Prec@1 95.703 (96.227)	Training Prec@5 0.000 (0.000)	
2022-07-07 13:41:56,135: ============================================================
2022-07-07 13:43:11,016: time cost, forward:0.012205071214415664, backward:0.03333128760683917, data cost:0.6940076496943502 
2022-07-07 13:43:11,016: ============================================================
2022-07-07 13:43:11,017: Epoch 13/36 Batch 5300/7662 eta: 1 day, 13:08:50.228918	Training Loss1 4.4150 (4.6161)	Training Total_Loss 4.4150 (4.6161)	Training Prec@1 95.898 (96.217)	Training Prec@5 0.000 (0.000)	
2022-07-07 13:43:11,017: ============================================================
2022-07-07 13:44:23,867: time cost, forward:0.012203033068904747, backward:0.03333351885440019, data cost:0.6937993411378389 
2022-07-07 13:44:23,868: ============================================================
2022-07-07 13:44:23,868: Epoch 13/36 Batch 5400/7662 eta: 1 day, 12:07:11.319827	Training Loss1 4.8689 (4.6184)	Training Total_Loss 4.8689 (4.6184)	Training Prec@1 95.117 (96.208)	Training Prec@5 0.000 (0.000)	
2022-07-07 13:44:23,868: ============================================================
2022-07-07 13:45:37,941: time cost, forward:0.012202914616566914, backward:0.03334411991186675, data cost:0.6938035511107722 
2022-07-07 13:45:37,941: ============================================================
2022-07-07 13:45:37,941: Epoch 13/36 Batch 5500/7662 eta: 1 day, 12:42:19.370884	Training Loss1 4.5817 (4.6209)	Training Total_Loss 4.5817 (4.6209)	Training Prec@1 96.680 (96.198)	Training Prec@5 0.000 (0.000)	
2022-07-07 13:45:37,942: ============================================================
2022-07-07 13:46:53,035: time cost, forward:0.01221485950410696, backward:0.03334798917618793, data cost:0.6939784520267269 
2022-07-07 13:46:53,035: ============================================================
2022-07-07 13:46:53,035: Epoch 13/36 Batch 5600/7662 eta: 1 day, 13:11:24.281055	Training Loss1 4.4728 (4.6223)	Training Total_Loss 4.4728 (4.6223)	Training Prec@1 96.680 (96.190)	Training Prec@5 0.000 (0.000)	
2022-07-07 13:46:53,036: ============================================================
2022-07-07 13:48:07,230: time cost, forward:0.012206616914571429, backward:0.033334594208810554, data cost:0.6940369839876613 
2022-07-07 13:48:07,230: ============================================================
2022-07-07 13:48:07,231: Epoch 13/36 Batch 5700/7662 eta: 1 day, 12:43:27.782156	Training Loss1 4.4460 (4.6241)	Training Total_Loss 4.4460 (4.6241)	Training Prec@1 97.461 (96.179)	Training Prec@5 0.000 (0.000)	
2022-07-07 13:48:07,231: ============================================================
2022-07-07 13:49:20,956: time cost, forward:0.012199105877653445, backward:0.03332751642981363, data cost:0.6940028733231935 
2022-07-07 13:49:20,957: ============================================================
2022-07-07 13:49:20,957: Epoch 13/36 Batch 5800/7662 eta: 1 day, 12:28:17.997744	Training Loss1 4.5932 (4.6260)	Training Total_Loss 4.5932 (4.6260)	Training Prec@1 97.461 (96.175)	Training Prec@5 0.000 (0.000)	
2022-07-07 13:49:20,957: ============================================================
2022-07-07 13:50:35,357: time cost, forward:0.012197352239773989, backward:0.03334471665715581, data cost:0.6940504312313175 
2022-07-07 13:50:35,357: ============================================================
2022-07-07 13:50:35,357: Epoch 13/36 Batch 5900/7662 eta: 1 day, 12:47:04.817232	Training Loss1 4.8193 (4.6278)	Training Total_Loss 4.8193 (4.6278)	Training Prec@1 96.875 (96.168)	Training Prec@5 0.000 (0.000)	
2022-07-07 13:50:35,357: ============================================================
2022-07-07 13:51:49,393: time cost, forward:0.012192655154160011, backward:0.033337192110944575, data cost:0.6940674411791486 
2022-07-07 13:51:49,394: ============================================================
2022-07-07 13:51:49,394: Epoch 13/36 Batch 6000/7662 eta: 1 day, 12:35:02.909470	Training Loss1 4.7236 (4.6296)	Training Total_Loss 4.7236 (4.6296)	Training Prec@1 95.898 (96.161)	Training Prec@5 0.000 (0.000)	
2022-07-07 13:51:49,394: ============================================================
2022-07-07 13:53:04,339: time cost, forward:0.01220073307473301, backward:0.03334264337752643, data cost:0.6942067210802115 
2022-07-07 13:53:04,339: ============================================================
2022-07-07 13:53:04,339: Epoch 13/36 Batch 6100/7662 eta: 1 day, 13:00:44.880669	Training Loss1 4.6782 (4.6312)	Training Total_Loss 4.6782 (4.6312)	Training Prec@1 95.312 (96.155)	Training Prec@5 0.000 (0.000)	
2022-07-07 13:53:04,340: ============================================================
2022-07-07 13:54:18,898: time cost, forward:0.012194796057742803, backward:0.03333797241761081, data cost:0.6943023824791771 
2022-07-07 13:54:18,898: ============================================================
2022-07-07 13:54:18,898: Epoch 13/36 Batch 6200/7662 eta: 1 day, 12:48:02.702219	Training Loss1 4.8512 (4.6329)	Training Total_Loss 4.8512 (4.6329)	Training Prec@1 95.117 (96.149)	Training Prec@5 0.000 (0.000)	
2022-07-07 13:54:18,898: ============================================================
2022-07-07 13:55:33,145: time cost, forward:0.012175401140156389, backward:0.03333868842632889, data cost:0.6943469024836251 
2022-07-07 13:55:33,146: ============================================================
2022-07-07 13:55:33,146: Epoch 13/36 Batch 6300/7662 eta: 1 day, 12:37:35.929128	Training Loss1 4.5874 (4.6340)	Training Total_Loss 4.5874 (4.6340)	Training Prec@1 97.461 (96.145)	Training Prec@5 0.000 (0.000)	
2022-07-07 13:55:33,146: ============================================================
2022-07-07 13:56:48,716: time cost, forward:0.012177518837748888, backward:0.033339366742942016, data cost:0.6945799691804891 
2022-07-07 13:56:48,716: ============================================================
2022-07-07 13:56:48,716: Epoch 13/36 Batch 6400/7662 eta: 1 day, 13:15:28.717741	Training Loss1 4.5190 (4.6358)	Training Total_Loss 4.5190 (4.6358)	Training Prec@1 96.875 (96.137)	Training Prec@5 0.000 (0.000)	
2022-07-07 13:56:48,716: ============================================================
2022-07-07 13:58:04,105: time cost, forward:0.012178804309831471, backward:0.03333881239209437, data cost:0.6947871544376155 
2022-07-07 13:58:04,105: ============================================================
2022-07-07 13:58:04,105: Epoch 13/36 Batch 6500/7662 eta: 1 day, 13:08:51.901794	Training Loss1 4.5476 (4.6372)	Training Total_Loss 4.5476 (4.6372)	Training Prec@1 94.336 (96.131)	Training Prec@5 0.000 (0.000)	
2022-07-07 13:58:04,105: ============================================================
2022-07-07 13:59:18,025: time cost, forward:0.012180083158215279, backward:0.033341846857708246, data cost:0.6947561331744772 
2022-07-07 13:59:18,025: ============================================================
2022-07-07 13:59:18,026: Epoch 13/36 Batch 6600/7662 eta: 1 day, 12:24:12.849376	Training Loss1 4.6842 (4.6383)	Training Total_Loss 4.6842 (4.6383)	Training Prec@1 96.484 (96.126)	Training Prec@5 0.000 (0.000)	
2022-07-07 13:59:18,026: ============================================================
2022-07-07 14:00:32,139: time cost, forward:0.012184108081264697, backward:0.03334867763846717, data cost:0.694749845748767 
2022-07-07 14:00:32,139: ============================================================
2022-07-07 14:00:32,140: Epoch 13/36 Batch 6700/7662 eta: 1 day, 12:28:41.512152	Training Loss1 4.5040 (4.6397)	Training Total_Loss 4.5040 (4.6397)	Training Prec@1 96.484 (96.121)	Training Prec@5 0.000 (0.000)	
2022-07-07 14:00:32,140: ============================================================
2022-07-07 14:01:47,236: time cost, forward:0.012199124337505078, backward:0.03335512874932618, data cost:0.6948815372204461 
2022-07-07 14:01:47,237: ============================================================
2022-07-07 14:01:47,237: Epoch 13/36 Batch 6800/7662 eta: 1 day, 12:56:29.145088	Training Loss1 4.8272 (4.6406)	Training Total_Loss 4.8272 (4.6406)	Training Prec@1 95.898 (96.117)	Training Prec@5 0.000 (0.000)	
2022-07-07 14:01:47,237: ============================================================
2022-07-07 14:03:01,572: time cost, forward:0.012210102560969778, backward:0.03335508734856089, data cost:0.6949021629292579 
2022-07-07 14:03:01,573: ============================================================
2022-07-07 14:03:01,573: Epoch 13/36 Batch 6900/7662 eta: 1 day, 12:32:46.548887	Training Loss1 4.7096 (4.6418)	Training Total_Loss 4.7096 (4.6418)	Training Prec@1 95.312 (96.111)	Training Prec@5 0.000 (0.000)	
2022-07-07 14:03:01,573: ============================================================
2022-07-07 14:04:15,825: time cost, forward:0.012216846676175296, backward:0.03337620172965252, data cost:0.6948958672971653 
2022-07-07 14:04:15,826: ============================================================
2022-07-07 14:04:15,826: Epoch 13/36 Batch 7000/7662 eta: 1 day, 12:29:05.622849	Training Loss1 4.7731 (4.6435)	Training Total_Loss 4.7731 (4.6435)	Training Prec@1 95.898 (96.105)	Training Prec@5 0.000 (0.000)	
2022-07-07 14:04:15,826: ============================================================
2022-07-07 14:05:29,639: time cost, forward:0.012215069909048073, backward:0.03337922756529842, data cost:0.6948515277359583 
2022-07-07 14:05:29,640: ============================================================
2022-07-07 14:05:29,640: Epoch 13/36 Batch 7100/7662 eta: 1 day, 12:14:54.516776	Training Loss1 4.8273 (4.6447)	Training Total_Loss 4.8273 (4.6447)	Training Prec@1 95.117 (96.098)	Training Prec@5 0.000 (0.000)	
2022-07-07 14:05:29,640: ============================================================
2022-07-07 14:06:45,417: time cost, forward:0.012225455419108808, backward:0.033390799766283, data cost:0.6950616900797336 
2022-07-07 14:06:45,417: ============================================================
2022-07-07 14:06:45,418: Epoch 13/36 Batch 7200/7662 eta: 1 day, 13:11:31.288260	Training Loss1 4.6581 (4.6463)	Training Total_Loss 4.6581 (4.6463)	Training Prec@1 96.289 (96.091)	Training Prec@5 0.000 (0.000)	
2022-07-07 14:06:45,418: ============================================================
2022-07-07 14:07:59,979: time cost, forward:0.012229865994383528, backward:0.033394181511143754, data cost:0.6951069387936857 
2022-07-07 14:07:59,979: ============================================================
2022-07-07 14:07:59,979: Epoch 13/36 Batch 7300/7662 eta: 1 day, 12:34:27.779125	Training Loss1 4.8351 (4.6474)	Training Total_Loss 4.8351 (4.6474)	Training Prec@1 95.312 (96.085)	Training Prec@5 0.000 (0.000)	
2022-07-07 14:07:59,979: ============================================================
2022-07-07 14:09:14,317: time cost, forward:0.012236964978113546, backward:0.03339451711747208, data cost:0.6951332261134102 
2022-07-07 14:09:14,317: ============================================================
2022-07-07 14:09:14,317: Epoch 13/36 Batch 7400/7662 eta: 1 day, 12:26:38.406389	Training Loss1 4.7917 (4.6484)	Training Total_Loss 4.7917 (4.6484)	Training Prec@1 95.508 (96.083)	Training Prec@5 0.000 (0.000)	
2022-07-07 14:09:14,318: ============================================================
2022-07-07 14:10:29,615: time cost, forward:0.012238006144146043, backward:0.03339575970867568, data cost:0.6952823795212286 
2022-07-07 14:10:29,615: ============================================================
2022-07-07 14:10:29,616: Epoch 13/36 Batch 7500/7662 eta: 1 day, 12:53:37.667792	Training Loss1 5.0087 (4.6497)	Training Total_Loss 5.0087 (4.6497)	Training Prec@1 93.945 (96.076)	Training Prec@5 0.000 (0.000)	
2022-07-07 14:10:29,616: ============================================================
2022-07-07 14:11:45,187: time cost, forward:0.012244022273753784, backward:0.033396289950688426, data cost:0.6954657623274951 
2022-07-07 14:11:45,188: ============================================================
2022-07-07 14:11:45,188: Epoch 13/36 Batch 7600/7662 eta: 1 day, 13:00:25.640103	Training Loss1 4.9652 (4.6509)	Training Total_Loss 4.9652 (4.6509)	Training Prec@1 94.922 (96.071)	Training Prec@5 0.000 (0.000)	
2022-07-07 14:11:45,188: ============================================================
2022-07-07 14:12:33,901: Epoch 13/36 Batch 7663/7662 eta: 1 day, 12:59:38.029558	Training Loss1 4.8301 (4.6514)	Training Total_Loss 4.8301 (4.6514)	Training Prec@1 94.922 (96.068)	Training Prec@5 0.000 (0.000)	
2022-07-07 14:12:33,901: ============================================================
2022-07-07 14:13:57,336: time cost, forward:0.011389460226502082, backward:0.03238787313904425, data cost:0.7929542594485812 
2022-07-07 14:13:57,336: ============================================================
2022-07-07 14:13:57,337: Epoch 14/36 Batch 100/7662 eta: 1 day, 16:47:40.096326	Training Loss1 4.0890 (4.2112)	Training Total_Loss 4.0890 (4.2112)	Training Prec@1 98.242 (97.049)	Training Prec@5 0.000 (0.000)	
2022-07-07 14:13:57,337: ============================================================
2022-07-07 14:15:10,947: time cost, forward:0.011596880965496428, backward:0.03260708693882928, data cost:0.7416159986850605 
2022-07-07 14:15:10,948: ============================================================
2022-07-07 14:15:10,948: Epoch 14/36 Batch 200/7662 eta: 1 day, 11:59:36.085351	Training Loss1 4.2238 (4.2108)	Training Total_Loss 4.2238 (4.2108)	Training Prec@1 97.656 (97.097)	Training Prec@5 0.000 (0.000)	
2022-07-07 14:15:10,948: ============================================================
2022-07-07 14:16:24,018: time cost, forward:0.011500745314020776, backward:0.03287716374349434, data cost:0.7228510818353864 
2022-07-07 14:16:24,018: ============================================================
2022-07-07 14:16:24,018: Epoch 14/36 Batch 300/7662 eta: 1 day, 11:42:30.511855	Training Loss1 4.1541 (4.2280)	Training Total_Loss 4.1541 (4.2280)	Training Prec@1 98.438 (97.095)	Training Prec@5 0.000 (0.000)	
2022-07-07 14:16:24,019: ============================================================
2022-07-07 14:17:37,789: time cost, forward:0.011733979509587874, backward:0.03315814037370801, data cost:0.7147408661089445 
2022-07-07 14:17:37,790: ============================================================
2022-07-07 14:17:37,790: Epoch 14/36 Batch 400/7662 eta: 1 day, 12:01:50.044464	Training Loss1 4.4582 (4.2464)	Training Total_Loss 4.4582 (4.2464)	Training Prec@1 96.289 (97.061)	Training Prec@5 0.000 (0.000)	
2022-07-07 14:17:37,790: ============================================================
2022-07-07 14:18:51,890: time cost, forward:0.011843632600589363, backward:0.033127481808404406, data cost:0.7107940389063649 
2022-07-07 14:18:51,890: ============================================================
2022-07-07 14:18:51,890: Epoch 14/36 Batch 500/7662 eta: 1 day, 12:10:14.801590	Training Loss1 4.4958 (4.2606)	Training Total_Loss 4.4958 (4.2606)	Training Prec@1 98.242 (97.067)	Training Prec@5 0.000 (0.000)	
2022-07-07 14:18:51,891: ============================================================
2022-07-07 14:20:05,404: time cost, forward:0.011886145316300686, backward:0.03318220148102469, data cost:0.7071582140628005 
2022-07-07 14:20:05,404: ============================================================
2022-07-07 14:20:05,404: Epoch 14/36 Batch 600/7662 eta: 1 day, 11:51:50.548242	Training Loss1 4.1012 (4.2700)	Training Total_Loss 4.1012 (4.2700)	Training Prec@1 96.680 (97.045)	Training Prec@5 0.000 (0.000)	
2022-07-07 14:20:05,405: ============================================================
2022-07-07 14:21:17,921: time cost, forward:0.011877663998474208, backward:0.03333210774586777, data cost:0.7030587956970171 
2022-07-07 14:21:17,921: ============================================================
2022-07-07 14:21:17,921: Epoch 14/36 Batch 700/7662 eta: 1 day, 11:21:26.619485	Training Loss1 4.4508 (4.2848)	Training Total_Loss 4.4508 (4.2848)	Training Prec@1 95.898 (97.020)	Training Prec@5 0.000 (0.000)	
2022-07-07 14:21:17,921: ============================================================
2022-07-07 14:22:30,625: time cost, forward:0.011904211605296415, backward:0.03340051051821368, data cost:0.7002396801386369 
2022-07-07 14:22:30,625: ============================================================
2022-07-07 14:22:30,626: Epoch 14/36 Batch 800/7662 eta: 1 day, 11:25:43.055046	Training Loss1 4.6706 (4.2988)	Training Total_Loss 4.6706 (4.2988)	Training Prec@1 95.508 (96.979)	Training Prec@5 0.000 (0.000)	
2022-07-07 14:22:30,626: ============================================================
2022-07-07 14:23:42,781: time cost, forward:0.011974271067787994, backward:0.03338720827664894, data cost:0.6974676660488922 
2022-07-07 14:23:42,781: ============================================================
2022-07-07 14:23:42,781: Epoch 14/36 Batch 900/7662 eta: 1 day, 11:08:28.395659	Training Loss1 4.6460 (4.3092)	Training Total_Loss 4.6460 (4.3092)	Training Prec@1 97.070 (96.960)	Training Prec@5 0.000 (0.000)	
2022-07-07 14:23:42,781: ============================================================
2022-07-07 14:24:54,668: time cost, forward:0.012116794471626167, backward:0.03336443796052828, data cost:0.6948618874535546 
2022-07-07 14:24:54,668: ============================================================
2022-07-07 14:24:54,669: Epoch 14/36 Batch 1000/7662 eta: 1 day, 10:59:25.957525	Training Loss1 4.4404 (4.3182)	Training Total_Loss 4.4404 (4.3182)	Training Prec@1 96.484 (96.951)	Training Prec@5 0.000 (0.000)	
2022-07-07 14:24:54,669: ============================================================
2022-07-07 14:26:07,664: time cost, forward:0.01218681882141502, backward:0.03327495320695872, data cost:0.6938701984120891 
2022-07-07 14:26:07,664: ============================================================
2022-07-07 14:26:07,664: Epoch 14/36 Batch 1100/7662 eta: 1 day, 11:30:34.983092	Training Loss1 4.5769 (4.3296)	Training Total_Loss 4.5769 (4.3296)	Training Prec@1 96.094 (96.927)	Training Prec@5 0.000 (0.000)	
2022-07-07 14:26:07,664: ============================================================
2022-07-07 14:27:21,275: time cost, forward:0.012247614904281195, backward:0.03315724781694961, data cost:0.6935986895875398 
2022-07-07 14:27:21,275: ============================================================
2022-07-07 14:27:21,275: Epoch 14/36 Batch 1200/7662 eta: 1 day, 11:47:19.231070	Training Loss1 4.7296 (4.3417)	Training Total_Loss 4.7296 (4.3417)	Training Prec@1 96.094 (96.912)	Training Prec@5 0.000 (0.000)	
2022-07-07 14:27:21,275: ============================================================
2022-07-07 14:28:33,566: time cost, forward:0.01230780926000347, backward:0.03315631621979676, data cost:0.6922520712029484 
2022-07-07 14:28:33,567: ============================================================
2022-07-07 14:28:33,567: Epoch 14/36 Batch 1300/7662 eta: 1 day, 11:07:37.236840	Training Loss1 4.1556 (4.3532)	Training Total_Loss 4.1556 (4.3532)	Training Prec@1 96.680 (96.897)	Training Prec@5 0.000 (0.000)	
2022-07-07 14:28:33,567: ============================================================
2022-07-07 14:29:46,791: time cost, forward:0.012315556183297605, backward:0.03314561942716084, data cost:0.6918071306459046 
2022-07-07 14:29:46,791: ============================================================
2022-07-07 14:29:46,791: Epoch 14/36 Batch 1400/7662 eta: 1 day, 11:33:36.037703	Training Loss1 4.5009 (4.3627)	Training Total_Loss 4.5009 (4.3627)	Training Prec@1 95.703 (96.876)	Training Prec@5 0.000 (0.000)	
2022-07-07 14:29:46,791: ============================================================
2022-07-07 14:31:00,228: time cost, forward:0.01225755881118011, backward:0.033135153755814016, data cost:0.6916441309841733 
2022-07-07 14:31:00,229: ============================================================
2022-07-07 14:31:00,229: Epoch 14/36 Batch 1500/7662 eta: 1 day, 11:38:35.781744	Training Loss1 4.6738 (4.3726)	Training Total_Loss 4.6738 (4.3726)	Training Prec@1 96.680 (96.858)	Training Prec@5 0.000 (0.000)	
2022-07-07 14:31:00,229: ============================================================
2022-07-07 14:32:13,915: time cost, forward:0.012257059191524275, backward:0.0331544885044921, data cost:0.6915713455469776 
2022-07-07 14:32:13,915: ============================================================
2022-07-07 14:32:13,915: Epoch 14/36 Batch 1600/7662 eta: 1 day, 11:44:36.182247	Training Loss1 4.8558 (4.3824)	Training Total_Loss 4.8558 (4.3824)	Training Prec@1 95.117 (96.835)	Training Prec@5 0.000 (0.000)	
2022-07-07 14:32:13,915: ============================================================
2022-07-07 14:33:26,659: time cost, forward:0.012248062680509948, backward:0.033177575481295796, data cost:0.6909739711552665 
2022-07-07 14:33:26,660: ============================================================
2022-07-07 14:33:26,660: Epoch 14/36 Batch 1700/7662 eta: 1 day, 11:15:59.364274	Training Loss1 4.3580 (4.3914)	Training Total_Loss 4.3580 (4.3914)	Training Prec@1 96.680 (96.811)	Training Prec@5 0.000 (0.000)	
2022-07-07 14:33:26,660: ============================================================
2022-07-07 14:34:39,679: time cost, forward:0.012230564316754344, backward:0.03318668617812576, data cost:0.6905937653372459 
2022-07-07 14:34:39,680: ============================================================
2022-07-07 14:34:39,680: Epoch 14/36 Batch 1800/7662 eta: 1 day, 11:22:45.800230	Training Loss1 4.6117 (4.3996)	Training Total_Loss 4.6117 (4.3996)	Training Prec@1 96.875 (96.792)	Training Prec@5 0.000 (0.000)	
2022-07-07 14:34:39,680: ============================================================
2022-07-07 14:35:53,238: time cost, forward:0.012182684934032535, backward:0.03317568564553083, data cost:0.6905932051059508 
2022-07-07 14:35:53,238: ============================================================
2022-07-07 14:35:53,238: Epoch 14/36 Batch 1900/7662 eta: 1 day, 11:37:12.238687	Training Loss1 4.8064 (4.4071)	Training Total_Loss 4.8064 (4.4071)	Training Prec@1 95.508 (96.777)	Training Prec@5 0.000 (0.000)	
2022-07-07 14:35:53,238: ============================================================
2022-07-07 14:37:05,990: time cost, forward:0.012198065447175187, backward:0.03320186981384369, data cost:0.690105991998036 
2022-07-07 14:37:05,990: ============================================================
2022-07-07 14:37:05,991: Epoch 14/36 Batch 2000/7662 eta: 1 day, 11:12:34.425166	Training Loss1 4.3502 (4.4151)	Training Total_Loss 4.3502 (4.4151)	Training Prec@1 96.094 (96.754)	Training Prec@5 0.000 (0.000)	
2022-07-07 14:37:05,991: ============================================================
2022-07-07 14:38:19,037: time cost, forward:0.012199405035897629, backward:0.0332227999281463, data cost:0.6898122344941625 
2022-07-07 14:38:19,038: ============================================================
2022-07-07 14:38:19,038: Epoch 14/36 Batch 2100/7662 eta: 1 day, 11:19:55.105043	Training Loss1 4.6090 (4.4226)	Training Total_Loss 4.6090 (4.4226)	Training Prec@1 96.094 (96.732)	Training Prec@5 0.000 (0.000)	
2022-07-07 14:38:19,038: ============================================================
2022-07-07 14:39:31,871: time cost, forward:0.012172503816154449, backward:0.03320765072456974, data cost:0.6895157682619186 
2022-07-07 14:39:31,871: ============================================================
2022-07-07 14:39:31,871: Epoch 14/36 Batch 2200/7662 eta: 1 day, 11:12:29.400147	Training Loss1 4.5208 (4.4299)	Training Total_Loss 4.5208 (4.4299)	Training Prec@1 96.680 (96.714)	Training Prec@5 0.000 (0.000)	
2022-07-07 14:39:31,871: ============================================================
2022-07-07 14:40:45,324: time cost, forward:0.012194269892960956, backward:0.03318986295357431, data cost:0.6894635321420916 
2022-07-07 14:40:45,325: ============================================================
2022-07-07 14:40:45,325: Epoch 14/36 Batch 2300/7662 eta: 1 day, 11:29:15.787471	Training Loss1 4.7595 (4.4349)	Training Total_Loss 4.7595 (4.4349)	Training Prec@1 96.484 (96.707)	Training Prec@5 0.000 (0.000)	
2022-07-07 14:40:45,325: ============================================================
2022-07-07 14:41:59,072: time cost, forward:0.01216141111207734, backward:0.03318572312705265, data cost:0.6895866023346303 
2022-07-07 14:41:59,072: ============================================================
2022-07-07 14:41:59,072: Epoch 14/36 Batch 2400/7662 eta: 1 day, 11:36:32.726474	Training Loss1 4.9574 (4.4413)	Training Total_Loss 4.9574 (4.4413)	Training Prec@1 96.484 (96.690)	Training Prec@5 0.000 (0.000)	
2022-07-07 14:41:59,072: ============================================================
2022-07-07 14:43:12,554: time cost, forward:0.01214064765615719, backward:0.0331921130001378, data cost:0.689568538673404 
2022-07-07 14:43:12,554: ============================================================
2022-07-07 14:43:12,555: Epoch 14/36 Batch 2500/7662 eta: 1 day, 11:27:38.911843	Training Loss1 4.5607 (4.4474)	Training Total_Loss 4.5607 (4.4474)	Training Prec@1 95.508 (96.676)	Training Prec@5 0.000 (0.000)	
2022-07-07 14:43:12,555: ============================================================
2022-07-07 14:44:26,101: time cost, forward:0.012097010019881399, backward:0.03318905793689406, data cost:0.6896269639761184 
2022-07-07 14:44:26,102: ============================================================
2022-07-07 14:44:26,102: Epoch 14/36 Batch 2600/7662 eta: 1 day, 11:28:17.613085	Training Loss1 4.6661 (4.4533)	Training Total_Loss 4.6661 (4.4533)	Training Prec@1 95.898 (96.659)	Training Prec@5 0.000 (0.000)	
2022-07-07 14:44:26,102: ============================================================
2022-07-07 14:45:39,318: time cost, forward:0.012076766369916104, backward:0.033171438649655625, data cost:0.6895292964234269 
2022-07-07 14:45:39,318: ============================================================
2022-07-07 14:45:39,318: Epoch 14/36 Batch 2700/7662 eta: 1 day, 11:17:30.426233	Training Loss1 4.4500 (4.4591)	Training Total_Loss 4.4500 (4.4591)	Training Prec@1 97.852 (96.643)	Training Prec@5 0.000 (0.000)	
2022-07-07 14:45:39,318: ============================================================
2022-07-07 14:46:52,496: time cost, forward:0.012053679295547012, backward:0.03315855682471174, data cost:0.6894488241809655 
2022-07-07 14:46:52,496: ============================================================
2022-07-07 14:46:52,496: Epoch 14/36 Batch 2800/7662 eta: 1 day, 11:15:10.689941	Training Loss1 4.4686 (4.4638)	Training Total_Loss 4.4686 (4.4638)	Training Prec@1 95.703 (96.628)	Training Prec@5 0.000 (0.000)	
2022-07-07 14:46:52,497: ============================================================
2022-07-07 14:48:05,851: time cost, forward:0.012061523873051844, backward:0.033130843214184386, data cost:0.6894119919970678 
2022-07-07 14:48:05,851: ============================================================
2022-07-07 14:48:05,851: Epoch 14/36 Batch 2900/7662 eta: 1 day, 11:19:03.880380	Training Loss1 4.7200 (4.4689)	Training Total_Loss 4.7200 (4.4689)	Training Prec@1 96.680 (96.615)	Training Prec@5 0.000 (0.000)	
2022-07-07 14:48:05,851: ============================================================
2022-07-07 14:49:20,924: time cost, forward:0.01207879146920637, backward:0.03311164516653765, data cost:0.6899270125729674 
2022-07-07 14:49:20,925: ============================================================
2022-07-07 14:49:20,925: Epoch 14/36 Batch 3000/7662 eta: 1 day, 12:07:27.502318	Training Loss1 4.5223 (4.4740)	Training Total_Loss 4.5223 (4.4740)	Training Prec@1 96.875 (96.599)	Training Prec@5 0.000 (0.000)	
2022-07-07 14:49:20,925: ============================================================
2022-07-07 14:50:35,779: time cost, forward:0.012065508012503876, backward:0.03310771879360498, data cost:0.6903633771307355 
2022-07-07 14:50:35,779: ============================================================
2022-07-07 14:50:35,779: Epoch 14/36 Batch 3100/7662 eta: 1 day, 11:59:53.351962	Training Loss1 4.4426 (4.4790)	Training Total_Loss 4.4426 (4.4790)	Training Prec@1 96.875 (96.585)	Training Prec@5 0.000 (0.000)	
2022-07-07 14:50:35,779: ============================================================
2022-07-07 14:51:49,498: time cost, forward:0.012057927669156674, backward:0.033080788618626164, data cost:0.6904277110628949 
2022-07-07 14:51:49,499: ============================================================
2022-07-07 14:51:49,499: Epoch 14/36 Batch 3200/7662 eta: 1 day, 11:25:54.560997	Training Loss1 4.9251 (4.4838)	Training Total_Loss 4.9251 (4.4838)	Training Prec@1 95.312 (96.575)	Training Prec@5 0.000 (0.000)	
2022-07-07 14:51:49,499: ============================================================
2022-07-07 14:53:03,217: time cost, forward:0.012057038428892544, backward:0.03307189085729992, data cost:0.6904657955927067 
2022-07-07 14:53:03,218: ============================================================
2022-07-07 14:53:03,218: Epoch 14/36 Batch 3300/7662 eta: 1 day, 11:24:40.691056	Training Loss1 4.7042 (4.4873)	Training Total_Loss 4.7042 (4.4873)	Training Prec@1 95.508 (96.562)	Training Prec@5 0.000 (0.000)	
2022-07-07 14:53:03,218: ============================================================
2022-07-07 14:54:16,005: time cost, forward:0.012043875994209544, backward:0.03306316165020621, data cost:0.6902419197871497 
2022-07-07 14:54:16,005: ============================================================
2022-07-07 14:54:16,006: Epoch 14/36 Batch 3400/7662 eta: 1 day, 10:56:36.288464	Training Loss1 4.3529 (4.4914)	Training Total_Loss 4.3529 (4.4914)	Training Prec@1 96.875 (96.549)	Training Prec@5 0.000 (0.000)	
2022-07-07 14:54:16,006: ============================================================
2022-07-07 14:55:29,541: time cost, forward:0.012042824218326992, backward:0.03305414221088489, data cost:0.6902404136063542 
2022-07-07 14:55:29,541: ============================================================
2022-07-07 14:55:29,541: Epoch 14/36 Batch 3500/7662 eta: 1 day, 11:16:55.742651	Training Loss1 4.4826 (4.4957)	Training Total_Loss 4.4826 (4.4957)	Training Prec@1 96.680 (96.534)	Training Prec@5 0.000 (0.000)	
2022-07-07 14:55:29,541: ============================================================
2022-07-07 14:56:43,461: time cost, forward:0.012036868021467653, backward:0.03304322788072116, data cost:0.6903462480193676 
2022-07-07 14:56:43,461: ============================================================
2022-07-07 14:56:43,462: Epoch 14/36 Batch 3600/7662 eta: 1 day, 11:26:46.692215	Training Loss1 4.5204 (4.4995)	Training Total_Loss 4.5204 (4.4995)	Training Prec@1 96.289 (96.523)	Training Prec@5 0.000 (0.000)	
2022-07-07 14:56:43,462: ============================================================
2022-07-07 14:57:57,567: time cost, forward:0.012021061922286323, backward:0.03303161360953878, data cost:0.6905142629298044 
2022-07-07 14:57:57,568: ============================================================
2022-07-07 14:57:57,568: Epoch 14/36 Batch 3700/7662 eta: 1 day, 11:30:53.537233	Training Loss1 4.8644 (4.5029)	Training Total_Loss 4.8644 (4.5029)	Training Prec@1 96.094 (96.508)	Training Prec@5 0.000 (0.000)	
2022-07-07 14:57:57,568: ============================================================
2022-07-07 14:59:11,556: time cost, forward:0.012018468951701992, backward:0.033047664915457874, data cost:0.6905958165492344 
2022-07-07 14:59:11,557: ============================================================
2022-07-07 14:59:11,557: Epoch 14/36 Batch 3800/7662 eta: 1 day, 11:26:17.175144	Training Loss1 4.7019 (4.5072)	Training Total_Loss 4.7019 (4.5072)	Training Prec@1 97.266 (96.494)	Training Prec@5 0.000 (0.000)	
2022-07-07 14:59:11,557: ============================================================
2022-07-07 15:00:25,348: time cost, forward:0.012007539472264428, backward:0.03304214042160688, data cost:0.6906543150410404 
2022-07-07 15:00:25,349: ============================================================
2022-07-07 15:00:25,349: Epoch 14/36 Batch 3900/7662 eta: 1 day, 11:19:22.938848	Training Loss1 4.6380 (4.5103)	Training Total_Loss 4.6380 (4.5103)	Training Prec@1 96.484 (96.480)	Training Prec@5 0.000 (0.000)	
2022-07-07 15:00:25,349: ============================================================
2022-07-07 15:01:38,340: time cost, forward:0.012007772043127512, backward:0.03304109849998968, data cost:0.6904980305225499 
2022-07-07 15:01:38,340: ============================================================
2022-07-07 15:01:38,340: Epoch 14/36 Batch 4000/7662 eta: 1 day, 10:55:11.452001	Training Loss1 4.8158 (4.5139)	Training Total_Loss 4.8158 (4.5139)	Training Prec@1 94.336 (96.467)	Training Prec@5 0.000 (0.000)	
2022-07-07 15:01:38,341: ============================================================
2022-07-07 15:02:51,983: time cost, forward:0.012011496431509382, backward:0.03303065367459262, data cost:0.6905063720236874 
2022-07-07 15:02:51,983: ============================================================
2022-07-07 15:02:51,983: Epoch 14/36 Batch 4100/7662 eta: 1 day, 11:12:39.108043	Training Loss1 4.7831 (4.5168)	Training Total_Loss 4.7831 (4.5168)	Training Prec@1 96.289 (96.456)	Training Prec@5 0.000 (0.000)	
2022-07-07 15:02:51,983: ============================================================
2022-07-07 15:04:04,849: time cost, forward:0.011992063542779612, backward:0.033023455961172454, data cost:0.6903603326198344 
2022-07-07 15:04:04,850: ============================================================
2022-07-07 15:04:04,850: Epoch 14/36 Batch 4200/7662 eta: 1 day, 10:49:10.328991	Training Loss1 4.8885 (4.5204)	Training Total_Loss 4.8885 (4.5204)	Training Prec@1 94.922 (96.446)	Training Prec@5 0.000 (0.000)	
2022-07-07 15:04:04,850: ============================================================
2022-07-07 15:05:19,770: time cost, forward:0.011994101441608082, backward:0.03299745350944411, data cost:0.690694170792343 
2022-07-07 15:05:19,770: ============================================================
2022-07-07 15:05:19,770: Epoch 14/36 Batch 4300/7662 eta: 1 day, 11:46:48.379137	Training Loss1 4.6849 (4.5236)	Training Total_Loss 4.6849 (4.5236)	Training Prec@1 95.703 (96.433)	Training Prec@5 0.000 (0.000)	
2022-07-07 15:05:19,770: ============================================================
2022-07-07 15:06:33,916: time cost, forward:0.011998240095183209, backward:0.03301847894290925, data cost:0.6907805042067395 
2022-07-07 15:06:33,917: ============================================================
2022-07-07 15:06:33,917: Epoch 14/36 Batch 4400/7662 eta: 1 day, 11:23:23.753038	Training Loss1 4.4636 (4.5266)	Training Total_Loss 4.4636 (4.5266)	Training Prec@1 96.094 (96.423)	Training Prec@5 0.000 (0.000)	
2022-07-07 15:06:33,917: ============================================================
2022-07-07 15:07:47,605: time cost, forward:0.011997740224722518, backward:0.03302290392441335, data cost:0.6907859244964525 
2022-07-07 15:07:47,605: ============================================================
2022-07-07 15:07:47,605: Epoch 14/36 Batch 4500/7662 eta: 1 day, 11:09:03.135022	Training Loss1 4.7114 (4.5292)	Training Total_Loss 4.7114 (4.5292)	Training Prec@1 95.508 (96.414)	Training Prec@5 0.000 (0.000)	
2022-07-07 15:07:47,606: ============================================================
2022-07-07 15:09:02,350: time cost, forward:0.012011994950588332, backward:0.03303716695420144, data cost:0.690997726322646 
2022-07-07 15:09:02,350: ============================================================
2022-07-07 15:09:02,350: Epoch 14/36 Batch 4600/7662 eta: 1 day, 11:38:02.439732	Training Loss1 4.7673 (4.5322)	Training Total_Loss 4.7673 (4.5322)	Training Prec@1 95.703 (96.402)	Training Prec@5 0.000 (0.000)	
2022-07-07 15:09:02,350: ============================================================
2022-07-07 15:10:16,554: time cost, forward:0.012007429082740188, backward:0.03303737299420474, data cost:0.6911140328444022 
2022-07-07 15:10:16,555: ============================================================
2022-07-07 15:10:16,555: Epoch 14/36 Batch 4700/7662 eta: 1 day, 11:21:20.808673	Training Loss1 4.6096 (4.5343)	Training Total_Loss 4.6096 (4.5343)	Training Prec@1 97.070 (96.396)	Training Prec@5 0.000 (0.000)	
2022-07-07 15:10:16,555: ============================================================
2022-07-07 15:11:31,207: time cost, forward:0.012000382555154593, backward:0.03303521676569289, data cost:0.6913300947140445 
2022-07-07 15:11:31,207: ============================================================
2022-07-07 15:11:31,207: Epoch 14/36 Batch 4800/7662 eta: 1 day, 11:32:54.386125	Training Loss1 4.6803 (4.5373)	Training Total_Loss 4.6803 (4.5373)	Training Prec@1 96.484 (96.384)	Training Prec@5 0.000 (0.000)	
2022-07-07 15:11:31,207: ============================================================
2022-07-07 15:12:44,302: time cost, forward:0.011991741171075898, backward:0.03303857997233198, data cost:0.6912138446493279 
2022-07-07 15:12:44,302: ============================================================
2022-07-07 15:12:44,302: Epoch 14/36 Batch 4900/7662 eta: 1 day, 10:47:11.391455	Training Loss1 4.7955 (4.5404)	Training Total_Loss 4.7955 (4.5404)	Training Prec@1 95.508 (96.373)	Training Prec@5 0.000 (0.000)	
2022-07-07 15:12:44,302: ============================================================
2022-07-07 15:13:58,579: time cost, forward:0.011982245596916014, backward:0.03304198375342488, data cost:0.69132999287388 
2022-07-07 15:13:58,579: ============================================================
2022-07-07 15:13:58,579: Epoch 14/36 Batch 5000/7662 eta: 1 day, 11:19:42.746136	Training Loss1 4.5784 (4.5427)	Training Total_Loss 4.5784 (4.5427)	Training Prec@1 96.094 (96.364)	Training Prec@5 0.000 (0.000)	
2022-07-07 15:13:58,580: ============================================================
2022-07-07 15:15:13,320: time cost, forward:0.0119835329326982, backward:0.0330395884643842, data cost:0.691539238985671 
2022-07-07 15:15:13,320: ============================================================
2022-07-07 15:15:13,321: Epoch 14/36 Batch 5100/7662 eta: 1 day, 11:31:42.293305	Training Loss1 4.8729 (4.5454)	Training Total_Loss 4.8729 (4.5454)	Training Prec@1 93.359 (96.355)	Training Prec@5 0.000 (0.000)	
2022-07-07 15:15:13,321: ============================================================
2022-07-07 15:16:26,774: time cost, forward:0.01197893396206236, backward:0.03303800557388391, data cost:0.6914974923637377 
2022-07-07 15:16:26,774: ============================================================
2022-07-07 15:16:26,774: Epoch 14/36 Batch 5200/7662 eta: 1 day, 10:53:45.740755	Training Loss1 4.6638 (4.5476)	Training Total_Loss 4.6638 (4.5476)	Training Prec@1 95.703 (96.345)	Training Prec@5 0.000 (0.000)	
2022-07-07 15:16:26,775: ============================================================
2022-07-07 15:17:40,729: time cost, forward:0.011983259913380988, backward:0.03304561301658099, data cost:0.6915339714492306 
2022-07-07 15:17:40,729: ============================================================
2022-07-07 15:17:40,729: Epoch 14/36 Batch 5300/7662 eta: 1 day, 11:06:48.873222	Training Loss1 5.0283 (4.5493)	Training Total_Loss 5.0283 (4.5493)	Training Prec@1 95.117 (96.336)	Training Prec@5 0.000 (0.000)	
2022-07-07 15:17:40,729: ============================================================
2022-07-07 15:18:55,764: time cost, forward:0.012006756331572202, backward:0.03302996877079254, data cost:0.691769766838468 
2022-07-07 15:18:55,764: ============================================================
2022-07-07 15:18:55,764: Epoch 14/36 Batch 5400/7662 eta: 1 day, 11:36:20.105577	Training Loss1 4.7937 (4.5522)	Training Total_Loss 4.7937 (4.5522)	Training Prec@1 96.289 (96.324)	Training Prec@5 0.000 (0.000)	
2022-07-07 15:18:55,764: ============================================================
2022-07-07 15:20:10,098: time cost, forward:0.012017128272021027, backward:0.03302787420727552, data cost:0.6918605823780455 
2022-07-07 15:20:10,098: ============================================================
2022-07-07 15:20:10,098: Epoch 14/36 Batch 5500/7662 eta: 1 day, 11:15:08.002811	Training Loss1 4.6640 (4.5538)	Training Total_Loss 4.6640 (4.5538)	Training Prec@1 95.898 (96.318)	Training Prec@5 0.000 (0.000)	
2022-07-07 15:20:10,098: ============================================================
2022-07-07 15:21:23,854: time cost, forward:0.012020123049624798, backward:0.033016136872553364, data cost:0.6918786779261632 
2022-07-07 15:21:23,855: ============================================================
2022-07-07 15:21:23,855: Epoch 14/36 Batch 5600/7662 eta: 1 day, 10:57:28.989805	Training Loss1 4.7155 (4.5561)	Training Total_Loss 4.7155 (4.5561)	Training Prec@1 95.898 (96.308)	Training Prec@5 0.000 (0.000)	
2022-07-07 15:21:23,855: ============================================================
2022-07-07 15:22:39,183: time cost, forward:0.012036293091366512, backward:0.03300673138741799, data cost:0.6921492478872187 
2022-07-07 15:22:39,184: ============================================================
2022-07-07 15:22:39,185: Epoch 14/36 Batch 5700/7662 eta: 1 day, 11:40:57.233566	Training Loss1 4.7746 (4.5583)	Training Total_Loss 4.7746 (4.5583)	Training Prec@1 95.508 (96.300)	Training Prec@5 0.000 (0.000)	
2022-07-07 15:22:39,185: ============================================================
2022-07-07 15:23:52,833: time cost, forward:0.012029908981625839, backward:0.03301047312635701, data cost:0.6921282562845266 
2022-07-07 15:23:52,834: ============================================================
2022-07-07 15:23:52,834: Epoch 14/36 Batch 5800/7662 eta: 1 day, 10:51:58.488123	Training Loss1 4.5196 (4.5603)	Training Total_Loss 4.5196 (4.5603)	Training Prec@1 96.094 (96.292)	Training Prec@5 0.000 (0.000)	
2022-07-07 15:23:52,834: ============================================================
2022-07-07 15:25:07,187: time cost, forward:0.012032003559527063, backward:0.033013186589764994, data cost:0.6922215099030783 
2022-07-07 15:25:07,188: ============================================================
2022-07-07 15:25:07,188: Epoch 14/36 Batch 5900/7662 eta: 1 day, 11:10:45.119259	Training Loss1 4.6164 (4.5619)	Training Total_Loss 4.6164 (4.5619)	Training Prec@1 95.703 (96.286)	Training Prec@5 0.000 (0.000)	
2022-07-07 15:25:07,188: ============================================================
2022-07-07 15:26:21,751: time cost, forward:0.012044590062788277, backward:0.033005704083309946, data cost:0.6923449616130938 
2022-07-07 15:26:21,752: ============================================================
2022-07-07 15:26:21,752: Epoch 14/36 Batch 6000/7662 eta: 1 day, 11:15:28.005305	Training Loss1 4.6921 (4.5635)	Training Total_Loss 4.6921 (4.5635)	Training Prec@1 94.531 (96.281)	Training Prec@5 0.000 (0.000)	
2022-07-07 15:26:21,752: ============================================================
2022-07-07 15:27:35,166: time cost, forward:0.012051537146742647, backward:0.032997906139628344, data cost:0.6922828975633082 
2022-07-07 15:27:35,166: ============================================================
2022-07-07 15:27:35,167: Epoch 14/36 Batch 6100/7662 eta: 1 day, 10:41:38.097737	Training Loss1 4.4446 (4.5655)	Training Total_Loss 4.4446 (4.5655)	Training Prec@1 97.070 (96.273)	Training Prec@5 0.000 (0.000)	
2022-07-07 15:27:35,167: ============================================================
2022-07-07 15:28:48,384: time cost, forward:0.012064517592399192, backward:0.033001005197652096, data cost:0.6921748365388991 
2022-07-07 15:28:48,384: ============================================================
2022-07-07 15:28:48,385: Epoch 14/36 Batch 6200/7662 eta: 1 day, 10:34:50.219166	Training Loss1 4.6433 (4.5670)	Training Total_Loss 4.6433 (4.5670)	Training Prec@1 96.484 (96.268)	Training Prec@5 0.000 (0.000)	
2022-07-07 15:28:48,385: ============================================================
2022-07-07 15:30:02,154: time cost, forward:0.012075005532976446, backward:0.03299516858629129, data cost:0.6921663610570713 
2022-07-07 15:30:02,155: ============================================================
2022-07-07 15:30:02,155: Epoch 14/36 Batch 6300/7662 eta: 1 day, 10:49:15.824042	Training Loss1 4.6148 (4.5689)	Training Total_Loss 4.6148 (4.5689)	Training Prec@1 96.875 (96.261)	Training Prec@5 0.000 (0.000)	
2022-07-07 15:30:02,155: ============================================================
2022-07-07 15:31:16,232: time cost, forward:0.012069180526292255, backward:0.032993132294221, data cost:0.6922104844526865 
2022-07-07 15:31:16,233: ============================================================
2022-07-07 15:31:16,233: Epoch 14/36 Batch 6400/7662 eta: 1 day, 10:56:44.218838	Training Loss1 4.6867 (4.5704)	Training Total_Loss 4.6867 (4.5704)	Training Prec@1 95.898 (96.257)	Training Prec@5 0.000 (0.000)	
2022-07-07 15:31:16,233: ============================================================
2022-07-07 15:32:31,556: time cost, forward:0.01206727628800333, backward:0.03298014860040207, data cost:0.6924722328940287 
2022-07-07 15:32:31,557: ============================================================
2022-07-07 15:32:31,557: Epoch 14/36 Batch 6500/7662 eta: 1 day, 11:30:45.024457	Training Loss1 4.5921 (4.5718)	Training Total_Loss 4.5921 (4.5718)	Training Prec@1 95.703 (96.252)	Training Prec@5 0.000 (0.000)	
2022-07-07 15:32:31,557: ============================================================
2022-07-07 15:33:46,629: time cost, forward:0.012060949849005739, backward:0.0329765076528157, data cost:0.6926674303421018 
2022-07-07 15:33:46,630: ============================================================
2022-07-07 15:33:46,630: Epoch 14/36 Batch 6600/7662 eta: 1 day, 11:22:23.923143	Training Loss1 4.9561 (4.5731)	Training Total_Loss 4.9561 (4.5731)	Training Prec@1 94.531 (96.247)	Training Prec@5 0.000 (0.000)	
2022-07-07 15:33:46,630: ============================================================
2022-07-07 15:34:59,749: time cost, forward:0.012058739271390295, backward:0.032976296645951884, data cost:0.6925701730944253 
2022-07-07 15:34:59,750: ============================================================
2022-07-07 15:34:59,750: Epoch 14/36 Batch 6700/7662 eta: 1 day, 10:25:58.417051	Training Loss1 4.7203 (4.5744)	Training Total_Loss 4.7203 (4.5744)	Training Prec@1 95.312 (96.241)	Training Prec@5 0.000 (0.000)	
2022-07-07 15:34:59,750: ============================================================
2022-07-07 15:36:14,102: time cost, forward:0.012062282312580866, backward:0.03298146995766616, data cost:0.6926394750974094 
2022-07-07 15:36:14,103: ============================================================
2022-07-07 15:36:14,103: Epoch 14/36 Batch 6800/7662 eta: 1 day, 10:59:34.133126	Training Loss1 4.8509 (4.5758)	Training Total_Loss 4.8509 (4.5758)	Training Prec@1 95.508 (96.236)	Training Prec@5 0.000 (0.000)	
2022-07-07 15:36:14,103: ============================================================
2022-07-07 15:37:28,547: time cost, forward:0.012075649031453728, backward:0.03298274612647932, data cost:0.6927130489802772 
2022-07-07 15:37:28,547: ============================================================
2022-07-07 15:37:28,547: Epoch 14/36 Batch 6900/7662 eta: 1 day, 11:00:54.592844	Training Loss1 4.4924 (4.5775)	Training Total_Loss 4.4924 (4.5775)	Training Prec@1 95.703 (96.229)	Training Prec@5 0.000 (0.000)	
2022-07-07 15:37:28,548: ============================================================
2022-07-07 15:38:43,437: time cost, forward:0.012082493736124291, backward:0.032970054334598806, data cost:0.692869711644412 
2022-07-07 15:38:43,437: ============================================================
2022-07-07 15:38:43,437: Epoch 14/36 Batch 7000/7662 eta: 1 day, 11:12:14.202152	Training Loss1 4.6119 (4.5786)	Training Total_Loss 4.6119 (4.5786)	Training Prec@1 94.727 (96.224)	Training Prec@5 0.000 (0.000)	
2022-07-07 15:38:43,438: ============================================================
2022-07-07 15:39:56,780: time cost, forward:0.01207749311949841, backward:0.03297416769899034, data cost:0.6927970250335642 
2022-07-07 15:39:56,780: ============================================================
2022-07-07 15:39:56,781: Epoch 14/36 Batch 7100/7662 eta: 1 day, 10:27:23.120342	Training Loss1 4.6569 (4.5801)	Training Total_Loss 4.6569 (4.5801)	Training Prec@1 97.070 (96.219)	Training Prec@5 0.000 (0.000)	
2022-07-07 15:39:56,781: ============================================================
2022-07-07 15:41:10,726: time cost, forward:0.012076538161182258, backward:0.03297795184967766, data cost:0.6928023928684532 
2022-07-07 15:41:10,726: ============================================================
2022-07-07 15:41:10,727: Epoch 14/36 Batch 7200/7662 eta: 1 day, 10:43:08.470643	Training Loss1 4.9935 (4.5806)	Training Total_Loss 4.9935 (4.5806)	Training Prec@1 95.312 (96.217)	Training Prec@5 0.000 (0.000)	
2022-07-07 15:41:10,727: ============================================================
2022-07-07 15:42:24,349: time cost, forward:0.012079916191127206, backward:0.03299239707786852, data cost:0.6927594401310823 
2022-07-07 15:42:24,349: ============================================================
2022-07-07 15:42:24,350: Epoch 14/36 Batch 7300/7662 eta: 1 day, 10:32:49.219699	Training Loss1 4.4411 (4.5819)	Training Total_Loss 4.4411 (4.5819)	Training Prec@1 95.508 (96.209)	Training Prec@5 0.000 (0.000)	
2022-07-07 15:42:24,350: ============================================================
2022-07-07 15:43:39,669: time cost, forward:0.012084417591901837, backward:0.032997902381547414, data cost:0.6929512481493537 
2022-07-07 15:43:39,669: ============================================================
2022-07-07 15:43:39,669: Epoch 14/36 Batch 7400/7662 eta: 1 day, 11:19:19.883257	Training Loss1 4.4752 (4.5838)	Training Total_Loss 4.4752 (4.5838)	Training Prec@1 97.656 (96.202)	Training Prec@5 0.000 (0.000)	
2022-07-07 15:43:39,669: ============================================================
2022-07-07 15:44:53,452: time cost, forward:0.012092445131651098, backward:0.03299347285128129, data cost:0.6929358053022996 
2022-07-07 15:44:53,452: ============================================================
2022-07-07 15:44:53,452: Epoch 14/36 Batch 7500/7662 eta: 1 day, 10:34:51.836363	Training Loss1 4.5336 (4.5858)	Training Total_Loss 4.5336 (4.5858)	Training Prec@1 95.312 (96.192)	Training Prec@5 0.000 (0.000)	
2022-07-07 15:44:53,452: ============================================================
2022-07-07 15:46:06,739: time cost, forward:0.012093052799442219, backward:0.032995726720551656, data cost:0.6928574074442598 
2022-07-07 15:46:06,739: ============================================================
2022-07-07 15:46:06,740: Epoch 14/36 Batch 7600/7662 eta: 1 day, 10:19:42.305013	Training Loss1 4.5401 (4.5869)	Training Total_Loss 4.5401 (4.5869)	Training Prec@1 95.117 (96.185)	Training Prec@5 0.000 (0.000)	
2022-07-07 15:46:06,740: ============================================================
2022-07-07 15:46:54,989: Epoch 14/36 Batch 7663/7662 eta: 1 day, 10:18:56.133965	Training Loss1 4.2422 (4.5874)	Training Total_Loss 4.2422 (4.5874)	Training Prec@1 97.656 (96.183)	Training Prec@5 0.000 (0.000)	
2022-07-07 15:46:55,007: ============================================================
2022-07-07 15:48:18,867: time cost, forward:0.011105693952001706, backward:0.03237059862926753, data cost:0.796142380646985 
2022-07-07 15:48:18,867: ============================================================
2022-07-07 15:48:18,867: Epoch 15/36 Batch 100/7662 eta: 1 day, 15:12:55.141170	Training Loss1 4.0624 (4.0968)	Training Total_Loss 4.0624 (4.0968)	Training Prec@1 96.289 (97.343)	Training Prec@5 0.000 (0.000)	
2022-07-07 15:48:18,868: ============================================================
2022-07-07 15:49:31,283: time cost, forward:0.011107387255184615, backward:0.032853300247959155, data cost:0.7379906141578253 
2022-07-07 15:49:31,283: ============================================================
2022-07-07 15:49:31,284: Epoch 15/36 Batch 200/7662 eta: 1 day, 9:52:03.617691	Training Loss1 4.2202 (4.1283)	Training Total_Loss 4.2202 (4.1283)	Training Prec@1 98.633 (97.285)	Training Prec@5 0.000 (0.000)	
2022-07-07 15:49:31,284: ============================================================
2022-07-07 15:50:44,921: time cost, forward:0.011373181805562814, backward:0.03305877570723211, data cost:0.721725126572676 
2022-07-07 15:50:44,922: ============================================================
2022-07-07 15:50:44,922: Epoch 15/36 Batch 300/7662 eta: 1 day, 10:25:07.414791	Training Loss1 4.0363 (4.1469)	Training Total_Loss 4.0363 (4.1469)	Training Prec@1 98.242 (97.303)	Training Prec@5 0.000 (0.000)	
2022-07-07 15:50:44,922: ============================================================
2022-07-07 15:51:56,788: time cost, forward:0.011348311464888112, backward:0.03318007787068685, data cost:0.7098564886509028 
2022-07-07 15:51:56,789: ============================================================
2022-07-07 15:51:56,789: Epoch 15/36 Batch 400/7662 eta: 1 day, 9:34:14.868086	Training Loss1 4.0923 (4.1593)	Training Total_Loss 4.0923 (4.1593)	Training Prec@1 97.070 (97.290)	Training Prec@5 0.000 (0.000)	
2022-07-07 15:51:56,789: ============================================================
2022-07-07 15:53:10,027: time cost, forward:0.011494986279932912, backward:0.03338002394100946, data cost:0.7048442153510206 
2022-07-07 15:53:10,028: ============================================================
2022-07-07 15:53:10,028: Epoch 15/36 Batch 500/7662 eta: 1 day, 10:11:29.641988	Training Loss1 4.5924 (4.1817)	Training Total_Loss 4.5924 (4.1817)	Training Prec@1 96.289 (97.256)	Training Prec@5 0.000 (0.000)	
2022-07-07 15:53:10,028: ============================================================
2022-07-07 15:54:21,856: time cost, forward:0.011445954168380202, backward:0.033374332227372565, data cost:0.6996406270984019 
2022-07-07 15:54:21,857: ============================================================
2022-07-07 15:54:21,857: Epoch 15/36 Batch 600/7662 eta: 1 day, 9:30:47.190997	Training Loss1 4.1864 (4.1970)	Training Total_Loss 4.1864 (4.1970)	Training Prec@1 97.266 (97.213)	Training Prec@5 0.000 (0.000)	
2022-07-07 15:54:21,857: ============================================================
2022-07-07 15:55:34,895: time cost, forward:0.01161953069280316, backward:0.03334428141898181, data cost:0.6974029602410967 
2022-07-07 15:55:34,895: ============================================================
2022-07-07 15:55:34,895: Epoch 15/36 Batch 700/7662 eta: 1 day, 10:03:26.076543	Training Loss1 4.1572 (4.2119)	Training Total_Loss 4.1572 (4.2119)	Training Prec@1 97.461 (97.181)	Training Prec@5 0.000 (0.000)	
2022-07-07 15:55:34,895: ============================================================
2022-07-07 15:56:46,646: time cost, forward:0.01160485693748961, backward:0.03333587073563634, data cost:0.69423919834094 
2022-07-07 15:56:46,647: ============================================================
2022-07-07 15:56:46,647: Epoch 15/36 Batch 800/7662 eta: 1 day, 9:26:13.733000	Training Loss1 4.2750 (4.2245)	Training Total_Loss 4.2750 (4.2245)	Training Prec@1 97.461 (97.164)	Training Prec@5 0.000 (0.000)	
2022-07-07 15:56:46,647: ============================================================
2022-07-07 15:57:59,728: time cost, forward:0.011601669504592097, backward:0.03331547610884381, data cost:0.6932648336794538 
2022-07-07 15:57:59,729: ============================================================
2022-07-07 15:57:59,729: Epoch 15/36 Batch 900/7662 eta: 1 day, 10:02:13.268716	Training Loss1 4.4211 (4.2364)	Training Total_Loss 4.4211 (4.2364)	Training Prec@1 97.266 (97.137)	Training Prec@5 0.000 (0.000)	
2022-07-07 15:57:59,729: ============================================================
2022-07-07 15:59:13,164: time cost, forward:0.01159329743714662, backward:0.03330067805461101, data cost:0.6928499234211934 
2022-07-07 15:59:13,164: ============================================================
2022-07-07 15:59:13,165: Epoch 15/36 Batch 1000/7662 eta: 1 day, 10:10:52.318466	Training Loss1 4.1717 (4.2491)	Training Total_Loss 4.1717 (4.2491)	Training Prec@1 97.266 (97.128)	Training Prec@5 0.000 (0.000)	
2022-07-07 15:59:13,165: ============================================================
2022-07-07 16:00:25,642: time cost, forward:0.011562919052651626, backward:0.03330653770280166, data cost:0.6916304660776292 
2022-07-07 16:00:25,642: ============================================================
2022-07-07 16:00:25,643: Epoch 15/36 Batch 1100/7662 eta: 1 day, 9:42:55.368019	Training Loss1 4.1975 (4.2601)	Training Total_Loss 4.1975 (4.2601)	Training Prec@1 97.070 (97.111)	Training Prec@5 0.000 (0.000)	
2022-07-07 16:00:25,643: ============================================================
2022-07-07 16:01:39,470: time cost, forward:0.011628029443901514, backward:0.033308179901479384, data cost:0.691669116922972 
2022-07-07 16:01:39,470: ============================================================
2022-07-07 16:01:39,470: Epoch 15/36 Batch 1200/7662 eta: 1 day, 10:19:21.512466	Training Loss1 4.3996 (4.2725)	Training Total_Loss 4.3996 (4.2725)	Training Prec@1 96.094 (97.087)	Training Prec@5 0.000 (0.000)	
2022-07-07 16:01:39,470: ============================================================
2022-07-07 16:02:53,906: time cost, forward:0.011629778389934396, backward:0.03326652745635258, data cost:0.6922385756835467 
2022-07-07 16:02:53,907: ============================================================
2022-07-07 16:02:53,907: Epoch 15/36 Batch 1300/7662 eta: 1 day, 10:35:06.362190	Training Loss1 4.4275 (4.2831)	Training Total_Loss 4.4275 (4.2831)	Training Prec@1 96.484 (97.058)	Training Prec@5 0.000 (0.000)	
2022-07-07 16:02:53,907: ============================================================
2022-07-07 16:04:08,018: time cost, forward:0.011627169657469308, backward:0.033292885930986386, data cost:0.692479385828614 
2022-07-07 16:04:08,019: ============================================================
2022-07-07 16:04:08,019: Epoch 15/36 Batch 1400/7662 eta: 1 day, 10:24:49.835327	Training Loss1 4.5534 (4.2905)	Training Total_Loss 4.5534 (4.2905)	Training Prec@1 97.070 (97.043)	Training Prec@5 0.000 (0.000)	
2022-07-07 16:04:08,019: ============================================================
2022-07-07 16:05:20,338: time cost, forward:0.011606484910024651, backward:0.033284389948829006, data cost:0.6915168870362224 
2022-07-07 16:05:20,338: ============================================================
2022-07-07 16:05:20,338: Epoch 15/36 Batch 1500/7662 eta: 1 day, 9:33:39.938508	Training Loss1 4.2632 (4.2982)	Training Total_Loss 4.2632 (4.2982)	Training Prec@1 96.875 (97.031)	Training Prec@5 0.000 (0.000)	
2022-07-07 16:05:20,338: ============================================================
2022-07-07 16:06:34,211: time cost, forward:0.011645470804688035, backward:0.03329422713966203, data cost:0.6915791070483639 
2022-07-07 16:06:34,211: ============================================================
2022-07-07 16:06:34,212: Epoch 15/36 Batch 1600/7662 eta: 1 day, 10:15:42.736595	Training Loss1 4.5401 (4.3076)	Training Total_Loss 4.5401 (4.3076)	Training Prec@1 96.484 (97.002)	Training Prec@5 0.000 (0.000)	
2022-07-07 16:06:34,212: ============================================================
2022-07-07 16:07:48,021: time cost, forward:0.011637611905570028, backward:0.03331632064046967, data cost:0.6916133240435388 
2022-07-07 16:07:48,021: ============================================================
2022-07-07 16:07:48,021: Epoch 15/36 Batch 1700/7662 eta: 1 day, 10:12:42.301707	Training Loss1 4.4914 (4.3167)	Training Total_Loss 4.4914 (4.3167)	Training Prec@1 97.852 (96.981)	Training Prec@5 0.000 (0.000)	
2022-07-07 16:07:48,021: ============================================================
2022-07-07 16:09:01,937: time cost, forward:0.011663097351905436, backward:0.03332311183363282, data cost:0.691675948990657 
2022-07-07 16:09:01,938: ============================================================
2022-07-07 16:09:01,938: Epoch 15/36 Batch 1800/7662 eta: 1 day, 10:14:27.633057	Training Loss1 4.6835 (4.3262)	Training Total_Loss 4.6835 (4.3262)	Training Prec@1 96.094 (96.962)	Training Prec@5 0.000 (0.000)	
2022-07-07 16:09:01,938: ============================================================
2022-07-07 16:10:15,629: time cost, forward:0.011656839010149257, backward:0.03333711398156333, data cost:0.6916605030128113 
2022-07-07 16:10:15,629: ============================================================
2022-07-07 16:10:15,629: Epoch 15/36 Batch 1900/7662 eta: 1 day, 10:06:57.223538	Training Loss1 4.3316 (4.3344)	Training Total_Loss 4.3316 (4.3344)	Training Prec@1 97.266 (96.943)	Training Prec@5 0.000 (0.000)	
2022-07-07 16:10:15,629: ============================================================
2022-07-07 16:11:28,219: time cost, forward:0.01166210215111981, backward:0.03336266758085311, data cost:0.691064289297206 
2022-07-07 16:11:28,219: ============================================================
2022-07-07 16:11:28,220: Epoch 15/36 Batch 2000/7662 eta: 1 day, 9:35:10.153264	Training Loss1 4.4471 (4.3431)	Training Total_Loss 4.4471 (4.3431)	Training Prec@1 96.484 (96.923)	Training Prec@5 0.000 (0.000)	
2022-07-07 16:11:28,220: ============================================================
2022-07-07 16:12:43,775: time cost, forward:0.011683477907875937, backward:0.03333523581288098, data cost:0.6919715706651242 
2022-07-07 16:12:43,776: ============================================================
2022-07-07 16:12:43,776: Epoch 15/36 Batch 2100/7662 eta: 1 day, 10:56:14.731169	Training Loss1 4.3722 (4.3499)	Training Total_Loss 4.3722 (4.3499)	Training Prec@1 96.484 (96.907)	Training Prec@5 0.000 (0.000)	
2022-07-07 16:12:43,776: ============================================================
2022-07-07 16:13:57,567: time cost, forward:0.011684451226810805, backward:0.03333933801204305, data cost:0.6919799989437504 
2022-07-07 16:13:57,567: ============================================================
2022-07-07 16:13:57,567: Epoch 15/36 Batch 2200/7662 eta: 1 day, 10:06:03.301713	Training Loss1 4.7016 (4.3568)	Training Total_Loss 4.7016 (4.3568)	Training Prec@1 95.703 (96.887)	Training Prec@5 0.000 (0.000)	
2022-07-07 16:13:57,567: ============================================================
2022-07-07 16:15:10,142: time cost, forward:0.01170433008344135, backward:0.033352363000698014, data cost:0.6914276541601632 
2022-07-07 16:15:10,143: ============================================================
2022-07-07 16:15:10,143: Epoch 15/36 Batch 2300/7662 eta: 1 day, 9:31:07.655887	Training Loss1 4.6812 (4.3627)	Training Total_Loss 4.6812 (4.3627)	Training Prec@1 95.703 (96.871)	Training Prec@5 0.000 (0.000)	
2022-07-07 16:15:10,143: ============================================================
2022-07-07 16:16:23,581: time cost, forward:0.011710575194396592, backward:0.033353185693439515, data cost:0.6913138449614422 
2022-07-07 16:16:23,581: ============================================================
2022-07-07 16:16:23,581: Epoch 15/36 Batch 2400/7662 eta: 1 day, 9:53:48.787863	Training Loss1 4.3273 (4.3690)	Training Total_Loss 4.3273 (4.3690)	Training Prec@1 97.266 (96.853)	Training Prec@5 0.000 (0.000)	
2022-07-07 16:16:23,581: ============================================================
2022-07-07 16:17:36,976: time cost, forward:0.011719294288913076, backward:0.0333695955494014, data cost:0.6911653655679191 
2022-07-07 16:17:36,977: ============================================================
2022-07-07 16:17:36,977: Epoch 15/36 Batch 2500/7662 eta: 1 day, 9:51:24.318149	Training Loss1 4.7004 (4.3748)	Training Total_Loss 4.7004 (4.3748)	Training Prec@1 97.852 (96.835)	Training Prec@5 0.000 (0.000)	
2022-07-07 16:17:36,977: ============================================================
2022-07-07 16:18:50,069: time cost, forward:0.011709316274944568, backward:0.03336280187582594, data cost:0.6909528493239082 
2022-07-07 16:18:50,070: ============================================================
2022-07-07 16:18:50,070: Epoch 15/36 Batch 2600/7662 eta: 1 day, 9:41:49.310158	Training Loss1 4.2496 (4.3803)	Training Total_Loss 4.2496 (4.3803)	Training Prec@1 97.266 (96.818)	Training Prec@5 0.000 (0.000)	
2022-07-07 16:18:50,070: ============================================================
2022-07-07 16:20:04,493: time cost, forward:0.011718928173499092, backward:0.03334725587709871, data cost:0.691239093311984 
2022-07-07 16:20:04,494: ============================================================
2022-07-07 16:20:04,494: Epoch 15/36 Batch 2700/7662 eta: 1 day, 10:17:23.433682	Training Loss1 4.5381 (4.3861)	Training Total_Loss 4.5381 (4.3861)	Training Prec@1 97.070 (96.807)	Training Prec@5 0.000 (0.000)	
2022-07-07 16:20:04,494: ============================================================
2022-07-07 16:21:17,099: time cost, forward:0.011692298655426472, backward:0.033347784599775755, data cost:0.6908840047073773 
2022-07-07 16:21:17,100: ============================================================
2022-07-07 16:21:17,100: Epoch 15/36 Batch 2800/7662 eta: 1 day, 9:25:54.757217	Training Loss1 4.4587 (4.3924)	Training Total_Loss 4.4587 (4.3924)	Training Prec@1 95.898 (96.786)	Training Prec@5 0.000 (0.000)	
2022-07-07 16:21:17,100: ============================================================
2022-07-07 16:22:31,319: time cost, forward:0.011722423077123088, backward:0.033349963540494666, data cost:0.6910560577645225 
2022-07-07 16:22:31,319: ============================================================
2022-07-07 16:22:31,319: Epoch 15/36 Batch 2900/7662 eta: 1 day, 10:09:15.904227	Training Loss1 4.4737 (4.3977)	Training Total_Loss 4.4737 (4.3977)	Training Prec@1 96.875 (96.772)	Training Prec@5 0.000 (0.000)	
2022-07-07 16:22:31,319: ============================================================
2022-07-07 16:23:45,743: time cost, forward:0.01173392825621134, backward:0.033355284786574166, data cost:0.6912854228189843 
2022-07-07 16:23:45,743: ============================================================
2022-07-07 16:23:45,744: Epoch 15/36 Batch 3000/7662 eta: 1 day, 10:13:41.202880	Training Loss1 4.4914 (4.4029)	Training Total_Loss 4.4914 (4.4029)	Training Prec@1 96.094 (96.757)	Training Prec@5 0.000 (0.000)	
2022-07-07 16:23:45,744: ============================================================
2022-07-07 16:24:59,795: time cost, forward:0.011726707902867088, backward:0.03335708070085987, data cost:0.6913972396395136 
2022-07-07 16:24:59,795: ============================================================
2022-07-07 16:24:59,795: Epoch 15/36 Batch 3100/7662 eta: 1 day, 10:02:08.980470	Training Loss1 4.3045 (4.4068)	Training Total_Loss 4.3045 (4.4068)	Training Prec@1 97.266 (96.744)	Training Prec@5 0.000 (0.000)	
2022-07-07 16:24:59,795: ============================================================
2022-07-07 16:26:15,092: time cost, forward:0.011734847986686971, backward:0.03335077243135959, data cost:0.6918509661611001 
2022-07-07 16:26:15,093: ============================================================
2022-07-07 16:26:15,093: Epoch 15/36 Batch 3200/7662 eta: 1 day, 10:35:15.700451	Training Loss1 4.7252 (4.4112)	Training Total_Loss 4.7252 (4.4112)	Training Prec@1 95.898 (96.729)	Training Prec@5 0.000 (0.000)	
2022-07-07 16:26:15,093: ============================================================
2022-07-07 16:27:30,044: time cost, forward:0.011745761690373925, backward:0.03333962119033966, data cost:0.6922587937895331 
2022-07-07 16:27:30,044: ============================================================
2022-07-07 16:27:30,044: Epoch 15/36 Batch 3300/7662 eta: 1 day, 10:24:28.314254	Training Loss1 4.5986 (4.4161)	Training Total_Loss 4.5986 (4.4161)	Training Prec@1 97.656 (96.717)	Training Prec@5 0.000 (0.000)	
2022-07-07 16:27:30,044: ============================================================
2022-07-07 16:28:44,739: time cost, forward:0.011740922015987799, backward:0.033337401586197586, data cost:0.6925310840253165 
2022-07-07 16:28:44,739: ============================================================
2022-07-07 16:28:44,740: Epoch 15/36 Batch 3400/7662 eta: 1 day, 10:16:10.666860	Training Loss1 4.5086 (4.4200)	Training Total_Loss 4.5086 (4.4200)	Training Prec@1 98.633 (96.705)	Training Prec@5 0.000 (0.000)	
2022-07-07 16:28:44,740: ============================================================
2022-07-07 16:29:58,739: time cost, forward:0.011742844108718911, backward:0.03335263218733882, data cost:0.6925634924225481 
2022-07-07 16:29:58,739: ============================================================
2022-07-07 16:29:58,739: Epoch 15/36 Batch 3500/7662 eta: 1 day, 9:55:47.648997	Training Loss1 4.3244 (4.4236)	Training Total_Loss 4.3244 (4.4236)	Training Prec@1 96.289 (96.691)	Training Prec@5 0.000 (0.000)	
2022-07-07 16:29:58,739: ============================================================
2022-07-07 16:31:12,960: time cost, forward:0.011752972903600101, backward:0.03335787164201071, data cost:0.6926610021334153 
2022-07-07 16:31:12,960: ============================================================
2022-07-07 16:31:12,961: Epoch 15/36 Batch 3600/7662 eta: 1 day, 10:00:39.208262	Training Loss1 4.4964 (4.4283)	Training Total_Loss 4.4964 (4.4283)	Training Prec@1 97.266 (96.674)	Training Prec@5 0.000 (0.000)	
2022-07-07 16:31:12,961: ============================================================
2022-07-07 16:32:25,732: time cost, forward:0.011743453361756674, backward:0.03335003261148495, data cost:0.6923899564848748 
2022-07-07 16:32:25,732: ============================================================
2022-07-07 16:32:25,732: Epoch 15/36 Batch 3700/7662 eta: 1 day, 9:19:34.786329	Training Loss1 4.2770 (4.4314)	Training Total_Loss 4.2770 (4.4314)	Training Prec@1 97.461 (96.662)	Training Prec@5 0.000 (0.000)	
2022-07-07 16:32:25,732: ============================================================
2022-07-07 16:33:40,762: time cost, forward:0.01175507892900845, backward:0.03333851989240011, data cost:0.6927161984269197 
2022-07-07 16:33:40,763: ============================================================
2022-07-07 16:33:40,763: Epoch 15/36 Batch 3800/7662 eta: 1 day, 10:20:24.043287	Training Loss1 4.4418 (4.4351)	Training Total_Loss 4.4418 (4.4351)	Training Prec@1 97.070 (96.647)	Training Prec@5 0.000 (0.000)	
2022-07-07 16:33:40,763: ============================================================
2022-07-07 16:34:56,515: time cost, forward:0.01177642552722384, backward:0.03333392214181943, data cost:0.6931875397774402 
2022-07-07 16:34:56,515: ============================================================
2022-07-07 16:34:56,515: Epoch 15/36 Batch 3900/7662 eta: 1 day, 10:38:58.186745	Training Loss1 4.5811 (4.4388)	Training Total_Loss 4.5811 (4.4388)	Training Prec@1 96.680 (96.637)	Training Prec@5 0.000 (0.000)	
2022-07-07 16:34:56,516: ============================================================
2022-07-07 16:36:10,957: time cost, forward:0.01179153056525087, backward:0.03335258697801663, data cost:0.6932868459696292 
2022-07-07 16:36:10,957: ============================================================
2022-07-07 16:36:10,957: Epoch 15/36 Batch 4000/7662 eta: 1 day, 10:01:44.863907	Training Loss1 4.5982 (4.4427)	Training Total_Loss 4.5982 (4.4427)	Training Prec@1 95.508 (96.624)	Training Prec@5 0.000 (0.000)	
2022-07-07 16:36:10,957: ============================================================
2022-07-07 16:37:27,283: time cost, forward:0.011810480835787347, backward:0.03335246024232982, data cost:0.6938574755008583 
2022-07-07 16:37:27,283: ============================================================
2022-07-07 16:37:27,284: Epoch 15/36 Batch 4100/7662 eta: 1 day, 10:52:10.483604	Training Loss1 4.7236 (4.4456)	Training Total_Loss 4.7236 (4.4456)	Training Prec@1 96.680 (96.613)	Training Prec@5 0.000 (0.000)	
2022-07-07 16:37:27,284: ============================================================
2022-07-07 16:38:41,581: time cost, forward:0.011808339514372377, backward:0.033355377492066594, data cost:0.6939390714068048 
2022-07-07 16:38:41,582: ============================================================
2022-07-07 16:38:41,582: Epoch 15/36 Batch 4200/7662 eta: 1 day, 9:55:20.366747	Training Loss1 4.8602 (4.4488)	Training Total_Loss 4.8602 (4.4488)	Training Prec@1 95.508 (96.602)	Training Prec@5 0.000 (0.000)	
2022-07-07 16:38:41,582: ============================================================
2022-07-07 16:39:55,961: time cost, forward:0.01181129234617437, backward:0.03337123034083031, data cost:0.6940158838226397 
2022-07-07 16:39:55,961: ============================================================
2022-07-07 16:39:55,961: Epoch 15/36 Batch 4300/7662 eta: 1 day, 9:56:19.448325	Training Loss1 4.4592 (4.4522)	Training Total_Loss 4.4592 (4.4522)	Training Prec@1 95.898 (96.595)	Training Prec@5 0.000 (0.000)	
2022-07-07 16:39:55,961: ============================================================
2022-07-07 16:41:09,965: time cost, forward:0.011831903327565542, backward:0.033403119490238234, data cost:0.6939689261611415 
2022-07-07 16:41:09,965: ============================================================
2022-07-07 16:41:09,966: Epoch 15/36 Batch 4400/7662 eta: 1 day, 9:44:49.146763	Training Loss1 4.6791 (4.4555)	Training Total_Loss 4.6791 (4.4555)	Training Prec@1 94.922 (96.580)	Training Prec@5 0.000 (0.000)	
2022-07-07 16:41:09,966: ============================================================
2022-07-07 16:42:23,265: time cost, forward:0.011851994083520704, backward:0.03342404575394535, data cost:0.6937796787093231 
2022-07-07 16:42:23,265: ============================================================
2022-07-07 16:42:23,265: Epoch 15/36 Batch 4500/7662 eta: 1 day, 9:24:18.900150	Training Loss1 4.6208 (4.4586)	Training Total_Loss 4.6208 (4.4586)	Training Prec@1 95.703 (96.568)	Training Prec@5 0.000 (0.000)	
2022-07-07 16:42:23,265: ============================================================
2022-07-07 16:43:36,081: time cost, forward:0.011851924013692313, backward:0.03341754573043156, data cost:0.6935326651299252 
2022-07-07 16:43:36,082: ============================================================
2022-07-07 16:43:36,082: Epoch 15/36 Batch 4600/7662 eta: 1 day, 9:09:53.615187	Training Loss1 4.4693 (4.4616)	Training Total_Loss 4.4693 (4.4616)	Training Prec@1 96.875 (96.560)	Training Prec@5 0.000 (0.000)	
2022-07-07 16:43:36,082: ============================================================
2022-07-07 16:44:50,711: time cost, forward:0.011871321248510945, backward:0.033400921142717754, data cost:0.6936830602622738 
2022-07-07 16:44:50,711: ============================================================
2022-07-07 16:44:50,711: Epoch 15/36 Batch 4700/7662 eta: 1 day, 9:58:11.757785	Training Loss1 4.6822 (4.4640)	Training Total_Loss 4.6822 (4.4640)	Training Prec@1 93.555 (96.550)	Training Prec@5 0.000 (0.000)	
2022-07-07 16:44:50,711: ============================================================
2022-07-07 16:46:04,959: time cost, forward:0.011888441480082952, backward:0.03340571536250749, data cost:0.6937161712602765 
2022-07-07 16:46:04,960: ============================================================
2022-07-07 16:46:04,960: Epoch 15/36 Batch 4800/7662 eta: 1 day, 9:46:33.152643	Training Loss1 4.9506 (4.4662)	Training Total_Loss 4.9506 (4.4662)	Training Prec@1 96.484 (96.542)	Training Prec@5 0.000 (0.000)	
2022-07-07 16:46:04,960: ============================================================
2022-07-07 16:47:19,717: time cost, forward:0.011881846266149087, backward:0.03340313872115226, data cost:0.6938870711870694 
2022-07-07 16:47:19,717: ============================================================
2022-07-07 16:47:19,718: Epoch 15/36 Batch 4900/7662 eta: 1 day, 9:59:12.302810	Training Loss1 4.5367 (4.4696)	Training Total_Loss 4.5367 (4.4696)	Training Prec@1 96.484 (96.530)	Training Prec@5 0.000 (0.000)	
2022-07-07 16:47:19,718: ============================================================
2022-07-07 16:48:32,859: time cost, forward:0.011874297829383993, backward:0.033395624799856215, data cost:0.6937344982805765 
2022-07-07 16:48:32,859: ============================================================
2022-07-07 16:48:32,860: Epoch 15/36 Batch 5000/7662 eta: 1 day, 9:13:54.521929	Training Loss1 4.6470 (4.4725)	Training Total_Loss 4.6470 (4.4725)	Training Prec@1 96.484 (96.523)	Training Prec@5 0.000 (0.000)	
2022-07-07 16:48:32,860: ============================================================
2022-07-07 16:49:47,656: time cost, forward:0.01189603789644303, backward:0.0333964222902222, data cost:0.6938795443492021 
2022-07-07 16:49:47,656: ============================================================
2022-07-07 16:49:47,656: Epoch 15/36 Batch 5100/7662 eta: 1 day, 9:57:46.683268	Training Loss1 4.4979 (4.4752)	Training Total_Loss 4.4979 (4.4752)	Training Prec@1 96.289 (96.513)	Training Prec@5 0.000 (0.000)	
2022-07-07 16:49:47,657: ============================================================
2022-07-07 16:51:01,274: time cost, forward:0.011914575620439563, backward:0.03339891916147721, data cost:0.6937908110056366 
2022-07-07 16:51:01,275: ============================================================
2022-07-07 16:51:01,275: Epoch 15/36 Batch 5200/7662 eta: 1 day, 9:24:26.872253	Training Loss1 4.5324 (4.4771)	Training Total_Loss 4.5324 (4.4771)	Training Prec@1 96.484 (96.503)	Training Prec@5 0.000 (0.000)	
2022-07-07 16:51:01,275: ============================================================
2022-07-07 16:52:15,900: time cost, forward:0.011917773767065655, backward:0.03338927222908972, data cost:0.6939185659128172 
2022-07-07 16:52:15,901: ============================================================
2022-07-07 16:52:15,901: Epoch 15/36 Batch 5300/7662 eta: 1 day, 9:50:38.251665	Training Loss1 4.6511 (4.4792)	Training Total_Loss 4.6511 (4.4792)	Training Prec@1 94.922 (96.491)	Training Prec@5 0.000 (0.000)	
2022-07-07 16:52:15,901: ============================================================
2022-07-07 16:53:30,184: time cost, forward:0.011922431579451359, backward:0.03338176799187022, data cost:0.6939780598637085 
2022-07-07 16:53:30,184: ============================================================
2022-07-07 16:53:30,184: Epoch 15/36 Batch 5400/7662 eta: 1 day, 9:40:04.477807	Training Loss1 4.6380 (4.4815)	Training Total_Loss 4.6380 (4.4815)	Training Prec@1 95.117 (96.484)	Training Prec@5 0.000 (0.000)	
2022-07-07 16:53:30,185: ============================================================
2022-07-07 16:54:44,550: time cost, forward:0.011943263343343476, backward:0.03336156665422544, data cost:0.6940438615168023 
2022-07-07 16:54:44,550: ============================================================
2022-07-07 16:54:44,550: Epoch 15/36 Batch 5500/7662 eta: 1 day, 9:41:04.492475	Training Loss1 4.6543 (4.4839)	Training Total_Loss 4.6543 (4.4839)	Training Prec@1 97.656 (96.475)	Training Prec@5 0.000 (0.000)	
2022-07-07 16:54:44,550: ============================================================
2022-07-07 16:55:58,547: time cost, forward:0.011948672378248435, backward:0.03336360710479251, data cost:0.694041434686766 
2022-07-07 16:55:58,548: ============================================================
2022-07-07 16:55:58,548: Epoch 15/36 Batch 5600/7662 eta: 1 day, 9:29:50.591494	Training Loss1 4.7414 (4.4858)	Training Total_Loss 4.7414 (4.4858)	Training Prec@1 95.703 (96.466)	Training Prec@5 0.000 (0.000)	
2022-07-07 16:55:58,548: ============================================================
2022-07-07 16:57:13,050: time cost, forward:0.01196486838220776, backward:0.033367980005532365, data cost:0.6940841850930712 
2022-07-07 16:57:13,050: ============================================================
2022-07-07 16:57:13,050: Epoch 15/36 Batch 5700/7662 eta: 1 day, 9:42:18.450899	Training Loss1 4.6213 (4.4878)	Training Total_Loss 4.6213 (4.4878)	Training Prec@1 94.336 (96.459)	Training Prec@5 0.000 (0.000)	
2022-07-07 16:57:13,051: ============================================================
2022-07-07 16:58:26,737: time cost, forward:0.011967472998021615, backward:0.0333691233292718, data cost:0.6940449112179896 
2022-07-07 16:58:26,737: ============================================================
2022-07-07 16:58:26,737: Epoch 15/36 Batch 5800/7662 eta: 1 day, 9:18:56.415876	Training Loss1 4.6074 (4.4897)	Training Total_Loss 4.6074 (4.4897)	Training Prec@1 95.703 (96.451)	Training Prec@5 0.000 (0.000)	
2022-07-07 16:58:26,737: ============================================================
2022-07-07 16:59:40,454: time cost, forward:0.011971637381802456, backward:0.03336893528027946, data cost:0.6939971897638052 
2022-07-07 16:59:40,454: ============================================================
2022-07-07 16:59:40,454: Epoch 15/36 Batch 5900/7662 eta: 1 day, 9:18:31.319434	Training Loss1 4.9966 (4.4917)	Training Total_Loss 4.9966 (4.4917)	Training Prec@1 94.141 (96.443)	Training Prec@5 0.000 (0.000)	
2022-07-07 16:59:40,454: ============================================================
2022-07-07 17:00:54,626: time cost, forward:0.011984796201334256, backward:0.0333527928889841, data cost:0.694030457445931 
2022-07-07 17:00:54,626: ============================================================
2022-07-07 17:00:54,627: Epoch 15/36 Batch 6000/7662 eta: 1 day, 9:29:38.459340	Training Loss1 4.6993 (4.4937)	Training Total_Loss 4.6993 (4.4937)	Training Prec@1 95.703 (96.434)	Training Prec@5 0.000 (0.000)	
2022-07-07 17:00:54,627: ============================================================
2022-07-07 17:02:08,331: time cost, forward:0.011994725036746185, backward:0.033359181237897044, data cost:0.6939617102801712 
2022-07-07 17:02:08,332: ============================================================
2022-07-07 17:02:08,332: Epoch 15/36 Batch 6100/7662 eta: 1 day, 9:15:45.186034	Training Loss1 4.6980 (4.4953)	Training Total_Loss 4.6980 (4.4953)	Training Prec@1 95.898 (96.426)	Training Prec@5 0.000 (0.000)	
2022-07-07 17:02:08,332: ============================================================
2022-07-07 17:03:23,490: time cost, forward:0.012002520569679641, backward:0.03335421353429532, data cost:0.6941497185130642 
2022-07-07 17:03:23,490: ============================================================
2022-07-07 17:03:23,490: Epoch 15/36 Batch 6200/7662 eta: 1 day, 9:53:51.005548	Training Loss1 4.5599 (4.4974)	Training Total_Loss 4.5599 (4.4974)	Training Prec@1 95.508 (96.417)	Training Prec@5 0.000 (0.000)	
2022-07-07 17:03:23,490: ============================================================
2022-07-07 17:04:37,986: time cost, forward:0.012016388589871424, backward:0.033371641590853006, data cost:0.6941937616768858 
2022-07-07 17:04:37,986: ============================================================
2022-07-07 17:04:37,986: Epoch 15/36 Batch 6300/7662 eta: 1 day, 9:34:41.164284	Training Loss1 4.6954 (4.4989)	Training Total_Loss 4.6954 (4.4989)	Training Prec@1 94.531 (96.411)	Training Prec@5 0.000 (0.000)	
2022-07-07 17:04:37,986: ============================================================
2022-07-07 17:05:51,557: time cost, forward:0.012030963842562166, backward:0.03337069961648003, data cost:0.6941102899076567 
2022-07-07 17:05:51,557: ============================================================
2022-07-07 17:05:51,558: Epoch 15/36 Batch 6400/7662 eta: 1 day, 9:08:26.715043	Training Loss1 4.6199 (4.5008)	Training Total_Loss 4.6199 (4.5008)	Training Prec@1 94.922 (96.401)	Training Prec@5 0.000 (0.000)	
2022-07-07 17:05:51,558: ============================================================
2022-07-07 17:07:06,096: time cost, forward:0.012034967654043756, backward:0.03337333176315409, data cost:0.6941826856765477 
2022-07-07 17:07:06,096: ============================================================
2022-07-07 17:07:06,096: Epoch 15/36 Batch 6500/7662 eta: 1 day, 9:33:21.179871	Training Loss1 4.7073 (4.5021)	Training Total_Loss 4.7073 (4.5021)	Training Prec@1 95.508 (96.394)	Training Prec@5 0.000 (0.000)	
2022-07-07 17:07:06,096: ============================================================
2022-07-07 17:08:21,038: time cost, forward:0.01203710459492246, backward:0.03336824401072759, data cost:0.6943269744933166 
2022-07-07 17:08:21,039: ============================================================
2022-07-07 17:08:21,039: Epoch 15/36 Batch 6600/7662 eta: 1 day, 9:43:01.067091	Training Loss1 4.3773 (4.5041)	Training Total_Loss 4.3773 (4.5041)	Training Prec@1 95.898 (96.384)	Training Prec@5 0.000 (0.000)	
2022-07-07 17:08:21,039: ============================================================
2022-07-07 17:09:35,891: time cost, forward:0.012027942025673925, backward:0.03336403013645917, data cost:0.6944650250560295 
2022-07-07 17:09:35,891: ============================================================
2022-07-07 17:09:35,892: Epoch 15/36 Batch 6700/7662 eta: 1 day, 9:39:19.899883	Training Loss1 4.6558 (4.5058)	Training Total_Loss 4.6558 (4.5058)	Training Prec@1 95.898 (96.379)	Training Prec@5 0.000 (0.000)	
2022-07-07 17:09:35,892: ============================================================
2022-07-07 17:10:50,488: time cost, forward:0.012029598803884194, backward:0.033355450766948166, data cost:0.6945503288585485 
2022-07-07 17:10:50,489: ============================================================
2022-07-07 17:10:50,489: Epoch 15/36 Batch 6800/7662 eta: 1 day, 9:31:12.197471	Training Loss1 4.3910 (4.5076)	Training Total_Loss 4.3910 (4.5076)	Training Prec@1 95.508 (96.372)	Training Prec@5 0.000 (0.000)	
2022-07-07 17:10:50,489: ============================================================
2022-07-07 17:12:04,820: time cost, forward:0.012039425477098254, backward:0.03336243968819307, data cost:0.6945737437729145 
2022-07-07 17:12:04,821: ============================================================
2022-07-07 17:12:04,821: Epoch 15/36 Batch 6900/7662 eta: 1 day, 9:22:48.889113	Training Loss1 4.4387 (4.5092)	Training Total_Loss 4.4387 (4.5092)	Training Prec@1 97.266 (96.366)	Training Prec@5 0.000 (0.000)	
2022-07-07 17:12:04,821: ============================================================
2022-07-07 17:13:19,057: time cost, forward:0.012056882423338746, backward:0.0333752902273894, data cost:0.6945676591366015 
2022-07-07 17:13:19,057: ============================================================
2022-07-07 17:13:19,057: Epoch 15/36 Batch 7000/7662 eta: 1 day, 9:19:00.240556	Training Loss1 4.4246 (4.5101)	Training Total_Loss 4.4246 (4.5101)	Training Prec@1 95.312 (96.362)	Training Prec@5 0.000 (0.000)	
2022-07-07 17:13:19,057: ============================================================
2022-07-07 17:14:34,010: time cost, forward:0.01205836969255511, backward:0.03336752913572164, data cost:0.6947032280212759 
2022-07-07 17:14:34,011: ============================================================
2022-07-07 17:14:34,011: Epoch 15/36 Batch 7100/7662 eta: 1 day, 9:37:03.684611	Training Loss1 4.4592 (4.5115)	Training Total_Loss 4.4592 (4.5115)	Training Prec@1 95.508 (96.355)	Training Prec@5 0.000 (0.000)	
2022-07-07 17:14:34,011: ============================================================
2022-07-07 17:15:49,701: time cost, forward:0.012053361119851749, backward:0.03336645272195728, data cost:0.6949323145345377 
2022-07-07 17:15:49,701: ============================================================
2022-07-07 17:15:49,701: Epoch 15/36 Batch 7200/7662 eta: 1 day, 9:55:38.045379	Training Loss1 4.2046 (4.5127)	Training Total_Loss 4.2046 (4.5127)	Training Prec@1 95.898 (96.349)	Training Prec@5 0.000 (0.000)	
2022-07-07 17:15:49,701: ============================================================
2022-07-07 17:17:04,156: time cost, forward:0.012059856496586965, backward:0.033371950277058554, data cost:0.6949709507680492 
2022-07-07 17:17:04,156: ============================================================
2022-07-07 17:17:04,156: Epoch 15/36 Batch 7300/7662 eta: 1 day, 9:21:09.669151	Training Loss1 4.5517 (4.5139)	Training Total_Loss 4.5517 (4.5139)	Training Prec@1 96.289 (96.344)	Training Prec@5 0.000 (0.000)	
2022-07-07 17:17:04,156: ============================================================
2022-07-07 17:18:17,753: time cost, forward:0.012074754212027966, backward:0.03337941177472309, data cost:0.6948789791378367 
2022-07-07 17:18:17,753: ============================================================
2022-07-07 17:18:17,754: Epoch 15/36 Batch 7400/7662 eta: 1 day, 8:56:53.055200	Training Loss1 4.5914 (4.5152)	Training Total_Loss 4.5914 (4.5152)	Training Prec@1 95.312 (96.337)	Training Prec@5 0.000 (0.000)	
2022-07-07 17:18:17,754: ============================================================
2022-07-07 17:19:32,421: time cost, forward:0.012074598679146396, backward:0.03338331956198286, data cost:0.6949470324235879 
2022-07-07 17:19:32,421: ============================================================
2022-07-07 17:19:32,421: Epoch 15/36 Batch 7500/7662 eta: 1 day, 9:24:23.620947	Training Loss1 4.7268 (4.5164)	Training Total_Loss 4.7268 (4.5164)	Training Prec@1 95.703 (96.332)	Training Prec@5 0.000 (0.000)	
2022-07-07 17:19:32,421: ============================================================
2022-07-07 17:20:46,143: time cost, forward:0.012074428728527577, backward:0.03339217791260505, data cost:0.694888936985416 
2022-07-07 17:20:46,143: ============================================================
2022-07-07 17:20:46,143: Epoch 15/36 Batch 7600/7662 eta: 1 day, 8:57:46.178079	Training Loss1 4.4896 (4.5175)	Training Total_Loss 4.4896 (4.5175)	Training Prec@1 97.070 (96.328)	Training Prec@5 0.000 (0.000)	
2022-07-07 17:20:46,143: ============================================================
2022-07-07 17:21:34,733: Epoch 15/36 Batch 7663/7662 eta: 1 day, 8:56:59.733391	Training Loss1 4.5794 (4.5182)	Training Total_Loss 4.5794 (4.5182)	Training Prec@1 96.289 (96.325)	Training Prec@5 0.000 (0.000)	
2022-07-07 17:21:34,734: ============================================================
2022-07-07 17:21:34,907: Save Checkpoint...
2022-07-07 17:21:34,907: ============================================================
2022-07-07 17:21:37,980: Save done!
2022-07-07 17:21:37,980: ============================================================
2022-07-07 17:23:21,104: time cost, forward:0.011621085080233488, backward:0.03224430180559255, data cost:0.9915743163137725 
2022-07-07 17:23:21,104: ============================================================
2022-07-07 17:23:21,105: Epoch 16/36 Batch 100/7662 eta: 1 day, 22:02:08.834423	Training Loss1 4.0999 (4.0783)	Training Total_Loss 4.0999 (4.0783)	Training Prec@1 97.266 (97.345)	Training Prec@5 0.000 (0.000)	
2022-07-07 17:23:21,105: ============================================================
2022-07-07 17:24:35,366: time cost, forward:0.011225700378417969, backward:0.03237134248168025, data cost:0.8444174570054864 
2022-07-07 17:24:35,367: ============================================================
2022-07-07 17:24:35,367: Epoch 16/36 Batch 200/7662 eta: 1 day, 9:09:01.368509	Training Loss1 4.1672 (4.0863)	Training Total_Loss 4.1672 (4.0863)	Training Prec@1 98.047 (97.396)	Training Prec@5 0.000 (0.000)	
2022-07-07 17:24:35,367: ============================================================
2022-07-07 17:25:50,304: time cost, forward:0.011165610125232301, backward:0.03235636188035027, data cost:0.7979458590415011 
2022-07-07 17:25:50,304: ============================================================
2022-07-07 17:25:50,304: Epoch 16/36 Batch 300/7662 eta: 1 day, 9:25:51.793480	Training Loss1 4.2514 (4.0927)	Training Total_Loss 4.2514 (4.0927)	Training Prec@1 97.266 (97.382)	Training Prec@5 0.000 (0.000)	
2022-07-07 17:25:50,304: ============================================================
2022-07-07 17:27:03,593: time cost, forward:0.011095480811327024, backward:0.032448490759483854, data cost:0.7705367382307698 
2022-07-07 17:27:03,593: ============================================================
2022-07-07 17:27:03,593: Epoch 16/36 Batch 400/7662 eta: 1 day, 8:40:31.187609	Training Loss1 4.5383 (4.1094)	Training Total_Loss 4.5383 (4.1094)	Training Prec@1 97.070 (97.372)	Training Prec@5 0.000 (0.000)	
2022-07-07 17:27:03,593: ============================================================
2022-07-07 17:28:17,238: time cost, forward:0.011083649728962319, backward:0.03244281388475804, data cost:0.7548722418133386 
2022-07-07 17:28:17,238: ============================================================
2022-07-07 17:28:17,238: Epoch 16/36 Batch 500/7662 eta: 1 day, 8:48:48.585484	Training Loss1 4.0419 (4.1232)	Training Total_Loss 4.0419 (4.1232)	Training Prec@1 97.656 (97.315)	Training Prec@5 0.000 (0.000)	
2022-07-07 17:28:17,238: ============================================================
2022-07-07 17:29:32,599: time cost, forward:0.01103234131865589, backward:0.03258886639781309, data cost:0.7472115402826682 
2022-07-07 17:29:32,600: ============================================================
2022-07-07 17:29:32,600: Epoch 16/36 Batch 600/7662 eta: 1 day, 9:33:27.037762	Training Loss1 4.3446 (4.1332)	Training Total_Loss 4.3446 (4.1332)	Training Prec@1 95.508 (97.311)	Training Prec@5 0.000 (0.000)	
2022-07-07 17:29:32,600: ============================================================
2022-07-07 17:30:46,295: time cost, forward:0.010969738080266208, backward:0.032681960063601426, data cost:0.739412729320608 
2022-07-07 17:30:46,295: ============================================================
2022-07-07 17:30:46,296: Epoch 16/36 Batch 700/7662 eta: 1 day, 8:47:42.902059	Training Loss1 4.5845 (4.1510)	Training Total_Loss 4.5845 (4.1510)	Training Prec@1 95.898 (97.271)	Training Prec@5 0.000 (0.000)	
2022-07-07 17:30:46,296: ============================================================
2022-07-07 17:32:00,959: time cost, forward:0.010977221967580173, backward:0.03271961122639337, data cost:0.7347279185795217 
2022-07-07 17:32:00,960: ============================================================
2022-07-07 17:32:00,960: Epoch 16/36 Batch 800/7662 eta: 1 day, 9:12:19.685690	Training Loss1 3.9142 (4.1670)	Training Total_Loss 3.9142 (4.1670)	Training Prec@1 97.461 (97.232)	Training Prec@5 0.000 (0.000)	
2022-07-07 17:32:00,960: ============================================================
2022-07-07 17:33:16,264: time cost, forward:0.010935955238554448, backward:0.032811157960647735, data cost:0.7318093416025164 
2022-07-07 17:33:16,264: ============================================================
2022-07-07 17:33:16,264: Epoch 16/36 Batch 900/7662 eta: 1 day, 9:28:08.888610	Training Loss1 4.6246 (4.1791)	Training Total_Loss 4.6246 (4.1791)	Training Prec@1 96.484 (97.209)	Training Prec@5 0.000 (0.000)	
2022-07-07 17:33:16,264: ============================================================
2022-07-07 17:34:32,529: time cost, forward:0.010881059043280952, backward:0.032897344699970354, data cost:0.730436733893088 
2022-07-07 17:34:32,530: ============================================================
2022-07-07 17:34:32,530: Epoch 16/36 Batch 1000/7662 eta: 1 day, 9:52:31.501942	Training Loss1 4.3281 (4.1913)	Training Total_Loss 4.3281 (4.1913)	Training Prec@1 95.898 (97.191)	Training Prec@5 0.000 (0.000)	
2022-07-07 17:34:32,530: ============================================================
2022-07-07 17:35:48,964: time cost, forward:0.010867836260600346, backward:0.03295890063562645, data cost:0.7294364708786775 
2022-07-07 17:35:48,964: ============================================================
2022-07-07 17:35:48,964: Epoch 16/36 Batch 1100/7662 eta: 1 day, 9:55:44.631240	Training Loss1 4.1446 (4.2015)	Training Total_Loss 4.1446 (4.2015)	Training Prec@1 96.875 (97.181)	Training Prec@5 0.000 (0.000)	
2022-07-07 17:35:48,965: ============================================================
2022-07-07 17:37:02,899: time cost, forward:0.010960175257309761, backward:0.03304838716635811, data cost:0.7263770369910717 
2022-07-07 17:37:02,899: ============================================================
2022-07-07 17:37:02,899: Epoch 16/36 Batch 1200/7662 eta: 1 day, 8:47:56.151756	Training Loss1 4.3367 (4.2132)	Training Total_Loss 4.3367 (4.2132)	Training Prec@1 96.289 (97.150)	Training Prec@5 0.000 (0.000)	
2022-07-07 17:37:02,899: ============================================================
2022-07-07 17:38:16,079: time cost, forward:0.011042058238439876, backward:0.03313153059873515, data cost:0.7231827123611133 
2022-07-07 17:38:16,080: ============================================================
2022-07-07 17:38:16,080: Epoch 16/36 Batch 1300/7662 eta: 1 day, 8:26:38.655509	Training Loss1 4.3147 (4.2231)	Training Total_Loss 4.3147 (4.2231)	Training Prec@1 97.070 (97.138)	Training Prec@5 0.000 (0.000)	
2022-07-07 17:38:16,080: ============================================================
2022-07-07 17:39:30,537: time cost, forward:0.011066314575926077, backward:0.03315443852869761, data cost:0.721352132240988 
2022-07-07 17:39:30,538: ============================================================
2022-07-07 17:39:30,538: Epoch 16/36 Batch 1400/7662 eta: 1 day, 8:59:22.464142	Training Loss1 4.3351 (4.2317)	Training Total_Loss 4.3351 (4.2317)	Training Prec@1 97.070 (97.125)	Training Prec@5 0.000 (0.000)	
2022-07-07 17:39:30,538: ============================================================
2022-07-07 17:40:43,631: time cost, forward:0.011082270369679233, backward:0.033149196753269675, data cost:0.7191045413103161 
2022-07-07 17:40:43,632: ============================================================
2022-07-07 17:40:43,632: Epoch 16/36 Batch 1500/7662 eta: 1 day, 8:21:54.563326	Training Loss1 3.9874 (4.2404)	Training Total_Loss 3.9874 (4.2404)	Training Prec@1 98.047 (97.113)	Training Prec@5 0.000 (0.000)	
2022-07-07 17:40:43,632: ============================================================
2022-07-07 17:41:58,005: time cost, forward:0.011127307461231034, backward:0.03316738532437914, data cost:0.7177772216307812 
2022-07-07 17:41:58,005: ============================================================
2022-07-07 17:41:58,005: Epoch 16/36 Batch 1600/7662 eta: 1 day, 8:54:38.495243	Training Loss1 4.4317 (4.2493)	Training Total_Loss 4.4317 (4.2493)	Training Prec@1 96.875 (97.090)	Training Prec@5 0.000 (0.000)	
2022-07-07 17:41:58,005: ============================================================
2022-07-07 17:43:11,429: time cost, forward:0.01114796287105531, backward:0.033175607791292167, data cost:0.7160733160094137 
2022-07-07 17:43:11,429: ============================================================
2022-07-07 17:43:11,429: Epoch 16/36 Batch 1700/7662 eta: 1 day, 8:28:13.072976	Training Loss1 4.3245 (4.2584)	Training Total_Loss 4.3245 (4.2584)	Training Prec@1 97.461 (97.072)	Training Prec@5 0.000 (0.000)	
2022-07-07 17:43:11,429: ============================================================
2022-07-07 17:44:25,715: time cost, forward:0.011217216573336708, backward:0.033223487855064134, data cost:0.7149390795285202 
2022-07-07 17:44:25,715: ============================================================
2022-07-07 17:44:25,716: Epoch 16/36 Batch 1800/7662 eta: 1 day, 8:49:52.037161	Training Loss1 4.4860 (4.2658)	Training Total_Loss 4.4860 (4.2658)	Training Prec@1 96.680 (97.054)	Training Prec@5 0.000 (0.000)	
2022-07-07 17:44:25,716: ============================================================
2022-07-07 17:45:39,148: time cost, forward:0.011273852645126753, backward:0.03323487183368476, data cost:0.7135254294700281 
2022-07-07 17:45:39,148: ============================================================
2022-07-07 17:45:39,149: Epoch 16/36 Batch 1900/7662 eta: 1 day, 8:26:00.608684	Training Loss1 4.3350 (4.2748)	Training Total_Loss 4.3350 (4.2748)	Training Prec@1 95.898 (97.026)	Training Prec@5 0.000 (0.000)	
2022-07-07 17:45:39,149: ============================================================
2022-07-07 17:46:53,406: time cost, forward:0.011306709143565618, backward:0.033263131700318235, data cost:0.7126668334424704 
2022-07-07 17:46:53,406: ============================================================
2022-07-07 17:46:53,406: Epoch 16/36 Batch 2000/7662 eta: 1 day, 8:46:37.666000	Training Loss1 4.3749 (4.2835)	Training Total_Loss 4.3749 (4.2835)	Training Prec@1 98.438 (97.011)	Training Prec@5 0.000 (0.000)	
2022-07-07 17:46:53,406: ============================================================
2022-07-07 17:48:08,062: time cost, forward:0.011317914187652602, backward:0.033268247007358184, data cost:0.7121158829753089 
2022-07-07 17:48:08,062: ============================================================
2022-07-07 17:48:08,062: Epoch 16/36 Batch 2100/7662 eta: 1 day, 8:55:55.958811	Training Loss1 4.6066 (4.2899)	Training Total_Loss 4.6066 (4.2899)	Training Prec@1 95.117 (96.991)	Training Prec@5 0.000 (0.000)	
2022-07-07 17:48:08,062: ============================================================
2022-07-07 17:49:22,368: time cost, forward:0.011309611791911695, backward:0.03325436450286907, data cost:0.7114934291336524 
2022-07-07 17:49:22,369: ============================================================
2022-07-07 17:49:22,369: Epoch 16/36 Batch 2200/7662 eta: 1 day, 8:45:26.883385	Training Loss1 4.3030 (4.2959)	Training Total_Loss 4.3030 (4.2959)	Training Prec@1 96.094 (96.976)	Training Prec@5 0.000 (0.000)	
2022-07-07 17:49:22,369: ============================================================
2022-07-07 17:50:36,928: time cost, forward:0.011327834272446867, backward:0.033277300348899946, data cost:0.7109708026887646 
2022-07-07 17:50:36,928: ============================================================
2022-07-07 17:50:36,929: Epoch 16/36 Batch 2300/7662 eta: 1 day, 8:50:53.715681	Training Loss1 4.7834 (4.3021)	Training Total_Loss 4.7834 (4.3021)	Training Prec@1 95.898 (96.960)	Training Prec@5 0.000 (0.000)	
2022-07-07 17:50:36,929: ============================================================
2022-07-07 17:51:50,241: time cost, forward:0.011368868598445051, backward:0.03329305581223622, data cost:0.7099483033029573 
2022-07-07 17:51:50,241: ============================================================
2022-07-07 17:51:50,241: Epoch 16/36 Batch 2400/7662 eta: 1 day, 8:16:43.085906	Training Loss1 4.1582 (4.3088)	Training Total_Loss 4.1582 (4.3088)	Training Prec@1 96.875 (96.940)	Training Prec@5 0.000 (0.000)	
2022-07-07 17:51:50,241: ============================================================
2022-07-07 17:53:06,109: time cost, forward:0.011421983267794422, backward:0.03330921020065131, data cost:0.7100188764585119 
2022-07-07 17:53:06,110: ============================================================
2022-07-07 17:53:06,110: Epoch 16/36 Batch 2500/7662 eta: 1 day, 9:22:57.815763	Training Loss1 4.2411 (4.3127)	Training Total_Loss 4.2411 (4.3127)	Training Prec@1 95.898 (96.930)	Training Prec@5 0.000 (0.000)	
2022-07-07 17:53:06,110: ============================================================
2022-07-07 17:54:18,146: time cost, forward:0.011419842453267126, backward:0.033334747467099725, data cost:0.7086530382149767 
2022-07-07 17:54:18,147: ============================================================
2022-07-07 17:54:18,147: Epoch 16/36 Batch 2600/7662 eta: 1 day, 7:40:37.156618	Training Loss1 4.5619 (4.3202)	Training Total_Loss 4.5619 (4.3202)	Training Prec@1 96.094 (96.906)	Training Prec@5 0.000 (0.000)	
2022-07-07 17:54:18,147: ============================================================
2022-07-07 17:55:33,716: time cost, forward:0.011427721742260408, backward:0.033332728332570415, data cost:0.7087103514902766 
2022-07-07 17:55:33,716: ============================================================
2022-07-07 17:55:33,716: Epoch 16/36 Batch 2700/7662 eta: 1 day, 9:12:32.953893	Training Loss1 4.5360 (4.3254)	Training Total_Loss 4.5360 (4.3254)	Training Prec@1 95.312 (96.893)	Training Prec@5 0.000 (0.000)	
2022-07-07 17:55:33,717: ============================================================
2022-07-07 17:56:47,459: time cost, forward:0.011459464130762775, backward:0.03335368569385328, data cost:0.708062441274923 
2022-07-07 17:56:47,459: ============================================================
2022-07-07 17:56:47,459: Epoch 16/36 Batch 2800/7662 eta: 1 day, 8:23:09.887422	Training Loss1 4.3670 (4.3313)	Training Total_Loss 4.3670 (4.3313)	Training Prec@1 96.094 (96.877)	Training Prec@5 0.000 (0.000)	
2022-07-07 17:56:47,460: ============================================================
2022-07-07 17:58:01,447: time cost, forward:0.01145524269714566, backward:0.033356772327719164, data cost:0.707589345210254 
2022-07-07 17:58:01,447: ============================================================
2022-07-07 17:58:01,447: Epoch 16/36 Batch 2900/7662 eta: 1 day, 8:28:23.111084	Training Loss1 4.2818 (4.3356)	Training Total_Loss 4.2818 (4.3356)	Training Prec@1 96.875 (96.863)	Training Prec@5 0.000 (0.000)	
2022-07-07 17:58:01,447: ============================================================
2022-07-07 17:59:16,001: time cost, forward:0.011454704643369078, backward:0.0333457425579543, data cost:0.7073549890406889 
2022-07-07 17:59:16,002: ============================================================
2022-07-07 17:59:16,002: Epoch 16/36 Batch 3000/7662 eta: 1 day, 8:42:03.624768	Training Loss1 4.4755 (4.3399)	Training Total_Loss 4.4755 (4.3399)	Training Prec@1 95.898 (96.854)	Training Prec@5 0.000 (0.000)	
2022-07-07 17:59:16,002: ============================================================
2022-07-07 18:00:29,822: time cost, forward:0.011450603416789997, backward:0.03335780942005356, data cost:0.7068798588952467 
2022-07-07 18:00:29,822: ============================================================
2022-07-07 18:00:29,822: Epoch 16/36 Batch 3100/7662 eta: 1 day, 8:21:31.186182	Training Loss1 4.6382 (4.3445)	Training Total_Loss 4.6382 (4.3445)	Training Prec@1 97.266 (96.839)	Training Prec@5 0.000 (0.000)	
2022-07-07 18:00:29,822: ============================================================
2022-07-07 18:01:44,266: time cost, forward:0.011459075275455723, backward:0.03338308712958395, data cost:0.706597438712685 
2022-07-07 18:01:44,267: ============================================================
2022-07-07 18:01:44,267: Epoch 16/36 Batch 3200/7662 eta: 1 day, 8:36:41.192491	Training Loss1 4.2857 (4.3493)	Training Total_Loss 4.2857 (4.3493)	Training Prec@1 97.461 (96.827)	Training Prec@5 0.000 (0.000)	
2022-07-07 18:01:44,267: ============================================================
2022-07-07 18:02:57,278: time cost, forward:0.011469956635344784, backward:0.033392694148919044, data cost:0.7058437107620401 
2022-07-07 18:02:57,279: ============================================================
2022-07-07 18:02:57,279: Epoch 16/36 Batch 3300/7662 eta: 1 day, 7:57:49.782984	Training Loss1 4.4188 (4.3536)	Training Total_Loss 4.4188 (4.3536)	Training Prec@1 96.484 (96.814)	Training Prec@5 0.000 (0.000)	
2022-07-07 18:02:57,280: ============================================================
2022-07-07 18:04:10,567: time cost, forward:0.011485263437830585, backward:0.033396604938624924, data cost:0.7053360164638967 
2022-07-07 18:04:10,567: ============================================================
2022-07-07 18:04:10,567: Epoch 16/36 Batch 3400/7662 eta: 1 day, 8:03:50.810825	Training Loss1 4.6988 (4.3578)	Training Total_Loss 4.6988 (4.3578)	Training Prec@1 96.484 (96.802)	Training Prec@5 0.000 (0.000)	
2022-07-07 18:04:10,567: ============================================================
2022-07-07 18:05:24,955: time cost, forward:0.011506118921594437, backward:0.03339490293604744, data cost:0.7051112818765654 
2022-07-07 18:05:24,956: ============================================================
2022-07-07 18:05:24,956: Epoch 16/36 Batch 3500/7662 eta: 1 day, 8:31:29.850330	Training Loss1 4.2585 (4.3626)	Training Total_Loss 4.2585 (4.3626)	Training Prec@1 97.070 (96.789)	Training Prec@5 0.000 (0.000)	
2022-07-07 18:05:24,956: ============================================================
2022-07-07 18:06:38,860: time cost, forward:0.011514108821596494, backward:0.03336887678923823, data cost:0.7048238255176719 
2022-07-07 18:06:38,860: ============================================================
2022-07-07 18:06:38,860: Epoch 16/36 Batch 3600/7662 eta: 1 day, 8:17:33.762372	Training Loss1 4.3701 (4.3661)	Training Total_Loss 4.3701 (4.3661)	Training Prec@1 96.680 (96.780)	Training Prec@5 0.000 (0.000)	
2022-07-07 18:06:38,860: ============================================================
2022-07-07 18:07:52,433: time cost, forward:0.011525750708083714, backward:0.03338337047707877, data cost:0.7043979123464369 
2022-07-07 18:07:52,433: ============================================================
2022-07-07 18:07:52,434: Epoch 16/36 Batch 3700/7662 eta: 1 day, 8:07:39.371651	Training Loss1 4.4415 (4.3697)	Training Total_Loss 4.4415 (4.3697)	Training Prec@1 95.703 (96.767)	Training Prec@5 0.000 (0.000)	
2022-07-07 18:07:52,434: ============================================================
2022-07-07 18:09:07,700: time cost, forward:0.01152797421834192, backward:0.03338627082230261, data cost:0.7044693774127684 
2022-07-07 18:09:07,700: ============================================================
2022-07-07 18:09:07,701: Epoch 16/36 Batch 3800/7662 eta: 1 day, 8:50:46.916836	Training Loss1 4.3548 (4.3740)	Training Total_Loss 4.3548 (4.3740)	Training Prec@1 96.680 (96.754)	Training Prec@5 0.000 (0.000)	
2022-07-07 18:09:07,701: ============================================================
2022-07-07 18:10:21,834: time cost, forward:0.011544720335904377, backward:0.03336589994966204, data cost:0.7042445180109752 
2022-07-07 18:10:21,834: ============================================================
2022-07-07 18:10:21,835: Epoch 16/36 Batch 3900/7662 eta: 1 day, 8:19:52.454015	Training Loss1 4.5758 (4.3774)	Training Total_Loss 4.5758 (4.3774)	Training Prec@1 96.094 (96.743)	Training Prec@5 0.000 (0.000)	
2022-07-07 18:10:21,835: ============================================================
2022-07-07 18:11:36,798: time cost, forward:0.0115689027008339, backward:0.03333949231898734, data cost:0.7042429719039218 
2022-07-07 18:11:36,798: ============================================================
2022-07-07 18:11:36,798: Epoch 16/36 Batch 4000/7662 eta: 1 day, 8:40:20.630976	Training Loss1 4.5302 (4.3804)	Training Total_Loss 4.5302 (4.3804)	Training Prec@1 96.680 (96.734)	Training Prec@5 0.000 (0.000)	
2022-07-07 18:11:36,799: ============================================================
2022-07-07 18:12:50,348: time cost, forward:0.011590842242123412, backward:0.033326616284904846, data cost:0.703892595507977 
2022-07-07 18:12:50,348: ============================================================
2022-07-07 18:12:50,348: Epoch 16/36 Batch 4100/7662 eta: 1 day, 8:02:08.379874	Training Loss1 4.8079 (4.3841)	Training Total_Loss 4.8079 (4.3841)	Training Prec@1 96.680 (96.723)	Training Prec@5 0.000 (0.000)	
2022-07-07 18:12:50,348: ============================================================
2022-07-07 18:14:04,139: time cost, forward:0.011615404488785433, backward:0.03331203419811869, data cost:0.7036071359671193 
2022-07-07 18:14:04,139: ============================================================
2022-07-07 18:14:04,140: Epoch 16/36 Batch 4200/7662 eta: 1 day, 8:07:13.125263	Training Loss1 4.4631 (4.3871)	Training Total_Loss 4.4631 (4.3871)	Training Prec@1 96.875 (96.714)	Training Prec@5 0.000 (0.000)	
2022-07-07 18:14:04,140: ============================================================
2022-07-07 18:15:18,418: time cost, forward:0.011624318329393379, backward:0.03330721314992148, data cost:0.7034546350650828 
2022-07-07 18:15:18,419: ============================================================
2022-07-07 18:15:18,419: Epoch 16/36 Batch 4300/7662 eta: 1 day, 8:18:43.708095	Training Loss1 4.4152 (4.3904)	Training Total_Loss 4.4152 (4.3904)	Training Prec@1 96.680 (96.699)	Training Prec@5 0.000 (0.000)	
2022-07-07 18:15:18,419: ============================================================
2022-07-07 18:16:32,666: time cost, forward:0.01166628647674401, backward:0.033282693501737175, data cost:0.703288216568118 
2022-07-07 18:16:32,667: ============================================================
2022-07-07 18:16:32,667: Epoch 16/36 Batch 4400/7662 eta: 1 day, 8:16:39.949535	Training Loss1 4.5347 (4.3933)	Training Total_Loss 4.5347 (4.3933)	Training Prec@1 96.875 (96.691)	Training Prec@5 0.000 (0.000)	
2022-07-07 18:16:32,667: ============================================================
2022-07-07 18:17:47,640: time cost, forward:0.011665598607958887, backward:0.033275392379302875, data cost:0.7033199956083753 
2022-07-07 18:17:47,641: ============================================================
2022-07-07 18:17:47,641: Epoch 16/36 Batch 4500/7662 eta: 1 day, 8:34:21.926755	Training Loss1 4.5558 (4.3965)	Training Total_Loss 4.5558 (4.3965)	Training Prec@1 95.703 (96.680)	Training Prec@5 0.000 (0.000)	
2022-07-07 18:17:47,641: ============================================================
2022-07-07 18:19:02,278: time cost, forward:0.011671149023047321, backward:0.03328636491472344, data cost:0.7032503084816034 
2022-07-07 18:19:02,278: ============================================================
2022-07-07 18:19:02,278: Epoch 16/36 Batch 4600/7662 eta: 1 day, 8:24:20.690083	Training Loss1 4.6791 (4.3994)	Training Total_Loss 4.6791 (4.3994)	Training Prec@1 95.312 (96.668)	Training Prec@5 0.000 (0.000)	
2022-07-07 18:19:02,279: ============================================================
2022-07-07 18:20:17,557: time cost, forward:0.011681207166526845, backward:0.03328972137793756, data cost:0.7032867890516478 
2022-07-07 18:20:17,557: ============================================================
2022-07-07 18:20:17,557: Epoch 16/36 Batch 4700/7662 eta: 1 day, 8:39:47.383109	Training Loss1 4.3176 (4.4012)	Training Total_Loss 4.3176 (4.4012)	Training Prec@1 96.875 (96.661)	Training Prec@5 0.000 (0.000)	
2022-07-07 18:20:17,557: ============================================================
2022-07-07 18:21:31,978: time cost, forward:0.011689426104558908, backward:0.033284768334873815, data cost:0.7032146899991791 
2022-07-07 18:21:31,978: ============================================================
2022-07-07 18:21:31,979: Epoch 16/36 Batch 4800/7662 eta: 1 day, 8:16:14.022892	Training Loss1 4.6780 (4.4037)	Training Total_Loss 4.6780 (4.4037)	Training Prec@1 95.898 (96.652)	Training Prec@5 0.000 (0.000)	
2022-07-07 18:21:31,979: ============================================================
2022-07-07 18:22:45,886: time cost, forward:0.011707318902234686, backward:0.03327822889642196, data cost:0.703014698386752 
2022-07-07 18:22:45,887: ============================================================
2022-07-07 18:22:45,887: Epoch 16/36 Batch 4900/7662 eta: 1 day, 8:01:39.197860	Training Loss1 4.2712 (4.4068)	Training Total_Loss 4.2712 (4.4068)	Training Prec@1 96.680 (96.642)	Training Prec@5 0.000 (0.000)	
2022-07-07 18:22:45,887: ============================================================
2022-07-07 18:24:00,952: time cost, forward:0.011742062748945053, backward:0.033288663138053634, data cost:0.7030074129488068 
2022-07-07 18:24:00,953: ============================================================
2022-07-07 18:24:00,953: Epoch 16/36 Batch 5000/7662 eta: 1 day, 8:30:30.205428	Training Loss1 4.6792 (4.4095)	Training Total_Loss 4.6792 (4.4095)	Training Prec@1 95.703 (96.635)	Training Prec@5 0.000 (0.000)	
2022-07-07 18:24:00,953: ============================================================
2022-07-07 18:25:15,894: time cost, forward:0.01177588998862261, backward:0.03327846742185992, data cost:0.7029969848869221 
2022-07-07 18:25:15,894: ============================================================
2022-07-07 18:25:15,894: Epoch 16/36 Batch 5100/7662 eta: 1 day, 8:26:00.782735	Training Loss1 4.3824 (4.4122)	Training Total_Loss 4.3824 (4.4122)	Training Prec@1 96.094 (96.624)	Training Prec@5 0.000 (0.000)	
2022-07-07 18:25:15,894: ============================================================
2022-07-07 18:26:30,102: time cost, forward:0.011791005183192578, backward:0.03328257364638839, data cost:0.7028479681585494 
2022-07-07 18:26:30,103: ============================================================
2022-07-07 18:26:30,103: Epoch 16/36 Batch 5200/7662 eta: 1 day, 8:05:45.248542	Training Loss1 4.5341 (4.4155)	Training Total_Loss 4.5341 (4.4155)	Training Prec@1 96.289 (96.614)	Training Prec@5 0.000 (0.000)	
2022-07-07 18:26:30,103: ============================================================
2022-07-07 18:27:43,996: time cost, forward:0.011789806970314476, backward:0.03327944891073497, data cost:0.7026713483399728 
2022-07-07 18:27:43,996: ============================================================
2022-07-07 18:27:43,996: Epoch 16/36 Batch 5300/7662 eta: 1 day, 7:56:20.267739	Training Loss1 4.5742 (4.4178)	Training Total_Loss 4.5742 (4.4178)	Training Prec@1 96.094 (96.606)	Training Prec@5 0.000 (0.000)	
2022-07-07 18:27:43,996: ============================================================
2022-07-07 18:28:58,377: time cost, forward:0.011792657772331993, backward:0.03328284547823097, data cost:0.7025863827102867 
2022-07-07 18:28:58,378: ============================================================
2022-07-07 18:28:58,378: Epoch 16/36 Batch 5400/7662 eta: 1 day, 8:07:45.700120	Training Loss1 4.4354 (4.4208)	Training Total_Loss 4.4354 (4.4208)	Training Prec@1 96.680 (96.596)	Training Prec@5 0.000 (0.000)	
2022-07-07 18:28:58,378: ============================================================
2022-07-07 18:30:12,577: time cost, forward:0.011815321794486649, backward:0.033298246165496, data cost:0.7024368217022208 
2022-07-07 18:30:12,577: ============================================================
2022-07-07 18:30:12,578: Epoch 16/36 Batch 5500/7662 eta: 1 day, 8:01:48.485501	Training Loss1 4.7779 (4.4228)	Training Total_Loss 4.7779 (4.4228)	Training Prec@1 94.922 (96.587)	Training Prec@5 0.000 (0.000)	
2022-07-07 18:30:12,578: ============================================================
2022-07-07 18:31:27,564: time cost, forward:0.011829281134314995, backward:0.033290531448347906, data cost:0.702459545598794 
2022-07-07 18:31:27,565: ============================================================
2022-07-07 18:31:27,565: Epoch 16/36 Batch 5600/7662 eta: 1 day, 8:20:57.733005	Training Loss1 4.7735 (4.4252)	Training Total_Loss 4.7735 (4.4252)	Training Prec@1 93.945 (96.577)	Training Prec@5 0.000 (0.000)	
2022-07-07 18:31:27,565: ============================================================
2022-07-07 18:32:42,743: time cost, forward:0.011842029725151913, backward:0.03330091460375728, data cost:0.7025009761213901 
2022-07-07 18:32:42,743: ============================================================
2022-07-07 18:32:42,744: Epoch 16/36 Batch 5700/7662 eta: 1 day, 8:24:39.518528	Training Loss1 4.6336 (4.4275)	Training Total_Loss 4.6336 (4.4275)	Training Prec@1 95.312 (96.565)	Training Prec@5 0.000 (0.000)	
2022-07-07 18:32:42,744: ============================================================
2022-07-07 18:33:57,603: time cost, forward:0.01184968755951954, backward:0.033304758453434925, data cost:0.7024945483821942 
2022-07-07 18:33:57,604: ============================================================
2022-07-07 18:33:57,604: Epoch 16/36 Batch 5800/7662 eta: 1 day, 8:15:10.513151	Training Loss1 4.5769 (4.4294)	Training Total_Loss 4.5769 (4.4294)	Training Prec@1 95.898 (96.556)	Training Prec@5 0.000 (0.000)	
2022-07-07 18:33:57,604: ============================================================
2022-07-07 18:35:10,700: time cost, forward:0.011846048222858839, backward:0.03330816065058665, data cost:0.7022011687056778 
2022-07-07 18:35:10,701: ============================================================
2022-07-07 18:35:10,701: Epoch 16/36 Batch 5900/7662 eta: 1 day, 7:28:23.110368	Training Loss1 4.6209 (4.4319)	Training Total_Loss 4.6209 (4.4319)	Training Prec@1 95.703 (96.547)	Training Prec@5 0.000 (0.000)	
2022-07-07 18:35:10,702: ============================================================
2022-07-07 18:36:25,867: time cost, forward:0.011848952257945192, backward:0.03331333340197966, data cost:0.7022514204161031 
2022-07-07 18:36:25,867: ============================================================
2022-07-07 18:36:25,868: Epoch 16/36 Batch 6000/7662 eta: 1 day, 8:20:34.963467	Training Loss1 4.5305 (4.4341)	Training Total_Loss 4.5305 (4.4341)	Training Prec@1 96.484 (96.539)	Training Prec@5 0.000 (0.000)	
2022-07-07 18:36:25,868: ============================================================
2022-07-07 18:37:39,606: time cost, forward:0.011856697293300475, backward:0.03332443314705702, data cost:0.7020624505631121 
2022-07-07 18:37:39,606: ============================================================
2022-07-07 18:37:39,607: Epoch 16/36 Batch 6100/7662 eta: 1 day, 7:42:30.037403	Training Loss1 4.5628 (4.4361)	Training Total_Loss 4.5628 (4.4361)	Training Prec@1 96.680 (96.530)	Training Prec@5 0.000 (0.000)	
2022-07-07 18:37:39,607: ============================================================
2022-07-07 18:38:54,040: time cost, forward:0.011848911582933238, backward:0.0333310497405164, data cost:0.7020070562825739 
2022-07-07 18:38:54,040: ============================================================
2022-07-07 18:38:54,040: Epoch 16/36 Batch 6200/7662 eta: 1 day, 7:59:10.997006	Training Loss1 4.6811 (4.4378)	Training Total_Loss 4.6811 (4.4378)	Training Prec@1 96.680 (96.523)	Training Prec@5 0.000 (0.000)	
2022-07-07 18:38:54,040: ============================================================
2022-07-07 18:40:08,206: time cost, forward:0.011858975211672035, backward:0.033343668304978716, data cost:0.7018857322849722 
2022-07-07 18:40:08,207: ============================================================
2022-07-07 18:40:08,207: Epoch 16/36 Batch 6300/7662 eta: 1 day, 7:51:03.974725	Training Loss1 4.5940 (4.4396)	Training Total_Loss 4.5940 (4.4396)	Training Prec@1 95.898 (96.515)	Training Prec@5 0.000 (0.000)	
2022-07-07 18:40:08,207: ============================================================
2022-07-07 18:41:23,781: time cost, forward:0.01185898658614137, backward:0.03333899277712259, data cost:0.702012594797999 
2022-07-07 18:41:23,781: ============================================================
2022-07-07 18:41:23,782: Epoch 16/36 Batch 6400/7662 eta: 1 day, 8:26:05.094935	Training Loss1 4.5173 (4.4409)	Training Total_Loss 4.5173 (4.4409)	Training Prec@1 96.094 (96.509)	Training Prec@5 0.000 (0.000)	
2022-07-07 18:41:23,782: ============================================================
2022-07-07 18:42:39,538: time cost, forward:0.011863629842541882, backward:0.03333588882049499, data cost:0.7021697167342105 
2022-07-07 18:42:39,538: ============================================================
2022-07-07 18:42:39,538: Epoch 16/36 Batch 6500/7662 eta: 1 day, 8:29:30.779904	Training Loss1 4.6094 (4.4425)	Training Total_Loss 4.6094 (4.4425)	Training Prec@1 95.898 (96.501)	Training Prec@5 0.000 (0.000)	
2022-07-07 18:42:39,538: ============================================================
2022-07-07 18:43:53,114: time cost, forward:0.01186508051390575, backward:0.03333342846712753, data cost:0.701981741544929 
2022-07-07 18:43:53,115: ============================================================
2022-07-07 18:43:53,115: Epoch 16/36 Batch 6600/7662 eta: 1 day, 7:32:10.700347	Training Loss1 4.4749 (4.4437)	Training Total_Loss 4.4749 (4.4437)	Training Prec@1 96.289 (96.496)	Training Prec@5 0.000 (0.000)	
2022-07-07 18:43:53,115: ============================================================
2022-07-07 18:45:06,143: time cost, forward:0.011876479460777035, backward:0.03334232087739636, data cost:0.7016986780227841 
2022-07-07 18:45:06,143: ============================================================
2022-07-07 18:45:06,144: Epoch 16/36 Batch 6700/7662 eta: 1 day, 7:16:52.749011	Training Loss1 4.3525 (4.4451)	Training Total_Loss 4.3525 (4.4451)	Training Prec@1 96.680 (96.490)	Training Prec@5 0.000 (0.000)	
2022-07-07 18:45:06,144: ============================================================
2022-07-07 18:46:20,840: time cost, forward:0.011887620908229698, backward:0.03334008772454905, data cost:0.7016848420584828 
2022-07-07 18:46:20,840: ============================================================
2022-07-07 18:46:20,840: Epoch 16/36 Batch 6800/7662 eta: 1 day, 7:58:29.960828	Training Loss1 4.1955 (4.4463)	Training Total_Loss 4.1955 (4.4463)	Training Prec@1 96.875 (96.485)	Training Prec@5 0.000 (0.000)	
2022-07-07 18:46:20,841: ============================================================
2022-07-07 18:47:37,423: time cost, forward:0.011905327761133505, backward:0.03334494362120733, data cost:0.7019261016519471 
2022-07-07 18:47:37,423: ============================================================
2022-07-07 18:47:37,423: Epoch 16/36 Batch 6900/7662 eta: 1 day, 8:45:39.622824	Training Loss1 4.5013 (4.4476)	Training Total_Loss 4.5013 (4.4476)	Training Prec@1 96.289 (96.478)	Training Prec@5 0.000 (0.000)	
2022-07-07 18:47:37,423: ============================================================
2022-07-07 18:48:51,763: time cost, forward:0.011912879236665244, backward:0.033351713256301804, data cost:0.7018509053863752 
2022-07-07 18:48:51,764: ============================================================
2022-07-07 18:48:51,764: Epoch 16/36 Batch 7000/7662 eta: 1 day, 7:46:53.124389	Training Loss1 4.4713 (4.4490)	Training Total_Loss 4.4713 (4.4490)	Training Prec@1 95.312 (96.471)	Training Prec@5 0.000 (0.000)	
2022-07-07 18:48:51,765: ============================================================
2022-07-07 18:50:06,426: time cost, forward:0.011914551669501103, backward:0.03335403200437828, data cost:0.7018301422822003 
2022-07-07 18:50:06,426: ============================================================
2022-07-07 18:50:06,426: Epoch 16/36 Batch 7100/7662 eta: 1 day, 7:53:52.132482	Training Loss1 4.5978 (4.4505)	Training Total_Loss 4.5978 (4.4505)	Training Prec@1 95.312 (96.465)	Training Prec@5 0.000 (0.000)	
2022-07-07 18:50:06,426: ============================================================
2022-07-07 18:51:21,740: time cost, forward:0.011915968961062605, backward:0.03334984760811667, data cost:0.7018962536011824 
2022-07-07 18:51:21,740: ============================================================
2022-07-07 18:51:21,740: Epoch 16/36 Batch 7200/7662 eta: 1 day, 8:09:20.120946	Training Loss1 4.5515 (4.4518)	Training Total_Loss 4.5515 (4.4518)	Training Prec@1 97.656 (96.460)	Training Prec@5 0.000 (0.000)	
2022-07-07 18:51:21,740: ============================================================
2022-07-07 18:52:36,536: time cost, forward:0.011920246200571976, backward:0.03336322982109709, data cost:0.7018896138966941 
2022-07-07 18:52:36,537: ============================================================
2022-07-07 18:52:36,537: Epoch 16/36 Batch 7300/7662 eta: 1 day, 7:54:50.076545	Training Loss1 4.5433 (4.4533)	Training Total_Loss 4.5433 (4.4533)	Training Prec@1 95.898 (96.454)	Training Prec@5 0.000 (0.000)	
2022-07-07 18:52:36,537: ============================================================
2022-07-07 18:53:51,073: time cost, forward:0.011929305119520265, backward:0.03336461422684741, data cost:0.7018488381807668 
2022-07-07 18:53:51,073: ============================================================
2022-07-07 18:53:51,073: Epoch 16/36 Batch 7400/7662 eta: 1 day, 7:46:55.565199	Training Loss1 4.4171 (4.4543)	Training Total_Loss 4.4171 (4.4543)	Training Prec@1 97.266 (96.449)	Training Prec@5 0.000 (0.000)	
2022-07-07 18:53:51,073: ============================================================
2022-07-07 18:55:05,691: time cost, forward:0.011935548760729133, backward:0.03335678356459084, data cost:0.7018177206952789 
2022-07-07 18:55:05,692: ============================================================
2022-07-07 18:55:05,692: Epoch 16/36 Batch 7500/7662 eta: 1 day, 7:47:47.137144	Training Loss1 4.6529 (4.4555)	Training Total_Loss 4.6529 (4.4555)	Training Prec@1 95.703 (96.444)	Training Prec@5 0.000 (0.000)	
2022-07-07 18:55:05,692: ============================================================
2022-07-07 18:56:20,201: time cost, forward:0.011950860793440887, backward:0.03335901733636385, data cost:0.7017753932456905 
2022-07-07 18:56:20,202: ============================================================
2022-07-07 18:56:20,202: Epoch 16/36 Batch 7600/7662 eta: 1 day, 7:43:45.856583	Training Loss1 4.4606 (4.4570)	Training Total_Loss 4.4606 (4.4570)	Training Prec@1 96.875 (96.438)	Training Prec@5 0.000 (0.000)	
2022-07-07 18:56:20,202: ============================================================
2022-07-07 18:57:08,567: Epoch 16/36 Batch 7663/7662 eta: 1 day, 7:42:58.915369	Training Loss1 4.3498 (4.4582)	Training Total_Loss 4.3498 (4.4582)	Training Prec@1 96.875 (96.433)	Training Prec@5 0.000 (0.000)	
2022-07-07 18:57:08,568: ============================================================
2022-07-07 18:58:51,265: time cost, forward:0.010703561281917072, backward:0.03350029088029958, data cost:0.9764597969825821 
2022-07-07 18:58:51,266: ============================================================
2022-07-07 18:58:51,266: Epoch 17/36 Batch 100/7662 eta: 1 day, 19:14:00.501685	Training Loss1 3.8161 (3.9895)	Training Total_Loss 3.8161 (3.9895)	Training Prec@1 97.852 (97.542)	Training Prec@5 0.000 (0.000)	
2022-07-07 18:58:51,266: ============================================================
2022-07-07 19:00:04,475: time cost, forward:0.010686232216993169, backward:0.033449492861877136, data cost:0.830785527301194 
2022-07-07 19:00:04,475: ============================================================
2022-07-07 19:00:04,476: Epoch 17/36 Batch 200/7662 eta: 1 day, 7:07:20.914063	Training Loss1 4.0136 (4.0107)	Training Total_Loss 4.0136 (4.0107)	Training Prec@1 96.875 (97.534)	Training Prec@5 0.000 (0.000)	
2022-07-07 19:00:04,476: ============================================================
2022-07-07 19:01:18,575: time cost, forward:0.010850573064491501, backward:0.03315455618510677, data cost:0.786242687582571 
2022-07-07 19:01:18,576: ============================================================
2022-07-07 19:01:18,576: Epoch 17/36 Batch 300/7662 eta: 1 day, 7:28:50.106399	Training Loss1 3.8940 (4.0237)	Training Total_Loss 3.8940 (4.0237)	Training Prec@1 99.219 (97.481)	Training Prec@5 0.000 (0.000)	
2022-07-07 19:01:18,576: ============================================================
2022-07-07 19:02:32,697: time cost, forward:0.010970496294791238, backward:0.03295090144738219, data cost:0.7638734964499796 
2022-07-07 19:02:32,698: ============================================================
2022-07-07 19:02:32,698: Epoch 17/36 Batch 400/7662 eta: 1 day, 7:28:08.646380	Training Loss1 4.2792 (4.0419)	Training Total_Loss 4.2792 (4.0419)	Training Prec@1 97.656 (97.446)	Training Prec@5 0.000 (0.000)	
2022-07-07 19:02:32,698: ============================================================
2022-07-07 19:03:46,265: time cost, forward:0.01120093255817054, backward:0.033418966438583955, data cost:0.7485612948576291 
2022-07-07 19:03:46,265: ============================================================
2022-07-07 19:03:46,266: Epoch 17/36 Batch 500/7662 eta: 1 day, 7:12:48.092958	Training Loss1 4.2291 (4.0546)	Training Total_Loss 4.2291 (4.0546)	Training Prec@1 96.680 (97.447)	Training Prec@5 0.000 (0.000)	
2022-07-07 19:03:46,266: ============================================================
2022-07-07 19:05:00,382: time cost, forward:0.011322774154714034, backward:0.033613885981411684, data cost:0.7394186487181955 
2022-07-07 19:05:00,383: ============================================================
2022-07-07 19:05:00,383: Epoch 17/36 Batch 600/7662 eta: 1 day, 7:25:33.115001	Training Loss1 4.3237 (4.0683)	Training Total_Loss 4.3237 (4.0683)	Training Prec@1 96.875 (97.422)	Training Prec@5 0.000 (0.000)	
2022-07-07 19:05:00,383: ============================================================
2022-07-07 19:06:13,097: time cost, forward:0.011322430445571484, backward:0.033739731547146906, data cost:0.731056715797457 
2022-07-07 19:06:13,098: ============================================================
2022-07-07 19:06:13,098: Epoch 17/36 Batch 700/7662 eta: 1 day, 6:48:40.174563	Training Loss1 4.3966 (4.0886)	Training Total_Loss 4.3966 (4.0886)	Training Prec@1 97.461 (97.373)	Training Prec@5 0.000 (0.000)	
2022-07-07 19:06:13,098: ============================================================
2022-07-07 19:07:27,361: time cost, forward:0.011334325554075467, backward:0.03386536587463303, data cost:0.7266101458195005 
2022-07-07 19:07:27,362: ============================================================
2022-07-07 19:07:27,362: Epoch 17/36 Batch 800/7662 eta: 1 day, 7:26:49.017480	Training Loss1 4.2562 (4.1019)	Training Total_Loss 4.2562 (4.1019)	Training Prec@1 97.461 (97.344)	Training Prec@5 0.000 (0.000)	
2022-07-07 19:07:27,362: ============================================================
2022-07-07 19:08:40,224: time cost, forward:0.01137318361853068, backward:0.034043345753687775, data cost:0.7215894804117544 
2022-07-07 19:08:40,225: ============================================================
2022-07-07 19:08:40,225: Epoch 17/36 Batch 900/7662 eta: 1 day, 6:50:00.425736	Training Loss1 4.2918 (4.1130)	Training Total_Loss 4.2918 (4.1130)	Training Prec@1 96.289 (97.318)	Training Prec@5 0.000 (0.000)	
2022-07-07 19:08:40,225: ============================================================
2022-07-07 19:09:55,416: time cost, forward:0.011392209384295795, backward:0.03410641543261401, data cost:0.7199471388254557 
2022-07-07 19:09:55,417: ============================================================
2022-07-07 19:09:55,417: Epoch 17/36 Batch 1000/7662 eta: 1 day, 7:47:52.523012	Training Loss1 4.1202 (4.1253)	Training Total_Loss 4.1202 (4.1253)	Training Prec@1 97.461 (97.301)	Training Prec@5 0.000 (0.000)	
2022-07-07 19:09:55,417: ============================================================
2022-07-07 19:11:09,181: time cost, forward:0.011417397376729532, backward:0.034236568662662524, data cost:0.717176247988103 
2022-07-07 19:11:09,181: ============================================================
2022-07-07 19:11:09,182: Epoch 17/36 Batch 1100/7662 eta: 1 day, 7:10:26.572308	Training Loss1 4.1266 (4.1366)	Training Total_Loss 4.1266 (4.1366)	Training Prec@1 96.680 (97.279)	Training Prec@5 0.000 (0.000)	
2022-07-07 19:11:09,182: ============================================================
2022-07-07 19:12:22,130: time cost, forward:0.011515645209305281, backward:0.03434583840517326, data cost:0.7140840102077226 
2022-07-07 19:12:22,131: ============================================================
2022-07-07 19:12:22,131: Epoch 17/36 Batch 1200/7662 eta: 1 day, 6:48:32.735092	Training Loss1 4.3000 (4.1482)	Training Total_Loss 4.3000 (4.1482)	Training Prec@1 97.070 (97.262)	Training Prec@5 0.000 (0.000)	
2022-07-07 19:12:22,131: ============================================================
2022-07-07 19:13:35,712: time cost, forward:0.011511699156728132, backward:0.03435438903503183, data cost:0.7122641397128204 
2022-07-07 19:13:35,712: ============================================================
2022-07-07 19:13:35,712: Epoch 17/36 Batch 1300/7662 eta: 1 day, 7:03:20.718764	Training Loss1 4.2688 (4.1582)	Training Total_Loss 4.2688 (4.1582)	Training Prec@1 97.852 (97.243)	Training Prec@5 0.000 (0.000)	
2022-07-07 19:13:35,713: ============================================================
2022-07-07 19:14:49,850: time cost, forward:0.011561804110872652, backward:0.03434236463774435, data cost:0.7109380680122402 
2022-07-07 19:14:49,851: ============================================================
2022-07-07 19:14:49,851: Epoch 17/36 Batch 1400/7662 eta: 1 day, 7:16:12.568430	Training Loss1 4.2265 (4.1673)	Training Total_Loss 4.2265 (4.1673)	Training Prec@1 96.484 (97.226)	Training Prec@5 0.000 (0.000)	
2022-07-07 19:14:49,851: ============================================================
2022-07-07 19:16:03,631: time cost, forward:0.011592123968112938, backward:0.03442955351098527, data cost:0.7095441228155298 
2022-07-07 19:16:03,631: ============================================================
2022-07-07 19:16:03,631: Epoch 17/36 Batch 1500/7662 eta: 1 day, 7:05:54.642891	Training Loss1 4.2890 (4.1778)	Training Total_Loss 4.2890 (4.1778)	Training Prec@1 96.680 (97.202)	Training Prec@5 0.000 (0.000)	
2022-07-07 19:16:03,631: ============================================================
2022-07-07 19:17:18,134: time cost, forward:0.011614848554991722, backward:0.03439690650739544, data cost:0.7088204830269876 
2022-07-07 19:17:18,135: ============================================================
2022-07-07 19:17:18,135: Epoch 17/36 Batch 1600/7662 eta: 1 day, 7:22:58.525238	Training Loss1 4.3190 (4.1888)	Training Total_Loss 4.3190 (4.1888)	Training Prec@1 96.680 (97.180)	Training Prec@5 0.000 (0.000)	
2022-07-07 19:17:18,135: ============================================================
2022-07-07 19:18:32,443: time cost, forward:0.011657890535369208, backward:0.03444112982028649, data cost:0.7080257999819822 
2022-07-07 19:18:32,444: ============================================================
2022-07-07 19:18:32,444: Epoch 17/36 Batch 1700/7662 eta: 1 day, 7:16:48.815243	Training Loss1 4.3580 (4.1981)	Training Total_Loss 4.3580 (4.1981)	Training Prec@1 97.070 (97.156)	Training Prec@5 0.000 (0.000)	
2022-07-07 19:18:32,444: ============================================================
2022-07-07 19:19:46,206: time cost, forward:0.011665224697670716, backward:0.03445913912257332, data cost:0.7070560305565181 
2022-07-07 19:19:46,207: ============================================================
2022-07-07 19:19:46,207: Epoch 17/36 Batch 1800/7662 eta: 1 day, 7:01:46.865199	Training Loss1 4.6654 (4.2072)	Training Total_Loss 4.6654 (4.2072)	Training Prec@1 95.703 (97.136)	Training Prec@5 0.000 (0.000)	
2022-07-07 19:19:46,207: ============================================================
2022-07-07 19:21:01,094: time cost, forward:0.011652812887455928, backward:0.03451937923561968, data cost:0.7066921657986112 
2022-07-07 19:21:01,095: ============================================================
2022-07-07 19:21:01,095: Epoch 17/36 Batch 1900/7662 eta: 1 day, 7:28:56.516912	Training Loss1 4.4576 (4.2167)	Training Total_Loss 4.4576 (4.2167)	Training Prec@1 96.875 (97.113)	Training Prec@5 0.000 (0.000)	
2022-07-07 19:21:01,095: ============================================================
2022-07-07 19:22:15,038: time cost, forward:0.011630069499853075, backward:0.03454627914390545, data cost:0.7060131386198242 
2022-07-07 19:22:15,038: ============================================================
2022-07-07 19:22:15,039: Epoch 17/36 Batch 2000/7662 eta: 1 day, 7:03:53.245879	Training Loss1 4.2306 (4.2243)	Training Total_Loss 4.2306 (4.2243)	Training Prec@1 96.484 (97.098)	Training Prec@5 0.000 (0.000)	
2022-07-07 19:22:15,039: ============================================================
2022-07-07 19:23:28,493: time cost, forward:0.011629801128182087, backward:0.03458543309942775, data cost:0.7051104512198758 
2022-07-07 19:23:28,493: ============================================================
2022-07-07 19:23:28,493: Epoch 17/36 Batch 2100/7662 eta: 1 day, 6:50:20.046679	Training Loss1 4.3555 (4.2322)	Training Total_Loss 4.3555 (4.2322)	Training Prec@1 96.094 (97.076)	Training Prec@5 0.000 (0.000)	
2022-07-07 19:23:28,493: ============================================================
2022-07-07 19:24:41,727: time cost, forward:0.011611593805046828, backward:0.03461846886791387, data cost:0.7042306142809609 
2022-07-07 19:24:41,728: ============================================================
2022-07-07 19:24:41,729: Epoch 17/36 Batch 2200/7662 eta: 1 day, 6:43:34.853865	Training Loss1 4.4883 (4.2396)	Training Total_Loss 4.4883 (4.2396)	Training Prec@1 95.312 (97.058)	Training Prec@5 0.000 (0.000)	
2022-07-07 19:24:41,729: ============================================================
2022-07-07 19:25:54,293: time cost, forward:0.011626093633385418, backward:0.034613176655281935, data cost:0.7031228199063202 
2022-07-07 19:25:54,294: ============================================================
2022-07-07 19:25:54,294: Epoch 17/36 Batch 2300/7662 eta: 1 day, 6:25:31.053240	Training Loss1 4.4993 (4.2460)	Training Total_Loss 4.4993 (4.2460)	Training Prec@1 97.461 (97.039)	Training Prec@5 0.000 (0.000)	
2022-07-07 19:25:54,294: ============================================================
2022-07-07 19:27:07,699: time cost, forward:0.01161577493859212, backward:0.03460201982559388, data cost:0.7024897203290398 
2022-07-07 19:27:07,700: ============================================================
2022-07-07 19:27:07,700: Epoch 17/36 Batch 2400/7662 eta: 1 day, 6:45:26.542465	Training Loss1 4.2250 (4.2510)	Training Total_Loss 4.2250 (4.2510)	Training Prec@1 96.875 (97.024)	Training Prec@5 0.000 (0.000)	
2022-07-07 19:27:07,700: ============================================================
2022-07-07 19:28:22,640: time cost, forward:0.011625370630124608, backward:0.034603252655126995, data cost:0.7024841770356824 
2022-07-07 19:28:22,640: ============================================================
2022-07-07 19:28:22,641: Epoch 17/36 Batch 2500/7662 eta: 1 day, 7:22:46.228052	Training Loss1 4.3962 (4.2569)	Training Total_Loss 4.3962 (4.2569)	Training Prec@1 97.852 (97.010)	Training Prec@5 0.000 (0.000)	
2022-07-07 19:28:22,641: ============================================================
2022-07-07 19:29:36,561: time cost, forward:0.011619467054618785, backward:0.034601975514733735, data cost:0.702102865701274 
2022-07-07 19:29:36,561: ============================================================
2022-07-07 19:29:36,561: Epoch 17/36 Batch 2600/7662 eta: 1 day, 6:55:55.004988	Training Loss1 4.4411 (4.2640)	Training Total_Loss 4.4411 (4.2640)	Training Prec@1 95.508 (96.984)	Training Prec@5 0.000 (0.000)	
2022-07-07 19:29:36,561: ============================================================
2022-07-07 19:30:50,585: time cost, forward:0.011631501078738156, backward:0.03460250717041536, data cost:0.7017600644116226 
2022-07-07 19:30:50,585: ============================================================
2022-07-07 19:30:50,585: Epoch 17/36 Batch 2700/7662 eta: 1 day, 6:57:16.415537	Training Loss1 4.1240 (4.2698)	Training Total_Loss 4.1240 (4.2698)	Training Prec@1 97.266 (96.968)	Training Prec@5 0.000 (0.000)	
2022-07-07 19:30:50,585: ============================================================
2022-07-07 19:32:04,810: time cost, forward:0.011607138162512744, backward:0.03461377745911495, data cost:0.7015447289486278 
2022-07-07 19:32:04,810: ============================================================
2022-07-07 19:32:04,810: Epoch 17/36 Batch 2800/7662 eta: 1 day, 7:01:05.118691	Training Loss1 4.3436 (4.2742)	Training Total_Loss 4.3436 (4.2742)	Training Prec@1 97.070 (96.954)	Training Prec@5 0.000 (0.000)	
2022-07-07 19:32:04,811: ============================================================
2022-07-07 19:33:16,799: time cost, forward:0.011600807067565813, backward:0.034634000064998546, data cost:0.700552711243381 
2022-07-07 19:33:16,800: ============================================================
2022-07-07 19:33:16,800: Epoch 17/36 Batch 2900/7662 eta: 1 day, 6:03:49.470451	Training Loss1 4.4483 (4.2797)	Training Total_Loss 4.4483 (4.2797)	Training Prec@1 97.070 (96.940)	Training Prec@5 0.000 (0.000)	
2022-07-07 19:33:16,800: ============================================================
2022-07-07 19:34:30,864: time cost, forward:0.011586656964751394, backward:0.034649919930916304, data cost:0.7003329754988723 
2022-07-07 19:34:30,864: ============================================================
2022-07-07 19:34:30,864: Epoch 17/36 Batch 3000/7662 eta: 1 day, 6:54:35.412150	Training Loss1 4.4691 (4.2847)	Training Total_Loss 4.4691 (4.2847)	Training Prec@1 96.289 (96.924)	Training Prec@5 0.000 (0.000)	
2022-07-07 19:34:30,864: ============================================================
2022-07-07 19:35:44,693: time cost, forward:0.011577713293350677, backward:0.03464613271628937, data cost:0.7000595793180906 
2022-07-07 19:35:44,694: ============================================================
2022-07-07 19:35:44,694: Epoch 17/36 Batch 3100/7662 eta: 1 day, 6:47:28.235344	Training Loss1 4.5419 (4.2895)	Training Total_Loss 4.5419 (4.2895)	Training Prec@1 96.289 (96.908)	Training Prec@5 0.000 (0.000)	
2022-07-07 19:35:44,694: ============================================================
2022-07-07 19:36:57,767: time cost, forward:0.011583588651732826, backward:0.03463758770917944, data cost:0.6995479469561658 
2022-07-07 19:36:57,768: ============================================================
2022-07-07 19:36:57,768: Epoch 17/36 Batch 3200/7662 eta: 1 day, 6:27:20.936910	Training Loss1 4.1620 (4.2939)	Training Total_Loss 4.1620 (4.2939)	Training Prec@1 96.875 (96.898)	Training Prec@5 0.000 (0.000)	
2022-07-07 19:36:57,768: ============================================================
2022-07-07 19:38:10,679: time cost, forward:0.011581365178302766, backward:0.034629218684575455, data cost:0.6990409905565764 
2022-07-07 19:38:10,679: ============================================================
2022-07-07 19:38:10,679: Epoch 17/36 Batch 3300/7662 eta: 1 day, 6:22:04.035920	Training Loss1 4.4062 (4.2987)	Training Total_Loss 4.4062 (4.2987)	Training Prec@1 97.070 (96.887)	Training Prec@5 0.000 (0.000)	
2022-07-07 19:38:10,679: ============================================================
2022-07-07 19:39:25,062: time cost, forward:0.011569285750494315, backward:0.034630195994207386, data cost:0.6989934318168755 
2022-07-07 19:39:25,063: ============================================================
2022-07-07 19:39:25,063: Epoch 17/36 Batch 3400/7662 eta: 1 day, 6:57:37.260824	Training Loss1 4.4673 (4.3028)	Training Total_Loss 4.4673 (4.3028)	Training Prec@1 96.875 (96.874)	Training Prec@5 0.000 (0.000)	
2022-07-07 19:39:25,063: ============================================================
2022-07-07 19:40:38,977: time cost, forward:0.011580034949909656, backward:0.03466028906884075, data cost:0.6987608360133535 
2022-07-07 19:40:38,977: ============================================================
2022-07-07 19:40:38,977: Epoch 17/36 Batch 3500/7662 eta: 1 day, 6:44:40.376775	Training Loss1 4.6948 (4.3071)	Training Total_Loss 4.6948 (4.3071)	Training Prec@1 95.117 (96.861)	Training Prec@5 0.000 (0.000)	
2022-07-07 19:40:38,978: ============================================================
2022-07-07 19:41:52,721: time cost, forward:0.01158369809728624, backward:0.03467127130110418, data cost:0.6985244591986679 
2022-07-07 19:41:52,722: ============================================================
2022-07-07 19:41:52,722: Epoch 17/36 Batch 3600/7662 eta: 1 day, 6:39:11.917221	Training Loss1 4.6084 (4.3109)	Training Total_Loss 4.6084 (4.3109)	Training Prec@1 96.680 (96.849)	Training Prec@5 0.000 (0.000)	
2022-07-07 19:41:52,722: ============================================================
2022-07-07 19:43:06,961: time cost, forward:0.01158561040079571, backward:0.03465990750781263, data cost:0.6984529582253338 
2022-07-07 19:43:06,961: ============================================================
2022-07-07 19:43:06,962: Epoch 17/36 Batch 3700/7662 eta: 1 day, 6:50:18.630881	Training Loss1 4.7824 (4.3147)	Training Total_Loss 4.7824 (4.3147)	Training Prec@1 95.898 (96.836)	Training Prec@5 0.000 (0.000)	
2022-07-07 19:43:06,962: ============================================================
2022-07-07 19:44:21,949: time cost, forward:0.011583843680550219, backward:0.03465824178659028, data cost:0.6985772461852264 
2022-07-07 19:44:21,949: ============================================================
2022-07-07 19:44:21,950: Epoch 17/36 Batch 3800/7662 eta: 1 day, 7:07:43.000803	Training Loss1 4.4183 (4.3189)	Training Total_Loss 4.4183 (4.3189)	Training Prec@1 96.289 (96.822)	Training Prec@5 0.000 (0.000)	
2022-07-07 19:44:21,950: ============================================================
2022-07-07 19:45:36,941: time cost, forward:0.011588351180474554, backward:0.03465496426699986, data cost:0.6986820311936454 
2022-07-07 19:45:36,942: ============================================================
2022-07-07 19:45:36,942: Epoch 17/36 Batch 3900/7662 eta: 1 day, 7:06:34.242604	Training Loss1 4.5275 (4.3230)	Training Total_Loss 4.5275 (4.3230)	Training Prec@1 95.898 (96.809)	Training Prec@5 0.000 (0.000)	
2022-07-07 19:45:36,942: ============================================================
2022-07-07 19:46:51,257: time cost, forward:0.011572664932895821, backward:0.03465493555872641, data cost:0.6986496856314566 
2022-07-07 19:46:51,257: ============================================================
2022-07-07 19:46:51,258: Epoch 17/36 Batch 4000/7662 eta: 1 day, 6:48:29.367958	Training Loss1 4.2729 (4.3259)	Training Total_Loss 4.2729 (4.3259)	Training Prec@1 97.656 (96.800)	Training Prec@5 0.000 (0.000)	
2022-07-07 19:46:51,258: ============================================================
2022-07-07 19:48:05,269: time cost, forward:0.011593387661459505, backward:0.034665823215448324, data cost:0.6984839204405249 
2022-07-07 19:48:05,269: ============================================================
2022-07-07 19:48:05,269: Epoch 17/36 Batch 4100/7662 eta: 1 day, 6:39:41.550065	Training Loss1 4.5601 (4.3299)	Training Total_Loss 4.5601 (4.3299)	Training Prec@1 95.508 (96.785)	Training Prec@5 0.000 (0.000)	
2022-07-07 19:48:05,269: ============================================================
2022-07-07 19:49:19,315: time cost, forward:0.011587948196131322, backward:0.03467340825937793, data cost:0.6983655069123623 
2022-07-07 19:49:19,315: ============================================================
2022-07-07 19:49:19,315: Epoch 17/36 Batch 4200/7662 eta: 1 day, 6:39:19.458173	Training Loss1 4.2986 (4.3336)	Training Total_Loss 4.2986 (4.3336)	Training Prec@1 96.484 (96.772)	Training Prec@5 0.000 (0.000)	
2022-07-07 19:49:19,316: ============================================================
2022-07-07 19:50:33,101: time cost, forward:0.011595901818462904, backward:0.0346707500782532, data cost:0.6981941543919842 
2022-07-07 19:50:33,102: ============================================================
2022-07-07 19:50:33,102: Epoch 17/36 Batch 4300/7662 eta: 1 day, 6:31:38.364425	Training Loss1 4.3919 (4.3368)	Training Total_Loss 4.3919 (4.3368)	Training Prec@1 95.312 (96.762)	Training Prec@5 0.000 (0.000)	
2022-07-07 19:50:33,102: ============================================================
2022-07-07 19:51:47,297: time cost, forward:0.01159975213824578, backward:0.034664774678137715, data cost:0.6981222883195437 
2022-07-07 19:51:47,298: ============================================================
2022-07-07 19:51:47,298: Epoch 17/36 Batch 4400/7662 eta: 1 day, 6:40:33.990792	Training Loss1 4.4718 (4.3404)	Training Total_Loss 4.4718 (4.3404)	Training Prec@1 95.898 (96.750)	Training Prec@5 0.000 (0.000)	
2022-07-07 19:51:47,298: ============================================================
2022-07-07 19:53:01,495: time cost, forward:0.01162056955768681, backward:0.034692604135317016, data cost:0.6980043205321431 
2022-07-07 19:53:01,496: ============================================================
2022-07-07 19:53:01,496: Epoch 17/36 Batch 4500/7662 eta: 1 day, 6:39:22.585398	Training Loss1 4.2853 (4.3436)	Training Total_Loss 4.2853 (4.3436)	Training Prec@1 96.289 (96.741)	Training Prec@5 0.000 (0.000)	
2022-07-07 19:53:01,496: ============================================================
2022-07-07 19:54:16,068: time cost, forward:0.011632057396477527, backward:0.03468810783621798, data cost:0.698011559334805 
2022-07-07 19:54:16,069: ============================================================
2022-07-07 19:54:16,069: Epoch 17/36 Batch 4600/7662 eta: 1 day, 6:47:26.399453	Training Loss1 4.5767 (4.3465)	Training Total_Loss 4.5767 (4.3465)	Training Prec@1 95.117 (96.732)	Training Prec@5 0.000 (0.000)	
2022-07-07 19:54:16,069: ============================================================
2022-07-07 19:55:29,599: time cost, forward:0.011655847273828832, backward:0.03467250540043908, data cost:0.6977987416274093 
2022-07-07 19:55:29,600: ============================================================
2022-07-07 19:55:29,600: Epoch 17/36 Batch 4700/7662 eta: 1 day, 6:20:23.650686	Training Loss1 4.3485 (4.3495)	Training Total_Loss 4.3485 (4.3495)	Training Prec@1 96.680 (96.721)	Training Prec@5 0.000 (0.000)	
2022-07-07 19:55:29,600: ============================================================
2022-07-07 19:56:43,309: time cost, forward:0.01164031177790221, backward:0.03467082833220348, data cost:0.6976609563897068 
2022-07-07 19:56:43,309: ============================================================
2022-07-07 19:56:43,309: Epoch 17/36 Batch 4800/7662 eta: 1 day, 6:23:34.735720	Training Loss1 4.4887 (4.3519)	Training Total_Loss 4.4887 (4.3519)	Training Prec@1 97.070 (96.712)	Training Prec@5 0.000 (0.000)	
2022-07-07 19:56:43,309: ============================================================
2022-07-07 19:57:57,562: time cost, forward:0.01164077106459478, backward:0.0346706596338693, data cost:0.697614894591684 
2022-07-07 19:57:57,562: ============================================================
2022-07-07 19:57:57,562: Epoch 17/36 Batch 4900/7662 eta: 1 day, 6:35:47.611638	Training Loss1 4.2667 (4.3551)	Training Total_Loss 4.2667 (4.3551)	Training Prec@1 97.656 (96.698)	Training Prec@5 0.000 (0.000)	
2022-07-07 19:57:57,562: ============================================================
2022-07-07 19:59:13,232: time cost, forward:0.011650467042947775, backward:0.03467984465652286, data cost:0.6978425600452884 
2022-07-07 19:59:13,233: ============================================================
2022-07-07 19:59:13,233: Epoch 17/36 Batch 5000/7662 eta: 1 day, 7:09:34.816589	Training Loss1 4.5475 (4.3579)	Training Total_Loss 4.5475 (4.3579)	Training Prec@1 96.875 (96.687)	Training Prec@5 0.000 (0.000)	
2022-07-07 19:59:13,233: ============================================================
2022-07-07 20:00:26,912: time cost, forward:0.011651043752568169, backward:0.034668706917112824, data cost:0.6976967682719675 
2022-07-07 20:00:26,913: ============================================================
2022-07-07 20:00:26,913: Epoch 17/36 Batch 5100/7662 eta: 1 day, 6:19:10.190710	Training Loss1 4.5306 (4.3598)	Training Total_Loss 4.5306 (4.3598)	Training Prec@1 96.094 (96.681)	Training Prec@5 0.000 (0.000)	
2022-07-07 20:00:26,913: ============================================================
2022-07-07 20:01:40,338: time cost, forward:0.011637907620690653, backward:0.03466819033849283, data cost:0.6975137228047671 
2022-07-07 20:01:40,338: ============================================================
2022-07-07 20:01:40,338: Epoch 17/36 Batch 5200/7662 eta: 1 day, 6:11:39.668205	Training Loss1 4.3463 (4.3622)	Training Total_Loss 4.3463 (4.3622)	Training Prec@1 96.289 (96.672)	Training Prec@5 0.000 (0.000)	
2022-07-07 20:01:40,338: ============================================================
2022-07-07 20:02:55,738: time cost, forward:0.011641836229372213, backward:0.03467217754206358, data cost:0.6976838978894996 
2022-07-07 20:02:55,738: ============================================================
2022-07-07 20:02:55,738: Epoch 17/36 Batch 5300/7662 eta: 1 day, 6:59:07.689090	Training Loss1 4.3966 (4.3643)	Training Total_Loss 4.3966 (4.3643)	Training Prec@1 95.898 (96.665)	Training Prec@5 0.000 (0.000)	
2022-07-07 20:02:55,738: ============================================================
2022-07-07 20:04:09,954: time cost, forward:0.011629518302949981, backward:0.03467563201507212, data cost:0.6976520612430166 
2022-07-07 20:04:09,954: ============================================================
2022-07-07 20:04:09,954: Epoch 17/36 Batch 5400/7662 eta: 1 day, 6:28:41.797227	Training Loss1 4.7863 (4.3666)	Training Total_Loss 4.7863 (4.3666)	Training Prec@1 96.680 (96.657)	Training Prec@5 0.000 (0.000)	
2022-07-07 20:04:09,954: ============================================================
2022-07-07 20:05:24,859: time cost, forward:0.011624248835537126, backward:0.03467533956507939, data cost:0.6977382399945242 
2022-07-07 20:05:24,860: ============================================================
2022-07-07 20:05:24,860: Epoch 17/36 Batch 5500/7662 eta: 1 day, 6:44:26.364673	Training Loss1 4.5447 (4.3683)	Training Total_Loss 4.5447 (4.3683)	Training Prec@1 96.289 (96.650)	Training Prec@5 0.000 (0.000)	
2022-07-07 20:05:24,860: ============================================================
2022-07-07 20:06:40,187: time cost, forward:0.01163742831401004, backward:0.034676223296015406, data cost:0.6978777085570145 
2022-07-07 20:06:40,187: ============================================================
2022-07-07 20:06:40,187: Epoch 17/36 Batch 5600/7662 eta: 1 day, 6:53:33.839353	Training Loss1 4.3334 (4.3701)	Training Total_Loss 4.3334 (4.3701)	Training Prec@1 97.070 (96.642)	Training Prec@5 0.000 (0.000)	
2022-07-07 20:06:40,187: ============================================================
2022-07-07 20:07:54,364: time cost, forward:0.011634116299132712, backward:0.034676882985977354, data cost:0.6978247294113874 
2022-07-07 20:07:54,364: ============================================================
2022-07-07 20:07:54,365: Epoch 17/36 Batch 5700/7662 eta: 1 day, 6:24:02.102171	Training Loss1 4.2899 (4.3720)	Training Total_Loss 4.2899 (4.3720)	Training Prec@1 96.094 (96.636)	Training Prec@5 0.000 (0.000)	
2022-07-07 20:07:54,365: ============================================================
2022-07-07 20:09:07,892: time cost, forward:0.01163617223064372, backward:0.034681260328824036, data cost:0.6976596975680116 
2022-07-07 20:09:07,893: ============================================================
2022-07-07 20:09:07,893: Epoch 17/36 Batch 5800/7662 eta: 1 day, 6:06:51.014841	Training Loss1 4.3384 (4.3739)	Training Total_Loss 4.3384 (4.3739)	Training Prec@1 96.680 (96.630)	Training Prec@5 0.000 (0.000)	
2022-07-07 20:09:07,893: ============================================================
2022-07-07 20:10:22,148: time cost, forward:0.011655141345766323, backward:0.03467837736391985, data cost:0.6976064327390017 
2022-07-07 20:10:22,148: ============================================================
2022-07-07 20:10:22,149: Epoch 17/36 Batch 5900/7662 eta: 1 day, 6:23:28.911242	Training Loss1 4.5334 (4.3765)	Training Total_Loss 4.5334 (4.3765)	Training Prec@1 96.875 (96.621)	Training Prec@5 0.000 (0.000)	
2022-07-07 20:10:22,149: ============================================================
2022-07-07 20:11:36,949: time cost, forward:0.011666995323703853, backward:0.03466956892457082, data cost:0.6976593993349579 
2022-07-07 20:11:36,949: ============================================================
2022-07-07 20:11:36,950: Epoch 17/36 Batch 6000/7662 eta: 1 day, 6:35:37.617366	Training Loss1 4.5623 (4.3781)	Training Total_Loss 4.5623 (4.3781)	Training Prec@1 96.289 (96.616)	Training Prec@5 0.000 (0.000)	
2022-07-07 20:11:36,950: ============================================================
2022-07-07 20:12:51,753: time cost, forward:0.011669870946696203, backward:0.034678367107183077, data cost:0.6977051519374219 
2022-07-07 20:12:51,753: ============================================================
2022-07-07 20:12:51,753: Epoch 17/36 Batch 6100/7662 eta: 1 day, 6:34:26.840257	Training Loss1 4.6569 (4.3803)	Training Total_Loss 4.6569 (4.3803)	Training Prec@1 96.094 (96.608)	Training Prec@5 0.000 (0.000)	
2022-07-07 20:12:51,753: ============================================================
2022-07-07 20:14:06,709: time cost, forward:0.011678042075656694, backward:0.03466448650800099, data cost:0.6977888696673301 
2022-07-07 20:14:06,709: ============================================================
2022-07-07 20:14:06,710: Epoch 17/36 Batch 6200/7662 eta: 1 day, 6:36:56.382332	Training Loss1 4.4413 (4.3825)	Training Total_Loss 4.4413 (4.3825)	Training Prec@1 95.898 (96.598)	Training Prec@5 0.000 (0.000)	
2022-07-07 20:14:06,710: ============================================================
2022-07-07 20:15:20,513: time cost, forward:0.011690028604391473, backward:0.03464597212850035, data cost:0.6976886437154607 
2022-07-07 20:15:20,513: ============================================================
2022-07-07 20:15:20,513: Epoch 17/36 Batch 6300/7662 eta: 1 day, 6:07:28.416772	Training Loss1 4.5590 (4.3846)	Training Total_Loss 4.5590 (4.3846)	Training Prec@1 97.070 (96.592)	Training Prec@5 0.000 (0.000)	
2022-07-07 20:15:20,514: ============================================================
2022-07-07 20:16:33,995: time cost, forward:0.011695312399252408, backward:0.034639772129610266, data cost:0.6975357165130196 
2022-07-07 20:16:33,996: ============================================================
2022-07-07 20:16:33,996: Epoch 17/36 Batch 6400/7662 eta: 1 day, 5:58:22.508656	Training Loss1 4.5727 (4.3865)	Training Total_Loss 4.5727 (4.3865)	Training Prec@1 95.117 (96.584)	Training Prec@5 0.000 (0.000)	
2022-07-07 20:16:33,996: ============================================================
2022-07-07 20:17:48,362: time cost, forward:0.011712730251875157, backward:0.03463184611579788, data cost:0.6975142189788349 
2022-07-07 20:17:48,362: ============================================================
2022-07-07 20:17:48,363: Epoch 17/36 Batch 6500/7662 eta: 1 day, 6:18:46.247078	Training Loss1 4.1850 (4.3882)	Training Total_Loss 4.1850 (4.3882)	Training Prec@1 96.680 (96.576)	Training Prec@5 0.000 (0.000)	
2022-07-07 20:17:48,363: ============================================================
2022-07-07 20:19:03,347: time cost, forward:0.011725719633707948, backward:0.034634045352175624, data cost:0.697582151406027 
2022-07-07 20:19:03,347: ============================================================
2022-07-07 20:19:03,347: Epoch 17/36 Batch 6600/7662 eta: 1 day, 6:32:38.072288	Training Loss1 4.4477 (4.3900)	Training Total_Loss 4.4477 (4.3900)	Training Prec@1 96.484 (96.570)	Training Prec@5 0.000 (0.000)	
2022-07-07 20:19:03,347: ============================================================
2022-07-07 20:20:16,571: time cost, forward:0.011730898990793395, backward:0.03463301838004851, data cost:0.6973964382168214 
2022-07-07 20:20:16,572: ============================================================
2022-07-07 20:20:16,572: Epoch 17/36 Batch 6700/7662 eta: 1 day, 5:48:24.075523	Training Loss1 4.4489 (4.3916)	Training Total_Loss 4.4489 (4.3916)	Training Prec@1 97.070 (96.564)	Training Prec@5 0.000 (0.000)	
2022-07-07 20:20:16,572: ============================================================
2022-07-07 20:21:30,161: time cost, forward:0.011744199210816507, backward:0.03463326483758903, data cost:0.6972575554130253 
2022-07-07 20:21:30,162: ============================================================
2022-07-07 20:21:30,162: Epoch 17/36 Batch 6800/7662 eta: 1 day, 5:56:05.901399	Training Loss1 4.5679 (4.3933)	Training Total_Loss 4.5679 (4.3933)	Training Prec@1 95.508 (96.558)	Training Prec@5 0.000 (0.000)	
2022-07-07 20:21:30,162: ============================================================
2022-07-07 20:22:43,595: time cost, forward:0.011756873922186288, backward:0.03460808836354572, data cost:0.6971228295157726 
2022-07-07 20:22:43,595: ============================================================
2022-07-07 20:22:43,595: Epoch 17/36 Batch 6900/7662 eta: 1 day, 5:51:03.157466	Training Loss1 4.5216 (4.3947)	Training Total_Loss 4.5216 (4.3947)	Training Prec@1 95.312 (96.552)	Training Prec@5 0.000 (0.000)	
2022-07-07 20:22:43,595: ============================================================
2022-07-07 20:23:57,948: time cost, forward:0.011756929640668446, backward:0.03459853369059742, data cost:0.6970893666307864 
2022-07-07 20:23:57,948: ============================================================
2022-07-07 20:23:57,948: Epoch 17/36 Batch 7000/7662 eta: 1 day, 6:12:14.763782	Training Loss1 4.2035 (4.3960)	Training Total_Loss 4.2035 (4.3960)	Training Prec@1 96.289 (96.548)	Training Prec@5 0.000 (0.000)	
2022-07-07 20:23:57,948: ============================================================
2022-07-07 20:25:12,483: time cost, forward:0.011759832285209212, backward:0.034586741598849065, data cost:0.6971504534444501 
2022-07-07 20:25:12,483: ============================================================
2022-07-07 20:25:12,483: Epoch 17/36 Batch 7100/7662 eta: 1 day, 6:15:26.165904	Training Loss1 4.5252 (4.3974)	Training Total_Loss 4.5252 (4.3974)	Training Prec@1 97.266 (96.541)	Training Prec@5 0.000 (0.000)	
2022-07-07 20:25:12,483: ============================================================
2022-07-07 20:26:27,641: time cost, forward:0.01176098320679228, backward:0.034570101748441454, data cost:0.6972740799010603 
2022-07-07 20:26:27,642: ============================================================
2022-07-07 20:26:27,642: Epoch 17/36 Batch 7200/7662 eta: 1 day, 6:29:22.602706	Training Loss1 4.3989 (4.3986)	Training Total_Loss 4.3989 (4.3986)	Training Prec@1 97.461 (96.536)	Training Prec@5 0.000 (0.000)	
2022-07-07 20:26:27,642: ============================================================
2022-07-07 20:27:41,736: time cost, forward:0.011749732852031113, backward:0.03456244176014562, data cost:0.6972440233751918 
2022-07-07 20:27:41,736: ============================================================
2022-07-07 20:27:41,736: Epoch 17/36 Batch 7300/7662 eta: 1 day, 6:02:13.752595	Training Loss1 4.5900 (4.3998)	Training Total_Loss 4.5900 (4.3998)	Training Prec@1 95.703 (96.531)	Training Prec@5 0.000 (0.000)	
2022-07-07 20:27:41,736: ============================================================
2022-07-07 20:28:55,497: time cost, forward:0.011754899206057096, backward:0.03456230913727553, data cost:0.6971543123954405 
2022-07-07 20:28:55,498: ============================================================
2022-07-07 20:28:55,498: Epoch 17/36 Batch 7400/7662 eta: 1 day, 5:52:54.626917	Training Loss1 4.6448 (4.4014)	Training Total_Loss 4.6448 (4.4014)	Training Prec@1 95.508 (96.524)	Training Prec@5 0.000 (0.000)	
2022-07-07 20:28:55,498: ============================================================
2022-07-07 20:30:10,106: time cost, forward:0.011774423838075056, backward:0.03457639321976939, data cost:0.697140538862569 
2022-07-07 20:30:10,106: ============================================================
2022-07-07 20:30:10,106: Epoch 17/36 Batch 7500/7662 eta: 1 day, 6:12:15.145150	Training Loss1 4.5733 (4.4028)	Training Total_Loss 4.5733 (4.4028)	Training Prec@1 96.680 (96.520)	Training Prec@5 0.000 (0.000)	
2022-07-07 20:30:10,106: ============================================================
2022-07-07 20:31:25,943: time cost, forward:0.01178576281422423, backward:0.03456839838691849, data cost:0.6973249787703237 
2022-07-07 20:31:25,944: ============================================================
2022-07-07 20:31:25,944: Epoch 17/36 Batch 7600/7662 eta: 1 day, 6:40:50.787969	Training Loss1 4.3817 (4.4039)	Training Total_Loss 4.3817 (4.4039)	Training Prec@1 96.484 (96.515)	Training Prec@5 0.000 (0.000)	
2022-07-07 20:31:25,944: ============================================================
2022-07-07 20:32:13,982: Epoch 17/36 Batch 7663/7662 eta: 1 day, 6:40:03.010217	Training Loss1 4.2987 (4.4046)	Training Total_Loss 4.2987 (4.4046)	Training Prec@1 95.898 (96.512)	Training Prec@5 0.000 (0.000)	
2022-07-07 20:32:13,982: ============================================================
2022-07-07 20:33:49,551: time cost, forward:0.010885599887732304, backward:0.03287188693730518, data cost:0.9133922042268695 
2022-07-07 20:33:49,552: ============================================================
2022-07-07 20:33:49,552: Epoch 18/36 Batch 100/7662 eta: 1 day, 14:30:55.890874	Training Loss1 4.2053 (3.9500)	Training Total_Loss 4.2053 (3.9500)	Training Prec@1 96.289 (97.567)	Training Prec@5 0.000 (0.000)	
2022-07-07 20:33:49,552: ============================================================
2022-07-07 20:35:04,674: time cost, forward:0.010977294576827007, backward:0.032536326940335224, data cost:0.8098494359596291 
2022-07-07 20:35:04,675: ============================================================
2022-07-07 20:35:04,675: Epoch 18/36 Batch 200/7662 eta: 1 day, 6:20:13.600854	Training Loss1 3.8998 (3.9606)	Training Total_Loss 3.8998 (3.9606)	Training Prec@1 96.875 (97.566)	Training Prec@5 0.000 (0.000)	
2022-07-07 20:35:04,675: ============================================================
2022-07-07 20:36:20,135: time cost, forward:0.011059797727144681, backward:0.03239840089676771, data cost:0.7767586771859771 
2022-07-07 20:36:20,136: ============================================================
2022-07-07 20:36:20,136: Epoch 18/36 Batch 300/7662 eta: 1 day, 6:27:08.753378	Training Loss1 4.0088 (3.9787)	Training Total_Loss 4.0088 (3.9787)	Training Prec@1 97.852 (97.562)	Training Prec@5 0.000 (0.000)	
2022-07-07 20:36:20,136: ============================================================
2022-07-07 20:37:34,371: time cost, forward:0.010936980856988663, backward:0.032751591880817464, data cost:0.7568479134026626 
2022-07-07 20:37:34,372: ============================================================
2022-07-07 20:37:34,372: Epoch 18/36 Batch 400/7662 eta: 1 day, 5:56:14.896655	Training Loss1 4.2200 (3.9942)	Training Total_Loss 4.2200 (3.9942)	Training Prec@1 97.070 (97.534)	Training Prec@5 0.000 (0.000)	
2022-07-07 20:37:34,372: ============================================================
2022-07-07 20:38:49,599: time cost, forward:0.010913817820424785, backward:0.03304152832719272, data cost:0.7467947135229627 
2022-07-07 20:38:49,599: ============================================================
2022-07-07 20:38:49,599: Epoch 18/36 Batch 500/7662 eta: 1 day, 6:18:59.517741	Training Loss1 4.1895 (4.0159)	Training Total_Loss 4.1895 (4.0159)	Training Prec@1 97.656 (97.467)	Training Prec@5 0.000 (0.000)	
2022-07-07 20:38:49,600: ============================================================
2022-07-07 20:40:04,241: time cost, forward:0.01112572338823882, backward:0.03326411517912239, data cost:0.7386446643950346 
2022-07-07 20:40:04,241: ============================================================
2022-07-07 20:40:04,242: Epoch 18/36 Batch 600/7662 eta: 1 day, 6:03:35.485402	Training Loss1 4.3443 (4.0288)	Training Total_Loss 4.3443 (4.0288)	Training Prec@1 97.656 (97.463)	Training Prec@5 0.000 (0.000)	
2022-07-07 20:40:04,242: ============================================================
2022-07-07 20:41:17,433: time cost, forward:0.011311613609521345, backward:0.03338395918217169, data cost:0.7309803283947902 
2022-07-07 20:41:17,433: ============================================================
2022-07-07 20:41:17,433: Epoch 18/36 Batch 700/7662 eta: 1 day, 5:27:19.224090	Training Loss1 4.3287 (4.0397)	Training Total_Loss 4.3287 (4.0397)	Training Prec@1 96.875 (97.444)	Training Prec@5 0.000 (0.000)	
2022-07-07 20:41:17,433: ============================================================
2022-07-07 20:42:31,360: time cost, forward:0.011391830981449132, backward:0.03358253579265036, data cost:0.7261880828680771 
2022-07-07 20:42:31,360: ============================================================
2022-07-07 20:42:31,361: Epoch 18/36 Batch 800/7662 eta: 1 day, 5:43:51.314710	Training Loss1 4.2354 (4.0535)	Training Total_Loss 4.2354 (4.0535)	Training Prec@1 98.047 (97.418)	Training Prec@5 0.000 (0.000)	
2022-07-07 20:42:31,361: ============================================================
2022-07-07 20:43:44,401: time cost, forward:0.011375869341501272, backward:0.03362742043177994, data cost:0.7215849883829526 
2022-07-07 20:43:44,402: ============================================================
2022-07-07 20:43:44,402: Epoch 18/36 Batch 900/7662 eta: 1 day, 5:21:15.485291	Training Loss1 4.3114 (4.0669)	Training Total_Loss 4.3114 (4.0669)	Training Prec@1 97.266 (97.399)	Training Prec@5 0.000 (0.000)	
2022-07-07 20:43:44,402: ============================================================
2022-07-07 20:44:58,713: time cost, forward:0.011403748223015497, backward:0.03364685395577768, data cost:0.7190843435140463 
2022-07-07 20:44:58,713: ============================================================
2022-07-07 20:44:58,714: Epoch 18/36 Batch 1000/7662 eta: 1 day, 5:50:39.035682	Training Loss1 3.9381 (4.0821)	Training Total_Loss 3.9381 (4.0821)	Training Prec@1 97.266 (97.371)	Training Prec@5 0.000 (0.000)	
2022-07-07 20:44:58,714: ============================================================
2022-07-07 20:46:11,951: time cost, forward:0.01140809406249278, backward:0.03360594023998701, data cost:0.7162137411202595 
2022-07-07 20:46:11,952: ============================================================
2022-07-07 20:46:11,952: Epoch 18/36 Batch 1100/7662 eta: 1 day, 5:23:34.037295	Training Loss1 4.1079 (4.0929)	Training Total_Loss 4.1079 (4.0929)	Training Prec@1 96.875 (97.347)	Training Prec@5 0.000 (0.000)	
2022-07-07 20:46:11,952: ============================================================
2022-07-07 20:47:26,397: time cost, forward:0.011422672502392029, backward:0.033650684794154735, data cost:0.714716170806503 
2022-07-07 20:47:26,397: ============================================================
2022-07-07 20:47:26,397: Epoch 18/36 Batch 1200/7662 eta: 1 day, 5:51:23.305482	Training Loss1 4.1837 (4.1042)	Training Total_Loss 4.1837 (4.1042)	Training Prec@1 96.680 (97.326)	Training Prec@5 0.000 (0.000)	
2022-07-07 20:47:26,397: ============================================================
2022-07-07 20:48:40,427: time cost, forward:0.011471783958828568, backward:0.03372467729658049, data cost:0.713041579567349 
2022-07-07 20:48:40,427: ============================================================
2022-07-07 20:48:40,427: Epoch 18/36 Batch 1300/7662 eta: 1 day, 5:40:09.550337	Training Loss1 4.0341 (4.1155)	Training Total_Loss 4.0341 (4.1155)	Training Prec@1 98.047 (97.305)	Training Prec@5 0.000 (0.000)	
2022-07-07 20:48:40,427: ============================================================
2022-07-07 20:49:55,109: time cost, forward:0.011557219623241194, backward:0.033715957910184606, data cost:0.7121030534481133 
2022-07-07 20:49:55,109: ============================================================
2022-07-07 20:49:55,109: Epoch 18/36 Batch 1400/7662 eta: 1 day, 5:54:35.708417	Training Loss1 4.2630 (4.1242)	Training Total_Loss 4.2630 (4.1242)	Training Prec@1 96.484 (97.279)	Training Prec@5 0.000 (0.000)	
2022-07-07 20:49:55,109: ============================================================
2022-07-07 20:51:09,461: time cost, forward:0.011608470830223892, backward:0.03378210439930127, data cost:0.7107329099793844 
2022-07-07 20:51:09,462: ============================================================
2022-07-07 20:51:09,462: Epoch 18/36 Batch 1500/7662 eta: 1 day, 5:45:26.974603	Training Loss1 4.2326 (4.1334)	Training Total_Loss 4.2326 (4.1334)	Training Prec@1 96.289 (97.268)	Training Prec@5 0.000 (0.000)	
2022-07-07 20:51:09,462: ============================================================
2022-07-07 20:52:23,875: time cost, forward:0.011644124239217199, backward:0.033804191359137654, data cost:0.710150011335782 
2022-07-07 20:52:23,875: ============================================================
2022-07-07 20:52:23,875: Epoch 18/36 Batch 1600/7662 eta: 1 day, 5:45:39.685912	Training Loss1 4.0392 (4.1408)	Training Total_Loss 4.0392 (4.1408)	Training Prec@1 97.266 (97.253)	Training Prec@5 0.000 (0.000)	
2022-07-07 20:52:23,876: ============================================================
2022-07-07 20:53:36,482: time cost, forward:0.011634460682725823, backward:0.03380763790339424, data cost:0.7083939506840607 
2022-07-07 20:53:36,483: ============================================================
2022-07-07 20:53:36,483: Epoch 18/36 Batch 1700/7662 eta: 1 day, 5:01:06.866137	Training Loss1 4.0409 (4.1501)	Training Total_Loss 4.0409 (4.1501)	Training Prec@1 98.047 (97.230)	Training Prec@5 0.000 (0.000)	
2022-07-07 20:53:36,483: ============================================================
2022-07-07 20:54:50,434: time cost, forward:0.011624498192372091, backward:0.03380561683362163, data cost:0.7075803146023032 
2022-07-07 20:54:50,434: ============================================================
2022-07-07 20:54:50,434: Epoch 18/36 Batch 1800/7662 eta: 1 day, 5:32:06.387387	Training Loss1 4.4377 (4.1587)	Training Total_Loss 4.4377 (4.1587)	Training Prec@1 96.289 (97.213)	Training Prec@5 0.000 (0.000)	
2022-07-07 20:54:50,434: ============================================================
2022-07-07 20:56:03,953: time cost, forward:0.011656333171046992, backward:0.03380288796527817, data cost:0.7065808752952845 
2022-07-07 20:56:03,953: ============================================================
2022-07-07 20:56:03,953: Epoch 18/36 Batch 1900/7662 eta: 1 day, 5:20:31.424377	Training Loss1 4.3946 (4.1650)	Training Total_Loss 4.3946 (4.1650)	Training Prec@1 96.875 (97.200)	Training Prec@5 0.000 (0.000)	
2022-07-07 20:56:03,953: ============================================================
2022-07-07 20:57:17,814: time cost, forward:0.01164140183666815, backward:0.03384173709550698, data cost:0.7058457962091473 
2022-07-07 20:57:17,814: ============================================================
2022-07-07 20:57:17,815: Epoch 18/36 Batch 2000/7662 eta: 1 day, 5:27:29.370001	Training Loss1 4.3066 (4.1706)	Training Total_Loss 4.3066 (4.1706)	Training Prec@1 97.461 (97.197)	Training Prec@5 0.000 (0.000)	
2022-07-07 20:57:17,815: ============================================================
2022-07-07 20:58:32,963: time cost, forward:0.01165973668782242, backward:0.033830594880175396, data cost:0.7058342534510961 
2022-07-07 20:58:32,963: ============================================================
2022-07-07 20:58:32,963: Epoch 18/36 Batch 2100/7662 eta: 1 day, 5:57:02.316608	Training Loss1 4.7485 (4.1780)	Training Total_Loss 4.7485 (4.1780)	Training Prec@1 95.508 (97.179)	Training Prec@5 0.000 (0.000)	
2022-07-07 20:58:32,963: ============================================================
2022-07-07 20:59:46,074: time cost, forward:0.01168998754691297, backward:0.03384191711255777, data cost:0.7047497742606489 
2022-07-07 20:59:46,074: ============================================================
2022-07-07 20:59:46,075: Epoch 18/36 Batch 2200/7662 eta: 1 day, 5:07:06.545483	Training Loss1 4.4471 (4.1857)	Training Total_Loss 4.4471 (4.1857)	Training Prec@1 96.484 (97.160)	Training Prec@5 0.000 (0.000)	
2022-07-07 20:59:46,075: ============================================================
2022-07-07 21:00:59,428: time cost, forward:0.01170571475715521, backward:0.03387703694380486, data cost:0.7040290105545091 
2022-07-07 21:00:59,429: ============================================================
2022-07-07 21:00:59,429: Epoch 18/36 Batch 2300/7662 eta: 1 day, 5:11:41.331441	Training Loss1 4.2560 (4.1929)	Training Total_Loss 4.2560 (4.1929)	Training Prec@1 97.266 (97.145)	Training Prec@5 0.000 (0.000)	
2022-07-07 21:00:59,429: ============================================================
2022-07-07 21:02:13,430: time cost, forward:0.011710151725632292, backward:0.033887957175009545, data cost:0.7035935399133795 
2022-07-07 21:02:13,430: ============================================================
2022-07-07 21:02:13,430: Epoch 18/36 Batch 2400/7662 eta: 1 day, 5:25:54.619818	Training Loss1 4.1650 (4.1983)	Training Total_Loss 4.1650 (4.1983)	Training Prec@1 96.875 (97.129)	Training Prec@5 0.000 (0.000)	
2022-07-07 21:02:13,430: ============================================================
2022-07-07 21:03:26,879: time cost, forward:0.011715206827054552, backward:0.033883907070823935, data cost:0.7029811275057813 
2022-07-07 21:03:26,879: ============================================================
2022-07-07 21:03:26,880: Epoch 18/36 Batch 2500/7662 eta: 1 day, 5:11:30.279090	Training Loss1 4.3622 (4.2056)	Training Total_Loss 4.3622 (4.2056)	Training Prec@1 95.703 (97.111)	Training Prec@5 0.000 (0.000)	
2022-07-07 21:03:26,880: ============================================================
2022-07-07 21:04:40,328: time cost, forward:0.011714142164206128, backward:0.03387079361816148, data cost:0.7024197181218769 
2022-07-07 21:04:40,329: ============================================================
2022-07-07 21:04:40,329: Epoch 18/36 Batch 2600/7662 eta: 1 day, 5:10:17.183463	Training Loss1 4.4260 (4.2100)	Training Total_Loss 4.4260 (4.2100)	Training Prec@1 95.117 (97.096)	Training Prec@5 0.000 (0.000)	
2022-07-07 21:04:40,329: ============================================================
2022-07-07 21:05:53,279: time cost, forward:0.011712023574981746, backward:0.03386816504974196, data cost:0.7017259055395928 
2022-07-07 21:05:53,279: ============================================================
2022-07-07 21:05:53,280: Epoch 18/36 Batch 2700/7662 eta: 1 day, 4:57:11.170422	Training Loss1 4.7643 (4.2162)	Training Total_Loss 4.7643 (4.2162)	Training Prec@1 93.164 (97.078)	Training Prec@5 0.000 (0.000)	
2022-07-07 21:05:53,280: ============================================================
2022-07-07 21:07:07,746: time cost, forward:0.011679443047275796, backward:0.03387918502954808, data cost:0.7016328941630057 
2022-07-07 21:07:07,746: ============================================================
2022-07-07 21:07:07,747: Epoch 18/36 Batch 2800/7662 eta: 1 day, 5:32:03.201176	Training Loss1 4.3011 (4.2224)	Training Total_Loss 4.3011 (4.2224)	Training Prec@1 97.070 (97.066)	Training Prec@5 0.000 (0.000)	
2022-07-07 21:07:07,747: ============================================================
2022-07-07 21:08:21,740: time cost, forward:0.011672265696583143, backward:0.033869899112876425, data cost:0.7013442442309408 
2022-07-07 21:08:21,741: ============================================================
2022-07-07 21:08:21,741: Epoch 18/36 Batch 2900/7662 eta: 1 day, 5:19:34.574444	Training Loss1 4.3701 (4.2277)	Training Total_Loss 4.3701 (4.2277)	Training Prec@1 95.703 (97.048)	Training Prec@5 0.000 (0.000)	
2022-07-07 21:08:21,741: ============================================================
2022-07-07 21:09:34,949: time cost, forward:0.01166677013879301, backward:0.0338552917946017, data cost:0.7008880018671182 
2022-07-07 21:09:34,950: ============================================================
2022-07-07 21:09:34,950: Epoch 18/36 Batch 3000/7662 eta: 1 day, 4:59:40.669446	Training Loss1 4.2414 (4.2328)	Training Total_Loss 4.2414 (4.2328)	Training Prec@1 96.875 (97.038)	Training Prec@5 0.000 (0.000)	
2022-07-07 21:09:34,950: ============================================================
2022-07-07 21:10:48,304: time cost, forward:0.011681165184348427, backward:0.033865108456139256, data cost:0.7004247781883405 
2022-07-07 21:10:48,305: ============================================================
2022-07-07 21:10:48,305: Epoch 18/36 Batch 3100/7662 eta: 1 day, 5:01:55.380458	Training Loss1 4.5256 (4.2383)	Training Total_Loss 4.5256 (4.2383)	Training Prec@1 95.117 (97.025)	Training Prec@5 0.000 (0.000)	
2022-07-07 21:10:48,305: ============================================================
2022-07-07 21:12:01,927: time cost, forward:0.011673938933667931, backward:0.0338818227995109, data cost:0.7000869533798776 
2022-07-07 21:12:01,928: ============================================================
2022-07-07 21:12:01,928: Epoch 18/36 Batch 3200/7662 eta: 1 day, 5:07:03.369231	Training Loss1 4.2260 (4.2428)	Training Total_Loss 4.2260 (4.2428)	Training Prec@1 96.289 (97.010)	Training Prec@5 0.000 (0.000)	
2022-07-07 21:12:01,928: ============================================================
2022-07-07 21:13:16,138: time cost, forward:0.01165791792232147, backward:0.03386830358513922, data cost:0.6999969120349404 
2022-07-07 21:13:16,139: ============================================================
2022-07-07 21:13:16,139: Epoch 18/36 Batch 3300/7662 eta: 1 day, 5:19:46.816541	Training Loss1 4.2940 (4.2471)	Training Total_Loss 4.2940 (4.2471)	Training Prec@1 96.680 (97.000)	Training Prec@5 0.000 (0.000)	
2022-07-07 21:13:16,139: ============================================================
2022-07-07 21:14:29,006: time cost, forward:0.011639851547402822, backward:0.033879533239096954, data cost:0.6994852314769748 
2022-07-07 21:14:29,006: ============================================================
2022-07-07 21:14:29,007: Epoch 18/36 Batch 3400/7662 eta: 1 day, 4:46:42.420885	Training Loss1 4.5775 (4.2516)	Training Total_Loss 4.5775 (4.2516)	Training Prec@1 93.945 (96.987)	Training Prec@5 0.000 (0.000)	
2022-07-07 21:14:29,007: ============================================================
2022-07-07 21:15:42,748: time cost, forward:0.011644640320469631, backward:0.03388123247888505, data cost:0.6992502901410335 
2022-07-07 21:15:42,749: ============================================================
2022-07-07 21:15:42,749: Epoch 18/36 Batch 3500/7662 eta: 1 day, 5:06:12.559923	Training Loss1 4.3506 (4.2571)	Training Total_Loss 4.3506 (4.2571)	Training Prec@1 96.680 (96.973)	Training Prec@5 0.000 (0.000)	
2022-07-07 21:15:42,749: ============================================================
2022-07-07 21:16:57,012: time cost, forward:0.011658878649695444, backward:0.03390406773931021, data cost:0.6991390017344906 
2022-07-07 21:16:57,012: ============================================================
2022-07-07 21:16:57,012: Epoch 18/36 Batch 3600/7662 eta: 1 day, 5:17:18.641992	Training Loss1 4.6948 (4.2606)	Training Total_Loss 4.6948 (4.2606)	Training Prec@1 96.094 (96.960)	Training Prec@5 0.000 (0.000)	
2022-07-07 21:16:57,013: ============================================================
2022-07-07 21:18:10,568: time cost, forward:0.011679371488065325, backward:0.03390061761856595, data cost:0.6988622415191452 
2022-07-07 21:18:10,569: ============================================================
2022-07-07 21:18:10,569: Epoch 18/36 Batch 3700/7662 eta: 1 day, 4:59:20.943109	Training Loss1 4.5264 (4.2644)	Training Total_Loss 4.5264 (4.2644)	Training Prec@1 96.484 (96.949)	Training Prec@5 0.000 (0.000)	
2022-07-07 21:18:10,569: ============================================================
2022-07-07 21:19:24,530: time cost, forward:0.011709715824875275, backward:0.03388923392480347, data cost:0.69870097827334 
2022-07-07 21:19:24,531: ============================================================
2022-07-07 21:19:24,531: Epoch 18/36 Batch 3800/7662 eta: 1 day, 5:07:42.709913	Training Loss1 4.4125 (4.2683)	Training Total_Loss 4.4125 (4.2683)	Training Prec@1 97.656 (96.935)	Training Prec@5 0.000 (0.000)	
2022-07-07 21:19:24,531: ============================================================
2022-07-07 21:20:38,180: time cost, forward:0.011722251310443903, backward:0.03389201087198309, data cost:0.6984677234042085 
2022-07-07 21:20:38,181: ============================================================
2022-07-07 21:20:38,181: Epoch 18/36 Batch 3900/7662 eta: 1 day, 4:59:06.642748	Training Loss1 4.3763 (4.2730)	Training Total_Loss 4.3763 (4.2730)	Training Prec@1 96.289 (96.920)	Training Prec@5 0.000 (0.000)	
2022-07-07 21:20:38,181: ============================================================
2022-07-07 21:21:51,957: time cost, forward:0.011715231373418001, backward:0.033874688490714754, data cost:0.6983219743162491 
2022-07-07 21:21:51,957: ============================================================
2022-07-07 21:21:51,957: Epoch 18/36 Batch 4000/7662 eta: 1 day, 5:00:51.783829	Training Loss1 4.3324 (4.2765)	Training Total_Loss 4.3324 (4.2765)	Training Prec@1 97.461 (96.908)	Training Prec@5 0.000 (0.000)	
2022-07-07 21:21:51,957: ============================================================
2022-07-07 21:23:07,084: time cost, forward:0.011727722832911711, backward:0.03385363907079983, data cost:0.698489638298539 
2022-07-07 21:23:07,084: ============================================================
2022-07-07 21:23:07,085: Epoch 18/36 Batch 4100/7662 eta: 1 day, 5:31:29.277243	Training Loss1 4.4754 (4.2803)	Training Total_Loss 4.4754 (4.2803)	Training Prec@1 96.875 (96.895)	Training Prec@5 0.000 (0.000)	
2022-07-07 21:23:07,085: ============================================================
2022-07-07 21:24:21,391: time cost, forward:0.011726758172893047, backward:0.03385364427314426, data cost:0.6984179302691619 
2022-07-07 21:24:21,392: ============================================================
2022-07-07 21:24:21,392: Epoch 18/36 Batch 4200/7662 eta: 1 day, 5:10:55.019929	Training Loss1 4.4571 (4.2828)	Training Total_Loss 4.4571 (4.2828)	Training Prec@1 97.070 (96.885)	Training Prec@5 0.000 (0.000)	
2022-07-07 21:24:21,392: ============================================================
2022-07-07 21:25:35,882: time cost, forward:0.01173626125954173, backward:0.03385889715969798, data cost:0.6984475148669729 
2022-07-07 21:25:35,882: ============================================================
2022-07-07 21:25:35,883: Epoch 18/36 Batch 4300/7662 eta: 1 day, 5:13:59.612991	Training Loss1 4.2088 (4.2856)	Training Total_Loss 4.2088 (4.2856)	Training Prec@1 97.266 (96.876)	Training Prec@5 0.000 (0.000)	
2022-07-07 21:25:35,883: ============================================================
2022-07-07 21:26:50,498: time cost, forward:0.011744266803981662, backward:0.03388141875755898, data cost:0.6984418636290803 
2022-07-07 21:26:50,498: ============================================================
2022-07-07 21:26:50,499: Epoch 18/36 Batch 4400/7662 eta: 1 day, 5:15:42.187178	Training Loss1 4.3221 (4.2889)	Training Total_Loss 4.3221 (4.2889)	Training Prec@1 96.875 (96.866)	Training Prec@5 0.000 (0.000)	
2022-07-07 21:26:50,499: ============================================================
2022-07-07 21:28:04,936: time cost, forward:0.01174218359457755, backward:0.033893045570405754, data cost:0.6984366447985451 
2022-07-07 21:28:04,937: ============================================================
2022-07-07 21:28:04,937: Epoch 18/36 Batch 4500/7662 eta: 1 day, 5:10:17.355691	Training Loss1 4.1137 (4.2918)	Training Total_Loss 4.1137 (4.2918)	Training Prec@1 98.438 (96.854)	Training Prec@5 0.000 (0.000)	
2022-07-07 21:28:04,938: ============================================================
2022-07-07 21:29:17,538: time cost, forward:0.011732457538977165, backward:0.03389650330540408, data cost:0.6980361572994722 
2022-07-07 21:29:17,538: ============================================================
2022-07-07 21:29:17,538: Epoch 18/36 Batch 4600/7662 eta: 1 day, 4:25:51.932303	Training Loss1 4.5432 (4.2948)	Training Total_Loss 4.5432 (4.2948)	Training Prec@1 95.312 (96.844)	Training Prec@5 0.000 (0.000)	
2022-07-07 21:29:17,538: ============================================================
2022-07-07 21:30:32,936: time cost, forward:0.011732586040525239, backward:0.033895798403294854, data cost:0.6982439637412464 
2022-07-07 21:30:32,936: ============================================================
2022-07-07 21:30:32,936: Epoch 18/36 Batch 4700/7662 eta: 1 day, 5:30:20.004515	Training Loss1 4.2631 (4.2982)	Training Total_Loss 4.2631 (4.2982)	Training Prec@1 96.484 (96.834)	Training Prec@5 0.000 (0.000)	
2022-07-07 21:30:32,936: ============================================================
2022-07-07 21:31:45,857: time cost, forward:0.011745332951196955, backward:0.03390270189633839, data cost:0.6978985332255315 
2022-07-07 21:31:45,857: ============================================================
2022-07-07 21:31:45,858: Epoch 18/36 Batch 4800/7662 eta: 1 day, 4:30:58.162803	Training Loss1 4.2619 (4.3005)	Training Total_Loss 4.2619 (4.3005)	Training Prec@1 97.266 (96.825)	Training Prec@5 0.000 (0.000)	
2022-07-07 21:31:45,858: ============================================================
2022-07-07 21:33:00,357: time cost, forward:0.01174947115128613, backward:0.033909421425543165, data cost:0.6979083342317611 
2022-07-07 21:33:00,358: ============================================================
2022-07-07 21:33:00,358: Epoch 18/36 Batch 4900/7662 eta: 1 day, 5:06:46.353747	Training Loss1 4.5567 (4.3033)	Training Total_Loss 4.5567 (4.3033)	Training Prec@1 94.922 (96.815)	Training Prec@5 0.000 (0.000)	
2022-07-07 21:33:00,358: ============================================================
2022-07-07 21:34:14,648: time cost, forward:0.011753664896187245, backward:0.033924005298190986, data cost:0.6978674307420841 
2022-07-07 21:34:14,648: ============================================================
2022-07-07 21:34:14,648: Epoch 18/36 Batch 5000/7662 eta: 1 day, 5:00:36.283503	Training Loss1 4.6343 (4.3062)	Training Total_Loss 4.6343 (4.3062)	Training Prec@1 96.289 (96.804)	Training Prec@5 0.000 (0.000)	
2022-07-07 21:34:14,648: ============================================================
2022-07-07 21:35:28,860: time cost, forward:0.011762752465627595, backward:0.03392604786546868, data cost:0.6978159857909103 
2022-07-07 21:35:28,861: ============================================================
2022-07-07 21:35:28,861: Epoch 18/36 Batch 5100/7662 eta: 1 day, 4:57:33.405042	Training Loss1 4.4337 (4.3085)	Training Total_Loss 4.4337 (4.3085)	Training Prec@1 96.484 (96.797)	Training Prec@5 0.000 (0.000)	
2022-07-07 21:35:28,861: ============================================================
2022-07-07 21:36:43,171: time cost, forward:0.011749471373502096, backward:0.03393530405400051, data cost:0.6977821465844626 
2022-07-07 21:36:43,171: ============================================================
2022-07-07 21:36:43,171: Epoch 18/36 Batch 5200/7662 eta: 1 day, 4:58:36.198772	Training Loss1 4.3365 (4.3107)	Training Total_Loss 4.3365 (4.3107)	Training Prec@1 96.875 (96.788)	Training Prec@5 0.000 (0.000)	
2022-07-07 21:36:43,171: ============================================================
2022-07-07 21:37:57,520: time cost, forward:0.011749333313083307, backward:0.03395023938056815, data cost:0.6977750029422626 
2022-07-07 21:37:57,521: ============================================================
2022-07-07 21:37:57,521: Epoch 18/36 Batch 5300/7662 eta: 1 day, 4:58:17.027667	Training Loss1 4.4718 (4.3130)	Training Total_Loss 4.4718 (4.3130)	Training Prec@1 96.289 (96.781)	Training Prec@5 0.000 (0.000)	
2022-07-07 21:37:57,521: ============================================================
2022-07-07 21:39:11,604: time cost, forward:0.011750563932229114, backward:0.033950875922250934, data cost:0.6977091385360381 
2022-07-07 21:39:11,604: ============================================================
2022-07-07 21:39:11,604: Epoch 18/36 Batch 5400/7662 eta: 1 day, 4:50:48.834561	Training Loss1 4.6614 (4.3145)	Training Total_Loss 4.6614 (4.3145)	Training Prec@1 95.508 (96.774)	Training Prec@5 0.000 (0.000)	
2022-07-07 21:39:11,604: ============================================================
2022-07-07 21:40:26,991: time cost, forward:0.011747809968703138, backward:0.033952025765396285, data cost:0.6978930686902818 
2022-07-07 21:40:26,991: ============================================================
2022-07-07 21:40:26,991: Epoch 18/36 Batch 5500/7662 eta: 1 day, 5:20:01.753277	Training Loss1 4.1919 (4.3170)	Training Total_Loss 4.1919 (4.3170)	Training Prec@1 96.680 (96.764)	Training Prec@5 0.000 (0.000)	
2022-07-07 21:40:26,991: ============================================================
2022-07-07 21:41:41,800: time cost, forward:0.011749703408479903, backward:0.03397534306208179, data cost:0.6979364433295387 
2022-07-07 21:41:41,800: ============================================================
2022-07-07 21:41:41,800: Epoch 18/36 Batch 5600/7662 eta: 1 day, 5:05:16.639829	Training Loss1 4.6125 (4.3194)	Training Total_Loss 4.6125 (4.3194)	Training Prec@1 95.312 (96.756)	Training Prec@5 0.000 (0.000)	
2022-07-07 21:41:41,800: ============================================================
2022-07-07 21:42:56,242: time cost, forward:0.011753537316430262, backward:0.033979967950331286, data cost:0.697909862414894 
2022-07-07 21:42:56,242: ============================================================
2022-07-07 21:42:56,243: Epoch 18/36 Batch 5700/7662 eta: 1 day, 4:55:29.232307	Training Loss1 4.3718 (4.3218)	Training Total_Loss 4.3718 (4.3218)	Training Prec@1 96.094 (96.745)	Training Prec@5 0.000 (0.000)	
2022-07-07 21:42:56,243: ============================================================
2022-07-07 21:44:10,307: time cost, forward:0.011751249260399995, backward:0.03398947494567355, data cost:0.697862635934984 
2022-07-07 21:44:10,307: ============================================================
2022-07-07 21:44:10,308: Epoch 18/36 Batch 5800/7662 eta: 1 day, 4:45:27.286770	Training Loss1 4.3537 (4.3240)	Training Total_Loss 4.3537 (4.3240)	Training Prec@1 98.047 (96.738)	Training Prec@5 0.000 (0.000)	
2022-07-07 21:44:10,308: ============================================================
2022-07-07 21:45:25,934: time cost, forward:0.011759005718098634, backward:0.033999987670295745, data cost:0.6980446759149733 
2022-07-07 21:45:25,934: ============================================================
2022-07-07 21:45:25,934: Epoch 18/36 Batch 5900/7662 eta: 1 day, 5:20:34.487976	Training Loss1 4.1598 (4.3259)	Training Total_Loss 4.1598 (4.3259)	Training Prec@1 97.070 (96.729)	Training Prec@5 0.000 (0.000)	
2022-07-07 21:45:25,934: ============================================================
2022-07-07 21:46:40,135: time cost, forward:0.011769677901550181, backward:0.0340186059226551, data cost:0.6979781219732326 
2022-07-07 21:46:40,135: ============================================================
2022-07-07 21:46:40,136: Epoch 18/36 Batch 6000/7662 eta: 1 day, 4:46:09.755527	Training Loss1 4.6237 (4.3281)	Training Total_Loss 4.6237 (4.3281)	Training Prec@1 95.898 (96.721)	Training Prec@5 0.000 (0.000)	
2022-07-07 21:46:40,136: ============================================================
2022-07-07 21:47:54,419: time cost, forward:0.01177910637280886, backward:0.034019973751442764, data cost:0.6979431309334898 
2022-07-07 21:47:54,419: ============================================================
2022-07-07 21:47:54,419: Epoch 18/36 Batch 6100/7662 eta: 1 day, 4:46:49.662760	Training Loss1 4.7216 (4.3298)	Training Total_Loss 4.7216 (4.3298)	Training Prec@1 94.922 (96.714)	Training Prec@5 0.000 (0.000)	
2022-07-07 21:47:54,419: ============================================================
2022-07-07 21:49:07,929: time cost, forward:0.011788270919241046, backward:0.034012801379114416, data cost:0.6977882077182795 
2022-07-07 21:49:07,929: ============================================================
2022-07-07 21:49:07,929: Epoch 18/36 Batch 6200/7662 eta: 1 day, 4:27:37.533459	Training Loss1 4.3637 (4.3317)	Training Total_Loss 4.3637 (4.3317)	Training Prec@1 96.484 (96.707)	Training Prec@5 0.000 (0.000)	
2022-07-07 21:49:07,929: ============================================================
2022-07-07 21:50:23,482: time cost, forward:0.011796139974332192, backward:0.034017923162520586, data cost:0.6979561900502066 
2022-07-07 21:50:23,482: ============================================================
2022-07-07 21:50:23,482: Epoch 18/36 Batch 6300/7662 eta: 1 day, 5:13:49.994140	Training Loss1 4.5602 (4.3335)	Training Total_Loss 4.5602 (4.3335)	Training Prec@1 95.703 (96.701)	Training Prec@5 0.000 (0.000)	
2022-07-07 21:50:23,483: ============================================================
2022-07-07 21:51:36,841: time cost, forward:0.011797884960326577, backward:0.03403548122029842, data cost:0.697768116653068 
2022-07-07 21:51:36,842: ============================================================
2022-07-07 21:51:36,842: Epoch 18/36 Batch 6400/7662 eta: 1 day, 4:21:40.696868	Training Loss1 4.3243 (4.3358)	Training Total_Loss 4.3243 (4.3358)	Training Prec@1 97.070 (96.694)	Training Prec@5 0.000 (0.000)	
2022-07-07 21:51:36,842: ============================================================
2022-07-07 21:52:51,099: time cost, forward:0.011805664082456872, backward:0.034032513204217414, data cost:0.6977380033015544 
2022-07-07 21:52:51,099: ============================================================
2022-07-07 21:52:51,099: Epoch 18/36 Batch 6500/7662 eta: 1 day, 4:41:16.743516	Training Loss1 4.5484 (4.3377)	Training Total_Loss 4.5484 (4.3377)	Training Prec@1 96.680 (96.687)	Training Prec@5 0.000 (0.000)	
2022-07-07 21:52:51,099: ============================================================
2022-07-07 21:54:05,189: time cost, forward:0.011809419223550124, backward:0.0340479158021985, data cost:0.6976711891658163 
2022-07-07 21:54:05,189: ============================================================
2022-07-07 21:54:05,189: Epoch 18/36 Batch 6600/7662 eta: 1 day, 4:36:09.272917	Training Loss1 4.6380 (4.3391)	Training Total_Loss 4.6380 (4.3391)	Training Prec@1 96.484 (96.680)	Training Prec@5 0.000 (0.000)	
2022-07-07 21:54:05,189: ============================================================
2022-07-07 21:55:19,226: time cost, forward:0.01180957050212445, backward:0.03406604141739878, data cost:0.6975955420028702 
2022-07-07 21:55:19,226: ============================================================
2022-07-07 21:55:19,226: Epoch 18/36 Batch 6700/7662 eta: 1 day, 4:33:41.867664	Training Loss1 4.4926 (4.3409)	Training Total_Loss 4.4926 (4.3409)	Training Prec@1 97.461 (96.673)	Training Prec@5 0.000 (0.000)	
2022-07-07 21:55:19,226: ============================================================
2022-07-07 21:56:33,992: time cost, forward:0.011809349165258732, backward:0.03405529314112113, data cost:0.6976598805409177 
2022-07-07 21:56:33,992: ============================================================
2022-07-07 21:56:33,993: Epoch 18/36 Batch 6800/7662 eta: 1 day, 4:49:20.189780	Training Loss1 4.4731 (4.3426)	Training Total_Loss 4.4731 (4.3426)	Training Prec@1 96.289 (96.665)	Training Prec@5 0.000 (0.000)	
2022-07-07 21:56:33,993: ============================================================
2022-07-07 21:57:47,995: time cost, forward:0.011814904188760762, backward:0.034047627383374635, data cost:0.6976010592402989 
2022-07-07 21:57:47,996: ============================================================
2022-07-07 21:57:47,996: Epoch 18/36 Batch 6900/7662 eta: 1 day, 4:30:26.972527	Training Loss1 4.3059 (4.3443)	Training Total_Loss 4.3059 (4.3443)	Training Prec@1 98.047 (96.657)	Training Prec@5 0.000 (0.000)	
2022-07-07 21:57:47,996: ============================================================
2022-07-07 21:59:01,909: time cost, forward:0.01181203376431008, backward:0.03405339630318805, data cost:0.6975279444370087 
2022-07-07 21:59:01,909: ============================================================
2022-07-07 21:59:01,910: Epoch 18/36 Batch 7000/7662 eta: 1 day, 4:27:08.887612	Training Loss1 4.3129 (4.3460)	Training Total_Loss 4.3129 (4.3460)	Training Prec@1 95.898 (96.650)	Training Prec@5 0.000 (0.000)	
2022-07-07 21:59:01,910: ============================================================
2022-07-07 22:00:16,788: time cost, forward:0.01181006767427708, backward:0.03405309794805204, data cost:0.697600576974654 
2022-07-07 22:00:16,789: ============================================================
2022-07-07 22:00:16,789: Epoch 18/36 Batch 7100/7662 eta: 1 day, 4:48:12.034035	Training Loss1 4.6488 (4.3476)	Training Total_Loss 4.6488 (4.3476)	Training Prec@1 94.922 (96.644)	Training Prec@5 0.000 (0.000)	
2022-07-07 22:00:16,789: ============================================================
2022-07-07 22:01:32,266: time cost, forward:0.011807093307001257, backward:0.03406226868463202, data cost:0.697741734880526 
2022-07-07 22:01:32,266: ============================================================
2022-07-07 22:01:32,266: Epoch 18/36 Batch 7200/7662 eta: 1 day, 5:00:44.926862	Training Loss1 4.3880 (4.3489)	Training Total_Loss 4.3880 (4.3489)	Training Prec@1 97.656 (96.636)	Training Prec@5 0.000 (0.000)	
2022-07-07 22:01:32,267: ============================================================
2022-07-07 22:02:46,457: time cost, forward:0.011809872117560601, backward:0.03407032147778732, data cost:0.697698170362327 
2022-07-07 22:02:46,457: ============================================================
2022-07-07 22:02:46,458: Epoch 18/36 Batch 7300/7662 eta: 1 day, 4:29:51.077613	Training Loss1 4.4912 (4.3506)	Training Total_Loss 4.4912 (4.3506)	Training Prec@1 96.094 (96.629)	Training Prec@5 0.000 (0.000)	
2022-07-07 22:02:46,458: ============================================================
2022-07-07 22:04:00,258: time cost, forward:0.011815182758934, backward:0.034074741725197255, data cost:0.6976058801810054 
2022-07-07 22:04:00,259: ============================================================
2022-07-07 22:04:00,259: Epoch 18/36 Batch 7400/7662 eta: 1 day, 4:19:37.783089	Training Loss1 4.6852 (4.3520)	Training Total_Loss 4.6852 (4.3520)	Training Prec@1 95.703 (96.623)	Training Prec@5 0.000 (0.000)	
2022-07-07 22:04:00,259: ============================================================
2022-07-07 22:05:14,124: time cost, forward:0.011815996261608888, backward:0.03408463755708199, data cost:0.697516554752212 
2022-07-07 22:05:14,125: ============================================================
2022-07-07 22:05:14,125: Epoch 18/36 Batch 7500/7662 eta: 1 day, 4:19:53.176614	Training Loss1 4.8174 (4.3537)	Training Total_Loss 4.8174 (4.3537)	Training Prec@1 96.289 (96.617)	Training Prec@5 0.000 (0.000)	
2022-07-07 22:05:14,125: ============================================================
2022-07-07 22:06:28,235: time cost, forward:0.011818307122834059, backward:0.034086376040338574, data cost:0.6974791092125268 
2022-07-07 22:06:28,235: ============================================================
2022-07-07 22:06:28,236: Epoch 18/36 Batch 7600/7662 eta: 1 day, 4:24:17.496372	Training Loss1 4.4325 (4.3552)	Training Total_Loss 4.4325 (4.3552)	Training Prec@1 97.070 (96.612)	Training Prec@5 0.000 (0.000)	
2022-07-07 22:06:28,236: ============================================================
2022-07-07 22:07:17,631: Epoch 18/36 Batch 7663/7662 eta: 1 day, 4:23:30.806497	Training Loss1 4.3047 (4.3560)	Training Total_Loss 4.3047 (4.3560)	Training Prec@1 96.289 (96.608)	Training Prec@5 0.000 (0.000)	
2022-07-07 22:07:17,632: ============================================================
2022-07-07 22:08:54,066: time cost, forward:0.010888581324105312, backward:0.03286986399178553, data cost:0.9230500062306722 
2022-07-07 22:08:54,066: ============================================================
2022-07-07 22:08:54,066: Epoch 19/36 Batch 100/7662 eta: 1 day, 12:52:31.016465	Training Loss1 3.9357 (3.8972)	Training Total_Loss 3.9357 (3.8972)	Training Prec@1 98.047 (97.719)	Training Prec@5 0.000 (0.000)	
2022-07-07 22:08:54,066: ============================================================
2022-07-07 22:10:09,545: time cost, forward:0.010902929545646936, backward:0.032843319015886316, data cost:0.8158247422932381 
2022-07-07 22:10:09,545: ============================================================
2022-07-07 22:10:09,545: Epoch 19/36 Batch 200/7662 eta: 1 day, 4:52:27.462494	Training Loss1 3.8310 (3.9059)	Training Total_Loss 3.8310 (3.9059)	Training Prec@1 97.852 (97.699)	Training Prec@5 0.000 (0.000)	
2022-07-07 22:10:09,545: ============================================================
2022-07-07 22:11:25,281: time cost, forward:0.010840601745656502, backward:0.033317570702288066, data cost:0.7812010189362593 
2022-07-07 22:11:25,281: ============================================================
2022-07-07 22:11:25,281: Epoch 19/36 Batch 300/7662 eta: 1 day, 4:57:05.558707	Training Loss1 3.7071 (3.9157)	Training Total_Loss 3.7071 (3.9157)	Training Prec@1 98.242 (97.695)	Training Prec@5 0.000 (0.000)	
2022-07-07 22:11:25,281: ============================================================
2022-07-07 22:12:40,740: time cost, forward:0.010746695344011886, backward:0.03357266602958354, data cost:0.7631714732425853 
2022-07-07 22:12:40,741: ============================================================
2022-07-07 22:12:40,741: Epoch 19/36 Batch 400/7662 eta: 1 day, 4:49:29.817109	Training Loss1 4.4052 (3.9355)	Training Total_Loss 4.4052 (3.9355)	Training Prec@1 96.289 (97.659)	Training Prec@5 0.000 (0.000)	
2022-07-07 22:12:40,741: ============================================================
2022-07-07 22:13:52,715: time cost, forward:0.010869490598628899, backward:0.033831374678678645, data cost:0.74510586476756 
2022-07-07 22:13:52,715: ============================================================
2022-07-07 22:13:52,715: Epoch 19/36 Batch 500/7662 eta: 1 day, 3:28:25.400402	Training Loss1 3.9176 (3.9628)	Training Total_Loss 3.9176 (3.9628)	Training Prec@1 98.242 (97.603)	Training Prec@5 0.000 (0.000)	
2022-07-07 22:13:52,715: ============================================================
2022-07-07 22:15:06,841: time cost, forward:0.010887322322355088, backward:0.03401027856167648, data cost:0.7367027327293943 
2022-07-07 22:15:06,841: ============================================================
2022-07-07 22:15:06,841: Epoch 19/36 Batch 600/7662 eta: 1 day, 4:16:27.686079	Training Loss1 4.1170 (3.9816)	Training Total_Loss 4.1170 (3.9816)	Training Prec@1 98.242 (97.564)	Training Prec@5 0.000 (0.000)	
2022-07-07 22:15:06,842: ============================================================
2022-07-07 22:16:19,717: time cost, forward:0.010993169271553705, backward:0.03419409255271988, data cost:0.7288514418322299 
2022-07-07 22:16:19,718: ============================================================
2022-07-07 22:16:19,718: Epoch 19/36 Batch 700/7662 eta: 1 day, 3:46:38.721449	Training Loss1 3.9444 (3.9948)	Training Total_Loss 3.9444 (3.9948)	Training Prec@1 97.656 (97.556)	Training Prec@5 0.000 (0.000)	
2022-07-07 22:16:19,718: ============================================================
2022-07-07 22:17:33,564: time cost, forward:0.01106838171413455, backward:0.03422410228523951, data cost:0.7237375361450921 
2022-07-07 22:17:33,564: ============================================================
2022-07-07 22:17:33,564: Epoch 19/36 Batch 800/7662 eta: 1 day, 4:07:35.867630	Training Loss1 3.8198 (4.0080)	Training Total_Loss 3.8198 (4.0080)	Training Prec@1 97.852 (97.533)	Training Prec@5 0.000 (0.000)	
2022-07-07 22:17:33,564: ============================================================
2022-07-07 22:18:46,294: time cost, forward:0.011159756027153788, backward:0.03416361904250369, data cost:0.7192589875986102 
2022-07-07 22:18:46,295: ============================================================
2022-07-07 22:18:46,295: Epoch 19/36 Batch 900/7662 eta: 1 day, 3:40:53.394494	Training Loss1 4.1404 (4.0226)	Training Total_Loss 4.1404 (4.0226)	Training Prec@1 97.266 (97.502)	Training Prec@5 0.000 (0.000)	
2022-07-07 22:18:46,295: ============================================================
2022-07-07 22:19:59,638: time cost, forward:0.011204809994549604, backward:0.034203548927803536, data cost:0.71611571025562 
2022-07-07 22:19:59,638: ============================================================
2022-07-07 22:19:59,638: Epoch 19/36 Batch 1000/7662 eta: 1 day, 3:53:39.797448	Training Loss1 4.0016 (4.0353)	Training Total_Loss 4.0016 (4.0353)	Training Prec@1 97.461 (97.472)	Training Prec@5 0.000 (0.000)	
2022-07-07 22:19:59,639: ============================================================
2022-07-07 22:21:13,215: time cost, forward:0.011261005852849403, backward:0.03424556522178476, data cost:0.71342821116877 
2022-07-07 22:21:13,215: ============================================================
2022-07-07 22:21:13,215: Epoch 19/36 Batch 1100/7662 eta: 1 day, 3:57:45.585283	Training Loss1 4.1119 (4.0470)	Training Total_Loss 4.1119 (4.0470)	Training Prec@1 96.289 (97.453)	Training Prec@5 0.000 (0.000)	
2022-07-07 22:21:13,215: ============================================================
2022-07-07 22:22:27,371: time cost, forward:0.011311786586389231, backward:0.034183287640429216, data cost:0.7121064933366433 
2022-07-07 22:22:27,371: ============================================================
2022-07-07 22:22:27,372: Epoch 19/36 Batch 1200/7662 eta: 1 day, 4:09:44.297448	Training Loss1 4.1498 (4.0551)	Training Total_Loss 4.1498 (4.0551)	Training Prec@1 97.656 (97.440)	Training Prec@5 0.000 (0.000)	
2022-07-07 22:22:27,372: ============================================================
2022-07-07 22:23:41,630: time cost, forward:0.011374528817344942, backward:0.03414312044045299, data cost:0.7108644655431757 
2022-07-07 22:23:41,631: ============================================================
2022-07-07 22:23:41,631: Epoch 19/36 Batch 1300/7662 eta: 1 day, 4:10:50.828198	Training Loss1 4.1736 (4.0651)	Training Total_Loss 4.1736 (4.0651)	Training Prec@1 97.266 (97.417)	Training Prec@5 0.000 (0.000)	
2022-07-07 22:23:41,631: ============================================================
2022-07-07 22:24:55,600: time cost, forward:0.011384150230347726, backward:0.03414899643358799, data cost:0.7096049529982943 
2022-07-07 22:24:55,600: ============================================================
2022-07-07 22:24:55,600: Epoch 19/36 Batch 1400/7662 eta: 1 day, 4:03:01.065761	Training Loss1 4.1998 (4.0741)	Training Total_Loss 4.1998 (4.0741)	Training Prec@1 96.875 (97.393)	Training Prec@5 0.000 (0.000)	
2022-07-07 22:24:55,600: ============================================================
2022-07-07 22:26:09,212: time cost, forward:0.011392068194897673, backward:0.034148962677439665, data cost:0.7083259454323818 
2022-07-07 22:26:09,212: ============================================================
2022-07-07 22:26:09,213: Epoch 19/36 Batch 1500/7662 eta: 1 day, 3:53:39.425782	Training Loss1 4.3490 (4.0824)	Training Total_Loss 4.3490 (4.0824)	Training Prec@1 96.680 (97.372)	Training Prec@5 0.000 (0.000)	
2022-07-07 22:26:09,213: ============================================================
2022-07-07 22:27:23,652: time cost, forward:0.01144229269832876, backward:0.03416166430790026, data cost:0.7076584007532765 
2022-07-07 22:27:23,653: ============================================================
2022-07-07 22:27:23,653: Epoch 19/36 Batch 1600/7662 eta: 1 day, 4:11:15.115890	Training Loss1 4.3440 (4.0912)	Training Total_Loss 4.3440 (4.0912)	Training Prec@1 96.875 (97.351)	Training Prec@5 0.000 (0.000)	
2022-07-07 22:27:23,653: ============================================================
2022-07-07 22:28:39,526: time cost, forward:0.011482874037870034, backward:0.03414717149987089, data cost:0.7078726913312943 
2022-07-07 22:28:39,527: ============================================================
2022-07-07 22:28:39,527: Epoch 19/36 Batch 1700/7662 eta: 1 day, 4:42:32.983671	Training Loss1 4.2668 (4.1010)	Training Total_Loss 4.2668 (4.1010)	Training Prec@1 95.898 (97.328)	Training Prec@5 0.000 (0.000)	
2022-07-07 22:28:39,527: ============================================================
2022-07-07 22:29:53,392: time cost, forward:0.011527568383505769, backward:0.03415015301749466, data cost:0.7069845102839234 
2022-07-07 22:29:53,392: ============================================================
2022-07-07 22:29:53,392: Epoch 19/36 Batch 1800/7662 eta: 1 day, 3:55:43.143346	Training Loss1 4.3489 (4.1104)	Training Total_Loss 4.3489 (4.1104)	Training Prec@1 96.484 (97.304)	Training Prec@5 0.000 (0.000)	
2022-07-07 22:29:53,392: ============================================================
2022-07-07 22:31:06,846: time cost, forward:0.011559409552840825, backward:0.0341363932472458, data cost:0.7059868011052763 
2022-07-07 22:31:06,846: ============================================================
2022-07-07 22:31:06,846: Epoch 19/36 Batch 1900/7662 eta: 1 day, 3:45:10.231359	Training Loss1 3.9814 (4.1181)	Training Total_Loss 3.9814 (4.1181)	Training Prec@1 97.070 (97.287)	Training Prec@5 0.000 (0.000)	
2022-07-07 22:31:06,846: ============================================================
2022-07-07 22:32:21,258: time cost, forward:0.011583071461076913, backward:0.034125624447241015, data cost:0.7055219058217616 
2022-07-07 22:32:21,259: ============================================================
2022-07-07 22:32:21,259: Epoch 19/36 Batch 2000/7662 eta: 1 day, 4:05:39.431926	Training Loss1 4.0679 (4.1258)	Training Total_Loss 4.0679 (4.1258)	Training Prec@1 96.289 (97.269)	Training Prec@5 0.000 (0.000)	
2022-07-07 22:32:21,259: ============================================================
2022-07-07 22:33:35,262: time cost, forward:0.011617086000701483, backward:0.03409851773004409, data cost:0.7049794119843532 
2022-07-07 22:33:35,263: ============================================================
2022-07-07 22:33:35,263: Epoch 19/36 Batch 2100/7662 eta: 1 day, 3:55:10.012934	Training Loss1 4.1964 (4.1337)	Training Total_Loss 4.1964 (4.1337)	Training Prec@1 96.680 (97.248)	Training Prec@5 0.000 (0.000)	
2022-07-07 22:33:35,263: ============================================================
2022-07-07 22:34:49,702: time cost, forward:0.011631812004134458, backward:0.03411913265039185, data cost:0.7046377422485421 
2022-07-07 22:34:49,702: ============================================================
2022-07-07 22:34:49,702: Epoch 19/36 Batch 2200/7662 eta: 1 day, 4:03:47.010718	Training Loss1 4.3530 (4.1402)	Training Total_Loss 4.3530 (4.1402)	Training Prec@1 98.047 (97.229)	Training Prec@5 0.000 (0.000)	
2022-07-07 22:34:49,703: ============================================================
2022-07-07 22:36:03,899: time cost, forward:0.011632813739486237, backward:0.034139267409973015, data cost:0.7042025693243822 
2022-07-07 22:36:03,899: ============================================================
2022-07-07 22:36:03,899: Epoch 19/36 Batch 2300/7662 eta: 1 day, 3:57:03.714809	Training Loss1 4.4531 (4.1478)	Training Total_Loss 4.4531 (4.1478)	Training Prec@1 96.680 (97.208)	Training Prec@5 0.000 (0.000)	
2022-07-07 22:36:03,900: ============================================================
2022-07-07 22:37:18,864: time cost, forward:0.011677055271430132, backward:0.03415869752185054, data cost:0.7040098353493656 
2022-07-07 22:37:18,864: ============================================================
2022-07-07 22:37:18,864: Epoch 19/36 Batch 2400/7662 eta: 1 day, 4:13:10.267884	Training Loss1 4.5190 (4.1552)	Training Total_Loss 4.5190 (4.1552)	Training Prec@1 96.875 (97.192)	Training Prec@5 0.000 (0.000)	
2022-07-07 22:37:18,864: ============================================================
2022-07-07 22:38:31,808: time cost, forward:0.01169294641226852, backward:0.034182301899489044, data cost:0.7032450396998399 
2022-07-07 22:38:31,809: ============================================================
2022-07-07 22:38:31,809: Epoch 19/36 Batch 2500/7662 eta: 1 day, 3:26:19.185723	Training Loss1 4.2367 (4.1623)	Training Total_Loss 4.2367 (4.1623)	Training Prec@1 97.266 (97.172)	Training Prec@5 0.000 (0.000)	
2022-07-07 22:38:31,809: ============================================================
2022-07-07 22:39:45,824: time cost, forward:0.0116800437206578, backward:0.034164742443734936, data cost:0.7028147100989477 
2022-07-07 22:39:45,825: ============================================================
2022-07-07 22:39:45,825: Epoch 19/36 Batch 2600/7662 eta: 1 day, 3:49:16.253670	Training Loss1 4.2681 (4.1683)	Training Total_Loss 4.2681 (4.1683)	Training Prec@1 96.875 (97.156)	Training Prec@5 0.000 (0.000)	
2022-07-07 22:39:45,825: ============================================================
2022-07-07 22:40:58,555: time cost, forward:0.011699955036747053, backward:0.03414662938155082, data cost:0.7020660452862146 
2022-07-07 22:40:58,555: ============================================================
2022-07-07 22:40:58,555: Epoch 19/36 Batch 2700/7662 eta: 1 day, 3:19:03.833168	Training Loss1 4.2730 (4.1746)	Training Total_Loss 4.2730 (4.1746)	Training Prec@1 96.680 (97.137)	Training Prec@5 0.000 (0.000)	
2022-07-07 22:40:58,555: ============================================================
2022-07-07 22:42:12,295: time cost, forward:0.011723397330924331, backward:0.034133248177542354, data cost:0.7016664575193132 
2022-07-07 22:42:12,295: ============================================================
2022-07-07 22:42:12,295: Epoch 19/36 Batch 2800/7662 eta: 1 day, 3:40:35.313182	Training Loss1 3.9995 (4.1798)	Training Total_Loss 3.9995 (4.1798)	Training Prec@1 98.438 (97.121)	Training Prec@5 0.000 (0.000)	
2022-07-07 22:42:12,295: ============================================================
2022-07-07 22:43:27,592: time cost, forward:0.01174238148373791, backward:0.03411032578664716, data cost:0.701771525853089 
2022-07-07 22:43:27,592: ============================================================
2022-07-07 22:43:27,593: Epoch 19/36 Batch 2900/7662 eta: 1 day, 4:14:24.182717	Training Loss1 4.3052 (4.1843)	Training Total_Loss 4.3052 (4.1843)	Training Prec@1 96.484 (97.111)	Training Prec@5 0.000 (0.000)	
2022-07-07 22:43:27,593: ============================================================
2022-07-07 22:44:41,131: time cost, forward:0.011751831511967816, backward:0.03412017181500788, data cost:0.7013847704687369 
2022-07-07 22:44:41,131: ============================================================
2022-07-07 22:44:41,131: Epoch 19/36 Batch 3000/7662 eta: 1 day, 3:33:36.340868	Training Loss1 4.3355 (4.1894)	Training Total_Loss 4.3355 (4.1894)	Training Prec@1 95.898 (97.096)	Training Prec@5 0.000 (0.000)	
2022-07-07 22:44:41,131: ============================================================
2022-07-07 22:45:54,846: time cost, forward:0.011749865663324722, backward:0.034110231759587425, data cost:0.7010639574728539 
2022-07-07 22:45:54,846: ============================================================
2022-07-07 22:45:54,847: Epoch 19/36 Batch 3100/7662 eta: 1 day, 3:36:20.769613	Training Loss1 4.4264 (4.1936)	Training Total_Loss 4.4264 (4.1936)	Training Prec@1 96.875 (97.086)	Training Prec@5 0.000 (0.000)	
2022-07-07 22:45:54,847: ============================================================
2022-07-07 22:47:09,287: time cost, forward:0.011761887962648964, backward:0.034105003755813317, data cost:0.7009486865907879 
2022-07-07 22:47:09,287: ============================================================
2022-07-07 22:47:09,287: Epoch 19/36 Batch 3200/7662 eta: 1 day, 3:51:24.221684	Training Loss1 4.1817 (4.1977)	Training Total_Loss 4.1817 (4.1977)	Training Prec@1 96.289 (97.076)	Training Prec@5 0.000 (0.000)	
2022-07-07 22:47:09,287: ============================================================
2022-07-07 22:48:22,827: time cost, forward:0.011773599064975264, backward:0.03413292717738526, data cost:0.7005416978377579 
2022-07-07 22:48:22,827: ============================================================
2022-07-07 22:48:22,828: Epoch 19/36 Batch 3300/7662 eta: 1 day, 3:29:57.659812	Training Loss1 4.4379 (4.2016)	Training Total_Loss 4.4379 (4.2016)	Training Prec@1 96.289 (97.063)	Training Prec@5 0.000 (0.000)	
2022-07-07 22:48:22,828: ============================================================
2022-07-07 22:49:37,337: time cost, forward:0.011760235393913607, backward:0.03415542555121893, data cost:0.7004838176389483 
2022-07-07 22:49:37,337: ============================================================
2022-07-07 22:49:37,337: Epoch 19/36 Batch 3400/7662 eta: 1 day, 3:50:27.981354	Training Loss1 4.2646 (4.2052)	Training Total_Loss 4.2646 (4.2052)	Training Prec@1 96.680 (97.049)	Training Prec@5 0.000 (0.000)	
2022-07-07 22:49:37,337: ============================================================
2022-07-07 22:50:51,312: time cost, forward:0.011776397963461449, backward:0.034140668960597455, data cost:0.7002658506705782 
2022-07-07 22:50:51,312: ============================================================
2022-07-07 22:50:51,313: Epoch 19/36 Batch 3500/7662 eta: 1 day, 3:37:15.539338	Training Loss1 3.9334 (4.2092)	Training Total_Loss 3.9334 (4.2092)	Training Prec@1 98.633 (97.034)	Training Prec@5 0.000 (0.000)	
2022-07-07 22:50:51,313: ============================================================
2022-07-07 22:52:05,007: time cost, forward:0.011755116749684259, backward:0.034150864621538955, data cost:0.7000063404370493 
2022-07-07 22:52:05,007: ============================================================
2022-07-07 22:52:05,007: Epoch 19/36 Batch 3600/7662 eta: 1 day, 3:29:44.213984	Training Loss1 4.1727 (4.2143)	Training Total_Loss 4.1727 (4.2143)	Training Prec@1 96.289 (97.020)	Training Prec@5 0.000 (0.000)	
2022-07-07 22:52:05,007: ============================================================
2022-07-07 22:53:18,931: time cost, forward:0.011724043936625014, backward:0.0341636218003693, data cost:0.6998018980606339 
2022-07-07 22:53:18,931: ============================================================
2022-07-07 22:53:18,931: Epoch 19/36 Batch 3700/7662 eta: 1 day, 3:33:39.067591	Training Loss1 4.2760 (4.2177)	Training Total_Loss 4.2760 (4.2177)	Training Prec@1 97.070 (97.007)	Training Prec@5 0.000 (0.000)	
2022-07-07 22:53:18,932: ============================================================
2022-07-07 22:54:33,003: time cost, forward:0.011712032106243393, backward:0.03417796911644791, data cost:0.6996780736536125 
2022-07-07 22:54:33,003: ============================================================
2022-07-07 22:54:33,004: Epoch 19/36 Batch 3800/7662 eta: 1 day, 3:35:43.362352	Training Loss1 4.4894 (4.2217)	Training Total_Loss 4.4894 (4.2217)	Training Prec@1 95.898 (96.996)	Training Prec@5 0.000 (0.000)	
2022-07-07 22:54:33,004: ============================================================
2022-07-07 22:55:46,200: time cost, forward:0.01171807504122182, backward:0.03417500932267398, data cost:0.6993042222962498 
2022-07-07 22:55:46,201: ============================================================
2022-07-07 22:55:46,201: Epoch 19/36 Batch 3900/7662 eta: 1 day, 3:14:56.992274	Training Loss1 3.9802 (4.2247)	Training Total_Loss 3.9802 (4.2247)	Training Prec@1 97.656 (96.987)	Training Prec@5 0.000 (0.000)	
2022-07-07 22:55:46,201: ============================================================
2022-07-07 22:56:59,893: time cost, forward:0.011730784563816736, backward:0.03418476839726137, data cost:0.6990683948615098 
2022-07-07 22:56:59,893: ============================================================
2022-07-07 22:56:59,894: Epoch 19/36 Batch 4000/7662 eta: 1 day, 3:24:46.888507	Training Loss1 4.5036 (4.2288)	Training Total_Loss 4.5036 (4.2288)	Training Prec@1 95.703 (96.974)	Training Prec@5 0.000 (0.000)	
2022-07-07 22:56:59,894: ============================================================
2022-07-07 22:58:13,652: time cost, forward:0.011710023030795014, backward:0.03418667364713767, data cost:0.6988904039346174 
2022-07-07 22:58:13,652: ============================================================
2022-07-07 22:58:13,652: Epoch 19/36 Batch 4100/7662 eta: 1 day, 3:25:01.566814	Training Loss1 4.4217 (4.2330)	Training Total_Loss 4.4217 (4.2330)	Training Prec@1 96.680 (96.962)	Training Prec@5 0.000 (0.000)	
2022-07-07 22:58:13,652: ============================================================
2022-07-07 22:59:27,150: time cost, forward:0.011693860837805126, backward:0.034203253578191484, data cost:0.6986430440240884 
2022-07-07 22:59:27,151: ============================================================
2022-07-07 22:59:27,151: Epoch 19/36 Batch 4200/7662 eta: 1 day, 3:18:00.217656	Training Loss1 4.5326 (4.2374)	Training Total_Loss 4.5326 (4.2374)	Training Prec@1 96.289 (96.950)	Training Prec@5 0.000 (0.000)	
2022-07-07 22:59:27,151: ============================================================
2022-07-07 23:00:40,610: time cost, forward:0.011658370536436839, backward:0.03422699514780801, data cost:0.6984048634524899 
2022-07-07 23:00:40,610: ============================================================
2022-07-07 23:00:40,610: Epoch 19/36 Batch 4300/7662 eta: 1 day, 3:15:53.833552	Training Loss1 4.5273 (4.2408)	Training Total_Loss 4.5273 (4.2408)	Training Prec@1 97.070 (96.938)	Training Prec@5 0.000 (0.000)	
2022-07-07 23:00:40,610: ============================================================
2022-07-07 23:01:54,630: time cost, forward:0.011642896091160272, backward:0.03423224072153933, data cost:0.6983146487541918 
2022-07-07 23:01:54,630: ============================================================
2022-07-07 23:01:54,630: Epoch 19/36 Batch 4400/7662 eta: 1 day, 3:27:09.856367	Training Loss1 4.4296 (4.2442)	Training Total_Loss 4.4296 (4.2442)	Training Prec@1 97.266 (96.927)	Training Prec@5 0.000 (0.000)	
2022-07-07 23:01:54,631: ============================================================
2022-07-07 23:03:08,868: time cost, forward:0.011637770088282286, backward:0.03422883463637197, data cost:0.6982760992705173 
2022-07-07 23:03:08,868: ============================================================
2022-07-07 23:03:08,868: Epoch 19/36 Batch 4500/7662 eta: 1 day, 3:30:46.030917	Training Loss1 4.3212 (4.2478)	Training Total_Loss 4.3212 (4.2478)	Training Prec@1 95.898 (96.918)	Training Prec@5 0.000 (0.000)	
2022-07-07 23:03:08,868: ============================================================
2022-07-07 23:04:23,853: time cost, forward:0.011617376846343338, backward:0.03423310705153002, data cost:0.698402300998682 
2022-07-07 23:04:23,853: ============================================================
2022-07-07 23:04:23,853: Epoch 19/36 Batch 4600/7662 eta: 1 day, 3:46:07.245971	Training Loss1 4.4429 (4.2507)	Training Total_Loss 4.4429 (4.2507)	Training Prec@1 96.094 (96.906)	Training Prec@5 0.000 (0.000)	
2022-07-07 23:04:23,853: ============================================================
2022-07-07 23:05:38,534: time cost, forward:0.011605908196386973, backward:0.034243491843143, data cost:0.6984362133920738 
2022-07-07 23:05:38,534: ============================================================
2022-07-07 23:05:38,534: Epoch 19/36 Batch 4700/7662 eta: 1 day, 3:38:08.187321	Training Loss1 4.4867 (4.2541)	Training Total_Loss 4.4867 (4.2541)	Training Prec@1 96.875 (96.897)	Training Prec@5 0.000 (0.000)	
2022-07-07 23:05:38,534: ============================================================
2022-07-07 23:06:53,334: time cost, forward:0.011586013697763114, backward:0.034265912207595305, data cost:0.6984531772114332 
2022-07-07 23:06:53,334: ============================================================
2022-07-07 23:06:53,335: Epoch 19/36 Batch 4800/7662 eta: 1 day, 3:39:31.830456	Training Loss1 4.1243 (4.2571)	Training Total_Loss 4.1243 (4.2571)	Training Prec@1 98.242 (96.887)	Training Prec@5 0.000 (0.000)	
2022-07-07 23:06:53,335: ============================================================
2022-07-07 23:08:07,065: time cost, forward:0.01156937635584884, backward:0.03427888087093356, data cost:0.6983288100457332 
2022-07-07 23:08:07,065: ============================================================
2022-07-07 23:08:07,065: Epoch 19/36 Batch 4900/7662 eta: 1 day, 3:14:34.315450	Training Loss1 4.1805 (4.2593)	Training Total_Loss 4.1805 (4.2593)	Training Prec@1 96.875 (96.880)	Training Prec@5 0.000 (0.000)	
2022-07-07 23:08:07,065: ============================================================
2022-07-07 23:09:21,871: time cost, forward:0.011562671583160015, backward:0.03429256102685381, data cost:0.6983908967367052 
2022-07-07 23:09:21,872: ============================================================
2022-07-07 23:09:21,872: Epoch 19/36 Batch 5000/7662 eta: 1 day, 3:37:10.865476	Training Loss1 4.2861 (4.2619)	Training Total_Loss 4.2861 (4.2619)	Training Prec@1 97.070 (96.869)	Training Prec@5 0.000 (0.000)	
2022-07-07 23:09:21,872: ============================================================
2022-07-07 23:10:36,215: time cost, forward:0.011549500442762239, backward:0.03429862615477223, data cost:0.6983895634735161 
2022-07-07 23:10:36,215: ============================================================
2022-07-07 23:10:36,216: Epoch 19/36 Batch 5100/7662 eta: 1 day, 3:25:40.937041	Training Loss1 4.3826 (4.2642)	Training Total_Loss 4.3826 (4.2642)	Training Prec@1 96.680 (96.862)	Training Prec@5 0.000 (0.000)	
2022-07-07 23:10:36,216: ============================================================
2022-07-07 23:11:50,382: time cost, forward:0.011534076856865198, backward:0.034296324950590755, data cost:0.698339427290203 
2022-07-07 23:11:50,382: ============================================================
2022-07-07 23:11:50,382: Epoch 19/36 Batch 5200/7662 eta: 1 day, 3:20:31.886486	Training Loss1 4.5043 (4.2670)	Training Total_Loss 4.5043 (4.2670)	Training Prec@1 96.289 (96.850)	Training Prec@5 0.000 (0.000)	
2022-07-07 23:11:50,382: ============================================================
2022-07-07 23:13:04,007: time cost, forward:0.011530822482867653, backward:0.03428915145825071, data cost:0.6981603849111896 
2022-07-07 23:13:04,007: ============================================================
2022-07-07 23:13:04,007: Epoch 19/36 Batch 5300/7662 eta: 1 day, 3:07:19.158748	Training Loss1 4.3479 (4.2697)	Training Total_Loss 4.3479 (4.2697)	Training Prec@1 96.289 (96.842)	Training Prec@5 0.000 (0.000)	
2022-07-07 23:13:04,007: ============================================================
2022-07-07 23:14:18,257: time cost, forward:0.011531853017861766, backward:0.03428892052423117, data cost:0.6981542185514719 
2022-07-07 23:14:18,257: ============================================================
2022-07-07 23:14:18,257: Epoch 19/36 Batch 5400/7662 eta: 1 day, 3:19:53.963808	Training Loss1 4.1399 (4.2721)	Training Total_Loss 4.1399 (4.2721)	Training Prec@1 96.484 (96.834)	Training Prec@5 0.000 (0.000)	
2022-07-07 23:14:18,257: ============================================================
2022-07-07 23:15:32,372: time cost, forward:0.01153101854312201, backward:0.034293496970762706, data cost:0.6980899690953054 
2022-07-07 23:15:32,373: ============================================================
2022-07-07 23:15:32,373: Epoch 19/36 Batch 5500/7662 eta: 1 day, 3:15:41.433517	Training Loss1 4.4364 (4.2742)	Training Total_Loss 4.4364 (4.2742)	Training Prec@1 96.094 (96.827)	Training Prec@5 0.000 (0.000)	
2022-07-07 23:15:32,373: ============================================================
2022-07-07 23:16:46,534: time cost, forward:0.011528250872609785, backward:0.034316728531963, data cost:0.6980176490637889 
2022-07-07 23:16:46,534: ============================================================
2022-07-07 23:16:46,534: Epoch 19/36 Batch 5600/7662 eta: 1 day, 3:15:28.315775	Training Loss1 4.2061 (4.2762)	Training Total_Loss 4.2061 (4.2762)	Training Prec@1 97.852 (96.822)	Training Prec@5 0.000 (0.000)	
2022-07-07 23:16:46,534: ============================================================
2022-07-07 23:17:59,879: time cost, forward:0.011523890189903623, backward:0.03433424737458063, data cost:0.6978106476963978 
2022-07-07 23:17:59,879: ============================================================
2022-07-07 23:17:59,880: Epoch 19/36 Batch 5700/7662 eta: 1 day, 2:56:14.846493	Training Loss1 4.6261 (4.2781)	Training Total_Loss 4.6261 (4.2781)	Training Prec@1 96.484 (96.815)	Training Prec@5 0.000 (0.000)	
2022-07-07 23:17:59,880: ============================================================
2022-07-07 23:19:13,505: time cost, forward:0.011528554096738312, backward:0.034347858032618625, data cost:0.697658101573733 
2022-07-07 23:19:13,506: ============================================================
2022-07-07 23:19:13,506: Epoch 19/36 Batch 5800/7662 eta: 1 day, 3:01:13.008519	Training Loss1 4.4750 (4.2803)	Training Total_Loss 4.4750 (4.2803)	Training Prec@1 96.289 (96.805)	Training Prec@5 0.000 (0.000)	
2022-07-07 23:19:13,506: ============================================================
2022-07-07 23:20:27,093: time cost, forward:0.011531801097654533, backward:0.0343388818364807, data cost:0.6975174942427236 
2022-07-07 23:20:27,094: ============================================================
2022-07-07 23:20:27,094: Epoch 19/36 Batch 5900/7662 eta: 1 day, 2:59:08.383298	Training Loss1 4.3941 (4.2829)	Training Total_Loss 4.3941 (4.2829)	Training Prec@1 95.898 (96.798)	Training Prec@5 0.000 (0.000)	
2022-07-07 23:20:27,094: ============================================================
2022-07-07 23:21:41,638: time cost, forward:0.011526819943865054, backward:0.03434018938516374, data cost:0.6975466421314589 
2022-07-07 23:21:41,638: ============================================================
2022-07-07 23:21:41,638: Epoch 19/36 Batch 6000/7662 eta: 1 day, 3:18:56.835504	Training Loss1 4.4037 (4.2847)	Training Total_Loss 4.4037 (4.2847)	Training Prec@1 95.508 (96.791)	Training Prec@5 0.000 (0.000)	
2022-07-07 23:21:41,638: ============================================================
2022-07-07 23:22:56,428: time cost, forward:0.011525291207384372, backward:0.034362235681446564, data cost:0.6975881566687048 
2022-07-07 23:22:56,428: ============================================================
2022-07-07 23:22:56,428: Epoch 19/36 Batch 6100/7662 eta: 1 day, 3:23:05.871080	Training Loss1 4.5450 (4.2866)	Training Total_Loss 4.5450 (4.2866)	Training Prec@1 96.875 (96.783)	Training Prec@5 0.000 (0.000)	
2022-07-07 23:22:56,428: ============================================================
2022-07-07 23:24:11,830: time cost, forward:0.011531261152404992, backward:0.03436507342572865, data cost:0.6977369258780309 
2022-07-07 23:24:11,831: ============================================================
2022-07-07 23:24:11,831: Epoch 19/36 Batch 6200/7662 eta: 1 day, 3:35:18.016957	Training Loss1 4.3520 (4.2889)	Training Total_Loss 4.3520 (4.2889)	Training Prec@1 95.703 (96.774)	Training Prec@5 0.000 (0.000)	
2022-07-07 23:24:11,831: ============================================================
2022-07-07 23:25:26,486: time cost, forward:0.011529923583008143, backward:0.0343608173383079, data cost:0.6977818203759697 
2022-07-07 23:25:26,486: ============================================================
2022-07-07 23:25:26,487: Epoch 19/36 Batch 6300/7662 eta: 1 day, 3:17:39.841784	Training Loss1 4.4475 (4.2909)	Training Total_Loss 4.4475 (4.2909)	Training Prec@1 96.680 (96.769)	Training Prec@5 0.000 (0.000)	
2022-07-07 23:25:26,487: ============================================================
2022-07-07 23:26:40,714: time cost, forward:0.0115281002729046, backward:0.034374246114416966, data cost:0.697747782517791 
2022-07-07 23:26:40,715: ============================================================
2022-07-07 23:26:40,715: Epoch 19/36 Batch 6400/7662 eta: 1 day, 3:07:02.761316	Training Loss1 4.1932 (4.2925)	Training Total_Loss 4.1932 (4.2925)	Training Prec@1 96.680 (96.760)	Training Prec@5 0.000 (0.000)	
2022-07-07 23:26:40,715: ============================================================
2022-07-07 23:27:54,563: time cost, forward:0.011523200981725929, backward:0.034381831237069824, data cost:0.697648303548012 
2022-07-07 23:27:54,564: ============================================================
2022-07-07 23:27:54,564: Epoch 19/36 Batch 6500/7662 eta: 1 day, 2:57:30.121187	Training Loss1 4.4245 (4.2943)	Training Total_Loss 4.4245 (4.2943)	Training Prec@1 96.484 (96.755)	Training Prec@5 0.000 (0.000)	
2022-07-07 23:27:54,564: ============================================================
2022-07-07 23:29:07,962: time cost, forward:0.011514487312063698, backward:0.03438890643292511, data cost:0.6974957503411133 
2022-07-07 23:29:07,962: ============================================================
2022-07-07 23:29:07,963: Epoch 19/36 Batch 6600/7662 eta: 1 day, 2:46:25.050088	Training Loss1 4.2745 (4.2960)	Training Total_Loss 4.2745 (4.2960)	Training Prec@1 96.094 (96.748)	Training Prec@5 0.000 (0.000)	
2022-07-07 23:29:07,963: ============================================================
2022-07-07 23:30:22,282: time cost, forward:0.011522856554463294, backward:0.0343769662218995, data cost:0.697489723872384 
2022-07-07 23:30:22,282: ============================================================
2022-07-07 23:30:22,282: Epoch 19/36 Batch 6700/7662 eta: 1 day, 3:05:19.775728	Training Loss1 4.2616 (4.2974)	Training Total_Loss 4.2616 (4.2974)	Training Prec@1 96.484 (96.742)	Training Prec@5 0.000 (0.000)	
2022-07-07 23:30:22,282: ============================================================
2022-07-07 23:31:36,698: time cost, forward:0.011527728431276371, backward:0.03437847378569888, data cost:0.697489823816734 
2022-07-07 23:31:36,698: ============================================================
2022-07-07 23:31:36,699: Epoch 19/36 Batch 6800/7662 eta: 1 day, 3:06:12.789024	Training Loss1 4.4725 (4.2993)	Training Total_Loss 4.4725 (4.2993)	Training Prec@1 96.484 (96.734)	Training Prec@5 0.000 (0.000)	
2022-07-07 23:31:36,699: ============================================================
2022-07-07 23:32:50,707: time cost, forward:0.01154379358082893, backward:0.03437682883880124, data cost:0.6974177569267559 
2022-07-07 23:32:50,707: ============================================================
2022-07-07 23:32:50,707: Epoch 19/36 Batch 6900/7662 eta: 1 day, 2:56:03.823717	Training Loss1 4.4099 (4.3012)	Training Total_Loss 4.4099 (4.3012)	Training Prec@1 97.070 (96.726)	Training Prec@5 0.000 (0.000)	
2022-07-07 23:32:50,707: ============================================================
2022-07-07 23:34:04,861: time cost, forward:0.011564713986469416, backward:0.034381933800917655, data cost:0.6973560905947074 
2022-07-07 23:34:04,862: ============================================================
2022-07-07 23:34:04,862: Epoch 19/36 Batch 7000/7662 eta: 1 day, 2:58:00.799019	Training Loss1 4.7193 (4.3027)	Training Total_Loss 4.7193 (4.3027)	Training Prec@1 96.289 (96.719)	Training Prec@5 0.000 (0.000)	
2022-07-07 23:34:04,862: ============================================================
2022-07-07 23:35:18,593: time cost, forward:0.011560154088803926, backward:0.03438369786845141, data cost:0.6972617384312371 
2022-07-07 23:35:18,594: ============================================================
2022-07-07 23:35:18,594: Epoch 19/36 Batch 7100/7662 eta: 1 day, 2:47:34.432226	Training Loss1 4.6452 (4.3047)	Training Total_Loss 4.6452 (4.3047)	Training Prec@1 95.312 (96.712)	Training Prec@5 0.000 (0.000)	
2022-07-07 23:35:18,594: ============================================================
2022-07-07 23:36:33,622: time cost, forward:0.011558321685091558, backward:0.03438204386976464, data cost:0.6973614348257758 
2022-07-07 23:36:33,622: ============================================================
2022-07-07 23:36:33,622: Epoch 19/36 Batch 7200/7662 eta: 1 day, 3:14:34.637633	Training Loss1 4.3595 (4.3064)	Training Total_Loss 4.3595 (4.3064)	Training Prec@1 96.484 (96.706)	Training Prec@5 0.000 (0.000)	
2022-07-07 23:36:33,622: ============================================================
2022-07-07 23:37:47,369: time cost, forward:0.011560842752097355, backward:0.034382453339118504, data cost:0.6972375641883048 
2022-07-07 23:37:47,369: ============================================================
2022-07-07 23:37:47,369: Epoch 19/36 Batch 7300/7662 eta: 1 day, 2:45:25.914051	Training Loss1 4.3346 (4.3082)	Training Total_Loss 4.3346 (4.3082)	Training Prec@1 96.680 (96.700)	Training Prec@5 0.000 (0.000)	
2022-07-07 23:37:47,369: ============================================================
2022-07-07 23:39:02,051: time cost, forward:0.011555088873021683, backward:0.03437781398369503, data cost:0.6973181757222544 
2022-07-07 23:39:02,051: ============================================================
2022-07-07 23:39:02,051: Epoch 19/36 Batch 7400/7662 eta: 1 day, 3:04:33.017015	Training Loss1 4.5580 (4.3094)	Training Total_Loss 4.5580 (4.3094)	Training Prec@1 95.508 (96.694)	Training Prec@5 0.000 (0.000)	
2022-07-07 23:39:02,051: ============================================================
2022-07-07 23:40:16,434: time cost, forward:0.01154727448716388, backward:0.034380675315984106, data cost:0.6973190944120715 
2022-07-07 23:40:16,434: ============================================================
2022-07-07 23:40:16,434: Epoch 19/36 Batch 7500/7662 eta: 1 day, 2:56:48.041218	Training Loss1 4.3876 (4.3103)	Training Total_Loss 4.3876 (4.3103)	Training Prec@1 96.875 (96.692)	Training Prec@5 0.000 (0.000)	
2022-07-07 23:40:16,434: ============================================================
2022-07-07 23:41:30,983: time cost, forward:0.011547697674429626, backward:0.03437836792362663, data cost:0.6973382868818867 
2022-07-07 23:41:30,983: ============================================================
2022-07-07 23:41:30,984: Epoch 19/36 Batch 7600/7662 eta: 1 day, 2:59:10.428933	Training Loss1 4.4649 (4.3118)	Training Total_Loss 4.4649 (4.3118)	Training Prec@1 95.703 (96.685)	Training Prec@5 0.000 (0.000)	
2022-07-07 23:41:30,984: ============================================================
2022-07-07 23:42:19,792: Epoch 19/36 Batch 7663/7662 eta: 1 day, 2:58:23.462865	Training Loss1 4.4304 (4.3127)	Training Total_Loss 4.4304 (4.3127)	Training Prec@1 96.289 (96.681)	Training Prec@5 0.000 (0.000)	
2022-07-07 23:42:19,793: ============================================================
2022-07-07 23:43:58,874: time cost, forward:0.012326454875445125, backward:0.03364206323719988, data cost:0.9464510113301904 
2022-07-07 23:43:58,874: ============================================================
2022-07-07 23:43:58,874: Epoch 20/36 Batch 100/7662 eta: 1 day, 11:43:53.614464	Training Loss1 3.7875 (3.6376)	Training Total_Loss 3.7875 (3.6376)	Training Prec@1 97.266 (97.932)	Training Prec@5 0.000 (0.000)	
2022-07-07 23:43:58,875: ============================================================
2022-07-07 23:45:11,978: time cost, forward:0.011895642208693614, backward:0.03353939224128148, data cost:0.8152808256484755 
2022-07-07 23:45:11,979: ============================================================
2022-07-07 23:45:11,979: Epoch 20/36 Batch 200/7662 eta: 1 day, 2:24:35.911501	Training Loss1 3.4040 (3.5979)	Training Total_Loss 3.4040 (3.5979)	Training Prec@1 98.242 (98.021)	Training Prec@5 0.000 (0.000)	
2022-07-07 23:45:11,979: ============================================================
2022-07-07 23:46:24,280: time cost, forward:0.012090686970331199, backward:0.03384837976666199, data cost:0.7685448389786941 
2022-07-07 23:46:24,280: ============================================================
2022-07-07 23:46:24,281: Epoch 20/36 Batch 300/7662 eta: 1 day, 2:05:59.675624	Training Loss1 3.7798 (3.5724)	Training Total_Loss 3.7798 (3.5724)	Training Prec@1 96.680 (98.050)	Training Prec@5 0.000 (0.000)	
2022-07-07 23:46:24,281: ============================================================
2022-07-07 23:47:39,637: time cost, forward:0.012175396869057104, backward:0.03389341849133484, data cost:0.753033791568345 
2022-07-07 23:47:39,638: ============================================================
2022-07-07 23:47:39,638: Epoch 20/36 Batch 400/7662 eta: 1 day, 3:10:55.246120	Training Loss1 3.2882 (3.5570)	Training Total_Loss 3.2882 (3.5570)	Training Prec@1 98.438 (98.059)	Training Prec@5 0.000 (0.000)	
2022-07-07 23:47:39,638: ============================================================
2022-07-07 23:48:53,233: time cost, forward:0.012079075008690477, backward:0.03397126236038361, data cost:0.7402582168579102 
2022-07-07 23:48:53,234: ============================================================
2022-07-07 23:48:53,234: Epoch 20/36 Batch 500/7662 eta: 1 day, 2:31:34.273500	Training Loss1 3.4550 (3.5432)	Training Total_Loss 3.4550 (3.5432)	Training Prec@1 97.070 (98.080)	Training Prec@5 0.000 (0.000)	
2022-07-07 23:48:53,234: ============================================================
2022-07-07 23:50:06,038: time cost, forward:0.01199676596461632, backward:0.0340778346053746, data cost:0.7303786329514594 
2022-07-07 23:50:06,038: ============================================================
2022-07-07 23:50:06,038: Epoch 20/36 Batch 600/7662 eta: 1 day, 2:13:15.055446	Training Loss1 3.3143 (3.5297)	Training Total_Loss 3.3143 (3.5297)	Training Prec@1 98.633 (98.118)	Training Prec@5 0.000 (0.000)	
2022-07-07 23:50:06,039: ============================================================
2022-07-07 23:51:19,214: time cost, forward:0.012013848759074068, backward:0.03415049742560871, data cost:0.7238117072715268 
2022-07-07 23:51:19,215: ============================================================
2022-07-07 23:51:19,215: Epoch 20/36 Batch 700/7662 eta: 1 day, 2:20:03.463481	Training Loss1 3.4299 (3.5175)	Training Total_Loss 3.4299 (3.5175)	Training Prec@1 98.047 (98.127)	Training Prec@5 0.000 (0.000)	
2022-07-07 23:51:19,215: ============================================================
2022-07-07 23:52:33,086: time cost, forward:0.012001341066611127, backward:0.03422168885661902, data cost:0.7197611230484983 
2022-07-07 23:52:33,087: ============================================================
2022-07-07 23:52:33,087: Epoch 20/36 Batch 800/7662 eta: 1 day, 2:33:51.266402	Training Loss1 3.6345 (3.5098)	Training Total_Loss 3.6345 (3.5098)	Training Prec@1 98.047 (98.138)	Training Prec@5 0.000 (0.000)	
2022-07-07 23:52:33,087: ============================================================
2022-07-07 23:53:47,131: time cost, forward:0.01199894991016494, backward:0.03423701483627845, data cost:0.7168256623859003 
2022-07-07 23:53:47,132: ============================================================
2022-07-07 23:53:47,132: Epoch 20/36 Batch 900/7662 eta: 1 day, 2:36:20.658806	Training Loss1 3.5790 (3.5026)	Training Total_Loss 3.5790 (3.5026)	Training Prec@1 98.047 (98.158)	Training Prec@5 0.000 (0.000)	
2022-07-07 23:53:47,132: ============================================================
2022-07-07 23:55:00,412: time cost, forward:0.011942774445206314, backward:0.034305762242268514, data cost:0.7137388755847981 
2022-07-07 23:55:00,412: ============================================================
2022-07-07 23:55:00,413: Epoch 20/36 Batch 1000/7662 eta: 1 day, 2:18:39.132998	Training Loss1 3.4692 (3.4957)	Training Total_Loss 3.4692 (3.4957)	Training Prec@1 98.047 (98.164)	Training Prec@5 0.000 (0.000)	
2022-07-07 23:55:00,413: ============================================================
2022-07-07 23:56:13,567: time cost, forward:0.011861876426120582, backward:0.03432075319993051, data cost:0.7111693244288464 
2022-07-07 23:56:13,568: ============================================================
2022-07-07 23:56:13,569: Epoch 20/36 Batch 1100/7662 eta: 1 day, 2:14:44.329591	Training Loss1 3.3814 (3.4891)	Training Total_Loss 3.3814 (3.4891)	Training Prec@1 98.633 (98.164)	Training Prec@5 0.000 (0.000)	
2022-07-07 23:56:13,569: ============================================================
2022-07-07 23:57:27,473: time cost, forward:0.011885620535563388, backward:0.034249402166307716, data cost:0.7096456892794624 
2022-07-07 23:57:27,474: ============================================================
2022-07-07 23:57:27,474: Epoch 20/36 Batch 1200/7662 eta: 1 day, 2:29:38.529404	Training Loss1 3.2166 (3.4822)	Training Total_Loss 3.2166 (3.4822)	Training Prec@1 99.219 (98.168)	Training Prec@5 0.000 (0.000)	
2022-07-07 23:57:27,474: ============================================================
2022-07-07 23:58:41,200: time cost, forward:0.011876525834856627, backward:0.03421285888431071, data cost:0.7082026146117131 
2022-07-07 23:58:41,200: ============================================================
2022-07-07 23:58:41,200: Epoch 20/36 Batch 1300/7662 eta: 1 day, 2:24:34.066535	Training Loss1 3.2009 (3.4752)	Training Total_Loss 3.2009 (3.4752)	Training Prec@1 98.242 (98.178)	Training Prec@5 0.000 (0.000)	
2022-07-07 23:58:41,200: ============================================================
2022-07-07 23:59:55,211: time cost, forward:0.011841739050570005, backward:0.03423595786350297, data cost:0.7071549031800931 
2022-07-07 23:59:55,211: ============================================================
2022-07-07 23:59:55,212: Epoch 20/36 Batch 1400/7662 eta: 1 day, 2:29:27.343675	Training Loss1 3.4326 (3.4690)	Training Total_Loss 3.4326 (3.4690)	Training Prec@1 98.242 (98.185)	Training Prec@5 0.000 (0.000)	
2022-07-07 23:59:55,212: ============================================================
2022-07-08 00:01:07,846: time cost, forward:0.011800300287675508, backward:0.034211969916386316, data cost:0.705384852490161 
2022-07-08 00:01:07,847: ============================================================
2022-07-08 00:01:07,847: Epoch 20/36 Batch 1500/7662 eta: 1 day, 1:58:41.424470	Training Loss1 3.2914 (3.4622)	Training Total_Loss 3.2914 (3.4622)	Training Prec@1 96.680 (98.196)	Training Prec@5 0.000 (0.000)	
2022-07-08 00:01:07,847: ============================================================
2022-07-08 00:02:20,717: time cost, forward:0.011771612423818658, backward:0.03422207888996251, data cost:0.7039205280969559 
2022-07-08 00:02:20,717: ============================================================
2022-07-08 00:02:20,718: Epoch 20/36 Batch 1600/7662 eta: 1 day, 2:02:31.957210	Training Loss1 3.4201 (3.4583)	Training Total_Loss 3.4201 (3.4583)	Training Prec@1 99.023 (98.199)	Training Prec@5 0.000 (0.000)	
2022-07-08 00:02:20,718: ============================================================
2022-07-08 00:03:34,782: time cost, forward:0.011754413855082852, backward:0.03421133332143046, data cost:0.7034180581113603 
2022-07-08 00:03:34,782: ============================================================
2022-07-08 00:03:34,782: Epoch 20/36 Batch 1700/7662 eta: 1 day, 2:26:53.817320	Training Loss1 3.2315 (3.4533)	Training Total_Loss 3.2315 (3.4533)	Training Prec@1 99.219 (98.201)	Training Prec@5 0.000 (0.000)	
2022-07-08 00:03:34,782: ============================================================
2022-07-08 00:04:47,947: time cost, forward:0.011749099267065823, backward:0.03416664021223237, data cost:0.7024405738126576 
2022-07-08 00:04:47,948: ============================================================
2022-07-08 00:04:47,948: Epoch 20/36 Batch 1800/7662 eta: 1 day, 2:06:24.734354	Training Loss1 3.4299 (3.4494)	Training Total_Loss 3.4299 (3.4494)	Training Prec@1 98.633 (98.203)	Training Prec@5 0.000 (0.000)	
2022-07-08 00:04:47,948: ============================================================
2022-07-08 00:06:01,138: time cost, forward:0.011775777865987882, backward:0.034187307478315644, data cost:0.7015052503381923 
2022-07-08 00:06:01,138: ============================================================
2022-07-08 00:06:01,139: Epoch 20/36 Batch 1900/7662 eta: 1 day, 2:05:44.043321	Training Loss1 3.4798 (3.4452)	Training Total_Loss 3.4798 (3.4452)	Training Prec@1 98.438 (98.209)	Training Prec@5 0.000 (0.000)	
2022-07-08 00:06:01,139: ============================================================
2022-07-08 00:07:15,578: time cost, forward:0.01177089675895687, backward:0.03417438754682364, data cost:0.7013426647596565 
2022-07-08 00:07:15,578: ============================================================
2022-07-08 00:07:15,579: Epoch 20/36 Batch 2000/7662 eta: 1 day, 2:31:12.902206	Training Loss1 3.2354 (3.4405)	Training Total_Loss 3.2354 (3.4405)	Training Prec@1 97.852 (98.216)	Training Prec@5 0.000 (0.000)	
2022-07-08 00:07:15,579: ============================================================
2022-07-08 00:08:29,377: time cost, forward:0.011786126136325438, backward:0.03419378043470524, data cost:0.7008374706230145 
2022-07-08 00:08:29,378: ============================================================
2022-07-08 00:08:29,378: Epoch 20/36 Batch 2100/7662 eta: 1 day, 2:16:17.556106	Training Loss1 3.1205 (3.4346)	Training Total_Loss 3.1205 (3.4346)	Training Prec@1 98.633 (98.219)	Training Prec@5 0.000 (0.000)	
2022-07-08 00:08:29,378: ============================================================
2022-07-08 00:09:43,438: time cost, forward:0.0117715435062771, backward:0.03419581864735602, data cost:0.7004332873104593 
2022-07-08 00:09:43,438: ============================================================
2022-07-08 00:09:43,439: Epoch 20/36 Batch 2200/7662 eta: 1 day, 2:20:38.538913	Training Loss1 3.7330 (3.4310)	Training Total_Loss 3.7330 (3.4310)	Training Prec@1 97.852 (98.224)	Training Prec@5 0.000 (0.000)	
2022-07-08 00:09:43,439: ============================================================
2022-07-08 00:10:57,323: time cost, forward:0.011766811825493825, backward:0.03417660029570192, data cost:0.7002092462459197 
2022-07-08 00:10:57,324: ============================================================
2022-07-08 00:10:57,324: Epoch 20/36 Batch 2300/7662 eta: 1 day, 2:15:39.815622	Training Loss1 3.4590 (3.4266)	Training Total_Loss 3.4590 (3.4266)	Training Prec@1 97.461 (98.230)	Training Prec@5 0.000 (0.000)	
2022-07-08 00:10:57,324: ============================================================
2022-07-08 00:12:12,331: time cost, forward:0.011771639569096885, backward:0.03414191847893038, data cost:0.7003701739929378 
2022-07-08 00:12:12,331: ============================================================
2022-07-08 00:12:12,331: Epoch 20/36 Batch 2400/7662 eta: 1 day, 2:38:20.593956	Training Loss1 3.4739 (3.4237)	Training Total_Loss 3.4739 (3.4237)	Training Prec@1 97.266 (98.230)	Training Prec@5 0.000 (0.000)	
2022-07-08 00:12:12,331: ============================================================
2022-07-08 00:13:25,931: time cost, forward:0.011751488715756079, backward:0.034175567027806, data cost:0.6998669522053816 
2022-07-08 00:13:25,931: ============================================================
2022-07-08 00:13:25,931: Epoch 20/36 Batch 2500/7662 eta: 1 day, 2:07:08.016757	Training Loss1 3.3760 (3.4202)	Training Total_Loss 3.3760 (3.4202)	Training Prec@1 98.633 (98.234)	Training Prec@5 0.000 (0.000)	
2022-07-08 00:13:25,932: ============================================================
2022-07-08 00:14:40,615: time cost, forward:0.011731512411689245, backward:0.03417879620530414, data cost:0.6999560269359076 
2022-07-08 00:14:40,616: ============================================================
2022-07-08 00:14:40,616: Epoch 20/36 Batch 2600/7662 eta: 1 day, 2:28:58.265314	Training Loss1 3.1604 (3.4166)	Training Total_Loss 3.1604 (3.4166)	Training Prec@1 98.633 (98.239)	Training Prec@5 0.000 (0.000)	
2022-07-08 00:14:40,616: ============================================================
2022-07-08 00:15:54,975: time cost, forward:0.01174461695829026, backward:0.034197574988609335, data cost:0.6998240832003367 
2022-07-08 00:15:54,976: ============================================================
2022-07-08 00:15:54,976: Epoch 20/36 Batch 2700/7662 eta: 1 day, 2:20:49.879315	Training Loss1 3.5115 (3.4131)	Training Total_Loss 3.5115 (3.4131)	Training Prec@1 97.266 (98.240)	Training Prec@5 0.000 (0.000)	
2022-07-08 00:15:54,976: ============================================================
2022-07-08 00:17:08,250: time cost, forward:0.011756424564853572, backward:0.03415936195411696, data cost:0.6992994671678833 
2022-07-08 00:17:08,250: ============================================================
2022-07-08 00:17:08,250: Epoch 20/36 Batch 2800/7662 eta: 1 day, 1:56:31.859166	Training Loss1 3.4518 (3.4099)	Training Total_Loss 3.4518 (3.4099)	Training Prec@1 98.828 (98.246)	Training Prec@5 0.000 (0.000)	
2022-07-08 00:17:08,250: ============================================================
2022-07-08 00:18:21,549: time cost, forward:0.011789314168697803, backward:0.03414001626037408, data cost:0.698903247133211 
2022-07-08 00:18:21,549: ============================================================
2022-07-08 00:18:21,549: Epoch 20/36 Batch 2900/7662 eta: 1 day, 1:55:49.963951	Training Loss1 3.3446 (3.4073)	Training Total_Loss 3.3446 (3.4073)	Training Prec@1 98.242 (98.246)	Training Prec@5 0.000 (0.000)	
2022-07-08 00:18:21,549: ============================================================
2022-07-08 00:19:36,292: time cost, forward:0.01179216296802405, backward:0.03414046466251181, data cost:0.6989713357503751 
2022-07-08 00:19:36,292: ============================================================
2022-07-08 00:19:36,292: Epoch 20/36 Batch 3000/7662 eta: 1 day, 2:25:14.042977	Training Loss1 3.3080 (3.4046)	Training Total_Loss 3.3080 (3.4046)	Training Prec@1 98.633 (98.249)	Training Prec@5 0.000 (0.000)	
2022-07-08 00:19:36,292: ============================================================
2022-07-08 00:20:49,673: time cost, forward:0.011794721976369764, backward:0.03413727061138418, data cost:0.6985892671737105 
2022-07-08 00:20:49,673: ============================================================
2022-07-08 00:20:49,674: Epoch 20/36 Batch 3100/7662 eta: 1 day, 1:55:08.337887	Training Loss1 3.2692 (3.4016)	Training Total_Loss 3.2692 (3.4016)	Training Prec@1 99.414 (98.249)	Training Prec@5 0.000 (0.000)	
2022-07-08 00:20:49,674: ============================================================
2022-07-08 00:22:02,722: time cost, forward:0.011797785498120331, backward:0.03413579329061076, data cost:0.6981372810893224 
2022-07-08 00:22:02,723: ============================================================
2022-07-08 00:22:02,723: Epoch 20/36 Batch 3200/7662 eta: 1 day, 1:46:52.848643	Training Loss1 3.6061 (3.3987)	Training Total_Loss 3.6061 (3.3987)	Training Prec@1 98.828 (98.254)	Training Prec@5 0.000 (0.000)	
2022-07-08 00:22:02,723: ============================================================
2022-07-08 00:23:16,745: time cost, forward:0.011808961042674175, backward:0.03412345085190296, data cost:0.6979968091074934 
2022-07-08 00:23:16,745: ============================================================
2022-07-08 00:23:16,745: Epoch 20/36 Batch 3300/7662 eta: 1 day, 2:06:15.277939	Training Loss1 3.4361 (3.3958)	Training Total_Loss 3.4361 (3.3958)	Training Prec@1 98.047 (98.255)	Training Prec@5 0.000 (0.000)	
2022-07-08 00:23:16,746: ============================================================
2022-07-08 00:24:30,326: time cost, forward:0.011823276450753949, backward:0.034117597732588836, data cost:0.6977329758483896 
2022-07-08 00:24:30,326: ============================================================
2022-07-08 00:24:30,326: Epoch 20/36 Batch 3400/7662 eta: 1 day, 1:55:40.764220	Training Loss1 3.4642 (3.3933)	Training Total_Loss 3.4642 (3.3933)	Training Prec@1 98.242 (98.257)	Training Prec@5 0.000 (0.000)	
2022-07-08 00:24:30,326: ============================================================
2022-07-08 00:25:43,759: time cost, forward:0.011806342900906607, backward:0.03410489663426349, data cost:0.6973989454123865 
2022-07-08 00:25:43,760: ============================================================
2022-07-08 00:25:43,760: Epoch 20/36 Batch 3500/7662 eta: 1 day, 1:51:21.192981	Training Loss1 3.3516 (3.3907)	Training Total_Loss 3.3516 (3.3907)	Training Prec@1 98.242 (98.257)	Training Prec@5 0.000 (0.000)	
2022-07-08 00:25:43,760: ============================================================
2022-07-08 00:26:58,301: time cost, forward:0.011802435848705634, backward:0.034096920877802736, data cost:0.6975231412451411 
2022-07-08 00:26:58,302: ============================================================
2022-07-08 00:26:58,302: Epoch 20/36 Batch 3600/7662 eta: 1 day, 2:13:31.076258	Training Loss1 3.0661 (3.3881)	Training Total_Loss 3.0661 (3.3881)	Training Prec@1 99.219 (98.260)	Training Prec@5 0.000 (0.000)	
2022-07-08 00:26:58,302: ============================================================
2022-07-08 00:28:11,762: time cost, forward:0.011795942188437226, backward:0.0340969298265534, data cost:0.6972736587199562 
2022-07-08 00:28:11,762: ============================================================
2022-07-08 00:28:11,763: Epoch 20/36 Batch 3700/7662 eta: 1 day, 1:49:27.962028	Training Loss1 3.1232 (3.3847)	Training Total_Loss 3.1232 (3.3847)	Training Prec@1 98.047 (98.265)	Training Prec@5 0.000 (0.000)	
2022-07-08 00:28:11,763: ============================================================
2022-07-08 00:29:25,994: time cost, forward:0.01181991585432526, backward:0.03406622912514112, data cost:0.6972482311126276 
2022-07-08 00:29:25,994: ============================================================
2022-07-08 00:29:25,995: Epoch 20/36 Batch 3800/7662 eta: 1 day, 2:04:30.053733	Training Loss1 3.1864 (3.3820)	Training Total_Loss 3.1864 (3.3820)	Training Prec@1 98.047 (98.266)	Training Prec@5 0.000 (0.000)	
2022-07-08 00:29:25,995: ============================================================
2022-07-08 00:30:39,930: time cost, forward:0.011817798519110061, backward:0.034067426775932066, data cost:0.6971378489071419 
2022-07-08 00:30:39,930: ============================================================
2022-07-08 00:30:39,931: Epoch 20/36 Batch 3900/7662 eta: 1 day, 1:57:01.757624	Training Loss1 3.2189 (3.3797)	Training Total_Loss 3.2189 (3.3797)	Training Prec@1 97.656 (98.269)	Training Prec@5 0.000 (0.000)	
2022-07-08 00:30:39,931: ============================================================
2022-07-08 00:31:54,682: time cost, forward:0.011816087559659232, backward:0.034054931088309495, data cost:0.6972438585582331 
2022-07-08 00:31:54,683: ============================================================
2022-07-08 00:31:54,683: Epoch 20/36 Batch 4000/7662 eta: 1 day, 2:12:58.606700	Training Loss1 3.3077 (3.3775)	Training Total_Loss 3.3077 (3.3775)	Training Prec@1 99.609 (98.271)	Training Prec@5 0.000 (0.000)	
2022-07-08 00:31:54,683: ============================================================
2022-07-08 00:33:10,234: time cost, forward:0.011811311839993158, backward:0.03406248478867362, data cost:0.6975346305481426 
2022-07-08 00:33:10,234: ============================================================
2022-07-08 00:33:10,235: Epoch 20/36 Batch 4100/7662 eta: 1 day, 2:28:32.383532	Training Loss1 3.1583 (3.3752)	Training Total_Loss 3.1583 (3.3752)	Training Prec@1 98.828 (98.274)	Training Prec@5 0.000 (0.000)	
2022-07-08 00:33:10,235: ============================================================
2022-07-08 00:34:24,435: time cost, forward:0.011818020478348757, backward:0.03405524532293586, data cost:0.6974861274931822 
2022-07-08 00:34:24,435: ============================================================
2022-07-08 00:34:24,436: Epoch 20/36 Batch 4200/7662 eta: 1 day, 1:58:53.898010	Training Loss1 3.1030 (3.3731)	Training Total_Loss 3.1030 (3.3731)	Training Prec@1 99.023 (98.277)	Training Prec@5 0.000 (0.000)	
2022-07-08 00:34:24,436: ============================================================
2022-07-08 00:35:38,699: time cost, forward:0.011814472924334749, backward:0.03405661836949358, data cost:0.697453320373017 
2022-07-08 00:35:38,699: ============================================================
2022-07-08 00:35:38,700: Epoch 20/36 Batch 4300/7662 eta: 1 day, 1:58:59.221724	Training Loss1 3.4691 (3.3713)	Training Total_Loss 3.4691 (3.3713)	Training Prec@1 97.070 (98.278)	Training Prec@5 0.000 (0.000)	
2022-07-08 00:35:38,700: ============================================================
2022-07-08 00:36:52,264: time cost, forward:0.011812946367708221, backward:0.0340545716733384, data cost:0.697274176362808 
2022-07-08 00:36:52,264: ============================================================
2022-07-08 00:36:52,264: Epoch 20/36 Batch 4400/7662 eta: 1 day, 1:43:04.863246	Training Loss1 3.1322 (3.3687)	Training Total_Loss 3.1322 (3.3687)	Training Prec@1 98.438 (98.281)	Training Prec@5 0.000 (0.000)	
2022-07-08 00:36:52,264: ============================================================
2022-07-08 00:38:07,650: time cost, forward:0.011806245855978791, backward:0.03406538637936658, data cost:0.6974963826003353 
2022-07-08 00:38:07,650: ============================================================
2022-07-08 00:38:07,650: Epoch 20/36 Batch 4500/7662 eta: 1 day, 2:20:01.664197	Training Loss1 3.0891 (3.3666)	Training Total_Loss 3.0891 (3.3666)	Training Prec@1 99.219 (98.285)	Training Prec@5 0.000 (0.000)	
2022-07-08 00:38:07,650: ============================================================
2022-07-08 00:39:22,295: time cost, forward:0.011802618647171224, backward:0.034059820550502606, data cost:0.6975588410230895 
2022-07-08 00:39:22,295: ============================================================
2022-07-08 00:39:22,295: Epoch 20/36 Batch 4600/7662 eta: 1 day, 2:03:15.229850	Training Loss1 3.4110 (3.3647)	Training Total_Loss 3.4110 (3.3647)	Training Prec@1 98.242 (98.288)	Training Prec@5 0.000 (0.000)	
2022-07-08 00:39:22,295: ============================================================
2022-07-08 00:40:37,121: time cost, forward:0.011790369033407572, backward:0.034067450444427896, data cost:0.697654323594117 
2022-07-08 00:40:37,121: ============================================================
2022-07-08 00:40:37,121: Epoch 20/36 Batch 4700/7662 eta: 1 day, 2:05:47.344828	Training Loss1 3.2575 (3.3625)	Training Total_Loss 3.2575 (3.3625)	Training Prec@1 98.438 (98.290)	Training Prec@5 0.000 (0.000)	
2022-07-08 00:40:37,121: ============================================================
2022-07-08 00:41:51,393: time cost, forward:0.01177881647830557, backward:0.034065473673368, data cost:0.6976334948320144 
2022-07-08 00:41:51,394: ============================================================
2022-07-08 00:41:51,394: Epoch 20/36 Batch 4800/7662 eta: 1 day, 1:52:58.993246	Training Loss1 3.1067 (3.3606)	Training Total_Loss 3.1067 (3.3606)	Training Prec@1 98.828 (98.289)	Training Prec@5 0.000 (0.000)	
2022-07-08 00:41:51,394: ============================================================
2022-07-08 00:43:06,525: time cost, forward:0.011765841149047678, backward:0.0340770572320518, data cost:0.6977843205085407 
2022-07-08 00:43:06,526: ============================================================
2022-07-08 00:43:06,526: Epoch 20/36 Batch 4900/7662 eta: 1 day, 2:09:41.671340	Training Loss1 3.2423 (3.3586)	Training Total_Loss 3.2423 (3.3586)	Training Prec@1 97.852 (98.291)	Training Prec@5 0.000 (0.000)	
2022-07-08 00:43:06,526: ============================================================
2022-07-08 00:44:20,519: time cost, forward:0.01175340821109168, backward:0.034078462812084515, data cost:0.697708775077159 
2022-07-08 00:44:20,519: ============================================================
2022-07-08 00:44:20,519: Epoch 20/36 Batch 5000/7662 eta: 1 day, 1:44:40.405220	Training Loss1 3.5856 (3.3564)	Training Total_Loss 3.5856 (3.3564)	Training Prec@1 96.484 (98.293)	Training Prec@5 0.000 (0.000)	
2022-07-08 00:44:20,519: ============================================================
2022-07-08 00:45:33,865: time cost, forward:0.011749200807830637, backward:0.034082386909360676, data cost:0.6975015433869378 
2022-07-08 00:45:33,866: ============================================================
2022-07-08 00:45:33,866: Epoch 20/36 Batch 5100/7662 eta: 1 day, 1:29:56.863597	Training Loss1 3.1624 (3.3545)	Training Total_Loss 3.1624 (3.3545)	Training Prec@1 97.852 (98.297)	Training Prec@5 0.000 (0.000)	
2022-07-08 00:45:33,866: ============================================================
2022-07-08 00:46:47,420: time cost, forward:0.011750469759900562, backward:0.03408378953084416, data cost:0.6973391151079698 
2022-07-08 00:46:47,421: ============================================================
2022-07-08 00:46:47,421: Epoch 20/36 Batch 5200/7662 eta: 1 day, 1:33:04.270033	Training Loss1 2.9918 (3.3523)	Training Total_Loss 2.9918 (3.3523)	Training Prec@1 99.219 (98.299)	Training Prec@5 0.000 (0.000)	
2022-07-08 00:46:47,421: ============================================================
2022-07-08 00:48:01,948: time cost, forward:0.011746574154573244, backward:0.034091543534900313, data cost:0.6973504474374973 
2022-07-08 00:48:01,949: ============================================================
2022-07-08 00:48:01,949: Epoch 20/36 Batch 5300/7662 eta: 1 day, 1:52:06.441393	Training Loss1 3.4296 (3.3506)	Training Total_Loss 3.4296 (3.3506)	Training Prec@1 98.047 (98.301)	Training Prec@5 0.000 (0.000)	
2022-07-08 00:48:01,949: ============================================================
2022-07-08 00:49:16,422: time cost, forward:0.011737571069103057, backward:0.03409257034920701, data cost:0.6973795083125977 
2022-07-08 00:49:16,422: ============================================================
2022-07-08 00:49:16,422: Epoch 20/36 Batch 5400/7662 eta: 1 day, 1:49:43.824739	Training Loss1 3.2859 (3.3484)	Training Total_Loss 3.2859 (3.3484)	Training Prec@1 97.461 (98.303)	Training Prec@5 0.000 (0.000)	
2022-07-08 00:49:16,422: ============================================================
2022-07-08 00:50:30,816: time cost, forward:0.011721966721444026, backward:0.034095658022916454, data cost:0.6973978958903366 
2022-07-08 00:50:30,816: ============================================================
2022-07-08 00:50:30,816: Epoch 20/36 Batch 5500/7662 eta: 1 day, 1:46:50.605376	Training Loss1 2.9881 (3.3467)	Training Total_Loss 2.9881 (3.3467)	Training Prec@1 98.438 (98.304)	Training Prec@5 0.000 (0.000)	
2022-07-08 00:50:30,817: ============================================================
2022-07-08 00:51:45,663: time cost, forward:0.011713918989780737, backward:0.03411907263154706, data cost:0.6974566605372564 
2022-07-08 00:51:45,663: ============================================================
2022-07-08 00:51:45,663: Epoch 20/36 Batch 5600/7662 eta: 1 day, 1:55:00.188005	Training Loss1 3.1745 (3.3451)	Training Total_Loss 3.1745 (3.3451)	Training Prec@1 99.219 (98.306)	Training Prec@5 0.000 (0.000)	
2022-07-08 00:51:45,663: ============================================================
2022-07-08 00:53:00,790: time cost, forward:0.011708025514797112, backward:0.034134261042094056, data cost:0.6975756824842816 
2022-07-08 00:53:00,790: ============================================================
2022-07-08 00:53:00,791: Epoch 20/36 Batch 5700/7662 eta: 1 day, 1:59:34.815078	Training Loss1 3.5595 (3.3434)	Training Total_Loss 3.5595 (3.3434)	Training Prec@1 98.438 (98.307)	Training Prec@5 0.000 (0.000)	
2022-07-08 00:53:00,791: ============================================================
2022-07-08 00:54:16,330: time cost, forward:0.011694936017205662, backward:0.03413677647270443, data cost:0.6977740255876499 
2022-07-08 00:54:16,330: ============================================================
2022-07-08 00:54:16,330: Epoch 20/36 Batch 5800/7662 eta: 1 day, 2:06:53.083816	Training Loss1 3.5360 (3.3415)	Training Total_Loss 3.5360 (3.3415)	Training Prec@1 97.852 (98.309)	Training Prec@5 0.000 (0.000)	
2022-07-08 00:54:16,330: ============================================================
2022-07-08 00:55:31,956: time cost, forward:0.011694788387173777, backward:0.03413424352040269, data cost:0.6979937932110981 
2022-07-08 00:55:31,956: ============================================================
2022-07-08 00:55:31,956: Epoch 20/36 Batch 5900/7662 eta: 1 day, 2:07:24.435589	Training Loss1 3.2035 (3.3397)	Training Total_Loss 3.2035 (3.3397)	Training Prec@1 98.242 (98.311)	Training Prec@5 0.000 (0.000)	
2022-07-08 00:55:31,956: ============================================================
2022-07-08 00:56:44,763: time cost, forward:0.011684731138330795, backward:0.034141115515127565, data cost:0.6977280285541645 
2022-07-08 00:56:44,763: ============================================================
2022-07-08 00:56:44,764: Epoch 20/36 Batch 6000/7662 eta: 1 day, 1:07:46.787160	Training Loss1 3.1703 (3.3378)	Training Total_Loss 3.1703 (3.3378)	Training Prec@1 98.438 (98.315)	Training Prec@5 0.000 (0.000)	
2022-07-08 00:56:44,764: ============================================================
2022-07-08 00:57:59,258: time cost, forward:0.011675943642644574, backward:0.03415338819897513, data cost:0.6977399446315737 
2022-07-08 00:57:59,258: ============================================================
2022-07-08 00:57:59,258: Epoch 20/36 Batch 6100/7662 eta: 1 day, 1:41:28.747021	Training Loss1 3.4273 (3.3360)	Training Total_Loss 3.4273 (3.3360)	Training Prec@1 98.438 (98.316)	Training Prec@5 0.000 (0.000)	
2022-07-08 00:57:59,258: ============================================================
2022-07-08 00:59:13,356: time cost, forward:0.01166504901308151, backward:0.03415191267782458, data cost:0.6976988821726573 
2022-07-08 00:59:13,356: ============================================================
2022-07-08 00:59:13,357: Epoch 20/36 Batch 6200/7662 eta: 1 day, 1:32:02.668223	Training Loss1 3.2513 (3.3345)	Training Total_Loss 3.2513 (3.3345)	Training Prec@1 97.461 (98.317)	Training Prec@5 0.000 (0.000)	
2022-07-08 00:59:13,357: ============================================================
2022-07-08 01:00:27,451: time cost, forward:0.011652166000489754, backward:0.03415155335066148, data cost:0.6976601934031771 
2022-07-08 01:00:27,451: ============================================================
2022-07-08 01:00:27,451: Epoch 20/36 Batch 6300/7662 eta: 1 day, 1:30:44.482701	Training Loss1 3.3279 (3.3330)	Training Total_Loss 3.3279 (3.3330)	Training Prec@1 98.242 (98.319)	Training Prec@5 0.000 (0.000)	
2022-07-08 01:00:27,452: ============================================================
2022-07-08 01:01:41,650: time cost, forward:0.011650722759704066, backward:0.03415690181515779, data cost:0.697618850713075 
2022-07-08 01:01:41,650: ============================================================
2022-07-08 01:01:41,651: Epoch 20/36 Batch 6400/7662 eta: 1 day, 1:31:39.369150	Training Loss1 3.4197 (3.3319)	Training Total_Loss 3.4197 (3.3319)	Training Prec@1 97.461 (98.320)	Training Prec@5 0.000 (0.000)	
2022-07-08 01:01:41,651: ============================================================
2022-07-08 01:02:56,219: time cost, forward:0.011630275466292065, backward:0.03415889387076443, data cost:0.6976653518521212 
2022-07-08 01:02:56,219: ============================================================
2022-07-08 01:02:56,219: Epoch 20/36 Batch 6500/7662 eta: 1 day, 1:38:02.669155	Training Loss1 3.3856 (3.3306)	Training Total_Loss 3.3856 (3.3306)	Training Prec@1 98.242 (98.321)	Training Prec@5 0.000 (0.000)	
2022-07-08 01:02:56,220: ============================================================
2022-07-08 01:04:09,967: time cost, forward:0.011613960644750456, backward:0.0341573801703987, data cost:0.6975854939268401 
2022-07-08 01:04:09,967: ============================================================
2022-07-08 01:04:09,968: Epoch 20/36 Batch 6600/7662 eta: 1 day, 1:19:53.154734	Training Loss1 3.3866 (3.3291)	Training Total_Loss 3.3866 (3.3291)	Training Prec@1 98.633 (98.322)	Training Prec@5 0.000 (0.000)	
2022-07-08 01:04:09,968: ============================================================
2022-07-08 01:05:23,613: time cost, forward:0.011609421325879481, backward:0.034157673731404, data cost:0.6974813235234922 
2022-07-08 01:05:23,613: ============================================================
2022-07-08 01:05:23,613: Epoch 20/36 Batch 6700/7662 eta: 1 day, 1:16:33.251558	Training Loss1 3.2481 (3.3278)	Training Total_Loss 3.2481 (3.3278)	Training Prec@1 98.828 (98.325)	Training Prec@5 0.000 (0.000)	
2022-07-08 01:05:23,614: ============================================================
2022-07-08 01:06:38,011: time cost, forward:0.011606882347536712, backward:0.034158007995856825, data cost:0.697450609974413 
2022-07-08 01:06:38,011: ============================================================
2022-07-08 01:06:38,011: Epoch 20/36 Batch 6800/7662 eta: 1 day, 1:30:47.917566	Training Loss1 3.2426 (3.3267)	Training Total_Loss 3.2426 (3.3267)	Training Prec@1 98.242 (98.325)	Training Prec@5 0.000 (0.000)	
2022-07-08 01:06:38,011: ============================================================
2022-07-08 01:07:52,137: time cost, forward:0.011596135219502646, backward:0.034156691666910106, data cost:0.6974463484601398 
2022-07-08 01:07:52,137: ============================================================
2022-07-08 01:07:52,138: Epoch 20/36 Batch 6900/7662 eta: 1 day, 1:23:58.109859	Training Loss1 3.2929 (3.3252)	Training Total_Loss 3.2929 (3.3252)	Training Prec@1 97.461 (98.327)	Training Prec@5 0.000 (0.000)	
2022-07-08 01:07:52,138: ============================================================
2022-07-08 01:09:06,413: time cost, forward:0.011594216403560582, backward:0.0341618267497534, data cost:0.6974379879046311 
2022-07-08 01:09:06,413: ============================================================
2022-07-08 01:09:06,413: Epoch 20/36 Batch 7000/7662 eta: 1 day, 1:25:48.724261	Training Loss1 3.1780 (3.3236)	Training Total_Loss 3.1780 (3.3236)	Training Prec@1 98.633 (98.329)	Training Prec@5 0.000 (0.000)	
2022-07-08 01:09:06,413: ============================================================
2022-07-08 01:10:20,404: time cost, forward:0.011582935741374586, backward:0.0341707860471363, data cost:0.6973864748740233 
2022-07-08 01:10:20,404: ============================================================
2022-07-08 01:10:20,404: Epoch 20/36 Batch 7100/7662 eta: 1 day, 1:18:43.379018	Training Loss1 3.1613 (3.3225)	Training Total_Loss 3.1613 (3.3225)	Training Prec@1 98.438 (98.330)	Training Prec@5 0.000 (0.000)	
2022-07-08 01:10:20,404: ============================================================
2022-07-08 01:11:32,972: time cost, forward:0.011575261094964599, backward:0.03417195381596943, data cost:0.6971409069794651 
2022-07-08 01:11:32,972: ============================================================
2022-07-08 01:11:32,973: Epoch 20/36 Batch 7200/7662 eta: 1 day, 0:48:19.199412	Training Loss1 3.1300 (3.3212)	Training Total_Loss 3.1300 (3.3212)	Training Prec@1 99.023 (98.332)	Training Prec@5 0.000 (0.000)	
2022-07-08 01:11:32,973: ============================================================
2022-07-08 01:12:48,064: time cost, forward:0.011575321315624793, backward:0.034177158348918664, data cost:0.6972418273045667 
2022-07-08 01:12:48,065: ============================================================
2022-07-08 01:12:48,065: Epoch 20/36 Batch 7300/7662 eta: 1 day, 1:38:49.544498	Training Loss1 3.3159 (3.3198)	Training Total_Loss 3.3159 (3.3198)	Training Prec@1 98.438 (98.333)	Training Prec@5 0.000 (0.000)	
2022-07-08 01:12:48,065: ============================================================
2022-07-08 01:14:02,600: time cost, forward:0.011574585190623625, backward:0.03417828441036764, data cost:0.6972656512295883 
2022-07-08 01:14:02,600: ============================================================
2022-07-08 01:14:02,600: Epoch 20/36 Batch 7400/7662 eta: 1 day, 1:26:10.768139	Training Loss1 3.1787 (3.3189)	Training Total_Loss 3.1787 (3.3189)	Training Prec@1 97.852 (98.334)	Training Prec@5 0.000 (0.000)	
2022-07-08 01:14:02,600: ============================================================
2022-07-08 01:15:17,655: time cost, forward:0.011577033952071296, backward:0.03418172618709798, data cost:0.6973517531155745 
2022-07-08 01:15:17,655: ============================================================
2022-07-08 01:15:17,655: Epoch 20/36 Batch 7500/7662 eta: 1 day, 1:35:33.682506	Training Loss1 3.2453 (3.3174)	Training Total_Loss 3.2453 (3.3174)	Training Prec@1 98.633 (98.336)	Training Prec@5 0.000 (0.000)	
2022-07-08 01:15:17,655: ============================================================
2022-07-08 01:16:32,684: time cost, forward:0.011565627479477923, backward:0.03418704292808399, data cost:0.697444299566603 
2022-07-08 01:16:32,684: ============================================================
2022-07-08 01:16:32,684: Epoch 20/36 Batch 7600/7662 eta: 1 day, 1:33:46.985813	Training Loss1 3.2875 (3.3162)	Training Total_Loss 3.2875 (3.3162)	Training Prec@1 98.438 (98.337)	Training Prec@5 0.000 (0.000)	
2022-07-08 01:16:32,685: ============================================================
2022-07-08 01:17:20,653: Epoch 20/36 Batch 7663/7662 eta: 1 day, 1:32:59.717458	Training Loss1 3.3203 (3.3155)	Training Total_Loss 3.3203 (3.3155)	Training Prec@1 97.852 (98.337)	Training Prec@5 0.000 (0.000)	
2022-07-08 01:17:20,654: ============================================================
2022-07-08 01:17:20,794: Save Checkpoint...
2022-07-08 01:17:20,794: ============================================================
2022-07-08 01:17:23,741: Save done!
2022-07-08 01:17:23,741: ============================================================
2022-07-08 01:18:59,592: time cost, forward:0.0113042677291716, backward:0.03229558106624719, data cost:0.9182151808883204 
2022-07-08 01:18:59,592: ============================================================
2022-07-08 01:18:59,592: Epoch 21/36 Batch 100/7662 eta: 1 day, 8:35:47.878652	Training Loss1 2.7986 (3.0432)	Training Total_Loss 2.7986 (3.0432)	Training Prec@1 99.609 (98.826)	Training Prec@5 0.000 (0.000)	
2022-07-08 01:18:59,593: ============================================================
2022-07-08 01:20:12,910: time cost, forward:0.011236973144301218, backward:0.03241674864112432, data cost:0.8029612296789734 
2022-07-08 01:20:12,910: ============================================================
2022-07-08 01:20:12,911: Epoch 21/36 Batch 200/7662 eta: 1 day, 0:55:36.271710	Training Loss1 3.1209 (3.0169)	Training Total_Loss 3.1209 (3.0169)	Training Prec@1 98.828 (98.809)	Training Prec@5 0.000 (0.000)	
2022-07-08 01:20:12,911: ============================================================
2022-07-08 01:21:26,356: time cost, forward:0.011169156103229841, backward:0.03254812138535107, data cost:0.7651160991311472 
2022-07-08 01:21:26,356: ============================================================
2022-07-08 01:21:26,357: Epoch 21/36 Batch 300/7662 eta: 1 day, 0:56:59.415452	Training Loss1 2.8780 (3.0152)	Training Total_Loss 2.8780 (3.0152)	Training Prec@1 97.656 (98.790)	Training Prec@5 0.000 (0.000)	
2022-07-08 01:21:26,357: ============================================================
2022-07-08 01:22:41,461: time cost, forward:0.011033903686026284, backward:0.03284821354954464, data cost:0.7502953970342651 
2022-07-08 01:22:41,462: ============================================================
2022-07-08 01:22:41,462: Epoch 21/36 Batch 400/7662 eta: 1 day, 1:29:33.345461	Training Loss1 3.0913 (3.0250)	Training Total_Loss 3.0913 (3.0250)	Training Prec@1 97.852 (98.774)	Training Prec@5 0.000 (0.000)	
2022-07-08 01:22:41,462: ============================================================
2022-07-08 01:23:54,906: time cost, forward:0.010976375702148928, backward:0.033055951934539245, data cost:0.7380563075652342 
2022-07-08 01:23:54,907: ============================================================
2022-07-08 01:23:54,907: Epoch 21/36 Batch 500/7662 eta: 1 day, 0:54:31.295754	Training Loss1 3.0307 (3.0268)	Training Total_Loss 3.0307 (3.0268)	Training Prec@1 98.047 (98.771)	Training Prec@5 0.000 (0.000)	
2022-07-08 01:23:54,907: ============================================================
2022-07-08 01:25:07,628: time cost, forward:0.011060630737839637, backward:0.03328968208898885, data cost:0.7281368642498137 
2022-07-08 01:25:07,629: ============================================================
2022-07-08 01:25:07,629: Epoch 21/36 Batch 600/7662 eta: 1 day, 0:38:35.490458	Training Loss1 3.1099 (3.0265)	Training Total_Loss 3.1099 (3.0265)	Training Prec@1 98.047 (98.781)	Training Prec@5 0.000 (0.000)	
2022-07-08 01:25:07,629: ============================================================
2022-07-08 01:26:20,923: time cost, forward:0.011274763442927676, backward:0.033386132918372856, data cost:0.7224234108931687 
2022-07-08 01:26:20,924: ============================================================
2022-07-08 01:26:20,924: Epoch 21/36 Batch 700/7662 eta: 1 day, 0:49:01.548550	Training Loss1 3.0788 (3.0309)	Training Total_Loss 3.0788 (3.0309)	Training Prec@1 97.461 (98.777)	Training Prec@5 0.000 (0.000)	
2022-07-08 01:26:20,924: ============================================================
2022-07-08 01:27:33,877: time cost, forward:0.011414458068351126, backward:0.033367626956467035, data cost:0.717494975043477 
2022-07-08 01:27:33,877: ============================================================
2022-07-08 01:27:33,878: Epoch 21/36 Batch 800/7662 eta: 1 day, 0:40:52.633204	Training Loss1 3.0721 (3.0302)	Training Total_Loss 3.0721 (3.0302)	Training Prec@1 98.633 (98.780)	Training Prec@5 0.000 (0.000)	
2022-07-08 01:27:33,878: ============================================================
2022-07-08 01:28:48,027: time cost, forward:0.011525421439606833, backward:0.03351444131938183, data cost:0.7149174841943386 
2022-07-08 01:28:48,027: ============================================================
2022-07-08 01:28:48,027: Epoch 21/36 Batch 900/7662 eta: 1 day, 1:03:54.795006	Training Loss1 3.2113 (3.0312)	Training Total_Loss 3.2113 (3.0312)	Training Prec@1 98.438 (98.779)	Training Prec@5 0.000 (0.000)	
2022-07-08 01:28:48,027: ============================================================
2022-07-08 01:30:01,410: time cost, forward:0.011655295336688007, backward:0.033580925132896566, data cost:0.7119992218456708 
2022-07-08 01:30:01,410: ============================================================
2022-07-08 01:30:01,410: Epoch 21/36 Batch 1000/7662 eta: 1 day, 0:47:08.956339	Training Loss1 2.9954 (3.0305)	Training Total_Loss 2.9954 (3.0305)	Training Prec@1 98.828 (98.779)	Training Prec@5 0.000 (0.000)	
2022-07-08 01:30:01,411: ============================================================
2022-07-08 01:31:15,017: time cost, forward:0.011675602962365467, backward:0.03357910285547064, data cost:0.710029287485777 
2022-07-08 01:31:15,017: ============================================================
2022-07-08 01:31:15,017: Epoch 21/36 Batch 1100/7662 eta: 1 day, 0:50:27.157125	Training Loss1 2.9544 (3.0286)	Training Total_Loss 2.9544 (3.0286)	Training Prec@1 99.609 (98.785)	Training Prec@5 0.000 (0.000)	
2022-07-08 01:31:15,017: ============================================================
2022-07-08 01:32:29,356: time cost, forward:0.011677162164047026, backward:0.0336242849574276, data cost:0.7089339245151142 
2022-07-08 01:32:29,356: ============================================================
2022-07-08 01:32:29,356: Epoch 21/36 Batch 1200/7662 eta: 1 day, 1:04:02.309260	Training Loss1 3.0026 (3.0289)	Training Total_Loss 3.0026 (3.0289)	Training Prec@1 98.633 (98.779)	Training Prec@5 0.000 (0.000)	
2022-07-08 01:32:29,356: ============================================================
2022-07-08 01:33:43,280: time cost, forward:0.01164023466895781, backward:0.0336974204917244, data cost:0.707706478029329 
2022-07-08 01:33:43,280: ============================================================
2022-07-08 01:33:43,281: Epoch 21/36 Batch 1300/7662 eta: 1 day, 0:54:25.094552	Training Loss1 3.0160 (3.0293)	Training Total_Loss 3.0160 (3.0293)	Training Prec@1 98.633 (98.776)	Training Prec@5 0.000 (0.000)	
2022-07-08 01:33:43,281: ============================================================
2022-07-08 01:34:57,146: time cost, forward:0.011653033557152902, backward:0.03371337825183446, data cost:0.7066050109222499 
2022-07-08 01:34:57,147: ============================================================
2022-07-08 01:34:57,147: Epoch 21/36 Batch 1400/7662 eta: 1 day, 0:52:00.710828	Training Loss1 2.8435 (3.0306)	Training Total_Loss 2.8435 (3.0306)	Training Prec@1 99.414 (98.779)	Training Prec@5 0.000 (0.000)	
2022-07-08 01:34:57,147: ============================================================
2022-07-08 01:36:10,302: time cost, forward:0.011630551189959567, backward:0.033747824929092944, data cost:0.7052078829199732 
2022-07-08 01:36:10,303: ============================================================
2022-07-08 01:36:10,303: Epoch 21/36 Batch 1500/7662 eta: 1 day, 0:36:26.846059	Training Loss1 2.9554 (3.0315)	Training Total_Loss 2.9554 (3.0315)	Training Prec@1 98.633 (98.770)	Training Prec@5 0.000 (0.000)	
2022-07-08 01:36:10,303: ============================================================
2022-07-08 01:37:23,539: time cost, forward:0.01165811086610528, backward:0.03376696287206443, data cost:0.7039508928426584 
2022-07-08 01:37:23,540: ============================================================
2022-07-08 01:37:23,540: Epoch 21/36 Batch 1600/7662 eta: 1 day, 0:36:51.672532	Training Loss1 3.1625 (3.0334)	Training Total_Loss 3.1625 (3.0334)	Training Prec@1 97.852 (98.773)	Training Prec@5 0.000 (0.000)	
2022-07-08 01:37:23,540: ============================================================
2022-07-08 01:38:38,264: time cost, forward:0.011702488842538133, backward:0.033735024080057574, data cost:0.7038013100132934 
2022-07-08 01:38:38,265: ============================================================
2022-07-08 01:38:38,265: Epoch 21/36 Batch 1700/7662 eta: 1 day, 1:05:36.965839	Training Loss1 2.9540 (3.0343)	Training Total_Loss 2.9540 (3.0343)	Training Prec@1 99.219 (98.774)	Training Prec@5 0.000 (0.000)	
2022-07-08 01:38:38,265: ============================================================
2022-07-08 01:39:51,660: time cost, forward:0.011704757254676332, backward:0.03375462706450822, data cost:0.7028926716306728 
2022-07-08 01:39:51,660: ============================================================
2022-07-08 01:39:51,660: Epoch 21/36 Batch 1800/7662 eta: 1 day, 0:37:36.585641	Training Loss1 2.9656 (3.0354)	Training Total_Loss 2.9656 (3.0354)	Training Prec@1 97.852 (98.771)	Training Prec@5 0.000 (0.000)	
2022-07-08 01:39:51,660: ============================================================
2022-07-08 01:41:04,537: time cost, forward:0.011664786296119308, backward:0.033756932062246475, data cost:0.7018486204242756 
2022-07-08 01:41:04,537: ============================================================
2022-07-08 01:41:04,538: Epoch 21/36 Batch 1900/7662 eta: 1 day, 0:25:57.949063	Training Loss1 3.1448 (3.0349)	Training Total_Loss 3.1448 (3.0349)	Training Prec@1 97.852 (98.769)	Training Prec@5 0.000 (0.000)	
2022-07-08 01:41:04,538: ============================================================
2022-07-08 01:42:19,008: time cost, forward:0.011684093432404985, backward:0.03377141315618594, data cost:0.7016845354144128 
2022-07-08 01:42:19,009: ============================================================
2022-07-08 01:42:19,009: Epoch 21/36 Batch 2000/7662 eta: 1 day, 0:56:47.024301	Training Loss1 2.8767 (3.0347)	Training Total_Loss 2.8767 (3.0347)	Training Prec@1 98.828 (98.771)	Training Prec@5 0.000 (0.000)	
2022-07-08 01:42:19,009: ============================================================
2022-07-08 01:43:33,381: time cost, forward:0.011712864275601092, backward:0.033773618746280896, data cost:0.7014564765868384 
2022-07-08 01:43:33,381: ============================================================
2022-07-08 01:43:33,381: Epoch 21/36 Batch 2100/7662 eta: 1 day, 0:53:33.474797	Training Loss1 2.8273 (3.0359)	Training Total_Loss 2.8273 (3.0359)	Training Prec@1 99.414 (98.769)	Training Prec@5 0.000 (0.000)	
2022-07-08 01:43:33,381: ============================================================
2022-07-08 01:44:47,599: time cost, forward:0.01172412639859049, backward:0.03376995514283781, data cost:0.7012046116381788 
2022-07-08 01:44:47,599: ============================================================
2022-07-08 01:44:47,599: Epoch 21/36 Batch 2200/7662 eta: 1 day, 0:49:13.162420	Training Loss1 3.0847 (3.0362)	Training Total_Loss 3.0847 (3.0362)	Training Prec@1 98.633 (98.769)	Training Prec@5 0.000 (0.000)	
2022-07-08 01:44:47,599: ============================================================
2022-07-08 01:45:59,833: time cost, forward:0.011691744195839383, backward:0.033796030109267794, data cost:0.7001277779226149 
2022-07-08 01:45:59,833: ============================================================
2022-07-08 01:45:59,833: Epoch 21/36 Batch 2300/7662 eta: 1 day, 0:08:12.432388	Training Loss1 3.1991 (3.0365)	Training Total_Loss 3.1991 (3.0365)	Training Prec@1 99.023 (98.766)	Training Prec@5 0.000 (0.000)	
2022-07-08 01:45:59,833: ============================================================
2022-07-08 01:47:13,993: time cost, forward:0.011697853043855554, backward:0.033799777581523784, data cost:0.6999325147018973 
2022-07-08 01:47:13,993: ============================================================
2022-07-08 01:47:13,994: Epoch 21/36 Batch 2400/7662 eta: 1 day, 0:45:35.864509	Training Loss1 3.0150 (3.0382)	Training Total_Loss 3.0150 (3.0382)	Training Prec@1 99.805 (98.765)	Training Prec@5 0.000 (0.000)	
2022-07-08 01:47:13,994: ============================================================
2022-07-08 01:48:27,525: time cost, forward:0.011734809623617514, backward:0.03377854113294488, data cost:0.6994874668197663 
2022-07-08 01:48:27,525: ============================================================
2022-07-08 01:48:27,525: Epoch 21/36 Batch 2500/7662 eta: 1 day, 0:31:46.449839	Training Loss1 3.0647 (3.0391)	Training Total_Loss 3.0647 (3.0391)	Training Prec@1 98.438 (98.762)	Training Prec@5 0.000 (0.000)	
2022-07-08 01:48:27,525: ============================================================
2022-07-08 01:49:41,199: time cost, forward:0.011768864227653055, backward:0.033784035032829354, data cost:0.6990963722843994 
2022-07-08 01:49:41,199: ============================================================
2022-07-08 01:49:41,199: Epoch 21/36 Batch 2600/7662 eta: 1 day, 0:33:23.375074	Training Loss1 3.0357 (3.0404)	Training Total_Loss 3.0357 (3.0404)	Training Prec@1 99.219 (98.758)	Training Prec@5 0.000 (0.000)	
2022-07-08 01:49:41,199: ============================================================
2022-07-08 01:50:54,378: time cost, forward:0.011772441440001379, backward:0.0338274207367814, data cost:0.6985484944223783 
2022-07-08 01:50:54,378: ============================================================
2022-07-08 01:50:54,379: Epoch 21/36 Batch 2700/7662 eta: 1 day, 0:22:16.882244	Training Loss1 3.3474 (3.0408)	Training Total_Loss 3.3474 (3.0408)	Training Prec@1 98.828 (98.757)	Training Prec@5 0.000 (0.000)	
2022-07-08 01:50:54,379: ============================================================
2022-07-08 01:52:08,549: time cost, forward:0.011775020362224354, backward:0.03384071190300138, data cost:0.6983922027016845 
2022-07-08 01:52:08,549: ============================================================
2022-07-08 01:52:08,549: Epoch 21/36 Batch 2800/7662 eta: 1 day, 0:40:51.604914	Training Loss1 3.0561 (3.0401)	Training Total_Loss 3.0561 (3.0401)	Training Prec@1 99.023 (98.758)	Training Prec@5 0.000 (0.000)	
2022-07-08 01:52:08,550: ============================================================
2022-07-08 01:53:22,038: time cost, forward:0.011793537442541895, backward:0.03384217010279613, data cost:0.6980858985700867 
2022-07-08 01:53:22,038: ============================================================
2022-07-08 01:53:22,038: Epoch 21/36 Batch 2900/7662 eta: 1 day, 0:26:01.137502	Training Loss1 3.0678 (3.0410)	Training Total_Loss 3.0678 (3.0410)	Training Prec@1 98.047 (98.757)	Training Prec@5 0.000 (0.000)	
2022-07-08 01:53:22,039: ============================================================
2022-07-08 01:54:35,856: time cost, forward:0.011802766036096911, backward:0.033825644575464366, data cost:0.697887244642715 
2022-07-08 01:54:35,856: ============================================================
2022-07-08 01:54:35,857: Epoch 21/36 Batch 3000/7662 eta: 1 day, 0:31:21.273176	Training Loss1 2.9486 (3.0419)	Training Total_Loss 2.9486 (3.0419)	Training Prec@1 98.828 (98.756)	Training Prec@5 0.000 (0.000)	
2022-07-08 01:54:35,857: ============================================================
2022-07-08 01:55:51,879: time cost, forward:0.011789806506909951, backward:0.033827690510412844, data cost:0.6984158176958811 
2022-07-08 01:55:51,879: ============================================================
2022-07-08 01:55:51,880: Epoch 21/36 Batch 3100/7662 eta: 1 day, 1:14:02.332619	Training Loss1 3.0507 (3.0427)	Training Total_Loss 3.0507 (3.0427)	Training Prec@1 98.242 (98.754)	Training Prec@5 0.000 (0.000)	
2022-07-08 01:55:51,880: ============================================================
2022-07-08 01:57:04,862: time cost, forward:0.011768936626461753, backward:0.033830262303687735, data cost:0.69796950491416 
2022-07-08 01:57:04,863: ============================================================
2022-07-08 01:57:04,863: Epoch 21/36 Batch 3200/7662 eta: 1 day, 0:12:16.807583	Training Loss1 3.0520 (3.0432)	Training Total_Loss 3.0520 (3.0432)	Training Prec@1 99.023 (98.755)	Training Prec@5 0.000 (0.000)	
2022-07-08 01:57:04,863: ============================================================
2022-07-08 01:58:17,946: time cost, forward:0.011769583384966843, backward:0.033831662862869635, data cost:0.6975656160624615 
2022-07-08 01:58:17,946: ============================================================
2022-07-08 01:58:17,947: Epoch 21/36 Batch 3300/7662 eta: 1 day, 0:13:03.729639	Training Loss1 3.0664 (3.0445)	Training Total_Loss 3.0664 (3.0445)	Training Prec@1 98.828 (98.753)	Training Prec@5 0.000 (0.000)	
2022-07-08 01:58:17,947: ============================================================
2022-07-08 01:59:31,756: time cost, forward:0.01177824486981914, backward:0.03385846598704586, data cost:0.6973584870374634 
2022-07-08 01:59:31,756: ============================================================
2022-07-08 01:59:31,756: Epoch 21/36 Batch 3400/7662 eta: 1 day, 0:26:16.066780	Training Loss1 2.7917 (3.0451)	Training Total_Loss 2.7917 (3.0451)	Training Prec@1 99.219 (98.751)	Training Prec@5 0.000 (0.000)	
2022-07-08 01:59:31,756: ============================================================
2022-07-08 02:00:46,413: time cost, forward:0.011776285329591414, backward:0.03385613379597017, data cost:0.6974559951830196 
2022-07-08 02:00:46,413: ============================================================
2022-07-08 02:00:46,414: Epoch 21/36 Batch 3500/7662 eta: 1 day, 0:41:51.539916	Training Loss1 3.1488 (3.0465)	Training Total_Loss 3.1488 (3.0465)	Training Prec@1 98.242 (98.751)	Training Prec@5 0.000 (0.000)	
2022-07-08 02:00:46,414: ============================================================
2022-07-08 02:02:00,211: time cost, forward:0.011780008205807053, backward:0.03387307127040769, data cost:0.6972727664280812 
2022-07-08 02:02:00,211: ============================================================
2022-07-08 02:02:00,211: Epoch 21/36 Batch 3600/7662 eta: 1 day, 0:23:34.339357	Training Loss1 3.0094 (3.0471)	Training Total_Loss 3.0094 (3.0471)	Training Prec@1 97.656 (98.751)	Training Prec@5 0.000 (0.000)	
2022-07-08 02:02:00,212: ============================================================
2022-07-08 02:03:13,482: time cost, forward:0.011777592208070283, backward:0.03386673214436222, data cost:0.6969928444962658 
2022-07-08 02:03:13,482: ============================================================
2022-07-08 02:03:13,482: Epoch 21/36 Batch 3700/7662 eta: 1 day, 0:11:53.623625	Training Loss1 2.9979 (3.0477)	Training Total_Loss 2.9979 (3.0477)	Training Prec@1 98.828 (98.750)	Training Prec@5 0.000 (0.000)	
2022-07-08 02:03:13,482: ============================================================
2022-07-08 02:04:26,919: time cost, forward:0.011774332092196792, backward:0.03385551178508697, data cost:0.6967694875471653 
2022-07-08 02:04:26,919: ============================================================
2022-07-08 02:04:26,920: Epoch 21/36 Batch 3800/7662 eta: 1 day, 0:13:58.564342	Training Loss1 3.0969 (3.0481)	Training Total_Loss 3.0969 (3.0481)	Training Prec@1 99.219 (98.750)	Training Prec@5 0.000 (0.000)	
2022-07-08 02:04:26,920: ============================================================
2022-07-08 02:05:41,286: time cost, forward:0.011772435516783995, backward:0.03385435749121463, data cost:0.6967889561228766 
2022-07-08 02:05:41,287: ============================================================
2022-07-08 02:05:41,287: Epoch 21/36 Batch 3900/7662 eta: 1 day, 0:31:08.759903	Training Loss1 2.9493 (3.0487)	Training Total_Loss 2.9493 (3.0487)	Training Prec@1 98.633 (98.750)	Training Prec@5 0.000 (0.000)	
2022-07-08 02:05:41,287: ============================================================
2022-07-08 02:06:55,396: time cost, forward:0.011777907915489768, backward:0.03383959809313061, data cost:0.6967532006941249 
2022-07-08 02:06:55,396: ============================================================
2022-07-08 02:06:55,396: Epoch 21/36 Batch 4000/7662 eta: 1 day, 0:24:48.604891	Training Loss1 2.8967 (3.0490)	Training Total_Loss 2.8967 (3.0490)	Training Prec@1 99.219 (98.751)	Training Prec@5 0.000 (0.000)	
2022-07-08 02:06:55,396: ============================================================
2022-07-08 02:08:09,036: time cost, forward:0.011766996055616057, backward:0.03384479076928062, data cost:0.6966008840464591 
2022-07-08 02:08:09,036: ============================================================
2022-07-08 02:08:09,036: Epoch 21/36 Batch 4100/7662 eta: 1 day, 0:14:18.442233	Training Loss1 2.8272 (3.0494)	Training Total_Loss 2.8272 (3.0494)	Training Prec@1 99.219 (98.749)	Training Prec@5 0.000 (0.000)	
2022-07-08 02:08:09,037: ============================================================
2022-07-08 02:09:23,359: time cost, forward:0.011782593033262082, backward:0.03384791388060826, data cost:0.6965868176662176 
2022-07-08 02:09:23,359: ============================================================
2022-07-08 02:09:23,359: Epoch 21/36 Batch 4200/7662 eta: 1 day, 0:26:32.844036	Training Loss1 3.2524 (3.0505)	Training Total_Loss 3.2524 (3.0505)	Training Prec@1 98.242 (98.747)	Training Prec@5 0.000 (0.000)	
2022-07-08 02:09:23,359: ============================================================
2022-07-08 02:10:37,526: time cost, forward:0.011770804445808448, backward:0.033860452509558624, data cost:0.696564823617822 
2022-07-08 02:10:37,527: ============================================================
2022-07-08 02:10:37,527: Epoch 21/36 Batch 4300/7662 eta: 1 day, 0:22:15.254111	Training Loss1 3.2166 (3.0511)	Training Total_Loss 3.2166 (3.0511)	Training Prec@1 97.656 (98.748)	Training Prec@5 0.000 (0.000)	
2022-07-08 02:10:37,527: ============================================================
2022-07-08 02:11:51,282: time cost, forward:0.01175503368728891, backward:0.033869992876410564, data cost:0.6964512309802611 
2022-07-08 02:11:51,282: ============================================================
2022-07-08 02:11:51,283: Epoch 21/36 Batch 4400/7662 eta: 1 day, 0:12:54.159453	Training Loss1 3.0797 (3.0510)	Training Total_Loss 3.0797 (3.0510)	Training Prec@1 98.438 (98.747)	Training Prec@5 0.000 (0.000)	
2022-07-08 02:11:51,283: ============================================================
2022-07-08 02:13:06,257: time cost, forward:0.011752271260068427, backward:0.03386753446447979, data cost:0.696614576143857 
2022-07-08 02:13:06,257: ============================================================
2022-07-08 02:13:06,257: Epoch 21/36 Batch 4500/7662 eta: 1 day, 0:35:39.776993	Training Loss1 2.9876 (3.0513)	Training Total_Loss 2.9876 (3.0513)	Training Prec@1 98.828 (98.745)	Training Prec@5 0.000 (0.000)	
2022-07-08 02:13:06,257: ============================================================
2022-07-08 02:14:20,223: time cost, forward:0.01175190469808593, backward:0.033891658104873525, data cost:0.6965224691566423 
2022-07-08 02:14:20,223: ============================================================
2022-07-08 02:14:20,224: Epoch 21/36 Batch 4600/7662 eta: 1 day, 0:14:35.104196	Training Loss1 2.9515 (3.0517)	Training Total_Loss 2.9515 (3.0517)	Training Prec@1 98.828 (98.745)	Training Prec@5 0.000 (0.000)	
2022-07-08 02:14:20,224: ============================================================
2022-07-08 02:15:34,971: time cost, forward:0.011747348052335562, backward:0.03389466861685075, data cost:0.6966235675211028 
2022-07-08 02:15:34,972: ============================================================
2022-07-08 02:15:34,972: Epoch 21/36 Batch 4700/7662 eta: 1 day, 0:28:43.262444	Training Loss1 3.2123 (3.0520)	Training Total_Loss 3.2123 (3.0520)	Training Prec@1 99.023 (98.745)	Training Prec@5 0.000 (0.000)	
2022-07-08 02:15:34,972: ============================================================
2022-07-08 02:16:50,352: time cost, forward:0.01173833440457515, backward:0.03391715823970603, data cost:0.6968346779782167 
2022-07-08 02:16:50,353: ============================================================
2022-07-08 02:16:50,353: Epoch 21/36 Batch 4800/7662 eta: 1 day, 0:39:53.360799	Training Loss1 2.9073 (3.0523)	Training Total_Loss 2.9073 (3.0523)	Training Prec@1 98.828 (98.745)	Training Prec@5 0.000 (0.000)	
2022-07-08 02:16:50,353: ============================================================
2022-07-08 02:18:03,883: time cost, forward:0.011716665260936319, backward:0.03393217178480215, data cost:0.6966842466725406 
2022-07-08 02:18:03,883: ============================================================
2022-07-08 02:18:03,884: Epoch 21/36 Batch 4900/7662 eta: 1 day, 0:02:20.325087	Training Loss1 3.0157 (3.0531)	Training Total_Loss 3.0157 (3.0531)	Training Prec@1 98.633 (98.744)	Training Prec@5 0.000 (0.000)	
2022-07-08 02:18:03,884: ============================================================
2022-07-08 02:19:16,611: time cost, forward:0.011702959383456892, backward:0.03394252859513553, data cost:0.6963781815906791 
2022-07-08 02:19:16,611: ============================================================
2022-07-08 02:19:16,611: Epoch 21/36 Batch 5000/7662 eta: 23:45:22.558933	Training Loss1 3.1439 (3.0532)	Training Total_Loss 3.1439 (3.0532)	Training Prec@1 98.633 (98.743)	Training Prec@5 0.000 (0.000)	
2022-07-08 02:19:16,611: ============================================================
2022-07-08 02:20:31,777: time cost, forward:0.011705166359793137, backward:0.03395097067272413, data cost:0.6965434291732617 
2022-07-08 02:20:31,778: ============================================================
2022-07-08 02:20:31,778: Epoch 21/36 Batch 5100/7662 eta: 1 day, 0:31:55.603974	Training Loss1 3.0828 (3.0540)	Training Total_Loss 3.0828 (3.0540)	Training Prec@1 98.828 (98.742)	Training Prec@5 0.000 (0.000)	
2022-07-08 02:20:31,778: ============================================================
2022-07-08 02:21:44,973: time cost, forward:0.011713476771688342, backward:0.03394520830754982, data cost:0.6963346641002698 
2022-07-08 02:21:44,973: ============================================================
2022-07-08 02:21:44,974: Epoch 21/36 Batch 5200/7662 eta: 23:52:06.589954	Training Loss1 2.9971 (3.0542)	Training Total_Loss 2.9971 (3.0542)	Training Prec@1 99.023 (98.741)	Training Prec@5 0.000 (0.000)	
2022-07-08 02:21:44,974: ============================================================
2022-07-08 02:22:59,751: time cost, forward:0.011737274255228844, backward:0.03394507637427064, data cost:0.6964099525527968 
2022-07-08 02:22:59,751: ============================================================
2022-07-08 02:22:59,751: Epoch 21/36 Batch 5300/7662 eta: 1 day, 0:21:49.285570	Training Loss1 3.1037 (3.0544)	Training Total_Loss 3.1037 (3.0544)	Training Prec@1 98.633 (98.740)	Training Prec@5 0.000 (0.000)	
2022-07-08 02:22:59,752: ============================================================
2022-07-08 02:24:13,076: time cost, forward:0.011742904862334804, backward:0.033940928537418584, data cost:0.6962326838144838 
2022-07-08 02:24:13,076: ============================================================
2022-07-08 02:24:13,077: Epoch 21/36 Batch 5400/7662 eta: 23:52:11.846658	Training Loss1 3.1366 (3.0550)	Training Total_Loss 3.1366 (3.0550)	Training Prec@1 98.828 (98.737)	Training Prec@5 0.000 (0.000)	
2022-07-08 02:24:13,077: ============================================================
2022-07-08 02:25:27,538: time cost, forward:0.011735389960594754, backward:0.03395964869977691, data cost:0.6962545130074642 
2022-07-08 02:25:27,538: ============================================================
2022-07-08 02:25:27,538: Epoch 21/36 Batch 5500/7662 eta: 1 day, 0:13:09.226446	Training Loss1 3.0128 (3.0554)	Training Total_Loss 3.0128 (3.0554)	Training Prec@1 98.633 (98.736)	Training Prec@5 0.000 (0.000)	
2022-07-08 02:25:27,538: ============================================================
2022-07-08 02:26:41,623: time cost, forward:0.011739125910093155, backward:0.033976259860082875, data cost:0.6961937285806691 
2022-07-08 02:26:41,624: ============================================================
2022-07-08 02:26:41,624: Epoch 21/36 Batch 5600/7662 eta: 1 day, 0:04:35.251797	Training Loss1 3.1028 (3.0552)	Training Total_Loss 3.1028 (3.0552)	Training Prec@1 99.414 (98.736)	Training Prec@5 0.000 (0.000)	
2022-07-08 02:26:41,624: ============================================================
2022-07-08 02:27:55,831: time cost, forward:0.011733021228266173, backward:0.033991681837077556, data cost:0.6961878988905568 
2022-07-08 02:27:55,831: ============================================================
2022-07-08 02:27:55,831: Epoch 21/36 Batch 5700/7662 eta: 1 day, 0:05:43.076979	Training Loss1 3.0905 (3.0557)	Training Total_Loss 3.0905 (3.0557)	Training Prec@1 98.242 (98.734)	Training Prec@5 0.000 (0.000)	
2022-07-08 02:27:55,831: ============================================================
2022-07-08 02:29:09,195: time cost, forward:0.011718049380754186, backward:0.03400626131575114, data cost:0.6960293937498259 
2022-07-08 02:29:09,195: ============================================================
2022-07-08 02:29:09,195: Epoch 21/36 Batch 5800/7662 eta: 23:48:04.028311	Training Loss1 2.9008 (3.0561)	Training Total_Loss 2.9008 (3.0561)	Training Prec@1 99.219 (98.733)	Training Prec@5 0.000 (0.000)	
2022-07-08 02:29:09,195: ============================================================
2022-07-08 02:30:22,793: time cost, forward:0.011706915320451228, backward:0.03402667127235155, data cost:0.6959170858664803 
2022-07-08 02:30:22,793: ============================================================
2022-07-08 02:30:22,793: Epoch 21/36 Batch 5900/7662 eta: 23:51:24.025802	Training Loss1 3.0437 (3.0563)	Training Total_Loss 3.0437 (3.0563)	Training Prec@1 98.047 (98.734)	Training Prec@5 0.000 (0.000)	
2022-07-08 02:30:22,794: ============================================================
2022-07-08 02:31:36,585: time cost, forward:0.011715533197234125, backward:0.03403931427923992, data cost:0.6958245827687106 
2022-07-08 02:31:36,586: ============================================================
2022-07-08 02:31:36,586: Epoch 21/36 Batch 6000/7662 eta: 23:53:56.933746	Training Loss1 2.9002 (3.0570)	Training Total_Loss 2.9002 (3.0570)	Training Prec@1 98.828 (98.732)	Training Prec@5 0.000 (0.000)	
2022-07-08 02:31:36,586: ============================================================
2022-07-08 02:32:50,900: time cost, forward:0.01171642050310752, backward:0.03404719103631631, data cost:0.6958334650401503 
2022-07-08 02:32:50,900: ============================================================
2022-07-08 02:32:50,900: Epoch 21/36 Batch 6100/7662 eta: 1 day, 0:02:51.259196	Training Loss1 3.3703 (3.0576)	Training Total_Loss 3.3703 (3.0576)	Training Prec@1 98.633 (98.731)	Training Prec@5 0.000 (0.000)	
2022-07-08 02:32:50,901: ============================================================
2022-07-08 02:34:04,826: time cost, forward:0.01171269049892927, backward:0.03405448493889829, data cost:0.6957778525287095 
2022-07-08 02:34:04,826: ============================================================
2022-07-08 02:34:04,826: Epoch 21/36 Batch 6200/7662 eta: 23:54:04.158733	Training Loss1 3.1491 (3.0578)	Training Total_Loss 3.1491 (3.0578)	Training Prec@1 97.852 (98.732)	Training Prec@5 0.000 (0.000)	
2022-07-08 02:34:04,826: ============================================================
2022-07-08 02:35:19,350: time cost, forward:0.011706216465122909, backward:0.03405657668476314, data cost:0.6958328112096404 
2022-07-08 02:35:19,350: ============================================================
2022-07-08 02:35:19,350: Epoch 21/36 Batch 6300/7662 eta: 1 day, 0:04:26.156144	Training Loss1 3.0233 (3.0580)	Training Total_Loss 3.0233 (3.0580)	Training Prec@1 99.219 (98.732)	Training Prec@5 0.000 (0.000)	
2022-07-08 02:35:19,350: ============================================================
2022-07-08 02:36:33,620: time cost, forward:0.011688396211228608, backward:0.03405556274142223, data cost:0.6958608773746123 
2022-07-08 02:36:33,620: ============================================================
2022-07-08 02:36:33,621: Epoch 21/36 Batch 6400/7662 eta: 23:58:17.093744	Training Loss1 3.0356 (3.0584)	Training Total_Loss 3.0356 (3.0584)	Training Prec@1 99.414 (98.731)	Training Prec@5 0.000 (0.000)	
2022-07-08 02:36:33,621: ============================================================
2022-07-08 02:37:49,194: time cost, forward:0.011678259195520577, backward:0.03405510636362081, data cost:0.6960817749160201 
2022-07-08 02:37:49,195: ============================================================
2022-07-08 02:37:49,195: Epoch 21/36 Batch 6500/7662 eta: 1 day, 0:22:16.540801	Training Loss1 3.1751 (3.0587)	Training Total_Loss 3.1751 (3.0587)	Training Prec@1 97.656 (98.730)	Training Prec@5 0.000 (0.000)	
2022-07-08 02:37:49,195: ============================================================
2022-07-08 02:39:02,879: time cost, forward:0.011681202813194888, backward:0.03405834523308077, data cost:0.6959867247633363 
2022-07-08 02:39:02,880: ============================================================
2022-07-08 02:39:02,880: Epoch 21/36 Batch 6600/7662 eta: 23:44:29.566431	Training Loss1 3.0297 (3.0591)	Training Total_Loss 3.0297 (3.0591)	Training Prec@1 98.438 (98.730)	Training Prec@5 0.000 (0.000)	
2022-07-08 02:39:02,880: ============================================================
2022-07-08 02:40:16,909: time cost, forward:0.011671929950944735, backward:0.034062846238301005, data cost:0.6959617595242679 
2022-07-08 02:40:16,909: ============================================================
2022-07-08 02:40:16,910: Epoch 21/36 Batch 6700/7662 eta: 23:49:55.143560	Training Loss1 3.0597 (3.0596)	Training Total_Loss 3.0597 (3.0596)	Training Prec@1 98.242 (98.728)	Training Prec@5 0.000 (0.000)	
2022-07-08 02:40:16,910: ============================================================
2022-07-08 02:41:31,122: time cost, forward:0.01166082820676323, backward:0.03406957770677362, data cost:0.6959609591552379 
2022-07-08 02:41:31,122: ============================================================
2022-07-08 02:41:31,122: Epoch 21/36 Batch 6800/7662 eta: 23:52:12.865604	Training Loss1 3.0402 (3.0599)	Training Total_Loss 3.0402 (3.0599)	Training Prec@1 99.023 (98.728)	Training Prec@5 0.000 (0.000)	
2022-07-08 02:41:31,122: ============================================================
2022-07-08 02:42:46,468: time cost, forward:0.011654149312733878, backward:0.03406707313306471, data cost:0.6961382043276996 
2022-07-08 02:42:46,468: ============================================================
2022-07-08 02:42:46,468: Epoch 21/36 Batch 6900/7662 eta: 1 day, 0:12:50.275844	Training Loss1 2.9382 (3.0598)	Training Total_Loss 2.9382 (3.0598)	Training Prec@1 99.023 (98.728)	Training Prec@5 0.000 (0.000)	
2022-07-08 02:42:46,468: ============================================================
2022-07-08 02:44:00,249: time cost, forward:0.011649481039896133, backward:0.034069218998688394, data cost:0.6960700374788038 
2022-07-08 02:44:00,249: ============================================================
2022-07-08 02:44:00,250: Epoch 21/36 Batch 7000/7662 eta: 23:41:25.905469	Training Loss1 3.0805 (3.0602)	Training Total_Loss 3.0805 (3.0602)	Training Prec@1 98.633 (98.727)	Training Prec@5 0.000 (0.000)	
2022-07-08 02:44:00,250: ============================================================
2022-07-08 02:45:15,167: time cost, forward:0.01163940316170836, backward:0.03407588376513937, data cost:0.6961743461529896 
2022-07-08 02:45:15,167: ============================================================
2022-07-08 02:45:15,167: Epoch 21/36 Batch 7100/7662 eta: 1 day, 0:02:04.500514	Training Loss1 2.9282 (3.0608)	Training Total_Loss 2.9282 (3.0608)	Training Prec@1 98.633 (98.726)	Training Prec@5 0.000 (0.000)	
2022-07-08 02:45:15,167: ============================================================
2022-07-08 02:46:29,391: time cost, forward:0.011640938938881129, backward:0.034072955725407965, data cost:0.6961696679798459 
2022-07-08 02:46:29,391: ============================================================
2022-07-08 02:46:29,391: Epoch 21/36 Batch 7200/7662 eta: 23:47:29.687110	Training Loss1 3.0808 (3.0613)	Training Total_Loss 3.0808 (3.0613)	Training Prec@1 99.219 (98.725)	Training Prec@5 0.000 (0.000)	
2022-07-08 02:46:29,391: ============================================================
2022-07-08 02:47:43,912: time cost, forward:0.011641952171278646, backward:0.0340825840453119, data cost:0.6961921195915944 
2022-07-08 02:47:43,912: ============================================================
2022-07-08 02:47:43,913: Epoch 21/36 Batch 7300/7662 eta: 23:51:57.777077	Training Loss1 3.1624 (3.0614)	Training Total_Loss 3.1624 (3.0614)	Training Prec@1 98.828 (98.724)	Training Prec@5 0.000 (0.000)	
2022-07-08 02:47:43,913: ============================================================
2022-07-08 02:48:58,798: time cost, forward:0.011640698768944656, backward:0.034084043787659654, data cost:0.696280792897288 
2022-07-08 02:48:58,798: ============================================================
2022-07-08 02:48:58,798: Epoch 21/36 Batch 7400/7662 eta: 23:57:43.112125	Training Loss1 3.1675 (3.0617)	Training Total_Loss 3.1675 (3.0617)	Training Prec@1 97.852 (98.723)	Training Prec@5 0.000 (0.000)	
2022-07-08 02:48:58,798: ============================================================
2022-07-08 02:50:13,594: time cost, forward:0.01163967880730248, backward:0.03409815308316133, data cost:0.6963367396027966 
2022-07-08 02:50:13,594: ============================================================
2022-07-08 02:50:13,595: Epoch 21/36 Batch 7500/7662 eta: 23:54:45.290940	Training Loss1 3.0169 (3.0619)	Training Total_Loss 3.0169 (3.0619)	Training Prec@1 99.023 (98.722)	Training Prec@5 0.000 (0.000)	
2022-07-08 02:50:13,595: ============================================================
2022-07-08 02:51:28,569: time cost, forward:0.011633933351328223, backward:0.034097708060657025, data cost:0.6964291486164067 
2022-07-08 02:51:28,569: ============================================================
2022-07-08 02:51:28,569: Epoch 21/36 Batch 7600/7662 eta: 23:56:55.448650	Training Loss1 3.4015 (3.0623)	Training Total_Loss 3.4015 (3.0623)	Training Prec@1 98.633 (98.721)	Training Prec@5 0.000 (0.000)	
2022-07-08 02:51:28,569: ============================================================
2022-07-08 02:52:17,556: Epoch 21/36 Batch 7663/7662 eta: 23:56:08.214703	Training Loss1 3.0791 (3.0624)	Training Total_Loss 3.0791 (3.0624)	Training Prec@1 98.633 (98.721)	Training Prec@5 0.000 (0.000)	
2022-07-08 02:52:17,564: ============================================================
2022-07-08 02:53:51,533: time cost, forward:0.011130301639287158, backward:0.033325067674270785, data cost:0.8969899428011191 
2022-07-08 02:53:51,533: ============================================================
2022-07-08 02:53:51,533: Epoch 22/36 Batch 100/7662 eta: 1 day, 5:54:25.467015	Training Loss1 2.9755 (2.8851)	Training Total_Loss 2.9755 (2.8851)	Training Prec@1 99.219 (99.029)	Training Prec@5 0.000 (0.000)	
2022-07-08 02:53:51,534: ============================================================
2022-07-08 02:55:06,001: time cost, forward:0.010839647983186809, backward:0.03344430995346913, data cost:0.7978311220006128 
2022-07-08 02:55:06,001: ============================================================
2022-07-08 02:55:06,001: Epoch 22/36 Batch 200/7662 eta: 23:43:57.556861	Training Loss1 2.8324 (2.8809)	Training Total_Loss 2.8324 (2.8809)	Training Prec@1 99.609 (98.981)	Training Prec@5 0.000 (0.000)	
2022-07-08 02:55:06,001: ============================================================
2022-07-08 02:56:19,797: time cost, forward:0.010766522142799403, backward:0.03353490398879035, data cost:0.7628437388302092 
2022-07-08 02:56:19,797: ============================================================
2022-07-08 02:56:19,798: Epoch 22/36 Batch 300/7662 eta: 23:29:53.527587	Training Loss1 2.8632 (2.8868)	Training Total_Loss 2.8632 (2.8868)	Training Prec@1 99.414 (98.978)	Training Prec@5 0.000 (0.000)	
2022-07-08 02:56:19,798: ============================================================
2022-07-08 02:57:33,771: time cost, forward:0.010679846120657479, backward:0.03357015516524924, data cost:0.7458184285271436 
2022-07-08 02:57:33,771: ============================================================
2022-07-08 02:57:33,771: Epoch 22/36 Batch 400/7662 eta: 23:32:03.084910	Training Loss1 2.9866 (2.8872)	Training Total_Loss 2.9866 (2.8872)	Training Prec@1 98.633 (98.967)	Training Prec@5 0.000 (0.000)	
2022-07-08 02:57:33,771: ============================================================
2022-07-08 02:58:49,371: time cost, forward:0.010642521367044392, backward:0.0336628461887459, data cost:0.7388026059748892 
2022-07-08 02:58:49,372: ============================================================
2022-07-08 02:58:49,372: Epoch 22/36 Batch 500/7662 eta: 1 day, 0:01:50.211571	Training Loss1 2.8713 (2.8836)	Training Total_Loss 2.8713 (2.8836)	Training Prec@1 98.633 (98.978)	Training Prec@5 0.000 (0.000)	
2022-07-08 02:58:49,372: ============================================================
2022-07-08 03:00:05,311: time cost, forward:0.01061230390418153, backward:0.033755833796149305, data cost:0.7346458240025031 
2022-07-08 03:00:05,312: ============================================================
2022-07-08 03:00:05,312: Epoch 22/36 Batch 600/7662 eta: 1 day, 0:07:03.129106	Training Loss1 2.7305 (2.8857)	Training Total_Loss 2.7305 (2.8857)	Training Prec@1 99.219 (98.983)	Training Prec@5 0.000 (0.000)	
2022-07-08 03:00:05,312: ============================================================
2022-07-08 03:01:20,983: time cost, forward:0.01060007229042326, backward:0.0338075017724426, data cost:0.7313127746227303 
2022-07-08 03:01:20,983: ============================================================
2022-07-08 03:01:20,984: Epoch 22/36 Batch 700/7662 eta: 1 day, 0:00:40.425786	Training Loss1 2.7961 (2.8933)	Training Total_Loss 2.7961 (2.8933)	Training Prec@1 99.414 (98.983)	Training Prec@5 0.000 (0.000)	
2022-07-08 03:01:20,984: ============================================================
2022-07-08 03:02:35,867: time cost, forward:0.01070037174582929, backward:0.03386544375604622, data cost:0.7278108173079126 
2022-07-08 03:02:35,867: ============================================================
2022-07-08 03:02:35,867: Epoch 22/36 Batch 800/7662 eta: 23:44:25.815663	Training Loss1 2.9682 (2.8966)	Training Total_Loss 2.9682 (2.8966)	Training Prec@1 98.828 (98.979)	Training Prec@5 0.000 (0.000)	
2022-07-08 03:02:35,868: ============================================================
2022-07-08 03:03:49,755: time cost, forward:0.010872640917378088, backward:0.033981227768674176, data cost:0.7236715434523128 
2022-07-08 03:03:49,755: ============================================================
2022-07-08 03:03:49,755: Epoch 22/36 Batch 900/7662 eta: 23:24:14.964569	Training Loss1 2.9054 (2.8975)	Training Total_Loss 2.9054 (2.8975)	Training Prec@1 99.414 (98.972)	Training Prec@5 0.000 (0.000)	
2022-07-08 03:03:49,755: ============================================================
2022-07-08 03:05:02,695: time cost, forward:0.010902690457868146, backward:0.03393536096101289, data cost:0.7197302688468803 
2022-07-08 03:05:02,695: ============================================================
2022-07-08 03:05:02,695: Epoch 22/36 Batch 1000/7662 eta: 23:05:01.449928	Training Loss1 2.8482 (2.8985)	Training Total_Loss 2.8482 (2.8985)	Training Prec@1 99.219 (98.971)	Training Prec@5 0.000 (0.000)	
2022-07-08 03:05:02,696: ============================================================
2022-07-08 03:06:15,519: time cost, forward:0.01099120106232828, backward:0.03390445223279819, data cost:0.7163206938725368 
2022-07-08 03:06:15,519: ============================================================
2022-07-08 03:06:15,519: Epoch 22/36 Batch 1100/7662 eta: 23:01:35.962989	Training Loss1 2.9184 (2.8994)	Training Total_Loss 2.9184 (2.8994)	Training Prec@1 98.828 (98.965)	Training Prec@5 0.000 (0.000)	
2022-07-08 03:06:15,519: ============================================================
2022-07-08 03:07:29,535: time cost, forward:0.011041289871190367, backward:0.03379987417607629, data cost:0.7145871245135259 
2022-07-08 03:07:29,536: ============================================================
2022-07-08 03:07:29,536: Epoch 22/36 Batch 1200/7662 eta: 23:22:59.847154	Training Loss1 3.2524 (2.9024)	Training Total_Loss 3.2524 (2.9024)	Training Prec@1 99.219 (98.959)	Training Prec@5 0.000 (0.000)	
2022-07-08 03:07:29,536: ============================================================
2022-07-08 03:08:42,488: time cost, forward:0.01110482142465311, backward:0.03372378308925379, data cost:0.7122554692788892 
2022-07-08 03:08:42,489: ============================================================
2022-07-08 03:08:42,489: Epoch 22/36 Batch 1300/7662 eta: 23:01:37.255747	Training Loss1 2.8352 (2.9025)	Training Total_Loss 2.8352 (2.9025)	Training Prec@1 99.023 (98.963)	Training Prec@5 0.000 (0.000)	
2022-07-08 03:08:42,489: ============================================================
2022-07-08 03:09:56,702: time cost, forward:0.01113241974842216, backward:0.03372331531325607, data cost:0.7110130911302873 
2022-07-08 03:09:56,702: ============================================================
2022-07-08 03:09:56,703: Epoch 22/36 Batch 1400/7662 eta: 23:24:15.628082	Training Loss1 2.8087 (2.9034)	Training Total_Loss 2.8087 (2.9034)	Training Prec@1 99.609 (98.960)	Training Prec@5 0.000 (0.000)	
2022-07-08 03:09:56,703: ============================================================
2022-07-08 03:11:09,901: time cost, forward:0.011158162232157865, backward:0.03372312657748802, data cost:0.7094372957050203 
2022-07-08 03:11:09,901: ============================================================
2022-07-08 03:11:09,902: Epoch 22/36 Batch 1500/7662 eta: 23:03:50.349984	Training Loss1 2.7870 (2.9044)	Training Total_Loss 2.7870 (2.9044)	Training Prec@1 99.219 (98.961)	Training Prec@5 0.000 (0.000)	
2022-07-08 03:11:09,902: ============================================================
2022-07-08 03:12:23,402: time cost, forward:0.011158048845664495, backward:0.03374813153193547, data cost:0.7081866171898284 
2022-07-08 03:12:23,403: ============================================================
2022-07-08 03:12:23,403: Epoch 22/36 Batch 1600/7662 eta: 23:08:19.842445	Training Loss1 3.0721 (2.9064)	Training Total_Loss 3.0721 (2.9064)	Training Prec@1 98.438 (98.960)	Training Prec@5 0.000 (0.000)	
2022-07-08 03:12:23,403: ============================================================
2022-07-08 03:13:37,359: time cost, forward:0.011155549324983144, backward:0.033757908895760864, data cost:0.7073579816835077 
2022-07-08 03:13:37,359: ============================================================
2022-07-08 03:13:37,360: Epoch 22/36 Batch 1700/7662 eta: 23:15:41.763405	Training Loss1 2.8498 (2.9081)	Training Total_Loss 2.8498 (2.9081)	Training Prec@1 98.633 (98.958)	Training Prec@5 0.000 (0.000)	
2022-07-08 03:13:37,360: ============================================================
2022-07-08 03:14:49,819: time cost, forward:0.011199780475304748, backward:0.03374072894445719, data cost:0.7057115622133994 
2022-07-08 03:14:49,819: ============================================================
2022-07-08 03:14:49,820: Epoch 22/36 Batch 1800/7662 eta: 22:46:14.790884	Training Loss1 3.1490 (2.9102)	Training Total_Loss 3.1490 (2.9102)	Training Prec@1 98.242 (98.950)	Training Prec@5 0.000 (0.000)	
2022-07-08 03:14:49,820: ============================================================
2022-07-08 03:16:04,126: time cost, forward:0.011314764218684433, backward:0.033739579734581276, data cost:0.7052131919499257 
2022-07-08 03:16:04,126: ============================================================
2022-07-08 03:16:04,126: Epoch 22/36 Batch 1900/7662 eta: 23:19:49.477252	Training Loss1 2.8641 (2.9126)	Training Total_Loss 2.8641 (2.9126)	Training Prec@1 98.633 (98.947)	Training Prec@5 0.000 (0.000)	
2022-07-08 03:16:04,126: ============================================================
2022-07-08 03:17:17,066: time cost, forward:0.011357073428453119, backward:0.03377162843659379, data cost:0.70405240116148 
2022-07-08 03:17:17,066: ============================================================
2022-07-08 03:17:17,066: Epoch 22/36 Batch 2000/7662 eta: 22:52:52.205871	Training Loss1 2.7912 (2.9136)	Training Total_Loss 2.7912 (2.9136)	Training Prec@1 99.023 (98.944)	Training Prec@5 0.000 (0.000)	
2022-07-08 03:17:17,067: ============================================================
2022-07-08 03:18:30,955: time cost, forward:0.011404816339900802, backward:0.03378558738166915, data cost:0.7034807259721834 
2022-07-08 03:18:30,955: ============================================================
2022-07-08 03:18:30,956: Epoch 22/36 Batch 2100/7662 eta: 23:09:29.737873	Training Loss1 2.9526 (2.9150)	Training Total_Loss 2.9526 (2.9150)	Training Prec@1 98.633 (98.944)	Training Prec@5 0.000 (0.000)	
2022-07-08 03:18:30,956: ============================================================
2022-07-08 03:19:44,610: time cost, forward:0.011448731689140871, backward:0.03374034223257276, data cost:0.702870490389447 
2022-07-08 03:19:44,610: ============================================================
2022-07-08 03:19:44,610: Epoch 22/36 Batch 2200/7662 eta: 23:03:51.758384	Training Loss1 2.9120 (2.9160)	Training Total_Loss 2.9120 (2.9160)	Training Prec@1 98.242 (98.944)	Training Prec@5 0.000 (0.000)	
2022-07-08 03:19:44,610: ============================================================
2022-07-08 03:20:57,676: time cost, forward:0.01149630629534097, backward:0.03374848452896178, data cost:0.702055247984227 
2022-07-08 03:20:57,677: ============================================================
2022-07-08 03:20:57,677: Epoch 22/36 Batch 2300/7662 eta: 22:51:35.450071	Training Loss1 2.9815 (2.9173)	Training Total_Loss 2.9815 (2.9173)	Training Prec@1 99.219 (98.944)	Training Prec@5 0.000 (0.000)	
2022-07-08 03:20:57,677: ============================================================
2022-07-08 03:22:11,046: time cost, forward:0.01151459591743498, backward:0.03372145454403558, data cost:0.7014714302048677 
2022-07-08 03:22:11,047: ============================================================
2022-07-08 03:22:11,047: Epoch 22/36 Batch 2400/7662 eta: 22:56:04.164402	Training Loss1 2.7484 (2.9192)	Training Total_Loss 2.7484 (2.9192)	Training Prec@1 99.023 (98.945)	Training Prec@5 0.000 (0.000)	
2022-07-08 03:22:11,047: ============================================================
2022-07-08 03:23:24,760: time cost, forward:0.01150509623252377, backward:0.033711585105538795, data cost:0.7010822099607055 
2022-07-08 03:23:24,760: ============================================================
2022-07-08 03:23:24,760: Epoch 22/36 Batch 2500/7662 eta: 23:01:16.896514	Training Loss1 2.9225 (2.9204)	Training Total_Loss 2.9225 (2.9204)	Training Prec@1 98.438 (98.943)	Training Prec@5 0.000 (0.000)	
2022-07-08 03:23:24,761: ============================================================
2022-07-08 03:24:38,437: time cost, forward:0.011529901019423318, backward:0.033721887042495825, data cost:0.7006710331547301 
2022-07-08 03:24:38,437: ============================================================
2022-07-08 03:24:38,437: Epoch 22/36 Batch 2600/7662 eta: 22:59:21.872028	Training Loss1 3.0881 (2.9216)	Training Total_Loss 3.0881 (2.9216)	Training Prec@1 98.633 (98.940)	Training Prec@5 0.000 (0.000)	
2022-07-08 03:24:38,437: ============================================================
2022-07-08 03:25:52,584: time cost, forward:0.011544757262120736, backward:0.03371556744216857, data cost:0.7004767067567558 
2022-07-08 03:25:52,585: ============================================================
2022-07-08 03:25:52,585: Epoch 22/36 Batch 2700/7662 eta: 23:06:56.713830	Training Loss1 2.7934 (2.9230)	Training Total_Loss 2.7934 (2.9230)	Training Prec@1 99.219 (98.937)	Training Prec@5 0.000 (0.000)	
2022-07-08 03:25:52,585: ============================================================
2022-07-08 03:27:05,715: time cost, forward:0.011533812481661106, backward:0.0337198154548953, data cost:0.6999377223073094 
2022-07-08 03:27:05,715: ============================================================
2022-07-08 03:27:05,715: Epoch 22/36 Batch 2800/7662 eta: 22:46:41.600667	Training Loss1 2.4932 (2.9235)	Training Total_Loss 2.4932 (2.9235)	Training Prec@1 99.414 (98.937)	Training Prec@5 0.000 (0.000)	
2022-07-08 03:27:05,715: ============================================================
2022-07-08 03:28:19,581: time cost, forward:0.011555678929160816, backward:0.033732541308973775, data cost:0.6996609120995639 
2022-07-08 03:28:19,582: ============================================================
2022-07-08 03:28:19,582: Epoch 22/36 Batch 2900/7662 eta: 22:59:13.958651	Training Loss1 2.9985 (2.9250)	Training Total_Loss 2.9985 (2.9250)	Training Prec@1 98.438 (98.935)	Training Prec@5 0.000 (0.000)	
2022-07-08 03:28:19,582: ============================================================
2022-07-08 03:29:33,641: time cost, forward:0.011556038501939205, backward:0.03373203423866712, data cost:0.6994875952894587 
2022-07-08 03:29:33,642: ============================================================
2022-07-08 03:29:33,642: Epoch 22/36 Batch 3000/7662 eta: 23:01:35.946957	Training Loss1 2.9823 (2.9266)	Training Total_Loss 2.9823 (2.9266)	Training Prec@1 100.000 (98.932)	Training Prec@5 0.000 (0.000)	
2022-07-08 03:29:33,642: ============================================================
2022-07-08 03:30:47,451: time cost, forward:0.011539646485960457, backward:0.03375734418159379, data cost:0.6992476197279973 
2022-07-08 03:30:47,451: ============================================================
2022-07-08 03:30:47,451: Epoch 22/36 Batch 3100/7662 eta: 22:55:41.343607	Training Loss1 3.1572 (2.9283)	Training Total_Loss 3.1572 (2.9283)	Training Prec@1 99.023 (98.929)	Training Prec@5 0.000 (0.000)	
2022-07-08 03:30:47,451: ============================================================
2022-07-08 03:32:00,833: time cost, forward:0.011576482898632263, backward:0.03374166360457415, data cost:0.6988717221811288 
2022-07-08 03:32:00,833: ============================================================
2022-07-08 03:32:00,833: Epoch 22/36 Batch 3200/7662 eta: 22:46:30.885655	Training Loss1 2.9283 (2.9292)	Training Total_Loss 2.9283 (2.9292)	Training Prec@1 99.219 (98.927)	Training Prec@5 0.000 (0.000)	
2022-07-08 03:32:00,834: ============================================================
2022-07-08 03:33:15,184: time cost, forward:0.01159628776753805, backward:0.03371105262025554, data cost:0.6988341248949645 
2022-07-08 03:33:15,185: ============================================================
2022-07-08 03:33:15,185: Epoch 22/36 Batch 3300/7662 eta: 23:03:19.263386	Training Loss1 2.9933 (2.9312)	Training Total_Loss 2.9933 (2.9312)	Training Prec@1 99.023 (98.925)	Training Prec@5 0.000 (0.000)	
2022-07-08 03:33:15,185: ============================================================
2022-07-08 03:34:28,606: time cost, forward:0.011583028382573208, backward:0.033700263510735184, data cost:0.6985552240799862 
2022-07-08 03:34:28,607: ============================================================
2022-07-08 03:34:28,607: Epoch 22/36 Batch 3400/7662 eta: 22:44:48.224532	Training Loss1 2.7764 (2.9323)	Training Total_Loss 2.7764 (2.9323)	Training Prec@1 99.023 (98.926)	Training Prec@5 0.000 (0.000)	
2022-07-08 03:34:28,607: ============================================================
2022-07-08 03:35:42,785: time cost, forward:0.011602233498053538, backward:0.03369020414066233, data cost:0.6984823481905083 
2022-07-08 03:35:42,785: ============================================================
2022-07-08 03:35:42,786: Epoch 22/36 Batch 3500/7662 eta: 22:57:38.067430	Training Loss1 2.8316 (2.9324)	Training Total_Loss 2.8316 (2.9324)	Training Prec@1 99.023 (98.925)	Training Prec@5 0.000 (0.000)	
2022-07-08 03:35:42,786: ============================================================
2022-07-08 03:36:56,696: time cost, forward:0.011607180373077095, backward:0.03369407423273263, data cost:0.6983325024981338 
2022-07-08 03:36:56,696: ============================================================
2022-07-08 03:36:56,696: Epoch 22/36 Batch 3600/7662 eta: 22:51:25.824104	Training Loss1 2.9996 (2.9338)	Training Total_Loss 2.9996 (2.9338)	Training Prec@1 99.414 (98.922)	Training Prec@5 0.000 (0.000)	
2022-07-08 03:36:56,697: ============================================================
2022-07-08 03:38:10,340: time cost, forward:0.01159575301977582, backward:0.03369618003579145, data cost:0.6981284449505916 
2022-07-08 03:38:10,341: ============================================================
2022-07-08 03:38:10,341: Epoch 22/36 Batch 3700/7662 eta: 22:45:15.439559	Training Loss1 3.2258 (2.9344)	Training Total_Loss 3.2258 (2.9344)	Training Prec@1 98.828 (98.923)	Training Prec@5 0.000 (0.000)	
2022-07-08 03:38:10,341: ============================================================
2022-07-08 03:39:24,444: time cost, forward:0.011622876423099976, backward:0.033698903663938504, data cost:0.6980016666451515 
2022-07-08 03:39:24,444: ============================================================
2022-07-08 03:39:24,445: Epoch 22/36 Batch 3800/7662 eta: 22:52:32.008419	Training Loss1 3.0591 (2.9357)	Training Total_Loss 3.0591 (2.9357)	Training Prec@1 98.633 (98.920)	Training Prec@5 0.000 (0.000)	
2022-07-08 03:39:24,445: ============================================================
2022-07-08 03:40:37,082: time cost, forward:0.011655887171805716, backward:0.0336968382678603, data cost:0.6975341082291898 
2022-07-08 03:40:37,083: ============================================================
2022-07-08 03:40:37,083: Epoch 22/36 Batch 3900/7662 eta: 22:24:11.040603	Training Loss1 2.9667 (2.9366)	Training Total_Loss 2.9667 (2.9366)	Training Prec@1 98.828 (98.918)	Training Prec@5 0.000 (0.000)	
2022-07-08 03:40:37,083: ============================================================
2022-07-08 03:41:50,611: time cost, forward:0.011680755534151788, backward:0.03369354319351856, data cost:0.6973025202602111 
2022-07-08 03:41:50,612: ============================================================
2022-07-08 03:41:50,612: Epoch 22/36 Batch 4000/7662 eta: 22:39:26.388125	Training Loss1 2.5595 (2.9375)	Training Total_Loss 2.5595 (2.9375)	Training Prec@1 99.805 (98.919)	Training Prec@5 0.000 (0.000)	
2022-07-08 03:41:50,612: ============================================================
2022-07-08 03:43:05,203: time cost, forward:0.01168374905908477, backward:0.03369406666165883, data cost:0.6973611566316037 
2022-07-08 03:43:05,203: ============================================================
2022-07-08 03:43:05,204: Epoch 22/36 Batch 4100/7662 eta: 22:57:50.912082	Training Loss1 2.7759 (2.9387)	Training Total_Loss 2.7759 (2.9387)	Training Prec@1 99.023 (98.919)	Training Prec@5 0.000 (0.000)	
2022-07-08 03:43:05,204: ============================================================
2022-07-08 03:44:19,787: time cost, forward:0.011688214649782773, backward:0.03368378571312494, data cost:0.6974147660699905 
2022-07-08 03:44:19,788: ============================================================
2022-07-08 03:44:19,788: Epoch 22/36 Batch 4200/7662 eta: 22:56:28.039224	Training Loss1 2.6990 (2.9395)	Training Total_Loss 2.6990 (2.9395)	Training Prec@1 99.805 (98.918)	Training Prec@5 0.000 (0.000)	
2022-07-08 03:44:19,788: ============================================================
2022-07-08 03:45:33,462: time cost, forward:0.01171375496716354, backward:0.03366392372541301, data cost:0.6972665251008464 
2022-07-08 03:45:33,462: ============================================================
2022-07-08 03:45:33,462: Epoch 22/36 Batch 4300/7662 eta: 22:38:26.670174	Training Loss1 3.1809 (2.9411)	Training Total_Loss 3.1809 (2.9411)	Training Prec@1 99.219 (98.916)	Training Prec@5 0.000 (0.000)	
2022-07-08 03:45:33,462: ============================================================
2022-07-08 03:46:46,483: time cost, forward:0.011733081726140123, backward:0.03365850632882817, data cost:0.6969533064712798 
2022-07-08 03:46:46,484: ============================================================
2022-07-08 03:46:46,484: Epoch 22/36 Batch 4400/7662 eta: 22:25:11.493373	Training Loss1 3.0652 (2.9420)	Training Total_Loss 3.0652 (2.9420)	Training Prec@1 98.242 (98.914)	Training Prec@5 0.000 (0.000)	
2022-07-08 03:46:46,484: ============================================================
2022-07-08 03:48:00,084: time cost, forward:0.011765938171892067, backward:0.033647320487282494, data cost:0.6967765547270561 
2022-07-08 03:48:00,084: ============================================================
2022-07-08 03:48:00,084: Epoch 22/36 Batch 4500/7662 eta: 22:34:37.783280	Training Loss1 2.9698 (2.9434)	Training Total_Loss 2.9698 (2.9434)	Training Prec@1 99.219 (98.913)	Training Prec@5 0.000 (0.000)	
2022-07-08 03:48:00,085: ============================================================
2022-07-08 03:49:13,896: time cost, forward:0.011762098064368693, backward:0.03363890242488469, data cost:0.6966421635779746 
2022-07-08 03:49:13,896: ============================================================
2022-07-08 03:49:13,896: Epoch 22/36 Batch 4600/7662 eta: 22:37:17.287065	Training Loss1 3.1252 (2.9442)	Training Total_Loss 3.1252 (2.9442)	Training Prec@1 98.633 (98.912)	Training Prec@5 0.000 (0.000)	
2022-07-08 03:49:13,896: ============================================================
2022-07-08 03:50:27,043: time cost, forward:0.011752926001880595, backward:0.0336339887240309, data cost:0.696465047985271 
2022-07-08 03:50:27,043: ============================================================
2022-07-08 03:50:27,043: Epoch 22/36 Batch 4700/7662 eta: 22:23:50.637326	Training Loss1 2.9508 (2.9452)	Training Total_Loss 2.9508 (2.9452)	Training Prec@1 98.438 (98.911)	Training Prec@5 0.000 (0.000)	
2022-07-08 03:50:27,043: ============================================================
2022-07-08 03:51:40,295: time cost, forward:0.011738065233526688, backward:0.033641544971199776, data cost:0.6962617260884633 
2022-07-08 03:51:40,295: ============================================================
2022-07-08 03:51:40,295: Epoch 22/36 Batch 4800/7662 eta: 22:24:33.070423	Training Loss1 2.9074 (2.9463)	Training Total_Loss 2.9074 (2.9463)	Training Prec@1 99.414 (98.909)	Training Prec@5 0.000 (0.000)	
2022-07-08 03:51:40,295: ============================================================
2022-07-08 03:52:53,576: time cost, forward:0.01173616837764132, backward:0.03362827769199861, data cost:0.6960914831887608 
2022-07-08 03:52:53,577: ============================================================
2022-07-08 03:52:53,577: Epoch 22/36 Batch 4900/7662 eta: 22:23:52.468375	Training Loss1 3.0895 (2.9472)	Training Total_Loss 3.0895 (2.9472)	Training Prec@1 99.219 (98.908)	Training Prec@5 0.000 (0.000)	
2022-07-08 03:52:53,577: ============================================================
2022-07-08 03:54:08,173: time cost, forward:0.011734153728862839, backward:0.033632230367582304, data cost:0.69612171125784 
2022-07-08 03:54:08,173: ============================================================
2022-07-08 03:54:08,173: Epoch 22/36 Batch 5000/7662 eta: 22:46:44.599174	Training Loss1 2.7447 (2.9479)	Training Total_Loss 2.7447 (2.9479)	Training Prec@1 99.805 (98.907)	Training Prec@5 0.000 (0.000)	
2022-07-08 03:54:08,173: ============================================================
2022-07-08 03:55:21,772: time cost, forward:0.01173352821127156, backward:0.033635302650435205, data cost:0.6960229622099675 
2022-07-08 03:55:21,772: ============================================================
2022-07-08 03:55:21,772: Epoch 22/36 Batch 5100/7662 eta: 22:27:14.617171	Training Loss1 2.7624 (2.9493)	Training Total_Loss 2.7624 (2.9493)	Training Prec@1 99.414 (98.906)	Training Prec@5 0.000 (0.000)	
2022-07-08 03:55:21,772: ============================================================
2022-07-08 03:56:35,527: time cost, forward:0.011734469346436979, backward:0.03364624103965106, data cost:0.6959381523121319 
2022-07-08 03:56:35,527: ============================================================
2022-07-08 03:56:35,528: Epoch 22/36 Batch 5200/7662 eta: 22:28:52.396113	Training Loss1 3.0584 (2.9504)	Training Total_Loss 3.0584 (2.9504)	Training Prec@1 99.414 (98.905)	Training Prec@5 0.000 (0.000)	
2022-07-08 03:56:35,528: ============================================================
2022-07-08 03:57:49,162: time cost, forward:0.011734921294667851, backward:0.03364520114330689, data cost:0.6958363050333755 
2022-07-08 03:57:49,163: ============================================================
2022-07-08 03:57:49,163: Epoch 22/36 Batch 5300/7662 eta: 22:25:27.048743	Training Loss1 3.1506 (2.9513)	Training Total_Loss 3.1506 (2.9513)	Training Prec@1 99.023 (98.903)	Training Prec@5 0.000 (0.000)	
2022-07-08 03:57:49,163: ============================================================
2022-07-08 03:59:03,004: time cost, forward:0.011746005275377986, backward:0.03364234558850179, data cost:0.6957695566740141 
2022-07-08 03:59:03,005: ============================================================
2022-07-08 03:59:03,005: Epoch 22/36 Batch 5400/7662 eta: 22:28:00.266997	Training Loss1 3.0349 (2.9522)	Training Total_Loss 3.0349 (2.9522)	Training Prec@1 99.023 (98.901)	Training Prec@5 0.000 (0.000)	
2022-07-08 03:59:03,005: ============================================================
2022-07-08 04:00:17,953: time cost, forward:0.011743488388075398, backward:0.03365995810668801, data cost:0.6958912211041989 
2022-07-08 04:00:17,954: ============================================================
2022-07-08 04:00:17,954: Epoch 22/36 Batch 5500/7662 eta: 22:46:57.262646	Training Loss1 3.1755 (2.9533)	Training Total_Loss 3.1755 (2.9533)	Training Prec@1 99.023 (98.900)	Training Prec@5 0.000 (0.000)	
2022-07-08 04:00:17,954: ============================================================
2022-07-08 04:01:31,826: time cost, forward:0.011742422593067875, backward:0.03366751814765746, data cost:0.6958270676754739 
2022-07-08 04:01:31,827: ============================================================
2022-07-08 04:01:31,827: Epoch 22/36 Batch 5600/7662 eta: 22:26:06.016020	Training Loss1 2.9864 (2.9541)	Training Total_Loss 2.9864 (2.9541)	Training Prec@1 98.828 (98.898)	Training Prec@5 0.000 (0.000)	
2022-07-08 04:01:31,827: ============================================================
2022-07-08 04:02:45,508: time cost, forward:0.011729473774005163, backward:0.03366165990305692, data cost:0.69574603977528 
2022-07-08 04:02:45,509: ============================================================
2022-07-08 04:02:45,509: Epoch 22/36 Batch 5700/7662 eta: 22:21:23.576740	Training Loss1 2.9282 (2.9551)	Training Total_Loss 2.9282 (2.9551)	Training Prec@1 98.828 (98.898)	Training Prec@5 0.000 (0.000)	
2022-07-08 04:02:45,509: ============================================================
2022-07-08 04:03:58,416: time cost, forward:0.011728284152998434, backward:0.03365442727758753, data cost:0.695547683585572 
2022-07-08 04:03:58,416: ============================================================
2022-07-08 04:03:58,416: Epoch 22/36 Batch 5800/7662 eta: 22:06:04.404674	Training Loss1 2.8382 (2.9561)	Training Total_Loss 2.8382 (2.9561)	Training Prec@1 99.023 (98.896)	Training Prec@5 0.000 (0.000)	
2022-07-08 04:03:58,416: ============================================================
2022-07-08 04:05:12,047: time cost, forward:0.011735830090372901, backward:0.03364188272198452, data cost:0.695465700811078 
2022-07-08 04:05:12,047: ============================================================
2022-07-08 04:05:12,048: Epoch 22/36 Batch 5900/7662 eta: 22:18:00.956970	Training Loss1 3.0911 (2.9574)	Training Total_Loss 3.0911 (2.9574)	Training Prec@1 99.414 (98.894)	Training Prec@5 0.000 (0.000)	
2022-07-08 04:05:12,048: ============================================================
2022-07-08 04:06:26,143: time cost, forward:0.011745821259224052, backward:0.03361757522146788, data cost:0.6954668326106821 
2022-07-08 04:06:26,143: ============================================================
2022-07-08 04:06:26,143: Epoch 22/36 Batch 6000/7662 eta: 22:25:13.297892	Training Loss1 3.0931 (2.9584)	Training Total_Loss 3.0931 (2.9584)	Training Prec@1 98.242 (98.891)	Training Prec@5 0.000 (0.000)	
2022-07-08 04:06:26,143: ============================================================
2022-07-08 04:07:40,239: time cost, forward:0.011744761939986179, backward:0.03359979456576153, data cost:0.695480469270385 
2022-07-08 04:07:40,239: ============================================================
2022-07-08 04:07:40,240: Epoch 22/36 Batch 6100/7662 eta: 22:23:59.737124	Training Loss1 3.2328 (2.9593)	Training Total_Loss 3.2328 (2.9593)	Training Prec@1 98.242 (98.889)	Training Prec@5 0.000 (0.000)	
2022-07-08 04:07:40,240: ============================================================
2022-07-08 04:08:53,973: time cost, forward:0.01174210340558646, backward:0.033604637194610563, data cost:0.6954140340076145 
2022-07-08 04:08:53,973: ============================================================
2022-07-08 04:08:53,974: Epoch 22/36 Batch 6200/7662 eta: 22:16:11.746094	Training Loss1 3.1840 (2.9602)	Training Total_Loss 3.1840 (2.9602)	Training Prec@1 97.656 (98.888)	Training Prec@5 0.000 (0.000)	
2022-07-08 04:08:53,974: ============================================================
2022-07-08 04:10:08,534: time cost, forward:0.011743415327446103, backward:0.03359914087155335, data cost:0.6954880060894487 
2022-07-08 04:10:08,534: ============================================================
2022-07-08 04:10:08,534: Epoch 22/36 Batch 6300/7662 eta: 22:29:55.943303	Training Loss1 2.9703 (2.9611)	Training Total_Loss 2.9703 (2.9611)	Training Prec@1 97.656 (98.886)	Training Prec@5 0.000 (0.000)	
2022-07-08 04:10:08,534: ============================================================
2022-07-08 04:11:22,740: time cost, forward:0.0117460618001965, backward:0.03359658823551322, data cost:0.6954932912548439 
2022-07-08 04:11:22,740: ============================================================
2022-07-08 04:11:22,740: Epoch 22/36 Batch 6400/7662 eta: 22:22:16.658862	Training Loss1 2.8693 (2.9623)	Training Total_Loss 2.8693 (2.9623)	Training Prec@1 99.219 (98.885)	Training Prec@5 0.000 (0.000)	
2022-07-08 04:11:22,741: ============================================================
2022-07-08 04:12:36,275: time cost, forward:0.011751945577487337, backward:0.03359632291029299, data cost:0.6953972310428529 
2022-07-08 04:12:36,276: ============================================================
2022-07-08 04:12:36,276: Epoch 22/36 Batch 6500/7662 eta: 22:08:55.269786	Training Loss1 2.9847 (2.9630)	Training Total_Loss 2.9847 (2.9630)	Training Prec@1 98.242 (98.884)	Training Prec@5 0.000 (0.000)	
2022-07-08 04:12:36,276: ============================================================
2022-07-08 04:13:50,469: time cost, forward:0.011755900051326783, backward:0.03359739801019841, data cost:0.6954039776572712 
2022-07-08 04:13:50,469: ============================================================
2022-07-08 04:13:50,469: Epoch 22/36 Batch 6600/7662 eta: 22:19:34.412794	Training Loss1 3.1332 (2.9634)	Training Total_Loss 3.1332 (2.9634)	Training Prec@1 98.047 (98.883)	Training Prec@5 0.000 (0.000)	
2022-07-08 04:13:50,469: ============================================================
2022-07-08 04:15:04,345: time cost, forward:0.011760375734264592, backward:0.033577954240620426, data cost:0.6953756444791233 
2022-07-08 04:15:04,346: ============================================================
2022-07-08 04:15:04,346: Epoch 22/36 Batch 6700/7662 eta: 22:12:37.397684	Training Loss1 2.9371 (2.9643)	Training Total_Loss 2.9371 (2.9643)	Training Prec@1 98.242 (98.881)	Training Prec@5 0.000 (0.000)	
2022-07-08 04:15:04,346: ============================================================
2022-07-08 04:16:18,303: time cost, forward:0.011773213864705338, backward:0.033570002169973065, data cost:0.6953348458418164 
2022-07-08 04:16:18,304: ============================================================
2022-07-08 04:16:18,304: Epoch 22/36 Batch 6800/7662 eta: 22:12:51.344973	Training Loss1 3.0405 (2.9652)	Training Total_Loss 3.0405 (2.9652)	Training Prec@1 98.633 (98.879)	Training Prec@5 0.000 (0.000)	
2022-07-08 04:16:18,304: ============================================================
2022-07-08 04:17:33,248: time cost, forward:0.011785956288890781, backward:0.033562749723607795, data cost:0.6954562713104947 
2022-07-08 04:17:33,249: ============================================================
2022-07-08 04:17:33,249: Epoch 22/36 Batch 6900/7662 eta: 22:29:23.857604	Training Loss1 2.8359 (2.9659)	Training Total_Loss 2.8359 (2.9659)	Training Prec@1 98.828 (98.878)	Training Prec@5 0.000 (0.000)	
2022-07-08 04:17:33,249: ============================================================
2022-07-08 04:18:48,378: time cost, forward:0.01179463557812772, backward:0.03357837281579341, data cost:0.6955720841807967 
2022-07-08 04:18:48,378: ============================================================
2022-07-08 04:18:48,379: Epoch 22/36 Batch 7000/7662 eta: 22:31:28.371288	Training Loss1 2.8451 (2.9666)	Training Total_Loss 2.8451 (2.9666)	Training Prec@1 99.219 (98.875)	Training Prec@5 0.000 (0.000)	
2022-07-08 04:18:48,379: ============================================================
2022-07-08 04:20:03,128: time cost, forward:0.011908894543043912, backward:0.033589265870114314, data cost:0.6955308035941741 
2022-07-08 04:20:03,128: ============================================================
2022-07-08 04:20:03,128: Epoch 22/36 Batch 7100/7662 eta: 22:23:23.273755	Training Loss1 3.0226 (2.9675)	Training Total_Loss 3.0226 (2.9675)	Training Prec@1 98.047 (98.874)	Training Prec@5 0.000 (0.000)	
2022-07-08 04:20:03,128: ============================================================
2022-07-08 04:21:18,036: time cost, forward:0.011913718473813586, backward:0.033588449298250854, data cost:0.6956315192601336 
2022-07-08 04:21:18,051: ============================================================
2022-07-08 04:21:18,051: Epoch 22/36 Batch 7200/7662 eta: 22:25:15.475746	Training Loss1 3.2512 (2.9684)	Training Total_Loss 3.2512 (2.9684)	Training Prec@1 99.219 (98.872)	Training Prec@5 0.000 (0.000)	
2022-07-08 04:21:18,052: ============================================================
2022-07-08 04:22:32,452: time cost, forward:0.011909058623517077, backward:0.03358707517479394, data cost:0.6956638582341719 
2022-07-08 04:22:32,453: ============================================================
2022-07-08 04:22:32,453: Epoch 22/36 Batch 7300/7662 eta: 22:14:39.370732	Training Loss1 3.0193 (2.9691)	Training Total_Loss 3.0193 (2.9691)	Training Prec@1 98.828 (98.872)	Training Prec@5 0.000 (0.000)	
2022-07-08 04:22:32,453: ============================================================
2022-07-08 04:23:46,510: time cost, forward:0.011904371446943843, backward:0.03358564146113792, data cost:0.6956619124651632 
2022-07-08 04:23:46,510: ============================================================
2022-07-08 04:23:46,510: Epoch 22/36 Batch 7400/7662 eta: 22:07:14.345647	Training Loss1 2.9478 (2.9700)	Training Total_Loss 2.9478 (2.9700)	Training Prec@1 99.023 (98.870)	Training Prec@5 0.000 (0.000)	
2022-07-08 04:23:46,510: ============================================================
2022-07-08 04:25:01,394: time cost, forward:0.011906097214736053, backward:0.03358738205244993, data cost:0.6957557169274181 
2022-07-08 04:25:01,395: ============================================================
2022-07-08 04:25:01,395: Epoch 22/36 Batch 7500/7662 eta: 22:20:49.158515	Training Loss1 2.9491 (2.9707)	Training Total_Loss 2.9491 (2.9707)	Training Prec@1 99.414 (98.869)	Training Prec@5 0.000 (0.000)	
2022-07-08 04:25:01,395: ============================================================
2022-07-08 04:26:16,483: time cost, forward:0.011908939973761148, backward:0.03360105113051944, data cost:0.6958538138375406 
2022-07-08 04:26:16,483: ============================================================
2022-07-08 04:26:16,483: Epoch 22/36 Batch 7600/7662 eta: 22:23:13.398663	Training Loss1 3.0654 (2.9716)	Training Total_Loss 3.0654 (2.9716)	Training Prec@1 98.242 (98.868)	Training Prec@5 0.000 (0.000)	
2022-07-08 04:26:16,484: ============================================================
2022-07-08 04:27:04,579: Epoch 22/36 Batch 7663/7662 eta: 22:22:26.092814	Training Loss1 3.1455 (2.9722)	Training Total_Loss 3.1455 (2.9722)	Training Prec@1 98.438 (98.868)	Training Prec@5 0.000 (0.000)	
2022-07-08 04:27:04,579: ============================================================
2022-07-08 04:28:39,725: time cost, forward:0.011464672859268958, backward:0.03214759296841092, data cost:0.9083643946984802 
2022-07-08 04:28:39,725: ============================================================
2022-07-08 04:28:39,725: Epoch 23/36 Batch 100/7662 eta: 1 day, 4:14:46.717709	Training Loss1 2.6608 (2.8038)	Training Total_Loss 2.6608 (2.8038)	Training Prec@1 99.414 (99.112)	Training Prec@5 0.000 (0.000)	
2022-07-08 04:28:39,725: ============================================================
2022-07-08 04:29:54,689: time cost, forward:0.01132625670888316, backward:0.032591629267936975, data cost:0.8062550410553438 
2022-07-08 04:29:54,689: ============================================================
2022-07-08 04:29:54,690: Epoch 23/36 Batch 200/7662 eta: 22:17:43.550529	Training Loss1 2.6537 (2.8169)	Training Total_Loss 2.6537 (2.8169)	Training Prec@1 99.609 (99.117)	Training Prec@5 0.000 (0.000)	
2022-07-08 04:29:54,690: ============================================================
2022-07-08 04:31:08,573: time cost, forward:0.011023969554582168, backward:0.033114681275791945, data cost:0.7685794798426804 
2022-07-08 04:31:08,574: ============================================================
2022-07-08 04:31:08,574: Epoch 23/36 Batch 300/7662 eta: 21:57:13.410095	Training Loss1 2.7723 (2.8193)	Training Total_Loss 2.7723 (2.8193)	Training Prec@1 98.828 (99.106)	Training Prec@5 0.000 (0.000)	
2022-07-08 04:31:08,574: ============================================================
2022-07-08 04:32:23,249: time cost, forward:0.010850406828380767, backward:0.03339374095276185, data cost:0.7518431751949147 
2022-07-08 04:32:23,250: ============================================================
2022-07-08 04:32:23,250: Epoch 23/36 Batch 400/7662 eta: 22:10:05.297100	Training Loss1 2.7079 (2.8213)	Training Total_Loss 2.7079 (2.8213)	Training Prec@1 99.414 (99.105)	Training Prec@5 0.000 (0.000)	
2022-07-08 04:32:23,250: ============================================================
2022-07-08 04:33:37,734: time cost, forward:0.010871255087231347, backward:0.03354611616574213, data cost:0.7410813644080458 
2022-07-08 04:33:37,734: ============================================================
2022-07-08 04:33:37,734: Epoch 23/36 Batch 500/7662 eta: 22:05:26.648472	Training Loss1 2.8792 (2.8261)	Training Total_Loss 2.8792 (2.8261)	Training Prec@1 99.609 (99.100)	Training Prec@5 0.000 (0.000)	
2022-07-08 04:33:37,735: ============================================================
2022-07-08 04:34:51,212: time cost, forward:0.011042498586969901, backward:0.03365805869508466, data cost:0.7323413344973912 
2022-07-08 04:34:51,212: ============================================================
2022-07-08 04:34:51,212: Epoch 23/36 Batch 600/7662 eta: 21:46:17.919670	Training Loss1 2.9112 (2.8270)	Training Total_Loss 2.9112 (2.8270)	Training Prec@1 98.828 (99.106)	Training Prec@5 0.000 (0.000)	
2022-07-08 04:34:51,212: ============================================================
2022-07-08 04:36:04,603: time cost, forward:0.011113037537778056, backward:0.033860066417972415, data cost:0.7258191262191969 
2022-07-08 04:36:04,604: ============================================================
2022-07-08 04:36:04,604: Epoch 23/36 Batch 700/7662 eta: 21:43:32.796993	Training Loss1 2.8350 (2.8287)	Training Total_Loss 2.8350 (2.8287)	Training Prec@1 99.219 (99.099)	Training Prec@5 0.000 (0.000)	
2022-07-08 04:36:04,604: ============================================================
2022-07-08 04:37:17,331: time cost, forward:0.011100802164949075, backward:0.0338774565910368, data cost:0.7202813249356457 
2022-07-08 04:37:17,332: ============================================================
2022-07-08 04:37:17,332: Epoch 23/36 Batch 800/7662 eta: 21:30:32.746572	Training Loss1 2.8522 (2.8322)	Training Total_Loss 2.8522 (2.8322)	Training Prec@1 100.000 (99.106)	Training Prec@5 0.000 (0.000)	
2022-07-08 04:37:17,332: ============================================================
2022-07-08 04:38:30,894: time cost, forward:0.011245038008132952, backward:0.03390340041265604, data cost:0.7167365519170369 
2022-07-08 04:38:30,894: ============================================================
2022-07-08 04:38:30,894: Epoch 23/36 Batch 900/7662 eta: 21:44:07.498829	Training Loss1 2.8887 (2.8352)	Training Total_Loss 2.8887 (2.8352)	Training Prec@1 99.219 (99.095)	Training Prec@5 0.000 (0.000)	
2022-07-08 04:38:30,894: ============================================================
2022-07-08 04:39:43,868: time cost, forward:0.011383487178279354, backward:0.03376148126504801, data cost:0.7134590378036728 
2022-07-08 04:39:43,868: ============================================================
2022-07-08 04:39:43,868: Epoch 23/36 Batch 1000/7662 eta: 21:32:28.640970	Training Loss1 2.8873 (2.8358)	Training Total_Loss 2.8873 (2.8358)	Training Prec@1 99.609 (99.094)	Training Prec@5 0.000 (0.000)	
2022-07-08 04:39:43,868: ============================================================
2022-07-08 04:40:57,648: time cost, forward:0.011511239059628737, backward:0.03366188812082306, data cost:0.7114915841270079 
2022-07-08 04:40:57,648: ============================================================
2022-07-08 04:40:57,649: Epoch 23/36 Batch 1100/7662 eta: 21:45:31.950885	Training Loss1 2.6729 (2.8362)	Training Total_Loss 2.6729 (2.8362)	Training Prec@1 99.414 (99.097)	Training Prec@5 0.000 (0.000)	
2022-07-08 04:40:57,649: ============================================================
2022-07-08 04:42:11,499: time cost, forward:0.011608722311342827, backward:0.0335869799065928, data cost:0.7098865910705872 
2022-07-08 04:42:11,499: ============================================================
2022-07-08 04:42:11,499: Epoch 23/36 Batch 1200/7662 eta: 21:45:32.899672	Training Loss1 2.8980 (2.8398)	Training Total_Loss 2.8980 (2.8398)	Training Prec@1 99.609 (99.092)	Training Prec@5 0.000 (0.000)	
2022-07-08 04:42:11,499: ============================================================
2022-07-08 04:43:24,962: time cost, forward:0.011626296634395092, backward:0.03359495831783961, data cost:0.7082874987839368 
2022-07-08 04:43:24,962: ============================================================
2022-07-08 04:43:24,962: Epoch 23/36 Batch 1300/7662 eta: 21:37:27.693247	Training Loss1 2.7264 (2.8415)	Training Total_Loss 2.7264 (2.8415)	Training Prec@1 99.023 (99.087)	Training Prec@5 0.000 (0.000)	
2022-07-08 04:43:24,962: ============================================================
2022-07-08 04:44:37,769: time cost, forward:0.01169186596192148, backward:0.033628843272047605, data cost:0.7063075333854997 
2022-07-08 04:44:37,769: ============================================================
2022-07-08 04:44:37,769: Epoch 23/36 Batch 1400/7662 eta: 21:24:40.235085	Training Loss1 2.8587 (2.8439)	Training Total_Loss 2.8587 (2.8439)	Training Prec@1 98.438 (99.087)	Training Prec@5 0.000 (0.000)	
2022-07-08 04:44:37,769: ============================================================
2022-07-08 04:45:51,372: time cost, forward:0.011746307943088362, backward:0.033626918875431525, data cost:0.7051841568517399 
2022-07-08 04:45:51,373: ============================================================
2022-07-08 04:45:51,373: Epoch 23/36 Batch 1500/7662 eta: 21:37:29.618468	Training Loss1 2.9700 (2.8462)	Training Total_Loss 2.9700 (2.8462)	Training Prec@1 98.242 (99.088)	Training Prec@5 0.000 (0.000)	
2022-07-08 04:45:51,373: ============================================================
2022-07-08 04:47:05,400: time cost, forward:0.01176575648180763, backward:0.033585350687910874, data cost:0.7045099119457175 
2022-07-08 04:47:05,401: ============================================================
2022-07-08 04:47:05,401: Epoch 23/36 Batch 1600/7662 eta: 21:43:44.749728	Training Loss1 2.8559 (2.8489)	Training Total_Loss 2.8559 (2.8489)	Training Prec@1 98.828 (99.082)	Training Prec@5 0.000 (0.000)	
2022-07-08 04:47:05,401: ============================================================
2022-07-08 04:48:20,159: time cost, forward:0.01179250202998475, backward:0.03363514297355127, data cost:0.7042903365493873 
2022-07-08 04:48:20,159: ============================================================
2022-07-08 04:48:20,159: Epoch 23/36 Batch 1700/7662 eta: 21:55:21.863894	Training Loss1 2.6444 (2.8510)	Training Total_Loss 2.6444 (2.8510)	Training Prec@1 99.609 (99.078)	Training Prec@5 0.000 (0.000)	
2022-07-08 04:48:20,159: ============================================================
2022-07-08 04:49:33,180: time cost, forward:0.011805525880975814, backward:0.03365947313610881, data cost:0.7030991052772815 
2022-07-08 04:49:33,180: ============================================================
2022-07-08 04:49:33,180: Epoch 23/36 Batch 1800/7662 eta: 21:23:34.116564	Training Loss1 3.0502 (2.8534)	Training Total_Loss 3.0502 (2.8534)	Training Prec@1 99.219 (99.074)	Training Prec@5 0.000 (0.000)	
2022-07-08 04:49:33,180: ============================================================
2022-07-08 04:50:45,890: time cost, forward:0.011791262644224886, backward:0.033669978082023086, data cost:0.7019510766341223 
2022-07-08 04:50:45,890: ============================================================
2022-07-08 04:50:45,890: Epoch 23/36 Batch 1900/7662 eta: 21:16:54.164459	Training Loss1 2.8438 (2.8558)	Training Total_Loss 2.8438 (2.8558)	Training Prec@1 98.047 (99.072)	Training Prec@5 0.000 (0.000)	
2022-07-08 04:50:45,890: ============================================================
2022-07-08 04:51:59,916: time cost, forward:0.011786122271989571, backward:0.03368383565504829, data cost:0.7015719289717643 
2022-07-08 04:51:59,916: ============================================================
2022-07-08 04:51:59,917: Epoch 23/36 Batch 2000/7662 eta: 21:38:46.664631	Training Loss1 2.8115 (2.8581)	Training Total_Loss 2.8115 (2.8581)	Training Prec@1 99.219 (99.070)	Training Prec@5 0.000 (0.000)	
2022-07-08 04:51:59,917: ============================================================
2022-07-08 04:53:13,387: time cost, forward:0.011794925474336795, backward:0.03365081000634748, data cost:0.700983570665902 
2022-07-08 04:53:13,387: ============================================================
2022-07-08 04:53:13,387: Epoch 23/36 Batch 2100/7662 eta: 21:27:48.073792	Training Loss1 2.7941 (2.8586)	Training Total_Loss 2.7941 (2.8586)	Training Prec@1 99.023 (99.070)	Training Prec@5 0.000 (0.000)	
2022-07-08 04:53:13,387: ============================================================
2022-07-08 04:54:26,604: time cost, forward:0.01178933621103409, backward:0.03361484190180606, data cost:0.7003367732144746 
2022-07-08 04:54:26,605: ============================================================
2022-07-08 04:54:26,605: Epoch 23/36 Batch 2200/7662 eta: 21:22:09.338437	Training Loss1 2.6737 (2.8603)	Training Total_Loss 2.6737 (2.8603)	Training Prec@1 98.828 (99.070)	Training Prec@5 0.000 (0.000)	
2022-07-08 04:54:26,605: ============================================================
2022-07-08 04:55:39,761: time cost, forward:0.011780537331088723, backward:0.033635057019585884, data cost:0.6996826198423567 
2022-07-08 04:55:39,761: ============================================================
2022-07-08 04:55:39,762: Epoch 23/36 Batch 2300/7662 eta: 21:19:51.716415	Training Loss1 2.7998 (2.8609)	Training Total_Loss 2.7998 (2.8609)	Training Prec@1 99.023 (99.067)	Training Prec@5 0.000 (0.000)	
2022-07-08 04:55:39,762: ============================================================
2022-07-08 04:56:53,392: time cost, forward:0.011805746047483875, backward:0.033631100859329965, data cost:0.6992775487522127 
2022-07-08 04:56:53,392: ============================================================
2022-07-08 04:56:53,392: Epoch 23/36 Batch 2400/7662 eta: 21:26:55.821154	Training Loss1 2.9086 (2.8622)	Training Total_Loss 2.9086 (2.8622)	Training Prec@1 98.828 (99.063)	Training Prec@5 0.000 (0.000)	
2022-07-08 04:56:53,392: ============================================================
2022-07-08 04:58:07,664: time cost, forward:0.011807153872749051, backward:0.03360615791726847, data cost:0.6991892264527576 
2022-07-08 04:58:07,664: ============================================================
2022-07-08 04:58:07,665: Epoch 23/36 Batch 2500/7662 eta: 21:36:54.441661	Training Loss1 3.0628 (2.8639)	Training Total_Loss 3.0628 (2.8639)	Training Prec@1 99.414 (99.059)	Training Prec@5 0.000 (0.000)	
2022-07-08 04:58:07,665: ============================================================
2022-07-08 04:59:21,844: time cost, forward:0.01181431236795482, backward:0.03362498167800463, data cost:0.6990532720029331 
2022-07-08 04:59:21,845: ============================================================
2022-07-08 04:59:21,845: Epoch 23/36 Batch 2600/7662 eta: 21:34:03.786190	Training Loss1 2.9590 (2.8656)	Training Total_Loss 2.9590 (2.8656)	Training Prec@1 99.414 (99.056)	Training Prec@5 0.000 (0.000)	
2022-07-08 04:59:21,845: ============================================================
2022-07-08 05:00:36,541: time cost, forward:0.01181515299333118, backward:0.03362914454985566, data cost:0.6990830641227459 
2022-07-08 05:00:36,541: ============================================================
2022-07-08 05:00:36,541: Epoch 23/36 Batch 2700/7662 eta: 21:41:49.155030	Training Loss1 2.8778 (2.8675)	Training Total_Loss 2.8778 (2.8675)	Training Prec@1 99.219 (99.055)	Training Prec@5 0.000 (0.000)	
2022-07-08 05:00:36,541: ============================================================
2022-07-08 05:01:50,142: time cost, forward:0.011832593721592158, backward:0.033667063449015995, data cost:0.6986516389986497 
2022-07-08 05:01:50,142: ============================================================
2022-07-08 05:01:50,143: Epoch 23/36 Batch 2800/7662 eta: 21:21:30.631017	Training Loss1 2.8565 (2.8683)	Training Total_Loss 2.8565 (2.8683)	Training Prec@1 98.633 (99.053)	Training Prec@5 0.000 (0.000)	
2022-07-08 05:01:50,143: ============================================================
2022-07-08 05:03:03,860: time cost, forward:0.01185315664409152, backward:0.03369969464697152, data cost:0.698340849203667 
2022-07-08 05:03:03,860: ============================================================
2022-07-08 05:03:03,861: Epoch 23/36 Batch 2900/7662 eta: 21:22:18.644795	Training Loss1 2.7516 (2.8691)	Training Total_Loss 2.7516 (2.8691)	Training Prec@1 99.414 (99.050)	Training Prec@5 0.000 (0.000)	
2022-07-08 05:03:03,861: ============================================================
2022-07-08 05:04:17,338: time cost, forward:0.011853881977764357, backward:0.033696038359679874, data cost:0.6980896698073095 
2022-07-08 05:04:17,338: ============================================================
2022-07-08 05:04:17,338: Epoch 23/36 Batch 3000/7662 eta: 21:16:54.450081	Training Loss1 3.2085 (2.8711)	Training Total_Loss 3.2085 (2.8711)	Training Prec@1 97.852 (99.046)	Training Prec@5 0.000 (0.000)	
2022-07-08 05:04:17,338: ============================================================
2022-07-08 05:05:30,533: time cost, forward:0.011847377477364604, backward:0.03368888512162402, data cost:0.6977044432037836 
2022-07-08 05:05:30,534: ============================================================
2022-07-08 05:05:30,534: Epoch 23/36 Batch 3100/7662 eta: 21:10:47.220713	Training Loss1 3.0697 (2.8726)	Training Total_Loss 3.0697 (2.8726)	Training Prec@1 98.438 (99.044)	Training Prec@5 0.000 (0.000)	
2022-07-08 05:05:30,534: ============================================================
2022-07-08 05:06:42,879: time cost, forward:0.011859874942966758, backward:0.033696549502936476, data cost:0.6970426800028166 
2022-07-08 05:06:42,879: ============================================================
2022-07-08 05:06:42,880: Epoch 23/36 Batch 3200/7662 eta: 20:54:49.290492	Training Loss1 2.9226 (2.8739)	Training Total_Loss 2.9226 (2.8739)	Training Prec@1 99.219 (99.043)	Training Prec@5 0.000 (0.000)	
2022-07-08 05:06:42,880: ============================================================
2022-07-08 05:07:58,654: time cost, forward:0.0118892189949778, backward:0.033663654587564415, data cost:0.6974907937502276 
2022-07-08 05:07:58,654: ============================================================
2022-07-08 05:07:58,654: Epoch 23/36 Batch 3300/7662 eta: 21:53:02.051269	Training Loss1 2.8646 (2.8758)	Training Total_Loss 2.8646 (2.8758)	Training Prec@1 99.219 (99.042)	Training Prec@5 0.000 (0.000)	
2022-07-08 05:07:58,654: ============================================================
2022-07-08 05:09:11,919: time cost, forward:0.01186879847673291, backward:0.03366355469522142, data cost:0.697188148992347 
2022-07-08 05:09:11,920: ============================================================
2022-07-08 05:09:11,920: Epoch 23/36 Batch 3400/7662 eta: 21:08:20.379013	Training Loss1 2.9154 (2.8771)	Training Total_Loss 2.9154 (2.8771)	Training Prec@1 99.023 (99.040)	Training Prec@5 0.000 (0.000)	
2022-07-08 05:09:11,920: ============================================================
2022-07-08 05:10:25,508: time cost, forward:0.011867892507077217, backward:0.033676911640521556, data cost:0.6969611334712139 
2022-07-08 05:10:25,508: ============================================================
2022-07-08 05:10:25,508: Epoch 23/36 Batch 3500/7662 eta: 21:12:41.700759	Training Loss1 3.0049 (2.8783)	Training Total_Loss 3.0049 (2.8783)	Training Prec@1 98.828 (99.039)	Training Prec@5 0.000 (0.000)	
2022-07-08 05:10:25,508: ============================================================
2022-07-08 05:11:38,648: time cost, forward:0.011860288888688019, backward:0.03368309584880213, data cost:0.6966292390428539 
2022-07-08 05:11:38,648: ============================================================
2022-07-08 05:11:38,649: Epoch 23/36 Batch 3600/7662 eta: 21:03:44.057148	Training Loss1 2.9130 (2.8795)	Training Total_Loss 2.9130 (2.8795)	Training Prec@1 98.633 (99.034)	Training Prec@5 0.000 (0.000)	
2022-07-08 05:11:38,649: ============================================================
2022-07-08 05:12:52,202: time cost, forward:0.01184705980212729, backward:0.03367945360924689, data cost:0.6964663976461509 
2022-07-08 05:12:52,202: ============================================================
2022-07-08 05:12:52,203: Epoch 23/36 Batch 3700/7662 eta: 21:09:39.236484	Training Loss1 3.0637 (2.8812)	Training Total_Loss 3.0637 (2.8812)	Training Prec@1 97.656 (99.034)	Training Prec@5 0.000 (0.000)	
2022-07-08 05:12:52,203: ============================================================
2022-07-08 05:14:06,254: time cost, forward:0.011832559570007244, backward:0.033677999456796746, data cost:0.6964249505467025 
2022-07-08 05:14:06,255: ============================================================
2022-07-08 05:14:06,255: Epoch 23/36 Batch 3800/7662 eta: 21:17:00.980611	Training Loss1 2.9074 (2.8834)	Training Total_Loss 2.9074 (2.8834)	Training Prec@1 98.438 (99.031)	Training Prec@5 0.000 (0.000)	
2022-07-08 05:14:06,255: ============================================================
2022-07-08 05:15:20,007: time cost, forward:0.011811817630984043, backward:0.033678751843010474, data cost:0.6962204184340158 
2022-07-08 05:15:20,007: ============================================================
2022-07-08 05:15:20,007: Epoch 23/36 Batch 3900/7662 eta: 21:10:37.291283	Training Loss1 2.9270 (2.8843)	Training Total_Loss 2.9270 (2.8843)	Training Prec@1 99.414 (99.028)	Training Prec@5 0.000 (0.000)	
2022-07-08 05:15:20,007: ============================================================
2022-07-08 05:16:33,357: time cost, forward:0.011789470173234074, backward:0.03367057947195539, data cost:0.696130122861793 
2022-07-08 05:16:33,358: ============================================================
2022-07-08 05:16:33,358: Epoch 23/36 Batch 4000/7662 eta: 21:02:28.251383	Training Loss1 3.0503 (2.8857)	Training Total_Loss 3.0503 (2.8857)	Training Prec@1 99.023 (99.026)	Training Prec@5 0.000 (0.000)	
2022-07-08 05:16:33,358: ============================================================
2022-07-08 05:17:47,898: time cost, forward:0.01178829644941417, backward:0.03367220375356979, data cost:0.6961921468889692 
2022-07-08 05:17:47,899: ============================================================
2022-07-08 05:17:47,899: Epoch 23/36 Batch 4100/7662 eta: 21:21:43.484094	Training Loss1 2.8769 (2.8865)	Training Total_Loss 2.8769 (2.8865)	Training Prec@1 98.633 (99.023)	Training Prec@5 0.000 (0.000)	
2022-07-08 05:17:47,899: ============================================================
2022-07-08 05:19:01,337: time cost, forward:0.011784983919075087, backward:0.03367120051673549, data cost:0.6960143946443009 
2022-07-08 05:19:01,337: ============================================================
2022-07-08 05:19:01,337: Epoch 23/36 Batch 4200/7662 eta: 21:01:32.344938	Training Loss1 3.2071 (2.8880)	Training Total_Loss 3.2071 (2.8880)	Training Prec@1 98.242 (99.020)	Training Prec@5 0.000 (0.000)	
2022-07-08 05:19:01,338: ============================================================
2022-07-08 05:20:14,441: time cost, forward:0.011783307306875764, backward:0.0336914724681399, data cost:0.6957402003036041 
2022-07-08 05:20:14,442: ============================================================
2022-07-08 05:20:14,442: Epoch 23/36 Batch 4300/7662 eta: 20:54:34.957932	Training Loss1 2.7078 (2.8891)	Training Total_Loss 2.7078 (2.8891)	Training Prec@1 99.219 (99.017)	Training Prec@5 0.000 (0.000)	
2022-07-08 05:20:14,442: ============================================================
2022-07-08 05:21:26,397: time cost, forward:0.011771916367569196, backward:0.033690321524052706, data cost:0.6952367861397186 
2022-07-08 05:21:26,397: ============================================================
2022-07-08 05:21:26,397: Epoch 23/36 Batch 4400/7662 eta: 20:33:39.834016	Training Loss1 2.9794 (2.8905)	Training Total_Loss 2.9794 (2.8905)	Training Prec@1 98.633 (99.015)	Training Prec@5 0.000 (0.000)	
2022-07-08 05:21:26,398: ============================================================
2022-07-08 05:22:39,767: time cost, forward:0.01176072740904568, backward:0.03368420101690621, data cost:0.6950918981090443 
2022-07-08 05:22:39,767: ============================================================
2022-07-08 05:22:39,767: Epoch 23/36 Batch 4500/7662 eta: 20:56:41.611507	Training Loss1 2.9579 (2.8920)	Training Total_Loss 2.9579 (2.8920)	Training Prec@1 99.023 (99.012)	Training Prec@5 0.000 (0.000)	
2022-07-08 05:22:39,768: ============================================================
2022-07-08 05:23:54,130: time cost, forward:0.011754850585400009, backward:0.03367770368779683, data cost:0.6951656313039967 
2022-07-08 05:23:54,130: ============================================================
2022-07-08 05:23:54,131: Epoch 23/36 Batch 4600/7662 eta: 21:12:27.947636	Training Loss1 3.0476 (2.8932)	Training Total_Loss 3.0476 (2.8932)	Training Prec@1 99.219 (99.010)	Training Prec@5 0.000 (0.000)	
2022-07-08 05:23:54,131: ============================================================
2022-07-08 05:25:06,827: time cost, forward:0.011741154141617877, backward:0.03369257307529551, data cost:0.6948618432211607 
2022-07-08 05:25:06,827: ============================================================
2022-07-08 05:25:06,828: Epoch 23/36 Batch 4700/7662 eta: 20:42:44.553189	Training Loss1 2.9686 (2.8945)	Training Total_Loss 2.9686 (2.8945)	Training Prec@1 99.023 (99.008)	Training Prec@5 0.000 (0.000)	
2022-07-08 05:25:06,828: ============================================================
2022-07-08 05:26:21,087: time cost, forward:0.011746129931994195, backward:0.033695962732596854, data cost:0.6948817306867513 
2022-07-08 05:26:21,088: ============================================================
2022-07-08 05:26:21,088: Epoch 23/36 Batch 4800/7662 eta: 21:08:13.594214	Training Loss1 2.9122 (2.8962)	Training Total_Loss 2.9122 (2.8962)	Training Prec@1 99.219 (99.006)	Training Prec@5 0.000 (0.000)	
2022-07-08 05:26:21,088: ============================================================
2022-07-08 05:27:34,480: time cost, forward:0.011751136625998117, backward:0.0337026102198803, data cost:0.6947329670683562 
2022-07-08 05:27:34,481: ============================================================
2022-07-08 05:27:34,481: Epoch 23/36 Batch 4900/7662 eta: 20:52:11.812583	Training Loss1 2.9682 (2.8975)	Training Total_Loss 2.9682 (2.8975)	Training Prec@1 99.219 (99.004)	Training Prec@5 0.000 (0.000)	
2022-07-08 05:27:34,481: ============================================================
2022-07-08 05:28:48,833: time cost, forward:0.011751060367560573, backward:0.03370027204446016, data cost:0.6947909660591176 
2022-07-08 05:28:48,834: ============================================================
2022-07-08 05:28:48,834: Epoch 23/36 Batch 5000/7662 eta: 21:07:20.088513	Training Loss1 2.8559 (2.8985)	Training Total_Loss 2.8559 (2.8985)	Training Prec@1 99.609 (99.002)	Training Prec@5 0.000 (0.000)	
2022-07-08 05:28:48,834: ============================================================
2022-07-08 05:30:03,664: time cost, forward:0.011758642445407351, backward:0.03369975127433183, data cost:0.694928262111696 
2022-07-08 05:30:03,664: ============================================================
2022-07-08 05:30:03,665: Epoch 23/36 Batch 5100/7662 eta: 21:14:13.750033	Training Loss1 2.9424 (2.8999)	Training Total_Loss 2.9424 (2.8999)	Training Prec@1 99.023 (99.001)	Training Prec@5 0.000 (0.000)	
2022-07-08 05:30:03,665: ============================================================
2022-07-08 05:31:17,794: time cost, forward:0.011760362273662176, backward:0.03369841728790101, data cost:0.6949382015410972 
2022-07-08 05:31:17,795: ============================================================
2022-07-08 05:31:17,795: Epoch 23/36 Batch 5200/7662 eta: 21:01:03.910429	Training Loss1 2.9007 (2.9009)	Training Total_Loss 2.9007 (2.9009)	Training Prec@1 99.219 (98.998)	Training Prec@5 0.000 (0.000)	
2022-07-08 05:31:17,795: ============================================================
2022-07-08 05:32:30,973: time cost, forward:0.011757167786286674, backward:0.03369935104635037, data cost:0.694759468466274 
2022-07-08 05:32:30,973: ============================================================
2022-07-08 05:32:30,973: Epoch 23/36 Batch 5300/7662 eta: 20:43:39.144648	Training Loss1 3.0582 (2.9023)	Training Total_Loss 3.0582 (2.9023)	Training Prec@1 98.242 (98.997)	Training Prec@5 0.000 (0.000)	
2022-07-08 05:32:30,973: ============================================================
2022-07-08 05:33:44,540: time cost, forward:0.011754242440774984, backward:0.03369928792927702, data cost:0.6946628050442911 
2022-07-08 05:33:44,541: ============================================================
2022-07-08 05:33:44,541: Epoch 23/36 Batch 5400/7662 eta: 20:49:02.729281	Training Loss1 2.9282 (2.9031)	Training Total_Loss 2.9282 (2.9031)	Training Prec@1 99.219 (98.995)	Training Prec@5 0.000 (0.000)	
2022-07-08 05:33:44,541: ============================================================
2022-07-08 05:34:58,015: time cost, forward:0.011764586546308757, backward:0.033712250858160514, data cost:0.694535408784832 
2022-07-08 05:34:58,015: ============================================================
2022-07-08 05:34:58,015: Epoch 23/36 Batch 5500/7662 eta: 20:46:14.056634	Training Loss1 3.0020 (2.9040)	Training Total_Loss 3.0020 (2.9040)	Training Prec@1 98.633 (98.994)	Training Prec@5 0.000 (0.000)	
2022-07-08 05:34:58,015: ============================================================
2022-07-08 05:36:10,851: time cost, forward:0.011777681375235442, backward:0.03371600079353334, data cost:0.6942998622438485 
2022-07-08 05:36:10,851: ============================================================
2022-07-08 05:36:10,851: Epoch 23/36 Batch 5600/7662 eta: 20:34:11.567842	Training Loss1 3.1213 (2.9051)	Training Total_Loss 3.1213 (2.9051)	Training Prec@1 98.047 (98.992)	Training Prec@5 0.000 (0.000)	
2022-07-08 05:36:10,851: ============================================================
2022-07-08 05:37:24,393: time cost, forward:0.011780394234350218, backward:0.033703671649665784, data cost:0.6942244118233484 
2022-07-08 05:37:24,394: ============================================================
2022-07-08 05:37:24,394: Epoch 23/36 Batch 5700/7662 eta: 20:44:56.633932	Training Loss1 3.1216 (2.9063)	Training Total_Loss 3.1216 (2.9063)	Training Prec@1 98.047 (98.990)	Training Prec@5 0.000 (0.000)	
2022-07-08 05:37:24,394: ============================================================
2022-07-08 05:38:38,232: time cost, forward:0.011788784049465484, backward:0.033705377891199775, data cost:0.6941817291113072 
2022-07-08 05:38:38,232: ============================================================
2022-07-08 05:38:38,232: Epoch 23/36 Batch 5800/7662 eta: 20:48:43.068563	Training Loss1 3.2651 (2.9075)	Training Total_Loss 3.2651 (2.9075)	Training Prec@1 98.633 (98.989)	Training Prec@5 0.000 (0.000)	
2022-07-08 05:38:38,232: ============================================================
2022-07-08 05:39:52,213: time cost, forward:0.011783674745807044, backward:0.03370196873059736, data cost:0.6941805725320757 
2022-07-08 05:39:52,213: ============================================================
2022-07-08 05:39:52,214: Epoch 23/36 Batch 5900/7662 eta: 20:49:54.312686	Training Loss1 3.2658 (2.9087)	Training Total_Loss 3.2658 (2.9087)	Training Prec@1 98.047 (98.987)	Training Prec@5 0.000 (0.000)	
2022-07-08 05:39:52,214: ============================================================
2022-07-08 05:41:06,039: time cost, forward:0.01178626418809212, backward:0.033691785080787795, data cost:0.6941488738615605 
2022-07-08 05:41:06,039: ============================================================
2022-07-08 05:41:06,039: Epoch 23/36 Batch 6000/7662 eta: 20:46:02.578117	Training Loss1 3.0828 (2.9102)	Training Total_Loss 3.0828 (2.9102)	Training Prec@1 98.242 (98.985)	Training Prec@5 0.000 (0.000)	
2022-07-08 05:41:06,039: ============================================================
2022-07-08 05:42:21,171: time cost, forward:0.011792006815509886, backward:0.0337037026520576, data cost:0.694319742471395 
2022-07-08 05:42:21,171: ============================================================
2022-07-08 05:42:21,171: Epoch 23/36 Batch 6100/7662 eta: 21:06:50.374818	Training Loss1 2.9616 (2.9109)	Training Total_Loss 2.9616 (2.9109)	Training Prec@1 98.828 (98.983)	Training Prec@5 0.000 (0.000)	
2022-07-08 05:42:21,171: ============================================================
2022-07-08 05:43:35,801: time cost, forward:0.011786789754875862, backward:0.03370602770493211, data cost:0.6944216611135735 
2022-07-08 05:43:35,801: ============================================================
2022-07-08 05:43:35,801: Epoch 23/36 Batch 6200/7662 eta: 20:57:07.637223	Training Loss1 3.0222 (2.9123)	Training Total_Loss 3.0222 (2.9123)	Training Prec@1 98.633 (98.983)	Training Prec@5 0.000 (0.000)	
2022-07-08 05:43:35,801: ============================================================
2022-07-08 05:44:50,545: time cost, forward:0.011778530269828103, backward:0.033707003268689875, data cost:0.6945397391700048 
2022-07-08 05:44:50,546: ============================================================
2022-07-08 05:44:50,546: Epoch 23/36 Batch 6300/7662 eta: 20:57:48.872343	Training Loss1 3.1851 (2.9132)	Training Total_Loss 3.1851 (2.9132)	Training Prec@1 98.047 (98.981)	Training Prec@5 0.000 (0.000)	
2022-07-08 05:44:50,546: ============================================================
2022-07-08 05:46:05,190: time cost, forward:0.011780237477167376, backward:0.03371215973222306, data cost:0.6946188887873186 
2022-07-08 05:46:05,190: ============================================================
2022-07-08 05:46:05,191: Epoch 23/36 Batch 6400/7662 eta: 20:54:53.339407	Training Loss1 2.9208 (2.9144)	Training Total_Loss 2.9208 (2.9144)	Training Prec@1 98.438 (98.978)	Training Prec@5 0.000 (0.000)	
2022-07-08 05:46:05,191: ============================================================
2022-07-08 05:47:20,257: time cost, forward:0.011787368473887058, backward:0.033723338418125026, data cost:0.6947568157376244 
2022-07-08 05:47:20,257: ============================================================
2022-07-08 05:47:20,257: Epoch 23/36 Batch 6500/7662 eta: 21:00:43.902121	Training Loss1 2.9023 (2.9155)	Training Total_Loss 2.9023 (2.9155)	Training Prec@1 99.219 (98.977)	Training Prec@5 0.000 (0.000)	
2022-07-08 05:47:20,257: ============================================================
2022-07-08 05:48:33,446: time cost, forward:0.011792969100311645, backward:0.033733536138879944, data cost:0.6946004173722768 
2022-07-08 05:48:33,446: ============================================================
2022-07-08 05:48:33,446: Epoch 23/36 Batch 6600/7662 eta: 20:27:58.535175	Training Loss1 3.1125 (2.9166)	Training Total_Loss 3.1125 (2.9166)	Training Prec@1 99.609 (98.975)	Training Prec@5 0.000 (0.000)	
2022-07-08 05:48:33,446: ============================================================
2022-07-08 05:49:47,346: time cost, forward:0.011791038342350756, backward:0.03372902453061377, data cost:0.6945824689305635 
2022-07-08 05:49:47,346: ============================================================
2022-07-08 05:49:47,346: Epoch 23/36 Batch 6700/7662 eta: 20:38:40.530659	Training Loss1 3.1988 (2.9177)	Training Total_Loss 3.1988 (2.9177)	Training Prec@1 99.023 (98.972)	Training Prec@5 0.000 (0.000)	
2022-07-08 05:49:47,346: ============================================================
2022-07-08 05:51:02,475: time cost, forward:0.011786955211912644, backward:0.0337292321518355, data cost:0.694747721452821 
2022-07-08 05:51:02,476: ============================================================
2022-07-08 05:51:02,476: Epoch 23/36 Batch 6800/7662 eta: 20:58:02.058238	Training Loss1 2.8713 (2.9188)	Training Total_Loss 2.8713 (2.9188)	Training Prec@1 99.219 (98.970)	Training Prec@5 0.000 (0.000)	
2022-07-08 05:51:02,476: ============================================================
2022-07-08 05:52:15,600: time cost, forward:0.011788776049079679, backward:0.03373885365530518, data cost:0.6945963927085269 
2022-07-08 05:52:15,600: ============================================================
2022-07-08 05:52:15,600: Epoch 23/36 Batch 6900/7662 eta: 20:23:14.378737	Training Loss1 2.8787 (2.9198)	Training Total_Loss 2.8787 (2.9198)	Training Prec@1 98.828 (98.969)	Training Prec@5 0.000 (0.000)	
2022-07-08 05:52:15,600: ============================================================
2022-07-08 05:53:28,610: time cost, forward:0.011791602596757685, backward:0.033725294117791974, data cost:0.6944491391455144 
2022-07-08 05:53:28,610: ============================================================
2022-07-08 05:53:28,611: Epoch 23/36 Batch 7000/7662 eta: 20:20:06.495622	Training Loss1 2.8073 (2.9212)	Training Total_Loss 2.8073 (2.9212)	Training Prec@1 99.219 (98.967)	Training Prec@5 0.000 (0.000)	
2022-07-08 05:53:28,611: ============================================================
2022-07-08 05:54:42,734: time cost, forward:0.011792171134094333, backward:0.033722170407813376, data cost:0.6944686296473491 
2022-07-08 05:54:42,734: ============================================================
2022-07-08 05:54:42,735: Epoch 23/36 Batch 7100/7662 eta: 20:37:29.385222	Training Loss1 3.1560 (2.9223)	Training Total_Loss 3.1560 (2.9223)	Training Prec@1 98.633 (98.966)	Training Prec@5 0.000 (0.000)	
2022-07-08 05:54:42,735: ============================================================
2022-07-08 05:55:57,254: time cost, forward:0.011799534222602447, backward:0.03371213422680683, data cost:0.6944957713746979 
2022-07-08 05:55:57,255: ============================================================
2022-07-08 05:55:57,255: Epoch 23/36 Batch 7200/7662 eta: 20:42:51.612749	Training Loss1 3.0334 (2.9236)	Training Total_Loss 3.0334 (2.9236)	Training Prec@1 98.438 (98.963)	Training Prec@5 0.000 (0.000)	
2022-07-08 05:55:57,255: ============================================================
2022-07-08 05:57:11,442: time cost, forward:0.011798587690103314, backward:0.03370947004230174, data cost:0.6945562173216485 
2022-07-08 05:57:11,442: ============================================================
2022-07-08 05:57:11,442: Epoch 23/36 Batch 7300/7662 eta: 20:36:04.669670	Training Loss1 2.9374 (2.9247)	Training Total_Loss 2.9374 (2.9247)	Training Prec@1 99.023 (98.961)	Training Prec@5 0.000 (0.000)	
2022-07-08 05:57:11,443: ============================================================
2022-07-08 05:58:26,182: time cost, forward:0.0117991128504671, backward:0.0337059916411079, data cost:0.6946474141503592 
2022-07-08 05:58:26,182: ============================================================
2022-07-08 05:58:26,182: Epoch 23/36 Batch 7400/7662 eta: 20:44:02.101086	Training Loss1 2.8835 (2.9255)	Training Total_Loss 2.8835 (2.9255)	Training Prec@1 98.438 (98.960)	Training Prec@5 0.000 (0.000)	
2022-07-08 05:58:26,183: ============================================================
2022-07-08 05:59:40,061: time cost, forward:0.011803239802548625, backward:0.03371330092216845, data cost:0.694611319988183 
2022-07-08 05:59:40,061: ============================================================
2022-07-08 05:59:40,061: Epoch 23/36 Batch 7500/7662 eta: 20:28:28.164626	Training Loss1 3.3057 (2.9263)	Training Total_Loss 3.3057 (2.9263)	Training Prec@1 98.242 (98.959)	Training Prec@5 0.000 (0.000)	
2022-07-08 05:59:40,061: ============================================================
2022-07-08 06:00:53,871: time cost, forward:0.011800695711224466, backward:0.0337137440848247, data cost:0.6945721992992667 
2022-07-08 06:00:53,872: ============================================================
2022-07-08 06:00:53,872: Epoch 23/36 Batch 7600/7662 eta: 20:26:06.063585	Training Loss1 3.0573 (2.9278)	Training Total_Loss 3.0573 (2.9278)	Training Prec@1 98.438 (98.956)	Training Prec@5 0.000 (0.000)	
2022-07-08 06:00:53,872: ============================================================
2022-07-08 06:01:42,044: Epoch 23/36 Batch 7663/7662 eta: 20:25:19.563048	Training Loss1 2.9027 (2.9284)	Training Total_Loss 2.9027 (2.9284)	Training Prec@1 99.219 (98.956)	Training Prec@5 0.000 (0.000)	
2022-07-08 06:01:42,044: ============================================================
2022-07-08 06:03:11,412: time cost, forward:0.01231848109852184, backward:0.03163671011876578, data cost:0.8514395073206737 
2022-07-08 06:03:11,412: ============================================================
2022-07-08 06:03:11,413: Epoch 24/36 Batch 100/7662 eta: 1 day, 0:39:01.426630	Training Loss1 2.9315 (2.7722)	Training Total_Loss 2.9315 (2.7722)	Training Prec@1 99.414 (99.211)	Training Prec@5 0.000 (0.000)	
2022-07-08 06:03:11,413: ============================================================
2022-07-08 06:04:23,857: time cost, forward:0.012488852793247856, backward:0.03240024384541727, data cost:0.7642700672149658 
2022-07-08 06:04:23,858: ============================================================
2022-07-08 06:04:23,858: Epoch 24/36 Batch 200/7662 eta: 20:00:15.680512	Training Loss1 2.8078 (2.7872)	Training Total_Loss 2.8078 (2.7872)	Training Prec@1 98.828 (99.197)	Training Prec@5 0.000 (0.000)	
2022-07-08 06:04:23,858: ============================================================
2022-07-08 06:05:36,920: time cost, forward:0.012247475493313079, backward:0.03284035000115334, data cost:0.7375569997423868 
2022-07-08 06:05:36,920: ============================================================
2022-07-08 06:05:36,920: Epoch 24/36 Batch 300/7662 eta: 20:09:16.045470	Training Loss1 2.9002 (2.7783)	Training Total_Loss 2.9002 (2.7783)	Training Prec@1 99.609 (99.210)	Training Prec@5 0.000 (0.000)	
2022-07-08 06:05:36,920: ============================================================
2022-07-08 06:06:49,808: time cost, forward:0.011963804264116407, backward:0.033155483709540884, data cost:0.7239286230321516 
2022-07-08 06:06:49,808: ============================================================
2022-07-08 06:06:49,808: Epoch 24/36 Batch 400/7662 eta: 20:05:10.153334	Training Loss1 2.6583 (2.7882)	Training Total_Loss 2.6583 (2.7882)	Training Prec@1 98.828 (99.207)	Training Prec@5 0.000 (0.000)	
2022-07-08 06:06:49,808: ============================================================
2022-07-08 06:08:02,895: time cost, forward:0.011831444107697818, backward:0.03329731945045487, data cost:0.7161706965528652 
2022-07-08 06:08:02,895: ============================================================
2022-07-08 06:08:02,896: Epoch 24/36 Batch 500/7662 eta: 20:07:14.639452	Training Loss1 2.8519 (2.7946)	Training Total_Loss 2.8519 (2.7946)	Training Prec@1 98.438 (99.189)	Training Prec@5 0.000 (0.000)	
2022-07-08 06:08:02,896: ============================================================
2022-07-08 06:09:15,150: time cost, forward:0.011776001505143257, backward:0.033444634662048646, data cost:0.7094980699192105 
2022-07-08 06:09:15,150: ============================================================
2022-07-08 06:09:15,151: Epoch 24/36 Batch 600/7662 eta: 19:52:17.546440	Training Loss1 2.8143 (2.7946)	Training Total_Loss 2.8143 (2.7946)	Training Prec@1 99.023 (99.182)	Training Prec@5 0.000 (0.000)	
2022-07-08 06:09:15,151: ============================================================
2022-07-08 06:10:27,643: time cost, forward:0.01168733366228139, backward:0.03349378248823218, data cost:0.7051770305087809 
2022-07-08 06:10:27,644: ============================================================
2022-07-08 06:10:27,644: Epoch 24/36 Batch 700/7662 eta: 19:55:00.702712	Training Loss1 2.8704 (2.7946)	Training Total_Loss 2.8704 (2.7946)	Training Prec@1 99.023 (99.183)	Training Prec@5 0.000 (0.000)	
2022-07-08 06:10:27,644: ============================================================
2022-07-08 06:11:41,033: time cost, forward:0.01164198846781209, backward:0.03349824482866461, data cost:0.7030340294366486 
2022-07-08 06:11:41,034: ============================================================
2022-07-08 06:11:41,034: Epoch 24/36 Batch 800/7662 eta: 20:08:34.528783	Training Loss1 2.6296 (2.7968)	Training Total_Loss 2.6296 (2.7968)	Training Prec@1 99.609 (99.175)	Training Prec@5 0.000 (0.000)	
2022-07-08 06:11:41,034: ============================================================
2022-07-08 06:12:53,079: time cost, forward:0.011608261950686989, backward:0.03351737129542401, data cost:0.6999577929631489 
2022-07-08 06:12:53,079: ============================================================
2022-07-08 06:12:53,079: Epoch 24/36 Batch 900/7662 eta: 19:45:13.890302	Training Loss1 2.9114 (2.7989)	Training Total_Loss 2.9114 (2.7989)	Training Prec@1 99.219 (99.168)	Training Prec@5 0.000 (0.000)	
2022-07-08 06:12:53,079: ============================================================
2022-07-08 06:14:06,576: time cost, forward:0.011654635210772295, backward:0.0335781557543261, data cost:0.6987684247968672 
2022-07-08 06:14:06,577: ============================================================
2022-07-08 06:14:06,577: Epoch 24/36 Batch 1000/7662 eta: 20:07:53.716444	Training Loss1 2.7615 (2.8017)	Training Total_Loss 2.7615 (2.8017)	Training Prec@1 99.023 (99.165)	Training Prec@5 0.000 (0.000)	
2022-07-08 06:14:06,577: ============================================================
2022-07-08 06:15:19,991: time cost, forward:0.011630949049889771, backward:0.03363176212189304, data cost:0.6977613347568112 
2022-07-08 06:15:19,991: ============================================================
2022-07-08 06:15:19,991: Epoch 24/36 Batch 1100/7662 eta: 20:05:18.510525	Training Loss1 3.0906 (2.8044)	Training Total_Loss 3.0906 (2.8044)	Training Prec@1 98.633 (99.164)	Training Prec@5 0.000 (0.000)	
2022-07-08 06:15:19,992: ============================================================
2022-07-08 06:16:33,068: time cost, forward:0.011617864739208842, backward:0.033695135641535486, data cost:0.6966776306973188 
2022-07-08 06:16:33,068: ============================================================
2022-07-08 06:16:33,069: Epoch 24/36 Batch 1200/7662 eta: 19:58:33.106418	Training Loss1 2.6926 (2.8073)	Training Total_Loss 2.6926 (2.8073)	Training Prec@1 99.023 (99.163)	Training Prec@5 0.000 (0.000)	
2022-07-08 06:16:33,069: ============================================================
2022-07-08 06:17:45,525: time cost, forward:0.011619558327008983, backward:0.033681652378907474, data cost:0.6953027668689379 
2022-07-08 06:17:45,525: ============================================================
2022-07-08 06:17:45,525: Epoch 24/36 Batch 1300/7662 eta: 19:47:09.851118	Training Loss1 2.9222 (2.8094)	Training Total_Loss 2.9222 (2.8094)	Training Prec@1 99.023 (99.162)	Training Prec@5 0.000 (0.000)	
2022-07-08 06:17:45,525: ============================================================
2022-07-08 06:18:58,937: time cost, forward:0.011634413730765856, backward:0.033684825965385086, data cost:0.6947544894105967 
2022-07-08 06:18:58,937: ============================================================
2022-07-08 06:18:58,938: Epoch 24/36 Batch 1400/7662 eta: 20:01:36.000945	Training Loss1 2.7900 (2.8097)	Training Total_Loss 2.7900 (2.8097)	Training Prec@1 99.414 (99.159)	Training Prec@5 0.000 (0.000)	
2022-07-08 06:18:58,938: ============================================================
2022-07-08 06:20:12,719: time cost, forward:0.011632191967852836, backward:0.033708682610560765, data cost:0.6945605639062619 
2022-07-08 06:20:12,719: ============================================================
2022-07-08 06:20:12,719: Epoch 24/36 Batch 1500/7662 eta: 20:06:25.292769	Training Loss1 2.7166 (2.8134)	Training Total_Loss 2.7166 (2.8134)	Training Prec@1 98.828 (99.151)	Training Prec@5 0.000 (0.000)	
2022-07-08 06:20:12,720: ============================================================
2022-07-08 06:21:26,667: time cost, forward:0.011664354480602653, backward:0.033739464218874436, data cost:0.694432319738926 
2022-07-08 06:21:26,668: ============================================================
2022-07-08 06:21:26,668: Epoch 24/36 Batch 1600/7662 eta: 20:07:54.449748	Training Loss1 2.8255 (2.8153)	Training Total_Loss 2.8255 (2.8153)	Training Prec@1 98.633 (99.144)	Training Prec@5 0.000 (0.000)	
2022-07-08 06:21:26,668: ============================================================
2022-07-08 06:22:39,930: time cost, forward:0.01171413346414639, backward:0.03377083738527977, data cost:0.6938833679571932 
2022-07-08 06:22:39,931: ============================================================
2022-07-08 06:22:39,931: Epoch 24/36 Batch 1700/7662 eta: 19:55:29.608456	Training Loss1 2.8126 (2.8175)	Training Total_Loss 2.8126 (2.8175)	Training Prec@1 98.633 (99.140)	Training Prec@5 0.000 (0.000)	
2022-07-08 06:22:39,931: ============================================================
2022-07-08 06:23:53,546: time cost, forward:0.011734378145693938, backward:0.03379773192434857, data cost:0.6936346173882816 
2022-07-08 06:23:53,546: ============================================================
2022-07-08 06:23:53,546: Epoch 24/36 Batch 1800/7662 eta: 20:00:01.285086	Training Loss1 2.6329 (2.8180)	Training Total_Loss 2.6329 (2.8180)	Training Prec@1 99.023 (99.140)	Training Prec@5 0.000 (0.000)	
2022-07-08 06:23:53,546: ============================================================
2022-07-08 06:25:06,082: time cost, forward:0.011730870050527724, backward:0.03380945608953603, data cost:0.6928639585184637 
2022-07-08 06:25:06,083: ============================================================
2022-07-08 06:25:06,083: Epoch 24/36 Batch 1900/7662 eta: 19:41:13.245487	Training Loss1 2.8574 (2.8202)	Training Total_Loss 2.8574 (2.8202)	Training Prec@1 98.828 (99.136)	Training Prec@5 0.000 (0.000)	
2022-07-08 06:25:06,083: ============================================================
2022-07-08 06:26:20,217: time cost, forward:0.011764011483242538, backward:0.033840800953722404, data cost:0.6929079001399503 
2022-07-08 06:26:20,218: ============================================================
2022-07-08 06:26:20,218: Epoch 24/36 Batch 2000/7662 eta: 20:06:00.857286	Training Loss1 2.9556 (2.8220)	Training Total_Loss 2.9556 (2.8220)	Training Prec@1 99.023 (99.126)	Training Prec@5 0.000 (0.000)	
2022-07-08 06:26:20,218: ============================================================
2022-07-08 06:27:34,891: time cost, forward:0.011794597549402128, backward:0.03386941553582005, data cost:0.6932135705098247 
2022-07-08 06:27:34,891: ============================================================
2022-07-08 06:27:34,891: Epoch 24/36 Batch 2100/7662 eta: 20:13:31.949683	Training Loss1 2.9281 (2.8248)	Training Total_Loss 2.9281 (2.8248)	Training Prec@1 98.633 (99.122)	Training Prec@5 0.000 (0.000)	
2022-07-08 06:27:34,891: ============================================================
2022-07-08 06:28:47,773: time cost, forward:0.011781439774683683, backward:0.03389308017836532, data cost:0.6927200401300948 
2022-07-08 06:28:47,773: ============================================================
2022-07-08 06:28:47,773: Epoch 24/36 Batch 2200/7662 eta: 19:43:11.964878	Training Loss1 2.7729 (2.8270)	Training Total_Loss 2.7729 (2.8270)	Training Prec@1 99.414 (99.119)	Training Prec@5 0.000 (0.000)	
2022-07-08 06:28:47,773: ============================================================
2022-07-08 06:30:00,812: time cost, forward:0.011796808180574646, backward:0.0338642055856606, data cost:0.6923606392610275 
2022-07-08 06:30:00,813: ============================================================
2022-07-08 06:30:00,813: Epoch 24/36 Batch 2300/7662 eta: 19:44:32.595911	Training Loss1 2.8848 (2.8291)	Training Total_Loss 2.8848 (2.8291)	Training Prec@1 99.219 (99.115)	Training Prec@5 0.000 (0.000)	
2022-07-08 06:30:00,813: ============================================================
2022-07-08 06:31:13,458: time cost, forward:0.011814552925685487, backward:0.03386767281249644, data cost:0.6918282241511216 
2022-07-08 06:31:13,459: ============================================================
2022-07-08 06:31:13,459: Epoch 24/36 Batch 2400/7662 eta: 19:36:56.977200	Training Loss1 2.6388 (2.8304)	Training Total_Loss 2.6388 (2.8304)	Training Prec@1 99.023 (99.114)	Training Prec@5 0.000 (0.000)	
2022-07-08 06:31:13,459: ============================================================
2022-07-08 06:32:25,606: time cost, forward:0.011863767265939578, backward:0.03383334630391463, data cost:0.6911394310837128 
2022-07-08 06:32:25,606: ============================================================
2022-07-08 06:32:25,606: Epoch 24/36 Batch 2500/7662 eta: 19:27:40.408765	Training Loss1 2.9045 (2.8318)	Training Total_Loss 2.9045 (2.8318)	Training Prec@1 99.023 (99.115)	Training Prec@5 0.000 (0.000)	
2022-07-08 06:32:25,606: ============================================================
2022-07-08 06:33:38,617: time cost, forward:0.011871546954088553, backward:0.033792417110870235, data cost:0.6908900478153148 
2022-07-08 06:33:38,617: ============================================================
2022-07-08 06:33:38,617: Epoch 24/36 Batch 2600/7662 eta: 19:40:25.546632	Training Loss1 2.7770 (2.8334)	Training Total_Loss 2.7770 (2.8334)	Training Prec@1 98.828 (99.111)	Training Prec@5 0.000 (0.000)	
2022-07-08 06:33:38,617: ============================================================
2022-07-08 06:34:51,244: time cost, forward:0.011874788997349098, backward:0.03377119979844265, data cost:0.6904728008049777 
2022-07-08 06:34:51,244: ============================================================
2022-07-08 06:34:51,244: Epoch 24/36 Batch 2700/7662 eta: 19:33:00.889115	Training Loss1 2.8863 (2.8349)	Training Total_Loss 2.8863 (2.8349)	Training Prec@1 98.047 (99.108)	Training Prec@5 0.000 (0.000)	
2022-07-08 06:34:51,244: ============================================================
2022-07-08 06:36:03,988: time cost, forward:0.011882375759412324, backward:0.03374785029406886, data cost:0.6901908939589173 
2022-07-08 06:36:03,988: ============================================================
2022-07-08 06:36:03,988: Epoch 24/36 Batch 2800/7662 eta: 19:33:41.114397	Training Loss1 2.9865 (2.8366)	Training Total_Loss 2.9865 (2.8366)	Training Prec@1 99.609 (99.106)	Training Prec@5 0.000 (0.000)	
2022-07-08 06:36:03,988: ============================================================
2022-07-08 06:37:16,605: time cost, forward:0.011902876992437831, backward:0.03374915363131494, data cost:0.6898159303102628 
2022-07-08 06:37:16,606: ============================================================
2022-07-08 06:37:16,606: Epoch 24/36 Batch 2900/7662 eta: 19:30:26.492846	Training Loss1 2.9282 (2.8374)	Training Total_Loss 2.9282 (2.8374)	Training Prec@1 99.414 (99.106)	Training Prec@5 0.000 (0.000)	
2022-07-08 06:37:16,606: ============================================================
2022-07-08 06:38:29,921: time cost, forward:0.011904867937979041, backward:0.033759670044510075, data cost:0.6897082489385092 
2022-07-08 06:38:29,921: ============================================================
2022-07-08 06:38:29,921: Epoch 24/36 Batch 3000/7662 eta: 19:40:27.683298	Training Loss1 2.7817 (2.8389)	Training Total_Loss 2.7817 (2.8389)	Training Prec@1 99.414 (99.104)	Training Prec@5 0.000 (0.000)	
2022-07-08 06:38:29,921: ============================================================
2022-07-08 06:39:43,011: time cost, forward:0.01190615923568563, backward:0.03377431244494723, data cost:0.6895115829429614 
2022-07-08 06:39:43,011: ============================================================
2022-07-08 06:39:43,011: Epoch 24/36 Batch 3100/7662 eta: 19:35:37.118307	Training Loss1 2.7876 (2.8407)	Training Total_Loss 2.7876 (2.8407)	Training Prec@1 99.023 (99.102)	Training Prec@5 0.000 (0.000)	
2022-07-08 06:39:43,012: ============================================================
2022-07-08 06:40:56,346: time cost, forward:0.011934114940914, backward:0.033764660898764905, data cost:0.6894233454089866 
2022-07-08 06:40:56,346: ============================================================
2022-07-08 06:40:56,347: Epoch 24/36 Batch 3200/7662 eta: 19:38:20.140833	Training Loss1 2.9761 (2.8423)	Training Total_Loss 2.9761 (2.8423)	Training Prec@1 98.828 (99.097)	Training Prec@5 0.000 (0.000)	
2022-07-08 06:40:56,347: ============================================================
2022-07-08 06:42:10,466: time cost, forward:0.011925161517219278, backward:0.033778271338331875, data cost:0.6895872758135141 
2022-07-08 06:42:10,466: ============================================================
2022-07-08 06:42:10,466: Epoch 24/36 Batch 3300/7662 eta: 19:49:42.548296	Training Loss1 2.8309 (2.8441)	Training Total_Loss 2.8309 (2.8441)	Training Prec@1 98.633 (99.094)	Training Prec@5 0.000 (0.000)	
2022-07-08 06:42:10,466: ============================================================
2022-07-08 06:43:24,509: time cost, forward:0.011918085678495635, backward:0.03378549110331792, data cost:0.6897167561158744 
2022-07-08 06:43:24,510: ============================================================
2022-07-08 06:43:24,510: Epoch 24/36 Batch 3400/7662 eta: 19:47:15.171518	Training Loss1 3.0404 (2.8463)	Training Total_Loss 3.0404 (2.8463)	Training Prec@1 98.438 (99.093)	Training Prec@5 0.000 (0.000)	
2022-07-08 06:43:24,510: ============================================================
2022-07-08 06:44:38,086: time cost, forward:0.011939983566885984, backward:0.033785689384741725, data cost:0.6896900020690944 
2022-07-08 06:44:38,086: ============================================================
2022-07-08 06:44:38,086: Epoch 24/36 Batch 3500/7662 eta: 19:38:32.040542	Training Loss1 2.9531 (2.8481)	Training Total_Loss 2.9531 (2.8481)	Training Prec@1 99.609 (99.091)	Training Prec@5 0.000 (0.000)	
2022-07-08 06:44:38,086: ============================================================
2022-07-08 06:45:51,108: time cost, forward:0.01195092531136918, backward:0.03379735949305105, data cost:0.6895080089039125 
2022-07-08 06:45:51,109: ============================================================
2022-07-08 06:45:51,109: Epoch 24/36 Batch 3600/7662 eta: 19:28:26.707034	Training Loss1 3.2128 (2.8504)	Training Total_Loss 3.2128 (2.8504)	Training Prec@1 99.023 (99.087)	Training Prec@5 0.000 (0.000)	
2022-07-08 06:45:51,109: ============================================================
2022-07-08 06:47:05,171: time cost, forward:0.011925770869671445, backward:0.03381696879203076, data cost:0.689632845814404 
2022-07-08 06:47:05,171: ============================================================
2022-07-08 06:47:05,172: Epoch 24/36 Batch 3700/7662 eta: 19:43:51.224543	Training Loss1 2.7388 (2.8525)	Training Total_Loss 2.7388 (2.8525)	Training Prec@1 99.414 (99.085)	Training Prec@5 0.000 (0.000)	
2022-07-08 06:47:05,172: ============================================================
2022-07-08 06:48:19,158: time cost, forward:0.011924240958787918, backward:0.03380688864107225, data cost:0.6897537690710162 
2022-07-08 06:48:19,158: ============================================================
2022-07-08 06:48:19,158: Epoch 24/36 Batch 3800/7662 eta: 19:41:24.395695	Training Loss1 2.8498 (2.8539)	Training Total_Loss 2.8498 (2.8539)	Training Prec@1 99.023 (99.084)	Training Prec@5 0.000 (0.000)	
2022-07-08 06:48:19,158: ============================================================
2022-07-08 06:49:32,816: time cost, forward:0.01192368223410932, backward:0.03380167511800339, data cost:0.6897718722956644 
2022-07-08 06:49:32,816: ============================================================
2022-07-08 06:49:32,816: Epoch 24/36 Batch 3900/7662 eta: 19:34:55.943514	Training Loss1 2.7665 (2.8560)	Training Total_Loss 2.7665 (2.8560)	Training Prec@1 99.609 (99.080)	Training Prec@5 0.000 (0.000)	
2022-07-08 06:49:32,816: ============================================================
2022-07-08 06:50:47,409: time cost, forward:0.011926965374861934, backward:0.03379832091525842, data cost:0.6900163786087551 
2022-07-08 06:50:47,409: ============================================================
2022-07-08 06:50:47,410: Epoch 24/36 Batch 4000/7662 eta: 19:48:36.550006	Training Loss1 3.1477 (2.8578)	Training Total_Loss 3.1477 (2.8578)	Training Prec@1 98.438 (99.079)	Training Prec@5 0.000 (0.000)	
2022-07-08 06:50:47,410: ============================================================
2022-07-08 06:52:01,347: time cost, forward:0.011910080473491057, backward:0.033814814009879325, data cost:0.6900965717834041 
2022-07-08 06:52:01,348: ============================================================
2022-07-08 06:52:01,348: Epoch 24/36 Batch 4100/7662 eta: 19:36:56.162136	Training Loss1 2.9028 (2.8595)	Training Total_Loss 2.9028 (2.8595)	Training Prec@1 98.633 (99.077)	Training Prec@5 0.000 (0.000)	
2022-07-08 06:52:01,348: ============================================================
2022-07-08 06:53:15,502: time cost, forward:0.011929425718557781, backward:0.03384606087028938, data cost:0.6901649302827599 
2022-07-08 06:53:15,503: ============================================================
2022-07-08 06:53:15,503: Epoch 24/36 Batch 4200/7662 eta: 19:39:08.960282	Training Loss1 2.9030 (2.8610)	Training Total_Loss 2.9030 (2.8610)	Training Prec@1 98.633 (99.075)	Training Prec@5 0.000 (0.000)	
2022-07-08 06:53:15,503: ============================================================
2022-07-08 06:54:29,803: time cost, forward:0.011953613596701239, backward:0.033881950666805175, data cost:0.6902475070332228 
2022-07-08 06:54:29,803: ============================================================
2022-07-08 06:54:29,804: Epoch 24/36 Batch 4300/7662 eta: 19:40:13.878307	Training Loss1 3.0891 (2.8622)	Training Total_Loss 3.0891 (2.8622)	Training Prec@1 98.633 (99.073)	Training Prec@5 0.000 (0.000)	
2022-07-08 06:54:29,804: ============================================================
2022-07-08 06:55:42,557: time cost, forward:0.011962184582983643, backward:0.033908562867255014, data cost:0.6899962750964068 
2022-07-08 06:55:42,557: ============================================================
2022-07-08 06:55:42,558: Epoch 24/36 Batch 4400/7662 eta: 19:14:26.829910	Training Loss1 2.9151 (2.8634)	Training Total_Loss 2.9151 (2.8634)	Training Prec@1 98.438 (99.070)	Training Prec@5 0.000 (0.000)	
2022-07-08 06:55:42,558: ============================================================
2022-07-08 06:56:56,343: time cost, forward:0.01197163585451715, backward:0.033913419998653944, data cost:0.6900222986691473 
2022-07-08 06:56:56,344: ============================================================
2022-07-08 06:56:56,344: Epoch 24/36 Batch 4500/7662 eta: 19:29:35.912252	Training Loss1 2.9237 (2.8651)	Training Total_Loss 2.9237 (2.8651)	Training Prec@1 99.219 (99.069)	Training Prec@5 0.000 (0.000)	
2022-07-08 06:56:56,344: ============================================================
2022-07-08 06:58:09,595: time cost, forward:0.011998908678897958, backward:0.033903985574054156, data cost:0.6899078727468353 
2022-07-08 06:58:09,596: ============================================================
2022-07-08 06:58:09,596: Epoch 24/36 Batch 4600/7662 eta: 19:19:54.680399	Training Loss1 2.7238 (2.8661)	Training Total_Loss 2.7238 (2.8661)	Training Prec@1 99.219 (99.068)	Training Prec@5 0.000 (0.000)	
2022-07-08 06:58:09,596: ============================================================
2022-07-08 06:59:23,309: time cost, forward:0.012005525285778057, backward:0.033928632025871916, data cost:0.6898982494936317 
2022-07-08 06:59:23,309: ============================================================
2022-07-08 06:59:23,309: Epoch 24/36 Batch 4700/7662 eta: 19:25:59.220555	Training Loss1 2.5636 (2.8672)	Training Total_Loss 2.5636 (2.8672)	Training Prec@1 99.219 (99.066)	Training Prec@5 0.000 (0.000)	
2022-07-08 06:59:23,310: ============================================================
2022-07-08 07:00:37,230: time cost, forward:0.012000967249519554, backward:0.03393000909551329, data cost:0.6899614001741308 
2022-07-08 07:00:37,230: ============================================================
2022-07-08 07:00:37,230: Epoch 24/36 Batch 4800/7662 eta: 19:28:02.034737	Training Loss1 2.9973 (2.8690)	Training Total_Loss 2.9973 (2.8690)	Training Prec@1 99.219 (99.063)	Training Prec@5 0.000 (0.000)	
2022-07-08 07:00:37,230: ============================================================
2022-07-08 07:01:50,229: time cost, forward:0.011994847620621241, backward:0.03392640481946127, data cost:0.6898307839713065 
2022-07-08 07:01:50,229: ============================================================
2022-07-08 07:01:50,229: Epoch 24/36 Batch 4900/7662 eta: 19:12:15.070195	Training Loss1 3.0658 (2.8707)	Training Total_Loss 3.0658 (2.8707)	Training Prec@1 99.414 (99.060)	Training Prec@5 0.000 (0.000)	
2022-07-08 07:01:50,229: ============================================================
2022-07-08 07:03:04,659: time cost, forward:0.011977694515801354, backward:0.033930883714737334, data cost:0.6900090701486092 
2022-07-08 07:03:04,659: ============================================================
2022-07-08 07:03:04,659: Epoch 24/36 Batch 5000/7662 eta: 19:33:36.129560	Training Loss1 3.0385 (2.8724)	Training Total_Loss 3.0385 (2.8724)	Training Prec@1 99.219 (99.057)	Training Prec@5 0.000 (0.000)	
2022-07-08 07:03:04,659: ============================================================
2022-07-08 07:04:18,326: time cost, forward:0.011969007401168054, backward:0.03393641502910045, data cost:0.6900110389232916 
2022-07-08 07:04:18,326: ============================================================
2022-07-08 07:04:18,326: Epoch 24/36 Batch 5100/7662 eta: 19:20:20.651549	Training Loss1 2.9184 (2.8734)	Training Total_Loss 2.9184 (2.8734)	Training Prec@1 99.023 (99.055)	Training Prec@5 0.000 (0.000)	
2022-07-08 07:04:18,327: ============================================================
2022-07-08 07:05:33,175: time cost, forward:0.011957480325495241, backward:0.03395338988482986, data cost:0.6902426585116554 
2022-07-08 07:05:33,176: ============================================================
2022-07-08 07:05:33,176: Epoch 24/36 Batch 5200/7662 eta: 19:37:43.180689	Training Loss1 2.9558 (2.8749)	Training Total_Loss 2.9558 (2.8749)	Training Prec@1 98.242 (99.052)	Training Prec@5 0.000 (0.000)	
2022-07-08 07:05:33,176: ============================================================
2022-07-08 07:06:45,658: time cost, forward:0.011941957887691649, backward:0.033951941515549464, data cost:0.6900306804874389 
2022-07-08 07:06:45,659: ============================================================
2022-07-08 07:06:45,659: Epoch 24/36 Batch 5300/7662 eta: 18:59:16.553640	Training Loss1 2.7616 (2.8761)	Training Total_Loss 2.7616 (2.8761)	Training Prec@1 99.219 (99.051)	Training Prec@5 0.000 (0.000)	
2022-07-08 07:06:45,659: ============================================================
2022-07-08 07:07:59,331: time cost, forward:0.011931904953350555, backward:0.033949317082495, data cost:0.6900465435883716 
2022-07-08 07:07:59,331: ============================================================
2022-07-08 07:07:59,331: Epoch 24/36 Batch 5400/7662 eta: 19:16:44.594477	Training Loss1 3.2749 (2.8771)	Training Total_Loss 3.2749 (2.8771)	Training Prec@1 98.828 (99.050)	Training Prec@5 0.000 (0.000)	
2022-07-08 07:07:59,331: ============================================================
2022-07-08 07:09:12,376: time cost, forward:0.011935922010830694, backward:0.03395614270232638, data cost:0.6899218720552118 
2022-07-08 07:09:12,376: ============================================================
2022-07-08 07:09:12,376: Epoch 24/36 Batch 5500/7662 eta: 19:05:40.287029	Training Loss1 2.9882 (2.8788)	Training Total_Loss 2.9882 (2.8788)	Training Prec@1 98.633 (99.048)	Training Prec@5 0.000 (0.000)	
2022-07-08 07:09:12,376: ============================================================
2022-07-08 07:10:26,614: time cost, forward:0.011956747098998697, backward:0.03396647882197537, data cost:0.6900005539009925 
2022-07-08 07:10:26,615: ============================================================
2022-07-08 07:10:26,615: Epoch 24/36 Batch 5600/7662 eta: 19:23:09.573731	Training Loss1 3.2059 (2.8798)	Training Total_Loss 3.2059 (2.8798)	Training Prec@1 97.852 (99.046)	Training Prec@5 0.000 (0.000)	
2022-07-08 07:10:26,615: ============================================================
2022-07-08 07:11:40,742: time cost, forward:0.01197526082174258, backward:0.033946977537710386, data cost:0.6900852397567955 
2022-07-08 07:11:40,743: ============================================================
2022-07-08 07:11:40,743: Epoch 24/36 Batch 5700/7662 eta: 19:20:11.345605	Training Loss1 2.9130 (2.8812)	Training Total_Loss 2.9130 (2.8812)	Training Prec@1 99.023 (99.044)	Training Prec@5 0.000 (0.000)	
2022-07-08 07:11:40,743: ============================================================
2022-07-08 07:12:55,506: time cost, forward:0.011984586756811983, backward:0.03394692169014473, data cost:0.6902561172120919 
2022-07-08 07:12:55,506: ============================================================
2022-07-08 07:12:55,506: Epoch 24/36 Batch 5800/7662 eta: 19:28:53.323958	Training Loss1 2.9011 (2.8828)	Training Total_Loss 2.9011 (2.8828)	Training Prec@1 99.414 (99.042)	Training Prec@5 0.000 (0.000)	
2022-07-08 07:12:55,506: ============================================================
2022-07-08 07:14:09,635: time cost, forward:0.011992073034831964, backward:0.0339377024634892, data cost:0.6903329296099128 
2022-07-08 07:14:09,635: ============================================================
2022-07-08 07:14:09,635: Epoch 24/36 Batch 5900/7662 eta: 19:17:44.061758	Training Loss1 3.0227 (2.8838)	Training Total_Loss 3.0227 (2.8838)	Training Prec@1 99.023 (99.039)	Training Prec@5 0.000 (0.000)	
2022-07-08 07:14:09,635: ============================================================
2022-07-08 07:15:24,269: time cost, forward:0.011982382685169615, backward:0.0339448676544103, data cost:0.6904938747970675 
2022-07-08 07:15:24,270: ============================================================
2022-07-08 07:15:24,270: Epoch 24/36 Batch 6000/7662 eta: 19:24:23.021144	Training Loss1 2.8450 (2.8854)	Training Total_Loss 2.8450 (2.8854)	Training Prec@1 99.023 (99.036)	Training Prec@5 0.000 (0.000)	
2022-07-08 07:15:24,270: ============================================================
2022-07-08 07:16:38,355: time cost, forward:0.011991529273955543, backward:0.03394736726081925, data cost:0.6905441184105648 
2022-07-08 07:16:38,355: ============================================================
2022-07-08 07:16:38,355: Epoch 24/36 Batch 6100/7662 eta: 19:14:35.226134	Training Loss1 2.8076 (2.8863)	Training Total_Loss 2.8076 (2.8863)	Training Prec@1 99.023 (99.035)	Training Prec@5 0.000 (0.000)	
2022-07-08 07:16:38,355: ============================================================
2022-07-08 07:17:51,699: time cost, forward:0.011983874998355723, backward:0.03393689042657667, data cost:0.6905106730106512 
2022-07-08 07:17:51,700: ============================================================
2022-07-08 07:17:51,700: Epoch 24/36 Batch 6200/7662 eta: 19:01:48.841946	Training Loss1 2.7836 (2.8877)	Training Total_Loss 2.7836 (2.8877)	Training Prec@1 99.023 (99.033)	Training Prec@5 0.000 (0.000)	
2022-07-08 07:17:51,700: ============================================================
2022-07-08 07:19:04,614: time cost, forward:0.011983718772145713, backward:0.03393687390395433, data cost:0.6903729912666579 
2022-07-08 07:19:04,615: ============================================================
2022-07-08 07:19:04,615: Epoch 24/36 Batch 6300/7662 eta: 18:53:54.950288	Training Loss1 3.0713 (2.8885)	Training Total_Loss 3.0713 (2.8885)	Training Prec@1 99.023 (99.032)	Training Prec@5 0.000 (0.000)	
2022-07-08 07:19:04,615: ============================================================
2022-07-08 07:20:18,704: time cost, forward:0.011994422609162603, backward:0.033939395775774865, data cost:0.6904127535214181 
2022-07-08 07:20:18,704: ============================================================
2022-07-08 07:20:18,705: Epoch 24/36 Batch 6400/7662 eta: 19:10:56.762219	Training Loss1 2.9164 (2.8898)	Training Total_Loss 2.9164 (2.8898)	Training Prec@1 99.023 (99.029)	Training Prec@5 0.000 (0.000)	
2022-07-08 07:20:18,705: ============================================================
2022-07-08 07:21:33,617: time cost, forward:0.01200239290400897, backward:0.0339304150609094, data cost:0.6906262503933734 
2022-07-08 07:21:33,618: ============================================================
2022-07-08 07:21:33,618: Epoch 24/36 Batch 6500/7662 eta: 19:22:29.633484	Training Loss1 3.1594 (2.8911)	Training Total_Loss 3.1594 (2.8911)	Training Prec@1 98.828 (99.027)	Training Prec@5 0.000 (0.000)	
2022-07-08 07:21:33,618: ============================================================
2022-07-08 07:22:47,595: time cost, forward:0.011996200580021743, backward:0.03392502357967334, data cost:0.6906655383915734 
2022-07-08 07:22:47,595: ============================================================
2022-07-08 07:22:47,596: Epoch 24/36 Batch 6600/7662 eta: 19:06:44.249176	Training Loss1 2.6957 (2.8920)	Training Total_Loss 2.6957 (2.8920)	Training Prec@1 99.219 (99.026)	Training Prec@5 0.000 (0.000)	
2022-07-08 07:22:47,596: ============================================================
2022-07-08 07:24:00,498: time cost, forward:0.011993718371495932, backward:0.033920716911950276, data cost:0.6905629452991386 
2022-07-08 07:24:00,498: ============================================================
2022-07-08 07:24:00,499: Epoch 24/36 Batch 6700/7662 eta: 18:48:52.035727	Training Loss1 3.0731 (2.8935)	Training Total_Loss 3.0731 (2.8935)	Training Prec@1 98.828 (99.022)	Training Prec@5 0.000 (0.000)	
2022-07-08 07:24:00,499: ============================================================
2022-07-08 07:25:14,521: time cost, forward:0.011996167497540908, backward:0.033911280043599605, data cost:0.6906152831612132 
2022-07-08 07:25:14,522: ============================================================
2022-07-08 07:25:14,522: Epoch 24/36 Batch 6800/7662 eta: 19:04:58.770335	Training Loss1 3.0171 (2.8946)	Training Total_Loss 3.0171 (2.8946)	Training Prec@1 97.852 (99.018)	Training Prec@5 0.000 (0.000)	
2022-07-08 07:25:14,522: ============================================================
2022-07-08 07:26:27,716: time cost, forward:0.012003164737876696, backward:0.03390066408388752, data cost:0.6905434113651933 
2022-07-08 07:26:27,717: ============================================================
2022-07-08 07:26:27,717: Epoch 24/36 Batch 6900/7662 eta: 18:50:56.855212	Training Loss1 2.8814 (2.8957)	Training Total_Loss 2.8814 (2.8957)	Training Prec@1 98.828 (99.016)	Training Prec@5 0.000 (0.000)	
2022-07-08 07:26:27,717: ============================================================
2022-07-08 07:27:41,915: time cost, forward:0.011997883516407844, backward:0.03388117275709492, data cost:0.6906334078470321 
2022-07-08 07:27:41,915: ============================================================
2022-07-08 07:27:41,915: Epoch 24/36 Batch 7000/7662 eta: 19:05:12.973687	Training Loss1 3.1078 (2.8967)	Training Total_Loss 3.1078 (2.8967)	Training Prec@1 98.242 (99.014)	Training Prec@5 0.000 (0.000)	
2022-07-08 07:27:41,915: ============================================================
2022-07-08 07:28:56,146: time cost, forward:0.012000215609386985, backward:0.03387483974160704, data cost:0.6907152197599109 
2022-07-08 07:28:56,147: ============================================================
2022-07-08 07:28:56,147: Epoch 24/36 Batch 7100/7662 eta: 19:04:29.304509	Training Loss1 3.1130 (2.8976)	Training Total_Loss 3.1130 (2.8976)	Training Prec@1 98.828 (99.013)	Training Prec@5 0.000 (0.000)	
2022-07-08 07:28:56,147: ============================================================
2022-07-08 07:30:09,811: time cost, forward:0.012001468764690744, backward:0.0338783638396848, data cost:0.6906944496265003 
2022-07-08 07:30:09,812: ============================================================
2022-07-08 07:30:09,812: Epoch 24/36 Batch 7200/7662 eta: 18:54:31.609244	Training Loss1 2.8208 (2.8988)	Training Total_Loss 2.8208 (2.8988)	Training Prec@1 99.219 (99.011)	Training Prec@5 0.000 (0.000)	
2022-07-08 07:30:09,812: ============================================================
2022-07-08 07:31:23,590: time cost, forward:0.012006589755209721, backward:0.03387351205274167, data cost:0.6907093346911043 
2022-07-08 07:31:23,591: ============================================================
2022-07-08 07:31:23,591: Epoch 24/36 Batch 7300/7662 eta: 18:55:03.386682	Training Loss1 3.0477 (2.9001)	Training Total_Loss 3.0477 (2.9001)	Training Prec@1 99.414 (99.009)	Training Prec@5 0.000 (0.000)	
2022-07-08 07:31:23,591: ============================================================
2022-07-08 07:32:38,105: time cost, forward:0.012017188224941995, backward:0.03386838105195663, data cost:0.6908143660654521 
2022-07-08 07:32:38,105: ============================================================
2022-07-08 07:32:38,105: Epoch 24/36 Batch 7400/7662 eta: 19:05:07.440052	Training Loss1 2.9899 (2.9012)	Training Total_Loss 2.9899 (2.9012)	Training Prec@1 98.633 (99.008)	Training Prec@5 0.000 (0.000)	
2022-07-08 07:32:38,105: ============================================================
2022-07-08 07:33:53,408: time cost, forward:0.012021634114203508, backward:0.03388296602439651, data cost:0.6910055775152141 
2022-07-08 07:33:53,408: ============================================================
2022-07-08 07:33:53,408: Epoch 24/36 Batch 7500/7662 eta: 19:15:59.246126	Training Loss1 2.9820 (2.9025)	Training Total_Loss 2.9820 (2.9025)	Training Prec@1 99.023 (99.005)	Training Prec@5 0.000 (0.000)	
2022-07-08 07:33:53,408: ============================================================
2022-07-08 07:35:08,859: time cost, forward:0.012013074049339089, backward:0.033889071943571984, data cost:0.6912336664492245 
2022-07-08 07:35:08,859: ============================================================
2022-07-08 07:35:08,859: Epoch 24/36 Batch 7600/7662 eta: 19:17:00.369140	Training Loss1 2.9475 (2.9035)	Training Total_Loss 2.9475 (2.9035)	Training Prec@1 99.414 (99.003)	Training Prec@5 0.000 (0.000)	
2022-07-08 07:35:08,860: ============================================================
2022-07-08 07:35:56,755: Epoch 24/36 Batch 7663/7662 eta: 19:16:12.834895	Training Loss1 2.8219 (2.9043)	Training Total_Loss 2.8219 (2.9043)	Training Prec@1 99.414 (99.002)	Training Prec@5 0.000 (0.000)	
2022-07-08 07:35:56,756: ============================================================
2022-07-08 07:37:31,259: time cost, forward:0.01126022290701818, backward:0.03194858811118386, data cost:0.9028372571925924 
2022-07-08 07:37:31,259: ============================================================
2022-07-08 07:37:31,260: Epoch 25/36 Batch 100/7662 eta: 1 day, 0:02:38.620299	Training Loss1 2.5952 (2.7585)	Training Total_Loss 2.5952 (2.7585)	Training Prec@1 99.219 (99.181)	Training Prec@5 0.000 (0.000)	
2022-07-08 07:37:31,260: ============================================================
2022-07-08 07:38:44,345: time cost, forward:0.012164566385087056, backward:0.03246100943292206, data cost:0.793025055123334 
2022-07-08 07:38:44,346: ============================================================
2022-07-08 07:38:44,346: Epoch 25/36 Batch 200/7662 eta: 18:37:33.056900	Training Loss1 2.8286 (2.7635)	Training Total_Loss 2.8286 (2.7635)	Training Prec@1 99.023 (99.181)	Training Prec@5 0.000 (0.000)	
2022-07-08 07:38:44,346: ============================================================
2022-07-08 07:39:56,629: time cost, forward:0.01242560845952369, backward:0.032773036223191485, data cost:0.7535445028324191 
2022-07-08 07:39:56,629: ============================================================
2022-07-08 07:39:56,629: Epoch 25/36 Batch 300/7662 eta: 18:24:04.176172	Training Loss1 2.8292 (2.7675)	Training Total_Loss 2.8292 (2.7675)	Training Prec@1 99.414 (99.180)	Training Prec@5 0.000 (0.000)	
2022-07-08 07:39:56,629: ============================================================
2022-07-08 07:41:10,399: time cost, forward:0.012426967310128654, backward:0.03288569247214716, data cost:0.7381628736816254 
2022-07-08 07:41:10,400: ============================================================
2022-07-08 07:41:10,400: Epoch 25/36 Batch 400/7662 eta: 18:45:33.284058	Training Loss1 2.7157 (2.7756)	Training Total_Loss 2.7157 (2.7756)	Training Prec@1 98.828 (99.178)	Training Prec@5 0.000 (0.000)	
2022-07-08 07:41:10,400: ============================================================
2022-07-08 07:42:23,791: time cost, forward:0.012477895300947353, backward:0.03313918820841757, data cost:0.7278140532468746 
2022-07-08 07:42:23,791: ============================================================
2022-07-08 07:42:23,791: Epoch 25/36 Batch 500/7662 eta: 18:38:32.716547	Training Loss1 2.6438 (2.7777)	Training Total_Loss 2.6438 (2.7777)	Training Prec@1 99.023 (99.168)	Training Prec@5 0.000 (0.000)	
2022-07-08 07:42:23,791: ============================================================
2022-07-08 07:43:36,338: time cost, forward:0.012475461912075545, backward:0.03327240211537764, data cost:0.7195603568884288 
2022-07-08 07:43:36,338: ============================================================
2022-07-08 07:43:36,338: Epoch 25/36 Batch 600/7662 eta: 18:24:27.990010	Training Loss1 2.6549 (2.7751)	Training Total_Loss 2.6549 (2.7751)	Training Prec@1 99.219 (99.165)	Training Prec@5 0.000 (0.000)	
2022-07-08 07:43:36,338: ============================================================
2022-07-08 07:44:49,779: time cost, forward:0.012471225640292844, backward:0.03334676110863856, data cost:0.714979365489343 
2022-07-08 07:44:49,779: ============================================================
2022-07-08 07:44:49,780: Epoch 25/36 Batch 700/7662 eta: 18:36:51.563055	Training Loss1 2.6303 (2.7769)	Training Total_Loss 2.6303 (2.7769)	Training Prec@1 99.219 (99.165)	Training Prec@5 0.000 (0.000)	
2022-07-08 07:44:49,780: ============================================================
2022-07-08 07:46:03,189: time cost, forward:0.012462969864712788, backward:0.03344850098534728, data cost:0.7114255285084023 
2022-07-08 07:46:03,189: ============================================================
2022-07-08 07:46:03,189: Epoch 25/36 Batch 800/7662 eta: 18:35:09.293372	Training Loss1 2.9110 (2.7799)	Training Total_Loss 2.9110 (2.7799)	Training Prec@1 99.023 (99.166)	Training Prec@5 0.000 (0.000)	
2022-07-08 07:46:03,189: ============================================================
2022-07-08 07:47:18,261: time cost, forward:0.012463352969278882, backward:0.033504963981959394, data cost:0.7105118204674811 
2022-07-08 07:47:18,261: ============================================================
2022-07-08 07:47:18,262: Epoch 25/36 Batch 900/7662 eta: 18:59:09.480203	Training Loss1 2.6054 (2.7799)	Training Total_Loss 2.6054 (2.7799)	Training Prec@1 99.414 (99.168)	Training Prec@5 0.000 (0.000)	
2022-07-08 07:47:18,262: ============================================================
2022-07-08 07:48:31,945: time cost, forward:0.012466878623695107, backward:0.03356995334377041, data cost:0.7084810435473621 
2022-07-08 07:48:31,946: ============================================================
2022-07-08 07:48:31,946: Epoch 25/36 Batch 1000/7662 eta: 18:36:52.200029	Training Loss1 2.8170 (2.7818)	Training Total_Loss 2.8170 (2.7818)	Training Prec@1 99.414 (99.166)	Training Prec@5 0.000 (0.000)	
2022-07-08 07:48:31,946: ============================================================
2022-07-08 07:49:47,274: time cost, forward:0.012426074360369334, backward:0.0336959450975996, data cost:0.7082484998520772 
2022-07-08 07:49:47,274: ============================================================
2022-07-08 07:49:47,275: Epoch 25/36 Batch 1100/7662 eta: 19:00:32.379667	Training Loss1 2.5051 (2.7847)	Training Total_Loss 2.5051 (2.7847)	Training Prec@1 99.805 (99.161)	Training Prec@5 0.000 (0.000)	
2022-07-08 07:49:47,275: ============================================================
2022-07-08 07:51:01,971: time cost, forward:0.012394737461589594, backward:0.033666013577662475, data cost:0.707624098576537 
2022-07-08 07:51:01,972: ============================================================
2022-07-08 07:51:01,972: Epoch 25/36 Batch 1200/7662 eta: 18:49:44.038451	Training Loss1 2.7637 (2.7870)	Training Total_Loss 2.7637 (2.7870)	Training Prec@1 99.414 (99.163)	Training Prec@5 0.000 (0.000)	
2022-07-08 07:51:01,972: ============================================================
2022-07-08 07:52:16,394: time cost, forward:0.012405550782730068, backward:0.033744394641550254, data cost:0.7067549524167761 
2022-07-08 07:52:16,394: ============================================================
2022-07-08 07:52:16,394: Epoch 25/36 Batch 1300/7662 eta: 18:44:20.150548	Training Loss1 2.7739 (2.7886)	Training Total_Loss 2.7739 (2.7886)	Training Prec@1 99.609 (99.163)	Training Prec@5 0.000 (0.000)	
2022-07-08 07:52:16,394: ============================================================
2022-07-08 07:53:30,518: time cost, forward:0.012387738558460424, backward:0.033742668630396835, data cost:0.7058843180824809 
2022-07-08 07:53:30,518: ============================================================
2022-07-08 07:53:30,519: Epoch 25/36 Batch 1400/7662 eta: 18:38:35.944582	Training Loss1 2.6904 (2.7909)	Training Total_Loss 2.6904 (2.7909)	Training Prec@1 99.414 (99.161)	Training Prec@5 0.000 (0.000)	
2022-07-08 07:53:30,519: ============================================================
2022-07-08 07:54:44,751: time cost, forward:0.012390547072275071, backward:0.03370639035668351, data cost:0.7052290764071291 
2022-07-08 07:54:44,751: ============================================================
2022-07-08 07:54:44,751: Epoch 25/36 Batch 1500/7662 eta: 18:38:59.912248	Training Loss1 3.0680 (2.7915)	Training Total_Loss 3.0680 (2.7915)	Training Prec@1 99.219 (99.164)	Training Prec@5 0.000 (0.000)	
2022-07-08 07:54:44,752: ============================================================
2022-07-08 07:55:59,165: time cost, forward:0.012309720472964442, backward:0.033756483488339345, data cost:0.704773843549355 
2022-07-08 07:55:59,165: ============================================================
2022-07-08 07:55:59,165: Epoch 25/36 Batch 1600/7662 eta: 18:40:29.222785	Training Loss1 2.8709 (2.7936)	Training Total_Loss 2.8709 (2.7936)	Training Prec@1 99.023 (99.161)	Training Prec@5 0.000 (0.000)	
2022-07-08 07:55:59,165: ============================================================
2022-07-08 07:57:13,574: time cost, forward:0.012307280438868279, backward:0.03375947861337465, data cost:0.7043222986718639 
2022-07-08 07:57:13,574: ============================================================
2022-07-08 07:57:13,574: Epoch 25/36 Batch 1700/7662 eta: 18:39:10.458780	Training Loss1 2.8164 (2.7959)	Training Total_Loss 2.8164 (2.7959)	Training Prec@1 99.414 (99.158)	Training Prec@5 0.000 (0.000)	
2022-07-08 07:57:13,575: ============================================================
2022-07-08 07:58:27,097: time cost, forward:0.012313772268332397, backward:0.033780822626678995, data cost:0.7034498848737512 
2022-07-08 07:58:27,097: ============================================================
2022-07-08 07:58:27,097: Epoch 25/36 Batch 1800/7662 eta: 18:24:37.087841	Training Loss1 2.8372 (2.7980)	Training Total_Loss 2.8372 (2.7980)	Training Prec@1 99.805 (99.156)	Training Prec@5 0.000 (0.000)	
2022-07-08 07:58:27,097: ============================================================
2022-07-08 07:59:42,578: time cost, forward:0.012350292441843685, backward:0.03385747401823553, data cost:0.7035752021996456 
2022-07-08 07:59:42,578: ============================================================
2022-07-08 07:59:42,579: Epoch 25/36 Batch 1900/7662 eta: 18:52:47.100622	Training Loss1 2.8973 (2.7998)	Training Total_Loss 2.8973 (2.7998)	Training Prec@1 98.633 (99.152)	Training Prec@5 0.000 (0.000)	
2022-07-08 07:59:42,579: ============================================================
2022-07-08 08:00:56,604: time cost, forward:0.012375763620717219, backward:0.03392013315560521, data cost:0.7029664762142958 
2022-07-08 08:00:56,604: ============================================================
2022-07-08 08:00:56,604: Epoch 25/36 Batch 2000/7662 eta: 18:29:42.442325	Training Loss1 2.9667 (2.8021)	Training Total_Loss 2.9667 (2.8021)	Training Prec@1 98.828 (99.147)	Training Prec@5 0.000 (0.000)	
2022-07-08 08:00:56,604: ============================================================
2022-07-08 08:02:12,085: time cost, forward:0.01231820098328102, backward:0.03397589913432288, data cost:0.7032193580998188 
2022-07-08 08:02:12,085: ============================================================
2022-07-08 08:02:12,085: Epoch 25/36 Batch 2100/7662 eta: 18:50:15.968022	Training Loss1 2.9913 (2.8046)	Training Total_Loss 2.9913 (2.8046)	Training Prec@1 98.828 (99.148)	Training Prec@5 0.000 (0.000)	
2022-07-08 08:02:12,085: ============================================================
2022-07-08 08:03:26,817: time cost, forward:0.012319324774436377, backward:0.03402457631897417, data cost:0.703021880982951 
2022-07-08 08:03:26,817: ============================================================
2022-07-08 08:03:26,817: Epoch 25/36 Batch 2200/7662 eta: 18:37:48.064466	Training Loss1 2.7066 (2.8058)	Training Total_Loss 2.7066 (2.8058)	Training Prec@1 99.414 (99.147)	Training Prec@5 0.000 (0.000)	
2022-07-08 08:03:26,817: ============================================================
2022-07-08 08:04:41,481: time cost, forward:0.012328280008788106, backward:0.03403322786909438, data cost:0.7028731749129327 
2022-07-08 08:04:41,481: ============================================================
2022-07-08 08:04:41,482: Epoch 25/36 Batch 2300/7662 eta: 18:35:33.012183	Training Loss1 2.9324 (2.8076)	Training Total_Loss 2.9324 (2.8076)	Training Prec@1 99.219 (99.146)	Training Prec@5 0.000 (0.000)	
2022-07-08 08:04:41,482: ============================================================
2022-07-08 08:05:56,698: time cost, forward:0.012317968736642993, backward:0.03404128596205272, data cost:0.7029737176970672 
2022-07-08 08:05:56,698: ============================================================
2022-07-08 08:05:56,699: Epoch 25/36 Batch 2400/7662 eta: 18:42:33.144851	Training Loss1 2.8891 (2.8089)	Training Total_Loss 2.8891 (2.8089)	Training Prec@1 99.219 (99.144)	Training Prec@5 0.000 (0.000)	
2022-07-08 08:05:56,699: ============================================================
2022-07-08 08:07:11,344: time cost, forward:0.012323725648096152, backward:0.03405571460914688, data cost:0.7027776253705218 
2022-07-08 08:07:11,345: ============================================================
2022-07-08 08:07:11,345: Epoch 25/36 Batch 2500/7662 eta: 18:32:47.129972	Training Loss1 2.8154 (2.8114)	Training Total_Loss 2.8154 (2.8114)	Training Prec@1 99.609 (99.140)	Training Prec@5 0.000 (0.000)	
2022-07-08 08:07:11,345: ============================================================
2022-07-08 08:08:26,067: time cost, forward:0.012317299154823953, backward:0.03408454674489226, data cost:0.7026930108534551 
2022-07-08 08:08:26,067: ============================================================
2022-07-08 08:08:26,068: Epoch 25/36 Batch 2600/7662 eta: 18:32:41.070338	Training Loss1 3.2163 (2.8132)	Training Total_Loss 3.2163 (2.8132)	Training Prec@1 99.414 (99.140)	Training Prec@5 0.000 (0.000)	
2022-07-08 08:08:26,068: ============================================================
2022-07-08 08:09:40,029: time cost, forward:0.012305363145922236, backward:0.03409486984756091, data cost:0.7022619563679026 
2022-07-08 08:09:40,029: ============================================================
2022-07-08 08:09:40,029: Epoch 25/36 Batch 2700/7662 eta: 18:20:07.360633	Training Loss1 3.0117 (2.8154)	Training Total_Loss 3.0117 (2.8154)	Training Prec@1 98.438 (99.136)	Training Prec@5 0.000 (0.000)	
2022-07-08 08:09:40,030: ============================================================
2022-07-08 08:10:55,192: time cost, forward:0.012288116991370864, backward:0.03410368776611023, data cost:0.7023994996744465 
2022-07-08 08:10:55,192: ============================================================
2022-07-08 08:10:55,193: Epoch 25/36 Batch 2800/7662 eta: 18:36:44.227751	Training Loss1 2.7809 (2.8180)	Training Total_Loss 2.7809 (2.8180)	Training Prec@1 99.609 (99.130)	Training Prec@5 0.000 (0.000)	
2022-07-08 08:10:55,193: ============================================================
2022-07-08 08:12:09,537: time cost, forward:0.012268687577525597, backward:0.03412439133143088, data cost:0.7021887491554505 
2022-07-08 08:12:09,537: ============================================================
2022-07-08 08:12:09,538: Epoch 25/36 Batch 2900/7662 eta: 18:23:20.425663	Training Loss1 2.7981 (2.8190)	Training Total_Loss 2.7981 (2.8190)	Training Prec@1 99.805 (99.128)	Training Prec@5 0.000 (0.000)	
2022-07-08 08:12:09,538: ============================================================
2022-07-08 08:13:24,228: time cost, forward:0.012257553728948874, backward:0.034133118603697776, data cost:0.7021275779810616 
2022-07-08 08:13:24,229: ============================================================
2022-07-08 08:13:24,229: Epoch 25/36 Batch 3000/7662 eta: 18:27:14.360991	Training Loss1 2.8485 (2.8210)	Training Total_Loss 2.8485 (2.8210)	Training Prec@1 99.219 (99.126)	Training Prec@5 0.000 (0.000)	
2022-07-08 08:13:24,229: ============================================================
2022-07-08 08:14:39,046: time cost, forward:0.01224761695467914, backward:0.03413704104021927, data cost:0.7020940011299284 
2022-07-08 08:14:39,046: ============================================================
2022-07-08 08:14:39,047: Epoch 25/36 Batch 3100/7662 eta: 18:27:51.562223	Training Loss1 3.1133 (2.8235)	Training Total_Loss 3.1133 (2.8235)	Training Prec@1 99.023 (99.125)	Training Prec@5 0.000 (0.000)	
2022-07-08 08:14:39,047: ============================================================
2022-07-08 08:15:53,739: time cost, forward:0.01226861784703361, backward:0.034150086182585054, data cost:0.7020010921350678 
2022-07-08 08:15:53,740: ============================================================
2022-07-08 08:15:53,740: Epoch 25/36 Batch 3200/7662 eta: 18:24:46.610775	Training Loss1 2.7363 (2.8248)	Training Total_Loss 2.7363 (2.8248)	Training Prec@1 99.609 (99.122)	Training Prec@5 0.000 (0.000)	
2022-07-08 08:15:53,740: ============================================================
2022-07-08 08:17:08,496: time cost, forward:0.012262256407817229, backward:0.0341618733898948, data cost:0.701947776792121 
2022-07-08 08:17:08,496: ============================================================
2022-07-08 08:17:08,496: Epoch 25/36 Batch 3300/7662 eta: 18:24:27.862233	Training Loss1 2.7885 (2.8264)	Training Total_Loss 2.7885 (2.8264)	Training Prec@1 98.828 (99.120)	Training Prec@5 0.000 (0.000)	
2022-07-08 08:17:08,496: ============================================================
2022-07-08 08:18:23,999: time cost, forward:0.012283849519784045, backward:0.034158121596086936, data cost:0.7021104625899429 
2022-07-08 08:18:23,999: ============================================================
2022-07-08 08:18:23,999: Epoch 25/36 Batch 3400/7662 eta: 18:34:13.813229	Training Loss1 2.6794 (2.8282)	Training Total_Loss 2.6794 (2.8282)	Training Prec@1 99.805 (99.119)	Training Prec@5 0.000 (0.000)	
2022-07-08 08:18:23,999: ============================================================
2022-07-08 08:19:39,151: time cost, forward:0.012284444992662872, backward:0.034165306955311905, data cost:0.7021714203287514 
2022-07-08 08:19:39,151: ============================================================
2022-07-08 08:19:39,151: Epoch 25/36 Batch 3500/7662 eta: 18:27:48.223680	Training Loss1 2.9062 (2.8300)	Training Total_Loss 2.9062 (2.8300)	Training Prec@1 99.609 (99.119)	Training Prec@5 0.000 (0.000)	
2022-07-08 08:19:39,151: ============================================================
2022-07-08 08:20:53,368: time cost, forward:0.012285572716049699, backward:0.03417104944715105, data cost:0.7019590706121727 
2022-07-08 08:20:53,368: ============================================================
2022-07-08 08:20:53,368: Epoch 25/36 Batch 3600/7662 eta: 18:12:47.249408	Training Loss1 3.1585 (2.8314)	Training Total_Loss 3.1585 (2.8314)	Training Prec@1 98.633 (99.117)	Training Prec@5 0.000 (0.000)	
2022-07-08 08:20:53,368: ============================================================
2022-07-08 08:22:09,484: time cost, forward:0.012283514305912955, backward:0.03417869437930068, data cost:0.7022751021559221 
2022-07-08 08:22:09,484: ============================================================
2022-07-08 08:22:09,484: Epoch 25/36 Batch 3700/7662 eta: 18:39:28.546682	Training Loss1 2.7588 (2.8332)	Training Total_Loss 2.7588 (2.8332)	Training Prec@1 99.609 (99.114)	Training Prec@5 0.000 (0.000)	
2022-07-08 08:22:09,484: ============================================================
2022-07-08 08:23:23,937: time cost, forward:0.01228651701697992, backward:0.03419370863367991, data cost:0.7021477472220449 
2022-07-08 08:23:23,937: ============================================================
2022-07-08 08:23:23,937: Epoch 25/36 Batch 3800/7662 eta: 18:13:46.564337	Training Loss1 3.1460 (2.8352)	Training Total_Loss 3.1460 (2.8352)	Training Prec@1 98.047 (99.113)	Training Prec@5 0.000 (0.000)	
2022-07-08 08:23:23,937: ============================================================
2022-07-08 08:24:38,929: time cost, forward:0.012271729271422291, backward:0.03420928998860557, data cost:0.7021612842806366 
2022-07-08 08:24:38,929: ============================================================
2022-07-08 08:24:38,930: Epoch 25/36 Batch 3900/7662 eta: 18:20:27.035009	Training Loss1 2.5492 (2.8370)	Training Total_Loss 2.5492 (2.8370)	Training Prec@1 98.633 (99.110)	Training Prec@5 0.000 (0.000)	
2022-07-08 08:24:38,930: ============================================================
2022-07-08 08:25:53,105: time cost, forward:0.0122581296159077, backward:0.03421935852720428, data cost:0.7019794929263055 
2022-07-08 08:25:53,106: ============================================================
2022-07-08 08:25:53,106: Epoch 25/36 Batch 4000/7662 eta: 18:07:14.319191	Training Loss1 3.1060 (2.8387)	Training Total_Loss 3.1060 (2.8387)	Training Prec@1 99.609 (99.109)	Training Prec@5 0.000 (0.000)	
2022-07-08 08:25:53,106: ============================================================
2022-07-08 08:27:09,893: time cost, forward:0.012257997336460923, backward:0.034211609647983046, data cost:0.7023718870102007 
2022-07-08 08:27:09,893: ============================================================
2022-07-08 08:27:09,893: Epoch 25/36 Batch 4100/7662 eta: 18:44:13.700738	Training Loss1 2.8277 (2.8403)	Training Total_Loss 2.8277 (2.8403)	Training Prec@1 99.414 (99.107)	Training Prec@5 0.000 (0.000)	
2022-07-08 08:27:09,893: ============================================================
2022-07-08 08:28:25,176: time cost, forward:0.01224449243565973, backward:0.03421880739534092, data cost:0.7024776852111017 
2022-07-08 08:28:25,176: ============================================================
2022-07-08 08:28:25,176: Epoch 25/36 Batch 4200/7662 eta: 18:20:57.346371	Training Loss1 2.9924 (2.8426)	Training Total_Loss 2.9924 (2.8426)	Training Prec@1 98.828 (99.104)	Training Prec@5 0.000 (0.000)	
2022-07-08 08:28:25,177: ============================================================
2022-07-08 08:29:40,592: time cost, forward:0.012243466422734745, backward:0.03420284965144226, data cost:0.7026546354154066 
2022-07-08 08:29:40,592: ============================================================
2022-07-08 08:29:40,592: Epoch 25/36 Batch 4300/7662 eta: 18:21:38.269518	Training Loss1 2.9040 (2.8442)	Training Total_Loss 2.9040 (2.8442)	Training Prec@1 99.219 (99.103)	Training Prec@5 0.000 (0.000)	
2022-07-08 08:29:40,592: ============================================================
2022-07-08 08:30:55,087: time cost, forward:0.012218436589970537, backward:0.03421175054431801, data cost:0.7025672204658697 
2022-07-08 08:30:55,087: ============================================================
2022-07-08 08:30:55,087: Epoch 25/36 Batch 4400/7662 eta: 18:06:56.556646	Training Loss1 3.0487 (2.8457)	Training Total_Loss 3.0487 (2.8457)	Training Prec@1 99.219 (99.102)	Training Prec@5 0.000 (0.000)	
2022-07-08 08:30:55,087: ============================================================
2022-07-08 08:32:08,921: time cost, forward:0.012207840039587518, backward:0.03420792073243246, data cost:0.7023255628436161 
2022-07-08 08:32:08,922: ============================================================
2022-07-08 08:32:08,922: Epoch 25/36 Batch 4500/7662 eta: 17:56:04.577131	Training Loss1 3.1304 (2.8473)	Training Total_Loss 3.1304 (2.8473)	Training Prec@1 97.852 (99.100)	Training Prec@5 0.000 (0.000)	
2022-07-08 08:32:08,922: ============================================================
2022-07-08 08:33:24,221: time cost, forward:0.012208656114867315, backward:0.03419844164333024, data cost:0.7024189465251739 
2022-07-08 08:33:24,222: ============================================================
2022-07-08 08:33:24,222: Epoch 25/36 Batch 4600/7662 eta: 18:16:10.810781	Training Loss1 3.0030 (2.8486)	Training Total_Loss 3.0030 (2.8486)	Training Prec@1 99.219 (99.098)	Training Prec@5 0.000 (0.000)	
2022-07-08 08:33:24,222: ============================================================
2022-07-08 08:34:38,100: time cost, forward:0.012193582240102849, backward:0.03419380239741197, data cost:0.7022021114635935 
2022-07-08 08:34:38,100: ============================================================
2022-07-08 08:34:38,101: Epoch 25/36 Batch 4700/7662 eta: 17:54:15.615356	Training Loss1 2.8398 (2.8499)	Training Total_Loss 2.8398 (2.8499)	Training Prec@1 99.609 (99.096)	Training Prec@5 0.000 (0.000)	
2022-07-08 08:34:38,101: ============================================================
2022-07-08 08:35:54,905: time cost, forward:0.012216378162492934, backward:0.03418896411403712, data cost:0.7025862938415312 
2022-07-08 08:35:54,905: ============================================================
2022-07-08 08:35:54,906: Epoch 25/36 Batch 4800/7662 eta: 18:35:31.578726	Training Loss1 2.8394 (2.8511)	Training Total_Loss 2.8394 (2.8511)	Training Prec@1 98.828 (99.095)	Training Prec@5 0.000 (0.000)	
2022-07-08 08:35:54,906: ============================================================
2022-07-08 08:37:09,649: time cost, forward:0.012209684465777804, backward:0.03420227278152469, data cost:0.7025371214934187 
2022-07-08 08:37:09,649: ============================================================
2022-07-08 08:37:09,650: Epoch 25/36 Batch 4900/7662 eta: 18:04:21.093656	Training Loss1 3.0765 (2.8524)	Training Total_Loss 3.0765 (2.8524)	Training Prec@1 99.414 (99.094)	Training Prec@5 0.000 (0.000)	
2022-07-08 08:37:09,650: ============================================================
2022-07-08 08:38:25,615: time cost, forward:0.01220946732605188, backward:0.03420818011792666, data cost:0.7027291411231771 
2022-07-08 08:38:25,615: ============================================================
2022-07-08 08:38:25,616: Epoch 25/36 Batch 5000/7662 eta: 18:20:48.458217	Training Loss1 2.8598 (2.8533)	Training Total_Loss 2.8598 (2.8533)	Training Prec@1 98.633 (99.092)	Training Prec@5 0.000 (0.000)	
2022-07-08 08:38:25,616: ============================================================
2022-07-08 08:39:41,245: time cost, forward:0.012211391939371562, backward:0.0342154678678391, data cost:0.7028532379817719 
2022-07-08 08:39:41,245: ============================================================
2022-07-08 08:39:41,246: Epoch 25/36 Batch 5100/7662 eta: 18:14:40.964082	Training Loss1 2.9680 (2.8545)	Training Total_Loss 2.9680 (2.8545)	Training Prec@1 99.219 (99.091)	Training Prec@5 0.000 (0.000)	
2022-07-08 08:39:41,246: ============================================================
2022-07-08 08:40:56,365: time cost, forward:0.012210784175804566, backward:0.03422742523718715, data cost:0.7028659559438082 
2022-07-08 08:40:56,366: ============================================================
2022-07-08 08:40:56,366: Epoch 25/36 Batch 5200/7662 eta: 18:06:02.973781	Training Loss1 2.7559 (2.8559)	Training Total_Loss 2.7559 (2.8559)	Training Prec@1 99.219 (99.090)	Training Prec@5 0.000 (0.000)	
2022-07-08 08:40:56,366: ============================================================
2022-07-08 08:42:11,313: time cost, forward:0.012203145958518371, backward:0.034238715692834376, data cost:0.7028540275888322 
2022-07-08 08:42:11,314: ============================================================
2022-07-08 08:42:11,314: Epoch 25/36 Batch 5300/7662 eta: 18:02:18.855278	Training Loss1 3.0164 (2.8572)	Training Total_Loss 3.0164 (2.8572)	Training Prec@1 98.633 (99.088)	Training Prec@5 0.000 (0.000)	
2022-07-08 08:42:11,314: ============================================================
2022-07-08 08:43:25,799: time cost, forward:0.01220256236995408, backward:0.03424641440854865, data cost:0.7027502327986306 
2022-07-08 08:43:25,800: ============================================================
2022-07-08 08:43:25,800: Epoch 25/36 Batch 5400/7662 eta: 17:54:23.690033	Training Loss1 2.9536 (2.8591)	Training Total_Loss 2.9536 (2.8591)	Training Prec@1 99.414 (99.086)	Training Prec@5 0.000 (0.000)	
2022-07-08 08:43:25,800: ============================================================
2022-07-08 08:44:41,751: time cost, forward:0.01220079863541862, backward:0.03425955486245579, data cost:0.702920887638903 
2022-07-08 08:44:41,752: ============================================================
2022-07-08 08:44:41,752: Epoch 25/36 Batch 5500/7662 eta: 18:14:16.881502	Training Loss1 2.9210 (2.8607)	Training Total_Loss 2.9210 (2.8607)	Training Prec@1 98.828 (99.082)	Training Prec@5 0.000 (0.000)	
2022-07-08 08:44:41,752: ============================================================
2022-07-08 08:45:56,438: time cost, forward:0.012192996575760402, backward:0.03426823962648163, data cost:0.7028617822691721 
2022-07-08 08:45:56,438: ============================================================
2022-07-08 08:45:56,439: Epoch 25/36 Batch 5600/7662 eta: 17:54:48.149273	Training Loss1 2.9198 (2.8623)	Training Total_Loss 2.9198 (2.8623)	Training Prec@1 98.633 (99.079)	Training Prec@5 0.000 (0.000)	
2022-07-08 08:45:56,439: ============================================================
2022-07-08 08:47:12,078: time cost, forward:0.012187994955129467, backward:0.03427037918310371, data cost:0.7029793736055705 
2022-07-08 08:47:12,078: ============================================================
2022-07-08 08:47:12,078: Epoch 25/36 Batch 5700/7662 eta: 18:07:15.235902	Training Loss1 2.9541 (2.8636)	Training Total_Loss 2.9541 (2.8636)	Training Prec@1 98.242 (99.077)	Training Prec@5 0.000 (0.000)	
2022-07-08 08:47:12,078: ============================================================
2022-07-08 08:48:27,026: time cost, forward:0.012179602259375921, backward:0.03427509608649451, data cost:0.70296791159381 
2022-07-08 08:48:27,026: ============================================================
2022-07-08 08:48:27,026: Epoch 25/36 Batch 5800/7662 eta: 17:56:04.011247	Training Loss1 2.8523 (2.8649)	Training Total_Loss 2.8523 (2.8649)	Training Prec@1 97.852 (99.075)	Training Prec@5 0.000 (0.000)	
2022-07-08 08:48:27,026: ============================================================
2022-07-08 08:49:41,847: time cost, forward:0.012176463999653655, backward:0.03427029937217752, data cost:0.7029487851070618 
2022-07-08 08:49:41,847: ============================================================
2022-07-08 08:49:41,847: Epoch 25/36 Batch 5900/7662 eta: 17:53:00.009561	Training Loss1 3.0245 (2.8663)	Training Total_Loss 3.0245 (2.8663)	Training Prec@1 98.242 (99.072)	Training Prec@5 0.000 (0.000)	
2022-07-08 08:49:41,847: ============================================================
2022-07-08 08:50:56,447: time cost, forward:0.012159868645099704, backward:0.03427213294284704, data cost:0.7028984424968147 
2022-07-08 08:50:56,447: ============================================================
2022-07-08 08:50:56,448: Epoch 25/36 Batch 6000/7662 eta: 17:48:35.091839	Training Loss1 2.8728 (2.8673)	Training Total_Loss 2.8728 (2.8673)	Training Prec@1 98.242 (99.071)	Training Prec@5 0.000 (0.000)	
2022-07-08 08:50:56,448: ============================================================
2022-07-08 08:52:11,577: time cost, forward:0.012164696608826575, backward:0.034255418294295854, data cost:0.7029341301149492 
2022-07-08 08:52:11,578: ============================================================
2022-07-08 08:52:11,578: Epoch 25/36 Batch 6100/7662 eta: 17:54:55.588881	Training Loss1 3.1647 (2.8686)	Training Total_Loss 3.1647 (2.8686)	Training Prec@1 98.828 (99.069)	Training Prec@5 0.000 (0.000)	
2022-07-08 08:52:11,578: ============================================================
2022-07-08 08:53:26,485: time cost, forward:0.012170321942529557, backward:0.03425823601816408, data cost:0.7029090146130758 
2022-07-08 08:53:26,485: ============================================================
2022-07-08 08:53:26,486: Epoch 25/36 Batch 6200/7662 eta: 17:50:29.603534	Training Loss1 3.0158 (2.8703)	Training Total_Loss 3.0158 (2.8703)	Training Prec@1 99.023 (99.065)	Training Prec@5 0.000 (0.000)	
2022-07-08 08:53:26,486: ============================================================
2022-07-08 08:54:41,622: time cost, forward:0.012167725492647894, backward:0.03426667322599996, data cost:0.7029261394878629 
2022-07-08 08:54:41,622: ============================================================
2022-07-08 08:54:41,622: Epoch 25/36 Batch 6300/7662 eta: 17:52:30.819495	Training Loss1 2.9343 (2.8718)	Training Total_Loss 2.9343 (2.8718)	Training Prec@1 99.219 (99.063)	Training Prec@5 0.000 (0.000)	
2022-07-08 08:54:41,622: ============================================================
2022-07-08 08:55:56,630: time cost, forward:0.012168751040144364, backward:0.03427969934344571, data cost:0.7029167785367326 
2022-07-08 08:55:56,630: ============================================================
2022-07-08 08:55:56,631: Epoch 25/36 Batch 6400/7662 eta: 17:49:25.903320	Training Loss1 2.9147 (2.8736)	Training Total_Loss 2.9147 (2.8736)	Training Prec@1 99.023 (99.061)	Training Prec@5 0.000 (0.000)	
2022-07-08 08:55:56,631: ============================================================
2022-07-08 08:57:11,474: time cost, forward:0.012170081102659124, backward:0.03429583722507978, data cost:0.7028649602785241 
2022-07-08 08:57:11,474: ============================================================
2022-07-08 08:57:11,474: Epoch 25/36 Batch 6500/7662 eta: 17:45:50.213871	Training Loss1 3.1179 (2.8749)	Training Total_Loss 3.1179 (2.8749)	Training Prec@1 98.828 (99.060)	Training Prec@5 0.000 (0.000)	
2022-07-08 08:57:11,474: ============================================================
2022-07-08 08:58:24,536: time cost, forward:0.01216895082788515, backward:0.03431277875557761, data cost:0.7025648688778658 
2022-07-08 08:58:24,537: ============================================================
2022-07-08 08:58:24,537: Epoch 25/36 Batch 6600/7662 eta: 17:19:15.341809	Training Loss1 3.0873 (2.8761)	Training Total_Loss 3.0873 (2.8761)	Training Prec@1 98.438 (99.058)	Training Prec@5 0.000 (0.000)	
2022-07-08 08:58:24,537: ============================================================
2022-07-08 08:59:40,031: time cost, forward:0.01216744714609668, backward:0.034296324829999, data cost:0.702660093380099 
2022-07-08 08:59:40,031: ============================================================
2022-07-08 08:59:40,031: Epoch 25/36 Batch 6700/7662 eta: 17:52:35.062285	Training Loss1 3.0106 (2.8771)	Training Total_Loss 3.0106 (2.8771)	Training Prec@1 99.219 (99.055)	Training Prec@5 0.000 (0.000)	
2022-07-08 08:59:40,031: ============================================================
2022-07-08 09:00:54,995: time cost, forward:0.012169746637940494, backward:0.03429860363183328, data cost:0.702656713649269 
2022-07-08 09:00:54,995: ============================================================
2022-07-08 09:00:54,995: Epoch 25/36 Batch 6800/7662 eta: 17:43:48.124585	Training Loss1 3.0954 (2.8785)	Training Total_Loss 3.0954 (2.8785)	Training Prec@1 98.828 (99.054)	Training Prec@5 0.000 (0.000)	
2022-07-08 09:00:54,995: ============================================================
2022-07-08 09:02:10,706: time cost, forward:0.01218170649004183, backward:0.034306355914718464, data cost:0.7027442080678413 
2022-07-08 09:02:10,706: ============================================================
2022-07-08 09:02:10,706: Epoch 25/36 Batch 6900/7662 eta: 17:53:08.486833	Training Loss1 2.8831 (2.8798)	Training Total_Loss 2.8831 (2.8798)	Training Prec@1 98.633 (99.051)	Training Prec@5 0.000 (0.000)	
2022-07-08 09:02:10,706: ============================================================
2022-07-08 09:03:26,283: time cost, forward:0.012185043565783097, backward:0.034318931001580635, data cost:0.7028105253831951 
2022-07-08 09:03:26,283: ============================================================
2022-07-08 09:03:26,283: Epoch 25/36 Batch 7000/7662 eta: 17:49:58.694017	Training Loss1 3.1430 (2.8814)	Training Total_Loss 3.1430 (2.8814)	Training Prec@1 98.047 (99.049)	Training Prec@5 0.000 (0.000)	
2022-07-08 09:03:26,283: ============================================================
2022-07-08 09:04:41,356: time cost, forward:0.01219112800198351, backward:0.03432911754510893, data cost:0.7028075768118393 
2022-07-08 09:04:41,356: ============================================================
2022-07-08 09:04:41,356: Epoch 25/36 Batch 7100/7662 eta: 17:41:35.944322	Training Loss1 3.1463 (2.8825)	Training Total_Loss 3.1463 (2.8825)	Training Prec@1 98.242 (99.046)	Training Prec@5 0.000 (0.000)	
2022-07-08 09:04:41,356: ============================================================
2022-07-08 09:05:56,973: time cost, forward:0.012186872543502408, backward:0.03433091313594877, data cost:0.7028946733786043 
2022-07-08 09:05:56,973: ============================================================
2022-07-08 09:05:56,974: Epoch 25/36 Batch 7200/7662 eta: 17:48:01.817875	Training Loss1 2.5232 (2.8835)	Training Total_Loss 2.5232 (2.8835)	Training Prec@1 98.633 (99.045)	Training Prec@5 0.000 (0.000)	
2022-07-08 09:05:56,974: ============================================================
2022-07-08 09:07:11,669: time cost, forward:0.012195562855775005, backward:0.034328586027252785, data cost:0.7028464676501213 
2022-07-08 09:07:11,669: ============================================================
2022-07-08 09:07:11,669: Epoch 25/36 Batch 7300/7662 eta: 17:33:46.212541	Training Loss1 2.9905 (2.8850)	Training Total_Loss 2.9905 (2.8850)	Training Prec@1 99.023 (99.042)	Training Prec@5 0.000 (0.000)	
2022-07-08 09:07:11,669: ============================================================
2022-07-08 09:08:25,208: time cost, forward:0.012190228588662609, backward:0.034330579006505955, data cost:0.7026510042731127 
2022-07-08 09:08:25,209: ============================================================
2022-07-08 09:08:25,209: Epoch 25/36 Batch 7400/7662 eta: 17:16:13.849532	Training Loss1 3.1517 (2.8864)	Training Total_Loss 3.1517 (2.8864)	Training Prec@1 98.633 (99.038)	Training Prec@5 0.000 (0.000)	
2022-07-08 09:08:25,209: ============================================================
2022-07-08 09:09:40,230: time cost, forward:0.01218923477669337, backward:0.034337191982958565, data cost:0.7026519278460048 
2022-07-08 09:09:40,231: ============================================================
2022-07-08 09:09:40,231: Epoch 25/36 Batch 7500/7662 eta: 17:35:52.349707	Training Loss1 2.9549 (2.8878)	Training Total_Loss 2.9549 (2.8878)	Training Prec@1 98.633 (99.036)	Training Prec@5 0.000 (0.000)	
2022-07-08 09:09:40,231: ============================================================
2022-07-08 09:10:54,117: time cost, forward:0.012190055621268013, backward:0.03434732252397825, data cost:0.7024996027787714 
2022-07-08 09:10:54,118: ============================================================
2022-07-08 09:10:54,118: Epoch 25/36 Batch 7600/7662 eta: 17:18:40.031445	Training Loss1 3.1266 (2.8888)	Training Total_Loss 3.1266 (2.8888)	Training Prec@1 99.023 (99.035)	Training Prec@5 0.000 (0.000)	
2022-07-08 09:10:54,118: ============================================================
2022-07-08 09:11:42,639: Epoch 25/36 Batch 7663/7662 eta: 17:17:53.482604	Training Loss1 2.9106 (2.8896)	Training Total_Loss 2.9106 (2.8896)	Training Prec@1 99.219 (99.034)	Training Prec@5 0.000 (0.000)	
2022-07-08 09:11:42,639: ============================================================
2022-07-08 09:11:42,925: Save Checkpoint...
2022-07-08 09:11:42,926: ============================================================
2022-07-08 09:11:45,734: Save done!
2022-07-08 09:11:45,734: ============================================================
2022-07-08 09:13:38,684: time cost, forward:0.01093391938643022, backward:0.03382562868522875, data cost:1.0890917055534595 
2022-07-08 09:13:38,684: ============================================================
2022-07-08 09:13:38,684: Epoch 26/36 Batch 100/7662 eta: 1 day, 2:23:31.421286	Training Loss1 2.6995 (2.7364)	Training Total_Loss 2.6995 (2.7364)	Training Prec@1 99.609 (99.288)	Training Prec@5 0.000 (0.000)	
2022-07-08 09:13:38,685: ============================================================
2022-07-08 09:14:54,061: time cost, forward:0.010816080486355115, backward:0.03420098103470539, data cost:0.8978189235955627 
2022-07-08 09:14:54,061: ============================================================
2022-07-08 09:14:54,061: Epoch 26/36 Batch 200/7662 eta: 17:36:19.191067	Training Loss1 2.7515 (2.7364)	Training Total_Loss 2.7515 (2.7364)	Training Prec@1 99.805 (99.250)	Training Prec@5 0.000 (0.000)	
2022-07-08 09:14:54,061: ============================================================
2022-07-08 09:16:11,106: time cost, forward:0.010833451580443111, backward:0.03425090129558857, data cost:0.8398722230790052 
2022-07-08 09:16:11,106: ============================================================
2022-07-08 09:16:11,106: Epoch 26/36 Batch 300/7662 eta: 17:58:24.702414	Training Loss1 2.7383 (2.7401)	Training Total_Loss 2.7383 (2.7401)	Training Prec@1 99.414 (99.248)	Training Prec@5 0.000 (0.000)	
2022-07-08 09:16:11,106: ============================================================
2022-07-08 09:17:26,118: time cost, forward:0.010781813384895037, backward:0.03431496225801626, data cost:0.8059043991834598 
2022-07-08 09:17:26,118: ============================================================
2022-07-08 09:17:26,119: Epoch 26/36 Batch 400/7662 eta: 17:28:42.542622	Training Loss1 2.9163 (2.7445)	Training Total_Loss 2.9163 (2.7445)	Training Prec@1 99.414 (99.248)	Training Prec@5 0.000 (0.000)	
2022-07-08 09:17:26,119: ============================================================
2022-07-08 09:18:41,823: time cost, forward:0.010770719849274966, backward:0.03422435443243665, data cost:0.7869361044170862 
2022-07-08 09:18:41,823: ============================================================
2022-07-08 09:18:41,823: Epoch 26/36 Batch 500/7662 eta: 17:37:07.613463	Training Loss1 2.5083 (2.7472)	Training Total_Loss 2.5083 (2.7472)	Training Prec@1 99.805 (99.243)	Training Prec@5 0.000 (0.000)	
2022-07-08 09:18:41,823: ============================================================
2022-07-08 09:19:58,740: time cost, forward:0.010763536112535377, backward:0.03428357232592142, data cost:0.7764231561619371 
2022-07-08 09:19:58,740: ============================================================
2022-07-08 09:19:58,740: Epoch 26/36 Batch 600/7662 eta: 17:52:46.461935	Training Loss1 2.8303 (2.7562)	Training Total_Loss 2.8303 (2.7562)	Training Prec@1 99.023 (99.236)	Training Prec@5 0.000 (0.000)	
2022-07-08 09:19:58,740: ============================================================
2022-07-08 09:21:13,309: time cost, forward:0.010757241979006875, backward:0.03436673454972296, data cost:0.7653935327379829 
2022-07-08 09:21:13,309: ============================================================
2022-07-08 09:21:13,309: Epoch 26/36 Batch 700/7662 eta: 17:18:47.002492	Training Loss1 2.8773 (2.7567)	Training Total_Loss 2.8773 (2.7567)	Training Prec@1 99.023 (99.230)	Training Prec@5 0.000 (0.000)	
2022-07-08 09:21:13,309: ============================================================
2022-07-08 09:22:26,245: time cost, forward:0.01074200786547607, backward:0.034430816564452515, data cost:0.7551053164151493 
2022-07-08 09:22:26,245: ============================================================
2022-07-08 09:22:26,245: Epoch 26/36 Batch 800/7662 eta: 16:54:49.384293	Training Loss1 2.7719 (2.7590)	Training Total_Loss 2.7719 (2.7590)	Training Prec@1 99.414 (99.220)	Training Prec@5 0.000 (0.000)	
2022-07-08 09:22:26,246: ============================================================
2022-07-08 09:23:41,422: time cost, forward:0.010887723610849349, backward:0.034517382355500115, data cost:0.7494662701752083 
2022-07-08 09:23:41,422: ============================================================
2022-07-08 09:23:41,422: Epoch 26/36 Batch 900/7662 eta: 17:24:44.618671	Training Loss1 2.9151 (2.7613)	Training Total_Loss 2.9151 (2.7613)	Training Prec@1 98.633 (99.212)	Training Prec@5 0.000 (0.000)	
2022-07-08 09:23:41,422: ============================================================
2022-07-08 09:24:55,690: time cost, forward:0.010946145644775024, backward:0.034593022263443865, data cost:0.7440218295420971 
2022-07-08 09:24:55,691: ============================================================
2022-07-08 09:24:55,691: Epoch 26/36 Batch 1000/7662 eta: 17:10:53.091123	Training Loss1 2.5870 (2.7644)	Training Total_Loss 2.5870 (2.7644)	Training Prec@1 100.000 (99.207)	Training Prec@5 0.000 (0.000)	
2022-07-08 09:24:55,691: ============================================================
2022-07-08 09:26:10,362: time cost, forward:0.010955148007893585, backward:0.03464225707431616, data cost:0.7400263355904215 
2022-07-08 09:26:10,362: ============================================================
2022-07-08 09:26:10,362: Epoch 26/36 Batch 1100/7662 eta: 17:15:14.125703	Training Loss1 2.8782 (2.7645)	Training Total_Loss 2.8782 (2.7645)	Training Prec@1 99.219 (99.206)	Training Prec@5 0.000 (0.000)	
2022-07-08 09:26:10,363: ============================================================
2022-07-08 09:27:24,312: time cost, forward:0.01105727346068725, backward:0.034766530274748304, data cost:0.7359047377477396 
2022-07-08 09:27:24,312: ============================================================
2022-07-08 09:27:24,313: Epoch 26/36 Batch 1200/7662 eta: 17:03:59.902508	Training Loss1 3.0205 (2.7662)	Training Total_Loss 3.0205 (2.7662)	Training Prec@1 99.609 (99.205)	Training Prec@5 0.000 (0.000)	
2022-07-08 09:27:24,313: ============================================================
2022-07-08 09:28:37,105: time cost, forward:0.01110686789667542, backward:0.0347212939376185, data cost:0.7316770353530168 
2022-07-08 09:28:37,105: ============================================================
2022-07-08 09:28:37,105: Epoch 26/36 Batch 1300/7662 eta: 16:46:45.508909	Training Loss1 2.9029 (2.7685)	Training Total_Loss 2.9029 (2.7685)	Training Prec@1 99.219 (99.204)	Training Prec@5 0.000 (0.000)	
2022-07-08 09:28:37,105: ============================================================
2022-07-08 09:29:50,695: time cost, forward:0.011121616097669077, backward:0.034728442369996865, data cost:0.7286649225778968 
2022-07-08 09:29:50,695: ============================================================
2022-07-08 09:29:50,695: Epoch 26/36 Batch 1400/7662 eta: 16:56:33.473357	Training Loss1 2.7027 (2.7703)	Training Total_Loss 2.7027 (2.7703)	Training Prec@1 99.023 (99.199)	Training Prec@5 0.000 (0.000)	
2022-07-08 09:29:50,695: ============================================================
2022-07-08 09:31:03,665: time cost, forward:0.01112728837810412, backward:0.034727396688276804, data cost:0.7256153736852502 
2022-07-08 09:31:03,665: ============================================================
2022-07-08 09:31:03,665: Epoch 26/36 Batch 1500/7662 eta: 16:46:46.987231	Training Loss1 2.9874 (2.7727)	Training Total_Loss 2.9874 (2.7727)	Training Prec@1 98.633 (99.197)	Training Prec@5 0.000 (0.000)	
2022-07-08 09:31:03,665: ============================================================
2022-07-08 09:32:16,456: time cost, forward:0.01116344375562638, backward:0.03472034166275225, data cost:0.7228267142144943 
2022-07-08 09:32:16,456: ============================================================
2022-07-08 09:32:16,456: Epoch 26/36 Batch 1600/7662 eta: 16:43:05.628282	Training Loss1 2.6352 (2.7748)	Training Total_Loss 2.6352 (2.7748)	Training Prec@1 99.219 (99.199)	Training Prec@5 0.000 (0.000)	
2022-07-08 09:32:16,456: ============================================================
2022-07-08 09:33:30,117: time cost, forward:0.011211265038573932, backward:0.03472111139527625, data cost:0.7208583743660643 
2022-07-08 09:33:30,117: ============================================================
2022-07-08 09:33:30,118: Epoch 26/36 Batch 1700/7662 eta: 16:53:51.764494	Training Loss1 2.7530 (2.7769)	Training Total_Loss 2.7530 (2.7769)	Training Prec@1 98.633 (99.198)	Training Prec@5 0.000 (0.000)	
2022-07-08 09:33:30,118: ============================================================
2022-07-08 09:34:43,280: time cost, forward:0.011233734117076422, backward:0.034733959938036595, data cost:0.7188223175634073 
2022-07-08 09:34:43,280: ============================================================
2022-07-08 09:34:43,280: Epoch 26/36 Batch 1800/7662 eta: 16:45:46.756162	Training Loss1 2.7757 (2.7790)	Training Total_Loss 2.7757 (2.7790)	Training Prec@1 98.633 (99.195)	Training Prec@5 0.000 (0.000)	
2022-07-08 09:34:43,280: ============================================================
2022-07-08 09:35:55,771: time cost, forward:0.011277742923216295, backward:0.03472371086313449, data cost:0.7166586700648367 
2022-07-08 09:35:55,771: ============================================================
2022-07-08 09:35:55,771: Epoch 26/36 Batch 1900/7662 eta: 16:35:20.496963	Training Loss1 2.6068 (2.7817)	Training Total_Loss 2.6068 (2.7817)	Training Prec@1 99.023 (99.187)	Training Prec@5 0.000 (0.000)	
2022-07-08 09:35:55,772: ============================================================
2022-07-08 09:37:08,296: time cost, forward:0.011289075948763872, backward:0.034683101114003044, data cost:0.7148100305283409 
2022-07-08 09:37:08,297: ============================================================
2022-07-08 09:37:08,297: Epoch 26/36 Batch 2000/7662 eta: 16:34:36.061086	Training Loss1 2.9593 (2.7848)	Training Total_Loss 2.9593 (2.7848)	Training Prec@1 100.000 (99.185)	Training Prec@5 0.000 (0.000)	
2022-07-08 09:37:08,297: ============================================================
2022-07-08 09:38:22,175: time cost, forward:0.011342219933831959, backward:0.034636829170855865, data cost:0.7137023976668112 
2022-07-08 09:38:22,175: ============================================================
2022-07-08 09:38:22,176: Epoch 26/36 Batch 2100/7662 eta: 16:51:55.697158	Training Loss1 2.6672 (2.7860)	Training Total_Loss 2.6672 (2.7860)	Training Prec@1 98.828 (99.184)	Training Prec@5 0.000 (0.000)	
2022-07-08 09:38:22,176: ============================================================
2022-07-08 09:39:35,117: time cost, forward:0.011371897480172317, backward:0.034574143937524206, data cost:0.7123346166103306 
2022-07-08 09:39:35,118: ============================================================
2022-07-08 09:39:35,118: Epoch 26/36 Batch 2200/7662 eta: 16:37:53.293148	Training Loss1 2.9749 (2.7871)	Training Total_Loss 2.9749 (2.7871)	Training Prec@1 99.219 (99.182)	Training Prec@5 0.000 (0.000)	
2022-07-08 09:39:35,118: ============================================================
2022-07-08 09:40:48,422: time cost, forward:0.011392614228562616, backward:0.03450841393456246, data cost:0.7112416210979314 
2022-07-08 09:40:48,422: ============================================================
2022-07-08 09:40:48,422: Epoch 26/36 Batch 2300/7662 eta: 16:41:36.976759	Training Loss1 2.8786 (2.7891)	Training Total_Loss 2.8786 (2.7891)	Training Prec@1 99.219 (99.181)	Training Prec@5 0.000 (0.000)	
2022-07-08 09:40:48,422: ============================================================
2022-07-08 09:42:01,520: time cost, forward:0.01142901964811744, backward:0.034428792180693016, data cost:0.7101963485663709 
2022-07-08 09:42:01,520: ============================================================
2022-07-08 09:42:01,521: Epoch 26/36 Batch 2400/7662 eta: 16:37:35.232662	Training Loss1 2.7077 (2.7911)	Training Total_Loss 2.7077 (2.7911)	Training Prec@1 99.609 (99.179)	Training Prec@5 0.000 (0.000)	
2022-07-08 09:42:01,521: ============================================================
2022-07-08 09:43:15,157: time cost, forward:0.011480287915947629, backward:0.0343549820173736, data cost:0.709403444738949 
2022-07-08 09:43:15,157: ============================================================
2022-07-08 09:43:15,158: Epoch 26/36 Batch 2500/7662 eta: 16:43:42.650146	Training Loss1 2.7453 (2.7931)	Training Total_Loss 2.7453 (2.7931)	Training Prec@1 99.023 (99.175)	Training Prec@5 0.000 (0.000)	
2022-07-08 09:43:15,158: ============================================================
2022-07-08 09:44:29,237: time cost, forward:0.011512771483887706, backward:0.0343121629166759, data cost:0.7088235881338674 
2022-07-08 09:44:29,238: ============================================================
2022-07-08 09:44:29,238: Epoch 26/36 Batch 2600/7662 eta: 16:48:31.090982	Training Loss1 2.8804 (2.7958)	Training Total_Loss 2.8804 (2.7958)	Training Prec@1 99.414 (99.171)	Training Prec@5 0.000 (0.000)	
2022-07-08 09:44:29,238: ============================================================
2022-07-08 09:45:43,590: time cost, forward:0.011514273251635624, backward:0.03429766229542594, data cost:0.7084160302470639 
2022-07-08 09:45:43,590: ============================================================
2022-07-08 09:45:43,591: Epoch 26/36 Batch 2700/7662 eta: 16:50:58.998488	Training Loss1 2.8189 (2.7974)	Training Total_Loss 2.8189 (2.7974)	Training Prec@1 98.438 (99.168)	Training Prec@5 0.000 (0.000)	
2022-07-08 09:45:43,591: ============================================================
2022-07-08 09:46:58,225: time cost, forward:0.011571082697463231, backward:0.034239989427550854, data cost:0.7081196935911952 
2022-07-08 09:46:58,225: ============================================================
2022-07-08 09:46:58,225: Epoch 26/36 Batch 2800/7662 eta: 16:53:34.589736	Training Loss1 2.8728 (2.7998)	Training Total_Loss 2.8728 (2.7998)	Training Prec@1 98.828 (99.166)	Training Prec@5 0.000 (0.000)	
2022-07-08 09:46:58,225: ============================================================
2022-07-08 09:48:11,834: time cost, forward:0.011622699962562016, backward:0.034210089281864434, data cost:0.707453929378724 
2022-07-08 09:48:11,834: ============================================================
2022-07-08 09:48:11,834: Epoch 26/36 Batch 2900/7662 eta: 16:38:25.352923	Training Loss1 3.0081 (2.8019)	Training Total_Loss 3.0081 (2.8019)	Training Prec@1 99.219 (99.163)	Training Prec@5 0.000 (0.000)	
2022-07-08 09:48:11,835: ============================================================
2022-07-08 09:49:24,967: time cost, forward:0.011640584957762613, backward:0.034210704572600656, data cost:0.7066813123428889 
2022-07-08 09:49:24,968: ============================================================
2022-07-08 09:49:24,968: Epoch 26/36 Batch 3000/7662 eta: 16:30:44.926146	Training Loss1 2.6978 (2.8046)	Training Total_Loss 2.6978 (2.8046)	Training Prec@1 99.414 (99.158)	Training Prec@5 0.000 (0.000)	
2022-07-08 09:49:24,968: ============================================================
2022-07-08 09:50:38,204: time cost, forward:0.011653262517189894, backward:0.034210416723659404, data cost:0.7059893448839806 
2022-07-08 09:50:38,204: ============================================================
2022-07-08 09:50:38,204: Epoch 26/36 Batch 3100/7662 eta: 16:30:55.664076	Training Loss1 2.7484 (2.8068)	Training Total_Loss 2.7484 (2.8068)	Training Prec@1 99.414 (99.157)	Training Prec@5 0.000 (0.000)	
2022-07-08 09:50:38,204: ============================================================
2022-07-08 09:51:52,482: time cost, forward:0.011687483851631644, backward:0.034188032150268555, data cost:0.7056732144196282 
2022-07-08 09:51:52,482: ============================================================
2022-07-08 09:51:52,482: Epoch 26/36 Batch 3200/7662 eta: 16:43:46.815562	Training Loss1 2.8946 (2.8079)	Training Total_Loss 2.8946 (2.8079)	Training Prec@1 98.633 (99.155)	Training Prec@5 0.000 (0.000)	
2022-07-08 09:51:52,482: ============================================================
2022-07-08 09:53:06,544: time cost, forward:0.01171995062075011, backward:0.034187124584182965, data cost:0.7052945694658893 
2022-07-08 09:53:06,544: ============================================================
2022-07-08 09:53:06,545: Epoch 26/36 Batch 3300/7662 eta: 16:39:37.870451	Training Loss1 2.9068 (2.8109)	Training Total_Loss 2.9068 (2.8109)	Training Prec@1 99.023 (99.151)	Training Prec@5 0.000 (0.000)	
2022-07-08 09:53:06,545: ============================================================
2022-07-08 09:54:20,660: time cost, forward:0.011749668730185571, backward:0.03417468070983887, data cost:0.7049031255525082 
2022-07-08 09:54:20,661: ============================================================
2022-07-08 09:54:20,661: Epoch 26/36 Batch 3400/7662 eta: 16:39:07.406986	Training Loss1 3.0243 (2.8137)	Training Total_Loss 3.0243 (2.8137)	Training Prec@1 98.438 (99.148)	Training Prec@5 0.000 (0.000)	
2022-07-08 09:54:20,661: ============================================================
2022-07-08 09:55:34,464: time cost, forward:0.011780820801858393, backward:0.0341647944814241, data cost:0.7045633373140573 
2022-07-08 09:55:34,464: ============================================================
2022-07-08 09:55:34,464: Epoch 26/36 Batch 3500/7662 eta: 16:33:40.683473	Training Loss1 2.9734 (2.8158)	Training Total_Loss 2.9734 (2.8158)	Training Prec@1 99.219 (99.145)	Training Prec@5 0.000 (0.000)	
2022-07-08 09:55:34,464: ============================================================
2022-07-08 09:56:48,007: time cost, forward:0.01176814809048232, backward:0.034155832392932906, data cost:0.7041403003850557 
2022-07-08 09:56:48,007: ============================================================
2022-07-08 09:56:48,007: Epoch 26/36 Batch 3600/7662 eta: 16:28:56.582296	Training Loss1 2.7775 (2.8176)	Training Total_Loss 2.7775 (2.8176)	Training Prec@1 99.219 (99.142)	Training Prec@5 0.000 (0.000)	
2022-07-08 09:56:48,007: ============================================================
2022-07-08 09:58:01,312: time cost, forward:0.011760691753365794, backward:0.03413577020474465, data cost:0.7036749059105281 
2022-07-08 09:58:01,313: ============================================================
2022-07-08 09:58:01,313: Epoch 26/36 Batch 3700/7662 eta: 16:24:31.791263	Training Loss1 3.1033 (2.8192)	Training Total_Loss 3.1033 (2.8192)	Training Prec@1 99.219 (99.139)	Training Prec@5 0.000 (0.000)	
2022-07-08 09:58:01,313: ============================================================
2022-07-08 09:59:15,730: time cost, forward:0.011759452111911196, backward:0.03414931633686448, data cost:0.7035271235910583 
2022-07-08 09:59:15,731: ============================================================
2022-07-08 09:59:15,731: Epoch 26/36 Batch 3800/7662 eta: 16:38:13.947918	Training Loss1 2.9286 (2.8212)	Training Total_Loss 2.9286 (2.8212)	Training Prec@1 99.219 (99.137)	Training Prec@5 0.000 (0.000)	
2022-07-08 09:59:15,731: ============================================================
2022-07-08 10:00:29,625: time cost, forward:0.01176554901717901, backward:0.0341473575982414, data cost:0.7032362683426573 
2022-07-08 10:00:29,626: ============================================================
2022-07-08 10:00:29,626: Epoch 26/36 Batch 3900/7662 eta: 16:29:59.108484	Training Loss1 2.8554 (2.8230)	Training Total_Loss 2.8554 (2.8230)	Training Prec@1 99.023 (99.133)	Training Prec@5 0.000 (0.000)	
2022-07-08 10:00:29,626: ============================================================
2022-07-08 10:01:41,630: time cost, forward:0.011742336268900751, backward:0.03414043255763281, data cost:0.7025112184055688 
2022-07-08 10:01:41,630: ============================================================
2022-07-08 10:01:41,630: Epoch 26/36 Batch 4000/7662 eta: 16:03:27.219728	Training Loss1 2.9745 (2.8248)	Training Total_Loss 2.9745 (2.8248)	Training Prec@1 98.828 (99.131)	Training Prec@5 0.000 (0.000)	
2022-07-08 10:01:41,630: ============================================================
2022-07-08 10:02:54,973: time cost, forward:0.011733325698603128, backward:0.03415660027557246, data cost:0.7021272883353568 
2022-07-08 10:02:54,973: ============================================================
2022-07-08 10:02:54,973: Epoch 26/36 Batch 4100/7662 eta: 16:20:08.559140	Training Loss1 2.8207 (2.8268)	Training Total_Loss 2.8207 (2.8268)	Training Prec@1 99.609 (99.127)	Training Prec@5 0.000 (0.000)	
2022-07-08 10:02:54,973: ============================================================
2022-07-08 10:04:09,308: time cost, forward:0.011731579009054046, backward:0.034145651956091726, data cost:0.7020243118705849 
2022-07-08 10:04:09,308: ============================================================
2022-07-08 10:04:09,308: Epoch 26/36 Batch 4200/7662 eta: 16:32:09.558318	Training Loss1 3.0184 (2.8281)	Training Total_Loss 3.0184 (2.8281)	Training Prec@1 98.438 (99.124)	Training Prec@5 0.000 (0.000)	
2022-07-08 10:04:09,308: ============================================================
2022-07-08 10:05:22,804: time cost, forward:0.01172110407151131, backward:0.03414218512821486, data cost:0.7017131303737096 
2022-07-08 10:05:22,804: ============================================================
2022-07-08 10:05:22,804: Epoch 26/36 Batch 4300/7662 eta: 16:19:44.271206	Training Loss1 2.8618 (2.8302)	Training Total_Loss 2.8618 (2.8302)	Training Prec@1 99.219 (99.123)	Training Prec@5 0.000 (0.000)	
2022-07-08 10:05:22,804: ============================================================
2022-07-08 10:06:35,214: time cost, forward:0.011707909894710402, backward:0.03413464400301632, data cost:0.7011915946391584 
2022-07-08 10:06:35,214: ============================================================
2022-07-08 10:06:35,215: Epoch 26/36 Batch 4400/7662 eta: 16:04:03.807170	Training Loss1 2.8985 (2.8315)	Training Total_Loss 2.8985 (2.8315)	Training Prec@1 99.609 (99.121)	Training Prec@5 0.000 (0.000)	
2022-07-08 10:06:35,215: ============================================================
2022-07-08 10:07:48,585: time cost, forward:0.011713360330480342, backward:0.034113712484610294, data cost:0.7009074337139584 
2022-07-08 10:07:48,586: ============================================================
2022-07-08 10:07:48,586: Epoch 26/36 Batch 4500/7662 eta: 16:15:37.730107	Training Loss1 2.7623 (2.8332)	Training Total_Loss 2.7623 (2.8332)	Training Prec@1 99.023 (99.118)	Training Prec@5 0.000 (0.000)	
2022-07-08 10:07:48,586: ============================================================
2022-07-08 10:09:03,127: time cost, forward:0.011722341468215481, backward:0.03407342171093567, data cost:0.7008499632609567 
2022-07-08 10:09:03,127: ============================================================
2022-07-08 10:09:03,127: Epoch 26/36 Batch 4600/7662 eta: 16:29:56.786111	Training Loss1 3.0052 (2.8350)	Training Total_Loss 3.0052 (2.8350)	Training Prec@1 99.023 (99.117)	Training Prec@5 0.000 (0.000)	
2022-07-08 10:09:03,127: ============================================================
2022-07-08 10:10:18,208: time cost, forward:0.01172131466139984, backward:0.03406279009437277, data cost:0.7009805490372408 
2022-07-08 10:10:18,208: ============================================================
2022-07-08 10:10:18,209: Epoch 26/36 Batch 4700/7662 eta: 16:35:52.034101	Training Loss1 2.8076 (2.8368)	Training Total_Loss 2.8076 (2.8368)	Training Prec@1 99.023 (99.116)	Training Prec@5 0.000 (0.000)	
2022-07-08 10:10:18,209: ============================================================
2022-07-08 10:11:31,470: time cost, forward:0.011714240565203607, backward:0.0340422070207733, data cost:0.7007010120181993 
2022-07-08 10:11:31,470: ============================================================
2022-07-08 10:11:31,471: Epoch 26/36 Batch 4800/7662 eta: 16:10:30.833063	Training Loss1 2.9606 (2.8385)	Training Total_Loss 2.9606 (2.8385)	Training Prec@1 98.047 (99.114)	Training Prec@5 0.000 (0.000)	
2022-07-08 10:11:31,471: ============================================================
2022-07-08 10:12:44,980: time cost, forward:0.01171305038948939, backward:0.0340412576530972, data cost:0.7004504061689375 
2022-07-08 10:12:44,980: ============================================================
2022-07-08 10:12:44,980: Epoch 26/36 Batch 4900/7662 eta: 16:12:34.154854	Training Loss1 2.9878 (2.8404)	Training Total_Loss 2.9878 (2.8404)	Training Prec@1 98.438 (99.110)	Training Prec@5 0.000 (0.000)	
2022-07-08 10:12:44,980: ============================================================
2022-07-08 10:13:58,171: time cost, forward:0.011709766069348513, backward:0.03402041258585885, data cost:0.7001828425262995 
2022-07-08 10:13:58,172: ============================================================
2022-07-08 10:13:58,172: Epoch 26/36 Batch 5000/7662 eta: 16:07:08.445069	Training Loss1 2.9977 (2.8422)	Training Total_Loss 2.9977 (2.8422)	Training Prec@1 98.633 (99.109)	Training Prec@5 0.000 (0.000)	
2022-07-08 10:13:58,172: ============================================================
2022-07-08 10:15:12,782: time cost, forward:0.011719055843484193, backward:0.03399828299047152, data cost:0.70018278427932 
2022-07-08 10:15:12,783: ============================================================
2022-07-08 10:15:12,783: Epoch 26/36 Batch 5100/7662 eta: 16:24:39.377698	Training Loss1 2.9651 (2.8438)	Training Total_Loss 2.9651 (2.8438)	Training Prec@1 99.219 (99.107)	Training Prec@5 0.000 (0.000)	
2022-07-08 10:15:12,783: ============================================================
2022-07-08 10:16:26,488: time cost, forward:0.01170586393209209, backward:0.03400539714433891, data cost:0.7000160220953839 
2022-07-08 10:16:26,488: ============================================================
2022-07-08 10:16:26,488: Epoch 26/36 Batch 5200/7662 eta: 16:11:28.103029	Training Loss1 2.7455 (2.8452)	Training Total_Loss 2.7455 (2.8452)	Training Prec@1 99.023 (99.106)	Training Prec@5 0.000 (0.000)	
2022-07-08 10:16:26,488: ============================================================
2022-07-08 10:17:40,251: time cost, forward:0.01170975861852631, backward:0.03398663940508875, data cost:0.6998679336454986 
2022-07-08 10:17:40,251: ============================================================
2022-07-08 10:17:40,252: Epoch 26/36 Batch 5300/7662 eta: 16:11:00.740431	Training Loss1 3.0465 (2.8465)	Training Total_Loss 3.0465 (2.8465)	Training Prec@1 99.219 (99.105)	Training Prec@5 0.000 (0.000)	
2022-07-08 10:17:40,252: ============================================================
2022-07-08 10:18:54,719: time cost, forward:0.011706957620125078, backward:0.033985459599192, data cost:0.6998432945997588 
2022-07-08 10:18:54,719: ============================================================
2022-07-08 10:18:54,719: Epoch 26/36 Batch 5400/7662 eta: 16:19:02.230351	Training Loss1 2.9966 (2.8480)	Training Total_Loss 2.9966 (2.8480)	Training Prec@1 99.219 (99.103)	Training Prec@5 0.000 (0.000)	
2022-07-08 10:18:54,719: ============================================================
2022-07-08 10:20:08,699: time cost, forward:0.011715609889872443, backward:0.03398212508128586, data cost:0.6997162354905121 
2022-07-08 10:20:08,699: ============================================================
2022-07-08 10:20:08,699: Epoch 26/36 Batch 5500/7662 eta: 16:11:23.568559	Training Loss1 2.8900 (2.8493)	Training Total_Loss 2.8900 (2.8493)	Training Prec@1 98.828 (99.101)	Training Prec@5 0.000 (0.000)	
2022-07-08 10:20:08,699: ============================================================
2022-07-08 10:21:22,810: time cost, forward:0.011719312342517524, backward:0.03399768648966867, data cost:0.6996106623240637 
2022-07-08 10:21:22,810: ============================================================
2022-07-08 10:21:22,810: Epoch 26/36 Batch 5600/7662 eta: 16:11:52.852351	Training Loss1 3.0516 (2.8509)	Training Total_Loss 3.0516 (2.8509)	Training Prec@1 99.023 (99.100)	Training Prec@5 0.000 (0.000)	
2022-07-08 10:21:22,810: ============================================================
2022-07-08 10:22:36,123: time cost, forward:0.01172109352201511, backward:0.034006953971556224, data cost:0.6993751103762138 
2022-07-08 10:22:36,123: ============================================================
2022-07-08 10:22:36,123: Epoch 26/36 Batch 5700/7662 eta: 16:00:11.603099	Training Loss1 2.9894 (2.8526)	Training Total_Loss 2.9894 (2.8526)	Training Prec@1 99.609 (99.098)	Training Prec@5 0.000 (0.000)	
2022-07-08 10:22:36,123: ============================================================
2022-07-08 10:23:49,787: time cost, forward:0.011721620314654492, backward:0.03401687889802988, data cost:0.6991738826576072 
2022-07-08 10:23:49,787: ============================================================
2022-07-08 10:23:49,788: Epoch 26/36 Batch 5800/7662 eta: 16:03:33.929713	Training Loss1 2.7233 (2.8540)	Training Total_Loss 2.7233 (2.8540)	Training Prec@1 99.219 (99.096)	Training Prec@5 0.000 (0.000)	
2022-07-08 10:23:49,788: ============================================================
2022-07-08 10:25:04,784: time cost, forward:0.011714463841007773, backward:0.03400409227711687, data cost:0.6993030016453393 
2022-07-08 10:25:04,784: ============================================================
2022-07-08 10:25:04,784: Epoch 26/36 Batch 5900/7662 eta: 16:19:44.673304	Training Loss1 3.0796 (2.8557)	Training Total_Loss 3.0796 (2.8557)	Training Prec@1 98.242 (99.093)	Training Prec@5 0.000 (0.000)	
2022-07-08 10:25:04,784: ============================================================
2022-07-08 10:26:18,648: time cost, forward:0.011704976369110937, backward:0.034026374219159, data cost:0.6991728120772992 
2022-07-08 10:26:18,648: ============================================================
2022-07-08 10:26:18,649: Epoch 26/36 Batch 6000/7662 eta: 16:03:43.259596	Training Loss1 2.8931 (2.8572)	Training Total_Loss 2.8931 (2.8572)	Training Prec@1 98.828 (99.091)	Training Prec@5 0.000 (0.000)	
2022-07-08 10:26:18,649: ============================================================
2022-07-08 10:27:32,110: time cost, forward:0.0116939204191454, backward:0.034043826007671016, data cost:0.6989920950459738 
2022-07-08 10:27:32,111: ============================================================
2022-07-08 10:27:32,111: Epoch 26/36 Batch 6100/7662 eta: 15:57:14.920639	Training Loss1 2.9687 (2.8583)	Training Total_Loss 2.9687 (2.8583)	Training Prec@1 98.828 (99.089)	Training Prec@5 0.000 (0.000)	
2022-07-08 10:27:32,111: ============================================================
2022-07-08 10:28:45,418: time cost, forward:0.011681805427737111, backward:0.03404125864995374, data cost:0.6988023422402438 
2022-07-08 10:28:45,418: ============================================================
2022-07-08 10:28:45,418: Epoch 26/36 Batch 6200/7662 eta: 15:54:00.736092	Training Loss1 2.8308 (2.8598)	Training Total_Loss 2.8308 (2.8598)	Training Prec@1 99.219 (99.087)	Training Prec@5 0.000 (0.000)	
2022-07-08 10:28:45,418: ============================================================
2022-07-08 10:30:00,114: time cost, forward:0.01167590857725481, backward:0.03403059617548372, data cost:0.6988524121128391 
2022-07-08 10:30:00,114: ============================================================
2022-07-08 10:30:00,114: Epoch 26/36 Batch 6300/7662 eta: 16:10:49.938194	Training Loss1 2.8720 (2.8614)	Training Total_Loss 2.8720 (2.8614)	Training Prec@1 99.219 (99.085)	Training Prec@5 0.000 (0.000)	
2022-07-08 10:30:00,114: ============================================================
2022-07-08 10:31:14,526: time cost, forward:0.011677008454623418, backward:0.034020136549875575, data cost:0.6988452715247027 
2022-07-08 10:31:14,526: ============================================================
2022-07-08 10:31:14,526: Epoch 26/36 Batch 6400/7662 eta: 16:05:54.457048	Training Loss1 2.8592 (2.8629)	Training Total_Loss 2.8592 (2.8629)	Training Prec@1 99.219 (99.083)	Training Prec@5 0.000 (0.000)	
2022-07-08 10:31:14,526: ============================================================
2022-07-08 10:32:28,901: time cost, forward:0.011670884507897267, backward:0.034022832544129855, data cost:0.6988259259141909 
2022-07-08 10:32:28,901: ============================================================
2022-07-08 10:32:28,902: Epoch 26/36 Batch 6500/7662 eta: 16:04:11.376820	Training Loss1 2.7457 (2.8647)	Training Total_Loss 2.7457 (2.8647)	Training Prec@1 99.609 (99.080)	Training Prec@5 0.000 (0.000)	
2022-07-08 10:32:28,902: ============================================================
2022-07-08 10:33:43,006: time cost, forward:0.011671290720641785, backward:0.0340240977536297, data cost:0.6987546015587841 
2022-07-08 10:33:43,006: ============================================================
2022-07-08 10:33:43,007: Epoch 26/36 Batch 6600/7662 eta: 15:59:26.877335	Training Loss1 2.9842 (2.8660)	Training Total_Loss 2.9842 (2.8660)	Training Prec@1 99.414 (99.078)	Training Prec@5 0.000 (0.000)	
2022-07-08 10:33:43,007: ============================================================
2022-07-08 10:34:57,655: time cost, forward:0.011670208205072039, backward:0.03401725070479023, data cost:0.6987889226932529 
2022-07-08 10:34:57,656: ============================================================
2022-07-08 10:34:57,656: Epoch 26/36 Batch 6700/7662 eta: 16:05:15.208669	Training Loss1 3.0866 (2.8674)	Training Total_Loss 3.0866 (2.8674)	Training Prec@1 98.828 (99.076)	Training Prec@5 0.000 (0.000)	
2022-07-08 10:34:57,656: ============================================================
2022-07-08 10:36:13,116: time cost, forward:0.011664708619048305, backward:0.03402075600599538, data cost:0.698934611055251 
2022-07-08 10:36:13,116: ============================================================
2022-07-08 10:36:13,116: Epoch 26/36 Batch 6800/7662 eta: 16:14:29.034832	Training Loss1 2.5509 (2.8687)	Training Total_Loss 2.5509 (2.8687)	Training Prec@1 99.219 (99.074)	Training Prec@5 0.000 (0.000)	
2022-07-08 10:36:13,116: ============================================================
2022-07-08 10:37:28,782: time cost, forward:0.01165971104209536, backward:0.03401790395787288, data cost:0.6991084163854875 
2022-07-08 10:37:28,782: ============================================================
2022-07-08 10:37:28,783: Epoch 26/36 Batch 6900/7662 eta: 16:15:52.815891	Training Loss1 2.8032 (2.8700)	Training Total_Loss 2.8032 (2.8700)	Training Prec@1 99.414 (99.071)	Training Prec@5 0.000 (0.000)	
2022-07-08 10:37:28,783: ============================================================
2022-07-08 10:38:42,700: time cost, forward:0.011653499001008236, backward:0.0340270121313194, data cost:0.6990164141090176 
2022-07-08 10:38:42,701: ============================================================
2022-07-08 10:38:42,701: Epoch 26/36 Batch 7000/7662 eta: 15:52:06.278064	Training Loss1 3.1016 (2.8712)	Training Total_Loss 3.1016 (2.8712)	Training Prec@1 98.828 (99.070)	Training Prec@5 0.000 (0.000)	
2022-07-08 10:38:42,701: ============================================================
2022-07-08 10:39:57,406: time cost, forward:0.011650869553820282, backward:0.03402926119503328, data cost:0.6990425610881504 
2022-07-08 10:39:57,406: ============================================================
2022-07-08 10:39:57,406: Epoch 26/36 Batch 7100/7662 eta: 16:00:59.790666	Training Loss1 2.7730 (2.8722)	Training Total_Loss 2.7730 (2.8722)	Training Prec@1 98.828 (99.068)	Training Prec@5 0.000 (0.000)	
2022-07-08 10:39:57,406: ============================================================
2022-07-08 10:41:10,721: time cost, forward:0.0116499527111072, backward:0.03403329647221587, data cost:0.6988685447021498 
2022-07-08 10:41:10,721: ============================================================
2022-07-08 10:41:10,722: Epoch 26/36 Batch 7200/7662 eta: 15:41:53.650516	Training Loss1 3.0076 (2.8735)	Training Total_Loss 3.0076 (2.8735)	Training Prec@1 99.414 (99.066)	Training Prec@5 0.000 (0.000)	
2022-07-08 10:41:10,722: ============================================================
2022-07-08 10:42:25,787: time cost, forward:0.011650353527212816, backward:0.03403917595627765, data cost:0.6989392134437399 
2022-07-08 10:42:25,787: ============================================================
2022-07-08 10:42:25,787: Epoch 26/36 Batch 7300/7662 eta: 16:03:08.038579	Training Loss1 2.8177 (2.8751)	Training Total_Loss 2.8177 (2.8751)	Training Prec@1 98.633 (99.063)	Training Prec@5 0.000 (0.000)	
2022-07-08 10:42:25,788: ============================================================
2022-07-08 10:43:40,047: time cost, forward:0.011646268496337429, backward:0.0340427779751801, data cost:0.698904224401681 
2022-07-08 10:43:40,047: ============================================================
2022-07-08 10:43:40,048: Epoch 26/36 Batch 7400/7662 eta: 15:51:33.389114	Training Loss1 3.0481 (2.8765)	Training Total_Loss 3.0481 (2.8765)	Training Prec@1 98.633 (99.061)	Training Prec@5 0.000 (0.000)	
2022-07-08 10:43:40,048: ============================================================
2022-07-08 10:44:56,014: time cost, forward:0.011640862315984579, backward:0.034059216521838326, data cost:0.6990863810477058 
2022-07-08 10:44:56,015: ============================================================
2022-07-08 10:44:56,015: Epoch 26/36 Batch 7500/7662 eta: 16:12:09.943720	Training Loss1 2.8543 (2.8781)	Training Total_Loss 2.8543 (2.8781)	Training Prec@1 99.609 (99.058)	Training Prec@5 0.000 (0.000)	
2022-07-08 10:44:56,015: ============================================================
2022-07-08 10:46:09,639: time cost, forward:0.01162953608317475, backward:0.03406833585806153, data cost:0.6989694923644851 
2022-07-08 10:46:09,639: ============================================================
2022-07-08 10:46:09,639: Epoch 26/36 Batch 7600/7662 eta: 15:40:57.483956	Training Loss1 2.9353 (2.8791)	Training Total_Loss 2.9353 (2.8791)	Training Prec@1 98.438 (99.057)	Training Prec@5 0.000 (0.000)	
2022-07-08 10:46:09,639: ============================================================
2022-07-08 10:46:57,242: Epoch 26/36 Batch 7663/7662 eta: 15:40:11.100514	Training Loss1 2.9722 (2.8799)	Training Total_Loss 2.9722 (2.8799)	Training Prec@1 99.219 (99.056)	Training Prec@5 0.000 (0.000)	
2022-07-08 10:46:57,242: ============================================================
2022-07-08 10:46:57,405: Save Checkpoint...
2022-07-08 10:46:57,425: ============================================================
2022-07-08 10:47:00,182: Save done!
2022-07-08 10:47:00,182: ============================================================
2022-07-08 10:48:49,272: time cost, forward:0.010887947949496183, backward:0.03334234940885293, data cost:1.051742886051987 
2022-07-08 10:48:49,273: ============================================================
2022-07-08 10:48:49,273: Epoch 27/36 Batch 100/7662 eta: 23:10:52.925383	Training Loss1 2.6002 (2.6989)	Training Total_Loss 2.6002 (2.6989)	Training Prec@1 99.219 (99.264)	Training Prec@5 0.000 (0.000)	
2022-07-08 10:48:49,273: ============================================================
2022-07-08 10:50:03,689: time cost, forward:0.010806052529033106, backward:0.03392763353472379, data cost:0.8742078692469765 
2022-07-08 10:50:03,690: ============================================================
2022-07-08 10:50:03,690: Epoch 27/36 Batch 200/7662 eta: 15:47:49.973830	Training Loss1 2.5746 (2.7168)	Training Total_Loss 2.5746 (2.7168)	Training Prec@1 99.414 (99.255)	Training Prec@5 0.000 (0.000)	
2022-07-08 10:50:03,690: ============================================================
2022-07-08 10:51:16,487: time cost, forward:0.011105363584282405, backward:0.034093926981540026, data cost:0.8096476286948724 
2022-07-08 10:51:16,487: ============================================================
2022-07-08 10:51:16,487: Epoch 27/36 Batch 300/7662 eta: 15:25:59.759879	Training Loss1 2.7908 (2.7223)	Training Total_Loss 2.7908 (2.7223)	Training Prec@1 98.438 (99.270)	Training Prec@5 0.000 (0.000)	
2022-07-08 10:51:16,487: ============================================================
2022-07-08 10:52:29,263: time cost, forward:0.01115814247226954, backward:0.03397788260514874, data cost:0.7777216123757804 
2022-07-08 10:52:29,263: ============================================================
2022-07-08 10:52:29,263: Epoch 27/36 Batch 400/7662 eta: 15:24:30.653311	Training Loss1 2.6463 (2.7259)	Training Total_Loss 2.6463 (2.7259)	Training Prec@1 99.609 (99.254)	Training Prec@5 0.000 (0.000)	
2022-07-08 10:52:29,264: ============================================================
2022-07-08 10:53:42,237: time cost, forward:0.01119630417986241, backward:0.03389711179331931, data cost:0.7589903154927409 
2022-07-08 10:53:42,237: ============================================================
2022-07-08 10:53:42,238: Epoch 27/36 Batch 500/7662 eta: 15:25:48.622188	Training Loss1 2.6742 (2.7336)	Training Total_Loss 2.6742 (2.7336)	Training Prec@1 99.609 (99.253)	Training Prec@5 0.000 (0.000)	
2022-07-08 10:53:42,238: ============================================================
2022-07-08 10:54:56,765: time cost, forward:0.011233862333982337, backward:0.033927207797118934, data cost:0.7490122565044982 
2022-07-08 10:54:56,765: ============================================================
2022-07-08 10:54:56,765: Epoch 27/36 Batch 600/7662 eta: 15:44:16.705677	Training Loss1 2.7452 (2.7314)	Training Total_Loss 2.7452 (2.7314)	Training Prec@1 99.219 (99.262)	Training Prec@5 0.000 (0.000)	
2022-07-08 10:54:56,765: ============================================================
2022-07-08 10:56:08,793: time cost, forward:0.011387222655682434, backward:0.03400749471225111, data cost:0.7381260575825224 
2022-07-08 10:56:08,793: ============================================================
2022-07-08 10:56:08,793: Epoch 27/36 Batch 700/7662 eta: 15:11:24.464491	Training Loss1 2.6939 (2.7343)	Training Total_Loss 2.6939 (2.7343)	Training Prec@1 99.609 (99.254)	Training Prec@5 0.000 (0.000)	
2022-07-08 10:56:08,794: ============================================================
2022-07-08 10:57:21,539: time cost, forward:0.011567217238405918, backward:0.03401213981332409, data cost:0.7308427046177832 
2022-07-08 10:57:21,539: ============================================================
2022-07-08 10:57:21,539: Epoch 27/36 Batch 800/7662 eta: 15:19:16.662990	Training Loss1 2.8203 (2.7379)	Training Total_Loss 2.8203 (2.7379)	Training Prec@1 99.414 (99.246)	Training Prec@5 0.000 (0.000)	
2022-07-08 10:57:21,539: ============================================================
2022-07-08 10:58:35,780: time cost, forward:0.0115481664129306, backward:0.03403145717964554, data cost:0.7270009586622771 
2022-07-08 10:58:35,780: ============================================================
2022-07-08 10:58:35,780: Epoch 27/36 Batch 900/7662 eta: 15:36:56.140576	Training Loss1 2.6465 (2.7397)	Training Total_Loss 2.6465 (2.7397)	Training Prec@1 99.609 (99.239)	Training Prec@5 0.000 (0.000)	
2022-07-08 10:58:35,780: ============================================================
2022-07-08 10:59:48,504: time cost, forward:0.011490465284467817, backward:0.03402188685801891, data cost:0.7224748979459654 
2022-07-08 10:59:48,505: ============================================================
2022-07-08 10:59:48,505: Epoch 27/36 Batch 1000/7662 eta: 15:16:34.802988	Training Loss1 2.6296 (2.7416)	Training Total_Loss 2.6296 (2.7416)	Training Prec@1 99.609 (99.236)	Training Prec@5 0.000 (0.000)	
2022-07-08 10:59:48,505: ============================================================
2022-07-08 11:01:02,165: time cost, forward:0.011492770839757112, backward:0.03406335376847105, data cost:0.7195098907758801 
2022-07-08 11:01:02,166: ============================================================
2022-07-08 11:01:02,166: Epoch 27/36 Batch 1100/7662 eta: 15:27:09.720621	Training Loss1 2.6758 (2.7422)	Training Total_Loss 2.6758 (2.7422)	Training Prec@1 99.023 (99.238)	Training Prec@5 0.000 (0.000)	
2022-07-08 11:01:02,166: ============================================================
2022-07-08 11:02:15,411: time cost, forward:0.011541341323470752, backward:0.03405932827329914, data cost:0.716701122002367 
2022-07-08 11:02:15,411: ============================================================
2022-07-08 11:02:15,412: Epoch 27/36 Batch 1200/7662 eta: 15:20:42.524765	Training Loss1 2.7189 (2.7467)	Training Total_Loss 2.7189 (2.7467)	Training Prec@1 99.609 (99.243)	Training Prec@5 0.000 (0.000)	
2022-07-08 11:02:15,412: ============================================================
2022-07-08 11:03:27,749: time cost, forward:0.011598305669172256, backward:0.034052759064813136, data cost:0.7136035110511809 
2022-07-08 11:03:27,749: ============================================================
2022-07-08 11:03:27,749: Epoch 27/36 Batch 1300/7662 eta: 15:08:05.347303	Training Loss1 2.4452 (2.7500)	Training Total_Loss 2.4452 (2.7500)	Training Prec@1 100.000 (99.238)	Training Prec@5 0.000 (0.000)	
2022-07-08 11:03:27,749: ============================================================
2022-07-08 11:04:40,839: time cost, forward:0.011640994526642915, backward:0.03405896794208039, data cost:0.7114724983395296 
2022-07-08 11:04:40,839: ============================================================
2022-07-08 11:04:40,840: Epoch 27/36 Batch 1400/7662 eta: 15:16:19.444906	Training Loss1 2.9217 (2.7523)	Training Total_Loss 2.9217 (2.7523)	Training Prec@1 99.414 (99.235)	Training Prec@5 0.000 (0.000)	
2022-07-08 11:04:40,840: ============================================================
2022-07-08 11:05:54,420: time cost, forward:0.011692445861887661, backward:0.03407578805512472, data cost:0.7099468854365943 
2022-07-08 11:05:54,421: ============================================================
2022-07-08 11:05:54,421: Epoch 27/36 Batch 1500/7662 eta: 15:21:14.857047	Training Loss1 2.8011 (2.7554)	Training Total_Loss 2.8011 (2.7554)	Training Prec@1 99.023 (99.231)	Training Prec@5 0.000 (0.000)	
2022-07-08 11:05:54,421: ============================================================
2022-07-08 11:07:08,284: time cost, forward:0.011673250967745038, backward:0.03402307005208906, data cost:0.7089238897422614 
2022-07-08 11:07:08,284: ============================================================
2022-07-08 11:07:08,284: Epoch 27/36 Batch 1600/7662 eta: 15:23:33.209221	Training Loss1 2.7886 (2.7581)	Training Total_Loss 2.7886 (2.7581)	Training Prec@1 99.414 (99.226)	Training Prec@5 0.000 (0.000)	
2022-07-08 11:07:08,284: ============================================================
2022-07-08 11:08:21,247: time cost, forward:0.011653712807577312, backward:0.03399137386930487, data cost:0.7074695323901432 
2022-07-08 11:08:21,248: ============================================================
2022-07-08 11:08:21,248: Epoch 27/36 Batch 1700/7662 eta: 15:11:05.246610	Training Loss1 2.5989 (2.7604)	Training Total_Loss 2.5989 (2.7604)	Training Prec@1 99.609 (99.225)	Training Prec@5 0.000 (0.000)	
2022-07-08 11:08:21,248: ============================================================
2022-07-08 11:09:34,517: time cost, forward:0.011679954963501722, backward:0.03395883741479506, data cost:0.7063048928893229 
2022-07-08 11:09:34,517: ============================================================
2022-07-08 11:09:34,517: Epoch 27/36 Batch 1800/7662 eta: 15:13:40.564636	Training Loss1 2.8695 (2.7627)	Training Total_Loss 2.8695 (2.7627)	Training Prec@1 99.219 (99.220)	Training Prec@5 0.000 (0.000)	
2022-07-08 11:09:34,517: ============================================================
2022-07-08 11:10:47,147: time cost, forward:0.011710611878727033, backward:0.03388937879324336, data cost:0.704957096623144 
2022-07-08 11:10:47,147: ============================================================
2022-07-08 11:10:47,147: Epoch 27/36 Batch 1900/7662 eta: 15:04:30.042672	Training Loss1 2.8598 (2.7649)	Training Total_Loss 2.8598 (2.7649)	Training Prec@1 99.023 (99.217)	Training Prec@5 0.000 (0.000)	
2022-07-08 11:10:47,147: ============================================================
2022-07-08 11:12:01,712: time cost, forward:0.011719570450928285, backward:0.03388561994925685, data cost:0.7046851470149595 
2022-07-08 11:12:01,712: ============================================================
2022-07-08 11:12:01,713: Epoch 27/36 Batch 2000/7662 eta: 15:27:21.355424	Training Loss1 2.7689 (2.7670)	Training Total_Loss 2.7689 (2.7670)	Training Prec@1 99.805 (99.216)	Training Prec@5 0.000 (0.000)	
2022-07-08 11:12:01,713: ============================================================
2022-07-08 11:13:15,821: time cost, forward:0.011741610468427813, backward:0.03386421019602753, data cost:0.7042207910992976 
2022-07-08 11:13:15,821: ============================================================
2022-07-08 11:13:15,822: Epoch 27/36 Batch 2100/7662 eta: 15:20:26.717407	Training Loss1 2.7629 (2.7695)	Training Total_Loss 2.7629 (2.7695)	Training Prec@1 99.414 (99.214)	Training Prec@5 0.000 (0.000)	
2022-07-08 11:13:15,822: ============================================================
2022-07-08 11:14:29,019: time cost, forward:0.011762975182734928, backward:0.033859886544137824, data cost:0.7033540910891697 
2022-07-08 11:14:29,019: ============================================================
2022-07-08 11:14:29,019: Epoch 27/36 Batch 2200/7662 eta: 15:07:54.399830	Training Loss1 2.8216 (2.7719)	Training Total_Loss 2.8216 (2.7719)	Training Prec@1 99.023 (99.210)	Training Prec@5 0.000 (0.000)	
2022-07-08 11:14:29,019: ============================================================
2022-07-08 11:15:41,317: time cost, forward:0.011779498929508669, backward:0.03385190758408542, data cost:0.702165379426748 
2022-07-08 11:15:41,317: ============================================================
2022-07-08 11:15:41,317: Epoch 27/36 Batch 2300/7662 eta: 14:55:32.524180	Training Loss1 2.8123 (2.7748)	Training Total_Loss 2.8123 (2.7748)	Training Prec@1 99.023 (99.208)	Training Prec@5 0.000 (0.000)	
2022-07-08 11:15:41,317: ============================================================
2022-07-08 11:16:55,095: time cost, forward:0.011788249761176735, backward:0.03381566516356251, data cost:0.7017715539769264 
2022-07-08 11:16:55,096: ============================================================
2022-07-08 11:16:55,096: Epoch 27/36 Batch 2400/7662 eta: 15:12:39.401732	Training Loss1 2.9464 (2.7782)	Training Total_Loss 2.9464 (2.7782)	Training Prec@1 98.828 (99.205)	Training Prec@5 0.000 (0.000)	
2022-07-08 11:16:55,096: ============================================================
2022-07-08 11:18:08,061: time cost, forward:0.011793342768168059, backward:0.03381843211985722, data cost:0.7010288101141335 
2022-07-08 11:18:08,061: ============================================================
2022-07-08 11:18:08,061: Epoch 27/36 Batch 2500/7662 eta: 15:01:22.487079	Training Loss1 2.8127 (2.7814)	Training Total_Loss 2.8127 (2.7814)	Training Prec@1 99.414 (99.198)	Training Prec@5 0.000 (0.000)	
2022-07-08 11:18:08,061: ============================================================
2022-07-08 11:19:22,158: time cost, forward:0.01180144491999275, backward:0.03384207495821123, data cost:0.7007549374137488 
2022-07-08 11:19:22,158: ============================================================
2022-07-08 11:19:22,158: Epoch 27/36 Batch 2600/7662 eta: 15:14:07.256632	Training Loss1 2.7779 (2.7835)	Training Total_Loss 2.7779 (2.7835)	Training Prec@1 99.219 (99.194)	Training Prec@5 0.000 (0.000)	
2022-07-08 11:19:22,158: ============================================================
2022-07-08 11:20:35,176: time cost, forward:0.011781035109156368, backward:0.03382457261087277, data cost:0.7001678781095988 
2022-07-08 11:20:35,176: ============================================================
2022-07-08 11:20:35,176: Epoch 27/36 Batch 2700/7662 eta: 14:59:35.899001	Training Loss1 3.0871 (2.7852)	Training Total_Loss 3.0871 (2.7852)	Training Prec@1 99.219 (99.193)	Training Prec@5 0.000 (0.000)	
2022-07-08 11:20:35,176: ============================================================
2022-07-08 11:21:48,366: time cost, forward:0.011757284285724909, backward:0.033815794733857714, data cost:0.6996867982095035 
2022-07-08 11:21:48,366: ============================================================
2022-07-08 11:21:48,366: Epoch 27/36 Batch 2800/7662 eta: 15:00:29.297425	Training Loss1 2.5048 (2.7873)	Training Total_Loss 2.5048 (2.7873)	Training Prec@1 99.609 (99.192)	Training Prec@5 0.000 (0.000)	
2022-07-08 11:21:48,366: ============================================================
2022-07-08 11:23:02,002: time cost, forward:0.011760600479194402, backward:0.0337818476527919, data cost:0.6993938630595212 
2022-07-08 11:23:02,002: ============================================================
2022-07-08 11:23:02,002: Epoch 27/36 Batch 2900/7662 eta: 15:04:45.404659	Training Loss1 2.9173 (2.7902)	Training Total_Loss 2.9173 (2.7902)	Training Prec@1 98.047 (99.188)	Training Prec@5 0.000 (0.000)	
2022-07-08 11:23:02,002: ============================================================
2022-07-08 11:24:14,540: time cost, forward:0.011781710233239978, backward:0.0337768094704206, data cost:0.6986990873318348 
2022-07-08 11:24:14,540: ============================================================
2022-07-08 11:24:14,540: Epoch 27/36 Batch 3000/7662 eta: 14:50:03.345166	Training Loss1 3.0036 (2.7925)	Training Total_Loss 3.0036 (2.7925)	Training Prec@1 98.828 (99.185)	Training Prec@5 0.000 (0.000)	
2022-07-08 11:24:14,541: ============================================================
2022-07-08 11:25:27,666: time cost, forward:0.011794528487267976, backward:0.03376235712647784, data cost:0.6982486387266964 
2022-07-08 11:25:27,667: ============================================================
2022-07-08 11:25:27,667: Epoch 27/36 Batch 3100/7662 eta: 14:56:03.310146	Training Loss1 2.9958 (2.7944)	Training Total_Loss 2.9958 (2.7944)	Training Prec@1 99.219 (99.182)	Training Prec@5 0.000 (0.000)	
2022-07-08 11:25:27,667: ============================================================
2022-07-08 11:26:40,694: time cost, forward:0.011784873779358883, backward:0.03375612940405189, data cost:0.6978343872399433 
2022-07-08 11:26:40,694: ============================================================
2022-07-08 11:26:40,695: Epoch 27/36 Batch 3200/7662 eta: 14:53:37.682458	Training Loss1 2.6031 (2.7970)	Training Total_Loss 2.6031 (2.7970)	Training Prec@1 99.609 (99.179)	Training Prec@5 0.000 (0.000)	
2022-07-08 11:26:40,695: ============================================================
2022-07-08 11:27:54,193: time cost, forward:0.011810257132033862, backward:0.03373042306382572, data cost:0.6975685158221062 
2022-07-08 11:27:54,193: ============================================================
2022-07-08 11:27:54,193: Epoch 27/36 Batch 3300/7662 eta: 14:58:09.839111	Training Loss1 2.7500 (2.7995)	Training Total_Loss 2.7500 (2.7995)	Training Prec@1 98.828 (99.177)	Training Prec@5 0.000 (0.000)	
2022-07-08 11:27:54,193: ============================================================
2022-07-08 11:29:06,901: time cost, forward:0.011832441432085342, backward:0.03374087365103596, data cost:0.6970486961487077 
2022-07-08 11:29:06,901: ============================================================
2022-07-08 11:29:06,901: Epoch 27/36 Batch 3400/7662 eta: 14:47:17.592024	Training Loss1 2.9092 (2.8009)	Training Total_Loss 2.9092 (2.8009)	Training Prec@1 99.023 (99.175)	Training Prec@5 0.000 (0.000)	
2022-07-08 11:29:06,901: ============================================================
2022-07-08 11:30:20,536: time cost, forward:0.01183603681404613, backward:0.03374231539647488, data cost:0.6968467728210607 
2022-07-08 11:30:20,536: ============================================================
2022-07-08 11:30:20,536: Epoch 27/36 Batch 3500/7662 eta: 14:57:22.618358	Training Loss1 2.7830 (2.8036)	Training Total_Loss 2.7830 (2.8036)	Training Prec@1 98.633 (99.172)	Training Prec@5 0.000 (0.000)	
2022-07-08 11:30:20,536: ============================================================
2022-07-08 11:31:33,153: time cost, forward:0.011856624370616289, backward:0.03372587830399632, data cost:0.6963749290274461 
2022-07-08 11:31:33,154: ============================================================
2022-07-08 11:31:33,154: Epoch 27/36 Batch 3600/7662 eta: 14:43:46.205609	Training Loss1 2.7982 (2.8052)	Training Total_Loss 2.7982 (2.8052)	Training Prec@1 99.219 (99.169)	Training Prec@5 0.000 (0.000)	
2022-07-08 11:31:33,154: ============================================================
2022-07-08 11:32:46,415: time cost, forward:0.0118403804724395, backward:0.03373119347029101, data cost:0.6961180505059029 
2022-07-08 11:32:46,415: ============================================================
2022-07-08 11:32:46,416: Epoch 27/36 Batch 3700/7662 eta: 14:50:23.080048	Training Loss1 2.7879 (2.8070)	Training Total_Loss 2.7879 (2.8070)	Training Prec@1 99.414 (99.166)	Training Prec@5 0.000 (0.000)	
2022-07-08 11:32:46,416: ============================================================
2022-07-08 11:34:00,131: time cost, forward:0.011836537375955965, backward:0.03372360254846519, data cost:0.6959964526142061 
2022-07-08 11:34:00,132: ============================================================
2022-07-08 11:34:00,132: Epoch 27/36 Batch 3800/7662 eta: 14:54:40.987978	Training Loss1 2.8755 (2.8097)	Training Total_Loss 2.8755 (2.8097)	Training Prec@1 98.828 (99.163)	Training Prec@5 0.000 (0.000)	
2022-07-08 11:34:00,132: ============================================================
2022-07-08 11:35:12,939: time cost, forward:0.011816149278921053, backward:0.033728760246987156, data cost:0.695650428953951 
2022-07-08 11:35:12,939: ============================================================
2022-07-08 11:35:12,939: Epoch 27/36 Batch 3900/7662 eta: 14:42:26.283042	Training Loss1 2.8301 (2.8118)	Training Total_Loss 2.8301 (2.8118)	Training Prec@1 99.023 (99.160)	Training Prec@5 0.000 (0.000)	
2022-07-08 11:35:12,939: ============================================================
2022-07-08 11:36:26,404: time cost, forward:0.01179420557520514, backward:0.03372906362691442, data cost:0.6954896008261862 
2022-07-08 11:36:26,404: ============================================================
2022-07-08 11:36:26,405: Epoch 27/36 Batch 4000/7662 eta: 14:49:11.211334	Training Loss1 2.7330 (2.8136)	Training Total_Loss 2.7330 (2.8136)	Training Prec@1 99.414 (99.158)	Training Prec@5 0.000 (0.000)	
2022-07-08 11:36:26,405: ============================================================
2022-07-08 11:37:41,497: time cost, forward:0.01179718756041721, backward:0.0337280606490631, data cost:0.6957178093742004 
2022-07-08 11:37:41,497: ============================================================
2022-07-08 11:37:41,497: Epoch 27/36 Batch 4100/7662 eta: 15:07:38.053221	Training Loss1 2.8700 (2.8150)	Training Total_Loss 2.8700 (2.8150)	Training Prec@1 99.414 (99.156)	Training Prec@5 0.000 (0.000)	
2022-07-08 11:37:41,498: ============================================================
2022-07-08 11:38:54,867: time cost, forward:0.011794612248132955, backward:0.033744162620604395, data cost:0.6955087828221677 
2022-07-08 11:38:54,867: ============================================================
2022-07-08 11:38:54,867: Epoch 27/36 Batch 4200/7662 eta: 14:45:35.161917	Training Loss1 3.1576 (2.8170)	Training Total_Loss 3.1576 (2.8170)	Training Prec@1 98.633 (99.153)	Training Prec@5 0.000 (0.000)	
2022-07-08 11:38:54,867: ============================================================
2022-07-08 11:40:08,376: time cost, forward:0.011796087851549864, backward:0.03375235988140439, data cost:0.6953477496794696 
2022-07-08 11:40:08,376: ============================================================
2022-07-08 11:40:08,377: Epoch 27/36 Batch 4300/7662 eta: 14:46:02.711024	Training Loss1 2.8947 (2.8191)	Training Total_Loss 2.8947 (2.8191)	Training Prec@1 99.219 (99.149)	Training Prec@5 0.000 (0.000)	
2022-07-08 11:40:08,377: ============================================================
2022-07-08 11:41:23,521: time cost, forward:0.01179316169051968, backward:0.033748901440463684, data cost:0.6955816850902872 
2022-07-08 11:41:23,522: ============================================================
2022-07-08 11:41:23,522: Epoch 27/36 Batch 4400/7662 eta: 15:04:30.700480	Training Loss1 2.9050 (2.8206)	Training Total_Loss 2.9050 (2.8206)	Training Prec@1 98.633 (99.147)	Training Prec@5 0.000 (0.000)	
2022-07-08 11:41:23,522: ============================================================
2022-07-08 11:42:37,118: time cost, forward:0.01179410214158105, backward:0.03374668767012922, data cost:0.6954523463544912 
2022-07-08 11:42:37,118: ============================================================
2022-07-08 11:42:37,119: Epoch 27/36 Batch 4500/7662 eta: 14:44:38.657918	Training Loss1 2.9375 (2.8225)	Training Total_Loss 2.9375 (2.8225)	Training Prec@1 99.023 (99.144)	Training Prec@5 0.000 (0.000)	
2022-07-08 11:42:37,119: ============================================================
2022-07-08 11:43:50,114: time cost, forward:0.011781676434050127, backward:0.033748740760055046, data cost:0.6952137680617745 
2022-07-08 11:43:50,115: ============================================================
2022-07-08 11:43:50,115: Epoch 27/36 Batch 4600/7662 eta: 14:36:12.548961	Training Loss1 3.0101 (2.8242)	Training Total_Loss 3.0101 (2.8242)	Training Prec@1 98.828 (99.142)	Training Prec@5 0.000 (0.000)	
2022-07-08 11:43:50,115: ============================================================
2022-07-08 11:45:02,950: time cost, forward:0.011780004243592958, backward:0.03374496189222155, data cost:0.6949412216909846 
2022-07-08 11:45:02,950: ============================================================
2022-07-08 11:45:02,951: Epoch 27/36 Batch 4700/7662 eta: 14:33:04.301344	Training Loss1 2.8623 (2.8263)	Training Total_Loss 2.8623 (2.8263)	Training Prec@1 99.219 (99.137)	Training Prec@5 0.000 (0.000)	
2022-07-08 11:45:02,951: ============================================================
2022-07-08 11:46:16,883: time cost, forward:0.011779073825302808, backward:0.033754560246420894, data cost:0.6948967277568985 
2022-07-08 11:46:16,883: ============================================================
2022-07-08 11:46:16,884: Epoch 27/36 Batch 4800/7662 eta: 14:44:59.415883	Training Loss1 2.9883 (2.8280)	Training Total_Loss 2.9883 (2.8280)	Training Prec@1 99.414 (99.136)	Training Prec@5 0.000 (0.000)	
2022-07-08 11:46:16,884: ============================================================
2022-07-08 11:47:31,024: time cost, forward:0.011779089805227709, backward:0.033763501127779934, data cost:0.6948927592004798 
2022-07-08 11:47:31,025: ============================================================
2022-07-08 11:47:31,025: Epoch 27/36 Batch 4900/7662 eta: 14:46:14.886534	Training Loss1 2.7549 (2.8297)	Training Total_Loss 2.7549 (2.8297)	Training Prec@1 98.633 (99.133)	Training Prec@5 0.000 (0.000)	
2022-07-08 11:47:31,025: ============================================================
2022-07-08 11:48:43,442: time cost, forward:0.01176969312052413, backward:0.03376502984999466, data cost:0.6945678941200533 
2022-07-08 11:48:43,443: ============================================================
2022-07-08 11:48:43,443: Epoch 27/36 Batch 5000/7662 eta: 14:24:26.405266	Training Loss1 2.9121 (2.8315)	Training Total_Loss 2.9121 (2.8315)	Training Prec@1 98.633 (99.131)	Training Prec@5 0.000 (0.000)	
2022-07-08 11:48:43,443: ============================================================
2022-07-08 11:49:56,934: time cost, forward:0.01176148794473071, backward:0.03376083136493259, data cost:0.6944688464361304 
2022-07-08 11:49:56,934: ============================================================
2022-07-08 11:49:56,935: Epoch 27/36 Batch 5100/7662 eta: 14:36:02.020536	Training Loss1 2.8190 (2.8336)	Training Total_Loss 2.8190 (2.8336)	Training Prec@1 99.219 (99.128)	Training Prec@5 0.000 (0.000)	
2022-07-08 11:49:56,935: ============================================================
2022-07-08 11:51:10,794: time cost, forward:0.011751902564302457, backward:0.033750373415131596, data cost:0.6944507366190692 
2022-07-08 11:51:10,795: ============================================================
2022-07-08 11:51:10,795: Epoch 27/36 Batch 5200/7662 eta: 14:39:11.807309	Training Loss1 3.2204 (2.8353)	Training Total_Loss 3.2204 (2.8353)	Training Prec@1 98.633 (99.125)	Training Prec@5 0.000 (0.000)	
2022-07-08 11:51:10,795: ============================================================
2022-07-08 11:52:24,787: time cost, forward:0.011756113057407393, backward:0.033744915315937964, data cost:0.6944417382978363 
2022-07-08 11:52:24,787: ============================================================
2022-07-08 11:52:24,787: Epoch 27/36 Batch 5300/7662 eta: 14:39:32.135199	Training Loss1 3.0594 (2.8372)	Training Total_Loss 3.0594 (2.8372)	Training Prec@1 98.242 (99.122)	Training Prec@5 0.000 (0.000)	
2022-07-08 11:52:24,787: ============================================================
2022-07-08 11:53:38,392: time cost, forward:0.011756892556679605, backward:0.033733884412550354, data cost:0.694365925646685 
2022-07-08 11:53:38,392: ============================================================
2022-07-08 11:53:38,392: Epoch 27/36 Batch 5400/7662 eta: 14:33:42.146255	Training Loss1 3.1198 (2.8385)	Training Total_Loss 3.1198 (2.8385)	Training Prec@1 98.828 (99.121)	Training Prec@5 0.000 (0.000)	
2022-07-08 11:53:38,392: ============================================================
2022-07-08 11:54:51,660: time cost, forward:0.01174636042363038, backward:0.033731832745335796, data cost:0.6942354180765576 
2022-07-08 11:54:51,660: ============================================================
2022-07-08 11:54:51,661: Epoch 27/36 Batch 5500/7662 eta: 14:28:29.178375	Training Loss1 2.9562 (2.8400)	Training Total_Loss 2.9562 (2.8400)	Training Prec@1 98.828 (99.118)	Training Prec@5 0.000 (0.000)	
2022-07-08 11:54:51,661: ============================================================
2022-07-08 11:56:06,220: time cost, forward:0.011747125472995208, backward:0.033739623863327864, data cost:0.6943209562201141 
2022-07-08 11:56:06,221: ============================================================
2022-07-08 11:56:06,221: Epoch 27/36 Batch 5600/7662 eta: 14:42:33.500883	Training Loss1 3.2638 (2.8413)	Training Total_Loss 3.2638 (2.8413)	Training Prec@1 98.828 (99.117)	Training Prec@5 0.000 (0.000)	
2022-07-08 11:56:06,221: ============================================================
2022-07-08 11:57:19,828: time cost, forward:0.011743038866598996, backward:0.03373777441736647, data cost:0.6942512683647518 
2022-07-08 11:57:19,828: ============================================================
2022-07-08 11:57:19,828: Epoch 27/36 Batch 5700/7662 eta: 14:30:03.126093	Training Loss1 3.1226 (2.8433)	Training Total_Loss 3.1226 (2.8433)	Training Prec@1 98.633 (99.113)	Training Prec@5 0.000 (0.000)	
2022-07-08 11:57:19,828: ============================================================
2022-07-08 11:58:33,194: time cost, forward:0.01173945109707299, backward:0.033741651310717616, data cost:0.6941354262415634 
2022-07-08 11:58:33,194: ============================================================
2022-07-08 11:58:33,195: Epoch 27/36 Batch 5800/7662 eta: 14:25:58.703835	Training Loss1 3.0674 (2.8451)	Training Total_Loss 3.0674 (2.8451)	Training Prec@1 98.633 (99.111)	Training Prec@5 0.000 (0.000)	
2022-07-08 11:58:33,195: ============================================================
2022-07-08 11:59:48,188: time cost, forward:0.011740334419137967, backward:0.033743308709625226, data cost:0.6943037958544459 
2022-07-08 11:59:48,188: ============================================================
2022-07-08 11:59:48,189: Epoch 27/36 Batch 5900/7662 eta: 14:43:56.535206	Training Loss1 2.9265 (2.8468)	Training Total_Loss 2.9265 (2.8468)	Training Prec@1 99.805 (99.109)	Training Prec@5 0.000 (0.000)	
2022-07-08 11:59:48,189: ============================================================
2022-07-08 12:01:02,850: time cost, forward:0.01174109831395239, backward:0.03374698047221432, data cost:0.694400564871901 
2022-07-08 12:01:02,851: ============================================================
2022-07-08 12:01:02,851: Epoch 27/36 Batch 6000/7662 eta: 14:38:47.174228	Training Loss1 3.0507 (2.8484)	Training Total_Loss 3.0507 (2.8484)	Training Prec@1 98.828 (99.108)	Training Prec@5 0.000 (0.000)	
2022-07-08 12:01:02,851: ============================================================
2022-07-08 12:02:16,169: time cost, forward:0.011748083694427985, backward:0.033760180999498166, data cost:0.6942603700296628 
2022-07-08 12:02:16,169: ============================================================
2022-07-08 12:02:16,169: Epoch 27/36 Batch 6100/7662 eta: 14:21:44.708565	Training Loss1 2.9101 (2.8503)	Training Total_Loss 2.9101 (2.8503)	Training Prec@1 98.828 (99.106)	Training Prec@5 0.000 (0.000)	
2022-07-08 12:02:16,169: ============================================================
2022-07-08 12:03:31,496: time cost, forward:0.011748861278097636, backward:0.033757251546274826, data cost:0.6944752084880053 
2022-07-08 12:03:31,496: ============================================================
2022-07-08 12:03:31,496: Epoch 27/36 Batch 6200/7662 eta: 14:44:06.324450	Training Loss1 2.9752 (2.8516)	Training Total_Loss 2.9752 (2.8516)	Training Prec@1 99.023 (99.104)	Training Prec@5 0.000 (0.000)	
2022-07-08 12:03:31,497: ============================================================
2022-07-08 12:04:45,741: time cost, forward:0.011742925545510308, backward:0.03376976636349729, data cost:0.6944980721262489 
2022-07-08 12:04:45,741: ============================================================
2022-07-08 12:04:45,741: Epoch 27/36 Batch 6300/7662 eta: 14:30:09.817987	Training Loss1 3.0114 (2.8536)	Training Total_Loss 3.0114 (2.8536)	Training Prec@1 99.414 (99.100)	Training Prec@5 0.000 (0.000)	
2022-07-08 12:04:45,742: ============================================================
2022-07-08 12:05:58,840: time cost, forward:0.011739702816399992, backward:0.03375872244479452, data cost:0.6943615769050814 
2022-07-08 12:05:58,840: ============================================================
2022-07-08 12:05:58,840: Epoch 27/36 Batch 6400/7662 eta: 14:15:30.539549	Training Loss1 3.0164 (2.8550)	Training Total_Loss 3.0164 (2.8550)	Training Prec@1 98.438 (99.098)	Training Prec@5 0.000 (0.000)	
2022-07-08 12:05:58,840: ============================================================
2022-07-08 12:07:11,959: time cost, forward:0.011741514773823, backward:0.0337422119688852, data cost:0.6942345920315631 
2022-07-08 12:07:11,960: ============================================================
2022-07-08 12:07:11,960: Epoch 27/36 Batch 6500/7662 eta: 14:14:32.356421	Training Loss1 2.9536 (2.8561)	Training Total_Loss 2.9536 (2.8561)	Training Prec@1 98.633 (99.096)	Training Prec@5 0.000 (0.000)	
2022-07-08 12:07:11,960: ============================================================
2022-07-08 12:08:27,031: time cost, forward:0.011736348824602923, backward:0.03375504356132238, data cost:0.694385428449605 
2022-07-08 12:08:27,031: ============================================================
2022-07-08 12:08:27,031: Epoch 27/36 Batch 6600/7662 eta: 14:36:05.869816	Training Loss1 2.9261 (2.8574)	Training Total_Loss 2.9261 (2.8574)	Training Prec@1 99.609 (99.093)	Training Prec@5 0.000 (0.000)	
2022-07-08 12:08:27,032: ============================================================
2022-07-08 12:09:40,061: time cost, forward:0.011740053886975044, backward:0.0337470886084122, data cost:0.6942354272881414 
2022-07-08 12:09:40,061: ============================================================
2022-07-08 12:09:40,061: Epoch 27/36 Batch 6700/7662 eta: 14:11:03.213759	Training Loss1 3.1175 (2.8586)	Training Total_Loss 3.1175 (2.8586)	Training Prec@1 98.242 (99.091)	Training Prec@5 0.000 (0.000)	
2022-07-08 12:09:40,061: ============================================================
2022-07-08 12:10:54,018: time cost, forward:0.011723648398952425, backward:0.033762288069020194, data cost:0.6942276341684742 
2022-07-08 12:10:54,018: ============================================================
2022-07-08 12:10:54,018: Epoch 27/36 Batch 6800/7662 eta: 14:20:37.258127	Training Loss1 2.8461 (2.8600)	Training Total_Loss 2.8461 (2.8600)	Training Prec@1 99.414 (99.088)	Training Prec@5 0.000 (0.000)	
2022-07-08 12:10:54,018: ============================================================
2022-07-08 12:12:07,767: time cost, forward:0.011728695845807838, backward:0.03376593391417351, data cost:0.6941773694811533 
2022-07-08 12:12:07,768: ============================================================
2022-07-08 12:12:07,768: Epoch 27/36 Batch 6900/7662 eta: 14:16:59.069610	Training Loss1 2.9171 (2.8616)	Training Total_Loss 2.9171 (2.8616)	Training Prec@1 99.023 (99.086)	Training Prec@5 0.000 (0.000)	
2022-07-08 12:12:07,768: ============================================================
2022-07-08 12:13:22,236: time cost, forward:0.01173074038680374, backward:0.033773128126907186, data cost:0.694232556935395 
2022-07-08 12:13:22,237: ============================================================
2022-07-08 12:13:22,237: Epoch 27/36 Batch 7000/7662 eta: 14:24:06.342916	Training Loss1 3.0660 (2.8632)	Training Total_Loss 3.0660 (2.8632)	Training Prec@1 99.023 (99.083)	Training Prec@5 0.000 (0.000)	
2022-07-08 12:13:22,237: ============================================================
2022-07-08 12:14:36,424: time cost, forward:0.011742310182093433, backward:0.033781923833305125, data cost:0.6942324773377643 
2022-07-08 12:14:36,424: ============================================================
2022-07-08 12:14:36,424: Epoch 27/36 Batch 7100/7662 eta: 14:19:35.745351	Training Loss1 2.8747 (2.8648)	Training Total_Loss 2.8747 (2.8648)	Training Prec@1 98.633 (99.082)	Training Prec@5 0.000 (0.000)	
2022-07-08 12:14:36,424: ============================================================
2022-07-08 12:15:51,155: time cost, forward:0.01175327684535204, backward:0.03379298932255267, data cost:0.6943069326329486 
2022-07-08 12:15:51,156: ============================================================
2022-07-08 12:15:51,156: Epoch 27/36 Batch 7200/7662 eta: 14:24:39.203771	Training Loss1 3.0816 (2.8663)	Training Total_Loss 3.0816 (2.8663)	Training Prec@1 99.219 (99.079)	Training Prec@5 0.000 (0.000)	
2022-07-08 12:15:51,156: ============================================================
2022-07-08 12:17:04,569: time cost, forward:0.011759129039619636, backward:0.03379037609197029, data cost:0.6942151332656101 
2022-07-08 12:17:04,570: ============================================================
2022-07-08 12:17:04,570: Epoch 27/36 Batch 7300/7662 eta: 14:08:11.501261	Training Loss1 2.7765 (2.8679)	Training Total_Loss 2.7765 (2.8679)	Training Prec@1 99.219 (99.078)	Training Prec@5 0.000 (0.000)	
2022-07-08 12:17:04,570: ============================================================
2022-07-08 12:18:19,855: time cost, forward:0.011765331815329577, backward:0.033796479048189526, data cost:0.6943729572126005 
2022-07-08 12:18:19,856: ============================================================
2022-07-08 12:18:19,856: Epoch 27/36 Batch 7400/7662 eta: 14:28:33.551587	Training Loss1 2.8835 (2.8694)	Training Total_Loss 2.8835 (2.8694)	Training Prec@1 98.633 (99.075)	Training Prec@5 0.000 (0.000)	
2022-07-08 12:18:19,856: ============================================================
2022-07-08 12:19:33,680: time cost, forward:0.011765184299455259, backward:0.033798969082871125, data cost:0.6943398346057144 
2022-07-08 12:19:33,681: ============================================================
2022-07-08 12:19:33,681: Epoch 27/36 Batch 7500/7662 eta: 14:10:28.565758	Training Loss1 2.9030 (2.8708)	Training Total_Loss 2.9030 (2.8708)	Training Prec@1 99.219 (99.073)	Training Prec@5 0.000 (0.000)	
2022-07-08 12:19:33,681: ============================================================
2022-07-08 12:20:46,721: time cost, forward:0.011766395093202748, backward:0.03380026674879305, data cost:0.6942051424605546 
2022-07-08 12:20:46,722: ============================================================
2022-07-08 12:20:46,722: Epoch 27/36 Batch 7600/7662 eta: 14:00:13.713446	Training Loss1 2.9559 (2.8719)	Training Total_Loss 2.9559 (2.8719)	Training Prec@1 98.828 (99.071)	Training Prec@5 0.000 (0.000)	
2022-07-08 12:20:46,722: ============================================================
2022-07-08 12:21:34,325: Epoch 27/36 Batch 7663/7662 eta: 13:59:27.697539	Training Loss1 2.8169 (2.8727)	Training Total_Loss 2.8169 (2.8727)	Training Prec@1 99.414 (99.071)	Training Prec@5 0.000 (0.000)	
2022-07-08 12:21:34,326: ============================================================
2022-07-08 12:21:34,613: Save Checkpoint...
2022-07-08 12:21:34,613: ============================================================
2022-07-08 12:21:37,161: Save done!
2022-07-08 12:21:37,161: ============================================================
2022-07-08 12:23:25,767: time cost, forward:0.011079188549157345, backward:0.03278739524610115, data cost:1.0471508406629466 
2022-07-08 12:23:25,767: ============================================================
2022-07-08 12:23:25,767: Epoch 28/36 Batch 100/7662 eta: 20:45:55.781294	Training Loss1 2.6212 (2.6992)	Training Total_Loss 2.6212 (2.6992)	Training Prec@1 99.414 (99.345)	Training Prec@5 0.000 (0.000)	
2022-07-08 12:23:25,767: ============================================================
2022-07-08 12:24:40,571: time cost, forward:0.010885846075700156, backward:0.032934636925932154, data cost:0.8745437063763489 
2022-07-08 12:24:40,571: ============================================================
2022-07-08 12:24:40,571: Epoch 28/36 Batch 200/7662 eta: 14:17:14.735242	Training Loss1 3.0370 (2.7068)	Training Total_Loss 3.0370 (2.7068)	Training Prec@1 99.023 (99.308)	Training Prec@5 0.000 (0.000)	
2022-07-08 12:24:40,572: ============================================================
2022-07-08 12:25:54,674: time cost, forward:0.01089304107487401, backward:0.03288199829816021, data cost:0.8151131537447007 
2022-07-08 12:25:54,674: ============================================================
2022-07-08 12:25:54,675: Epoch 28/36 Batch 300/7662 eta: 14:07:58.486431	Training Loss1 2.5614 (2.7087)	Training Total_Loss 2.5614 (2.7087)	Training Prec@1 99.805 (99.310)	Training Prec@5 0.000 (0.000)	
2022-07-08 12:25:54,675: ============================================================
2022-07-08 12:27:08,985: time cost, forward:0.010888863924451937, backward:0.03291811560628408, data cost:0.7859257731521339 
2022-07-08 12:27:08,985: ============================================================
2022-07-08 12:27:08,985: Epoch 28/36 Batch 400/7662 eta: 14:09:06.652830	Training Loss1 2.8527 (2.7130)	Training Total_Loss 2.8527 (2.7130)	Training Prec@1 99.023 (99.276)	Training Prec@5 0.000 (0.000)	
2022-07-08 12:27:08,985: ============================================================
2022-07-08 12:28:24,009: time cost, forward:0.01084990157393033, backward:0.03310599212417144, data cost:0.7697197683827433 
2022-07-08 12:28:24,009: ============================================================
2022-07-08 12:28:24,009: Epoch 28/36 Batch 500/7662 eta: 14:16:00.584792	Training Loss1 2.5429 (2.7131)	Training Total_Loss 2.5429 (2.7131)	Training Prec@1 99.414 (99.280)	Training Prec@5 0.000 (0.000)	
2022-07-08 12:28:24,009: ============================================================
2022-07-08 12:29:39,719: time cost, forward:0.010819876532323771, backward:0.03325965289082471, data cost:0.7600330689514618 
2022-07-08 12:29:39,719: ============================================================
2022-07-08 12:29:39,719: Epoch 28/36 Batch 600/7662 eta: 14:22:34.805585	Training Loss1 2.8976 (2.7189)	Training Total_Loss 2.8976 (2.7189)	Training Prec@1 99.219 (99.285)	Training Prec@5 0.000 (0.000)	
2022-07-08 12:29:39,719: ============================================================
2022-07-08 12:30:54,933: time cost, forward:0.010846866899634976, backward:0.03333513214864444, data cost:0.7524335834601407 
2022-07-08 12:30:54,934: ============================================================
2022-07-08 12:30:54,934: Epoch 28/36 Batch 700/7662 eta: 14:15:40.626138	Training Loss1 2.7968 (2.7203)	Training Total_Loss 2.7968 (2.7203)	Training Prec@1 98.828 (99.286)	Training Prec@5 0.000 (0.000)	
2022-07-08 12:30:54,934: ============================================================
2022-07-08 12:32:08,150: time cost, forward:0.010953257170427725, backward:0.03361272244936832, data cost:0.7439101342116489 
2022-07-08 12:32:08,151: ============================================================
2022-07-08 12:32:08,151: Epoch 28/36 Batch 800/7662 eta: 13:51:43.942859	Training Loss1 2.6230 (2.7236)	Training Total_Loss 2.6230 (2.7236)	Training Prec@1 99.805 (99.277)	Training Prec@5 0.000 (0.000)	
2022-07-08 12:32:08,151: ============================================================
2022-07-08 12:33:20,384: time cost, forward:0.010959552843393023, backward:0.03373138233604898, data cost:0.736345845414481 
2022-07-08 12:33:20,384: ============================================================
2022-07-08 12:33:20,384: Epoch 28/36 Batch 900/7662 eta: 13:39:21.300733	Training Loss1 2.7100 (2.7257)	Training Total_Loss 2.7100 (2.7257)	Training Prec@1 99.023 (99.277)	Training Prec@5 0.000 (0.000)	
2022-07-08 12:33:20,384: ============================================================
2022-07-08 12:34:33,252: time cost, forward:0.010977496136654843, backward:0.033834904641121835, data cost:0.7309575510454608 
2022-07-08 12:34:33,252: ============================================================
2022-07-08 12:34:33,253: Epoch 28/36 Batch 1000/7662 eta: 13:45:20.621926	Training Loss1 2.6068 (2.7274)	Training Total_Loss 2.6068 (2.7274)	Training Prec@1 100.000 (99.278)	Training Prec@5 0.000 (0.000)	
2022-07-08 12:34:33,253: ============================================================
2022-07-08 12:35:46,103: time cost, forward:0.011040525722763992, backward:0.03391012720241668, data cost:0.7264619233718886 
2022-07-08 12:35:46,104: ============================================================
2022-07-08 12:35:46,104: Epoch 28/36 Batch 1100/7662 eta: 13:43:56.150563	Training Loss1 2.8408 (2.7303)	Training Total_Loss 2.8408 (2.7303)	Training Prec@1 99.414 (99.276)	Training Prec@5 0.000 (0.000)	
2022-07-08 12:35:46,104: ============================================================
2022-07-08 12:37:00,607: time cost, forward:0.011096289000777625, backward:0.03382315070953242, data cost:0.7242475639690052 
2022-07-08 12:37:00,608: ============================================================
2022-07-08 12:37:00,608: Epoch 28/36 Batch 1200/7662 eta: 14:01:23.163871	Training Loss1 2.7283 (2.7326)	Training Total_Loss 2.7283 (2.7326)	Training Prec@1 99.023 (99.275)	Training Prec@5 0.000 (0.000)	
2022-07-08 12:37:00,608: ============================================================
2022-07-08 12:38:11,811: time cost, forward:0.011132607926213806, backward:0.03387562305400517, data cost:0.7197049159651265 
2022-07-08 12:38:11,812: ============================================================
2022-07-08 12:38:11,812: Epoch 28/36 Batch 1300/7662 eta: 13:22:55.904840	Training Loss1 2.7845 (2.7362)	Training Total_Loss 2.7845 (2.7362)	Training Prec@1 98.828 (99.269)	Training Prec@5 0.000 (0.000)	
2022-07-08 12:38:11,812: ============================================================
2022-07-08 12:39:25,818: time cost, forward:0.011202739425179275, backward:0.03389302349840427, data cost:0.7178306765348422 
2022-07-08 12:39:25,818: ============================================================
2022-07-08 12:39:25,818: Epoch 28/36 Batch 1400/7662 eta: 13:53:17.837111	Training Loss1 2.7357 (2.7380)	Training Total_Loss 2.7357 (2.7380)	Training Prec@1 99.414 (99.270)	Training Prec@5 0.000 (0.000)	
2022-07-08 12:39:25,818: ============================================================
2022-07-08 12:40:39,923: time cost, forward:0.011200401288338548, backward:0.03394701148447313, data cost:0.7162576038253713 
2022-07-08 12:40:39,923: ============================================================
2022-07-08 12:40:39,923: Epoch 28/36 Batch 1500/7662 eta: 13:53:10.603582	Training Loss1 2.7811 (2.7418)	Training Total_Loss 2.7811 (2.7418)	Training Prec@1 99.219 (99.262)	Training Prec@5 0.000 (0.000)	
2022-07-08 12:40:39,923: ============================================================
2022-07-08 12:41:54,159: time cost, forward:0.011223699242864421, backward:0.03398286513494953, data cost:0.7149896739496896 
2022-07-08 12:41:54,159: ============================================================
2022-07-08 12:41:54,159: Epoch 28/36 Batch 1600/7662 eta: 13:53:24.611221	Training Loss1 2.9049 (2.7445)	Training Total_Loss 2.9049 (2.7445)	Training Prec@1 99.609 (99.259)	Training Prec@5 0.000 (0.000)	
2022-07-08 12:41:54,159: ============================================================
2022-07-08 12:43:07,313: time cost, forward:0.01127269143143284, backward:0.03400918116914728, data cost:0.7131919180245313 
2022-07-08 12:43:07,314: ============================================================
2022-07-08 12:43:07,314: Epoch 28/36 Batch 1700/7662 eta: 13:40:03.080894	Training Loss1 2.7959 (2.7473)	Training Total_Loss 2.7959 (2.7473)	Training Prec@1 99.219 (99.257)	Training Prec@5 0.000 (0.000)	
2022-07-08 12:43:07,314: ============================================================
2022-07-08 12:44:20,445: time cost, forward:0.01128579524571926, backward:0.033993847970501326, data cost:0.7116512859974258 
2022-07-08 12:44:20,445: ============================================================
2022-07-08 12:44:20,445: Epoch 28/36 Batch 1800/7662 eta: 13:38:34.305310	Training Loss1 2.7878 (2.7502)	Training Total_Loss 2.7878 (2.7502)	Training Prec@1 99.609 (99.255)	Training Prec@5 0.000 (0.000)	
2022-07-08 12:44:20,445: ============================================================
2022-07-08 12:45:33,188: time cost, forward:0.011313156682356463, backward:0.03399076519544781, data cost:0.7100395721909621 
2022-07-08 12:45:33,188: ============================================================
2022-07-08 12:45:33,188: Epoch 28/36 Batch 1900/7662 eta: 13:33:00.744698	Training Loss1 3.0588 (2.7521)	Training Total_Loss 3.0588 (2.7521)	Training Prec@1 98.242 (99.253)	Training Prec@5 0.000 (0.000)	
2022-07-08 12:45:33,188: ============================================================
2022-07-08 12:46:46,456: time cost, forward:0.011315195962391595, backward:0.0340020029231153, data cost:0.7088642657071487 
2022-07-08 12:46:46,457: ============================================================
2022-07-08 12:46:46,457: Epoch 28/36 Batch 2000/7662 eta: 13:37:39.885946	Training Loss1 2.9287 (2.7548)	Training Total_Loss 2.9287 (2.7548)	Training Prec@1 99.023 (99.248)	Training Prec@5 0.000 (0.000)	
2022-07-08 12:46:46,457: ============================================================
2022-07-08 12:48:00,131: time cost, forward:0.011327894714231887, backward:0.03402251399886671, data cost:0.7079746608452435 
2022-07-08 12:48:00,132: ============================================================
2022-07-08 12:48:00,132: Epoch 28/36 Batch 2100/7662 eta: 13:40:58.481395	Training Loss1 2.9393 (2.7574)	Training Total_Loss 2.9393 (2.7574)	Training Prec@1 98.633 (99.245)	Training Prec@5 0.000 (0.000)	
2022-07-08 12:48:00,132: ============================================================
2022-07-08 12:49:13,361: time cost, forward:0.011340903606995934, backward:0.03405256041509013, data cost:0.7069518492405065 
2022-07-08 12:49:13,361: ============================================================
2022-07-08 12:49:13,362: Epoch 28/36 Batch 2200/7662 eta: 13:34:47.386355	Training Loss1 2.7674 (2.7601)	Training Total_Loss 2.7674 (2.7601)	Training Prec@1 99.609 (99.243)	Training Prec@5 0.000 (0.000)	
2022-07-08 12:49:13,362: ============================================================
2022-07-08 12:50:26,600: time cost, forward:0.011360069211019853, backward:0.0340511602855548, data cost:0.7060320169939172 
2022-07-08 12:50:26,601: ============================================================
2022-07-08 12:50:26,601: Epoch 28/36 Batch 2300/7662 eta: 13:33:40.571010	Training Loss1 2.7364 (2.7634)	Training Total_Loss 2.7364 (2.7634)	Training Prec@1 99.219 (99.239)	Training Prec@5 0.000 (0.000)	
2022-07-08 12:50:26,601: ============================================================
2022-07-08 12:51:40,206: time cost, forward:0.011390940653080243, backward:0.034066872380086904, data cost:0.7053184278709981 
2022-07-08 12:51:40,206: ============================================================
2022-07-08 12:51:40,207: Epoch 28/36 Batch 2400/7662 eta: 13:36:31.218191	Training Loss1 2.9388 (2.7664)	Training Total_Loss 2.9388 (2.7664)	Training Prec@1 98.438 (99.236)	Training Prec@5 0.000 (0.000)	
2022-07-08 12:51:40,207: ============================================================
2022-07-08 12:52:54,016: time cost, forward:0.011408222823583778, backward:0.03407683492708607, data cost:0.7047605134812104 
2022-07-08 12:52:54,016: ============================================================
2022-07-08 12:52:54,017: Epoch 28/36 Batch 2500/7662 eta: 13:37:33.289464	Training Loss1 3.1273 (2.7694)	Training Total_Loss 3.1273 (2.7694)	Training Prec@1 99.609 (99.230)	Training Prec@5 0.000 (0.000)	
2022-07-08 12:52:54,017: ============================================================
2022-07-08 12:54:05,105: time cost, forward:0.011422344151255074, backward:0.03405783725913188, data cost:0.703228818861142 
2022-07-08 12:54:05,106: ============================================================
2022-07-08 12:54:05,106: Epoch 28/36 Batch 2600/7662 eta: 13:06:14.235865	Training Loss1 2.6621 (2.7714)	Training Total_Loss 2.6621 (2.7714)	Training Prec@1 99.219 (99.228)	Training Prec@5 0.000 (0.000)	
2022-07-08 12:54:05,106: ============================================================
2022-07-08 12:55:18,557: time cost, forward:0.011461233377191658, backward:0.03406294075017861, data cost:0.7026364187613025 
2022-07-08 12:55:18,557: ============================================================
2022-07-08 12:55:18,557: Epoch 28/36 Batch 2700/7662 eta: 13:31:08.229976	Training Loss1 3.0135 (2.7734)	Training Total_Loss 3.0135 (2.7734)	Training Prec@1 98.633 (99.223)	Training Prec@5 0.000 (0.000)	
2022-07-08 12:55:18,558: ============================================================
2022-07-08 12:56:31,682: time cost, forward:0.011445418218494782, backward:0.034063060780259787, data cost:0.7020225270214401 
2022-07-08 12:56:31,682: ============================================================
2022-07-08 12:56:31,682: Epoch 28/36 Batch 2800/7662 eta: 13:26:18.622214	Training Loss1 2.8496 (2.7770)	Training Total_Loss 2.8496 (2.7770)	Training Prec@1 99.805 (99.218)	Training Prec@5 0.000 (0.000)	
2022-07-08 12:56:31,682: ============================================================
2022-07-08 12:57:44,635: time cost, forward:0.011423354232751242, backward:0.034090300353077536, data cost:0.7013802919029244 
2022-07-08 12:57:44,635: ============================================================
2022-07-08 12:57:44,635: Epoch 28/36 Batch 2900/7662 eta: 13:23:12.099961	Training Loss1 3.0469 (2.7800)	Training Total_Loss 3.0469 (2.7800)	Training Prec@1 99.414 (99.212)	Training Prec@5 0.000 (0.000)	
2022-07-08 12:57:44,635: ============================================================
2022-07-08 12:58:58,492: time cost, forward:0.011446118951042559, backward:0.034114242434779896, data cost:0.7010371089577874 
2022-07-08 12:58:58,492: ============================================================
2022-07-08 12:58:58,492: Epoch 28/36 Batch 3000/7662 eta: 13:31:55.322978	Training Loss1 2.9011 (2.7829)	Training Total_Loss 2.9011 (2.7829)	Training Prec@1 98.633 (99.210)	Training Prec@5 0.000 (0.000)	
2022-07-08 12:58:58,492: ============================================================
2022-07-08 13:00:11,807: time cost, forward:0.011464312138885173, backward:0.03410959797699477, data cost:0.7005710070192448 
2022-07-08 13:00:11,807: ============================================================
2022-07-08 13:00:11,808: Epoch 28/36 Batch 3100/7662 eta: 13:24:44.691544	Training Loss1 2.7470 (2.7849)	Training Total_Loss 2.7470 (2.7849)	Training Prec@1 99.414 (99.206)	Training Prec@5 0.000 (0.000)	
2022-07-08 13:00:11,808: ============================================================
2022-07-08 13:01:25,213: time cost, forward:0.011466706905859863, backward:0.03409235139830703, data cost:0.700191010009799 
2022-07-08 13:01:25,214: ============================================================
2022-07-08 13:01:25,214: Epoch 28/36 Batch 3200/7662 eta: 13:24:31.249646	Training Loss1 2.9810 (2.7864)	Training Total_Loss 2.9810 (2.7864)	Training Prec@1 98.828 (99.205)	Training Prec@5 0.000 (0.000)	
2022-07-08 13:01:25,214: ============================================================
2022-07-08 13:02:38,863: time cost, forward:0.011477385625292873, backward:0.034072615587917306, data cost:0.6999005255246747 
2022-07-08 13:02:38,864: ============================================================
2022-07-08 13:02:38,864: Epoch 28/36 Batch 3300/7662 eta: 13:25:57.872191	Training Loss1 2.9098 (2.7883)	Training Total_Loss 2.9098 (2.7883)	Training Prec@1 97.852 (99.204)	Training Prec@5 0.000 (0.000)	
2022-07-08 13:02:38,864: ============================================================
2022-07-08 13:03:53,060: time cost, forward:0.01148436033715217, backward:0.0340702909692381, data cost:0.6997771512132843 
2022-07-08 13:03:53,061: ============================================================
2022-07-08 13:03:53,061: Epoch 28/36 Batch 3400/7662 eta: 13:30:42.734658	Training Loss1 2.7645 (2.7899)	Training Total_Loss 2.7645 (2.7899)	Training Prec@1 99.219 (99.201)	Training Prec@5 0.000 (0.000)	
2022-07-08 13:03:53,061: ============================================================
2022-07-08 13:05:06,036: time cost, forward:0.011474599562975024, backward:0.03407071283388969, data cost:0.6993268139194032 
2022-07-08 13:05:06,037: ============================================================
2022-07-08 13:05:06,037: Epoch 28/36 Batch 3500/7662 eta: 13:16:09.382984	Training Loss1 2.8696 (2.7920)	Training Total_Loss 2.8696 (2.7920)	Training Prec@1 99.219 (99.201)	Training Prec@5 0.000 (0.000)	
2022-07-08 13:05:06,037: ============================================================
2022-07-08 13:06:20,179: time cost, forward:0.011483212251337279, backward:0.03407041819170469, data cost:0.6992030854555062 
2022-07-08 13:06:20,180: ============================================================
2022-07-08 13:06:20,180: Epoch 28/36 Batch 3600/7662 eta: 13:27:39.110363	Training Loss1 3.1613 (2.7943)	Training Total_Loss 3.1613 (2.7943)	Training Prec@1 98.828 (99.199)	Training Prec@5 0.000 (0.000)	
2022-07-08 13:06:20,180: ============================================================
2022-07-08 13:07:32,348: time cost, forward:0.011494181484233756, backward:0.03406484328788433, data cost:0.6985602078485502 
2022-07-08 13:07:32,349: ============================================================
2022-07-08 13:07:32,349: Epoch 28/36 Batch 3700/7662 eta: 13:04:56.716307	Training Loss1 2.9353 (2.7963)	Training Total_Loss 2.9353 (2.7963)	Training Prec@1 98.633 (99.197)	Training Prec@5 0.000 (0.000)	
2022-07-08 13:07:32,349: ============================================================
2022-07-08 13:08:46,100: time cost, forward:0.011506405024818447, backward:0.034059076567768076, data cost:0.6983650252203403 
2022-07-08 13:08:46,101: ============================================================
2022-07-08 13:08:46,101: Epoch 28/36 Batch 3800/7662 eta: 13:20:56.085160	Training Loss1 2.8760 (2.7982)	Training Total_Loss 2.8760 (2.7982)	Training Prec@1 99.219 (99.195)	Training Prec@5 0.000 (0.000)	
2022-07-08 13:08:46,101: ============================================================
2022-07-08 13:09:59,684: time cost, forward:0.011508862095999394, backward:0.03404000124034896, data cost:0.6981578182030653 
2022-07-08 13:09:59,684: ============================================================
2022-07-08 13:09:59,685: Epoch 28/36 Batch 3900/7662 eta: 13:17:52.835322	Training Loss1 2.8350 (2.8006)	Training Total_Loss 2.8350 (2.8006)	Training Prec@1 99.219 (99.193)	Training Prec@5 0.000 (0.000)	
2022-07-08 13:09:59,685: ============================================================
2022-07-08 13:11:13,464: time cost, forward:0.011503251262473058, backward:0.034042166781204884, data cost:0.6979990893228258 
2022-07-08 13:11:13,464: ============================================================
2022-07-08 13:11:13,464: Epoch 28/36 Batch 4000/7662 eta: 13:18:46.442446	Training Loss1 2.9097 (2.8026)	Training Total_Loss 2.9097 (2.8026)	Training Prec@1 98.633 (99.191)	Training Prec@5 0.000 (0.000)	
2022-07-08 13:11:13,464: ============================================================
2022-07-08 13:12:27,441: time cost, forward:0.011513117378180886, backward:0.0340410613176095, data cost:0.6978836054917108 
2022-07-08 13:12:27,441: ============================================================
2022-07-08 13:12:27,441: Epoch 28/36 Batch 4100/7662 eta: 13:19:40.835829	Training Loss1 2.8540 (2.8048)	Training Total_Loss 2.8540 (2.8048)	Training Prec@1 99.414 (99.189)	Training Prec@5 0.000 (0.000)	
2022-07-08 13:12:27,441: ============================================================
2022-07-08 13:13:40,758: time cost, forward:0.011541526980217254, backward:0.03405560099189978, data cost:0.697580320774359 
2022-07-08 13:13:40,759: ============================================================
2022-07-08 13:13:40,759: Epoch 28/36 Batch 4200/7662 eta: 13:11:20.037484	Training Loss1 2.7097 (2.8071)	Training Total_Loss 2.7097 (2.8071)	Training Prec@1 99.414 (99.186)	Training Prec@5 0.000 (0.000)	
2022-07-08 13:13:40,760: ============================================================
2022-07-08 13:14:54,201: time cost, forward:0.011538949115910234, backward:0.03406791860044044, data cost:0.6973505627973103 
2022-07-08 13:14:54,201: ============================================================
2022-07-08 13:14:54,201: Epoch 28/36 Batch 4300/7662 eta: 13:11:26.870431	Training Loss1 2.9683 (2.8089)	Training Total_Loss 2.9683 (2.8089)	Training Prec@1 99.023 (99.183)	Training Prec@5 0.000 (0.000)	
2022-07-08 13:14:54,201: ============================================================
2022-07-08 13:16:08,057: time cost, forward:0.011551366499484357, backward:0.03407843201288881, data cost:0.6972162535472956 
2022-07-08 13:16:08,057: ============================================================
2022-07-08 13:16:08,057: Epoch 28/36 Batch 4400/7662 eta: 13:14:40.564173	Training Loss1 2.8875 (2.8109)	Training Total_Loss 2.8875 (2.8109)	Training Prec@1 98.242 (99.181)	Training Prec@5 0.000 (0.000)	
2022-07-08 13:16:08,057: ============================================================
2022-07-08 13:17:22,630: time cost, forward:0.011549460249335057, backward:0.03408424752000756, data cost:0.6972635931162126 
2022-07-08 13:17:22,631: ============================================================
2022-07-08 13:17:22,631: Epoch 28/36 Batch 4500/7662 eta: 13:21:09.435740	Training Loss1 3.1318 (2.8127)	Training Total_Loss 3.1318 (2.8127)	Training Prec@1 99.414 (99.178)	Training Prec@5 0.000 (0.000)	
2022-07-08 13:17:22,631: ============================================================
2022-07-08 13:18:36,374: time cost, forward:0.011537611238280957, backward:0.03410996979126388, data cost:0.6971148287480124 
2022-07-08 13:18:36,374: ============================================================
2022-07-08 13:18:36,374: Epoch 28/36 Batch 4600/7662 eta: 13:11:00.712197	Training Loss1 3.2107 (2.8149)	Training Total_Loss 3.2107 (2.8149)	Training Prec@1 98.633 (99.174)	Training Prec@5 0.000 (0.000)	
2022-07-08 13:18:36,375: ============================================================
2022-07-08 13:19:49,933: time cost, forward:0.011540065803130045, backward:0.034119404384647944, data cost:0.6969356613479845 
2022-07-08 13:19:49,933: ============================================================
2022-07-08 13:19:49,933: Epoch 28/36 Batch 4700/7662 eta: 13:07:48.106843	Training Loss1 2.8928 (2.8170)	Training Total_Loss 2.8928 (2.8170)	Training Prec@1 98.828 (99.172)	Training Prec@5 0.000 (0.000)	
2022-07-08 13:19:49,933: ============================================================
2022-07-08 13:21:04,565: time cost, forward:0.011547496155367019, backward:0.03412013492079471, data cost:0.6969911710846843 
2022-07-08 13:21:04,566: ============================================================
2022-07-08 13:21:04,566: Epoch 28/36 Batch 4800/7662 eta: 13:18:03.614622	Training Loss1 2.6561 (2.8192)	Training Total_Loss 2.6561 (2.8192)	Training Prec@1 99.609 (99.170)	Training Prec@5 0.000 (0.000)	
2022-07-08 13:21:04,566: ============================================================
2022-07-08 13:22:17,449: time cost, forward:0.0115455691973563, backward:0.03411626660062187, data cost:0.6967010163219395 
2022-07-08 13:22:17,449: ============================================================
2022-07-08 13:22:17,450: Epoch 28/36 Batch 4900/7662 eta: 12:58:08.496005	Training Loss1 3.1785 (2.8217)	Training Total_Loss 3.1785 (2.8217)	Training Prec@1 98.828 (99.165)	Training Prec@5 0.000 (0.000)	
2022-07-08 13:22:17,450: ============================================================
2022-07-08 13:23:30,502: time cost, forward:0.011546584982279659, backward:0.034106373858466155, data cost:0.6964638623792568 
2022-07-08 13:23:30,503: ============================================================
2022-07-08 13:23:30,503: Epoch 28/36 Batch 5000/7662 eta: 12:58:44.275063	Training Loss1 3.0035 (2.8236)	Training Total_Loss 3.0035 (2.8236)	Training Prec@1 99.414 (99.162)	Training Prec@5 0.000 (0.000)	
2022-07-08 13:23:30,503: ============================================================
2022-07-08 13:24:44,213: time cost, forward:0.011554591069854599, backward:0.034096055742478135, data cost:0.6963531039560231 
2022-07-08 13:24:44,213: ============================================================
2022-07-08 13:24:44,213: Epoch 28/36 Batch 5100/7662 eta: 13:04:30.595750	Training Loss1 2.7544 (2.8262)	Training Total_Loss 2.7544 (2.8262)	Training Prec@1 99.414 (99.159)	Training Prec@5 0.000 (0.000)	
2022-07-08 13:24:44,213: ============================================================
2022-07-08 13:25:57,394: time cost, forward:0.011557747112097339, backward:0.034093942933872266, data cost:0.6961454278484036 
2022-07-08 13:25:57,394: ============================================================
2022-07-08 13:25:57,394: Epoch 28/36 Batch 5200/7662 eta: 12:57:39.355520	Training Loss1 2.9988 (2.8282)	Training Total_Loss 2.9988 (2.8282)	Training Prec@1 99.023 (99.156)	Training Prec@5 0.000 (0.000)	
2022-07-08 13:25:57,394: ============================================================
2022-07-08 13:27:11,312: time cost, forward:0.011546565847906172, backward:0.03409904132453557, data cost:0.6960935733929785 
2022-07-08 13:27:11,312: ============================================================
2022-07-08 13:27:11,313: Epoch 28/36 Batch 5300/7662 eta: 13:04:15.815825	Training Loss1 2.9768 (2.8301)	Training Total_Loss 2.9768 (2.8301)	Training Prec@1 98.242 (99.152)	Training Prec@5 0.000 (0.000)	
2022-07-08 13:27:11,313: ============================================================
2022-07-08 13:28:25,987: time cost, forward:0.011550473910743472, backward:0.03409514163992851, data cost:0.6961753096353525 
2022-07-08 13:28:25,987: ============================================================
2022-07-08 13:28:25,987: Epoch 28/36 Batch 5400/7662 eta: 13:11:02.607755	Training Loss1 2.8120 (2.8319)	Training Total_Loss 2.8120 (2.8319)	Training Prec@1 100.000 (99.150)	Training Prec@5 0.000 (0.000)	
2022-07-08 13:28:25,988: ============================================================
2022-07-08 13:29:39,565: time cost, forward:0.011554220629336726, backward:0.034094899453820264, data cost:0.6960500536625722 
2022-07-08 13:29:39,565: ============================================================
2022-07-08 13:29:39,566: Epoch 28/36 Batch 5500/7662 eta: 12:58:11.967762	Training Loss1 2.9453 (2.8337)	Training Total_Loss 2.9453 (2.8337)	Training Prec@1 99.023 (99.148)	Training Prec@5 0.000 (0.000)	
2022-07-08 13:29:39,566: ============================================================
2022-07-08 13:30:53,263: time cost, forward:0.011535864682000841, backward:0.03410058328989979, data cost:0.6959687450311507 
2022-07-08 13:30:53,263: ============================================================
2022-07-08 13:30:53,263: Epoch 28/36 Batch 5600/7662 eta: 12:58:14.109746	Training Loss1 2.8676 (2.8355)	Training Total_Loss 2.8676 (2.8355)	Training Prec@1 99.414 (99.145)	Training Prec@5 0.000 (0.000)	
2022-07-08 13:30:53,263: ============================================================
2022-07-08 13:32:07,992: time cost, forward:0.01154659793845058, backward:0.03408641040398376, data cost:0.6960630797570077 
2022-07-08 13:32:07,993: ============================================================
2022-07-08 13:32:07,993: Epoch 28/36 Batch 5700/7662 eta: 13:07:53.190847	Training Loss1 2.9733 (2.8370)	Training Total_Loss 2.9733 (2.8370)	Training Prec@1 99.219 (99.142)	Training Prec@5 0.000 (0.000)	
2022-07-08 13:32:07,993: ============================================================
2022-07-08 13:33:21,573: time cost, forward:0.011612660433839449, backward:0.0340695664027083, data cost:0.6959018461826362 
2022-07-08 13:33:21,573: ============================================================
2022-07-08 13:33:21,573: Epoch 28/36 Batch 5800/7662 eta: 12:54:32.513672	Training Loss1 2.7329 (2.8388)	Training Total_Loss 2.7329 (2.8388)	Training Prec@1 99.219 (99.140)	Training Prec@5 0.000 (0.000)	
2022-07-08 13:33:21,573: ============================================================
2022-07-08 13:34:35,426: time cost, forward:0.011616611383712621, backward:0.034077174341421976, data cost:0.6958288161870604 
2022-07-08 13:34:35,426: ============================================================
2022-07-08 13:34:35,427: Epoch 28/36 Batch 5900/7662 eta: 12:56:11.184530	Training Loss1 2.7180 (2.8403)	Training Total_Loss 2.7180 (2.8403)	Training Prec@1 98.828 (99.139)	Training Prec@5 0.000 (0.000)	
2022-07-08 13:34:35,427: ============================================================
2022-07-08 13:35:48,862: time cost, forward:0.01163150561136054, backward:0.034079968323209205, data cost:0.695681935927335 
2022-07-08 13:35:48,863: ============================================================
2022-07-08 13:35:48,863: Epoch 28/36 Batch 6000/7662 eta: 12:50:34.890434	Training Loss1 3.0752 (2.8420)	Training Total_Loss 3.0752 (2.8420)	Training Prec@1 98.438 (99.138)	Training Prec@5 0.000 (0.000)	
2022-07-08 13:35:48,863: ============================================================
2022-07-08 13:37:03,043: time cost, forward:0.01163903180253879, backward:0.034076461168093104, data cost:0.6956750130454015 
2022-07-08 13:37:03,044: ============================================================
2022-07-08 13:37:03,044: Epoch 28/36 Batch 6100/7662 eta: 12:57:09.396121	Training Loss1 2.9006 (2.8438)	Training Total_Loss 2.9006 (2.8438)	Training Prec@1 99.414 (99.135)	Training Prec@5 0.000 (0.000)	
2022-07-08 13:37:03,044: ============================================================
2022-07-08 13:38:17,737: time cost, forward:0.011643768260701662, backward:0.03406547780843834, data cost:0.6957578944436849 
2022-07-08 13:38:17,737: ============================================================
2022-07-08 13:38:17,737: Epoch 28/36 Batch 6200/7662 eta: 13:01:16.767554	Training Loss1 3.0328 (2.8452)	Training Total_Loss 3.0328 (2.8452)	Training Prec@1 98.828 (99.134)	Training Prec@5 0.000 (0.000)	
2022-07-08 13:38:17,737: ============================================================
2022-07-08 13:39:32,290: time cost, forward:0.011632692058761265, backward:0.03406320009596443, data cost:0.6958275911334507 
2022-07-08 13:39:32,290: ============================================================
2022-07-08 13:39:32,291: Epoch 28/36 Batch 6300/7662 eta: 12:58:34.401038	Training Loss1 3.0421 (2.8465)	Training Total_Loss 3.0421 (2.8465)	Training Prec@1 99.023 (99.130)	Training Prec@5 0.000 (0.000)	
2022-07-08 13:39:32,291: ============================================================
2022-07-08 13:40:46,925: time cost, forward:0.011631344236197145, backward:0.034064021813234216, data cost:0.6958974455833286 
2022-07-08 13:40:46,925: ============================================================
2022-07-08 13:40:46,925: Epoch 28/36 Batch 6400/7662 eta: 12:58:10.647733	Training Loss1 2.7588 (2.8482)	Training Total_Loss 2.7588 (2.8482)	Training Prec@1 99.414 (99.128)	Training Prec@5 0.000 (0.000)	
2022-07-08 13:40:46,925: ============================================================
2022-07-08 13:42:00,734: time cost, forward:0.011643915841131508, backward:0.03406888372183837, data cost:0.6958163030001911 
2022-07-08 13:42:00,734: ============================================================
2022-07-08 13:42:00,734: Epoch 28/36 Batch 6500/7662 eta: 12:48:20.470835	Training Loss1 2.7740 (2.8496)	Training Total_Loss 2.7740 (2.8496)	Training Prec@1 99.023 (99.126)	Training Prec@5 0.000 (0.000)	
2022-07-08 13:42:00,734: ============================================================
2022-07-08 13:43:13,872: time cost, forward:0.011640793375037515, backward:0.03407007810798156, data cost:0.6956553929212292 
2022-07-08 13:43:13,873: ============================================================
2022-07-08 13:43:13,873: Epoch 28/36 Batch 6600/7662 eta: 12:40:08.438538	Training Loss1 2.8454 (2.8511)	Training Total_Loss 2.8454 (2.8511)	Training Prec@1 99.609 (99.123)	Training Prec@5 0.000 (0.000)	
2022-07-08 13:43:13,873: ============================================================
2022-07-08 13:44:27,914: time cost, forward:0.011632205123491368, backward:0.034067693299758894, data cost:0.6956441262565917 
2022-07-08 13:44:27,914: ============================================================
2022-07-08 13:44:27,914: Epoch 28/36 Batch 6700/7662 eta: 12:48:17.346285	Training Loss1 3.0755 (2.8529)	Training Total_Loss 3.0755 (2.8529)	Training Prec@1 99.023 (99.119)	Training Prec@5 0.000 (0.000)	
2022-07-08 13:44:27,914: ============================================================
2022-07-08 13:45:41,544: time cost, forward:0.01162520642314944, backward:0.03405615462505006, data cost:0.6955780260596911 
2022-07-08 13:45:41,544: ============================================================
2022-07-08 13:45:41,544: Epoch 28/36 Batch 6800/7662 eta: 12:42:47.672216	Training Loss1 3.0542 (2.8545)	Training Total_Loss 3.0542 (2.8545)	Training Prec@1 98.828 (99.117)	Training Prec@5 0.000 (0.000)	
2022-07-08 13:45:41,544: ============================================================
2022-07-08 13:46:56,923: time cost, forward:0.011630022175019333, backward:0.03404701414411008, data cost:0.6957578854312723 
2022-07-08 13:46:56,923: ============================================================
2022-07-08 13:46:56,923: Epoch 28/36 Batch 6900/7662 eta: 12:59:39.422950	Training Loss1 2.9080 (2.8559)	Training Total_Loss 2.9080 (2.8559)	Training Prec@1 99.414 (99.114)	Training Prec@5 0.000 (0.000)	
2022-07-08 13:46:56,923: ============================================================
2022-07-08 13:48:09,963: time cost, forward:0.011643436129118038, backward:0.03404372922862184, data cost:0.6955776040188533 
2022-07-08 13:48:09,964: ============================================================
2022-07-08 13:48:09,964: Epoch 28/36 Batch 7000/7662 eta: 12:34:15.229381	Training Loss1 2.9497 (2.8571)	Training Total_Loss 2.9497 (2.8571)	Training Prec@1 98.633 (99.112)	Training Prec@5 0.000 (0.000)	
2022-07-08 13:48:09,964: ============================================================
2022-07-08 13:49:23,256: time cost, forward:0.011644124984741211, backward:0.034039947411966656, data cost:0.6954569328937887 
2022-07-08 13:49:23,256: ============================================================
2022-07-08 13:49:23,257: Epoch 28/36 Batch 7100/7662 eta: 12:35:38.307125	Training Loss1 3.1440 (2.8586)	Training Total_Loss 3.1440 (2.8586)	Training Prec@1 97.852 (99.110)	Training Prec@5 0.000 (0.000)	
2022-07-08 13:49:23,257: ============================================================
2022-07-08 13:50:37,916: time cost, forward:0.01163947544158838, backward:0.03404533417626609, data cost:0.6955253808328485 
2022-07-08 13:50:37,916: ============================================================
2022-07-08 13:50:37,916: Epoch 28/36 Batch 7200/7662 eta: 12:48:29.112637	Training Loss1 3.2869 (2.8604)	Training Total_Loss 3.2869 (2.8604)	Training Prec@1 99.023 (99.105)	Training Prec@5 0.000 (0.000)	
2022-07-08 13:50:37,917: ============================================================
2022-07-08 13:51:53,086: time cost, forward:0.01165290361627322, backward:0.034046585224380005, data cost:0.6956449637495993 
2022-07-08 13:51:53,087: ============================================================
2022-07-08 13:51:53,087: Epoch 28/36 Batch 7300/7662 eta: 12:52:29.299530	Training Loss1 3.3505 (2.8621)	Training Total_Loss 3.3505 (2.8621)	Training Prec@1 98.828 (99.101)	Training Prec@5 0.000 (0.000)	
2022-07-08 13:51:53,087: ============================================================
2022-07-08 13:53:06,441: time cost, forward:0.011664094433846998, backward:0.0340431752213273, data cost:0.6955229525212292 
2022-07-08 13:53:06,442: ============================================================
2022-07-08 13:53:06,442: Epoch 28/36 Batch 7400/7662 eta: 12:32:36.559404	Training Loss1 2.9842 (2.8640)	Training Total_Loss 2.9842 (2.8640)	Training Prec@1 99.414 (99.099)	Training Prec@5 0.000 (0.000)	
2022-07-08 13:53:06,442: ============================================================
2022-07-08 13:54:20,722: time cost, forward:0.011661964474495037, backward:0.03404535562423948, data cost:0.6955363527586149 
2022-07-08 13:54:20,723: ============================================================
2022-07-08 13:54:20,723: Epoch 28/36 Batch 7500/7662 eta: 12:40:52.485597	Training Loss1 2.9661 (2.8655)	Training Total_Loss 2.9661 (2.8655)	Training Prec@1 100.000 (99.096)	Training Prec@5 0.000 (0.000)	
2022-07-08 13:54:20,723: ============================================================
2022-07-08 13:55:34,371: time cost, forward:0.011645127698173177, backward:0.034047659454666986, data cost:0.695480499915158 
2022-07-08 13:55:34,372: ============================================================
2022-07-08 13:55:34,372: Epoch 28/36 Batch 7600/7662 eta: 12:33:10.138894	Training Loss1 2.8302 (2.8670)	Training Total_Loss 2.8302 (2.8670)	Training Prec@1 99.609 (99.094)	Training Prec@5 0.000 (0.000)	
2022-07-08 13:55:34,372: ============================================================
2022-07-08 13:56:22,792: Epoch 28/36 Batch 7663/7662 eta: 12:32:23.740179	Training Loss1 2.8164 (2.8679)	Training Total_Loss 2.8164 (2.8679)	Training Prec@1 99.414 (99.092)	Training Prec@5 0.000 (0.000)	
2022-07-08 13:56:22,792: ============================================================
2022-07-08 13:56:22,947: Save Checkpoint...
2022-07-08 13:56:22,952: ============================================================
2022-07-08 13:56:25,835: Save done!
2022-07-08 13:56:25,835: ============================================================
2022-07-08 13:58:09,652: time cost, forward:0.011980203667072335, backward:0.03196683074488784, data cost:0.9984721800293586 
2022-07-08 13:58:09,652: ============================================================
2022-07-08 13:58:09,653: Epoch 29/36 Batch 100/7662 eta: 17:38:21.945608	Training Loss1 2.8663 (2.6820)	Training Total_Loss 2.8663 (2.6820)	Training Prec@1 99.609 (99.333)	Training Prec@5 0.000 (0.000)	
2022-07-08 13:58:09,653: ============================================================
2022-07-08 13:59:21,478: time cost, forward:0.011776921737134157, backward:0.03279038410090921, data cost:0.8346235464565718 
2022-07-08 13:59:21,478: ============================================================
2022-07-08 13:59:21,478: Epoch 29/36 Batch 200/7662 eta: 12:11:23.300323	Training Loss1 2.5216 (2.6906)	Training Total_Loss 2.5216 (2.6906)	Training Prec@1 99.219 (99.326)	Training Prec@5 0.000 (0.000)	
2022-07-08 13:59:21,478: ============================================================
2022-07-08 14:00:34,002: time cost, forward:0.011701624529018849, backward:0.03317857426544495, data cost:0.7826136035664025 
2022-07-08 14:00:34,002: ============================================================
2022-07-08 14:00:34,002: Epoch 29/36 Batch 300/7662 eta: 12:17:17.520663	Training Loss1 2.9123 (2.6897)	Training Total_Loss 2.9123 (2.6897)	Training Prec@1 99.609 (99.322)	Training Prec@5 0.000 (0.000)	
2022-07-08 14:00:34,002: ============================================================
2022-07-08 14:01:47,868: time cost, forward:0.011654553258030635, backward:0.03341106663371686, data cost:0.7600523003360682 
2022-07-08 14:01:47,868: ============================================================
2022-07-08 14:01:47,868: Epoch 29/36 Batch 400/7662 eta: 12:29:42.048182	Training Loss1 2.7568 (2.6945)	Training Total_Loss 2.7568 (2.6945)	Training Prec@1 98.828 (99.317)	Training Prec@5 0.000 (0.000)	
2022-07-08 14:01:47,868: ============================================================
2022-07-08 14:03:00,772: time cost, forward:0.011733954798482464, backward:0.033673475643914784, data cost:0.7442686099088741 
2022-07-08 14:03:00,772: ============================================================
2022-07-08 14:03:00,772: Epoch 29/36 Batch 500/7662 eta: 12:18:43.650303	Training Loss1 2.9804 (2.6962)	Training Total_Loss 2.9804 (2.6962)	Training Prec@1 99.219 (99.303)	Training Prec@5 0.000 (0.000)	
2022-07-08 14:03:00,773: ============================================================
2022-07-08 14:04:14,415: time cost, forward:0.01172825012461769, backward:0.033842693386173406, data cost:0.7351718860396956 
2022-07-08 14:04:14,416: ============================================================
2022-07-08 14:04:14,416: Epoch 29/36 Batch 600/7662 eta: 12:24:59.357335	Training Loss1 2.6658 (2.7015)	Training Total_Loss 2.6658 (2.7015)	Training Prec@1 99.609 (99.291)	Training Prec@5 0.000 (0.000)	
2022-07-08 14:04:14,416: ============================================================
2022-07-08 14:05:27,942: time cost, forward:0.011839830142063473, backward:0.03395218262515525, data cost:0.7283263561210578 
2022-07-08 14:05:27,942: ============================================================
2022-07-08 14:05:27,943: Epoch 29/36 Batch 700/7662 eta: 12:22:34.919366	Training Loss1 2.7145 (2.7030)	Training Total_Loss 2.7145 (2.7030)	Training Prec@1 99.414 (99.289)	Training Prec@5 0.000 (0.000)	
2022-07-08 14:05:27,943: ============================================================
2022-07-08 14:06:40,389: time cost, forward:0.011844174286003257, backward:0.03394414128290398, data cost:0.7220434524836916 
2022-07-08 14:06:40,389: ============================================================
2022-07-08 14:06:40,389: Epoch 29/36 Batch 800/7662 eta: 12:10:28.072513	Training Loss1 2.4629 (2.7087)	Training Total_Loss 2.4629 (2.7087)	Training Prec@1 99.609 (99.287)	Training Prec@5 0.000 (0.000)	
2022-07-08 14:06:40,389: ============================================================
2022-07-08 14:07:54,299: time cost, forward:0.011843549528959994, backward:0.034020579033619304, data cost:0.7186717318745953 
2022-07-08 14:07:54,300: ============================================================
2022-07-08 14:07:54,300: Epoch 29/36 Batch 900/7662 eta: 12:23:59.930632	Training Loss1 2.6158 (2.7132)	Training Total_Loss 2.6158 (2.7132)	Training Prec@1 99.414 (99.279)	Training Prec@5 0.000 (0.000)	
2022-07-08 14:07:54,300: ============================================================
2022-07-08 14:09:07,048: time cost, forward:0.011813558973707594, backward:0.03412497318065441, data cost:0.7148309438913554 
2022-07-08 14:09:07,048: ============================================================
2022-07-08 14:09:07,048: Epoch 29/36 Batch 1000/7662 eta: 12:11:04.879042	Training Loss1 2.7202 (2.7180)	Training Total_Loss 2.7202 (2.7180)	Training Prec@1 99.805 (99.269)	Training Prec@5 0.000 (0.000)	
2022-07-08 14:09:07,048: ============================================================
2022-07-08 14:10:19,626: time cost, forward:0.011830332281374737, backward:0.034174532321933404, data cost:0.7115567622128348 
2022-07-08 14:10:19,626: ============================================================
2022-07-08 14:10:19,627: Epoch 29/36 Batch 1100/7662 eta: 12:08:10.118128	Training Loss1 2.5804 (2.7220)	Training Total_Loss 2.5804 (2.7220)	Training Prec@1 99.023 (99.263)	Training Prec@5 0.000 (0.000)	
2022-07-08 14:10:19,627: ============================================================
2022-07-08 14:11:32,273: time cost, forward:0.011763329899639165, backward:0.034178694652656, data cost:0.7089735250655963 
2022-07-08 14:11:32,273: ============================================================
2022-07-08 14:11:32,273: Epoch 29/36 Batch 1200/7662 eta: 12:07:38.524352	Training Loss1 2.7355 (2.7241)	Training Total_Loss 2.7355 (2.7241)	Training Prec@1 99.023 (99.264)	Training Prec@5 0.000 (0.000)	
2022-07-08 14:11:32,273: ============================================================
2022-07-08 14:12:45,418: time cost, forward:0.011697591131150126, backward:0.03418555032114876, data cost:0.7071867987593841 
2022-07-08 14:12:45,418: ============================================================
2022-07-08 14:12:45,419: Epoch 29/36 Batch 1300/7662 eta: 12:11:24.938526	Training Loss1 2.7755 (2.7262)	Training Total_Loss 2.7755 (2.7262)	Training Prec@1 99.414 (99.262)	Training Prec@5 0.000 (0.000)	
2022-07-08 14:12:45,419: ============================================================
2022-07-08 14:13:57,970: time cost, forward:0.011674414369529958, backward:0.03417957093223152, data cost:0.7051924851385503 
2022-07-08 14:13:57,971: ============================================================
2022-07-08 14:13:57,971: Epoch 29/36 Batch 1400/7662 eta: 12:04:16.553438	Training Loss1 2.8930 (2.7304)	Training Total_Loss 2.8930 (2.7304)	Training Prec@1 98.633 (99.260)	Training Prec@5 0.000 (0.000)	
2022-07-08 14:13:57,971: ============================================================
2022-07-08 14:15:11,354: time cost, forward:0.011640689944012154, backward:0.03417418112827986, data cost:0.7040370697176719 
2022-07-08 14:15:11,354: ============================================================
2022-07-08 14:15:11,354: Epoch 29/36 Batch 1500/7662 eta: 12:11:21.060413	Training Loss1 2.6739 (2.7334)	Training Total_Loss 2.6739 (2.7334)	Training Prec@1 99.609 (99.259)	Training Prec@5 0.000 (0.000)	
2022-07-08 14:15:11,354: ============================================================
2022-07-08 14:16:23,574: time cost, forward:0.011607704645697216, backward:0.034170796678840105, data cost:0.7023097773952138 
2022-07-08 14:16:23,575: ============================================================
2022-07-08 14:16:23,575: Epoch 29/36 Batch 1600/7662 eta: 11:58:33.528385	Training Loss1 2.8352 (2.7361)	Training Total_Loss 2.8352 (2.7361)	Training Prec@1 99.219 (99.259)	Training Prec@5 0.000 (0.000)	
2022-07-08 14:16:23,575: ============================================================
2022-07-08 14:17:37,640: time cost, forward:0.01162659946506763, backward:0.03414396091795725, data cost:0.701828810521755 
2022-07-08 14:17:37,640: ============================================================
2022-07-08 14:17:37,640: Epoch 29/36 Batch 1700/7662 eta: 12:15:40.830399	Training Loss1 2.9347 (2.7386)	Training Total_Loss 2.9347 (2.7386)	Training Prec@1 98.633 (99.257)	Training Prec@5 0.000 (0.000)	
2022-07-08 14:17:37,640: ============================================================
2022-07-08 14:18:50,243: time cost, forward:0.011589244447064571, backward:0.034132001266140216, data cost:0.7006662934935709 
2022-07-08 14:18:50,243: ============================================================
2022-07-08 14:18:50,243: Epoch 29/36 Batch 1800/7662 eta: 11:59:56.399904	Training Loss1 2.6234 (2.7421)	Training Total_Loss 2.6234 (2.7421)	Training Prec@1 99.219 (99.256)	Training Prec@5 0.000 (0.000)	
2022-07-08 14:18:50,243: ============================================================
2022-07-08 14:20:02,432: time cost, forward:0.01156959739592654, backward:0.03415040231617329, data cost:0.6993344619815258 
2022-07-08 14:20:02,432: ============================================================
2022-07-08 14:20:02,433: Epoch 29/36 Batch 1900/7662 eta: 11:54:38.468744	Training Loss1 3.0756 (2.7455)	Training Total_Loss 3.0756 (2.7455)	Training Prec@1 99.609 (99.254)	Training Prec@5 0.000 (0.000)	
2022-07-08 14:20:02,433: ============================================================
2022-07-08 14:21:16,205: time cost, forward:0.011582634817546102, backward:0.034175218612686166, data cost:0.6989183753892861 
2022-07-08 14:21:16,205: ============================================================
2022-07-08 14:21:16,205: Epoch 29/36 Batch 2000/7662 eta: 12:09:05.018885	Training Loss1 2.7585 (2.7487)	Training Total_Loss 2.7585 (2.7487)	Training Prec@1 98.828 (99.247)	Training Prec@5 0.000 (0.000)	
2022-07-08 14:21:16,205: ============================================================
2022-07-08 14:22:28,671: time cost, forward:0.011580838766366086, backward:0.03417543447148295, data cost:0.6979395635585776 
2022-07-08 14:22:28,671: ============================================================
2022-07-08 14:22:28,672: Epoch 29/36 Batch 2100/7662 eta: 11:54:57.905115	Training Loss1 2.7529 (2.7512)	Training Total_Loss 2.7529 (2.7512)	Training Prec@1 99.414 (99.242)	Training Prec@5 0.000 (0.000)	
2022-07-08 14:22:28,672: ============================================================
2022-07-08 14:23:42,382: time cost, forward:0.011608323599870447, backward:0.03422840186930505, data cost:0.6975335648733142 
2022-07-08 14:23:42,383: ============================================================
2022-07-08 14:23:42,383: Epoch 29/36 Batch 2200/7662 eta: 12:06:01.102650	Training Loss1 2.6819 (2.7535)	Training Total_Loss 2.6819 (2.7535)	Training Prec@1 99.609 (99.238)	Training Prec@5 0.000 (0.000)	
2022-07-08 14:23:42,383: ============================================================
2022-07-08 14:24:56,490: time cost, forward:0.011618860704373048, backward:0.034259005389352525, data cost:0.6973670819055624 
2022-07-08 14:24:56,490: ============================================================
2022-07-08 14:24:56,490: Epoch 29/36 Batch 2300/7662 eta: 12:08:41.086338	Training Loss1 2.5525 (2.7558)	Training Total_Loss 2.5525 (2.7558)	Training Prec@1 99.609 (99.239)	Training Prec@5 0.000 (0.000)	
2022-07-08 14:24:56,490: ============================================================
2022-07-08 14:26:09,975: time cost, forward:0.011657758273895506, backward:0.03428593065501154, data cost:0.6969168917642826 
2022-07-08 14:26:09,976: ============================================================
2022-07-08 14:26:09,976: Epoch 29/36 Batch 2400/7662 eta: 12:01:20.952706	Training Loss1 2.6362 (2.7588)	Training Total_Loss 2.6362 (2.7588)	Training Prec@1 99.609 (99.235)	Training Prec@5 0.000 (0.000)	
2022-07-08 14:26:09,976: ============================================================
2022-07-08 14:27:23,934: time cost, forward:0.011659664266249713, backward:0.0342974736243069, data cost:0.6967582639669027 
2022-07-08 14:27:23,934: ============================================================
2022-07-08 14:27:23,934: Epoch 29/36 Batch 2500/7662 eta: 12:04:45.341342	Training Loss1 2.8969 (2.7617)	Training Total_Loss 2.8969 (2.7617)	Training Prec@1 98.438 (99.232)	Training Prec@5 0.000 (0.000)	
2022-07-08 14:27:23,935: ============================================================
2022-07-08 14:28:37,778: time cost, forward:0.01165346725026476, backward:0.03427812052305133, data cost:0.6965903261616947 
2022-07-08 14:28:37,778: ============================================================
2022-07-08 14:28:37,778: Epoch 29/36 Batch 2600/7662 eta: 12:02:24.056561	Training Loss1 2.5835 (2.7640)	Training Total_Loss 2.5835 (2.7640)	Training Prec@1 99.609 (99.229)	Training Prec@5 0.000 (0.000)	
2022-07-08 14:28:37,778: ============================================================
2022-07-08 14:29:52,465: time cost, forward:0.011677401116177875, backward:0.034282888293752145, data cost:0.6966964521863894 
2022-07-08 14:29:52,465: ============================================================
2022-07-08 14:29:52,466: Epoch 29/36 Batch 2700/7662 eta: 12:09:24.572345	Training Loss1 3.0678 (2.7668)	Training Total_Loss 3.0678 (2.7668)	Training Prec@1 98.633 (99.226)	Training Prec@5 0.000 (0.000)	
2022-07-08 14:29:52,466: ============================================================
2022-07-08 14:31:05,036: time cost, forward:0.011732010809001261, backward:0.034297584592976625, data cost:0.6960054661981461 
2022-07-08 14:31:05,037: ============================================================
2022-07-08 14:31:05,037: Epoch 29/36 Batch 2800/7662 eta: 11:47:31.953603	Training Loss1 2.8854 (2.7693)	Training Total_Loss 2.8854 (2.7693)	Training Prec@1 99.023 (99.223)	Training Prec@5 0.000 (0.000)	
2022-07-08 14:31:05,037: ============================================================
2022-07-08 14:32:19,174: time cost, forward:0.011742153098641612, backward:0.03430234329089414, data cost:0.6959422869121424 
2022-07-08 14:32:19,175: ============================================================
2022-07-08 14:32:19,175: Epoch 29/36 Batch 2900/7662 eta: 12:01:34.478276	Training Loss1 3.0848 (2.7715)	Training Total_Loss 3.0848 (2.7715)	Training Prec@1 99.219 (99.222)	Training Prec@5 0.000 (0.000)	
2022-07-08 14:32:19,175: ============================================================
2022-07-08 14:33:31,770: time cost, forward:0.011734542309264018, backward:0.0343006767802097, data cost:0.6953936938088351 
2022-07-08 14:33:31,771: ============================================================
2022-07-08 14:33:31,771: Epoch 29/36 Batch 3000/7662 eta: 11:45:21.178068	Training Loss1 2.7415 (2.7738)	Training Total_Loss 2.7415 (2.7738)	Training Prec@1 99.414 (99.218)	Training Prec@5 0.000 (0.000)	
2022-07-08 14:33:31,771: ============================================================
2022-07-08 14:34:45,259: time cost, forward:0.011751256399902462, backward:0.03431741835110108, data cost:0.6951320452934775 
2022-07-08 14:34:45,259: ============================================================
2022-07-08 14:34:45,259: Epoch 29/36 Batch 3100/7662 eta: 11:52:48.152781	Training Loss1 2.9295 (2.7764)	Training Total_Loss 2.9295 (2.7764)	Training Prec@1 99.219 (99.214)	Training Prec@5 0.000 (0.000)	
2022-07-08 14:34:45,260: ============================================================
2022-07-08 14:35:59,515: time cost, forward:0.011759331689174564, backward:0.03432282569744543, data cost:0.6951411163929888 
2022-07-08 14:35:59,516: ============================================================
2022-07-08 14:35:59,516: Epoch 29/36 Batch 3200/7662 eta: 11:59:00.855461	Training Loss1 2.8695 (2.7794)	Training Total_Loss 2.8695 (2.7794)	Training Prec@1 99.023 (99.210)	Training Prec@5 0.000 (0.000)	
2022-07-08 14:35:59,516: ============================================================
2022-07-08 14:37:13,325: time cost, forward:0.011745908181571209, backward:0.03432675808550698, data cost:0.695028657152928 
2022-07-08 14:37:13,325: ============================================================
2022-07-08 14:37:13,326: Epoch 29/36 Batch 3300/7662 eta: 11:53:27.400101	Training Loss1 2.8228 (2.7820)	Training Total_Loss 2.8228 (2.7820)	Training Prec@1 99.023 (99.206)	Training Prec@5 0.000 (0.000)	
2022-07-08 14:37:13,326: ============================================================
2022-07-08 14:38:26,880: time cost, forward:0.011753284359511364, backward:0.03432978451620238, data cost:0.6948519635460032 
2022-07-08 14:38:26,880: ============================================================
2022-07-08 14:38:26,880: Epoch 29/36 Batch 3400/7662 eta: 11:49:45.866869	Training Loss1 2.8966 (2.7846)	Training Total_Loss 2.8966 (2.7846)	Training Prec@1 99.609 (99.203)	Training Prec@5 0.000 (0.000)	
2022-07-08 14:38:26,880: ============================================================
2022-07-08 14:39:41,532: time cost, forward:0.011737509433389835, backward:0.034369368592682276, data cost:0.6949705606734763 
2022-07-08 14:39:41,532: ============================================================
2022-07-08 14:39:41,532: Epoch 29/36 Batch 3500/7662 eta: 11:59:06.743324	Training Loss1 2.7581 (2.7873)	Training Total_Loss 2.7581 (2.7873)	Training Prec@1 99.023 (99.200)	Training Prec@5 0.000 (0.000)	
2022-07-08 14:39:41,533: ============================================================
2022-07-08 14:40:55,885: time cost, forward:0.011742074345840153, backward:0.03437141710998416, data cost:0.6950112514676038 
2022-07-08 14:40:55,886: ============================================================
2022-07-08 14:40:55,886: Epoch 29/36 Batch 3600/7662 eta: 11:54:59.712832	Training Loss1 2.8688 (2.7893)	Training Total_Loss 2.8688 (2.7893)	Training Prec@1 99.023 (99.197)	Training Prec@5 0.000 (0.000)	
2022-07-08 14:40:55,886: ============================================================
2022-07-08 14:42:08,793: time cost, forward:0.01174318497166114, backward:0.03437451357195654, data cost:0.6946647698313972 
2022-07-08 14:42:08,793: ============================================================
2022-07-08 14:42:08,793: Epoch 29/36 Batch 3700/7662 eta: 11:39:52.458775	Training Loss1 2.6732 (2.7928)	Training Total_Loss 2.6732 (2.7928)	Training Prec@1 100.000 (99.193)	Training Prec@5 0.000 (0.000)	
2022-07-08 14:42:08,793: ============================================================
2022-07-08 14:43:21,584: time cost, forward:0.011729259558745703, backward:0.03435963641721721, data cost:0.6943434438256095 
2022-07-08 14:43:21,585: ============================================================
2022-07-08 14:43:21,585: Epoch 29/36 Batch 3800/7662 eta: 11:37:33.048344	Training Loss1 3.0362 (2.7946)	Training Total_Loss 3.0362 (2.7946)	Training Prec@1 98.633 (99.191)	Training Prec@5 0.000 (0.000)	
2022-07-08 14:43:21,585: ============================================================
2022-07-08 14:44:36,040: time cost, forward:0.011713963100377582, backward:0.03434661964050591, data cost:0.6944570442932513 
2022-07-08 14:44:36,040: ============================================================
2022-07-08 14:44:36,040: Epoch 29/36 Batch 3900/7662 eta: 11:52:15.061930	Training Loss1 2.6848 (2.7965)	Training Total_Loss 2.6848 (2.7965)	Training Prec@1 99.219 (99.189)	Training Prec@5 0.000 (0.000)	
2022-07-08 14:44:36,040: ============================================================
2022-07-08 14:45:49,457: time cost, forward:0.011699973240170547, backward:0.03435078016606889, data cost:0.6942999520937363 
2022-07-08 14:45:49,457: ============================================================
2022-07-08 14:45:49,457: Epoch 29/36 Batch 4000/7662 eta: 11:41:05.612844	Training Loss1 3.0238 (2.7990)	Training Total_Loss 3.0238 (2.7990)	Training Prec@1 98.828 (99.187)	Training Prec@5 0.000 (0.000)	
2022-07-08 14:45:49,457: ============================================================
2022-07-08 14:47:04,069: time cost, forward:0.011708218983307964, backward:0.03435215359055202, data cost:0.6944130329016681 
2022-07-08 14:47:04,069: ============================================================
2022-07-08 14:47:04,069: Epoch 29/36 Batch 4100/7662 eta: 11:51:16.099870	Training Loss1 2.9162 (2.8016)	Training Total_Loss 2.9162 (2.8016)	Training Prec@1 99.414 (99.185)	Training Prec@5 0.000 (0.000)	
2022-07-08 14:47:04,069: ============================================================
2022-07-08 14:48:17,795: time cost, forward:0.011708021220720278, backward:0.034346229151675574, data cost:0.6943299733448324 
2022-07-08 14:48:17,796: ============================================================
2022-07-08 14:48:17,796: Epoch 29/36 Batch 4200/7662 eta: 11:41:35.617955	Training Loss1 2.9275 (2.8041)	Training Total_Loss 2.9275 (2.8041)	Training Prec@1 99.023 (99.182)	Training Prec@5 0.000 (0.000)	
2022-07-08 14:48:17,796: ============================================================
2022-07-08 14:49:30,869: time cost, forward:0.011736307346036085, backward:0.0343383751683081, data cost:0.6940306622806219 
2022-07-08 14:49:30,869: ============================================================
2022-07-08 14:49:30,870: Epoch 29/36 Batch 4300/7662 eta: 11:34:09.810646	Training Loss1 2.7828 (2.8068)	Training Total_Loss 2.7828 (2.8068)	Training Prec@1 99.023 (99.177)	Training Prec@5 0.000 (0.000)	
2022-07-08 14:49:30,870: ============================================================
2022-07-08 14:50:44,155: time cost, forward:0.011749792868615714, backward:0.034325603301700175, data cost:0.6938942535055256 
2022-07-08 14:50:44,156: ============================================================
2022-07-08 14:50:44,156: Epoch 29/36 Batch 4400/7662 eta: 11:34:57.577887	Training Loss1 3.1941 (2.8086)	Training Total_Loss 3.1941 (2.8086)	Training Prec@1 99.414 (99.175)	Training Prec@5 0.000 (0.000)	
2022-07-08 14:50:44,156: ============================================================
2022-07-08 14:51:58,172: time cost, forward:0.011768109959002255, backward:0.03433755854284215, data cost:0.6938433236984657 
2022-07-08 14:51:58,172: ============================================================
2022-07-08 14:51:58,172: Epoch 29/36 Batch 4500/7662 eta: 11:40:39.049400	Training Loss1 2.9217 (2.8104)	Training Total_Loss 2.9217 (2.8104)	Training Prec@1 99.414 (99.174)	Training Prec@5 0.000 (0.000)	
2022-07-08 14:51:58,172: ============================================================
2022-07-08 14:53:11,800: time cost, forward:0.01177634760513853, backward:0.03435943317973217, data cost:0.6937299015781728 
2022-07-08 14:53:11,800: ============================================================
2022-07-08 14:53:11,800: Epoch 29/36 Batch 4600/7662 eta: 11:35:44.918539	Training Loss1 2.8195 (2.8125)	Training Total_Loss 2.8195 (2.8125)	Training Prec@1 99.805 (99.170)	Training Prec@5 0.000 (0.000)	
2022-07-08 14:53:11,800: ============================================================
2022-07-08 14:54:26,284: time cost, forward:0.011767039224933528, backward:0.03436187521704564, data cost:0.693826510516043 
2022-07-08 14:54:26,284: ============================================================
2022-07-08 14:54:26,284: Epoch 29/36 Batch 4700/7662 eta: 11:42:35.663718	Training Loss1 2.8120 (2.8146)	Training Total_Loss 2.8120 (2.8146)	Training Prec@1 99.609 (99.167)	Training Prec@5 0.000 (0.000)	
2022-07-08 14:54:26,284: ============================================================
2022-07-08 14:55:40,959: time cost, forward:0.011755442167227655, backward:0.03437355777377212, data cost:0.6939582595181331 
2022-07-08 14:55:40,960: ============================================================
2022-07-08 14:55:40,960: Epoch 29/36 Batch 4800/7662 eta: 11:43:09.500836	Training Loss1 2.8370 (2.8167)	Training Total_Loss 2.8370 (2.8167)	Training Prec@1 99.023 (99.164)	Training Prec@5 0.000 (0.000)	
2022-07-08 14:55:40,960: ============================================================
2022-07-08 14:56:53,771: time cost, forward:0.011750883850717476, backward:0.03436282893350402, data cost:0.6937152497937276 
2022-07-08 14:56:53,771: ============================================================
2022-07-08 14:56:53,772: Epoch 29/36 Batch 4900/7662 eta: 11:24:23.663452	Training Loss1 3.0769 (2.8188)	Training Total_Loss 3.0769 (2.8188)	Training Prec@1 98.828 (99.161)	Training Prec@5 0.000 (0.000)	
2022-07-08 14:56:53,772: ============================================================
2022-07-08 14:58:06,300: time cost, forward:0.011738683157239969, backward:0.034349076961083136, data cost:0.6934427569737123 
2022-07-08 14:58:06,301: ============================================================
2022-07-08 14:58:06,301: Epoch 29/36 Batch 5000/7662 eta: 11:20:31.782827	Training Loss1 2.9705 (2.8202)	Training Total_Loss 2.9705 (2.8202)	Training Prec@1 98.633 (99.160)	Training Prec@5 0.000 (0.000)	
2022-07-08 14:58:06,301: ============================================================
2022-07-08 14:59:21,125: time cost, forward:0.011745789210500379, backward:0.03434600959129955, data cost:0.6936006618962847 
2022-07-08 14:59:21,126: ============================================================
2022-07-08 14:59:21,126: Epoch 29/36 Batch 5100/7662 eta: 11:40:49.455253	Training Loss1 2.8409 (2.8217)	Training Total_Loss 2.8409 (2.8217)	Training Prec@1 99.609 (99.158)	Training Prec@5 0.000 (0.000)	
2022-07-08 14:59:21,126: ============================================================
2022-07-08 15:00:34,868: time cost, forward:0.011768872014695255, backward:0.034350464586616364, data cost:0.6935174314763414 
2022-07-08 15:00:34,868: ============================================================
2022-07-08 15:00:34,868: Epoch 29/36 Batch 5200/7662 eta: 11:29:27.231692	Training Loss1 2.9501 (2.8235)	Training Total_Loss 2.9501 (2.8235)	Training Prec@1 99.219 (99.157)	Training Prec@5 0.000 (0.000)	
2022-07-08 15:00:34,868: ============================================================
2022-07-08 15:01:47,897: time cost, forward:0.011765533088400445, backward:0.03433869402011311, data cost:0.6933440406674776 
2022-07-08 15:01:47,897: ============================================================
2022-07-08 15:01:47,898: Epoch 29/36 Batch 5300/7662 eta: 11:21:34.303085	Training Loss1 3.0654 (2.8256)	Training Total_Loss 3.0654 (2.8256)	Training Prec@1 99.023 (99.153)	Training Prec@5 0.000 (0.000)	
2022-07-08 15:01:47,898: ============================================================
2022-07-08 15:03:02,608: time cost, forward:0.01177172065553985, backward:0.03432918199898469, data cost:0.6934788709305949 
2022-07-08 15:03:02,609: ============================================================
2022-07-08 15:03:02,609: Epoch 29/36 Batch 5400/7662 eta: 11:36:01.274285	Training Loss1 3.0280 (2.8272)	Training Total_Loss 3.0280 (2.8272)	Training Prec@1 98.242 (99.151)	Training Prec@5 0.000 (0.000)	
2022-07-08 15:03:02,609: ============================================================
2022-07-08 15:04:17,011: time cost, forward:0.01176066844327642, backward:0.03433088051837062, data cost:0.6935590524460147 
2022-07-08 15:04:17,011: ============================================================
2022-07-08 15:04:17,012: Epoch 29/36 Batch 5500/7662 eta: 11:31:54.613506	Training Loss1 2.9882 (2.8292)	Training Total_Loss 2.9882 (2.8292)	Training Prec@1 98.828 (99.148)	Training Prec@5 0.000 (0.000)	
2022-07-08 15:04:17,012: ============================================================
2022-07-08 15:05:30,554: time cost, forward:0.011748698805672588, backward:0.03432520195125874, data cost:0.6934902574318097 
2022-07-08 15:05:30,555: ============================================================
2022-07-08 15:05:30,555: Epoch 29/36 Batch 5600/7662 eta: 11:22:41.428617	Training Loss1 3.1503 (2.8315)	Training Total_Loss 3.1503 (2.8315)	Training Prec@1 98.828 (99.145)	Training Prec@5 0.000 (0.000)	
2022-07-08 15:05:30,555: ============================================================
2022-07-08 15:06:44,273: time cost, forward:0.011744979976206249, backward:0.034317125456649854, data cost:0.6934503692768189 
2022-07-08 15:06:44,273: ============================================================
2022-07-08 15:06:44,273: Epoch 29/36 Batch 5700/7662 eta: 11:23:05.049578	Training Loss1 2.8969 (2.8331)	Training Total_Loss 2.8969 (2.8331)	Training Prec@1 98.828 (99.142)	Training Prec@5 0.000 (0.000)	
2022-07-08 15:06:44,273: ============================================================
2022-07-08 15:07:59,225: time cost, forward:0.011735241707901972, backward:0.0343283946646927, data cost:0.6936117340560863 
2022-07-08 15:07:59,225: ============================================================
2022-07-08 15:07:59,225: Epoch 29/36 Batch 5800/7662 eta: 11:33:16.159416	Training Loss1 3.1045 (2.8349)	Training Total_Loss 3.1045 (2.8349)	Training Prec@1 99.023 (99.140)	Training Prec@5 0.000 (0.000)	
2022-07-08 15:07:59,225: ============================================================
2022-07-08 15:09:12,623: time cost, forward:0.011735386799141236, backward:0.034334338545940715, data cost:0.6934997469191835 
2022-07-08 15:09:12,623: ============================================================
2022-07-08 15:09:12,623: Epoch 29/36 Batch 5900/7662 eta: 11:17:40.251627	Training Loss1 3.0532 (2.8366)	Training Total_Loss 3.0532 (2.8366)	Training Prec@1 97.852 (99.138)	Training Prec@5 0.000 (0.000)	
2022-07-08 15:09:12,623: ============================================================
2022-07-08 15:10:28,126: time cost, forward:0.0117349763734477, backward:0.03434783165644439, data cost:0.6937338689462923 
2022-07-08 15:10:28,126: ============================================================
2022-07-08 15:10:28,127: Epoch 29/36 Batch 6000/7662 eta: 11:35:51.123188	Training Loss1 2.8333 (2.8383)	Training Total_Loss 2.8333 (2.8383)	Training Prec@1 99.219 (99.136)	Training Prec@5 0.000 (0.000)	
2022-07-08 15:10:28,127: ============================================================
2022-07-08 15:11:41,064: time cost, forward:0.01172108285875472, backward:0.034338611719119276, data cost:0.6935764443856768 
2022-07-08 15:11:41,064: ============================================================
2022-07-08 15:11:41,064: Epoch 29/36 Batch 6100/7662 eta: 11:10:59.357277	Training Loss1 2.8422 (2.8397)	Training Total_Loss 2.8422 (2.8397)	Training Prec@1 99.219 (99.134)	Training Prec@5 0.000 (0.000)	
2022-07-08 15:11:41,064: ============================================================
2022-07-08 15:12:54,116: time cost, forward:0.011719470563329483, backward:0.03432222981090641, data cost:0.6934379958629531 
2022-07-08 15:12:54,117: ============================================================
2022-07-08 15:12:54,117: Epoch 29/36 Batch 6200/7662 eta: 11:10:49.782432	Training Loss1 2.9160 (2.8414)	Training Total_Loss 2.9160 (2.8414)	Training Prec@1 99.219 (99.132)	Training Prec@5 0.000 (0.000)	
2022-07-08 15:12:54,117: ============================================================
2022-07-08 15:14:08,142: time cost, forward:0.011728559908251437, backward:0.03431669797835264, data cost:0.6934368322341854 
2022-07-08 15:14:08,143: ============================================================
2022-07-08 15:14:08,143: Epoch 29/36 Batch 6300/7662 eta: 11:18:32.284702	Training Loss1 2.8616 (2.8427)	Training Total_Loss 2.8616 (2.8427)	Training Prec@1 99.414 (99.130)	Training Prec@5 0.000 (0.000)	
2022-07-08 15:14:08,143: ============================================================
2022-07-08 15:15:21,782: time cost, forward:0.011739963962801137, backward:0.03431232557909286, data cost:0.693372925178467 
2022-07-08 15:15:21,782: ============================================================
2022-07-08 15:15:21,782: Epoch 29/36 Batch 6400/7662 eta: 11:13:45.548265	Training Loss1 3.1005 (2.8443)	Training Total_Loss 3.1005 (2.8443)	Training Prec@1 98.633 (99.126)	Training Prec@5 0.000 (0.000)	
2022-07-08 15:15:21,782: ============================================================
2022-07-08 15:16:35,792: time cost, forward:0.011749951064283984, backward:0.03430169309940975, data cost:0.6933697210603319 
2022-07-08 15:16:35,792: ============================================================
2022-07-08 15:16:35,792: Epoch 29/36 Batch 6500/7662 eta: 11:15:55.352192	Training Loss1 2.7740 (2.8460)	Training Total_Loss 2.7740 (2.8460)	Training Prec@1 99.414 (99.124)	Training Prec@5 0.000 (0.000)	
2022-07-08 15:16:35,792: ============================================================
2022-07-08 15:17:50,040: time cost, forward:0.011754113881041342, backward:0.03428639880020089, data cost:0.6934216176764426 
2022-07-08 15:17:50,041: ============================================================
2022-07-08 15:17:50,041: Epoch 29/36 Batch 6600/7662 eta: 11:16:52.019908	Training Loss1 2.9154 (2.8476)	Training Total_Loss 2.9154 (2.8476)	Training Prec@1 99.609 (99.123)	Training Prec@5 0.000 (0.000)	
2022-07-08 15:17:50,042: ============================================================
2022-07-08 15:19:03,634: time cost, forward:0.011768354837850664, backward:0.034280797299528716, data cost:0.6933517233971999 
2022-07-08 15:19:03,635: ============================================================
2022-07-08 15:19:03,635: Epoch 29/36 Batch 6700/7662 eta: 11:09:39.885315	Training Loss1 2.9607 (2.8485)	Training Total_Loss 2.9607 (2.8485)	Training Prec@1 99.219 (99.121)	Training Prec@5 0.000 (0.000)	
2022-07-08 15:19:03,635: ============================================================
2022-07-08 15:20:18,021: time cost, forward:0.01176828211730921, backward:0.03428858819297525, data cost:0.6934014603151506 
2022-07-08 15:20:18,022: ============================================================
2022-07-08 15:20:18,022: Epoch 29/36 Batch 6800/7662 eta: 11:15:38.697078	Training Loss1 3.0269 (2.8502)	Training Total_Loss 3.0269 (2.8502)	Training Prec@1 98.828 (99.119)	Training Prec@5 0.000 (0.000)	
2022-07-08 15:20:18,022: ============================================================
2022-07-08 15:21:32,079: time cost, forward:0.01177600601960445, backward:0.03427866760034944, data cost:0.6934124133710948 
2022-07-08 15:21:32,079: ============================================================
2022-07-08 15:21:32,079: Epoch 29/36 Batch 6900/7662 eta: 11:11:24.939803	Training Loss1 2.9519 (2.8517)	Training Total_Loss 2.9519 (2.8517)	Training Prec@1 99.219 (99.117)	Training Prec@5 0.000 (0.000)	
2022-07-08 15:21:32,079: ============================================================
2022-07-08 15:22:46,334: time cost, forward:0.011777046391377706, backward:0.034274723925306415, data cost:0.6934503283325579 
2022-07-08 15:22:46,335: ============================================================
2022-07-08 15:22:46,335: Epoch 29/36 Batch 7000/7662 eta: 11:11:58.522988	Training Loss1 2.9999 (2.8533)	Training Total_Loss 2.9999 (2.8533)	Training Prec@1 98.828 (99.114)	Training Prec@5 0.000 (0.000)	
2022-07-08 15:22:46,335: ============================================================
2022-07-08 15:24:00,490: time cost, forward:0.01178401986517223, backward:0.03427452304897585, data cost:0.6934634195715462 
2022-07-08 15:24:00,491: ============================================================
2022-07-08 15:24:00,491: Epoch 29/36 Batch 7100/7662 eta: 11:09:50.585697	Training Loss1 2.9736 (2.8551)	Training Total_Loss 2.9736 (2.8551)	Training Prec@1 98.828 (99.112)	Training Prec@5 0.000 (0.000)	
2022-07-08 15:24:00,491: ============================================================
2022-07-08 15:25:15,880: time cost, forward:0.011789090005138348, backward:0.0342782665117033, data cost:0.6936455590308648 
2022-07-08 15:25:15,880: ============================================================
2022-07-08 15:25:15,881: Epoch 29/36 Batch 7200/7662 eta: 11:19:43.433902	Training Loss1 3.0269 (2.8568)	Training Total_Loss 3.0269 (2.8568)	Training Prec@1 99.023 (99.109)	Training Prec@5 0.000 (0.000)	
2022-07-08 15:25:15,881: ============================================================
2022-07-08 15:26:31,220: time cost, forward:0.011793718744359746, backward:0.03429125125872989, data cost:0.6938061700779896 
2022-07-08 15:26:31,220: ============================================================
2022-07-08 15:26:31,221: Epoch 29/36 Batch 7300/7662 eta: 11:18:01.234831	Training Loss1 2.9662 (2.8582)	Training Total_Loss 2.9662 (2.8582)	Training Prec@1 99.023 (99.107)	Training Prec@5 0.000 (0.000)	
2022-07-08 15:26:31,221: ============================================================
2022-07-08 15:27:46,158: time cost, forward:0.0118032163632111, backward:0.03428988425147454, data cost:0.6939168821590819 
2022-07-08 15:27:46,158: ============================================================
2022-07-08 15:27:46,159: Epoch 29/36 Batch 7400/7662 eta: 11:13:09.390124	Training Loss1 2.9934 (2.8599)	Training Total_Loss 2.9934 (2.8599)	Training Prec@1 99.414 (99.104)	Training Prec@5 0.000 (0.000)	
2022-07-08 15:27:46,159: ============================================================
2022-07-08 15:29:01,861: time cost, forward:0.011801288070353147, backward:0.0342900695475217, data cost:0.6941389001390269 
2022-07-08 15:29:01,862: ============================================================
2022-07-08 15:29:01,862: Epoch 29/36 Batch 7500/7662 eta: 11:18:46.129953	Training Loss1 3.1784 (2.8615)	Training Total_Loss 3.1784 (2.8615)	Training Prec@1 99.023 (99.102)	Training Prec@5 0.000 (0.000)	
2022-07-08 15:29:01,862: ============================================================
2022-07-08 15:30:15,732: time cost, forward:0.011808042009185216, backward:0.03428848462130525, data cost:0.6941046407621524 
2022-07-08 15:30:15,733: ============================================================
2022-07-08 15:30:15,733: Epoch 29/36 Batch 7600/7662 eta: 11:01:06.454823	Training Loss1 3.0510 (2.8631)	Training Total_Loss 3.0510 (2.8631)	Training Prec@1 99.414 (99.100)	Training Prec@5 0.000 (0.000)	
2022-07-08 15:30:15,733: ============================================================
2022-07-08 15:31:02,218: Epoch 29/36 Batch 7663/7662 eta: 11:00:19.916159	Training Loss1 2.8808 (2.8641)	Training Total_Loss 2.8808 (2.8641)	Training Prec@1 99.805 (99.098)	Training Prec@5 0.000 (0.000)	
2022-07-08 15:31:02,219: ============================================================
2022-07-08 15:31:02,415: Save Checkpoint...
2022-07-08 15:31:02,428: ============================================================
2022-07-08 15:31:05,068: Save done!
2022-07-08 15:31:05,068: ============================================================
2022-07-08 15:32:52,771: time cost, forward:0.010739952626854482, backward:0.03357717485138864, data cost:1.0368136805717392 
2022-07-08 15:32:52,771: ============================================================
2022-07-08 15:32:52,772: Epoch 30/36 Batch 100/7662 eta: 16:00:18.294213	Training Loss1 2.6569 (2.6322)	Training Total_Loss 2.6569 (2.6322)	Training Prec@1 98.828 (99.335)	Training Prec@5 0.000 (0.000)	
2022-07-08 15:32:52,772: ============================================================
2022-07-08 15:34:08,745: time cost, forward:0.0107393779946332, backward:0.033711621509724524, data cost:0.875121805536088 
2022-07-08 15:34:08,745: ============================================================
2022-07-08 15:34:08,746: Epoch 30/36 Batch 200/7662 eta: 11:16:36.611339	Training Loss1 2.5325 (2.6152)	Training Total_Loss 2.5325 (2.6152)	Training Prec@1 99.805 (99.334)	Training Prec@5 0.000 (0.000)	
2022-07-08 15:34:08,746: ============================================================
2022-07-08 15:35:23,916: time cost, forward:0.010657575218175168, backward:0.03386088996427913, data cost:0.8187235868894137 
2022-07-08 15:35:23,917: ============================================================
2022-07-08 15:35:23,917: Epoch 30/36 Batch 300/7662 eta: 11:08:12.611676	Training Loss1 2.6907 (2.6104)	Training Total_Loss 2.6907 (2.6104)	Training Prec@1 99.219 (99.359)	Training Prec@5 0.000 (0.000)	
2022-07-08 15:35:23,917: ============================================================
2022-07-08 15:36:39,259: time cost, forward:0.010728751806388223, backward:0.03403135827908241, data cost:0.7908129811585697 
2022-07-08 15:36:39,259: ============================================================
2022-07-08 15:36:39,260: Epoch 30/36 Batch 400/7662 eta: 11:08:28.786362	Training Loss1 2.7359 (2.6089)	Training Total_Loss 2.7359 (2.6089)	Training Prec@1 99.414 (99.365)	Training Prec@5 0.000 (0.000)	
2022-07-08 15:36:39,260: ============================================================
2022-07-08 15:37:53,446: time cost, forward:0.011041573388781959, backward:0.03429205049732644, data cost:0.771336607560366 
2022-07-08 15:37:53,447: ============================================================
2022-07-08 15:37:53,447: Epoch 30/36 Batch 500/7662 eta: 10:56:59.364830	Training Loss1 3.0433 (2.6083)	Training Total_Loss 3.0433 (2.6083)	Training Prec@1 98.633 (99.363)	Training Prec@5 0.000 (0.000)	
2022-07-08 15:37:53,447: ============================================================
2022-07-08 15:39:07,526: time cost, forward:0.011141589169510219, backward:0.03432098254934575, data cost:0.7583911888587455 
2022-07-08 15:39:07,526: ============================================================
2022-07-08 15:39:07,526: Epoch 30/36 Batch 600/7662 eta: 10:54:47.948118	Training Loss1 2.5460 (2.6080)	Training Total_Loss 2.5460 (2.6080)	Training Prec@1 99.414 (99.363)	Training Prec@5 0.000 (0.000)	
2022-07-08 15:39:07,526: ============================================================
2022-07-08 15:40:22,076: time cost, forward:0.011264317025442491, backward:0.03439592564736995, data cost:0.7498082074314057 
2022-07-08 15:40:22,076: ============================================================
2022-07-08 15:40:22,076: Epoch 30/36 Batch 700/7662 eta: 10:57:43.121859	Training Loss1 2.8732 (2.6059)	Training Total_Loss 2.8732 (2.6059)	Training Prec@1 99.219 (99.360)	Training Prec@5 0.000 (0.000)	
2022-07-08 15:40:22,076: ============================================================
2022-07-08 15:41:35,642: time cost, forward:0.011292095029160138, backward:0.034471324746390905, data cost:0.7421462840222298 
2022-07-08 15:41:35,642: ============================================================
2022-07-08 15:41:35,642: Epoch 30/36 Batch 800/7662 eta: 10:47:48.592313	Training Loss1 2.6584 (2.6034)	Training Total_Loss 2.6584 (2.6034)	Training Prec@1 98.828 (99.360)	Training Prec@5 0.000 (0.000)	
2022-07-08 15:41:35,642: ============================================================
2022-07-08 15:42:48,321: time cost, forward:0.011265880406499573, backward:0.03445831978811703, data cost:0.7352920817055877 
2022-07-08 15:42:48,322: ============================================================
2022-07-08 15:42:48,322: Epoch 30/36 Batch 900/7662 eta: 10:38:47.678214	Training Loss1 2.6753 (2.6013)	Training Total_Loss 2.6753 (2.6013)	Training Prec@1 99.219 (99.366)	Training Prec@5 0.000 (0.000)	
2022-07-08 15:42:48,322: ============================================================
2022-07-08 15:44:00,877: time cost, forward:0.011306566996378702, backward:0.03440852232046194, data cost:0.7297121029835683 
2022-07-08 15:44:00,877: ============================================================
2022-07-08 15:44:00,877: Epoch 30/36 Batch 1000/7662 eta: 10:36:29.464961	Training Loss1 2.5131 (2.6019)	Training Total_Loss 2.5131 (2.6019)	Training Prec@1 99.609 (99.370)	Training Prec@5 0.000 (0.000)	
2022-07-08 15:44:00,877: ============================================================
2022-07-08 15:45:14,822: time cost, forward:0.011398049459552851, backward:0.03425533018728296, data cost:0.726434051827803 
2022-07-08 15:45:14,822: ============================================================
2022-07-08 15:45:14,822: Epoch 30/36 Batch 1100/7662 eta: 10:47:27.019743	Training Loss1 2.7619 (2.6015)	Training Total_Loss 2.7619 (2.6015)	Training Prec@1 99.609 (99.373)	Training Prec@5 0.000 (0.000)	
2022-07-08 15:45:14,822: ============================================================
2022-07-08 15:46:28,825: time cost, forward:0.011518156657724007, backward:0.03410477654152457, data cost:0.7237489358696767 
2022-07-08 15:46:28,825: ============================================================
2022-07-08 15:46:28,825: Epoch 30/36 Batch 1200/7662 eta: 10:46:43.370174	Training Loss1 2.4812 (2.5995)	Training Total_Loss 2.4812 (2.5995)	Training Prec@1 99.609 (99.374)	Training Prec@5 0.000 (0.000)	
2022-07-08 15:46:28,825: ============================================================
2022-07-08 15:47:42,657: time cost, forward:0.011557454416805089, backward:0.034029882811325345, data cost:0.7213479769606146 
2022-07-08 15:47:42,657: ============================================================
2022-07-08 15:47:42,658: Epoch 30/36 Batch 1300/7662 eta: 10:44:00.156762	Training Loss1 2.6712 (2.5999)	Training Total_Loss 2.6712 (2.5999)	Training Prec@1 99.609 (99.373)	Training Prec@5 0.000 (0.000)	
2022-07-08 15:47:42,658: ============================================================
2022-07-08 15:48:57,387: time cost, forward:0.01161764382123095, backward:0.03404284324536927, data cost:0.7198384922687457 
2022-07-08 15:48:57,387: ============================================================
2022-07-08 15:48:57,387: Epoch 30/36 Batch 1400/7662 eta: 10:50:35.078643	Training Loss1 2.6936 (2.5985)	Training Total_Loss 2.6936 (2.5985)	Training Prec@1 99.609 (99.374)	Training Prec@5 0.000 (0.000)	
2022-07-08 15:48:57,387: ============================================================
2022-07-08 15:50:10,716: time cost, forward:0.011622475337155108, backward:0.033984609092371394, data cost:0.7176994373990823 
2022-07-08 15:50:10,717: ============================================================
2022-07-08 15:50:10,717: Epoch 30/36 Batch 1500/7662 eta: 10:37:10.553696	Training Loss1 2.7425 (2.5981)	Training Total_Loss 2.7425 (2.5981)	Training Prec@1 99.219 (99.372)	Training Prec@5 0.000 (0.000)	
2022-07-08 15:50:10,717: ============================================================
2022-07-08 15:51:24,222: time cost, forward:0.011649303096320347, backward:0.03393149062795442, data cost:0.7159198125203451 
2022-07-08 15:51:24,222: ============================================================
2022-07-08 15:51:24,223: Epoch 30/36 Batch 1600/7662 eta: 10:37:28.568853	Training Loss1 2.7768 (2.5974)	Training Total_Loss 2.7768 (2.5974)	Training Prec@1 99.219 (99.374)	Training Prec@5 0.000 (0.000)	
2022-07-08 15:51:24,223: ============================================================
2022-07-08 15:52:37,932: time cost, forward:0.011708618262853954, backward:0.03386461096275828, data cost:0.7144582329110724 
2022-07-08 15:52:37,932: ============================================================
2022-07-08 15:52:37,933: Epoch 30/36 Batch 1700/7662 eta: 10:38:01.266603	Training Loss1 2.7241 (2.5972)	Training Total_Loss 2.7241 (2.5972)	Training Prec@1 99.805 (99.377)	Training Prec@5 0.000 (0.000)	
2022-07-08 15:52:37,933: ============================================================
2022-07-08 15:53:52,637: time cost, forward:0.011735702236868926, backward:0.033809939909803, data cost:0.7137282844912416 
2022-07-08 15:53:52,637: ============================================================
2022-07-08 15:53:52,638: Epoch 30/36 Batch 1800/7662 eta: 10:45:23.317431	Training Loss1 2.3335 (2.5967)	Training Total_Loss 2.3335 (2.5967)	Training Prec@1 99.609 (99.383)	Training Prec@5 0.000 (0.000)	
2022-07-08 15:53:52,638: ============================================================
2022-07-08 15:55:06,766: time cost, forward:0.01177260259253656, backward:0.033803471519546546, data cost:0.7127194036741894 
2022-07-08 15:55:06,767: ============================================================
2022-07-08 15:55:06,767: Epoch 30/36 Batch 1900/7662 eta: 10:39:10.821045	Training Loss1 2.7570 (2.5966)	Training Total_Loss 2.7570 (2.5966)	Training Prec@1 99.219 (99.385)	Training Prec@5 0.000 (0.000)	
2022-07-08 15:55:06,767: ============================================================
2022-07-08 15:56:19,493: time cost, forward:0.011784632603128651, backward:0.03376514020712749, data cost:0.7111633940301221 
2022-07-08 15:56:19,494: ============================================================
2022-07-08 15:56:19,494: Epoch 30/36 Batch 2000/7662 eta: 10:25:52.603315	Training Loss1 2.6271 (2.5956)	Training Total_Loss 2.6271 (2.5956)	Training Prec@1 99.414 (99.386)	Training Prec@5 0.000 (0.000)	
2022-07-08 15:56:19,494: ============================================================
2022-07-08 15:57:32,907: time cost, forward:0.01179277505006831, backward:0.03374081580283359, data cost:0.7100754623585738 
2022-07-08 15:57:32,907: ============================================================
2022-07-08 15:57:32,907: Epoch 30/36 Batch 2100/7662 eta: 10:30:33.459149	Training Loss1 2.4882 (2.5954)	Training Total_Loss 2.4882 (2.5954)	Training Prec@1 99.023 (99.385)	Training Prec@5 0.000 (0.000)	
2022-07-08 15:57:32,907: ============================================================
2022-07-08 15:58:45,640: time cost, forward:0.011807099858865569, backward:0.033749389670121775, data cost:0.7087337932786165 
2022-07-08 15:58:45,640: ============================================================
2022-07-08 15:58:45,640: Epoch 30/36 Batch 2200/7662 eta: 10:23:30.371000	Training Loss1 2.6352 (2.5947)	Training Total_Loss 2.6352 (2.5947)	Training Prec@1 99.609 (99.387)	Training Prec@5 0.000 (0.000)	
2022-07-08 15:58:45,641: ============================================================
2022-07-08 16:00:00,561: time cost, forward:0.01180466064529452, backward:0.03376180236886096, data cost:0.708479822278282 
2022-07-08 16:00:00,562: ============================================================
2022-07-08 16:00:00,562: Epoch 30/36 Batch 2300/7662 eta: 10:41:01.076359	Training Loss1 2.6863 (2.5952)	Training Total_Loss 2.6863 (2.5952)	Training Prec@1 99.414 (99.386)	Training Prec@5 0.000 (0.000)	
2022-07-08 16:00:00,562: ============================================================
2022-07-08 16:01:13,555: time cost, forward:0.011774381333065312, backward:0.033766515953633225, data cost:0.7074760690039523 
2022-07-08 16:01:13,556: ============================================================
2022-07-08 16:01:13,556: Epoch 30/36 Batch 2400/7662 eta: 10:23:18.436789	Training Loss1 2.6730 (2.5949)	Training Total_Loss 2.6730 (2.5949)	Training Prec@1 99.023 (99.385)	Training Prec@5 0.000 (0.000)	
2022-07-08 16:01:13,556: ============================================================
2022-07-08 16:02:28,065: time cost, forward:0.011777902613071595, backward:0.033788816315405555, data cost:0.7071120483296163 
2022-07-08 16:02:28,066: ============================================================
2022-07-08 16:02:28,066: Epoch 30/36 Batch 2500/7662 eta: 10:35:00.495015	Training Loss1 2.5298 (2.5957)	Training Total_Loss 2.5298 (2.5957)	Training Prec@1 99.609 (99.385)	Training Prec@5 0.000 (0.000)	
2022-07-08 16:02:28,066: ============================================================
2022-07-08 16:03:40,099: time cost, forward:0.011764864868363678, backward:0.03378651122856067, data cost:0.705857544873668 
2022-07-08 16:03:40,099: ============================================================
2022-07-08 16:03:40,099: Epoch 30/36 Batch 2600/7662 eta: 10:12:42.298771	Training Loss1 2.3688 (2.5955)	Training Total_Loss 2.3688 (2.5955)	Training Prec@1 98.438 (99.385)	Training Prec@5 0.000 (0.000)	
2022-07-08 16:03:40,099: ============================================================
2022-07-08 16:04:52,304: time cost, forward:0.011758584806591373, backward:0.0337682168719591, data cost:0.704769704729683 
2022-07-08 16:04:52,304: ============================================================
2022-07-08 16:04:52,305: Epoch 30/36 Batch 2700/7662 eta: 10:12:57.772638	Training Loss1 2.4735 (2.5954)	Training Total_Loss 2.4735 (2.5954)	Training Prec@1 99.805 (99.383)	Training Prec@5 0.000 (0.000)	
2022-07-08 16:04:52,305: ============================================================
2022-07-08 16:06:05,917: time cost, forward:0.011732174609975757, backward:0.033770396054408604, data cost:0.7042736490099035 
2022-07-08 16:06:05,917: ============================================================
2022-07-08 16:06:05,917: Epoch 30/36 Batch 2800/7662 eta: 10:23:41.015310	Training Loss1 2.5735 (2.5951)	Training Total_Loss 2.5735 (2.5951)	Training Prec@1 99.023 (99.384)	Training Prec@5 0.000 (0.000)	
2022-07-08 16:06:05,917: ============================================================
2022-07-08 16:07:19,020: time cost, forward:0.011749280243341, backward:0.0337343590964363, data cost:0.70362343176269 
2022-07-08 16:07:19,020: ============================================================
2022-07-08 16:07:19,021: Epoch 30/36 Batch 2900/7662 eta: 10:18:09.008897	Training Loss1 2.7385 (2.5953)	Training Total_Loss 2.7385 (2.5953)	Training Prec@1 99.219 (99.383)	Training Prec@5 0.000 (0.000)	
2022-07-08 16:07:19,021: ============================================================
2022-07-08 16:08:34,384: time cost, forward:0.011782651585155663, backward:0.033697095939659125, data cost:0.7037579749337273 
2022-07-08 16:08:34,385: ============================================================
2022-07-08 16:08:34,385: Epoch 30/36 Batch 3000/7662 eta: 10:36:00.641602	Training Loss1 2.6519 (2.5956)	Training Total_Loss 2.6519 (2.5956)	Training Prec@1 99.609 (99.382)	Training Prec@5 0.000 (0.000)	
2022-07-08 16:08:34,385: ============================================================
2022-07-08 16:09:48,512: time cost, forward:0.011787463557762497, backward:0.03368470514155311, data cost:0.703493036505252 
2022-07-08 16:09:48,512: ============================================================
2022-07-08 16:09:48,512: Epoch 30/36 Batch 3100/7662 eta: 10:24:20.402638	Training Loss1 2.5758 (2.5956)	Training Total_Loss 2.5758 (2.5956)	Training Prec@1 99.805 (99.385)	Training Prec@5 0.000 (0.000)	
2022-07-08 16:09:48,513: ============================================================
2022-07-08 16:11:02,573: time cost, forward:0.011762566102896306, backward:0.033669379399172326, data cost:0.7032364505125084 
2022-07-08 16:11:02,573: ============================================================
2022-07-08 16:11:02,573: Epoch 30/36 Batch 3200/7662 eta: 10:22:32.545158	Training Loss1 2.6347 (2.5952)	Training Total_Loss 2.6347 (2.5952)	Training Prec@1 99.414 (99.385)	Training Prec@5 0.000 (0.000)	
2022-07-08 16:11:02,573: ============================================================
2022-07-08 16:12:16,488: time cost, forward:0.01175393462723116, backward:0.03367087594593392, data cost:0.7029482865196244 
2022-07-08 16:12:16,488: ============================================================
2022-07-08 16:12:16,489: Epoch 30/36 Batch 3300/7662 eta: 10:20:05.421851	Training Loss1 2.7608 (2.5954)	Training Total_Loss 2.7608 (2.5954)	Training Prec@1 99.219 (99.385)	Training Prec@5 0.000 (0.000)	
2022-07-08 16:12:16,489: ============================================================
2022-07-08 16:13:30,536: time cost, forward:0.011725261373427307, backward:0.03367395083951263, data cost:0.7027248574481637 
2022-07-08 16:13:30,537: ============================================================
2022-07-08 16:13:30,537: Epoch 30/36 Batch 3400/7662 eta: 10:19:58.012729	Training Loss1 2.7061 (2.5956)	Training Total_Loss 2.7061 (2.5956)	Training Prec@1 99.609 (99.385)	Training Prec@5 0.000 (0.000)	
2022-07-08 16:13:30,537: ============================================================
2022-07-08 16:14:44,010: time cost, forward:0.011745438367239099, backward:0.03368056185009071, data cost:0.7022923383415682 
2022-07-08 16:14:44,011: ============================================================
2022-07-08 16:14:44,011: Epoch 30/36 Batch 3500/7662 eta: 10:13:56.153790	Training Loss1 2.5567 (2.5955)	Training Total_Loss 2.5567 (2.5955)	Training Prec@1 99.609 (99.385)	Training Prec@5 0.000 (0.000)	
2022-07-08 16:14:44,011: ============================================================
2022-07-08 16:15:57,836: time cost, forward:0.011754746237010484, backward:0.03368411484146224, data cost:0.7019992919390848 
2022-07-08 16:15:57,837: ============================================================
2022-07-08 16:15:57,837: Epoch 30/36 Batch 3600/7662 eta: 10:15:38.972457	Training Loss1 2.6075 (2.5955)	Training Total_Loss 2.6075 (2.5955)	Training Prec@1 99.414 (99.386)	Training Prec@5 0.000 (0.000)	
2022-07-08 16:15:57,837: ============================================================
2022-07-08 16:17:11,601: time cost, forward:0.011784547275709248, backward:0.033681869958020055, data cost:0.7016879233452847 
2022-07-08 16:17:11,601: ============================================================
2022-07-08 16:17:11,601: Epoch 30/36 Batch 3700/7662 eta: 10:13:54.231118	Training Loss1 2.7852 (2.5955)	Training Total_Loss 2.7852 (2.5955)	Training Prec@1 98.438 (99.386)	Training Prec@5 0.000 (0.000)	
2022-07-08 16:17:11,601: ============================================================
2022-07-08 16:18:26,010: time cost, forward:0.0117850027513617, backward:0.03368446587825895, data cost:0.7015907236010378 
2022-07-08 16:18:26,010: ============================================================
2022-07-08 16:18:26,010: Epoch 30/36 Batch 3800/7662 eta: 10:18:01.757309	Training Loss1 2.3912 (2.5956)	Training Total_Loss 2.3912 (2.5956)	Training Prec@1 99.609 (99.387)	Training Prec@5 0.000 (0.000)	
2022-07-08 16:18:26,011: ============================================================
2022-07-08 16:19:39,776: time cost, forward:0.011781564704208198, backward:0.03367744350653485, data cost:0.7013439818448548 
2022-07-08 16:19:39,776: ============================================================
2022-07-08 16:19:39,777: Epoch 30/36 Batch 3900/7662 eta: 10:11:27.603595	Training Loss1 2.3864 (2.5954)	Training Total_Loss 2.3864 (2.5954)	Training Prec@1 99.609 (99.387)	Training Prec@5 0.000 (0.000)	
2022-07-08 16:19:39,777: ============================================================
2022-07-08 16:20:52,528: time cost, forward:0.011779961212780155, backward:0.033675638906178876, data cost:0.7008511477573182 
2022-07-08 16:20:52,528: ============================================================
2022-07-08 16:20:52,529: Epoch 30/36 Batch 4000/7662 eta: 10:01:50.475482	Training Loss1 2.5373 (2.5954)	Training Total_Loss 2.5373 (2.5954)	Training Prec@1 99.609 (99.387)	Training Prec@5 0.000 (0.000)	
2022-07-08 16:20:52,529: ============================================================
2022-07-08 16:22:06,552: time cost, forward:0.011786493099907836, backward:0.03367996407765009, data cost:0.7006752830681262 
2022-07-08 16:22:06,552: ============================================================
2022-07-08 16:22:06,552: Epoch 30/36 Batch 4100/7662 eta: 10:11:07.613458	Training Loss1 2.5996 (2.5956)	Training Total_Loss 2.5996 (2.5956)	Training Prec@1 99.805 (99.386)	Training Prec@5 0.000 (0.000)	
2022-07-08 16:22:06,552: ============================================================
2022-07-08 16:23:20,380: time cost, forward:0.011777225804629851, backward:0.03367811289535417, data cost:0.7004831214835741 
2022-07-08 16:23:20,380: ============================================================
2022-07-08 16:23:20,381: Epoch 30/36 Batch 4200/7662 eta: 10:08:16.978853	Training Loss1 2.7388 (2.5959)	Training Total_Loss 2.7388 (2.5959)	Training Prec@1 98.633 (99.385)	Training Prec@5 0.000 (0.000)	
2022-07-08 16:23:20,381: ============================================================
2022-07-08 16:24:35,172: time cost, forward:0.011775288256857943, backward:0.033673105475014654, data cost:0.7005238259606762 
2022-07-08 16:24:35,173: ============================================================
2022-07-08 16:24:35,173: Epoch 30/36 Batch 4300/7662 eta: 10:14:58.712741	Training Loss1 2.4776 (2.5966)	Training Total_Loss 2.4776 (2.5966)	Training Prec@1 99.609 (99.383)	Training Prec@5 0.000 (0.000)	
2022-07-08 16:24:35,173: ============================================================
2022-07-08 16:25:48,508: time cost, forward:0.011767787970204493, backward:0.03367818239250625, data cost:0.7002232545179301 
2022-07-08 16:25:48,508: ============================================================
2022-07-08 16:25:48,508: Epoch 30/36 Batch 4400/7662 eta: 10:01:46.805618	Training Loss1 2.3164 (2.5968)	Training Total_Loss 2.3164 (2.5968)	Training Prec@1 100.000 (99.381)	Training Prec@5 0.000 (0.000)	
2022-07-08 16:25:48,508: ============================================================
2022-07-08 16:27:02,888: time cost, forward:0.011764732406626385, backward:0.033673767938590574, data cost:0.7001766469060487 
2022-07-08 16:27:02,888: ============================================================
2022-07-08 16:27:02,888: Epoch 30/36 Batch 4500/7662 eta: 10:09:06.640703	Training Loss1 2.7105 (2.5968)	Training Total_Loss 2.7105 (2.5968)	Training Prec@1 99.023 (99.382)	Training Prec@5 0.000 (0.000)	
2022-07-08 16:27:02,889: ============================================================
2022-07-08 16:28:16,713: time cost, forward:0.011774783031814486, backward:0.03367746480264516, data cost:0.6999904396067912 
2022-07-08 16:28:16,714: ============================================================
2022-07-08 16:28:16,714: Epoch 30/36 Batch 4600/7662 eta: 10:03:20.277113	Training Loss1 2.3045 (2.5970)	Training Total_Loss 2.3045 (2.5970)	Training Prec@1 99.805 (99.380)	Training Prec@5 0.000 (0.000)	
2022-07-08 16:28:16,714: ============================================================
2022-07-08 16:29:30,382: time cost, forward:0.011781828178702883, backward:0.033679140606036106, data cost:0.6997814400699905 
2022-07-08 16:29:30,383: ============================================================
2022-07-08 16:29:30,383: Epoch 30/36 Batch 4700/7662 eta: 10:00:49.933506	Training Loss1 2.5572 (2.5968)	Training Total_Loss 2.5572 (2.5968)	Training Prec@1 99.219 (99.379)	Training Prec@5 0.000 (0.000)	
2022-07-08 16:29:30,383: ============================================================
2022-07-08 16:30:44,834: time cost, forward:0.011796685998006075, backward:0.033678922188185134, data cost:0.6997332115376038 
2022-07-08 16:30:44,834: ============================================================
2022-07-08 16:30:44,834: Epoch 30/36 Batch 4800/7662 eta: 10:05:58.457875	Training Loss1 2.8667 (2.5967)	Training Total_Loss 2.8667 (2.5967)	Training Prec@1 98.633 (99.379)	Training Prec@5 0.000 (0.000)	
2022-07-08 16:30:44,835: ============================================================
2022-07-08 16:31:59,518: time cost, forward:0.01180314365565278, backward:0.03365973789707985, data cost:0.699774059574807 
2022-07-08 16:31:59,519: ============================================================
2022-07-08 16:31:59,519: Epoch 30/36 Batch 4900/7662 eta: 10:06:37.361742	Training Loss1 2.5655 (2.5966)	Training Total_Loss 2.5655 (2.5966)	Training Prec@1 99.219 (99.379)	Training Prec@5 0.000 (0.000)	
2022-07-08 16:31:59,519: ============================================================
2022-07-08 16:33:13,631: time cost, forward:0.011798562467467858, backward:0.033664387592102774, data cost:0.699680635990632 
2022-07-08 16:33:13,631: ============================================================
2022-07-08 16:33:13,631: Epoch 30/36 Batch 5000/7662 eta: 10:00:44.665604	Training Loss1 2.6474 (2.5963)	Training Total_Loss 2.6474 (2.5963)	Training Prec@1 99.414 (99.378)	Training Prec@5 0.000 (0.000)	
2022-07-08 16:33:13,631: ============================================================
2022-07-08 16:34:26,854: time cost, forward:0.011815092427563635, backward:0.03367354832903781, data cost:0.6993888700024757 
2022-07-08 16:34:26,854: ============================================================
2022-07-08 16:34:26,854: Epoch 30/36 Batch 5100/7662 eta: 9:52:18.684715	Training Loss1 2.7215 (2.5961)	Training Total_Loss 2.7215 (2.5961)	Training Prec@1 99.023 (99.378)	Training Prec@5 0.000 (0.000)	
2022-07-08 16:34:26,854: ============================================================
2022-07-08 16:35:40,869: time cost, forward:0.011814655994401343, backward:0.03367422672160934, data cost:0.6992881346675244 
2022-07-08 16:35:40,869: ============================================================
2022-07-08 16:35:40,870: Epoch 30/36 Batch 5200/7662 eta: 9:57:29.404918	Training Loss1 2.4843 (2.5961)	Training Total_Loss 2.4843 (2.5961)	Training Prec@1 99.609 (99.378)	Training Prec@5 0.000 (0.000)	
2022-07-08 16:35:40,870: ============================================================
2022-07-08 16:36:55,266: time cost, forward:0.011820526882530855, backward:0.03367778426589865, data cost:0.699249002253656 
2022-07-08 16:36:55,266: ============================================================
2022-07-08 16:36:55,267: Epoch 30/36 Batch 5300/7662 eta: 9:59:19.778347	Training Loss1 2.6549 (2.5962)	Training Total_Loss 2.6549 (2.5962)	Training Prec@1 99.023 (99.378)	Training Prec@5 0.000 (0.000)	
2022-07-08 16:36:55,267: ============================================================
2022-07-08 16:38:09,476: time cost, forward:0.011825211998885992, backward:0.03367679325336217, data cost:0.6991859446810139 
2022-07-08 16:38:09,477: ============================================================
2022-07-08 16:38:09,477: Epoch 30/36 Batch 5400/7662 eta: 9:56:35.296904	Training Loss1 2.4975 (2.5961)	Training Total_Loss 2.4975 (2.5961)	Training Prec@1 100.000 (99.378)	Training Prec@5 0.000 (0.000)	
2022-07-08 16:38:09,477: ============================================================
2022-07-08 16:39:23,231: time cost, forward:0.011818763363857792, backward:0.033676593818324635, data cost:0.6990534386909708 
2022-07-08 16:39:23,231: ============================================================
2022-07-08 16:39:23,231: Epoch 30/36 Batch 5500/7662 eta: 9:51:41.643379	Training Loss1 2.7431 (2.5962)	Training Total_Loss 2.7431 (2.5962)	Training Prec@1 98.633 (99.377)	Training Prec@5 0.000 (0.000)	
2022-07-08 16:39:23,231: ============================================================
2022-07-08 16:40:37,591: time cost, forward:0.01183392835911054, backward:0.03368686330938024, data cost:0.698999893199037 
2022-07-08 16:40:37,592: ============================================================
2022-07-08 16:40:37,592: Epoch 30/36 Batch 5600/7662 eta: 9:55:19.111917	Training Loss1 2.5955 (2.5963)	Training Total_Loss 2.5955 (2.5963)	Training Prec@1 98.438 (99.377)	Training Prec@5 0.000 (0.000)	
2022-07-08 16:40:37,592: ============================================================
2022-07-08 16:41:50,097: time cost, forward:0.011829533144389774, backward:0.03367200644942078, data cost:0.6986686365502741 
2022-07-08 16:41:50,097: ============================================================
2022-07-08 16:41:50,098: Epoch 30/36 Batch 5700/7662 eta: 9:39:15.720491	Training Loss1 2.5960 (2.5964)	Training Total_Loss 2.5960 (2.5964)	Training Prec@1 99.609 (99.376)	Training Prec@5 0.000 (0.000)	
2022-07-08 16:41:50,098: ============================================================
2022-07-08 16:43:02,983: time cost, forward:0.011828818677273017, backward:0.033654424399625724, data cost:0.6984129035898398 
2022-07-08 16:43:02,983: ============================================================
2022-07-08 16:43:02,983: Epoch 30/36 Batch 5800/7662 eta: 9:41:04.782439	Training Loss1 2.6606 (2.5964)	Training Total_Loss 2.6606 (2.5964)	Training Prec@1 99.414 (99.376)	Training Prec@5 0.000 (0.000)	
2022-07-08 16:43:02,983: ============================================================
2022-07-08 16:44:17,538: time cost, forward:0.011827423160693306, backward:0.033646563348739424, data cost:0.698438981161782 
2022-07-08 16:44:17,538: ============================================================
2022-07-08 16:44:17,539: Epoch 30/36 Batch 5900/7662 eta: 9:53:08.988159	Training Loss1 2.4376 (2.5961)	Training Total_Loss 2.4376 (2.5961)	Training Prec@1 99.219 (99.377)	Training Prec@5 0.000 (0.000)	
2022-07-08 16:44:17,539: ============================================================
2022-07-08 16:45:32,217: time cost, forward:0.011829459402914504, backward:0.03365742689292617, data cost:0.6984621425691615 
2022-07-08 16:45:32,218: ============================================================
2022-07-08 16:45:32,218: Epoch 30/36 Batch 6000/7662 eta: 9:52:53.582032	Training Loss1 2.5548 (2.5957)	Training Total_Loss 2.5548 (2.5957)	Training Prec@1 98.828 (99.378)	Training Prec@5 0.000 (0.000)	
2022-07-08 16:45:32,218: ============================================================
2022-07-08 16:46:47,011: time cost, forward:0.011834672521931126, backward:0.033657097194913686, data cost:0.698516135021084 
2022-07-08 16:46:47,012: ============================================================
2022-07-08 16:46:47,012: Epoch 30/36 Batch 6100/7662 eta: 9:52:33.189139	Training Loss1 2.6257 (2.5955)	Training Total_Loss 2.6257 (2.5955)	Training Prec@1 99.219 (99.378)	Training Prec@5 0.000 (0.000)	
2022-07-08 16:46:47,012: ============================================================
2022-07-08 16:48:00,636: time cost, forward:0.011837281725410109, backward:0.033664367183175156, data cost:0.6983698687835708 
2022-07-08 16:48:00,636: ============================================================
2022-07-08 16:48:00,637: Epoch 30/36 Batch 6200/7662 eta: 9:42:03.929180	Training Loss1 2.6465 (2.5953)	Training Total_Loss 2.6465 (2.5953)	Training Prec@1 99.023 (99.379)	Training Prec@5 0.000 (0.000)	
2022-07-08 16:48:00,637: ============================================================
2022-07-08 16:49:14,886: time cost, forward:0.011840177312845805, backward:0.03367476414869581, data cost:0.6983252498985832 
2022-07-08 16:49:14,886: ============================================================
2022-07-08 16:49:14,886: Epoch 30/36 Batch 6300/7662 eta: 9:45:46.121710	Training Loss1 2.5408 (2.5955)	Training Total_Loss 2.5408 (2.5955)	Training Prec@1 99.023 (99.379)	Training Prec@5 0.000 (0.000)	
2022-07-08 16:49:14,886: ============================================================
2022-07-08 16:50:29,943: time cost, forward:0.011836008124657769, backward:0.03368370464806036, data cost:0.6984144083912214 
2022-07-08 16:50:29,943: ============================================================
2022-07-08 16:50:29,943: Epoch 30/36 Batch 6400/7662 eta: 9:50:53.209387	Training Loss1 2.8963 (2.5959)	Training Total_Loss 2.8963 (2.5959)	Training Prec@1 98.828 (99.378)	Training Prec@5 0.000 (0.000)	
2022-07-08 16:50:29,944: ============================================================
2022-07-08 16:51:44,330: time cost, forward:0.011837914973557004, backward:0.03367912584056229, data cost:0.6984071619309982 
2022-07-08 16:51:44,331: ============================================================
2022-07-08 16:51:44,331: Epoch 30/36 Batch 6500/7662 eta: 9:44:22.532302	Training Loss1 2.7870 (2.5960)	Training Total_Loss 2.7870 (2.5960)	Training Prec@1 98.633 (99.378)	Training Prec@5 0.000 (0.000)	
2022-07-08 16:51:44,331: ============================================================
2022-07-08 16:52:58,819: time cost, forward:0.011828404048082051, backward:0.033679632079079216, data cost:0.698422688393001 
2022-07-08 16:52:58,820: ============================================================
2022-07-08 16:52:58,820: Epoch 30/36 Batch 6600/7662 eta: 9:43:55.929896	Training Loss1 2.6212 (2.5962)	Training Total_Loss 2.6212 (2.5962)	Training Prec@1 98.633 (99.378)	Training Prec@5 0.000 (0.000)	
2022-07-08 16:52:58,820: ============================================================
2022-07-08 16:54:13,278: time cost, forward:0.011832597807710394, backward:0.03369043196897255, data cost:0.6984104362774792 
2022-07-08 16:54:13,279: ============================================================
2022-07-08 16:54:13,279: Epoch 30/36 Batch 6700/7662 eta: 9:42:27.293096	Training Loss1 2.4537 (2.5962)	Training Total_Loss 2.4537 (2.5962)	Training Prec@1 99.219 (99.378)	Training Prec@5 0.000 (0.000)	
2022-07-08 16:54:13,279: ============================================================
2022-07-08 16:55:27,838: time cost, forward:0.011830929886472455, backward:0.033695933572999485, data cost:0.6984226950864123 
2022-07-08 16:55:27,838: ============================================================
2022-07-08 16:55:27,838: Epoch 30/36 Batch 6800/7662 eta: 9:41:59.818316	Training Loss1 2.6084 (2.5965)	Training Total_Loss 2.6084 (2.5965)	Training Prec@1 99.414 (99.377)	Training Prec@5 0.000 (0.000)	
2022-07-08 16:55:27,838: ============================================================
2022-07-08 16:56:42,532: time cost, forward:0.01183454699059434, backward:0.03369734245446268, data cost:0.6984489767909793 
2022-07-08 16:56:42,532: ============================================================
2022-07-08 16:56:42,532: Epoch 30/36 Batch 6900/7662 eta: 9:41:48.239454	Training Loss1 2.4136 (2.5966)	Training Total_Loss 2.4136 (2.5966)	Training Prec@1 99.023 (99.377)	Training Prec@5 0.000 (0.000)	
2022-07-08 16:56:42,532: ============================================================
2022-07-08 16:57:57,723: time cost, forward:0.011838705067226488, backward:0.033695634015373954, data cost:0.6985557528287449 
2022-07-08 16:57:57,723: ============================================================
2022-07-08 16:57:57,724: Epoch 30/36 Batch 7000/7662 eta: 9:44:25.588245	Training Loss1 2.5809 (2.5969)	Training Total_Loss 2.5809 (2.5969)	Training Prec@1 99.414 (99.377)	Training Prec@5 0.000 (0.000)	
2022-07-08 16:57:57,724: ============================================================
2022-07-08 16:59:13,097: time cost, forward:0.011839980154847541, backward:0.033689913371529843, data cost:0.6986887717283953 
2022-07-08 16:59:13,097: ============================================================
2022-07-08 16:59:13,097: Epoch 30/36 Batch 7100/7662 eta: 9:44:35.179098	Training Loss1 2.8044 (2.5971)	Training Total_Loss 2.8044 (2.5971)	Training Prec@1 98.828 (99.377)	Training Prec@5 0.000 (0.000)	
2022-07-08 16:59:13,098: ============================================================
2022-07-08 17:00:27,357: time cost, forward:0.011842371573264706, backward:0.033693077299624355, data cost:0.6986486001020671 
2022-07-08 17:00:27,357: ============================================================
2022-07-08 17:00:27,358: Epoch 30/36 Batch 7200/7662 eta: 9:34:42.654245	Training Loss1 2.4574 (2.5973)	Training Total_Loss 2.4574 (2.5973)	Training Prec@1 100.000 (99.376)	Training Prec@5 0.000 (0.000)	
2022-07-08 17:00:27,358: ============================================================
2022-07-08 17:01:41,475: time cost, forward:0.011840983961915167, backward:0.03368825526380559, data cost:0.6986065808510614 
2022-07-08 17:01:41,475: ============================================================
2022-07-08 17:01:41,475: Epoch 30/36 Batch 7300/7662 eta: 9:32:22.423748	Training Loss1 2.3532 (2.5971)	Training Total_Loss 2.3532 (2.5971)	Training Prec@1 99.414 (99.376)	Training Prec@5 0.000 (0.000)	
2022-07-08 17:01:41,475: ============================================================
2022-07-08 17:02:55,607: time cost, forward:0.011839488661439053, backward:0.03368494652109962, data cost:0.6985637823590267 
2022-07-08 17:02:55,607: ============================================================
2022-07-08 17:02:55,608: Epoch 30/36 Batch 7400/7662 eta: 9:31:15.078890	Training Loss1 2.5691 (2.5974)	Training Total_Loss 2.5691 (2.5974)	Training Prec@1 100.000 (99.376)	Training Prec@5 0.000 (0.000)	
2022-07-08 17:02:55,608: ============================================================
2022-07-08 17:04:08,931: time cost, forward:0.011845394553685445, backward:0.0336757588822105, data cost:0.6984153836389306 
2022-07-08 17:04:08,932: ============================================================
2022-07-08 17:04:08,932: Epoch 30/36 Batch 7500/7662 eta: 9:23:48.262404	Training Loss1 2.6378 (2.5973)	Training Total_Loss 2.6378 (2.5973)	Training Prec@1 99.414 (99.376)	Training Prec@5 0.000 (0.000)	
2022-07-08 17:04:08,932: ============================================================
2022-07-08 17:05:23,914: time cost, forward:0.01185521810897825, backward:0.033675025428403504, data cost:0.6984759607288709 
2022-07-08 17:05:23,915: ============================================================
2022-07-08 17:05:23,915: Epoch 30/36 Batch 7600/7662 eta: 9:35:18.411337	Training Loss1 2.6168 (2.5972)	Training Total_Loss 2.6168 (2.5972)	Training Prec@1 99.219 (99.376)	Training Prec@5 0.000 (0.000)	
2022-07-08 17:05:23,915: ============================================================
2022-07-08 17:06:13,077: Epoch 30/36 Batch 7663/7662 eta: 9:34:31.172064	Training Loss1 2.6955 (2.5972)	Training Total_Loss 2.6955 (2.5972)	Training Prec@1 99.414 (99.376)	Training Prec@5 0.000 (0.000)	
2022-07-08 17:06:13,077: ============================================================
2022-07-08 17:06:13,195: Save Checkpoint...
2022-07-08 17:06:13,208: ============================================================
2022-07-08 17:06:34,042: Save done!
2022-07-08 17:06:34,042: ============================================================
2022-07-08 17:07:50,021: time cost, forward:0.011131789949205186, backward:0.03336335914303558, data cost:0.7174457082844744 
2022-07-08 17:07:50,021: ============================================================
2022-07-08 17:07:50,022: Epoch 31/36 Batch 100/7662 eta: 9:40:44.801286	Training Loss1 2.4846 (2.5377)	Training Total_Loss 2.4846 (2.5377)	Training Prec@1 100.000 (99.467)	Training Prec@5 0.000 (0.000)	
2022-07-08 17:07:50,022: ============================================================
2022-07-08 17:09:04,972: time cost, forward:0.010735055310043259, backward:0.03359065223578832, data cost:0.7111050172067767 
2022-07-08 17:09:04,972: ============================================================
2022-07-08 17:09:04,973: Epoch 31/36 Batch 200/7662 eta: 9:31:47.357996	Training Loss1 2.4924 (2.5432)	Training Total_Loss 2.4924 (2.5432)	Training Prec@1 99.414 (99.435)	Training Prec@5 0.000 (0.000)	
2022-07-08 17:09:04,973: ============================================================
2022-07-08 17:10:21,065: time cost, forward:0.010801903778892695, backward:0.03379066413062871, data cost:0.7124396351268858 
2022-07-08 17:10:21,065: ============================================================
2022-07-08 17:10:21,065: Epoch 31/36 Batch 300/7662 eta: 9:39:13.689617	Training Loss1 2.5025 (2.5503)	Training Total_Loss 2.5025 (2.5503)	Training Prec@1 99.219 (99.409)	Training Prec@5 0.000 (0.000)	
2022-07-08 17:10:21,065: ============================================================
2022-07-08 17:11:36,270: time cost, forward:0.010968262689155444, backward:0.033860240663800924, data cost:0.7108178688469985 
2022-07-08 17:11:36,271: ============================================================
2022-07-08 17:11:36,271: Epoch 31/36 Batch 400/7662 eta: 9:31:13.577832	Training Loss1 2.4877 (2.5499)	Training Total_Loss 2.4877 (2.5499)	Training Prec@1 99.219 (99.415)	Training Prec@5 0.000 (0.000)	
2022-07-08 17:11:36,271: ============================================================
2022-07-08 17:12:50,821: time cost, forward:0.011285148784966172, backward:0.03373023264393778, data cost:0.7084666010373102 
2022-07-08 17:12:50,821: ============================================================
2022-07-08 17:12:50,821: Epoch 31/36 Batch 500/7662 eta: 9:25:00.294727	Training Loss1 2.4807 (2.5508)	Training Total_Loss 2.4807 (2.5508)	Training Prec@1 99.219 (99.416)	Training Prec@5 0.000 (0.000)	
2022-07-08 17:12:50,822: ============================================================
2022-07-08 17:14:04,708: time cost, forward:0.011415606150046016, backward:0.033669979226012066, data cost:0.7058743387709476 
2022-07-08 17:14:04,708: ============================================================
2022-07-08 17:14:04,709: Epoch 31/36 Batch 600/7662 eta: 9:18:44.916115	Training Loss1 2.4500 (2.5525)	Training Total_Loss 2.4500 (2.5525)	Training Prec@1 99.414 (99.407)	Training Prec@5 0.000 (0.000)	
2022-07-08 17:14:04,709: ============================================================
2022-07-08 17:15:16,655: time cost, forward:0.011481526924646292, backward:0.033610000119188826, data cost:0.7012318753036477 
2022-07-08 17:15:16,656: ============================================================
2022-07-08 17:15:16,656: Epoch 31/36 Batch 700/7662 eta: 9:02:52.721078	Training Loss1 2.2624 (2.5528)	Training Total_Loss 2.2624 (2.5528)	Training Prec@1 99.609 (99.405)	Training Prec@5 0.000 (0.000)	
2022-07-08 17:15:16,656: ============================================================
2022-07-08 17:16:29,672: time cost, forward:0.01156186729259276, backward:0.03365112604277304, data cost:0.6990135047253739 
2022-07-08 17:16:29,672: ============================================================
2022-07-08 17:16:29,672: Epoch 31/36 Batch 800/7662 eta: 9:09:43.689801	Training Loss1 2.5910 (2.5510)	Training Total_Loss 2.5910 (2.5510)	Training Prec@1 99.219 (99.408)	Training Prec@5 0.000 (0.000)	
2022-07-08 17:16:29,673: ============================================================
2022-07-08 17:17:42,232: time cost, forward:0.011652465922150914, backward:0.03375244697553828, data cost:0.69666848988899 
2022-07-08 17:17:42,232: ============================================================
2022-07-08 17:17:42,232: Epoch 31/36 Batch 900/7662 eta: 9:05:04.843581	Training Loss1 2.6928 (2.5534)	Training Total_Loss 2.6928 (2.5534)	Training Prec@1 99.023 (99.410)	Training Prec@5 0.000 (0.000)	
2022-07-08 17:17:42,232: ============================================================
2022-07-08 17:18:55,605: time cost, forward:0.011653197062266123, backward:0.03386152661717809, data cost:0.6956874918531966 
2022-07-08 17:18:55,606: ============================================================
2022-07-08 17:18:55,606: Epoch 31/36 Batch 1000/7662 eta: 9:09:58.444876	Training Loss1 2.4753 (2.5557)	Training Total_Loss 2.4753 (2.5557)	Training Prec@1 99.805 (99.407)	Training Prec@5 0.000 (0.000)	
2022-07-08 17:18:55,606: ============================================================
2022-07-08 17:20:10,327: time cost, forward:0.011663722601448871, backward:0.033890169896897235, data cost:0.6961404053702801 
2022-07-08 17:20:10,327: ============================================================
2022-07-08 17:20:10,327: Epoch 31/36 Batch 1100/7662 eta: 9:18:49.698527	Training Loss1 2.6228 (2.5557)	Training Total_Loss 2.6228 (2.5557)	Training Prec@1 99.805 (99.409)	Training Prec@5 0.000 (0.000)	
2022-07-08 17:20:10,327: ============================================================
2022-07-08 17:21:23,839: time cost, forward:0.011669734202393698, backward:0.033886253883482716, data cost:0.6955332079959771 
2022-07-08 17:21:23,840: ============================================================
2022-07-08 17:21:23,840: Epoch 31/36 Batch 1200/7662 eta: 9:08:33.885614	Training Loss1 2.5684 (2.5571)	Training Total_Loss 2.5684 (2.5571)	Training Prec@1 99.414 (99.406)	Training Prec@5 0.000 (0.000)	
2022-07-08 17:21:23,840: ============================================================
2022-07-08 17:22:37,464: time cost, forward:0.011685217959409131, backward:0.03391934028490403, data cost:0.695070691435405 
2022-07-08 17:22:37,465: ============================================================
2022-07-08 17:22:37,465: Epoch 31/36 Batch 1300/7662 eta: 9:08:10.371422	Training Loss1 2.8297 (2.5591)	Training Total_Loss 2.8297 (2.5591)	Training Prec@1 99.805 (99.405)	Training Prec@5 0.000 (0.000)	
2022-07-08 17:22:37,465: ============================================================
2022-07-08 17:23:50,064: time cost, forward:0.01165091216010311, backward:0.03390483194968801, data cost:0.6940173155244033 
2022-07-08 17:23:50,065: ============================================================
2022-07-08 17:23:50,065: Epoch 31/36 Batch 1400/7662 eta: 8:59:20.010391	Training Loss1 2.8394 (2.5592)	Training Total_Loss 2.8394 (2.5592)	Training Prec@1 98.828 (99.407)	Training Prec@5 0.000 (0.000)	
2022-07-08 17:23:50,065: ============================================================
2022-07-08 17:25:02,441: time cost, forward:0.011699590625724766, backward:0.03387163956217801, data cost:0.6929056213409445 
2022-07-08 17:25:02,441: ============================================================
2022-07-08 17:25:02,441: Epoch 31/36 Batch 1500/7662 eta: 8:56:27.901657	Training Loss1 2.7851 (2.5608)	Training Total_Loss 2.7851 (2.5608)	Training Prec@1 99.219 (99.404)	Training Prec@5 0.000 (0.000)	
2022-07-08 17:25:02,441: ============================================================
2022-07-08 17:26:16,710: time cost, forward:0.011746825539670637, backward:0.03393207974102886, data cost:0.6930336879148119 
2022-07-08 17:26:16,710: ============================================================
2022-07-08 17:26:16,711: Epoch 31/36 Batch 1600/7662 eta: 9:09:15.591489	Training Loss1 2.5097 (2.5610)	Training Total_Loss 2.5097 (2.5610)	Training Prec@1 99.219 (99.408)	Training Prec@5 0.000 (0.000)	
2022-07-08 17:26:16,711: ============================================================
2022-07-08 17:27:30,639: time cost, forward:0.011799853854210255, backward:0.03394155406895773, data cost:0.6929437040651174 
2022-07-08 17:27:30,640: ============================================================
2022-07-08 17:27:30,640: Epoch 31/36 Batch 1700/7662 eta: 9:05:30.771059	Training Loss1 2.5324 (2.5613)	Training Total_Loss 2.5324 (2.5613)	Training Prec@1 99.414 (99.409)	Training Prec@5 0.000 (0.000)	
2022-07-08 17:27:30,640: ============================================================
2022-07-08 17:28:44,157: time cost, forward:0.011794190064876062, backward:0.033949186167099396, data cost:0.6927291534555297 
2022-07-08 17:28:44,158: ============================================================
2022-07-08 17:28:44,158: Epoch 31/36 Batch 1800/7662 eta: 9:01:14.988136	Training Loss1 2.3668 (2.5619)	Training Total_Loss 2.3668 (2.5619)	Training Prec@1 99.219 (99.411)	Training Prec@5 0.000 (0.000)	
2022-07-08 17:28:44,158: ============================================================
2022-07-08 17:29:56,638: time cost, forward:0.011758536398567734, backward:0.03391752549382873, data cost:0.6920398159238023 
2022-07-08 17:29:56,638: ============================================================
2022-07-08 17:29:56,638: Epoch 31/36 Batch 1900/7662 eta: 8:52:24.406099	Training Loss1 2.5826 (2.5623)	Training Total_Loss 2.5826 (2.5623)	Training Prec@1 99.805 (99.411)	Training Prec@5 0.000 (0.000)	
2022-07-08 17:29:56,639: ============================================================
2022-07-08 17:31:09,683: time cost, forward:0.011723377634251696, backward:0.03388088747762095, data cost:0.6917242411078662 
2022-07-08 17:31:09,683: ============================================================
2022-07-08 17:31:09,684: Epoch 31/36 Batch 2000/7662 eta: 8:55:20.098432	Training Loss1 2.6157 (2.5630)	Training Total_Loss 2.6157 (2.5630)	Training Prec@1 99.609 (99.410)	Training Prec@5 0.000 (0.000)	
2022-07-08 17:31:09,684: ============================================================
2022-07-08 17:32:24,185: time cost, forward:0.011741064684115007, backward:0.03384308885426224, data cost:0.6920804327700807 
2022-07-08 17:32:24,185: ============================================================
2022-07-08 17:32:24,186: Epoch 31/36 Batch 2100/7662 eta: 9:04:46.284467	Training Loss1 2.5979 (2.5624)	Training Total_Loss 2.5979 (2.5624)	Training Prec@1 99.609 (99.410)	Training Prec@5 0.000 (0.000)	
2022-07-08 17:32:24,186: ============================================================
2022-07-08 17:33:38,114: time cost, forward:0.011736487301440062, backward:0.03381775530320289, data cost:0.692159611618264 
2022-07-08 17:33:38,114: ============================================================
2022-07-08 17:33:38,114: Epoch 31/36 Batch 2200/7662 eta: 8:59:20.732818	Training Loss1 2.5657 (2.5623)	Training Total_Loss 2.5657 (2.5623)	Training Prec@1 99.219 (99.411)	Training Prec@5 0.000 (0.000)	
2022-07-08 17:33:38,114: ============================================================
2022-07-08 17:34:50,341: time cost, forward:0.011717859378530959, backward:0.033791535934607535, data cost:0.6915038469927681 
2022-07-08 17:34:50,341: ============================================================
2022-07-08 17:34:50,342: Epoch 31/36 Batch 2300/7662 eta: 8:45:43.917620	Training Loss1 2.7172 (2.5631)	Training Total_Loss 2.7172 (2.5631)	Training Prec@1 98.828 (99.409)	Training Prec@5 0.000 (0.000)	
2022-07-08 17:34:50,342: ============================================================
2022-07-08 17:36:03,032: time cost, forward:0.011685774295515892, backward:0.03376413584252406, data cost:0.6911214128440993 
2022-07-08 17:36:03,032: ============================================================
2022-07-08 17:36:03,033: Epoch 31/36 Batch 2400/7662 eta: 8:47:53.576807	Training Loss1 2.4710 (2.5627)	Training Total_Loss 2.4710 (2.5627)	Training Prec@1 99.414 (99.408)	Training Prec@5 0.000 (0.000)	
2022-07-08 17:36:03,033: ============================================================
2022-07-08 17:37:15,855: time cost, forward:0.011659883126682069, backward:0.03375400624880079, data cost:0.6908021184051929 
2022-07-08 17:37:15,856: ============================================================
2022-07-08 17:37:15,856: Epoch 31/36 Batch 2500/7662 eta: 8:47:38.475750	Training Loss1 2.6126 (2.5627)	Training Total_Loss 2.6126 (2.5627)	Training Prec@1 99.219 (99.408)	Training Prec@5 0.000 (0.000)	
2022-07-08 17:37:15,856: ============================================================
2022-07-08 17:38:29,169: time cost, forward:0.01169498969427023, backward:0.033718858328449036, data cost:0.6906611666215204 
2022-07-08 17:38:29,170: ============================================================
2022-07-08 17:38:29,170: Epoch 31/36 Batch 2600/7662 eta: 8:49:58.526156	Training Loss1 2.5842 (2.5626)	Training Total_Loss 2.5842 (2.5626)	Training Prec@1 99.219 (99.410)	Training Prec@5 0.000 (0.000)	
2022-07-08 17:38:29,170: ============================================================
2022-07-08 17:39:44,408: time cost, forward:0.011713741708128661, backward:0.033725949913186025, data cost:0.6912159780168057 
2022-07-08 17:39:44,409: ============================================================
2022-07-08 17:39:44,409: Epoch 31/36 Batch 2700/7662 eta: 9:02:38.135158	Training Loss1 2.5089 (2.5631)	Training Total_Loss 2.5089 (2.5631)	Training Prec@1 99.805 (99.410)	Training Prec@5 0.000 (0.000)	
2022-07-08 17:39:44,409: ============================================================
2022-07-08 17:40:58,244: time cost, forward:0.011705595665891156, backward:0.033732594315943526, data cost:0.6912555123022855 
2022-07-08 17:40:58,245: ============================================================
2022-07-08 17:40:58,245: Epoch 31/36 Batch 2800/7662 eta: 8:51:17.214309	Training Loss1 2.5769 (2.5636)	Training Total_Loss 2.5769 (2.5636)	Training Prec@1 99.219 (99.411)	Training Prec@5 0.000 (0.000)	
2022-07-08 17:40:58,245: ============================================================
2022-07-08 17:42:10,743: time cost, forward:0.011683537903305743, backward:0.033720853781856394, data cost:0.6908650830023122 
2022-07-08 17:42:10,743: ============================================================
2022-07-08 17:42:10,743: Epoch 31/36 Batch 2900/7662 eta: 8:40:27.229659	Training Loss1 2.5897 (2.5640)	Training Total_Loss 2.5897 (2.5640)	Training Prec@1 99.609 (99.411)	Training Prec@5 0.000 (0.000)	
2022-07-08 17:42:10,743: ============================================================
2022-07-08 17:43:23,805: time cost, forward:0.01170232734031461, backward:0.03371574044744346, data cost:0.690643257679801 
2022-07-08 17:43:23,806: ============================================================
2022-07-08 17:43:23,806: Epoch 31/36 Batch 3000/7662 eta: 8:43:17.148740	Training Loss1 2.7467 (2.5643)	Training Total_Loss 2.7467 (2.5643)	Training Prec@1 99.414 (99.410)	Training Prec@5 0.000 (0.000)	
2022-07-08 17:43:23,806: ============================================================
2022-07-08 17:44:36,139: time cost, forward:0.011700802212493887, backward:0.03370785351605829, data cost:0.6902143944459947 
2022-07-08 17:44:36,139: ============================================================
2022-07-08 17:44:36,140: Epoch 31/36 Batch 3100/7662 eta: 8:36:51.687177	Training Loss1 2.3401 (2.5647)	Training Total_Loss 2.3401 (2.5647)	Training Prec@1 100.000 (99.410)	Training Prec@5 0.000 (0.000)	
2022-07-08 17:44:36,140: ============================================================
2022-07-08 17:45:49,331: time cost, forward:0.011737290677818592, backward:0.033707945896111716, data cost:0.6900381027590151 
2022-07-08 17:45:49,331: ============================================================
2022-07-08 17:45:49,331: Epoch 31/36 Batch 3200/7662 eta: 8:41:46.251568	Training Loss1 2.6372 (2.5646)	Training Total_Loss 2.6372 (2.5646)	Training Prec@1 99.023 (99.410)	Training Prec@5 0.000 (0.000)	
2022-07-08 17:45:49,331: ============================================================
2022-07-08 17:47:03,297: time cost, forward:0.011742871398093232, backward:0.033686727059541524, data cost:0.6901576401935126 
2022-07-08 17:47:03,298: ============================================================
2022-07-08 17:47:03,298: Epoch 31/36 Batch 3300/7662 eta: 8:46:03.731482	Training Loss1 2.4599 (2.5649)	Training Total_Loss 2.4599 (2.5649)	Training Prec@1 99.219 (99.410)	Training Prec@5 0.000 (0.000)	
2022-07-08 17:47:03,298: ============================================================
2022-07-08 17:48:16,487: time cost, forward:0.011747120408038245, backward:0.033704030720687464, data cost:0.690017287048672 
2022-07-08 17:48:16,488: ============================================================
2022-07-08 17:48:16,488: Epoch 31/36 Batch 3400/7662 eta: 8:39:19.303267	Training Loss1 2.6071 (2.5656)	Training Total_Loss 2.6071 (2.5656)	Training Prec@1 99.219 (99.408)	Training Prec@5 0.000 (0.000)	
2022-07-08 17:48:16,488: ============================================================
2022-07-08 17:49:30,657: time cost, forward:0.01173927259976675, backward:0.03369574895685964, data cost:0.6902001195037049 
2022-07-08 17:49:30,657: ============================================================
2022-07-08 17:49:30,657: Epoch 31/36 Batch 3500/7662 eta: 8:45:01.845508	Training Loss1 2.5845 (2.5660)	Training Total_Loss 2.5845 (2.5660)	Training Prec@1 99.609 (99.409)	Training Prec@5 0.000 (0.000)	
2022-07-08 17:49:30,657: ============================================================
2022-07-08 17:50:44,939: time cost, forward:0.011751393736584646, backward:0.03368335122630211, data cost:0.6903767393641619 
2022-07-08 17:50:44,940: ============================================================
2022-07-08 17:50:44,940: Epoch 31/36 Batch 3600/7662 eta: 8:44:35.778695	Training Loss1 2.5605 (2.5659)	Training Total_Loss 2.5605 (2.5659)	Training Prec@1 99.609 (99.410)	Training Prec@5 0.000 (0.000)	
2022-07-08 17:50:44,940: ============================================================
2022-07-08 17:51:58,824: time cost, forward:0.011778822007067109, backward:0.033682962854864405, data cost:0.6904156099754142 
2022-07-08 17:51:58,824: ============================================================
2022-07-08 17:51:58,824: Epoch 31/36 Batch 3700/7662 eta: 8:40:33.238438	Training Loss1 2.7975 (2.5660)	Training Total_Loss 2.7975 (2.5660)	Training Prec@1 99.609 (99.412)	Training Prec@5 0.000 (0.000)	
2022-07-08 17:51:58,824: ============================================================
2022-07-08 17:53:13,336: time cost, forward:0.011794151648561338, backward:0.033704956445796894, data cost:0.6906021425804988 
2022-07-08 17:53:13,336: ============================================================
2022-07-08 17:53:13,337: Epoch 31/36 Batch 3800/7662 eta: 8:43:44.063940	Training Loss1 2.6579 (2.5656)	Training Total_Loss 2.6579 (2.5656)	Training Prec@1 99.805 (99.411)	Training Prec@5 0.000 (0.000)	
2022-07-08 17:53:13,337: ============================================================
2022-07-08 17:54:27,069: time cost, forward:0.011796487114557275, backward:0.03370825857283305, data cost:0.6906107668082938 
2022-07-08 17:54:27,069: ============================================================
2022-07-08 17:54:27,070: Epoch 31/36 Batch 3900/7662 eta: 8:37:01.668957	Training Loss1 2.5854 (2.5657)	Training Total_Loss 2.5854 (2.5657)	Training Prec@1 99.609 (99.411)	Training Prec@5 0.000 (0.000)	
2022-07-08 17:54:27,070: ============================================================
2022-07-08 17:55:41,273: time cost, forward:0.01180118469930822, backward:0.03369741870272484, data cost:0.6907536107678806 
2022-07-08 17:55:41,274: ============================================================
2022-07-08 17:55:41,274: Epoch 31/36 Batch 4000/7662 eta: 8:39:05.783217	Training Loss1 2.4733 (2.5662)	Training Total_Loss 2.4733 (2.5662)	Training Prec@1 99.219 (99.411)	Training Prec@5 0.000 (0.000)	
2022-07-08 17:55:41,274: ============================================================
2022-07-08 17:56:56,026: time cost, forward:0.011809821883827688, backward:0.0337096172648251, data cost:0.690994376466169 
2022-07-08 17:56:56,026: ============================================================
2022-07-08 17:56:56,027: Epoch 31/36 Batch 4100/7662 eta: 8:41:41.145796	Training Loss1 2.4108 (2.5665)	Training Total_Loss 2.4108 (2.5665)	Training Prec@1 99.609 (99.411)	Training Prec@5 0.000 (0.000)	
2022-07-08 17:56:56,027: ============================================================
2022-07-08 17:58:08,631: time cost, forward:0.011798719872631156, backward:0.03369611324256703, data cost:0.69075733623382 
2022-07-08 17:58:08,632: ============================================================
2022-07-08 17:58:08,632: Epoch 31/36 Batch 4200/7662 eta: 8:25:29.377389	Training Loss1 2.5486 (2.5666)	Training Total_Loss 2.5486 (2.5666)	Training Prec@1 99.609 (99.412)	Training Prec@5 0.000 (0.000)	
2022-07-08 17:58:08,632: ============================================================
2022-07-08 17:59:21,686: time cost, forward:0.011805112984713413, backward:0.0336896967793598, data cost:0.6906060235226923 
2022-07-08 17:59:21,686: ============================================================
2022-07-08 17:59:21,686: Epoch 31/36 Batch 4300/7662 eta: 8:27:23.931782	Training Loss1 2.5165 (2.5671)	Training Total_Loss 2.5165 (2.5671)	Training Prec@1 99.219 (99.410)	Training Prec@5 0.000 (0.000)	
2022-07-08 17:59:21,686: ============================================================
2022-07-08 18:00:35,841: time cost, forward:0.011798175634864136, backward:0.03369642984165227, data cost:0.6907199377036957 
2022-07-08 18:00:35,841: ============================================================
2022-07-08 18:00:35,841: Epoch 31/36 Batch 4400/7662 eta: 8:33:48.592443	Training Loss1 2.6335 (2.5669)	Training Total_Loss 2.6335 (2.5669)	Training Prec@1 99.414 (99.410)	Training Prec@5 0.000 (0.000)	
2022-07-08 18:00:35,841: ============================================================
2022-07-08 18:01:51,209: time cost, forward:0.011805235478421746, backward:0.03369764206965358, data cost:0.6910845806238837 
2022-07-08 18:01:51,209: ============================================================
2022-07-08 18:01:51,209: Epoch 31/36 Batch 4500/7662 eta: 8:40:57.269202	Training Loss1 2.5996 (2.5673)	Training Total_Loss 2.5996 (2.5673)	Training Prec@1 99.609 (99.409)	Training Prec@5 0.000 (0.000)	
2022-07-08 18:01:51,209: ============================================================
2022-07-08 18:03:05,078: time cost, forward:0.011804043145043923, backward:0.033686759187284046, data cost:0.6911318860486373 
2022-07-08 18:03:05,079: ============================================================
2022-07-08 18:03:05,079: Epoch 31/36 Batch 4600/7662 eta: 8:29:22.133058	Training Loss1 2.5755 (2.5677)	Training Total_Loss 2.5755 (2.5677)	Training Prec@1 99.414 (99.409)	Training Prec@5 0.000 (0.000)	
2022-07-08 18:03:05,079: ============================================================
2022-07-08 18:04:17,063: time cost, forward:0.011812405780062419, backward:0.033660437457483865, data cost:0.6907800298773195 
2022-07-08 18:04:17,063: ============================================================
2022-07-08 18:04:17,064: Epoch 31/36 Batch 4700/7662 eta: 8:15:10.209103	Training Loss1 2.6079 (2.5672)	Training Total_Loss 2.6079 (2.5672)	Training Prec@1 99.805 (99.409)	Training Prec@5 0.000 (0.000)	
2022-07-08 18:04:17,064: ============================================================
2022-07-08 18:05:30,222: time cost, forward:0.011850533075048467, backward:0.033639390559513434, data cost:0.6906527802705218 
2022-07-08 18:05:30,223: ============================================================
2022-07-08 18:05:30,223: Epoch 31/36 Batch 4800/7662 eta: 8:22:01.820120	Training Loss1 2.4291 (2.5676)	Training Total_Loss 2.4291 (2.5676)	Training Prec@1 100.000 (99.410)	Training Prec@5 0.000 (0.000)	
2022-07-08 18:05:30,223: ============================================================
2022-07-08 18:06:44,046: time cost, forward:0.011875369106416534, backward:0.03362880460727845, data cost:0.6906695880800345 
2022-07-08 18:06:44,047: ============================================================
2022-07-08 18:06:44,047: Epoch 31/36 Batch 4900/7662 eta: 8:25:21.846044	Training Loss1 2.6889 (2.5682)	Training Total_Loss 2.6889 (2.5682)	Training Prec@1 99.219 (99.409)	Training Prec@5 0.000 (0.000)	
2022-07-08 18:06:44,047: ============================================================
2022-07-08 18:07:57,691: time cost, forward:0.011863761769458993, backward:0.03361196950999087, data cost:0.690685337461169 
2022-07-08 18:07:57,691: ============================================================
2022-07-08 18:07:57,691: Epoch 31/36 Batch 5000/7662 eta: 8:22:54.203129	Training Loss1 2.6416 (2.5689)	Training Total_Loss 2.6416 (2.5689)	Training Prec@1 99.414 (99.409)	Training Prec@5 0.000 (0.000)	
2022-07-08 18:07:57,691: ============================================================
2022-07-08 18:09:11,418: time cost, forward:0.011865097439787064, backward:0.03360455380769121, data cost:0.690707627079678 
2022-07-08 18:09:11,418: ============================================================
2022-07-08 18:09:11,418: Epoch 31/36 Batch 5100/7662 eta: 8:22:14.538348	Training Loss1 2.5102 (2.5691)	Training Total_Loss 2.5102 (2.5691)	Training Prec@1 99.414 (99.408)	Training Prec@5 0.000 (0.000)	
2022-07-08 18:09:11,418: ============================================================
2022-07-08 18:10:25,587: time cost, forward:0.011869527716250529, backward:0.033591359412356005, data cost:0.6908120025829939 
2022-07-08 18:10:25,587: ============================================================
2022-07-08 18:10:25,587: Epoch 31/36 Batch 5200/7662 eta: 8:24:00.914377	Training Loss1 2.6516 (2.5690)	Training Total_Loss 2.6516 (2.5690)	Training Prec@1 99.414 (99.409)	Training Prec@5 0.000 (0.000)	
2022-07-08 18:10:25,587: ============================================================
2022-07-08 18:11:39,036: time cost, forward:0.011870478071971172, backward:0.0335738478932522, data cost:0.6907833758604529 
2022-07-08 18:11:39,037: ============================================================
2022-07-08 18:11:39,037: Epoch 31/36 Batch 5300/7662 eta: 8:17:54.083750	Training Loss1 2.5997 (2.5687)	Training Total_Loss 2.5997 (2.5687)	Training Prec@1 99.023 (99.410)	Training Prec@5 0.000 (0.000)	
2022-07-08 18:11:39,037: ============================================================
2022-07-08 18:12:52,481: time cost, forward:0.011862221592597375, backward:0.03356330110797575, data cost:0.6907587583516788 
2022-07-08 18:12:52,481: ============================================================
2022-07-08 18:12:52,482: Epoch 31/36 Batch 5400/7662 eta: 8:16:38.735060	Training Loss1 2.7185 (2.5688)	Training Total_Loss 2.7185 (2.5688)	Training Prec@1 99.219 (99.410)	Training Prec@5 0.000 (0.000)	
2022-07-08 18:12:52,482: ============================================================
2022-07-08 18:14:06,858: time cost, forward:0.011880968804575353, backward:0.03354231772324805, data cost:0.690888086130975 
2022-07-08 18:14:06,859: ============================================================
2022-07-08 18:14:06,859: Epoch 31/36 Batch 5500/7662 eta: 8:21:42.684400	Training Loss1 2.6285 (2.5690)	Training Total_Loss 2.6285 (2.5690)	Training Prec@1 99.609 (99.411)	Training Prec@5 0.000 (0.000)	
2022-07-08 18:14:06,859: ============================================================
2022-07-08 18:15:20,678: time cost, forward:0.011888489379991823, backward:0.03353254619209357, data cost:0.69091116013027 
2022-07-08 18:15:20,678: ============================================================
2022-07-08 18:15:20,679: Epoch 31/36 Batch 5600/7662 eta: 8:16:43.251835	Training Loss1 2.5146 (2.5694)	Training Total_Loss 2.5146 (2.5694)	Training Prec@1 99.414 (99.409)	Training Prec@5 0.000 (0.000)	
2022-07-08 18:15:20,679: ============================================================
2022-07-08 18:16:34,989: time cost, forward:0.011898165356592038, backward:0.033533280848369075, data cost:0.6910089634033353 
2022-07-08 18:16:34,989: ============================================================
2022-07-08 18:16:34,989: Epoch 31/36 Batch 5700/7662 eta: 8:18:47.239692	Training Loss1 2.6278 (2.5696)	Training Total_Loss 2.6278 (2.5696)	Training Prec@1 99.219 (99.408)	Training Prec@5 0.000 (0.000)	
2022-07-08 18:16:34,989: ============================================================
2022-07-08 18:17:48,580: time cost, forward:0.011911916782124573, backward:0.0335239436137592, data cost:0.6909852185358691 
2022-07-08 18:17:48,580: ============================================================
2022-07-08 18:17:48,581: Epoch 31/36 Batch 5800/7662 eta: 8:12:43.771750	Training Loss1 2.6293 (2.5703)	Training Total_Loss 2.6293 (2.5703)	Training Prec@1 99.219 (99.408)	Training Prec@5 0.000 (0.000)	
2022-07-08 18:17:48,581: ============================================================
2022-07-08 18:19:02,892: time cost, forward:0.011911479552573401, backward:0.03351642661507725, data cost:0.6910963657852511 
2022-07-08 18:19:02,893: ============================================================
2022-07-08 18:19:02,893: Epoch 31/36 Batch 5900/7662 eta: 8:16:19.263125	Training Loss1 2.5188 (2.5704)	Training Total_Loss 2.5188 (2.5704)	Training Prec@1 99.609 (99.407)	Training Prec@5 0.000 (0.000)	
2022-07-08 18:19:02,893: ============================================================
2022-07-08 18:20:16,562: time cost, forward:0.011897450746109256, backward:0.03350859368755572, data cost:0.691108486536722 
2022-07-08 18:20:16,562: ============================================================
2022-07-08 18:20:16,562: Epoch 31/36 Batch 6000/7662 eta: 8:10:47.773950	Training Loss1 2.5305 (2.5708)	Training Total_Loss 2.5305 (2.5708)	Training Prec@1 99.219 (99.406)	Training Prec@5 0.000 (0.000)	
2022-07-08 18:20:16,562: ============================================================
2022-07-08 18:21:30,644: time cost, forward:0.011881135451752624, backward:0.03351457937171487, data cost:0.6911826524642242 
2022-07-08 18:21:30,645: ============================================================
2022-07-08 18:21:30,645: Epoch 31/36 Batch 6100/7662 eta: 8:12:18.945923	Training Loss1 2.5570 (2.5713)	Training Total_Loss 2.5570 (2.5713)	Training Prec@1 99.219 (99.406)	Training Prec@5 0.000 (0.000)	
2022-07-08 18:21:30,645: ============================================================
2022-07-08 18:22:44,429: time cost, forward:0.011868127374269056, backward:0.033518979733635254, data cost:0.6911988027981547 
2022-07-08 18:22:44,430: ============================================================
2022-07-08 18:22:44,430: Epoch 31/36 Batch 6200/7662 eta: 8:09:06.549808	Training Loss1 2.4442 (2.5717)	Training Total_Loss 2.4442 (2.5717)	Training Prec@1 99.805 (99.406)	Training Prec@5 0.000 (0.000)	
2022-07-08 18:22:44,430: ============================================================
2022-07-08 18:23:58,871: time cost, forward:0.011864017505345978, backward:0.03352287716857213, data cost:0.6913198223377451 
2022-07-08 18:23:58,871: ============================================================
2022-07-08 18:23:58,871: Epoch 31/36 Batch 6300/7662 eta: 8:12:13.045460	Training Loss1 2.7069 (2.5721)	Training Total_Loss 2.7069 (2.5721)	Training Prec@1 99.219 (99.405)	Training Prec@5 0.000 (0.000)	
2022-07-08 18:23:58,871: ============================================================
2022-07-08 18:25:12,106: time cost, forward:0.011854174919921284, backward:0.033520668181502684, data cost:0.6912543379081229 
2022-07-08 18:25:12,107: ============================================================
2022-07-08 18:25:12,107: Epoch 31/36 Batch 6400/7662 eta: 8:03:01.640130	Training Loss1 2.4479 (2.5723)	Training Total_Loss 2.4479 (2.5723)	Training Prec@1 99.414 (99.405)	Training Prec@5 0.000 (0.000)	
2022-07-08 18:25:12,107: ============================================================
2022-07-08 18:26:26,063: time cost, forward:0.011850342088010534, backward:0.03351331021276176, data cost:0.6913019692206276 
2022-07-08 18:26:26,063: ============================================================
2022-07-08 18:26:26,063: Epoch 31/36 Batch 6500/7662 eta: 8:06:32.685231	Training Loss1 2.3061 (2.5725)	Training Total_Loss 2.3061 (2.5725)	Training Prec@1 99.414 (99.405)	Training Prec@5 0.000 (0.000)	
2022-07-08 18:26:26,063: ============================================================
2022-07-08 18:27:41,643: time cost, forward:0.011858755611148563, backward:0.03350999333999757, data cost:0.6915773867043352 
2022-07-08 18:27:41,644: ============================================================
2022-07-08 18:27:41,644: Epoch 31/36 Batch 6600/7662 eta: 8:15:58.475343	Training Loss1 2.5600 (2.5725)	Training Total_Loss 2.5600 (2.5725)	Training Prec@1 98.828 (99.405)	Training Prec@5 0.000 (0.000)	
2022-07-08 18:27:41,644: ============================================================
2022-07-08 18:28:54,211: time cost, forward:0.01185414783633241, backward:0.03351910474816798, data cost:0.691392781432306 
2022-07-08 18:28:54,211: ============================================================
2022-07-08 18:28:54,212: Epoch 31/36 Batch 6700/7662 eta: 7:54:59.486193	Training Loss1 2.5975 (2.5727)	Training Total_Loss 2.5975 (2.5727)	Training Prec@1 99.219 (99.404)	Training Prec@5 0.000 (0.000)	
2022-07-08 18:28:54,212: ============================================================
2022-07-08 18:30:08,331: time cost, forward:0.01185014795285671, backward:0.0335323542317041, data cost:0.6914416181110147 
2022-07-08 18:30:08,331: ============================================================
2022-07-08 18:30:08,332: Epoch 31/36 Batch 6800/7662 eta: 8:03:55.009436	Training Loss1 2.4154 (2.5730)	Training Total_Loss 2.4154 (2.5730)	Training Prec@1 99.414 (99.404)	Training Prec@5 0.000 (0.000)	
2022-07-08 18:30:08,332: ============================================================
2022-07-08 18:31:22,586: time cost, forward:0.011860128692447802, backward:0.03352547289755296, data cost:0.6915139345038298 
2022-07-08 18:31:22,587: ============================================================
2022-07-08 18:31:22,587: Epoch 31/36 Batch 6900/7662 eta: 8:03:33.732211	Training Loss1 2.5026 (2.5733)	Training Total_Loss 2.5026 (2.5733)	Training Prec@1 99.219 (99.404)	Training Prec@5 0.000 (0.000)	
2022-07-08 18:31:22,587: ============================================================
2022-07-08 18:32:36,123: time cost, forward:0.01185524989952614, backward:0.033519175141551595, data cost:0.6914964006668943 
2022-07-08 18:32:36,124: ============================================================
2022-07-08 18:32:36,124: Epoch 31/36 Batch 7000/7662 eta: 7:57:39.620424	Training Loss1 2.7492 (2.5735)	Training Total_Loss 2.7492 (2.5735)	Training Prec@1 99.609 (99.404)	Training Prec@5 0.000 (0.000)	
2022-07-08 18:32:36,124: ============================================================
2022-07-08 18:33:51,575: time cost, forward:0.011863121635092028, backward:0.0335188998455967, data cost:0.6917282148286782 
2022-07-08 18:33:51,575: ============================================================
2022-07-08 18:33:51,575: Epoch 31/36 Batch 7100/7662 eta: 8:08:50.145906	Training Loss1 2.6888 (2.5740)	Training Total_Loss 2.6888 (2.5740)	Training Prec@1 99.805 (99.402)	Training Prec@5 0.000 (0.000)	
2022-07-08 18:33:51,575: ============================================================
2022-07-08 18:35:05,096: time cost, forward:0.0118580219198853, backward:0.03351986307222854, data cost:0.6916965791824411 
2022-07-08 18:35:05,096: ============================================================
2022-07-08 18:35:05,096: Epoch 31/36 Batch 7200/7662 eta: 7:55:06.331221	Training Loss1 2.7606 (2.5745)	Training Total_Loss 2.7606 (2.5745)	Training Prec@1 99.219 (99.400)	Training Prec@5 0.000 (0.000)	
2022-07-08 18:35:05,096: ============================================================
2022-07-08 18:36:20,275: time cost, forward:0.01185859655873353, backward:0.03350261705087332, data cost:0.691908009494228 
2022-07-08 18:36:20,275: ============================================================
2022-07-08 18:36:20,276: Epoch 31/36 Batch 7300/7662 eta: 8:04:34.072644	Training Loss1 2.6889 (2.5749)	Training Total_Loss 2.6889 (2.5749)	Training Prec@1 99.219 (99.400)	Training Prec@5 0.000 (0.000)	
2022-07-08 18:36:20,276: ============================================================
2022-07-08 18:37:34,802: time cost, forward:0.011863045441748274, backward:0.03348473017723887, data cost:0.6920204839926827 
2022-07-08 18:37:34,803: ============================================================
2022-07-08 18:37:34,803: Epoch 31/36 Batch 7400/7662 eta: 7:59:07.436903	Training Loss1 2.8066 (2.5749)	Training Total_Loss 2.8066 (2.5749)	Training Prec@1 99.805 (99.401)	Training Prec@5 0.000 (0.000)	
2022-07-08 18:37:34,803: ============================================================
2022-07-08 18:38:49,339: time cost, forward:0.011876877060984434, backward:0.03348803100529981, data cost:0.6921015688698678 
2022-07-08 18:38:49,339: ============================================================
2022-07-08 18:38:49,339: Epoch 31/36 Batch 7500/7662 eta: 7:57:56.374251	Training Loss1 2.4003 (2.5753)	Training Total_Loss 2.4003 (2.5753)	Training Prec@1 99.609 (99.400)	Training Prec@5 0.000 (0.000)	
2022-07-08 18:38:49,339: ============================================================
2022-07-08 18:40:02,606: time cost, forward:0.011882507702224676, backward:0.03348998026340192, data cost:0.6920237805376179 
2022-07-08 18:40:02,606: ============================================================
2022-07-08 18:40:02,606: Epoch 31/36 Batch 7600/7662 eta: 7:48:34.742144	Training Loss1 2.7624 (2.5753)	Training Total_Loss 2.7624 (2.5753)	Training Prec@1 99.023 (99.399)	Training Prec@5 0.000 (0.000)	
2022-07-08 18:40:02,606: ============================================================
2022-07-08 18:40:51,139: Epoch 31/36 Batch 7663/7662 eta: 7:47:48.583940	Training Loss1 2.6516 (2.5753)	Training Total_Loss 2.6516 (2.5753)	Training Prec@1 99.414 (99.399)	Training Prec@5 0.000 (0.000)	
2022-07-08 18:40:51,139: ============================================================
2022-07-08 18:40:51,330: Save Checkpoint...
2022-07-08 18:40:51,331: ============================================================
2022-07-08 18:40:53,641: Save done!
2022-07-08 18:40:53,641: ============================================================
2022-07-08 18:42:41,631: time cost, forward:0.011354309139829693, backward:0.0323816453567659, data cost:1.0393119171412304 
2022-07-08 18:42:41,631: ============================================================
2022-07-08 18:42:41,632: Epoch 32/36 Batch 100/7662 eta: 11:26:12.956689	Training Loss1 2.4497 (2.5390)	Training Total_Loss 2.4497 (2.5390)	Training Prec@1 99.609 (99.412)	Training Prec@5 0.000 (0.000)	
2022-07-08 18:42:41,632: ============================================================
2022-07-08 18:43:57,200: time cost, forward:0.01139537772940631, backward:0.03272409055700254, data cost:0.8740732310405329 
2022-07-08 18:43:57,201: ============================================================
2022-07-08 18:43:57,201: Epoch 32/36 Batch 200/7662 eta: 8:00:00.027175	Training Loss1 2.6264 (2.5478)	Training Total_Loss 2.6264 (2.5478)	Training Prec@1 99.609 (99.436)	Training Prec@5 0.000 (0.000)	
2022-07-08 18:43:57,201: ============================================================
2022-07-08 18:45:12,082: time cost, forward:0.01154810050658159, backward:0.0324628927237214, data cost:0.8173961798881607 
2022-07-08 18:45:12,082: ============================================================
2022-07-08 18:45:12,082: Epoch 32/36 Batch 300/7662 eta: 7:54:23.099032	Training Loss1 2.4598 (2.5433)	Training Total_Loss 2.4598 (2.5433)	Training Prec@1 99.219 (99.409)	Training Prec@5 0.000 (0.000)	
2022-07-08 18:45:12,082: ============================================================
2022-07-08 18:46:27,957: time cost, forward:0.011357521353508895, backward:0.03284693481330585, data cost:0.7913188898473754 
2022-07-08 18:46:27,957: ============================================================
2022-07-08 18:46:27,958: Epoch 32/36 Batch 400/7662 eta: 7:59:25.150216	Training Loss1 2.5994 (2.5404)	Training Total_Loss 2.5994 (2.5404)	Training Prec@1 99.609 (99.424)	Training Prec@5 0.000 (0.000)	
2022-07-08 18:46:27,958: ============================================================
2022-07-08 18:47:42,894: time cost, forward:0.011170590329982475, backward:0.03315336575250109, data cost:0.7737937260247424 
2022-07-08 18:47:42,894: ============================================================
2022-07-08 18:47:42,894: Epoch 32/36 Batch 500/7662 eta: 7:52:14.292960	Training Loss1 2.4031 (2.5377)	Training Total_Loss 2.4031 (2.5377)	Training Prec@1 99.609 (99.447)	Training Prec@5 0.000 (0.000)	
2022-07-08 18:47:42,894: ============================================================
2022-07-08 18:48:57,344: time cost, forward:0.011022564166774336, backward:0.03328981144798419, data cost:0.7614556429581173 
2022-07-08 18:48:57,344: ============================================================
2022-07-08 18:48:57,344: Epoch 32/36 Batch 600/7662 eta: 7:47:55.892385	Training Loss1 2.2788 (2.5383)	Training Total_Loss 2.2788 (2.5383)	Training Prec@1 99.805 (99.451)	Training Prec@5 0.000 (0.000)	
2022-07-08 18:48:57,344: ============================================================
2022-07-08 18:50:11,394: time cost, forward:0.010927068658482192, backward:0.03328212545665037, data cost:0.7521182808582705 
2022-07-08 18:50:11,394: ============================================================
2022-07-08 18:50:11,394: Epoch 32/36 Batch 700/7662 eta: 7:44:10.841373	Training Loss1 2.4613 (2.5384)	Training Total_Loss 2.4613 (2.5384)	Training Prec@1 99.414 (99.445)	Training Prec@5 0.000 (0.000)	
2022-07-08 18:50:11,394: ============================================================
2022-07-08 18:51:27,950: time cost, forward:0.010859083920456142, backward:0.033406444127031504, data cost:0.7481718842168624 
2022-07-08 18:51:27,950: ============================================================
2022-07-08 18:51:27,951: Epoch 32/36 Batch 800/7662 eta: 7:58:37.151448	Training Loss1 2.6473 (2.5401)	Training Total_Loss 2.6473 (2.5401)	Training Prec@1 99.414 (99.441)	Training Prec@5 0.000 (0.000)	
2022-07-08 18:51:27,951: ============================================================
2022-07-08 18:52:45,885: time cost, forward:0.010810726078784506, backward:0.033517297038246976, data cost:0.7465932891684459 
2022-07-08 18:52:45,885: ============================================================
2022-07-08 18:52:45,885: Epoch 32/36 Batch 900/7662 eta: 8:05:56.123506	Training Loss1 2.5419 (2.5412)	Training Total_Loss 2.5419 (2.5412)	Training Prec@1 99.414 (99.442)	Training Prec@5 0.000 (0.000)	
2022-07-08 18:52:45,885: ============================================================
2022-07-08 18:54:01,145: time cost, forward:0.010760206360000748, backward:0.03355174737649637, data cost:0.7426822028002581 
2022-07-08 18:54:01,145: ============================================================
2022-07-08 18:54:01,145: Epoch 32/36 Batch 1000/7662 eta: 7:48:00.303697	Training Loss1 2.4697 (2.5412)	Training Total_Loss 2.4697 (2.5412)	Training Prec@1 99.609 (99.446)	Training Prec@5 0.000 (0.000)	
2022-07-08 18:54:01,146: ============================================================
2022-07-08 18:55:15,101: time cost, forward:0.010787848237430757, backward:0.033591456148600554, data cost:0.7382749888547666 
2022-07-08 18:55:15,102: ============================================================
2022-07-08 18:55:15,102: Epoch 32/36 Batch 1100/7662 eta: 7:38:39.944541	Training Loss1 2.4362 (2.5424)	Training Total_Loss 2.4362 (2.5424)	Training Prec@1 99.805 (99.445)	Training Prec@5 0.000 (0.000)	
2022-07-08 18:55:15,102: ============================================================
2022-07-08 18:56:28,881: time cost, forward:0.010842757586939719, backward:0.03361183728050251, data cost:0.7344116027202081 
2022-07-08 18:56:28,881: ============================================================
2022-07-08 18:56:28,882: Epoch 32/36 Batch 1200/7662 eta: 7:36:20.335641	Training Loss1 2.5908 (2.5438)	Training Total_Loss 2.5908 (2.5438)	Training Prec@1 99.219 (99.440)	Training Prec@5 0.000 (0.000)	
2022-07-08 18:56:28,882: ============================================================
2022-07-08 18:57:42,076: time cost, forward:0.010869337651617624, backward:0.03355535128375399, data cost:0.730792866935172 
2022-07-08 18:57:42,076: ============================================================
2022-07-08 18:57:42,077: Epoch 32/36 Batch 1300/7662 eta: 7:31:30.200984	Training Loss1 2.5440 (2.5442)	Training Total_Loss 2.5440 (2.5442)	Training Prec@1 99.609 (99.442)	Training Prec@5 0.000 (0.000)	
2022-07-08 18:57:42,077: ============================================================
2022-07-08 18:58:55,463: time cost, forward:0.010904102686731367, backward:0.033541290652675235, data cost:0.7277806699915048 
2022-07-08 18:58:55,463: ============================================================
2022-07-08 18:58:55,464: Epoch 32/36 Batch 1400/7662 eta: 7:31:27.875601	Training Loss1 2.6949 (2.5456)	Training Total_Loss 2.6949 (2.5456)	Training Prec@1 99.609 (99.443)	Training Prec@5 0.000 (0.000)	
2022-07-08 18:58:55,464: ============================================================
2022-07-08 19:00:09,323: time cost, forward:0.010982006052639423, backward:0.033464926254598196, data cost:0.7254956250512019 
2022-07-08 19:00:09,324: ============================================================
2022-07-08 19:00:09,324: Epoch 32/36 Batch 1500/7662 eta: 7:33:08.713740	Training Loss1 2.6821 (2.5470)	Training Total_Loss 2.6821 (2.5470)	Training Prec@1 99.805 (99.435)	Training Prec@5 0.000 (0.000)	
2022-07-08 19:00:09,324: ============================================================
2022-07-08 19:01:24,146: time cost, forward:0.011065571512409566, backward:0.033422526156179154, data cost:0.7240679026991967 
2022-07-08 19:01:24,147: ============================================================
2022-07-08 19:01:24,147: Epoch 32/36 Batch 1600/7662 eta: 7:37:48.304598	Training Loss1 2.3909 (2.5470)	Training Total_Loss 2.3909 (2.5470)	Training Prec@1 99.609 (99.436)	Training Prec@5 0.000 (0.000)	
2022-07-08 19:01:24,147: ============================================================
2022-07-08 19:02:37,323: time cost, forward:0.01104441595610764, backward:0.03341798855319593, data cost:0.7218922754818724 
2022-07-08 19:02:37,323: ============================================================
2022-07-08 19:02:37,323: Epoch 32/36 Batch 1700/7662 eta: 7:26:30.601397	Training Loss1 2.5078 (2.5470)	Training Total_Loss 2.5078 (2.5470)	Training Prec@1 99.414 (99.437)	Training Prec@5 0.000 (0.000)	
2022-07-08 19:02:37,323: ============================================================
2022-07-08 19:03:52,782: time cost, forward:0.011076306422065536, backward:0.03342968705894551, data cost:0.7211544300331679 
2022-07-08 19:03:52,782: ============================================================
2022-07-08 19:03:52,782: Epoch 32/36 Batch 1800/7662 eta: 7:39:10.807936	Training Loss1 2.7075 (2.5486)	Training Total_Loss 2.7075 (2.5486)	Training Prec@1 99.219 (99.433)	Training Prec@5 0.000 (0.000)	
2022-07-08 19:03:52,782: ============================================================
2022-07-08 19:05:06,545: time cost, forward:0.01117218551414775, backward:0.03345362207273109, data cost:0.719525851972358 
2022-07-08 19:05:06,546: ============================================================
2022-07-08 19:05:06,546: Epoch 32/36 Batch 1900/7662 eta: 7:27:38.019295	Training Loss1 2.5893 (2.5497)	Training Total_Loss 2.5893 (2.5497)	Training Prec@1 98.828 (99.433)	Training Prec@5 0.000 (0.000)	
2022-07-08 19:05:06,546: ============================================================
2022-07-08 19:06:19,390: time cost, forward:0.01118698902521329, backward:0.0334666226135605, data cost:0.7176850310798405 
2022-07-08 19:06:19,390: ============================================================
2022-07-08 19:06:19,390: Epoch 32/36 Batch 2000/7662 eta: 7:20:50.614553	Training Loss1 2.5350 (2.5494)	Training Total_Loss 2.5350 (2.5494)	Training Prec@1 99.023 (99.437)	Training Prec@5 0.000 (0.000)	
2022-07-08 19:06:19,390: ============================================================
2022-07-08 19:07:32,583: time cost, forward:0.011190705665126763, backward:0.033438081000747424, data cost:0.7162305141074593 
2022-07-08 19:07:32,584: ============================================================
2022-07-08 19:07:32,584: Epoch 32/36 Batch 2100/7662 eta: 7:21:44.115222	Training Loss1 2.5511 (2.5491)	Training Total_Loss 2.5511 (2.5491)	Training Prec@1 99.414 (99.435)	Training Prec@5 0.000 (0.000)	
2022-07-08 19:07:32,584: ============================================================
2022-07-08 19:08:45,228: time cost, forward:0.011186806599407535, backward:0.03344129518575699, data cost:0.7146433446015917 
2022-07-08 19:08:45,228: ============================================================
2022-07-08 19:08:45,228: Epoch 32/36 Batch 2200/7662 eta: 7:17:12.689495	Training Loss1 2.5338 (2.5496)	Training Total_Loss 2.5338 (2.5496)	Training Prec@1 99.219 (99.431)	Training Prec@5 0.000 (0.000)	
2022-07-08 19:08:45,229: ============================================================
2022-07-08 19:09:58,846: time cost, forward:0.011219740328761794, backward:0.033459846223629575, data cost:0.7135656882805014 
2022-07-08 19:09:58,846: ============================================================
2022-07-08 19:09:58,846: Epoch 32/36 Batch 2300/7662 eta: 7:21:50.447231	Training Loss1 2.4571 (2.5501)	Training Total_Loss 2.4571 (2.5501)	Training Prec@1 99.414 (99.431)	Training Prec@5 0.000 (0.000)	
2022-07-08 19:09:58,846: ============================================================
2022-07-08 19:11:12,658: time cost, forward:0.011229993602344024, backward:0.033451654554258144, data cost:0.7126991667316177 
2022-07-08 19:11:12,658: ============================================================
2022-07-08 19:11:12,658: Epoch 32/36 Batch 2400/7662 eta: 7:21:46.644970	Training Loss1 2.5512 (2.5515)	Training Total_Loss 2.5512 (2.5515)	Training Prec@1 99.609 (99.431)	Training Prec@5 0.000 (0.000)	
2022-07-08 19:11:12,658: ============================================================
2022-07-08 19:12:25,742: time cost, forward:0.011225462818489212, backward:0.033468574846015064, data cost:0.7116016037419302 
2022-07-08 19:12:25,743: ============================================================
2022-07-08 19:12:25,743: Epoch 32/36 Batch 2500/7662 eta: 7:16:12.304665	Training Loss1 2.4733 (2.5520)	Training Total_Loss 2.4733 (2.5520)	Training Prec@1 99.609 (99.427)	Training Prec@5 0.000 (0.000)	
2022-07-08 19:12:25,743: ============================================================
2022-07-08 19:13:38,612: time cost, forward:0.011228337385141653, backward:0.03347471063987435, data cost:0.7105124673736971 
2022-07-08 19:13:38,612: ============================================================
2022-07-08 19:13:38,613: Epoch 32/36 Batch 2600/7662 eta: 7:13:42.532437	Training Loss1 2.6013 (2.5533)	Training Total_Loss 2.6013 (2.5533)	Training Prec@1 99.023 (99.425)	Training Prec@5 0.000 (0.000)	
2022-07-08 19:13:38,613: ============================================================
2022-07-08 19:14:52,481: time cost, forward:0.011250533718407353, backward:0.03346717538724082, data cost:0.7098593685352259 
2022-07-08 19:14:52,482: ============================================================
2022-07-08 19:14:52,482: Epoch 32/36 Batch 2700/7662 eta: 7:18:25.639259	Training Loss1 2.5542 (2.5530)	Training Total_Loss 2.5542 (2.5530)	Training Prec@1 100.000 (99.427)	Training Prec@5 0.000 (0.000)	
2022-07-08 19:14:52,482: ============================================================
2022-07-08 19:16:06,962: time cost, forward:0.011267616562265803, backward:0.033487664413861015, data cost:0.7094510593087215 
2022-07-08 19:16:06,962: ============================================================
2022-07-08 19:16:06,962: Epoch 32/36 Batch 2800/7662 eta: 7:20:48.768656	Training Loss1 2.7329 (2.5529)	Training Total_Loss 2.7329 (2.5529)	Training Prec@1 99.609 (99.428)	Training Prec@5 0.000 (0.000)	
2022-07-08 19:16:06,963: ============================================================
2022-07-08 19:17:19,973: time cost, forward:0.01129577430456661, backward:0.03350533078809819, data cost:0.7085524825812949 
2022-07-08 19:17:19,973: ============================================================
2022-07-08 19:17:19,973: Epoch 32/36 Batch 2900/7662 eta: 7:10:53.842190	Training Loss1 2.6363 (2.5535)	Training Total_Loss 2.6363 (2.5535)	Training Prec@1 99.414 (99.427)	Training Prec@5 0.000 (0.000)	
2022-07-08 19:17:19,973: ============================================================
2022-07-08 19:18:34,954: time cost, forward:0.0113083527620016, backward:0.03350128027231306, data cost:0.7084138469721485 
2022-07-08 19:18:34,954: ============================================================
2022-07-08 19:18:34,955: Epoch 32/36 Batch 3000/7662 eta: 7:21:16.638465	Training Loss1 2.7715 (2.5537)	Training Total_Loss 2.7715 (2.5537)	Training Prec@1 98.633 (99.426)	Training Prec@5 0.000 (0.000)	
2022-07-08 19:18:34,955: ============================================================
2022-07-08 19:19:49,068: time cost, forward:0.011341106126138418, backward:0.03351073051199062, data cost:0.7079642302915333 
2022-07-08 19:19:49,069: ============================================================
2022-07-08 19:19:49,069: Epoch 32/36 Batch 3100/7662 eta: 7:14:56.388360	Training Loss1 2.6564 (2.5537)	Training Total_Loss 2.6564 (2.5537)	Training Prec@1 99.219 (99.426)	Training Prec@5 0.000 (0.000)	
2022-07-08 19:19:49,069: ============================================================
2022-07-08 19:21:02,028: time cost, forward:0.01135907600953751, backward:0.03350628096821085, data cost:0.707202791310579 
2022-07-08 19:21:02,028: ============================================================
2022-07-08 19:21:02,029: Epoch 32/36 Batch 3200/7662 eta: 7:06:56.882900	Training Loss1 2.5430 (2.5545)	Training Total_Loss 2.5430 (2.5545)	Training Prec@1 99.219 (99.424)	Training Prec@5 0.000 (0.000)	
2022-07-08 19:21:02,029: ============================================================
2022-07-08 19:22:15,161: time cost, forward:0.011381462365434039, backward:0.03351282076099924, data cost:0.7065290498458895 
2022-07-08 19:22:15,162: ============================================================
2022-07-08 19:22:15,162: Epoch 32/36 Batch 3300/7662 eta: 7:06:44.664795	Training Loss1 2.7075 (2.5550)	Training Total_Loss 2.7075 (2.5550)	Training Prec@1 99.805 (99.424)	Training Prec@5 0.000 (0.000)	
2022-07-08 19:22:15,162: ============================================================
2022-07-08 19:23:29,207: time cost, forward:0.011385084566350333, backward:0.03352288408607692, data cost:0.7061714692549272 
2022-07-08 19:23:29,207: ============================================================
2022-07-08 19:23:29,207: Epoch 32/36 Batch 3400/7662 eta: 7:10:50.067718	Training Loss1 2.6227 (2.5549)	Training Total_Loss 2.6227 (2.5549)	Training Prec@1 99.219 (99.423)	Training Prec@5 0.000 (0.000)	
2022-07-08 19:23:29,207: ============================================================
2022-07-08 19:24:42,932: time cost, forward:0.011406142972612013, backward:0.03350633946647982, data cost:0.7057562417457975 
2022-07-08 19:24:42,932: ============================================================
2022-07-08 19:24:42,932: Epoch 32/36 Batch 3500/7662 eta: 7:07:44.401168	Training Loss1 2.6016 (2.5556)	Training Total_Loss 2.6016 (2.5556)	Training Prec@1 99.414 (99.423)	Training Prec@5 0.000 (0.000)	
2022-07-08 19:24:42,932: ============================================================
2022-07-08 19:25:56,385: time cost, forward:0.011437317436686752, backward:0.03349824871212683, data cost:0.7052685186974901 
2022-07-08 19:25:56,386: ============================================================
2022-07-08 19:25:56,386: Epoch 32/36 Batch 3600/7662 eta: 7:04:56.505968	Training Loss1 2.4120 (2.5557)	Training Total_Loss 2.4120 (2.5557)	Training Prec@1 99.414 (99.423)	Training Prec@5 0.000 (0.000)	
2022-07-08 19:25:56,386: ============================================================
2022-07-08 19:27:11,010: time cost, forward:0.011464419510597214, backward:0.033492355225504526, data cost:0.7051220934079705 
2022-07-08 19:27:11,011: ============================================================
2022-07-08 19:27:11,011: Epoch 32/36 Batch 3700/7662 eta: 7:10:28.454872	Training Loss1 2.5311 (2.5556)	Training Total_Loss 2.5311 (2.5556)	Training Prec@1 99.609 (99.424)	Training Prec@5 0.000 (0.000)	
2022-07-08 19:27:11,011: ============================================================
2022-07-08 19:28:25,096: time cost, forward:0.011465510558881205, backward:0.033480446035531235, data cost:0.7048748431942531 
2022-07-08 19:28:25,096: ============================================================
2022-07-08 19:28:25,096: Epoch 32/36 Batch 3800/7662 eta: 7:06:07.606753	Training Loss1 2.5214 (2.5557)	Training Total_Loss 2.5214 (2.5557)	Training Prec@1 99.219 (99.424)	Training Prec@5 0.000 (0.000)	
2022-07-08 19:28:25,096: ============================================================
2022-07-08 19:29:38,713: time cost, forward:0.01147205990441306, backward:0.033494209870218346, data cost:0.7044908269670384 
2022-07-08 19:29:38,713: ============================================================
2022-07-08 19:29:38,714: Epoch 32/36 Batch 3900/7662 eta: 7:02:12.450919	Training Loss1 2.5021 (2.5560)	Training Total_Loss 2.5021 (2.5560)	Training Prec@1 99.219 (99.424)	Training Prec@5 0.000 (0.000)	
2022-07-08 19:29:38,714: ============================================================
2022-07-08 19:30:52,653: time cost, forward:0.011492622050680974, backward:0.03349114179790065, data cost:0.7042052470972968 
2022-07-08 19:30:52,653: ============================================================
2022-07-08 19:30:52,653: Epoch 32/36 Batch 4000/7662 eta: 7:02:49.404700	Training Loss1 2.4616 (2.5568)	Training Total_Loss 2.4616 (2.5568)	Training Prec@1 100.000 (99.421)	Training Prec@5 0.000 (0.000)	
2022-07-08 19:30:52,653: ============================================================
2022-07-08 19:32:07,041: time cost, forward:0.011509544705728054, backward:0.03346780789541192, data cost:0.7040709315581739 
2022-07-08 19:32:07,041: ============================================================
2022-07-08 19:32:07,042: Epoch 32/36 Batch 4100/7662 eta: 7:04:09.011391	Training Loss1 2.6678 (2.5570)	Training Total_Loss 2.6678 (2.5570)	Training Prec@1 99.414 (99.420)	Training Prec@5 0.000 (0.000)	
2022-07-08 19:32:07,042: ============================================================
2022-07-08 19:33:20,692: time cost, forward:0.011504798992726597, backward:0.033472367541282966, data cost:0.7037626581266966 
2022-07-08 19:33:20,692: ============================================================
2022-07-08 19:33:20,693: Epoch 32/36 Batch 4200/7662 eta: 6:58:43.091723	Training Loss1 2.5239 (2.5572)	Training Total_Loss 2.5239 (2.5572)	Training Prec@1 99.609 (99.420)	Training Prec@5 0.000 (0.000)	
2022-07-08 19:33:20,693: ============================================================
2022-07-08 19:34:34,620: time cost, forward:0.011500639592694472, backward:0.03346266505828595, data cost:0.7035403114664025 
2022-07-08 19:34:34,621: ============================================================
2022-07-08 19:34:34,621: Epoch 32/36 Batch 4300/7662 eta: 6:59:03.684425	Training Loss1 2.5394 (2.5579)	Training Total_Loss 2.5394 (2.5579)	Training Prec@1 98.828 (99.420)	Training Prec@5 0.000 (0.000)	
2022-07-08 19:34:34,621: ============================================================
2022-07-08 19:35:49,371: time cost, forward:0.011499421329329192, backward:0.03345275564772564, data cost:0.7035159121103844 
2022-07-08 19:35:49,372: ============================================================
2022-07-08 19:35:49,372: Epoch 32/36 Batch 4400/7662 eta: 7:02:28.842874	Training Loss1 2.4783 (2.5584)	Training Total_Loss 2.4783 (2.5584)	Training Prec@1 99.805 (99.420)	Training Prec@5 0.000 (0.000)	
2022-07-08 19:35:49,372: ============================================================
2022-07-08 19:37:03,705: time cost, forward:0.011509643498726171, backward:0.03347021814292472, data cost:0.7033600745187333 
2022-07-08 19:37:03,706: ============================================================
2022-07-08 19:37:03,706: Epoch 32/36 Batch 4500/7662 eta: 6:58:53.082078	Training Loss1 2.5470 (2.5587)	Training Total_Loss 2.5470 (2.5587)	Training Prec@1 99.219 (99.419)	Training Prec@5 0.000 (0.000)	
2022-07-08 19:37:03,706: ============================================================
2022-07-08 19:38:17,499: time cost, forward:0.01150100882816999, backward:0.03347073619483372, data cost:0.7031259756032268 
2022-07-08 19:38:17,499: ============================================================
2022-07-08 19:38:17,500: Epoch 32/36 Batch 4600/7662 eta: 6:54:36.587851	Training Loss1 2.4336 (2.5593)	Training Total_Loss 2.4336 (2.5593)	Training Prec@1 100.000 (99.418)	Training Prec@5 0.000 (0.000)	
2022-07-08 19:38:17,500: ============================================================
2022-07-08 19:39:31,755: time cost, forward:0.011513869136819233, backward:0.03346738523055858, data cost:0.7029861004003999 
2022-07-08 19:39:31,755: ============================================================
2022-07-08 19:39:31,755: Epoch 32/36 Batch 4700/7662 eta: 6:55:58.084967	Training Loss1 2.5032 (2.5599)	Training Total_Loss 2.5032 (2.5599)	Training Prec@1 99.219 (99.418)	Training Prec@5 0.000 (0.000)	
2022-07-08 19:39:31,755: ============================================================
2022-07-08 19:40:45,076: time cost, forward:0.011533324831250956, backward:0.033463002741647326, data cost:0.7026471118923028 
2022-07-08 19:40:45,077: ============================================================
2022-07-08 19:40:45,077: Epoch 32/36 Batch 4800/7662 eta: 6:49:30.811510	Training Loss1 2.5023 (2.5604)	Training Total_Loss 2.5023 (2.5604)	Training Prec@1 99.805 (99.417)	Training Prec@5 0.000 (0.000)	
2022-07-08 19:40:45,077: ============================================================
2022-07-08 19:41:58,087: time cost, forward:0.01153194439559597, backward:0.03344850044733263, data cost:0.702293808106428 
2022-07-08 19:41:58,087: ============================================================
2022-07-08 19:41:58,087: Epoch 32/36 Batch 4900/7662 eta: 6:46:33.488194	Training Loss1 2.4875 (2.5606)	Training Total_Loss 2.4875 (2.5606)	Training Prec@1 99.609 (99.417)	Training Prec@5 0.000 (0.000)	
2022-07-08 19:41:58,087: ============================================================
2022-07-08 19:43:11,051: time cost, forward:0.011533044819642029, backward:0.03343831908586002, data cost:0.701937190387983 
2022-07-08 19:43:11,052: ============================================================
2022-07-08 19:43:11,052: Epoch 32/36 Batch 5000/7662 eta: 6:45:05.202752	Training Loss1 2.6414 (2.5607)	Training Total_Loss 2.6414 (2.5607)	Training Prec@1 99.609 (99.417)	Training Prec@5 0.000 (0.000)	
2022-07-08 19:43:11,052: ============================================================
2022-07-08 19:44:25,736: time cost, forward:0.01155219215532218, backward:0.033441386753074044, data cost:0.7019017345415749 
2022-07-08 19:44:25,736: ============================================================
2022-07-08 19:44:25,736: Epoch 32/36 Batch 5100/7662 eta: 6:53:23.452106	Training Loss1 2.5718 (2.5608)	Training Total_Loss 2.5718 (2.5608)	Training Prec@1 99.414 (99.416)	Training Prec@5 0.000 (0.000)	
2022-07-08 19:44:25,736: ============================================================
2022-07-08 19:45:40,256: time cost, forward:0.01155812081338626, backward:0.03345715598340997, data cost:0.7018355169441177 
2022-07-08 19:45:40,256: ============================================================
2022-07-08 19:45:40,257: Epoch 32/36 Batch 5200/7662 eta: 6:51:14.488736	Training Loss1 2.7190 (2.5613)	Training Total_Loss 2.7190 (2.5613)	Training Prec@1 99.414 (99.416)	Training Prec@5 0.000 (0.000)	
2022-07-08 19:45:40,257: ============================================================
2022-07-08 19:46:54,180: time cost, forward:0.011576259781851322, backward:0.033469942025945734, data cost:0.7016482794593023 
2022-07-08 19:46:54,180: ============================================================
2022-07-08 19:46:54,180: Epoch 32/36 Batch 5300/7662 eta: 6:46:42.827419	Training Loss1 2.5752 (2.5613)	Training Total_Loss 2.5752 (2.5613)	Training Prec@1 99.805 (99.416)	Training Prec@5 0.000 (0.000)	
2022-07-08 19:46:54,180: ============================================================
2022-07-08 19:48:08,699: time cost, forward:0.011583402877075625, backward:0.03347462913596557, data cost:0.7015980314515127 
2022-07-08 19:48:08,699: ============================================================
2022-07-08 19:48:08,699: Epoch 32/36 Batch 5400/7662 eta: 6:48:44.978945	Training Loss1 2.6816 (2.5616)	Training Total_Loss 2.6816 (2.5616)	Training Prec@1 97.852 (99.416)	Training Prec@5 0.000 (0.000)	
2022-07-08 19:48:08,699: ============================================================
2022-07-08 19:49:22,069: time cost, forward:0.01158261494238521, backward:0.03347388864278923, data cost:0.7013537072987963 
2022-07-08 19:49:22,069: ============================================================
2022-07-08 19:49:22,070: Epoch 32/36 Batch 5500/7662 eta: 6:41:13.537834	Training Loss1 2.6067 (2.5622)	Training Total_Loss 2.6067 (2.5622)	Training Prec@1 99.609 (99.416)	Training Prec@5 0.000 (0.000)	
2022-07-08 19:49:22,070: ============================================================
2022-07-08 19:50:35,215: time cost, forward:0.011588234670631884, backward:0.03346367128450203, data cost:0.7010801989045563 
2022-07-08 19:50:35,215: ============================================================
2022-07-08 19:50:35,216: Epoch 32/36 Batch 5600/7662 eta: 6:38:46.822423	Training Loss1 2.4871 (2.5625)	Training Total_Loss 2.4871 (2.5625)	Training Prec@1 99.219 (99.416)	Training Prec@5 0.000 (0.000)	
2022-07-08 19:50:35,216: ============================================================
2022-07-08 19:51:49,596: time cost, forward:0.011593041116259646, backward:0.03345465053485389, data cost:0.7010330020973485 
2022-07-08 19:51:49,596: ============================================================
2022-07-08 19:51:49,597: Epoch 32/36 Batch 5700/7662 eta: 6:44:16.408683	Training Loss1 2.5353 (2.5627)	Training Total_Loss 2.5353 (2.5627)	Training Prec@1 99.219 (99.416)	Training Prec@5 0.000 (0.000)	
2022-07-08 19:51:49,597: ============================================================
2022-07-08 19:53:04,518: time cost, forward:0.01159804807611325, backward:0.03345478972724274, data cost:0.7010724220137736 
2022-07-08 19:53:04,519: ============================================================
2022-07-08 19:53:04,519: Epoch 32/36 Batch 5800/7662 eta: 6:45:57.900544	Training Loss1 2.4798 (2.5627)	Training Total_Loss 2.4798 (2.5627)	Training Prec@1 99.414 (99.416)	Training Prec@5 0.000 (0.000)	
2022-07-08 19:53:04,519: ============================================================
2022-07-08 19:54:18,242: time cost, forward:0.011607443807407605, backward:0.03345253282046799, data cost:0.7008991913181944 
2022-07-08 19:54:18,242: ============================================================
2022-07-08 19:54:18,242: Epoch 32/36 Batch 5900/7662 eta: 6:38:14.518180	Training Loss1 2.4369 (2.5630)	Training Total_Loss 2.4369 (2.5630)	Training Prec@1 99.609 (99.416)	Training Prec@5 0.000 (0.000)	
2022-07-08 19:54:18,242: ============================================================
2022-07-08 19:55:30,911: time cost, forward:0.011610328723915738, backward:0.03346125136456662, data cost:0.7005596757829339 
2022-07-08 19:55:30,911: ============================================================
2022-07-08 19:55:30,911: Epoch 32/36 Batch 6000/7662 eta: 6:31:20.094813	Training Loss1 2.6952 (2.5633)	Training Total_Loss 2.6952 (2.5633)	Training Prec@1 99.609 (99.415)	Training Prec@5 0.000 (0.000)	
2022-07-08 19:55:30,911: ============================================================
2022-07-08 19:56:46,345: time cost, forward:0.011612938005116206, backward:0.03346564711498655, data cost:0.7006880317208883 
2022-07-08 19:56:46,345: ============================================================
2022-07-08 19:56:46,345: Epoch 32/36 Batch 6100/7662 eta: 6:44:57.984307	Training Loss1 2.4967 (2.5635)	Training Total_Loss 2.4967 (2.5635)	Training Prec@1 99.609 (99.415)	Training Prec@5 0.000 (0.000)	
2022-07-08 19:56:46,345: ============================================================
2022-07-08 19:58:00,888: time cost, forward:0.01162032777983482, backward:0.03346730263161263, data cost:0.7006644688800259 
2022-07-08 19:58:00,889: ============================================================
2022-07-08 19:58:00,889: Epoch 32/36 Batch 6200/7662 eta: 6:38:56.808806	Training Loss1 2.6573 (2.5639)	Training Total_Loss 2.6573 (2.5639)	Training Prec@1 99.609 (99.415)	Training Prec@5 0.000 (0.000)	
2022-07-08 19:58:00,889: ============================================================
2022-07-08 19:59:14,972: time cost, forward:0.011619272298672063, backward:0.03346419879454888, data cost:0.7005802156206425 
2022-07-08 19:59:14,973: ============================================================
2022-07-08 19:59:14,973: Epoch 32/36 Batch 6300/7662 eta: 6:35:14.986307	Training Loss1 2.7874 (2.5640)	Training Total_Loss 2.7874 (2.5640)	Training Prec@1 99.805 (99.415)	Training Prec@5 0.000 (0.000)	
2022-07-08 19:59:14,973: ============================================================
2022-07-08 20:00:27,856: time cost, forward:0.01163258010809413, backward:0.03345720640177428, data cost:0.7003003162673757 
2022-07-08 20:00:27,856: ============================================================
2022-07-08 20:00:27,856: Epoch 32/36 Batch 6400/7662 eta: 6:27:37.813698	Training Loss1 2.4940 (2.5644)	Training Total_Loss 2.4940 (2.5644)	Training Prec@1 99.414 (99.414)	Training Prec@5 0.000 (0.000)	
2022-07-08 20:00:27,856: ============================================================
2022-07-08 20:01:41,941: time cost, forward:0.011651705991196474, backward:0.033451815168020045, data cost:0.7002075739797583 
2022-07-08 20:01:41,941: ============================================================
2022-07-08 20:01:41,941: Epoch 32/36 Batch 6500/7662 eta: 6:32:47.122100	Training Loss1 2.6309 (2.5644)	Training Total_Loss 2.6309 (2.5644)	Training Prec@1 98.828 (99.414)	Training Prec@5 0.000 (0.000)	
2022-07-08 20:01:41,941: ============================================================
2022-07-08 20:02:56,459: time cost, forward:0.011658263253450285, backward:0.033452891096741454, data cost:0.700189757480786 
2022-07-08 20:02:56,460: ============================================================
2022-07-08 20:02:56,460: Epoch 32/36 Batch 6600/7662 eta: 6:33:50.612294	Training Loss1 2.4934 (2.5647)	Training Total_Loss 2.4934 (2.5647)	Training Prec@1 99.219 (99.414)	Training Prec@5 0.000 (0.000)	
2022-07-08 20:02:56,460: ============================================================
2022-07-08 20:04:11,165: time cost, forward:0.01166962224843876, backward:0.03345423446589218, data cost:0.700187212674542 
2022-07-08 20:04:11,165: ============================================================
2022-07-08 20:04:11,165: Epoch 32/36 Batch 6700/7662 eta: 6:33:35.176974	Training Loss1 2.4439 (2.5650)	Training Total_Loss 2.4439 (2.5650)	Training Prec@1 99.609 (99.413)	Training Prec@5 0.000 (0.000)	
2022-07-08 20:04:11,166: ============================================================
2022-07-08 20:05:25,234: time cost, forward:0.011686957431270859, backward:0.033468152831838245, data cost:0.7000785000202567 
2022-07-08 20:05:25,234: ============================================================
2022-07-08 20:05:25,234: Epoch 32/36 Batch 6800/7662 eta: 6:28:59.869670	Training Loss1 2.3802 (2.5653)	Training Total_Loss 2.3802 (2.5653)	Training Prec@1 99.414 (99.413)	Training Prec@5 0.000 (0.000)	
2022-07-08 20:05:25,234: ============================================================
2022-07-08 20:06:39,965: time cost, forward:0.011695221172310094, backward:0.03346636122872059, data cost:0.7000943630186436 
2022-07-08 20:06:39,965: ============================================================
2022-07-08 20:06:39,965: Epoch 32/36 Batch 6900/7662 eta: 6:31:13.782477	Training Loss1 2.7955 (2.5653)	Training Total_Loss 2.7955 (2.5653)	Training Prec@1 99.414 (99.413)	Training Prec@5 0.000 (0.000)	
2022-07-08 20:06:39,966: ============================================================
2022-07-08 20:07:54,610: time cost, forward:0.011712451239350285, backward:0.03347142762261674, data cost:0.700077826473641 
2022-07-08 20:07:54,611: ============================================================
2022-07-08 20:07:54,611: Epoch 32/36 Batch 7000/7662 eta: 6:29:32.301459	Training Loss1 2.6977 (2.5657)	Training Total_Loss 2.6977 (2.5657)	Training Prec@1 99.414 (99.412)	Training Prec@5 0.000 (0.000)	
2022-07-08 20:07:54,611: ============================================================
2022-07-08 20:09:08,456: time cost, forward:0.011722954079573852, backward:0.03346458726037403, data cost:0.6999736004168592 
2022-07-08 20:09:08,456: ============================================================
2022-07-08 20:09:08,456: Epoch 32/36 Batch 7100/7662 eta: 6:24:07.873462	Training Loss1 2.6893 (2.5659)	Training Total_Loss 2.6893 (2.5659)	Training Prec@1 99.414 (99.412)	Training Prec@5 0.000 (0.000)	
2022-07-08 20:09:08,457: ============================================================
2022-07-08 20:10:23,056: time cost, forward:0.011736776848968027, backward:0.03345614877868517, data cost:0.6999703848886893 
2022-07-08 20:10:23,057: ============================================================
2022-07-08 20:10:23,057: Epoch 32/36 Batch 7200/7662 eta: 6:26:48.949498	Training Loss1 2.5800 (2.5665)	Training Total_Loss 2.5800 (2.5665)	Training Prec@1 99.219 (99.411)	Training Prec@5 0.000 (0.000)	
2022-07-08 20:10:23,057: ============================================================
2022-07-08 20:11:37,457: time cost, forward:0.011742905078317748, backward:0.033459097314393754, data cost:0.6999351902846882 
2022-07-08 20:11:37,457: ============================================================
2022-07-08 20:11:37,458: Epoch 32/36 Batch 7300/7662 eta: 6:24:32.399331	Training Loss1 2.6747 (2.5665)	Training Total_Loss 2.6747 (2.5665)	Training Prec@1 99.609 (99.411)	Training Prec@5 0.000 (0.000)	
2022-07-08 20:11:37,458: ============================================================
2022-07-08 20:12:52,422: time cost, forward:0.011757122985349021, backward:0.0334642840198672, data cost:0.699967439020948 
2022-07-08 20:12:52,422: ============================================================
2022-07-08 20:12:52,422: Epoch 32/36 Batch 7400/7662 eta: 6:26:12.376292	Training Loss1 2.5133 (2.5670)	Training Total_Loss 2.5133 (2.5670)	Training Prec@1 99.219 (99.410)	Training Prec@5 0.000 (0.000)	
2022-07-08 20:12:52,423: ============================================================
2022-07-08 20:14:07,553: time cost, forward:0.011767111105638467, backward:0.03346603564348741, data cost:0.7000330367840549 
2022-07-08 20:14:07,553: ============================================================
2022-07-08 20:14:07,554: Epoch 32/36 Batch 7500/7662 eta: 6:25:48.684560	Training Loss1 2.4366 (2.5672)	Training Total_Loss 2.4366 (2.5672)	Training Prec@1 99.609 (99.411)	Training Prec@5 0.000 (0.000)	
2022-07-08 20:14:07,554: ============================================================
2022-07-08 20:15:21,454: time cost, forward:0.011781105949370731, backward:0.03345832041587182, data cost:0.6999355060581408 
2022-07-08 20:15:21,454: ============================================================
2022-07-08 20:15:21,454: Epoch 32/36 Batch 7600/7662 eta: 6:18:15.572835	Training Loss1 2.6685 (2.5671)	Training Total_Loss 2.6685 (2.5671)	Training Prec@1 99.414 (99.411)	Training Prec@5 0.000 (0.000)	
2022-07-08 20:15:21,454: ============================================================
2022-07-08 20:16:09,326: Epoch 32/36 Batch 7663/7662 eta: 6:17:29.015540	Training Loss1 2.6805 (2.5673)	Training Total_Loss 2.6805 (2.5673)	Training Prec@1 98.633 (99.410)	Training Prec@5 0.000 (0.000)	
2022-07-08 20:16:09,326: ============================================================
2022-07-08 20:16:09,412: Save Checkpoint...
2022-07-08 20:16:09,428: ============================================================
2022-07-08 20:16:11,519: Save done!
2022-07-08 20:16:11,519: ============================================================
2022-07-08 20:17:37,787: time cost, forward:0.011504910208962181, backward:0.03229249607432972, data cost:0.8222503108207626 
2022-07-08 20:17:37,788: ============================================================
2022-07-08 20:17:37,788: Epoch 33/36 Batch 100/7662 eta: 7:19:13.057081	Training Loss1 2.5840 (2.5400)	Training Total_Loss 2.5840 (2.5400)	Training Prec@1 98.828 (99.430)	Training Prec@5 0.000 (0.000)	
2022-07-08 20:17:37,788: ============================================================
2022-07-08 20:18:53,485: time cost, forward:0.011314043447599937, backward:0.0324773944202979, data cost:0.7671590474382717 
2022-07-08 20:18:53,485: ============================================================
2022-07-08 20:18:53,485: Epoch 33/36 Batch 200/7662 eta: 6:24:09.071445	Training Loss1 2.4410 (2.5484)	Training Total_Loss 2.4410 (2.5484)	Training Prec@1 99.414 (99.424)	Training Prec@5 0.000 (0.000)	
2022-07-08 20:18:53,485: ============================================================
2022-07-08 20:20:07,814: time cost, forward:0.0110845773116402, backward:0.032659807332782044, data cost:0.7444014804419068 
2022-07-08 20:20:07,814: ============================================================
2022-07-08 20:20:07,815: Epoch 33/36 Batch 300/7662 eta: 6:15:58.278683	Training Loss1 2.5179 (2.5393)	Training Total_Loss 2.5179 (2.5393)	Training Prec@1 98.828 (99.443)	Training Prec@5 0.000 (0.000)	
2022-07-08 20:20:07,815: ============================================================
2022-07-08 20:21:24,207: time cost, forward:0.011030623787327817, backward:0.03298046296102959, data cost:0.7379309222811744 
2022-07-08 20:21:24,207: ============================================================
2022-07-08 20:21:24,207: Epoch 33/36 Batch 400/7662 eta: 6:25:08.081972	Training Loss1 2.7811 (2.5427)	Training Total_Loss 2.7811 (2.5427)	Training Prec@1 98.828 (99.432)	Training Prec@5 0.000 (0.000)	
2022-07-08 20:21:24,208: ============================================================
2022-07-08 20:22:40,906: time cost, forward:0.010979363817967967, backward:0.03313565540887072, data cost:0.7347142299812638 
2022-07-08 20:22:40,907: ============================================================
2022-07-08 20:22:40,907: Epoch 33/36 Batch 500/7662 eta: 6:25:24.158229	Training Loss1 2.4586 (2.5403)	Training Total_Loss 2.4586 (2.5403)	Training Prec@1 99.414 (99.446)	Training Prec@5 0.000 (0.000)	
2022-07-08 20:22:40,907: ============================================================
2022-07-08 20:23:56,739: time cost, forward:0.010898545906818371, backward:0.03325724442534534, data cost:0.7311667822836238 
2022-07-08 20:23:56,739: ============================================================
2022-07-08 20:23:56,740: Epoch 33/36 Batch 600/7662 eta: 6:19:46.903191	Training Loss1 2.4374 (2.5391)	Training Total_Loss 2.4374 (2.5391)	Training Prec@1 99.805 (99.446)	Training Prec@5 0.000 (0.000)	
2022-07-08 20:23:56,740: ============================================================
2022-07-08 20:25:12,612: time cost, forward:0.010845386930801327, backward:0.03330992560870999, data cost:0.7287155340328407 
2022-07-08 20:25:12,612: ============================================================
2022-07-08 20:25:12,612: Epoch 33/36 Batch 700/7662 eta: 6:18:43.102063	Training Loss1 2.3365 (2.5370)	Training Total_Loss 2.3365 (2.5370)	Training Prec@1 100.000 (99.445)	Training Prec@5 0.000 (0.000)	
2022-07-08 20:25:12,612: ============================================================
2022-07-08 20:26:27,786: time cost, forward:0.010953461870234063, backward:0.03336496615738087, data cost:0.7258293566029421 
2022-07-08 20:26:27,786: ============================================================
2022-07-08 20:26:27,786: Epoch 33/36 Batch 800/7662 eta: 6:13:58.677304	Training Loss1 2.6005 (2.5357)	Training Total_Loss 2.6005 (2.5357)	Training Prec@1 99.414 (99.450)	Training Prec@5 0.000 (0.000)	
2022-07-08 20:26:27,786: ============================================================
2022-07-08 20:27:41,489: time cost, forward:0.010972012402085759, backward:0.03338301858063932, data cost:0.7220427162522601 
2022-07-08 20:27:41,490: ============================================================
2022-07-08 20:27:41,490: Epoch 33/36 Batch 900/7662 eta: 6:05:26.089405	Training Loss1 2.4388 (2.5371)	Training Total_Loss 2.4388 (2.5371)	Training Prec@1 99.414 (99.450)	Training Prec@5 0.000 (0.000)	
2022-07-08 20:27:41,490: ============================================================
2022-07-08 20:28:53,860: time cost, forward:0.011067337459988065, backward:0.033406264073139916, data cost:0.7175981191782145 
2022-07-08 20:28:53,860: ============================================================
2022-07-08 20:28:53,860: Epoch 33/36 Batch 1000/7662 eta: 5:57:37.058034	Training Loss1 2.6587 (2.5367)	Training Total_Loss 2.6587 (2.5367)	Training Prec@1 99.219 (99.449)	Training Prec@5 0.000 (0.000)	
2022-07-08 20:28:53,860: ============================================================
2022-07-08 20:30:07,336: time cost, forward:0.011127551541315414, backward:0.03342287490539273, data cost:0.7149727053811488 
2022-07-08 20:30:07,336: ============================================================
2022-07-08 20:30:07,337: Epoch 33/36 Batch 1100/7662 eta: 6:01:51.547465	Training Loss1 2.3871 (2.5370)	Training Total_Loss 2.3871 (2.5370)	Training Prec@1 99.609 (99.449)	Training Prec@5 0.000 (0.000)	
2022-07-08 20:30:07,337: ============================================================
2022-07-08 20:31:20,473: time cost, forward:0.011188538100343629, backward:0.03341643704882853, data cost:0.71252357571994 
2022-07-08 20:31:20,474: ============================================================
2022-07-08 20:31:20,474: Epoch 33/36 Batch 1200/7662 eta: 5:58:58.190703	Training Loss1 2.3821 (2.5363)	Training Total_Loss 2.3821 (2.5363)	Training Prec@1 99.219 (99.450)	Training Prec@5 0.000 (0.000)	
2022-07-08 20:31:20,474: ============================================================
2022-07-08 20:32:33,972: time cost, forward:0.011261179412301455, backward:0.03342755855827537, data cost:0.710669233580568 
2022-07-08 20:32:33,972: ============================================================
2022-07-08 20:32:33,973: Epoch 33/36 Batch 1300/7662 eta: 5:59:31.138333	Training Loss1 2.6084 (2.5379)	Training Total_Loss 2.6084 (2.5379)	Training Prec@1 98.828 (99.446)	Training Prec@5 0.000 (0.000)	
2022-07-08 20:32:33,973: ============================================================
2022-07-08 20:33:49,082: time cost, forward:0.011303151480379576, backward:0.03342397388515513, data cost:0.710288672212024 
2022-07-08 20:33:49,082: ============================================================
2022-07-08 20:33:49,083: Epoch 33/36 Batch 1400/7662 eta: 6:06:08.934678	Training Loss1 2.5916 (2.5387)	Training Total_Loss 2.5916 (2.5387)	Training Prec@1 99.414 (99.447)	Training Prec@5 0.000 (0.000)	
2022-07-08 20:33:49,083: ============================================================
2022-07-08 20:35:01,217: time cost, forward:0.01136672218455085, backward:0.03339673726856112, data cost:0.7079568380033914 
2022-07-08 20:35:01,218: ============================================================
2022-07-08 20:35:01,218: Epoch 33/36 Batch 1500/7662 eta: 5:50:26.758743	Training Loss1 2.5309 (2.5385)	Training Total_Loss 2.5309 (2.5385)	Training Prec@1 99.609 (99.450)	Training Prec@5 0.000 (0.000)	
2022-07-08 20:35:01,218: ============================================================
2022-07-08 20:36:13,817: time cost, forward:0.011422364394168246, backward:0.03336793754606265, data cost:0.7062122368529262 
2022-07-08 20:36:13,817: ============================================================
2022-07-08 20:36:13,817: Epoch 33/36 Batch 1600/7662 eta: 5:51:29.357333	Training Loss1 2.6588 (2.5393)	Training Total_Loss 2.6588 (2.5393)	Training Prec@1 99.414 (99.450)	Training Prec@5 0.000 (0.000)	
2022-07-08 20:36:13,817: ============================================================
2022-07-08 20:37:28,051: time cost, forward:0.011429244171106655, backward:0.033371836245235376, data cost:0.7056633121059388 
2022-07-08 20:37:28,052: ============================================================
2022-07-08 20:37:28,052: Epoch 33/36 Batch 1700/7662 eta: 5:58:10.201498	Training Loss1 2.5180 (2.5397)	Training Total_Loss 2.5180 (2.5397)	Training Prec@1 99.805 (99.448)	Training Prec@5 0.000 (0.000)	
2022-07-08 20:37:28,052: ============================================================
2022-07-08 20:38:40,634: time cost, forward:0.011457407984752135, backward:0.033337861713666, data cost:0.7042681509551239 
2022-07-08 20:38:40,634: ============================================================
2022-07-08 20:38:40,634: Epoch 33/36 Batch 1800/7662 eta: 5:48:59.312833	Training Loss1 2.8526 (2.5402)	Training Total_Loss 2.8526 (2.5402)	Training Prec@1 98.828 (99.447)	Training Prec@5 0.000 (0.000)	
2022-07-08 20:38:40,634: ============================================================
2022-07-08 20:39:54,003: time cost, forward:0.011473122617330847, backward:0.033336212410306605, data cost:0.7034030048517003 
2022-07-08 20:39:54,003: ============================================================
2022-07-08 20:39:54,003: Epoch 33/36 Batch 1900/7662 eta: 5:51:32.868809	Training Loss1 2.5335 (2.5406)	Training Total_Loss 2.5335 (2.5406)	Training Prec@1 100.000 (99.444)	Training Prec@5 0.000 (0.000)	
2022-07-08 20:39:54,004: ============================================================
2022-07-08 20:41:07,751: time cost, forward:0.011527260880043293, backward:0.0333654504826571, data cost:0.7027674949783393 
2022-07-08 20:41:07,751: ============================================================
2022-07-08 20:41:07,751: Epoch 33/36 Batch 2000/7662 eta: 5:52:08.052198	Training Loss1 2.6536 (2.5412)	Training Total_Loss 2.6536 (2.5412)	Training Prec@1 99.023 (99.444)	Training Prec@5 0.000 (0.000)	
2022-07-08 20:41:07,752: ============================================================
2022-07-08 20:42:20,618: time cost, forward:0.011552885636197436, backward:0.03339968629539893, data cost:0.7017736523534185 
2022-07-08 20:42:20,618: ============================================================
2022-07-08 20:42:20,619: Epoch 33/36 Batch 2100/7662 eta: 5:46:42.841720	Training Loss1 2.5352 (2.5412)	Training Total_Loss 2.5352 (2.5412)	Training Prec@1 99.609 (99.445)	Training Prec@5 0.000 (0.000)	
2022-07-08 20:42:20,619: ============================================================
2022-07-08 20:43:33,718: time cost, forward:0.011577502875612128, backward:0.03341863620492641, data cost:0.7009870417283958 
2022-07-08 20:43:33,718: ============================================================
2022-07-08 20:43:33,719: Epoch 33/36 Batch 2200/7662 eta: 5:46:36.239999	Training Loss1 2.5450 (2.5412)	Training Total_Loss 2.5450 (2.5412)	Training Prec@1 99.023 (99.445)	Training Prec@5 0.000 (0.000)	
2022-07-08 20:43:33,719: ============================================================
2022-07-08 20:44:48,696: time cost, forward:0.011605989212261796, backward:0.033386818063212455, data cost:0.7011348042813733 
2022-07-08 20:44:48,697: ============================================================
2022-07-08 20:44:48,697: Epoch 33/36 Batch 2300/7662 eta: 5:54:15.555848	Training Loss1 2.6645 (2.5416)	Training Total_Loss 2.6645 (2.5416)	Training Prec@1 99.219 (99.444)	Training Prec@5 0.000 (0.000)	
2022-07-08 20:44:48,697: ============================================================
2022-07-08 20:46:02,675: time cost, forward:0.011663582683752456, backward:0.03336948183686995, data cost:0.7008022598148933 
2022-07-08 20:46:02,676: ============================================================
2022-07-08 20:46:02,676: Epoch 33/36 Batch 2400/7662 eta: 5:48:18.316017	Training Loss1 2.5162 (2.5419)	Training Total_Loss 2.5162 (2.5419)	Training Prec@1 99.219 (99.444)	Training Prec@5 0.000 (0.000)	
2022-07-08 20:46:02,676: ============================================================
2022-07-08 20:47:15,675: time cost, forward:0.011652295233584156, backward:0.03334421594412912, data cost:0.7001676927713835 
2022-07-08 20:47:15,675: ============================================================
2022-07-08 20:47:15,675: Epoch 33/36 Batch 2500/7662 eta: 5:42:28.592286	Training Loss1 2.5442 (2.5422)	Training Total_Loss 2.5442 (2.5422)	Training Prec@1 99.219 (99.444)	Training Prec@5 0.000 (0.000)	
2022-07-08 20:47:15,675: ============================================================
2022-07-08 20:48:29,535: time cost, forward:0.011652813181596429, backward:0.033331351905843305, data cost:0.6999120940699767 
2022-07-08 20:48:29,536: ============================================================
2022-07-08 20:48:29,536: Epoch 33/36 Batch 2600/7662 eta: 5:45:17.242014	Training Loss1 2.6192 (2.5432)	Training Total_Loss 2.6192 (2.5432)	Training Prec@1 99.023 (99.443)	Training Prec@5 0.000 (0.000)	
2022-07-08 20:48:29,536: ============================================================
2022-07-08 20:49:42,111: time cost, forward:0.01164861536326343, backward:0.03332245239464165, data cost:0.6991957455663692 
2022-07-08 20:49:42,111: ============================================================
2022-07-08 20:49:42,111: Epoch 33/36 Batch 2700/7662 eta: 5:38:04.085184	Training Loss1 2.5029 (2.5433)	Training Total_Loss 2.5029 (2.5433)	Training Prec@1 99.414 (99.442)	Training Prec@5 0.000 (0.000)	
2022-07-08 20:49:42,111: ============================================================
2022-07-08 20:50:54,749: time cost, forward:0.011674319986532143, backward:0.03328789707250619, data cost:0.6985489713928451 
2022-07-08 20:50:54,749: ============================================================
2022-07-08 20:50:54,749: Epoch 33/36 Batch 2800/7662 eta: 5:37:08.968707	Training Loss1 2.4918 (2.5440)	Training Total_Loss 2.4918 (2.5440)	Training Prec@1 99.414 (99.441)	Training Prec@5 0.000 (0.000)	
2022-07-08 20:50:54,750: ============================================================
2022-07-08 20:52:08,684: time cost, forward:0.011685060689925489, backward:0.03326581584539608, data cost:0.6983969899941083 
2022-07-08 20:52:08,684: ============================================================
2022-07-08 20:52:08,685: Epoch 33/36 Batch 2900/7662 eta: 5:41:56.235373	Training Loss1 2.7971 (2.5448)	Training Total_Loss 2.7971 (2.5448)	Training Prec@1 99.609 (99.441)	Training Prec@5 0.000 (0.000)	
2022-07-08 20:52:08,685: ============================================================
2022-07-08 20:53:22,624: time cost, forward:0.011683987394576472, backward:0.03327097659033114, data cost:0.6982396001933455 
2022-07-08 20:53:22,625: ============================================================
2022-07-08 20:53:22,625: Epoch 33/36 Batch 3000/7662 eta: 5:40:43.743656	Training Loss1 2.6209 (2.5449)	Training Total_Loss 2.6209 (2.5449)	Training Prec@1 99.609 (99.441)	Training Prec@5 0.000 (0.000)	
2022-07-08 20:53:22,625: ============================================================
2022-07-08 20:54:35,794: time cost, forward:0.011696933353666568, backward:0.033262973217934935, data cost:0.6978437712054824 
2022-07-08 20:54:35,795: ============================================================
2022-07-08 20:54:35,795: Epoch 33/36 Batch 3100/7662 eta: 5:35:57.641022	Training Loss1 2.6980 (2.5452)	Training Total_Loss 2.6980 (2.5452)	Training Prec@1 99.023 (99.440)	Training Prec@5 0.000 (0.000)	
2022-07-08 20:54:35,795: ============================================================
2022-07-08 20:55:50,240: time cost, forward:0.011714866586907575, backward:0.033237288317929284, data cost:0.6978915196055359 
2022-07-08 20:55:50,241: ============================================================
2022-07-08 20:55:50,241: Epoch 33/36 Batch 3200/7662 eta: 5:40:34.698797	Training Loss1 2.6672 (2.5454)	Training Total_Loss 2.6672 (2.5454)	Training Prec@1 99.414 (99.439)	Training Prec@5 0.000 (0.000)	
2022-07-08 20:55:50,241: ============================================================
2022-07-08 20:57:03,475: time cost, forward:0.01173947536067263, backward:0.03321464071132155, data cost:0.6975497994216221 
2022-07-08 20:57:03,475: ============================================================
2022-07-08 20:57:03,475: Epoch 33/36 Batch 3300/7662 eta: 5:33:48.884020	Training Loss1 2.5126 (2.5459)	Training Total_Loss 2.5126 (2.5459)	Training Prec@1 99.609 (99.439)	Training Prec@5 0.000 (0.000)	
2022-07-08 20:57:03,475: ============================================================
2022-07-08 20:58:17,486: time cost, forward:0.011746288503257974, backward:0.033203583459497796, data cost:0.6974689001614783 
2022-07-08 20:58:17,486: ============================================================
2022-07-08 20:58:17,486: Epoch 33/36 Batch 3400/7662 eta: 5:36:07.267957	Training Loss1 2.5312 (2.5467)	Training Total_Loss 2.5312 (2.5467)	Training Prec@1 99.609 (99.438)	Training Prec@5 0.000 (0.000)	
2022-07-08 20:58:17,487: ============================================================
2022-07-08 20:59:31,449: time cost, forward:0.01176179937377389, backward:0.033230413399821995, data cost:0.6973285153103611 
2022-07-08 20:59:31,449: ============================================================
2022-07-08 20:59:31,449: Epoch 33/36 Batch 3500/7662 eta: 5:34:40.137342	Training Loss1 2.5004 (2.5471)	Training Total_Loss 2.5004 (2.5471)	Training Prec@1 99.805 (99.437)	Training Prec@5 0.000 (0.000)	
2022-07-08 20:59:31,449: ============================================================
2022-07-08 21:00:44,248: time cost, forward:0.011772700434560477, backward:0.03324660734190945, data cost:0.6968776070101124 
2022-07-08 21:00:44,249: ============================================================
2022-07-08 21:00:44,249: Epoch 33/36 Batch 3600/7662 eta: 5:28:11.550875	Training Loss1 2.5767 (2.5472)	Training Total_Loss 2.5767 (2.5472)	Training Prec@1 99.414 (99.438)	Training Prec@5 0.000 (0.000)	
2022-07-08 21:00:44,249: ============================================================
2022-07-08 21:01:58,183: time cost, forward:0.01179404882651208, backward:0.0332462643249256, data cost:0.696784053115659 
2022-07-08 21:01:58,183: ============================================================
2022-07-08 21:01:58,183: Epoch 33/36 Batch 3700/7662 eta: 5:32:04.654403	Training Loss1 2.7061 (2.5476)	Training Total_Loss 2.7061 (2.5476)	Training Prec@1 99.414 (99.438)	Training Prec@5 0.000 (0.000)	
2022-07-08 21:01:58,184: ============================================================
2022-07-08 21:03:11,309: time cost, forward:0.011778095829766121, backward:0.033235296132408276, data cost:0.6965138095088557 
2022-07-08 21:03:11,309: ============================================================
2022-07-08 21:03:11,310: Epoch 33/36 Batch 3800/7662 eta: 5:27:13.656180	Training Loss1 2.4687 (2.5474)	Training Total_Loss 2.4687 (2.5474)	Training Prec@1 98.633 (99.437)	Training Prec@5 0.000 (0.000)	
2022-07-08 21:03:11,310: ============================================================
2022-07-08 21:04:25,237: time cost, forward:0.011778697872137405, backward:0.03323960530510252, data cost:0.6964398104889511 
2022-07-08 21:04:25,238: ============================================================
2022-07-08 21:04:25,238: Epoch 33/36 Batch 3900/7662 eta: 5:29:35.176284	Training Loss1 2.8138 (2.5474)	Training Total_Loss 2.8138 (2.5474)	Training Prec@1 98.828 (99.436)	Training Prec@5 0.000 (0.000)	
2022-07-08 21:04:25,239: ============================================================
2022-07-08 21:05:39,989: time cost, forward:0.011787192766056505, backward:0.03325055813485308, data cost:0.6965565305258161 
2022-07-08 21:05:39,990: ============================================================
2022-07-08 21:05:39,990: Epoch 33/36 Batch 4000/7662 eta: 5:32:00.535974	Training Loss1 2.5584 (2.5480)	Training Total_Loss 2.5584 (2.5480)	Training Prec@1 99.609 (99.435)	Training Prec@5 0.000 (0.000)	
2022-07-08 21:05:39,990: ============================================================
2022-07-08 21:06:52,897: time cost, forward:0.01179644578141275, backward:0.033270458443393415, data cost:0.6962061193577398 
2022-07-08 21:06:52,897: ============================================================
2022-07-08 21:06:52,898: Epoch 33/36 Batch 4100/7662 eta: 5:22:36.265606	Training Loss1 2.6064 (2.5486)	Training Total_Loss 2.6064 (2.5486)	Training Prec@1 99.609 (99.435)	Training Prec@5 0.000 (0.000)	
2022-07-08 21:06:52,898: ============================================================
2022-07-08 21:08:07,841: time cost, forward:0.011797259551736678, backward:0.03327247102250937, data cost:0.6963833921095904 
2022-07-08 21:08:07,841: ============================================================
2022-07-08 21:08:07,842: Epoch 33/36 Batch 4200/7662 eta: 5:30:21.993486	Training Loss1 2.4310 (2.5493)	Training Total_Loss 2.4310 (2.5493)	Training Prec@1 99.609 (99.434)	Training Prec@5 0.000 (0.000)	
2022-07-08 21:08:07,842: ============================================================
2022-07-08 21:09:22,597: time cost, forward:0.01178811278058141, backward:0.03327868577629279, data cost:0.6965166732138549 
2022-07-08 21:09:22,597: ============================================================
2022-07-08 21:09:22,598: Epoch 33/36 Batch 4300/7662 eta: 5:28:17.408885	Training Loss1 2.5992 (2.5499)	Training Total_Loss 2.5992 (2.5499)	Training Prec@1 99.023 (99.434)	Training Prec@5 0.000 (0.000)	
2022-07-08 21:09:22,598: ============================================================
2022-07-08 21:10:37,348: time cost, forward:0.011803911447145637, backward:0.033318650210329176, data cost:0.6965764746608505 
2022-07-08 21:10:37,349: ============================================================
2022-07-08 21:10:37,349: Epoch 33/36 Batch 4400/7662 eta: 5:27:01.452616	Training Loss1 2.6554 (2.5502)	Training Total_Loss 2.6554 (2.5502)	Training Prec@1 99.609 (99.434)	Training Prec@5 0.000 (0.000)	
2022-07-08 21:10:37,349: ============================================================
2022-07-08 21:11:50,210: time cost, forward:0.011808300633037267, backward:0.03334513842516355, data cost:0.6962385204109146 
2022-07-08 21:11:50,210: ============================================================
2022-07-08 21:11:50,211: Epoch 33/36 Batch 4500/7662 eta: 5:17:32.609377	Training Loss1 2.8567 (2.5507)	Training Total_Loss 2.8567 (2.5507)	Training Prec@1 99.023 (99.434)	Training Prec@5 0.000 (0.000)	
2022-07-08 21:11:50,211: ============================================================
2022-07-08 21:13:03,595: time cost, forward:0.011826884152967532, backward:0.03331983092039091, data cost:0.6960755499271394 
2022-07-08 21:13:03,595: ============================================================
2022-07-08 21:13:03,596: Epoch 33/36 Batch 4600/7662 eta: 5:18:36.057530	Training Loss1 2.6563 (2.5513)	Training Total_Loss 2.6563 (2.5513)	Training Prec@1 98.633 (99.432)	Training Prec@5 0.000 (0.000)	
2022-07-08 21:13:03,596: ============================================================
2022-07-08 21:14:18,093: time cost, forward:0.011840458194304841, backward:0.03331588009211022, data cost:0.6961335211922499 
2022-07-08 21:14:18,093: ============================================================
2022-07-08 21:14:18,093: Epoch 33/36 Batch 4700/7662 eta: 5:22:11.461929	Training Loss1 2.4221 (2.5512)	Training Total_Loss 2.4221 (2.5512)	Training Prec@1 99.414 (99.431)	Training Prec@5 0.000 (0.000)	
2022-07-08 21:14:18,093: ============================================================
2022-07-08 21:15:31,443: time cost, forward:0.011843691420669381, backward:0.03330513208353115, data cost:0.6959621641978196 
2022-07-08 21:15:31,443: ============================================================
2022-07-08 21:15:31,443: Epoch 33/36 Batch 4800/7662 eta: 5:16:00.179045	Training Loss1 2.6672 (2.5519)	Training Total_Loss 2.6672 (2.5519)	Training Prec@1 99.414 (99.431)	Training Prec@5 0.000 (0.000)	
2022-07-08 21:15:31,443: ============================================================
2022-07-08 21:16:45,533: time cost, forward:0.01184391235667702, backward:0.033298395584738724, data cost:0.6959558321666075 
2022-07-08 21:16:45,534: ============================================================
2022-07-08 21:16:45,534: Epoch 33/36 Batch 4900/7662 eta: 5:17:57.671536	Training Loss1 2.6879 (2.5526)	Training Total_Loss 2.6879 (2.5526)	Training Prec@1 99.609 (99.430)	Training Prec@5 0.000 (0.000)	
2022-07-08 21:16:45,534: ============================================================
2022-07-08 21:17:59,713: time cost, forward:0.011851459723707436, backward:0.03329957187306907, data cost:0.6959451832612006 
2022-07-08 21:17:59,713: ============================================================
2022-07-08 21:17:59,714: Epoch 33/36 Batch 5000/7662 eta: 5:17:06.287873	Training Loss1 2.5854 (2.5528)	Training Total_Loss 2.5854 (2.5528)	Training Prec@1 99.805 (99.429)	Training Prec@5 0.000 (0.000)	
2022-07-08 21:17:59,714: ============================================================
2022-07-08 21:19:14,023: time cost, forward:0.011861931742301383, backward:0.0333135405763221, data cost:0.6959524408558533 
2022-07-08 21:19:14,024: ============================================================
2022-07-08 21:19:14,024: Epoch 33/36 Batch 5100/7662 eta: 5:16:25.525479	Training Loss1 2.5936 (2.5528)	Training Total_Loss 2.5936 (2.5528)	Training Prec@1 98.633 (99.429)	Training Prec@5 0.000 (0.000)	
2022-07-08 21:19:14,024: ============================================================
2022-07-08 21:20:27,626: time cost, forward:0.01186062441717824, backward:0.03332684709145762, data cost:0.6958310672424692 
2022-07-08 21:20:27,626: ============================================================
2022-07-08 21:20:27,626: Epoch 33/36 Batch 5200/7662 eta: 5:12:11.140807	Training Loss1 2.6188 (2.5529)	Training Total_Loss 2.6188 (2.5529)	Training Prec@1 99.805 (99.430)	Training Prec@5 0.000 (0.000)	
2022-07-08 21:20:27,627: ============================================================
2022-07-08 21:21:43,389: time cost, forward:0.011858999650418521, backward:0.03330789064096716, data cost:0.6961544872027655 
2022-07-08 21:21:43,389: ============================================================
2022-07-08 21:21:43,389: Epoch 33/36 Batch 5300/7662 eta: 5:20:05.147341	Training Loss1 2.4666 (2.5532)	Training Total_Loss 2.4666 (2.5532)	Training Prec@1 99.023 (99.430)	Training Prec@5 0.000 (0.000)	
2022-07-08 21:21:43,390: ============================================================
2022-07-08 21:22:57,417: time cost, forward:0.011856698618926126, backward:0.03331436464401898, data cost:0.6961197557217944 
2022-07-08 21:22:57,417: ============================================================
2022-07-08 21:22:57,418: Epoch 33/36 Batch 5400/7662 eta: 5:11:31.385975	Training Loss1 2.4513 (2.5534)	Training Total_Loss 2.4513 (2.5534)	Training Prec@1 99.023 (99.431)	Training Prec@5 0.000 (0.000)	
2022-07-08 21:22:57,418: ============================================================
2022-07-08 21:24:11,220: time cost, forward:0.011855929174039945, backward:0.03332340355287099, data cost:0.6960398882036752 
2022-07-08 21:24:11,220: ============================================================
2022-07-08 21:24:11,221: Epoch 33/36 Batch 5500/7662 eta: 5:09:20.673532	Training Loss1 2.4224 (2.5540)	Training Total_Loss 2.4224 (2.5540)	Training Prec@1 99.805 (99.430)	Training Prec@5 0.000 (0.000)	
2022-07-08 21:24:11,221: ============================================================
2022-07-08 21:25:25,256: time cost, forward:0.011849083034326656, backward:0.03332503788555109, data cost:0.6960170784258889 
2022-07-08 21:25:25,257: ============================================================
2022-07-08 21:25:25,257: Epoch 33/36 Batch 5600/7662 eta: 5:09:05.338738	Training Loss1 2.6734 (2.5542)	Training Total_Loss 2.6734 (2.5542)	Training Prec@1 99.609 (99.430)	Training Prec@5 0.000 (0.000)	
2022-07-08 21:25:25,257: ============================================================
2022-07-08 21:26:40,821: time cost, forward:0.011854710045938514, backward:0.033332094474306524, data cost:0.6962463567499153 
2022-07-08 21:26:40,822: ============================================================
2022-07-08 21:26:40,822: Epoch 33/36 Batch 5700/7662 eta: 5:14:12.789609	Training Loss1 2.4674 (2.5545)	Training Total_Loss 2.4674 (2.5545)	Training Prec@1 99.219 (99.429)	Training Prec@5 0.000 (0.000)	
2022-07-08 21:26:40,822: ============================================================
2022-07-08 21:27:56,105: time cost, forward:0.011857126021841555, backward:0.033342897943390466, data cost:0.6964248938691228 
2022-07-08 21:27:56,106: ============================================================
2022-07-08 21:27:56,106: Epoch 33/36 Batch 5800/7662 eta: 5:11:47.250876	Training Loss1 2.5807 (2.5550)	Training Total_Loss 2.5807 (2.5550)	Training Prec@1 99.805 (99.429)	Training Prec@5 0.000 (0.000)	
2022-07-08 21:27:56,106: ============================================================
2022-07-08 21:29:10,569: time cost, forward:0.011860988285202437, backward:0.033344719203412886, data cost:0.6964439110627395 
2022-07-08 21:29:10,569: ============================================================
2022-07-08 21:29:10,569: Epoch 33/36 Batch 5900/7662 eta: 5:07:09.013220	Training Loss1 2.4938 (2.5554)	Training Total_Loss 2.4938 (2.5554)	Training Prec@1 99.609 (99.429)	Training Prec@5 0.000 (0.000)	
2022-07-08 21:29:10,570: ============================================================
2022-07-08 21:30:24,956: time cost, forward:0.011853659107280107, backward:0.033350274610129925, data cost:0.6964871797547338 
2022-07-08 21:30:24,956: ============================================================
2022-07-08 21:30:24,956: Epoch 33/36 Batch 6000/7662 eta: 5:05:35.618741	Training Loss1 2.4893 (2.5557)	Training Total_Loss 2.4893 (2.5557)	Training Prec@1 99.609 (99.428)	Training Prec@5 0.000 (0.000)	
2022-07-08 21:30:24,956: ============================================================
2022-07-08 21:31:38,913: time cost, forward:0.011856854362631649, backward:0.0333517858837057, data cost:0.6964363576076249 
2022-07-08 21:31:38,914: ============================================================
2022-07-08 21:31:38,914: Epoch 33/36 Batch 6100/7662 eta: 5:02:35.846278	Training Loss1 2.4136 (2.5562)	Training Total_Loss 2.4136 (2.5562)	Training Prec@1 99.805 (99.427)	Training Prec@5 0.000 (0.000)	
2022-07-08 21:31:38,914: ============================================================
2022-07-08 21:32:52,017: time cost, forward:0.011848072406456805, backward:0.033354661102774914, data cost:0.6962623453886398 
2022-07-08 21:32:52,017: ============================================================
2022-07-08 21:32:52,017: Epoch 33/36 Batch 6200/7662 eta: 4:57:53.004214	Training Loss1 2.6734 (2.5564)	Training Total_Loss 2.6734 (2.5564)	Training Prec@1 99.414 (99.427)	Training Prec@5 0.000 (0.000)	
2022-07-08 21:32:52,017: ============================================================
2022-07-08 21:34:05,874: time cost, forward:0.011841358429175518, backward:0.033340035213101644, data cost:0.6962262924029006 
2022-07-08 21:34:05,874: ============================================================
2022-07-08 21:34:05,875: Epoch 33/36 Batch 6300/7662 eta: 4:59:43.553405	Training Loss1 2.6705 (2.5567)	Training Total_Loss 2.6705 (2.5567)	Training Prec@1 99.414 (99.426)	Training Prec@5 0.000 (0.000)	
2022-07-08 21:34:05,875: ============================================================
2022-07-08 21:35:21,337: time cost, forward:0.01184555589640433, backward:0.03333467654016432, data cost:0.6964234848621581 
2022-07-08 21:35:21,337: ============================================================
2022-07-08 21:35:21,338: Epoch 33/36 Batch 6400/7662 eta: 5:04:59.054335	Training Loss1 2.7486 (2.5573)	Training Total_Loss 2.7486 (2.5573)	Training Prec@1 99.219 (99.426)	Training Prec@5 0.000 (0.000)	
2022-07-08 21:35:21,338: ============================================================
2022-07-08 21:36:34,714: time cost, forward:0.011852932262464677, backward:0.03334255089373162, data cost:0.6962820368375131 
2022-07-08 21:36:34,715: ============================================================
2022-07-08 21:36:34,715: Epoch 33/36 Batch 6500/7662 eta: 4:55:19.839446	Training Loss1 2.5289 (2.5577)	Training Total_Loss 2.5289 (2.5577)	Training Prec@1 99.805 (99.425)	Training Prec@5 0.000 (0.000)	
2022-07-08 21:36:34,715: ============================================================
2022-07-08 21:37:50,819: time cost, forward:0.011855406695413741, backward:0.03334316858325443, data cost:0.6965641452970244 
2022-07-08 21:37:50,819: ============================================================
2022-07-08 21:37:50,820: Epoch 33/36 Batch 6600/7662 eta: 5:05:02.440195	Training Loss1 2.6382 (2.5581)	Training Total_Loss 2.6382 (2.5581)	Training Prec@1 99.609 (99.425)	Training Prec@5 0.000 (0.000)	
2022-07-08 21:37:50,820: ============================================================
2022-07-08 21:39:05,012: time cost, forward:0.011851722615070176, backward:0.03335240780906831, data cost:0.6965539530509086 
2022-07-08 21:39:05,013: ============================================================
2022-07-08 21:39:05,013: Epoch 33/36 Batch 6700/7662 eta: 4:56:08.537203	Training Loss1 2.5695 (2.5584)	Training Total_Loss 2.5695 (2.5584)	Training Prec@1 99.414 (99.426)	Training Prec@5 0.000 (0.000)	
2022-07-08 21:39:05,013: ============================================================
2022-07-08 21:40:18,953: time cost, forward:0.011850430204826587, backward:0.03334904288628431, data cost:0.696514209310243 
2022-07-08 21:40:18,953: ============================================================
2022-07-08 21:40:18,954: Epoch 33/36 Batch 6800/7662 eta: 4:53:54.160542	Training Loss1 2.6461 (2.5587)	Training Total_Loss 2.6461 (2.5587)	Training Prec@1 99.219 (99.425)	Training Prec@5 0.000 (0.000)	
2022-07-08 21:40:18,954: ============================================================
2022-07-08 21:41:33,234: time cost, forward:0.011855889444922102, backward:0.03334279391433488, data cost:0.6965258236224452 
2022-07-08 21:41:33,234: ============================================================
2022-07-08 21:41:33,235: Epoch 33/36 Batch 6900/7662 eta: 4:54:00.936459	Training Loss1 2.7256 (2.5590)	Training Total_Loss 2.7256 (2.5590)	Training Prec@1 99.609 (99.425)	Training Prec@5 0.000 (0.000)	
2022-07-08 21:41:33,235: ============================================================
2022-07-08 21:42:47,581: time cost, forward:0.011856375430069373, backward:0.0333394854387942, data cost:0.6965442768317118 
2022-07-08 21:42:47,581: ============================================================
2022-07-08 21:42:47,582: Epoch 33/36 Batch 7000/7662 eta: 4:53:02.337508	Training Loss1 2.5946 (2.5590)	Training Total_Loss 2.5946 (2.5590)	Training Prec@1 99.414 (99.425)	Training Prec@5 0.000 (0.000)	
2022-07-08 21:42:47,582: ============================================================
2022-07-08 21:44:01,675: time cost, forward:0.011861459959357671, backward:0.03333182915245451, data cost:0.6965217291427206 
2022-07-08 21:44:01,675: ============================================================
2022-07-08 21:44:01,675: Epoch 33/36 Batch 7100/7662 eta: 4:50:48.320344	Training Loss1 2.4826 (2.5594)	Training Total_Loss 2.4826 (2.5594)	Training Prec@1 99.219 (99.425)	Training Prec@5 0.000 (0.000)	
2022-07-08 21:44:01,675: ============================================================
2022-07-08 21:45:16,526: time cost, forward:0.011866102054361205, backward:0.03332225073210182, data cost:0.696616728581692 
2022-07-08 21:45:16,527: ============================================================
2022-07-08 21:45:16,527: Epoch 33/36 Batch 7200/7662 eta: 4:52:32.000866	Training Loss1 2.4198 (2.5590)	Training Total_Loss 2.4198 (2.5590)	Training Prec@1 99.609 (99.425)	Training Prec@5 0.000 (0.000)	
2022-07-08 21:45:16,527: ============================================================
2022-07-08 21:46:32,211: time cost, forward:0.01187061260686964, backward:0.03332293685257704, data cost:0.6968110172140025 
2022-07-08 21:46:32,211: ============================================================
2022-07-08 21:46:32,211: Epoch 33/36 Batch 7300/7662 eta: 4:54:31.457331	Training Loss1 2.5630 (2.5592)	Training Total_Loss 2.5630 (2.5592)	Training Prec@1 99.414 (99.424)	Training Prec@5 0.000 (0.000)	
2022-07-08 21:46:32,211: ============================================================
2022-07-08 21:47:46,604: time cost, forward:0.011873443346762113, backward:0.03331026748670631, data cost:0.6968374953815818 
2022-07-08 21:47:46,605: ============================================================
2022-07-08 21:47:46,605: Epoch 33/36 Batch 7400/7662 eta: 4:48:15.835464	Training Loss1 2.6542 (2.5593)	Training Total_Loss 2.6542 (2.5593)	Training Prec@1 99.219 (99.424)	Training Prec@5 0.000 (0.000)	
2022-07-08 21:47:46,605: ============================================================
2022-07-08 21:49:00,293: time cost, forward:0.01187980116200552, backward:0.03330392655666263, data cost:0.6967622769611774 
2022-07-08 21:49:00,294: ============================================================
2022-07-08 21:49:00,294: Epoch 33/36 Batch 7500/7662 eta: 4:44:18.285460	Training Loss1 2.3833 (2.5598)	Training Total_Loss 2.3833 (2.5598)	Training Prec@1 99.805 (99.423)	Training Prec@5 0.000 (0.000)	
2022-07-08 21:49:00,294: ============================================================
2022-07-08 21:50:14,870: time cost, forward:0.011885925160691776, backward:0.03331233730660032, data cost:0.6967896694791271 
2022-07-08 21:50:14,871: ============================================================
2022-07-08 21:50:14,871: Epoch 33/36 Batch 7600/7662 eta: 4:46:29.175224	Training Loss1 2.6490 (2.5601)	Training Total_Loss 2.6490 (2.5601)	Training Prec@1 99.414 (99.422)	Training Prec@5 0.000 (0.000)	
2022-07-08 21:50:14,871: ============================================================
2022-07-08 21:51:02,792: Epoch 33/36 Batch 7663/7662 eta: 4:45:42.191926	Training Loss1 2.6675 (2.5602)	Training Total_Loss 2.6675 (2.5602)	Training Prec@1 99.414 (99.422)	Training Prec@5 0.000 (0.000)	
2022-07-08 21:51:02,792: ============================================================
2022-07-08 21:51:02,911: Save Checkpoint...
2022-07-08 21:51:02,913: ============================================================
2022-07-08 21:51:05,669: Save done!
2022-07-08 21:51:05,670: ============================================================
2022-07-08 21:52:32,123: time cost, forward:0.011193345291445953, backward:0.03371569604584665, data cost:0.8224422811257719 
2022-07-08 21:52:32,123: ============================================================
2022-07-08 21:52:32,123: Epoch 34/36 Batch 100/7662 eta: 5:29:34.459640	Training Loss1 2.6557 (2.5344)	Training Total_Loss 2.6557 (2.5344)	Training Prec@1 99.609 (99.440)	Training Prec@5 0.000 (0.000)	
2022-07-08 21:52:32,124: ============================================================
2022-07-08 21:53:46,357: time cost, forward:0.010930662778154689, backward:0.033628412227534765, data cost:0.7596727519778151 
2022-07-08 21:53:46,357: ============================================================
2022-07-08 21:53:46,357: Epoch 34/36 Batch 200/7662 eta: 4:41:55.699997	Training Loss1 2.5790 (2.5410)	Training Total_Loss 2.5790 (2.5410)	Training Prec@1 98.828 (99.470)	Training Prec@5 0.000 (0.000)	
2022-07-08 21:53:46,358: ============================================================
2022-07-08 21:55:02,751: time cost, forward:0.010911528482086284, backward:0.03370861225702292, data cost:0.7458577355413533 
2022-07-08 21:55:02,751: ============================================================
2022-07-08 21:55:02,751: Epoch 34/36 Batch 300/7662 eta: 4:48:51.510524	Training Loss1 2.6695 (2.5370)	Training Total_Loss 2.6695 (2.5370)	Training Prec@1 99.023 (99.464)	Training Prec@5 0.000 (0.000)	
2022-07-08 21:55:02,752: ============================================================
2022-07-08 21:56:18,046: time cost, forward:0.010855623355186673, backward:0.03387308479251718, data cost:0.7362610630522993 
2022-07-08 21:56:18,046: ============================================================
2022-07-08 21:56:18,046: Epoch 34/36 Batch 400/7662 eta: 4:43:26.823454	Training Loss1 2.6314 (2.5336)	Training Total_Loss 2.6314 (2.5336)	Training Prec@1 99.414 (99.459)	Training Prec@5 0.000 (0.000)	
2022-07-08 21:56:18,046: ============================================================
2022-07-08 21:57:34,128: time cost, forward:0.010899244663949481, backward:0.03400805956853893, data cost:0.7319367557823777 
2022-07-08 21:57:34,128: ============================================================
2022-07-08 21:57:34,128: Epoch 34/36 Batch 500/7662 eta: 4:45:08.584864	Training Loss1 2.5096 (2.5348)	Training Total_Loss 2.5096 (2.5348)	Training Prec@1 99.414 (99.438)	Training Prec@5 0.000 (0.000)	
2022-07-08 21:57:34,128: ============================================================
2022-07-08 21:58:47,999: time cost, forward:0.010883354384433446, backward:0.03421582682104859, data cost:0.7252264627829219 
2022-07-08 21:58:47,999: ============================================================
2022-07-08 21:58:48,000: Epoch 34/36 Batch 600/7662 eta: 4:35:37.565258	Training Loss1 2.3040 (2.5323)	Training Total_Loss 2.3040 (2.5323)	Training Prec@1 99.219 (99.449)	Training Prec@5 0.000 (0.000)	
2022-07-08 21:58:48,000: ============================================================
2022-07-08 22:00:01,883: time cost, forward:0.010944821121696069, backward:0.03429194444921054, data cost:0.7205165537641796 
2022-07-08 22:00:01,883: ============================================================
2022-07-08 22:00:01,884: Epoch 34/36 Batch 700/7662 eta: 4:34:26.528263	Training Loss1 2.5023 (2.5345)	Training Total_Loss 2.5023 (2.5345)	Training Prec@1 99.023 (99.446)	Training Prec@5 0.000 (0.000)	
2022-07-08 22:00:01,884: ============================================================
2022-07-08 22:01:14,281: time cost, forward:0.011052289206035742, backward:0.03424116786340897, data cost:0.7151479682277827 
2022-07-08 22:01:14,282: ============================================================
2022-07-08 22:01:14,282: Epoch 34/36 Batch 800/7662 eta: 4:27:43.017418	Training Loss1 2.3979 (2.5366)	Training Total_Loss 2.3979 (2.5366)	Training Prec@1 99.609 (99.446)	Training Prec@5 0.000 (0.000)	
2022-07-08 22:01:14,282: ============================================================
2022-07-08 22:02:27,039: time cost, forward:0.011060045081065414, backward:0.0342160613173505, data cost:0.7114634442249845 
2022-07-08 22:02:27,040: ============================================================
2022-07-08 22:02:27,040: Epoch 34/36 Batch 900/7662 eta: 4:27:50.054856	Training Loss1 2.5297 (2.5372)	Training Total_Loss 2.5297 (2.5372)	Training Prec@1 99.219 (99.444)	Training Prec@5 0.000 (0.000)	
2022-07-08 22:02:27,040: ============================================================
2022-07-08 22:03:39,587: time cost, forward:0.011109333496551972, backward:0.0341194122283905, data cost:0.7083316539023612 
2022-07-08 22:03:39,588: ============================================================
2022-07-08 22:03:39,588: Epoch 34/36 Batch 1000/7662 eta: 4:25:51.163274	Training Loss1 2.4775 (2.5358)	Training Total_Loss 2.4775 (2.5358)	Training Prec@1 99.609 (99.445)	Training Prec@5 0.000 (0.000)	
2022-07-08 22:03:39,588: ============================================================
2022-07-08 22:04:53,703: time cost, forward:0.01112466795646244, backward:0.0341553143526447, data cost:0.7070810334914592 
2022-07-08 22:04:53,704: ============================================================
2022-07-08 22:04:53,704: Epoch 34/36 Batch 1100/7662 eta: 4:30:21.761757	Training Loss1 2.6092 (2.5357)	Training Total_Loss 2.6092 (2.5357)	Training Prec@1 99.609 (99.446)	Training Prec@5 0.000 (0.000)	
2022-07-08 22:04:53,704: ============================================================
2022-07-08 22:06:06,639: time cost, forward:0.011154795408845446, backward:0.034161155874078926, data cost:0.7050901099579646 
2022-07-08 22:06:06,640: ============================================================
2022-07-08 22:06:06,640: Epoch 34/36 Batch 1200/7662 eta: 4:24:50.538242	Training Loss1 2.5408 (2.5361)	Training Total_Loss 2.5408 (2.5361)	Training Prec@1 99.219 (99.451)	Training Prec@5 0.000 (0.000)	
2022-07-08 22:06:06,640: ============================================================
2022-07-08 22:07:18,805: time cost, forward:0.011203970332802765, backward:0.03410900694485166, data cost:0.7028411436851801 
2022-07-08 22:07:18,805: ============================================================
2022-07-08 22:07:18,806: Epoch 34/36 Batch 1300/7662 eta: 4:20:50.565009	Training Loss1 2.5956 (2.5379)	Training Total_Loss 2.5956 (2.5379)	Training Prec@1 100.000 (99.449)	Training Prec@5 0.000 (0.000)	
2022-07-08 22:07:18,806: ============================================================
2022-07-08 22:08:32,481: time cost, forward:0.011213877611794243, backward:0.0341026951706009, data cost:0.7019626421106978 
2022-07-08 22:08:32,481: ============================================================
2022-07-08 22:08:32,482: Epoch 34/36 Batch 1400/7662 eta: 4:25:04.454718	Training Loss1 2.5922 (2.5392)	Training Total_Loss 2.5922 (2.5392)	Training Prec@1 99.414 (99.449)	Training Prec@5 0.000 (0.000)	
2022-07-08 22:08:32,482: ============================================================
2022-07-08 22:09:45,904: time cost, forward:0.01126889724426066, backward:0.034113066605204655, data cost:0.7009999993803344 
2022-07-08 22:09:45,905: ============================================================
2022-07-08 22:09:45,905: Epoch 34/36 Batch 1500/7662 eta: 4:22:56.420625	Training Loss1 2.6654 (2.5396)	Training Total_Loss 2.6654 (2.5396)	Training Prec@1 99.023 (99.452)	Training Prec@5 0.000 (0.000)	
2022-07-08 22:09:45,905: ============================================================
2022-07-08 22:11:00,055: time cost, forward:0.0113032244383506, backward:0.034111874486745485, data cost:0.7006250608705445 
2022-07-08 22:11:00,055: ============================================================
2022-07-08 22:11:00,055: Epoch 34/36 Batch 1600/7662 eta: 4:24:18.561941	Training Loss1 2.3727 (2.5386)	Training Total_Loss 2.3727 (2.5386)	Training Prec@1 99.414 (99.451)	Training Prec@5 0.000 (0.000)	
2022-07-08 22:11:00,055: ============================================================
2022-07-08 22:12:12,891: time cost, forward:0.011360452201802847, backward:0.03410505729257675, data cost:0.699504516347848 
2022-07-08 22:12:12,892: ============================================================
2022-07-08 22:12:12,892: Epoch 34/36 Batch 1700/7662 eta: 4:18:24.707669	Training Loss1 2.5707 (2.5387)	Training Total_Loss 2.5707 (2.5387)	Training Prec@1 99.609 (99.452)	Training Prec@5 0.000 (0.000)	
2022-07-08 22:12:12,892: ============================================================
2022-07-08 22:13:25,961: time cost, forward:0.011414031309177638, backward:0.03414356145280941, data cost:0.6985813439588139 
2022-07-08 22:13:25,962: ============================================================
2022-07-08 22:13:25,962: Epoch 34/36 Batch 1800/7662 eta: 4:18:01.394430	Training Loss1 2.6334 (2.5391)	Training Total_Loss 2.6334 (2.5391)	Training Prec@1 99.414 (99.452)	Training Prec@5 0.000 (0.000)	
2022-07-08 22:13:25,962: ============================================================
2022-07-08 22:14:39,197: time cost, forward:0.01145180342635586, backward:0.03406086088545138, data cost:0.6979778099210718 
2022-07-08 22:14:39,198: ============================================================
2022-07-08 22:14:39,198: Epoch 34/36 Batch 1900/7662 eta: 4:17:23.269149	Training Loss1 2.4586 (2.5394)	Training Total_Loss 2.4586 (2.5394)	Training Prec@1 99.414 (99.453)	Training Prec@5 0.000 (0.000)	
2022-07-08 22:14:39,198: ============================================================
2022-07-08 22:15:52,583: time cost, forward:0.011503593512568968, backward:0.033993710393366544, data cost:0.6974723033752365 
2022-07-08 22:15:52,583: ============================================================
2022-07-08 22:15:52,584: Epoch 34/36 Batch 2000/7662 eta: 4:16:41.435240	Training Loss1 2.5773 (2.5393)	Training Total_Loss 2.5773 (2.5393)	Training Prec@1 99.805 (99.451)	Training Prec@5 0.000 (0.000)	
2022-07-08 22:15:52,584: ============================================================
2022-07-08 22:17:06,819: time cost, forward:0.011517616383742013, backward:0.033974970449090515, data cost:0.6974115389877981 
2022-07-08 22:17:06,820: ============================================================
2022-07-08 22:17:06,820: Epoch 34/36 Batch 2100/7662 eta: 4:18:25.712674	Training Loss1 2.5767 (2.5395)	Training Total_Loss 2.5767 (2.5395)	Training Prec@1 99.023 (99.449)	Training Prec@5 0.000 (0.000)	
2022-07-08 22:17:06,820: ============================================================
2022-07-08 22:18:20,205: time cost, forward:0.011530702468643085, backward:0.03396289367033927, data cost:0.6969836660274976 
2022-07-08 22:18:20,206: ============================================================
2022-07-08 22:18:20,206: Epoch 34/36 Batch 2200/7662 eta: 4:14:14.743194	Training Loss1 2.6597 (2.5404)	Training Total_Loss 2.6597 (2.5404)	Training Prec@1 99.609 (99.446)	Training Prec@5 0.000 (0.000)	
2022-07-08 22:18:20,206: ============================================================
2022-07-08 22:19:34,345: time cost, forward:0.01153579874109216, backward:0.03396850712872838, data cost:0.6968916593919168 
2022-07-08 22:19:34,345: ============================================================
2022-07-08 22:19:34,346: Epoch 34/36 Batch 2300/7662 eta: 4:15:37.319084	Training Loss1 2.4400 (2.5410)	Training Total_Loss 2.4400 (2.5410)	Training Prec@1 99.219 (99.445)	Training Prec@5 0.000 (0.000)	
2022-07-08 22:19:34,346: ============================================================
2022-07-08 22:20:46,660: time cost, forward:0.011573095627753324, backward:0.03395353858298985, data cost:0.6960489094977877 
2022-07-08 22:20:46,661: ============================================================
2022-07-08 22:20:46,661: Epoch 34/36 Batch 2400/7662 eta: 4:08:07.528721	Training Loss1 2.6528 (2.5420)	Training Total_Loss 2.6528 (2.5420)	Training Prec@1 99.023 (99.444)	Training Prec@5 0.000 (0.000)	
2022-07-08 22:20:46,661: ============================================================
2022-07-08 22:22:01,118: time cost, forward:0.01158539587710084, backward:0.033947495376171706, data cost:0.6961447967439234 
2022-07-08 22:22:01,118: ============================================================
2022-07-08 22:22:01,119: Epoch 34/36 Batch 2500/7662 eta: 4:14:14.148709	Training Loss1 2.4938 (2.5426)	Training Total_Loss 2.4938 (2.5426)	Training Prec@1 99.414 (99.441)	Training Prec@5 0.000 (0.000)	
2022-07-08 22:22:01,119: ============================================================
2022-07-08 22:23:14,921: time cost, forward:0.011609514110957076, backward:0.03395168411589531, data cost:0.695954719934614 
2022-07-08 22:23:14,921: ============================================================
2022-07-08 22:23:14,922: Epoch 34/36 Batch 2600/7662 eta: 4:10:46.229853	Training Loss1 2.5074 (2.5427)	Training Total_Loss 2.5074 (2.5427)	Training Prec@1 99.609 (99.441)	Training Prec@5 0.000 (0.000)	
2022-07-08 22:23:14,922: ============================================================
2022-07-08 22:24:28,863: time cost, forward:0.011614289801400782, backward:0.0339332482866907, data cost:0.6958653509903944 
2022-07-08 22:24:28,864: ============================================================
2022-07-08 22:24:28,864: Epoch 34/36 Batch 2700/7662 eta: 4:10:00.686219	Training Loss1 2.5571 (2.5428)	Training Total_Loss 2.5571 (2.5428)	Training Prec@1 99.609 (99.441)	Training Prec@5 0.000 (0.000)	
2022-07-08 22:24:28,864: ============================================================
2022-07-08 22:25:42,731: time cost, forward:0.011642325559059353, backward:0.03396544630248958, data cost:0.6956840667949484 
2022-07-08 22:25:42,731: ============================================================
2022-07-08 22:25:42,732: Epoch 34/36 Batch 2800/7662 eta: 4:08:31.665785	Training Loss1 2.4150 (2.5428)	Training Total_Loss 2.4150 (2.5428)	Training Prec@1 99.219 (99.443)	Training Prec@5 0.000 (0.000)	
2022-07-08 22:25:42,732: ============================================================
2022-07-08 22:26:55,202: time cost, forward:0.01164197897080431, backward:0.03397031083687621, data cost:0.6950851766435637 
2022-07-08 22:26:55,202: ============================================================
2022-07-08 22:26:55,202: Epoch 34/36 Batch 2900/7662 eta: 4:02:37.151105	Training Loss1 2.4867 (2.5433)	Training Total_Loss 2.4867 (2.5433)	Training Prec@1 99.414 (99.443)	Training Prec@5 0.000 (0.000)	
2022-07-08 22:26:55,202: ============================================================
2022-07-08 22:28:10,802: time cost, forward:0.011649956501257662, backward:0.03396636551719938, data cost:0.6955730693266368 
2022-07-08 22:28:10,803: ============================================================
2022-07-08 22:28:10,803: Epoch 34/36 Batch 3000/7662 eta: 4:11:50.327662	Training Loss1 2.5633 (2.5437)	Training Total_Loss 2.5633 (2.5437)	Training Prec@1 99.609 (99.443)	Training Prec@5 0.000 (0.000)	
2022-07-08 22:28:10,803: ============================================================
2022-07-08 22:29:24,874: time cost, forward:0.01164721788687643, backward:0.03398166606025413, data cost:0.6955293075005137 
2022-07-08 22:29:24,875: ============================================================
2022-07-08 22:29:24,875: Epoch 34/36 Batch 3100/7662 eta: 4:05:30.680438	Training Loss1 2.5312 (2.5438)	Training Total_Loss 2.5312 (2.5438)	Training Prec@1 99.609 (99.443)	Training Prec@5 0.000 (0.000)	
2022-07-08 22:29:24,875: ============================================================
2022-07-08 22:30:37,413: time cost, forward:0.01167926731687965, backward:0.03398986927007429, data cost:0.6949749954345265 
2022-07-08 22:30:37,413: ============================================================
2022-07-08 22:30:37,413: Epoch 34/36 Batch 3200/7662 eta: 3:59:13.217965	Training Loss1 2.2768 (2.5444)	Training Total_Loss 2.2768 (2.5444)	Training Prec@1 100.000 (99.442)	Training Prec@5 0.000 (0.000)	
2022-07-08 22:30:37,414: ============================================================
2022-07-08 22:31:50,624: time cost, forward:0.011702902572160058, backward:0.03396647400695579, data cost:0.6946950088164487 
2022-07-08 22:31:50,624: ============================================================
2022-07-08 22:31:50,625: Epoch 34/36 Batch 3300/7662 eta: 4:00:13.071201	Training Loss1 2.6137 (2.5439)	Training Total_Loss 2.6137 (2.5439)	Training Prec@1 99.414 (99.442)	Training Prec@5 0.000 (0.000)	
2022-07-08 22:31:50,625: ============================================================
2022-07-08 22:33:04,414: time cost, forward:0.011713033495457182, backward:0.033963761143068524, data cost:0.69459689606916 
2022-07-08 22:33:04,414: ============================================================
2022-07-08 22:33:04,414: Epoch 34/36 Batch 3400/7662 eta: 4:00:53.182895	Training Loss1 2.4505 (2.5439)	Training Total_Loss 2.4505 (2.5439)	Training Prec@1 99.414 (99.441)	Training Prec@5 0.000 (0.000)	
2022-07-08 22:33:04,414: ============================================================
2022-07-08 22:34:18,032: time cost, forward:0.011717996245692478, backward:0.0339637082724886, data cost:0.6944600802620808 
2022-07-08 22:34:18,033: ============================================================
2022-07-08 22:34:18,033: Epoch 34/36 Batch 3500/7662 eta: 3:59:06.029614	Training Loss1 2.5697 (2.5442)	Training Total_Loss 2.5697 (2.5442)	Training Prec@1 98.828 (99.439)	Training Prec@5 0.000 (0.000)	
2022-07-08 22:34:18,033: ============================================================
2022-07-08 22:35:31,202: time cost, forward:0.011725306146573477, backward:0.033966921209858406, data cost:0.6941984521246314 
2022-07-08 22:35:31,203: ============================================================
2022-07-08 22:35:31,203: Epoch 34/36 Batch 3600/7662 eta: 3:56:25.521949	Training Loss1 2.5559 (2.5441)	Training Total_Loss 2.5559 (2.5441)	Training Prec@1 99.805 (99.439)	Training Prec@5 0.000 (0.000)	
2022-07-08 22:35:31,203: ============================================================
2022-07-08 22:36:44,772: time cost, forward:0.011750346230442184, backward:0.033959682002587074, data cost:0.6940525862035574 
2022-07-08 22:36:44,772: ============================================================
2022-07-08 22:36:44,773: Epoch 34/36 Batch 3700/7662 eta: 3:56:29.367485	Training Loss1 2.4867 (2.5445)	Training Total_Loss 2.4867 (2.5445)	Training Prec@1 99.414 (99.439)	Training Prec@5 0.000 (0.000)	
2022-07-08 22:36:44,773: ============================================================
2022-07-08 22:37:57,989: time cost, forward:0.011762413422538595, backward:0.03395980846006389, data cost:0.6938110940485887 
2022-07-08 22:37:57,989: ============================================================
2022-07-08 22:37:57,989: Epoch 34/36 Batch 3800/7662 eta: 3:54:08.102928	Training Loss1 2.4710 (2.5442)	Training Total_Loss 2.4710 (2.5442)	Training Prec@1 99.219 (99.438)	Training Prec@5 0.000 (0.000)	
2022-07-08 22:37:57,989: ============================================================
2022-07-08 22:39:11,498: time cost, forward:0.011759928844928375, backward:0.03397563042534287, data cost:0.6936696544920185 
2022-07-08 22:39:11,499: ============================================================
2022-07-08 22:39:11,499: Epoch 34/36 Batch 3900/7662 eta: 3:53:50.731512	Training Loss1 2.5098 (2.5449)	Training Total_Loss 2.5098 (2.5449)	Training Prec@1 99.609 (99.439)	Training Prec@5 0.000 (0.000)	
2022-07-08 22:39:11,499: ============================================================
2022-07-08 22:40:24,206: time cost, forward:0.011753638168071682, backward:0.033966473383616136, data cost:0.693368056262246 
2022-07-08 22:40:24,206: ============================================================
2022-07-08 22:40:24,207: Epoch 34/36 Batch 4000/7662 eta: 3:50:05.024582	Training Loss1 2.5465 (2.5454)	Training Total_Loss 2.5465 (2.5454)	Training Prec@1 98.828 (99.438)	Training Prec@5 0.000 (0.000)	
2022-07-08 22:40:24,207: ============================================================
2022-07-08 22:41:37,302: time cost, forward:0.011742254035244282, backward:0.03395128820139654, data cost:0.693184009090404 
2022-07-08 22:41:37,302: ============================================================
2022-07-08 22:41:37,302: Epoch 34/36 Batch 4100/7662 eta: 3:50:05.573786	Training Loss1 2.6308 (2.5458)	Training Total_Loss 2.6308 (2.5458)	Training Prec@1 99.414 (99.438)	Training Prec@5 0.000 (0.000)	
2022-07-08 22:41:37,302: ============================================================
2022-07-08 22:42:49,375: time cost, forward:0.011719065639171524, backward:0.03392018622289132, data cost:0.6927895216068559 
2022-07-08 22:42:49,375: ============================================================
2022-07-08 22:42:49,375: Epoch 34/36 Batch 4200/7662 eta: 3:45:40.368118	Training Loss1 2.4940 (2.5461)	Training Total_Loss 2.4940 (2.5461)	Training Prec@1 99.414 (99.438)	Training Prec@5 0.000 (0.000)	
2022-07-08 22:42:49,375: ============================================================
2022-07-08 22:44:02,736: time cost, forward:0.011722894900619887, backward:0.03392586327619568, data cost:0.6926546173889877 
2022-07-08 22:44:02,736: ============================================================
2022-07-08 22:44:02,737: Epoch 34/36 Batch 4300/7662 eta: 3:48:29.040476	Training Loss1 2.5125 (2.5468)	Training Total_Loss 2.5125 (2.5468)	Training Prec@1 99.414 (99.438)	Training Prec@5 0.000 (0.000)	
2022-07-08 22:44:02,737: ============================================================
2022-07-08 22:45:16,509: time cost, forward:0.011734451210263046, backward:0.03392594861669902, data cost:0.69261684404717 
2022-07-08 22:45:16,509: ============================================================
2022-07-08 22:45:16,509: Epoch 34/36 Batch 4400/7662 eta: 3:48:32.135396	Training Loss1 2.3973 (2.5467)	Training Total_Loss 2.3973 (2.5467)	Training Prec@1 99.609 (99.438)	Training Prec@5 0.000 (0.000)	
2022-07-08 22:45:16,509: ============================================================
2022-07-08 22:46:30,061: time cost, forward:0.01174819556891481, backward:0.03393615736222633, data cost:0.6925172944099645 
2022-07-08 22:46:30,061: ============================================================
2022-07-08 22:46:30,061: Epoch 34/36 Batch 4500/7662 eta: 3:46:37.579097	Training Loss1 2.5028 (2.5468)	Training Total_Loss 2.5028 (2.5468)	Training Prec@1 99.414 (99.436)	Training Prec@5 0.000 (0.000)	
2022-07-08 22:46:30,062: ============================================================
2022-07-08 22:47:42,871: time cost, forward:0.011773740760552725, backward:0.03394152361767581, data cost:0.6922530075030939 
2022-07-08 22:47:42,872: ============================================================
2022-07-08 22:47:42,872: Epoch 34/36 Batch 4600/7662 eta: 3:43:07.665829	Training Loss1 2.5846 (2.5473)	Training Total_Loss 2.5846 (2.5473)	Training Prec@1 99.414 (99.435)	Training Prec@5 0.000 (0.000)	
2022-07-08 22:47:42,872: ============================================================
2022-07-08 22:48:57,670: time cost, forward:0.01177456298263105, backward:0.03394001315162141, data cost:0.6924583714524338 
2022-07-08 22:48:57,670: ============================================================
2022-07-08 22:48:57,670: Epoch 34/36 Batch 4700/7662 eta: 3:47:58.361071	Training Loss1 2.6192 (2.5475)	Training Total_Loss 2.6192 (2.5475)	Training Prec@1 99.219 (99.435)	Training Prec@5 0.000 (0.000)	
2022-07-08 22:48:57,670: ============================================================
2022-07-08 22:50:12,143: time cost, forward:0.011771996584155207, backward:0.03393402182079648, data cost:0.6925891532230238 
2022-07-08 22:50:12,144: ============================================================
2022-07-08 22:50:12,144: Epoch 34/36 Batch 4800/7662 eta: 3:45:44.541454	Training Loss1 2.5560 (2.5476)	Training Total_Loss 2.5560 (2.5476)	Training Prec@1 99.414 (99.435)	Training Prec@5 0.000 (0.000)	
2022-07-08 22:50:12,144: ============================================================
2022-07-08 22:51:25,515: time cost, forward:0.011767661481469134, backward:0.033935885547155945, data cost:0.6924872616890329 
2022-07-08 22:51:25,515: ============================================================
2022-07-08 22:51:25,516: Epoch 34/36 Batch 4900/7662 eta: 3:41:10.711962	Training Loss1 2.4547 (2.5476)	Training Total_Loss 2.4547 (2.5476)	Training Prec@1 99.805 (99.436)	Training Prec@5 0.000 (0.000)	
2022-07-08 22:51:25,516: ============================================================
2022-07-08 22:52:38,660: time cost, forward:0.011763226678309905, backward:0.033935504284923756, data cost:0.692344844377048 
2022-07-08 22:52:38,660: ============================================================
2022-07-08 22:52:38,660: Epoch 34/36 Batch 5000/7662 eta: 3:39:16.532867	Training Loss1 2.5764 (2.5483)	Training Total_Loss 2.5764 (2.5483)	Training Prec@1 99.805 (99.435)	Training Prec@5 0.000 (0.000)	
2022-07-08 22:52:38,660: ============================================================
2022-07-08 22:53:52,045: time cost, forward:0.011775921830758788, backward:0.033927581104069834, data cost:0.6922478489745807 
2022-07-08 22:53:52,045: ============================================================
2022-07-08 22:53:52,045: Epoch 34/36 Batch 5100/7662 eta: 3:38:46.337463	Training Loss1 2.4659 (2.5485)	Training Total_Loss 2.4659 (2.5485)	Training Prec@1 99.414 (99.434)	Training Prec@5 0.000 (0.000)	
2022-07-08 22:53:52,045: ============================================================
2022-07-08 22:55:05,779: time cost, forward:0.011785506835280072, backward:0.03391274435516962, data cost:0.6922305972100589 
2022-07-08 22:55:05,780: ============================================================
2022-07-08 22:55:05,780: Epoch 34/36 Batch 5200/7662 eta: 3:38:35.228698	Training Loss1 2.6736 (2.5486)	Training Total_Loss 2.6736 (2.5486)	Training Prec@1 99.023 (99.433)	Training Prec@5 0.000 (0.000)	
2022-07-08 22:55:05,780: ============================================================
2022-07-08 22:56:19,735: time cost, forward:0.011810015723218915, backward:0.03391624932290024, data cost:0.6922187447030491 
2022-07-08 22:56:19,736: ============================================================
2022-07-08 22:56:19,736: Epoch 34/36 Batch 5300/7662 eta: 3:38:00.620802	Training Loss1 2.3208 (2.5490)	Training Total_Loss 2.3208 (2.5490)	Training Prec@1 100.000 (99.434)	Training Prec@5 0.000 (0.000)	
2022-07-08 22:56:19,736: ============================================================
2022-07-08 22:57:33,303: time cost, forward:0.011827072273207761, backward:0.033919262563681066, data cost:0.6921447320080705 
2022-07-08 22:57:33,304: ============================================================
2022-07-08 22:57:33,304: Epoch 34/36 Batch 5400/7662 eta: 3:35:38.353354	Training Loss1 2.7551 (2.5494)	Training Total_Loss 2.7551 (2.5494)	Training Prec@1 99.609 (99.432)	Training Prec@5 0.000 (0.000)	
2022-07-08 22:57:33,304: ============================================================
2022-07-08 22:58:48,350: time cost, forward:0.011840095908495702, backward:0.033904516647069706, data cost:0.6923671288151246 
2022-07-08 22:58:48,350: ============================================================
2022-07-08 22:58:48,350: Epoch 34/36 Batch 5500/7662 eta: 3:38:43.414636	Training Loss1 2.3202 (2.5495)	Training Total_Loss 2.3202 (2.5495)	Training Prec@1 99.609 (99.431)	Training Prec@5 0.000 (0.000)	
2022-07-08 22:58:48,351: ============================================================
2022-07-08 23:00:03,325: time cost, forward:0.011848577113423226, backward:0.033911844857528094, data cost:0.6925455212784699 
2022-07-08 23:00:03,326: ============================================================
2022-07-08 23:00:03,326: Epoch 34/36 Batch 5600/7662 eta: 3:37:15.998950	Training Loss1 2.7789 (2.5503)	Training Total_Loss 2.7789 (2.5503)	Training Prec@1 99.023 (99.431)	Training Prec@5 0.000 (0.000)	
2022-07-08 23:00:03,326: ============================================================
2022-07-08 23:01:17,508: time cost, forward:0.011855803826207089, backward:0.03391721027318711, data cost:0.6925846343919841 
2022-07-08 23:01:17,508: ============================================================
2022-07-08 23:01:17,509: Epoch 34/36 Batch 5700/7662 eta: 3:33:43.943552	Training Loss1 2.5245 (2.5502)	Training Total_Loss 2.5245 (2.5502)	Training Prec@1 99.414 (99.431)	Training Prec@5 0.000 (0.000)	
2022-07-08 23:01:17,509: ============================================================
2022-07-08 23:02:32,308: time cost, forward:0.011854411980513355, backward:0.0339211037003145, data cost:0.6927393311199432 
2022-07-08 23:02:32,308: ============================================================
2022-07-08 23:02:32,309: Epoch 34/36 Batch 5800/7662 eta: 3:34:15.889924	Training Loss1 2.7048 (2.5504)	Training Total_Loss 2.7048 (2.5504)	Training Prec@1 99.414 (99.431)	Training Prec@5 0.000 (0.000)	
2022-07-08 23:02:32,309: ============================================================
2022-07-08 23:03:45,551: time cost, forward:0.011846225005850022, backward:0.033925618452831006, data cost:0.6926291450885903 
2022-07-08 23:03:45,551: ============================================================
2022-07-08 23:03:45,551: Epoch 34/36 Batch 5900/7662 eta: 3:28:34.939957	Training Loss1 2.6874 (2.5508)	Training Total_Loss 2.6874 (2.5508)	Training Prec@1 99.609 (99.431)	Training Prec@5 0.000 (0.000)	
2022-07-08 23:03:45,551: ============================================================
2022-07-08 23:04:59,755: time cost, forward:0.011844272553115948, backward:0.033933478288798356, data cost:0.6926737586385628 
2022-07-08 23:04:59,756: ============================================================
2022-07-08 23:04:59,756: Epoch 34/36 Batch 6000/7662 eta: 3:30:05.180819	Training Loss1 2.7031 (2.5511)	Training Total_Loss 2.7031 (2.5511)	Training Prec@1 99.414 (99.431)	Training Prec@5 0.000 (0.000)	
2022-07-08 23:04:59,756: ============================================================
2022-07-08 23:06:13,739: time cost, forward:0.011852482260788322, backward:0.03393314048528163, data cost:0.6926741215377035 
2022-07-08 23:06:13,739: ============================================================
2022-07-08 23:06:13,739: Epoch 34/36 Batch 6100/7662 eta: 3:28:13.509780	Training Loss1 2.6543 (2.5514)	Training Total_Loss 2.6543 (2.5514)	Training Prec@1 99.609 (99.432)	Training Prec@5 0.000 (0.000)	
2022-07-08 23:06:13,739: ============================================================
2022-07-08 23:07:27,918: time cost, forward:0.011851752490877316, backward:0.03394097000346066, data cost:0.6927185557430493 
2022-07-08 23:07:27,918: ============================================================
2022-07-08 23:07:27,919: Epoch 34/36 Batch 6200/7662 eta: 3:27:32.508120	Training Loss1 2.6373 (2.5515)	Training Total_Loss 2.6373 (2.5515)	Training Prec@1 99.805 (99.431)	Training Prec@5 0.000 (0.000)	
2022-07-08 23:07:27,919: ============================================================
2022-07-08 23:08:42,224: time cost, forward:0.011847461475457705, backward:0.03394408770299446, data cost:0.6927769411970914 
2022-07-08 23:08:42,225: ============================================================
2022-07-08 23:08:42,225: Epoch 34/36 Batch 6300/7662 eta: 3:26:39.526961	Training Loss1 2.4811 (2.5517)	Training Total_Loss 2.4811 (2.5517)	Training Prec@1 99.805 (99.431)	Training Prec@5 0.000 (0.000)	
2022-07-08 23:08:42,225: ============================================================
2022-07-08 23:09:55,976: time cost, forward:0.011854557157177575, backward:0.033943642487952924, data cost:0.6927475856233154 
2022-07-08 23:09:55,977: ============================================================
2022-07-08 23:09:55,977: Epoch 34/36 Batch 6400/7662 eta: 3:23:53.227765	Training Loss1 2.6914 (2.5521)	Training Total_Loss 2.6914 (2.5521)	Training Prec@1 99.023 (99.429)	Training Prec@5 0.000 (0.000)	
2022-07-08 23:09:55,977: ============================================================
2022-07-08 23:11:10,021: time cost, forward:0.011850926523521177, backward:0.03394172781888366, data cost:0.6927728658090061 
2022-07-08 23:11:10,022: ============================================================
2022-07-08 23:11:10,022: Epoch 34/36 Batch 6500/7662 eta: 3:23:27.795979	Training Loss1 2.4172 (2.5523)	Training Total_Loss 2.4172 (2.5523)	Training Prec@1 99.219 (99.429)	Training Prec@5 0.000 (0.000)	
2022-07-08 23:11:10,022: ============================================================
2022-07-08 23:12:23,792: time cost, forward:0.01185160124730045, backward:0.03393136557168465, data cost:0.692761163094456 
2022-07-08 23:12:23,793: ============================================================
2022-07-08 23:12:23,793: Epoch 34/36 Batch 6600/7662 eta: 3:21:28.843597	Training Loss1 2.5072 (2.5526)	Training Total_Loss 2.5072 (2.5526)	Training Prec@1 99.414 (99.429)	Training Prec@5 0.000 (0.000)	
2022-07-08 23:12:23,793: ============================================================
2022-07-08 23:13:38,203: time cost, forward:0.011855530834924037, backward:0.03392267426477829, data cost:0.692841771610247 
2022-07-08 23:13:38,204: ============================================================
2022-07-08 23:13:38,204: Epoch 34/36 Batch 6700/7662 eta: 3:21:59.318135	Training Loss1 2.5940 (2.5525)	Training Total_Loss 2.5940 (2.5525)	Training Prec@1 98.828 (99.429)	Training Prec@5 0.000 (0.000)	
2022-07-08 23:13:38,204: ============================================================
2022-07-08 23:14:53,303: time cost, forward:0.011862569634467999, backward:0.033916643357027945, data cost:0.6930069168063889 
2022-07-08 23:14:53,304: ============================================================
2022-07-08 23:14:53,304: Epoch 34/36 Batch 6800/7662 eta: 3:22:36.414099	Training Loss1 2.4824 (2.5527)	Training Total_Loss 2.4824 (2.5527)	Training Prec@1 99.609 (99.428)	Training Prec@5 0.000 (0.000)	
2022-07-08 23:14:53,304: ============================================================
2022-07-08 23:16:08,298: time cost, forward:0.011868395931842725, backward:0.033909278600902586, data cost:0.6931631683974979 
2022-07-08 23:16:08,298: ============================================================
2022-07-08 23:16:08,298: Epoch 34/36 Batch 6900/7662 eta: 3:21:04.400297	Training Loss1 2.6139 (2.5530)	Training Total_Loss 2.6139 (2.5530)	Training Prec@1 99.414 (99.427)	Training Prec@5 0.000 (0.000)	
2022-07-08 23:16:08,299: ============================================================
2022-07-08 23:17:24,075: time cost, forward:0.011883483952940456, backward:0.033913860458666165, data cost:0.6934047189162857 
2022-07-08 23:17:24,076: ============================================================
2022-07-08 23:17:24,076: Epoch 34/36 Batch 7000/7662 eta: 3:21:54.530882	Training Loss1 2.7459 (2.5533)	Training Total_Loss 2.7459 (2.5533)	Training Prec@1 99.219 (99.427)	Training Prec@5 0.000 (0.000)	
2022-07-08 23:17:24,076: ============================================================
2022-07-08 23:18:37,757: time cost, forward:0.011887894867003543, backward:0.03391686841322849, data cost:0.6933520298001463 
2022-07-08 23:18:37,758: ============================================================
2022-07-08 23:18:37,758: Epoch 34/36 Batch 7100/7662 eta: 3:15:05.854025	Training Loss1 2.6243 (2.5537)	Training Total_Loss 2.6243 (2.5537)	Training Prec@1 99.609 (99.426)	Training Prec@5 0.000 (0.000)	
2022-07-08 23:18:37,758: ============================================================
2022-07-08 23:19:52,332: time cost, forward:0.01188626688774269, backward:0.033909710732942355, data cost:0.6934445536555573 
2022-07-08 23:19:52,332: ============================================================
2022-07-08 23:19:52,332: Epoch 34/36 Batch 7200/7662 eta: 3:16:13.093868	Training Loss1 2.6279 (2.5541)	Training Total_Loss 2.6279 (2.5541)	Training Prec@1 99.219 (99.427)	Training Prec@5 0.000 (0.000)	
2022-07-08 23:19:52,332: ============================================================
2022-07-08 23:21:05,856: time cost, forward:0.011880405995433895, backward:0.03390599789889255, data cost:0.6933959655719908 
2022-07-08 23:21:05,857: ============================================================
2022-07-08 23:21:05,857: Epoch 34/36 Batch 7300/7662 eta: 3:12:13.756321	Training Loss1 2.4910 (2.5544)	Training Total_Loss 2.4910 (2.5544)	Training Prec@1 99.219 (99.426)	Training Prec@5 0.000 (0.000)	
2022-07-08 23:21:05,857: ============================================================
2022-07-08 23:22:20,648: time cost, forward:0.011864721783110701, backward:0.033903224449864044, data cost:0.6935225025127507 
2022-07-08 23:22:20,648: ============================================================
2022-07-08 23:22:20,648: Epoch 34/36 Batch 7400/7662 eta: 3:14:17.787390	Training Loss1 2.6166 (2.5547)	Training Total_Loss 2.6166 (2.5547)	Training Prec@1 99.805 (99.426)	Training Prec@5 0.000 (0.000)	
2022-07-08 23:22:20,649: ============================================================
2022-07-08 23:23:35,527: time cost, forward:0.01185043370951047, backward:0.033906033999571115, data cost:0.6936517192898058 
2022-07-08 23:23:35,528: ============================================================
2022-07-08 23:23:35,528: Epoch 34/36 Batch 7500/7662 eta: 3:13:16.597973	Training Loss1 2.5359 (2.5549)	Training Total_Loss 2.5359 (2.5549)	Training Prec@1 99.219 (99.425)	Training Prec@5 0.000 (0.000)	
2022-07-08 23:23:35,528: ============================================================
2022-07-08 23:24:50,140: time cost, forward:0.011838933232113286, backward:0.03391657520052727, data cost:0.693733710052936 
2022-07-08 23:24:50,141: ============================================================
2022-07-08 23:24:50,141: Epoch 34/36 Batch 7600/7662 eta: 3:11:20.707360	Training Loss1 2.3699 (2.5550)	Training Total_Loss 2.3699 (2.5550)	Training Prec@1 99.609 (99.425)	Training Prec@5 0.000 (0.000)	
2022-07-08 23:24:50,141: ============================================================
2022-07-08 23:25:38,476: Epoch 34/36 Batch 7663/7662 eta: 3:10:33.701149	Training Loss1 2.4476 (2.5552)	Training Total_Loss 2.4476 (2.5552)	Training Prec@1 99.414 (99.425)	Training Prec@5 0.000 (0.000)	
2022-07-08 23:25:38,476: ============================================================
2022-07-08 23:25:38,602: Save Checkpoint...
2022-07-08 23:25:38,617: ============================================================
2022-07-08 23:25:40,756: Save done!
2022-07-08 23:25:40,756: ============================================================
2022-07-08 23:27:10,105: time cost, forward:0.010875829542526092, backward:0.03276681177543871, data cost:0.8533765547203295 
2022-07-08 23:27:10,105: ============================================================
2022-07-08 23:27:10,105: Epoch 35/36 Batch 100/7662 eta: 3:46:42.626012	Training Loss1 2.6888 (2.5047)	Training Total_Loss 2.6888 (2.5047)	Training Prec@1 99.414 (99.440)	Training Prec@5 0.000 (0.000)	
2022-07-08 23:27:10,105: ============================================================
2022-07-08 23:28:25,061: time cost, forward:0.010679688285942653, backward:0.03343544054270989, data cost:0.778519396805883 
2022-07-08 23:28:25,061: ============================================================
2022-07-08 23:28:25,061: Epoch 35/36 Batch 200/7662 eta: 3:08:57.090867	Training Loss1 2.4960 (2.5233)	Training Total_Loss 2.4960 (2.5233)	Training Prec@1 99.805 (99.413)	Training Prec@5 0.000 (0.000)	
2022-07-08 23:28:25,061: ============================================================
2022-07-08 23:29:41,958: time cost, forward:0.010641424950947331, backward:0.03371917045236032, data cost:0.7600831873839515 
2022-07-08 23:29:41,958: ============================================================
2022-07-08 23:29:41,958: Epoch 35/36 Batch 300/7662 eta: 3:12:33.774369	Training Loss1 2.3207 (2.5257)	Training Total_Loss 2.3207 (2.5257)	Training Prec@1 99.805 (99.436)	Training Prec@5 0.000 (0.000)	
2022-07-08 23:29:41,958: ============================================================
2022-07-08 23:30:58,037: time cost, forward:0.010574442999703544, backward:0.03385156856144879, data cost:0.7489394663569323 
2022-07-08 23:30:58,038: ============================================================
2022-07-08 23:30:58,038: Epoch 35/36 Batch 400/7662 eta: 3:09:14.896398	Training Loss1 2.5243 (2.5288)	Training Total_Loss 2.5243 (2.5288)	Training Prec@1 100.000 (99.439)	Training Prec@5 0.000 (0.000)	
2022-07-08 23:30:58,038: ============================================================
2022-07-08 23:32:13,874: time cost, forward:0.01064065940872223, backward:0.034024197496249825, data cost:0.7416022679132068 
2022-07-08 23:32:13,875: ============================================================
2022-07-08 23:32:13,875: Epoch 35/36 Batch 500/7662 eta: 3:07:22.816501	Training Loss1 2.4118 (2.5295)	Training Total_Loss 2.4118 (2.5295)	Training Prec@1 99.023 (99.439)	Training Prec@5 0.000 (0.000)	
2022-07-08 23:32:13,875: ============================================================
2022-07-08 23:33:27,924: time cost, forward:0.010902015912114878, backward:0.034242037739698, data cost:0.7333739790972167 
2022-07-08 23:33:27,924: ============================================================
2022-07-08 23:33:27,924: Epoch 35/36 Batch 600/7662 eta: 3:01:43.787996	Training Loss1 2.3323 (2.5308)	Training Total_Loss 2.3323 (2.5308)	Training Prec@1 99.609 (99.436)	Training Prec@5 0.000 (0.000)	
2022-07-08 23:33:27,924: ============================================================
2022-07-08 23:34:41,476: time cost, forward:0.010955659446115998, backward:0.03424349977223146, data cost:0.7270788232314911 
2022-07-08 23:34:41,477: ============================================================
2022-07-08 23:34:41,477: Epoch 35/36 Batch 700/7662 eta: 2:59:17.036041	Training Loss1 2.4944 (2.5295)	Training Total_Loss 2.4944 (2.5295)	Training Prec@1 99.219 (99.440)	Training Prec@5 0.000 (0.000)	
2022-07-08 23:34:41,477: ============================================================
2022-07-08 23:35:54,813: time cost, forward:0.011106727120276536, backward:0.03431812245795067, data cost:0.7218951027145672 
2022-07-08 23:35:54,813: ============================================================
2022-07-08 23:35:54,813: Epoch 35/36 Batch 800/7662 eta: 2:57:32.143203	Training Loss1 2.5007 (2.5287)	Training Total_Loss 2.5007 (2.5287)	Training Prec@1 99.219 (99.444)	Training Prec@5 0.000 (0.000)	
2022-07-08 23:35:54,813: ============================================================
2022-07-08 23:37:08,475: time cost, forward:0.011244111915053727, backward:0.03430802087497393, data cost:0.718308286221327 
2022-07-08 23:37:08,475: ============================================================
2022-07-08 23:37:08,475: Epoch 35/36 Batch 900/7662 eta: 2:57:05.702393	Training Loss1 2.2941 (2.5316)	Training Total_Loss 2.2941 (2.5316)	Training Prec@1 99.023 (99.445)	Training Prec@5 0.000 (0.000)	
2022-07-08 23:37:08,475: ============================================================
2022-07-08 23:38:22,457: time cost, forward:0.011312832942118755, backward:0.034244247384973475, data cost:0.7158395325218713 
2022-07-08 23:38:22,457: ============================================================
2022-07-08 23:38:22,458: Epoch 35/36 Batch 1000/7662 eta: 2:56:37.982617	Training Loss1 2.6318 (2.5326)	Training Total_Loss 2.6318 (2.5326)	Training Prec@1 99.609 (99.446)	Training Prec@5 0.000 (0.000)	
2022-07-08 23:38:22,458: ============================================================
2022-07-08 23:39:35,667: time cost, forward:0.011292378830844647, backward:0.03419957408262883, data cost:0.7131947473138978 
2022-07-08 23:39:35,668: ============================================================
2022-07-08 23:39:35,668: Epoch 35/36 Batch 1100/7662 eta: 2:53:34.150485	Training Loss1 2.4738 (2.5340)	Training Total_Loss 2.4738 (2.5340)	Training Prec@1 99.805 (99.443)	Training Prec@5 0.000 (0.000)	
2022-07-08 23:39:35,668: ============================================================
2022-07-08 23:40:48,489: time cost, forward:0.011366681718547907, backward:0.03410915914826636, data cost:0.7105953504484429 
2022-07-08 23:40:48,489: ============================================================
2022-07-08 23:40:48,489: Epoch 35/36 Batch 1200/7662 eta: 2:51:26.034089	Training Loss1 2.3703 (2.5337)	Training Total_Loss 2.3703 (2.5337)	Training Prec@1 100.000 (99.446)	Training Prec@5 0.000 (0.000)	
2022-07-08 23:40:48,489: ============================================================
2022-07-08 23:42:02,190: time cost, forward:0.01139946310588082, backward:0.03406950434507821, data cost:0.7091177010921628 
2022-07-08 23:42:02,191: ============================================================
2022-07-08 23:42:02,191: Epoch 35/36 Batch 1300/7662 eta: 2:52:16.681545	Training Loss1 2.5842 (2.5338)	Training Total_Loss 2.5842 (2.5338)	Training Prec@1 99.219 (99.445)	Training Prec@5 0.000 (0.000)	
2022-07-08 23:42:02,191: ============================================================
2022-07-08 23:43:14,656: time cost, forward:0.011479196418942171, backward:0.034043625135605805, data cost:0.706877278293176 
2022-07-08 23:43:14,657: ============================================================
2022-07-08 23:43:14,657: Epoch 35/36 Batch 1400/7662 eta: 2:48:10.887756	Training Loss1 2.6103 (2.5331)	Training Total_Loss 2.6103 (2.5331)	Training Prec@1 99.414 (99.447)	Training Prec@5 0.000 (0.000)	
2022-07-08 23:43:14,657: ============================================================
2022-07-08 23:44:28,193: time cost, forward:0.011577133022204011, backward:0.034017184641140154, data cost:0.7056315635505559 
2022-07-08 23:44:28,193: ============================================================
2022-07-08 23:44:28,193: Epoch 35/36 Batch 1500/7662 eta: 2:49:26.369966	Training Loss1 2.5812 (2.5327)	Training Total_Loss 2.5812 (2.5327)	Training Prec@1 99.023 (99.449)	Training Prec@5 0.000 (0.000)	
2022-07-08 23:44:28,193: ============================================================
2022-07-08 23:45:40,509: time cost, forward:0.011570442460938645, backward:0.033947634204914603, data cost:0.7039119763401167 
2022-07-08 23:45:40,510: ============================================================
2022-07-08 23:45:40,510: Epoch 35/36 Batch 1600/7662 eta: 2:45:25.446032	Training Loss1 2.3179 (2.5332)	Training Total_Loss 2.3179 (2.5332)	Training Prec@1 100.000 (99.449)	Training Prec@5 0.000 (0.000)	
2022-07-08 23:45:40,510: ============================================================
2022-07-08 23:46:53,383: time cost, forward:0.011608840578650642, backward:0.033965343163250616, data cost:0.7025951685240298 
2022-07-08 23:46:53,383: ============================================================
2022-07-08 23:46:53,383: Epoch 35/36 Batch 1700/7662 eta: 2:45:29.030730	Training Loss1 2.4918 (2.5323)	Training Total_Loss 2.4918 (2.5323)	Training Prec@1 99.805 (99.449)	Training Prec@5 0.000 (0.000)	
2022-07-08 23:46:53,383: ============================================================
2022-07-08 23:48:07,515: time cost, forward:0.011595723627672519, backward:0.033923907833936943, data cost:0.7022544166126007 
2022-07-08 23:48:07,516: ============================================================
2022-07-08 23:48:07,516: Epoch 35/36 Batch 1800/7662 eta: 2:47:06.413199	Training Loss1 2.6201 (2.5338)	Training Total_Loss 2.6201 (2.5338)	Training Prec@1 99.414 (99.449)	Training Prec@5 0.000 (0.000)	
2022-07-08 23:48:07,516: ============================================================
2022-07-08 23:49:20,785: time cost, forward:0.01160767029435337, backward:0.03395210535291498, data cost:0.7013828112866892 
2022-07-08 23:49:20,785: ============================================================
2022-07-08 23:49:20,785: Epoch 35/36 Batch 1900/7662 eta: 2:43:56.452271	Training Loss1 2.7829 (2.5342)	Training Total_Loss 2.7829 (2.5342)	Training Prec@1 99.219 (99.449)	Training Prec@5 0.000 (0.000)	
2022-07-08 23:49:20,786: ============================================================
2022-07-08 23:50:33,870: time cost, forward:0.011648884291885018, backward:0.03390735754554065, data cost:0.7005323859200947 
2022-07-08 23:50:33,871: ============================================================
2022-07-08 23:50:33,871: Epoch 35/36 Batch 2000/7662 eta: 2:42:18.618572	Training Loss1 2.6196 (2.5348)	Training Total_Loss 2.6196 (2.5348)	Training Prec@1 99.219 (99.448)	Training Prec@5 0.000 (0.000)	
2022-07-08 23:50:33,871: ============================================================
2022-07-08 23:51:47,934: time cost, forward:0.01167153664689339, backward:0.033904919117731726, data cost:0.7002292037180573 
2022-07-08 23:51:47,935: ============================================================
2022-07-08 23:51:47,935: Epoch 35/36 Batch 2100/7662 eta: 2:43:14.968684	Training Loss1 2.4793 (2.5351)	Training Total_Loss 2.4793 (2.5351)	Training Prec@1 100.000 (99.450)	Training Prec@5 0.000 (0.000)	
2022-07-08 23:51:47,935: ============================================================
2022-07-08 23:53:01,857: time cost, forward:0.011730610863519507, backward:0.03391980235822746, data cost:0.699824359428888 
2022-07-08 23:53:01,858: ============================================================
2022-07-08 23:53:01,858: Epoch 35/36 Batch 2200/7662 eta: 2:41:42.418703	Training Loss1 2.5048 (2.5367)	Training Total_Loss 2.5048 (2.5367)	Training Prec@1 99.609 (99.448)	Training Prec@5 0.000 (0.000)	
2022-07-08 23:53:01,858: ============================================================
2022-07-08 23:54:15,927: time cost, forward:0.01176872052229607, backward:0.033958236670276296, data cost:0.6995189852588019 
2022-07-08 23:54:15,927: ============================================================
2022-07-08 23:54:15,927: Epoch 35/36 Batch 2300/7662 eta: 2:40:47.506256	Training Loss1 2.5790 (2.5362)	Training Total_Loss 2.5790 (2.5362)	Training Prec@1 99.023 (99.449)	Training Prec@5 0.000 (0.000)	
2022-07-08 23:54:15,927: ============================================================
2022-07-08 23:55:28,970: time cost, forward:0.011791158885248208, backward:0.033960592254791325, data cost:0.698856642764029 
2022-07-08 23:55:28,970: ============================================================
2022-07-08 23:55:28,970: Epoch 35/36 Batch 2400/7662 eta: 2:37:20.807625	Training Loss1 2.3148 (2.5364)	Training Total_Loss 2.3148 (2.5364)	Training Prec@1 100.000 (99.451)	Training Prec@5 0.000 (0.000)	
2022-07-08 23:55:28,970: ============================================================
2022-07-08 23:56:43,013: time cost, forward:0.011820477740962107, backward:0.033968069783302725, data cost:0.6986158090670045 
2022-07-08 23:56:43,013: ============================================================
2022-07-08 23:56:43,013: Epoch 35/36 Batch 2500/7662 eta: 2:38:16.015971	Training Loss1 2.7824 (2.5372)	Training Total_Loss 2.7824 (2.5372)	Training Prec@1 99.414 (99.449)	Training Prec@5 0.000 (0.000)	
2022-07-08 23:56:43,013: ============================================================
2022-07-08 23:57:57,040: time cost, forward:0.011823930112890851, backward:0.03397450652568328, data cost:0.6984108286942368 
2022-07-08 23:57:57,040: ============================================================
2022-07-08 23:57:57,041: Epoch 35/36 Batch 2600/7662 eta: 2:36:59.973455	Training Loss1 2.6446 (2.5373)	Training Total_Loss 2.6446 (2.5373)	Training Prec@1 99.219 (99.449)	Training Prec@5 0.000 (0.000)	
2022-07-08 23:57:57,041: ============================================================
2022-07-08 23:59:10,746: time cost, forward:0.011811243246643134, backward:0.0339924919910014, data cost:0.6981333543212823 
2022-07-08 23:59:10,746: ============================================================
2022-07-08 23:59:10,747: Epoch 35/36 Batch 2700/7662 eta: 2:35:05.404093	Training Loss1 2.5842 (2.5365)	Training Total_Loss 2.5842 (2.5365)	Training Prec@1 99.805 (99.450)	Training Prec@5 0.000 (0.000)	
2022-07-08 23:59:10,747: ============================================================
2022-07-09 00:00:24,631: time cost, forward:0.01181944322057944, backward:0.03399777250572714, data cost:0.6979127686634452 
2022-07-09 00:00:24,632: ============================================================
2022-07-09 00:00:24,632: Epoch 35/36 Batch 2800/7662 eta: 2:34:14.123991	Training Loss1 2.8149 (2.5365)	Training Total_Loss 2.8149 (2.5365)	Training Prec@1 99.023 (99.450)	Training Prec@5 0.000 (0.000)	
2022-07-09 00:00:24,632: ============================================================
2022-07-09 00:01:38,506: time cost, forward:0.011835700357811499, backward:0.03400462847325094, data cost:0.6976998193628338 
2022-07-09 00:01:38,506: ============================================================
2022-07-09 00:01:38,507: Epoch 35/36 Batch 2900/7662 eta: 2:32:58.922715	Training Loss1 2.5796 (2.5368)	Training Total_Loss 2.5796 (2.5368)	Training Prec@1 99.609 (99.449)	Training Prec@5 0.000 (0.000)	
2022-07-09 00:01:38,507: ============================================================
2022-07-09 00:02:52,236: time cost, forward:0.011831466576861476, backward:0.03400555782693352, data cost:0.6974772973710913 
2022-07-09 00:02:52,237: ============================================================
2022-07-09 00:02:52,237: Epoch 35/36 Batch 3000/7662 eta: 2:31:27.249478	Training Loss1 2.3124 (2.5365)	Training Total_Loss 2.3124 (2.5365)	Training Prec@1 99.023 (99.449)	Training Prec@5 0.000 (0.000)	
2022-07-09 00:02:52,237: ============================================================
2022-07-09 00:04:06,344: time cost, forward:0.011840689293835848, backward:0.033990644570049376, data cost:0.697394181467249 
2022-07-09 00:04:06,345: ============================================================
2022-07-09 00:04:06,345: Epoch 35/36 Batch 3100/7662 eta: 2:30:59.746900	Training Loss1 2.7370 (2.5373)	Training Total_Loss 2.7370 (2.5373)	Training Prec@1 99.805 (99.449)	Training Prec@5 0.000 (0.000)	
2022-07-09 00:04:06,345: ============================================================
2022-07-09 00:05:20,630: time cost, forward:0.011856455249911586, backward:0.034008947749851866, data cost:0.6973233733485735 
2022-07-09 00:05:20,631: ============================================================
2022-07-09 00:05:20,631: Epoch 35/36 Batch 3200/7662 eta: 2:30:07.157439	Training Loss1 2.5933 (2.5376)	Training Total_Loss 2.5933 (2.5376)	Training Prec@1 99.023 (99.448)	Training Prec@5 0.000 (0.000)	
2022-07-09 00:05:20,631: ============================================================
2022-07-09 00:06:34,120: time cost, forward:0.01186419834184372, backward:0.034009627336153446, data cost:0.6970416421997219 
2022-07-09 00:06:34,120: ============================================================
2022-07-09 00:06:34,121: Epoch 35/36 Batch 3300/7662 eta: 2:27:17.124250	Training Loss1 2.5562 (2.5379)	Training Total_Loss 2.5562 (2.5379)	Training Prec@1 99.609 (99.449)	Training Prec@5 0.000 (0.000)	
2022-07-09 00:06:34,121: ============================================================
2022-07-09 00:07:48,742: time cost, forward:0.011871984195063906, backward:0.03399885560035986, data cost:0.6971351852063468 
2022-07-09 00:07:48,743: ============================================================
2022-07-09 00:07:48,743: Epoch 35/36 Batch 3400/7662 eta: 2:28:18.696527	Training Loss1 2.5306 (2.5381)	Training Total_Loss 2.5306 (2.5381)	Training Prec@1 99.414 (99.448)	Training Prec@5 0.000 (0.000)	
2022-07-09 00:07:48,743: ============================================================
2022-07-09 00:09:01,826: time cost, forward:0.011875160492021855, backward:0.03401502052965625, data cost:0.6967506886346233 
2022-07-09 00:09:01,826: ============================================================
2022-07-09 00:09:01,827: Epoch 35/36 Batch 3500/7662 eta: 2:24:02.172553	Training Loss1 2.6275 (2.5386)	Training Total_Loss 2.6275 (2.5386)	Training Prec@1 99.414 (99.447)	Training Prec@5 0.000 (0.000)	
2022-07-09 00:09:01,827: ============================================================
2022-07-09 00:10:15,302: time cost, forward:0.011884376452213593, backward:0.03400236495702457, data cost:0.696514354543111 
2022-07-09 00:10:15,302: ============================================================
2022-07-09 00:10:15,302: Epoch 35/36 Batch 3600/7662 eta: 2:23:35.010942	Training Loss1 2.7071 (2.5390)	Training Total_Loss 2.7071 (2.5390)	Training Prec@1 98.633 (99.447)	Training Prec@5 0.000 (0.000)	
2022-07-09 00:10:15,302: ============================================================
2022-07-09 00:11:29,726: time cost, forward:0.011913513744093334, backward:0.03399794041772055, data cost:0.696526606297551 
2022-07-09 00:11:29,726: ============================================================
2022-07-09 00:11:29,727: Epoch 35/36 Batch 3700/7662 eta: 2:24:11.827059	Training Loss1 2.7285 (2.5394)	Training Total_Loss 2.7285 (2.5394)	Training Prec@1 99.023 (99.447)	Training Prec@5 0.000 (0.000)	
2022-07-09 00:11:29,727: ============================================================
2022-07-09 00:12:41,935: time cost, forward:0.011911826122431543, backward:0.03397246359774676, data cost:0.6959950017690596 
2022-07-09 00:12:41,935: ============================================================
2022-07-09 00:12:41,935: Epoch 35/36 Batch 3800/7662 eta: 2:18:42.037913	Training Loss1 2.5810 (2.5399)	Training Total_Loss 2.5810 (2.5399)	Training Prec@1 99.414 (99.447)	Training Prec@5 0.000 (0.000)	
2022-07-09 00:12:41,935: ============================================================
2022-07-09 00:13:55,838: time cost, forward:0.011930984544521664, backward:0.03396483194097307, data cost:0.6958973865748735 
2022-07-09 00:13:55,839: ============================================================
2022-07-09 00:13:55,839: Epoch 35/36 Batch 3900/7662 eta: 2:20:43.485453	Training Loss1 2.2321 (2.5402)	Training Total_Loss 2.2321 (2.5402)	Training Prec@1 100.000 (99.446)	Training Prec@5 0.000 (0.000)	
2022-07-09 00:13:55,839: ============================================================
2022-07-09 00:15:09,267: time cost, forward:0.011963249832786719, backward:0.03395651483213821, data cost:0.6956740346185026 
2022-07-09 00:15:09,267: ============================================================
2022-07-09 00:15:09,268: Epoch 35/36 Batch 4000/7662 eta: 2:18:35.805024	Training Loss1 2.3898 (2.5407)	Training Total_Loss 2.3898 (2.5407)	Training Prec@1 99.023 (99.446)	Training Prec@5 0.000 (0.000)	
2022-07-09 00:15:09,268: ============================================================
2022-07-09 00:16:22,163: time cost, forward:0.011977966077794795, backward:0.03395252025368796, data cost:0.695337987463775 
2022-07-09 00:16:22,163: ============================================================
2022-07-09 00:16:22,164: Epoch 35/36 Batch 4100/7662 eta: 2:16:22.579496	Training Loss1 2.6429 (2.5412)	Training Total_Loss 2.6429 (2.5412)	Training Prec@1 99.609 (99.446)	Training Prec@5 0.000 (0.000)	
2022-07-09 00:16:22,164: ============================================================
2022-07-09 00:17:36,172: time cost, forward:0.011982458152780082, backward:0.033938821028118675, data cost:0.6953064479496287 
2022-07-09 00:17:36,172: ============================================================
2022-07-09 00:17:36,172: Epoch 35/36 Batch 4200/7662 eta: 2:17:13.491178	Training Loss1 2.4523 (2.5412)	Training Total_Loss 2.4523 (2.5412)	Training Prec@1 99.414 (99.446)	Training Prec@5 0.000 (0.000)	
2022-07-09 00:17:36,173: ============================================================
2022-07-09 00:18:50,897: time cost, forward:0.011997696132708716, backward:0.03393450086131765, data cost:0.695422878595917 
2022-07-09 00:18:50,898: ============================================================
2022-07-09 00:18:50,898: Epoch 35/36 Batch 4300/7662 eta: 2:17:18.496244	Training Loss1 2.7807 (2.5417)	Training Total_Loss 2.7807 (2.5417)	Training Prec@1 98.633 (99.445)	Training Prec@5 0.000 (0.000)	
2022-07-09 00:18:50,898: ============================================================
2022-07-09 00:20:05,018: time cost, forward:0.01200587566832733, backward:0.0339468135213711, data cost:0.6953846529739286 
2022-07-09 00:20:05,018: ============================================================
2022-07-09 00:20:05,018: Epoch 35/36 Batch 4400/7662 eta: 2:14:57.648485	Training Loss1 2.5473 (2.5420)	Training Total_Loss 2.5473 (2.5420)	Training Prec@1 99.023 (99.445)	Training Prec@5 0.000 (0.000)	
2022-07-09 00:20:05,018: ============================================================
2022-07-09 00:21:20,038: time cost, forward:0.012018048145898741, backward:0.033950091733167265, data cost:0.695553399107408 
2022-07-09 00:21:20,038: ============================================================
2022-07-09 00:21:20,038: Epoch 35/36 Batch 4500/7662 eta: 2:15:20.896906	Training Loss1 2.7548 (2.5426)	Training Total_Loss 2.7548 (2.5426)	Training Prec@1 99.414 (99.445)	Training Prec@5 0.000 (0.000)	
2022-07-09 00:21:20,038: ============================================================
2022-07-09 00:22:34,447: time cost, forward:0.012020253077567362, backward:0.03393948210351077, data cost:0.6956020286482919 
2022-07-09 00:22:34,447: ============================================================
2022-07-09 00:22:34,447: Epoch 35/36 Batch 4600/7662 eta: 2:13:00.372555	Training Loss1 2.5284 (2.5428)	Training Total_Loss 2.5284 (2.5428)	Training Prec@1 99.609 (99.444)	Training Prec@5 0.000 (0.000)	
2022-07-09 00:22:34,447: ============================================================
2022-07-09 00:23:48,543: time cost, forward:0.012025658895066758, backward:0.03394383419115611, data cost:0.6955661004491247 
2022-07-09 00:23:48,543: ============================================================
2022-07-09 00:23:48,543: Epoch 35/36 Batch 4700/7662 eta: 2:11:12.688976	Training Loss1 2.5613 (2.5429)	Training Total_Loss 2.5613 (2.5429)	Training Prec@1 98.828 (99.445)	Training Prec@5 0.000 (0.000)	
2022-07-09 00:23:48,543: ============================================================
2022-07-09 00:25:03,304: time cost, forward:0.012019699179746131, backward:0.03394253046767467, data cost:0.6956897894276458 
2022-07-09 00:25:03,305: ============================================================
2022-07-09 00:25:03,305: Epoch 35/36 Batch 4800/7662 eta: 2:11:08.687335	Training Loss1 2.6318 (2.5432)	Training Total_Loss 2.6318 (2.5432)	Training Prec@1 99.023 (99.444)	Training Prec@5 0.000 (0.000)	
2022-07-09 00:25:03,305: ============================================================
2022-07-09 00:26:17,201: time cost, forward:0.012014307569888057, backward:0.033946578953796124, data cost:0.6956216337048635 
2022-07-09 00:26:17,201: ============================================================
2022-07-09 00:26:17,202: Epoch 35/36 Batch 4900/7662 eta: 2:08:23.721147	Training Loss1 2.1044 (2.5436)	Training Total_Loss 2.1044 (2.5436)	Training Prec@1 99.609 (99.444)	Training Prec@5 0.000 (0.000)	
2022-07-09 00:26:17,202: ============================================================
2022-07-09 00:27:31,027: time cost, forward:0.01201228228395618, backward:0.03395114552619386, data cost:0.6955427700911887 
2022-07-09 00:27:31,027: ============================================================
2022-07-09 00:27:31,027: Epoch 35/36 Batch 5000/7662 eta: 2:07:02.486667	Training Loss1 2.5107 (2.5439)	Training Total_Loss 2.5107 (2.5439)	Training Prec@1 99.219 (99.443)	Training Prec@5 0.000 (0.000)	
2022-07-09 00:27:31,027: ============================================================
2022-07-09 00:28:44,065: time cost, forward:0.012025811855034119, backward:0.033958137678291124, data cost:0.6952909477366305 
2022-07-09 00:28:44,065: ============================================================
2022-07-09 00:28:44,065: Epoch 35/36 Batch 5100/7662 eta: 2:04:28.136900	Training Loss1 2.5725 (2.5442)	Training Total_Loss 2.5725 (2.5442)	Training Prec@1 98.438 (99.441)	Training Prec@5 0.000 (0.000)	
2022-07-09 00:28:44,065: ============================================================
2022-07-09 00:29:58,156: time cost, forward:0.012037614373707685, backward:0.03393494667835386, data cost:0.695283156400645 
2022-07-09 00:29:58,156: ============================================================
2022-07-09 00:29:58,156: Epoch 35/36 Batch 5200/7662 eta: 2:05:01.720566	Training Loss1 2.4513 (2.5440)	Training Total_Loss 2.4513 (2.5440)	Training Prec@1 100.000 (99.441)	Training Prec@5 0.000 (0.000)	
2022-07-09 00:29:58,156: ============================================================
2022-07-09 00:31:11,160: time cost, forward:0.01203487215907782, backward:0.03391294543260357, data cost:0.6950800325717987 
2022-07-09 00:31:11,161: ============================================================
2022-07-09 00:31:11,161: Epoch 35/36 Batch 5300/7662 eta: 2:01:58.710605	Training Loss1 2.4204 (2.5439)	Training Total_Loss 2.4204 (2.5439)	Training Prec@1 99.219 (99.441)	Training Prec@5 0.000 (0.000)	
2022-07-09 00:31:11,161: ============================================================
2022-07-09 00:32:25,038: time cost, forward:0.01203483386180162, backward:0.033916095557710066, data cost:0.695025741976706 
2022-07-09 00:32:25,039: ============================================================
2022-07-09 00:32:25,039: Epoch 35/36 Batch 5400/7662 eta: 2:02:12.371743	Training Loss1 2.3467 (2.5439)	Training Total_Loss 2.3467 (2.5439)	Training Prec@1 99.805 (99.441)	Training Prec@5 0.000 (0.000)	
2022-07-09 00:32:25,039: ============================================================
2022-07-09 00:33:38,384: time cost, forward:0.012041548378447182, backward:0.03391039065825634, data cost:0.6948721604382782 
2022-07-09 00:33:38,384: ============================================================
2022-07-09 00:33:38,384: Epoch 35/36 Batch 5500/7662 eta: 2:00:06.210366	Training Loss1 2.3380 (2.5439)	Training Total_Loss 2.3380 (2.5439)	Training Prec@1 99.414 (99.441)	Training Prec@5 0.000 (0.000)	
2022-07-09 00:33:38,384: ============================================================
2022-07-09 00:34:52,205: time cost, forward:0.012053070674732042, backward:0.03390343739829291, data cost:0.694817146801016 
2022-07-09 00:34:52,205: ============================================================
2022-07-09 00:34:52,205: Epoch 35/36 Batch 5600/7662 eta: 1:59:39.076122	Training Loss1 2.5720 (2.5441)	Training Total_Loss 2.5720 (2.5441)	Training Prec@1 99.219 (99.440)	Training Prec@5 0.000 (0.000)	
2022-07-09 00:34:52,205: ============================================================
2022-07-09 00:36:06,900: time cost, forward:0.01204537922801794, backward:0.03391789252098286, data cost:0.6949056390085269 
2022-07-09 00:36:06,900: ============================================================
2022-07-09 00:36:06,900: Epoch 35/36 Batch 5700/7662 eta: 1:59:49.394248	Training Loss1 2.7558 (2.5449)	Training Total_Loss 2.7558 (2.5449)	Training Prec@1 99.414 (99.439)	Training Prec@5 0.000 (0.000)	
2022-07-09 00:36:06,900: ============================================================
2022-07-09 00:37:21,590: time cost, forward:0.012040304467480313, backward:0.03392853451548085, data cost:0.6949939685024913 
2022-07-09 00:37:21,590: ============================================================
2022-07-09 00:37:21,591: Epoch 35/36 Batch 5800/7662 eta: 1:58:34.253186	Training Loss1 2.5800 (2.5452)	Training Total_Loss 2.5800 (2.5452)	Training Prec@1 99.805 (99.438)	Training Prec@5 0.000 (0.000)	
2022-07-09 00:37:21,591: ============================================================
2022-07-09 00:38:35,698: time cost, forward:0.01203167052526841, backward:0.03392655119125591, data cost:0.694995297599918 
2022-07-09 00:38:35,698: ============================================================
2022-07-09 00:38:35,698: Epoch 35/36 Batch 5900/7662 eta: 1:56:24.659432	Training Loss1 2.4077 (2.5454)	Training Total_Loss 2.4077 (2.5454)	Training Prec@1 99.805 (99.438)	Training Prec@5 0.000 (0.000)	
2022-07-09 00:38:35,698: ============================================================
2022-07-09 00:39:49,303: time cost, forward:0.012024310295294474, backward:0.033913910637340616, data cost:0.6949283260765782 
2022-07-09 00:39:49,304: ============================================================
2022-07-09 00:39:49,304: Epoch 35/36 Batch 6000/7662 eta: 1:54:23.705314	Training Loss1 2.6585 (2.5459)	Training Total_Loss 2.6585 (2.5459)	Training Prec@1 99.609 (99.438)	Training Prec@5 0.000 (0.000)	
2022-07-09 00:39:49,304: ============================================================
2022-07-09 00:41:03,116: time cost, forward:0.012014848205921668, backward:0.03390624187367532, data cost:0.6948915668971657 
2022-07-09 00:41:03,117: ============================================================
2022-07-09 00:41:03,117: Epoch 35/36 Batch 6100/7662 eta: 1:53:29.256725	Training Loss1 2.4128 (2.5461)	Training Total_Loss 2.4128 (2.5461)	Training Prec@1 99.414 (99.439)	Training Prec@5 0.000 (0.000)	
2022-07-09 00:41:03,117: ============================================================
2022-07-09 00:42:17,876: time cost, forward:0.012010027274217773, backward:0.03390586924256769, data cost:0.6949940749687001 
2022-07-09 00:42:17,877: ============================================================
2022-07-09 00:42:17,877: Epoch 35/36 Batch 6200/7662 eta: 1:53:41.850913	Training Loss1 2.5364 (2.5464)	Training Total_Loss 2.5364 (2.5464)	Training Prec@1 99.609 (99.438)	Training Prec@5 0.000 (0.000)	
2022-07-09 00:42:17,877: ============================================================
2022-07-09 00:43:30,800: time cost, forward:0.012003180223299333, backward:0.03391047257585249, data cost:0.6948013444574395 
2022-07-09 00:43:30,801: ============================================================
2022-07-09 00:43:30,801: Epoch 35/36 Batch 6300/7662 eta: 1:49:41.387839	Training Loss1 2.5928 (2.5464)	Training Total_Loss 2.5928 (2.5464)	Training Prec@1 98.242 (99.439)	Training Prec@5 0.000 (0.000)	
2022-07-09 00:43:30,801: ============================================================
2022-07-09 00:44:44,339: time cost, forward:0.011996389944342118, backward:0.03391002733123584, data cost:0.6947144235851505 
2022-07-09 00:44:44,340: ============================================================
2022-07-09 00:44:44,340: Epoch 35/36 Batch 6400/7662 eta: 1:49:23.351774	Training Loss1 2.4137 (2.5466)	Training Total_Loss 2.4137 (2.5466)	Training Prec@1 100.000 (99.439)	Training Prec@5 0.000 (0.000)	
2022-07-09 00:44:44,340: ============================================================
2022-07-09 00:45:57,994: time cost, forward:0.011992231187939295, backward:0.03391224506323586, data cost:0.6946457635257626 
2022-07-09 00:45:57,994: ============================================================
2022-07-09 00:45:57,994: Epoch 35/36 Batch 6500/7662 eta: 1:48:19.994519	Training Loss1 2.4895 (2.5467)	Training Total_Loss 2.4895 (2.5467)	Training Prec@1 99.805 (99.438)	Training Prec@5 0.000 (0.000)	
2022-07-09 00:45:57,994: ============================================================
2022-07-09 00:47:11,362: time cost, forward:0.011993899600472228, backward:0.03390339526791955, data cost:0.6945402187946295 
2022-07-09 00:47:11,363: ============================================================
2022-07-09 00:47:11,363: Epoch 35/36 Batch 6600/7662 eta: 1:46:41.411443	Training Loss1 2.5257 (2.5469)	Training Total_Loss 2.5257 (2.5469)	Training Prec@1 99.805 (99.438)	Training Prec@5 0.000 (0.000)	
2022-07-09 00:47:11,363: ============================================================
2022-07-09 00:48:25,608: time cost, forward:0.012003365479791177, backward:0.03392023648018445, data cost:0.6945364063116023 
2022-07-09 00:48:25,608: ============================================================
2022-07-09 00:48:25,609: Epoch 35/36 Batch 6700/7662 eta: 1:46:43.702616	Training Loss1 2.5699 (2.5474)	Training Total_Loss 2.5699 (2.5474)	Training Prec@1 99.219 (99.438)	Training Prec@5 0.000 (0.000)	
2022-07-09 00:48:25,609: ============================================================
2022-07-09 00:49:39,744: time cost, forward:0.012009722991171331, backward:0.03392800760192018, data cost:0.6945264373461733 
2022-07-09 00:49:39,745: ============================================================
2022-07-09 00:49:39,745: Epoch 35/36 Batch 6800/7662 eta: 1:45:20.129054	Training Loss1 2.3806 (2.5477)	Training Total_Loss 2.3806 (2.5477)	Training Prec@1 99.414 (99.437)	Training Prec@5 0.000 (0.000)	
2022-07-09 00:49:39,745: ============================================================
2022-07-09 00:50:54,019: time cost, forward:0.012004441637148942, backward:0.03393072949957029, data cost:0.6945402372711067 
2022-07-09 00:50:54,019: ============================================================
2022-07-09 00:50:54,019: Epoch 35/36 Batch 6900/7662 eta: 1:44:17.618943	Training Loss1 2.7476 (2.5482)	Training Total_Loss 2.7476 (2.5482)	Training Prec@1 99.023 (99.438)	Training Prec@5 0.000 (0.000)	
2022-07-09 00:50:54,019: ============================================================
2022-07-09 00:52:08,261: time cost, forward:0.011991469106225904, backward:0.03392918070038143, data cost:0.6945857216859139 
2022-07-09 00:52:08,261: ============================================================
2022-07-09 00:52:08,261: Epoch 35/36 Batch 7000/7662 eta: 1:43:00.622929	Training Loss1 2.7007 (2.5487)	Training Total_Loss 2.7007 (2.5487)	Training Prec@1 99.414 (99.437)	Training Prec@5 0.000 (0.000)	
2022-07-09 00:52:08,261: ============================================================
2022-07-09 00:53:22,765: time cost, forward:0.0119990525673537, backward:0.03393453080010323, data cost:0.6946272867164875 
2022-07-09 00:53:22,766: ============================================================
2022-07-09 00:53:22,766: Epoch 35/36 Batch 7100/7662 eta: 1:42:08.047633	Training Loss1 2.6776 (2.5491)	Training Total_Loss 2.6776 (2.5491)	Training Prec@1 99.219 (99.436)	Training Prec@5 0.000 (0.000)	
2022-07-09 00:53:22,767: ============================================================
2022-07-09 00:54:37,390: time cost, forward:0.01199944914505041, backward:0.03393896007922014, data cost:0.6946879045915928 
2022-07-09 00:54:37,390: ============================================================
2022-07-09 00:54:37,390: Epoch 35/36 Batch 7200/7662 eta: 1:41:03.198669	Training Loss1 2.6048 (2.5494)	Training Total_Loss 2.6048 (2.5494)	Training Prec@1 99.219 (99.436)	Training Prec@5 0.000 (0.000)	
2022-07-09 00:54:37,390: ============================================================
2022-07-09 00:55:51,192: time cost, forward:0.012007976300194748, backward:0.03394717823268453, data cost:0.6946310101673854 
2022-07-09 00:55:51,193: ============================================================
2022-07-09 00:55:51,193: Epoch 35/36 Batch 7300/7662 eta: 1:38:42.673566	Training Loss1 2.6482 (2.5494)	Training Total_Loss 2.6482 (2.5494)	Training Prec@1 99.414 (99.437)	Training Prec@5 0.000 (0.000)	
2022-07-09 00:55:51,193: ============================================================
2022-07-09 00:57:05,146: time cost, forward:0.012005255115662158, backward:0.03394724962147108, data cost:0.6946101793809136 
2022-07-09 00:57:05,147: ============================================================
2022-07-09 00:57:05,147: Epoch 35/36 Batch 7400/7662 eta: 1:37:40.838723	Training Loss1 2.3887 (2.5495)	Training Total_Loss 2.3887 (2.5495)	Training Prec@1 99.609 (99.436)	Training Prec@5 0.000 (0.000)	
2022-07-09 00:57:05,147: ============================================================
2022-07-09 00:58:19,357: time cost, forward:0.012004936197659606, backward:0.033942278456188774, data cost:0.6946338073525974 
2022-07-09 00:58:19,358: ============================================================
2022-07-09 00:58:19,358: Epoch 35/36 Batch 7500/7662 eta: 1:36:47.014553	Training Loss1 2.6808 (2.5497)	Training Total_Loss 2.6808 (2.5497)	Training Prec@1 98.828 (99.436)	Training Prec@5 0.000 (0.000)	
2022-07-09 00:58:19,358: ============================================================
2022-07-09 00:59:32,764: time cost, forward:0.012012654659794826, backward:0.033942199660094256, data cost:0.6945280820731349 
2022-07-09 00:59:32,764: ============================================================
2022-07-09 00:59:32,764: Epoch 35/36 Batch 7600/7662 eta: 1:34:30.651672	Training Loss1 2.4979 (2.5499)	Training Total_Loss 2.4979 (2.5499)	Training Prec@1 99.414 (99.437)	Training Prec@5 0.000 (0.000)	
2022-07-09 00:59:32,765: ============================================================
2022-07-09 01:00:21,678: Epoch 35/36 Batch 7663/7662 eta: 1:33:44.405581	Training Loss1 2.5603 (2.5501)	Training Total_Loss 2.5603 (2.5501)	Training Prec@1 99.609 (99.436)	Training Prec@5 0.000 (0.000)	
2022-07-09 01:00:21,678: ============================================================
2022-07-09 01:00:21,875: Save Checkpoint...
2022-07-09 01:00:21,877: ============================================================
2022-07-09 01:00:24,684: Save done!
2022-07-09 01:00:24,685: ============================================================
2022-07-09 01:01:44,223: time cost, forward:0.012011554506089952, backward:0.033366863173667834, data cost:0.751869625515408 
2022-07-09 01:01:44,224: ============================================================
2022-07-09 01:01:44,224: Epoch 36/36 Batch 100/7662 eta: 1:40:10.822465	Training Loss1 2.2103 (2.5174)	Training Total_Loss 2.2103 (2.5174)	Training Prec@1 100.000 (99.536)	Training Prec@5 0.000 (0.000)	
2022-07-09 01:01:44,224: ============================================================
2022-07-09 01:02:56,717: time cost, forward:0.011834538761694827, backward:0.03322106749568153, data cost:0.7154618531615291 
2022-07-09 01:02:56,717: ============================================================
2022-07-09 01:02:56,717: Epoch 36/36 Batch 200/7662 eta: 1:30:10.162823	Training Loss1 2.4634 (2.5094)	Training Total_Loss 2.4634 (2.5094)	Training Prec@1 99.219 (99.500)	Training Prec@5 0.000 (0.000)	
2022-07-09 01:02:56,717: ============================================================
2022-07-09 01:04:10,895: time cost, forward:0.011828802899772109, backward:0.03364432057409382, data cost:0.7074806530738754 
2022-07-09 01:04:10,895: ============================================================
2022-07-09 01:04:10,896: Epoch 36/36 Batch 300/7662 eta: 1:31:01.744834	Training Loss1 2.5405 (2.5155)	Training Total_Loss 2.5405 (2.5155)	Training Prec@1 99.805 (99.486)	Training Prec@5 0.000 (0.000)	
2022-07-09 01:04:10,896: ============================================================
2022-07-09 01:05:23,025: time cost, forward:0.01191307428785434, backward:0.03365223808097361, data cost:0.7001597194145796 
2022-07-09 01:05:23,025: ============================================================
2022-07-09 01:05:23,026: Epoch 36/36 Batch 400/7662 eta: 1:27:18.807900	Training Loss1 2.5328 (2.5156)	Training Total_Loss 2.5328 (2.5156)	Training Prec@1 99.219 (99.478)	Training Prec@5 0.000 (0.000)	
2022-07-09 01:05:23,026: ============================================================
2022-07-09 01:06:36,445: time cost, forward:0.01187869016536491, backward:0.033737568195931655, data cost:0.6976423144101619 
2022-07-09 01:06:36,445: ============================================================
2022-07-09 01:06:36,446: Epoch 36/36 Batch 500/7662 eta: 1:27:39.082444	Training Loss1 2.4535 (2.5153)	Training Total_Loss 2.4535 (2.5153)	Training Prec@1 99.609 (99.479)	Training Prec@5 0.000 (0.000)	
2022-07-09 01:06:36,446: ============================================================
2022-07-09 01:07:49,708: time cost, forward:0.01198872381538302, backward:0.03386493915309492, data cost:0.695564940298141 
2022-07-09 01:07:49,709: ============================================================
2022-07-09 01:07:49,709: Epoch 36/36 Batch 600/7662 eta: 1:26:14.574414	Training Loss1 2.5315 (2.5187)	Training Total_Loss 2.5315 (2.5187)	Training Prec@1 99.414 (99.476)	Training Prec@5 0.000 (0.000)	
2022-07-09 01:07:49,709: ============================================================
2022-07-09 01:09:02,296: time cost, forward:0.011917703994183411, backward:0.03389593425908996, data cost:0.6932654674131642 
2022-07-09 01:09:02,296: ============================================================
2022-07-09 01:09:02,297: Epoch 36/36 Batch 700/7662 eta: 1:24:14.287304	Training Loss1 2.6266 (2.5191)	Training Total_Loss 2.6266 (2.5191)	Training Prec@1 99.805 (99.477)	Training Prec@5 0.000 (0.000)	
2022-07-09 01:09:02,297: ============================================================
2022-07-09 01:10:15,938: time cost, forward:0.011970268769914725, backward:0.033963877805631065, data cost:0.6927550874454655 
2022-07-09 01:10:15,938: ============================================================
2022-07-09 01:10:15,938: Epoch 36/36 Batch 800/7662 eta: 1:24:14.040541	Training Loss1 2.4829 (2.5207)	Training Total_Loss 2.4829 (2.5207)	Training Prec@1 99.219 (99.473)	Training Prec@5 0.000 (0.000)	
2022-07-09 01:10:15,939: ============================================================
2022-07-09 01:11:29,816: time cost, forward:0.01198671975310838, backward:0.03394812577558439, data cost:0.6926998988672411 
2022-07-09 01:11:29,816: ============================================================
2022-07-09 01:11:29,816: Epoch 36/36 Batch 900/7662 eta: 1:23:16.353372	Training Loss1 2.4502 (2.5206)	Training Total_Loss 2.4502 (2.5206)	Training Prec@1 99.609 (99.478)	Training Prec@5 0.000 (0.000)	
2022-07-09 01:11:29,816: ============================================================
2022-07-09 01:12:43,865: time cost, forward:0.012049070230356089, backward:0.0339871803680817, data cost:0.692702731570682 
2022-07-09 01:12:43,865: ============================================================
2022-07-09 01:12:43,865: Epoch 36/36 Batch 1000/7662 eta: 1:22:13.873275	Training Loss1 2.5670 (2.5210)	Training Total_Loss 2.5670 (2.5210)	Training Prec@1 99.609 (99.476)	Training Prec@5 0.000 (0.000)	
2022-07-09 01:12:43,865: ============================================================
2022-07-09 01:13:57,528: time cost, forward:0.012004180861343786, backward:0.03392972720547955, data cost:0.6925617928283664 
2022-07-09 01:13:57,528: ============================================================
2022-07-09 01:13:57,529: Epoch 36/36 Batch 1100/7662 eta: 1:20:34.529877	Training Loss1 2.3946 (2.5223)	Training Total_Loss 2.3946 (2.5223)	Training Prec@1 99.219 (99.470)	Training Prec@5 0.000 (0.000)	
2022-07-09 01:13:57,529: ============================================================
2022-07-09 01:15:10,475: time cost, forward:0.011950543167394235, backward:0.03390277992993022, data cost:0.6918532225964366 
2022-07-09 01:15:10,476: ============================================================
2022-07-09 01:15:10,476: Epoch 36/36 Batch 1200/7662 eta: 1:18:34.595599	Training Loss1 2.5367 (2.5232)	Training Total_Loss 2.5367 (2.5232)	Training Prec@1 99.414 (99.466)	Training Prec@5 0.000 (0.000)	
2022-07-09 01:15:10,476: ============================================================
2022-07-09 01:16:24,903: time cost, forward:0.011956512973894056, backward:0.033909088836622935, data cost:0.692307702571819 
2022-07-09 01:16:24,904: ============================================================
2022-07-09 01:16:24,904: Epoch 36/36 Batch 1300/7662 eta: 1:18:55.850286	Training Loss1 2.6555 (2.5239)	Training Total_Loss 2.6555 (2.5239)	Training Prec@1 99.219 (99.467)	Training Prec@5 0.000 (0.000)	
2022-07-09 01:16:24,904: ============================================================
2022-07-09 01:17:38,627: time cost, forward:0.011945209646327228, backward:0.03395530068081903, data cost:0.6921560040024709 
2022-07-09 01:17:38,628: ============================================================
2022-07-09 01:17:38,628: Epoch 36/36 Batch 1400/7662 eta: 1:16:57.323143	Training Loss1 2.6080 (2.5257)	Training Total_Loss 2.6080 (2.5257)	Training Prec@1 98.828 (99.466)	Training Prec@5 0.000 (0.000)	
2022-07-09 01:17:38,628: ============================================================
2022-07-09 01:18:51,738: time cost, forward:0.011926288362977662, backward:0.033957561705413065, data cost:0.6916577516992224 
2022-07-09 01:18:51,738: ============================================================
2022-07-09 01:18:51,738: Epoch 36/36 Batch 1500/7662 eta: 1:15:05.800782	Training Loss1 2.5238 (2.5261)	Training Total_Loss 2.5238 (2.5261)	Training Prec@1 98.828 (99.463)	Training Prec@5 0.000 (0.000)	
2022-07-09 01:18:51,738: ============================================================
2022-07-09 01:20:05,862: time cost, forward:0.01189934275461928, backward:0.0339869634295494, data cost:0.6918557319438331 
2022-07-09 01:20:05,862: ============================================================
2022-07-09 01:20:05,862: Epoch 36/36 Batch 1600/7662 eta: 1:14:54.147217	Training Loss1 2.6444 (2.5280)	Training Total_Loss 2.6444 (2.5280)	Training Prec@1 99.414 (99.463)	Training Prec@5 0.000 (0.000)	
2022-07-09 01:20:05,863: ============================================================
2022-07-09 01:21:19,729: time cost, forward:0.011908118061067919, backward:0.03401860761389864, data cost:0.6918382222263725 
2022-07-09 01:21:19,729: ============================================================
2022-07-09 01:21:19,729: Epoch 36/36 Batch 1700/7662 eta: 1:13:24.677032	Training Loss1 2.6128 (2.5285)	Training Total_Loss 2.6128 (2.5285)	Training Prec@1 99.609 (99.463)	Training Prec@5 0.000 (0.000)	
2022-07-09 01:21:19,729: ============================================================
2022-07-09 01:22:34,555: time cost, forward:0.011929064210485656, backward:0.03399139235190646, data cost:0.6923776578081522 
2022-07-09 01:22:34,555: ============================================================
2022-07-09 01:22:34,556: Epoch 36/36 Batch 1800/7662 eta: 1:13:07.063629	Training Loss1 2.4668 (2.5290)	Training Total_Loss 2.4668 (2.5290)	Training Prec@1 100.000 (99.460)	Training Prec@5 0.000 (0.000)	
2022-07-09 01:22:34,556: ============================================================
2022-07-09 01:23:47,291: time cost, forward:0.011936950583154117, backward:0.03398314283169088, data cost:0.6917808000635888 
2022-07-09 01:23:47,291: ============================================================
2022-07-09 01:23:47,291: Epoch 36/36 Batch 1900/7662 eta: 1:09:51.753067	Training Loss1 2.6454 (2.5288)	Training Total_Loss 2.6454 (2.5288)	Training Prec@1 99.219 (99.458)	Training Prec@5 0.000 (0.000)	
2022-07-09 01:23:47,291: ============================================================
2022-07-09 01:25:01,162: time cost, forward:0.011925340593308433, backward:0.033950278495418366, data cost:0.691851777157347 
2022-07-09 01:25:01,162: ============================================================
2022-07-09 01:25:01,163: Epoch 36/36 Batch 2000/7662 eta: 1:09:43.341885	Training Loss1 2.6084 (2.5290)	Training Total_Loss 2.6084 (2.5290)	Training Prec@1 99.023 (99.460)	Training Prec@5 0.000 (0.000)	
2022-07-09 01:25:01,163: ============================================================
2022-07-09 01:26:14,648: time cost, forward:0.011919979710644799, backward:0.03394673596455291, data cost:0.691684360558672 
2022-07-09 01:26:14,648: ============================================================
2022-07-09 01:26:14,649: Epoch 36/36 Batch 2100/7662 eta: 1:08:08.026223	Training Loss1 2.5757 (2.5288)	Training Total_Loss 2.5757 (2.5288)	Training Prec@1 99.609 (99.457)	Training Prec@5 0.000 (0.000)	
2022-07-09 01:26:14,649: ============================================================
2022-07-09 01:27:30,107: time cost, forward:0.011917550653801987, backward:0.033956201686919846, data cost:0.6924409949817458 
2022-07-09 01:27:30,107: ============================================================
2022-07-09 01:27:30,107: Epoch 36/36 Batch 2200/7662 eta: 1:08:42.314079	Training Loss1 2.5629 (2.5293)	Training Total_Loss 2.5629 (2.5293)	Training Prec@1 99.609 (99.457)	Training Prec@5 0.000 (0.000)	
2022-07-09 01:27:30,108: ============================================================
2022-07-09 01:28:43,933: time cost, forward:0.011920850035313577, backward:0.03396099792868742, data cost:0.6923915654381964 
2022-07-09 01:28:43,934: ============================================================
2022-07-09 01:28:43,934: Epoch 36/36 Batch 2300/7662 eta: 1:05:59.321457	Training Loss1 2.2400 (2.5299)	Training Total_Loss 2.2400 (2.5299)	Training Prec@1 99.023 (99.454)	Training Prec@5 0.000 (0.000)	
2022-07-09 01:28:43,934: ============================================================
2022-07-09 01:29:56,792: time cost, forward:0.01190367168364499, backward:0.03395454145163583, data cost:0.6919959583298372 
2022-07-09 01:29:56,792: ============================================================
2022-07-09 01:29:56,792: Epoch 36/36 Batch 2400/7662 eta: 1:03:54.529253	Training Loss1 2.5034 (2.5304)	Training Total_Loss 2.5034 (2.5304)	Training Prec@1 99.609 (99.453)	Training Prec@5 0.000 (0.000)	
2022-07-09 01:29:56,792: ============================================================
2022-07-09 01:31:10,387: time cost, forward:0.011905762232413717, backward:0.03394149092971539, data cost:0.6918990202740032 
2022-07-09 01:31:10,387: ============================================================
2022-07-09 01:31:10,388: Epoch 36/36 Batch 2500/7662 eta: 1:03:19.722715	Training Loss1 2.5144 (2.5315)	Training Total_Loss 2.5144 (2.5315)	Training Prec@1 99.609 (99.452)	Training Prec@5 0.000 (0.000)	
2022-07-09 01:31:10,388: ============================================================
2022-07-09 01:32:23,156: time cost, forward:0.011910230850155145, backward:0.03394295124422362, data cost:0.6914933303907863 
2022-07-09 01:32:23,157: ============================================================
2022-07-09 01:32:23,157: Epoch 36/36 Batch 2600/7662 eta: 1:01:24.317927	Training Loss1 2.5470 (2.5318)	Training Total_Loss 2.5470 (2.5318)	Training Prec@1 99.219 (99.449)	Training Prec@5 0.000 (0.000)	
2022-07-09 01:32:23,157: ============================================================
2022-07-09 01:33:36,862: time cost, forward:0.01186919636353602, backward:0.0339338031244437, data cost:0.6915043782816855 
2022-07-09 01:33:36,862: ============================================================
2022-07-09 01:33:36,862: Epoch 36/36 Batch 2700/7662 eta: 1:00:57.984234	Training Loss1 2.6104 (2.5324)	Training Total_Loss 2.6104 (2.5324)	Training Prec@1 99.219 (99.449)	Training Prec@5 0.000 (0.000)	
2022-07-09 01:33:36,862: ============================================================
2022-07-09 01:34:50,863: time cost, forward:0.011857053900497561, backward:0.03393770320452124, data cost:0.6915925197321928 
2022-07-09 01:34:50,864: ============================================================
2022-07-09 01:34:50,864: Epoch 36/36 Batch 2800/7662 eta: 0:59:58.704395	Training Loss1 2.5399 (2.5330)	Training Total_Loss 2.5399 (2.5330)	Training Prec@1 98.633 (99.448)	Training Prec@5 0.000 (0.000)	
2022-07-09 01:34:50,864: ============================================================
2022-07-09 01:36:04,739: time cost, forward:0.011828787781609137, backward:0.03392734236452406, data cost:0.6916587183334861 
2022-07-09 01:36:04,740: ============================================================
2022-07-09 01:36:04,740: Epoch 36/36 Batch 2900/7662 eta: 0:58:38.720281	Training Loss1 2.6757 (2.5328)	Training Total_Loss 2.6757 (2.5328)	Training Prec@1 99.609 (99.447)	Training Prec@5 0.000 (0.000)	
2022-07-09 01:36:04,740: ============================================================
2022-07-09 01:37:18,954: time cost, forward:0.01181685038112171, backward:0.033911086273574954, data cost:0.6918274666238284 
2022-07-09 01:37:18,954: ============================================================
2022-07-09 01:37:18,954: Epoch 36/36 Batch 3000/7662 eta: 0:57:40.624089	Training Loss1 2.4784 (2.5333)	Training Total_Loss 2.4784 (2.5333)	Training Prec@1 99.609 (99.447)	Training Prec@5 0.000 (0.000)	
2022-07-09 01:37:18,955: ============================================================
2022-07-09 01:38:32,900: time cost, forward:0.011828373693273544, backward:0.03390879944933349, data cost:0.6918567118624711 
2022-07-09 01:38:32,900: ============================================================
2022-07-09 01:38:32,900: Epoch 36/36 Batch 3100/7662 eta: 0:56:14.152014	Training Loss1 2.6673 (2.5341)	Training Total_Loss 2.6673 (2.5341)	Training Prec@1 99.414 (99.446)	Training Prec@5 0.000 (0.000)	
2022-07-09 01:38:32,901: ============================================================
2022-07-09 01:39:46,709: time cost, forward:0.011812710769476835, backward:0.03391120619384823, data cost:0.6918708988188504 
2022-07-09 01:39:46,709: ============================================================
2022-07-09 01:39:46,709: Epoch 36/36 Batch 3200/7662 eta: 0:54:54.097022	Training Loss1 2.6196 (2.5346)	Training Total_Loss 2.6196 (2.5346)	Training Prec@1 100.000 (99.447)	Training Prec@5 0.000 (0.000)	
2022-07-09 01:39:46,710: ============================================================
2022-07-09 01:41:01,070: time cost, forward:0.011817520045627063, backward:0.03391296518828226, data cost:0.6920314620718446 
2022-07-09 01:41:01,070: ============================================================
2022-07-09 01:41:01,070: Epoch 36/36 Batch 3300/7662 eta: 0:54:04.366896	Training Loss1 2.5797 (2.5351)	Training Total_Loss 2.5797 (2.5351)	Training Prec@1 99.414 (99.446)	Training Prec@5 0.000 (0.000)	
2022-07-09 01:41:01,070: ============================================================
2022-07-09 01:42:15,630: time cost, forward:0.011815738243087315, backward:0.03393391477041085, data cost:0.6922264022664415 
2022-07-09 01:42:15,631: ============================================================
2022-07-09 01:42:15,631: Epoch 36/36 Batch 3400/7662 eta: 0:52:58.514314	Training Loss1 2.5748 (2.5352)	Training Total_Loss 2.5748 (2.5352)	Training Prec@1 99.414 (99.446)	Training Prec@5 0.000 (0.000)	
2022-07-09 01:42:15,631: ============================================================
2022-07-09 01:43:29,601: time cost, forward:0.01182506758337465, backward:0.03394321415484991, data cost:0.6922369720800224 
2022-07-09 01:43:29,602: ============================================================
2022-07-09 01:43:29,602: Epoch 36/36 Batch 3500/7662 eta: 0:51:19.416917	Training Loss1 2.5631 (2.5355)	Training Total_Loss 2.5631 (2.5355)	Training Prec@1 100.000 (99.448)	Training Prec@5 0.000 (0.000)	
2022-07-09 01:43:29,602: ============================================================
2022-07-09 01:44:45,293: time cost, forward:0.011845607299147529, backward:0.03394430012926852, data cost:0.692716208124333 
2022-07-09 01:44:45,294: ============================================================
2022-07-09 01:44:45,295: Epoch 36/36 Batch 3600/7662 eta: 0:51:15.385011	Training Loss1 2.4800 (2.5359)	Training Total_Loss 2.4800 (2.5359)	Training Prec@1 99.219 (99.447)	Training Prec@5 0.000 (0.000)	
2022-07-09 01:44:45,295: ============================================================
2022-07-09 01:45:59,411: time cost, forward:0.011864326489426117, backward:0.03395573311027368, data cost:0.6927480015699269 
2022-07-09 01:45:59,411: ============================================================
2022-07-09 01:45:59,411: Epoch 36/36 Batch 3700/7662 eta: 0:48:57.246642	Training Loss1 2.3957 (2.5360)	Training Total_Loss 2.3957 (2.5360)	Training Prec@1 100.000 (99.447)	Training Prec@5 0.000 (0.000)	
2022-07-09 01:45:59,411: ============================================================
2022-07-09 01:47:13,418: time cost, forward:0.01185571096168753, backward:0.033963160252502074, data cost:0.6927765211515534 
2022-07-09 01:47:13,418: ============================================================
2022-07-09 01:47:13,418: Epoch 36/36 Batch 3800/7662 eta: 0:47:38.891219	Training Loss1 2.6199 (2.5359)	Training Total_Loss 2.6199 (2.5359)	Training Prec@1 99.219 (99.445)	Training Prec@5 0.000 (0.000)	
2022-07-09 01:47:13,418: ============================================================
2022-07-09 01:48:26,329: time cost, forward:0.011848300015140601, backward:0.03396724786291247, data cost:0.6925097068293519 
2022-07-09 01:48:26,329: ============================================================
2022-07-09 01:48:26,329: Epoch 36/36 Batch 3900/7662 eta: 0:45:43.644717	Training Loss1 2.6292 (2.5358)	Training Total_Loss 2.6292 (2.5358)	Training Prec@1 99.023 (99.445)	Training Prec@5 0.000 (0.000)	
2022-07-09 01:48:26,329: ============================================================
2022-07-09 01:49:40,787: time cost, forward:0.01187746958244917, backward:0.033965899664689735, data cost:0.6926236756594963 
2022-07-09 01:49:40,787: ============================================================
2022-07-09 01:49:40,787: Epoch 36/36 Batch 4000/7662 eta: 0:45:27.388058	Training Loss1 2.5927 (2.5370)	Training Total_Loss 2.5927 (2.5370)	Training Prec@1 99.219 (99.443)	Training Prec@5 0.000 (0.000)	
2022-07-09 01:49:40,787: ============================================================
2022-07-09 01:50:55,318: time cost, forward:0.01190147297531839, backward:0.03398065434400266, data cost:0.6927404992898577 
2022-07-09 01:50:55,319: ============================================================
2022-07-09 01:50:55,319: Epoch 36/36 Batch 4100/7662 eta: 0:44:15.570813	Training Loss1 2.5269 (2.5371)	Training Total_Loss 2.5269 (2.5371)	Training Prec@1 99.219 (99.443)	Training Prec@5 0.000 (0.000)	
2022-07-09 01:50:55,319: ============================================================
2022-07-09 01:52:08,484: time cost, forward:0.011932533677063206, backward:0.03398199903593088, data cost:0.6925274333831213 
2022-07-09 01:52:08,484: ============================================================
2022-07-09 01:52:08,484: Epoch 36/36 Batch 4200/7662 eta: 0:42:13.716573	Training Loss1 2.6059 (2.5374)	Training Total_Loss 2.6059 (2.5374)	Training Prec@1 99.023 (99.443)	Training Prec@5 0.000 (0.000)	
2022-07-09 01:52:08,485: ============================================================
2022-07-09 01:53:22,630: time cost, forward:0.011919936847620216, backward:0.033975497543271074, data cost:0.6926038655660185 
2022-07-09 01:53:22,631: ============================================================
2022-07-09 01:53:22,631: Epoch 36/36 Batch 4300/7662 eta: 0:41:33.545404	Training Loss1 2.4660 (2.5377)	Training Total_Loss 2.4660 (2.5377)	Training Prec@1 99.609 (99.444)	Training Prec@5 0.000 (0.000)	
2022-07-09 01:53:22,631: ============================================================
2022-07-09 01:54:37,127: time cost, forward:0.0119080623731637, backward:0.033951470135937876, data cost:0.6927763000621826 
2022-07-09 01:54:37,127: ============================================================
2022-07-09 01:54:37,127: Epoch 36/36 Batch 4400/7662 eta: 0:40:30.811756	Training Loss1 2.5881 (2.5383)	Training Total_Loss 2.5881 (2.5383)	Training Prec@1 99.609 (99.443)	Training Prec@5 0.000 (0.000)	
2022-07-09 01:54:37,127: ============================================================
2022-07-09 01:55:50,249: time cost, forward:0.011905725756388924, backward:0.03393113430300456, data cost:0.6926177774807908 
2022-07-09 01:55:50,250: ============================================================
2022-07-09 01:55:50,250: Epoch 36/36 Batch 4500/7662 eta: 0:38:32.877282	Training Loss1 2.6173 (2.5385)	Training Total_Loss 2.6173 (2.5385)	Training Prec@1 99.414 (99.443)	Training Prec@5 0.000 (0.000)	
2022-07-09 01:55:50,250: ============================================================
2022-07-09 01:57:02,917: time cost, forward:0.0119217802944793, backward:0.03391360044220163, data cost:0.6923489852116455 
2022-07-09 01:57:02,917: ============================================================
2022-07-09 01:57:02,917: Epoch 36/36 Batch 4600/7662 eta: 0:37:05.805504	Training Loss1 2.6377 (2.5388)	Training Total_Loss 2.6377 (2.5388)	Training Prec@1 99.805 (99.442)	Training Prec@5 0.000 (0.000)	
2022-07-09 01:57:02,918: ============================================================
2022-07-09 01:58:17,631: time cost, forward:0.011935384660661156, backward:0.033900364380386135, data cost:0.6925275828590238 
2022-07-09 01:58:17,631: ============================================================
2022-07-09 01:58:17,631: Epoch 36/36 Batch 4700/7662 eta: 0:36:53.769391	Training Loss1 2.5659 (2.5390)	Training Total_Loss 2.5659 (2.5390)	Training Prec@1 99.805 (99.442)	Training Prec@5 0.000 (0.000)	
2022-07-09 01:58:17,631: ============================================================
2022-07-09 01:59:31,677: time cost, forward:0.01194681940438425, backward:0.03389912546860921, data cost:0.692547551441451 
2022-07-09 01:59:31,678: ============================================================
2022-07-09 01:59:31,678: Epoch 36/36 Batch 4800/7662 eta: 0:35:19.956222	Training Loss1 2.5664 (2.5394)	Training Total_Loss 2.5664 (2.5394)	Training Prec@1 99.414 (99.441)	Training Prec@5 0.000 (0.000)	
2022-07-09 01:59:31,678: ============================================================
2022-07-09 02:00:44,427: time cost, forward:0.011957445347107146, backward:0.03390354641993987, data cost:0.6922987693911987 
2022-07-09 02:00:44,428: ============================================================
2022-07-09 02:00:44,428: Epoch 36/36 Batch 4900/7662 eta: 0:33:30.083343	Training Loss1 2.6020 (2.5399)	Training Total_Loss 2.6020 (2.5399)	Training Prec@1 99.805 (99.441)	Training Prec@5 0.000 (0.000)	
2022-07-09 02:00:44,428: ============================================================
2022-07-09 02:01:57,878: time cost, forward:0.01199058342704918, backward:0.033893409073889366, data cost:0.6921907217174942 
2022-07-09 02:01:57,879: ============================================================
2022-07-09 02:01:57,879: Epoch 36/36 Batch 5000/7662 eta: 0:32:35.993698	Training Loss1 2.6151 (2.5400)	Training Total_Loss 2.6151 (2.5400)	Training Prec@1 99.219 (99.442)	Training Prec@5 0.000 (0.000)	
2022-07-09 02:01:57,879: ============================================================
2022-07-09 02:03:10,795: time cost, forward:0.011988013696380632, backward:0.033858942924749384, data cost:0.6920366842715406 
2022-07-09 02:03:10,796: ============================================================
2022-07-09 02:03:10,796: Epoch 36/36 Batch 5100/7662 eta: 0:31:08.865681	Training Loss1 2.3471 (2.5399)	Training Total_Loss 2.3471 (2.5399)	Training Prec@1 100.000 (99.442)	Training Prec@5 0.000 (0.000)	
2022-07-09 02:03:10,796: ============================================================
2022-07-09 02:04:24,796: time cost, forward:0.01199596880674133, backward:0.03386321643793393, data cost:0.6920595634531622 
2022-07-09 02:04:24,797: ============================================================
2022-07-09 02:04:24,797: Epoch 36/36 Batch 5200/7662 eta: 0:30:22.647024	Training Loss1 2.4867 (2.5404)	Training Total_Loss 2.4867 (2.5404)	Training Prec@1 99.414 (99.442)	Training Prec@5 0.000 (0.000)	
2022-07-09 02:04:24,797: ============================================================
2022-07-09 02:05:38,757: time cost, forward:0.011990259359143414, backward:0.033866785858954813, data cost:0.6920745057370398 
2022-07-09 02:05:38,757: ============================================================
2022-07-09 02:05:38,758: Epoch 36/36 Batch 5300/7662 eta: 0:29:07.691409	Training Loss1 2.4642 (2.5405)	Training Total_Loss 2.4642 (2.5405)	Training Prec@1 98.633 (99.442)	Training Prec@5 0.000 (0.000)	
2022-07-09 02:05:38,758: ============================================================
2022-07-09 02:06:52,888: time cost, forward:0.01198305141309783, backward:0.03384708011342455, data cost:0.6921569412561407 
2022-07-09 02:06:52,889: ============================================================
2022-07-09 02:06:52,889: Epoch 36/36 Batch 5400/7662 eta: 0:27:57.592424	Training Loss1 2.5506 (2.5408)	Training Total_Loss 2.5506 (2.5408)	Training Prec@1 99.414 (99.442)	Training Prec@5 0.000 (0.000)	
2022-07-09 02:06:52,889: ============================================================
2022-07-09 02:08:08,037: time cost, forward:0.012002918021768673, backward:0.03386401384391445, data cost:0.6923548738660324 
2022-07-09 02:08:08,037: ============================================================
2022-07-09 02:08:08,038: Epoch 36/36 Batch 5500/7662 eta: 0:27:05.461863	Training Loss1 2.5215 (2.5411)	Training Total_Loss 2.5215 (2.5411)	Training Prec@1 99.609 (99.442)	Training Prec@5 0.000 (0.000)	
2022-07-09 02:08:08,038: ============================================================
2022-07-09 02:09:21,488: time cost, forward:0.012002439578956185, backward:0.03385661320721258, data cost:0.6922826005169528 
2022-07-09 02:09:21,489: ============================================================
2022-07-09 02:09:21,489: Epoch 36/36 Batch 5600/7662 eta: 0:25:15.298984	Training Loss1 2.4559 (2.5413)	Training Total_Loss 2.4559 (2.5413)	Training Prec@1 99.414 (99.441)	Training Prec@5 0.000 (0.000)	
2022-07-09 02:09:21,489: ============================================================
2022-07-09 02:10:36,432: time cost, forward:0.012009197796702615, backward:0.03384863365991301, data cost:0.6924744650112326 
2022-07-09 02:10:36,432: ============================================================
2022-07-09 02:10:36,432: Epoch 36/36 Batch 5700/7662 eta: 0:24:31.140152	Training Loss1 2.5416 (2.5415)	Training Total_Loss 2.5416 (2.5415)	Training Prec@1 99.414 (99.441)	Training Prec@5 0.000 (0.000)	
2022-07-09 02:10:36,432: ============================================================
2022-07-09 02:11:50,282: time cost, forward:0.012009093218331584, backward:0.0338421462013467, data cost:0.6924710466977254 
2022-07-09 02:11:50,282: ============================================================
2022-07-09 02:11:50,283: Epoch 36/36 Batch 5800/7662 eta: 0:22:55.830331	Training Loss1 2.5279 (2.5421)	Training Total_Loss 2.5279 (2.5421)	Training Prec@1 99.609 (99.441)	Training Prec@5 0.000 (0.000)	
2022-07-09 02:11:50,283: ============================================================
2022-07-09 02:13:04,535: time cost, forward:0.012010836564882223, backward:0.03382617442319708, data cost:0.69254408450142 
2022-07-09 02:13:04,536: ============================================================
2022-07-09 02:13:04,536: Epoch 36/36 Batch 5900/7662 eta: 0:21:49.085922	Training Loss1 2.3939 (2.5424)	Training Total_Loss 2.3939 (2.5424)	Training Prec@1 99.414 (99.440)	Training Prec@5 0.000 (0.000)	
2022-07-09 02:13:04,536: ============================================================
2022-07-09 02:14:20,015: time cost, forward:0.012025814013473987, backward:0.03382813141611859, data cost:0.6927953714290288 
2022-07-09 02:14:20,015: ============================================================
2022-07-09 02:14:20,016: Epoch 36/36 Batch 6000/7662 eta: 0:20:55.228249	Training Loss1 2.4558 (2.5426)	Training Total_Loss 2.4558 (2.5426)	Training Prec@1 99.023 (99.440)	Training Prec@5 0.000 (0.000)	
2022-07-09 02:14:20,016: ============================================================
2022-07-09 02:15:33,487: time cost, forward:0.012032514596536602, backward:0.033821463995359825, data cost:0.6927198049845823 
2022-07-09 02:15:33,488: ============================================================
2022-07-09 02:15:33,488: Epoch 36/36 Batch 6100/7662 eta: 0:19:08.371893	Training Loss1 2.5331 (2.5429)	Training Total_Loss 2.5331 (2.5429)	Training Prec@1 99.805 (99.439)	Training Prec@5 0.000 (0.000)	
2022-07-09 02:15:33,488: ============================================================
2022-07-09 02:16:48,690: time cost, forward:0.01202847238778491, backward:0.03383692950467022, data cost:0.6929154362596222 
2022-07-09 02:16:48,691: ============================================================
2022-07-09 02:16:48,691: Epoch 36/36 Batch 6200/7662 eta: 0:18:20.222465	Training Loss1 2.6100 (2.5432)	Training Total_Loss 2.6100 (2.5432)	Training Prec@1 99.219 (99.439)	Training Prec@5 0.000 (0.000)	
2022-07-09 02:16:48,691: ============================================================
2022-07-09 02:18:03,331: time cost, forward:0.012033613168317034, backward:0.03383608166424693, data cost:0.6930231088909918 
2022-07-09 02:18:03,331: ============================================================
2022-07-09 02:18:03,331: Epoch 36/36 Batch 6300/7662 eta: 0:16:57.347884	Training Loss1 2.5797 (2.5434)	Training Total_Loss 2.5797 (2.5434)	Training Prec@1 99.609 (99.438)	Training Prec@5 0.000 (0.000)	
2022-07-09 02:18:03,331: ============================================================
2022-07-09 02:19:18,510: time cost, forward:0.012030590510141069, backward:0.03384600365268083, data cost:0.6932077294942979 
2022-07-09 02:19:18,510: ============================================================
2022-07-09 02:19:18,510: Epoch 36/36 Batch 6400/7662 eta: 0:15:49.510317	Training Loss1 2.3966 (2.5436)	Training Total_Loss 2.3966 (2.5436)	Training Prec@1 99.414 (99.438)	Training Prec@5 0.000 (0.000)	
2022-07-09 02:19:18,510: ============================================================
2022-07-09 02:20:32,837: time cost, forward:0.012044327573457816, backward:0.033864918956941485, data cost:0.693230828462628 
2022-07-09 02:20:32,837: ============================================================
2022-07-09 02:20:32,838: Epoch 36/36 Batch 6500/7662 eta: 0:14:24.426300	Training Loss1 2.8609 (2.5438)	Training Total_Loss 2.8609 (2.5438)	Training Prec@1 99.023 (99.437)	Training Prec@5 0.000 (0.000)	
2022-07-09 02:20:32,838: ============================================================
2022-07-09 02:21:46,788: time cost, forward:0.01204683585932154, backward:0.033866216240732716, data cost:0.6932219513475326 
2022-07-09 02:21:46,789: ============================================================
2022-07-09 02:21:46,789: Epoch 36/36 Batch 6600/7662 eta: 0:13:06.101015	Training Loss1 2.5464 (2.5443)	Training Total_Loss 2.5464 (2.5443)	Training Prec@1 99.414 (99.438)	Training Prec@5 0.000 (0.000)	
2022-07-09 02:21:46,789: ============================================================
2022-07-09 02:23:01,914: time cost, forward:0.012059312878233013, backward:0.03385181864049296, data cost:0.6933951596036422 
2022-07-09 02:23:01,915: ============================================================
2022-07-09 02:23:01,915: Epoch 36/36 Batch 6700/7662 eta: 0:12:03.464213	Training Loss1 2.7336 (2.5444)	Training Total_Loss 2.7336 (2.5444)	Training Prec@1 98.828 (99.438)	Training Prec@5 0.000 (0.000)	
2022-07-09 02:23:01,915: ============================================================
2022-07-09 02:24:17,356: time cost, forward:0.01207167759662622, backward:0.03383468484015899, data cost:0.6936145025169977 
2022-07-09 02:24:17,357: ============================================================
2022-07-09 02:24:17,357: Epoch 36/36 Batch 6800/7662 eta: 0:10:51.064733	Training Loss1 2.5491 (2.5451)	Training Total_Loss 2.5491 (2.5451)	Training Prec@1 99.609 (99.437)	Training Prec@5 0.000 (0.000)	
2022-07-09 02:24:17,357: ============================================================
2022-07-09 02:25:32,648: time cost, forward:0.01207243606549689, backward:0.03383735132003145, data cost:0.693795740025547 
2022-07-09 02:25:32,649: ============================================================
2022-07-09 02:25:32,649: Epoch 36/36 Batch 6900/7662 eta: 0:09:34.476945	Training Loss1 2.6502 (2.5455)	Training Total_Loss 2.6502 (2.5455)	Training Prec@1 99.609 (99.436)	Training Prec@5 0.000 (0.000)	
2022-07-09 02:25:32,649: ============================================================
2022-07-09 02:26:46,886: time cost, forward:0.012073563003322026, backward:0.03384026286772003, data cost:0.6938215100198052 
2022-07-09 02:26:46,886: ============================================================
2022-07-09 02:26:46,887: Epoch 36/36 Batch 7000/7662 eta: 0:08:12.196488	Training Loss1 2.5317 (2.5458)	Training Total_Loss 2.5317 (2.5458)	Training Prec@1 99.805 (99.437)	Training Prec@5 0.000 (0.000)	
2022-07-09 02:26:46,887: ============================================================
2022-07-09 02:28:02,333: time cost, forward:0.012076187912956697, backward:0.033841293653076275, data cost:0.6940170966633475 
2022-07-09 02:28:02,333: ============================================================
2022-07-09 02:28:02,334: Epoch 36/36 Batch 7100/7662 eta: 0:07:04.767017	Training Loss1 2.4794 (2.5458)	Training Total_Loss 2.4794 (2.5458)	Training Prec@1 100.000 (99.436)	Training Prec@5 0.000 (0.000)	
2022-07-09 02:28:02,334: ============================================================
2022-07-09 02:29:17,358: time cost, forward:0.012073548241843281, backward:0.033842128554157525, data cost:0.6941544173707365 
2022-07-09 02:29:17,358: ============================================================
2022-07-09 02:29:17,358: Epoch 36/36 Batch 7200/7662 eta: 0:05:47.364417	Training Loss1 2.4729 (2.5462)	Training Total_Loss 2.4729 (2.5462)	Training Prec@1 99.414 (99.437)	Training Prec@5 0.000 (0.000)	
2022-07-09 02:29:17,358: ============================================================
2022-07-09 02:30:31,656: time cost, forward:0.012075928894358639, backward:0.033841478610662654, data cost:0.6941836425777591 
2022-07-09 02:30:31,656: ============================================================
2022-07-09 02:30:31,657: Epoch 36/36 Batch 7300/7662 eta: 0:04:29.702527	Training Loss1 2.4576 (2.5464)	Training Total_Loss 2.4576 (2.5464)	Training Prec@1 99.609 (99.437)	Training Prec@5 0.000 (0.000)	
2022-07-09 02:30:31,657: ============================================================
2022-07-09 02:31:45,929: time cost, forward:0.012078687039109916, backward:0.03384353728177725, data cost:0.6942069617167149 
2022-07-09 02:31:45,930: ============================================================
2022-07-09 02:31:45,930: Epoch 36/36 Batch 7400/7662 eta: 0:03:15.338416	Training Loss1 2.5304 (2.5462)	Training Total_Loss 2.5304 (2.5462)	Training Prec@1 100.000 (99.437)	Training Prec@5 0.000 (0.000)	
2022-07-09 02:31:45,930: ============================================================
2022-07-09 02:32:59,661: time cost, forward:0.012089288430239998, backward:0.03383371829668638, data cost:0.6941581580587698 
2022-07-09 02:32:59,661: ============================================================
2022-07-09 02:32:59,661: Epoch 36/36 Batch 7500/7662 eta: 0:02:00.182644	Training Loss1 2.5928 (2.5466)	Training Total_Loss 2.5928 (2.5466)	Training Prec@1 99.219 (99.437)	Training Prec@5 0.000 (0.000)	
2022-07-09 02:32:59,662: ============================================================
2022-07-09 02:34:15,032: time cost, forward:0.012099316691486344, backward:0.03383530301629815, data cost:0.6943189268253998 
2022-07-09 02:34:15,033: ============================================================
2022-07-09 02:34:15,033: Epoch 36/36 Batch 7600/7662 eta: 0:00:47.483966	Training Loss1 2.6008 (2.5469)	Training Total_Loss 2.6008 (2.5469)	Training Prec@1 99.805 (99.437)	Training Prec@5 0.000 (0.000)	
2022-07-09 02:34:15,033: ============================================================
2022-07-09 02:35:03,728: Epoch 36/36 Batch 7663/7662 eta: 0:00:00	Training Loss1 2.6809 (2.5472)	Training Total_Loss 2.6809 (2.5472)	Training Prec@1 99.414 (99.437)	Training Prec@5 0.000 (0.000)	
2022-07-09 02:35:03,728: ============================================================
2022-07-09 02:35:03,801: Save Checkpoint...
2022-07-09 02:35:03,816: ============================================================
2022-07-09 02:35:06,197: Save done!
2022-07-09 02:35:06,197: ============================================================
